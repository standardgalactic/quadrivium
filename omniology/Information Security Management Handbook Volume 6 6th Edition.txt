
Information Security
Management Handbook
Sixth Edition
Volume 6

OTHER INFORMATION SECURITY BOOKS FROM AUERBACH
A Practical Guide to Security Assessments 
Sudhanshu Kairab
ISBN 978-0-8493-1706-4
Adaptive Security Management Architecture 
James S. Tiller
ISBN 978-0-8493-7052-6 
Assessing and Managing Security Risk in IT 
Systems: A Structured Methodology 
John McCumber
ISBN 978-0-8493-2232-7 
Asset Protection through Security 
Awareness
Tyler Justin Speed
ISBN 978-1-4398-0982-2 
Cyber Security Essentials 
James Graham and Ryan Olson, Editors
ISBN 978-1-4398-5123-4 
Data Mining and Machine Learning in 
Cybersecurity 
Sumeet Dua and Xian Du
ISBN 978-1-4398-3942-3
Defense against the Black Arts: How 
Hackers Do What They Do and How to 
Protect against It 
Jesse Varsalone and Matthew McFadden
ISBN 978-1-4398-2119-0 
Publication Date:  September 09, 2011
FISMA Principles and Best Practices: 
Beyond Compliance 
Patrick D. Howard
ISBN 978-1-4200-7829-9 
Information Security Risk Analysis, Third 
Edition 
Thomas R. Peltier
ISBN 978-1-4398-3956-0
Information Technology Control and Audit, 
Third Edition 
Frederick Gallegos and Sandra Senft
ISBN 978-1-4200-6550-3 
Introduction to Security and Network 
Forensics 
William J. Buchanan
ISBN 978-0-8493-3568-6 
Machine Learning Forensics for Law 
Enforcement, Security, and Intelligence 
Jesus Mena
ISBN 978-1-4398-6069-4 
Managing an Information Security and 
Privacy Awareness and Training Program, 
Second Edition 
Rebecca Herold
ISBN 978-1-4398-1545-8 
Mobile Device Security: A Comprehensive 
Guide to Securing Your Information in a 
Moving World 
Stephen Fried
ISBN 978-1-4398-2016-2 
Practical Risk Management for the CIO 
Mark Scherling 
ISBN 978-1-4398-5653-6
Secure and Resilient Software: 
Requirements, Test Cases, and Testing 
Methods 
Mark S. Merkow
ISBN 978-1-4398-6621-4 
Secure Java: For Web Application 
Development 
Abhay Bhargav and B. V. Kumar
ISBN 978-1-4398-2351-4
Secure Semantic Service-Oriented Systems 
Bhavani Thuraisingham
ISBN 978-1-4200-7331-7
The Security Risk Assessment Handbook: 
A Complete Guide for Performing Security 
Risk Assessments, Second Edition 
Douglas Landoll
ISBN 978-1-4398-2148-0 
Security of Mobile Communications 
Noureddine Boudriga
ISBN 978-0-8493-7941-3
Security Patch Management 
Felicia Nicastro
ISBN 978-1-4398-2499-3 
Security Strategy: From Requirements to 
Reality 
Bill Stackpole and Eric Oksendahl
ISBN 978-1-4398-2733-8
AUERBACH PUBLICATIONS
www.auerbach-publications.com
To Order Call: 1-800-272-7737 •  Fax: 1-800-374-3401 
E-mail: orders@crcpress.com

Information Security
Management Handbook
Edited by
Harold F. Tipton, CISSP • Micki Krause Nozaki, CISSP
Sixth Edition
Volume 6

CRC Press
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
© 2012 by Taylor & Francis Group, LLC
CRC Press is an imprint of Taylor & Francis Group, an Informa business
No claim to original U.S. Government works
Version Date: 20120215
International Standard Book Number-13: 978-1-4398-9315-9 (eBook - PDF)
This book contains information obtained from authentic and highly regarded sources. Reasonable efforts have been 
made to publish reliable data and information, but the author and publisher cannot assume responsibility for the valid-
ity of all materials or the consequences of their use. The authors and publishers have attempted to trace the copyright 
holders of all material reproduced in this publication and apologize to copyright holders if permission to publish in this 
form has not been obtained. If any copyright material has not been acknowledged please write and let us know so we may 
rectify in any future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, transmitted, or uti-
lized in any form by any electronic, mechanical, or other means, now known or hereafter invented, including photocopy-
ing, microfilming, and recording, or in any information storage or retrieval system, without written permission from the 
publishers.
For permission to photocopy or use material electronically from this work, please access www.copyright.com (http://
www.copyright.com/) or contact the Copyright Clearance Center, Inc. (CCC), 222 Rosewood Drive, Danvers, MA 01923, 
978-750-8400. CCC is a not-for-profit organization that provides licenses and registration for a variety of users. For 
organizations that have been granted a photocopy license by the CCC, a separate system of payment has been arranged.
Trademark Notice: Product or corporate names may be trademarks or registered trademarks, and are used only for 
identification and explanation without intent to infringe.
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the CRC Press Web site at
http://www.crcpress.com

v
Contents
Introduction..........................................................................................................................ix
Editors...................................................................................................................................xi
Contributors....................................................................................................................... xiii
Domain 1: ACCESS CONTROL
Access Control Administration
  1	 What Business Associates Need to Know about Protected Health Information 
under HIPAA and HITECH.........................................................................................3
REBECCA HEROLD
Domain 2: TELECOMMUNICATIONS AND NETWORK SECURITY
Internet, Intranet, Extranet Security
  2	 E-Mail Security...........................................................................................................15
TERENCE FERNANDES
Domain 3: INFORMATION SECURITY AND RISK MANAGEMENT
Security Management Concepts and Principles
  3	 Appreciating Organizational Behavior and Institutions to Solidify Your 
Information Security Program....................................................................................29
ROBERT K. PITTMAN, JR.
Risk Management
  4	 The Information Security Auditors Have Arrived, Now What?..................................47
TODD FITZGERALD
  5	 Continuous Monitoring: Extremely Valuable to Deploy within Reason.....................63
FOSTER J. HENDERSON AND MARK A. PODRACKY

vi  ◾  Contents
  6	 Social Networking.......................................................................................................73
SANDY BACIK
  7	 Insider Threat Defense................................................................................................79
SANDY BACIK
  8	 Risk Management in Public Key Certificate Applications..........................................83
ALEX GOLOD
  9	 Server Virtualization: Information Security Considerations....................................101
THOMAS A. JOHNSON
Security Management Planning
10	 Security Requirements Analysis................................................................................113
SEAN M. PRICE
11	
CERT Resilience Management Model: An Overview................................................135
BONNIE A. GOINS PILEWSKI AND CHRISTOPHER PILEWSKI
12	 Managing Bluetooth Security...................................................................................153
E. EUGENE SCHULTZ, MATTHEW W. A. PEMBLE, AND WENDY GOUCHER
Employment Policies and Practices
13	 Slash and Burn: In Times of Recession, Do Not Let Emotions Drive Business 
Decisions...................................................................................................................169
ANONYMOUS
14	 A “Zero Trust” Model for Security............................................................................175
KEN SHAURETTE AND THOMAS J. SCHLEPPENBACH
Domain 4: APPLICATION DEVELOPMENT SECURITY
System Development Controls
15	 Application Whitelisting...........................................................................................193
GEORGES J. JAHCHAN
16	 Design of Information Security for Large System Development Projects.................223
JAMES C. MURPHY
17	 Building Application Security Testing into the Software Development Life 
Cycle.................................................................................................................... 249
SANDY BACIK
Malicious Code
18	 Twenty-Five (or Forty) Years of Malware History.....................................................259
ROBERT M. SLADE

Contents  ◾  vii
Domain 5: CRYPTOGRAPHY
Cryptographic Concepts, Methodologies, and Practices
19	 Format Preserving Encryption..................................................................................289
RALPH SPENCER POORE
20	 Elliptic Curve Cryptosystems....................................................................................295
JEFF STAPLETON
21	 Pirating the Ultimate Killer App: Hacking Military Unmanned Aerial Vehicles.....301
SEAN P. MCBRIDE
Domain 6: SECURITY ARCHITECTURE AND DESIGN
Principles of Computer and Network Organizations, Architectures, 
and Designs
22	 Service-Oriented Architecture...................................................................................317
WALTER B. WILLIAMS
23	 Cloud Security...........................................................................................................331
TERRY KOMPERDA
24	 Enterprise Zones of Trust..........................................................................................349
SANDY BACIK
Domain 7: OPERATIONS SECURITY
Operations Controls
25	 Complex Event Processing for Automated Security Event Analysis..........................357
ROB SHEIN
26	 Records Management................................................................................................361
SANDY BACIK
Domain 8: BUSINESS CONTINUITY AND DISASTER RECOVERY 
PLANNING
Business Continuity Planning
27	 Data Backup Strategies: Traditional versus Cloud....................................................375
CARL B. JACKSON
Domain 9: LEGAL, REGULATIONS, COMPLIANCE, AND INVESTIGATIONS
Major Categories of Computer Crime
28	 Managing Advanced Persistent Threats....................................................................387
E. EUGENE SCHULTZ AND CUC DU

viii  ◾  Contents
Incident Handling
29	 Virtualization Forensics............................................................................................405
PAUL A. HENRY
Domain 10: PHYSICAL (ENVIRONMENTAL) SECURITY
Elements of Physical Security
30	 Terrorism: An Overview............................................................................................417
FRANK BOLZ, JR., KENNETH J. DUDONIS, AND DAVID P. SCHULZ
Technical Controls
31	 Countermeasure Goals and Strategies.......................................................................437
THOMAS L. NORMAN
Information Security Management Handbook: Comprehensive Table of Contents..........463

ix
Introduction
Halfway through 2011, the Wall Street Journal labeled it the “Year of the Security Breach.”
Victims ranged from small caps to multinationals, with two important things in common—a 
reliance on technology and vulnerable humans.
As we write this introduction, headlines such as the following declare the state of security:
◾
◾Multi-national Electronics Firm Grapples with U.S. Lawsuits after PSN Hack
◾
◾Heads Roll as Scandal Grows; Sr. Exec Arrested
◾
◾Chief of Scotland Yard Resigns
◾
◾LulzSec and Anonymous Vow to Hack On
One may very well question whether the man-years of investment in firewalls, malware fixes, 
policies, and awareness made us more secure. A better question may be: Will a preponderance of 
technology always make us less than 100 percent safe?
It seems that the ubiquity of computers and networks will always enable chance, motive, and 
means to do harm. And once a threat is deployed, the good guys are behind the eight ball, scram-
bling to install fixes that may or may not resolve the situation. Case in point: Buffer overflow was 
identified as a security issue several years ago, yet we still suffer from the effects of it today.
Moreover, current and future innovations such as cloud computing, mobile banking, digital 
wallets, and near-field communications—to name a few—provide opportunities for exploitation. 
Thus, we continue to hear: “it’s more a question of when, not if.”
So, vigilance is key; awareness and action are indisputably essential. And, useful, constructive 
information at the ready is critical.
Hence, we offer the 2012 Information Security Management Handbook, with topics aligned 
to the profession’s Common Body of Knowledge and encompassing all the requisite aspects of 
information security.
This edition addresses a range of topics including the following:
◾
◾Access Control—Technologies and administration, including the most current require-
ments for the updated laws
◾
◾Telecommunications and Network Security—Addressing the Internet, intranet, and 
extranet
◾
◾Information Security and Risk Management—Organizational culture, preparing for a secu-
rity audit and the risks of social media

x  ◾  Introduction
◾
◾Application Security—Ever-present malware threats and building security into the develop-
ment process
◾
◾Security Architecture and Design—Principles of design, including zones of trust
◾
◾Cryptography—Elliptic curve cryptosystems, format-preserving encryption
◾
◾Operations Security—Event analysis
◾
◾Business Continuity and Disaster Recovery Planning—Business continuity in the cloud
◾
◾Legal, Regulations, Compliance, and Investigation—Persistent threats, incident response in 
the virtual realm
◾
◾Physical Security—Essential aspects of physical security
The Handbook’s uses are many—as study material for domain and professional certification, 
implementation of a new security technology, strategy for risk management, and/or just plain 
good reading.
As always, we are grateful to our authors who offer their “been there, done that” experience 
and expertise, and we wish our readers the very best of luck in their professional endeavors.
Hal Tipton
Micki Krause Nozaki

xi
Editors
Harold F. Tipton, CISSP, currently an independent consultant and past president of the 
International Information System Security Certification Consortium (ISC)2Ⓡ, was director of 
Computer Security for Rockwell International Corporation for 15 years. He initiated the Rockwell 
computer and data security program in 1977 and then continued to administer, develop, enhance, 
and expand the program to accommodate the control needs produced by technological advances 
until his retirement from Rockwell in 1994. He has been a member of the Information Systems 
Security Association (ISSA) since 1982, was president of the Los Angeles chapter in 1984, and was 
president of the national organization of ISSA from 1987 to 1989. He was added to the ISSA Hall 
of Fame and the ISSA Honor Roll in 2000. He received the Computer Security Institute “Lifetime 
Achievement Award” in 1994 and the (ISC)2 “Hal Tipton Award” in 2001.
He was a member of the National Institute for Standards and Technology (NIST) Computer 
and Telecommunications Security Council and the National Research Council Secure Systems 
Study Committee (for the National Academy of Science). He received a bachelor of science 
degree in engineering from the U.S. Naval Academy, a master’s degree in personnel admin-
istration from George Washington University, and a certificate in computer science from the 
University of California, Irvine. He has published several papers on information security issues in 
the Information Security Management Handbook, Data Security Management, Information Systems 
Security, and the National Academy of Sciences report Computers at Risk.
He has been a speaker at all of the major information security conferences, including the 
Computer Security Institute, ISSA Annual Working Conference, Computer Security Workshop, 
MIS Conferences, AIS Security for Space Operations, DOE Computer Security Conference, 
National Computer Security Conference, IIA Security Conference, EDPAA, UCCEL Security 
and Audit Users Conference, and Industrial Security Awareness Conference. He has conducted 
and participated in information security seminars for (ISC)2, Frost & Sullivan, UCI, CSULB, 
System Exchange Seminars, and the Institute for International Research.
Micki Krause Nozaki, CISSP, has held positions in the information security profession for the 
past 20 years. She was previously the chief information security officer at Pacific Life Insurance 
Company in Newport Beach, California, where she was accountable for directing their infor-
mation protection and security program enterprisewide. Micki has held several leadership roles 
in industry-influential groups including the Information Systems Security Association (ISSA) 
and the International Information System Security Certification Consortium (ISC)2 and is a 
long-term advocate for professional security education and certification. In 2003, Krause Nozaki 

xii  ◾  Editors
received industry recognition as a recipient of the “Women of Vision” award given by Information 
Security magazine. In 2002, Krause Nozaki was honored as the second recipient of the Harold 
F. Tipton Award in recognition of her sustained career excellence and outstanding contributions 
to the profession. She is a reputed speaker, published author, and coeditor of the Information 
Security Management Handbook series.

xiii
Contributors
Sandy Bacik, CISSP-ISSMP, CISM, 
CGEIT, CHS-III
Bacik Consulting Service
Frank Bolz, Jr.
Bolz Associates, Inc.
Cuc Du, CISSP, CISM
Fremont Investment & Loan
Kenneth J. Dudonis
New York City Police Department (Retired)
Terence Fernandes
Illinois Institute of Technology
Todd Fitzgerald, CISSP, CGEIT, PMP, 
HITRUST, ISO27000, ITILV3
National Government Services
Bonnie A. Goins Pilewski
Illinois Institute of Technology
Alex Golod, CISSP
Hewlett Packard
Wendy Goucher
Idrach, Ltd.
Foster J. Henderson, CISSP
United States Government
Paul A. Henry, CISSP
Security & Forensic Analyst Forensics & 
Recovery LLC
Rebecca Herold, CISSP
Rebecca Herold & Associates, LLC
Carl B. Jackson, CISSP
Crisis Management and Continuity Planning 
Resource Center
Georges J. Jahchan, CISSP
Quattro Associates
Thomas A. Johnson
Illinois Institute of Technology
Terry Komperda
Illinois Institute of Technology
Sean P. McBride, CISSP
The Washington Post Company
James C. Murphy, CISSP, ISSMP, GSEC, 
CISA, CISM
North Carolina Office of Medicaid 
Management Information System Services
Thomas L. Norman
Protection Partners International
Matthew W. A. Pemble, CISSP
Idrach, Ltd.
Christopher Pilewski, CISSP
Robert K. Pittman, CISSP
County of Los Angeles

xiv  ◾  Contributors
Mark A. Podracky
TSTC
Ralph Spencer Poore, CISSP, CISA, CFE, 
CHS-III, CTGA, QSA
Cryptographic Assurance Services, LLC
Sean M. Price, CISA, CISSP
Independent Security Researcher and 
Consultant
Thomas J. Schleppenbach, CISSP, CISM
Inacom Information Systems, Inc.
E. Eugene Schultz, Ph.D., CISSP, 
CISM, GSLC
Emagined Security Consulting
David P. Schulz
Journalist
Ken Shaurette, CISSP
Financial Institution Products Corporation®
Rob Shein, CISSP
Hewlett-Packard
Robert M. Slade, CISSP
Consultant
Jeff Stapleton, CISSP
Bank of America
Walter B. Williams, CISSP, SSCP, CEH, 
CPT, MCSE, MCP
Passkey

DOMAIN
1
ACCESS CONTROL
Access Control Administration


3
Chapter 1
What Business Associates 
Need to Know about 
Protected Health Information 
under HIPAA and HITECH
Rebecca Herold
Introduction
Before launching into a discussion of protected health information (PHI) as defined under the 
Health Insurance Portability and Accountability Act (HIPAA), it is first important to have a basic 
understanding of HIPAA, and also why HIPAA even exists. This chapter first provides a high-
level description of HIPAA and the subsequent Health Information Technology for Economic and 
Clinical Health Act (HITECH Act) to provide readers with the necessary background informa-
tion to help better understand the term PHI. The chapter then describes certain specific types of 
information considered to be PHI, other situations where other information may be considered to 
be PHI, and then situations when these same information items do not fall under the definition 
of PHI. The chapter concludes with a set of recommendations for defining and protecting PHI 
within covered entities (CEs) and business associates (BAs), as they are defined within HIPAA and 
the HITECH Act.
HIPAA Overview
In today’s high-tech and increasingly online all the time, network-connected world, depending 
on locking file cabinets, passwords, and encryption alone to protect health information is not 
realistic. In addition to technology challenges, the laws that exist to protect patient information 
are a hodgepodge patchwork and greatly diverse under growing numbers of state, federal, and 
international laws and regulations. Before the dawning of the twenty-first century, patients’ health 

4  ◾  Information Security Management Handbook
information could be distributed without notice for almost any reason, including those not even 
related to healthcare or medical treatments. For example, such health information could be passed 
from an insurer to a lender, who subsequently could deny the individual’s application for a mort-
gage or a loan. The health information could even be sent to an individual’s employer, who could 
then consider it for making personnel decisions.
By enacting HIPAA, Congress mandated that organizations must take specific actions to 
protect individually identifiable health information. HIPAA contains an important section 
called Administrative Simplification. The provisions of this section are intended to reduce 
the costs and administrative burdens of healthcare by standardizing many administrative and 
financial forms and transactions. Administrative Simplification includes the Privacy Rule and 
Security Rule subsections that mandate standards for safeguarding, physical storage and main-
tenance, transmission, and access of PHI. The privacy requirements are collectively referred to 
as the Privacy Rule, and the security, or safeguard, requirements are collectively referred to as 
the Security Rule.
The Privacy Rule was passed on 14 April 2001, and updated on 14 August 2002, with com-
pliance required by most health plans, healthcare providers, and healthcare clearing houses, 
collectively referenced as CEs, by 14 April 2003. Those entities that do not comply with these 
regulations are subject to severe civil and criminal penalties.
The Privacy Rule has requirements to safeguard PHI by
◾
◾Giving patients more control over their health information
◾
◾Setting limitations on the use and release of health records
◾
◾Establishing safeguards that CEs must implement to protect the privacy of health 
information
◾
◾Holding those in noncompliance responsible through civil and criminal penalties for 
privacy violations
◾
◾Attempting to create a balance between public responsibility for disclosure of some forms of 
information and the personal information of individual patients
◾
◾Giving patients the opportunity to make informed choices when seeking care and reim-
bursement for care based on considering how personal health information can be used
◾
◾Enabling patients to learn how their information can be used along with the disclosures of 
their information
◾
◾Limiting release to only the minimal amount of information needed for required 
disclosures
◾
◾Giving patients the right to examine and correct any mistakes in their personal health records
The Security Rule came into effect in 2005 and can be characterized as being many things, 
including:
◾
◾A set of information security “best practices” that make good business sense
◾
◾A minimum security baseline that is intended to help prevent unauthorized use and disclo-
sure of PHI
◾
◾An outline of what to do to establish a security program
◾
◾Something that encourages healthcare organizations to embrace e-business and leverage the 
benefits that an improved technology infrastructure can provide
◾
◾Standards to reduce the threats, vulnerabilities, and overall risks to PHI along with their 
associated costs and negative impact on the organization

What Business Associates Need to Know about PHI  ◾  5
It is important for CEs and BAs to understand that the Security Rule is not
◾
◾A set of specific how-to instructions covering exactly how to secure PHI
◾
◾A set of rules that must be implemented the same way for every organization
◾
◾New, magical, or all that are complicated.
The overall goals of the Security Rule revolve around the confidentiality, integrity, and availability 
of electronic PHI. These terms are defined as
◾
◾Confidentiality: The requirement that data stored or transmitted is revealed only to those 
authorized to see it
◾
◾Integrity: The requirement that data remains free from unauthorized creation, modification, 
or deletion
◾
◾Availability: The requirement that data is available when needed
When the proper policies, procedures, and technologies are in place, PHI can be reasonably 
protected against known threats and vulnerabilities. This will allow entities to protect against 
unauthorized uses and disclosures of PHI, a primary consideration of the HIPAA.
HITECH Overview
The HITECH Act is part of President Obama’s $787 billion stimulus package, known as 
the American Recovery and Reinvestment Act (ARRA) of 2009, which was signed into 
law on 17 February 2009. The HITECH Act was designed to help fulfill a promise that 
President Obama made in a speech on 8 January 2009, at George Mason University:*
To improve the quality of our health care while lowering its costs, we will make the 
immediate investments necessary to ensure that, within five years, all of America’s 
medical records are computerized. This will cut waste, eliminate red tape and reduce 
the need to repeat expensive medical tests…. But it just won’t save billions of dollars 
and thousands of jobs; it will save lives by reducing the deadly but preventable medical 
errors that pervade our health-care system.
There are significant additional requirements to the HIPAA as a result of the HITECH Act. 
The bulk of all the original HIPAA Security Rule and Privacy Rule requirements are still valid 
and should still be followed. It would be dangerous not to do so, not only from a compliance 
perspective, but also from an information security, privacy, and risk management point of view. 
The HITECH Act did not replace all the HIPAA requirements. Generally, the HITECH Act 
augmented the HIPAA and expanded its requirements primarily by
◾
◾Adding breach response requirements and additional BA contract requirements for the CEs
◾
◾Greatly expanding the BA responsibilities for safeguarding PHI by requiring the BAs to fol-
low the Security Rule requirements
*	See the full text of the speech at http://www.upi.com/Top_News/2009/01/08/Transcript-of-Obama-speech-
on-economy/UPI-61161231435966/.

6  ◾  Information Security Management Handbook
◾
◾Including a specific direction for rendering PHI unusable
◾
◾Including the non-CE and non-BA requirements for a breach response that is under the 
purview of the FTC for electronic health records and electronic medical records.
What Is PHI?
When considering PHI, most CEs, and now BAs under the HITECH Act, tend to think of 
the following 18 specific information items that are listed within the HIPAA Privacy Rule as 
being PHI because they are the elements that must be removed from a health record for it to 
be “de-identified.” They include
	
1.	Name
	
2.	Geographic subdivisions smaller than a state
	
3.	Dates (excluding year) of
	
a.	 Birth
	
b.	 Admission
	
c.	 Discharge
	
d.	 Death
	
4.	Phone number
	
5.	Fax number
	
6.	E-mail address
	
7.	Social security number
	
8.	Medical records numbers
	
9.	Health plan beneficiary numbers
	 10.	Account numbers
	 11.	License and certificate numbers
	 12.	Vehicle identifiers (such as license plate number)
	 13.	Device identifiers (such as serial numbers)
	 14.	Internet universal resource locators (URLs)
	 15.	Internet Protocol (IP) address
	 16.	Biometric identifiers (such as finger and voice prints)
	 17.	Full-face photographic images (and any comparable images)
	 18.	Other unique identifiers that can be attributed to a specific individual.
On 21 May 2008, the Genetic Information Nondiscrimination Act (GINA) was signed into 
law. In a related move in 2009, the Office of Civil Rights modified the Privacy Rule to add genetic 
information to the list of 18 items as another specific type of PHI.
Of note is that PHI generally means the same thing as “individually identifiable information,” 
which is defined within HIPAA as follows:
Individually identifiable health information is information that is a subset of health 
information, including demographic information collected from an individual, and:
	
1.	Is created or received by a health care provider, health plan, employer, or health 
care clearinghouse; and
	
2.	Relates to the past, present, or future physical or mental health or con-
dition of an individual; the provision of health care to an individual; or 

What Business Associates Need to Know about PHI  ◾  7
the past, present, or future payment for the provision of health care to an 
individual; and
	
i.	 That identifies the individual; or
	
ii.	 With respect to which there is a reasonable basis to believe the information 
can be used to identify the individual.
Taking the 19 specifically named items into consideration, in addition to the specific definition 
of individually identifiable health information, it is then important to know
	
1.	The type of entity that created the information
	
2.	If the information can be reasonably linked to a specific individual.
BAs Must Start Doing More
Prior to the HITECH Act, the question of what was considered to be PHI was not as com-
plicated for the BAs as it was after the HITECH Act came into effect. Prior to the HITECH 
Act, the BAs typically depended on the BA agreements to specify the information that needed 
to be protected and how to protect it. After the HITECH Act came into effect, the CEs often 
updated the BA agreements to simply state that the BAs had to follow all the HIPAA Security 
Rule and the HITECH requirements, and they also often added a requirement to follow the 
Privacy Rule requirements even though the BAs were often not actually required to do so by 
the regulations. The specific direction was basically removed, leaving the BAs with the respon-
sibility to think for themselves, to understand the HIPAA and HITECH requirements, and 
to make decisions for changing how they protected the information they received from their 
CE clients.
With literally millions of BA organizations, from one-person shops up to organizations with 
hundreds of thousands of personnel, many and perhaps most of which are also doing work for 
entities that are in other industries and are not considered to be CEs, it is more important to deter-
mine whether or not organizations must consider information to be PHI, and as such, they also 
need to follow all the HIPAA and HITECH Act requirements and standards. The first step that 
the BAs need to take is to determine the information that is PHI.
BAs Must Understand PHI
PHI is basically information that originates from CEs and is used in the support of treatment, 
payment, or operations (TPO) that are related to patient healthcare services. Under HIPAA, orga-
nizations defined as “covered entities” and “business associates” must safeguard PHI according to 
all the HIPAA Security Rule requirements, along with their BA agreements, and in some cases, 
some of the Privacy Rule requirements.
Significant numbers of BAs have explicitly stated that they do not consider information 
that can be found in public locations, online through searches, on social media sites, or count-
less other locations, to be PHI. More than one BA has stated, “If information is found in the 
phone book, or can be Googled, then we don’t worry about safeguarding it. Why should we? 
It’s already out there!” This is a dangerous and incorrect interpretation to make. Various types 
of PHI are often found in public places, but must still be protected according to the HIPAA 

8  ◾  Information Security Management Handbook
safeguards. Let us revisit the list of specific PHI data items and consider which items are often 
found in public locations:
	
1.	Names: ⇐ OFTEN FOUND IN PUBLIC
	
2.	All geographic subdivisions smaller than a state, including street address, city, county, pre-
cinct, zip code, and their equivalent geocodes: ⇐ OFTEN FOUND IN PUBLIC except for 
the initial three digits of a zip code if, according to the current publicly available data from 
the Bureau of the Census:
	
a.	 The geographic unit formed by combining all zip codes with the same three initial digits 
contains more than 20,000 people
	
b.	 The initial three digits of a zip code for all such geographic units containing 20,000 or 
fewer people is changed to 000
	
3.	All elements of dates (except year) for dates directly related to an individual, including birth 
date, admission date, discharge date, date of death; and all ages over 89 and all elements 
of dates (including year) indicative of such age, except that such ages and elements may be 
aggregated into a single category of age 90 or older
	
4.	Phone numbers: ←OFTEN FOUND IN PUBLIC
	
5.	Fax numbers: ←OFTEN FOUND IN PUBLIC
	
6.	E-mail addresses: ←OFTEN FOUND IN PUBLIC
	
7.	Social security numbers: ←ALARMINGLY FOUND MORE OFTEN IN PUBLIC
	
8.	Medical record numbers
	
9.	Health plan beneficiary numbers
	 10.	Account numbers
	 11.	Certificate/license numbers
	 12.	Vehicle identifiers and serial numbers, including license plate numbers: ←OFTEN FOUND 
IN PUBLIC
	 13.	Device identifiers and serial numbers
	 14.	Web URLs: ←OFTEN FOUND IN PUBLIC
	 15.	IP address numbers: ←INCREASINGLY FOUND ON PUBLIC SITES
	 16.	Biometric identifiers, including finger and voice prints
	 17.	Full-face photographic images and any comparable images: ←OFTEN FOUND IN 
PUBLIC
	 18.	Genetic information
	 19.	Any other unique identifying number, characteristic, or code, except as permitted by HIPAA: 
←OFTEN FOUND IN PUBLIC
Even though many of these HIPAA PHI items are widely found in public places, each CE, and 
now BA under the HITECH Act, must still ensure that all the PHI items are safeguarded, used, 
shared, retained, and otherwise handled according to the HIPAA requirements.
PHI Decision Making
It is important for business leaders to know whether or not the information they are respon-
sible for is considered to be PHI. They can help understand if the information they manage in 
their areas is PHI, by looking at each of the business processes in their area that involves infor-
mation processing. Consider the following real-life scenarios, along with the decision-making 

What Business Associates Need to Know about PHI  ◾  9
processes for how to determine whether or not the information is PHI and should be safe-
guarded as such.
Using PHI for Marketing Purposes
A CE sends the BA a list of names, addresses, and phone numbers to process. After doing some 
online research, the BA’s marketing and sales area finds all the names, addresses, and phone num-
bers of the individuals online. The BA has another client that is not a CE, for whom they do mar-
keting activities. The BA marketing area wants to add the names, addresses, and phone numbers 
from the CE into their other client’s marketing databases. The marketing manager states that 
because the information can be found online, it is “fair game” to use. What should a privacy offi-
cer or security officer advise the marketing manager?
	
1.	These names, addresses, and phone numbers originated from the CE.
	
2.	These names, addresses, and phone numbers are considered to be PHI and must be safeguarded 
according to the HIPAA and the HITECH Act.
	
3.	Even if the information is found elsewhere on public sites, it still must be protected according 
to the BA agreement, the HIPAA and the HITECH requirements.
	
4.	The information cannot be used for marketing purposes unless the individuals have explicitly 
provided consent, via the CE.
It is worth noting that, in general, personal information found in public locations should not 
be used for marketing and sales purposes anyway. A common privacy principle is obtaining con-
sent before using personal information in general, and for marketing and sales in particular, no 
matter where the information may exist publicly.
Sending PHI in ClearText E-Mail Messages
A large number of BAs, as well as CEs, have expressed the opinion that if a patient or a customer 
sends them cleartext PHI, then it is permissible to send cleartext PHI to those customers and 
patients. Similarly, many have indicated that if a customer or a patient says that it is permissible for 
the CE or BA to send PHI to them without encrypting it, then they can do so without any worries 
of potential incidents or breaches.
If either of these situations occur within a BA or CE, what should a privacy officer or security 
officer advise those who communicate with the patients or customers?
	
1.	Sending cleartext PHI within digital communications is a long-known, high-risk activity.
	
2.	Many privacy breaches have occurred because
	
a.	 Cleartext e-mail messages containing PHI were accidentally sent to unintended recipients
	
b.	 The computers containing the e-mails were stolen
	
c.	 A recipient of the e-mail forwarded it to others not authorized to have access to the PHI.
	
3.	Most people with no background or experience in information security may give such per-
mission to share PHI in risky ways simply because they do not know about the associated 
risks.
	
4.	HIPAA specifies that encryption should be used if appropriate to mitigate identified risk. 
Communicating PHI via e-mail is a well-known demonstrated risk, and encrypting the data 
is an appropriate way to mitigate the associated risks.

10  ◾  Information Security Management Handbook
	
5.	The CE entrusted the PHI to the BA to protect according to specific safeguards and as 
required by the HIPAA and the HITECH Act.
	
6.	The BA must follow these safeguards, regardless of what others, including the associated 
individual, say can be done.
	
7.	If the CE has not indicated that encryption is required, then the BA must apply their own 
risk mitigation practices to meet the HIPAA and HITECH requirements.
In general, sending cleartext confidential information, such as PHI, through the Internet 
using any one of the many available messaging methods is a known and proven high-risk 
activity. Any type of confidential information, beyond just PHI, should be encrypted within 
such messages.
Posting PHI on Web Sites
Many CEs and BAs have posted photographs or other types of images of the patients on various 
types of Web sites. Often, they do not post the patient’s face, but such things as x-rays, surgery 
views, and even tattoos. Their justification is typically that such images (1) are valuable for poten-
tial patients or clients, (2) would be educational from a medical point of view, or (3) were just 
something so sensational that they were compelled to share with the world. What should a privacy 
officer or security officer advise to those who post patient images, of any type, online?
	
1.	Photographs of a patient are considered to be PHI.
	
2.	Two of the 19 items specified as PHI include “full face photographic images (and any 
comparable images)” and “other unique identifiers that can be attributed to a specific 
individual.”
	
3.	Patient images must be safeguarded so that only those who have a business need can access 
them.
	
4.	Even if the patient’s name is not tagged within the photograph, if it can be linked to the 
individual, then it cannot be posted online, even if the site claims that it is “private.”
	
5.	Explicit consent must be obtained from individuals before posting images for others to see.
A growing number of online social media sites are urging people to post videos and photo-
graphs and tag all persons in them. This creates a large number of privacy concerns, not only to 
the organizations who do the posting, but also to those within the images who did not want their 
name to be associated with an image. Not to mention that some people are tagged with the wrong 
names, much to the chagrin of those whose names are labeled on often derogatory images. Policies 
and procedures need to exist to clearly indicate what is and is not acceptable with regard to post-
ing images online.
Think about Your Own Situations
The listing of scenarios could go on infinitely. If you are a BA, what are the ways in which your 
organization uses information that falls within the list of PHI items? Have you determined the 
ways in which your organization uses PHI? Identifying likely scenarios can help organizations 
create policies and supporting procedures to protect PHI, in addition to supporting HIPAA and 
HITECH compliance.

What Business Associates Need to Know about PHI  ◾  11
Steps for BAs to Take
To help establish appropriate safeguards for the information that originates from CEs, in 
addition to helping ensure compliance with the HIPAA and the HITECH Act, BAs need to 
take the following high-level actions to effectively safeguard information, manage risks, and 
meet compliance.
	
1.	Know the PHI you have: Define “protected health information” as it applies to your organiza-
tion. Additionally, define the larger set of “personal information” items, taking into account 
all the types of personal information that are covered by your other applicable information 
protection legal requirements. Also, consider if information can be linked to a specific indi-
vidual, even if it is not 1 of the 19 specifically named information items. Establish an inven-
tory of PHI and personal information and maintain it to keep it up to date.
	
2.	Know how PHI is used: Identify who collects, processes, stores, or accesses personal infor-
mation, in addition to documenting how it is used. Determine who is, or who should be, 
responsible for these activities.
	
3.	Know where PHI is kept: Identify storage locations, including mobile endpoints and employee-
owned storage locations. Also, include third parties that you entrust to store information.
	
4.	Know data retention requirements: Identify, document, and follow data retention require-
ments as specified by the CEs, as well as within the HIPAA and the HITECH Act. 
Incorporate these into your inventory information, or use a completely separate system to 
manage them. Be sure to dispose of data securely and irreversibly.
	
5.	Limit access to PHI: Restrict access to only those who have a business need to access the 
information for business purposes. Do not give access beyond the purposes for which you 
collected the information.
	
6.	Implement appropriate safeguards: Perform a risk assessment, and then implement effective 
safeguards to appropriately mitigate the identified risks, following your policies and proce-
dures. Ensure that personnel understand that, no matter where PHI may be found in public, 
or what customers or patients tell them to the contrary, they must follow the policies and 
procedures.
	
7.	Communicate: Be sure you communicate information about PHI policies, procedures, and 
how to do the associated activities through regular training and ongoing awareness com-
munications. These actions need to be supported with the appropriate technology tools and 
the appropriate control processes.


DOMAIN
2
TELECOMMUNICATIONS 
AND NETWORK 
SECURITY
Internet, Intranet, 
Extranet Security


15
Chapter 2
E-Mail Security
Terence Fernandes
While e-mail still serves the theoretically simple purpose of transmitting information just like 
regular mail, it does so in a digital form, allowing for more options, customization, convenience, 
and an overall experience that is more aligned with the demands of our modern world, which is, 
day after day, relying more on the Internet and its different associated services.
As mentioned earlier, this technology has evolved in many ways and continuously offers new 
methods of usage; however, it still relies on quite basic protocols. For example, although we can 
now use a browser to directly manage our mailbox, clicking on the send button is still translated 
and eventually handled by the server in the same way as if a SMTP (Simple Message Transfer 
Protocol) transaction was initiated. These complex evolutions, associated with rather modest yet 
powerful protocols, make securing e-mail transactions a challenge on various levels.
We will first describe how e-mail actually functions and illustrate the different scenarios used 
nowadays. We will then state the major security threats and vulnerabilities that the e-mail ecosys-
tem faces. Finally, we will develop various solutions to make the use of e-mail more secure and see 
that trying to fix issues related to e-mail security is not always a matter of technical solution, but 
sometimes involves management decisions and the strict enforcement of policies.
How Does E-Mail Actually Work?
When trying to understand the exchange of digital information that occurs while using e-mail, 
it is first interesting to know that different scenarios can result in the transmission of data. For 
example, it is possible to send and receive e-mails between two user agents on the same machine, 
or to exchange messages between two users through one single internal network. But the most 
common scenario can be described by identifying a user agent residing in network A, which sends 
a message to another user agent residing in network B. In this section, we will focus on this last 
scenario because it will give us an overview of the e-mail architecture and exchange process. The 
general idea can easily be extrapolated to the other scenarios as well.
Let us imagine a situation where Alice wants to send a message to Bob, each residing in dif-
ferent networks. Alice has several solutions to help her write the message. The most common one 

16  ◾   Information Security Management Handbook
would be for Alice to use some software that would act as an e-mail client, to write and then send 
her message. When Alice is ready to send the message, the e-mail client transfers the message to a 
Mail transfer agent (MTA). We can see that the e-mail software in this case, or a Webmail in other 
examples, is really just an interface between the user and the MTA client.
Usually, it will send the message across the network using an application-level “transfer” proto-
col, called Simple Message Transfer Protocol (SMTP), defined in RFC 821 (Internet Engineering 
Task Force, 1982). The role of the MTA client is to transfer the message to the MTA server through 
the network that Alice is connected to. This MTA server can be either on the same network or on a 
different one, in which case, Alice will need to use its Internet access to reach the server.
The MTA server acts as a back-to-back agent, with a server running and receiving the message 
sent by Alice’s MTA client, and as an agent preparing to send this message across the Internet 
to another MTA server linked to Bob’s network. This recipient server is also a back-to-back user 
agent, with the first one being the agent receiving Alice’s message from the first MTA server, 
and the second agent being a mail access agent, allowing Bob’s client to retrieve the message and 
display it in the e-mail software that he commonly uses. This retrieval operation involves another 
set of application-layer protocols, often described as “access” protocols (Comer, 2009), with the 
most common ones being Post Office Protocol (POP), defined in RFC 1939 (Internet Engineering 
Task Force, 1996), and Internet Message Access Protocol (IMAP), defined in RFC 3501 (Internet 
Engineering Task Force, 2003). Figure 2.1 gives a visual representation of the flow just described.
Many other e-mail architectures exist, particularly in a corporate environment (e.g., Microsoft 
Exchange is one of the most popular), but these will not be described in this chapter. However, the 
UA
Alice
LAN or WAN
MTA
client
MAA
client
MAA
server
MTA
client
MTA
server
MTA
server
System
System
Internet
Bob
UA
LAN or WAN
UA: user agent
MTA: message transfer agent
MAA: message access agent
Figure 2.1  Traditional e-mail flow. (K. Vaccaro, Email.ppt, 2011 © All Rights Reserved.)

E-Mail Security  ◾  17
potential vulnerabilities and important security principles described in the following sections can 
be applied to any of those architectures. It is important to identify and understand the flaws that 
such a system can have, to better understand the risks and find appropriate solutions to secure the 
use of e-mail. We will describe these in the following section.
E-Mail System at Risk
Recognizing e-mail vulnerabilities is a serious challenge as various security issues, on different 
layers, can target and compromise the security of the e-mail system. Indeed, we will see vulner-
abilities, from the protocols used to transmit or retrieve the message that are, by default, insecure, 
to a corporate e-mail policy that might be too lenient. The vulnerabilities are diverse and need 
to be carefully reviewed to provide an architecture that is globally safe, or at least, minimizes a 
reasonable number of risks.
Even if, at first, e-mail was designed to only carry text in its body, with the evolution of per-
sonal computing, the increase of the bandwidth capacity available, and the extensive use among 
businesses, e-mail users naturally began to exchange more than just plaintext and attached docu-
ments, photographs, small videos, and even executable programs to their digital exchanges. E-mail 
has become a very simple and efficient way to share content between users, with the classic exam-
ple of a mother e-mailing the photographs of her newborn baby to her family. We can also think of 
a company sending with ease and in a very short amount of time, a business proposal by e-mail to 
its future client. These legitimate uses of the e-mail attachment function justify the usefulness of 
this service in both a corporate and a personal environment and explain why we, as users, choose 
to rely more on e-mail for our communication needs and see it as an essential component of the 
new computing era.
However, ill-intended people quickly understood that such a solution would be an easy 
yet powerful vector of attack to rapidly spread malicious codes or software to numerous users 
(Bradley, 2006, chap. 6). Such malicious codes or software are often designated as “virus” or 
“malwares” and are intended to harm either the installed programs or the hardware components 
of the infected machine, steal information from it, or use the machine as a relay to send more 
information across the network.
On 26 March 1999, “Melissa” became the first widespread virus that used e-mail to propagate 
onto more than a million computers across the globe (F-Secure). The virus spread at an unprec-
edented rate, infiltrating thousands of networks in a matter of hours and forcing big corporations 
like Microsoft and Intel to shut down their e-mail servers to protect their assets. One of the reasons 
that can explain this fast-paced infiltration was the behavior of this virus regarding its propaga-
tion. Indeed, once the virus infected a machine, it would send itself to the first 50 entries in the 
address book, using one of the e-mail accounts available on the computer, all of this of course, 
without the user’s knowledge. The virus was embedded in a Word document, which supposedly 
contained passwords that would give you full access to pornographic Web sites. It made use of the 
“macro” functions to execute its malicious code, to lower the security features of Microsoft Word, 
it modified keys in the Windows registry, and compromised the template used by Word for every 
new document (normal.dot), infecting every single new document by default (CERT—Carnegie 
Mellon Software Engineering Institute, 1999). Other variants of the virus were even more destruc-
tive, targeting Windows system files, for example.
“Melissa” is just one of the iconic examples of the many viruses that have either used or still 
capitalize on e-mail as a vector of propagation. They constantly innovate their way of operating; 

18  ◾   Information Security Management Handbook
e.g., they mask the true extension of the attached file, thereby hoping to exploit an operating system 
flaw, because, by default, Windows hides known file extensions. Using this method, an apparently 
innocent .txt text file can instead reveal a .exe executable program. Viruses also heavily rely on a 
concept called “social engineering,” which, in this case, could be described as a science that has been 
developed to find ways to fool or trick the targeted user into trusting the malicious e-mail. We will 
see that this concept is used by several other types of threats and develop it further on.
Even though the trend currently shows that e-mail virus-based intrusions are declining 
(Kaspersky, 2010), they still represent a serious menace that can threaten and damage various 
company’s assets in terms of data (e.g., expose confidential information) or affect the network and, 
consequently, business operations (e.g., e-mail servers down), while costing billions of dollars in 
maintenance, prevention, and recovery every year.
Another serious threat related to the exchange of digital information using e-mail is called 
“spam” or “junk e-mail.” Most e-mail users are now familiar with the spam concept, which is 
defined as abundant amounts of unwanted e-mails sent to an extensive list of addresses. This con-
cept, which is basically a marketing one, relies heavily on the idea that revenues can be obtained by 
sending very large amounts of advertisement and then capitalizing on the percentage of responses. 
In order to be successful in your campaign, you need to generate more revenues from the positive 
responses compared with your up-front cost of sending the advertisement material. However, it is 
interesting to remind ourselves of the comparison with regular junk mail because in this case, it is 
costly for the sender (he has to pay the shipping cost for every single piece of mail), whereas with 
e-mail, the cost of sending a message to 1 or 1000 recipients is the same for the sender. Indeed, 
the sender’s Internet Service Provider (ISP) and possibly their e-mail provider, if different, will 
transfer the message at their own cost (Barile, 2006, 202–12). We therefore understand better how 
spam can be profitable, considering that the up-front cost is negligible, but the amount of poten-
tial customers reached is enormous. Revenues are generated as soon as the first victim clicks on a 
link—legitimate or not—to buy a product or service advertised in the e-mail, with the potential of 
many more unsuspicious users contributing to potentially large sums of money.
Interestingly, several studies describe global e-mail traffic to be mainly spam, with numbers 
reaching as high as 85 percent of the traffic in June 2010 (Kaspersky, 2010). Given the fact that 
e-mail traffic was estimated to be around 117 trillion messages in 2010 (Pingdom Statistics, 2011), 
we can easily see why spam represents a challenge for network administrators all around the world, 
as it wastes an incredible amount of resources and bandwidth. Plus, spam requires the use of a lot of 
those network and human resources to try to avoid further serious damages to companies and ISPs’ 
network infrastructure. For example, in certain cases, spam is used to perpetrate DoS attacks against 
e-mail servers (Paul, 2007) or against a specific mailbox (the concept of “mail bomb”), as the amount 
of traffic generated by spam messages that are being sent to a specific location, can, if not filtered 
properly, easily saturate the destination server and make the use of e-mail impossible for other users.
To be able to send such an amount of e-mail through several networks around the world, 
hackers use botnets, which are small programs similar to viruses that are installed covertly on an 
infected machine, and use the machine’s resources to send a spam message across the network(s) 
that it is connected to. These infected machines are often called “zombies” to amusingly refer to 
their passive state in the transmission of unwanted e-mail messages.
However, apart from the network challenges that spam poses, it also acts as a powerful vector 
for other types of attacks, including the one we have already discussed, namely, malicious attach-
ments. According to Kaspersky’s 2010 Security Bulletin, between 2.2 percent and 6.29 percent 
of spam traffic in 2010 contained malicious attachment(s) and given the description of spam that 
we have just illustrated, we can easily see why such a powerful solution that could virtually reach 

E-Mail Security  ◾  19
an extensive number of users, using illegitimate ways of transmission, would be an ideal carrier of 
malicious software.
One of the largest security threats related to e-mail, and often conveyed using spam, is the con-
tent of the message itself. Indeed, even though e-mail was designed to only permit the exchange of 
text, a translation protocol called MIME, defined in RFC 2045 (Internet Engineering Task Force, 
1996), allows the implementation of rich-format content like, e.g., formatted text or HTML code 
in the message itself. It is then quite simple to implement a malicious JavaScript in the HTML 
code and retrieve information from the victim without his/her knowledge. On 23 September 
2010, Dave Michmerhuizen, a security researcher from Barracuda Labs, reported the following:
Barracuda Labs has seen an enormous increase—in fact, well over one million 
instances a day—of spam containing malicious HTML […]. After all, what harm can 
an HTML file do?
The answer is—plenty … (Michmerhuizen, 2010)
The HTML code contained in the message is usually displayed by default by most e-mail clients. 
The users are then, if not already just by viewing the message, usually one click away from being 
infected. Indeed, if they choose to open one of the links, they could be redirected to a malicious 
Web page that would try to upload a malicious payload onto the victim’s machine. Also, the HTML 
code can be embedded in a file, usually with an .html or .htm extension, and can be attached to the 
e-mail as a malicious attachment that would infect the targeted computer upon opening.
The previous security issues related to the e-mail architecture exposed the technical use of the 
vulnerabilities of the system and the malicious use of the e-mail service. But, to have a global pic-
ture of the security of e-mail communication, it is also interesting to explore a vulnerability that, 
although not obvious at first sight, is one of the most dangerous: the user itself.
Indeed, the best security solutions will neither prevent nor protect against an incident like a 
user giving away his password or using the one that is very easy to guess. Similarly, the powerful 
security measures implemented on a company’s network are useless if a careless employee were to 
use a company’s laptop to send e-mail over an unencrypted network at a coffee shop, for example. 
The failure to use basic computer security principles by some of the employees of a company can 
be disastrous in terms of the loss of assets and image and requires resources like people, time, 
and money to fix the problems caused. Also, users can respect those principles directly related 
to e-mail, but at the same time, fail to protect data or could be compromised while using other 
services. Shawn Davis, at the NetSecure conference held in February 2011 at the Illinois Institute 
of Technology, explained how easy it is to retrieve the Facebook password of a user that displays 
too much information on his/her public profile and therefore facilitate the guess of the password 
retrieval’s security questions (Davis, 2011). To worsen the problem, most users use the same cre-
dentials, or an easy-to-guess combination of the same password, for many services. A study by 
CPP UK shows that
46 percent of British internet users, 15.6 million, have the same password for most 
web-based accounts and five per cent, or 1.7 million, use the same password for every 
single website.
Some 29 per cent use variations of the same password, for example using days of the 
week or adding numbers to the end of a word.
Memorable dates, children’s names and mother’s maiden names are each used by one 
in 10. One in five users sign in with their pet’s name. (The Telegraph, 2010)

20  ◾   Information Security Management Handbook
Therefore, we can understand how the same password used for several Internet-based services can 
represent a serious, difficult to protect from, yet often overlooked threat for both personal and 
business e-mail accounts. This example also emphasizes the point that vulnerabilities related to 
e-mail can be found by exploring threats other than those directly related to the service itself and 
that global security measures are necessary to protect the e-mail.
The recent trend in terms of security threats, also capitalizing on the social engineering aspects 
and using e-mail as a vector, is called “phishing.” Phishing e-mails are designed to match the 
design and layout of specific Web sites to try to deceive and trick the users into providing some 
of their personal information, like their name, their e-mail address, their telephone number, or 
more importantly, their social security number or their bank account numbers and passwords for 
online access. These attacks have been increasing in the past few years—one in every 250 e-mails 
sent in March 2011 was a phishing attack (Symantec Corp., 2011)—although their complexity 
and the design of the malicious e-mail have greatly improved. It has actually reached the point 
where the received phishing e-mails are very close, if not almost identical, to a legitimate e-mail 
sent by one of the targeted companies, making the distinction between a valid and a fraudulent 
e-mail quite difficult for a regular user. Phishing attempts usually target financial companies like 
PayPal (PayPal Inc.), and national banks like Chase (JP Morgan Chase Bank Inc., 2011) or Bank 
of America (Bank of America Inc.), but a fair amount of these phishing attacks also target e-mail 
service providers, such as Hotmail (Microsoft Corp.) and Gmail (Google Inc., 2011). Other types 
of scams, like the famous “Nigerian Prince” (Barile, 2006, 218–19), use false stories and promise 
financial gain in exchange for personal information.
Once again, the preferred vector for these attacks is e-mail, and spam plays an important role 
in these phishing threats, by facilitating the sending of a large amount of forged e-mails, at a low 
cost, with potentially important gains even with a very low response rate. A typical attack would 
consist of a HTML formatted e-mail, with a layout similar to a targeted company’s Web site or 
newsletter, stating a false reason (like a security breach, a locked account, or a routine mainte-
nance) to ask the user to provide his/her personal information by clicking on one of the embedded 
links that would take the user to a forged Web site. Other variants of attacks, especially used with 
scams such as the one described earlier, consist of a plaintext story, with personal information 
requested in a reply.
Technology is evolving very rapidly and while new services are emerging, new ways to use 
the existing ones, including e-mail, are developing as well. Indeed, although we have described 
a typical e-mail exchange using software acting as e-mail clients on physical machines in the 
first section of this chapter, a new concept called “webmail” has quickly grown in popular-
ity; in 2008, it reached more than 650 million users (Email Marketing Report, 2008), while 
more than “94 percent of US Internet users have gone online to send or read e-mail” as of May 
2010 (Pew Internet, 2010). Webmail allows users to send and receive e-mail through a Web 
interface accessible via a Web browser, while also offering them several options to manage their 
e-mail mailbox (e.g., folder arrangement, labels, and specific rules). While this Web interface has 
many advantages, including the convenient option of managing an e-mail mailbox from virtu-
ally any computer connected to the Internet, it is important to note that the e-mail architecture 
behind this interface stays the same, and clicking on the send button on the Web page is simply 
translated into a SEND command on one of the mail servers that handles the exchange of the 
specific account. Moreover, this new way of using the e-mail service brings new security chal-
lenges to the surface, especially those related to the use of the Web browser. For example, we 
have seen earlier in the chapter that e-mail providers are commonly targeted by phishing attacks. 
Additionally, a forensics analysis of the machine used to access the Webmail account can reveal 

E-Mail Security  ◾  21
private information, e.g., the e-mail address, the type of account, and whether or not the con-
nection to the Web site is secure. These pieces of information are stored in the cache file of the 
browser, the registry, or other locations in the computer and can easily be retrieved (Lidinsky 
and Vaccaro, 2011). In addition to these issues, using a Webmail service, a company employee 
can bypass certain network restrictions enforced by the company’s policies (e.g., adding a per-
sonal account on his/her e-mail client located in his/her professional computer). Indeed, with 
a Webmail provider, the user can easily log on to his/her personal e-mail account, and, if not 
filtered properly, the traffic generated would be no different from regular Web traffic on port 80. 
All of the above-mentioned security issues would then threaten the company network and assets, 
if, e.g., the user downloaded an infected attachment or browsed a fraudulent Web site instead of 
its legitimate e-mail provider Web site.
Last but not the least, one of the major security threats is the dependence of e-mail on sev-
eral intermediary clients, servers, and protocols that can themselves have vulnerabilities, which 
eventually threaten the integrity of an e-mail communication. For example, most Windows users 
choose Microsoft Outlook© as their primary e-mail client for managing their e-mail mailbox. 
Unfortunately, this software, along with many others, often needs to be patched to fix newly dis-
covered security vulnerabilities, such as up-to-date viruses or HTML formatted messages, which 
could be exploited by hackers to compromise the user’s stored data. Some of these updates are not 
automatically applied, and the user ultimately decides to download and install them at his or her 
will. It can thus create a problem, when users wait for a long time, or even skip security updates, 
allowing malicious people and software to take advantage of those vulnerabilities for a certain 
period of time. Additionally, Web browsers and mail servers are also impacted by these security 
updates, ultimately putting the architecture at risk if the updates are not properly applied in a 
timely fashion.
Additionally, the usual mail protocols, namely, POP, IMAP, and SMT, often by default, use 
their nonsecure version to handle the exchange of e-mail messages (through common ports 25, 
110, and 143), making the interception of traffic (e.g., using a sniffer like WireShark or other 
specialized software) potentially dangerous. The Hypertext Transfer Protocol (HTTP) traffic gen-
erated using Webmail services (through common port 80) can also be compromised if the secure 
version of the HTTP is not used. Also, some flaws in the format of the headers can lead to unex-
pected events, including failure of the mail server that handled those purposely badly formatted 
messages.
Finally, some common Internet attacks, although not specifically designed to target the e-mail 
system and architecture, can be used for that purpose. Man-in-the-middle attacks can compro-
mise the certificates used to protect the transmission of e-mail messages, while DoS attacks tar-
geting e-mail servers can cause problems in the sending and delivery of e-mail messages, to cite a 
few examples.
In the previous paragraphs, we explored some of the serious issues, vulnerabilities, and 
threats that can affect the e-mail architecture, either by disrupting its ability to handle mes-
sages, by transporting malicious content that could potentially be dangerous to both the serv-
ers and the end-user machine, or by letting unauthorized people exploit flaws that allow them 
to access and retrieve private data. From the examples we have shown, it therefore seems that 
the e-mail service, as well as the architecture it relies on, is very insecure, leading us to ask 
ourselves why these serious problems do not affect the popularity of e-mail across the world. 
In the next section, we will see that many measures, some easier to implement than others, 
contribute in making the e-mail system more secure and usable for both personal and profes-
sional correspondence.

22  ◾   Information Security Management Handbook
Securing the E-Mail Architecture
One of the biggest security threats that we discussed in the previous section is related to malicious 
software, including viruses, malware, and spyware, which are attached to e-mail and rely on an 
unsuspecting user to open the attachment to infect the targeted machine. Fortunately, several 
solutions exist in protect the user against these threats. Indeed, as malicious software is not new to 
the computing world (it is worth remembering that the Melissa virus that we previously described 
is more than 10 years old), security companies, network administrators, and software developers 
have had time to work on ways to protect the end users from such threats. The most common 
layer of protection on Windows machines is antivirus software, either installed as a stand-alone 
program, or contained in a global security suite that would also include a firewall and protection 
against malwares along with a spam filter. Several renowned security vendors such as Symantec 
Corp. and McAfee Inc., offer these suites, including professional editions with enhanced security 
in a corporate environment. These software rely on updates of their virus definitions—either being 
downloaded automatically at regular intervals, or pushed directly to the user’s machine when 
serious threats are discovered—to protect the users and their data against malicious codes. The 
major downside of these solutions is that such suites are often seen as retroactive security measures, 
because initially they are dependent on the discovery of the malicious code and methods to render 
it ineffective, and subsequently, on the update being successfully and quickly delivered to a large 
pool of computers. Most antivirus software also use “heuristic” engines, which detect suspicious 
processes running on the operating system without relying on virus definitions; however, this 
method does not guarantee a perfect detection rate and often returns annoying false-positives. 
Almost all of the security suites will offer plug-ins for common e-mail clients, allowing automatic 
scanning of attachments. Additionally, the mail server itself can perform these security measures, 
and many ISPs offer such protection as automatic scanning of attachments, with Comcast Inc. 
and their SmartZone service being one of many other examples. Webmail providers like Hotmail 
also offer similar services.
Finally, the suites along with the measures taken by the ISPs and the Webmail providers help 
reduce the amount of spam received in the actual mailbox to a manageable level. Because of 
improved scanning and detection technologies—that use keywords, common patterns, definitions 
tables, and user’s input (Barile, 2006, 207–14)— it is possible to recognize as much as 95 percent 
of spam messages, tag them, and either put them in a specialized folder or delete them before they 
arrive in the user’s mailbox.
Resolving the phishing issue is, however, more complex, and even though a thin layer of 
protection against this specific threat is provided by the suites previously described, additional 
measures embedded either in the Internet browser or the network architecture, and more specifi-
cally the Domain Name System (DNS), are preferable for a more powerful defense. Indeed, we 
have seen that most phishing attempts included in e-mail messages will invite the user to visit a 
fraudulent Web site after clicking on a link on the message, thereby leaving the environment of 
the e-mail client, or the Webmail page. Updated versions of the most popular Internet browsers, 
including Microsoft Internet Explorer (versions 8 and 9), Mozilla Firefox, and Google Chrome, 
all include a phishing filter, based on a remote database, which warns an unsuspicious user when 
he or she browses a reported fraudulent Web site. Similarly, the DNS, which plays an important 
role in Internet browsing, has evolved to provide more protection for its users against phishing 
attacks. Explaining the functioning of the DNS is out of the scope of this chapter, but OpenDNS 
(OpenDNS Inc.) and Google DNS, e.g., provide their users with phishing protection, even with 
their free solutions. They also offer professional solutions, with enhanced features, tighter security 

E-Mail Security  ◾  23
measures, and better support. Nevertheless, regardless if the environment is a company or a per-
sonal network, we can see that these different solutions, all capable of working together, can pro-
vide acceptable protection against phishing links received in an e-mail that a user could accidently 
click on.
We have also developed issues related to the lack of proper training of some users. Fortunately, 
many options can remedy such problems. For personal users, several books and Internet docu-
mentation are available and can offer important information in terms of best security practices 
when using a computer and Internet-based services like e-mail or browsing. Public libraries in 
major cities, including, e.g., the Chicago Public Library, also offer training classes and workshops, 
giving users tips and advice to make their use of computers more secure and more prudent while 
using e-mail.
Companies are also encouraged to invest in professional training for their employees, to give 
them a basic knowledge of security measures that can prevent damaging events to the company. 
Private organizations and colleges, like the Illinois Institute of Technology, often offer such pro-
grams destined for professionals seeking to keep up to date with technology-related issues. Also, 
the policies of a company need to be carefully designed, reviewed, and enforced to provide an 
additional, but essential layer of protection. Writing a specific policy regarding the use of corporate 
e-mail with detailed instructions on how to avoid potential risks, and requiring all employees to 
read and acknowledge it, will strengthen the company’s security posture, in addition to providing 
grounds for potential legal action in case of a security breach caused by a careless employee. An 
example of the measures detailed in such policies and enforced by the administrators would be 
the disabling of the HTML content of e-mails received on corporate e-mail addresses to prevent 
vulnerabilities related to embedded malicious HTML code.
Secure versions of the security protocols should also be used by default, according to the speci-
fications detailed in the respective request for comments (RFCs). The Secure Socket Layer (SSL), 
which is a secure protocol commonly used to provide integrity protection of the transmitted data, 
can be used conjointly with the POP and the SMTP protocols, e.g., (the port used will change 
from 110 to 995 for POP and from 25 to 465 for SMTP). Similarly, while accessing the Webmail 
service using the regular version of HTTP can lead to the interception of the user’s information 
across the network, using the secure version of the protocol, HTTPS, will make those common 
spoofing attacks much more difficult and provide the user with authentication protection between 
his or her machine and the distant server.
Conclusion
E-mail security has never been a more current subject than today. Indeed, while the usage of 
the basic e-mail service has evolved through time with the demands of its users and the innova-
tive progress in technology, the vulnerabilities and threats are also growing more complex and 
involve new concepts like social engineering, which we have described in this chapter. At the 
same time, our world is increasingly interconnected via the Internet and increasingly dependent 
on its various services, either for business or personal purposes, while the amount of data stored 
and transmitted via e-mail rises constantly. This information, whether private or confidential, 
personal or business-related, interests malicious people who seek opportunities to make profits 
and quick financial gains by exploiting e-mail’s technical flaws and by fooling people who are 
careless or simply uninformed. A very recent example would be the Epsilon security breach that 
occurred on 4 April 2011, exposing millions of users’ e-mail addresses, along with partial private 

24  ◾   Information Security Management Handbook
personal information from banks, stores, hospitals, customers, and patients. As this attack is seen 
as one of the biggest security breaches that has occurred in recent times, and yet, is probably not 
the last, it is important to carefully review and prudently implement various security measures on 
different layers to protect the e-mail service. In this chapter, we explored some of the methods and 
explained that the correct use of technical security solutions, along with the strict enforcement of 
procedures and appropriate training given to users, could effectively reduce the risks related to the 
use of e-mail to a minimum.
E-mail security can be defined as an interesting combination of processes and products, 
which requires a very careful analysis, combined with accurate risk assessments and the meticu-
lous design of adequate solutions. It has been, and will continue to be, a very tough challenge to 
take on. But, at the same time, with users reaching more than a billion, it becomes even more 
clear and urgent that security is a priority that no personal user or business can afford to overlook 
in the future.
References
Bank of America Inc. Phony emails and fraudulent websites. http://corp.bankofamerica.com/public/public.
portal?_pd_page_label=landing/directsecurity/fraud (accessed April 20, 2011).
Barile, I. Protecting Your PC, First Edition. Charles River Media, Boston, MA, 2006.
Bradley, T. Essential Computer Security: Everyone’s Guide to E-Mail, Internet and Wireless Security. Syngress, 
Rockland, MA, 2006.
CERT – Carnegie Mellon Software Engineering Institute. March 27, 1999. CERT® Advisory CA-1999-04 
Melissa Macro Virus. http://www.cert.org/advisories/CA-1999-04.html (accessed March 19, 2011).
Comer, D. E. Computer Networks and Internets, Fifth Edition, vol. 1. Pearson, Upper Saddle River, NJ, 2009.
Davis, S. Effective Training and Policy Takes Fear out of Social Networking. Illinois Institute of Technology, 
Wheaton, IL, 2011.
Email Marketing Report. April 2008. Email and webmail user statistics. http://www.email-marketing-reports.
com/metrics/email-statistics.htm (accessed April 14, 2011).
F-Secure. Threat description: Virus:W32/Melissa. http://www.f-secure.com/v-descs/melissa.shtml (accessed 
February 21, 2011).
Google Inc. Messages asking for personal information, March 20, 2011. http://mail.google.com/support/bin/
answer.py?answer=8253 (accessed April 19, 2011).
Internet Engineering Task Force. RFC 821, August 1982. http://www.ietf.org/rfc/rfc0821.txt (accessed 
March 2011).
Internet Engineering Task Force. RFC 1939, May 1996. http://www.ietf.org/rfc/rfc1939.txt (accessed 
February 2011).
Internet Engineering Task Force. RFC 2045, November 1996. http://www.ietf.org/rfc/rfc2045.txt (accessed 
March 28, 2011).
Internet Engineering Task Force. RFC 3501, March 2003. http://www.ietf.org/rfc/rfc3501.txt (accessed 
March 2011).
JP Morgan Chase Bank Inc. Fraudulent e-mail examples, January 11, 2011. https://www.chase.com/index.
jsp?pg_name=ccpmapp/privacy_security/fraud/page/fraud_examples (accessed April 20, 2011).
Kaspersky. Security bulletin 2010, December 2010. http://www.securelist.com/en/analysis/204792163/
Kaspersky_Security_Bulletin_Spam_Evolution_2010 (accessed January 29, 2011).
Lidinsky, W. and Vaccaro, K. Web forensics. Institute of Technology, Wheaton, IL, 2011.
Michmerhuizen, D. HTML is not harmless—Email security update, September 23, 2010. http://www.
barracudalabs.com/wordpress/index.php/2010/09/23/html-is-not-harmless-email-security-update/ 
(accessed April 2, 2011).
Microsoft Corp. Microsoft safety and security center. http://www.microsoft.com/security/online-privacy/
phishing-faq.aspx (accessed April 19, 2011).

E-Mail Security  ◾  25
Paul, R. Spammers launch denial of service attacks against antispam sites, 2007. http://arstechnica.com/
security/news/2007/09/spammers-launch-denial-of-service-attacks-against-antispam-sites.ars (accessed 
April 2, 2011).
PayPal Inc. Report fraudulent activity. https://cms.paypal.com/us/cgi-bin/?cmd=_render-content&content_
ID=security/report_problem (accessed April 20, 2011).
Pew Internet. Trend data—Online activity, May 2010. http://www.pewinternet.org/Static-Pages/Trend-Data/
Online-Activites-Total.aspx (accessed April 14, 2011).
Pingdom Statistics. Internet 2010 in numbers, January 11, 2011. http://royal.pingdom.com/2011/01/12/
internet-2010-in-numbers/ (accessed March 6, 2011).
Symantec Inc. MessageLabs Intelligence: March 2011, March 2011. http://www.messagelabs.com/mlireport/
MLI_2011_03_March_Final-EN.pdf (accessed April 13, 2011).
The Telegraph. Almost 16 million use same password for every website, study finds. The Telegraph (UK), 2010. 
http://www.telegraph.co.uk/technology/news/6922207/ (accessed January 2010).


DOMAIN
3
INFORMATION 
SECURITY AND RISK 
MANAGEMENT
Security Management 
Concepts and Principles


29
Chapter 3
Appreciating Organizational 
Behavior and Institutions to 
Solidify Your Information 
Security Program
Robert K. Pittman, Jr.
Introduction
Throughout life, many of us commute to and from our occupation, travel during vacation to other 
states and perhaps other countries, spend quality time with our family, as well as find time for 
entertainment at a sporting event, a play, the beach, or a concert. Many of these trips and activi-
ties place us in an environment where people exist. People are unavoidable, regardless of where 
we commute or where our travels take us. In the gathering of people, there exists a culture that 
requires a keen knowledge and insight to ascertain how you should approach an individual(s). To 
identify an appropriate approach is warranted but challenging when establishing or cultivating 
an information security program, regardless of the sector (e.g., public, private, and nonprofit) in 
which you are employed.
Many well-known theorists like Douglas McGregor (created the Theory X and Y model), 
Edgar Schein (created the Organization Culture model), as well as psychologist Abraham Maslow, 
who created the Hierarchy of Needs five-level model, and numerous others in the field of orga-
nizational behavior and culture research have brought this topic to the forefront because of their 
immense research and the value that it brings to organizations worldwide.
Organizations throughout the world use government businesses essentially supported by 
the public. The public comprises its citizens and constituents, its businesses such as nonprofit 
organizations and corporations, including government agencies at all levels. A relationship 
among everyone involves citizens in terms of governments and associated organizations inter-
relating their programs and services on behalf of the public. At least, this is one of the goals 

30  ◾  Information Security Management Handbook
of governments, because they are providing services that a corporate business would not even 
consider. The plethora of services being provided to the public are social services, general 
government, healthcare, and public safety.
Some of the countless government social services programs include addressing and support-
ing low-income families, foster care, emancipated youths, and general relief payments for food 
and housing for the disadvantaged. Other services, including property value assessment, property 
tax payment, requests for a birth certificate, a marriage license, or a death certificate, as well as 
simply registering to vote, in part, constitute general government services. Our citizens, from the 
time they are brought into this world and throughout their lives will require healthcare services. 
Medical and mental healthcare, including public health issues, will always be of prime concern 
to all levels of government, involving all ages. It may seem obvious that public safety services are 
at the top of the list with healthcare as well. The security of our homeland, the protection of our 
borders and ports, law enforcement, and protection of our loved ones is an area where government 
visibly plays a significant role.
All of the aforementioned government services are provided externally to the citizens. The 
perspective on services provided internally would be contrary to corporate services, in terms of 
the existence and loyalty of a significant number of employee’s labor unions (i.e., Civil Service 
Rules), attractive sustained retirement packages, consistent health and dental benefits, career and 
job advancements within the same government level where opportunities exist in different depart-
ments, branches, and agencies, and are knowingly supporting a cause or the application of Greek 
philosophy using Aristotle’s definition of greater good.
Regardless of the lens that we use to view government and corporate (i.e., comprised of both the 
market activities of the individuals and the actions of organizations as corporate actors) (Coleman 
1990) obvious differences do exist. Much of government services are provided to the public are 
unique as compared to corporate provided services. These unique government services (e.g., Social 
Work, Probation Officer, Librarian) are predominately performed by government employees that 
are usually passionate about their work including a strong will to deliver good service. Later in this 
chapter, you will become acquainted with the lack of similarities from the perspective of institutions.
By viewing a government at the 80,000-foot level and viewing through a Looking Glass, 
differences exist between the perspective of an employee and an organization. Differences exist 
between local government (i.e., county and city) organizations and corporations (e.g., corporate 
stock shares and well-compensated). Therefore, the establishment of an information security pro-
gram differs significantly between local governments and corporations.
To establish an information security program in local government involves an array of focal 
points that must be addressed within the initial 18 months by the chief information security offi-
cer (CISO), chief security officer (CSO), or information security manager (ISM). Additionally, in 
some recent information security forums and industry writings, the chief risk officer (CRO) may 
have a significant role. It is imperative that these focal points are addressed in terms of having 
them established and adopted by the organization:
◾
◾Enterprise information security policies
◾
◾Information Security Steering Committee (ISSC)
◾
◾Enterprise information security program
◾
◾Enterprise information security strategy
◾
◾The organization’s health level based on an information security risk assessment
◾
◾Enterprise and departmental (or agencies) Computer Emergency Response Teams (CERTs)
◾
◾Enterprise Security Engineering Teams (SETs)

Appreciating Organizational Behavior and Institutions  ◾  31
These focal points can be categorized as your “Lucky 7,” and will be referred to as such 
throughout this chapter. The security professional who addresses these points will be “lucky,” 
and the others will not be as “lucky” in terms of continued employment with that particular 
organization, because the primary responsibility exists with the information security unit. This 
may sound harsh; however, at the end of the day the business and services being provided to the 
citizens and constituents expect their confidential, sensitive, and personally identifiable informa-
tion (PII) is secured and protected. It is the job of the information security professional to accept 
the challenge and responsibility to ensure that the organization stays away from any press or media 
release announcing a data breach, or perhaps, a breach of trust. As information security practi-
tioners are aware, there has been a plethora of announcements in the press and media regarding 
organizations (public and private sectors) that have experienced computer security breaches. These 
breaches occurred in corporate America, colleges and universities, healthcare organizations, as 
well as the 26 million veterans’ records with PII that are the responsibility of the federal govern-
ment Veteran’s Administration (public sector) and T.J. Maxx’s 45.7 million credit and debit card 
owners (private sector) that occurred in 2005. However, the all-time record breach occurred in 
2009 with Heartland Payment Systems, which now leads all of the hacks that have hit or affected 
the financial services industry (private sector), with 130 million credit and debit card account 
numbers compromised.
Organizational Governance
It seems increasingly apparent that the public sector leverages a security-related event to promote 
an information security program, or at the minimum, obtain a funding source to support a proj-
ect or initiative. Despite the consequences of failure or compromise, security governance is still 
a muddle. It is poorly understood and ill defined, and means different things to different people. 
Essentially, security governance is a subset of enterprise or corporate governance. Moreover, one 
could identify governance as: security responsibilities and practices; strategies and objectives for 
security; risk assessment and management; resource management for security; and compliance 
with legislation, regulations, security policies, and rules.
Information security governance is “the establishment and maintenance of the control envi-
ronment to manage the risks relating to the confidentiality, integrity, and availability of informa-
tion and its supporting processes and systems.”
From a local government perspective, the county government is governed by a five-member 
board of supervisors and the chief executive officer (CEO). The CISO, the departmental infor-
mation security officers (DISOs), and the ISSC or a security council comprise the information 
security governance.
A federated organizational structure is the norm for the majority of local government orga-
nizations. If the discussion is about county or city government, numerous business units or 
departments serve unique and differing business purposes. Because of these unique business 
units, comprehensible governance is vital to the success of any information security program. 
This governance involves a strategic organization framework (Figure 3.2) that provides a clear 
illustration of the involved players. The “Security Triangle” (Figure 3.1) is a framework that is 
doable for the CISO’s organization, regardless if their information technology (IT) is decentral-
ized, centralized, or a managed-security service. Additionally, a local government organization 
can be deemed as an organization with 30 or more corporations, in terms of having 30+ county 
departments with distinct businesses as they serve their respective constituents.

32  ◾  Information Security Management Handbook
The organization’s senior management must support the Security Triangle; however, articula-
tion of this support should be achieved by the development of Board-adopted policies (Table 3.1). 
These policies are similar to the corporate world where the Board of Directors and the CEO can 
adopt policies. However, an information security council or steering committee can approve infor-
mation standards and procedures. The use of an advisory council or committee provides a weaker 
connotation that is not supportive of establishing or sustaining an information security program.
Organizational Culture and Behavior
Bruce Schneier is an internationally renowned security technologist and author, as well as the well-
respected security expert for business leaders and policy makers. Currently, he is the chief security 
technology officer for BT Managed Security Solutions. In his book, Beyond Fear, Thinking Sensibly 
about Security in an Uncertain World, Schneier states that security is all about people: not only the 
people who attack systems, but also the people who defend those systems. If we are to have any 
hope of making security work, we need to understand these people and their motivations. We have 
already discussed attackers; now we have to discuss defenders.
Schneier also states that good security has people in charge. People are resilient. People can 
improvise. People can be creative. People can develop on-the-spot solutions. People are the stron-
gest point in a security process. When a security system succeeds in the face of a new, coordinated, 
or devastating attack, it is usually due to the efforts of people. (See the section Organizations Are 
Institutions, for more detail.)
If it was not obvious prior to reading this chapter, it should be obvious now that people play 
a significant and critical role as part of any information security program. Moreover, those same 
people at times can bring about challenges, as well. However, the culmination of people defines 
organizational behavior and its culture. Organizational culture is the culture that exists in an 
organization, something akin to a societal culture. It is composed of many intangible phenom-
ena, such as values, beliefs, assumptions, perceptions, behavioral norms, artifacts, and patterns of 
behavior. The unseen and unobserved force is always behind the organizational activities that can 
be seen and observed. Organizational culture is a social energy that moves people to act. “Culture 
is to the organization what personality is to the individual—a hidden, yet unifying theme that 
provides meaning, direction, and mobilization.”
Organizations are assumed to be rational-utilitarian institutions whose primary purpose is the 
accomplishment of established goals (i.e., information security strategy and initiatives). People in 
positions of formal authority set goals. The personal preferences of an organization’s employees 
Table 3.1  The Public Sector versus the Private Sector and Corporate 
Organizations
Public-Sector
Private-Sector
Public Corporation
Director
Owner
Board of Directors
Deputy Director/Branch Manager
Vice President
Executive management
Division Chief
Manager
Middle management
Section Manager 
Manager
Supervisory management
Associate
Employees
Employees

Appreciating Organizational Behavior and Institutions  ◾  33
are restrained by systems of formal rules (e.g., policies, standards, and procedures), authority, and 
norms of rational behavior.
These patterns of assumptions continue to exist and influence behaviors in an organization 
because they have repeatedly led people to make decisions that “worked in the past.” With repeated 
use, the assumptions slowly drop out of people’s consciousness but continue to influence organi-
zational decisions and behaviors even when the environment changes and different decisions are 
needed. The assumptions become the underlying, unquestioned, but largely forgotten reasons for 
“the way we do things here”—even when such ways may no longer be appropriate. They are so 
basic, so ingrained, and so completely accepted that no one thinks about or remembers them. (See 
the section Organizations Are Institutions, for more detail.)
In the public sector, it seems that almost every employee has worked at least 20 years or more. In 
retrospect, they may have worked many years less. Reality sets in when many employees consistently 
echo the phase, “this is the way we do things here.” As the CISO, attempting to implement one of 
your many information security initiatives, this echo seems to sound loudly, increasing exponentially 
with the employees that will be affected by implementing a change to their environment. This type 
of behavior illustrates the presence of a strong organizational culture.
A strong organizational culture can control organizational behavior. For example, an orga-
nizational culture can block an organization from making changes that are needed to adapt to 
new information technologies. From the organizational culture perspective, systems of formal 
rules, authority, and norms of rational behavior do not restrain the personal preferences of an 
organization’s employees. Instead, they are controlled by cultural norms, values, beliefs, and 
assumptions. To understand or predict how an organization will behave under varying circum-
stances, one must know and understand the organization’s patterns of basic assumptions—its 
organizational culture.
Organizational cultures differ for several reasons. Some organizational cultures are more dis-
tinctive than others. Some organizations have strong, unified, pervasive cultures, whereas others 
have weaker or less pervasive cultures; some cultures are quite pervasive, whereas others may have 
many subcultures existing in different functional or geographical areas.
By contrast, using “prescriptive aphorisms” or “specific considerations in changing organiza-
tional cultures” when this occurs, your information security program (i.e., Lucky 7) along with its 
processes and practices will flourish with positive outcomes:
◾
◾Capitalize on propitious moments.
◾
◾Combine caution with optimism.
◾
◾Understand resistance to culture change.
◾
◾Change many elements, but maintain some continuity and synergy.
◾
◾Recognize the importance of a planned implementation.
◾
◾Select, modify, and create appropriate cultural forms.
◾
◾Modify socialization tactics.
◾
◾Locate and cultivate innovative leadership.
Altering the organizational culture is merely the first—but essential—step in reshaping orga-
nizations to become more flexible, responsive, and customer-driven. Changing an organizational 
culture is not a task to be undertaken lightly, but can be achieved over time.
Organizational cultures are just one of the major tenets that constrain the establishment and 
building of an information security program. As a CISO, or an information security practitioner 
within your organization, you should have at least some interaction with the various target groups 

34  ◾  Information Security Management Handbook
(i.e., stakeholders) to grasp an awareness of their behavior. Table 3.2 illustrates the expected behav-
ior of the target groups and the desired behavior to assist in driving your program. This chart will 
prove beneficial when you are assessing each stakeholder from your perspective.
Organizations Are Institutions
When discussing organizational culture, it is moot if we are referring to government or cor-
poration. To extend the conversation on culture, a CISO must have a clear understanding of 
institutions. The term “institution” designates organizations of every kind. To avoid confusion, 
it is useful to distinguish between institutions and organizations. Institutions are the rules of 
the game; organizations are corporate actors, i.e., groups of individuals bound by some rules 
designed to achieve a common objective (Coleman, 1990). They can be political organizations 
such as political parties, educational organizations such as universities, social services organi-
zations such as a government department, or economic organizations such as firms. Therefore, 
organizations, when interacting with other organizations or individuals, submit to those gen-
eral social rules called institutions, i.e., they are equally constrained by the general rules of 
the game. Essentially, institutions are simply normative social rules, or rules of the game in a 
society, enforced through the coercive power of the state or other enforcement agencies that 
shape human interaction (Mantzavinos, 2001). This interaction is vital to establishing and 
sustaining your information security program. Institutions exist based on an individualistic 
approach. The first class of reasons refer to the human motivational possibilities and the second 
class to cognitive possibilities. The main assumption about motivation is that every individual 
strives to increase his/her utility or, in other words, that every individual strives to better 
his/her condition by all means available to him/her. Obviously, conflicts between individu-
als are bound to arise. From the perspective of the observer, however, such social problems 
are clearly identifiable, and their basic characteristic is that the utility obtained by some kind 
of individual behavior depends in one way or another on the behavior of other individuals. 
Some stylized social problems have been identified in game theory or the game of trust. When 
asking the question of why not solve social problems ad hoc because, in a way, every problem 
situation—and thus every social problem—is unique, the response is associated with the cog-
nitive structure of the human mind. The human mind is far from being a perfect tool, able to 
Table 3.2  Stakeholders’ Desired Behavior
Organizational Target Group
Desired Behavior
Board of Supervisors/City Council
Endorsement
Executive management
Priority
Middle management
Resources
Supervisory management
Support
Employees
Diligence 
Constituents/Consumers
Trust 
Security Program 
Execution

Appreciating Organizational Behavior and Institutions  ◾  35
perform all the difficult computations needed for solving problems that arise from interacting 
with other minds. Because of a restricted cognitive capacity, every individual mobilizes his/her 
energies only when a “new problem” arises, and follows routines when the individual classifies 
the problem situation as a familiar one. This distinction is rooted in the limited computational 
capacity of human beings and is a means to free up an individual’s mind from unnecessary 
operations so that the individual can deal more adequately with the problem situations arising 
in the individual’s environment (Mantzavinos, 2001).
The individual’s environment could be deemed complex. This precisely indicates that the indi-
vidual’s limited cognitive capacity makes their environment appear rather complicated for the 
individual and in need of simplification to be mastered. This refers to both the natural and the 
social environment of the individual. Because of the perceived complexity of the social environ-
ment, people consciously or unconsciously adopt rules as solutions to social problems rather than 
deciding each time anew how to act and react to the settings where coordination with other indi-
viduals is needed. Rules in general, “are a device for coping with our constitutional ignorance”; 
they are the “device we have learned to use because our reason is insufficient to master the full 
detail of complex reality (Hayek, 1960).”
A very productive and very widely used distinction among types of institutions is based on the 
criterion of the enforcement agency of institutions. Institutions are commonly classified according 
to the criterion shown in Table 3.3.
The most important feature of conventions is their self-policing character. After they have 
emerged, nobody has an incentive to change the rules that everybody else sticks to. In game 
theory, conventions are usually analyzed with the help of what are known as “coordination 
games.” Examples of such rules are traffic rules (e.g., traffic speed signs are regulatory), indus-
trial standards, forms of economic contracts, language, etc. The moral rules are largely culture-
independent because they provide solutions to problems that are prevalent in every society, as 
Lawrence Kohlberg has shown in his famous empirical research (Kohlberg, 1984). These rules 
(e.g., policy and standards) are critical to establishing and sustaining an information security 
program, as well as assisting in culture change. The mechanisms for the enforcement of moral 
rules are entirely internal to the individual, and therefore no external enforcement agency for 
rule compliance is required. Typical examples of moral rules are “keep promises,” “respect other 
people’s property,” “tell the truth,” etc. These have a universal character. However, their existence 
does not necessarily mean that they are followed, and in fact, many individuals break them. (Thus, 
the empirical phenomenon to be explained is the existence of moral rules in a society, which are 
followed by part of the population.) On the contrary, social norms are not of universal character, 
Table 3.3  Informal and Formal Institutions
Informal Institutions
Mechanism
Character
Conventions
Self-Policing
Moral Rules
First Party
Social Norms
Third Party: Social Forces
(i.e., Individuals of the Group)
Formal Institutions
Law
Third Party: State
Source:	Schein, E.H., Organizational Culture and Leadership, Third Edition. Jossey 
Bass, San Francisco, CA, 2004.

36  ◾  Information Security Management Handbook
and they are enforced by an enforcement agency external to the agent, usually the other group 
members. The mechanism of enforcement refers to the approval or disapproval of specific kinds 
of behavior. Social norms provide solutions to problems of less importance than moral rules and 
regulate settings appearing mainly at specific times and places.
The enforcement agency (i.e., conventions, moral rules, and social norms) of each different 
category of informal institution (Table 3.3) is different, as is the specific enforcement mechanism 
(i.e., approval or disapproval of specific kinds of behavior). The common element between each 
type of informal institution, and this is critical, is when all emerge as the unintended (i.e., not 
planned) outcome of human action (Mantzavinos, 2001). It may be obvious that this outcome 
may be favorable or unfavorable depending on the situation as it relates to the previously described 
equation.
Their mechanism of emergence is thus an evolutionary process of the invisible-hand type. 
This process starts when an individual perceives his/her situation as constituting a new problem 
because the environment has changed, and then in an act of creative choice, the individual tries a 
new solution to this problem. Both the problem and its solution are of a strictly personal nature, 
and the solution is attempted because the individual expects it to increase their utility.
Whereas informal institutions emerge from the unintended results of human action in a pro-
cess that no individual mind can consciously control, a law or the sum of the social rules that are 
called formal institutions, are products of collective decisions. The state as an organism* creates 
law by constructing the conscious decision of its organ’s new legal rules or by providing a means of 
suitable adaptation—existing informal rules with sanctions (Gemtos, 2001: 36).
Informal institutions are generated through an invisible-hand process in a way from within 
the society. The formal institutions are the outcome of the political process, which are imposed 
exogenously onto the society from the collective decisions of individuals who avail of politi-
cal, economic, and ideological resources. On the other hand, this is reflective of an institution 
adopting policies and standards to address a baseline for their information security practices 
for compliance by its employees. There is no necessity for informal and formal institutions to 
complement each other in such a way that a workable social order is produced or even more, in 
order for the economic development of a society to take place.
Information Security Executive in the Organization
The late, legendary, men’s head basketball coach at the University of California at Los Angeles 
(UCLA), John Wooden, wrote “there is a choice you have to make in everything you do, so keep in 
mind that in the end, the choice you make makes you.” Nowhere is this more evident than the rela-
tionships that are established throughout your organization, as well as external to the organization. 
Surround yourself with people who add value to you and encourage you. At the minimum, having 
photographs or prints hanging on your office walls of individuals who have achieved greatness, 
regardless of the industry, will provide an added psychological benefit when tough decisions must be 
made. If the opportunity presents itself, where you are able to visit my business office or home office, 
this psychological benefit is apparent. In plain sight, you will see the memories of and fondness for 
greatness from the first African-American athlete to enter major league baseball, Jackie Robinson; 
*	See the famous definition of the modern state of Max Weber (1919/1994: 36): “The state is that human 
Gemeinschaft, which within a certain territory (this: the territory, belongs to the distinctive feature) successfully 
lays claim to the monopoly of legitimate physical force for itself.”

Appreciating Organizational Behavior and Institutions  ◾  37
Muhammad Ali (born Cassius Clay), who changed the culture of boxing to a style, business, and 
character (e.g., charisma) that was not seen previously; and Louis Armstrong (nicknamed Satchmo), 
who was once proclaimed the greatest musician to ever live and the first jazz musician to appear on 
the cover of Time magazine on 21 February 1949. Without doubt, these individuals changed their 
respective institution’s culture overnight. The establishment of strong relationships is an excellent 
indicator of a strong CISO; however, staying visible in the organization is equally important and 
provides a path to having a positive information security culture throughout your organization (e.g., 
department, agency, and division).
People can trace the successes and failures in their lives to their most significant relationships. 
Establishing relationships is part of our livelihood in terms of family, personally, professionally, 
and business. Moreover, as the CISO, when establishing an information security program and 
chairing an ISSC meeting with your security peers or colleagues in your organization, those rela-
tionships are imperative to your success. Effective CISOs have learned how to gain the trust and 
confidence of the executive team. The CISO must remember that security is easier to sell if the 
focus is on the benefits to the company. Sometimes, while selling security, analogs associated with 
personal and home practices will provide clarity and additional reinforcement.
The CISO is the information security executive (i.e., senior management), regardless of 
whether we are referencing public, private (i.e., Corporate American), or nonprofit sector organi-
zations. Regardless of the sector, an organization’s CISO must address the big picture and must 
rely on timely and actionable risk information that enhances his/her ability to make decisions that 
will drive local government efficiencies and operational effectiveness.
In local government, many CISOs are using a matrix reporting structure and either report 
to the chief information officer (CIO) or the CEO, and ultimately the city manager, board of 
supervisors (board), or city council (council). Actually, this matrix model can only function in this 
fashion as long as no operations responsibilities are incorporated. In other words, the daily opera-
tional activities and tasks may collide, at the minimum, with the strategic and tactical mindset 
of the information security practitioner. This model has brought this author numerous successful 
implementations of information security projects and initiatives, including program sustainability.
However, there are many other ways to organize the security function and they all have advan-
tages and disadvantages. Strong CISOs understand that it is not important how security or the 
hierarchical structure is organized. The key to success is the support structure that the CISO is 
able to build among the executive team. However, the manner in which security is organized 
will change the methods and processes that a CISO will use to be successful. Effective CISOs 
will adapt their approach to the most advantageous organizational structure. The two primary 
and most common organization structures are (1) the matrix structure, in which the CISO is an 
enterprise-level (or corporate-level for private sector) organization and the security staff report in 
the business lines; or (2) the CISO has direct or indirect (e.g., dotted-line organizational structure 
model) responsibility for the implementation and operations of security.
Smart CISOs understand that they do not need to have all the security staff in their direct 
reporting line. Be ready for decentralization. Being a strong CISO is not about how many staff 
you manage; it is about how many staff you can influence. Drive the difference of security any way 
you can—through direct staff, matrix staff, and supporting staff—to reach the security program 
goals and initiatives. Large organizations have already implemented a matrix organization or are 
seriously reviewing how to manage their business lines more effectively. Be prepared to manage in 
a matrix organization.
Regardless of the reporting structure, decisions are made to eliminate press clippings in 
tomorrow’s local newspaper or perhaps the national news. The CISO cannot be risk-adverse. All 

38  ◾  Information Security Management Handbook
information security practitioners should think quantitatively. This does not necessarily mean 
doing calculations. Rather, it means thinking about things in terms of the balance of arguments, 
the force of each of which depends on some magnitude.
Some local government organizations are forward-thinking companies that have recognized 
that business and IT executives (e.g., CIO, CISO, or chief technology officer) need to establish 
standardized, repeatable ways to identify, prioritize, measure, and reduce business and technology 
risks, both collaboratively and effectively. Moreover, security executives who were accustomed to 
working in their own silo must now consider all business-related risk areas to align initiatives (e.g., 
business and applications system migration projects and customer-based applications to enhance 
e-government/e-services) properly with exposures.
Collaboration and communication are sunshine on its brightest day. Team relationships and/
or team meetings are training gold nuggets. If the opportunity exists, inviting individuals to 
attend selected meetings within your security program can go a long way to helping them under-
stand the scope and breadth of security. Make them an honorary member of the team. This has 
been done on several occasions to break through the myopia barrier. In addition, if other groups 
Table 3.4  The Stages of Group/Team Evolution
Stage
Dominant Assumption
Socioemotional Focus
Group/Team 
Formation
Dependence:
“The leader knows what we 
should do.”
Self-Orientation:
Emotional focus on issues of:
	 1.	 Inclusion,
	 2.	 Power and influence,
	 3.	 Acceptance and intimacy, and
	 4.	 Identity and role.
Group/Team 
Building
Fusion:
“We are a great group/team; we 
all like each other.”
Group/Team as Idealized Object:
Emotional focus on harmony, conformity, 
and search for intimacy.
Member differences are not valued.
Group/Team 
Work
Work:
“We can perform effectively 
because we know and accept 
each other.”
Group/Team Mission and Tasks:
The emotional focus is primarily on 
accomplishment, teamwork, and 
maintaining the group in good working 
order.
Member differences are valued.
Group/Team 
Maturity
Maturity:
“We know who we are, what 
we want, and how to get it. We 
have been successful, so we 
must be right.”
Group/Team Survival and Comfort:
The emotional focus is preserving the 
group/team and its culture.
Creativity and member differences are 
seen as threats.
Source:	Mantzavinos, C., Individuals, Institutions, and Markets, Cambridge University Press, 
Cambridge, 2001.

Appreciating Organizational Behavior and Institutions  ◾  39
allow you to attend a team meeting or two, go for it. This seems very simple, and it is, but it can 
be unbelievably powerful.
It is very true that there is success in numbers from an empirical perspective, where teams can 
drive your information security program. Two types of teams should be implemented to support 
an information security program: proactive and reactive.
The proactive measures teams we call the SETs. These teams develop and review policies, 
standards, procedures, and guidelines and are usually experienced and knowledgeable in terms 
of the technical, culture, and organizational perspectives. These teams address host strengthen-
ing and isolation, policy and operating procedures, malware defense, and application security, 
to name a few. However, there will be opportunities where a proactive team will be formed to 
address a point-in-time project. For example, our implementation of an Internet content filter 
was a win-win because of the formulation of a SET from the development of the technical speci-
fications to enterprise deployment. Once deployed throughout the organization, the team was 
no longer required.
A reactive team addresses an enterprisewide CERT. This team reacts to situations that poten-
tially affect or have affected the enterprise network, servers, applications, workstations, etc. This 
team is reactive in nature. However, use of a structured methodology while responding, resolving, 
and reporting the incident is vital. Use of well-maintained and clearly written documentation (e.g., 
narratives, matrixes, and diagrams) for responding to incidents and use of a standardized incident 
reporting form are crucial. It may be obvious that by defining the various types of information 
security incidents to report will provide one of the numerous performance metrics that can be 
established to measure a portion of the operational aspects of your program (Table 3.4).
Information Security Policies, Standards, 
Procedures, and Guidelines
One of the major and critical components of an information security program is the formula-
tion, collaboration, and adoption of information security policies. These written policies cannot 
survive without associated supporting standards, procedures (some private sector organizations 
use standard operating procedures [SOPs]), and guidelines. Personally, having clear, distinct, and 
physically separated policies, standards, and procedures would provide benefits to your overall 
information security program.
Charles Cresson Wood, well known in the information security industry as a leader for infor-
mation security policy development, has emphasized segregating information that has different 
purposes. Specifically, one should formulate different documents for policy, standards, proce-
dures, and guidelines. This structure provides numerous benefits to the responsible owner of 
these documents in terms of ease of modification to maintain currency and relevance, reviews 
and approvals are more efficient, and requests for any single type of document can be distributed 
on a need-to-know basis that protects the security and privacy of the written information, where 
applicable.
Policy is defined as the rules and regulations set by the organization (including addressing 
institutional issues). Policies are laid down by management in compliance with applicable laws, 
industry regulations, and the decisions of enterprise leaders and stakeholders. Policies, standards, 
and procedures are mandatory; guidelines are optional. However, policies can be used to clearly 
define the roles and responsibilities of the information security program, including the CISOs, the 
steering committee, etc. Moreover, policies are written in a definite, clear, and concise language 

40  ◾  Information Security Management Handbook
that requires compliance. The failure to conform to policy can result in disciplinary action, termi-
nation of employment, and even legal action.
Information security policy governs how an organization’s information is to be protected 
against breaches of security. Familiar examples of policy include requirements for establishing an 
information security program, ensuring that all laptops are deployed with automatic hard disk 
encryption software, employees’ Internet usage, security awareness and training, malware (e.g., 
antivirus, antispam, and antispyware) defense, and computer incident reporting for employees, 
to name a few.
Information security standards can be an accepted specification for software, hardware, or 
human actions. These standards can also be de facto when they are so widely used that new 
applications routinely respect their conventions. However, the written format is preferred and 
recommended from the perspective of an information security professional and IT professionals 
including auditors.
A software standard can address a specific vendor’s solution for antivirus software protection. 
In fact, from a defense-in-depth perspective, an organization may standardize on two vendor’s 
solutions. If a particular organization has implemented all Cisco Systems Inc. (Cisco) network 
devices, they could conclude that their hardware standard for network infrastructure is Cisco. 
There are many standards to address human actions and even their behavior. For example, to 
address a potential computer security breach, a standard will address actions to be performed by 
specific employees’ roles, responsibilities, and timelines for an appropriate response.
Procedures prescribe how people are to behave when implementing policies. For example, 
a policy might stipulate that all confidential and private data network communications from 
employees who are working or traveling and want to connect externally to the enterprise net-
work must be encrypted. This would constitute previously identified software and hardware 
(perhaps an adopted standard for communicating externally) required to be implemented 
based on policy. The corresponding procedure (the “how-to”) would explain in detail each step 
required to initiate a secure connection using a particular virtual private network (VPN) or 
some other technology.
As previously stated, policies, standards, and procedures are mandatory. However, guidelines 
are not mandatory. Guidelines could be used as a documented standard or procedure that, invari-
ably, in the future could be transformed and adopted into a standard or procedure. Guidelines can 
be established to assist with specific security controls that may be transformed into a standard or 
perhaps a procedure. For example, if an organization prefers using the Windows Mobile operating 
system for all mobile devices; however, there is a small community within the organization that 
prefers the proprietary Blackberry device. Therefore, one may have to satisfy both communities. 
A guideline would be feasible to address the appropriate security controls for the Blackberry device, 
where a standard would address the appropriate security controls for all Windows Mobile devices. 
Eventually, the Blackberry security controls guideline would be transformed into a standard after 
a greater acceptance within the organization was achieved. This eliminates the use of a de facto 
standard in this example.
All documents should use suitable policy resources, including the aforementioned Charles 
Cresson Wood’s Information Security Policy Made Easy, government (e.g., National Institute of 
Standards and Technology [NIST], National Security Agency [NSA] Security Guidelines, and 
RFC 2196), industry bodies (e.g., International Standards Organization [ISO] 17799/27002, 
Control Objectives for Information and related Technology [COBIT], and Committee of 
Sponsoring Organizations [COSO]), and commercial (e.g., Microsoft) organizations in preparing 
to formulate policies and standards.

Appreciating Organizational Behavior and Institutions  ◾  41
The writing style should state what employees can do and what they cannot do, and use 
short sentences, written at a tenth-grade level similar to the model that newspapers use; review 
and improve (i.e., the sunset date), or adapt policies regularly; circulate drafts showing changes 
in policies to the stakeholders and the interested participants prior to adoption, and articulate 
major changes to senior management (e.g., department heads, counsel, CIOs, and privacy officers) 
within the enterprise.
Information Security Organization
The organizational culture and behavior, the CISO as the information security executive, and the 
organization structure are the dependent variables in establishing an information security pro-
gram. The framework that has been proved by numerous local governments west of the Mississippi 
River, regardless of the workforce size, is the “Security Triangle” (Figure 3.1). This framework has 
paid dividends in having clearly defined roles and responsibilities, while addressing defense and 
offense strategies. In other words, these strategies are the previously stated reactive and proac-
tive teams that allow for continual collaboration with stakeholders vertically and horizontally 
throughout the public sector organization.
The following information security strategic organization diagram (i.e., the Security 
Triangle) depicts an example from a local government (i.e., county government). It illustrates 
the CISO at the top of the organization who may report to a CIO or CEO, as previously 
stated. The ISSC is composed of the DISOs. This will provide a forum for all information secu-
rity-related collaboration and decision making. This deliberative body will weigh the balance 
ISSC
Information Security Steering Committee
CISO
Chief Information Security Oﬃcer
CCERT
Countywide Computer
Emergency Response Team
Technical Staﬀ
SET
Security
Engineering Teams
County Departments
DISO
DISO
DISO
DISO
DISO
DISO
Figure 3.1  Information security strategic organization security triangle.

42  ◾  Information Security Management Handbook
between heightened security and departments performing their individual business. The ISSC 
responsibilities will be to
◾
◾Develop, review, and recommend information security policies
◾
◾Develop, review, and approve best practices, standards, guidelines, and procedures
◾
◾Coordinate interdepartmental communication and collaboration
◾
◾Coordinate countywide education and awareness
◾
◾Coordinate countywide purchasing and licensing
◾
◾Adopt information security standards.
The DISOs are responsible for departmental security initiatives and efforts to comply with 
countywide information security policies and activities. They also represent their departments on 
the ISSC. To perform these duties, the DISO must be established at a level that provides man-
agement visibility, management support, and objective independence. The DISO responsibilities 
include:
◾
◾Representing their department on the ISSC
◾
◾Developing departmental information security systems
◾
◾Developing departmental information security policies, procedures, and standards
◾
◾Advising the department head on security-related issues
◾
◾Developing department security awareness programs
◾
◾Conducting information security and privacy self-assessments/audits
The Countywide Computer Emergency Response Team (CCERT) will respond to informa-
tion security events that affect several departments within the county with actions that must be 
coordinated and planned. The CCERT is comprised of membership from the various departments 
that are often members of the Departmental Computer Emergency Response Team (DCERT). 
The CCERT team meets biweekly to review the latest threats and vulnerabilities and ensures that 
membership data is kept current. The CISO participates in their activities, as well as leads the 
response to cyber-related events. Efforts include improved notification and communication pro-
cesses, and ensuring that weekend and after-hours response is viable. Additionally, training will 
be conducted to provide forensic capabilities to the CCERT team members, but specific to the 
incident response in terms of maintaining the chain-of-custody of electronic evidence.
The Information Security Strategic Framework (Figure 3.2) developed to support local gov-
ernment is designed to address the organization, people, processes, and technology as they relate 
to information security. The strategy is based on the principle that security is not a onetime 
event, but must be a continuously improving process, an emergent process that addresses changes 
in business requirements, technology changes, new threats and vulnerabilities, and a need to 
maintain currency with regard to software release levels at all levels within the security network, 
server, and client arena. It is also based on the realization that perfect security is an impossible 
goal and that efforts to secure systems must be based on the cost of the protective measures versus 
the risk of loss.
As the CISO or ISM, many of these protective measures are identified in an information 
security strategy, as a necessity. A documented strategy that is annually reviewed is imperative to 
ensure the currency of the projects and initiatives for that particular fiscal year. It is prudent that, 
as the information security practitioner, you align your security projects, initiatives, and activities 
with the annual budget process of the organization. This will provide a means and awareness to 

Appreciating Organizational Behavior and Institutions  ◾  43
senior management that funding is mandatory to sustain a true information security program 
that will reduce risk. This strategy must clearly articulate the mission and vision of the program. 
Additionally, information security program goals and objectives are articulated in the strategy, in 
terms of short- and near-term timelines. For example, your high-level goals can be derived from 
the 12 information security domains that are articulated in the ISO 27002 standard. The objec-
tives will support the stated goal that should apply to your organization’s required level of security 
protections. The strategy will assist in the CISO’s ability to achieve the stated goals and objectives 
over a defined period.
Conclusion
Today’s information security professional practitioner is increasingly being challenged in numer-
ous facets that are warranted based on the numerous human and technological (e.g., mobile device 
or Bring Your Own Device, virtualization, and cloud computing) threats and vulnerabilities that 
exist in the world. Globally, government organizations and major software houses experience con-
stant probing for various reasons. While discussing local government or private sector organiza-
tion challenges, some specific areas are unique to government, such as the diversity of businesses 
and services under a single organization (i.e., county or city government), the type of businesses 
that warrant differing security and privacy protections, multiple legislations and regulations that 
sanction departments within a local government organization, and perhaps most of all the orga-
nizational and institutional culture issue because of the Civil Service Rules that provide difficulty 
when employee termination is considered.
The CISO responsibilities range through establishing and sustaining relationships with exec-
utive management, learning about the organization’s culture and behavior including the insti-
tutional culture, constantly being visible and communicating the security message throughout 
the organization, having formulated clearly defined policies, standards, and procedures, and 
Culture
Human factors
Architecture
Organization
People
Technology
PROCESS
• Detect
• Respond
Governance
Engagement
Enabling &
Figure 3.2  Information security strategic framework.

44  ◾  Information Security Management Handbook
establishing a governance structure that comprises and establishes a successful information secu-
rity program.
In today’s global society, a career path definitely exists for information security practitioners 
that would ultimately lead to holding a position as a CISO or CSO. This chapter as well as other 
chapters in this book should provide dividends throughout your career as a practitioner. However, 
having a business acumen, IT experience, management, soft skills, enormous leadership, and orga-
nizational skills are only a few of the major tenets in striving to be an outstanding and success-
ful CISO. On the other hand, the IT training curriculum does not usually include managerial 
skills, such as leadership, team building, collaboration, risk assessment, and communication skills 
including negotiations, as well as psychology and philosophy courses.
About the Author
Robert K Pittman, Jr., MPA, is a public sector employee with over thirty-two years in the field of 
information technology and seventeen years within the field of information security. He is a third-
year doctoral degree candidate with interest in the field of organizational behavior and culture at 
the University of Southern California in Los Angeles, California.
References
Coleman, J. Foundations of Social Theory. Harvard University Press, Cambridge, MA, 1990.
Gemtos, P. A. Institutions. The sage handbook of the philosophy of social services. Retrieved from: http://
www.mantzavinos.org/wp-content/uploads/2011/05/Mantzavinos-chapter-19.pdf. 2010, p. 405.
Hayek, F. A. The Constitution of Liberty. Routledge, London and New York, 1960.
Kohlberg, L. Essays on Moral Development. Vol. II, The Psychology of Moral Development. The Nature and 
Validity of Moral Stages. Harper & Row, New York, 1984.
Mantzavinos, C. Individuals, Institutions, and Markets, Chapter 6. Cambridge University Press, Cambridge, 
2001.

Risk Management


47
Chapter 4
The Information 
Security Auditors Have 
Arrived, Now What?
Todd Fitzgerald
Introduction
Auditors perform an essential role in protecting the information assets of an organization, which 
should be embraced rather than feared. Many times, when an audit is scheduled, whether inter-
nally or externally initiated, the response is one of fear of what the auditors will find as gaps in the 
information security program. Analogous to how many people feel when they are scheduled for 
their annual performance review, anxiety is almost certain to be a normal response. Why is it that 
way? The answer is simple—no one likes to be criticized for what they have put their best efforts 
into, and just like the potentially stressful performance reviews, audits have the potential to be 
taken very personally and viewed as a negative experience.
The truth is that audits typically do cause anxiety and cause people’s stress levels and outward 
emotions to reflect the pressure of being “judged.” The truth is also that audits can be extremely 
valuable learning experiences by which those leading the information security programs can learn 
greatly from the auditors. Auditors are typically very detail oriented and as a result may see items that 
may be overlooked by the big-picture people. Auditors also typically follow a methodical, systematic 
approach to analyzing what the organization asserts are the controls that are in place. This systematic 
approach allows the auditors to uncover what may be assumed is actually occurring by the company. 
For example, a manager may assume that a policy in place requiring all access be terminated for an 
exiting employee within 72 hours is being followed. When the auditor reviews the policy, he may 
find that there was no documented standard operating procedure, thus raising doubts that a consis-
tent procedure was actually being followed. The auditor may also find that while logical access was 
promptly removed, there was no equivalent procedure within physical security, thus creating a gap. 
Many times, the auditor will request a full population of employees and subsequently request a ran-
dom sample, say 25, and test to determine if the requirement was consistently met.

48  ◾  Information Security Management Handbook
How often do the operational departments within an organization perform an independent 
test of the product or service they are creating? Companies are doing their utmost best to just get 
the product or service out the door. This creates a situation where compliance with the company’s 
policies, procedures, standards, and guidelines is assumed, but is not regularly tested. In this 
respect, we should be welcoming the auditors with open arms!
A by-product of performing audits on a regular basis is that managers are more apt to pay atten-
tion to ensure that the standard operating procedures are actually accurate and reviewed on a periodic 
basis (minimally on an annual basis). Knowing that they will be judged on the basis of what process 
is written versus the current process, if different, even if the current process is better, will encourage 
managers to take the documentation more seriously. Documentation should be regarded as manage-
ment directives to ensure that the appropriate activities are being performed at the right time.
From experience gained through dozens of audits involving the Big Four accounting firms, 
audit firms occupying the middle-market tier, and boutique technical auditing firms, it is safe to 
say that no two audits are conducted the same way or necessarily have the same goals in mind. 
However, there are some basic commonalities to the flow of an audit and how the information 
security department should interact with the auditors. The following sections discuss the anatomy 
of an IT audit and how the security professional should best prepare for the audit.
Anatomy of an Audit
From a security officer’s point of view, the audit can be separated into five phases: (1) Planning, 
(2) On-site arrival, (3) Audit execution, (4) Entrance/status/exit conferences, and (5) Report issu-
ance and remediation. It is useful to look at the audit as a project, with a discrete set of steps, a 
beginning, and an end. Viewing the audit as an activity in this manner permits the prioritizing, 
scheduling, and resourcing of the audit similar to other projects within the company. The success 
of an audit depends upon having knowledgeable individuals available to answer the questions for 
which they are most qualified at the appropriate time.
External audits involve an upfront period of negotiation for the scope and pricing of the 
audit. This process is normally administered through the company’s internal audit department in 
response to a contractual requirement for a piece of awarded business (i.e., government contract 
with FISMA provisions or HIPAA compliance requirements). Because internal audit may have 
many internal/external audits scheduled during a given year, the audit may not occur at the best 
time for the IT department to have the resources available. Partnership with internal audit, infor-
mation security, information technology, and compliance areas can help mitigate the scheduling 
disruptions that can occur. Once the external audit dates are set, there is typically limited flex-
ibility to move the schedule, as the external audit firms must also balance their resources with the 
needs of other clients. Typically, teams are only put together a few weeks at the most for the audit 
firm, but once they are, they tend to be “locked in.”
The following phases assume that the contract and the schedule are now in place and 
Information security and the other departments need to prepare for the audit.
Planning Phase
Preparation of Document Request List
The first step is to establish an audit coordinator for the information security/IT portion of 
the audit. This individual is usually someone within the IT organization who understands the 

The Information Security Auditors Have Arrived, Now What?  ◾  49
interoperability of the technical infrastructure, operations, and management of IT. Internal audit 
departments traditionally focus on the Financial and Operational audit areas and may or may not 
have the IT auditing skills. Even if they do have individuals with these skills, their role is to audit 
the organization. The role of the audit coordinator is to respond to the requests of the auditors, 
which may be internal or external. To mitigate any conflict of interest questions (auditors prepar-
ing responses to their own managed audits), an audit coordinator position is established. The 
function of this individual is to coordinate all audit requests, ensure timely receipt and delivery of 
the artifacts, schedule meetings, communicate issues, and generally ensure that a smooth process 
is followed.
Anywhere from 3 to 5 weeks ahead of the audit, the auditors will prepare and deliver a 
request for documentation. The request goes by such names as Prepared By Client (PBC) listing, 
Client Assistance List (CAL), Agreed-Upon Procedures (AUPs), etc. Regardless of the name, the 
intent of the request is the same—a document typically in the form of a Word document or a 
spreadsheet that contains the auditor’s request for documentation that they would like to have 
available when they start the audit. It is in everyone’s best interest to comply with the request 
and have 100 percent of the requested items available when the auditors start the audit. This 
permits the auditors to immediately start reviewing and understanding the materials provided. 
By supplying all of the information at the beginning, it can also reduce the stress level by avoid-
ing hurry-up requests that must be immediately supplied to the auditors. There will also be 
additional requests by the auditors that will consume valuable time during the audit, so it makes 
sense to solicit the materials in advance and give the departments as much of the 3–5 weeks’ 
time as necessary to collect the artifacts. The failure to adequately allow ample preparation time 
causes the organization to respond “on the fly” and not necessarily provide the best responses 
due to the short time frame allowed during the audit to provide the responses.
If any of the audit requests are not clear, the audit coordinator may need to schedule a 
meeting to discuss the deliverables requested. The scope may not be clearly understood by the 
auditors or the client. As new auditors are brought into an engagement, they must quickly 
come up to speed with the organization, processes, and the business operations. Because the 
request list is typically based upon a generic template, assumptions may be made about the 
processing that is performed by the company being audited. For example, it may be assumed 
that the company is following a system development life cycle (SDLC) process to develop soft-
ware, when in fact the organization may have outsourced the development and maintenance 
activities to a system integrator and is running these processes from a data center. If the audit 
of the data center is also in scope, the SDLC processes can be obtained through a separate audit 
of the data center.
The requests are usually organized into sections deemed important by the auditor and 
may or may not be numbered. The number of items requested varies, but typically 50–200 
requests for different security elements are normal. There is little consistency between audit 
firms as to what is requested, as each audit firm has constructed their audit program based 
upon what they consider to be important, modified by the focus desired by the organization 
or the branch of government requesting the audit. The number of auditors and scope may 
dictate how much testing is performed within the audit. An audit that has 2–3 auditors on 
site for 1–3 weeks will involve substantially less testing than a 4-week audit with 10 auditors 
on site.
A description of the contents of the request, an associated control ID, dates requested and 
dates received, and a field for comments are typical components of a document request list. One 
item that is not stated is how this document will be used within the audit! The auditors do not 

50  ◾  Information Security Management Handbook
necessarily tie the request to the control item being tested, nor do they necessarily want to make 
this clear. After all, this is an audit to test the operations, and if they are testing to determine if the 
controls are adequate to protect the information assets, then it should be irrelevant if the company 
knows what control is being tested when the documentation request is made—the organization 
should have the document in question. On the other hand, it helps to know the context of the 
request, to supply the correct documentation.
Once the request list is received, the items should be assigned an internal control number 
for tracking. This helps tremendously during the audit, to track and determine what has and 
what has not been provided. The next step is to determine which (1) Director, (2) Manager, 
and (3) Subject matter expert, or primary point of contact, is in the best position, in terms of 
knowledge, to respond to the request. The documentation request list can be modified to place 
these accountable and responsible positions in columns for each request so that it is clear who 
will own this deliverable. Although it may seem obvious, it is vitally important to establish 
who the correct owners are up front, or time ends up being wasted when a manager indicates 
the day before the deliverable is due that they are not the correct owner. This action is unfair 
to the manager who now needs to scramble to complete the request and does not promote the 
generation of a quality product.
The updated spreadsheet with the internal tracking numbers, accountable management, and 
subject matter experts is then distributed to the organization by the audit coordinator, typically 
within 1 week after receiving the initial request list. The managers should be given a couple of days 
to receive the listing and confirm that the items are theirs, and if not, recommend who should 
own the requested item. At this point, they are not fulfilling the request, but merely indicating 
whether or not it is theirs to supply. It is best to place the responsibility with the assigned manager 
to reach an agreement with the department manager on who should own the request and inform 
the audit coordinator. This avoids multiple conversations between the audit coordinator and each 
party, which can potentially increase the time to gain agreement due to the unavailability of all 
parties to the conversation.
Now that the documentation requests each have an owner associated with them, each owner 
can now begin the process of collecting the artifacts for submission. The audit coordinator should 
create an audit artifact repository of some sort to capture and organize the artifacts. This may be 
a simple directory structure, containing one folder for each item on the request list (the folder will 
most likely contain multiple documents to satisfy the request), or it may be a more elaborate home-
grown database or vendor-created database. Either of these methods is preferred to subject matter 
experts sending the requests via e-mail, as the file sizes can typically exceed the internal 5/10MB 
limitations of the e-mail service or the storage of the audit participants. Additionally, when others 
need to look up the audit artifacts that have been supplied, without a central network storage area, 
they may or may not have been the recipient of the initial e-mail and will have to request that the 
information be forwarded again. This, in turn, increases the company’s storage requirements and 
is very inefficient.
Gather Audit Artifacts
Once each manager has accumulated all of the artifacts assigned to him for the audit, the manager 
needs to confirm with the audit coordinator that the collection is complete. At this point, the audit 
coordinator can review the contents and determine whether or not all of the information has been 
provided. This quality assurance process increases the likelihood that the information will not 
have to be re-requested. The auditor coordinator looks for such discrepancies as:

The Information Security Auditors Have Arrived, Now What?  ◾  51
◾
◾Accuracy spot-check: Check to determine if the information supplied matches the informa-
tion requested.
◾
◾Empty folders: Contents may have been placed in a different audit directory, accidently 
deleted, moved to another folder, or misplaced. It all happens.
◾
◾An insufficient artifact: The audit coordinator has typically seen a similar request across 
audits over time and is usually in the best position to determine whether or not this artifact 
is complete.
◾
◾Time period not valid: If the audit is from 1 October 2012 to 31 March 2013 and a standard 
operating procedure updated on 4 August 2013 is supplied, the new procedure would not 
have been effective during the audit period.
◾
◾Sizes too large: If the file sizes are too large, say >10MB, then it may be difficult if the files 
need to be subsequently e-mailed to the auditor. It is best to break these directories into 
subdirectories prior to the audit.
◾
◾Outdated policies/procedures: A quick review of the last update date would indicate whether 
or not this might be an old artifact.
While the management and subject matter experts are responsible for ensuring that the audit 
artifacts are accurate and comply with the information request, the spot-checking by the audit coor-
dinator is a value-added step that can find problems with the information prior to its presentation 
to the auditors.
Provide Information to Auditors
Once the audit coordinator has collected all the information for the items requested on the docu-
ment request list, the audit coordinator can burn an initial CD/DVD containing all of the infor-
mation. Because much of the information will be highly confidential (network diagrams, access 
control lists, employee listings, background checks, logs, etc.), the information must be encrypted. 
Encryption programs have fallen in price substantially in the past few years, so there is little 
justifiable reason not to protect this information. Programs such as WinZip, SecureZip, PKZip, 
or programs based upon the zip format are used by most audit firms and can be opened by their 
auditors. This should be verified with the auditors prior to starting the engagement, as not all 
encryption programs are compatible. For example, a file encrypted using Pointsec software cannot 
be opened by Winzip or SecureZip because it uses a proprietary nonzip internal format. A self-
extracting file may need to be created if using this type of software. However, a file encrypted by 
Winzip (version 9.0 or greater) or SecureZip can be opened by either program, because the internal 
format used in both products is based on the zip format. Providing multiple copies for the auditors 
is typically appreciated to enable them to ramp up quickly while on site without having to spend 
time copying sizable files across a network or waiting for others to complete copying the files to 
their disks. While most auditors utilize encrypted hard disks on their PCs to store the client files, 
it is advisable to confirm this with the auditors before providing them with the information.
Preparation for On-Site Audit
To ensure that the appropriate logistics have been taken care of, the auditors may schedule a pre–
on-site meeting ahead of the audit. Figure 4.1 provides a complete listing of the items typically 
requested by the auditors in advance. The following sections discuss considerations for some of the 
key items requested by the auditors.

52  ◾  Information Security Management Handbook
Internet Access
Even though the auditors are engaged at the client site, they still have responsibilities to their home 
office and need to communicate with other senior-level auditors and partners. They may need to 
share files, access e-mail, conduct conference calls, access home-office software, and so forth. One 
method of providing this access is to provide internal network access and subsequent access to the 
Internet. This involves setting up the auditors similar to how contractors may be connected to the 
system—with a user account on the network and access to the Internet. The problem with this 
configuration is that the auditors are now resident on the network and may have access to more 
network files than desired. Auditors should be treated with the same security “need-to-know” and 
“least-privilege” principles that are applied to other users of the organization’s information assets.
An alternative solution that serves to provide the access that the auditors need while simulta-
neously limiting the exposure of internal information outside the scope of the audit is to provide 
network access via a wireless broadband router. This relatively inexpensive solution provides the 
auditor with the access required and keeps the auditor from having to be set up on the organiza-
tion’s computer network. Not only does this save time in setup, but it also provides a fast solution 
to deploy to the auditors. In other words, the day that the auditors arrive on site, the wireless 
broadband router can be plugged in and they are ready to begin work. The router also permits 
sharing of the broadband connection between the auditors. It is advisable to have one broadband 
router for every four auditors to ensure an adequate bandwidth when downloading/uploading 
large files.
Once the availability of this device is known within the company, it is not unusual for the 
IT department to have more requests than there are routers. Given the inexpensive nature of this 
piece of hardware (under $200 as of this writing) and the aircard monthly fees (generally $60/
month or less depending upon pricing discounts and usage), it makes sense to ensure that there are 
extra routers that can be shipped to alternate audit locations to support the audit. The hidden costs 
of requesting accounts, setting up audit access, terminating accounts, requesting auditor names, 
etc., are greater than the one-time cost of the routers and monthly charges.
Visitor badges
Internet access
Conference
rooms
Conference
speaker phones
Printer and
scanner access
Audit
coordinator
liaison
Entrance, exit,
status meeting
locations
Document
request list
Preengagement
questions
Directions to
facilities
Area hotels and
restaurants
Scheduling and
communications
protocols
Figure 4.1  Listing of items typically requested in advance by auditors.

The Information Security Auditors Have Arrived, Now What?  ◾  53
Reserve Conference Rooms
Depending upon the size and duration of the audit, a small or large conference room may be 
needed. The failure to provide a room with enough space for both the auditors and the auditees 
can create an environment that increases the stress levels of both parties. The proper size confer-
ence room for the interviews may not be known until the interview schedule has been created. 
Most organizations do not have extra conference rooms available, so these should be scheduled at 
the start of the audit.
The auditors may also request that a room be reserved for their private conversations, separate 
from the room reserved for the interviews and the other auditors. This permits sidebar discussions 
without disturbing the rest of the team. However, it is not unusual to see auditors with headphones 
on in large conference rooms to block out the distractions of the other auditors.
If possible, locate a conference room that is away from the individuals performing a bulk of 
the work that is being audited. This avoids embarrassing situations where someone may make a 
comment related to an aspect that is currently under audit and being overheard by the auditor. 
Although the comment may be accurate, it may be taken out of context by the auditor or substan-
tiate an issue that the auditor was investigating. Staff should also be courteous to the auditors and 
respect the noise levels and conversations outside the conference room.
Temperature control is always a consideration. Although it may be tempting to smoke out 
or freeze the auditors, this strategy is ill-advised! While this may be obvious, keep in mind that 
there will be more individuals in the room at any onetime with the auditors and auditees and 
body heat will tend to raise the temperature.
Physical Access
The degree of physical access needs to be defined in advance: What building? What times? Must 
the auditors be escorted? How long can they keep their badges? Some auditors will be using their 
own experiences with the badging process to evaluate the physical visitor/consultant/employee/
contractor security controls. If the visitor log policy indicates that an individual is supposed to 
obtain a badge and sign out at the end of each day and this function is not required of the audi-
tors, then this may result in an audit finding based upon the lack of control enforcement. Or, if 
the policy is that the auditor must be escorted and the auditor finds that during the course of the 
audit, they were free to roam the building, this could also result in a finding.
Special auditor badges with predefined access and the requirement to conform to a separate 
auditor visitor policy are recommended. Auditors generally work until the early evening hours or 
start early, so a 7:00 a.m. to 7:00 p.m. access policy would satisfy most auditor needs. As far as 
escorting, auditors are being entrusted with vast amounts of confidential information to perform 
an audit, so the risk of damage by allowing the auditors into the building without an escort is low. 
Auditors could be granted access badges that permit entry during the week of their audit and be 
required to return the badges at the end of the fieldwork. Agreements with the auditors should be 
made that they will confine their activities to the conference rooms, restrooms, and break rooms 
without needing an escort, but if they need to visit other operational areas, then they must have an 
escort. The escort would preferably be the audit coordinator or his designate.
Conference Phones
Have you ever been on a phone conference call, seen someone shuffling papers, having a conversa-
tion on their cell phone, or heard dogs barking in the background? We all have, and it does not 

54  ◾  Information Security Management Handbook
help the subject matter being discussed. A good quality conference phone, such as a Polycom, 
should be placed in each conference room where interviews will be held. Because interviews gener-
ally involve geographically dispersed individuals or will involve someone calling in while traveling, 
a phone will be required for the conference. The speakerphones on office phones are not designed 
to handle a room of people 4–8 ft. away from the phone. A better setup is to have a conference 
phone with two microphones attached by 3–4 ft. cords. The acoustics of the room should also 
be tested to ensure that outside, heating/air conditioning, or fan noise does not interfere with the 
sound quality level.
Schedule Entrance, Exit, Status Meetings
Each of these meetings should be scheduled at least 1 week in advance of the start of the audit, 
preferably 2 weeks or more, so that the appropriate management and technical staff can make 
themselves available to attend. Consideration should be given to those individuals who reside in 
different time zones, with the avoidance of a pre-8:00 a.m. meeting in any time zone if possible. 
Individuals should be at their best for the audit calls and for most staff, this would be during their 
normal workday hours.
Entrance Meeting
The audit entrance meeting provides the opportunity to ensure that the organization knows the 
scope of the audit, the expectations, and the key dates. The entrance meeting is often scheduled late 
Monday morning to early afternoon to allow for traveling. The auditors generally travel on Sunday 
night through Thursday evening or Monday morning through Friday evening to provide for some 
balance, because on-site auditors for the Big Four accounting firms are traveling 80–100 percent 
of the time, depending upon the contracts. Hopefully, the audit coordinator has communicated as 
much as possible to the organization prior to the arrival of the entrance meeting, as the preparation 
activities previously mentioned are needed to ensure that the documentation would be available for 
the entrance meeting. Some auditors will request that the documentation request list be provided as 
soon as possible, sometimes ahead of the entrance meeting, however, as is more often the case, the 
auditors tend to start looking at the materials after the entrance meeting has begun. Why? Because, 
their time is usually fully committed to a prior client during the weeks preceding this engagement. 
As a result, there is limited time to look at the files that may be provided to them, and most auditors 
will agree that receiving the files the day they are on site gives them plenty to keep busy. In addition, 
this also provides more time to ensure that the document request list has been adequately prepared, 
reviewed, and QA’d prior to providing it to the auditors. The exception to this may be when scripts 
are requested to be run against infrastructure devices, such as UNIX/Windows Servers, Firewalls, 
Routers, etc., and the output is needed for the auditors to begin their analysis.
Senior management should be invited to the entrance meeting so that they are aware of the 
scope and timeline of the audit. All managers that have a role in providing information, attend-
ing interviews, or providing staff should also be included. Depending upon the organization, it 
generally does not hurt to encourage everyone that has a key role in providing information to 
the auditors to attend as well. The entrance call is scheduled for 30 minutes to 1 hour; however, 
in practice, the call is normally 10–15 minutes as there is not much to discuss at this point. The 
scope has been agreed to per prior audit engagement contracts or conversations and should not 
be a surprise at this juncture. The meeting is more of a formality to kick off the audit project and 
answer any questions that need to be clarified.

The Information Security Auditors Have Arrived, Now What?  ◾  55
From an organization’s point of view, the audit entrance meeting should not be considered 
complete if there are still lingering questions regarding (1) audit scope, (2) timing of fieldwork, 
(3) delivery dates of the draft and final reports (may be approximate), (4) documentation 
requested, (5) samples that will be requested, and (6) departments that must be involved. The 
failure to have an understanding of any of these items by this point can lead to unnecessary 
confusion.
Exit Meeting
An audit may have multiple exit meetings depending on the duration of the audit. If the audit 
involves on-site fieldwork of several weeks, but the audit itself takes several months to complete, 
the auditors may hold a site exit meeting to reaffirm the results of their fieldwork, while scheduling 
a formal exit conference at the end of their analysis and prior to the issuance of the audit report. 
The purpose of the exit meeting is to signal the end of the audit activities and ensure that both the 
auditor and auditee come away with the same understanding. These meetings are usually sched-
uled in late morning or midday on the final day of the audit, again permitting auditor cleanup and 
travel time in the afternoon.
Status Meetings
Status meetings provide a more frequent opportunity for the auditor and the auditee to ensure 
that there are no surprises or misunderstandings at the exit conference. Knowing what issues the 
auditors are facing early in the process provides an opportunity to provide other documentation 
that may better answer the auditors’ request or permit further dialogue to clarify the control in 
question. It also provides the opportunity for the audit coordinator to validate that the auditor has 
received the information requested and that the information provided was satisfactory.
Some organizations prefer a daily status meeting; however, in practice, if the audit coordi-
nator is communicating on a frequent basis with the auditor, a formal meeting every other day 
should be sufficient. These are scheduled near the end of the normal workday (4:00 or 4:30 p.m.) 
for 30 minutes so that other management staff can attend. This is true even if the auditors 
may be working until 6:00 or 7:00 p.m., to ensure the most attendance possible. The meetings 
should focus on what observations/gaps/findings have been noted or what documentation has 
been requested and is still outstanding. An agenda and updated document request list should be 
provided by the auditor in advance of each status update meeting to ensure that the conversation 
is focused on the important issues.
Setup Interviews
As with the entrance, exit, and status meetings, as many setup interviews as possible should be 
scheduled prior to the start of the audit. The document request list provides the procedures, 
reports, samples, and other evidence, but does not have the element of human interaction or an 
explanation of what is written in the documents. The setup interview provides the auditor with 
the opportunity to ask clarifying questions of the information provided. This also represents an 
opportunity to provide an overall big-picture description of a control or management area. For 
example, the information security manager could provide an overview of access management 
or security administration and how user IDs and logins are obtained, the business continuity/
disaster recovery manager could explain all the activities involved in ensuring continuity of 

56  ◾  Information Security Management Handbook
operations, or the human resources manager could explain how a new hire is on boarded into 
the organization with reference checks, background checks, confidentiality statements, and 
PeopleSoft human resource/payroll transactions.
Interviews should be scheduled for 1–1.5 hours each with at least 30 minutes in between each 
interview to permit the auditors a chance to digest what they have heard and subsequently review 
their notes. They will also need time to prepare for the next interview. Generally, the interviews 
should be scheduled during the first week of a multiweek audit so that the environment controls 
and processes are understood by the audit early on in the process. This can avoid sample pulls of 
the wrong information or invalid assumptions when evaluating the documents provided, leading 
to rework for both parties. Given these constraints, it is generally advisable to spread the inter-
views out during the first week, with no more than two scheduled for a morning or an afternoon. 
Afternoon or morning status meetings will also be scheduled during these days. Given that the 
first day is a travel day, many auditors will request that no more than one interview is scheduled on 
the afternoon of the first day, in addition to the entrance meeting. The status meeting is typically 
not scheduled on the first day, as there is nothing to report. The auditors also prefer this time to 
begin reviewing the document request list items.
Finally, it is also useful to create a spreadsheet to map the individuals to the date and time of 
the interview to ensure that there are no availability issues. It should also be noted whether or not 
that person is required to be physically present for the interview. There is usually more interaction 
with a face-to-face interview and more rapport is established with the auditor. At a minimum, the 
primary point of contact should be present in the interview, with the secondary individuals avail-
able by phone. The audit coordinator should also be present in the interviews to monitor how the 
audit is performing as well as to initiate the conference calls, record the attendees, and continu-
ously look for ways to improve the audit process.
Execution Phase
Additional Audit Meetings
With appropriate planning and scheduling, the meetings should flow from the entrance to the 
exit conference according to the schedule. Additional meetings will have to be scheduled as 
the auditor reviews the documents requested and performs tests of the audit plan. The security 
manager is best served by letting the auditor request these additional meetings, as they are only 
necessary if the auditor is having difficulty interpreting the information provided. In other 
words, volunteering to set up meetings to walk through every document requested when the 
auditor has not specifically requested such meetings, only takes away from the valuable audit 
time that the auditor has to complete the audit. The auditor may have reviewed the informa-
tion provided and decided that the evidence was sufficient and therefore needed no further 
explanation.
Establish Auditor Communication Protocol
Messages on the Internet get from person A to person B through a standard communications pro-
tocol. Teenage text messages are sent by understanding an agreed-upon set of communications, 
some of which make us LOL. To be really effective in working with the auditors to ensure that 
they have the right information, at the right place, and at the right time, we need to establish an 

The Information Security Auditors Have Arrived, Now What?  ◾  57
effective way of communicating. The failure to do so ends up with the auditor saying things like 
“I requested that information 5 days ago and haven’t seen it,” possibly evoking the response, “but 
we sent it to your team 3 times already.” Who is right? At this point, it does not really matter; 
what matters is that the process of communication failed. At the end of the day, if the auditor does 
not receive the information requested during the audit time period, they cannot validate that the 
documented control is in place and working.
To increase the likelihood that the above-mentioned scenario does not occur, the following 
activities should be agreed upon with the auditor no later than the first day of the audit. A good 
time to discuss this protocol is after the entrance meeting, between the audit coordinator and the 
lead auditor and the audit team.
◾
◾Track every information request from the auditor during the audit in a spreadsheet separate 
from the auditor document request list.
◾
◾Assign a unique number to each information request to enable tracking.
◾
◾Ensure during the audit that it is clear which information request referred to is being 
analyzed by referring to the tracking number.
◾
◾Implement a scheme (i.e., a, b, c, 0.01, 0.02, 0.03) to track follow-up requests for informa-
tion already provided. This helps keep the information organized together.
◾
◾Require the auditors to put all requests in writing and assign a number to ensure that it is 
clear what the auditor is requesting.
◾
◾Determine the number of times a day that the auditor would like to receive outstand-
ing requests. Limiting the number to once or twice a day, unless there are many requests, 
increases both auditor and auditee efficiency.
◾
◾Require that all incoming and outgoing requests go through the audit coordinator so that 
they can be tracked.
The net effect of these items is that all information is tracked and its status is immediately 
known. When the status meetings are held and the auditor and the audit coordinator have tracked 
the requests, they can be compared to see where the gaps are and reconciled. Accurate tracking 
by a central person avoids the “he said she said” discussion, as well as creating the impression 
that the company is working diligently to ensure that the auditor has the information on a timely 
basis. From an economic perspective, it is just better business to have to request and furnish the 
information onetime.
Establish Internal Company Protocol
Just as it is important to have a protocol established with the auditors, it is equally important that 
the following protocol is followed internally:
◾
◾All audit requests for additional information are sent only from the audit coordinator.
◾
◾All responses to requests for additional information are sent to the auditor from the audit 
coordinator.
◾
◾E-mail subject lines contain the year, audit name, tracking number, and a brief description 
of the item to permit searching for requests.
◾
◾Information is placed in a directory related to the tracking number and a reply to the request 
from the audit coordinator from the person providing the information indicates that the 
information is complete and ready to provide to the auditor.

58  ◾  Information Security Management Handbook
◾
◾A protocol is established for moving the request from “completed status” to “sent to the audi-
tor” by the audit coordinator.
◾
◾Audit requests are expected to be fulfilled within 24 hours (exceptions may be accept-
able for items that must be retrieved from off-site or other contractors/outsourced 
operations).
Figure 4.2 shows the flow of information from the initial request through fulfillment. 
By tracking each request in a spreadsheet and subsequently maintaining a tracking number 
throughout the process, information is less likely to be lost. As shown in the diagram, when the 
audit coordinator assigns the request, it is logged in a spreadsheet with a tracking number. The 
Audit evidence delivery process
Subject
matter
expert/
Point of
contact
Manager
Auditor
Request
audit
evidence
Assign
unique
tracking
number (i.e. 
AC33) and 
record in
spreadsheet 
as YELLOW 
status
Create
network
location
AuditName\
REQ\
041310\
AC33
Send email
request  to
SME/
Manager
Complete
evidence
and
explanation
in
auditName\ 
REQ\
041310\
AC33
Verify
evidence
contains all 
elements of 
Auditor
request
Cut and
Copy
evidence
to
auditName\
SENT\
041313a\
AC33
Update
tracking
spreadsheet to
GREEN status
Encrypt
and
copy
data to
USB
and
provide
to
auditors
Reply to
email from
audit
coordinator
indicating
evidence is
complete
Audit
coordinator
Review
evidence
Figure 4.2  Flow of information from initial request through fulfillment.

The Information Security Auditors Have Arrived, Now What?  ◾  59
same number, in this case AC33, is used as the folder name under the directory REQ\041313, 
where 041313 is the date that the item was requested (13 April 2013). Once the audit coordina-
tor receives the e-mail response from the point of contact assigned to fulfill the request in the 
folder that the information is complete, he proceeds to move the folder to the SENT\(today’s 
date) folder. He then provides this information to the auditor along with other items that are 
complete.
Using this method of SENT and REQ folders (1) provides a mechanism (a place) for the 
point of contact to place the items requested and (2) provides knowledge that the information 
was subsequently provided to the auditor. The folder structure also serves as an additional valida-
tion of the tracking spreadsheet; i.e., no contents in the REQ folder indicates that the request 
was completed.
Media Handling
The documents provided for the auditor’s review during the course of an audit contain confidential 
information that could cause harm if disclosed outside the organization or beyond the audit firm. 
For this reason, all information provided to the auditors should be encrypted, preferably with a 
product that is FIPS 140-2 compliant. This greatly reduces the risk that this information will be 
disclosed during its useful life. Documents such as security plans, baseline configurations, script 
output, and firewall rules contain highly confidential information.
The media may be passed to the auditors on site by burning the information onto a CD or USB 
thumb drive. In either case, it is not necessary to encrypt each file individually, but rather each sub-
mission to the auditor could be encrypted by encrypting the high-level folder and all subdirec-
tories. For example, if the contents were copied to an\InfoSecAudits\2013\SENT\041910a folder, 
where “a” is the first submission of the day to the auditors, then this folder could be encrypted and 
the contents copied to a CD or USB drive.
Establishing a common password for the entire project makes the encryption process much 
easier and also increases the probability that after the audit, the files will be readable because one-
time passwords may not be well documented. The password should be communicated to the team 
in a separate e-mail. The password should also be constructed as a strong password due to the nature 
of the audit artifacts that are being collected. A password composed of at least 8 characters (prefer-
ably 10), at least one uppercase, one lowercase, one numeric, and one special character, should be 
sufficient. A password constructed in this way also tends to void the use of pets names, dictionary 
names, birthdays, etc.
It is not advisable to send the audit artifacts by e-mail, as the average user has a plethora of 
e-mails on a daily basis and tracking who sent what, when, and to whom becomes a challenge. As 
mentioned previously, the better approach is to use the e-mail system for the audit coordinator 
to distribute the requests to the points of contact, requesting that the audit artifacts be placed in 
the appropriate REQ\Date\ItemTrackingNo on the server for subsequent handling. These can be 
placed on the server in an unencrypted format, as the audit coordinator will encrypt the entire 
contents of the SENT\Date+suffix folder when the items are sent. It is also not uncommon for 
the size of many of these files or file collections to exceed the 10MB range, which is typically a 
constraint imposed on the e-mails today.
It is to the company’s advantage to provide as much information to the auditors while on 
site because these files easily fit on 16G/32G/64G USB drives. Once the auditor has left the site, 
the files may have to be broken into 10MB file sizes or less, the files encrypted, and multiple 
e-mails sent to the off-site auditors. This situation can be avoided by adequate preparation and 

60  ◾  Information Security Management Handbook
confirmation that the auditors have received all the required documents during the status meet-
ings and the site exit meeting. The file size may be so large (>100MB) that it only makes sense 
to burn this information onto a CD or copy it to a USB and send it via overnight mail. This is 
not desirable, as there are still delays for the auditor in receiving the information, plus this adds 
unnecessary expense in having to provide rework.
Audit Coordinator Quality Review
The point of contacts or the subject matter experts who are supplying the information are in the 
best position to ascertain whether or not they are meeting the audit request, as they are the ones 
closest to the business process. The audit coordinator still needs to briefly review the informa-
tion provided to the auditors as a second look to catch errors similar to those previously noted in 
reviewing the initial document request list. Given that it may take an overnight process to extract 
the requested information, and the auditors may not review the information provided immedi-
ately, it behooves the organization to provide the information requested correctly the first time. 
The QA process helps ensure completeness of the response.
The Interview Itself
Auditees are expected to answer questions truthfully, and failure to do so may constitute obstruc-
tion of a federal audit with the U.S. government-initiated audits, or constitute a company or 
industry ethics violation. Audits are intended to improve the organization’s control environment 
and lying or misrepresenting the facts would serve little purpose and would not lead to making 
needed improvements in processes that would be identified by the audits.
With truthfulness as the foundation for the audit, the auditee respondent should only 
answer the questions that are asked. Providing details outside the request not only wastes 
the auditor’s time with “filler fluff” that may be irrelevant to the testing that the auditor is 
performing, but it may also expose other areas of vulnerability that are beyond the scope of 
the audit. Some auditors are known for going on fishing expeditions, whereby they may ask, 
“I have just one more question,” a line made famous by the TV show Columbo in the 1970s 
and 1980s. This line of questioning is primarily intended to reveal a flaw somewhere within 
the system by poking around. So why wouldn’t we want to know all the areas where we have 
issues? The answer is not so much that we don’t want to know, but rather we want to be on a 
fair-playing field with our competitors. Say, our firm is being audited for PCI compliance by 
a aualified auditor, or our contractual requirements mandate that an SAS070 be performed 
to get the business, we would want to be evaluated based upon an audit program that our 
competitors are being evaluated against. Therefore, it is important that individuals who are 
selected for interview are able to answer the questions posed by the auditors, but not so ver-
bose that they start talking about unrelated items or bring up other vulnerabilities outside 
the scope of the audit. Most people are proud of their work and want to talk about it with 
whoever listens. An audit interview, outside the interview sections where overviews of the 
processes are provided, is not the time to explain all the details of a process unless requested 
by the auditor.
Mock interview sessions are advantageous for those individuals who have not been involved in 
an audit before, as well as a refresher for those who are engaged in them infrequently. In a mock 
interview, an individual can portray the auditor, asking a series of questions requesting evidence 
that a control activity was performed. This can help put the interviewee more at ease during the 

The Information Security Auditors Have Arrived, Now What?  ◾  61
audit. The mock interview may also trigger additional information request ideas that were previ-
ously missed, to support the organization’s control position.
Reporting Phase
All control deficiencies should be known and communicated by the exit conference. If, for some 
reason, testing could not be completed, additional deficiencies could be noted after the auditors 
have left the site. If this is the case, for reasons mentioned in the Media Handling section, this 
complicates the audit and should be avoided. Proactive inquiry of the auditors to ensure that they 
have all the necessary information, especially by the start of the final week of the audit, should 
be done. The auditors should be focused on completing their workpapers in the final week of the 
audit versus performing additional testing. This usually occurs because of a disagreement in earlier 
testing or the selection of a new sample that was deemed insufficient (i.e., population was assumed 
to be both employees and contractors, but only employees were provided).
At the exit conference, the auditor should provide a listing of the control deficiencies (also 
referred to as gaps, observations, exceptions, findings, depending upon the nomenclature used by 
the auditor). These may or may not end up as findings on the final report. The auditors may have 
to evaluate the findings with other organizations that have been included in the scope of the audit. 
For example, for a chief financial officer’s (CFO’s) audit contracted by the federal government, the 
audit firm may wait until they have been to all the sites to ensure that they have been consistent 
in their approach and fair to each contractor. Another reason for not receiving the findings at the 
exit conference is that further peer reviews may need to be performed, or the senior partners may 
need to review the workpapers containing the audit testing and evidence collected.
A draft report is subsequently issued with the findings. There should be no surprises if the 
audit team and the organization have worked together. Usually, when surprises end up on the 
report, it is the result of (1) a lack of clear communication in the beginning as to what conditions 
would create a finding, (2) a prior issue surfaced but was not communicated that it was a find-
ing, (3) documents requested were not provided, (4) misunderstanding whether or not an earlier 
agreement was reached when discussing a gap, or (5) the auditor held the issue to the end to avoid 
confrontation. Based on experience of many audits, item (5) does occur, but usually one of the 
other items is the primary reason for surprises. Surprises should be left for birthdays and holidays 
and not audit findings!
Once the draft report is received by the organization from the auditor, the auditee has 5–10 
business days to provide a response. The response provides the auditee with an opportunity to 
agree or disagree with the audit finding and explain why. These comments are included in the reis-
sued draft report, which should be issued 5–10 days after receipt of the auditee’s comments. If the 
organization agrees with the finding, it is best to also note a corrective action plan (CAP) at this 
time. The CAP explains at a high level what will be done to mitigate the deficiency and when this 
will be completed. The CAP will need to be submitted within 30 days after the final report is reis-
sued with the auditee comments, so if there is agreement, this may as well be included in the draft 
report. This provides the reader who is not so familiar with the audit, with an early understanding 
of the steps that will be taken.
The final report issuance varies by audit firm and the contractual requirements. An internal 
review of the draft report and the workpapers adds off-site time after the fieldwork to ensure that 
the audit report is accurate. Sometimes, this process can take months between the issuance of 
the draft and the final report. Firms that are security conscious will not wait for the final report 

62  ◾  Information Security Management Handbook
to begin taking action on the issues. CAPs are typically due within 30 days after the final report 
issuance, and it is preferable to mitigate the vulnerability within 90 days from the CAP due date. 
Obviously, long security implementations will be the exception, but should not be the rule. Ninety 
days should be sufficient to mitigate most vulnerabilities, given the appropriate priority. Each of 
the CAPs should be tracked to ensure that the person responsible is completing the milestones 
and that the target date is still on track. As the CAPs are completed, the audit artifacts, including 
changed processes, reports, project plans, and evidence of implementation, should be retained to 
provide to the auditor for next year’s review. The auditor will then take these items and use them 
as partial evidence to close the finding.
About the Author
Todd Fitzgerald, CISSP, CISA, CISM, CGEIT, PMP, HITRUST, ISO27000, ITILV3, National 
Government Services (WellPoint, Inc. Affiliate), is responsible for external technical audit and 
internal security compliance for one of the largest processors of Medicare claims. He has led the 
development of several security programs and actively serves as an international speaker and author 
of information security issues. He coauthored the 2008 ISC2 book entitled CISO Leadership: 
Essential Principles for Success. He graduated from the University of Wisconsin–La Crosse, serves 
as an advisor to the College of Business Administration, and holds an MBA with highest honors 
from Oklahoma State University.

63
Chapter 5
Continuous Monitoring: 
Extremely Valuable to 
Deploy within Reason
Foster J. Henderson and Mark A. Podracky
Introduction
Given the media coverage of the U.S. government’s information technology (IT) continuous 
monitoring requirements over the last 12 months, it is understandable how some individuals 
may have been led to believe that continuous monitoring is something new. The requirement to 
perform continuous monitoring has been around even before the Federal Information Security 
Management Act (FISMA) of 2002 was enacted. For example, the Department of Defense 
(DoD) Information Technology Security Certification and Accreditation Process (DITSCAP) 
Application Manual (2000, 113) stated, “effective management of the risk continuously evaluates 
the threats that the system is exposed to, evaluates the capabilities of the system and environment 
to minimize the risk, and balances the security measures against cost and system performance.” 
Furthermore, the document stated that the Designated Approving Authority, users, security 
practitioners, etc., continuously perform evaluations as a method to ensure secure system 
management (DoD, 2000). It is safe to say that the Office of Management and Budget’s (OMB) 
Circular A-130 Appendix III intended the requirement for continuous monitoring (NIST, 
2010a, 2010b).
Continuous monitoring, implemented with sound rationale and procedures (i.e., an organization’s 
goals and level of risk acceptance taken into consideration against an organization’s functional 
business practices/mission objectives), is a powerful capability to assist IT security practitioners, 
authorizing officials (AOs), or designated accrediting authorities (DAAs) in their respective decision-
making processes. That is in contrast to individuals who incorrectly contend that continuous 
monitoring will supplant the current certification and accreditation (C&A) process within the 
U.S. federal government, “… continuous monitoring can support ongoing authorization decisions. 
Continuous monitoring supports, but does not supplant, the need for system reauthorization” 

64  ◾  Information Security Management Handbook
(NIST, 2010a, 2010b, p. 1). The intent of this chapter is to discuss the key components of continu-
ous monitoring, provide recommendations to assist others with continuous monitoring planning, 
and provide rationale for why continuous monitoring will not supplant existing authorization (i.e., 
accreditation) procedures.
Background
In the past, the U.S. federal government has released several key IT regulatory provisions. The 
following is a list of key IT regulatory policies provided in chronological order:
	
1.	Computer Security Act of 1987
	
2.	Paper Reduction Act 1995
	
3.	Clinger–Cohen Act of 1996
	
4.	OMB Circular A 130 Appendix III, 1997 (NIST, 2010a, 2010b)
	
5.	Government Information Security Reform Act (GISRA) enacted 2000
	
6.	FISMA
GISRA’s requirements leveraged the key existing requirements from earlier regulatory governance 
predecessors (What is.com, 2008). The main difference with the early predecessors of GISRA is 
that the annual compliance reporting of federal departments and agencies was to be tied to their 
budgetary cycles. Specifically, noncompliance threatened organizations with having portions of 
their IT fiscal budgets removed. However, the problem with GISRA is that
◾
◾It lacked detailed guidance provided to federal agencies to meet its goals (i.e., lack of a 
uniform set of IT controls across the government) (What is.com, 2008).
−
−“Specific standards for defined risk levels would not only have helped agencies ensure 
compliance, but provide a standard framework for assessment, ensure the adequate 
protection of shared data and reduce the effort—and resources—required to achieve 
GISRA compliance” (What is.com, 2008, para 4).
◾
◾It produced labor-intensive data calls (i.e., calling/e-mailing agency’s subordinate units in 
an attempt to populate the data fields of GISRA and stop work on other priority activities 
within the organization).
−
−The absence of automated tools to assist in populating data fields was a consistently 
recognized problem.
◾
◾Organizations eventually discovered that being noncompliant would not result in the OMB 
or Congress withholding their IT budgets.
To say that 11 September 2001, changed many procedures within the federal government 
is a humble understatement. One of the by-products of 9/11 was the replacement of GISRA 
with FISMA in October 2002. My intent is not to discuss FISMA at the granular level, as there 
are several papers and articles addressing the topic. The nine key components of FISMA are as 
follows:
	
1.	Risk assessment—categorize the IT and information according to the risk.
	
2.	Inventory of IT systems

Continuous Monitoring: Extremely Valuable to Deploy within Reason  ◾  65
	
3.	System security plans (SSPs)
	
4.	Security awareness training
	
5.	Security controls
	
6.	C&A
	
7.	Incident response/reporting security incidents
	
8.	Continuity planning
	
9.	Continuous monitoring (NIST, 2010a, 2010b)
Federal Desktop Core Configuration
The Federal Desktop Core Configuration (FDCC) is an OMB-mandated security configuration. 
The FDCC settings currently exist for Microsoft’s Windows XP service pack 3 and Vista operating 
system (OS) software. Although not addressed specifically as the FDCC, the requirement is within 
OMB memorandum M-07-11 (OMB, 2007). Memorandum M-07-11 was addressed to all federal 
agencies and department heads and a corresponding memorandum from OMB was addressed to 
all federal agencies and department chief information officers (CIOs).
How Was FDCC Created?
The National Security Agency’s (NSA’s) Red Team visited the Armed Forces during one of 
their periodic network exercises. Subsequently, in the early 2000s, the Air Force CIO requested 
assistance to develop standard desktop configurations and hardening guidance with assistance 
from NSA and the Defense Information Security Agency (DISA) as remediation based upon the 
action items from the recent NSA Red Team exercise. It was later realized that a very large per-
centage of network incidents could have been avoided if the available patches had been applied 
or the available hardening guidance had been used. From tracking information assurance vul-
nerability alert (IAVA) (i.e., U.S. Strategic Command’s Joint Task Force—Computer Network 
Operations vulnerability messages based upon the Common Vulnerabilities Exposures [CVEs]) 
compliances, the Air Force leadership realized that the time to apply a software patch took well 
over 100 days in some instances. An internal lean engineer process meeting was held; recom-
mendations and a list of action items were tracked and that number shrank to 57 days. Later, 
through an enterprisewide standard desktop configuration deployment, that time was reduced 
from 57 days to less than 72 hours. In 2007, a group of cyber security experts stated that this 
U.S. Air Force proof of concept was one of the most significant successes in cyber security 
(Mosquera, 2007).
U.S. Government Configuration Baseline
The FDCC mandate later evolved into the U.S. Government Configuration Baseline (USGCB). 
USGCB is a federal governmentwide initiative that provides guidance on what can be done to 
improve and maintain effective configuration settings, focusing primarily on security. Specifically, 
its charge is to create security configuration baselines for IT products deployed across federal agen-
cies. USGCB is now a required task under the latest FISMA guidance from OMB.

66  ◾  Information Security Management Handbook
The Requirement (Continuous Monitoring)
IT Security in the federal government has undergone a paradigm shift to continuous monitor-
ing, as indicated by the slew of recent National Institute of Standards and Technology (NIST) 
and OMB communications. For example, the OMB’s memorandum M-10-15, titled FY 2010 
Reporting Instructions for the FISMA and Agency Privacy Management, mandated continuous 
monitoring. This document placed the Department of Homeland Security (DHS) in charge of 
continuous monitoring (i.e., the monitoring and reporting of federal agencies’ compliance) (OMB, 
2010). NIST recently defined continuous monitoring as
…maintaining ongoing awareness of information security, vulnerabilities, and threats 
to support organization risk management decisions. The objective is to conduct ongo-
ing monitoring of the security of an organization’s network, information and systems, 
and respond by accepting, avoiding/rejecting, transferring/sharing, or mitigating risk 
as situations arise (NIST, 2010a, 2010b, p. 1).
NIST provides excellent guidance on continuous monitoring within Special Publications (SP) 
(draft) 800-137, Information Security Continuous Monitoring for Federal Information Systems. 
Rather than recite and repackage the draft SP contents for the reader, this chapter restates the 
high-level aspects and provides specific examples to better assist individuals in their specific con-
tinuous monitoring implementations. For additional details, it is recommended to reference draft 
SP 800-137.
Reviewing NIST’s executive summary (i.e., SP 800-137), continuous monitoring can be 
explicated using the following list.
	
1.	Define the strategy.
	
2.	Establish measures and metrics.
	
3.	Establish monitoring and assessment frequencies.
	
4.	Implement a continuous monitoring program.
	
5.	Analyze the data and report the findings.
	
6.	Respond with mitigating strategies.
	
7.	Review and improve the program (NIST, 2010a, 2010b).
Admittedly, this may be overly simplistic, as there are many underlying disciplines to support 
the above categories—the majority of those disciplines are addressed in the next section.
Define the Strategy
Plan the work and do the work according to the plan—this is a basic project management 
statement. An individual has to understand that continuous monitoring is more of a system 
engineering/project management effort that is processing IT security data than being a purely 
information security effort. For example, what are the needs and requirements of the stakehold-
ers? What is the overall purpose or objective of the task? The answers are fundamental project 
management principles. SP 800-137 discusses a three-tiered approach for applying continuous 
monitoring throughout an organization.

Continuous Monitoring: Extremely Valuable to Deploy within Reason  ◾  67
	
1.	Tier 1 is described as those tasks that provide governance/risk management for an organiza-
tion; e.g., policies, strategic planning, vision, and overall risk management governing the 
entire organization.
	
2.	Tier 2 is the core business functional requirements or mission objectives/goals for an 
organization.
	
3.	Tier 3 is the information system and the user requirements that the IT system is fulfilling. 
Specifically, the technical, administrative (i.e., training), and physical controls required for 
protecting IT systems and enabling the users (NIST, 2010a, 2010b).
This may sound complicated, but it is actually simple, considering that this approach is further 
broken down into work breakdown structures (WBS) and the realization that a large portion of 
the WBS should have been accomplished by the organization’s CIO (federal side). For example, 
NIST separates the continuous monitoring process into nine steps, as documented by the Risk 
Management Framework (RMF) from SP 800-37 Revision 1: Applying the RMF to federal infor-
mation systems. Step 1 of the RMF states to categorize the information system.
Any security practitioner with at least 3–4 years of experience securing federal IT systems 
should know to review the Federal Information Processing Standards (FIPS) 199, Security 
Categorization of Federal Information and Information Systems, codes within their organiza-
tion’s respective portfolio management directory, database, or their cloud. For clarification, simply 
reviewing an organization’s FIPS 199 categorization codes for those individual IT systems used 
to fulfill its mission or goal would meet that requirement. The DoD terms it Mission Assurance 
Category (MAC) codes in accordance with DoD Instruction 8510.01, DoD Information Assurance 
Certification and Accreditation Process for top secret and below classified rated systems.
Steps 2–4 of NIST’s RMF process include selecting, implementing, and assessing the security 
controls, respectively. As previously mentioned in the section: U.S. Government Configuration 
Baseline, the OMB has mandated NIST’s USGCB (i.e., addresses the desktop controls suggested 
within NIST’s RMF Steps 2 and 3). To further streamline and define the strategy, a continuous moni-
toring strategy recommendations are listed. However, the recommendations must be based upon the 
organization’s “as is” architecture model or must support the “to be” architecture model (i.e., depend-
ing on the current status of the architecture model if it is going through a transition process).
	
1.	Identify the best tool or available tools for the job (understand the continuous monitoring 
capability from each vendor and their tools. Security Content Automation Protocol Validated 
Products use is critical to not making one’s life difficult). (Reference NIST’s http://nvd.nist.
gov/scapproducts.cfm URL for additional details.) In addition, the SPAWAR tool is a govern-
ment off-the-shelf tools (GOTS) product and it is free to federal government entities.
	
2.	Install/deploy network-monitoring tools currently not available.
	
3.	Connect those tools’ output to a central repository.
	
4.	Determine which process to conduct (manual or automated collection).
	
5.	It is recommended to initially conduct continuous monitoring on a monthly basis until the 
system administrators, the leadership’s expectation, and the reporting process become fairly 
routine. This assumes that the reporting process (i.e., the data output) adjustments were made. 
For example, the data were reviewed (no issues) and the processes were streamlined internally.
For further clarification, the Common Platform Enumeration (CPE) (i.e., the list of OS by 
version), the CVE (i.e., the false-positives from the scanning tool are validated), and the Common 

68  ◾  Information Security Management Handbook
Configuration Enumeration (CCE) values are properly reconciled. That is, they are compliant 
with NIST’s USGCB and the respective OS hardening guidance from NSA or DISA’s Security 
Technical Implementation Guides (STIGs). Was the scanning tool’s latest signature pulled down 
from the vendor? What is the frequency of those updates? These are the types of issues that have 
to be considered within the continuous monitoring strategy.
Based upon experience, these items are communicated within the existing C&A plan, the SSP, 
and the organization’s standard operating procedures. By now, it should be apparently clear why 
continuous monitoring supports, but will not supplant, the C&A process.
Based upon the current commercial monitoring technologies used within the federal government 
(i.e., admittedly excluding Einstein, NSA, or other GOTS tools), the following are the recommended 
continuous monitoring automated process areas to adapt.
	
1.	Asset management
	
2.	Vulnerability management
	
3.	Configuration management
	
a.	 It is critical that an organization has an internal mature configuration control process. 
For example, a current client has an exorbitant number of printers that need to be phased 
out and reduced. The USGCB Windows 7 setting breaks a large portion of those 
printers. To make matters worse, the vendor’s universal printer drive does not work, but 
it is stated as USGCB compliant. The only solution is to use Windows update to get the 
driver directly from Microsoft. Therefore, one is faced with either not supporting those 
printers (i.e., legacy) or providing a list of approved printers to users during a continuing 
resolution (as of writing this chapter) when we cannot purchase Jack Schmidt! The 
problem in this example is that the configuration management process was not being 
followed nor was there any guidance provided.
 
b. It is literally akin to the Wild Wild West with purchases being made in FY 10 not 
supporting the Windows 7 USGCB images. The second issue includes JAVA runtime 
updates that are frequently pushed. It has been our experience that this breaks several 
USGCB settings and increases trouble tickets within the organization. It is thus recom-
mended to place these updates in a control approval process as well.
	
4.	Malware detection
	
5.	Patch management
	
6.	Log integration
	
7.	Security information and event management (SIEM)
As previously mentioned in this section, it is recommended that a manual process from the 
various tools collected data be used first, before fully automating the continuous monitoring 
reporting. This way it is easier to make comparisons between the automated process’ output and 
the earlier collected manual feeds (i.e., placed in an Excel spreadsheet and then pushed via an 
XML format) and make the necessary adjustments, because there is a working experience and 
baseline in which to perform an initial comparison (i.e., after the initial investigations/verification 
have been performed to validate the information).
Establish Measures and Metrics
Guidance on the specific metrics within the federal government related to FISMA compliance 
comes from OMB. The issue is that OMB yearly FISMA guidance is usually released 5–6 months 

Continuous Monitoring: Extremely Valuable to Deploy within Reason  ◾  69
into the fiscal year’s reporting cycle. It is recommended to have a list of metrics for internal stake-
holders and external stakeholders. The external stakeholders would be OMB, the U.S. Computer 
Emergency Response Team, DHS, etc. The internal stakeholders are the organization’s internal 
leadership and the IT security practitioners (CIO, chief information security officer, information 
system security manager, etc.). The following are possible metrics based upon the seven earlier 
recommended continuous monitoring automated processes.
Asset Management
◾
◾Blocking of unauthorized network connections.
◾
◾Blocking of unauthorized devices (mobile phones [excludes BlackBerry given its prevalent 
use within the federal government], unapproved unencrypted USB flash drives, cameras, 
etc.). Don’t you love your users’ colleagues?
Vulnerability Management
◾
◾Know the list of vulnerabilities marked by criticality codes.
Configuration Management
◾
◾FDCC/USGCB compliance (scan for compliance with NIST’s latest guidance)
◾
◾DISA STIG, SANS, or NSA hardening guidance compliance
◾
◾Port and Protocol compliance (based upon deny all, allow by exception)
◾
◾Prohibit authorized remote connections not meeting the configuration guidance (i.e., place 
in demilitraized zone (DMZ) or some similar quarantined area until all patches are applied)
◾
◾Data feed of connected network devices (includes wireless devices)
Malware Detection
◾
◾Age of virus signatures against current baseline
Patch Management
◾
◾Compliance with NIST’s national CVE database or U.S. Cyber Command IAVAs 
(percentage-based)
Log Integration/SIEM
◾
◾Viruses not deleted (my client has over 1 million events per day so my colleagues’ pain is 
clearly understood)
◾
◾Enabling or disabling of accounts (user and admin)
Establish Monitoring and Assessment Frequencies
This was sufficiently covered earlier as an individual can see that there were some overlaps men-
tioned from the previous section and within the section: Define the Strategy. One lesson learned 

70  ◾  Information Security Management Handbook
is to use a test Active Directory organization unit (OU) to monitor how a patch or other software 
will impact the USCGB settings. Specifically, it is recommended to create a baseline before instal-
lation, during the installation, and on removal of the software to see how the USGCB settings 
are changed. This needs to be monitored, otherwise an individual will increase the help desk calls 
when an unexpected value changes the USGCB settings. It should be noted that a large portion of 
applications (i.e., commercial) are okay, but it was the custom applications that generally wreaked 
havoc upon our organization.
Implement Continuous Monitoring Program
After the organizational continuous monitoring strategy has been completed (internally) or pro-
vided from a higher level (i.e., headquarters or the parent organization level), it is suggested that 
a continuous monitoring implementation plan be drafted to communicate to internal stakeholders 
the “who, what, when, where, and with what” tools that are going to be used. This document 
needs to be agreed upon and approved internally. The following chart was provided by a colleague 
to communicate the high-level functions, milestone dates, and other pertinent information. For 
clarification, each area—i.e., of the seven earlier recommended continuous monitoring automated 
processes—data fields need to be completed. This assumes that the deficiencies are being tracked 
and mitigated, although this is not communicated within the chart (by the respective owners). For 
example, the plans of action of milestones (i.e., the get-well plan to eliminate the issues or trends 
from the scans impacting the organization) are being tracked until resolved.
Requirement:
(e.g., Asset, Vulnerability, 
Configuration, Management)
Points of contact:
  Technical
(e.g., Information System Security 
Manager)
  Operational
(e.g., Network Ops Manager)
  Management
(e.g., CISO)
Manual processes employed:
Available tools that can address the 
requirement:
Planned approach:
Quarterly milestones:
  Q1FY11
  Q2FY11
  Q3FY11
  Q4FY11
  Q1FY12

Continuous Monitoring: Extremely Valuable to Deploy within Reason  ◾  71
Major tasks required to address the 
milestones:
  Task 1:
  Task 2:
  Task 3:
Current status:
Not started/requirements gathering/
design/implementation/testing/
roll-out/refinement. If available, the 
percentage complete would also be 
useful
Limitation of Continuous Monitoring
At the beginning of the chapter, I noted that continuous monitoring cannot supplant existing 
authorization procedures. Instead, it supports the process. By now, it is apparent that continuous 
monitoring cannot present an overall comprehensive risk management plan for an entire organi-
zation. Specifically, not all of NIST’s SP 800-53 Revision 3: Recommended security controls for 
federal information systems and organizations can be fully automated. As examples, contingency 
planning, other similar administrative controls, and some physical controls cannot be automated 
when performing a C&A. Yes, although the expiration dates can be tracked in C&A tools, such 
as Trusted Agent FISMA, Xacta’s IA Manager, Enterprise Mission Assurance Support Service 
(eMASS), etc., those respective disciplines and procedures involve people and processes and will 
remain a manual process.
It is not my intent to embarrass an organization or fellow colleague. Rather, the following example 
is used to illustrate a point. I recall reading Federal Computer Weekly and a similar article, which 
stated how the National Aeronautics and Space Administration (NASA) had saved money by doing 
away with the old C&A process and adopting a continuous monitoring procedure. They testified 
about their “success” before the Congress (FCW, 2010). Several months passed and I happened to 
notice a rather interesting article, which described how NASA failed to remove or sanitize sensitive 
data when it released 14 previously used computers to the public (Gooding, 2010). Furthermore, at 
a disposal facility, auditors discovered computers containing NASA’s Internet Protocol addresses as 
well as the fact that NASA had authorized the release of other computers that were subject to export 
controls (Gooding, 2010).
Recently, an article by Jackson (2010) detailed a State Department report that its “… high-risk 
security vulnerabilities were reduced by 90 percent from July 2008 to July 2009 and the cost of 
certifying and accrediting IT systems required under FISMA was cut by 62 percent by continu-
ously updating security data” (para 8). That is an excellent accomplishment and an excellent success 
story. The point is that metric is addressing technical controls. It is not the total picture. And to 
take this a step further, one need to look no further than the State Department’s recent issue with 
Wikileaks. Yes, an Army private first class was responsible for the damage, but a substantial 
portion of the files that he retrieved were from the State Department. IT experts have indicated 
that this would not have happened had we (as a community) done “X, Y, and Z.” This should have 
been in place, etc. “You hypocrite, first cast out the beam out of your own eye; and then shall you 
see clearly to cast out the mote out of your brother’s eye” (Matt. 7:5 King James Version). Most 

72  ◾  Information Security Management Handbook
of the commercial sector does not even perform background investigations (it costs money) on 
employees unless their work requires a U.S. government clearance. Almost every other month 
there seems to be some “Insider” article about someone who has burned a commercial organi-
zation. The Computer Security Institute’s annual Computer Crime and Security Surveys and 
Verizon’s 2008–2010 data breach reports should validate my claim (i.e., growing insider threat) 
(Verizon, 2009).
Conclusion
Continuous monitoring is a very important key to successfully strengthen and validate the FISMA 
reporting, and this is an improvement over what has occurred in the past. However, its mandated 
use should be expedited throughout the federal government as OMB intends. As communicated 
several times throughout this chapter, continuous monitoring is a key component to leverage the 
accreditation process.
References
DoD. Department of Defense Manual 8510.1-M, Department of Defense Information Technology Security 
Certification and Accreditation Process (DITSCAP). Assistant Secretary of Defense Command, 
Control, Communications, and Intelligence, 2000.
DoD. Department of Defense Instruction 8510.01, DoD Information Assurance Certification and 
Accreditation Process (DIACAP). Assistant Secretary of Defense Networks and Information Integration 
(ASD NII), 2007.
Federal Computer Weekly News. NASA FISMA stance stirs up a debate: Readers still see value in certification 
and accreditation, 2010. http://fcw.com/articles/2010/06/14/fcw-challenge-fisma-nasa.aspx (accessed 
February 27, 2010).
Gooding, D. NASA sells PC with restricted space shuttle data: Disk wiping? We’ve heard about it. The Register, 
2010. http://www.theregister.co.uk/2010/12/08/nasa_disk_wiping_failure/ (accessed February 26, 2010).
Jackson, W. FISMA’s future may lie in state department security model: FISMA re-working is increasingly 
likely. Government Computer News, 2010. http://gcn.com/articles/2010/03/03/rsa-futue-of-fisma.
aspx (accessed January 23, 2011).
Mosquera, M. Air force desktop initiative named top cybersuccess story. Federal Computer Weekly, 2007. 
http://fcw.com/articles/2007/12/13/air-force-desktop-initiative-named-top-cybersecurity-success-
story.aspx (accessed January 23, 2011).
National Institute of Standards and Technology. Special Publications 800-137 DRAFT Information Security 
Continuous Monitoring for Federal Information Systems and Organizations, 2010a. http://csrc.nist.
gov/publications/drafts/800-137/draft-SP-800-137-IPD.pdf (accessed February 6, 2011).
National Institute of Standards and Technology. FISMA detailed overview, 2010b. http://csrc.nist.gov/
groups/SMA/fisma/overview.html (accessed February 20, 2011).
Office of Management and Budget. OMB Memo 07-11, Implementation of Commonly Accepted Security 
Configurations for Windows Operating Systems, 2007. http://www.whitehouse.gov/sites/default/files/
omb/assets/omb/memoranda/fy2007/m07-11.pdf (accessed February 12, 2011).
Office of Management and Budget. OMB Memo 10-15, FY 2010 Reporting Instructions for the Federal 
Information Security Management Act and Agency Privacy Management, 2010. http://www.white-
house.gov/sites/default/files/omb/assets/memoranda_2010/m10-15.pdf (accessed February 20, 2011).
Verizon. Data breach investigation report, 2009. http://www.verizonbusiness.com/resources/reports/
rp_2010-data-breach-report_en_xg.pdf (accessed March 1, 2011).
Whatis.com. Government Information Security Reform Act, 2008. http://whatis.techtarget.com/definition/
government-information-security-reform-act.html (accessed February 20, 2011).

73
Chapter 6
Social Networking
Sandy Bacik
Did you get my tweet? Can I join your LinkedIn? Did you see my updates on Facebook or 
MySpace? Some people with limited knowledge of computers might think, “what language are 
you talking?” Social networking is continuing to creep into all arenas of people using computers, 
even the corporate environment. Does your enterprise permit access to social networking sites 
during business hours? Does your enterprise have a policy that states what can and cannot 
be posted to a social networking site? Many enterprises do not have guidelines or education 
programs for their staff and the enterprise does not know what information may be being 
disclosed and what the staff are posting about themselves or the enterprise. In the age of social 
networking, what are the enterprise risks with using social networking internally and not guiding 
employees on information disclosure?
What exactly is social networking? A social network is a social structure made up of people 
that are linked by one or more specific types of interconnections, such as values, ideas, friendship, 
or a professional connection, similar to the game six-degrees of separation. Our network of social 
relations has expanded, moved to the Internet, and organized. Online social networking exploded 
during 2003 and 2004. All online social networking sites allow a person to provide information 
about themselves and whatever other information they would like to share. The types of com-
munications within social networking sites include forums, chat rooms, e-mail, and instant mes-
senger. The social networking sites allow a person to browse based on certain criteria. Some social 
networking sites have communities and subgroups for particular interests. So, what are some of 
the security implications of online social networks?
◾
◾Some people may not exercise caution when disclosing information, as they would when 
they are in person.
◾
◾There is a perception of anonymity when online.
◾
◾Lack of physical interaction provides a false sense of security.
◾
◾Many Internet sites are now tailoring information for those they are connected to without 
realizing who else may see it.
◾
◾A person may offer insights to impress his friends and colleagues.

74  ◾  Information Security Management Handbook
Generally, people using these sites do not pose any threats, yet malicious people may be drawn 
to these sites because of the freely available (personal) information. The more information avail-
able about a person, the more someone might be able to use it for malicious reasons. Malicious 
people can attempt to form relationships and eventually perform a social engineering attack using 
the information a person provided about the enterprise in which he is or was employed. Social 
networking sites, depending on the site, store a person’s personal information. What is the largest 
global enterprise you can think of? Now, think of the number of accounts and images that global 
enterprise stores. It does not matter which one you choose, because you can bet that Facebook 
or MySpace contains many more accounts and images. And what is used to secure those social 
networking accounts—yes, a simple user ID and password. For many security professionals, their 
social networking accounts probably have strong passwords, but what about the millions of other 
accounts that have no security background. Today, many enterprise users prefer to manage their 
personal information on a social networking site to keep acquaintances abreast of their activities 
and accomplishments.
Ok, so we share personal information. What types of privacy and security issues and threats 
are present with social networking sites to the enterprise?
◾
◾One of the larger enterprise risks is social engineering attacks: Social engineering is a means of 
attack that is frequently used by hackers to bypass security mechanisms and access sensi-
tive enterprise data—not by using technology (although technology may be involved), but 
by using enterprise employees. Data is collected subtly and are gathered gradually, piece by 
piece. Some information is necessary to create an account or to enter an online community, 
but often the privacy settings are neglected; therefore, the threshold for gaining information 
to be used in a social engineering attack is low.
◾
◾Spam: Social networking sites enable various types of messaging. These messaging services 
allow others to provide unsolicited e-mails to members, even though site policies are in 
place.
◾
◾Spear phishing: With social networking messaging, members are potentially opening them-
selves up to an e-mail spoofing fraud attempt that targets a specific enterprise, seeking unau-
thorized access to confidential data.
◾
◾Information leakage: Some information is only available to “friends” or members of a 
restricted group within a social networking site and this is the first line of defense in protect-
ing privacy. Because it is easy to become linked to another, someone may be linked under 
false pretences. Some users do not intend to release information about their enterprise, yet it 
is part of their profile details.
◾
◾Reputation slander: Fake profiles are created in the name of well-known personalities or 
brands or to slander people who are well known within a particular network of linked 
profiles. Not all profiles are necessarily accurate portrayals of the individual posting the 
profile.
◾
◾Stalking and bullying: These are repeated and purposeful acts of harm that are carried out 
using technology against individuals.
◾
◾Information aggregation: Profiles on social networking sites can be downloaded and stored 
over time and incrementally by third parties. This information can be used by third parties 
for purposes and contexts not intended by the original person.
◾
◾Secondary data collection: Personal information knowingly disclosed in a profile can be seen 
by the site operator using the network itself (data such as time and length of connections, 

Social Networking  ◾  75
location [IP address] of connection, other users’ profiles visited, messages sent and received, 
and so forth).
◾
◾Face recognition: Personal information on social networking sites can include user-provided 
digital images, which are an integral and popular part of a profile.
◾
◾Linkability from image metadata, tagging, and cross-profile images: Many social networking 
users tag images with metadata, such as a link to their profile or e-mail address.
◾
◾Social network aggregators: This is a relatively new breed of applications that attempt to con-
solidate all of a person’s various social networking profiles into one. Many social network 
aggregators have not seen much success to date.
◾
◾Creating an account: Many social networking sites require a birth date as part of the registra-
tion to ensure that the member is over a certain age. Other information requested is phone 
number, address, likes, dislikes, favorite things, and family. Although this information is 
simple, what can happen if it falls into the hands of a malicious person?
◾
◾Difficulty of complete account deletion: Trying to completely delete an account from a social 
networking site is difficult. It is easy to remove the primary pages and information, but sec-
ondary information, such as public comments made to others within the social networking 
sites, remains online and is linked to the original account.
From a business point of view, there are benefits to various social networking sites that start 
with recruitment and go through staff termination and trying to find resources to acquire for a 
project. Many human resource recruitment processes now include Internet and social networking 
site searches to find prospective employees and contractors. Social networking sites can reveal how 
professional a person can potentially be, the various activities that the recruit is involved in, and 
also validate information on their resume. Prospective employees can also do research on enter-
prises for which they are applying for a position. On the other hand, when an employee is exhibit-
ing anomalous behavior and is reported for disciplinary actions, the Human Resource department 
can again use a social networking site to see if the enterprise is possibly being slandered or discussed 
by the employee in question. They can determine the level to which the employee is disciplined. 
During a professional career, we meet many people, we lose touch, and we want to reconnect for 
an opportunity or a resource. Professional networks allow enterprises to research and connect with 
potential resources and business partners for technology projects. With caution and validation of 
the information researched, social networking sites can benefit an enterprise.
Trying to adequately control employee use of public social networking by simply telling them 
to stop is futile. Employee behavior can be modified somewhat by awareness training, but behav-
ior is what it is. Some employees will continue to act in either careless or malicious ways, especially 
if motivated to do so. Recommendations should be implemented based on business need, risk, and 
the availability of resources. The following is a list of a few enterprise recommendations to limit 
the risk of social networking sites within the enterprise:
◾
◾Block the use of social networking sites from the enterprise network. This will help protect 
your data or social engineered information about your company or network, from finding 
its way directly from the employee’s desk or your network.
◾
◾Strengthen or implement a data leakage prevention program. Know where and how your 
data is moving.
◾
◾User awareness training. User awareness is one of the better defenses against any type of 
technological or nontechnological attacks. Within the user awareness training, information 

76  ◾  Information Security Management Handbook
awareness should be discussed from a business and personal point of view for a better under-
standing of the risk of information disclosure. Information awareness should also include 
social engineering attack awareness. Promote the idea that the more information given out, 
the more vulnerable you are and that the Internet is a public resource.
◾
◾Establish a security policy architecture that includes a security policy on information and a 
standard or guideline on the use of social networks. Topics for the security policy architec-
ture include accounts, passwords, information handling, and disclosure.
◾
◾Set up processes to routinely search social networking sites for enterprise (and employee) 
information.
◾
◾Set up processes to report and detect abuse. Possible techniques for detecting abuse can 
include:
−
−Filtering of malicious or spam comments
−
−Filtering by Web sites or providers
−
−Filtering comments by quality to increase content quality
−−Filtering of enterprise or staff names
If the enterprise decides that the use of social networking sites is permitted, then the enterprise 
needs to define guidance for the enterprise employees while connected to the enterprise network 
and when not connected to the enterprise network. The benefits of a social networking enterprise 
statement may shield the enterprise from defamation lawsuits and can limit the potential disclo-
sure of company proprietary information. An enterprise could make a policy statement like “Be 
mature, be ethical, and think before you type and press Enter.” Such a statement will leave much 
interpretation up to the enterprise employee. As the enterprise decides to incorporate a social net-
working policy, standard, or guideline into the employee handbook, the enterprise might want to 
consider the following questions:
	
1.	How far should the statements reach? Should the statements be meant only for employees 
while at work or connected to the enterprise network, or should the statements be meant for 
employees when they are not at work? For liability reasons, the statements should cover both 
scenarios.
	
2.	Does the enterprise want to permit social networking while connected to the enterprise 
network? It is not realistic to ban all social networking at work. The enterprise will lose the 
benefit of business-related networking, such as LinkedIn.
	
3.	If the enterprise prohibits social networking, how will social networking be monitored? 
Turning off Internet access, installing software to block certain sites, monitoring employees’ 
use, and disciplining offenders are all possibilities, depending on how many resources the 
enterprise has or how aggressive the enterprise monitoring wants to be.
	
4.	If the enterprise permits employees to social network while connected to the enterprise net-
work, does the enterprise limit the access to work-related conduct, or permit limited personal 
use?
	
5.	Does the enterprise want employees to identify with the enterprise when networking online? 
Enterprise employees should be made aware that if they post as an employee of the enter-
prise, the enterprise can hold them responsible for any negative portrayals. Or, the enterprise 
can simply require the employees to not affiliate with the enterprise and, potentially, lose the 
networking and marketing potential.
	
6.	How does the enterprise define “appropriate behavior”? The enterprise needs to understand 
that what is posted online is public and they have no privacy rights in what they put out for 

Social Networking  ◾  77
the world to see. Another note is that anything in cyberspace might be used as grounds to 
discipline an employee, no matter whether the employee wrote it from work or outside of 
work.
The information that should be included in enterprise guidance for social networking is as 
follows:
◾
◾Notice: Make sure that the statements are easily accessible by all employees and that the 
statements are included in orientation, awareness, and employee manuals. The enterprise 
may also want to consider whether employee acknowledgements of the statements are 
required.
◾
◾Competence: Inform employees that they should not use any social media tool unless they 
really understand how it works. Offer social networking awareness training regarding these 
technologies.
◾
◾Purpose: Remind employees that enterprise assets are designed and intended for business, 
not for personal use. Make sure that the enterprise knows that social networking must not 
interfere with their work obligations.
◾
◾Respect: Inform employees that social networking sites are not to be used to harass, threaten, 
malign, defame, or discriminate against anyone within the enterprise, customers, or anyone 
else.
◾
◾Employment decisions: Include counsel to determine what steps the enterprise may legally 
take to obtain information from social networking sites as part of hiring, promotion, and 
other employment decisions.
◾
◾Integrity: Remind employees of the enterprise ethics statements.
◾
◾Appropriate content: Remind employees that any electronic communications for work-related 
purposes must maintain and reflect the enterprise’s standards for professionalism.
◾
◾Confidential information: The enterprise must state that employees must comply with all 
company policies covering confidential information and trade secrets.
◾
◾Disclaimers: Remind employees to state in any social media environments that what they 
write is their own opinion and not that of the enterprise.
◾
◾No right to privacy: Remind employees that they have no right to privacy with respect to any 
information sent, received, created, accessed, obtained, viewed, stored, or otherwise found 
at any time on the enterprise network and assets.
◾
◾Penalties/discipline: The enterprise needs to state that any violations of the policy will be 
subject to discipline, up to and including termination.
◾
◾Modifications: The enterprise should state that they reserve the right to modify, discontinue, 
or replace the policy or any terms of the policy.
◾
◾The enterprise statement should include examples of content that should not be permitted 
for posting, such as:
−
−Comments not topically related to the resource being commented on
−
−Content that promotes, fosters, or perpetuates discrimination against the enterprise
−
−Content that promotes, fosters, or perpetuates discrimination on the basis of race, 
creed, color, age, religion, gender, marital status, status with regard to public assistance, 
national origin, physical or mental disability, or sexual orientation
−
−Profane language or content
−
−Sexual content or links to sexual content
−
−Solicitations of commerce

78  ◾  Information Security Management Handbook
−
−Conduct or encouragement of illegal activity
−
−Information that may tend to compromise the safety or security of the public or public 
systems
−−Content that violates a legal ownership interest of any other party
Social networking sites have business benefits and risks. Yes, social networking sites can be 
blocked through filtering software, but will it help or hurt the enterprise business model? It is up to 
the enterprise to protect their assets and intellectual property through awareness, technology, and 
processes. As with any technology, the enterprise needs to document business requirements and 
perform a risk assessment before implementing or allowing the use of specific technology within 
the enterprise network.

79
Chapter 7
Insider Threat Defense
Sandy Bacik
It is a known fact that insider threats exist for all organizations. Essentially, this threat lies in the 
potential that a trusted staff member may betray their obligations and allegiances to the enterprise 
and conduct sabotage or espionage against them. Many enterprises use the 80–20 rule when look-
ing at threats. In the past, most of the enterprise threats were external. In today’s environment, 
the 80–20 threat has changed to be more of an insider threat. An “insider” is anyone who is or 
who has been authorized to access an enterprise asset. Insider threat activities can fall into several 
general categories:
	
1.	Exceeds given asset (network, system, or data) permissions.
	
2.	Conducts malicious activity against or across enterprise assets (network, system, or data).
	
3.	Provides unapproved access to enterprise assets (network, system, or data).
	
4.	Circumvents security controls or exploits security weaknesses to exceed authorized permit-
ted activity or disguises identity.
	
5.	Nonmaliciously or unintentionally damages assets and resources (network, system, or data) 
by destruction, corruption, denial of access, or disclosure.
Some of the insider threat activities can be composed of the following:
◾
◾Virus-laden CD, USB flash drive, or floppy
◾
◾Administrator lockout
◾
◾Social engineering passwords
◾
◾Smuggling out USB sticks or other mobile media
◾
◾Responsible for “missing” laptops or hardware
◾
◾Targeted acquisition of equipment or data adjustments
◾
◾Using unpatched systems
◾
◾Sabotaging patches
◾
◾False positives on antivirus reports
◾
◾Use of unattended desk areas
◾
◾Keystroke loggers

80  ◾  Information Security Management Handbook
◾
◾Extra copies of backups
◾
◾Wireless access
◾
◾Recording devices, such as cell phones, PDA, or blackberries
◾
◾Suspicious system activities
◾
◾Mislabeling information classifications
◾
◾Copying and pasting between different information classes
To limit the risk of insider threats, an enterprise must base an effective trust relationship with 
a staff member on the following criteria:
	
1.	Establish an appropriate level of trust at the beginning of employment.
	
2.	Create effective compliance monitoring to ensure that the established trust is valid over 
time.
	
3.	Revoke access, in a timely and effective manner.
This includes former staff members who might lack current access but who might have retained 
knowledge of the potential security measures or vulnerabilities. In addition, it includes nonstaff 
individuals with access, such as contractors and consultants. Inside knowledge draws emphasis to 
those mission-critical positions within the enterprise where a staff member’s access, combined with 
their knowledge of the systems and vulnerabilities, creates the greatest potential for harm from an 
insider attack. For instance, despite technical advances, the greatest potential risk factor that still 
remains is the staff member with access to high-level system privileges. This staff member may or 
may not have malicious intent and due to the rapid evolution of increasingly mobile and decentral-
ized control access, he need not be physically collocated with the traditional data center. Thus, this 
risk can exist both internally and externally to the enterprise.
As the boundaries between systems become more open and the perimeters of individual systems 
less easily defined, the critical distinction between an insider and an outsider will be based less on 
geographic location and more on the access and privilege level obtained (appropriately, inadver-
tently, or maliciously) within the system. A good deal of attention within information technology is 
placed on creating a tower wall, a defense perimeter, that will keep malicious outsiders from gaining 
access to transmission control networks. The reality is that the greatest threat to the enterprise envi-
ronment and its information assets is still from an internal vector. This is because, once an external 
actor climbs the “tower wall,” he will essentially become an insider.
Thus, it is believed that the greatest effort to protect systems will need to be placed on protect-
ing the system from those with insider access. This insider can be both accidental and malicious. As 
the use of technology continues to increase, there needs to be a refinement of the concept of insider 
versus outsider. As the devices and the access to critical systems migrate out of highly protected data 
control centers into the field, the boundary that defines where an insider can have access will change 
and potentially cease to exist as a relevant point of division. Thus, the enterprise will need to ensure 
that there are more robust internal controls on insider behavior. This can include the traditional 
approaches to segmenting networks and duties, along with new and alternative approaches.
Unfortunately, insider threat is not limited to fraud. There is also sabotage, negligence, human 
error, and exploitation by outsiders to consider. Once someone is hired by the enterprise, a trust 
relationship is established, which may degrade over time. We know that
◾
◾If we can persuade you to run something, it is not your machine anymore.
◾
◾If someone can alter your operating system (OS), it is not your machine anymore.

Insider Threat Defense  ◾  81
◾
◾If someone can gain physical access, it is not your area anymore.
◾
◾If someone can upload to your machine or Web site, it is not yours anymore.
◾
◾Weak passwords ruin strong security.
◾
◾An environment is as secure as the personnel are trustworthy.
◾
◾Encryption is only as secure as the decryption key.
◾
◾Out-of-date virus scanners are only a bit better than no virus scanner.
◾
◾Anonymity is not practical.
◾
◾Technology is not a panacea.
All these items can contribute to a degradation of trust within the enterprise, possibly enhanc-
ing the risk of insider threat. Any trust can degrade over time as the enterprise’s assets continue 
to grow and become mobile. The enterprise needs to take continued steps to ensure that trust is 
maintained.
An enterprise can take steps to mitigate insider threats, including:
	
1.	Security policy architecture: Documenting information classification requirements, how 
information should be used within the enterprise environment, and the responsibility of 
every staff member in relation to protecting that information is a requirement for any 
enterprise.
	
2.	Classify information and impact analysis: Classify the enterprise’s critical information by 
confidentiality, integrity, and availability with impact ratings, using something like NIST 
SP800-60, for examples. Once the information has been defined and classified, the enter-
prise needs to identify system boundaries that include system, data flow, networks, people, 
hard copies of information, and responsibilities.
	
3.	Identify baseline controls: Establish a baseline control standard for each impact category of 
information, mapping the information to low, moderate, and high controls, using some-
thing like NIST SP800-53, for examples. Established baseline controls can be procedural, 
technological, and physical. Insiders are familiar with internal controls and may find ways 
around single-layer or poorly implemented controls. Some key areas would be
◾
◾Human resources: Human resources personnel should follow detailed new hire and 
termination procedures. The new hire procedures might include criminal background 
investigations, credit checks, and employment verification for all staff (direct hire, 
contractors, temporary staffing, and cleaning crews) and then periodically repeat the 
background checks for people in highly sensitive positions. Require all staff to sign a 
statement demonstrating that they have read and understood the information security 
policies. Ensure that third parties comply with the enterprise’s security requirements 
(e.g., employment and background checks of new personnel). Establish an anonymous 
abuse and fraud reporting mechanism.
◾
◾Security awareness program: All staff should annually attend a comprehensive awareness 
training session on security policies and procedures for all levels in the enterprise.
◾
◾Access control: Implement a need-to-know access control for the routine performance of 
the employees’ duties or their role-based access. All access requests should be formally 
documented and approved by the information or application owner. Configure physical 
building access cards to restrict personnel to the areas and time periods required in the 
performance of their duties, and review on a regular basis the access logs and access and 
ask managers to formally sign off on the privileges of their direct reports. Separation of 
duties should be used as an additional control.

82  ◾  Information Security Management Handbook
◾
◾Administrators: Administrators have complete control over systems and applications; 
therefore, prohibit the use of default administrative accounts to facilitate accountability.
◾
◾Workstations: Laptops and mobile devices can store large amounts of sensitive informa-
tion and are frequent targets of thieves. Issue laptops and mobile devices based upon 
business need and with consideration of the type of information typically processed. 
Restrict workstation/laptop administrative access to the desktop team. Exceptions 
should be limited to personnel with a well-defined need for administrative privileges 
in the performance of their duties, including formal sign-off by their manager. Restrict 
who has access to use USB storage devices.
◾
◾Network security: Configure perimeter devices using security best practices by restricting 
outbound traffic to common services. Use proxies to limit traffic to designated protocols. 
Establish separate rules to limit outbound file transfers to an authorized set of users 
and systems. Restrict accesses between offices to specific systems, ports, and protocols. 
Use network segregation to restrict access to systems hosting sensitive databases. Block 
some of the “bad” applications and services, such as peer-to-peer file-sharing services, 
instant messenger, and services that allow unauthorized external access to the corporate 
network (e.g., GoToMyPC and PCAnywhere).
◾
◾Social engineering: Con artists attempt information extracts from authorized personnel 
or get them to take actions on their behalf. Three ideas to address social engineering 
are: raise awareness of the techniques used by social engineering; establish processes to 
protect sensitive data and valuable assets; and provide a documented escalation path.
◾
◾Backups: As part of the business continuity and disaster recovery testing, perform restore 
tests of critical systems at least annually. Take backups of workstations and laptops to 
provide a record of employee activity. If there is a business requirement, encrypt backup 
tapes and e-vaulting data to keep sensitive information confidential while off site.
◾
◾Audit trails and monitoring: Ensure auditing and log files are configured for each system 
component (e.g., network devices, OSs, applications). The audit trails must be protected 
by file permissions and, possibly, synchronized in real time to a central log server to 
prevent modification. Logs should be reviewed by automated processes with notification 
sent to the appropriate personnel.
	
4.	Implementation: Depth in defense will continue to limit the enterprise risk to insider threat. 
Layer on additional controls in accordance with the confidentiality, integrity, and availabil-
ity information ratings. Any deviation from the baseline controls should require a formal 
exception approved by the information security management and the business owner.
	
5.	Audit: An audit function is required to ensure that sensitive data and valuable assets are 
appropriately safeguarded. The audit function should monitor systems/applications and 
insiders to detect illicit activity. If you have audit trails, you must review audit trails search-
ing for security events and abuse of privileges. Verify directory permissions, payroll controls, 
and accounting system configurations. Validate accesses for transferred staff to ensure that 
accesses are systematically rescinded as the transition occurs. Conduct regular system and 
access assessments.
Documented and tested defense-in-depth or layered controls, separation of duties, and access 
controls are key actions that an enterprise can take to limit the risk of an insider threat. As the 
enterprise knows, the threat from within is very real and trust is a requirement and necessary, but 
it must be controlled and monitored.

83
Chapter 8
Risk Management in Public 
Key Certificate Applications
Alex Golod
Introduction
As public key certificates technology became an enabler for many security controls, it became 
more important to understand all types of risk associated with the use of this technology and its 
processes and components. This understanding is necessary to address and mitigate the risk and 
also to make intelligent design decisions that would afford a desirable performance and availability 
without jeopardizing confidentiality, integrity, and other security requirements. As new technol-
ogy trends, like cloud computing and service-oriented architecture, are maturing, the reliance 
on public key-based security controls, like digital signature and encryption, is increasing, as is 
the risk of misuse or compromise of the certificates. Several recent researches and publications 
(KMNSK, STRV) point at a few very specific vulnerabilities that can be exploited in the certifi-
cate applications.
This chapter is an attempt to analyze the risk surrounding the certificate applications in a little 
broader scope. In this chapter, there are two logical areas. One is dedicated to the risk analysis 
and threat modeling for public key infrastructure (PKI) services, their internal processes, and 
certificate life-cycle management (CLM). The second area relates to the risk analysis and threat 
modeling for some certificate-based applications and security controls. We will see in the conclud-
ing sections of the chapter how the security weakness of a PKI and the certificate services (CS) 
may negatively affect the security controls of the applications that are consuming the certificates 
provided by those services.
The scope of this chapter includes the risk analysis from a technology and processes point of 
view. It does not follow a thorough quantitative or qualitative risk assessment and risk manage-
ment approach prescribed in the published guides, which would have to take into consideration 
the assets values and business impact. However, we do follow the “vulnerability-threat” method-
ology. This risk analysis may be useful as part of a full risk assessment and a risk management 
program, where a value of the potential loss or damage to the specific assets is factored in. This 

84  ◾  Information Security Management Handbook
limited risk analysis may also help focus limited resources on the most critical areas of the public 
key certificates applications implementation.
We will perceive any vulnerability, as defined in the NIST SP800-30 publication (NIST80030), 
as a “… flaw or weakness in system security procedures, design, implementation, or internal con-
trols that could be exercised (accidentally triggered or intentionally exploited) and result in a 
security breach or a violation of the system’s security policy. …” Our risk analysis will include the 
analysis of vulnerabilities associated with the public key CS and the certificate applications pro-
cesses, as well as the underlying technologies and implementation flaws, which could be exploited 
by potential threat sources.
Overview of Certificate Service Processes 
and the Relying Applications
Before analyzing the risk, let us try to identify the typical processes in the CS, the certificate-based 
applications, and the interaction between each other. These processes will be described very briefly 
just to lay a foundation for the following risk analysis. We will assume that the key components 
of a PKI and a CS have already been deployed, they have undergone the required acceptance 
processes like certification and accreditation (C&A), and are operated in accordance with their 
certificate practice statements (CPSs). Thus, the focus is on analyzing the risk associated with the 
consumption of these CS by different categories of applications, including certificate enrollment 
and PKI registration, the certificate life cycle, and the processes of certificate utilization.
PKI Registration, Certificate Enrollment, and 
Certificate Life-cycle Management
The processes, subprocesses, and phases of PKI registration, certificate enrollment, and certificates 
life cycle may be identified as follows:
◾
◾Subscriber’s registration with PKI: This process may vary, depending on the class of the cer-
tificates, the boundaries of the user base, and the assurance level that these certificates are 
expected to support. For low-assurance certificates, the process may include just very basic 
validation of the subscriber’s name for its uniqueness in its domain. For certificates of higher-
level assurance, the process may include additional proofs of identities. Upon successful vali-
dation of the subscriber’s identity, the subscriber’s directory entry may be assigned certificate 
attributes and an entry for this subscriber in the PKI database can be created.
◾
◾Process of generating a public/private key pair: In many cases, this process takes place on the 
subscriber’s platform to ensure that a subscriber’s private key does not leave this platform, 
to support a higher assurance and nonrepudiation. This process may be implemented as an 
integral part of the certificate enrollment process or as a stand-alone utility (openssl, certu-
til, etc.). It may use the underlying libraries (e.g., Java class KeyPairGenerator) and random 
number generators (RNGs) from different sources. In those cases when future utilization 
does not imply nonrepudiation or requires key escrow, the key pair may be generated on the 
PKI CA site. This especially applies to the embedded PKI CAs, which support the certificate 
needs of the infrastructure components. For example, the key pair generating facility may 
reside on the management center of the firewall or the applications gateway and the keys 
would be distributed to the managed appliances in a secure fashion.

Risk Management in Public Key Certificate Applications  ◾  85
◾
◾Process of generating a certificate signing request (CSR): This process chiefly includes binding 
the generated public key with the subscriber’s name and the certificate attributes. Similar to 
the key pair generation, this process may also be implemented as an integral part of the certif-
icate enrollment process or as a stand-alone utility. The most important point here is to make 
the subscriber provide a proof of possession of the counterpart private key. For the signing of 
dual-purpose certificates, this proof is simply provided by self-signing, or by the subscriber’s 
digital signature, which can be verified by the registration authority (RA) or the CA.
◾◾Submitting a certificate request to the CA: The CSR can be submitted to the RA/CA via the 
network (e.g., HTTP or SMTP) or out of band. The implementation of messaging between the 
subscribers, the RA, and the CA depends on the vendor and the product. Although the CSR 
message does not contain a subscriber’s private key, its integrity and authenticity are critical. In 
cases when subscribers’ private keys (usually, it is a case for an encryption certificate) must be 
stored in the CA database, escrowed, or archived, the keys are transmitted in the encrypted mes-
sage. A full description of all the messages between the subscribers and the RA and between the 
RA and the CA can be found in the IETF publication RFC 4210 (RFC 4210).
◾
◾Certificate issuance and publication
−
−Messages between the subscribers, the RA, and the CA usually include a body in ASN.1 
form, which is parsed and analyzed by the receiving side. It includes parsing and verify-
ing the subscriber’s name, the public key, and the requested certificate’s attributes and 
message authentication code.
−
−When the requested X.509 certificate is generated according to its template, the issuing 
CA information such as the certificate revocation list (CRL) distribution point, the author-
ity key identifier, and the digest are added. Finally, the certificate is signed by the CA.
−
−The certificate is added to the subscriber’s data entry in the PKI database and is pub-
lished in the directory as a subscriber’s object certificate attribute.
◾
◾Certificate revocation and validity status support: This process, in response to business events, 
publishes the certificate revocation status in the CRL. The status is also made available to an 
online certificate status protocol (OCSP) server, which responds to the relying parties’ real-
time client requests. The frequency and availability of up-to-date certificate status informa-
tion depend on policies and implementation.
◾
◾Certificate renewal: This process may be initiated by a subscriber or automatically by the PKI 
when a certificate approaches the end of its validity. This process may allow reusing the old 
certificate’s keys or may require regenerating the key pair. In the latter case, the renewal is 
essentially a reissuing of a new certificate that should replace the old one.
Public Key Applications and Certificates Utilization
The relying parties and subscribers may implement a number of standard and application-specific 
protocols that utilize public key certificates and are very specific about certificate requirements, 
their attributes, extensions, life cycle, and utilization. The following are some of the protocols and 
applications that support specific security controls, which help the business applications meet their 
security requirements and objectives.
◾
◾Secure application tunnels that implement transport layer security (TLS)/Secure Sockets 
Layer (SSL) for HTTP, lightweight directory access protocol (LDAP), File Transfer Protocol 
(FTP), and SSL virtual private network (VPN) applications. The certificates enable client 

86  ◾  Information Security Management Handbook
and server authentication and negotiation of the symmetric session (ephemeral) key for data 
in transit encryption (tunneling).
◾
◾Secure messaging (e.g., Secure/Multipurpose Internet Mail Extensions [S/MIME] and 
Simple Object Access Protocol [SOAP]), which provides message signing and encryption for 
e-mail applications, such as the Exchange/Outlook or SOAP messaging, over HTTP appli-
cations, and others. Senders encrypt their messages (or part of the messages) with symmetric 
keys and use the recipients’ certificates to encrypt that symmetric key. Therefore, only the 
recipients in possession of the certificates’ counterpart private keys will be able to decrypt the 
message. The sender also uses his private key for message signing. Therefore, a recipient can 
verify the sender’s digital signature with the sender’s public certificate.
◾
◾Document and code signing applications would utilize a certificate and counterpart private 
key to generate a digital signature for data digest in a way similar way to what was described 
above for secure message signing.
◾
◾File and folder encryption: After encrypting a file or folder with a generated symmetric file 
encryption key (FEK), a user encrypts the FEK with his (and optionally with other selected 
users’) and the data recovery agent’s (DRA) public key. The user and optionally other desig-
nated users (whose certificates have been used for encryption), as well as the DRA, use their 
private keys to decrypt the encrypted file.
◾◾Local and remote access control with strong authentication: Access control with certificates may be 
implemented as a separate application security control or as part of a suite. Both strong authenti-
cation and permission control are part of the access control, which are supported by certificates.
The implementers may use standard or individual custom processes for keys and certificates 
management, utilization, validation, etc. However, most likely, the processes will include some or 
all of the following:
◾
◾Obtaining another party’s public key certificate: A relying party may receive another party’s 
certificate in several ways. For data encryption or encrypted communication purposes, the 
encryption certificate can be obtained from a receiver’s entry in an LDAP directory, from 
a receiver’s e-mail, or from other sources. For digitally signed messages, a sender usually 
attaches his certificate to the signed message. Peers of TLS/SSL applications would exchange 
the certificates in the TLS handshake protocol exchange (RFC 2246). The trusted CA’s 
certificates may be preinstalled on the clients’ software or distributed via trusted sources. 
For example, all browsers have VeriSign and other major commercial CA’s certificates prein-
stalled to support SSL/TLS applications, which have VeriSign certificates installed on their 
servers. Internal PKI CA’s certificates may be added to the organization’s standard build or 
distributed via software management processes.
◾
◾Certificate validation: This process involves several steps, including verification of the CA 
signature, validity dates, attributes and extensions, and the subject name. The relying party 
application may also be forced to validate the counterpart certificates’ revocation status by 
checking the certificates in question against their CRL distribution points or by challenging 
the OCSP server(s).
◾
◾Parsing and mapping a certificate’s contents: A relying party would parse a certificate when 
it needs to validate it (as described above) and also extract particular attributes needed for 
mapping for its application. The relying party’s application is using its ASN.1 parser and an 
X.509 template complying with the RFC 3647 standard (RFC 3647) with the expectation 
that the parsed certificate was generated in compliance with the mentioned standard.

Risk Management in Public Key Certificate Applications  ◾  87
◾
◾Encryption and decryption: A sender encrypts data and messages with the recipients’ encryp-
tion public keys (in most cases, distributed as encryption certificates) and then the recipients 
decrypt that data with the counterpart private keys. As mentioned earlier, in many applica-
tions the asymmetrically encrypted data is a symmetric session key or a bulk data encryption 
key, and the recipient’s certificate can be obtained from different sources, such as the LDAP 
server or the recipient’s e-mail.
◾
◾Signing and verifying the signature: Producing a signature (RFC 3126) may also include the 
process of attaching the signer’s certificate chain, so that the relying party would easily verify 
the signature.
Vulnerability in each of the mentioned processes and in their underlying technologies may 
be intentionally or unintentionally exploited. There is always some threat of internal and external 
origin, application flaw exploits, as well as human errors. For example, if a malicious user B can 
register as a subscriber A, then B can forge and submit a CSR on behalf of user A. Consequently, 
a third party, C, will be deceived when exchanging transactions with B instead of the legitimate 
user A. The scenarios when this type of situation leads to wrongly issued or wrongly validated 
certificates, as well as other incidents, will be analyzed in the following sections dedicated to risk 
analysis.
Risk Analysis for CS and Certificate Applications
Even when an application itself is generating a private/public key pair and issuing a self-signed 
certificate for its own use locally or sends it to other parties, that application is often using its 
local rudimentary PKI. More advanced embedded PKI, dedicated to support one or a family of 
products of the same vendor, may use certificate- and key-dedicated repositories and management 
mechanisms. The larger applications may leverage external commercial or in-house leveraged PKI 
to obtain, utilize, and support their public key certificates as an important part of their security 
controls. The processes of certificate enrollment and life-cycle management with their subpro-
cesses and technologies have their own vulnerabilities that may be exposed. The PKI with its assets 
and resources may be a threat target, so performing an overall PKI threat modeling and risk analy-
sis, at least on a limited scale, should be in order. All PKI interfaces that are available for legitimate 
subscribers and relying parties, as well as communication channels, represent the entry points that 
can allow the threats to exploit the PKI vulnerabilities. The scope of our analysis does not include 
vulnerabilities related to physical controls. Figure 8.1 presents a consolidated data flow diagram.
The suggested risk analysis will focus on collaboration between the CS, the subscribers, and 
the relying parties, as well as the ability of the serviced certificates to meet the security control 
requirements of the consuming applications. In the following two subsections, we will cover the 
certificate-based applications risk analysis and the CS risk analysis (including certificate enroll-
ment and certificate life cycle).
CS Risk Analysis
For the sake of clarity, in this section, the scope of the CS and the related threats will be limited to 
certificate enrollment and CLM, which include certificate renewal, recovery, and revocation with 
status publication. The threats and their actions and exploited vulnerabilities are presented in Table 8.1. 
Diagrams of some of the threats associated with external actors are presented in Figure 8.2.

88  ◾  Information Security Management Handbook
PKI Manager
Certiﬁcates
management
PKI Subscribers
Registration
Certiﬁcate
signing request
(CSR)
Certiﬁcate
issuing
Key pair
generation
CSR generation
Key
management
Certiﬁcate
signing
Certiﬁcate
management
End users,
servers,
processes,
services.
Registration
approval
Certiﬁcate
signing
approval
Certiﬁcate 
services
PKI CA/RA
Renewal
request
Revocation
request
Certiﬁcates
revocation status
update
Publication
services
Counter parts
certiﬁcates
retrieval
PKI CA’s
certiﬁcates
retrieval
Certiﬁcate status
validation
PKI relying
parties
End users,
servers,
processes,
services.
Certiﬁcates and
certiﬁcates
revocation
status
(CRL or OCSP)
PKI CA’s
certiﬁcates
publication
Subscribers
certiﬁcates
publication
Figure 8.1  Certificate services, subscribers, and relying parties.

Risk Management in Public Key Certificate Applications  ◾  89
Table 8.1  Certificate Services Threats and Vulnerabilities
No.
Process/control
Threats
Vulnerabilities and Threat Action
1
PKI registration and 
certificate request
1.1
Subscriber registers 
after submitting the 
proof of identity
Adversary tries to register or 
login to the PKI RA on behalf of 
or obtain a certificate issued for 
another subject
A PKI registration process or its supporting technologies may 
have weaknesses in verifying a new subscriber’s identity or 
authenticating a returning subscriber
A subject “X,” which impersonates and authenticates with the PKI 
registration process as a subject “Y,” would submit its own public 
key and certificate signing request (CSR) as a subject “Y.” As a 
result, “X” will receive a properly signed certificate that matches 
the private key of “X,” so “X” can sign and authenticate on behalf 
of “Y” and decrypt data encrypted for “Y”
•	 There is a vulnerability in the insufficient level of a 
subscriber’s identity verification or flawed authentication 
process (COMODO)
•	 X.509 subject names can be spoofed by strings and 
characters manipulation in many ways (e.g., Homograph 
attack, LayerCake)
1.2
Key pair generation
An adversary obtains or guesses a 
legitimate subject’s private and 
public keys
A private/public key pair generation process or the RNG on the 
subscriber’s platform may have a flaw
•	 An attacker may complete a successful cryptographic attack 
on a private key, based on the public key available in a public 
certificate
•	 An attacker may intercept a private key in the transaction 
from a CA or RA platform to a subscriber’s platform. This 
scenario is applicable when the key pair is generated outside 
the subscriber’s platform
(continued)

90  ◾  Information Security Management Handbook
Table 8.1 (Continued)  Certificate Services Threats and Vulnerabilities
No.
Process/control
Threats
Vulnerabilities and threat action
1.3
CSR and POP 
generation
A CA accepts a forged CSR as 
authentic. An adversary, acting on 
behalf of a legitimate subscriber, 
submits a forged CSR to make the 
CA sign a certificate with a public 
key different from what the 
legitimate subscriber and owner 
of the private key would request
A PKI registration process may have a weakness in verifying the 
subscriber’s proof of possession of the private key, which is a 
counterpart of the public key in the CSR. It may allow a 
fraudulent subscriber to deceive a CA and make the CA issue a 
certificate with wrong attributes, not corresponding to the 
attributes and the public key in the CSR of the legitimate 
subscriber. It may happen when a key pair and the CSR are 
generated on the nonsubscriber’s platform (LayerCake)
1.4
Sending a CSR 
message to the CA
2
Parsing a certificate 
request and issuing 
the certificate
2.1
Parsing a certificate 
request
A subscriber intentionally or 
unintentionally may send a 
malformatted certificate request 
message which cannot be 
correctly diagnosed or 
interpreted by the PKI CA ASN.1 
interpreter. As a result, the 
elevated privilege commands can 
be executed on the CA or a 
certificate with unauthorized 
attributes and names may be 
issued
•	 An ASN.1 decoder, which is part of PKI CA/RA, may be unable 
to properly handle a malformatted PKCS10 (RFC 2986) 
certificate request, which contains in its ASN.1 body:
•	 Unrecognizable or impossible to parse object identifiers 
(OID), which may cause the decoder malfunction
•	 String attributes, constructed by the requester with 
special and escape characters, which make the decoder 
produce ambiguous results and make the CA issue 
certificates with unauthorized names and attributes
•	 If a CA ASN.1 parser does not perform a comprehensive 
string validation of the certificate subject name before 
inserting it into the CA database, it may allow a SQL injection 
attack on the PKI DB (KMNSK)

Risk Management in Public Key Certificate Applications  ◾  91
2.2
Issuing a certificate
A rogue CA, capable of issuing 
“trusted certificates,” may be 
fabricated
•	 A flawed PKI/CA management may allow stealing a CA’s 
signing key and installing it on a rogue device to 
impersonate a legitimate CA
•	 There may be fabrication of the “trusted” certificate chain by 
forging an intermediate CA’s certificate, “issued” by a trusted 
root. It may occur because of a CA’s weak secure digest 
(STRV)
3
Certificate revocation
3.1
Revocation request 
processing
A broken administrative process 
or malformatted revocation 
request message may prevent 
timely revocation or the message 
cannot be correctly diagnosed or 
interpreted
•	 A parser of certificate service requests (CMS), which is a part 
of the PKI, may be unable to handle a revocation request, 
and the CA will not be able to update and sign the new CRL
3.2
Revocation status 
update
A broken communication without 
provisions for high availability 
may prevent timely revocation 
status publication
•	 Transmission of an updated CRL or certificate revocation 
status message, intentionally or unintentionally, may be 
disrupted. As a result, the relying parties will either have false 
certificate status information or will not be able to process 
the certificate-relying operations
4
Trusted certificates 
distribution and 
publication
There may be a broken 
publication process or a 
malicious attack on the relying 
parties’ clients
•	 There may be unsanctioned publication of the PKI CA’s 
certificates on the CDP servers
•	 Unsanctioned or mistaken updates of the relying party’s 
trusted certificates store may install malicious certificates 
and update the trusted roots or intermediate certificates list
(continued)

92  ◾  Information Security Management Handbook
Table 8.1 (Continued)  Certificate Services Threats and Vulnerabilities
No.
Process/control
Threats
Vulnerabilities and threat action
5
Certificate validation
5.1
Parsing the certificate 
attributes and verifying 
the chain to the 
trusted root
An adversary “subscriber” would 
forge a leaf certificate whose 
chain of trust looks like it is 
rooted to a publicly trusted root 
CA. Therefore, a relying party 
may mistakenly trust that leaf 
certificate
A relying party’s trusted roots or 
intermediate certificates may 
become unavailable
Contrary, a nontrusted certificate 
may be fraudulently implanted 
into the list of trusted certificates 
on the relying party’s platform
•	 As described in (STRV), there is a known exploit of the 
collision weakness in the MD5 cryptographic hash algorithm. 
A rogue issuing CA can be installed and configured in such a 
way that its certificate’s digital signature will be identical to a 
signature of a leaf certificate, which was legitimately 
requested and obtained from a publicly trusted CA that 
issues certificates with MD5 signatures. Because the rogue 
issuing CA has a trusted chain root, all the certificates issued 
by that CA will be trusted by the browsers. Although this 
weakness is known, those CA’s certificates cannot be swiftly 
removed from the field because of backward compatibility 
issues
•	 Some implementations of the PKI clients (relying parties) are 
not capable of understanding a certificate chain, so they can 
trust a leaf certificate only if that certificate’s issuing CA 
certificate is in the trusted certificates list of this device
•	 By contrast, any malicious or negligent installation of a 
questionable CA’s certificate as a trusted root, may lead to a 
very serious security risk, allowing unconditional connection 
to not trusted sites
5.2
Certificate status 
validation
Intentional or unintentional 
disabling of the certificate 
validation channel
A relying party cannot obtain the status of a certificate in 
question because the services providing CRL OCSP information 
are not available

Risk Management in Public Key Certificate Applications  ◾  93
Certificate Applications Risk Analysis
The most common public key certificate applications have been described in the section Public 
Key Applications and Certificates Utilization. Any vulnerability in certificate enrollment or in the 
processes supporting the certificates’ life cycle may potentially translate into vulnerability of the 
relying applications and controls that utilize those certificates. Consequently, a particular threat 
source may successfully exercise a particular vulnerability of the public key certificate-based secu-
rity control, which would result in an application security breach.
These threats and their actions and exploited vulnerabilities are presented in Table 8.2. The 
diagrams of some of the TLS applications threats associated with external actors are presented in 
Figure 8.3.
The certificate applications and security controls reviewed above, as well as other applications 
in general, have their own vulnerabilities that can be exploited. Risk, associated with those vul-
nerabilities, can be analyzed by traditional methods, such as static code analysis, scanning, and 
penetration testing.
However, we have to take into consideration and assess and mitigate the risk specifically 
related to certificate use and all supporting processes. Although PKI may be outside the applica-
tion boundary, any weakness or flaw in it or its processes may affect both the subscribers and the 
relying parties as consumers of the CS.
Many vulnerabilities, which have been identified in the certificate-based applications in 
Table 8.2, are tightly related to the vulnerabilities in the PKI and the CS, which provide for 
those applications.
How the Applications Inherit the Risk
As we can see, the certificate-based applications and the security controls largely inherit the risk 
from the technologies and processes of certificate enrollment and life-cycle management imple-
mented in the CS. There are several avenues for this undesirable inheritance.
THREAT: An adversary
registers with PKI on
behalf of a legitimate
subscriber and obtains a
certiﬁcate issued by
a trusted CA
THREAT: An adversary
obtains private and public
keys of a legitimate
subscriber during PKI
registration of that
legitimate subscriber
An adversary steals a
private/public key pair
from a platform which
generates CSR
An adversary submits a
fake proof of identity
and registers
An adversary submits
a forged CSR
Te PKI RA or
CA software
parsing CSR, is
unable to
correctly verify
the attributes
Te registration
process is unable
to detect a
forged proof of
possession of
private keys
An weak access
control on a
platform which
generates CSR
A weak key
generation
process on a
platform which
generates the
private/public
key pair
A weak process
of subsriber’s
identity
veriﬁcation
A spoofed
X.509 subject
name passes
undetected
Figure 8.2  PKI registration threat modeling.

94  ◾  Information Security Management Handbook
Table 8.2  Certificate Applications Threats and Vulnerabilities
Applications/
Security Control
Threats
Vulnerability and Threat Action
Certificate Process
TLS/SSL 
applications
False-negative validation of 
the certificate chain
A peer (client) is unable to parse a certificate chain of 
another peer (server) because it does not have a 
trusted root certificate in its certificates store
•	 Trusted certificates 
distribution and 
publication
•	 Certificate validation
False-positive validation of 
the certificate chain
A malicious peer (server) submits a fabricated/forged 
certificate, which is rooting to a trusted root (STRV), to 
another peer (client) for authentication
•	 Certificate issuing
•	 Certificate validation
An attacker modifies or convinces an administrative 
user of the relying party to modify the trusted 
certificates list on the relying party’s platforms
•	 Trusted certificates 
distribution and 
publication
•	 Certificate validation
False-negative validation of 
the certificate revocation 
status
CRL/OCSP service is unavailable for a validating relying 
party because of misconfiguration or broken links
•	 Certificate validation
•	 Revocation status update
False-positive validation of 
the certificate revocation 
status
Design or operation process flaws allow a peer to skip 
validation of certification revocation status where it is 
required. A human error or hacking may cause this
•	 Certificate validation
Impersonation of the user 
in possession of the 
legitimate certificate and its 
private key
	 1.	 A compromised enrollment or CLM process allows 
an unauthorized entity to obtain a certificate for an 
authorized entity and its matching private key
	 2.	 A compromised/stolen private key with a matching 
certificate is installed on a rogue device
•	 PKI registration
•	 Certificate and key 
life-cycle management

Risk Management in Public Key Certificate Applications  ◾  95
A TLS session negotiated 
symmetric key becomes 
available to the adversary 
sniffing the network
	 1.	 A weak asymmetric crypto used in the TLS 
certificates, allows it to crack a session key 
negotiation phase
	 2.	 An attacker obtains a private key of a TLS session 
pear
•	 Issuing of certificates
•	 Key and certificates 
management
File or message 
encryption
An intended group of users 
(subscribers) cannot 
decrypt an encrypted file, 
message, or part of a 
message while the 
unintended group of users 
can
Any flaw in the infrastructure or in the processes of 
certificate issuing and publication may allow use of the 
file encryption certificates of unintended users instead 
of the designated group certificates, e.g.:
	 1.	 An enterprise certificates publication facility 
(Directory, DB, or IdM) does not provide a reliable 
binding between a user entry and its certificate 
attribute
	 2.	 A flawed certificate distribution process
•	 Issuing of certificates
•	 Trusted certificates 
distribution and 
publication
An encrypted file, message, 
or part of the message 
cannot be decrypted by a 
legitimate user or recovery 
agent
A private key(s) that is a counterpart of the 
certificate(s) used for encryption, is lost
A system can also lose a recovery agent’s certificate
•	 Key and certificates 
management
Documents, 
code, or 
message signing
An unauthorized party 
registers with the PKI or 
obtains a private signing key
	 1.	 It is a flawed process
	 2.	 A signing private key is stolen from a legitimate 
subscriber
•	 PKI registration
•	 Certificate and key 
life-cycle management
A relying party is unable to 
verify a signature of a 
legitimate subscriber who 
signed a document, code, 
or message
A signer’s and verifier’s software is incompliant and 
incompatible on the signer’s or verifier’s side
A relying party is unable to verify the full certificate chain 
of the signer because of missing trusted certificates
The signer’s X.509 certificate includes the attributes or 
extensions that a relying party cannot parse
•	 Trusted certificates 
distribution and 
publication
•	 Certificate validation
(continued)

96  ◾  Information Security Management Handbook
Table 8.2 (Continued)  Certificate Applications Threats and Vulnerabilities
Applications/
Security Control
Threats
Vulnerability and Threat Action
Certificate Process
A relying party is unable to 
verify the signing certificate 
revocation status
The signing certificate’s CRL or OCSP services are not 
available
•	 Certificate validation
Certification-
based strong 
authentication
An unauthorized entity in 
possession of a smart card 
with a pin or in possession 
of a certificate and its 
private key may 
authenticate as a legitimate 
client
	 1.	 A compromised PKI registration or certificate and 
key management processes allow an unauthorized 
entity to obtain credentials
	 2.	 A compromised/stolen smart card with its PIN or a 
certificate private key
•	 Smart card management 
processes
•	 See all related to TLS/SSL 
applications
Authentication of a 
legitimate user in 
possession of its smart card 
and PIN cannot be 
completed because of a 
broken authentication 
process on the back end
Back end (EAP authenticator or SSP Kerberos 
integration) cannot complete the certificate 
authentication for multiple reasons
•	 See all related to TLS/SSL 
applications

Risk Management in Public Key Certificate Applications  ◾  97
◾
◾The latest achievements in cryptographic research and increased inexpensive computing 
power make the breaking of digital signatures easier. It allows the perpetrators to produce 
the certificates rooted to the publicly trusted CAs and to install them on rogue impersonat-
ing devices. The relying parties may be easily deceived unless they implement a very thor-
ough certificate chain validation process.
◾
◾New techniques implemented in the advanced persistent threats (APTs) against govern-
ment, commercial, and private (internal) certificate authorities (PKI CA), are capable of cir-
cumventing the PKI RA subscribers’ authentication, certificate enrollment, and certificate 
life-cycle processes. Thus, the relying parties will trust the certificates inadvertently issued 
to fraudulent subscribers.
◾
◾A poorly implemented process of certificate enrollment or life-cycle management may allow 
an attacker to obtain a private key associated with a trusted certificate, thereby allowing the 
attacker to impersonate a trusted party. It is likely to happen in private or integrated internal 
PKIs.
◾
◾Many attacks on certificate-enabled applications and controls may be successful only in con-
cert with successful attacks on and compromise of DNS servers. An attacker would replace a 
DNS entry on the server with a compromised certificate; therefore, a deceived relying party 
client will be pointed to the impersonating server with a fabricated certificate. Because that 
forged certificate’s chain is routed to the trusted CA certificate, the trusted connection will 
be established.
To minimize the impact of the inherited risks, many mitigation measures can be used, on both 
the subscribers’ and the relying parties’ sides.
THREAT: An adversary
impersonates a
legitimate party in
TLS session
authentication
An adversary
(malicious server) presents
a forged certiﬁcate chain,
rooted to a
trusted root CA
A weak PKI
registration or
life-cycle
management of
the TLS server’s
certiﬁcates
Acceptance of
the chains with
weak CA signing
algorithm allows
to validate a forged
certiﬁcate chain
A weakness on
the relying party’s
conﬁguration or
processes allow
unauthorized
modiﬁcation of
TCL
A weakness or
absence of the
certiﬁcate
validation
process by a
relying party
An attacker modiﬁes or
convinces a relying party to
modify the certiﬁcates
trusted list
A relying party is
mistakenly accepts a
compromised and revoked
certiﬁcate of another party
as a valid one
Figure 8.3  TLS applications threat modeling.

98  ◾  Information Security Management Handbook
◾
◾The selection of the certificate providers and certificate requirements should be based 
on the application security requirements. An application security risk assessment should 
include the risk associated with the certificate-based security controls of that application. 
Only a CA that can provide an adequate life-cycle management of the certificate chain 
complying with the latest NIST cryptographic recommendations should be used. All 
new vulnerabilities in the embedded certificate solutions (e.g., open source libraries like 
OpenSSL) or in the external providers’ solutions (e.g., weakness of MD5 signature used in 
some publicly trusted root certificates) should be assessed and addressed.
◾
◾Consumers of the CS (both subscribers and relying parties) need to familiarize themselves 
with certificate policies. Unawareness of certificate processes and the trustworthiness of the 
issuing PKI may degrade rather than upgrade the application security level.
◾
◾The methods of certificate validation supported by the certificate’s providers, e.g., validation 
of the certificate revocation status (over HTTP/LDAP CRL access or OCSP) and extended 
validation (EV), should be used, even if supporting these features is adding some cost.
◾
◾Consumers of the CS should make provisions for cases of certificate compromise as part 
of their incident and emergency response planning. For example, the vendors of Internet 
browser software may implement short- and medium-term response plans. They would 
include a simple notification of the users about a mistaken issuance of fraudulent cer-
tificates by the trusted CA and add those certificates to the untrusted certificates’ list 
(COMODOMOZ).
Conclusions
Public key certificate technology, as any other, has never been an absolutely bulletproofed enabler 
for security controls. Other traditionally very secure technologies, like a one-time password (OTP), 
can also be the targets for successful attacks (RSACOMP). For example, a compromised OTP seed 
file may drastically weaken an expensive Two Factor authentication control. The security breaches 
on certificate-enabled applications and controls are the results of implementation and operations 
flaws, so some prophecies about the upcoming demise of the PKI may be a little premature.
As with all other technologies, only the right processes and the timely implementation of 
advanced cryptography may keep the certificate-based security controls at an adequate level. The 
concentration on these problems is represented in the series of NIST and other publications. Some 
publications are focused on the certificate and key management and selection of cryptographic 
algorithms and key lengths for the new systems and upgrades (NIST800-57-1), and would be 
helpful for PKI implementations. Other publications (NIST800-57-3) are more specific and rec-
ommend application-specific keys and certificates guidance. These recommendations assume a 
realistic prediction of the cryptographic strength required to withstand the attacks today and in 
the predictable future.
References
Nystrom, M. and Kaliski, B. (RFC 2986) PKCS10: Certification request syntax specification version 1.7. 
IETF 2000. http://tools.ietf.org/html/rfc2986.
Higgins, K. J. (KMNSK) Black hat: PKI hack demonstrates flaws in digital certificate technology. Researcher 
Dan Kaminsky illuminates flaws in X.509 authentication. Darkreading 2009. http://www.darkreading.
com/security/vulnerabilities/218900008/index.html.

Risk Management in Public Key Certificate Applications  ◾  99
(NIST80030) NIST Special Publication 800-30. Risk Management Guide for Information Technology 
Systems. July 2002.
Kaminsky, D., Sassaman, L., and Patterson, M. (LayerCake) PKI Layer cake: New collision attacks against the 
global X.509 CA infrastructure. http://www.ioactive.com/pdfs/PKILayerCake.pdf.
Adams, C., Farrell, S., Kause, T., and Mononen, T. (RFC 4210) Internet X.509 public key infrastructure 
certificate management protocol (CMP). PKIX-CMP http://tools.ietf.org/html/rfc4210.
Dierks, T. and Allen, C. (RFC 2246) The TLS protocol version 1.0. http://tools.ietf.org/html/rfc2246.
Chokhani, S., Ford, W., Sabett, R., Merrill, C., and Wu, S. (RFC 3647) Internet X.509 public key infrastruc-
ture certificate policy and certification practices framework. http://tools.ietf.org/html/rfc3647.
Pinkas, D., Ross, J., and Pope, N. (RFC 3126) Electronic signature formats for long term electronic signa-
tures. http://tools.ietf.org/html/rfc3126.
(COMODO) Comodo report of incident on 15-MAR-2011. http://www.comodo.com/Comodo-Fraud-
Incident-2011-03-23.html.
Gabrilovich, E. and Gontmakher, A. (Homograph attack) The homograph attack. Communications of the 
ACM 45(2): 128, 2002. http://www.cs.technion.ac.il/~gabr/papers/homograph_full.pdf.
Samson, T. (RSACOMP) EMC: RSA SecurID info swiped via sophisticated hack attack. InfoWorld, March 
2011. http://www.infoworld.com/d/security/emc-rsa-securid-info-swiped-sophisticated-hack-attack-917.
Keizer, G. (COMODOMOZ) Mozilla regrets keeping quiet on SSL certificate theft. Computer World, 
March 2011. http://www.computerworld.com/s/article/9215077/Mozilla_regrets_keeping_quiet_on_ 
SSL_certificate_theft?taxonomyId=82.
Stevens, M., Sotirov, A., Appelbaum, J., Lenstra, A., Molnar, D., Osvik, D., and de Weger, B. (STRV) Short 
chosen-prefix collisions for MD5 and the creation of a rogue CA certificate. Crypto 2009. http://eprint.
iacr.org/2009/.


101
Chapter 9
Server Virtualization: 
Information Security 
Considerations
Thomas A. Johnson
Overview
Still considered an ‘emergent technology,’ virtualization has been in use since the mid-1960s 
(CDW 2010), and is well established in the mainframe and minicomputer world as a common 
way of sharing resources (ISACA 2010). The adoption of virtualization and the way the industry 
is currently using it is making the term popular, much like Windows, which has become a house-
hold name today. Until recently, there was no software package available, much less a need for 
one, to establish true resource sharing on servers common to a data center. Now that virtualiza-
tion has been proliferating throughout data centers, companies have been able to take advantage 
of the technology on Intel-based servers, virtualizing everything from in-house utility servers to 
enterprise content management systems. With advancements in virtualization technology moving 
to the workstation, disk, and CPU, virtualization has been revolutionizing data centers, allowing 
companies to realize major wins, such as cost savings and streamlined recovery plans.
Virtualization technology can encompass various technologies, doing amazing things with 
disk and network communications. Many virtualization concepts are emerging in the market-
place, namely, workstation and disk virtualization. While these exciting technologies can take 
virtualization to the next level, expanding on the concept to cover all the popular and emerging 
practices would fill a book. Because of the heightened exposure that this technology has gained 
over other virtualization technologies, as well as its widespread adoption, our focus will be on the 
issues surrounding server virtualization.
What exactly is virtualization? “Virtualization is simply the logical separation of the request 
for some service from the physical resources that actually provide that service” (von Hagen, 2008). 
Putting it another way, “you can think of virtualization as inserting another layer of encapsula-
tion so that multiple operating systems can operate on a single piece of hardware” (Golden, 2008). 

102  ◾  Information Security Management Handbook
If you are still confused, you are not alone. It is difficult to sum up the technology in one or two 
sentences, but it can be described as software or technology that allows multiple systems to use the 
same resources, such as computer processors or disks, while tricking the system into thinking that 
these resources are exclusively theirs, when in reality they are shared.
The following diagram logically shows how server virtualization works. The illustration 
shows four servers running on one machine. Instances are shown of each server, including the 
operating system and its associated applications, operating in its own ecosystem—accessing 
physical hardware. The hypervisor brokers the requests for the CPU, memory, disk, and network 
resources and creates an illusion for the virtual server to which the resources are dedicated (Rule 
and Dittner, 2007).
Applications
Applications
Applications
Applications
OS
OS
Physical host hardware
CPU, Memory, Disk, Network
OS
OS
As the illustration shows, because four machines are able to run on a single piece of hardware, 
there are cost savings associated with virtualization. Both hard and soft costs will be covered here, 
as well as the underlying management, audit, and security issues. As with other innovative tech-
nologies, care should be taken while evaluating the lofty claims made by the vendors. Although 
cost savings and improved business agility are certainly proven with virtualization, it is often 
the security and management of these systems that seem to be lacking. There are many security 
and management issues surrounding virtualization and challenges that information security staff 
and auditors face when approaching this new technology, prompting more collaboration between 
these areas (ISACA, 2010). “It is critical for all parties involved to understand the business process 
changes that occur as a result of migrating to a virtualized environment” (ISACA, 2010).
Benefits of Server Virtualization
In a cost-conscious environment where businesses are constantly trying to reduce spending, many 
are turning to the benefits of virtualization. The promise of “lower [total cost of ownership], 
increased efficiency, positive impacts to sustainable IT plans and increased agility” is what server 
virtualization can bring to an organization and they are a major catalyst to getting virtualization 
projects approved (ISACA, 2010).
The fact that an organization could eliminate half of its servers from its data center and gain 
additional functionality would have sounded absurd as little as 5 years ago. Now, companies are 
scrambling to get traction on virtualization projects and counting the savings by identifying mul-
tiple servers that are candidates for virtualization and moving them into a virtual environment. 
Table 9.1 shows a simple example of how consolidating servers into a single machine can generate 
significant cost savings (Rule and Dittner, 2007).
Reducing the acquisition cost of equipment is not the only way that cost savings are gained by 
virtualization. By having fewer servers, the data center power consumption goes down dramati-
cally. Most data centers charge by the kilowatt-hour, so an annual savings is practically guaranteed 

Server Virtualization: Information Security Considerations  ◾  103
(Fogarty, 2009). Soft costs, such as time-to-implement and personnel costs associated with proj-
ects, are also part of the cost savings. When a new initiative comes from management, there is no 
longer lead time for hardware to arrive, be racked, installed, and configured—it can all be done 
remotely, consistently, and quickly, dramatically decreasing the time it takes to provision a new 
system. Decreasing the time that engineers spend on provisioning hardware translates to cost 
savings.
Imagine you can take a set of applications and move them over to the disaster recovery site in 
a matter of minutes. This seems too good to be true, but it is true, and many companies are tak-
ing advantage of these abilities to enhance their business continuity plans and reduce the time to 
recover. Virtualized systems in the recovery center are intelligent and can handle load balancing 
and advanced disaster scenarios. This provides the company with “previously unavailable options 
for flexibly scaling for load and dynamically shifting and aligning resources to respond to business 
continuity and disaster events” (ISACA, 2010).
Testing and development are two areas that are often neglected by smaller IT departments. The 
equipment and procedures for migrating from test to production cost time and money. Today, test 
environments can be built from images of real production environments so that patches and new 
applications can be tested. A tested application can then be rolled out to a production environment 
and, if there are issues, can be rolled back with the snapshotting capabilities of virtualization.
There are a number of options available when evaluating virtualization platforms and proper 
due diligence should be performed when deciding which solution is right for your business. The 
following systems are arguably the three most popular and offer enterprise-class solutions for 
server virtualization: VMware, Citrix XENServer, and Microsoft Hyper-V.
VMware, a commercial software company that specializes in virtualization, is probably the 
most popular and is a widely adopted system for server and desktop virtualization. Their product 
offering comes with many tools and functionality to allow a business to take full advantage of 
virtualization technology.
The Citrix XENServer, a virtualization platform based on the open source XENSource proj-
ect, is gaining ground, offering a robust suite of products to support an enterprise virtualization 
effort. Despite its origins in the open source world, companies such as Novell, HP, and IBM have 
invested time and effort in the development of the platform. The XEN Server is commercially 
supported, easy to use, and offers a robust management interface (Rule and Dittner, 2007, p. 423).
Table 9.1  A Simple Example of the Cost of Five Two-Way Application Servers
Component
Unit Cost ($)
Physical Cost ($)
Virtual Cost ($)
Server hardware
  7,500.00
37,500.00
  7,500.00
Software licenses/CPU
  2,000.00
20,000.00
  4,000.00
Supporting infrastructure
  2,500.00
12,500.00
  2,500.00
Power per server year
     180.00
  2,700.00
     540.00
Cooling per server year
     150.00
  2,250.00
     450.00
Total three-year costs
74,950.00
16,490.00
Realized savings over three years
58,460.00
Source:	Rule, D. and Dittner, R. The Best Damn Server Virtualization Book Period. Syngress, 
Burlington, MA, 2007.

104  ◾  Information Security Management Handbook
Microsoft Hyper-V, offered with the latest version of Enterprise Windows Server, is continually 
maturing and could be a great option if an organization is running Microsoft servers. While Linux 
is supported, only two distributions are available with Hyper-V (Microsoft, 2011). The Microsoft 
solution may be right for an enterprise if the right combination of licensing and existing operating 
systems exist. Because the product is not as mature as the other platforms, it may lack the report-
ing and granular administrative controls offered by VMware.
When introducing a new technology, the timeline for adoption naturally extends to cover edu-
cating engineers, managers, and technicians. Once able to access the console of a virtual server, it 
looks and feels just like any other server, so an engineer familiar with a traditional server may not 
know that they are working on the one that is virtualized. Because of this, only specific training 
relating to the virtual environment is needed and is another reason why virtualization has been 
rapidly adopted.
The statistics are compelling, the offerings continue to get more robust, and the software sup-
porting virtualization is continually maturing. Cost-saving promises, along with many availabil-
ity, testing, and development options make virtualization seem like an obvious choice. This begs 
the question: What concerns should IT professionals and management have with the deployment 
of such an important technology?
Security and Control of Virtual Servers
Companies around the world are scrambling to take advantage of server virtualization and are 
rapidly adopting the technology. As with any new technology, marketing efforts are continually 
guiding us toward looking at the possibilities of what the technology can do for our business, but 
few look deeper into the risks that it will introduce. Virtualization is exactly one of those technolo-
gies. It has become mainstream and there is a more widespread understanding of the technology. 
Information security professionals are starting to take note of the risks that such a technology 
introduces.
Administration and management are critical to maintaining control of the environment. With 
all the benefits that virtualization brings to a business, when left unchecked, it has many risks 
that warrant attention. Putting forth the effort on the administration and management of the 
virtual environment will allow management and information security personnel to identify com-
mon information security issues and institute policy, procedures, and standards to control risk. 
Because management needs to be behind the policies put in place by the business, they need to be 
actively involved from the very beginning so that the controls are already in place once the virtual 
environment is built.
Once the management and administration functions have been identified and the environ-
ment has been created, a postimplementation assessment will need to be performed in addition 
to regular auditing to ensure that the environment conforms to the set standards, policies, and 
procedures put forth for the implementation.
Administration
Administration of the virtual environment consists of the day-to-day care and feeding of the 
systems to keep them up and running and secure. “Patching, antivirus, limited services, logging, 
appropriate permissions and other configuration settings that represent a secure configuration 
for any server gain importance on a host carrying multiple guest servers” (Hoesing, 2006). Any 

Server Virtualization: Information Security Considerations  ◾  105
administrative tasks being performed on a nonvirtualized server should always continue to be 
performed on the server once it is virtualized, but it does not stop there. Based on the policies put 
in place, administrative tasks will need to be created for the hypervisor as well, adding overhead 
to the administrative function of the server environment.
To administer the virtual environment, there are tools available for the platform that is cho-
sen. “Virtualization tools usually include a management console used to start and stop guests and 
to provision resources (memory, storage) used by those guests” (Hoesing, 2006). The tools can 
also do things such as moving a virtual server to another physical machine, as well as adjusting 
the resources available to the virtual machine. The virtual console and the management tools 
should be tightly restricted to only appropriate and approved personnel, and the administration 
of security to the virtual environment should be audited regularly. “Access to the host OS and the 
management tool should be strictly limited to technical staff with a role-based need” (Hoesing, 
2006). Access to the tools or the “management console” should be set to the highest security set-
ting to reduce the possibility of unauthorized access. “Access to configuration files used for host 
and guest OSs should be limited to system administrators. Strong root passwords should be veri-
fied as well as allowed routes to and from hosts” (Hoesing, 2006). As noted, ensuring proper rights 
management of the tools and administrative console is important in maintaining the integrity of 
the environment.
As virtual servers get provisioned and decommissioned, housekeeping tasks must be addressed. 
Images of old machines, long forgotten by the IT staff and management, may still reside on the 
shared disk. Without monitoring and inventories of the virtual machines, images provisioned 
for other business units throughout the organization will be forgotten (Fogarty, 2009). Because 
virtual systems are so portable, the ease with which someone can copy a system for malicious 
use becomes quite easy. “With virtualization, a server (or cluster of servers) can be deployed into 
production with a single mouse click, potentially bypassing the controls associated with tradi-
tional system life cycle management” (ISACA, 2010). Virtualization platforms, such as VMware, 
comprise a couple of files stored on the disk. These files are easily portable, which is great for 
disaster recovery scenarios, but can be disastrous if they are in the hands of individuals with bad 
intentions. Not managing old images creates a risk, so securing and keeping an inventory of the 
images become a top priority. If someone gains access to the files, it does not take much to launch 
an instance of the virtual machine anywhere, regardless of hardware type. A proper cleanup and 
inventory should be performed on a regular basis and the audit program should address this as 
well (ISACA, 2010).
Running a backup system that is incompatible with virtualization technology could render all 
the virtual servers running on a physical machine useless. For instance, if all the virtual machines 
launched a backup job at the same time on the same hardware, the underlying backbone that sup-
ports the data transfer could be saturated to the point where a denial-of-service could be realized, 
even if there is disk-to-disk technology in place (Marks, 2010). Taking a close look at the backup 
jobs and how they affect the performance of the virtual machine should be evaluated before 
launching a new backup system in a virtual environment.
Running antivirus systems on a virtual environment complicates matters in much the same 
way as backup systems affect the virtual machines. When selecting an antivirus system, a prod-
uct that is aware of the virtual environment is necessary to prevent problems. Configuration and 
managing signature download are important to the health of the virtual system. The scheduling 
of virus scanning and the signature download on the same host must be staggered to prevent 
saturation of the CPU. Some sort of antivirus measures should be taken to protect the hypervisor 
as well.

106  ◾  Information Security Management Handbook
Management
Although a business may get excited about the versatility of a virtual environment and the cost sav-
ings that are realized from the technology, management of the virtual environment understandably 
gets a lot less attention. Designing proper management controls to include policies, standards, and 
best practices will go a long way to producing secure systems.
Policies will set the stage for what is expected of the personnel taking care of the system and 
outline the rules that they need to live by. Adhering to industry standards and best practices will 
create a strong and consistent environment, providing a configuration that has been proven by 
others. These governance principles are essential to protecting the virtual environment.
Design is an important element when building a virtual solution. When designing a solution, 
it is important to take into consideration the network design, the firewall placement, and the 
development of a virtual network. Segmenting the connectivity to the shared disk is also impor-
tant and should be on its own physical network or a virtual LAN. “A host server failure can take 
down several virtual servers and cripple your network. Because host server failures can be so dis-
ruptive, you need to have a plan that will help minimize the impact of an outage” (Posey, 2010). 
Adding at least one additional host will allow the administrators to spread the load across multiple 
machines, in effect, hedging against the possibility of a total failure.
Roles will need to be defined and procedures developed to ensure that the right people are doing 
the right things with the technology. “Traditionally, technology has been managed by IT within vari-
ous functional and technical areas, such as storage, networking, security and computers/servers. With 
virtualization, these lines are significantly blurred, so enterprises that embrace virtualization need to 
mature their support models to reap all of the benefits that virtualization can provide” (ISACA, 2010). 
A training program for all the functional areas of IT would be beneficial to ensure that personnel all 
understand the technology and look for ways to expand on its adoption.
“Probably the single biggest mistake administrators make when virtualizing a datacenter is 
overloading the host servers” (Posey, 2010). While virtualization provides many options to pre-
vent this by sharing resources across multiple physical servers, such options need to be identified 
and implemented. Hardware failures are not uncommon, so hardware support contracts will still 
be needed and possibly enhanced to provide a quicker response time. A plan for maintaining the 
availability of the systems will also need to be developed and added to the corporate business 
continuity plan.
An unpatched server operating system and hypervisor can leave vulnerabilities exposed, so 
it is important to make sure that all systems are patched on a regular basis. “The most tangible 
risk that can come out of a lack of responsibility is the failure to keep up with the constant, 
labor-intensive process of patching, maintaining and securing each virtual server in a company” 
(Fogarty, 2009). Virtualization adds some additional overhead to a patch management program. 
Not only does the operating system in the virtual environment need to be patched, but the 
hypervisor does as well. The very nature of the physical servers makes the patching process 
straightforward and immediate. In the virtual environment, an image of a server could be in 
any number of states and could have been built long before critical patches are issued, so it is 
imperative to have an inventory of the virtual servers that breaks down the patch level of the 
virtual machine (Fogarty, 2009). Access to the server through vulnerabilities in the operating 
system could provide a hacker with access to the server environment and compromise the data. 
Attackers realize the importance of attacking the hypervisor, so we will see more attacks targeting 
the hypervisor in the future. A comprehensive patch management program that addresses not 
only the operating system but also the hypervisor is paramount to securing the environment.

Server Virtualization: Information Security Considerations  ◾  107
Depending on the type of patch or upgrade, the environment containing all the virtual servers 
might need to be taken offline. This could be an issue in high availability environments. Virtual 
systems have the capabilities to achieve a high rate of availability, but it may not be automatic. 
Ensuring that the organization has the correct licensing and virtual design will allow the systems 
to be upgraded, patched, or even moved in the event of a hardware failure.
Whether or not there is a configuration management program in place, introducing virtual-
ization into the organization will create a need to formalize it. Managing the configurations on 
systems that will be harder to identify will be a challenge. By virtue of having virtual systems, 
there will be virtual machines in various states: on, off, and standby—all of which will need to be 
tracked and accounted for. Managing the configuration of the virtual environment is important, 
because if the standards are not followed, there is a chance that integrity can be compromised.
Continued monitoring is necessary to ensure that the system complies with the policies and 
standards established by management. This holds true for any server, whether or not it is vir-
tual. However, because of the complexity of the virtual environment, focusing on the enhanced 
monitoring of both the guest and hypervisor is required. Various things should be included in 
the monitoring plan, including administrative access, access control, virtual machine state, and 
hardware resource consumption. In a comprehensive monitoring plan, each of these items should 
already be addressed, but because a hypervisor and a management system for the virtual systems 
are additional devices, the duplication of this effort to include the hypervisor is mandatory.
Whether there is an internal audit department or a third party handling the technology audits 
for the company, the project should be introduced to the audit department from its inception. The 
audit department needs to put together an audit program that will address the monitoring and 
management controls and to ensure that the practices comply with stated policies and standards 
(ISACA, 2010). If there is internal audit staff, they may have difficulty keeping up with technology 
and they could have problems putting together an audit program. Regardless, a comprehensive 
audit program to test the controls that were put in place will need to be tested to identify where the 
risks to the data really lie. It is common to outsource this function, and the management should 
seriously consider doing so to gain a comprehensive audit.
Sometimes it is easier to document what you can see. With virtualization, you cannot exactly 
see all of the virtual servers running on each host, and you certainly cannot see the servers in an 
“off” or “suspended” state. There may be communications between virtual sessions that might 
not be able to be traced or reported on. Virtual server-to-server communications should be docu-
mented so that the auditors can report correctly on the risks (ISACA, 2010). Comprehensive 
documentation on the virtual environment will allow the engineers to troubleshoot and give the 
auditors or experts assessing risk the ability to see if there are any areas of risk that need to be 
addressed.
Risk assessments should be performed throughout the life cycle of the system. This will include 
a preimplementation assessment, a postimplementation assessment, and ongoing assessments until 
the environment is decommissioned. When choosing a virtualization technology, a risk assess-
ment will need to be performed and this should be included in the project plan. The risks associ-
ated with the implementation can be tracked by management while approaching milestones in 
the project. Approaching a project with a preliminary risk assessment completed will make many 
of the decisions easier (vendor, topology design, etc.). When performing a security assessment 
after the environment has been built, there are areas that might be missed if the documentation is 
inaccurate or not inclusive of communications happening between virtual machines residing on 
the same host. This postimplementation assessment will ensure that all policies and guidelines are 
complied with. This will also show the need for monitoring and management software. Ongoing 

108  ◾  Information Security Management Handbook
risk assessments and security assessments are also necessary and will be able to capture changes in 
the environment. The procedures and policies surrounding the virtualization technology will need 
to be kept up to date and modified on an as-needed basis.
“The auditor may use commercial management or assessment tools to poll the environment 
and compare what is found to the authorized inventory” (ISACA, 2010). VMware has a robust set 
of tools to assess the security of the environment, but not all hypervisors have this capability built 
in. A thorough evaluation of the solutions will ensure that the appropriate reporting and man-
agement tools are available to be able to do a proper audit and security assessment. “Assessment 
procedures should ensure that the hypervisor and related management tools are kept current with 
vendor patches so that communication and related actions take place as designed” (ISACA, 2010). 
Out-of-date management tools will not provide management and auditors with an accurate secu-
rity picture of the environment.
Keeping up with technology and the latest findings in the virtualization arena is important. 
Every day there are more exploits found, so understanding them and knowing the technology will 
help implement the appropriate controls and procedures. Of all the security concerns discussed, 
there are certainly controls, processes, and procedures that can be put in place to mitigate the 
risks associated with implementing server virtualization. The management’s ability to monitor 
the activities in the virtual environment is crucial and should be instituted from the beginning. 
Each company will need to evaluate the possible security risks that are associated with moving to 
a virtualized environment. “Mitigating many of these threats and having well-documented busi-
ness processes and strong audit capabilities will help ensure that enterprises generate the highest 
possible value from their IT environments” (ISACA, 2010).
Conclusion
Virtualization can be a powerful tool for an organization—not only from a cost-saving stand-
point, but also from a process and management standpoint. Being able to move machines from 
one location to another for disaster recovery purposes is a quantum leap from the expense and 
logistics of what businesses were doing just a few years ago. Making use of idle server time with 
multiple server instances running on one machine makes great financial sense, especially if you 
can cut down on the number of servers in the data center. This not only saves money, but also 
provides for a greener operation.
As with any new initiative, there are always risks that must be identified. A thorough review 
of the technology is essential to highlight these risks so that management can address them. Once 
the technology risks are identified, the auditors and compliance personnel should be looking at 
the human element behind the processes and procedures to ensure that the administrators of the 
new system are following the policy. This is an area that is often overlooked because it is hard not 
to focus on the new technology.
The auditors’ role should be highly considered, not only because they are required on any new 
projects or initiatives, but also because they will report any lack of control to management. While 
malicious activities are a concern, part of the control review will be to check to make sure that 
people who are doing their job are doing it accurately and following the policy. All of the control 
reviews will ultimately go toward protecting the organization.
The need for controls is important. By instituting controls to address some of the risks with 
virtualization, you will lower your overall risk in implementing such a technology. These con-
trols can be as simple as basic reports, or as complex as technological controls. Knowing your 

Server Virtualization: Information Security Considerations  ◾  109
technology is also important and getting the training needed to create a safe computing environ-
ment is essential.
Selecting a virtualization platform should be a fully vetted process, addressing all the technical 
needs, but making sure not to forget information security. Often times, reporting and auditing 
take a back seat to the process, but should really be brought to the forefront because it is difficult 
to evaluate what you have when you do not have the tools to be able to do so.
In the future, virtualization may create other obstacles that need to be addressed. With the 
emergence of CPU virtualization, I/O virtualization, and virtual appliances, there may be control 
problems that will need attention. Gartner (2010), a research firm, states that 18 percent of systems 
that could, took advantage of virtualization with an anticipated target of over 50 percent by 2012. 
More than half of them will not be as secure as their physical equivalent.
Virtualization is here to stay and will only get bigger and more complex. Howard Marks 
(2010) of Information Week said it well: “Server virtualization is a clear win for the data center, but 
it presents a mixed bag of challenges and opportunities for those charged with backing up their 
companies’ data.” Our ability to adapt and ensure the safety of the organization is critical.
References
CDW. Server virtualization [White paper], 2010. http://viewer.media.bitpipe.com/1064596181_865/12928
77744_720/TT10019CDWVirtlztnComparWPFINAL.pdf.
Fogarty, K. Server virtualization: Top five security concerns. CIO, May 13, 2009. http://www.cio.com/
article/492605/Server_Virtualization_Top_Five_Security_Concerns.
Gartner. Gartner says 60 percent of virtualized servers will be less secure than the physical servers they replace 
through 2012 [Press release], March 15, 2010. http://www.gartner.com/it/page.jsp?id=1322414.
Golden, B. Wrapping your head around virtualization. In Virtualization for Dummies, Chapter 1. Wiley, 
Hoboken, NJ, 2008. [Books24 / 7 version]. http://common.books24/7.com.ezproxy.gl.iit.edu/book/
id_23388/book.asp.
Hoesing, M. Virtualization usage, risks and audit tools. Information Systems Control Journal (Online), 2006. 
http://www.isaca.org/Journal/Past-Issues/2006/Volume-3/Pages/JOnline-Virtualization-Usage-Risks-
and-Audit-Tools1.aspx.
ISACA. Virtualization: Benefits and challenges [White paper], 2010. http://www.isaca.org/Knowledge-
Center/Research/Documents/Virtulization-WP-27Oct2010-Research.pdf.
Marks, H. Virtualization and backup: VMs need protection, too. Information Week, February 12, 2010. 
http://www.informationweek.com/news/storage/virtualization/showArticle.jhtml?articleID=2292002
18&cid=RSSfeed_IWK_All.
Microsoft. Microsoft server Hyper-V home page, 2011. http://www.microsoft.com/hyper-v-server/.
Posey, B. 10 issues to consider during virtualization planning, February 5, 2010. Message posted to http://
www.techrepublic.com/blog/10things/10-issues-to-consider-during-virtualization-planning/1345.
Rule, D. and Dittner, R. The Best Damn Server Virtualization Book Period. Syngress, Burlington, MA, 2007.
Von Hagen, W. Professional Xen virtualization, 2008. [Books24 / 7 version]. http://common.books24/7.com.
ezproxy.gl.iit.edu/book/id_23442/book.asp.


Security Management Planning


113
Chapter 10
Security Requirements 
Analysis
Sean M. Price
Requirements are the basis for system design. The successful planning, initiation, development, 
and maintenance of an information technology (IT) system hinge on solid requirements speci-
fications. These system life-cycle activities are negatively impacted when requirements are not 
adequately analyzed. Inadequately defined requirements lead to poor planning. System develop-
ment activity may proceed in a direction contrary to user wishes or mission requirements when 
the planning is weak or the requirements are poorly defined. Appropriate maintenance is difficult 
to achieve when the timing and activities are not clearly identified and communicated. Proceeding 
down a path without regard to what is required is an invitation to failure. Likewise, security man-
agement also fails to deliver when a security requirements analysis is lacking.
A security requirements analysis typically occurs during the initiation phase of a system. 
High-level security requirements translate readily into understandable activities, such as account 
management, auditing, and installation and updating of antivirus software. Requirements are 
quickly translated into equally high-level actions affecting people, processes, and technology. The 
security requirements, pushed early in the life of a system, quickly become dated.
The rapid advancement of technology, threats, and vulnerabilities complicates system and secu-
rity management. New technology can introduce weaknesses not previously considered. Mutating 
threats reveal new attack vectors, inducing migraines for those responsible for system security. The 
never-ending avalanche of software flaws continuously degrades the existing controls. Authorities 
of all stripes promulgate new policies in an attempt to address these complicated advancements. 
Thus, a periodic security requirements analysis is needed to keep up with these changes.
A security requirements analysis is an activity commonly practiced but seldom specified in 
detail by the security community. The need for gathering and analyzing security requirements 
is obvious. Without security requirements, there is little authority to dictate countermeasures 
or evaluate their effectiveness. Ad hoc (and poorly documented) methods of evaluating security 
requirements impede efficiency and repeatability. An effective security requirements analysis, 
therefore, implies the need for a repeatable methodology.

114  ◾  Information Security Management Handbook
This chapter introduces a security requirements analysis methodology (SRAM). The goal of 
this methodology is to assist the security professional with identifying, analyzing, associating, and 
integrating security requirements into the security management process. Each aspect of this goal 
helps the security professional to
◾
◾Identify: relevant security requirements
◾
◾Analyze: security requirements under consideration
◾
◾Associate: security requirements with the targeted system
◾
◾Integrate: applicable security requirements into the system’s life cycle and documentation
The attributes in this methodology are joined in a circle, much like other techniques for 
continuous monitoring or improvement. The methodology is started by identifying the security 
requirements applicable to the organization and system. Once collected, these requirements are 
broken down into smaller chunks of information. This provides a means to compare existing 
requirements, ensuring that nominal differences are considered. Interpretations of a security 
requirement component are performed to ensure consistent meanings. Next, the compilation 
of decomposed requirements is compared with the target system. An evaluation is conducted 
to determine if a deficiency in the requirements list exists. This list of requirement components 
is trimmed according to the system architecture and management guidance. In the final step, 
life-cycle documentation is updated to comply with the tailored list of security requirements.
Definitions
To begin with, it is worth taking a few moments to express some definitions that might not be 
universally accepted. For the purpose of this chapter, the definitions included here are meant as a 
guide for understanding as opposed to rigid interpretations.
“Implement only those security controls that are necessary.” This is a common security man-
agement mantra that is as logical as it is deceptively difficult to comply with. It is often associated 
with the concept of risk management.
◾
◾Risk management: A process to evaluate the impact of a threat exploiting a weakness. It does 
not imply a means to conduct risky operations.
Security goals are the collective objectives of confidentiality, integrity, and availability pertain-
ing to the system and the information processed, stored, and transmitted within it.
◾
◾Confidentiality: Enables resource access only to those authorized.
◾
◾Integrity: Protects against improper resource modification or destruction.
◾
◾Availability: Ensures timely and reliable access to resources.
Security goals are often expressed in a policy.
◾
◾Policy: A compulsory collection of rules formally promulgated and authorized by an author-
ity or a ruling body
Examples of policies include laws, regulations, and standards (established to implement policy). 
Governments, industry regulators, and organizations themselves establish policies. This forms the 
basis for security requirements.

Security Requirements Analysis  ◾  115
◾
◾Security requirement: A compulsory discrete rule supporting the desired security goals
By definition, a security requirement must be followed. If it is optional, then it is not really a 
requirement. A valid security requirement should in some way dictate an action, behavior, process, 
or system attribute supporting one or more of the security goals. For example, file level encryption 
supports confidentiality.
Well-defined security requirements support the overall security goals of confidentiality, integ-
rity, and availability. Requirements must in some way support the protection of information and 
the system within the overall security goals.
Following these definitions, we can proceed with a common basis into the SRAM.
Identify Phase
The goal of this initial phase is to gather all policies that may potentially apply to the system. It 
is important to remember that security requirements are system-specific. An organization might 
have two systems with different operational and functional requirements. This might dictate dif-
ferent requirements for each system. In the beginning, no candidate policy should be ignored until 
it has been properly evaluated for its applicability.
Anyone who has used a search engine on the Internet understands that the amount of infor-
mation available online is staggering. Sifting through mountains of data to find the security 
requirements needed can seem like a monumental task. As with all projects, it is important 
to limit the scope of the work. At this early stage, the security professional should establish 
boundaries to narrow the search to quickly sort out the needed information. The boundaries are 
defined by the parameters and attributes of the system in question. Some high-level attributes 
to consider include:
◾
◾System role
◾
◾User types
◾
◾Industry focus
◾
◾Data types
◾
◾Locality
Use a high-level viewpoint to focus on key elements that will guide the security requirements 
search. Investigate these aspects to discover the key elements. Ask the following questions to estab-
lish the initial boundaries of the requirements search:
What is the role of the system? A system might have a primary function, such as accounting. Most 
systems are a collection of smaller systems performing many functions within an organization. 
Someone must decide where to draw the line for system boundaries. Knowing the purpose of the 
system helps focus the search for the relevant security requirements.
Who uses the system? A system will often have at least a few employees who are responsible for main-
tenance. Internet-facing systems could have various classes of users to consider. The general public 
is one type of users who are very different than a buying customer. Likewise, systems designed to 
support collaboration between third parties may have different requirements from those hosting 
government users. Organizational departments with particular functions such as research and 

116  ◾  Information Security Management Handbook
development may have different requirements than those that involve the privacy or health-related 
information of employees or customers.
What is the industry focus of the users? This question considers the role and users of the system. Some 
industries may have explicit regulations that others do not. For instance, systems designed to sup-
port the healthcare industry will have specific requirements. By contrast, a Web-hosting system 
that has health industry customers among others probably would not need to support healthcare 
industry requirements. But, if an aspect of the Web hosting is focused on the healthcare industry, 
then the additional requirements might be needed. Look to the business mission of the system and 
types of users supported to help answer this question.
What types of data are processed, stored, and transmitted by the system? Systems often contain a great 
variety of data types. Common data types include financial, legal, customer, and publicly avail-
able information. Some types of information are more regulated than others. For instance, privacy 
information is often controlled by a multitude of regulations. By contrast, there may be no regu-
lations at all for an organization’s proprietary information. What makes this more interesting is 
that an organization would likely value proprietary above privacy information. Local policy might 
dictate rigid requirements to protect information affecting the future of the company. Managers 
often recognize the importance of protecting information sensitive to corporate survival. However, 
the organization is still compelled by higher authorities to protect other types of information in 
their custody. Knowing the types of information processed, stored, and transmitted by the system 
is essential to identifying the needed security requirements.
Where are the physical and logical locations of the system and its users? A system may reside in one 
country and service customers in another. In some instances, a multinational corporation may 
have an internal system spanning multiple countries. In both cases, the physical and logical loca-
tions of the system and its users may require very different standards to be in place. For example, 
privacy laws in the European Union are typically more rigid than those in the United States. 
A system in the United States recently extended to the European Union would incur new security 
requirements. This type of situation is further complicated when a security practitioner must con-
sider foreign laws and regulations levied in a language not understood.
With answers to the prior questions in hand, the security requirement scope should now be 
manageable. The type of information to be searched to discover the security requirements has 
already been alluded to. Laws, regulations, industry standards, and organizational policies are the 
primary sources of security requirements. These types of requirement sources are often compul-
sory. That is to say, they must be followed.
Aside from the Internet, there are other resources available to help identify security require-
ments. Finding security requirements can be as easy as asking a question. The following are a few 
groups who can get you going in the right direction:
◾
◾Organization management: Various business units in an organization are often focused pri-
marily on regulations affecting what they do. Functional managers with a significant influ-
ence or stake in the system are a starting point to discover requirements.
◾
◾Informal leaders: These are the go-to people who always seem to have an answer or can at 
least point you in the right direction. Many people shy away from management roles, but 
possess voluminous knowledge on a topic. They are often an excellent source of information 
that is sometimes overlooked by managers focused on other priorities.

Security Requirements Analysis  ◾  117
◾
◾Legal department: Organizational lawyers are on guard to keep their employer out of legal 
trouble. They are one of the best placed to identify applicable laws and regulations or at least 
point you to sources to find what you need. While their focus is the law, do not rely on them 
exclusively. Although lawyers are quite knowledgeable, they do not know it all. It is probable 
that they are unaware of the technical security requirements that might exist. Furthermore, 
a lawyer lacking an in-depth understanding of technology would have difficulty translating 
or interpreting a law into a technical security requirement.
◾
◾Professional associations: Industry groups and trade associations often provide their members 
with areas to post and answer questions. Periodic meetings of these groups offer another 
forum to discuss issues with people in the same business arena. A security professional does 
not need to have access to every type of professional group. It is quite likely that at least a 
few people within the organization already have access to associations in your industry. Talk 
with those coworkers and ask them to seek feedback from their peers. Better yet, attend 
some meetings with the coworker and ask questions yourself.
◾
◾Industry partners: Organizations sharing data has a mutual interest in protecting it. The 
IT managers and security professionals from partnering organizations may have identified 
requirements not immediately apparent or previously considered. An open dialog with a 
business partner is also a good way to learn of the pitfalls that they might have encountered 
with a particular requirement.
◾
◾Regulatory agencies: The statement, “Hello, we are from the government and are here to 
help,” is not something that many people want to hear. However, most people in govern-
ment positions are actually human, have families, and can be compassionate. While some 
managers cringe at the thought of contacting a regulatory agency, it is not something to be 
feared. Government agencies are a legitimate source and are often quite helpful. Just asking 
a government agency for information does not imply guilt, incompetence, or wrongdoing (at 
least in most democracies). Many government workers are quite professional and are happy 
to answer your questions. After all, their job is to serve the people. Your tax dollars are likely 
paying their salary. Doesn’t it make sense to leverage that money to help you achieve your 
own work objectives?
External sources of requirements arising from laws and regulations are the most obvious 
sources. However, the number of security requirements that the organization creates for itself may 
be surprising. Within an organization, there are a variety of sources that can be used to obtain 
security requirements. The security professional should consider:
◾
◾Organizational policy: Organizational management is just as likely as government bodies 
to establish its own laws driving security requirements. High-level policies are sometimes 
created to mimic other laws and requirements. This is an efficient approach to guide the 
organization into compliance with government laws and regulations. While organizational 
policy might only paraphrase higher laws, in some instances, additional security require-
ments will emerge.
◾
◾Mission statements: Ordinarily, a mission statement is not considered policy. It is a way 
for management to convey an overall strategy guiding the workforce. In this regard, it 
might feel awkward to consider a mission statement as a security requirement source. 
However, organization and business unit mission statements can hint at desired security 
requirements. This can reveal an underlying concern that business activities should support 
security goals.

118  ◾  Information Security Management Handbook
◾◾Business objectives: Short- and medium-term activities of an organization sometimes include 
security attributes. For instance, an organization wanting to expand into E-commerce will 
incur security requirements. Although not specified, the use of Secure Sockets Layer (SSL) and 
the protection of the associated certificate are needed. Digital transactions involving credit cards 
may also necessitate compliance with the Payment Card Industry (PCI) data security standard.
◾
◾Contractual obligations: Contractual agreements with customers, business partners, and sup-
pliers sometimes require compliance with particular security requirements. An organization 
hosting a system for the U.S. federal government will need to comply with the Federal 
Information Security Management Act (FISMA). Retail business partners may require 
acknowledgement of compliance with PCI standards or that national privacy standards 
are met. Managers associated with the contracts should be able to elaborate on particular 
requirements agreed to by the organization.
◾
◾User needs: Systems exist for users because they are the primary group driving the require-
ments. In some cases, users might need remote access to the system. The dramatic prolif-
eration of mobile devices pushes system boundaries into higher-risk scenarios. Savvy users 
and system managers recognizing the risk will establish security requirements in conjunc-
tion with functional requirements. However, this does not always occur. Often, functional 
requirements are specified without regard to security. This is still not a problem, because a 
functional requirement often has an associated security requirement buried somewhere in 
the policy. Understanding what users want and need helps the security professional identify 
previously unconsidered security requirements.
◾
◾Risk acceptance: A system with a known flaw represents an operational risk. In some cases, 
the risk is considered small enough to be inconsequential. At other times, a risk might be 
concerning, but addressing the threat or vulnerability might be too costly or infeasible. In 
either case, managers accept the risk and continue operations. The management’s decision 
to continue operations despite the risk may represent a type of operational policy for the sys-
tem. The management could reason that a particular threshold is acceptable for continued 
operations. A boundary or threshold on a security requirement might imply an additional 
security requirement for the system. Ongoing acceptance of a particular risk can therefore 
create new security requirements.
Another place to obtain security requirements is from the system itself. A review of the system’s 
documentation and its architecture can also reveal security requirements. Sometimes, the system’s 
documentation does not fully imply the need for security. Security controls built into a system 
might also allude to forgotten security requirements. After reviewing the documentation and the 
system, ask yourself and others:
◾
◾Why was the system built this way?
◾
◾Why is a particular security control required?
◾
◾What is the purpose of a given security configuration?
These questions might lead to written policies, point to risk-based decisions, or reveal tech-
niques used to counteract specific threats. In any case, if it is built into the system and is needed, 
it is implied that it is required.
Many of the aforementioned sources are derived from external authorities and organizational 
people, processes, and policies. There is one final source that ought to be considered: You, the secu-
rity professional. Aside from a chief security officer, most security professionals do not possess the 

Security Requirements Analysis  ◾  119
power to promulgate policy as they see fit. However, those with education and experience should 
not discount their own worth and that of their peers. It is worth considering:
◾◾Publications: Peer-reviewed literature from journals and conferences often provide innovative 
solutions to ongoing problems. Some security books also suggest ways to handle vexing security 
issues. It is not unusual for research solutions and recommendations to emerge years ahead of 
policy makers. The guidance provided by these sources is valuable and should not be discounted.
◾
◾Best practices: Each year, numerous external groups form to address the ongoing problems in 
the realms of cyber security and information security. These groups combine talented people 
from a variety of industries to solve vexing problems. For example, the Center for Internet 
Security developed security configuration benchmarks for a wide variety of technologies. 
The Open Web Application Security Project, as another example, promotes secure design 
for Web-based technologies. The work by these groups and others provides great value to 
the security community and society at large. Their recommendations ought to be considered 
along with traditional security requirements.
◾
◾Experience: Your history as a security professional and the advice of your peers are not with-
out value. Over time, security professionals see patterns of what does and does not work in 
technology, society, as well as our current organization. Seek out the advice of peers in new 
situations. Share with others things that you have learned. By no means will experience 
alone be counted directly as a security requirement. However, the advice we give can affect 
decision makers and the outcome of policy.
Many security requirements can be discovered by simply networking with other profession-
als. Talking to internal and external professionals at all levels enables a wider dynamic viewpoint. 
Networking with others expands the discovery possibilities and is more efficient than relying on 
a Web-based search engine alone. Life does not occur in a vacuum and neither should the search 
for security requirements.
Analyze Phase
The quest to identify security requirements can result in a multitude of sources. Undoubtedly, 
sources emerge from diverse authorities. Many policies express similar requirements in very dif-
ferent phrases. But, do they really say the same things? Do policy statements express the same 
requirements? The purpose of the analyze phase of the SRAM is to break down policies into their 
smallest components and capture the explicit security requirement of each policy.
Written policies are a collection of sentences expressing the authority’s security objectives. We 
refer to each sentence in a policy as a policy statement. A single sentence can express one or more 
security objectives. A policy statement with a single objective is itself a basic security requirement. 
Policy statements with multiple objectives must be broken down until each objective is expressed 
as a unique security requirement. The process of breaking down a policy into security require-
ments is called policy statement decomposition.
Security requirements obtained from policy statement decomposition still require further 
analysis. Comparisons must be made between similar security requirements to infer any unique-
ness. One way to facilitate this is to compile the results into a security requirements traceability 
matrix (SRTM). This provides a security professional with a means to track, manage, analyze, and 
interpret the relevant security requirements.

120  ◾  Information Security Management Handbook
Repetition of security requirements from divergent sources and authorities will definitely 
occur. It is neither efficient nor relevant to list the same security requirement multiple times in the 
SRTM. The final step in the analyze phase is to combine similar requirements through interpreta-
tion. Contextual differences between individual security requirements may imply different things. 
Some degree of reasoning is needed to interpret the similarities and differences between security 
requirements. The ultimate goal is to eliminate redundancy in the SRTM through the use of 
analysis guided by security professional reasoning.
Decomposition
Policy statements can be simple or complex. Simple policy statements contain a single objective 
and require little or no interpretation. By contrast, a complex policy statement may have multiple 
objectives or require extensive interpretation. Vague statements can be challenging to interpret 
when multiple valid interpretations are possible. Consider the following security requirement 
obtained from the National Institute of Standards and Technology (NIST) Special Publication 
800-53, Recommended Security Controls for Federal Information Systems and Organizations, 
Revision 3. For our purposes, we shall disregard the supplemental guidance and control enhance-
ments specified in NIST 800-53.
◾
◾AU-8 time stamps: The information system uses internal system clocks to generate time 
stamps for audit records.
This policy statement contains only one security objective. Although some might argue the 
interpretation of internal clocks, the statement requires little or no interpretation. Now consider 
the following NIST 800-53 policy statement:
◾
◾AU-3 content of audit records: The information system produces audit records that contain 
sufficient information to, at a minimum, establish what type of event occurred, when 
(date and time) the event occurred, where the event occurred, the source of the event, the 
outcome (success or failure) of the event, and the identity of any user/subject associated 
with the event.
This is an example of a complex policy statement. It contains multiple security objectives. 
Some might feel that alternate degrees of interpretation are possible within the individual objec-
tives. For instance, the “where” an event occurred might refer to the location of the log, the 
location of the subject associated with the event, or both. Most, however, would generally agree 
that “where” refers to the location of the subject. Breaking down this policy statement into the 
individual security requirements provides the following:
	
1.	The information system produces audit records that contain sufficient information to 
establish:
	
a.	 What type of event occurred
	
b.	 When (date and time) the event occurred
	
c.	 Where the event occurred
	
d.	 The source of the event
	
e.	 The outcome (success or failure) of the event
	
f.	 The identity of any user/subject associated with the event

Security Requirements Analysis  ◾  121
This single policy statement generated six individual security requirements identified by 1.a 
through 1.f. Decomposing down to this level enables granular identification of the security require-
ments for a system. This is especially helpful when manual verification of the security requirement 
implementations is needed. More importantly, to the SRAM, decomposition to this level facilitates 
direct comparison between similar security requirements.
SRTM
An SRTM is a tool used to help facilitate the comparison and analysis between security require-
ments. An SRTM is nothing more than columns and rows used to organize the security require-
ment details. A spreadsheet is ideal for this task. Keep in mind that the overall goal in this phase is 
to list a security requirement only once in the SRTM. To accomplish this, consider a spreadsheet 
with the following types of defined columns:
◾
◾Group: A collection of similar or related security requirements
◾
◾Identifier: A unique label for the security requirement
◾
◾Name: A short name representing the policy statement or requirement
◾
◾Description: An individual security objective from a decomposed policy statement
◾
◾Source: The abbreviated name of the source document where the policy statement was 
obtained
◾
◾Related: Additional sources stipulating the same requirement
Group
Select group names that collect security requirements areas into focused management areas. 
Ideally, a single organizational unit would be responsible for all the requirements in the group. 
Arguably, some of the suggested groups that follow could be combined. However, what matters 
is that the requirements are identified once and are grouped according to how those requirements 
might be managed. Where practical, it is best to have one organizational unit responsible for simi-
lar requirements. This helps to reduce conflict and confusion about who is responsible for which 
requirements. There will be overlap. For instance, those responsible for managing network devices 
(network security) will still be required to implement account management (access control) secu-
rity requirements. The suggested groups are
◾
◾Access control: This group covers most aspects of account use and management as well as 
access enforcement. Policies covering granular concepts, such as separation of duties, least 
privilege, roles, rights, and permissions, are candidate members for this group.
◾
◾Audit and accountability: Policy statements on the types of auditing are included in this 
group.
◾
◾Configuration management: Requirements in this collection are critical to system integrity. 
Policies addressing hardware and software inventories as well as required security settings 
are common examples. Configuration management guidance typically requires docu-
mented processes for approving, developing, testing, deploying, and validating changes to 
a system.
◾
◾Contingency planning: This group encompasses a wide range of requirements related to 
threats against system availability. Policies related to disaster recovery, business continuity 

122  ◾  Information Security Management Handbook
planning, and business resumption planning are closely related topics that could be included 
in this collection.
◾
◾Identification and authentication: Requirements covering the creation and management of 
account names, authenticators, and tokens are placed in this group. Security requirements 
specifying account-naming conventions, password complexity, and authenticator protection 
against disclosure are common examples.
◾
◾Incident response: Some organizations have a core team that responds to instances of mal-
ware, data breaches, and denial-of-service attacks. Collecting incident response types of 
requirements into a single group is advisable.
◾
◾Intrusion detection: Operational monitoring for intrusions implies network security. Response 
to a detected intrusion implies incident response. It is reasonable to view intrusion detection 
as a balance between network security requirements and those for incident response. An 
intrusion detection function is handled as a subelement function of the network security 
group in some organizations. For this reason, it is reasonable to gather intrusion detection 
security requirements into their own group.
◾
◾Network security: This group is used to identify the security requirements related to tele-
communication and networking equipment. Security requirements focused on Layer 3 and 
below of the Open Systems Interconnection model are candidates for this group.
◾
◾Operations security: Security guidelines for everyday system management can be placed in 
this group. System availability is usually the focus of those assigned to an operations group. 
In this regard, requirements for failover, shadowing, redundancy, backup, and recover are 
prime candidates for inclusion.
◾
◾Personnel security: Policies specifying the controls and requirements of personnel using the 
system are included in this group. Security requirements involving human resources func-
tions, such as background checks, duty rotation, terminations, and transfers, are examples 
of personnel security items to include.
◾
◾Physical security: The collective requirements for barriers, deterrents, and detective physical 
controls make up this group. In some cases, a system is subject to rules that specify in great 
detail the makeup of the physical components required to protect a system. For example, 
some physical security requirements delineate facility perimeter controls, intrusion detec-
tion, fire detection/suppression, and even construction requirements for sensitive processing 
areas. This group should also include the requirements for environmental factors, such as 
facility power, lighting, temperature, and humidity controls.
◾
◾System security: Explicit guidance for system hosts and devices are included in this group. For 
example, specifications for host-based controls, such as encryption, antivirus, and security 
configurations, are candidates for inclusion.
◾
◾Security management: An organization might be required to implement a security program 
overseeing all aspects of security management. These types of requirements might specify 
the appointment of a chief security officer, Information system security officers, or internal 
system auditors. In many cases, these broad requirements will intersect with or have man-
agement authority over groups with related security requirements.
◾
◾Security awareness and training: Security requirements specifying the training needs for 
managers, users, developers, and administrators are contained in this group. In large organi-
zations, training is sometimes handled by a dedicated personnel office. In smaller organiza-
tions, these requirements are handled by those with security management responsibilities. In 
either case, collecting the requirements into the same group enables efficient management of 
awareness and training programs.

Security Requirements Analysis  ◾  123
Identifier
The security requirement in each row should be unique. The label assigned to each requirement 
should be unique as well. Ideally, the label should contain some meaningful information to help 
identify its relevant group. One way to do this is to construct the identifier to contain an abbre-
viation of the group name. For instance, a requirement in the Audit and Accountability group 
could be to use “AA” as the group abbreviation. Consider again the auditing security requirement 
previously mentioned:
The information system produces audit records that contain sufficient information to establish:
	
a.	What type of event occurred
	
b.	When (date and time) the event occurred
	
c.	Where the event occurred
	
d.	The source of the event
	
e.	The outcome (success or failure) of the event
	
f.	The identity of any user/subject associated with the event
Suppose this is the twelfth security requirement in the audit and accountability (AA) group of 
the SRTM. Each requirement would then be uniquely identified as:
AA-12.a
−
−The information system produces audit records that contain sufficient information to 
establish what type of event occurred.
AA-12.b
−
−The information system produces audit records that contain sufficient information to 
establish when (date and time) the event occurred.
AA-12.c
−
−The information system produces audit records that contain sufficient information to 
establish where the event occurred.
AA-12.d
−
−The information system produces audit records that contain sufficient information to 
establish the source of the event.
AA-12.e
−
−The information system produces audit records that contain sufficient information to 
establish the outcome (success or failure) of the event.
AA-12.f
−
−The information system produces audit records that contain sufficient information to 
establish the identity of any user/subject associated with the event.
Name
The short name is an abbreviated phrase representing the policy statement or requirement. Again, 
this should also be unique to aid in understanding the relevance. The prior list of security require-
ments could have names assigned as follows:
AA-12.a
−
−Event type

124  ◾  Information Security Management Handbook
AA-12.b
−
−Event date and time
AA-12.c
−
−Event location
AA-12.d
−
−Event source
AA-12.e
−
−Event outcome
AA-12.f
−
−Event subject
Description
This field contains the actual language of the requirement. Remember, this is the individual secu-
rity objective from a decomposed policy statement.
Source
Use an abbreviated name in this field of the source document containing the policy statement. Be 
mindful that obscure abbreviations may need to be identified elsewhere. Include revision num-
bers, versions, or dates of the policy to distinguish between published versions.
Related
Security requirements that are related but not listed elsewhere are included in this field. The 
related requirement must be equivalent or a subset of the source with which it is associated. This 
will be discussed in detail next.
Table 10.1 shows how the audit requirement would look in the SRTM.
Requirements Consolidation
A fully populated SRTM will undoubtedly contain redundant statements or objectives. At first, 
it may seem appropriate to simply eliminate one objective in favor of another. This has the first 
disadvantage of not appropriately acknowledging the valid requirements. It has the second disad-
vantage of potentially being inexact. On close examination, similar security objectives often have 
subtle differences. These differences may imply unique requirements. The goal then is to consoli-
date the requirements that are identical and distinguish those that are unique.
The various security policies obtained likely make similar statements. Whenever possible, we 
combine policy statements together by making one the source and the other “Related” in the 
SRTM. A careful review is needed to determine if similarly worded statements actual imply the 
same meaning. Consider the following three policy statements recorded in a hypothetical SRTM 
in Table 10.2.
SS-1 requires scanning of e-mail attachments only before they are opened. This statement has 
some glaring weaknesses that should be questioned. For instance, if the attachment is not opened, 
must scanning be conducted? Likewise, is scanning required at all for the e-mail body itself? Given 
the threats regarding phishing, spyware, spam, and active content embedded in e-mail messages, 
scanning the e-mail message body is imperative.

Security Requirements Analysis  ◾  125
Table 10.1  Example Breakdown of Audit Requirement
Group
Identifier
Name
Description
Source
Related
AA
Audit and 
accountability
AA-12.a
Event type
The information system 
produces audit records 
that contain sufficient 
information to establish 
what type of event 
occurred
NIST 800-53, 
Rev3:AU-3
AA-12.b
Event date and 
time
The information system 
produces audit records 
that contain sufficient 
information to establish 
when (date and time) the 
event occurred
NIST 800-53, 
Rev3:AU-3
AA-12.c
Event location
The information system 
produces audit records 
that contain sufficient 
information to establish 
where the event occurred
NIST 800-53, 
Rev3:AU-3
AA-12.d
Event source
The information system 
produces audit records 
that contain sufficient 
information to establish 
the source of the event
NIST 800-53, 
Rev3:AU-3
AA-12.e
Event 
outcome
The information system 
produces audit records 
that contain sufficient 
information to establish 
the outcome (success or 
failure) of the event
NIST 800-53, 
Rev3:AU-3
AA-12.f
Event subject
The information system 
produces audit records 
that contain sufficient 
information to establish 
the identity of any user/
subject associated with 
the event
NIST 800-53, 
Rev3:AU-3
SS-2 addresses some of the shortcomings of SS-1. At first glance, it may appear that the attri-
butes of SS-1 are completely addressed by SS-2. Suppose SS-2 is decomposed into its two principle 
components represented as SS-2.a and SS-2.b, as seen in Table 10.3.
In this case, SS-1 is not related to SS-2.a, but has a commonality with SS-2.b. Neither SS-2.a 
nor SS-2.b indicate when scanning must be conducted. SS-1 does contain an additional element 

126  ◾  Information Security Management Handbook
Table 10.2  Hypothetical SRTM
Group
Identifier
Name
Description
Source
Related
SS
System security
SS-1
Attachment 
scanning
Scan all e-mail 
attachments with antivirus 
software before opening
P1
SS-2
E-mail scanning
E-mail and attachments 
shall be scanned for 
viruses
P2
SS-3
E-mail threat 
scanning
All incoming and 
outgoing e-mail must be 
scanned for all threats
P3
Table 10.3  Hypothetical SRTM—Decomposing
Group
Identifier
Name
Description
Source
Related
SS
System security
SS-1
Attachment 
scanning
Scan all e-mail 
attachments with 
antivirus software before 
opening
P1
SS-2.a
E-mail scanning #1
E-mail shall be scanned 
for viruses
P2
SS-2.b
E-mail scanning #2
E-mail attachments shall 
be scanned for viruses
P2
SS-3
E-mail threat 
scanning
All incoming and 
outgoing e-mail must be 
scanned for all threats
P3
not found in SS-2.b. In this regard, it would be proper to subordinate SS-2.b to SS-1. These two 
requirements would be rewritten as shown in Table 10.4.
The identifier for P2 is returned back to SS-2 because it cannot be further decomposed. P2 is 
noted as related to P1 because part of its original statement can be contained within the P1 statement.
SS-3 stipulates two requirements:
◾
◾All incoming e-mail must be scanned for all threats.
◾
◾All outgoing e-mail must be scanned for all threats.
Clearly, the policy folks got it right, coming and going. However, we are presented with two 
issues. First, does e-mail, in this requirement, also constitute attachments? Second, what exactly are 
“all threats”? This is where some degree of professional judgment must be used to interpret policy.
It is not unusual when someone refers to e-mail to also mean attachments. By contrast, when 
someone refers explicitly to an e-mail attachment, they generally are not referring to the e-mail 

Security Requirements Analysis  ◾  127
Table 10.4  Hypothetical SRTM—Combining P2 with P1
Group
Identifier
Name
Description
Source
Related
SS
System security
SS-1
Attachment 
scanning
Scan all e-mail attachments 
with antivirus software 
before opening
P1
P2
SS-2
E-mail scanning
E-mail shall be scanned for 
viruses
P2
SS-3
E-mail threat 
scanning
All incoming and outgoing 
e-mail must be scanned for 
all threats
P3
Table 10.5  Hypothetical SRTM—Interpreting P3
Group
Identifier
Name
Description
Source
Related
SS
System security
SS-1
Attachment 
scanning
Scan all e-mail 
attachments with 
antivirus software before 
opening
P1
P2
SS-2
E-mail scanning
E-mail shall be scanned 
for viruses
P2
SS-3.a
Inbound e-mail 
scanning
All incoming e-mail (and 
attachments) must be 
scanned for all threats 
(e.g., malware, phishing, 
spam, etc.)
P3
SS-3.b
Outbound e-mail 
scanning
All outgoing e-mail (and 
attachments) must be 
scanned for all threats 
(e.g., malware, phishing, 
spam, etc.)
P3
message body. In this case, it is not unreasonable to interpret the term “e-mail,” in the case of SS-3, 
to also imply attachments. After all, the most damaging malicious code commonly arrives in e-mail 
as an executable attachment or as an exploit for a vulnerability related to the type of file sent.
Do we really know “all threats” related to e-mail? Arguably, we have not seen every conceivable 
abuse that could be sent via e-mail. But, we know that malware (includes spyware), phishing, and 
spam are ongoing problems associated with e-mail. Our interpretation, therefore, is that “scanned for 
all threats” implies that a tool looks for known types of threats, such as malware, phishing, and spam. 
We bracket these interpretations within the decomposed P3 description to provide clarity and show 
that they are not part of the original statement. We also change the name fields in Table 10.5 to better 
represent the decomposed statements.

128  ◾  Information Security Management Handbook
Table 10.6  Hypothetical SRTM—Consolidated Requirements
Group
Identifier
Name
Description
Source
Related
SS
System security
SS-1.a
Inbound e-mail 
scanning
All incoming e-mail (and 
attachments) must be 
scanned for all threats 
(e.g., malware, phishing, 
spam, etc.)
P3
P1, P2
SS-1.b
Outbound 
e-mail scanning
All outgoing e-mail (and 
attachments) must be 
scanned for all threats 
(e.g., malware, phishing, 
spam, etc.)
P3
P2
Moving along, we now compare SS-1 and SS-2 to the decomposed elements of SS-3. 
Requirement SS-1 is related to SS-3.a because both require antivirus scanning before an attach-
ment is opened. SS-3.a contains additional attributes, such as handling nonmalware threats, 
which are not part of SS-1. In this case, SS-1 can clearly be subordinated to (i.e., contained within) 
SS-3.a.
SS-2 is still a little troublesome because it does not tell us at what point an e-mail must be 
scanned. It only says that it must be accomplished. Once again, we could reasonably assume 
that scanning must be conducted, at a minimum, when the e-mail is received. Fortunately, it is 
irrelevant in this case. It makes no difference what SS-2 requires because SS-3.a and SS-3.b got it 
covered, coming and going. And, because SS-3.a and SS-3.b have additional attributes, SS-2 can 
be subordinated to both. Finally, SS-3.a becomes SS-1.a and SS-3.b is identified as SS-1.b.
The original security requirements are now shown decomposed and combined in Table 10.6.
Associate Phase
In the analysis phase, candidate policies with broad applicability are reduced to their security 
objectives, resulting in a multitude of security requirements. The many candidate security require-
ments populating the SRTM have some degree of relevance to the system according to the attri-
butes used with the initial selection process. Aspects of a given policy are likely to be applicable, 
but perhaps not the whole source. However, is the SRTM complete? Were all needed requirements 
captured? The gap between the known requirements and those that are not known must be closed.
The purpose of the associate phase is to determine what security requirements are needed for 
a given system. This is accomplished from two points of view. The first perspective evaluates the 
known requirements. The second viewpoint seeks what is missing. Each perspective can be con-
sidered by asking the following questions:
◾
◾Which security requirements in the SRTM are applicable or not to the system?
◾
◾Which requirements are suitable?
◾
◾What security requirements are missing from the SRTM?
◾
◾What are the requirement gaps?

Security Requirements Analysis  ◾  129
Security Requirement Suitability
Organizations are compelled to follow policies. Any given policy will express multiple security 
requirements. Some of the requirements will simply not apply. For example, a policy may express 
a number of rules for wireless nodes along with other basic network security guidelines. If, how-
ever, the system does not implement wireless technology, then these requirements would not 
apply. Furthermore, if another policy forbids the use of wireless technology, then these particular 
security requirements would not be suitable. The determination of a requirement’s suitability is 
affected by aspects of the system and other security requirements. Decisions to include or exclude 
a security requirement should be documented.
It may seem easier to simply remove or hide a particular security requirement from the SRTM. 
Why even bother with documenting the decision? It is important to remember that rapid changes 
in systems are a way of life. This often has the undesirable effect of shifting requirements too. 
Tracking the reason for including or excluding a requirement supports continuity of management 
decisions. The question “Why did we include/exclude this requirement?” is bound to come up 
when prior decision makers have moved on. An easy way to support the tracking of decisions is to 
append the following columns in the SRTM:
◾
◾Target purpose: Tracks the interpreted scope of the requirement with respect to the system.
◾
◾Requirement validity: Determines the applicability of the requirement to the system.
◾
◾Validation justification: Identifies other information shaping the determination.
◾
◾Comment: Records clarifying statements for future reference.
Target Purpose
A suitable security requirement has a corresponding purpose with the system. This means that 
the security requirement has an intersecting purpose with the system. This column records an 
interpretation of how the requirement most significantly impacts the system. In other words, the 
purpose of the requirement is deemed to primarily affect the system from a particular perspective. 
These perspectives pertaining to the system can be broadly categorized as
◾◾Intended operations: Security requirements that are focused on people and processes using and 
managing the system. These include user types and anticipated use of the system. A requirement 
from this perspective may impart guidance regarding various types of system users. Or it might 
provide guidance on the proper use or management of the system.
◾
◾Target data: Not all data is created equal. Some types of data can have very explicit, if not 
unique, security requirements. This perspective is reserved for the security requirements that 
are directed at a class of sensitive data. Data related to an individual’s privacy, legal, finan-
cial, or health are example classes of sensitive data commonly addressed by unique security 
requirements. In some cases, a particular type of data is prohibited. Requirements of this 
type are also good candidates for this category.
◾
◾Functional capability: The physical and logical attributes of a system are some of the best 
ways to implement security requirements. System architecture, such as physical loca-
tion, connectivity, and technology, can be used to directly enforce policy. A security 
requirement addressing a particular technology is a prime candidate for this category. 
However, technology-specific security requirements are the exception as opposed to the 
rule. More typically, security requirements specify concepts enforceable by a wide range 

130  ◾  Information Security Management Handbook
of technologies. For example, password lengths are a functional capability supported 
by many technologies. Policies expressing minimum requirements are quite common. 
Security requirements that are enforceable by system design and technology implemented 
are best placed in this category.
Requirement Validity
As previously mentioned, not every requirement from a given policy applies to all systems. The 
decision and reason to include or exclude a requirement should be documented. Recording the 
reason conveys, to some extent, the thought process used to arrive at the decision. Most impor-
tantly, recording this type of information illustrates a degree of due diligence with respect to the 
security requirements. Within this column, the applicability of a requirement objective is identi-
fied as one of the following:
◾
◾Applicable: The security requirement applies to the system. Aspects of the requirement apply 
to the operational, data, or functional attributes of the system.
◾
◾Unsuitable: The requirement objective does not address a planned or implemented func-
tional attribute of the system. For example, E-commerce security requirements would not 
apply to a system not processing financial transactions and without a public-facing interface 
(e.g., E-commerce Web server).
◾
◾Prohibited: Attributes of the requirement are not allowed. Suppose a security requirement 
discusses appropriate uses of peer-to-peer (P2P) technology. However, P2P may be prohib-
ited in the target system. In this case, any P2P security requirements would be marked as 
prohibited.
◾
◾Irrelevant: The requirement objective is not pertinent to the system. This choice primarily 
applies to data types. For instance, a security requirement discussing health-related informa-
tion probably would not apply to a system supporting E-commerce.
Validation Justification
A security requirement applies when it touches on an aspect of the operations, data, or func-
tionality of the system. A requirement would not apply when it contracts other guidance or fact. 
Pointing to the relevant guidance is needed to support the requirement validity. Supporting evi-
dence is needed to affirm that the decision to include or exclude a security requirement was done 
properly. Evidence to support the decision is best obtained from:
◾
◾Existing policy: It is not rare for security requirements to contradict each other. For example, 
one requirement might call for passwords with a minimum length of six characters while 
another requires eight. Generally, one policy trumps the other or the more rigid requirement 
becomes the standard.
◾
◾Design documentation: Most validation justifications for a requirement validity that is appli-
cable would point to this justification. System documentation should contain enough infor-
mation to allude to the intended operations, data types, and functional capabilities of the 
system. Likewise, the security requirements, unsuitable or irrelevant, would also rely on 
design documentation for justification.
◾
◾Security documentation: Specialized documents, such as security plans, configuration 
guidance, and other standards, are reliable sources. These sources are particularly 

Security Requirements Analysis  ◾  131
useful when they describe implemented security controls directly related to the security 
requirement.
◾
◾Management decision: Risk acceptance and the authority to operate statements are prime 
examples of management decisions conveying what is and is not allowed. Sometimes, 
managers express decisions in memorandums and other less than formal communications. 
Regardless of the medium, communications representing a management directive are a valid 
means of justifying requirement validity.
It is important to note that evidence supporting validation justification constitutes something 
in writing. That something becomes an artifact supporting the due diligence decision to include 
or exclude a candidate security requirement. The artifact of the evidence should be clearly identi-
fied. In this column, record the path to the artifact document supporting the justification of the 
requirement validity.
Comment
Sometimes, a few words of wisdom can clarify a murky situation. Use a comments column to 
record information that may help others better understand the decisions made or find pertinent 
documents. Avoid recording anything that does not clarify and contribute to understanding the 
decisions made.
Security Requirement Gaps
Policies are broadly applicable, but this does not imply that they provide comprehensive cover-
age. In some cases, a policy may not go far enough to require adequate security. The security 
objectives stated are weak. This occurs when those crafting the policy seek to make it broadly 
applicable. Sometimes, the intent is to set a low threshold in the hope that the system owners 
will build on it. A nonexplicit policy can create unintentional weaknesses in a system. In other 
cases, policies simply do not address critical security needs. The policy is often far behind the 
rapid advancements of technology and threats. System owners may not have considered the 
need for additional requirements. This has the potential effect of introducing weaknesses in 
the system as well.
Weak Security Objectives
Vague security requirements are a common occurrence. It is important to consider how a secu-
rity requirement might be enforced by a system or put into practice. Begin by comparing the 
requirement to the system design and the security architecture of the system. Typically, a security 
requirement can be implemented any number of ways. For instance, our audit requirements given 
in Table 10.1 are a good example of this situation. Clearly, auditing must be implemented, but how 
and where? Places where auditing can be implemented include:
◾
◾Applications
◾
◾Workstations
◾
◾File servers
◾
◾Systems services
◾
◾Databases

132  ◾  Information Security Management Handbook
◾
◾E-mail servers
◾
◾Web servers
◾
◾Network devices
Where should auditing be implemented? Should it be in all these locations or only at selected 
ones? To some extent, the decision becomes a judgment call. Recall that AA-12.f from Table 10.1 
states:
◾
◾The information system produces audit records that contain sufficient information to estab-
lish the identity of any user/subject associated with the event.
This could be loosely interpreted as, “Turn on auditing wherever it’s needed to identify an 
attacker” or it might also be implying, “Turn on auditing in at least one place to identify who is 
doing what.” The problem here is that we have the what of auditing but not the where. This vague-
ness hinders interpretation and may result in a poor implementation decision.
The common ailment of weak security objectives is a lack of specificity about the breadth or 
the depth of an implementation. Think of breadth, of how wide a requirement applies. How many 
different types of things or like items should implement the requirement? Insufficient breadth 
quickly translates into insufficient coverage. By contrast, depth refers to how many layers into an 
item the requirement should be implemented. Undetected or unmitigated compromises become 
possible when depth is missing. Inadequate depth implies a lack of defense-in-depth.
Missing Security Requirements
It is unlikely that policy makers will keep up with the advancing technology and the evolving 
threats. This is immediately apparent to the security practitioner who is asked to evaluate a new 
technology implemented in a system. It becomes even more painfully apparent when the technol-
ogy becomes a new attack vector. However, missing security requirements need not arise from 
something new. The need for new security requirements can be found over time through common 
system and security management activities. Some of the activities providing the best likelihood of 
identifying missing security requirements include:
◾
◾System changes: A change itself may call out for a new security requirement. In some cases, 
investigating a change reveals another system weakness occurring due to a lack of security 
requirements.
◾
◾Security assessments: Skilled security assessors sometimes discover a unique attack vector to 
compromise a system under test. Trivial attack vectors are the most serious and require miti-
gating controls. Explaining the importance of mitigating the weakness to system managers 
is sometimes challenging. This alone cries out for explicit security requirements needed to 
close the gap.
◾
◾Risk assessments: New threats should be addressed in a system’s periodic risk assessment. 
The assessment should seek to determine if existing requirements adequately address new 
threats. Risk assessment results should call for new security requirements or security controls 
when threat mitigation is deemed insufficient.
◾
◾Mission/system objectives: Changes to organizational and system objectives may introduce 
weaknesses insufficiently addressed by policy. Innovative uses of technology to meet mission 
objectives can place systems in locations not previously considered. Explicit requirements 

Security Requirements Analysis  ◾  133
for protecting the system in a new environment might not exist. Similarly, integrating a 
system with new technology to meet expanding objectives is another challenge. Integrated 
technology can make a new weakness apparent. However, a policy identifying the appropri-
ate controls for this instance may not have been conceived as of yet.
Security gaps are serious and should be addressed as quickly as possible. Whether the gap arises 
from weak statements or missing requirements, proactive measures are needed. Those necessary 
measures are handled in the next phase of the SRAM.
Integrate Phase
Security requirements that are identified, analyzed, and associated with the systems are ready for 
integration. The first step is to ensure that proactive measures are undertaken for the identified 
gaps. Next, the formal integration of policy needs and requirement gaps is merged with the sys-
tem security policy. Lastly, the system security plan is updated to reflect the security requirement 
changes.
Proactive Measures
Security requirement gaps should be addressed as quickly as possible. There are a number of 
avenues that a security professional can take to proactively close a gap. Some of the common 
methods used include:
◾
◾Policy changes: Work with local management to create a policy or standard stipulating the 
new requirement. This could mean an amendment to an existing policy or the creation of 
something new. In some cases, it could also mean removing defunct requirements from an 
existing policy.
◾
◾Design alterations: Coordinate the change of the system design or security architecture. 
Removing software or hardware is sometimes an easy fix to a problem. In other situations, 
applying existing security controls in a manner compliant with an existing policy to assuage 
the problem is another approach.
◾
◾Risk management: In some organizations, risk assessments are the primary tool used to push 
for changes affecting the security gaps. Formal risk management has the advantage of docu-
menting threats leveraging a policy gap and the potential impact. The potential magnitude 
of harm may be sufficient to warrant immediate changes to the system as well as the policy.
◾
◾Management decisions: A memorandum from top management can be enough to require a 
change to be made. While this might not carry the finesse of a full risk assessment, it can 
help expedite changes to accommodate a critical gap.
System Security Policy
The identify phase of the SRAM suggested business objectives, user needs, and risk acceptance, as 
well as education and experience, as possible security requirement sources. Ordinarily, these policy 
needs would not be referred to directly as security requirements. Legitimate security requirements 
come from an authority. This is to say, it should be specified in writing by organizational manage-
ment or some governmental body. A policy need might be considered a gap when serious. However, 
disagreements over severity and interpretation may dissuade management to take immediate action. 

134  ◾  Information Security Management Handbook
In any event, policy needs should be given appropriate authority through policy. Since these needs 
are particular to a given system, they should be included in the system security policy.
A system security policy is specific to a particular system. This type of documentation is an 
underused tool essential to the SRAM. It should contain the necessary requirements not identi-
fied in other policies or security requirements. Requirements in the system security policy serve 
to bridge the gap between the system and the applicable security objectives from other policies. It 
can also be used as the source to record policy interpretations. This makes it an ideal reference for 
the validation justification as well.
System Security Plan
The final step in the SRAM is to update the associated system security plan. Changes to the 
security requirements affect the security controls designated through the system security plan. 
A comparison of the security requirements versus the planned and implemented controls is 
needed to ensure that the gaps between the policy and the security architecture are identified 
and accommodated when needed.
SRAM Cycle
The intent of the SRAM is to support continuous monitoring of the system. This cycle should be 
periodically repeated as necessary. There are a number of events that should trigger a run through 
the cycle. Some of these event triggers include:
◾
◾Known policy changes: Updates to any policy in the SRTM is a good time to review all associ-
ated policies.
◾◾Risk assessments: Changes to risk posture or new threats may reveal security requirement gaps.
◾
◾Security assessments: System weaknesses or trivial attack vectors are another source of poten-
tial security requirement gaps.
◾
◾System changes: Adding or removing system components could change the security require-
ment validity.
◾
◾Defined period: Minimally, the SRAM should be associated with a key anniversary date, 
such as a system accreditation or authorization cycle. In some cases, a mandatory annual 
review may be more appropriate.
Summary
A security requirements analysis is an important function in security management. Improper 
identification of requirements can at best make a system an easy target for auditors and at worse 
enable an exploitable weakness. Rapid advances in technology and threats quickly date many poli-
cies. Using a defined SRAM is one way to implement continuous monitoring to counteract the 
rapid changes. The SRAM consists of phases that Identify, Analyze, Associate, and Integrate life-
cycle security requirements. The identified security requirements must be analyzed for inclusion in 
the SRTM. Suitable security requirements contained in the SRTM are those associated with the 
system. Lastly, integrating applicable security requirements and mitigating identified gaps into a 
system security policy and system security plan are essential to security management.

135
Chapter 11
CERT Resilience Management 
Model: An Overview
Bonnie A. Goins Pilewski and Christopher Pilewski
The CERT ® Resilience Management Model (CERT-RMM) is a process model that seeks to 
improve the management of risk and maintain operational resilience for an organization. It does 
this by aligning the business continuity management and IT operations and security management 
disciplines. It also brings the concept of quality and process management into the organization. 
CERT defines quality as “the extent to which an organization controls its ability to operate in a 
mission-driven, complex risk environment [CMMI Product Team 2006].”
With the advent of RMM, the model seeks to present the disciplines above in a process 
approach, which allows the organization to apply process improvement mechanisms, as well as 
to develop a basis for metrics and measurement. As most security professionals have experienced 
within their careers, it is difficult at best to craft meaningful metrics for security implementation; 
as such, any tool that would assist in this capacity is very welcome indeed! It also provides a unified 
framework for organizing the work in the field that is performed within the organization. As is true 
with process maturity models, such as the Capability Maturity Model for Integration (CMMI), 
RMM provides a base for process institutionalization and organizational process maturity.
CERT-RMM v1.0 contains 26 process areas that cover four areas of operational resilience 
management: enterprise management, engineering, operations, and process management. The 
practices focus on the activities that an organization performs to actively direct, control, and man-
age operational resilience. The model does not prescribe specifically how an organization should 
secure information. Instead, it focuses on identifying critical information assets, making decisions 
about the activities and controls required to protect and sustain these assets, implementing strate-
gies to achieve asset control, and maintaining control throughout the life of the assets.
The process areas and theirs tags are represented in the Table 11.1.
The model is managed much the same as the CMMI and includes the following levels for 
measurements:
Level 0: Incomplete
Level 1: Performed

136  ◾  Information Security Management Handbook
Level 2: Managed
Level 3: Defined
Levels 4 and 5: Quantitatively Managed and Optimizing
As stated in the CERT-RMM Report, RMM includes: a process definition, expressed in capa-
bility areas across the four RMM framework competencies (enterprise management, engineering, 
Table 11.1  Process Area Tags
Process Area
Tag
Asset Definition and Management
ADM
Access Management
AM
Communications
COMM
Compliance
COMP
Controls Management
CTRL
Environmental Control
EC
Enterprise Focus
EF
External Dependencies Management
EXD
Financial Resource Management
FRM
Human Resource Management
HRM
Identity Management
ID
Incident Management and Control
IMC
Knowledge and Information Management
KIM
Measurement and Analysis
MA
Monitoring
MON
Organizational Process Definition
OPD
Organizational Process Focus
OPF
Organizational Training and Awareness
OTA
People Management
PM
Risk Management
RISK
Resilience Requirements Development
RRD
Resilience Requirements Management
RRM
Resilient Technical Solution Engineering
RTSE
Service Continuity
SC
Technology Management
TM
Vulnerability Analysis and Resolution
VAR

CERT Resilience Management Model: An Overview  ◾  137
operations management, and process management); focus on the resiliency of four essential 
operational assets (people, information, technology, and facilities); the inclusion of processes 
and practices that define a scale of five capability levels for each capability area (incomplete, per-
formed, managed, directed, and continuously improved); and easily aligns with and references 
common codes of practice such as ISO27000, ITIL, COBIT, and others, such as BS25999 and 
ISO24762.
RMM also includes quantitative process metrics and measurements that can be used to ensure 
that operational resiliency processes perform as intended.
Key Components of the RMM
RMM capability areas define the resiliency engineering process. Each capability area has a set of 
goals. Goals are required elements of the capability area. An example of a goal from the Service 
Continuity (SC) capability area is “SC-1 Prepare for Service Continuity.” These goals are bro-
ken down into specific practices. Specific practices are considered to be the “base practices” of 
the capability. An example of a specific practice from the SC capability area is “SC-1.1 Plan for 
Service Continuity,” which is a practice aimed at completing the goal “SC-1 Prepare for Service 
Continuity.”
These practices are also broken down into subpractices. Subpractices are neither specific nor 
detailed, but help the user determine how specific practices are implemented and how this helps 
achieve the goals of the capability area. Each organization will have its own subpractices either 
organically developed by the organization or acquired from a code of practice.
Subpractices can be linked to common codes of practice. Subpractices are typically generic in 
nature, while codes of practice can be very specific. For example, a subpractice may suggest “set 
password standards and guidelines” while a specific code of practice may state that “passwords 
should be changed in no longer than 90 day intervals.”
Examples of common codes of practice are detailed next, as detailed in the RMM Report.
BS 25999
BS 25999 is the British Standards Institution’s (BSI’s) code of practice and specification for busi-
ness continuity management. The purpose of the standard is to provide a basis for understanding, 
developing, and implementing business continuity within an organization and to provide confi-
dence in the organization’s dealings with the customers and other organizations.
There are two BS 25999 documents: the Code of Practice, BS 25999-1:2006 [BSI 2006] and 
the specification, BS 25999-2: 2007 [BSI 2007].
COBIT
COBIT is the Control Objectives for Information and Related Technology [ITGI 2007]. It was 
developed by the Information Systems Audit and Control Association (ISACA) and the IT 
Governance Institute (ITGI) to provide managers, auditors, and IT users with generally accepted 
information technology control objectives to maximize IT benefits and ensure appropriate IT 
governance, security, and control.
References are also made to Val IT [ITGI 2006] in this document. Val IT is a reference frame-
work that addresses the governance of IT-enabled business investments.

138  ◾  Information Security Management Handbook
COSO Enterprise Risk Assessment
In 2004, the Committee of Sponsoring Organizations of the Treadway Commission (COSO) issued 
an enterprise risk management framework to help organizations enhance their corporate governance 
and risk management activities [COSO 2004]. The ERM integrated framework provides a broader 
risk management view that encompasses COSO’s original focus on internal controls.
CMMI
CMMI ® 3 is a process improvement maturity model for the development of products and services. 
It has several constellations or areas of interest that provide application-specific models that share 
common content.
The CMMI for Development (CMMI-DEV) represents the systems and software develop-
ment domain [CMMI 2006]. In addition, the CMMI for Services (CMMI-SVC) constellation is 
represented by a draft CMMI model designed to cover the activities required to manage, establish, 
and deliver services [SEI 2007].
DRJ/DRII Gap
The DRJ/DRII GAP (Generally Accepted Practices) is put forth jointly by the Disaster Recovery 
Journal (DRJ) and the Disaster Recovery Institute International [DRJ 2007]. GAP is a set of 
identified and documented standards and guidelines that aim to create a depository of knowledge 
by and for the business continuity profession. The practices are aligned with DRII’s 10 areas of 
professional practice, as detailed in the DRII Professional Practice Guidelines.
FFIEC
The Federal Financial Institutions Examination Council (FFIEC) publishes a series of booklets 
that comprise the FFIEC Information Technology Examination Handbook. These booklets are 
published to help bank examiners with evaluation of financial institutions and service provider risk 
management processes, with the goal being to ensure the availability of critical financial services.
ISO/IEC 20000-2: 2005 (E)
ISO/IEC 20000 is a standard and code of practice for IT service management published by 
the International Organization for Standardization and the International Electrotechnical 
Commission (ISO/IEC). It is based on (and supersedes) the earlier British Standard BS 15000. It 
reflects the best practice guidance for IT service management as provided in the ITIL (Information 
Technology Infrastructure Library) framework, but also broadly covers other service management 
standards.
ISO/IEC 24762: 2008
ISO/IEC 24762, “Guidelines for information and communications technology disaster recovery 
services” [ISO/IEC 2008], is part of the business continuity management standards published 
by ISO/IEC. It can be applied in-house or to outsourced providers of disaster recovery physical 
facilities and services.

CERT Resilience Management Model: An Overview  ◾  139
ISO/IEC 27002: 2005
ISO/IEC 27002, “Code of Practice for Information Security Management” [ISO/IEC 2005b], is 
also published by ISO/IEC. It is part of a growing “27000 series” that evolved from the original 
British Standard BS 7799, which was translated to ISO standard ISO 17799.
NFPA 1600
NFPA 1600 is the National Fire Protection Agency Standard on Disaster/Emergency Management 
and Business Continuity Programs [NFPA 2007]. It is primarily focused on the development, 
implementation, and operation of disaster, emergency, and business continuity programs, includ-
ing the development of various types of related plans. The 2007 edition of this standard was used 
for reference and is an update of the 2004 standard.
Crossmapping
Materials are available that demonstrate the relationship among existing standards, their constitu-
ent relationships, and the RMM framework.
Figure 11.1 illustrates the relationship of RMM to these bodies of knowledge.
Common and derived
process areas
CMMI-DEV
CMMI-ACQ
Common “services” object
Subpractices connect
to common practices
Bodies of knowledge and codes of practice
[ITIL, CobiT, ISO2700x, BS25999,
NFPA 1600, PCI DSS. . .]
CERT-RMM
process areas
CERT-RMM
generic goals/
practices
CERT-RMM
typical work
products and
subpractices
Generic goals
and practices
CMMI-SVC
Figure 11.1  Relationship of CERT-RMM to CMMI process areas and bodies of knowledge.

140  ◾  Information Security Management Handbook
Process Areas
Table 11.2 represents the process areas of the RMM, by category.
These process areas also have equivalents in other process models, such as CMMI. This allows the 
user to align resiliency processes with ongoing work in the integration activities of the organization.
Table 11.2  Process Areas by Category
Category Process Area
Engineering Asset Definition and Management
Engineering Controls Management
Engineering Resilience Requirements Development
Engineering Resilience Requirements Management
Engineering Resilient Technical Solution Engineering
Engineering Service Continuity
Enterprise Management Communications
Enterprise Management Compliance
Enterprise Management Enterprise Focus
Enterprise Management Financial Resource Management
Enterprise Management Human Resource Management
Enterprise Management Organizational Training and Awareness
Enterprise Management Risk Management
Operations Access Management
Operations Environmental Control
Operations External Dependencies Management
Operations Identity Management
Operations Incident Management and Control
Operations Knowledge and Information Management
Operations People Management
Operations Technology Management
Operations Vulnerability Analysis and Resolution
Process Management Measurement and Analysis
Process Management Monitoring
Process Management Organizational Process Definition
Process Management Organizational Process Focus

CERT Resilience Management Model: An Overview  ◾  141
The alignment between CMMI and RMM is represented in Table 11.3.
RMM also contains the generic goals and practices that the organization implements to 
improve its organizational processes and capability to manage its environment toward resiliency 
of its operations. These practices exhibit the organization’s commitment and ability to perform 
resilience management processes, as well as its ability to measure performance and verify imple-
mentation. Generic processes are detailed in the RMM for use where noted.
Table 11.3  CMMI to RMM Alignment
CMMI Models Process Areas
Equivalent CERT-RMM Process Areas
CAM – Capacity and Availability 
Management (CMMI-SVC only)
TM – Technology Management
CERT-RMM addresses capacity management from 
the perspective of technology assets. It does not 
address the capacity of services. Availability 
management is a central theme of CERT-RMM, 
significantly expanded from CMMI-SVC. Service 
availability is addressed in CERT-RMM by 
managing the availability requirement for people, 
information, technology, and facilities. Thus, the 
process areas that drive availability management 
include
RRD – Resilience Requirements Development 
(where availability requirements are established)
RRM – Resilience Requirements Management 
(where the life cycle of availability requirements is 
managed)
EC – Environmental Control (where the availability 
requirements for facilities are implemented and 
managed)
KIM – Knowledge and Information Management 
(where the availability requirements for 
information are implemented and managed)
IRP – Incident Resolution and 
Prevention (CMMI-SVC only)
IMC – Incident Management and Control. In 
CERT-RMM, IMC expands IRP to address a broader 
incident management system and incident life 
cycle at the asset level
MA – Measurement and Analysis
MA – Measurement and Analysis is carried over 
intact from CMMI. In CERT-RMM, MA is directly 
connected to MON
OPD – Organizational Process 
Definition
OPD – Organizational Process Definition is carried 
over from CMMI
OPF – Organizational Process Focus
OPF – Organizational Process Focus is carried over 
intact from CMMI
(continued)

142  ◾  Information Security Management Handbook
The alignment of generic practice to process area and its subsequent implementation in the 
organization is given in Table 11.4.
Engineering Process
Given that aspects of operational resilience management are requirements-driven, process areas in 
the Engineering category represent those that are focused on establishing and implementing resil-
ience for organizational assets and business processes. These processes establish the basic building 
blocks for resilience and create the foundation to protect and sustain the assets.
Engineering process areas fall into three broad categories:
Requirements Management addresses the development and management of the security (pro-
tect) and resilience (sustain) objectives for assets and services.
Asset Management establishes the important people, information, technology, and facilities as 
assets present in the organization.
Establishing and Managing Resilience addresses the selection, implementation, and management 
of preventive controls. In addition, it addresses the development and implementation of 
SC and impact management plans and programs. It also recommends the consideration of 
resilience for software and systems early in the development life cycle.
Table 11.3 (Continued)  CMMI to RMM Alignment
CMMI Models Process Areas
Equivalent CERT-RMM Process Areas
OT – Organizational Training
OTA – Organizational Training and Awareness. OT 
is expanded to include awareness activities in OTA
REQM – Requirements 
Management
RRM – Resilience Requirements Management. 
Basic elements of REQM are included in RRM, but 
the focus is on managing the resilience 
requirements for assets and services
RD – Requirements Development
RRD – Resilience Requirements Development 
Basic elements of RD are included in RRM
RSKM – Risk Management
RISK – Risk Management Basic elements of RSKM 
are reflected in RRM
SAM – Supplier Agreement
Management
EXD – External Dependencies Management In 
CERT-RMM, SAM is expanded to address all 
external dependencies
SCON – Service Continuity
(CMMI-SVC only)
SC – Service Continuity In CERT-RMM, SC is 
positioned as an operational risk management 
activity that addresses what is required to sustain 
assets and services balanced
TS – Technical Solution
RTSE – Resilient Technical Solution Engineering

CERT Resilience Management Model: An Overview  ◾  143
Table 11.4  Generic Process Mapped to Related Process Area
Generic Practice
Related Process Area
How the Process Area Helps 
Implement the Generic Practice
GG2.GP1
Establish process 
governance
Enterprise Focus
Enterprise Focus addresses the 
governance aspect of managing 
operational resilience. Mastery of the 
Enterprise Focus process area can help 
achieve GG2.GP1 in other process 
areas
GG2.GP3
Provide resources
Human Resource 
Management
Financial Resource 
Management
Human Resource Management 
ensures that resources have the 
proper skill sets and their 
performance is consistent over time. 
Financial Resource Management 
addresses the provision of other 
resources to the process, such as 
financial capital
GG2.GP4
Train people
Organizational Training 
and Awareness
Organizational Training and 
Awareness ensures that resources are 
properly trained
GG2.GP8
Monitor and control 
the process
Monitoring
Measurement and 
Analysis
Monitoring provides the structure and 
process for identifying and collecting 
relevant information for controlling 
processes. Measurement and Analysis 
provide general guidance about 
measuring, analyzing, and recording 
information that can be used in 
establishing measures for monitoring 
actual performance of the process 
[CMMI 2007]
GG2.GP10
Review status with 
higher level managers
Enterprise Focus
As part of the governance process, 
Enterprise Focus requires oversight of 
the resilience process including 
identifying corrective actions
GG3.GP1
Establish a defined 
process
Organizational Process 
Definition
Organizational Process Definition 
establishes the organizational process 
assets necessary to implement the 
generic practice [CMMI 2007]
GG3.GP2
Collect improvement 
information
Organizational Process 
Definition
Organizational Process 
Focus
Organizational Process Definition 
establishes the organizational process 
assets. Organizational Process Focus 
addresses the incorporation of 
experiences into the organizational 
process assets [CMMI 2007]

144  ◾  Information Security Management Handbook
The Engineering process areas include:
Requirements Management
Resilience Requirements Development (RRD)
Resilience Requirements Management (RRM)
Asset Management
Asset Definition and Management (ADM)
Establishing and Managing Resilience
Controls Management (CTRL)
Resilient Technical Solution Engineering (RTSE)
Service Continuity (SC)
Operations
The Operations process areas represent the core activities for managing the operational resilience 
of assets and services during this life-cycle phase. These process areas are focused on maintaining 
an acceptable level of operational resilience as determined by the organization. These process areas 
represent core security, business continuity, and IT operations/service delivery management activi-
ties. Areas of focus include the resilience of people, information, technology, and facilities assets.
Operations process areas fall into three broad categories:
Supplier Management addresses the management of external dependencies and the potential 
impact on the organization’s operational resilience.
Threat, Vulnerability, and Incident Management addresses the organization’s continuous cycle of 
identifying and managing threats, vulnerabilities, and incidents to minimize organizational 
disruption.
Asset Resilience Management addresses the asset-level activities that the organization performs 
to manage operational resilience of people, information, technology, and facilities to ensure 
that business processes and services are sustained.
The Operations process areas are:
Supplier Management
External Dependency Management (EXD)
Threat and Incident Management
Access Management (AM)
Identity Management (ID)
Incident Management and Control (IMC)
Vulnerability Analysis and Resolution (VAR)
Model Relationships
To understand how the elements of the process model translate to relationships in the environ-
ment, a number of maps have been created. These maps are depicted below.

CERT Resilience Management Model: An Overview  ◾  145
People
Figure 11.2 shows the CERT-RMM process areas that participate in managing the operational 
resilience of people. They establish people as an important asset in service delivery and ensure that 
people meet job requirements and standards, have appropriate skills, are appropriately trained, and 
have access to other assets as needed to do their jobs.
Information
Figure 11.3 shows the CERT-RMM process areas that drive the operational resilience manage-
ment of information. Information is established as a key element in service delivery. Requirements 
for protecting and sustaining information are established and used by processes such as risk man-
agement, controls management, and SC planning.
Communications
requirements and
standards
SC
Requirements
for
sustainment
strategies
Operational resilience
plan and program
Resilience standards
and policies
Governance and
oversight
RRD
RRM
CTRL
Risk drivers, appetite,
and tolerances
Strategies to mitigate
risk
Strategies to mitigate
risk
EF
FRM
COMP
COMM – Communications
COMP – Compliance
CTRL – Controls Management
EF – Enterprise Focus
EXD – External Dependencies Management
FRM – Financial Resource Management
HRM – Human Resource Management
IMC – Incident Management and Control
MON – Monitoring
OTA – Organizational Training and Awareness
RISK – Risk Management
RRD – Resilience Requirements Development
RRM – Resilience Requirements Management
SC – Service Continuity
VAR – Vulnerability Analysis and Resolution
HRM
IMC
COMM
Communications
training requirements
EXD
Guidelines for
communicating with
external entities
OTA
Committed
funds
Cost and performance
analysis
RORI
Compliance plan and
program
Compliance
requirements and
standards
Skill deﬁciencies and
training needs
Governance and
oversight
Compliance data
MON
RISK
Risks due to
noncompliance
Vulnerabilities
Data for governance
and decision making
Funding
needs
Requirements
for protection
strategies
Strategic
objectives
and CSFs
Communications plan
and program
Communications
requirements
Operational
Resilience
Management
Program
Resilience goals and
objectives
Guidelines for
communicating about
incidents
Awareness
requirements
VAR
Figure 11.2  Enterprise-level relationships.

146  ◾  Information Security Management Handbook
Technology
Figure 11.4 shows the CERT-RMM process areas that drive the operational resilience manage-
ment of technology. These relationships address the complexities of software and systems resil-
ience, as well as the resilience of architectures where the technology assets live, their development 
and acquisition processes, and other processes such as configuration management and capacity 
planning and management.
Facilities
Figure 11.5 shows the CERT-RMM process areas that drive the operational resilience manage-
ment of facilities. As with information and technology assets, relationships that drive the resilience 
Enterprise
Processes
Governance and
oversight
Internal control
system
Mission, objectives
Risk appetite,
tolerances
Services
Services dependent
on key people
Vital staﬀ
Staﬀ
Control objectives for
hiring, training, and
deploying staﬀ
Staﬀ availability
requirements
Staﬀ availability
requirements
Return-to-work
considerations
Redeployment plans
Traing and
awareness needs
Traing and
awareness activities
Skill needs
Hiring strandards
Redundancy and
succession plans
Risks due to lack of
staﬀ availability
Performance
standards
Skills and training
gaps 
Staﬀ availability
requirements
Staﬀ availability
requirements
RRD
CTRL
ADM
EF
RISK
PM
HRM
OTA
RRM
ADM – Asset Deﬁnition and Management
PM – People Management
RRD – Resilience Requirements Deﬁnition
RRM – Resilience Requirements Management
RISK – Risk Management
SC – Service Continuity
CTRL – Controls Management
EF – Enterprise Focus
HRM – Human Resource Management
OTA – Organizational Training and Awareness
SC
Figure 11.3  Relationships that drive the resilience of people.

CERT Resilience Management Model: An Overview  ◾  147
of facilities have special considerations, such as protecting facilities from disruption, ensuring 
that facilities are sustained, managing the environmental conditions of facilities, determining the 
dependencies of facilities on their geographical region, and planning for the decommissioning of a 
facility. Because facilities are often owned and managed by an external party, consideration must 
also be given to how external parties implement and manage the resilience of facilities at the direc-
tion of the organization (Figure 11.6).
Understanding Capability Levels
Like the standards that were described earlier in this chapter, CERT-RMM is not a prescriptive 
model. Process improvement is unique to each organization and, as such, CERT-RMM provides 
the basic structure to allow organizations to chart their own specific improvement path using the 
model as the basis.
Improvement paths are defined in RMM by capability levels. Levels characterize improvement 
from a poorly defined state to a state where processes are characterized and used consistently across 
the organization.
Enterprise
Processes
Internal control
system
CTRL
Governance and
oversight
Services
Mission, objectives
EF
ADM
Risk appetite,
tolerances
Risks to information
assets
KIM
RISK
Risk mitigation
strategies
Information
vulnerabilities
Information incident
reports
Incidents involving
information
Information access
privileges
AM
ID
IMC
VAR
Information
vulnerabilities
Identities and
roles
Information assets
used by services
High-value
information assets
Information assets
Information control
objectives
Requirements for
information control
objectives
RRD
SC
Information resilience
requirements
RRM
Information
availability
requirements
ADM – Asset Deﬁnition and Management
IMC – Incident Management and Control
KIM – Knowledge and Information Management
RISK – Risk Management
RRD – Resilience Requirements Development
RRM – Resilience Requirements Management
AM – Access Management
CTRL – Controls Management
EF – Enterprise Focus
ID – Identity Management
SC – Service Continuity
VAR – Vulnerability Analysis
            and Resolution
Information resilience
requirements
Information asset
repository
Institutional
knowledge
Vital records
Figure 11.4  Relationships that drive information resilience.

148  ◾  Information Security Management Handbook
To reach a particular level, an organization must satisfy all of the relevant goals of the process 
area (or a set of process areas), as well as the generic goals that apply to the specific capability level. 
The structure of the continuous representation for CERT-RMM is provided in Table 11.5.
Connecting Capabilities to Process Maturity
Capability levels describe the degree to which a process has been institutionalized. Likewise, the 
degree to which a process is institutionalized is defined by the generic goals and practices. Table 11.5 
links capability levels to the progression of processes and generic goals.
The progression of capability levels and the degree of process adoption are characterized by the 
following descriptions.
Capability Level 0: Incomplete
An incomplete process is a process that either is not performed or is partially performed. This leads 
to one or more of the specific goals of the process area not being satisfied. [CMMI 2007].
Enterprise
Processes
Governance and
oversight
Internal control
system
Services
Mission, objectives
Risk appetite,
tolerances
EF
RISK
Risk mitigation
strategies
Risk to technology
assets
Incident reports
for technology
Incidents involving
technology 
Software and systems
access privileges
Resilience-focused
technology assets
Integrity and
availability
requirements for
technology
High-value
technology assets
RTOs, RPOs,
continuity plans
Identities and roles
Technology
availability
requirements
Technology assets
used by services
High-value
technology assets
Technology assets
Control objectives for
software and systems
Resilient developement
and integration
guidelines
Technology assets in
developement
Guidelines for
determining resilience
requirements
Technology resilience
requirements
RRM
ADM – Asset Deﬁnition and Management
IMC – Incident Management and Control
SC – Service Continuity
TM – Technology Management
VAR – Vulnerability Analysis and Resolution
RISK – Risk Management
RRD – Resilience Requirements Development
RRM – Resilience Requirements Management
RTSE – Resilient Technical Solution Engineering
EXD – External Dependencies Management
CTRL – Controls Management
EF– Enterprise Focus
ID – Identity Management
AM – Access Management
RRD
TM
ID
AM
IMC
VAR
SC
RTSE
Requirements for
software and systems
control objectives
EXD
ADM
CTRL
General guidelines for
building resilience in
Resilient
acquisition
guidelines
Technology
vulnerabilities
Technology
vulnerabilities
Figure 11.5  Relationships that drive technology resilience.

CERT Resilience Management Model: An Overview  ◾  149
Capability Level 1: Performed
Capability Level 1 characterizes a performed process. A performed process is a process that 
satisfies all of the specific goals of the process area. It also supports work needed to perform 
RMM practices as defined by the specific goals. Although achieving Capability Level 1 results 
in important improvements, those improvements can be lost over time if they are not adopted. 
[CMMI 2007].
Enterprise
Processes
Governance and
oversight
Internal control
system
Services
Mission, objectives
Risk appetite,
tolerances
EF
RISK
Risk
mitigation
strategies
Facility risks
Incident reports for
facilities
Incidents involving
facilities
Facility access
privileges
Resilience-focused
facilities
Availability
requirements for
facilities
High-value facilities
Continuity plans for
facilities
Identities and
roles
Availability
requirements for
facilities
High-value facilities
Facilities
Control objectives for
facilities
Performance reports
Service-level
agreements High-value facilities
managed by external
parties
Facility resilience
requirements
Facility resilience
requirements
RRM
ADM–Asset Deﬁnition and Management
IMC –Incident Management and Control
SC –Service Continuity
VAR–Vulnerability Analysis and Resolution
RISK – Risk Management
RRD – Resilience Requirements Development
RRM – Resilience Requirements Management
EXD – External Dependencies Management
ID – Identity Management
EC – Environmental Control
CTRL–Controls Management
EF– Enterprise Focus
AM–Access Management
RRD
EC
ID
AM
IMC
VAR
SC
EXD
Requirements for
facility control
objectives
ADM
CTRL
Facility vulnerabilities
Facility vulnerabilities
Facilities used by
services
Figure 11.6  Relationships that drive facilities.
Table 11.5  Capability Levels Related to Goals and Process Progression
0 N/A Incomplete or no process or partially performed process
1 GG1 Performed process
2 GG2 Managed process
3 GG3 Defined process

150  ◾  Information Security Management Handbook
Capability Level 2: Managed
As stated in the RMM Manual, a Capability Level 2 process is characterized as a managed process. 
A managed process is a performed process that has the basic infrastructure in place to support the 
process. At this level, the process is planned and executed in accordance with policy.
Corrective actions are taken when the actual results and performance deviate significantly 
from the plan. A managed process achieves the objectives of the plan and is adopted for consistent 
performance. [CMMI 2007].
Organizations operating at this capability level should begin to know that they can achieve 
and sustain their resilience goals, regardless of changes in or when faced with emerging threats. 
Instead of shifting planning and practices for security and business continuity to address the 
next threat, the organization defines and refines its processes to address any risk that comes 
its way.
Capability Level 3: Defined
A Capability Level 3 process is characterized as a defined process. A defined process is a man-
aged process that is tailored from the organization’s set of standard processes. The process also 
contributes work products, measures, and other process improvement information for use by all 
organizational units [CMMI 2007].
What does this ultimately mean to the organization? When business units operate with 
different goals, assumptions, and practices, it is difficult to ensure that the organization’s col-
lective goals and objectives can be reached. This is particularly true with risk management. If 
the organization’s risk assumptions are not reflected consistently in security, continuity, and IT 
operations, the organization’s risk management process will not be effective and may actually 
deter operational resilience. At Capability Level 3, there is more consistency across units and 
improvements made by each organizational unit can be accessed and used by the organiza-
tion as a whole. Another significant distinction at Capability Level 3 is that the processes are 
typically described more rigorously and managed more proactively than at Capability Level 2. 
[CMMI 2007].
To summarize, an organization that reaches higher capability levels in each process area argu-
ably exhibits a higher degree of organizational maturity with regard to security, continuity, and 
IT resilience.
Informal Diagnosis
Examples of informal diagnostic methods for CERT-RMM include: meetings or exercises in 
which the people who are responsible for the practices in a given process area meet, review the 
guidance, and discuss the extent to which the organization’s practices achieve intent; reviews 
or analyses performed by a single person or a small group to compare the organization’s prac-
tices to the guidance; informal collection and review of evidence that demonstrates appropriate 
performance. These activities can be useful to guide informal process improvement activities or 
to provide information for scoping or setting capability level targets for a more formal process 
improvement project.

CERT Resilience Management Model: An Overview  ◾  151
Analyzing Gaps
Diagnostic activities typically reveal gaps between the current and the required performance. 
Before plans are established to close any gaps, it is important to consider the identified gaps in the 
context of the overall improvement objectives. If it is determined that one or more of the identified 
gaps are acceptable to the organization, it is recommended that the organization revisit and update 
the objectives for improvement. This iterative approach is valuable to ensure that the organization 
spends improvement resources in the most productive manner.
Reference
Caralli, R. A., Allen, J. H., Curtis, P. D., White, D. W., Young, L. R. CERT® Resilience Management Model, 
Version 1: Improving Operational Resilience Processes. Technical Report: CMU/SEI-2010-TR-012: 
ESC-TR-2010-012, May 2010.


153
Chapter 12
Managing Bluetooth Security
E. Eugene Schultz, Matthew W. A. Pemble, and 
Wendy Goucher
Mobile computing technology has been one of the true revolutions of the early twenty-first cen-
tury. One of the most popular technologies within the mobile computing arena is Bluetooth 
technology, which allows different devices to connect to one other without complications such as 
having to manually synchronize them with each other. Like any other type of mobile technology, 
Bluetooth has a number of inherent security vulnerabilities that give rise to risks, some of which 
are potentially serious. This chapter explains the numerous vulnerabilities and risks in connection 
with Bluetooth technology and recommends control measures that can substantially reduce the 
level of associated risk. At the same time, however, some of Bluetooth’s built-in features combined 
with a limited range of Bluetooth-specific technology controls are significant barriers to achieving 
desired risk levels. Administrative controls are thus in many respects the most effective in control-
ling Bluetooth-related security risk.
Introduction
The mobile computing revolution has been underway for years. People everywhere are using smart-
phones, personal digital assistants (PDAs), laptop computers, removable storage media, and you 
name it. Mobile computing offers numerous, well-known benefits to the point that it is being used 
just as much in business as in personal contexts. Information security managers have, in recent 
years, experienced considerable progress in understanding the vulnerabilities and risks involved in 
mobile computing and also to some degree being able to mitigate these risks using a combination 
of technical, administrative, and physical controls. However, one wireless protocol, the Bluetooth 
protocol, has some characteristics and functions that are different from other wireless protocols. 
These differences require that vulnerabilities, risks, and security controls in Bluetooth environ-
ments be separately analyzed and understood. This chapter focuses on Bluetooth security from the 
perspective of an information security manager who is trying to achieve acceptable levels of risk in 
mobile computing environments, but now realizes that Bluetooth has its own idiosyncrasies from 
a risk management perspective.

154  ◾  Information Security Management Handbook
About Bluetooth Technology
Before analyzing Bluetooth security issues, it is necessary to first understand what Bluetooth is, 
the functionality it delivers, and the advantages of this functionality. These issues are covered in 
this section.
What Is Bluetooth?
Bluetooth is a proprietary standard for open wireless technology when information is transmitted 
over short distances via short-wavelength radio. Initially, it was developed by telecommunica-
tion vendor Ericsson as a wireless alternative to RS-232 data cabling. A group called the Wireless 
Personal Area Network (WPAN) Working Group that includes companies such as IBM, Nokia, 
Toshiba, and Ericsson furthered its development. Part of the IEEE 802.15 specification, Bluetooth 
is currently managed by the Bluetooth Special Interest Group. It is used to connect multiple 
devices simply and without an extensive synchronization process. Bluetooth technology is very 
widely used, as evidenced by the estimate that by 2008, there were over 1 billion Bluetooth devices 
being used around the world.
Bluetooth Functionality
Bluetooth provides both wireless LAN connectivity and short-range wireless connectivity to appli-
cations that were at first designed to work only in connection with conventional (wired) networks. 
It creates PANs. Bluetooth is built into many smartphones, e.g., iPhones, but is by no means 
exclusively for mobile devices. It works just as well with fixed devices and also for communications 
between fixed and mobile devices.
Every Bluetooth wireless link (a “pairing”) is created within the boundary of a piconet in 
which up to eight devices use the identical physical channel. Every piconet has one “master;” 
every other device within the same piconet is called a “slave.” To join a piconet, a Bluetooth device 
must be “discoverable,” i.e., it must reveal some information about itself to others within the same 
physical vicinity. The most critical information that must be revealed is the device’s address, which 
is called the “BD_ADDR.” The device must also obtain information (including each BD_ADDR) 
about the other devices. Discoverability can be configured such that a Bluetooth device is in:
	
1.	Nondiscoverable mode—A device will not respond to other devices’ attempts to discover the 
device in question.
	
2.	Limited discoverable mode—A device is discoverable for only a narrow time period, during 
temporary circumstances, or only while a specific event occurs.
	
3.	General discoverable mode—A device is continuously discoverable.
When Bluetooth devices discover each other, they create a shared initialization key, which is in 
turn used to generate a shared symmetric encryption key known as the “link key.” A PIN between 
8 and 128 bits long, the PIN length, and a random number are used to create an initialization key 
for each device. The unit key (a built-in key for each device) is XORed* with the initialization key 
*	XOR is exclusive or a logical operation on bit values. If the initial bit value is the same as the bit value of the key 
(e.g., 0 and 0, or 1 and 1), the result is 0. If the bit values are different (e.g., 0 and 1), the result is 1.

Managing Bluetooth Security  ◾  155
to produce the link key for each device pair. This step is sometimes preceded by generation of a 
random number used to encrypt the initialization key. Both devices store the link key for use in 
further communications between them.
Advantages of Using Bluetooth Technology
The main reason that Bluetooth technology is currently so popular is that it can be used to 
connect just about any device to just about any other, e.g., a PDA to a mobile phone. For exam-
ple, in the states within the United States, in which driving and holding a mobile phone to 
carry on conversation simultaneously is illegal, a Bluetooth device with a wireless connection 
to a mobile phone can enable a user to be able to both speak on and listen to the mobile phone 
because the Bluetooth device serves as an intermediary device. Bluetooth is also extremely flex-
ible and versatile; it can create ad-hoc networks supporting up to eight devices. Internet access 
is another purpose for which these devices are so frequently used. And Bluetooth functionality 
is not limited to handheld devices, either. Bluetooth can also be used to synchronize desktop 
machines.
Disadvantages of Using Bluetooth Technology
Less than 10 years ago, Bluetooth was not very popular due to some inherent limitations, sev-
eral of which were substantial. One is that earlier versions of this technology had a line-of-sight 
requirement, such that if a solid object such as a tree were directly in the transmission path of 
two devices, communication failures would occur. More recent Bluetooth implementations are 
not subject to this problem. One of the most significant disadvantages of Bluetooth today is its 
relatively short range—only about 300 feet in many implementations (and even less in some 
implementations*). Many implementations are thus not suitable as a long-range communication 
technology.
Despite the deliberately low nominal range of the majority of Bluetooth implementations, 
there are commercially available implementations that have a significantly longer range. These 
implementations exceed what is known as the Class 1 power settings and, additionally, provide 
high gain and/or directional antenna. Devices from manufacturers such Aircable or Balutek have 
the proven ability to interoperate at ranges as great as a mile.
The high tolerance for latency within the Bluetooth specification also allows connections to be 
established at much longer ranges than 300 feet, even with lower-powered devices.
Additionally, Bluetooth has always been slow. In theory, Bluetooth has a maximum band-
width of only 1 Mbps, but the actual bandwidth is almost always lower because of Bluetooth’s 
forward error correction functionality. Furthermore, Bluetooth operates within the 2.45 GHz 
frequency range, a range also used by a number of other wireless devices (including baby moni-
tors), something that can potentially cause interference. To lessen its susceptibility to interference 
problems, Bluetooth uses the Frequency Hopping Spread Spectrum (FHSS) transmission type. 
Finally, as discussed in greater detail shortly, a number of security vulnerabilities in Bluetooth 
have been identified over the years, and some types of attacks are almost impossible to prevent 
or stop.
*	The range for the commonest Class 2 devices is just 33 feet.

156  ◾  Information Security Management Handbook
Bluetooth Security Risks
In this section of this chapter, security risks inherent in Bluetooth technology will be described.
Generic Mobile Computing Vulnerabilities
The majority of Bluetooth devices have the same or extremely similar vulnerabilities that generic 
mobile computing devices typically have. One of the most widely exploited vulnerabilities in the 
mobile computing arena is unauthorized capture of wireless transmissions. If the transmissions are 
encrypted, the encryption is often not sufficiently strong to prevent even simple cryptanalytic attacks. 
Also, denial-of-service (DoS) attacks against mobile computing devices and wireless networks are 
easy to perpetrate and difficult to defend against. Low power radio frequency (RF) communications 
are highly susceptible to interference, either deliberate or accidental, as well as general RF noise from 
nontuned devices. All an attacker must do is to send a stronger signal at the same frequency as the 
targeted wireless connection. Additionally, size restrictions and form factor in mobile computing 
devices almost invariably compromise the user interface. For example, a typical Bluetooth earpiece 
may have just one multipurpose control and one indicator. For some devices, additional control and 
monitoring may be provided by a driver downloaded to the connected computer, but where the con-
nection is to a mobile phone or similarly restricted device, this is unlikely. Furthermore, like many 
consumer devices, software, and firmware, updates for known vulnerabilities are often not available 
or are available only long after exploits for these vulnerabilities have been “in the wild.” Even if 
updates are available, they are only rarely downloaded and installed in mobile computing devices. 
Vulnerabilities are thus likely to persist more so than in conventional computing systems. The small 
physical size, a common design feature (and also a constraint) in mobile devices, also substantially 
increases the chance that these devices will be lost or misplaced.
Bluetooth-Specific Vulnerabilities
There are more vulnerabilities specific to Bluetooth devices than one might expect. These vulner-
abilities are discussed in the following section.
Interception of Transmissions
Simple RF interception, using directional antenna, can occur wherever “line of sight” between the 
sending and receiving points in Bluetooth transmissions can be established. Long-range attacks 
(“blue-sniping” attacks) against Bluetooth devices have been publicly demonstrated with low-cost 
equipment at ranges of over half a mile. When considering the use of Bluetooth for security or 
other sensitive applications, it is thus necessary to consider much longer ranges for the outer range 
of interception of transmissions than one might think.
Passwords and PINs
PINs used in Bluetooth authentication are generally between 4 and 16 characters long. Shorter 
PINs can easily be guessed* or brute-forced if conventional bad login limit lockouts are not built 
*	Many Bluetooth devices come with well-known default PINs such as 0000 or 1234, something that greatly 
simplifies the task of guessing PINs.

Managing Bluetooth Security  ◾  157
into the devices, and the fact that they are only a maximum of four characters long in some 
Bluetooth implementations makes these devices unusually vulnerable. Furthermore, in some of 
these devices, PINs are fixed and thus unchangeable by their users. PIN guessing can thus enable 
perpetrators to impersonate the identity of Bluetooth devices, enabling perpetrators to make long-
distance calls billed to the account of legitimate users as well as to gain unauthorized access to 
call lists, phone books, photos, and other information. PIN spoofing can also be used for similar 
purposes. And if a Bluetooth device falls into the hands of an attacker, the attacker can gain access 
to the same types of information, often by gleaning PINs from memory and/or the device’s hard 
drive.
Malicious Code
Malicious code such as viruses and worms can and do infect Bluetooth devices and then spread 
themselves to others. The now infamous/Cabir/Caribe/SymbOS virus that infected so many 
mobile phones at the Helsinki Games several years ago is one of the best examples of viruses that 
are capable of infecting Bluetooth and well as other wireless devices. And the fact that relatively 
few Bluetooth users run antimalware tools on their devices significantly increases the probability 
of malware infections.
Denial-of-Service
Bluetooth devices are extremely susceptible to DoS attacks, as are wireless devices and networks 
in general. All an attacker needs to do is to jam the frequency (2.4 GHz) that Bluetooth devices 
use. And the previously mentioned fact that Bluetooth devices share this frequency with IEEE 
802.11b and 11g networks as well as microwave ovens and baby-monitoring devices is a further 
DoS-related issue.
Discovery-Related Vulnerabilities
The Bluetooth discovery process is potentially the point of greatest exposure to attacks. Bluetooth 
devices have a variety of keys such as link keys, master keys, and others. During the Bluetooth 
authentication process, a simple type of challenge–response process is used in which information 
used to create keys is exchanged between Bluetooth devices. Because Bluetooth authentication is 
not based on user identities and encryption is not in place during the initial stages of this process, 
an attacker in the immediate physical vicinity can initiate a “man-in-the-middle” attack by listen-
ing to and capturing credentials and information being exchanged. The perpetrator must first get 
a copy of the link key used between two paired Bluetooth devices. Once the perpetrator has this 
key, s/he can set up a link with one of these devices by impersonating the identity of the other. The 
device with which a link has been created will behave as if it is linked to the device for which the 
identity has been impersonated. This also makes possible decrypting encrypted information sent 
between devices.
Unauthorized Access to Bluetooth Devices Using Bluetooth Hacking Tools
A surprising number of Bluetooth hacking tools exist that allow computer criminals to do every-
thing from sniff keys used in authentication to insert information into transmissions between 
devices. These tools will be covered in the next section of this chapter.

158  ◾  Information Security Management Handbook
Exposure of Individuals’ Physical Location
A perpetrator can discover the physical location of someone who is using one of these devices. 
Built-in global positioning systems (GPSs) are handy for Bluetooth users who need to know where 
they are, but anyone who can intercept Bluetooth transmissions can also discover the physical 
location.
Cryptanalytic Attacks
One of the most potentially straightforward kind of attacks is a cryptanalysis attack against the 
encrypted content that is transmitted between paired Bluetooth devices. Bluetooth uses the Eo 
encryption algorithm for safeguarding the data in motion. Because Eo is a stream cipher, it is 
potentially vulnerable to a variety of cryptanalysis methods developed against stream cipher algo-
rithms. For example, it is possible to recover the initial value used in generating stream cipher 
keys by solving sets of nonlinear equations over finite fields. If the sets of equations are next trans-
formed into linear versions, the resulting number of linear independent equations becomes suf-
ficiently small to solve for unknowns using brute-force methods. However, Bluetooth’s encryption 
algorithm differs just enough from other stream cipher algorithms that it is not very vulnerable to 
these types of attacks.
Another cryptoanalytic attack targets the Bluetooth challenge–response protocol, which is 
based on an algorithm called E1. E1 is in turn based on a block cipher called SAFER+. A flaw 
in SAFER+ key scheduling allows the number of potential keys to be reduced, thereby making a 
brute-force attack against the remaining keyspace feasible.
Bluetooth Hacker Tools
An abundance of attack tools against Bluetooth devices greatly simplify attacking these 
devices. Bluescanner is one of the most widely used tools of this nature. Bluescanner discov-
ers these devices, their names, and their addresses as well as what kind they are (keyboard, 
mouse, phone, computer, and so forth) and any advertised services. This tool can also be used 
to record the time of discovery and additional contextual information regarding the devices 
that are targeted for reconnaissance activity. One of the advantages perpetrators who use this 
tool have is that they can record these kinds of information without having to authenticate to 
targeted devices.
Bluesnarf is another attack tool that can be used for reconnaissance purposes. Although it 
has somewhat less functionality than does Bluescanner, it can download phonebooks and other 
information stored on Bluetooth devices. One advantage of Bluesnarf is that it works covertly—
Bluetooth users do not notice that reconnaissance activity is occurring.
Btcrack enables a perpetrator to make phone calls on another phone with charges billed to 
whoever owns the other phone. Additionally, Btcrack cracks Bluetooth PINs and tries to recon-
struct both the pass and the link keys, which are obtained during the pairing process in discovery 
mode.
BlueSniff finds discoverable and hidden Bluetooth devices. One of the primary advantages of 
using BlueSniff is that it has an extremely intuitive graphical user interface (GUI).
BlueBug attempts to gain unauthorized entry to phone books, call lists, and other personal 
information in remote Bluetooth devices during discovery mode.

Managing Bluetooth Security  ◾  159
Security Risks
How do the known Bluetooth vulnerabilities and exploit methods translate to security risks? This 
question is addressed in this section of this chapter.
Unauthorized Access to Sensitive/Proprietary Information
Bluetooth devices are used with a variety of mobile computing devices. The technology has largely 
replaced earlier infrared (IrDA) and radio technologies for wireless peripherals such as mice or 
keyboards for laptop and desktop computers. The extensive use of e-mail enabled devices and ever-
increasing storage capabilities of mobile computers mean that paired access, where the computer’s 
Bluetooth application offers a file access service (as all major operating systems do), can allow an 
attacker to potentially gain access to any of the information stored on the device. It is possible to 
disable Bluetooth file sharing on some, but not all, mobile computing devices, but everyday users 
are not likely to do so.
The risk of the attacker decrypting a Bluetooth transmission is also always present. Successful 
decryption could also result in compromise of personally identifiable information (PII) in 
motion as well as of intellectual property (IP). But an attacker may not have to decrypt anything. 
Versions of the Bluetooth protocol before V2.1 do not require encryption, so devices communi-
cating with a Bluetooth V2.0 or earlier (or forced to fall back to that protocol) may be transmit-
ting in cleartext.
Still another data confidentiality risk scenario results from Bluetooth accessories generally 
failing to offer granular access controls. If an attacker manages to pair with a Bluetooth device, 
therefore, the attacker will have open access to the device’s functionality and, if the device has a 
data storage capability, access to all of the information stored on the device. For modern devices 
that support multiple pairings (known as “multi-point” pairings), there is also the potential for 
data in transit from the legitimate client to be exposed, although this is partially mitigated by a 
special “round-robin” time-division multiplex mechanism within a piconet.
Unauthorized File Integrity Modification
Bluetooth service models do not always differentiate between read and write capabilities for file 
sharing. Therefore, an attacker with paired access may be able to modify the files if the underlying 
file system security inadequately differentiates between the logged-in and remote users, or inad-
equately enforces granularity between read and write accesses. The former is particularly common 
in smartphones and PDAs, which generally only support a single-user access model and do not 
provide controllable file-system security.
Unauthorized Long-Distance Phone Calls
One of the earliest attacks against Bluetooth-enabled mobile phones was the ability to peer with 
the phone and then to use it to make unauthorized calls. The use of fixed (and known) PINs for 
many Bluetooth handsets, as well as the ability of an attacker to control the information delivered 
by their Bluetooth device as part of the pairing process, allows them to mimic, to the human 
user, a currently paired device. This then allows the attacker to make phones calls, including to 
premium rate lines, a common “cashing out” mechanism for telephone attacks.

160  ◾  Information Security Management Handbook
Location Discovery
Many devices now provide location information through GPS, cell-tower triangulation, Wi-Fi 
hotspot detection, or other means. These data are often exchangeable via Bluetooth: an attacker 
may be able to access this information, either by pairing or by interception.
Additionally, Bluetooth-enabled devices transmit radio information that contains their unique 
“BD_ADDR” code, similar to the MAC address for an IP network device. This portion of the 
information is transmitted in cleartext, even if the data portion of each packet is encrypted. 
A sophisticated attacker can thus passively determine the location of a specific active device by 
triangulation or relative amplitude measurement.
Loss of Availability
Availability-related risk is the final risk considered here. This means that if Bluetooth is used to 
transmit critical information, the likelihood of temporary disruptions to access must be factored 
into safety and/or business cases. Also, a sophisticated attacker can launch “man-in-the-middle” 
attacks to interfere with the pairing process, potentially affecting even more modern pairing 
schemes. However, current Bluetooth attack methods require special RF equipment, thus greatly 
reducing the feasibility of launching such attacks.
Control Measures
Despite all the vulnerabilities and risks in connection with Bluetooth functionality, numerous 
proven control measures exist. This section of this chapter describes some of the most frequently 
used of these measures.
Policy
Policy is the anchor of an information security practice. Bluetooth usage restrictions and 
required configurations and procedures should, like any other area or issue, be addressed in pol-
icy (and ultimately in standards that are derived from policy provisions), regardless of whether 
Bluetooth devices are owned by an individual or an organization. Critical policy issues include 
the following:
◾
◾Ownership of Bluetooth devices, especially when devices contain an organization’s data,* as 
discussed previously in this chapter
◾
◾Acceptable use: An organization’s acceptable use policy (AUP) must state what kinds of user 
actions are and are not allowed. Are users allowed to use their own Bluetooth devices to 
conduct company business? Are they allowed to store sensitive and/or proprietary data on 
Bluetooth devices? Are they allowed to loan their devices to other employees and nonem-
ployees? Users should also be informed that they may not download pornographic, pirated, 
and hateful information onto any Bluetooth device.
*	For example, telephone contact lists and date/time records for calls, stored on the Bluetooth hands-free equip-
ment in an executive’s or salesperson’s car, may have significant commercial or legal value to a competitor.

Managing Bluetooth Security  ◾  161
◾
◾When and where Bluetooth connections are permitted? The open nature of the Bluetooth 
RF component means that risks of deliberate or inadvertent compromise, of data or avail-
ability, are much more likely in a crowded radio environment. The use of Bluetooth in these 
cases should in general thus be prohibited. By contrast, Bluetooth use within a controlled 
environment, such as a car, or within the workplace (where both some degree of approved 
access to the data and a general reluctance to interfere with colleagues’ work can be assumed) 
should in most cases be permitted.
◾
◾Approval of devices: Another alternative is to approve Bluetooth devices on a per case basis. 
The approval criterion might be evidence of sufficient technical controls that adequately 
protect Bluetooth access and other functions.
◾
◾Use in connection with sensitive data at rest and in motion. Bluetooth was not by any means 
designed as a channel of secure communication or storage. Permission to use Bluetooth in 
connection with access to sensitive data (government classified, credit card information, PII, 
and so on) and other business-related purposes must thus by default be denied and allowed 
only on a per-case basis.
◾
◾Physical security: Policy must forbid leaving mobile devices in any place in which the prob-
ability of theft is higher than usual (e.g., on a desk in a public library). In the case of devices 
on which IP or PII is stored, additional controls (e.g., remote wipe software) may be appro-
priate if available. What users must do in case they lose or misplace their Bluetooth device 
should also be described.
Standards
Standards should cover required configurations for Bluetooth devices, the required frequency 
of patching and backups, and other critical technical prescriptions for these devices. Standards 
should also state the kind of encryption that must be used to protect the data stored on Bluetooth 
devices and any password and/or PIN requirements (e.g., the minimum length of PINs).
Technology Controls
There are several areas in which technological controls can be used to mitigate Bluetooth-related 
security risk. First, ensuring that all authorized devices are compatible with the latest Bluetooth 
standards is essential. Many of the particular security weaknesses discovered exist at the protocol 
level rather than being an artifact of specific flawed implementations. Information security man-
agers and auditors may have to ensure that Bluetooth devices have software or firmware patched 
at the most modern update levels. The monetary cost and amount of time and labor involved with 
such an effort may or may not be justifiable, depending upon an organization’s risk appetite level 
and availability of resources.*
Secondly, an increasing variety of security tools such as endpoint firewalls and antivirus and 
antimalware software that protect Bluetooth devices are slowly but surely becoming available. 
Although many of these are rather generic to mobile devices, these tools can mitigate risks such as 
unauthorized access to devices and the information stored on them and malicious code infections 
rather effectively. More specialized security tools similar to products designed to control risks asso-
ciated with the use of USB and removable media devices are available, but they are not universally 
*	It is especially difficult to justify the cost, time, and labor involved if Bluetooth devices have low levels of func-
tionality and are only rarely connected to public networks.

162  ◾  Information Security Management Handbook
available for all operating systems and for all low-end Bluetooth devices. Use of technology that 
provides at least some level of access control may be somewhat deceptive, however. The previously 
mentioned BD_ADDR code is the primary method of identifying devices in discovery mode, so 
even if sound security technology is implemented in Bluetooth devices, any attacker who is able to 
monitor the pairing process is likely to be able to impersonate a target device, thereby bypassing 
security technology.
Procedural Controls
Procedural controls are also necessary. Information security managers should, e.g., consider 
extending their current vulnerability scanning efforts by also scanning for unauthorized Bluetooth 
devices. Many network/domain administration and vulnerability scanning tool plug-ins can find 
these devices, regardless of whether they are active at the time of scanning. Scanning in sensi-
tive locations, such as areas within buildings where servers that store IP and/or PII are physically 
located, can prove exceptionally beneficial. Procedures should also specify how and how often 
updates must be tested and installed. And information security managers should strongly con-
sider creating and maintaining an inventory of discovered devices and, if possible, comparing this 
inventory with a list of registered devices.
Evaluation of Controls
The widespread use of Bluetooth technology is a relatively new trend, and controls invariably 
lag behind technology advancements. Bluetooth controls are no exception. Bluntly put, technol-
ogy controls currently available for Bluetooth devices are not all that adequate in that they leave 
residual risk levels that many organizations find unacceptable. And information security managers 
do not currently have the range of choices concerning Bluetooth technical controls that they have 
in other areas, such as in network security. Additionally, technical controls in the Bluetooth arena 
have so far not been able to help overcome problems such as fixed defaults, e.g., fixed PINs and 
passwords in some Bluetooth devices.
Information security managers should also realize that technical controls generally work on 
the master device. Accordingly, authorized accessories, which among other things may provide 
access to stored information, are likely to be readily connectable to and thus openly accessible by 
unauthorized master devices. Given the limited audit logging capabilities of most accessories, this 
type of access is unlikely to be detectable even if the accessory is subsequently connected back to 
the authorized device.
Controls can be technical, administrative, or physical, or a combination of all three, so infor-
mation security managers can supplement technical controls with other types, of which adminis-
trative controls (discussed earlier in this chapter) are the most useful in the Bluetooth arena.
The widely used mantra, “Plan, Do, Check, Act,” dictates that organizations must incorpo-
rate evaluation and review into operational cycles. Controls are only effective when they are sys-
tematically evaluated and tested and, when appropriate, modified or replaced. This is especially 
true in the Bluetooth arena, where technical controls currently do not generally adequately 
deliver what organizations need for risk mitigation. Information security managers should thus 
continually examine the current generation of controls for Bluetooth devices to determine if 
changes in technology products have been made such that reconfiguring or upgrading them 
can more effectively reduce residual risk, and if so, to ensure that appropriate changes are made. 
In addition, new controls will emerge in time, and as they do, information security managers 

Managing Bluetooth Security  ◾  163
and others will have potentially new risk mitigation solutions to evaluate, test, and possibly 
implement.
Management Strategies and Issues
Bluetooth, as a generic “wireless technology” and one that is primarily used to support mobile 
computing and communications, needs to be an integral part of the organizational policy and 
controls within this area of business support. When formal certification of information secu-
rity management or information assurance (ISO/IEC 27001, PCI-DSS, SAS-70, and so on) is 
required, the controls for Bluetooth-related risks must be incorporated into wider RF or wireless 
security policies, as well as being specifically highlighted in user guidance for mobile computing 
in general.
Integration of Bluetooth into any existing technical controls environment is a more difficult 
issue. As mentioned previously, in most organizations users typically own and use more advanced 
and capable devices than an organization is likely to issue to them. There will thus be significant 
pressure either for an organization to provide equivalent functionality or to allow the use of per-
sonal devices. The much more difficult scenario from a security management viewpoint is when 
there is a mixture of personally and organization-owned Bluetooth devices.
Integrating Bluetooth into an Overall Mobile Device 
Security Risk Management Strategy
There may be important appropriate technology controls incorporated into managing devices that 
use Bluetooth technology. Technology controls need to for the most part be incorporated into 
system administration, but technology controls go only so far in mitigating risk in the Bluetooth 
environment. Security training and education (covered soon) in addition to previously covered 
security policy and standards provisions are in many ways more effective (especially cost-effective) 
as Bluetooth security controls than are technology controls.
Mobile technology is proliferating to the point that technical staff now typically suspect but 
do not know for sure that there are more devices (including personal devices) being used than 
those that are registered with an organization. If employees cannot be persuaded to register their 
devices with a central system, they must assume greater responsibility for updating the devices’ 
software. One very advantageous and uncommon feature of Bluetooth security is the incentive for 
ordinary users to keep their devices as secure as possible by installing updates—improved perfor-
mance, especially with smartphone updates. When users are prompted to update their Bluetooth 
devices, they thus tend to view the update process as advantageous independently of security 
considerations.
But not all Bluetooth users update their devices, despite the advantages. Procedures for IT staff 
members to systematically locate and update Bluetooth devices must thus be developed and fol-
lowed. As previously discussed, organizations should keep a record of all the types and instances 
of Bluetooth-enabled devices, using a status update and notification system if possible. Doing this 
allows the technical support team to test and monitor the availability of updates, so that they can 
notify both users and their line managers when new updates are ready to be installed. This also 
means that if users are absent from work for a significant time period, part of their return-to-work 
procedure can be having IT staff update their Bluetooth as well as other devices.

164  ◾  Information Security Management Handbook
The Role of Training and Awareness
Security training and awareness are one of the most singly important elements in securing the 
Bluetooth environment. Security awareness, if carefully developed from “first contact” with a staff 
member, can lead to more effective understanding of and compliance with policies, standards, and 
procedures. Ensuring that all Bluetooth users are fully aware of organizational restrictions (e.g., 
that certain types of information may not be stored on Bluetooth devices) on the use of Bluetooth 
is essential. Users must become familiar with and sign off on AUP provisions concerning Bluetooth 
usage. Users must be educated concerning any approval processes for using the technology and 
also the types of controls that must be in place. Additionally, they must also be educated concern-
ing the dangers of using Bluetooth devices in public places and must be instructed to avoid this 
context of use. Finally, they must be informed of the ramifications of noncompliance.
As staff work when they travel, they often use Bluetooth earpieces while talking on their 
mobile phones. Although these employees may understand some of the risks associated with mobile 
phones, they are unlikely to realize that more risks are present because of their use of Bluetooth 
earpieces. Security training and awareness efforts must thus attempt to help users understand 
and counter Bluetooth-specific risks. More and more organizations are sending text messages with 
a “security tip of the week” to mobile device users, something that is likely to work better than 
herding users into an auditorium to hear a blasé lecture about mobile device security once a year.
Enforcement of Policy, Standards, and Procedures
Enforcement of Bluetooth security-related policy, standards, and procedures is generally an 
extremely difficult task. Random “spot-checks” on Bluetooth devices’ configuration and update 
status can be conducted as employees enter and leave the building in which they work. These 
“spot-checks” can also be useful in identifying whether nonauthorized Bluetooth devices are being 
used at work. But there is a significant downside—employees are likely to view such “spot-checks” 
as an invasion of privacy, an indication of distrust of employees by employers, and a waste of their 
time. Alternatively, IT staff members can inspect Bluetooth devices while troubleshooting them. 
Auditors, who in particular need to come up to speed regarding Bluetooth security issues, should 
also focus in part on Bluetooth security whenever IT audits are performed.
Because there is no bulletproof method of enforcement in the Bluetooth environment, the 
best way to enforce policy, standards, and procedures in the Bluetooth environment is to create a 
voluntary compliance program—a “soft shoe” approach. One way to implement such a program 
is to create and distribute Bluetooth security compliance checklists to employees. Employees can 
then be required to complete and return checklists within a specified period of time. True/false 
items such as “I use Bluetooth only when I am in non-public, non-crowded places,” “I update my 
Bluetooth device no less than once a month,” and “I make sure that no company proprietary infor-
mation is stored on my Bluetooth device” might appear in the checklist. If an employee indicates 
that s/he is not conforming to policy, standards, and/or procedures, someone from information 
security or IT can assist that person in achieving compliance.
Conclusion
Just when information security managers thought things were getting out of control in the mobile 
computing arena, Bluetooth popularity started to soar, and this trend has continued until now. 

Managing Bluetooth Security  ◾  165
Bluetooth device functionality and transmission range are growing rapidly, and there is no end in 
sight. Some degree of risk mitigation for Bluetooth technology is possible, but the level of residual 
risk is likely to be excessively high for organizations such as financial institutes that typically have 
low risk appetites. Technology controls can help in reducing security risk in Bluetooth environ-
ments, but built-in features such as discovery pairing and the limited length of PINs and pass-
words in some devices result in vulnerabilities that available technology cannot really remediate 
very well at this point in time. The fact that so many widely available and easy-to-use exploit tools 
for Bluetooth technology exist only exacerbates this dilemma. Fortunately, most Bluetooth devices 
in use today have a limited transmission distance; attackers are thus generally unable to launch 
successful remote attacks against these devices.
Selection of appropriate Bluetooth controls will vary significantly, depending on the culture 
and risk appetite of each particular organization, but all things considered, administrative controls 
such as a requirement for approval of use, location, and/or data sensitive-based restrictions on use, 
and training and awareness are likely to be most effective. Training and awareness efforts in con-
nection with a voluntary compliance approach provide particularly promising benefits in the wild, 
unruly world of Bluetooth technology.
About the Authors
E. Eugene Schultz, PhD, CISM, CISSP, GSLC, is the chief technology officer at Emagined 
Security, an information security consultancy based in San Carlos, California. He is the author/
coauthor of five books, one on UNIX security, another on Internet security, a third on Windows 
NT/2000 security, a fourth on incident response, and the latest on intrusion detection and pre-
vention. He has also written over 120 published papers. He was the editor-in-chief of Computers 
and Security from 2002 to 2007 and is currently an associate editor of Computers and Security 
and Network Security. He is also a certified SANS instructor, senior SANS analyst, member of 
the SANS NewsBites editorial board, coauthor of the 2005 and 2006 Certified Information 
Security Manager preparation materials, and is on the technical advisory board of three compa-
nies. He has previously managed an information security practice as well as a national incident 
response team. He has also been a professor of computer science at several universities and is 
retired from the University of California. He has received the NASA Technical Excellence 
Award, the Department of Energy Excellence Award, the ISACA John Kuyers Best Speaker/
Best Conference Contributor Award, the Vanguard Conference Top Gun Award (for best pre-
senter) twice, the Vanguard Chairman’s Award, and the National Information Systems Security 
Conference Best Paper Award. Named a distinguished fellow of the Information Systems 
Security Association (ISSA), Gene has also received the ISSA Hall of Fame award as well as 
the ISSA’s Professional Achievement and Honor Roll awards. While at Lawrence Livermore 
National Laboratory, he founded and managed the U.S. Department of Energy’s Computer 
Incident Advisory Capability (CIAC). He is also a cofounder of FIRST, the Forum of Incident 
Response and Security Teams. Dr. Schultz has provided expert testimony before committees 
within the U.S. Senate and House of Representatives on various security-related issues and has 
served as an expert witness in legal cases.
Matthew W. A. Pemble, Eur Ing, has been technical director of Idrach Ltd., since its found-
ing in 1997, having previously worked for the U.K. government (as a regular and reservist mili-
tary officer and as a civilian consultant), an international banking group, and several testing and 

166  ◾  Information Security Management Handbook
security consultancies. Perhaps, recently, best known for his contributions to security testing, 
incident management, and counter-fraud strategies, Matthew also has considerable experience in 
policy-based security, security architectures, and ISO/IEC 27001. Historically, he was one of the 
first people to qualify as a penetration test team leader under the U.K. government “CHECK” 
scheme and was also one of the original BS7799 (now ISO/IEC 27001) c:cure Auditors. An expe-
rienced technical and journal author, he has been lead contributor to many customer publications, 
including user and technical manuals, and is one of the lead authors on the forthcoming ENISA 
publication “How to shop safely online.” His work has been published in numerous trade and 
academic journals, including Computer Fraud and Security, the International Journal of Digital 
Evidence, Information Security Bulletin, and Network Security. Additionally, he is a visiting lecturer 
of digital forensics at the Universities of Glasgow and Strathclyde and a regular speaker at national 
and international conferences. Matthew is a chartered and European registered engineer, a fel-
low of the British Computer Society, a founder member of the Institute for Information Security 
Professionals, and a member of the Institute of Engineering & Technology.
Wendy Goucher is a security consultant working mainly in the human controls and policy areas, 
helping to improve the interface between organizations security requirements and the actual 
behavior patterns of staff, customers, and passersby. In this role, she brings the communication 
skills and managerial insight gained from a background in psychology and sociology and her first 
career as lecturer in both university and various colleges of higher education. She has also com-
pleted her Ph.D. in information security at the University of Glasgow, where she has been investi-
gating the operational risks of mobile working. Wendy is an active member of the Security Culture 
Project Team for ISACA and an ENISA taskforce that seeks to bring security awareness into the 
home. Since moving into the information security arena, she has gained experience working with 
clients in the public sector, government contractors, and the finance sector, principally in compli-
ance preparation and security awareness. She is a member of the Scottish Centre of Excellence 
in Cybercrime and Security Project, based at Napier University, and is an active member of the 
Cybercrime and Forensics program at the Scottish Universities’ Insight Institute. Wendy also 
writes a monthly column for Computer Fraud and Security.

Employment Policies 
and Practices


169
Chapter 13
Slash and Burn: In Times 
of Recession, Do Not Let 
Emotions Drive Business 
Decisions
Anonymous
“Don’t let operational developments influence strategy” writes noted warrior Sun Tzu. Many of 
the principles the great General developed can be applied to modern business. In particular, Sun 
Tzu stressed the importance of always positioning oneself in a proactive rather than reactive pos-
ture. It is all too clear, however, that the recent economic recession has forced many firms to 
learn the hard way that deviating from their objective strategies to react to—as Sun Tzu phrased 
them—“operational developments” is dangerous. It is always the most sound strategy to make 
decisions—business or otherwise—based on logic and clear-thinking rather than fear and related 
emotions. Dwindling capital, customer withdrawal, or uncertainty of the future can all place 
businesses on the defense, rushing headlong into decisions that will almost certainly hurt them in 
the long run.
Some of the first areas firms will look to cut costs are technology, human resources, and 
operations—often viewed as nonrevenue-producing cost centers, which are mere necessity. 
Arguably the most valuable of these departments is the information technology department and 
yet still often finds itself under the knife as one of the first areas to be hit in recession, often 
to the firm’s long-term detriment. Karl Flinders discusses this point in an issue of Computer 
Weekly, essentially taking the position that companies often panic in times of crisis and make 
irrational decisions not grounded in thorough analysis. “Companies risk reducing future business 
opportunities when they cut IT budgets in times of economic slowdown, according to Harvard 
Management, which manages the assets of Harvard University” (Flinders, 2009). Recessions end, 
economies recover, and businesses once again have the opportunity to thrive. The short-sighted 
slash and burn approach might make sense in the near-term, but falls apart when companies look 

170  ◾  Information Security Management Handbook
to return to market with fresh initiatives during economic recovery. “Harvard Management says 
companies often cut IT budgets because of three common errors: they delay decisions that will 
improve the long-term health of the firm; they assume the smart way to grow is always cautiously 
and incrementally; and they focus on broadening their customer base” (Flinders, 2009).
Broadening a customer base seems, on paper, a worthwhile endeavor, yet many businesses 
do not time these initiatives correctly. A recession is the worst time to spend finite resources on 
marketing and increased sales initiatives. Instead, it is a tremendous opportunity to focus on cli-
ent service and retention. By providing superior service to existing clients during an economic 
slowdown, firms place themselves in a strong position to expand that customer base when the time 
is right. By throwing resources at sales and marketing, firms miss a key opportunity to build their 
infrastructure and improve their strategy. “Harvard Management says businesses should cherish 
customers that stay with them through a slump because they will probably be its best customers 
when things pick up” (Flinders, 2009).
Some chief information officers (CIOs) do remain calm in crisis and ultimately guide their 
teams and the larger business to success. As one example, “Justin Speake, CEO at analyst firm 
Bloor Research, says during an economic slowdown businesses should re-examine their decisions, 
but warns against cutting projects as a knee-jerk reaction. If there was a justification for a project, 
it may still apply…” (Flinders, 2009). An often-hailed mantra in business leadership is a reference 
to the Chinese symbol for crisis, which is a combination of the symbols for danger and opportu-
nity. The CIO is in the best position to seize an opportunity from a financial crisis through his 
leadership and decision making along with his ability to influence other senior management. To 
that end, “the CIO should not stand out as different from the rest of the senior management team 
due to a lack of business knowledge, but should be involved in all areas” (Computer Weekly, 2009). 
If the CIO can win the rest of the C-level executives and show that his strategy is business-focused 
and rooted in long-term gains, his firm should be effective at capitalizing on a crisis and turning 
it into an opportunity.
CIOs are in the best position to know the importance of capabilities such as flexibil-
ity, skills, innovation or knowledge to each area of the business and whether they are 
expendable or not. “CIOs should refocus on business strategy and then prioritise [sic] 
the IT portfolio based on that” (Computer Weekly, 2009).
Strategy is nothing without tactics. Assuming leadership is behind the CIO and his decisions, 
where does he actually begin to place his finite resources to generate the best results? According to 
Katherine Heires, companies are focusing on “nondiscretionary, must-tackle technology and com-
pliance issues—including low latency, trade reporting, risk management and options symbology 
requirements …” (Heires, 2009). Another interesting approach focuses on the IT department’s use 
of vendors and other external resources and applications. In times of crisis,
Every organization must consider one area: on-demand applications. Why? First, a 
low initial capital investment (no hardware and small-scale implementation costs) and 
rapid deployment will accelerate payback so financial capital can be reinvested in other 
projects. Second, because you’re not buying licenses, you can scale up or down on user 
accounts if your business changes. Third, because you’re probably not financing the 
project like a capital investment, you don’t have to worry about how interest rate fluc-
tuations increase the financial risk (need to verify/track down the source as I misplaced 
the printout).

Slash and Burn  ◾  171
Donald Hopkins of SunGard Availability Services advised against focusing on incremental 
cost reduction projects and taking the time to analyze more strategic initiatives—even in times 
of economic stress. “ ‘Cost reductions can be very addictive,’ he says, ‘where you end up always 
thinking about the next 15 percent to cut’” (Heires, 2009). Some breakthroughs he suggested 
include the use of “de-duplication technology as part of one’s disaster recovery plan—a technique 
that removes any duplicate data prior to compression and thus, Hopkins argues, can result in 
significant savings” (Heires, 2009).
Hopkins’ view is a classic example of not reacting to negative forces but rather remaining 
focused on his original objectives and not wavering from them. Businesses who fall into the cost 
reduction project trap sacrifice robust infrastructure for incremental and marginal gains. Often 
these projects hold appeal because they might temporarily improve the bottom line—especially, 
key for public companies that need to satisfy shareholders. This approach is flawed and long-term 
shareholders will suffer as a result. To underscore this point, “Harvard Management also believes 
it is wrong to assume that cautious growth is always best. Businesses can use technology to grow 
their businesses quickly when things pick up” (Flinders, 2009). To that end, everyone, from the 
CEO to the first-year analysts, must understand the value of strong technology. Some firms get it. 
Epicor is one of them.
“Technology is productivity,” [Epicor senior vice president and chief marketing officer 
John Hiraoka] said, highlighting studies and analysts who predict resilience in the 
IT sector. Hiraoka referenced Cisco Systems CEO John Chamber’s keynote address 
at Gartner ITEXPO in mid-October, who said there will be an ‘instant replay’ in 
technology-led productivity gains, with collaborative IT intertwined with business 
strategy (Manning, 2008).
Further, Rod Winger, Epicor’s senior director of product marketing, said that even in a down 
economy, companies understand that the road to recovery is the leveraging of business process and 
innovation (Manning, 2008). What are the real outcomes of these decisions? Ask Cisco. In 2009, 
Cisco Systems Inc. experienced a 2-hour shutdown of their Web site. “Kurt Roemer, chief security 
strategist at Citrix Systems Inc. in Fort Lauderdale, Fla., said he wonders whether [the shutdown] 
‘would [have] happened a few years ago … when they had multiple people checking every single 
change.’ Cisco blamed the outage on human error” (Thibodeau, 2009). Other firms have had 
similar situations. As less flashy projects like database maintenance and hardware infrastructure 
are chronically ignored, the firm’s risk increases exponentially. “We’re not doing the maintenance 
we should be doing, and when you don’t do maintenance, you increase the probability of cata-
strophic failure” (Thibodeau, 2009).
Our discussion so far has been in general terms, but not all firms are created equal, and gen-
eral economic trends have microscopic consequences, which vary in a myriad of ways. A large 
company may, based on past financial decisions, assets on hand, liquidity, and so on, may have 
the ability—should they choose to exercise it—to weather financial storms with relatively little 
impact to IT budgets or projects. “But the impact may be much more acute at smaller companies, 
which may spend a higher percentage of their annual revenue on IT products and services but 
have far fewer ‘real’ dollars available to trim, compared with larger businesses …” (Weston 2001). 
One could make a case that smaller businesses are less reliant on in-house technology and more 
on vendors. To that end, their challenges may be even worse. “Take, for example, the semian-
nual headache of negotiating software site licenses. At some point, you begin to test the limits 
of your negotiating skills. The vendors can only shave off so much margin. What can you do? 

172  ◾  Information Security Management Handbook
The trade-off is unthinkable—telling users they’ll have to share software seats” (Weston 2002). 
A smaller firm could more easily revert to “pen and paper,” so to speak, but such firms may also 
have less bandwidth to map contingency plans. On the other hand, they have the advantage of 
working in presumably more agile environments. The ultimate question as to how a firm’s market 
capitalization impacts the damage of IT budgetary cuts is outside the scope of this discussion, but 
it is clear that each firm must address external challenges with a keen eye toward their specific 
business challenges.
All firms have the potential to capitalize upon crises. In an article for InformationWeek, Rusty 
Weston suggests using budget cuts as an opportunity to get creative with your IT priorities and 
expenditures. If senior management is cutting big projects in favor of cost-cutting, perhaps it is 
time to “try a plan B that lets you move ahead with at least some of your initiatives. Consider that 
in E-business, the best use of your time might be conducting usability or performance tests or, 
for enterprise applications, user focus groups” (Weston 2001), which might be more cost-effective 
while still delivering tangible business value. Sometimes, however, managers are not taking a criti-
cal eye to their specific dockets and workloads and scrambling to meet the bottom line and all 
costs. According to one study, “most managers have opted to trim the biggest part of the budget 
pie, labor costs, by instituting hiring freezes or, in three out of five cases, reducing head count” 
(Weston 2002). In an article that appeared in InformationWeek in 2002, analyzing the fallout of 
the U.S. economy following the terrorist attacks of 11 September 2001, it was noted that “only 
29 percent of the cost-cutters have frozen their IT projects, preferring instead to scale back the 
size of projects, reduce administrative overhead, or outsource work when possible” (Weston 2002).
For a contradictory example, we need to turn no farther than the U.S. government, which, in 
2005, increased its IT budget.* As noted by Grant Gross in ComputerWorld, “President George 
Bush’s proposed budget for the federal government’s 2006 fiscal year … includes an increase in 
IT spending, despite significant cuts elsewhere” (Gross, 2005). Although government and busi-
ness strategies may be arguably different—even drastically so—yet commonalities exist. One area 
in which the government has been notably at the forefront of policy and spending is the area of 
information security. Bush sought to increase spending, in particular “for information security at 
17 federal agencies … by $113 million…. The Information Technology Association of America 
(ITAA), an industry trade group, praised the IT budget plan.” “ ‘America must pick up the pace 
in science, math and engineering,’ ITAA President Harris Miller said in a statement. ‘Countries 
around the world have clearly signaled their intent to challenge U.S. leadership in technology. Our 
economic well-being depends on answering this challenge’ ” (Gross, 2005).
The importance of sound information security is a clearly understood maxim throughout 
government and business. Even as firms turn to outside vendors for solutions (e.g., Salesforce.com 
for Contact Relationship Management), they continue to place emphasis on stringent security 
requirements. But this field finds itself on the defense on several fronts. A survey by Ernst & Young 
conducted in 2003 “questioned whether organizations use their IT security budgets effectively. 
Nearly 50 percent of respondents admitted that their security spending is not closely aligned to 
their business objectives” (Goodwin, 2003). This is a fundamental problem, which is independent 
of economic circumstances. However, bigger the budget might be, it is the responsibility of profes-
sionals to manage it effectively to support the business. If it is not aligned effectively when times 
are good, it will be even worse when economic stress is applied. The results of this study are per-
plexing; they suggest that it is the department personnel and leadership who are pursuing projects 
*	The reader might recall that 2005 hardly marked a year of significant economic recovery since 11 September 
2001.

Slash and Burn  ◾  173
“not closely aligned to business objectives,” yet other data indicates that information security woes 
are a direct result of funding issues. To that end, “pressure to cut IT budgets is now the biggest 
obstacle to effective information security, a survey of 1,400 IT executives around the world has 
revealed” (Goodwin, 2003). The challenge for the information security specialist, consultant, and 
manager is to engage in a continuous evaluation of his projects and objectives to ensure that they 
are aligned constantly with business priorities and be agile where needed. A time of economic 
crisis—as the IT department is led to the proverbial guillotine—may serve as the critical catalyst 
that forces difficult but ultimately productive decisions.
References
Computer Weekly. IT budgets set to defy the worst predictions for 2009. Computer Weekly, p. 9, January 20, 
2009.
Flinders, K. Beware hidden costs of IT budget cuts. Computer Weekly, p. 8, April 7, 2009.
Grant, I. Untitled. Computer Weekly, p. 66, October 12, 2010.
Gross, G. Bush plan calls for more IT spending. ComputerWorld, p. 19, February 14, 2005.
Heires, K. Focusing on budget cuts. Securities Industry News, pp. 9–10, June 15, 2009.
Hume, L. Donaldson: ’06 budget will force technology, hiring slowdown. The Bond Buyer, p. 5, March 14, 
2005.
Manning, A. Technology is productivity. Modern Materials Handling, p. 10, December 2008.
Singh, M., Nath, S., and Walvekar, R. IT sourcing trends in the current market. Infosys Technologies Limited, 
pp. 17–19, January 2009.
Thibodeau, P. Cutbacks could be causing IT outages. ComputerWorld, p. 8, August 17/24, 2009.
Wagner, M. Hard-hit industry makes deep cuts in IT. InformationWeek, p. 89, September 14, 2009.
Weston, R. Don’t let budget cuts jeopardize progress, InformationWeek, 2001.
Weston, R. Cost cutting: When less equals less. InformationWeek, September 2, 2002.
Wettemann, R. With recession in the air, don’t just cut and react. InformationWeek, p. 64, March 3, 2008.


175
Chapter 14
A “Zero Trust” Model 
for Security
Ken Shaurette and Thomas J. Schleppenbach
When Was the Last Time You Changed 
Your Social Security Number?
This is an interesting question. Currently, for an individual living and working in the United 
States, a social security number (SSN) is the only thing that will truly stay with you “Until Death 
Do You Part.” No matter how clever we get, how many times we have moved, or how many con-
trols are in place to protect it, the tie between an individual and their SSN leaves us vulnerable to 
those trying to steal identities for their personal betterment.
There are three words or concepts we would like to expand on relating to protecting ourselves 
against those malicious people whoever they may be, trust, risk, and data privacy. We will elaborate 
all the ideas to support the concept of zero trust.
Trust
Definition of Trust:
◾
◾A charge or duty imposed in faith or confidence or as a condition of some relationship
◾
◾Something committed or entrusted to the one to be used or cared for in the interest of 
another
◾
◾On the character, ability, strength, or truth of someone or something
◾
◾One in which confidence is placed
A good dictionary (like the really big thick ones at the library) will usually tell roughly when 
a word was introduced.

176  ◾  Information Security Management Handbook
The origin of “trust” can be traced back to Middle English, probably of Scandinavian origin; 
akin to Old Norse “traust,” trust; akin to Old English “trēowe,” faithful where the first known use 
was in the thirteenth century.
So the word “trust” has been in our vocabulary for some time.
We as Americans seem to be trusting in nature. We go about our lives living the dream, work-
ing hard, getting an education, buying a house or a car, and spending time with our families. To 
do any of these things, we must expose ourselves to risk and are vulnerable to those who prey on 
the unsuspecting.
Let us look at three simple questions affecting anyone over the age of 18.
Did You Go to College? Did You Take Out a 
Loan? Do You Have a Credit Card?
If you can answer yes to any of these questions, what are the chances that personal information 
has been compromised and is stored on some geeks’ hard drive just waiting to be sold or used in 
some other potentially malicious manner.
The education industry in the United States has failed millions of students in the early years 
of the electronic age, and the Internet as it relates to Data Privacy has continued that trend with 
an open network philosophy. As of 2005, higher education and even elementary education pro-
vided access to the Internet with limited controls in place and the level of information sharing was 
expected to be open as a right or freedom from restrictions to education.
For people who attended higher education years ago, the student ID was an individual’s SSN. 
Even if the ID was something other than the SSN, a number of systems storing millions of stu-
dent records had weak access controls, thus making the information available to authorized and 
unauthorized people, especially hackers with little effort.
The banking industry, e.g., has been a target since the dawn of time from bank robbers to now 
those attempting to compromise individual accounts to move and steal money.
Anyone who has taken out loans or who have held credit cards is in a similar predicament of 
sharing private information to a entity in which we have to place a significant amount of trust. 
Consider the number of years that credit cards existed before regulatory requirements such as 
those put in place by VISA and the Payment Card Industry (PCI) when they first implemented 
the Data Security Standard’s (DSS’s), often affectionately named, 12-step program.
Before improved controls became a regulated requirement, just think of all of the electronic 
records with confidential data that were being stored in systems. Consider over the last 60 years 
all of the mergers and acquisitions, new systems, redesigns, and conversions; system development 
life cycles where developers made complete copies of a database; importing the data into test sys-
tems, with minimal controls, to be used for system testing and so on. Is there still the potential 
opportunity for someone to obtain those millions and billions of records on some old database? 
We wonder how great the odds are against us to have been missed from those database, especially 
those of us from the baby boomer age group.
Hackers, crackers, smackers, or snapperheads (one of my favorite words) have been gathering 
data for many years before and after the inception of the Internet. Accordingly, many systems and 
databases were compromised and information was downloaded and stored long before controls 
were in place like we see today.
For how long have we given out our personal confidential information freely; simply trusting 
that the information would be handled safely by the organizations we had to deal with in our daily 
lives and those that we have worked for over time.

A “Zero Trust” Model for Security  ◾  177
Risk
Are there risks in trusting? Of course, we see this all the time. In the movies we always hear, 
“but I trusted you,” betrayal seems to be commonplace to thicken the plot of any good movie or 
story. Unfortunately, this is also true in real life and business. Maybe the betrayal is not so much 
direct betrayal, but comes more from an inability of organizations to implement enough controls 
compared to the number of attackers looking for a way to gain access. Organizational challenges 
included difficulty outlining the risks so that informed decisions could be made to avoid a poten-
tial hazard to ourselves or the business.
So another word that ties directly into trust is risk. Trust is something that has to be established 
over a period of time; however, it is still necessary in the mean time until trust can be established 
to continue conducting business. As a result, to form an initial level of trust, we must go through a 
process of weighing and assessing risk. Consider the risks that are involved in trusting. They often 
are somewhat contrary to the true definition of trust, but that is where we are at in our society today.
Definition of Risk:
◾
◾To expose to hazard or danger
◾
◾To incur the risk or danger
◾
◾Possibility of loss or injury
◾
◾The degree of probability of a loss or peril
The word “risk” has also been in our vocabulary for a long time. The first known use of the 
word “risk” was in the mid-1600s. From one Webster resource site, it identifies the first known 
usage of “risk” to be in 1687.
Gregory H. Duckert, a noted author on risk management, states in his book titled Practical 
Enterprise Risk Management—A Business Process Approach, that common sense is the best friend of 
managing risk. And we know just how much management decisions are based solely on common 
sense.
To illustrate our point, let us use a real-life story to characterize what happens when a common 
sense approach to assessing and managing risk is not applied.
The story begins on a sunny fall day in late September in Wisconsin. Our author was in the 
northern part of the state, relaxing on a weekend, participating in the popular fall Wisconsin sport 
known as “hunting.” Specifically, he was walking the woods for the ruffed grouse (aka partridge in 
an oak tree) and sitting in a tree stand with bow and arrow for hunting deer.
After spending the morning sitting with the bow and arrows on a tree, our author decided to 
take his young yellow Lab for a walk to see if the dog would be able to flush a few grouse. The 
grouse population had been in one of its down years, but the walk would be good exercise and 
provide a chance to see if the dog training was working.
Leaving the house headed to the favorite grouse trail, Dad asked where I would be. I told him 
and he simply stated “Now we have had a lot of rain and where you’re going the roads can get a 
little tricky!” I said; “Okay, okay, yeah, yeah” and headed down the road.
As I reached the favorite trail, I was faced with a somewhat large puddle in the middle of the 
road. Now I usually parked just around the bend from the puddle, which was only a short distance 
farther. Looking back, I should have been hearing Dad’s words ringing clearly in my ears and done 
a better job of assessing the risk, but that is all in hindsight and we all know the saying, hindsight 
is 20–20. I should have probably backed up and pulled off the road and started the afternoons 
hunt from there, but noooo.

178  ◾  Information Security Management Handbook
Now let us take a closer look at the risks that were involved in the decision that was about to 
made here.
◾
◾Risk: The main goal is to return back to the cabin safely.
◾
◾Impact: The impact ranges widely; from missing out on one of Mom’s home-cooked meal, to 
ending up in the hospital and damage to the car.
◾
◾Likelihood: High
◾
◾Risk: Car gets stuck out in the woods.
◾
◾Impact: Spending the night in the woods and potentially ending up on an episode of 
“I shouldn’t be alive”
◾
◾Impact: A long walk to the nearest main road and the cost of a tow truck
◾
◾Impact: Severe damage to the car, resulting in even more expenses for repair
◾
◾Likelihood: High
Everyone performs mini risk assessments all the time as we make decisions in our daily life. 
Simply walking out of the house, we assess the risk of getting hit by a car as we cross the road, or 
the risk of other bad things happening if we decide to go out to eat in that bad section of town 
with the great restaurant. We weigh the impact of what could happen and the likelihood that 
it will happen to us. Experience plays a very important part in determining how successful or 
unsuccessful we will be at assessing risk. Surely, the author’s risk assessment decision would have 
been different now, if he could use hindsight, the experience that he now has available to better 
rate the risk.
The puddle did not look too bad, so our author just took the high side of the logging trail and 
made it past the puddle without incident. Guess the risk was not that great, but did we gauge the 
fact that we have to come back that same way later today?
Trail walking for grouse with the trusty yellow Lab doing what she was supposed to do con-
tinued without incident. After walking about three miles without seeing a grouse; it was time to 
head back to the car. It was now early afternoon and there was still time to get to the car, grab the 
bowing equipment, and get back out to the deer stand for the evening bow hunt.
We got back to the car, just a little tired but the exercise felt good, and it was still a very nice 
day to be outdoors. I cased up my gun, jumped into the car, and turned the car around to head 
back out of the woods. There it was the same large puddle, same place no change, but is the risk 
the same? With the first experience being successful, my experience would tend to lower the risk 
so there I was taking the high side of the puddle; however, this time I was on the other side of 
the puddle, the front tires spun a little and the entire vehicle slipped right into the deepest part 
of the puddle. This puddle turned out to be a bit more than a just a large puddle in the woods. 
Now that the car is stuck, it seems more like a small lake and darned if the risk of going past the 
puddle without getting stuck does not seem really high now.
The whole nose of the vehicle just beyond the bumper was now deep in water. Unfortunately, 
I was driving a Pontiac Grand Am and not a large four-wheel drive truck or modern SUV. I got 
out of the car and found myself standing in water just below my knees. Yuch, this was one very 
deep and slippery mud puddle. In northern Wisconsin, there are two basic types of soil; mostly 
you will find sandy soil, but there are some areas where the soil type consists of heavy sand and 
clay mix. Well, how lucky could I be that this was one of those sandy clay mixtures. I guess that 
was never included in my risk assessment; the likelihood that the less desirable soil would be here 
in this place of all places.

A “Zero Trust” Model for Security  ◾  179
I probably should have spent more time gathering risk data to include in my assessment before 
making my decision to proceed past the puddle. Such as:
◾
◾How deep is the puddle?
◾
◾What is the soil type: clay or sand?
◾
◾What is the probability of getting stuck?
◾
◾How much would be the impact of slipping into the deepest part of the puddle?
◾
◾Is the vehicle right to minimize the potential of going into the puddle and getting stuck?
Needless to say, I was without doing a very good risk assessment so I ended up very stuck. I took 
the tire jack out of the trunk and attempted to jack the car up. Next, I found some sticks, logs, and 
whatever I could that was solid and placed them under the front tires in an attempt to build a foun-
dation so the car could get traction. Then I tried to drive forward out of the puddle. This process 
was repeated … well … let us just say I tried more times than I can actually remember.
It was now starting to get late and I had about 45 minutes of light left in the day. Covered head 
to toe in mud, my blue Pontiac was now brown, very tired and physically exhausted, I was about 
10 miles from the nearest blacktop road and I had no cell phone to call for help. In the back of my 
mind now I could hear my father saying “Now we have had a lot of rain and where you’re going the 
roads can get a little tricky.” Why did not I take that into account in my risk assessment?
I walked up the road a short distance and sat down to think things over a little bit. As I was 
sitting there, to add insult to injury, a grouse strutted across the dirt road. I could hardly believe 
that my poor assessment process had put myself into this predicament. All I needed to do was 
park a mere 50 yards short from where I usually park and I would have avoided the puddle 
altogether.
Well I got a second wind and thought I could give the whole jacking up the car process another 
try, but once again it failed. I definitely needed a tow truck. I called the dog and we started down 
the dirt road toward civilization. I walked about 100 feet before I heard a vehicle or vehicles driv-
ing down a road some distance away. What luck, I thought I had wasted it all. They were getting 
closer and closer. Then here come four ATVs turning the corner and heading my way. It was a 
small group of guys out for a fall ride.
They pulled up to me and my sunken vehicle and one of them yelled out “Wooh-ho gettin’ 
awfully brave with that Pontiac, aren’t ya?” Swallowing my pride, as I was not in much of a posi-
tion to say anything to him in rebuttal, I asked if they could possibly pull me out. Luckily, they 
had some chains with them and they hooked up two of the ATVs, with me behind the wheel driv-
ing the car, we slowly pulled the Pontiac out.
I thanked them and stated that if I ever ran into them in the bar I would buy them a beer. It 
was just getting dark as I pulled into the driveway at the cabin. My father stepped out, looked at 
me and the car, just smiled ear-to-ear, shook his head, and said “It looks like you got stuck.” I did 
not say too much, as it was obvious I should have listened and heeded his warning, so I just took 
off my wet muddy clothes, took a hot shower, and called it a day.
What is that idiom? “Never trust to luck!” Gather data before making a critical decision in 
a risk assessment. Well, that day I got lucky. Oh FYI … luck should never be a part of your risk 
assessment process.
Obviously, I could have saved a lot of trouble by using a little common sense and considered 
the risk of going around that puddle. If I had, the whole experience could have been a pleasure 
memory about an enjoyable walk in the woods at the cabin.

180  ◾  Information Security Management Handbook
Surprisingly, businesses make decisions every day contrary to common sense. In doing so, they 
end up in systemic failure and the potential risk is that the organization could collapse. Failing 
organizations might end up making massive cuts in work force just to stay in business or needing 
to completely close their doors. Was the risk without at minimum a common sense assessment 
worth the end result? Could a few more minutes of data gathering to include in the assessment 
process been well worth a better outcome?
Using common sense to identify the risks in a trusted relationship will frame how we should 
view and handle each situation along with how the data and confidential information we store, 
transmit, or process should be handled and controlled. The methodology, the process of using 
common sense, provides us a very simple and basic ability to better assess and ultimately, better 
manage risk.
Data Privacy
Because “data privacy” is a phrase, rather than a word, it is not likely that it will be found in the 
dictionary like the words we defined earlier. However, one way to tell when a phrase started to gain 
wide use is to use the Web site www.newspaperarchive.com and search for the phrase. Although 
this is normally a pay Web site, it is available free when possessing a local library card. Use the site 
simply by searching for the word or phrase and sorting the results by date.
As for “data privacy,” there are a few uses that lie outside of our familiar use in computer con-
text, which dates back to the early 1950s. Usually, these terms are introduced in technical journals 
first and gradually find their way into mainstream use such as newspapers. The first computer-
related use of the term appeared in newspapers around 1971.
So starting about 15–20 years before the Internet, before anyone began commercially using the 
World Wide Web, ”WWW,” the term “data privacy” was already being discussed in information 
technology professional circles.
Data Handling
Let us dive briefly into the history of how data was handled in the past and then move forward to 
how data is viewed today.
As was mentioned previously, individuals trust the companies they work for and those orga-
nizations have clearly let their employees down by not adequately protecting their personal infor-
mation. This is probably why the government has established regulations on data privacy and the 
recommended secure data handling practices that are in place today.
Recently, while going through a few personal files from my past that I was considering discard-
ing, I noticed that my old pay stubs included the SSN, my medical cards included the SSN, and 
even most of my medical bills included my SSN printed on them. To safely discard these files and 
manage the potential risk of releasing my personal information to protect my privacy, I was going 
to have to shred the documents. Here is another simple example of how freely people’s personal 
information was used by many businesses in several critical industries. Thinking more on this brief 
trip back in history, it is not hard to remember how much we took our personal information for 
granted.
Today, we expect that the personally identifiable data we disclose to the company where we 
work or the many organizations where we are required to share our personal data, it will be much 
better guarded than it was in our past, or is it? Not all that long ago there was as lot of assumption 

A “Zero Trust” Model for Security  ◾  181
that the data was protected, but as the number of breaches grew, it was easy to realize that there 
are still some gaps existing with data handling. Too often there is a misunderstanding of the 
regulations that have been designed to improve the protection of nonpublic personally identifiable 
information (i.e., HIPAA, GLBA, FERPA).
Just the other day I took my daughter to a new oral and maxillofacial surgeon to set up an 
appointment to have her wisdom teeth surgically removed. We were handed a form that was 
mainly directed at my daughter to fill out, but there was a section for the parent/guardian to fill 
out. There was a line right after my name providing space for my SSN. I asked the individual at 
the desk, do you really need my SSN on this form? You have my medical card and my dental card, 
is not that good enough? She indicated that it was required for billing purposes. I subsequently 
asked how the information on the form would be handled from a privacy perspective. She confi-
dently stated that the information was protected under HIPAA regulations and would be handled 
appropriately. She was quick to ask if I had read the privacy notice; I did not say any more because 
I did not want to get into a heated discussion, but HIPAA is designed to regulate the protection 
of health data about their patients, not necessarily addressing my personal billing information. 
I was not the patient and my SSN in combination with my name is not technically considered 
PHI (Protected Health Information). In that case, how does that make it suddenly fall under the 
HIPAA regulations? As such, this makes me wonder what will establish requirements for protect-
ing my (nonpatient) information within that organization. Granted my information, although 
confidential, would not have regulated protection to ensure that it is handled appropriately. Do we 
simply trust that proper controls will be in place?
Moral of the story, there are still a lot of gaps in reasonable data handling, gaps in how 
organizations are training their staff to handle the data, and gaps in how the organizational 
information security programs are managing risk. The gaps carryover to the regulations that 
we assume protect all confidential data; HIPAA = protected health information, GLBA = non-
public personal information, SOX = financial data and financial statements, PCI/DSS = credit 
card data. Way too often each of these regulations puts blinders on an organization that looks 
to purely “comply” with a regulation but ignore the protection of data that does not directly fall 
into one of the categories of data they are regulated to protect. As an example, bank examin-
ers will review the banks for compliance with GLBA. The workpapers that examiners/auditors 
use when reviewing controls only consider how the banks handle customer data, they do not 
care how the organization handles employee’s personal data or data from other sources that, 
although not regulated, still requires privacy and security considerations. Having personally 
audited numerous banking organizations to the GLBA regulation, from personal experience, 
the bank has reached compliance, e.g., with incident response requirements because they have 
created an incident response plan that describes what to do should customer data be breached, 
but the plan has very limited information covering any other computer incidents. By regulation, 
they are compliant, but may not in my opinion have adequate controls in place for responding 
to incidents.
View on Information Security
In our history; just to qualify how far back we are talking, we only need to go back to 1997. Much 
less so today, but back in 1997 until about 2004, many organizations covering many industries 
would have laughed when asked if they were interested in completing an information security 
assessment or even a basic technical network vulnerability assessment. This included organizations 
ranging from the manufacturing industry to retail and banking.

182  ◾  Information Security Management Handbook
In 2001, we even tried to give customers a “free” technical network vulnerability assessment of 
their perimeter. This was offered as a value addition for other purchases they were already making. 
We had to discontinue the practice because it was beginning to take more sales effort just to “sell” 
(maybe it really was educate) to our customers on the value of getting their perimeter controls 
reviewed regularly because of the potential risk of attack from the Internet.
Why might this have been the case?
Many in the industry did not understand what a vulnerability assessment was a short decade 
ago. Now regulations such as the PCI DSS have set compliance requirements on organizations to 
perform at least quarterly vulnerability assessments for both internal and external networks.
Security awareness, security policy, and related security processes are interesting concepts, 
unlike pieces of technology, applications, or systems, you are trying to work with and guide some-
thing that has incredible dynamics and complexity, people—the human being. Let us call it the 
“human firewall.” This is often the last bastion protecting an organization’s data. Prepare the 
human firewall with information security awareness and test the controls of the human firewall 
with social engineering—phone and e-mail are sample common tests.
Technology, such as firewalls, routers, applications, and intrusion prevention devices and sys-
tems, has technical means to block or permit access to data and secure confidential informa-
tion. Unfortunately, after deploying thousands of dollars worth of technical controls targeted at 
protecting the data and properly securing information assets, it can all be breached in less than 
5 minutes by simply having one person in your organization say the wrong thing at the wrong time 
to the wrong person. Compliance may have been technically met, but all for naught if the data is 
compromised by careless people.
Human beings are walking vulnerabilities capable of spewing out lots of information and are 
virtually impossible to control. To secure the information held within humans, we would have 
to be able to treat them like machines, which they are not, and even so, there are still sufficient 
struggles to be faced with securing the data located on computing systems in the first place, but 
that also means you cannot forget to educate and train your users. The best way for people to learn 
how to protect data is to use Ken’s Golden Rule: “Treat all data you work with like it is data about 
yourself or your family and you will provide it adequate protections!”
So how does an organization control the flow of information?
Can the information contained within us be managed?
The control that covers information security is policy. It provides the framework for the infor-
mation security program. Policy provides definition for how people handle and treat the data they 
access and come into contact with each and every day. Organizations perform patch management 
and manage risk by establishing an information security program made up of various information 
security policies and standards along with supporting procedures and guidelines. The objective 
of the information security program is to establish the importance that executive management 
places on information assets, adequate controls, and compliance with regulations. The company 
must clearly assert that there is significant value (and importance) placed on protecting its assets, 
consisting of business process, raw data, customer information, and physical facilities. The compo-
nents that make up the program may consist of policy, standards, procedures, and guidelines. The 
program must have at least one policy statement to establish that information is important and 
must be protected and have the procedures to support the protection. To further clarify; Policies 
provide the directive statements that outline the information security objectives in topical areas. 
Standards may be used to provide added operational detail requirements to further support the 
policy statements. Procedures and guidelines document the instructive ways to implement and com-
ply with policy or meet required security standards. It is best never to mix policy with procedures. 

A “Zero Trust” Model for Security  ◾  183
Making policy that can be clearly communicated at all levels in the organization is critical to the 
success of the information security control. Policy must be read, understood, and everyone must 
accept the organization’s expectations to comply.
As noted, procedures dictate the process in support of policy and provide steps for how infor-
mation should be handled. Policy and Procedures are required for an effective information security 
program. Technology can be used to control access to sensitive data based on access controls and the 
authentication of user accounts for access to the organization’s systems or applications. However, the 
authentication process has a major flaw in that people hold the keys for proper access control. They 
hold the keys and are often the weakest link. Regardless how much money is spent on technical con-
trols, a weak human firewall can result in other controls being bypassed.
We have seen that even with the best of intentions, the human firewall is an easy target for 
social engineering attacks, simple mistakes, poor computing practices, and attacks from malicious 
code such as phishing and deception. It is human nature to create trusted relationships with other 
people. By nature, humans are trusting and the trust is increased by the customer service training 
that instills in people the importance of being friendly, the focus placed on customer satisfaction 
and being helpful. The challenge is that not all individuals have good intentions with the customer 
relationships they form and especially with how they handle the information received or gathered. 
Attackers prey on this natural trust tendency during the course of what would seem to be a normal 
conversation between two individuals, when in reality it is an attack; using data mining and the 
trust that the attacker uses to gain access to information they might not otherwise have access to, 
another of the risks of trusting.
So how do we bridge the gap between people and securing information?
At this point, having absolute control over how humans communicate and how they use and 
disseminate information is never likely to be attained, so there is no absolute way to control the 
flow of information within the organization. However, we can monitor and track activity verify-
ing that data is being handled appropriately to reduce the overall risk of trusted relationships; 
employer to employee, employee to employee, employee to employer, the organization to custom-
ers, and so on.
As already mentioned, because confidential data (i.e., SSNs) was historically so poorly handled 
by many organizations and industries, in the grand scheme of things, unless you were born 5–10 
years ago, there is a strong likelihood that your data was already compromised and the probability 
could be quite high that a large volume of personal information is sitting out on storage media 
somewhere just waiting to be released or used in some malicious manner. Does that mean that 
there are a lot of baby boomers just waiting to retire on the money they have spent their lives 
saving, but when the time comes, someone else will have already made plans for their retirement 
money by using the breached data?
Trust, but Monitor
In order for organizations to assess how well they are functioning, frequent tests of internal con-
trols and security must be conducted. The results should be used to determine where controls are 
efficient and effective and where new controls must be implemented.
Overall monitoring and logging operations should be established. The monitoring operations 
should be designed to produce results that are logical and objective. Test results that indicate an 
unacceptable risk in an institution’s security should be traceable to the actions subsequently taken 
to reduce the risk and improve controls. Tests should be thorough, providing assurance that the 

184  ◾  Information Security Management Handbook
security plan and internal controls are meeting objectives. Testing is an ongoing process and 
should be frequent enough to encourage a proactive process and increase the potential for more 
accurate control testing results.
Policies, standards, plans, and procedures must be audited regularly to determine control 
deficiencies that can be repaired so that the security program can be enhanced and improved. 
Introduced in this statement is the concept of “plans,” which refer to documentation such as 
business continuity/disaster recovery plans, incident response plans, or a vendor management 
plan. Overall, the security program should be tested frequently and with a variety of tests to 
ensure protection from both internal and external sources as well as technical and nontechnical 
attacks. Vulnerability management, user identity management, business continuity, and incident 
management are all parts of the bigger concept of risk management. Other components such as 
performance monitoring, monitoring of risk, and monitoring compliance by employees, vendors, 
or other third parties with security plans, laws, and regulations are all important factors for an 
effective program. A key to accomplishing this is monitoring access and activities by users and 
computers in the computing environment. To make monitoring possible, we have to consider 
whether there is logging of information that can be monitored. Operating systems, databases, 
firewalls, and even applications must have logging of events occur in order for most monitoring 
to be successful.
To provide a level of due diligence that can be illustrated by an organization so they can show 
that they are taking reasonable measures to provide data security and privacy for their custom-
ers and employees, an organization should not only manage, but monitor internal controls to 
ensure that employees are complying with policy and not engaging in illegal or immoral activi-
ties. Monitoring helps provide a proactive measure to identify that the human firewall has put 
confidential information and most importantly, the organization at risk. The risk of data loss, 
risk of financial loss, and the more difficult risk to assign a dollar value to reputational risk are all 
potential concerns.
Most industry regulations require monitoring and measurement to some degree, setting expec-
tations for organizations to track what is happening in the computing environment and implement 
incident response programs that can react to situations that are detected as unusual or warranting 
follow-up with appropriate actions.
Let us use schools for a case study. Remember when the hall monitor could see the bullies 
down the hall. White T-shirts with sleeves rolled up, with a pack of cigarettes, huddled together, 
a little pushing and shoving was happening, and there was this one poor individual who seemed 
to be the center of the attention. This undesirable bullying activity was quite easy to monitor and 
break up by dispersing the group.
Now fast-forward to today, how would the school or an organization accomplish similar moni-
toring of the bullying or malicious, maybe fraudulent, activity that occurs today? We can obvi-
ously start with knowing that somehow technology will be involved. The halls have moved to 
cyberspace and the criminal and the bullies have too—Facebook, MySpace, Twitter, LinkedIn, 
instant messaging, and e-mail; all popular places to frequent and use for malicious activity. In the 
corporate environment, the places may be less personal or social in use and could simply be our 
enterprise applications, databases, or the administrative tools that are used to manage our comput-
ing environments. These are all common places requiring levels of monitoring.
Are the activities in the cyberhalls or of our employees when using company resources tracked? 
“Trust, but verify,” a signature phrase Ronald Reagan used famously and frequently during his 
presidency. He employed it in public, although he was not the first person known to use it. President 
Reagan’s signature phrase has fresh currency in these times of cyber warfare and computer fraud. 

A “Zero Trust” Model for Security  ◾  185
In the fall of 2010, Forrester released research studies and articles hinting at a new concept of 
“zero trust.” Is it really all that different from the idea of “trust, but verify.” It is easy to do the first 
(trust), but how does a company or should a company accomplish the second (verify)?
Today, it is critical for organizations to have the ability to know what is happening in their 
network, on their systems, with the applications, or in their databases. The need to know who 
changed what and when is often difficult; compounded by few standards, technical jargon, and 
maybe just downright nonexistent logging or performance problems with logging access activities. 
Many tools for correlating logs are still complex and quite costly for wide adoption. If the informa-
tion can be brought together, it is probably followed by the basic difficulty of making sense of the 
technical content of the data gathered.
Thinking back to 1996 as a network manager of a large call center that took technical support 
calls for several large organizations. There were approximately 500+ technical individuals taking 
level 1 and 2 support calls 24 hours a day, 7 days a week, and 365 days a year. To say that these 
types of individuals love to experiment with technology would be an understatement. One day, 
the network team receives a call complaining about a network slowdown. The issue continued 
to repeat itself but was sporadic. The network manager put in place a network sniffer to assist in 
identifying the cause.
Network sniffers are programs that monitor and analyze network traffic, detecting bottlenecks 
and problems. They can be a self-contained software program or a hardware device with the appro-
priate software programming. Sniffers typically act as network probes to examine network traffic 
and make copies of the data without redirecting or altering it.
Now a plan of action was prepared just in case the “network slow down” began again. Then 
it happened, the call came in that the network was running slow, calling the network room, the 
sniffer was turned on and began capturing the sudden flood of traffic. Quickly, it was possible to 
identify the source of the additional traffic by the IP address of the device where it was originating. 
At that time, every system deployed used what was known as static IP addressing.
Static IP addressing involves manually configuring a unique IP address for each computer 
versus the use of DHCP (Dynamic Host Configuration Protocol), which uses an application 
to dynamically assign IP addresses. With dynamic addressing, a device can have a different IP 
address every time it connects to the network.
By checking the IP address mapping that charted location by floor, row, and cubicle, the network 
manager was able to very quickly go physically to the location to find out what was happening. The 
events were very cryptic and it was difficult to determine exactly what might have been happening 
based on the traffic alone. On arrival at the cubicle, the support representative was on a customer call. 
One of the desktops was being used to track the problem with the customer and the other appeared 
to be running some kind of tool that was running against the network. The representative turned 
around and upon noticing the network manager, immediately hit the power off button to shut the 
desktop system off. Under questioning about what was going on with the powered off desktop, the 
representative simply responded with a dumb founded look and said “What????” The bottom line is 
that he would not admit to anything special going on and did not indicate what the spare system was 
doing. Well the tool that the individual was running over the course of about 3 weeks turned out to 
be a “get admin” type tool that was very network resource intensive.
“Get admin” tools are applications specifically designed for attempting to gather the admin-
istrative password from an independent workstation, server, or network operating environment. 
More specifically, they were often used as hacking tools used to gain unauthorized access.
To determine what was being executed on that system took another week and several hours of 
research and other employees physically watching the activities of the rogue employee until they 

186  ◾  Information Security Management Handbook
visually were able to see what was being run on the system and what appeared to be happening. 
We were able to obtain access to further evaluate the workstation when the representative was on 
a break and had not logged out or locked the workstation (a temporary moment of forgetfulness). 
It was almost as though the Network Manager was the “bad guy” by simply trying to find out 
what was causing the network performance problems and impacting the ability to supply customer 
service.
With a good monitoring solution, a great deal of time could have been saved in the above expe-
rience. There are monitoring tools, such as Sergeant Laboratories, Aristotle, or one of the complex 
security information event management (SIEM) type systems, which would have been able to 
identify when the malicious application was downloaded, installed, and run, solving the confu-
sion and the problem of who did what, when, and where. There would have been a quicker time 
to resolution followed by a nearly zero effort in investigation other than running a simple report. 
Then to top it off, the log data could already have been gathered, chain of custody maintained, and 
digital forensics requirements met to support the termination of the employee or maybe a criminal 
case. Some SIEM tools manage to mitigate at least some of the technical knowledge required to 
make sense of the events collected.
Having the ability to monitor and quickly report what is going on within a networking envi-
ronment can save an organization from potential data breaches and identify risks before they 
escalate. The monitoring data can save significant cost when gathering evidence to support a 
criminal case. Best, if possible, is having multiple layers of monitoring, something close to the user 
to identify unusual activity backed up by individual detail logs at the other application, database, 
or operating system layers.
Is there a potential in organizations for proprietary information to be removed by an engineer 
who coincidentally just began a new job at the competition? Or maybe it is a simpler case and 
bank examiners are just asking the Information Security Officer for the evidence to illustrate day-
to-day activities being performed by authorized users of the system, application, or maybe more 
specifically of the system, network, or database administrators. If an organization has outsourced 
even only a portion of their information technology support, it is critical to monitor those highly 
trusted third-party vendor consultants. Often they have privileged access and there is limited log-
ging in place to allow tracking for purposes of change management.
Organizations scan the infrastructure including the firewall, Web servers, databases, and appli-
cations for vulnerabilities to verify secure coding or determine exploits, but how do we scan the 
human firewall? The human firewall (i.e., employees, contractors, and even our family) remains 
the weak link in any technical implementation of security controls. Organizations can do this by 
trusting that employee’s intent is pure, but verifying that their activities follow acceptable use and 
meet compliance with policy through monitoring their computer use behavior.
◾
◾Can we see when there is abnormal activity at odd hours?
◾
◾Can we identify what even looks abnormal? Do we know what is normal?
◾
◾Do we know when programs or browser add-ons are being installed?
◾
◾How would we know which administrator made the user access changes?
◾
◾Can we tell when a USB device or maybe the CD/DVD burner is used?
Historically, information technology has felt the need to protect users from themselves, by 
implementing technology to stop or restrict an activity when it is attempted, often reducing func-
tionality or productivity. Powerful technology tools are implemented with the intent to control 
the features and functionality that may be considered risky. In recent years, there has become 

A “Zero Trust” Model for Security  ◾  187
more and more end-user education. Better trained, technology savvy users. Not only can users be 
taught how best to use applications, systems, database, etc., appropriately, but how to use them 
in compliance with policy. It was not all that long ago we used to hear the information security 
officers state, “It isn’t worth trying to train the user they can’t even remember their password, how 
are they going to learn how to use the technology?”
Monitoring for the activities that users perform can be tough. Several applications do not 
support basic monitoring of changes by administrative-type users. Often database performance is 
impacted when the auditing feature is turned on. Storage can be an issue on systems and the data 
collected will be very cryptic and it can be even tougher when you do not know what to look for. 
Imagine trying to investigate an incident when you do not even have the data to analyze.
Forrester Research in September identified a so-called “zero trust” model for security. This 
model has revived debate about the way organizations secure their networks. The concept of “zero 
trust” means that end users are no more trusted than outsiders. As such it is important for orga-
nizations to monitor user traffic, from the outside as well as the inside. With this model, security 
becomes an even more integral part of the network.
There are usually two excuses why organizations do not monitor user activity in some way.
	
1.	The first reason is that organizations do not have the manpower to devote to log monitoring. 
I would not want to allocate manpower to watching logs as they scroll by on the screen. It 
would be a boring, monotonous job and it is not likely the person would even understand 
the logged data or recognize what was abnormal or what they should be looking for.
	
	
Have you ever had to deal with a security breach? Does your incident response plan actu-
ally provide for a way to identify that an incident is suspected or does it magically just decide 
that customer data has been breached and you need to start notifications? How do you inves-
tigate what happened and do you have forensic evidence of a possible crime? Investigations 
can be lengthy (and costly), and the more systems or users involved, the longer it takes.
	
	
Having the right user activity data to know what happens in your network, applications, 
databases, and systems can make it possible to not only detect data breaches, identify non-
compliance with end-user policy, but also detect and provide evidence of criminal activity 
using the computer.
	
	
With the right tools, your organization could prevent a breach or at least prevent serious 
collateral damage.
	
2.	The second excuse is that monitoring solutions are too expensive. How expensive is an inci-
dent if you do not catch it quickly? What happens if you do not have enough evidence of 
what happened or if you cannot meet examiner monitoring requirements?
	
	
At minimum, network server logging should be turned on to gather as much information 
as possible. Then at least maybe you will have lots of information for when the stuff hits the 
fan or when you try to explain why you cannot figure out what happened or how long it has 
been going on for.
	
	
There are solutions available to easily and reasonably monitor user activity. Sure there are 
also the very expensive vendor solutions to centralize logs and those often take a lot of effort 
to manage. Not many organizations can afford the price tag or the resources.
As new legislation, such as the looming PCI deadline and tracking of user’s (especially admin-
istrative) activity, becomes a hot button for examiners, logging is something organizations will be 
scrambling to implement as they try to better protect customer information. Simply logging is 
not enough, showing evidence that review of logs is next and having the technical knowledge to 

188  ◾  Information Security Management Handbook
understand the content will become issues. It is not enough just to generate the reports of activity 
and file them, someone has to look at them or monitor the data interactively.
Another aspect to “zero trust” is how we personally handle our private information. Each 
individual has a responsibility to protect themselves against the constant barrage of scams and 
phishing attacks through personal e-mail and links embedded within the Web sites we visit that 
have the potential for downloading Trojans and other applications (i.e., keyloggers, botnets) to 
capture our information.
In spring 2011, Epsilon, the largest distributor of permission-based e-mail in the world, had 
a data breach revealing billions of e-mail addresses. These types of breaches open the door for a 
surge of targeted phishing attacks often referred to as “spear phishing.” Not only when these types 
of breaches occur should an individual exercise a healthy dose of cautious skepticism toward any 
e-mails that they receive directly to their home e-mail accounts, even when you are a customer of 
the company allegedly sending the e-mail or even when the e-mail looks convincingly legitimate, 
do not trust it.
Many people have had this happen to them more than once, a call comes from their wife stat-
ing, “I was browsing this website looking for Old English sheepdogs and this thing popped up, 
so I clicked on it and now the screen is blank. What should I do?” As one could guess, malicious 
code was installed and wiped out the system. Typically, the first response might be, “You shouldn’t 
have clicked on anything” where the response always received is, “Well how am I to know that?” 
Most everyone at some time has had the “false alert trojan” pop up. One time comes to mind 
watching scores during NCAA basketball’s March Madness from a popular and legitimate Web 
site for sports.
It is important to maintain up-to-date antivirus and even personal firewalls with some level 
of basic intrusion prevention. Be careful, just implementing a tool can lead to overconfidence and 
a sense that now the system cannot be attacked. These tools alone are not a silver bullet, they do 
not catch everything, and hackers continue to get cleverer about how to compromise systems. And 
there is still the Human Firewall to keep up to date.
In its simplest form, security can be defined as the state of being free from unacceptable risk. 
The journey to a secure computing environment remains exciting, with a never-ending goal of 
managing risk in mind. Implementing a proactive yet flexible security program, which includes 
proactive user and computer activity monitoring, will allow both organizations and individuals at 
home to foster a model of “zero trust.”
About the Authors
Ken Shaurette is an experienced security and audit professional with a strong understanding 
of complex computing environments, legislative and regulatory requirements, and security solu-
tions. He is a founding member and past president of Western Wisconsin InfraGard Chapter, past 
president of ISSA–Milwaukee (International Systems Security Association), current president and 
founding member of ISSA–Madison, past chairman of MATC Milwaukee Security Specialist 
Curriculum Advisory Committee, member of Herzing University’s Department of Homeland 
Security Degree Program, and member of Western Wisconsin Association of Computer Crime 
Investigators (WWACCI). He has security information published in several books and trade mag-
azines. In his spare time, he works as director of IT Services for Financial Institution Products 
Corporation (FIPCO®), a subsidiary of the Wisconsin Bankers Association. If you would like to 
contact Ken, he can be reached via e-mail at kshaurette@charter.net.

A “Zero Trust” Model for Security  ◾  189
Thomas J. Schleppenbach, CISSP, CISM, is a senior information security advisor with over 
20 total years of IT experience. He is a trained IT auditor and assessor, who focuses on helping 
organizations with secure infrastructure design. He provides strategic security advice that helps 
organizations plan and build information security programs for compliance with legal and regu-
latory requirements. He is a member of the Western Wisconsin Chapter of InfraGard Executive 
planning committee and a member of the Wisconsin Association of Computer Crime Investigators 
(WACCI). For questions or comments, contact Tom at tjschlepp@schleppenbach.org.
References
Kindervag, J. No more chewy centers: Introducing the zero trust model of information security. Forrester Research, 
September 2010. http://www.forrester.com/rb/Research no_more_chewy_centers_ introducing_zero_trust/q/
id/56682/t/2.
Merriam-Webster Online. http://www.merriam-webster.com/dictionary.
Wagley, J. Zero trust model. Security Management. http://www.securitymanagement.com/article/
zerotrust-model-007894.


DOMAIN
4
APPLICATION 
DEVELOPMENT 
SECURITY
System Development 
Controls


193
Chapter 15
Application Whitelisting
Georges J. Jahchan
Last year (2010) has seen the proliferation of some high-profile pieces of malware that targeted 
attacks aimed at specific organizations and were initiated for a specific purpose that varies from 
sabotaging industrial machinery (reportedly, uranium enrichment centrifuges in Iran) to wide-
scale industrial espionage.
By several security experts’ accounts, StuxNet is by far the most sophisticated piece of 
malware ever launched, targeting what was at the time four as yet undisclosed vulnerabilities 
in the Windows operating system and relying on stolen digital certificates. Experts believe 
it was purpose-built to cause physical damage to machinery controlled by Siemens’ SCADA 
industrial control software. StuxNet is also able to mutate and propagate from one system to 
another across a network. For example, in an industrial system in which SCADA controls the 
flow of oil to the parts of a machine that need it to function, StuxNet could be programmed to 
instruct SCADA to stop the flow of oil while a machine is running and simultaneously feeding 
sensor signals that all is OK with the flow of oil, potentially leading to physical damage or out-
right destruction of the machine. While typical malware size is quite small (tens of kilobytes), 
StuxNet is hundreds of kilobytes in size and is widely believed to be the work of a government 
sponsored team of programmers, with significant time and resources at their disposal.
Another big story of 2010 was Operation Aurora, which by the accounts of the targeted soft-
ware publishers (Google and Adobe among others) went on for months. It is widely believed to 
be the work of Chinese hackers. Operation Aurora exploited an undisclosed vulnerability in the 
Internet Explorer browser.
Theoretically, the targeted sites or systems were protected using conventional (blacklist-based) 
antimalware technology. Application whitelisting vendors claim that such attacks would not 
have been successful had the victim systems been protected by a properly configured application 
whitelisting solution.
Antimalware technology has relied on identifying known bad or suspicious bit patterns in files 
to prevent malware from exploiting vulnerable systems. Herein lies the problem. Tweak a known 
piece of malware and the malware is likely to evade blacklist detection. In this cat-and-mouse 
game, antimalware vendors released an estimated 6 million new malware signatures in 2010. 
Come to think of it, on average, a new signature was released every 4.5 seconds, round the clock. 

194  ◾  Information Security Management Handbook
There is little in terms of assurance that signatures will be deployed onto systems before malware 
targets them. New malware is being created and spreads faster than antimalware vendors can put 
their hands on the code and create its signatures, and end users download these signatures and 
distribute them where they are needed—on the endpoints they are supposed to protect.
To address the variations in malware code, heuristics have been introduced. However, with 
strong heuristics enabled, it takes more CPU cycles to inspect content, and the technology is prone 
to false-positives.
Behavior rules were added to improve detection capabilities, again these cause additional pro-
cessing overhead and are prone to false-positives.
In a bid to improve the time to detect, Trend Micro is now proposing their Titanium Suite, 
a cloud-based antimalware solution with client components installed on end-users systems. 
However, blacklist-based technology still falls short of achieving the levels of protection required 
by businesses and individuals.
In a Q2 2010 evaluation of 10 corporate endpoint security suites from various vendors (AVG, 
ESET, F-Secure, Kaspersky, McAfee, Norman, Panda, Sophos, Symantec, and Trend Micro), NSS 
Labs found their effectiveness at stopping malware at download time varied between 35 percent for the 
worst performer and 88 percent for the best performer. In other words, in the best of cases, 12 pieces of 
malware out of every 100 that knock on a system’s doors are likely to evade blacklist-based antimalware 
defenses. The consequences of such evasion can range from a mere inconvenience to catastrophic.
Furthermore, according to the same NSS Labs tests, it took on average between 4.6 hours and over 
92 hours for the vendors to block malicious Web sites. Ample time for such sites to spread malware.
In this context, a new endpoint security line of thought has emerged: instead of blocking the 
known or suspected bad (blacklist), why not allow only authorized code to run and block every-
thing else, regardless of its nature. Enter application whitelisting technology.
The theory goes that by only allowing known good applications and blocking everything else, 
application whitelisting technology can effectively protect organizations against unknown (zero-
day), or new variations of known malware, in addition to preventing execution of unauthorized 
applications, and a host of other collateral benefits.
In other words, among its benefits, a properly configured application whitelist acts as a strong first 
line of defense against unauthorized applications, which includes malware—known and unknown 
as well as applications not explicitly allowed by policy. As of the writing of this chapter, technology 
solutions were available from a handful of vendors: Bit9 (Parity Suite), CoreTrace (Bouncer), 
Lumension (Application Control), McAfee (Application Control), Microsoft (AppLocker—on 
Windows 7 and Server 2008 only), and Sophos (Endpoint Security and Data Protection).
In this chapter, the author will get into the details of managing application whitelists and solu-
tion deployment in a corporate environment, taking one such application with which the author 
is thoroughly familiar—Parity Suite from Bit9—as an example.
Architecture
The solution architecture consists of the following components:
◾
◾Server software provides central file security management, event monitoring, and a live 
inventory of files of interest on all agent systems.
◾
◾Agent software, which runs on servers, desktops, and laptops, monitors files and either 
blocks or permits their execution based on security policy settings. It also reports new files 
to the Parity server.

Application Whitelisting  ◾  195
◾
◾Knowledge service compares new files introduced on computers running the agent to a 
database of known files, providing information on threat level, trust factor, and software 
categorization.
Solution Architecture
Server
Server software runs on standard Windows computers. It can be run on a dedicated system or as 
a virtual machine. The server is used to manage policies, including software and device approvals 
and software bans, and to provide visibility into events and file activity on computers running 
agents. The console, a convenient Web-based user interface, provides access to the server from any 
connected computer.
The server database uses Microsoft SQL server, either on the same machine or on separate 
hardware. Key data is accessible outside of the solution through a series of published views in the 
database that are part of the Live Inventory SDK.
Integration with active directory: Named users, computers, and groups may have already been 
defined using Microsoft Active Directory. The Server can take advantage of the existing Active 
Directory environment to set access privileges for users of the console, assign security policies to 
computers, provide user and computer metadata, and designate certain groups or users to be able 
to install software (and have it automatically approved) on managed computers.
Agent
Agent software running on Windows client computers monitors file, device, and registry activity 
and communicates with the server when necessary. Even when disconnected from the server, the 
agent continues to enforce the last specified bans and security policies it received. When a discon-
nected computer running the agent reconnects, the agent receives updates from the server and com-
municates relevant file activity during the time it was off the network. Parity agent runs silently in 

196  ◾  Information Security Management Handbook
the background until it blocks a file, at which point it displays a message to the computer user that 
explains why the file was not permitted to execute. Depending on the file state and the agent’s security 
level, the agent may also let the user on the client computer choose to run an otherwise blocked file.
Parity Knowledge Service and Trust Rating
Parity Knowledge is a Web service, hosted by Bit9, that helps identify and classify software discov-
ered in your network by comparing it to an extensive database of known files. Based on weighted 
analysis, Parity Knowledge service further assigns a threat level (malicious, potentially malicious, 
unknown, or clean) and a trust rating (0–10 or unknown) to each file. Parity server can include 
this information in its live file inventory so that you immediately know the threat status and other 
key information about the files on your systems. With Parity Knowledge enabled, any file in the 
Server inventory can be analyzed to get whatever information is available.
A file’s trust rating goes beyond the information available from an antivirus scan. It is based on 
a series of factors, including how long and on how many computers the file has been seen, whether 
it has a trusted digital certificate, and the results of scanning by multiple antivirus programs.
For example, a file that scans as clean on antivirus programs has a trusted digital certificate 
from a known publisher and appears on many computers for a long period of time might have a 
Parity trust rating of 10, highly trusted. Another file that also produces clean antivirus scans but 
has only recently been seen is on very few computers and does not have a digital certificate might 
only get a trust rating of 2, low trust.
Because the operational model of Parity is policy-based, we shall start by delving into the 
important aspects of policies.
Security Policies and Levels
Parity policies are named groups of protection rules shared by targeted groups of computers run-
ning the Parity agent—every computer running the agent must belong to a policy. You create 
policies based on your security and organizational requirements. For example, you might base 
policy membership on functional group (marketing, customer service), location, or type of com-
puter (laptop, desktop, server).
Each policy has its own Parity agent installer, which is automatically generated on the server when 
the policy is created. Each installer automatically assigns a policy to each agent it installs. However, 
if so desired, the Parity server can assign a policy based on Active Directory data for the user and/or 
computer running the agent, each time the computer with the agent connects to the server.
Policy Settings
Policy settings define the way you want Parity to manage a particular group of computers. There 
are three categories of settings:
Basic policy definitions: These include the policy name and other descriptive information, 
whether computers in this policy allow agent upgrades, whether live file inventory is activated for 
these computers, and the basic security level (the Mode and SecCon) for the policy. Modes and 
SecCons are described in more detail below.
Device settings: Device settings control the way a Parity policy treats removable devices. 
Different rules control read, write, and execute operations on devices, and devices can be desig-
nated as approved, to be treated differently than nonapproved devices.

Application Whitelisting  ◾  197
Advanced settings: Advanced policy settings control whether computers in a policy have certain 
file types blocked, whether files installed by specially designated “trusted” users are allowed to 
execute, and whether special treatment of certain directories is enabled. The possible values are 
Active, Off, and Report Only.
Modes and SecCon Levels
The SecCon (security condition) level in a security policy controls whether pending files (appli-
cations that may be unidentified and that have not been approved or banned) are allowed to 
execute. The availability of different SecCon levels enables you to choose a setting for each policy 
that suits the security and user requirements for the group of computers associated with that 
policy.
Parity offers three different modes of operation: Visibility and Control, Visibility Only, 
and Agent Disabled. The available SecCons for each mode are described in the following 
table.
Mode
SecCon 
Level 
Visibility and Control Behavior
Visibility 
and 
Control
Lockdown
Protects against unwanted software:
•	 Blocks banned and pending files
•	 Allows only approved applications to execute
Tracks file activity using Parity discovery, analysis, and monitoring 
tools. Tracks events
Visibility 
and 
Control
Block and 
Ask
Protects against unwanted software:
•	 Blocks banned files
•	 Displays a dialog for pending files that allows users to block 
or execute them
•	 Allows approved applications to execute
Tracks file activity using Parity discovery, analysis, and monitoring 
tools. Tracks events
Visibility 
and 
Control
Monitor
Protects against all known unwanted software:
•	 Blocks banned files
•	 Allows pending files and approved files to execute
Tracks file activity using Parity discovery, analysis, and monitoring 
tools. Tracks events
Visibility 
Only
Visibility 
Only
Allows all files (approved, pending, and banned) to execute
Tracks file activity using Parity discovery, analysis, and monitoring 
tools
Tracks events
Agent 
Disabled
Agent 
Disabled
Agent is disabled and Parity does not track or block anything on 
endpoints in this policy. The agent continues to periodically 
communicate with the Parity server

198  ◾  Information Security Management Handbook
Following are screenshots of the relevant screens:
Computers (managed endpoints)
Events
Customizable executive dashboards

Application Whitelisting  ◾  199
The initial deployment is either with the Agent Disabled, which essentially deploys the 
agent software with no policy, or in the Visibility Only mode. As soon as a Visibility policy 
is deployed on the endpoint or the endpoint is moved from Agent Disabled to Visibility 
Only, it is initialized. The initialization process involves a comprehensive scan of all files 
on local file systems on the endpoint, the computation of hashes for all the files found, and 
forwarding of that information to the server. Depending on the number of files found on 
the endpoint, initialization takes at least an hour and is resource-intensive on the endpoint, 
the network, and the server. It is recommended that the deployment be performed outside 
business hours and be in phases so as not to create overload conditions on the Server or on 
the network.
Once initialization is complete, the hashes of all files found on the system are stored in the 
database and are marked as in the Visibility only mode. As soon as a Visibilicontrol is enabled, these 
executables will be allowed to run. Any files that find their way onto the system postinitialization 
will be marked as be marke and depending on the applied policy, may be allowed to run (Visibility 
Only and Monitor), generate a prompt on the endpoint upon execution (Block and Ask), or are 
prevented from executing (Lockdown). In all cases, creation/execution events are reported to the 
console.
Contrary to blacklist-based technology that searches for known bad bit patterns and attempts 
to identify suspicious software behaviors, application whitelists rely on:
◾
◾Hashes (MD5, SHA1, and SHA256) that uniquely identify each executable, regardless of its 
file path, file name, or network location. Computing a file hash takes far fewer CPU cycles 
and less memory than does real-time signature pattern matching, especially in the case of 
large executables. The hash function is run once when the program is executed. A whitelist 
check involves computing the file hash and looking it up among the file hashes stored in the 
whitelist database. If it is not approved, the type of enforcement policy being applied to the 
system will determine the behavior.

200  ◾  Information Security Management Handbook
Screenshot of Block Message on Endpoint while in Lockdown Mode
◾
◾File state, whitelisting, and blacklisting
	
Several key feature groups work together in Parity to secure managed computers. At the 
heart of this security capability is the ability to classify files according to their state. Groups 
of security rules, called policies, can control how different groups of computers treat files in 
different states. This section describes primary file states—approved (whitelisted), banned 
(blacklisted), and pending—and how they can be changed.
◾
◾Global file state
	
The server maintains a central database of unique files (determined by hash) for all execut-
able files tracked on managed computers running the agent. Each file has a global state, 
which indicates how it is to be treated on Parity-managed computers.
State
Description
Approved
Allowed to execute on all computers
Banned
Banned by hash and not allowed to execute on any 
computer running in Visibility and Control mode
Approved (Custom)
Allowed to execute on all computers in one or more 
policies
Banned (Custom)
Banned by hash from execution on all computers in 
one or more policies (in Visibility and Control mode)

Application Whitelisting  ◾  201
State
Description
Pending
Not Approved or Banned (globally or by policy). 
Blocks or permits execution of a pending file 
depending on the security control level of the Policy 
of the computer attempting the execution
	
In addition to its primary global state, some files in the database have a more detailed global 
flag that may identify the source of its approval or other decisions made about it. For exam-
ple, a file with a global state of “Approved” in the File Catalog may have a global flag of 
“Installer” on the File Details page.
Screenshot of File Details

202  ◾  Information Security Management Handbook
◾
◾Local file state
	
While the Parity server keeps a global state for a file, each instance of a file on a computer 
in the Parity network has its own local state. Files that are globally Banned or Approved 
have the same local and global states. Files with a global state of Pending may have different 
local states. In particular, it is possible to locally approve a file by a variety of methods, as 
long as that file was not globally banned. The local file state can be viewed on the Files on 
Computers tab of the Files page.
State
Description
Approved
This instance of the file is approved for execution. Local approval can be 
due to approval by name or hash for all computers in a policy or all 
computers controlled by Parity. It also could be due to a global Parity 
approval method, a change in control level, or an explicit Local Approval 
of this single file instance. Locally approved files can have a global state 
of Pending or Approved, but cannot be Banned
Banned
Banned by hash and not allowed to execute on any computer running in 
Visibility and Control mode. This instance of the file is banned from 
execution. A file that has a local state of banned might be banned on all 
computers in a policy or all computers controlled by Parity. Its global 
state could be something other than banned, depending upon how it 
was banned
Pending
Allowed to execute on all computers in one or more policies. This 
instance of the file has not been approved or banned. Its execution is 
blocked or permitted based on the control level for the policy of the 
computer it is on
Deleted
This instance of the file has been deleted, but the record of it still exists 
in the Parity database
◾
◾File approval methods
	
Software approval ensures that users of computers running Parity agent can freely install 
and run known-good applications regardless of the Parity settings and control level enforce-
ment level in effect. Approving files, often called “whitelisting,” also can reduce the time 
devoted to tracking files that you are not concerned about. Parity supports several comple-
mentary methods for approving software on computers:

Application Whitelisting  ◾  203
◾
◾When there is a need to preapprove applications to run on all computers, trusted directories, 
publishers, or updaters can be designated to automatically generate approvals.
◾
◾Individual files can be approved by hash, either for all computers or by policy.
◾
◾When there is a need to approve software for installation on selected individual computers, 
either designate trusted users (or groups) to perform installations, or choose one of Parity’s 
local approval methods.
◾
◾File ban methods
	
In Visibility and Control mode, Parity allows banning of specific files from executing on all 
computers, or on computers associated with specified policies. Files can be banned using the 
following methods:
◾
◾File-name bans ban execution of named files on either all systems running the Parity agent 
or on all systems in specific policies.
◾
◾Hash bans prevent files matching a unique hash from executing regardless of the file name 
used. They are enforced on either all systems running the agent or on systems in specific 
policies. More than one file can be banned in a single operation by importing a file contain-
ing the list of hashes that are to be banned.
◾
◾Custom rules
	
In addition to the variety of ban and approval rules described previously, Parity pro-
vides other ways to protect computers, allow needed software to run, and optimize 
performance.
	
	
Custom rules allow the designation of one or more paths, either to the directory 
or the file level, at which certain activities are allowed or blocked. In some cases, this 
involves changing the state of files, but in others it simply allows, blocks, or disables 
certain behavior on a case-by-case basis without any global rule changes. Custom rules 
can be used for File Integrity Control, to create a Trusted Path for installation directo-
ries, to reduce tracking of files in directories known to be safe or not of interest, and for 
many other purposes you can configure. These are covered in detail in the Custom rules 
section next.
◾
◾Trusted directories are network shares used to distribute authorized applications on end-
points. They relieve security administrators from the burden of having to allow each indi-
vidual deployment package to run.
Trusted Directories Screenshot
◾
◾Trusted publishers: Allows packages digitally signed by selected vendors to run without 
intervention and have the installers and all resulting files automatically added to the 
whitelists.

204  ◾  Information Security Management Handbook
Trusted Publishers Screenshot
◾
◾Trusted updaters: Allows updates to select applications to run without prompt, with the 
update packages and resulting files being automatically added to the whitelists.
Trusted Updaters Screenshot

Application Whitelisting  ◾  205
◾
◾Trusted users: Users who are allowed to bypass policy. In a high security scenario, no one 
should be allowed to bypass policy, but that feature can be enabled in exceptional situations.
Trusted Users Screenshot
◾
◾Custom rules: Some custom rules take precedence over other (noncustom) rules and settings, 
including bans and approvals:
◾
◾A custom rule that specifies an Execute Action takes precedence over all other rules. For 
example, if a custom rule specifies that a specified file is allowed to execute, that file can 
execute even if it is banned by hash. If a custom rule specifies that a file is blocked from 
execution, it will be blocked even if it is globally or locally approved.
◾
◾A custom rule that blocks writing takes precedence over other rules, whether “Block” is cho-
sen on the Write Action menu or “Prompt” is chosen and a user clicks “Block” in response 
to a prompt on an agent computer.
◾
◾A custom rule that has a Write Action that approves (Approve, Approve as Installer, or choos-
ing Approve on the agent computer for a Prompt rule) does not take precedence over other 
rules that block writing. Currently, this is limited to the case in which a Device Control rule 
blocks writing, regardless of any custom rule that would allow it.
◾
◾Each Parity policy includes an “Enforce custom (file and path) rules” setting permanently 
set to “Active.” One can click on this rule to change the notifier message that appears on 
agent computers when a custom rule blocks an action.
◾
◾For computers in Visibility Only policies, custom rules that would block a file have no effect, 
although they still generate events. Similarly, rules that approve a file do change the file state, 

206  ◾  Information Security Management Handbook
but in Visibility Only, this has no effect on file execution. “Ignore” setting on the Write 
menu (see below) is effective in Visibility Only.
Field
Description
Rule Type
The type of rule you want to create, which changes other options and 
defaults on the Add/Edit Custom Rule page to partially preconfigure certain 
common rule types. Fields whose values are fixed for the chosen rule type 
are hidden. Inline hints are shown for setting the values of the fields that 
remain present. The menu choices are:
•	 File Integrity Control: Protects specified folders or files from being 
modified
•	 Trusted Path: Defines folders or files for which file execution is always 
allowed
•	 Execution Control: Controls behavior when an attempt is made to 
execute a file matching the rule
•	 File Creation Control: Controls behavior when an attempt is made to 
write a file matching the rule
•	 Performance Optimization: Specifies folders or files to avoid tracking 
(execution will still be monitored)
•	 Advanced: Defines custom behavior for controlling file execution, 
creation, and/or tracking. Choose Advanced for the greatest selection 
of options
Operation
The type of operation the rule affects. The menu choices are Execute, Write, 
or Execute and Write
Execute Action
The action to take when there is a file execution attempt matching this rule. 
This menu appears when the Operation choice is Execute or Execute and 
Write. The choices are:
•	 Default: Apply existing policy settings and other noncustom rules to file 
execution attempts matching this rule, and do not process other 
custom rules
•	 Allow: Allow file(s) matching the rule to execute in the specified path, 
even if Parity would otherwise block execution
•	 Note that the promotion state (whether the file is treated as an installer) 
will depend on the calling process (e.g., if the caller is promoted, the 
newly created process will also be promoted)<
•	 Block: Prevent the file from executing. When Block is selected, the 
Display Notifier checkbox will display. By default, agent computers see 
a notifier when a block occurs due to this rule. If you remove the 
checkbox, the agent computers do not receive notifications when this 
rule blocks a file execution
•	 Promote: Promote (treat as an installer) any file matching this rule. Note that 
even if promoted, whether this file can run or not depends on its existing 
file state and the SecCon of the machine on which the execution is 
attempted. If the file is allowed to run, any files written by it will be locally

Application Whitelisting  ◾  207
Field
Description
approved unless already banned, and they will also be promoted if the 
process that created them also attempts to execute them
•	 Allow and Promote: Allow any file matching the Path or File specification 
to execute regardless of its state, and promote it (treat it as an installer). 
Files written by a file matching the rule will be locally approved unless 
already banned. See the section “Trusted Paths” for more on choosing 
to trust execution of files by path name
•	 Prompt: Display a notifier dialog to the users when an attempt is 
made to execute files matching this rule. The dialog allows them to 
Block or Allow execution of the file (and locally approve it if 
allowed). The behavior for the choice the user makes is the same as 
the behavior if the rule specified either Block or Allow. Note that 
blocking or allowing execution from a Custom Rule prompt does not 
change the global approval or ban state
•	 Report: Report (as an event) execution of files matching this rule, 
regardless of file state
Write Action
The action to take when there is a file execution attempt matching this rule. 
This menu appears when the Operation choice is Execute or Execute and 
Write. The choices are:
•	 Default: Apply existing policy settings and other noncustom rules to file 
execution attempts matching this rule, and do not process other 
custom rules
•	 Allow: Allow file(s) matching the rule to execute in the specified path, 
even if Parity would otherwise block execution
•	 Note that the promotion state (whether the file is treated as an installer) 
will depend on the calling process (e.g., if the caller is promoted, the 
newly created process will also be promoted)
•	 Block: Prevent the file from executing. When Block is selected, the 
Display Notifier checkbox will display. By default, agent computers see 
a notifier when a block occurs due to this rule. If you remove the 
checkbox, the agent computers do not receive notifications when this 
rule blocks a file execution
•	 Promote: Promote (treat as an installer) any file matching this rule. Note 
that even if promoted, whether this file can run or not depends on its 
existing file state and the SecCon of the machine on which the 
execution is attempted. If the file is allowed to run, any files written by 
it will be locally approved unless already banned, and they will also be 
promoted if the process that created them also attempts to execute 
them
•	 Allow and Promote: Allow any file matching the Path or File specification 
to execute regardless of its state, and promote it (treat it as an installer). 
Files written by a file matching the rule will be locally approved unless 
already banned. See the section “Trusted Paths” for more on choosing 
to trust execution of files by path name

208  ◾  Information Security Management Handbook
Field
Description
•	 Prompt: Display a notifier dialog to the users when an attempt is made 
to execute files matching this rule. The dialog allows them to Block or 
Allow execution of the file (and locally approve it if allowed). The 
behavior for the choice the user makes is the same as the behavior if 
the rule specified either Block or Allow. Note that blocking or allowing 
execution from a Custom Rule prompt does not change the global 
approval or ban state
•	 Report: Report (as an event) execution of files matching this rule, 
regardless of file state
File Path
Path to which this rule applies. For local access, specify the drive name (e.g., 
C:\dir\subdir\application). If computers access the path over the network, 
enter a UNC path (e.g., \\dir\subdir\application). You cannot specify mapped 
drives (e.g., Z:\application) for network access
•	 A directory or a specific file can be entered as the path. If a directory is 
chosen, the custom rule also applies to all subdirectories. The custom 
rule can, however, be overridden by specifying a separate rule for 
subdirectories that are to be treated differently and move those special 
rules above the broader rule in the rules list
•	 If the exact path is not known, the Path field accepts the (*) wildcard 
character for specifying partial paths. The wildcard can be used to 
specify multiple paths for directories that appear in different locations. 
If wildcards are used, care should be exercised not to specify a 
directory that is required for legitimate use by another application
•	 Custom Rules support certain macros in the Path field. To see the menu 
of macros, type < as the first character in the Path or File box. These 
macros are a subset of the well-known folders in the Microsoft 
Windows environment
•	 Note that if entering a Reg macro, the whole path must be provided and 
the close angle bracket > to complete the macro. Other macros are 
self-completing once they are chosen from the menu
•	 If using <Reg> macro that ends in a slash (such as “<Reg:HKLM\
Software\MyApp\>\somefile.exe”), the macro is replaced with the 
default value of the specified key because the <Reg:> macro must 
resolve to a value, not a key
•	 More than one Path or File can be entered
Process
Path to which this rule applies. For local access, specify the drive name (e.g., 
C:\dir\subdir\application). If computers access the path over the network, 
enter a UNC path (e.g., \\dir\subdir\application). You cannot specify mapped 
drives (e.g., Z:\application) for network access
A directory or a specific file can be entered as the path. If choosing a 
directory, the custom rule also applies to all subdirectories. A custom rule 
can, however, be overridden by specifying a separate rule for subdirectories 
that are to be treated differently, and move those special rules above the 
broader rule in the rules list

Application Whitelisting  ◾  209
Field
Description
If the exact path is not known, the Path field accepts the (*) wildcard 
character for specifying partial paths. Wildcards can be used to specify 
multiple paths for directories that appear in different locations
•	 Custom Rules support certain macros in the Path field. To see the menu 
of macros, type < as the first character in the Path or File box. These 
macros are a subset of the well-known folders in the Microsoft 
Windows environment
Note that if you enter a Reg macro, you must provide the whole path and 
type the close angle bracket > to complete the macro. Other macros are 
self-completing once you choose them from the menu
•	 If using <Reg> macro that ends in a slash (such as “<Reg:HKLM\
Software\MyApp\>\somefile.exe”), the macro is replaced with the 
default value of the specified key because the <Reg:> macro must 
resolve to a value, not a key
•	 More than one Path or File can be entered
User or Group
This menu allows specifying users or groups to which this rule applies. 
There are three choices:
•	 All Users applies the rule to all users
•	 Specific User or Group opens a text box to the right of the menu, in 
which AD users or groups in the format userorgroupname@domain or 
domainuserorgroupname can be entered
•	 The other menu choices are built-in Windows groups, such as 
Authenticated Users and Local Administrators
•	 If specifying both a User or Group and a Process for a rule, they work 
together. For example, if choosing Specific Process, a matching user or 
group must be running a matching process for the rule to be applied. 
If Any Process Except is selected, this means that the rule is applied 
unless both the User or Group and the Process match the rule 
definition
Rule applies to
The radio buttons allow the rule to apply to All policies or Selected policies. 
If choosing Selected policies, a list of all policies available on the Parity 
Server appears, each with a checkbox
History
For existing rules, a History panel appears at the bottom of the Custom Rule 
page, showing when and by whom the rule was created and the time and 
user for other changes
Custom rules use cases:
◾
◾Prevent modification of specific folders or files.
◾
◾Define folders or files for which file execution is always allowed.
◾
◾Control behavior when an attempt is made to execute a file matching the rule.
◾
◾Control behavior when an attempt is made to write a file matching the rule.

210  ◾  Information Security Management Handbook
◾
◾Specify folders or files to avoid tracking (execution will still be monitored).
◾
◾Define custom behavior for controlling file execution, creation, and/or tracking.
Device Rules
In addition to the monitoring/execution controls mentioned above, removable storage devices can 
be controlled globally in policies and individually in Device Rules.
Device Rules in Policies
Parity policies include a series of Device Control settings. The following table shows the effects 
of different choices for these settings. The effect of the settings on CD/DVD drives differs from 
the effect on USB devices with nonremovable media. Burning a CD or DVD does not constitute 
a “Write” operation. If you want to block burning of CD/DVD media, ban the media-burning 
software application.
Setting
Deny
Permit Approved
Permit
Report
Executions 
from 
removable 
devices
Tracks execution of files 
on removable devices 
(e.g., USB CD/DVD 
drives, USB thumb 
drives) and blocks them 
according to SecCon 
level:
•	 Lockdown: Blocks 
removable-device 
executables
•	 Block-and-Ask: 
Blocks removable-
device executables
•	 Monitor: Blocks 
removable-device 
executables
•	 Visibility Only: 
Permits executions 
of files from 
removable devices
For devices on the 
Device Approvals 
page, permits files 
not explicitly 
banned to 
execute, 
according to 
SecCon level. For 
other devices, 
behaves like Deny, 
according to 
SecCon level
Permits 
removable-
device files 
not 
explicitly 
banned to 
execute, 
according 
to SecCon 
level
Permits 
executions 
and reports 
them as 
events
Reads from 
removable 
devices
Choice not available
Choice not 
available
Permits 
read 
operations 
from 
removable 
devices but 
does not 
report the 
event
Permits read 
operations 
and reports 
them as 
events

Application Whitelisting  ◾  211
Setting
Deny
Permit Approved
Permit
Report
Writes to 
removable 
devices
Tracks write operations 
to removable devices 
(e.g., USB CD/DVD 
drives, USB thumb 
drives) and blocks them 
according to SecCon 
level:
•	 Lockdown: Blocks 
write operations 
to removable 
devices
•	 Block-and-Ask: 
Blocks write 
operations 
to removable 
devices
•	 Monitor: Blocks 
write operations 
to removable 
devices
•	 Visibility Only: 
Permits write 
operations 
to removable 
devices
•	 Note: Denying CD/
DVD devices has 
no effect on writes 
because CD/DVD 
devices are 
read-only
For devices in the 
Approve Devices 
table, permits 
write operations 
to removable 
devices but does 
not report the 
event
For other devices, 
behaves like Deny, 
according to 
SecCon level
Note: Approving 
CD/DVD devices 
has no effect on 
writes because 
CD/DVD devices 
are read-only
Permits 
write 
operations 
to 
removable 
devices but 
does not 
report the 
event
Permits write 
operations 
and reports 
them as 
events
Screenshots—Device Rules and Device Details

212  ◾  Information Security Management Handbook
Device rules use case:
Policy-based fine-grained control over removable storage devices.
Registry Rules
Parity provides the ability to create registry rules, which control what happens when there is an 
attempt to make any changes at specified registry paths. Rules can apply to specific users and/or 
processes.
Field
Description
Name
Name by which this rule is identified in the Registry Rules table. (Required)
Description
Optional information about the registry rule. This can be any text you 
choose to enter
Status
Radio buttons that make this rule Enabled or Disabled. This allows you to 
create a rule that you use only at certain times, or to temporarily disable 
without losing the information used to create it
Write Action
The action to take when there is a registry write attempt matching this rule. 
The choices are:
•	 Block: Prevent creation, deletion, and modification of registry keys and 
values at locations matching this rule. When Block is chosen, a checkbox 
appears that allows you to choose whether a user whose action is 
blocked by this rule sees a notifier or is blocked silently
•	 Prompt: Present a notifier dialog to users when an attempt to modify the 
registry is made at this location. The dialog choices are Block and Allow. 
Once you have responded to the dialog, your response applies anytime 
the same process matches the same rule—you will not be prompted 
again in this case
•	 Report: Do not block modifications at this registry path but report them 
as Parity events
•	 Allow: Allow creation, deletion, and modification of registry keys and 
values at locations matching this rule. This is the default behavior if 
there is no rule for this path

Application Whitelisting  ◾  213
Field
Description
Use of Allow gives you a way to create an exception to a more general 
rule that blocks at a particular location. For example, if you create a rule 
that blocks all writes to “\Software\MyApp\*,” you could use Allow to 
create a higher ranking rule that allows writes to “\Software\MyApp\
SpecialKey”
Registry Path
Registry path to which this rule applies. All registry paths must be prefixed 
with one of the following:
•	 “HKLM\” (HKEY_LOCAL_MACHINE)
•	 “HKCU\” (HKEY_CURRENT_USER)
•	 “*\”
If a rule ends with a “\”, it applies to all keys, subkeys and values underneath 
that path
You can add additional paths by clicking the Expand button to the right of 
the path filed, typing the additional path in the box, and clicking Add after 
each one. You can remove any path by selecting it in the list below the 
Registry Path box and clicking the Remove button. On the Registry Rules 
page, rules with more than one path show the first one in the Registry Path 
field followed by (multiple)
Process
This menu allows you to specify processes to which this rule applies. The 
choices are:
•	 Any Process applies the rule to any process that attempts to write to the 
registry
•	 Any Promoted Process applies the rule to any process that is promoted 
at the time the rule is evaluated. A promoted process is any approved 
process that is marked as an installer, or has been promoted as a 
consequence of a custom rule, or is an approved process launched by a 
promoted process
•	 Any System Process applies the rule to every process that is running 
under the security context of the Local System user. This choice has the 
same effect as choosing Local System in the User or Group menu
•	 Specific Process opens a text box to the right of the menu in which you 
can enter processes you want controlled by this rule
•	 Any Process Except opens a text box to the right of the menu, in which 
you can enter processes you do not want controlled by this rule
A full path must be provided to the process, or use wildcards or a macro that 
make it possible for Parity to match the process in various locations. Registry 
rules support certain macros (a subset of the well-known folders in the 
Microsoft Windows environment) in the Process field. To see the menu of 
macros, type < as the first character in the Registry Path box
If you use a <Reg> macro that ends in a slash (such as “<Reg:HKLM\
Software\MyApp\>\somefile.exe”), the macro is replaced with the default 
value of the specified key because the <Reg:> macro must resolve to a value, 
not a key

214  ◾  Information Security Management Handbook
Field
Description
User or Group
This menu allows you to specify users or groups to which this rule applies. 
There are three choices:
•	 Any User applies the rule to all users and groups
•	 Specific User or Group opens a text box to the right of the menu, in 
which you can enter AD users or groups in the format 
userorgroupname@domain or domain\userorgroupname
The other menu choices are built-in Windows groups, such as Authenticated 
Users and Local System
Note: If you specify a User or Group and also choose Any Process Except from 
the process menu, the rule specifies that the action you specify will happen 
unless the process specified is being executed by the user or group specified
Rule applies to
The radio button for this rule allows you to apply the rule to All policies or 
Selected policies. If you choose Selected policies, a list of all policies 
available on your Parity Server appears, each with a checkbox. You can check 
as many policies as you choose
History
For existing rules, a History panel appears at the bottom of the Custom Rule 
page, showing when and by whom the rule was created and the time and 
user for other changes
Registry rules are ranked on the rules page in the order by which they are evaluated. If a path 
location matches two different rules, the highest ranking rule (i.e., the one with the lowest number) 
takes precedence and the lower-ranked (higher number) rule has no effect. You can change the rank-
ing of rules if you decide that you want one of your rules to be considered before its current position.
Registry rules use case:
Monitor or prevent changes to critical registry keys or trees by user and by process.
Registry Rules Screenshot

Application Whitelisting  ◾  215
Registry Rule Detail Screenshot
Software Meter
Software metering enables tracking the number of times users run specified files. When a meter is 
created, it specifies the file to be tracked. Each time the specified file runs on a computer, its execu-
tion is recorded. Configurable reports enable the display cumulative execution events by time of 
execution, user, computer, and policy. As many meters as needed can be created and centrally 
managed (view reports, edit, and delete) in one place. Monitoring begins almost immediately after 
the meter is created.

216  ◾  Information Security Management Handbook
Use cases:
◾
◾Gather data about how often applications are used.
◾
◾Determine which computers are running an application.
◾
◾Locate computers running obsolete versions of software for upgrade.
◾
◾Retire older versions of an application.
Alerts
Alerts notify administrators of important Parity-monitored changes on the managed endpoints 
as they occur. When conditions specified in an alert are met, the server notifies in the following 
ways:
◾
◾E-mail notification: E-mail notification about the event(s) triggering the alert goes to a list 
of subscribers.
◾
◾Alerts page banner: All currently triggered alerts appear on the Alerts page, highlighted with 
a bright-colored banner.
◾
◾Home page and other dashboards: All currently triggered alerts appear in the Triggered Parity 
Alerts portlet, which is part of the default Parity Home Page and can be added to other 
Dashboards.
In addition, Parity keeps an Alert History for each alert, and this history is modified as alerts 
are triggered and reset, keeping details for events of current significance and eliminating the low-
est level details of past alerts.
An alert can be reset when there is no longer a need to be notified about it. This removes the 
alert warning banners on the Alerts and Home pages (and any dashboard with the Triggered 
Alerts portlet), and if automatic resends of alert e-mail are enabled, it stops those. If the conditions 
that triggered the alert occur again, another alert will be triggered.
Alerts can be viewed, created, and edited through the Alerts page. In addition, several system 
alerts are built-in.
Alerts Screen Screenshot

Application Whitelisting  ◾  217
Malicious Alert Detail Screenshot
One alert of particular interest is the file propagation alert. The file propagation alert is trig-
gered when a file is first seen at a frequency that exceeds a user-defined threshold. The threshold is 
set as a percentage or as a number of managed endpoints per period of time set in minutes, hours, 
days, or weeks.
File Propagation Alert Screenshot

218  ◾  Information Security Management Handbook
Reporting
Event Reports
The Events page provides access to all recorded events related to activities, including files blocked, 
pending files executed, system management processes, and actions by console users. Parity updates 
event data in near real-time for connected computers, with minor variations due to event volume 
and network latency.
There are predefined reports, available on the Saved Views menu, custom views can also be 
created and saved using existing views as templates or starting with the full events table. For any 
event report, the time window can be changed for the time for which results are needed, without 
having to create a new Saved View.
Events Screenshot
The Events page displays up to 200 events per page for a user-specified time period. The num-
ber of events displayed can be adjusted in a table by changing the rows per page parameter in the 
bottom right of any report.

Application Whitelisting  ◾  219
File Reports
The server keeps track of all files on all connected computers running the agent, in near real-time. 
Because of this “live inventory,” files or groups of files matching a name, hash, or any other criteria 
available in the database can be quickly located. Even if a computer is offline, its most recent file 
inventory is available.
This section focuses on the Find Files page, which is preconfigured for file searches and opens 
by default with a filter that allows a search for a file by name. Filters can be added to fine-tune the 
results, and searches can be saved (Saved View). File searches can be exported to a comma sepa-
rated values (csv) file suitable for importing into spreadsheets.
Saved Filtered Find Files View
Baseline Drift
Parity’s Live Inventory of files on the network gives the ability to measure baseline drift, the differ-
ence between a baseline of files and the current files on a specific target. This difference is available 
as a baseline drift report that can be viewed either in detail in dynamic tables or as graphic charts 
on a Parity dashboard. Baseline drift reports provide not only simple numbers of file differences 
but also risk analysis related to those changes.
Drift Values Explanation

220  ◾  Information Security Management Handbook
Term
Description
Drift
The amount of drift measured simply in terms of files added, 
changed, and (if configured for a report) deleted in the target. 
Files are identified by their hash value. An added file, a changed 
file, or a modified file each has a drift value of 1
Weighted Drift
A calculation based on the drift value and adjusted by several 
factors that might increase or decrease the significance of the 
drift for each file. Among the adjustment factors are trust level, 
threat level, file type, and associations with other files
Risk
A calculation similar to weighted drift, but adjusted so that files 
believed to pose no threat show a risk of zero
Percent Weighted Drift
The percentage of total weighted drift in the current report 
contributed by the item in a row
Percent Risk
The percentage of total risk in the current report contributed 
by the item in a row
Other key factors in determining the total drift and risk reported in a baseline drift report are:
◾
◾File filtering: The security administrator can decide which files in the baseline and in the tar-
get participate in the comparison. For example, the preconfigured reports compare pending 
files, but ignore Banned or Approved files—this behavior can be changed. There are several 
other file categories that can be included or excluded from the comparison.
◾
◾File comparison method: By default, if a file hash found in the baseline is also found anywhere 
in the target, it is considered a matching file, and no drift is reported. This is called the File 
Content method. The alternative is the File Location method, in which the same hash in 
different locations in the baseline and the target is considered a drift.
There are two preconfigured baseline drift reports: Drift of all computers, and Daily drift of 
all computers. These are enabled by default, the results of these reports can be viewed shortly after 
the Server and Agents are installed, and the initialization is completed (the inventory of files on 
systems). These preconfigured reports also provide a useful way to view the configuration options 
for baseline drift and view their results in a report. Existing reports can be copied and serve as a 
starting point for new reports.
Drift reports use case:
Assessment of risk resulting from changes to files on computers.
Conclusion
Sensible use of an application whitelisting solution significantly reduces the likelihood of success-
ful exploitation of vulnerabilities in applications, mitigates the risk of malware gaining a foothold 
on systems, improves reliability and reduces administration costs by enforcing compliance with 
corporate policies, and helps pass security audits.

Application Whitelisting  ◾  221
Parity also provides an unprecedented insight into which files are (or were) present on 
systems—even if they were later deleted, and their prevalence, trust, and threat factors pro-
vided by the Web-based Knowledge subscription.
The low CPU and memory footprint of the agent enables safe deployment on heavily utilized 
servers. The absence of signatures maintains effectiveness of protection in the face of new or zero-
day malware. It allows instant selective or global banning of applications that do not meet corporate 
policies. The agent protects endpoints on and off the corporate network. In Lockdown mode, it 
supplants antimalware real-time scanning engines, rendering them redundant. It is, however, not 
recommended to completely remove the antivirus application except on point-of-sale systems and 
ATMs. On desktops and laptops, it is still needed to conduct periodic malware scans.
Device control rules provide granular control over the use of removable storage devices. 
Registry rules enable protection of critical registry keys, either by denying changes or providing 
controlled channels for changes.


223
Chapter 16
Design of Information 
Security for Large System 
Development Projects
James C. Murphy
Information security professionals (ISPs) provide a number of services within their organizations 
to employ. Certified ISPs are expected to be engaged in all the domains of the Security Common 
Body of Knowledge (CBK) (Table 16.1), demonstrating active expertise in a few and broad knowl-
edge in the remainder. Some ISPs are more traditional—documenting policies and procedures, 
training users, implementing access control technologies, tracking network activities, or reviewing 
system logs for problems. Additionally, some provide expertise in resolving internal information 
security incidents or conducting recovery tasks in the event of serious interruptions to organiza-
tional services. It is rare that an ISP will have the opportunity to initiate the security planning 
process in an organization; e.g., in the case of a new, startup organization. Most enter into an 
existing information security structure and adapt to the processes, offering modifications as cir-
cumstances demand.
A large system development project (LSDP) can provide an opportunity to engage in informa-
tion security planning that will stretch across all the CBK domains and will require more than a 
broad knowledge of each. It is an opportunity that every ISP should jump to—at least once!
This chapter offers perspectives based on my own personal experience with such LSDPs. 
Through the different projects, I learned some of the most important perspectives through my 
mistakes and incorrect assumptions, and it is those experiences that offer the most fruitful lessons. 
This type of experience certainly is a way to influence the design of an enterprise security struc-
ture, depending on the size and scope of the effort.
This chapter is written specifically for ISPs who face the challenge of contributing to an LSDP 
and will be responsible (individually or within a group of ISPs) for designing the information 
security structure. It can also benefit non-ISP participants of such a project, the senior Project 
Management staff who will oversee the project, and the subject matter experts (SMEs) who will 
be developing the business rules and tracking the design and development of the specific systems 

224  ◾  Information Security Management Handbook
within the project. ISPs who are not in such a project can benefit also from the emphasis on 
building up the personal information security knowledge base toward the development of an 
enterprise security structure—end-to-end—as well as the object lessons in personal and profes-
sional communications. This chapter will not be a duplication of the chapters on application 
system security, found elsewhere. The efforts described here require a thorough understanding of 
application security but the emphasis here will be on designing and implementing an enterprise 
security structure surrounding a major system design and development effort.
“LSDP” Definition
The first point of clarification is the definition of an LSDP. Though each project is distinct, most 
have more than one of the following characteristics:
◾
◾Significant organizational changes
	
The organization is replacing older systems or initiating major process automation efforts; 
the project could be a consequence of recent mergers or acquisitions, or the organization is 
expanding into new service or product lines.
◾
◾Involves more than one organizational unit
	
A large sector of the organization, potentially involving a geographic distribution of units, 
e.g., all of “Research” or “Marketing”; or a significant change in an organizationwide 
service, e.g., personnel, finance, or purchasing systems
◾
◾Multiyear time frame
	
At least 1 year and potentially, 3 or more years
◾
◾External developer
	
Based on the lack of internal resources, it may be more cost-efficient to engage an external 
vendor with a similar existing system or with experience in the integration of appropriate 
commercial off-the-shelf (COTS) systems. In the largest of these projects, the vendor will 
likely propose a fiscal agent service beyond the design and development efforts. In this, the 
vendor will actually run the developed system and provide the emanating services on behalf 
of the primary organization. The fiscal agency effort will be for a contracted period of time 
and often within the vendor-owned data center and network.
Table 16.1  (ISC)2 Ten Domains of CISSP CBK
ACCESS CONTROL
APPLICATION DEVELOPMENT SECURITY
BUSINESS CONTINUITY AND DISASTER RECOVERY PLANNING
CRYPTOGRAPHY
INFORMATION SECURITY GOVERNANCE AND RISK MANAGEMENT
LEGAL, REGULATIONS, INVESTIGATIONS AND COMPLIANCE
OPERATIONS SECURITY
PHYSICAL (ENVIRONMENTAL) SECURITY
SECURITY ARCHITECTURE AND DESIGN
TELECOMMUNICATIONS AND NETWORK SECURITY

Design of Information Security for Large System Development Projects  ◾  225
◾
◾Procurement process
	
Given the size and need for external help, a formal procurement process may be needed, 
involving a request for proposal (RFP) creation and subsequent vendor evaluation and selec-
tion. In-house developed systems will benefit from a structured planning, design, and imple-
mentation, even if a formal procurement process is unnecessary.
Any development effort that requires most of these characteristics will obviously incur sig-
nificant cost, which most definitely mandates a properly managed structure. The more complex 
and time-consuming the project is, the more rigorous the information security planning needs 
to be. Even smaller projects demand a high level of security, and much of what is identified 
in this chapter can be scaled to fit smaller efforts. Even in-house developed projects should be 
expected to conform to appropriate security expectations and will require similar review and 
validation efforts to external vendor-based projects.
Project within a Project
The first perspective is that someone else within the organization is driving the project—usually a 
senior management–level group, including SMEs who are actually the focal points of the design 
and will judge the overall success of the project. Many of these participants are information tech-
nology (IT) professionals in their own right, with project management, programming, network, 
system architecture, or other IT skills. ISPs who participate are part of the team and how impor-
tant a part and how much value can be added will depend on the individual (or group) of ISPs. As I 
will illustrate, collaboration cooperation skills will affect the value added to the project by the ISP. 
The security perspective will essentially be a project that is threaded through the larger project, 
potentially affecting all systems and subsystems, especially the data and information components 
of the subsystems. This perspective will be driven by regulatory responsibilities (pertinent to the 
organizational posture) and will be integral to the architecture designs for both software and 
infrastructure. ISPs will help ensure that access to the data and information is restricted appropri-
ately and that the data and information are protected even during and after major disasters and 
other service interruptions.
Project Management Structure
Most large projects will be structured in a logical way to provide context and to help facilitate 
the implementation, and the information security perspective should have a similar structure. 
For this chapter, I will use the Deming cycle (Figure 16.1). (http://www.balancedscorecard.org/
TheDemingCycle/tabid/112/Default.aspx), which offers a familiar perspective to project managers. 
Plan
Do
Act
Check
Figure 16.1  The Deming cycle.

226  ◾  Information Security Management Handbook
It also speaks to the continuous nature of information security management and helps indicate the 
reality that the protection of the information and services succeeds the actual project itself—once 
the project is formally accepted, the information security management actually elevates to a higher 
and more persistent effort.
The next section is Before the Beginning, which highlights in some detail the need for prepara-
tion in all areas of information security, including a clear understanding of key information secu-
rity terms. Vital to the success of all phases of the project are the personal communications skills 
of the ISPs—knowing the subject matter, knowing how to listen at all levels of the organization, 
and knowing how to provide answers in appropriate settings. This will be the largest section of the 
chapter, reflecting the importance of laying a solid foundation before the project actually starts. 
The remaining sections reflect the components of the Deming cycle.
Throughout the LDSP, the ISPs will PLAN for the components and requirements of security 
demanded by the project design and expectations and based on the organizational characteriza-
tion. This will lead to the development of a Security Specification that documents the expectations 
for the finished system. The ISPs will DO the next part by designing the information security 
requirements and reviewing the selected vendor’s responses and assertions to the requirements. 
Then, the ISPs will CHECK by participating in testing the system as designed and assessing the 
fulfillment of the security assertions made during the design and development. Finally, during the 
Preoperations and actual operations, the ISPs will ACT to ensure that all the security components 
are indeed in place and are tracked and assessed appropriately, both at the completion of the proj-
ect and through the subsequent challenges.
Before the Beginning
A participant in any major project requires significant depth of domain knowledge appropriate 
to their role within the project. This is especially the case for ISPs involved in an LSDP. In this 
case, ISP participants must have a broad, practical information security background knowledge to 
a significant depth within all 10 of the CBK domains—certifications are certainly preferred, but 
actual experience across the range of the CBK domains is vital. This should include a familiariza-
tion with the state of Information Security Warfare—the general picture of attacker patterns. 
Experienced ISPs should have a healthy and growing sense of paranoia! Knowledge of the organi-
zational industry sector enables an orientation of the security knowledge toward the specific types 
of industry- and organizational-specific data and information at issue with the impending LSDP; 
which will also help identify the potential attacker targets. Industry sector knowledge also identi-
fies the general and specific regulatory environment that underpins the governance structure for 
the organizational information and data.
Knowledge and expertise are the baseline, but it is not sufficient for a successful involvement. 
Most of the project participants will have a general understanding of information security, and the 
terms involved, but most will not have the same grasp of information security as a well-experienced 
ISP. This discrepancy in the understanding of information security details has the potential for 
causing the most difficulty in planning and implementing a security plan for an LSDP. The bur-
den for avoiding the consequences of conflicting terms and definitions falls squarely on the ISPs 
involved! The most significant mistake for an ISP is to assume that all other project team members 
understand information security terms and frames of reference exactly as she or he does.
A example of an apparent lack of communication between ISPs and other IT professionals 
was illustrated by Chris Murphy (no relation!) in a recent Information Week article. In the article, 

Design of Information Security for Large System Development Projects  ◾  227
Murphy interviews several chief information officers (CIOs) and other IT professionals about 
general impatience with the slow pace of IT projects (e.g., LSDPs!). In one section, information 
security was at issue, and Murphy quoted a consultant and former CISO.
… security and regulatory compliance make business IT more complicated than con-
sumer IT, but security can’t be the overriding excuse for not moving faster.
CISOs must bring more of a business point of view to their security judgments… . 
CISOs must weigh a delay against the risk and decide if the app can be rolled out and 
any problems resolved along the way. Again, it’s velocity over perfection—and it’s heresy 
to some security pros. “CISOs need to get comfortable with that, [the consultant] says.”
CISOs also need to … [automate] more security testing … . “Reserve these really good 
security people for the really difficult security problems [the consultant] says. … Too often, 
the interpretation of a law or regulation gets debated anew with every security problem.”
This offers an example of a professional difference of opinion about the importance of informa-
tion security within a project development effort. The consultant appears to express an opinion 
that IT security is a troublesome task that needs to stay below the radar of project or system devel-
opment. It also highlights the need for careful planning and personal/professional communication 
about the various aspects of information security within the development process.
My own personal experience when I began with an earlier project reflects this. I spoke read-
ily to other project participants about information security terms, concepts, and regulations, but 
I found that I was not being heard, or I encountered disagreement about information security 
practices and concepts. I was clearly not communicating past the apparent barriers! After more 
discussion and consideration, it became clear to me that I was the problem and the reason for the 
barriers! My communications skills were at issue, and after reflection, I wrote and published a 
paper that described my situation (Murphy, 2009). Much of the following paragraphs are drawn 
from that paper, with some updates from the years since it was written.
As the title of my paper indicates, I was frustrated that “no one was listening,” but I did finally 
comprehend my responsibility:
“The very security professionals who are convinced that we have the answers are the 
primary barriers preventing the message from being heard.” (Murphy, 2009)
There are three personal/professional areas that need attention for ISPs to communicate 
effectively:
Know the message
Win the right to be heard
Be always ready to give an answer
Know the Message
Knowing the message includes the knowledge gained from experience and/or certification. It also 
involves understanding crucial information security concepts and how they are interpreted and 
used within the context of the impending project. As mentioned above, nearly everyone in the 
organization connected with the project will have an opinion on specific information security 
terms and frames of reference. Four specific terms are at issue:

228  ◾  Information Security Management Handbook
Trust–Privacy–Security–Risk
These are key terms for all ISPs, and yet these represent most of the significant differences of opin-
ion among all types of IT professionals. As a matter of learned practice, I offer my own contextual 
definitions of these terms, acknowledging that differences may exist. Yet, I intend to be clear about 
how I use these terms in explaining the breadth of enterprise security.
Trust is a concept that I believe has been overused. It is prevalently used in most current litera-
ture describing potential networking relationships and in many recent privacy and security stan-
dards documents. Examples are such as: “… we need to establish trust among …,” “… [the effort] 
builds trust that is essential …,” “… this constitutes a trust agreement … .”
Its persistent usage is understandable and it speaks to a genuine desire for positive human 
relationships, but I believe it no longer reflects the reality of our twenty-first century societies. 
The option for “trusted hosts” within UNIX environments was eliminated more than 20 years 
ago when UNIX became a mainstream operating system. I believe we err in designing legal docu-
ments that assert “trust” among the signees. I do believe it is possible to develop reliable trust 
among close friends and family (with exceptions!), but I believe that it is increasingly impossible 
to develop trust among large groups, such as one organization to several others where data and 
information are expected to be shared.
The following limited set of recent articles speak to the problem of “trust,” as reflected in the 
titles themselves (Table 16.2):
Table 16.2  Recent Articles on Trust
There Is No Universal Security Architecture
Szabo (1998)
Trusted Third Parties Are Security Holes
Szabo (2005)
Former Cedars-Sinai Employee Held in Identity Theft, Fraud
Zavis and Zavis (2008)
Complete Data Security a Mission Impossible, Study Claims.
Gruener (2008)
Computer Crash Hinders Texas Attorney General’s Medicaid Fraud Case
Ramshaw and Garrett (2008)
Google Health Accused of Inaccuracy in Electronic Medical Records
Kolakowski (2009)
Hackers Break into Virginia Health Professions Database, Demand Ransom
Krebs (2009)
Broad New Hacking Attack Detected
Gorman (2010)
Security Fail: When Trusted IT People Go Bad
Harbert (2011)
Data Breaches at Arizona Medical Center Makes Case for Zero Trust Security
Rashid (2011)

Design of Information Security for Large System Development Projects  ◾  229
The last article describes the awful invasion of privacy by the employees of the medical center 
treating the tragic victims of the January 2011 shooting in Tucson, Arizona.
“Trust” agreements signed by the officials of the organizations do not actually provide trust or 
guarantee any assurance of trust; they only establish the application of consequences of the breach 
of the contract. The reality of the twenty-first century is that though we talk about “trust relation-
ships,” in reality we actually do not trust—groups or individuals! There are too many loose ends—
within our own organization (we cannot absolutely control the behavior of all workforce members) 
and certainly within the remote organizations. Also, it should be apparent to all (certainly to ISPs) 
that the Internet is becoming increasingly hazardous to the integrity of all transmitted informa-
tion (and to the health and wealth of the owners of the information). That is clearly indicated 
by the technical and physical barriers we place between the outside world and our information! 
Agreement documents are vital, because they do provide clear consequences for breaches; however, 
I strongly suggest that they be described as Data Protection Commitments indicating each party’s 
role in exchanging and protecting the other’s information. Finally, any agreement requires disci-
plined follow-up, by means of active infrastructure monitoring, service assessments, and process 
audits to prevent or rapidly detect any possible interruptions.
In the last 10 years, the debates over Privacy and Security have increased and become more 
polarized in the aftermath of several national and regional crises. Most of the debates address 
the apparent dichotomy (or tug-of-war) between the two concepts. The quantity of publications 
is overwhelming as the need for personal privacy is measured against the importance of societal 
security (e.g., Rotenberg, 2007; Sanchez, 2009). The debate is over the importance of choosing one 
concept over the other or how to balance the importance of each. The debate is often characterized 
(sensationally) as a choice between a Police State monitoring every individual’s activities and the 
imminent invasion by foreign forces. Ironically, both sides of the argument describe the “worst 
case scenario” as the disastrous loss of personal liberty on a grand scale! Schneier (2008) rightly 
sees that there is (or should not be) a dichotomy, because security (at least technical or informa-
tional) can be implemented without a complete loss of privacy.
This predominant view of privacy has a human-personal characterization—identified by 
phrases such as “my space,” “my personal identity,” or “my health record.” This is the perspec-
tive of most legal and compliance efforts in organizations, epitomized by the recent healthcare 
regulations. In this context, privacy is often stated in terms of personal control, and recent updates 
to healthcare regulations (HITECH Breach Notification Interim Final Rule, 2009) have been 
implemented to strengthen the enforcement of the original regulations (Summary of the HIPAA 
Privacy Rule, 2003).
In the context of protecting data and information, I target a different characterization of pri-
vacy and security that more appropriately suits the LSDP at hand. This view is from the perspec-
tive of data and information, and as such, privacy refers to specific categories of digitized or paper 
information identified or classified as private/personal about identifiable persons. For ISPs working 
on the large project “privacy” refers to information that others in the organization have identified 
and specifically classified as “private.” It is a subset of the larger body of corporate information, but 
not necessarily the only private information. Other subsets of organizational information may be 
designated as “private” or “proprietary” as well for different reasons. This “private” information, 
then, is the appropriate target for protection mechanisms.
In the debate referenced above, security also has a personal context, indicating protection of 
human life and liberty from forces intent to harm. Information security, as distinct from personal, 
human security, is the totality of policy, technology, and process efforts implemented to protect 
private data. From an information management perspective, both privacy (the characterization 

230  ◾  Information Security Management Handbook
of selected information as “private”) and information security are necessary—privacy cannot be 
assured without adequate information security, and information security cannot be efficiently 
implemented without the identification and classification of private information. To be clear, pri-
vacy and information security are distinct (not synonymous) and they are complementary—both 
disciplines are necessary for a complete protection scheme. Information security is not simply a 
privacy requirement (established by regulations and compliance standards), but it enables privacy 
requirements to be fulfilled.
The confusion of information security with privacy is not the only problem. ISPs struggle with 
a general lack of appreciation among organizational workforce members for the breadth and depth 
of information security. To be clear, information security is not (exclusively):
A product
A checklist
A regulation
A headcount
	
A budget item
	
	
An IT problem
Information security certainly encompasses all these ideas and items, but it is more clearly 
defined as:
an organizational initiative that requires the responsible participation of all workforce 
members—top to bottom!!
Information security has often been correctly characterized as a process, but it will be most 
understood and appreciated when it becomes an organizational culture among all the work-
force, and an ongoing discipline among the ISPs and other IT staff in monitoring points of 
vulnerability.
The simplest description of information security is that it performs two main services: provid-
ing protection of and controlling access to data and information. The “CIA Triad”—Confidentiality, 
Availability, and Integrity—have been recognized as attributes of information security (Perrin, 
2008) and have brought needed recognition to the discipline. In reality, they reflect the qualities of 
data and information and they are misused when seen as measurable values, as such, they provide 
an incomplete picture of information security.
Table 16.3 indicates more of a complete, contextual description of information security, under 
the two main services. These characteristics include qualities of data and information and prac-
tices involved in the two main services. Continuity and Encryption are emphasized to indicate that 
there are components of each that help protect and control access to information.
Identity management includes authentication, the matching for the sake of the system of per-
sonal identifiers (user ID and password) to an individual person; authorization, first, the granting 
of permission for accessing selected system components (from a data owner or manager), and 
second, the enabling of the permission within the architecture of the system; and provisioning, the 
practice of activating modifying, monitoring, and deactivating the user accounts established by 
authentication and authorization. These three activities, authentication, authorization, and provi-
sioning, make up the larger service process of access control. Note that the combination of the user 
identifier and the password is considered single-factor authentication. Adding more identifiers (e.g., 
a pin number and/or a biometric marker) creates two- or three-factor authentication.

Design of Information Security for Large System Development Projects  ◾  231
Information security will not be complete by simple initiation of the contextual characteris-
tics. All efforts require processes to be defined and documented, and all the components require 
the disciplines of organizational workforce training, active monitoring, and periodic auditing for 
consistency and continuity of practices.
Finally, Risk is the last of the four information security topics that requires attention. In a pre-
vious writing (Murphy, 2011), I detailed my views on the muddled picture of risk and expressed 
the need for clarification, especially within the context of information security. Risk management 
is a top-down, Senior Management–led endeavor with collaboration from several organizational 
groups. ISPs contribute to the complete picture by assessing the vulnerabilities. The first column 
of Table 16.4 indicates the classic, general view of risks, summarized as the probability of mon-
etary loss. IT risks (middle column of Table 16.4) are the specific types of threats and vulner-
abilities involving information, which include additional monetary consequences due to fines, 
penalties, and lost reputation. The third column emphasizes the actual contribution of ISPs to risk 
evaluation—controlling information vulnerabilities, which include proper care and management 
of infrastructures, careful management of software environments, and appropriate documentation 
and communication for organizational workforce members.
Win the Right to Be Heard
Information security is a service provided to the larger organization. ISPs certainly have more 
information security knowledge and experience than most of the organizational workforce, but 
sometimes that knowledge is a barrier to effective communication. As the LSDP efforts begin to 
pick up steam, ISPs will have more chances to interact with other workforce members. Regardless 
of the size of the ISP group (one or many) or responsibility within the group (e.g., manager to entry 
Table 16.3  Information Security in Context
Protection of Information
Access to Information
Confidentiality
Availability
Integrity
Accessibility
Transmission
Timeliness
Storage
Usability
Locks
Keys
Continuity
Continuity
Encryption
Encryption
Redundancy
Input/Output
Backup/Archive
Display/Distribute
Malware Defense
Identity Management
Separation of Duties
Account Authorization, 
Authentication, 
Provisioning
Intrusion Detection/Prevention

232  ◾  Information Security Management Handbook
level; technical or policy writing; help desk, etc.), all ISPs will have interactions with the rest of 
the workforce, whether in formal training classes, organizational committees and teams, or even 
hallway conversations.
In every circumstance and opportunity, the most important communication skill for ISPs 
is LISTENING!! In casual hallway conversations, one can “pick up” information about the 
background and planning for the LSDP—often more can be learned than from formal meet-
ings and presentations! As the project begins to form, ISPs will have opportunities to meet 
more formally with data owners, from whom descriptions of the current state and the reasons 
for the change, and ultimately, the access restrictions from specific subsections of the future 
system (listen). Additionally, meetings with SMEs will provide more details about the busi-
ness processes and types of data that will be needed (LISTEN). Formal presentations by 
senior project and business management will indicate the initiatives, plans, and goals of the 
future system (LISTEN!). All these opportunities will provide a foundational understanding 
of the future system, and the ISP can begin to identify aspects of the future system that will 
require information security attention.
From these listening opportunities, the ISP can begin to fit into the organizational jargon and 
hopefully, can begin to be accepted as an “insider.” During this time, before the actual procure-
ment process for the LSDP begins, the ISP can build knowledge about the organization itself and 
the overall picture of the merits and justification of seeking the future system. Table 16.5 sum-
marizes the types of valuable context information that will assist the ISP in crafting appropriate 
information security plans for the future system.
Table 16.4  Risk Perspectives
Risks—General
Risks—From IT Perspective
IT Risk Management
Threats (T)
•	 Fairly constant sources
•	 Increasing in quantity 
and varieties
•	 Expressed as Probability (P)
Threats
•	 Information Is the target
•	 Interruptions to services
•	 Unauthorized access → 
disclosure/loss
Controlling vulnerabilities: 
Infrastructure
•	 Reduce complexity
•	 Increase redundancy
•	 Change management
•	 Monitoring/
maintenance/audit
Vulnerabilities (V)
•	 Breakdown in protection 
structure
•	 Actualization of threats
Vulnerabilities
•	 Infrastructure—data 
storage and movement
•	 Policies/procedures/practices
•	 Human omission/commission
Software development
•	 Planning
•	 Design/development
•	 Testing
Asset Value (AV)
•	 Value of threat target
•	 Costs of successful threat
R = P(T) × V × AV
Probability of monetary loss
Probability of monetary loss
•	 Value of data/information
•	 Infrastructure replacement
•	 Regulatory fines/penalties
•	 Disclosure costs: 
Reputation, lawsuits
User awareness and training
•	 Policy and procedure 
Documentation
•	 Communication!!

Design of Information Security for Large System Development Projects  ◾  233
Be Always Ready to Give an Answer
Targeted listening is the key that opens up the sources of information that will be vital for the ISP 
to build a set of plans for the future system. As may be expected, as the anticipated project begins 
to come together, careful listening will lead to questioning, and questions will require appropriate 
answers. Based on the knowledge and experience with information security, and the context of 
the organization’s current state and future plans, ISPs must be ready to respond. Responses should 
reflect the nature of the question asked in the specific organizational context, not the overall gen-
eral knowledge of information security. ISPs must be ready to respond to informal questions that 
may come within the hallway conversations as they pertain to the impending project. Other ques-
tions may come from help desk calls, e-mail requests, or job-related problem solving. Admitting 
ignorance to selected questions is not wrong, especially when accompanied by an expressed inter-
est in researching an answer. Questions may also arise in meetings based on targeted discussions, 
and again, contextual answers with commitments to research will help the ISP gain the confidence 
of the questioners.
ISPs may be asked to make formal presentations in some of the meetings or in more targeted 
planning sessions. These could also be based on specific information security topics or tech-
nologies and may allow time for research and preparation. Beyond those, ISPs may offer writ-
ten communications on targeted subjects to address certain aspects of the future system. These 
writings may be delivered in newsletters or blogs, specific “white paper” essays, or formal journal 
publications.
ISPs must be able to blend the listening to the felt needs of the organization, and the under-
standing of the current state and future system contexts toward the preparation of general and 
Table 16.5  Organization Characteristics, 
Targets, Needs
Organizational profile
•	 Industry profile; products and services
•	 Partners, customers, competitors
•	 Regulatory responsibilities
Nature of the data/information
•	 Internal stores, current volume
•	 External sources
•	 Information products
Basis for changing
•	 Legacy systems, aging out
•	 New business opportunities
•	 Existing points of pain
Desired target state
•	 Future system
•	 New service/product expectations
•	 Organizational growth/decline

234  ◾  Information Security Management Handbook
specific responses. The ideal result will be the growing sense of confidence, expressed by individu-
als within the organization, in the ISP as a competent, if not important resource for information 
security within the planning and implementation of the future system.
The following list is a set of actual questions or topics that could be posed by the other partici-
pants during various discussions or meetings leading to the planning of the future system. ISPs 
can consider these as a starting point for understanding how to prepare and present information 
security topics in organizational context. Obviously, many more similar topical questions could be 
posed, the most important consideration is to keep the answers in context.
Professional Responses
◾
◾Can you recommend standard methods and practices for developing secure software within 
small or large system development projects?
◾
◾Can you break your overall plan into incremental steps that will better fit a budget-managed 
environment?
◾
◾Can you identify and present the return on investment (ROI) that information security 
enhancements can bring to the organization?
◾
◾Have you read (or at least identified) the international, national, and local laws and standards 
about information privacy and security that directly affect your organization’s practices?
◾
◾Can you participate in organizational discussions about the distribution of responsibilities 
for personal safety and information security practices?
◾
◾Do you know how to answer the questions about incidents that may lead to emergency 
response or disaster declaration within your organization?
◾
◾Will you be able to answer the questions about liability of data loss within your organization?
◾
◾Will you be able to initiate (or participate responsibly in) an investigation of data loss or 
theft?
◾
◾Can you give answers to the questions about numbers and types of successful and unsuc-
cessful attacks on your network?
◾
◾Can you recommend technology solutions and countermeasures to prevent such activities 
in the future?
◾
◾Can you recommend business practices and behaviors that will also mitigate the same activi-
ties in the future?
◾
◾Can you design and lead a security assessment after the project is complete and the system 
is in production?
PLAN–Do–Check–Act
Based on the communication efforts described above, the ISP now has a foundation for planning 
the information security portion of the future system. Before the LSDP is formally initiated by 
organizational management, teams will be formed and documentation about the future system 
will be accumulated. The ISP will be a participant in the larger project and will follow the plan-
ning structure, project sequence, and general direction of the Senior Project Managers. ISPs will 
certainly work closely with the IT technical staff contributing to the design of the infrastructure, 
architecture, and network environments. The main task for the ISP at this stage is to draw on the 
organizational understanding gained, fill in missing pieces from deliberate interviews and meetings, 
and produce a general Information Security Specification that will describe the overall information 

Design of Information Security for Large System Development Projects  ◾  235
security structure of the future system. We will assume that this future system will indeed be 
designed, developed, and administered by the vendor as a fiscal agent and housed at the vendor-
owned offices and data center. This means that the specification will address the complete enterprise 
security of the system, its workforce members, and its technical and physical support structures. 
Trained and experienced ISPs are able to define a generalized enterprise security structure, but the 
challenge here will be to tailor the specification to the organizational specificities.
Before diving into the preparation of the security specification, there are a number of founda-
tional perspectives for ISPs to keep in mind. First, remember that information security ….
Provides Protection of and Controls Access to Data and Information
For the duration of the project—planning, procurement, design, development, testing, pre-
operations, operations, and beyond—remember these guidelines about managing information 
security:
The Most Important Information Security Asset:
The Human Resource (internal)
The Greatest Source of Threats and Vulnerabilities:
The Human Resource (internal and external)
The Most Important (and Most Difficult) Context:
People > Information > Technology > Process
The Most Important Capability:
Personal Communication (all kinds)
Information security is fundamentally about influencing people!!
From the background and familiarization gained (above), the ISP should be able to document 
the organizational posture:
◾
◾Size, growth (expansion, mergers/acquisitions)
◾
◾Public or private status (there are many important differences)
◾
◾Industry sector (partners, customers, competitors)
◾◾Regulatory and standards environment (much more rigorous with public sector organizations)
◾
◾Nature of the future system (replacing a legacy environment or entirely new)
Senior executives, project managers, and SMEs will be the greatest official sources of these cir-
cumstances and characterizations. The SMEs and the organizational users who will employ the 
future system will be identifying and documenting the overall business purposes, including (ideally) 
the business rules that describe the desired work functions addressed and served by the future sys-
tem. The system will have an overarching purpose and will be composed of subsystems that define 
the components and collateral systems. The SMEs and primary users will define the business rules—
activities described in plain language—that comprise the subsystems. The breadth and completeness 
of the sets of business rules will facilitate the design and development of the overall system.
ISPs will need to attend to the subtending data and information which the subsystems will 
use and/or generate, especially if it is sets of private, protected (by regulation) information about 
identifiable people. From the start, it is important to identify the sets of private information and the 

236  ◾  Information Security Management Handbook
expectations of its protection by the users and SMEs. Even though other technical groups will handle 
the transfer of data from the legacy environments (if any), including conversion from the old to the 
new environments, ISPs will need to confirm that private data is protected during transfers and that 
older copies (if any) involved in the transfer are destroyed after the transfer and conversion.
The SMEs and system users will determine the ultimate inputs and outputs of data (included 
private and/or financial information) and will be the primary resource for estimating the volume 
of information and its growth over time. The outputs may be products of specific services of the 
future system and may include custom searches and regulatory reports for external databases. 
The SMEs and users will be the decision makers for the access restrictions to various sets of 
data within the subsystems, for the most part defined by regulatory requirements. They will 
also determine (drawing perhaps from regulatory requirements) the nature of the stored data 
and information—online, near-line, backed up, archived, and the lengths of time for each type 
of storage. ISPs will be expected to be familiar with all regulations affecting the sets of data for 
the new system and will ensure that any regulated audit and reporting requirements are docu-
mented as part of the overall requirements development.
From the preceding details derived from the SMEs and primary users of the future system, 
the ISP can begin to draft the security specification that addresses the uniqueness of the future 
system and its environment. The specification should be written as descriptive text, for a gen-
eral nontechnical audience at a sufficient length to address the overall scope, ideally 5–10 pages. 
It should express the specifics of the information security expectations, not in exhaustive details. 
The specification will be the basis for the security requirements within the formal RFP, but it will 
not necessarily be part of the RFP. The specification should be structured in a way that enables 
the project team to grasp readily the required security environment. I recommend that the most 
effective way is to create a document framework that indicates the auditability of the overall system, 
once completed. An audit framework will be recognizable by senior management and project 
management participants—not to mention internal auditors—and will facilitate communication 
about the security expectations.
Several audit standards offer frameworks that should be familiar to business-oriented users 
and to ISPs as well. I recommend using the Federal Information System Controls Audit Manual 
(FISCAM) (U.S. GAO, 2009), which offers a straightforward categorization of enterprise security 
general controls, as summarized in Table 16.6. The intent for using the FISCAM structure is not 
Table 16.6  FISCAM: General Controls
Security management: Enterprisewide; risk assessment/ 
control, policies/procedures, awareness/training
Access controls: Physical/logical; identification, 
authentication, authorization, provisioning
Configuration management: Installation, maintenance, 
monitoring of hardware/infrastructure; software, 
systems/applications
Segregation of duties: No single point of human failure 
or control
Contingency planning: Intrusion detection/prevention, 
incident response, data backup/recovery, BC/DR plans

Design of Information Security for Large System Development Projects  ◾  237
to duplicate the detailed control schemes within the FISCAM document itself, but to describe 
in brief statements the expected security structure within the future system organized with the 
FISCAM outline. The Security Specification can be used to convey the details of the expected 
security structure in discussions or presentations with the rest of the organizational project plan-
ning group as an internal working document. It can certainly be modified based on comments and 
feedback as the project begins to unfold. Take advice of the senior project managers about offering 
the Security Specification to the vendors who will bid on the system. It may not be appropriate 
because vendors may attempt to bid the Specification itself, instead of offering their own interpre-
tation of the requirements.
Plan–DO–Check–Act
At this point, the actual work begins. Under the leadership of the senior project managers, the ISPs 
will participate in all the phases of the project. Table 16.7 indicates a high-level view of the major 
phases, but note that this list is idealized and may not reflect all types of LSDP phases.
Procurement Participation
The descriptions below are not meant to be a complete, detailed description of the procurement 
process and the development of the RFP, but to offer illustrations for discussing the ISP partici-
pation. Each procurement and RFP process is unique and tailored to the subject matter and to 
Table 16.7  LSDP Major Phases
Procurement
RFP design—Detailed system requirements
Proposal review—Vendor evaluation, selection
System creation
Design—Major subsystem descriptions
Development—Analysis, coding, and integration
Testing—System integration, user acceptance
Preoperation readiness
Final architecture/infrastructure
Final data transfer
Stress testing, “parallel” testing
Project acceptance
Validation
Verification
Certification
Operations
Adjustments
Assessments

238  ◾  Information Security Management Handbook
the size of the project; the information security contribution is a subset of the greater work of the 
project managers and SMEs and their teams.
ISPs (and all participants) must understand that procurement is a formal, controlled set of 
activities. Ideally, it will be led by senior managers with sufficient formal project management 
experience in managing large projects. For larger projects involving significant cost, there may be 
legal implications of how the procurement processes are conducted. This is even more important 
in public sector organizations (local, state, and federal government agencies) where competitive 
bid processes are required. Proposing vendors will undoubtedly be submitting proprietary infor-
mation, if not technology, and each vendor will expect confidentiality in the review of the sub-
mitted proposal information. This also means that there will be restrictions on communication 
among the procurement participants to ensure that the proposal information is kept under wraps. 
Any organizational staff who have clear conflicts of interest (e.g., personal involvement with any 
vendor—family member employment, significant vendor investment holdings, etc.) may not be 
permitted to participate in the process.
Private organizations may not be tied strictly to a formal procurement process, unless competi-
tive bidding is expected. Nonetheless, even private organizations who approach a single vendor 
directly will be best served to follow a formal proposal process similar to the procurement process 
to clarify detailed expectations and to reduce ambiguity during the creation of the system.
The general sequence of events in the procurement process will begin with the crafting of the 
RFP, though preliminary announcements or formal Requests of Interest may precede the RFP. In 
this, the desired system is described at a high level, the sequence of events are described (includ-
ing calendar dates), the contract and other legal obligations and regulatory responsibilities are 
documented, the organization’s expectations of vendor qualifications are spelled out, the actual 
proposal processes are defined, and all the detailed requirements of the desired system are listed. 
The set of requirements will include specific subject matter subsystem requirements toward the 
overall purpose of the large system. It will also include general sections, spanning or supporting all 
the subsystems, which include system architecture, interfaces (for users and between subsystems), 
service level expectations, and information security. Business continuity and disaster recovery 
requirements may be included within the security section.
After the RFP is submitted for public review, vendors may be given an opportunity for ques-
tions and comments about the RFP, and the organization will have a similar opportunity to 
respond and clarify the vendor issues raised. By the announced date, all the proposing vendors 
are expected to have submitted a complete, authorized proposal, following the expectations of the 
RFP, which also may include personal interviews and/or proposed system demonstrations.
The evaluation process is next, during which all vendors whose proposals were accepted are 
formally reviewed and evaluated. There could be legal implications involving the details of the evalu-
ations, which may include careful control of written notes and a ban on discussing the evaluations—
with anyone in or outside the organization—outside the formal evaluation sessions. After the 
evaluations are completed, some procurement efforts may indeed allow the vendors to make adjust-
ments to their proposals based on the evaluation summaries. When the evaluations are complete, 
a separate group, usually the project management staff, will rank the vendors and make the final 
selection.
During procurement, the ISPs will be able to draw on the security specification plus feedback 
to create the requirements for the components of information security. Requirements must be 
crafted to be clear, succinct, and unambiguous and organized topically to avoid duplications and 
inconsistencies. Ideally, all the information security requirements should be in a separate section, 
(arranged in sections similar to the structure of the security specification) with clear instructions 

Design of Information Security for Large System Development Projects  ◾  239
stating the general applicability across all the systems and subsystems. Some security requirements 
may be addressed in legal/contractual sections or in architectural and systems administrative sec-
tions. The RFP will be a legal foundation for the subsequent design and development of the new 
system, so ISPs must ensure that the set of requirements is complete and addresses all the expecta-
tions of the security specification. The RFP will be referenced frequently during design by both 
the organization and the vendor to clarify differences of opinion. Adding new requirements after 
the process begins could be difficult and costly.
Optimally, requirements will express the expectation that the vendor will be able to accomplish 
the object of the requirements in the future system, e.g., “provide capability to …” or “document 
intent for ….” The requirements also should be objectives-based, which means that the requirement 
statement will briefly solicit a solution to a specific desired state, giving the vendors the opportu-
nity to describe how they plan to fulfill the desired state. Requirements that include examples (use 
of “e.g.” or parenthetic suggested lists) may lead the vendor to propose exactly the examples pro-
vided, when the expectation was for something broader or more inclusive. Requirements should 
not be posed as questions, because that gives the vendors opportunities to respond simply with an 
affirmative (no vendor will ever respond with a negative answer to a requirements question!), and 
reduces or eliminates the expected explanation from the vendor. The intent is for the vendor to 
propose the final solution or the plan for the desired state in some detail. This provides the basis 
for evaluating the vendor responses; it allows for questions seeking clarification and more detailed 
explanation and for ultimately making comparisons that lead to the final selection.
Table 16.8 provides examples of the benefit of objectives-based requirements.
The first example spells out details that describe a classic backup structure using tapes and 
specifying timeframes and distances. This will lock the vendor into exactly fulfilling the require-
ment. The alternative gives the vendor the opportunity to describe what the vendor considers to be 
Table 16.8  Objectives-Based Requirements
Not this
But this
Provide the ability for backups to be 
performed nightly, using DLT tapes; 
incrementals 6 nights, full 7th night; tapes 
archived off site for 6 months, at least 50 
miles from data center, recovery of lost data 
must be within 24 hours
Provide the ability to document a protected 
backup environment allowing prompt 
recovery of lost files, backups located 
sufficiently distant to prevent simultaneous 
loss with main data center
Document an incident response plan that 
captures all attempts to break into the 
system from undesirable IP addresses and 
malicious software (e.g., viruses, trojan 
horses)
Document and implement an incident 
response plan
Provide the capability to control the system 
administrator accounts by restricting the 
number of administrators; protect the 
system administrator password by frequent 
changes (at least monthly) and limit system 
operators to their assigned tasks and 
frequent (at least monthly) changes to the 
operator passwords
Document policies to implement operational 
practices preventing any person(s) from 
establishing unauthorized complete control 
over the privacy, security, and processing of 
critical information

240  ◾  Information Security Management Handbook
a protected backup environment, what timeframe is “prompt,” and what distance is “sufficient.” 
Under the alternative requirement, a vendor could propose a real-time mirroring or shadowing 
backup environment with an archival on disk storage arrays that uses no tapes. Recovered files 
could be brought back in seconds by enabling a remotely mounted backup environment directory 
structure. The vendor could also propose a location for the backup environment that is geographi-
cally separated from the data center but may be less than 50 miles distant.
In the second example, there will certainly be other incident sources besides undesirable IP 
addresses, and there are also more malicious software threats than the ones listed. The suggested 
list could be interpreted as the only malicious software to be blocked. The alternative allows for the 
vendor to propose a comprehensive incident response plan that will allow for thorough evaluation 
and comparison with other proposals. Not every requirement will be stated with an open-ended 
expectation; some specifics will indeed be expected, if regulations or organizational policies and 
standards already spell them out in detail.
The third example attempts to address the need to establish the separation of duties or respon-
sibilities so that no individual will gain control over the whole environment. As stated, the require-
ment is specific for a number of situations, but deals primarily with systems and operational staff 
and delimits the password change frequency, which may or may not be appropriate. It does not 
address the need for physical protection of the system administrator/operator environment, which 
is an example of an omission that may result in a future costly change request. The alternative 
explains the desired state and leaves it to the vendors to describe their approach in as much detail 
as needed.
All three alternative requirement statements emphasize the need to require documentation for the 
desired processes and capabilities. Hopefully, most vendors will assume the need for documentation, 
but such assumptions may not necessarily be reliable. A desired expectation for documentation of 
processes, policies, and procedures may be stated in some of the introductory sections of the RFP as a 
general requirement for the whole system, which would then obviate the need for repeating it within 
each individual requirement. For any points of confusion or concerns about requirement verbiage and 
expectations, it may be advisable to consult with the legal or contracts experts within the project team. 
For truly large and expensive LSDPs, ISPs should definitely include a requirement for an internal 
assessment of the security structure before the system is accepted. Many problems can be detected and 
avoided with a final security assessment!
The proposal evaluation will be led by the project senior management, and ISPs will be 
expected to address the appropriateness and satisfaction of the responses to the requirements. In 
general, ISPs will be determining if the vendor has an acceptable concept of enterprise security 
as well as responses that demonstrate awareness of current and future information practices and 
technologies. The open-ended, objectives-based requirements will allow for creativity on the part 
of the vendors and possibly different responses among several vendors. During evaluation, direct 
comparison between vendors will not be allowed; rather each vendor will be assessed separately. 
Ultimately, the comparison will be made by the senior staff who actually choose among the pro-
posals, taking additional criteria into account such as cost, time until completion, vendor repu-
tation, experience, and fitness for the project. In large, expensive projects, it is possible that the 
finalists (two or three vendors) will be allowed to make modifications to their proposals.
System Creation
Once the selection has been made for the optimal vendor, the workload of all the project partici-
pants will actually increase. All the project staff will be reviewing the initial set of documentation 

Design of Information Security for Large System Development Projects  ◾  241
from the vendor based on the final proposal. The vendor is expected to document the detailed 
design of the various subsystems for the larger project, as well as the general areas including archi-
tecture, information security, and business continuity. Depending upon the size of the project, 
other general documents may be separated out, such as risk management, change management, 
network design, identity management, and others, as appropriate. All the project staff are expected 
to review and critique the design documents for matching and fulfilling the requirements and for 
the detailed description of how the operational systems and subsystems will work and interoperate.
ISPs will be reviewing the technical documents for descriptions of information security prac-
tices and processes for the future production environment. In these cases, ISPs will be working 
closely with the other IT technical participants, including the server-network architecture profes-
sionals as well as the software development professionals. The process will include tracking the 
requirements from the RFP through final proposal and in the design documentation. The design 
documents will contain assertions about the future state of the system. As the project unfolds, the 
ISPs will be responsible for tracking the assertions through the development and into testing and 
production to validate the assertions—finding the evidence and documentation to ensure that the 
vendor actually performed as asserted.
Besides the requirements tracking, the ISPs will have the responsibility for tracking any vul-
nerabilities that may be evident in the design of the systems and subsystems. This is where an 
understanding of software development security becomes important. Most of the SMEs will be 
reviewing and critiquing the design documents for functional requirements. ISPs are expected to 
assist the software development professionals in insisting on requirements that capture most of the 
software vulnerabilities before the designs are implemented. ISPs can also scan the design docu-
mentation for data flow patterns—how data is brought into the subsystems and then disseminated 
to others through various interfaces, within the larger system and to external systems beyond the 
organization. These design documents will also describe storage and archival processes and will 
include access permissions and restrictions. ISPs will be able to review these processes, looking for 
omitted, incomplete, or inadequate descriptions and inconsistencies in descriptions of the same 
process across multiple design documents. Ideally, problem areas can be caught in the review of 
the documentation, and corrections or controls can be offered by the vendor. All identified vulner-
abilities in the design documents should be documented, along with the specified control(s); the 
vulnerabilities document can be part of the preoperations security assessment to ensure that the 
controls recommended are indeed implemented.
It is becoming very rare to see a software development initiative that does not employ a Web 
interface for user interaction and electronic commerce. ISPs and software development profession-
als are expected to be aware of this explosion in usage of Web tools and interfaces and the extreme 
vulnerabilities that exist in Web development design tools. All participants, therefore, should be 
familiar with the advancements in developing secure interfaces that will afford protection from 
many of the Internet threats, indicated by the links in Table 16.9, which provide a wide range 
of resources for ensuring a high level of security within Web interface development. The RFP 
requirements should expect that vendors have a working knowledge of the standards and processes 
so described.
It is important to complete a thorough review of all design documentation during the allotted 
time. Once the documents are reviewed and corrections are made, the documentation is ready for 
finalization and authorized acceptance. Any problems discovered in the documents after accep-
tance of the final versions will require an unplanned expense.
The general documentation, e.g., security, business continuity, architecture, change manage-
ment, risk management, will be subject to the same review and requirements tracking. Because 

242  ◾  Information Security Management Handbook
they are describing a future state, it will be appropriate to consider the initial set of documents as 
“preliminary.” It will be expected that these documents will undergo at least minor modifications 
as the complete system is finalized. The “preliminary” plans will be finalized during the preopera-
tions stage and will also be subject for review. These final documents should contain no assertions 
for planned processes and technologies, but clear descriptions of the final states. The final versions 
of these general documents will be the bases for live operations policies and procedures.
Plan–Do–CHECK–Act
After development of the system, logically comes the testing. In general, there are two primary test 
categories involving the created system: systems (or systems integration) testing and user accep-
tance testing.
Typically, systems testing is performed by the vendor to check the functionality of the initial 
coding and to ensure that the developed systems and subsystems integrate appropriately. On some 
occasions, users may participate or at least observe this testing process. All such tests and results 
Table 16.9  Resources for High-Level Security in Web Interface Development
The Building Security in Maturity Model (BSIMM): “… designed to help you understand, 
measure, and plan a software security initiative.”
http://bsimm.com/
Common Weaknesses Enumeration (CWE): “… a unified, measurable set of software 
weaknesses …”
http://cwe.mitre.org/
Common Vulnerabilities and Exposures (CVE): “… a dictionary of publicly known information 
security vulnerabilities and exposures.”
http://cve.mitre.org/
The Open Web Application Security Project (OWASP): “… focused on improving the security 
of application software.”
https://www.owasp.org/
Organization for the Advancement of Structured Information Standards (OASIS): “… produces 
worldwide standards for security, Cloud computing, SOA, Web services, the Smart 
Grid, electronic publishing, emergency management, and other areas.”
http://www.oasis-open.org/
Web Application Security Consortium (WASC): “… open source … security standards for the 
World Wide Web.”
http://www.webappsec.org/
Web Services Interoperability Organization (WS-I): “… Web services standards across 
platforms, operating systems, and programming languages.” (now an OASIS Member 
Section, Q4 2010)
http://www.ws-i.org/
http://www.oasis-ws-i.org/

Design of Information Security for Large System Development Projects  ◾  243
are expected to be made available to the organization for review and explanation. The tests may 
also be staggered, depending upon the completion timetables of the subsystems. ISPs need to 
be aware of any problems where data leakage may occur during interchanges, and if the logging 
mechanisms capture problems appropriately, but most of the review will be handled by the project 
managers and the SMEs. These reviewers must be able to accept that the system is performing as 
required.
User acceptance testing does involve active participation by the project team members and pos-
sibly organizational users outside of the project team. This level of testing should address business 
processes and work flow requirements as required, and the vendor should be able to demonstrate 
the expected performance of the system. This testing should stimulate the production system, 
but with the expectation of finding (and correcting) problems. Vendors should be challenged to 
complete the development sufficiently for performance evaluation, eliminating as many problems 
and bugs as possible, and not to employ user testing as a shortcut to the final development. ISPs 
will be more involved in this level, because potentially, live data from a legacy environment may 
need to be transferred. If any data is private or regulated, then the exchange must be protected and 
documented. Any media used in transferring the data must be destroyed appropriately and with 
proper authorization. The user testers will also look for correctness of interface transfers, including 
matching record counts, and where financial transfers are involved, the totals must also balance. 
Also, ISPs will be able to track problems within the logging mechanisms of exchanges and errors, 
accidental or deliberate.
Apart from testing the systems themselves, ISPs will also need to be involved with testing of the 
user interface (especially for a Web interface) and the mechanisms behind user authentication and 
authorization. More than likely, the details of the design of the user access control environment will 
be documented in the security plan. ISPs should be able to review the provisioning plans and observe 
sufficient demonstrations to evaluate the effectiveness of providing access only to authorized users. 
The processes should be according to the requirements, and most importantly, a deprovisioning 
process should be described and demonstrated. Part of the testing should also include attempting 
to break in with a known unauthorized user ID and password and observe the system response and 
the access log files for evidence of the rejection. The vendor technical staff also will be expected to 
describe the long-term monitoring and assessment practices of the provisioning efforts.
Other tests may be necessary, depending on the nature of the system being developed. If legacy 
system data is expected to be transferred to the new system, it will most likely require conversion 
testing. This requires careful planning to ensure that the records transferred will be acceptable and 
may involve the processes of extraction, transformation, and loading (ETL). Extraction is the col-
lecting of the data from the older system in an ordered manner, which may involve an authorized 
transfer for private, regulated data. Transformation aligns the older data terminology and record 
structure to the new system structures. This can be complex and time-consuming if the legacy 
system is much older than the new replacement system. Finally, Loading is the careful moving of 
the transformed data to the new system records. ISPs may be involved in planning and observing, 
but this process is usually driven by the SMEs and project management staff.
If the new system is to be hosted and managed by the vendor, a series of network assessments 
will be required. Ideally, an external service organization will be contracted to provide network 
discovery, penetration tests, common vulnerability assessments, and perhaps Web interface evalu-
ation. ISPs will be involved in planning, but the validity of the effort depends on the work being 
performed by a truly independent organization.
The primary testing responsibility for the ISPs will be the preoperations security assessment. This is 
most important for any system that involves collecting, storing, and processing regulated data and 

244  ◾  Information Security Management Handbook
information. The assessment can be based on any standard security review or audit methodology, as 
long as all areas are examined. It is not expected to take the place of a postoperations assessment or 
audit (depending on regulatory requirements). This assessment will best be performed as an advocacy 
process, where the organization and the contracted vendor participate together in a collaborative 
effort. The objective is to achieve a clean, secure environment, not to embarrass or find fault with 
the vendor. It should be led by the ISPs and should include the vendor ISPs and other organizational 
representatives as recommended by the senior management. The assessment should include specifi-
cally reviewing the vulnerabilities identified in the design and development phases, looking for hard 
evidence that the controls have indeed been implemented. The bulk of the assessment should track 
all the assertions and intentions to their final implementation, which may be the operations manual 
and final versions of the security and the business continuity plans. The summary report should 
include “findings” that will certainly need prompt attention as well as references to existing docu-
mentation for all the enterprise security structures. The assessment can also provide a preparation 
of documentation and other evidence that may be useful in any future postoperations audit. The 
assessment may also include a review or table-top exercise of the business continuity plan, although 
this may be a separate plan altogether. If possible, and if warranted by the nature of the new system, 
it may be desirable to observe the vendor’s formal business continuity recovery test.
Plan–Do–Check–ACT
Finally, with the new system loaded and tested, and with the vendor staffing underway, the whole 
environment is ready for the initiation of formal operations. Arguably, this may be counted in the 
previous section (“Check”), but because all of the formal testing is complete, the environment is 
expected to be in final operations status. Before the contract is finally settled, the environment will 
undergo an operational readiness review.
This may be the opportunity for running the new system in parallel with the older system; 
attempting to run the same processes with the same data on both environments. Because the two 
may be significantly different in architecture, infrastructure, and software, a truly parallel test 
may not be possible, but the exercise will allow for valid comparisons. In all practicality, the older 
system should not be taken down before such an exercise has been conducted. This may also be the 
time that all the latest data from the legacy system—since the earlier tests were conducted—will 
be moved to the new environment. This again may require a controlled, authorized process to 
protect regulated data and information. This also may be the best time for simulated stress testing 
to ensure that volumes of data and numbers of processes can be achieved as required and expected. 
This is also the opportune time for training of the organization’s general user population as well as 
the vendor staff who will operate the live system.
The final efforts before formally initiating the production environment involve signing off on 
the major achievements. These sign-offs may not characterize all projects in all industrial settings.
First is Validation, which is the formal acceptance that all requirements have been addressed or 
fulfilled—the system was built the way it was expected with all the desired subsystems and other 
components. This will be the formal result of the design and development documentation.
Second is Verification, which confirms that the system actually works the way the business 
process requirements and SMEs desired—data taken in, analyzed, and processed accordingly, and 
resulting data disseminated appropriately. This also includes accepting that the vendor has com-
plied with the service level agreements for performance and availability. This will be the formal 
result of the system and user acceptance testing and corrections.

Design of Information Security for Large System Development Projects  ◾  245
Third is Certification or Accreditation, which is the approval of the ISPs that the enterprise and 
system/infrastructure security is in place and operating as expected. Some industry sectors and 
public organizations may require an Accreditation signifying that an authorized board of review 
has granted the approval based on conformance to expected thresholds or service expectations. 
This will be the formal result of the final security assessment, including the vulnerability controls 
evaluation and the review of the business continuity tests.
After all such final hurdles, the senior executive responsible for the new system will formally 
sign the acceptance and authorize the initiation of the live production operations environment. 
This will trigger the final payments to the vendor for the system.
For most of the project participants, this is the end of a (relatively) long journey. For ISPs, 
the initiation of live operations is not the ending, but the true beginning—the beginning of 
information security discipline! After live operations begin, the calendar for postoperational 
assessments begins (based on regulatory requirements), and the ISPs will be tracking the project 
requirements for adjustments made in the first few months (very few large systems operate 
flawlessly in the first weeks/months). Any change or correction must follow the project change 
management process, which will entail reviews, signatures, and assurance that separation of 
duties is enforced. Depending on the organization and the nature of the system, regulatory 
audits and assessments will be scheduled for the first year. Some industry certifications or 
accreditations may not be awarded until after the system has been operational for several 
months. ISPs will also begin the periodic reviews of logs and error files and the tracking of the 
reported incidents in hopes of avoiding major interruptions. ISPs will also begin the tracking 
of expected changes to the software system and to the infrastructure/architecture based on 
normal growth in the organization.
Working through the design of an enterprise security structure for an LSDP provides a more 
complete perspective on the management of information security through time. Compelled to 
view the structure end-to-end, one is able to understand the limitations and inhibitions of the clas-
sic, task-oriented, compartmentalized view of information security. In many settings, the informa-
tion security role is considered part of the IT organizational unit; all other organizational users 
defer to the technical unit for security information. Its focus is operational or tactical, having 
a monthly-to-yearly planning perspective. The tasks also are short-term oriented—user account 
management, policy and procedure documentation, user training, etc. More technical ISPs may 
participate in network access device configuration, device and system log reviews, and incident 
response and resolution. Some ISPs may target business continuity/disaster recovery planning and 
testing. Classic information security is interrupt-driven—fire-fighting. It is detection-/response-
oriented and is usually measured by how quickly service interruptions can be resolved. In this 
view, information security is rarely considered part of long-term, strategic planning.
Personally identifiable Information is increasingly becoming a target of attackers because of 
its increasing value. Because of the increasing regulatory burden, organizations cannot maintain 
optimal protection of information with a short-term view. It is becoming increasingly apparent 
that all employees—from the top-down to the end of each hallway—have roles to play in protect-
ing data and information. Protection mechanisms cannot be relegated to purchased products or 
even to additional technical staff. Protection processes cannot continue to be interrupt-driven, 
with one-off responses to individual incidents. To gain efficiencies in time and money, informa-
tion security must be viewed as an organizational strategic emphasis. The administration of an 
information protection strategy must be separate from the IT unit because of the potential for 
conflicts in planning. The precedent in financial management is clear—no financial auditor unit 
would ever be allowed to report to the organizational financial officer.

246  ◾  Information Security Management Handbook
As a strategic resource, the ISPs will fill an important and necessary role for designing the 
protection of information throughout its complete life cycle—from gathering and creating to 
archiving and destruction. ISPs will offer strategies for technology change management, ensuring 
that changes do not open new vulnerabilities to the protection mechanisms. As described in this 
chapter, ISPs will play valuable roles in designing the enterprise security structure. In this mode, 
the information security resource will be anticipation-oriented, looking forward to determine the 
effects of organizational change on the information resource.
The short-term operational and tactical efforts will not go away, but they will be coordinated 
in ways that emphasize the interrelationships of the incidents, taking into account the potential 
for careful, slow-paced strategy of attackers seeking monetary gain. With the benefit of a strategic 
view, ISPs can become important organizational collaborators, building bridges among the 
Privacy and Risk Management groups, the IT technical support staff, the senior-level busi-
ness and service continuity planners, and the physical security groups involved with emergency 
response and human safety. From this strategic emphasis, the information security strategic unit 
will necessarily develop the Discipline of Information Security. Table 16.10 provides a summary 
view of the classic and necessary views of information security, though the complete story is for 
another time!
References
Associated Press. IBM says it can’t find hard drives with 2M health records. WRAL Techwire, 2011. http://
wraltechwire.com/business/tech_wire/news/blogpost/9270864/ (accessed March 15, 2011).
deBronkart, D. Imagine someone had been managing your data, and then you looked. E-Patient.net. 2009.
http://e-patients.net/archives/2009/04/imagine-if-someone-had-been-managing-your-data-and-
then-you-looked.html (accessed April 1, 2009).	
Table 16.10  Redefining the Information Security Role
Classic view of IS: The tasks of information 
security
Necessary view of IS: The discipline of 
information security
•	 Part of IT technical support
•	 Responsibility of technical experts
•	 InfoSec Operational/tactical planning
•	 Help-desk problem-solving
•	 Log review, incident response
•	 Interrupt driven fire-fighting
•	 Detection-/response-oriented
•	 Assignment-follower
•	 User account management
•	 User training, testing
•	 Policy/procedure documentation
•	 BC/DR planning, testing
•	 Independent of IT (conflicts)
•	 Responsibility of all employees
•	 InfoSec strategic planning, management
•	 Information life-cycle protection
•	 Technology change management
•	 Development project planning
•	 Anticipation-oriented!
•	 Collaborator, coordinator, 
bridge-builder
•	 Privacy/risk/audit
•	 Service continuity
•	 IT tech support
•	 Safety/physical security

Design of Information Security for Large System Development Projects  ◾  247
GHIT Notebook. What’s more important, privacy or security? (Based on interview with Dr. Deborah Peel, 
Patient Privacy Rights). Government Health IT, 2008. http://www.govhealthit.com/blogs/ghitnote-
book/350238-1.html (accessed February 27, 2008).
Goldberg, B. N. J. State computers nearly sold with sensitive data. Reuters.com, 2011. http://www.reuters.
com/article/2011/03/10/us-computer-snafu-idUSTRE7296KC20110310 (accessed March 10, 2011).
Gorman, S. Broad new hacking attack detected. Wall Street Journal Technology, 2010. http://online.wsj.com/
public/page/news-tech-technology.html (accessed February 18, 2010).
Gruener, W. Complete data security a mission impossible, study claims. Tom’s Hardware, 2008. http://www.
tomshardware.com/news/complete-data-security-a-mission-impossible-study-claims,4801.html.
Harbert, T. Security fail: When trusted IT people go bad. Computerworld, 2011. http://www.networkworld.
com/news/2011/011811-security-fail-when-trusted-it.html (accessed January 18, 2011).
Kiefer, B. Health Net, Inc. Investigating unaccounted-for server drives. News Release, 2011. http://healthnet.
tekgroup.com/article_display.cfm?article_id=5529 (accessed March 14, 2011).
Kolakowski, N. Google health accused of inaccuracy in electronic medical records. Information Week, 2009. 
http://www.eweek.com/c/a/Health-Care-IT/Google-Health-Accused-of-Inaccuracy-in-Electronic-
Medical-Records-603668/ (accessed April 13, 2009).
Krebs, B. Hackers break into Virginia health professions database, demand ransom, Washington Post, May 
4, 2009.
Murphy, C. IT is too darn slow. Information Week, 2011. http://www.informationweek.com/news/global-cio/
interviews/showArticle.jhtml?articleID=229218781 (accessed February 26, 2011).
Murphy, J. C. No one is listening! ISSA Journal, pp. 27–30, May 2009.
Perrin, C. The CIA Triad. Tech Republic, 2008. http://blogs.techrepublic.com.com/security/?p=488.
Ramshaw, E. and Garrett, R. T. Computer crash hinders Texas Attorney General’s Medicaid fraud case. Dallas 
Morning News, 2008. http://www.dallasnews.com/sharedcontent/dws/dn/latestnews/stories/102308dn
tswcomputerwoes.3d684d8.html (accessed October 23, 2008).
Rashid, F. Y. Data breaches at Arizona Medical Center makes case for zero trust security. EWeek, 2011. http://
www.eweek.com/c/a/Security/Data-Breaches-at-Arizona-Medical-Center-Makes-Case-for-Zero-Trust-
Security-571698/ (accessed January 14, 2011).
Rotenberg, M. Privacy vs. security? Privacy. Huffington Post, 2007. http://www.huffingtonpost.com/marc-
rotenberg/privacy-vs-security-priva_b_71806.html (accessed November 9, 2007).
Sanchez, J. Security vs. privacy? Reinterpreting the fourth amendment. Ars Technica, 2009. http://arstech-
nica.com/tech-policy/news/2009/03/from-the-academy-the-end-of-privacy.ars (accessed March 11, 
2009).
Schneier, B. Security vs. privacy. Schneier on security, 2008. http://www.schneier.com/blog/archives/2008/01/
security_vs_pri.html (accessed January 29, 2008).
Szabo, N. There is no universal security architecture, 1998. http://szabo.best.vwh.net/index.html.
Szabo, N. Trusted third parties are security holes, 2005. http://szabo.best.vwh.net/index.html.
Tom’s Guide. http://www.tomsguide.com/us/data-security,news-563.html (accessed February 11, 2008).
U.S. Department of Health & Human Services. Summary of the HIPAA Privacy Rule, 2003. http://www.
hhs.gov/ocr/privacy/hipaa/understanding/summary/index.html (accessed May, 2003).
U.S. Department of Health & Human Services. HITECH Breach Notification Interim Final Rule, 2009. 
http://www.hhs.gov/ocr/privacy/hipaa/understanding/coveredentities/breachnotificationifr.html 
(accessed October 2009).
U.S. Government Accountability Office (GAO). Federal Information System Controls Audit Manual (FISCAM). 
GAO-09-232G, 2009. http://www.gao.gov/special.pubs/fiscam.html (accessed February 2, 2009).
Washington Post. http://voices.washingtonpost.com/securityfix/2009/05/hackers_break_into_virginia_he.html 
(accessed May 4, 2009).
Zavis, A. and Zavis, R. Former Cedars-Sinai employee held in identity theft, fraud. Los Angeles Times, 2008. 
http://articles.latimes.com/2008/dec/23/local/me-cedars-sinai23 (accessed December 23, 2008).


249
Chapter 17
Building Application Security 
Testing into the Software 
Development Life Cycle
Sandy Bacik
Every enterprise should utilize an application development life cycle and within that life cycle 
there should be an application security architecture. An application security architecture contains 
a strong foundation of the application, providing controls to protect the confidentiality of infor-
mation, integrity of data, and access to the data when it is required (availability) and ensuring it 
is the authorized entities. And an application security architecture carefully considers feature sets, 
controls, safer and reliable processes using the enterprise’s security posture. As security controls 
are developed for an application, they must be tested during the use test and quality assurance 
testing processes. At a very high level, application security testing should consider answering the 
following questions:
◾
◾Is the process surrounding this function, service, or feature as safe and strong as possible 
without impacting operational requirements? In other words, is this a flawed process?
◾
◾If I were a bad entity, how could/would I abuse this function, service, or feature?
◾
◾If I were an inexperienced user, how could/would I use/abuse this function, service, or 
feature?
◾
◾Is the function, service, or feature required to be on by default? If so, are there limits or 
options that could help limit the risk from this function, service, or feature?
◾
◾Have success, failure, and abuse been considered when testing this function, service, or 
feature?
Security functions, services, and features that are built into an application should be based 
on existing application objectives, business requirements, use cases, and then test cases. When 
developing security functions, services, and features within an application that are based on docu-
mented requirements, the development of test cases for security should be relatively easy. Many 

250  ◾  Information Security Management Handbook
times, this is not the case. The tester must then attempt to build security testing into the quality 
assurance testing processes. If it is the responsibility of the tester to include security testing into 
their process without the support of management and security being built into the life cycle, the 
job of the tester will be uphill in ensuring that security testing is included as part of the application 
life cycle. Building in security requirements and test cases will produce a stronger and more secure 
application and application development life cycle.
Over the last decade, many software issues have not improved. Some of the top software devel-
opment flaws include the following, but this is not an exhaustive list:
◾
◾Buffer overruns
◾
◾Format string problems
◾
◾Integer overflows
◾
◾SQL and command injection
◾
◾Failing to handle errors or revealing too much information
◾
◾Cross-site scripting
◾
◾Failing to protect network transactions
◾
◾Use of magic URLs and hidden form fields
◾
◾Improper use of SSL and TLS
◾
◾Use of weak authentication mechanism, such as weak passwords
◾
◾Failing to store and protect data securely
◾
◾Information leakage
◾
◾Improper file access
◾
◾Race conditions
◾
◾Poor usability
How can we improve this? Yes, extending the application development life cycle to include more 
testing, specifically security testing. Without a good foundation to develop security testing, improving 
the security of an application cannot be accomplished. Before developing application test cases and 
testing requirements, standard definitions need to be accepted by the group. For example,
◾
◾A set of test requirements are technical or administrative actionable statements that are not 
subject to interpretation for a tester to develop a test plan/procedure.
◾
◾A test case is a step scenario of the items to be tested based upon a set of use cases and 
requirements.
◾
◾A test plan/procedure is a detailed list of tasks based on a requirement to perform the test. 
This would be the “how.” For example, a test plan/procedure will contain a requirement, 
passed, failed, and remarks about the test. A requirement would be something similar to 
“the time stamp shall be read from the clock off a centralized time source.”
◾
◾A test program is a set or collection of test plans/procedures.
◾
◾Defining a test requirement
−
−The term “shall” means the requirement is required.
−
−The term “should” means the requirement is optional.
−
−The requirement shall be positively stated.
−
−The requirement shall contain one and only one action.
−
−The requirement shall be documented as technical or administrative.

Building Application Security Testing into the Software Development Life Cycle  ◾  251
−
−The requirement shall be detailed enough to tell the tester what specifically needs to be 
tested and not contain implementation details.
−
−The requirement shall include what needs to be verified.
−
−The requirement shall use strong verbs. Action verbs are observable and better commu-
nicate the intent of what is to be attempted, like to plan, write, conduct, produce, apply, 
recite, revise, contrast, install, select, assemble, compare, investigate, develop, demon-
strate, find, use, perform, show, assess, identify, illustrate, classify, formulate, indicate, 
represent, explain, etc.
−
−The requirement shall avoid using verbs that can be misinterpreted, such as understand, 
know, think, determine, believe, aware of, familiar with, conceptualize, learn, compre-
hend, appreciate, and are conscious of.
−
−The requirement shall avoid generalities in objective statements and infinitives to avoid 
include to know, understand, enjoy, and believe rather than to learn, understand, and 
feel. The words need to be not only active but also measurable.
Example of Integrating Security into the 
Application Development Life Cycle
As an example of integrating security into the application development life cycle and developing 
security application testing, while an application is being developed, use or business cases are 
developed to ensure that the application being developed meets the needs of the stakeholders. 
Then application use cases form the basis of developing test cases for quality assurance testers to 
test. The application use case can provide the following baselines for developing a test case and 
test requirements:
◾
◾Name the system scope and boundaries.
◾
◾Who are the primary actors or what are the endpoints sending and receiving information?
◾
◾What is the goal of the system or transaction?
◾
◾Who are the stakeholders?
◾
◾What are the requirements?
◾
◾What are actor/endpoint interests, preconditions, and guarantees?
◾
◾What is the main success scenario?
◾
◾What are the steps to success?
From the above information being described in an application use case, application security 
requirements can be developed. Therefore, if the application development requirements include 
something like the following, again, not an exhaustive list:
◾
◾Data entry fields shall have secure defaults.
◾
◾Access shall be based on the principle of least privilege.
◾
◾The application shall employ a defense-in-depth strategy.
◾
◾The application shall fail securely and not display sensitive information.
◾
◾The application shall verify and validate all services.
◾
◾The application shall employ segregation of duties based on roles.

252  ◾  Information Security Management Handbook
From this list of requirements, we know that the following functions are the minimum that 
are required for this application:
◾
◾Administration
◾
◾Integration
◾
◾Authentication
◾
◾Authorization
◾
◾Segregation of duties
◾
◾Access control
◾
◾Logging
◾
◾Record/log retention
◾
◾Reporting, alerting, and monitoring
As the scenarios are developed for test cases, the above functions need to be integrated into 
the scenarios and steps within the application. A sample test case paragraph could be as follows:
The application user shall be authenticated using an application user account and 
password prior to being placed in an application role and having one and only one user 
session at one time. The application shall log all successful and failed authentication 
attempts to access the application.
The steps developed within the application test case would then include the following:
	
1.	The application shall display a use logon screen.
	
2.	The user shall enter a user ID and password.
	
3.	The application shall validate the entered user ID and password.
	
4.	If the user ID or password is invalid, the application shall display an invalid logon message.
	
5.	If the user ID or password is invalid, the application shall log an invalid logon message.
	
6.	If the user ID and password are valid, the application shall validate that this is the only 
signed-in location for the use account.
	
7.	If the user ID and password are valid, the application shall log a valid logon message.
	
8.	If the user ID and password are valid, the session shall be placed in an application role based 
on the use account membership.
From the above set of requirements, the application tester can now produce detailed steps to 
perform security testing of the authentication process. These security testing steps need to include 
testing as a good user, as an intentionally bad user, as an accidentally bad user, and as a user not 
authorized to access and use the application.
Other things that could be considered when testing authentication and authorization could 
include the following:
◾
◾Setting up multiple sessions with the same and different information to overload the system
◾
◾Valid/invalid/disabled accounts
◾
◾Password changes/lockouts/resets
◾
◾Elevating privileges (administrative versus nonadministrative)
◾
◾Accessing screens/fields/tables/functions
◾
◾Valid/invalid data in each field
◾
◾Logging out versus aborting the application

Building Application Security Testing into the Software Development Life Cycle  ◾  253
◾
◾Information disclosure on errors and aborting
◾
◾Information and access within log files and alerts
◾
◾Hidden fields—special areas to click to execute
◾
◾Can you get to a command line (listing or seeing directory content)?
◾
◾Can you put in extra characters in a field and get the application to accept them?
◾
◾Use application security requirements to build security test cases.
◾◾Use existing testing cases and look at them from a security point of view to do additional testing.
◾
◾Look at what can accidently or deliberately be done with the application.
Using the flaws listed above with many applications, the following table describes some of the 
tests that could be performed during the quality assurance testing to build security testing into 
the application life cycle.
Potential Software Flaw
Security Testing to be Included
Buffer overruns
Carefully check your buffer accesses by using safe string and 
buffer handling functions.
Use compiler-based defenses.
Use operating system–level buffer overrun defenses.
Understand what data the attacker controls, and manage that 
data safely in code.
Format string problems
Use fixed format strings, or format string from a trusted source.
Check and limit locale requests to valid values.
Integer overflows
Check all calculations used to determine memory allocations to 
check that arithmetic cannot overflow.
Check all calculations used to determine array indexes to check 
that the arithmetic cannot overflow.
Use unsigned integers for array offsets and memory allocation 
sizes.
SQL and command 
injection
Understand the database you use.
Check the input for validity and trustworthiness.
Use parameterized queries, prepared statements, placeholders, 
or parameter binding to build SQL statements.
Store the database connection information in a location outside 
of the application.
Perform input validate on all inputs before passing it to a 
command processor.
Handle the failure security if an input validation check failed.
Failing to handle errors
Check the return value of every function.
Attempt to gracefully recover from error conditions.
Cross-site scripting
Check all Web-based inputs for validity and trustworthiness.
HTML-encode all outputs originating from user input.

254  ◾  Information Security Management Handbook
Failing to protect 
network traffic
Perform ongoing message authentication for all network traffic.
Use a strong initial authentication mechanism.
Encrypt all data for which privacy is a concern and err on the side 
of privacy.
Use SSL/TLS for all on-the-wire crypto needs.
Use of magic URLs and 
hidden form fields
Test all Web input, including forms, with malicious input.
Understand the strengths and weaknesses of the approach, if 
you are not using cryptographic primitives to solve some of 
these issues.
Improper user of SSL 
and TLS
Use the latest version of SSL/TLS available.
Use a certificate allow list, if applicable.
Ensure that, before you send data, the peer certificate is traced 
back to a trusted CA and within its validity period.
Check that the expected hostname appears in a proper field of 
the peer certificate.
Use of weak password-
based systems
Ensure that passwords are not unnecessarily snoopable over the 
wire when authenticating.
Give one a single message for failed login attempts.
Log failed password attempts.
Use a strong, salted cryptographic one-way function based on a 
hash for password storage.
Provide a secure mechanism for people who know their 
passwords to change them.
Improper file access
Be strict and account what you will accept as a valid filename.
Race conditions
Write code that does not depend on side effects.
Be very careful when writing signal handlers.
Information leakage
Define who should have access to what error and status 
information data.
Use operating system defenses such as ACLs and permissions.
Use cryptographic means to protect sensitive data.
Failing to store and 
protect data securely
Think about the access controls the application explicitly places 
on objects, and the access controls objects inherit by default.
Realize that some data is so sensitive it should never be stored 
on a general purpose, production server.
Leverage the operating system capabilities to secure secret and 
sensitive data.
Use appropriate permissions.
Remove the secret from memory space once you have used it.
Scrub the memory before you free it.

Building Application Security Testing into the Software Development Life Cycle  ◾  255
Poor usability
Understand security needs and provide the appropriate 
information to help them get their jobs done.
Default to a secure configuration whenever possible.
Provide a simple and easy-to-understand message.
Make security prompts actionable.
Conclusion
If the application life cycle includes security from the beginning, then the security application 
testing will logically follow when performing the quality assurance and user testing. If security is 
not included throughout the application life cycle, it will be harder to accomplish good applica-
tion security testing within the quality assurance and user test processes. Including application 
security testing within the application life cycle will reduce the risk to information assets within 
the enterprise.


Malicious Code


259
Chapter 18
Twenty-Five (or Forty) Years 
of Malware History*
Robert M. Slade
As 1986 dawned, computer users around the world were unaware that life, as they knew it, would 
never be the same. Within weeks, the Brain computer virus would be unleashed upon an unsus-
pecting planet, and the computing world would never be the same again!
Well, not quite.
Brain [or BRAIN or (c)BRAIN] was probably written and released some time before 1986. It 
did become widespread, and well-known, and was likely the first virus written for the MS-DOS 
platform, but it was not the first virus ever written. (We will get back to it.)
It is hard to say where to start with viruses. Viruses work best when they work silently, so the 
most important ones did not cause a lot of fuss or fanfare. There are also a lot of people who claim 
“the first virus” was a particular game or prank or utility, even when these programs had nothing 
to do with reproduction, which is a central aspect of viruses (Figure 18.1).
I suppose we might begin with Howard Aiken. Not that computer viruses were his fault—far 
from it! Aiken designed computers in the 1940s and 1950s, which were operated at Harvard 
University, mostly in terms of work done for the U.S. Navy. (Grace Hopper was one of the crew 
that maintained and programmed these computers.) Aiken’s central design structure made a very 
strict separation between the programs that these computers used and the data that was operated 
upon. This arrangement, which became known as the Harvard Architecture, would have made it 
almost impossible for the viruses that we know today to operate. Unfortunately, the industry pre-
ferred the von Neumann architecture, which makes no distinction between programs and data, 
and the malware situation that we see today was set to emerge.
Of course, it did not emerge right away. There were a few related items that came up over the 
years, though. Like the game of Core Wars that programmers played, where some of the more 
successful programs created copies of themselves. Or the prank played one time (ironically to get 
attention for a security problem) where two programs would check for each other in a machine 
and, if the other had been killed, start up a new copy.
*	© Copyright Robert M. Slade. Used by permission.

260  ◾  Information Security Management Handbook
(a)
(b)
(c)
Figure 18.1  Some viruses do present some kind of symptom or message. These illustrations 
show the effect of the Cascade virus, which caused, over time, characters to fall from their 
normal position on the screen toward the bottom, eventually forming “piles” of letters at 
the base.

Twenty-Five (or Forty) Years of Malware History  ◾  261
Core Wars
With programmers being who they are, the development of rogue programs 
became a sport. This is now enshrined in the game of “Core Wars.” A program 
that “simulates” a computer environment is run. A standard set of instructions, 
known as “Redstone code,” are used to build programs that battle each other 
within the simulated environment. The objective is survival. The use of such 
tactics as attack, avoidance, and replication is of interest to virus research, as is 
the trade-off between complexity of design and chance of destruction.
“Password trojans” were extremely popular in the university and college environments and 
have lately been followed by more malicious identity and monetary theft systems known as phish-
ing. The original programs were simple: a facsimile of the normal login screen will generally get 
the user to enter his or her name and password. It is quite simple to have a program write this 
information to a file or even mail it to a specific account.
A famous, if relatively harmless, prank in earlier computers was the “cookie” program, which 
ran on PDP series computers. This program would halt the operation that the victim was working 
on and present a message requesting a cookie. If the user typed “cookie,” then processing would 
continue. There was a later viral program that followed this pattern, a “Spanish Cookie” virus. 
This copying of ideas—viruses using ideas that came from jokes and gags using symptoms of 
viruses—is relatively common (Figure 18.2).
The earliest reproductive program was the one called Creeper, which was created, as an experi-
ment in “mobile” computing, at one of the earliest companies involved in research into computer 
networking, in 1971. Creeper copied itself from one machine to another over a network. It is, 
therefore, closer to our definition of a worm than a virus.
Viruses and Worms Begin
John Shoch and Jon Hupp, two researchers at Xerox PARC (Palo Alto Research Center) were 
interested in the concept of distributed processing—the ability of computers to work cooperatively 
on single or related tasks. The specific experimental program they were testing was the one that 
would examine other computers on the net, and, if a computer was idle after normal working 
hours, e.g., submit a copy of itself to the idle machine. In this way, the original program would 
spawn multiple copies of itself to idle machines to make use of the CPU time that would otherwise 
go to waste. By breaking a problem down into small chunks, each capable of solution on one of the 
machines on the network, you would have a large program consisting of small program segments 
working on individual machines. Because biological worms are defined by the fact that they have 
segmented bodies, they called this new type of program a “worm.”
Apple 1, 2, 3
The earliest case of a virus that succeeded “in the wild” goes back to late 1981. The idea was 
sparked by a speculation regarding “evolution” and “natural selection” in pirated copies of games 
at Texas A&M: the “reproduction” of preferred games and the “extinction” of poor ones. This led 
to considerations of programs that reproduced on their own. Apple II computer diskettes of that 

262  ◾  Information Security Management Handbook
time, when formatted in the normal way, always contained the Disk Operating System (DOS). 
The programmer attempted to find the minimum change that would make a version of DOS that 
was viral, and then tried to find an “optimal” viral DOS. A group came up with an initial version 
of such a virus in early 1982, but quarantined it because of adverse effects.
A second version was allowed to “spread” through the disks of group members. A bug was 
identified after this viral DOS spread outside the group members, and a third version was writ-
ten that avoided the memory problems: parts of the coding involve bytes that are both data and 
opcode. Version 3 was subsequently found to have spread into disk populations previously felt to 
be uninfected, but no adverse reactions were ever reported.
(For those who have Apple DOS 3.3 disks, location B6E8 in memory, toward the end of track 0, 
sector 0 on disk, should be followed by 18 zero bytes. If, instead, the text “(GEN xxxxxxx TAMU)” 
appears, the digits represented by the “x”s should be a generation counter for virus version 3.)
The story has an interesting postscript. In 1984, a malicious virus was found to be spreading 
through the schools where all this took place. Some disks appeared to have immunity. All of these 
immune disks turned out to be infected with version 3.
The Work of Dr. Cohen
No historical overview of viral programs can be complete without mention of the work of Fred 
Cohen. He first presented his ideas in a data-security seminar in 1983, and his seminar advi-
sor, Len Adelman (the “A” in “RSA”), suggested the term “virus” to apply to Cohen’s concept. 
Figure 18.2  This is a screenshot of the prank program known as Anthem. (The program also 
plays the French national anthem over a sound card.) This reversal of the screen is also a feature 
of an older virus, known as Flip.

Twenty-Five (or Forty) Years of Malware History  ◾  263
Cohen’s master’s thesis on the topic was published in 1984, and his doctoral dissertation, in 1986, 
expanded his earlier research.
His practical work proved the technical feasibility of a viral attack in any computer-system 
environment. Equally important, his theoretical study proved that the “universal” detection of a 
virus is undecidable, and therefore a “perfect” antiviral program is impossible. Cohen also out-
lined the three major classes of antiviral protection and that is the basis for all antiviral systems 
created to date.
Viruses Start to Spread
It is reasonably certain that the first major virus started to reproduce in 1986. Autumn 1987 really 
seemed to get the ball rolling with regard to virus research. In fact, most virus history seems to 
have happened between 1986 and 1990, with everything that followed being a repeat, in one form 
or another, of what had gone before.
(c)Brain
The “Brain” virus is probably the earliest MS-DOS virus. At one time, it was the most widespread 
of PC viral programs. Like the Apple viruses in the early 1980s, it was disk-based, rather than 
being related to program files. Until the advent of macro viruses, disk-based viruses (usually tech-
nically known as boot sector infectors or BSIs) were “superior” in terms of the numbers of infec-
tions created. The Brain family is prolific, although less so than Jerusalem.
(Seemingly, any successful virus spawns a plague of copies as virus writer-wannabes use it as 
a template.) Like the later Jerusalem virus, it seems that one of the lesser variants might be the 
“original.” The “ashar” version appears to be somewhat less sophisticated than the most common 
Brain, and Brain contains text that makes no sense unless Brain is “derived” from ashar. Brain 
contains other “timing” information: a “copyright” date of 1986 and an apparent “version” num-
ber of 9.0 (Figure 18.3).
Brain is at once sly and brazen about its work. It is, in fact, the first stealth virus, in that a 
request to view the boot sector of an infected disk on an infected system will result in a display of 
Figure 18.3  (c)BRAIN disk map.

264  ◾  Information Security Management Handbook
the original boot sector. However, the Brain virus is designed not to hide its light under a bushel: 
the volume label of infected diskettes becomes “(c)Brain” (or “(c)ashar” or “Y.C.1.E.R.P” for dif-
ferent variants). Hence, the name of the virus (Figure 18.4).
Lehigh
In November 1987, it appeared that certain failed disks reported at Lehigh University were due to 
something other than user carelessness. The Lehigh virus infected copies of COMMAND.COM, 
and, when run (usually upon booting from an infected disk), the virus stayed resident in memory. 
When any access was made to another disk, via the TYPE, COPY, DIR, or other normal DOS 
commands, any (and only) uninfected COMMAND.COM files would be infected. A counter was 
kept of infections: after four infections, the virus would overwrite the boot and FAT areas of disks. 
The extreme destructiveness of Lehigh probably limited its spread: aside from copies in research 
“zoos,” the Lehigh virus never spread off the campus.
CHRISTMA exec
In December 1987, IBM mainframe computers in Europe, connected via the EARN network, 
experienced a “mailstorm.” Such events were fairly common on the early “internetworks,” caused 
by various mailer problems. This particular mailstorm, however, was of unprecedented severity.
The CHRISTMA exec was a message that contained a script program. “Christmas card” mes-
sages with the REXX system can be more than just the usual “typewriter picture.” These mes-
sages could include forms of animation such as asterisk snowflakes falling on a winter scene, or a 
crackling fire from a Yule log. Typing either “christmas” or “christma” would generate the “card.” 
It really was not anything special—a very simplistic conifer shape made out of asterisks.
However, at the same time that it was displaying the tree on the screen, it was also search-
ing for the lists of other users that either sent mail to, or received mail from, this account. The 
CHRISTMA exec would then mail copies of itself to all of these accounts (Figure 18.5).
CHRISTMA exec was thus the first e-mail virus, and the first script virus, over a decade before 
the much later Loveletter or LoveBug virus.
In March 1990, an MS-DOS virus, XA1 Christmas Tree, was discovered. Although it has no 
technical or programming aspects related to any of the network worms, it seems to have been written 
“in memor” of them. It contains (in German) the message “And still it is alive: the Christmas Tree!”
Jerusalem
Initially known as the “Israel” virus, the version reported by Y. Radai in early 1988 (also sometimes 
referred to as “1813” or Jerusalem-B) tends to be seen as the central virus in the family. Although 
it was the first to be very widely disseminated and was the first to be “discovered” and publicized, 
internal examination suggests that it was, itself, the outcome of previous viral experiments.
Although one of the oldest viral programs, the Jerusalem family still defies description, pri-
marily because the number of variants makes it very difficult to say anything about the virus for 
Figure 18.4  BRAIN version with address text removed.

Twenty-Five (or Forty) Years of Malware History  ◾  265
sure. The “Jerusalem” that you have may not be the same as the “Jerusalem” of your neighbor. Like 
Brain before it, Jerusalem was used as a template by young virus writers who wanted to get into 
the act, but lacked the necessary programming skills.
MacMag
The MacMag virus was relatively benign. It attempted to reproduce until 2 March 1988, using 
the disk-based INIT resource on the Mac system. When an infected computer was booted on that 
date, the virus would activate a message that “RICHARD BRANDOW, publisher of MacMag, 
and its entire staff would like to take this opportunity to convey their UNIVERSAL MESSAGE 
OF PEACE to all Macintosh users around the world.” Fortunately, on 3 March, the message 
appeared once and then the virus erased itself.
Richard Brandow was the publisher and editor of the MacMag computer magazine. Brandow 
at one point said that he had been thinking about the “message” for 2 years prior to releasing it. 
(Interestingly, in view of the fact that the date selected as a trigger, 2 March 1988, was the first anni-
versary of the introduction of the Macintosh II line. It is also interesting that a “bug” in the virus 
that caused system crashes affected only the Mac II.) Indeed, he was proud to claim “authorship,” 
in spite of the fact that he did not, himself, write the virus. (Brandow had apparently commissioned 
the programming of the virus, and the internal structure contains the name “Drew Davidson.”)
MacMag holds a number of “firsts” in the computer world. It seems to have been released via a 
dropper program that was embedded within a HyperStack data file, thus predating the later macro 
viruses. It also infected a commercial application and was widely spread in that manner.
Figure 18.5  Part (mostly the display section) of the script code for the CHRISTMA exec virus.

266  ◾  Information Security Management Handbook
Scores
The Scores Mac virus is interesting for a number of reasons, but it gets inclusion here simply 
because it was the first virus that had a definite company and application as a target.
Stoned, Michelangelo, and Other Variants
The Stoned virus was originally written by a high school student in New Zealand. All evidence 
suggests that he wrote it only for study and that he took precautions against its spread. Insufficient 
precautions, as it turned out: it is reported that his brother stole a copy and decided that it would 
be fun to infect the machines of his friends.
Stoned spawned a large number of mutations ranging from minor variations in the spelling of 
the payload message to the somewhat functionally different Empire, Monkey, and No-Int varia-
tions. Interestingly, only Michelangelo appears to have been as successful in reproducing.
Like the Apple viruses and Brain, Stoned was disk-based. Until the Word macro viruses came 
along in 1994, disk-based viruses were the dominant form.
If They Joke About It, Is It Mainstream?
The Modem virus was first “reported” on 6 October 1988. Although this may not constitute the 
very first virus hoax, many subsequent hoaxes have used many of the same features. The original 
report was supposed to have come from a telecommunications firm in Seattle (therefore laying 
claim to have come from some kind of authority), and claimed that the virus was transmitted 
via the “subcarrier” on 2400 bps modems, so you should use only 300 or 1200 bps. (There is no 
“subcarrier” on any modem.)
The initial source of the hoax seems to have been a posting on Fidonet, apparently by someone 
who gave his name as Mike RoChenle. This pseudonym was probably meant as a joke on “micro-
channel,” the then-new bus for IBM’s PS/2 machines.
The Internet Worm
The Internet Worm is possibly the preeminent case of a viral program in our time. In many ways, this 
fame (or infamy) is deserved: the Internet Worm is the story of data security in miniature. The Worm 
used trusted links, password cracking, security holes in standard programs, the almost ubiquitous buf-
fer overflow, standard and default operations, and, of course, the power of viral replication.
Server computers on the networks are generally designed to run constantly—to be ready for 
“action” at all times. They are specifically set up to run various types of programs and procedures 
in the absence of operator intervention. Many of these utility programs deal with the communica-
tions between systems.
When the Worm was well established on a machine, it would try to infect another. Two of the 
major loopholes it used were a buffer overflow in the fingerd program and the debug mode of the 
sendmail utility, which was frequently left enabled.
Robert Tappan Morris (RTM) was a student of data security at Cornell University, when he 
wrote the Worm. The Worm is often referred to as a part of his research, although it was neither 
an assigned project, nor had it been discussed with his advisor.
RTM was convicted of violating the computer Fraud and Abuse Act on 16 May 1990. In 
March 1991, an appeal was denied. He was sentenced to 3 years of probation, a $10,000 fine, and 
400 hours of community service.

Twenty-Five (or Forty) Years of Malware History  ◾  267
More of the Same
At this point in time, most of the major viral and malware technologies had been invented. Most 
future nasties simply refined or rang changes on what had gone before.
More Shapes for Polymorphism
Christopher Pile, who was known to the blackhat community as the Black Baron, produced 
SMEG, the Simulated Metamorphic Encryption Engine. Polymorphism was a virus technology 
that had been known since the relatively unsuccessful V2P1 or 1260 virus in the early days, and 
even polymorphic engines were common. In May 1995, Pile was charged with 11 offences under 
the United Kingdom’s Computer Misuse Act 1990.
Good Times for All—Not!
The Good Times virus warning hoax is probably the most famous of all false alerts and was cer-
tainly the earliest that was widely distributed. The hoax probably started in early December 1994. 
Virus hoaxes and false alerts have an interesting double relationship with viruses: the hoax usually 
warns about a fictitious virus and also suggests that the reader send the alert to all friends and 
contacts, thus getting the user to do the reproductive part.
At the time of the original Good Times message, e-mail was almost universally text-based. The 
hoax warned of a viral message that would infect your computer if you even read it, and the possi-
bility of a straightforward text message carrying a virus in an infective form is remote. It provided 
no information on how to detect, avoid, or get rid of the “virus,” except for its warning not to read 
messages with “Good Times” in the subject line. (The irony of the fact that many of the warnings 
contained these words seems to have escaped most people.)
Predictably, a member of the vx community produced a “Good Times” virus. Like the virus 
named after the older Proto-T hoax, the programmed “Good Times” was an uninteresting speci-
men, having nothing in common with the original alert.
Proof of Concept
Concept was not the first macro virus, a virus that embeds executable program script within a 
data file, ever created. HyperCard viruses were commonplace in the Macintosh environment, 
and a number of antivirus researchers had explored WordBasic and other malware-friendly macro 
environments before the virus appeared in August 1995.
However, Concept was the first macro virus to be publicly described as such and certainly the 
most successful in terms of spreading. For a while, it was easily the most widely encountered virus in 
the world, knocking disk-based viruses out of top spot for the first time. From the fall of 1995 until the 
“fast-burner” e-mail viruses of 2000, macro viruses were pretty consistently in the top spot.
Unlike earlier boot sector and program file viruses, macro viruses carried their own source 
code. This made it even easier for those with almost no programming skills to produce variants 
based on a copy they encountered.
The Power of E-Mail
By 1999, and the turn of the millennium, everyone had become convinced of the benefits of 
e-mail. So had virus writers.

268  ◾  Information Security Management Handbook
W97M/Melissa (MAILISSA)
She came from alt.sex. Now, as the old joke goes, that I have your attention ... At this instance, 
though, the lure of sex was certainly employed to launch the virus into the wild. The source of 
the infestation of the Melissa Word macro virus (more formally identified as some variation on 
W97M/Melissa) was a posting on the Usenet newsgroup alt.sex, probably originally on 26 March 
1999. The message had an attachment, a Word document. The posting suggested that the docu-
ment contained account names and passwords for Web sites carrying salacious material.
The document carried a macro that used the functions of Microsoft Word and the Microsoft 
Outlook mailer program to reproduce and spread itself. Melissa is not the fastest burning e-mail-
aware malware to date, but it certainly held the record for a while. In 1994, an e-mail virus was 
impossible. Padgett Peterson, author of MacroList, one of the best available macro virus protection 
tools, stated, “For years we have been saying you could not get a virus just by opening E-Mail. 
That bug is being fixed.”
As a macro virus, Melissa also carried its own source code. As an e-mail virus, it spread widely. 
Therefore, it was widely used as a template for other variants, some of which appeared within days.
Happy99 (SKA)
Happy99 used e-mail to spread, but sent itself out as an executable attachment. To do this, it actu-
ally took over the computer’s connection to the Internet. Later viruses, using the same method, 
would actually prevent users from contacting antivirus Web sites for help with detection and 
disinfection (Figure 18.6).
PrettyPark
PrettyPark is versatile: not only is it a worm, but it also steals passwords and has backdoor func-
tionality. Thus, it is one of first examples of the convergence that we have seen recently: malware 
containing functions from a variety of classes of nasty programs (Figure 18.7).
VBS/Loveletter
The Love Bug, as it will probably always be known, first hit the Net on 3 May 2000. It spread 
rapidly, arguably faster than Melissa had done the previous year.
Figure 18.6  Viruses have many ways to disable protection, or to get you to disable it for them. 
The Fakespy would actually pop up this message, to direct the user to a site to download … well, 
anything the blackhats wanted, really.

Twenty-Five (or Forty) Years of Malware History  ◾  269
The message consisted of a short note urging you to read the attached love letter. The attach-
ment filename, LOVE-LETTER-FOR-YOU.TXT.vbs, was a fairly obvious piece of social engi-
neering. The .TXT bit was supposed to make people think that the attachment was a text file 
and thus safe to read. At that point, many people had no idea what the .VBS extension signified, 
and might in any case have been unaware that if a filename has a double extension, only the last 
filename extension has any special significance to Windows. Putting vbs in lowercase was likely 
meant to play down the extension’s significance.
VBS stood for Visual Basic Script, and, if you had updated your computer to Windows 98 or 
2000, or even if you had updated to the latest version of Internet Explorer, it was now associated 
with Windows Script Host, a new batch language provided by Microsoft. Almost everybody had. 
Almost nobody knew the significance of VBS. As well as hugely rapid spread, Loveletter had a 
somewhat destructive payload that cost a lot of people their graphics and MP3 files.
VBS/Stages
VBS/Stages spread via Internet chat clients, e-mail, and mapped network drives. If it arrived 
by e-mail, the attachment is called LIFE_STAGES.TXT.SHS. The .SHS extension denotes a 
Windows scrap object, a file that can, in principle, be any kind of file and can be executed. 
Windows Explorer does not show the .SHS file extension, irrespective of whether file extensions 
are set to be displayed, thus providing another interesting way for viruses to hide what they are 
(Figures 18.8 through 18.10).
Linux Worms
By the spring of 2001, a number of examples of Linux malware were extent. Interestingly, the new 
Linux worms are similar to the Internet/Morris/UNIX worm in that they primarily relied on bugs 
in automatic networking software.
Figure 18.7  Some viruses take over many parts of your computer. The Avril-A virus would open 
this (legitimate) Web page in your Internet Explorer browser.

270  ◾  Information Security Management Handbook
Poly/Noped
This 2001 VBScript worm displays a message about stopping child pornography. It scans for 
JPEG files on the hard disk, looking for specific strings in the filename that the virus author obvi-
ously thought might relate to pornography. The worm will collect these files and e-mail them to 
Figure 18.8  Note that the two “test” file icons look very similar to either text or undefined file 
icons.
Figure 18.9  However, in detail view, although the SHS extension is still not shown, the fact that 
the files are scrap objects is noted.

Twenty-Five (or Forty) Years of Malware History  ◾  271
addresses thought to belong to law enforcement agencies. Despite the attempt to prove that viruses 
can provide a socially useful service, this does not help anyone.
LINDOSE/WINUX
Summer of 2001 saw a virus that could infect both Linux ELF files and Windows PE-EXE files. 
Big deal. Jerusalem and sURIV3 could infect both .COM and .EXE files back in 1987.
Code Red
In 2001, Microsoft’s IIS contained a buffer overrun vulnerability in the index server, and Code 
Red used it to spread startlingly quickly as a worm. A later version, Nimda, took the multipartite 
concept (spreading via multiple objects or vectors) to new heights and would spread using the same 
worm activity, as well as e-mail attachment, file infection, and spreading over local area networks 
using drive shares (Figure 18.11).
Sircam
In 2001, Sircam searched for documents on your computer and incorporated the document into 
the virus itself, thus changing the size and name of the attachment. However, because it also 
mailed the document out to the addresses on your computer, it could breach your privacy. A later 
virus, Klez, did something similar. In one case, a confidential document from a security concern 
got sent to a mailing list.
Sobig.F
As I was struggling to get a book manuscript off to the publisher in August 2003, I was having a 
hard time keeping my e-mail open because of a massive deluge of Sobig.F infected messages. Sobig 
was one of the original spambotnet viruses, carrying with it software for its own SMTP server, a 
backdoor capability, and other utilities. It was at this point that virus writers seemed to start to think 
in commercial terms. Later, the authors of Bagle, Netsky, and MyDoom would actually engage in a 
type of war, trying to target and take down each other’s infected nets, while building their own to 
“rent” massive numbers of infected machines to spammers. Interestingly, the virus writers are also 
using the spambotnets as distribution systems to “seed out” new viruses as they are written.
Figure 18.10  A directory listing in a DOS box does shows the SHS extension.

272  ◾  Information Security Management Handbook
Spyware and Adware
There is a lot of controversy over a number of technologies generally described 
as adware or spyware. Most people would agree that the marketing functions 
are not specifically malicious, but what one person sees as “aggressive selling,” 
another will see as an intrusion or invasion of privacy. Therefore, it is not only 
difficult to say for sure whether a specific piece of software is adware or spy-
ware, but also exactly when this type of malware started to appear, as malware.
Because it is so hard to draw the line between legitimate and malicious 
programs in this area, you will probably have to get spyware detection sepa-
rately from antivirus scanning. After all, the antivirus companies have a good 
test: if you can make it reproduce, it is a virus. Certain companies involved in 
detecting spyware are trying to find similar functional definitions of spyware 
and adware, but the initial proposals have not been greeted with universal 
enthusiasm (Figure 18.12).
Even the spyware companies themselves admit that it is not always pos-
sible to determine which spyware is actually unwanted. A number of the spy-
ware or adware programs are related to certain games or utilities. If you want 
the program that you downloaded from the Net, you have to let the spyware 
or adware run (Figure 18.13).
All questions of the difficulty of defining spyware aside, there is no question 
that there is an enormous amount of it out there. In fact, although a computer 
that seems to be running more slowly than usual has traditionally been suggested 
as the sign of a virus, now we are much more likely to find that the culprit is 
adware or spyware. (On one visit to a Web-based greeting card site, I found that 
Figure 18.11  Worms can spread quickly, although some have a tendency to confine to a given 
location or range of Internet addresses. You can explore the patterns of spread with a worm 
simulator that can be downloaded from the Symantec Web site.

Twenty-Five (or Forty) Years of Malware History  ◾  273
it installed 150 pieces of spyware on my computer. Obviously, we do not read 
those greeting cards anymore.) Be careful out there: you no longer have to ask to 
download and install games or screensavers to get spyware these days. A lot of 
sites will do “browse by” installs when you simply visit or look at the site.
Can I Get a Virus on My Cell?
Or, Blackberry, PDA, smartphone, or other form of mobile computing device? 
The mobile issue is fairly simple. Mobile malware is already out there, although 
none of it has made much of an impact. So far. Eventually, it will. The only 
indicator that we have ever found about prevalence of malware on a given 
Figure 18.12  Spybot Search and Destroy, one of the spyware detecting programs you can find.
Figure 18.13  When you run Spybot, it warns you that deleting certain instances of spyware or 
adware may cause the program that you actually wanted to cease operating.

274  ◾  Information Security Management Handbook
platform is the number of users. In other words, as soon as a lot of people are 
using a given mobile/smart cell phone operating system, there will be malware.
Even More of the Same
All of the foregoing will seem like old hat and ancient history. Unfortunately, the big malware 
names that have recently hit the news do not really bring anything new to the table. If anyone 
had been paying attention to malware, these “major new threats” would have failed to find any 
traction at all.
Conficker
The Conficker system began setting up botnets in late 2008. Of course, botnets had been around 
for more than 5 years at that point. Conficker used vulnerabilities that had been patched if the 
operating system was kept up to date. Unfortunately, we have seen that too many people do not 
learn the lessons of computer history and do not keep themselves up to date. The virus also used a 
variety of methods to spread, but all had been used before.
Conficker also tried to prevent those who had been infected from getting help. On an infected 
machine, the user would be prevented from contacting certain security sites. As versions of the virus 
came out, new sites were added to the list. Of course, this type of thing had been done before, and 
the only new twist this time was that one of the malware researchers got a clever idea for a simple 
Web page, which would tell if you were infected with Conficker, and which version of Conficker 
you had, simply by trying to load logos from sites that were banned by the different versions.
Stuxnet
The virus that has created the latest furor is Stuxnet, so I have to mention it. Once again, though, 
it used the same technologies that have been used in the past, although in slightly different ways. 
First off, it is fairly clear (although some people still disagree) that Stuxnet was targeted at a specific 
institution. Well, that happened back in 1987. (As a side issue, Stuxnet has also created concern 
because it related to SCADA [supervisory control and data acquisition] and PLC [programmable 
logic control] systems. In fact, it was directed at a program on the ordinary, which created the 
codes for such systems, so there was nothing new here, either.)
Secondly, there was the fear that there was something new about the fact that Stuxnet (one 
version of it, anyway) hitched a ride on USB sticks. I will admit that the specific weakness Stuxnet 
used (now closed, if you have kept your Windows Updates up to date) was clever. But this is basi-
cally the same type of technology that boot sector infectors used, and BRAIN, in 1986, was a BSI.
Summary
Well, it has been 25 (or 40) years, more or less, and what a long, strange trip it has been. From my 
perspective, it has been full of interesting technologies, and some even more fascinating people. 
(Others might have experienced a bit less curiosity and a lot more frustration.)
There are some developments that you might want to watch out for. I have always said that 
the only reason we have not been in worse shape than we already are, with respect to malware, is 
that the “enemy” was a collection of iconoclastic amateurs. Well, now some of them have turned 

Twenty-Five (or Forty) Years of Malware History  ◾  275
professional, and there are even effective groups forming, instead of the bands of bickering indi-
viduals that we saw in years gone by. Malware has been regarded as not really part of security: 
merely a nuisance. Well, the danger is getting pretty real, now.
Viruses breach confidentiality and even try to break down your firewalls. Viruses have always 
infected desktop systems, but now those same systems are starting to run the servers for your enterprise.
New malware is often multipartite, and the virus writers are always finding new objects to 
infect and new places to hide. And we are also seeing increasing convergence, so that spambotnets 
will seed out a virus that will carry a remote access trojan to allow someone to set up a phishing 
Web site on your desktop machine.
The risk has been growing, slowly and steadily, for 20 years. The danger now is not something that 
you are unlikely to ever encounter personally, but one that seeks you out hundreds of times per day.
Additional Parts: Timeline
1971
A program called “Creeper” is created as an experiment to move from one machine to another 
over a network.
1977
“The Adolescence of P-1,” a novel by Thomas J. Ryan, describes a program that copies itself to 
various computers.
1980
John Shoch and Jon Hupp at Xerox PARC experiment with programs consisting of copying 
“segments” to different computers, calling the system as a whole a “worm.”
1981
First experiments with “viral” Apple DOS.
1983
Fred Cohen proposes the idea of reproductive programs in a security seminar.
1984
Cohen’s master’s thesis outlines the major forms of antiviral protection.
1986
Fred Cohen’s doctoral dissertation published.
The (c)Brain virus code contains a copyright date of 1986.
1987
A destructive virus is found on the campus of Lehigh University. The Lehigh virus never did 
spread off the campus.
The CHRISTMA exec message creates problems for IBM mainframe mail systems.
1988
First reported in February 1988, it was felt that Jerusalem had been circulating prior to 
November 1987.
The Stoned virus is released and becomes immensely successful, spawning many imitators and 
variants.
A 6 October Fidonet posting by “Mike RoChenle” announces the Modem virus, likely the 
first virus hoax.

276  ◾  Information Security Management Handbook
In October 1988, a program called MOIN exec was reported to be loose on the nets. Although 
undoubtedly inspired by CHRISTMA, the description of MOIN appears to be more consistent 
with a trojan horse program. It purported to be a type of CHAT program and to provide the user 
who ran it with an e-mail “answering machine” capability (answering mail while the user was 
away), but also allowed an outside “caller” to submit commands to be run on the user’s account.
On 3 November 1988, Robert Morris Jr. releases or loses control of his Worm, ultimately 
infecting 4,000 to 6,000 UNIX-based machines, clogging mail queues and consuming enormous 
amounts of bandwidth.
In December 1988, VMS systems on DECNet networks were hit by a worm based on a file 
called HI.COM. On VMS systems, COM files are similar to the REXX exec files and MS-DOS 
batch files, using VMS DCL source code. HI.COM used the fact that DECNet nodes had, by 
default, a standard “anonymous” account that could be used by the network and other machines 
to gain limited access to a machine. This account was able to start processes running. The process 
that HI.COM started replicated, submitted itself to other machines, informed a specific account at 
a specific site, and waited until midnight on 24 December 1988, when it began mailing Christmas 
greetings to all users.
Thus, it seemed to have similarities to both CHRISTMA exec and the Morris Worm.
1989
1989 saw an explosion of new antivirus programs and companies, leading to a series of com-
parative reviews of the products by one Robert Slade. This year also saw a lot of really bad books 
published on the subject.
In the fall of 1989, the “AIDS Information” software package was sent to medical establish-
ments and a number of other companies.
The WANK/W.COM worm of October 1989 and its successor owed most of its inspiration (if 
you can call plagiarism inspiration) to the Morris Worm and HI.COM.
In the fall of 1989, there was a large amount of media attention given to Datacrime and 
“Columbus Day” (actually different names for roughly the same virus). The promotion appeared 
to be instigated by a particular antiviral service vendor. It turned out that these viruses had far less 
distribution than was being claimed. Columbus Day thus can lay claim to being the first “media” 
virus, which obtains attention out of all proportion to its actual significance.
1990
The XA1 Christmas Tree PC virus, released in March 1990, although it contains the message 
“And still it is alive: the Christmas Tree!” owes no technical or programming detail to any of the 
network worms.
Elsevier publishes the “Computer Virus Handbook,” edited by Harold Joseph Highland, one 
of the first accurate and detailed references.
1991
The United States launches “Desert Storm,” an attack against Iraq.
Microsoft releases MS-DOS version 6, including an antiviral program universally acknowl-
edged to be terrifically mediocre.
The April edition of InfoWorld carries an April Fools joke (story) about a virus, referred to as 
AF/91, that was supposed to have helped in reducing Iraqi air defenses during the war. The story 
was actually poking fun at the recent release of Windows 3.0.
Springer-Verlag publishes Alan Solomon’s “PC Viruses,” a detailed guide to the known 
malware.

Twenty-Five (or Forty) Years of Malware History  ◾  277
1992
U.S. News and World Report publishes “Triumph without Victory,” a book about the Persian 
Gulf War. The book reports the InfoWorld AF/91.
April Fools story as fact. In 1998, another book reports the story as real, and even today many 
U.S. military people believe the story is true.
Although it was known to exist in February 1991, 2 March 1992, was the date that first made 
the majority of computer users aware of a virus. Michelangelo, a destructive variant of the earlier 
Stoned virus, triggered on 6 March. (The name, Michelangelo, was given due to the fact that 
Michelangelo Buonarroti, the Italian Renaissance artist, was born in Caprese on 6 March 1475. 
A friend of the earliest discoverer of the virus shared the same birth date.)
(As a piece of trivia, 6 March is also Ed McMahon’s birthday, leading to jokes about viral mes-
sages stating “Congratulations! Your computer may already be infected!”)
Springer-Verlag publishes David Ferbrache’s “Pathology of Computer Viruses,” one of the best 
academic texts on the topic.
1993
The Year of the Buyouts. Symantec and Central Point buy up dozens of smaller antiviral com-
panies for market share. The purchased products and technologies are generally not included in 
the subsequent programs by the large vendors. Eventually, Symantec buys Central Point.
1994
Good Times, the first of a major wave of virus hoaxes, probably starts in December 1994.
Springer-Verlag publishes “Robert Slade’s Guide to Computer Viruses.”
The title was NOT my idea.
1995
Concept, first of the Word macro viruses, is released.
1996
The second edition of “Robert Slade’s Guide to Computer Viruses” is released, and, as one 
might expect, things were pretty quiet on the virus front.
1997
Researchers take a first look at beta versions of Windows 98 and note potential vulnerabilities. 
These are later used in the Melissa virus.
1998
Chernobyl/CIH, a particularly nasty beast. Happy99 and PrettyPark are also prevalent.
1999
Melissa, first of the “fast-burner” e-mail viruses.
2000
The LoveBug goes worldwide in hours.
2001
Linux worms start to be seen.
Code Red infects 350,000 IIS servers within 9 hours.
2002
It is quiet. Too quiet.

278  ◾  Information Security Management Handbook
2003
Sobig is one of the most successful of the new breed of viruses that will eventually make up 
spambotnets.
2004
Jose Nazario writes “Defense and Detection Strategies Against Internet Worms,” the first aca-
demic review of worms as a specific class of malware.
2005
Addison-Wesley publishes Peter Szor’s “The Art of Computer Virus Research and Defense,” a 
demanding but accurate text for virus research.
2008
Conficker uses a number of previously used technologies, and, as a side effect of trying to keep 
people from getting help, allows a simple Web page to identify if a computer is infected and by 
which version.
2010
Stuxnet creates a huge furor among people who have not been paying attention to malware 
over the past 25 years.
tenworst.txt
The “how to protect yourself” piece is HELP!
A recent computer crime survey by the FBI found that almost all companies have some form 
of antivirus protection. In spite of that, viruses and malware are the largest category of computer 
crime encountered. In fact, not only is malware more than twice as large as the next category of 
computer crime, but, according to the statistics compiled for the survey, malware accounted for 
a third of the total dollar loss of all computer crime, totaling tens of billions of dollars per year in 
the United States. That means the loss is in the multiple millions of dollars per hour. Obviously, 
companies and computer users need help here.
One of the important things that Fred Cohen discovered was that a “perfect” antiviral pro-
gram is inherently impossible: either it is going to miss a lot, or it is going to warn you about a lot 
of things that aren’t viruses.
What this means is that the price of effective and safe computing is constant vigilance. You 
cannot “set and forget” malware protection, and there is on step-by-step procedure to follow for 
every malware incident. Sorry.
However, we can give you some general advice that can help reduce your risk. A lot.
Prevention and Maintenance
Educate yourself. Learn about your enemy. Study malware.
Unfortunately, in this field, you cannot rely on someone else. You have no way of knowing 
whether an “expert” is giving you valid information about viruses, unless you are educated about 
viruses yourself.
A little education and basic policies can really help. You can reduce your risk further by train-
ing your systems’ users. (As a matter of fact, in the virus arena, a company can help reduce its 
own risk by providing security training for the general public. Fewer infected machines out there 
means less copies of viruses hitting your systems.)

Twenty-Five (or Forty) Years of Malware History  ◾  279
Have some good, basic policies, like:
◾
◾Do not double-click on attachments. Do not open attachments until you have checked them 
out. You can check them by using an up-to-date scanner or by contacting the person who 
sent you the attachment, to be sure of what it is.
◾
◾When sending attachments, be really specific. Do not just reply with the same subject line, 
or a vague “Here’s the stuff you wanted.” Use a subject line that says, “Here is a WordPerfect 
document file containing the Anderson contract.” In the body of the message, tell your cor-
respondent, “Frank, this is Mary. This file is the third version of the contract with Anderson 
Corporation, as you requested on Thursday. The file is called ‘Anderson Contract 3.wpd’ 
and is 34,958 bytes long.” This gives the person on the other end some assurance that the 
message, and the file, really is from you, and is not just some ambiguous, “Hi, I’m fun! Open 
me!” virus or Trojan come-on.
◾
◾Do not blindly use popular products as a company standard. We know this point will be 
controversial, but consider it carefully. You can read MS Word documents with OpenOffice 
or other office suite packages, or even with WordViewer, which is available from Microsoft. 
Internet Explorer is more dangerous than Firefox. MS Outlook is more dangerous than 
Pegasus. MS Windows ... well, you get the picture. You do have options.
◾
◾Disable Windows Script Host. Disable ActiveX. Disable VBScript.
◾
◾Disable JavaScript. Disable cookies, although that is more for privacy than for viruses. Run 
with those dangerous technologies disabled by default. When you come across a Web site 
that requires them, ask yourself whether you really need what that site has to offer. Do not 
send HTML-formatted e-mail. Be wary of receiving HTML-formatted e-mail and use a 
mailer that informs you when you do receive such e-mail.
◾
◾Disable unnecessary services. Of course, few computer users know what services are neces-
sary these days, so corporate IT offices should take the lead in this regard. For those who 
do not have an IT office that can provide a list, Thomas Greene’s book “Computer Security: 
for the Home and Small Office” has an excellent discussion of services and how to check 
for them. Disable DCOM, unless your company has an internal application that requires it. 
(Run “dcomcnfg/disable.”) In most Windows systems that is sufficient, or close to it. With 
Windows XP, double-click “Component Services,” then “Computers,” then right-click “My 
Computer” and select “Properties.” Under the “Default Properties” tab (note: NOT “COM 
Security”) make sure the “Enable Distributed COM on this computer” box is unchecked, 
as in the illustration.
DCOM is enabled on all Windows versions by default, and disabling it is unnecessarily com-
plicated. These screen shots walk you through the process on Windows XP.

280  ◾  Information Security Management Handbook

Twenty-Five (or Forty) Years of Malware History  ◾  281
◾
◾Use more than one scanner. Have defense-in-depth. A content scanner on a firewall is con-
venient, but probably will take shortcuts. An on-access scanner is handy but must operate 
within the confines of the operating system. Do a manual scan with a different product once 
in a while, just to make sure.
You have a choice of a number of excellent antiviral scanners. Pick any two.

282  ◾  Information Security Management Handbook

Twenty-Five (or Forty) Years of Malware History  ◾  283
	
All scanners will miss some viruses and falsely report others. That is why we always recom-
mend getting more than one. Note that even the old DOS version of F-Prot manages to find 
one sample that the other scanners miss.

284  ◾  Information Security Management Handbook
	
Of course, defense-in-depth is more than using multiple scanners—it is having protection at 
each layer of your network: at desktops, file servers, e-mail servers, gateways, and each point 
of entry into your network. It is also reasonable to have more than one vendor’s product in 
this mix-such as one vendor on the desktop and a different vendor on the e-mail servers.
◾
◾Do not think you are safe: everybody is at risk. Even virus experts get caught. You can too.
How to Tell if You Are Being Attacked
Well, partly this is where the education comes in. There is no one indicator of a malware attack, 
and the old traditional symptoms (remember spyware?) are not valid anymore.
However, there is one thing that most people could do and do not check what is outbound 
from your network. We have a fortress mentality when it comes to security: the bad guys are out 
there, and we have to watch anything inbound, but we never check the wagons on the way out. 
Simple traffic anomalies can tell you interesting things about your security. Is a lot of mail heading 
out? Maybe someone is infected with a spambotnet virus. Are certain machines trying to make a 
lot of connections over the Net? Maybe some machine is infected with a worm. Egress scanning is 
an important, and neglected, detection method in the modern environment.
Containing and Removing the Infection
Step one: Pull the network plug. If your machine has a wired connection, this is simple. If your 
network has a wireless LAN, you may need to take down the access point until you can figure how 
to turn off the wireless connection on the infected machine. Modern malware is net-aware, and if 
it has a connection, it will use it. Usually, a lot.
Step two is generally deciding whether you are going to do any forensic study to try and 
find out where the beast came from. Most people do not, because forensic investigation is time-
consuming and requires specialized training. However, if you do want to look into the details, 
remember that a lot of the activity is counterintuitive.
A lot of people will immediately make a backup. Wrong move. Normal backup software destroys 
a lot of information that the forensics guys need. Best just to pull the plug and wait for them.
If you are not doing forensics, you probably just want to disinfect it.
Unfortunately, this is getting harder. Much recent malware ties itself so deeply into the sys-
tem that normal disinfection may still leave the computer unusable. In this case, yes, make that 
backup, aiming primarily at your data. You may have to blow off the computer and reinstall all 
the software, so have your data image as up to date as possible. Reinstalling and reconfiguring 
the operating system and applications are time-consuming. Reinstalling data you have not got is 
impossible.
Determining Damages and Restoring Services
Once you have disinfected a machine, check it again to make sure.
Check it with another scanner: you might want to use more than two at this stage.
Do thorough checks on all machines on the same network as the infected machine. Check for 
unusual levels of traffic on your network.

Twenty-Five (or Forty) Years of Malware History  ◾  285
Check the registry for entries with the name of the infected file, and also for entries in the 
same directory. Viruses frequently leave inactive copies around, ready to be started the next time 
you reboot your computer.
Check the hosts file in the \Windows\system32\drivers\etc directory.
Many viruses make changes to the file to block or redirect attempts to contact vendors for help.
Postmortem
In the midst of the fuss, take notes. That way you will be able to sit down calmly after the frenzy 
is over and learn something from the attack. Do you need different protection? Do you need 
new policies or training for your users? What caused the greatest problem, and what can be done 
about it?


DOMAIN
5
CRYPTOGRAPHY
Cryptographic Concepts, 
Methodologies, and Practices


289
Chapter 19
Format Preserving Encryption
Ralph Spencer Poore
Introduction
When an application encrypts data using a standard block cipher (e.g., TDES, IDEA, or 
AES),* or all but the special class of algorithms know as format preserving encryption (FPE), 
the process changes the format to that of a binary string, usually of fixed length. If a datum 
were a social security account number (SSAN), e.g., with a format that is NNN-NN-NNNN, 
an AES 128-bit electronic codebook mode (ECB) encryption might look (in hexadecimal) like 
3E07D4719AF32558BC02411F931E51846. If a preexisting database had a template for the 
SSAN (3 digits, a hyphen, 2 digits, a hyphen, 4 digits) taking up 12 bytes of storage, then the 
encrypted value (32-hexadecimal digits or 16 ASCII characters) would be wrong in length and 
type. This poses a challenge for legacy systems where a complete redesign of data structures is 
not a business’ first choice. In some applications, the data must pass through intervening service 
providers who have standardized on a message format that does not allow changes. In both of 
these cases, to protect the data through encryption requires a mechanism that does not violate the 
format requirements. FPE becomes the obvious choice. However, not all encryption techniques 
that preserve formatting are equally secure.
In Figure 19.1, an overview of the generic FPE process is shown. The plaintext datum and the 
ciphertext datum are identical in length and data type and may be identical in all aspects of format 
depending on the implementation. The key and (in some implementations) additional variable 
input are also used in the cipher process.
Conceptually, it is a reversible mapping of a plaintext datum to a ciphertext datum of the same 
format. Because, in theory, the cryptographic algorithm used in the cipher process could be any 
keyed, reversible algorithm, an almost limitless number of schemes are possible that would preserve 
format. However, determining the security afforded by a given scheme is a Herculean (and for some, 
* Triple Data Encryption Standard (TDES): Based on the Data Encryption Standard (DES), this is the applica-
tion of DES three times with one or more keys in an encrypt, decrypt, encrypt sequence; International Data 
Encryption Algorithm (IDEA) is a block cipher designed by James Massey of ETH Zurich and Xuejia Lai; 
Advance Encryption Standard (AES): http://csrc.nist.gov/publications/fips/fips197/fips-197.pdf.

290  ◾  Information Security Management Handbook
a Sisyphean!) task. For information security practitioners who are not crypto-mathematicians, 
relying on published standards and well-vetted implementations is essential.
The Security Issues
To understand the security issues, consider the protection of a primary account number (PAN). 
Most of these are now standardized as 16 numeric digits in the format depicted in Figure 19.2.
The first six digits form the bank identification number (BIN), which is composed of the major 
industry identifier (MII) and the issuer identification number (IIN). The next 5–12 digits (usu-
ally 9) is an account number (AC), and the last digit is a check digit based on the Luhn formula 
(LCD). The international standard ISO 7812 Identification Cards—Identification of Issuers (ISO/
IEC, 2007) defines this in detail.
If the only formatting requirement were that the encrypted result must be 16 numeric dig-
its, a direct cryptographic transformation would have 1016 possible inputs and 1016 possible out-
puts. However, as shown in Figure 19.2, the formatting rules are potentially more restrictive. For 
example, the BIN may have to remain cleartext to permit routing through intermediate networks. 
And the LCD may have to remain valid to prevent rejection by intermediate networks. This 
would result in only 109 possible inputs and therefore outputs. 1,000,000,000 possibilities is a 
tiny fraction of the cryptographic key space for AES 128, which is 2128 > 1038, or 29 orders of 
magnitude above the billion possible outputs. An SSAN is another example that has, at best, the 
same 1 billion possibilities. Other sensitive data, e.g., authentication data, which includes personal 
Plaintext datum
Cipher process
Key
Variable
input (e.g.,
tweak, or
IV)
Ciphertext datum
Figure 19.1  Overview of an FPE.
MII
BIN
IIN
PAN
LCD
AC
b
b
b
b
b
b
a
a
a
5–12 Digits
a
a
a
a
a
a
c
Figure 19.2  PAN.

Format Preserving Encryption  ◾  291
identification numbers, card validation codes, and expiration dates, may have only three or four 
digits. Preserving format could so limit the input-to-output mapping that a cryptanalyst would no 
longer face the more daunting task of key space exhaustion.
Sample Implementation
This problem of FPE has received many years of analysis. Lead researchers have included Mihir 
Bellare, John Black, Michael Brightwell, Moses Liskov, Michael Luby, Stefan Lucks, John Kelsey, 
Patarin, Charles Rackoff, Thomas Ristenpart, Ronald L. Rivest, Phillip Rogaway, Bruce Schneier, 
Harry E. Smith, Terence Spies, Till Stegers, and David Wagner. The Bibliography at the end of 
this chapter provides references used in the development of this chapter and is an excellent source 
of technical details for those who wish to have a more in-depth understanding.
The theoretical basis for some FPE is well described (if you are a mathematician) in the fol-
lowing writings:
◾
◾Ciphers with Arbitrary Finite Domains by Black and Rogaway1
◾
◾Format-Preserving Encryption by Bellare et al.2
◾
◾The FFX Mode of Operation for Format-Preserving Encryption by Bellare et al.3
◾
◾Format-Preserving Encryption: A Survey and Assessment (draft) by Rogaway4
Two broader treatments directly related to the Payment Card Industry (PCI) are
◾
◾FPE for the PCI DSS and VISA Best Practices—Data Field Encryption5
◾
◾Tokenization and Other Methods of Security for Cardholder Data6
The FFX mode is an enhancement of the Feistel Finite Set Encryption Mode (FFSEM)7 cur-
rently under consideration by NIST as an approved encryption mode for government use. FFSEM 
is a submode of FFX. Formal proofs are based on work by Luby–Rackoff,8 Black–Rogaway,1 and 
Patarin.9 Additional work in this area by Schneier and Kelsey10 and by Lucks11 document block-
cipher design related to Feistel networks. The body of work supporting the mathematical basis for 
the FFX mode spans more than two decades.
The mathematical basis for FFX relates to two important cryptographic criteria:
	
1.	The extent to which the output is indistinguishable from a random number generator.
	
2.	The extent to which knowledge of previous plaintext/ciphertext pairs gives no knowledge of 
either ciphertext from another plaintext or plaintext from another ciphertext.
FFX is based on AES, which is a known, good deterministic random number generator. The 
evaluation of its outputs utilizing statistical tests does not provide any means by which to compu-
tationally distinguish it from truly random sources.12 This remains true for FFX over the domain 
used by the input and output sets (e.g., digits).
Another approach to format preservation was described in Using Datatype-Preserving Encryption 
to Enhance Data Warehouse Security by Brightwell and Smith.13 This uses indexing and shuffling 
based on a symmetric key and both cipher-feedback and data-feedback mechanisms. The result is 
a complex mapping within the domain of the datum’s format, e.g., digits, alphabetic characters, or 
printable ASCII. It is not based on the same mathematical foundation as FFSEM or FFX. As such, 

292  ◾  Information Security Management Handbook
the mathematical proofs of security that apply to Feistel-based FPE may not apply to datatype-
preserving encryption (DPE).
Similar to FFX, a generic format-preserving symmetric encryption algorithm designated BPS 
by Brier et al.14 can cipher short or long strings of characters from any given set. Unlike DPE, this 
algorithm can claim strong security proofs similar to those of FFX.
Residual Risk
The best cryptographic scheme ensures that, given a known plaintext/ciphertext pair, no crypt-
analytic method exists that will transform an unknown ciphertext into its associated plaintext 
more efficiently than key-space exhaustion. However, systems that use cryptography rarely pro-
tect against the possibility of a perpetrator creating chosen plaintext/ciphertext pairs. Unless the 
perpetrator’s ability to do this is limited by the number of such pairs she is permitted to create, 
a data-space exhaustion attack remains a risk. In the case of a four-digit PIN, e.g., only 0000 
through 9999 are possible values, i.e., 10,000 pairs would produce a dictionary that is 100 per-
cent effective. This is why a PIN in financial services applications is, by standard, encrypted in a 
PIN block that includes the PAN. The resulting block has over 1020 possible outputs based on an 
exhaustion of potential inputs. This remains substantially lower than the number of attempts for 
key-space exhaustion (i.e., two-key TDES has a key space of 2112 > 1033), but is an improvement 
by many orders of magnitude.
The exhaustion of the datum-space is a risk independent of the cryptographic system used. 
Organizations must implement other controls, e.g., limiting the number of incorrect attempts or 
introducing time delays that make such attacks require exponential time, to address this.
Conclusion
FPE provides a means for addressing the need to protect sensitive data elements without adversely 
impacting databases, message formats, and format-sensitive applications. Care is needed in select-
ing an FPE that provides the level of cryptographic security required. Methods in addition to 
cryptography remain essential to address residual risks.
References
	
1.	Black, J. and Rogaway, P. Ciphers with Arbitrary Finite Domains. Topics in Cryptology—CT-RSA 2002. 
LNCS 2271, Springer-Verlag, 2002, 114–130.
	
2.	Bellare, M., Ristenpart, T., Rogaway, P., and Stegers, T. Format-preserving encryption, Selected Areas in 
Cryptography (SAC 2009). LNCS 5867, Springer, 2009, 295–312.
	
3.	Bellare, M., Rogaway, P., and Spies, T. The FFX mode of operation for format-preserving encryption, 
2010. http://csrc.nist.gov/groups/ST/toolkit/BCM/documents/proposedmodes/ffx/ffx-spec.pdf.
	
4.	Rogaway, P. Format-preserving encryption: A survey and assessment (draft), 2009.
	
5.	Poore, R. S. Format Preserving Encryption for the PCI DSS and VISA Best Practices—Data Field 
Encryption. Cryptographic Assurance Services, LLC, December 2009.
	
6.	Stapleton, J. and Poore, R. S. Tokenization and other methods of security for cardholder data. In 
Proceedings of Information Security Journal: A Global Perspective, 91–99, 2011.
	
7.	Spies, T. Feistel finite set encryption mode. http://csrc.nist.gov/groups/ST/toolkit/BCM/documents/
proposedmodes/ffsem/ffsem-spec.pdf, 2008.

Format Preserving Encryption  ◾  293
	
8.	Luby, M. and Rackoff, C. How to construct pseudo-random permutations from pseudo-random func-
tions. In Advances in Cryptology—CRYPTO 85 (Santa Barbara, CA), LNCS 218, H. C. Williams, Ed. 
Springer-Verlag New York, New York, p. 447, 1986.
	
9.	Patarin, J. Luby-Rackoff: 7 rounds are enough for 2n(1‐ε) security. Advances in Cryptology—CRYPTO 
2003, LNCS 2729, 513–529, 2003.
	 10.	Schneier, B. and Kelsey, J. Unbalanced Feistel networks and block-cipher design. Fast Software Encryption, 
Third International Workshop Proceedings, February 1996, Springer-Verlag, 1996, pp. 121–144.
	 11.	Lucks, S. Faster Luby-Rackoff ciphers. Fast Software Encryption (FSE 1996), LNCS 1039, Springer, 
Heidelberg, pp. 180–203, 1996.
	 12.	Soto, J., Jr. NIST IR 6390—Randomness testing of the advanced encryption standard candidate algo-
rithms. National Institute of Standards and Technology, Gaithersburg, MD, September 1999. http://
csrc.nist.gov/groups/ST/toolkit/rng/documents/AES-REPORT2.doc.
	 13.	Brightwell, M. and Smith, H. E. Using datatype-preserving encryption to enhance data warehouse 
security. 20th NISSC Proceedings, Baltimore, MD, 1997.
	 14.	Brier, E., Peyrin, T., and Stern, J. BPS: A format-preserving encryption proposal. http://csrc.nist.gov/
groups/ST/toolkit/BCM/documents/proposedmodes/bps/bps-spec.pdf.
	 15.	Dworkin, M. Recommendation for block cipher modes of operation: Methods and techniques. NIST 
Special Publication 800-38A. NIST, Washington, DC, 2001.
	 16.	Liskov, M., Rivest, R. L., and Wagner, D. Tweakable block ciphers, Advances in Cryptology—CRYPTO 
2002. LNCS 2442, Springer, 2002, 31–46.
	 17.	Morris, B., Rogaway, P., and Stegers, T. How to encipher messages on a small domain deterministic 
encryption and the Thorp shuffle. Advances in Cryptology—CRYPTO 2009. LNCS 5677, Springer, 
2009, 286–302.
	 18.	Schadd, J. Use of the advanced encryption standard (AES) encryption algorithm in cryptographic mes-
sage syntax (CMS). RFC 3565. The Internet Society, 2003. http://tools.ietf.org/html/rfc3565.
	 19.	Stapleton, J. and Poore, R. S. Registry of approved cryptographic resources for financial services industry 
standard—Registry number: 00002—Advanced Encryption Standard (AES). ANSI X9 SD-34-2009.
	 20.	Stapleton, J. and Poore, R. S. Announcing the advanced encryption standard (AES). Federal Information 
Processing Standards (FIPS) Publication 197. U.S. DoC/NIST, 2001.
	 21.	Stapleton, J. and Poore, R. S. Information technology—Security techniques—Encryption algorithms—
Part 3: Block ciphers. ISO/IEC 18033-3:2005.
	 22.	Stapleton, J. and Poore, R. S. VISA best practices—Data field encryption. Version 1.0 (October 5, 
2009).


295
Chapter 20
Elliptic Curve Cryptosystems
Jeff Stapleton
Cryptography Overview
Cryptography, from the Greek words “kryptos” and “graphin” for hidden and secret writing, has 
a broader meaning for protecting electronic information during transmission and in storage. The 
birth of writing, depending on one’s perspectives of ideographs, mnemonic symbols, or phonetic 
writing, seems to be somewhere between 8000 and 6000 years old. Cryptography, by comparison, 
is a 4000-year-old technology attributed to an Egyptian scribe using unusual hieroglyphics carved 
about 1900 BC in the main tomb chamber of the nobleman Khnumhotep II. One of the more 
well-known ancient methods is the Caesar Cipher based on the Grecian writer Polybius’ signaling 
system used by Julius Cesar during the Gallic Wars. Another well-known historical method is the 
Jefferson Wheel based on the French Vigenére cipher used by the U.S. Army in World War I.1 
World War II ushered in the modern cryptography era, notably with the declassification and pub-
lication of Claude Shannon’s paper “The Communication Theory of Secrecy Systems,” published 
in the Bell System Technical Journal in 1949.2
Information security afforded by modern cryptography includes data confidentiality, integrity, 
authenticity, nonrepudiation, and reliability.3 Modern cryptography is based on mathematically 
“hard” problems translated into algorithms or schemes. Algorithms are the basic building blocks 
with a precise set of rules having specific inputs and outputs. Schemes are more general in nature, 
characteristically using one or more algorithms in an orderly fashion to achieve a particular infor-
mation security goal such as data encryption, digital signature, or establishing cryptographic keys. 
Protocols are implementations of a particular scheme incorporating algorithms, configuration 
parameters, inputs, and outputs.
For example, one such “hard” problem is factorization for the RSA public key schemes intro-
duced by its inventors, Rivest et al. in 1978.4 The RSA modulus is the product of two random 
prime numbers, which is difficult to factor for very large numbers. Another difficult problem is 
discrete logarithms (DLs), which are group theory analogs of ordinary logarithms. Recall that the 
log of a number is the power to which a base number must be raised to produce that number, e.g., 
the log of 343 is 3 for base 7 because 73 = 343. The first DL scheme was the key agreement proto-
col proposed by Diffie and Hellman in 1976.5 ElGamal described another DL scheme for digital 

296  ◾  Information Security Management Handbook
signature in 1984. Another DL scheme is the Digital Signature Algorithm (DSA) proposed by the 
National Institute of Standards and Technology (NIST) in 1991 and published as FIPS PUB 186 
in 1994. All of these DL schemes can be described in the abstract setting of a finite cyclic group, 
including elliptic curve groups, which provide the foundation for elliptic curve cryptosystems 
(ECCs).6
Elliptic Curve Cryptography
The study of elliptic curves (which is not an ellipse) by algebraists and number theorists dates back 
to the mid-nineteenth century. Hence, elliptic curves have a rich history, having been studied by 
mathematicians for over 100 years with an extensive literature describing their elegant properties. 
They have been used to solve a diverse range of problems, such as Lenstra’s elliptic curve factoriza-
tion method (ECM) and including proving Fermat’s Last Theorem.6
An elliptic curve is a set of points specified by two coefficients a and b, which are elements of a 
finite field Fq of the size prime number q, e.g., an equation of the form y2 = x3 + ax + b.7
Elliptic curve systems as applied to ElGamal protocols were first proposed in 1985 indepen-
dently by Koblitz8 from the University of Washington, and Miller9 then at IBM. The security 
of the cryptosystems using elliptic curves hinges on the intractability of the DL problem in the 
algebraic system (another “hard” problem). Unlike the case of the DL problem in finite fields, or 
the problem of factoring integers, there is no subexponential-time algorithm known for the elliptic 
curve DL problem. The best algorithm known to date takes fully exponential time.
ECC Schemes
Digital Signatures
Digital signatures in lieu of written signatures are computed using a set of rule and parameters 
that allow the identity of the signatory and the integrity of the signed data to be verified by a 
relying party. A cryptographic private key is to generate a digital signature, the digital signature 
is provided to the relying party along with the signed data, and the corresponding cryptographic 
public key (not the same as the private key) is used to verify the digital signature. Public keys 
may be known and used by anyone; however, only the signer posses the associated private key. 
Anyone can verify the signature by employing the signatory’s public key. Only the user that pos-
sesses the private key can perform signature generation. Digital signatures may be used for stored 
or transmitted data.10
Federal Information Processing Standards Publication (FIPS PUB) 186-3 defines three 
approved methods for digital signature generation and verification. (1) DSA is specified in FIPS 
PUB 186-3, which includes criteria for the generation of domain parameters, for the generation of 
public and private key pairs, and for the generation and verification of digital signatures. (2) The 
RSA DSA is specified in American National Standard X9.31 and Public Key Cryptography 
Standard (PKCS) #1. FIPS 186-3 approves the use of implementations of either or both of 
these standards, but specifies additional requirements. (3) The Elliptic Curve Digital Signature 
Algorithm (ECDSA) is specified in ANS X9.62. FIPS 186-3 approves the use of ECDSA, but 
specifies additional requirements.10
The ECDSA X9.62 standard provides methods and criteria for the generation of public and 
private keys that are required by the ECDSA and the procedural controls required for the secure 

Elliptic Curve Cryptosystems  ◾  297
use of the algorithm with these keys. ECDSA is the elliptic curve analog of the DSA defined in 
FIPS PUB 186.10 The ECDSA standard also provides methods and criteria for the generation of 
elliptic curve domain parameters that are required by the ECDSA and the procedural controls 
required for the secure use of the algorithm with these domain parameters.7
Key Establishment
Key establishment schemes are cryptographic methods that establish keying data suitable for sub-
sequent cryptographic use by cryptographic schemes to its legitimate users. Key agreement schemes 
and key transport schemes are types of key establishment schemes. A key transport scheme is a key 
establishment scheme in which the keying data established is determined entirely by one entity. 
A key agreement scheme is a key establishment scheme in which the keying data established is a 
function of contributions provided by both entities in such a way that neither party can predeter-
mine the value of the keying data.11
X9.63 specifies asymmetric key establishment schemes. The operation of each of the schemes 
employs arithmetic operations in the group of points on an elliptic curve defined over a finite field. 
The standard defines both key agreement schemes and key transport schemes. Common to all 
schemes, the elliptic curve domain parameters are previously known by each participating entity. 
The public key of at least one entity is exchanged with the other, although sometimes both entities 
exchange public keys. As an additional security precaution, some of the schemes use ephemeral 
keys, which are short-lived asymmetric keys whose lifetime is limited to the actual key establish-
ment process. Hence, the standard distinguishes between “static” longtime keys where the public 
key is typically encapsulated in an X.509 certificate and ephemeral keys. The standard also offers 
the elliptical curve analog of the Diffie–Hellman key agreement method.
The eleven (11) key agreement schemes provided in X9.62 include the following:
◾
◾Ephemeral Unified Model Scheme
◾
◾1-Pass Diffie–Hellman Scheme
◾
◾Static Unified Model Scheme
◾
◾Combined Unified Model with Key Confirmation Scheme
◾
◾1-Pass Unified Model Scheme
◾
◾Full Unified Model Scheme
◾
◾Full Unified Model with Key Confirmation Scheme
◾
◾Station-to-Station Scheme
◾
◾1-Pass MQV Scheme
◾
◾Full MQV Scheme
◾
◾Full MQV with Key Confirmation Scheme
The Menezes–Qu–Vanstone (MQV) schemes incorporate both static and ephemeral asym-
metric keys.
The two (2) key transport schemes provided in X9.62 include the following:
◾
◾1-Pass Transport Scheme
◾
◾3-Pass Transport Scheme
Each scheme has slightly different characteristics that can be applied depending on the application 
requirements and environmental restrictions such as data size considerations, the number of messages 

298  ◾  Information Security Management Handbook
exchanges, and computational restrictions. The standard also provides background on finite fields, 
elliptic curve and point compression, data conversion, cryptographic primitives common to the various 
key establishment schemes including number-theory algorithms, security considerations, and examples.
Identity-Based Encryption
Identity-based cryptography is an asymmetric method of employing a relatively unique yet pub-
licly available data element such as an electronic mail (e-mail) address or an Internet Protocol 
(IP) address as the public key and securely deriving the corresponding private key. Although the 
concept had been theorized as early as 1984 by Adi Shamir, one of the first practical implementa-
tions for identity-based encryption (IBE) was finally devised by Boneh and Franklin in 2001.12,13
IBE is based on bilinear maps, which is a relationship between three groups such that any two 
elements, one from the first group and another from the second group, map to a third group. This 
allows a public key generator to determine a private key for a chosen public key such that a message 
encrypted with the public key can only be decrypted using the derived private key. The chosen 
public key must be an assigned identifier unique to the key pair owner.
RFC 5409 defines the way to use the Boneh–Franklin and Boneh–Boyen IBE public-key algo-
rithms in the Cryptographic Message Syntax (CMS). IBE is a public-key technology for encrypt-
ing content-encryption keys (CEK) implemented within the framework of the CMS using the 
recipient’s e-mail address. The sender can use the recipient’s public “email” key to encrypt a mes-
sage, a trusted intermediary party can generate the private key for the public “email” key, and the 
recipient can decrypt the message using the derived private key.
IBE can avoid the complexity of requesting, distributing, verifying, and revoking public key 
certificates by using publicly managed information such as e-mail or IP addresses.
Implicit Certificates
An implicit certificate scheme differs from a traditional certificate scheme by removing the explicit 
inclusion of a public key and a trusted third-party signature on that key and associated identity 
with the notion just a public-key reconstruction value. Traditional public key certificates are cre-
ated by a trusted third-party certificate authority (CA). The CA signature on the certificate binds 
the subject’s identity to the subject’s public key. X.509 certificates range in size from 1100 bytes for 
a 160-bit ECC public key to 1650 bytes for a 2048-bit RSA public key.14
An ECC implicit certificate consists of two elements, the subject’s identity value and public key 
reconstruction data, issued from a CA. The subject’s public key can be reconstructed by a relying 
party based on the subject’s identity value, the reconstruction data, and the CA public key. The subject 
proves its identity with a relying party by engaging in an action that requires the action of the subject’s 
private key. The benefit is that the implicit certificate is a third of an X.509 certificate. Thus, an 1100 
byte X.509 certificate for a 160-bit ECC public key is reduced to a 376 byte implicit certificate.
Summary
Cryptography is a 4000-year-old technology that has recently been enriched in the past 25 years 
by elliptic curve cryptography (ECC) based on 100 years of mathematical research. ECC offers 
digital signature, key management schemes, IBE, and implicit certificates. Its relative cryptogra-
phy strength for smaller key sizes makes it ideal for less powerful systems, narrower bandwidth, 

Elliptic Curve Cryptosystems  ◾  299
and storage constraints. Moore’s law of doubling the number of transistors on an integrated circuit 
every 2 years has continued to increase computing power and consequently pushed the need for 
stronger and larger cryptographic keys. Even the National Security Agency (NSA) has recognized 
its importance as its Suite B cryptography includes ECDSA, Ephemeral Unified Model Scheme, 
and 1-Pass Diffie–Hellman Scheme (ECHD).
References
	
1.	Kahn, D. The Code Breakers: The Story of Secret Writing. Macmillan Publishing Company, New York, 
ISBN 0-02-560460-0, 1967.
	
2.	Schneier, B. Applied Cryptography, Second Edition: Protocols, Algorithms, and Source Code in C. Wiley, 
New York, ISBN 0-471-12845-7, 1995.
	
3.	Tipton, H. F. and Nozaki, M. K. Information Security Management Handbook, Sixth Edition, vol. 4. 
Auerbach, New York, ISBN 978-1-4398-1902-9, 2010.
	
4.	Rivest, R., Shamir, A., and Adleman, L. A method for obtaining digital signatures and public key cryp-
tosystems. Communications of the ACM 21(2): 120–126, 1978.
	
5.	Diffie, W. and Hellman, M. E. New directions in cryptography. IEEE Transactions on Information 
Theory 22(6): 644–654, 1976.
	
6.	Hankerson, D., Menezes, A., and Vanstone, S. Guide to Elliptic Curve Cryptography. Springer, New 
York, ISBN 0-387-95273-X, 2004.
	
7.	American National Standard X9.62-2005, Public key cryptography for the financial services industry—
The elliptic curve digital signature algorithm (ECDSA).
	
8.	Koblitz, N. Elliptic curve cryptosystems. Mathematics of Computation 48: 203–209, 1987.
	
9.	Miller, V. Use of elliptic curves in cryptography, Advances in Cryptology—CRYPTO 85 (Santa Barbara, 
CA), LNCS 218, 417–426, 1985.
	 10.	Federal Information Processing Standards Publication (FIPS PUB) 186-3, Digital signature standard 
(DSS), National Institute of Standards and Technology, Information Technology Laboratory, June 
2009.
	 11.	American National Standard X9.63-2001, Public key cryptography for the financial services industry—
Key agreement and key transport using elliptic curve cryptography.
	 12.	Shamir, A. Identity-based cryptosystems and signature schemes. Advances in Cryptology: Proceedings of 
CRYPTO 84. LNCS 7: 47–53, 1984.
	 13.	Dan, B. and Matt, F. Identity-based encryption from the Weil pairing. In Advances in Cryptology—
CRYPTO 2001, LNCS 2139/2001. Springer, pp. 213–229, 2001.
	 14.	American National Standard X9.123-draft, Elliptic curve Qu-Vanstone implicit certificates.
	 15.	Menezes, A. J., Qu, M., and Vanstone, S. A. Some new key agreement [MQV] protocols providing 
implicit authentication. Workshop record. 2nd Workshop on Selected Areas in Cryptography (SAC ’95), 
Ottawa, ON, May 18–19, 1995.
	 16.	Law, L., Menezes, A., Qu, M., Solinas, J., and Vanstone, S. An efficient protocol for authenticated key 
agreement [MQV]. Technical report CORR 98-05, Department of Combinatorics & Optimization, 
University of Waterloo, March 1998.
	 17.	Internet Engineering Task Force (IETF). Using the Boneh–Franklin and Boneh–Boyen Identity-Based 
Encryption Algorithms with the Cryptographic Message Syntax (CMS). RFC 5409, 2009.


301
Chapter 21
Pirating the Ultimate Killer 
App: Hacking Military 
Unmanned Aerial Vehicles
Sean P. McBride
Introduction
In late 2008, a U.S. Army commander in Iraq planned and ordered a combat operation based off 
intelligence that suggested the possible location of a known Shiite militant.1 To the assigned com-
bat patrol, this action was a seemingly typical combat operation. As on most other days, the sol-
diers planned and rehearsed how they would storm the target location based on maps and digital 
imagery intercepted from Predator drones. The patrol traveled to the suspected location, stormed 
the building, and neutralized the target without significant resistance. After the soldiers subdued, 
disarmed, and tied up the insurgent, they searched his person and immediate surroundings for 
anything that could possibly yield actionable intelligence for future combat operations. Among 
other things, the soldiers found and cataloged a laptop computer.
The discovery of an enemy combatant’s laptop computer can often be extremely useful for 
coalition forces. Much like domestic police, the U.S. Army has trained experts in digital forensics 
who are able to extract actionable intelligence from laptops and other captured enemy electron-
ics. Such actionable intelligence can include documents and digital communications between 
insurgent cells, which provides commanders and intelligence officers information on enemy 
personnel, weapons, and operational intent. When the Army digital forensics experts analyzed 
this laptop, they likely found many of these things. However, they also found something seem-
ingly impossible: files containing the very Predator drone video feeds used to plan missions and 
assaults against insurgent forces. In the following months, other coalition commanders in Iraq 
and Afghanistan discovered other laptops containing similar collections of drone footage, dem-
onstrating that the Predator possessed a serious vulnerability.
Approximately 1 year after the Department of Defense (DOD) learned that enemy insurgents 
possessed the ability to intercept drone footage, the Wall Street Journal published a front-page 

302  ◾  Information Security Management Handbook
tell-all expose based on a series of anonymous military tips. To the eyes of the media and the pub-
lic, this story raised grave concerns about military information security (InfoSec) policy, particu-
larly involving unmanned aerial vehicles (UAVs) like the Predator. Media reports that the Predator 
drone transmitted real-time reconnaissance footage over an unencrypted satellite data link made 
the Pentagon appear foolish and short-sighted. With only a PC, a small satellite receiver, and a 
$26 piece of software called SkyGrabber, the enemy gained the MacGyver-like ability to access the 
exact same footage as coalition commanders.3 Watching the breaking news (perhaps on a satellite 
TV receiver), the viewers likely wondered how a military reconnaissance drone could possibly pos-
sess less encryption than Direct T.V.
This chapter seeks to examine the narrative of the Predator project to determine how the 
Pentagon allowed this crucial InfoSec vulnerability to develop, how insurgent forces learned to 
exploit this vulnerability, and how the Pentagon has responded. To understand the nature of 
this vulnerability, this chapter will examine how drone pilots near Las Vegas launch missiles at 
insurgents located thousands of miles away. This narrative will follow the Predator drone through 
design, deployment to the Balkans, to destructive use in Iraq, Afghanistan, and Pakistan. Next, 
this chapter will analyze the hardware and software that allowed enemy forces to intercept Predator 
drone feeds, including the theories for how insurgent cells received their equipment and training. 
By examining these portions of the Predator narrative, this chapter will then analyze the underly-
ing security decisions that led to the 2008 Predator “hack” in terms of InfoSec threat analysis and 
risk management.
Development of UAVs
The wars of the future will not be fought on the battlefield or at sea. They will be 
fought in space, or possibly on top of a very tall mountain. In either case, most of the 
actual fighting will be done by small robots. And as you go forth today remember 
always your duty is clear: To build and maintain those robots.
—The Simpsons4
Despite recent attention by the media and military theorists, UAV technology dates back to 
1896, when Dr. Samuel Pierpoint Langley launched the first unmanned aircraft over the Potomac 
River.5 Since this early date, UAVs have developed more or less alongside their manned counter-
parts. However, due to the elimination of risk to manned pilots, UAVs became associated with the 
most dull, dirty, and dangerous of missions. The earliest models of UAVs were the so-called “aerial 
torpedoes,” flying bombs designed to explode on impact. Although these projects were ultimately 
scrapped before being fielded during WWI, they laid the technical groundwork for the cruise 
missile platform, including the infamous German Vergeltungswaffe used extensively in the London 
Blitz. By WWII, B-movie actor Lee Dugmore Denny, inspired by his love of radio-controlled 
hobby aircraft, evangelized a new dangerous mission for UAVs: expendable aerial target drones 
used to train American pilots in mock dogfights.5
As improved communication technology allowed for a more reliable data link between the 
UAV and the remote operator, military theorists began to envision UAVs as the ideal platform 
for high-risk reconnaissance missions. However, many leaders within the defense establishment 
strongly resisted the idea that UAVs could replace small manned reconnaissance aircraft.6 The 
strongest resistance to the operational use of UAVs often came from pilots themselves, who 

Pirating the Ultimate Killer App: Hacking Military Unmanned Aerial Vehicles  ◾  303
considered UAVs a threat to manned flight hours and benefits such as flight pay. Following the 
creation of the Air Force as a separate military branch, these pilots gained the decision-making 
authority to effectively sideline the development and use of UAV technologies. The exception to 
this was the BQM-34 Frisbee, which successfully flew more than 34,000 clandestine surveillance 
missions over Cambodia and Laos, due to political restrictions over manned flight in those areas.5
Despite this aircraft’s tremendous track record, the Air Force terminated the Frisbee’s use as a 
reconnaissance platform following the end of conflict in Vietnam, and further American develop-
ment in unmanned aerial technologies languished.
In contrast to the U.S. Air Force, the armed forces of the newly created state of Israel were 
quite willing to experiment with new and untested military technologies. Due to Israel’s severe 
sense of military insecurity brought about by close proximity to hostile neighbors, Israeli ground 
commanders demanded a technology that would allow effective “over-the-horizon” reconnais-
sance.6 Drawing from the lessons learned of the BQM-34 Frisbee’s operations in Vietnam, Israeli 
engineers created the Mastiff, a 13′9″ wingspan UAV built out of fiberglass and equipped with TV 
cameras and infrared sensors to provide 360° surveillance.6 Over the next few years, the Mastiff 
demonstrated the tremendous capabilities of unmanned aircraft, allowing the Israeli Air Force 
to spoof Egyptian air defenses into wasting their surface to air missiles prior to launching Israeli 
fighter-bombers during the Yom Kippur War,6 and enabling Israel to eliminate all radar systems 
in the Bekaa Valley in Lebanon, without losing a single pilot.6
Development of the Predator
The elimination of pilot life support systems and control interfaces allows for smaller, 
simpler aircraft [that] can be placed in flight ready storage for years, eliminating con-
sumables, maintenance, and personnel requirements.6
—Rich Alldredge
Boeing Program Director
Due to Israel’s successful record at employing UAV technology during the Yom Kippur War, 
the U.S. military’s perception of UAVs began to shift. The excellent combat record of the Israeli 
Mastiff demonstrated that UAVs offer force projection without risk to human pilots, allowing the 
Air Force leaders to “breathe easier when making a combat decision.” 6 Furthermore, UAVs offered 
far more economical force projection than manned aircraft, which provided unmanned develop-
ment considerable support in the austere post-Cold War era.7 Due to these factors, the U.S. mili-
tary and the Central Intelligence Agency (CIA) began to fund Abraham Karem, a former chief 
aircraft designer of the Israeli Air Force turned U.S. citizen, to create a new UAV for the United 
States. His creation was the Predator, a prototype UAV (officially named the Gnat 750) that incor-
porated many of the lessons of the Israeli UAV program.5
After General Atomics won the contract to develop and manufacture Abraham Karem’s prototype 
in 1994, the testing and fielding of the Predator proceeded extremely quickly. Within a year, the 
Predators took part in the 1995 Roving Sands exercise, impressing the Air Force and Army leaders 
as a capable reconnaissance platform. Within 3 months of Roving Sands, the Air Force formed and 
trained its first Predator squadron: the 11th Reconnaissance Squadron. By July 1995, the pilots and 
UAVs of this squadron were deployed to the Balkans to provide aerial reconnaissance support for 
NATO operations.6 In total, this meant that the period of time from the awarding of the Predator 

304  ◾  Information Security Management Handbook
contract to its first use in combat was around 2 years: a grueling development timeline that led to 
numerous technical and training shortcomings. During operations in Bosnia, 19 of 68 deployed 
Predators were lost, mostly due to poor weather conditions “including visible moisture such as rain, 
snow, ice, frost or fog” and operator error associated with the loss of “situational awareness that 
a normal pilot would have of where the ground is and where the attitude of this aircraft is.” 6 Despite 
these criticisms, the Predator proved highly capable of providing battlefield intelligence, earning praise 
from the Congress as one of the major military success stories of FY1996.5 Furthermore, the high loss 
rate of UAVs attracted little media attention relative to the shooting down of Captain Scott O’Grady, 
leading Major General Kenneth Israel to note that “when an F-16 pilot … was shot down, it was a 
crisis, but when a $2 million Predator UAV was shot down, it was a curiosity. Who is going to tell a 
parent that their child is not worth $2 million?” 7
Based on these successes, the Air Force dramatically increased support for UAVs. In addition 
to beginning development on newer unmanned aircraft (including the Global Hawk and the 
Reaper), the Air Force began a substantial upgrade program to install a larger turbocharged engine 
and deicing system to make the Predators more resilient in adverse weather conditions. While 
the Air Force undertook to improve the Predator as a reconnaissance platform, the CIA began 
development of a new offensive variant of the Predator that could be used to remotely fire muni-
tions at enemy targets. Due to increased intelligence chatter, the CIA was particularly interested 
in using this weapon as a means to assassinate Osama Bin Laden, a man increasingly viewed as a 
major terrorist threat following the failed 1993 bombing of the World Trade Center. Although it 
proved difficult to find a warhead that could work with this small aircraft, by 16 February 2001, 
a specially modified Predator drone successfully destroyed a target at a testing facility, using an 
AGM-114 Hellfire missile. Ultimately, the CIA was unable to follow through with its operational 
intent to assassinate Bin Laden, as the Predator was still undergoing testing when Al-Qaeda ter-
rorists destroyed the World Trade Center on 11 September 2001.
Shortly after the 9/11 attacks, President George W. Bush told the military that “the enemy who 
appeared on September 11 seeks to avoid our strengths and constantly searches for our weaknesses … so 
America is required once again to change the way our military thinks and fights.” 6 Drawing on this 
exhortation, General John P. Jumper, the new Air Force Chief of Staff, ordered immediate coordination 
with the CIA to arm all Predators. Unlike other generals, John P. Jumper was a serious supporter of the 
UAV program. After working with Predator drones in Bosnia, he cooperated extensively with the CIA 
on the project to develop an offensive UAV, believing that arming the Predator would allow it to strike 
“fleeting, perishable targets that don’t require a big warhead that we can just go ahead and take 
care of.”6 After the start of Operation Enduring Freedom, armed Predator drones were some of the very 
first deployed assets, scoring their first kill on 4 November 2002, 100 miles east of the capital of Yemen, 
by blowing up an SUV carrying Al-Harthi, the head of Al-Qaeda in Yemen and the mastermind 
behind the suicide attack on the USS Cole, which killed 17 American sailors.6 Although 9/11 disrupted 
CIA plans to use the Predator to preemptively assassinate Osama Bin Laden, the Hellfire-equipped 
Predator quickly grew to become the quintessential weapon in the war against Al-Qaeda.
Predator Vulnerability
Global terrorism is extreme both in its lack of realistic goals and in its cynical exploita-
tion of the vulnerability of complex systems.
—Jürgen Habermas8

Pirating the Ultimate Killer App: Hacking Military Unmanned Aerial Vehicles  ◾  305
The Predator UAV relies on highly complex data links to connect with operators and end 
users throughout the world. These data links occurs over two distinct wireless mediums. If the 
UAV is in line-of-sight proximity to its operator, it can transmit directly to its control van using 
the C-band, which then retransmits the live surveillance video feed onto the military network 
through numerous other network technologies (see Figure 21.1). However, this line-of-sight data 
link is rarely used, as drone pilots typically fly deployed UAVs remotely from military bases in the 
United States. In this case, where the operator and control equipment is out of theater, the UAV 
instead sends and receives all data over a satellite data link on the Ku band.5
These satellites, such as the INTELSAT 602, serve to simultaneously provide the UAV with 
three important connections (see Figure 21.2):
	
1.	A link to the remote UAV control station that allows the drone pilot to fly the UAV from the 
United States
UAV in
Afghanistan
Bridge in Afghanistan
that puts video feed
on secure network
UAV pilot
in Afghanistan
Coalition ground
commander in
Afghanistan
Figure 21.1  Line-of-sight.
UAV in
Afghanistan
Coalition ground
commander in
Afghanistan
UAV pilot
in the
United States
Bridge in the
United States that
puts video feed
on secure network
Figure 21.2  Non–line-of-sight.

306  ◾  Information Security Management Handbook
	
2.	A link to a communications station that rebroadcasts the data over the secure U.S. military 
network
	
3.	A link to Trojan Spirit communications terminals (or equivalent) in theater for immediate 
dissemination of the video feed to American and coalition commanders5
Through these communications methods, a UAV has a duplex connection with its pilot and 
two distinct simplex connections: one to commanders in theater and one to a network bridge con-
nected to the secure military network. The two simplex connections serve as the primary distribu-
tion methods for Predator surveillance video data.
The vulnerability of the Predator platform lies in the fact that it does not encrypt its surveil-
lance video data as it does with its command and control (C2) data prior to transmission over the 
C or Ku bands. This means that secure video communications depend on the network encryption 
of the specific data link used. In the case of line-of-sight communications, this data is protected 
by encryption built into the military’s C-band transmission equipment, but when the Predator 
uses the satellite-based Ku data link, the surveillance video data is completely unprotected and 
widely vulnerable to interception.5 In practical terms, this means that any Ku band–compatible 
satellite dish within the broadcast area of the Predator’s geosynchronous satellite can intercept 
the Predator’s surveillance video downlink. Additionally, such a satellite dish can also access the 
Predator Joint Broadcast System, which is essentially a CNN-like broadcast that switches between 
various live video feeds designed to provide coalition troops in Afghanistan and Iraq simultaneous 
access to a “common picture of the battlefield.” 5
A key factor behind this InfoSec vulnerability is the speed with which the Predator drone 
was initially fielded. Throughout the Cold War, the arms race to develop the most sophisticated 
weapons systems, such as fighter jets, led the real unit production cost of combat aircraft to double 
around every 7 years (see Figure 21.3).10 As previously mentioned, one of the key reasons the DOD 
supported the development of the Predator UAV was because it offered force projection without 
the exponential cost increase of developing a new manned aircraft. In the years following the end 
Comparative
unit cost
Price at
entry into
service
Phantom
F–18
F–15E
F–22
Euroﬁghter
Lightning
Tornado
1950
1960
1970
1980
1990
2000
2010
Date of ﬁrst production delivery
Figure 21.3  The exponential increase in jet fighter development cost. (From Sandler, T. and 
Hartley, K., eds., Handbook of Defense Economics: Volume 2 Defense in a Globalized World, 
Elsevier, London, p. 1153, 2007.)

Pirating the Ultimate Killer App: Hacking Military Unmanned Aerial Vehicles  ◾  307
of the Cold War, defense budgets fell precipitously throughout the world (see Figure 21.4). Given 
that the U.S. defense budget halved during the 1990s, the DOD began to rethink its operational 
requirements and weapons procurement model. Rather than seeking, what Defense Secretary 
Robert Gates called, “gold-plated” solutions to defense procurement, the Pentagon began to look 
for ways to pursue “75 percent solutions over a period of months.” 11 Predator procurement during 
the 1990s fit this model of producing rapidly scalable battlefield solutions within months and at 
minimal cost using as much commercial off-the-shelf (COTS) technology as possible, causing the 
Predator platform to exist, in the words of the Air Force director of UAV systems, “on the ragged 
edge … [seeking] to do just the absolute minimum needed to sustain the fight now, and accept the 
risks, while making fixes as you go along.” 11 Because of this procurement posture, the Pentagon 
judged the risk exposure associated with the myriad issues that could develop during the opera-
tional lifespan of the Predator to be less than the added utility of rushing the Predator into opera-
tional use, largely due to the elimination of risk to the pilot in the calculation of risk exposure.
Of particular interest to this case study was the Pentagon’s decision to lower costs by using 
COTS satellite technology based on the Ku band for the military data link of the Predator 
drones. As the Predator was undergoing development in 1996, the Undersecretary of Defense for 
Acquisition and Technology stated that “Hughes is the primary provider of direct (satellite) TV 
that you can buy in the United States, and that’s the technology we’re leveraging off of.” 9
By basing their data link on a television model, the Joint Broadcast System that displayed 
military reconnaissance footage developed as a sort of CNN for military reconnaissance videos. 
American and coalition commanders with the proper Trojan Spirit communications terminals 
could “tune” into the UAV “channel,” which greatly simplified data distribution by forgoing the 
Defense spending as a share of GDP
0
1
2
3
4
5
6
1988
1990
1992
1994
1996
1998
2000
2002
2004
2006
Year
Share of GDP (%)
USA
Germany
France
UK
Italy
Figure 21.4  The precipitous drop of global defense spending post Cold War. (From SIPRI 
Yearbook 1990 and SIPRI Yearbook 2007. Solna, Sweden: Stockholm International Peace 
Research Institute [SIPRI].)

308  ◾  Information Security Management Handbook
need to share U.S. encryption codes with allies and coalition partners. Many Air Force leaders 
actually considered the use of unencrypted video downlinks to be a feature of the Predator sys-
tem. For example, General David McKeirnan named this unencrypted data link as an important 
factor in “tripartite” cooperation between Pakistan, Afghanistan, and the International Security 
Assistance Force, allowing them to better “coordinate[] at various levels [by] exchange[ing] fre-
quencies, … intelligence, [and] … Predator feed[s].” 12
In 2002, a British satellite enthusiast named John Locker stumbled upon military reconnais-
sance footage from Kosovo when he accidently tuned into the Joint Broadcast System. Locker 
was shocked at the discovery that such footage was being transmitted over an open commercial 
satellite channel, leading him to contact the military with the concern that the ease of potential 
signal interception “may be compromising the troops on the ground, and, for that reason … we 
should either get it encrypted or get it switched off.” Ultimately, the U.S. military ignored Locker’s 
warnings with the explanation that:
	
1.	The images need to remain unencrypted to allow NATO allies that lack proper decrypting 
equipment to see them.
	
2.	The surveillance footage would be of no real value if intercepted by a potential adversary due 
to the absence of any meaningful operational context.
Media coverage of this event largely questioned this explanation, suggesting that enemy forces 
could systematically study intercepted surveillance footage to learn U.S. operational priorities and 
objectives. In an ironic premonition of things to come, a CBS reporter wrapped up this story with 
the comment that “even Al Qaeda reported terrorists are known to be in the area.” 13
Skygrabber Functionality and Exploit
Skygrabber is a piece of software designed to intercept unencrypted satellite data through the 
use of a digital satellite TV tuner card attached to a computer. In technical terms, Skygrabber is 
most accurately described as a sniffer for digital communications over a satellite data link. This 
makes the design, functionality, and usage of Skygrabber extremely similar to Kismet, an 802.11 
sniffer that allows for the capture of data packets using NIC cards. Like Kismet and other sniffers, 
Skygrabber listens to the packets passed over the data link, intercepts them, and then reassembles 
them as files on a local machine.1 In Russia (where Skygrabber was developed), this offered users, 
which otherwise could not afford an expensive satellite Internet connection, the opportunity to 
gain limited access to digital media, including “new movie, best music, and funny pictures for 
free” [sic].14
By running the Skygrabber sniffer on a PC attached to a digital satellite TV tuner card, a user 
effectively piggybacks on the unencrypted downlink of legitimate satellite Internet users (see Figure 
21.5). The software configures the TV tuner card to listen to and intercept different types of pack-
ets, which the PC then reassembles into usable files. This method only allows the user to tap into 
someone else’s downlink, due to the inability to transmit from a TV tuner card and the increased 
levels of authentication required for satellite uplink. This means that the Skygrabber user is at the 
mercy of the tastes of legitimate users, merely able to intercept all files that pass through the com-
mon satellite downlink. Nonetheless, Skygrabber users can exercise limited control over the files 
they intercept and download by applying software filters. While the sniffer is running, Skygrabber 
downloads all files that pass through the satellite data link meeting the defined filter criteria.6

Pirating the Ultimate Killer App: Hacking Military Unmanned Aerial Vehicles  ◾  309
Given the known Iranian affiliation of the Kata’ib Hezbollah militia originally caught possessing 
laptops filled with Predator intercepts, it is highly likely that Iranian Quds agents taught enemy com-
batants how to use SkyGrabber to intercept drone footage.16 The Iranian Quds agents themselves likely 
learned this system based off equipment seized from Iranian activists, as SkyGrabber is often used by 
dissidents to circumvent restrictions on information, such as those caused by the Iranian Firewall.1 
By reverse engineering the Skygrabber software, Iranian experts were likely able to apply their previ-
ous experience tapping into the video downlink of geosynchronous satellites used by American drones 
in Iraq and Afghanistan to turn the Skygrabber package into an easy and user-friendly means of 
signal interception for Shiite militias in Iraq and Afghanistan. The ease with which the Skygrabber 
software could be modified to intercept drone footage reflects very poorly on the Pentagon’s decision 
to base its surveillance footage data link on COTS technology without additional encryption or secu-
rity countermeasures. The common data link between the military’s Joint Broadcast System and the 
CNN network greatly aided low-cost signal interception techniques by ensuring that the techniques 
used to intercept satellite TV and Internet data could be easily reconfigured for military feeds, thereby 
enabling Quds agents to configure Skygrabber to emulate the technical settings of the Trojan Spirit 
communication terminals used by American and coalition forces to view Predator feeds.
Military Response
On 18 December 2009, Admiral Mike Mullen, the chairman of the Joint Chiefs of Staff, admitted 
that the Pentagon had been aware of the Predator’s data link weakness since 2004.17 In fact, fur-
ther investigations demonstrated that the military knew about this vulnerability much earlier. As 
previously mentioned, John Locker contacted the Pentagon about Predator encryption in 2002, 
but the military had received similar reports as early as the 1996 Bosnia deployment, when it was 
reportedly easier for the Serbians to tap into military feeds than the Disney Channel.6
Indeed, a 1996 Air Force document very bluntly analyzed electromagnetic spectrum threats to 
the Predator platform as the following:
The Predator is designed to operate with unencrypted datalinks. Depending on the 
theater of operation and hostile electronic combat systems present, the threat to the 
UAVs could range from negligible with only a potential of signal intercept for detec-
tion purpose, to an active jamming effort made against an operating, unencrypted 
UAV. The link characteristics of the baseline Predator system could be vulnerable to 
corruption of downlink data or hostile data insertions.18
Incoming
traﬃc
Satellite
Satellite TV
tuner card
Computer with
skygrabber
Figure 21.5  Skygrabber functionality.

310  ◾  Information Security Management Handbook
This candid assessment demonstrates that the military officials were quite aware of several 
electromagnetic threats associated with this data link vulnerability, but chose not to mitigate them 
for several reasons. The first reason was the belief at the Pentagon that enemy combatants lacked 
the technical sophistication to intercept these signals,1 making the subsequent fiasco akin to the 
military’s failure to anticipate sophisticated IEDs in their counterinsurgency strategy.17
This is demonstrated by the fact that early Pentagon risk analyses focused on the threat of 
Russia or China exploiting this unencrypted data link to manipulate the surveillance feed such 
that “a commander looking on a feed, [would see] nothing, and then [have] an enemy tank bri-
gade come roaring into [his] command post.” 17 In contrast to Russia and China, Afghan and 
Iraqi insurgents were not even considered threat-sources. The second reason for not mitigating 
was the Air Force’s view that this data link vulnerability would eventually be fixed by phasing out 
the Predator platform and replacing it with DarkStar, a next-generation UAV platform designed 
with encryption and stealth characteristics. This argument, found in an Air Force officer’s thesis 
from the School of Advanced Airpower Studies, may have made sense when the military owned 
only 167 drones in 2001,19 but in light of the 5500 drones the military possessed in 2009 (nearly 
all of which were unencrypted), it seems doubtful that thousands of these craft would actually 
be retired in the near-term.11 The third reason for not mitigating was the military’s insistence 
that the interception of UAV footage by enemy combatants did little damage. Ultimately, this 
is impossible to judge, but it appears that intercepted drone footage assisted certain high-value 
enemy combatants evade capture.13 The final reason for not mitigating was the military’s per-
ception of the unencrypted data link as a “feature” that helped the sharing of data with less-
advanced coalition partners. Given the technical state of Iraqi and Afghan police and military 
units, this view is logical, but in many ways this view created a lowest-common denominator 
approach to InfoSec.
Despite Admiral Mike Mullen’s assurances that the drone “hack” caused no damage, the 
Pentagon promised to step up the effects to prevent drone footage from falling into the wrong 
hands by upgrading all Predators to encrypt video data before transmission.20 However, due to the 
age of the platform and its reliance on proprietary design, the military has warned that it may be 
quite some time until these changes are fully completed.1 Certain military analysts have suggested 
that these technical modifications will likely not be completed until 2014, and even then, this fix 
would not solve the larger problem of dependence on an unencrypted COTS satellite technology 
for the transmission of critical military data.21
Conclusion
The overarching narrative of the history, design, use, vulnerability, and exploitation of the Predator 
UAV is important, given the increasing military bullishness toward unmanned systems. Leaders 
such as Major General Kenneth Israel state that UAVs “will play an increasingly important role in 
many military missions beyond intelligence, surveillance and reconnaissance.” 5 Indeed, military 
policy documents seem to reflect this view. An Air Force study called the Unmanned Aircraft 
System Flight Plan envisions a future where unmanned aircraft carry out all types of aerial mis-
sions, including the hitherto sacrosanct areas of dog fighting and strategic bombing.22 Recent 
research and development is slowly making this a reality. In response to the success of the Predator 
as an armed weapons platform, General Atomics has been developing a new generation of UAVs: 
the MQ-9 Reaper. Unlike the Predator, the Reaper has been conceptually designed and built to 
optimize its performance as a hunter-killer, which allows it to carry 15 times the weapons payload 

Pirating the Ultimate Killer App: Hacking Military Unmanned Aerial Vehicles  ◾  311
and equips it to take over many of the ground-support missions previously tasked to fighter jets.1 
Because of similar capabilities, full squadrons of F-16 pilots are being retrained to fly the MQ-9 
Reaper. As P. W. Singer, a defense analyst at the Brookings Institution, notes, the Predators “are 
very much Model T Fords. These things will only get more advanced.” 11
In light of the very strong possibility that unmanned aircraft may eventually become the 
United States’ primary vehicle for air power, it is important to consider the implications of the 
Skygrabber fiasco. Throughout the process of designing, testing, and fielding the Predator, the U.S. 
Air Force demonstrated a troubling tendency to view InfoSec concerns as an afterthought, when, 
in fact, electronics warfare is becoming an ever more-important element of military power. In a 
military environment where pilots telecommute to UAV hunter-killers on the other side of the 
world, it is absolutely crucial that the data links that carry UAV control data is protected more 
than any other component of the aircraft. Initially, the Pentagon viewed UAV technologies as 
inherently less risky than manned aircraft due to the relative safety of the pilot, allowing UAV pro-
curement to be “on the ragged edge,” but now that UAVs are offensive weapons platforms, this can 
no longer be the case. If an enemy were to electronically penetrate the command and control chan-
nel of these hunter-killer UAVs, they could potentially use American weapons against American 
soldiers. This is ultimately the biggest problem. Under the current system, the development of 
UAVs is managed by aircraft program managers and purchased by pilots.21 Although these parties 
may understand airframes, they know little about networking and InfoSec. Going forward, the 
Pentagon must drop its cavalier attitude toward the security of its data links and integrate com-
munications engineering and networking throughout the UAV development cycle.
References
	
1.	Gorman, S., Dreazen, Y. J., and Cole, A. Insurgents hack U.S. drones: $26 software is used to breach 
key weapons in Iraq; Iranian backing suspected. The Wall Street Journal, sec. A. p. 1, December 17, 
2009. http://online.wsj.com/article/SB126102247889095011.html (accessed February 13, 2011).
	
2.	Giordano, J. and Maciag, C. Cyber forensics: A military operations perspective. International Journal of 
Digital Evidence 1(2), 2002.
	
3.	Gorman et al., Insurgents hack U.S. drones, The Wall Street Journal, 17 December 2009, sec. A. p. 1. 
Technical information for the Skygrabber program can be found at http://www.skygrabber.com/en/
index.php.
	
4.	Appel, R. The secret war of Lisa Simpson. The Simpsons archive, May 18, 1997. http://www.snpp.com/
episodes/4F21 (accessed March 27, 2011).
	
5.	McDavid, H. and Oliver, D. Smart Weapons: Top Secret History of Remote Controlled Airborne Weapons. 
Welcome Rain, New York, pp. 9, 10, 14, 34, 50, 104, 112, 113, 115, 1997.
	
6.	Yenne, B. Attack of the Drones: A History of Unmanned Aerial Combat. Zenith Press, Saint Paul, MN, 
pp. 8, 11, 12, 19, 21, 35, 60, 66, 85, 86, 2004.
	
7.	Siuru, W. D. Planes without Pilots: Advances in Unmanned Flight. Tab/Aero Books, Blue Ridge Summit, 
PA, pp. 1, 7, 1991.
	
8.	Habermas, J., Derrida, J., and Borradori, G. Philosophy in a Time of Terror: Dialogues with Jurgen 
Habermas and Jacques Derrida. University of Chicago Press, Chicago, IL, p. 34, 2003.
	
9.	McCullagh, D. U.S. was warned of predator drone hacking. CBSNews.com, December 17, 2009. 
http://www.cbsnews.com/8301-504383 162-5988978-504383.html?tag=mncol%3btxt (accessed March 
22, 2011).
	 10.	Sandler, T. and Hartley, K., eds. Handbook of Defense Economics, Volume 2: Defense in a Globalized 
World. Elsevier, London, p. 1153, 2007.
	 11.	Drew, C. Drones are weapons of choice in fighting Al Qaeda. The New York Times, March 17, 2009. 
http://www.nytimes.com/2009/03/17/business/17uav.html (accessed February 13, 2011).

312  ◾  Information Security Management Handbook
	 12.	Hodge, N. U.S. sharing predator video with Afghanistan, Pakistan. Wired.com, November 19, 2008. 
http://www.wired.com/dangerroorn/2008111/in-a-presentati/ (accessed March 22, 2011).
	 13.	Phillips, M. Military surveillance hack warning. 60 Minutes, December 17, 2009 (original broadcast in 
2002). http://www.cbsnews.com/video/watch/?id=5990213n (accessed April 10, 2011).
	 14.	Official Site for … Skygrabber. http://www.skygrabber.com/en/index.php (accessed April 10, 2011).
	 15.	For a complete video tutorial of how to operate SkyGrabber, please visit the developer’s official Web site 
at http://www.skygrabber.com/en/video tutorials/main/skygrabber how to work.php.
	 16.	Hoffman, M. Fixes on the way for nonsecure UAV links. Air Force Times, December 18, 2009. http://
www.airforcetimes.com/news/2009/12/airforce uav hack 121809w/ (accessed February 13, 2011).
	 17.	Commanders discussed drone hacking in 2004. CBSNews.com, December 18, 2009. http://www.
cbsnews.com/stories/2009112/18/world/main5993716.shtml (accessed March 22, 2011).
	 18.	U.S. Air Force. Air Combat Command Concept of Operations for Endurance Unmanned Aerial Vehicles 
(Version 2), December 3, 1996. http://www.fas.org/irp/doddir/usaf/conops uav/partOl.htm (accessed 
April 10, 2011).
	 19.	Stephenson, J. L. The Air Refueling Receiver That Does Not Complain. Air University Press, Maxwell 
AFB, p. 10, 1999.
	 20.	Mullen: Drone hack caused no damage. CBSNews.com, December 18, 2009. http://www.cbsnews.
com/stories/2009112/18/national/main5994775.shtml (accessed February 13, 2011).
	 21.	Hodge, N. Fixing drone data: A not-so-modest proposal. Wired.com, December 21, 2009. http://
www.wired.com/dangerroom/2009112/fixing-drone-data-a-not-so-modest-proposal/ (accessed March 
22, 2011).
	 22.	Axe, D. Air Force plans for all-drone future. Wired.com, July 17, 2009. http://www.wired.com/danger-
room/2009/07/air-force-plans-for-all-drone-future/ (accessed March 22, 2011).
	 23.	Hoffman, M. Troops use archived UAV feed downrange. Air Force Times, February 27, 2010. http://
www.airforcetimes.com/news/2010/02/airforce video bank 022710w/ (accessed March 22, 2011).
	 24.	Hoffman, M. AF looks to automation to help monitor UAVs. Air Force Times, August 27, 2010. http://
www.airforcetimes.com/news/2010/08/air-force-automation-uav-0827101 (accessed March 22, 2011).
	 25.	Iraq rebels ‘hack into video feeds from US drones’. BBC News, December 17, 2009. http://news.bbc.
co.uk/2/hi/8419147.stm (accessed February 13, 2011).
	 26.	Jelinek, P. Pentagon: Insurgents intercepted UAV videos. Air Force Times, December 17, 2009. http://
www.airforcetimes.com/news/2009112/ap uav insurgents hacked 121709/ (accessed February 13, 
2011).
	 27.	Martin, M. J. Predator: The Remote-Control Air War over Iraq and Afghanistan: A Pilot’s Story. Zenith 
Press, Grand Rapids, MI, 2010.
	 28.	Mount, M. and Quijano, E. Iraqi insurgents hacked Predator drone feeds, U.S. official indicates. CNN.
com, December 17, 2009. http:l/articles.cnn.com/2009-12-17/us/drone.video.hacked 1 uav-systems-
encryption-feeds? s=PM:US (accessed February 13, 2011).
	 29.	Official site for programs SkyGrabber (accepting free to air satellite data by digital satellite TV tuner 
card (DVB-S/DVB-S2)), LanGrabber (save YouTube video), Tuner4PC (software for satellite internet). 
http://www.skygrabber.com/enlindex.php (accessed April 10, 2011).
	 30.	Rolfsen, B. Unmanned a misnomer when it comes to UAVs. Air Force Times, June 11, 2010. http://
www.airforcetimes.com/news/2010/06/airforce uav personnel 061110w/ (accessed March 22, 2011).
	 31.	Schneier, B. Insurgents intercepting predator video? No problem. Wired.com, December 23, 2009. 
http://www.wired.com/politics/security/commentary/securitymatters/2009112/securitym atters 1223 
(accessed March 22, 2011).
	 32.	Shachtman, N. Military faces bandwidth crunch. Wired.com, January 31, 2003. http://www.wired.
com/techbizlit/news/2003/01/57420 (accessed March 22, 2011).
	 33.	Shachtman, N. Not just drones: Militants can snoop on most U.S. warplanes. Wired.com, December 17, 
2009. 
http://www.wired.com/dangerroom/2009112/not-just-drones-militants-can-snoop-on-most-us-
warolanes/ (accessed March 22, 2011).
	 34.	SkyGrabber and the curse of encryption. Strategypage.com, December 19, 2009. http://www.strat-
egypage.comlhtmwlhtairfo/articles/20080811.aspx (accessed February 13, 2011).

Pirating the Ultimate Killer App: Hacking Military Unmanned Aerial Vehicles  ◾  313
	 35.	Spoth, T. GAO: UAV surge leaves many shortfalls. Air Force Times, April 16, 2010. http://www.air-
forcetimes.com/news/2010/04/airforce gao uavs 041610w/ (accessed March 22, 2011).
	 36.	Taylor, J. W. R. and Munson, K. Jane’s Pocket Book of Remotely Piloted Vehicles: Robot Aircraft Today. 
Collier Books, New York, 1977.
	 37.	U.S. Air Force. Unmanned Aircraft Systems Flight Plan 2009–2047. HSDL, Washington, DC, 2009. 
http://www.scribd.com/doc/17312080/United-States-Air-Force-Unmanned-Aircraft-Systems-Flight-
Plan-20092047-Unclassified (accessed March 22, 2011).
	 38.	U.S. House of Representatives, Committee on Oversight and Government Reform, Subcommittee 
on National Security and Foreign Affairs. Rise of the Drones: Unmanned Systems and the Future of War. 
HSDL, Washington, DC, 2010.
	 39.	Warplanes: The rise of the droids. Strategypage.com, August 11, 2008. http://www.strategypage.com/
htmwlhtairfo/articles/20080811.aspx (accessed February 13, 2011).


DOMAIN
6
SECURITY 
ARCHITECTURE 
AND DESIGN
Principles of Computer and 
Network Organizations, 
Architectures, and Designs


317
Chapter 22
Service-Oriented Architecture
Walter B. Williams
What Is a Service-Oriented Architecture?
To properly understand what a service-oriented architecture (SOA) is, it is helpful to understand 
where it sits as an architecture and the problem that an SOA tries to solve. An SOA, first, is a 
software architecture. Software architectures are the structures of software, their elements, and 
the relationship between them. SOA was developed by applying the concept of software architec-
ture to solve the problem of how to connect disparate systems in a way that they could function 
together in a systematic manner.
Each application in an SOA is treated as if it can only perform one specialized function, or 
as if it were an element in the larger software. This specialized function is called a service. Thus, 
each service functions as an element of the SOA, where the structure and the defined relationship 
between the elements must transcend application and often corporate boundaries.
Distributed Computing and Services
SOAs are not the only approach to integrating disparate computer applications into a larger uni-
fied system. A message-oriented model (MOM) was developed with the idea of distributing the 
components of a system among existing and emerging applications and platforms. Messages were 
used to connect these systems, implemented through specialized platforms called message queues. 
Message queues are very reliable, but required not only a system to manage them, but also a staff 
to maintain the messaging system. Most importantly, support for the message queues had to be 
built into all the application components, restricting the implementation of a system built on an 
MOM architecture to the internal needs of a single corporate infrastructure.
An Architecture Based upon Services
As business realized that other companies applications provided a better solution to meet 
their requirements than their own internally developed systems, they realized that they could 

318  ◾  Information Security Management Handbook
provide better products to their customers if they found a way to leverage the capabilities of 
other corporations expertise for components that were not part of the core competency of 
their own company.
As an example, a travel company might recognize that MapQuest’s maps (or Google Maps) 
were vastly superior to their own, and because their home-grown map application was not how 
they brought in new business, but still provided a desired component to their customers, it would 
benefit everyone if there was a way to leverage the capabilities of the other company’s superior 
product.
SOAs abstract the diverse applications, protocols, systems, and data into four key concepts:
◾
◾Application front end
◾
◾Service
◾
◾Service repository
◾
◾Service bus
An application front end is the owner of the business process the application provides and 
other services can use. A service is an implementation that provides business logic and data, 
and a service contract specifies functionality, usage, and constraints that must be observed by 
any client, and an interface exposes the functionality. A service repository stores the service 
contract of the individual services. A service bus interconnects the application front ends and 
the services.
There are various technologies that can be applied in the implementation of an SOA. Some of 
these are more appropriate for internal enterprise-specific projects, and others may be applied to 
any project with any scope. Precisely, because of the common architecture, there are issues that 
transcend the individual technologies that must be considered when establishing a security archi-
tecture appropriate for the protection of the business and its objectives as supported by the specific 
implementation of an SOA.
Process Integrity
Data integrity is a key factor in the success of many SOAs, as data is transferred from one service 
to another. However, the integrity of data is not sufficient to guarantee that the service returns the 
correct results due to the complexity of business processes that span multiple systems and often 
involve multiple corporations. Process integrity involves not only the integrity of the assets, but 
also their utility throughout the architecture.
The principles of entity, domain, and referential integrity are borrowed, where appropri-
ate, from relational databases. Entity integrity requires that each row in a table be uniquely 
identified. Domain integrity requires that certain data be within a valid range (such as the date 
of purchase of an item not being in the future, or before the date of which the item was first 
placed on sale). Referential integrity refers to the validity of the relationship between different 
datasets, preserving as an example the names of the residents in relationship to their appropriate 
residence.
Where data must be processed across multiple systems through the use of their services, there 
is the risk of inconsistencies that impact the validity of both the data and the use of the data in all 
services. There might be technical failures, business exceptions, and special cases that impact the 

Service-Oriented Architecture  ◾  319
integrity of the process. Because the process is not centrally controlled, the impact of the failure of 
any particular component may be high.
There have been a number of techniques applied to solve this problem, each with their own 
merits and issues. The most common approach is to apply logging and tracing. This is similar to 
the use of transaction logs in a transactional system, allowing for recovery to a valid state in the 
event of a failure. The problem is that it is difficult for logging and tracing to resolve issues that 
relate to logical processes, which span the multiple systems involved in an SOA.
Online transaction processing systems were developed to enable large numbers of users to 
concurrently manipulate shared data. Such systems are based upon the concept of transactions on 
a unit of work that transforms data from one state to another. A unit of work is presumed to be 
atomic, or indivisible, consistent (move from one consistent state to another), in isolation where no 
process is visible to any other, and durable where committed updates are permanent. Such systems 
depend upon a central control mechanism that resolves conflicts. Such a central control mecha-
nism is often unavailable to an SOA that leverages services from multiple organizations.
The Two-Phase Commit Protocol (2PC) was developed to allow online transactional pro-
cessing to span multiple systems. A transaction coordinator is implemented as part of a transac-
tion monitor. This enforces that in the first phase of the processing, all relevant locks have been 
acquired and that the state of the data has been properly captured. Depending upon the results 
of this examination, the transaction coordinator informs the participating systems if they should 
roll the transaction forward or backward. These systems “vote” on how to handle the data, a single 
abort vote will cause the entire transaction to be rolled back.
All of these mechanisms of tracking changes to data are predicated on some assumptions that 
often do not apply in an SOA. One is that it is possible to ensure the isolation to the data; another 
is that the transaction is short-term. Neither can be assumed in an SOA, where the various services 
may be entirely ignorant of access and use of data by other services, and transactions are often 
long-lived. SOAs are also often implemented on discontinuous networks, and none of the above 
mechanisms are designed to operate under such conditions.
Two techniques scale well to address the issues of process integrity. The first is that of per-
sistent queues with transactional steps. Persistent queues, which follow the data, can guarantee 
consistency of the individual steps of the process, where errors are handled by a dequeue and 
the error is returned with the data. Such systems depend heavily upon the presence of a mes-
sage queuing system and are more often implemented in internal SOAs where such systems 
are present.
The second is transactional chains and compensation. Complex workflows are created through 
individual process steps (transaction chains); where failures are dealt with through compensat-
ing transactions that logically undo a prior transaction. Each transaction is made visible to each 
service, so that data may be made available to a compensating control.
To permit these workflows to transcend the boundaries and controls of a single corpora-
tion, the Business Process Execution Language (BPEL) was developed. It is based upon Business 
Process Markup Language (BPML), an extension of XML as a formal meta language for modeling 
business processes, which provides an abstract execution model for describing collaborations and 
transactions. BPEL allows the capability to:
◾
◾Describe the logic of business processes through composition of services
◾
◾Compose larger processes from smaller processes
◾
◾Handle synchronous and asynchronous operations

320  ◾  Information Security Management Handbook
◾
◾Invoke services in series or parallel
◾
◾Selectively compensate completed activities in case of failure
◾
◾Maintain interruptible long-term transactional systems
◾
◾Resume interrupted and/or failed activities
◾
◾Route incoming messages to the appropriate service
◾
◾Correlate requests within and across business processes
◾
◾Schedule activities based upon predefined times
◾
◾Define order of execution
◾
◾Handle both message- and time-related events.
With BPEL, business processes can be described in two distinct ways:
	
1.	As executable business processes wherein the exact details of the process are defined and 
follow the orchestration paradigm
	
2.	As abstract business processes or the public message exchange. These are not executable and 
follow the choreography paradigm.
In the orchestration paradigm, a central process, which can be another service, takes control 
and coordinates the execution of different operations in the services involved in the operation.
The Choreography paradigm does not rely upon a central process, but is a peer-based system 
where each service knows when to execute its operations and with what other services to interact.
Enterprise Service Bus
An enterprise service bus is the technical infrastructure of the distributed environment. It is com-
posed of an XML-based communications protocol with a message-oriented middleware core to 
perform the actual message delivery. There are a variety of message bus frameworks in common 
use. Some, such as Enterprise Java Beans within the J2EE specification and Microsoft’s .Net, are 
based upon the capabilities of an application architecture. Others rely upon either message queues 
or object-oriented communications infrastructures such as Common Object Request Broker 
Architecture (CORBA). In practice, a successful Enterprise Service Bus is not a single product, 
no matter how flexible or how many communications protocols it supports, but one that supports 
accessing services on a meta level, which can leverage the capacities of all application architectures, 
allowing .Net, Enterprise Java Beans, and other diverse applications to function within a single 
business process.
Web Services and SOA, an Alternative Service Bus
Unlike an internal SOA, a Web services–based SOA cannot rely upon a single monolithic ser-
vice bus. To this end, Web services are based upon slightly different principles than a traditional 
SOA. Each service needs to be reusable, stateless, autonomous, abstract, discoverable, and loosely 
coupled. Instead of a form service bus, you have a service integration layer, which operates as a 
logical or virtual service bus (Exhibit 22.1).
Services engage with this service integration layer and each other through a formal contract, 
which defines the terms of information exchanged and provides supplemental service description. 

Service-Oriented Architecture  ◾  321
Because services need to be discoverable, they make themselves known through a service pro-
vider. Services also need to know which service to call and thus will have a service requester. 
These roles can be and often will be reversed, as the role of the service changes within the larger 
workflow from the client to the server. There may be more than one service provider through 
which a workflow must pass before it arrives at its ultimate destination, and these are called 
intermediary services. Intermediary services may or may not do more than discover the next step 
in the workflow, depending upon the nature of the service and the contract it has as a service 
provider.
Web services tend to be broken down into one of a set of roles:
◾
◾Utility service
◾
◾Business service
◾
◾Controller service
◾
◾Proxy service
◾
◾Wrapper service
◾
◾Coordination service
◾
◾Process service
The nature of the service offered, how to engage it, and the results to be expected are all defined 
in a specialized XML document present on the service provider. This document will be written in 
the Web Services Description Language (WSDL). The WSDL functions as the integrations layer 
of the Web service, providing the basis for other services to discover how to engage the particular 
service.
Some implementations of Web services will register themselves in a central registry of 
services using a specification called the Universal Description, Discovery, and Integration 
(UDDI). UDDI repositories provide a market place of generic services and are often hosted by 
major corporations.
Many protocols can be used and are used to communicate between the various Web ser-
vices over TCP/IP. The most common is the Simple Object Access Protocol (SOAP). SOAP pro-
vides a standard message format that consists of an XML document capable of hosting RPC and 
Exhibit 22.1  Web 2.0 and SOA (Web Services)
Service Registry (UDDI)
Business Process 
(BPEL)
Quality of Service
Service 
Implementation
Security
WS-Security
Coordination and Transactions
WS-Atomic Transact and 
WS-BusinessActivity
Reliable Messaging
WS-Reliable Messaging
Message Correlation
WS-Addressing
Introspection
WS-Inspection
Event Model
WS-Event Model
Management
ESB Management Features
Service 
Description 
(WSDL)
Service Protocol 
(SOAP, ReST)
Service Bus

322  ◾  Information Security Management Handbook
document centric data. SOAP can be easily leveraged by both synchronous and asynchronous data 
exchange models. SOAP, as a raw protocol set, does not define a preset language, allowing the 
application designer to create a language specific to the architecture.
An alternative to SOAP-based Web services is the Representative State Transfer (ReST)-based 
Web services. ReST leverages the existing vocabulary of the Hypertext Transfer Protocol (HTTP) 
or other robust application layer protocols with existing vocabularies. SOAs based upon ReST are 
easier to implement, but less flexible.
With second-generation Web services, or Web 2.0, a limited vocabulary was developed 
to provide a common framework for common constructs that all business services rely upon, 
such as business process or workflow, security, reliability, policies, and attachments. These stan-
dards, managed by the Organization for the Advancement of Structured Information Standards 
(OASIS), are called the WS or Web Services standards. The most common of these protocols are 
defined next.
Web Services Description Language
WSDL, currently in its second revision, serves to define a Web service to service discoverers. It 
does this in two ways, one abstract and the other concrete. In the abstract, a WDSL will describe 
the messages the service sends and receives, typically using XML schema. It defines operations 
associating message exchange patterns with one or more messages. Message exchange patterns are 
the sequence and cardinality of the messages sent and received. At the concrete level, a WDSL 
will specify bindings of transport and wire format details for an interface and associate a network 
address with a binding.
Simple Object Access Protocol
SOAP is probably the most commonly used protocol within an SOA because of its versatility. It 
has a very simple structure to it, being composed of an envelope, a header, and a body as shown 
in Exhibit 22.2.
The envelope is a construct that defines the overall framework for interpreting a SOAP mes-
sage, in essence defining the vocabulary, who should deal with it in whole or part, and what parts, 
if any, are mandatory.
The header carries a representation of a resource that is needed to process the SOAP message, 
but that cannot be obtained through the URI for the resource carried within the message.
Exhibit 22.2  SOAP Structure
SOAP-ENV: Envelope
SOAP-ENV: 
Header
SOAP-ENV: Body

Service-Oriented Architecture  ◾  323
The header and the envelope allow SOAP to provide a flexible and custom workflow imple-
mentation for the SOA. However, this flexibility comes at a cost of lower performance as each 
SOAP message must be parsed so that the vocabulary may be learnt and its instructions followed 
appropriately by the service.
Representative State Transfer
ReST is used by SOAs where performance considerations outweigh flexibility and security. ReST 
depends upon six fundamental architectural assumptions in the use of HTTP and other protocols:
Clients are separated from the servers by a uniform interface, with the clients remaining 
unconcerned with data storage and the servers unconcerned with a user interface. This preserves 
the portability of the clients and the scalability of the servers.
No client information is stored on the server between requests, providing a stateless environ-
ment. The server can be stateful, as needed, providing reliability and scalability.
Clients may cache information from the servers and reuse it in preference to fresh data from 
the servers.
Clients cannot determine if they are connected directly to the terminal service provider, or to 
an intermediary service provider, allowing scalability and load balancing.
Clients can have their code extended on a temporary basis by the servers. Examples include 
JavaScript run within a browser or Java applets.
Clients and servers have a uniform interface consisting of identification of resources, usually 
through URI, manipulations of these resources, self-descriptive messages, most often through 
MIME types, and the use of hypermedia as the engine of application state.
Distributed Component Object Model
Distributed Component Object Model (DCOM) is a set of remote procedural call libraries 
designed for the Microsoft Windows operating system (OS). DCOM is often used within an 
enterprise-specific SOA and is an alternative to SOAP or ReST.
Common Object Request Broker Architecture
CORBA is a platform agnostic method of remote procedural calls with predefined mappings into 
many common languages designed to allow different applications written in different languages 
to interchange instructions and data. CORBA is often used within an enterprise-specific SOA and 
is an alternative to SOAP or ReST.
Data Distribution Service
Data Distribution Service (DDS) was developed to provide a mechanism to distribute data in 
a publish/subscribe model. It is an alternative to SOAP or ReST, but is rarely used in modern 
implementations.

324  ◾  Information Security Management Handbook
Windows Communication Framework
Windows Communication Framework (WCF) is a Microsoft-specific technology designed for 
building Web services using Microsoft products. Until recently, Microsoft technology did not 
support key Web services technologies such as Security Assertion Markup Language (SAML) and 
relied upon WCF to provide proprietary alternatives. It is a replacement for DCOM and is an 
alternative to SOAP and ReST.
WS-Coordination
A defined set of instructions to coordinate the behavior of various Web services within the SOA. It 
is used to maintain process integrity and functionality. WS-Coordination can manage any of the 
protocols typically used to call services and provide them with the required information.
WS-Transaction
A defined set of instructions to handle atomic (individual) transactions and business transactions 
for long-term operations. WS-Transaction is an alternative to BPEL.
BPEL for Web Services
BPEL as such has been a very successful language for defining workflow in SOA specific to enter-
prises. BPEL-WS (also written WS-BPEL) is just an extension of BPEL for Web services.
WS-Security
WS-Security is a suite of standards that provide the security layer of a Web 2.0 SOA. The Suite 
consists of WS-Policy, SAML, XML Signature, and XML Encryption; though WS-Trust, 
WS-Authorization, WS-SecureConversation, and WS-Privacy also exist, they are less com-
mon. See Exhibit 22.3.
Exhibit 22.3  WS-Security Sack
WS-DigitalSignature
WS-Encryption
XMLKMS (Key Management 
Service)
WS-SecureConversation
WS-Federation (SAML, 
.Net Passport)
WS-Authorization
WS-Policy
WS-Trust
WS-Privacy
WS-Security
SOAP
SSL/TLS

Service-Oriented Architecture  ◾  325
Security Assertion Markup Language
SAML provides the authentication service for Web services–based SOA. It is not mandatory and 
not supported by all platforms and vendors. There are major compatibility issues between the 
different versions of SAML, where products that support SAML 2.0 will not likely also sup-
port SAML 1.1. SAML is commonly used to extend trust boundaries, allowing for federated 
identity. SAML assertions will contain information necessary to provide both authentication and 
authorization.
.Net Passport
.Net Passport is a Microsoft propriety alternative to SAML, which was not supported in Microsoft 
products until recently.
XML Encryption
XML Encryption provides XML with the structure to encrypt the whole of a separate XML docu-
ment, part of an XML document, or the attachment to an XML document. The most common 
tags are:
◾
◾EncryptedData
◾
◾EncryptedData Schema
◾
◾EncryptedType
◾
◾EncryptionMethod
◾
◾EncryptionProperties, which likely will contain CipherData, CipherValue, and/or 
CipherReference
◾
◾KeyInfo
◾
◾EncryptedKey
◾
◾ReferenceList (where multiple items have been encrypted with the same key)
XML Digital Signature
Provides the use of digital signatures in the signing of the whole, part, or attachments to 
XML documents. XML Digital Signatures can leverage certificates issued by a public key 
infrastructure.
WS-Policy
WS-Policy is often considered to be a component of WS-Security, as it is used to communicate 
the security policy of the Web service much like the WSDL is used to communicate the rules of 
engagement for the service. Like the WSDL, it defines those rules that must be followed and those 
that are optional, but in a hierarchical manner wherein some or all of the child objects must be 
satisfied to comply with the defined policy.

326  ◾  Information Security Management Handbook
Attacking SOAs
Despite very impressive security controls to guarantee the integrity of data, the utility of process, 
and the confidentiality and availability of information, there are numerous ways to successfully 
attack even the best-protected Web service.
Many Web services are not authenticated properly; often authorization is not checked after 
authentication. Most importantly, the service logic itself may be used in ways that the developers 
never intended.
To footprint a Web service, you often have to go no further than the UDDI and the WSDL. 
The UDDI will provide the location of the specific service, and the WSDL provides, in unpro-
tected detail, how to engage the service. WSDL can often be discovered by simply appending 
“?wsdl” to the end of a URL. You look in the WSDL for open methods and resources that are 
unprotected. Service tags, easily found with a <service.*?> regex pattern, define the name of the 
service and how to engage it.
Once the Web service is understood, it can be attacked. If .Net is used, vulnerabilities associ-
ated with that platform may appear. Same with J2EE or ReST. Often, because the XML in the 
SOAP packets can be encrypted, the transport between the services is not protected with SSL/
TLS. The SOAP packets can be intercepted with a sniffer, and those values not encrypted can 
be readily replaced. Also, if the encrypted components are not properly digitally signed, then 
the entire encrypted section of the SOAP message may be replaced by the one that matches the 
requirements of the WSDL exactly.
As many Web services are developed to respond to XPATH queries, one can manipulate 
XPATH to transverse through any XML document in search of key information.
If the Web service is using DOM, the DOM parser will read the entire XML into memory 
before processing. One can overload a DOM processor using complex XML structures and large 
envelopes. Once the DOM processor is overloaded, it is often possible to run arbitrary code or take 
down the service entirely.
Another technique that can be used to elevate privileges is to poison the XML with SAX pars-
ing. One can place a tag inside the logic of another tag and overwrite data without authorization. 
As an example:
<AccountInformation>
<AccountNumber>XJ12M</AccountNumber><Privileges>15</Privileges>
<AccountNumber>XJ12M</AccountNumber>
If later in the same XML, the following is written, the Privileges will be overwritten to 
become 1:
<AccountNumber>XJ12M</AccountNumber><Privileges>1</Privileges>
<AccountNumber>XJ12M</AccountNumber>
Just as in URL manipulation, the parameters of a SOAP packet can be tampered with if they 
are not signed. Metacharacters can be injected into the parameters and break the services logic. 
Where data in the XML is not signed, one can often cause a denial of service within a service 
provider by mistyping the data expected in a tag.
Just as with any Web application, SQL injection and LDAP injection may reveal information 
in services exposed to the architecture but not designed to provide the information you request 
through the injection attack. If the underlying database or directory service does not properly 

Service-Oriented Architecture  ◾  327
check authorization, price lists, account information, and even password hashes and x509v3, 
private keys may be provided.
When Web services leverage file systems and the underlying OS, the SOAP packets can 
manipulate the Web service to providing file data or executing code in the context of the account 
under which the Web service is running.
In the absence of proper account lockout policies, Web services accounts can be brute forced 
by using a SOAP message that contains account after account. Proper logging can record this, but 
may not alert you to the attack unless the log is monitored.
Web services messages can have their sessions hijacked when the session is maintained with 
either cookies or information in the SOAP header.
Tools exist to assist in attacking Web services. WS-Knight, WS-Audit, Crowbar, and, of 
course, the many proxy-based tools used in attacking a Web application all serve to simplify the 
steps needed to compromise a Web service.
Defending SOAs
Fortunately, Web services have many excellent and robust controls that can be applied to dili-
gently and proactively protect the service, data, and business process.
There are three layers to defend: the service container, the service, and the messages between 
the services.
SSL/TLS provides excellent and well-understood transport layer security, which can easily 
be deployed in a Web service. Unfortunately, if the WS-Routing protocols are used in the Web 
services, SSL/TLS will not work.
In the absence of SSL/TLS, or even while using an encrypted transport, XML Encryption 
and XML Signature can be leveraged to sign and encrypt data within the SOAP packets. XML 
Signature contains four major items, though two of the four are optional.
	
1.	Pointers to the object to be signed
	
2.	The actual signature
	
3.	They key (or means to discover the key) (optional)
	
4.	Options tag (optional)
The item to be signed can be internal to the XML document itself, can be an attachment, 
such as a binary object, or can be another XML document. There are three classifications of XML 
signatures:
	
1.	Enveloping
	
2.	Enveloped
	
3.	Detached
Enveloping signatures wrap the data that is being signed within the tags. Enveloped signatures 
refer to a parent XML element through a reference contained within the tag. Detached signatures 
obviously refer to objects external to the XML, which are signed.
XML encryption works much like that of SSL/TLS where the recipient’s public key is used to 
encrypt the symmetric key used to actually encrypt and decrypt the message. Upon receipt, the 
private key is then used to decrypt the encryption key, which is then used to decrypt the encrypted 

328  ◾  Information Security Management Handbook
portion of the XML. This is both the strength and weakness of XML encryption. The data con-
fidentiality is maintained, but unless the portion of the XML containing the XML encryption is 
signed, it is a trivial thing to replace the encrypted data with other encrypted data, and because a 
public key is known (being public), the recipient will be able to decrypt the substituted strongly 
encrypted data and process the related workflows.
Depending upon the service, it may not be advisable to expose it to the entire Internet. Access 
control at the IP address level can provide a measure of assurance. Although IP addresses can be 
spoofed, the permitted IP address has to be known in advance by the attacker. In the absence of 
that information, even the normally unprotected WSDL file will be unavailable.
To provide for both authentication and the basis of authorization, all Web services support 
multiple authentication frameworks. One that is unique to Web services and provides support 
for distributed administration is SAML. SAML allows company A to provide authorization to 
accounts created and maintained by company B, and a mechanism for services providing those 
accounts to be made available to the members of company A without having to provide company 
A with the passwords of their members or customers.
As with every application, the Web service must be configured to handle errors and exceptions 
gracefully so that no information regarding the technical details of the error are passed to the 
service caller, but are logged so that support staff can debug and resolve the issue.
Auditing SOAs
The auditing of an SOA will involve inspecting the WSDL and WS-Policy for each service to make 
certain that only those functions desired for the workflow can be called; that all services, which 
provide sensitive functionality or operate on data which remain confidential, require authentica-
tion; that data is encrypted; and that encrypted data is signed. The auditor must also verify that 
authentication and authorization are logged by the service and that logs can record who did what, 
when, and with what authority.
Because the SOA is a complex multiplatform cross-enterprise unity of capabilities in the ser-
vice of business objectives, properly auditing any SOA for compliance with internal or external 
standards will take time and diligence. However, no shortcuts should be taken as a flaw caught in 
an audit may prevent the business from compromise by a criminal who found a service without 
authentication or sensitive data that remained unencrypted.
About the Author
Walter B. Williams has over 25 years of experience in information technology, over 12 of which 
have been in information security. He has designed and implemented successful PKI, metadi-
rectories, and the security layer of SOA-based E-commerce solutions. He helped create the risk 
management program at multiple enterprises in various business sectors and has served as the chief 
security officer of a start-up in the identity theft prevention industry. He has sat on the board of 
the New England chapter of the ISSA, where he remains an active member. He currently manages 
security and compliance for a Massachusetts-based hospitality service provider. Walter holds the 
SSCP, CEH, CPT, and CISSP certifications.

Service-Oriented Architecture  ◾  329
References
Chappell, D. Enterprise Service Bus. O’Reilly Media, Sebastopol, CA, 2004.
Erl, T. Service-Oriented Architecture, a Field Guide to Integrating XML and Web Services. Prentice Hall, Upper 
Saddle River, NJ, 2004.
Juric, M. Business Process Execution Language for Web Services. Packt Publishing, Burmingham, 2006.
Krafzig, D., Banke, K., and Slama, D. Enterprise SOA, Service-Oriented Architecture Best Practices. Prentice 
Hall, Upper Saddle River, NJ, 2005.
Shreeraj, S. Hacking Web Services. Charles River Media, Boston, MA, 2007.
Rosenberg, J. and Remy, D. Securing Web Services with WS-Security. SAMS Publishing, Indianapolis, IN, 
2004.


331
Chapter 23
Cloud Security
Terry Komperda
Introduction
Before we can assess the current state of cloud computing security and then recommend best 
practices and ideas on how to improve it, we need to have a common understanding of what cloud 
computing is, the service models employed, and the related deployment models that customers 
choose when deciding to use the cloud. With this background, an analysis of the current state can 
take place and the additional security issues that need to be addressed can be defined to give cloud 
computing a long-lasting and secure future for providing secure services and business models for 
customers across the globe.
What Is Cloud Computing?
Cloud computing is a business model where resources are shared by multiple customers (users) at 
the network, host, and application levels. It provides the ability to scale thousands of systems as 
well as enable the scaling of bandwidth and storage space. Computing resources can be rapidly 
increased and decreased and resources can be released when no longer needed, providing for a 
great degree of elasticity. This model follows a utility company model whereby customers only pay 
for what they use and only for the time period that they actually use it.
Cloud Computing Services
Today, there are three main services provided by cloud computing. This is known as the SPI 
(SaaS, PaaS, IaaS) Framework:*
	
A.	Software as a Service (SaaS): Customers subscribe on a pay-per-use basis for software host-
ing and management of applications to reduce the cost of application software licensing, 
servers (and other infrastructure), and personnel. Applications can be accessed via a Web 
*	Mather, T., Kumaraswamy, S., and Latif, S. Cloud security and privacy. O’Reilly Media, p. 11, September 2009.

332  ◾  Information Security Management Handbook
browser and delivered via the Internet to a firm’s firewall. The backend hardware architec-
ture is shared across many customers but logically unique to each customer. This model 
offers the least amount of customer extensibility, and there is very little visibility and con-
trol for the customer. Most of the responsibilities for security management reside with the 
Cloud Service Provider (CSP), as storage is completely managed by the CSP and access 
to the Web portal is controlled through management of user identities, application level 
configurations, and restrictions to specific IP address ranges. Service levels, security gover-
nance, and compliance expectations for the services and CSP are contractually stipulated, 
managed, and enforced.
	
B.	Platform as a Service (PaaS): This service model is basically an environment as a service 
for application developers. The CSP typically develops toolkits and standards for devel-
opment and channels for distribution and payment. Development tools are hosted in 
the cloud and accessed through a browser. This is a more extensible model than SaaS as 
security features and capabilities are less complete, but there are provisions for the ability 
to layer on additional security. The customer assumes more responsibility for managing 
configurations and security for middleware, database software, and application runtime 
environments. The drawbacks here are that the customer is locked into vendor APIs, con-
ventions, and platform behavior. The customer can extract his/her data, but applications, 
data structures, and any add-ons are useless outside of that particular vendor environment.
	 C.	Infrastructure as a Service (IaaS): This model offers computing services in the same way 
as a utility company offers service. You pay for the amount of processing power and disk 
space that you actually consume. You can scale infrastructure requirements such as com-
puting resources, memory, and storage based on usage. The customer provisions processing, 
storage networks, and other resources where the customer runs arbitrary software that 
can include OS and applications, but does not control or manage the infrastructure. This 
model provides an enormous amount of extensibility, but there are less integrated security 
capabilities and functionality beyond protecting the infrastructure itself. The customer is 
responsible for secure configurations, patch management, installation/removal of plug-
ins, access control integration, archive security, and key management services for data 
encryption.
Looking across the models, SaaS builds upon PaaS and PaaS builds upon IaaS. As capabilities 
are inherited (as you move from SaaS to IaaS), so are the information security issues and risks.
Cloud Deployment Models
The following are the ways in which clouds are deployed:
	
A.	Public Cloud: Also known as an external cloud. Resources are provided on a self-service 
basis via Web applications and services to the general public or a large industry group. 
It is hosted, operated, managed, and owned by a CSP that has one or more data centers. 
Security management and day-to-day operations are relegated to the CSP and the customer 
has a low degree of control and oversight of the physical and logical security aspects of the 
cloud.
	
B.	Private Cloud: Also known as an internal cloud. This model basically emulates cloud 
computing on a private network. The cloud infrastructure is operated solely for an orga-
nization and can be managed by the organization or a third party on or off the premises. 

Cloud Security  ◾  333
It delivers some of the benefits of cloud computing without its pitfalls, capitalizing on 
data security, corporate governance, and reliability concerns. Organizations buy, build, 
and manage the cloud and do not benefit from the lower upfront capital costs and less 
hands on management offered by cloud computing in general. Security management and 
day-to-day operation of hosts are relegated to an internal IT Department or a third party 
bound with service-level agreements (SLAs). The customer should have a high degree of 
control and oversight of the physical and logical security aspects of the infrastructure, and 
this makes it easier to comply with established corporate security policies, standards, and 
regulatory compliance. An added benefit of a private cloud over a public cloud is lower 
latency during peak traffic loads.
	 C.	Hybrid Cloud: This is a model where two or more clouds remain as unique entities but are 
bound together by standard or proprietary technologies that enable data and application 
portability. The clouds can be private or public or a combination of the two. Organizations 
that use this model typically run noncore applications in the public cloud while running 
core applications and sensitive data in-house in the private cloud.
The bottom line is that an organization wants to consider selection of the cloud deployment 
model based on the criticality of their assets and specific requirements for security and compliance.
Security Considerations and Issues in Cloud Computing
Now that we have some background on the services that cloud computing provides as well as 
knowledge of how clouds are deployed, we can look at the security considerations and issues in 
cloud computing by certain areas of security:
Infrastructure Security
Issues
◾
◾Infrastructure security can be looked at in terms of the network, host, and application 
levels. At the network level, the security challenges associated with cloud computing are 
exacerbated by the cloud, but not specifically caused by it. At the host level, there is an 
increased need for host perimeter security and secured virtual environments but this is also 
exacerbated by cloud computing and not caused by it. At the application level, there is a 
need for a secure software development life cycle due to the public facing nature of public 
cloud applications and to ensure that APIs have been thoroughly tested for security. But, 
application level security requirements are again exacerbated by the cloud and not caused 
by it.
◾
◾Trust boundaries between the customer and CSPs have moved, and customers are not sure 
where the trust boundaries have moved to. CSPs have not done an adequate job of clearly 
articulating the boundaries, nor are these boundaries effectively enforced in SLAs.
◾
◾The established model of network tiers and zones no longer exists. This model has been 
replaced with domains that are less precise and afford less protection than the long standing 
models of tiers and zones.
◾
◾Data separation in cloud computing is logical and not physical. There are valid security 
concerns with logical segregation.

334  ◾  Information Security Management Handbook
Data Security and Storage
Issues
◾
◾The major reason for lack of effective data security is simply the limitations of current 
encryption capabilities.
◾
◾Efforts to adequately detail data mapping are simply not possible in today’s cloud computing 
offerings.
◾
◾There’s a lack of serious attention to customer concerns about data remnance (data residue 
left over and possibly becoming available to unauthorized parties).
◾
◾Storage as a service is effective for nonsensitive, nonregulated data. Data can be encrypted 
in transit and at rest, but encrypted data cannot be processed, indexed, or sorted while 
encrypted. If the data is unencrypted, it becomes a security and compliance concern espe-
cially if the data in the cloud is beyond the customer’s visibility and control (difficult to 
locate where it is stored).
◾
◾Currently, not all CSPs provide storage management data protection and disaster 
recovery.
◾
◾Using cloud services actually decreases your protection from search of data by law enforce-
ment. What you lose in the cloud is protection of warrant (requiring probable cause), guar-
antee of notice, and the ability to fight seizure beforehand. Government agencies state that 
they can subpoena your data from CSPs with no prior notice to you. A good CSP that 
directly receives legal process concerning customer or end-user data will inform the cus-
tomer unless they are legally prevented from doing so.
◾
◾Having data collocated with that of another organization that has a high threat profile can 
lead to a denial of service as an unplanned result from an attack targeted at the organization 
with the high threat profile.
◾
◾Organizations that need to comply with HIPAA or PCI DSS must be considered. HIPAA, 
e.g., requires both technical and physical safeguards for controlling access to data and this 
may create compliance issues for some CSPs.
Identity and Access Management
Issues
◾
◾Traditional network controls are no longer relevant in the cloud and need to be superseded 
by data security and identity based controls.
◾
◾Managing access control and governance within identity and access management (IAM) 
to meet business needs remains one of the major hurdles for enterprise adoption of cloud 
services.
◾
◾The proliferation of consumer technologies (like the iPhone) into the enterprise and steady 
dissolution of the network perimeter present greater risks in terms of protecting intellectual 
property (IP) and sensitive information as well as sustaining compliance.
◾
◾Web 2.0 technologies (like social networking) delivered via browsers are another catalysts 
that are accelerating the trend to consumerize IAM services. Protecting information that is 
mobile, dynamic, replicated, and scattered on a variety of media is becoming increasingly 
problematic.

Cloud Security  ◾  335
Security Management
Issues
◾
◾Customers have to rely on the CSPs for service instrumentation to measure and manage 
security, availability, and performance of services in the cloud.
◾
◾A lack of standards and weak capabilities from CSPs to help the customers place probes 
into the virtual environment has exacerbated cloud service management. In a virtualized 
environment where infrastructure is shared across multiple tenants (multitenancy), customer 
data is combined with that of other customers at every phase of the data life cycle (during 
transit, processing, and storage). Even if probes are installed at infrastructure layers available 
to the customer, resource bottlenecks that are visible may not be able to give the information 
necessary to perform root cause analysis.
Privacy
Issues
◾
◾Cloud computing is facing a huge challenge in terms of how to deal with cross-border data 
flows. This involves a number of foreign jurisdictions and complexities developing due to 
conflicting rules among foreign governments (or states within the United States). An organi-
zation may be able to define where (which country) it would like to have its data stored and 
processed, but to determine which specific server or storage device will be used is problem-
atic due to cloud computing’s dynamic nature.
◾
◾Storage devices are not always sanitized or destroyed, especially as it relates to virtual storage 
devices (where storage is constantly being reused).
◾
◾Multiple privacy laws and requirements such as the European Union and U.S. Safe Harbor 
Program require knowledge of where data is stored at all times. This requires CSPs to store 
data on servers in specific jurisdictions to minimize legal risk.
◾
◾Data protection and privacy policies need to be applied to data and should follow through 
the data’s life cycle to ensure that the original commitments are met and to create account-
ability and knowledge of what happens to data.
◾
◾Accountability for privacy protection falls on the organization that collected the informa-
tion in the first place. To accomplish this, organizations must understand the privacy and 
security policies and the security architecture of the service that the CSP is delivering to have 
the right contracts in place to monitor CSP compliance.
Audit and Compliance
Issues
◾
◾The question here is which compliance framework should a CSP adopt to satisfy customers 
and manage its own risks. There is a growing industry concept to develop an IT governance, 
risk, and compliance (GRC) program. The goal is to develop a uniform IT compliance 
framework that uses a number of tools such as ISO 27001, PCI, COBIT, ITIL, NIST, 
and others to automate the process. Adoption of a GRC will allow the CSP to deliver more 
reports to reflect standards relevant to the customer in a more timely manner.

336  ◾  Information Security Management Handbook
◾
◾Most SaaS vendors do not provide the level of audit logs necessary to recover from a serious 
breach. The customer needs to know who logged in, from where, and when. It also needs 
to be known what admin actions were taken and what documents/data were accessed. The 
other question is who can/should access log data and under what controls? Also, if cloud 
users can access log files, are there privacy issues to be concerned with?
◾
◾Because of the lack of transparency, auditing can be difficult if not impossible. If some-
thing goes wrong or there is unauthorized access, it could be difficult to conduct a forensic 
investigation.
Other Issues and Considerations
◾
◾In terms of vulnerability management, the patch management cycle is not in the customer’s 
control. This lack of control leaves the cloud customer unable to close vulnerability gaps on 
their own terms.
◾
◾Relationships with CSPs can be short in duration and the ability to rapidly and practically 
verify physical controls of multiple CSPs becomes difficult to achieve.
◾
◾In the cloud, a single server can host multiple applications of many different users. Any of 
the applications on the server are vulnerable, and it may lead to a compromise or unavail-
ability of other applications as well. Also, a large number of ports may be open, providing a 
larger network level attack surface.
◾
◾Using virtual machines (VMs) to run different OS instances on a single hardware platform 
opens up a new attack vector because VM flaws can compromise the server and therefore 
affect many customers.
◾
◾Basically, CSPs develop and deliver services as they seem fit as there is no industry standards 
to guide them.
◾
◾Business units, developers, and corporate departments have started using cloud services 
without the knowledge of the IT department. The added productivity and convenience 
are being realized without regard for policy, and some users do not want to wait until IT 
provides them with a private cloud. These moves can compromise continuity, security, and 
compliance.
Now that we know something about the current security issues with cloud computing, we can 
look at best practices and other ideas that need to be employed to deal with the issues and make 
the cloud more secure.
Security Best Practices and Suggestions for Securing the Cloud
The following are a number of best practices covering strategic and policy issues (governance 
domains) as well as tactical issues (operational domains) within the cloud environment. They are 
based on the Cloud Security Alliance’s Security Guidance for Critical Areas of Focus in Cloud 
Computing and are organized into the following domains:*
*	Cloud Security Alliance. Security guidance for critical areas of focus in cloud computing. Version 2.1. December 
2009.

Cloud Security  ◾  337
Governance and Enterprise Risk Management
This deals with the ability of the organization to govern and measure enterprise risk introduced by 
cloud computing. Customers must be able to assess the risk of the CSP and the responsibility to 
protect sensitive data when the CSP and user may be at fault.
Recommendations
◾
◾There is an increased need to scrutinize the security capabilities of the CSP, application of 
security controls, and ongoing detailed assessments and audits to ensure that requirements 
are continuously met.
◾
◾CSPs and customers need to collaborate on information security governance to achieve 
agreed-upon goals to support the business mission and information security program regard-
less of the service or deployment model.
◾
◾The CSP’s security governance processes should be assessed for sufficiency, maturity, and 
consistency with the customer’s information security management processes. CSP security 
controls should be risk-based and support the management processes.
◾
◾Collaborative governance structures and processes need to be incorporated into service 
agreements.
◾
◾Security departments need to be engaged during the development of SLAs to ensure that 
security requirements are contractually enforceable.
◾
◾Metrics and standards for measuring performance and effectiveness of information security 
management should be established before moving into the cloud. The metrics and standards 
should be documented and auditable.
◾
◾The risk management approach should include identification and valuation of assets; identi-
fication and analysis of threats and vulnerabilities and their potential impact on assets; anal-
ysis of the likelihood of events/scenarios; management of approved risk acceptance levels and 
criteria; and development of risk treatment plans with the option to control, avoid, transfer, 
or accept the risk. Risk assessment between the customer and CSP should be consistent in 
terms of impact analysis criteria and the definition of likelihood.
◾
◾The CSP’s incident management, business continuity, and disaster recovery policies, pro-
cesses, and procedures should be assessed and should include a review of colocation and 
backup facilities. Facilities should be geographically dispersed and guarantee failover and 
redundancy in case a data center becomes unavailable.
◾
◾Customer business continuity and disaster recovery plans should include scenarios for loss 
of CSP services and for loss of CSP third-party services and dependencies. Testing of these 
scenarios should be coordinated with the CSP.
Legal and Electronic Discovery
This involves protection requirements for information and computer systems, security breach 
disclosure laws, regulatory requirements, privacy requirements, international laws, etc.
Recommendations
◾
◾Customers and CSPs must have a mutual understanding of the roles and responsibilities 
related to electronic discovery regarding activities such as litigation hold, discovery searches, 
providing testimony, etc.

338  ◾  Information Security Management Handbook
◾
◾Data in the custody of CSPs must receive equivalent guardianship as in the hands of the 
original owner.
◾
◾Knowing where the CSP will host data is a prerequisite to ensure compliance with local laws 
that restrict cross-border flow of data.
◾
◾Security issues such as data breaches must be addressed in the SLA to clarify the commit-
ments of the CSP versus the customer.
◾
◾There should be a unified process between the CSP and customer for responding to sub-
poenas and other legal requests.
◾
◾Provisions should be detailed for recovering client data after the contractual relationship 
ends.
Compliance and Audit
This is concerned with maintaining and proving compliance in cloud computing. Compliance 
involves adherence to internal security policies as well as regulatory or legislative compliance 
requirements.
Recommendations
◾
◾A right to audit clause is needed especially when the CSP is providing services for which the 
customer has regulatory compliance responsibilities. The need for this could be reduced if 
the CSP is certified to ISO 27001.
◾
◾Customers should develop processes to collect and store compliance evidence including 
audit logs and activity reports, copies of system configurations, change management reports, 
and test procedure outputs. Depending on the deployment model, the CSP may have to 
provide much of this information.
◾
◾If the organization has input into the selection of security auditors and assessors, it is advis-
able to select someone that is “cloud aware” to make sure that they are familiar with cloud 
and virtualization challenges.
◾
◾A CSP should have a SAS 70 Type II audit statement at a minimum. Although it only 
ensures that controls are implemented as documented, the scope of the audit needs to be 
understood and it needs to utilize controls that meet customer requirements.
◾
◾If a CSP has not achieved ISO 27001 certification, it should at least demonstrate alignment 
with ISO 27002 practices.
Information Life Cycle Management
This looks at managing data that is placed in the cloud. The focus is on identification and control 
of data in the cloud as well as compensating controls to be used due to loss of physical control 
when moving data into the cloud. It is also important to determine who is responsible for data 
confidentiality, integrity, and availability.
Recommendations
◾
◾Customers should understand how integrity is maintained and compromise of integrity is 
detected and reported by the CSP. This same recommendation applies to confidentiality.

Cloud Security  ◾  339
◾
◾All specific controls used during the data security life cycle (create, store, use, share, archive, 
and destroy) need to be identified. A data security life cycle focuses on data security and not 
securing the database container that other database security models focus on. Focusing on 
securing the data minimizes reliance on security provided by the database, network, plat-
form, or places where the data is stored. Because the customer does not always know where 
the infrastructure is, where the data is located, or who has access, you need to account for 
the security of data as it moves into and through the cloud.
◾
◾Use SLAs to stipulate knowing where your data is and to know the geographic location of 
storage.
◾
◾The data owner should maintain a default denying all policy for both the data owner and 
CSP employees.
◾
◾Data must be encrypted at rest and in transit.
◾
◾Decommissioning procedures need to be put into place to sanitize media and destroy data. 
DoD 5220.22-M or NIST 800-88 guidelines and techniques for decommissioning can be 
used, but if the hardware device cannot be decommissioned, it should be degaussed or physi-
cally destroyed in accordance with industry standard practices.* This makes sure that data 
residue does not remain to become available to unauthorized parties.
◾
◾Identify trust boundaries throughout the IT architecture and abstraction layers. Ensure that 
subsystems only span trust boundaries as needed with appropriate safeguards in place to 
prevent unauthorized disclosure, alteration, or destruction of data.
◾
◾Customers should understand what techniques CSPs use to separate or isolate customers 
from one another.
◾
◾Customers need to understand how encryption is used on multitenant storage. Is there a 
system in place to make sure that different data owners do not have the same encryption 
key?
◾
◾Strong storage encryption should be used that renders data unreadable when storage is recy-
cled, disposed, or accessed outside of authorized applications, processes, and entities.
◾
◾Regular backup and recovery tests need to be performed to ensure logical segregation and 
controls are effective.
◾
◾CSP personnel controls need to be in place to provide for a logical separation of duties.
Portability and Interoperability
This focuses on the ability to move data/services from one provider to another or bringing it back 
entirely in-house. Issues surrounding interoperability between providers are also important here.
Recommendations
◾
◾The customer should understand how VM images can be captured and ported to new CSPs 
who may use different virtualization technologies.
◾
◾Customers should have access to system logs, traces and access to and billing of records from 
the legacy CSP.
◾
◾Options should be identified to resume or extend service with the legacy CSP should the 
new provider prove to be less than stellar.
*	Amazon Web Services: Overview of security processes, p. 9, August 2010.

340  ◾  Information Security Management Handbook
◾
◾Customers should understand the tools available for secure data transfer, backup, and 
restoration.
◾
◾The customer should understand how testing will be completed prior to and after migration 
to verify that services and applications are operating properly.
◾
◾It needs to be understood what metadata can be preserved and migrated.
Traditional Security, Business Continuity, and Disaster Recovery
This looks at how cloud computing affects operational processes and procedures currently in use 
to implement security, business continuity, and disaster recovery.
Recommendations
◾
◾CSPs should compartmentalize job duties, perform background checks, require/enforce 
employee nondisclosure agreements (NDAs), and limit employee knowledge of customers to 
that which is only needed to perform their job.
◾
◾Customers should perform on-site inspections of CSP facilities whenever possible.
◾
◾Recovery time objectives (RTOs) should be fully understood and defined in SLAs. This 
defines the maximum amount of time that loss of a critical process, resource, or function 
can be dealt with before it becomes a serious adverse impact.
◾
◾Recovery point objectives (RPOs) should also be fully understood and covered in SLAs. 
This is the maximum amount of data loss that can be sustained due to an event and the abil-
ity to go back to a “last known good” configuration.
◾
◾CSP business continuity programs should be certified or mapped to recognized standards 
such as BS 25999.
Data Center Operations
This concerns itself with how to evaluate a CSP’s data center architecture and operations. It 
focuses on helping users to identify common data center characteristics that could detrimen-
tally affect ongoing services as well as fundamental characteristics that can affect long-term 
stability.
Recommendations
◾
◾Data centers need to be designed for fault tolerance and securing data against a physical 
security breach, earthquake, fire, flood, loss of power, or other natural phenomenon. They 
should be built in clusters in various global regions and all data centers should be online and 
serving customers (no “cold” data centers).
◾
◾Data centers should be in nondescript facilities and physical access should be controlled at 
the perimeter and building ingress points by professional security staff using video surveil-
lance and other electronic means. Authorized staff should have to use two-factor authentica-
tion, and all visitors and contractors should have to present identification and be escorted 
through the facility at all times. Access should only be provided to those with a legitimate 
business need, and when there is no longer a need, access should be revoked immediately. 
All access to the facility should be logged and audited routinely.

Cloud Security  ◾  341
◾
◾Customers should understand CSP patch management policies and procedures and how 
these may impact their environments.
◾
◾CSPs should have standard continuous improvement processes in place.
◾
◾Customers should ensure that CSP support processes, procedures, tools, and support hours 
are compatible with their business needs.
Incident Response, Notification, and Remediation
This area is important as it looks at adequate incident detection, response, notification, and reme-
diation. It looks to address items that should be in place at both provider and user levels to ensure 
proper incident handling and forensics.
Recommendations
◾
◾Customers may have limited involvement with CSP incident response activities. Thus, cus-
tomers must understand communication paths to the CSP’s incident response team.
◾
◾CSP incident analysis and detection tools should be compatible with that of the 
customer’s.
◾
◾Proper risk management on systems and use of defense-in-depth practices are essential to 
reduce the chance of a security incident in the first place.
◾
◾CSPs should have the ability to deliver snapshots to customers on their entire virtual 
environment and should include firewalls, network switches, systems, applications, and 
data.
◾
◾Containment approaches focused on the CIA Security Triad are necessary.
◾
◾Remediation efforts need to be able to restore systems to earlier states. Remediation may also 
need to focus on forensic recording of incident data.
Application Security
This looks to secure application software running or being developed in the cloud. It also looks 
at whether to migrate or design an application to run in the cloud, and if so, on what platform 
(SaaS, PaaS, IaaS)?
Recommendations
◾
◾Managing and protecting application credentials and key materials are critical.
◾
◾Care should be taken with management of files used for application logging and debug-
ging as the location of the files may be remote or unknown and the information may be 
sensitive.
◾
◾Metrics should be used to assess the effectiveness of application security programs. 
Vulnerability scores and patch coverage should be looked at, as they can be indicative of the 
quality of application coding.
◾
◾Customers should obtain permission to conduct remote vulnerability assessments, including 
network/hosts and application vulnerability assessments. Many CSPs restrict these assess-
ments due to the CSP’s inability to distinguish them from an actual attack and to avoid 
potential impact on other customers.

342  ◾  Information Security Management Handbook
Encryption and Key Management
This relates to identifying proper encryption usage and scalable key management.
Recommendations
◾
◾Encryption should be used to separate data holding from data usage.
◾
◾Key management should be segregated from the CSP hosting the data, creating a chain of 
separation. This protects the CSP and the customer when required to provide data due to a 
legal mandate.
◾
◾When a CSP does perform key management, the customer should understand whether the 
CSP has defined processes for a key management life cycle (key generation, use, storage, 
backup, recovery, rotation, and deletion). It should also be determined whether each cus-
tomer has his/her own key set.
Identity and Access Management
This involves managing identities and leveraging directory services for access control. The focus is 
on the issues that will present when extending an organization’s identity into the cloud.
Recommendations
◾
◾Customers should modify or extend authoritative repositories of identity data so that it 
encompasses applications and processes in the cloud.
◾
◾Enterprises should authenticate users via their identity provider and establish trust with 
their Saas vendor by federation using Security Assertion Markup Language (SAML) 
or OpenID standards. Otherwise, one authentication system for the internal organiza-
tion system and one for the external cloud system may result and this may turn into an 
unworkable solution.
◾
◾Especially for IaaS deployment, a dedicated and secure VPN to the corporate network or 
federation may be a good idea.
◾
◾CSPs should consider supporting various strong authentication options such as one-time 
passwords, biometrics, digital certificates, and Kerberos.
Virtualization
This domain addresses the risks associated with multitenancy, VM isolation, VM coresidence, 
hypervisor vulnerabilities, etc.
Recommendations
◾
◾Customers should identify which types of virtualization a CSP uses if any. Not all CSPs 
or services use virtualization, and cloud computing does not necessarily equate with 
virtualization.
◾
◾Layered security controls should be used on virtualized operating systems to reduce depen-
dency on the platform provider alone.

Cloud Security  ◾  343
◾
◾Security controls other than the built-in hypervisor isolation internal to the VM must be 
understood. Intrusion detection and antivirus and vulnerability scanning should be consid-
ered. Secure by default configuration must be ensured.
◾
◾The integrity of any VM image originating from the CSP must be validated before using.
◾
◾The feasibility of segregating VMs and creating security zones by usage (desktop versus 
server), production stage (development, production, or testing), and placing sensitive data on 
separate physical hardware like servers, storage, etc., need to be considered.
◾
◾Reporting mechanisms need to be in place to provide evidence of isolation, and alerts need 
to be raised if isolation is breached.
Additional Security Suggestions and Best Practices 
for CSPs by a CSP
These are some of the security suggestions for CSPs based on one of the largest CSP’s (IBM’s) 
Cloud Security Guidance:*
Build and Maintain a Secure Cloud Infrastructure
	
A.	Install and maintain firewall configurations:
◾
◾There should be a formal change management process for firewalls that results in formal 
approvals and acceptance of firewall changes.
◾
◾Firewalls should be placed at each external network interface and between each security 
zone.
◾
◾The default setting for ports is to deny access.
◾
◾There should be a quarterly assessment of firewall and router configurations and rule 
sets.
◾
◾Firewalls should be deployed that deny access from untrusted sources or applications 
and log these events.
	
B.	Do not use vendor supplied defaults for passwords and other security parameters:
◾
◾Change vendor supplied passwords before activating a server or prior to creation of VM 
images.
◾
◾Remove all unnecessary applications, scripts, or modules from the virtual system.
	 C.	Implement a physical environment security plan:
◾
◾Prevent unauthorized access to critical areas within facilities and access to physical assets 
and systems by unauthorized users.
◾
◾Ensure adequate natural disaster protection.
	 D.	Protect hybrid communications:
◾
◾Ensure that access to corporate infrastructure is only possible through secure 
communications.
◾
◾Ensure that communications between remote and corporate infrastructure are encrypted.
◾
◾Ensure that communications can only originate from the corporate infrastructure.
◾
◾Make provisions for protected out-of-band communications in event of an emergency.
*	Buecker, A., et al., Cloud security guidance: IBM recommendations for the implementation of cloud security. 
IBM Corporation, 2009.

344  ◾  Information Security Management Handbook
Ensure Confidential Data Protection
	
A.	Securely destroy all nonessential personally identifiable information (PII):
	
	 Mask displayed PII when appropriate (like only showing a subset of social security numbers, 
for example).
◾
◾Render PII unreadable whenever stored.
◾
◾Ensure that PII is not recorded in log or other system files.
	
B.	Protect intellectual property (IP):
◾
◾Risk assessment should include IP that may be exposed.
◾
◾General counsel should ensure that SLAs cover protection of IP.
◾
◾Organizations should obscure IP through encryption so that malicious users cannot 
reverse engineer information.
Protect Encryption Keys from Misuse or Disclosure
◾
◾Keys should be periodically recycled on an annual basis.
◾
◾There should be a method for destruction of old or inactive keys.
◾
◾There should be prompt disposal and replacement of compromised keys.
◾
◾All access to keys should be logged.
◾
◾There should be split-knowledge and establishment of dual control of keys.
Implement Strong Access and Identity Management
	
A.	Implement a least privilege model:
◾
◾Regularly evaluate users’ access lists to ensure that only appropriate levels of access are 
granted and only personnel with authorized need have access to systems.
◾
◾Restrict access based on need to know.
◾
◾Verify and check identity of all users against an approved access list.
◾
◾Implement multifactor authentication to all systems and administrator systems.
	
B.	Implement federated identity management:
◾
◾Ensure that federated identity management is implemented when bridging cloud 
environments.
Establish Application and Environment Provisioning
	
A.	Implement a program for application provisioning:
◾
◾Design and implement a program for provisioning images and applications.
◾
◾Ensure that application and virtual image deprovisioning activities are logged.
◾
◾Ensure that all changes to access of virtual images and applications are logged.
◾
◾Destroy outdated or invalid virtual images.
Implement a Governance and Audit Management Program
	
A.	Implement a privacy management program:
◾
◾Create a program/process for notification of appropriate parties in the event of breach.
	
B.	Implement mechanisms for audit capture and management:
◾
◾Create policies for capture and retention of legal and regulatory documents.

Cloud Security  ◾  345
Implement a Vulnerability and Intrusion Management Program
	
A.	Implement and regularly update antivirus/antispyware and IDS/IPS:
◾
◾Deploy antivirus software on all supported systems that could be exposed to virus or 
spyware attacks.
◾
◾Confirm that IDS/IPS are properly configured to alert the personnel of suspected 
compromises.
Maintain Environmental Testing and Validation
	
A.	Implement a change management process:
◾
◾The change management process must be formal and documented.
◾
◾The process should follow a configuration change management process for systems and 
software that includes change request logging, an impact assessment statement, and a 
process for rollback to a prior state.
	
B.	Implement a program for secure application development and testing:
◾
◾Validate all security patches prior to production deployment.
◾
◾Ensure that test and production environments are separated.
◾
◾Ensure separation of duties between test, development, and administration personnel.
◾
◾Ensure that all test accounts and custom accounts are removed prior to production 
activation.
◾
◾Ensure that trace and debug statements are removed from production code.
◾
◾Ensure that audit trails are enabled for all events:
−
−Invalid login attempts
−
−Administrator access attempts
−
−Events involving access to confidential or PII data
−
−Retention of audit trail history for at least a year
−
−Perform pen testing at least every 90 days to detect any vulnerabilities.
Current Developments and Needs for the Future 
of Cloud Computing
The following are a few of the developments that need to take place or will take place to further 
expand cloud computing and further ensure its future success:*
	
A.	Cloud Services Architect: This is a new IT role in the organization that looks at what applica-
tions and services will go into the cloud based on the business case and the capabilities of 
the cloud. This role will help businesses to curtail the business units that go directly to the 
cloud for services without involving the IT Department.
	
B.	Information Authority: Today, when connecting two networks without completely merging 
them, you need multifactor authentication, identity brokers, and access brokers. An infor-
mation authority would act as a central repository for securing data and control of appli-
cations. It makes identity management part of the application delivery network through 
*	Mather, T., Kumaraswamy, S., and Latif, S. Cloud security and privacy. O’Reilly Media, pp. 260–266, 
September 2009.

346  ◾  Information Security Management Handbook
establishment of a trust fabric. Today, each new application or service requires a new set of 
credentials and privileges leading to inconsistent user rights and a need to remember multi-
ple passwords. Moving identity into a central point in the network forms the necessary trust 
fabric that delivers single sign-on (SSO) spanning all organizational users and resources 
across SaaS and IaaS environments.
	 C.	Web Security: Today, tools used to defend against hackers are software installed on each 
device or appliance on the premises. For this to work, things must be constantly updated. 
And, it takes time to discover vulnerabilities, create signatures, and test and deploy patches, 
so you are always going to have a gap in security. With Web security, the thought here is that 
the threats are moving to the Web (directed at Web-based applications) so it makes sense 
that the protections are placed there. It looks at placing the protections closer to the threats 
to stop them before they ever reach the corporate network. It requires a Web services security 
package that includes antimalware, spyware, and phishing controls; Web content and URL 
filtering; acceptable use policies (which users can access which resources); and the ability to 
access using a browser without first accessing the corporate network (allowing for scaling 
without placing things on client machines or having to use VPNs).
	 D.	Security-as-a-Cloud Service: This will be a growing area because there will be a continued 
shift in information security from in-house to outsourced work, and information security 
will accelerate in need and complexity to go along with the growing adoption of cloud com-
puting. As you can see from all of the suggestions and recommendations in this chapter, this 
will become a monumental task for companies to handle all of the security implications of 
cloud computing, and they may not have all of this expertise in-house. Therefore, they will 
have to contract with some external firms that have the resources and expertise to deal with 
all of the security implications related to cloud computing.
	
E.	Open Standards: These will be necessary to provide greater transparency to organizations 
so that it is clearer and agreed upon, as to who provides (organization or CSP or multiple 
CSPs) certain security capabilities and safeguards. And, there also needs to be some stan-
dardization across CSPs as to who provides certain security capabilities specific to certain 
offerings in the SPI Delivery Model. Open standards will also facilitate unified management 
functions across CSPs through the development of cloud resource management protocols, 
packaging formats, and security mechanisms to facilitate interoperability.
	
F.	Global Privacy Standard: Today, it is a challenge for a CSP to understand international pri-
vacy laws to understand how data can be transferred from one part of the world to another. 
But, it is essential for them to understand these different jurisdictional laws because their 
customers depend on this to meet their data compliance needs. Development of a global 
privacy standard would help provide consistency across jurisdictions and would erase many 
of the challenges and guesswork that take place in terms of dealing with where data resides.
	 G.	Uniform Compliance Framework: Today, a CSP defines many of its own processes and con-
trols, but as CSPs connect to each other and provide cross-CSP solutions, a uniform com-
pliance framework will become necessary to ensure that appropriate security measures are 
being consistently applied. The adoption of the previously mentioned GRC program is a 
good starting point for gaining agreement on the adequacy of security measures being con-
sistently applied and based on standards relevant to the CSP and its customers.
	 H.	Predicate Encryption: Predicate encryption involves the ability for various individuals to 
selectively decrypt data without having to decrypt all of the encrypted data. This area is still 
being researched but shows promise in providing data security and storage in high volume, 
multitenancy, cloud computing environments.

Cloud Security  ◾  347
These are a few of the efforts that will make cloud computing even more appealing and more 
secure, compliant, and resilient for organizations looking to pursue a more affordable and scalable 
business model for their future needs and requirements.
Conclusion
Cloud computing is making a huge impact on how companies are conducting business as they 
look to serve their internal constituents while trying to drive down costs. And, cloud computing 
is poised to explode even more. But, the major hurdle that could prevent cloud computing from 
reaching its full potential is security. Organizations must make sure that the cloud is at least 
as secure as their own corporate networks, otherwise the cloud business model does not make 
sense, no matter how affordable it may be. The burden for dealing with security challenges in the 
cloud does not just fall on the customer; however, it requires cooperation between the customers 
and the CSPs and between and across CSPs. Only with proper security practices, further future 
developments and tightly coupled coordination between the customers and the providers can 
cloud computing reach its full potential and become the future blockbuster technology and busi-
ness model that it can become.
Bibliography
	
1.	Mather, T., Kumaraswamy, S., Latif, S. Cloud security and privacy. O’Reilly Media, September 2009.
	
2.	Cloud Security Alliance. Security guidance for critical areas of focus in cloud computing. Version 2.1. 
December 2009.
	
3.	Jansen, W., Grance, T. Guidelines on security and privacy in public cloud computing. National Institute 
of Standards and Technology. U.S. Department of Commerce. Draft Special Publication 800-144.
	
4.	Citrix OpenCloud Access. White Paper. www.citrix.com.
	
5.	IBM Corporation. Seeding the clouds: Key infrastructure elements for cloud computing. February 
2009.
	
6.	Dell Tech Dossier. A revolutionary approach to cloud building. June 7, 2010. www.networkworld.com/
news.
	
7.	Stratecast. Overcoming obstacles to cloud computing. February 2011. www.frost.com.
	
8.	Kraieski, E. The hybrid enterprise data center. InformationWeek Analytics, November 2010. Analytics.
informationweek.com.
	
9.	Microsoft Global Foundation Services. Securing Microsoft’s cloud infrastructure. May 2009.
	 10.	Google Apps for Business. www.google.com/apps/intl/en/privacy/.
	 11.	Google, Inc. Security Whitepaper: Google Apps messaging and collaboration products. 2010.
	 12.	Olden, E. Architecting a cloud-scale identity fabric. Symplified. Published by IEEE Computer Society.
	 13.	Amazon Web services: Overview of security processes, August 2010. http://aws.amazon.com/security.
	 14.	Howarth, F. Why Web security is best served in the cloud. Bloor Research, February 2010.
	 15.	National Institute of Standards and Technology. Cloud architecture reference models. NIST 
CCRATWG-004.
	 16.	Microsoft Corporation. The economics of the cloud. November 2010.
	 17.	Babcock, C. Ready for this?: Cloud computing will force the IT organization to change. InformationWeek 
Analytics, November 30, 2009. www.informationweek.com.
	 18.	Microsoft Security Development Lifecycle. Security considerations for client and cloud applications, 
November 4, 2010. www.microsoft.com/sdl.
	 19.	IBM Global Technology Services. Leveraging security from the cloud: The who, what, when, why and 
how of cloud-based security services, 2010.

348  ◾  Information Security Management Handbook
	 20.	IBM point of view: Security and cloud computing. Cloud Computing White Paper, November 2009.
	 21.	Buecker, A., Lodewijkx, K., Moss, H., Skapintez, K., Waidner, M. Cloud security guidance: IBM rec-
ommendations for the implementation of cloud security. IBM Corporation, 2009. Ibm.com/redbooks.
	 22.	Red hat cloud foundations: Cloud 101. www.redhat.com.
	 23.	Cloud Computing. en.wikipedia.org/wiki/Cloud_computing.
	 24.	Unleashing cloud performance: Making the promise of the cloud a reality. Riverbed Technology 
Whitepaper, 2009.
	 25.	Lane, A. Database lockdown in the cloud. Dark Reading, March 9, 2011.
	 26.	Armin, J. Hacker deploys cloud to smash passwords. January 17, 2011. www.internetevolution.com.
	 27.	IBM Corporation. Cloud services may be a game-changer for business. 2010. www.304.ibm.com/
businesscenter/cpe/html0/190102.html
	 28.	Cloud computing security. www.oyyas.com/articles/cloud-computing-security.
	 29.	Cloud computing security. en.wikipedia.org/wiki/Cloud_computing_security.
	 30.	Becherer, A., Stamos, A., Wilcox, N. Cloud computing security: Raining on the trendy new parade. 
Blackhat USA. ISEC Partners, 2009. www.isecpartners.com.
	 31.	NIST Cloud Computing Reference Architecture and Taxonomy Working Group. A strawman model. 
National Institute of Standards and Technology, January 3, 2011.
	 32.	Badger, L., Grance, T. Standards acceleration to jumpstart adoption of cloud computing (SAJACC). 
National Institute of Standards and Technology, May 20, 2010. cloudcomputing@nist.gov.
	 33.	Roiter, N. Cloud services redefining rules for regulatory compliance. Dark Reading, February 17, 2011.
	 34.	Roiter, N. RSA announces identity and compliance profiling services for the cloud. Dark Reading, 
February 14, 2011.
	 35.	Lane, A. Securing databases in the cloud. Dark Reading, February 2, 2011.
	 36.	Muzilla, C. True PaaS: What users need to succeed in the cloud. RedHat, Inc., September 22, 2010.
	 37.	Murphy, C. FedEx CIO explains the real power of the cloud. Informationweek.com, February 14, 
2011.
	 38.	Mell, P., Grance, T. The NIST definition of cloud computing. Version 15. National Institute of 
Standards and Technology, October 7, 2009.
	 39.	Knode, R. Cloud security report out. National Institute of Standards and Technology. cloudcomput-
ing@nist.gov.
	 40.	IBM. Effective storage management and data protection for cloud computing. IBM Software Thought 
Leadership White Paper, September 2010.

349
Chapter 24
Enterprise Zones of Trust
Sandy Bacik
Security is a critical component of the development of any enterprise security architecture. Ad 
hoc approaches to developing conceptual security architectures do not work and are inefficient, 
inconsistent, and miss critical details that are important to system design. As such, there is a criti-
cal need to use established frameworks, methodologies, procedures, and best practices to ensure 
that there is a holistic approach to the development of security architectures so that the security 
architectures are effective, efficient, optimal, consistent, and well thought out. Without a holistic 
approach and without an enterprise conceptual architecture, the enterprise may not have trusts 
built into the framework.
Using an enterprise security architecture framework provides comprehensive traceability to 
enterprise goals and objectives, established business, and use cases and requirements and avoids 
recreating the wheel. A phased approached with increasing levels of granularity and specificity 
will develop a conceptual security architecture that is robust and adaptable to any utility environ-
ment. The security conceptual architecture will be the translation of the enterprise business vision 
and business requirements into a defense-in-depth strategy. Basic questions and issues that will be 
addressed when using an established enterprise security architecture framework are:
	
1.	What goals and objectives were used to assist in developing use cases and security 
requirements?
	
2.	What business and technical requirements were used in generating security services?
	
3.	How can this conceptual architecture complement and enhance existing enterprise architec-
ture and processes?
	
4.	Has an overall design philosophy to ensure that security is “baked in” from the start of the 
life cycle been determined?
	
5.	How can we identify all system components to ensure that security services are implemented 
throughout the enterprise where necessary?
	
6.	How do we ensure the effectiveness and secure operation of enterprise system components?
	
7.	How do we ensure efficient operation around security for the integration of enterprise system 
components?

350  ◾  Information Security Management Handbook
	
8.	How is the assurance of the interoperability and integration of security services within the 
overall enterprise system maintained?
	
9.	How to ensure that security does not degrade the performance of the overall enterprise 
system?
	 10.	How to ensure that security services are doing what they are intended and designed to do?
	 11.	How to ensure that, once implemented, the enterprise system is being operated properly and 
securely?
Using an enterprise security architecture framework as a foundational structure can be the 
impetus in developing a broad range of different security architectures. An enterprise security 
architecture reference model and framework will aid in designing a target state around security for 
the enterprise by identifying essential building blocks and ensuring that those building blocks for 
the smart grid actually fit together. By establishing the baseline processes for what information is 
being created, transmitted, and stored and by identifying the end and middle points of processes, 
zones or domains of trusts can be established.
Understanding and Modeling Trust
Consider a simple model of doing an online transaction with the following steps:
	
1.	A flower merchant has flower arrangements to sell online and advertises them on the Internet.
	
2.	The Web interface allows a customer to browse the arrangements to fit an occasion.
	
3.	The customer selects an arrangement on the Web interface and places an order.
	
4.	The customer makes an electronic payment through the Web interface by sending a digitally 
signed authorization message to use his/her credit card.
	
5.	The Web interface places the order to create a financial transaction, a flower arrangement, 
and a delivery entry.
As you review this transaction, what needs to be protected? What business functions are 
required? What security functions need to be part of the business functions? What functions 
does security serve for this transaction? All of these answers can be summed up into a single 
word—TRUST.
The key security-related issue in any business or security transactions or any relationship 
between two entities is trust. And in many ways, security transactions must have two-way trust. 
Using the above example, let us examine the trust characteristics. The customer must trust the 
flower merchant to:
◾
◾Offer flower arrangements for a good quality at a good price
◾
◾Actually deliver the proper quality order to the proper address, once payment has been 
received
◾
◾Not repudiate the payment receipt that has been received
◾
◾Dispatch the quality order on the proper date and time
◾
◾Accept a return of the flower arrangement and refund the money, if the flower arrangement 
does not meet the expectations once it is delivered and seen
◾
◾Handle after sale complaints about the quality of the flower arrangement and quality of the 
delivery service.

Enterprise Zones of Trust  ◾  351
The flower merchant must trust the customer to:
◾
◾Pay for the flower arrangement and have enough credit to cover the price
◾◾Not make false claims about the quality of the flower arrangement and quality of the delivery 
service
◾
◾Not repudiate the flower arrangement order that has been ordered by the customer
◾
◾Not repudiate receipt of the flower arrangement delivered to the customer
◾
◾Not repudiate the credit payment authorization.
This is not an exhaustive list, but it shows some basic trust elements needed in a transac-
tion between entities and that the trust elements are multifaceted. A security professional must 
understand that trust is an attribute of relationships and transactions between entities. A security 
professional must also understand that levels of trust vary greatly from one transaction to and each 
transaction is unique.
Identifying and Protecting Trust Relationships
Analyzing each transaction will allow the security professional to identify a series of one-way trust 
relationships in the transactions, which will make building trust models easier. As a security pro-
fessional, you will develop and implement technical and procedural solutions to protect these trust 
relationships. In the above example with the customer and the florist, the customer must trust and 
be convinced of that trust that the florist has implemented the technical and procedural solutions 
to protect the identity of the customer, protect the credit card information of the customer, and 
deliver the appropriate order to the customer, to name a few items. The florist becomes a trust 
broker. The florist becomes the responsible party to offer remediation, should the transaction go 
wrong. The florist, the trust broker, takes responsibility for the trust and liability of the transac-
tion. There is also an implied transitive trust. The customer must trust the florist to perform the 
credit card transaction. The florist trusts a credit card processing firm to execute the transaction 
properly. The customer then has a transitive trust to the credit card processing firm.
Depending upon the transaction content, different defense-in-depth technologies and pro-
cesses will be put in place. The above described transaction with the trust and transitive trust 
models can be applied to the larger and more complex transactions within the enterprise.
Establishing Zones/Levels of Trust
There are different zones and levels of trust for different and more complex transactions. More 
specifically, the level of trust applied to a transaction will depend upon the trust of the endpoints 
of the transaction. The security professional designing the architecture will need to answer:
◾
◾How much validation is done regarding the identity of the endpoint?
◾
◾How much verification of trust is being carried out within the transaction?
Many times, verifying the credentials or information within the transaction involves transitive 
trust in a third party. The stronger the process of validation and verification of the identity and 
transaction content, the higher the level of trust.

352  ◾  Information Security Management Handbook
A security professional architecting security will establish security domains. A security domain 
is a set of security elements subject to a common set of security controls. A security element is an 
object such as a field, record, file, database, system, or subsystem. The security controls express 
security requirements in general terms. Following the florist example, all customer accounts must 
have an established account with a password and a valid phone number for confirmation. It is the 
florist who is responsible for establishing the security controls for the requirement. This will be a 
combination of procedure and technology implementations.
Zones of trust are established based on the enterprise asset value. The security controls imple-
mented establish the trusted entities and endpoints. The larger the asset value, the more or stronger 
security controls and a lesser amount of allowed devices, applications, locations, and accounts (see 
Figure 24.1). When an asset is more valuable, less resources have access to the asset. As an asset is 
more valuable, more trust is required for accessing or using the asset to ensure that the asset is not 
compromised. Setting up zones or segments for asset protection with access controls compromises 
a set of security controls for that specific zone of trust. These security controls are a set of activities 
to perform a specific transaction within an application at a location on a device using an account. 
The zone of trust security control provides detection and alerting mechanisms when a security 
control is violated. Depending upon the zone and the asset value, the monitoring, detecting, and 
alerting mechanisms are higher in priority.
◾
◾An untrusted zone is an area where information has a limited value and can be accessed by 
anything by any account from any location. An untrusted zone has a high risk of attack and 
compromise. Access from this zone must be highly controlled. An example of an untrusted 
zone might provide limited access to enterprise resources, such as corporate e-mail.
◾
◾A selective trust zone provides more protection than the untrusted zone. Selective trust 
zones do not contain critical data or highly valuable assets. An example of a selective trust 
zone might provide the contractors or partners access to specific applications or data.
◾
◾A trusted zone provides the most protection for the enterprise’s critical assets. These assets 
are highly secured and locked down. Access to these resources is specifically controlled by 
account, location, application, and/or device. An example of a trusted zone might be admin-
istrative access to the network routing infrastructure.
Because of the asset values, a security professional must watch to ensure that a trusted 
entity that can misbehave without a security control violation is said to be unconditionally 
Trusted zones
Selective trust zones
Untrusted zones
Asset value
Stronger/
more
detailed
controls
Allowed
devices,
accounts,
locations,
applications
Figure 24.1  Zones of trust to asset value.

Enterprise Zones of Trust  ◾  353
trusted. Aligning the enterprise in zones of trust based on asset value provides a good way 
to right-size security control so the asset is used and accessed properly. Establishing zones of 
trusts for asset access and use allows for easier policy enforcement. By increasing detective 
controls and implementing aggressive corrective controls, we can mitigate the risk of allowing 
broader access to the less-trusted assets. The actual balance of preventative, detective, and 
corrective controls will vary depending upon the zone of trust. For example, in an untrusted 
zone, we allow broad access to a very limited set of assets and mitigate the risk by increasing 
detective and corrective controls.
As a security professional sets up security domains within the security architecture, trusts will 
need to be set up between security domains. Jointly agreed-upon security controls and communi-
cations for transactions between security domains will need to be established. Like documenting 
the transactions within a domain, the transactions must also be documented between domains. 
The security domains must negotiate a common set of security services and mechanisms, as well 
as the information that will be exchanged. The security professional will start by establishing the 
multidomain transaction endpoints and the transaction contents. Within the transaction layers of 
protection (defense-in-depth), controls will be placed around the information and transaction as 
it moves between the established domains.
To establish and continue to maintain zones of trust within security domains, the security 
professional must:
	
1.	Make sure there are explicit, detailed, and clear requirements for transactions
	
2.	Make sure the control of the transaction is explicit and ownership is defined
	
3.	Make sure there is a clear authority established for the transaction within each security 
domain
	
4.	Be prepared to develop smaller security domain, subdomains, for more complex transactions 
or transactions that have a need for additional layers of security
	
5.	When designing security controls and security control points, make sure all domain bound-
aries and interaction points are covered.
Lastly, remember that there is always a surrounding domain that is a “super-domain” and con-
tains all of the security domains that you have defined. This “super-domain” should be considered 
hostile with no security controls, no security authority, and no trusted security elements.
Conclusion
The security professional must be vigilant on the boundaries of the established security domains. 
Because as a boundary expands and contracts, the security controls must be trusted enough to 
monitor the changes and catch any misbehaviors from the endpoints or the transactions within a 
security domain and among the other defined domains.


DOMAIN
7
OPERATIONS SECURITY
Operations Controls


357
Chapter 25
Complex Event Processing 
for Automated Security 
Event Analysis
Rob Shein
Over the past 15 years, the same mantra has wound its way through the security industry, 
particularly the entities and offerings concerned with incident detection and response: “Collect 
More Data.” The problem is that although the means to collect and store that data has grown 
in both variety and scale (as have the sources of the data that can be collected), the means to 
analyze that data has not kept pace. As a result, what began as one or two IDS devices and/or 
firewalls providing data has turned into, in some cases, tens of thousands of endpoints sending 
their data to collection points. Everything from a high-end IPS down to the system logs of a 
low-end desktop at a receptionist’s desk can provide useful data, but the challenge is finding that 
data amidst the tremendously high noise background of just plain normal activity. Additionally, 
the amount of data being collected is so large in some environments that the current state of 
the art for event rule processing is no longer sufficient to detect the attacks that involve multiple 
components of activity in an enterprise.
Current commonly deployed rule detection engines use a very basic form of correlation, based 
primarily on streams of information. Firewall logs, IPS/IDS alerts, SNMP messages from antivi-
rus servers all are sent to a single point, which then watches for two pieces of data within a certain 
temporal proximity to each other according to a rule. If two such pieces of data come through 
the stream within a certain interval of time, then the rule fires, and an action takes place as a 
result. That action—e.g., checking to see if a buffer overflow directed at a device was actually 
successful—is largely manual in nature, done by humans at the speed of phone calls and the rate 
at which an e-mailed trouble ticket can be read and acted upon. As a result, in many large environ-
ments, it can take up to a week to determine if a security incident is real or just a false-positive, 
and in a week, an attacker can do a great deal to further strengthen his/her position in a targeted 
environment, as many have already begun to discover. The goal of the approach listed here is to 

358  ◾  Information Security Management Handbook
reduce that window of time, by automating the early responder activities using rule engines that 
can perform the kind of logical actions that humans do when performing early incident response.
To examine the nature of the problem, it is important to first establish the difference between 
the two types of rules being processed. The underlying rule engines define the nature of the rules, 
which in turn define the limitations and challenges of event processing that uses those rules. 
Significant changes to the rule engines also incur changes to the architecture, which has both 
advantages and challenges that will be discussed later.
Current methods are the equivalent to a person watching activity in a certain area with a rule 
that is labeled “Two people just got married,” with a definition based on witnessing two people—
a man in a tuxedo and a woman in a white wedding gown—emerging from a church and getting 
into a limousine. The problem with this is that a great many things can cause a false-negative. 
A marriage is between two people of the same gender, a variation in the theme of dress for the 
couple, or even failure to use a limousine as the mode of transportation away from the church 
will all cause the observing rule engine to fail to recognize a valid event. Conversely, although the 
definition of what would be observed can be loosened, this in turn will result in false-positives—
the very nature of which is so very resource-intensive from a process management perspective in 
the first place. What if the couple is wealthy and has emerged from their home to attend a cos-
tume party via limousine? What if it is a couple getting into their car to go home after attending 
a Sunday mass? This challenge is bad enough when the actors being observed are indifferent to 
observation; it becomes far more troublesome when the actors are aware of the risk of observation 
and wish to evade identification of their actions, as is the case with rules that intend to detect 
hostile activity on a network.
Imagine, instead, a rule system that works retroactively. Two individuals get into a vehicle of 
some sort and depart; this is the point of entry for the rule. From there, the observer asks, “What 
kind of building did they emerge from?” Or, more accurately, the observer asks a set of questions, 
including whether people threw rice at the couple, the nature of music heard from within the 
building they just came out of prior to getting into the vehicle, and many other things that might 
be indicative of a wedding. Furthermore, aspects of the rule may trigger deeper, more resource-
intensive investigative actions. These can be activities like walking up to a bystander who exited 
the same building as the couple to ask some basic questions about what transpired inside; this 
kind of activity would be too resource-intensive to perform every time a couple exited the build-
ing (it is safe to say that whomever kept asking random people such questions would be asked 
to leave, after all) but would be perfectly acceptable as a resolution effort in the face of enough 
evidence that a wedding had indeed taken place. This kind of conditional rule system uses what 
is known as “branching logic,” where the processing path of the rule will vary based upon what 
data is fed to the rule. This allows for iterative examination within a single rule, which in turn 
allows other approaches. A rule system like this can be tied to an orchestration engine that can 
do things like going forth and fetching data from non–stream-based sources (like the bystander) 
and returning the result for additional processing.
The kind of engine that runs rules of this nature is known as a Complex Event Processing 
(CEP) engine, and there are several companies that make such software. Tibco, Informatica, Aleri, 
and Vertica compete in the space, in different ways. A CEP engine does not exist on its own as a 
useful system, but instead must be coupled to a larger architecture in order to be effective. Part of 
that architecture must include an orchestration engine (also produced by companies such as those 
listed above) and adapters to accept and process data from outside sources.
What is important to remember is that the use of a CEP engine (and the complex rules that it 
can process) does not supplant or replace existing architecture. Instead, it supplements it, allowing 

Complex Event Processing for Automated Security Event Analysis  ◾  359
for automated fusion of data between existing silos of information. The architecture functions 
much like the command structure of a large naval vessel; the captain performs a decision-making 
process, while the executive officer delegates tasks and queries the sources of data. Commands 
pass down through the organizational structure to the different areas of shipboard operations—
damage control, flight operations, engineering, and so on—and in this manner, a single man can 
quite effectively maintain command and control of an aircraft carrier with over 5000 sailors under 
his command while projecting power over an area on the side of a continent. In the architecture 
described here, the CEP acts as the captain and the orchestration engine serves as the executive 
officer. An SOA-based infrastructure enables communications as would take place aboard the ship 
to different areas of the enterprise.
Now, to use this analogy in a computer security context, imagine the following scenario:
◾
◾An attacker performs a cache poisoning attack against the victim’s DNS server.
◾
◾The attacker then sends a series of e-mails to a subset of the victim’s population, containing 
a link that points to the same domain leveraged in the DNS cache poisoning attack.
◾
◾The DNS entry in the cache of the victim’s DNS server would point to a transparent proxy 
out on the larger Internet (controlled by the attacker) rather than the correct system; this 
proxy would return a browser exploit in return traffic to members of the targeted victim 
population and install a purpose-built piece of malware on their systems.
Now, in this scenario, the initial attack is quite noisy and easy to detect. Unfortunately, it also 
gives little indication as to the true intent of the attacker or the exact systems being targeted. To 
discern that, a lot of manual action is normally taken—especially because the disparate systems 
involved are usually run by separate departments within a larger enterprise. Such activities are 
done by trouble tickets, e-mails, and phone calls—many of which require the action of finding 
out who exactly to contact in the first place. This is the kind of laborious process that slows down 
the incident response.
Imagine, instead, there existed a complex rule that initiated once the DNS cache poisoning 
attack was detected, which in turn would extract the Fully Qualified Domain Name (FQDN) 
from the alert provided. Following up on that information, the CEP could query outbound proxy 
servers for all activity within a certain period of time (ranging from the initial detection of the 
DNS cache poisoning attack until the current moment) involving that FQDN; the list of internal 
hosts that would exist within that recordset is the list of systems that have been compromised. 
The user accounts of that proxy traffic would be the people who were tied to those systems, but 
this alone is not necessarily helpful information. To really get to the answer of who was targeted 
within the victim organization, the orchestration engine would trigger a query to find all inbound 
e-mails containing that FQDN; of these, there would be a specific population (if not a same set) 
of e-mails that originated from the attacker. The list of people who received this e-mail would be 
the list of people who were targeted. From this list, some information may be gleaned as to the 
attacker’s motive—why them? What would these people have in common, that would make them 
a valuable target, and to whom?
Without an automated process, the DNS cache poisoning attack would be just as obvious, 
but the different steps listed in determining the precise nature of the attack would all require 
manual intervention. Adding to the challenge would be that no single “pane of glass” would have 
access to all of the sources of data, so coordination and information requests via human-intensive 
means would be necessary to perform each step. And even then, the potential for human error or 
inconsistency—there are likely to be more than one outbound proxy server, e.g., and what if one is 

360  ◾  Information Security Management Handbook
missed?— gives the attacker the opportunity to maintain a degree of his/her control in the victim 
environment even after the incident is considered closed.
The orchestration engine enables automation of certain functions as well, including the defi-
nition of predefined courses of action. These, in turn, facilitate the simplification of frequently 
repeated tasks, using a flexible approach that can evolve as new technologies and methods are 
put into service. Another benefit to an automated approach to such incidents is the way it lends 
itself to the gathering of metrics. The workflow processes incorporated within this approach can 
themselves generate metrics to determine where further rules development is needed. If, for a fre-
quently occurring event, a nonstandard course of action has taken a significant percentage of the 
time, then that in turn indicates a potential need to define new courses of action within the work-
flow component of the architecture. Additionally, metrics can indicate where additional proactive 
security measures are lacking; the recurrence of certain kinds of security events, again and again, 
typically indicates a systemic weakness that should be addressed.
There are challenges to achieving this level of sophistication, however. The basis for the rules 
can be something of a challenge; the greater potential afforded by the rule engine also opens the 
door for enough possibilities that determining the right approach can be difficult. For this, the 
best approach is to start with automating what activities currently take place. Go for efficiency first 
and new capability later. The larger challenge will be in getting organizational buy-in to be able 
to consume data sources and in the effort needed to integrate those data sources into the overall 
system. As with most things, this is a question of organization, available skilled people, and coop-
eration more than technical difficulty.
In closing and summary, much of the current activity involved in dealing with security events 
revolves around repeated actions, which are (in organizations with mature security operations) 
fairly well-documented but difficult or impossible to automate using standard off-the-shelf secu-
rity technologies available today. The issue is one of rules logic; it is possible to document these 
activities on paper, but not possible to describe them with standard correlation rules. Use of a 
complex event processing engine in conjunction with automated orchestration changes makes it 
possible for an organization to not only simplify and automate such actions, but also accelerate 
the rate at which they are performed. Furthermore, the way in which they can be automated helps 
facilitate capturing statistics about which events still have poorly developed responses, which in 
turn can be used to drive evolution of the rules logic and corresponding response actions.

361
Chapter 26
Records Management
Sandy Bacik
As electronic storage gets larger and enterprise information continues to grow, records management is 
a key topic that needs to be discussed. A record is evidence of what an enterprise does. An enter-
prise captures its business activities and transactions—information. Records management main-
tains information storage of an organization from the time the information is created up to the 
information disposal, a systematic control of information. This may include classification, storage, 
preservation, and destruction of information. Records come in many formats, such as physical 
paper, electronic messages, Web site content, PDAs, flash drives, and databases, to name a few. 
When there is an issue, such as a lawsuit, all of these may be identified as discoverable, including 
copies that individuals have retained and any items prematurely destroyed.
All enterprise records are information assets and hold value for the enterprise. The enterprise 
has a duty to all internal and external stakeholders to manage these records to maximize prof-
its, control costs, and ensure effective and efficient enterprise operations. Effective and efficient 
records management ensures that the information asset is stored, retrieved, authenticated, and 
accurate. This all must be done in a timely manner. To ensure that the enterprise has an effective 
and efficient records management program requires:
◾
◾Establishing and following enterprise policies, standards, and procedures
◾
◾Identifying who is responsible and accountable for managing records
◾
◾Communicating and executing procedures consistently
◾
◾Integrating enterprise records management standards and process flows with all enterprise 
departments
◾
◾Preserving the enterprise history and identity
◾◾Identifying vital/critical records and establishing standards and procedures for business continuity
To begin with, all staff use records and information daily to:
◾
◾Deliver goods and/or services consistently with accuracy and integrity
◾
◾Perform daily business transactions and duties
◾
◾Comply with internal policies, standards, and procedures, as well as laws and regulations

362  ◾  Information Security Management Handbook
◾
◾Protect internal and external stakeholder interests
◾
◾Provide documentation for all enterprise projects for products and/or services.
Because the staff use information on a daily basis, it is each staff member’s responsibility to 
manage the records and information. In turn, each staff member has an important role in protect-
ing the future of the enterprise by creating, using, retrieving, and disposing of records in accordance 
with the enterprise’s established policies and procedures, as well as applicable laws and regulations.
An enterprise needs to address well-defined objectives to add value, either directly to the bot-
tom line or toward the achievement of the enterprise’s mission, vision, and values (goals and objec-
tives). Records management objectives can fall into one of three categories:
	
1.	Profit/cost-avoidance
	
2.	Moral, ethical, and legal responsibility
	
3.	Effective and efficient service.
Enterprise record management programs need to manage information assets to be timely, 
accurate, complete, cost-effective, cost-efficient, accessible, and useable.
Within most enterprises, records management programs are not the primary business func-
tion and usually do not generate income, and the following are important reasons to establish 
a records management program within the enterprise. (Adapted from “Ten Business Reasons 
for Records Management,” in Robek, M.F., Brown, G.F., and Stephens, D.O., Information and 
Records Management: Document‐Based Information Systems, New York: Glencoe, 1995.)
	
1.	To control the creation and growth of records: Despite the growth of portable and electronic 
media, paper records in enterprises continue to increase. An effective records management 
program addresses both creation control by limiting records generation and copying not 
required for business operations and records retention by destroying useless or retiring inac-
tive records. This can stabilize the growth of records in all formats.
	
2.	To reduce operating costs: Any recordkeeping requires administrative dollars for storage and 
filing equipment and spaces and the staff to maintain this.
	
3.	To improve efficiency and productivity: Time spent searching for missing or misfiled records is 
nonproductive. Good records management can help an enterprise enhance recordkeeping systems.
	
4.	To assimilate new records management technologies: When an enterprise knows what informa-
tion assets (records) are needed to be maintained, the enterprise can assimilate new tech-
nologies and take advantage of their benefits. When an enterprise invests in new systems 
and equipment without formal goals and objectives, the full potential of the systems and 
equipment will not be recognized and may not solve the root cause of the problems.
	
5.	To ensure regulatory compliance: Most countries have regulations for recordkeeping. Many 
times, these regulations can create major compliance problems for the enterprise due to dif-
ficulty in locating, interpreting, and applying the regulation. With formal records manage-
ment policies, standards, and procedures, compliance with regulations is made easier.
	
6.	To minimize litigation risks: Enterprise records management can reduce risks associated with 
litigation and potential penalties. Consistently applied records management can reduce 
liabilities associated with information/records disposal with a standard, systematic, and rou-
tine disposal during the course of business.
	
7.	To safeguard vital information: All enterprises should require a comprehensive program for 
protecting critical and vital records and information from a disaster, because every enterprise 

Records Management  ◾  363
is vulnerable to loss. Records management program can preserve the integrity and confiden-
tiality of the critical and vital records and information according to the “plan.”
	
8.	To support better management decision making: Enterprises that can present the most relevant 
and complete data first often win the decision or competition or can make better decisions. 
An enterprise records management program helps managers and executives ensure that the 
information is in the hands of the staff when they need it for what they need it for.
	
9.	To preserve the corporate memory: Enterprise files contain institutional memory, an irreplace-
able asset that is often not addressed. The enterprise records create background data for cur-
rent and future management decisions and planning. This history needs to be preserved for 
effective and efficient future enterprise activities.
	 10.	To foster professionalism in running the business: In an enterprise that is messy, files, papers, 
boxes, and equipment displayed in an unorganized manner create a poor working environ-
ment and culture. This unorganized display may change the perception of the customers and 
the public to something unwanted. This perception can also change the moral of the staff, 
though hard to quantify in cost–benefit terms, may be among the best reasons to establish a 
records management program.
How would an enterprise start with developing record management requirements? The enter-
prise must create and preserve adequate and proper documentation of enterprise activities to 
support operational needs and allow accountability to ensure complete documentation, records, 
including those generated electronically with automated applications. At a minimum, the records 
management system shall include the following capabilities:
◾
◾Proper identification of originators
◾
◾Proper identification of recipients
◾
◾Appropriate dates (creation, storage, update)
◾
◾Any other information needed by the enterprise to meet business requirements
◾
◾Information generated by automated applications shall be copied to a recordkeeping system 
where they are maintained for as long as needed, such as data flows
◾
◾Complete identification documentation, including originators, recipients, appropriate dates, 
and other information necessary for enterprise business requirements
◾
◾A capability to organize and index information to properly preserve, retrieve, use, and dis-
pose of information, including different disposal schedules
◾
◾Shall be accessible to all appropriate staff using access control mechanisms
◾
◾Shall have a manual or automated system to collect, organize, and categorize records to 
facilitate their preservation, retrieval, use, and disposition
◾
◾Shall provide required instruction for what to do with the records that are no longer needed 
for business. This set of instructions are sometimes called a records destruction schedule or 
records retention schedule.
To start a records management program, definitions for information classification need to be 
established. An enterprise can start with something similar to the following for an easy start to 
information classification for records management:
◾
◾Confidential: This classification applies to less sensitive information that is intended for use 
within the enterprise. Its unauthorized disclosure could adversely impact the enterprise, its 
partners, its employees, the citizens, and/or its customers. Information that some people 

364  ◾  Information Security Management Handbook
would consider to be private is included in this classification. Examples include employee 
performance evaluations, call and dispatch information, and internal audit reports.
◾
◾For internal use only: This classification applies to information that should not be distrib-
uted to anyone outside the enterprise and can be distributed to others within the enterprise. 
Although its unauthorized disclosure is against policy, it is not expected to seriously or 
adversely impact the enterprise, its employees, its stockholders, its business partners, and/or 
its customers. Examples include the enterprise telephone directory, manufacturing produc-
tion schedules, training materials, and policy manuals.
◾
◾Public: This classification applies to information that has been explicitly approved by the 
enterprise management for release to the public. By definition, there is no such thing as 
unauthorized disclosure of this information and it may be freely disseminated without 
potential harm. Examples include advertisements, job opening announcements, and press 
releases.
Although this chapter cannot tell the enterprise what specific technology to select and imple-
ment, what follows is a sample enterprise records retention policy and standard.
In conclusion, the enterprise records management does not have to be elaborate; it needs to 
cover the business and legal requirements to ensure that business operations continue regardless 
of the situation.
Sample Records and Information Policy
Policy: It is MyCompany (MYC) policy to maintain a companywide records and information 
management program to ensure appropriate retention, protection, maintenance, and disposition 
of all records, regardless of format or media.
Scope: This policy applies to all employees, contractors, consultants, temporaries, and other 
workers at MYC, including those workers affiliated with third parties who access MYC company 
network asset devices. Throughout this policy, the word “employee” will be used to collectively 
refer to all such individuals. The policy also applies to all computer and data communication 
systems owned by and/or administered by MYC. The company will establish asset management 
programs and support infrastructure to optimize the company asset values. Employees are aware 
that effective management of the company assets under their direct control is closely linked to 
expected performance.
Definition: A record is defined as any written, recorded, or graphic material generated or 
received in any form: paper, electronic, drawing, photograph, microfilm, diskette, magnetic 
tape, optical disk, voice mail, electronic mail, or other data compilation from which informa-
tion can be obtained, or any printed copy that has sufficient information value to warrant its 
retention. A record can contain information from which decisions are made, plans are devel-
oped, and control is exercised.
Responsibility: Records and information management will:
◾
◾Develop and maintain companywide records retention standards and business/operating 
unit supplemental records retention schedules
◾
◾Retrieve records in an expeditious manner
◾
◾Make records readily available to employees who are granted access
◾
◾Assure privacy and security of records

Records Management  ◾  365
◾
◾Communicate tax and/or litigation holds on records and subsequent releases, and protect 
records during the hold period
◾
◾Identify the records with historical value
◾
◾Ensure prompt record destruction at the end of the retention period.
◾
◾Note: If necessary for litigation or other special holds, normal disposition of records will be 
superseded until written notification of the release of the hold is received from the law or 
tax departments.
Responsibility: All employees are responsible for proper attention, adherence, and compliance 
to this policy, including:
◾
◾Identifying the records for which they are responsible
◾
◾Confirming the retention time for each type of document
◾
◾Disposing of records that are beyond the scheduled retention period, unless the retention has 
been suspended in writing by the law/tax departments.
Responsibility: Management is responsible for the following:
◾
◾Partner with records and information management to develop, approve, implement, and 
ensure compliance with companywide records retention standards and business/operating 
unit supplemental records retention schedules
◾
◾Ensure that individual employee responsibilities are carried out
◾
◾Give business units the option to assign/appoint a records coordinator
◾
◾Ensure communication with records and information management.
Responsibility: The process owner is responsible for the following:
◾
◾Partner with records and information management to develop, approve, implement, and 
ensure compliance with companywide records retention standards
◾
◾Monitor processes to verify and measure compliance the records and information manage-
ment program
◾
◾Serve as an advisor to the corporate records manager
◾
◾Communicate all legal, regulatory, operational, archival, and financial requirements.
Responsibility: The corporate records manager is responsible for the following:
◾
◾Implement and manage the companywide records and information management program 
to ensure compliance with legal requirements, state and federal regulations, and business 
operations
◾
◾Establish policies, retention standards/schedules and procedures for the best use, and stor-
age, destruction, and safekeeping protection of company records, regardless of media
◾
◾Assist in matters of litigation holds, tax audits, and regulatory changes
◾
◾Analyze, recommend, and support records and information management systems technol-
ogy and implementation.
Violations: Failure to comply with this policy could potentially adversely affect the company in 
legal matters. Failure to comply could result in disciplinary actions, up to and including dismissal.

366  ◾  Information Security Management Handbook
Sample Records Retention Standard
Specification: MYC accumulates, generates, and maintains records in the course of all of its opera-
tions. This Information Services (IS) Records Retention and Disposal Standard is in support of 
MYC’s corporate Records Retention Policy. For the purpose of this IS Records Retention and 
Disposal Standard, a “record” is defined as any written, recorded, or graphic material generated or 
received in any form: paper, electronic, drawing, photograph, microfilm, diskette, magnetic tape, optical 
disk, voice mail, electronic mail, audio tapes, maps, indices, electronic media, video tapes, reference 
materials, or other forms of data compilations from which information can be obtained, recorded, or 
printed. Records contain information from which decisions are made, plans are developed, and control 
is exercised. An adequate records and information management program encompasses the control 
of all records, including electronic, from their inception or receipt to their destruction or permanent 
retention. For the purpose of this IS Standard, “record retention” is the act of retaining records in any 
form or media for specified, predetermined periods of time commensurate with their value, with 
subsequent disposal or permanent preservation as a matter of official organizational policy.
This IS Standard, including the attached Retention Schedules, set forth requirements regarding 
the retention and disposal of MYC IS records, the person(s) responsible for their proper mainte-
nance, retention time periods, and procedures for on- and off-site storage. They are designed to 
promote sound business practices, safeguard confidential and proprietary information, and com-
ply with applicable laws and contractual obligations. All IS records are subject to this IS Standard.
Separation of duties: All MYC IS employees are responsible for complying with this IS Standard. 
All IS staff must, periodically and as deemed appropriate by IS management, review files and 
records in their work area, on local hard drives, and on appropriate network shares, then remove 
inactive records for disposal, destruction, or off-site storage in accordance with the IS Standard set 
forth below, and work cooperatively with the persons identified below, who have specific respon-
sibilities in connection with the implementation of this IS Standard:
◾
◾Chief security officer (CSO): The CSO is the records administrator for the IS department and 
works with the staff to ensure compliance with this IS Standard, oversees off-site record stor-
age (if required), tracks stored records, coordinates records retrieval, and documents record 
destruction. The CSO also consults with MYC counsel prior to destruction of records in 
accordance with the Retention Schedules. The CSO works with MYC counsel upon request 
to process and respond to all third-party requests for information about and/or production 
of MYC records, in accordance with this IS Standard.
◾
◾IS work unit lead: An IS work unit lead oversees their unit’s work to ensure compliance with 
this IS Standard. Specific responsibilities of each IS work unit lead include:
−
−Maintaining IS records in accordance with MYC’s internal requirements, legal requirements 
including state, federal, or local laws and regulations and any other applicable requirements
−
−Performing a timely records review each year, resulting in the disposal or retention of 
work unit records in accordance with their respective Retention Schedule
−
−Approving the destruction of stored IS records in accordance with their respective 
Retention Schedule
−
−Immediately notifying the CSO of any third-party requests for IS records
−
−Consulting with MYC counsel or the CSO regarding any questions or concerns about 
the retention or destruction of particular IS records
−
−Coordinating file review for centralized filing areas, shared network files, and staff work areas
−
−Working with the CSO to document, track, and retrieve records sent to off-site storage locations

Records Management  ◾  367
−
−Coordinating the destruction of IS records, including obtaining appropriate approvals 
from their work unit leads
−
−Documenting approvals/exemptions and destruction of IS records.
◾
◾MYC Counsel: MYC counsel may serve in an advisory capacity for any of the following:
−
−Reviewing, processing, and responding to all third-party requests for information about 
IS records, in conjunction with the CSO and in accordance with this IS Standard
−
−Reviewing and approving the scheduled destruction of records in conjunction with the 
CSO, when necessary
−
−Notifying IS work unit leads, other managers, or staff to halt the destruction of particu-
lar IS records
−−Providing consultation to the IS staff regarding this IS Standard
Standard: The Retention Schedules included as part of this IS Standard identify the timeframes 
for retaining MYC IS records as well as the work unit(s) responsible for their integrity, maintenance, 
and retention. Appendix A applies to all IS work units and includes the following features:
◾
◾Record Series: Identifies records by functional categories, such as Service Request Files, 
Business Records, Finance Files, HR Files, etc.
◾
◾Description: Lists the type of documents, files, or other media that are contained within the 
Records Series.
◾
◾IS work unit responsible for official copy of records: Identifies the IS work unit responsible for 
the official copy of each Record Series. The location designated as the official record copy 
holder is responsible for maintaining those records for the retention period designated for 
Records Held Off Site.
◾
◾Official record copy held On Site: IS work units may hold records On Site for the specified 
period. After this time, records must be either destroyed or moved Off Site. On Site means 
the primary office filing location. Off Site means a designated central location. The meaning 
of Current will vary. Depending on the type of record, Current means:
−
−The end of the calendar year
−
−The closure of an incident
−
−The completion of a project or lease
−
−The sale of property
−
−The usefulness of the information
◾
◾Comments: This section holds information about the Records Series, including identification 
of critical records. Records designated as critical are considered essential to continued busi-
ness operations and should be protected from loss by the official record copy holder.
Periodic file reviews: Each IS work unit must conduct a file review for the purpose of deter-
mining the disposition of records in accordance with this IS Standard. The file review includes 
all record media (paper, electronic, photos, videos, tapes, etc.) and all IS Staff. Periodically and 
as deemed appropriate by IS management, IS Staff are responsible for reviewing records and files 
maintained in their personal work areas and in individual computer and backup folders. At the 
direction of their work unit leads, IS Staff will conduct a periodic file review for their work units, 
including the following:
	
1.	Review all records media.
	
2.	Identify Records Series on the schedule in Table 26.1.

368  ◾  Information Security Management Handbook
Table 26.1  Information Services Record Retention Schedule
Record Series
Description
Work Unit 
Responsible for 
Official Copy of 
Records
Record On 
Site 
Record Off 
Site 
Comments
*ux* messages
Contains system event activity 
pertaining to the *ux* operating 
system
UNIX Administrator 
14 days
*ux* system logs
All other key logs within the *ux* 
operating system
UNIX Administrator
14 days
Administrative
Personnel information—
evaluations, awards, 
recommendations, and 
professional development
IS Administrative 
Assistant
3 years
3 years from personnel 
action or termination 
date, whichever is later 
per HR policy
Database logs
This log contains the auditing 
records for the enabled auditing 
on the database
Knowledge and 
Database
14 days
Exchange logs
This log contains all the activity 
from the exchange mail server
E-mail 
Administrator 
14 days
IS Financial 
(budget-related 
information)
IS Administrative 
Assistant
Follow Finance 
and 
Accounting 
Retention 
Policies

Records Management  ◾  369
IS Policies/
Guidelines/
Standards/
Procedures/
Processes/Work 
Flows (Current 
Revision)
These are all of the IS specific 
policies, guidelines, standards, 
procedures, processes, and work 
flows
CSO
Indefinitely
When a new version of 
the document has 
been accepted, all 
older versions of the 
document are to be 
destroyed
Login/off Script 
logs
This log contains the information 
logged during the login/off process 
of a workstation or server
Infrastructure 
Support
30 days
Operations
Standard checklists (daily, weekly, 
monthly, quarterly, annually) and 
operating procedures
Operations Support
2 years
Firewall logs
This log contains the traffic of 
inbound and outbound Internet 
and DMZ traffic
Firewall 
Administrator 
14 days
IS Projects (Project 
Archive)
All documentation per the Project 
Folder Archive Policy and Project 
Sponsor Survey Policy
IS Projects
Indefinitely
All documentation 
should be kept in 
electronic form, if at all 
possible
RSA logs
This log contains the 
authentication activity for the 
remote access using the RSA 
tokens
Firewall 
Administrator
14 days
(continued)

370  ◾  Information Security Management Handbook
Table 26.1 (Continued)  Information Services Record Retention Schedule
Record Series
Description
Work Unit 
Responsible for 
Official Copy of 
Records
Record On 
Site 
Record Off 
Site 
Comments
Security Incidents
Stored on separate media, this is 
all documentation related to 
various information security 
incidents within the environment
CSO
3 years
As noted 
in special 
backup/
restore 
requests
If there are legal or 
criminal actions to take 
place, the records will 
be kept for 3 years 
after the court 
decision or per HR and 
Legal policy. If legal or 
civil means is not 
pursued and it is 
against an employee, it 
will be kept for 3 years 
after the activity 
against the employee 
or per HR and Legal 
policy. Otherwise, it is 
to be kept for 3 years 
after the close of the 
incident
Support
These are the Help Desk and 
Change Management requests 
within CA Unicenter Service Desk
Infrastructure 
Support/Customer 
Support
Indefinitely

Records Management  ◾  371
Technical 
Documentation 
(system and 
application) 
(Current Revision)
This is the vendor and IS 
developed documentation to 
support system hardware and 
software and application software. 
This also includes application and 
system upgrade documentation
Respective system 
and IS application 
owner/Operations 
Support
Indefinitely
If possible, only retain 
the electronic version 
of the vendor 
documentation
Vendor
This is the vendor contracts, 
nondisclosures, leases, and 
confidentiality agreements
IS Administrative 
Assistant
3 years
3 years from contract 
termination or 
expiration date of 
nondisclosures and 
confidentiality 
agreements
VPN Logs
This log contains the activity for 
VPN access to the network
Firewall 
Administrator
14 days
System event logs/
logs
This log contains the auditing 
records for the enabled security 
auditing on the server
Windows 
Administrator
14 days

372  ◾  Information Security Management Handbook
	
3.	Follow the schedule’s instructions for on-site and off-site retention requirements.
	
4.	Per the schedule, remove the records from active filing locations that have met their on-site 
retention time.
Electronic records: MYC IS performs incremental backup of application programs and data 
files Monday through Thursday with full backup at close of business on Friday. The full backup 
performed on the first Sunday after the 16th of a month is sent to Recall Data Protection Services 
(RDPS) for permanent (indefinite) off-site storage. All other full backups are sent off site to RDPS 
as well but rotated back to the designated MYC Network Engineer after 30 days have elapsed. 
Tapes rotated back on site are overwritten with the next set of backups.
Records disposal: In accordance with Retention Schedules, the following records should be 
disposed as set forth: 
Record Type
Disposal
Physical—not confidential
Recycle paper; throw away other media 
Physical—confidential
Shred paper (or place in shred bin); 
physically destroy other media
Electronic
Delete from the network or hard drive and 
empty your Recycle Bin
Backed up files
Remove when the backup tape is rotated 
back on site for the next set of backups
Note:	 For large amounts of material to be shredded or destroyed, engage a vendor specializing 
in records destruction. The CSO is available to provide assistance.

DOMAIN
8
BUSINESS CONTINUITY 
AND DISASTER 
RECOVERY PLANNING
Business Continuity Planning


375
Chapter 27
Data Backup Strategies: 
Traditional versus Cloud
Carl B. Jackson
Questions concerning the adequacy of data backup strategies have long been a major concern 
of enterprise management. There is no news on that. But there IS news in that Internet-
centric data backup supporting technologies are evolving rapidly. Given the Internet cloud 
computing trends, might a reevaluation of existing data backup strategies make sense for your 
organization?
When considering data backup strategy options, there is no shortage of new or old solutions. 
A simple Internet search will quickly deluge you with solutions heaped upon solutions and offering 
various technological alternatives in numbers and types that are truly staggering. But, what is the 
problem we are trying to solve? It is that the vast majority of today’s organizations have come to 
rely heavily, if not entirely, on information technology (IT) to support mission-critical business 
processes. And as such, they continue at an exponentially increasing rate to pack away enormous 
amounts of data/information for archival and backup purposes.
The meaning of the term “data backup” for one entity may be, or in fact probably is, differ-
ent than for another. Terms such as virtual server backup, mirroring, failover, cloud computing, 
cloud online backup, cloud storage administration, electronic vaulting, data reduction/compression and 
encryption, data classification, incremental backups, and the like have become everyday jargon of IT 
and continuity and disaster recovery planning professionals.
So, although technological advances have made redundancy of information assets much 
more foolproof and efficient, some things never change. Without the data, all the machines 
and networks in the world are of little use. With this as a given, what is the best data backup 
solution?
While detailing the listing of every possible alternative solution is well outside the scope 
of this chapter, we will attempt to sort out some of the jargon and offer a few important 
suggestions that the management might want to consider when building their data backup 
strategies.

376  ◾  Information Security Management Handbook
Why Backup?
There are numerous reasons for performing data archival and restoration backups. Primarily, it is 
to support organizational time-critical business process functionality (e.g., increasing profitability, 
sales support, customer service, mission-critical support, etc.). Audit and regulatory mandates also 
necessitate access to archival data and ensure availability of information. Also because regular and 
ongoing backup processes reduce the possibility of data loss, a sound data backup strategy is quite 
plainly a compulsory requirement for doing business.
Disruptions: The Root Causes
It is unfortunate but inevitable that business process disruptions occur. Generally, the root cause 
for these events can be classified in one of the following categories:
Hardware failure: IT hardware and other equipment (e.g., hard drives, circuit boards, 
magnetic tapes, network controllers, etc.) or their countless components are subject to 
malfunction.
Software failures: The failure of software for continual support processing of mission-critical 
business processes regularly impacts IT infrastructure and is often a major source of finan-
cial loss and/or customer service impacts or dissatisfaction.
Facility/environmental failures: Facilities or environmental disruptions (e.g., fire, water damage, 
utilities failures, HVAC failures, etc.) result in a surprisingly high number of disruptions 
annually. Add to this list man-made or natural disaster. The tragic consequences surround-
ing the 2011 Japanese earthquakes, tsunami and atomic radiation releases or in the case 
of the Churchill New Zealand earthquake in February 2011, or the flooding in America’s 
Northwest and Midwest areas, etc., are constant reminders of the fragility of organizational 
infrastructures in the face of natural regional or, in the case of Japan, national disaster. 
In addition, in uncertain times, the potential threat of terrorist-related violence calls for 
reexamination of the integrity of the organization resiliency program, including data and 
application backup processes.
Human errors, accidents, or omissions: By far, the single most frequent cause of disruptions 
within an enterprise results from the errors, accidents, and omissions of people. Not just 
any people. They are the organization’s own people. Whether accidental or intentional, 
human errors, accidents, and omissions are traditionally considered the major cause of 
organizational process interruptions or breakdowns. It is often because of the human 
errors, accidents, and omissions of insiders that lead to many of the other disruptions 
cited above.
Outsider actions: Viruses, worms, and a whole host of other insidious outsider-originated attacks 
on your organization and its facilities, systems, communications, and data are increasingly 
to blame for the loss of data integrity and availability.
These potential disruptions clearly illustrate why the management must perform regular physi-
cal security, information security, and emergency response status reviews. The answer is to antici-
pate and mitigate the root causes of serious disruptions that might necessitate data recovery or 
restoration. Further on in this chapter, a number of relevant recommendations along these lines 
will be offered.

Data Backup Strategies: Traditional versus Cloud  ◾  377
Other Data Backup Mandates
Aside from the usual list of business- and technology-related potential disasters, other require-
ments often mandated through standards or compliance-related entities can be added, such as:
Standards Requirements: There are a number of external entities that in some way, shape, or 
form mandate good data backup practices. Standards are issued by the ISO for IT Disaster 
Recovery and Information Security Management Programs, the National Fire Protection 
Association (NFPA) Standard on Disaster/Emergency Management and Business Continuity 
Programs, and the British Standards Institution’s Business Continuity Code. The BSI code 
stresses off-site data backup storage and other leading practices. These are just a minor few 
of the numerous standards organizations that can and do provide justifications for backup 
approaches.
Audit/regulatory requirements: Internal and external audit requirements, as well as governmental 
mandates, through U.S. governmental agencies such as the FFIEC, IRS, and SEC continue 
to stress the importance of fundamental business continuity planning including provisions 
for appropriate data backup. Intended for those enterprises that operate in countries outside 
the United States, large numbers of similar corresponding requirements are mandated.
Data Backup Requirements Gathering
A sound and well-thought-out data backup management process must dovetail with various com-
ponents of the enterprisewide Continuity Planning Business Process. All data backup strategies must 
provide support to the enterprise business goals, of course. They must also work in unison with 
existing continuity planning business processes and defined business process recovery objectives 
and time frames.
Here are just some of the primary data gathering requirements:
Status of the existing enterprise business continuity planning infrastructure: A fully developed 
enterprise continuity planning business process should consist of several components. These 
closely interrelated components include the Business Continuity Plans (i.e., business process 
recovery planning), the Disaster Recovery Plans (i.e., technology recovery planning), and the 
overarching enterprise Crisis Management Plans and planning structure. These components 
once implemented and tested, rely on the timely and accurate recovery of data/information 
in both electronic and hardcopy forms.
	
At the outset, the executive management must insist on having a clear definition of the 
backup strategies requirements. The requirements gathering process includes undertaking a 
business process impact assessment as well as an emergency preparedness analysis.
Status of the business impact assessment (BIA) process: Reasonable estimate of the time needed to 
restore interrupted functionality to minimize impacts on time-critical business processes is 
the goal of the BIA activity. A properly conducted BIA provides enterprise managers with 
prioritized inventories of time-critical business processes including the estimates of their 
recovery time objectives (RTOs). How can the management possibly make informed backup 
process and resource acquisition decisions without a BIA? Only through development of a 
sound understanding of all potential loss impacts can the management efficiently allocate 
resource requirements.

378  ◾  Information Security Management Handbook
Status of enterprise emergency response capabilities: Along with the BIA, the management should 
also perform an enterprise emergency preparedness analysis focusing on current and antici-
pated emergency response capabilities. These include environmental security (e.g., fire 
detection and suppression, electrical supply monitoring and conditioning), physical security of 
facilities (e.g., access control, surveillance, personnel identification practices, etc.), and personnel 
security considerations (e.g., employee awareness and training) and the regular and ongoing 
testing or exercises of these emergency response capabilities.
Data Backup Process Selection Criteria
Once the management has a handle on the status of existing threats, potential impacts, and exist-
ing control measures, they should turn their attention to developing data backup philosophies 
and practices that fit their organization’s needs. This chapter does not presume to present an 
all-inclusive directory of the criteria that enterprise managers should use in selecting data backup 
schemes; however, following are a few of the most important considerations:
Support the enterprise mission: Above all, the data backup strategy, including data restoration 
timing requirements and expense allocations, must fit the overall enterprise mission/goals. 
Consider what is driving time-critical business process recovery windows, which, by the 
way, force data restoration time windows and mandate that the data backup strategy be 
designed accordingly.
Management scope: Depending upon the size, organizational structure, geographical footprint, 
and enterprise mission objectives, the executive management group should articulate their 
expectations to all concerned business process and technology owners/leaders. Mid-level 
managers will inevitably be responsible and accountable for the in-the-trenches develop-
ment, implementation, and ongoing oversight and reporting on the data backup and archi-
val strategy for each of their specific areas of responsibility. It should go without saying that 
executive management’s support and direction in this effort are of paramount importance. 
Success in this complex and rather daunting undertaking requires resource allocation and 
management support. Failure of the executive to clearly articulate the expectations will very 
possibly result in incomplete and inconsistent application of the strategies and ultimately 
result in some very unpleasant surprises, should a restoration become necessary.
Temporal scope: Utilizing business process recovery time frames (i.e., RTOs) determined during 
the BIA, the management must insist that data backup and archival processes meet or, even 
better, exceed RTO time frames. Beware. Experience has demonstrated that failures in this 
area are common and costly if allowed to go unaddressed.
Fiscal scope: Again, depending upon business process RTOs, backup strategy cost estimates are 
required and the methods determined for allocating those costs across the enterprise.
Data and media scope: Considering the best way to manage multiple types of media (e.g., hard 
drives, tape, logical, virtual, and even hardcopy) is the challenge. Another is to understand 
and organize types of data (e.g., historical data, transactions, legally mandated data [IRS, 
SEC, etc.]). Do not forget the requirement for data classification. Accumulated information 
of large organizations can include literally millions of gigabytes of data. Simply coming to 
grips on how best to administer backup processes by prioritizing information according to 
the type can be off-putting. In the world of information security, classification of data has 
always been a colossal implementation and management problem. The sheer magnitude 

Data Backup Strategies: Traditional versus Cloud  ◾  379
of information makes classification of electronic and hardcopy information daunting. 
Experience has shown that more often than not, and sometimes in frustration, management 
eventually defaults to the “everything goes” principle and simply opts to “back it all up.”
Backup geography considerations: The assessments must also take account of the organization’s 
geographical footprint (i.e., one or multiple locations), IT architectures, and user reliability 
expectations and requirements.
Technology scope: Understand the precise technological scope and requirements for backup. Are 
we talking about server backup, e-mail backup, mainframe backup, etc.? What systems (e.g., 
mainframe vendor supplied, MS-based, UNIX, Linux) are utilized and how are they config-
ured (e.g., mainframes, server implementations, multiple facilities, desktop implementations, or 
combinations of the preceding)? Of key consideration for data backup purposes are the volume 
of data currently being processed and the bandwidth currently being used. It is crucial to 
factor in both volume and bandwidth the expectations for the future.
Special circumstances considerations: Organizations that serve unique public safety or national 
security related populations may well have special circumstances that also require analy-
sis. As an example, take the Department of Homeland Security initiatives for supporting 
America’s critical national infrastructure during times of national crisis.
Does Your Organization Support America’s 
National Infrastructure?[1]
For those enterprises that are considered part of America’s critical national 
infrastructure, the Department of Homeland Security (DHS) is attempting 
to provide guidance through the release of the 2009 National Infrastructure 
Protection Plan (NIPP).[2] The DHS is endeavoring to form a partnership with 
the 18 critical supporting private sector industries by defining a unifying struc-
ture process for integration for the protection of what the DHS calls “critical 
infrastructure and key resources” (CIKR). As the primary emphasis, the CIKR 
sets forth objectives for establishing a safer, more secure resiliency for America’s 
CIKR by developing a set of tools. These tools will, among other objectives, 
“provide for the appropriate protection of information, including develop-
ing an inventory of asset information…” DHS directive Homeland Security 
Presidential Directive/HSPD-7 directs the Secretary of Homeland Security to 
implement plans and programs that identify, catalog, prioritize, and protect 
CIKR in cooperation with all levels of government and private sector entities. 
Data systems currently provide the capability to catalog, prioritize, and protect 
CIKR through such functions as: (1) Maintaining an inventory of asset infor-
mation and estimating the potential consequences of an attack or incident 
(e.g., the IDW); (2) Storing information related to terrorist attacks or incidents 
(e.g., the National Threat and Incident Database); (3) Analyzing dependen-
cies and interdependencies (e.g., the NISAC); (4) Managing the implementa-
tion of various protective programs (e.g., the BZPP Request Database); and 
(5) Providing the continuous maintenance and updates required to enable the 
data in these systems to reflect changes in actual circumstances, using tools 
such as iCAV and DHS Earth. Organizations supporting America’s critical infra-
structure should factor data backup programs accordingly.

380  ◾  Information Security Management Handbook
Data Backup Solution Alternative: Cloud Data Backup
At the very least, the topic of cloud computing is hot and getting hotter! Internet searches reveal 
many sites dealing with the latest and greatest services, predictions, surveys, capabilities, recom-
mendations, technology reviews and discussions, and the like—all related to the topic of cloud 
computing. Keeping up with the cloud computing industry and technology will be a major chal-
lenge for managers considering the cloud for data backup purposes.
Cloud backup: The meaning of cloud computing can have multiple definitions depending on 
who is using it. For the individual or smaller sized organization manager, cloud computing, 
including cloud data backup, takes place over the public cloud. However, for organizations 
of any significant size, rapid RTOs mandate the use of a private cloud. Reputedly, one of 
the downsides of using the public cloud is the length of time it can take for data recovery 
and restoration. For information-only purposes, a good source for cloud computing–related 
information is the Cloud Computing Journal.[3]
Lines are blurring: The lines between public and private cloud capabilities are blurring quickly. 
Making hard and fast declarations concerning the various cloud computing data backup 
support capabilities, advantages, and disadvantages to be somewhat problematic.
Public cloud backup providers: Public cloud users include individuals and small business through 
services provided by vendors such as Carbonite, CrashPlan, IDrive, Jungle Disk, and others. 
Today, public cloud servers are capable of collecting, compressing, and encrypting data that 
is transferred, typically every 24 hours, over the Internet. Public cloud backup offerings are 
rapidly evolving, including trends toward allocation of storage space, storage space expenses, 
recovery/restoration time frames bandwidth support, etc. Needless to say, this space will 
certainly look different as industry, technology and user requirements mature.
Private cloud backup: As the name implies, a private cloud is “private” or, in other words, 
proprietary to a particular organization or other consortiums. Some larger organizations 
have been using cloud backup for archival purposes, mainly because of slower data recovery 
turnaround times. Some large organizations have built or are building private clouds for 
their use. Companies that provide cloud computing services for larger organizations include: 
SunGuard Availability Services, EMC, Inc., IBM, Cisco Systems, et al.
	
Under either the public or the private cloud scenarios, enterprise management backup strate-
gies require optimizing the amount and type of data that will be stored and synchronized. It 
also requires a reasonably well-established set of operating procedures by the user organiza-
tions to keep backups organized and accessible when needed (e.g., data, applications, etc.).
Prepare for the cloud: Cloud computing online backup techniques include transmitting real or 
virtual copies of data over public or private networks to be stored and accessible as backup. 
This process can be done by the organization itself or farmed out to a third-party vendor. 
Either way, care must be taken to ensure that the solution is sound from a data integrity, 
privacy, availability, and overall security standpoint. There is much guidance available in 
the wild that will assist managers in making decisions on how best to utilize cloud comput-
ing service offerings and capabilities. One word of warning, however, would be the con-
cern related to governmental initiatives toward implementing controls that could be used 
to interrupt Internet access and/or other capabilities under a certain set of predetermined 
circumstances. See the discussions on National Institute of Science and Technology (NIST) 
standards below for some assistance, but be aware that governments around the world have 
looked or are looking very closely at Internet monitoring and even attempting to or actually 

Data Backup Strategies: Traditional versus Cloud  ◾  381
controlling Internet accessibility. Should your data be in the wrong place at the wrong 
time—you could have a very big problem.
National Institute of Science and 
Technology (NIST) Standards[3]
Cloud computing standards: The ever-widening acceptance and use of cloud 
computing have been recognized by the government, which is now consid-
ering appropriate standards and practices. For instance, in February 2011, 
the federal technology agency National Institute of Science and Technology 
(NIST) issued a working draft of a paper titled NIST Cloud Computing 
Standards Roadmap. In it, NIST defines cloud computing[3] as “Cloud com-
puting is a model for enabling ubiquitous, convenient, on-demand network 
access to a shared pool of configurable computing resources (e.g., networks, 
servers, storage, applications, and services) that can be rapidly provisioned 
and released with minimal management effort or service provider interac-
tion. This cloud model promotes availability and is composed of five essential 
characteristics, three service models, and four deployment models.”
The future of cloud computing: Cloud computing services and technologies are moving beyond 
the hype and evolving into a market presence so quickly that by the time this chapter is pub-
lished, there is a very real likelihood that what has been said here will be obsolete. One thing 
is for sure—cloud computing is not going away anytime soon and its potential for providing 
enterprise services can only increase. Not only can individuals, small companies, and larger 
organizations utilize the cloud (public or private) for data backup purposes, this topic alone 
can be likened to one very small pixel in a much wider screen. Significant conceptual issues 
including applications management among and between cloud spaces, managing overall 
information security issues (not just data backup security), understanding cost/performance 
issues, and keeping an eye on networking bandwidth concerns are all currently at the top of 
the discussion queues. Stand by!
Data Backup Solution Alternatives: Localize Solution
The term “localized” within the context of this chapter is meant to involve data backup solutions 
that utilize local enterprise resources, whether located in a single facility or data center or colocated 
in two or more facilities. These backup facilities can be managed solely by enterprise management 
or can be provided by a third party.
Following are several points of consideration regarding the localized data backup solution:
Facilities availability: What is the organization’s geographical footprint? Does it include single 
or multiple locations? Do other sites have the ability to accommodate backup systems? Or 
should they already accommodate systems capabilities, might they be made suitable for off-
site backup and data storage?

382  ◾  Information Security Management Handbook
IT infrastructure: Can the organization’s technology infrastructure (including hardware, soft-
ware, networks, support personnel, operating practices) support in-house redundancy solutions 
such as implementation of a completely redundant data center? Does it have access to cost-
effective third-party physical media off-site storage or online data storage capabilities (e.g., 
electronic vaulting)?
Virtual machine backup: IT managers now often utilize a more advanced “virtual machine” 
technology for data backup purposes. Once accomplished, virtual machine restorations look 
and feel the same to the end user, but virtualization of the backup process is an entirely dif-
ferent approach to data storage. In a virtual machine implementation, the virtual machine 
software sees single or multiple physical devices (e.g., servers, networks, applications, desktops, 
and other IT appliances) not in a physical way, but in a virtual way. So, the contents of 
large numbers of devices can be stored in a virtual manner upon one or fewer devices at 
other locations. This can be a very efficient process, although resource contention issues 
related to concatenation of multiple devices, data, and processes into virtual environments 
can possibly result in processing performance degradation. In addition, backup costs can 
escalate when using the virtual backup approach. Expenses would include acquisition and 
maintenance of multiple copies of backup software to facilitate backup processes. Restoring 
virtual machine backups can sometimes turn into an all-or-nothing restoration approach. 
Restoration of individual files or applications only can be problematic. In virtual restora-
tion circumstances, the entire virtual snapshot (see the Virtual machine utilities topic below) 
must be recreated, which can mean restoring tremendous amounts of data for the sake of a 
single file. Virtual machine backup processes can be utilized in a localized, remote, or cloud 
processing environment.
Virtual machine utilities: There are many utilities offered that will assist the enterprise in mak-
ing backup processes more efficient and effective in the virtual environment. One useful 
alternative backup utility concept is referred to as “Snapshot-based backup.” This is a virtual 
copy of a device or files system that can be adapted to rapid RTOs. It is not necessarily 
a backup file, but a symbolic link to a file or data that has been captured and frozen in 
time. With a snapshot approach, although very useful under the right circumstances, it can 
be problematic if instantaneous access is a requirement. So this solution, as with others, 
requires requirements analysis before adaptation. Although the resource requirements and 
operating costs of this approach can be significant, organizations requiring almost instan-
taneous access to their data should consider such a solution. There are several large service 
providers that can provide both the hardware and software support that will, among other 
functions, support snapshot-based backup.
Other Localized Backup Alternatives
Off-site data storage (Tape): Of course, there remains the more traditional data backup and 
recovery solutions. Backing up data to tape and rotating it to an off-site location may work 
for archival information, but not when short recovery windows are involved.
Electronic vaulting: Electronic vaulting technology is not a new concept by any measure. 
Electronic vaulting capabilities have been a very useful alternative to backing up data and 
storing it at the primary site. Like all other technologies, electronic vaulting capabilities 
have evolved substantially over the years. Companies that offer electronic vaulting services 

Data Backup Strategies: Traditional versus Cloud  ◾  383
include: EMC Corp., EVault Inc., Iron Mountain Inc., LiveVault, and SunGard Availability 
Services, to name just a few.
Service provider support: Utilizing third-party service providers not only for data backup sup-
port but also for rapid IT support (i.e., hotsite) following a disaster remains a perfectly viable 
option for some organizations.
Cloud versus Localized Data Backup Decision
Whether enterprise management decides upon cloud data backup or, on the other hand, the more 
traditional methods of data backup is relative. When considering which alternative backup strat-
egy to use, the answer comes down to “it depends.” It depends on understanding where the orga-
nization is relative to these questions:
	
1.	What are we doing relative to data backup now and is it working for our users?
	
2.	Are our organization’s mission-critical success factors supported by our current data backup 
strategies?
	
3.	Are our current IT infrastructure backup strategies adequate in addressing our data security 
and RTO requirements?
	
4.	How much data (i.e., volume) do we really need to backup and restore? And at what cost?
	
5.	At what rate (i.e., bandwidth) must data be transmitted to and from backup facilities? And 
at what cost?
	
6.	How quickly does the data need to be retrieved and available if needed? And at what cost?
Short recovery window mandates: If enterprise RTOs are very short (e.g., seconds, minutes), then 
the enterprise must be equipped with the appropriate hardware, (including data storage 
capacities), software, and bandwidth to move the data. It all really boils down to time. Short 
RTOs, large data volumes, and large pipes (network bandwidth) are the key deciding factors 
and tend to force the organization toward localized backup strategies. This probably will 
include multiple locations, geographically disbursed, that can be equipped with very robust 
IT and data network capabilities.
Extended recovery window: If enterprise RTOs are longer (e.g., hours, days), then the enterprise 
may have the luxury of time to take advantage of a more remote data storage strategy, such as 
cloud computing, to support the lower data volumes and smaller bandwidth requirements.
At the end of the day, there are no hard and fast rules. Each organization is unique (e.g., dif-
fering missions, technologies, geography, threat scenarios, number of employees, etc.), so each solution 
must be customized to fit the environment.
Linking Backup Strategies to the Broader 
Continuity Planning Program
In the broader scheme of things, a well-prepared enterprise would have already considered the 
risk potentials and have provided for commonly accepted protection mechanisms that are well 
rounded and make good business sense, including:

384  ◾  Information Security Management Handbook
Impact assessment: The BIA, which should be undertaken and updated periodically, provides 
the management with empirical loss impact and time criticality information needed to make 
informed decisions.
Physical security: Physical security should be reviewed and designed or enhanced to provide as 
much mitigation as cost justified for the enterprise. It is important to ensure the physical 
and environmental security of all remote off-site storage facilities that are being used for 
time-critical data backup.
Data security: Data security mechanisms, including access control, data transmission, and stor-
age encryption of off-site data, provide a degree of data integrity and security.
Business continuity and crisis management planning: As mentioned previously in this chapter, 
attention to the development, maintenance, and testing of full scope enterprise business 
continuity and crisis management planning processes are fundamental in helping support 
data backup recovery and restoration.
Metrics: If we truly get what we measure, development of measurements is necessary. They 
should be designed to help make enterprise business process more efficient and effective 
and must be uniquely designed for the agreed-upon data backup policies, processes, and 
practices (e.g., operational-, financial-, and personnel-related), so the metrics will enhance the 
possibilities of success.
Conclusion
Questions about the adequacy of data backup strategies have long been a major concern of enter-
prise managers. Although there is no major news on that, there IS news that Internet-centric data 
backup supporting technologies are evolving rapidly. Given the Internet cloud computing trends, 
might a reevaluation of existing data backup strategies make sense?
Whether considering traditional approaches to data backup or use of Internet cloud comput-
ing, determination of requirements objectives is the first step. But, making decisions between 
cloud and localized data backup options can be reduced to a few key questions. These are: (1) How 
does our current data backup strategies meet enterprise recovery time objectives? (2) How much 
data is involved? (3) How much IT horsepower and network bandwidth will be needed to support 
the volumes of data and the recovery time objectives?
In reevaluating these questions, remember that the lines between more traditional localized 
backup solutions and the use of public and private cloud computing are blurring. Given every 
organization’s uniqueness in size, mission, technology footprint, recovery time requirements, and 
geographical location(s), the solutions must be customized to fit each unique environment. There 
is no one-size-fits-all in this arena. With history as a guide, we know that evolving technologies 
hardly ever fail to present us with better mouse traps.
References
	
1.	NIST Cloud Computing Standards Roadmap (NIST Document: NIST CCSRWG – 040), February 16, 
2011, p. 3.
	
2.	Department of Homeland Security National Infrastructure Protection Plan, p. 92. (http://www.dhs.gov/
xlibrary/assets/NIPP_Plan.pdf).
	
3.	Cloud Computing Journal (http://cloudcomputing.sys-con.com/).

DOMAIN
9
LEGAL, REGULATIONS, 
COMPLIANCE, AND 
INVESTIGATIONS
Major Categories of 
Computer Crime


387
Chapter 28
Managing Advanced 
Persistent Threats
E. Eugene Schultz and Cuc Du
Over the years, information security managers have faced a multitude of security threats and risks, 
some of which have been minor, but many of which have been major in terms of the magnitude 
of potential impacts to the organizations that we have served. In many ways, we have been lucky, 
however. With the exception of viruses and worms, the threats against the computing systems and 
information that we have tried to protect have been transitory. If, in the past, someone tried to 
attack one or more of these assets, they either succeeded or failed, and if they failed, they generally 
moved on to their next target. A widely accepted axiom among information security profession-
als was to ensure that the assets of one’s organization were just a little more secure than the other 
organizations’ assets so the “bad guys” would find the path of least resistance.
Things have changed. Security-related threats (and thus also risks) have grown considerably in 
severity in the last few years; much of the reason is that attacks have become so much more clever and 
sophisticated, and another is that threats are now so much more persistent. The Aurora attacks that 
plagued so many Fortune 500 companies and the U.S. military and government in 2009 serve as a 
strong case in point. Contrary to the way perpetrators attacked systems, applications, and databases 
just a few years ago, the Aurora attackers tended not to give up until they had conquered their targets. 
Given such a target- and vulnerability-rich environment, the attackers were almost guaranteed suc-
cess in attacking the organizations with average or below-average security. But they even succeeded 
in attacking the computing systems of the companies that by all appearances had achieved “best 
practices” status in information security, forcing us to rethink the problem and how we try to solve it. 
This chapter deals with the problem (advanced persistent threats, APTs), its nature and severity, and 
what we should and should not be doing from an information security management point of view.
Introduction
In March, 2011, the attackers gained unauthorized access to the RSA systems that contained 
information concerning the intricacies of the RSA products that provide strong authentication. 

388  ◾  Information Security Management Handbook
RSA’s SecurID is a good example of such a product, one that is preferred by clandestine agencies 
of the U.S. government because of its ability to provide much stronger authentication than con-
ventional authentication methods; e.g., password-based authentication. An investigation of the 
RSA break-ins has led to early speculation of the origin—the People’s Republic of China. Yet at 
the same time, other widespread break-ins into the systems in the United States, United Kingdom, 
Canada, Germany, and other countries reveal that regardless of the apparent origin, a relatively 
new pattern of attacks characterized by great sophistication and persistence are occurring. This 
chapter covers what the nature of the threats associated with such attacks is, the toll, and what 
information security managers can do to mitigate the resulting security risks.
About APTs
The term “APT” means different things to different people, yet it is clear that the threats that are 
sophisticated and incessant have resulted in a variety of highly undesirable outcomes. One such 
outcome is a data security breach in which classified, proprietary, personal, and financial data is 
compromised. Another is prolonged denial-of-service (DoS), and still another is a compromise of 
the integrity of data, systems, applications, networks, and more. In the next section, the range of 
meanings of APT will be discussed and the scope of the associated risks will be described.
Definition of APT
The term “advanced persistent threats” means different things to different persons. Some claim 
that the term originated in the military and defense sectors to define a series of ongoing cyber-
attack as espionage assaults from nation-states such as China, which initially targeted the military 
as well as certain manufacturing and technology industries. The term APT quickly entered the 
security industry with vendors using the term to promote their products, thereby substantially 
diluting its meaning. For the security community and professionals, APT may be a new term, but 
the concept is older. In general, the term refers to a series of “below the radar” attacks that were 
previously seen on a relatively small scale, but are now used collectively to launch highly targeted, 
prolonged attacks. Definitions vary, as summarized below:
◾
◾Advanced means that the adversaries can operate in the full spectrum of computer intrusion. 
They can use the most pedestrian, publicly available exploit against a well-known vulner-
ability, or they can elevate their game to research new vulnerabilities and develop custom 
exploits (often in connection with “zero-day” vulnerabilities), depending on the nature of 
the target and the goal(s) of the attack.
Advanced also means that the perpetrators utilize a full spectrum of techniques in gather-
ing intelligence, developing sophisticated malware, and executing attacks. Methods used by 
the adversaries may include traditional intrusion technologies and techniques coupled with 
advanced tools and techniques developed to accomplish the task. Additionally, using advanced 
social engineering skills is another tactic used to capitalize on the weakest link of all, people.
◾
◾Persistent means the adversary is determined (often formally) to accomplish a mission. The 
adversary is not acting opportunistically. Like an intelligence unit, the adversaries receive 
directives and work to meet the requirements handed to them. Persistent does not necessar-
ily mean that they need to constantly execute malicious code on victim computers. Rather, 
they maintain the level of interaction needed to fulfill their objectives.

Managing Advanced Persistent Threats  ◾  389
Persistent also means that the perpetrators are highly focused with a goal of accomplish-
ing their mission according to prioritization of specific tasks. Rather than using a “slash 
and burn” strategy to seize the first opportunity to attack, they execute a “low and slow” 
approach to continuously gather their information through sustained monitoring for long-
term presence. They wait patiently for the appropriate time to strike.
◾
◾Threat means that the adversary is organized, well-funded, and highly motivated. Adversaries 
often consist of multiple “groups” consisting of dedicated “crews” with a variety of missions. 
Some people equate the term “threat” with malware, but the adversary is not a piece of 
mindless code. If malware had no human (someone to control the victim, read the stolen 
data, etc.) in connection with its use, most of it would be of considerably less concern (as 
long as it did not capture, destroy, or modify information). The adversaries in APTs are the 
real threat.
Threat also means that the level of coordinated efforts involving the human factor is extensive. 
It is not about automated codes and scripts being tossed in the wild. Because the groups behind 
APTs are organized, motivated, and well-funded, they are highly evolved with their research and 
development (R&D) capabilities and they take great care in selecting their targets.
Brief History of APT-Related Attacks
APT-related attacks first surfaced in the late 1990s, although they were not recognized as such 
until later. The “Titan Rain” attacks, a steady barrage of coordinated attacks against U.S. com-
puters that started in 2003, were the first to raise an alarm concerning the existence of APTs and 
the risks they posed. Targets included Sandia National Laboratory, Redstone Arsenal, NASA, 
Lockheed-Martin, and other organizations and sites (including numerous U.S. military sites). 
Evidence that the Chinese military was the primary instigator of these attacks exists and the fact 
that most of the attacks were traced to China strongly supports this notion. The exact nature of 
these attacks and their motivation remain unknown, however, in part because the perpetrators 
were clever in using a wide variety of methods (including installing extremely sophisticated mal-
ware in the victim systems) to evade detection.
Another flurry of APT-related attacks dubbed the “GhostNet” attacks was first discovered 
in early 2009. In these attacks, more than 1295 computing systems in 103 countries, including 
Taiwan, the United States, Germany, India, Tibet, Vietnam, Iran, South Korea, Bangladesh, 
Latvia, Indonesia, the Philippines, Brunei, Barbados and Bhutan, Romania, Cyprus, Thailand, 
and Pakistan, were victimized. These attacks were characterized by their focus on high-importance 
systems, such as critical government systems that held information that if leaked could cause harm 
to the security and interests of the nations. The attacks also frequently resulted in the installation of 
remote administration tool (RAT) called GhostRat in compromised systems to allow the attackers 
remote back door access and to make changes in these systems at will. The origin of this tool, as well 
as the attacks themselves, was once again traced to China.
Operation Aurora was the next big round of APT-related attacks. Aurora (named after the file 
path of some malware on the attackers’ computing systems and possibly also the code name that 
the conspirators gave this operation) began in mid-2009 and continued until the end of 2009. 
Many corporations, some of which include Google, Rackspace, Juniper Networks, Northrop 
Grumman, Dow Chemical, Symantec, Adobe Systems, Yahoo, and Morgan Stanley, were tar-
geted, as was also the U.S. military. Because of the covert methods used to subvert systems, 
however, the attacks were not detected until they subsided. Google was the first to publicly 

390  ◾  Information Security Management Handbook
announce the attacks, and the speculation that Google was targeted because of its refusal to 
provide China with information about Chinese dissidents and its eventual withdrawal of Google 
search engine services from that country ran rampant. More than in any previous attacks, the 
Aurora attackers did not give up until they had vanquished their targets. The attackers gleaned 
large amounts of proprietary information and accessed (and presumably stole) a great deal of 
source code. Once again, the victims of these attacks failed to detect them for many months 
and the origin of the attacks was traced to China. Chinese officials denied any complicity in the 
attacks, however, instead blamed the U.S. for what it called a “conspiracy.” According to McAfee, 
the main objective of the attack was to access and possibly also modify the source code at the tar-
geted corporations. The major “lesson learned” for the information security community was that 
implementing “best practices” is insufficient to thwart such sophisticated and persistent attacks. 
Additionally, the information security community was once again reminded of the importance 
of sharing information concerning incidents with others so that they could identify previously 
unrecognized attack patterns.
Still another set of clever, subtle, and persistence attacks labeled “Night Dragon” began in late 
2009. Global energy, oil, and petrochemical corporations were targeted in this series of attacks, 
which utilized social engineering and spear-phishing, exploited Windows vulnerabilities, and uti-
lized RATs in stealing highly proprietary commercial, financial, and oil and gas site bid-related 
operational information. The attacks, which yet another time were traced to China, were once 
again highly complex, coordinated, persistent, and covert to the point that most of the targeted 
corporations did not know that their systems had been compromised until they were informed by 
the U.S. government many months after they had initially occurred.
Characteristics of APT-Related Attacks
Cyber-attacks have occurred over the entire lifespan of the Internet. However, with ATPs, there is 
a paradigm shift concerning the purpose, motivations, methods, and people who are behind these 
attacks. Nonetheless, no two APTs are exactly the same. The methods and technologies used in 
each attack vary, but in general, APTs exhibit several similar characteristics.
Goal-Directed, Customized for Specific Targets
APT-related attacks are goal-driven and purposeful. The perpetrators take great care in planning 
their attacks, selecting their targets, and customizing their attack methods toward a specific sec-
tor, company, or technology to produce the greatest impact. The main goal is to create advantages 
that maximize the financial returns with each attack. Attackers use advanced social engineering 
methods to scope out a targeted organization’s employee structure to determine who has elevated 
privileges and the process to obtain privileged accesses. Other methods include tailored mal-
ware and reconnaissance to map out a target organization’s applications, networks, and systems 
to exploit weak or unpatched zero-day vulnerabilities. These activities are distributed over long 
periods of time, which makes them harder to detect and correlate based on behavior patterns, 
anomalies, or with timestamps. With APTs, the perpetrators have clear goals, expectations, and 
interests. Stealing sensitive data such as credit card information and social security numbers for 
identity theft is still prevalent. But, stealing intellectual property and trade secrets and participat-
ing in corporate espionage of targeted organization produce long-term damage that can ultimately 
destroy a brand and reputation of the company altogether. Government entities can lose power 
and competitive advantage over other countries if national security is compromised.

Managing Advanced Persistent Threats  ◾  391
Well-Organized
Although there is an enormous increase in organized cyber-crime, a shift in the threat landscape 
changed the way these members operate today. These organizations are professionally managed like 
a legitimate corporation. CEOs, payrolls, HR, and recruiters often exist. Perpetrators of these groups 
have formal positions within a hierarchy, suggesting that there are teams of specialized individuals 
across multidisciplinary capabilities, skills, and expertise. Individuals possess different specialties and 
collaborate their attacks. For example, there are development teams who write malware and there 
are beta testers. Their social connections to the communities and other groups with similar criminal 
interests serve as an advantage to obtaining available computing resources. Espionage groups such 
as the Shadow Network, a hacker group in China, are highly evolved and may already own many 
of the already compromised networks and assets of the world. Additionally, the perpetrators actively 
recruit and seek new individuals to educate and train them to be professional cyber-attackers. These 
skilled individuals are paid well to carry out the attacks to achieve the mission of their organization. 
According to IT Business Edge, insider threats are the second highest danger to organizations. The 
economic downturn may inadvertently pressurize disgruntled employees to resort to stealing com-
pany information from within. The perpetrators may take advantage of the situation by recruiting 
financially strained employees for the insider information to increase their chance of success in attacks.
Well-Funded
Individual stakeholders of these organizations must have the financial funding to carefully 
research, plan, and carry out intensive attacks over long periods of time. Additionally, writing 
the quality of malicious code needed in these attacks requires considerable time and effort, again 
showing the need to be well-funded if an organization is going to be a player in the APT arena.
Diverse Attack Methodologies
It is common for the APT perpetrators to use multiple attack vectors concurrently to increase the 
likelihood that their attacks will be successful. Because the attackers are highly paid for their skills, 
there is strong motivation to use creative techniques and technologies to penetrate a targeted orga-
nization’s environment. Attackers use automated methods and human social engineering schemes 
to trick an organization’s own employees to be participants in their attacks. Attackers understand 
that people are the weakest links and therefore take advantage of their lack of awareness. The use 
of social media tools, such as spoofed Facebook and LinkedIn inquiries, creates a false sense of 
trust. Clicking on such links as “We went to high school together” may inadvertently install mal-
ware onto their computers. Such tactics are used to solicit further information and eventually gain 
access to a targeted organization’s network. The perpetrators take their time to get to know their 
victims. The huge amount of shrewdness, patience, and commitment involved in these attacks 
make these attacks so effective and deadly.
How APT-Related Attacks Differ from Conventional Attacks
Conventional attacks vary considerably, making them difficult to compare with APT-related 
attacks. Nevertheless, conventional attacks can at a high level be contrasted with APT-related 
attacks. Compared with conventional attacks, the following are the main characteristics of many 
APT-related attacks:

392  ◾  Information Security Management Handbook
◾
◾Detailed planning (sometimes over several months)
◾
◾Reconnaissance-in-depth, often to the point of learning detailed information about social 
interactions, friendship patterns, and information access patterns among potential spear-
phishing targets
◾
◾Prolonged attempts (if necessary) to compromise the computing systems through extremely 
subtle spear-phishing attempts
◾
◾Installing and using highly covert tools to create backdoor access with elevated privileges 
and to steal authentication credentials and data
◾
◾Using compromised systems as a “pivot point” from which to launch further attacks
Malware Used in APT-Related Attacks
Sometimes, the malware used in APT-related attacks is identical to the malware used in conven-
tional attacks, but the malware in the former type of attack is also often different. If it is different, 
it is likely to have the following characteristics.
Unique
New malware that has not been previously identified is likely to be used in APT-related attacks. 
Sometimes, new malware is created because of the desire to launch newly designed attacks. In 
other cases, new malware is developed because the fact that it is new will create obstacles for mal-
ware and intrusion detection tools that require malware signatures before they can recognize the 
malicious program.
Extremely Covert
If APT-related attacks are to go unnoticed by victim organizations, malware must be extremely 
difficult to detect. Malware authors who are part of an APT effort therefore program their soft-
ware to be as covert as possible. In conventional attacks, malware such as viruses, worms, and 
Trojan programs are frequently used. Viruses and worms are almost never used in APT-related 
attacks, however, because these types of malware are self-reproducing, thereby greatly increasing 
the probability that the attacks will be noticed. These authors also often build mechanisms such as 
code packing, i.e., encoding a program such that malware scanners do not recognize it, designed 
to evade the detection of their malware.
Bot Functionality
Although bots and botnets are common in conventional attacks, they are even more prevalent in 
APT-related attacks. The main reason is the desire for control of systems and networks on the part 
of attackers. At the same time, however, bots and botnets are seldom used to launch distributed 
denial-of-service (DDoS) attacks because such attacks are so noticeable.
Well-Written
Analysis of some of the malware used in APT-related attacks shows that the quality of the software 
is often much higher (in terms of code structure and the absence of coding errors) than for most 
commercially available software. The reason is that APT-related attacks are often well-funded, 

Managing Advanced Persistent Threats  ◾  393
allowing sponsor nation-states to hire top-notch programmers and use coding standards, develop-
ment tools, and testing methods that go far beyond conventional ones typically used in commer-
cial software development.
The Perpetrators, Motivations, and Targets
Who are the perpetrators of APT-related attacks, what are their motivations, and what types of 
targets are they attacking? This section answers these questions.
Perpetrators
The types of perpetrators potentially associated with APT-related attacks include countries, terror-
ists, activists, organized crime, disgruntled employees, and members of the “black hat” community. 
The list of types of potential perpetrators is narrowed considerably by the need for considerable 
labor and financial resources in preparing for and launching APT-related attacks. This is, in fact, 
the major reason that nation-states and organized crime are currently the major perpetrators of 
these attacks.
When APT-related attacks are discovered, the origin is often (but not always) China. Although 
China has repeatedly denied being involved in such attacks, their denial has almost always been 
implausible. Connections in these attacks frequently trace back directly to one or more IP addresses 
in China, and if not, to proxy servers in other countries that in turn have connections originating 
from China. Furthermore, the malware known to be developed and actively used in China (such 
as GhostRat) is frequently also found in victim systems, and comments in the code are very often 
written in Chinese.
Not all attacks are from China, however. Some attacks originate from Eastern European coun-
tries such as Russia, Belarus, and Ukraine. Others originate from Brazil and the United States. 
These attacks are almost always the work of organized crime gangs in these countries who plun-
der Western computing systems and use mules to cleanly and carefully move money to accounts 
where the money can be stored until needed.
Motivations
Of all the motivations for launching APT-related attacks, financial gain is the easiest to under-
stand. To put it bluntly, there is a lot of money to be made by stealing proprietary information. 
The fact that financial information and lease bid data owned by oil companies have been frequent 
targets of APT-related attacks in the past strongly points to a financial motive in at least some of 
the attacks. Countries such as China that invest heavily in the U.S. stock market may be gaining 
the equivalent of insider trading information when they break into corporations’ systems that hold 
financial information. They may also be attempting to give a critical competitive advantage to 
companies in their country. Or, perhaps, these countries may more than anything be attempting 
to achieve economic dominance.
Other motivations for launching APT-related attacks are less clear. Although we know that 
nation-state–sponsored activity is motivated by the desire to gain intelligence, how this intel-
ligence is actually used is not very well understood at this time. Additionally, the theft of so 
much U.S. military information as the result of APT-related attacks suggests that gaining a 
military advantage over potentially adversarial countries is another motivation for launching 
these attacks.

394  ◾  Information Security Management Handbook
Targets
Targets can easily be derived based on understanding the profiles of the perpetrators and their 
motives. Less than 3 years ago, APT attacks targeted mostly U.S. government organizations. More 
recent incidents such as Operation Aurora indicate that the targets have expanded to large corpo-
rations and to national governments other than the U.S. government. It is also common to target 
critical infrastructures, including water, electric power, nuclear power, or chemical companies and 
facilities. Countries near China, such as Tibet and Taiwan, are experiencing a growing number 
of APT-related attacks, suggesting that any country that is adversarial to China’s desire for power 
and dominance is also a likely target of APT-related attacks.
APTs and Security-Related Risk
How do APTs affect the types and levels of security-related risk? This section addresses this 
question.
Confidentiality, Integrity, and Availability Risk
Of confidentiality, integrity, and availability, confidentiality is most at risk when APT-related 
attacks occur. Most of these attacks are motivated by the desire to obtain information—financial, 
intellectual property, personal, military, or other information. These types of information are 
often targeted in conventional attacks—the big difference in terms of risk is the fact that the per-
petrators of APT-related risk typically do not give up until they have obtained the information on 
which they have focused. APT-related confidentiality risks are thus potentially disproportionately 
high, something about which risk and information security managers within national govern-
ments and large corporations should be highly cognizant. At the same time, however, confidenti-
ality risks within organizations generally not targeted in APT-related attacks are in most cases in 
reality not higher than normal.
Other Risk (Reputational, Legal, Regulatory, and More)
APTs also raise the reputational risk considerably. Corporations that have been victimized in 
APT-related attacks are invariably mentioned in the media, often in a negative light. For exam-
ple, Google received a disproportionate amount of press attention, much of it negative, after the 
details of the Aurora attacks started to publicly surface. The same was true of Exxon-Mobile, 
Shell, and BP, after the Night Dragon attacks came to light. The fact that almost every APT-
related attack over the years has not been detected until months after the attack’s occurrence 
has also tended to make attack victims appear hapless, as if they had incompetent information 
security practices.
APTs also elevate legal and regulatory risk. Theft of certain types of financial information, e.g., 
constitutes a violation of the U.S. Gramm–Leach–Bliley statute. Theft of patient medical data is 
a violation of the U.S. Health Information Portability and Accountability Act (HIPAA). Theft of 
cleartext credit card information violates the PCI-DSS standard. Theft of personal information 
of European Union (EU) citizens constitutes a violation of the EU Privacy Directive as well as 
certain EU country-specific laws.

Managing Advanced Persistent Threats  ◾  395
Where Conventional Risk Analysis Fails
Is conventional risk analysis, qualitative or quantitative, sufficient when it comes to APTs? The 
answer is perhaps, but probably not, for the following reasons:
◾
◾One of the typical limitations of risk analysis is that an insufficient range of threats is generally 
considered. Numerous potentially relevant risks are too often eliminated from further analy-
sis because they are considered extremely unlikely to occur. APTs are one such threat source. 
If you are an information security manager at Google, you will almost certainly include APTs 
in your risk analysis. By contrast, if you work for a sports manufacturing corporation, you are 
unlikely to evaluate the risk due to APTs because so far this kind of company has not to the 
best of our knowledge been targeted in advanced persistent attacks. But APT-related attacks 
are constantly occurring, and the focus of these attacks often shifts midstream during their 
course. One, therefore, never really knows what the next target will be.
◾
◾It is difficult to obtain a realistic estimate of the likelihood of such attacks for risk analysis 
purpose because so many of these attacks have gone completely undetected or detected only 
long after they have occurred and many are overlooked altogether. As such, historical data 
about these attacks is of limited use.
◾
◾Even if a somewhat realistic estimate of the likelihood of APTs surfacing could be derived, 
APTs are so dynamic that this estimate would almost certainly be invalid a short time later.
◾
◾Many security professionals view risk as equal to value × threats × likelihood. Threats must 
exploit vulnerabilities if they are to manifest themselves as risk factors, but the vulnerabilities 
that are almost always exploited in APT-related attacks are usually zero-day vulnerabilities, 
vulnerabilities that cannot be anticipated. Without a realistic estimate of the vulnerability 
factor in the above risk equation, risk cannot be suitably estimated.
We are not in any way saying that risk analysis should omit all consideration of APTs. We are 
instead saying that even the best risk analysis is unlikely to be even marginally accurate when it 
comes to APTs. The solution, improving risk analysis methods to accurately take into account 
APTs and other nonconventional and serious threats, is certain to come in time, however.
How Potential Victims Become Targets
Any organization anywhere can be a victim. The proverbial battlefield is getting bigger, more 
nation-states are getting involved in espionage and information warfare, and organization crime 
is becoming incredibly proficient in inventing and exploiting ways to profit from its sordid activi-
ties. At the same time, however, it is important to realize that when individuals are targeted in 
APT-related spear-phishing attacks, it is generally in fact the organization to which the individual 
belongs, not the individual per se, that is being targeted. The attacks that have occurred so far 
show that having information that is of interest and value to the adversaries is most likely to make 
a certain organization or individual the target of an APT-related attack. Attackers will send one 
spear-phishing message to one user within the targeted organization, then another, then another, 
until enough machines are compromised and a sufficient number of Trojans that allow remote 
backdoor access and contain keystroke and packet capturing routines have been installed. All the 
while, no one is likely to notice what is happening.
Another possibility is that an organization or individual could be targeted by APTs because 
of an association (e.g., a third-party business partnership) with another organization or individual 

396  ◾  Information Security Management Handbook
that is the real target. If attempts to penetrate the target’s computers and networks fail, the focus 
of the attacks might quickly shift to the other organization or individual.
Risk Mitigation Measures
No problem is unsolvable, but some problems are extraordinarily challenging. APTs constitute 
one such problem. The next section will cover how and why conventional security measures fail, 
how information security managers need to adjust their information security framework in deal-
ing with APTs, and the types of controls that are most likely to be successful against APT-related 
attacks.
How and Why Conventional Security Measures Fail
Three types of controls—administrative, physical, and technical controls—are available to miti-
gate information security risks. Administrative controls are critical, but measures such as policy 
and standards go only so far in countering the levels of risk that APTs produce. Password policies 
do not really help in countering APT-related risk because passwords are virtually never cracked 
in advanced persistent attacks. If anything, passwords are sniffed instead. Standards requiring 
certain system configurations for the sake of security and patching are likely to help in slowing 
the process of attacking, but advanced persistent attackers keep trying one attack method after 
another until they finally succeed. So if they cannot exploit any configuration weakness, they 
try to exploit one bug, then another, then another, until one exploit works. And remember, also, 
that many APT-related attacks exploit zero-day bugs, bugs that not even the best of vulnerability 
patching efforts can fix until patches finally become available.
Physical controls are irrelevant to APTs, at least up to this point in time. But technical controls 
are potentially highly relevant—after all, firewalls and intrusion prevention systems (IPSs) are 
designed to stop many attacks, as also are strong authentication methods and file and directory 
permissions. Intrusion detection systems (IDSs) are designed to discover attacks. To some extent, 
these controls serve their purpose, but there is a big caveat—the residual risk associated with each 
control. No control mitigates all relevant risks. An application firewall that thwarts 95 percent of 
all known attacks against Web applications fails to stop the remaining 5 percent of attacks. An 
IPS that stops 90 percent of all network attacks will fail in preventing the remaining 10 percent. 
And if you have seen the empirical results of independent testing conducted on commercial Web 
application firewalls and IPSs such as the ones that NSSLabs frequently conducts and publishes, 
you will not be surprised to learn that many widely used commercial security products score only 
60 or 70 percent when they are tested for ability to stop attacks. Given the limitations in today’s 
security technology, advanced persistent attackers truly have a target-rich environment.
But traditional wisdom says to use a defense-in-depth strategy in combating information secu-
rity threats. The basic idea is that control 1 may at some point fail, control 2 may also fail at 
another point, and perhaps even control 3 may fail at yet another point, but then control 4 will 
finally defeat an attacker’s efforts. We have seen this type of scheme work in thwarting numer-
ous attacks in the past, but not in stopping more recent APT-related attacks. The fundamental 
problem with the conventional defense-in-depth security model is that every control is imperfect. 
Suppose that in a defense-in-depth scheme control 1 is highly effective to the point that it has only 
a 10 percent residual risk factor. As far as conventional attacks go, the control is nearly perfect. 
But now consider an APT scenario in which a highly persistent attacker will not quit until s/he 

Managing Advanced Persistent Threats  ◾  397
has defeated or bypassed this control. After considerable time and effort, the attacker succeeds 
and moves on to defeat or bypass the next control in the defense-in-depth scheme. Suppose, fur-
thermore, that the next control has a residual risk factor of 20 percent, a factor with which most 
information security professionals who really understand the nature and amount of residual risk 
would be happy. The attacker is even more likely to succeed in defeating or bypassing this control 
than the first control, which had a residual risk factor of only 10 percent. Now consider the third 
control, and the point should now really become clear.
Defense-in-depth is a good strategy, but it was not designed to meet the onslaught of APT-
related attacks that have been plaguing us. Any time that any control has residual risk, a deter-
mined attacker is likely to be able to defeat or bypass it. Defense-in-depth per se is not the real 
problem. The real problem instead is defense-in-depth with controls that are less than perfect 
(or, more realistically, at least somewhat ineffective against the range of possible actions of highly 
determined attackers). The higher the residual risk associated with a control measure, the more 
likely an APT-related attack is to succeed.
We are not suggesting that information security managers abandon defense-in-depth strate-
gies. We instead recommend that these managers rethink how to deploy defense-in-depth. We 
have moved from having endpoint solutions (e.g., a firewall at the external gateway in each net-
work, network IDSs, network IPSs, network access control appliances, and so forth) to a unified 
threat management (UTM) or “all-in-one” approach. In theory, this move has solved the problem 
of point solutions being unaware of and unable to coordinate and cooperate with each other, but 
at the same time we have set ourselves up for failure when it comes to APTs. We buy one vendor’s 
UTM product with all the functions we need, but many of the functions are not “best-of-breed.” 
One vendor may make the best application firewall, another may make the best IDS, and still 
another may make the best network access control tool. Each UTM function that is not “best-
of-breed” makes advanced persistent attacks easier with respect to defeating or bypassing that 
function. One of the most important considerations in countering APTs, therefore, is having 
defense-in-depth based on the concept of “best-of-breed,” not simply having multiple barriers, 
each of which may be insufficiently effective.
Recommended Controls
In this next section, controls that are most likely to be effective against APTs are discussed.
E-Mail Filters and Virus Walls
APT-related attacks often use spear-phishing to get unsuspecting users to open attachments sent 
with e-mail messages that appear to be sent by someone the users know and trust. They also use 
spear-phishing to get the users to click on URLs that redirect browsers to malicious Web sites 
that push malware into the users’ computers. Having the ability to filter incoming e-mail from a 
known phishing site or IP address is thus an effective measure against APTs. Additionally, having 
a virus wall that inspects each e-mail attachment for malicious code and deletes anything that is 
found is useful for the same purpose.
Ensuring That Web Browsers Have Built-in Protections
Users do not have to be sent e-mail containing malicious URLs to visit malicious Web sites. 
Having browsers that help protect against common types of attacks (including advanced persistent 

398  ◾  Information Security Management Handbook
attacks) is thus an effective control measure. For example, the Internet Explorer 8 warns the users 
when they attempt to go to a known malicious site, including but not limited to a site known to 
be used in connection with phishing.
Enforcing the Least Privilege Principle
In most operating systems, root- or administrator-level privileges are required to install software. 
Ensuring that the users do not have these levels of privilege thus helps prevent their systems from 
being infected with malware. In Windows Vista and Windows 7, e.g., everyday users run with 
normal privilege levels by default.
User Training and Awareness
Phishing and spear-phishing are in reality types of social engineering attacks. Training users to 
refrain from opening attachments they are not expecting, even if the attachments appear to be sent 
from someone they know, and to avoid clicking on URLs that are sent to them in e-mail messages 
unless they know that it is safe to do so, is another effective measure against APTs.
Using “Best-of-Breed” Malware Detection and Eradication Tools
Antivirus technology has reached its limit. It, for the most part, relies on “signatures” to detect 
malware, but today’s generation of malware is extremely sophisticated to the point that it formats 
and frequently changes itself to avoid detection. Only “best-of-breed” malware detection and 
eradication tools (e.g., Trusteer Rapport) are genuinely effective. Using these tools can consider-
ably help in the fight against APTs.
Random Inspection of Systems
Some organizations recognize the limitations of most of today’s antimalware tools to the point 
that although they use these tools, they never trust their output (or lack thereof). Instead, they 
hire top-notch technology talent to randomly inspect a given number of systems daily. Perhaps not 
surprisingly, these gurus generally find several new types of malware every week. These organiza-
tions then determine what the identifying characteristics of these new types of malware are and 
then inform the system administrators, who are required to inspect the systems that they manage 
to determine if any are infected with the identified malware and, if so, to eradicate it.
Personnel Measures
The Aurora attacks against Google were aided by several Google employees who came from China 
to work for Google in the United States. Having effective personnel screening measures is thus 
another potentially useful control against APTs.
Greater Cross-Organization Cooperation
Organizations that experience security-related breaches tend to keep the information about the 
breaches to themselves. If the organizations shared this kind of information with other organi-
zations, APT-related attacks might be identified sooner than they typically are and ultimately 

Managing Advanced Persistent Threats  ◾  399
stopped or at least slowed down. Organizations such as FIRST (The Forum of Incident Response 
and Security Teams) promote sharing incident-related information, but unfortunately, very few 
organizations are members of FIRST.
Effective Intrusion Detection
APT-related attacks that have occurred so far have been greatly facilitated by the fact that the 
victim organizations have almost without exception failed to detect these attacks until it was too 
late. Being able to detect such attacks in near real-time would enable the organizations to inter-
vene much earlier in the attack cycle, possibly to the degree that further attacks could be stopped. 
Effective intrusion detection, including the ability to effectively correlate system logs, firewall and 
IPS logs, and IDS output to identify patterns that indicate that slow and subtle attacks are occur-
ring, would go a long way in the war against APTs.
Effective Incident Response
Yet another potentially effective control in countering APTs is having an effective incident response 
capability that is capable of quickly identifying advanced persistent attacks and containing them 
and their effects so that they do not spread and get out of control. An interesting twist on the 
incident response theme is being tried by an increasing number of organizations that assume that 
their networks are already compromised and that they are thus always in incident response mode. 
Every connection, internal and external, is considered suspicious and is thus investigated. The 
main limitation with this approach is the resources needed to be in a constant state of reaction to 
events, but those who use it generally attest to its many advantages, given the number, severity, 
and persistence of today’s attacks.
Adjusting the Security Framework
An information security framework is one of the most valuable tools that information security 
managers have in moving their information security practice in an appropriate direction to achieve 
the desired level of information security governance. This kind of framework should, among other 
things, include the goals of the information security risk management program and how they are 
aligned with business drivers, the major strengths/advantages and potential obstacles with respect 
to achieving the defined goals, and what constitutes success. Given the reality of APTs today, most 
information security managers need to revisit their security frameworks, looking in particular how 
APT-related risk potentially affects business processes and how APTs result in new obstacles that 
information security practices need to address. Managing an information security effort is not 
easy, but with the advent of APTs, doing so just got more difficult. Information security managers 
must think strategically and proactively, and doing so with respect to dealing with APTs is not an 
option, but is now rather a de facto requirement.
Conclusion
This final section presents a summary of the major points raised in this chapter, a discussion of what 
APTs are likely to be in the future, and, finally, a discussion of possible next steps in dealing with APTs.

400  ◾  Information Security Management Handbook
Summary
APTs have grown from being little-noticed and rather insignificant to threats that should be on 
every information security manager’s proverbial radar screen. APT-related attacks such as Titan 
Rain, GhostNet, Operation Aurora, and Night Dragon have resulted in a considerable amount 
of sensitive information falling into the hands of adversaries. Adversaries have generally become 
well-financed, well-organized, and highly motivated to succeed to the point that, contrary to the 
way things worked in the past, they do not give up, even after experiencing multiple setbacks. 
They frequently use spear-phishing methods, targeting individuals whom they have thoroughly 
researched. They develop and use malware that is incredibly well-written and tested and that 
incorporates mechanisms that help cloak its presence. They also often exploit zero-day vulnerabili-
ties. Of confidentiality, availability, and integrity risks, advanced persistent attacks are most likely 
to cause confidentiality-related risks to soar. Defending against APT-related attacks is exception-
ally difficult, in part because of the persistence of the attackers coupled with the residual risk in 
connection with controls commonly used as part of a defense-in-depth scheme. The best approach 
is to use “best-of-breed” technical controls (e.g., e-mail and browser filters, virus walls, intru-
sion detection, and more) in conjunction with user awareness and training and effective incident 
response. More effective sharing of incident-related information would also help organizations be 
able to better thwart APT-related risks. Information security managers should also update and 
revise their practice’s information security framework to take APTs into account.
APTs in the Future
As long as the adversaries continue to have the upper hand, they are likely to continue with 
the same strategies that they are currently using. They can continue to focus on finding victim 
organizations, preparing for attacks, writing and using new malware, and gleaning volumes of 
information that meets their goals. Large organizations such as Fortune 500 companies and gov-
ernment departments and agencies are likely to continue to be the major targets of APT-related 
attacks. Given these organizations’ very high risk appetite, advanced persistent attacks are likely 
to continue mostly unabated well into the future, but the range of targets is likely to expand. Not 
surprisingly, small and medium-sized businesses and academic institutions have almost without 
exception been immune to APT-related attacks so far. Although future APT-related attacks will 
primarily be aimed against corporations and governments, other types of organizations will also be 
likely future candidates as their IT services move to the target-rich cloud computing environment.
Next Steps
APTs are for all purposes presently unstoppable and much of the blame falls upon security tech-
nology vendors. Instead of producing best-in-class products, they too often freely use the “APT” 
acronym in their marketing strategies as a means of inciting fear in individuals who might not 
otherwise be inclined to buy their products. When confronted with the results of independent 
testing that show that their products are not all that proficient in accomplishing what the vendors 
say they do, the vendors often unjustly impugn the testing process used to produce the results and/
or claim that the disappointing results for their product were due to the fact that an older version 
of their product was used in the tests. We need a massive amount of help from vendors if we are 

Managing Advanced Persistent Threats  ◾  401
going to have a chance against APTs, but too many vendors are barking up the wrong tree, so 
to speak. Vendors need to pursue making products that are above everything else best-in-class. 
The sooner they do this, the more likely our systems, devices, and networks will be to resist APT-
related attacks.
About the Authors
E. Eugene Schultz, PhD, CISM, CISSP, GSLC, is the chief technology officer at Emagined 
Security, an information security consultancy based in San Carlos, California. He is the author/
coauthor of five books, one on UNIX security, another on Internet security, a third on Windows 
NT/2000 security, a fourth on incident response, and the latest on intrusion detection and preven-
tion. He has also written over 120 published papers. Gene was the editor-in-chief of Computers 
and Security from 2002 to 2007 and is currently an associate editor of Computers and Security and 
Network Security. He is also a certified SANS instructor, senior SANS analyst, member of the 
SANS NewsBites editorial board, coauthor of the 2005 and 2006 Certified Information Security 
Manager preparation materials, and is on the technical advisory board of three companies. Gene 
has previously managed an information security practice as well as a national incident response 
team. He has also been a professor of computer science at several universities and is retired 
from the University of California. He has received the NASA Technical Excellence Award, the 
Department of Energy Excellence Award, the ISACA John Kuyers Best Speaker/Best Conference 
Contributor Award, the Vanguard Conference Top Gun Award (for best presenter) twice, the 
Vanguard Chairman’s Award, and the National Information Systems Security Conference Best 
Paper Award. Named a distinguished fellow of the Information Systems Security Association 
(ISSA), Gene has also received the ISSA Hall of Fame award as well as the ISSA’s Professional 
Achievement and Honor Roll awards. While at Lawrence Livermore National Laboratory, he 
founded and managed the U.S. Department of Energy’s Computer Incident Advisory Capability 
(CIAC). He is also a cofounder of FIRST, the Forum of Incident Response and Security Teams. 
He is currently a member of the accreditation board of the Institute of Information Security 
Professionals (IISP). Dr. Schultz has provided expert testimony before committees within the U.S. 
Senate and House of Representatives on various security-related issues and has served as an expert 
witness in legal cases.
Cuc Du is currently the information security officer for the Office of the Chancellor at the 
California State University, where she holds responsibility for the overall information security 
function and program at the Chancellor’s Office. Prior to serving in this position, she served in a 
senior security role for Fremont Investment and Loan, where she played a key role in developing 
and implementing the company’s information security program. In addition, Cuc was a security 
engineer at Option One Mortgage Corporation and security consultant at Callisma, Inc. (now 
known as AT&T).


Incident Handling


405
Chapter 29
Virtualization Forensics
Paul A. Henry
A Brief Virtualization Technology Review
Virtualization is one of the most rapidly growing and evolving fields in information technology 
today. At its heart, virtualization represents the abstraction of computing resources from the physical 
hardware layer. A number of different types of virtualization technologies exist:
◾
◾Server virtualization: Server operating platforms, such as Microsoft Windows 2003 Server 
and Red Hat Enterprise Linux, are installed as virtual images on top of a “Hyper Visor” 
that imitates the underlying hardware layer. In this manner, multiple virtual servers can be 
simultaneously run on one physical platform.
◾
◾Application virtualization: Applications are virtualized and encapsulated from the underly-
ing operating platform, as well as the hardware.
◾
◾Desktop virtualization: Similar to server virtualization, but focused on desktop operating 
environments such as Microsoft Windows XP
◾
◾Storage virtualization: Physical storage devices are abstracted to represent a virtual storage 
platform.
This chapter focuses on server virtualization, as this is the primary use of virtualization 
in most enterprises today. The major server virtualization vendors currently include VMware 
(vSphere), Microsoft (Hyper-V), and Citrix (XenServer). This chapter focuses on VMware’s 
product line.
Throughout this chapter, several terms have constantly been used, so we need to define them 
up front.
In the realm of server virtualization, the host is the underlying server virtualization platform 
that will be used to provide virtual hardware layers to the virtual servers. The virtual systems can 
be located directly on the host’s local storage device or on a network storage device (or devices).
The virtual guest comprises a set of files that represent the virtual server itself. These files will 
be covered in more detail later in the chapter, but each serves a specific purpose in interacting with 
the host software and the underlying hardware that the host is installed on.

406  ◾  Information Security Management Handbook
The hypervisor is the primary component of any server virtualization platform. Often 
referred to as the virtual machine monitor (VMM), the hypervisor is the central nervous 
system within a virtual infrastructure. It manages the host’s underlying hardware resources 
and handles all guest-initiated operating system and application requests for CPU, memory, 
I/O, and disk resources.
Two types of hypervisors are commonly found today:
◾
◾Type 1 hypervisors are essentially their own self-contained operating platforms and are 
installed on the “bare metal” of the host hardware. Guest systems run at a level “above” the 
hardware, allowing for more complete isolation. A LinuxRedHat6.2 of this type of hypervi-
sor would be VMware’s ESX Server.
◾
◾Type 2 hypervisors are applications that run on an existing operating system platform. 
LinuxRedHat6.2s of a Type 2 hypervisor would be VMware Workstation or VMware 
Fusion.
Components of VMware Infrastructure 4 (Figure 29.1):
	
1.	ESX/ESXi Server
	
2.	Virtual switch
	
3.	vCenter
	
4.	vSphere Client(s)
ESX server
VMDK ﬁle
Virtual
switch
Virtual
machine
Physical NIC
Physical network
vSphere client
vCenter
NIC
Figure 29.1  Components of VMware infrastructure.

Virtualization Forensics  ◾  407
	
5.	Virtual machines (VMs)
	
6.	Storage
Where Are the VM Files Stored?
The most powerful features of VMware, such as vMotion, HA, and DRS, require the use of 
“Shared Storage,” which is a centralized storage that is shared between multiple VMs. That being 
said, most rack-mounted servers do include a hard disk; however, it is typically only used for ISO 
storage and templates.
The most common type of shared storage types include:
◾
◾Network-Attached Storage (NAS) using Network File System (NFS)
◾
◾SAN using Fibre Channel
◾
◾SAN using iSCSI
In all likelihood, the VM files you will need to image are stored on a large shared storage 
device.
Virtual Machine File System and Virtual Machine 
Disk Format Considerations
It is important to note that the specifications for the powerful journaling files system created 
by VMware called Virtual Machine File System (VMFS) have not been released yet. As of the 
date of this writing, there are no commercial forensic tools that provide for the recovery or 
analysis of the media that utilize VMware’s VMFS. This creates serious issues, as it is unlikely 
that the files deleted by a malicious party will be able to be recovered by a forensic expert from a 
VMFS formatted disk. Further, as the file system is proprietary, the forensic expert is restrained 
to working with VMFS from within VMware. Although this is somewhat limiting, it is not 
a showstopper as a VM is typically stored within a container called a Virtual Machine Disk 
Format (VMDK) on top of VMFS. The VMDK “container” contains the complete abstraction 
of the VM and is supported by multiple forensic analysis tools. The VMDK can be copied from 
the VMFS-based storage from within VMware; or, if an image of the hard disk containing 
the VMFS is available using an open source tool called “Open Source Virtual Machine File 
System,” a copy of the VMDK can be made in Windows or Linux using either a command line 
interface or WebDav GUI. The open source tool referenced above can be downloaded from this 
Web site: http://code.google.com/p/vmfs/.
Is there really any need to capture an entire VMFS to acquire a forensic image of a VM?
◾
◾Hundreds, if not thousands, of VMs potentially impacted
◾
◾Privacy considerations
◾
◾Scope of search warrant issues
Probability of recovery of any deleted materials is low, so why not focus on the VMDK for the 
VM that is the focus of the investigation.

408  ◾  Information Security Management Handbook
VMDK Details
VMDK files represent physical hard drives for VMs, so as many as 60 VMDK files can be allo-
cated for a VM, with a hard limit of 2TB for each.
There are four different categories of virtual disks that can be allocated:
◾
◾Zeroed thick: This is the default VMDK type, created with the stand-alone vSphere Client, 
the vSphere Client, and the vCenter, or at the Service Console with the “vmkfstools-c” com-
mand. This disk type allocates all needed space up front and writes random data over any 
accessed areas the first time a VM tries to access them. This disk type strikes a good balance 
between performance, efficiency, and security.
◾
◾Eager zeroed thick: This can only be created using the “vmkfstools-d eager zeroed thick” 
command or by selecting the virtual disks that support clustering and Fault Tolerance 
(FT) options. The major difference with this disk type versus the “zeroed thick” disk 
type is that eager zeroed thick disks overwrite all disk space with zeros upon initial 
creation.
◾
◾Thick: Preexisting data on the drive where this is allocated is never wiped out. This is a 
HUGE security risk, and as such this VMDK type should never be used.
◾
◾Thin: Thin VMDK files are both allocated and zeroed at the time of access, which is very 
efficient but also consumes more resources in real time. This is the default disk type for 
VMDKs created on NFS volumes, as well as VMDKs created in VMware Workstation.
Two modes can be configured for VMDK disks:
◾
◾Persistent: Default mode, VMDK behaves like a standard physical disk. Changes are written 
to disk.
◾
◾Nonpersistent: Once set as nonpersistent, no changes are saved.
Exactly What Files Are Associated with a VM?
When we create a VM called “LinuxRedHat6.2,” the following files would be created and placed 
in the respective VMDK container:
◾
◾LinuxRedHat6.2.vmx: VM configuration file
◾
◾LinuxRedHat6.2.vmdk: Virtual disk configuration file
◾
◾LinuxRedHat6.2-flat.vmdk: Actual VM hard disk
◾
◾LinuxRedHat6.2.nvram: VM’s BIOS file
◾
◾LinuxRedHat6.2*.log: VM log
◾
◾LinuxRedHat6.2.vswp: The VM Swap file
◾
◾LinuxRedHat6.2.vmsn/vmsd: VM snapshot metadata
◾
◾LinuxRedHat6.20000001-delta.vmdk: Real-time snapshot write file
◾
◾LinuxRedHat6.2-***.vmss: Suspended VM memory data
The primary focus of a forensic investigation of a VM would be on the respective flat.vmdk file; 
however, it is suggested to copy all of the available files from within the VMDK to be certain that 
potential valuable evidence is not missed.

Virtualization Forensics  ◾  409
VMDK State Considerations
A copy of a VMDK file can be made while the respective VM is in any one of the following states:
◾
◾On
−
−I have used this in IR-related cases without issue, but others have reported errors from 
VMware when copying a running VM.
−
−This method is useless from a forensics perspective, as the disk is constantly changing; 
hence, it would be impossible to verify the forensic soundness of any copy.
◾
◾Off
−
−Traditional state for forensic imaging
◾
◾Suspended
−
−When you suspend a VM, you also get a copy of what was in the memory at the moment 
it was suspended as a bonus.
◾
◾Snapshot
−
−The VMDK is no longer changing as all data is being written to the new snapshot disk 
and you get the added bonus of collecting an image of the RAM at the time of the 
snapshot.
When you create a snapshot, you are basically telling VMware you are going to create a new 
disk for this VM, so from now on only write to this new disk and no longer write to the original 
disk. This is great if you are only going to create a single snapshot (Figure 29.2) but can get very 
complex very quickly with multiple snapshots (Figure 29.3). Today, there are no tools to analyze 
an individual snapshot’s delta file. The only available work around is to restore and analyze each 
snapshot sequentially.
It is important to consider that when you consolidate your snapshots, you are effectively 
sequentially applying each snapshot and the respective changes contained within that snapshot to 
the original VMDK. Valuable evidence could potentially be found literally in between snapshot 
events. Therefore, it is important to analyze the VMDK after each individual snapshot is restored.
Figure 29.2  A single snapshot. When you create a snapshot you are basically telling VMware 
I am going to create a new disk for this VM, so from now on only write to this new disk and no 
longer write to the original disk. This is great if you are only going to create a single snapshot, 
but can get very complex very quickly with multiple snapshots.

410  ◾  Information Security Management Handbook
W2K3DC
SP2
baseline
Sysprepped Windomain
.com base
Windomain
.com base
With clients With clients
and server*
Capgroup
base
US.ray.com
IIS and SQL
Ready to
conﬁgure
Left oﬀ
Contoso.com
base
Updated
Windomain
.com EFR
Mygroups
demo setu...
Mygroups
rollback P...
Mygroups
preinstall B...
Mygroups
preinstall B...
Mygroups
installed
Service
installed
Demo base
TW demo
start
TW demo
base
Left oﬀ
Wincon
demo start
Working
Mygroups
rollback
Windomain
.com EFR
Figure 29.3  Multiple snapshots.

Virtualization Forensics  ◾  411
Suggested Steps for Sound Forensic Imaging of a VMware VMDK
	
1.	Enable the remote console mode (Figure 29.4) and remote SSH (Figure 29.5) in ESXi.
	
2.	Suspend the respective VM using the vCenter Client (Figure 29.6).
	
3.	Log in to ESXi via SSH.
Figure 29.4  Step 1A for sound forensic imaging of a VMware VMDK: Enable remote console 
mode in ESXi.
Figure 29.5  Step 1B: Enable remote SSH in ESXi.

412  ◾  Information Security Management Handbook
	
4.	Navigate to the storage medium using the remote console and hash the respective VMDK 
and VMSS (Figure 29.7).
	
5.	Connect a remote NAS device to receive a copy of VMDK (Figure 29.8).
	
6.	Copy the LinuxRedhat6.2 VMDK (Figure 29.9) and LinuxRedHat6.2 VMSS files 
(Figure 29.10) to a removable temporary NAS device using DD.
Figure 29.6  Step 2: Suspend the respective VM using the vCenter Client.
Figure 29.7  Step 4: Navigate to the storage medium using the remote console and hash the 
respective VMDK and VMSS.

Virtualization Forensics  ◾  413
	
7.	Hash the copies and verify that the hashes match the original.
	
8.	Resume the VM to place the VM back in service.
Summary
Current incident response and forensics practices must be updated to meet the new constraints of the 
virtual realm. The age-old practice of simply pulling the plug on a potentially compromised server 
Figure 29.8  Step 5: Connect a remote NAS device to receive a copy of VMDK.
Figure 29.9  Step 6A: Copy the LinuxRedhat6.2 VMDK to a removable temporary NAS device 
using DD.

414  ◾  Information Security Management Handbook
and imaging the hard drive to begin the incident analysis has now been replaced with shutting down, 
suspending, or snap-shooting the impacted VM and imaging the respective container (VMDK) 
within the shared storage. The large numbers of individual servers that could potentially belong to 
separate and individual unrelated entities that operate from the shared disk storage of the virtual 
realm also introduce privacy and scope issues for subpoenas that have yet to be fully addressed within 
the legal community. Today, using commonly available forensic tools, a complete and thorough 
analysis can be produced for an existing specific server operating as a VM by operating on the respec-
tive files contained within the VMDK. With that being said, although most forensic tools vendors 
have solutions for working within the VMs container (VMDK), none as of this writing can properly 
process and analyze the underlying file system (VMFS). Hence, the analysis of VMs that have been 
deleted from VMFS is currently problematic at best, as we simply lack the ability to reliably recover 
the deleted file structures from this popular underlying file system.
Figure 29.10  Step 6B: Copy the LinuxRedHat6.2 VMSS files to a removable temporary NAS 
device using DD.

DOMAIN
10
PHYSICAL 
(ENVIRONMENTAL) 
SECURITY
Elements of Physical Security


417
Chapter 30
Terrorism: An Overview*
Frank Bolz, Jr., Kenneth J. Dudonis, and David P. Schulz
New Game
Terrorism is a political act, though its use and processes have very specific, horrific components 
and consequences. In this country terror is perhaps no longer perceived to be the same thing it was 
in the years immediately following the events of September 11, 2001—events that tragically intro-
duced international terrorism to the American public. Terrorism on American soil was not new, 
since political activists, extremists, and radicals had used bombs, kidnapping, hijackings, and 
hostage taking as tactics in campaigns to press their points of view into the public awareness. But 
foreign terrorists striking on the American mainland had a devastating effect physically, psycho-
logically, and emotionally that, a decade later, still inhabits the nation’s psyche. Governments—
federal, state, and local—continue to struggle to reduce the anxiety levels among the general 
public. In addition, private sector security has never been so finely tuned.
The last two decades of the twentieth century saw the rise of extreme Islamic radicalism to levels 
that threaten regimes throughout the Muslim world, as well as nations throughout Asia, Europe, 
much of Africa, and North America. Terrorist attacks carried out by Islamic terrorist groups have 
risen not only in number, but also in level of violence. The United States, which had largely been 
free of confrontations with Islamic terrorism, received its first taste in 1993, with a truck bomb 
attack on the World Trade Center in New York City, the same target leveled in the aerial assault 
on September 11, 2001. The earlier incident was largely disregarded at the highest levels of our 
government, perhaps considered aberrant and amateurish, and it went largely unacknowledged. 
In the years up to the first World Trade Center attack, there were a number on incidents against 
Americans and American interests perpetrated, or believed to have been perpetrated, by Islamic 
radicals. But these were largely confined to the Middle East and adjacent territories. More recently, 
however, the United States has been engaged in hot wars in Iraq and Afghanistan. The war in Iraq 
quickly went from a classic military operation into an insurgency—though the “rebels” were mostly 
from outside Iraq—with the improvised explosive device a weapon of choice. The incursion by 
American forces into these countries further fanned the flames of radical Islam.
*	From Frank Bolz, Jr., Kenneth J. Dudonis, and David P. Schulz, The Counterterrorism Handbook: Tactics, 
Procedures, and Techniques, Fourth Edition, Boca Raton, FL: CRC Press, 2011. Used by permission.

418  ◾   Information Security Management Handbook
Terrorist activities on American soil by foreigners were a lightly regarded threat in large part 
because it was believed that there was not a critical mass of immigrant population through which 
terrorists could establish a support infrastructure. This has all changed with the influx of a large 
number of Middle Eastern immigrants at the end of the twentieth century and in the early years of 
the twenty-first century. The great majority of these immigrants follow the Islamic faith in a peace-
ful manner, but some do not. This has raised concern among many in the law enforcement and 
intelligence communities, but the level of their concern has not always been shared by those in other 
areas of government, particularly at the federal level, such as the Department of State, to name one.
Global War on Terrorism
A decade has passed since the devastating attack on the World Trade Center in New York City. 
The counterterrorism response that was formulated precipitated a bold and rapid reaction to what 
is still called the war on terrorism. It began in October 2001, when President George W. Bush 
told the American people, “The attack took place on the American soil, but it was an attack on the 
heart and soul of the civilized world. And the world has come together to fight a new and different 
war, the first, and we hope the only one, of the twenty-first century. A war against all those who 
seek to export terror and a war against the governments that support or shelter them.”[1] This war 
is being waged not only by the military, but also by numerous law enforcement and intelligence 
agencies around the globe. Inevitably, there are arguments as to whether bullets or diplomats are 
the way to address the problem. The answer is not easy—force must be met with force—but we 
still need the cooperation of the governments in countries where terrorists operate.
After 9/11, the United States and a number of allies began implementing policies that would 
take the war to the terrorists on multiple fronts and in multiple ways. The battle to destroy terror-
ism, or at least control it, involves diplomatic, financial, military, and traditional law enforcement 
strategies and tactics. In an effort to thwart future terrorist attacks, New York City launched a 
number of initiatives, including the placement of police detectives in selected overseas locations 
to interact with their counterparts in the gathering of intelligence information. In this way infor-
mation that is useful to New York’s safety can be transmitted directly without being first filtered 
through federal intelligence agencies.
After three decades of intensive activity by Islamic radicals who were increasing attacks in 
both number and audacity against civilized countries and their worldwide interests, the civilized 
world struck back. Led by the United States in the wake of 9/11, the fight was brought to the 
enemy, through the Taliban and al Qaeda operations in Afghanistan and the removal of Saddam 
Hussein’s regime in Iraq. Initially more than 170 nations participated in the war on terrorism by 
actively pursuing terrorists within their borders, freezing funds of terrorist support networks, and 
providing military assistance. Enthusiasm, both at home and abroad, ebbs and flows, but yet the 
war against terrorism continues.
On the domestic front, the creation of the cabinet-level Department of Homeland Security 
(DHS) brought together virtually all the federal agencies directly involved with the war on terror. 
The enactment of the USA Patriot Act codified many existing practices and extended them to uses 
specific to both preventing and fighting terrorism.
The creation of the DHS represents one of the most sweeping restructurings of the U.S. gov-
ernment in the nation’s history. The speed with which the department came into existence in the 
wake of 9/11 is almost as dramatic as the tasks assigned to the department. Though something of 
an unwieldy superagency, DHS now includes Customs and Border Protection (CBP), the Federal 

Terrorism: An Overview  ◾  419
Emergency Management Agency (FEMA), the Transportation Security Administration (TSA), U.S. 
Citizenship and Immigration Services (USCIS), the Coast Guard, U.S. Immigration and Customs 
Enforcement (ICE), and the Secret Service among its constituent agencies. On a day-to-day basis, 
none of the department’s responsibilities stray from the primary reason for its creation: to prevent ter-
rorist attacks by reducing the nation’s vulnerability to terrorism, to minimize the damage that might 
occur in the event of terrorist attacks, and to assist in the recovery from attacks that might have 
occurred. Under DHS, there are more than a hundred joint terrorism task forces around the country, 
70% of them created since 9/11, with more than 600 state and local agencies and 50 different federal 
agencies participating. Their efforts are coordinated by the National Joint Terrorism Task Force.
Though much has been made of the differences between the Bush and the Obama adminis-
trations’ respective approaches to counterterrorism, the differences are more of style and rhetoric 
than substance. The Obama administration has largely followed the groundwork developed by 
its predecessor, but has adopted new language and moved to treat some incidents as criminal acts 
rather than part of a terror war.
Meaning of Terrorism
The word terror derives from the Latin word terrere, meaning “to frighten.” The word and its 
derivatives have been applied in a variety of contexts—from a sobriquet for a vicious despot (as 
in Ivan the Terrible), to eras of violent political turbulence (as in the Reign of Terror during the 
French Revolution), to the sporadic outbursts of violence the world knows today as international 
terrorism. Violence is not the key characteristic, however, since such violent confrontations as 
World Wars I and II are not considered terrorism. Rather than being an end in itself, violence is a 
means to instill fear into, i.e., to terrify, whole populations.
Instilling fear can be purposeful for criminal or political ends that are malevolent in nature, 
yet populations can be frightened without terrorism being involved; for example, the cause may 
be disease, such as the West Nile-type avian virus that plagued sections of the United States, the 
“mad cow” virus that struck England and parts of Europe and North America, the spread of auto-
immune deficiency syndrome (AIDS) through many countries south of the equator, the severe 
acute respiratory syndrome (SARS) outbreak in China, and the deadly Ebola epidemics in sub-
Saharan Africa in the late 1990s and early twenty-first century, to name just a few. There are those 
who believe that the outbreaks of these diseases were not entirely natural but were intentionally 
spread by human intervention; if true, they would be acts of bioterrorism.
The intention of all terrorists is to instill fear in the population at large. With the bombings 
of the resort hotels and night clubs in Bali, the attacks in Mumbai, the bombings of transporta-
tion facilities in Spain and London, and of course, the attacks of 9/11, such fear has been greatly 
elevated both in the United States and around the world. For terrorists, there is a common motiva-
tion to the specific acts that they perpetrate, and frequently in today’s world it is the advancement 
of radical Islam. Because there are common elements to terrorism, counterterrorism has a founda-
tion on which to base defensive strategies and tactics. Anything that can be done to reduce fear 
and anxiety among the general population is an effective defense against terrorism.
What Is Terrorism?
The modern godfather of urban terrorism and author of the Minimanual of the Urban Guerrilla, 
Carlos Marighella, defined terrorism as action: “It is an action that the urban guerilla must execute 

420  ◾   Information Security Management Handbook
with the greatest of cold-bloodedness, calmness and decisions.”[2] No police officers, legislatures, 
or philosophers could better describe the essence of terrorism: attacks that are ruthless in nature 
and calculated in their impact on society at large.
On a more scholarly level, Brian Jenkins of the Rand Corporation described terrorism as 
“the calculated use of violence to attain goals that are political, religious or ideological in nature. 
Terrorism is a criminal act that is often symbolic in nature and intended to influence an audience 
beyond the immediate victims.”[3]
On the political level, the U.S. Department of State acknowledges that there are a range of 
definitions for terrorism, influenced particularly by the definer’s perspective on any given con-
flict or group. A middle-of-the-road definition that initially surfaced in the mid-1980s and has 
retained currency says it best: “Terrorism is a premeditated, politically motivated violence per-
petrated against non-combat targets by substantial groups of clandestine state agents, usually 
intended to influence an audience.”[4] Since 9/11, we have come to recognize, however, that all 
terrorists are not state agents; they may be adherents of groups of organizations that often act with 
the assistance of state agents.
In the past, the lack of a working definition of terrorism presented a serious problem when 
terrorists were apprehended and brought to trial. Terrorism itself was, for the most part, not 
prohibited by law, although the planting of explosive devices, kidnapping, arson, robbery, tak-
ing hostages, hijacking planes, conspiring to commit illegal acts, and similar activities were pro-
hibited by federal, state, and local laws. The result was that in court, terrorists argued they were 
being persecuted for supporting certain political or religious beliefs, and that the proceeding was 
a political trial rather than a criminal case. Arguments continue on how to adjudicate criminal 
acts committed in a terrorism context. The Obama administration has been particularly riven by 
internal debate over whether such actions should be handled by civilian courts or through military 
tribunals.
Terrorism is included in many parts of the U.S. legal code, but definitions and context vary. 
Some of these uses include:
International terrorism: Terrorism involving citizens or territory of more than one 
county.
Terrorism: Premeditated, politically motivated violence perpetrated against non-
combatant targets by substantial groups or clandestine agents.
Terrorist group: A group that has significant subgroups that practice international 
terrorism.
Terrorist territory: An area in a country or countries used by a terrorist or ter-
rorist organization to carry out terrorist activities, including training, fund-raising, 
financing, and recruitment; or as a transit point, in which the government(s) expressly 
consents to, or with knowledge, allows, tolerates, or disregards such use of its territory.
With the USA Patriot Act and related legislation, Congress has addressed terrorism at the federal 
level, and many states and even some municipalities have followed suit. The USA Patriot Act, for 
instance, provides specific authority to seize assets used by terrorists or in support of the commis-
sion of terrorist acts, thus depriving terrorists of the use of these assets, including funds. There have 
also been questions, not all of them fully resolved legally, as to whether individuals apprehended in 
the war on terrorism are “enemy combatants” who may be tried by military tribunals.
Like the creation of the DHS, the USA Patriot Act, formally named the United and 
Strengthening America by Providing Appropriate Tools Required to Intercept and Obstruct 
Terrorism Act, was signed into law in the wake of 9/11. It was adopted on October 26, 2001, 
less than two months after it was initially proposed by the Department of Justice attorneys, 

Terrorism: An Overview  ◾  421
and made permanent, with a few modifications, five years later. It is intended, in the words of 
the law, to provide the government with “resources necessary to disrupt, weaken, thwart, and 
eliminate the infrastructure of terrorist organizations, to prevent and thwart terrorist attacks, 
and to punish perpetrators of terrorist acts.”[5] Despite these national security aims, it is one 
of the most controversial pieces of domestic legislation that has become law in the past three 
decades.
Many groups, foremost among them civil libertarians, are concerned about the expansion 
of information that the law makes available to law enforcement. The law expands the methods 
permitted for collection of personal data and for sharing that data among law enforcement and 
investigative agencies. This is particularly true surrounding investigations in which foreign intel-
ligence information is sought even when it is not a primary purpose of the investigation. The USA 
Patriot Act also broadens the use of a number of traditional surveillance techniques and permits 
the expanded use of wiretaps for certain types on investigations, most of which involve, primarily, 
federal law enforcement agencies rather than local police. Provisions of the law have been, and will 
continue to be, tested in a number of court cases around the country. It remains to be seen what 
impact various sections of the law will have as the courts decide on their constitutionality and the 
part they will play in the long and ongoing fight against terrorism.
Brief History of Terrorism
International terrorism, though it has intensified in the twenty-first century, is not a new phe-
nomenon. Political betrayal, treachery, deceit, and violence have been around as long as humans 
have formed themselves into political groups. Ancient texts such as the Bible, the Iliad, and the 
Odyssey, and Egyptian hieroglyphics and letters inscribed in cuneiform on clay tablets have related 
specific details about such occurrences in the eastern Mediterranean. The act of murder for politi-
cal ends, a major component of terrorism, was raised to a fine art by a small group of Ismali Shiite 
Muslims late in the eleventh century, under the direction of Hassam-I Sabbah. His followers, who 
came to be known as Assassins, were a small fundamentalist religious sect engaged in numerous 
confrontations with other Shiites and the more dominant Sunni Muslims of the Fatimid dynasty. 
In the world of Islam, the demarcation between secular and religious authority is blurred so that a 
religious dispute may equally be viewed as political, and vice versa.
In addition to their name and legacy of terrorism, the Assassins have also been credited with 
precipitating the invention of chain-mail body armor as protection against dagger attacks. These 
loyal followers of Sabbah and his successors were known as fedai, or faithful, and as fadayeen, men 
of sacrifice.
As religious and domestically political as their motives usually were, the Assassins were not 
above engaging in terrorism on behalf of others, including, according to some accounts, Richard 
the Lion-Hearted (King Richard III of England) while he was engaged in one of his crusades 
to the Holy land. The Christian religious group Order of the Knights Templar was said to have 
adopted the Assassins’ system of military organization.
The Assassins were also trained to participate in suicide missions. They were often paid in 
advance so they could give the money to their families. The only success was the death of the tar-
get, whether or not it cost the life of the individual assassin. The Assassins eventually fell prey to 
internal squabbles and internecine disputes and were effectively neutralized as a political power by 
the middle of the thirteenth century, but managed to remain cohesive enough to resurface in the 
1830s and again in the 1940s as foes of the Shah of Iran.

422  ◾   Information Security Management Handbook
Although the Assassins were the most notorious group of historical terrorists, there have 
been many others, including the celebrated Guy Fawkes, bomber of the English Parliament (who 
nonetheless is viewed by others as a fighter against oppression). The Barbary pirates of North 
Africa in the eighteenth and nineteenth centuries made their living kidnapping citizens of other 
countries and holding them for ransom. This activity led to the founding of another Christian 
religious group, the Redemptionist Order, whose members often acted as intermediaries between 
the states of the Barbary Coast and the foreign governments whose citizens were being held 
hostage.
Terrorism in the United Kingdom
In 1605, the Gunpowder Plot involved a group with Guy Fawkes at the center that planned to kill 
King James I at the opening session of Parliament. The plan failed when one of the plotters advised 
a relative not to attend Parliament that day. Terrorism was also prominent in England during 
the nineteenth century when Irish rebels launched what became known as the Fenian Dynamite 
Campaign from the mid-1860s until 1885, in which prisons, Scotland Yard, London Bridge, the 
House of Commons, and the Tower of London became bomb targets. The 75 years from the middle 
of the nineteenth century until World War I was an active period for nationalists and rebels who 
employed terrorist acts in their campaign against the British, including a bombing campaign in 
London that diminished as World War II heated up. Sporadic bomb attacks occurred in the last 
three decades of the twentieth century as terrorists adopted the status of Northern Ireland as their 
cause. The turn of the twenty-first century saw the rise of Islamic terrorists in Great Britain, with 
bomb attacks on the London transit system and multiple other plots that were foiled by authori-
ties or otherwise failed in execution. Many of the Islamic radicals involved in these incidents were 
born in Britain, a vestige of Britain’s imperial heritage as a colonial power in regions that are today 
referred to as the Muslim world.
Modern Terrorist Groups
In the Middle East, the rise of Islamic fundamentalism in the modern era can be traced to the 
Muslim Brotherhood, founded in 1928 by Hassen al-Banna, a schoolteacher who preached for 
Sharia law. A militant wing known as the secret apparateur was formed, and in 1948 some of the 
Brotherhood members assassinated Egypt’s prime minister. A short time later, alleged government 
agents killed Hassen al-Banna. In the early 1950s the Brotherhood was accused in some 750 cases 
of arson, mostly in Cairo. The targets were mainly nightclubs, theaters, hotels, and restaurants 
frequented by the British and other Westerners, including tourists, in an effort to end the secular 
lifestyle. In 1954, after the attempt on the life of Gamal Nassar, a crackdown on the Brotherhood 
was carried out. After Nassar’s ousting, Anwar Sadat became president and eased the restrictions 
on the Brotherhood, but he also fell from favor when he signed a peace accord with Israel. He was 
assassinated on October 6, 1981, by members of the violent Tanzim al-Jihad.
The Brotherhood has spawned or inspired a number of ideological terrorist groups, such as al 
Qaeda, Hamas, and Jamaat-al-Islamiyya, to mention a few. In addition, the second in command 
to Osama bin Laden, Ayman al-Zawahiri, was a former member of the Egyptian Brotherhood.
During the 1960s, 1970s, and 1980s, radical Islamic terror groups increased in number and 
strength throughout the Middle East and also spread into Europe. This coincided with a number 

Terrorism: An Overview  ◾  423
of terrorist groups espousing a Marxist-Leninist philosophy. These groups, the most notable of 
which included the Baader-Mienhof Gang (later Red Army Faction) in Germany and the Red 
Brigades in Italy, which kidnapped and later killed Aldo Moro, a former prime minister of Italy, 
would operate well into the 1980s. It was reported that a conclave of terrorists occurred in 1983 
in Benghazi, Libya, when Muamar Khaddafy brought together more than a thousand represen-
tatives from such disparate organizations as the Palestine Liberation Army, Abu Nidal, the Irish 
Republican Army (IRA), the Puerto Rican independence group FALN, the Black Liberation 
Army, the American Indian Movement, the Nation of Islam, and several unaffiliated freelance 
terrorists, to further push their terrorist campaign against the West.
There were also a number of nationalistic groups that engaged in major acts of terrorism. One of 
the more well-known groups was the Euskadi ta Askatasuna (ETA), a Basque separatist group that 
operates throughout Spain and is still very much alive today. The Provisional Irish Republican Army, 
which was still active in the early 2000s in Ireland, Northern Ireland, and England, carried out a 
number of devastating bomb attacks around Great Britain and particularly in London. Armenian 
nationalist causes have also given rise to a number of terrorist groups going back to 1890 with 
the Armenian Revolutionary Faction, a group seeking autonomy for Armenia from the Ottoman 
Empire. More recently, the Armenian Secret Army for the Liberation of Armenia was active from the 
mid-1970s well into the 1980s, using as a rationale the massacre of Armenians by Turkey in the early 
1900s. The group launched a number of bomb attacks across Europe, mainly in Turkey and France.
The Balkans have long been a hotbed of terrorist activity, from the days of the Black Hand, 
to the assassination of Archduke Franz Ferdinand that touched off World War I, through 
the cowardly Croatian terrorist who hijacked TWA flight 355 en route to Chicago from JFK 
airport. A New York City Police Department Bomb Squad officer was killed in an attempt to 
disarm an improvised explosive device (IED) left in a locker at Grand Central Terminal by the 
hijackers.
In the United States, in the early decades of the twentieth century anarchists operating under 
the banner of the Black Hand preyed on newly arrived immigrants, especially on the Lower East 
Side of Manhattan. Their tactics of selective assassinations with guns and bombs proved extremely 
effective for a short period of time.
Many Third World leaders of Africa, the Middle East, the Caribbean, and the Pacific Rim 
engaged in activities that could be described as terrorism against colonial governments prior to 
their countries gaining independence. In the post-World War II period, the Middle East became 
a particular focal point of wars of liberation, or terrorist insurrection, depending upon politi-
cal perspective. In an area called Palestine, Zionists popularly called the Stern Gang and Irgun 
fought the British rulers for a state in the traditional Jewish homeland. When Israel was created 
and became an independent state in 1948, many Arab and Islamic residents of the immediate area 
settled outside the borders and began demanding a fully independent Palestinian state, a demand 
that continues to this time and reinforces how the designation terrorism or terrorists can be seen 
differently from opposite sides of an issue.
In the United States, the war in Vietnam and opposition to it was a springboard for launching 
a wave of domestic terrorism unparalleled in this country’s history. Such groups as the Weather 
Underground, the New World Liberation Front, and groups with similar antiwar, antiestablish-
ment, and anarchist sympathies spawned bombing campaigns, armed robberies to finance their 
activities, and other criminal acts. The attention drawn by these groups to various causes encour-
aged political radicals of other stripes, spanning the political spectrum from the Puerto Rican 
national group FALN to the Black Panthers to the anti-Castro Cuban group Omega-7, to engage 
in increasingly violent activities.

424  ◾   Information Security Management Handbook
Such domestic terrorism waned following the end of the Vietnam War, only to yield to a new 
breed of domestic terrorists that included antiabortionists, environmental extremists, and such 
radicals as Aryan Nation members, survivalists, and militia groups. Among the more notori-
ous of these was Timothy McVeigh, who carried out the bombing of a federal office building in 
Oklahoma City, Oklahoma, in 1995. Another such terrorist, Eric Rudolf, a loner with an anti-
abortion and antigay agenda, carried out a series of bombings; the most well known was at an 
Olympic venue in Atlanta, Georgia, in 1996.
Terrorism as a Political Statement
One argument often advanced by radical apologists is that the judgment of terrorists’ actions is 
purely subjective, so that one man’s terrorist is another man’s patriot and revolutionary leader. 
In recent times, this view has been articulated by the Baader-Meinhof partisans in the Red 
Army Faction, the West German terrorist group, when one of its members declared that George 
Washington was a terrorist. More pointedly, in early 2001, German Foreign Minister Joschka 
Fischer, a member of the Green Party and part of Chancellor Gerhard Schroder’s government 
alliance, admitted he had participated in terrorist activity in his youth, including incidents that 
resulted in the deaths of hostages. In a court trial, however, he swore he had never been a member 
of the Red Army Faction.
Many modern terrorists believe that they will not see their goals achieved during their life-
times, and so they view their activities as the base or building blocks of greater movements yet to 
come. These individuals, even when imprisoned, will use any and every opportunity to further 
their goals by recruiting, training, and indoctrinating new members, in addition to keeping exist-
ing members in line.
Examining, analyzing, and critiquing such philosophical arguments goes beyond the scope of 
the book. It is important to note, however, that almost every terrorist group espouses a noble or at 
least rational or justifiable cause. The truth is, however, that the terrorists may be merely a group 
of common criminals using their stated cause as a smokescreen or front for nefarious activities. 
Alternatively, a group may have legitimate origins as a political or activist organization but have 
since degenerated into terrorist activity. On rare occasions, they may actually be a group of dedi-
cated people acting on behalf of a legitimate cause against oppression or repression, but engaged 
in terrorist activity nonetheless.
Regardless of which type of group is involved, terrorist activities are all the same. The bomb-
ings, hostage takings, kidnappings, or other types of illegal behavior all present the same problems 
and challenges to law enforcement and private security personnel.
The Nature of Terrorism
Brian Jenkins of the Rand Corporation has said terrorism is “the use or threatened use of force 
designed to bring about political change,”[6] while the Federal Bureau of Investigation (FBI) has 
defined terrorism as “the unlawful use of force or violence against persons or property to intimi-
date or coerce a government, the civilian population, or any segment thereof, in furtherance of 
political or social objectives.”[7] In the twenty-first century, the once driving forces of terrorism—
Marxist-Leninism or Maoism, or both—have largely been replaced by fundamentalist Islamic 

Terrorism: An Overview  ◾  425
radicalism on the world stage. Yet Jenkins’s observation remains valid that the three most serious 
conflicts that fall short of nuclear confrontation are:
	
1.	Conventional warfare
	
2.	Guerrilla or insurgency warfare
	
3.	International terrorism
In the first two types of conflict, noncombatants are usually able to distinguish themselves 
from the combatants. This is not to say that noncombatants are never killed, because they are, 
whether through inadvertent collateral damage or at times when insurgents use noncombatant 
civilians and their houses or other structures as cover. These casualties are usually isolated or 
unusual incidents because in both guerrilla and conventional warfare the major focus of killing is 
one armed force against another. Conflicts can be either high intensity or low intensity in nature, 
such as the vast majority of combat taking place in Third World areas of the globe and the few 
confrontations in industrial nations of the world. Battlegrounds range from erstwhile socialist 
republics of the old Soviet Union, to former colonies of European imperial powers and areas where 
age-old ethnic hatreds still exist, to territories where drug trafficking is rampant.
However, the exploitation of noncombatants (i.e., their suffering and death) is the essence of 
international terrorism. Because of the covert nature of the activity, terrorist attacks can be carried 
out by a small cohort of operatives who receive financial and logistical support from radical politi-
cal and activist organizations, which can, and do, include governments of rogue nations. Political, 
ethnic, religious, fraternal, and other activist organizations may be suspected of acting in support 
of terrorist goals, even if not actually fostering and furthering these goals.
In many terrorist acts, individuals and groups only loosely connected or ostensibly unconnected 
to the terrorist operatives perform support functions, such as arranging financial assistance; provid-
ing travel documents, safe houses, and ground transportation as required; and providing alibis or 
other cover. Today we see major terrorist operations being funded not only by sympathetic state 
sponsors and wealthy ideologues, but also by legitimate business networks and so-called charitable 
funds that raise funds specifically to finance terrorist operations. Osama bin Laden built his al 
Qaeda organization with his personal wealth, donations from sympathetic family members and 
other wealthy individuals, and through the cash flow of business fronts engaged in legal activities.
The U.S. Department of Defense (DOD) has described terrorism as a phenomenon in transi-
tion and has indicated that the nature of the terrorist threat has changed dramatically. The DOD 
attributes the change to five factors:
	
1.	Collapse of the Soviet Union spawning insurgent nationalist groups
	
2.	Changing motivations of terrorists and emergence of radical Islamic fundamentalism
	
3.	Proliferation in technologies in the production of weapons of mass destruction
	
4.	Increased access to information and communication technologies
	
5.	Accelerated centralization of vital components of the national infrastructure, which has 
increased vulnerability to terrorist attack
Much of the thrust on international terrorism has been, and will continue to be, directed 
toward the United States, American targets abroad, and U.S. allies on a global scale. As seen in 
the 9/11 attacks, there is almost no limit to the imagination used in designing an assault. Attacks 
will continue to be directed toward high-profile targets that may be difficult to defend, such as 
landmark buildings and national icons. On the other hand, the most hard core of the terrorist 

426  ◾   Information Security Management Handbook
groups, such as al Qaeda, will continue to tackle high-security targets, such as airports, airplanes, 
and airline facilities, on which they seem to have a particular fixation. And most likely, they will 
be concentrated in urban locations, perpetrated by those acting on behalf of religious and ethnic 
causes and, as in the past, political points of view.
Characteristics of Terrorism
Terrorist groups are becoming tougher, more resilient, and more difficult to defeat. In addition, 
terror attacks are becoming more sophisticated and deadly. Terrorist groups evolve and adapt 
in response to the ever-changing tactics of law enforcement and intelligence agencies working 
to defeat them. Terrorist groups are organized in many different ways, including the traditional 
pyramidal power chart with a leader or small clique at the top and ever-widening tiers of authority 
moving down the chain of command. Various other configurations for depicting the organization 
of terrorist groups include circles, squares, and bull’s-eye target designs. Anarchist groups claim 
to be leaderless. With that possible exception, one thing all groups have in common is a hard-
core leadership, surrounded by active and loyal cadre, and then, moving farther from the center, 
a broader group of active supporters, and outside that, an even broader level of passive support.
In the shifting nature of terrorist groups—or at least the vocal justifications they provide for 
their actions—religion and ethnicity have equaled or surpassed politics as the driving force behind 
their stated goals. Hiding behind the shield of accepted religious organizations (or ethnic societies 
or political activist associations), support groups are free to operate with virtual impunity in most 
parts of the world and particularly in Western democracies. In addition to fund-raising, religious 
and ethnic groups provide cover for covert activities of more militant representatives of terrorist 
organizations. This has become evident since 9/11 in tracing the preincident activities of the perpe-
trators of the attacks and their supporters, where Islamic mosques in North America and Europe 
were the sites of fund-raising and recruiting activities. There is ample evidence of training camps 
organized for terrorist recruits, Islamic radicals in particular, being conducted in Afghanistan, 
Pakistan, Yemen, and Lebanon, to name a few countries where these camps have been reported.
Actions and characteristics of terrorist groups do change over time. For example, kneecapping 
was used as a signal or scar to demonstrate the wide reach of a terrorist organization during the 
1970s and 1980s. In Italy, terrorists shot the victim in the knee; in Ireland, an electric drill was 
used to mutilate the knee. In either case, victims walking around for the remainder of their lives 
with a limp were a constant reminder to the populace of terrorist power and omnipresence in the 
region. In Africa, terrorists use a machete to chop the hand(s) of victims, even children, to accom-
plish a similar effect on villagers and urban dwellers alike. Today, Islamic terrorist groups enforce 
their warped beliefs by beheading selected captured enemies who oppose their views.
Financial Terrorism
Money laundering can lead to financial terrorism or at least financing terrorism, and many well-
known financial institutions have had officers involved in moving money in and out of offshore 
banks. Some manipulations and movement of money are done for the purposes of avoiding taxes 
or legal restrictions and regulations, but often, and this is what makes the movement of funds 
money laundering, the machinations are performed to legitimize ill-gotten funds of illegal busi-
nesses, criminals, and terrorists. Major financial institutions and even governments of both large 

Terrorism: An Overview  ◾  427
and small countries have been brought down as a result of money manipulations. There are recur-
ring attempts or at least reports of attempts at large-scale counterfeiting of U.S. and other Western 
currencies by rogue states, terrorists, and criminal organizations. The USA Patriot Act and other 
legislation dealing with the use of otherwise legitimate international financial dealings for terror-
ist purposes were highlighted by President Bush in November 2001 when he said, “We put the 
world’s financial institutions on notice: If you do business with terrorists, if you support them or 
sponsor them, you will not do business with the United States of America.”[8]
Even with these strong words, little can be done about funding terrorism with legitimately 
gained funds. For example, the United States continues to rely on foreign oil, a good portion 
of which comes from the Middle East, Saudi Arabia in particular. It is strongly suspected that 
a substantial amount of oil profit is funneled through various organizations and eventually into 
the hands of terrorist organizations. Since the liberation of Iraq and the reestablishment of the 
oil industry, it is estimated that a substantial amount of oil is redirected to the black market, and 
eventually into insurgent operations.
According to Loretta Napoleoni, the Italian economist who tracks terrorist financing, the 
Taliban and al Qaeda gain funds from rogue economies located within the so-called tribal belt of 
Pakistan in South America. Centered in the city of Quetta, and similar to its New World coun-
terpart in Ciudad del Este in South America, markets thrive on trade in counterfeit luxury goods 
and stolen merchandise, as well as drugs and smuggled arms.
The following are among the tools used to monitor financial activities:
	
1.	The Terrorist Finance Tracking Program, under the aegis of the Treasury Department, 
works to identify foreign terrorist groups, assesses their funding sources and fund-raising 
methods, and provides information to law enforcement agencies as to how the funds are 
moved about.
	
2.	Operation Green Quest is a Customs Service-led multiagency initiative involving investiga-
tors from the Internal Revenue Service, the Treasury’s Office of Financial Assets Control, 
and the FBI who target sources of funding for terrorist groups.
	
3.	The Financial Action Task Force, with representatives from 35 different countries, oversees 
and reviews money laundering and terrorist financing techniques and countermeasures. The 
aim is to identify, disrupt, and dismantle the financial operations of charities and nongov-
ernmental organizations associated with Osama bin Laden and al Qaeda, as well as other 
terrorist organizations.
Early in the war on terrorism, the United States shut down al-Barakaat and al-Tawa, both of 
which were important financial conduits for al Qaeda and Osama bin Laden. In addition, in the 
United States, the Holy Land Foundation for Relief and Development was closed for activities that 
included funneling money to the Palestinian group Hamas.
Narcoterrorism is a specific type of financial terrorism that is so named because it relies on the 
profits from illegal narcotics trade to finance various terrorist activities around the world. Unlike 
most terrorism, it is not based on any ideology, but is strictly profit driven. A classic example of this 
was found in South America, where a substantial amount of profits from drug dealing were used 
to support the Revolutionary Armed Forces of Columbia, a Marxist insurgent group known by its 
acronym FARC. Drug profits from the Far East, primarily involving Afghanistan and Myanmar, 
have supported al Qaeda and other Muslim terrorist groups. Although most of the drugs filtering 
into the United States come from South America and Mexico, with Far Eastern poppies primarily 
supplying European drug markets, the intertwining of profits and support for terrorist activities 

428  ◾   Information Security Management Handbook
makes the location where the supplies end up less important than the vast amount of money the 
supplies generate.
The source countries for drug products share in common weak state authorities that are often 
corrupt or considered illegitimate by the general population. The poorer the population, the more 
likely they are to turn to drug crops, where profits greatly exceed those that could be derived from 
any legitimate agriculture or subsistence farming. Just as drug distribution sources led to the cre-
ation of such drug millionaires as Colombian cocaine baron Pablo Escobar in the 1980s, and more 
recent examples among Mexican drug cartels, those same sources have been tapped by terrorist 
groups to amass cash that can be used to pay for terrorist activities. It is extremely difficult for local 
police to stem such activity. Most cases must be made at the federal level, where agents may rely 
on a variety of federal drug, racketeering, and money laundering laws.
Terrorist Actions
By definition, terrorists espouse a philosophical, religious, or political basis for their actions, and 
thus they have strategic goals to achieve. The methods by which these goals are reached, or at least 
approached, are the tactics of terrorists. By and large, these tactics are designed to gain as much 
media attention as possible through intimidation and fear, while at the same time enhancing 
the group’s stature in its theater of political operation. Bomb attacks, hostage taking, hijacking, 
kidnapping, and similar types of assaults have been the traditional tactics of terrorists. Domestic 
terrorists, the so-called New Age terrorists of the twenty-first century, have to some extent taken 
a step backward from the violent confrontational tendencies of their predecessors. The Weather 
Underground, the FALN, and similar “bombing groups” have faded into history. The new groups 
now engage in such activities as arson, vandalism, and theft in the conduct of their ecoterrorism, 
bioterrorism, animal rights terrorism, and cyberterrorism. On the other hand, American jihadists 
tend to favor bombs, armed assaults, and similar confrontational tactics.
The bomb remains the weapon of choice among terrorists on the international level, both for 
the anonymity it affords operatives and the amount of media attention an explosion garners. This 
latter point is still valid, even in light of the relatively quick apprehension and trials, dating back 
to the 1995 Oklahoma City and 1993 World Trade Center bombings, and internationally, the 
Madrid train bombing early in 2004. There has, however, been less success against the frequent 
bomb attacks in Iraq and Afghanistan as al Qaeda and various insurgent groups try to maintain 
control over the civilian population. The success, where it has occurred, in apprehending the 
individuals and breaking up the groups of terrorist cells responsible for these actions has been 
attributed to more sophisticated investigative techniques, coupled with an increase in intelligence 
operations, particularly on the transborder international level.
The four types of bomb attacks are:
	
1.	Antipersonnel
	
2.	Symbolic target
	
3.	Selected target
	
4.	Sustained or prolonged campaign
Antipersonnel attacks include targeted individuals as well as improvised explosive devices 
(IEDs) placed in areas with a high population density that can be expected to produce a high 
casualty rate. At the other end of the spectrum are bomb attacks directed at individuals, such as 

Terrorism: An Overview  ◾  429
those of the “Unabomber,” Theodore Kaczynski, with his mail bombs, or Eric Rudolph, known 
as the abortion clinic bomber, who used strategically placed IEDs in attacking his targets. The 
devices used can be as simple as a pipe bomb, a parcel or letter bomb, or a vehicle rigged with 
explosives designed to detonate by some action of the intended driver/victim or by remote control. 
Vehicles can also be filled with explosives and driven to the attack site, sometimes by a driver pre-
pared to commit suicide to ensure the bomb is delivered. Total disregard for human life, including 
the perpetrator’s, is a common element in this type of terrorist action. Bombs directed at specific 
individuals, such as politicians, businessmen, celebrities, etc., are typically referred to as assassina-
tions or assassination attempts.
Symbolic target attacks are generally carried out against government buildings, military instal-
lations, facilities of selected corporate enterprises, or historic or iconic landmarks. The devices used 
in these attacks are usually placed at a time or a location in which casualties could be expected to 
be at a minimum, although this circumstance cannot be guaranteed to terrorists or would-be ter-
rorists. Symbolic bomb attacks are sometimes preceded by a warning call that may be construed 
as an effort to reduce casualties, although it also serves as a claim for credit by the perpetrating 
group. In recent years, the use of warning calls has waned and has been replaced by a certain group 
claiming credit for the attack by a notification to a news organization or a posting on the Internet 
after the attack is completed. Diligent security measures, call tracing techniques, voice identifica-
tion technology, and rapid response by law enforcement may have also contributed to the waning 
use of warning calls. Also helping to reduce the number of bomb attacks against the symbolic 
targets are the widespread increases in physical security and the additional use of bomb detection 
equipment, walk-through metal detectors and other sensors, and use of explosive-sniffing canines.
Selected target attackers aim at a specific facility or group of individuals in order to accom-
modate a belief or political ideology. The attack may be part of a series of actions against a gov-
ernment, a governmental agency or private enterprise, its buildings, property, or personnel, or all 
of them. Many international terrorist groups, particularly Islamic groups terrorizing Israel, the 
Jewish Diaspora, and Western sympathizers, are examples of selected target attacks, as are anti-
globalists attacking such iconic American symbols as Coca-Cola bottling plants or McDonalds 
restaurants.
Sustained or prolonged campaigns are designed to draw attention to a particular cause or target, 
such as the release of imprisoned comrades of the perpetrating group or operatives of a terrorist 
group, or even “political prisoners” believed to be sympathetic to the terrorists’ cause or aims. 
Some classic examples of this type of activity include the Real IRA attacks against Britain for an 
independent Northern Ireland, most of the Palestinian attacks against Israel, and the al Qaeda 
campaign against the United States, “the Great Satan.” The FALN and Weather Underground 
bombing campaigns during the 1970s are domestic examples of this type of attack.
Other Terrorist Actions
Hostage taking, warehousing of hostages, and other incidents involving hostages are tactics that 
may be used by terrorists to attempt to coerce governments or private companies to act in a certain 
fashion, desist from certain actions, or modify a specific point or subject. Such was the case on 
October 23, 2002, when Chechen terrorists took over an entire theater in Moscow and held the 
audience hostage. A rescue attempt by Russia proved to be a disaster, seeing some 120 of the hos-
tages dying during it. Two years later, on September 1, 2004, Chechen and Ingush terrorists occu-
pied a Russian school in Beslan in the North Caucus region, taking hundreds of schoolchildren 

430  ◾   Information Security Management Handbook
hostage in the process. Again, the rescue attempt turned into a disaster. These are extreme examples 
of hostage taking. More commonly, criminals may use hostages to abet their escape during the 
commission of a crime interrupted by the police; emotionally disturbed persons may use hostages 
in times of rage or in domestic disputes. Although there is a distinction between hostage taking 
and kidnapping, both are used by terrorists in political contexts to elicit behavior modification or 
change of heart on the part of governments or private entities. The distinction between hostage 
taking and kidnapping is, in the simplest terms, knowledge of where the victims are being held. 
Both are used to raise a group’s profile and to garner media exposure. Kidnappings, in particular, 
are also used to raise funds via ransom payments. A dramatic example of this occurred in 2000, 
when a terrorist from the Abu Sayyaf Group (ASG) kidnapped a group of tourists from a resort 
in Indonesia and removed them to the ASG camp located in the Philippines. Police freed the 
abducted tourists, including two Americans, several months later. This did not stop the ASG from 
continuing to kidnap foreigners and wealthy businessmen to extort funds. Terrorists, including 
narcoterrorists in South America and Islamic fundamentalists in Egypt, have in the past used the 
kidnapping of tourists to elicit ransoms.
Aircraft hijackings of the type we witnessed throughout the 1970s and 1980s, in which aircraft 
are left intact and passengers held as hostages, have all but disappeared due to the enhanced secu-
rity procedures that have been implemented in major airports around the globe. Nonetheless, the 
potential obviously exists for this type of action to occur, even in the age of heightened security 
precautions.
The threatened use of weapons of mass destruction by terrorists is still very real. These types 
of attacks might take the form of “dirty bombs” using toxic biological agents such as anthrax or 
chemicals such as ricin, as well as nuclear material to attack crowds of people or even entire cities. 
While threat levels have been heightened, actual use of such weapons has been limited and con-
tained within a very small number of sophisticated and well-organized terror groups.
Intimidation and Threats
The “chatter,” or terrorist operatives communicating about activity in the works or in the plan-
ning stage, has virtually vanished from the 24/7 news cycle. It was different in the immediate 
aftermath of 9/11, when it seemed every alert or warning issued by government agencies was based 
on “increased chatter” picked up by intelligence operatives monitoring terrorist activity or at key 
communication listening posts. In truth, much of the chatter was rife with misinformation or 
false threats.
As far as furthering terrorist aims, however, destructive and violent action is itself a potent 
weapon, and there are a number of different forms these threats may take:
	
1.	The bomb threat is still the most useful tool to harass or intimidate, particularly when 
privately owned facilities or industrial installations are involved. It is also a weapon against 
specialized targets, such as schools, abortion clinics, airlines, and similar facilities and opera-
tions. A bomb threat, especially one handled improperly, can cause as much disruption as an 
explosive device that is actually planted. The use of bomb threats is particularly successful in 
the aftermath of an actual terrorist attack, at a time when public awareness and apprehen-
sion are intensified. In a classic example, a bomb threat was uncovered in February 2003, 
based upon information provided by an al Qaeda operative captured during Operation 
Enduring Freedom in Afghanistan. The captive indicated al Qaeda intended to use a dirty 

Terrorism: An Overview  ◾  431
bomb against an unspecified target, resulting in the national terror threat level being raised 
to orange. The information about the dirty bomb proved to be false, whether by design or 
the captive’s intent to curry favor with his captors, but the incident caused heightened anxi-
ety levels throughout the United States and Western Europe.
	
2.	Scare or hoax bombs are simulated, improvised explosive devices that can cause an even 
longer disruption of operations than the use of an anonymous bomb threat because a search 
must be conducted and an evacuation ordered once the device is discovered. These devices 
must be treated as though they contain actual explosives, until they can be verified as other-
wise by qualified bomb technicians.
	
3.	Environmental and public service threats can generate widespread disruption and unrest, 
particularly on a short-term basis. In recent years, the threat of biological and chemical 
agents in this type of attack has increased greatly in the wake of a successful sarin gas attack 
on the Tokyo subway system in 1995 by the group Aum Shinrikyo. Threats of this nature 
have also included contaminating sources of public drinking water, attacks against electrical 
grids (i.e., power lines, transformers, generating plants, etc.), and disrupting mass transit 
systems. Also included are hacking attacks on computers supporting any of these utilities 
and installations.
	
4.	Expropriation and extortion encompass everything from armed robbery to coerced protec-
tion money used to fund an organization and its terrorist activity. This funding may include 
purchasing arms, renting and maintaining safe houses, obtaining transportation, receiving 
advanced terrorist training, or paying day-to-day living expenses. In his tract on urban 
guerillas, Carlos Marighella, a South American terrorist of the 1960s, recommends such 
illegal activities because they are the “expropriation of wealth of the principle enemies of the 
people.”[9] Such activity is more common outside the United States, particularly in Latin 
America. Domestically, however, one of the most spectacular terrorist acts of expropriation 
took place on October 21, 1981, in Nanuet, New York, when members of several different 
terrorist groups acting under the umbrella of the Armed Revolutionary Task Force bungled 
an armored car robbery. They killed one guard and two police officers at a roadblock in 
their subsequent escape attempt. Members of the gang were identified with such terrorist 
groups as the Weather Underground, the Black Liberation Army, the May 19th Communist 
Coalition, and the Republik of New Afrika. Expropriation is still a very viable weapon in the 
arsenal of a terrorist organization.
	
5.	The disruption of legitimate government operations is of paramount importance to a terror-
ist organization. With radical Islam, any influence by a Western power on the Middle East is 
an affront. One example: During the latter stages of Operation Iraqi Freedom, and particu-
larly during the country’s transition from American administration to Iraqi self-rule, terror-
ists were actively trying to undermine the effort. In Iraq, there was a series of kidnappings of 
foreign nationals—both Americans and others whose governments were allies of the United 
States. The kidnapped victims were threatened with death unless their governments ended 
their roles in Iraq. Most were subsequently executed, but one Filipino was spared when the 
Philippine government promised to withdraw its troops from Iraq. Similarly, in Spain in 
2004 Moroccans associated with al Qaeda bombed commuter trains near Madrid three 
days before national elections. The attack was credited with influencing the election so the 
candidate who opposed Spain’s support of the United States in Iraq was elected.
	
6.	Other criminal activities include almost anything that generates funds or furthers the aim of 
the terrorist organizations, or both. Drug trafficking is a major source of income, with virtu-
ally every major terrorist organization engaged in some sort of drug business either directly 

432  ◾   Information Security Management Handbook
or by providing security and performing other services for smugglers and traffickers. In the 
past, the more prominent groups involved in drug trafficking were the FARC in Colombia 
(where two IRA terrorists were apprehended along with members of FARC) and the Tamil 
Tigers in Sri Lanka. It appears now that al Qaeda operatives in the Middle East, Western 
Asia, and parts of Africa are also involved in the drug trade in the form of supplying poppies 
that eventually become heroin or opium. These poppies are grown in the Taliban-controlled 
areas of Afghanistan. Support groups abetting the 9/11 terrorists were said to have raised 
money by bootlegging cigarettes from low-tax states to high-tax urban areas.
	
7.	Sabotage and subversive acts may not be immediately recognized as terrorist acts when they 
first occur. These actions involve the blockading of military installations and damage of 
property, looting during street demonstrations, civil disobedience by disrupting transporta-
tion systems or government operations, and other actions carried out under the banner of 
“protest.” These acts of selective indignation and “spontaneous” expressions of protected 
speech are often initiated by well-intentioned, legitimate organizations that are undermined 
by terrorist-supported groups. One example: The February 15, 2003, demonstrations pro-
testing the military effort that resulted in the liberation of Iraq, the toppling of Saddam 
Hussein, and the ending of the Baathist reign in Iraq were orchestrated by an organization 
calling itself Not in Our Name. Realizing it had been undermined and used as a cover for 
nefarious intent, the organization ended its operations in the spring of 2009. There are 
many such groups that have been spawned by old-school Marxist-Leninist thinkers who use 
such issues as climate change, the petroleum industry, and financial institutions to foment 
protests and propagate an anti-American message. Some of this activity is carried out by 
anarchist groups, many of which may also voice support for Palestinian terrorists operating 
in the Middle East.
Acts of sabotage are intentional destruction of property and disruption of an industrial or 
governmental operation by means other than an explosive device. These include break-ins or other 
illegal entries designed to harass or intimidate the owners or occupants of the premises. Computer 
hacking, electronic attacks against a website, and disruption of network servers or other commu-
nications are other examples of sabotage, as are simple arson and various attacks staged by ecoter-
rorists, animal rights activists, and antiabortion extremists. More traditional incidents include 
damaging power transmission lines and oil pipelines.
Subversion is a systemic attempt to undermine a society. The ultimate objective is the total 
collapse of the state as a result of bringing its governing administration into disrepute, causing 
a loss of confidence in the ruling establishment’s institutions and government and provoking a 
breakdown of law and order.
Disinformation and Propaganda
Misinformation, disinformation, propaganda, and media manipulation are not always clearly 
defined as terrorist activities, although these actions certainly must be included as tactics employed 
by terrorist organizations and their support apparatus. In his guerilla warfare treatise, Carlos 
Marighella recommends these tactics as part of what he called a war of nerves. Such actions 
include using the telephone and mail to announce false clues to the government and police, letting 
false plans fall into the hands of the police to divert their attention, planting rumors, and exploit-
ing by every means possible the corruption, errors, and failures of government. Contemporary 

Terrorism: An Overview  ◾  433
followers of Marighella’s advice are finding new methods virtually every day to use cell phones, 
the Internet, social media, and other electronic communications to advance their agendas. Even 
knowing that law enforcement agencies may be monitoring the airwaves allows operatives the 
opportunities to provide misinformation and false leads.
Assassination
Assassination is a specialized form of assault that has been proven to be a very effective terror-
ist tool. It is the ultimate weapon of intimidation against target communities. These attacks are 
designed to gain maximum media attention as well as to have a major psychological impact on 
the organization the victim represented. Frequently, political leaders and their military or police 
officials will react to an assassination with a wave of repression aimed at the general population, 
which usually works to further the terrorists’ aims. Assassination is a tactic that has been recently 
used by such groups as the separatist Basque movement, ETA, in Spain; the FARC narcoterrorist 
rebels in Colombia; and the various Islamic groups in the Middle East.
In January 2010, in the United Arab Emirates, the Hamas military commander Mahmoud al 
Mabhouh was assassinated. It was suspected that this was carried out by more than a dozen covert 
operatives of Israel’s intelligence agency, the Mossad. Security videos at airports and hotels indi-
cated that the persons responsible for the action had fake or stolen passports and stolen identities. 
Some countries whose passports were used made vocal outcries, even to the extent of expelling 
Israeli diplomats for a time. Whether or not the expected results were accomplished remains to be 
seen. Sometimes assassinations have more immediate effects with the desired outcome. One such 
example is the shooting of Archduke Franz Ferdinand of Austria and his wife on June 28, 1914, 
in Sarajevo, Bosnia. This was carried out by a group of Bosnia Serbs. Within a month, the Great 
War, as World War I was then called, started.
Notes
	
1.	President Bush’s Opening Statement, articles.orlandosentinel.com/2001-10-12/new, viewed March 29, 
2011.
	
2.	Minimanual of the Urban Guerilla, Carlos Marighella, New World Liberation Front, 1970.
	
3.	As introduced to the U.S. Senate by Senator Abraham Ribicoff of Connecticut on October 25, 1977, 
and as indicated in On Domestic Terrorism, a publication of the National Governors Association, 
Emergency Preparedness Project, Center for Policy Research, Washington, DC, May 1979.
	
4.	Pattern of Global Terrorism—1984, U.S. Department of State, cover statement, Washington, DC, 1985.
	
5.	Strategic Plan for Fiscal Years 2001–2006, Washington, D.C., U.S. Department of Justice, 2001 
(Patriot Act).
	
6.	Defining Terrorism, drstevebest.org, viewed March 29, 2011.
	
7.	28 Code of Federal Regulations (C.F.R.) Sec. 0.85.
	
8.	The HSBC Monitor, householdwatch.com/Arizona/php, viewed March 30, 2011.
	
9.	Minimanual of the Urban Guerilla, Carlos Marighella, New World Liberation Front, 1970.


Technical Controls


437
Chapter 31
Countermeasure Goals 
and Strategies*
Thomas L. Norman
Introduction
At the completion of this chapter, you will understand why security countermeasures are required, 
and the elements of countermeasure objectives, goals, and strategies.
The term security countermeasures implies correctly that they are measures taken to counter a 
threat action. In an ideal world, security countermeasures would be so effective as to completely 
eliminate the will of potential threat actors to take action.
Although most people believe that is not possible, in fact it has been done. There are actually 
numerous examples, but perhaps the best known is the Fort Knox Gold Depository. As one could 
imagine, there have been many potential threat actors who would be interested in accessing the 
gold at Fort Knox since it was built. But none have even attempted. Countermeasures including 
a formidable building and complex, heavily armed guards, layered detection systems, automatic 
weapons (oh, and do not forget that it sits next to the largest assembly of U.S. Army tanks and 
tank crews in the world) that are so well developed that no one has ever attempted a robbery there.
Compare that to the average U.S. convenience store, which as a class, these stores have the 
highest incidence of robberies of any fixed asset, including many fatal violent attacks. It is worth-
while to compare the two in order to develop study models of risk mitigation.
Fort Knox has multiple layers of protection, including heavy arms and multiple layers of detec-
tion systems to protect its assets. Its focus is on access control.
Convenience stores have little, if any, protection—often the cash register drawer is directly acces-
sible by reaching across the counter from the public side. Access to the store is free to anyone, good 
or bad. There are generally no responsive weapons and no detection until a robbery is announced by 
the threat actor. The greatest protection is usually a video camera system that records the robbery 
but which cannot intervene. Access control is often limited to a hopeful expectation of politeness.
*	From Thomas L. Norman, Risk Analysis and Security Countermeasure Selection, Boca Raton, FL: CRC Press, 
2009. Used by permission.

438  ◾   Information Security Management Handbook
In one case, access control is heavy. In the other, access control is minimal. The obvious lesson 
is that keeping bad people out is good for security.
I am not suggesting that all facilities should be equipped like Fort Knox, because most orga-
nizations could not function with this level of access control, and the presence of automated 
.50-caliber weapons and guards on parapets with scoped weapons would be not only a deterrent 
to crime but also a deterrent to normal business.
Countermeasures should be focused not only on security measures, but also on being balanced 
with the needs of the organization’s daily business needs. Like all other business programs, compro-
mises are necessary. What are the goals of countermeasures, given that compromises are necessary?
Countermeasure Objectives, Goals, and Strategies
All security countermeasures have the broad goal of adjusting the behavior of potential threat 
actors so that they do not pose a threat to the organization.
There are three main goals for all security countermeasures:
	
1.	Where possible, identify and deny access to potential threat actors.
	
2.	Deny access to weapons, explosives, and dangerous chemicals to the facility (except for 
legitimate exceptions, which should be well controlled and monitored).
	
3.	Make the environment suitable for appropriate behavior, unsuitable for inappropriate or 
criminal or terroristic behavior, and mitigate the actions of both hazards and threats.
Implementation objectives and strategies include:
Control access to the target, denying access to possible threat actors.
Where possible, deter threat actors from acting.
Detect any threat action.
Assess what has been detected.
Delay the progress of any threat actor into or out of the facility.
Respond to any active threat action.
Gather evidence for prosecution, investigations, and training.
Comply with the business culture of the organization.
Minimize any impediment to normal business operations.
Help to create an environment where people feel safe and secure and can focus on the purpose 
of the organization.
Design programs to mitigate possible harm from hazards and threat actors.
Each aspect of the overall security program has the ability to support one of the three main 
goals. An incomplete example of how to map these is illustrated in Figure 31.1. You can use this 
as an example to help build your own list of countermeasures.
Access Control
Goals
Access control should be sufficient to facilitate access by authorized users and to deny access to 
unauthorized persons to all critical areas.

Countermeasure Goals and Strategies  ◾  439
Unlike Fort Knox, most organizations rely on access by the public to their facilities. However, 
access should not be universal. All members of the public and all employees do not require full 
access to all areas of a facility. In the most humble shop, there is a public area and a storeroom/
office. In complex facilities, access may be layered so that one needs progressively higher access 
authorization as one moves deeper into the facility.
Modes: Access control has two modes:
	
1.	Passive—Screening of employees, contractors, and vendors
	
2.	Active—Screening of entry by employees, contractors, vendors, and visitors
Passive Strategies:
Develop an employee/contractor/vendor screening program
Screen for criminal background, drug abuse (and financial responsibility where possible)
Enforce it strictly
Active Strategies: Access control should be arranged in layers, typically including:
Public areas
Semipublic areas
Controlled areas
Restricted areas
Public layers will be nearest the main public door, such as a public lobby, customer waiting 
area, or service desks.
Semipublic areas are areas where the general public may not freely go, but where they may be 
escorted, such as to an interview or triage room or emergency department in a hospital.
Controlled areas are for those individuals with authorization, such as nonpublic office floors, 
mechanical rooms, auto-mechanic work areas, airport tarmacs, and so forth.
Remove all
metal objects
before passing
through
metal detector
Figure 31.1  Security checkpoint.

440  ◾   Information Security Management Handbook
Restricted areas are those that require a high degree of vetting and where access is limited to a 
relatively small number of persons, such as research and development areas, the boardroom, main 
information technology server room, cash vaults, counting rooms, and so forth.
Access control can be achieved by technology or personnel means. There are two basic types 
of access control:
	
1.	General Access Control
	
2.	Positive Access Control
General access control assumes that if one in a group has access to a space, anyone he or she 
is escorting is also permitted. This approach is commonly used in employee work spaces and 
the like, where an access card reader on a suite door controls access to the space. General access 
control should not be used where it is important to ensure that each person in a group has access 
privileges. This is because of the phenomena of an unauthorized person “tailgating” entry behind 
an authorized person as the door is opened. Although many organizations have tried to encourage 
employees to vet visitors who try to tailgate, none I know have fully succeeded.
Positive access control uses technology or guards to assure that each person is checked to 
be sure that they are authorized to enter the space. Examples of positive access control include 
card-reader–controlled revolving doors and turnstiles, theater or sports event ticket checkers, and 
airport boarding screening.
Deterrence
Goals
Deterrence is the ultimate goal. Deterrence achieves security without intervention against a threat 
actor. Deterrence builds its own momentum. The longer attacks are deterred, the less likely it is 
that an attack may take place.
Deterrence occurs when potential threat actors evaluate the risks and rewards of an attack and 
determine that the risk is not worth the reward.
For terrorists, this could mean that an attack is not likely to succeed, that their attack would 
not capture the media’s attention, or that they could be perceived negatively by their own 
constituency.
For economic criminals, it could mean that they may not be able to access the desired assets, 
or to leave with them, or the likelihood of capture after the heist would be high.
For violent criminals, this could mean that the threat actor could not reach his target, could 
not succeed in the attack, or might not escape, or might be captured later.
For subversives, this could mean that they might not succeed in subverting the normal opera-
tions of the organization.
For petty criminals, this could mean that they might not be able to carry out their crime or 
would likely be captured in the act or later.
Strategies
Deterrence is achieved through making countermeasures visible enough that possible threat actors 
think twice about their crime. Deterrence countermeasures can include architectural hardness, 

Countermeasure Goals and Strategies  ◾  441
access control measures, guards, obvious cameras, witnesses, alarms, and alarm signs. To be effec-
tive as a deterrent, countermeasures must be visible and must seem to create too much risk to carry 
out the attack. Ultimately, the entire baseline security program is about deterrence, and it creates 
the environment for all the other countermeasure functions (Figure 31.2).
There is no such thing as deterrent-specific countermeasures. All visible countermeasures 
can act as deterrents, but no countermeasures deter alone. Deterrence is a side effect of the 
countermeasure’s other (primary) role. Countermeasures deter because the potential threat 
actor believes that the countermeasure creates risk to him. That risk is the result of the coun-
termeasure serving its primary role of limiting access, detection, assessment, response, or 
evidence gathering.
Detection
Goals
Although at first the reader may be tempted to think that detection means catching the crook in 
the act, in fact every threat actor must carry out a plan in order to attack a facility. The basic steps 
in every threat action, whether it is terrorism or vandalism, include:
Select an appropriate target for an attack.
Surveil the target to determine the target’s vulnerabilities.
Determine the best way to carry out the attack.
Plan the attack (the approach, the attack, and the escape).
Test the target to determine if the vulnerability assessment is correct.
Execute the attack:
Enter
Establish and maintain control
Establish and maintain countersurveillance
Execute the objective
Escape
For petty crimes, all these steps may occur in one linear timeline. However, the more valuable 
the asset, the more important the attack is to the threat actor’s strategic goals, the more robust the 
RESTRICTED AREA
NO ENTRY
Figure 31.2  Deterrence is achieved through making countermeasures visible enough that pos-
sible threat actors think twice about their crime.

442  ◾   Information Security Management Handbook
countermeasures, the more time is required to carry out all these steps. Interviews with highly suc-
cessful criminals indicate that the planning cycle for some crimes can take months or even years. 
This gives the target many opportunities to detect the plan through the detection of surveillance 
and interception of planning communications.
Strategies
Strategies include surveillance detection and attack detection.
Surveillance Detection
Most people think of detection as occurring during an attack; however, detection can also occur 
during surveillance. Surveillance is required for virtually every attack in order to:
Select the target.
Surveil target vulnerabilities.
Determine the best way to carry out the attack.
Test the target to determine if the vulnerability assessment is correct.
Additionally, the longer a criminal spends time with eyes on the target, the more inter-
action he may have with individuals working in the target space. Each interaction gives the 
target opportunity to recognize surveillance, attack planning or testing, and interrupt the 
attack before it occurs.
A good countersurveillance program is highly useful to all organizations where asset values 
are high, and especially where there is a possibility of violence occurring in the carrying out of a 
crime. For terrorism, a good countersurveillance program is an absolutely essential component of 
any workable terrorism countermeasures program.
A good countersurveillance program includes:
Ample use of video surveillance in exterior and public spaces
Trained and alert security officers
Trained and alert console officers
Loitering detection software on the video system
Attack Detection
Once an attack of any kind is under way, whether it is terrorism, economic crime, violent crime, 
subversive action, or a petty crime, it is important, where possible, to be able to detect the crime 
under way.
Detection countermeasures may include:
Intrusion detection system on property and building perimeters
Intrusion detection system applied to critical passageways and internal spaces
Duress alarms at critical counters and desks
Hold-up alarms

Countermeasure Goals and Strategies  ◾  443
Intrusion detection systems on property and building perimeters may include fence detection 
systems, microwave and infrared beams, seismic detectors, pneumatic line detectors, video fence-
line detection systems, glass break detectors, and door position switches.
Internal space detection systems may include door position switches, area motion detectors, 
and video motion detectors.
Duress alarms may include hidden finger switches, foot switches, and so forth.
Hold-up alarms may include duress alarms and bill traps (last bill removed in a cash drawer 
triggers a silent alarm).
Alarms may be either silent or audible. It is best to use an audible alarm if the property is 
vacant, such as at nighttime, and the audible alarm could act as a deterrent, frightening the 
intruder away. Silent alarms are best where an audible alarm could be false or nuisance and where 
on-site security staff can respond quickly and where such response would not possibly escalate the 
crime to violence.
Assessment
Goals
When an attack is detected, it is then necessary to assess the threat for the following reasons:
Is the detection real, false, or a nuisance detection?
If the detection is real, what are the level and nature of the threat actors?
What is their goal?
What weapons are they carrying?
What are their tactics?
Does this appear to be unfolding as a property or violent crime or a property crime with potential 
for violence?
Are they employing countersurveillance methods?
How are they dressed? How can law enforcement recognize the threat actors from ordinary 
employees or customers?
What is their apparent exit strategy?
Is the detection real, false, or a nuisance detection? Many alarms are either false or nuisance 
alarms. Before responding to any alarm, it is useful to investigate and assess to see if the alarm is 
real. This can often be done by using a second alarm device as a confirmation, or using a second 
technology to confirm. For example, on perimeter alarms where nuisance alarms are common, it 
is useful to have two types of alarm detection technologies, each having different nuisance modes, 
and both working together. For example, the use of infrared beams and fence line detection, where 
infrared is subject to nuisance alarms from blowing newspapers or animals, and the fence-line 
detection is subject to nuisance alarms from nearby trains. If only one alerts, it could be a nuisance 
alarm, but when both do, it is confirmed. Video cameras can also be used to confirm the alarm 
when the presence of an intruder can be seen on camera.
If the detection is real, what are the level and nature of the threat actors? Once confirmed, it is 
important to know the nature of the threat actors. How many threat actors are there? Does their 
intrusion seem organized or chaotic? Is there an obvious leader? Is the group cohesive and profes-
sional, or are they displaying anxiety and fear?

444  ◾   Information Security Management Handbook
What is their goal? Are they carrying a sign protesting the activities of the organization, or 
are they carrying automatic weapons? How many threat actors are there? Can their intentions be 
determined by their actions?
What weapons are they carrying? If the threat actors are carrying weapons, what type are 
they? Are they knives, handguns, automatic weapons, rocket-propelled grenades (RPGs), or 
mortars? Does the use of the weapons indicate a high degree of training, or do they seem 
amateurish?
What are their tactics? The tactics of an individual or group speak to their capabilities and train-
ing and preparation to use force or to counter a security presence. Tactics may indicate that it is 
appropriate to confront or to stand off.
Could their intentions include violence? Based upon observations such as their interactions with 
employees and customers, it may be possible to determine their willingness to use violence as a 
means to control the crime scene or to gain access to specific assets. The willingness to use violence 
may be important to help dictate your response.
Are they employing countersurveillance methods? The presence of obvious countersurveillance 
such as a person waiting in a car nearby but not at the door indicates a high level of prepara-
tion and planning. This indicates that contingency planning may also be in place to deal with 
approaching law enforcement or the arrival of external security team members. The presence of 
countersurveillance will dictate different response strategies.
How are they dressed? How can law enforcement recognize the threat actors from ordinary employ-
ees or customers? Whether the response will be by law enforcement or by internal security, it is 
important for them to know who are the threat actors and who are the victims. Otherwise, all 
persons will be treated as threat actors. This is especially true where the threat actors are using 
violence to control the crime scene.
What is their apparent exit strategy? Often overlooked, it is important to determine the probable 
exit strategies, where possible. These may include:
A waiting car, perhaps with a getaway driver (look for a getaway car at all exits)
Waiting motorcycles or bicycles
The use of weapons to exit the premises
The taking of hostages
The staging of stolen goods (such as dumping jewelry into a dumpster for later retrieval)
This knowledge can help to cut off the criminals or allow for the interception of the criminals 
or their stolen goods.
Strategies
Effective assessment countermeasures include video and voice communications systems.
Video cameras should be placed at all facility perimeter areas, facility approaches, and facility 
entries in order to get a positive identification of any threat actors who enter the facility and to 
determine what external support they have in terms of lookouts and getaways.
It is very useful to have a video camera viewing every reasonable area where a threat action 
could occur, including all entry control locations. This allows both detection and assessment of 
crimes in progress. It is also very useful to have a two-way voice station (intercom station or station 
without call button) near the camera wherever a threat action could occur. This allows interrup-
tion of the threat action by a remote console operator, and for many crimes, this is enough to end 
the crime.

Countermeasure Goals and Strategies  ◾  445
Response (Including Delay)
Goals
Once a threat action is detected, a response is possible. Responses to threat actions could 
include:
Take no direct action to counter the threat actors, instead try to minimize any potential harm 
to innocent people.
Gather evidence for an investigation and for a postevent analysis resulting in scenario planning 
and training later.
Call others (such as the police) for help.
Intervene directly against the attack to stop it and capture the threat actors.
Before any response is undertaken, it is necessary to formulate an appropriate response. I pro-
pose that the best time to do this is before any attack, when heads are clear and planning time is 
leisurely. It may be necessary to adjust the plan if an actual attack takes place, but at least there 
will be a response plan in place.
For example, before September 11, 2001, it was the policy of airlines to cooperate with air-
plane hijackers and let negotiators arrange for freedom of the hostages once back on the ground. 
This strategy included allowing hijackers access to the cockpit to avoid casualties on the plane. 
However, when United Airlines Flight 93 passengers used their cell phones to call loved ones after 
the plane was hijacked, the passengers learned that another plane had crashed into the World 
Trade Center, the passengers changed the strategy from one of cooperation to one of counterforce. 
Although this strategy did not save their own lives, it did save many lives in the ultimate target, in 
Washington, D.C., and, as such, was certainly an act of heroism.
Strategies
Responses may also include delaying the threat actors, denying them access to the target asset, 
voice communications for negotiations, and ultimately force on force.
As a design consultant, I am a big believer in using technology to counter threat actors instead 
of placing lives at risk. The use of reactive electronic automated protection systems (REAPS tech-
nologies) may include two-way voice communications, delaying technologies, disruptive technolo-
gies, and active force technology for direct use against threat actors. See Chapter 16 for more on 
REAPS technologies.* Also, REAPs technologies are covered in great detail in my book Integrated 
Security Systems Design.
Intercoms are the forgotten technology of security. Security intercom systems, along with 
ample use of security video systems, allow for immediate assessment of threat actions without 
dispatching a guard, which could escalate the crime to violence. One of the most effective tools 
against convenience store crimes has proven to be a two-way voice communication system that 
allows console officers in a remote security command center to speak directly to store robbers, 
alerting them that they are not only being recorded by video cameras, but that their identification 
is solid and that police have been called and are on the way, and that any escalation to violence will 
*	For even more on REAPS technologies, see the author’s book: Thomas L. Norman, Integrated Security Systems 
Design—Concepts, Specifications, and Implementation (Burlington, MA: Butterworth Heinemann, 2007).

446  ◾   Information Security Management Handbook
result in more severe charges by law enforcement. This has proven to be effective to get robbers to 
stop the robbery and leave the premises immediately without further harm to the store employees 
or customers and in many cases also without completing the robbery.
It is very useful to have a two-way voice station (intercom station or station without call but-
ton) near the camera wherever a threat action could occur. This allows interruption of the threat 
action by a remote console operator, and for many crimes, this is enough to end the crime.
Evidence Gathering
Goals
The goals of evidence include providing resources for investigations, strategy development, and 
training.
Evidence sources may include:
Video footage
Audio recordings
Fingerprints
Crime scene forensics
Computer forensics
Witness statements
Strategies
The security program should be designed to gather evidence from its outset, and personnel should 
be trained to protect physical evidence.
Camera placement should be useful to identify threat actors as they approach and enter the 
facility and at the most likely locations where crimes may occur. This requires, during the risk 
analysis, careful consideration of the types of threat scenarios that are most likely and the locations 
where such scenarios might occur. All these should be noted in the report.
Audio should be recorded on all outgoing calls to emergency responder phone numbers (911 in 
the United States and 112 in other countries) and on all active security intercom stations.
Security officers should be trained to secure a crime scene immediately after a crime until law 
enforcement arrives. Security barrier marker tape (“Crime Scene—Do Not Cross”) should be kept 
in stock for this use.
Any computers that could have been involved in a crime should be unplugged from the net-
work but left powered on, secured, and sealed for the arrival of a law enforcement or internal 
computer forensics team.
Comply with the Business Culture of the Organization
Goal
Every organization has its own unique business culture. It may be formal or relaxed, top-down 
or lateral, or open for free movement of the public or imposing restricted movements. The secu-
rity program should be configured to comply with the business culture of the organization. All 

Countermeasure Goals and Strategies  ◾  447
security measures have some consequence both to normal business operations and to the business 
culture. Both should be minimized as much as possible.
I have been consulted on many projects to correct failed security programs that, upon review, 
were basically sound in principle, but which did not take the organization’s business culture into 
account and thus were not accepted by the users. The users are stakeholders in the system. If their 
point of view and expectations of convenience and perceived intrusion are not taken into account, 
the security provisions will not be accepted. This is the most important nontechnical element that 
addresses directly the success or failure of the system.
People will naturally take the path of least resistance. And, if after many years of moving freely, 
they are suddenly confronted by a queue or a barrier, they will attempt to circumvent it because 
they are used to being able to move freely through a portal without impediment. If there is a sneak-
path, they will use it. If there is a guard, they will argue with him or her. There will be complaints, 
and pressure will be applied to the security manager to change the procedures or technology. It is 
important to take traffic flow, throughput, and people’s perceptions of how they are being treated 
by management into account.
Strategies
In the countermeasure planning phase, it is important to understand the organization’s business 
culture as much as possible. This is perhaps the most difficult task that a security practitioner has 
to do. Business cultures are rarely well documented. Culture by definition is that body of knowl-
edge that is common and allows a common communication based upon shared assumptions of 
those working together.
For example, in one high-security project, the entire campus could be easily secured by moving 
all visitor parking to an adjacent parking lot and having all visitors clear through a single visitor 
center. However, the business culture of that organization required that all visitors be granted 
access to parking on the campus, thus allowing visitors past the visitor center. Security took sec-
ond place to business culture.
It should be assumed that the security program should impede as little as possible into the 
movements of people, and the security program should ensure that everyone is treated with con-
sideration, kindness, and respect.
Minimize Impediments to Normal Business Operations
Goals
As with business culture, all security measures have some consequence to normal business opera-
tions. The security program should impede as little as possible into the normal business operations.
Strategies
The key impediment to business operations is almost always in the area of access control.
A key strategy of controlling access without creating the sense of an impediment is to rely more 
on technology than on people for security access control.
It takes more time to clear a staffed checkpoint than to clear through a card reader. And 
people tend to see technological delays as “part of the environment.” However, when the delay 

448  ◾   Information Security Management Handbook
is associated with a security guard, they tend to personalize the screening action. (People 
sometimes presuppose a bias against the person by the screener and infer an intent on the part 
of the security officer to delay the person.) No such intent can be imposed on a card reader, as 
technology has no capacity to develop intent or biases or to distinguish any one person from 
another.
This strategy has other benefits as well. Because technology does not distinguish people, it 
treats everyone fairly and cannot be compromised by threat, intimidation, or enticement.
All security officers dealing with the public should be trained to be gracious under fire and not 
to personalize any verbal abuse.
In areas where people are carrying bags or totes, provisions should be made to use as few hand 
actions as possible. In such cases, the use of photo IDs as an access vetting measure can help speed 
people along.
Safe and Secure Environments
Goals
Help to create an environment where people feel safe and secure and can focus on the purpose of 
the organization.
Strategies
The use of crime prevention through environmental design (CPTED) principles helps to create a 
safe and secure environment and conveys a feeling of safety and security to all.
Good lighting, gracious guards, well-maintained facilities and security equipment, good way-
finding signage, security awareness inserts in the company newsletter—all these things contribute 
to a feeling of well-being on the part of users.
Design Programs to Mitigate Possible Harm 
from Hazards and Threat Actors
The security program should include elements to deal with unwanted exceptions, such as:
Intruders and Offenders
Disruptive People
Medical Emergencies
Natural Disasters
Civil Disorder and Riot
Loss of Business Continuity
Chemical, Biological, Radiological Emergency
Challenges to the Security Program from Outside and Inside Sources
Countermeasure goals and functions are presented in Table 31.1.

Countermeasure Goals and Strategies  ◾  449
Table 31.1  Countermeasure Goals and Functions (Examples)
Countermeasure 
Goals
Countermeasure Functions
Access 
Control
Deterrence
Detection
Assessment
Delay
Response
Evidence
Identify and Deny 
Access to Potential 
Threat Actors
Access Control, 
Screening Posts, 
and Employee 
Screening
Visible Devices, 
Signage, 
Guards, and 
Procedures
Guards, Dogs, 
and Alarm 
Devices 
Including Video 
Motion
Console, 
Guards, and 
Security 
Awareness 
Policy
Operable 
Barriers and 
Guard Posts
Console, 
Guards, 
Operable 
Barriers and 
Intercoms
CCTV, 
Intercoms, and 
Witness Reports
Deny Access to 
Weapons, Explosives, 
and Dangerous 
Chemicals to the 
Facility
Screening, 
Guard Posts, 
and Procedures
Signage, 
Guards, and 
Procedures
Detectors, Dogs, 
Guards, and 
Procedures
Screening Posts, 
Detectors, Dogs, 
and Patrols
Operable 
Barriers and 
Guard Posts
Console, 
Guards, 
Operable 
Barriers and 
Intercoms
CCTV, 
Intercoms, and 
Witness Reports
Make the 
Environment Suitable 
for Appropriate 
Behavior and 
Unsuitable for 
Inappropriate for 
Criminal or 
Terroristic Behavior, 
and to Mitigate the 
Actions of Both 
Hazards and Threats
CPTED Design, 
Policies and 
Procedures, 
Training 
Programs, and 
Security 
Awareness 
Programs
CPTED Design, 
Policies and 
Procedures, 
Training 
Programs, and 
Security 
Awareness 
Programs
Patrols and 
Reports by 
Organization 
Members
Patrols and 
Reports by 
Organization 
Members
See Above
See Above
CCTV, 
Intercoms, and 
Witness Reports

450  ◾   Information Security Management Handbook
Summary
Security countermeasures are measures that are taken to counter a threat action. Ideally, secu-
rity countermeasures would be so effective as to completely eliminate the will of potential threat 
actors to take action. Countermeasures should be focused on both security measures but also on 
being balanced with the needs of the organization’s daily business needs. Compromises are always 
necessary.
All security countermeasures have the broad goal of adjusting the behavior of potential threat 
actors so that they do not pose a threat to the organization. This is done in three ways:
	
1.	Design an environment that encourages appropriate behavior and discourages inappropri-
ate, criminal, or terroristic behavior.
	
2.	Detect, assess, and respond to exceptions.
	
3.	Design the program to mitigate any potential harm from hazards and threats.
Implementation strategies include:
Control access to the target, denying access to possible threat actors.
Deter any threat action from occurring.
Detect any threat action.
Assess what has been detected.
Respond to any active threat action.
Gather evidence for prosecution, investigation, and training.
Comply with the business culture of the organization.
Minimize any impediment to normal business operations.
Help to create an environment where people feel safe and secure and can focus on the purpose 
of the organization.
Design programs to mitigate possible harm from hazards and threat actors.

451
Information Security 
Management Handbook: 
Comprehensive Table 
of Contents
Domain 1  Access Control
Title
Vol. 1 
Vol. 2 
Vol. 3 
Vol. 4 
Vol. 5
Vol. 6
1.1 Access Control Techniques
A Look at RFID Security, Ben Rothke 
x 
New Emerging Information Security 
Technologies and Solutions, Tara 
Chand 
x 
Sensitive or Critical Data Access 
Controls, Mollie E. Krehnke and 
David Krehnke 
x 
An Introduction to Role-Based Access 
Control, Ian Clark 
x 
Smart Cards, Jim Tiller 
x 
A Guide to Evaluating Tokens, Joseph 
T. Hootman 
x 
Controlling FTP: Providing Secured 
Data Transfers, Chris Hare 
x 
Authentication Tokens, Paul A. Henry 
x 
Authentication and the Role of 
Tokens, Jeff Davis 
x 
(continued)

452  ◾  Comprehensive Table of Contents
Domain 1 (continued)  Access Control
Title 
Vol. 1 
Vol. 2 
Vol. 3 
Vol. 4 
Vol. 5
Vol. 6
Expanding PKI-Based Access Control 
Capabilities with Attribute 
Certificates, Alex Golod 
x 
Whitelisting for Endpoint Defense, 
Rob Shein
x
Whitelisting, Sandy Bacik
x
1.2 Access Control Administration 
Back to the Future, Paul A. Henry 
x 
End Node Security and Network 
Access Management: Deciding 
among Different Strategies, Franjo 
Majstor 
x
Identity Management: Benefits and 
Challenges, Lynda L. McGhie 
x
Blended Threat Analysis: Passwords 
and Policy, Daniel D. Houser 
x
Accountability, Dean R. Bushmiller 
x 
Five Components to Identity 
Management Systems, Kevin 
Castellow 
x 
RFID and Information Security, 
Salahuddin Kamran
x
Privileged User Management, 
Georges J. Jahchan
x
Privacy in the Age of Social 
Networking, Salahuddin Kamran
x
What Business Associates Need to 
Know about Protected Health 
Information under HIPAA and 
HITECH, Rebecca Herold
x
1.3 Identification and Authentication Techniques
Enhancing Security through Biometric 
Technology, Stephen D. Fried 
x
Single Sign-On for the Enterprise, 
Ross A. Leo 
x

Comprehensive Table of Contents  ◾  453
Domain 1 (continued)  Access Control
Title 
Vol. 1 
Vol. 2 
Vol. 3 
Vol. 4 
Vol. 5
Vol. 6
1.4 Access Control Methodologies and Implementation
Centralized Authentication Services 
(RADIUS, TACACS, DIAMETER), Bill 
Stackpole
x
An Introduction to Secure Remote 
Access, Christina M. Bird
x
1.5 Methods of Attack
Hacker Tools and Techniques, 
Ed Skoudis 
x
A New Breed of Hacker Tools and 
Defenses, Ed Skoudis 
x
Breaking News: The Latest Hacker 
Attacks and Defenses, Ed Skoudis 
x
Counter-Economic Espionage, Craig 
A. Schiller 
x
Rootkits: The Ultimate Malware Threat, 
E. Eugene Schultz and Edward Ray 
x 
Security Weaknesses of System and 
Application Interfaces Used to Process 
Sensitive Information, Sean Price 
x 
1.6 Monitoring and Penetration Testing 
Insight into Intrusion Prevention 
Systems, Gildas Deograt-Lumy 
x 
Penetration Testing, Stephen D. Fried 
x 
Domain 2  Telecommunications and Network Security
Title 
Vol. 1 
Vol. 2 
Vol. 3 
Vol. 4 
Vol. 5
Vol. 6
2.1 Communications and Network Security 
Adaptive Threats and Defenses, Sean 
Price 
x 
Achieving Global Information Systems 
Transformation (GIST) through 
Standards: Foundations for Standards-
Based Network Visibility via IF-MAP 
and Beyond, David O’Berry 
x 
(continued)

454  ◾  Comprehensive Table of Contents
Domain 2 (continued)  Telecommunications and Network Security
Title
Vol. 1
Vol. 2
Vol. 3
Vol. 4
Vol. 5
Vol. 6
A Primer on Demystifying U.S. 
Government Networks, Samuel 
W. Chun
x 
Network Security Utilizing an 
Adaptable Protocol Framework, 
Robby Fussell 
x 
The Five W’s and Designing a Secure, 
Identity-Based, Self-Defending 
Network (5W Network), Samuel W. 
Chun 
x 
Maintaining Network Security: 
Availability via Intelligent Agents, 
Robby Fussell 
x 
PBX Firewalls: Closing the Back Door, 
William A. Yarberry, Jr. 
x 
Network Security Overview, Bonnie 
A. Goins and Christopher A. Pilewski 
x 
Putting Security in the Transport: TLS, 
Chris Hare 
x 
WLAN Security Update, Franjo 
Majstor 
x
Understanding SSL, Chris Hare 
x
Packet Sniffers and Network 
Monitors, James S. Tiller and Bryan D. 
Fish 
x
Secured Connections to External 
Networks, Steven F. Blanding 
x
Security and Network Technologies, 
Chris Hare 
x
Wired and Wireless Physical Layer 
Security Issues, James Trulove 
x
Network Router Security, Steven F. 
Blanding 
x
What’s Not So Simple about SNMP? 
Chris Hare 
x
Network and Telecommunications 
Media: Security from the Ground Up, 
Samuel Chun 
x

Comprehensive Table of Contents  ◾  455
Domain 2 (continued)  Telecommunications and Network Security
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
Security and the Physical Network 
Layer, Matthew J. Decker 
x
Wireless LAN Security Challenge, 
Frandinata Halim and Gildas Deograt 
x
ISO/OSI and TCP/IP Network Model 
Characteristics, George G. McBride 
x
Facsimile Security, Ben Rothke 
x 
Mobile Data Security, George 
McBride
x
Integrated Security through Open 
Standards: A Path to Enhanced 
Network Visibility, David O’Berry 
x 
IF-MAP as a Standard for Security Data 
Interchange, David O’Berry
x
2.2 Internet, Intranet, Extranet Security
VoIP Security Issues, Anthony Bruno 
x 
An Examination of Firewall 
Architectures, Paul A. Henry 
x 
Voice over WLAN, Bill Lipiczky 
x 
Spam Wars: How to Deal with Junk 
E-Mail, Al Bredenberg 
x 
Secure Web Services: Holes and 
Fillers, Lynda L. McGhie 
x 
IPSec Virtual Private Networks, James 
S. Tiller 
x 
Internet Security: Securing the 
Perimeter, Douglas G. Conorich 
x 
Application-Layer Security Protocols 
for Networks, Bill Stackpole 
x 
Application Layer: Next Level of 
Security, Keith Pasley 
x 
Security of Communication Protocols 
and Services, William Hugh Murray 
x 
An Introduction to IPSec, Bill 
Stackpole 
x 
(continued)

456  ◾  Comprehensive Table of Contents
Domain 2 (continued)  Telecommunications and Network Security
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
VPN Deployment and Evaluation 
Strategy, Keith Pasley 
x 
Comparing Firewall Technologies, Per 
Thorsheim 
x 
Cookies and Web Bugs: What They 
Are and How They Work Together, 
William T. Harding, Anita J. Reed, and 
Robert L. Gray 
x 
Security for Broadband Internet 
Access Users, James Trulove
x
Network Content Filtering and Leak 
Prevention, Georges J. Jahchan
x
Web Application Firewalls, Georges 
J. Jahchan 
x
Understating the Ramifications of 
IPv6, Foster Henderson
x
E-Mail Security, Terence Fernandes
x
2.3 E-Mail Security 
Instant Messaging Security Issues, 
William Hugh Murray 
x 
2.4 Secure Voice Communications 
Voice Security, Chris Hare 
x 
Secure Voice Communications, 
Valene Skerpac 
x 
2.5 Network Attacks and Countermeasures 
Deep Packet Inspection 
Technologies, Anderson Ramos 
x 
Wireless Penetration Testing: Case 
Study and Countermeasures, 
Christopher Pilewski
x
Auditing the Telephony System: 
Defenses against Communications 
Security Breaches and Toll Fraud, 
William A. Yarberry, Jr.
x
Insecurity by Proxy, Micah Silverman
x

Comprehensive Table of Contents  ◾  457
Domain 2 (continued)  Telecommunications and Network Security
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
Wireless Security, Charles R. Hudson 
and Chris R. Cunningham
x
Packet Sniffers: Use and Misuse, 
Steve A. Rodgers
x
ISPs and Denial-of-Service Attacks, K. 
Narayanaswamy
x
The Ocean Is Full of Phish, Todd 
Fitzgerald
x
Botnets, Robert M. Slade
x
Antispam: Bayesian Filtering, Georges 
J. Jahchan
x
Managing Security in Virtual 
Environments, E. Eugene Schultz and 
Edward Ray
x
Domain 3  Information Security and Risk Management
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
3.1 Security Management Concepts and Principles
Bits to Bytes to Boardroom, Micki 
Krause
x
Information Security Governance, 
Todd Fitzgerald
x
Corporate Governance, David 
Krehnke
x
IT Governance Institute (ITGI) 
Overview, Molly Krehnke
x
Top Management Support Essential 
for Effective Information Security, 
Kenneth J. Knapp and Thomas 
E. Marshall
x
Managing Security by the Standards: 
An Overview and Primer, Bonnie A. 
Goins
x
Information Security for Mergers and 
Acquisitions, Craig A. Schiller
x
(continued)

458  ◾  Comprehensive Table of Contents
Domain 3 (continued)  Information Security and Risk Management
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
Information Security Governance, 
Ralph Spencer Poore 
x 
Belts and Suspenders: Diversity in 
Information Technology Security, 
Jeffrey Davis 
x 
Building Management Commitment 
through Security Councils, Todd 
Fitzgerald 
x 
Validating Your Business Partners, Jeff 
Misrahi 
x 
Measuring ROI on Security, Carl F. 
Endorf 
x 
The Human Side of Information 
Security, Kevin Henry 
x 
Integrated Threat Management, 
George G. McBride 
x 
Understanding Information Security 
Management Systems, Tom Carlson 
x 
Security Management, Ken Buszta 
x 
It Is All about Control, Chris Hare 
x 
Collaborating Information Security 
and Privacy to Create Effective 
Awareness and Training, Rebecca 
Herold
x
Security Information and Event 
Management (SIEM) Technology, 
E. Eugene Schultz 
x 
Managing Mobile Device Security, 
E. Eugene Schultz and Gal Shpantzer
x 
Establishing an Information Security 
Program for Local Government, 
Robert Pittman 
x 
Do Your Business Associate Security 
and Privacy Programs Live Up to 
HIPAA and HITECH Requirements? 
Rebecca Herold
x
Organization Culture Awareness Will 
Cultivate Your Information Security 
Program, Robert Pittman
x

Comprehensive Table of Contents  ◾  459
Domain 3 (continued)  Information Security and Risk Management
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
Appreciating Organizational Behavior 
and Institutions to Solidify Your 
Information Security Program, 
Robert K. Pittman, Jr.
x
3.2 Change Control Management
Patch Management 101: It Just Makes 
Good Sense! Lynda McGhie
x
Security Patch Management Process, 
Felicia M. Nicastro
x
Configuration Management: Charting 
the Course for the Organization, 
Mollie E. Krehnke and David 
C. Krehnke
x
3.3 Data Classification
Understanding Information Risk 
Management, Tom Carlson and Nick 
Halvorson
x
Information Classification: A 
Corporate Implementation Guide, 
Jim Appleyard
x
Ownership and Custody of Data, 
William Hugh Murray
x
Developing and Conducting a Security 
Test and Evaluation, Sean M. Price
x
Enterprise Security Management, 
George McBride
x
A Matter of Trust, Ray Kaplan
x
Trust Governance in a Web Services 
World, Daniel D. Houser
x
3.4 Risk Management
The Role of Information Security in the 
Enterprise Risk Management Structure, 
Carl Jackson and Mark Carey
x
Technology Convergence and 
Security: A Simplified Risk 
Management Model, Ken M. 
Shaurette 
x 
(continued)

460  ◾  Comprehensive Table of Contents
Domain 3 (continued)  Information Security and Risk Management
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
Using Quasi-Intelligence Resources to 
Protect the Enterprise, Craig A. Schiller 
x 
Information Risk Management: A 
Process Approach to Risk Diagnosis 
and Treatment, Nick Halvorson 
x 
Department-Level Transformation, 
R. Scott McCoy 
x 
Setting Priorities in Your Security 
Program, Derek Schatz 
x 
Why and How Assessment of 
Organization Culture Shapes Security 
Strategies, Don Saracco 
x 
Information Security Risk 
Assessment, Samantha Thomas Cruz 
x 
Risk Management and Analysis, Kevin 
Henry 
x 
New Trends in Information Risk 
Management, Brett Regan Young 
x 
Cyber-Risk Management: Technical 
and Insurance Controls for Enterprise-
Level Security, Carol A. Siegel, Ty R. 
Sagalow, and Paul Serritella 
x 
A Look Ahead, Samantha Thomas 
x 
The Insider Threat: A View from the 
Outside, Todd Fitzgerald 
x 
Pod Slurping, Ben Rothke 
x 
The USB (Universal Security Burden) 
Nightmare: Pod-Slurping and Other 
High Storage Capacity Portable Device 
Vulnerabilities, Kenneth F. Belva
x
Diary of a Security Assessment: “Put 
That in Your Pipe and Smoke It!” Ken 
M. Shaurette
x
Role-Based Information Security
Governance: Avoiding the Company 
Oil Slick, Todd Fitzgerald
x
Social Networking Security Exposure, 
Sandy Bacik
x
Social Networking, Social Media, and 
Web 2.0 Security Risks, Robert M. Slade
x

Comprehensive Table of Contents  ◾  461
Domain 3 (continued)  Information Security and Risk Management
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
Applying Adult Education Principles 
to Security Awareness Programs, 
Chris Hare
x
The Information Security Auditors Have 
Arrived, Now What?, Todd Fitzgerald
x
Continuous Monitoring: Extremely 
Valuable to Deploy Within Reason, 
Foster J. Henderson and Mark A. 
Podracky
x
Social Networking, Sandy Bacik
x
Insider Threat Defense, Sandy Bacik
x
Risk Management in Public Key 
Certificate Applications, Alex Golod
x
Server Virtualization: Information 
Security Considerations, Thomas A. 
Johnson
x
3.5 Policies, Standards, Procedures, and Guidelines 
Committee of Sponsoring 
Organizations (COSO), Mignona Cote 
x 
Toward Enforcing Security Policy: 
Encouraging Personal Accountability 
for Corporate Information Security 
Policy, John O. Wylder 
x 
The Security Policy Life Cycle: 
Functions and Responsibilities, 
Patrick D. Howard 
x 
People, Processes, and Technology: A 
Winning Combination, Felicia M. 
Nicastro 
x 
Building an Effective Privacy Program, 
Rebecca Herold 
x 
Establishing an E-Mail Retention 
Policy: Preventing Potential Legal 
Nightmares, Stephen Fried 
x 
Ten Steps to Effective Web-Based 
Security Policy Development and 
Distribution, Todd Fitzgerald 
x 
(continued)

462  ◾  Comprehensive Table of Contents
Domain 3 (continued)  Information Security and Risk Management
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
Roles and Responsibilities of the 
Information Systems Security Officer, 
Carl Burney
x
Organizing for Success: Some Human 
Resources Issues in Information 
Security, Jeffrey H. Fenton and James 
M. Wolfe
x
Information Security Policies from the 
Ground Up, Brian Shorten 
x 
Policy Development, Chris Hare 
x 
Training Your Employees to Identify 
Potential Fraud and How to 
Encourage Them to Come Forward, 
Rebecca Herold 
x 
Planning for a Privacy Breach, 
Rebecca Herold 
x 
A Business Case for ISO 27001 
Certification, Tom Carlson and Robert 
Forbes 
x 
Achieving PCI DSS Compliance: A 
Compliance Review, Bonnie A. Goins 
and Christopher A. Pilewski 
x 
The Sarbanes–Oxley Revolution: Hero 
or Hindrance? Seth Kinnett 
x 
Leveraging IT Control Frameworks for 
Compliance, Todd Fitzgerald 
x 
Rats in the Cellar and Bats in the Attic, 
“Not Enough Depth to My Security”, 
Ken M. Shaurette 
x 
Security Outsourcing, Sandy Bacik
x
3.6 Security Awareness Training 
Measuring Information Security and 
Privacy Training and Awareness 
Effectiveness, Rebecca Herold 
x 
Change That Attitude: The ABCs of a 
Persuasive Security Awareness 
Program, Sam Chun 
x 

Comprehensive Table of Contents  ◾  463
Domain 3 (continued)  Information Security and Risk Management
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
Maintaining Management’s 
Commitment, William Tompkins 
x 
Making Security Awareness Happen, 
Susan D. Hansche 
x 
Beyond Information Security 
Awareness Training: It Is Time to 
Change the Culture, Stan Stahl 
x 
3.7 Security Management Planning 
The Outsourcing of IT: Seeing the Big 
Picture, Foster Henderson 
x 
Overview of an IT Corporate Security 
Organization, Jeff Davis 
x 
Make Security Part of Your Company’s 
DNA, Ken M. Shaurette 
x 
Building an Effective and Winning 
Security Team, Lynda McGhie 
x 
When Trust Goes beyond the Border: 
Moving Your Development Work 
Offshore, Stephen Fried 
x 
Maintaining Information Security 
during Downsizing, Thomas J. Bray 
x 
The Business Case for 
Information Security: Selling 
Management on the Protection of 
Vital Secrets and Products, Sanford 
Sherizen 
x 
How to Work with a Managed 
Security Service Provider, Laurie Hill 
McQuillan 
x 
Considerations for Outsourcing 
Security, Michael J. Corby 
x 
Achieving NERC Compliance: A 
Compliance Review, Bonnie Goins 
Pilewski and Christopher A. 
Pilewski 
x 
Controlling the Emerging Data 
Dilemma: Building Policy for 
Unstructured Data Access, Anne 
Shultz
x
(continued)

464  ◾  Comprehensive Table of Contents
Domain 3 (continued)  Information Security and Risk Management
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
Governance and Risk Management 
within the Context of Information 
Security, James C. Murphy
x
Improving Enterprise Security 
through Predictive Analysis, Chris 
Hare
x
Security Requirements Analysis, Sean 
M. Price
x
CERT Resilience Management Model: 
An Overview, Bonnie A. Goins 
Pilewski and Christopher Pilewski
x
Managing Bluetooth Security, 
E. Eugene Schultz, Matthew W. A. 
Pemble, and Wendy Goucher
x
3.8 Ethics 
The Ethical and Legal Concerns of 
Spyware, Janice C. Sipior, Burke T. 
Ward, and Georgina R. Roselli 
x 
Ethics and the Internet, Micki Krause 
x 
Computer Ethics, Peter S. Tippett 
x 
3.9 Employment Policies and Practices
Slash and Burn: In Times of 
Recession, Do Not Let Emotions Drive 
Business Decisions, Anonymous
x
A “Zero Trust” Model for Security, Ken 
Shaurette and Thomas J. 
Schleppenbach
x
Domain 4  Application Development Security
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
4.1 Application Issues 
Application Service Provider Security: 
Ensuring a Secure Relationship for 
the Client and the ASP, Stephen D. 
Fried 
x 
Stack-Based Buffer Overflows, 
Jonathan S. Held 
x 

Comprehensive Table of Contents  ◾  465
Domain 4 (continued)  Application Development Security
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
Web Application Security, Mandy 
Andress 
x 
Security for XML and Other Metadata 
Languages, William Hugh Murray 
x 
XML and Information Security, 
Samuel C. McClintock 
x 
Application Security, Walter S. Kobus, 
Jr. 
x 
Covert Channels, Anton Chuvakin 
x 
Security as a Value Enhancer in 
Application Systems Development, 
Lowell Bruce McCulley 
x 
Open Source versus Closed Source, 
Ed Skoudis 
x 
A Look at Java Security, Ben Rothke 
x 
Neural Networks and Information 
Assurance Uses, Sean M. Price 
x 
Information Technology 
Infrastructure Library and Security 
Management Overview, David 
McPhee 
x 
Adaptation: A Concept for Next-
Generation Security Application 
Development, Robby S. Fussell 
x 
Quantum Computing: Implications 
for Security, Robert M. Slade 
x 
Mashup Security, Mano Paul 
x 
Format String Vulnerabilities, Mano 
Paul 
x 
4.2 Databases and Data Warehousing
Reflections on Database Integrity, 
William Hugh Murray
x
Digital Signatures in Relational 
Database Applications, Mike R. 
Prevost 
x 
(continued)

466  ◾  Comprehensive Table of Contents
Domain 4 (continued)  Application Development Security
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
Security and Privacy for Data 
Warehouses: Opportunity or Threat? 
David Bonewell, Karen Gibbs, and 
Adriaan Veldhuisen 
x 
4.3 Systems Development Controls 
Data Loss Prevention Program, Powell 
Hamilton 
x 
Data Reliability: Trusted Time Stamps, 
Jeff Stapleton 
x 
Security in the .NET Framework, 
James D. Murray 
x 
Building and Assessing Security in the 
Software Development Lifecycle, 
George G. McBride 
x 
Avoiding Buffer Overflow Attacks, 
Sean Price 
x 
Secure Development Life Cycle, 
Kevin Henry 
x 
System Development Security 
Methodology, Ian Lim and Ioana V. 
Bazawan 
x 
Software Engineering Institute 
Capability Maturity Mode, Matt Nelson 
x 
Enterprise Security Architecture, 
William Hugh Murray 
x 
Certification and Accreditation 
Methodology, Mollie E. Krehnke and 
David C. Krehnke 
x 
System Development Security 
Methodology, Ian Lim and Ioana V. 
Carastan 
x 
Methods of Auditing Applications, 
David C. Rice and Graham Bucholz
x
The Effectiveness of Access 
Management Reviews, Chris Hare
x
Securing SaaS Applications: A Cloud 
Security Perspective for Application 
Providers, Pradnyesh Rane
x
Attacking RFID Systems, Pedro 
Peris-Lopez, Julio Cesar Hernandez-
Castro, Juan M. Estevez-Tapiador, and 
Arturo Ribagorda
x

Comprehensive Table of Contents  ◾  467
Domain 4 (continued)  Application Development Security
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
Application Whitelisting, Georges J. 
Jahchan
x
Design of Information Security for 
Large System Development Projects, 
James C. Murphy
x
Building Application Security Testing 
into the Software Development Life 
Cycle, Sandy Bacik
x
4.4 Malicious Code 
Fast Scanning Worms, Paul A. Henry 
x 
Organized Crime and Malware, 
Michael Pike 
x 
Net-Based Malware Detection: A 
Comparison with Intrusion Detection 
Models, Robert M. Slade 
x 
Malware and Computer Viruses, 
Robert M. Slade 
x 
An Introduction to Hostile Code and 
Its Control, Jay Heiser 
x 
A Look at Java Security, Ben Rothke 
x 
Twenty-Five (or Forty) Years of 
Malware History, Robert M. Slade
x
4.5 Methods of Attack 
Hacking Methods, Georges J. Jahchan 
x 
Enabling Safer Deployment of 
Internet Mobile Code Technologies, 
Ron Moritz 
x 
Domain 5  Cryptography
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
5.1 Use of Cryptography 
Auditing Cryptography: Assessing 
System Security, Steve Stanek 
x
Three New Models for the Application 
of Cryptography, Jay Heiser
x
(continued)

468  ◾  Comprehensive Table of Contents
Domain 5 (continued)  Cryptography
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
5.2 Cryptographic Concepts, Methodologies, and Practices
Cryptography: A Unifying Principle in 
Compliance Programs, Ralph Spencer 
Poore
x
Cryptographic Transitions, Ralph 
Spencer Poore
x
Blind Detection of Steganographic 
Content in Digital Images Using 
Cellular Automata, Sasan Hamidi
x
An Overview of Quantum 
Cryptography, Ben Rothke
x
Elliptic Curve Cryptography: 
Delivering High-Performance 
Security for E-Commerce and 
Communications, Paul Lambert 
x 
Cryptographic Key Management 
Concepts, Ralph Spencer Poore 
x 
Message Authentication, James S. 
Tiller 
x 
Fundamentals of Cryptography and 
Encryption, Ronald A. Gove 
x 
Steganography: The Art of Hiding 
Messages, Mark Edmead 
x 
An Introduction to Cryptography, 
Javek Ikbal 
x 
Hash Algorithms: From Message 
Digests to Signatures, Keith Pasley 
x 
A Look at the Advanced Encryption 
Standard (AES), Ben Rothke 
x 
Message Digest, Ralph Spencer Poore 
x
 
Quantum Computing: The Rise of the 
Machine, Robby Fussell 
x
 
Cryptography: Mathematics vs. 
Engineering, Ralph Spencer Poore
x
Cryptographic Message Syntax, Jeff 
Stapleton
x
Format Preserving Encryption, Ralph 
Spencer Poore
x

Comprehensive Table of Contents  ◾  469
Domain 5 (continued)  Cryptography
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
Elliptic Curve Cryptosystems, Jeff 
Stapleton
x
Pirating the Ultimate Killer App: 
Hacking Military Unmanned Aerial 
Vehicles, Sean P. McBride
x
5.3 Private Key Algorithms
Principles and Applications of 
Cryptographic Key Management, 
William Hugh Murray
x
5.4 Public Key Infrastructure (PKI)
Preserving Public Key Hierarchy, 
Geoffrey C. Grabow
x
PKI Registration, Alex Golod
x
Encryption Key Management in 
Large-Scale Network Deployments, 
Franjo Majstor and Guy Vancollie
x
5.5 System Architecture for Implementing Cryptographic Functions 
Implementing Kerberos in Distributed 
Systems, Joe Kovara and Ray Kaplan 
x 
5.6 Methods of Attack
Methods of Attacking and Defending 
Cryptosystems, Joost Houwen
x
Domain 6  Security Architecture and Design
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
6.1 Principles of Computer and Network Organizations, Architectures, and Designs
Enterprise Assurance: A Framework 
Explored, Bonnie A. Goins
x
Creating a Secure Architecture, 
Christopher A. Pilewski and Bonnie 
A. Goins
x
Common Models for Architecting an 
Enterprise Security Capability, 
Matthew J. Decker
x
(continued)

470  ◾  Comprehensive Table of Contents
Domain 6 (continued)  Security Architecture and Design
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
The Reality of Virtual Computing, 
Chris Hare
x
Service-Oriented Architecture and 
Web Services Security, Glenn J. Cater
x
Analysis of Covert Channels, Ralph 
Spencer Poore
x
Security Architecture of Biological 
Cells: An Example of Defense in 
Depth, Kenneth J. Knapp and R. 
Franklin Morris, Jr.
x
ISO Standards Draft Content, Scott 
Erkonen
x
Security Frameworks, Robert M. Slade
x
Information Flow and Covert 
Channels, Sean Price
x
Securing Data at Rest: From 
Smartphones to Tapes Defining Data 
at Rest, Sam Chun and Leo Kahng
x
Best Practices in Virtualization 
Security, Shanit Gupta
x
Everything New Is Old Again, Robert 
M. Slade
x
An Introduction to Virtualization 
Security, Paul Henry
x
Service-Oriented Architecture, Walter 
B. Williams
x
Cloud Security, Terry Komperda
x
Enterprise Zones of Trust, Sandy Bacik
x
6.2 Principles of Security Models, Architectures, and Evaluation Criteria
Formulating an Enterprise 
Information Security Architecture, 
Mollie E. Krehnke and David C. 
Krehnke
x
Security Architecture and Models, 
Foster J. Henderson and Kellina M. 
Craig-Henderson
x
The Common Criteria for IT Security 
Evaluation, Debra S. Herrmann
x

Comprehensive Table of Contents  ◾  471
Domain 6 (continued)  Security Architecture and Design
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
6.3 Common Flaws and Security Issues: System Architecture and Design
Common System Design Flaws and 
Security Issues, William Hugh 
Murray
x
Domain 7  Operations Security
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
7.1 Concepts 
Security Considerations in 
Distributed Computing: A Grid 
Security Overview, Sasan Hamidi 
x 
Managing Unmanaged Systems, Bill 
Stackpole and Man Nguyen 
x 
Storage Area Networks Security 
Protocols and Mechanisms, Franjo 
Majstor 
x 
Operations: The Center of Support 
and Control, Kevin Henry 
x 
Why Today’s Security Technologies 
Are So Inadequate: History, 
Implications, and New Approaches, 
Steven Hofmeyr 
x 
Operations Security and Controls, 
Patricia A.P. Fisher 
x 
7.2 Resource Protection Requirements 
The Nebulous Zero Day, Rob Slade 
x 
Understanding Service Level 
Agreements, Gilbert Held 
x 
Physical Access Control, Dan M. 
Bowers 
x 
7.3 Auditing 
Auditing the Electronic Commerce 
Environment, Chris Hare 
x 
(continued)

472  ◾  Comprehensive Table of Contents
Domain 7 (continued)  Operations Security
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
7.4 Intrusion Detection 
Improving Network-
Level Security through Real-Time 
Monitoring and Intrusion Detection, 
Chris Hare 
x 
Intelligent Intrusion Analysis: 
How Thinking Machines Can 
Recognize Computer Intrusions, 
Bryan D. Fish 
x 
7.5 Operations Controls
Directory Security, Ken Buszta
x
Patch Management 101: It Just 
Makes Good Sense! Lynda 
McGhie
x
Security Patch Management: The 
Process, Felicia M. Nicastro
x
Validating Tape Backups, Sandy 
Bacik
x
A Brief Summary of Warfare and 
Commercial Entities, Rob Shein
x
Information Destruction 
Requirements and Techniques, Ben 
Rothke
x
Warfare and Security: Deterrence and 
Dissuasion in the Cyber Era, Samuel 
Chun
x
Configuration, Change, and Release 
Management, Sean M. Price
x
Tape Backup Considerations, Sandy 
Bacik
x
Productivity vs. Security, Sandy Bacik
x
Complex Event Processing for 
Automated Security Event Analysis, 
Rob Shein
x
Records Management, Sandy Bacik
x

Comprehensive Table of Contents  ◾  473
Domain 8  Business Continuity and Disaster Recovery Planning
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
8.1 Business Continuity Planning
Developing Realistic Continuity 
Planning Process Metrics, Carl B. 
Jackson
x 
Building Maintenance Processes for 
Business Continuity Plans, Ken 
Doughty 
x 
Identifying Critical Business 
Functions, Bonnie A. Goins 
x 
Selecting the Right Business 
Continuity Strategy, Ken Doughty 
x 
Contingency Planning Best Practices 
and Program Maturity, Timothy R. 
Stacey 
x 
Reengineering the Business 
Continuity Planning Process, Carl B. 
Jackson 
x 
The Role of Continuity Planning in 
the Enterprise Risk Management 
Structure, Carl Jackson 
x 
Determining Business Unit Priorities 
in Business Continuity Management, 
Kevin Henry 
x 
Continuity Program Testing, 
Maintenance, Training and 
Awareness, Carl Jackson 
x 
Integrated Business Continuity 
Planning, James C. Murphy 
x 
CERT/BERT: Community and 
Business Emergency Response, Carl 
B. Jackson 
x 
Continuity Planning for Small- and 
Medium-Sized Organizations, Carl 
Jackson
x
Data Backup Strategies: Traditional 
versus Cloud, Carl B. Jackson
x
(continued)

474  ◾  Comprehensive Table of Contents
Domain 8 (continued)  Business Continuity and Disaster Recovery Planning
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
8.2 Disaster Recovery Planning 
Contingency at a Glance, Ken M. 
Shaurette and Thomas J. 
Schleppenbach 
x 
The Business Impact Assessment 
Process and the Importance of Using 
Business Process Mapping, Carl 
Jackson 
x 
Testing Business Continuity and 
Disaster Recovery Plans, James S. 
Mitts 
x 
Restoration Component of Business 
Continuity Planning, John Dorf and 
Martin Johnson 
x 
Business Resumption Planning and 
Disaster Recovery: A Case History, 
Kevin Henry 
x 
Business Continuity Planning: A 
Collaborative Approach, Kevin Henry
x 
8.3 Elements of Business Continuity Planning
The Business Impact Assessment 
Process, Carl B. Jackson
x
Domain 9  Legal, Regulations, Compliance, and Investigations
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
9.1 Information Law 
Sarbanes–Oxley Compliance: A 
Technology Practitioner’s Guide, 
Bonnie A. Goins 
x
 
Health Insurance Portability and 
Accountability Act Security Rule, 
Lynda L. McGhie 
x
Jurisdictional Issues in Global 
Transmissions, Ralph Spencer Poore 
x
An Emerging Information Security 
Minimum Standard of Due Care, 
Robert Braun and Stan Stahl 
x
ISPs and Accountability, Lee Imrey 
x
 

Comprehensive Table of Contents  ◾  475
Domain 9 (continued)  Legal, Regulations, Compliance, and Investigations
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
The Case for Privacy, Michael J. Corby 
x 
Liability for Lax Computer Security in 
DDoS Attacks, Dorsey Morrow 
x 
Compliance Assurance: Taming the 
Beast, Todd Fitzgerald 
x 
The Cost of Risk: An Examination of 
Risk Assessment and Information 
Security in the Financial Industry, 
Seth Kinnett
x
Data Security and Privacy Legislation, 
Salahuddin Kamran
x
9.2 Investigations 
Operational Forensics, Michael J. 
Corby 
x 
Computer Crime Investigation 
and Computer Forensics, Thomas 
Welch 
x 
What Happened? Kelly J. Kuchta 
x 
9.3 Major Categories of Computer Crime 
Potential Cyber Terrorist Attacks, 
Chris Hare 
x
 
The Evolution of the Sploit, Ed 
Skoudis 
x 
Computer Crime, Christopher A. 
Pilewski 
x 
Phishing: A New Twist to an Old 
Game, Stephen D.Fried 
x 
It’s All about Power: Information 
Warfare Tactics by Terrorists, 
Activists, and Miscreants, Gerald L. 
Kovacich, Andy Jones, and Perry G. 
Luzwick 
x 
Bluesnarfing, Mano Paul 
x 
Cyberstalking, Micki Krause Nozaki 
x
Managing Advanced Persistent 
Threats, E. Eugene Schultz and Cuc Du
x
(continued)

476  ◾  Comprehensive Table of Contents
Domain 9 (continued)  Legal, Regulations, Compliance, and Investigations
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
9.4 Incident Handling 
Social Engineering: The Human Factor 
in Information Assurance, Marcus K. 
Rogers 
x 
Privacy Breach Incident Response, 
Rebecca Herold 
x 
Security Event Management, Glenn 
Cater 
x 
DCSA: A Practical Approach to Digital 
Crime Scene Analysis, Marcus K. Rogers 
x 
What a Computer Security 
Professional Needs to Know about 
E-Discovery and Digital Forensics, 
Larry R. Leibrock 
x 
How to Begin a Non-Liturgical 
Forensic Examination, Carol Stucki 
x 
Honeypot Essentials, Anton Chuvakin 
x 
Managing the Response to a 
Computer Security Incident, Michael 
Vangelos 
x 
Cyber-Crime: Response, 
Investigation, and Prosecution, 
Thomas Akin
x
Enterprise Incident Response and 
Digital Evidence Management and 
Handling, Marcus K. Rogers 
x 
Security Information Management 
Myths and Facts, Sasan Hamidi 
x 
Virtualization and Digital 
Investigations, Marcus K. Rogers and 
Sean C. Leshney
x
Is Software Write Blocking a Viable 
Alternative to Hardware Write 
Blocking in Computer Forensics? Paul 
A. Henry
x
Discovery of Electronically Stored 
Information, Salahuddin Kamran
x
Virtualization Forensics, Paul A. 
Henry
x

Comprehensive Table of Contents  ◾  477
Domain 10  Physical (Environmental) Security
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
10.1 Elements of Physical Security 
Perimeter Security, R. Scott McCoy 
x 
Melding Physical Security and 
Traditional Information Systems 
Security, Kevin Henry 
x 
Physical Security for Mission-Critical 
Facilities and Data Centers, Gerald 
Bowman 
x 
Physical Security: A Foundation for 
Information Security, Christopher 
Steinke 
x 
Physical Security: Controlled Access and 
Layered Defense, Bruce R. Matthews 
x 
Computing Facility Physical Security, 
Alan Brusewitz 
x 
Closed-Circuit Television and Video 
Surveillance, David Litzau 
x 
Mantraps and Turnstiles, R. Scott 
McCoy 
x 
Halon Fire Suppression Systems, 
Chris Hare 
x 
Crime Prevention through 
Environmental Design, Mollie 
Krehnke 
x 
Data Center Site Selection and Facility 
Design Considerations, Sandy Bacik 
x 
Protection of Sensitive Data, Sandy 
Bacik 
x 
Water Leakage and Flooding, Sandy 
Bacik 
x 
Site Selection and Facility Design 
Considerations, Sandy Bacik 
x 
An Overview of IP-Based Video 
Surveillance, Leo Kahng 
x 
The Layered Defense Model and 
Perimeter Intrusion Detection, Leo 
Kahng
x
(continued)

478  ◾  Comprehensive Table of Contents
Domain 10 (continued)  Physical (Environmental) Security
Title 
Vol. 1
Vol. 2
Vol. 3
Vol. 4 
Vol. 5
Vol. 6
Terrorism an Overview, Frank Bolz, Jr., 
Kenneth J. Dudonis, and David P. 
Schulz
x
10.2 Technical Controls 
Types of Information Security 
Controls, Harold F. Tipton 
x 
Countermeasure Goals and 
Strategies, Thomas L. Norman
x
10.3 Environment and Life Safety 
Workplace Violence: Event 
Characteristics and Prevention, 
George Richards 
x 
Physical Security: The Threat after 
September 11, 2001, Jaymes 
Williams 
x 

Sixth Edition • Volume 6
Information Security
Management Handbook
Edited by
Harold F. Tipton, CISSP • Micki Krause Nozaki, CISSP
ISBN 978-1-4398-9313-5
9 781439 893135
90000
K14176
IT Management
Updated annually, the Information Security Management Handbook, Sixth Edition, Volume 6 
is the most comprehensive and up-to-date reference available on information security and risk 
management. Bringing together the knowledge, skills, techniques, and tools required of IT security 
professionals, it facilitates the up-to-date understanding required to stay one step ahead of evolving 
threats, standards, and regulations. 
Reporting on the latest developments in information security and recent changes to the (ISC)2® 
CISSP Common Body of Knowledge (CBK®), this volume features new information on advanced 
persistent threats, HIPAA requirements, social networks, virtualization, and Service Oriented 
Architecture (SOA). Its comprehensive coverage touches on all the key areas IT security  
professionals need to know, including:
• 
Access Control: Technologies and administration including the requirements of current laws
• 
Telecommunications and Network Security: Addressing the Internet, intranet, and extranet
• 
Information Security and Risk Management: Organizational culture, preparing for a 
security audit, and the risks of social media
• 
Application Security: Ever-present malware threats and building security into the 
development process
• 
Security Architecture and Design: Principles of design including zones of trust 
• 
Cryptography: Elliptic curve cryptosystems, format-preserving encryption
• 
Operations Security: Event analysis 
• 
Business Continuity and Disaster Recovery Planning: Business continuity in the cloud
• 
Legal, Regulations, Compliance, and Investigation: Persistent threats and incident response 
in the virtual realm
• 
Physical Security: Essential aspects of physical security
The ubiquitous nature of computers and networks will always provide the opportunity and means 
to do harm. This edition updates its popular predecessors with the information you need to address 
the vulnerabilities created by recent innovations such as cloud computing, mobile banking, digital 
wallets, and near-field communications. This handbook is also available on CD.

