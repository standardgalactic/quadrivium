
Advances in Optimization and
Linear Programming


Advances in Optimization
and Linear Programming
Ivan Stanimirović

First edition published 2022
Apple Academic Press Inc. 
CRC Press
1265 Goldenrod Circle, NE, 
6000 Broken Sound Parkway NW, 
Palm Bay, FL 32905 USA 
Suite 300, Boca Raton, FL 33487-2742 USA
4164 Lakeshore Road, Burlington,  
2 Park Square, Milton Park,
ON, L7L 1A4 Canada 
Abingdon, Oxon, OX14 4RN UK
© 2022 Apple Academic Press, Inc.
Apple Academic Press exclusively co-publishes with CRC Press, an imprint of Taylor & Francis Group, LLC
Reasonable efforts have been made to publish reliable data and information, but the authors, editors, and publisher 
cannot assume responsibility for the validity of all materials or the consequences of their use. The authors, editors, 
and publishers have attempted to trace the copyright holders of all material reproduced in this publication and 
apologize to copyright holders if permission to publish in this form has not been obtained. If any copyright material 
has not been acknowledged, please write and let us know so we may rectify in any future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, transmitted, or 
utilized in any form by any electronic, mechanical, or other means, now known or hereafter invented, including 
photocopying, microfilming, and recording, or in any information storage or retrieval system, without written 
permission from the publishers.
For permission to photocopy or use material electronically from this work, access www.copyright.com or contact the 
Copyright Clearance Center, Inc. (CCC), 222 Rosewood Drive, Danvers, MA 01923, 978-750-8400. For works that 
are not available on CCC please contact mpkbookspermissions@tandf.co.uk
Trademark notice: Product or corporate names may be trademarks or registered trademarks and are used only for 
identification and explanation without intent to infringe.
Library and Archives Canada Cataloguing in Publication
Title: Advances in optimization and linear programming / Ivan Stanimirović.
Names: Stanimirović, Ivan, author.
Description: First edition. | Includes bibliographical references and index.
Identifiers: Canadiana (print) 20210285362 | Canadiana (ebook) 20210285389 | ISBN 9781774637401 
(hardcover) | ISBN 9781774637418 (softcover) | ISBN 9781003256052 (ebook)
Subjects: LCSH: Linear programming—Mathematical models.
Classification: LCC T57.76 .S73 2022 | DDC 519.7/2—dc23
Library of Congress Cataloging‑in‑Publication Data
Names: Stanimirović, Ivan, author.  
Title: Advances in optimization and linear programming / Ivan Stanimirović.  
Description: First edition. | Palm Bay, FL : Apple Academic Press, 2022. | Includes bibliographical references 
and index. | Summary: “This new volume provides the information needed to understand the simplex method, 
the revised simplex method, dual simplex method, and more for solving linear programming problems. 
Following a logical order, the book first gives a mathematical model of the linear problem programming 
and describes the usual assumptions under which the problem is solved. It gives a brief description of classic 
algorithms for solving linear programming problems as well as some theoretical results. It goes on to explain 
the definitions and solutions of linear programming problems,  outlining the simplest geometric methods, and 
showing how they can be implemented. Practical examples are included along the way. The book concludes 
with a discussion of multi-criteria decision-making methods. This volume is a highly useful guide to linear 
programming for professors and students in optimization and linear programming”-- Provided by publisher.  
Identifiers: LCCN 2021037727 (print) | LCCN 2021037728 (ebook) | ISBN 9781774637401 (hardcover) |  
ISBN 9781774637418 (paperback) | ISBN 9781003256052 (ebook)  
Subjects: LCSH: Linear programming. | Simplexes (Mathematics) | Mathematical optimization. 
Classification: LCC T57.76 .S83 2022  (print) | LCC T57.76  (ebook) | DDC 519.7/2--dc23 
LC record available at https://lccn.loc.gov/2021037727
LC ebook record available at https://lccn.loc.gov/2021037728
ISBN: 978-1-77463-740-1 (hbk)
ISBN: 978-1-77463-741-8 (pbk)
ISBN: 978-1-00325-605-2 (ebk)

About the Author
Ivan Stanimirović, PhD, is currently working as an Associate Profes-
sor at the Department of Computer Science, Faculty of Sciences and
Mathematics at the University of Niš, Serbia. He was formerly with
the Faculty of Management at Megatrend University, Belgrade, as a
Lecturer. His work spans from multi-objective optimization methods
to applications of generalized matrix inverses in areas such as im-
age processing and restoration and computer graphics. His current
research interests include computing generalized matrix inverses and
their applications, applied multi-objective optimization and decision
making, as well as deep learning neural networks. Dr. Stanimirović
was the Chairman of a workshop held at the 13th Serbian Mathe-
matical Congress, Vrnjačka Banja, Serbia, in 2014.
v


Contents
About the Author
v
Preface
ix
1
Introduction
1
1.1
Multiobjective Optimization
. . . . . . . . . . . . .
9
1.2
Symbolic Transformations in Multi-Sector 
Optimization . . . . . . . . . . . . . . . . . . . . . .
11
1.3
Pareto Optimality Test
. . . . . . . . . . . . . . . .
14
1.4
The Method of Weight Coeﬃcients
. . . . . . . . .
17
1.5
Mathematical Model
. . . . . . . . . . . . . . . . .
33
1.6
Properties of a Set of Constraints
. . . . . . . . . .
43
1.7
Geometrical Method
. . . . . . . . . . . . . . . . .
54
2
Simplex Method
63
2.1
Properties of Simplex Methods . . . . . . . . . . . .
63
2.2
The Algebraic Essence of the Simplex Method
. . .
70
2.3
The Term Tucker’s Tables and the Simplex Method
for Basic Permissible Canonical Forms
. . . . . . .
76
2.4
Algorithm of Simplex Method
. . . . . . . . . . . .
79
2.5
Determination of the Initial Basic Permissible
Solution . . . . . . . . . . . . . . . . . . . . . . . . .
101
vii

viii
Contents
2.6
Two-Phase Simplex Methods . . . . . . . . . . . . .
103
2.6.1 
A Two-Phase Simplex Method That Uses 
Artificial Variables . . . . . . . . . . . . . .
104
2.6.2 
Two-Phase Simplex Method Without 
Artificial Variables . . . . . . . . . . . . . .
109
2.7
BigM Method
. . . . . . . . . . . . . . . . . . . . .
116
2.8
Duality in Linear Programming
. . . . . . . . . . .
125
2.9
Dual Simplex Method . . . . . . . . . . . . . . . . .
133
2.10 Elimination of Equations and Free Variables
. . . .
139
2.11 Revised Simplex Method
. . . . . . . . . . . . . . .
144
2.12 Cycling Concept and Anti-Cyclic Rules . . . . . . . 
149
2.13 Complexity of Simplex Methods and Minty-Klee 
Polyhedra  . . . . . . . . . . . . . . . . . . . . . . .
156
3  Three Direct Methods in Linear Programming
163
3.1
Basic Terms
. . . . . . . . . . . . . . . . . . . . . .
164
3.2
Minimum Angle Method
. . . . . . . . . . . . . . .
166
3.3
Dependent Constraints and Application of Game 
Theory 
. . . . . . . . . . . . . . . . . . . . . . . . .
171
3.4
Algorithms and Implementation Details . . . . . . .
176
3.5
Direct Heuristic Algorithm with General Inverses
.
177
Bibliography
183
Index
191

Preface
In the ﬁrst part of this book, we give a mathematical model of lin-
ear problem programming and describe the usual assumptions under
which the problem is solved. Below is a brief description of classic
algorithms for solving linear programming problems and some theo-
retical results. Proofs of the theorem can be found in standard mono-
graphs and linear textbooks programming and optimization from the
literature list. Then, we will study the deﬁnition and solution of lin-
ear programming problems. That is what it entails ﬁrst mathematical
model and basic deﬁnitions and basic properties of a set of permis-
sible solutions. We will then outline the simplest geometric method
for solving the linear problem programming and show how it can be
implemented.
In the second chapter, we will study the simplex method for solv-
ing the linear programming problem in general form, and we will
detail its stages and the dual simplex method. We will also consider
another version called the simplex method and the revised simplex
method to resolve the problem of numerical stability of the classi-
cal simplex method. Finally, we will point to the problem of cycling
and two ways to overcome this problem. We will also show that it is
a simplex algorithm of exponential complexity, despite its excellent
properties on practical problems.
ix

x
Advances in Optimization and Linear Programming
The third chapter presents the results from the work [43, 54],
and deals with modiﬁcations and reﬁnements of particular stages of
simplex methods. In Ref. [54], this algorithm was used, since it does
not require the introduction of artiﬁcial variables. In this chapter,
two algorithms were introduced to obtain an initial basic permissible
solution in phase I of the two-phase simplex algorithm (described in
Refs. [40] and [55]). A new rule is described for the choice of basic and
non-basic variables to select the variable that enters the base and the
variable that leaves the base. At the end of this chapter, we will detail
the implementation of the simplex and revised simplex method.
In the ﬁnal chapter, the post-optimal analysis of simplex methods
is studied, and multi-criteria decision-making methods are listed, and
ﬁnal remarks are provided.

Chapter 1
Introduction
Mathematical programming problems occur in diﬀerent disciplines.
For example, a stock market manager has to choose the investments
that will generate the highest possible proﬁt at an opportunity; this
puts the risk of large losses at a predetermined level. The production
manager organizes production at the factory so that the quantity
of products and the quality are maximum, and the consumption of
materials and time are minimum, with limited resources (number of
workers, machine capacity, and opening hours). A scientist makes a
mathematical model of the physical process which best describes a
particular physical occurrence, and has a ﬁnite number of measure-
ment results available. Also, the model should not be too complicated.
Operations research is a branch of mathematics consistent in the
use of mathematical, statistical, and algorithms in order to carry out
a process of decision-making models. It often deals with the study of
complex real systems, in order to improve (or optimize) the operation
of the same. Operations research enables analysis of decision-making,
given the scarcity of resources to determine how they can maximize
or minimize them.
In mathematics and computer science, an algorithm is a step-
by-step procedure used to perform calculations. Algorithms are used
for computing, data processing, and automatic locking. More pre-
1

2
Advances in Optimization and Linear Programming
cisely, an algorithm is an eﬃcient method expressed by a ﬁnal list
of deﬁned instructions. Start the pipe from the initial step and the
entrance (which can be empty). The instructions describe the calcu-
lation, which after execution leads to a ﬁnite number of successive
steps, giving the output in the last step. The complexity of an al-
gorithm can be described as the number of primitive operations or
basic steps that need to be performed. For certain input data, see the
analysis of algorithms in Ref. [11].
The symbolic expression is a concept that denotes the use of com-
puter tools for the transformation of mathematical symbols. It can
be used to compute explicit results without numerical errors. That
is why symbolic expression always expressed applies to conditioned
problems. These can be rational functions or polynomials of one or
more variables. There are several diﬀerent computer algebra soft-
ware packages that support symbolic computing, such as MATHEMAT-
ICA, MAPLE, MATLAB.
Traditional programming languages are procedural languages.
The procedural program is written as a list of instructions, which
are executed step-by-step by reading Zotos. Programs in procedural
computer languages such as C can be used in calculations, but are
limited in cost in understanding more complex algorithms, because
they give little information about the steps. Many researchers use
the ability to develop “rapid-prototype” code to test the behavior of
the algorithm before investing eﬀort in developing code for the algo-
rithm in a procedural language. The approach with MATHEMATICA has
great advantages in researching over procedural programming avail-
able in MAPLE and in procedural languages. MATHEMATICA allows several
program paradigms: object-oriented, procedural, symbolic, and func-

Introduction
3
tional programming. Our main goal of the research was to develop
algorithms suitable for implementation both in MATHEMATICA and in
procedural programming languages.
Although linear programming is very applicable in practice, many
problems in practice cannot be adequately linearized without while
the drastically does not lose on accuracy. In this case, nonlinear pro-
gramming methods are applied. In addition to nonlinearity, in many
problems, it is necessary to ﬁnd the optimum of more than one objec-
tive function. In that case, we need to solve the problem of multi-
objective optimization. If all , the goal functions have an optimum
at the same point, the problem is trivial and comes down directly
to the problem of nonlinear or linear programming. In practice, this
situation is very rare. There are several methods for rescuing prob-
lems multiobjective optimization [36]. Common to all these methods
is that the initial problem in the appropriate way is to reduce the
problem of linear and nonlinear programming.
Higher sectoral criteria optimization can be seen as a continuation
of research in the classroom (single-criteria) optimization along with
some extensions. Formally, the basic extension is the introduction of
a vector criterion function, which leads to the vector maximum prob-
lem. Essentially, it is necessary to expand the concept of optimality.
Considering the problem of the vector maximum, the concept of op-
timality is replaced by the concept of noninferiority (Pareto optimal-
ity). The notion of a general (unique) optimization criterion can be
introduced, which includes criterion functions and decision-makers.
The solution of the multiobjective optimization problem obtained ac-
cording to such a criterion is optimal. In this case, the notion of the
optimal solution from the classical optimization can be retained in the

4
Advances in Optimization and Linear Programming
higher sectoral one. However, these diﬃculties will only arise when
trying to formalize such a unique criterion. Therefore, two phases or
stages are used in multiobjective optimization. In the ﬁrst phase, a
set of “better” solutions is determined on the basis of a vector crite-
rion function. And in the second phase, based on the preference of
the decision-maker, the ﬁnal decision is adopted, which can be called
optimal. The set of decisions presented to the decision-maker should
contain a small number of decisions, which are non-inferior to the
given criterion functions. The problem of multi-sector optimization
occurs most often in the planning of complex systems; for example,
regional development, development of water or electricity systems,
urban planning, and preservation of the natural environment [38].
The higher securitization problem occurs in economics as a problem
of determining the market equilibrium [38]. A similar problem arises
as a problem of equilibrium in game theory. In game theory, games
are considered in which decision theory appears as “group decision
making” or decision making with several decision-makers.
In this chapter, we will present the problem of multi-sector op-
timization, as well as the means for its solution. We will ﬁrst give
a deﬁnition of the problem of multiobjective optimization as well as
necessary terms for later consideration. Theoretically, we will process
and implement several classical methods of multi-criteria optimiza-
tion. Each of the described methods will be illustrated by one or
more examples. Implementation considerations methods are original
and are taken from the works [57].

Introduction
5
The general formulation of multiobjective optimization (MOO)
has the general form:
max
Q(x) = Q1(x), . . . , Ql(x),
x ∈Rn
p.o.
fi(x) ≤0, i = 1, . . . , m
(1.0.1)
hi(x) = 0, i = 1, . . . , k.
where; Q1(x), . . . , Ql(x), f1(x), . . . , fm(x), g1(x), . . . , gm(x) are the
real functions of n variables contained in the vector x = (x1, . . . , xn).
This task looks for a solution to x that maximizes all 1 functions
of the target. That is why the task of multiobjective optimization
(MOO) is also called the vector optimization task. Because of sim-
plicity only maximization problems are considered here. It is known
that the task of minimization simply translates into the task of max-
imization by multiplication criterion functions with −1. All further
presented deﬁnitions and methods are possible to adjust and solve
the minimization task.
We say that X ⊆Rn is a set of admissible shadows if:
X = {x|fi(x) ≤0, i = 1, . . . , m; hi(x) = 0, i = 1, . . . , k}.
Each admissible solution x ∈X corresponds to a set of criteria
values function, i.e., vector Q(x) = (Q1(x), Q2(x), . . . , Ql(x)). In that
way, the set of admissible solutions is mapped to the criterion set,
i.e., S = {Q(x)|x ∈X}.
In the following text, the following terms will be used:
- Marginal solutions of the MOO task is determined by by op-
timizing each of the goal functions individually over the given one
permissible set, i.e., solving l one objective tasks:

6
Advances in Optimization and Linear Programming
max
Qj(x),
x ∈Rn
p.o.
fi(x) ≤0, i = 1, . . . , m
hi(x) = 0, i = 1, . . . , k.
We will mark marginal solutions with
(j)∗
(j)∗,
(j)∗
(j)∗
x
= (x1
x2
, . . . , xn
),
where; x(j)∗is the optimal solution obtained by optimizing the j-th
objective function over a given allowable set X.
- The ideal values of the objective functions, denoted by the prices
with Q∗
j are the values of objective functions for marginal solutions
Q∗= Q (x(j)∗
j
j
), æ = 1, . . . , l.
- The ideal values of the goal functions determine the ideal point
in the criterion space, i.e., ideal value of the vector function
Q∗= (Q∗
1, Q∗
2, . . . , Q∗
l ).
- If there is a solution x∗that simultaneously maximizes all func-
tions of the target, i.e.:
x∗= {x|Qj(x) = Q∗
j, j = 1, . . . , l},
then such a word is called perfect hay solution.
In most cases, the marginal word shadow diﬀers and the perfect
word shadow does not exist. When a perfect solution exists, then it
is not really a MOO problem.

Introduction
7
It is very important to keep in mind that in real problems, the
goals are over always in collision, which means that not everyone can
be fully reached. It is not possible to strictly deﬁne the optimum
nor for every two words formally determine which is better than the
other. For this reason, the process of obtaining a solution requests
the inﬂuence of the decision maker (hereinafter DM). This is the best
thing for someone who has a deeper insight into the problem, and
according to whose request, the solution is approached. Bearers deci-
sions can be made, and then the problem can be further complicated
because of their diﬀerent goals, participation in decision-making and
the degree of responsibility they are willing to take on.
The fact that the tasks of the MOO, as a rule, do not have a
perfect meaning to reconsider the concept of optimality and the deﬁ-
nition of the optimal solution. The concept of Pareto optimality plays
a key role in this. It is an expansion of the known concept of opti-
mality used in classical single-criterion optimization.
Pareto optimum is deﬁned as follows:
Deﬁnition 1.0.1. The admissible solution x∗represents Pareto op-
timum if there is no other admissible solution x such that:
Qj(x) ≥Qj(x∗)
∀j = 1, . . . , l
where at least one of the inequalities turns into a strict inequality >.
In other words, x is Pareto optimum if it would improve the value
of any target function caused a deterioration in the value of another
target function. For Pareto optimum, there are the following syn-
onyms: eﬃcient, dominant, and non-dominant solution.

8
Advances in Optimization and Linear Programming
In addition to the Pareto optimum, weak and strict (strong)
Pareto optimums are deﬁned.
Deﬁnition 1.0.2. The admissible solution x∗is weak Pareto opti-
mum if there is no one another admissible solution x such that
Qj(x) > Qj(x∗)
∀j = 1, . . . , l.
In other words, x∗is a weak Pareto optimum if it cannot at the
same time improve all target functions.
Deﬁnition 1.0.3. The Pareto optimal solution x∗is strict Pareto
optimum if there is a the number β > 0 such that for each index
j ∈{1, . . . , l} and for each x which satisﬁes the condition:
Qj(x) > Qj(x∗)
there is at least one i ∈{1, . . . , l} \ {j} such that:
Qi(x) > Qi(x∗)
and that it is valid
Qj(x) −Qj(x∗)
Qi(x∗) −Qi(x) ≥β.
The strict Pareto optimum is distinguished by the Pareto solu-
tion that does not change causes excessive relative changes in goal
functions.
The relation between the described optimums is such that each set
of stricter Pareto optimum is a subset of weaker optimums, i.e., every
Pareto is the optimum at the same time a weak Pareto optimum, and
every strict Pareto optimum is also a Pareto optimum.

Introduction
9
1.1
Multiobjective Optimization
In multi-criteria optimization, several opposing goal functions
should be reduced to a minimum at the same time respecting the
given restrictions:
Max.:
Q(x) = {Q1(x), . . . , Ql(x)},
x ∈Rn
p.o.:
fi(x) ≤0, i = 1, . . . , m
(1.1.2)
hi(x) = 0, i = 1, . . . , k.
It is possible to construct an interval (often called a constraint) in
( refMOO); we simply denote by X. Thus, the whole X is deﬁned
by X = {x|fi(x) ≤0, i = 1, . . . , m; hi(x) = 0, i = 1, . . . , k}.
As a consequence, the notation xX will indicate that x satis-
ﬁes the inequality and equality of boundaries in (1.0.1). With xj∗
we denote the point that maximizes the j-th function of the target
depending on the constraint x ∈X.
In general, there is no special point that maximizes all target
functions at once. For these reasons, a possible point is constructed
as optimal if there is no possible point with the same or goal function
being estimated. So that the true increase has the minimum value
of the target function. For the sake of completeness, we redeﬁne the
deﬁnitions of non-inferior solution (Pareto-optimal solution) and ideal
(utopia) point from Refs. [12], [34], and [35].
Deﬁnition 1.1.1. Solution x∗is said to be Pareto optimal solution
multiobjective optimization problems (1.0.1) if there is no other pos-

10
Advances in Optimization and Linear Programming
sible revision of x ∈X so that Qj(x) ≥Qj(x∗) for every j = 1, . . . , l,
and Qj(x) > Qj(x∗) for at least one index j.
Deﬁnition 1.1.2. A point x0 is the ideal point of the problem (1.0.1)
of the problem if and only if:
Qi(x0) = max{Qi(x)| x ∈X}, i = 1, . . . , l.
x
The multicriteria problem is often solved by combining multiple
goals in one goal, which solution is Pareto optimal point for the orig-
inal problem.
The following optimization tools are available:
1. Compiled programming languages (Fortran 90, C, etc.) with
subroutine libraries (NAG, IMSL, etc.)
2. Interactive mathematical software: fast to deﬁne, solve, and
prototype small problems, less eﬃcient for large ones: a. General tools
for numerical analysis (Matlab, IDL); b. Symbolic mathematical com-
puter systems (Mathematica, Maple, Macsyma); c. Modeling tools for
optimization (GAMS, AMPL).
One of the goals of our research was the implementation of the
main methods of multi-sector optimization in computer algebraic sys-
tem MATHEMATICA. The software package MATHEMATICA is one of the vari-
ous programming languages available today, and is applicable to sym-
bolic languages, and for numerical calculations Maeder, Wol. Several
functions for limiting the cost of numerical optimization are available
in the software package MATHEMATICA (see [33], [70]).
The Maximize and Minimize functions allow a speciﬁcation of
the maximization and minimization goal function, along with a set
of constraints. In all cases, it is assumed that all variables are price
limits that do not have negative values.

Introduction
11
Minimize[f, {cons}, {x, y,...}] or Minimize[{f, cons}, {x,
y,...}], minimize f in the area speciﬁed by cons;
Maximize [f, {cons }, {x, y, ... }] or Maximize[{f,cons },
{x, y, ...}], ﬁnd a maximum of f, in the area speciﬁed by cons.
Minimize and Maximize can be used to properly solve any polyno-
mial programming problem function in which the functions of the goal
f and the constraints cons include arbitrary polynomial functions of
the variables [70]. An important feature of Minimize and Maximize is
that they always ﬁnd global minima and maxima [70].
The NMinimize and NMaximize functions implement several al-
gorithms for ﬁnding global optimum constraints. Expressions:
NMaximize[{f,cons}, vars, Method -> {method, mopts}],
NMinimize[{f,cons}, vars, Method -> {method, mopts}],
ﬁnd the global maximum and minimum, respectively, for the objective
functions f by the constraint prices cons, using the method with
optimization methods method with the method options deﬁned in
mopts.
1.2
Symbolic Transformations in Multi-Sector
Optimization
The main details of multi-sector optimization that are speciﬁc
to symbols and the expressions are described in the paper [57]. The
implementation was performed in the software package MATHEMATICA.
The method of weight coeﬃcients, the main priority methods, and the
method of target programming are discussed. The symbolic conver-

12
Advances in Optimization and Linear Programming
sion of given goal functions and constraints into the corresponding
problem of one goal function is treated in particular. Transforma-
tions from multiobjective to one-criteria problem u procedural pro-
gramming languages are actually combinations of real values, and
involve procedures that depend on the function of the goal. In our im-
plementation, these transformations are performed in symbolic form
by taking combinations of target functions, which include undeﬁned
symbols and unmarked variable prices.
We will suggest the following clear beneﬁts that will result from
the implementation problems of multiobjective optimization in the
symbolic programming language MATHEMATICA, respect the traditional
implementation in procedural programming languages.
1. Possibility to use arbitrary target functions and limitations
(which are not deﬁned by subroutines) during the execution
of the implementation function. The main aspects of these ad-
vantages are:
(i) The problem of secretory optimization (1.0.1) is represented
by a suitable in its form, whose elements can be used prices
as formal parameters in the optimization software. Inside the
dream form of the problem (1.0.1) is an edited triple
{Q1(x), . . . , Ql(x)},
{f1(x) ≤0, . . . , fm(x) ≤0, h1(x) = 0, . . . , hk(x) = 0},
{x1, . . . , xn}
(1.2. 1)
The ﬁrst element of the inner form, denoted by q, is a list
{Q1(x), . . . , Ql(x) } whose elements indeﬁnite expressions rep-
resenting goal functions. The second element in (1.2.1) is the

Introduction
13
constraint list fi(x) ≤0, i = 1, . . . , m, hi(x) = 0, i = 1, . . . , k.
We will label this argument as constr. The third element, la-
beled var, is a generic list of variables {x1, . . . , xn}, determined
on the basis of x. In this sense, it is allowed that some argu-
ments in x can be deﬁned in global environment MATHEMATICA
kernela.
(ii) If f is the objective function of the one-criteria optimization
problem obtained from (1.2. 1), we can calculate its maximum
using the standard function Maximize:
Maximize [f, constr, var].
The possibility of software to process arbitrary target functions
at arbitrary constraints enables the application of all optimiza-
tion models.
2. Possibility to use arrays of functions, whose elements can be
select and later apply to the given arguments. These structures
are not inherent in procedural programming languages.
Each expression contains in the list q = {Q1(x), . . . , Ql(x)} can
be immediately applied to the given arguments. It is possible to cal-
culate the value of the function q[[[]]] in point x0 using the trans-
formation rules q[[i]] /. X - > X0 or q[[i]] /. Thread [Rule [x,
x0]]. MATHEMATICA searches for parts of the function q[[i]] that can
be replaced using the speciﬁed rule, and then performs a replacement.
Also, it is possible to deﬁne a function that takes another function
as an argument, for example: pf[f_, x_]: = f[x] + f[1-x]. Later,
expressions such as pf[q[[i]], x0] can be used. In the expression
f[x], the name of the function f is also expression, and can be treated

14
Advances in Optimization and Linear Programming
as any numeric expression [70]. In particular, any element from q can
be taken as an argument in the functions Minimize and Maximize.
3. An eﬀective and natural symbolic transformation from a multi-
criteria model to a corresponding one-criterion model.
Many optimization methods are based on sub-algorithms that re-
quire the construction of goal functions of general form.
G (q(x), Φ(f(x), h(x), λ)) ,
where; λ is a possible set of larger variables, and Φ is an arbitrary
function.
Transformation of multiobjective to the one-criterion problem in
procedural languages is basically a combination of real values. We will
perform these transformations in symbolic form, using combinations
of unexpressed expressions and symbols.
1.3
Pareto Optimality Test
As a rule, it is impossible to ﬁnd a complete inﬁnite set of Pareto
optimal solutions to special problems from real life. For this reason,
the engineering securitization problem of the command seeks to de-
termine a subset of criterion-wise diﬀerent Pareto optimal solutions
ﬁnally. Also, there are a number of methods for proving Pareto op-
timality. These methods can also be used to ﬁnd the original Pareto
optimal solution of [?].

Introduction
15
An algorithm for determining the Pareto optimality was intro-
duced in the paper [57] solutions of multiobjective of the problem,
using direct proof in accordance with the Pareto deﬁnition of the
optimal point.
Algoritam 1.1 Pareto optimality test of ﬁxed point x∗.
Require: Optimization problem (1.0.1). Arbitrary ﬁxed point x∗.
1: Specify the set X = Reduce [constr /. List -> And, var] and
set Optimal = true.
2: For each index j = 1, . . . , l repeat Steps 2.1 and 2.2:
2.1: Generate the following conjunction constraint
Par = X && u1(x) && . . . && ul(x)
(1.3.1)
where
(
Qi(x) ≥Qi(x∗), j = i,
ui(x) =
(1.3.2)
Qi(x) > Qi(x∗), j = i.
2.2: If Par = ∅, set Optimal := false and to Step 3.
3: return the value of the variable Optimal as a result.
The corresponding function in our implementation is:
IsPareto[q _List, constr _List, var _List, sol _List],
where the formal parameters are taken in the following sense:
q, constr, var: internal representation of the problem of sector
criteria optimization (1.0.1);
sol: The solution to the corresponding one-goal optimization
problem.
Calling this function is a form:
IsPareto[q, constr, var, First[Rest[Maximize[fun, constr,
var]]]];
̸

16
Advances in Optimization and Linear Programming
where; fun, constr, and var are the representation of the corre-
sponding one-target optimization problem.
In this function we use the following version of the standard MATH-
EMATICA functions Reduce and FindInstance [70]:
Reduce [expr, var] ﬁnds all real values of variables contained
in the list var which satisﬁes a set of numbers containing logical
connections and invariant polynomial equations and inequalities.
FindInstance [expr, var] determines the values of the variables
from var in which the assertion is expr true. If no value is found
for var, the result is an empty list. The expr parameter can contain
equations, inequalities, a speciﬁcation area, and quantiﬁers (see Ref.
[70]).
Algebra ‘InequalitySolve’
IsPareto[q_List, constr_List, var_List, res_List] : =
Module[{X = {}, l = Length[q]},
X = Reduce[constr/.{List->And}, var]; Ok = 1;
(* Korak 1. *)
For[j = 1, j < = l, j++,
(* Korak 2. *)
Par = X;
For[i = 1, i < = l, i++,
(* Korak 2.1. *)
If [j ! = i, Par = Par && q[[i]] > = (q[[i]]/. res),
Par = Par && q[[i]] > (q[[i]]/. res)
];
]; (* Par is of the form (4.1), (4.2) *)
If[FindInstance[Par, var] ! = {}, Ok = 0; Break[]];
(* Korak 2.2. *)
(*If a var instance is found, abort the loop*)
];
If[Ok = = 1,
Print[“Solution”, {q/.res, res}, “is Pareto optimal”],

Introduction
17
Print[“Solution”, {q/.res, res}, “is not Pareto optimal”];
];
Return[Ok]; (* Step 3. *)
]
1.4
The Method of Weight Coeﬃcients
Weight coeﬃcient method is the oldest method used for MOO.
According to this method, the weight coeﬃcient wi is introduced for
all criterion functions Qi( mathbfx), i = 1, ldots, l, so the problem
optimization reduces to the following scalar optimization:
l
max
Q(x) =
wiQi(x)
(1.4.1)
i=1
p.o.
x ∈X,
X
where; wi, i=1, ldots, l meet the following conditions:
X
l
wi = 1,
wi
0, i = 1, . . . , l.
i=1
≥
The method of weight coeﬃcients is often used by setting the val-
ues of these coeﬃcients. However, this always causes certain diﬃcul-
ties and objections to this procedure, because the subjective inﬂuence
on the ﬁnal solution is entered through the given values of the weight
coeﬃcients.
The main idea in the method of weight coeﬃcients is to choose
weight coeﬃcients wi that correspond to target functions Qi(x),

18
Advances in Optimization and Linear Programming
i = 1, . . . , l. Many authors have developed systematic approaches
in weight selection, the review of which can be found in Refs. [23],
[24], and [63]. One of the advantages of this method is that the vari-
ation of weights is consistent and continuous; it does not always have
to result in an accurate and complete representation of the Pareto
optimal set. This shortcoming has been discussed in Ref. [17].
Theorem 1.4.1. If all weight coeﬃcients wi are positive, then the
solution of the problem (1.4.1) is Pareto optimal solution of the initial
MOO problem.
Proof. Let x∗solve the problem (1.4.1), and let all weight coeﬃcients
be strictly positive. Suppose that it is not Pareto optimal, i.e., there
exists x ∈S so for i = 1, . . . , l it is valid Qi(x) ≥Qi(x∗), where at
least one strict inequality holds (say for the index j). As wi > 0 for
every i, it is valid
X
l
wiQi(x) >
i=1
X
l
wiQi( mathbfx∗)
i=1
So we get a contradiction with the assumption that x∗is a shadow
and problem (1.4.1). It follows that x∗Pareto is optimal.
Theorem 1.4.2. If for every i ∈{1, . . . , l} the condition wi ≥0 is
fulﬁlled, then the solution is problem (1.4.1) weak Pareto optimum of
the initial MOO problem.
Proof. Let x∗solve the problem (1.4.1) and that the condition wi ≥0
is satisﬁed. Suppose that it is not weak Pareto optimal, i.e., yes there
is x ∈S so that for i = 1, . . . , l it is valid Qi(x) > Qi(x∗). All
coeﬃcients wi are non-negative and at least one is strictly greater
than zeros (due to Pl
i=1 wi = 1), so it is valid

Introduction
19
X
l
l
wiQi(x) >
i=1
X
wiQi(x∗)
i=1
So we get a contradiction with the assumption that x∗is a shadow
of the weight problem. Thus, x∗is a weak Pareto optimum.
Theorem 1.4.3. If the solution of the problem (1.4.1) is unique, then
Pareto is also optimal.
Proof. Let x∗be a unique solution to the problem (1.4.1). Suppose
that it is not a Pareto optimal solution to the MOO problem, i.e., that
there exists x ∈S so that for i = 1, . . . , l it is valid Qi(x) ≥Qi(x∗),
where at least one strict inequality (say for index j). Note that it
knows x = x∗. Since wi ≥0 for every i, it is valid
X
l
l
wiQi(x)
i=1
≥
X
wiQi(x∗)
i=1
If a strict inequality were valid, then x∗would not be a solu-
tion to the problem (1.4.1). So your equality. This means that there
are two diﬀerent readings of x and x∗problem (1.4.1), which is a
contradiction.
We will now show a strong assertion.
Theorem 1.4.4. If all wi > 0, i ∈{1, . . . , l}, then the solution of
the problem (1.4.1) is a strict Pareto optimum of the MOO problem.
Proof. Let x∗be the shadow of the weight problem. We have shown
that Pareto is optimal. Prove in winter that this solution is also a
strict Pareto optimum with a constant
̸

20
Advances in Optimization and Linear Programming
w
M
−
j
= (k
1) max
.
i ,j
wi
Suppose the opposite, that exists x ∈S and index i such that
Qi(x) > Qi(x∗) where for each j for which Qj(x∗) > Qj(x) it is true
Qi(x∗) −Qi(x) < M(Qj(x) −Qj(x∗)). With change:
(k
M =
−1)wj
wi
We get:
Qi(x∗)
wi
−Qi(x) < wj (Q
k −
j(x)
1
−Qj(x∗)) > 0 .
So, for each j = i for which it is true that Qj(x∗) > Qj(x). For
index j = i for which Qj(x∗) ≤Qj(x) the above inequality certainly
holds. So, for each j = i it is true.
Qi(x∗) −Qi(x)
wi
< wj (Qj(x) −Qj(x∗)),
k −1
so by summing these inequalities for j = 1, . . . , i −1, i + 1, . . . , l we
get:
l
wi (Qi(x∗) −Qi(x)) <
X
wj (Qj(x) −Qj(x∗))
j=1,j=i
that is:
X
l
l
wjQj(x∗) <
wjQj(x) .
j=1
X
j=1
̸
̸
̸
̸

Introduction
21
We get that x∗is not a solution to the weight problem, i.e., we are
coming to the contradiction. We conclude that x∗is indeed a strict
Pareto optimum of the initial problem.
The weight coeﬃcient should in some way represent the value of
the cross-function to which it is assigned. In order to achieve that, we
must ﬁrst normalize the criterion functions, that is to them change
so that they have approximately equal values, while retaining all the
essential properties. For example, if it is a criterion function linear
n
Qj(x) = P
i=1 aixi, then normalized form of this function be:
PQj(x)
.
i=1 nai
If the decision-maker himself deﬁnes the weight coeﬃcients, then
this method belongs to the group of a priori methods. However, little
is usually known about how the odds should be chosen. Therefore, the
usual weight problem is solved for various vector values (w1, . . . , wl)
and in this way, they get diﬀerent readings between the sentences in
which DO chooses the one that suits him best. If this approach is
used, then this method becomes a posteriori method.
The main disadvantage of this method is the diﬃculty of deter-
mining the weight coeﬃcients when we do not have enough informa-
tion about the problem. For this reason, we propose an algorithm
for the automatic generation of weight coeﬃcients in order to obtain
Pareto optimal points. For positive weights and a convex problem,
the optimal solutions of a single-criterion problem are Pareto optimal,
i.e., minimizing the corresponding single-criteria problem is suﬃcient
for Pareto optimality.

22
Advances in Optimization and Linear Programming
There are numerous operations research problems investigated
and implemented at the moment. In [57], the implementation of poly-
nomial multi-objective optimization has been analyzed in MATHE-
MATICA. We developed a linear weighted sum method for multi-
objective optimization problem and presented it in [60]. Also, we
provided the so-called compendious lexicographic method for multi-
objective optimization tasks in [59].
Many applications of operations research exist in everyday life
and science and technology. For instance, an optimization algorithm
for LED-based Vis-NIR spectrally tunable light source is examined
in [32]. An application of the ELECTRE method to planetary gear
train optimization is detailed in [50], and in [51] a model of plan-
etary gear multicriteria optimization is further developed. We have
also investigated the computation of some eﬃcient locations of the
Weber problem with barriers in [58]. Also, a heuristic algorithm for a
single resource-constrained project scheduling problem based on the
dynamic programming is investigated in [61].
Linear programming task is to determine the maximum (mini-
mum) linear function that depends on multiple variables provided
that these variables are nonnegative and satisfy linear restrictions in
the form of equations and/or inequalities. The linear objective func-
tion to be optimized is called the goal function or target function.
Linear programming is one of the most eﬀective approaches to for-
mulating and solving complex decision-making problems and, as such,
is a fundamental discipline of operational research.
Linear programming does report in the ﬁeld of solving practical
tasks such as are economic development planning both at the work
organization level so on the broader regional or broadest social plane.

Introduction
23
It is generally accepted that it is the ﬁrst work to belong linear
programming published by L.V. Kantorovic in 1939 [26]. It deﬁnes the
transport task for the ﬁrst time. The ﬁrst work in this area included
the work of Colonel Vlastimir Ivanovic from 1940, entitled “Rules
for the calculation of the required number of means of transport”
[25]. In this paper, Colonel Ivanovic demonstrated how to calculate
the minimum number of vehicles for transporting a given quantity
of material using the “Principle of Economy.” Linear models are also
used in solving certain transport problems, which are known in theory
and practice as transportation problems, and in other planning areas.
The ﬁrst algorithm for solving the transport problem was elab-
orated by F. F. Hitchock in [22] in 1941. On the formulation of the
transport problem and it’s also worked with Koopmans, which is the
results of his research published in 1947. The greatest contribution to
the development of linear of programming was given by G.B. Dantzig,
who formulated the general in 1947 linear programming problem and
set up a simplex method. In [16], the basics of simplex methods are
presented. The papers of John von Neumann from this period made
it possible in theory formulating a dual problem as well as ﬁnding a
connection between linear programming and game theory. Removal
method degeneration is suggested in [9]. Also signiﬁcant are the pa-
pers of Gass and Saaty in 1955. Fr. parametric programming as well
as works by E. Beale and R. Gomory from 1958 on integer program-
ming.
– Linear Programming
The linear programming is a mathematical method or algorithm
by which an undetermined problem is solved, formulated by linear
equations, optimizing the objective function, also linear.

24
Advances in Optimization and Linear Programming
The linear programming is to optimize (minimize or maximize) a
linear function, which we call objective function, such that the vari-
ables of the function are subject to a number of constraints expressed
by a system of linear inequalities.
The variables are real numbers greater than or equal to zero. If it
is required that the resulting value of the variable is an integer, the
resolution procedure is called integer programming. This is the kind
of programming that will be used to solve the problem that concerns
us, because the solution will be “number of sheets” to cut a certain
way, and veneers are a whole variable type.
– Excel Solver
It serves for solving linear and nonlinear optimization. You can
also specify restrictions on integer decision variables. Solver can solve
problems with up to 200 decision variables, 100 explicit constraints,
and 400 simple (upper and lower bounds or integer restrictions on
variables decision). The literature is a link to an online manual in a
pdf ﬁle that explains how to use the excel solver function.
From the year 1949, a number of publications listed on the basis
of the theory of linear programming and its applications to various
branches of the economy. Deserve special mention for the decisive in-
ﬂuence they had in the perfection and dissemination of these mathe-
matical techniques, the work and activities of the Cowles Commission
for Research in economics, the Rand Corporation, the Department of
Mathematics at Princeton University, and the Carnegie Institute of
Technology.
Moya (1998, p. 63) mentions that George B. Dantzig and another
group of associated researchers in 1947, accepted the request of mili-
tary authorities of the government of the United States, they set out
to investigate how it could apply mathematics and statistics to solve

Introduction
25
problems of planning and progression for purely military purposes. In
the same year, Dantzig and his colleagues raised for the ﬁrst time the
basic mathematical structure of the linear programming problem.
Generally speaking, one can say that any phenomenon involving
a given nonnegative number of variables (i.e., variables whose value
is positive or zero) can be linked together by relations of inequality or
equality and reﬂect the limited or restrictions that the phenomenon
presents in order to optimize an objective can be formulated as a
mathematical programming model. If both the constraints and the
objective function can be stated by linear expressions, we are facing
a particular ﬁeld of mathematical programming that denominates
“linear programming.”
In this case, the word “programming” does not refer to computer
programming; but it is used as a synonym for planning. Linear pro-
gramming deals with planning activities to obtain an optimal result,
that is, the result that best achieves the speciﬁed target (as the math-
ematical model) between alternative solutions.
Weber (1984, p. 718), the linear programming problem is about
maximizing or minimizing a linear function of several primary vari-
ables, called a goal function subject to a set of equalities or linear
inequalities called constraints, with the further proviso that none of
the variables can be negative. The latter can be seen when the prob-
lem requires, through the ingenious device of expressing the variable
of interest as the diﬀerence of two non-negative variables.
Brieﬂy, it stated that linear programming is a mathematical
method of solving problems where the objective is to optimize (maxi-
mize or minimize) a result from selecting the values of a set of decision
variables, respecting restrictions pertaining to availability resources,

26
Advances in Optimization and Linear Programming
technical speciﬁcations, or other conditions that limit the freedom of
choice.
As if we have a particular interest in linear programming, we can
represent a production system using a model or matrix which include:
• Costs and revenues generated per unit of activity (objective
function).
• Contributions and input and output requirements for each ac-
tivity (coeﬃcients input/output).
• Resource availability, technical speciﬁcations, and business to
respect (the right-side values of the constraints).
Speciﬁcally, linear programming is a mathematical method to analyze
and choose the best among many alternatives. In general terms, one
can think of programming as a means to determine the best way to
distribute a limited amount of resources in an attempt to achieve an
expressible target to maximize or minimize a certain amount.
The general model of a programming problem consists of two
linear important very parts: the objective function and constraints.
– The Linear Objective Function
The mathematical expression of the target is called the objec-
tive function, and the goal must be to maximize or minimize that
expression.
The aim can be the maximization of some input variables, which
may vary from gross or net income, depending on the model is struc-
tured. Linear programming can also be applied to problems of cost
minimization, and these programs are based on a diﬀerent set of cri-
teria for optimization.

Introduction
27
C1, C2, ..., coeﬃcients Cn are the cost coeﬃcients (known) or in-
come, depending on the type of problem you’re seeing resole. More-
over, y1, y2..., yn are the decision variables (variables, or activity
levels) to be determined such that the target is reached within the
constraints faced by the problem.
Restrictions, expressed by linear inequalities, are composed of
technical coeﬃcients (Aij), activities, or processes (yn), which are
also taken into account in the target function and also the cellular
levels or limitations (Bi). According to Beneke and Winterboer (1984,
p. 25), there are three basic types of restrictions: “higher than” (>=)
of “less than” (<=) or equal (=), and these can be classiﬁed due to
their nature:
• Resource Constraints or Entries: As such may include land,
capital, labor, and facilities.
• External Constraints: This kind includes concepts such as gov-
ernment area of land allocations, credit limits assigned to prod-
ucts or legal obligations.
• Subjective Restrictions: These are the restrictions imposed by
the operator. Limits may be diﬃcult to deﬁne, but often are
real and signiﬁcant in the planning process. Often restrictions
come from their own personal goals or business of the glider.
Among the limitations of this kind may include the following:
– Limitations on the level of credit that the glider is ready to
be utilized. It is often less than the amount lenders are dis-
placed to contribute. The typical motivation for such kind
of limitations is little explicit desire to avoid the hazards
of debt.

28
Advances in Optimization and Linear Programming
– Restrictions risk level activities involving aspects related
to highly variable income such as raising sheep or cattle.
– Minimum restrictions concerning the operator consider de-
sirable for not properly direct income such as maintaining
pure, dairy cows or crops to maintain the qualities of the
breed cows ﬁeld.
As for the application that has linear programming, Moya (1998, 63)
indicates that some of the major problems that came to settle with
this tool are located in three areas: (1) production management, (2)
evaluation project, and (3) inversion and agricultural applications.
We indicate that this list does not exhaust in any way the options
that linear programming has proven to be an excellent tool to support
decision-making.
In all these situations, we can identify three common terms [5]:
1. There is a global size (goal) that wants to be optimized (proﬁt,
the diﬀerence between model predictions and experimental
data).
2. In addition to the global goal, there are usually additional re-
quirements or constraints that must be met (limited risk, re-
sources, model complexity).
3. There are certain sizes so that if their values are selected “good,”
they are also satisﬁed objective and limitations. These quanti-
ties are called optimization variables or parameters.
So, in order to set the problem of mathematical programming, we
must:
1. Select one or more optimization variables;

Introduction
29
2. Select the objective function f;
3. Form a constraint set.
After that, the class of problem to which the mathematicians obtained
ˇis identiﬁed the model belongs to, and the method for solving it is
selected.
There are several methods for solving linear programming prob-
lems [5, 8]. The geometric method is applicable to problems with a
number of variables n = 2 or when n−m = 2, where m is the number
of constraints. In principle, the linear programming problem can be
solved geometrically in the case of n = 3. The disadvantage of the ge-
ometric method is that it does not solve the general task of linear pro-
gramming, but only some special cases. Until the ﬁrst general method
for solving linear programming, problems came American mathemati-
cian Danzing in 1947 [16]. This method is known as the simplex linear
programming method. He also formulated a general form of a linear
programming problem and gave an algorithm for solving it, known as
the simplex method. Dantzig’s work has circulated among experts
for many years and served as a basis for all subsequent considera-
tions of the problem linear programming. Although other methods
have been found in the meantime, this method is still in use today
through numerous modiﬁcations (see papers [6]). Both geometric and
simplex methods seek maximum (minimum) target functions at the
boundaries of the boundary region.
In the later period, alternative approaches to resolution emerge
as linear programming problems. We mention the works which are
used generalized inverses [45] as well as works by Conn [10] and Dax
[18] that do not use the simplex method. However, the practice has
shown that the simplex method is very eﬀective, in 1972. V. Klee

30
Advances in Optimization and Linear Programming
(Kli) and G.L. Minty proved that it was not polynomial [28]. They
constructed a simple example of a linear task programming where
the admissible set is deformed n -dimensional cube with 2n top, for
which the simplex method with a standard choice of a leading ele-
ment requires 2n −1 iterative steps. The ﬁrst polynomial algorithm
for solving a problem of linear programming was given by Hacien
in [27] in 1979. This has taken a major turn in the development of
linear programming. Khatsian has shown that his ellipsoid method
solves the problem linear programming for O(n4Λ) elementary arith-
metic operation, where Λ is the number of bits required to write
all the parameters problems (constraint matrices, target functions,
and right-hand side constraints. Hezian solved a very important the-
oretical question. However, it turned out that the ellipsoid method
was not applicable in practice. Testing has shown that the simplex
method is far more eﬃcient because it “rarely” reaches an upper limit
of complexity, unlike ellipsoid methods, which often does. This con-
clusion led them to ﬁnd new methods for solving linear programming
problems that, in addition, to polynomial complexity, they also have
practical applicability.
The ﬁrst such method was proposed in 1984 by N. Karmarkar in
his work on Karmakar. Karmarkar’s algorithm solved some test cases
and up to 50 times faster than simplex methods. Karmarkar’s result
sparked a real revolution in the development of this area. After the
Karmarkar method, a whole family of methods emerged known as in-
ternal methods. Today, primal-dual intrinsic methods are dominant
for solving linear programming problems [71]. Although polynomial
methods were discovered, simplex the method is still used today, and
is still alive through numerous modiﬁcations. The simplex method
is much better than the inner point method on the so-called poorly

Introduction
31
conditioned problems, because of its slow but reliable convergence.
Likewise, in practice, there is often a need for solving a class of re-
lated problems where the optimal solution is one of them that can be
eﬀectively used as a starting point to solve other problems. In this
case, too, the simplex method is a better choice than the inner point
method.
In addition to the theoretical results, software packages for solving
linear programmed problems appeared, and which are based on the-
oretical results. These software packages have found wide application
in practice.
Internal methods are divided intoprimal, dual and primal-dual.
The primal methods solve the linear programming problem in stan-
dard form:
min
dT y,
subj.
Ay = β,
y ≥0,
where A is a matrix of type m×n, while a, β, and γ are vectors of the
corresponding dimension. Dual problems solve a dual form problem:
max
βT y,
subj.
AT y + p = γ,
p ≥0.
Primal-dual methods work simultaneously with both primal and
dual problems (primal-dual method). Today, primal-dual methods are
dominant. These methods are described in [71]. Learn your method
internally points for solving linear programming problems belong
modern and modern trend in the world, which is already conﬁrmed
published monographs on polynomial methods, such as [5, 71]. In the

32
Advances in Optimization and Linear Programming
last 10 years, a large number of papers have been published areas so
that the bibliography has thousands of titles.
There are three tools for solving linear programming problems.
• Models: The formulation of problems in detailed mathematical
terms.
• Algorithms: Techniques for solving models.
• Computers and Software: Machines for performing algorithmic
steps.
There are a number of software packages that are designed to
solve the problem of linear programming.
HOPDM is written in the programming language FORTRAN [21].
LIPSOL is written in MATLAB and FORTRAN. Part of the code relating
to Sparse Cholesky factorization and solution of linear systems is
written in FORTRAN and the rest of the code in MATLAB. The algorithm
is described in [72].
LOQO is written in the programming language C and is described
in [62].
PCx is written in C and programming languages FORTRAN. Sparse
Cholesky code is written in FORTRAN and the rest of the code in C.
A detailed description can be provided ﬁnd [15].
MOSEK is written in the programming language C ++ and represents
one of the strongest solvers not only for linear problems programming
already in general for square and nonlinear programming. Unlike the
previously mentioned program, this program is commercial.

Introduction
33
LINDO-linear interactive and discrete optimizer-is an interactive
software package that can be used to solve linear programming prob-
lems. It was developed in 1980 and has been around ever since,
adapted to the Windows environment and graphically oriented appli-
cations. The LINDO software package is used to solve problems posed
directly from the keyboard.
1.5
Mathematical Model
The implementation of some linear programming methods in the
MATHEMATICA programming language can be found in [5]. The General
form of linear programming problems can be expressed as follows.
Determine the values of the variables y1, . . . , yk that match linear
equations the inequalities
k
(1)
Ni
:
X
aijyj
i
j
≤β ,
i
=1
∈I1
k
Ji :
X
aijyj = βi,
i
j=1
∈I2
(1.5.0. 1)
k
(2)
Ni
:
X
aijyj
j=1
≥βi,
i ∈I3
yj ≥0,
j ∈J ⊆{1, . . . , k},

34
Advances in Optimization and Linear Programming
where I1∪I2∪I3 = {1, . . . , m}, I1∩I2 = ∅, I1∩I3 = ∅, I2∩I3 = ∅,
so that the linear objective function
ω(y) = ω(y1, . . . , yk) = γ1y1 + · · · + γkxk
(1.5.0. 2)
has an extremum, i.e., minimum or maximum. They are αij, βi, γj
known real numbers.
By convention, in the general case, a vector y ∈Rk represents
the k−tuple of real numbers y = (y1, . . . , yk),, while matrix formulas
imply that y is a matrix of type k × 1 (vector), i.e.:
y =

y1
.
..

,
yτ = [y1 . . . yk].
yk
Next, y ≥0 means y1 ≥0, . . . , yk ≥0.
y = (y1, y2, . . . , yk) solution in applications meaning of a plan
or program (production, transportation), so this is the task named
“programming” and the name “linear programming” indicates that the
constraints of the variables (1.5.0. 1) as well as the objective function
(1.5.0. 2) are linear.
An arbitrary solution of a system of inequalities (1.5.0. 1) can
be think of the vector y = (y1, y2, . . . , yk), which in geometric the
interpretation represents the point of the k -dimensional space Rk.
We call each nonnegative solution to the system of inequalities (1.5.0.
1).
If we denote by ΓP the set of admissible solutions, then ΓP is a
subset of Rk. For ΓP , we assume that it is not empty and contains at
least one element (case when task (1.5.0. 1)–(1.5.0. 2) has a solution).

Introduction
35
Optimal solution y∗= (y1
∗, . . . , yk
∗)ΓP task linear programming is
the permissible solution for which function goal ω(y) = ω(y1, . . . , yk)
reaches maximum (minimum). In the case of goal function maximiza-
tion is a requirement
ω(y∗) = max ω(y)
y∈ΓP
or
ω(y∗) ≥ω(y)
∀y ∈ΓP .
It is often sought in practice that the optimal value of the goal
function is the smallest on the set of admissible solutions ΓP . In this
case, optimally y∗∈ΓP is the admissible solution for which it is
fulﬁlled
ω(y∗) = min ω(y).
y∈ΓP
or
ω(y∗) ≤ω(y)
∀y ∈ΓP .
In one speciﬁc task, only the maximization problem, that is, the
minimization problem, is solved. The problem of the minimum can
be transformed into the problem of the maximum (and vice versa) by
simply multiplying the objective function by −1, using the following
Proposition 1.5.1 result.
Proposition 1.5.1. The optimization criterion can be given replace
with the opposite, without this replacement aﬀecting the optimal so-
lution, that is, if for y∗∈ΓP satisﬁed
ω(y∗) = max ω(y)
y∈ΓP

36
Advances in Optimization and Linear Programming
then
−ω(y∗) = min[ ω(y)]
y∈ΓP −
and reverse.
Proof. By the assumption of the theorem, it is fulﬁlled
ω(y∗) ≥ω(y)
∀y ∈ΓP .
If we multiply this inequality sa −1, is obtained by:
−ω(y∗) ≤−ω(y)
∀y ∈ΓP ,
by which the theorem is proved.
A linear programming problem has a solution if ωmax (ωmin) has a
value on the set ΓP of permissible solutions. The linear programming
problem has no solution if the system is unequal (1.5.0. 1) has no
non-negative solutions or if the value ωmax (ωmin) does not have a
ﬁnite value.
Constraints (1.5.0. 1) deﬁne in a k -dimensional space a convex
domain ΓP bounded by a set of hyperlevels
X
k
αijyj = βi, ß = 1, . . . , m.
j=1
Let’s call this area a ΓP polyhedron, though in some cases, it can
be endless. This area is called the allowable solution area. As the func-
tions to be maximized or minimized are linear, classic mathematical
methods by maxima or minima goal functions ω(y) = ω(y1, . . . , yk)

Introduction
37
reach at area boundaries ΓP speciﬁed by the given restrictions. If
the hyperlink ω(y) = const is not parallel to any of the hyperlinks
mentioned, which represent the polyhedron, then the target function
ω(y) will reach its maximum (minimum) in one of the tops of the
polyhedron.
Let A = [αij]m×k be a data matrix with types V1, . . . , Vm, let
β ∈Rm and γ ∈Rk be given vectors and let y ∈Rk be an unknown
vector. Inmatrix form problem (1.5.0. 1)–(1.5.0. 2) can be written as
follows:
min
γT x,
subj.
V T
i x ≤βi,
i ∈I1,
V T
i x = βi,
i ∈I2,
(1.5.0. 3)
V T
i x ≥βi,
i ∈I3,
yj ≥0,
j ∈J ⊆{1, . . . , k},
where I1 ∪I2 ∪I3 = {1, . . . , m}, I1 ∩I2 = ∅, I1 ∩I3 = ∅, I2 ∩I3 = ∅.
If it’s I2 = {1, . . . , m} i J = {1, . . . , k}, A = [αij]
n
m×n, γ, y ∈R ,
problem (1.5.0. 3) it comes down to the so called standard format
linear programming problems
min
γT x,
subj.
Ay = β,
(1.5.0. 4)
y ≥0.

38
Advances in Optimization and Linear Programming
In case I3 = {1, . . . , m} and J = {1, . . . , k} problem (1.5.0. 3) it
comes down to the so called symmetric shape
min
γT x,
subj.
Ay ≥β,
(1.5.0. 5)
y ≥0.
Without destroying the general one can assume that βi ≥is 0 for
every i = 1, . . . , m (otherwise, the corresponding inequality can be
multiplied by −1).
For a vector y that satisﬁes the conditions (1.5.0. 1) we say yes
is the acceptable solution to the problem. The admissible solution y∗
isminimum if:
γT x∗≤γT x
for each admissible solution y.
The problem given in the general form (1.5.0. 1)–(1.5.0. 2) can be
transformed in standard or symmetrical form. If new unknowns are
introduced:
k
yk+i
=
βi −
X
aijyj,
i
1
=1
∈I
j
k
yk+i
=
X
aijyj
j=1
−βi,
i ∈I3.
Then the conditions (1.5.0. 1) pass into the system of equations
with k + q = n unknown, where q = |I1| + |I3|.

Introduction
39
X
k
aijyj + yk+i
=
βi,
i
j=1
∈I1
X
k
aijyj
=
βi,
i
j=1
∈I2
(1.5.0. 6)
X
k
aijyj
y
=1
−
k+i
=
βi,
i
j
∈I3.
In doing so, we look at function
ω = γ1y1 + · · · + γkxk + · · · + γnxn
(1.5.0. 7)
where γk+1 = . . . = γn = 0.
The following table illustrates the relationship between the basic
forms of a linear problem.
Restriction
Canonical Form
Standard Form
ατ
i y ≤βi
−ατ
i y ≥−βi
τ
αi y + si = βi, si ≥0
ατ
i y ≥βi
τ
αi y −si = βi, si ≥0
ατ
i y = βi
τ
τ
αi y ≥βi, −αi y ≥−βi
The si variables are called slack variables . Introducing each slack
variable increases the dimension of problem n by 1, and the matrix
A is expanded by the column of the unit matrix I, while the vector
of the objective function γ is expanded by a null element. Variables
from set {1, . . . , n}\J, not imposed the condition of non-negativity is
called free variables . Each free variable yj, j ∈{1, . . . , n}\J we can
replace in the target function and all constraints with an expression

40
Advances in Optimization and Linear Programming
y+
j −yj
−, with y+
j ≥0, yj
−≥0, and so we come to the model where all
the variables are imposed a non-negativity condition. The problem
thus posed is equivalent to the problem (1.5.0. 1)–(1.5.0. 2).
Example 1.5.1. Let us consider the problem of linear programming:
min
5y1 −4y2,
subj.
y1 + y2 ≤80,
3y1 + y2 ≤180,
y1 + 3y2 ≤180,
y1 ≥0, y2 ≥0.
The standard form of this problem is obtained by introducing equaliza-
tion y3, y4 and y5 variables:
min
−5y1 −4y2,
subj.
y1 + y2 + y3 + y4 + y5 = 80,
3y1 + y2 + y3 + y4 + y5 = 180,
y1 + 3y2 + y3 + y4 + y5 = 180,
yi ≥0, ß = 1, . . . , 5.
To translate the problem in a general form to a symmetrical
form equation type constraints need to be eliminated. Equations
V T
i x = βi, and ∈I2 can be equivalently replaced by inequalities
V T
T
i x ≥βi, (−Vi) x ≥−βi, i and I2. Limiting the form (−Vi)T x ≥
−βi is obtained by multiplying the shape constraint V T
i x ≤βi with
−1. Further, each free variable yj, j ∈{1, . . . , n}\J replace in target
function and all constraints as before with two non-negative variables
each and thus we get a problem of type (1.5.0. 5).

Introduction
41
Remark 1.5.1. Considered to be a symmetrical vase assuming that
the system of equations {Ji}i I2 is consistent and of complete rank.
∈
Otherwise, the ﬁrst equations should be eliminated (for example, by
the Gaussian method of elimination), that is, to form an equivalent
system of full rank.
From these considerations, it follows that one does not lose sight
of what is observed in the linear problem of form (1.5.0. 4) or (1.5.0.
5). We mainly deal with the following linear programming problem
in standard form because best suited for theoretical considerations.
The setting of the linear programming task in standard format is
given as follows. The system of equations Ay = β has a solution if
the matrix rank of the system is equation:

α11
α12
. . .
α1n
.
.
.
.
.
.
A = 
.
.
.
.
..

αm1
αm2
. . .
αmn

equal to the rank of the expanded matrix [A|β],

which is obtained by
adding free member columns β1, . . . , βm matrix A (Kronecker-Capelli
theorem). The rank r of the matrix A is called the rank of the system
and represents the number of linearly independent equations between
given constraints. If this condition is not met, the set of admissible
solutions ΓP is empty, and the problem has no solution.
Obviously, the rank of the system equation Ay = β cannot be
greater than the number of equations m, that is, is always ﬁlled by
r ≤m, but the number r cannot be greater than the number of vari-
ables n, so it is also valid r ≤n. If r < m, then by applying the
Gaussian algorithm, we reach a conclusion about system inconsis-
tencies or eliminate m −r related equations in Ay = β. So, suppose

42
Advances in Optimization and Linear Programming
r = m, i.e., that there are no constraints (1.5.0. 4) linearly dependent
and that the system Ay = β agrees. In the event that r = m = n, the
system has a unique solution y = A−1β so it only remains to check
the condition y ≥0. We will be interested in the case r = m < n,
when the number is linearly independent an equation smaller than
the number of variables. Then, if the system equation Ay = β agrees,
it exists endless many solutions. Each of these solutions is obtained
in the same way arbitrary values are selected for n −r = s variables
and then values are selected the remaining r variables are calculated
from the system of equations Ay = β. The variables we calculate are
called dependent or basic (there are r), and the variable sizes are ar-
bitrarily called independent or free variables (n −r = s). Practically,
from the system of equations r dependent variables expresses by pos-
sible n −r = s independent variables, so arbitrary values are chosen
for independent variables. As there are inﬁnitely many independent
variables to choose from of diﬀerent values, the system of equations
Ay = β is inﬁnite many solutions.
Deﬁnition 1.5.1. A non-negative solution, obtained by applying in-
dependent values to be equal to zero, is called basic solution linear
programming task.
Example 1.5.2. The factory produces two types of items α1 and α2, both
on machines M1 and M2. For α1, M1 is 2h, M2 for 4h, and for type α2, M1
runs 4h, and M2 runs 2h. The factory gets 3500 dinars per unit of product
α1, a 4800 per item α2. How much to produce α1 and α2 items and how to
use the work of M1 and M2 to maximize the daily proﬁt of the factory?
Solution: Let y1 be the number of items produced α1 and y2 the number
of items produced α2 items throughout the day. Then the daily proﬁt of
the factory is:

Introduction
43
ω(y) = 3500y1 + 4800y2
with conditions:
2y1 + 4y2 ≤24
4y1 + 2y2 ≤24
y1 ≥0, y2 ≥0.
This gave us a symmetrical shape. If we now introduce the slack vari-
ables y3 and y4 we get equivalent problem in standard format:
max
3500y1 + 4800y2
subj.
2y1 + 4y2 −24 = −y3
4y1 + 2y2 −24 = −y4
y1 ≥0, y2 ≥0.
that is, in matrix form (1.5.0. 4):
2
4
1
0
24
3500
A =
"
0
1
#
β =
2
"
24
#
γ =
4
"
4800
#
1.6
Properties of a Set of Constraints
Let the linear programming problem be given in the standard
format (1.5.0. 4). The set ΓP = {y|Ay = β, y ≥0} on which the
function ω is essentially deﬁned inﬂuences extreme values and has
interesting geometric properties. Below, we assume that r = m < n,
where m and n are dimensions matrix A, and r is its rank. Then the
system has inﬁnitely many solutions so it makes sense to seek extreme

44
Advances in Optimization and Linear Programming
value functions ω(y) deﬁned on the set ΓP . Label the columns of the
matrix A as K1, . . . , Kn.
Note that the vectors K1, . . . , Kn, and β are dimensions of m.
Recall that the vectors y1, . . . , yn are linearly independent if it
follows from the equation α1y1 + · · · + αnyn = 0 α1 = · · · = αn = 0,
otherwise they are linearly dependent. Form expression a = σa1 +
(1 −σ)a2, 0
2
≤σ ≤1 is called the convex combination of vectors a1
and a . Generally a convex combination of vectors a1, . . . , ak is any
vector of a forms:
k
a =
X
k
σiai,
i=1
X
σi = 1,
(σ1, . . . , σk
i=1
≥0.)
The set of vectors K is convex if:
(∀a1, a2 ∈K)(σa1 + (1 −σ)a2 ∈K,
0 ≤σ ≤1).
Geometrically, the set K is convex if for every two points a1, a2 ∈
K implies that the segment deﬁned by these points is contained in
K. The smallest convex set in Rn contains n + 1 of diﬀerent points
is called simplex in Rn; in space R2 each triangle is simplex, and in
R3 each tetrahedron is simplex. Here are some well-known statements
and basic deﬁnitions that are necessary for studying simplex methods
as well as internal methods dots.
Theorem 1.6.1. The set ΓP = {y|Ay = β, y ≥0} is convex.
Proof. Let be y1, y2 ∈ΓP . Then for their convex combination
y = σy1 + (1 −σ)y2,
0 ≤σ ≤1

Introduction
45
we have that
Ay = σAy1 + (1 −σ)Ay2 = σβ + β −σβ = β.
How obvious y ≥0, it is y ∈ΓP .
Deﬁnition 1.6.1. A possible solution to y isosnovno (bazicno) if they
are in the equation:
β = y1K1 + · · · + ynKn
vectors Ki for which yi > 0, are linearly independent.
Note that the basic solution may have the most m coordinate
greater than zero.
Deﬁnition 1.6.2. A basic solution for which it is true A m coor-
dinate greater than zero is called undegenerated. Basic a solution for
which less than m coordinates is greater than zero is called degenerate.
Note that from
  n columns of matrix A, i.e., of vectors K1, . . . , Kn
we can form
n
m
submatrices with m columns. If the vectors
Ki1, . . . , Kim are linearly independent, then matrix β = [Ki1
1
1
· · · Kim]
regular and there is β−. Then it is vector y = β−β uniquely deter-
mined and if y
is, then y is the basic solution. Note that y
Rn
a β−1β ∈Rm
≥
∈
, and that y = β−1β by deﬁnition means that the
coordinates are yi for and ∈/ {i1, . . . , im} equal to zero.
Deﬁnition 1.6.3. The matrix αβ = [Ki1 · · · Kim] isbasic (basic) if
regular. The remaining columns of the A matrix form the nonbasic
matrix αN. The variables yi1, . . . yim are called basic while the re-
maining variables we call non-base . Two basic matrices are adjacent
if they diﬀer in one column.

46
Advances in Optimization and Linear Programming
Let αβ be a basis matrix. Now the system from (1.5.0. 4) can be
written as:
α
1
Bxβ + αNxN = β =⇒yβ = αβ
−β −αβ
−1αNxN
If we now put yN = 0 we get one basic solution (y = (yβ, yN) =
(β−1β, 0), after the corresponding renumbering variables). On the
contrary, each basic solution determines the corresponding basic ma-
trix (if under generated, then is this matrix unique and otherwise
not). This justiﬁes the name “basic matrix” in the Deﬁnition 1.6.3.
It follows from the previous deﬁnition that the maximum number
of basic solutions is equal to
 n
m

.
Deﬁnition 1.6.4. The point y is the extreme point of the convex set
ΓP if it satisﬁes the conditions
y = σy(1) + (1 −σ)y(2) ∧σ ∈[0, 1] ⇔y = y(1) = y(2).
Deﬁnition 1.6.5. The basic solution of y system Ay = β for which
condition y ≥0 is also true basic admissible solution.
Example 1.6.1. In the example (1.5.1) there is:


1
K1 = 3


1
,
K2 =






1

1
1
K3 = 0,
K4 = 
0

1
0
,
,
K5 =
3
0
0
0
1
.
Since m = 3 and n = 5, are basic matrices and basic solutions has
at most 10. Determine basic matrices, basic solutions and values of the
objective function in them:

Introduction
47
β1 = [K3 K4 K5],
y1 = (0, 0, 80, 180, 180),
ω1 = 0,
β2 = [K1 K3 K5],
y2 = (60, 0, 20, 0, 120),
ω2 =
300,
β = [K K K ],
y3 = (50, 30, 0, 0, 40),
ω3
−
3
1
1
5
= −370,
β4 = [K1 K2 K4],
y4 = (30, 50, 0, 40, 0),
ω4 = −350,
β5 = [K2 K3 K4],
y5 = (0, 60, 20, 120, 0),
ω1 = −240.
So there are ﬁve basic solutions. The following solutions are not per-
missible for other databases:
β6 = [K
6
6
1 K2 K3],
y = (45, 45, −10, 0, 0),
ω = −405,
β7 = [K1 K
7
7
4 K5],
y = (80, 0, 0, −60, 100),
ω = −400,
β8 = [K1 K3 K4],
y8 = (180, 0, −100, −360, 0),
ω8 = −900,
β9 = [K2 K3 K5],
y9 = (0, 180, −100, 0, −360),
ω9 =
10
−720,
β10 = [K2 K4 K5],
y
= (0, 80, 0, 100, −60),
ω10 = −320.
A very important fact is the existence of a basic solution follows
from the existence of an admissible solution, which follows from the
following theorem.
Theorem 1.6.2. If ΓP = {y|Ay = β, y ≥0} = ∅, then it contains at
least one basic solution.
Proof. Suppose y = (y1, . . . , yn) ∈ΓP is valid. If necessary we renum-
ber the columns Ki and the coordinates of the vector y such that
yi > 0 for i ≤p i yi = 0 for i > p. Now it is valid
β =
X
n
p
xiKi =
i=1
X
xiKi.
i=1
If the vectors K1, . . . , Kp are linearly independent, then p ≤m
and y is the basic solution. If the vectors K1, . . . , Kp are linearly
dependent, then they exist σ1, . . . , σp ∈R such that
̸

48
Advances in Optimization and Linear Programming
X
p
σiKi = 0
i=1
and then exists σi = 0, 1 ≤i ≤p. Let σk = 0 be and σk > 0. Then:
Kk = −
X σj Kj
i
β =
σk
j=k
X
K
j

σ
yj −
j
yk σk
=k

j.
Thus, the vector β is represented as the sum of p −1 columns of
the matrix A. If moreover, yj −
σ
y
j
k
≥0, j = k,
σk
then the vector:
y1
σ
=
(y1−
1
σk
1
yk
, . . . , yk
,
−1−yk
−
0,
σk
σk
σ
yk+1−
k+1
σp
yk
, 0, . . . , 0, yp−yk
, 0, . . . , 0)
σk
σk
Element of the set ΓP (i.e., the solution of Ay = β). If it is σj ≤0,
then obviously y1
j ≥
σ
0. Otherwise y1
j = yj −y
j
k σk ≥0, which is equiv-
alent to yj
yk
y1
0
σj ≥σk . Therefore, in this case, too,
j ≥, so we conclude
that y1Γ
1
P . However, y
has at most p −1 strictly positive coordi-
nates, which is a contradiction. Therefore, the vectors K1, . . . , Kp are
linearly independent, and y is a basic admissible solution.
The link between the basic solutions and the top set ΓP is given
by the following theorem.
Theorem 1.6.3. If y ∈ΓP is the basic solution of the system Ay =
β, y ≥0, then y is the extreme point of the set ΓP . Conversely, if it
is y is the extreme point of ΓP , then y is the basic solution.
Proof. Let y be a basic solution and let it be a new numbering (if
necessary)
̸
̸
̸
̸
̸

Introduction
49
X
m
β =
xjKj,
y = (y1, . . . , ym, 0, . . . , 0).
j=1
Suppose y is not an extreme point of the set ΓP ,, i.e., since y1, y2 ∈
ΓP , y1 = (y1
1, . . . , y1
n), y2 = (y2
1, . . . , y2
n), such that:
y = σy1 + (1 −σ)y2,
0 < σ < 1.
How it is yi = σy1
i + (1 −σ)y2
i , i = 1, . . . , n, then y1
i = y2
i = 0 for
i > m. Therefore, y1 i y2 are basic solutions for the base K1, . . . , Km,.
m
β =
X
m
x1
jKj =
X
m
x2
jKj =
X
xjKj.
j=1
j=1
j=1
Since K1, . . . , Km are linearly independent, this is y = y1 = y2
which means that y is an extreme point of the set ΓP .
Let us prove the opposite. Let yΓP be the extreme point of ΓP .
New by numbering (if necessary) we obtain that yi > 0 for i ≤p i
yi = 0 for i ≥p. Suppose that the corresponding vectors K1, . . . , Km
from β = Pp
j=1 xjKj, linearly dependent, i.e., Yes there is at least
one σj > 0, 1 ≤j ≤p, so it applies:
X
p
σjKj = 0.
j=1
Now we have:
p
β =
X
p
p
xjKj
=1
±
X
µσjKj =
j
j=1
X
(yj
j=1
± µσj)Kj

50
Advances in Optimization and Linear Programming
for each µ ∈R. If µ = 1
y
min
j
2
σj | 1 ≤j ≤p
, then yj ± µσj >
0, 1 ≤j ≤p, so
y1
=
(y1 + µσ1, . . . , yp + µσp, 0, . . . , 0) ∈ΓP ,
y2
=
(y1 −µσ1, . . . , yp −µσp, 0, . . . , 0) ∈ΓP ,
and it is valid
1
1
y =
y1 +
y2,
2
2
which is impossible because y is an extreme point expensive ΓP .
It follows from the foregoing that the number of extreme points is
less than
n .
m
Corollary 1.6.1.

The set ΓP ﬁnally has many extreme points
Proof. Each basic matrix β determines exactly one basic solution (by
Theorem 1.6.3), and for any basic solution it can ﬁnd the correspond-
ing matrix β such that Theorem 1.6.3 holds. We conclude that the
basis matrices have no less than the basic solutions, and, based on the
previous theorem of extreme points, the set ΓP . Obviously, the basis
matrices have no more than a binomial coeﬃcient of n over m.
The signiﬁcance of the previous theorem and the consequence is that
the number of potential extrema reduces ω(y) functions from (in the
general case) an inﬁnite set ΓP to a ﬁnite set of vertices that has
a maximum of the binomial coeﬃcient of n over m elements. The
objective function ω(y) will be the maximum or minimum in the
foundations of the convex set Γp. Formally, it is suﬃcient to calculate
the values of the objective function in all extreme points of the set
ΓP and determine that point, or points, in which the value of the
n
o

Introduction
51
function ω(y) is extreme. This number of potential extremes grows
rapidly with an increasing value of m i n.
Example 1.6.2. We look at the following problem
max
ω(y) = 2y1 + 5y2
subj.
y1 + 4y2 ≤24, 3y1 + y2 ≤21, y1 + y2 ≤9.
After calculating the values of ω(A), ω(B), ω(C), ω(D), we can see that
the maximum value has ω(B) = ω(4, 5) = 33, which is the solution to the
problem.
We will prove later in Theorem 2.1.1 that the extremum of the
function ω(y) (if any) is exactly at the extremes of the set ΓP , and
by Theorem 1.6.3 in the admissible solutions of Ay = β.
The following theorem provides the criterion for detecting the
boundlessness of the set ΓP .
Theorem 1.6.4. If there is a basic matrix αB = [Ki1 · · · Kim] and
the column Kp of the matrix A such that α−1
B Kp ≤0, then ΓP is an
unlimited set.
Proof. Let αB = [K1 . . . Km] i B−1Kp ≤0 be valid for each p. Then:
Kp = σ1K1 + · · · + σmKm
and it is true σj ≤0, 1 ≤j ≤m. Now it is:
m
β =
X
xjKj
j=1
−µKp + µKp,
µ > 0,
follows:

52
Advances in Optimization and Linear Programming
X
m
β =
(yj −µσj)Kj + µKp,
µ > 0,
j=1
where’s he from:
(p)
yµ = (y1 −µσ1, . . . , ym −µσm, 0, . . . , 0, →µ, 0, . . . , 0) ∈ΓP
for each µ > 0, ΓP is an unlimited set.
If for every basic matrix β and every vector Kp vector β−1Kp
negative then the set ΓP is limited and each yΓP is a convex com-
bination of basic (basic) solutions. So, it is enough to know only
basic solutions. If one basic solution is known, we can determine
another basic solution. Let β = [K1 · · · Km] be basic matrix and
let y = β−1β = (y1, . . . , ym, 0, . . . , 0) known basic the solution. If
β−1Kr ≤0 for Kr, set ΓP is unlimited so suppose ΓP is restricted,
i.e., β−1Kr nonnegative. Let it be:
β−1Kr = (σ1, . . . , σm, 0, . . . , 0)
non-negative and let it be σk > 0 for some k, 1 ≤k ≤m. Then from:
Kr = σ1K1 + · · · + σmKm
follows:
1
Kk =
Kr
σk
−
X σj Kj.
(1.6.0.1)
σk
j=k
By replacement (1.6.0.1) u
̸

Introduction
53
β = y1K1 + · · · + ykKk + · · · + ymKm
we get:
yk
σj
β = y1K1 + · · · +
Kr
σk
−
X
yk
Kj +
σk
· · · + ymKm
j=k
to jest
σ
β =
X
(yj −
j
yk
yk
)Kj +
Kr.
σk
σk
j=k
An appropriate solution
(k)
(r)
y1
σ1
σ
y
= (y1 −yk
, . . . ,
σk
→0, . . . , ym −
m
k
yk
, 0, . . . , 0, →
, 0, . . . , 0)
σk
σk
is in the set ΓP if yj −
σ
y
j
k σk ≥0, j k, hundred is ﬁlled if k is chosen
so that:
yk
yj
= min
sigmaj > 0
.
σ
j
k

σj
|

The base solution y1 is diﬀerent from y if yk > 0 which is fulﬁlled
if y is a non-degenerate solution. The corresponding basic matrix is
obtained by replacing column Kk with column Kr.
̸
̸
̸

54
Advances in Optimization and Linear Programming
1.7
Geometrical Method
It corresponds to each condition of negativity in vector space Rn
half-space in which the corresponding variable is non-negative. Each
conditional equation in Rn corresponds to one hyper-straight. Each
conditional inequality corresponds to the half-space bounded hyper-
bolic associated with the corresponding equation. A set of all the
admissible vectors y is the intersection of all given half-spaces and
given hypergraphs, therefore, constitutes a convex polyhedron ΓP .
The equation γT x = k for some k is a hyperparallel parallel to space
Rn−1 which is normal at γ. Projection of polyhedra ΓP on the direc-
tion determined by the vector γ is a closed set of [l, Λ] real numbers,
where l minimum and Λ maximum of the objective function (1.5.0.
2). Appropriately hyper straight normal to γ are touched by hyper
straight polyhedra ΓP . The common points of these touching hyper-
lines with the polyhedron ΓP give values in which the function (1.5.0.
2) reaches an extreme value.
The geometric method can be used for problems containing n = 2
pro men li ve, and the highest š is n = 3 pro men li ve. The linear
programming task is given in the basic form it fulﬁlls the condition n−
m = 2 (and the highest n−m = 3) can also be to geometric geometry.
The geometric method, while not very basic, is used because easy
access to the general algebraic method.
Let be given a linear problem in form:

Introduction
55
max ω(y) = γ1y1 + . . . + γnyn
subj. α11y1 + α12y2 + ... + α1nyn ≤β1
· · · · · · · · ·
αm1y1 + αm2y2 + ... + αmnyn ≤βm.
For a given system we know that every solution of the system
is an unequal solution one point space Rn, and a set of nonnegative
admissible ones Γp is a subset of Rn. Each of the unequal acts:
X
n
αijyj
i
=1
≤β , ß = 1, 2, ..., m
j
speciﬁes a subset of D
n
i ⊂R , i = 1, . . . , m representing the set of ta
aka on the one hand hyper-straight:
X
n
αijyj = βi,
j=1
So, the area of admissible solutions (polyhedron in Rn) is deter-
mined by the intersection of sets:
Γp = D1 ∩D2 ∩· · · ∩Dm ∩Dm+1 ∩· · · ∩Dm+n,
where subsets Dm+1, ..., Dm+n are obtained from the conditions of the
nonnegativity of the variables y1 ≥0, . . . , yn ≥0. The set of admissi-
ble solutions geometrically represents the polyhedron (simpliﬁcation
complex).
The set of points where the function of goal ω(y) has the value
d also represents one hyperline Wω,d = {y ∈Rn∥ω(y) = d}, which,

56
Advances in Optimization and Linear Programming
depending on the value of d, we can translate in the direction of
the vector γ. Now the problem of linear programming comes down to
ﬁnding it maximum (minimum) values for d such that Wω,d∩ΓP = ∅.
It is on this fact that the geometric method is based. It is now clear
why this method is applicable only in the cases n = 2 and n = 3.
Note also that, by theorem 2.1.1, the extremum goal functions reach
at the extreme point of the set ΓP . The set of optimal points Γ∗
P
from the same theorem is convex and represents a k -dimensional
polyhedron. The objective function, which for ω(y) = d is interpreted
as hyper-straight, reaching the maximum (minimum) in one vertex
of the polyhedron (single unique optimal solution) or one by one
polyhedra if the hyperline ω(y) = d is parallel to it (the case of
inﬁnite but many optimal solutions).
This model consists of a function ω(y) and a constraint (system
non-uniform), and is called the mathematical model. Factory daily
proﬁt is a function of ω(y) that depends on two variables y1 and y2,
and this form of dependency is linear. Indeed, value units of α1 in
the market, i.e., 3500 is multiplied by the number units of y1 of that
type of product produced, and to that added the unit value of the
product α2, 4800 multiplied by the number y2 produced the only α2
items. The limitations stem from the fact that M1 produces a unit
of product α
h
1 for 2 . Hence the linear ones unequal in the above
mathematical model, where the ﬁrst refers to options are M1 and
the other is options M2. These inequalities add to the nature of the
variables sought y1 and y2, which are to be nonnegative quantities.
The set Γp is a convex set because it is the intersection of the ﬁnite
number convex sets. The ω(y) function will suﬃce to be maximum
or minimum in the tops of the convex set Γp.
̸

Introduction
57
If the boundary graphs are represented in the coordinate sys-
tem y1y2 yields one quadrilateral ABCD, which is convex, in area
of which there are possible solutions of a given linear model. Within
the quadrilateral, as well as at the points of the edge, (AB, BC, CD,
and DA) there are possible solutions to a given model. However, it is
noted that C(4, 4) with y1 = 4 and y2 = 4 such that it corresponds to
the optimal solution of a given model, because it is farthest from the
real 3500y1 + 4800y2 = 0 received from the function targets ω(y) for
ω(y) = 0. Indeed, the corresponding value of the criterion function is
max ω(y) = 3500 ∗4 + 4800 ∗4 = 14000 + 19200 = 33200 dinars daily
proﬁt, which is the highest possible under the given conditions.
Example 1.7.1. Two mines R1 and R2 supply coal to the three cities A,
B and C. The R1 mine can deliver 500 tons of coal a day, and mine R2
800 tons. Cost of transporting 1 tonne of coal to new units from mines to
cities are shown in the table. How to arrange transportation to minimize
the total cost of transportation?
Mines
A
B
C
R1
8
5
5
R2
4
6
8
Re š: Mark with y1 the number of tons of coal to be mined R1 to the
city A, and with y2 the number of tons of coal from R1 to B. Considering
that in cities the daily demand is the same as much coal as we can get from
the mine a day, we can other quantities of coal to express by y1 and y2:
R1
→
C : 500 −y1 −y2
R2
→
A : 500 −y1
R2
→
B : 400 −y2
R2
→
C : 800 −500 + y1 −400 + y2 = y1 + y2 −100.

58
Advances in Optimization and Linear Programming
Restrictions and conditions of non-negativity are:
(D1)
500 −y1 −y2 ≥0
Rightarrowy1 + y2 ≤500
(D2)
500 −y1 ≥0
Rightarrow y1 ≤500
(D3)
400 −y2 ≥0
Rightarrow y2 ≤400
(D4)
y1 + y2 −100 ≥0
Rightarrow y1 + y2 ≥100
(D5)
y1 ≥0
(D6)
y2 ≥0.
The areas D1, D2, . . . , D6 are indicated by the arrows in the given im-
age, and the area of permissible solutions:
6
D =
\
Di
i=1
Total costs are:
ω=8y1 + 5y2 + 5(500 −y1 −y2) + 4(500 −y1)
+ 6(400 −y2) + 8(y1 + y2 −100)
= 7y1 + 2y2 + 6500.
The quantities of y1 and y2 should now be determined so that the total
costs are minimal. Real 7y1 +2y2 +6500 = const takes the smallest value in
the points of the permissible values (D), which are nearest to the coordinate
origin. For this reason, the simplest is to calculate the value the objective
functions in the points of the permissible values of (D), which are closest
to the coordinate origin. The simplest is because of this compute the value
of the target function in points M4(100, 0) i M5(0, 100):

Introduction
59
ω(M4) = 7 ∗100 + 2 ∗0 + 6500 = 7200
ω(M5) = 7 ∗0 + 2 ∗100 + 6500 = 6700 = ωmin.
In this way, the minimum cost of transportation from R1 and R2 to the
mine cities A, B and C are provided if the transportation plan is as follows
(y1 = 0, y2 = 100):
Mines
A
B
C
R1 (500)
0
100
400
R2 (800)
500
300
0
In this table, therefore, the optimal coal transportation plan is shown.
Like this, the task is known as the transport task. As we see it, in the case
where we have two dispatch stations (mines) and three receiving stations
(cities), the transport task can be solved geometrically, because the number
of unknowns is reduced to two thanks to provided that the quantity of coal
oﬀered by the mine is R1 i R2 equals the amount of coal in cities A, B i C.
Example 1.7.2. Solve the problem of linear programming by the graphical
method:
max
ω(y) = 2y1 + 3y2
subj.
y1 + y2 ≤5
y1 −3y2 ≥0
2y1 + 3y2 ≥6
yi ≥0,
i = 1, 2.
Mark we have restrictions and conditions of negativity respectively with
D1, D2, D3, D4, D5:
(D1)
y1 + y2 ≤5
(D2)
y1 −3y2 ≥0

60
Advances in Optimization and Linear Programming
(D3)
2y1 + 3y2 ≥6
(D4)
y1 ≥0
(D5)
y2 ≥0.
Each of the limitations and conditions of non-negativity is represented by
in the space R2. Clearly, all permissible solutions will be found in a subset.
D = D1 ∩D2 ∩D3 ∩D4 ∩D5.
Show the geometric area of permissible solutions determined by planes
Di(i = 1, 2, ..., 6):
The reﬁned surface represents the domain of permissible solutions. The
optimal solution will be at one of the points A, B, C, D. Yes, to determine
which point represents the optimal solution, we need to ﬁrst draw a line
representing the objective function for ω = 0. The law thus drawn should
be shifted in the direction of growth in parallel unknown y1 and y2 until
we reach the last point š of the reﬁned surface, or to the last point of the
polygon permissible solutions. At this point, the target function will have
the maximum value; i.e., this point will optimally represent the solution.
In this case, this will apparently be that B is the coordinates that should
be calculated and included in the objective function. From the system:
y1 + y2 = 5y1 −3y2
= 0
we get B(15/4, 5/4) and
ωmax = ω(B) = ω(15/4, 5/4) = 2 ∗15/4 + 3 ∗5/4 = 45/4.
Now we can draw the following conclusions regarding the geomet-
ric method:

Introduction
61
I.
The area of admissible solutions of D is at least one vertex at
its boundary that represents the optimum solution. The proof follows
from the theorem of Weierstrass, which says that a continuous the
function given on a closed and bounded set reaches at least at one
point in the set of the highest value, and at least at one point the
smallest value. Since the objective function is linear and continuous,
this theorem is valid when it comes to convex and bounded areas.
II.
There is no linear programming task the optimal solution
when the set of admissible solutions is D empty or when D is un-
bounded and at the same time the objective function, which is mini-
mized (maximized), is inﬁnite no decreases (grows).
III
If two optimal solutions are obtained then they are all true
between these points, optimal solutions. Thus, if y(1) ∈D and y(2) ∈
D are optimal solutions, then each is a vector of shape:
y(0)
σ
= σy(2) + (1 −σ)y(1),
0 ≤σ ≤1
In the case of n = 2, if the constraints are represented graph-
ically in the coordinate system y1y2 a convex polygon is obtained,
at its extremes (extreme points) ﬁnd a possible solution to a given
linear programming problem. Topics farthest from the real one deter-
mined by the goal function represents the optimal solution to a given
problem.
The geometric method, for the case n = 2, we implemented in the
programming language MATHEMATICA [67]. This is how the GEOM [56],
program was created, which introduced a linear programming prob-
lem in symmetric form from the two variables ﬁnd the optimal solu-
tion by the geometric method and graphically show all the intermedi-
ate steps. We used the following standard functions to graphically dis-
play the set of ΓP allowable solutions MATHEMATICA programming lan-

62
Advances in Optimization and Linear Programming
guage: InequalityPlot, InequalitySolve, FindInstance, etc. These
features are in the standard packages Graphics‘InequalityGraphics
and Algebra’InequalitySolve. Complete code GEOM and implemen-
tation details are shown in the appendix and can be found in the work
[56]. Let’s now consider the work of GEOM in the following example:
Example 1.7.3. Solve linear programming problem:
max
ω(y, y) = 8y + 12y
subj.
8y + 4y ≤600
2y + 3y ≤300
4y + 3y ≤360
5y + 10y ≥600
y −y ≥−80
y −y ≤40
y, y ≥0
We solve the problem with the following command:
Geom[8y+12y,{8y+4y< = 600, 2y+3y< = 300, 4y+3y< = 360,
5y+10y> = 600,y> = 0, y> = 0}]
The program gives a graphical representation of the set of admissible solu-
tions ΓP , as well as the right one corresponding to the objective function
(Wω,d). We move “upward” right, in the direction of the vector γ =
"
8
12
#
,
as long as there is a cross-section with the polygon of permissible solutions.
The program also provides the optimal solution (or an expression that
describes all the optimal solutions). In this case, it is:
y∗= σ
"
190
3
#
+ (1 −σ)
"
45
#
, 0 ≤σ ≤1
70
60
3

Chapter 2
Simplex Method
The simplex method is based on three essential principles: (1) It is
possible to determine at least one permissible solution (plan), which
is often referred to as a baseline plan or a permissible baseline plan.
(2) It is possible to check whether the basic allowable plan is optimal
or not. (3) There is a possibility that in case the plan is not optimal,
a new one can be selected, which is closer to the optimum.
According to the above, the simplex method is based on the suc-
cessive improvement of the initial admissible plan until an optimal
plan is obtained. The simplex algorithm method also allows one to
determine whether a task is serious or not; or whether there is a
contradiction in the restrictions.
2.1
Properties of Simplex Methods
Note ﬁrst that the vector y∗in which the objective function ω(y)
reaches extreme value need not be unique. The following theorem
shows that the target function reaches an extreme value in some of
the extreme points of the set ΓP .
63

64
Advances in Optimization and Linear Programming
Theorem 2.1.1. If ΓP = {y : Ay = β, y ≥0} limited set i ω(y) =
γ1y1 + · · · + γnxn given a linear function, then there is a bar one
extreme point y∗∈Γp such that:
inf ω(y) = ω(y∗).
y∈ΓP
Set {y| y ∈ΓP , ω(y) = ω(y∗)} is convex.
Proof. Let y1, . . . , yp be the extreme points of the set ΓP and let is y∗
the extreme point for which ω(yi) ≥ω(y∗), i = 1, . . . , p. How is each
y ∈ΓP a convex combination of extremes dots, there are positive
scalars σ1, . . . , σp such that it is:
p
y =
X
p
σkyk,
σk = 1.
k=1
X
k=1
Now we have:
ω(y) = ω
 X
p
σkyk
!
p
=
X
p
σkω(yk)≥
)
k=1
k=1
X
σkω(y∗)=ω(y∗,
k=1
which proves that ω reaches the minimum in y∗.
Let ω(y1) = ω(y2) = ω(y∗) be valid. Then:
ω(σy1 + (1 −σ)y2) = σω(y1) + (1 −σ)ω(y2) = ω(y∗)
for each 0 ≤σ ≤1.
The signiﬁcance of the previous theorem is that the number of
potential extremes of ω(y) reduces from (in the general case) an in-
ﬁnite set ΓP to a ﬁnite set of vertices that has a maximum of the
binomial coeﬃcient of n over m elements. Formally, it is suﬃcient to

Simplex Method
65
calculate the values of the objective function in all extreme points of
the set ΓP and determine that point, or points, in which the value of
the function ω(y) is extreme.
Let j1 < · · · < jm be indexes such that AB = {Kj1, . . . , Kjm} one
base of A and let β = {j1, . . . , jm}. Unless otherwise emphasized, we
imply that base AB is joined by base submatrix αB = [Kj1 . . . Kjm].
If the basic solution is admissible, we call base ABadmissible base.
Suppose:
N = {i1, . . . , in
m} = {1, . . . , n}\B
−
growing set and let αN = {Ki1, . . . , Kin
m}. Now the constraint sys-
−
tem Ay = β can be written in the form:
αBxB + αNxN = β,
(2.1.0.1)
where yB is the vector of the base and yN the vector of the non-base
variables. Now from (2.1.0.1) it follows y
= α−1β −α−1
B
B
B αNxN, so it
can be eliminated basic variables from the target function. Analogous
to yB i yN we deﬁne γB and γN such that:
γT x = γT
BxB + γT
T
1
τ
T
1
NxN = γBA−
B β + (γN −γBA−
B αN)yN,
hence γT x∗= γT
BA−1
B β for the base solution y∗. Let’s introduce tags
d′ = γT
BA−1
B β, (γN
′ )τ = γτ
N −γT
BA−
B
1αN, αN
′
= α−1
B αN, β′ = α−1
B β.

66
Advances in Optimization and Linear Programming
Now the standard form of the problem (1.5.0. 4) can be written
in equivalent form:
min &d′ +(γN
′ )T xN,
subj.
yB
+αN
′ yN = β′,
(2.1.0.2)
yB
≥0, yN ≥0.
Problem (2.1.0.1) is the canonical form of problem (1.5.0.4) relative
to base αB. In the canonical form, the matrices of the corresponding
system are one řank with basic variables with hold diﬀerent unit
columns, and in the objective function the coeﬃcients with the basic
variables are equal to zero.
Lemma 2.1.1. The vector of coeﬃcients of the objective function
in canonical the form of the problem of not ar
s programming is
uniquely determined base αB,, i.e., does not depend on the order of
the columns in the matrix AB.
Proof. Let αB be associated with the matrix α¯B with column order
diﬀerent from j1, . . . , jm then α¯B = αBP, where P is a permutation
matrix. As P −1 = P τ, the starting problem can be written in the
form:
min γ¯τ
By¯
T
B + γNxN,
α¯By¯B + αNxN = β,
y¯B ≥0,
yN ≥0,
where y¯
= P −1
1
B
yB, γ¯B = P −γB, hence the canonical form is ob-
tained:

Simplex Method
67
min
γ¯τ
B
(α¯B)−1β + (γτ
N −γ¯τ
B(α¯
1
B)−αN)yN,
subj.
y¯B
+(α¯B)−1α
1
NxN = (α¯B)−β,
(2.1.0.3)
y¯B
≥0,
yN ≥0.
Since the γ¯τ (α¯ )−1 = γτ (P −1)τ(P −1
T
B
)
1
B
B
αB
−
= γBA−1
B , these are
free terms and coeﬃcient vectors in the objective functions problems
(2.1.0.1) and (2.1.0.3) are equal, while the system of equations in
(2.1.0.3) can be write in the form P −1(yB +α−1
B αNxN) = P −1β,, i.e.,
it is about by permuting the equations of the system in (2.1.0.1).
We will use the linear programming problem in the symmetric
form:
Deﬁnition 2.1.1. The problem (??) is basically admissible if βi ≥0
for every i = 1, . . . , m
The previous deﬁnition is closely related to the notion of a basic
permissible solution. Namely, if we introduce additional slack vari-
ables, we get:
n
minω(y) =
X
γiyi + d
(2.1.0.4)
i=1
n
p.o
X
αijyj
=
=1
−βi
−yn+i, i = 1, . . . , m.
(2.1.0.5)
j
The form (2.1.0.5) is often called the canonical form of linear
programming problems. The variables on the right (in this case
yn+1, . . . , yn+m) are called basic while those on the left-hand side of
the equations (in this case y1, . . . , yn)non-basic. We will further label

68
Advances in Optimization and Linear Programming
the variables with yB,1, . . . , yB,m and yN,1, . . . , yN,n, respectively. If
we now put yN,1 = . . . = yN,n = 0, then yB,i = βi for i = 1, . . . , m.
The solution thus obtained is basically admissible, if βi ≥0 for each
i = 1, . . . , m.
Corollary 2.1.1. Let (2.1.0.5) in the basic admissible canonical
form be γj ≥0 for every j = 1, . . . , n. Then the basic solution
y∗= (0, . . . , 0, β1, . . . , βm) is optimal.
The fundamental feature of the canonical form is that it is based
on the coeﬃcients can determine whether the basis is correct sizing
optimally, as in which case the target function is unbounded from
below:
Theorem 2.1.2. Let it be in canonical form (2.1.0.3)
γj
′ ≥0, j ∈N, βi
′ ≥0, ß = 1, . . . , m.
Then the basic solution corresponding to the base αB is optimal.
Proof. From yN
∗= 0 it follows yB
∗= β′ ≥0, so y∗is permissible
solution. If y is an arbitrary admissible solution, then from y ≥0 i
yj
∗= 0, j ∈N follows:
γT x = d′ +
X
γj
′yj ≥d′ = d′ +
j∈N
j
X
γj
′yj
∗= γT x∗,
∈N
so y∗is the optimal solution.
Theorem 2.1.3. Let it be in canonical form (3.1.2) βi
′ ≥0, i =
1, . . . , m and for some k ∈N is valid that γk
′ < 0 i αik
′
≤0, i =
1, . . . , m. Then the target function on the permissible set is unbounded
from below:

Simplex Method
69
Proof. Let t ≥0 be the coordinates of the point y(t) deﬁned by:
yji(t) = βi
′ −αik
′ t, i = 1, . . . , m,
yj(t) = 0, j ∈N\{k},
yk(t) = t.
It is directly veriﬁed that y(t) is the admissible point of the prob-
lem (2.1.1) and is valid.
γT x(t) = d′ +
X
γj
′yj(t) = d′ + γk
′ t →−∞,
t →∞.
j∈N
Unless the requirements of Theorems 3.1.2 or 3.1.3 can then be
switched to the canonical form that corresponds to some new neigh-
bor base but so that the value of the target function in the new one
reduce, or at least not increase, the basic permissible solution. That
idea is in the basic simplex method. It is used in this spreadsheet
linear programming problems.
Elemental Transformations LP-tables are:
1. multipliing i−th row with σ = 0, for i ∈{1, . . . , m}, 2. adding
i−th row, for i = 1, . . . , m, j−-th row for j ∈{0, 1, . . . , m}.
Lemma 2.1.2. The LP-table is ﬁnally applied a lot of elements trans-
form transforms to LP-table corresponding to equivalent linear pro-
gramming problem.
Proof. Elementary transformations with i−of this type for and ∈
{1, . . . , m} obviously do not change the allowed set. Add i−of this
type for i ∈{1, . . . , m} zero type transforms it into a species.
[−d + βi | γ1 + αi1 · · · γn + αin],
̸

70
Advances in Optimization and Linear Programming
corresponding to the new target function:
ω
=
d −βi + (γ1 + αi1)y1 + · · · + (γn + αin)yn
=
d + γ1y1 + · · · + γnxn + (−βi + αi1y1 + · · · + αinyn)
=
d + γ1y1 + · · · + γnxn,
i.e., on the admissible set of values of the transformed objective func-
tion, the starting target functions are the same, so the problems are
equivalent.
It follows from Lemma 3.1.2 that by a procedure analogous to
Gauss-Jordan, diﬀerent formulations of the problem are obtained by
the method.
In this chapter, we will present a simplex method for solving prob-
lems linear programming. This method was developed in 1940 by
George B. Danzig. We will ﬁrst show an algebraic approach, which is
suitable when it is about the task of smaller size, and then we will give
the forgiveness simplex algorithm using the so-called simplex table.
2.2
The Algebraic Essence of the Simplex Method
Let the following linear problem be given programming with r =
m li ne ar no independent constraints:

Simplex Method
71
X
n
X
n
min
ω(y) = γT x =
γixi
i=1
p.o
αijyj = βi,
i = 1, . . . , m,
j=1
yj ≥0,
j = 1, . . . , n.
The optimal solution lies in one of the convex polyhedron foundations,
where at least k = n −m variables equal to zero. Let us choose
arbitrarily k variables for the independent (free) variables and by
means of expressing them dependent variables. Let the independent
variables y1, . . . , yk such that when we use them to express m = n−k
dependent variables:
−yk+1 = αk+1,1y1 + αk+1,2y2 + · · · + αk+1,kyk −βk+1
. . .
−yn = αn,1y1 + αn,2y2 + · · · + αn,kyk −βn (2.2.0.1)
the coeﬃcients βk+1, . . . , βn are positive. The target function at point
y = (y1, . . . , yk) gets a value:
ω(y1, . . . , yn)=ω(y1, . . . , yk)=γ0 + γ1y1 + · · · + γkxk. (2.2.0.2)
Assuming y1 = y2 = · · · = yk = 0 we get a basic solution:
(0|, 0,{z. . . , 0}, βk+1, βk+2, . . . , βn),
βk+1, . . . , βn ≥0
k

72
Advances in Optimization and Linear Programming
and minimum value:
ω = γ0.
Let us now consider whether we can reduce the value of the ob-
jective function ω by increasing it one of the variables y1, y2, . . . , yk.
If all the coeﬃcients γ1, γ2, . . . , γk with y1, y2, . . . , yk of the target
function is positive, then it magniﬁes one of these pro’s (to values
greater than zero) we cannot reduce the value goal functions. This
means that the basic solution is obtained and is optimal. However,
if between the coeﬃcients γ1, γ2, . . . , γk has and negative, then mag-
nifying the value of the variable in front of which the coeﬃcient in
the function of the target is negative, we can reduce the value of the
function goal ω, i.e., we can come up with a better basic solution. For
example, let be a negative coeﬃcient γj in the expression (2.2.0.2).
Now it makes sense to increase the variable yj and thus go beyond
of the basic solution obtained, where yj was equal to zero, to a new
basic solution where instead of yj will be zero some of the dependent
variables. Increasing yj decreases the value functions of the ω target,
but we need to make sure that some of the dependents are doing this
yk+1, yk+2, . . . , yn does not become negative. Oh no, obviously they
will not become negative if they are in the equations (2.2.0.1) coef-
ﬁcients αk+1,j, . . . , αnj with yj negative, so then yj can be increased
indeﬁnitely, for some j, 1 ≤j ≤k. This means that the target func-
tion is not bounded on the bottom (i.e., ωmin = −∞). In this case,
the problem does not have the optimal solution. Suppose now that
between the coeﬃcients of yj in the equations (2.2.0.1) there are also
positive coeﬃcients. For example, let it be in the singular expressing
the dependent variable yi, i ∈{k + 1, . . . , n}

Simplex Method
73
−yi = αi1y1 + · · · + αijyj + · · · + αikyk −βi
positive coeﬃcient with yj, i.e., αij >0. If we put it y1 =· · ·=yj−1 =
yj+1 =· · ·=yk =0, we get the system:
−yk+1 = αk+1,jyj −βk+1
. . .
−yn = αn,jyj −βn.
This means that yj can be increased to a value:
βi ,
βi > 0, αij > 0, ß = k + 1, . . . , n
αij
because for that value of variable yj the variable yi becomes zero:
yi = 0. Further increasing yj the variable yi would become negative.
Now let’s choose between the variables yk+1, yk+2, . . . , yn variable yp
by condition:
βp
i
= min
 β ,
αij > 0, k + 1
i
αpj
αij
≤
≤n

.
Then the value yj is expressed from the equation:
−yp = αp1y1 + · · · + αp,jyj + · · · + αpkyk −βp
and substitutes in the other equations (2.2.0.1) and in the function
of the objective (2.2.0.2). That way, instead of the variable yj among
the independent variable is a variable yp, and the pro men li va yj,
which was in the previous the basic solution was independent, now it
becomes a dependent variable. Symbolically, we designate this change

74
Advances in Optimization and Linear Programming
as yp ↔yj. So the variables are dependent now:
yj, yk+1, . . . , yp−1, yp+1, . . . , yn.
These dependent variables are expressed by independent vari-
ables:
y1, . . . , yj−1, yj+1, . . . , yk, yp.
Also, the target function is expressed by independent variables.
The performed procedure is now being repeated. If all the coeﬃ-
cients are with independent changes li ve y1, . . . , yj
1, yj+1, . . . , y
−
k, yp
in the function of the objective positive, then for
yj = yk+1 = · · · = yp−1 = yp+1 = · · · = yn = 0
basic solution obtained and optimal solution. If there are also negative
coeﬃcients with independent changes, the procedure is repeated until
it is added to the optimal solution.
Let, in the general case, be given a basic admissible problem
(2.1.0.5) for which γj < 0 for some j ∈{1, . . . , n} i αij > 0 for some
i ∈{1, . . . , m}. Given γj < 0, it makes sense to increase the variable
yN,j and thus go beyond of the basic solution obtained, where yN,j
was equal to zero, to a new basic solution where instead of yN,j will
be zero some of the dependent variables. Increasing yN,j decreases
the value functions of the ω(y) target, but we need to make sure that
some of the basic ones are yB,1, yB,2, . . . , yB,m do not become nega-
tive. If αsj < 0, the variable yB,s will obviously not become negative.
Now consider the equation:
−yB,i = αi1yN,1 + . . . + αijyN,j + . . . + αinyN,n −βi

Simplex Method
75
If we put yN,1 =· · ·=yN,j−1 =yN,j+1 =· · ·=yN,n =0, we get:
−yB,1 = α1jyN,j −βi
. . .
−yB,m = αnjyN,j −βn.
This means that yN,j can be increased up to:
βi ,
βi > 0, αij > 0,
αij
because for this value of the variable yN,j the variable yB,i becomes
zero. Further increasing yN,j the variable yB,i would become negative.
Let us now choose the basic variable yB,p by condition:
βp = min
 βi ,
αij > 0, k + 1
i
αpj
αij
≤
≤n

.
(2.2.0.3)
Now we replace the variables yB,p and yN,j, i.e., we now express
the variable yN,j from equation:
−yB,p = αp1yN,1 + · · · + αpjyN,j + · · · + αpnyN,n −βp
and replace it in the other equations and in the function of the goal.
That way, instead of the variable yN,j among the non-base variable is
a variable yB,p, and the pro men li va yN,j which is in the previous the
basic solution was independent, now it becomes a dependent variable.
This gives us a new basic solution:
y1 = (y1
N, y1
B) =
 (0, . . . , 0, β1
p, 0, . . . , 0), (β1
1, . . . , β1
p−1, 0, β1
p+1, . . . , β1
n)


76
Advances in Optimization and Linear Programming
where:
β1
βp
p =
,
β1
β
l = βl
αpj
−
p
αlj
,
l = p
αpj
As well as the equivalent problem in canonical form. At point y1,
the goal function has a larger value than in the basic, basic admis-
sible solution. If we now continue to apply the same procedure with
the new one in canonical form, the goal function will increase, and at
some point, we will surely get into the situation that we can apply a
lemma (??) or come to the conclusion that the objective function un-
limited. This intuitive consideration is crucial to the simplex method,
and will be more formally implemented in the next section. Also, we
will introduce the notion of Tucker’s table, which in many respects
simpliﬁes the procedure just described for constructing a new basic
solution. This is the most common approach to beneﬁt when imple-
menting simplex methods.
2.3
The Term Tucker’s Tables and the Simplex
Method for Basic Permissible Canonical Forms
Consider one canonical form of linear programming problem:
̸

Simplex Method
77
max f(y) = γ1yN,1 + . . . + γnyN,n + d
subj.α11yN,1 + α12yN,2 + ... + α1nyN,n −β1 = −yB,1
α21yN,1 + α22yN,2 + ... + α2nyN,n −β2 = −yB,2
(2.3.0.1)
· · · · · · · · ·
αm1yN,1 + αm2yN,2 + ... + αmnyN,n −βm = −yB,m.
The problem can be summarized in the following way:
yN,1
yN,2
· · ·
yN,n
−1
α11
α12
· · ·
α1n
β1
=
−yB,1
α21
α22
· · ·
α2n
β2
=
−yB,2
...
...
...
...
...
...
αm1
αm2
· · ·
αmn
βm
=
−yB,m
γ1
γ2
· · ·
γn
d
=
f
(2.3.0.2)
We call this table Tucker Table for the problem (2.3.0.1). Let us in-
troduce the labels αm+1,j = γj for j = 1, . . . , n as well as αi,n+1 = βi
for i = 1, . . . , n. Also, let αm+1,n+1 = d. Now, to describe the canon-
ical form is linear programming suﬃcientexpanded Tucker’s table:
A = {αij}i=1,m+1,j=1,n+1. Below, we will often identify matrices A
and A whenever there is no risk of confusion.
Two forms of Tucker tables are encountered in the literature,
where y1, . . . , yn are non-base, and t1, . . . , tm are base variables.
At the end of the previous section, it was necessary to express
non-base variable yN,j from the p equation of the system (2.3.0.1)
and replace it in other equations and as a function of the goal. In this
way, the variable yB,p becomes non-basic, while yN,j becomes basic.

78
Advances in Optimization and Linear Programming
Now let’s look at what happens to the A′ matrix of the appro-
priate standard form (2.1.0.2). In the matrix A′ the columns corre-
sponding to the basic variables form a unit matrix while the others
form Tucker’s A table. After replacing the column variables KvN,j of
the matrix A′ becomes equal to p that column unit matrices. To do
this, it suﬃces to subtract for each i = 1, . . . , m, and = p of the and
type matrix A′ p-that type multiplied by:
a‘i,vn,j
αij
=
,
A‘ = [a′ ]
a
i
′p,v
=
n,j
α
ij
1,m,j=1,m+n
pj
while we only divide p by αpj = a‘p,vn,j. In the same way, we transform
the vector β‘ and the objective function by counting them in the order
n + m + 1 column and the m + 1 type of matrix A′. We describe this
transformation in vector and scalar form as follows:
1
α
−
qj
a′
,v
V
= V
V
−
pla
,
a′)1
q
′
(
= a′
B,j
q
q
p
α
ql
ql
(2.3.0.3)
pj
a′p,vB,j
Where Vi is note for i-th row A′
i
of matrix A′. In this case, new
•
Tucker table is equal to:
yN,1
· · ·
yN,j−1
yB,p
yN,j+1
· · ·
yN,n
−1
a1
1
11
A =
1
· · ·
a1
1,j
a1
−
1j
a1
1
1,j+1
· · ·
a1
1n
β1
1 =−yB,1
a21
· · ·
a1
2,j
1
a1
2j
a1
2,j+1
· · ·
a1
2n
β1
2 = y
−
−B,2
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(2.3.0.4)
̸

Simplex Method
79
a1
p−1,1
· · ·
a1
p−1,j−1
a1
p−1,j
a1
1
1
p
1
β
−,j+1
· · ·
ap−1,n
p−1=
1
1
1
1
1
1
−yB,p−1
ap1
· · ·
ap,j−1
apj
ap,j+1
1
1
1
1
· · ·
apn
βp = −yB,j
a
1
1
p+1,1
· · ·
ap+1,j
1
ap+1,j
ap+1,j+1
· · ·
a
=
−
p+1,n
βp+1 −yB,p+1
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
a1
1
1
1
1
m1
· · ·
am,j
1
amj
am,j+1
· · ·
amn
β1
m = −y
−
B,m
γ1
· · ·
γ1
1
1
j−1
γ
1
1
1
j
γj+1
· · ·
γn
d
=
f
where the elements a1
ql are given by the expression:
α1
1
pj =
;
αpj
αpl
α1
pl =
,
l = j;
αpj
(2.3.0.5)
α1
α j
q = −
q
j
,
q = p;
αpj
α1
α
ql =αql −
plαqj ,
q = p, = j;
αpj
Of course, we mean here that q = 1, . . . , m+1 and l = 1, . . . n+1.
Expressions (2.3.0.5) are derived directly from expressions (2.3.0.3)
if the structure of the matrix A′ is considered.
2.4
Algorithm of Simplex Method
We consider linear program:
̸
̸
̸
̸

80
Advances in Optimization and Linear Programming
n1
max ω(y) = ω(yN,1, . . . , yN,n1) =
X
γiyN,i
i=1
−d
n1
(1)
Ni
:
X
αijyN,j ≤βi,
i = 1, . . . , r
j=1
n1
(2)
Ni
:
X
αijyN,j
1
j
≥βi,
i = r + , . . . , s (2.4.0.1)
=1
n1
Ji :
X
αijyN,j = βi,
i = s + 1, . . . , m
j=1
yN,j ≥0,
j = 1, . . . , n1.
In this case, αij, βi and γj are known real numbers. Any inequality
of the form
(1)
Ni
(LE constraints) is transforms into the appropriate
equation by addingslack variables yB,i:
n1
(1)
Ni
:
X
αijyN,j + yB,i = βi,
i = 1, . . . , r.
j=1
Also, any inequality of the form
(2)
Ni
(GE constraint) is trans-
forms into equality by subtractingsurplus (oﬀset) variables yB,i:
n1
(2)
Ni
:
X
αijyN,j
yB,i = βi,
i = r + 1, . . . , s.
j=1
−
That way, we get a linear program in standard form:

Simplex Method
81
max
γ1y1 + · · · + γn1yn1 −d
subj.
Ay = β,
β =(β1, . . . , βm), y=(yN,1, . . . , yN,n1, yB,1, . . . , yB,m)
yN,j ≥0, j = 1, . . . , n1,
(2.4.0.2)
yB,i ≥0, ß = 1, . . . , s, yB,i = 0, ß = s + 1, . . . , m
where the matrix A belongs to the set Rm×(n1+s).
In each equation, we choose one of the variables yN,j for which
apply αp,j <> 0 to the base one, and make the corresponding sub-
stitutions in other equations. An algorithm can be used to replace
the base one variables yB,p = 0 and nonbasic yN,j. After replacing
n = n1+s, the canonical form of the problem (2.4.0.2) can be written
in the following table form τ0: Beginning table τ0
heightyN,1
yN,2
. . .
yN,n
-1
α0
11
α0
12
. . .
α0
1n
β0
1
= -yB,1
. . .
. . .
. . .
. . .
. . .
. . .
α0
m1
α0
m2
. . .
α0
mn
β0
m
= -yB,m
γ0
1
γ0
2
. . .
0
γn
0
d
=
0
ω
where yN,1, . . . , yN,n non-basic variables i yB,1, . . . , yB,m base vari-
ables. Table (2.4) transforms the coeﬃcients of the matrix A and the
vector γ denoted by α0
ij and γ0
j , respectively. Table (2.4) is called
Tucker’s corresponding to maximize the goal function.
Deﬁnition 2.4.1. The solution of a linear code programming task
whose independent variables are equal to zero is called the basic solu-
tion.

82
Advances in Optimization and Linear Programming
Proposition 2.4.1. Let Tucker be a table of basic maximization the
task of li ne ar nog programming represented by a table of τk forms:
Table τk in the k iteration.
heightyN,1
yN,2
. . .
yN,n
-1
αk
11
αk
12
. . .
αk
1n
βk
1
= -yB,1
. . .
. . .
. . .
. . .
. . .
. . .
αk
m1
αk
m2
. . .
k
αmn
βk
m
= -yB,m
γk
1
γk
2
. . .
γk
n
dk
= ωk
If βk
1, . . . , βk
m ≥0, then in the base-admissible maximization, the
basic solution in the table is an acceptable solution.
Proof. Indeed, putting all the independent variables equal Zero, all
major ogs are reduced to equations −βk
i = −yB,i or βk
i = yB,i. In this
way, every solution satisﬁes all limitations task, so it is admissible.
The following is a simplex algorithm for maximizing the base
admissible table τk (2.4.1).
Algorithm SimplexStandardMax
(A simplex method for maximizing the base admissible table).
k-th an iteration of the simplex method consists of the following
steps: Step 1. If γk
1, . . . , γk
n ≤0, the algorithm stalls. Basic the admis-
sible solution corresponding to the simplex table τk is optimal. Step
2. Select arbitrary γk
j > 0. (Can be taken maximum γk
j > 0. Selecting
the ﬁrst γk
j > 0 solves the cycling problem.)
Step 3. For every l for which γk
l > 0, examine whether αk
il ≥0
for each i = 1, . . . , m. If such l there is a barn algorithm. Target
the function on the admissible set is unbounded from above, i.e., the
maximum is +∞.

Simplex Method
83
This step is a modiﬁcation of the corresponding step from [43].
Modiﬁcation consists in being a condition from Step 3 checks for
every l for which γk
l > 0 applies, not just l = j.
Step 4. Calculate
βk
βk
min
i ,
αk
p
k
ij > 0
=
k
1≤i≤m
(
αij
)
αpj
and replace the non-base variable yN,j and the base variable yB,p.
Symbolically, this transformation is written as follows mode: yN,j ↔
yB,p.
This transformation is described in more detail in the Replace
algorithm.
Algorithm Replace.
(Substitution of the base variable yB,p and the non-base variable
yN,j.)
Lead element transformation:
αk+1
1
pj
=
.
αk
(2.4.0.3)
pj
Transformation of an element into a leading species, excluding the
leading element:
αk
αk+1
pl
=
,
l = j,
pl
k
(2.4.0.4)
αpj
Transform a vector element β into a leading type:
βk
βk+1
p
p
=
,
αk
(2.4.0.5)
pj
̸

84
Advances in Optimization and Linear Programming
Transformation of an element in the leading circle, except for the
leading element:
αk
αk+1
q
qj
= −
j ,
q = p,
αk
(2.4.0.6)
pj
Transformation of an element beyond the leading type and the leading
column:
αk
αk+1 = αk
ql −
plak
qj ,
q = p, l = j;
ql
αk
(2.4.0.7)
pj
Transform a vector element β outside the leading type:
βkαk
k+1
k −
p
qj
βq
= βq
,
q = p
αk
(2.4.0.8)
pj
Transform the vector element γ into a leading type:
γk
γk+1
j
= −
j ,
αk
(2.4.0.9)
pj
Transform a vector element γ outside the leading type:
γk
γk+1 = γk
l −
j ak
pl ,
l = j;
l
αk
(2.4.0.10)
pj
Free member transformation d:
βkγk
dk+1 =
k −
p
j
d
.
αk
(2.4.0.11)
pj
Step 5. Replace k with k + 1 and go to Step 1.
̸
̸
̸
̸
̸

Simplex Method
85
Consider the Replace algorithm.
The equation expressing the basic variable yB,p is of the form:
X
n
αk
k
plyN,l −βp = −yB,p
l=1
hence obtained after replacement:
X
n
αk
pl
βk
1
−
p
yN,l +
yB,p
=
yN,j.
αk
αk
αk
(2.4.0.12)
pj
pj
pj
−
l=1,l=j
Equations are derived from there (2.4.0.3)–(2.4.0.5). For q = p from
X
n
αk y
−βk
ql N,l
q = −yB,q
l=1
X
n
n
αk
βk
αk
X
pl
l
−
p
q yN,l
αk
qj


1
yN,l +
y
βk
B,p
p =
yB,q,
αk
pj
αk
pj
−αk
pj
l=1,l

−
−
=j
l=1,l=j
i.e.:
 
αk ak !
αk
k
k
p
αq −
1 qj
a
1
yN,1 + · · · +
 
αk
j
q
1 −
p,j−1 q
,j
!
yN
αk
pj
−
,j
αk
−1
pj
αk
−
qj yB,p
αk
 pj
αk
!
α
k
−
p,j+1ak
qj
 
k
k
k −
pnaqj
+
αq,j+1
yN,j+1 +
αqn
!
yN,n
αk
pj
αk
pj
−
 
βk
βk
q −
pαk
qj
αk
pj
!
= −yB,q.
̸
̸
̸
̸

86
Advances in Optimization and Linear Programming
That’s where they come from (2.4.0.6)–(2.4.0.8). Finally, from:
ωk = γk
1y
k
k
N,1 + · · · + γnyN,n −d
and (2.4.0.12) we get:
n
ωk =
X
αk
βk
1
γk
l yN,l −
pl
p
γk
j

X
yN,l +
yB,p
dk,
αk
k
pj
αk
pj
−αpj
−
l=1,l=j
l=1,l=j


i.e.:
ωk
=
 
γk
k
j αp1
γk
j αk
p,j
1
γk −
yN,1 + · · · +
 
k
1
!
γj−1 −
−
!
yN,j−1
αk
pj
αk
pj
γk
−
j yB,p
αk
pj
+
 
γkαk
γk
p,j
j
−
j
+1
+1
αk
pj
!
yN,j+1 +
 
γk
γk
n −
j αk
pn
αk
pj
!
yN,n
−
 
βk
pγk
j
dk −αk
pj
!
.
That’s where they come from (2.4.0.9), (2.4.0.10) i (2.4.0.11).
This transformation is similar to the Gaussian elimination pro-
cess:
- select p = αij = 0;
- exchange yN,j i yB,i;
- change p sa 1/p;
- change each value q in ith row with q/p;
- change each value r in column j sa −r/p;
̸
̸
̸

Simplex Method
87
- change another value s sa s −(q · r/p).
Remark 2.4.1. In the general case, the indices p and j in Step 3 are
not unambiguous from re where ni, i.e., there may be more candidates
who meet the above requirements. When p and j are selected, they de-
termine the so-called pivot element αpj with which they are performed
transformations in Step 4. Transition from table τk to table τk+1 is
called pivoting. A series of elementary transformations in Step 4 it
makes one complex, the so-called transformation. The following the-
orem proves that pivoting does not increases the target function and
that τk+1 is also a simplex table.
Simplex algorithm method for minimizing base admissible table
(2.4.1) is similar to the maximization table algorithm: Algorithm
SimplexStandardMin
(Simplex method for minimizing the base admissible table, as in
[55, 64]).
k-th iteration of the simplex method consists of the following
steps:
Step 1. If γk
1, . . . , γk
n ≥0, the algorithm stops. The base admissible
solution corresponding to the simplex table τk is optimal.
Step 2. Select arbitrary γk
k
j < 0. (Minimum γj < 0 or ﬁrst may be
taken γk
j < 0.)
Step 3. Examine whether αk
ij ≤0 for each i = 1, . . . , m. If this
condition is satisﬁed, the algorithm stops. Target the function on the
admissible set is unbounded from below, i.e., the minimum is −∞.
Step 4. Calculate

88
Advances in Optimization and Linear Programming
βk
β
min
1≤i≤m
(
k
i
p
,
αk
ij > 0
=
αk
ij
)
αk
pj
and replace the non-base variable yN,j and the base variable yB,p,
using the Replace algorithm.
Step 5. Change k with k + 1 and go to step 1.
This practically means that the table τk applies the following elemen-
tal transformations:
• multiply p−th row with −αk
qj
k
and add to rows q = 0, . . . , m,
αpj
q = p;
• divide p-th row with αk
pj.
Theorem 2.4.1. By applying the elemental transformations de-
scribed in Step 4. The algorithm SimplexStandardMin is obtained from
the simplex table τk simplex table τk+1 corresponding to an equivalent
linear problem programming. Here dk+1 ≥dk.
Proof. Based on Lemma 2.1.2, the table τk+1 corresponds to the
equivalent linear programming problem. In doing so, it exits the ba-
sic matrix a column that had a unit in p−that type and a j−that
column enters. Based on previous considerations about moving to an
adjacent base, out of condition:
βk
p
βk
= min
i
αk > 0
αk
k
ij
pj
(
αij
|
)
follows yk+1 basic permissible solution, i.e., βk+1
i
≥0. The proof
follows from:
βk
βk+1
i
= βk
i −
pαk
ij
αk
pj
̸

Simplex Method
89
i.e.,
βk
p
βk
αk
pj
≤
i .
αk
ij
From γk
j < 0 follows:
γk
−dk+1 = −dk
j
+
βk
αk
p
pj
≤−dk,
i.e., dk+1 ≥dk.
Let’s now apply the SimplexStandardMin algorithm to the example
already discussed in 2.1.0.2:
Example 2.4.1. To problem
5y1 −4y2,
y1 + y2 ≤80,
3y1 + y2 ≤180,
y1 + 3y2 ≤180,
y1 ≥0, y2 ≥0
ﬁts simplex table τ0 : (pivot elements are framed for transparency), τ0 =
y1
y2
-1
1
1
80
= -y3
3
1
180
= -y4
1
3
180
= -y5
-5
-4
0
= ω
The corresponding basic permissible solution is y0 = (0, 0, 80, 180, 180), and
the value of the objective function γτy0 = 0. Obviously, the tests in steps 1
and 2 are not satisﬁed. Let us choose j = 1. Now
β0
1/α0
11 = 80, β0
2/α0
21 = 60, β0
3/α0
31 = 180,

90
Advances in Optimization and Linear Programming
from where we determine p = 2. So, we need a replacement y1 ↔y4. The
Replace algorithm is obtained following a series of transformations as well
as the corresponding table τ1:
α1
1
21 = α1
pj =
= 1,
α0
pj
α0
α1
22 = α1
pl
α0
pl =
=
22
1
=
,
α0
α0
pj
21
3
α0
α1
11 = α1
11
q = −
qj
α0
1
j
= −
= −,
α0
pj
α0
21
3
α0
0
1
1
qj
α31
1
α0 α0
3 1
2
α31 = αqj = −
= −
= −α0
21
31 = 1
=
,
α0
·
α0
21
3
31 −
α0
pj
21
−
3
3
α0
0
1
1
−
plα0
0
0
qj
α
α
1 1
2
α12 = α
0
ql = αq
= α
α0
12
pj
−
22
11
l
= 1
=
α0
·
,
21
−
3
3
α0
0
0
α1
qj
= α1 = α0 −
plα0
= α0
α
1 1
32
ql
ql
32 −
22α31
8
= 3
=
0
·
α0
pj
α21
−
.
3
3
β0
0
0
0
1
1
0 −
pαqj
0
β2α
80
β1 = βq = βq
= β
α0
1
pj
−
11 = 80
· 1 = 20,
α0
21
−
3
β0
0
β1
p
=
1
β
2
βp =
2
180
=
=
= 60,
α0
pj
α0
21
3
β0
1
1
pα0
0
qj
0
β0α0
180 1
β3 = βq = β
31
q
= β
2
0
3
= 180
0
·
−
αpj
−
α21
−
= 120.
3
γ0
1
j
γ0
5
5
γ1 = γ1
−
=
α0
pj
−
1
j =
=
α0
−
21
−
=
,
3
3
γ0α0
0
0
γ1 = γ1
γ
=
−
−
pl
=
0
j
2
l
γ
γ0
5
2 −
1α22
l
· 1
7
= −4 −
=
,
α0
pj
α0
21
3
−3
1
β0
0
2γ0
d = d −
1
180
= 0
α0
· (−5)
21
−
=
3
−300.

Simplex Method
91
y4
y2
-1
1
- 3
1
3
1
- 3
2
3
1
3
8
3
20
60
120
=
=
=
-y3
1
-y
-y5
5
3
7
- 3
300
= ω
τ1
=
Now the solution y1 = (60, 0, 20, 0, 120), which correspond to value of
goal function γT x1 = −300. Tests in steps 1 and 2 are not allowed. Now
j = 2 and
β1/α1 = 30, β1/α1
1
1
12
2
22 = 180, β3/α1
32 = 45,
and it is valid p = 1. The following change should be made y2 ↔y3. From
AlgorithmReplace we have the next transformations and the corresponding
table τ2:
α2
12 = α2
pj = 1,
α1
1
α2
pl
=
2
α
11
αpl =
=
11
1
=
,
α1
1
pj
α12
−2
α1
α2
22 = α2
qj
α1
22
1
qj = −
=
,
1
pj
−
=
α
α1
12
−2
α1
1
2
2
−
qj
α
α32 = αqj =
=
α1
pj
−
32 =
4,
α1
12
−
α1
plα1
1
qj
α1 α
7
α2
21 = α2
ql = α1 −
= α1
α
21
pj
−
11
22
ql
=
,
1
α1
12
6
α1
plα1
2
31 = α2
ql = α1
α
ql −
qj
α1
1
α
= α1
11
α1
31
pj
−
32 = 1.
α1
12
β1
β2
1
β2
p
β1
p =
1
20
=
=
=
= 30,
α1
pj
α1
12
2/3
β1α1
1
1
β2 = β2
p
qj
β α
20 1/3
2
q = β1
1
q −
= β1
22 = 60
·
= 50,
α1
2
α1
pj
−
12
−
2/3

92
Advances in Optimization and Linear Programming
β1
1
1
β2 = β2
pα1
= β1 −
qj = β1
β
−
1α32
20 8/3
3
q
q
3
= 120
·
α1
pj
α1
12
−
= 40.
2/3
γ1
γ2 = γ2
j
γ1
2
7
2
j = −
= −
=
,
α1
1
pj
α11
2
γ1α1
1
1
2
2
1
j
pl
α
=
1
γ
5
7/3
γ
γ = γl
= γ
2
11
1
l
=
1
1
1
−
· (−1/3)
1
−αpj
−
α12
3 −
=
,
2/3
2
1
1
d2
γ
=
1
β
d −
1
2
20 ( 7/3)
= 300
= 370.
α1
· −
12
−
2/3
τ2 =
y4
y3
-1
1
- 2
1
2
3
2
1
- 2
30
50
=
=
y2
-
-y1
1
-4
40
= -y5
1
2
7
2
370
= ω
The base admissible solution is y2 = (50, 30, 0, 0, 40), and the objective
function takes the value γT x2 = −370. As the test in Step 1 is satisﬁed, this
is a y2 optimal solution, a the value of the objective function is ω = −370.
Note that each simplex table corresponds to one extreme point
together ΓP , so that the simplex method represents a “walk” in the
dark. Since dk+1 < dk, that no peak can be to repeat. Since the
number of vertices is ﬁnite, it follows that there are ﬁnitely many
iterations that come either to the optimal solution or to the conclusion
that the target function is not restricted from below.
Remark 2.4.2. More than one value of p can occur for which the
fragment
βk
p
αk
is the smallest. Then arbitrarily, p can be selected. In
pj
the following chapters, we will say more about this.
Theorem 2.4.2. If γk
1, . . . , γk
n ≤0 the target function has the ex-
tremum at the point yN,i = 0, i = 1, . . . , n.

Simplex Method
93
Proof. Suppose yN,1, . . . , yN,n arbitrary nonnegative numbers. Then
it works:
n
ω(y) =
X
γky
k
i
N,i
i=1
−d ≤−dk
because γk
i yN,i ≤0 for each i = 1, . . . , n. Equality applies if and only
if yN,i = 0, i = 1, . . . , N.
Theorem 2.4.3. Make it for someone j ∈{1, . . . , n} γk
k
j > 0 i αij ≤0
for each i = 1, . . . , m, then the objective function is unlimited.
Proof. If αk
ij ≤0 for each i = 1, . . . , m, considering restrictions
αk x
+ · · · + αk x
+ · · · + αk
k
i1
N,1
ij
N,j
inxN,N −βi = −yB,i, ß = 1, . . . , m,
the variable yN,j can be increased indeﬁnitely without any the depen-
dent variable yB,and is not negative. Since γk
j > 0, so with increasing
the variable yj also increases the value of the target function. This
means that the target function is unlimited.
In the general case, γk
k
j > 0 for some j and αij > 0 for some i. We
will show that the table (2.4.1) can be transformed into an equivalent,
with one independent and dependent variable swapping places. Let’s
choose p so that:
βk
p
βk
= min
i αk
αk
ij > 0
.
(2.4.0.13)
1
pj
≤i≤
(
k
m
αij
|
)
We can replace the variable yN,j from the equation:

94
Advances in Optimization and Linear Programming
yB,p = βk
p −(αk
p1xN,1 + · · · + αk
pjxN,j + · · · + αk
pnxN,n)
and replace it in all other equations and in the function of the goal. In
this way we get a system equivalent to the system (2.4.0.2) now yB,p
independent a yN,j dependent variable. They still are the free terms
βi in all equations are positive as γk
j becomes not positive. The proof
of this assertion (the following theorem) as well as the algorithm for
the transformation of the system of equations (2.4.0.2) (to replace the
variables yB,p and yN,j) will be shown below. We now apply the same
procedure as long as one of the numbers γj is positive. When all γk
j
is positive, an admissible solution is obtained yN,1 = · · · = yN,n = 0
is optimal, i.e., the objective function reaches the extremum.
Theorem 2.4.4. If βk
1, . . . , βk
m ≥0 and if index p selected according
to the criterion (3.3.15) and γk
j > 0, then and after the change of place
y
and y
variables βk+1
k
B,p
N,j
1
, . . . , β +1
n
≥0. It is also i γk+1
j
< 0.
Proof. According to the variable replacement algorithm yB,p i yN,j
after the transformation is:
αk bk
αk
k+1
pj q
qjbk
p
βq
=
−
.
αk
pj
If αk
qj ≥0, considering
βk
p
αk
pj ≤βk
q
αk we get:
qj
αk bk −αk βk
αk bk −αk bk
q
βk+1
pj q
qj
p
pj
q
αk
≥
q
pj
=
= 0.
pj
αk
pj
Now suppose it is αk
qj < 0. Considering −αk
qjbk
p
αk
> 0, we get:
pj

Simplex Method
95
αk
k
k
pjbq
αqjbk
p
βk+1
q
=
−
> βk
αk
q > 0.
pj
After the shift, we get it:
γk
γk+1
j
= −
j < 0,
αk
pj
by which the theorem is proved.
Element αpj we will call the pivot element a the replacement of
the variables yB,p and yN,j we will call it replacement by the key
element αk
pj.
Example 2.4.2. Solve the following linear problem:
max
Λ = 7y1 + 5y2
subj.
2y1 + 3y2 + y3 = 19
2y1 + y2 + y4 = 13
3y2 + y5 = 15
3y1 + y6 = 18.
Solution. The rank of the system matrix and the expanded matrix is 4.
This means that we can take 4 variables for bases (for example y3, y4, y5,
y6), and two variables (y1, y2) for independent (free).
y3 = 19 −2y1 −3y2
y4 = 13 −2y1 −y2
y5 = 15 −3y2
y6 = 18 −3y1
In addition, we conclude on the basis of the objective function:

96
Advances in Optimization and Linear Programming
Λ −7y1 −5y2 = 0.
The latter are negative coeﬃcients –7 and –5. Take the smallest negative
coeﬃcient, –7. Then in the column for y1 we notice three positive elements:
2,2,3. Let’s share these numbers are correspondingly free members. The
minimum of these ratios is:
19 13 18
18
min
,
,
2
2
3

=
.
3
The intersection of type for y6 and columns for y1 is number 3. So, the
variables y1 and y6 swap roles. The new base is y3, y4, y5, y1, while the
independent variables are y2, y6. In order to get 1 at the intersection point,
we divide the observed species by 3. The rest we add to the species a
split type, previously multiplied by the number such that u the column
corresponding to y2, below and above the leading element, we get zeros.
The same procedure is continued in the new table. The last one is
negative coeﬃcient –5. In the column for y2 we notice two positive elements:
3,1,3. We divide by these numbers the corresponding free members. The
minimum of these ratios is:
min
7 1 15
,
,
3 1
3

1
=
.
1
In the intersection of type for y4 and columns for y2 is number 1. Now
the variables y2 and y4 swap roles. They make a new base y3, y2, y5, y1,
while the independent variables are y4, y6. To the other species, we add
another species, previously multiplied by the number such that u column
y2 below and above the leading element, we get zeros.
The procedure is repeated in the last table.
min
 4
12
6
,
,
4/3
2
1/3

4
= 4/3

Simplex Method
97
Now the variables y6 and y3 are swapping roles. They make a new base
y6, y2, y5, y1, while the independent variables are y3, y4.
The new species for Λ has no negative coeﬃcients. The maximum target
value of function is Λmax =50, and is obtained for base {5, 3, 0, 0, 6, 3}.
Remark 2.4.3. If there are more than one equals in an iteration of
the minimum quantities βi/αip, it is necessary to choose the type for
which is the ratio of the elements of the next column to those of the
column that we use the smallest to solve. This process is repeated until
we arrive to the single-digit minimum element βj/αjp.
The simplex model of a linear programming type of maximum
type is a system of non-equilibrium forms:
α11y1 + α12y2 + · · · + α1mym
≤
β1
α21y2 + α22y2 + · · · + α2mym
≤
β2
. . .
αn1y1 + αn2y2 + · · · + αnmym
≤
βn
We translate this system of inequalities into a system of equations,
by introducing additional pro’s, as follows:
α11y1 + α12y2 + · · · + α1mym + ym+1
=
β1
α21y2 + α22y2 + · · · + α2mym + ym+2
=
β2
. . .
αn1y1 + αn2y2 + · · · + αnmym + ym+n
=
βn
The criteria function takes the form:

98
Advances in Optimization and Linear Programming
X
n
G(y) =
cjxj + 0 · (γn+1yn+1 +
j=1
· · · + γn+myn+m) .
Based on this model, we set a zero simplex table of forms:
max ST - 0
where: C – coeﬃcient vector γi with the variables yi of the criterion
function, i = 1, . . . , n; γβ – vector of coeﬃcients as a function of the
criteria with variables that make up the basic admissible solution. At
max ST - 0, the value of these coeﬃcients is 0; yβ – vector of variables
of the basic admissible solution; B – the vector of the values of the
variables of the base allowable solution for the observed ite ra ci ju;
yj – base vector multipliers; Gj −γj – optimality criterion. Based on
this criterion, it is decided whether a solution was obtained maximum.
The solution is maximum if the condition is fulﬁlled.
(∀j)Gj −γj ≥0.
In case the solution is not optimal, this criterion determines the
vector that enters the base, which is a vector yj that satisﬁes the
condition:
min
j
{Gj −γj|Gj −γj < 0} .
On the other hand, on the basis of the “theta” criterion, it is
determined which vector exits the base, i.e.:
βi
βp
θ = min

,
αk
i
α
ij > 0
ij

=
.
αpj

Simplex Method
99
Procedure for Finding the Optimal Solution by Simplex
Method
The general problem of linear programming is considered. Need
to ﬁnd the negative values of the variables y1, . . . , yk that will ﬁll a
restriction system given by linear inequalities and equations 1.5.0. 1,
and provide the maximum value of the criterion function:
k
ω0 =
X
γjyj.
j=1
We solve the linear programming problem, thus formulated the
simplex method according to the following procedure:
1) We translate all inequalities of systems into equations. If it is
an unequal of type “≤,” then we add the corresponding one variable; if
the inequality is of type “≥” then we subtract the corresponding oﬀset
variable from the left foreign inequalities. With leveling variables in
the function, the criteria are always zero.
News variables are added to all equations and unequal “type” ≥.
With these variables in function criteria, we put the coeﬃcients M.
2) From the coeﬃcients of the custom model, we compile the ini-
tial simplex table. The vector space for the initial solution is made up
of unit vectors. These are the vectors that correspond to the “added”
variable (add the equalization and all expert).
3) We calculate coeﬃcients for an additional row of simplex tables
Gj −γj for every j. The simplex table contains the initial solution.
4) Let’s check the order coeﬃcients (Gj −γj):
If Gj −γj ≥0 for every j, then we claim that the optimal solution
is found.

100
Advances in Optimization and Linear Programming
If there is Gj −γj < 0, then we choose:
Gs −γs =

min(Gj
j
−γj)

< 0.
The coeﬃcient (Gs −γs) corresponds to the vector αs, so we
determine that the vector αs enters the new vector base.
5) Vector coordinates B we divide by the corresponding positive
coordinates of the vector αs and determine
βr
βi
θ =
= min
(αis > 0).
α
i
rs
αis
The smallest value of these ratios corresponds to vector αr, so we
determine that the vector αr should come out of the initial base.
6) We calculate the coeﬃcients for the new simplex table at the
coeﬃcients from the initial simplex table according to the transfor-
mation rules described.
7) We return to point 4) of this procedure. Each the next iteration
begins with step 4) and repeats the procedure until 7) until all the
diﬀerences are found in 4) Gj −γj ≥0. Then the process ends, the
optimal solution to the linear problem is found.
Example 2.4.3. Solve the system of inequalities by applying the simplex
method if the following criteria and constraints are given:
max
G(y) = 10y1 + 12y2 + 10y3
subj.
4y1 + 5y2 + 4y3 ≤4200
2y1 = 2y2 + y3 ≤1500
2y1 + 3y2 + 4y3 ≤2400

Simplex Method
101
Based on this model, we will form a starting simplex table, max ST-0.
max
G(y) = 10y1 + 12y2 + 10y3
subj.
4y1 + 5y2 + 4y3 + y4 = 4200
2y1 + 2y2 + y3 + y5 = 1500
2y1 + 3y2 + 4y3 + y6 = 2400
This table contains the optimal solution, which is:
y∗
τ
= [0, 720, 60, 360, 0, 0] ,
G(y∗) = Gmax = 9240.
2.5
Determination of the Initial Basic Permissible
Solution
The implementation of the SimplexStandardMax algorithm im-
plies that one is known basic permissible solution. This is fulﬁlled if
they are all restrictions of type ≤and if βi ≥0, i = 1, . . . , m, or
if all constraints of type ≥and if βi ≥is, i = 1, . . . , m. By adding
leveling variables, we immediately form the base permissible solution.
However, in the general case, the underlying permissible solution is
unknown. We prove the theorem on a basis for determining the basic
admissible solution if the set of permissible solutions to the linear
programming problem is blank.
The algorithm has been described so far (the SimplexStandard-
Max/Simp leks Ba sic Min algorithm) to ﬁnd the optimal solution,
if any, when in the basic form tasks it looks for the maximum/min-
imum of the objective function and when they are initial maximiza-

102
Advances in Optimization and Linear Programming
tion/minimization tables are basically permissible. What to do if the
basic linear programming task table starts not basic permissible? Be-
fore we can apply the simplex method, the algorithm must ﬁrst be
transformed into a maximization table with a basic allowable solu-
tion. That’s how it is described; the algorithm must ﬁrst introduce the
steps of such a transformation. Consider a simplex algorithm ﬁnally
for the maximization table in the general case.
Deﬁnition 2.5.1. The basic task of linear programming with maxi-
mization is unacceptable if there is no acceptable solution.
Theorem 2.5.1. If αk
i1, . . . , αk
in ≥0 i βk
i < 0 then the and equations
in the system (2.3.2) have no solution, i.e., the system is intolerable.
Proof. With the above assumptions, we get:
−yB,i = αk
i1xN,1 + · · · αk
inxB,N −βk
i ≥−βk
i > 0,
that is, yB,and < 0, which contradicts the starting point assuming
that all variables are nonnegative.
In this section, we will discuss the problem of ﬁnding the ﬁrst basic
permissible solution (canonical form). Most commonly, two types of
methods are used to solve this problem. One group of methods is
called the two-phase simplex method, and the second type is the BigM
methods (BigM methods). Three approaches are described here. The
two approaches are the so-called phase simplex method. One method
requires the introduction of artiﬁcial variables and thus increases the
dimensions of the problem, while the other does not require the use
of artiﬁcial variables. The third method combines these two stages
into one, and is called the BigM method.

Simplex Method
103
2.6
Two-Phase Simplex Methods
The two-phase simplex method consists of two phases, phase I
and phase II. Phase I is trying to ﬁnd someone initial basic feasible
solution. When the initial basic permissible solution is found, then
Phase II is applied to ﬁnd the optimal solution. A simplex method
is an iterative procedure whose each iteration is characterized by
the determination of m basis variables yB,1, . . . , yB,m and n non-base
variables yN,1, . . . , yN,n.
Geometrically, the simplex method moves from one extreme point
(angle) to the set of admissible solutions in the second, while improv-
ing the values of the objective function in each iteration. The two-
phase simplex method goes through two phases, phase I and phase
II. Phase I attempts an extremely extreme point from above. Once
the initial extreme point is found once, phase II is applied to resolve
the original LP.
Example 2.6.1. For
−y1 −y2
2y1 + 3y2 ≤24, 2y1 −y2 ≤8, y1 −2y2 ≤2,
−y1 + 2y2 ≤8, y1 + 3y2 ≥6, 3y1 −y2 ≥3,
0 ≤y1 ≤7, 0 ≤y2 ≤7
Phase I of the simplex algorithm ends at the extreme point indicated by
(a) in the following ﬁgure. Then Phase II follows a sequence of extreme
points marked by arrows along the edges of a set of admissible solutions.
The optimum extreme point is indicated by (d).

104
Advances in Optimization and Linear Programming
If β ≥0 and if all nonbasic variables yN,1, . . . , yN,n are equal to
zero, then yB,1 = β1, . . . , yB,m = βm base admissible solution. If the
condition β ≥0 is not met, it is necessary to ﬁnd an initial basic
admissible solution or to determine that it does not exist. There are
several strategies for Phase I.
2.6.1
A Two-Phase Simplex Method That Uses Artiﬁcial
Variables
The classic approach is to associate a linear program in standard
form the so-called widespread problem [3, 13].
Let the linear programming problem be given in standard form:
γT x,
subj.
Ay = β,
(2.6.1.1)
y ≥0.
J it is only fair that we can assume that u the standard form β ≥0
(otherwise we multiply the corresponding equations by −1). We at-
tach to the problem (2.6.1.1) an auxiliary linear programming prob-
lem:
min
eT w,
subj.
Ay + w = β,
(2.6.1.2)
y ≥0, w ≥0,
where e = (1, . . . , 1) ∈Rm and w ∈Rm is a vector of so-called.
artiﬁcial variables. The important fact is that the set of admissible
solutions to the problem (2.6.1.2) is empty because its gur no belongs

Simplex Method
105
to it point (y = 0, w = β). It is also clear that the target function is
on that set bottom bounded by zero. The permissible base consists of
columns that correspond to the variables w1, . . . , wm, a the canonical
form of the problem (2.6.1.2) is obtained by eliminating w from the
objective function using Eq w = β −Ay. Problems (2.6.1.1) and
(2.6.1.2) are related by the following theorem:
Theorem 2.6.1. The set of admissible solutions to the problem
(2.6.1.1) is non-empty if and only if the optimal value of the objective
function problems (2.6.1.2) equal to zero.
Proof. Let y¯ be a valid solution (2.6.1.1). Then (y¯, 0) is an admissible
solution to the problem (2.6.1.2), with the value of the objective func-
tion is zero. Since zero is the lower bound for the objective function
of the problem (2.6.1.2), it follows that (y¯, 0) is optimal solution and
that zero is the optimal value of the objective function of the prob-
lem. Suppose now that (y¯, w¯) is the optimal solution to the problem
(2.6.1.2) and suppose eτw¯ = 0. From e > 0, w¯ ≥0 follows w¯ = 0,
so we have Ay¯ = β, i.e., y¯ is a permissible solution to the problem
(2.6.1.2).
The previous theorem is based on the so-called two-phase modiﬁ-
cation of simplex methods.
Algorithm 2. (Two-phase modiﬁcation of simplex methods). I Faza:
II Faza:
Step 1. All are removed from the last simplex table non-basic
columns corresponding to artiﬁcial variables, the null type is replaced
by the type [0| γ1 . . . γn 0 . . . 0] which has a n + k + 1 element, with

106
Advances in Optimization and Linear Programming
k being the number of basic news ˇof variables. The resulting LP ta-
ble is reduced to a simplex table by eliminating those γj = 0 that
correspond to the base variables.
Step 2. If k = 0 go to Step 3. If k > 0 there are basic columns in
the simplex table that correspond to artiﬁcial ones variable. Note the
basic column corresponding to the artiﬁcial one variable ws. Let that
column contain a unit of type v. Two cases are possible:
1. All elements of type v except the base unit are zero. Then is
the type v and the column corresponding to the variable ws omitted
from the simplex table. 2. In addition to the basic unit, let r−be an
element of type v diﬀerent from zero. Obviously, r > 0 because it is in
the zero column an artiﬁcial variable ws that equals zero, and that r−
ta the column does not match the artiﬁcial variable because they are
missing all columns corresponding to non-basic variables. Stozernom
by transforming with the pivotal element αvs, make r−tu column
basic and then omit the column corresponding to the variable ws
because this is now a non-base column corresponding to an artiﬁcial
variable. Replace k with k −1 and repeat Step 2.
Step 3. The resulting simplex table contains columns only that cor-
respond to the changes in the problem (2.6.1.1). Apply Algorithm
1.
Note that Algorithm 2 obviously ends in a ﬁnite number of steps.
An example to illustrate Algorithm 2 is taken from [13].
̸

Simplex Method
107
Example 2.6.2. Determine the solution to the following problem:
min
y1 −y2 + y3,
subj.
y1 + y2 + 2y3 + y4 = 3,
−y2 −y3 + y4 = 3,
y1 −y2 + 3y4 = 9,
y ≥0.
As the basic admissible solution is not known, we will apply a two-phase
modiﬁcation of the simplex algorithm. I Phase.
An associated problem is:
min
w1 + w2 + w3,
y1
+y2
+2y3
+y4
+w1
=
3,
subj.
−y2
−y3
+y4
+w2
=
3,
y1
−y2
+3y4
+w3
=
9,
y ≥0,
w ≥0,
and is matched by the following LP table:
0
0
0
0
0
1
1
1
3
1
1
2
1
1
0
0
3
0
−1
−1
1
0
1
0
9
1
−1
0
3
0
0
1
hence by eliminating units from zero species (by subtracting all other types
of zero) gets a simplex table (below are pivot elements framed):
−15
−2
1
−1
−5
0
0
0
3
1
1
2
1
1
0
0
3
0
−1
−1
1
0
1
0
9
1
−1
0
3
0
0
1

108
Advances in Optimization and Linear Programming
Using a simplex algorithm we get a new simplex table:
−9
0
3
3
−3
−2
0
0
3
1
1
2
1
1
0
0
3
0
−1
−1
1
0
1
0
6
0
−2
−2
2
−1
0
1
As there are negative elements in the zero column, again we apply a
simplex algorithm:
0
0
0
0
0
1/2
0
3/2
0
1
2
3
0
2
0
−1/2
0
0
0
0
0
−1/2
1
−1/2
3
0
−1
−1
1
−1/2
0
1/2
As the optimal value of the auxiliary problem min eT w = 0, we move
on to the second stage.
Phase II. By removing the non-base columns that correspond artiﬁcial vari-
ables (ﬁfth and seventh) and coeﬃcient replacement zero-type LP table is
given by the corresponding coeﬃcients of the starting problem:
0
1
−1
1
0
0
0
1
2
3
0
0
0
0
0
0
0
1
3
0
−1
−1
1
0
where, after eliminating the unit in the zero row of the ﬁrst column, gets a
simplex table:
0
0
−3
−2
0
0
0
1
2
3
0
0
0
0
0
0
0
1
3
0
−1
−1
1
0

Simplex Method
109
Now we eliminate the second type because it contains all the elements
(except coeﬃcient corresponding to an artiﬁcial variable) equal to zero and
we eliminate the ﬁfth column because all elements are zero. We get a simplex
table from which all artiﬁcials are eliminated variables:
0
0
−3
−2
0
0
1
2
3
0
3
0
−1
−1
1
Now all the requirements for Algorithm 1 are fulﬁlled. The next step is
to obtain the optimal solution:
0
3/2
0
5/2
0
0
1/2
1
3/2
0
3
1/2
0
1/2
1
Another variant of the two-phase simplex method is described in
[40] and [55]. This algorithm has the advantage in relation to the
extended problem because it does not use artiﬁcial variables.
2.6.2
Two-Phase Simplex Method Without Artiﬁcial
Variables
We will now present one version of the algorithm for determining
the initial one a basic admissible solution that does not require the
introduction of artiﬁcial variables. The main disadvantage of the pre-
vious method is the increase in the dimension of the linear problem.
We consider the standard form of linear programming problem with-
out restrictions on the sign of the coeﬃcients βi in which the base
is an unknown permissible solution. The existence of a permissible
solution follows from the following lemma:

110
Advances in Optimization and Linear Programming
Lemma 2.6.1. Let βi = αi0 be a coeﬃcient for some and. If αij ≥
0, j = 1, . . . , n, then the set of admissible solutions is empty.
Proof. Given the conditions in the lemma, in the set of restriction,
there is an equation in which the sum of the products is negative
colors a negative number, which is impossible.
Let the set of solutions be linear programming is permissible and
let y be a basic impermissible solution with q negative coordinates.
Let (new numbering if necessary) achieved y = (y1, . . . , ym, 0, . . . , 0)
basic inadmissible solution such that y1, . . . , yq < 0, q ≤m, and
yp ≥0 for p > q. The corresponding base is K1, . . . , Km.
If q = m, is selected for the element αms < 0 (such exists by
Lemma (2.6.1) and by applying a simplex transformation we imme-
diately get a new solution in which at least one coordinate is positive.
If q < m, we consider αrs < 0 for r = 1, . . . , q (exist by Lemma(2.6.1).
If exists r ∈{1, . . . , q} i s ∈{1, . . . , n} such that:
 yh

yr
min
α
αhs
|
hs > 0
h>q
≥
,
(2.6.2. 1)
αrs
we choose αrs for the element. Then it is:
1
X 
y

y
−
r
r
y =
yj
αjs
Kj +
Ks.
αrs
αrs
j=r
y
For j > q i αjs < 0 it is valid
r
yj −
αjs
.
αr
≥0 For αjs
s
≥0 and
j > q is:
yj
y
αjs
≥
r
y
αjs
αrs
⇔yj −
r αjs
0
αrs
≥
̸

Simplex Method
111
y
and since
r > 0, it is obvious that y1 has at most q −1 negative
αrs
coordinates.
If there is no r such that the condition (2.6.2. 1) is satisﬁed, let
them be now r ∈/ {1, . . . , q} and s ∈{1, . . . , n} such that:
min
h>q
 yh
y
αhs
| αhs > 0

r
=
.
(2.6.2. 2)
αrs
For such r and s, we set αrs for the pivot element. Using a simplex
transformation, we get a new solution y1 in which we prove analogous
to the former that the coordinates y1
q+1, . . . , y1
m remain nonnegative.
As the set of basic solutions is ﬁnite, (applying anti-cycling rules if
necessary), after many transformations the condition (2.6.2. 1) will
be fulﬁlled. Based on these considerations, the following algorithm is
ﬁnite. Algorithm 3.
(Solving linear programming problems without introducing artiﬁcial
variables).
Step 1. We form an initial LP form table:
−d
γ1
· · ·
γn
β1
α11
· · ·
α1n
.
.
.
.
.
.
.
.
.
βm
αm1
· · ·
αmn
If βi ≥is0, i = 1, . . . , m, then we apply Algorithm 1.
Step 2. Let βi1, . . . , βiq < 0. If αij ≥0 for some i ∈{i1, . . . , iq}
i each j = 1, . . . , n, algorithm stops because the set of constraints is
unacceptable. Otherwise, we continue.
Step 3. If q = m we choose αms < 0 for the element.

112
Advances in Optimization and Linear Programming
If q < m and if there are r ∈{i1, . . . , iq} = I and s such that
condition fulﬁlled.
min
h∈/I
 βh |
r
αhs > 0

β
≥
,
αrs < 0,
αhs
αrs
we choose αrs for the element.
If there is no r such that the previous condition is satisﬁed, let is
now r such that:
βh
βr
min
αhs > 0
=
.
h∈/I

αhs
|

αrs
For such r and s we set αrs for the parent element. Step 4. Apply
transform and go to Step 1.
Example 2.6.3. Let it be the initial LP chart
720
7
0
0
5
0
−100
−2
0
1
−1
0
−360
−8
0
0
−3
1
180
3
1
0
1
0
Since there are negative coeﬃcients in the zero column, we apply Algo-
rithm 3. The condition (2.6.2. 1) is satisﬁed in the ﬁrst column (the pivot
elements are framed), and by applying the simplex transformation, we ob-
tain:
405
0
0
0
11/8
7/8
−10
0
0
1
−1/4
−1/4
45
1
0
0
3/8
−1/8
45
0
1
0
−1/8
3/8

Simplex Method
113
In the next step, we again apply Algorithm 3, because α01 < 0, i we
immediately get the optimal solution:
370
0
0
3/2
1/2
0
40
0
0
−4
1
1
50
1
0
−1/2
1/2
0
30
0
1
3/2
−1/2
0
We have proved that if ΓP = ∅is then basic permissible solution.
The condition for the existence of an optimal basic admissible solution
is the following lemma.
Lemma 2.6.2. If the admissible set of problems (1.5.0.4) is empty
and if the target function on it is bounded from below, then the problem
(1.5.0.4) has a basic admissible optimal solution.
Proof. How the target function of the problem (1.5.0. 4) is limited
from below, the application of the simplex algorithm to the initial
base admissible the solution ends after a lot of steps and that basic
permissible optimal solutions.
A direct consequence of Lemma 2.6.2 is that the existence of an
optimal solution withdraws the existence of a basic permissible opti-
mal solution.
The SimplMax/SimplMin algorithm.
Simplex method algorithm forms maximization/minimization ta-
bles, which are not basically permissible. The current table is in the
form (2.3.4)
Step 1. If βk
1, βk
2, . . . , βk
m ≥0, we move on to Step 5.
Otherwise, we continue.
Step 2. We choose βk
i < 0 (For example, the last one). Step 3. If
̸

114
Advances in Optimization and Linear Programming
αk
i1, αk
i2, . . . , αk
in ≥0, STOP: the maximization task is unacceptable.
(We will discuss this case in more detail later).
Otherwise, we continue.
Step 4. If i = m, we choose αk
mj < 0, we take the key element αk
mj
and we go to Step 1. If i < m, we choose αk
ij < 0 and we calculate:
 (
βk ) [ (
βk
βk
p
min
i
l ; αk
k
k
lj > 0
l>i
αij
)!
=
α
αk
lj
pj
so we choose αk
pj as the key element (which corresponds to the sub-
stitution of the base element variables yB,p and non-base variables
yN,j). Go to Step 1.
Step 5. Apply a simplex algorithm for base admissible max-
imization (mini mi za ci onu) table (algorithm SimplexStandard-
Max/SimplexStandardMin).
Remark 2.6.1. As in algorithm SimplexStandardMax can be more
than one value for
βk
p for which
p
αk
is at least. P can be arbitrarily
pj
selected.
Implementation of a simplex algorithm that does not use artiﬁcial
variables by means of functionalities in MATHEMATICA is described in
the [49] monograph.
Example 2.6.4. This example illustrates a general simplex algorithm (the
SimplexMax algorithm) on a maximization table
y1
y2
-1
-1
-2
-3
= -t1
1
1
3
= -t2
1
1
2
= -t3
-2
4
0
= ω

Simplex Method
115
Solution:
(1) The initial table is obviously a maximization table.
(2) We move on to step (2) because β1 = −3 is negative.
(3) We choose β1 = −3.
(4) We proceed to step (4), since both coeﬃcients α11 = −1 and α12 =
−2 are negative.
(5) We can choose α11 = −1 or α12 = −2. For the sake of determination
we choose α11 = −1. How 1 = and < m = 3 is calculated
min
 β1 = −3
α11
−1
 [  β2
3
β3
2
=
,
=
α21
1 α31
1

β3
= α31
We take the key element α31:
y1
y2
-1
-1
1∗
-2
1
-3
3
=
=
-t1
-t2
1
1
2
= -t3
-2
4
0
= ω
t3
y2
-1
-1
-1
-1
= -t1
-1
0
1
= -t2
1
1
2
= -y1
2
6
4
= ω
⇒
We proceed to step (1).
(1) Apparently!
(2) We move on to step (2) because β2 = −1 is negative.
(3) We have to choose β2 = −1.
(4) We proceed to step (4), because α12 = −1 is negative.
(5) We have to choose α12 = −1. As 1 = and < m = 3, we calculate
min
 β1
3
= −1
[
β
2
β1
=
α12
−1


=
α32
1

α12

116
Advances in Optimization and Linear Programming
The key is α12:
t3
y2
-1
-1
-1
-1
= -t1
-1
0
1
= -t2
1
1
2
= -y1
2
6
4
= ω
⇒
t3
t1
-1
-1
-1
1
= -y2
-1
0
1
= -t2
2
1
1
= -y1
8
6
-2
= ω
We proceed to step (1).
(1) Apparently!
(2) β1, β2, β3 ≥0, that is, the table is maximally permissible. We proceed
to step (5).
(5) Apply a simplex algorithm for maximization tables with basic per-
missible solutions (let’s leave the reader alone complete the task).
2.7
BigM Method
By combining Phase I and Phase II, an algorithm is obtained
that can be solved; there is a very linear programming problem. Fi-
nally, note that the essence of the idea of a two-phase modiﬁcation of
the simplex method is as follows: limitations of the starting problem
(2.5.1) by introducing artiﬁcial ones of the variables w1, . . . , wm to
the base admissible solutions while observing the extended objective
function.

Simplex Method
117
ωw = γT x + Mw1 + · · · + Mwm,
where M is an arbitrarily large coeﬃcient. As long as the artiﬁcial
variables occur in a basic admissible solution, the optimal solution
was not found due to the pro is validity of the coeﬃcient M. So
the goal is to use simplex methods to make all artiﬁcial variables are
eliminated from the basis of the admissible solution and thus equated
with zero. When a basic admissible, non-artiﬁcial solution is formed
variables, we no longer need them because they are in a reduced
problem the, requirements for the implementation of Algorithm 1 are
fulﬁlled. The meaning of introducing artiﬁcial variables is only to
channel the order of performing elementary transformations.
In one embodiment of this method, [13], an auxiliary problem is
formed at as follows:
min
γT x + MeT w,
subj.
Ay + w = β,
(2.7.0.1)
y ≥0, w ≥0,
where M is a suﬃciently large constant. The initial basic solution
to this problem is (0, β). If, applying the simplex method gives the
optimal solution for which some of the variables wi is a basic starting
problem is inadmissible (due to the arbitrariness of the constant M).
Otherwise, the solution obtained is optimal for the starting problem.
Due to the constant M, this method is often referred to as the BigM
method. The main disadvantage of this method is the increase in the
dimension of the problem and the uncertainty about the choice of the
constant M.

118
Advances in Optimization and Linear Programming
Example 2.7.1. Now let’s consider a problem that requires a minimum
value criteria functions using BigM methods:
min
160y1 + 100y2+120y3,
subj.
2y1 + y2 + 2y3 ≥350,
y1 + y2 + y3 ≥300,
(2.7.0.2)
4y1 + y2 + 2y3 ≥400,
y1 ≥0 y2 ≥0 &y3 ≥0.
By introducing equalization variables, we will (2.7.0.2) express in the
form of equations. Since the left side is inequality of this system larger than
the right, we subtract the leveling variables and we get the following system
of equations:
2y1 + y2 + 2y3 −y4
= 350
y1 + y2 + y3
−y5
= 300
(2.7.0.3)
4y1 + y2 + 2y3
−y6
= 400.
The coeﬃcients with the smoothing variables are negative. It means
that we cannot determine the initial nonnegative solution in the ﬁrst sim-
plex table. Therefore, we introduce new variables into the model, the so-
called artiﬁcial variables. These variables do not belong to the system re-
strictions and have no speciﬁc economic signiﬁcance, except that serve as a
calculating tool. In the process of problem-solving are eliminated from the
solution so that they are not in the optimal solution; no artiﬁcial variable
can occur. If a non-nonnegative problem solution contains at least one pos-
itive artiﬁcial variable (which cannot be released), then there is no possible
solution to the problem.
So that artiﬁcial variables do not appear in the optimum solution, we
introduce coeﬃcients in the function of criteria with these variables marked

Simplex Method
119
with M, where M is a relatively large positive number. 1 So, after expanding
the problem with artiﬁcial variables, we got the following model:
(min); ω0 = 160y1 +100y2 +120y3 +0y4 +0y5 ++0y6 +Mx7 +Mx8 +Mx9
2y1 + y2 + 2y3 −y4
+ y7
= 350
y1 + y2 + y3
−y5
+ y8
= 300
4y1 + y2 + 2y3
−y6
+ y9
= 400
in which all variables must be nonnegative, the initial simplex table can be
ﬁlled in, and the initial basic solution can be determined. It will be made
up of artiﬁcial variables.
160
100
120
0
0
0
M
M
M
C
B
y0
y1
y2
y3
y4
y5
y6
y7
y8
y9
M
y7
350
2
1
2
−1
0
0
1
0
0
M
y8
300
1
1
1
0
−1
0
0
1
0
M
y9
400
4
1
2
0
0
−1
0
0
1
→
ωj −γj
0
−160
−100
−120
0
0
0
0
0
0
1050
7
3
5
−1
−1
−1
0
0
0
↑
Table 2.7.1.
The simplex of the tables is ﬁlled in as usual. Only are the coeﬃcients
in row (ωj −γj) divided into two parts. In the ﬁrst part of the row are
entered the coeﬃcients with which M does not occur, and in the second
part, the coeﬃcients with which M occurs. So, for example, is the coeﬃcient
(ω1−γ1) = 7M-160. It is obtained by multiplying column C, and column y1,
the products are collected, and the coeﬃcient from the header is subtracted.
The coeﬃcients for the other columns were determined in the same way.
1When looking for the maximum value of the criterion function, in addition
to artiﬁcial pro me neer we introduce the coeﬃcient −M.

120
Advances in Optimization and Linear Programming
The division of coeﬃcients from the order (ωj −γj) into two parts is done
only for practical reasons. As M is a very large number, it will, as long
as are artiﬁcial variables in the solution, the second part of the order is
determined which variable enters the next solution.
Did the ﬁrst simplex table ﬁnd the optimal solution and, if not, which
variable should you choose to enter into the next solution? The answer is
quite obvious here: the initial solution cannot be optimal. As long as there
are positives in row (ωj −γj) coeﬃcients (and we look for the minimum
value of the function), not found the optimal solution. Let’s add a second
criterion to this: next, the solution should be entered by the variable to
which in the simplex table corresponds to the highest (positive) value of
the coeﬃcient in the order (ωj −γj).
Let’s go back to the ﬁrst table and ﬁnd that the optimal solution was
not found, and that the variable y1 should enter into the next solution.
Based on the quotient between column y0 and column y1, from solution
output variable y9. The ﬁrst simplex table is marked with a column y1,
the third row in which the variable is y9 and is rounded oﬀcharacteristic
coeﬃcient. Based on the ﬁrst simplex so prepared tables, we get another
simplex table.
The basic solution in the second table is made up of variables:
y1 = 100
y7 = 150
y8 = 200
and the value of the criterion function is ω0 = 16000+ 350M. No optimal
solution found. The next solution is yes, the variable y3 will enter, and the
variable will come out of the solution y7. Therefore, in the second table, we
marked the column y3, the ﬁrst row in which the variable is y7, and you
round oﬀthe characteristic coeﬃcient.

Simplex Method
121
160
100
120
0
0
0
M
M
M
C
B
y0
y1
y2
y3
y4
y5
y6
y7
y8
y9
M
y7
150
0
1/2
1
−1
0
1/2
1
0
−1/2 →
M
y8
200
0
3/4
1/2
0
−1
1/4
0
1
−1/4
160
y1
100
1
1/4
1/2
0
0
−1/4
0
0
1/4
ωj −γj
16000
0
−60
−40
0
0
−40
0
0
40
350
0
5/4
3/2
−1
−1
3/4
0
0
−7/4
↑
Table 2.7.2.
We compile a third simplex table.
160
100
120
0
0
0
M
M
M
C
B
y0
y1
y2
y3
y4
y5
y6
y7
y8
y9
120
y3
150
0
1/2
1
−
1
0
1/2
1
0
−1/2
M
y8
125
0
1/2
0
1/2 −1
0 −1/2
1
0 →
160
y1
25
1
0
0
1/2
0 −1/2 −1/2
0
1/2
ωj −γj
22000
0
−40
0
−40
0 −20
40
0
20
125
0
1/2
0
1/2 −1
0 −3/2
0
−
1
↑
Table 2.7.3.
Even the third simplex table was not found the solution optimally.
There is another artiﬁcial variable in the solution (y8 = 125), and there are
positives in the second part of row (ωj −γj) coeﬃcients. It is necessary to
determine which variable enters the next solution. We see that in the third
simplex table, two variables (y2 and y4) equal competition to enter the
next solution because they have completed the same coeﬃcients. According
to the supplementary criterion, the advantage will be to get the variable
that (if selected to enter the solution) gets more value. So let’s ﬁrst divide
column y0 by column y2 and we determine that the variable y2, if it enters

122
Advances in Optimization and Linear Programming
the next word šhading, get value 250; then divide column y0 by column y4
we determine that the variable y4, if it does, will get 50.
Therefore, the next solution enters a variable that receives a higher
value, i.e., variable y2. In the third table, we marked the column y2, then the
second row (because the variable y8 comes out of the solution) and rounded
oﬀthe characteristic coeﬃcient. We compile a fourth simplex table.
C
B
y0
160
100
120
0
0
0
M
M
M
y1
y2
y3
y4
y5
y6
y7
y8
y9
120
100
y3
y2
25
250
0
0
0
1
1
0
−3/2
1
1
−2
1/2
0
3/2
−
1
−1
2
−1/2
0
160
y1
25
1
0
0
1/2
0
−1/2
−1/2
0
1/2
ωj −γj
32000
0
0
0
0
−80
−20
0
80
20
0
0
0
0
0
0
0
−
1
−1
−
1
Table 2.7.4.
The fourth simplex table has no major variables in the solution. This
can be concluded by column B, but also by the second part of row (ωj −γj).
Because they are artiﬁcial variables solution in this part of row (ωj −γj)
below all columns are zero except below the columns of artiﬁcial variables
where the units with minus sign are.
The problem can still be solved without the corresponding columns ve
sta ck variables (these variables once exited solutions, they can no longer
return to it) and without another part of the order (ωj −γj). These columns
can be ignored immediately as well an artiﬁcial variable comes out of the
solution. There is, however, the reason to keep these columns: simplex tables
provide data that can be used for the analysis of the optimal solution.
Resolve the simplex spreadsheet problem by continuing to estimating
the optimality of the solution and choosing the variable to enter the solution
takes into account the ﬁrst part of order (ωj −γj). By watching this of
the row in the fourth simplex table, we see that there are no positives
coeﬃcients, so we can conclude that the solution is in this table optimally.
It consists of variables:

Simplex Method
123
y1 = 25
y2 = 250
y3 = 25
and the minimum value of the criterion function is ω0 = 32000.
We said that in the fourth simplex table, the optimal solution was found.
However, row (ωj −γj) of column y4 (column of non-base variable y4) has
a coeﬃcient of zero. This means that we can specify that the variable y4
enters the next solution and determine another solution with the same the
criterion function value. In other words, we can determine another optimal
solution, so we need to put together another simplex spreadsheet. As the
variable y4 goes into the next one solution, in the fourth table, we marked
the column y4. From the variable y1 comes out of the solution, so we also
label the third row and rounded oﬀthe characteristic coeﬃcient. Now we
can specify the ﬁfth simplex table.
C
B
y0
160
100
120
0
0
0
M
M
M
y1
y2
y3
y4
y5
y6
y7
y8
y9
120
y3
100
3
0
1
0
1
−1
0
−1
1
100
y2
200
−2
1
0
0
−2
1
0
2
−1
0
y4
50
2
0
0
1
0
−1
−1
0
1
ωj −γj
32000
0
0
0
0
−80
−20
0
80
20
0
0
0
0
0
0
0
−1
−1
−1
Table 2.7.5.
In the ﬁfth simplex table, we get another optimal solution. It is made
up of variables
y2 = 200
y3 = 100
y4 = 50
and the minimum value of the criterion function, ω0 = 32000, is the same
as for the solution in the fourth simplex table.
Let us just mention that the convex combination of the two optimal
solutions can be obtained by other, also optimal solutions. The solutions

124
Advances in Optimization and Linear Programming
found using simplex tables are basic; all the solutions that can be obtained
as a convex combination of basic solutions are not basic.
We denote the optimal solution from the fourth simplex table with y1
0,
and the solution from the ﬁfth table with y2
0, so we get the following term
for convex combination:
y3
0 = qX1
0 + (1 −q)y2
0
0 < q < 1
where y3
0 represents the new optimal solution.
The problem in which the constraint system had all the unequal direc-
tions of “≥,” is subtracted in all inequalities and added. For problems like
this have artiﬁcial base. Of course, it may not always be the case. If the
problem has fewer artiﬁcial variables than the number restrictions, then we
have an incomplete artiﬁcial base. The procedure of solving these problems
makes no diﬀerence to the procedure already discussed.
Let us now consider the Ref. [43] method for which there is no in-
crease in the dimensions of the problem. We will look at one canonical
form (2.3.0.1) of a linear programming problem:
max ω(y) = γ1yN,1 + . . . + γnyN,n + d
subj. α11y1 + α12y2 + ... + α1nyn −β1 = −yB,1
α21y1 + α22y2 + ... + α2nyn −β2 = −yB,2
(2.7.0.4)
· · ·
· · ·
· · ·
αm1y1 + αm2y2 + ... + αmnyn −βm = −yB,m.
whereby not all βi ≥0, i.e., there is some i ∈{1, . . . , m} such that
βi < 0 but the coeﬃcients γi satisfy the optimality condition. Now
the corresponding basic solution y = (0, . . . , 0, β1, . . . , βn) is not per-
missible, i.e., does not belong to the set ΓP . The task we are solving

Simplex Method
125
is ﬁnding an equivalent a basic admissible problem (2.7.0.4), that is,
ﬁnding one basic admissible solution. For this we need a dual simplex
method.
2.8
Duality in Linear Programming
In some cases, the mathematical model of the basic LP task can-
not help ﬁnd the optimal plan using the simplex method described. In
such cases, the reformulation of the primal task LP into a dual-task,
by which a solution can be found. There are the following correspon-
dences between the primary and dual tasks:
1. The dual model has as many variables as the primary constraint
task; the restrictions on how much the primary task of variables;
2. The free members in the constraints of the primal task become
coeﬃcients with variable functions of the criterion (goal) of the dual
model, and the coeﬃcients with the variable functions of the criteria
of the primal model become free members in the limitations of the
dual model;
3. The direction of the inequalities of the dual model is opposite
to that of the primal model;
4. If the maximum of the criterion function is required in the
appropriate model, in the dual, the minimum is sought, and vice
versa;
5. Supplementary variable yn+1 receiving which is in the optimal
base solution corresponds to the variable yj in the dual model, with
yn+1yj = 0, j = 1, . . . , m.

126
Advances in Optimization and Linear Programming
6. It corresponds to the real variable yj of the receiver from the
base admissible solution supplementary variable ym+j of the zero-
value dual model yjym+j = 0, j = 1, . . . , n.
7. The constraint matrix in the primary model is the same as the
transposed matrix limitations in the dual model.
We consider the problem of linear programming in standard form:
min
γT x,
subj.
Ay = β,
(2.8.0. 1)
y ≥0,
where A is a matrix of type m × n with the usual assumption rank
(A) = m. We associate the problem (2.8.0. 1) with the so-called.dual
problem shape
max
βT y,
subj.
AT y ≤γ
(2.8.0. 2)
in which the free coeﬃcients of the problem (2.8.0. 1) have become
coeﬃcients in the objective function, and coeﬃcients in the objec-
tive function of the problem (2.8.0. 1) become free coeﬃcients in the
constraint system. Note that for no negative condition is imposed on
vector y. The problem (2.8.0. 1) is in the context of duality theory,
it callsthe primal problem. Adding the of the balancing variables the
problem (2.8.0. 2) is reduced to:

Simplex Method
127
max
βT y,
subj.
AT y + s = γ,
(2.8.0. 3)
xs ≥0.
Let ΓP and ΓD be admissible sets of problems (2.8.0. 1) and (2.8.0.
3), respectively. There is a link between the target recipient and dual
target functions:
Theorem 2.8.1. (Poor Duality). If ΓP i ΓD void sets and if y ∈ΓP
i (y, s) ∈ΓD, then γT x ≥βT y.
Proof. Since it is valid that y ≥0 and s ≥0 we get:
0 ≤sT x = (γ −AT y)T x = γT x −yτ(Ay) = γT x −βT y.
The proof is complete.
The following theorem is fundamental in the theory of duality.
Theorem 2.8.2. (Strong Duality) If problem (2.8.0.1) has then the
optimal solution then also (2.8.0.3) has the optimal solution i thereby
min γT x = max βT y.
Proof. How optimally the problem (2.8.0. 1) is by assuming the the-
orem solution, that the application of Algorithm 2 to (2.8.0. 1) ends
in the ﬁnal the number of iterations with the optimum basic allow-
able solution y∗. Let j1 < · · · < jm be indexes of the base and
i1 < · · · < in
m indices of non-basic columns in the corresponding
−
simplex table and let is αB = [Kj1 . . . Kjm], αN = [Ki1 . . . Kjn−m],

128
Advances in Optimization and Linear Programming
γB = (γj1, . . . , γjm), γN = (γi1, . . . , γjn
m). Based on previous con-
−
siderations of the canonical form of the linear problems, the zero
type at the zero position contains −cTx∗= −γT
BA−1
B β, at posi-
tions j1, . . . , jm contain zeros and positions i1, . . . , jn−m contains
a vector γ
τ
1 T
N −αN(αB
−) cB which is non-negative due to optimal-
ity conditions. Suppose that y∗= (α
1 T
B
−) cB and s∗deﬁned with
s∗
B = 0, s∗
N = γN −ατ
N(α−1
B )T cB. Then s∗≥0 i
αT
By∗+ s∗
B = γB,
αT
Ny∗+ s∗
N = γN,
i.e., solution (y∗, s∗) is plausible. In addition, it is γT x∗= γT A−1
B
B β =
(y∗)T b = βT y∗. As in Theorem 2.8.1 βT y ≤γT x∗= βT y∗, it follows
that (y∗, s∗) is the optimal solution to the problem (2.8.0. 3).
The following theorem follows Karash-Kuhn-Tucker’s optimality
conditions.
Theorem 2.8.3. (i) y∗ΓP is the optimal solution to the problem
(2.8.0.1) if and only if there is (y∗, s∗) ∈ΓD such that γT x∗= βT y∗.
(ii) y∗ΓP is the optimal solution to the problem (2.8.0.1) if and
only if there is (y∗, s∗) ∈ΓD such that (y∗)T s∗= 0.
Proof. (i) Let y∗ΓP be the optimal solution to the problem (2.8.0.
1). Then by Theorem 2.8.2 the problem (2.8.0. 3) has an optimal
solution (y∗, s∗) ∈ΓD and it is valid γT x∗= βT y∗.
If there is (y∗, s∗) ∈Γ
T
D such that γ x∗= βT y∗, on the basis of
Theorem 2.8.1 implies that for every y ∈ΓP it holds γT x ≥γT x∗.
How is y∗ΓP , this is y∗optimal re problem
ˇ
solving (2.8.0. 1).
(ii) Let y∗ΓP be the optimal solution to the problem (2.8.0. 1).
Then according to (i) there is (y∗, s∗) ∈ΓD i γT x∗= βT y∗. When we

Simplex Method
129
transpose this equality from subtract equality (y∗)T AT y∗= (y∗)T Ax∗
we obtain:
(y∗)τ(γ −AT y∗) = (y∗)τ(β −Ay∗).
Now from s∗= γ −AT y∗i β −Ay∗= 0 follows (y∗)T s∗= 0.
If it is valid i(y∗, s∗) ∈ΓD such that it is (y∗)T s∗= 0, because
permissibility y∗i (y∗, s∗) follows:
(y∗)T s∗= (y∗)τ(γ−AT y∗) = (y∗)T c−(y∗)T AT y∗= (y∗)T c−βT y∗= 0,
so it follows from (i) that y∗is the optimal solution to the problem
(2.8.0. 1).
The signiﬁcance of Theorem 2.8.3 is that the following is estab-
lished equivalence: the vector y∗Rn is the optimal solution problems
(2.8.0. 1) if and only if there are vectors s∗∈Rn i y∗∈Rm so that
the following conditions apply:
AT y∗+ s∗= γ,
Ay∗= β,
yi
∗s∗
i = 0,
i = 1, . . . , n,
(2.8.0. 4)
(y∗, s∗) ≥0.
It is obvious that (2.8.0. 4) is also a necessary condition for yes
(y∗, s∗) is the optimal solution to the problem (2.8.0. 3). These con-
ditions play out an important role in the so-called primal-dual inner
point methods.
The question of the existence of permissible solutions to the pri-
mal and dual problems is solved by the following theorem:

130
Advances in Optimization and Linear Programming
Theorem 2.8.4. (i) ΓP = ∅and ΓD = ∅if and only if problems
(2.8.0.1) and (2.8.0.3) have optimal solutions. (ii) It is valid that ΓP =
∅. Then ΓD = ∅if and only if inf γT x =
y∈ΓP
−∞.
(iii) It is valid that ΓD = ∅. Then ΓP
= ∅if and only if
sup
βT y =
(y,s)y∈ΓD
∞.
Proof. (i) If problems (2.8.0.1) and (2.8.0.3) have optimal solutions,
it is trivial ΓP = ∅i ΓD = ∅.
Let ΓP = ∅and ΓD = ∅be observed arbitrarily (y, s) ∈ΓD.
Then by Theorem 2.8.1 the objective function is problems (2.8.0. 1)
limited from below and, therefore, it follows from Theorem 2.8.2 that
the problem (2.8.0. 3) also has an optimal solution.
(ii) Let ΓD = ∅and assume the opposite, i.e., that γT y ≥M
for y ∈ΓP . Then the problem (2.8.0. 1) has an optimal solution and
by Theorem 2.8.2 it follows that the problem (2.8.0. 3) also has an
optimal and therefore acceptable solution, which is a contradiction.
It is valid that infy ΓP γT x = −∞and we suppose that (y, s)
∈
∈
Γ
T
D. Then by Theorem 2.8.1 γT x ≥γ y for eachy ∈ΓP , which is
impossible.
(iii) By introducing the shift y = y+ −y−, y+ ≥0, y−≥0, the
problem (2.8.0. 3) is equivalent to the minimization problem:
min
(−β)τ(y+ −y−),
subj.
Aτ(y+ −y−) + s = γ,
(2.8.0. 5)
y+ ≥0, y−≥0, s ≥0,
which is dual
̸
̸
̸
̸
̸
̸
̸
̸

Simplex Method
131
max
γT u,
subj.
Au ≤−β,
−Au ≤β,
u ≤0.
(2.8.0. 6)
By replacing y = −u dual (2.8.0. 6) becomes:
max
(−γ)T x,
subj.
Ay = β,
(2.8.0. 7)
y ≥0.
Applying (ii) to the dual pair (2.8.0. 5) and (2.8.0. 7) it fol-
lows directly that ΓP = ∅if and only if
inf
(−β)T y =
(y,s)y∈ΓD
−∞,
i.e.
sup
βT y =
.
(y,s)y
∞
∈ΓD
Note that from the proof of Theorem 2.8.4 (iii) the conclusion is
that dual of the dual problem equal to the primal problem.
Remark 2.8.1. In Example 2.6.1, ΓP = ∅i ΓD = ∅, which indicates
that this is also possible.
It is valid that I1 ∪I2 = {1, . . . , m}, I1 ∩I2 = ∅, J1 ∪J2 =
{1, . . . , n}, J1 ∩J2 = ∅, and let V1, . . . , Vm be rows K1, . . . , Kn
columns of matrix A. Then to problem:
min
γT x,
subj.
V T
i x = βi,
i ∈I1,
V T
i x ≥βi,
i ∈I2,
(2.8.0. 8)
yj ≥0,
j ∈J1,
yj unbounded by sign,j ∈J2,

132
Advances in Optimization and Linear Programming
a dual problem answers:
max
βT y,
subj.
yi unbounded by sign, i ∈I1,
yi ≥0,
i ∈I2,
(2.8.0. 9)
KT
j y ≥γj,
j ∈J1,
KT
j y = γj,
j ∈J2,
and the analogs of Theorem 2.8.1 and 2.8.2. Dual symmetric problem
linear programming:
min
γT x,
subj.
Ay ≥β,
y ≥0,
it is given with
max
βT y,
subj.
AT y ≤γ,
y ≥0.
From (2.8.0. 8) and (2.8.0. 9) follows that problem is dual with
(1.5.0. 3) given with

Simplex Method
133
max
βT y,
subj.
yi unbounded by sign, i ∈I1,
yi ≥0,
i ∈I2,
yi ≤0,
i ∈I3,
KT
j y ≤γj,
j ∈J,
KT
j y = γj,
j ∈{1, . . . , n}\J.
2.9
Dual Simplex Method
Consider the linear programming problem to which the LP table
corresponds
−d
γ1
· · ·
γn
β1
α11
· · ·
α1n
.
.
.
.
.
.
.
.
.
βm
αm1
· · ·
αmn
which we calldual simplex table if it contains m diﬀerent base columns
and γ1 ≥0, . . . , γn ≥0. If β1 ≥0, . . . , βm ≥0, then the dual simplex
table is also and a simplex table to which the optimal basic solution
corresponds. If there is k ∈{1, . . . , m} such that βk < 0 i αk1 ≥
0, . . . , αkn ≥0, we have shown that the set of admissible solutions
is empty. If there is αki < 0 it is possible to apply the dual simplex
method.

134
Advances in Optimization and Linear Programming
Let a linear programming problem be given:
min
d + γT x,
subj.
Ay = β,
y ≥0,
to which the initial dual simplex table corresponds DT0 :
−d0
γ0
1
· · ·
γ0
n
β0
1
α0
11
· · ·
α0
1n
.
.
.
.
.
.
.
.
.
β0
α0
m
m1
· · ·
α0
mn
The conditions for applying the dual simplex method are now
fulﬁlled by the following algorithm:
Algorithm 4. (Dual simplex method).
Put k = 0; k−this iteration is followed by the following steps:
Step 1. If βk
i ≥0 for all i = 1, . . . , m, the algorithm stops, because
the base admissible solution is optimal.
Step 2. For each i for which βk
i < 0, examine whether αk
ij ≥0 for
γk
γk
all
j
j = 1, . . . , n.
r = max
αksr
(
αk
sj
|αk
sj < 0
)
.
Step 4. Apply the following elemental transformations to DTk:
• multiply s−th row with −αk
ir/αk
sr and add to rows i =
0, . . . , m, i = s;
• divide s−th row with αk
sr.
Step 5. Replace k with k + 1 and go to Step 1.
̸

Simplex Method
135
The dual simplex algorithm is a maximization for the objective
function, which follows from the following theorem:
Theorem 2.9.1. By applying the elemental transformations from
Step 4 Algorithm 4 is obtained from the dual simplex table DTk dual
simplex table DTk+1 corresponding to an equivalent problem linear
programming. In doing so, dk+1 ≥dk.
Proof. Obviously, using elemental transformations gets LP-tab li ca
DTk+1 corresponding to an equivalent problem linear programming.
In doing so, all the base columns are in s−that the species that had
zeros remain basic, and r−this column becomes basic instead of one
that had a unit in s−. For j = 1, . . . , n is
αk
γk+1
j
= γk
j −
sj γk
αk
r .
sr
If αk
sj ≥0, from γk
r ≥0 i αk
sr < 0 follows γk+1
j
≥γk
j ≥0. If
αk
sj < 0, by choice r in Step 3 follows:
γk
γk+1
j
= αk
j
γk
r
sj
 
αk
sj
−αksr
!
≥0.
Therefore, DTk+1 is a dual simplex table. From γk
r bk
s/αk
sr ≥0,
follows:
−dk+1 = −dk
βk
−
s γk
k
k+1
k
αk
r ≤
d
sr
−d
⇔
≥d
which completes the proof.

136
Advances in Optimization and Linear Programming
Example 2.9.1. Let the problem be given:
min
3y1 + 2y2,
−y1
+3y2
+y3
=
−1,
2y
10y
+y
=
10,
subj.
−
1
−
2
4
−
2y1
+4y2
+y5
=
8,
3y1
−5y2
+y6
=
6,
y ≥0.
to which the dual simplex table corresponds
0
3
2
0
0
0
0
−1
−1
3
1
0
0
0
−10
−2
−10
0
1
0
0
8
2
4
0
0
1
0
6
3
−5
0
0
0
1
By applying Algorithm 4 with framed pivot elements, we obtain:
−3
0
11
3
0
0
0
1
1
−3
−1
0
0
0
−8
0
−16
−2
1
0
0
6
0
10
2
0
1
0
3
0
4
3
0
0
1
from which the dual simplex table immediately follows:
−17/2
0
0
13/8
11/16
0
0
5/2
1
0
−5/8
−3/16
0
0
1/2
0
1
1/8
−1/16
0
0
1
0
0
3/4
10/16
1
0
1
0
0
5/2
1/4
0
1

Simplex Method
137
The corresponding basic permissible solution is (5/2, 1/2, 0, 0, 1, 1) op-
timum and optimal value of the objective function is 17/2. Note that in
this case, the dual algorithm steps are identical to Algorithm 3.
Note that Algorithm 4 can be applied if a dual simplex table is
known. If not, we can construct a simplex table using the following
algorithm:
Algorithm 5. (Dual algorithm for arbitrary simplex table).
Step 1. We form an initial LP form table
−d
γ1
· · ·
γn
β1
α11
· · ·
α1n
.
.
.
.
.
.
.
.
.
βm
αm1
· · ·
αmn
If γ1, . . . , γn ≥is0, we apply Algorithm 4.
Step 2. If γj < 0 for some j i α1j, . . . , αmj ≤0, the algorithm
stops because it is expensive restrictions inadmissible.
Step 3. Let γj1, . . . , γjq < 0.
If q = n we choose αin < 0 for the stator element, we apply
simplex transformation and we move on to Step 1.
If q < n and if there is p ∈{j1, . . . , jq} such that it is ﬁlled
following the condition:
min
 γk
γ
|
p
αik > 0, γk
k
≥0
αik

≥αip
≥0,
(2.9.0.1)
S elect αip < 0 for the stoser element, apply the simplex trans-
formation and go to Step 1. If there are more elements αip < 0 that
satisfy the condition (2.9.0.1), we choose the one for which

138
Advances in Optimization and Linear Programming
β
min

h | βh ≥0, αhp > 0

β
≥
i ,
βi < 0.
αhp
αip
If the condition 2.9.0.1 is not met, let it be:
min
k
 γk
γ
αik
| γk ≥
r
0, αik > 0

=
.
αir
For this r, we set αir for the pivot element, apply the simplex
transformation, and go to Step 1.
Note that no simplex table generated by the dual algorithm does
not correspond to the permissible solution of the primal problem
except the last one is at the same time a simplex table. We show that
each dual simplex the table corresponds to the permissible solution
to the dual problem. Let u dual simplex table DTk index set of basic
columns denote čen with B and let be the corresponding base αB. by
renumbering the column in the associated matrix αB we can achieve
that DTk corresponds to the following linear programming problem:
min
γT
BA
1
τ
T
−
B β + (γN −γBA−1
B αN)yN,
subj.
yB + α−1
B αNxN = α−1
B β,
(2.9.0.2)
yB ≥0,
yN ≥0.
The problem (2.9.0.2) is the canonical form of the standard linear
problem programming relative to the base αB for which it applies
γτ
N −γT
BA−1
B αN ≥0. We deﬁne (y∗, s∗) sa y∗= (α−1
B )T cB, s∗
B =
0, s∗
N = γN −αT
Ny∗. Then:
αT
By∗+ s∗= γ
T
B,
αNy∗+ s∗= γN
s∗
B ≥0,
s∗
N ≥0,

Simplex Method
139
i.e., (y∗, s∗) is a permissible solution to a dual problem. So to each,
the dual simplex table corresponds to the permissible solution of the
dual. Coordinates the vectors s∗are explicitly given in the table and
the vector y∗is calculated from the system αT
By∗= γB.
2.10
Elimination of Equations and Free Variables
In the beginning, when we deﬁned the forms of the problem linear
programming, we have shown how the general form of linear problems
is reduces programming to a standard or symmetrical form. Here we
will show how Tucker’s can be used tables and variable substitution
(Replace algorithm) to reduce the general linear programming prob-
lem to canonical form. So, let us now consider the general form of the
linear programming problem:
max ω(y) = γ1y1 + . . . + γnyn + d
X
n
subj. N (1)
i
:
aijyj
βi,
i = 1, . . . , p
j=1
≤
n
N (2)
i
:
X
aijyj ≥βi,
i = p + 1, . . . , q
j=1
n
ji :
X
aijyj = βi,
i = q + 1, . . . , m
j=1
yjc ≥0, j ∈J = {1, . . . , s},
s ≤n.
Multiply all inequalities of type N(2) by −1 and introduce additional
variables yn+1, . . . , yn+q as in reducing to the standard form. For-

140
Advances in Optimization and Linear Programming
mally, we mark the pro men li ve on the left of the table with yB,i
and those on the right yN,j. This gave us a problem in a form remi-
niscent of the canonical one.
max ω(y) = γ1yN,1 + . . . + γnyN,n + d
subj. α11yN,1 + α12yN,2 + ... + α1nyN,n −β1 = −yB,1
α21yN,1 + α22yN,2 + ... + α2nyN,n −β2 = −yB,2
· · ·
· · ·
· · ·
αq1yN,1 + αq2yN,2 + ... + αqnyN,n −βm = −yB,q
αq+1,1yN,1 + αq+1,2yN,2 + ... + αq+1,nyN,n −βq+1 = −0
· · ·
· · ·
· · ·
αm1yN,1 + αm2yN,2 + ... + αmnyN,n −βm = −0
(2.10.0. 1)
The diﬀerence is only in the equations q + 1, . . . , m. Assuming
that they are assigned additional variables that are identically zero,
we get the problem in canonical form. The equivalent Tucker table
has the following appearance:
yN,1
yN,2
· · ·
yN,n
−1
α11
α12
· · ·
α1n
β1
=
−yB,1
α21
α22
· · ·
α2n
β2
=
−yB,2
(2.10.0. 2)
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
αq1
αq2
· · ·
αqn
βq
=
−yB,q

Simplex Method
141
αq+1,1
αq+1,2
· · ·
αq+1,n
βq+1
=
−yB,q+1 ≡0
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
αm1
αm2
· · ·
αmn
βm
=
−yB,m ≡0
γ1
γ2
· · ·
γn
d
=
ω
Let us now consider one such equation (e.g., the last one).
αm1yN,1 + αm2yN,2 + ... + αmnyN,n −βm = −yB,m = −0
If all αq+1,j = 0 then this equation is either impossible, so the
problem is inadmissible, or identity, so it can easily get out of the
way. Now let αmj = 0 for some j. If we replace the variables yB,m
and yN,j are given by:
yN,1
· · ·
yB,m ≡0
· · ·
yN,n
−1
α11
· · ·
α1j
· · ·
α1n
β1
=
−yB,1
.
.
.
.
.
.
.
.
.
.
.
.
.
.
.
(2.10.0. 3)
αm1
· · ·
αmj
· · ·
αmn
βm
=
−yN,j
γ1
· · ·
γj
· · ·
γn
d
=
ω
Obviously, the now independent variable yB,m ≡0 does not aﬀect
the objective function or the conditions. It follows that we can throw
out the j table column (2.10.0. 3). This reduced the number of nonba-
sic variables for 1. We repeat this procedure until the base variables
that are zero are completely eliminated. The following algorithm can
be described.
ElJed algorithm (Equation elimination)
̸

142
Advances in Optimization and Linear Programming
Step 1. If there are no basic variables identically equal to zero,
apply bf NoStandardMax algorithm.
Step 2. Let yB,i ≡0. Find αij = 0. If such does not exist, and if
βi = 0, eject and equation and go to step 1, otherwise STOP. The
problem is intolerable.
Step 3. Substitute the variables yB,i and yN,j, drop the j column,
reduce n by 1, and go to step 1.
Similarly, we eliminate the free variables. If any of the basic vari-
ables free, e.g., yB,1, its value can always be calculated from the
equation:
α11yN,1 + α12yN,2 + ... + α1nyN,n −β1 = −yB,1
for arbitrary values of nonbasic variables. So this equation is always
satisﬁed and can be thrown out of trouble. Suppose we have elim-
inated all basic free variables in this way. Also, suppose it is some
non-base variable (e.g., yN,j) is free. First, let αij = 0 for each
i = 1, . . . , m. If γj = 0 then the goal function is unlimited if the
problem is acceptable. Otherwise, variable yN,j has no eﬀect on the
goal function either, so it can be thrown out.
Now let αij = 0 for some i ∈{1, . . . , m}. We replace the variables
yB,i and yN,j. After the transformation, the variable yN,j becomes
basic, so they are eliminated as in the previous case. According to we
have:
ElSl algorithm (Eliminating free variables)
Step 1. If there are no free variables, apply the algorithm ElJed.
Step 2. Let the variable yB,and be free. Throw out the and equation
(type) and go to Step 1.
̸
̸
̸

Simplex Method
143
Step 3. Let the variable yN,j be free. If αij = 0 for every i =
1, . . . , m, go to Step 2’. Otherwise, select αij = 0 and go to Step 4.
Step 3’. If γj = 0 is to throw out j-th column, reduce n by 1 and
go to step 1. Otherwise, drop the j column, go to step 1 and continue
with the algorithm until it is determined that the problem is accept-
able or not. If permissible, STOP. The goal function is unlimited.
Step 4. Substitute the variables yB,i and yN,j. Now yN,j becomes
basic free variable, eliminate it as in Step 2.
A complete algorithm has now been introduced to solve the lin-
ear programming starting problem. In the following example, we will
show how equations and free variables are eliminated at the same
time.
Example 2.10.1. The following table is given:
y1
y2
y3
−1
1
1
1
6
=
τ0 =
−0
1
1
0
1
=
−y4
1
2
1
0
=
ω
The framed variable is free. Let’s choose α12 for the pivot element.
After changing the variables, you get a table τ1. By ejecting the species
corresponding to the free variable and the column corresponding to zero is
given the equivalent table τ1
′.
y1
0
y3
−1
y
y
−
1
3
1
1
1
1
6
=
y2
−
τ1 =
τ1
′ =
0
0
1
1
5
=
y4
−1
−5
=
−y
−
−
−
−
4
−1
−1
−1
−2
−1
−12
=
ω
−12
=
ω
Note that if we now choose (according to the NoStandardMax algo-
rithm) α12 for the pivot, we get the optimal the solution.
̸

144
Advances in Optimization and Linear Programming
2.11
Revised Simplex Method
The simplex method works by replacing variables at each step
with the objective of increasing (decreasing) the function aim or ob-
tain an acceptable solution. In each iteration, variables are replaced,
whereby compute new values of Tucker’s table elements. During this
repair, a series of divisions is made, which causes a numerical error to
accumulate. Because of this, the simplex method fails in cases where
a large number of iterations are required. To avoid this, it is neces-
sary to have Tucker table elements they calculate using the starting
matrix of problems. This is achieved by the revised simplex method.
We look at the problem of linear programming in standard format
(1.5.0. 4). Let one basic be given solution (obtained by solving the
system Ay = β or the method of eliminating equations) y∗. Let’s look
now the starting problem in canonical form:
max
(γ∗)T xN −d
subj.
TxN −β∗= −yB
(2.11.0. 1)
y = (yB, yN) ≥0
Let us now denote by n and m the row of nonbasic and basic variables
and by τ a matrix of type m × n which represents Tucker’s spread-
sheet. The vectors β∗and γ∗are the corresponding free vector and the
vector of the objective function u canonical form. The system of equa-
tions in (2.11.0. 1) can be otherwise written as [τ|Im]
Now write the system Ay = β in the form αBxB + αNx
h
yNyB
i
= β∗.
N = β. From
this condition and (2.11.0. 1) we get the direct that:

Simplex Method
145
τ = α−1
B αN
β∗= α−1
B β.
(2.11.0. 2)
So if we know the indices of the base variables vB,1, . . . vB,m (yB,i =
yvB,i) can we reconstruct Tucker’s spreadsheet using formulas (2.11.0.
2). αB = [KvB,1 · · · KvB,m] was met.
The objective function f(y) = γT x can be treated here as an
equation, with the addition of an additional variable yn+1 so that
A0
γT x + yn+1 = 0. Now the system matrix has the form αγ =
"
γτ1
#
with yγ = (y1, . . . , yn+1). It is also:
αB0
(αγ)B =
"
γB1
#
.
So, if we now apply formulas (2.11.0. 2) for an extended system
αcxγ =
"
β∗
d
#
,
we can completely reconstruct Tucker’s spreadsheet.
As we can see, the method of reconstruction of the Tucker table
just presented does not accumulate, so this method is more stable
than the classic simplex method. However, we notice that at every
step, we have to calculate the inverse of the matrix, which makes one
iteration of the revised simplex method signiﬁcantly algorithmic more
complex than the corresponding iteration of the classical simplex.
With most test cases (and practice problems that come down
to linear programming), system matrices are very sparse (sparse),

146
Advances in Optimization and Linear Programming
i.e., there are few non-zero elements. Unfortunately, inverse matrices
sparse matrix in the general case no must be sparse. It is even possible
to construct an example sparse matrices of relatively small dimen-
sions whose inverse is absent not a single zero, and in most cases, the
number of zeros is very small. Matrix inversion methods take a very
long time, and the inverse matrix requires a lot of memory space.
Also, in the algorithms of the simplex method we do not need
to know the whole Tucker table. Enough to know (to reconstruct)
individual rows or columns of Tucker’s table. Below we describe the
method we are in calculating the required part of Tucker’s table is
reduced only to solving a system of linear equations. Denote the j-th
column of the matrix A by A•j and i-th row by αi . To reconstruct
•
a j column, it is suﬃcient to multiply the corresponding column of
the starting matrix by α−1
B that is, the system αBT•j = KvN,j should
be solved. Here we have to solve as many systems as the columns
need reconstruct. We only need the NoStandardMax algorithm one
column and vector β. To reconstruct the and th order required we
know the and-th order of the matrix αB
−1 and [5, 43, ?] respectively:
τi = (α−1
B )
•
i α
•
N
(2.11.0. 3)
The vector (α−1
B )and is determined from the following equation:
•
(α−1) α
= (I )
=⇒ατ (α−1)τ =
τ
B
i
B
m i
B
B
i
(Im)i
(2.11.0. 4)
•
•
•
•
which also represents a system of linear equations to solve.
Note that, to solve a system of linear equations (2.11.0. 3) and
(2.11.0. 4), we use methods such as Gaussian elimination, LR fac-
torization, etc. [37]. We only need to reconstruct the StandardMax

Simplex Method
147
algorithm in the last row (goal function), which means in each itera-
tion of the StandardMax algorithm we need to solve three systems
linear equations. In the NoStandardMax algorithm in each iter-
ation need to reconstruct one row and two columns. As whic
ˇ
h we
can see, except for the great memory savings (reconstruction using
an inverse matrix due to the problem mentioned it makes no sense
to implement using the sparse representation matrix) is obtained on
time as well.
Let us now formulate the StandardMax and NoStandardMax
algorithms “language” of the revised simplex method.
RevBasicMax algorithm (Revised simplex metho
"
d for
α
permissible canonical forms). Form a matrix
B
0
(αγ)B =
γB
1
# basic
where
γB is a vector consisting of the coeﬃcients of the objective function
with basic variables.
Step 1. Solve (αB)γβ∗= β i (αB)τ
γ((α
1 τ
τ
B)−
γ )m+1 = (I
•
m+1)m+1 ,
•
reconstruct n + 1 row of Tucker’s table γ∗= ((αγ)−1
B )n+1 N
•
γ.
Step 2. If γ∗≤0 the objective function has an extremum. Other-
wise, let γj
∗> 0
Step 3. Reconstruct j-th column of matrix τγ, i.e., solve system
αBT j = KvN,j. If τ
unlimit
•
j
STOP
• ≤0,
. The goal function is
ed.
Step 4. Calculate:
β
β
min

i
∗
∗
∥
p
τij > 0
1
i
τij

=
≤≤m
τpj
Step 5. Drop the variable yB,j (or vector KvB,j) from the database
and insert the variable yN,j (i.e., vector KvB,j). In other words, sub-
stitute vB,p and vN,j. Go to step 2.

148
Advances in Optimization and Linear Programming
The following algorithm has not been found in the literature, so it
is partially original. However, using the previous algorithm without
the following is meaningless, because already in the NoStandard-
Max algorithm, numerical errors accumulate.
RevNoBasicMax algorithm (Revised simplex method for non-
basic canonical forms) Step 1. Let be the initial basis matrix B.
Step 2. Resolve (αB)γβ∗= β. If β∗≥0, apply the algorithm
RevBasicMax. Otherwise, choose βi
∗< 0 such that and is maximal.
Step 3. Reconstruct the and -type τand
matrix τ (Tucker’s ta-
•
bles). If τi• ≤0, STOP. The problem of linear programming is unac-
ceptable. Otherwise, select τij < 0.
Step 4. If i = m replace the variables yB,i and yN,j and go to step
2.
Step 5. To reconstruct the j-th column of the matrix τ, i.e., solve
the system αBτ•j = KvN,j
Step 6. Calculate
βi
∗ [ βl
∗
βp
∗
min
α
l>i
τij
τlj
∥
lj > 0

= τpj
Substitute the variables yB,p and yN,j and move to Step 2.
Algorithms for the elimination of equations and free probes can be
described analogously. In the end, we again mention the advantages
and disadvantages of the revised simplex method.
Advantages:
• The elements of Tucker’s table τ are calculated directly on the
basis of the matrix A, thus avoiding the accumulation error of
the computational operations.

Simplex Method
149
• Since the algorithms of the simplex method does not need the
entire matrix τ, but only the individual rows and columns, by
the revised simplex method, we only reconstruct those rows and
columns and not the entire τ matrix.
Disadvantages:
• Given that at each step, we have to either search for an inverse
matrix or solve several (maximum 3) systems of linear equa-
tions, the iteration of the revised simplex is much slower than
the iteration of the ordinary.
• In ordinary simplex, we used a simple algorithm to replace the
pros. This is where it needs to be implemented complex algo-
rithms for solving systems of linear equations or inversion of
matrices.
2.12
Cycling Concept and Anti-Cyclic Rules
In 2.4.1 Theorem, we have shown that after each iteration of the
StandardMax algorithm, the value of the function is either targeted
or increased, or it remains the same. In this way, we have “proved”
that the same algorithm ends up in a ﬁnite number of iterations (since
there are ﬁnally many basic solutions available). In doing so, we have
not considered the possibility of value does not change the function of
the target while running the StandardMax algorithm. In this case,
we have no guarantee that the algorithm will StandardMax ﬁnish
in ﬁnite time. The following is an example.

150
Advances in Optimization and Linear Programming
Example 2.12.1. Consider the following linear programming problem in
symmetric form:
3
1
max ω =
y1 −20y2 +
y3
4
2
−6y4
1
subj. & y1 −8y2
y
4
−y3 + 9 4 ≤0
1
1
(2.12.0. 1)
& y1 −12y2 −
y3 + 3y4 ≤0
2
2
&y3 ≤1
&y1, y2, y3, y4 ≥0.
Let’s form an appropriate canonical form, Tucker’s table, and apply the
StandardMax 7 algorithm:
y1
y2
y3
y4
−1
1
−8
−1
9
0
=
4
−y5
1
2
−12
−1
3
0
=
2
−y6
(2.12.0. 2)
0
0
1
0
1
=
−y7
3
20
1
4
−
2
−6
0
=
ω
Should we continue with the StandardMax algorithm obtained 6
spreadsheets would be repeated over and over again optimal solution. No-
tice that in steps 2, 3, and 4, the choice element does not have to be unique.
This is the main reason for the occurrence of cycling. Cycling is
most often treated as a rare occurrence that occurs only in artiﬁcially
constructed examples [64, 55]. However, back in 1977, Kotiah and
Steinberg [30] discovered a whole class “cycle” problems. Also, as we
will see later, when testing the programs, we noticed the occurrence
of cyclization on a number of examples.
In this section, we will look at the rules that are being prevented
by cycling. These rights are called anticyclical rules.

Simplex Method
151
We’ll handle two types of anti-cyclical rules:Lexicographic
Method and Bland Rules.
αp,n+1
α
= min
αpj
{
i,n+1
αij
∥αij > 0}.
Consider now again the appropriate standard form 2.1.0.2, at to
which we will add the vector β‘ as a null column to the matrix A′. Cy-
cling is avoided if p is selected in Step 3 so that instead, the minimum
reaches the lexicographic minimum. The modiﬁed step is:
Determine j ∈{1, . . . , n} for which it is valid that γj < 0. Deter-
mine p ∈{1, . . . , m} such that:
Vp
i
= lex-min
pj
 V
α
αij
|αij > 0

,
Example 2.12.2. In the case of Tucker’s table from the example at the
beginning of this section, with the same rule for choosing the index j it
follows that j = 1, αij > 0 for i = 1, 2, i
V1
V
−
−
2
= [0, 1,
32,
4, 36, 4, 0, 0],
= [0, 1, −24, −1, 6, 0, 2, 0],
α1j
α2j
so lex-min is reached by p = 1, and is the ﬁrst pivot element of α11. Applying
the lexicographic rule further generates pivot elements α1
22, α2
23, α3
34, leading
to Tucker’s table τ4 with new the value of the target function and cycling is
avoided.
Remark 2.12.1. It is important to note that lex-min is always unique
because from the assumption it is rankA‘ = m implies that there are
no two proportional types.
Let us now prove the correctness of the lexicographic rule.

152
Advances in Optimization and Linear Programming
Theorem 2.12.1. Let A′ be all types in the initial matrix V1, . . . , Vm
lexicographically positive and let it be in the algorithm Standard-
Max step 3 replaced by step 3.’ Then the cycling is eliminated, i.e.,
the simplex method in ﬁnite number iteration comes either to the op-
timal solution or to the conclusion that the target the function is not
restricted from below:
Proof. We will show ﬁrst that species V k
i , i = 1, . . . , m, matrices A′
remain lexicographically positive. For
V
i = p it is valid that V 1
p =
p
αpj
lex
lex
pa αpj > 0 i Vp > 0 implies Vp > 0. For i = p it is true that:
l
V 1
αij
Vi
V
ex
p
i = Vi −
Vp = αij
αpj

αij
−αpj

> 0,
where strict inequality applies based on the foregoing. For i = p i
lex
lex
αk
ij ≤0 it is valid that V 1
αij
i = Vi + |
|Vp
αpj
≥Vi > 0. For m + 1-th row
it is valid that:
V 1
α
m+1 = Vm+1 −
m+1,j
α
lex
m+1,j
Vp = Vm+1 + |
|Vp > Vm+1
αpj
αpj
because of
lex
αm+1,j < 0, αpj > 0
i
Vp > 0.
Therefore, m+ 1 is strictly lexicographically growing and cannot
be repeated.
Remark 2.12.2. The assumption of lexicographic positivity of ma-
trix types A′ in the previous theorem is not restrictive as this can
be achieved in to every canonical form of linear programming. It is
enough, at the beginning, to perform renumber the variables and bring
the columns of the unit matrix to positions 1, . . . , m.
̸
̸

Simplex Method
153
We are reminded that for simpler formulation.
Step 3. Determine s ∈{1, . . . , m}(for which αk
s0 < 0. Determine
αk
αk
∈{
} such that
0r
0j
r
1, . . . , m
= max
αksr
αk
sj
|αk
sj < 0
)
;
Let’s take the following step:
Step 3’. Determine s ∈{1, . . . , m} for which it (is true βk
s < 0.
Kk
Kk
Determine r ∈{1, . . . , m} such that
r = lex-
j
max
αksr
αk
sj
|αk
sj < 0
)
,
where Kk
j j−-th column k−th of dual simplex table.
We can prove the ﬁnality of the dual simplex method.
Theorem 2.12.2. Let DT0 columns in the dual simplex table
K0
1, . . . , K0
n lexicographically positive and let it be in Algorithm 4 Step
3 replaced by Step 3.’ Then the string of zero columns (Kk
0 ) is strictly
lexicographically, the dual simplex method also decreases in the ﬁnal
number iteration comes either to the optimal solution or to the con-
clusion that the admissible set is empty.
Let’s now consider Bland’s rules. According to Bland [7], the
following two modiﬁcations should apply steps 2 and 4:
• Step 2’. Select γj > 0 such that the index of the corresponding
non-base variable is yN,j the smallest.
• Step 4’.
βi
βp
min
,
αij > 0
=
1≤and≤m

αij

αpj
In the case of equal values, choose p such that it is an index
corresponding base changes like yB,p smallest. Substitute the

154
Advances in Optimization and Linear Programming
non-base variable yN,j and the base variable yB,p and go to
Step 1. Calculate
 βi
β
min
,
αij > 0
1≤and≤m
αij

p
= αpj
In the case of equal values, choose p such that it is an index cor-
responding base changes like yB,p smallest. Substitute the non-
base variable yN,j and the base variable yB,p and go to Step
1.
Let us now prove the correctness of these rules. In the proof, the
matrix A represents the system matrix, vectors β and γ RHS vector
and vector objective functions in the appropriate standard problem
form, a matrix τ extended Tucker table. These marks are the same
as in section 2.11.
Theorem 2.12.3. Bland rules eliminate cycling in simplex methods.
Proof. Assume the opposite. Let τ be a set of indexes j such that
variable yj during cycle becomes basic. Let it be q = max τ. Let
τ‘ be a table with variable yq becomes basic a τtable where yq
becomes non-base (in the tables τ‘ and τthe variable yq is non-
base and basic respectively). Label it with t pivot transformation
column after which we get table τ.
We
deﬁne
the
vectors
y
=
(y1, . . . , yn, yn+1)
and
v
=
(v1, . . . , vn, vn+1) as follows:
1
i = n + 1
−1
i = vN,t
yi =



τ ′
i = v′

vi =
n+1,j
N,j
0



in contrary


τit
i = vB,i
0
in contrary

Simplex Method
155
Based onthe ﬁrst Bland rule, y1, . . . , yq−1
1
≥0 and yq < 0.
Since τ = (αγ)−
B (αγ)N. If we rearrange the columns of matrices
αγ and vectors y and v we can write αγ =
h
(αγ)B
(αγ)N
i
as well
h
τ
τ
v = τ•t
−(Im)•t
i y = τn
′
+1 0
.
•
Now we have that:
i
h
i
τt
αcv = [(αγ)B(αγ)N]
"
•
= ((αγ)N) t
((αγ)N) t = 0
−(Im)
•
•
#
−
•
t
The signs v belong to the kernel N(αγ) of the matrix αγ. Note
also that the vector y bass n + 1 is a vector matrix type (αγ)−1
B αγ. It
follows that yT v = 0. Note that vn+1 = τm+1,t < 0, so yn+1vn+1 < 0.
So there is j, so yjvj > 0.
Since yj = 0, the variable yj is basic in τ‘ and since vj = 0, or
yj is non-basic in τor j = t. In any case, j ∈τ, so j ≤q. Also,
since vq = τpt > 0 (q = vB,p, according to Step 4 of the algorithm
StandardMax a yq = τ‘m+1,p′ < 0 (q = v‘N,p′, by step 2 of the
algorithm StandardMax, we have that yqvq < 0, so 1 ≥j < q.
Since yj ≥0 it follows that vj ≥0.
We conclude that the variable yj is basic in table τ. Therefore,
let j = vB,k. Now τkt = vj > 0. Note also that during the cycle, the
last column of Tucker’s table τ (vector β∗) does not change. Namely,
since the value of the objective functions τm+1,n+1 does not change,
on the basis of formulas (2.3.0.5) we conclude that βp
∗= 0 (p is the
index of the pivot type), so based on the same the formula doesn’t
change β∗either.
Values of all variables from τ in the corresponding baselines so-
lutions are 0. Indeed, if ω ∈τ and yω are basic variable, let’s notice
̸
̸

156
Advances in Optimization and Linear Programming
the moment when it became basic. Then, if the pivot element is τql,
where vN,l = ω i βq
∗= 0, after transformation we have that vB,q = ω
a βq
∗remains 0.
Therefore (β∗)k = τk,n+1 = 0. So now we have (β∗)k = 0, τkt >
0, vB,k = j a vB,p= q where pis the corresponding pivot type
(in the next iteration yq becomes non-base). Based on the second
Bland rule, we conclude that q = vB,p≤vB,k = j which is a
contradiction. This proves the theorem.
An example of how these rules avoid cycling in the previous ex-
ample can be found in Ref. [43].
Let us mention at the end two shortcomings of Bland’s rules.
Applying these rules may result in such a choice pivot element that
changes in the value of the goal function are small, which often causes
more iterations simplex method. There is also a danger of picking
pivot elements that are close to zero and cause large one’s numerical
errors.
2.13
Complexity of Simplex Methods and Minty-Klee
Polyhedra
In the introduction, we mentioned that despite the good features
he showed in practice, the simplex algorithm is not polynomial. This
claim was ﬁrst proven by Minty and Klee in [28], back in 1970, as-
suming that for the pivot column, the ﬁrst column is γj < 0. It was
later proven to [29] for almost everyone deterministic pivot column
selection rule there is a class example of linear programming prob-

Simplex Method
157
lems such that the number of iterations the simplex method depends
exponentially on the dimension of the problem.
Deﬁnition 2.13.1. Let’s look at the following linear programming
problem, given in canonical form and via Tucker’s table:
min ϵn−1y
n
2
1 + ϵ −y2 + . . . + ϵyn−1 + yn
y1
≤t
2ϵy1 + y2
≤t2
2ϵ2y1 + 2ϵy2
≤t3
.
.
.
.
.
.
2ϵn−1y +2ϵn−2
n
1
y2+. . .+2ϵyn−1+yn ≤t
y ≥0
y1
y2
· · ·
yn
−1
1
0
· · ·
0
t
= −yn+1
2ϵ
1
· · ·
0
t2 = −yn+2
.
.
.
.
.
.
.
.
..
.
.
.
.
.
.
.
.
2ϵn−1
2ϵn−2
· · ·
1
tm =−yn+m
ϵn
ϵn−1
· · ·
1
0
=
f
Label this problem with Pn(ϵ, t) and call ita general Minty-Klee prob-
lem of dimension n.
In their work [28], Minty and Klee observed the problem of
Pn(2, 5). Obviously, for t > 0, this problem is basically permissible,
so we can immediately apply the algorithm StandardMax. Now let
us prove that the algorithm StandardMax after 2n −1 iterations

158
Advances in Optimization and Linear Programming
comes to an optimal solution y∗= (0, . . . , 0, tn) (y∗∈Rn). This is
precisely what the main theorem of this section states:
Theorem 2.13.1. Let ϵ, t > 0 and ϵ > 1
t
2. The algorithm Standard-
Max, applied to the problem P(ϵ, t), undergoes an 2n −1 iteration to
the optimal solutions y∗= (0, . . . , 0, tn).
Before giving evidence, let us consider some features of the general
Minty-Klee problem.
Lemma 2.13.1. Let the conditions of Theorem 2.13.1 apply. If we
apply an algorithm to replace variables k times, whereby the pivot ele-
ments are ai
pipi = 1 where the numbers pi ∈{1, . . . , n}, i = 0, . . . , k−1
a with al
ij is an element of (i, j) of Tucker’s table after l transfor-
mations, we get Tucker’s table of τk whose elements are equal to
tk = (−1)γk
ij
ij
t0
ij, for j < n + 1. With γl
ij we denote the number of
pivot elements ps for which j ≤ps < i and 1 ≤s ≤l.
Proof. We will prove the proof by mathematical induction. For l = 0,
the claim is trivial, given that γ0
ij = 0 for each (i, j) ∈{1, . . . , m +
1} × {1, . . . , n}. Suppose the claim holds for all numbers less than or
equal to k and prove it for k + 1. Let p = pk+1. According to the
induction hypothesis, in the pivot type and the p pivot column, the
elements are non-zero in sequence tk
ip and tk
pj such that i ≥p a p ≥j.
Therefore, if at least one of these two conditions does not apply, we
have that tk+1
ij
= tk
ij and γk+1
ij
= γk
ij, because p ∈/ [j, i) so the claim
of the lemma is valid.
For i = p it is valid that
tk
tk+1
pj
k
k+1
pj
=
= tk
pj = (−1)γpjt0
tk
pj = (−1)γpj t0
pj
pp

Simplex Method
159
because γk+1
pj
= γk
pj, for j ≥p. For j = p we have that:
tk
k+1
−ip
−
k
t
=
=
tk = −(−1)γipt0
γ
ip
tk
ip
ip = (
pp
−
k+1
1)
ip t0
ip
because γk+1
ip
= γk
ip + 1 for i ≤p.
For j < p and p < i is obtained:
tk+1
ij
= tk
ij −tk
pjtk
k
k
k
ip = (−1)γijt0 −(−1)γip+γpj 0
ij
tipt0
pj
Since it is t0
i
j
k
k
k
ij = 2ϵ −i γip + γpj = γij we have
k
tk+1
ij
= (−1)γ
k
ij t0
ij −t0 t0
= (−1)γij 2ϵi
j
ip pj
−
−
k+1
−4ϵi−p+p−j
k
= −( 1)γij
 2ϵi−j = (−

1)γij t0
ij.
 
that γk+1
ij
= γk
ij + 1 because i > p and p > j. This proves the
lemma.
From the evidence of the previous lemma it follows that if we
always choose the pivot species p = j (select pivot column as in
algorithm StandardMax) after 2n−1 steps we arrive at the optimal
solution. To prove it, suppose in the k th step we selected the j th
column for kljucnu. Then τ k
m+1,1, . . . , τ k
m+1,j
< 0 a τ k
> 0. Now
−1
m+1,j
choosing the element τ k
jj for the key, at on the basis of the evidence of
the previous lemma, we conclude that after transformations of vasitis
τ k+1
m+1,1, . . . , τ k+1
m+1,j
1 > 0 a τ k+1
< 0. Let us now add one natural
−
m+1,j
number to each Tucker table τ k τ(τ k) as follows. Digit at l th position
in binary notation τ(τ k) equals 0 if τ k
m+1,l positive otherwise is equal
to 1. We just proved that it is valid τ(τ k+1) = τ(τ k)+1, or τ(τ k) = k.
The algorithm stalls when all the digits of the number τ(τ k) are equal
to one, that is, when k = 2n −1.

160
Advances in Optimization and Linear Programming
The following lemma, which we will not prove, ends with the proof
of Theorem 2.13.1:
Lemma 2.13.2. In each iteration of the algorithm StandardMax
applied to the Pn(ϵ, t) problem p = j, i.e., the pivot element will be
on the main diagonal of the Tucker table.
The polyhedron of admissible solutions ΓP for the problem P(ϵ, t)
is called Minty-Klee poly edar. Note that if we make the appropriate
shifts of variables, the Minty-Klee polyhedron can also be described
by the following by a system of inequalities:
min
yn
subj.
y1 ≤1
ϵy1 ≤
y2 ≤1 −ϵy1
ϵy2 ≤
y3 ≤1 −ϵy2
...
ϵyn−1 ≤
yn ≤1 −ϵyn−1
y ≥0
Geometrically,
the
last
system
represents
a
deformed
n-
dimensional unit hypercube.
Minty-Klee polyhedra and their properties have been studied by a
number of authors. With repeated repetition of appropriate inequal-
ity, it was shown in [19] that a certain class of interior-point method
also has exponential complexity at worst. In [20], we have considered
a variant of simplex methods in which both pivot columns and pivot

Simplex Method
161
species are selected at random. In this case, the expected number of
iterations for the example was calculated Pn(ϵ, t) which is:
n ( 1)k+1
n
k
π
1
Gn(y¯) = n + 2
X −
k + 2
k=1

−
2

≈

4 −2

n2.


Chapter 3
Three Direct Methods in Linear
Programming
In addition to the classic simplex methods, there are alternative meth-
ods for solving problems in linear programming that based on either
the geometric properties of the constraint set [10, 16] or on general in-
verses [47, 45]. We also mention papers relating to Banach premises
[31]. We describe the results of a similar type in this chapter and
introduce three diﬀerent methods for solving problems in linear pro-
gramming that satisfy certain conditions. The ﬁrst method ﬁnds a
starting point that represents either an extreme point or an adjacent
point extreme point. The second method is based on game theory,
and the third method is based on general inverses. In the event that
the conditions for ﬁnding the extreme point directly are not satisﬁed,
these methods can be applied to construct the initial points for the
classic simplex method. Improved eﬃciency simplex method, with
the starting point obtained by applying new one’s method, is com-
pared with the original simplex method as well as the method’s inner
points, as illustrated by several characteristic examples. In addition,
the elimination of dependent constraints on the linear programming
problem is considered. By the end of this section, we are following
the papers [52, 53] and [47].
163

164
Advances in Optimization and Linear Programming
3.1
Basic Terms
Consider the problem of linear programming in which the con-
straints are inequalities. Determine the maximum of the linear objec-
tive function
X
n
ω(y) =
γjxj = cx
(3.1.0.1)
j=1
relative to linear constraints
X
n
αijyj = riy ≤βi,
i = 1, . . . , m
j=1
yj
≥0, j = 1, . . . , n
(3.1.0.2)
where riy, i=1, . . . , m scalar product of vectors ri i y, i
γ =(γ1, . . . , γn), y=(y1, . . . , yn), ri =(αi1, . . . , αin),
i=1, . . . , m.
We consider the following problem: generate a convenient starting
point for the simplex method, with the aim of reducing the required
number of iterative steps to ﬁnd the optimal solution. It was ob-
tained a method that is applicable to linear problems programming
that is deﬁned without dependent conditions. It turns out that the
same method is sometimes applicable to linear programming prob-
lems where dependent conditions exist.
Below we introduce the method (the so-called method of mini-
mum angles), to speed up simplex methods in some classes of linear
problems programming. The worst-case method makes a convenient

Three Direct Methods in Linear Programming
165
point for the start of the standard simplex algorithm. That point is
the solution linear system obtained after replacing l ≤n electives re-
strictions with corresponding equations whereby n−l variables equal
ce ne with zero. For some linear problems programming a simplex
method only if tvr ju is a point selected the optimal solution and the
algorithm ﬁnishes in just one step. In the worst case, the method of
minimal angles gives the topics convex together that is adjacent to
the extreme point. This method of minimal angles provides, in certain
cases, a signiﬁcantly reduced number of iterative steps compared to
the classic simplex method. In addition to accelerating convergence,
the dimension of the problem is reduced for certain types of problems.
The basic prerequisite for the successful application of minimum an-
gle methods is yes is to give the problem without any constraints.
For these reasons, we also consider the problem of eliminating de-
pendent constraints. One direct method based on game theory is also
introduced. Some linear programming problems can be solved to be
obtained directly, while some of its problems eliminate the necessary
restrictions.
In the fourth section, appropriate algorithms for the introduced
ones are developed. Here are the most important details of implement-
ing methods minimum angles in the software package MATHEMATICA.
The eﬀectiveness of the presented methods is shown in several il-
lustrative examples. These examples are also compared with standard
simplex method dom as well as with internal point methods.

166
Advances in Optimization and Linear Programming
3.2
Minimum Angle Method
The main idea behind [53] is to improve the choice of initial bases.
It is well known that the optimal theme is formed as the intersection
of n constraints, where n is the number of variables in the LP. Such
n constraints that form the optimal theme should capture the least
angles with the objective function.
The following deﬁnition is required to describe the minimum angle
method.
Deﬁnition 3.2.1. Let P ⊆Rn be polyhedron (convex set or cone)
deﬁned without any inequalities with:
X
n
P :
αijyj = riy ≤βi,
i = 1, . . . , m.
j=1
The tangential polyhedron P 0 polyhedra P is deﬁned by the fol-
lowing set of inequalities:
n
P 0 :
X
αijyj = riy
j=1
≤|ri|,
|ri| =
q
α2
i1 + · · · + α2
in, ß = 1, . . . , m.
The method presented in the following theorem is straightforward
and convenient linear programming problems (3.1.0.1)–(3.1.0.2) are
deﬁned as optimal pitch in just one step. We will now describe the
main idea of that method. In the event that the problem is linear
programming with only two variables, we can apply the graphical
procedure for solving [46, 64]. Suppose the restrictive conditions are
given by inequalities, each of the corresponding real parts equal to

Three Direct Methods in Linear Programming
167
the set of admissible and the set of impermissible points for the given
conditions. The permissible points are in the P area, which satisﬁes
all the conditions given. The optimal solution can now be determined
by drawing the graph of the modiﬁed objective function ω(y1, y2) = 0
i by its parallel displacement in the direction of the gradient vector
(γ1, γ2). The optimal solution is unique if the right one ω(y1, y2) =
ωmax passes through only one topic (extreme point) of the permissible
area. In the case of a minimization problem, we move the given right
parallel in the opposite direction.
It is well known that in the n -dimensional case the theme is
admissible polyhedra determines by solving the appropriate system
with n equation given by bounding conditions ma. In the following
theorems we introduce the criterion for the convenient choice of these
equations, which is based on the generalization and formalization of
the graphical method. This gives us the main result of this section.
Theorem 3.2.1. [53] Let the maximization problem of the linear be
given programming (3.1.0.1) - (3.1.0.2) without any inequalities. Let
it is P ⊆Rn polyhedron deﬁned by (3.1.0.2). With γ = (γ1, . . . , γn)
we denote the gradient vector of the target function. The vectors ri
are deﬁned by ri = (αi1, . . . , αin), i = 1, . . . , m. Consider the set
V =

cri
vi =
, |r | =
q
α2
2
i
i1 + · · · + αin,
i=1, . . . , m
|ri|

(3.2.0.
.
1)
Suppose that V contains l positive elements, denoted by vi1, . . . vil.
We distinguish the following cases:
(1) If P is an empty set, there is no solution to the problem.

168
Advances in Optimization and Linear Programming
(2) If l = 0, then ωmax = +∞, where ωmax denotes the maximum
value of the objective function ω(y).
(3) If l ≥n, let y0 be the solution of the following system of equa-
tions:
αi1,1y1 + · · · + αi1,nyn = ri1y = βi1
· · ·
· · ·
(3.2.0. 2)
αin,1y1 + · · · + αin,nyn = riny = βin,
with indexes i1, . . . , in corresponding to a set of n maximum and
positive values selected from the set V . If we denote the optimal
point in P by yP , the following cases can occur:
(i) y0 = yP , or
(ii) y0 i yP belong to the same boundary hyper straight polyhe-
dra P.
(d) In the event that 0 < l < n, consider the following system:
αi1,1y1 + · · · + αi1,nyn = ri1y = βi1
· · ·
· · ·
(3.2.0. 3)
αil,1y1 + · · · + αil,nyn = rily = βil,
where
the
indices
i1, . . . , il
correspond
to
positive
values
vi1, . . . , vil from V . Basic solution y0 of problem (3.1.0.1) -
(3.1.0.2) is given by
n −l variables with zero and resolution
l equation from (3.2.0.3)

Three Direct Methods in Linear Programming
169
Example 3.2.1. To illustrate the geometric sense Theorems 3.2.1, consider
the following problem:
max ω(y1, y2) = y1 + y2
subj.(γ1)
y1/3 + y2 ≤1
(γ2)
y1 + y2 ≤2
(γ3)
y1 + y2/3 ≤1.
The minimum angle is captured between the gradient vector γ = (1, 1)
target functions and make W2 ≡y1 + y2 = 2. Angles between the vectors γ
and the real W1 ≡y1/3 + y2 = 1 and W3 ≡y1 + y2/3 = 1 are identical. If
we take two angles between the vectors γ and the hyper straight W2 and W3,
then the solution y0 = W2 ∩W3 satisﬁes y0 = (1/2, 3/2) ∈/ P. Similarly, if
we take hyper straight W2 and W1, we get y0 = W2 ∩W1 = (3/2, 1/2) ∈/ P.
The optimal solution yP is in the dark yP = (3/4, 3/4). However, y0 and
yP are common elements on the real W2. Condition (γ2) is dependent. If
the condition (γ2) is eliminated, we get y0 = yP = (3/4, 3/4).
Remark 3.2.1. If the polyhedron P is deﬁned without dependent
constraints, then the 3.2.1 theorem can be successfully applied. If the
system the inequality (3.1.0.2) contains several dependent constraints
Ho
ˇ wever, it is possible that some of the minimum angles in (3.2.0. 1)
are determined by dependent constraints. In this case, it may be that
y0 ∈/ P, so that points y0 and yP are not elements of the same hyper-
link of P. Of course, in this case too y0 can be used as a starting point
for simplex method, but convergence acceleration is not guaranteed
in that case. In fact, for the successful application of Theorem 3.2.1,
it is suﬃcient is that none of the l minimum angles is caught with
anyone by a dependent restriction. This provides the motivation for
the elimination of dependent restrictions, which is discussed in the
next section.

170
Advances in Optimization and Linear Programming
Remark 3.2.2. The method used in the case of 0 < l < n is also
possible apply also in the case of m < n. In that case, proposed
the method is a modiﬁcation of a positive method for constructing
a basic one solutions from [8]. Note that [8] is basic problem solving
(3.1.0.1)–(3.1.0.2) for which m < n applies, obtained by equating
n −m variables with zero and solving m equations.
Remark 3.2.3. The method of minimum angles gives the basic solu-
tion that belongs to the same hyperlink as the extreme point. Apart
from these signiﬁcant properties, we emphasize the following signiﬁ-
cant property of this method. U simplex method all restrictions are
used in every step as well you add leveling variables. In minimum an-
gle methods, the number of active restrictions is lower than the stan-
dard simplex algorithm. Moreover, with the minimum angle methods,
leveling variables are not used. Hence the dimension of the problem
is considered with the method of minimum angles, which is signif-
icant smaller than the dimension of the corresponding application
problem simplex method. So, replacing several iterations of simplex
methods with only one application of the minimum angle method, it
usually means it reduces the number of operations required and the
processing time.
Remark 3.2.4. The work [66] gives a counter-example where Theo-
rem 3.2.1 don’t mind. Later in his master’s thesis, Wang [65] showed
that the example from [66] is incorrect because it contains dependent
restrictions; then gave a radical counter-example. That said, based on
the papers [42], Theorem 3.2.1 can be used as a successful heuristic to
ﬁnd the starting point of a simplex algorithm or, under suitable con-
ditions, the optimal points of a linear problem. Let us also mention
that the work [52] apart from [66, 65] is also cited in [2].

Three Direct Methods in Linear Programming
171
3.3
Dependent Constraints and Application of Game
Theory
At the beginning of this section, we introduce several rules for
elimination of dependent on ra ni ce nja. These rules are also useful in
the case are hearing transformations of the problem (3.1.0.1)–(3.1.0.2)
into a form suitable for the application of simplex methods. This
section is based on papers [52] and [53].
It is known that Gaussian elimination or QR factorization can
be applied to eliminate redundant restrictions [14, 64]. However, the
following issues occur jumps.
A. Before applying Gaussian elimination, inequalities must be
transformed into appropriate equations. That way, the dimension of
the system to which the Gaussian elimination is applied usually very
signiﬁcant increases.
B. What’s more, rounding errors and need the number of arith-
metic operations is signiﬁcant in many cases with teas.
C. The Gaussian elimination process is linear only dependent con-
straints of the equality type. Application of the simplex algorithm
usually requires the introduction of supplementary variables. In that
in the equivalent form, the constraint matrix A is ordinary full rank,
so the problem incomplete rank is not of great importance in practice
[71].
Implementation of intrinsic point methods for linear problems
large-scale programming usually contains a preparatory phase to
eliminate dependent variables and dependent constraints [1]. For ex-

172
Advances in Optimization and Linear Programming
ample, the preparatory phase of PCx executes several types of elimi-
nation of dependent variables and dependent ones restrictions [15].
The preparation phase in PCx is running into problems linear shape
programming. The preparatory phase checks the input data with re-
spect to the following elimination rules [15].
Blank Types. If the matrix A has a zero type and a corre-
sponding zero coordinate in vector β, this type can be omitted from
considerations.
Duplicate Types. When the matrix type is A (and the corre-
sponding element from constraint vector β) is proportional to an-
other, she may be left out.
Duplicate Columns. When the column of the matrix A is pro-
portional to another column, the two columns can be combined. In-
bound uniﬁed column variables are either normal or free, hundred
depends on whether the column proportionality factor is positive or
negative.
Fixed variables. If the variable has zero for the above and lower
limits, it is obvious that it is possible here equate the variable to zero
and omit the problem.
Single-element types. If and are the matrix type A contains
only one element αij diﬀerent from zero, it is clear that yj = βi/αij,
so that variable can be eliminated from problems. Also, the and-that
type of matrix A can be omitted.
One-element columns. When αij is the only element diﬀerent
čit from zero in column j of matrix A, and yj is free variable, then
variable yj can be expressed via other variables that occur in the and
type matrix A i eliminate it from the problem. Even if the variable is
not free, yj can be eliminated if its constraints are weaker from the

Three Direct Methods in Linear Programming
173
restrictions that follow from the domain of the other elements that
ﬁgure in the form αi. A similar technique was used in [1]. However,
some of the dependent restrictions are not covered by the consider-
ations described u [1] and [15]. As noted in [1], in the case of linear
programming problems, the dimension cannot eliminate all the in-
equalities manually. Thus, the analysis of the preparatory phase aims
at improvement problem formulations. To this end, we propose a few
additional rules in this section to eliminate redundant restrictions.
The ﬁrst rule is based on the almost sharp geometric properties of
some dependent boundaries ˇappreciates.
Consider the following limitations with respect to (3.1.0.2):
1 riy =
e
βi
X
ijyj
≤1,
i = 1, . . . , m
yj
≥0,
j = 1, . . . , n.
(3.3.0. 1)
α
where
ij
eij =
, βi = 0, i = 1, . . . , m, j = 1, . . . n. If it is condition
βi
(∃p, q)(1 ≤p, q ≤m) eps ≥eqs,
s = 1, . . . , n,
(3.3.0. 2)
satisﬁed, then q-this limit not from (3.3.0.1) (respectively (3.1.0.2))
may be omitted.
However, this rule of elimination is not universal. For example,
depending on the constraint not (γ2) from the problem (3.2.1) does
not satisfy the condition (3.3.0.2).
In the following theorem, a well-known result from game theory
is applied, and several additional rules for elimination are deﬁned as
a well direct method for solving some types of linear programming
problems.
̸

174
Advances in Optimization and Linear Programming
Theorem 3.3.1. [53] Consider the following linear programming
problem: from edit the maximum of the objective function
n
with(y) =
X
cjxj = cx,
γj > 0, j = 1, . . . , n
j=1
in relation to restrictions
X
n
aijyj = riy
≤
βi, βi > 0,
i=1, . . . , m,
(3.3.0. 3)
j=1
yj
≥
0,
j =1, . . . , n.
α
Suppose it is valid
ij
dij =
,
i = 1, . . . , m, j = 1, . . . , n. Then
βicj
the following statements apply:
(1)In case
max
min dij = min
max dij = dkl,
(3.3.0. 4)
1≤i≤m 1≤j≤n
1≤j≤n 1≤i≤m
the optimal solution to the problem (3.1.0.1) −(3.1.0.2)is
β
l
yj =



k ,
j = ,
αkl
(3.3.0. 5)
0,
j = l.
(2) If


max
min dij = min
max dij
1≤i≤m 1≤j≤n
1≤j≤n 1≤i≤m
and if there are k, l such that dik ≥dil, and1, . . . , m, then it pulls
that yk =0, so that we can omit the k column.
Also, if there are k, l such that dkj ≤is valid dlj, j = 1, . . . , n,
then we can omit the k type.
̸
̸

Three Direct Methods in Linear Programming
175
Proof. Let yj = γjxj, j = 1, . . . , n. Then there is the problem
n
(3.3.0.3) is equivalent to the problem ω(y) = P
j=1 yj →max with
restrictions
X
n
dijyj ≤1,
i = 1, . . . , m,
yj ≥0, j = 1, . . . , n.
j=1
Note that this linear programming problem is equivalent to play-
ing two players with a payment matrix D = ||dij|| [39, 53]. Denote
the optimal strategy for the other players vector q = (q1, . . . , qn).
(1) If the condition (3.3.0.4) is satisﬁed, then the optimal strategy
for another player pure strategy ql = 1, qj = 0, j <> l. How is
qj
γjxj =yj =
, where is to game value, we get [39] yj = 0, j = l i
v
yl = max
1≤i≤m
αil
βi

β
= min
1≤i≤m

i
αil

βk
=
.
αkl
(2) If k, l such that dik ≥dil, i = 1, . . . , m, then from game theory
follows qk = 0, hundred drag yk = 0 [39]. So, we can omit k-th column.
If there are k, l such that dkj ≤dlj, j = 1, . . . , n, then
X
n
X
n
dljxij ≤1 ⇒
dkjxij ≤1, for arbitraryxij > 0, j = 1, . . . , n
j=1
j=1
such that k-this limit is dependent.
General Theorems 3.3.1 can be found in [65].
Remark 3.3.1. If all redundant constraints are eliminated, then the
condition is y0 ∈P ﬁlled. Unfortunately, the proposed algorithms for
̸

176
Advances in Optimization and Linear Programming
eliminating redundant restrictions does not guarantee complete elim-
ination. For example, the dependent constraint (γ2) on the problem
(3.2.1) remains after all eliminations. In that case, the basic solution
is constructed using the method use minimal angles as a starting
point for applying the simplex algorithm.
3.4
Algorithms and Implementation Details
In accordance with Theorem 3.2.1 we introduce two algorithms,
denoted by Algorithm An and Algorithm Al for implementing mini-
mum angle methods. These algorithms can be used to maximize the
objective function (3.1.0.1) under restrictions (3.1.0.2), and they are
possible to apply in the case of l ≥n.
An algorithm
Step 1. Eliminate redundant restrictions, using the results in the
previous section and Gaussian elimination.
γr
Step 2. Calculate values
i
vi = |γ| cos(γ, ri) =
,
i = 1, . . . , m.
|ri|
Step 3. Determine n maximum and positive values
vi1 ≥· · · ≥vin > 0
from set {v1, · · · vm}.
Step 4. Calculate y0 as a solution of the system of equations
(3.2.0.2).
Step 5. Check that y0 is basic admissible solution (y1≥0, . . . , yn ≥
0), because implementation of simplex methods in the next step.

Three Direct Methods in Linear Programming
177
Step 6. If the condition is from the previous step ﬁlled in, apply
the simplex method algorithm SimMax from of Section 1.2 for the
basic admissible solution [64]). Otherwise, apply the simplex method
preparatory algorithm PreSim Max from Section 1.2, which generates
the ﬁrst base word ˇand complete the algorithm for basic permissible
solution [64].
Some software details ofAlgorithm An implementation are de-
scribed below. The internal form of the problem posed in (3.1.0.1)
contains two diﬀerent parts. The ﬁrst part is an arbitrary target
function, determined by the corresponding an expression from the
MATHEMATICA package, denoted by a parameter objective. The second
part is a list of selected restrictions that we call constraints. Accord-
ing to the internal linear form programs required infunctions Lin-
earProgramming,ConstrainedMin, and ConstrainedMax from MATH-
EMATICA [67, 69], we omit the list of variables used in the target
function and the constraints given. The list of variables we omit for
ease of use. That list is can be reconstructed using the standard
V ariablesfunction and Union (see [68] and [69] for these functions).
For this purpose, we deﬁne the following function that extracts the
list lis_.
3.5
Direct Heuristic Algorithm with General Inverses
In this section, we give an algorithm from [47]. This heuristic
method very often gives either the optimal or the solution from which,
using the simplex method, obtains the optimal solution by applying

178
Advances in Optimization and Linear Programming
a small number of iterations. The basic idea of this method is to show
the general solutions of the linear system Ay = β bypseudoinverse A†
(Moore-Penrose general inverse) matrices A. More about the Moore-
Penrose inverse as well as other general (generalized) inverses oper-
ator and matrix can be found in the monographs [4]. Let’s just say
it is matrix A† unique solution of the following system of matrix
equations:
AXA = A,
XAX = y,
(Ay)∗= Ay,
(XA)∗= XA
Other general inverses of the A matrix are similarly deﬁned. There
are several methods for calculating Moore-Penrose and other gen-
eralized matrix inverses. A method known in the literature as the
Leverrier-Faddev or Souriau-Frame method uses the characteristic
polynomial of the matrix A. This method is primarily intended for
symbolic purposes calculation of general inverses. In [48], a modiﬁ-
cation of the method Leverrier-Faddev is examined, if the matrix A
is a polynomial matrix. Let’s also mention the partitioning method
in which the Moore-Penrose inversion is calculated using appropri-
ate recurrent formulas. Modiﬁcations to this method for polynomial
matrices of one or more variables are shown in the papers [44].
We consider the problem of linear programming in standard form:
min
γT x,
subj.
Ay = β,
(3.5.0. 1)
y ≥0.

Three Direct Methods in Linear Programming
179
The algorithm input is A, β, γ while the output is vector y, the
value of the objective function ω, and the comments based on the
optimality test. Algoritam D2.
Step 1. Load m, n, A = [αij], β, γ.
Step 2. Calculate d = A†β, where d = [di] is the vector of dimen-
sion n × 1 a A† is a Moore-Penrose inverse (or p -inverse) and let
e = Ad.
If e = β, the output is “The problem is intolerable” and the algo-
rithm stalls.
Step 3. Calculate
W = A†A,
γ′ = (nI −W)γ,
sk = min
di
γi
′ |γi
′ > 0
,
y = d −γ′sk,
o
where γ′ = [γi
′] n×1 vector, I is n×n unit matrix, W is n×n matrix.
The direction vector γ′sk tries to make the vector y move from set of
solutions of equation Ay = β to set of permissible solutions deﬁned
by Ay = β, y ≥0 if he is no longer in it. The solution will be the
extreme point of the set of permissible solutions.
Step 4. Remove that unknown yi that equals zero, remove and
column of the matrix A and the corresponding coordinate γi from
the vector γ of the objective function. Calculate d = A†β.
Remark 3.5.1. The following matrix A† in Step 4 was calculated
from the previous A†. This calculation requires a O(mn) operation.
It is possible to calculate A+ from A, but this requires a O(mn2) oper-
̸

180
Advances in Optimization and Linear Programming
ation. If two or more coordinates yi equate to zero, one should apply
the algorithm by eliminating one yi and compute the corresponding
vector y. The vector y that gives the minimum of the objective func-
tion of the solution (output) of the algorithm will be sought. There is
no suitable criterion for deciding which of two (or more) coordinates
of yi that equals zero will be dropped from the base. However, such a
situation is not so common.
Step 5. Repeat Steps 3 and 4 until sk = 0 or cannot be calculated
(i.e., γi
′ ≤0 for every i).
Step 6. Calculate the value of the objective function ω = γT x
where they are y and γ obtained in the last step of the algorithm and
throw out the result.
Optimality Test. Let be the vector we get using the algorithm,
and let A, β, and γ from (3.5.0. 1) be known. Let B be a basic
matrix that consists of columns of matrix A corresponding to the
basic coordinates yi vectors y, let γτ
B be a vector consisting of the
coordinates of the vector γ which correspond to the basic coordinates
of the yi vector y, and let pj j be that column of a nonbasic column
of A.
Step 7. Calculate yτ = γτ
BB−1 (species vector).
Step 8. Compute ωj −γj = yT pj −γj for all nonbasic vectors pj.
Step 9. If ωj −γj ≤is 0 for every j, then the solution is op-
timal; otherwise, the solution is unlimited, or the algorithm cannot
determine the optimal solution. In this case, the optimal solution is
obtained by applying a simplex algorithm using the vector y as a
valid starting point.
D2 algorithm comment.

Three Direct Methods in Linear Programming
181
In Step 1, we load the data. Step 2 checks the agreement of the
equations Ay = β. In the case of e = AA†β = β, the problem has no
acceptable solution. The general solution of Ay = β is y = A†β ±Pz,
where P = (I −AA†) an orthogonal projection operator that projects
an arbitrary vector ω orthogonally to null space of matrix A. We
calculate the point γ′ in the null space of the matrix A in Step 3.
The vector y = d −γ′sk = A†β −(I −A†A)csk is the form A†β −Pz.
where csk corresponds to an arbitrary vector column ω. Scalar sk is
calculated in Step 3 this way for two reasons:
(i) one (or more) coordinates of yand vectors y are equal to zero,
(ii) the value of the objective function decreases.
In addition, the vector y moves to the set of admissible solutions,
if it is not already in it. Sometimes (quite rarely), it happens that the
base coordinate equals zero and is marked as non-base. A problem
has been opened under which the necessary and suﬃcient conditions
cannot happen.
In Step 4, the variables yi are eliminated, which equals zero. In
numerical experiments, in more than 95 % of the problems, such
coordinates are nonbasic.
In Step 5 we check the criterion for the end of the algorithm,
while in Step 6, we provide output. In Steps 7, 8, and 9, we check
that the solution is optimal. Most often, the matrix is B square and
insigniﬁcant, and in this case, we check the optimality of the solution
directly.
If the matrix B is rectangular (m < n), then we add one (or more)
types to the matrix B and one (or more) corresponding elements to
vector β such that the newly acquired matrix B and the vector β does
not change the vector y and, in doing so, B is a square non-singular
̸

182
Advances in Optimization and Linear Programming
matrix. Then apply the optimality test as in Steps 7, 8, and 9. If not
ωj −γj ≤0 for every j, let’s apply a simplex algorithm using y as a
starting point.

Bibliography
[1] Andersen, E. D., Gondzio, J., Meszaros, C., & Xu, X., (1996). Imple-
mentation of Interior Point Methods for Large Scale Linear Program-
ming. Technical report, HEC, Universite de Geneve.
[2] Angel, S. P., & Pablo, G. G., (2001). Solving a Sequence of Sparse
Compatible Systems. 19th biennial conf. numerical analysis, Dundee,
Scotland.
[3] Bertsimas, D., & Tsitsiklis, J. N., (1997). Introduction to Linear Op-
timization. Athena Scientiﬁc, Belmont, Massachusetts.
[4] Ben-Israel, A., & Greville, T. N. E., (2003). Generalized Inverses: The-
ory and Applications (2nd edn., Vol. 15). CMS Books in Mathematic-
s/Ouvrages de Mathmatiques de la SMC, Springer-Verlag, New York.
[5] Bhatti, M. A., (2000). Practical Optimization with Mathematica Ap-
plications. Springer Verlag, Telos.
[6] Bixby, R., (1992). Implementing the simplex method: The initial basis.
ORSA Journal on Computing, 4, 267–284.
[7] Bland, R. G., (1977). New ﬁnite pivoting rules for the simplex method.
Mathematics of Operations Research, 2, 103–107.
[8] Bounday, B. D., (1984). In: Edvard, A., Basic Linear Programming.
Baltimore.
[9] Charnes, A., (1952). Optimality and degeneracy in linear program-
ming. Econometrica, 20(2).
[10] Conn, A. R., (1976). Linear programming via a nondiﬀerentiable
penalty function. SIAM J. Numer. Anal., 13(1), 145–154.
183

184
Advances in Optimization and Linear Programming
[11] Cormen, T. H., Leiserson, C. E., Rivest, R. L., & Stein, C. (2009).
Introduction to algorithms. MIT Press.
[12] Chankong, V., & Haimes, Y. Multiobjective decision making: Theory
and methodology Series, Volume 8, North-Holland, New York, Ams-
terdam, Oxford, 1983.
[13] Cvetkovic, D., Cangalovic, M., Dugosija, D. J., Kovacevic-Vujcic, V.,
Simic, S., & Vuleta, J., (1996). Combinatorial Optimization, Drustvo
operacionih istrazivaca Jugoslavije DOPIS, Beograd. In Serbian.
[14] Cvetkovic, D., (1996). Discrete Mathematics. Prosveta, Nis. In Ser-
bian.
[15] Czyzyk, J., Mehrotra, S., & Wright, S. J., (1996). PCx User Guide,
(pp. 1–21). Optimization technology center, Technical Report 96/01.
[16] Dantzig, G. B., (1949). Programming of interdependent activities,
mathematical model. Econometrica, 17, 200–211.
[17] Das, I., & Dennis, J. E. (1997). A closer look at drawbacks of minimiz-
ing weighted sums of objectives for Pareto set generation in višekri-
terijumska optimizacija problems, Struct. Optim. 14 63–69.
[18] Dax, A., (1988). Linear programming via least squares. Linear Algebra
and its Applications, 111, 313–324.
[19] Deza, A., Nematollahi, E., & Terlaky, T., (2004). How Good are Inte-
rior Point Methods? Klee-Minty Cubes Tighten Iteration-Complexity
Bounds. AdvOL-Report #2004/20 Advanced Optimization Labora-
tory, Department of Computing and Software, McMaster University,
Hamilton, Ontario, Canada.
[20] Gartner, B., Henk, M., & Ziegler, G. M., (1998). Randomized simplex
algorithms on Klee-minty cubes. Combinatorica, 18, 349–372.
[21] Gondzio, J., (1995). HOPDM (Version 2.12), A fast LP solver based on
a primal-dual interior-point method. European Journal of Operations
Research, 85, 221–225.

Bibliography
185
[22] Hitchcock, G. L., (1941). The distribution of a product from several
sources to numerous localities. Journal Math. Phys., 20, 224–230.
[23] Hwang, C. L. & Yoon, K. (1981). Multiple attribute decision making
methods and applications: a state-of-the-art survey. In: Beckmann, M.,
& Kunzi, H. P. (eds.) Lecture Notes in Economics and Mathematical
Systems, No. 186. Berlin: Springer-Verlag.
[24] Hobbs, B. F. (1980). A comparison of weighting methods in power
plant siting., Decis. Sci., 11 725–737.
[25] Ivanovic, V., (1940). Pravila za proracun potrebnog broja transportnih
sredstava, Vojno-Izdavacki Glasnik, Sveska 1–10.
[26] Kantorovich, L. V., (1939). Matematicheskie Metodi v Organizacii I
Planirovanii Proizvodstva. In Russian. Izd. LGU.
[27] Khachian, L. G., (1979). A Polynomial algorithm in linear program-
ming. Doklady Akademii Nauk SSSR, 244(5), 1093–1096.
[28] Klee, V., & Minty, G. L., (1972). How good is the simplex method?
In: Shisha, O., (ed.), Inequalities III (pp. 159–175). Academic Press,
New York.
[29] Klee, V., & Kleinschmidtm, P., (1987). The d-step conjecture and its
relatives. Math. Operations Research, 12, 718–755.
[30] Kotiah, T. C. T., & Steinberg, D. I., (1977). Occurrences of cycling
and other phenomena arising in a class of linear programming models.
Communications of the ACM, 20, 107–112.
[31] Kulkarni, S. G., & Sivakumar, K. C., (1995). Applications of gener-
alized inverses to interval linear programs in Hilbert spaces, Numer.
Funct. Anal. Optimiz., 16(7/8), 965–973.
[32] Lukovic, M., Lukovic, V., Belca, I., Kasalica, B., Stanimirovic, I., &
Vicic, M., (2016). LED-based Vis-NIR spectrally tunable light source-
the optimization algorithm. Journal of the European Optical Society-
Rapid Publications, 12–19, doi: 10.1186/s41476-016-0021-9.

186
Advances in Optimization and Linear Programming
[33] Maeder, R. (1996). Programming in Mathematica, Third Edition, Red-
wood City, California: Adisson-Wesley.
[34] Marler, R.T. (2004). Survey of multi-objective optimization methods
for engineering, Struct. Multidisc. Optim. 26, 369–395.
[35] Miettien, K.Nonlinear Multiobjective Optimization, Kluver Academic
Publishers, Boston, London, Dordrecht, 1999.
[36] Miettinen, K., & Kirilov, L. (2005). Interactive reference direction
approach using implicit parametrization for nonlinear multiobjective
optimization. Journal of Multi-Criteria Decision Analysis, 13(2–3),
115–123.
[37] Milovanovic, G. V., (1991). Numerical Analysis I Part. Naucna knjiga,
Beograd, In Serbian.
[38] Oliveira, V., & Pinho, P. (2010). Evaluation in urban planning: Ad-
vances and prospects. Journal of Planning Literature, 24(4), 343–361.
[39] Owen, G., (1968). Game Theory. W.B. Saunders Company, Philadel-
phia, London, Toronto.
[40] Nering, E., & Tucker, A., (1993). Linear Programs Related Problems:
A Volume in the Computer Science and Scientiﬁc Computing Series.
Elsevier.
[41] Pan, P. Q. (1990). Practical ﬁnite pivoting rules for the simplex
method. Operations-Research-Spektrum, 12(4), 219–225.
[42] Pan, P. Q., (1991). A simplex-like method with bisection for linear
programming. Optimization, 22, 717–743.
[43] Petkovic, M. D., Stanimirovic, P. S., & Stojkovic, N. V., (2002). Two
modiﬁcations of the revised simplex method. Matematicki Vesnik, 54,
163–169.
[44] Petkovic, M. D., & Stanimirovic, P. S., (2005). Symbolic computation
of the Moore-Penrose inverse using the partitioning method. Interna-
tional Journal of Computer Mathematics, 82, 355–367.

Bibliography
187
[45] Pyle, L. D., (1977). The Weighted Generalized Inverse in Nonlinear
Programming-Active set Selection using a Variable-Metric Generaliza-
tion of the Simplex Algorithm. Lecture notes in economics and math-
ematical system, Austin, Texas.
[46] Sakarovitch, M., (1983). Linear Programming. Springer-Verlag, New
York.
[47] Sen, S. K., & Ramful, A., (2000). A direct heuristic algorithm for linear
programming, Proc. Indian Acad. Sci. (Math. Sci.), 110(1), 79–101.
[48] Stanimirovic, P. S., & Petkovic, M. D., (2006). Computation of gen-
eralized inverses of polynomial matrices by interpolation. Appl. Math.
Comput., 172(1), 508–523.
[49] Stanimirovic, P. S., & Milovanovic, G. V., (2002). Programming Pack-
age Mathematica and Applications, Elektronski fakultet u Nisu, Edi-
cija monograﬁje, Nis. In Serbian.
[50] Stefanovic-Marinovic, J., Petkovi c, M., & Stanimirovi c, I., (2015).
Application of the ELECTRE method to planetary gear train op-
timization. Journal of Mechanical Science and Technology, 29(2),
647–654.
[51] Stefanovic- Marinovic, J., Petkovic, M., Stanimirovic, I., & Milo-
vančevi c, M., (2011). A model of planetary gear multicriteria op-
timization. Transactions of Famena, 35(4), 21–34.
[52] Stojkovic, N. V., & Stanimirovic, P. S., (1999). On elimination of ex-
cessive constraints in linear programming. SYMOPIS, 207–210.
[53] Stojkovic, N. V., & Stanimirovic, P. S., (2001). Two direct methods in
linear programming. Europ. J. Oper. Res., 131(2), 417–439.
[54] Stojkovic, N. V., Stanimirovic, P. S., & Petkovic, M. D. (2009). Mod-
iﬁcation and implementation of two-phase simplex method. Interna-
tional Journal of Computer Mathematics, 86(7), 1231–1242.
[55] Strayer, J. K. (2012). Linear programming and its applications.
Springer Science Business Media.

188
Advances in Optimization and Linear Programming
[56] Tasic, M., Stanimirovic, P. S., Stanimirovic, I. P., Petkovic, M. D.,
& Stojkovic, N. V., (2005). Some useful MATHEMATICA teaching
examples. Facta Universitatis (Nis) Series Electronics and Energetics,
18(2), 329–344.
[57] Stanimirovic, P., & Stanimirovic, I., (2008). Implementation of poly-
nomial multi-objective optimization in MATHEMATICA. Structural
and Multidisciplinary Optimization, 36, 411–428.
[58] Stanimirovic, I., (2013). Successive computation of some eﬃcient lo-
cations of the weber problem with barriers. Journal of Applied Math-
ematics and Computing, 42, 193–211.
[59] Stanimirovic, I., (2012). Compendious lexicographic method for multi-
objective optimization. Facta Universitatis (Niš) Ser. Math. Inform.,
27(1), 55–66.
[60] Stanimirovic, I., Zlatanovic, M., & Petkovic, M., (2011). On the linear
weighted sum method for multi-objective optimization. Facta Univer-
sitatis (Niš) Ser. Math. Inform., 26, 47–62.
[61] Stanimirovic, I., Petkovic, M., Stanimirovic, P., & Ciric, M., (2009).
Heuristic algorithm for single resource constrained project scheduling
problem based on the dynamic programming. YUJOR, 19, 281–298.
[62] Vanderbei,
R.
J.,
(1994).
LOQO: An Interior-Point Code for
Quadratic Programming, Technical Report SOR-94-15. Department
of Civil Engineering and Operations Research, Princeton University,
Princeton, N.J.
[63] Voogd, H. (1983). Multicriteria Evaluation for Urban and Regional
Planning, London: Pion.
[64] Vukadinovic, S., & Cvejic, S., (1996). Mathematical Programming.
Univerzitet u Pristini, Pristina, In Serbian.
[65] Wang, C. M., (2004). Comments on Two Direct Methods in Linear
Programming. Master Thesis, Windsor, Ontario, Canada.
[66] Wei, L., (2004). A note on two direct methods in linear programming.
Europ. J. Oper. Res., 158, 262–265.

Bibliography
189
[67] Wolfram, S., (1991). Mathematica: A System for Doing Mathematics
by Computer. Addison-Wesley Publishing Co, Redwood City, Califor-
nia.
[68] Wolfram, S., (1996). Mathematica Book, Version 3.0. Wolfram Media
and Cambridge University Press.
[69] Wolfram, S., (1999). The Mathematica Book (4th edn.), Wolfram Me-
dia/Cambridge University Press.
[70] Wolfram, S. (2003). The MATHEMATICA Book, 5th ed., Wolfram
Media/Cambridge University Press, Champaign, IL 61820, USA.
[71] Wright, S. J., (1997). Primal-dual interior-point methods. Society
for Industrial and Applied Mathematics. Primal-Dual Interior-Point
Methods. SIAM, Philadelphia.
[72] Zang, Y., (1995). User’s guide to LIPSOL. Department of Mathemat-
ics and Statistics, University of Maryland, Baltimore County, Balti-
more, MD, USA.


Index
αB, 65
αN, 65
AB, 65
algoritam
D2, 179
Replace, 83
SimplexStandardMin, 87
algorithm, 2
An, 176
dual simplex, 134
ElJed, 141
ElSl, 142
RevBasicMax, 147
RevNoBasicMax, 148
SimplexStandardMax, 82
baza
dopustiva, 65
Columns
Duplicate, 172
columns
one-element, 172
cycling, 150
decision maker, 7
dependent restrictions, 171
function
target, 22
unlimited from below, 68
GEOM, 61
HOPDM, 32
hyperlink, 36
ideal values of objective
functions, 6
inverse
general, generalized, 178
Moore-Penrose, 178
LOQO, 32
LINDO, 33
LIPSOL, 32
191

192
Index
linear programming, 22
general form, 33
Matrix form, 37
standard format, 37
symmetric shape, 38
MOSEK, 32
marginal solution, 5
MATHEMATICA, 2, 10, 16
MATLAB, 2
matrix
adjacent, 46
basic (basic), 45
method
BigM, 102, 116
Complexity, 156
Leverrier-Faddev, 178
lexicographic, 151
minimum angles, 164
Pareto optimality test, 15
Partitioning, 178
Revised simplex, 144
metod
geometrijski, 54
simpleks, 63
Minty-Klee polyhedron, 160
ΓD, 127
ΓP , 43
Pn(ϵ, t), 157
PCx, 32
Pareto optimum, 7, 15
Strict, 8
weak, 8
payment matrix, 175
points
ideal, 6
problem, 4
basic admissible, 67
canonical shape, 66
dual, 125
Multiobjective
optimization, 3, 5, 12
primal, 126
prosireni, 104
spreadsheet, 69
re v shadow
perfect hay, 6
rules
anticyclical, 150
Bland’s, 151
scalar optimization, 17
set
constraints, 29
Convex, 44
simplex, 44
simbolic calculation, 10

Index
193
solution
basic, 42
basic admissible, 46
Minimal, 38
Optimal, 35
sparse matrix, 145
symbolic computation, 11
symbolic computations, 2
table
extended Tucker’s, 77
Tucker’s, 77
tacka
ekstremna, 46
the algorithm
SimpleksMax/Sim-
pleksMin,
113
Theorem
Karash-Kuhn-Tucker, 128
Kronecker-Capellija, 41
Two-phase simplex, 103
Types
Blank, 172
Duplicate, 172
types
single-element, 172
variables
Dependent (basic), 45
expert, 104
ﬁxed, 172
free (independent), 39
independent (non-base),
45
leveling, 40
Slack, 39
vectors
convex combination, 44
Weierstrass theorem, 61
weight coeﬃcient method, 17
weight coeﬃcients, 17

