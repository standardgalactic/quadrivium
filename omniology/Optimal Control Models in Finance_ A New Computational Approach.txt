

OPTIMAL CONTROL MODELS
IN FINANCE

Applied Optimization
Volume 95
Series Editors:
Panos M. Pardalos
University of Florida, U.S.A.
Donald W. Hearn
University of Florida, U.S.A.

OPTIMAL CONTROL MODELS
IN FINANCE
A New Computational Approach
by
PING CHEN
Victoria University, Melbourne, Australia
SARDAR M.N. ISLAM
Victoria University, Melbourne, Australia
Springer

eBook ISBN:
0-387-23570-1
Print ISBN:
0-387-23569-8
Print ©2005 Springer Science + Business Media, Inc.
All rights reserved
No part of this eBook may be reproduced or transmitted in any form or by any means, electronic,
mechanical, recording, or otherwise, without written consent from the Publisher
Created in the United States of America
Boston
©2005 Springer Science + Business Media, Inc.
Visit Springer's eBookstore at:
http://ebooks.springerlink.com
and the Springer Global Website Online at:         http://www.springeronline.com

Contents
List of Figures
List of Tables
Preface
Introduction
ix
xi
xiii
xv
1.
OPTIMAL CONTROL MODELS
1
2
3
4
5
6
7
8
An Optimal Control Model of Finance
(Karush) Kuhn-Tucker Condition
Pontryagin Theorem
Bang-Bang Control
Singular Arc
Indifference Principle
Different Approaches to Optimal Control Problems
Conclusion
1
2
4
6
7
7
8
10
20
2. THE STV APPROACH TO FINANCIAL OPTIMAL CONTROL
MODELS
1
2
3
4
5
6
7
Introduction
Piecewise-linear Transformation
Non-linear Time Scale Transformation
A Computer Software Package Used in this Study
An Optimal Control Problem When the Control can only Take
the Value 0 or 1
Approaches to Bang-Bang Optimal Control with a Cost of
Changing Control
An Investment Planning Model and Results
21
21
21
23
25
26
27
30

vi
OPTIMAL CONTROL MODELS IN FINANCE
8
Financial Implications and Conclusion
36
3.
A FINANCIAL OSCILLATOR MODEL
1
2
3
4
5
6
7
Introduction
Controlling a Damped Oscillator in a Financial Model
Oscillator Transformation of the Financial Model
Computational Algorithm: The Steps
Financial Control Pattern
Computing the Financial Model: Results and Analysis
Financial Investment Implications and Conclusion
39
39
40
41
44
47
47
89
4.
AN OPTIMAL CORPORATE FINANCING MODEL
1
2
3
4
5
6
7
8
9
Introduction
Problem Description
Analytical Solution
Penalty Terms
Transformations for the Computer Software Package for the
Finance Model
Computational Algorithms for the Non-linear Optimal Control
Problem
Computing Results and Conclusion
Optimal Financing Implications
Conclusion
91
91
91
94
98
99
101
104
107
108
5.
FURTHER COMPUTATIONAL EXPERIMENTS AND RESULTS
1
2
3
4
Introduction
Different Fitting Functions
The Financial Oscillator Model when the Control Takes Three
Values
Conclusion
109
109
109
120
139
6.
CONCLUSION
141
Appendices
145
A CSTVA Program List
145
1
2
3
4
Program A: Investment Model in Chapter 2
Program B: Financial Oscillator Model in Chapter 3
Program C: Optimal Financing Model in Chapter 4
Program D: Three Value-Control Model in Chapter 5
145
149
153
156

Contents
vii
B
Some Computation Results
1
2
3
4
Results for Program A
Results for Program B
Results for Program C
Results for Program D
C
D
E
F
Differential Equation Solver from the SCOM Package
SCOM Package
Format of Problem Optimization
A Sample Test Problem
161
161
163
167
175
181
183
189
191
References
Index
193
199

This page intentionally left blank

List of Figures
2.1
2.2
2.3
2.4
2.5
2.6
Plot of n=2, forcing function ut=1,0
Plot of n=4, forcing function ut=1,0,1,0
Plot of n=6, forcing function ut= 1,0,1,0,1,0
Plot of n=8, forcing function ut= 1,0,1,0,1,0,1,0
Plot of n=10, forcing function ut= 1,0,1,0,1,0,1,0,1,0
Plot of the values of the objective function to the num-
ber of the switching times
2.7
3.1
3.2
3.3
Plot of the cost function to the cost of switching control
Plot of integral F against 1/ns at ut=-2,2
Plot of integral F against 1/ns at ut=2,-2
Plot of cost function F against the number of large time
intervals nb
5.1
5.2
5.3
5.4
5.5
5.6
5.7
5.8
Plot of n=4, forcing function ut=1,0,1,0
Plot of n=10, forcing function ut= 1,0,1,0,1,0,1,0,1,0
Results of objective function at n=2,4,6,8,10
Plot of n=4, forcing function ut=1,0,1,0
Plot of n=8, forcing function ut=1,0,1,0,1,0,1,0
Plot of n=8, forcing function ut= 1,0,1,0,1,0,1,0
Plot of nb=9, ns=8, forcing function ut=-2,0,2,-2,0,2,-2,0,2
Relationship between two state functions during the
time period 1,0
31
31
32
32
33
34
35
87
87
88
110
112
113
116
117
119
123
123

This page intentionally left blank

List of Tables
2.1
2.2
3.1
3.2
4.1
4.2
4.3
5.1
5.2
5.3
5.4
Objective functions with the number of the switching times
Costs of the switching control attached to the objective
function
Results of the objective function at control pattern -2,2, ...
Results of the objective function at control pattern 2,-2, ...
Computing results for solution case [1]
Computing results for solution case [2]
Computing results for solution case 2 with another map-
ping control
Results of objective function at n=2,4,6,8,10
Results of objective functions at n=2,6,10
Test results of the five methods
Results of financial oscillator model
33
34
48
86
105
106
106
114
118
120
121

This page intentionally left blank

Preface
This book reports initial efforts in providing some useful extensions in fi-
nancial modeling; further work is necessary to complete the research agenda.
The demonstrated extensions in this book in the computation and modeling
of optimal control in finance have shown the need and potential for further
areas of study in financial modeling. Potentials are in both the mathematical
structure and computational aspects of dynamic optimization. There are needs
for more organized and coordinated computational approaches. These exten-
sions will make dynamic financial optimization models relatively more stable
for applications to academic and practical exercises in the areas of financial
optimization, forecasting, planning and optimal social choice.
This book will be useful to graduate students and academics in finance,
mathematical economics, operations research and computer science. Profes-
sional practitioners in the above areas will find the book interesting and infor-
mative.
The authors thank Professor B.D. Craven for providing extensive guidance
and assistance in undertaking this research. This work owes significantly to
him, which will be evident throughout the whole book. The differential equa-
tion solver “nqq” used in this book was first developed by Professor Craven.
Editorial assistance provided by Matthew Clarke, Margarita Kumnick and Tom
Lun is also highly appreciated. Ping Chen also wants to thank her parents for
their constant support and love during the past four years.
PING CHEN AND SARDAR M.N. ISLAM

This page intentionally left blank

Introduction
Optimal control methods have significant applications in finance. This book
discusses the general applications of optimal control methods to several areas
in finance with a particular focus on the application of bang-bang control to
financial modeling.
During the past half-century, many optimization problems have arisen in
fields such as finance management, engineering, computer science, production,
industry, and economics. Often one needs to optimize (minimize or maximize)
certain objectives subject to some constraints. For example, a public utility
company must decide what proportion of its earnings to retain to the advantage
of its future earnings at the expense of gaining present dividends, and also
decide what new stock issues should be made. The objective of the utility is
to maximize the present value of share ownership, however, the retention of
retained earnings reduces current dividends and new stock issues can dilute
owners’ equity.
Some optimization problems involve optimal control, which are consider-
ably more complex and involve a dynamic system. There are very few real-
world optimal control problems that lend themselves to analytical solutions.
As a result, using numerical algorithms to solve the optimal control problems
becomes a common approach that has attracted attention of many researchers,
engineers and managers. There are many computational methods and theoreti-
cal results that can be used to solve very complex optimal control problems. So
computer software packages of certain optimal control problems are becoming
more and more popular in the era of a rapidly developing computer industry.
They rescue scientists from large calculations by hand.
Many real-world financial problems are too complex for analytical solu-
tions, so must be computed. This book studies a class of optimal financial
control problems where the control takes only two (or three) different discrete
values. The non-singular optimal control solution of linear-analytic systems in
finance with bounded control is commonly known as the bang-bang control.
The problem of finding the optimal control becomes one of finding the switch-

xvi
OPTIMAL CONTROL MODELS IN FINANCE
ing times in the dynamic financial system. A cost of switching control is added
to usual models since there is a cost for switching from one financial instrument
to another. Computational algorithms based on the time scaled transformation
technique are developed for this kind of problems. A set of computer software
packages named CSTVA is generated for real-world financial decision-making
models.
The focus in this research is the development of computational algorithms
to solve a class of non-linear optimal control problems in finance (bang-bang
control) that arise in operations research. The Pontryagin theory [69, 1962] of
optimal control requires modification when a positive cost is associated with
each switching of the control. The modified theory, which was first introduced
by Blatt [2, 1976], will give the solutions of a large class of optimal control
problems that cannot be solved by standard optimal control theories. The the-
orem is introduced but not used to solve the problems in this book. However,
the cost of changing control, which is attached to the cost function, is used
here for reaching the optimal solution in control system. In optimization com-
putation, especially when calculating minimization of an integral, an improved
result can be obtained by using a greater number of time intervals.
In this research, a modified version of the Pontryagin Principle, in which
a positive cost is attached to each switching of the control, indicates that a
form of bang-bang control is optimal. Several computational algorithms were
developed for such financial control problems, where it is essential to com-
pute the switching times. In order to achieve the possibility of computation,
some transformations are included to convert control functions, state functions
and the integrals from their original mathematical forms to computable forms.
Mainly, the MATLAB “constr” optimization package was applied to construct
the general computer programs for different classes of optimal control prob-
lems. A simplified financial optimal control problem that only has one state
and one control is introduced first. The optimal control of such a problem
is bang-bang control, which switches between two values in successive time
intervals. A computer software package was developed for solving this partic-
ular problem, and accurate results were obtained. Also some transformations
are applied into the problem formalization. A financial oscillator problem is
then treated, which has two states and one control. The transformation of sub-
division of time interval technique is used to gain a more accurate gradient.
Different sequences of control are then studied. The computational algorithms
are applied to a non-linear optimal control problem of an optimal financing
model, which was original introduced by Davis and Elzinga [22, 1970]. In that
paper, Davis and Elzinga had an analytical solution for the model. In this book
a computer software package was developed for the same model, including set-
ting up all the parameters, calculating the results, and testing different initial
points of an iterative algorithm. During the examination of the algorithms, it

INTRODUCTION
xvii
was found that sometimes a local minimum was reached instead of a global
optimum. The reasons for the algorithms leading to such a local minimum are
indicated, and as a result, a part of the algorithms are modified so as to obtain
the global optimum eventually.
The computing results were obtained, and are presented in graphical forms
for future analysis and improvement here. This work is also compared with
other contemporary research. The advantages and disadvantages of them are
analyzed. The STV approach provides an improved computational approach
by combing the time discretization method, the control step function method,
the time variable method, the consideration of transaction costs and by coding
the computational requirements in a widely used programming system MAT-
LAB. The computational experiments validated the STV approach in terms of
computational efficiency, and time, and the plausibility of results for financial
analysis.
The present book also provides a unique example of the feasibility of model-
ing and computation of the financial system based on bang-bang control meth-
ods. The computed results provide useful information about the dynamics of
the financial system, the impact of switching times, the role of transaction
costs, and the strategy for achieving a global optimum in a financial system.
One of the areas of applications of optimal control models is normative so-
cial choice for optimal financial decision making. The optimal control models
in this book have this application as well. These models specify the welfare
maximizing financial resource allocation in the economy subject to the under-
lying dynamic financial system.
Chapter 1 is an introduction to the optimal control problems in finance and
the classical optimal control theories, which have been successfully used for
years. Some relevant sources in this research field are also introduced and
discussed.
Chapter 2 discusses a particular case of optimal control problems and the
switching time variable (STV) algorithm. Some useful transformations intro-
duced in Section 2.2 are standard for the control problems. The piecewise-
linear transformation and the computational algorithms discussed in Section
2.6 are the main work in this book. A simple optimal aggregate investment
planning model is presented here. Accurate results were obtained in using
these computational algorithms, and are presented in Section 2.7. A part of
the computer software SCOM developed in Craven and Islam [18, 2001] and
Islam and Craven [38, 2002] is used here to solve the differential equation.
Chapter 3 presents a financial oscillator model (which is a different version
of the optimal aggregative investment planning model developed in Chapter 2)
whose state is a second-order differential equation. A new time-scaled trans-
formation is introduced in Section 3.3. The new transformation modifies the
old transformations that are used in Chapter 2. All the modifications are made

xviii
OPTIMAL CONTROL MODELS IN FINANCE
to match the new time-scale division. The computational algorithms for this
problem and the computing results are also discussed. An extension of the con-
trol pattern is indicated. The new transformation and algorithms in this chapter
are the important parts in this research.
Chapter 4 contains an optimal financing model, which was first introduced
by Davis and Elzinger [22, 1970]. A computer software package for this
model is constructed in this book (for details see Appendix A.3 model 1_1.m -
model1_5.m). The computing result is compared with the analytical result and
another computing result obtained from using the SCOM package.
Chapter 5 reports computing results of the algorithms 2.1-2.3 and algorithms
3.1-3.4 in other cases of optimal control problems. After analyzing the results,
the computer packages in Appendix A.1 and Appendix A.2 (project1_1.m -
project1_4.m and project2_2.m - project2_4.m) have been improved.
Chapter 6 gives the conclusion of this research. Optimal control methods
have high potential applications to various areas in finance. The present study
has enhanced the state of the art for applying optimal control methods, es-
pecially the bang-bang control method, for financial modeling in a real life
context.

Chapter 1
OPTIMAL CONTROL MODELS IN FINANCE
Optimal control theory has been important in finance (Islam and Craven [38,
2002]; Taperio [81, 1998]; Ziemba and Vickson [89, 1975]; Senqupta and Fan-
chon [80, 1997]; Sethi and Thompson [79, 2000]; Campbell, Lo and MacKin-
lay [7, 1997]; Eatwell, Milgate and Neuman [25, 1989]). During nearly fifty
years of development and extension of optimal control theories, they have been
successfully used in finance. Many famous models effectively utilize optimal
control theories. However, with the increasing requirements of more workable
and accurate solutions to optimal control problems, there are many real-world
problems which are too complex to lead to analytical solutions. Computational
algorithms therefore become essential tools for most optimal control problems
including dynamic optimization models in finance.
Optimal control modeling, both deterministic and stochastic, is probably
one of the most crucial areas in finance given the time series characteristics
of financial systems’ behavior. It is also a fast growing area of sophisticated
academic interest as well as practice using analytical as well as computational
techniques. However, there are some limits in some areas in the existing lit-
erature in which improvements are needed. It will facilitate the discipline if
dynamic optimization in finance is to be at the same level of development
in modeling as the modeling of optimal economic growth (Islam [36, 2001];
Chakravarty [9, 1969]; Leonard and Long [52, 1992]). These areas are: (a)
specification of the element of the dynamic optimization models; (b) the struc-
ture of the dynamic financial system; (c) mathematical structure; and (d) com-
putational methods and programs. While Islam and Craven [38, 2002] have
recently made some extensions to these areas, their work does not explicitly
focus on bang-bang control models in finance. The objective of this book is
to present some suggested improvements in modeling bang-bang control in

2
OPTIMAL CONTROL MODELS IN FINANCE
finance in the deterministic optimization strand by extending the existing liter-
ature.
In this chapter, a typical general financial optimal control model is given in
Section 1.1 to explain the formula of the optimal control problems and their
accompanying optimal control theories. In addition, some classical concepts
in operations research and famous standard optimal control theories are intro-
duced in Section 1.2-1.5, and a brief description on how they are applied in
financial optimal control problems is also discussed. In Section 1.6, some im-
provements that are needed to meet the higher requirements for the complex
real-world problems are presented. In Section 1.7, the algorithms on similar
optimal control problems achieved by other researchers are discussed. Critical
comparisons of the methods used in this research and those employed in oth-
ers’ work are made, and the advantages and disadvantages between them are
shown to motivate the present research work.
1.
An Optimal Control Model of Finance
Consider a financial optimal control model:
subject to:
Here 
is the state, and 
is the control. The time T is the “planning
horizon”. The differential equation 
describes the dynamics of the
financial system; it determines 
from 
It is required to find an optimal
which minimizes 
(We may consider 
as a cost function.) Al-
though the control problem is stated here (and other chapters in this book) as a
minimization problem, many financial optimization models are in a maximiza-
tion form. Detailed discussion of control theory applications to finance may be
seen in Sethi and Thompson [79, 2000].
Often, 
is taken as a piece-wise continuous function (note that jumps
are always needed if the problem is linear in the control 
to reach an op-
timum), and then 
is a piece-wise smooth function. A financial optimal
control model is represented by the formula (1.1)-(1.4), and can always use
the “maximum principle” in Pontryagin theory [69, 1962]. The cost function
is usually the sum of the integral cost and terminal cost in a standard optimal

Optimal Control Models
3
control problem which can be found in references [1, 1988], [5, 1975], and
[8, 1983]. However, for a large class of reasonable cases, there are often no
available results from standard theories. A more acceptable method is needed.
In Blatt [2, 1976], there is some cost added when switching the control. The
cost can be wear and tear on the switching mechanism, or it can be as the cost
of “loss of confidence in a stop-go national economy”. The cost is associated
with each switching of control. The optimal control problem in financial deci-
sion making with a cost of switching control can be described as follows:
subject to:
Here, 
is the positive cost. 
is an integer, representing the number of
times the control jumps during the planning period [0, T]. In particular,
may be a piece-wise constant, thus it can be approximated by a step-function.
Only fixed-time optimal control problems are considered in this book which
means T is a constant. Although time-optimal control problems are also very
interesting, they have not been considered in this research.
The essential elements of an optimal control model (see Islam [36, 2001])
are: (i) an optimization criteria; (ii) the form of inter-temporal time preference
or discounting; (iii) the structure of dynamic systems-under modeling; and(iv)
the initial and terminal conditions. Although the literature on the method-
ologies and practices in the specification of the elements of an optimal con-
trol model is well developed in various areas in economics (such as optimal
growth, see Islam [36, 2001]; Chakravarty [9, 1969]), the literature in finance
in this area is not fully developed (see dynamic optimization modeling in Ta-
perio [81, 1998]; Sengupta and Fanchon [80, 1997]; Zieamba and Vickson
[89, 1975]). The rationale for and requirements of the specification of the
above four elements of dynamic optimization financial models are not pro-
vided in the existing literature except in Islam and Craven [38, 2002]. In the
present study, the main stream practices are adopted: (i) an optimization crite-
ria (of different types in different models); (ii) the form of inter-temporal time
preference-positive or zero discounting; (iii) the structure of dynamic systems

4
OPTIMAL CONTROL MODELS IN FINANCE
under modeling (different types – linear and non-linear); and (iv) the initial
and terminal conditions – various types in different models.
Optimal control models in finance can take different forms including the
following: bang-bang control, deterministic and stochastic models, finite and
infinite horizon models, aggregative and disaggregative, closed and open loop
models, overtaking or multi-criteria models, time optimal models, overlapping
generation models, etc.(see Islam [36, 2001]).
Islam and Craven [38, 2002] have proposed some extensions to the method-
ology of dynamic optimization in finance. The proposed extensions in the
computation and modeling of optimal control in finance have shown the need
and potential for further areas of study in financial modeling. Potentials are
in both mathematical structure and computational aspects of dynamic opti-
mization. These extensions will make dynamic financial optimization models
relatively more organized and coordinated. These extensions have potential ap-
plications for academic and practical exercises. This book reports initial efforts
in providing some useful extensions; further work is necessary to complete the
research agenda.
Optimal control models have applications to a wide range of different areas
in finance: optimal portfolio choice, optimal corporate finance, financial engi-
neering, stochastic finance, valuation, optimal consumption and investment,
financial planning, risk management, cash management, etc. (Tapiero [81,
1998]; Sengupta and Fanchon [80, 1997]; Ziemba and Vickson [89, 1975]).
As it is difficult to cover all these applications in one volume, two important
areas in financial applications of optimal control models – optimal investment
planning for the economy and optimal corporate financing – are considered in
this book.
2.
(Karush) Kuhn-Tucker Condition
The Kuhn-Tucker Condition condition is the necessary condition for a local
minimum of a minimization problem (see [14, 1995]). The Hamiltonian of
the Pontryagin maximum principle is based on a similar idea that deals with
optimal control problems.
Consider a general mathematical programming problem:
subject to:

Optimal Control Models
5
The Lagrangian is:
The (Karush-) Kuhn-Tucker conditions necessary for a (local) minimum
of the problem at 
are that Lagrange multipliers 
and 
exist, for
which 
satisfies the constraints of the problem, and:
The inequality constraints are written here as 
then the corresponding
at the minimum; the multipliers of the equality constraints can take any
sign. So for some minimization problems where the inequality constraints are
represented as 
the sign of the inequalities should be changed first. Then
the KKT condition can be applied.
The conditions for global minimum are that the objective and constraint
functions are differentiable, and satisfy the constraint qualifications and are
convex and concave respectively. If these functions are strictly convex then the
minimum is also a unique minimum. Further extensions to these conditions
have been made in the cases when the objective and constraint functions are
quasi-convex and invex (see Islam and Craven [37, 2001]).
Duality properties of the programming models in finance not only provide
useful information for computing purposes, but also for determining efficiency
or show prices of financial instruments.

6
OPTIMAL CONTROL MODELS IN FINANCE
3.
Pontryagin Theorem
The Pontryagin theorem was first introduced in Pontryagin [69, 1962].
Consider a minimization problem in finance given as follows:
T is planning horizon, subject to a differential equation and some constraint:
Here (1.23) represents the differential equation. (1.24) represents the con-
straint on control
Let the optimal control problem (1.22) reach a (local) minimum at
with respect to the 
for 
Assume that 
and 
are partially Fréchet
differentiable with respect to 
uniformly in 
near 
The Hamiltonian is
shown as follows:
The necessary conditions for the minimum are:
(a) a co-state function
satisfies the adjoint differential equation:
with boundary condition.
(b) the associated problems minimize at 
for all except at a null set.

Optimal Control Models
7
4.
Bang-Bang Control
In some optimal control problems, when the dynamic equation is linear in
the control 
bang-bang control (the control only jumps on the extreme
points in the feasible area of the constraints on the control) is likely to be
optimal. Here a small example is used to explain this concept. Consider the
following constraints on the control:
In this case the control 
is restricted to the area of a
triangle. The control, which is only staying on the vertices of the triangle
and also jumping from one vertex to the other in successive switching time
intervals, is the optimal solution. This kind of optimal control is called bang-
bang control. The concept can also be used to explain a control:
where the optimal control 
only takes two possible cases 
or depending
on the initial value of the control. This control is also a bang-bang control.
In this research, only bang-bang optimal control models in finance are con-
sidered. Sometimes, a singular arc (see Section 1.5) might occur following a
bang-bang control in a particular situation. So the possibility of a singular arc
occurring should always be considered after a bang-bang control is obtained in
the first stage.
5.
Singular Arc
As mentioned earlier, when the objective function and dynamic equation
are linear in the control, a singular arc might occur following the bang-bang
control. In that case, the co-efficient of control 
in the associated problem
equals zero, thus the control equals zero. So after discovering a bang-bang
control solution, it is necessary to check whether a singular arc exists.
In what kind of situation will the singular arc occur? Only when the co-
efficient of 
in the associated problem may happen to be identically zero
for some time interval of time 
say 
The optimum path for such an
interval
is called a singular arc; on such an arc, the associated problem
only gives
A singular arc is very common in real-world trajectory
following problems.

8
OPTIMAL CONTROL MODELS IN FINANCE
6.
Indifference Principle
In Blatt [2, 1976], certain financial optimal control models that are con-
cerned with optimal control with a cost of switching control were discussed,
and an optimal policy was proved to exist. Also, the maximum principle of the
Pontryagin theory was replaced by a weaker condition theorem (“indifference
principle”), and several new theories were developed for solving the optimal
control problems with cost of changing control. This research is dealing with
an optimal control problem with a cost of changing control. Although the
“indifference principle” theory is not being employed for solving the optimal
control problems in this study, it is still very important to be introduced for
understanding the ideas of this research.
Consider a financial optimal control model as follows:
subject to:
Let:
where 
or 1 is the control setting at time 
the non-negative
integer 
is the number of times control alters during time horizon T; and the
are the times at which control alters, satisfying:

Optimal Control Models
9
Given the policy P, the control function 
is shown in (1.30). Now the
Hamiltonian of the Pontryagin theory is constructed as follows:
The co-state equation is:
The end-point condition:
Theorem 2. An admissible optimal policy exists. See proof in reference [2,
1976].
Theorem 5. The indifference principle:
Let P(1.32) be an optimal policy. Let H and 
be defined by (1.34),
(1.35) and (1.36). Then at each switching time 
of 
The
Hamiltonian H is indifferent to the choice of the control, which is:
The relationship between the “maximum principle” and the “indifference
principle” is that the “indifference principle” can be implied by the “maxi-
mum principle”. The “maximum principle” makes a stronger condition, that
is, the control is forced to switch by the “maximum principle” when the phase
space orbit crosses the indifference curve (1.37), while the control is allowed
to change by the “indifference principle” at the same point. That means the
control can stay the same in a region of phase space and also be optimal. It
is not allowed to change the value of control
until reaching the indifference
curve (1.37) again. It is workable even though the new theory requires more
candidate optimal control paths. When a cost of a switching control exists, the

10
OPTIMAL CONTROL MODELS IN FINANCE
“maximum principle” should be replaced by the “indifference principle”, and
optimal control will also exist. The existence of an optimal solution can be
proved by Theorem 2 in Blatt’s paper.
This research originated from Blatt’s work. The goal of this book involves
some novel computational algorithms for solving (1.28-1.32) based on the the-
orems in Blatt’s paper. The work on the cost analysis, difference of optimal
control policy sequences and division of the time intervals are extended from
Blatt’s original work. The methods, which could avoid the solution staying at
local minimum without reaching the global minimum, are also discussed. This
book is more concerned with using the computer software package to solve the
problems rather than solutions analysis.
There are some computing optimal control methods (see next section) which
have been successfully applied in many fields. They involve subdividing the
interval [0, T] into many (usually equal) subintervals. However, the accuracy
will be lost if the switching times do not lie on the end-points of the equal
subintervals. Hence it is essential to compute the optimal switching times.
7.
Different Approaches to Optimal Control Problems
With the advances of modern computers and rapid development of software
engineering, more and more people are concerned with computational algo-
rithms, which could shorten computing time and provide more accurate results
for complex optimal control problems that are difficult to solve analytically.
During last thirty years, many efficient approaches have been developed and
successfully applied in many models in a wide range of fields. Several nu-
merical methods are available in the references ([24, 1981]; [56, 1975]; [57,
1986]; [58, 1986]; [76, 1981]; [75, 1980]; [84, 1991]; [85, 1991]), while some
typical computing optimal control problems and efficient computational algo-
rithms relevant to the present study will be discussed in the next few sections,
the general computational approaches and algorithms for optimal control may
be classified as the following (Islam [36, 2001]).
There is a wide range of algorithms which can be used for computing op-
timal control models in finance and can be classified under the algorithms for
continuous and discrete optimal control models (Islam [36, 2001]). Algorithms
for continuous optimal control models in finance include: (i) gradient search
methods; (ii) algorithms based two value boundary problems; (iii) dynamic
programming, approximate solution methods (steady-state solution, numerical
methods based on approximation and perturbation, contraction mapping based
algorithm and simulation); and (iv) control discretization approach based on
step function, spline etc. Algorithms for discrete optimal control models in
finance may be classified as follows: (i) algorithms based on linear and non-
linear programming solution methods; (ii) algorithms based on the difference
equations of the Pontryagin maximum principle and solved as a two value-

Optimal Control Models
11
boundary problem; (iii) gradient search method; (iv) approximation methods;
and (v) dynamic programming.
For computing optimal control finance models, some recently developed
computer packages such as SCOM, MATLAB, MATHEMATICA, DUAL, RI-
OTS, MISER and OCIM can be used.
7.1
OCIM
In reference [15, Craven 1998], a FORTRAN computer software package
OCIM (Optimal Control in Melbourne) was discussed for solving a class of
fixed-time optimal control problems. This computational method is based on
the Augmented Lagrangian algorithm which was discussed in Section 6.3.2 in
Craven [14, 1995]. Powell and Hestenes first made the Augmented Lagrangian
for a problem with equality constraints. Rockafellar extended it to inequality
constraints in paper [74, 1974]. OCIM can be run on a Macintosh as well as
UNIX.
The basic idea of this method is to divide the time interval [0, T] into
subintervals. The control 
is approximated by a step-function as in MISER
[33, 1987], with 
(constant) on subinterval
In MISER [33, 1987], Goh and Teo had obtained good numerical results us-
ing the apparently crude approximation of 
by a step-function, which is
called “control parameterization technique”. In Craven [14, 1995], the the-
ory in Section 7.6 and 7.8 proves that this occurs when the control system
acts as a suitable low-pass filter; also the smoothing effect of integrating the
state differential equation will often have this result. Increasing the number
of subdivisions will lead to a greater accuracy. Note in the calculation of
the co-state equation for 
the interpolation of the values of state 
is
required. It is done by linear interpolation of the value of 
at subdivision
points 
The linear interpolation is also used for calculating the gra-
dient in this research.
A brief description of the computing method is discussed here. First, given
the approximated control 
to solve the state equation, obtain the state values
taken at the grid-points of the subintervals; second solve the co-state equation
with respect to 
thirdly, calculate the augmented Lagrangian; and lastly,
calculate the gradients of the cost function respect to 
This algorithm had
been programmed in FORTRAN. Note that jumps in co-states are not yet im-
plemented. Unconstrained minimization is done using the CONMIN package
[70], which uses the BFGS quasi-Newton algorithm [28, 1980].
Using the augmented Lagrangian allows gradients to be calculated by a sin-
gle adjoint differential equation, and instead of having to code a separated
formula for each constraint. In this algorithm, a time interval [0, T] is divided
into equal subintervals. A diversity of control problems can be solved by this
method, but the equality constraint like 
presents some

12
OPTIMAL CONTROL MODELS IN FINANCE
problems with OCIM. Several famous models were successfully solved by this
method. They are a damped oscillator (the approaches developed in this re-
search also solved an example of an oscillator problem), the Dodgem problem
[29, 1975], and the Fish problem [12, 1976]. In Craven’s paper, there was
a useful non-linear transformation of the time scale that can effectively give a
good subdivision in big time ranges, without requiring a large number of subdi-
visions, and also avoid computing problems. The details of the transformation
will be described in Section 2.3.
7.2
RIOTS 95
Relating to another computing optimal control software package SCOM,
which will be introduced in Section 1.7.5, the RIOTS (Recursive Integration
Optimal Trajectory Solver 95) package [77, 1997] also runs on MATLAB . It
solves optimal control problems by solving (in various ways) the differential
equations that lead to function values and gradients, and then applying a mini-
mizer package. The computing scheme is similar to the one that was described
by Craven [14, 1995] in Section 6.4.5. This package obtains good accuracy
of the switching times by using a sufficiently small subdivision of the time
interval.
7.3
A computational approach for the cost of changing
control
A computational method based on the control parameterization technique
[84, 1991] was introduced in reference [82, 1992] for solving a class of optimal
control problems where the cost function is the sum of integral cost, terminal
cost, and full variation of a control. The full variation of a control is used to
measure changes on the control action.
This method involves three stages of approximation. In the first stage, the
problem is approximated by a sequence of approximation problems based on
the control parameterization technique. Every approximation problem involv-
ing full variation of control is an optimal parameter selection problem. They
become non-smooth functions in the form of
– norm. In the second stage,
the non-smooth functions are smoothen by a smoothing technique [83, 1988].
Another smoothing technique [42, 1991] is used to approximate the continuous
state inequality constraints by a sequence of conventional canonical constraints
in stage three. All these approximation problems are standard optimal param-
eter selection problems which can be solved by the general optimal control
software package MISER3 [40, 1991]. The method is supported by the con-
vergence properties. A calculation of a fishery harvesting model (which was
computed in reference [41, 1990] with penalty 
was involved to illus-
trate the method, and the chosen value penalty term 
was explained in this

Optimal Control Models
13
paper. A similar situation is also discussed in this book, which is called the
chosen cost, in Section 2.8. An application of an optimal control problem in
which the cost function does not have the full variation of control can also
utilize this method by adjusting the penalty constant appropriately to obtain a
smoother control without changing the optimum of the original cost function.
There are some relevant references [55, 1987], [2, 1976], [66, 1977] for this
problem.
7.4
Optimal switching control computational method
In Li [53, 1995], a computational method was developed for solving a class
of optimal control problems involving the choice of a fixed number of switch-
ing time points 
which divide the system’s time horizon [0, T] into
K time periods. A subsystem 
is selected for each time periods
from a finite number of given candidate subsystems, which run in that time
period. All the K subsystems and K – 1 switching times will be taken as de-
cision variables. These decision variables form candidate selection systems ,
which will lead the optimal control problem to a minimum. Here, the optimal
control problem is only considered over a finite time horizon. In this method,
the original problem is transformed into an equivalent optimal control problem
with system parameters by using some suitable constraints on the co-efficient
of the linear combination, which is formed by the candidate subsystems, and
using a time re-scaling technique.
Many control problems related to the system dynamics that are subject to
sudden changes can be put into this model. In recent years, general optimal
switching control problems have been studied. The optimality principle is ap-
plied and existence of optimal controls is discussed. Basically the problems
are formulated as optimal control problems , in which the feasible controls are
determined by appropriate switching functions. There are relevant references
available in the bibliography [53, 1995], [87, 1989], [88, 1991], [27, 1979].
This situation has problems involving both discrete and continuous deci-
sions represented by the subsystems and switching times. A transformed tech-
nique is introduced for solving this mixed discrete and continuous optimal con-
trol problem. The basic idea behind this technique is transforming the mixed
continuous-discrete optimal control problem into an optimal parameter selec-
tion problem [84, 1991], which only deals with continuous decision variables.
Since the transformed problem still involves the switching times located within
subdivisions, which make the numerical solution of such an optimal control
problem difficult. Another transformation is introduced to further transform
the problem into an optimal control problem with system parameters. The
control is taken as the lengths of the switching intervals as parameters. The
second equivalent optimal control problem can be solved by standard optimal

14
OPTIMAL CONTROL MODELS IN FINANCE
control techniques. A numerical problem was solved in Li’s paper [53, 1995]
by using this computational method.
This kind of optimal control problem has sudden changes in the dynamics at
switching time, and therefore has a mixed continuous-discrete nature. Switch-
ing times, a time scaling and a control function are introduced to deal with
the discontinuities in the system dynamics. The control function is a piece-
wise constant function with grid-points corresponding the discontinuities of
the original problem, hence allowing the general optimal control software to
solve the problem.
7.5
SCOM
In Craven and Islam [18, 2001] (See also Islam and Craven [38, 2002]), a
class of optimal control problems in continuous time were solved by a com-
puter software package called SCOM, also using the MATLAB system. As
in the MISER [33, 1987] and OCIM [15, 1998] packages, the control is ap-
proximated by a step-function. Because of the matrix features in MATLAB,
programming is made easier. Finite difference approximations for gradients
give some advantages for computing gradients. In this paper, end-point con-
ditions and implicit constraints in some economic models are simply handled.
Consider an optimal control problem of the form:
subject to:
The end-point term and constraints can be handled by a penalty term; its de-
tailed description will be introduced in Section 4.4. The concern here is only
with how this computational algorithm works. The differential equation (1.39)
with initial condition, determines 
from 
Denote
The interval [0,1] is then divided into N equal subintervals, and 
is ap-
proximated by a step-function taking values 
on the succes-
sive subintervals. An extra constraint 
is added to the given problem,
where V is the subspace of such step-functions. Consequently, 
becomes a
polynomial function, determined by its values 
at the grid-points
Since there are discontinuities at the grid-points on
the right side of the differential equation which is a non-smooth function of

Optimal Control Models
15
a suitable differential equation solver must be chosen for such functions.
Many standard solvers do not have this feature. Only one of the six ODE
solvers in MATLAB is designed for stiff differential equations. However, this
ODE solver is not used in this book. Instead, a good computer software pack-
age “nqq” is used to deal with the jumps on the right side of the differential
equation in the dynamic system of the optimal control problems. The fourth
order Runge-Kutta method [30, 1965] (a standard method for solving ordinary
differential equations) is slightly modified for solving a differential equation of
the form 
where 
is a step-function. The modification
is simply recording the counting number 
and time to make sure that
always takes the appropriatevalue 
not 
in subinterval
when 
In the computation, the differential equation is com-
puted forward (starting at 
while the adjoint equation is solved backward
(starting at
Two steps are introduced to solve such optimal control problems:
Compute objective values from the objective function, differential equation,
and augmented Lagrangian, not compute gradients from the adjoint equa-
tion and Hamiltonian. That assumes gradients can be estimated by finite
differences from what to be computed.
Compute objective values and gradients from the adjoint equation and Hamil-
tonian.
1
2
Implicit Constraints: in some economic models, such as the model [48,
1971 ] to which Craven and Islam have applied the SCOM package in the paper
[18, 2001], fractional powers of the functions (with 
in the right side of
the differential equation where 
appear, then some choices of
will lead to 
causing the solver to crash. The requirement of
forms an implicit constraint. A finite-difference approximation to gradients
is useful as approximations over a wider domain in this case. As mentioned
in Section 1.7.1, linear interpolation can also be used in solving gradients and
co-state functions. Increasing the number of the subintervals N will get better
results. It will be discussed later in Section 2.7 and 2.8.
Two problems were tested using SCOM in a paper by Craven and Islam
[18, 2001], and accurate results were found for both. In Craven and Islam [18,
2001], “constr” estimated gradients by finite differences to compute the opti-
mum. The economic models in this paper [18, 2001] with implicit constraints
are different from the models that were solved by other computer software
packages. However, this computer software also needs to be further developed
for more general use.

16
OPTIMAL CONTROL MODELS IN FINANCE
7.6
Switching Costs Model
An investment model for the natural resource industry was introduced in
Richard and Mihall’s paper [73, 2001] with switching cost. The problem com-
bines both absolutely continuous and impulse stochastic control. In particu-
lar, the control strategy involves a sequence of interventions at discrete times.
However, this component of the control strategy does not have all the features
of impulse control because the sizes of the jumps associated with each inter-
ventions strategy are not part of the control strategy but are constrained to the
pattern...,1, –1,1, –1,..., jumping between two levels. This kind of control
patterns is also considered in this research.
Perthame [68, 1984] first introduced the combination of impulse and abso-
lutely continuous stochastic control problems which have been further studied
by Brekke and B.Øksendal [3, 1991]. Mundaca and Øksendal [62, 1998] and
Cadenillas and Zapatero [6, 2000] work on the applications to the control of
currency exchange rates.
7.7
CPET
Time optimal control problems (which are not considered in this research)
with bang-bang control associated with or without singular arc solutions can
make the calculation difficult. A novel problem transformation called the Con-
trol Parameterization Enhancing Transform (CPET) was introduced in refer-
ence [51, 1997] to provide a computationally simple and numerically accurate
solution without assuming that the optimal control is pure bang-bang control
for time optimal control problems. A standard parameterization algorithm can
calculate the exact switching times and singular control values of the original
problem with CPET. Also, with the CPET, switching points for the control
match the control parameterization knot points naturally, and hence piece-wise
integration can be conveniently and accurately carried out in the usual control
parameterization manner.
Several models used this technique and gave numerical results with ex-
tremely high accuracy. They are F-8 flight aircraft (first introduced in reference
[31, 1977]) [71, 1994], the well-known “dodgem car” problem [29, 1975], and
a stirred tank mixer [34, 1976]. The generalizations of CPET technique to a
large range of problems were also introduced in reference [72, 1999].
7.8
STC
A new control method, the switching time computation (STC) method,
which finds a suitable concatenation of constant-input arcs (or, equivalently,
the places of switchings) that would take a given single-input non-linear sys-
tem from a given initial point to the target, was first introduced in Kaya and
Noakes’ paper [43, 1994]. It was also described in detail of the mathematical

Optimal Control Models
17
reasoning in paper [44, 1996]. The method is applicable to single-input non-
linear systems. It finds the switching times for a piecewise-constant input with
a given number of switchings. It can also be used for solving the time-optimal
bang-bang control problem. The TOBC algorithm, which is based on the STC
method, is given for this purpose. Since the STC method is basically designed
for a non-linear control system, the problem of the initial guess is equally dif-
ficult when it is applied to a linear system. For the optimization procedure,
an improper guess for the arc times may cause the method to fail in linear
systems. However, the initial guess can be improved by experience from the
failures. In non-linear systems, there does not exist a scheme for ‘guessing’ a
proper starting point in general optimization procedures. In general, the STC
method handles a linear or a non-linear system without much discrimination.
The reason is that the optimization is carried out in arc time space and even a
linear system has a solution that is complicated in arc time space. The STC
method has been applied as part of the TOBC algorithm to two ideal systems
and a physical system (F-8 aircraft). They have been shown to be fast and ac-
curate. The comparisons with results obtained through MISER3 software have
demonstrated the efficiency of the STC method, both in its own right in find-
ing bang-bang controls and in finding time-optimal bang-bang controls when
incorporated in the TOBC algorithm. There is also a possibility to generalize
the system from a single-input system to the multi-input system, which needs
more computer programming involving.
7.9
Leap-frog Algorithm
Pontryagin’s Maximum Principle gives the necessary conditions for opti-
mality of the behavior of a control system, which requires the solution of a
two-point boundary-value problem (TPBVP). Noakes [64, 1997] has devel-
oped a global algorithm for finding a geodesic joining two given points on a
Riemannian manifold. A geodesic problem is a special type of TPBVP. The
algorithm can be viewed as a solution method for a special type of TPBVP.
It is simple to implement and works well in practice. The algorithm is called
the Leap-Frog Algorithm because of the nature of its geometry. Application
of the Leap-Frog Algorithm to optimal control was first announced in Kaya
and Noakes [45, 1997]. This algorithm gave promising results when it was ap-
plied to find an optimal control for a class of systems with unbounded control.
In Kaya and Noakes’ paper [46, 1998], a direct and intuitive implementation
of the algorithm for general non-linear systems with unbounded controls has
been discussed. This work gave a more detailed and extended account of the
announcement. A theoretical analysis of the Leap-Frog Algorithm for a class
of optimal control problems with bounded controls in the plane was given in
Kaya and Noakes’ paper [47, 1998]. The Leap-Frog Algorithm assumes that
the problem is already solved locally. This requirement translates to the case

18
OPTIMAL CONTROL MODELS IN FINANCE
of optimal control as the availability of a local solution of the problem. This is
related to the structure of the small-time reachable sets.
7.10
An obstruction optimal control problem
In Craven [17, 1999], an optimal control problem relating to flow around an
obstacle (original proposed by Giannesi [32, 1996]) can be treated as a mini-
mization problem which leads to a necessary condition or an optimal control
problem. In this paper, Craven gave the discretization augment, and proved
that, if an optimal path exists, the Pontryagin principle can be used to calculate
the optimum. The optimum was verified to be reached by a discretization of
the problem, and was also proved to be a global minimum.
7.11
Computational approaches to stochastic optimal
control models in finance
Computational approaches specific to stochastic financial optimal control
models are relatively well developed in the literature. However, computational
approaches to deterministic financial optimal control models are not well doc-
umented in the literature, the standard general computational approaches to
optimal control discussed above are applied to financial models as well. Some
discussion of the computational approaches with specific applications to fi-
nance may be seen in Islam and Craven [38, 2002].
7.12
Comparisons of the methods
While a discussion of the comparisons of the general computational ap-
proaches is provided below, such comparisons are also relevant when the gen-
eral approaches are applied to financial models. In financial optimal control
models, the control function 
is approximated by a vector on some vec-
tor space of finite dimension in all algorithms for numerical computation of
such an optimal control model 1.38-1.40. There are some examples with
different chosen approximations. The RIOTS 95 package [77, 1997] which
uses MATLAB, uses various spline approximations, solves the optimization
problems by projected descent methods; MISER3 [33, 1987], uses a step-
function to approximate the control function, solves the optimization problems
by sequential quadratic programming; OCIM [15, 1998], uses conjugate gra-
dient methods. Different implementations behave differently especially on the
functions defined on a restricted domain, since some optimization methods
might want to search the area outside the domain. Although a step-function
is obviously a crude approximation, it produces accurate results shown in
many instants in reference [84, 1991]. Since integrating the dynamic equation
to obtain 
is a smooth operation, the high-frequency
oscillations are attenuated. In Craven [14, 1995], if this attenuation is suffi-

Optimal Control Models
19
ciently rapid, the result of step-function approximations converges to the exact
optimum while 
It is necessary to have some assumption of this
qualitative kind in order to ensure that the chosen finite dimensional approxi-
mations will permit a good approximation to the exact optimum. The RIOTS
95 package can run faster than SCOM, maybe because of its implementation
in the C programming language. The efficiency of the STC method has been
demonstrated by comparisons with results through MISER3 optimal control
software (a general-purpose optimal control software package incorporating
sophisticated numerical algorithms). MISER3 did not get results as fast as
the STC method did, perhaps because the general-purpose might be hamper-
ing its agility to certain extent because of some default settings regarding the
tolerances for the accuracy of the ODE solver and optimization routine in the
software.
This research is only concerned with pure bang-bang control problems within
a fixed-time period. All the algorithms and transformations are made for this
purpose. The control function is also approximated by a step-function. How-
ever, because the control does not always jump at the grid-points of the subdi-
visions of the time intervals which are usually equally divided in other works,
it is necessary to calculate the optimal divisions of the time horizon. This
research is mainly computing the optimal ranges of the subdivisions in time
period as well as calculating the minimum of the objective function. Situations
when a cost of changing control is involved in the cost function are discussed
as well as how this cost can effectively work on the whole system. Although
the STC method is also concerned with the calculation of the optimal switching
times, it does not include the cost of each switching control.
The limitations of the above computational approaches are summarized in
Chen and Craven [10, 2002]. From the above survey it will also appear that
each of the above computational methods has characteristics which are compu-
tationally efficient for computing optimal control financial models with switch-
ing times. A new approach which can adapt various convenient components
of the above computational approaches is developed in the next section. Al-
though the present algorithm has similarity with CPET, the details of the two
algorithms are different. A new computer package called CSTVA is also devel-
oped here which can suitably implement the proposed algorithm. The present
computational method consisting the STV algorithm and the CSTVA computer
programs does, therefore, provide a new computational approach for modeling
optimal corporate financing. The computational approach can be suitably ap-
plied to any other disciplines as well.
This approach (STV) consists of several computational methods (described
in Chapter 2):
The STV method where the switching time is made a control variable opti-
mal value of which is to be determined by the model.
1

20
OPTIMAL CONTROL MODELS IN FINANCE
A piecewise-linear (or non-linear) transformation of time.
The step function approach to approximate the control variable.
Finite difference method for estimating gradients if gradients are not pro-
vided.
An optimization program based on the sequential quadratic programming
(SQP) (as in MATLAB’s “constr” program similar to the Newton Method
for constrained optimization).
A second order differential equation to represent the dynamic model.
2
3
4
5
6
8.
Conclusion
This book is mainly concerned with using the computational algorithms to
solve certain classes of optimal control problems. The next chapter will in-
troduce the computational approach named Switching Time Variable (STV)
algorithm developed in this book that can solve a class of financial optimal
control problems when the control is approximated by a step-function. The
piecewise-linear transformation that is constructed for the computer software
package is described in Section 2.2. Some non-linear transformations, which
were first introduced by Craven [14, 1995] , are also discussed in Section 2.3.
These transformations are used to solve the large time period optimal control
problem in Chapter 4. A computer software package that was developed by
Craven and Islam [18, 2001] and Islam and Craven [37, 2001] is presented in
Section 2.4. The “nqq” function for solving differential equations is quoted
as a part of the computer software package in this research. The thrust of this
book involves a general computer software for certain optimal control prob-
lems. The principal algorithms behind it are introduced in Section 2.6. All the
computing results of an example problem for optimal investment planning for
the economy are shown in graphs and tables in Section 2.7. A cost of changing
control is also discussed in Section 2.8.

Chapter 2
THE STV APPROACH TO
FINANCIAL OPTIMAL CONTROL MODELS
1.
Introduction
In this chapter, a particular case of the optimal financial control problems,
which has one state function and one control function that is approximated by
a step-function, is discussed. Before the problem is defined, it is necessary
to cover some concepts and transformations in Section 2.2 and Section 2.3, to
explain the problems and algorithms that will be introduced in later sections
and chapters. As part of the computer software package SCOM (that was con-
structed by Craven and Islam), “nqq” is used as a DE solver in the algorithms
in this research. This program is described in Section 2.4. Then a simplified
control problem is introduced in Section 2.5. The computational algorithms ,
which are used to solve this simplified control problem, are indicated in Sec-
tion 2.6. Some problems with different fitting functions will be discussed later
in Chapter 5. Lastly, graphs and tables in Section 2.7 represent all the comput-
ing results of this problem. The analysis of the results is discussed in Section
2.8
2.
Piecewise-linear Transformation
The idea of piecewise-linear transformation of the time variable was first in-
troduced by Teo [40, 1991], but the time intervals were mapped into
instead of 
where 
is the number of time intervals.
In Lee, Teo, Rehbock and Jennings [51, 1997], the time transformation is de-
scribed by 
where 
is a piece-wise constant transformation. In
this book, a similar idea is used, but the implementation is a little simpler, not
requiring another differential equation. A non-linear transformation of the time
scale given by Craven [15, 1998], is introduced in Section 2.3. The transfor-

22
OPTIMAL CONTROL MODELS IN FINANCE
mations in this chapter are the essential part of the algorithms in the research,
and will be directly applied in Section 2.6.
Consider a financial optimal control model, to minimize an integral:
subject to:
The time interval [0,1] is divided as follows:
so there are 
subintervals:
A scaled time 
is constructed here to replace the real time in computation;
will be used later in the “nqq” package (differential equation solver).
The scaled time 
takes values:
where 
thus the time intervals [0, 1] is divided into equal intervals.
The relationship between and can be expressed by the following formula:
where
Thus the subdivision point 
maps to point
Now the control 
takes values:

The STV Approach to Financial Optimal Control Models
23
in successive subintervals:
Define
Then the dynamic equation
transforms to:
The objective function transforms to the sum of integrals:
3.
Non-linear Time Scale Transformation
In some time-optimal control problems or optimal control problems that are
over a long time interval, the large number of subintervals of the time scale will
cause computational difficulty. The optimal control functions lead to stable
values monotonically when time 
becomes large. So it would be useful if
a suitable non-linear transformation of time scale is practical, (see reference
[15, 1998]). With a suitable non-linear time scale, a few subintervals may be
enough to get the same accuracy of large subintervals.
Goh and Teo [33, 1987] introduced a change of time scale for a time-optimal
control problem while the terminal time T is a variable. Let 
where
is the new time variable mapping in [0,1]. 
is again written for 
then
problem becomes a fixed-time optimal control problem with time interval [0,1]
and parameter T. This allows T to be computed accurately without being
interpolated between subdivision points.
This makes the original financial optimization problem as the following:

24
OPTIMAL CONTROL MODELS IN FINANCE
subject to:
Transform into:
subject to:
This transformation will be used later in the computational methods 4.1 - 4.5
for the financial model in Chapter 4.
Now consider, an objective function with a discount factor 
where 
is
positive, thus:
Define time as:
The objective function becomes:

The STV Approach to Financial Optimal Control Models
25
and the differential equation changes from 
to:
For T is fixed and large, the denominator satisfies 
If
T is a variable to be optimized over, then 
replaces the variable T, in an
interval
For example, in a fixed-time optimal control problem, if there is some “dis-
tinguished time” 
then an additional constraint 
must
be satisfied. A transformation of 
to 
maps 
to 
thus to a
subdivision point. In particular:
At 
the piecewise-linear transformation is not differentiable, and the
co-state may be discontinuous.
4.
A Computer Software Package Used in this Study
The computer package SCOM ([18, 2001]) is a tool to solve step-function
optimal control problems on MATLAB 5.2, on a Macintosh computer. It is
noted that a program written and compiled in C language will run faster than a
MATLAB program for the same computation. However MATLAB is a matrix
computation language, so it requires much less programming work in calcu-
lating matrix operations on MATLAB than other computer languages, such as
C language and Fortran, etc. The program “constr” is a constrained optimiza-
tion package in MATLAB’s Toolbox, based on a SQP (sequential quadratic
programming) method. “constr” will use gradients if supplied; otherwise it
will estimate gradients by finite difference. In non-linear programming meth-
ods, the SQP method is very successful. The method closely mimics Newton’s
method for constrained optimization, just as it is done for unconstrained opti-
mization. Using a quasi-Newton updating method , an approximation is made
of the Hessian of the Lagrangian function at each major iteration. It is then used
to generate a Quadratic Programming sub-problem whose solution is used to
form a search direction for a line search procedure. In the research, we build
another subroutine to be called as the objective function in “constr”.

26
OPTIMAL CONTROL MODELS IN FINANCE
The state functions in this research were solved by the differential equation
solver “nqq” in the SCOM package (see details in Appendix C). When results
of the state come out on the grid-points, the objective function 
becomes
a function 
of N variables that can also be calculated by
“nqq”.
When the subroutines for the state functions and objective function are con-
structed, the MATLAB program “constr” is then used to obtain the optimal
solution of the problem with respect to optimal switching times. In the pro-
gram, the control 
is approximated by a step-function.
5.
An Optimal Control Problem When the Control can
only Take the Value 0 or 1
From the point of view of control theory, the bang-bang optimal control
happens when the systems of the optimal control problems are linear in control.
The Nerlove-Arrow model [63, 1962] is an example of a bang-bang control
following a singular arc control. Now, introduce a typical bang-bang optimal
control problem.
We consider an optimal control problem:
subject to:
In this case, the state function 
is assumed piece-wise smooth, and the
control 
jumps many times between 0 and 1 during the time interval [0, T].
Here, simplify the problem to T = 1. Now use a step-function:
to approximate the control 
Here the target function is: 
Let
Observe that if having instead 
then
would be optimal, with 
But if 
must be either 0 or 1, then

The STV Approach to Financial Optimal Control Models
27
will jump many times between 0 and 1. Suppose a further restriction is
made that, for some given integer 
time interval [0, 1] is divided into 
equal
subintervals
takes a constant value (1 or 0) on each subinterval
So if 
takes the values in this pattern 1, 0, 1, 0, …, 1, 0
on the successive subinterval, then each subintervals contributes 
to
as 
But the optimal value J = 0 is not
reached, unless an infinite number of jumps are allowed.
Now a term
   is added to the objective function. (2.7) is modified as
follows:
Here, K is the cost of changing control and 
is the number of time intervals.
The objective function of the optimal control problem becomes a cost function.
The algorithms in the next section are used for solving these kind of optimal
control problems.
6.
Approaches to Bang-Bang Optimal Control with a Cost
of Changing Control
In this section, the computational methods for solving bang-bang optimal
control problems with a cost of switching control are introduced. Simply mod-
ifying certain parts of these methods can satisfy a class of similar problems.
Suppose the number N of switching times is fixed by N = nn, say switch-
ing times 
Now consider (2.7) as a function of the switching
times, say 
Then the minimum of this function
is computed, starting from a small value of N. Here the components of the
vector
are the lengths between each switching
time. The vector um must satisfy the upper and lower bounds 0 and 1, thus
and a constraint 
must be satisfied. The
vector
represents the values of the state func-
tion takes at each switching time. The algorithms are as follows:
Algorithm 2.1 Main Program (see project1_1.m in Appendix A.1)
Step 1. Initialization. Set the maximum number of function evaluations, par,
which is the system parameter of the MATLAB “constr” function, and
also another system parameter par(13) = 1 (1 represents the number
of the equation constraint in the minimization problem), and a vector of
the parameters which are used in the whole subroutines, par = [number
of the state components, number of control components, nn= number of
total subintervals], arbitrary starting lengths of switching time intervals

28
OPTIMAL CONTROL MODELS IN FINANCE
and vector ul = lower bound of um,
vector uu = upper bound of um, thus 
Initialize the value
of the state function xinit.
Step 2. Call the MATLAB “constr” function. In turn, “constr” calls the “Mini-
mizing Program” to calculate the minimization of the calling program with
respect to the optimal vector um.
Step 3. Input the optimal result um into “Minimizing Program” again to ob-
tain the results of the objective function 
(the last value of the calcula-
tion) and the state vector xm, corresponding to the optimal um.
Step 4. Attach a cost K to nn. Add
  to the objective function (2.7) and
calculate
Step 5. Set a bigger nn; then go back to Step 2; EXIT when the result of cost
function J stops decreasing.
Algorithm 2.2: Minimizing Program (see project1_2.m in Appendix A.1)
Step 1. Initialization. Input vectors um, par and initial state xinit. Set the
initial state xm(1) = xinit, and nx = par(1), the number of the state
components, nu = par(2), the number of the control components; initial-
ize scaled time 
subinterval counter it = 1, hs = 1/nn(length of
each equal subinterval). Choose the “Input function for dynamic equation”
as the right side of equation (2.9) to calculate the differential equation, input
um.
Step 2. Call SCOM package function “nqq” with the stated “Input function
for dynamic equation” to solve the differential equation (2.9) of the state
function 
Tabulate the solutions as the components of the vector
Step 3. Set the initial state zz = 0. Set initial scaled time 
subinterval
counter it = 1 again, choose the “input function for integration calcula-
tion” for SCOM function “nqq” for solving the integration of the objective
function (2.7), input vector xm and um.
Step 4. Call SCOM function “nqq” with the stated “Input function for integra-
tion calculation” to calculate:
where:

The STV Approach to Financial Optimal Control Models
29
when:
by solving the differential equation:
when:
Tabulate the results in 
as the components of vector
Step 5. Take the last result of the vector jm as the value of the objective func-
tion, and calculate the constraint function of “Minimizing program”, which
is:
Algorithm 2.3: Input function for dynamic equation (see project1_3.m in
Appendix A.1)
Step 1. Initialization. Input scaled time
subinterval counter it, the length of
subintervals hs, and vector um, and set the number of subintervals nn =
1/hs.
Step 2. Set the control policy as vector 
with al-
ternating values 1 and 0 (as in 2.10) in successive subintervals.
Step 3. Construct the right side of the differential equation for the state func-
tion using the piecewise-linear transformation in (2.5).
Algorithm 2.4: Input function for integration calculation (see project1_4.m
in Appendix A.1)
Step 1. Initialization. Input scaled time 
subinterval counter it, the length
of subintervals hs, vector xm representing the values of the state function
at each switching time, and also a new initial state 
for integral, and the
vector um. Set the number of subintervals nn = 1/hs.
Step 2. Use the linear interpolation to get an estimate “xmt” of the state, in a
time
between grid-points 
where
Step 3. Add up components of the lengths of the switching time intervals in
um to obtain the switching times 
in (2.4).
Step 4. Construct the right side of the equation (2.4) to obtain the time variable

30
OPTIMAL CONTROL MODELS IN FINANCE
Step 5. Calculate the integral in (2.6) at scaled time
When the number of switching time N increases, the cost function decreases
because of the better approximation. While calculating a minimization prob-
lem 
the term KN increases with N increasing, and 
decreases
with bigger N. It can be found that the cost of changing control is very criti-
cal in the cost function. A proper chosen cost K will efficiently lead the cost
function to the minimum. The analysis of the cost will be discussed in later
sections.
7.
An Investment Planning Model and Results
In this section, the computational results reported by a set of graphs will
be introduced to verify the algorithms developed in Section 2.6. First we will
introduce the fitting function. In this example, the fitting function is set to be
The state function 
is used to approximate this fitting function. The
formulae for this financial optimal control model is shown as follows:
subject to:
where x(t) = stock price, u(t) = the proportion of total investment in stocks
compared to other forms of financial investment.
Although the above model is an illustrative model, it can, however, represent
an interesting financial decision making problem. The state equation represents
the dynamics of the price of a stock. It is assumed that the change in the
price of a stock is determined by the proportion of allocation of total funds for
purchasing a stock. The objective of this control problem is to determine the
value of u(t) (which only takes the value of 1 or 0) which can optimize the
objective function so as to minimize the deviation of the state variable from
its target value specified. Therefore this model (2.11 to 2.15) is an investment
planning model with some sub-utilization criterion included in the model.
The target function is 
First set 
(n is the number of time
intervals), and control takes as 1,0 in time intervals 
The model
2.11 to 2.15 was solved with these parameter values and the results are shown

The STV Approach to Financial Optimal Control Models
31
in Appendix B.1 and are represented by Figure 2.1. In Figure 2.1, it is shown
that during the planning horizon [0,1], the control only jumps once at time
The state vector xm takes the value [0.127, 0.127] at the grid-points
of two subintervals [0, 0.127] and [0.127, 1]. The approximation between the
state function xm and the fitting function 
is not very good when the
number of the switching times is quite small 
is only 2). “*–” represents
the state function 
and “.” represents the fitting function 
in the
following graph.
Figure 2.1. Plot of n=2, forcing function ut=1, 0
Then increase 
to 4. During the whole time [0,1], the control jumps three
times. A better approximation is shown in Figure 2.2 with more jumps of the
control.
Figure 2.2. 
Plot of n=4, forcing function ut=1,0,1,0

32
OPTIMAL CONTROL MODELS IN FINANCE
Set 
and run the program. A much better approximation than
is shown in Figure 2.3 because of the increased switching times.
Figure 2.3. 
Plot of n=6, forcing function ut= 1,0,1.0,1,0
When 
a very close fit between state xm and the given fitting function
is shown in Figure 2.4. The result proves a very good convergence of the
algorithms.
Figure 2.4. Plot of n=8, forcing function ut= 1,0,1,0,1,0,1,0
In Figure 2.5, although the approximation between xm and 
is still get-
ting better when 
the difference between the result of 
and
is not as big as between 
and 
The decreasing of the results of the
objective function slows down when 
is very large.

The STV Approach to Financial Optimal Control Models
33
Figure 2.5. 
Plot of n=10, forcing function ut= 1,0,1,0,1,0,1,0,1,0
The results of the objective function according to different numbers of the
time intervals 
are put in Table 2.1. The decreasing of the results of the
objective function follows the increases number of the time intervals 
When
is small, the result of the objective function will decrease very fast, however
this decrease will slow down when becomes big. A good illustration is shown
in Figure 2.6.
In Figure 2.6, the results of the objective function against the different num-
ber of the time intervals 
are shown. From the graph, we will find out that the
descent of the results of the objective function slows down when the number of
time intervals 
increases. The conclusion can be made that more jumps of the
control in the time period [0, 1] give a better association between the state
and fitting function 
(i.e. makes the financial system more stable along

34
OPTIMAL CONTROL MODELS IN FINANCE
its desired path) and leads the financial system to reach the best fit when
becomes infinity.
Figure 2.6. 
Plot of the values of the objective function to the number of the switching times
The optimal control problem in (2.11)-(2.15) is computed and the results are
shown in the above graphs. The number of time intervals 
is
set consequently. A better fit comes into being Figures 2.1, 2.2, 2.3, 2.4 and 2.5.
In Figure 2.6, it is shown that the result of the objective function J decreases
while the number of time intervals 
increases. Same results are also shown in
Table 2.1. Now a proper cost K is set and attached with the number of the time
intervals 
to the objective function J. The objective function (2.11) becomes:
Use the algorithms to solve this new optimal control problem with the same
constraints as in (2.12)-(2.15). Three different values of cost K are chosen for
The results of adding K * n to the objective function
are shown in Table 2.2, corresponding to

The STV Approach to Financial Optimal Control Models
35
From the results in Table 2.2, a conclusion can be made that only when
cost K takes a certain value, it will lead the cost function to a minimum in-
finite switching times. When K = 0.02, the results of the cost function are
increasing from 
to 
and the increases become faster. When
K = 0.0002, the results are decreasing, but this decrease begins to slow down
when 
increases. It is conjectured that when the number of the switching
times 
is getting very big, this decreases will stop at a certain value of
Meaningful results from K = 0.002 are given, and a minimum is obtained at
The following Figure 2.7 shows the results of the cost function against
the number of the time intervals 
while the cost K = 0.002 is attached to the
objective function. The bottom of the line in the figure is the minimum point
Figure 2.7. 
Plot of the cost function to the cost of switching control
This is an effective example of computational algorithms. All the results
confirm the accuracy of computational algorithms in Section 2.6. A hand cal-
culation of the part of the differential equation to exam the algorithms also
gives a proof of computational accuracy. Some other experiments with differ-
ent fitting functions will be discussed later in Chapter 5.

36
OPTIMAL CONTROL MODELS IN FINANCE
8.
Financial Implications and Conclusion
The crucial aspect of the computational experiments undertaken here is that
switching times and and the cost of switching times have significant implica-
tions for optimal investment planning. 
As the graphical results showed in
Section 2.7, different numbers of switching times lead to different results for
the objective function of the financial model. While the number of switching
times increases, the value of the objective function decreases. That means a
better fit is obtained. When a cost of changing control at each switching time
is added to the original objective, the perspective changes. In the present case,
when the number of switching times increases, the value of the term, which
includes cost and the number of the switching, also increases. This increase
slows down the decreasing of the original objective function. When the number
of switching times increase to a certain value, the cost function stops decreas-
ing and instead increases. The intermediate point between the decreasing and
increasing is the optimal point.
The value of the cost of switching significantly influence the values of the
switching times and optimal control. Comparing with the result of the objective
function, if the cost is too big, the cost functional will increase all the time. It
can be explained that it costs too much to change a control at each time interval.
The financial system can never reach an optimal solution. But if the cost is too
small, it could not affect the cost function at all. Then the control will jump
infinitely in the time period to search an optimal solution, which is difficult
to realize in real computation. Therefore, the value of the cost of switching
time affects the optimal number of switching time. In terms of the value of the
optimal control, it is found that several jumps in the strategy of investment in
the stock market, shown by 1,0 values of investment in the stock market are
optimal. A higher cost for switching reduces the optimal value of switching
times compared to a situation when there is no cost for control switching.
An optimal investment strategy, therefore, should always be made on the
consideration of the cost of control switching to determine how often the in-
vestment strategy can be changed between 1 and 0.
In the next chapter, a financial oscillator model for optimal aggregative in-
vestment planning will be presented. Since the oscillator problem has a state
function, which is a second-order differential equation, the computational al-
gorithms require transforming the second-order differential equation into two
equivalent first-order differential equations. A new time scaled transformation
for better integral calculation will be introduced in Section 3.3. The corre-
sponding transformations of the state functions and the objective function will
also be contained in Section 3.3. The computational algorithms for the finan-
cial oscillator problem will be described in Section 3.4. The computer software
packages for these algorithms will be introduced in Appendix A.2. Differ-
ent patterns of the control might lead the computation to different minimum

The STV Approach to Financial Optimal Control Models
37
points. The control with different initial starts was put into the program. The
final result of the comparison will be the optimum of the control problem. The
computing results of a particular oscillator problem are represented in graphs
and tables in Section 3.6.

This page intentionally left blank

Chapter 3
A FINANCIAL OSCILLATOR MODEL
1.
Introduction
The financial sector is very volatile, more volatile than the business cycle
instabilities of the whole economy. Modeling the oscillatory dynamics of the
financial sector is well developed. This type of dynamic financial system can
also be modeled as an oscillatory optimal control model with dampening where
a control law is specified in the model to make the financial system stable (see
Sengupta and Fanchon [80, 1997]). The objective of this type of model in-
volves the minimization of deviations of the system variables from their de-
sired path. Such an oscillatory financial model is developed and computed
in the chapter. These type of oscillatory financial models are useful in finan-
cial decision making since general optimal control models may not provide
stabilization policies and the damped oscillator models provide an effective
stabilization mechanism.
In Section 2.5, a financial optimal control model, which has one state func-
tion, one control function, and the control taking two constant values sequen-
tially, was discussed. The computational algorithms were also developed and
applied to this problem (For a general discussion of this approach see also Chen
and Craven [10, 2002], as most of the materials in this chapter are adapted in
this paper. However, while Chen and Craven [10, 2002] provide a discussion
of the approach, the present chapter shows the application of this approach
to financial modeling only.) Substantial results were obtained to verify the
algorithms. In this chapter a more complicated optimal control problem is in-
troduced in Section 3.2 that can represent the oscillatory behavior of the finan-
cial sector. The financial system includes a second order differential equation.
A transformation of time scale used to obtain the optimal switching times as
well as a better gradient is described in Section 3.3. The transformations of

40
OPTIMAL CONTROL MODELS IN FINANCE
the control, state, and the objective function are changed corresponding to the
new time subdivision. The computational methods for these kinds of optimal
control problems are constructed in Section 3.4. In this chapter, the control is
also approximated by a step-function. Additional analysis of the control with
different patterns leading to different minimums is discussed in Section 3.5.
In Section 3.6, two sets of graphical results with different control patterns are
presented.
In economics problems, the dynamic behavior may require a second order
differential equation and more than one control. In Blatt [2, 1976], some gen-
eralizations of multi-state functions and controls were discussed. But Blatt
did not give any explicit proof and explanation of these generalizations. The
computational algorithms in this chapter effectively solve the second order dif-
ferential equation. This technique is also applied to an optimal corporate fi-
nancing model later in Chapter 4.
2.
Controlling a Damped Oscillator in a Financial Model
We consider an aggregate dynamic financial system described by a second-
order differential equation as follows:
This financial system second order differential equation can be transformed
into an equivalent pair of first-order differential equations:
We now consider an oscillator problem with the bang-bang optimal control
solution. A damped oscillator financial model for the above aggregate financial
system with forcing function 
and parameter T, is presented as follows
(see another version of this financial model in Section 5.3.1):
/indexforcing function
subject to:

A Financial Oscillator Model
41
where 
= stock prices, 
= the proportion of investment in stocks com-
pared to other form of financial investment.
Here 
is a given target function showing the desired path to be achieved
by the financial system. Suppose that 
is restricted by:
Since the dynamics are linear in 
if an optimum is reached, then bang-
bang control may be expected, with possibly a singular arc for a time interval.
However, singular arc control is not considered here.
The model (3.2) to (3.7) represents a financial decision making problem
where the cost of changing control is added to the objective function, shown as
follows:
Here, K is the cost of switching control, 
is the number of control jumps. The
modified model calculates the optimal allocation for stocks with an explicit
consideration of changing allocation shares. The cost function becomes the
new objective function to be computed.
The model (3.2) to (3.7) is similar to the model (2.11) to (2.15) and repre-
sent a financial decision making problem of choosing the optimal allocation
of finance in an economy for stocks. The forcing function is an additional
feature of this model compared to the model in (2.11) to (2.15). To make the
model realistic, it is necessary to incorporate the cost of changing control in
this model.
3.
Oscillator Transformation of the Financial Model
In this section, a good transformation of time scale is introduced. The com-
puter package “nqq” is also used for solving the differential equations in this
chapter. However, the “nqq” package does a limited job, it only does one
Runge-Kutta step for each subinterval given to it. So when smaller subinter-
vals are needed for accuracy, they must be supplied by the “small subintervals”

42
OPTIMAL CONTROL MODELS IN FINANCE
construction. Although “nqq” package has this limitation, it has a great ben-
efit for solving the differential equation with a non-smooth right-hand side of
the differential equation which means there can be jumps at the end-points of
intervals. Since a time-optimal control problem is not considered in this re-
search, T is a constant. To make it easy, the time period of the optimal control
problem described in last section is simplified to be [0,1] (the transformation
of time scales when T is variable was given in Section 2.3).
First, the time horizon [0, 1] is divided into nb “big subintervals”, with end-
points:
Since the functions change quite rapidly within each big subinterval, further
subdivisions into “small intervals” are needed to get sufficient precision in
solving the differential equations. Then each subinterval
is subdivided into ns “small subintervals” with end-points:
The whole subdivision of the time interval [0, 1] is shown as follows:
The relationship between 
and can be represented as follows:
The control only jumps from one big interval to the next one. It takes values
as follows:
A scaled time 
is constructed for the computer package, corresponding to
the total number of subintervals
which takes values:

A Financial Oscillator Model
43
Here,
Two vectors which represent two different levels of the subdivision of the
time period [0,1] um and sm are defined for mapping the control and calcu-
lating the integral (see the next section).
The relationship between the real time which is used in the calculation of
the integration and the scaled time 
is shown as follows:
where 
time 
and 
 
Here, the
control only jumps at the end-points of the big subintervals. Thus the control
has the same constant value in all the small subintervals which make up a big
subinterval. Another real time pt which represents the real switching times for
the control is defined as follows:
where, nb is the number of big subintervals. This pt is used in differential
equation solving with respect to control 
Correspondingly the control and
state with respect to 
are defined:
The two first-order differential equations of the state functions of the finan-
cial system in (3.2) and (3.3) are transformed into two equivalent first-order
equations:

44
OPTIMAL CONTROL MODELS IN FINANCE
The objective function of the financial optimal control model is then trans-
formed to a sum of integrals in successive subintervals:
where h = 1/nn, nn = nb*ns.
4.
Computational Algorithm: The Steps
In this approach, time intervals of the financial model are defined at two
levels, with the planning period [0, T] first divided into nb big intervals, repre-
sented by vector um (see also Chen and Craven [10, 2002]):
then each big subinterval is subdivided into ns small subintervals. Thus [0, T]
is subdivided into nb * ns numbers of subintervals, represented by the vector
sm:
At each end-point of the big subintervals, the control jumps.
Algorithm 3.1 Main Program for the oscillator problem (see project2_l.m
in Appendix A.2)
Step 1. Initialization. Set a vector of parameters par = [the number of the state
components, number of control components, nb = the number of big subin-
tervals, ns = the number of small subintervals]; and get the total number
of the subintervals by calculating nn = nb * ns. Set the MATLAB “con-
str” function’s system parameters par(13) = 1 (here, 1 represents only one
equation constraint in the minimization problem), par(14) = the maximum
number of function evaluations; arbitrary starting lengths of the switching
timeintervals 
Set the vectors of upper

A Financial Oscillator Model
45
bounds uu and the vector of lower bounds ul of um, thus
Also set the initial state xinit.
Step 2. Call the MATLAB “constr” function. In turn, “constr” calls the “Min-
imization Program” to calculate the minimization of the calling program
with respect to the optimal vector um.
Step 3. Input the optimal result um into “Minimization Program”, to obtain
the values of the objective function J(nn) (the last value of the integral)
and state vector xm (xm is a vector of all the values of the state functions
take at the grid-points of the switching time intervals).
Step 4. Attach a cost K to nn. Add K * nn to the objective function (3.2) and
calculate
Step 5. Set a bigger nn and new starting time intervals, go back to Step 2;
EXIT when the result of cost function J stops decreasing.
Algorithm 3.2: Minimization Program (see project2_2.m in Appendix A.2)
Step 1. Initialization. Input um, par and initial state xinit. Set the initial state
xm(1, :) = xinit, and nx = par(1), the number of the state components,
nu = par(2), the number of the control components, nb = par(3), the
number of big time intervals, ns = par(4), the number of small time inter-
vals, nn = par(3) * par(4), the number of total time intervals; initialize
the scaled time 
subinterval counter it = 1, hs = length of each equa-
tion subintervals. Choose the “Input function for second order differential
equation” as the right side of the differential equation (3.1), input um (in
this chapter, the second order equation in the optimal control problem is
transformed into two equivalent first order differential equations; so there
are two state functions).
Step 2. Construct the vector sm whose components represent the lengths of
the all time intervals by dividing each big time interval um by ns.
Step 3. Call the SCOM package function “nqq” with the stated “Input function
for second order differential equation” to solve the two equivalent first order
differential equations (3.3), (3.4) for the state function 
Tabulate the
solution for the state as the vector
is the result of (3.3),
is the result of (3.4).
Step 4. Set the initial scaled time 
subinterval counter it = 1, initial
state zz(: 1) = 0, ma = 1, the number of the input state function. Choose
the “input function for the oscillator problem” for SCOM function “nqq”

46
OPTIMAL CONTROL MODELS IN FINANCE
to solve the integration of the objective function (3.2). Input the vectors
xm(: 1) and sm.
Step 5. Call SCOM function “nqq” with the stated “Input function for the os-
cillator problem” to solve the differential equation
Tabulate results in 
as the components of vector
Step 6. Take the last result of the vector jm as the value of the objective
function, and calculate the constraint function of “Minimization program”
which is
Algorithm 3.3: Input function for second order differential equation (see
project2_3.m in Appendix A.2)
Step 1. Initialization. Input scaled time 
subinterval counter it, the length of
total subintervals hs and vector um. Set the value to parameters T, (set
B for(3.18) and (3.19) in the next section). Set the number of the total
subintervals nn = 1/hs.
Step 2. Obtain the number of the big time intervals by nb = nn/ns for estab-
lishing the control policy.
Step 3. Set the control policy as vector 
with al-
ternating value 1 and –1, see (3.8); the control only jumps at the end points
of the big time intervals.
Step 4. Construct the right side of the transformation equation for time pt in
(3.10): 
for
Step 5. Obtain the right sides of the differential equations by using the trans-
formations in (3.13) and (3.14):
Algorithm 3.4: Input function for the oscillator problem (see project2_4.m
in Appendix A.2)
Step 1. Initialization. Input scaled time 
subinterval counter it, the length of
total subintervals hs, vector xm of values of first state function at switching
times, and also the initial state 
and vector sm. Set the number of the total
subintervals nn = 1/hs.
Step 2. Use linear interpolation to get the estimate “xmt” of the state, in a
time between grid points 
where
Step 3. Add up the time intervals sm to get time 
in (3.9):
for

A Financial Oscillator Model
47
Step 4. Construct the right side of the equation (3.9) to obtain time variable
Step 5. Calculate the integrand in (3.15) at scaled time t:
5.
Financial Control Pattern
The financial dynamic system introduced in Section 3.2 is a second-order
differential equation, and the forcing function /indexforcing function 
takes
values such as –2, 2, –2,2,..., switching between them at optimal switching
times determined by an optimization calculation. Note if 
is restricted
to choose two values –2 and 2, then both the patterns –2,2, –2,2,... and
2, –2,2, –2,... have to be computed. The comparison of the solutions of
these two patterns will be discussed in next section. This research studies
a set of bang-bang controls that jump on the extreme points of the feasible
area. However, since the sequences of the control switching are not defined,
all the sequences of the control patterns need to be computed and analyzed. A
numerical example in financial modeling is shown next.
6.
Computing the Financial Model: Results and Analysis
In this section, the control 
is set to be –2 and 2. The solutions of two
different initial starts of control 
are discussed and compared.
We can formulate the financial optimal control problem as follows:
subject to:
takes value – 2,2,... or 2, –2,... in successive time intervals (3.19)
The target value of the target =
– 5.

48
OPTIMAL CONTROL MODELS IN FINANCE
Computational results are indicated in Table 3.1 above.
All the graphs shown below and on the following few pages are the com-
puting results of the financial optimal control problem (3.16)-(3.22). There are
three sets of the graphs, which represent the solutions at nb = 2, nb = 4,
and nb = 6, where nb is the number of the big time intervals. In each set,
the big time interval is subdivided by ns = 1,2,4,6,8,10 respectively, where
ns is the number of the small time intervals. Each set has six pairs of graphs
representing six different subdivisions. All the graphs are shown in the same
order. A pair of graphs represent “the state function 
and the given fitting
function against time 
and the comparison of two state functions, 
and

A Financial Oscillator Model
49

50
OPTIMAL CONTROL MODELS IN FINANCE

A Financial Oscillator Model
51

52
OPTIMAL CONTROL MODELS IN FINANCE

A Financial Oscillator Model
53

54
OPTIMAL CONTROL MODELS IN FINANCE
Set 1 for nb = 2
The first set of the graphs is the solution at nb (the number of big time
subintervals) equals 2. The time period [0,1] is divided into 
and
ns (the number of small time subintervals) takes 1,2,4,6,8,10 respectively.
As mentioned in Section 3.3, the control policy allows the control only to jump
at the end points of the big time intervals (so the control does not jump at the
end of the small time intervals). The control takes value –2,2 in two big time
intervals 
and switches once at time 
The first pair of graphs
are the results of nb = 2 and ns = 1, that is, the time period is divided by
2 big intervals and each subinterval has no further subdivision. It is obvious
that the approximation between state and the given fitting function is not very
close because of the small nb and ns. As ns (the number of small intervals)
increases, a better approximation is obtained. But since control only jumps
once during the whole time horizon, it is hard to reach the global minimum. It
is understandable that more jumps are helpful for searching a better fit – to find
a more stable financial system. Although the ns still increases, the decreasing
of the objective function slows down, thus nb needs to be increased. The results
are also reported in Table 3.1. These results demonstrate the complexities of
the dynamics of the financial system with damped oscillator.

A Financial Oscillator Model
55

56
OPTIMAL CONTROL MODELS IN FINANCE

A Financial Oscillator Model
57

58
OPTIMAL CONTROL MODELS IN FINANCE

A Financial Oscillator Model
59

60
OPTIMAL CONTROL MODELS IN FINANCE
Set 2 for

A Financial Oscillator Model
61
This set of the graphs is the graphical solution at nb = 4 and ns = 1,2,4,6,
8,10. The control policy is 
in successive time intervals
and control jumps three times at 
A better
approximation than the results at nb = 2 is shown. Most of the results confirm
the computational algorithms 3.1-3.4 except a typical case nb = 4, ns = 8.
In this case, the value of the objective function is bigger than the value of the
objective function at nb = 4, ns = 6. That means the decrease of the objective
function stopped at this point and increased instead. We also discovered that
the value of the objective function at this point is same as the value of the other
control pattern 2, –2, 2, –2 at the same point. They are shown in Table 3.1 and
Table 3.2. From this test, it may be conjectured that the optimal search stops at
a certain point for some reason. A small test was also made in the experiment,
another control policy, which was created as 
2, –2.05,2, was
put into the program to replace the old control policy. A better search was
obtained and the value of the objective function of the financial model became
J = 0.2034. The new control policy enables the optimal search to continue
until the optimum is reached.

62
OPTIMAL CONTROL MODELS IN FINANCE

A Financial Oscillator Model
63

64
OPTIMAL CONTROL MODELS IN FINANCE

A Financial Oscillator Model
65

66
OPTIMAL CONTROL MODELS IN FINANCE

A Financial Oscillator Model
67
Set 3 for nb = 6
This is the set of the graphical results at nb = 6 and ns = 1, 2, 4, 6, 8, 10.
A better approximation than nb = 4 is obtained as expected. A similar com-
putation as in case nb = 4, ns = 8 happened at case nb = 6, ns = 8 and case
nb = 6, ns = 64. In case nb = 6, ns = 8, the optimal switching times are
the control stays
at –2 from the third subinterval until the end of the time period. Although the
control policy was set to switch five times in the program, the real computation
did not show that the control jumped so often. As in the experiment we did for
case nb = 4, ns = 8, this problem also can be solved by perturbing the control
by a small amount. From the results shown in the Table 3.1, a conclusion can
be made that when the number of big intervals and small intervals increases,
the result of the objective function decreases. Although there are some unex-
pected results, a small disturbance of the control can easily obtain the correct
answers. The experiment gave some promising results which confirm the ac-
curacy of the computational algorithms in this chapter.
Another experiment is also presented to indicate the effects of the different
patterns of the control.

68
OPTIMAL CONTROL MODELS IN FINANCE

A Financial Oscillator Model
69

70
OPTIMAL CONTROL MODELS IN FINANCE

A Financial Oscillator Model
71

72
OPTIMAL CONTROL MODELS IN FINANCE

A Financial Oscillator Model
73
Set 1 for nb = 2

74
OPTIMAL CONTROL MODELS IN FINANCE

A Financial Oscillator Model
75

76
OPTIMAL CONTROL MODELS IN FINANCE

A Financial Oscillator Model
77

78
OPTIMAL CONTROL MODELS IN FINANCE

A Financial Oscillator Model
79
Set 2 for

80
OPTIMAL CONTROL MODELS IN FINANCE

A Financial Oscillator Model
81

82
OPTIMAL CONTROL MODELS IN FINANCE

A Financial Oscillator Model
83

84
OPTIMAL CONTROL MODELS IN FINANCE

A Financial Oscillator Model
85
Set 3 for nb = 6

86
OPTIMAL CONTROL MODELS IN FINANCE
In this group of graphs, the pattern of control is 2, –2,2, –2,.... Like the
previous experiment, this experiment starts from nb = 2, ns = 1 and increases
nb and ns gradually. As expected, better approximation is obtained by increas-
ing either nb or ns. Unexpected answers were also found at certain points. A
small perturbation is helpful to gain the accurate results. Here, we only put
the attention on the comparison of these two different patterns of the control.
From Table 3.1 and Table 3.2, it is found that the values of the objective func-
tion of two different control patterns at starting points (nb = 2, ns = 1) have
big differences. Pattern – 2 , 2 , – 2 , 2 , . . . gives much better result than pattern
2, –2, 2, – 2 , . . . . It is an interesting phenomenon that when nb and ns be-
come very big (more jumps and better gradient), the results of the objective
function with different control patterns are very close. We can conclude that
when optimal control jumps infinitely and the integration calculation has more
subdivisions of the time period, the better fit for the problem can be reached
whatever pattern of the optimal control is used.
Figure 3.1 and Figure 3.2 show the results of the objective function against
1/ns at two different control patterns. The value of the objective function tends
to zero when the number nb of subdivisions increases. It is also confirmed
that a greater number of subdivisions of the time interval will lead to a better
integral calculation. The three lines in each figure also show that more jumps
of the control will give better approximation. In the next figure, a cost 
is
added to the objective function. A complete description of the cost of switching
control has been discussed in Chapter 2. In this chapter, a cost is only attached
to the number of large subintervals concerned with the control jumping, shown
as follows:
K is the cost of changing control, nb is the number of large subintervals.
In this computation, K is set to be 0.01, and ns = 64 for the accuracy of the

A Financial Oscillator Model
87
calculation. The same constraints (3.17)-(3.22) are included for this modified
optimal control problem (3.23).
Figure 3.1. 
Plot of integral F against 1/ns at ut=-2,2
Figure 3.2. Plot of integral F against 1/ns at ut=2,-2

88
OPTIMAL CONTROL MODELS IN FINANCE
Figure 3.3.
Plot of cost function F against the number of large time intervals nb
As discussed earlier, two different levels of the subdivision of the time in-
tervals are used in this example. But the control policy is only constructed so
that the control switches at the end of the large subintervals. In two experi-
ments shown in Figure 3.3, a cost
attached to nb (the number of the
large subintervals) is added to the objective function. It is known that a greater
number of subintervals lead the system to a more accurate minimization. A
more accurate value of the objective function can be obtained when
The cost is attached to the results of the objective function at ns = 64. Two
different lines in Figure 3.3 represent the results of the two different patterns
of the control which are shown in Figure 3.1 and Figure 3.2. At point nb = 6,
both of them reach the optimum. It is confirmed that the financial system with
two different control patterns will reach the same minimum with the same cost
when the number nb of subdivisions increases.
Since there are some non-switching times obtained from the computation, it
is conjectured that whether an optimal control with a zero value in the middle to
match the non-switching times can bring a better approximation. An example
with this matching control will be discussed in Chapter 5.

A Financial Oscillator Model
89
7.
Financial Investment Implications and Conclusion
Since the financial sector is volatile, a financial oscillator model is neces-
sary to study the non-linear complex dynamic behavior of the sector. Incorpo-
ration of a damping function to stabilize the oscillatory dynamics of the finan-
cial sector can facilitate an understanding of the control mechanism useful for
smooth functioning of the financial market. The modeling and computational
experiments in this chapter show similar results as those obtained in Chapter 2.
Switching times and costs of switching control are significant factors in the de-
termination of optimal investment planning strategy for the economy. Higher
costs of switching control reduce the optimal number of switching times es-
sential in evolving an optimal investment strategy overtime. The dampening
factor is also significant in designing stable optimal investment planning.

This page intentionally left blank

Chapter 4
AN OPTIMAL CORPORATE FINANCING MODEL
1.
Introduction
In this chapter, an optimal corporate financing model (Davis and Elzinga
[22, 1970]) has been used since it is one of the well known and pioneering
models on optimal control in finance. Some other recent work in this area
include [21, 1998] and [61, 2001]. The approaches that were constructed in
Chapter 2 and Chapter 3 for the optimal control problems are applied. The
model discusses investment allocation in order to decide what proportion of its
earnings should be retained for internal investment and what proportion should
be distributed for shareholders and dividends in a public utility. The aim is to
choose the “smart” investment program that the owners can get most benefits
from. In the real world, these kinds of problems are common.
Section 4.2 defines the problem of this financial model. Then the analytical
solution, which was created by Davis and Elzinga, is discussed in Section 4.3.
In Section 4.4, an important technique called “penalty term” is introduced for
solving optimal control problems with constraints and end-term condition. By
using the “penalty term”, all the constraints become easy to be included into
the cost function. The transformations of this model are described next in Sec-
tion 4.5 for the computation. The computational algorithms for this model are
constructed in Section 4.6. A computer software package for the algorithms is
shown in Appendix A.3. The analysis and discussion of the computing results
are presented in Section 4.7.
2.
Problem Description
A firm decides how it should generate its finance to maximize the value of
the firm, the stock value, or to achieve any other specified objectives. Two well
known papers by Modigliani and Miller [59, 1958] [60, 1963] were instru-

92
OPTIMAL CONTROL MODELS IN FINANCE
mental in developing the literature on the modern theory of optimal corporate
finance. According to this theory, the optimal financial structure of the firm is
determined by the optimal financing level, the cost of capital or the weighted
average cost of capital 
is equal to the weighted average costs of alternative
sources of financing. For a firm, if funds can be obtained from debt or equity
and retaining earnings, the optimal financial structure of the firm is given at the
marginal investment, where:
where 
= the value of stock,
= the current value of the firm - the value of
all outstanding claims against the firm’s assets, 
= the cost of equity, 
= the
value of retained earnings, 
= the opportunity cost of the retained earnings.
It is academically interesting and practically useful to determine the opti-
mal proportion between different funds that minimize the cost of capital and
to maximize the value of the firm. In a dynamic framework, there may be
switches among funds over time depending on the developments in the firm
and in the financial market and the economy. It is, therefore, important to
know the optimal timing for switching from one source of funds to another,
which is optimal for the firm in minimizing the cost of capital and maximizing
the value of firm. Unlike Modigdiani and Miller, it is assumed in this paper
that the structure of capital has impact on the values of shares and the firm.
Modeling optimal corporate financial structure is a useful area for research
in corporate finance since such models can provide information about the op-
timal proportion of sources of finances of the corporation, its investment and
dividend strategies over a period of time. Dynamic optimization models in
the form of optimal control in addressing optimal corporate financial structure
have been developed initially by Davis and Elzinga [22, 1970], Krouse and Lee
[49, 1973], Elton and Gruber [26, 1975] and Sethi [78, 1978] (see also Craven
[14, 1995], Sethi and Thompson [79, 2000]).
A general limitation of the existing literature on optimal corporate financing
is that although there are some analytical studies in this area, computational
exercises (numerical model building, application of an algorithm and develop-
ment or application of a computer program) are not well known (except Islam
and Craven [38, 2002]). One limitation of the existing literature on the compu-
tation of optimal corporate financing models (including Islam and Craven [38,
2002]) is that the algorithms applied to solve these models produce optimal lev-
els of various funds, but do not generate optimal timing for switching from one
fund to another fund. In this paper, a computational approach (algorithm and
program) which can generate optimal switching time among different funds is
presented.

An Optimal Corporate Financing Model
93
In terms of algorithm, there is a scope for improvement in the existing al-
gorithms for computing optimal corporate financial models as well. The limi-
tation of the existing literature on optimal control with switching times is that
computation of such models is performed by algorithms based on discretiza-
tion of the switching time. After switching time discretion, the resulting model
is a discrete time continuous variable optimal control model with switching
times. If the switching times are sub-division times of time discretization, this
method can generate a unique solution. In models where switching time is
made a parameter or a variable, the determination of optimal switching time
may also be difficult due to the difficulty of the switching times and time sub-
divisions not coinciding. If the sub-division times and the switching times are
different, then the computation involves two steps. First, to find the optimal
solution for the time sub-division and later to find optimal solution in terms of
optimal switching time. Computing an optimal financial model with too many
time steps may be difficult in some cases due to computer memory and time
required to compute.
A computational approach, which can overcome the above computational
problems by suitable transformation of the original time is developed in this
chapter.
A simplified non-linear optimal control model which can address the above
optimal financing problems for corporations is described below, involving two
state variables and two control variables. Price 
and equity per share
are the state variables, and the earnings retention rate 
and stock financing
rate 
are the control variables. The objective of the utility is defined as the
discounted sum of dividends and capital gains, thus, the present value of share
ownership is to be maximized. Two differential equations describe the change
in stock price and equity per share.
The state, control variables , and parameters are expressed as follows:
State variables
= market price of a share of stock
= equity per share of outstanding common stock (net worth of utility
divided by the number of shares outstanding)
Control variables
= retention rate which describes the fraction of earnings retained for in-
creasing the capital assets
= stock financing rate concerning new money invested in the company
Parameters
= market capitalization rate (or investor discount rate)
= maximum investment rate
= rate of return to equity (maximum return allowed by government)

94
OPTIMAL CONTROL MODELS IN FINANCE
= discount on share price resulting from flotation cost
= a positive constant denoting the responsiveness of the price to changes in
earnings and dividends
T = planning horizon of the optimal financing program
The objective function of this model is to maximize the present value of the
owners’ shares. Expressed by an integral plus an end-point term:
subject to:
where, 
and the terminal condition is given by the fixed
planning horizon T.
Davis and Elzinga used the reverse-time construction technique which was
given in reference [35, 1965], which will be described below, to systematically
construct a complete solution from solution cases. The solution cases are clas-
sified according to the solution of a mathematical programming problem of
each instant at time arising from the Maximum Principle [69, 1962].
3.
Analytical Solution
Davis and Elzinga used the reverse-time construction technique that is par-
ticularly significant in solution synthesis. Starting from the terminal manifold
and moving backwards in time, the entire space of state is filled with optimal
trajectories solving the problem for arbitrary initial states. A linear program
solved by inspection originally determined the solution of this model. The
Maximum principle was successfully used and also modified to allow ease in
handling discounted objective functional. The existence of the optimal control
for this problem was established by corollary 2 of Theorem 4 in reference [50,
1967]:
Theorem 4. Consider the non-linear process in
The data are as follows:

An Optimal Corporate Financing Model
95
1. The initial and target sets 
and 
are non-empty compact sets
varying continuously in 
for all 
in the basic prescribed compact interval
2. The control restraint set 
is a non-empty compact set varying
continuously n 
for
3. The state constraints are (possibly vacuous)
a finite or infinite family of constraints, where 
are real continuous
functions on
4. The family 
of admissible controllers consists of all measurable func-
tions 
on various time intervals 
in 
such that each
has a response 
on 
steering 
to
and
5. The cost for each 
is:
where 
in 
and 
and 
are continuous in
Assume:
a.
b.
The family 
of admissible controllers is not empty.
There exists a uniform bound:
for all responses 
to controllers
c. The extend velocity set:
is convex in
for  each  fixed
Then there exists an optimal controller 
on 
in 
minimiz-
ing
Corollary 2. Consider the control process in
with cost:

96
OPTIMAL CONTROL MODELS IN FINANCE
where:
where the matrices A, B, 
are 
functions on 
and
are continuous in 
and 
is a convex function of 
for each fixed
Assume that the restraint set 
is compact and convex for all
Then hypothesis c. is valid. If we assume 1. to 4. and a. b., then the existence
of an optimal control 
on 
in 
is assured.
Due to the Maximum Principle , the necessary conditions for 
to be
optimal are:
where:
Here, 
The Hamiltonian can be modified by introducing new “steady
state” variables

An Optimal Corporate Financing Model
97
The adjoint variables are defined as follows:
with boundary conditions
Parameterizing terminal values of the state variables as 
and
The maximization of H with respect to 
can be characterized as follows:
(a)
(b)
(c)
(d)
(e)
(f)
(g)
The synthesis of the solution was done by a construction technique in the
reverse time sense. The complete solution is given as follows:
In the case (a)
A.
B.
C.
1.
2.
3.
The solution shows the classical bang-bang control. Although the singular
arc cases appear in the synthesis, none of them are optimal. The computational
methods established in Chapter 2 and Chapter 3 will be used to verify this
solution in Section 4.6.

98
OPTIMAL CONTROL MODELS IN FINANCE
4.
Penalty Terms
A substantial class of optimal control problems will deal with the terminal
constraint as well as other constraints that may describe physical limitations on
some process. For computational reasons, some penalty terms are required to
be used to replace these constraints in order to obtain an unconstrained prob-
lem. There are some approaches with good reputations. Since the financial
model discussed in this chapter has an end-point constraint on the market price
of a share of stock at the end of the time planning horizon, the penalty term is
used in the terminal constraint transformation. First an approach is introduced
to deal with a minimization problem subject to both inequality and equality
constraints:
Consider the objective function 
as a cost to be minimized; then additional
penalty costs are added to 
when 
does not satisfy the constraints. Define
vector 
if
if 
The problem (1) is replaced by the following uncon-
strained problem:
The terms in 
and 
consist of the penalty functions. They are zero when
satisfy all the constraints. 
is a positive parameter, that can more generally be
replaced by different parameters for each component of 
and
and are Lagrange multipliers. From the theory of augmented Lagrangian [14,
1995], this unconstrained problem with the penalty terms is minimized at the
same point as the given constrained problem [A], provided that the Lagrange
multipliers and 
are suitably chosen.
Before the penalty method of terminal constraints is stated, the Delta func-
tion should be introduced since it will be used to include the terminal con-
straints into the integral later. The Dirac delta function 
is described by:
Now consider an optimal control problem of the form:

An Optimal Corporate Financing Model
99
A terminal constraint 
can be replaced by a penalty term added to
where 
is a positive parameter, and 
approximates to 
thus
and where 
is the Lagrange multiplier.
Thus an “end-point term” in a control problem can be included in the inte-
grand as shown:
and so is not an additional case to be treated separately.
A constraint such as 
which involves controls at different
times, can be treated by adjoining an additional state component:
and imposing the state constraint
The latter can be handled by a
penalty term
where the parameter 
is small.
5.
Transformations for the Computer Software Package
for the Finance Model
In this section, in order to develop a computer software package of the opti-
mal control for this financial model, some transformations of the formulas are
introduced here to meet the requirement of the computation. Basically most
transformation techniques with the division of time scales used here were in-
troduced in Chapter 3. Only the different transformations for this particular
computer package are introduced here.
The differential equations in (4.2) and (4.3) are represented as follows:

100
OPTIMAL CONTROL MODELS IN FINANCE
The integral in (4.1) is transformed as:
where
Terminal state is treated separately for nqq package:
Since in this model, time horizon parameter T is assumed to be greater than
1, another transformation of changing time interval [0, T ] to [0,1] is required
for the program which only deals with the time period [0,1].
This transformation was indicated in section 2.3. Let a new time 
equal
here 
is the scaled time set for the computational methods.
Then the differential equations and integral of objective function become:
The integral in (4.1) is transformed as:
where

An Optimal Corporate Financing Model
101
The transformations here only deal with the time variable 
The end-point
term is considered separately in the program.
6.
Computational Algorithms for the Non-linear Optimal
Control Problem
From section 4.3, we know that at a particular case (a), the bang-bang con-
trol is the optimal solution of the system. 
lies on the
vertices of a triangular area:
However, a singular arc is possible, with 
lying on an edge of the trian-
gle (instead of a vertex), when the parameters 
etc.) of the functions take
particular values. Since Davis and Elzinga did not have a computer software
package for this optimal control problem, this research is focused on devel-
oping computer software based on the research work which has been done in
Chapter 2 and Chapter 3. In order to get accurate estimates of the switching
times, some computational methods have to divide [0, T] into many subinter-
vals. The time transformation introduced by Goh and Teo [33, 1987] makes
it possible to avoid this difficulty. The technique was also used to construct
the computational algorithms in this section. We establish the control policy
as bang-bang control here. The optimal switching times will be computed.
Several sequences of the control patterns will be experimented with different
initialization of the states. The results will be discussed and analyzed in next
section.
Computational method 4.1 Main Model Program (see model 1_1.m in Ap-
pendix A.3)
Step1. Initialization. First set the a vector of parameters =
which includes all the parameters in this financial model. 
= is market
capitalization rate, 
= maximum investment rate, 
= rate of return to
equity, 
= discount on share price resulting from flotation costs, 
= a
positive constant denoting the responsiveness of the price to changes in
earnings and dividends, T = planning horizon of the capital budgeting
program. Then set parameter par = [the number of the state components,
number of control components, nb = the number of big subintervals, ns
= the number of small subintervals, parameters]; and get the total num-
ber of the subintervals by calculating
Set the MATLAB

102
OPTIMAL CONTROL MODELS IN FINANCE
“constr” function parameters par (13) = 1 (one equation, constraint in
the minimization problem) , par(14) = the maximum number of function
evaluations, and arbitrary starting lengths of the switching time intervals
Set the vectors of upper bounds uu and
the vector of lower bounds ul of urn, thus 
Also set the
initial state xinit;
Step2. Call the MATLAB “constr” function. In turn, “constr” calls the “Model2”
to calculate the minimization of the calling program with respect to the op-
timal vector um;
Step3. Input the optimal result um to “Model2”, to obtain the values of the
objective function J(nn) (the last value of the integral) and state vector
xm (xm is a vector of all the values of the state functions take at the grid-
points of the switching time intervals). The result of the objective with
respect to optimal switching times is the solution of this financial system
model.
Computational method 4.2: Model 2 (see model1_2.m in Appendix A.3)
Step1. Initialization. Input um, par and initial state xinit. Set the initial state
xm(1, :) = xinit, and nx = par(1), the number of the state components,
nu = par(2), the number of the control components (in this case, nx and
nu both equal 2, there are two states and two controls,) nb = par(3), the
number of big time intervals, ns = par (4), the number of small time inter-
vals, nn = par(3) *par(4), the number of total time intervals, initial scaled
time 
subinterval counter it = 1, hs = length of the whole subinter-
vals. Choose the “Model3” as the right side of the differential equations
(4.2) and (4.3), input um;
Step2. Construct the vector sm whose components represent the lengths of
the total time intervals by dividing each big time interval um by ns;
Step3. Call the SCOM package function “nqq” with the stated “Model3” to
solve dynamic equations (4.2) and (4.3). Tabulate the solution for the state
as the vector 
the result of (4.2),
the result of (4.3);
Step4. Set the initial scaled time
subinterval counter it = 1, initial state
zz(: 1) = 0, ma = 1, the number of the input state function. Choose the
“Model3” for SCOM function “nqq”. Input the vector xm(: 1) and um;
Step5. Call SCOM function “nqq” with the stated “Model4” to solve the dif-
ferential equation 
Tabulate the results in 
as the
components of the vector

An Optimal Corporate Financing Model
103
Step6. Obtain the last value xm(nn, 1) of the state vector for the “end-point
condition”;
Step7. Call the “End-point condition” to calculate the terminal state;
Step8. Add the result gained from “End-point” condition to the last value of
the vector jm as the result of the objective function 
in (4.1), and calcu-
late the constraint function of ’model2” which is
Computational method 4.3: Model 3 (see model1_3.m in Appendix A.3)
Step1. Initialization. Input scaled time 
subinterval counter it, the length of
total subintervals hs, vector um and vector par. Set the value of parameters
T. Set the number of the total subintervals nn = 1/hs;
Step2. Obtain the number of the big time intervals by nb = nn/ns for con-
structing the optimal control policy;
Step3. Set the control policy as vector 
which jumps between the
vertices of the triangle area (4.18)-(4.19). The control only jumps at the
end points of the big time intervals;
Step4. Construct the right side of the transformation equation for time pt in
(3.10);
Step5. Obtain the right side of the differential equations by using the transfor-
mations in (4.15), (4.16).
Computational method 4.4: Model 4 (see model1_4.m in Appendix A.3)
Step1. Initialization. Input scaled time 
subinterval counter it, the length
of subintervals hs, vector xm of values of first state function at switching
times, and also the initial state 
and vector sm. Set total subintervals
nn = 1/hs;
Step2. Use linear interpolation to get the estimate “xmt” of the state, in a time
between grid points 0h, h, 2h,..., h * nn, where h = 1/nn;
Step3. Add up the time intervals sm to get time 
in (3.9);
Step4. Construct the right side of the equation (3.9) to obtain time variable
Step5. Calculate the integrand in (4.17) at the scaled time 
and change the
sign of the integral. (This problem is seeking for a maximum. Since the
computer package only deals with minimization calculation, an opposite
sign of the objective function needs to be changed.)

104
OPTIMAL CONTROL MODELS IN FINANCE
Computational method 4.5 End-point condition (see model1_5.m in Ap-
pendix A.3)
Step1. Initialization. Input the last value of the first state function in vector xm
and the parameters par which are required by the “End-point condition”;
Step2. Construct the terminal term in (4.14).
7. 
Computing Results and Conclusion
In this section, the algorithms 4.1-4.5 are used in a computer software pack-
age (see in Appendix A.3) which was developed for this financial decision-
making model (4.1)-(4.5). Before we present the computing results, the ana-
lytical solution in the Davis and Elzinga [22, 1970] finance model is described
first for the future comparisons. Figure 6 in Davis and Elzinga [22, 1970]
shows the optimum solution graphically, which means:
Solution case [1]: when
the optimal solution has control
in case [C] all the time;
Solution case [2]: when
the optimal solution has control
switching from case [B] to [A] at a switching time.
The control regions [A], [B], [C] are described in Section 4.3.
First, set the parameters:
which meets the restriction on
in case (a) in Section 4.3.
Initialize the states:

An Optimal Corporate Financing Model
105
Map the control
in this order:
[B]
[C]
[A]
in successive time intervals. [B], [C], [A] for nb = 3, or [B], [C], [A], [B],
[C], [A] for nb = 6.
Then run the programs for the algorithms 4.1 -4.5 (details see “model1_1.m”,
“model1_2.m”, “model1_3.m”, “model1_4.m”, “model1_5.m” in Appendix A.3).
All the cases are put into Table 4.1.
Here, “most [C]” indicates that most of the time is spent in [C].
From the results in Table 4.1:
Then according the analytical solution in Davis’ work, the optimal solution
is supposed to be in solution case [1], which is control [C]. The computing
results in Table 4.1 almost agree with the analytical solution. Since 1.49 is very
close to 1.47, the case [A] will mix with case [C] at some point. This computed
case is close to the theoretical optimum, but it does not exactly agree with it.
Another solution case is verified next.
Initialize the states:

106
OPTIMAL CONTROL MODELS IN FINANCE
Map the optimal control
in this order:
[C]
[B]
[A]
in successive time intervals. [C], [B], [A] for nb = 3, or [C], [B], [A], [C],
[B], [A] for nb = 6.
Then run the programs. The results are shown in Table 4.2.
From the result in Table 4.2:
The computing results agree with the analytical solution in solution case [2],
which is control case [B] switching to [A] at a certain switching time. In this
example, the computed results agree well with the theory. Another example
with the same initialization but a different given order of control mapping is
given in Table 4.3; the results agree with Table 4.2.
The optimal control 
are in order:
[B]
[C]
[A]

An Optimal Corporate Financing Model
107
An approximate calculation using the SCOM package, dividing [0,1] into
20 equal subintervals, also confirms the switching patterns for solution case
[2]. The following computation has the same initialization of the parameters
as the above computation. The initial states also take: P(0) = 0.5, E(0) = 1.
The solution of the computation is shown as follows.
The optimal control takes values:
The states are:
P(T) = 1.99
E(T) = 1.96
The objective function is:
the optimal solution
is expected to be in solution case [2] in the analytical solution. The results of
this computation are very close to Table 4.2 and Table 4.3 and also confirm the
analytical solution in Davis and Elzing’s finance model. The optimal control
jumps from [B] to [C] at
The computation in this chapter agrees with the analytical solution in Davis
and Elzinga [22, 1970]. The results might change if the parameters have been
changed. The parameters set in this research are chosen to meet the restriction
on 
in case (a) (section 4.3). Further research on different parameters and
more subdivisions of the time interval will be very interesting.
8.
Optimal Financing Implications
The results of this computation in Tables 4.2 and 4.3 are very close to the
analytical results in Section 3 and also confirm the analytical solution in Davis
and Elzinga [22, 1970]. The model results provide the dynamic structure of
capital of a firm and the optimal switching time from moving from one source
of finance to another. There is one switch in the firm’s financing strategy over
the planning period. The levels of the two sources of fund depend on the
relationships between the rate of return on equity capital 
and the investor’s
discount rate 
and the relationship between the equity per share (E) and
the market price of stock(P), thus the optimal control jumps from [B] to [C] at
Since the computational results of the optimal financing model are consis-
tent with the analytical results derived in Section 3 and the results of Davis and

108
OPTIMAL CONTROL MODELS IN FINANCE
Elzinga, they can be applied to understand optimal financing strategies of cor-
porations to determine the optimal mix of structure of long-term funds to use in
actual management of the capital structure of companies. Although theoretical
controversies continue, model results suggest that the optimal structure which
minimizes the firms’ composite cost of capital changes over time. The model
results provide the timing of switching from one fund to another fund. In real
life, these switches depend on the cost of these funds, the rate of return, share
prices, debt capacity, business cycles, business risks, etc. Various results are
generated by different sets of parameter values of the model. Sometimes sub-
jective judgments need to be made to choose the appropriate optimal capital
mix path of the firm.
9.
Conclusion
The determination of the optimal structure of corporate capital and the switch-
ing times for different methods of financing are essential for the actual manage-
ment of capital structure of corporations. The computation of optimal switch-
ing time in this paper agrees with the analytical solution in Davis and Elzinga
[22, 1970]. The results might change if the parameters are changed. The pa-
rameters set in this research is chosen to meet the restriction on 
in case (a)
(Section 4.3). Further research on different parameters and more subdivisions
of the time interval will be very interesting. Development of an algorithm to
coincide the time subdivisions with switching times are also another important
area of further research.

Chapter 5
FURTHER COMPUTATIONAL EXPERIMENTS AND
RESULTS
1.
Introduction
This chapter will give some experiments that have been done for examin-
ing the computational algorithms developed in Chapter 2 and Chapter 3 for
computing dynamic optimization financial models. The computation tests for
the algorithms in Chapter 2 are presented in Section 5.2. Three computing
examples are included. The problems met during computation are discussed
and the solutions for those problems are indicated. Section 5.3 contains a dif-
ferent control policy with one possible pattern of the financial optimal control
problem (3.2)-(3.6). The computing results of this new control policy are also
included. The objectives of the modeling experiments are to provide examples
of additional modeling structures which can be adopted in financial modeling
including some new forms of the objective functions and control patterns, and
to test the computational algorithms and the computer program by applying
them to some further models.
2.
Different Fitting Functions
In this section, three different given fitting functions of OCPWCS (Optimal
Control Problems When Control are Step functions) are indicated. The diffi-
culty and non-accuracy in the computation of financial models are analyzed
and the possible solutions of those problems are given.
2.1
Calculation with square criterion in the objective
function
Consider a financial optimal control model as follows:

110
OPTIMAL CONTROL MODELS IN FINANCE
subject to:
The target function is: 1/2*t.
Now apply the algorithms 2.1 - 2.4 to solve this problem. Note the objective
function is no longer an absolute value. The algorithm 2.4 needs to be modified
to meet the square value. The time division technique will be used here. The
following graphs and tables are the computing results of this control problem.
In the figures, “*-” represents the state function 
and “.” represents the
given fitting function
This model is the same investment planning model as in Section 2.7. How-
ever this model has a different fitting functions and the objective function is
in a squared form which is a preferred form of decision criteria in economies
(Islam [36, 2001]).
Figure 5.1 is the result of 
(numbers of the time intervals).
Figure 5.1.
Plot of n=4, forcing function ut=1,0,1,0

Further Computational Experiments and Results
111
The outputs of this computation are shown as follows:
The real optimal switching times are:
Time period [0,1] is divided into four subintervals:
The control is mapped as:
As results, the state variables of the financial system takes values as:
The minimization of the objective function at
is:
Figure 5.2 is the graph result of

112
OPTIMAL CONTROL MODELS IN FINANCE
Figure 5.2. 
Plot of n=10, forcing function ut=1,0,1,0,1,0,1,0,1,0
The outputs of
are:
The real optimal switching times are:
Time period [0,1] is divided into 10 subintervals:
The control is mapped into:
As results, the state takes values as:

Further Computational Experiments and Results
113
The minimization of the objective function at 
is:
When the jump of the control increases, a better approximation between state
and given fitting function is obtained.
In this experiment, several other computations have also been done in the
case of 
and, 8. The results of the objective function of all these cases
are shown in Figure 5.3 and in Table 5.1. The value of the objective function
decreases when 
increases. It is confirmed that the value of the objective
function tends to zero when the control jumps infinitely often.
Figure 5.3. Results of objective function at n=2,4,6,8,10
The above results imply that for the development of a stable investment plan
aimed at certain target value for the stock price, flexibility in switching among
investment strategies is essential.

114
OPTIMAL CONTROL MODELS IN FINANCE
2.2
Calculation with absolute value criterion in the
objective function
In this section, a similar financial model similar experiments as in Section
5.2.1 are introduced. The difference is that the objective function in this section
is the absolute value of the state approximating the given fitting function.
The financial optimal control problem is shown as follows:
subject to:
The definition of the variables and parameters are same as in Section 3.2.
However the present model has a different forcing function.
This is an optimal financing model for a firm where the decision problem
involves whether to buy back (–1) or issue (1) some stocks or to maintain the
present situation (0) of the amount of stocks used in the market so that the
firm’s stock price remains stable.
Apply the algorithms 2.1-2.4 on the problem (5.5)-(5.9). Only one modifi-
cation is made in algorithm 2.4 for this given fitting function 
There are

Further Computational Experiments and Results
115
two graphs shown as follows which represent 
and 
respectively.
As in the last section, the lines represent “state function” by “*-”, and “given
fitting function” by “.”.
The results gained from 
are shown as follows:
The real optimal switching times are:
Time period [0,1] is divided into four subintervals:
The control is mapped into:
As results, the state variable of the financial system variable of the financial
system takes values as:
The minimization of the objective function at 
is:
Figure 5.4 also shows the approximation between the state function 
and
given fitting function 
Three jumps of the optimal control are shown.

116
OPTIMAL CONTROL MODELS IN FINANCE
Figure 5.4. 
Plot of n=4, forcing function ut=1,0,1,0
An interesting situation was met during the computation at the case
Clearly the wrong result was gained in which the control only jumped once at
and the minimum of the objective function was 
greater
than the value of the minimum at the case 
It is possible that the com-
putation was finding some local minimum, instead of the global minimum.
A check for this mistake was also made. It was found that error was in the
initialization of the lengths of time intervals um0. Originally um0 was set as
[1/2,1/2,1/2,1/2,1/2,1/2,1/2]. Since the constraint on time is
then the original set of um0 did not meet this restriction. It also misled the
computation to a local minimum. The correct initialization of um is very crit-
ical for the whole computation. The mistake also occurred in the computation
of the case 
in Section 5.2.3. Now set um0 as 
Accurate results of
the problem are shown as follows.
The real optimal switching times are:
Time period [0,1] is divided into four subintervals:

Further Computational Experiments and Results
117
The control is mapped into:
The state takes values as:
The minimization of the objective function at 
is:
Figure 5.5. 
Plot of n=8, forcing function ut=1,0,1,0,1,0,1,0
Figure 5.5 also shows a better approximation than

118
OPTIMAL CONTROL MODELS IN FINANCE
The results of other cases at 
are shown in Table 5.2. The value
of the objective function decreases when 
(the number of the time intervals)
increases.
2.3
Problem of the fitting function with big slope
In this section, a special case is introduced where the fitting function’s slope
is greater than 1 at time 
Since the given fitting function is approximated
by a piecewise-linear function with slope 1 and 0, the fitted function does not
need any part of slope 0 near 
In this case, the give fitting function
has a slope 1.6 at 
thus a slope 1 cannot give a good fit any more. A
similar problem happened in Section 5.2.2 where the computation reached a
local minimum also occurred at case
Consider the following optimal control model of finance:
subject to:
After running the program of the algorithms 2.1-2.4, two mistakes were
found. First, the control stopped jumping at case 
Second, the approxi-
mation did not work well at the slope close to 1.

Further Computational Experiments and Results
119
The first problem was met while computing the optimal control problem
(5.5)-(5.9). A different start of um can fix this problem. Here, we introduce
several other methods to exam which one works well in the computation. First
(method 1), simply divide each optimal um at case 
by 2 as the initial
start of um for case 
The idea behind this method is that if the com-
putation starts from a good minimum at the smaller jumps of control, it will
also lead to a good minimum at the greater jumps of control. Second (method
2), since the non-accurate results always gave zero of um, which means no
switching times, the lower bound of the um can be modified from the original
zero to a very small number to avoid the situation of um = 0. Thus, the control
jumps. It does not guarantee the computation will reach optimum. Sometimes
these two methods can be combined together. Method 3, is the method used in
Section 5.2.2 for solving a similar problem.
Using a control that can provide a bigger slope for the fitting function can
solve the second problem mentioned earlier about the slope of the given fitting
function. Method 4 lets control take a larger value to fit a function whose slope
is great.
Figure 5.6 is the result of method 3. “*-” represents state function, “.” rep-
resents the fitting function
Figure 5.6. 
Plot of n=8, forcing function ut= 1,0,1,0,1,0,1,0

120
OPTIMAL CONTROL MODELS IN FINANCE
The tests of all these methods are put in Table 5.3.
J is the value of the objective function. These five cases represent four
methods described earlier. Case 1 is for method 1, Case 2 is for method 2,
Case 3 is for the combination of method 2 and method 3, Case 4 is for method
3, and Case 5 is for method 4. Method 1 and method 3 both obtain similar re-
sults. This proves that the right initialization of um0 will help the computation
searching the optimum. Method 2 did not give promising results in the test. It
can be explained that certain time intervals are not optimal, so if the control
is forced to jump in that period, the optimum will be skipped. Method 5 does
solve the problem with a big slope of the fitting function.
2.4
Conclusion
The three experiments that have been done in Section 5.2.1, 5.2.2, 5.2.3
are very important for the computer package which was developed for solv-
ing a certain class of optimal control problems. They make the program more
general, the results more accurate, and computation more stable. The optimal
control problems when controls are step functions can be solved using this
computer package. Only very small modifications are needed. The accuracy
gained from these computational algorithms is also very useful for the algo-
rithms 3.1-3.4 for oscillator problems.
3.
The Financial Oscillator Model when the Control Takes
Three Values
In this section, an experiment when the control takes three values is intro-
duced to test the algorithms 3.1-3.4 in Chapter 3. The results of the problem
are also analyzed.

Further Computational Experiments and Results
121
3.1
The control takes three values in an oscillator problem
Consider the financial oscillator model as follows:
subject to:
Apply the Algorithms 3.1-3.4 to this problem. There are two changes that
need to be made in Algorithm 3.3 and Algorithm 3.4. One is re-mapping the
control from original two-value pattern to three-value pattern. Here, the con-
trol is mapped to –1,0,1 in the successive time intervals. Note the smallest
number of the subdivisions must be 3 because of the control values. Another
change is in Algorithm 3.4 for the new fitting function
Several cases are tried and the results are shown in Table 5.4. The time
horizon [0,1] is first divided by 3,6,9, thus becomes 3,6,9 time intervals.
Each time interval is further subdivided by 2,3,4,6,8 to gain the better results
of the integral in the objective function.
From the results in Table 5.4, a conclusion can be made that the subdivision
of the time intervals is necessary especially when the nb (the number of the

122
OPTIMAL CONTROL MODELS IN FINANCE
time intervals) is big. Note that in case nb = 9, ns = 1, the result of the
objective function is 1.5791, nearly double of the result of nb = 6, ns = 1.
This solution cannot be optimal. The results of states and optimal switching
times in this case are shown as follows.
The real optimal switching times are:
The states take values:
The value of the objective function is:
In this case, the control only jumps twice and then does not change. From
the computation, we notice that a local minimum is reached instead of a global
minimum. The increased number of subdivision of the subintervals will give
more time for the system to reach the global minimum.
The chosen number for the subdivisions in the computation should be con-
sidered carefully. Since the control takes three values in this problem, the num-
ber of the big time intervals must be a multiplier of 3. Theoretically whether
the number of small time intervals is a multiple of 3 does not matter for the
computation. However, from the experimental results, we know that when the
number of the subdivisions are the multiplier of 3, the computation gives a
better approximation.
Figure 5.7 and Figure 5.8 are the graphical results in the case nb = 9 and
ns = 8. In that case, the computation gives accurate results. Figure 5.7 shows
the state function 
and the fitting function 
“o-” represents
state function 
“+:” represents the given fitting function

Further Computational Experiments and Results
123
Figure 5.7. Plot of nb=9, ns=8, forcing function ut=-2,0,2,-2,0,2,-2,0,2
Figure 5.8 shows the relationship between two state functions during the
time period [0,1]. Since in this case, the state takes 72 values, we only give the
graphical results here.
Figure 5.8. Relationship between two state functions during the time period 1,0

124
OPTIMAL CONTROL MODELS IN FINANCE
Graphic results of this oscillator problem are shown below. There are three
sets of them representing the solutions at nb = 3,6,9.

Further Computational Experiments and Results
125

126
OPTIMAL CONTROL MODELS IN FINANCE

Further Computational Experiments and Results
127

128
OPTIMAL CONTROL MODELS IN FINANCE
Set 1 for

Further Computational Experiments and Results
129

130
OPTIMAL CONTROL MODELS IN FINANCE

Further Computational Experiments and Results
131

132
OPTIMAL CONTROL MODELS IN FINANCE

Further Computational Experiments and Results
133
Set 2 for

134
OPTIMAL CONTROL MODELS IN FINANCE

Further Computational Experiments and Results
135

136
OPTIMAL CONTROL MODELS IN FINANCE

Further Computational Experiments and Results
137

138
OPTIMAL CONTROL MODELS IN FINANCE
Set 3 for

Further Computational Experiments and Results
139
4.
Conclusion
There are some financial optimal control models where the given fitting
functions are cos or sin functions; then the financial control needs to take three
values with the middle being zero, to ensure a good approximation. The exper-
iment in Section 5.3.1 verifies the accuracy of the algorithms 3.1-3.4, thus the
computer software package CSTVA (for details see Appendix A.4) based on
these algorithms can solve all these kinds of control problems. The computed
results provide insights into the dynamics of the financial system in terms of
the state and control variables.

This page intentionally left blank

Chapter 6
CONCLUSION
Modeling and computation of dynamic optimization problems in finance is
an important area for research in financial modeling. The thrust of this research
has been to develop computational methods in order to solve financial optimal
control models which are difficult to solve by traditional analysis using optimal
control theories. Four computer software packages called CSTVA have been
constructed, each of them used for different optimal control problems in two
areas of finance: optimal investment planning and optimal corporate financing.
The STV approach consists of the following six major computational meth-
ods:
1
2
3
4
5
An optimization program based on the sequential quadratic programming
(SQP)
The switching time variable method, the switching time is made a control
variable.
The finite difference method for estimating gradients when gradients are
not provided.
The step function approach to approximate the control variable.
A piecewise-linear (or non linear) transformation of time (as in MATLAB’s
“constr” program similar to the Newton Method for constrained optimiza-
tion).
6 Second order differential equations represent the oscillatory dynamic finan-
cial models.

142
OPTIMAL CONTROL MODELS IN FINANCE
Financial optimal control modeling with a cost of changing control is the
main topic in this book. Normally a cost is attached to a number of switch-
ing times then added to the objective function. The cost function becomes
a new objective function to be treated. The chosen cost for such an optimal
control problem for optimal investment planning in the stock market has been
discussed in Chapter 2. The control in the problem is approximated by a step-
function. The softwares constructed in this thesis compute the optimal switch-
ing times. Basically, the time period of the problem is divided into a certain
number of subintervals to solve the differential equation and calculate the ob-
jective function as an integral. For the problem in Chapter 2, a greater number
N of subdivisions will lead to a better fit to the target function 
When a
cost is attached to the switching times, the integral decreases as N increases,
but the cost of switching increases with N. Hence the total cost function
reaches an optimum. There are some techniques required for this research,
such as the approximation of the control, the time scaled transformation for
using the SCOM package “nqq” function, the piece-wise linear transformation
for the calculation of the differential equation and integrals, non-linear trans-
formation for the large time period, and penalty term transformations for the
constraints of the problems. The computed results are also compared with the
theoretical results. A certain class of optimal control problems can be put into
the formula introduced in this research. The computer software packages de-
veloped in this research can then solve these problems with very little or no
change.
Financing oscillator problems can form another class of financial optimal
control models. These kinds of problems have a great number of applications
in the real world. In these problems, the dynamic system can be described by
a second-order differential equation. It is required to convert the second-order
differential equation to two equivalent pair of first-order differential equations,
to enable the software to be used. In order to get more accuracy in solving the
differential equation, a further subdivision of the time intervals is introduced.
While the control takes several discrete values, the sequences of these values
may follow more than one pattern, leading to a different computed minimum.
The computational algorithms are designed to handle these problems. The
obtained computing results give good comparisons of them.
The modeling exercises in this book show the potential for modeling dy-
namic financial systems by adopting bang-bang optimal control methods. The
results of this modeling can provide improved understanding about the behav-
ior of and the decision problems in dynamic financial systems. The roles of
switching times in financial strategies and transaction costs of controls are use-
ful for financial planning as well.
The algorithms constructed in this thesis are applied to an optimal corporate
financing model, which has two state functions and two control functions. The

Conclusion
143
computation experiments with two patterns of controls were tried. Effective
results were obtained which also agree with the analytical solution from the
original work. Another computation with the SCOM package also agreed with
the computational solution in this research and the analytical solution. Further
research of trying different parameters sets will be an interesting exercise. The
accuracy of the computational algorithms in Chapter 3 and Chapter 4 were ver-
ified by these experiments. The STV approach may be considered satisfactory
in view of its computational efficiency and time, and the plausibility of results.
In the damped oscillatory financial model, many corporate finance mod-
els are concerned with the application of optimal control. Computational ap-
proaches to the determination of the optimal financing problems were applied
in a financial model which was first introduced by Davis and Elzinga [22,
1970]. The model discusses investment allocation in order to determine the
optimal proportion of the sources of finance which can maximize the value of
the company. In particular, this model determines the proportion of its earnings
that should be retained for internal investment and what proportion should be
distributed to shareholders as dividends. The model also aims to choose the
“smart” investment program that gives the owners the most benefits.
In most of the existing optimal corporate financial structure models, the op-
timal proportion of various sources of funds is determined. In a linear dynamic
finance model, this proportion may change depending on the bang-bang char-
acter of the time path in the model. For an improved understanding of the
behavior of the dynamic path of such models, it is essential to know the op-
timal switching times for changing the optimal proportion of different funds.
No algorithm exists in the literature which can determine the optimal switch-
ing time for corporate funds. The present book has developed such a model for
optimal corporate financing and switching timing.
In this research, the computational algorithms have been improved for solv-
ing bang-bang optimal control problems. Applications of the STV algorithm
to finance have been made to show the potential and methods for developing
dynamic optimization methods in finance. Further research is necessary to im-
prove the state of the art in computing bang-bang optimal control in general
and financial optimal control models in particular.

This page intentionally left blank

Appendix A
CSTVA Program List
1.
Program A: Investment Model in Chapter 2
Project1.m
function J=project1(C,nn)
J=project1_1(nn)+C*nn
Project1_1.m
% Program for the project 1 in chapter2
function project1_1=project1_1(nn)
figure;
par=[1,1,nn];
% parameters: 1 state, 1 control, nn subintervals.
options(14)=2000;
% maximum number of function evaluations.
options(13)=1;
% one equality constraint
xinit=0.0;
% initialize the state function xt
um0=ones(nn,1)/nn;
% take a initial guess of starting time intervals
s=[0:0.05:1];
plot(s,1/2*s,‘:’)
ul=zeros(nn,1);
% lower bound of um, t(nn)-t(nn-1) >= 0
uu=ones(nn,1);

146
OPTIMAL CONTROL MODELS IN FINANCE
% upper bound of um, t(nn)—t(nn-1) <= 1
um=constr(‘project1_2’,um0,options,ul.uu,[],xinit,par)
% use the MATLAB “constr” to get the optimal time intervals
[f,g,xm]=project1_2(um,xinit,par)
v(1)=um(1);
for ii=2:nn
v(ii)=um(ii)+v(ii-1);
end
% obtain the real switching time t
v(nn)=0.9999999999999;
v=[0 v];
hold on
plot(v,xm,‘rx-’)
% plot the state function to switch time t
xlabel(‘Time T’)
ylabel(‘State function xm and given fit function 1/2*t’)
Project1_2.m
%. Function of calculating differential equations and intervals
function [f,g,xm]=project1_2(um,xinit,par)
nx=par(1);
nu=par(2);
nn=par(3);
ps=1;
xm=zeros(nn+1,nx);
xm(1,:)=xinit;
lm=zeros(nn+1,nx);
% co-state function, polygonal function. In this case no
co-state function
ma=nx;
% Component of the state functions.
t=0;
% scale time t
it=1;
% counter it
hs=1/nn;
px=‘project1_3’;
% form of the right side of the transformation of the
differential equation
xm=nqq(px,nx,nu,nn,xm,ma,t,it,hs,um,xm,lm,ps);

APPENDIX A: CSTVA Program List
147
% use SCOM package “nqq” to do the integral calculation
zz=zeros(nn+1,nx);
% here is the first xm in the calling function
zz(1,:)=0;
ma=1;
% set the number of the integral
t=0;
it=1;
hs=1/nn;
px=‘project1_4_1’;
% form of the right side of the linear transformation of the
integral
jm=nqq(px,nx,nu,nn,zz,ma,t,it,hs,um,xm,lm,ps)
f=jm(nn+1);
% the result of the integral
g(1)=sum(um)-1;
% calculate the constraint
Project1_3.m
% Form of the right side of linear transformation of the
differential equation
function ff = project1_3(t,it,z,yin,hs,um,xm,lm,ps)
nn=1/hs;
rr=nn/2;
for i=1:rr,
u(2*i-1)=1;
u(2*i)=0;
end
% map the control pattern ut=0,1,. . . in successive time
intervals
pt=nn*um(floor(it),1);
ff=(u(1,floor(it)))*pt;
% Piecewise-linear transformation d/d(xt) = (1/h)*(t(j+1)-t(j))*u(j)
Project1_4_1.m
% Form of the right side of the integral
function ff = project1_4_1 (t,it,z,yin,hs,um,xm,lm,ps)
nn=1/hs;
fr=nn*mod(t,hs);
% Linear interpolation

148
OPTIMAL CONTROL MODELS IN FINANCE
umx=zeros(nn,1);
umx(2) = um(1);
for ii=3:nn
umx(ii)=umx(ii-1) + um(ii-1);
end
xmt=(1-fr)*xm(it)+fr*xm(it+1);
% End-points of the time intervals
qt=nn*um(floor(it),1)*(t-hs*(it-1))+umx(floor(it),1);% time t
ll=abs (xmt-(1/2)*qt);
ff=nn*ll*um(floor(it),1); %|x(t)-1/2*t|
Project1_4_2.m
% A different case with the target function is (x(t)-1/2*t)^2
function ff = project1_4_2(t,it,z,yin,hs,um,xm,lm,ps)
nn=1/hs;
fr=nn*mod(t,hs);
umx=zeros(nn,1);
umx(2) = um(1);
for ii=3:nn
umx(ii)=umx(ii-1) + um(ii-1);
end
xmt=(1-fr)*xm(it)+fr*xm(it+1);
qt=nn*um(floor(it)
,1)*(t-hs*(it-1))+umx(floor(it),1);%
time t
ll=(xmt-(1/2)*qt)^2;
ff=nn*ll*um(floor(it),1); %(x(t)-1/2*t)^2
Project1_4_3.m
% A different case with target is |x(t)-0.4*(t^2)|
function ff = project1_4_3(t,it,z,yin,hs,um,xm,lm,ps)
nn=1/hs;
fr=nn*mod(t,hs);
umx=zeros(nn,1);
umx(2) = um(1);
for ii=3:nn
umx(ii)=umx(ii-1) + um(ii-1);
end
xmt=(1-fr)*xm(it)+fr*xm(it+1);
qt=nn*um(floor(it),1)*(t-hs*(it-1))+umx(floor(it),1);
ll=abs(xmt-0.4*(qt^2));
ff=nn*ll*um(floor(it),1); % |x(t)-0.4*(t^2)|
project1_4_4.m
% a different case with target is |x(t)-0.8*(t^2)|

APPENDIX A: CSTVA Program List
149
function ff = project1_4_4(t,it,z,yin,hs,um,xm,lm,ps)
nn=1/hs;
fr=nn*mod(t,hs);
umx=zeros (nn, 1);
umx(2) = um(1);
for ii=3:nn
umx(ii)=umx(ii-1) + um(ii-1);
end
xmt=(1-fr)*xm(it)+fr*xm(it+1);
qt=nn*um(floor(it),1)*(t-hs*(it-1))+umx(floor(it),1);
ll=abs (xmt-0.8*(qt^2));
ff=nn*ll*um(floor(it),1); % |x(t)-0.8*(t^2)|
2.
Program B: Financial Oscillator Model in Chapter 3
Project2_1.m
%Program for project2, oscillator problem in chapter 3
function project2_1=project2_1(nb,ns) % nb is big interval of time
t and ns is small interval
par = [2,1,nb,ns];
xinit= [3,5];
%xinit= [6,5];
%par=[1,1,nb,ns];
%xinit=0.0;
nb=par(3); % big intervals
ns=par(4); % small intervals
nn=nb*ns; %total intervals
options(13)=1;
options(14)=10000;
um0=ones(nb,1)/nb;
%um0=[ 0.00168225289917
0.12189477200848
0.64070279483764
0.23572018024164];
%um0=[0.39023521914983 0.39023521914983 0.10976478085245
0.10976478085245];
%um0=[00.1390,0.5714,0.2896]’;
ul=zeros(nb,1);
uu=ones(nb,1);
um=constr(‘project2_2’,um0,options,ul.uu,[],xinit,par)
[f,g,xm] = project2_2(um,xinit,par)
sm=zeros(nn,1);
v=zeros(nn,1);
for ii =1: nb
for jj= 1:ns
sm((ii-1)*ns+jj)=um(ii)/ns;
end
end
v(1)=sm(1);

150
OPTIMAL CONTROL MODELS IN FINANCE
for ii=2:nn
v(ii)=sm(ii)+v(ii-1);
end
v(nn)=0.9999999999999;
s=zeros(nn+1,1);
s(1)=0;
for ii = 2: nn+1
s(ii)=v(ii-1);
end
s
figure;
plot(s,xm(:,1),‘ob-’)
hold on;
t=[0:1/8 :1];
plot(t,-5*t+5, ‘+r:’)
%plot(t,0.4*t.^2,‘+r-’)
%plot(t,t,‘+r’)
xlabeL(‘Time T’)
ylabel(‘State function xm and given fit function -5*t+t’)
figure;
plot(xm(:,1),xm(:,2),‘*b-’)
xlabel(‘state function xm1’)
ylabel(‘state function xm2’)
%title(‘plot of switching time equal two’)
%Project2_2.m integral
function [f,g,xm] = project2_2(um, xinit, par)
nx=par(1);
nu=par(2);
nb=par(3);
ns=par(4); % ns is small interval
nn=par(3)*par(4) ; % nn is total interval
sm=zeros(nn,1);
for ii =1: nb
for jj= 1:ns
sm((ii-1)*ns+jj)=um(ii)/ns;
end
end
xm=zeros(nn+1,nx);
xm(1,:)=xinit;
lm=zeros(nn+1,nx);
ma=nx;
t=0;
it=1;
hs=1/nn;
px=‘project2_3’;
xm=nqq(px,nx,nu,nn,xm,ma,t,it,hs,sm,xm,lm,ns);
zz=zeros(nn+1,nx);
zz(1,:) = 0;

APPENDIX A: CSTVA Program List
151
ma=1;
t=0;
it=1;
hs=1/nn;
px=’project2_4’;
x=xm(:,1);
jm=nqq(px,nx,nu,nn,zz,ma,t,it,hs,sm,x,lm,ns);
f=jm(nn+1);
g(1)=sum(sm)-1;
%Project2_3.m compute differential equation
function ff = project2_3(t,it,z,yin,hs,sm,xm,lm,ns)
nn=1/hs;
T=5;
B=0.0;
B=0.1;
B=0.2;
nb=nn/ns;
rr=nn/(2*ns);
%for i=1:rr,
% 
ut(2*i-1)=2;
% 
ut(2*i)=-2;
%end
for i=1:rr,
ut(2*i-1)=2;
ut(2*i)=-2;
end
ts=zeros(nn,1);
if ns > 1
for ii= 1:nb
for jj=1:ns
ts(ii)=ts(ii)+sm((ii-1)*ns+jj);
end
end
else
for ii= 1: nb
ts(ii)=sm(ii);
end
end
pt=nb*ts((floor((it-1)/ns)+1),1);
%ff(1) = T*z(2)*nn*sm(1,floor(it));
%ff(2) = (-T*z(1)+T*ut(1,floor((it-1)/ns)+1)-T^2*B*z(2))
*nn*sm(1,floor(it));
ff(1)= T * z(2)*pt;
ff(2)= (-T * z(1) + T *ut(1,(floor((it-1)/ns)+1)) -
T^2 * B *z(2))*pt;
%ff=ut(1,(floor((it-1)/ns) + 1))*nn*sm(1,floor(it));
%ff=ut(1,(floor((it-1)/ns) +1))*pt;

152
OPTIMAL CONTROL MODELS IN FINANCE
%project2_4.m
function ff = project2_4(t,it,z,yin,hs,sm,x,lm,ns)
nn=1/hs;
fr=nn*mod(t,hs);
xmt=(1-fr)*x(it)+fr*x(it+1);
nb=nn/ns;
umx=zeros(nn,1);
umx(2)=sm(1);
for ii = 3: nn
umx(ii)=sm(ii-1)+umx(ii-1);
end
qt=nn*sm(floor(it),1)*(t-hs*(it-1))+umx(floor(it),1);
%qt=nb*ts((floor((it-1)/ns) +1),1)*(t-hs*ns*((
floor((it-1)/ns)+1)-1));
%qt=qt+umx((floor((it-1)/ns)+1),1);
ll=abs (xmt-((-5)*qt+5));% |x1(t)-((-5*t)+5)|
%ll= (xmt-((-5)*qt+5))^2;
%ll=abs (xmt-0.4*(qt^2));
%ll=(xmt-qt)^2;
ff=ll*nn*sm(floor(it),1);
%ff=ll*pt;
%Project2_4_test.m
function ff = project2_4_test(t,it,z,yin,hs,sm,x,lm,ps)
nn=1/hs;
fr=nn*mod(t,hs);
xmt=(1-fr)*x(it)+fr*x(it+1);
umx=zeros(nn,1);
umx(2) = sm(1);
for ii=3:nn
umx(ii)=umx(ii-1) + sm(ii-1);
end
u=zeros(nn/ps,1);
ts=zeros(nn/ps,1);
if ps > 1
for ii= 1:nn/ps
u(ii*ps-(ps-1))=sm(ii*ps-(ps-1));
for jj=ii*ps-(ps-2):ii*ps
u(jj)=u(jj-1)+sm(jj);
end
ts(ii)=u(jj);
end
else
for ii = 1: nn/ps
ts(ii)=sm(ii)
end

APPENDIX A: CSTVA Program List
153
end
pt=(nn/ps)*ts((floor((it-1)/ps)+1),1);
qt=nn*sm(1,floor(it))*(t-hs*(it-1))+umx(floor(it),1);
%ll=abs (xmt-((-5)*qt+5));% |x1(t)-((-5*t)+5)|
ll=(xmt-((-5)*qt+5))^2;
ff=nn*ll*sm(1,floor(it))*pt;
3.
Program C: Optimal Financing Model in Chapter 4
% An application of a model of investment of an utility.
%Model 1_1.m
function model1_1=model1_1(nb,ns,parameters) % parameters
here is used to define all the parameters in the model
%parameters = [p k r d c T]; % parameters here is used
to define all the parameters in the model
%parameters=[ 0.1 0.15 0.2 0.1 1 1];
par = [2,2,nb,ns,parameters];
%xinit= [P0,E0];
%xinit=[1 1];
%xinit = [0.5,0.5];
%xinit=[1.5 1.5];
xinit=[3 2];
nb=par(3); % big intervals
ns=par(4); % small intervals
nn=nb*ns; %total intervals
options(13)=1;
options(14)=10000;
um0=ones(nb,1)/nb;
%um=[0.1,0.3,0.6]’;
ul=zeros(nb,1);
uu=ones(nb,1);
um=constr(’model1_2’,um0,options,ul.uu,[],xinit,par);
[f,g,xm] = model1_2(um,xinit,par)
sm=zeros(nn,1);
v=zeros(nn,1);
for ii =1: nb
for jj= 1:ns
sm((ii-1)*ns+jj)=um(ii)/ns;
end
end
v(1)=sm(1);
for ii=2:nn
v(ii)=sm(ii)+v(ii-1);

154
OPTIMAL CONTROL MODELS IN FINANCE
end
v(nn)=0.9999999999999;
s=zeros(nn+1,1);
s(1)=0;
for ii = 2: nn+1
s(ii)=v(ii-1);
end
s
figure;
plot(xm(:,1),xm(:,2),’*b-’)
xlabel(’state function xm1’)
%Model 1_2.m
function [f,g,xm] = model1_2(um,xinit,par)
nx=par(1);
nu=par(2);
nb=par(3);
ns=par(4); % ns is small interval
nn=par(3)*par(4)
; % nn is total interval
sm=zeros(nn,1);
for ii =1: nb
for jj= 1:ns
sm((ii-1)*ns+jj)=um(ii)/ns;
end
end
xm=zeros(nn+1,nx);
xm(1,:)=xinit;
lm=zeros(nn+1,nx);
ma=nx;
t=0;
it=1;
hs=1/nn;
px=’model1_3’;
xm=nqq(px,nx,nu,nn,xm,ma,t,it,hs,sm,xm,lm,par);
zz=zeros(nn+1,nx);
zz(1,:) = 0;
ma=1;
t=0;
it=1;
hs=1/nn;
x=xm(:,2);
px=’model1_4’;
jm=nqq(px,nx,nu,nn,zz,ma,t,it,hs,sm,x,lm,par);

APPENDIX A: CSTVA Program List
155
%f=jm(nn+1);
g(1)=sum(sm)-1;
xf=xm(nn+1,1);
ed=’model1_5’;
f=jm(nn+1)+feval(ed,xf,par);
%Model1_3.m compute differential equation
function ff = model1_3(t,it,z,yin,hs,sm,xm,lm,par)
nn=1/hs;
nb=par(3);
ns=par(4);
rr=nn/(3*ns);
p=par(5);
r=par(7);
c=par(9);
T=par(10);
%for i=1:rr,
% 
us(3*i-2)=0;
%
ur(3*i-2)=0;
%
us(3*i-1)=0;
%
ur(3*i-1)=par(6)/par(7);
%
us(3*i)=par(6)/par(7);
% 
ur(3*i)=0;
%end
for i=1:rr,
us(3*i-2)=par(6)/par(7); 
% [C]
ur(3*i-2)=0;
us(3*i-1)=0; 
% [B]
ur(3*i-1)=par(6)/par(7);
us(3*i)=0; 
% [A]
ur(3*i)=0;
end
ts=zeros(nn,1);
if ns > 1
for ii= 1:nb
for jj=1 :ns
ts(ii)=ts(ii)+sm((ii-1)*ns+jj);
end
end
else
for ii= 1: nb
ts(ii)=sm(ii);
end
end

156
OPTIMAL CONTROL MODELS IN FINANCE
pt=nb*ts(floor((it-1)/ns)+1,1);
ff(1)= T*c*([1-ur(1,floor((it-1)/ns)+1)]*r*z(2)-p*z(1))*pt;
ff(2)= T*r*z(2)*[ur(1,floor((it-1)/ns)+1)+us(1,
floor((it-1)/ns)+1)*(1-z(2)/((1-d)
*z(1)))]*pt;
%Model1_4.m
function ff = model1_4(t,it,z,yin,hs,sm,xm,lm,par)
nn=1/hs;
fr=nn*mod(t,hs);
xmt=(1-fr)*xm(it)+fr*xm(it+1);
nn=1/hs;
rr=nn/(3*ns);
p=par(5);
r=par(7);
T=par(10);
%for i=1:rr,
%
ur(3*i-2)=0;
% 
ur(3*i-1)=0;
% 
ur(3*i)=par(6)/par(7);
%end
for i=1:rr,
ur(3*i-2)=0;
ur(3*i-1)=par(6)/par(7);
ur(3*i)=0;
end
umx=zeros(nn,1);
umx(2) = sm(1);
for ii=3:nn
umx(ii)=umx(ii-1)+ sm(ii-1);
end
qt=nn*sm(floor(it),1)*(t-hs*(it-1))+umx(floor(it),1);
ll=exp(-p*qt*T)*[1-ur(1,floor(it))]*r*xmt;
ff=-nn*ll*sm(floor(it),1)*T;
%Model1_5.m
function ff = model1_5(xf,par)
p=par(5);
T=par(10);
ff=-xf*exp(-p*T);
4.
Program D: Three Value-Control Model in Chapter 5
%Project3_1.m computation for the integral

APPENDIX A: CSTVA Program List
157
function project3_1=project3_1(nb,ns) % nb is big
interval of time t and ns is small interval
par = [2,1,nb,ns];
xinit= [3,5];
nb=par(3);% big intervals
ns=par(4);% small intervals
nn=nb*ns; %total intervals
options(13)=1;
options(14)=10000;
um0=ones(nb,1)/nb;
ul=zeros(nb,1);
uu=ones(nb,1);
um=constr(’project3_2’,um0,options,ul,uu,[],xinit,par);
[f,g,xm] = project3_2(um,xinit,par)
sm=zeros(nn,1);
v=zeros(nn,1);
for ii =1: nb
for jj= 1:ns
sm((ii-1)*ns+jj)=um(ii)/ns;
end
end
v(1)=sm(1);
for ii=2:nn
v(ii)=sm(ii)+v(ii-1);
end
v(nn)=0.9999999999999;
s=zeros(nn+1,1);
s(1)=0;
for ii = 2: nn+1
s(ii)=v(ii-1);
end
s
figure;
plot(s,xm(:,1),’ob-’)
hold on;
t= [0:1/10:1];
plot(t,4*sin(5*t+1), ’+r:’)
xlabel(’Time T’)
ylabel(’State function xm and given fit function
4*sin(5*t+1) ’)
figure;
plot(xm(:,1),xm(:,2),’*b-’)
xlabel(’state function xm1’)

158
OPTIMAL CONTROL MODELS IN FINANCE
ylabel(’state function xm2’)
%Project3_2.m integral
function [f,g,xm] = project3_2(um, xinit, par)
nx=par(1);
nu=par(2);
nb=par(3);
ns=par(4); % ns is small interval
nn=par(3)*par(4) ; % nn is total interval
sm=zeros(nn,1);
for ii =1: nb
for jj= 1:ns
sm((ii-1)*ns+jj)=um(ii)/ns;
end
end
xm=zeros(nn+1,nx);
xm(1,:)=xinit;
lm=zeros(nn+1,nx);
ma=nx;
t=0;
it=1;
hs=1/nn;
px=’project3_3’;
xm=nqq(px,nx,nu,nn,xm,ma,t,it,hs,sm,xm,lm,ns);
zz=zeros(nn+1,nx);
zz(1,:) = 0;
ma=1;
t=0;
it=1;
hs=1/nn;
px=’project3_4’;
x=xm(:,1);
jm=nqq(px,nx,nu,nn,zz,ma,t,it,hs,sm,x,lm,ns);
f=jm(nn+1);
g(1)=sum(sm)-1;
%Project3_3.m compute differential equation
function ff = project3_3(t,it,z,yin,hs,sm,xm,lm,ns)
nn=1/hs;
T=5;
B=0.0;
B=0.1;

APPENDIX A: CSTVA Program List
159
B=0.2;
nb=nn/ns;
rr=nn/(3*ns);
%for i=1:rr,
%        ut(3*i-1)=-1;
% 
 ut(3*i)=0;
%         ut(3*1+1)=1;
%end
for i=1:rr,
ut(3*i-2)=-2;
ut(3*i-1)=0;
ut(3*i)=2;
end
ts=zeros(nn,1);
if ns > 1
for ii= 1:nb
for jj=1:ns
ts(ii)=ts(ii)+sm((ii-1)*ns+jj);
end
end
else
for ii= 1: nb
ts(ii)=sm(ii);
end
end
pt=nb*ts((floor((it-1)/ns)+1),1);
ff(1)= T * z(2)*pt;
ff(2)= (-T * z(1)
+ T *ut(1,(floor((it-1)/ns) + 1)) –
T^2 * B *z(2))*pt;
%Project3_4.m
function ff = project3_4(t,it,z,yin,hs,sm,x,lm,ns)
nn=1/hs;
fr=nn*mod(t,hs);
xmt=(1-fr)*x(it)+fr*x(it+1);
nb=nn/ns;
umx=zeros(nn,1);
umx(2)=sm(1);
for ii = 3: nn
umx(ii)=sm(ii-1)+umx(ii-1);
end
qt=nn*sm(floor(it),1)*(t-hs*(it-1))+umx(floor(it),1);
ll=abs(xmt-4*sin(5*qt+1);% |x1(t)-cos(0.4*t+2.85)|
ff=ll*nn*sm(floor(it),1);

This page intentionally left blank

Appendix B
Some Computation Results
1.
Results for Program A
um: the optimal time intervals.
f: the result of the objective funtion
g: the result of the constraints
s: optimal switching times
xm: the values of the state variable
project1_1(2)
um =
0.1271
0.8729
f =
0.0627
g =
-4.5940e-11
xm =
0
0.1271
0.1271
project1_1(4)
um =
0.0299
0.4868
0.2912
0.1921
f =
0.0291
g =
-7.8249e-13
xm =

162
OPTIMAL CONTROL MODELS IN FINANCE
0.0154
0.0154
0.1380
0.1380
0.3515
0.3515
0.0108
0.0108
0.0908
0.0908
0.2109
0.2109
0.3647
0.3647
0
0.0299
0.0299
0.3211
0.3211
project1_1(6)
um =
0.0154
0.3612
0.1226
0.1763
0.2135
0.1111
f =
0.0184
g =
-3.4402e-11
xm =
0
project1_1(8)
um =
0.0108
0.3063
0.0801
0.1569
0.1200
0.0971
0.1539
0.0749
f =
0.0134
g =
-7.3581e-12
xm =
0

APPENDIX B: Some Computation Results
163
2.
Results for Program B
project2_1(2,1)
um =
0.4167
0.5833
f =
1.8227
g =
-6.1625e-11
xm =
3.0000
5.8281
0.6973
s =
0
0.4167
1.0000
project2_1(2,2)
um =
0.6512
0.3488
f =
0.9394
g =
-2.5978e-12
xm  =
3.0000
5.3714
2.3736
0.3249
-1.6526
s =
0
0.3256
0.6512
0.8256
1.0000
project2_1(4,1)
um =
0.0584
0.1610
0.5106
0.2700
f =
0.6311
g =
-2.8808e-11
xm =
3.0000 
5.0000
5.0000
-2.5048
-11.1396
5.0000
-1.6031
-1.6846
-2.6175
-1.7606

164
OPTIMAL CONTROL MODELS IN FINANCE
4.2091
4.3875
0.8660
-1.3328
s =
0
0.0584
0.2194
0.7300
1.0000
project2_1(4,2)
um =
0.0123
0.1431
0.5868
0.2578
f =
0.3388
g =
7.0286e-11
xm =
3.0000
3.1513
3.2968
4.3621
4.4301
2.5494
1.4915
0.8567
-0.3231
s =
0
0.0062
0.0123
0.0839
0.1554
0.4488
0.7422
0.8711
1.0000
project2_1(4,4)
um =
0.0024
0.1349
0.5626
0.3001
f =
0.2786
g =
3.3108
-2.2196
-1.3209
-1.5506
5.0000
4.8156
4.6323
1.4484
-0.9324
-1.2942
-0.1476
-1.6082
-1.9003

APPENDIX B: Some Computation Results
165
-5.7630e-11
xm =
3.0000
3.0147
3.0293
3.0438
3.0583
3.7520
4.1877
4.3942
4.4016
3.7206
2.7950
2.0640
1.6791
1.3593
0.7498
0.0120
-0.7284
s =
0
0.0006
0.0012
0.0018
0.0024
0.0361
0.0698
0.1036
0.1373
0.2779
0.4186
0.5592
0.6999
0.7749
0.8499
0.9250
1.0000
project2_1(6,1)
um =
0.3257
0.1238
0.1980
-0.0000
0.3526
-0.0000
f =
0.5290
g =
-1.4863e-10
xm =
5.0000
4.9824
4.9648
4.9472
4.9296
3.3204
1.8743
0.6038
-0.4854
-1.2868
-1.2454
-0.7997
-0.3053
-1.3175
-1.8604
-2.0176
-1.8917

166
OPTIMAL CONTROL MODELS IN FINANCE
3.0000
5.3715
3.5555
0.9604
0.9604
0.8020
0.8020
s =
0.3257
0.4495
0.6474
0.6474
1.0000
1.0000
project2_1(6,2)
um =
-0.0000
0.1329
0.5063
0.0741
0.1196
0.1671
f =
3.0000
3.0000
3.0000
4.1425
4.3902
3.0702
1.8010
1.6448
1.4012
1.0408
0.8471
0.5008
-0.0789
s =
-0.0000
-0.0000
0.0665
0.1329
0.3861
0.6392
0.6763
0
0.2615
g =
-4.3578e-11
xm =
0
5.0000
-1.6041
-3.8604
-1.3485
-1.3485
0.9757
0.9757
5.0000
5.0000
5.0000
1.9787
-0.3727
-1.3534
-0.5648
-1.0998
-1.5101
-0.9124
-0.3992
-1.1814
-1.5304

APPENDIX B: Some Computation Results
167
0.7133
0.7731
0.8329
0.9165
1.0000
3.
Results for Program C
Diferent controls in model1_1
p=0.1, k=0.15, r=0.2, d=0.1, c=1, T=10,
x0=(5,3)
control: [C] [B] [A]
results:
model1_1(3,3,parameters)
um =
0.94900897415069
-0.00000000000000
0.05099102586178
f =
-6.98762419479152
g =
1.247046910179961e-11
xm =
5.00000000000000
5.40600401539454
5.95896569319826
6.63077320213855
6.63077320213855
6.63077320213855
6.63077320213855
6.66948645920598
6.70754726725807
6.74496662226235
s =
0
0.31633632471690
0.63267264943379
0.94900897415069
0.94900897415069
0.94900897415069
0.94900897415069
0.96600598277128
0.98300299139188
0.99999999999990
3.00000000000000
3.47094537715380
3.95174665662712
4.46391793267020
4.46391793267020
4.46391793267020
4.46391793267020
4.46391793267020
4.46391793267020
4.46391793267020

168
OPTIMAL CONTROL MODELS IN FINANCE
control: [A] [B] [C]
results:
model1_1(3,3,parameters)
um =
0
0
1.00000000000000
f =
-6.98439125301710
g =
-2.220446049250313e-16
xm =
5.00000000000000
5.00000000000000
5.00000000000000
5.00000000000000
5.00000000000000
5.00000000000000
5.00000000000000
5.43239375551053
6.02582277381470
6.74935621984978
s =
0
0
0
0
0
0
0
0.33333333333333
0.66666666666667
0.99999999999990
p=0.1, k=0.15, r=0.2, d=0.1, c=1, T=10,
x0=(3,2)
control: [C] [B] [A]
model1_1(3,3,parameters)
um =
-0.00000000000000
0.43627214331862
0.56372785682345
f =
3.00000000000000
3.00000000000000
3.00000000000000
3.00000000000000
3.00000000000000
3.00000000000000
3.00000000000000
3.49626657386023
4.00489471104744
4.55053034609536

APPENDIX B: Some Computation Results
169
-4.34971604717521
g =
1.420692452569483e-10
xm =
3.00000000000000
3.00000000000000
3.00000000000000
3.00000000000000
2.74560664232866
2.56260603757432
2.45034521298337
3.34895792223138
4.09363087946859
4.71073523102452
s =
0
-0.00000000000000
-0.00000000000000
-0.00000000000000
0.14542404777287
0.29084809554574
0.43627214331862
0.62418142892643
0.81209071453425
0.99999999999990
x0=(5,3)
model1_1(3,3,parameters)
um =
0.94900897415069
-0.00000000000000
0.05099102586178
f =
-6.98762419479152
g =
1.247046910179961e-11
0
5.00000000000000
5.40600401539454
5.95896569319826
6.63077320213855
6.63077320213855
6.63077320213855
6.63077320213855
6.66948645920598
6.70754726725807
6.74496662226235
xm =
s =
2.00000000000000
2.00000000000000
2.00000000000000
2.00000000000000
2.48750405168379
3.09383820357164
3.84796753331929
3.84796753331929
3.84796753331929
3.84796753331929
3.00000000000000
3.47094537715380
3.95174665662712
4.46391793267020
4.46391793267020
4.46391793267020
4.46391793267020
4.46391793267020
4.46391793267020
4.46391793267020

170
OPTIMAL CONTROL MODELS IN FINANCE
0.31633632471690
0.63267264943379
0.94900897415069
0.94900897415069
0.94900897415069
0.94900897415069
0.96600598277128
0.98300299139188
0.99999999999990
p=0.1, k=0.15, r=0.2, d=0.1, c=1, T=10,
x0=(3,2)
control: [A] [B] [C]
model1_1(3,3,parameters)
um =
0
0
1.00000000000000
3.00000000000000
3.00000000000000
3.00000000000000
3.00000000000000
3.00000000000000
3.00000000000000
3.00000000000000
3.36336204900022
3.78530547911419
4.26744142249872
s =
0
0
0
0
0
0
0
0.33333333333333
0.66666666666667
0.99999999999990
x0=(5, 3)
f =
-4.49775108882148
g =
-2.220446049250313e-16
xm =
2.00000000000000
2.00000000000000
2.00000000000000
2.00000000000000
2.00000000000000
2.00000000000000
2.00000000000000
2.27071366163561
2.56979963470193
2.90415715247832

APPENDIX B: Some Computation Results
171
model1_1(3,3,parameters)
um =
0
0
5.00000000000000
5.00000000000000
5.00000000000000
5.00000000000000
5.00000000000000
5.00000000000000
5.00000000000000
5.43239375551053
6.02582277381470
6.74935621984978
s =
0
0
0
0
0
0
0
0.33333333333333
0.66666666666667
0.99999999999990
p=0.1, k=0.15, r=0.2, d=0.1, c=1, T=10,
x0=(0.5, 1)
control : [C] , [B] , [A]
results:
model1_1(3,3,parameters)
um =
-0.00000000000000
0.44198331380348
0.55801668619645
1.00000000000000
f =
-6.98439125301710
g =
-2.220446049250313e-16
xm =
f =
-2.03958198064794
g =
3.00000000000000
3.00000000000000
3.00000000000000
3.00000000000000
3.00000000000000
3.00000000000000
3.00000000000000
3.49626657386023
4.00489471104744
4.55053034609536

172
OPTIMAL CONTROL MODELS IN FINANCE
-6.283862319378386e-14
xm =
0.50000000000000
0.50000000000000
0.50000000000000
0.50000000000000
0.50836518053403
0.53459240084601
0.58093560157541
1.14106504606018
1.60612415480481
1.99224914208392
s =
0
-0.00000000000000
-0.00000000000000
-0.00000000000000
0.14732777126783
0.29465554253566
0.44198331380348
0.62798887586897
0.81399443793445
0.99999999999990
p=0.1, k=0.15, r=0.2, d=0.1, c=1, T=10,
x0=(0.5, 1)
control : [A] , [B] , [C]
results:
model1_1(3,3,parameters)
um =
0.52071677552328
-0.00000000000000
0.47928322447289
0.50000000000000
0.73901347970328
0.93994199708665
1.10885409839574
1.10885409839574
1.10885409839574
1.10885409839574
f =
-1.81807434266798
g =
-3.836042594684841e-12
xm =
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.24730846467207
1.55577840604261
1.94053557501097
1.94053557501097
1.94053557501097
1.94053557501097
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000

APPENDIX B: Some Computation Results
173
1.24170396001051
1.36155842306688
1.47466384342158
s =
0
0.17357225850776
0.34714451701552
0.52071677552328
0.52071677552328
0.52071677552328
0.52071677552328
0.68047785034757
0.84023892517187
0.99999999999990
model1_1(6,6,parameters)
um =
0.39890660392318
-0.00000000000000
0.00000000000000
0.11928746513786
-0.00000000000000
0.48180593092858
0.50000000000000
0.59648376317515
0.68676144864600
0.77123224690021
0.85026967149177
0.92422321064582
0.99341987262807
0.99341987262807
0.99341987262807
0.99341987262807
0.99341987262807
0.99341987262807
0.99341987262807
0.99341987262807
0.99341987262807
0.99341987262807
0.99341987262807
0.99341987262807
0.99341987262807
1.01323431734672
1.03265871639605
1.05170074779209
f =
-1.82053330509933
g =
-1.038513719464618e-11
xm =
1.01227203398012
1.04280425406198
1.08536853674905
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000

174
OPTIMAL CONTROL MODELS IN FINANCE
1.07036793840976
1.08866766695811
1.10660716689690
1.10660716689690
1.10660716689690
1.10660716689690
1.10660716689690
1.10660716689690
1.10660716689690
1.17569510221352
1.24040740530816
1.30187570955606
1.36097381645976
1.41839237440713
1.47468755717307
s =
0
0.06648443398720
0.13296886797439
0.19945330196159
0.26593773594879
0.33242216993598
0.39890660392318
0.39890660392318
0.39890660392318
0.39890660392318
0.39890660392318
0.39890660392318
0.39890660392318
0.39890660392318
0.39890660392318
0.39890660392318
0.39890660392318
0.39890660392318
0.39890660392318
0.41878784811282
0.43866909230247
0.45855033649211
0.47843158068175
0.49831282487140
0.51819406906104
0.51819406906104
0.51819406906104
0.51819406906104
0.51819406906104
0.51819406906104
0.51819406906104
0.59849505754914
0.67879604603723
0.75909703452533
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00000000000000
1.00307087089333
1.01202132418871
1.02549798919538
1.04259929524034
1.06270178723606
1.08536187030624

APPENDIX B: Some Computation Results
175
0.83939802301342
0.91969901150152
0.99999999999990
4.
Results for Program D
project3_1(3,1)
f =
1.0586
g =
-6.2238e-11
xm =
3.0000
3.2515
3.2515
-9.1222
5.0000
-3.4665
-3.4665
1.1345
s =
0
0.2840
0.2840
1.0000
project3_1(3,2)
f =
1.1967
g =
-1.4602e-10
xm =
3.0000
3.2944
-1.4369
-2.4523
-1.6076
-1.3167
-0.9671
5.0000
-3.4031
-2.7269
0.2524
1.3348
1.7035
1.9524
s =
0
0.2792
0.5584
0.7411
0.9239
0.9620
1.0000
project3_1(3,3)
f =
0.9367
g =
1.7265e-10

176
OPTIMAL CONTROL MODELS IN FINANCE
xm =
3.0000
3.7672
-0.0810
-2.7291
-2.8827
-2.3886
-1.6078
-1.6078
-1.6078
-1.6078
5.0000
-2.6588
-3.3194
-1.1775
0.4586
1.3429
1.5983
1.5983
1.5983
1.5983
s =
0
0.2302
0.4604
0.6906
0.7938
0.8969
1.0000
1.0000
1.0000
1.0000
project3_1(6,1)
f =
0.7708
g =
2.0042e-10
xm =
3.0000
4.3970
4.3970
4.3970
2.5059
2.5059
-8.8124
5.0000
-0.4306
-0.4306
-0.4306
-3.3710
-3.3710
3.4589
s =
0
0.1346
0.1346
0.1346
0.3056
0.3056
1.0000
project3_1(6,2)
f =
0.9828
g =
-1.9679e-10

APPENDIX B: Some Computation Results
177
xm =
3.0000
3.6722
-0.3772
-0.6028
-0.8093
-0.8093
-0.8093
-2.8731
-2.8489
-2.8489
-2.8489
-2.8489
-2.8489
5.0000
-2.8237
-3.2174
-2.9559
-2.6976
-2.6976
-2.6976
-0.6405
0.5052
0.5052
0.5052
0.5052
0.5052
s =
0
0.2400
0.4800
0.4946
0.5092
0.5092
0.5092
0.7546
1.0000
1.0000
1.0000
1.0000
1.0000
project3_1(9,1)
f =
1.5792
g =
-1.1642e-10
xm =
3.0000
3.0007
0.2249
0.2249
-3.4249
-3.4249
-3.4249
-3.4249
-3.4249
-3.4249
5.0000
-3.8736
-2.4065
-2.4065
-1.0539
-1.0539
-1.0539
-1.0539
-1.0539
-1.0539
s =
0
0.3164
0.4882
0.4882

178
OPTIMAL CONTROL MODELS IN FINANCE
1.0000
1.0000
1.0000
1.0000
1.0000
1.0000
project3_1(9,2)
f =
0.9830
g =
2.2104e-10
xm =
3.0000
3.7478
-0.1429
-0.4100
-0.6527
-0.6527
-0.6527
-2.8224
-2.8407
-2.8407
-2.8407
-2.8407
-2.8407
-2.8407
-2.8407
-2.8407
-2.8407
-2.8407
-2.8407
5.0000
-2.6935
-3.2994
-3.0087
-2.7209
-2.7209
-2.7209
-0.6915
0.4891
0.4891
0.4891
0.4891
0.4891
0.4891
0.4891
0.4891
0.4891
0.4891
0.4891
s =
0
0.2322
0.4644
0.4814
0.4983
0.4983
0.4983
0.7492
1.0000
1.0000
1.0000
1.0000
1.0000
1.0000
1.0000
1.0000
1.0000

APPENDIX B: Some Computation Results
179
1.0000
1.0000

This page intentionally left blank

Appendix C
Differential Equation Solver from the SCOM
Package
function 
xk=nqq(pd,nx,nu,nn,fil,ma,t,it,hs,um,xm,lm,ps)
% Calling the Runge-Kutta integration
yin=fil(1,:);xk(1,:)=yin;
while it < nn+1
[y2,it2,t2]=rqq(pd,ma,t,it,hs,yin,nx,nu,nn,um,xm,lm,ps);
xk(it+1,:)=y2;
it=it2;t=t2;
yin=y2;
end
function [y1,it,t]=rqq(pd,ma,t,it,hs,yin,nx,nu,nn,um,xm,lm,ps)
% Runge-Kutta stages
fp=zeros(ma,1)’; tt=zeros(ma,1)’;
P=0; q=1;
tz=kqq(pd,ma,t,it,hs,p,q,fp,yin,tt,um,xm,lm,ps);
tt=tz(1,:); fp=tz(2,:);
p=0.5;q=2;t=t+0.5*hs;
tz=kqq(pd,ma,t,it,hs,p,q,fp,yin,tt,um,xm,lm,ps);
tt=tz(1,:); fp=tz(2,:);
tz=kqq(pd,ma,t,it,hs,p,q,fp,yin,tt,um,xm,lm,ps);
tt=tz(1,:); fp=tz(2,:);
t=t+0.5*hs;p=1;q=1;
tz=kqq(pd,ma,t,it,hs,p,q,fp,yin,tt,um,xm,lm,ps);
tt=tz(1,:); fp=tz(2,:);
it=it+sign(hs);
it;
y1=yin+tt/6;

182
OPTIMAL CONTROL MODELS IN FINANCE
function tz=kqq(pd,ma,t,it,hs,p,q,fp,yin,tt,um,xm,lm,ps)
% Calling the function
z=yin+p*hs*fp;
ff=feval(pd,t,it,z,yin,hs,um,xm,lm,ps);
fp=ff;
tz=[tt+q*hs*fp;fp] ;
function ix=jqq(vv,hh,xi)
% Linear interpolation
global um xm jm
nn=length(vv’)-1;
nz=-1/hh;
if xi < 0, xi = 0; end
fr=-nz*mod(xi,hh);
bb=ceil(xi*nz)+1;
if bb>1, vw=vv(bb-1,:);
else vw=vv(1);
end
ix=(1-fr)*vv(bb,:) + fr*vw;

Appendix D
SCOM Package
subs=cell(1,9);
subs={’dnx’ ,’dnj’ ,’dnf’ ,’dnc’};
par=[2, 2, 20, 0, 0, 1, 6, 0.2, 0.1, 0.1, 0.75];
% nx, nu, nn, npa, grad, c, T, r, p, d , b=k/r\
% nx = number of states, nu = number of controls,
nn = number of subdivisions
% npa = 0 (reserved), grad = 1 if gradients calculated,
otherwise 0
% The remaining parameters, specific to the problem,
are passed to the subroutines
xinit=[2 1]; nn=par(3); % Initial values for the state(s)
u0=zeros(nn,2); % Starting values for computing the control
ul=zeros(nn,2); % Lower bound (vector or matrix) for the control
uu=ones(nn,2); % Upper bound (vector or matrix) for the control
figure
Control=constr(’fqq’ ,u0, [] ,ul,uu, [] ,par,subs,xinit)
% Calls constr package
[Objective,Constraint,State,Integral]= cqq(Control,par,subs,xinit)
% Computes optimal state, etc., from the optimal control
got from constr
% If gradients are calculated, then used instead
% [Objective, Constraint, State, Integral, Costate,Gradient]
=cqq(Control,par,subs,xinit)
% The following lines plot one state component against another,
and plot two control components, ehich are step-functions,
against time

184
OPTIMAL CONTROL MODELS IN FINANCE
plot(State(:,1),State(:,2),’x-’)
xlabel(’State 1’)
ylabel(’State 2’)
figure
t2=[0:0.001:0.999];
plot(t2,Control(floor(nn*t2)+1,1),’r’)
hold on
plot(t2,Control(floor(nn*t2)+1,2),’g’)
%The following codes comprise the SCOM package;
the user does not alter them
% Get function values as required by constr
function [f,g]=fqq(uz,ps,q,xinit) % Input data to the subroutine
if ps(5)==1
[a1,a2,a3,a4,a5,a6]=cqq(uz,ps,q,xinit);
% Output data
elseif ps(5)==0
[a1,a2,a3,a4]=cqq(uz,ps,q,xinit);
end
f=a1;
g=a2;
function [df,dg]=gqq(uu,ps,q,xinit)
% Get gradient values as required by constr
[a1,a2,a3,a4,a5,a6]=cqq(uu,ps,q,xinit);
df=a6’;
nn=ps(3);
pk=char(q(5));
dg=feval(pk,uu,nn);
function [f,g,xm,f0,lm,gr]=cqq(um,ps,q,xinit)
% Solve differential equations
nx=ps(1);nu=ps(2);nn=ps(3);npa=ps(4); rec=0;npar=1;
xm=zeros(nn+1,nx); xm(1,:)=xinit; lm=zeros(nn+1,nx);
ma=nx;t=0;it=1;hs=1/nn;
px=char(q(1));
xm=nqq(px,nx,nu,nn,xm,ma,t,it,hs,um,xm,lm,ps); %compute state
ma=1;t=0;it=1;hs=1/nn;
zz=zeros(nn+1,1); zz(1,:)=0;

APPENDIX D: SCOM Package
185
pj=char(q(2));
jm=nqq(pj,nx,nu,nn,zz,ma,t,it,hs,um,xm,lm,ps);%compute integral
xf=xm(nn+1,:) ;
pf=char(q(3));
f=jm(nn+1) + feval(pf,xf,um,xm,ps); %objective
pc=char(q(4));
for ii=1:nn
g(ii)=feval(pc,ii,hs,um,xm,lm,ps) ; %control constraint
end
f0=jm(nn+1);
%final state
if ps(5)==1
%if gradients are supplied
ma=nx;t=1;it=nn;hs=-1/nn;
lm=zeros(nn+1,nx);
pa=char(q(8));
lm(nn+1,:)=feval(pa,nn,xf,um,xm,ps);
pq=char(q(6));
lm=lqq(pq,nx,nu,nn,lm,ma,t,it,hs,um,xm,lm,ps);
%costate
function xk=nqq(pd,nx,nu,nn,fil,ma,t,it,hs,um,xm,lm,ps)
%Runge-Kutta (organize steps for fourth order RK
integration of DEs)
yin=fil(1,:);xk(1,:)=yin;
while it < nn+1
[y2,it2,t2]=rqq(pd,ma,t,it,hs,yin,nx,nu,nn,um,xm,lm,ps);
xk(it+1,:)=y2;
it=it2;t=t2;
yin=y2;
end
function 
[y1,it,t]=rqq(pd,ma,t,it,hs,yin,nx,nu,nn,um,xm,lm,ps)
% Runge-Kutta : increments
fp=zeros(ma,1)’; tt=zeros(ma,1)’;
P=0; q=1;
tz=kqq(pd,ma,t,it,hs,p,q,fp,yin,tt,um,xm,lm,ps);
tt=tz(1,:); fp=tz(2,:);
p=0.5;q=2;t=t+0.5*hs;
tz=kqq(pd,ma,t,it,hs,p,q,fp,yin,tt,um,xm,lm,ps);

186
OPTIMAL CONTROL MODELS IN FINANCE
tt=tz(1,:); fp=tz(2,:);
tz=kqq(pd,ma,t,it,hs,p,q,fp,yin,tt,um,xm,lm,ps);
tt=tz(1,:);
fp=tz(2,:);
t=t+0.5*hs;p=1;q=1;
tz=kqq(pd,ma,t,it,hs,p,q,fp,yin,tt,um,xm,lm,ps);
tt=tz(1,:); fp=tz(2,:);
it=it+sign(hs);
y1=yin+tt/6;
function tz=kqq(pd,ma,t,it,hs,p,q,fp,yin,tt,um,xm,lm,ps)
% Runge-Kutta : get function values
z=yin+p*hs*fp;
ff=feval(pd,t,it,z,yin,hs,um,xm,lm,ps);
fp=ff;
tz=[tt+q*hs*fp;fp] ;
function xk=lqq(pd,nx,nu,nn,fil,ma,t,it,hs,um,xm,lm,ps)
%Runge-Kutta for adjoint differential equation
(time reversed)
yin=fil(nn+1,:);xk(nn+1,:)=yin;
while it > 0 %< nn+1
[y2,it2,t2]=rqq(pd,ma,t,it,hs,yin,nx,nu,nn,um,xm,lm,ps);
xk(it,:)=y2;
it=it2; t=t2;
yin=y2;
end
function ix=iqq(vv,hh,xi)
% Linear interpolation (forwards)
nn=length(vv’)-1;
nz=1/hh;
fr=nz*mod(xi,hh);
bb=floor(xi*nz)+1;
if bb <= nn, vu=vv(bb+1,:);
else vu=vv(nn);
end
ix=(1-fr)*vv(bb,:) + fr*vu;
function ix=jqq(vv,hh,xi)
% Linear interpolation (backwards)

APPENDIX D: SCOM Package
187
global um xm jm
nn=length(vv’)-1;
nz=-1/hh;
if xi < 0, xi = 0;
end
fr=-nz*mod(xi,hh);
bb=ceil(xi*nz)+1;
if
bb>1,
vw=vv(bb-1,:);
else
vw=vv(1);
end
ix=(1-fr)*vv(bb,:)
+
fr*vw;
Note that linear interpolation of the state is required in integrating the objective function, and
in solving the adjoint differential equation. The latter is solved backwards in time t, so needs
backwards interpolation.

This page intentionally left blank

Appendix E
Format of Problem Optimization
The control function approximates the control function 
by a step-function, dividing
[0,1] into nn equal subintervals. (Because the dynamic equation has a smoothing effect, set
function controls are usually a sufficient approximation.) Function values (and often also gra-
dients with respect to control) for the objective function are obtained by solving differential
equations. They are then supplied to the optimization program constr in MATLAB’s Optimiza-
tion Toolbox. The computation is considerably faster if gradients are supplied, but this is not
suitable for some problems, especially if the functions are not well behaved outside the feasible
region of the problem. If gradients are used, then the adjoint differential equation is required.
If a constraint 
is required, then it is added to s a positive penalty parameter. The user
must supply a calling program (defining all parameters), and user subroutines for the functions
of the given control problem. This use of MATLAB minimizes the amount of programming
required for a given control problem, since MATLAB handles matrix calculations and pass-
ing of parameters very effectively. (But another programming language may be preferred for a
large control problem, if faster computation is needed.) The acronym SCOM stands for step-
function control optimization on Macintosh, since the intention was to compute optimal control
on a desktop computer, rather than on a mainframe or workstation. Note that MATLAB on a
Windows computer does the same job.

This page intentionally left blank

Appendix F
A Sample Test Problem
The following example has two controls and one state,
and gradients are calculated.
subs=cell(1,9);
subs={’t3x’,’t3j’,’t3f’,’t3c’,>t3k’,’t3l’,’t3g’,’t3a’,’t3p’};
par=[1, 2, 20, 0, 1, 0.25]; % Parameters
% nx, nu, nn, npa, grad, c
nnb=par(3); nx=par(1); nu=par(2);
xinit=[0.5];
% Initial value for the state
u0=zeros(nn,nu);
% Starting values for computing the control
ul=zeros(nn,nu);
% Lower bound (vector or matrix) for the control
uu=ones(nn,nu);
% Upper bound (vector or matrix) for the control
figure
Control=constr(’fqq’,u0,[],ul,uu,’gqq’,par,subs,xinit)
% Calls constr package
[Objective,Constraint,State,Integral,Costate,Gradient] =
cqq(Control,par,subs,xinit) % Right hand side of differential
equation
function yy=t3x(t,it,z,yin,hs,um,xm,lm,ps)

192
OPTIMAL CONTROL MODELS IN FINANCE
yy(1)=z(1)*um(floor(it),1)+um(floor(it),2);
% Dependent variables on the right hand side
of a differential equation are coded as
z(1), z(2), etc.
function ff=t3j(t,it,z,yin,hs,um,xm,lm,ps)
% Integrand of objective function
c=ps(6)
ff(1)=(um(floor(it),1)-1)*li3(xm,hs,t);
ff(1)=ff(1)+c*um(floor(it),2);
function ff=t3f(xf,um,xm,ps)
% Endpoint term
ff(1)=0; % Control constraint
function gg=t3c(ii,hs,um,xm,lm,ps)
gg=um(ii,1) + um(ii,1) - 1;
function dg=t3k(ii,hs,um,xm,lm,ps)
% Gradient of constraint
dg=[eye(nn);eye(nn)];
function yy=t3g(t,hs,um,xm,lm,nn)
% Gradient of objective
temp= 0.5*(lm(t,1)+lm(t+1,1));
t2=t/nn;
yy=[(1+temp)*li3(xm,hs,t2), 0.25+temp];
function yy=t3a(nn,xf,um,xm,ps)
%Boundary condition for adjoint equation (at t=1)
yy=0;
function yy=t3l(t,it,z,yin,hs,um,xm,lm,ps)
% Right hand side of adjoint equation
yy=-(1+z(1))*um(floor(it),1)+1;

References
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
Ahmed, N.U. (1988). Elements of Finite-Dimensional Systems and Control Theory. Long-
man Scientific and Technical, Harlow, Essex, England.
Blatt, John M. (1976). Optimal control with a cost of switching control. J. Austral. Math.
Soc., 19:316-332.
Brekke, K.A. and Øksendal, B. (1991). A verification theorem for combined stochastic
control and impulse control. Stochastic Anal. Related Topics, 6:211-220.
Brigham, E. and Houston, J. (2000) Fundamentals of Financial Management, 9th edn. The
Dryden Press, Harcourt Brace College Publishers, Orlando.
Bryson, A.E.Jr. and Ho, Y.G. (1975). Applied Optimal Control. Halsted Press, New York.
Cadenillas, A. and Zapatero, F. (2000). Classical and impulse stochastic control of the
exchange rate using interest rates and reserves. Math. Finance, 10:141-156.
Campbell, J. Y., Lo, A. W. and MacKinlay, A. C. (1997). The Econometrics of Financial
Markets. Princeton University Press, Princeton, New Jersey.
Cesari, L. (1983). Optimization - Theory and Applications. Springer-Verlag, New York.
Chakravarty, S. (1969). Capital and Economic Development Planning. MIT Press, Cam-
bridge.
Chen, P. and Craven, B.D. (2002). Computing switching times in bang-bang control.
Mimeo, University of Melbourne.
Chen, P. and Islam, S.M.N. (2002). Optimal financing for corporations: optimal control
with switching time and computational experiments using CSTVA. Paper presented at the
Financial Modeling seminar, Victoria University of Technology, Melbourne, Australia.
Clarke, C.W. (1976). Mathematical Bioeconomics: The Optimal Management of Renew-
able Resources. John Wiley, New York.
Craven, B.D. (1978). Mathematical Programming and Control Theory. Chapman and
Hall, London.

194
OPTIMAL CONTROL MODELS IN FINANCE
[14]
[15]
[16]
[17]
[18]
[19]
[20]
[21]
[22]
[23]
[24]
[25]
[26]
[27]
[28]
[29]
[30]
[31]
[32]
Craven, B.D. (1995). Control and Optimization. Chapman and Hall Mathematics, London.
Craven, B.D., HAAS, K.De. and Wettenhall, J.M. (1998). Computing optimal control.
Dynamics of Continuous, Discrete and Impulsive Systems, pp. 601-615.
Craven, B.D. (1999). Computing optimal control on MATLAB, Optimization Day.
Mimeo, University of Ballarat, Melbourne, Australia.
Craven, B.D. (1999). Optimal control for an obstruction problem. Journal of Optimization
Theory and Applications, 100.
Craven, B.D. and Islam, S.M.N. (2001). Computing optimal control on Matlab - The
SCOM package and economic growth models. Optimization and Related Topics, 61-70,
Kluwer Academic Publishers, Amsterdam.
Cuthbertson, K. (1997). Quantitative Financial Economics, Stocks, Bonds and Foreign
Exchange. John Wiley and Sons Ltd., West Sussex.
Dadebo, S.A., McCauley, K.B. and McLellan, P.J. (1998). On the computation of optimal
singular and bang-bang controls. Optimal Control Applications and Methods, 19:287-297.
Dasgupta, S. and Titman, S. (1998). Pricing strategy and financial policy. The Review of
Financial Studies, 11:705-737.
Davis, B.E. and Elzinga, D. Jack. (1970). The solution of an optimal control problem in
financial modeling. Operations Research, 19:1419-1433.
Davis, B.E. (1970). Investment and rate of return for the regulated firm. The Bell Journal
of Economics and Management Science, 1:245-270.
Dolezal, J. (1981). On the solution of optimal control problems involving parameters and
general boundary conditions, Kybernetika, 17:71-81.
Eatwell, J., Milgate, M. and Nuemann, P. (1989). The New Palgrave Dictionary of Fi-
nance. MacMillan Press, London.
Elton, E. and Gruber, M. (1975). Finance as a Dynamic Process. Prentice-Hall, Engle-
wood Cliffs, NJ.
Evans, L.C. and Friedman, A. (1979). Optimal stochastic switching and the Dirichlet prob-
lem for the bellman equation, Trans, Amer. Math. Soc., 253:365-389.
Fletcher, R. (1980). Practical Methods of Optimization. Vol.1. Unconstrained Optimiza-
tion. Wiley-Interscience Publication, New York.
Fleming, W.H. and Rishel, R.W. (1975). Deterministic and Stochastic Optimal Control.
Application of Mathematics, No. 1. Springer-Verlag, Berlin-New York.
Fröberg, Carl-Erick. (1965). Introduction to Numerical Analysis. Addison-Wesley Pub-
lishing Company, Reading, Massachusetts.
Garrad, W.L. and Jordan, J.M. (1977). Design of nonlinear automatic flight control sys-
tem. Automatica, 19:497-505.
Giannessi, F. (1996). Private Communication. University of Pisa, Pisa, Italy.

REFERENCES
195
[33]
[34]
[35]
[36]
[37]
[38]
[39]
[40]
[41]
[42]
[43]
[44]
[45]
[46]
[47]
[48]
Goh, G.J. and Teo, K.L. (1987). MISER, an Optimal Control Software. Department of
Industrial and Systems Engineering, National University of Singapore.
Hasdorff.L. (1976). Gradient Optimization and Nonlinear Control. John Wiley and Sons,
New York.
Isaacs, R. (1965). Differential Games. John Wiley, New York.
Islam, S.M.N. (2001). Optimal Growth Economics: An Investigation of the Contempo-
rary Issues, and Sustainability Implications, Contributions to Economic Analysis. North
Holland Publishing, Amsterdam.
Islam, S. M. N. and Craven B.D. (2001). Computation of non-Linear continuous optimal
growth models: Experiments with Optimal control algorithms and computer programs,
Economic Modeling. 18:551-586.
Islam, S. M. N. and Craven B.D. (2002). Dynamic optimization models in finance: some
extensions to the framework, models, and computation. Research Monograph, CSES, Vic-
toria University, Melbourne.
Islam, S. M. N. and Oh, K.B. (2003). Applied Financial Econometrics in E-Commerce,
Series Contributions to Economic Analysis. North Holland Publishing, Amsterdam.
Jennings, L.S., Fisher, M.E., Teo, K.L. and Goh, G.J. (1991). MISER3.0: Solving optimal
control problems - an update. Advances in Engineering Software, 13.
Jennings, L.S. and Teo, K.L. (1990). A numerical algorithm for constrained optimal con-
trol problem with applications to harvesting. Dynamics of Complex Interconnected Biolog-
ical Systems, 218-234.
Jennings, L.S. and Teo, K.L. (1991). A computational algorithm for functional inequality
constrained optimization problems. Automatica, 26:371-376.
Kaya, C.Y. and Noakes, J.L. (1994). A global control law with implications in time op-
timal control. In Proceedings of the 33rd IEEE Conference on Decision and Control, pp.
3823-3824, Orlando, Florida.
Kaya, C.Y. and Noakes, J.L. (1996). Computations and time-optimal controls. Optimal
Control Applications and Methods, 17:171-185.
Kaya, C.Y. and Noakes, J.L. (1997). Geodesics and an optimal control algorithm. In Pro-
ceedings of the 36th IEEE, pp. 4918-4919, San Diego, California.
Kaya, C.Y. and Noakes, J.L. (1998). The leap-frog algorithm and optimal control: Back-
ground and demonstration. In Proceedings of International Conference on Optimization
Techniques and Applications (ICOTA ’98), pp. 835-842, Perth, Australia.
Kaya, C.Y. and Noakes, J.L. (1998). The leap-frog algorithm and optimal control: theoret-
ical aspects. In Proceedings of International Conference on Optimization Techniques and
Applications (ICOTA ’98), pp. 843-850, Perth, Australia.
Kendrick, D.A. and Taylor, L. (1971). Numerical Methods and Nonlinear Optimizing
Models for Economic Planning. Studies in Development Planning, Cambridge, Mass.

196
OPTIMAL CONTROL MODELS IN FINANCE
[49]
[50]
[51]
[52]
[53]
[54]
[55]
[56]
[57]
[58]
[59]
[60]
[61]
[62]
[63]
[64]
[65]
Krouse, C.G. and Lee, W.Y. (1973). Optimal equity financing of the corporation. Journal
of Financial and Quantitative Analysis, 8:539-563.
Lee, E.B. and Markus, L. (1967). Foundations of Optimal Control Theory. John Wiley and
Sons, New York.
Lee, H.W.J., Teo, K.L., Rehbock, V. and Jennings, L.S. (1997). Control parameterization
enhancing technique for time optimal control problems. Dynamic Systems and Applica-
tions, 6:243-262.
Leonard, D. and Long, N.V. (1992). Optimal Control Theory and Static Optimization in
Economics. Cambridge University Press, Melbourne.
Li, X. and Yong, J. (1995). Optimal Control Theory for Infinite Dimensional Systems.
Birkauser Boston, Boston.
Liu, L. and Teo, K.L. (2000). Computational Method For a Class of Optimal Switching
Control Problems. Progress in Optimization, 221-237.
Matula, J. (1987). An extreme problem. Journal of Australian Mathematical Society,
28:376-392.
Miele, J. (1975). Recent advances in gradient algorithms for optimal control problems.
Journal of Optimization Theory and Applications, 17:361-430.
Miele, A. and Wang, T. (1986). Primal-dual properties of sequential gradient-restoration
algorithms for optimal control problems, Part 1, Basic Problem. Integral Methods in Sci-
ence and Engineering, 577-607.
Miele, A. and Wang, T. (1986). Primal-dual properties of sequential gradient-restoration
algorithms for optimal control problems, Part 2, General Problem. Journal of Mathemati-
cal Analysis and Applications, 119:21-54.
Modigliani, F. and Miller, M.H. (1958). The cost of capital, corporation finance, and the
theory of investment. American Economic Review, 48:261-97.
Modigliani, F. and Miller, M.H. (1963). Corporation income taxes and the cost of capital.
American Economic Review, 53:433-43.
Morellec, E. (2001). Asset liquidity, capital structure, and secured debt. Journal of Finan-
cial Economics, 61:173-206.
Mundaca, G. and Øksendal, B. (1998). Optimal stochastic intervention control with ap-
plication to the exchange rate. J.Math. Economy, 29:225-243.
Nerlove, M. and Arrow, K.J. (1962). Optimal advertising policy under dynamic condi-
tions. Economica, 39:129-142.
Noakes, J. Lyle (1997). A global algorithm for geodesics. Journal of the Australian Math-
ematical Society, Series A, 37-50.
Nordecai Avriel (1976). Nonlinear Programming Analysis and Methods. Technion-Israel
Institute of Technology, Haifa, Israel.

REFERENCES
197
[66]
[67]
[68]
[69]
[70]
[71]
[72]
[73]
[74]
[75]
[76]
[77]
[78]
[79]
[80]
[81]
[82]
Noussair, E.S. (1977). On the existence of piecewise continuous optimal controls. Journal
of Australia Mathematical Society, Series B, 20:31-37.
Oh, K.B. and Islam, S.M.N. (2001). Empirical Finance of E-Commerce: A Quantitative
Study of the Financial Issues of the Knowledge Economy. CSES Research Monograph,
Victoria University, Melbourne.
Perthame, B. (1984). Continuous and impulse control of diffusion process in 
Non-
linear Anal, 8:1227-1239.
Pontryagin, L.S., Boltyanskii, V.G., Gamkrelidze, R.V. and Mishchenko, E.F. (1962). The
Mathematical Theory of Optimal Processes. John Wiley, New York.
Powell, M.J.D. Private communication.
Redbock, V., Teo, K.L. and Jennings, L.S. (1994). Suboptimal feedback control for a
class of nonlinear systems using spline interpolation. Discrete and Continuous Dynamical
Systems, 1:223-236.
Redbock V., Teo, K.L., Jennings, L.S. and lEE, H.W.J. (1999). A survey of the control
parameterization and control parameterization enhancing methods for constrained optimal
control problems. Progress in Optimization, 247-275.
Richard, R. Lumley and Mihall Zervos (2001). A model for investments in the material
resource industry with switching costs. Mathematics of Operations Research, 26:637-653.
Rockafellar, R.T. (1974). Lagrange multiplier functions and duality in non-convex pro-
gramming. SIAM J. Control, 12:268-287.
Sakama, Y. and Shindo, Y. (1980). On global convergence of an algorithm for optimal
control. IEEE Transaction Automatic Control, AC-25:1149-1153.
Sakama, Y. (1981). On local convergence of an algorithm for optimal control. Numerical
Functional Analysis and Optimization, 3:301-319.
Schwartz, A., Polak, E. and Chen Y. (1997). Recursive Integration Optimal Trajectory
Solver 95. A MATLAB TOOLBOX for solving Optimal control problems, Version 1.0,
Stanford University, California.
Sethi, S.P. (1978). Optimal equity financing model of Krouse and Lee: corrections and
extensions. Journal of Financial and Quantitative Analysis, 13:487-505.
Sethi, S.P. and Thompson, G.L. (2000). Optimal Control Theory. Kluwer Academic Pub-
lishers, Amsterdam.
Sengupta, J.K. and Fanchon, P. (1997). Control Theory Methods in Economics. Kluwer
Academic Publishers, Boston.
Tapiero, C.S. (1998). Applied Stochastic Models and Control for Insurance and Finance.
Kluwer Academic Publishers, London.
Teo, K.L. (1992). A computational approach to an optimal control problem with a cost on
changing control. Optimization, 1:397-413.

198
OPTIMAL CONTROL MODELS IN FINANCE
[83]
[84]
[85]
[86]
[87]
[88]
[89]
Teo, K.L. and Goh, C.J. (1988). On constrained optimization problems with nonsmooth
cost functionals. Applied Mathematics and Optimization, 18:181-190.
Teo, K.L., Goh, G.J. and Wong, K.H. (1991). A Unified Computational Approach to Op-
timal Control Problems. Longman Scientific and Technical, London.
Teo, K.L. and Jennings, G.J. (1991). Optimal control with a cost on changing control.
Journal of Optimization Theory and Applications, 68:335-357.
Vidale, M.L. and Wolfe, H.B. (1957). An operations research study of sales response to
advertising. Operations Research, 5:370-81.
Yong, J. (1989). Systems governed by ordinary differential equations with continuous,
switching and impulse controls. Appl. Math.Optim., 20:223-235.
Yong, J. (1991). Existence of the value for a differential game with switching strategies in
a Banach space. System Sci. Math. Sci., 4:321-340.
Ziemba, W.T. and Vickson, R.G. (1975). Stochastic Optimization Models in Finance. Aca-
demic Press, New York.

Index
admissible controllers, 95
aggregate dynamic financial system, 40
analytical solution, xv, 1, 91, 104–108, 143
approximate solution methods, 10
approximation methods, 11
approximation problem, 12
associated problems, 6, 7
augmented Lagrangian algorithm, 11, 15, 98
bang-bang control, 1, 4, 7, 16, 17, 19, 26, 41,
47, 97, 101
bang-bang optimal control problems, 26, 27,
143
bang-bang optimal control solution, 40
big subintervals, 42–44, 101
boundary conditions, 6, 97
business cycle instabilities, 39
candidate selection systems, 13
cash management, 4
co-efficient, 7, 13
co-state function, 6, 9, 15
computational algorithms, 1, 10, 14, 20, 21, 101
computational experiments, xvii, 36, 89
computational methods, 1, 11, 19, 24, 27, 40,
97, 100, 101, 141
CONMIN, 11
constant-input arcs, 16
constr, 15, 20, 25–28, 44, 45, 102, 141, 189
continuous optimal control models, 10
control, 2, 12–14, 20, 22, 26, 27, 30, 31, 33, 36,
37, 39–47, 54, 61, 67, 86, 88, 103–
105, 111–113, 115–122, 142
control discretization approach, 10
control function, xvi, 9, 14, 18, 19, 21, 23, 39,
142, 189
control mechanism, 89
control parameterization knot points, 16
control parameterization technique, 11, 12
control policy, 10, 29, 46, 54, 61, 67, 88, 101,
103, 109
control restraint, 95
control strategy, 16
control system, 11, 17
control variables, 93, 139
convergence properties, 12
convex function, 96
cost analysis, 10
cost function, 2, 11–13, 19, 27, 28, 30, 35, 36,
41, 45, 91, 142
cost of changing control, 8, 19, 20, 27, 30, 36,
41, 86, 89, 142
CPET, 16, 19
CSTVA, 19, 139, 141
damped oscillator, 12, 39, 40, 54, 143
damping function, 89
DE solver, 15, 21, 22, 26
decision variables, 13
deterministic, 1, 4, 18
deterministic optimization, 2
difference of optimal control policy sequences,
10
discount factor, 24
discrete optimal control models, 10
discretization augment, 18
division of the time intervals, 10
Dodgem problem, 12
dynamic behavior, 40
dynamic equation, 7, 18, 23, 28, 29, 102, 189
dynamic financial system, 1, 39, 40, 142
dynamic optimization models, 1, 3
dynamic programming, 10, 11
economic models, 14, 15
end-point constraint, 98
end-points, 10, 42, 43
financial decision making, 3, 30, 39, 41

200
OPTIMAL CONTROL MODELS IN FINANCE
financial engineering, 4
financial market, 89, 92
financial optimal control models, 2, 8, 18, 22,
139, 141–143
financial optimization models, 2, 4
financial planning, 4, 142
financial sector, 39, 89
financial system, 1, 39–41, 43, 54, 88, 102, 111,
115, 139, 142
finite difference approximation, 15
finite difference method, 141
finite horizon models, 4
Fish problem, 12
fishery harvesting model, 12
fitting functional, 21, 30–33, 35, 48, 54, 109, 110,
113–115, 118–122, 139
fixed-time control, 3
fixed-time optimal control problem, 11, 23, 25
fixed-time period, 19
forcing function, 41, 114
global minimum, 5, 10, 18, 54, 116, 122
gradient search methods, 10, 11
grid-points, 11, 14, 19, 26, 29, 31, 45, 102
Hamiltonian, 4, 6, 9, 15, 96
implicit constraints, 14, 15
indifference principle, 8–10
infinite horizon models, 4
initial and terminal conditions, 4
inter-temporal time preference, 3
interpolation, 11
investment, 4, 30, 36, 41, 89, 91–93, 102, 110,
113, 141–143
investment allocation, 91, 143
investment model, 16
Karush-Kuhn-Tucker, 5
Lagrange multipliers, 5, 98, 99
Leap-Frog Algorithm, 17
linear interpolation, 11, 15, 29, 46, 103, 187
local minimum, xvii, 4, 10, 116, 118, 122
low-pass filter, 11
mathematical programming, 4, 94
mathematical structure, 1, 4
MATLAB, xvi, xvii, 11, 12, 14, 15, 18, 20, 25–
28,44,45, 101, 102, 141, 189
Maximum Principle, 2, 4, 94, 96
maximum principle, 8–10
minimization problem, 2, 4–6, 18, 27, 30, 44,
98, 102
MISER, 11, 12, 14, 17–19
mixed discrete and continuous optimal control
problem, 13
multi-state functions, 40
necessary conditions, 6, 17, 96
non-linear complex dynamic behavior, 89
non-linear control system, 17
non-linear transformation, 20, 21
non-smooth functions, 12
nqq computer package, 41
nqq function, 20
obstacle, 18
OCIM, 11, 12, 14, 18
ODE, 15, 19
operations research, 2
optimal consumption, 4
optimal control modeling, 1, 142
optimal control problems, 1, 2, 4, 7, 8, 10–15,
17, 20, 23, 25
optimal control theory, 1
optimal controller, 95
optimal corporate finance, 4, 92
optimal investment planning, 4, 20, 36, 89, 141
optimal investment strategy, 89
optimal path, 18
optimal portfolio choice, 4
optimization criteria, 3
oscillator problem, 12, 36, 37, 40, 44–46, 120,
124, 142
oscillatory behavior, 39
oscillatory dynamics, 39, 89
oscillatory financial model, 39
penalty constant, 13
penalty term, 14, 91, 98, 99, 142
piece-wise continuous function, 2
piecewise-linear transformation, 20, 21, 25, 29,
141
planning horizon, 2, 6, 31, 94, 98, 101
Pontryagin theorem, 2, 6, 8, 9, 18
Pontryagin’s Maximum Principle, 17
Quadratic Programming sub-problem, 25
quasi-Newton updating method, 11, 25
real-world problems, 1, 2
restricted domain, 18
reverse-time construction technique, 94
RIOTS, 11, 12, 18, 19
risk management, 4
scaled time, 22, 28–30, 42, 43, 45–7, 100, 102,
103
SCOM, 12, 21, 25
second order differential equation, 20, 39, 40,
45, 46, 141
sequential quadratic programming method, SQP,
20, 25, 141
single-input non-linear system, 16

INDEX
201
singular arc, 7, 16, 26, 41, 97
stabilization mechanism, 39
stable optimal investment planning, 89
state variables, 93, 97, 111
STC, 16, 17, 19
step function, 3, 10, 11, 14, 15, 18–21, 25, 26,
40, 120, 141, 142, 189
stochastic, 1, 4, 16, 18
stochastic finance, 4
stochastic financial optimal control model, 18
STV algorithm, 19, 20, 141, 143
switching control, 3, 27, 41, 86, 89
switching time computation method, 16
switching time variable method, 141
switching times, 13, 17, 19, 26, 27, 29, 31, 32,
35, 36, 39, 43, 46, 47, 67, 89
system parameters, 13, 44
terminal constraint transformation, 98
terminal manifold, 94
time optimal control problems, 16
time scale, 23, 39, 41, 42, 99
time subdivision, 40, 108
time transformation, 21, 101
time-optimal control, 3
time-optimal control problems, 23
TOBC, 17
TPBVP, 17
two-point boundary-value problem, 17
valuation, 4

