No
Foreword by Jeffrey Zeldman
Just Enough
Research
Erika Hall
Brief books for people who make websites
9
www.allitebooks.com

More from the A Book Apart Library
HTML5 for Web Designers
Jeremy Keith
CSS3 for Web Designers
Dan Cederholm
The Elements of Content Strategy
Erin Kissane
Responsive Web Design
Ethan Marcotte
Designing for Emotion
Aarron Walter
Mobile First
Luke Wroblewski
Design Is a Job
Mike Monteiro
Content Strategy for Mobile
Karen McGrane
Sass for Web Designers
Dan Cederholm
On Web Typography
Jason Santa Maria
Responsible Responsive Design
Scott Jehl
www.allitebooks.com

Copyright © 2013 Erika Hall
All rights reserved
Publisher: Jeffrey Zeldman
Creative Director: Jason Santa Maria
Editor-in-Chief: Mandy Brown
Editor: Rose Fox
Copyeditor: Krista Stevens
Proofreader: Tina Lee
Indexer: Sally Kerrigan
Compositor: Rob Weychert
Ebook Production: Nellie McKesson
ISBN 978-1-9375571-1-9
A Book Apart
New York, New York
http://abookapart.com
10 9 8 7 6 5 4 3 2 1
www.allitebooks.com

table of contents
chapter 1
Enough Is Enough
1
chapter 2
The Basics
10
chapter 3
The Process
37
chapter 4
Organizational Research
56
chapter 5
User Research
76
chapter 6
Competitive Research
chapter 7
Evaluative Research
chapter 8
Analysis and Models
94
102
115
chapter 9
Quantitative Research
133
Conclusion
143
Resources
144
References
Acknowledgements
149
151
Index
153
www.allitebooks.com

www.allitebooks.com

Foreword
In the digital age, creating meaningful design requires us to 
understand people who are different, anticipate what they will 
want to do, and provide them with the tools they need, exactly 
when they need them. But how can we do that? We are not 
saints, gods, or clairvoyants. We can only understand others 
through research, and that is the subject of this shiny little book.
How is this book different from others? In a perfect world, 
research budgets are sufficient, ample research time is provided 
in advance of project definition, and accuracy is assured through 
shared models and processes. In that perfect world, clients value 
research. They reward designers who ask difficult questions, and 
prioritize user needs over marketing directives, internal politics, 
or personal peccadillos.
But that’s not the world we work in. In our world, budgets are 
constrained, schedules are absurd, there is little internal agree-
ment about what constitutes worthwhile research, and “I don’t 
like yellow” is considered feedback. Or we may work for an or-
ganization that claims to want information about the customer, 
but actually prizes computer algorithms above human insight.
Fortunately, Erika Hall works in our world, and has devised 
a plan for us.
For research to help us, we need methods that deliver real 
benefits, fast. Armed with Just Enough Research, you’ll be able 
to quickly ascertain key facts and gather important insights, 
enabling you to design the right experience for the real, liv-
ing people who actually use your website. Just as importantly, 
you’ll be able to head off or win the internal debates that so 
often send promising projects plummeting to perdition. Best 
of all, this book will help you convert antagonists into true col-
laborative partners. Your team will never be the same again. It 
will be better.
But don’t take my word for it. Do your own research—start-
ing at Chapter 1.
—Jeffrey Zeldman
www.allitebooks.com

www.allitebooks.com

 	
Enough Is Enough	 1	
Enough 
Is Enough1
Throughout 2001, the internet buzzed with rumors of 
“Ginger” or simply “it,” the revolutionary future of personal 
transportation. It would change everything. Jeff Bezos was into 
it. Bono was into it. Tens of millions of dollars in venture invest-
ment had been poured into it.
Finally, in December of that year, it arrived—and the Segway 
debuted with a counterrevolutionary thud.
These days, Segways seldom appear outside of warehouse 
corridors except as a novelty, miracles of engineering convey-
ing awkward gaggles of tourists as they hum serenely by. It’s as 
though the finest minds of the late 20th century envisioned a 
brave new world ushered in by amphibious duck tour.
Transportation is a complicated system with very strong con-
ventions. The more industrialized the society, the more people 
traveling faster, the stronger the conventions. Otherwise, more 
collisions and chaos. There are currently four fundamental per-
sonal ground transportation options: walking (or wheelchair), 
bicycle, motorbike, and automobile.
www.allitebooks.com

	
2 	 Just Enough Research
There are two basic paths: the sidewalk and the street. 
Pedestrians and individuals in wheelchairs get to use the side-
walk. Vehicles, including bicycles, go in the street. A trans-
portation journey has a beginning and an end. If you travel by  
personal vehicle, you have to store your vehicle at each end, 
either inside or outside. Bikes go on racks outside or wherever 
they fit inside. Cars and motorbikes go into authorized zones 
on the street, parking lots, or garages. Reliable transportation is 
essential to daily life, as a flat tire will quickly confirm. 
No matter what our personal transportation preferences, 
we all share the rules and conventions of our locales, and most  
people share very common needs. People need to get to school 
or work on time. They need to carry groceries or children. They 
need to travel through sunshine and rain.
This established system is used with relatively small region-
al variations by billions of people around the world. But the 
Segway didn’t fit. It was slower than a car and at least ten times 
the price of a decent commuter bicycle. Even those who could 
afford it weren’t sure what to do with it. You couldn’t take the 
kids to school on it. You couldn’t commute twenty miles on it. 
You couldn’t pack the family into it or make out in its backseat.
Critics jumped on the dorky aspect and the high price, but 
those weren’t the dooming factors. Early adopters often put up 
with cost and ridicule for innovations that meet real needs. But 
no one needs a Segway.
What does the failure of the Segway have to teach de-
sign research? That where humans are concerned, context is 
everything. 
Enough!
“A little learning is a dangerous thing.”
—Alexander Pope
You like a little danger, don’t you? 
To design, to code, to write is to embrace danger, to plunge 
ahead into the unknown, making new things out of constantly 
changing materials, exposing yourself to criticism and failure 
every single day. It’s like being a sand painter in a windstorm, 
www.allitebooks.com

 	
Enough Is Enough	 3	
except Buddhist monks probably don’t have to figure out how 
to fit IAB ad units into their mandalas. 
You work one pixel or line or phrase at a time, and every strat-
egy shift or miscalculation leads to rewriting and reworking and 
revising. Yet you’re shadowed by the idea that the best designers 
and developers and writers are self-motivated, self-inspiring, 
hermetically sealed units of mastery. The myth of the creative 
genius makes it very difficult to say “I don’t know.”
You may be on a team that sees enthusiasm as a substitute 
for knowledge, high-fiving your way along a primrose path of 
untested assumptions. (Some people call that religion.) Or maybe 
you are driven before the whip, no time to stop or even breathe. 
You might not be going the right way, but who cares because 
you need to get there fast. Or you might be in an organization 
where everything is done in response to marketing, sales, and 
the competition. Every day there’s a new trend or buzzword to 
pay attention to. 
In these settings, research can be a very scary word. It sounds 
like money you don’t have and time you can’t spare, like some 
egghead is gathering wool in a lab or library when you could 
be moving forward and building something. Scariest of all, it 
means admitting you don’t have all the answers. You may have 
a vague idea that research is a good thing, but the benefits are 
fuzzy while the costs are all too clear.
This book is for you. 
Research is a tool—a periscope offering you a better view of 
your surroundings. It can be very powerful if applied thought-
fully. Rather than piling on the costs, research can save you and 
the rest of your team a ton of time and effort. 
You can use the techniques and methods I’ll describe to:
• Determine whether you’re solving the right problem. 
• Figure out who in an organization is likely to tank your project.
• Discover your best competitive advantages. 
• Learn how to convince your customers to care about the 
same things you do.
• Identify small changes with a huge potential influence.
• See where your own blind spots and biases are preventing 
you from doing your best work.
www.allitebooks.com

	
4 	 Just Enough Research
By the end of the book, you will possess just enough knowl-
edge to be very dangerous indeed. Because once you start getting 
answers, you’ll keep asking more questions. And that skeptical 
mind-set is more valuable than any specific methodology.
Risk and innovation
A couple of years ago, one of the world’s largest insurance com-
panies hired my company, Mule Design, to identify new prod-
uct and service opportunities enabled by emerging personal 
technologies. This is fun stuff. Thinky. Lots of meaty problems 
to solve with our minds. We said, “Great, can we talk to some 
of your salespeople and agents to better understand how you 
operate and serve customers now?”
They said, “No.”
The reason? “We don’t want the way we do things now to 
inhibit your creativity. We want blue-sky thinking!”
Now, I like to think that we have a clever group of people. 
We stay on top of technological advances. We have good imagi-
nations and read comic books and speculative fiction. We have 
well-considered opinions about monorails, vat-grown meats, 
and how to defend a space station from a zombie attack. (Lure 
zombies into the air lock with vat-grown meat while escaping 
on a monorail.)
None of this tells us where the insurance business might be 
in ten years. And while we enjoy speculating about the future, 
we felt irresponsible taking our client’s money for guessing. 
We ended up doing a lot of secondary research to learn their 
business, but reading reports and articles is more work and less 
fun than talking to live humans and hearing about their specific 
situations. And we didn’t get any information about our client’s 
business, which means that while our work was solid, it could 
have been better.
Businesses and designers are keen on innovation, as well they 
should be. But the better you know the current state of things 
and why they’re like that, the better you will be positioned to 
innovate.

 	
Enough Is Enough	 5	
What research is
Research is simply systematic inquiry. You want to know more 
about a particular topic, so you go through a process to increase 
your knowledge. The type of process depends on who you are 
and what you need to know.
A lot of personal research these days begins with a Google  
query (“Who is Mihaly Csikszentmihalyi?”) and ends on a 
Wikipedia page. (“Oh, so that’s how you pronounce it.”) Finding 
information is relatively easy. The knowledge already exists. You 
just have to find a trustworthy source for it. Assessing credibility 
is the hard part. (“Are all polar bears really left-handed?”)
Pure research is carried out to create new human knowledge, 
whether to uncover new facts or fundamental principles. The re-
searcher or investigator wants to advance a particular field, such 
as neuroscience, by answering a particular question, such as 
“Why do humans sleep?” Pure research is based on observation 
or experimentation. The results are published in peer-reviewed 
journals. This is science. Rigorous standards and methodologies 
exist to preserve objectivity and ensure the credibility of conclu-
sions. (Things get squishy when corporations fund ostensibly 
pure research, as they frequently do.)
Applied research borrows ideas and techniques from pure 
research to serve a specific real-world goal, such as creating a 
supersoldier or improving the quality of hospital care or finding 
new ways to market pork-flavored soda. While ethics are just 
as important, methods can be more relaxed. Maybe this means 
changing up the questions you ask partway through a study, or 
making the most of an imperfect sample group because you’re 
tight on time. The research is successful to the extent that it 
contributes to the stated goal.  As with pure research, sometimes 
you accidentally discover something valuable you weren’t even 
looking for, and that’s a fantastic bonus. 
And then there is design research.
Design research is a broad term with a long history. In the 
1960s, design research referred to the study of design itself, 
its purpose and processes. This is still how the term is used in 
academia today. There are various institutes of design research 

	
6 	 Just Enough Research
around the world, mostly involved in large existential or small 
theoretical questions couched in highly specialized academic 
language. If you’re interested in transformative concepts of 
spatial intelligence or the poetics of the sustainable kitchen, 
this field is for you. 
However, when practicing industrial or interactive design-
ers refer to design research, they typically mean research that 
is integral to the design work itself—inquiries that are part of 
designing, not about design. This research focuses largely on 
understanding the people for whom we’re designing, often re-
ferred to by the dehumanizing but instrumental term end users. 
Research is a core part of user-centered design. 
Jane Fulton Suri, creative director at the renowned in-
ternational design consultancy IDEO, offers this elegantly 
phrased statement of purpose in her 2008 article “Informing 
Our Intuition: Design Research for Radical Innovation” (http://
bkaprt.com/jer/1/):
Design research both inspires imagination and informs intuition 
through a variety of methods with related intents: to expose 
patterns underlying the rich reality of people’s behaviors and 
experiences, to explore reactions to probes and prototypes, and 
to shed light on the unknown through iterative hypothesis and 
experiment.
For a design to be successful, it must serve the needs and 
desires of actual humans. Strangely, simply being human is 
insufficient for understanding most of our fellows. That’s why 
Suri’s description could apply equally to the research extrater-
restrials conduct on unsuspecting abductees (including their 
reactions to probes!). Design research requires us to approach 
familiar people and things as though they are unknown to us 
to see them clearly. We need to peel away our assumptions like 
a gray alien shedding its encounter suit. 
Imagine you’re working with a well-established science and 
technology museum. Let’s call it the Fantastic Science Center. 
And this museum just received a grant for the vague purpose of 
improving its use of the web, which could mean anything from 

 	
Enough Is Enough	 7	
designing a new brochure website to creating interactive science 
education activities for remote students to developing mobile 
apps that complement the physical exhibits for visitors with 
smartphones. How do you prioritize alternatives and ensure the 
project succeeds? Throughout this book we’ll look at ways you 
can employ research techniques to ensure the museum (or any 
organization) makes the best use of your time and its resources.
Asking your own questions and knowing how to find the 
answers is a critical part of being a designer. If you rely on other 
people to set the agenda for inquiry, you might end up caught 
between fuzzy focus groups and an algorithm that scientifically 
chooses a drop shadow from among forty-one shades of blue. 
Discovering how and why people behave as they do and what 
opportunities that presents for your business or organization 
will open the way to more innovative and appropriate design 
solutions than asking how they feel or merely tweaking your 
current design based on analytics. 
You will find that when you ask the hard questions, your job 
gets much easier. You will have stronger arguments, clarity of 
purpose, and the freedom to innovate that only comes with truly 
knowing your constraints. 
What research is not
Research is not asking people what they like
As you start interviewing people involved in business and design 
decisions, you might hear them refer to what they do or don’t 
like. “Like” is not a part of the critical thinker’s vocabulary. On 
some level, we all want the things we do to be liked (particu-
larly on Facebook), so it’s easy to treat likability as a leading 
success indicator. But the concept of “liking” is as subjective 
as it is empty. It is a superficial and self-reported mental state 
unmoored from any particular behavior. This means you can’t 
get any useful insights from any given individual reporting that 
they like or hate a particular thing. I like horses, but I’m not go-
ing to buy any online.
Quash all liking, and hating too. Plenty of people habitually 
engage in activities they claim to hate.

	
8 	 Just Enough Research
Research is not a political tool
Don’t let your methods be guided by a desire to appear smart 
or conform to anyone else’s picture of research. Some clients 
will argue for doing interviews in a usability lab even when it 
isn’t appropriate, just because it feels research-y. You’ll need to 
explain to them why interviews with method and purpose are 
more valuable than having a social conversation with a random 
person—and why it really doesn’t matter where you do them, 
as long as they’re done right.
In the best case, you can use the real-world facts and insights 
you gather to bring an external perspective to internal debates 
and power struggles that threaten your ability to get good work 
done. At the very least, it’s up to everyone participating in the 
research to hold the line and not let interpersonal dynamics 
influence your findings. Watch out for those who would use 
information gathering for political purposes or as a popularity 
contest.
Applied research is not science
In addition to executives who prefer the authoritative appear-
ance of experimentation, you may run into sample-size queens 
who dispute the validity or utility of applied qualitative research. 
These people are often pollsters and marketers who run a lot of 
surveys. Avoid arguments about statistical significance; you will 
not win. Instead, keep the focus on gathering useful insights.
Why this book
There are dozens of books about applied qualitative research and 
related techniques out there. The good ones are many hundreds 
of pages long. Most were written by professional researchers 
for professional researchers. Very thorough individuals, profes-
sional researchers. Most of them are quite charming at parties. 
You, however, are not a professional researcher, which means 
you need a book written for you—a book that covers a lot of use-
ful ground in few words and makes some of the basic concepts 
and techniques more accessible. That’s this book.

 	
Enough Is Enough	 9	
People who make design decisions at any level benefit from 
asking more and better questions. Many of them also need a little 
guidance on what to do with the answers. Within are ideas and 
techniques for you to use in making your projects and design 
solutions better and more successful. It is a sampler rather than 
a survey, and a biased sampler in that I have included only the 
topics and approaches I personally have found most useful in 
my design career. Most of these are what we do at Mule in the 
beginning of a client project.
It is also a pointed book, and that point will help you cut 
through the laziness, arrogance, and politics that prevent more 
research.
Research is just another name for critical thinking. With a 
little encouragement, everyone on your team can open their 
minds and embrace it. And together, we can fix it so no one 
contemplating a web project ever mentions focus groups again.

	
10 	 Just Enough Research
2The Basics
Research is a discipline with many applications. This chapter 
introduces the core practices and fundamental ideas and tech-
niques you will use repeatedly in many situations. We’ll cover 
who should do research, different types of research and when 
to use them, and roles within each set of research activities. 
To help counter any skepticism about the business value of 
research, we’ll also review some common objections and how 
to overcome them.
Who should do research? Everyone!
Ideally, everyone who is on the design team should also partici-
pate in the research.
If you are a sole practitioner, well, that’s easy. You will have 
excellent direct experience and can tailor the process and docu-
mentation to suit your needs. (Just be particularly mindful of 
your personal biases.) If you work with other people, involve 

 	
The Basics	 11	
them from the start. Presenting them with the world’s most 
stunning report will give them a terrific reference document, 
but it’s far less likely to inspire them to approach their work 
differently. (Do you disagree? Perhaps you are an economist.) 
When you find yourself making a case for a skeuomorphic, 
bronze astrolabe interface based on the research you’ve all  
done together, you’ll be able to spend less time explaining the 
rationale and more time focused on the merit of the conclusion. 
“As you saw in the interviews, we found that our target group 
of amateur astronomers exclusively uses nineteenth-century 
equipment for stargazing....”
People who have a hand in collecting the insights will look 
for opportunities to apply them. Being the smart person is more 
fun than obeying the smart person, which is how the researcher/
designer dynamic can feel if designers are merely the recipients 
of the analysis. 
At my first design agency job, the research director was a 
charming PhD anthropologist with a penchant for vivid, striped 
shirts. Despite being fresh out of academia, he was much more 
of a scout troop leader than a fusty professor. Interviews and us-
ability tests were scavenger hunts and mysteries with real-world 
implications. Unlike heinous, contrived team-building activi-
ties—rope courses and trust falls—doing research together actu-
ally did make our team more collaborative. We were learning 
interesting, valuable new things, and everyone had something 
different to contribute. The content strategist would notice the 
vocabulary real people used and the developer had good ques-
tions about personal technology habits. The visual designer was 
just really into motorcycles, and that helped sometimes too. 
Someone needs to be the research lead—the person who 
keeps everyone on track and on protocol and takes ultimate 
responsibility for the quality of the work. If you take this on it 
might mean that you’re the primary researcher, gathering the 
data for others to help you analyze, or you could have more of an 
ensemble approach. The most important thing is that everyone 
involved knows the purpose or goal of the research, their role, 
and the process.

	
12 	 Just Enough Research
Find your purpose
One of our maxims at Mule is that every design project ulti-
mately amounts to a series of decisions. What are the most 
important features? What is the best navigation scheme? How 
big should the logo be? 
For any given project, we include only the research activities 
that support the specific decisions we anticipate. If the client has 
only identified an audience and wants to explore ways to better 
serve them (“What can we offer of value to high school science 
teachers?”), our research will be more open-ended than if the 
design problem is already well defined (“How can we get high 
school science teachers to download and use our lesson plans?”).
This has been playing out on the fields of “mobile first.” Many 
organizations are seeing a significant increase in their mobile 
traffic. They know they have to do something different for users 
on mobile devices, but aren’t quite sure what. So, they’re look-
ing for ideas, or should be. It’s too soon to jump to fine-tuning 
solutions. For example, should the Fantastic Science Center, 
our fictional museum client, rewrite all of the exhibit descrip-
tions for a mobile audience, or build a native event reservation 
app, or encourage school group students to post exhibit photos 
to Facebook from their phones? Organizational research will 
tell you which interactions benefit the museum most, while 
user research will indicate which are most plausible and the 
circumstances under which they will take place. Maybe you 
will discover that school district policy prohibits students from 
using their phones on field trips, but parents are likely to take 
photos of family visits to share with their Facebook friends. 
In that case, parents are the ones to target with a social media 
marketing campaign.
There are many, many ways of classifying research, depend-
ing on who is doing the classification. Researchers are always 
thinking up more classifications. Academic classifications may 
be interesting in the abstract, but we care about utility, what 
helps get the job done. Research is a set of tools. We want to 
make sure we can find the right one fast, but we aren’t too con-
cerned with the philosophy of how the toolbox is organized. 

 	
The Basics	 13	
To choose the best research tool for your project, you’ll need 
to know what decisions are in play (the purpose) and what 
you’re asking about (the topic). Then you can find the best ways 
to gather background information, determine the project’s goals 
and requirements, understand the project’s current context, and 
evaluate potential solutions. 
Generative or exploratory research: “What’s up with...?”
This is the research you do before you even know what you’re 
doing. It leads to ideas and helps define the problem. Don’t think 
of this as just the earliest research. Even if you’re working on an 
existing product or service, you might be looking for ideas for 
additional features or other enhancements, or new products you 
could bring to an audience you’re already serving. 
Generative research can include interviews, field observation, 
and reviewing existing literature—plus feeling fancy about say-
ing “generative research.”
Maybe the museum is trying to decide how to allocate that 
grant money and has discovered that a lot of parents who re-
cently had their first child are coming to the website and you 
want to figure out what else you can offer them. Your question 
might be, “What’s up with new parents anyway?” Your goal 
would be to see the new parent experience from their eyes, to 
understand what they do and what they need. Your generative 
research activities might include interviewing new parents on 
the phone, following new parents around on a typical day, or 
looking at the questions new parents ask on social websites. 
Once you’ve gathered information, the next step is to comb 
through it and determine the most commonly voiced unmet 
needs. This sort of research and analysis helps point out useful 
problems to solve. Your thinking might lead to a hypothesis, 
such as “Local parents of young children would value an app 
that offers ideas for science events and activities based on their 
child’s developmental milestones.” Then you can do further (de-
scriptive) research on how parents recognize and commemorate 
those milestones. 
www.allitebooks.com

	
14 	 Just Enough Research
Descriptive and explanatory: “What and how?”
Descriptive research involves observing and describing the char-
acteristics of what you’re studying. This is what you do when 
you already have a design problem and you need to do your 
homework to fully understand the context to ensure that you 
design for the audience instead of yourself. While the activities 
can be very similar to generative research, descriptive research 
differs in the high-level question you’re asking. You’ve moved 
past “What is a good problem to solve?” to “What is the best 
way to solve the problem I’ve identified?”
At Mule, we’ve done a lot of design work for eye health orga-
nizations. Despite the fact that several of us have really terrible 
vision (and very stylish glasses), none of us had any expertise 
beyond whether the chart looks sharper through lens number 
one or lens number two. The Glaucoma Research Foundation 
offered a clear design problem to solve: how to create useful, 
accurate educational materials for people who had been newly 
diagnosed with an eye disease. So, a round of descriptive re-
search was in order. 
To inform our design recommendations, we interviewed 
ophthalmologists and patients, and reviewed a large quantity of 
frankly horrifying literature. (Please, have your eyes examined 
regularly.) By understanding both the doctor and patient priori-
ties and experiences, we were able to create online resources 
full of clear information that passed clinical muster and didn’t 
provoke anxiety.  
For the Fantastic Science Center, descriptive research comes 
into play once we’ve identified a design problem, such as pro-
viding an online robotics course for students around the world. 
Maybe this supports the organizational goal to create a global 
robot army. It would be important to understand how online 
learning would best fit into the lives of the target students. For 
example, do they have their own equipment or do they share? 
How do target users find out about new online activities? How 
do the needs of students who only have mobile devices com-
pare to those who have access to a laptop or desktop? Which 
activities are they already engaged in that might compete with 
or complement such a course?

 	
The Basics	 15	
Evaluative research: “Are we getting close?”
Once you have a very clear idea of the problem you’re trying 
to solve, you can begin to define potential solutions. And once 
you have ideas for potential solutions, you can test them to 
make sure they work and meet the requirements you’ve identi-
fied. This is research you can, and should, do in an ongoing and 
iterative way as you move through design and development. The 
most common type of evaluative research is usability testing, but 
any time you put a proposed design solution in front of your 
client, you really are doing some evaluative research. 
Causal research: “Why is this happening?”
Once you have implemented the solutions you proposed, and 
have a website or application up and running out in the world, 
you might start noticing that people are using it in a certain way, 
possibly a way that isn’t exactly what you’d hoped. Or perhaps, 
something really terrific is happening and you want to replicate 
the success in other parts of your operation. For example, you’ve 
noticed that ever since the Fantastic Science Center redesign 
launched, tickets for the Friday evening science-loving singles 
event are selling better, but ticket sales have completely dropped 
off for the Sunday afternoon film program. You need to do some 
causal research.
Establishing a cause-and-effect relationship can be tricky. 
Causal research often includes looking at analytics and conduct-
ing multivariate testing (see Chapter 9). This means reviewing 
your site traffic to see how visitors are entering and moving 
around the site and what words they might be searching for, 
as well as trying design and language variations to see which 
ones are more effective. Causal research might show that your 
film program traffic all came from one referring website that 
no longer links to you. Or, you might have to expand beyond 
looking at site performance to see what else is going on. Maybe 
a competing organization started an event with a very similar 
name and confused your target audience.

	
16 	 Just Enough Research
As long as you’re clear about your questions and your ex-
pectations, don’t fret too much about the classification of the 
research you want to undertake. Remain open to learning at 
every stage of the process. And share this love of learning with 
your team. Your research will benefit from a collaborative ap-
proach that includes assigning specific responsibilities to dif-
ferent people. 
Roles
Research roles represent clusters of tasks, not individual people. 
Often one person will take multiple roles on a study, or a single 
role can be shared. 
Author
The author plans and writes the study. This includes the prob-
lem statement and questions, and the interview guide or test 
script.
Interviewer/Moderator
The interviewer is the person who interacts directly with the 
test participants.
Coordinator/Scheduler
The coordinator plans how time will be used during the study 
and schedules sessions, including arranging times with the 
participants. 
Notetaker/Recorder
The notetaker is responsible for capturing the data during a 
test session. It is best that the interviewer and notetaker be two 
separate people so that the interviewer can devote full attention 

 	
The Basics	 17	
to the participant. If this is impossible, the interviewer can ar-
range to record the session as unobtrusively as possible. Having 
both written notes and a recording makes data analysis easier. 
Recruiter
The recruiter screens potential participants and identifies the 
respondents who would be good subjects. The recruiter and 
scheduler can easily be the same person. 
Analyst
The analyst reviews the gathered data to look for patterns and 
insights. More than one person should have this role. 
Documenter
The documenter reports the findings once the research study 
is complete. 
Observer
Often it’s useful for clients or other available team members to 
watch the research in progress. This is appropriate as long as 
the presence of the observers will not influence the research 
itself. As a substitute, you can make raw recordings available. 
You can change roles with each set of activities if that works 
best, or develop a routine that allows you to focus on the infor-
mation gathering. Just as with design and coding, every time 
you complete some research, you’ll have ideas for how to do it 
better next time and you’ll have found new ways to incorporate 
learning into your work.
Listen. Be interested. Ask questions. Write clearly. And prac-
tice. Whatever your day job is, adding research skills will make 
you better at it. 

	
18 	 Just Enough Research
The research process
We’ll cover ways to organize research activities in extensive de-
tail in Chapter 3. For the purposes of this section, what matters 
is that everyone working together has a shared understanding of 
how the work will proceed. This can be as simple as a checklist. 
In addition to organizing the efforts of your immediate team, 
you might need to get approval to do research at all, either from 
the client or from decision-makers in your organization. Handle 
this as early as possible so you can focus on the work rather 
than defending it. 
Overcoming objections
Sometimes the people you’re working with or for will consider 
research somewhere between a threat and a nuisance. 
You might have to get a certain amount of what they call 
organizational buy-in to proceed. This could start with agree-
ment from your immediate team, but the whole point of doing 
research is to have a stronger basis for decision-making, so if 
another level of decision-making, such as executive fiat, trumps 
the research, you will have wasted your time. Get ready to ad-
vocate for your research project—before you start it.
The objections you will hear
Here is a handy list of objections and responses.
We don’t have time
You don’t have time to be wrong about your assumptions. What 
are your key assumptions? What if they’re all wrong? How much 
work would you have to redo? How long would that take? 
We don’t have the expertise, or the budget 
You have what it takes, thanks to this book! Even with little 
or no budget, you can usually locate some related research 
online, wrangle representative users to interview, and do a 

 	
The Basics	 19	
little usability testing. Applying some critical thinking to your 
assumptions costs nothing, but a change in your habits can offer 
tremendous returns. 
The CEO is going to dictate what we do anyway
You’re going to fight to change that dictatorial culture. Reasonably 
accurate and well-documented research has been known to 
sway even the most magnificent and well-fed egos. And if the 
leadership really does have a “damn the facts, full speed ahead” 
attitude, get a different job.
One research methodology is superior (qualitative vs. 
quantitative)
What you need to find out determines the type of research you 
need to conduct. It’s that simple.
You need to be a scientist
This isn’t pure science we’re talking about here. This is applied 
research. You just need to have (or develop) a few qualities in 
common with a good scientist:
• Your desire to find out needs to be stronger than your desire 
to predict. Otherwise you’ll be a mess of confirmation bias, 
looking for answers that confirm what you already assume.
• You need to be able to depersonalize the work. There are no 
hurt feelings or bruised toes in research, only findings. 
• You need to be a good communicator and a good analytical 
thinker. Otherwise questions and reports get muddy, and re-
sults will be worse. This is just a set of skills that most people 
can develop if they have the right attitude. 
You need infrastructure
I suspect you own or can borrow a laptop and have access to 
the internet. That is all you need. 

	
20 	 Just Enough Research
It will take too long
Upfront research can provide a basis for decision-making that 
makes the rest of the work go much faster. Nothing slows down 
design and development projects as much as arguing over per-
sonal opinions or wasting effort solving the wrong problem. 
And you can start small. A couple of weeks can mean very little 
to your overall schedule while adding significantly to your po-
tential for success. 
You can find out everything you need in beta
There are a lot of things you can find out in beta: what func-
tionality is working, whether users have a hard time finding 
core features. But there are also a lot of things that are very 
helpful to know before you start designing or coding at all, and 
you can find those out pretty fast: what your target audience is 
doing right now to solve the problems your product or service 
purports to solve, whether people want this product at all, and 
what your organization has to do to support it. 
Again, it’s a matter of where you want to invest and what you 
have to lose. Don’t waste anyone’s time or effort on untested 
assumptions if you don’t have to. 
We know the issue/users/app/problem inside and out already
Unless this knowledge comes from recent inquiry specific to 
your current goals, a fresh look will be helpful. Familiarity 
breeds assumptions and blind spots. Plus, if you are very famil-
iar with your users it will be very easy for you to find some to 
talk to.
And who is the “we” in this case? In the absence of a mind 
meld, the client’s experience with the users or the business 
problem doesn’t transfer to the designer. Shared understand-
ing is key. 

 	
The Basics	 21	
Research will change the scope of the project
It’s better to adjust the scope intentionally at the start than be 
surprised when new information pops up down the road to 
amend your plans. Research is an excellent prophylactic against 
unexpected complexity.  
Research will get in the way of innovation
Relevance to the real world is what separates innovation from 
invention. Understanding why and how people do what they 
do today is essential to making new concepts fit into their lives 
tomorrow.    
Actual reasons behind the objections
At the root of most of these objections is a special goo made up 
of laziness and fear. 
I don’t want to be bothered
Unless you are naturally curious about people, research can 
seem like annoying homework at first, but once you get into it, 
you’ll find it totally fun and useful. A little knowledge opens up 
a whole world of new problems to solve and new ways to solve 
the problems at hand. That makes your work more rewarding. 
If research is one more thing tossed on your already overfull 
plate, then someone needs to ask the “Who should be doing 
this?” question again—but the problem is you being too busy, 
not research being unimportant. Research needs to be integrated 
into process and workflow or it will get shoved in a corner. If 
your project has a project manager, talk with them about finding 
ways to make it work. 
I am afraid of being wrong
The cult of the individual genius designer/developer/entre-
preneur is strong. In certain “rockstar knows best” cultures, 

	
22 	 Just Enough Research
wanting to do research can come across as a sign of weakness 
or lack of confidence. Fight this. 
Information and iteration are the keys to a successful design. 
Research is just one set of inputs. 
I am very uncomfortable talking to people
You are creating a system or a service actual people are going to 
have to use. This system will be talking to people on your behalf, 
so it’s only fair that you talk to people on its behalf. That said, 
some people on your team will have more comfort and skills 
when it comes to interacting with your research subjects, so 
consider that when you’re deciding who does what. 
Having to respond to challenges and objections before you can 
get to work might feel like a waste of time, but it can be very 
useful in its own right. Describing the goals and potential of your 
research to people who aren’t sold on the value will actually 
help you focus and better articulate what you hope to uncover. 
These discussions will give you a better understanding of the 
environment you’re working in. Research is all about context. 
Research in any situation
“Poor user experiences inevitably come from poorly informed  
design teams.” 
—Jared M. Spool, founder of User Interface Engineering
Design happens in context. And research is simply understand-
ing that context.
Research happens in a context as well. Your professional 
environment should inform the research activities you choose 
and how you go about them.
The following contexts and situations aren’t mutually ex-
clusive. You might be in some that overlap. Just remember that 
no matter what situation you’re in, you can do or participate in 
some useful research.

 	
The Basics	 23	
Freelance 
On the one hand, as a freelancer, you can do whatever the hell 
you want as part of your design and development process as 
long as you deliver what the client expects when the client 
needs it. On the other hand, if someone is hiring you as a solo 
web designer, they may balk at paying for something that falls 
outside of their concept of that gig. 
If you are doing work, you need to get paid for it. “Just tossing 
in the research” is a terrible mistake designers who want to do 
good work make all the time. Instead, you have to commit to 
research personally as part of how you work, make your case 
for it, and be sure to include it in your fee. Research will make 
your design stronger and enhance your ability to defend your 
decisions to the client.
If you’re being brought in as a contractor to work as part of 
an internal team, make sure you have access to all of the infor-
mation and insight required to do your job. Contractors run the 
risk of being pigeonholed. You’re the designer, why do you need 
to bother with research? When information is distributed on a 
“need-to-know” basis, you’re the best judge of what you need 
to know to get the job done.  
At a client services agency
If you are at an agency, you have the opportunity to improve 
your process with each new project. A certain amount of re-
search is built in simply because you have to scope the work to 
bid on the job and understand the client’s needs (or do an awe-
some job of faking it) to land the gig. The better you do these 
things, the better time you’ll have doing the work. 
At Mule, and at many other agencies, the first phase of work 
on any new project is an intensive period including all the 
research that’s useful and practical. We talk to stakeholders, 
interview users, review competitors, and sometimes conduct a 
round of benchmark usability testing. Sometimes we do this in 
a matter of a few weeks. We need to get up to speed quickly, so 
working collaboratively is essential. 
www.allitebooks.com

	
24 	 Just Enough Research
As with freelancing, coming in from the outside puts us at a 
definite advantage because we are external to existing processes 
and political considerations. Some clients bring us in to ask the 
questions they know need to be asked, but are not in a position 
to ask themselves. 
Falling back on ignorance can be a position of strength. 
Asking naive questions can cut right to the heart of assumptions 
and open people up to thinking about problems in a new way. 
“How does that benefit the business?” and “Why do you do it 
that way?” are a couple of terrific questions that can be very 
tricky for someone on the inside to get away with. 
In-house at an established company
In an established organization of any size, politics are a huge 
consideration. Challenging the assumptions of those in power 
can be incredibly threatening to those people. It can also be the 
best thing you can do to ensure that your work succeeds—if you 
don’t get fired. (See Chapter 4 for more on introducing even the 
most stubborn organization to the joys of research.)
If you’re at an organization that genuinely embraces critical 
thinking and clear communication in the design process, that’s 
terrific. I hope you’re also taking very good care of your unicorn 
desk mate. Otherwise, proceed with open eyes and discretion. 
An existing product means that a glorious data trove exists: 
customer service! Customer service is where actual, individual 
human needs and expectations crash headfirst into reality. If you 
have ready access to the customer service representatives, talk 
to them. You will make friends. Customer service staff have so 
much expertise and often get very little respect within an orga-
nization. And they have to communicate with unhappy people 
all day, every day. A conversation with someone who respects 
and values their contribution is likely to be a good time for all. 
In addition to, or instead of, direct access to the customer ser-
vice people, get hold of the inbound support requests. This will 
be a fantastic source of insights into the ways different types of 
customers think about their needs and the language they use to 
describe them. You can also practice seeing through what people 
say they want to what they actually need. Steve in Louisville 

 	
The Basics	 25	
may be asking for a more informative error message, but what 
he really wants is to be able to reorder his usual pizza and salad 
with a different credit card and no error message.
You don’t just want insights; you also want a way to put those 
insights back into the product. 
It’s very helpful to have a clear idea of how product and mar-
keting decisions are made in your company. Do you have a truly 
customer-centered culture? When leaders talk about research, 
are they talking about market research, or do they have a more 
holistic view? Is there a market research group? Is design or user 
experience research already part of your process?
In-house at a startup
When you have a small startup team, you don’t have to worry 
too much about understanding your own organization beyond 
knowing what you have to do to keep the lights on. In the early 
stages it should be easy to share information with the team, as 
long as you aren’t growing so fast that people and perspectives 
start getting left out.
You do need to have some clarity around your audience and 
the business context you’re operating in. You’re trying to intro-
duce something new into the world. Who needs it and what is 
important to those people? When you’re discussing the initial 
design and development of your product, discuss the role of 
research with the team. Document and review assumptions to 
identify the areas in which doing some research might be the 
most beneficial. Get some early agreement on how research 
will be involved, keep track of your assumptions, and adopt a 
skeptical point of view. 
The approach and biases of the founder and the investors 
might dominate, so if you aren’t one of those, you will have to 
be very clear about the value of research to your endeavor and 
savvy about how to make your case. 
Working with an agile development team
Agile is a popular software development philosophy with the goal 
of building better software faster in a productive, collaborative 

	
26 	 Just Enough Research
working environment. Many short iterations of two or three 
weeks replace the traditional approach of multi-month or multi-
year projects broken into distinct phases.  
On the surface, agile seems antithetical to design. The agile 
manifesto explicitly values “responding to change over following 
a plan.” Design is planning. However, any work with complex 
ideas and dependencies requires holding some ideas outside the 
development process. You can’t cave in completely to the seduc-
tive solipsism that agile offers, or you’ll be tunneling efficiently 
and collaboratively toward the center of the earth. While flex-
ibility and responsiveness are certainly virtues that many project 
teams could use more of, let’s not discount the importance of 
having some sort of plan. 
From a user experience perspective, the primary problem 
with Agile is that it’s focused on the process, not the outcomes. 
It doesn’t offer guidance on what to build, only how. Perhaps 
your team is more efficient and happier making a lot of stuff 
together, but how do you know that stuff is the best it could be, 
meeting real user needs and fit to compete in the marketplace?
If you’re always reacting without a framework, you need 
some guiding mandates. Which customers do you listen to and 
why? Which user stories do you prioritize? What are you ulti-
mately building toward?
Research is not antithetical to moving fast and shipping con-
stantly. You’ll need to do some upfront work for background 
and strategy and the overall framework. Then, as the work 
progresses, do continual research. 
It might sound counterintuitive, but the most effective ap-
proach may be to decouple the research planning from the 
development process—that is, don’t wait to start coding until 
you’ve answered all your research questions. Once you have 
some basic tools and processes in place, such as observation 
guides, interview guides, recording equipment, and questions 
for analysis, you can take a Mad Libs approach and fill in your 
actual questions and prototypes on the fly.
Jeff Patton describes this continuous user research process in 
his article “Twelve Emerging Best Practices for Adding UX Work 
to Agile Development” (http://bkaprt.com/jer/2/). He offers a tidy 
three-point summary:

 	
The Basics	 27	
• Aggressively prioritize the highest-value users.
• Analyze and model data quickly and collaboratively.
• Defer less urgent research and complete it while the software 
is being constructed.
In other words, focus only on the essential user types, deal 
with your data as soon as you get it, involve your team in the 
analysis, and do the less important stuff later. 
This of course opens up the questions of who are the highest-
value users and what are the more or less urgent research activi-
ties. Prioritize those user types whose acceptance of the product 
is critical to success and those who least resemble the software 
developers on your team. Go learn about them.
Recruiting and scheduling participants is the most difficult 
part, so always be recruiting. Set up windows of time with dif-
ferent participants every three weeks. When you have them, 
you can either conduct an ethnographic interview (see Chapter 
5) to understand their behavior before the next round of devel-
opment or do some usability testing on the current state of the 
application.
Use what you learn from the initial user research and analy-
sis to create personas that inform high-level sketches and user 
stories. Then, when the team is working on a feature that has a 
lot more engineering complexity than interaction design com-
plexity, you can fit in additional evaluative research. 
Throughout the development cycle, the designers can use 
research to function as a periscope, keeping an eye out for new 
insights about users and competitive opportunities while doing 
usability testing on whatever is ready.
Just enough rigor
Professional researchers are not unlike journalists. While many 
people have sufficient skills to observe, analyze, and write, it’s 
allegiance to a set of standards that sets the pros apart. In addi-
tion to being professional and respectful in your work, there are 
just a few responsibilities to keep in mind.

	
28 	 Just Enough Research
Cover your bias
Wherever there is research there is bias. Your perspective is 
colored by your habits, beliefs, and attitudes. Any study you 
design, run, or analyze will have at least a little bit of bias. Your 
group of participants will be imperfectly representative. Your 
data gathering will be skewed. Your analysis will be colored by 
selective interpretation. 
Don’t give up!
You can’t eliminate it completely—but the simple act of not-
ing potential or obvious bias in your research process or results 
will allow you to weigh the results more appropriately. In lieu 
of a trained eye, use the following bias checklist, or make your 
own. Grade hard. 
Design bias
Design in this case refers to the design of the studies themselves, 
how they are structured and conducted. This is the bias that 
creeps into studies when you don’t acknowledge bias, or if you 
include or leave out information based on personal goals or 
preferences. 
Sampling bias
Since we’re talking about quick and dirty qualitative research, 
sampling bias is almost unavoidable. Counter it by being mindful 
in the general conclusions you draw. 
If your app for science-minded new parents is intended to 
serve men and women in equal numbers but all your subjects 
are women, that’s a biased sample.
Interviewer bias
Conducting unbiased interviews is difficult. Inserting one’s 
opinions is easy. Make sure that interviewers remain as neutral 
as possible.

 	
The Basics	 29	
This is something to watch out for particularly at the begin-
ning of interviews when you are trying to establish rapport. 
Maybe the interviewer is super enthusiastic about one aspect of 
the museum. Practice interviews and critiques with an internal 
team are the best way to develop a neutral interviewing style. 
Sponsor bias
This is one of the biggest issues with onsite lab usability tests, 
because going onsite feels special and can be exciting or even 
daunting to a participant. If the Fantastic Science Center is invit-
ing you in to their facility, offering you snacks, and writing you 
a check, it is very possible you will be gentler in your evalua-
tions. To decrease sponsor bias without being deceptive, use a 
general description of the organization and goals of the study 
without naming the specific company until and unless it appears 
in materials you are evaluating. (Once you get to the point of 
showing a website design featuring the Fantastic Science Center 
logo, the secret will be out.) 
For example, begin a phone interview with “We’re interested 
in how you select and plan activities for your family,” rather 
than “We want you to tell us what would entice you to visit the 
Fantastic Science Center.”
Social desirability bias
Everyone wants to look their best. People want to be liked. It can 
be hard to admit to an interviewer that you don’t floss or pay off 
your credit card bill every month, so participants will sometimes 
give the answers that put them in the best light. Emphasize the 
need for honesty and promise confidentiality. 
The Hawthorne effect
The behavior of the people you are studying might change just 
because you are there. Staff who typically goof around and chat 
during the day might clam up and shuffle files if you’re hanging 

	
30 	 Just Enough Research
about to observe their workflow. Do your best to blend into the 
background and encourage research participants to go about 
their normal day.
The ethics of user research
What harm can come of asking people how they decide what to 
have for dinner or how they use their phones to find directions? 
We aren’t talking about clinical trials of dangerous, new cancer 
drugs, but all research that includes people and their personal 
information should be conducted ethically and conscientiously. 
It’s our responsibility as professionals to proceed without de-
ceiving or injuring any of the participants. 
Below is a starter set of ethical concerns you should keep in 
mind whenever you are doing research. (For more thorough 
guidelines, take a look at the ICC/ESOMAR Code on Market and 
Social Research, which is available in fifteen languages: http://
bkaprt.com/jer/3/.)
The project as a whole
Maybe this goes without saying, but it is worth saying neverthe-
less. Is your overall goal, the project that the research supports, 
ethical? Will your success lead to harm for others? If it will, don’t 
participate in it. Designers have a role to play as gatekeepers. 
You should be intentional about your position. Conducting a 
completely above-the-board study on women to induce them to 
buy a diet aid with dangerous side effects doesn’t make it right.
The goals or methods of the research
A certain amount of user research and usability requires keep-
ing certain facts from the participants. Usually this is benign, 
such as hiding the name and description of the product you’re 
designing, but sometimes it’s a problem. Will concealing these 
facts lead those users to participate in anything they might not 
otherwise agree to? Are you tricking them or setting some un-
realistic expectation about the real world? Are you presenting 
false information as true? 

 	
The Basics	 31	
Consent and transparency
Informed consent is the rule. This means that participants must 
understand and agree in advance to the overall goals of any study 
and how their information will be recorded, used, or shared. 
Let them know if they are being watched by unseen observers. 
Make sure that research participants are of sound mind and able 
to give consent to participate. This means that working with 
underage research participants is very tricky, and requires the 
parents’ consent. 
Safety and privacy
Ensure that participants know what is required of them in ad-
vance and will be comfortable and not fatigued. Verify that your 
presence in a home or workplace will not lead to any risks or 
danger. For example, if you’re observing someone taking care 
of small children, make sure that your actions don’t distract in 
any way that would interfere with proper care. 
And for the love of all humanity, never, ever agree to do 
telephone interviews when anyone involved is driving. Not 
participants, not interviewers, not passive observers. No one. 
As soon as you learn that someone is on the phone while driv-
ing, end the call, and follow up by email or another means to 
reschedule if necessary. 
Be a skeptic
Get in the habit of asking a lot of questions. Question all your 
assumptions and determine whether you need to check your 
facts. If you’re constantly on the lookout for threats and poten-
tial points of failure, you and your products will be stronger. 
This is a type of critical thinking that will serve you well at all 
times. You need to be aware of how much you don’t know and 
what that means.
Awareness of your own limits will allow you to be as effective 
as possible within them.

	
32 	 Just Enough Research
Best practices
There are many good reasons why people get master’s degrees 
and PhDs and become professional analysts and researchers, and 
there are plenty of reasons why companies benefit from hiring 
those people. Specialized, educated, and trained researchers 
cultivate a deep curiosity, have a broad base of relevant knowl-
edge, and gain academic and professional experience conduct-
ing ethical and methodical studies. As a designer or developer, 
you might have good reasons to avoid DIY and hire a trained 
professional.
These include:
• A large, complex project.
• A large, complex organization.
• Complex or sensitive subject matter.
• A very specialized or challenging user base, such as children 
or neurosurgeons.
• Heinous organizational politics.
• Lack of team members with the time or inclination to acquire 
additional skills and duties.
Skilled, trained professional researchers have rigor. They can 
apply precise critical thinking in the face of common distractions 
and pressures, such as the enthusiasm of their team or their 
manager’s personal preferences. The best researchers are like 
Mr. Spock, with just enough humor and humanity to temper 
their logical thought processes and allow them to roll with im-
perfect circumstances. You want rigorous, not rigid.
In the absence of a trained professional, how do you ensure 
you are being sufficiently rigorous? You’re an amateur attempt-
ing these stunts on the open road instead of a closed course; how 
do you make sure you and your work don’t go up in flames?
You borrow the methods of America’s greatest amateur, 
Benjamin Franklin: discipline and checklists. 
Discipline requires you to be ever-watchful for bad habits, 
shoddy thinking, and other human frailties that will undermine 
your efforts. Checklists substitute the experience of others for 

 	
The Basics	 33	
your own. Discipline also requires that you don’t deviate from 
the checklists until you have sufficient experience yourself.
Here is the first checklist, that of best practices. Go over these 
again and again until you know them by heart, and then post 
them visibly so you never have to rely on memory. 
1. Phrase questions clearly
This refers not to the questions you’re asking, but the big ques-
tion you’re trying to answer. Unless you know and can clearly 
state what you’re trying to find out and why, applied research 
is a pointless exercise.
2. Set realistic expectations
A successful study is preceded by expectation-setting for ev-
eryone involved, including the questions to be answered, the 
methods to be used, and the decisions to be informed by the 
findings. This is particularly important if you need to request 
time or budget especially for the work. If your research work 
doesn’t meet the expectations of the stakeholders, they will treat 
you like you’ve wasted time and money. Ask team members and 
managers what they hope for. Tell them what to expect. 
3. Be prepared
Research is like kitchen work: the better you prep, the faster 
and cleaner the work goes. If you don’t prepare, you end up 
with a huge mess and a kitchen on fire. Get your process and 
materials in order before you start. Set these up so they’re easy 
to reuse as needed.
4. Allow sufficient time for analysis
You need a little time for things to click into place. After doing 
the research, it’s tempting to just forge ahead to solutions with-
out giving yourself enough time to digest. Again, a bit more time 
here can save lots later on. 
www.allitebooks.com

	
34 	 Just Enough Research
5. Take dictation
Notes or it didn’t happen. Effective research requires effective 
reporting, and sharing your results and recommendations with 
others. A good report doesn’t have to be arduous to compile 
or read. It needs to be sufficiently informative and very clear 
to anyone who needs to make decisions based on the research.
You may be doing your own research to save time and money, 
but be honest with yourself and your team about your capacity 
for maintaining this level of rigor. Otherwise you risk wasting 
both time and money, as well as spreading misinformation and 
decreasing the overall reputation of research as a necessary 
input into the work. 
Can you commit? 
Good. Then onward.
How much research is enough?
“There are things we know that we know. There are known 
unknowns—that is to say, there are things that we now know we 
don’t know. But there are also unknown unknowns—there are 
things we do not know we don’t know.”
—Donald Rumsfeld, former US secretary of defense
Avoiding unnecessary research
In addition to offering the clarity and confidence necessary to 
design, research is essential to reducing your risk—the risk you 
incur by relying on assumptions that turn out to be wrong or 
by failing to focus on what’s most important to your business 
and your users. However, some assumptions are higher-risk 
than others.
To make the best use of your time and truly do just enough 
research, try to identify your highest-priority questions—your 
assumptions that carry the biggest risk.
Ask this question: given our stated business goals, what po-
tential costs do we incur—what bad thing will happen—if, six 
months from now, we realize:

 	
The Basics	 35	
• We are solving the wrong problem.
• We were wrong about how much organizational support we 
have for this project.
• We don’t have a particular competitive advantage we thought 
we had, or we didn’t see a particular competitive advantage 
before our competitor copied us. 
• We were working on features that excited us but don’t actu-
ally matter that much to our most important customers.
• We failed to reflect what is actually most important to our 
users. 
• Our users don’t really understand the labels we’re using.
• We missed a key aspect of our users’ environments.
• We were wrong about our prospective users’ habits and 
preferences.
If there is no risk associated with an assumption—for ex-
ample, if you are working on a technical proof of concept that 
really, truly doesn’t have to satisfy any real-world users—then 
you don’t need to spend time investigating that assumption. 
On the other hand, maybe the success of the new design for 
the Fantastic Science Center’s online store depends on the as-
sumption that many people who shop online value the ability 
to publicly share their transactions. You could conduct research 
to understand the social sharing practices and motivations of 
people who shop online before diving into design and develop-
ment. Or you could go ahead and design based on an optimistic 
assumption, then see what happens. At risk are the time and 
money to design and build the functionality, as well as the orga-
nization’s reputation. (“They just told everyone on the internet 
about the robot I bought my kid for her birthday. Not cool!”)
Better understanding of online shoppers mitigates the risk by 
validating the assumption and informing your design with real 
user priorities. In addition, you might uncover opportunities to 
provide something of even greater value to that same audience. 
All it takes to turn potential hindsight into happy foresight is 
keeping your eyes open and asking the right questions. Failing 
isn’t the only way to learn. 

	
36 	 Just Enough Research
That satisfying click
No matter how much research you do, there will still be things 
you wish you’d known, and there are some things you can only 
learn once your design is out there in the world. Design is an 
iterative process. Questions will continue to crop up. Some of 
them you can answer with research and some you can only 
answer with design. Even with research, you’ll need to create a 
few iterations of the wrong thing to get to the right thing. There 
is no answer to the question of enough, other than the point at 
which you feel sufficiently informed and inspired. The topics 
in this book can only offer a starter kit of known unknowns.
That said, one way to know you’ve done enough research is 
to listen for the satisfying click. That’s the sound of the pieces 
falling into place when you have a clear idea of the problem you 
need to solve and enough information to start working on the 
solution. The click will sound at different times depending on 
the problem at hand and the people working on it. 
Patterns will begin to emerge from the data. Those patterns 
will become the answers you need to move forward. This will 
be very satisfying on a neurochemical level, especially when 
you start out with a lot of uncertainty. Since human brains are 
pattern recognition machines, you might start seeing the pat-
terns you want to see that aren’t actually there. Collaborating 
with a team to interpret the data will reduce the risk of overly 
optimistic interpretation.
If you don’t have enough information, or what you’re finding 
doesn’t quite hold together, the pieces will rattle around in your 
head. Ask a few more questions or talk to a few more people. 
Talk through the results. The pieces will fall into place. 
Learn to listen for that click.

 	
The Process	 37	
3 The Process
This is the “systematic” in the systematic inquiry. Whether 
the research requires a month or a single morning, being just a 
bit methodical will be the “extra” step that saves your precious 
time and brain. Whatever type of research you’re doing, and 
wherever it falls in your schedule, follow these six steps:
1.	Define the problem.
2.	Select the approach.
3.	Plan and prepare for the research.
4.	Collect the data.
5.	Analyze the data. 
6.	Report the results.
With practice, the first three steps will become muscle  
memory and you can focus on collecting, analyzing, and shar-
ing the data. 

	
38 	 Just Enough Research
1. Define the problem
Just as you need a clearly articulated problem to create a solid de-
sign solution, a useful research study depends on a clear problem 
statement. In design, you’re solving for user needs and business 
goals. In research, you’re solving for a lack of information. A 
research problem statement describes your topic and your goal.
You want to know when you’re finished, right? So base your 
statement on a verb that indicates an outcome, such as  “describe,” 
“evaluate,” or “identify.” Avoid using open-ended words like 
“understand” or “explore.” You’ll know when you have described 
something. Exploration is potentially infinite.
For example, if your topic is working parents of school-aged 
children and your question is, “How do they select and plan 
weekend activities?” then your problem statement could be, 
“We will describe how parents of school-age children select and 
plan weekend activities.” Or, if your topic is your competitors 
and your question is, “What are their competitive advantages 
and disadvantages relative to our service?” the corresponding 
problem statement might be, “We will analyze the relative ad-
vantages and disadvantages of a set of identified competitors.”
You might have a single question, a question with several sub-
questions, or a group of related questions you want to answer 
at the same time. Just make sure that your problem statements 
are clear.
Now that you’ve identified what you want to find out, you 
can move on to how.
2. Select the approach
Your problem statement will point you toward a general type 
of research. The amount of resources at your disposal (time, 
money, people) will indicate an approach. There are a lot of 
ways to answer a given question, and they all have tradeoffs.
If your question is about users themselves, you’ll be doing 
user research, or ethnography (see Chapter 5). If you want to 
assess an existing or potential design solution, you’ll be doing 
some sort of evaluative research (see Chapter 7). As a single 

thE PRocEss
39
question comes into focus you might conduct multiple studies 
or take one of several potential approaches (Fig 3.1).
Will you be conducting an expert review of existing science 
museum websites, ringing up friends and family to ask about 
their excursion-planning habits, or fl ying to a distant country 
to follow science teachers around?
These are just a few examples of how these considerations 
might play out.
Once you’ve selected the approach, write a quick description 
of the study by incorporating the question. For example: “We 
Descriptive
Generative
Descriptive
Evaluative
Analytic
Evaluative
Evaluative
Analytic
Interviews
Usability
Testing
A/B
Testing
Usability
Testing
Competitive
Analysis
Heuristic
Analysis
SWOT
Analysis
Brand
Audit
Interviews
Contextual
Inquiry
Literature
Review
Questions
About
Competition
Organization
Product
Users
Fig 3.1: the topic and nature of your questions will guide your choice of research activities.

	
40 	 Just Enough Research
will describe how parents of school-age children select and plan 
weekend activities by conducting telephone interviews and 
compiling the results.”
3. Plan and prepare for the research
First of all, identify the point person—the person responsible 
for the plan, the keeper of the checklist. This can be anyone on 
the team, whether or not they’re participating in the research; it 
just has to be one person. This will help keep things from falling 
through the cracks. 
Sketching out an initial plan can be very quick if you’re work-
ing by yourself or with a small group. Decide how much time 
and money you will be devoting to research, and who will be 
involved in which roles. Identify subjects and, if necessary, de-
cide how you’re going to recruit them. Include a list of materials. 
In the beginning, don’t worry about getting everything right. 
If you don’t know, go with your best guess. Since research is 
about seeking out new information, you’re going to encounter 
new situations and unpredictable circumstances. Make friends 
with the unexpected. And prepare to change the plan you’ve 
made to adapt once you have facts. 
You might plan for sixty-minute sessions but find that you’re 
getting all the information you need in half an hour. Or you 
might find that the name of a particular competitor keeps com-
ing up during an interview, so you decide to add fifteen minutes 
of competitive usability testing to the interview so that you can 
observe your target customers using their service.
Just be very clear about the points at which changes to your 
research plans might affect your larger project. It’s easy to be 
optimistic, but it’s more helpful to think about trade-offs and 
fallback plans in a cool moment before you get started. What will 
you do if recruiting and scheduling participants looks like it’s 
going to take longer than you’ve planned? You can push out the 
dates, relax your criteria for participants, or talk to fewer people 
now and try for more later. There’s no one right answer—only 
the best way to meet your overall project goals at the time.

 	
The Process	 41	
In addition to answering your research questions, you’ll 
continue to learn more about research itself.  Each activity will 
make you smarter and more efficient. So much win.  
Your research plan should include your problem statement, 
the duration of the study, who will be performing which roles, 
how you will target and recruit your subjects, plus any incen-
tives or necessary tools and materials.
This is just the start. You can always add more details as 
they’re helpful to you or your team. 
Recruiting
Recruiting is simply locating, attracting, screening, and acquiring 
research participants. There’s no draft, so you have to recruit. 
Good recruiting puts the quality in your qualitative research. 
Since you’ll probably be working with a small sample size, you 
need the individual participants to be as good as they can be. 
Participants are good to the extent they represent your target. 
If participants don’t match your target, your study will be use-
less. You can learn valuable things by asking the right people 
the wrong questions. If you’re talking to the wrong people, it 
doesn’t matter what you ask. Bad participants can undermine 
everything you’re trying to do.
A good research participant:
• Shares the concerns and goals of your target users.
• Embodies key characteristics of your target users, such as 
age or role.
• Can articulate their thoughts clearly.
• Is as familiar with the relevant technology as your target 
users.
In theory, recruiting is just fishing. Decide what kind of fish 
you want. Make a net. Go to where the fish are. Drop some 
bait in the water. Collect the ones you want. It isn’t actually 
that mysterious, and once you get the hang of it, you’ll develop 
good instincts.

	
42 	 Just Enough Research
In practice, recruiting is a time-consuming pain in the ass. 
Embrace it. Get good at it and all of your research will be faster 
and easier, plus this part of the process will get progressively 
less unpleasant. 
When designing web applications or websites, the web is a 
terrific place to find potential test participants. If you happen to 
have a high-traffic website you can put a link on, that’s the easiest 
way to draw people in (unless you need to recruit people who 
have never been to that site). Otherwise you can email a link to 
a screener—a survey that helps you identify potential partici-
pants that match your criteria—or post the screener where it 
will be visible. 
Go anywhere you’re allowed to post a message that might 
be seen by your target users or their forward-happy friends and 
family. Twitter. Craigslist. Facebook. LinkedIn. 
If you need people in a certain geographic area, see whether 
there are local community sites or blogs that would announce it 
as a service. Referring to it as “design research” rather than “mar-
keting research” goes a long way in the goodwill department.
There are such things as professional recruiters, but you 
probably have every advantage they describe.
The net is your screener. The bait is the incentive. 
A screener is simply a survey with questions to identify good 
participants and filter out anyone who would just waste your 
time. This is incredibly important. You can tell a good recruit 
immediately when you test. Good test participants care. When 
presented with a task, they get right into the scenario. You could 
offer a greasy piece of paper with a couple of rectangles scrawled 
on it and say “How would you use this interface to buy tickets 
to a special exhibit?” and if you’re talking to someone who buys 
tickets, by God they will try.
Mismatched participants are just as obvious as any other sort 
of bad blind date. Their attention will drift. They will go off on 
irrelevant tangents about themselves. (“I shoplift for fun.”) You 
could show them a fully functional, whiz-bang prototype and 
be met with stares and unhelpful critiques. (“Do all the links 
have to be blue? I find that really dull.”) And you will find a way 
to politely shake their hand and send them packing as soon as 

 	
The Process	 43	
possible. (With the incentive promised, by the way. It’s not their 
fault they didn’t get properly screened.)
The most efficient method of screening is an online survey. 
(See the Resources section for suggested tools for creating sur-
veys and recruiting participants.) To write the screener, you and 
your team will need to answer the following questions, adapted 
from an article by Christine Perfetti (http://bkaprt.com/jer/4/):
What are all of the specific behaviors you’re looking for? 
Behaviors are the most important thing to screen for. Even if 
you’re designing something you believe to be totally novel, cur-
rent behaviors determine whether your design has a chance of 
being relevant and intelligible to the participants. 
If you’re designing an app for cyclists, you need to test the 
app with people who ride bikes, not people who love bikes and 
wish they had time to ride. 
What level of tool knowledge and access do participants need? 
Be realistic about the amount of skill and comfort you’re target-
ing. And if you need them to have certain equipment or access 
to participate, make sure to mention that. Back in the old days 
we had to screen out a lot of people who couldn’t talk on the 
phone and use the internet at the same time because they used 
the same line for both. 
To usability-test a mobile app, you need people who are 
sufficiently familiar with their device to focus on the app’s  
usability. Otherwise, you might end up testing the phone and 
get nothing useful. 
What level of knowledge about the topic (domain knowledge) 
do they need?
If you’re truly designing something for very general audiences 
in a familiar domain—say, reading the news—you should verify 
that they actually do the activities you’re asking about, but you 
don’t have to screen for knowledge about the subject matter. On 
www.allitebooks.com

	
44 	 Just Enough Research
the other hand, if you’re making an iPad app that helps mechan-
ics work on cars, don’t test with brain surgeons. 
Writing a screener is a good test of your empathy with your 
target users. To have reliable results, you need to screen in the 
right potential participants, screen out the bad matches, and 
prevent professional research participants from trying to read 
your mind to get the study incentive. Even a $25 Amazon gift 
certificate will attract wily dissemblers. Be vague about the con-
tents of the actual test. If you recruit people from the site you 
are testing, then just refer to “an interview about this website.”
Asking age, gender, and location allows you to avoid certain 
biases, but you also need to get at differences in behavior pat-
terns that may have implications for your design.
For example, when recruiting for a usability study for the 
science and technology museum, you might ask the following 
question: how frequently do you engage in the following activi-
ties? (Answers could be: never or rarely; at least once a year; a 
few times per year; at least once a month; at least once a week.)
• Go to the movies.
• Go hiking.
• Go to an amusement park.
• Try a new restaurant.
• Visit a museum.
• See live music or go to a club.
• See other local sights.
• Go out of town for the weekend.
This question serves two purposes: it gauges museum-visiting 
frequency without giving away the topic of the study, and it 
offers a way to assess general habits around getting out of the 
house. 
At the same time, you should make the screener as short as 
possible to make it less likely potential participants will bail 
before they get to the end.

 	
The Process	 45	
For in-person testing, it’s best to follow up by phone with 
everyone who made the first cut. Asking a couple of quick ques-
tions will weed out axe murderers and the fatally inarticulate and 
may save you from a very awkward encounter. For example, “I 
just want to ask a couple more questions to see whether you’re 
a good match for our study. Could you tell me how you typically 
decide what to do on your days off?”
If the answer is a terse “I don’t,” or a verbose description 
of cat-hoarding and revenge fantasies, just reply that you’ll be 
in touch and follow up with an email thanking them for their 
interest.
Just like formulating queries in Google, writing screeners 
and reviewing the results you get makes you better and more 
accurate at screening. And even if it takes a little time to get it 
right, all the available online tools sure beat standing on the cor-
ner with a clipboard like market researchers still sometimes do. 
4. Collect the data
It’s go time—the research part of the research. Find your re-
search subjects. Conduct your interviews. Do your field obser-
vation. Run your usability tests. (We’ll get into the particulars 
of each activity further on.)
Research makes data. You might have photos, videos, screen 
captures, audio recordings, and even handwritten notes (the 
power goes out, but the interview goes on). These files will 
originate from an individual. Get them onto a shared drive as 
quickly as physics allows. Every researcher has at least once 
experienced the tragic loss of good data. 
Imagine you’ve captured a fantastic video of a parent interact-
ing with three separate applications to plan and purchase tickets 
for a family trip in a way that has significant implications for the 
interface you’re designing. Then you had to go to the restroom 
and, plonk, your iPhone goes into the toilet, the video is gone 
forever, and you’re stuck making notes from memory.
If you are in the field and away from internet access, have a 
small backup drive with you. Redundancy worked for the space 
program and a little bit certainly helps here. 

	
46 	 Just Enough Research
The more organized you are in gathering and storing your 
data, the more effective and pleasant the analysis will be. Any 
system you’re already using should work as long as it can ac-
commodate files of the size you’re anticipating. 
Use a consistent naming convention, such as “Study-Subject 
Name-Year-Month-Day.” This is another one of those things that 
seems obvious, but is really easy to forget when you’re in the 
throes of discovery. 
Take a few moments between sessions to check the files and 
make sure they’re named correctly and saved in the right place, 
and note your initial impressions while you’re at it. A few quick 
thoughts while you’re fresh will give you a great place to get the 
analysis started. 
Materials and tools
Design researchers used to have to walk up hills both ways in 
the snow and rig up a forensics lab to do a half-decent study. 
No more! It’s so easy now. It’s likely the essentials are scattered 
around your office, or already inside your messenger bag. (Of 
course, you can always use research as an excuse to go shopping 
at Spyville.com.)
Use what you already have first, and go for familiar tools. The 
trickiest parts of research often arise from technical difficulties 
and equipment learning curves. (The saddest research moment 
is accidentally erasing a session recording.) We are increasingly 
living in a cloud-based world, but a lot of research tools are 
platform-specific, most likely because of the audio and video 
features required. The most important consideration is that you 
select the tools and documentation that work for your team.
If you want to make things really easy on yourself, set up 
a research kit that’s ready to go at a moment’s notice, like a 
country doctor’s medical bag. You can also just have a checklist 
of things to grab. 
Applications and devices are popping up and disappearing 
every day, so it’s difficult to create a definitive list of what you 
need, but our favorite (currently available) research tools are 
listed in the Resources section in the back of the book.

 	
The Process	 47	
Interviewing
A simple interview remains the most effective way to get in-
side another person’s head and see the world as they do. It is a 
core research technique with many applications. Once you are 
comfortable conducting research interviews, you can apply this 
skill to any situation in which you need to extract information 
from another person.  
Being a good interviewer requires basic social skills, some 
practice, and a modicum of self-awareness. Introverts might 
want to start out as observers and notetakers, while extroverts 
may need to practice shutting up to let the other person talk.
In the research lingo, the type of interview covered in this 
book is a semi-structured interview, meaning that you will have 
prepared questions and topics, but not a strict script of questions 
to ask each participant in the same order and manner. This al-
lows more flexibility to respond to the individual perspective 
and topics that come up. You might find out some very useful 
things you would have never thought to ask.
A successful interview is a comfortable interaction for every-
one involved that yields the information you were looking for. 
The keys to success are preparation, structure, and conduct. (For 
more on interviewing, see Chapter 5.)
Usability testing
Usability testing is simply the process of conducting a directed 
interview with a representative user while they use a proto-
type or actual product to attempt certain tasks. The goal is to 
determine to what extent the product or service as designed is 
usable—whether it allows users to perform the given tasks to a 
predetermined standard—and hopefully to uncover any serious, 
resolvable issues along the way.
The sooner and more often you start doing it, and the more 
people on your team are familiar with the process, the more 
useful it is. You shouldn’t even think of it as a separate activity, 
just another type of review to ensure you’re meeting that set 
of needs. Business review. Design review. Technical review. 
Usability review. 

	
48 	 Just Enough Research
What usability testing does
If you have a thing, or even a rough facsimile of a thing, you can 
test it. If your competitor has a thing, you can test that to figure 
out what you need to do to create a more usable alternative. If 
you’re about to start redesigning something, usability-testing 
the current version can provide some input into what works 
and what doesn’t work about the current version. The test will 
tell you whether people understand the product or service and 
can use it without difficulty. This is really important, but not 
the whole story where a product is concerned. As philosophers 
would say, usability is necessary, but not sufficient. 
Usability testing can:
• Uncover significant problems with labeling, structure, mental 
model, and flow, which will prevent your product from suc-
ceeding no matter how well it functions.
• Let you know whether the interface language works for your 
audience.
• Reveal how users think about the problems you purport to 
solve with your design.
• Demonstrate to stakeholders whether the approved approach 
is likely to meet stated goals.
What usability testing doesn’t do
Some people criticize usability testing because aiming for a usable 
product is tantamount to aiming for mediocrity. But remember, 
usability is absolutely necessary, even though it is in no way 
sufficient. If your product isn’t usable then it will fail. However, 
usability testing won’t absolve you of your responsibilities as a 
designer or developer of excellent products and services. 
Usability testing absolutely cannot:
• Provide you with a story, a vision, or a breakthrough design.
• Tell you whether your product will be successful in the 
marketplace.

 	
The Process	 49	
• Tell you which user tasks are more important than others.
• Substitute for QA-testing the final product.
If you approach usability testing with the right expectations 
and conduct it early and often, you will be more likely to launch 
a successful product, and your team will have fun testing along 
the way. A habit of usability goes hand-in-hand with a habit of 
creating high-quality products that people like. 
No labs, no masters
We live in the future. There is no reason to test in anything 
called a “usability lab,” unless there’s a danger your experiment 
will escape and start wreaking havoc. A usability lab gives you 
the illusion of control when what you are trying to find out is 
how well your ideas work in the wild. You want unpredictability. 
You want screaming children in the background, you want glare 
and interruptions and distractions. We all have to deal with these 
things when we’re trying to check our balances, book travel, buy 
shoes, and decide where to go for dinner—that is, when we use 
products and services like the one you’re testing.
Go to where the people are. If you can travel and do this in 
person, great. If you can do this remotely, also good. If you’re 
testing mobile devices, ironically, you will need to do more 
testing in person.
Just like the corporate VP who is always tweaking the clip 
art in his presentation slides rather than developing his story-
telling skills, it’s easy for researchers (especially us introverted 
nerds) to obsess about the perfect testing and recording setup 
rather than the script and facilitation. Good participants, good 
facilitation, and good analysis make a good usability test. You can 
have a very primitive setup and still get a good result, identify-
ing as many usability issues as possible. Usability issues aren’t 
preferences and opinions, but issues that make a given design 
difficult and unpleasant to use. You are making the best use of 
your time if you are identifying the most significant issues in 
the least amount of time so that you can go back to the drawing 
board. (For more on usability testing, see Chapter 7.)

	
50 	 Just Enough Research
Literature review
Recruiting and observing or interviewing people one at a time 
is incredibly valuable. It can also be time-consuming. If it’s just 
not possible to talk to representative users directly, or if you’re 
looking for additional background information, you can turn 
to documented studies by other researchers. Both qualitative 
studies and surveys can increase your knowledge of the needs 
and behaviors you should consider. 
Sources include pre-existing research done by your own 
company or your client, published by a research consultant or 
by a research organization. Often organizations that serve spe-
cific populations, such as journalists or senior citizens, sponsor 
research and make it publicly available. 
The Pew Research Center’s Internet & American Life Project 
is a free and reputable source of data (http://bkaprt.com/jer/5/). 
As the name implies, the work focuses on Americans, but it’s a 
terrific place to start. Their work is typically survey-based, and 
good for thinking about trends. (Also, their reports are a good 
model for communicating clearly about research.) 
You can use these studies in a few ways:
• To inform your own general understanding of your target 
users and help you formulate better questions.
• To validate general assumptions.
• To complement your work.
When working with third-party literature, take these grains 
of salt:
• Note the questions they were asking and determine to what 
extent they align with your own.
• Check the sample and note the extent to which it maps to 
your target user base.
• Check the person or organization conducting and underwrit-
ing the study, so that you can note their biases.
• Check the date to note whether anything significant has 
changed since the research was done, such as a new product 
launch or shift in the economy.

 	
The Process	 51	
5. Analyze the data
What does it all mean? Once you have collected the data, gather 
it all together and look for meaningful patterns. Turn the pat-
terns into observations, and from those, recommendations will 
emerge. 
Refer to your initial problem statement and ask how the 
patterns answer the questions you originally posed. You can 
use the same qualitative data in different ways and for different 
purposes. For example, stakeholder interviews might yield busi-
ness requirements for a redesign and a description of the current 
editorial workflow that you can use as inputs to the content 
strategy. Usability testing might indicate issues that need to be 
fixed, as well as data about current customers that you can use 
to develop personas.
Returning to data from previous studies can yield new in-
sights as long as the conditions under which they were con-
ducted remain relevant and new questions arise.
Get everyone involved
If you are working with a design team, get as many members 
as possible involved in the analysis. A group can generate more 
insights faster, and those insights will be shared and internal-
ized far more effectively than if you simply circulated a report. 
Rule of thumb: include people who are able to contribute to 
a productive session and will benefit from participating. Exclude 
people who will be a distraction, or who will benefit more from 
reviewing the results of the analysis. 
At a minimum, include everyone who participated directly 
in the interview process. In the best-case scenario, involve the 
entire core project team—anyone who will be designing or 
coding. Working together to examine specific behaviors and 
concerns will help your team be more informed, invested, and 
empathetic with users from the start. At the end of the session, 
you can decide which outcomes from the analysis would be 
most useful to share up and across. 

	
52 	 Just Enough Research
Structuring an analysis session
Analysis is a fun group activity. You get into a room with your 
team, review all the notes together, make observations, and turn 
those into actionable insights. Expect this to take anywhere 
from half a day to a few days, depending on the number and 
extent of the interviews. It will save time if you give all the 
participants advance access to the notes or recordings so they 
can come prepared.
Even if the session includes only one interviewer and one 
notetaker, it’s useful to follow an explicit structure to make sure 
that you cover everything and work productively. Here’s a good 
baseline structure. Feel free to modify it to suit your project’s 
needs:
1.	Summarize the goals and process of the research. (What did 
you want to find out? Who from your side participated and 
in which roles?)
2.	Describe who you spoke with and under which circum-
stances (number of people, on the phone or in person, etc.).
3.	Describe how you gathered the data.
4.	Describe the types of analysis you will be doing.
5.	Pull out quotes and observations. 
6.	Group quotes and observations that typify a repeated pattern 
or idea into themes; for example “participants rely on pen 
and paper to aid memory,” or “the opinions of other parents 
are trusted.”
7.	Summarize findings, including the patterns you noticed, the 
insights you gleaned from these patterns, and their implica-
tions for the design.
8.	Document the analysis in a shareable format. 
This work can get a little intense. To proceed smoothly and 
stay focused, require everyone who participates to agree to the 
following ground rules. (Feel free to add house rules of your own.)
• Acknowledge that the goal of this exercise is to better un-
derstand the context and needs of the user. Focus solely on 
that goal. 

 	
The Process	 53	
• Respect the structure of the session. Refrain from identifying 
larger patterns before you’ve gone through the data. 
• Clearly differentiate observations from interpretations (what 
happened versus what it means).
• No solutions. It will be very tempting to propose solutions. 
Stick to insights and principles. Solutions come next.
What you’ll need
Sufficient time and willing colleagues are the most essential as-
sets for solid analysis. If you have those, just gather a few more 
additional office supplies:
• A big room with a lot of whiteboard wall space.
• Sticky notes (in different colors if you want to get fancy).
• Pens.
• A camera so you can take pictures of the whiteboard, walls of 
notes, etc., rather than copy everything down. (Also, photos 
of the session are fun for project retrospectives and company 
stock photography. “Look, thinky collaborative work!”)
Feel free to group your observations in a number of different 
ways until your team reaches agreement on the best groupings. 
By user type, by task type, by importance for product success are 
just a few potential groups. The most useful groupings are based 
on patterns that emerge, rather than those imposed or defined 
at the start before beginning analysis. If necessary, assign a time 
limit and take a vote when time is up. 
What is the data?
You are looking for quotes and observations that indicate:
• Goals (what the participant wants to accomplish that your 
product or service is intended to help them with or otherwise 
relates to).
• Priorities (what is most important to the participant).
• Tasks (actions the participant takes to meet their goal).
www.allitebooks.com

	
54 	 Just Enough Research
• Motivators (the situation or event that starts the participant 
down the task path).
• Barriers (the person, situation, or thing that prevents the 
participant from doing the task or accomplishing the goal).
• Habits (things the participant does on a regular basis).
• Relationships (the people the participant interacts with when 
doing the tasks).
• Tools (the objects the participant interacts with while fulfill-
ing the goals).
• Environment (what else is present or going on that affects the 
participant’s desire or ability to do the tasks that help them 
meet their goals).
Outliers
No matter how rigorous your screening, some outliers may have 
gotten through. You will know that a participant was an outlier 
if their behaviors and attributes would rule them out as a target 
user. If you have interviewed people who don’t match your 
design target, note this fact and the circumstances for future 
recruiting and set the data aside. 
For example, imagine that as a part of our museum project, 
we interviewed “Dan,” a sixty-five-year-old man, who demon-
strated no interest in science or technology and who isn’t a 
museum goer. He uses the computer his son set up for him to 
read the news and sports from the town he grew up in across 
the country, and he spent most of the interview arguing against 
the political views of the entrepreneur who funded the museum.
Given that our target users are school-age children and their 
parents, science teachers, single young adults in the local area, 
and retired technology enthusiasts, Dan doesn’t fit any of these. 
Nor does he indicate a previously unknown potential user type 
we should address. There is no reason to accommodate any of 
Dan’s stated needs or priorities in our design because there is 
no overlap between his needs and the museum’s goals. So, his 
data falls outside the patterns we’re looking for. 
There will be some people who would never realistically use 
your product. Don’t try to accommodate them in your model 
just because you talked to them.

 	
The Process	 55	
6. Report the results
The output of the analysis session is generally a summary report 
and one or more models. (See Chapter 8 for more detail on these 
various models.) The type of reporting you need to do depends 
on how decisions will be made based on the results. Within a 
small, closely knit team you can document more informally than 
if you need results to influence executive decision-making at a 
larger organization. 
Given good data, a quick sketch of a persona or a photo 
of findings documented in sticky notes on a whiteboard in a 
visible location is far superior to a lengthy written report that 
goes ignored. Always write up a brief, well-organized summary 
that includes goals, methods, insights, and recommendations. 
When you’re moving fast, it can be tempting to talk through 
your observations and move straight to designing, but think of 
your future self.  You’ll be happy you took the trouble when you 
want to refer to the results.
And repeat
The only way to design systems that succeed for imperfect 
humans in the messy real world is to get out and talk to people 
in the messy real world. Once you start researching, you won’t 
feel right designing without it.

	
56 	 Just Enough Research
4
Organizational 
Research
“Hell hath no fury like a bureaucrat scorned.”
—Milton Friedman
You’re an individual with a goal. If you’re a designer, you proba-
bly want to create something new that delights other individuals 
and becomes personally important to them. Designs that change 
the world do so because millions of individuals adopt them. 
Design doesn’t happen in the deep, cold vacuum of space. 
Design happens in the warm, sweaty proximity of people with 
a lot on their minds. People create and join organizations to 
accomplish greater things more efficiently. As an organization 
grows, it becomes more complex. The oral culture of how to 
get things done begins to outstrip the documentation. Various 
internal groups might develop different perspectives on high-
level goals, or even different goals entirely. Essential relation-
ships develop that don’t map to any org chart. 
A design project is a series of decisions, and making sure the 
right decisions get made can seem tricky in a complex organi-
zation. Take heart. You have more influence than you might 

 	
Organizational Research	 57	
think, as long as you take the opportunity to understand the 
inner workings. 
It’s inescapable that the nature of an organization matters to 
the design process. Budgets, approvals, timing, and resource 
availability can all depend on successfully negotiating an orga-
nization. The ultimate success of a product or service depends 
on how well it fits into everything else the organization is doing 
and how well the organization can and will support it. 
The habits of organizations and the people within them can 
be powerful. You’ll be working directly with other individuals, 
but how you work with them will be more or less successful 
depending on your understanding of the organization.
Think of an organization as physical terrain. A small start-
up is like an island. It might spring up out of nowhere and sink 
down under the waves just as quickly, but for the duration of 
its existence, you can get a clear view of the landscape pretty 
quickly. A large corporation is more like Australia: it’s impossible 
to see the whole landscape at once and there are so many things 
capable of maiming or killing you.
Fortunately, at any size, an organization is just a set of indi-
viduals and a set of rules, explicit and implicit. Once you under-
stand that environment, you’ll be able to navigate it and create 
the best possible product.
Put an MBA out of work
Organizational research—determining what drives a business, 
how all the pieces work together, and the extent of its capacity 
for change—is traditionally the purview of business analysts. 
However, researching an organization is very similar to tradi-
tional user research and can be incredibly helpful to interactive 
design and development projects.
Most user-centered design studios interview client stakehold-
ers—people whose jobs or roles will be directly affected by the 
outcome of the project—as a part of the standard requirements-
gathering process. Doing this is essential when you’re coming 
in cold to work with an unfamiliar organization.

	
58 	 Just Enough Research
Internal teams may have to do a bit of role-playing to gather 
the same information: “Talk to me about how you interact with 
other members of the marketing team as though I don’t work 
here and we’re speaking for the first time.”
 (Throughout the research process you may be in the posi-
tion to offer fictional or counterfactual scenarios to participants, 
asking them, for example, to imagine they want to renew their 
membership in the Fantastic Amateur Genetic Engineering 
Club. You will find that people are frequently quite suggestible. 
When you run into participants who resist going along, that is 
often an indicator of some deeper issue worth probing, obliquely 
and tactfully, of course. The question to answer is why that in-
dividual resists your potential scenario. Maybe some potential 
museum visitors are skeptical about the very idea of amateur 
genetic engineering.)
In organizational research, the observer effect can actually 
be a force for positive change. Asking hard questions of people 
throughout an organization will force those people to come 
up with answers, leading to at least a modicum of reflection. 
Asking the same question of different people will reveal crucial 
differences in motivation and understanding. And listening to 
people who might not feel heard is a fantastic source of goodwill. 
Asking a lot of questions can also make you sound quite smart.
If you are at a smaller, more nimble organization, such as a 
very early-stage or rapidly growing startup, the enemies aren’t 
complexity and stasis. Rather, you may have to contend with 
the desire to maintain momentum and “fail fast.”
Alternatively, to support “not failing at all, if we can avoid it,” 
identify the assumptions that pose the greatest risk and suggest 
activities to address those assumptions. Design Staff (http://
bkaprt.com/jer/6/) is your ally. This excellent product design and 
research blog is written by the Google Ventures Design Studio 
team specifically for startups. 
As for how to go about organizational research, it’s pretty 
straightforward and covers the same principles discussed in the 
previous chapter. The major difference is that you’re talking to 
current stakeholders instead of potential customers.

 	
Organizational Research	 59	
Who are stakeholders?
The stakeholder concept emerged in a 1963 internal memoran-
dum at the Stanford Research Institute (http://bkaprt.com/jer/7/). 
It defined stakeholders as “those groups without whose support 
the organization would cease to exist.” Your research should 
include anyone without whose support your project will fail. 
This might include executives, managers, subject matter experts, 
as well as staff in various roles. Be generous in your selection. 
A few additional hours in conversation will help ensure you’re 
both well informed and protected from an overlooked stake-
holder popping up too late. 
Executives
The leaders will help you understand the overall company mis-
sion and vision and how your project fits into it. 
Managers
Managers will frequently be concerned with resource alloca-
tion and how your project affects their incentives, monetary or 
otherwise, and their ability to do the work.
Subject matter experts
These are people who have specialized knowledge about the 
industry or business. You can find them by identifying those  
design-critical areas where you have the least background 
knowledge and by asking for introductions. They’ll provide 
you with essential background information.
Staff in various roles
Overlap with the subject matter experts. You will need to balance 
out the executives with people who do the day-to-day work. In 
particular, find anyone who has knowledge of the end users. 
Customer service people and salespeople are as valuable as they 
are overlooked. 

	
60 	 Just Enough Research
Investors and board members
In some organizations the board members are either influential 
or highly knowledgeable. In others, they are more removed and 
of less utility. Inquire about level of interest or concern with the 
project before arranging a conversation.
Interviewing stakeholders
“Interviews with project stakeholders offer a rich source of insights 
into the collective mind of an organization. They can help you 
uncover areas of misalignment between a company’s documented 
strategy and the attitudes and day-to-day decision-making of 
stakeholders. They can also highlight issues that deserve special 
consideration due to their strategic importance to a business.”
—Steve Baty, “Conducting Successful Interviews with Project Stakeholders”  
(http://bkaprt.com/jer/8/)
The term stakeholder is a bad bit of jargon, but there really 
isn’t a better alternative. Think of them as people who could 
potentially put a sharp stick in your back unless you get them on 
your side. But don’t fear them! Stakeholder interviews—sitting 
down individually with people who will be directly affected by 
the project—have many benefits.
What stakeholder interviews are for
Hearing the same issues considered by people in different roles 
relative to your work will give you a much more complete 
perspective and great insights. Some individual interviews are 
valuable on their own, and some higher-level insights are only 
possible in the aggregate. 
For example, the Fantastic Science Center’s marketing direc-
tor might actually know a lot about visitor behavior, or know 
where the organization has been making a lot of assumptions. 
Or you might find out from customer service that potential 
museum visitors have been expressing a set of needs that the 
marketing department doesn’t know about at all. This means 

 	
Organizational Research	 61	
you have one great insight about potential visitor needs, and 
another one about an organizational disconnect.
Stakeholder interviews will help you understand the essential 
structure of the organization, how your work fits into the orga-
nization as a whole, and the approval process for various aspects 
of your project. They’ll also provide you with some less obvious 
opportunities to influence your project’s chances of success.
Neutralizing politics 
Organizational politics are a depressing reality in most compa-
nies. If you pretend they don’t exist, you’re in for a world of 
pain. A significant benefit of organizational research is political. 
You don’t want your hard work to get trampled in a turf war 
you didn’t know existed. 
You may find that someone in the organization is deeply op-
posed to your work. If you know why, you may be able to get 
them on your side. Talking with stakeholders is an excellent 
opportunity to sell people on the value of your work in terms 
that matter to them. 
Better requirements gathering
Business requirements are frequently defined as though the 
project were taking place in a frictionless ideal state, but the ap-
plication you’re developing doesn’t exist in a vacuum. You have 
your own reasons for wanting to build or design it in a certain 
way. Similarly, you need to understand how your work might 
solve or create problems throughout the organization, and how 
the organization will prioritize those problems and solutions. 
It’s shocking how many projects get underway lacking clear, 
or even any, business requirements. How do you know whether 
your work has succeeded? If it’s fully functional? If the users 
are happy? If your work doesn’t support the business, you have 
failed, no matter how good the design. 
Don’t forget to inquire into technical requirements and take 
the time to locate anyone who might have particular knowledge 
about them. 

	
62 	 Just Enough Research
Understanding organizational priorities
How important is the work to the organization, really? The 
answer might be surprising. It makes a big difference whether 
the project at hand is genuinely valued by the organization. At 
Mule, we have a maxim based on repeated observation: the more 
important a project is to an organization, the more successful 
it will be. There might be a higher stress level among people 
working on an absolutely critical, number one priority project, 
but you can be more sure that the people working on it will be 
giving it their full attention. 
Tailoring the design process
Maybe you’re going to be using the same process you always use. 
There is some efficiency in doing that. Someone will say, “Let’s 
not reinvent the wheel.” But you should make sure that you’re 
using the right tires for the terrain ahead. During interviews, 
make sure to ask about the typical workday as well as how 
decisions are made within the team and the organization. This 
is especially critical if the project at hand brings together cross-
functional teams, or teams who have never worked together 
before, or an internal team and one or more outside vendors. 
You might find that one group is highly collaborative or 
consensus driven in their decision-making and another has an 
autocratic leader. Since the design team might be in a place to 
define the decision-making structure that everyone has to fol-
low, your life will be a lot easier if you adapt your process to 
existing work styles rather than try to change ingrained habits. 
Your project manager will thank you. 
Getting buy-in from stakeholders
For the definitive word on making influential people feel heard, 
I encourage you to read Paul Ford’s excellent essay “The Web 
Is a Customer Service Medium” (http://bkaprt.com/jer/9/). Here 
is the heart of it:

 	
Organizational Research	 63	
“Why wasn’t I consulted,” which I abbreviate as WWIC, is the 
fundamental question of the web. It is the rule from which 
other rules are derived. Humans have a fundamental need to be 
consulted, engaged, to exercise their knowledge (and thus power).
Asking someone for input before you get started is a peerless 
prophylactic against that person rearing up late in the game with 
insurmountable objections. Inquiry is flattery. Inviting people 
to participate empowers them.
Take it from the stalkers and internet trolls. Never underesti-
mate the ability of a single individual—no matter how seemingly 
unimportant or obscure—to really fuck things up for you once 
they set their mind to it. 
What are your assumptions about how the organization func-
tions, about how different disciplines interact, about what the 
workflow is and how well it’s working, about how much people 
know or need to know about what you’re doing? Now think of 
the worst-case scenario if you’re wrong. What happens if mar-
keting doesn’t understand how your work supports the brand, if 
the salespeople can’t see the benefits, if the production team has 
no incentive to give you any of their time? This is your oppor-
tunity to educate as well as listen, and to get everyone on board.
Understanding how your work affects the organization
Your work will affect everyone in an organization, even those 
who don’t directly use the product, service, or system you’re 
designing on its behalf. Executives will have to defend it as a part 
of the overall strategy. Customer service will have to support 
it. Salespeople will have to sell it. Production staff will have to 
maintain it.
The purported customers or audience members are not the 
only users of the product you’re building. Founders may be us-
ing it as proof of concept to raise more capital from investors. 
Salespeople may rely on prospects interacting with it before 
they can close the deal. Company representatives might expect 
to be asked questions about it when they’re out at conferences. 
www.allitebooks.com

	
64 	 Just Enough Research
You’ll benefit from gaining their perspectives and knowing their 
priorities in that regard. 
Don’t wait for people inside the organization to come to you, 
and don’t rely on a higher-up to tell you who to talk to. Based 
on the goals of this project, it’s up to you to determine whose 
input you need.
If you are creating something new, the very existence of the 
new system will require everyone in the organization to change. 
Similarly, those people will affect what you’re creating. Even 
if you’re the sole author of an application, you require the par-
ticipation of others for it to succeed. 
You can identify which people or departments will have to 
put in the time, effort, money, and other resources to cope with 
the changes. You can learn whether the resources will be avail-
able or whether the organization will need to buy more servers 
or hire more writers. 
Understanding how what you’re proposing to build relates to 
the organization responsible for it means that you can anticipate 
changes to workflow and minimize them where possible, or 
prepare people for changes when they’re necessary. 
Once you inform the organization how much work it will 
take to accommodate your project, you’ll find out whether you 
in truth lack the organizational support you need and thought 
you had. Then you can make decisions based on that knowledge, 
rather than have good work wither on the vine, neglected. 
Understanding workflow
Workflow is the set of processes through which complex work 
gets done. Unless you’re the sole developer of this application, 
your work doesn’t happen in an organizational vacuum. It has 
to fit into the work that everyone else is doing. You need to take 
into account the ways that design and development decisions 
will affect operations, and make very intentional decisions and 
recommendations based on that. You’ll also need to identify 
whether similar, complementary, or competing work is going 
on within the organization. 

 	
Organizational Research	 65	
Sharpen your tact
Build a wide list of people to interview: founders, executives, 
managers, technical staff, customer service, etc. Then prioritize 
it. In addition to people who are directly valuable to the proj-
ect, you will likely have to speak with some for purely political 
reasons. This is also an opportunity for learning. 
The maximum number of interviewees is the number you 
actually have time to talk to. In some large organizations where 
the project touches on many types of expertise, you might find 
yourself talking to dozens on an exciting voyage of discovery. 
Have a firm idea of how much time you have and stick with it. 
Once you have your list of people, find out as much about 
them as possible, just as you would in preparing for a job in-
terview. Use the information you find to inform your line of 
discussion, but avoid leading with any tidbit your subject would 
not expect and welcome to be common knowledge. “So, you 
transferred to this department because you were passed over 
for a promotion...” will not make you any friends. 
Individual interviews
As a rule, and as time permits, it’s best to interview stakehold-
ers individually. The more political an organization, the more 
important private conversations are to get an accurate picture 
of the organization. You may have to fight a manager who “just 
wants to sit in.” This sentiment indicates some combination 
of fear and curiosity—fear that you’ll be gossiping behind that 
person’s back, and curiosity about what will be said. Explain 
the observer effect—that person’s presence is likely to change 
the responses—and hold your ground. You’ll need to assure the 
interviewee that their answers will not be directly attributed and 
assure the interested parties that they will get all the information 
they need in an aggregated report. 
Group interviews
If there’s a group of people of roughly equal influence who work 
together closely and share the benefits and risk of the project at 

	
66 	 Just Enough Research
hand, you may save time by talking to them together. During the 
discussion, take care to note whether anyone seems particularly 
reticent. Follow up with that person with a quick note to give 
them an additional opportunity to give you information. 
Email interviews
In a pinch, for a stakeholder who is remote or impossible to get 
time with, it’s better to send a few key questions via email than 
not get any information from them at all.
Interview structure
Each interview should be thirty minutes to an hour long. Make 
sure to talk in a private place. 
The interviewer should be a calm and confident person, pref-
erably someone who is genuinely very interested in what these 
people have to say. The conversation should flow naturally. If 
you don’t quite understand something, ask for clarification, or 
ask the subject to repeat what they said. 
Have someone else taking notes so that the interviewer can 
focus on the conversation. You can record the conversation, 
but this may make the interview subject more nervous about 
speaking freely. The most important thing is for them to feel 
comfortable talking honestly and openly. 
Put the participant at ease and demonstrate respect for their 
time. Send an agenda and the key questions ahead—not all 
the questions, but the ones the participant will benefit from 
knowing in advance. More complex topics might require some 
forethought. It’s best to avoid making people feel ambushed or 
unprepared. 
The basic flow of a stakeholder interview is as follows:
• Introduce yourself and restate the purpose of the meeting. It 
should be something like: “We’re starting to work on a com-
plete redesign of the Fantastic Science Center website and we 
want to get your input. We’ll use your input to make sure that 
the design meets your needs as well as those of the visitors.” 

 	
Organizational Research	 67	
• Explain to what extent the information will be shared, by 
role or business function. “Please feel free to be totally frank. 
Honest answers are essential to this process. We’re talking to 
people throughout the organization, and will group answers 
together rather than focusing on what one person said. If we 
use a direct quote, we will not attribute it to you personally.”
• Like a good journalist, don’t narc on your sources. Get some-
thing in writing from the person directing or approving this 
research, stating that people can speak freely without fear 
of reprisal.
Ask questions and let the conversation follow its natural 
course. It’s very important to keep the interview feeling infor-
mal. It’s not an interrogation. 
At the end of the interview restate how you’ll use the infor-
mation and verify the level of the participant’s participation 
throughout the project. You definitely want to make sure that 
your expectations match. Make sure that it’s OK to follow up if 
you need more information or clarification.
In addition to name and title, these are the basic questions 
you’ll want to ask:
 
• How long have you been in this role?
• What are your essential duties and responsibilities?
• What does a typical day look like?
• Who are the people and teams you work most closely with? 
How well is that relationship working?
• Regarding the project we’re working on, how would you de-
fine success? From your perspective, what will have changed 
for the better once it’s complete?
• Do you have any concerns about this project?
• What do you think the greatest challenges to success are? 
Internal and external?
• How do you expect your interactions with other people 
inside or outside this organization will change based on the 
outcome of this project?

	
68 	 Just Enough Research
Then, there are the more specific questions that depend on 
the project. Stakeholders may themselves be users, often of 
back-end systems or administrative functions:
• What are your most common tasks with the system?
• What problems have you noticed?
• What kinds of work-arounds do you use?
• Have you any concerns about this project?
• Is there anyone else I should talk to?
Dealing with a hostile witness
It’s in the name. Stakeholders have a personal stake in the pro-
cess or outcome of the project. They might be in competition 
for resources, or they might have a larger or smaller workload 
if the project is successful. 
Stakeholder interviews tend to be interesting when they 
go well. People enjoy being consulted and treated as experts. 
However, sometimes stakeholder interviews take a turn for 
the ugly. This can be very unpleasant, particularly when you’re 
interviewing in person. The participant you’re interviewing will 
turn the tables and start attacking the process, or you personally. 
They may start questioning the value of what you’re doing or 
even say they don’t understand the questions you’re asking. If 
this happens, remain calm, take a deep breath, and attempt to 
get the interview back on track. Restate your goal, ask if that is 
clear, and then try asking a very general open-ended question 
about what the participant thinks is most important for you to 
know in the service of this goal. Depending on the reason for 
the hostility, you may just want to cut the interview short. 
Common reasons for stakeholder resistance or hostility:
• The stakeholder wasn’t sufficiently informed or prepared for 
the process and is suspicious of the motives, or just confused 
about why they were asked to participate. 
• It’s a power move. This individual wants to establish domi-
nance over you or, by extension, over the person who autho-
rized the interview or the project as a whole. 

 	
Organizational Research	 69	
• The stakeholder is under pressure to perform in some other 
area and doesn’t see a benefit from participating. This is 
common when interviewing salespeople who are wasting 
precious time when they could be selling and earning com-
missions. You have taken them “off the floor.”
Try to determine in advance whether any of the stakehold-
ers you plan to interview are at risk for a hostile reaction. Make 
sure that they know why you’re asking them to participate, how 
they need to prepare, how long it will take, and the reasons why 
their participation is essential to the process. Flattery usually 
goes a long way. 
Remaining calm and confident is essential. Never let anyone 
bully you when you’re gathering information that’s essential to 
your work. Make sure that you’re prepared to clearly describe 
the process and justify its value. 
Do not let them take control of the interview from you. While 
listening to someone go on a rant about what isn’t working can 
be interesting and useful, it’s up to you to guide the conversation.
Practice, practice, practice. If you’re new to doing these sorts 
of interviews, practice with members of your team before doing 
it for real. Have them throw in some challenging or unproduc-
tive responses:
• “Why are you asking me this?”
• “I don’t understand that question. It doesn’t make any sense.”
• “I don’t feel comfortable talking to you about that.”
• “No one pays attention to anything I have to say, so I don’t 
know why I should bother talking to you.”
• “How much more time is this going to take?”
Documenting interviews
For each stakeholder, note the following:
• What’s their general attitude toward this project?
• What’s the goal as they describe it?

	
70 	 Just Enough Research
• To what extent are this person’s incentives aligned with the 
project’s success?
• How much and what type of influence do they have?
• Who else do they communicate with on a regular basis?
• To what extent does this stakeholder need to participate 
throughout the project, and in which role?
• Is what you heard in harmony or in conflict with what you’ve 
heard from others throughout the organization?
Just enough
You’ve interviewed enough people when you feel confident 
that you know:
• Who all the stakeholders are.
• Their roles, attitudes, and perspectives.
• Their levels of influence, interest, and availability over the 
course of the project.
• How they stand to benefit or suffer with the success or failure 
of your work.
• The likelihood that any of them have the power or potential 
to prevent project success.
• All the ways that the workflow will have to change to make 
your project a success.
• The resources you have available for your project process.
• The resources required to support your project once it’s 
complete.
• All the business requirements and constraints.
• Whether your team and core stakeholders agree on the goals 
and definition of success.
• Whether the stated goals are the real shared goals, or whether 
anyone has a hidden agenda.
• How people outside the project team view this project.

 	
Organizational Research	 71	
What to do with stakeholder analysis
Stakeholder analysis can be pretty straightforward. If you’re in-
terviewing members of the organization as users of the system, 
refer to the ethnographic methods in Chapter 5. 
Create a clear statement of what you need to accomplish for 
the project to be considered a success by the organization. These 
are the business requirements. Design and development are how 
you satisfy the business requirements. It’s best if everyone who 
cares about the project agrees. 
The goal of gathering and documenting business require-
ments is to ensure that all the stakeholders agree on the purpose 
and limitations of what you’re doing. You want to increase your 
chance of success, connect what you’re doing to the goals of the 
business, increase collaboration, and save costs, particularly 
those associated with changes. Note that business strategy must 
remain constant for the duration of a project. 
Requirements must be:
• Cohesive. The requirements all refer to the same thing.
• Complete. No missing information. No secret requirements 
that didn’t make it onto the list. 
• Consistent. The requirements don’t contradict each other. 
• Current. Nothing obsolete. 
• Unambiguous. No jargon. No acronyms. No opinions. 
• Feasible. Within the realm of possibility on this project.
• Concise. Keeping them short and clear will increase the 
chances that they are read, understood, remembered, and 
used. Aim for no more than two to three pages.
The document should not contain specific solutions or design 
requirements. The type of organization determines the level of 
detail required in the business requirements documentation. 
Depending on the political situation at the company for whom 
you’re conducting the research, you may have one version for 
the core team and a more summarized (or polite) report for 
broader distribution.

	
72 	 Just Enough Research
What to include in your documentation
Problem statement and assumptions
What needs to be solved or improved from a business perspective?
Goals
Every project begins with a rough set of goals, or concepts of 
success. Every individual in an organization sees them a little 
bit differently. Gathering these and reconciling them is essential 
to a functioning project. 
Success metrics
What are the qualitative and quantitative measurements that 
tell you whether the project is hitting the mark? These should 
support the goals.
Metrics can include things like “boosts reputation of Fantastic 
Science Center among peers,” or “increases online sales in the 
store thirty percent by the six-month point.”
Completion criteria
How will you know you’re done? It may seem obvious, but it’s 
always good to validate. Otherwise, the project will never be 
finished!
Scope
Scope refers to the amount of work included in any project. 
“Scope creep” is what happens when more work just keeps 
getting tacked on and the scope grows uncontrollably. The best 
way to avoid scope creep is to document what is included in as 
much detail as possible and in language everyone understands. 
(Historically, designers and engineers have sparred mightily over 
the definition of a “template.”) And note who is responsible for 
what. Scope is a boundary, so it’s also very useful to note that 
which any of the stakeholders might assume to be included but 

 	
Organizational Research	 73	
is out of scope. Not touching the logo this time around? Note 
that! Not changing the registration process? Write it down. 
Detailed scope documentation makes for happy teams and func-
tional projects. 
Risks, concerns, and contingency plans
Want to increase your chances of project success? Then ac-
knowledge anything you’ve uncovered that might lead to failure 
or unmet expectations. 
A designer conducting research might pick up on a lot of 
information that matters to the project process as well as to the 
design approach. Some organizations are more functional and 
well resourced than others. Every organization has its chal-
lenges. If the team understands and acknowledges these, they 
will be able to work around them more effectively. Maybe key 
decision-makers will have limited availability. Or perhaps two 
departments who need to collaborate very closely have histori-
cally had a poor working relationship. 
All of this information gathering will allow you to anticipate 
potential problems before they arise. This is an area in which 
the practitioners (designers, writers, developers, etc.) and project 
managers should collaborate very closely. If these challenges are 
not openly acknowledged, which is sometimes the case, be very 
sensitive in how you talk about them. For your work to succeed, 
you have to address them. 
For example, you might find that the Fantastic Science Center 
media relations department is unavailable through the end of 
the year because of a big event, but you’re required to get ap-
proval from the head of media relations on several aspects of 
the design. This is a terrific thing to know about in advance so 
you can plan around it.
Getting everything done on a tight schedule is often a major 
shared concern. A clear, simple—and, most importantly—pub-
licly documented process for gathering feedback and making 
decisions helps everyone stay on track.  And, if you have heard 
different concerns from different groups, it’s best to address that 
head-on. The need to keep the total project cost down might 
be what you heard from operations, while the product team 

	
74 	 Just Enough Research
3. Drafts 
campaign copy
6. Sends approved
    design
7. Pushes
campaign live
Editor
Designer
VP Marketing
Writer
4. Collaborate on
    campaign design
Producer
1. 
Se
nd
s 
br
ie
f
2.
 A
ss
ig
ns
 b
ri
ef
5. 
Fe
ed
ba
ck
 &
 a
pp
ro
va
l
Fig 4.1: A workflow diagram can describe the current situation or illustrate your 
recommendation based on what you’ve learned about the organization.

 	
Organizational Research	 75	
mentioned the need to have a user experience that compares 
favorably to a major competitor. The most appropriate solution 
will address both. Maybe it requires focusing on the highest-
priority features to be identified through user research. 
Verbatim quotes
The specific words used are highly valuable in revealing an in-
dividual’s personal perspective and attitudes. If possible, share 
these without attaching identifying information.
Workflow diagrams
Who will need to be told about how things have changed and 
in what format? A workflow diagram is a good companion to 
this document (Fig 4.1). 
If you’re working on an internal project or a new customer-
facing product that’s likely to change internal workflow, diagram 
the current and proposed workflows. Throughout the project, 
you can use these diagrams to track any workflow ramifications 
and make sure that the organization is changing sufficiently to 
accommodate the new design.
Unpack the baggage
A solid understanding and honest assessment of an organization 
and its business is necessary for the success of any significant 
design project. Organizational habits and capabilities are just as 
relevant as target user behaviors and needs, although they’re less 
frequently included as fundamental topics of design research. 
And the true nature of workflow and interpersonal relationships 
is just as ripe for ethnographic exploration.
Even just the process of conducting research can be beneficial 
if only because it provides the motivation to open atrophied 
or nonexistent communication channels. Performed with tact 
and rigor, organizational research can neutralize politics, clarify 
requirements, and improve the odds that changes will be fully 
understood and take hold.

	
76 	 Just Enough Research
5User Research
“Doctor: ‘What are you doing here, honey? You’re not even old 
enough to know how bad life gets.’ Cecilia: ‘Obviously, Doctor, 
you’ve never been a thirteen-year-old girl.’”
—The Virgin Suicides
As a designer, you have an enormous, exciting responsibility. 
You define the human world, one object or system at a time. 
Every delightful and every frustrating artifact that exists, exists 
because of a series of design decisions. 
Design as a job is similarly delightful and frustrating. Whatever 
you create has to work for a diverse array of people who may 
not be anything like you. Your work must be sufficiently novel 
to attract attention while fitting into each user’s existing world 
of objects and situations  over which you have no control. How 
do you create one design that solves a problem for an endless 
combination of people and environments? 
You do user research to identify patterns and develop empa-
thy. From a designer’s perspective, empathy is the most useful 

 	
User Research	 77	
communicable condition: you get it from interacting with the 
people you’re designing for.
When we talk about user research as distinguished from  
usability testing, we’re talking about ethnography, the study of 
humans in their culture. We want to learn about our target users 
as people existing in a cultural context. We want to understand 
how they behave and why. This is very different from gathering 
opinions. It isn’t just surveying or polling. And it’s definitely not 
focus groups.
Ethnographic design research allows design teams to:
• Understand the true needs and priorities of your customers/
readers/target audience/end users.
• Understand the context in which your users will interact with 
what you’re designing.
• Replace assumptions about what people need and why with 
actual insight. 
• Create a mental model of how the users see the world.
• Create design targets (personas) to represent the needs of the 
user in all decision-making.
• Hear how real people use language to develop the voice of 
the site/application.
Everything in context
For you to design and develop something that appeals to real 
people and reflects their priorities, you’ll need to talk with or 
observe representative users directly in their context—their 
regular environment. This reduces your risk of making bad as-
sumptions based on your own experiences, hopes, or subjective 
preferences. That context includes the physical environment, 
mental model, habits, and relationships.
Physical environment
This is the physical context in which someone will use your 
product or service. This could be at their office at a desk, at 
home on the sofa, at home at a kitchen table, or outside in an 

	
78 	 Just Enough Research
unfamiliar city. Is your target user likely to be alone, or sur-
rounded by others, subject to interruptions? Needs can change 
vastly with setting. 
Mental model
A mental model is an individual’s pre-existing internal concept 
of and associations with any given institution, system, or situ-
ation. Every one of us has an imperfect, idiosyncratic map of 
reality in our head. Without it, we would be utterly lost. With 
it, we rely on assumptions based on previous experiences we 
consider analogous. The better the analogy, the more useful 
the map. This is why interfaces that strive for novelty are often 
unusable. With no hooks into an existing mental model, we have 
to figure things out from scratch. 
In the course of designing a new website for the Fantastic 
Science Center, it would be helpful to understand our target 
audience’s mental model of such institutions. What do they 
expect, and how do those expectations make it more or less 
likely that they would interact with the website in the ways we 
want them to?
Habits
This includes habits of body and mind. How does the user 
already solve the problem you are trying to solve for them, if 
indeed they do? We frequently hear from entrepreneurs that are 
trying to create a habit around a new product. Habits are hard 
to change, as anyone trying to kick one will attest, but inserting 
a new hook into an existing habit is much easier. 
For a science museum website, relevant habits might include 
their current weekend activities, or the sources of information 
they rely on for entertainment, education, events, or keeping up 
to date on technology changes. Social and collaborative decision-
making would be another interesting area for exploration. The 
concepts and associations that form the user’s mental model of 
weekend activities, that web of familiar meanings, could po-
tentially provide the bridge to creating new habits around this 
particular institution.

 	
User Research	 79	
Relationships
Social networks are merely the most obvious intersection of 
human relationships and digital products. People are social ani-
mals and every interactive system has an interpersonal compo-
nent. Your product or service will exist within a web of human 
relationships. 
For example, in a two-parent household, who finds and 
shares ideas for activities and how are decisions made about 
planning the weekend? Is one parent more motivated to plan 
activities than another? How do other parents who are friends 
figure in? Do groups of families plan outings together?
Assumptions are insults
There are about seven billion people on the planet. As of this 
writing, about two-thirds of them have no internet access. Wrap 
your head around that. That’s over four billion people who have 
never even received the $500 chocolate chip cookie recipe. You 
probably start getting itchy two minutes after your iPhone dies 
at TED and you can’t text your husband anymore. 
Did you see what I did there? I just made some assumptions 
about you. If they were correct, maybe you nodded slightly 
and moved on without noticing. However, if you don’t have an 
iPhone or don’t go to TED or don’t have a husband with whom 
you’re constantly exchanging messages, or if you have no idea 
what the $500 cookie recipe is, you probably got a little annoyed. 
When you make assumptions about your users, you run the 
risk of being wrong. When you embed wrong assumptions in 
the design of your product or service, you alienate people—pos-
sibly before they even have a chance to hear what you have to 
offer. The more obvious that wrong guess is, the more annoy-
ing it is. 
“Annoying” might be a generous description. By designing for 
yourself or your team, you are potentially building discrimina-
tion right into your product. Your assumptions about the age, 
gender, ethnicity, sexuality, and physical or cognitive abilities of 
your users might lead to barriers you don’t actually intend—bar-
riers that don’t serve your business goals or ethics. 

	
80 	 Just Enough Research
Every product doesn’t need to be all things to all people. 
However, every design decision should be a well-informed, 
intentional one that welcomes your intended users rather than 
pushing them away or making them feel bad. That’s why iden-
tifying and understanding your target audience or user base—to 
the point of true empathy—is the most important and useful 
design research you will do.
As the original motivational speaker, Dale Carnegie used to 
say, while getting rich saying it:
You can close more business in two months by becoming 
interested in other people than you can in two years by trying to 
get people interested in you. 
Getting good data from imperfect sources
It seems like a simple formula:
1.	If your goal is to make things people buy and use, you should 
design what people want. 
2.	To do that, you need to know what people want. 
3.	So just find some people and ask them what they want. 
4.	Then go off and make what they tell you. 
No. This does not work. The first rule of user research: never 
ask anyone what they want. 
You know what people want? People want to be liked. (If 
Facebook gets one thing right, this is it.) When you ask some-
one directly what they want, it is very possible the answer you 
receive will be what they think you want to hear, or the answer 
that reflects how they like to think of themselves. And because 
it’s impossible to want what you can’t imagine, you risk the 
scope of your ideas being limited by the imaginations of others. 
The television show House M.D. actually made a terrific case 
for ethnographic research, as long as you ignore certain ethical 
and medical realities. In each episode, Dr. Gregory House and 
his diagnostic team tackle a mysterious, challenging life-or-death 
case. Examining and directly questioning the patient leads only 
to one false diagnosis and subsequent dramatic defibrillation 

 	
User Research	 81	
after another, until finally a couple of comely physicians resort 
to breaking into the patient’s home and snooping around to dis-
cover evidence of undisclosed habits and behaviors. They return 
with artifacts. House has an epiphany. Patient lives! Awkward 
conversation with loved ones about habitual talcum powder 
huffing or previous traveling circus career ensues. 
“Everybody lies” was the perennial theme and occasional 
tagline of the show. Not only are most people straight-up craven 
dissemblers, but even those who we would call perfectly honest 
lack sufficient self-knowledge to give a true account. 
It may seem a harsh maxim for the designer who genuinely 
wants to empathize with users, but it is far more succinct and 
memorable than “most people are poor reporters or predic-
tors of their own preferences and behavior when presented 
with speculative or counterfactual scenarios in the company 
of others.”
Your challenge as a researcher is to figure out how to get the 
information you need by asking the right questions and observ-
ing the right details.
You won’t be breaking into anyone’s house. You need to fig-
ure out how to break into their brain. If you go in through the 
front door, asking direct questions, you’ll run into defenses and 
come up with pat, and potentially useless, answers. 
The questions you ask directly and the questions you want 
answered are two different sets of questions. During a job inter-
view at some point in your life, you may have been asked the 
question “What’s your greatest weakness?” This is definitively 
the worst interview question hiring ever devised. Everyone 
interviewing for a job thinks up an answer in advance. No 
one likes it. No one actually gets anything out of it. From the 
candidate’s perspective, this question indicates the interviewer 
doesn’t care enough to think of meaningful questions and relies 
too heavily on Job Interviews for Dummies. From the interviewer’s 
perspective, the most you’ll get is a creative twist on “I work too 
hard because I care too much about my work.” Waste of time. 
Even if a prospective employee did try to address the ques-
tion honestly, the answer would likely function as a blunt dis-
qualification (“I’m terrible at managing my time.” “I sometimes 

	
82 	 Just Enough Research
give knee-jerk answers before thinking the issue through.”) or 
wouldn’t tell you much about suitability for the job.
The real question behind the question is, “Do you have any 
habits or behaviors that would interfere with your ability to per-
form this specific job?”—a question that would be even weirder 
to ask the candidate directly. To get the answer, the interviewer 
needs to get the candidate to tell stories about relevant situations 
without indicating that there’s a right or wrong answer. Here 
are some much better interview questions:
• Walk me through a typical day in your current job. 
• Tell me about a misunderstanding you had with a coworker.
• Tell me about a situation at work where you had to deal with 
something unexpected. 
Similarly, to create a good fit between what you’re design-
ing and what your target users need, you have to know about 
the aspects of their habits, behaviors, and environment that 
are relevant to your work, and then turn that knowledge into 
insights you can act on. These insights will allow you to design 
with more confidence and less guesswork. 
What is ethnography?
Ethnography is a set of qualitative (descriptive rather than mea-
surable) methods to understand and document the activities and 
mind-sets of a particular cultural group who are observed going 
about their ordinary activities in their habitual environment. 
Radically simplified, the fundamental question of ethnog-
raphy is, “What do people do and why do they do it?” In the 
case of user research, we tack on the rider “...and what are the 
implications for the success of what I am designing?”
We are already observing people regularly, if only to deter-
mine how we should interact with them ourselves. (“Is that 
guy on the bus crazy or talking on a headset?”) And many of us 
are quite experienced at reporting interesting behaviors. (“You 
should have seen this guy on the bus...”) To do user research, 
you’ll need to make a slight mental shift to “how should what 
I’m designing interact with this person” and then do your best to 

 	
User Research	 83	
be totally nonjudgmental. That’s all it takes to stoke the human 
data-gathering machine. 
The four Ds of design ethnography
Humans and their habits and material culture are endlessly 
complex. Ethnography is an equally deep and nuanced field. 
The practices outlined in this chapter are merely a pragmatic 
simplification of a few core ideas intended to help you apply 
useful insights about people to your product design. 
It’s easy to get caught up in the specific techniques and ter-
minology, so try to keep the following key points in mind for 
more successful user research. 
Deep dive
You want to get to know a small but sufficient number of repre-
sentative users very well. We’re typically talking a Vulcan mind 
meld with a handful of individuals, not a ten-question survey 
of a thousand families. Walk in their shoes, live in their skins, 
see through their eyes...choose the creepy spiritual possession 
metaphor that works for you. 
Daily life
Fight the urge for control and get into the field where things 
are messy and unpredictable. (The field is wherever your target 
users generally are, anywhere from a cube farm to the London 
Tube.) As you’re probably well aware from how your day is go-
ing so far, life for everyone is messy and unpredictable in ways 
both good and bad. It’s very easy to think up ideal scenarios in 
which everything is smooth and simple. These are as useful to 
your work as a game of SimCity is to allocating actual resources 
in New York City. 
Participant observation, whether done in person or remotely, 
is the name of the game. Everyone’s behavior changes with the 
context and the circumstances. Soak in your subject’s actual 
environment. It’s of limited utility to learn how people behave 
in your conference room. No one is going to act naturally in 

	
84 	 Just Enough Research
there. Even calling them in their own home or office is better. 
The most interesting insights will come when you keep your 
eyes open and go off script. 
Data analysis
Gathering a lot of specific observations in the field is just the first 
part. Once you have all of this data you need to do a thorough 
job of sifting through it to figure out what it means. Systematic 
analysis is the difference between actual ethnography and just 
meeting interesting new people at a networking event. You can 
use a light touch and a casual approach, but take enough time 
to gain some real understanding, and get your team involved in 
creating useful models. 
Drama!
Lively narratives help everyone on your team rally around 
and act on the same understanding of user behavior. From the 
mundane realities of real people, personas emerge—fictional 
protagonists with important goals—along with scenarios, the 
stories of how they use the product you’re designing to meet 
those goals. Personas will keep you honest. You design for them, 
not for you or for your boss.
Interviewing humans
The goal of interviewing users is to learn about everything that 
might influence how the users might use what you’re creating. 
Good interviewing is a skill you develop with practice. The great 
myth is that you need to be a good talker. Conducting a good 
interview is actually about shutting up. This can be very hard, 
especially when you’re enthusiastic about the topic.
Remember, the people you’re interviewing want to be liked. 
They want to demonstrate their smarts. When you’re interview-
ing someone you know nothing. You’re learning a completely 
new and fascinating subject: that person.

 	
User Research	 85	
Preparation
Once you have established who you want to talk to and what you 
want to find out, create your interview guide. This is a document 
you should have with you while you’re interviewing to ensure 
that you stay on topic and get all of the information you need.  
The interview guide should contain:
1.	The brief description and goal of the study. This is for you 
to share with the participant and use to remind yourself to 
stay close to the topic. 
2.	The basic factual or demographic questions for putting the 
participant’s answers in context. These will vary depending 
on the purpose of the interview, but often include name, 
gender, age, location, and job title or role.
3.	A couple of icebreaker or warm-up questions to get the partic-
ipant talking. Most people know this as “small talk.” Feel free 
to improvise these based on the demographic information.
4.	The questions or topics that are the primary focus of the 
interview. 
You should also gather a bit of background information on the 
topic and people you’ll be discussing, particularly if the domain 
is unfamiliar to you. Talking to homeowners about how they 
selected their mortgage brokers? Read up on mortgages. Sitting 
down with the head of customer service? Review the support 
forums or frequently asked questions. 
Interview structure: three boxes, loosely joined 
An interview has three acts, like a play or a spin class: the in-
troduction and warm-up, the body of the interview, and the 
conclusion. 
Introduction
Introduce yourself with a smile, expressing genuine gratitude 
that the person you are interviewing has taken the time to talk 

	
86 	 Just Enough Research
(even if they’re getting a large incentive and especially if it’s a 
busy staff member who has taken time out of their workday).
Describe the purpose of the conversation and the topic with-
out going into so much detail that you influence the answer. 
Explain how the information will be used and shared. Obtain 
their explicit permission to record the conversation. 
Ask whether they have any questions about the process.
Move on to the demographic information or facts you need 
to verify. Use the collection of this information as the basis for 
the warm-up questions.
“Oh, you live in San Diego. What do you like to do for fun there?”
Body
Once you’ve covered the formalities and pleasantries, it’s time to 
dig into the interview meat. With a sufficiently talkative subject, 
you might get all of the answers you wanted and more without 
asking more than the initial question directly.
Ask open-ended questions that encourage the subject to talk, 
not closed questions that can be answered with “yes” or “no.” 
(Closed question: “Do you communicate with the marketing 
department often?” Open question: “Tell me about the internal 
groups you communicate with as part of your job.”)
If the subject doesn’t offer enough information on a topic, 
ask a follow-up or probing question, such as “Tell me more 
about that.” 
Allow pauses to let the story through. Silence is uncomfort-
able. Get used to it and don’t rush to fill gaps in the flow of 
conversation. You want your subject to do that. 
Use your list of questions more as a checklist than as a script. 
If you read the questions verbatim, you’ll sound like a robocall 
survey.
Conclusion
Once you have the information you were looking for, and hope-
fully even more, make a gentle transition to the wrap-up. Say 
something like “That’s it for my questions. Is there anything else 
you’d like to tell me about what we discussed?”

 	
User Research	 87	
Thank them for their time and cover any administrative top-
ics such as incentives or next steps on the project. 
Don’t be afraid to shut it down early if you find yourself in 
an unproductive interview situation. Sometimes an interview 
subject goes taciturn or hostile. It happens and the best thing 
you can do is move on to the next one. There is no rule that says 
you need to hang in until you’ve attempted to have every single 
one of your questions answered. 
Just do your part to remain friendly and respectful to the end. 
Conducting the interview
You, the interviewer, play the dual role of host and student. 
Begin by putting the participant at ease with your demeanor. 
The more comfortable a participant feels, the more and better 
information you will get. A relaxed participant will open up and 
be more honest, less likely to worry about putting on a good 
impression.
Once you’ve done your part to get the subject talking, get out 
of the way. You should strive to be a nearly invisible, neutral 
presence soaking up everything the other person has to say. 
Think of them as the world’s foremost expert on themselves, 
which is the all-absorbing matter at hand. Insert yourself only 
when necessary to redirect back on topic or get clarification. 
You will know when your interview is going particularly well 
because you won’t be able to get a word in, but you will be get-
ting answers to all your questions. 
Breathe
It’s easy to feel like you’re on stage and tense up without real-
izing it. Your own tension can be contagious, so remind yourself 
to breathe and remain relaxed and observant. 
Practice active listening
As long as you’re breathing, make interested mm-hmm sounds. 
If you’re interviewing in person, make sure to look at the speaker 

	
88 	 Just Enough Research
directly and nod. Unrelated thoughts might start to pop up, es-
pecially if an answer goes on at length. Stay alert and focused 
on the other person. 
Keep an ear out for vague answers
You want details and specifics. Always be ready to bust out 
a probing question such as “Why is that?” or “Tell me more 
about that.”
Avoid talking about yourself
Sometimes, what starts as active listening turns into “Let me 
tell you about a similar experience I had....” The interview isn’t 
about you or your opinions. This can be very hard to remember 
and takes practice to avoid. So, if you find that you’ve inserted 
yourself into their narrative, just stay relaxed and steer the con-
versation back on track.
Handy checklist
This checklist for effective user research was adapted from the 
Ethnography Field Guide produced by the Helsinki Design Lab, 
powered by Sitra, the Finnish Innovation Fund (http://bkaprt.
com/jer/10/):
• Create a welcoming atmosphere to make participants feel 
at ease.
• Always listen more than you speak.
• Take responsibility to accurately convey the thoughts and 
behaviors of the people you are studying.
• Conduct your research in the natural context of the topic 
you’re studying.
• Start each interview with a general description of the goal, 
but be careful of focusing responses too narrowly.
• Encourage participants to share their thoughts and go about 
their business.
• Avoid leading questions and closed yes/no questions. Ask 
follow-up questions.

 	
User Research	 89	
• Prepare an outline of your interview questions in advance, 
but don’t be afraid to stray from it.
• Whenever possible, snap photos of interesting things and 
behaviors.
• Also note the exact phrases and vocabulary that participants use.
• Pay attention after you stop recording. You might get a valu-
able revelation.
Try to be as conversational and natural as possible. If the user 
volunteers the information in the course of your conversation 
without you having to ask, that’s terrific. Your questions are 
just prompts to help the participant tell you a story that reveals 
situations, attitudes, and behaviors you didn’t even think to 
ask about. Offer enough information to set the scope for the 
conversation, but not so much that you influence the response. 
Here is a sample set of questions, based on our museum 
website design example, for you to modify to meet your needs: 
• Tell me about your job.
• Walk me through a typical week in your life.
• How often are you online?
• What computers or devices do you use?
• When do you use each of them?
• Do you share any of them?
• What do you typically do online? 
• What do you typically do on your days off?
• How do you decide what to do?
• Tell me about how your children use the internet.
• How do you decide what to do on your days off with your kids?
• What are your particular non-work interests? What do you 
read online besides the news? 
• How frequently do you visit museums in your town? Which ones?
• What prompts you to go?
What to do with the data you collect
The interview is the basic unit of ethnographic research. Once 
you’ve completed your interviews, analyze them all together 
to find themes, including user needs and priorities, behavior 

	
90 	 Just Enough Research
patterns, and mental models. Note the specific language and 
terms you heard so you can better reflect the way users think 
and talk in the actual interface. If you are doing generative re-
search, look to the needs and behaviors you discover to point 
out problems that need solving. Turn the clusters around user 
types into personas that you can use for the life of the product or 
service you’re working on. (See Chapter 8 for detailed examples.)
Contextual inquiry
Once you’re comfortable doing ethnographic interviews, you 
can take your skills into the field. If you like watching reality 
shows, you will love contextual inquiry, also called site visits or 
consensual home invasion—except instead of Project Runway, 
you’ll be enjoying Project Conference Call, Home Office 
Experience, or Saturday Morning Grocery Shopping. You en-
ter the participant’s actual environment and observe as they go 
about the specific activities you’re interested in studying. By 
doing this you will be able to see actual behaviors in action and 
learn about all of the small things you might not hear about in 
an interview, such as a janky work-around so unconscious and 
habitual the individual has completely forgotten it. 
Contextual inquiry is a deeper form of ethnographic inter-
view and observation. It is particularly useful for developing 
accurate scenarios, the stories of how users might interact with 
potential features, as well as identifying aspects of the user’s 
environment that will affect how someone might use a particular 
product.
Scott Cook, the founder of financial software giant Intuit, 
started the “Follow Me Home” practice very early in the compa-
ny’s history (http://bkaprt.com/jer/11/). He would quite literally 
hang out in Staples office supply stores waiting for someone to 
purchase Quicken, and then follow them home to observe them 
using the software.  He learned where they had difficulty setting 
up the program, which allowed him to make improvements to 
the initial experience. 
On behalf of a video game publisher, I’ve visited the homes of 
people who play video games to see how their gaming systems 
were configured. We saw patterns in how gamers purchased 

 	
User Research	 91	
and displayed games in their homes that we could reflect in the 
design of the website. Most importantly, we heard the language 
actual customers used when talking about the company brand 
and the gaming experience as a whole. 
Things to keep in mind
• Travel. Allow plenty of time to get to the site and set up.
• Get situated. Find a comfortable spot that allows you to talk 
to the participant without interrupting their normal routine. 
• Interview. Establish trust and learn about what you will be 
observing. Find out when it will be least disruptive to inter-
rupt and ask questions. 
• Observe. It’s a show. You’re watching. Note everything in as 
much detail as possible. The relevance will be apparent later. 
Pause to ask questions. Stay out of the way. 
• Summarize. Conclude by summarizing what you learned and 
asking the participant to verify whether your observations 
were correct. Note: even if the participant disagrees with 
your assessment, you might still be correct, and the contradic-
tory description is a very interesting data point. 
Contextual inquiry can be very inspirational. You might ob-
serve problems and opportunities you had no idea existed and 
open the door to some innovative and interesting ideas. Be ready 
to learn that people don’t need what you thought they need at 
all, but that they do need something totally different. Joyfully 
release all of your preconceived plans and notions.
Focus groups: just say no
A handful of “ordinary” people around a conference table en-
gaged in a lively discussion about how various brands make 
them feel. A cheerful, yet authoritative moderator. Observers 
wielding clipboards behind a two-way mirror. Focus groups are 
synonymous with qualitative research in popular culture, and 
it isn’t uncommon to hear all user research lumped as “focus 
groups.” 

	
92 	 Just Enough Research
Unlike the interviews and contextual inquiry mentioned 
above, focus groups don’t provide insight into behavior or the 
user’s habitual context. But because they’re so common, it’s 
worth mentioning them. 
Focus groups evolved from the “focused group interview” 
developed by American sociologist Robert K. Merton. (Fun 
fact: he also coined the terms “role model” and “self-fulfilling 
prophecy”; http://bkaprt.com/jer/12/). Merton himself deplored 
how focus groups came to be misused. As he said, “Even when 
the subjects are well selected, focus groups are supposed to be 
merely the source of ideas that need to be researched” (http://
bkaprt.com/jer/13/).
Focus groups are the antithesis of ethnography. Unlike in-
terviewing participants individually or observing people in 
their natural environment, the focus group creates an artificial 
environment that bears no resemblance to the context in which 
what you’re designing would actually be used. 
The conversation is a performance that invites social desir-
ability bias and gets in the way of finding out what people need 
and how they behave outside of this peculiar group dynamic. 
Participants are more likely to proclaim or conceal behaviors 
for the benefit of those around them. 
Recruiting and screening participants is the most time-con-
suming and least informative aspect of user research. If you are 
doing a focus group, one bad recruit in the group can tank the 
entire session. In one-on-one interviews, at least that recruit 
won’t taint the pool. 
There may be some group activities that might yield useful 
insights as part of the design process. However, focus groups are 
simply research theater. And your research time is too precious 
to squander on a sideshow.  
The talking (and watching) cure
Accept no substitute for listening to and observing real people 
who need to do the things you’re designing a thing to help 
people do. A few phone calls could change everything about 
how you approach your work. Or, maybe you’ll find out your 

 	
User Research	 93	
instincts were right all along. In any case, the information you 
gather will continue to pay dividends as you continue to gather 
and examine it, grounding your design decisions in real human 
needs and behaviors.
And as you develop the skill of stepping out of yourself to be-
come an effective design ethnographer you will develop powerful 
empathy that can inspire you to find creative, effective solutions.

	
94 	 JUST ENOUGH RESEARCH
Who is the competition?
a.	“No one! No one is doing anything that even comes close to 
what we are doing!”
b.	“The top five companies by market share in our vertical.” 
c.	“The first page of search results for ‘[relevant term]’ on 
Google. All of those guys.”
The correct answer is b plus c plus everything else anyone 
has considered or started using that solves the problem you 
want to solve or helps them avoid it. (If you aren’t working on 
something that solves a real problem or fills a real need, then 
your competition is d, “Anything else that anyone does with 
their time and money.”)
Your competition is Facebook, Apple, Twitter, the Haus of 
Gaga, Hulu, Wikipedia, a freaky Japanese YouTube channel, 
all of Google, everyone who ever had an idea for a startup, the 
nosey neighbor who offers unsolicited advice, the hot teaching 
assistant, all the people at the dog park, mom, dad, sloth, inertia, 
6
COMPETITIVE 
RESEARCH

 	
Competitive Research	 95	
insecurity, fear, corporate bureaucracy, sunk infrastructure 
costs, memory lapses, duct tape, bubble gum, ADD, marijuana 
(medical or otherwise), the sofa, some hacker in Serbia you’ve 
never heard of, what all the kids are doing these days, what 
mother never told you, some modern Chinese secrets...and more! 
The hardest competitor to beat is the one your potential cus-
tomers are using right now. If they have to stop using that one 
to start using yours, they may incur a switching cost. People are 
lazy, forgetful creatures of habit. Your target customers have to 
love you more than they hate change. 
This chapter follows user research for a reason. You need to 
know not only who your competitors are from the perspective 
of the business (that’s generally obvious) but who competes for 
attention in the minds of your target users. Attention is the rar-
est resource and the one you need to survive. Unless your goal 
is to sell one very expensive item to a small number of people, 
you need to convert attention into habit. 
This is not the place for wishful thinking. It’s a jungle out 
there, a hostile and constantly changing ecosystem, and you 
want the thing you’re building to have the best chance to adapt 
and survive—like the creature from Alien, but with a more 
pleasant user interface. You need to know the landscape and 
the competition.
So now that we’ve cast the doors wide open, how do we 
narrow down the field?
By taking a hard look at the role you want to play in your 
target customer’s life and the advantages and disadvantages that 
affect your ability to do so. 
Competitive research begins with a broad perspective on 
the competition. You may be looking for things to steal, like 
approaches and customers. You need to see how other people 
are solving similar problems, and identify opportunities to offer 
something uniquely valuable. You need to do this frequently and 
quickly; get in the habit of constantly asking not only “What 
matters to our customers?” (the user question) but “How are we 
better at serving that need than any competitor?” (the product 
question) and “How can we show our target customers that our 
product is the superior choice?” (the marketing question).

	
96 	 Just Enough Research
When you look at what your competitors are doing, you 
only see what is visible on the outside, unless you have a mole. 
That’s what your users see as well, so user research won’t help 
you here. It will take some deeper digging, critical thinking, and 
extrapolation to determine (or make a good guess at) why your 
competitor is doing things a certain way. 
SWOT analysis
Albert S. Humphrey was a management consultant who devised 
something called SWOT analysis (http://bkaprt.com/jer/14/): 
strengths, weaknesses, opportunities, and threats. You arrange 
them in a handy 2 × 2 grid and use them to guide your strategy 
(Fig 6.1). Your work with your own organization (or the research 
 
Positive
Negative
Internal
Strengths
Reputation
Excellent Staff
Weaknesses
Internal design 
resources are more 
exhibit focused than 
online technology 
focused.
External
Opportunities
Community desire 
for family-friendly 
weekend activities.
More dads are in 
charge of Saturday 
activities.
Threats
Competition for 
attention.
Schools are cutting 
back on field trips.
Fig 6.1: A SWOT analysis organized in a simple grid can help you grasp your  
competitive position.

 	
Competitive Research	 97	
you’ve done into your client’s organization) should have pro-
vided you with a good sense of your (or their) internal strengths 
and weaknesses. 
Once you’ve enumerated these characteristics, you can iden-
tify the aspects of the user experience that serve to amplify 
strengths and exploit opportunities as well as those that mitigate 
weaknesses and counteract threats. 
Your strengths and opportunities add up to your competitive 
advantage. Knowledge is a competitive advantage. If you do 
competitive research and your competitor doesn’t, you have an 
advantage. Specifically, your research should focus on competi-
tive opportunities and threats.
Competitive audit
Once you have identified a set of competitors and a set of brand 
attributes, conduct an audit to see how you stack up. In addition 
to those organizations you think of as competitors, conduct a 
web search to see who else comes up. Add in any product or 
service that was mentioned repeatedly in user interviews and 
anyone you admire as a leader solving a similar type of problem. 
For example, in thinking about the Fantastic Science Center, you 
might also consider other public-facing science organizations 
or museums that do an excellent job of reaching or expanding 
their audience online. 
Once you’ve compiled this list, identify which aspects of 
their work are most relevant and accessible. This might include  
marketing websites, mobile applications, information kiosks 
on site at the actual location, Facebook groups, third-party 
storefronts, etc. 
For each competitor and each site, product, service, or touch-
point, answer the following:
• How do they explicitly position themselves? What do they 
say they offer?
• Who do they appear to be targeting? How does this overlap 
or differ from your target audience or users?
• What are the key differentiators? The factors that make them 
uniquely valuable to their target market, if any?

	
98 	 Just Enough Research
• To what extent do they embody each of your positive/nega-
tive attributes?
• How do the user needs or wants they’re serving overlap or 
differ from those that you’re serving or desire to serve?
• What do you notice that they’re doing particularly well or 
badly?
• Based on this assessment, where do you see emerging or 
established conventions in how they do things, opportuni-
ties to offer something clearly superior, or good practices 
you’ll need to adopt or take into consideration to compete 
with them?
Brand audit
In addition to looking at how your competitors position and dif-
ferentiate themselves, take a good, hard look at your own brand. 
Is it doing the work it needs to and setting the right expectations 
for the overall experience? Do you need to do some work on it? 
Your brand is simply your reputation and those things that 
signify your identity and reputation to your current and poten-
tial customers. That reputation offers a promise of all the good 
things you do for your customers, most of which exist only in 
the customer’s mind. The stronger the brand, the more awe-
some associations pop up in more people’s minds. Coca-Cola is 
a phenomenal brand, producing positive emotional associations 
across the globe on a product that is fundamentally caffeinated 
sugar water. Tremendous continuous effort goes into brand 
marketing. You probably don’t need that. 
For many interactive products and services, there is no 
“brand” apart from the service itself. The brand experience is 
the user experience. The visual design of the interface is the 
brand identity. The brand personality is the voice of the inter-
face language.
Here are the questions you need to ask about your brand:
1.	Attributes: which characteristics do you want people inside 
and outside the company to associate with the brand or 
product, and which do you want to avoid? 

 	
Competitive Research	 99	
2.	Value proposition: what does your product or service offer 
that others do not and how does your brand communicate this?
3.	Customer perspective: when you conduct ethnographic 
interviews with existing or potential customers, what associa-
tions do they have with your brand? 
The importance of the different aspects of your brand will 
vary tremendously with your marketplace. If you’re a local busi-
ness providing an essential service with no competition—for 
example, the only dry cleaner in town—you just need a name so 
your potential customers know you exist. Given a wider audi-
ence, stronger competition, or a “premium” product or service 
(which just means it’s less necessary to daily life), branding gets 
more important. This is why branding is incredibly important 
to Pepsi and Tiffany. 
All of this is important to keep in mind as you do a com-
petitive brand analysis. Make sure you’re comparing apples to 
apples, not Starbright Cleaners to Apple. 
Name
The name is the single most important aspect of a brand. What 
makes a good name varies from market to market like everything 
else, but at a minimum, it needs to be unique, unambiguous, and 
easy to spell and say. (A lot of web companies and products have 
terrible names because the top-level domain system is broken— 
but that’s not an excuse!)
It’s arguable that mint.com’s name contributed to the suc-
cess of the personal finance application. Not only is it short and 
memorable, but it was easy to build a whole brand and interface 
around, integrating the concept of freshness and the color green, 
like American money. The name itself wasn’t unique online 
(there’s a company called Mint Analytics), but it was unique in 
the competitive field. The name was a particularly smart choice 
in the realm of personal finance, where trust is at a premium. 
The accompanying cohort of personal finance startups included 
Geezeo, Buxfer, and Wesabe, which together sound like a group 
of playful macaques. They might be cute, but do you trust them 
with your money?

	
100 	 Just Enough Research
Logo
A few years ago, an internet mogul with a penchant for dramatic 
pronouncements swept into our office and declared, “The logo-
mark is dead. The only thing that matters now is the URL. That’s 
how people find you.”
This is wrong, of course. But the right answer isn’t that a logo 
is incredibly important to every single internet-based business. 
The right answer is “It depends.” This is why a logo can cost 
between $99 and $5 million. 
The logo is simply the illustrative manifestation of your 
brand, which can take several forms: wordmark, bug, app icon, 
favicon, etc. Which logo you choose and how much you spend 
on it depends on the contexts in which people are going to have 
to identify your stuff and distinguish it from your competitors. 
Athletic apparel logos are incredibly important because they 
have to go out in the world on their own, differentiate otherwise 
similar sports shoes and shorts from each other, and remind 
people of the very expensive sponsorship of one famous athlete 
or another. 
The logo of a relatively new web application is less important. 
Customers won’t typically need to use the logo standing by itself 
to distinguish one service from another. The name, URL, and 
keywords are much more important. 
Native mobile apps represent a new level of challenge, since 
the logos are so constrained in size and dimension and do have 
to work very hard in that small uniform space to help a user 
distinguish one app from another. You don’t want to look at 
your phone’s desktop and get confused about which icon opens 
which program.
To conduct an effective logo assessment, list all of the con-
texts in which the target users are likely to encounter it, and 
review your competitors’ logos in the same contexts. Also note 
whether the logo will ever appear on its own or will always be 
connected to a larger brand or product experience. This will 
indicate the relative importance of the logo as an expression of 
your overall brand. 

 	
Competitive Research	 101	
Putting it all together
Once you’ve identified the core attributes of your brand, both 
positive and negative, assess the product name and brand iden-
tity for how well they reflect and communicate that personality. 
Usability-testing the competition
Don’t just test your own product—test the competitor’s! You 
can use task-based usability testing (described in Chapter 7) to 
evaluate a competitor’s website or application. This allows you 
to understand their strengths and weaknesses directly from 
the user’s point of view, identify opportunities to develop your 
advantages, and gain insight into how target users conceptualize 
core tasks and key features.
A niche in time
The competitive landscape and how what you’re designing fits 
into it may be the fastest moving target of all research topics. 
New options are appearing and product categories are collaps-
ing every day. Just taking a user-eye view at how your company, 
product, and message measure up will give you some competi-
tive advantage. The accurate, user-centered perspective of your 
comparative strengths and weaknesses will help you focus your 
message and hone your image.

	
102 	 JUST ENOUGH RESEARCH
“Within 30 minutes I realized, Oh my God, it’s broken. Holy shit, 
we totally fucked up.”
—Bill Nguyen, founder of photo-sharing service Color  
(http://bkaprt.com/jer/15/)
Your initial forays into clarifying requirements, understanding 
users, and checking out the competition helped you think up 
an appropriate design solution. Awesome! Now it’s a good idea 
to assess how well it works for the intended audience and its 
intended purpose before you stage a splashy public launch. 
Evaluation is assessing the merit of your design. It’s the re-
search you never stop doing. There are several ways to go about 
it, depending on where you are in the project.
In the early stages, evaluation takes the form of heuristic 
analysis and usability testing. You can test an existing site or 
application before redesigning. If you have access to a competi-
tor’s service or product, you can test that. You can test even the 
very earliest sketches. 7
EVALUATIVE 
RESEARCH

 	
Evaluative Research	 103	
Once a site or application is live, even if it’s in private alpha, 
you can start looking at quantitative data and use site analytics 
to see how people are actually interacting with the system and 
whether that meets your expectations. 
The best way to assess a functional design is through a com-
bination of quantitative and qualitative methods. The numbers 
will tell you what’s going on, and the individual people will help 
you understand why it’s happening. 
Heuristic analysis
Despite the fancy name (which is from the Greek heuriskein, to 
find out), heuristic analysis is the most casual method of evalu-
ating usability. “Heuristic” in English simply means “based on 
experience”; a heuristic is a qualitative guideline, an accepted 
principle of usability. The more you know about using and 
designing interactive systems, the better you’ll be at heuristic 
analysis. 
Godfather of usability Jakob Nielsen and his colleague Rolf 
Molich came up with the idea for heuristic analysis way back 
in 1990 (http://bkaprt.com/jer/16/). The method is very simple: 
evaluators (at least two or three, ideally) individually go through 
a site or application with a checklist of principles in hand and 
score the site for each one. 
 Nielsen’s ten heuristics (http://bkaprt.com/jer/17/) are:
• System status visibility. The system should provide appro-
priate feedback. 
• Match between system and real world. Use language familiar 
to the user and follow conventions.
• User control and freedom. Provide emergency exits, undo, 
and redo.
• Consistency and standards. Things that appear the same 
should behave the same. 
• Error prevention. Don’t just let users escape from errors: 
help users avoid them.
• Recognition rather than recall. Options should be visible. 
Instructions should be easy to find. Don’t make the user have 
to remember information. 

	
104 	 Just Enough Research
• Flexibility and efficiency of use. Support shortcuts for expert 
users.
• Aesthetic and minimalist design. Avoid providing irrelevant 
information. 
• Help users recognize and recover from errors. Error mes-
sages should be helpful.
• Help and documentation. Ideally, the system should be us-
able without documentation, but help should still be available 
and task oriented. 
Several of these heuristics focus on error prevention and 
recovery, which remains the most neglected area of system 
design. Every time an application displays “Unknown Error” or 
an unhelpful error code number with no instruction, you know 
someone should have done a little heuristic evaluation. 
The advantage of heuristic analysis is that it’s a quick and 
cheap way to identify potential issues. You don’t need to recruit 
users. You can just get two colleagues to sit down and do it in 
an hour. It’s a good way to deal with obvious issues in early 
prototypes before bringing in users. 
The downside is that it’s very simplistic and might not catch 
all the issues that would come up in context. Less experienced 
evaluators may not see all the problems. Different evaluators 
will find different issues. Some expert evaluators may find is-
sues that don’t present a problem to actual users. It focuses on 
the system itself rather than the relationship between the user 
and the system. The advantages were greater back in the day 
when fewer people were familiar with technology and recruiting 
people was much more difficult.
Heuristic inspection is not a substitute for usability testing, 
but it can be a good sanity check. The number of sites and ap-
plications that launch with major usability flaws is evidence of 
its continued usefulness. 
Every internal design review is an opportunity for a mini 
heuristic evaluation. If you’re about to embark on a major re-
design, it makes a tremendous amount of sense to identify key 
issues through usability testing.

 	
Evaluative Research	 105	
Usability testing
Usability is the absolute minimum standard for anything de-
signed to be used by humans. If a design thwarts the intended 
users who attempt the intended use, that design is a failure from 
the standpoint of user-centered design. 
Despite the vast amount of knowledge we possess about us-
ability, unusable objects are all around us: the completely unin-
telligible “universal” remote, the spiteful web form that discards 
every piece of entered data, the deceptive door that only appears 
to open outward until you walk into it. Each interaction brings 
a little more sadness into the world.
This amounts to basic manners. As a designer or a developer, 
you either care about usability, or you’re a jerk. And the easier 
it is for your customers to switch to an alternative, the more 
important usability is to the success of your product or service. 
The more complex a system is to design and build, the more 
work is required to ensure that it’s usable—but that work is al-
ways worth doing. (This is also an argument for keeping feature 
sets simple.) If the desire to rush to market trumps usability, 
you might see your first mover advantage dissolve as soon as a 
competitor copies all your functionality and leapfrogs your ease 
of use. Barriers to usability are barriers to sales. On the other 
hand, a more usable product will get better word of mouth and 
lower support costs. 
Don’t make me drink
Usability testing can save you from introducing unnecessary 
misery into the world—or having it associated with your brand.
According to Nielsen (http://bkaprt.com/jer/18/), usability is 
a quality attribute defined by five components:
• Learnability: how easy is it for users to accomplish basic tasks 
the first time they come across the design?
• Efficiency: once users have learned the design, how quickly 
can they perform tasks?
• Memorability: when users return to the design after a period 
of not using it, how easily can they reestablish proficiency?

	
106 	 Just Enough Research
• Errors: how many errors do users make, how severe are these 
errors, and how easily can they recover from the errors?
• Satisfaction: how pleasant is it to use the design?
Every aspect of a digital design that thwarts an intention it 
purported to fulfill might as well be a sharp ragged edge, a piece 
of broken glass, or a splinter. Would you offer a broken glass to 
a guest? All of your users are your guests. It is your job to make 
sure they don’t cut themselves on the stuff you make. 
Cheap tests first, expensive tests later
Usability testing can be more or less expensive. Don’t use ex-
pensive testing—costly in money or time—to find out things 
you can find out with cheap tests. Find out everything you can 
with paper prototypes or quick sketches before you move to a 
prototype. Find out everything you can in the comfort of your 
own office before you move into the field. Test with a general 
audience before you test with specific audiences who take more 
time and effort to find. 
In fact, start even earlier than that. Test a competitor’s prod-
uct before you even put pencil to paper. Then you should test 
some sketches. And then test at every stage as much as you can 
allow. 
How often you test depends on how frequently significant 
design decisions are being made. You can test every two weeks 
in conjunction with development sprints, if that’s how you roll. 
I’m not going to tell you when to do usability testing in your 
design and development cycle, but I will tell you when not to do 
it: right before you are about to launch. A good rule of thumb:
• The second most expensive kind of usability testing is the 
kind that you put off until very late in the process, when you 
risk finding out that there are huge usability problems that 
will be very difficult to fix. 
• The most expensive of all is the kind your customers do for 
you after launch by way of customer service. 
Try to avoid these situations.

 	
Evaluative Research	 107	
Preparing for usability testing
The most difficult part of usability testing is determining how 
it fits into your process as a decision-making input. There is no 
one way, but there are a few essential principles:
• Build usability practices into your workflow from the start, 
the same way you account for internal reviews of work in 
progress. 
• Create a testing process and checklist that includes all of the 
information and equipment you need. 
• Always be recruiting. Maintain a database, even just a Google 
doc, of potential participants and their contact information.
• Decide who’s in charge of this stuff. A point person makes 
everything operate more smoothly. 
What you will need
• A plan.
• A prototype or sketch.
• Four to eight participants of each target user type based on 
personas (ideally) or marketing segments. 
• A facilitator.
• An observer.
• One or more methods of documentation.
• A timer or watch.
Usability test plans
A usability test revolves around tasks. Ideally you have personas 
that you have been using throughout the design process and 
you can use them and their core tasks as a jumping off point for 
usability. The features you want to test should likewise have as-
sociated scenarios and tasks. For each feature, write a very brief 
story that offers background on how the user arrived there and 
what they are trying to accomplish. 
For example, if you wanted to test the new ticket purchase 
process design, you might use the following scenario: a science-
minded school friend is in town for the weekend and wants to 

	
108 	 Just Enough Research
visit the Fantastic Science Center. You did a web search and 
landed on this page. What would you do to find and purchase 
tickets for the weekend your friend is visiting? 
Not all tasks are created equal. When you go into a usability 
test, you should have a clear idea which failures are a bigger deal.
The ur-example of a deal-breaker task is using an online shop-
ping cart. If a user can do anything at all on your site, they need 
to be able to successfully give you money. For websites with 
the goal of marketing a physical location, such as the Fantastic 
Science Center, finding the address and operating hours is gener-
ally the most essential task.
Once you have your tasks, make a checklist test plan that you 
use to run and document each round of testing. The test plan 
lays out what you’re going to do, how you’re going to conduct 
the test, which metrics you’ll capture, the number of participants 
you’re going to test, and which scenarios you’ll use. Reducing 
the time you spend on planning will save your precious brain 
cells for analyzing and reacting to the results. 
Helpfully, the US Department of Health and Human Services 
maintains usability.gov, which is a resource for making useful 
and usable websites. (Even you libertarians out there should 
appreciate this.) All the materials are in the public domain, so 
have at it, no matter where you are. This checklist can be used 
for both planning the test and writing your report. Modify it to 
fit your needs:
• Objectives.
• Subject of the test: what are you testing and what state is it in?
• Methodology.
• Participants and recruiting.
• Procedure.
• Tasks.
• Usability goals.
• Completion rate (the percentage of tasks the user was able 
to complete).
• Error-free rate (the percentage of tasks completed without 
errors or hiccups). 

 	
Evaluative Research	 109	
Recruiting
Participants are the fuel that makes usability tests go, and they 
are single use, so you need a good supply of them. You can bring 
people back to see if your improvements have really improved 
things for them, but they might be tainted—influenced by their 
previous experience with your design—and won’t necessarily 
give you an accurate depiction of how someone is going to ap-
proach this system for the first time. 
Recruiting for usability testing is substantively the same as 
for ethnographic interviews. It is essential that the people you 
select for the test share some key goals with your target users. 
Otherwise, they won’t be able to immerse themselves suffi-
ciently in the scenarios you give them. 
Facilitating
Once you have your prototype, your plan, and your recruits, it’s 
time to run the test. This is the fun part. As long as you have an 
open mind, nothing is more interesting and valuable than seeing 
your precious theories of how people will interact with a design 
crash against the rocky shoals of reality. 
The first step is to choose a facilitator. Facilitating a usability 
test isn’t hard, but it does take the right temperament. Since a 
usability test is a guided journey of the imagination (imagine 
you’re using a fully realized application to do something per-
sonally meaningful), a bad facilitator will tank the whole test, 
no matter how on-target the participants are. It’s up to the fa-
cilitator to present the scenarios and tasks that are being tested. 
Unclear tasks can’t be tested. A good facilitator is personable 
and patient. A good facilitator can warm the participant up like 
Conan O’Brien and then dispassionately observe as the partici-
pant flails about with no idea what to do next, probably also just 
like Conan O’Brien.
This requires a balance of sociability and self-awareness. 
Making small talk is fine and helpful up front. Once the test 
starts, you’ll need some self-control so you don’t intervene. It’s 
one of those things that gets easier with practice. 

	
110 	 Just Enough Research
The greatest danger inherent in the actual designer or devel-
oper of the system facilitating the test is that they will not be 
able to sit idly by while their creation fails to perform or elicits 
derision from the participant. Small hints and leading ques-
tions will begin to creep into the program. Follow the general 
guidelines for user interviews in Chapter 3. In particular, avoid 
leading the user and helping them when they get lost. Embrace 
the uncomfortable silences. 
Frequently, users who encounter a usability issue are quick 
to blame themselves rather than the system. This is how people 
have been conditioned by frequent exposure to less than us-
able products. If this happens, ask the participant to describe 
how they expected the system to work and why they had that 
expectation. 
Be very honest with your team about who should be facilitat-
ing. If you don’t have a good facilitator on your team, you can 
always contract with someone or try to get a volunteer from 
another department. And again, practice. 
Observing and documenting
Even if you are set up to record, it’s very important to have a 
second person observing the tests and taking notes. This allows 
the facilitator to be responsive and the observer to be as obser-
vant as possible, creating the smallest number of distractions. 
Audio recording is fantastic. I think designers should be re-
cording everything all the time, just like Richard Nixon (except 
with informed consent). People have crappy memories and even 
if you have a notetaker, it’s useful to have a backup in case you 
missed anything. The files are easy to store and share. You can 
listen to them on the train home. 
Video recording, on the contrary, can be less valuable. In my 
experience, the people who are keen on having as much video 
as possible have far less experience with video than the people 
who are a bit more cautious and wary about it. As any episode 
of Cops will show you, the value of video is frequently a matter 
of good editing, and good editing takes vast amounts of time. 
Video also takes vast amounts of storage space. 

 	
Evaluative Research	 111	
Make sure that if you promise anyone video, it’s the right 
video at the right time. Screen capture with an audio track is very 
useful and relatively easy. If you add an additional camera on 
the participant’s face and body, this can be helpful, but you have 
to ask yourself whether the additional information is worth the 
additional overhead. Consider having the notetaker snap a few 
photos; accurately time-stamped photos combined with audio 
recording might be sufficient to capture information like how 
the user was holding their phone when they were experiencing 
that difficulty. 
If you are testing a tricky device, such as a smartphone or 
ereader, you might have to make a tricky little sled for it. A sled 
is simply a framework that holds the device you’re testing along 
with necessary peripherals and cameras. 
Usability testing applications on mobile devices is a free-for-
all right now, so it’s a terrific place for innovation. There is a 
great need for evaluating the usability of mobile interfaces, par-
ticularly in their context of use (walking around outside, rather 
than seated in your conference room), but there is no one clear, 
comfortable way to both observe the user over the shoulder and 
capture the activity on the user’s screen.
MailChimp’s solution to this conundrum, which they  detail 
on their blog (http://bkaprt.com/jer/19/), is to have a user set up 
a video chat on a MacBook and then hug it from the back so the 
iSight camera catches video of their interaction on the phone 
and the audio through the microphone (Fig 7.1). 
 The observer will need to note the following:
• The participant’s reaction to the task.
• How long it takes to complete the task.
• If the user failed to complete the task.
• Any terminology that presented a stumbling block.
The note-taker should work from a copy of the test script 
with space to insert annotations. The most important items to 
note are areas where the user exhibited nonverbal frustration, 
verbatim quotes, and any features that were particularly success-
ful or unsuccessful. If the notetaker can manage an approximate 
time code, that will make analysis easy. 

	
112 	 Just Enough Research
Eye-tracking
Eye-tracking measures where someone is looking, how long, 
and in what direction. Observation and analytics can tell you 
where a user taps with a finger or hovers with a mouse, but 
where that user directs their gaze is a mystery only a non-trivial 
amount of cash can reveal. Whether paying top dollar for this 
data is worthwhile remains a deeper mystery still.
As the sci-fi future of controlling interfaces directly with our 
eyes encroaches, eye-tracking may become more commonplace. 
Right now, systems cost upward of $5,000 and hiring a consul-
tant with the necessary skills and equipment is likely to cost even 
more. The only case where this could be worthwhile would be 
testing with populations who have trouble articulating what is 
drawing their attention on the page. 
Fig 7.1: A little awkward, but effective—remote test mobile usability by having participants 
hold their devices in front of a laptop webcam.

 	
Evaluative Research	 113	
Analyzing and presenting test data
The aim of usability testing is to identify specific significant 
problems in order to fix them. The outcome is essentially a 
ranked punch list with a rationale. Keep your source materials 
(e.g., session recordings or notes) organized so you can easily 
refer to them or provide more detail to anyone who is interested, 
or skeptical. Focus your written documentation on the issues, 
their severity, and recommended fixes. 
How bad and how often?
Rate each problem users encountered during the test on each 
of the following two scales: severity and frequency. You must 
look at both to ensure you’re prioritizing real obstacles, rather 
than chasing a fluke.
Severity:
• High: an issue that prevents the user from completing the 
task at all.
• Moderate: an issue that causes some difficulty, but the user 
can ultimately complete the task.
• Low: a minor problem that doesn’t affect the user’s ability to 
complete the task.
Frequency:
• High: 30% or more participants experience the problem.
• Moderate: 11–29% of participants experience the problem.
• Low: 10% or fewer of participants experience the problem.
It’ll end in tiers
Once you’ve conducted the tests, and rated the issues, sort them 
into three tiers. Each represents the combination of severity and 
frequency. Also take into account how core the related task is to 
your application (for example, confusion over changing a profile 
picture may be less core than obstacles to entering payment 
information). Rename the tiers if it will be more fun for you. 

	
114 	 Just Enough Research
• Tier 1: high-impact problems that often prevent a user from 
completing a task. If you don’t resolve these you have a high 
risk to the success of your product. 
• Tier 2: either moderate problems with low frequency or low 
problems with moderate frequency. 
• Tier 3: low-impact problems that affect a small number of 
users. There is a low risk to not resolving these. 
Now, get to work
As soon as you have usability test results, you can take action. 
Start with Tier 1 issues. Identify potential fixes with the lowest 
level of technical effort. Implement these fixes, then test again.
Need to convince someone before you can make any chang-
es? Watching actual users struggle with the system is more 
convincing than reading a report, and offers all the agitation of 
a suspense film. (Why doesn’t he see the button? It’s right there!) 
So if you’re starting to see frequent repeated usability issues, try 
to schedule sessions when it’s convenient for important people 
to observe. Verbatim quotes and video clips of failure presented 
in conjunction with a report can also be effective. Just make sure 
to connect the tasks you tested and the problems you found to 
high-priority business goals. 
Put the competition to the test 
In addition to conducting usability testing on your own site or 
application, you can also conduct it on those of your competitors 
(presuming that you have access and that competitive evaluation 
isn’t prohibited by the terms and conditions).
To conduct a benchmark usability study, identify a small 
common set of tasks to test across your website and those of 
your competitors. Use a common scoring system across all 
sites and tasks to identify which of the competitive group was 
most usable overall, and most usable per key task. Following a 
redesign, you can run the study again to verify improvement 
relative to competitors.

 	
Analysis and Models	 115	
8
Analysis  
and Models
Qualitative analysis can seem like a mysterious process. A 
group of people enters a conference room with interview notes 
and stickies and emerges with recommendations for creating or 
changing the functionality or interface of a system. 
For us humans, this is actually the most natural thing pos-
sible. We’re social creatures and pattern-recognition machines. 
Getting people together to analyze qualitative data is like throw-
ing a party for our brains. Once you start, you’ll get hooked. 
And this is where design truly starts. You take all this messy 
data and begin to organize it, and group it, and label the group-
ings. Through conversation, clarity will start to emerge. Clarity 
in the data analysis will translate to clarity of concept, content 
relationships, navigation, and interactive behaviors. And best of 
all, if you work collaboratively that clarity and deep understand-
ing will be shared.
Any models or maps you create will simply serve as docu-
mentation of what everyone already knows.
The process is actually pretty simple:

	
116 	 Just Enough Research
• Closely review the notes. 
• Look for interesting behaviors, emotions, actions, and ver-
batim quotes. 
• Write what you observed on a sticky note (coded to the 
source, the actual user, so you can trace it back). 
• Group the notes on the whiteboard. 
• Watch the patterns emerge. 
• Rearrange the notes as you continue to assess the patterns. 
You will end up with a visual representation of your research 
that you can apply toward your design work in a few different ways.
Affinity diagram
Your first pass—and if you don’t have a lot of time, your only 
pass—should be to extract general design mandates from your 
interviews. Then you can prioritize those mandates based on 
business goals. This also requires the least diagramming skill. 
This graphic shows how an affinity diagram starts to take 
shape (Fig 8.1).
The participants in the analysis build clusters of related ob-
servations. Once a cluster starts to take shape, you can extract 
the insights and the overarching mandate or recommendation.
The act of creating an affinity diagram will allow you to distill 
the patterns and useful insights from the many individual quotes 
and data points you gather through interviews and observation. 
If you work collaboratively with your team on identifying and 
documenting these patterns, the value of that research will be 
multiplied rather than lost in translation.
The diagram itself can be a handy visual reference or a tool 
for communicating with a larger team about your research and 
the principles you’ve uncovered.  
Write down observations
As you review the notes or recordings, write down anything 
interesting you observed on a sticky note. An observation is a 
direct quote or objective description of what the user did or said. 
Pull out all of the particularly interesting quotes. Flag those that 

analysIs and modEls
117 
seem to represent the particular needs of each user type. These 
will be useful for your personas. Also note the vocabulary that 
participants used to describe their goals and the elements of the 
tasks or systems you are working with, particularly if they diff er 
from those used in your organization. 
Note all stated or implicit user goals. Implicit goals can be 
found in quotes or actions that indicate a particular desire. For 
example, starting the weekend with some good activities in 
mind. In particular, fl ag those you didn’t anticipate, but that 
your product might readily meet. 
Example observations:
Fig 8.1: an affi  nity diagram helps turn research into evidence-based recommendations.
Design for multi-device access
Break information into small chunks
Build in low-eﬀort/high-value reminders 
Support collaborative decision-making
Include the voices of parents and educators to validate user engagement
Observations
Insights
Design 
Mandates
“I see signs for events 
when I’m driving, but 
never remember 
them.”
Checks email on phone 
ﬁrst thing in the 
morning.
“I take care of the kids 
on Saturday to give my 
partner a break.”
Many Interruptions/
Short Memory
Relies on 
Mobile Device
Being a “Good” Parent is 
a Top Priority
Four-year-old 
daughter interrupted 
interview frequently.
“Without my iPhone 
alarm, I’d never get the 
kids from school on 
time.”
“I like to start the 
weekend with some 
good activities in 
mind.”
“The week rushes by 
and then I wake up 
Saturday with no 
plans.”
Texts partner to 
coordinate daily 
activities.
“I want my kids to 
keep learning even 
when they are not in 
school.”

	
118 	 Just Enough Research
• “I reset my password every time I visit the website because 
I never remember it.”
• Participant’s four-year-old daughter interrupted three times 
during the thirty-minute interview.
• “I take care of the kids for the whole day every Saturday to 
give my partner some alone time.” 
• Participant reports checking email on her phone every morn-
ing before getting out of bed.
Example goals:
• “I like to start the weekend with some good activities in mind.”
• “I want my kids to keep learning even when they’re not  
in school.”
Create groups
Start grouping the notes on a whiteboard. You should start see-
ing patterns pretty quickly. Name the pattern and identify the 
user need that emerges from it, such as “Needs reminders for 
organized activities.”
• “I see signs around town for events that look interesting, but 
I never remember before it’s too late.”
• “The week rushes by and then I wake up on Saturday morn-
ing with no good ideas.”
Identify next steps
The final step of the analysis is to identify the actionable design 
mandate or principle. 
• When announcing a new exhibit, offer the ability to sign up 
for a reminder.
• Allow members the option of digital access to all services 
(e.g., online member newsletter instead of print, email guest 
passes to their friends).

 	
Analysis and Models	 119	
• Improve promotion of and navigation to activities and les-
son plans.
• Create a stronger voice for the museum based on the quality 
of its scholarship and expert status (e.g., offer the museum 
perspective alongside the feed of technology news).
In addition to serving as a useful input to other tools, such 
as personas, and a nifty visual representation of your research 
and analysis, the affinity diagram helps you make decisions. You 
can decide which features and functionality to prioritize based 
on the patterns of needs you recognize. You can decide to do 
additional research based on the questions it raises. And it can 
serve as a common reference point for your team in discussing 
those decisions. 
Creating personas
A persona is a fictional user archetype—a composite model you 
create from the data you’ve gathered by talking to real people—
that represents a group of needs and behaviors.
In the usual course of product development, every interest 
other than the user has a say: business leaders will provide busi-
ness goals and requirements, marketers will speak to marketing 
targets, engineers will speak to the technical constraints and 
level of effort required to develop particular features. Personas 
allow designers to advocate for users’ needs.
Good personas might be the most useful and durable out-
come of user research. Design, business strategy, marketing, and 
engineering can each benefit in their own way from a single set 
of personas. If you’re following an agile process, you can write 
your user stories based on a particular persona. 
Personas exist to represent the user in user-centered design, 
because there is no generic user. They embody the behavior 
patterns and priorities of real people and act as a reference point 
for decision-making. A persona is a tool for maintaining an 
empathetic mind-set rather than designing something a certain 
way just because someone on the team likes it.
Design targets are not marketing targets. Stamp that on ev-
ery persona document you create. Market segments do not 

	
120 	 Just Enough Research
translate into archetypes. And the user type with the highest 
value to your business may not be the one with the most value 
to the design process. Maybe existing Fantastic Science Center 
members with post-graduate science degrees generate the most 
revenue through gift shop sales and special event attendance, 
but they know too much. Their existing level of knowledge and 
Fig 8.2: A persona document should feel like the profile of a real individual while capturing 
the characteristics and behaviors most relevant to your design decisions
“I have so much going on between my 
job and taking care of the kid, I can’t 
remember a damn thing without my 
iPhone.”
Goals
Find a few places for reliable family 
outings that don’t require a lot of 
planning.
Entertain her family members when 
they are out of town.
Keep learning throughout her life.
Stats
33 years old
Married with a 5-year-old child
Lives in Chicago, IL
Account manager for a large health 
care company
Behaviors and habits
Works from home two days a week. 
Does most of her shopping online. 
Weekend routine is one day for “fun” 
and one day for errands and chores.
Technology and skills
Diane is a multi-device user. Has a 
work-assigned Windows laptop that 
she carries between home and the 
oﬃce, as well as an older MacBook and 
an iPhone for personal use. The family 
shares an iPad 2. Because she is 
pressed for time, she has strong habits, 
no patience, and little motivation to 
explore.
Relationships
Lives with husband and son. Has large 
extended family. Sisters often visit and 
bring their children.
Diane McAvoy
Local parent

 	
Analysis and Models	 121	
engagement is likely to be very high. Design for the users with 
less expertise and you can meet the needs of those with more. 
How many personas do you need? As few as possible, while 
representing all relevant behavior patterns. You can often reduce 
the number by creating relationships among them and assigning 
multiple roles to one persona. 
For the Fantastic Science Center website you might con-
sider an out-of-town visitor, a local parent, a teacher, and a staff 
member. Could the out-of-town visitor also be a teacher? Try it. 
All fictional user profiles are not created equal. A truly useful 
persona is the result of collaborative effort following firsthand 
user research. Otherwise you’re just making up a character that 
might be as relevant to the design process as any given imaginary 
friend. If you have interviewed some real people and worked 
collaboratively with your team to identify some patterns, you 
should be able to create some useful personas.
This doesn’t mean that the documentation needs to be 
lengthy or involved. You can create a vivid individual from a 
few key details (Fig 8.2). It’s better for the team to keep a hand-
ful of attributes in mind than to have to refer to a lengthy CV 
with every design decision or switch in situations and scenarios 
throughout the product development process. Once you’ve cre-
ated a set of personas, you can reuse them over time, even for 
different products.
Capturing the character
A persona description should have just enough detail to capture 
those aspects of a target user most useful and inspiring for the 
designers to keep in mind. You can start with the conventional 
“place mat” layout and go from there. Make a movie or a poster 
or an animated GIF, as long as the essential information about 
context of use and patterns of behavior are in a form you can 
integrate into your workspace and refer to repeatedly.  Consider 
your personas as a set. You don’t have to capture all concerns in 
a single one. And the personas can have relationships to each 
other, just like people do in real life. 

	
122 	 Just Enough Research
Photo
Use a real photo of a real, relatable person, not a stock photo. 
Creative Commons-licensed photos from Flickr or other photo-
sharing websites are very useful for this. Don’t use a photo 
of anyone who is known to the design team, or that has any 
distracting elements. 
Name
Give the persona a name that fits the demographic information 
and that everyone on the team can remember and pronounce. 
LinkedIn is a good source of inspiration for names. The Game 
of Thrones Name Generator is not. 
Demographics
Select the set of demographics that fit the role and behavior 
pattern. Be realistic without stereotyping. The persona must be 
plausible and representative (no teenage marketing VPs who 
model and fight crime on the side). Ideally, the gender, age, 
ethnicity, education, job, marital status, and location are derived 
from actual users you’ve interviewed. However, recruiting can 
be unpredictable and the lack of a complete match needn’t stop 
you from creating a suitable persona. Increase your knowl-
edge by finding people whose online profiles match the criteria 
you do have. Need more information for the Fantastic Science 
Center’s high school science teacher persona? Try searching 
for local news stories about teachers to get useful background 
details, quotes, and even pictures of actual classroom envi-
ronments. Just remember to create a composite from multiple 
people and avoid the crime section. 
Role
For the most accurate personas, select a role that closely matches 
that of one of the participants you interviewed and is also one 
of the identified target user types, such as the aforementioned 
teacher, parent, or tourist. 

 	
Analysis and Models	 123	
Quote
Use an actual quote from a user interview that embodies a core 
belief or attitude that is essential to keep in mind to meet their 
needs. The most useful quotes are those that could be answers 
to questions that reveal both behaviors and mind-set, such as 
“What’s most important to you when you’re making plans for 
the weekend?”
Goals
Goals and behavior patterns are the core of a persona. Identify 
three to four key goals for that persona based on what you heard 
in your user research. These will be the goals that the product 
or website will serve or relate to. 
The local parent’s goals might include finding weekend ac-
tivities, keeping kids learning when they aren’t in school, and 
keeping up to date with advances in science. 
Behaviors and habits
Note the specific and habitual behaviors that constitute the pat-
tern that defines the persona. Parenting. Teaching. Researching 
activities online. Switching among multiple devices. Making 
decisions with another person. Making plans at the last min-
ute. Real life is imperfect and complicated. Capture this. Maybe 
you spoke with a dad who is torn between wanting to relax on 
the sofa and wanting to get out and find new things to do on 
Saturdays. Does he have a habit of checking Facebook over cof-
fee to see what his friends are up to with their kids? This detail 
could open up a whole conversation about social media. 
Skills
Skills include the level of technical expertise and experience this 
persona has. Be realistic about the level of skill you’re targeting 
with your design. How much experience do you expect them 
to have based on their profession and educational background? 
This is a crucial area not to make assumptions. One of your 

	
124 	 Just Enough Research
target personas might be a very successful physician who’s a 
relative technology novice because she is in surgery all day and 
gets very little time to learn expert features or acquaint herself 
with the latest applications. She could be a very good proxy for 
everyone who has a lower skill level, but absolutely doesn’t want 
to be made to feel stupid. 
Environment
Note all aspects of the environment that will affect this persona’s 
interaction with the product. Include the relevant hardware, 
software, and internet access. Do they go online at work or 
home? Surrounded by people or in private? Is their time online 
continuous or does it happen in specific chunks? The teacher 
might have half an hour during the day using the classroom 
computer. The parent might have an office job with a browser 
window always open. 
Relationships
Note any relationships this persona has that will affect their 
interaction with your product. Is there a partner who influences 
decisions? Will children or coworkers be present or otherwise 
influence the use of your design? Relationships should be based 
on real-world information, either from your study or demo-
graphic information available through surveys or other research. 
Information from the census or from the Pew Center’s Internet 
& American Life Project is often useful in this regard. You can 
create some interesting multipurpose scenarios with personas 
that are related to each other.
Scenarios
If personas are your characters, scenarios are your plots. Each 
scenario is the story of how a persona interacts with your sys-
tem to meet one (or more) of their goals. Running a persona 
through a scenario helps you think through your design from 
the user’s point of view. You can use scenarios at several points 
in your process:

 	
Analysis and Models	 125	
• To flesh out requirements.
• To explore potential solutions.
• To validate proposed solutions.
• As the basics for a usability test script.
As long as a scenario hews closely to actual data gathered in 
user research, you have a lot of flexibility in the actual format. 
You can start from a specific answer to an interview question, 
such as “I wake up at 8 a.m. on Saturday and read a local news 
website while the kids run around the house making noise.” 
While personas should remain reasonably constant in their 
characteristics and priorities, scenarios can evolve and deepen 
over time and change as your understanding of the system 
changes. Your personas are the Simpsons, your scenarios are 
the couch gag. 
You can write a scenario as a short text narrative, a step-by-
step flow, or even a set of comic panels—whatever is easy for 
your team to create and use to keep each persona represented 
in design and technology decision-making. If you find anyone 
on your team resenting the effort necessary to work with per-
sonas and scenarios, you’re doing it wrong. Simply drawing out 
scenarios on a whiteboard can work. 
Scenarios are not themselves use cases or user stories, al-
though they can influence each. A use case is a list of interactions 
between a system and a user, and is typically a way to capture 
functional requirements. Scenarios are from the perspective of 
the individual human user represented by the persona, not the 
perspective of the system or business process. 
For example: Diane and her family just moved into the area. 
Her job as an account manager is very demanding during the 
week, but weekends are family time. 
• Goal: she wants to find local activities that will be entertain-
ing for her son and relaxing for her and her husband.
• Motivation: when she was driving home from the office on 
Friday evening, she saw banners for the Fantastic Science 
Center’s new exhibit on super storms. Sitting in her driveway, 
Diane Googles the science center on her iPhone. 

	
126 	 Just Enough Research
• Task: she needs to determine whether visiting the Fantastic 
Science Center will meet her needs. 
Stay on target
Developed with care, personas can be the most useful and lasting 
output of user research. They are the users in “user-centered” 
and an incredibly efficient and even fun distillation of your 
ethnographic work.
You will know your personas are working when they become 
the first people you want to see any new idea. Rather than asking 
“Does this work for me?” or “Does this make my boss happy?” 
you can ask “Does this address Dana’s concerns about privacy? 
Would Neven understand what to do? Would Anna find time 
for this in her busy schedule?” 
Mental models
All of us carry around a library of mental models in our heads. 
Without them, every new experience would be a complete 
surprise and we would have to painstakingly figure out each 
situation. Using a term from cognitive science, a mental model 
is an internal representation of something in the real world—
the sum total of what a person believes about the situation or 
object at hand, how it functions, and how it’s organized. This 
representation is based on a combination of hearsay and accu-
mulated experience. People have mental models of how stoves 
work, how dogs behave, and what happens at a rock show. (Band 
plays, band says “Thank you and goodnight,” band waits offstage 
while audience applauds, band returns to play popular favorites.)
Mental models can be real time-savers for deciding how to 
behave—to the extent they are accurate. Sometimes there’s no 
encore. Sometimes you get burned. The first time I rented a 
Prius, I spent ten minutes sitting in the parking lot because my 
mental model of “passenger car” didn’t include the hybrid’s in-
novative ignition system.

 	
Analysis and Models	 127	
In design, “intuitive” is a synonym for “matches the user’s 
mental model.” The closer an interface fits that image, the easier 
it will be to learn, use, and navigate. This is a concept with a lot 
of practical value.
You can use data from user research to diagram the (com-
posite) mental model of each particular user type, and use that 
diagram to guide the design. This is, strictly speaking, a mental 
model model. However, particularly following consultant and 
author Indi Young’s work in this area (Mental Models: Aligning 
Design Strategy with Human Behavior; http://bkaprt.com/jer/20/), 
people in the business tend to use the one term as a catchall. 
So there are two types of mental models: the type each of us 
holds in our head to help us deal with the world, and the type 
designers sketch out to better create that world. For maximum 
success, be aware of the former and get to work on the latter. 
To design an application or a website, think about the mental 
models of the activities you want to support. 
If you’re designing a mobile application to help commuters 
find the best way to get to work on public transit, it’s useful to 
look at the mental model of “getting to work.” If you’re rede-
signing buses, you’d want to look at the mental model of “bus.”
As a designer, you have your own mental model of what 
you’re designing, and you have a mental model of the users 
themselves, your set of assumptions about what they know and 
how they will interact with your design. It’s easy to overestimate 
how well your view matches their reality.
Documenting the user’s mental model allows you to not just 
get inside their head but get the inside of their head out of your 
head for everyone else to see. You can use a mental model dia-
gram to collaborate with your team, prioritize features, better 
organize information, and identify areas where users have needs 
that aren’t being served. 
A mental model diagram can help resolve issues that arise if 
different user types have widely divergent mental models, or if 
the actual design of the system is significantly different from the 
one that was originally proposed. 

 
128
Just Enough REsEaRch
 
How to create a mental model
• Do user research.
• Make an affi  nity diagram (see Fig 8.1).
• Place affi  nity clusters in stacks representing the user’s cog-
nitive space to create the model. These groups will include 
actions, beliefs, and feelings. 
• Group the stacks around the tasks or goals they relate to 
(Fig 8.3).
Building on the towers
Conceptual modeling/site mapping
For a new website or service design, you can translate the mental 
model to a conceptual map that relates content and functional-
ity according to the target user’s view (Fig 8.4). The model will 
Fig 8.3: mental model diagrams illustrate your users’ thought processes in detail. this 
information helps you identify relevant and necessary content and functionality.
Evaluate 
Alternatives
Visit websites
 of potential 
destinations
Read reviews on 
travel website
Suggest 
alternatives to 
children
Discuss potential 
destinations 
with partner
Choose Based on 
Priorities
Choose Destination
Plan a Visit
Choose based on 
proximity
Choose based 
on educational 
potential
Choose based 
on variety of 
activities
Choose based on 
value for money
Avoid Some 
Destinations
Avoid expensive 
destinations
Avoid 
complicated 
logistics
Avoid 
“tourist traps”
Avoid boring 
destinations
Select Time 
to Visit
Check own 
schedule
Check 
destination 
event calendar

 	
Analysis and Models	 129	
form the application framework or the basis of the information 
architecture as you proceed into more detailed design. 
Gap analysis
If you have an existing product or service, you can use a mental 
model to identify gaps, or mismatches between what you offer 
and what the user needs or expects. This will help you design 
features that fill those gaps.
For example, when designing the app for urban commuters, 
you might find that their mental model of getting to and from 
work includes changing plans suddenly based on contingen-
cies like bad weather, local events, and transit system delays. If 
your application only offers route suggestions based on optimal 
rather than actual conditions, you may recommend a route that’s 
influenced by rain or event traffic. 
Reviewing the mental model suggests an opportunity to offer 
additional information and support that allows users to antici-
pate and evade problems, leading to a more successful commute. 
Fig 8.4: A conceptual model bridges the gap between mental model and system map. 
Brand 
Messaging
Membership
Directory
Hours
Directions
Stated 
Mission
Guided 
Tour
Ticket
Sales
Event 
Calendar
Reviews/
Testimonials
Planning
How do I go?
Visiting
What can I do?
Awareness
What is this place?

	
130 	 Just Enough Research
On the other hand, you might find out that features you had 
considered offering don’t fit in the users’ mental model at all. 
Perhaps you were planning to display after-work entertainment 
suggestions along the route, but find that this is incompatible 
with the user’s desire to quickly locate the most efficient route.
Task analysis/workflow
Task analysis is simply breaking one particular task into the 
discrete steps required to accomplish it.
Contextual inquiry is the best prelude to task analysis, but 
you can also use data from user interviews as long as you’ve col-
lected sufficient detailed information about how the participants 
work toward their goals step by step. Any given task has both 
cognitive and physical components that may be more or less 
important given the domain and the goal of the analysis. For 
example, making a complex purchase decision such as buying a 
new car typically has a series of cognitive activities surrounding 
identifying the need or desire for a car and conducting research 
online, as well as the physical component of actually going to 
the dealership and test-driving the car itself. 
From simple to complex and back again
If you’re designing a site or application that addresses one or 
many complex tasks in helping users meet their goals, you can 
use task analysis. This method can be particularly helpful to map 
what people do in the real world to functionality you can offer 
on a site or in an application. 
For example, “purchasing tickets” sounds simple, but the 
online process is often a complex and stressful multistep flow 
with a lot of decision points. 
Task analysis can be helpful when designing any system in-
tended to replace a real-world task with an online interface or 
changing the nature of the physical interaction as with the shift 
to mobile devices from desktop-based applications. 

 	
Analysis and Models	 131	
Break it down
Using the information from user interviews or contextual inqui-
ry, identify each step the participants reported or you observed 
them taking to complete a given task. Note the initial state, the 
event prompting the user to begin the task, the information or 
tools the user needs at each step, and any steps at which the task 
is likely to be interrupted or resumed. Put all of these steps back 
together as a workflow.
1.	Receive postcard advertising fall event calendar.
2.	Go to website.
3.	Locate event information on homepage.
4.	Click on link to see all available upcoming events.
5.	Identify event.
6.	Verify ticket availability and price.
7.	Enter number of tickets desired.
8.	Enter preferred delivery method.
9.	Review information and total cost.
10.	Select “Buy Now.” 
11.	Enter credit card information.
12.	View confirmation page and instructions for receiving 
tickets.
Make it flow
In addition to informing the feature set and flow of an applica-
tion, task analysis will help you identify where specific content 
might support a user along their task path. Users might take 
very different paths than you anticipated, or be influenced by 
particular factors in the environment that you’ll need to consider 
in your designs (Fig 8.5). 
Model management
This is just a sample of a few common ways to work with the re-
search data and incorporate your findings into design decisions. 
A little exploration of the UX corners of the web will yield many 
more. Communicating the meaning and value of research is a 

	
132 	 Just Enough Research
design activity itself. And the act of working together to syn-
thesize individual observations will ensure that your team has 
a better shared understanding than a report could ever deliver.
You may also benefit from the fact that a clear, economical 
diagram is viscerally appealing. If you’re promoting the value 
of research among skeptics in your organization, don’t underes-
timate the accessibility and appeal of your analysis, visualized.
Fig 8.5: This task path for ticket purchase can help identify areas where the user needs 
specific content and functionality to meet her goal.
0
1
3
4
1.1
1.2
2
2.1
2.2
5
9
8
7
6
10
11
COMPLETE
BEGIN
Purchase 
Tickets
Select Ticket 
Type
Provide 
Payment 
Information
Review Total
Get Information 
about Ticket 
Options
Evaluate 
Options
Select Number 
of Tickets
Verify Number 
of Tickets with 
Friends
Check for 
Discounts
Select Delivery 
Method
Acquire Tickets
Receive 
Conﬁrmation/
Receipt
Complete 
Purchase
Provide Contact 
Information for 
Delivery
Transfer Tickets 
to Friends
Tell Others 
about Ticket 
Purchase

 	
Quantitative Research	 133	
9
quantitative  
research
“If they will not understand that we are bringing them a 
mathematically infallible happiness, we shall be obliged to force 
them to be happy.”
—yevgeny Zamyatin, We
Optimize.
That’s such a nice word. Optimize. Making something the very 
best it can be. Who doesn’t want to do that?  
Now that you’ve done all of the hard work to design and de-
velop your site, service, or application, you want to make sure 
that it’s the best. You want to optimize it. Optimizing a design 
is the chief aim of quantitative research and analysis. There are 
a lot of people out there who—in exchange for your money— 
very much want to help you do this. Google even offers a 
free tool called Optimizer (or they did—it’s called “Content 
Experiments” now). 
When you set out to optimize, you will run up against one 
of the oldest and thorniest philosophical problems, that of the 
Good. What is good? How do you know it’s good? What does 

	
134 	 Just Enough Research
it mean to be best? What are you optimizing for? How will 
you know when you have attained that optimal state and have 
reached the best of all possible worlds?
What if, in optimizing for one thing, you cause a lot of other 
bad things to happen?
Optimistic people talk as though there is some sort of obvi-
ous, objective standard, but once you start thinking about what 
is truly optimal, you will find that it’s always subjective and 
you’ll always have to make trade-offs. This is why designers will 
never be replaced by machines.
I was promised there would be no math
Qualitative research methods such as ethnography and usability 
testing can get you far. You’ll begin to understand how people 
make decisions and may even get a peek at habits they might not 
fully admit to themselves. (“Huh, I guess TMZ is in my browser 
history a lot.”) You can use these insights to design sensible, 
elegant systems primed for success. 
And then you release your work into the world to see how 
right you were—and the fun begins. No matter how much re-
search and smart design thinking you did up front, you won’t 
get everything right out of the gate, and that’s OK. Because here 
come the data...I mean, the visitors. 
Once your website or application is live and users arrive 
in significant numbers, you’ll start getting some quantitative 
data. (If no one shows up, please consult your marketing strat-
egy.) Every interaction each of those individuals has with your 
website can be measured. All those people with the particular 
needs and quirks you lovingly studied fade away in the face of 
the faceless masses. 
You were in the realm of informed assertions. Now you’re 
in the big time. Actual data. You can see how well your design 
is performing out there in the world. How many people? How 
long do they stay? What do they see? Where do they exit? Do 
they return? How frequently? And do they click the button?
Once you can measure your success in numerical terms, you 
can start tweaking. The elements of your design become so 

 	
Quantitative Research	 135	
many knobs and levers you can manipulate to get to the level 
of success you’d envisioned, and beyond.
Preaching to the converted
The term for clicking the button—you know, the button—is con-
version. A user is said to convert any time they take a measurable 
action you’ve defined as a goal of the site. For many websites 
there is an obvious primary raison d’être. On an application 
marketing website, conversion is clicking “sign up”; for ecom-
merce sites, “buy now”; on a hotel site, “make a reservation.” 
The success of the design can be measured by how many people 
click that button and do the thing that makes the money. 
Some websites are completely optimized for simple conver-
sion, and it’s easy to tell.  The design centers on one clear call to 
action, a vivid lozenge labeled with a verb. The usual picture is a 
little more complex, with several different types of conversion. 
Which converts do you want the most?
The Fantastic Science Center website might offer several 
potential actions with desirable outcomes: newsletter sign-up, 
advance ticket sales, shopping in an online store, becoming a 
member. Measuring the conversion rate for each of these will 
indicate the success of that particular path, but not how each 
type of conversion matters to the success of the organization 
itself. That is a business decision.
Ease into analytics
As soon as you have some data, you can start looking for trends 
and patterns. It might be a little overwhelming at first, but this 
sort of direct feedback gets addictive fast. Decision-makers love 
data, so being handy with the stats can be to your advantage in 
arguments. Sure, that involves math, but people who love math 
have built some tools to make it easy—and you’re going to need 
to use them unless you’re really keen on analyzing raw server 
logs yourself. 
Analytics refers to the collection and analysis of data on the ac-
tual usage of a website or application to understand how people 
are using it. Based on data from analytics, you can identify areas 

	
136 	 Just Enough Research
where your website is not as effective as you’d like it to be. For 
example, analytics could tell you that a thousand people visit 
the homepage every day, but only five people click on any other 
link on the page. Whether this is a problem depends on your 
goals for the site. You can make changes and then check these 
measurements, or metrics, again to see whether those changes 
have had an effect. 
If you would like more people to sign up for the newslet-
ter from the homepage, you could try making the link to the 
newsletter sign-up more visually prominent, then check the 
analytics again.
Over half of the world’s websites have Google Analytics in-
stalled. It’s an excellent place to start and will give you a variety 
of pleasing charts and graphs. After you sign up, you or a friendly 
developer will need to insert a snippet of JavaScript into the 
source code of the site you want to measure. 
Some of the basic stats to look at include:
• Total number of visits.
• Total number of pageviews.
• Average number of pages per visit.
• Bounce rate (the percentage of people who leave after view-
ing one page).
• Average time on site.
• Percentage of new visitors.
In general, you want to see the total number of visits and 
unique users go up over time as your site becomes more and 
more popular. The other items may be more open to interpre-
tation depending on your audience and business goals. More 
pageviews could mean increased engagement, or it might mean 
that you have a highly motivated audience who can’t find the 
information they’re looking for right away. Bounce rate sounds 
fun, but it’s not. A lower bounce rate means you offer something 
interesting enough for people to stick around, but if it’s too 
low, that might mean that not enough people are discovering 
your site through search or other means. (Getting a lot of traf-
fic through search is good, but visitors will bounce if your site 
wasn’t quite what they were looking for.)

 	
Quantitative Research	 137	
Some of the most interesting data points aren’t about what’s 
happening on your website at all, but where your traffic is 
coming from. Google Analytics will let you know how many 
people are coming from search results, other websites, or direct 
navigation—that relatively rare occurrence when someone just 
types in your URL. 
You can even use the In-Page Analytics feature to click around 
your site and see what percentage of users is taking various ac-
tions on each page. Are they seeing what you want them to see 
and clicking the things you want them to click? A brief tour may 
very quickly resolve the hoary argument about whether users 
scroll down the page. 
Clearly, access to data is no longer the issue. The question 
is what to do with all of these numbers. If you don’t already 
have quantitative goals, define some. You can start by looking 
up averages for your type of site or industry. Those are the 
numbers to beat.
If you aren’t making your numbers, review the data and 
prioritize changes. Bounce rate is a good place to start. Before 
you get around to fine-tuning your message, you need people 
not to run screaming and stick around long enough to hear it. 
A high bounce rate is often an indicator of unmet expectations 
or uncertainty about where to go next. 
You can use analytics to see which pages are the most fre-
quent entry points. Then review those pages for clarity. If you 
know what you want visitors to do, make sure that is coming 
through in the design and content of the page. How do you 
make sure? Well, you can do some usability testing to get more 
insight into the potential problems. Or venture into the scientific 
wonderland of split testing. 
Lickety split
There are many solutions to every problem. If your problem is 
getting as many people as possible to sign up for the newslet-
ter, there might be some debate over the most effective change 
to make to the site. To solve your dilemma, you could try split 
testing.

	
138 	 Just Enough Research
A split test is a clinical trial for a particular page or set of ele-
ments on your website. Some visitors are served the control—
the current design—and others get a variation. The variation that 
performs significantly better for a specific metric is the winner. 
Then you can either decide to switch all traffic to the winner, 
or put it up against another challenger, or set of challengers. 
This method is called split testing because you split your traffic 
programmatically and randomly serve different variations of a 
page or element on your site to your users. Maybe half gets the 
current homepage design with a sign-up button to the right of 
the call to action and half sees the exact same page with a sign-
up button underneath the call to action. Ahead of you on the 
horizon, the clouds part and you can see all the way to Mount 
Optimal, that mythic realm of mathematic perfection.
Like an international criminal, split testing has a lot of aliases, 
including A/B testing, A/B/n testing, bucket testing, multivari-
ate testing, and the incredibly Panglossian “whole site experi-
ence testing,” which promises to deliver the best of all possible 
website experiences. Each of these denotes a variation on the 
same basic idea.
This approach is of special interest to marketers, and actually 
derives from a technique first used in ancient times when special 
offers were sent on paper by direct mail. Send a flyer with one 
offer (“Free dessert with every pizza”) to a thousand houses, 
and a flyer with a different offer (“Free salad with every pizza”) 
to a thousand other houses, and see which one generates the 
better response.
There is both an art and a science, and quite a lot of statistics, 
to using split testing effectively and appropriately. As a designer, 
you may be asked to participate in the process or create varia-
tions. So even if you aren’t in charge of running them, it’s helpful 
to know the basics so you can deal with the effects.
The split testing process
At last, SCIENCE. Bust out that lab coat, because you will be 
running experiments.
The general outline of events for split testing is as follows:

 	
Quantitative Research	 139	
• Select your goal.
• Create variations.
• Choose an appropriate start date.
• Run the experiment until you’ve reached a ninety-five per-
cent confidence level.
• Review the data.
• Decide what to do next: stick with the control, switch to the 
variation, or run more tests.
You will need a specific, quantifiable goal. This is a track race, 
not rhythmic gymnastics. No room for interpretation. You have 
to know the current conversion rate (or other metric) and how 
much you want to change it. 
For example, five percent of all site visitors click on “Buy 
tickets,” and we want to increase the conversion rate to seven 
percent. 
Next, determine how much traffic you need. The average 
number of visitors your site gets is important for a couple of 
reasons. Small, incremental changes will have a more significant 
influence on a high-traffic site (one percent of one million versus 
one percent of one thousand) and tests will be faster and more 
reliable with a larger sample size. How large a sample do you 
need? It depends on the sensitivity and how large an improve-
ment you want to see. If you are looking at making a small 
change, you will need a larger sample to make sure that you can 
be confident in the result. A small change in a small sample size 
is more likely to be merely the result of chance. 
Approach this process with patience and confidence. The 
confidence in this case is statistical confidence, the probability 
that the winner is really the winner, rather than the outcome 
of chance events. The standard is ninety-five percent, meaning 
that there is a ninety-five percent chance that you can rely on 
the result. On a high-traffic site, you can get to this level within 
a couple of days. Lower traffic, and the test will take longer. To 
rule out the effect of other variables, such as day of the week, 
you would ideally let the test run over a two-week holiday-free 
period, allowing you to make day-over-day comparisons. If you 
have less patience, you open yourself up to more potential er-
rors, both false positives and false negatives.

	
140 	 Just Enough Research
Perhaps the Fantastic Science Center received an unusual 
mention in the New York Times, and the website variation you’re 
testing is particularly popular with Times readers but not with 
your typical population of site visitors. You need to let the test 
run long enough to counter these kinds of outliers.
It’s also important to keep in mind that if you want to test 
variations of a particular page against the current state, someone 
has to design those variations. Even if they’re small changes, 
it’s still work.
If you’re testing a landing page with one call to action—one 
button a user can click on—you can change any aspect of that 
page with regard to that one measurement, including:
• The wording, size, color, and placement of the button.
• Any piece of copy on the page and the total amount of copy.
• The price or specific offer.
• The image or type of image used (photo vs. illustration).
The winner is often counterintuitive, in a “Who would have 
thought that brown buttons would work the best with this au-
dience?” sort of way. If there’s agreement about which metric 
you’re optimizing for and the math is sound, it’s an opportunity 
to learn. After a number of tests you might see patterns begin to 
emerge that you can apply to your design work when solving 
for specific conversion goals. By the same token, remember that 
specific conversion goals are frequently just one aspect of the 
overall success of a website or a business. 
Cautions and considerations
More precautions apply to split testing than to most other in-
formation-gathering approaches for a couple of reasons. Testing 
can be seductive because it seems to promise mathematical 
certitude and a set-it-and-forget-it level of automation, even 
though human decision-making is still necessary and the results 
remain open to interpretation within the larger context. The best 
response to a user interface question is not necessarily a test. 
Additionally, these are activities that affect the live site itself, so 
that presents a little risk.

 	
Quantitative Research	 141	
Much like Dr. Frankenstein, you have set up your laboratory 
in the same place you receive visitors, so it’s important to design 
and run your experiments so as not to disrupt what’s already 
working well. A consistent online experience can help build 
trust and habit, and split testing by its very nature introduces 
inconsistency. Keep this in mind as you decide what and how 
to test. 
This is an incremental process—tweaking and knob-twid-
dling—not a source of high-level strategic guidance. Since you’re 
changing things up, it’s best suited for aspects of your design 
where users might expect to see variation, and where there is a 
single clear user behavior you want to elicit in a given context. 
Search engine marketing landing pages? Fantastic. Those are 
generally intended for new users. Global navigation? Maybe not. 
Focusing on small positive changes can lead to a culture of 
incrementalism and risk aversion. How will you ever make a 
great leap that might have short-term negative effects?
 On his excellent eponymous blog (http://bkaprt.com/jer/21/), 
entrepreneur and adviser Andrew Chen invokes the concept of 
the local maximum, which you may be excited to remember 
from calculus. The gist is that you can only do so much optimiz-
ing within an existing design system. If you focus on optimizing 
what you have rather than also considering larger innovations, 
who knows what vastly greater heights you might miss (Fig 9.1).
This is why understanding context and all the qualitative fac-
tors matters. Yahoo! could do all the split testing in the world 
and it wouldn’t turn into Google, and Google’s mathematical 
acumen is not turning Google+ into Facebook. You always need 
to answer “Why?” before asking “How?” And you need good 
answers for both.
Designers and data junkies can be friends
We admire Mr. Spock for his logical Vulcan acumen but find him 
relatable because of his human side. 
There is a tension between strategic design thinking and 
data-driven decision-making. In the best case this is a healthy 
tension that respects informed intuition and ambitious thinking 

	
142 	 Just Enough Research
and knows how to measure success. When data rules the roost, 
this can leave designers feeling frustrated and undervalued.
Doug Bowman left Google to become the creative director 
at Twitter in part because of A/B testing run rampant, saying: 
“When a company is filled with engineers, it turns to engi-
neering to solve problems. Reduce each decision to a simple 
logic problem. Remove all subjectivity and just look at the data” 
(http://bkaprt.com/jer/22/).
The best teams are Spock-like. They embrace data while 
encouraging and inspiring everyone working on a product to 
look beyond what can be measured to what might be valued. 
You can optimize everything and still fail, because you have 
to optimize for the right things. That’s where reflection and 
qualitative approaches come in. By asking why, we can see the 
opportunity for something better beyond the bounds of the 
current best. 
Even math has its limits.
Fig 9.1: Split testing can help you optimize your current design until you reach a local 
maximum, but it can’t tell you how much you can accomplish with a different approach.
The Local Maximum
The Limit of
Split Testing
Your Glorious
Potential

 	
Conclusion	 143	
Conclusion
If this book raised more questions than it answered, fantastic. 
I want you to be excited about asking questions. Questions are 
more powerful than answers. And asking often takes more cour-
age than sticking with comfortable assumptions. 
Every time you find a product or service that’s a joy to use, 
meets a need maybe you didn’t even know you had, and fits 
seamlessly into your life, you know that someone on the other 
end asked hard questions. Why should this exist? Who benefits? 
How can we make this better?
You can do the same for your users and your (or your client’s) 
business. They deserve no less. Your effort and craft also deserve 
to be put to use in a way that has real meaning. So, always make 
sure you inquire into the real-world context surrounding your 
work. When blue-sky thinking meets reality, reality always 
wins. Make friends with reality. Cultivate a desire to be proven 
wrong as quickly as possible and for the lowest cost. If you 
work in a culture that prizes failing fast, there is no faster way 
to fail than by testing an idea that’s still on the drawing board. 
Except maybe checking your assumptions before you even get 
down to drawing. 
The right questions will keep you honest. They will help 
improve communication within your team. They will prevent 
you from wasting time and money. They will be your competi-
tive advantage, guiding you toward workable solutions to real 
problems. 
Form questions. Gather data. Analyze. One sequence, many 
approaches. I hope the techniques briefly outlined in this book 
help you get started (right now!) and encourage you to develop 
a research habit wherever and however you work. Research 
needn’t be a burden or a luxury. It’s simply a means to develop 
useful insights within your existing process. 
I’ve listed some tools and websites for further exploration in 
the Resources section. Let curiosity be your guide. Your goals and 
available resources will help determine which are right for you.
How much research is just enough? You’ll need to do just 
enough to find out. 

	
144 	 Just Enough Research
Resources
So, now that you’re keen to get started here are some handy 
tools and guides, as well as places to turn for additional detail. 
Websites and blogs
• Helsinki Design Lab: The government of Finland cares deep-
ly about strategic design. This website is a trove of guides 
and templates, including an ethnography field guide (http://
bkaprt.com/jer/23/).
• Service Design Toolkit: The Belgians, on the other hand, 
have focused on human-centered service design. Posters, 
guides, and workshop materials (http://bkaprt.com/jer/24/).
• Service Design Tools: Roberta Tassi’s thesis work in in the 
design department of the Politecnico di Milano resulted in 
this orderly collection of communication tools and method-
ologies (http://bkaprt.com/jer/25/).
• Remote Research: From the genuinely nice people who cre-
ated Ethnio, a site to help you conduct remote research and 
testing (http://bkaprt.com/jer/26/).
• Design Staff: Google Ventures Design Studio publishes a fan-
tastic blog full of smart and practical ideas for lightweight re-
search, from recruiting to testing (http://bkaprt.com/jer/27/).
• Userfocus: This London-based usability consultancy pub-
lishes articles and ebooks. While many are free, some will 
cost a few pounds. Enjoy Usability Test Moderation: The Comic 
(http://bkaprt.com/jer/28/).
• Nielsen Norman Group: Jakob Nielsen’s evidence-based  
usability pronouncements are legendary. They have probably 
started as many arguments as they’ve settled (http://bkaprt.
com/jer/29/).
A few specifics
• Getting People to Talk: An Ethnography & Interviewing 
Primer: This video is handy because there are limits to how 
much you can glean about interviews from reading (http://
bkaprt.com/jer/30/).

 	
Resources	 145	
• ICC/ESOMAR Code on Market and Social Research: 
Professional and ethical rules defined by the International 
Chamber of Commerce and an international organization for 
market researchers. Works just as well as a code for design 
research (http://bkaprt.com/jer/31/).
• Human-Centered Design Considered Harmful: This critique 
of Human-Centered Design brings up several critical points 
about context (http://bkaprt.com/jer/32/).
• An Ethnography Primer: AIGA and Cheskin put together a 
downloadable primer on design ethnography with concise 
text and pretty photos. Very handy for certain internal audi-
ences (http://bkaprt.com/jer/33/).
Further reading
• Observing the User Experience (2nd Edition), Goodman, 
Kuniavsky, Moed.
• Designing and Conducting Ethnographic Research, Margaret D. 
LeCompte and Jean Schensul.
• Mental Models: Aligning Design Strategy with Human Behavior, 
Indi Young.
• Interviewing Users: How to Uncover Compelling Insights, Steve 
Portigal.
• Designing for the Digital Age: How to Create Human-Centered 
Products, Kim Goodwin.
Research tools
Recruiting
• Ethnio: An online recruiting tool from the guys who wrote 
the book on remote user research. It’s the best thing to hap-
pen to ethnographic research since the clipboard. After you 
sign up, the app guides you through creating a screener (the 
survey that qualifies potential participants), then generates 
a line of JavaScript that displays a screener to your website 
visitors. If you have a high-traffic website, this is recruiting 
magic, like dropping a net into a stream full of big fat salmon. 

	
146 	 Just Enough Research
If your website doesn’t have much traffic, or if you want 
to recruit people who have never visited the site, you can 
send a direct link to the screener in an email or on Twitter. 
The price varies with the amount of traffic and number of 
respondents. (Web)
Screeners
A recruiting screener is just a particular type of survey, so you 
can use Google Docs or SurveyMonkey or any other similar 
tool to make one if you have some in-house survey-writing 
expertise. (Web)
Audio, video, and screen recording
Having recordings of interviews and test sessions for reference 
makes everything easier. Getting those recordings can be a little 
fiddly, though. Recording is easier when you make phone calls 
over VOIP. And always, always remember to get permission 
before you start recording.
• Audio Hijack Pro: Record any audio on your Mac. Great for 
VOIP phone interviews. (Mac OS X)
• Digital or analog (tape) recorder: For landline or not-smart 
cell phone calls, you’ll need a device that connects to the 
phone itself. There are a great many makes and models; look 
for one that suits your needs. 
• iTalk Recorder: Dead simple. Press the big red button to 
record audio. Press it again to stop. (iOS, Android)
• Ecamm Call Recorder for Skype: Save audio and video as 
QuickTime and easily convert to MP3. (Mac OS X)
• Snapz Pro: This handy Mac application will record anything 
on your screen as a QuickTime movie or screenshot. (Mac 
OS X)
• Camtasia: Camtasia allows you to record and edit screencasts. 
The two versions have slightly different features depending 
on the platform. (Mac OS X, Windows)  

 	
Resources	 147	
Usability testing
• Silverback: Pretty nifty. Captures screen plus live video 
and audio. Eliminates setup for in-person usability testing. 
Exports everything to QuickTime. (Mac OS X)
• Morae: Morae is a Windows-only remote usability software 
package that offers a lot of features at a steep price. (Windows)
Remote research and testing
• Skype: Video calling, conference calling, screensharing. (Web 
and many platforms)
• GoToMeeting: Conference calling and screensharing. 
Promises screensharing from mobile devices in the near 
future. (Web and many platforms)
File storage and sharing
• Dropbox: All that data you generate, notes, photos, audio, and 
video start to take up a lot of room. Store them on Dropbox 
and your whole team will have access to them. (Web and 
many platforms)
Analytics and split testing
Split testing services cost between $0 (Google) and $300,000 
(Accenture) per year depending on the vendor, level of service, 
and amount of traffic. If you already have Google Analytics set 
up, you can give Content Experiments (formerly Optimizer) a 
try. It’s free and the documentation is clear and thorough. For 
not too much money, KISSmetrics is an analytics startup with 
reasonable, tiered pricing (starting at less than $50 per month), 
a refreshingly people-oriented philosophy, and a user-friendly 
interface. 

	
148 	 Just Enough Research
Diagramming
When you turn your research into models, you’re going to need 
to make some diagrams. This is really an area to use what you’re 
comfortable with. Some people like to diagram in PowerPoint. 
No judgment.
• Mockingbird: A web-based tool to create and share wire-
frames. Great for super-fast “paper” prototyping and usability 
tests. Very wireframe specific, though. Not a general-purpose 
tool. Price goes up with the number of active projects. (Web) 
• Creately: This is a cloud-based diagramming tool that allows 
teams to collaborate on making charts and graphs. Price in-
creases with the number of team members. (Web)
• OmniGraffle: Terrific for mapping. Fast to use once you get 
the hang of it. Not cheap. Not built for collaboration. (Mac 
OS X, iPad)
Physical objects
• Sticky notes: Frequently seen as a visual metaphor for the 
qualitative research analysis, these little guys are invaluable. 
Stock up on a bale. They make it easy to jot down observa-
tions, quotes, and insights and arrange and rearrange into 
patterns. Very few people are intimidated by sticky notes, so 
hand out sticky notes and pens to encourage the whole team 
to get involved. Extra points for using different colors to code 
different types of data in your analysis sessions. 
• Whiteboards: It’s sometimes shocking how little whiteboard 
space is available in offices where design and development 
are going on. Laptops are not conducive to collaborative 
thinking. You need a place to stick and rearrange all those 
notes. Ideally you will have a conference room with white-
board walls. In a pinch, you can use mobile boards, apply 
whiteboard wallpaper, or have the team over to brainstorm 
in your shower.

 	
References	 149	
references
Shortened URLs are numbered sequentially; the related long 
URLs are listed below for reference.  
Chapter 1
	 1	 http://www.ideo.com/images/uploads/news/pdfs/Informing_Our_ 
Intuition.pdf
Chapter 2
	 2	 http://agileproductdesign.com/blog/emerging_best_agile_ux_practice.html
 	 3	 http://www.esomar.org/knowledge-and-standards/codes-and- 
guidelines.php
Chapter 3
	 4	 http://www.uie.com/articles/usability_testing_three_steps/
	 5	 http://pewinternet.org
Chapter 4
	 6	 http://www.designstaff.org/
	 7	 http://sri.com
	 8	 http://www.uxmatters.com/mt/archives/2007/09/conducting-successful-
interviews-with-project-stakeholders.php
	 9	 http://www.ftrain.com/wwic.html
Chapter 5
	 10	 http://www.helsinkidesignlab.org/dossiers/design-ethnography
	 11	 http://www.inc.com/magazine/20040401/25cook.html
	 12	 http://www.laphamsquarterly.org/voices-in-time/self-fulfilling- 
prophecy.php
	 13	 http://archives.newyorker.com/?i=2000-10-16#folio=CV1

	
150 	 Just Enough Research
Chapter 6
	 14	 http://www.sri.com/sites/default/files/brochures/dec-05.pdf
Chapter 7
	 15	 http://www.fastcompany.com/1784823/bill-nguyen-boy-bubble
	 16	 http://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/
	 17	 http://www.nngroup.com/articles/ten-usability-heuristics/
	 18	 http://www.nngroup.com/articles/usability-101-introduction-to-usability/
	 20	 http://blog.mailchimp.com/remote-usability-testing-on-mobile-devices/
Chapter 8
	 20	 http://rosenfeldmedia.com/books/mental-models/
Chapter 9
	 21	 http://andrewchen.co/2008/06/04/5-steps-towards-building-a-metrics-
driven-business/
	 22	 http://stopdesign.com/archive/2009/03/20/goodbye-google.html
Resources
	 23	 http://www.helsinkidesignlab.org
	 24	 http://www.servicedesigntoolkit.org
	 25	 http://www.servicedesigntools.org/
	 26	 http://remoteresear.ch/
	 27	 http://www.designstaff.org/
	 28	 http://www.userfocus.co.uk/articles/index.html
	 29	 http://www.nngroup.com/articles/
	 30	 https://vimeo.com/1269848
	 31	 http://www.esomar.org/knowledge-and-standards/codes-and- 
guidelines.php
	 32	 http://www.jnd.org/dn.mss/human-centered.html
	 33	 http://www.aiga.org/ethnography-primer/

 	
Acknowledgements	 151	
Not Enough Thanks
This is the point at which my disbelief that I have really, truly 
finished writing this book gives way to the hope I’ve done right 
by anyone who takes the time to read it, and everyone who 
helped and inspired me along the way.
Of course I must first recognize my publishing superheroes 
at A Book Apart. Jeffrey Zeldman’s enthusiasm and support 
made the whole endeavor possible. Mandy Brown is the very 
best kind of editor—the sort I would trust as a surgeon—whose 
thoughtfulness and compassion are equal to the precision of her 
scalpel. The overall book design and individual diagrams shine 
with Jason Santa Maria’s sophisticated unicorn magic. Krista 
Stevens copyedited with a generous spirit and a keen eye. And 
Katel LeDu compelled the whole thing to coalesce at the mo-
ment the greatest number of pieces seemed to be whirling about.
The support and shining examples of so many worthy 
friends, colleagues, and leaders in the field (accruing over more 
years than I want to contemplate) provided me with the knowl-
edge and confidence to attack a project of this scope. Jeff Tidwell 
and Karen Wickre got me started in the design business and 
have been good friends and sounding boards ever since. Mike 
Kuniavsky and Liz Goodman continually impress me with their 
fortitude and discipline, and their unflagging and strangely 
complementary senses of humor in the midst of applying said 
fortitude. Jared Braiterman, the first professional ethnographer I 
ever met, will forever be a model of intellectual curiosity, genu-
ine collaboration, and sartorial flair. Indi Young’s deep work on 
mental models has proven tremendously useful. Her distance 
swimming tips were also invaluable when I was deep in the 
middle of the work, feeling far from shore. Nate Bolt deserves 
mad credit for liberating research from the lab and removing the 
pain from recruiting. I’ve frequently consulted Kim Goodwin’s 
comprehensive guide to the digital design process, and complet-
ing my own relatively minuscule work leaves me in even deeper 
awe of her ambition and achievement. Hiten Shah took time out 
from putting principles into practice to offer his astute insights, 

	
152 	 Just Enough Research
and I appreciate his generosity. Kristina Halvorson encouraged 
me and offered amusing book-writing anecdotes.
A hearty toast to the Mule team. They do this stuff every day 
and are always thinking of new ways to do it better. Working 
with such a dedicated and entertaining group ensures I never 
stop learning. Thanks to all the current staff and free-range 
members of the Mule Design Studio family, with a few special 
mentions. Katie Spence and Katie Gillum helped establish and 
formalize the research practice. David McCreath consistently 
translates Klingon directives into clear technical requirements 
with grace and good humor. Rawle Anders and Tom Carmony set 
the standard for teamwork and fair play. Jim Ray and Benjamin 
Nguyen would clearly run our espionage division... if we had 
one. Valeda Stull was instrumental in distilling and clarifying 
some of the thornier, complex concepts. She and Angela Kilduff 
also assisted in shaping key ideas into a companion talk. John 
Slingerland posed for the remote research photo, and Dianne 
Learned played the part of the persona with her son Delton.
Anything I’ve managed to accomplish in life, I owe to my 
family: Nancy, Esther, Bud, Al, and Gary. They taught me the 
Hall way—to climb mountains, prize laughter, and value what 
is good, or at least interesting, in people. A big hug to Judy and 
Nadine for their warmth and support over the years. 
As for Mike Monteiro, words are insufficient. He is the best 
partner in all things, and encourages me to be a better person 
in all ways.
And finally, big thanks to the little dog who remained at my 
side, through every late night and rewrite. Rupert can’t read, but 
my research shows he really appreciates chicken.

 	
Index	 153	
A
A/B testing, 138
affinity diagrams, 116
agile development, 25
analysis sessions, 52
analytics, 135
assumptions, 79
audio recording, 110
B
Baty, Steve, 60
best practices, 32
bias, 28
bounce rates, 136
Bowman, Doug, 142
brand audits, 98
C
checklists, 28, 32, 88, 103, 108
Chen, Andrew, 141
competitive audits, 97
contextual inquiry, 90
conversion, 135
Cook, Scott, 90
D
daily life observation, 83
data collection, 45
Design Staff (blog), 58
documentation, 72
E
ethics, 30
ethnography, 82
Ethnography Field Guide, 88
eye-tracking, 112
F
focus groups, 91
Ford, Paul, 62
G
gap analysis, 129
Google analytics, 136
Google Ventures Design Studio, 58
H
habits, 78
Helsinki Design Lab, 88
heuristic analysis, 103
House M.D., 80
Humphrey, Albert S., 96
I
ICC/ESOMAR Code on Market and 
Social Research, 30
IDEO, 6
informed consent, 31
Internet & American Life Project, 50
interviews
	
hostility during, 68
	
overview of, 47
	
with stakeholders, 60
	
with users, 84
intuitive design, 127
L
literature reviews, 50
logo assessment, 100
M
MailChimp, 111
mental models, 78, 126
	
diagrams, 128
Merton, Robert K., 92
Molich, Rolf, 103
Mule Design, 4, 12, 14, 23, 62
N
Nielsen, Jakob, 103, 105
index

	
154 	 Just Enough Research
O
oppositions to research, 18
outliers, 54
P
participant observation, 83
Patton, Jeff, 26
Perfetti, Christine, 43
personas, 119
Pew Research Center, 50
R
recruiting participants, 41, 109
research, 
	
basic definitions of, 5
	
causal, 15
	
descriptive, 14
	
evaluative, 15
	
explanatory, 14
	
exploratory, 13
	
generative, 13
	
tools for, 46
researchers, 
	
agency, 23
	
freelance, 23
	
in-house, 24
	
roles, 16
S
scenario development, 124
screeners, 42
Segways, 1
split testing, 137
stakeholders, 59
	
analysis, 71
	
interviews with, 60
Suri, Jane Fulton, 6
surveys, 42
SWOT analysis, 96
T
task analysis, 130
traffic analysis, 136
U
usability testing, 47, 105
	
analysis, 113
	
facilitating, 109
	
methodology, 107
user needs, 80
V
video recording, 110
W
workflow analysis, 130
workflow diagrams, 74
Y
Young, Indi, 127

About A Book Apart
We cover the emerging and essential topics in web design and 
development with style, clarity, and above all, brevity—because 
working designer-developers can’t afford to waste time.
colophon
The text is set in FF Yoga and its companion, FF Yoga Sans, both 
by Xavier Dupré. Headlines and cover are set in Titling Gothic 
by David Berlow.
This book was printed in the United States 
using FSC certified Finch papers.

About the author
Erika Hall has been working in web 
design and development since the 
late 20th century. In 2001, she co-
founded Mule Design Studio where 
she directs the research, interaction 
design, and strategy practices. Erika 
speaks and writes frequently about 
cross-disciplinary collaboration and 
the importance of natural language in 
user interfaces. In her spare time, she 
battles empty corporate jargon at Unsuck It. She also co-hosts 
Running from the Law, a weekly podcast on business law and 
endurance fitness, and can probably outrun you.
Photo by Mike Monteiro 

