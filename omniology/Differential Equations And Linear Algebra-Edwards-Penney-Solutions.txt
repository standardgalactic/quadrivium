 
Section 1.1 
1 
 
CHAPTER 1 
 
FIRST-ORDER DIFFERENTIAL EQUATIONS 
 
 
SECTION 1.1 
 
DIFFERENTIAL EQUATIONS AND MATHEMATICAL MODELS 
 
The main purpose of Section 1.1 is simply to introduce the basic notation and terminology of 
differential equations, and to show the student what is meant by a solution of a differential 
equation.  Also, the use of differential equations in the mathematical modeling of real-world 
phenomena is outlined. 
 
 
Problems 1–12 are routine verifications by direct substitution of the suggested solutions into the 
given differential equations.  We include here just some typical examples of such verifications. 
 
 
3. 
If  
1
2
cos2
and
sin 2
y
x
y
x
=
=
,  then  
1
2
2sin2
and
2cos 2
y
x
y
x
′
′
= −
=
 so 
 
1
1
4cos2
4
y
x
y
′′ = −
= −
     and     
2
2
4sin 2
4
.
y
x
y
′′ = −
= −
 
 
 
Thus  
1
1
4
0
y
y
′′+
=
 and  
2
2
4
0.
y
y
′′ +
=
 
 
4. 
If  
3
3
1
2
and
x
x
y
e
y
e−
=
=
,  then  
3
3
1
2
3
and
3
x
x
y
e
y
e−
=
= −
  so 
 
3
1
1
9
9
x
y
e
y
′′ =
=
     and     
3
2
2
9
9
.
x
y
e
y
−
′′ =
=
 
 
5. 
If  
x
x
y
e
e−
=
−
,  then  
x
x
y
e
e−
′ =
+
 so  
(
) (
)
2
.
x
x
x
x
x
y
y
e
e
e
e
e
−
−
−
′ −
=
+
−
−
=
  Thus 
 
2
.
x
y
y
e−
′ =
+
 
 
6. 
If  
2
2
1
2
and
x
x
y
e
y
x e
−
−
=
=
,  then  
2
2
2
2
1
1
2
2
,
4
,
2
,
x
x
x
x
y
e
y
e
y
e
xe
−
−
−
−
′
′′
′
= −
=
=
−
 and  
2
2
2
4
4
.
x
x
y
e
xe
−
−
′′ = −
+
  Hence 
 
 
 
 
(
)
(
)
(
)
2
2
2
1
1
1
4
4
4
4
2
4
0
x
x
x
y
y
y
e
e
e
−
−
−
′′
′
+
+
=
+
−
+
=
 
 
and 
 
 
(
)
(
)
(
)
2
2
2
2
2
2
2
2
4
4
4
4
4
2
4
0.
x
x
x
x
x
y
y
y
e
xe
e
xe
x e
−
−
−
−
−
′′
′
+
+
=
−
+
+
−
+
=
 

2 
Chapter 1 
 
8. 
If  
1
2
cos
cos2
and
sin
cos2 ,
y
x
x
y
x
x
=
−
=
−
  then  
1
sin
2sin2 ,
y
x
x
′ = −
+
  
1
cos
4cos2 ,
y
x
x
′′= −
+
 and  
2
2
cos
2sin2 ,
sin
4cos2 .
y
x
x
y
x
x
′
′′
=
+
= −
+
  Hence 
 
 
 
(
)
(
)
1
1
cos
4cos2
cos
cos2
3cos2
y
y
x
x
x
x
x
′′+
=
−
+
+
−
=
 
 
and 
 
 
(
)
(
)
2
2
sin
4cos2
sin
cos2
3cos2 .
y
y
x
x
x
x
x
′′ +
=
−
+
+
−
=
 
 
 
11. 
If  
2
1
y
y
x−
=
=
  then  
3
4
2
and
6
,
y
x
y
x
−
−
′
′′
= −
=
  so 
 
 
 
(
)
(
)
(
)
2
2
4
3
2
5
4
6
5
2
4
0.
x y
x y
y
x
x
x
x
x
−
−
−
′′
′
+
+
=
+
−
+
=
 
 
 
If  
2
2
ln
y
y
x
x
−
=
=
  then  
3
3
4
4
2
ln
and
5
6
ln ,
y
x
x
x
y
x
x
x
−
−
−
−
′
′′
=
−
= −
+
  so 
 
 
 
(
)
(
)
(
)
(
) (
)
2
2
4
4
3
3
2
2
2
2
2
2
5
4
5
6
ln
5
2
ln
4
ln
5
5
6
10
4
ln
0.
x y
x y
y
x
x
x
x
x x
x
x
x
x
x
x
x
x
x
x
−
−
−
−
−
−
−
−
−
−
′′
′
+
+
=
−
+
+
−
+
=
−
+
+
−
+
=
 
 
 
 
13. 
Substitution of  
rx
y
e
=
  into  3
2
y
y
′ =
 gives the equation  3
2
rx
rx
re
e
=
 that simplifies 
to  3
2.
r =
  Thus  r = 2/3. 
 
 
14. 
Substitution of  
rx
y
e
=
  into  4y
y
′′ =
 gives the equation  
2
4
rx
rx
r e
e
=
 that simplifies to  
2
4
1.
r =
  Thus  
1/ 2.
r = ±
 
 
 
15. 
Substitution of  
rx
y
e
=
  into  
2
0
y
y
y
′′
′
+
−
=
 gives the equation  
2
2
0
rx
rx
rx
r e
r e
e
+
−
=
 
that simplifies to  
2
2
(
2)(
1)
0.
r
r
r
r
+
−
=
+
−
=
  Thus  r = –2  or  r = 1. 
 
 
16. 
Substitution of  
rx
y
e
=
  into  3
3
4
0
y
y
y
′′
′
+
−
=
 gives the equation  
2
3
3
4
0
rx
rx
rx
r e
re
e
+
−
=
 that simplifies to  
2
3
3
4
0.
r
r
+
−
=
  The quadratic formula then 
gives the solutions  
(
)
3
57 /6.
r =
−±
 
 
 
The verifications of the suggested solutions in Problems 17–26 are similar to those in Problems 
1–12.  We illustrate the determination of the value of  C  only in some typical cases.  However, 
we illustrate typical solution curves for each of these problems. 

 
Section 1.1 
3 
−5
0
5
−5
0
5
x
y
(0,3)
−10
−5
0
5
10
−20
0
20
x
y
(0,10)
17. 
C  =  2 
18. 
C  =  3 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
19. 
If  ( )
1
x
y x
C e
=
− then  y(0) = 5  gives  C – 1  =  5,  so   C  =  6.  The figure is on the 
 
left below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
20. 
If  ( )
1
x
y x
C e
x
−
=
+
− then  y(0) = 10  gives  C – 1  =  10,  so   C  =  11.  The figure is 
 
on the right above. 
 
21. 
C  =  7.  The figure is on the left at the top of the next page. 
 
 
−5
0
5
−5
0
5
x
y
(0,2)
−5
0
5
−10
−5
0
5
10
x
y
(0,5)

4 
Chapter 1 
−20
−10
0
10
20
−5
0
5
x
y
(0,0)
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
−30
−20
−10
0
10
20
30
x
y
(1,1)
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
22. 
If  ( )
ln(
)
y x
x
C
=
+
 then  y(0) = 0  gives  ln C  =  0,  so   C  =  1. The figure is on the 
 
right above. 
 
 
23. 
If  
5
2
1
4
( )
y x
x
C x−
=
+
 then  y(2) = 1  gives  the equation  1
1
4
8
32
1
C
⋅
+
⋅
=
  with 
solution  C = –56.  The figure is on the left below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
24. 
C  =  17.  The figure is on the right above. 
 
−2
−1
0
1
2
−10
−5
0
5
10
x
y
(0,7)
0
1
2
3
−30
−20
−10
0
10
20
30
x
y
(2,1)

 
Section 1.1 
5 
25. 
If  
2
( )
tan(
)
y x
x
C
=
+
 then  y(0) = 1  gives  the equation  tan C  =  1.  Hence one value 
of  C  is  
/ 4
C
π
=
 (as is this value plus any integral multiple of  π). 
−2
−1
0
1
2
−4
−2
0
2
4
x
y
(0,1)
 
 
 
26. 
Substitution of  x = π   and  y = 0  into  
(
)cos
y
x
C
x
=
+
 yields the equation  
0
(
)( 1),
C
π
=
+
−
 so  
.
C
π
= −
 
0
5
10
−10
−5
0
5
10
x
y
(π,0)
 
 
 
27. 
y
x
y
′ =
+
 
 
 
28. 
The slope of the line through  ( , ) and ( / 2,0)
x y
x
  is  
(
0)/(
/ 2)
2 / ,
y
y
x
x
y x
′ =
−
−
=
  
so the differential equation is  
2 .
x y
y
′ =
 
 

6 
Chapter 1 
29. 
If  m
y′
=
 is the slope of the tangent line and  m′ is the slope of the normal line at  
( , ),
x y
 then the relation  
1
mm′ = − yields  
1/
(
1) /(
0).
m
y
y
x
′
′
=
=
−
−
  Solution for  
y′  then gives the differential equation  (1
)
.
y y
x
′
−
=
 
 
30. 
Here  
2
and
(
)
2 ,
x
m
y
m
D
x
k
x
′
′
=
=
+
=
 so the orthogonality relation 
1
mm′ = − gives 
the differential equation  2
1.
x y′ = −
 
 
31. 
The slope of the line through  ( , ) and (
, )
x y
y x
−
  is  
(
)/(
),
y
x
y
y
x
′ =
−
−
−
  so the 
differential equation is  (
)
.
x
y y
y
x
′
+
=
−
 
 
 
In Problems 32–36 we get the desired differential equation when we replace the "time rate of 
change" of the dependent variable with its derivative, the word "is" with the = sign, the phrase 
"proportional to" with  k,  and finally translate the remainder of the given sentence into symbols. 
 
32. 
/
dP dt
k
P
=
 
 
 
 
 
33. 
2
/
dv dt
k v
=
  
 
 
 
 
34. 
/
(250
)
dv dt
k
v
=
−
 
 
35. 
/
(
)
dN dt
k P
N
=
−
  
 
 
 
36. 
/
(
)
dN dt
k N P
N
=
−
 
 
37. 
The second derivative of any linear function is zero, so we spot the two solutions 
 
( )
1 or
( )
y x
y x
x
≡
=
of the differential equation  
0.
y′′ =
 
 
 
 
38. 
A function whose derivative equals itself, and hence a solution of the differential 
 
equation  y
y
′ =
 is ( )
.
x
y x
e
=
 
 
39. 
We reason that if  
2,
y
kx
=
 then each term in the differential equation is a multiple of 
2.
x  
 
The choice  
1
k =   balances the equation, and provides the solution
2
( )
.
y x
x
=
 
 
 
 
 
40. 
If  y  is a constant, then  
0
y′ ≡
 so the differential equation reduces to  
2
1.
y =
 This gives 
 
the two constant-valued solutions  ( )
1 and
( )
1.
y x
y x
≡
≡−
 
 
41. 
We reason that if  
,
x
y
ke
=
 then each term in the differential equation is a multiple of 
.
xe
 
 
The choice  
1
2
k =
  balances the equation, and provides the solution
1
2
( )
.
x
y x
e
=
  
 
 
 

 
Section 1.1 
7 
0
1
2
3
4
0
1
2
3
4
5
6
t
x
42. 
Two functions, each equaling the negative of  its own second derivative, are the two 
 
solutions  ( )
cos
y x
x
=
 and  ( )
sin
y x
x
=
  of the differential equation  
.
y
y
′′ = −
 
 
43. 
(a) 
We need only substitute  ( )
1/(
)
x t
C
kt
=
−
  in both sides of the differential 
 
equation  
2
x
kx
′ =
 for a routine verification. 
 
 
(b) 
The zero-valued function  ( )
0
x t ≡
 obviously satisfies the initial value problem 
 
2,
(0)
0.
x
kx
x
′ =
=
 
 
44. 
(a) 
The figure on the left below shows typical graphs of solutions of the differential 
 
equation  
2
1
2
.
x
x
′ =
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(b) 
The figure on the right above shows typical graphs of solutions of the differential 
 
equation  
2
1
2
.
x
x
′ = −
  We see that — whereas the graphs with  
1
2
k =
 appear to "diverge 
 
to infinity" — each solution with  
1
2
k = − appears to approach 0 as  
.
t →∞  Indeed, we 
 
see from the Problem 43(a) solution  
1
2
( )
1/(
)
x t
C
t
=
−
 that  ( )
x t →∞ as  
2 .
t
C
→
  
 
However, with  
1
2
k = − it is clear from the resulting solution  
1
2
( )
1/(
)
x t
C
t
=
+
  that  
 
( )
x t  remains  bounded on any finite interval, but ( )
0
x t →
  as  
.
t →+∞ 
 
45. 
Substitution of  
1 and
10
P
P
′ =
=
 into the differential equation  
2
P
kP
′ =
 gives  
1
100 ,
k =
 
 
so Problem 43(a) yields a solution of the form  
( )
1/(
/100).
P t
C
t
=
−
  The initial 
 
condition  
(0)
2
P
=
 now yields  
1
2 ,
C =
 so we get the solution 
 
 
 
 
  
1
100
( )
.
1
50
2
100
P t
t
t
=
=
−
−
 
0
1
2
3
4
0
1
2
3
4
5
t
x

8 
Chapter 1 
 
 
We now find readily that  
100 when
49,
P
t
=
=
  and that  
1000 when
49.9.
P
t
=
=
 
 
It appears that  P  grows without bound (and thus "explodes") as  t  approaches 50. 
 
46. 
Substitution of  
1 and
5
v
v
′ = −
=
 into the differential equation  
2
v
kv
′ =
  gives  
 
1
25 ,
k = −
so Problem 43(a) yields a solution of the form  ( )
1/(
/ 25).
v t
C
t
=
+
  The initial 
 
condition (0)
10
v
=
 now yields  
1
10 ,
C =
 so we get the solution 
 
 
 
 
 
  
1
50
( )
.
1
5
2
10
25
v t
t
t
=
=
+
+
 
 
 
We now find readily that  
1 when
22.5,
v
t
=
=
  and that  
0.1 when
247.5.
v
t
=
=
 
 
It appears that  v  approaches 0 as  t  increases without bound.  Thus the boat gradually 
 
slows, but never comes to a "full stop" in a finite period of time. 
 
47. 
(a) 
(10)
10 yields 10
1/(
10), so
101/10.
y
C
C
=
=
−
=
 
 
(b) 
There is no such value of  C,  but the constant function  ( )
0
y x ≡
 satisfies the 
conditions  
2 and
(0)
0.
y
y
y
′ =
=
 
 
(c) 
It is obvious visually (in Fig. 1.1.8 of the text) that one and only one solution 
curve passes through each point  ( , )
a b  of the xy-plane, so it follows that there exists a 
unique solution to the initial value problem  
2,
( )
.
y
y
y a
b
′ =
=
 
 
48. 
(b) 
Obviously the functions  
4
4
( )
and
( )
u x
x
v x
x
= −
= +
 both satisfy the differential 
equation  
4 .
xy
y
′ =
  But their derivatives  
3
3
( )
4
and
( )
4
u x
x
v x
x
′
′
= −
= +
 match at   
 
x  =  0,  where both are zero.  Hence the given piecewise-defined function  ( )
y x  is 
differentiable, and therefore satisfies the differential equation because  ( ) and
( )
u x
v x  
do so (for  
0 and
0,
x
x
≤
≥
 respectively). 
 
 
(c) 
If  a ≥ 0  (for instance), choose  C+  fixed so that  
4
.
C a
b
+
=
  Then the function 
 
 
 
 
 
 
4
4
if
0,
( )
if
0
C x
x
y x
C x
x
−
+

≤
= 
≥

 
 
 
satisfies the given differential equation for every real number value of   
.
C− 
 
 
 
 

 
Section 1.2 
9 
SECTION 1.2 
 
INTEGRALS AS GENERAL AND PARTICULAR SOLUTIONS 
 
This section introduces general solutions and particular solutions in the very simplest situation 
— a differential equation of the form  
( )
y
f x
′=
— where only direct integration and evaluation 
of the constant of integration are involved.  Students should review carefully the elementary 
concepts of velocity and acceleration, as well as the fps and mks unit systems. 
 
1. 
Integration of  
2
1
y
x
′ =
+   yields  
2
( )
(2
1)
.
y x
x
dx
x
x
C
=
+
=
+
+
∫
  Then substitution 
of  
0,
3
x
y
=
=
 gives  3  =  0 + 0 + C  =  C,  so  
2
( )
3.
y x
x
x
=
+
+
 
 
2. 
Integration of  
2
(
2)
y
x
′ =
−
  yields  
2
3
1
3
( )
(
2)
(
2)
.
y x
x
dx
x
C
=
−
=
−
+
∫
  Then 
substitution of  
2,
1
x
y
=
=  gives  1  =  0 + C  =  C,  so  
3
1
3
( )
(
2) .
y x
x
=
−
 
 
3. 
Integration of  y
x
′ =
  yields  
3/ 2
2
3
( )
.
y x
x dx
x
C
=
=
+
∫
  Then substitution of  
4,
0
x
y
=
=
 gives  
16
3
0
,
C
=
+
  so  
3/ 2
2
3
( )
(
8).
y x
x
=
−
 
 
4. 
Integration of  
2
y
x−
′ =
  yields  
2
( )
1/
.
y x
x
dx
x
C
−
=
= −
+
∫
  Then substitution of  
1,
5
x
y
=
=
 gives  5
1
,
C
= −+
  so  ( )
1/
6.
y x
x
= −
+
 
 
5. 
Integration of  
1/ 2
(
2)
y
x
−
′ =
+
  yields  
1/ 2
( )
(
2)
2
2
.
y x
x
dx
x
C
−
=
+
=
+
+
∫
  Then 
substitution of  
2,
1
x
y
=
= − gives  1
2 2
,
C
−=
⋅
+
  so  ( )
2
2
5.
y x
x
=
+
−
 
 
6. 
Integration of  
2
1/ 2
(
9)
y
x x
′ =
+
  yields  
2
1/ 2
2
3/ 2
1
3
( )
(
9)
(
9)
.
y x
x x
dx
x
C
=
+
=
+
+
∫
  
Then substitution of  
4,
0
x
y
= −
=
 gives  
3
1
3
0
(5)
,
C
=
+
  so  
2
3/ 2
1
3
( )
(
9)
125 .
y x
x


=
+
−

 
 
7. 
Integration of  
2
10/(
1)
y
x
′ =
+
  yields  
2
1
( )
10/(
1)
10tan
.
y x
x
dx
x
C
−
=
+
=
+
∫
  Then 
substitution of  
0,
0
x
y
=
=
 gives  0
10 0
,
C
=
⋅+
  so  
1
( )
10tan
.
y x
x
−
=
 
 
8. 
Integration of  
cos2
y
x
′ =
  yields  
1
2
( )
cos2
sin2
.
y x
x dx
x
C
=
=
+
∫
  Then substitution 
of  
0,
1
x
y
=
=  gives  1
0
,
C
=
+
  so  
1
2
( )
sin2
1.
y x
x
=
+
 
 
9. 
Integration of  
2
1/ 1
y
x
′ =
−
  yields  
2
1
( )
1/ 1
sin
.
y x
x dx
x
C
−
=
−
=
+
∫
  Then 
substitution of  
0,
0
x
y
=
=
 gives  0
0
,
C
=
+
  so  
1
( )
sin
.
y x
x
−
=
 

10 
Chapter 1 
 
10. 
Integration of  
x
y
x e−
′ =
  yields   
 
( )
(
1)
(
1)
x
u
u
x
y x
xe
dx
ue du
u
e
x
e
C
−
−
=
=
=
−
= −
+
+
∫
∫
   
 
(when we substitute  u
x
= −
 and apply Formula #46 inside the back cover of the 
textbook).  Then substitution of  
0,
1
x
y
=
=  gives  1
1
,
C
= −+
  so  
( )
(
1)
2.
x
y x
x
e−
= −
+
+
 
 
11. 
If  ( )
50
a t
=
 then  
0
( )
50
50
50
10.
v t
dt
t
v
t
=
=
+
=
+
∫
  Hence 
 
 
 
2
2
0
( )
(50
10)
25
10
25
10
20.
x t
t
dt
t
t
x
t
t
=
+
=
+
+
=
+
+
∫
 
 
12. 
If  ( )
20
a t
= −
 then  
0
( )
( 20)
20
20
15.
v t
dt
t
v
t
=
−
= −
+
= −
−
∫
  Hence 
 
 
 
2
2
0
( )
( 20
15)
10
15
10
15
5.
x t
t
dt
t
t
x
t
t
=
−
−
= −
−
+
= −
−
+
∫
 
 
13. 
If  ( )
3
a t
t
=
 then  
2
2
3
3
0
2
2
( )
3
5.
v t
t dt
t
v
t
=
=
+
=
+
∫
  Hence 
 
 
 
2
3
3
3
1
1
0
2
2
2
( )
(
5)
5
5 .
x t
t
dt
t
t
x
t
t
=
+
=
+
+
=
+
∫
 
 
14. 
If  ( )
2
1
a t
t
=
+  then  
2
2
0
( )
(2
1)
7.
v t
t
dt
t
t
v
t
t
=
+
=
+ +
=
+ −
∫
  Hence 
 
 
 
2
3
3
1
1
1
1
0
3
2
3
2
( )
(
7)
7
7
4.
x t
t
t
dt
t
t
t
x
t
t
t
=
+ −
=
+
−
+
=
+
−
+
∫
 
 
15. 
If  
2
( )
4(
3) .
a t
t
=
+
 then  
2
3
3
4
4
3
3
( )
4(
3)
(
3)
(
3)
37
v t
t
dt
t
C
t
=
+
=
+
+
=
+
−
∫
 (taking  
C = –37  so that  v(0) = –1).  Hence 
 
 
 
3
4
4
4
1
1
3
3
3
( )
(
3)
37
(
3)
37
(
3)
37
26.
x t
t
dt
t
t
C
t
t


=
+
−
=
+
−
+
=
+
−
−


∫
 
 
16. 
If  ( )
1/
4
a t
t
=
+
 then  ( )
1/
4
2
4
2
4
5
v t
t
dt
t
C
t
=
+
=
+
+
=
+
−
∫
  (taking   
C = –5  so that  v(0) = –1).  Hence 
 
 
 
3/ 2
3/ 2
29
4
4
3
3
3
( )
(2
4
5)
(
4)
5
(
4)
5
x t
t
dt
t
t
C
t
t
=
+
−
=
+
−
+
=
+
−
−
∫
 
 
 
(taking  
29 /3
C = −
 so that  (0)
1
x
= ). 

 
Section 1.2 
11 
 
17. 
If  
3
( )
(
1)
a t
t
−
=
+
 then  
3
2
2
1
1
1
2
2
2
( )
(
1)
(
1)
(
1)
v t
t
dt
t
C
t
−
−
−
=
+
= −
+
+
= −
+
+
∫
  
 
(taking  
1
2
C =
  so that  v(0) = 0).  Hence 
 
 
 
2
1
1
1
1
1
1
1
2
2
2
2
2
( )
(
1)
(
1)
(
1)
1
x t
t
dt
t
t
C
t
t
−
−
−




=
−
+
+
=
+
+
+
=
+
+ −




∫
 
 
 
(taking  
1
2
C = −
 so that  (0)
0
x
=
). 
 
 
18. 
If  ( )
50sin5
a t
t
=
 then  ( )
50sin5
10cos5
10cos5
v t
t dt
t
C
t
=
= −
+
= −
∫
  (taking   
0
C =
  so that  v(0) = –10).  Hence 
 
 
 
( )
( 10cos5 )
2sin5
2sin5
10
x t
t dt
t
C
t
=
−
= −
+
= −
+
∫
 
 
 
(taking  
10
C = −
 so that  (0)
8
x
=
). 
 
 
19. 
Note that  ( )
5
v t =
 for  0
5
t
≤≤
 and that ( )
10
v t
t
=
− for  5
10.
t
≤≤
  Hence   
 
1
( )
5
x t
t
C
=
+
for  0
5
t
≤≤
 and  
2
1
2
2
( )
10
x t
t
t
C
=
−
+
 for  5
10.
t
≤≤
 Now  
1
0
C =
 
 
because  (0)
0,
x
=
 and continuity of  ( )
x t  requires that  ( )
5
x t
t
=
  and  
 
2
1
2
2
( )
10
x t
t
t
C
=
−
+
agree when  
5.
t =
  This implies that  
25
2
2 ,
C = −
 and we get the 
 
following graph. 
 
 
0
2
4
6
8
10
0
10
20
30
40
(5,25)
t
v
 
 
 
 

12 
Chapter 1 
0
2
4
6
8
10
0
10
20
30
40
(5,12.5)
t
v
 
20. 
Note that  ( )
v t
t
=  for  0
5
t
≤≤
 and that ( )
5
v t =
 for  5
10.
t
≤≤
  Hence   
2
1
1
2
( )
x t
t
C
=
+
 
 
for  0
5
t
≤≤
 and  
2
( )
5
x t
t
C
=
+
 for  5
10.
t
≤≤
 Now  
1
0
C =
 because  (0)
0,
x
=
 and 
 
continuity of  ( )
x t  requires that  
2
1
2
( )
x t
t
=
  and  
2
( )
5
x t
t
C
=
+
 agree when  
5.
t =
  
 
This implies that  
25
2
2 ,
C = −
 and we get the graph on the left below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
21. 
Note that  ( )
v t
t
=  for  0
5
t
≤≤
 and that ( )
10
v t
t
=
− for  5
10.
t
≤≤
  Hence   
 
2
1
1
2
( )
x t
t
C
=
+
 for  0
5
t
≤≤
 and  
2
1
2
2
( )
10
x t
t
t
C
=
−
+
 for  5
10.
t
≤≤
 Now  
1
0
C =
 
 
because  (0)
0,
x
=
 and continuity of  ( )
x t  requires that  
2
1
2
( )
x t
t
=
  and  
 
2
1
2
2
( )
10
x t
t
t
C
=
−
+
agree when  
5.
t =
  This implies that  
2
25,
C = −
 and we get the 
 
graph on the right above. 
 
 
22. 
For 0
3:
t
≤≤
  
5
3
( )
v t
t
=
  so  
2
5
1
6
( )
.
x t
t
C
=
+
  Now  
1
0
C =
  because  (0)
0,
x
=
 so  
 
2
5
6
( )
x t
t
=
  on this first interval, and its right endpoint value is  
1
2
(3)
7 .
x
=
 
 
 
For 3
7 :
t
≤≤
  ( )
5
v t =
  so  
2
( )
5
.
x t
t
C
=
+
  Now  
1
2
(3)
7
x
=
 implies that  
1
2
2
7 ,
C = −
  
 
 
so  
1
2
( )
5
7
x t
t
=
−
  on this second interval, where its right endpoint value is  
1
2
(7)
27 .
x
=
 
 
 
For 7
10 :
t
≤≤
  
5
3
5
(
7),
v
t
−
= −
−
  so  
5
50
3
3
( )
.
v t
t
= −
+
  Hence  
2
5
50
3
6
3
( )
,
x t
t
t
C
= −
+
+
 
 
and  
1
2
(7)
27
x
=
 implies that  
290
3
6 .
C = −
  Finally,  
2
1
6
( )
( 5
100
290)
x t
t
t
=
−
+
−
  on this 
 
third interval, and we get the graph at the top of the next page. 
 
 
0
2
4
6
8
10
0
10
20
30
40
(5,12.5)
t
v

 
Section 1.2 
13 
0
2
4
6
8
10
0
10
20
30
40
(3,7.5)
(7,27.5)
t
v
 
 
 
23. 
v  =  –9.8t + 49,  so the ball reaches its maximum height  (v = 0) after  t = 5 seconds.  Its 
 
maximum height then is  y(5) = –4.9(5)2 + 49(5) = 122.5 meters. 
 
24. 
v  =  –32t  and   y  =  –16t2 + 400,  so the ball hits the ground  (y  =  0)  when   
 
t  =  5 sec,  and then  v  =  –32(5)  = –160 ft/sec. 
  
25. 
a  =  –10 m/s2  and  v0  =  100 km/h  ≈  27.78 m/s,  so  v  =  –10t + 27.78,  and hence 
x(t)  =  –5t2 + 27.78t.  The car stops when  v  =  0,  t  ≈  2.78,  and thus the distance 
traveled before stopping is  x(2.78)  ≈  38.59  meters. 
 
26. 
v  =  –9.8t + 100  and  y  =  –4.9t2 + 100t + 20. 
 
 
(a) 
v  =  0  when  t = 100/9.8  so the projectile's maximum height is 
 
y(100/9.8)  =  –4.9(100/9.8)2 + 100(100/9.8) + 20  ≈  530 meters. 
 
 
(b) 
It passes the top of the building when  y(t)  =  –4.9t2 + 100t + 20  =  20, 
 
and hence after  t = 100/4.9  ≈  20.41 seconds. 
 
 
(c) 
The roots of the quadratic equation  y(t)  =  –4.9t2 + 100t + 20  =  0  are   
 
t  =  –0.20,  20.61.  Hence the projectile is in the air  20.61 seconds. 
 
27. 
a  =  –9.8 m/s2  so  v  =  –9.8 t – 10  and 
y  =  –4.9 t2 – 10 t + y0. 
 
 
The ball hits the ground when   y  =  0  and 
v  =  –9.8 t – 10  =  –60, 
 
so  t ≈ 5.10 s.  Hence 
 
 
 
 
 
y0  =  4.9(5.10)2 + 10(5.10) ≈ 178.57 m. 

14 
Chapter 1 
    
28. 
v  =  –32t – 40  and   y  =  –16t2 – 40t + 555.  The ball hits the ground  (y  =  0) 
when  t  ≈  4.77 sec,  with velocity  v  =  v(4.77)  ≈  –192.64 ft/sec,  an impact 
speed of about 131 mph. 
 
29. 
Integration of  dv/dt = 0.12 t3 + 0.6 t,  v(0) = 0  gives  v(t) = 0.3 t2 + 0.04 t3.  Hence 
 
v(10) = 70.  Then integration of  dx/dt = 0.3 t2 + 0.04 t3,   x(0) = 0  gives 
 
x(t) = 0.1 t3 + 0.04 t4,  so  x(10) = 200.  Thus after 10 seconds the car has gone 200 ft and 
is traveling at 70 ft/sec.  
            
30. 
Taking  x0  =  0  and  v0  =  60 mph  =  88 ft/sec,  we get   
 
 
 
 
 
 
v  =   –at + 88,  
 
 
and  v  =  0  yields  t  =  88/a.  Substituting this value of  t  and  x  =  176  in   
 
 
 
 
 
 
x  =  –at2/2 + 88t,  
 
 
we solve for  a  =  22 ft/sec2.  Hence the car skids for  t  =  88/22  =  4 sec. 
 
31. 
If  a  =  –20 m/sec2  and  x0  =  0  then the car's velocity and position at time  t  are given 
by 
       
 
 
 
v  =  –20t + v0,     x  =  –10 t2 + v0t. 
 
 
It stops when  v  =  0  (so  v0  =  20t),  and hence when 
         
 
 
 
 
x  =  75  =  –10 t2 + (20t)t  =  10 t2. 
 
 
Thus  t  =  
7.5   sec  so 
 
 
 
 
 
v0  =  20
7.5   ≈  54.77 m/sec  ≈  197 km/hr. 
           
32. 
Starting with  x0  =  0  and  v0  =  50 km/h  =  5×104 m/h,  we find by the method of 
Problem 30 that the car's deceleration is  a  =  (25/3)×107 m/h2.  Then, starting with  x0  =  
0  and  v0  =  100 km/h  =  105 m/h,  we substitute  t  =  v0/a  into   
 
 
 
 
 
 
x  =   –at2/2 + v0t   
 
 
and find that  x  =  60 m  when v  =  0.  Thus doubling the initial velocity quadruples the 
distance the car skids. 
 
33. 
If  v0  =  0  and   y0  =  20  then 
 
 
 
 
 
v  =  –at  and   y  =  – 1
2 at2 + 20. 
 

 
Section 1.2 
15 
 
Substitution of   t  =  2,   y  =  0  yields  a  =  10 ft/sec2.  If  v0  =  0  and    
 
y0  =  200  then 
 
 
 
 
 
v  =  –10t  and   y  =  –5t2 + 200. 
 
 
Hence   y  =  0  when  t  =  
40   =  2 10  sec  and  v  =  –20 10   ≈  –63.25 ft/sec. 
  
34. 
On Earth:    v  =  –32t + v0,  so  t  =  v0/32  at maximum height (when v  =  0).  
Substituting this value of  t  and   y  =  144  in 
  
 
 
 
 
 
y  =  –16t2 + v0t,  
 
 
we solve for  v0  =  96 ft/sec  as the initial speed with which the person can throw a ball 
straight upward.  
 
 
On Planet Gzyx:    From Problem 27, the surface gravitational acceleration on planet 
Gzyx is  a  =  10 ft/sec2,  so  
 
 
 
 
 
v  =   –10t + 96     and      y  =  –5t2 + 96t.   
 
 
Therefore  v  =  0  yields  t  =  9.6 sec,  and thence   ymax  =   y(9.6)  =  460.8 ft  is the 
height a ball will reach if its initial velocity is  96 ft/sec. 
 
35. 
If  v0  =  0  and   y0  =  h  then the stone′s velocity and height are given by 
 
 
 
 
 
v  =  –gt,      y = –0.5 gt2 + h. 
 
 
 
Hence   y  =  0  when  t  =  
2 /
h g   so 
 
 
 
 
 
v  =  –g
2 /
h g   =  –
2gh .   
 
36. 
The method of solution is precisely the same as that in Problem 30.  We find first that, on 
Earth, the woman must jump straight upward with initial velocity  v0  =  12 ft/sec  to 
reach a maximum height of 2.25 ft.  Then we find that, on the Moon, this initial velocity 
yields a maximum height of about 13.58 ft.   
 
37. 
We use units of miles and hours.  If  x0  =  v0  =  0  then the car′s velocity and position 
after  t  hours are given by 
 
 
 
 
 
v  =  at,      x  =  1
2 t2. 
 
 
Since  v  =  60  when  t  =  5/6,  the velocity equation yields  a  =  72 mi/hr2.  Hence the 
distance traveled by  12:50 pm  is 
 
      
 
 
 
 
x  =  (0.5)(72)(5/6)2  =  25  miles. 
 

16 
Chapter 1 
38. 
Again we have 
 
 
 
 
 
v  =  at,      x  =  1
2 t2. 
 
 
But now  v  =  60  when  x  =  35.  Substitution of  a  =  60/t  (from the velocity equation) 
into the position equation yields 
 
 
 
 
 
 
35  =  (0.5)(60/t)(t2)  =  30t, 
 
 
whence  t  =  7/6 hr, that is,  1:10 p.m. 
 
 
39. 
Integration of  y′  =  (9/vS)(1 – 4x2)  yields 
 
 
 
 
 
 
y  =  (3/vS)(3x – 4x3) + C, 
 
 
and the initial condition   y(–1/2)  =  0  gives  C  =  3/vS.  Hence the swimmer′s trajectory 
is 
 
 
 
 
 
y(x)  =  (3/vS)(3x – 4x3 + 1). 
 
 
Substitution of   y(1/2)  =  1  now gives  vS  =  6 mph. 
 
40. 
Integration of  y′  =  3(1 – 16x4)  yields 
 
 
 
 
 
 
y  =  3x – (48/5)x5 + C, 
 
 
and the initial condition   y(–1/2)  =  0  gives  C  =  6/5.  Hence the swimmer′s trajectory 
is 
 
 
 
 
 
y(x)  =  (1/5)(15x – 48x5 + 6), 
 
 
so his downstream drift is   y(1/2)  =  2.4 miles. 
 
41. 
The bomb equations are  
2
32,
32, and
16
800,
B
a
v
s
s
t
= −
= −
=
= −
+
 with  
0
t =
 at the 
 
instant  the bomb is dropped.  The projectile is fired at time  
2,
t =
 so its corresponding 
 
equations are  
0
32,
32(
2)
,
a
v
t
v
= −
= −
−
+
 and 
 
 
 
 
 
2
0
16(
2)
(
2)
Ps
s
t
v t
=
= −
−
+
−
 
 
 
for  
2
t ≥
 (the arbitrary constant vanishing because  
(2)
0
Ps
=
).  Now the condition  
 
2
( )
16
800
400
Bs
t
t
= −
+
=
gives  
5,
t =
 and then the requirement that  
(5)
400
Ps
=
 also  
 
yields  
0
544/3
181.33
v =
≈
 ft/s  for the projectile's needed initial velocity. 
 
42. 
Let  ( )
x t  be the (positive) altitude (in miles) of the spacecraft at time  t  (hours), with  
 
0
t =
corresponding to the time at which the its retrorockets are fired; let  ( )
( )
v t
x t
′
=
  be 

 
Section 1.2 
17 
 
the velocity of the spacecraft at time  t.  Then  
0
1000
v = −
 and  
0
(0)
x
x
=
 is unknown.  
 
But the (constant) acceleration is  
20000,
a = +
 so 
 
 
 
 
2
0
( )
20000
1000
and
( )
10000
1000
.
v t
t
x t
t
t
x
=
−
=
−
+
 
 
 
Now  ( )
20000
1000
0
v t
t
=
−
=
  (soft touchdown) when  
1
20
t =
 hr (that is, after exactly 
 
3 minutes of descent. Finally, the condition 
 
 
 
 
 
2
1
1
1
0
20
20
20
0
(
)
10000(
)
1000(
)
x
x
=
=
−
+
 
 
 
yields  
0
25
x =
 miles for the altitude at which the retrorockets should be fired. 
 
43. 
The velocity and position functions for the spacecraft are  
( )
0.0098
Sv
t
t
=
 and  
 
2
( )
0.0049 ,
Sx
t
t
=
  and the corresponding functions for the projectile are  
 
7
1
10
( )
3 10
P
v
t
c
=
=
×
and  
7
( )
3 10 .
P
x
t
t
=
×
  The condition that  
S
P
x
x
=
 when the 
 
spacecraft overtakes the projectile gives  
2
7
0.0049
3 10 ,
t
t
=
×
 whence 
 
 
 
 
7
9
9
3 10
6.12245 10
sec
0.0049
6.12245 10
194 years.
(3600)(24)(365.25)
t
×
=
≈
×
×
≈
≈
 
 
 
Since the projectile is traveling at 1
10  the speed of light, it has then traveled a distance of 
 
about 19.4 light years, which is about 
17
1.8367 10
×
 meters. 
 
44. 
Let  
0
a >
  denote the constant deceleration of the car when braking, and take 
0
0
x =
 for 
the cars position at time  
0
t =
 when the brakes are applied.  In the police experiment 
with  
0
25
v =
 ft/s, the distance the car travels in  t  seconds is given by  
 
 
 
 
 
2
1
88
( )
25
2
60
x t
at
t
= −
+
⋅
 
 
 
(with the factor  88
60  used to convert the velocity units from mi/hr to ft/s).  When we solve 
simultaneously the equations  ( )
45 and
( )
0
x t
x t
′
=
=
 we find that  
1210
81
14.94
a =
≈
 ft/s2.  
With this value of the deceleration and the (as yet) unknown velocity  
0v  of the car 
involved in the accident, it position function is 
 
 
 
 
 
2
0
1 1210
( )
.
2
81
x t
t
v t
= −
⋅
+
 
 

18 
Chapter 1 
 
The simultaneous equations  ( )
210 and
( )
0
x t
x t
′
=
=
 finally yield  
110
0
9
42
79.21
v =
≈
 
ft/s, almost exactly 54 miles per hour. 
 
 
 
 
 
SECTION 1.3 
 
SLOPE FIELDS AND SOLUTION CURVES 
 
The instructor may choose to delay covering Section 1.3 until later in Chapter 1.  However, 
before proceeding to Chapter 2, it is important that students come to grips at some point with the 
question of the existence of a unique solution of a differential equation –– and realize that it 
makes no sense to look for the solution without knowing in advance that it exists.  It may help 
some students to simplify the statement of the existence-uniqueness theorem as follows: 
 
 
Suppose that the function  
( , )
f x y   and the partial derivative  
/
f
y
∂
∂ are both 
continuous in some neighborhood of the point  (a, b).  Then the initial value 
problem 
 
 
 
 
( , ),
( )
dy
f x y
y a
b
dx =
=
 
 
 
has a unique solution in some neighborhood of the point  a. 
 
Slope fields and geometrical solution curves are introduced in this section as a concrete aid in 
visualizing solutions and existence-uniqueness questions.  Instead, we provide some details of 
the construction of the figure for the Problem 1 answer, and then include without further 
comment the similarly constructed figures for Problems 2 through 9. 
 
1.  
The following sequence of Mathematica commands generates the slope field and the  
 
solution curves through the given points.  Begin with the differential equation  
  
/
( , )
dy dx
f x y
=
where 
f[x_, y_] := -y - Sin[x]
 
Then set up the viewing window 
a = -3; b = 3; c = -3; d = 3;
 
The components  ( , )
u v  of unit vectors corresponding to the short slope field line  
 
segments are given by 
 
u[x_, y_] := 1/Sqrt[1 + f[x, y]^2] 
v[x_, y_] := f[x, y]/Sqrt[1 + f[x, y]^2]
The slope field is then constructed by the commands
Needs["Graphics`PlotField`"]
dfield = PlotVectorField[{u[x, y], v[x, y]}, {x, a, b}, {y, c, d},
HeadWidth -> 0, HeadLength -> 0, PlotPoints -> 19,
PlotRange -> {{a, b}, {c, d}}, Axes -> True, Frame -> True,
FrameLabel -> {"x", "y"}, AspectRatio -> 1];

 
Section 1.3 
19 
The original curve shown in Fig. 1.3.12 of the text (and its initial point not shown there)  
 
are plotted by the commands 
x0 = -1.9; y0 = 0;
point0 = Graphics[{PointSize[0.025], Point[{x0, y0}]}];
soln = NDSolve[{Derivative[1][y][x] == f[x, y[x]], y[x0] == y0},
y[x], {x, a, b}];
soln[[1,1,2]];
curve0 = Plot[soln[[1,1,2]], {x, a, b},
PlotStyle -> {Thickness[0.0065], RGBColor[0, 0, 1]}];
 
The Mathematica NDSolve command carries out an approximate numerical solution of 
 
the given differential equation.  Numerical solution techniques are discussed in Sections 
 
2.4–2.6 of the textbook. 
 
 
The coordinates of the 12 points are marked in Fig. 1.3.12 in the textbook.  For instance 
 
the 7th point is (–2.5, 1).  It and the corresponding solution curve are plotted by the 
 
commands 
x0 = -2.5; y0 = 1;
point7 = Graphics[{PointSize[0.025], Point[{x0, y0}]}];
soln = NDSolve[{Derivative[1][y][x] == f[x, y[x]], y[x0] == y0},
y[x], {x, a, b}];
soln[[1,1,2]];
curve7 = Plot[soln[[1,1,2]], {x, a, b},
PlotStyle -> {Thickness[0.0065], RGBColor[0, 0, 1]}];
 
Finally, the desired figure is assembled by the Mathematica command 
Show[ dfield, point0,curve0,
point1,curve1, point2,curve2, point3,curve3,
point4,curve4, point5,curve5, point6,curve6,
point7,curve7, point8,curve8, point9,curve9,
point10,curve10, point11,curve11, point12,curve12];
 
 
-2
-1
0
1
2
3
x
-2
-1
0
1
2
3
y
 
 

20 
Chapter 1 
-2
-1
0
1
2
3
x
-2
-1
0
1
2
3
y
-2
-1
0
1
2
3
x
-2
-1
0
1
2
3
y
-2
-1
0
1
2
3
x
-2
-1
0
1
2
3
y
2. 
3.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
4. 
5. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
6. 
7. 
 
 
 
 
 
 
 
 
 
 
 
 
 
-2
-1
0
1
2
3
x
-2
-1
0
1
2
3
y
-2
-1
0
1
2
3
x
-2
-1
0
1
2
3
y
-2
-1
0
1
2
3
x
-2
-1
0
1
2
3
y

 
Section 1.3 
21 
-2
-1
0
1
2
3
x
-2
-1
0
1
2
3
y
8. 
9. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
10. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
11. 
Because both  
( , )
f x y   =  2x2y2  and  
/
f
y
∂
∂
=  4x2y  are continuous everywhere, the 
existence-uniqueness theorem of Section 1.3 in the textbook guarantees the existence of a 
unique solution in some neighborhood of  x  =  1. 
 
12. 
Both  
( , )
f x y   =  x ln y  and  
/
f
y
∂
∂
=   x/y  are continuous in a neighborhood of   
 
(1, 1),  so the theorem guarantees the existence of a unique solution in some 
 
neighborhood of  x  =  1. 
 
13. 
Both  
( , )
f x y   =   y1/3  and  
/
f
y
∂
∂
=   (1/3)y–2/3  are continuous near  (0, 1),  so the 
theorem guarantees the existence of a unique solution in some neighborhood of  x  =  0. 
  
-2
-1
0
1
2
3
x
-2
-1
0
1
2
3
y
-2
-1
0
1
2
3
x
-2
-1
0
1
2
3
y

22 
Chapter 1 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x
y
(4,0)
(−4,?)
14. 
( , )
f x y   =   y1/3  is continuous in a neighborhood of  (0, 0),  but  
/
f
y
∂
∂
=   (1/3)y–2/3  is 
not, so the theorem guarantees existence but not uniqueness in some neighborhood of   
 
x  =  0. 
  
15. 
( , )
f x y   =  (x –  y)1/2  is not continuous at  (2, 2)  because it is not even defined if   y > x.  
Hence the theorem guarantees neither existence nor uniqueness in any neighborhood of 
the point  x  =  2. 
 
16. 
( , )
f x y   =  (x –  y)1/2  and  
/
f
y
∂
∂
=   –(1/2)(x –  y)–1/2  are continuous in a neighborhood 
of  (2, 1),  so the theorem guarantees both existence and uniqueness of a solution in some 
neighborhood of  x  =  2. 
 
17. 
Both  
( , )
f x y   =  (x – 1/y  and  
/
f
y
∂
∂
=   –(x – 1)/y2  are continuous near (0, 1),  so the 
theorem guarantees both existence and uniqueness of a solution in some neighborhood of  
x  =  0. 
 
18. 
Neither  
( , )
f x y   =  (x – 1)/y  nor  
/
f
y
∂
∂
=   –(x – 1)/y2  is continuous near (1, 0),  so the 
existence-uniqueness theorem guarantees nothing. 
 
19. 
Both  
( , )
f x y   =  ln(1 +  y2)  and  
/
f
y
∂
∂
=   2y/(1 +  y2)  are continuous near (0, 0),  so 
the theorem guarantees the existence of a unique solution near  x  =  0. 
  
20. 
Both  
( , )
f x y   =  x2 –  y2  and  
/
f
y
∂
∂
=   –2y  are continuous near (0, 1),  so the theorem 
guarantees both existence and uniqueness of a solution in some neighborhood of  x  =  0.  
 
21. 
The curve in the figure on the left below can be constructed using the commands 
 
illustrated in Problem 1 above.  Tracing this solution curve, we see that  ( 4)
3.
y −
≈
   
 
An exact solution of the differential equation yields the more accurate approximation  
 
( 4)
3.0183.
y −
≈
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x
y
(0,0)
(−4,?)

 
Section 1.3 
23 
−2
−1
0
1
2
−2
−1
0
1
2
x
y
(−2,0)
(2,?)
22. 
Tracing the curve in the figure on the right at the bottom of the preceding page , we see 
 
that  ( 4)
3.
y −
≈−
  An exact solution  of the differential equation yields the more accurate 
 
approximation  ( 4)
3.0017.
y −
≈−
 
 
23. 
Tracing the curve in figure on the left below, we see that  (2)
1.
y
≈
  A more accurate 
 
approximation is  (2)
1.0044.
y
≈
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
24. 
Tracing the curve in the figure on the right above, we see that  (2)
1.5.
y
≈
 A more 
 
accurate approximation is  (2)
1.4633.
y
≈
 
 
25. 
The figure below indicates a limiting velocity of 20 ft/sec — about the same as jumping 
off a 
1
4
6 -foot wall, and hence quite survivable. Tracing the curve suggests that ( )
19
v t =
 
ft/sec when  t  is a bit less than 2 seconds.  An exact solution gives  
1.8723
t ≈
 then. 
 
0
1
2
3
4
5
0
5
10
15
20
25
30
35
40
t
v
 
 
−2
−1
0
1
2
−2
−1
0
1
2
x
y
(0,0)
(2,?)

24 
Chapter 1 
x
y
26. 
The figure below suggests that there are 40 deer after about 60 months; a more accurate 
value is 
61.61.
t ≈
 And it's pretty clear that the limiting population is 75 deer. 
 
0
50
100
150
200
250
300
0
25
50
75
100
125
150
t
P
 
 
27. 
If 
0
b <
 then the initial value problem  
2
,
(0)
y
y
y
b
′ =
=
  has no solution, because the 
 
square root of a negative number would be involved.  If 
0
b >
 we get a unique solution 
 
curve through (0, )
b  defined for all  x  by following a parabola — in the figure on the left 
 
below — down (and leftward) to the  x-axis and then following the x-axis to the left.  But 
 
starting at (0,0) we can follow the positive x-axis to the point ( ,0)
c
 and then branching 
 
off on the parabola  
2
(
) .
y
x
c
=
−
  This gives infinitely many different solutions if  
0.
b =
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
28. 
The figure on the right above makes it clear initial value problem  
,
( )
xy
y
y a
b
′ =
=
  has 
 
a unique solution off the y-axis where  
0;
a ≠
  infinitely many solutions through the 
 
origin  where  
0;
a
b
=
=
 no solution if  
0 but
0
a
b
=
≠
 (so the point ( , )
a b lies on the 
 
positive or negative y-axis).  
x
y
(0,0) 

 
Section 1.3 
25 
−pi
pi
−1
1
x
y
29. 
Looking at the figure on the left below, we see that we can  start at the point  ( , )
a b  and 
 
follow a branch of a cubic up or down to the x-axis, then follow the x-axis an arbitrary 
 
distance before branching off (down or up) on another cubic.  This gives infinitely many 
 
solutions of the initial value problem  
2/3
3
,
( )
y
y
y a
b
′ =
=
  that are defined for all  x.  
 
However, if  
0
b ≠
 there is only a single cubic 
3
(
)
y
x
c
=
−
 passing through  ( , )
a b , so 
 
the solution is unique near  
.
x
a
=
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
30. 
The function  ( )
cos(
),
y x
x
c
=
−
 with  
( )
sin(
),
y x
x
c
′
= −
−
  satisfies the differential 
 
equation 
2
1
y
y
′ = −
−
 on the interval  c
x
c
π
<
<
+
 where  sin(
)
0,
x
c
−
>
 so it follows 
 
that   
 
 
2
2
2
1
1
cos (
)
sin (
)
sin(
)
.
y
x
c
x
c
x
c
y
−
−
= −
−
−
= −
−
= −
−
=
 
 
 
If  
1
b >  then the initial value problem  
2
1
,
( )
y
y
y a
b
′ = −
−
=
  has no solution because 
 
the square root of a negative number would be involved.  If  
1
b <  then there is only one 
 
curve of the form  
cos(
)
y
x
c
=
−
 through the point( , );
a b  this give a unique solution.  
 
But if 
1
b = ±  then we can combine a left ray of the line 
1,
y = +
 a cosine curve from the 
 
line 
1
y = +  to the line  
1
y = −, and then a right ray of the line 
1.
y = −
 Looking at the 
 
figure on the right above, we see that this gives infinitely many solutions (defined for  
 
all  x) through any point of the form ( , 1).
a ±
 
 
31. 
The function  ( )
sin(
),
y x
x
c
=
−
 with  
( )
cos(
),
y x
x
c
′
=
−
  satisfies the differential 
 
equation 
2
1
y
y
′ =
−
 on the interval  
/ 2
/ 2
c
x
c
π
π
−
<
<
+
 where  cos(
)
0,
x
c
−
>
 so it  
 
follows that   
 
 
     
2
2
2
1
1
sin (
)
cos (
)
sin(
)
.
y
x
c
x
c
x
c
y
−
=
−
−
=
−
= −
−
=
 
 
 
x
y

26 
Chapter 1 
 
If  
1
b >  then the initial value problem  
2
1
,
( )
y
y
y a
b
′ =
−
=
  has no solution because 
 
the square root of a negative number would be involved.  If  
1
b <  then there is only one 
 
curve of the form  
sin(
)
y
x
c
=
−
 through the point( , );
a b  this give a unique solution.  
 
But if 
1
b = ±  then we can combine a left ray of the line 
1,
y = −
 a sine curve from the 
 
line 
1
y = − to the line  
1
y = + , and then a right ray of the line 
1.
y = +
 Looking at the 
 
figure on the left below, we see that this gives infinitely many solutions (defined for all x) 
 
through any point of the form ( , 1).
a ±
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
32. 
Looking at the figure on the right above, we see that we can piece together a "left half" of 
 
a quartic for x negative, an interval along the x-axis, and a "right half" of a quartic curve 
 
for  x   positive. This makes it clear he initial value problem  
4
,
( )
y
x
y
y a
b
′ =
=
  has 
 
infinitely many solutions (defined for all x) if  
0;
b ≥
  there is no solution if  
0
b <
 
 
because this would involve the square root of a negative number. 
 
33. 
Looking at the figure provided in the answers section of the textbook, it suffices to 
observe that, among the pictured curves 
/(
1)
y
x
cx
=
−
 for all possible values of  c,    
 
• there is a unique one of these curves through any point not on either coordinate axis;   
• there is no such curve through any point on the y-axis other than the origin; and 
• there are infinitely many such curves through the origin (0,0). 
 
 
But in addition we have the constant-valued solution  ( )
0
y x ≡
 that "covers" the x-axis.  
 
It follows that the given differential equation has near ( , )
a b  
 
• a unique solution if  
0
a ≠
;   
• no solution if  
0
a =
 but  
0
b ≠
; 
• infinitely many different solutions if  
0.
a
b
=
=
 
−pi/2
pi/2
−1
1
x
y
x
y

 
Section 1.4 
27 
 
SECTION 1.4 
 
SEPARABLE EQUATIONS AND APPLICATIONS 
 
Of course it should be emphasized to students that the possibility of separating the variables is 
the first one you look for.  The general concept of natural growth and decay is important for all 
differential equations students, but the particular applications in this section are optional.  
Torricelli's law in the form of Equation (24) in the text leads to some nice concrete examples and 
problems. 
 
1. 
2
2
2
2
;
ln
;
( )
x
c
x
dy
x dx
y
x
c
y x
e
C e
y
−
+
−
= −
= −
+
=
=
⌠⌡
∫
 
 
2. 
2
2
2
1
1
2
;
;
( )
dy
x dx
x
C
y x
y
y
x
C
= −
−
= −
−
=
+
⌠
⌠

⌡
⌡
 
 
3. 
cos
cos
sin
;
ln
cos
;
( )
x c
x
dy
x dx
y
x
c
y x
e
C e
y
−
+
−
=
= −
+
=
=
⌠⌡
∫
 
 
4. 
4
4
;
ln
4ln(1
)
ln ;
( )
(1
)
1
dy
dx
y
x
C
y x
C
x
y
x
=
=
+
+
=
+
+
⌠
⌠

⌡
⌡
 
 
5. 
(
)
1
2
;
sin
;
( )
sin
2
1
dy
dx
y
x
C
y x
x
C
x
y
−
=
=
+
=
+
−
⌠
⌠

⌡
⌡
 
 
6. 
(
)
2
3/ 2
3/ 2
3
;
2
2
2 ;
( )
dy
x dx
y
x
C
y x
x
C
y
=
=
+
=
+
⌠
⌡
∫
 
 
7. 
(
)
3/ 2
1/3
2/3
4/3
4/3
3
3
2
2
1/3
4
;
3
;
( )
2
dy
x
dx
y
x
C
y x
x
C
y
=
=
+
=
+
⌠⌡
∫
 
 
8. 
(
)
2
1
2
cos
2
;
sin
;
( )
sin
y dy
x dx
y
x
C
y x
x
C
−
=
=
+
=
+
∫
∫
 
 
9. 
2
2
1
1
(partial fractions)
1
1
1
dy
dx
dx
y
x
x
x


=
=
+


−
+
−


⌠
⌠
⌠



⌡
⌡
⌡
 
 
1
ln
ln(1
)
ln(1
)
ln ;
( )
1
x
y
x
x
C
y x
C
x
+
=
+
−
−
+
=
−
 
 

28 
Chapter 1 
10. 
2
2
1
1
1
(1
)
;
(1
)
(1
)
1
1
1
dy
dx
C
x
C
y
x
y
x
x
+
+
=
−
= −
−
= −
+
+
+
+
+
⌠
⌠

⌡
⌡
 
 
1
1
(1
)
1
;
( )
1
1
(1
)
1
(1
)
1
(1
)
x
x
x
C
x
y
y x
C
x
C
x
C
x
+
+
−
+
+
=
=
−
=
+
+
+
+
+
+
 
 
11. 
(
)
2
1/ 2
2
3
2
1
;
;
( )
2
2
2
dy
x
C
x dx
y x
C
x
y
y
−
=
−
=
−
=
−
⌠
⌠


⌡
⌡
 
 
12. 
(
)
2
2
2
2
1
1
1
2
2
2
2
;
ln
1
ln
;
1
1
x
y dy
x dx
y
x
C
y
C e
y
=
+
=
+
+
=
+
⌠⌡
∫
 
 
13. 
(
)
3
4
1
4
4
cos
;
ln
1
sin
1
y dy
x dx
y
x
C
y
=
+
=
+
+
⌠
⌡
∫
 
 
14. 
(
)
(
)
3/ 2
3/ 2
2
2
3
3
1
1
;
y dy
x dx
y
y
x
x
C
+
=
+
+
=
+
+
∫
∫
 
 
15. 
2
4
2
3
2
1
1
1
2
1
1
;
ln
3
dy
dx
x
C
y
y
x
x
y
y
x




−
=
−
−
+
=
+
+








⌠
⌠

⌡
⌡
 
 
16. 
(
)
2
1
2
2
sin
;
ln(cos )
ln 1
ln
cos
1
y dy
x dx
x
x
C
y
x
=
−
=
+
+
+
⌠
⌠

⌡
⌡
 
 
(
)
2
1
2
sec
1
;
( )
sec
1
y
C
x
y x
C
x
−
=
+
=
+
 
 
17. 
1
(1
)(1
)
y
x
y
xy
x
y
′ =
+
+
+
=
+
+
 
 
2
1
2
(1
)
;
ln 1
1
dy
x dx
y
x
x
C
y =
+
+
=
+
+
+
⌠⌡
∫
 
 
18. 
2
2
2
2
2
2
2
1
(1
)(1
)
x y
x
y
x y
x
y
′ =
−
+
−
=
−
+
 
 
1
2
2
1
1
1
1
;
tan
;
( )
tan
1
dy
dx
y
x
C
y x
C
x
y
x
x
x
−




=
−
= −
−
+
=
−
−




+




⌠
⌠

⌡
⌡
 
 
19. 
;
ln
ln
;
( )
exp(
)
x
x
x
dy
e dx
y
e
C
y x
C
e
y
=
=
+
=
⌠⌡
∫
 
 
(0)
2
implies
2 so
( )
2exp(
)
x
y
e
C
y x
e
=
=
=
. 
 
 

 
Section 1.4 
29 
 
20. 
(
)
2
1
3
3
2
3
;
tan
;
( )
tan
1
dy
x dx
y
x
C
y x
x
C
y
−
=
=
+
=
+
+
⌠⌡
∫
 
 
(
)
1
3
(0)
1 implies
tan 1
/ 4 so
( )
tan
/ 4
y
C
y x
x
π
π
−
=
=
=
=
+
. 
 
21. 
2
2
2
2
;
16
16
xdx
y dy
y
x
C
x
=
=
−
+
−
⌠
⌠

⌡
⌡
 
 
2
2
(5)
2 implies
1
so
1
16
y
C
y
x
=
=
=
+
−
. 
 
22. 
(
)
3
4
4
4
1
;
ln
ln
;
( )
exp(
)
dy
x
dx
y
x
x
C
y x
C
x
x
y
=
−
=
−
+
=
−
⌠⌡
∫
 
 
4
(1)
3 implies
3 so
( )
3exp(
)
y
C
y x
x
x
= −
= −
= −
−
. 
 
23. 
2
1
1
2
2
;
ln(2
1)
ln
;
2
1
2
1
x
dy
dx
y
x
C
y
C e
y
=
−
=
+
−
=
−
⌠⌡
∫
 
 
(
)
2
2
2
1
2
(1)
1 implies
so
( )
1
x
y
C
e
y x
e
−
−
=
=
=
+
. 
 
24. 
cos
;
ln
ln(sin )
ln
;
( )
sin
sin
dy
xdx
y
x
C
y x
C
x
y
x
=
=
+
=
⌠
⌠

⌡
⌡
 
 
2
2
2
2
( )
implies
so
( )
sin
y
C
y x
x
π
π
π
π
=
=
=
. 
 
25. 
2
2
1
2
;
ln
ln
ln
;
( )
exp(
)
dy
x
y
x
x
C
y x
C x
x
y
x


=
+
=
+
+
=




⌠
⌠

⌡
⌡
 
 
1
2
(1)
1 implies
so
( )
exp(
1)
y
C
e
y x
x
x
−
=
=
=
−
. 
 
26. 
(
)
2
2
3
2
2
3
1
1
2
3
;
;
( )
dy
x
x
x
x
C
y x
y
y
x
x
C
−
=
+
−
=
+
+
=
+
+
⌠
⌠

⌡
⌡
 
 
2
3
1
(1)
1 implies
1 so
( )
1
y
C
y x
x
x
= −
= −
=
−
−
. 
 
27. 
(
)
2
2
2
6
;
3
;
( )
ln 3
y
x
y
x
x
e dy
e
dx
e
e
C
y x
e
C
=
=
+
=
+
∫
∫
 
 
(
)
2
(0)
0 implies
2 so
( )
ln 3
2
x
y
C
y x
e
=
= −
=
−
. 
 

30 
Chapter 1 
28. 
(
)
2
1
sec
;
tan
;
( )
tan
2
dx
y dy
y
x
C
y x
x
C
x
−
=
=
+
=
+
⌠
⌠

⌡
⌡
 
 
(
)
1
4
(4)
implies
1 so
( )
tan
1
y
C
y x
x
π
−
=
= −
=
−
. 
 
29. 
(a) 
Separation of variables gives the general solution 
 
 
 
2
1
1
1
;
;
( )
.
dy
x dx
x
C
y x
y
y
x
C


−
= −
= −
+
= −


−


⌠
⌠


⌡
⌡
 
 
(b) 
Inspection yields the singular solution  ( )
0
y x ≡
 that corresponds to no value of  
 
 
the constant  C. 
 
 
(c) 
In the figure below we see that there is a unique solution curve through every  
 
 
point in the xy-plane.   
 
 
−6
−4
−2
0
2
4
6
−6
−4
−2
0
2
4
6
x
y
(0,2)
 
 
 
30. 
When we take square roots on both sides of the differential equation and separate  
 
variables, we get 
 
 
 
(
)
2
;
;
( )
.
2
dy
dx
y
x
C
y x
x
C
y
=
=
−
=
−
⌠
⌠


⌡
⌡
 
 
This general solution provides the parabolas illustrated in Fig. 1.4.5 in the textbook.  
 
Observe that  ( )
y x  is always nonnegative, consistent with both the square root and the 
 
original differential equation.  We spot also the singular solution  ( )
0
y x ≡
 that 
 
corresponds to no value of the constant  C.   

 
Section 1.4 
31 
 
(a)   
Looking at Fig. 1.4.5, we see immediately that the differential equation  
 
2
(
)
4
y
y
′
=
 has no solution curve through the point  ( , )
a b   if  
0.
b <
 
 
 
(b) 
But if  
0
b ≥
 we obviously can combine branches of parabolas with segments 
 
along the x-axis to form infinitely many solution curves through  ( , )
a b . 
 
 
(c) 
Finally, if  
0
b >
 then on a interval containing  ( , )
a b  there are exactly  two 
 
solution curves through this point, corresponding to the two indicated parabolas through 
 
( , )
a b , one ascending and one descending from left to right.  
 
 
 
−15
−10
−5
0
5
10
15
0
25
50
75
x
y
 
Problem 31 Figure 
 
31. 
The formal separation-of-variables process is the same as in Problem 30 where, indeed, 
we started by taking square roots in  
2
(
)
4
y
y
′
=
 to get the differential equation  
2
.
y
y
′ =
 But whereas  y′ can be either positive or negative in the original equation, the 
latter equation requires that  y′ be nonnegative.  This means that only the right half of 
each parabola  
(
)
2
y
x
C
=
−
 qualifies as a solution curve.  Inspecting the figure above, we 
therefore see that through the point  ( , )
a b  there passes   
 
 
(a)   
No solution curve if  
0,
b <
    
 
(b)  
A unique solution curve if  
0,
b >
   
 
(c) 
Infinitely many solution curves if  
0,
b =
 because in this case we can pick any   
 
 
c
a
>
 and define the solution  
2
( )
0 if
,
( )
(
)
if
.
y x
x
c
y x
x
c
x
c
=
≤
=
−
≥
 
 
 
 
 

32 
Chapter 1 
Problem 32 Figure (a) 
-pi
0
pi
2pi
-5
-4
-3
-2
-1
0
1
2
3
4
5
x
y
y = sec(x)
 
32. 
Separation of variables gives 
 
 
 
 
1
2
sec
1
dy
x
y
C
y
y
−
=
=
+
−
⌠
⌡
 
 
if  
1,
y >
 so the general solution has the form  ( )
sec(
).
y x
x
C
= ±
−
 But the original 
differential equation  
2
1
y
y
y
′ =
− implies that  
0 if
1,
y
y
′ >
>
 while  
0 if
y′ <
  
1.
y < −
  Consequently, only the right halves of translated branches of the curve  
sec
y
x
=
 (figure above) qualify as general solution curves.  This explains the plotted 
general solution curves we see in the figure at the top of the next page.  In addition, we 
spot the two singular solutions  ( )
1 and
( )
1.
y x
y x
≡
≡−
  It follows upon inspection of 
this figure that the initial value problem  
2
1,
( )
y
y
y
y a
b
′ =
−
=
 has a unique solution if  
1
b >   and has no solution if  
1.
b <
  But if  
1
b =  (and similarly if  
1)
b = −
 then we can 
pick any  c
a
>
and define the solution ( )
1 if
,
y x
x
c
=
≤
  
( )
sec(
)
y x
x
c
=
−
  if  
2 .
c
x
c
π
≤
<
+
  So we see that if  
1,
b = ±  then the initial value problem  
2
1,
( )
y
y
y
y a
b
′ =
−
=
  has infinitely many solutions. 
 
 
33. 
The population growth rate is   
ln(30000/ 25000)/10
0.01823,
k =
≈
  so the population 
of the city  t  years after 1960 is given by  
0.01823
( )
25000
.
t
P t
e
=
  The expected year 
2000 population is then  
0.01823 40
(40)
25000
51840.
P
e
×
=
≈
 
 
 
 

 
Section 1.4 
33 
Problem 32 Figure (b) 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
34. 
The population growth rate is   
ln(6) /10
0.17918,
k =
≈
  so the population after  t  
hours is given by  
0.17918
0
( )
.
t
P t
P e
=
  To find how long it takes for the population to 
double, we therefore need only solve the equation  
0.17918
0
2
t
P
P e
=
 for  
(ln 2) /0.17918
3.87
t =
≈
 hours. 
 
35. 
As in the textbook discussion of radioactive decay, the number of  14C  atoms after  t  
years is given by  
0.0001216
0
( )
.
t
N t
N e−
=
  Hence we need only solve the equation  
0.0001216
1
0
0
6
t
N
N e−
=
 for  
(ln6)/0.0001216
14735
t =
≈
 years to find the age of the 
skull. 
 
36. 
As in Problem 35, the number of  14C  atoms after  t  years is given by  
10
0.0001216
( )
5.0 10
.
t
N t
e−
=
×
  Hence we need only solve the equation  
10
10
0.0001216
4.6 10
5.0 10
t
e−
×
=
×
 for the age  
(
)
ln(5.0/ 4.6) /0.0001216
686
t =
≈
 years 
of the relic.   Thus it appears not to be a genuine relic of the time of Christ 2000 years 
ago. 
 
37. 
The amount in the account after  t  years is given by  
0.08
( )
5000
.
t
A t
e
=
  Hence the 
amount in the account after 18 years is given by  
0.08 18
(18)
5000
21,103.48
A
e
×
=
≈
 
dollars. 
 
38. 
When the book has been overdue for  t  years, the fine owed is given in dollars by  
0.05
( )
0.30
.
t
A t
e
=
  Hence the amount owed after 100 years is given by  
0.05 100
(100)
0.30
44.52
A
e
×
=
≈
 dollars. 
−4
−3
−2
−1
0
1
2
3
4
−4
−3
−2
−1
0
1
2
3
4
x
y

34 
Chapter 1 
39. 
To find the decay rate of this drug in the dog's blood stream, we solve the equation 
 
5
1
2
k
e−
=
 (half-life 5 hours) for  
(ln 2)/5
0.13863.
k =
≈
  Thus the amount in the dog's 
bloodstream after  t  hours is given by  
0.13863
0
( )
.
t
A t
A e−
=
  We therefore solve the 
equation  
0.13863
0
(1)
50
45
2250
A
A e−
=
=
×
=
 for  
0
2585
A ≈
mg, the amount to 
anesthetize the dog properly. 
 
40. 
To find the decay rate of radioactive cobalt, we solve the equation  
5.27
1
2
k
e−
=
 (half-life 
5.27 years) for  
(ln 2)/5.27
0.13153.
k =
≈
  Thus the amount of radioactive cobalt left 
after  t  years is given by  
0.13153
0
( )
.
t
A t
A e−
=
  We therefore solve the equation  
0.13153
0
0
( )
0.01
t
A t
A e
A
−
=
=
 for  
(ln100)/0.13153
35.01
t =
≈
 and find that it will be 
about 35 years until the region is again inhabitable. 
 
41. 
Taking  t  =  0  when the body was formed and  t  =  T  now, the amount  Q(t)  of  238U in 
the body at time  t  (in  years) is given by  Q(t)  =  Q0e–kt,  where  k  =  (ln 2)/(4.51×109).  
The given information tells us that 
 
0
( )
0.9
( )
Q T
Q
Q T
=
−
. 
 
 
After substituting  Q(T)  =  Q0e–kT,  we solve readily for  ekT  =  19/9,  so  
T  =  (1/k)ln(19/9) ≈ 4.86×109.  Thus the body was formed approximately 4.86 billion  
years ago. 
 
42. 
Taking  t  =  0  when the rock contained only potassium and  t  =  T  now, the amount  
Q(t)  of potassium in the rock at time  t  (in  years) is given by  Q(t)  =  Q0e–kt,  where   
 
k  =  (ln 2)/(1.28×109).  The given information tells us that the amount  A(t)  of argon at 
time  t  is 
1
0
9
( )
[
( )]
A t
Q
Q t
=
−
 
 
 
and also that  A(T)  =  Q(T).  Thus 
 
0
( )
9
( )
Q
Q T
Q T
−
=
. 
 
 
After substituting 
0
( )
kT
Q T
Q e−
=
 we readily solve for 
 
 
 
 
 
9
9
(ln10/ ln2)(1.28 10 )
4.25 10
T =
×
≈
×
. 
 
 
Thus the age of the rock is about 1.25 billion years. 
 
43. 
Because  A  =  0  the differential equation reduces to  T'  =  kT,  so  T(t)  =  25e–kt.  The 
fact that  T(20)  =  15  yields  k  =  (1/20)ln(5/3),  and finally we solve   
 

 
Section 1.4 
35 
        
 
 
5  =  25e–kt 
for   
t  =  (ln 5)/k  ≈  63 min. 
 
44. 
The amount of sugar remaining undissolved after  t  minutes is given by  
0
( )
;
kt
A t
A e−
=
  
we find the value of  k  by solving the equation  
0
0
(1)
0.75
k
A
A e
A
−
=
=
 for  
ln0.75
0.28768.
k = −
≈
  To find how long it takes for half the sugar to dissolve, we solve 
the equation  
1
0
0
2
( )
kt
A t
A e
A
−
=
=
  for  
(ln2)/0.28768
2.41
t =
≈
 minutes. 
 
45. 
(a) 
The light intensity at a depth of  x  meters is given by  
1.4
0
( )
.
x
I x
I e−
=
  We solve 
the equation  
1.4
1
0
0
2
( )
x
I x
I e
I
−
=
=
 for  
(ln2)/1.4
0.495
x =
≈
 meters. 
 
 
(b) 
At depth 10 meters the intensity is
1.4 10
7
0
0
(10)
(8.32 10 )
I
I e
I
−
×
−
=
≈
×
. 
 
 
 
(c) 
We solve the equation  
1.4
0
0
( )
0.01
x
I x
I e
I
−
=
=
 for  
(ln100)/1.4
3.29
x =
≈
  
 
 
meters.  
 
46. 
(a) 
The pressure at an altitude of  x  miles is given by  
0.2
( )
29.92
.
x
p x
e−
=
  Hence the 
pressure at altitude 10000 ft is  (10000/5280)
20.49
p
≈
 inches, and the pressure at 
altitude 30000 ft is  (30000/5280)
9.60
p
≈
 inches. 
 
 
(b) 
To find the altitude where  p = 15 in., we solve the equation  
0.2
29.92
15
x
e−
=
 for  
 
(ln29.92 /15)/0.2
3.452 miles
18,200 ft.
x =
≈
≈
 
    
47. 
If  N(t)  denotes the number of people (in thousands) who have heard the rumor after  t  
days, then the initial value problem is 
 
          
 
 
N′  =  k(100 – N),     N(0)  =  0 
 
 
and we are given that  N(7)  =  10.  When we separate variables (
/(100
)
dN
N
k dt
−
=
) 
and integrate, we get  ln(100
)
,
N
kt
C
−
= −
+
 and the initial condition  
(0)
0
N
=
 gives  
ln 100.
C =
  Then  
(
)
100
100
, so
( )
100 1
.
kt
kt
N
e
N t
e
−
−
−
=
=
−
  We substitute t = 7,  
 
N = 10  and solve for the value  
ln(100/ 90)/7
0.01505.
k =
≈
  Finally, 50 thousand 
people have heard the rumor after  
(ln2)/
46.05
t
k
=
≈
 days. 
  
48. 
Let  
8( )
N t  and  
5( )
N t  be the numbers of 238U and 235U atoms, respectively, at time  t  (in 
billions of years after the creation of the universe).  Then  
8
0
( )
k t
N t
N e−
=
 and  
5
0
( )
ct
N t
N e−
=
, where  
0
N  is the initial number of atoms of each isotope.  Also,  
(ln 2)/ 4.51
k =
  and  
(ln2)/0.71
c =
 from the given half-lives.  We divide the equations 
for  
8
5
and
N
N  and find that when  t  has the value corresponding to "now", 
 

36 
Chapter 1 
 
 
 
 
(
)
8
5
137.7.
c k t
N
e
N
−
=
=
 
 
 
Finally we solve this last equation for  
(ln137.7)/(
)
5.99.
t
c
k
=
−
≈
  Thus we get an 
estimate of about 6 billion years for the age of the universe. 
 
49. 
The cake's temperature will be 100° after 66 min 40 sec; this problem is just like Example 
6 in the text. 
 
50. 
(a)   
15 / 2
15
2
( )
10
. Also 30
( )
10
, so
kt
k
A t
e
A
e
=
=
=
so 
 
 
 
 
 
(
)
15 / 2
2/15
2
3;
ln3
ln 3
.
15
k
e
k
=
=
=
 
 
Therefore  
2 /15
( )
10(
)
10 3
.
k
t
t
A t
e
=
=
⋅
 
 
(b)   After 5 years we have  
2/3
(5)
10 3
20.80 pu.
A
=
⋅
≈
 
 
(c)   
( )
100
A t =
  when  
2 /15
15 ln(10)
( )
10 3
;
15.72 years.
2
ln(3)
t
A t
t
=
⋅
=
⋅
≈
 
 
51. 
(a)   
( )
15
; 10
(5)
15
,
kt
kt
A t
e
A
e
−
−
=
=
=
so 
 
 
 
 
 
3
1
3
;
ln
.
2
5
2
kt
e
k
=
=
 
 
Therefore 
 
 
 
/5
/5
3
3
2
( )
15exp
ln
15
15
.
5
2
2
3
t
t
t
A t
−






=
−
=
⋅
=
⋅












 
 
(b)   After 8 months we have 
 
 
 
 
8/5
2
(8)
15
7.84 su.
3
A


=
⋅
≈




 
 
(c)   
( )
1
A t =   when 
 
 
 
/5
1
15
2
3
2
ln( )
( )
15
1;
5
33.3944.
3
ln( )
t
A t
t


=
⋅
=
=
⋅
≈




 
 
Thus it will be safe to return after about 33.4 months. 
 
52. 
If  ( )
L t  denotes the number of human language families at time  t  (in years), then  
 
( )
kt
L t
e
=
for some constant  k.  The condition that  
6000
(6000)
1.5
k
L
e
=
=
 gives   

 
Section 1.4 
37 
 
1
3
ln
.
6000
2
k =
  If  "now" corresponds to time  
,
t
T
=
 then we are given that  
 
( )
3300,
kT
L T
e
=
=
so  
1
6000ln3300
ln3300
119887.18.
ln(3/ 2)
T
k
=
=
≈
  This result suggests 
 
that the original human language was spoken about 120 thousand years ago. 
 
53. 
If  ( )
L t  denotes the number of Native America language families at time  t  (in years), 
 
then  ( )
kt
L t
e
=
 for some constant  k.  The condition that  
6000
(6000)
1.5
k
L
e
=
=
 gives   
 
1
3
ln
.
6000
2
k =
  If  "now" corresponds to time  
,
t
T
=
 then we are given that  
 
( )
150,
kT
L T
e
=
=
so  
1
6000ln150
ln150
74146.48.
ln(3/ 2)
T
k
=
=
≈
  This result suggests  that the 
 
ancestors of today's Native Americans first arrived in the western hemisphere about 74 
 
thousand years ago.  
 
54. 
With  A(y)  constant, Equation (19) in the text takes the form 
 
dy
k
y
dt =
 
 
 
We readily solve this equation for  2
y
kt
C
=
+
.  The condition   y(0)  =  9  yields   
 
C  =  6,  and then   y(1)  =  4  yields  k  =  2.  Thus the depth at time  t  (in hours) is    
 
y(t)  =  (3 – t)2,  and hence it takes  3  hours for the tank to empty. 
 
55. 
With  
2
(3)
A
π
=
 and  
2
(1/12)
a
π
=
,  and taking  g  =  32 ft/sec2,  Equation (20) 
reduces to  162 y′  =  –
y .  The solution such that   y  =  9  when  t  =  0  is given by 
 
324
y   =  –t + 972.  Hence   y  =  0  when  t  =  972 sec  =  16 min 12 sec. 
 
56. 
The radius of the cross-section of the cone at height   y  is proportional to   y,  so  A(y)  is 
proportional to   y2.  Therefore Equation (20) takes the form 
 
2y y
k
y
′ = −
, 
 
 
and a general solution is given by 
 
 
 
 
 
 
2y5/2  =  –5kt + C. 
 
 
The initial condition   y(0)  =  16  yields  C  =  2048,  and then   y(1)  =  9  implies that   
 
5k  =  1562.  Hence   y  =  0  when 
 
      
 
 
 
t  =  C/5k  =  2048/1562  ≈  1.31 hr. 
 

38 
Chapter 1 
57. 
The solution of   y′  =  –k
y   is given by 
          
 
 
 
 
 
2
y   =  –kt + C. 
 
 
The initial condition  y(0) = h  (the height of the cylinder) yields  C = 2
h .  Then 
substitution of  t = T,  y = 0  gives  k = (2
h )/T.  It follows that 
 
      
 
 
 
 
y  =  h(1 – t/T)2. 
 
 
If  r  denotes the radius of the cylinder, then 
 
      
 
 
2
2
2
2
0
( )
(1
/
)
(1
/
) .
V y
r y
r h
t T
V
t T
π
π
=
=
−
=
−
 
 
58. 
Since  x  =   y3/4,  the cross-sectional area is  
2
3/ 2
( )
.
A y
x
y
π
π
=
=
  Hence the  
 
general equation  
( )
2
A y y
a
gy
′ = −
  reduces to the differential equation  yy
k
′ = −
  
with general solution 
 
 
 
 
 
(1/2)y2  =  –kt + C. 
 
 
The initial condition   y(0)  =  12  gives  C  =  72,  and then   y(1)  =  6  yields  k  =  54.  
Upon separating variables and integrating, we find that the the depth at time  t  is 
 
 
 
 
 
 
( )
144
108
y t
t
=
−
y(t). 
 
 
Hence the tank is empty after  t  =  144/108 hr,  that is, at  1:20 p.m. 
 
59. 
(a) 
Since  x2  =  by,  the cross-sectional area is  
2
( )
.
A y
x
by
π
π
=
=
  Hence the 
equation  
( )
2
A y y
a
gy
′ = −
  reduces to the differential equation 
 
1/2
( /
) 2
y
y
k
a
b
g
π
′ = −
= −
 
 
 
 
with the general solution 
 
 
 
 
 
 
(2/3)y3/2  =  –kt + C. 
 
 
The initial condition   y(0)  =  4  gives  C  =  16/3,  and then   y(1)  =  1  yields  k  =  14/3. 
It follows that the depth at time  t  is 
 
 
 
 
 
 
y(t)  =  (8 – 7t)2/3. 
 
 
(b) 
The tank is empty after  t  =  8/7 hr,  that is, at  1:08:34 p.m. 
 
 
(c) 
We see above that  k  =  (a/πb)
2g   =  14/3.  Substitution of  
2,
1,
a
r
b
π
=
=
 

 
Section 1.4 
39 
 
g  =  (32)(3600)2 ft/hr2  yields  r  =  (1/60)
7/12  ft ≈ 0.15 in  for the radius of the 
bottom-hole. 
  
60. 
With  g  =  32 ft/sec2  and  
2
(1/12) ,
a
π
=
  Equation (24) simplifies to 
 
 
 
 
 
 
( )
18
dy
A y
y
dt
π
= −
. 
 
 
If  z  denotes the distance from the center of the cylinder down to the fluid surface, then   
y  =  3 – z  and  A(y)   =   10(9 – z2)1/2.  Hence the equation above becomes 
 
2 1/ 2
1/ 2
1/ 2
10(9
)
(3
)
,
18
180(3
)
,
dz
z
z
dt
z
dz
dt
π
π
−
=
−
+
=
 
 
 
and integration yields 
 
      
      
 
 
1/ 2
120(3
)
.
z
t
C
π
+
=
+
 
 
 
Now  z  =  0  when  t  =  0,  so  C  =  120(3)3/2.  The tank is empty when  z  =  3  (that is, 
when   y  =  0)  and thus after 
 
      
 
 
 
t   =   (120/π)(63/2 – 33/2)  ≈  362.90 sec. 
 
 
It therefore takes about  6 min 3 sec  for the fluid to drain completely. 
 
61. 
2
( )
(8
)
A y
y
y
π
=
−
  as in Example 7 in the text, but now  
/144
a
π
=
  in Equation (24), 
so the initial value problem is 
 
 
 
 
 
18(8y –  y2)y′  =  –
y ,    
 y(0)  =  8. 
 
 
We seek the value of  t  when   y  =  0.  The answer is  t ≈ 869 sec  =  14 min 29 sec. 
 
62. 
The cross-sectional area function for the tank is  
2
(1
)
A
y
π
=
−
  and the area of the 
bottom-hole is  
4
10
,
a
π
−
=
  so  Eq. (24) in the text gives the initial value problem 
 
2
4
(1
)
10
2
9.8 ,
(0)
1.
dy
y
y
y
dt
π
π
−
−
= −
×
=
 
 
 
Simplification gives 
(
)
1/ 2
3/ 2
4
1.4 10
10
dy
y
y
dt
−
−
−
= −
×
 
 
so integration yields 

40 
Chapter 1 
 
1/ 2
5/ 2
4
2
2
1.4 10
10
.
5
y
y
t
C
−
−
= −
×
+
 
 
 
The initial condition  y(0) = 1  implies that  C  =  2 - 2/5  =  8/5,  so  y = 0  after   
   
4
(8/5) /(1.4 10
10)
3614
t
−
=
×
≈
  seconds.  Thus the tank is empty at about 14 
seconds after 2 pm. 
 
63. 
(a) 
As in Example 8, the initial value problem is 
 
2
(8
)
,
(0)
4
dy
y
y
k
y
y
dt
π
π
−
= −
=
 
 
 
where  
2
2
0.6
2
4.8
.
k
r
g
r
=
=
  Integrating and applying the initial condition just in 
the Example 8 solution in the text, we find that 
 
3/ 2
5/ 2
16
2
448.
3
5
15
y
y
kt
−
= −
+
 
 
 
When we substitute  y  =  2 (ft)  and  t  =  1800  (sec, that is, 30 min), we find that   
 
k  ≈  0.009469.  Finally,  y  =  0  when   
 
448
3154 sec
53 min 34 sec.
15
t
k
=
≈
=
 
 
 
Thus the tank is empty at  1:53:34 pm. 
 
 
(b) 
The radius of the bottom-hole is  
 
 
/ 4.8
0.04442 ft
0.53 in, thus about a half inch.
r
k
=
≈
≈
 
  
 64. 
The given rate of fall of the water level is  dy/dt  =  –4 in/hr  =  –(1/10800) ft/sec.  With  
2
2
and
,
A
x
a
r
π
π
=
=
  Equation (24) is 
 
2
2
2
(
)(1/10800)
(
) 2
8
.
x
r
gy
r
y
π
π
π
= −
= −
 
 
 
Hence the curve is of the form   y  =  kx4,  and in order that it pass through  (1, 4)  we 
must have  k  =  4.  Comparing  
y   =  2x2  with the equation above, we see that   
 
 
            
 
 
(8r2)(10800)  =  1/2,  
 
 
so the radius of the bottom hole is  
1/(240 3) ft
1/35 in.
r =
≈
 

 
Section 1.4 
41 
 
65. 
Let  t  =  0  at the time of death.  Then the solution of the initial value problem 
 
 
 
 
 
T'  =  k(70 – T),    
T(0)  =  98.6 
 
is 
( )
70
28.6
.
kt
T t
e−
=
+
 
 
 
If  t  =  a  at 12 noon, then we know that 
 
(
1)
( )
70
28.6
80,
(
1)
70
28.6
75.
ka
k a
T t
e
T a
e
−
−
+
=
+
=
+
=
+
=
 
 
 
Hence 
28.6
10
and
28.6
5.
ka
ka
k
e
e
e
−
−
−
=
=
 
 
 
It follows that  e–k  =  1/2,  so  k  =  ln 2.  Finally the first of the previous two equations 
yields 
 
 
 
 
a  =  (ln 2.86)/(ln 2)  ≈  1.516 hr  ≈  1 hr  31 min, 
 
 
so the death occurred at 10:29 a.m. 
      
66. 
Let  t  =  0  when it began to snow, and  t  =  t0  at 7:00 a.m.  Let  x  denote distance along 
the road, with  x  =  0  where the snowplow begins at 7:00 a.m.  If   y  =  ct  is the snow 
depth at time  t,  w  is the width of the road, and  v  =  dx/dt  is the plow′s velocity, then 
"plowing at a constant rate" means that the product  wyv  is  constant.  Hence our 
differential equation is of the form 
 
1.
dx
k dt
t
=
 
 
 
The solution with  x  =  0  when  t  =  t0  is 
 
     
 
 
 
 
 
t   =   t0 ekx. 
 
 
We are given that  x  =  2  when  t  =  t0 + 1  and  x  =  4  when  t  =  t0 + 3,  so it follows 
that 
 
      
 
 
 
t0 + 1  =  t0 e2k       and       t0 + 3  =  t0 e4k. 
 
 
Elimination of  t0  yields the equation 
 
 
 
 
 
e4k – 3e2k + 2  =  (e2k – 1)(e2k – 2)  =  0, 

42 
Chapter 1 
 
 
so it follows (since  k > 0) that  e2k  =  2.  Hence  t0 + 1  =  2t0,  so  t0  =  1.  Thus it began 
to snow at 6 a.m. 
 
67. 
We still have  t  =  t0 ekx,  but now the given information yields the conditions 
 
 
 
 
t0 + 1   =   t0 e4k       and       t0 + 2   =   t0 e7k 
 
 
at 8 a.m. and 9 a.m., respectively.  Elimination of  t0  gives the equation 
 
 
 
 
 
2e4k – e7k – 1   =   0, 
 
 
which we solve numerically for  k  =  0.08276.  Using this value, we finally solve one of 
the preceding pair of equations for  t0  =  2.5483 hr  ≈  2 hr 33 min.  Thus it began to 
snow at 4:27 a.m. 
 
68. 
(a)   Note first that if  θ  denotes the angle between the tangent line and the horizontal, 
 
then  
2
π
α
θ
=
−
  so  
2
cot
cot(
)
tan
( ).
y x
π
α
θ
θ
′
=
−
=
=
  It follows that 
 
 
 
2
2
2
2
sin
1
1
sin
.
sin
cos
1
cot
1
( )
y x
α
α
α
α
α
=
=
=
′
+
+
+
 
 
Therefore the mechanical condition  (sin
) /
constant
v
α
=
(positive) with  
2
v
gy
=
 
translates to 
 
 
 
2
1
constant,
2
1
(
)
gy
y
=
′
+
  so   
2
[1
(
) ]
2
y
y
a
′
+
=
 
 
for some positive constant  a.  We readily solve the latter equation for the differential  
 
equation 
 
 
 
 
 
2
.
dy
a
y
y
dx
y
−
′ =
=
 
 
(b)   The substitution  
2
2 sin
,
4 sin cos
y
a
t dy
a
t
t dt
=
=
  now gives 
 
 
 
2
2
2
2
2 sin
cos
4 sin cos
,
2 sin
sin
4 sin
.
a
a
t
t
a
t
t dt
dx
dx
a
t
t
dx
a
t dt
−
=
=
=
 
 
Integration now gives 
 
 
 
2
4 sin
2
(1
cos2 )
x
a
t dt
a
t dt
=
=
−
∫
∫
 
 
 
 
1
2
2 (
sin2 )
(2
sin2 )
,
a t
t
C
a
t
t
C
=
−
+
=
−
+
 
 
and we recall that  
2
2 sin
(1
cos2 ).
y
a
t
a
t
=
=
−
 The requirement that  
0
x =
 when  
0
t =
 

 
Section 1.4 
43 
 
 
implies that  
0.
C =
  Finally, the substitution  
2t
θ =
 (nothing to do with the previously  
 
 
mentioned angle  θ  of inclination from the horizontal) yields the desired parametric  
 
 
equations 
 
 
 
 
 
(
sin ),
x
a θ
θ
=
−
       
(1
cos )
y
a
θ
=
−
  
 
 
 
of the cycloid that is generated by a point on the rim of a circular wheel of radius  a  as it  
 
 
rolls along the x-axis. [See Example 5 in Section 10.4 of  Edwards and Penney, Calculus, 
 
 
6th edition (Upper Saddle River, NJ: Prentice Hall, 2002).]  
 
 
69. 
Substitution of  
/
v
dy dx
=
 in the differential equation for  
( )
y
y x
=
 gives    
 
 
 
 
 
2
1
,
dv
a
v
dx =
+
 
 
and separation of variables then yields 
 
 
1
1
1
2
;
sinh
;
sinh
.
1
dv
dx
x
dy
x
v
C
C
a
a
dx
a
v
−


=
=
+
=
+




+
⌠
⌠

⌡
⌡
 
 
The fact that  
(0)
0
y′
=
 implies that  
1
0,
C =
 so it follows that 
 
 
       
sinh
;
( )
cosh
.
dy
x
x
y x
a
C
dx
a
a




=
=
+








 
 
Of course the (vertical) position of the x-axis can be adjusted so that  
0,
C =
 and the units 
 
in which  
and
T
ρ  are measured may be adjusted so that  
1.
a =
 In essence, then the 
shape of the hanging cable is the hyperbolic cosine graph  
cosh .
y
x
=
 
 
 
SECTION 1.5 
 
LINEAR FIRST-ORDER EQUATIONS 
 
1. 
(
)
(
)
exp
1
;
2
;
2
;
( )
2
x
x
x
x
x
x
x
dx
e
D
y e
e
y e
e
C
y x
Ce
ρ
−
=
=
⋅
=
⋅
=
+
=
+
∫
  
(0)
0 implies
2 so
( )
2
2
x
y
C
y x
e−
=
= −
=
−
 
 
2. 
(
)
(
)
2
2
2
2
exp
( 2)
;
3;
3
;
( )
(3
)
x
x
x
x
x
dx
e
D
y e
y e
x
C
y x
x
C e
ρ
−
−
−
=
−
=
⋅
=
⋅
=
+
=
+
∫
  
 
2
(0)
0 implies
0 so
( )
3
x
y
C
y x
xe
=
=
=
 
 
3. 
(
)
(
)
3
3
3
2
2
3
exp
3
;
2 ;
;
( )
(
)
x
x
x
x
x
dx
e
D
y e
x
y e
x
C
y x
x
C e
ρ
−
=
=
⋅
=
⋅
=
+
=
+
∫
  
 

44 
Chapter 1 
4. 
(
)
(
)
2
2
2
2
exp
( 2 )
;
1;
;
( )
(
)
x
x
x
x
x
x dx
e
D
y e
y e
x
C
y x
x
C e
ρ
−
−
−
=
−
=
⋅
=
⋅
=
+
=
+
∫
 
 
5. 
(
)
(
)
2ln
2
2
2
2
3
exp
(2/ )
;
3
;
x
x
x dx
e
x
D
y x
x
y x
x
C
ρ =
=
=
⋅
=
⋅
=
+
∫
  
2
2
( )
/
;
(1)
5 implies
4 so
( )
4/
y x
x
C x
y
C
y x
x
x
=
+
=
=
=
+
 
 
6. 
(
)
(
)
5ln
5
5
6
5
7
exp
(5/ )
;
7
;
x
x
x dx
e
x
D
y x
x
y x
x
C
ρ =
=
=
⋅
=
⋅
=
+
∫
  
2
5
2
5
( )
/
;
(2)
5 implies
32 so
( )
32/
y x
x
C x
y
C
y x
x
x
=
+
=
=
=
+
 
 
7. 
(
)
(
)
(ln )/ 2
exp
(1/ 2 )
;
5;
5
x
x
x dx
e
x
D
y
x
y
x
x
C
ρ =
=
=
⋅
=
⋅
=
+
∫
 
 
( )
5
/
y x
x
C
x
=
+
 
 
8. 
(
)
(
)
(ln )/3
4/3
3
3
3
3
exp
(1/3 )
;
4
;
3
x
x
x dx
e
x
D
y
x
x
y
x
x
C
ρ =
=
=
⋅
=
⋅
=
+
∫
 
 
1/ 3
( )
3
y x
x
Cx−
=
+
 
 
9. 
(
)
(
)
ln
exp
( 1/ )
1/ ;
1/
1/ ;
1/
ln
x
x
x dx
e
x
D
y
x
x
y
x
x
C
ρ
−
=
−
=
=
⋅
=
⋅
=
+
∫
  
( )
ln
;
(1)
7 implies
7 so
( )
ln
7
y x
x
x
C x
y
C
y x
x
x
x
=
+
=
=
=
+
 
 
10. 
(
)
( 3ln )/ 2
3/ 2
exp
( 3/ 2 )
;
x
x dx
e
x
ρ
−
−
=
−
=
=
∫
 
 
(
)
3/ 2
1/ 2
3/ 2
3/ 2
9
/ 2;
3
;
x
D
y x
x
y x
x
C
−
−
⋅
=
⋅
=
+
 
3
3/ 2
( )
3
y x
x
Cx
=
+
 
 
11. 
(
)
(
)
ln
3
3
3
3
exp
(1/
3)
;
0;
x
x
x
x
x
x
x
dx
e
xe
D
y xe
y xe
C
ρ
−
−
−
−
=
−
=
=
⋅
=
⋅
=
∫
 
 
1 3
( )
;
(1)
0 implies
0 so
( )
0 (constant)
x
y x
C x e
y
C
y x
−
=
=
=
≡
 
 
12. 
(
)
(
)
3 ln
3
3
7
3
8
1
4
exp
(3/ )
;
2
;
x
x
x dx
e
x
D
y x
x
y x
x
C
ρ =
=
=
⋅
=
⋅
=
+
∫
  
5
3
5
3
1
1
4
4
( )
;
(2)
1 implies
56 so
( )
56
y x
x
C x
y
C
y x
x
x
−
−
=
+
=
= −
=
−
 
 
13. 
(
)
(
)
2
2
1
2
exp
1
;
;
x
x
x
x
x
x
dx
e
D
y e
e
y e
e
C
ρ =
=
⋅
=
⋅
=
+
∫
  
1
1
1
1
2
2
2
2
( )
;
(0)
1 implies
so
( )
x
x
x
x
y x
e
C e
y
C
y x
e
e
−
−
=
+
=
=
=
+
 
 
14. 
(
)
(
)
3ln
3
3
1
3
exp
( 3/ )
;
;
ln
x
x
x dx
e
x
D
y x
x
y x
x
C
ρ
−
−
−
−
−
=
−
=
=
⋅
=
⋅
=
+
∫
  

 
Section 1.5 
45 
3
3
3
3
( )
ln
;
(1)
10 implies
10 so
( )
ln
10
y x
x
x
C x
y
C
y x
x
x
x
=
+
=
=
=
+
 
 
15. 
(
)
(
)
2
2
2
2
2
1
2
exp
2
;
;
x
x
x
x
x
x
xdx
e
D
y e
x e
y e
e
C
ρ =
=
⋅
=
⋅
=
+
∫
  
2
2
5
5
1
1
2
2
2
2
( )
;
(0)
2 implies
so
( )
x
x
y x
C e
y
C
y x
e
−
−
=
+
= −
= −
=
−
 
 
16. 
(
)
(
)
sin
sin
sin
sin
sin
exp
cos
;
cos ;
x
x
x
x
x
x
xdx
e
D
y e
e
x
y e
e
C
ρ =
=
⋅
=
⋅
=
+
∫
  
sin
sin
( )
1
;
( )
2 implies
1 so
( )
1
x
x
y x
C e
y
C
y x
e
π
−
−
=
+
=
=
=
+
 
 
17. 
(
)
(
)
(
)
(
)
ln(1
)
exp
1/(1
)
1
;
1
cos ;
1
sin
x
x
x dx
e
x
D
y
x
x
y
x
x
C
ρ
+
=
+
=
= +
⋅
+
=
⋅
+
=
+
∫
  
sin
1
sin
( )
;
(0)
1 implies
1 so
( )
1
1
C
x
x
y x
y
C
y x
x
x
+
+
=
=
=
=
+
+
 
 
18. 
(
)
(
)
2ln
2
2
2
exp
( 2/ )
;
cos ;
sin
x
x
x dx
e
x
D
y x
x
y x
x
C
ρ
−
−
−
−
=
−
=
=
⋅
=
⋅
=
+
∫
  
(
)
2
( )
sin
y x
x
x
C
=
+
 
 
19. 
(
)
(
)
ln(sin )
exp
cot
sin ;
sin
sin cos
x
x
x dx
e
x
D
y
x
x
x
ρ =
=
=
⋅
=
∫
  
2
1
1
2
2
sin
sin
;
( )
sin
csc
y
x
x
C
y x
x
C
x
⋅
=
+
=
+
 
 
20. 
(
)
(
)
2
2
2
/ 2
/ 2
/ 2
exp
( 1
)
;
(1
)
x x
x x
x x
x
x dx
e
D
y e
x e
ρ
−−
−−
−−
=
−−
=
⋅
=
+
∫
  
2
2
2
/ 2
/ 2
/ 2
;
( )
1
x x
x x
x x
y e
e
C
y x
C e
−−
−−
−−
⋅
= −
+
= −+
 
2 / 2
(0)
0 implies
1 so
( )
1
x x
y
C
y x
e−−
=
=
= −+
 
 
21. 
(
)
(
)
3ln
3
3
3
exp
( 3/ )
;
cos ;
sin
x
x
x dx
e
x
D
y x
x
y x
x
C
ρ
−
−
−
−
=
−
=
=
⋅
=
⋅
=
+
∫
  
3
3
3
( )
sin
;
(2 )
0 implies
0 so
( )
sin
y x
x
x
C x
y
C
y x
x
x
π
=
+
=
=
=
 
 
22. 
(
)
(
)
2
2
2
2
3
exp
( 2 )
;
3
;
x
x
x
x
x dx
e
D
y e
x
y e
x
C
ρ
−
−
−
=
−
=
⋅
=
⋅
=
+
∫
  
(
)
(
)
2
2
3
3
( )
;
(0)
5 implies
5 so
( )
5
x
x
y x
x
C e
y
C
y x
x
e
+
+
=
+
=
=
=
+
 
 
23. 
(
)
(
)
2
3ln
3
2
3
2
2
exp
(2
3/ )
;
4
x
x
x
x
x
x
x dx
e
x e
D
y x e
e
ρ
−
−
−
=
−
=
=
⋅
=
∫
  
3
2
2
3
3
2
2
;
( )
2
x
x
x
y x e
e
C
y x
x
C x e
−
−
⋅
=
+
=
+
 

46 
Chapter 1 
 
24. 
(
)
(
)
2
2
3ln(
4)/2
2
3/2
2
3/2
2
1/ 2
exp
3 /(
4)
(
4)
;
(
4)
(
4)
x
x
x
x
dx
e
x
D
y
x
x x
ρ
+
=
+
=
=
+
⋅
+
=
+
∫
  
2
3/2
2
3/2
2
3/ 2
1
1
3
3
(
4)
(
4)
;
( )
(
4)
y
x
x
C
y x
C x
−
⋅
+
=
+
+
=
+
+
 
2
3/2
16
1
3
3
(0)
1 implies
so
( )
1 16(
4)
y
C
y x
x
−


=
=
=
+
+

 
 
25. 
First we calculate 
 
3
2
2
2
2
3
3
3
3
ln(
1)
1
1
2
x dx
x
x
dx
x
x
x
x
⌠
⌠



⌡
⌡




=
−
=
−
+




+
+


. 
 
 
It follows that  
2
3/2
2
(
1)
exp(3
/ 2)
x
x
ρ
−
=
+
 and thence that 
 
 
 
 
(
)
2
3/ 2
2
2
5/ 2
2
3/ 2
2
2
3/ 2
2
2
3/ 2
2
(
1)
exp(3
/ 2)
6 (
4)
,
(
1)
exp(3
/ 2)
2(
4)
,
( )
2exp(3
/ 2)
(
1)
exp( 3
/ 2).
x
D
y
x
x
x x
y
x
x
x
C
y x
x
C x
x
−
−
−
−
⋅
+
=
+
⋅
+
= −
+
+
= −
+
+
−
 
 
 
Finally,  y(0) = 1  implies that  C = 3  so the desired particular solution is 
 
 
    
 
2
2
3/ 2
2
( )
2exp(3
/ 2)
3(
1)
exp( 3
/ 2).
y x
x
x
x
= −
+
+
−
 
 
26. 
With  
/
x
dx dy
′ =
,  the differential equation is  
3
2
4
1.
y x
y x
′ +
=
  Then with   y  as the 
independent variable we calculate 
 
(
)
(
)
4ln
4
4
( )
exp
(4/ )
;
y
y
y
y dy
e
y
D
x y
y
ρ
=
=
=
⋅
=
∫
 
 
 
4
2
2
4
1
1
;
( )
2
2
C
x y
y
C
x y
y
y
⋅
=
+
=
+
 
 
27. 
With  
/
x
dx dy
′ =
,  the differential equation is  
.
y
x
x
y e
′−
=
  Then with   y  as the 
independent variable we calculate 
 
(
)
(
)
( )
exp
( 1)
;
y
y
y
y
dy
e
D
x e
y
ρ
−
−
=
−
=
⋅
=
∫
 
 
 
(
)
2
2
1
1
2
2
;
( )
y
y
x e
y
C
x y
y
C e
−
⋅
=
+
=
+
 
 
28. 
With  
/
x
dx dy
′ =
,  the differential equation is  
2
(1
)
2
1.
y
x
y x
′
+
−
=
  Then with   y  as the 
independent variable we calculate 
 

 
Section 1.5 
47 
(
)
2
2
ln(
1)
2
1
( )
exp
( 2 /(1
)
(1
)
y
y
y
y
dy
e
y
ρ
−
+
−
=
−
+
=
=
+
∫
 
(
)
2
1
2
2
(1
)
(1
)
y
D
x
y
y
−
−
⋅
+
=
+
 
 
 
An integral table (or trigonometric substitution) now yields 
 
 
 
(
)
(
)(
)
1
2
2
2
2
2
1
1
2
1
tan
1
2 1
1
( )
1
tan
x
dy
y
y
C
y
y
y
x y
y
y
y
C
−
−


=
=
+
+


+
+


+


=
+
+
+


⌠

⌡
 
 
 
 
29. 
(
)
(
)
2
2
2
2
2
0
exp
( 2 )
;
;
x
x
x
x
x
t
x
x dx
e
D
y e
e
y e
C
e
dt
ρ
−
−
−
−
−
=
−
=
⋅
=
⋅
=
+
∫
∫
  
 
(
)
2
1
2
( )
erf( )
x
y x
e
C
x
π
=
+
 
 
 
30. 
After division of the given equation by  2x,  multiplication by the integrating factor   
 
ρ = x–1/2  yields 
 
(
)
1/ 2
3/ 2
1/ 2
1
2
1/ 2
1/ 2
1/ 2
1/ 2
1
cos ,
cos ,
cos
.
x
x
x
y
x
y
x
x
D
x
y
x
x
x
y
C
t
t dt
−
−
−
−
−
−
−
′ −
=
=
=
+∫
 
 
 
The initial condition   y(1)  =  0  implies that  C  =  0,  so the desired particular solution is 
 
1/ 2
1/ 2
1
( )
cos
x
y x
x
t
t dt
−
=
∫
. 
 
31. 
(a) 
(
)
, so
0.
Pdx
c
c
c
c
y
C e
P
P y
y
P y
−∫
′
′
=
−
= −
+
=
 
 
 
(b) 
(
)
Pdx
Pdx
Pdx
Pdx
p
p
y
P e
Q e
dx
e
Q e
Py
Q
−
−




∫
∫
∫
∫
′ =
−
⋅
+
⋅
= −
+








⌠⌡
 
 
32. 
(a) 
If  
cos
sin
y
A
x
B
x
=
+
 then   
 
 
 
 
(
)cos
(
)sin
2sin
y
y
A
B
x
B
A
x
x
′ +
=
+
+
−
=
 
 
 
provided that  A = –1  and  B = 1.  These coefficient values give the particular solution   
 
yp(x)  =  sin x – cos x. 
 

48 
Chapter 1 
 
(b) 
The general solution of the equation  
0
y
y
′ +
=
 is  y(x)  =  Ce–x   so addition to the 
particular solution found in part (a) gives  y(x)  =  Ce–x + sin x – cos x.    
 
 
(c) 
The initial condition  y(0) = 1  implies that  C = 2,  so the desired particular 
solution is  y(x)  =  2e–x + sin x – cos x.  
 
33. 
The amount  ( )
x t  of salt (in kg) after  t  seconds satisfies the differential equation  
/ 200,
x
x
′ = −
  so  
/ 200
( )
100
.
t
x t
e−
=
  Hence we need only solve the equation  
/ 200
10
100
t
e−
=
  for  t  = 461 sec = 7 min 41 sec (approximately). 
 
34. 
Let ( )
x t  denote the amount of pollutants in the lake after  t  days, measured in millions of 
cubic feet (mft3). The volume of the lake is 8000 mft3, and the initial amount  (0)
x
 of  
 
pollutants is  
0
(0.25%)(8000)
20
x =
=
 mft3.  We want to know when  
( )
(0.10%)(8000)
8
x t =
=
 mft3.  We set up the differential equation in infinitesimal form 
by writing 
 
 
     
[in]
[out]
(0.0005)(500)
500
,
8000
x
dx
dt
dt
=
−
=
−
⋅
 
 
which simplifies to 
 
 
 
 
   
1
1
1
,
or
.
4
16
16
4
dx
x
dx
x
dt
dt
=
−
+
=
 
 
Using the integrating factor  
/16,
te
ρ =
 we readily derive the solution  
/16
( )
4
16
t
x t
e−
=
+
 
for which  (0)
20.
x
=
  Finally, we find that  
8 when
16ln 4
22.2
x
t
=
=
≈
 days. 
 
 
35. 
The only difference from the Example 4 solution in the textbook is that  V = 1640 km3  
and  r = 410 km3/yr for Lake Ontario, so the time required is 
 
ln 4
4 ln 4
5.5452 years.
V
t
r
=
=
≈
 
 
36. 
(a) 
The volume of brine in the tank after  t  min is  V(t)  =  60 – t gal,  so the initial 
value problem is 
 
3
2
,
(0)
0.
60
dx
x
x
dt
t
=
−
=
−
 
 
The solution is 
3
(60
)
( )
(60
)
3600
t
x t
t
−
=
−
−
. 
 
 
(b) 
The maximum amount ever in the tank is  40/
3
23.09 lb.
≈
  This occurs after  
60
20 3
25/36 min.
t =
−
≈
 
 

 
Section 1.5 
49 
37. 
The volume of brine in the tank after  t  min is  V(t)  =  100 + 2t  gal, so the initial value 
problem is 
3
5
,
(0)
50.
100
2
dx
x
x
dt
t
=
−
=
+
 
 
 
The integrating factor  
( )t
ρ
= (100 + 2t)3/2  leads to the solution 
 
3/ 2
50000
( )
(100
2 )
(100
2 )
x t
t
t
=
+
−
+
. 
 
 
such that  x(0)  =  50.  The tank is full after  t  =  150 min,  at which time   
 
x(150)  =  393.75 lb. 
  
38. 
(a) 
/
/ 20 and
(0)
50
dx dt
x
x
= −
=
so  
/ 20
( )
50
t
x t
e−
=
. 
 
 
 
(b) 
The solution of the linear differential equation 
 
/ 20
5
5
5
1
100
200
2
40
t
dy
x
y
e
y
dt
−
=
−
=
−
 
 
 
with   y(0)  =  50  is  
/ 40
/ 20
( )
150
100
.
t
t
y t
e
e
−
−
=
−
 
 
 
(c) 
The maximum value of  y  occurs when   
 
 
 
(
)
/ 40
/ 20
/ 40
/ 40
15
5
( )
5
3
4
0
4
4
t
t
t
t
y t
e
e
e
e
−
−
−
−
′
= −
+
= −
−
=
. 
 
 
We find that  ymax =  56.25 lb  when  t  =  40 ln(4/3)  ≈  11.51 min. 
 
39. 
(a) 
The initial value problem 
 
,
(0)
100
10
dx
x
x
dt = −
=
 
 
 
for Tank 1 has solution  
/10
( )
100
.
t
x t
e−
=
  Then the initial value problem 
 
/10
10
,
(0)
0
10
10
10
t
dy
x
y
y
e
y
dt
−
=
−
=
−
=
 
 
 
for Tank 2 has solution  
/10
( )
10
.
t
y t
t e−
=
 
 
 
 

50 
Chapter 1 
 
(b) 
The maximum value of  y  occurs when   
 
 
 
 
/10
/10
( )
10
0
t
t
y t
e
t e
−
−
′
=
−
=
 
 
 
 
and thus when  t = 10.  We find that  ymax  =   y(10)  =  100e–1  ≈  36.79  gal. 
 
40. 
(b) 
Assuming inductively that  
(
)
/ 2 /
!2
n
t
n
nx
t e
n
−
=
,  the equation for  xn+1  is 
 
/ 2
1
1
1
1
1
1
1
.
2
2
! 2
2
n
t
n
n
n
n
n
dx
t e
x
x
x
dt
n
−
+
+
+
+
=
−
=
−
 
 
 
We easily  solve this first–order equation with  
1(0)
0
nx +
=
  and find that   
 
1
/ 2
1
1 ,
(
1)! 2
n
t
n
n
t
e
x
n
+
−
+
+
=
+
 
 
 
thereby completing the proof by induction. 
 
41. 
(a) 
A'(t)  =  0.06A + 0.12S  =  
0.05
0.06
3.6
t
A
e
+
 
 
 
(b) 
The solution with  A(0)  =  0  is 
 
          
 
 
 
A(t)  =  360(e0.06 t – e0.05 t), 
           
 
so  A(40)  ≈  1308.283  thousand dollars. 
 
42. 
The mass of the hailstone at time  t  is  
3
3 3
(4 /3)
(4/3)
.
m
r
k t
π
π
=
=
  Then the equation  
d(mv)/dt  =  mg  simplifies to 
 
 
 
 
 
 
tv' + 3v  =  gt. 
 
 
The solution satisfying the initial condition  v(0)  =  0  is  v(t)  =  gt/4,  so  v'(t)  =  g/4. 
 
43. 
The solution of the initial value problem  
0
,
( 5)
y
x
y
y
y
′ =
−
−
=
  is  
 
5
0
( )
1
(
6)
.
x
y x
x
y
e−−
=
−+
+
 
 
 
Substituting  x = 5,  we therefore solve the equation  
10
0
1
4
(
6)
y
e
y
−
+
+
=
   
 
with  y1  =  3.998,  3.999,  4,  4.001,  4.002  for the desired initial values   
 
y0  =  –50.0529,   –28.0265,   –6.0000,  16.0265,  38.0529,  respectively. 
 
 

 
Section 1.5 
51 
44. 
The solution of the initial value problem  
0
,
( 5)
y
x
y
y
y
′ =
+
−
=
  is  
 
5
0
( )
1
(
4)
.
x
y x
x
y
e +
= −
−+
−
 
 
 
Substituting  x = 5,  we therefore solve the equation  
10
0
1
6
(
4)
y
e
y
−+
−
=
   
 
with  y1  =  –10,  –5,  0,  5, 10  for the desired initial values   
 
y0  =  3.99982,   4.00005,   4.00027,  4.00050,  4.00073,  respectively. 
 
45. 
With the pollutant measured in millions of liters and the reservoir water in millions of 
cubic meters, the inflow-outflow rate is  
1
5 ,
r =
 the pollutant concentration in the inflow 
is  
o
10,
c =
 and the volume of the reservoir is  
2.
V =
 Substituting these values in the  
 
equation  
o
( /
) ,
x
rc
r V x
′ =
−
 we get the equation 
 
 
 
 
 
1
2
10
dx
x
dt =
−
 
 
for the amount  ( )
x t  of pollutant in the lake after  t  months.  With the aid of the  
 
integrating factor  
/10,
te
ρ =
  we readily find that the solution with  (0)
0
x
=
 is 
 
 
 
 
 
(
)
/10
( )
20 1
.
t
x t
e−
=
−
 
 
Then we find that  
10 when
10ln2
6.93
x
t
=
=
≈
 months, and observe finally that, as 
expected,  ( )
20 as
.
x t
t
→
→∞ 
 
46. 
With the pollutant measured in millions of liters and the reservoir water in millions of 
cubic meters, the inflow-outflow rate is  
1
5 ,
r =
 the pollutant concentration in the inflow 
is  
o
10(1
cos ),
c
t
=
+
 and the volume of the reservoir is  
2.
V =
 Substituting these values  
 
in the equation  
o
( /
) ,
x
rc
r V x
′ =
−
 we get the equation 
 
 
     
1
1
2(1
cos )
,
that is,
2(1
cos )
10
10
dx
dx
t
x
x
t
dt
dt
=
+
−
+
=
+
 
 
for the amount  ( )
x t  of pollutant in the lake after  t  months.  With the aid of the  
 
integrating factor  
/10,
te
ρ =
  we get 
 
 
 
 
/10
/10
/10
(2
2
cos )
t
t
t
x e
e
e
t dt
⋅
=
+
∫
 
 
 
   
    
/10
/10
2
2
1
10
20
2 ( )
1
t
t
e
e
=
+
⋅
+
1 cos
sin
.
10
t
t
C


+
+




 
 
 
 
When we impose the condition  (0)
0,
x
=
 we get the desired particular solution 
 

52 
Chapter 1 
 
 
 
 
(
)
/10
20
( )
101 102
cos
10sin
.
101
t
x t
e
t
t
−
=
−
+
+
 
 
In order to determine when  
10,
x =
 we need to solve numerically.  For instance, we can  
 
use the Mathematica commands 
 
 
 
x = (20/101)(101 - 102 Exp[-t/10] + Cos[t] + 10 Sin[t]);
FindRoot[ x == 10, {t,7} ]
{t -> 6.474591767017537}
 
and find that this occurs after about 6.47 months.  Finally, as  t →∞ we observe that  
( )
x t  approaches the function  
20
101
20
(cos
10sin )
t
t
+
+
  that does, indeed, oscillate about 
the equilibrium solution  ( )
20.
x t ≡
 
 
 
SECTION 1.6 
 
SUBSTITUTION METHODS AND EXACT EQUATIONS 
 
It is traditional for every elementary differential equations text to include the particular types of 
equations that are found in this section.  However, no one of them is vitally important solely in 
its own right.  Their main purpose (at this point in the course) is to familiarize students with the 
technique of transforming a differential equation by substitution.  The subsection on airplane 
flight trajectories (together with Problems 56–59) is included as an application, but is optional 
material and may be omitted if the instructor desires. 
 
The differential equations in Problems 1–15 are homogeneous, so we make the substitutions 
 
 
 
 
,
,
.
y
dy
dv
v
y
v x
v
x
x
dx
dx
=
=
=
+
 
 
 
 
 
For each problem we give the differential equation in  x,  ( ),
v x and  
/
v
dv dx
′ =
 that results, 
together with the principal steps in its solution. 
 
1. 
(
)
(
)
(
)
2
2
2
2(
1)
1
2
1 ;
2
;
ln
2
1
2ln
ln
2
1
v
dv
x v
v
v
v
xdx
v
v
x
C
v
v
+
′
+
= −
+
−
= −
+
−
= −
+
+
−
⌠⌡
∫
 
 
(
)
2
2
2
2
2
1
;
2
x
v
v
C
y
xy
x
C
+
−
=
+
−
=
 
 
2. 
(
)
2
2
2
2
1;
2
;
ln
;
ln
dx
x vv
vdv
v
x
C
y
x
x
C
x
′ =
=
=
+
=
+
⌠⌡
∫
 
 
3. 
(
)
2
2
;
;
ln
;
ln
2
dv
dx
x v
v
v
x
C
y
x
x
C
x
v
′ =
=
=
+
=
+
⌠
⌠

⌡
⌡
 

 
 
Section 1.6 
53 
 
4. 
(
)
(
)
2
1
2
2
2(1
)
2
1
1 ;
;
2 tan
ln(
1)
2ln
1
v dv
dx
x v
v
v
v
v
x
C
v
x
−
−
′
−
= −
+
=
−
+
=
+
+
⌠
⌠


⌡
⌡
 
 
(
)
1
2
2
2tan
/
ln(
/
1)
2ln
y x
y
x
x
C
−
−
+
=
+
 
 
5. 
(
)
2
2
1
1
2
1
1
2
;
;
ln
2ln
dx
x v
v
v
dv
v
x
C
v
v
x
v


′
+
= −
+
= −
−
= −
+




⌠
⌠

⌡
⌡
 
 
ln
ln
2ln
;
ln(
)
x
x
y
x
x
C
xy
C
y
y
−
−
= −
+
=
+
 
 
6. 
(
)
2
2
2
2
1
2
1
2
1
2
;
;
ln
2ln
dx
x
v
v
v
dv
v
x
C
v
v
x
v


′
+
= −
+
= −
−
= −
+




⌠
⌠

⌡
⌡
 
 
2ln
2ln
2ln
;
2
ln
x
y
x
x
C
y
y
x
C y
y
−
−
= −
+
=
+
 
 
7. 
(
)
2
2
3
3
3
3
1;
3
;
3ln
;
3ln
dx
x v v
v dv
v
x
C
y
x
x
C
x
′ =
=
=
+
=
+
⌠⌡
∫
 
 
8. 
;
;
ln
;
ln(
ln )
v
v
v
dx
x v
e
e
dv
e
x
C
v
C
x
x
−
−
′ =
−
= −
= −
+
−
=
−
⌠⌡
∫
 
 
(
)
ln
ln
y
x
C
x
= −
−
 
 
9. 
(
)
2
2
1
;
;
ln
;
ln
dv
dx
x v
v
x
C
x
y C
x
v
x
v
′ =
−
= −
= −
+
=
−
⌠
⌠


⌡
⌡
 
 
10. 
(
)
2
2
2
4
4
2
1;
;
ln 2
1
4ln
ln
2
1
vdv
dx
x vv
v
v
x
C
v
x
′ =
+
=
+
=
+
+
⌠
⌠

⌡
⌡
 
 
2
2
4
2
2
6
2
/
1
;
2
y
x
C x
x
y
C x
+
=
+
=
 
 
11. 
(
)
2
2
3
3
2
1
1
2
1
;
;
1
v
dx
v
dx
x
v
v
v
v
dv
dv
v
v
x
v
v
x
−


′
−
=
+
=
−
=


+
+


⌠
⌠
⌠
⌠




⌡
⌡
⌡
⌡
 
 
(
)
(
)
(
)
2
2
2
2
ln
ln
1
ln
ln
;
1 ;
v
v
x
C
v
C x v
y
C x
y
−
+
=
+
=
+
=
+
 
 
12. 
2
2
2
4;
;
4
ln
4
v dv
dx
x vv
v
v
x
C
x
v
′ =
+
=
+
=
+
+
⌠
⌠

⌡
⌡
 
 
(
)
(
)
2
2
2
2
2
2
4
ln
;
4
ln
v
x
C
x
y
x
x
C
+
=
+
+
=
+
 

54 
Chapter 1 
 
13. 
(
)
2
2
2
1;
;
ln
1
ln
ln
1
dv
dx
x v
v
v
v
x
C
x
v
′ =
+
=
+
+
=
+
+
⌠
⌠

⌡
⌡
 
 
2
2
2
2
1
;
v
v
C x
y
x
y
C x
+
+
=
+
+
=
 
 
14. 
(
)
2
2
1
1
x vv
v
v
′ =
+
−
+
 
 
(
)
2
2
2
ln
1
(1
)
1
(
1
)
2
1
ln
ln
v dv
x
v
v
du
u
v
u
u
dw
w
C
w
⌠


⌡
⌠

⌡
⌠
⌡
=
+
−
+
=
=
+
−
=
−
= −
+
 
 
 
with   
1
w
u
= −
.  Back-substitution and simplification finally yields the implicit 
solution  
2
2
.
x
x
y
C
−
+
=
 
 
15. 
(
)
(
)
2
2
2
2(
1)
4
(
1)
2
2
;
;
ln
2
4ln
ln
2
v
dv
dx
x v
v
v
v
v
v
x
C
v
v
x
+
′
+
= −
+
= −
+
= −
+
+
⌠
⌠


⌡
⌡
 
 
2
4
2
2
3
2
/
;
2
v
v
C x
x y
x y
C
+
=
+
=
 
 
16. 
The substitution  v  =  x +  y + 1  leads to 
 
2
2
(
)
1
1
2
2ln(1
)
2
1
2 ln(1
1)
dv
u du
x
v
u
u
v
u
u
C
x
x
y
x
y
C
⌠
⌠



⌡
⌡
=
=
=
+
+
=
−
+
+
=
+
+
−
+
+
+
+
 
 
 17. 
v  =  4x +  y;     
2
1
2
1
4;
tan
4
2
2
2
dv
v
C
v
v
x
v
−
′ =
+
=
=
+
+
⌠⌡
 
 
2 tan(2
);
2 tan(2
)
4
v
x
C
y
x
C
x
=
−
=
−
−
 
 
18. 
v  =  x +  y;     
1
1;
1
ln(
1)
1
1
vdv
vv
v
x
dv
v
v
C
v
v


′ =
+
=
=
−
=
−
+
−


+
+


⌠
⌠

⌡
⌡
 
 
y  =  ln(x +  y + 1) + C. 
 

 
 
Section 1.6 
55 
Problems 19–25 are Bernoulli equations.  For each, we indicate the appropriate substitution as 
specified in Equation (10) of this section, the resulting linear differential equation in  v,  its 
integrating factor  ρ,  and finally the resulting solution of the original Bernoulli equation. 
 
19. 
(
)
2
2
4
2
5
;
4 /
10/
;
1/
;
/
2
v
y
v
v x
x
x
y
x
Cx
ρ
−
′
=
−
= −
=
=
+
 
 
20. 
2
2
3
3
3
3
;
6
18 ;
;
3
x
x
v
y
v
x v
x
e
y
C e
ρ
−
′
=
+
=
=
=
+
 
 
21. 
(
)
2
2
2
2
;
2
2;
;
1/
1
x
x
v
y
v
v
e
y
Ce
ρ
−
−
′
=
+
= −
=
=
−
 
 
22. 
(
)
3
2
6
3
7
;
6 /
15/
;
;
7 / 7
15
v
y
v
v x
x
x
y
x
Cx
ρ
−
−
′
=
−
= −
=
=
+
 
 
23. 
(
)
3
1/ 3
2
2
;
2 /
1;
;
v
y
v
v x
x
y
x
C x
ρ
−
−
−
′
=
−
= −
=
=
+
 
 
24. 
2
2
2
2
2
;
2
/ ;
;
/(
ln )
x
x
x
v
y
v
v
e
x
e
y
e
C
x
ρ
−
−
′
=
+
=
=
=
+
 
 
25. 
(
) (
)
3
4
3
3
4
3
;
3 /
3/ 1
;
;
3 1
/ 2
v
y
v
v x
x
x
y
C
x
x
ρ
′
=
+
=
+
=
=
+
+
 
 
26. 
The substitution  v  =  y3  yields the linear equation  v' + v  =  e–x  with integrating  
 
factor  ρ  =  ex.  Solution:   y3  =  e–x(x + C) 
 
27. 
The substitution  v  =  y3  yields the linear equation  x v' – v  =  3x4  with integrating 
 
factor  ρ  =  1/x.  Solution:   y  =  (x4 +  C x)1/3 
  
28. 
The substitution  v  =  ey  yields the linear equation  x v' – 2v  =  2x3e2x  with integrating 
 
factor  ρ  =  1/x2.  Solution:   y  =  ln(C x2 + x2e2x) 
 
29. 
The substitution  v  =  sin y  yields the homogeneous equation  2xv v'  =  4x2 + v2. 
 
Solution:  sin2y  =  4x2 – C x 
 
30. 
First we multiply each side of the given equation by  ey.  Then the substitution  v  =  ey  
gives the homogeneous equation  (x + v) v'   =  x – v  of Problem 1 above. 
 
Solution:  x2 – 2x ey – e2 y  =   C 
 
Each of the differential equations in Problems 31–42 is of the form  
0,
M dx
N dy
+
=
 and the 
exactness condition  
/
/
M
y
N
x
∂
∂= ∂
∂ is routine to verify.  For each problem we give the 
principal steps in the calculation corresponding to the method of Example 9 in this section. 
 
31. 
 
2
(2
3 )
3
( );
3
( )
3
2
y
F
x
y dx
x
xy
g y
F
x
g y
x
y
N
′
=
+
=
+
+
=
+
=
+
=
∫
 
 
2
2
2
( )
2 ;
( )
;
3
g y
y
g y
y
x
xy
y
C
′
=
=
+
+
=
 

56 
Chapter 1 
 
32. 
 
2
(4
)
2
( );
( )
6
y
F
x
y dx
x
xy
g y
F
x
g y
y
x
N
′
=
−
=
−
+
= −
+
=
−
=
∫
 
 
2
2
2
( )
6 ;
( )
3
;
3
g y
y
g y
y
x
xy
y
C
′
=
=
−
+
=
 
 
33. 
 
2
2
3
2
2
(3
2
)
( );
4
( )
4
6
y
F
x
y
dx
x
xy
g y
F
xy
g y
xy
y
N
′
=
+
=
+
+
=
+
=
+
=
∫
 
 
2
3
3
2
3
( )
6
;
( )
2
;
2
2
g y
y
g y
y
x
xy
y
C
′
=
=
+
+
=
 
 
34. 
 
2
2
3
2
2
2
2
3
(2
3
)
( );
2
( )
2
4
y
F
xy
x
dx
x
x y
g y
F
x y
g y
x y
y
N
′
=
+
=
+
+
=
+
=
+
=
∫
 
 
3
4
3
2
2
4
( )
4
;
( )
;
g y
y
g y
y
x
x y
y
C
′
=
=
+
+
=
 
 
35. 
 
3
4
2
1
4
(
/ )
ln
( );
ln
( )
ln
y
F
x
y x dx
x
y
x
g y
F
x
g y
y
x
N
′
=
+
=
+
+
=
+
=
+
=
∫
 
 
2
3
3
2
1
1
1
3
4
3
( )
;
( )
;
ln
g y
y
g y
y
x
y
y
x
C
′
=
=
+
+
=
 
 
36. 
 
(1
)
( );
( )
2
x y
x y
x y
x y
y
F
y e
dx
x
e
g y
F
xe
g y
y
x e
N
′
=
+
=
+
+
=
+
=
+
=
∫
 
 
2
2
( )
2 ;
( )
;
x y
g y
y
g y
y
x
e
y
C
′
=
=
+
+
=
 
 
37. 
 
(cos
ln )
sin
ln
( );
/
( )
/
y
y
F
x
y dx
x
x
y
g y
F
x y
g y
x y
e
N
′
=
+
=
+
+
=
+
=
+
=
∫
 
 
( )
;
( )
;
sin
ln
y
y
y
g y
e
g y
e
x
x
y
e
C
′
=
=
+
+
=
 
 
38. 
 
1
2
1
1
2
2
2
(
tan
)
tan
( );
( )
1
1
y
x
x
y
F
x
y dx
x
x
y
g y
F
g y
N
y
y
−
−
+
′
=
+
=
+
+
=
+
=
=
+
+
∫
 
 
2
2
1
2
1
1
1
2
2
2
2
( )
;
( )
ln(1
);
tan
ln(1
)
1
y
g y
g y
y
x
x
y
y
C
y
−
′
=
=
+
+
+
+
=
+
 
 
39. 
 
2
3
4
3
3
4
(3
)
( );
F
x y
y
dx
x y
x y
g y
=
+
=
+
+
∫
 
 
3
2
3
3
2
4
3
3
4
( )
3
4
y
F
x y
xy
g y
x y
y
xy
N
′
=
+
+
=
+
+
=
 
 
4
5
3
3
4
5
1
1
5
5
( )
;
( )
;
g y
y
g y
y
x y
xy
y
C
′
=
=
+
+
=
 
 
40. 
 
(
sin
tan )
sin
tan
( );
x
x
F
e
y
y dx
e
y
x
y
g y
=
+
=
+
+
∫
 
 
2
2
cos
sec
( )
cos
sec
x
x
y
F
e
y
x
y
g y
e
y
x
y
N
′
=
+
+
=
+
=
 
 
( )
0;
( )
0;
sin
tan
x
g y
g y
e
y
x
y
C
′
=
=
+
=
 

 
 
Section 1.6 
57 
41. 
 
2
2
2
4
3
2
3
( );
x
y
x
y
F
dx
g y
y
x
y
x


=
−
=
+
+




⌠
⌡
 
 
2
2
2
3
2
3
2
2
1
( )
y
x
y
x
y
F
g y
N
y
x
y
x
y
′
= −
+
+
= −
+
+
=
 
 
2
2
3
1
( )
;
( )
2
;
2
x
y
g y
g y
y
y
C
y
x
y
′
=
=
+
+
=
 
 
42. 
 
2/3
5/ 2
2/3
3/ 2
3
( );
2
F
y
x
y dx
x y
x
y
g y
−
−
−
−


=
−
=
+
+




⌠⌡
 
 
5/3
3/ 2
3/ 2
5/3
2
2
( )
3
3
y
F
x y
x
g y
x
x y
N
−
−
−
−
′
= −
+
+
=
−
=
 
 
2/ 3
3/ 2
( )
0;
( )
0;
g y
g y
x y
x
y
C
−
−
′
=
=
+
=
 
 
43. 
The substitution  
,
y
p
y
p
′
′′
′
=
=
 in  xy
y
′′
′
=
 yields 
 
 
 
2
2
1
2
,
(separable)
ln
ln
ln
,
,
( )
.
xp
p
dp
dx
p
x
C
p
x
y
p
Cx
y x
Cx
B
Ax
B
′ =
=
⇒
=
+
′ =
=
=
+
=
+
⌠
⌠

⌡
⌡
 
 
44. 
The substitution  
,
(
/
)
y
p
y
p p
p dp dy
′
′′
′
=
=
=
 in  
(
)
2
0
yy
y
′′
′
+
=
 yields 
 
 
 
2
2
2
0
,
(separable)
ln
ln
ln
,
1
/
( )
.
2
ypp
p
yp
p
dp
dy
p
y
C
p
y
y
p
C y
x
dy
dy
p
C
y
x y
B
Ay
B
C
′
′
+
=
⇒
= −
= −
⇒
= −
+
=
⇒
=
=
=
+
=
+
⌠
⌠

⌡
⌡
⌠
⌠

⌡
⌡
 
 
45. 
The substitution  
,
(
/
)
y
p
y
p p
p dp dy
′
′′
′
=
=
=
 in  
4
0
y
y
′′ +
=
 yields 
 
 
 
 
(
)
2
2
1
2
2
2
2
1
2
4
0,
(separable)
4
2
,
4
2
4
,
pp
y
p dp
y dy
p
y
C
p
y
C
C
y
′ +
=
= −
⇒
= −
+
= −
+
=
−
∫
∫
 

58 
Chapter 1 
 
 
 
 
1
2
2
1
1 sin
,
2
2
( )
sin[2
2
]
(sin2 cos2
cos2 sin2
),
( )
cos2
sin2 .
dy
y
x
dy
D
p
k
k
y
y x
k
x
D
k
x
D
x
D
y x
A
x
B
x
−
=
=
=
+
−
=
−
=
−
=
+
⌠
⌠

⌡
⌡
 
 
46. 
The substitution  
,
y
p
y
p
′
′′
′
=
=
 in  
4
xy
y
x
′′
′
+
=
 yields 
 
 
 
2
2
4 ,
(linear in
)
[
]
4
2
,
2
,
( )
ln
.
x
xp
p
x
p
D x p
x
x p
x
A
dy
A
p
x
dx
x
y x
x
A
x
B
′+
=
⋅
=
⇒
⋅
=
+
=
=
+
=
+
+
 
 
47. 
The substitution  
,
y
p
y
p
′
′′
′
=
=
 in  
(
)
2
y
y
′′
′
=
 yields 
 
 
 
2
2
,
(separable)
1
,
1
,
( )
ln
.
p
p
dp
xdx
x
B
p
p
dy
dx
x
B
y x
A
x
A
′ =
=
⇒
−
=
+
= −
+
=
−
+
⌠⌡
∫
 
 
48. 
The substitution  
,
y
p
y
p
′
′′
′
=
=
 in  
2
3
2
x y
xy
′′
′
+
=
 yields 
 
 
 
2
2
3
3
2
3
2
3
2
3
2
,
(linear in
)
[
]
2
,
1
,
( )
ln
.
x
x p
xp
p
p
p
p
x
D x
p
x
x
p
x
C
dy
C
dx
x
x
A
y x
x
B
x
′
′
+
=
⇒
+
=
⋅
=
⇒
⋅
=
+
=
+
=
+
+
 
49. 
The substitution  
,
(
/
)
y
p
y
p p
p dp dy
′
′′
′
=
=
=
 in  
(
)
2
yy
y
yy
′′
′
′
+
=
 yields 
 
 
 
 
2
2
2
(linear in
),
[
]
,
1
1
,
2
2
2
y
yp p
p
yp
y p
p
y
p
D
y p
y
y
C
yp
y
C
p
y
′
′
+
=
⇒
+
=
⋅
=
+
=
+
⇒
=
 

 
 
Section 1.6 
59 
 
 
 
(
)
(
)
2
2
1/ 2
2
1
2
ln
ln
,
( )
.
x
x
y dy
x
dy
y
C
B
p
y
C
y
C
Be
y x
A
Be
=
=
=
+
−
+
+
=
⇒
= ±
+
⌠
⌠


⌡
⌡
 
 
50. 
The substitution  
,
y
p
y
p
′
′′
′
=
=
 in  
(
)
2
y
x
y
′′
′
=
+
 gives  
2
(
) ,
p
x
p
′ =
+
  and then the  
 
substitution  
,
1
v
x
p
p
v
′
′
=
+
=
−  yields 
 
 
 
2
2
1
2
2
1
2
1
1
,
tan
,
1
tan(
)
tan(
)
,
( )
ln sec(
)
.
dv
v
v
v
dx
dv
dx
v
x
A
v
dy
v
x
y
x
A
x
A
x
dx
y x
x
A
x
B
−
′−
=
⇒
=
+
=
⇒
=
+
+
′
=
+
=
+
⇒
=
+
−
=
+
−
+
⌠⌡
∫
 
 
51. 
The substitution  
,
(
/
)
y
p
y
p p
p dp dy
′
′′
′
=
=
=
 in  
(
)
3
2
y
y y
′′
′
=
 yields 
 
 
 
3
2
2
3
3
1
2
2
,
1
1
,
3
3
0
dp
p p
yp
y dy
y
C
p
p
x
dy
y
Cx
D
p
y
x
Ay
B
′ =
⇒
=
⇒−
=
+
=
= −
−
+
+
+
+
=
⌠⌡
⌠⌡
∫
 
 
52. 
The substitution  
,
(
/
)
y
p
y
p p
p dp dy
′
′′
′
=
=
=
 in  
3
1
y y′′ =  yields 
 
 
 
3
2
3
2
2
2
2
2
2
2
2
2
1
1
1
,
2
2
2
1
1
,
1
1
1
1,
(
)
1.
dy
A
y p p
pdp
p
y
y
Ay
y dy
p
x
dy
y
p
Ay
x
Ay
C
Ax
B
Ay
A
Ay
Ax
B
′ =
⇒
=
⇒
= −
+
−
=
⇒
=
=
−
=
−+
⇒
+
=
−
−
+
=
⌠⌡
⌠
⌠

⌡
⌡
∫
 
 
53. 
The substitution  
,
(
/
)
y
p
y
p p
p dp dy
′
′′
′
=
=
=
 in  
2
y
yy
′′
′
=
 yields 
 
 
 
 
2
2
1
2
2
2
2
,
1
1 tan
,
p p
yp
dp
y dy
p
y
A
dy
y
x
dy
C
p
y
A
A
A
−
′ =
⇒
=
⇒
=
+
=
=
=
+
+
⌠
⌠

⌡
⌡
∫
∫
 

60 
Chapter 1 
 
 
 
 
1
tan
(
)
tan(
),
( )
tan(
).
y
y
A x
C
Ax
AC
A
A
y x
A
Ax
B
−
=
−
⇒
=
−
=
+
 
 
54. 
The substitution  
,
(
/
)
y
p
y
p p
p dp dy
′
′′
′
=
=
=
 in  
(
)
2
3
yy
y
′′
′
=
 yields 
 
 
 
2
3
3
2
2
3
3
ln
3ln
ln
,
1
1
,
2
(
)
1.
dp
dy
yp p
p
p
y
p
y
C
p
Cy
dy
x
dy
B
p
Cy
Cy
Ay
B
x
′ =
⇒
=
=
+
⇒
=
=
=
= −
+
−
=
⌠
⌠


⌡
⌡
⌠
⌠

⌡
⌡
 
 
55. 
The substitution  
,
(
)/
v
ax
by
c
y
v
ax
c
b
=
+
+
=
−
−
  in  
(
)
y
F ax
by
c
′ =
+
+
 yields the 
 
separable differential equation  (
/
)/
( ),
dv dx
a
b
F v
−
=
  that is,  
/
( ).
dv dx
a
b F v
=
+
 
 
56. 
If  
1 n
v
y −
=
  then  
1/(1
)
n
y
v
−
=
  so  
/(1
)
/(1
)
n
n
y
v
v
n
−
′
′
=
−
.  Hence the given Bernoulli 
equation transforms to 
 
 
 
 
 
/(1
)
1/(1
)
/(1
).
( )
( )
1
n
n
n
n
n
v
dv
P x v
Q x v
n dx
−
−
−
+
=
−
 
 
 
Multiplication by  
/(1
)
(1
)/
n
n
n
v
−
−
 then yields the linear differential equation  
(1
)
(1
)
.
v
n Pv
n Q v
′+
−
=
−
 
 
 
57. 
If  
ln
v
y
=
  then  
v
y
e
=
  so  
.
v
y
e v
′
′
=
  Hence the given equation transforms to  
( )
( )
.
v
v
v
e v
P x e
Q x v e
′ +
=
  Cancellation of the factor  
ve  then yields the linear 
differential equation  
( )
( ).
v
Q x v
P x
′−
=
 
 
58. 
The substitution  v = ln y,  y = ev,  y' = ev v'  yields the linear equation  x v' + 2 v  =  4x2 
 
with integrating factor  ρ  =  x2.  Solution:   y  =  exp(x2 + C/x2) 
 
59. 
The substitution  x  =  u – 1,   y  =  v – 2  yields the homogeneous equation 
 
 
 
 
 
 
dv
u
v
du
u
v
−
=
+
. 
 
 
 
The substitution  v  =  pu  leads to 
 

 
 
Section 1.6 
61 
(
)
2
2
(
1)
1
ln
ln
2
1
ln
.
(
2
1)
2
p
dp
u
p
p
C
p
p
⌠

⌡
+


= −
= −
+
−
−


+
−
 
 
We thus obtain the implicit solution  
 
(
)
2
2
2
2
2
2
2
2
2
2
2
2
1
2
1
2
(
2)
2(
1)(
2)
(
1)
2
2
6
.
u
p
p
C
v
v
u
v
uv
u
C
u
u
y
x
y
x
C
y
xy
x
x
y
C
+
−
=


+
−
=
+
−
=




+
+
+
+
−
+
=
+
−
+
+
=
 
 
60. 
The substitution  x  =  u – 3,   y  =  v – 2  yields the homogeneous equation 
 
 
 
 
 
 
2
4
3
dv
u
v
du
u
v
−+
=
−
. 
 
 
 
The substitution  v  =  pu  leads to 
 
[
]
(4
3 )
1
1
15
ln
(3
1)(
1)
4
1
3
1
1 ln(
1)
5ln(3
1)
ln
.
4
p dp
u
dp
p
p
p
p
p
p
C
⌠

⌡


−
=
=
−


+
−
−
+


=
−
−
+
+
⌠
⌡
 
 
We thus obtain the implicit solution  
 
4
4
5
5
5
5
5
(
1)
( /
1)
(
)
(3
1)
(3 /
1)
(3
)
(3
)
(
)
(
3
3)
(
5).
C p
C v u
C u v
u
u
p
v u
v
u
v
u
C v
u
x
y
C y
x
−
−
−
=
=
=
+
+
+
+
=
−
+
+
=
−
−
 
 
61. 
The substitution  v  =  x – y  yields the separable equation  v'   =  1 – sin v.  With the aid 
of the identity 
2
2
1
1
sin
sec
sec
tan
1
sin
cos
v
v
v
v
v
v
+
=
=
+
−
 
 
 
 
we obtain the solution 
 
 
 
 
 
x  =  tan(x –  y) + sec(x –  y) + C. 
 
62. 
The substitution  y
vx
=
 in the given homogeneous differential equation yields the  

62 
Chapter 1 
 
separable equation  (
)
(
)
3
4
2
1
x
v
v
v
v
′
−
= −
+
 that we solve as follows: 
 
 
 
 
3
4
2
2
2
2
2
3
3
2
1
2
1
1
1
(partial fractions)
1
1
ln(
1)
ln
ln(
1)
ln
ln
(
1)(
1)
(
)(
)
v
dx
dv
v
v
x
v
dx
dv
v
v
v
v
x
v
v
v
v
x
C
x v
v
v
C v
y
xy
x
x
y
C xy
x
y
C xy
−
= −
+
−


−
+
= −


−
+
+


−
+
−
+
+
= −
+
−
+
+
=
−
+
+
=
+
=
⌠
⌠

⌡
⌡
⌠
⌠

⌡
⌡
 
 
63. 
If we substitute  
2
1
1
1/ ,
/
y
y
v
y
y
v
v
′
′
′
=
+
=
−
 (primes denoting differentiation with 
respect to  x) into the Riccati equation  
2
y
Ay
By
C
′ =
+
+
 and use the fact that 
 
2
1
1
1
y
Ay
By
C
′ =
+
+
,  then we immediately get the linear differential equation 
 
1
(
2
)
v
B
A y v
A
′+
+
= −
. 
 
In Problems 64 and 65 we outline the application of the method of Problem 63 to the given 
Riccati equation. 
 
64. 
The substitution  
1/
y
x
v
=
+
 yields the linear equation  
2
1
v
xv
′−
=
 with integrating 
factor  
2.
x
e
ρ
−
=
  In Problem 29 of Section 1.5 we saw that the general solution of this 
linear equation is  
2
2
( )
erf( )
x
v x
e
C
x
π


=
+

 in terms of the error function  erf(x) 
introduced there  Hence the general solution of our Riccati equation is given by 
2
1
2
( )
erf( )
.
x
y x
x
e
C
x
π
−
−


=
+
+


 
 
 
65. 
The substitution  
1/
y
x
v
=
+
 yields the trivial linear equation  
1
v′ = − with immediate 
solution  ( )
.
v x
C
x
=
−
  Hence the general solution of our Riccati equation is given by 
 
( )
1/(
).
y x
x
C
x
=
+
−
 
 
66. 
The substitution  y'  =  C  in the Clairaut equation immediately yields the general solution  
y  =  Cx + g(C). 
 
67. 
Clearly the line  y  =  Cx – C2/4  and the tangent line at  (C/2, C2/4)  to the parabola   
 
y  =  x2  both have slope  C. 
 
68. 
(
)
(
)
2
ln
1
ln
ln
ln
/
k
v
v
k
x
k
a
x a
−
+
+
= −
+
=
 
 
(
)
2
1
/
k
v
v
x a
−
+
+
=
 

 
 
Section 1.6 
63 
 
(
)
2
2
/
1
k
x a
v
v
−


−
=
+


 
 
(
)
(
)
2
2
2
/
2
/
1
k
k
x a
v x a
v
v
−
−
−
+
=
+
 
 
2
1
1
1 /
2
2
k
k
k
k
x
x
x
x
v
a
a
a
a
−
−
−












=
−
=
−




























 
 
69. 
With  a  =  100  and  k  =  1/10,  Equation (19) in the text is 
 
 
 
 
 
y  =  50[(x/100)9/10 – (x/100)11/10]. 
 
 
The equation  y'(x)  =  0  then yields   
 
 
 
 
 
(x/100)1/10  =  (9/11)1/2, 
 
 
so it follows that 
 
 
 
 
ymax  =  50[(9/11)9/2 – (9/11)11/2]  ≈  3.68 mi. 
 
70. 
With  
0
/
10/500
1/10,
k
w v
=
=
=
 Eq. (16) in the text gives 
 
 
 
 
(
)
2
1
ln
1
ln
10
v
v
x
C
+
+
= −
+
 
 
where  
/ .
v
y x
=
  Substitution of   
200,
150,
3/ 4
x
y
v
=
=
=
 yields  
(
)
1/10
ln 2 200
,
C =
⋅
 
 
thence 
 
 
 
 
(
)
2
1/10
2
1
ln
1
ln
ln 2 200
,
10
y
y
x
x
x


+
+
= −
+
⋅






 
 
which — after exponentiation and then multiplication of the resulting equation by  x — 
 
simplifies as desired to  
(
)
1/10
2
2
9
2 200
.
y
x
y
x
+
+
=
  If  
0
x =
  then this equation 
 
yields   
0,
y =
thereby  verifying that the airplane reaches the airport at the origin. 
 
71. 
(a) 
With  a = 100 and  
0
/
2/ 4
1/ 2,
k
w v
=
=
=
 the solution given by equation (19) in 
the textbook is  y(x)  =  50[(x/100)1/2 – (x/100)3/2].  The fact that  y(0)  =  0  means that 
this trajectory goes through the origin where the tree is located. 
 
 
(b) 
With  k = 4/4 = 1  the solution is  y(x)  =  50[1 – (x/100)2]  and we see that the 
swimmer hits the bank at a distance  y(0)  =  50  north of the tree. 
 
 
(c) 
With  k = 6/4 = 1 the solution is  y(x)  =  50[(x/100)–1/2 – (x/100)5/2].  This 
trajectory is asymptotic to the positive x-axis, so we see that the swimmer never reaches 
the west bank of the river. 

64 
Chapter 1 
 
72. 
The substitution  
,
y
p
y
p
′
′′
′
=
=
 in  
2 3/ 2
[1
(
) ]
ry
y
′′
′
=
+
  yields 
 
 
 
2
3/ 2
2 3/ 2
(1
)
.
(1
)
rpdp
rp
p
dx
p
′ =
+
⇒
=
+
⌠⌡
∫
 
 
Now integral formula #52 in the back of our favorite calculus textbook gives 
 
 
 
2
2
2
2
2
(1
)(
) ,
1
rp
x
a
r p
p
x
a
p
=
−
⇒
=
+
−
+
 
 
and we solve readily for 
 
 
 
2
2
2
2
2
2
(
)
,
(
)
(
)
x
a
dy
x
a
p
p
r
x
a
dx
r
x
a
−
−
=
⇒
=
=
−
−
−
−
 
 
whence 
 
 
 
2
2
2
2
(
)
(
)
,
(
)
x
a dx
y
r
x
a
b
r
x
a
−
=
= −
−
−
+
−
−
⌠
⌡
 
 
which finally gives  
2
2
2
(
)
(
)
x
a
y
b
r
−
+
−
=
  as desired. 
 
 
CHAPTER 1 Review Problems 
 
The main objective of this set of review problems is practice in the identification of the different 
types of first-order differential equations discussed in this chapter.  In each of Problems 1–36 we 
identify the type of the given equation and indicate an appropriate method of solution. 
 
1. 
If we write the equation in the form  
2
(3/ )
y
x y
x
′−
=
 we see that it is linear with 
integrating factor  
3.
x
ρ
−
=
  The method of Section 1.5 then yields the general solution   
 
y  =  x3(C + ln x). 
 
2. 
We write this equation in the separable form  
2
2
/
(
3)/
.
y
y
x
x
′
=
+
  Then separation of 
variables and integration as in Section 1.4 yields the general solution   
 
y  =  x / (3 –  Cx – x ln x). 
 
3. 
This equation is homogeneous.  The substitution  y
vx
=
 of Equation (8) in Section 1.6 
leads to the general solution y  =  x/(C – ln x). 
 
4. 
We note that  
(
)
(
)
3
2
2
2
2
3
sin
6
,
x
y
x
D
xy
e
D
x y
y
xy
+
=
+
=
  so the given equation is 
exact.   The method of Example 9 in Section 1.6 yields the implicit general solution 
 
x2y3 + ex – cos  y  =  C. 
 

 
Review Problems 
65 
5. 
We write this equation in the separable form  
2
4
/
(2
3) /
.
y
y
x
x
′
=
−
  Then separation  
 
of variables and integration as in Section 1.4 yields the general solution   
 
y  =  C exp[(1 – x)/x3]. 
 
6. 
We write this equation in the separable form  
2
2
/
(1
2 )/
.
y
y
x
x
′
=
−
  Then separation  
 
of variables and integration as in Section 1.4 yields the general solution   
 
y  =  x / (1 + Cx + 2x ln x). 
 
7. 
If we write the equation in the form  
3
(2/ )
1/
y
x y
x
′ +
=
 we see that it is linear with 
integrating factor  
2.
x
ρ =
  The method of Section 1.5 then yields the general solution   
 
y  =  x–2(C + ln x). 
 
8. 
This equation is homogeneous.  The substitution  y
vx
=
 of Equation (8) in Section 1.6 
leads to the general solution y  =  3Cx/(C – x3). 
 
9. 
If we write the equation in the form  
(2/ )
6
y
x y
x
y
′ +
=
 we see that it is a Bernoulli 
equation with  n  =  1/2.  The substitution  
1/ 2
v
y−
=
 of Eq. (10) in Section 1.6 then 
yields the general solution  y  =  (x2 + C/x)2. 
 
10. 
We write this equation in the separable form  
(
)
2
2
/ 1
1
.
y
y
x
′
+
=
+
  Then separation  
 
of variables and integration as in Section 1.4 yields the general solution   
 
y  =  tan(C + x + x3/3). 
 
11. 
This equation is homogeneous.  The substitution  y
vx
=
 of Equation (8) in Section 1.6 
leads to the general solution  y  =  x / (C – 3 ln x). 
 
12. 
We note that  
(
)
(
)
3
4
2
2
3
2
3
6
2
9
8
18
8
,
y
x
D
xy
y
D
x y
xy
xy
y
+
=
+
=
+
  so the given 
equation is exact.  The method of Example 9 in Section 1.6 yields the implicit general 
solution  3x2y3 + 2xy4  =   C. 
 
13. 
We write this equation in the separable form  
2
4
/
5
4 .
y
y
x
x
′
=
−
  Then separation  
 
of variables and integration as in Section 1.4 yields the general solution    
 
 
y  =  1 / (C + 2x2 – x5). 
 
14. 
This equation is homogeneous.  The substitution  y
vx
=
 of Equation (8) in Section 1.6 
leads to the implicit general solution  y2  =  x2 / (C + 2 ln x). 
 
15. 
This is a linear differential equation with integrating factor  
3 .
x
e
ρ =
  The method of 
Section 1.5 yields the general solution   y  =  (x3 + C)e-3x. 
 

66 
Chapter 1 
16. 
The substitution  
,
,
1
v
y
x
y
v
x
y
v
′
′
=
−
=
+
=
+   gives the separable equation  
2
2
1
(
)
v
y
x
v
′+
=
−
=
 in the new dependent variable  v.  The resulting implicit general 
solution of the original equation is  y – x – 1  =  C e2x(y – x + 1).  
 
17. 
We note that  
(
)
(
)
,
x
x y
y
x y
x y
x y
y
x
D
e
y e
D
e
xe
e
xy e
+
=
+
=
+
  so the given equation is 
exact.  The method of Example 9 in Section 1.6 yields the implicit general solution   
 
ex + ey + ex y  =   C. 
 
18. 
This equation is homogeneous.  The substitution  y
vx
=
 of Equation (8) in Section 1.6 
leads to the implicit general solution  y2  =   Cx2(x2 –  y2). 
 
19. 
We write this equation in the separable form  
(
)
2
5
3
/
2
3
/
.
y
y
x
x
′
=
−
  Then separation  
 
of variables and integration as in Section 1.4 yields the general solution 
 
y  =  x2 / (x5 + Cx2 + 1). 
 
20. 
If we write the equation in the form  
5/2
(3/ )
3
y
x y
x−
′ +
=
 we see that it is linear with 
integrating factor  
3.
x
ρ =
  The method of Section 1.5 then yields the general solution   
 
y  =  2x–3/2 +  Cx–3. 
 
21. 
If we write the equation in the form  
(
)
2
1/(
1)
1/(
1)
y
x
y
x
′ +
+
=
−
 we see that it is linear 
with integrating factor  
1.
x
ρ =
+
  The method of Section then 1.5 yields the general 
solution  y  =  [C + ln(x – 1)] / (x + 1). 
 
22. 
If we write the equation in the form  
3
2/3
(6/ )
12
y
x y
x y
′ −
=
 we see that it is a Bernoulli 
equation with  n  =  1/3.  The substitution  
2/3
v
y−
=
 of Eq. (10) in Section 1.6 then 
yields the general solution  y  =  (2x4 +  Cx2)3. 
 
23. 
We note that  
(
)
(
)
cos
sin
cos ,
y
y
y
y
x
D
e
y
x
D
x e
x
e
x
+
=
+
=
+
  so the given equation  
 
is exact.  The method of Example 9 in Section 1.6 yields the implicit general solution   
 
x ey +  y sin x  =  C 
 
24. 
We write this equation in the separable form  
(
)
2
2
3/2
/
1
9
/
.
y
y
x
x
′
=
−
  Then separation  
 
of variables and integration as in Section 1.4 yields the general solution    
 
 
y  =  x1/2 / (6x2 + Cx1/2 + 2). 
 
25. 
If we write the equation in the form  
(
)
2/(
1)
3
y
x
y
′ +
+
=
 we see that it is linear with 
integrating factor  
(
)
2
1 .
x
ρ =
+
  The method of Section 1.5 then yields the general 
solution  y  =  x + 1 + C (x + 1)–2. 
 
26. 
We note that  
(
)
(
)
1/2
4/3
1/5
3/2
3/2
1/3
6/5
1/2
9
12
8
15
y
x
D
x
y
x
y
D
x
y
x
y
−
=
−
=    

 
Review Problems 
67 
 
1/2
1/3
1/5
1/2
12
18
,
x
y
x
y
−
so the given equation is exact.  The method of Example 9 in 
Section 1.6 yields the implicit general solution  6x3/2y4/3 – 10x6/5y3/2  =  C. 
 
27. 
If we write the equation in the form  
2
4
(1/ )
/3
y
x y
x y
′ +
= −
 we see that it is a Bernoulli 
equation with  n  =  4.  The substitution  
3
v
y−
=
 of Eq. (10) in Section 1.6 then yields 
the general solution  y  =  x–1(C + ln x)–1/3. 
 
28. 
If we write the equation in the form  
2
(1/ )
2
/
x
y
x y
e
x
′ +
=
 we see that it is linear with 
integrating factor  
.x
ρ =
  The method of Section 1.5 then yields the general solution   
 
y  =  x–1(C + e2x). 
 
29. 
If we write the equation in the form  
(
)
1/2
1/(2
1)
(2
1)
y
x
y
x
′ +
+
=
+
 we see that it is 
linear with integrating factor  
(
)
1/2
2
1
.
x
ρ =
+
  The method of Section 1.5 then yields  
 
the general solution y  =  (x2 + x + C)(2x + 1)–1/2. 
 
30. 
The substitution  
,
,
1
v
x
y
y
v
x
y
v
′
′
=
+
=
−
=
−  gives the separable equation  
1
v
v
′−
=
 in the new dependent variable  v.  The resulting implicit general solution of 
the original equation is  x  =  2(x +  y)1/2 – 2 ln[1 + (x +  y)1/2] + C. 
 
31. 
2
/(
7)
3
dy
y
x dx
+
=
is separable;  
2
2
3
21
y
x y
x
′+
=
is linear. 
 
32. 
2
/(
1)
dy
y
xdx
−
=
is separable;  
3
y
x y
x y
′+
=
is a Bernoulli equation with  n = 3. 
 
33. 
2
2
(3
2
)
4
0
x
y
dx
xy dy
+
+
=
is exact;  
(
)
1
4 3 /
2 /
y
x y
y x
′ = −
+
is homogeneous.  
 
 
34. 
(
3 )
(3
)
0
x
y dx
x
y dy
+
+
−
=
is exact;  
1
3 /
/
3
y x
y
y x
+
′ =
−
is homogeneous. 
 
35. 
(
)
2
/(
1)
2
/
1
dy
y
xdx
x
+
=
+
is separable;  
(
)
2
2
2 /(
1)
2 /(
1)
y
x
x
y
x
x
′ −
+
=
+
is linear. 
 
 
36. 
(
)
/
cot
dy
y
y
xdx
−
=
is separable;   
(cot )
(cot )
y
x y
x
y
′ +
=
is a Bernoulli equation  
with  n = 1/2. 
 

68 
Chapter 2 
0
1
−5
0
5
10
15
t
x
CHAPTER 2 
  
MATHEMATICAL MODELS  
AND NUMERICAL METHODS 
 
SECTION 2.1 
 
POPULATION MODELS 
 
Section 2.1 introduces the first of the two major classes of mathematical models studied in the 
textbook, and is a prerequisite to the discussion of equilibrium solutions and stability in Section 2.2. 
 
In Problems 1–8 we outline the derivation of the desired particular solution, and then sketch some 
typical solution curves. 
 
1. 
Noting that  
1 because
(0)
2,
x
x
>
=
 we write 
 
 
1
1
1
;
1
(1
)
1
dx
dt
dx
dt
x
x
x
x


=
−
=


−
−


⌠
⌠

⌡
⌡
∫
∫
 
 
ln
ln(
1)
ln
;
1
t
x
x
x
t
C
C e
x
−
−
=
+
=
−
 
 
(0)
2 implies
2;
2(
1)
t
x
C
x
x
e
=
=
=
−
 
 
2
2
( )
2
1
2
t
t
t
e
x t
e
e−
=
=
−
−
. 
 
Typical solution curves are shown in the figure on the left below. 
 
 
 
 
 
 
 
 
 
 
0
1
2
3
4
5
−1
0
1
2
3
t
x

 
Section 2.1 
69 
1
−3
−2
−1
0
1
2
3
t
x
2. 
Noting that  
10 because
(0)
1,
x
x
<
=
 we write 
 
 
1
1
1
;
10
(10
)
10
dx
dt
dx
dt
x
x
x
x


=
+
=


−
−


⌠
⌠

⌡
⌡
∫
∫
 
 
10
ln
ln(10
)
10
ln
;
10
t
x
x
x
t
C
C e
x
−
−
=
+
=
−
 
 
10
1
(0)
1 implies
;
9
(10
)
9
t
x
C
x
x e
=
=
=
−
 
 
10
10
10
10
10
( )
9
1
9
t
t
t
e
x t
e
e−
=
=
+
+
. 
 
Typical solution curves are shown in the figure on the right at the bottom of the  
 
preceding page. 
 
3. 
Noting that  
1 because
(0)
3,
x
x
>
=
 we write 
 
 
1
1
1
;
( 2)
(1
)(1
)
1
1
dx
dt
dx
dt
x
x
x
x


=
−
=
−


+
−
−
+


⌠
⌠

⌡
⌡
∫
∫
 
 
2
1
ln(
1)
ln(
1)
2
ln
;
1
t
x
x
x
t
C
C e
x
−
−
−
−
+
= −
+
=
+
 
 
2
1
(0)
3 implies
;
2(
1)
(
1)
2
t
x
C
x
x
e −
=
=
−
=
+
 
 
2
2
2
2
2
2
1
( )
2
2
1
t
t
t
t
e
e
x t
e
e
−
−
+
+
=
=
−
−
. 
 
Typical solution curves are shown in the figure on the left below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
1
2
3
−2
−1
0
1
2
3
4
t
x

70 
Chapter 2 
0
0.25
0.5
−5
0
5
10
t
x
 
4. 
Noting that  
3
2 because
(0)
0,
x
x
<
=
 we write 
 
 
1
1
1
;
6
(3
2 )(3
2 )
3
2
3
2
dx
dt
dx
dt
x
x
x
x


=
+
=


+
−
+
−


⌠
⌠

⌡
⌡
∫
∫
 
 
12
1
1
1
3
2
ln(3
2 )
ln(3
2 )
6
ln
;
2
2
2
3
2
t
x
x
x
t
C
C e
x
+
+
−
−
=
+
=
−
 
 
12
(0)
0 implies
1;
3
2
(3
2 )
t
x
C
x
x e
=
=
+
=
−
 
 
(
)
(
)
12
12
12
12
3
1
3
3
( )
2
2
2
1
t
t
t
t
e
e
x t
e
e
−
−
=
=
+
+
. 
 
Typical solution curves are shown in the figure on the right at the bottom of the  
 
preceding page. 
 
5. 
Noting that  
5 because
(0)
8,
x
x
>
=
 we write 
 
 
1
1
( 3)
;
15
(
5)
5
dx
dt
dx
dt
x x
x
x


=
−
−
=


−
−


⌠
⌠

⌡
⌡
∫
∫
 
 
15
ln
ln(
5)
15
ln
;
5
t
x
x
x
t
C
C e
x
−
−
=
+
=
−
 
 
15
(0)
8 implies
8/ 3;
3
8(
5)
t
x
C
x
x
e
=
=
=
−
 
 
15
15
15
40
40
( )
3
8
8
3
t
t
t
e
x t
e
e−
−
=
=
−
−
. 
 
Typical solution curves are shown in the figure on the left below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
0
0.25
0.5
−5
0
5
10
t
x

 
Section 2.1 
71 
0
0.01
0.02
−10
0
10
20
30
t
x
6. 
Noting that  
5 because
(0)
2,
x
x
<
=
 we write 
 
 
1
1
( 3)
;
( 15)
(5
)
5
dx
dt
dx
dt
x
x
x
x


=
−
+
=
−


−
−


⌠
⌠

⌡
⌡
∫
∫
 
 
15
ln
ln(5
)
15
ln
;
5
t
x
x
x
t
C
C e
x
−
−
−
= −
+
=
−
 
 
15
(0)
2 implies
2/3;
3
2(5
)
t
x
C
x
x e−
=
=
=
−
 
 
15
15
15
10
10
( )
3
2
2
3
t
t
t
e
x t
e
e
−
−
=
=
+
+
. 
 
Typical solution curves are shown in the figure on the right at the bottom of the  
 
preceding page. 
 
 
7. 
Noting that  
7 because
(0)
11,
x
x
>
=
 we write 
 
 
1
1
( 4)
;
28
(
7)
7
dx
dt
dx
dt
x x
x
x


=
−
−
=


−
−


⌠
⌠

⌡
⌡
∫
∫
 
 
28
ln
ln(
7)
28
ln
;
7
t
x
x
x
t
C
C e
x
−
−
=
+
=
−
 
 
28
(0)
11 implies
11/ 4;
4
11(
17)
t
x
C
x
x
e
=
=
=
−
 
 
28
28
28
77
77
( )
4
11
11
4
t
t
t
e
x t
e
e−
−
=
=
−
−
. 
 
Typical solution curves are shown in the figure on the left below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
0
0.1
−5
0
5
10
15
t
x

72 
Chapter 2 
 
8. 
Noting that  
13 because
(0)
17,
x
x
>
=
 we write 
 
 
1
1
7
;
( 91)
(
13)
13
dx
dt
dx
dt
x x
x
x


=
−
=
−


−
−


⌠
⌠

⌡
⌡
∫
∫
 
 
91
ln
ln(
13)
91
ln
;
13
t
x
x
x
t
C
C e
x
−
−
−
= −
+
=
−
 
 
91
(0)
17 implies
17/ 4;
4
17(
13)
t
x
C
x
x
e−
=
=
=
−
 
 
91
91
91
221
221
( )
4
17
17
4
t
t
t
e
x t
e
e
−
−
−
=
=
−
−
. 
 
Typical solution curves are shown in the figure on the right at the bottom of the  
 
preceding page. 
 
9. 
Substitution of  
(0)
100 and
(0)
20
P
P′
=
=
 into  P
k
P
′ =
 yields  k = 2, so the 
differential equation is  
2
.
P
P
′ =
  Separation of variables and integration,  
/ 2
,
dP
P
dt
=
∫
∫
 gives  
.
P
t
C
=
+
  Then  P(0) = 100  implies  C = 10, so   
 
P(t)  =  (t + 10)2.  Hence the number of rabbits after one year is  P(12)  =  484. 
 
10. 
Given  
( /
)
,
P
P
k
P P
k
P
δ
′ = −
= −
= −
 separation of variables and integration as in 
Problem 9 yields  2
.
P
kt
C
= −
+
  The initial condition  P(0)  =  900  gives  C = 60,  and 
then the condition  P(6)  =  441  implies that  k = 3.  Therefore  2
3
60,
P
t
= −
+
  so   
 
P  =  0  after  t  =  20  weeks. 
 
11. 
(a) 
Starting with  
/
,
dP dt
k
P
=
   dP/dt  =  k
,
P   we separate the variables and 
integrate to get  P(t)  =  (kt/2 + C)2.  Clearly  P(0)  =   P0  implies  
0.
C
P
=
 
 
 
(b) 
If  P(t)  =  (kt/2 + 10)2,  then  P(6)  =  169  implies that  k  =  1.  Hence   
 
P(t)  =  (t/2 + 10)2,  so there are  256  fish after  12  months. 
 
12. 
Solution of the equation  
2
P
k P
′ =
  by separation of variables and integration, 
 
 
 
 
 
2
1
;
,
dP
k dt
kt
C
P
P
=
−
=
−
⌠⌡
∫
 
 
  
gives  P(t)  =  1/(C – kt).  Now  P(0) = 12  implies that  C = 1/12, so now  P(t)  =   
 
12/(1 – 12kt).  Then  P(10) = 24  implies that  k = 1/240,  so finally   P(t)  =  240/(20 – t).   
Hence  P = 48  when t = 15, that is, in the year 2003.  And obviously  
as
20.
P
t
→∞
→
 
 

 
Section 2.1 
73 
13. 
(a) 
If the birth and death rates both are proportional to  P2  and  
,
β
δ
>
  then Eq. (1) in 
this section gives  
2
P
kP
′ =
  with  k  positive.  Separating variables and integrating as in 
Problem 12, we find that  ( )
1/(
).
P t
C
kt
=
−
 The initial condition  
0
(0)
P
P
=
 then gives 
 
0
1/
,
C
P
=
so  
0
0
0
( )
1/(1/
)
/(1
).
P t
P
kt
P
kPt
=
−
=
−
 
 
 
(b) 
If  
0
6
P =
 then  
( )
6/(1
6 ).
P t
kt
=
−
  Now the fact that  (10)
9
P
=
 implies that 
k = 180,  so  
( )
6/(1
/30)
180/(30
).
P t
t
t
=
−
=
−
  Hence it is clear that  
as
30
P
t
→∞
→
 (doomsday). 
 
14. 
Now  dP/dt  =  –kP2  with  k > 0,  and separation of variables yields  P(t)  =  1/(kt + C).   
Clearly  C  =  1/P0  as in Problem 13, so  P(t)  =  P0/(1 + kP0t) .  Therefore it is clear 
that
( )
0 as
P t
t
→
→∞, so the population dies out in the long run. 
 
15. 
If we write  
( /
)
P
b P a b
P
′ =
−
  we see that  M = a/b.  Hence   
 
0
0
0
0
2
0
0
(
)
.
B P
aP P
a
M
D
bP
b
=
=
=
 
 
 
Note also (for Problems 16 and 17) that  
0
0
/
a
B
P
=
  and  
2
0
0
/
.
b
D
P
k
=
=
 
 
16. 
The relations in Problem 15 give  k = 1/2400 and  M = 160.  The solution is 
 
/15
( )
19200/(120
40
).
t
P t
e−
=
+
  We find that  P = 0.95M  after about 27.69 months. 
 
17. 
The relations in Problem 15 give  k = 1/2400 and  M = 180.  The solution is 
 
3 /80
( )
43200/(240
60
).
t
P t
e−
=
−
  We find that  P = 1.05M  after about 44.22 months. 
 
18. 
If we write  
(
/ )
P
a P P
b a
′ =
−
  we see that  M = b/a.  Hence   
 
0
0
0
0
2
0
0
(
)
.
D P
bP P
b
M
B
aP
a
=
=
=
 
 
 
Note also (for Problems 19 and 20) that  
0
0
/
b
D
P
=
  and  
2
0
0
/
.
a
B
P
k
=
=
 
 
19. 
The relations in Problem 18 give  k = 1/1000 and  M = 90.  The solution is 
 
9 /100
( )
9000/(100
10
).
t
P t
e
=
−
  We find that  P = 10M  after about 24.41 months. 
 
20. 
The relations in Problem 18 give  k = 1/1100 and  M = 120.  The solution is 
 
6 /55
( )
13200/(110
10
).
t
P t
e
=
+
  We find that  P = 0.1M  after about 42.12 months. 
 
21. 
Starting with the differential equation  
/
(200
),
dP dt
kP
P
=
−
 we separate variables and 
 
integrate, noting that  
200
P <
 because  
0
100
P =
: 

74 
Chapter 2 
 
 
 
1
1
200
(200
)
200
dP
k dt
dP
k dt
P
P
P
P


=
⇒
+
=


−
−


⌠
⌠

⌡
⌡
∫
∫
; 
 
 
200
ln
200
ln
.
200
200
kt
P
P
kt
C
Ce
P
P
=
+
⇒
=
−
−
 
 
 
Now  
(0)
100
P
=
 gives  
1,
C =
 and  
(0)
1
P′
=  implies that  1
100(200
100),
k
=
⋅
−
 so 
 
we find that  
1/10000.
k =
  Substitution of these numerical values gives 
 
 
 
 
 
200 /10000
/50,
200
t
t
P
e
e
P =
=
−
 
 
 
and we solve readily for  
(
)
/50
( )
200/ 1
.
t
P t
e−
=
+
 Finally,  
(
)
6/5
(60)
200/ 1
153.7
P
e−
=
+
≈
 
 
million.  
 
22. 
We work in thousands of persons, so  M  =  100  for the total fixed population.  We 
 
substitute  M  =  100,  P′(0)  =  1,  and  P0  =  50  in the logistic equation, and thereby obtain 
 
 
 
 
1  =  k(50)(100 – 50),  
so 
k  =  0.0004. 
 
 
If  t  denotes the number of days until 80 thousand people have heard the rumor, then Eq. (7) 
in the text gives 
0.04
50 100
80
50
(100
50)
t
e−
×
=
+
−
, 
 
 
and we solve this equation for  t ≈ 34.66.  Thus the rumor will have spread to 80% of the 
population in a little less than 35 days. 
 
23. 
(a) 
x′  =  0.8x – 0.004x2  =  0.004x(200 – x),  so the maximum amount that will dissolve 
is  M  =  200 g. 
 
 
(b) 
With  M  =  200,  P0  =  50,  and  k  =  0.004,  Equation (4) in the text yields the 
solution 
 
 
 
 
 
0.08
10000
( )
.
50
150
t
x t
e−
=
+
 
 
 
Substituting  x = 100 on the left, we solve for  t  =  1.25 ln 3  ≈  1.37  sec. 
  
24. 
The differential equation for  N(t)  is  N'(t)  =  kN (15 – N).  When we substitute  N(0)  =  5 
(thousands)  and  N'(0)  =  0.5 (thousands/day)  we find that  k  =  0.01.  With  N  in place of  
P,  this is the logistic equation in Eq. (3) of the text, so its solution is given by Equation (7): 
 

 
Section 2.1 
75 
0.15
15 5
15
( )
.
5
10exp[ (0.01)(15) ]
1
2
t
N t
t
e−
×
=
=
+
−
+
 
 
 
Upon substituting  N  =  10  on the left, we solve for  t  =  (ln 4)/(0.15)  ≈  9.24  days. 
 
25. 
Proceeding as in Example 3 in the text, we solve the equations 
 
 
 
 
25.00k(M – 25.00)  =  3/8, 
47.54k(M – 47.54)  =  1/2 
 
 
for  M  =  100  and  k  =  0.0002.  Then Equation (4) gives the population function 
           
 
 
 
 
 
0.02
2500
( )
25
75
t
P t
e−
=
+
. 
 
 
We find that  P  =  75  when  t  =  50 ln 9  ≈  110,  that is, in 2035 A. D. 
   
26. 
The differential equation for  P(t)  is 
 
 
 
 
 
 
P′(t)  =  0.001P2 – δ P. 
 
 
When we substitute  P(0)  =  100  and  P′(0)  =  8  we find that  δ  =  0.02,  so 
 
 
 
 
2
0.001
0.02
0.001 (
20).
dP
P
P
P P
dt
=
−
=
−
 
 
 
We separate variables and integrate, noting that  
20
P >
 because  
0
100
P =
: 
 
 
 
1
1
0.001
0.02
(
20)
20
dP
dt
dP
dt
P P
P
P


=
⇒
−
=


−
−


⌠
⌠

⌡
⌡
∫
∫
; 
 
 
/50
20
1
20
ln
ln
.
50
t
P
P
t
C
Ce
P
P
−
−
=
+
⇒
=
 
 
 
Now  
(0)
100
P
=
 gives  
4/5,
C =
 hence 
 
 
 
/50
/50
100
5(
20)
4
( )
.
5
4
t
t
P
P e
P t
e
−
=
⇒
=
−
 
 
 
It follows readily that  P  =  200  when  t  =  50 ln(9/8)  ≈  5.89 months. 
 
27. 
We are given that 
 
 
 
 
 
P′  =  kP2 – 0.01P, 
 
 
When we substitute  P(0)  =  200  and  P′(0)  =  2  we find that  k  =  0.0001,  so 

76 
Chapter 2 
 
 
 
 
2
0.0001
0.01
0.0001 (
100).
dP
P
P
P P
dt
=
−
=
−
 
 
 
We separate variables and integrate, noting that  
100
P >
 because  
0
200
P =
: 
 
 
 
1
1
0.0001
0.01
(
100)
100
dP
dt
dP
dt
P P
P
P


=
⇒
−
=


−
−


⌠
⌠

⌡
⌡
∫
∫
; 
 
 
/100
100
1
100
ln
ln
.
100
t
P
P
t
C
Ce
P
P
−
−
=
+
⇒
=
 
 
 
Now  
(0)
100
P
=
 gives  
1/ 2,
C =
 hence 
 
 
 
/100
/100
200
2(
100)
( )
.
2
t
t
P
P e
P t
e
−
=
⇒
=
−
 
 
 
(a) 
P  =  1000  when  t  =  100 ln(9/5)  ≈  58.78. 
 
 
(b) 
as
100 ln 2
69.31
P
t
→∞
→
≈
. 
   
28. 
Our alligator population satisfies the equation 
 
 
 
 
2
0.0001
0.01
0.0001 (
100).
dP
x
x
x x
dt
=
−
=
−
 
 
 
With  x  in place of  P,  this is the same differential equation as in Problem 27, but now we 
 
use absolute values to allow both possibilities  
100 and
100 :
x
x
<
>
 
 
 
 
1
1
0.0001
0.01
(
100)
100
dx
dt
dP
dt
x x
x
x


=
⇒
−
=


−
−


⌠
⌠

⌡
⌡
∫
∫
; 
 
 
/100
100
100
1
ln
ln
.
100
t
x
x
t
C
Ce
x
x
−
−
=
+
⇒
=
 
 
 
 (*) 
 
 
(a) 
If  (0)
25
x
=
  then  
100 and
100
100
x
x
x
<
−
=
−
,  so (*) gives  
3
C =
 and hence 
 
 
 
 
/100
/100
100
100
3
( )
.
1
3
t
t
x
xe
x t
e
−
=
⇒
=
+
 
 
 
We therefore see that  ( )
0
x t →
  as  
.
t →∞ 

 
Section 2.1 
77 
 
(b) 
But if  (0)
150
x
=
 then  
100 and
100
100
x
x
x
>
−
=
−
,  so (*) gives  
1/3
C =
 
 
and hence 
 
 
 
/100
/100
300
3(
100)
( )
.
3
t
t
x
xe
x t
e
−
=
⇒
=
−
 
 
 
Now  ( )
x t →+∞  as  
(100ln3) ,
t
−
→
 so doomsday occurs after about 109.86 months. 
 
29. 
Here we have the logistic equation 
 
 
2
0.03135
0.0001489
0.0001489 (210.544
)
dP
P
P
P
P
dt
=
−
=
−
 
 
where  
0.0001489 and
210.544.
k
P
=
=
  With  
0
3.9
P =
 also, Eq. (7) in the text gives  
 
 
 
(0.0001489)(210.544)
0.03135
(210.544)(3.9)
821.122
( )
.
(3.9)
(210.544
3.9)
3.9
206.644
t
t
P t
e
e
−
−
=
=
+
−
+
 
 
 
(a)  
This solution gives  
(140)
127.008,
P
≈
 fairly close to the actual 1930 U.S. census  
 
population of 123.2 million. 
 
(b) 
The limiting population as  t →∞ is  821.122/3.9 = 210.544 million. 
 
(c) 
Since the actual U.S. population in 200 was about 281 million — already exceeding  
 
the maximum population predicted by the logistic equation — we see that that this model 
 
did not continue to hold throughout the 20th century. 
 
30. 
The equation is separable, so we have 
 
 
 
 
0
0
,
so
ln
.
t
t
dP
e
dt
P
e
C
P
α
α
β
β
α
−
−
=
= −
+
⌠
⌠

⌡
⌡
 
 
 
The initial condition  
0
(0)
P
P
=
  gives  
0
0
ln
/
,
C
P
β
α
=
+
 so 
 
 
 
 
 
(
)
0
0
( )
exp
1
.
t
P t
P
e α
β
α
−


=
−




 
 
31. 
If we substitute  P(0)  =  106  and  P′(0)  =  3×105  into the differential equation   
 
 
 
 
 
 
0
( )
,
t
P t
e
P
α
β
−
′
=
  
 
 
we find that  β0  =  0.3.  Hence the solution given in Problem 30 is 
 
 
 
 
 
0
( )
exp[(0.3/
)(1
)].
t
P t
P
e α
α
−
=
−
 
      

78 
Chapter 2 
 
The fact that  P(6)  =  2P0  now yields the equation 
 
 
 
 
 
f (α)  =  (0.3)(1 – e–6α) – α ln 2  =  0 
 
 
for  α.  We apply Newton′s iterative formula 
 
1
(
)
(
)
n
n
n
n
f
f
α
α
α
α
+
=
−
′
 
 
 
 
with  
6
( )
1.8
ln2
f
e
α
α
−
′
=
−
and initial guess  α0  =  1,  and find that  α  ≈   0.3915 .  
Therefore the limiting cell population as  t →∞  is 
 
6
6
0
0
exp(
/
)
10 exp(0.3/0.3915)
2.15 10 .
P
β
α
=
≈
×
 
 
 
Thus the tumor does not grow much further after  6  months. 
 
32. 
We separate the variables in the logistic equation and use absolute values to allow for both  
 
possibilities  
0
0
and
:
P
M
P
M
<
>
 
 
 
 
1
1
(
)
dP
k dt
dP
kM dt
P M
P
P
M
P


=
⇒
+
=


−
−


⌠
⌠

⌡
⌡
∫
∫
; 
 
 
ln
ln
.
kMt
P
P
kMt
C
Ce
M
P
M
P
=
+
⇒
=
−
−
  
 
 (*) 
 
 
If  
0P
M
<
  then  
and
P
M
M
P
M
P
<
−
=
−
,  so substitution of  
0
0,
t
P
P
=
=
 in  (*)  
 
gives  
0
0
/(
).
C
P
M
P
=
−
  It follows that 
 
 
 
 
 
0
0
.
kM t
P
P
e
M
P
M
P
=
−
−
 
 
But if  
0P
M
>
  then  
and
P
M
M
P
P
M
>
−
=
−
,  so substitution of  
0
0,
t
P
P
=
=
 in   
 
(*) gives  
0
0
/(
),
C
P
P
M
=
−
 and it follows that 
 
 
 
 
 
0
0
.
kM t
P
P
e
P
M
P
M
=
−
−
 
 
We see that the preceding two equations are equivalent, and either yields 
 
 
 
0
0
0
0
0
(
)
(
)
( )
,
(
)
kM t
kM t
kM t
MPe
M
P P
M
P P e
P t
M
P
Pe
−
=
−
⇒
=
−
+
 
 
which gives the desired result upon division of numerator and denominator by  
.
kM t
e
 
 

 
Section 2.1 
79 
33. 
(a) 
We separate the variables in the extinction-explosion equation and use absolute 
 
values to allow for both possibilities  
0
0
and
:
P
M
P
M
<
>
 
 
 
 
1
1
(
)
dP
k dt
dP
kM dt
P P
M
P
M
P


=
⇒
−
=


−
−


⌠
⌠

⌡
⌡
∫
∫
; 
 
 
ln
ln
.
kMt
P
M
P
M
kMt
C
Ce
P
P
−
−
=
+
⇒
=
  
 
 (*) 
 
 
If  
0P
M
<
  then  
and
P
M
P
M
M
P
<
−
=
−
,  so substitution of  
0
0,
t
P
P
=
=
 in  (*)  
 
gives  
0
0
(
)/
.
C
M
P
P
=
−
  It follows that 
 
 
 
 
 
0
0
.
kM t
M
P
M
P e
P
P
−
−
=
 
 
But if  
0P
M
>
  then  
and
P
M
P
M
P
M
>
−
=
−
,  so substitution of  
0
0,
t
P
P
=
=
 in   
 
(*) gives  
0
0
(
) /
,
C
P
M
P
=
−
 and it follows that 
 
 
 
 
 
0
0
.
kM t
P
M
P
M e
P
P
−
−
=
 
 
We see that the preceding two equations are equivalent, and either yields 
 
 
 
0
0
0
0
0
(
)
(
)
( )
.
(
)
kM t
kM t
MP
P
M P
P
M P e
P t
P
M
P e
−
=
−
⇒
=
+
−
 
 
(b) 
 If  
0P
M
<
 then the coefficient  
0
M
P
−
 is positive and the denominator increases 
 
without bound, so  
( )
0
P t →
 as  
.
t →∞  But if  
0
,
P
M
>
 then the denominator  
 
0
0
(
)
kM t
P
P
M e
−
−
 approaches zero — so  ( )
P t →+∞ — as  t  approaches the value 
 
0
0
(1/
)ln([
/(
)]
0
kM
P
P
M
−
>
 from the left. 
 
34. 
Differentiation of both sides of the logistic equation  
(
)
P
kP
M
P
′ =
⋅
−
 yields 
 
 
 
2
1
2
[
(
)
( 1)]
(
)
[
2 ]
(
)
2
(
)(
)
dP
dP
P
dP
dt
k
M
P
kP
kP M
P
k M
P
kP M
P
k P M
P M
P
′
′′ =
⋅
=
⋅
−
+
⋅−
⋅
−
=
−
⋅
−
=
−
−
 
 
as desired.  The conclusions that  
1
2
0 if 0
,
P
P
M
′′ >
<
<
  that   
1
2
0 if
,
P
P
M
′′ =
=
  and 
that   
1
2
0 if
P
M
P
M
′′ <
<
<
  are then immediate.  Thus it follows that each of the 
curves for which  
0P
M
<
 has an inflection point where it crosses the horizontal line  
1
2
.
P
M
=
 

80 
Chapter 2 
35. 
Any way you look at it, you should see that, the larger the parameter  k > 0  is, the faster the 
logistic population  P(t)  approaches its limiting population  M. 
 
36. 
With  
50
0
1
2
,
5.308,
23.192, and
76.212,
kM
x
e
P
P
P
−
=
=
=
=
 Eqs. (7) in the text take the 
form 
 
 
 
0
0
1
2
2
0
0
0
0
,
(
)
(
)
P M
P M
P
P
P
M
P x
P
M
P x
=
=
+
−
+
−
 
 
 
from which we get 
 
 
 
2
0
0
0
1
0
0
0
2
(
)
/
,
(
)
/
P
M
P x
P M P
P
M
P x
P M P
+
−
=
+
−
=
 
 
 
2
0
1
0
2
1
0
2
0
(
)
(
)
,
(
)
(
)
P M
P
P M
P
x
x
P M
P
P M
P
−
−
=
=
−
−
 
 
 
 
(i) 
 
 
2
2
0
1
0
2
2
2
1
0
2
0
(
)
(
)
(
)
(
)
P
M
P
P M
P
P
M
P
P M
P
−
−
=
−
−
 
 
 
2
2
0
2
1
1
0
2
(
)
(
)(
)
P P M
P
P
M
P
M
P
−
=
−
−
 
 
 
2
2
2
2
2
2
0
2
0
1
2
0
1
2
1
1
0
2
0
1
2
2
(
)
P P M
P PP M
P P P
P M
P
P
P M
P P P
−
+
=
−
+
+
 
 
 
We cancel the final terms on the two sides of this last equation and solve for 
 
 
 
 
1
0
2
0
1
1
2
2
0
2
1
(2
) .
P
P P
P P
PP
M
P P
P
−
−
=
−
 
 
 
 
(ii) 
 
 
Substitution of the given values  
0
1
2
5.308,
23.192, and
76.212
P
P
P
=
=
=
 now gives   
 
M  =  188.121.  The first equation in (i) and  
1
exp(
)
x
kMt
=
−
 yield 
 
 
 
 
0
1
1
1
0
1
(
)
ln
.
(
)
P M
P
k
Mt
P M
P
−
= −
−
 
 
 
 
 
(iii) 
 
 
Now substitution of  t1 = 50  and our numerical values of  
0
1
2
,
,
,
M P P P  gives 
k  =  0.000167716.  Finally, substitution of these values of  k  and  M  (and  P0) in the 
logistic solution (4) gives the logistic model of Eq. (8) in the text. 
 
In Problems 37 and 38 we give just the values of  k  and  M  calculated using Eqs. (ii) and (iii) in 
Problem 36 above, the resulting logistic solution, and the predicted year 2000 population. 
 
37. 
0.0226045
25761.7
0.0000668717 and
= 338.027, so
( )
76.212
261.815
t
k
M
P t
e−
=
=
+
, 
 
predicting  P  =  192.525  in the year 2000. 

 
Section 2.1 
81 
38. 
0.0305458
4829.73
0.000146679 and
= 208.250, so
( )
23.192
185.058
t
k
M
P t
e−
=
=
+
, 
 
predicting  P  =  248.856  in the year 2000.  
 
1
2
3
4
5
t
105
110
115
120
P
 
 
 
39. 
We readily separate the variables and integrate: 
 
 
 
(
cos2
)
ln
sin2
ln
.
2
dP
b
k
b
t dt
P
kt
t
C
P
π
π
π
=
+
⇒
=
+
+
⌠⌡
∫
  
 
Clearly  
0,
C
P
=
 so we find that  
0
( )
exp
sin2
.
2
b
P t
P
kt
t
π
π


=
+




  The colored curve in 
 
the figure above shows the graph that results with the typical numerical values  
 
0
100,
P =
 
0.03,
k =
 and  
0.06.
b =
  It oscillates about the black curve which represents 
 
natural growth with  
0 and
0.03.
P
k =
 We see that the two agree at the end of each full 
 
year. 
 
 
 
SECTION 2.2 
 
EQUILIBRIUM SOLUTIONS AND STABILITY 
 
In Problems 1–12 we identify the stable and unstable critical points as well as the funnels and spouts 
along the equilibrium solutions.  In each problem the indicated solution satisfying  x(0) = x0  is 
derived fairly routinely by separation of variables.  In some cases, various signs in the solution 
depend on the initial value, and we give a typical solution. For each problem we show typical 
solution curves corresponding to different values of  
0.
x  
 

82 
Chapter 2 
0
1
2
3
4
5
0
3
6
t
x
1. 
Unstable critical point:  x = 4 
 
Spout:  Along the equilibrium solution  x(t) =  4 
 
Solution:  If  
0
4
x >
 then 
 
 
0
;
ln(
4)
;
ln(
4)
4
dx
dt
x
t
C
C
x
x
=
−
=
+
=
−
−
⌠⌡
∫
 
 
 
(
)
0
0
4
4
;
( )
4
(
4)
t
t
x
x
e
x t
x
e
−
=
−
=
+
−
. 
 
Typical solution curves are shown in the figure on the left below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
2. 
Stable critical point:  x = 3 
 
Funnel:  Along the equilibrium solution  x(t)  =  3 
 
Solution:  If  
0
3
x >
 then 
 
 
0
( 1)
;
ln(
3)
;
ln(
3)
3
dx
dt
x
t
C
C
x
x
=
−
−
= −+
=
−
−
⌠⌡
∫
 
 
 
(
)
0
0
3
3
;
( )
3
(
3)
t
t
x
x
e
x t
x
e
−
−
−
=
−
=
+
−
. 
 
Typical solution curves are shown in the figure on the right above. 
 
3. 
Stable critical point:  x = 0 
 
Unstable critical point:  x = 4 
 
Funnel:  Along the equilibrium solution  x(t)  =  0 
 
Spout:  Along the equilibrium solution  x(t)  =  4 
 
Solution:  If  
0
4
x >
 then  
 
 
4
1
1
4
(
4)
4
dx
dt
dx
x x
x
x


=
=
−


−
−


⌠
⌠

⌡
⌡
∫
 
0
1
2
3
4
5
0
4
8
t
x

 
Section 2.2 
83 
0
1
2
3
4
5
−3
0
3
6
t
x
 
 
0
0
4
4
4
ln
;
ln
x
x
t
C
C
x
x
−
−
+
=
=
 
 
 
4
0
0
0
0
(
4)
(
4)
4
ln
;
(
4)
(
4)
t
x
x
x
x
t
e
x x
x x
−
−
=
=
−
−
 
 
 
0
4
0
0
4
( )
(4
)
t
x
x t
x
x
e
=
+
−
. 
 
Typical solution curves are shown in the figure on the left below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
4. 
Stable critical point:  x = 3 
 
Unstable critical point:  x = 0 
 
Funnel:  Along the equilibrium solution  x(t)  =  3 
 
Spout:  Along the equilibrium solution  x(t)  =  0 
 
Solution:    If  
0
3
x >
 then  
 
 
3
1
1
( 3)
(
3)
3
dx
dt
dx
x x
x
x


−
=
=
−


−
−


⌠
⌠

⌡
⌡
∫
 
 
 
0
0
3
3
3
ln
;
ln
x
x
t
C
C
x
x
−
−
−
+
=
=
 
 
 
3
0
0
0
0
(
3)
(
3)
3
ln
;
(
3)
(
3)
t
x
x
x
x
t
e
x x
x x
−
−
−
−
=
=
−
−
 
 
 
0
3
0
0
3
( )
(3
)
t
x
x t
x
x
e−
=
+
−
. 
 
Typical solution curves are shown in the figure on the right above. 
0
1
2
3
4
5
−4
0
4
8
t
x

84 
Chapter 2 
5. 
Stable critical point:  x = −2 
 
Unstable critical point:  x = 2 
 
Funnel:  Along the equilibrium solution  x(t)  =  −2 
 
Spout:  Along the equilibrium solution  x(t)  =  2 
 
Solution:   If  
0
2
x >
 then  
 
 
2
4
1
1
4
4
2
2
dx
dt
dx
x
x
x


=
=
−


−
−
+


⌠
⌠

⌡
⌡
∫
 
 
 
0
0
2
2
4
ln
;
ln
2
2
x
x
t
C
C
x
x
−
−
+
=
=
+
+
 
 
 
4
0
0
0
0
(
2)(
2)
(
2)(
2)
4
ln
;
(
2)(
2)
(
2)(
2)
t
x
x
x
x
t
e
x
x
x
x
−
+
−
+
=
=
+
−
+
−
 
 
 
4
0
0
4
0
0
2 (
2)
(
2)
( )
(
2)
(
2)
t
t
x
x
e
x t
x
x
e


+
+
−


=
+
−
−
. 
 
 
Typical solution curves are shown in the figure below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
6. 
Stable critical point:  x = 3 
 
Unstable critical point:  x = −3 
 
Funnel:  Along the equilibrium solution  x(t)  =  3 
 
Spout:  Along the equilibrium solution  x(t)  =  −3 
 
Solution:    If  
0
3
x >
 then  
 
 
 
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
−2
0
2
t
x

 
Section 2.2 
85 
 
 
 
2
6
1
1
6
9
3
3
dx
dt
dx
x
x
x


=
=
+


−
+
−


⌠
⌠

⌡
⌡
∫
 
 
 
0
0
3
3
6
ln
;
ln
3
3
x
x
t
C
C
x
x
+
+
+
=
=
−
−
 
 
 
6
0
0
0
0
(
3)(
3)
(
3)(
3)
6
ln
;
(
3)(
3)
(
3)(
3)
t
x
x
x
x
t
e
x
x
x
x
+
−
+
−
=
=
+
−
+
−
 
 
 
6
0
0
6
0
0
3 (
3)
(
3)
( )
(3
)
(
3)
t
t
x
x
e
x t
x
x
e


−
+
+


=
−
+
+
. 
 
 
Typical solution curves are shown in the figure below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
7. 
Critical point:   x  =  2 
 
This single critical point is semi-stable, meaning that solutions with  x0 > 2  go to infinity 
 
as  t  increases, while solutions with  x0 < 2  approach 2. 
 
Solution:    If  
0
2
x >
 then  
 
 
2
0
1
1
( 1)
;
;
(
2)
2
2
dx
dt
t
C
C
x
x
x
−
=
−
= −+
=
−
−
−
⌠
⌠

⌡
⌡
 
 
 
0
0
0
1
1
1
(
2)
2
2
2
t x
t
x
x
x
−
−
= −+
=
−
−
−
 
0
1
2
3
4
5
−3
0
3
t
x

86 
Chapter 2 
0
1
2
3
4
5
0
3
6
t
x
 
 
0
0
0
0
2
(2
1)
4
( )
2
1
(
2)
2
1
x
x
t
t
x t
t x
t x
t
−
−
−
=
+
=
−
−
−
−
. 
 
 
 
Typical solution curves are shown in the figure on the left below. 
 
  
 
 
 
 
 
 
 
 
 
 
 
8. 
Critical point:   x  =  3 
This single critical point is semi-stable, meaning that solutions with  x0 < 3  go to minus  
infinity as  t  increases, while solutions with  x0 > 3  approach 3. 
 
Solution:  If  
0
3
x >
 then  
 
 
2
0
1
1
;
;
(
3)
3
3
dx
dt
t
C
C
x
x
x
−
=
=
+
=
−
−
−
⌠
⌠

⌡
⌡
 
 
 
0
0
0
1
1
1
(
3)
3
3
3
t x
t
x
x
x
+
−
=
+
=
−
−
−
 
 
 
0
0
0
0
3
(3
1)
9
( )
3
1
(
3)
3
1
x
x
t
t
x t
t x
t x
t
−
+
−
=
+
=
+
−
−
+
. 
 
 
Typical solution curves are shown in the figure on the right above. 
 
9. 
Stable critical point:  x = 1 
 
Unstable critical point:  x = 4 
 
Funnel:  Along the equilibrium solution  x(t)  =  1 
 
Spout:  Along the equilibrium solution  x(t)  =  4 
 
Solution:    If  
0
4
x >
 then  
0
1
2
3
4
5
0
2
4
t
x

 
Section 2.2 
87 
 
 
3
1
1
3
(
4)(
1)
4
1
dx
dt
dx
x
x
x
x


=
=
−


−
−
−
−


⌠
⌠

⌡
⌡
∫
 
 
 
0
0
4
4
3
ln
;
ln
1
1
x
x
t
C
C
x
x
−
−
+
=
=
−
−
 
 
 
3
0
0
0
0
(
4)(
1)
(
4)(
1)
3
ln
;
(
1)(
4)
(
1)(
4)
t
x
x
x
x
t
e
x
x
x
x
−
−
−
−
=
=
−
−
−
−
 
 
 
3
0
0
3
0
0
4(1
)
(
4)
( )
(1
)
(
4)
t
t
x
x
e
x t
x
x
e
−
+
−
=
−
+
−
. 
 
 
Typical solution curves are shown in the figure on the left below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
10. 
Stable critical point:  x = 5 
 
Unstable critical point:  x = 2 
 
Funnel:  Along the equilibrium solution  x(t)  =  5 
 
Spout:  Along the equilibrium solution  x(t)  =  2 
 
Solution:    If  
0
5
x >
 then  
 
 
( 3)
1
1
3
(
5)(
2)
2
5
dx
dt
dx
x
x
x
x
−


=
=
−


−
−
−
−


⌠
⌠

⌡
⌡
∫
 
 
 
0
0
2
2
3
ln
;
ln
5
5
x
x
t
C
C
x
x
−
−
+
=
=
−
−
 
 
 
3
0
0
0
0
(
2)(
5)
(
2)(
5)
3
ln
;
(
5)(
2)
(
5)(
2)
t
x
x
x
x
t
e
x
x
x
x
−
−
−
−
=
=
−
−
−
−
 
0
1
2
3
4
5
−2
1
4
7
t
x

88 
Chapter 2 
0
1
2
3
4
5
−2
0
2
4
t
x
 
 
3
0
0
3
0
0
2(5
)
5(
2)
( )
(5
)
(
2)
t
t
x
x
e
x t
x
x
e
−
+
−
=
−
+
−
. 
 
Typical solution curves are shown in the figure on the left below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
11. 
Unstable critical point:  x = 1 
 
Spout:  Along the equilibrium solution  x(t) =  1 
 
Solution:    
3
2
2
0
2
1
1
( 2)
;
2
(
1)
(
1)
(
1)
dx
dt
t
x
x
x
−
=
−
= −
+
−
−
−
⌠⌡
∫
. 
 
 
Typical solution curves are shown in the figure on the right above. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
0
1
2
3
4
5
−1
2
5
8
t
x
0
1
2
3
4
5
−2
0
2
4
6
t
x

 
Section 2.2 
89 
 
 
12. 
Stable critical point:  x = 2 
 
Funnel:  Along the equilibrium solution  x(t) =  2 
 
 
Solution:    
3
2
2
0
2
1
1
2
;
2
(2
)
(2
)
(2
)
dx
dt
t
x
x
x
=
=
+
−
−
−
⌠⌡
∫
. 
 
 
Typical solution curves are shown in the figure at the bottom of the preceding page. 
 
 
 
 
 
In each of Problems 13 through 18 we present the figure showing slope field  and typical solution 
curves, and then record the visually apparent classification of critical points for the given differential 
equation. 
 
 
13. 
The critical points  
2 and
2
x
x
=
= − are both unstable.  A slope field and typical solution 
 
curves of the differential equation are shown below. 
 
 
0
1
2
3
4
−4
−2
0
2
4
t
x
x ’ = (x + 2) (x − 2)2
x = 2
x = −2
 
 
 
 

90 
Chapter 2 
14. 
The critical points  
2
x = ±  are both unstable, while the critical point  
0
x =
 is stable.  A 
 
slope field and typical solution curves of the differential equation are shown below. 
 
0
1
2
3
4
−4
−2
0
2
4
t
x
x ’ = x (x2 − 4)
x = 2
x = 0
x = −2
 
 
 
15. 
The critical points  
2 and
2
x
x
=
= − are both unstable.  A  slope field and typical solution 
 
curves of the differential equation are shown below. 
 
0
1
2
3
4
−4
−2
0
2
4
t
x
x ’ = (x2 − 4)2
x = 2
x = −2
 

 
Section 2.2 
91 
16. 
The critical point  
2
x =
 is unstable, while the critical point  
2
x = − is  stable.  A  
slope 
 
field and typical solution curves of the differential equation are shown below. 
 
0
1
2
3
4
−4
−2
0
2
4
t
x
x ’ = (x2 − 4)3
x = 2
x = −2
 
 
 
17. 
The critical points  
2
x =
 and  
0
x =
 are unstable, while the critical point  
2
x = − is  stable.  
 
A slope field and typical solution curves of the differential equation are shown below. 
 
0
1
2
3
4
−4
−2
0
2
4
t
x
x ’ = x2 (x2 − 4)
x = 2
x = 0
x = −2
 

92 
Chapter 2 
18. 
The critical points  
2
x =
 and  
2
x = − are unstable, while the critical point  
0
x =
 is  stable. 
 
A slope field and typical solution curves of the differential equation are shown below. 
 
0
1
2
3
−2
0
2
t
x
x ’ = x3 (x2 − 4)
x = 2
x = 0
x = −2
 
 
 
19. 
The critical points of the given differential equation are the roots of the quadratic equation 
 
 
 
 
2
1
10 (10
)
0,
that is,
10
10
0.
x
x
h
x
x
h
−
−
=
−
+
=
 
 
 
Thus a critical point  c  is given in terms of  h  by   
 
 
 
 
10
100
40
5
25
10 .
2
h
c
h
±
−
=
=
±
−
 
 
It follows that there is no critical point if  
1
2
2 ,
h >
 only the single critical point  
0
c =
 if   
 
1
2
2 ,
h =
 and two distinct critical points if  
1
2
2
h <
 (so  10
25
0
h
−
>
).  Hence the bifurcation 
 
diagram in the hc-plane is the parabola with the 
2
(
5)
25 10
c
h
−
=
−
 that is obtained upon 
 
squaring to eliminate the square root above. 
 
20. 
The critical points of the given differential equation are the roots of the quadratic equation 
 
 
 
 
2
1
100 (
5)
0,
that is,
5
100
0.
x x
s
x
x
s
−
+
=
−
+
=
 
 
 
Thus a critical point  c  is given in terms of  s  by   

 
Section 2.2 
93 
 
 
 
 
5
25
400
5
5 1 16 .
2
2
2
s
c
s
±
−
=
=
±
−
 
 
 
It follows that there is no critical point if  
1
16 ,
s >
 only the single critical point  
0
c =
 if   
 
1
16 ,
s =
 and two distinct critical points if  
1
16
s <
 (so  1 16
0
s
−
>
).  Hence the bifurcation 
 
diagram in the sc-plane is the parabola  
2
(2
5)
25(1 16 )
c
s
−
=
−
 that is obtained upon  
 
elimination of the radical above. 
 
21. 
(a) 
If  k = -a2  where  
0,
a ≥
  then  
3
2
3
2
2
(
)
kx
x
a x
x
x a
x
−
= −
−
= −
+
  is 0 only if 
 
x = 0,  so the only critical point is  
0.
c =
  If  
0
a >
 then we can solve the differential  
 
equation by writing 
 
 
 
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
1
,
(
)
1
1
ln
ln(
)
ln
,
2
2
.
1
a t
a t
a t
a dx
x
dx
a dt
x a
x
x
a
x
x
a
x
a t
C
x
a Ce
Ce
x
a
x
Ce
−
−
−


=
−
= −


+
+


−
+
= −
+
=
⇒
=
+
−
⌠
⌠

⌡
⌡
∫
 
 
It follows that  
0 as
0,
x
t
→
→
 so the critical point  
0
c =
 is stable. 
 
 
 
(b) 
If  k = +a2  where  
0
a >
  then  
3
2
3
(
)(
)
kx
x
a x
x
x x
a
x
a
−
= +
−
= −
+
−
 is  
 
0 if either  
0 or
.
x
x
a
k
=
= ±
= ±
 Thus we have the three critical points  
0,
,
c
k
=
±
 
and this observation together with part (a) yields the pitchfork bifurcation diagram shown in 
Fig. 2.2.13 of the textbook. If  
0
x ≠
 then we can solve the differential equation by writing 
 
 
 
     
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
1
1
2
,
(
)(
)
2 ln
ln(
)
ln(
)
2
ln
,
.
1
1
a t
a t
a t
a dx
dx
a dt
x x
a
x
a
x
x
a
x
a
x
x
a
x
a
a t
C
x
a
a
k
Ce
x
x
x
Ce
Ce
−
−
−


=
−
+
+
= −


−
+
−
+


−
+
−
+
−
= −
+
−
±
=
⇒
=
⇒
=
−
−
⌠
⌠

⌡
⌡
∫
 
 
 
It follows that if  (0)
0
x
≠
 then  
if
0,
x
k
x
→
>
 
if
0.
x
k
x
→−
<
 This implies that 
 
the critical point  
0
c =
 is unstable, while the critical points  c
k
= ±
 are stable. 
 
22.   
If  
0
k =
 then the only critical point  
0
c =
 of the equation  x
x
′ =
 is unstable, because the 
 
solutions  
0
( )
t
x t
x e
=
 diverge to infinity if  
0
0
x ≠
.  If  
2
0,
k
a
= +
>
 then 
 
2
3
2
2
(1
)
0
x
a x
x
a x
+
=
+
=
 only if  
0,
x =
 so again  
0
c =
 is the only critical point.  If  

94 
Chapter 2 
 
2
0,
k
a
= −
<
 then 
2
3
2
2
(1
)
(1
)(1
)
0
x
a x
x
a x
x
ax
ax
−
=
−
=
−
+
=
  if either 
0
x =
 or  
 
1/
1/ .
x
a
k
= ±
= ±
−
  Hence the bifurcation diagram of the differential equation  
 
3
x
x
kx
′ =
+
 looks as pictured below: 
4
k
c
 
 
 
23. 
(a) 
If  h < kM  then the differential equation is  
(
)
(
/ )
x
k x
M
h k
x
′ =
−
−
,  which is a  
 
logistic equation with the reduced limiting population  M - h / k. 
  
(b) 
If  h > kM  then the differential equation can be rewritten in the form  
2
x
ax
bx
′ = −
−
  with  a  and  b  both positive.   The solution of this equation is 
 
0
0
0
( )
(
)
a t
a x
x t
a
b x e
bx
=
+
−
 
 
 
so it is obvious that  ( )
0 as
x t
t
→
→∞. 
 
24. 
If  
0x
N
>
 then  
 
 
(
)
1
1
(
)
(
)(
)
N
H dx
k N
H dt
dx
x
N
x
H
x
N
x
H
−


−
−
=
=
−


−
−
−
−


⌠
⌠

⌡
⌡
∫
 
 
 
0
0
(
)
ln
;
ln
x
N
x
N
k N
H t
C
C
x
H
x
H
−
−
−
−
+
=
=
−
−
 
 
 
(
)
0
0
0
0
(
)(
)
(
)(
)
(
)
ln
;
(
)(
)
(
)(
)
k N H t
x
N
x
H
x
N
x
H
k N
H t
e
x
H
x
M
x
H
x
M
−
−
−
−
−
−
−
−
=
=
−
−
−
−
 
 

 
Section 2.2 
95 
 
 
(
)
0
0
(
)
0
0
(
)
(
)
( )
(
)
(
)
k N H t
k N H t
N x
H
H x
N e
x t
x
H
x
N e
−
−
−
−
−
−
−
=
−
−
−
 
 
25. 
(i) 
In the first alternative form that is given, all of the coefficients within parentheses are 
 
positive if  H < x0 < N.  Hence it is obvious that  ( )
as
x t
N
t
→
→∞. 
 
(ii) 
In the second alternative form that is given, all of the coefficients within parentheses 
are positive if  x0 < H.  Hence the denominator is initially equal to  N - H > 0,  but decreases 
as  t  increases, and reaches the value 0 when 
 
0
0
1
ln
0.
N
x
t
N
H
H
x
−
=
>
−
−
 
 
26. 
If  4h = kM2  then  Eqs. (13) and (14)in the text show that the differential equation takes 
 
the form  
2
(
/ 2
)
x
k M
x
′ = −
−
  with the single critical point  x = M / 2.  This equation is  
 
readily solved by separation of variables, but clearly  x'  is negative whether  x  is less than 
 
or greater than  M / 2. 
 
27. 
Separation of variables in the differential equation  
(
)
2
2
(
)
x
k
x
a
b
′ = −
−
+
  yields 
1
0
( )
tan
tan
a
x
x t
a
b
bk t
b
−
−


=
−
+



. 
 
 
It therefore follows that  x(t)  goes to minus infinity in a finite period of time. 
 
28. 
Aside from a change in sign, this calculation is the same as that indicated in Eqs. (13) and 
 
(14) in the text. 
 
29. 
This is simply a matter of analyzing the signs of  x'  in the cases  x < a,  a < x < b,  b < x < c, 
 
and  c > x.  Alternatively, plot slope fields and typical solution curves for the two differential 
 
equations using typical numerical values such as  
1,
1,
2.
a
b
c
= −
=
=
 
 
 
 
SECTION 2.3 
 
ACCELERATION-VELOCITY MODELS 
 
This section consists of three essentially independent subsections that can be studied separately: 
resistance proportional to velocity, resistance proportional to velocity-squared, and inverse-square 
gravitational acceleration.   
 
 

96 
Chapter 2 
1. 
Equation: 
v'  =  k(250 − v),    v(0)  =  0,    v(10)  =  100 
 
Solution: 
( 1)
;
ln(250
)
ln
,
250
dv
k dt
v
kt
C
v
−
= −
−
= −
+
−
⌠⌡
∫
 
 
 
 
(0)
0 implies
250;
( )
250(1
)
kt
v
C
v t
e−
=
=
=
−
 
 
 
 
1
10
(10)
100 implies
ln(250/150)
0.0511;
v
k
=
=
≈
 
 
Answer: 
200 when
(ln50/ 250) /
31.5 sec
v
t
k
=
= −
≈
 
 
 
2. 
Equation: 
0
0
,
(0)
;
,
(0)
v
kv
v
v
x
v
x
x
′
′
= −
=
=
=
 
 
Solution: 
0
0
( )
( )
;
( )
(
/ )
k t
k t
x t
v t
v e
x t
v
k e
C
−
−
′
=
=
= −
+
 
 
 
 
(
)
0
0
0
0
(
/ )
;
( )
(
/ ) 1
k t
k t
C
x
v
k e
x t
x
v
k
e
−
−
=
+
=
+
−
 
 
 
Answer: 
(
)
0
0
0
0
lim ( )
lim
(
/ ) 1
(
/ )
k t
t
t
x t
x
v
k
e
x
v
k
−
→∞
→∞

=
+
−
=
+


 
 
3. 
Equation: 
,
(0)
40;
(10)
20
,
(0)
0
v
kv
v
v
x
v
x
′
′
= −
=
=
=
=
 
 
Solution: 
v(t)  =  40 e−k t  with  k  =  (1/10)ln 2 
 
 
 
x(t)  =  (40/k)(1 − e−k t) 
 
Answer: 
x(∞)  =  lim(40/ )(1
)
k t
t
k
e−
→∞
−
 =  40/k  =  400/ln 2  ≈  577  ft 
 
4. 
Equation: 
2
0
0
,
(0)
;
,
(0)
v
kv
v
v
x
v
x
x
′
′
= −
=
=
=
 
 
Solution: 
2
0
1
1
;
;
dv
k dt
k t
C
C
v
v
v
−
=
=
+
=
⌠⌡
∫
 
 
 
 
(
)
0
0
0
0
1
( )
( )
;
( )
ln 1
1
v
x t
v t
x t
v kt
x
v kt
k
′
=
=
=
+
+
+
 
 
 
 
( )
as
( )
x t
x t
→∞
→∞ 
 
5. 
Equation: 
,
(0)
40;
(10)
20
,
(0)
0
v
kv
v
v
x
v
x
′
′
= −
=
=
=
=
 
 
Solution: 
40
(as in Problem 3)
1
40
v
kt
=
+
 
 
 
 
400
(10)
20 implies 40
1/10, so
( )
10
v
k
v t
t
=
=
=
+  
 
 
 
x(t)  =  400 ln[(10 + t)/10] 
 
Answer: 
x(60)  =  400 ln 7  ≈  778  ft 

 
Section 2.3 
97 
 
6. 
Equation: 
3/ 2
0
0
,
(0)
;
,
(0)
v
kv
v
v
x
v
x
x
′
′
= −
=
=
=
 
 
Solution: 
3/ 2
0
1
1
;
;
2
2
2
dv
k dt
kt
C
C
v
v
v
−
=
=
+
=
⌠
⌠

⌡
⌡
 
 
 
 
(
)
(
)
0
0
2
0
0
4
4
( )
( )
;
( )
2
2
v
v
x t
v t
x t
C
k
kt v
kt v
′
=
=
= −
+
+
+
 
 
 
 
0
0
0
0
0
2
2
2
;
( )
1
2
v
v
C
x
x t
x
k
k
kt v


=
+
=
+
−




+


 
 
 
 
0
0
( )
2
/
x
x
v
k
∞
=
+
 
 
7. 
Equation: 
10
0.1 ,
(0)
(0)
0
v
v
x
v
′ =
−
=
=
 
 
(a) 
 
0.1
( 0.1)
;
ln(10
0.1 )
/10
ln
10
0.1
dv
dt
v
t
C
v
−
=
−
−
= −
+
−
⌠⌡
∫
 
 
 
 
[
]
(0)
0 implies
10;
ln (10
0.1 )/10
/10
v
C
v
t
=
=
−
= −
 
 
 
 
/10
( )
100(1
)
t
v t
e−
=
−
;     ( )
100
v ∞
=
 ft/sec   (limiting velocity) 
 
 
(b) 
 
/10
( )
100
1000(1
)
t
x t
t
e−
=
−
−
 
 
 
 
v  =  90 ft/sec  when  t  =  23.0259 sec  and  x  =  1402.59 ft 
 
8. 
Equation: 
2
10
0.001
,
(0)
(0)
0
v
v
x
v
′ =
−
=
=
 
 
(a) 
 
1
2
0.01
;
tanh
1
0.0001
10
100
10
dv
dt
v
t
C
v
−
=
=
+
−
⌠⌡
∫
 
 
 
 
(0)
0 implies
0 so
v
C
=
=
( )
100tanh( /10)
v t
t
=
 
 
 
 
/10
/10
/10
/10
( )
lim100tanh( /10)
100 lim
100 ft /sec
t
t
t
t
t
t
e
e
v
t
e
e
−
−
→∞
→∞
−
∞
=
=
=
+
 
 
 
(b) 
 
( )
1000 ln(cosh /10)
x t
t
=
 
 
 
 
 
v  =  90 ft/sec  when  t  =  14.7222 sec  and  x  =  830.366 ft 
 
 
9. 
The solution of the initial value problem 
 
 
 
 
1000 v'  =  5000 − 100 v, 
v(0)  =  0   
 
is 

98 
Chapter 2 
 
 
 
 
v(t)  =  50(1 − e−t /10). 
 
 
Hence, as  
,
t →∞ we see that  v(t)  approaches  vmax  =  50 ft/sec  ≈  34 mph. 
 
10. 
Before opening parachute: 
 
 
 
0.15
0.15
32
0.15 ,
(0)
0,
(0)
10000
( )
213.333(
1),
(20)
202.712 ft/sec
( )
11422.2
1422.22
213.333 ,
(20)
7084.75 ft
t
ty
v
v
v
y
v t
e
v
y t
e
t
y
−
−
′ = −
−
=
=
=
−
= −
=
−
−
=
 
 
 
After opening parachute: 
 
 
 
1.5
1.5
32
1.5 ,
(0)
202.712,
(0)
7084.75
( )
21.3333 181.379
( )
6964.83 120.919
21.3333 ,
0 when
326.476
t
t
v
v
v
y
v t
e
y t
e
t
y
t
−
−
′ = −
−
= −
=
= −
−
=
+
−
=
=
 
 
 
Thus she opens her parachute after 20 sec at a height of 7085 feet, and the total  
 
time of descent is  20 + 326.476 = 346.476 sec,  about 5 minutes and 46.5 seconds.  Her 
 
impact speed is 21.33 ft/sec,  about 15 mph. 
 
11. 
If the paratrooper′s terminal velocity was  100 mph  =  440/3  ft/sec,  then Equation (7) in 
the text yields  ρ  =  12/55.  Then we find by solving Equation (9) numerically with   
 
y0  =  1200  and  v0  =  0  that  y  =  0  when  t  ≈  12.5  sec.  Thus the newspaper account is 
inaccurate. 
 
12. 
With  m  =  640/32  =  20 slugs,  W  =  640 lb,  B  =  (8)(62.5)  =  500 lb, and  FR  =  −v  lb  
(FR is upward when  v < 0), the differential equation is 
 
 
 
 
20 v'(t)  =  −640 + 500 − v  =  −140 − v . 
 
 
Its solution with  v(0)  =  0  is 
 
 
 
 
 
(
)
0.05
( )
140
1 ,
t
v t
e−
=
−
 
 
 
and integration with  y(0) = 0  yields 
 
 
 
 
 
(
)
0.05
( )
1
2800
140
t
y t
e
t
−
=
−
−
. 
 
 
Using these equations we find that  t  =  20 ln(28/13)  ≈  15.35 sec  when  v  =  −75 ft/sec,  
and that  y(15.35)  ≈  −648.31 ft.  Thus the maximum safe depth is just under 650 ft. 
 

 
Section 2.3 
99 
Given the hints and integrals provided in the text, Problems 13–16 are fairly straightforward (and 
fairly tedious) integration problems. 
 
17. 
To solve the initial value problem  
2
9.8
0.0011
,
(0)
49
v
v
v
′ = −
−
=
  we write 
 
 
 
(
)
2
2
0.010595
;
0.103827
9.8
0.0011
1
0.010595
dv
dv
dt
dt
v
v
= −
= −
+
+
⌠
⌠

⌡
⌡
∫
∫
 
 
 
1
tan (0.010595 )
0.103827
;
(0)
49 implies
0.478854
v
t
C
v
C
−
= −
+
=
=
 
 
 
( )
94.3841 tan(0.478854
0.103827 )
v t
t
=
−
 
 
 
Integration with  y(0) = 0  gives 
 
 
 
( )
108.468
909.052 ln(cos(0.478854
0.103827 ))
y t
t
=
+
−
. 
 
We solve  v(0) = 0  for  t = 4.612,  and then calculate  y(4.612) = 108.468.   
 
18. 
We solve the initial value problem  
2
'
9.8
0.0011
,
(0)
0
v
v
v
= −
+
=
  much as in 
Problem 17, except using hyperbolic rather than ordinary trigonometric functions.  We first 
get 
 
 
 
 
 
( )
94.3841 tanh(0.103827 )
v t
t
= −
, 
 
 
and then integration with  y(0) = 108.47  gives 
 
 
 
 
( )
108.47
909.052 ln(cosh(0.103827 ))
y t
t
=
−
. 
 
We solve  y(0) = 0  for  
1
cosh (exp(108.47/ 909.052))/0.103.827
4.7992,
t
−
=
≈
  and then 
calculate  v(4.7992) = −43.489. 
 
19. 
Equation: 
2
4
(1/ 400)
,
(0)
0
v
v
v
′ =
−
=
 
 
Solution: 
2
2
(1/ 40)
1
;
4
(1/ 400)
1
( / 40)
10
dv
dv
dt
dt
v
v
=
=
−
−
⌠
⌠
⌠


⌡
⌡
⌡
∫
 
 
 
1
( )
40tanh( /10)
tanh ( / 40)
/10
;
0;
v t
t
v
t
C
C
−
=
=
+
=
 
 
Answer: 
v(10)  ≈ 30.46  ft/sec,       v(∞)  =  40 ft/sec 
 
20. 
Equation: 
2
32
(1/800)
,
(0)
160
(0)
0
,
v
v
v
y
′ = −
−
=
=
 
 
Solution: 
2
2
(1/160)
1
;
;
32
(1/800)
1
( /160)
5
dv
dv
dt
dt
v
v
= −
= −
+
+
⌠
⌠
⌠


⌡
⌡
⌡
∫
 

100 
Chapter 2 
 
1
tan ( /160)
/5
;
(0)
160 implies
/ 4
v
t
C
v
C
π
−
= −
+
=
=
 
 
( )
160tan
4
5
t
v t
π


=
−




 
 
( )
800 ln cos
400ln2
4
5
t
y t
π




=
−
+








 
 
 
 
We solve  v(t)  =  0  for  t = 3.92699  and then calculate  y(3.92699)  =  277.26 ft. 
 
21. 
Equation: 
2
0
,
(0)
,
(0)
0
g
v
v
v
v
y
ρ
′ = −
−
=
=
 
 
Solution: 
(
)
2
2
/
;
;
1
/
g dv
dv
dt
g
dt
g
v
g v
ρ
ρ
ρ
ρ
= −
= −
+
+
⌠
⌠



⌡
⌡
∫
∫
 
 
 
(
)
(
)
1
1
0
0
tan
/
;
(0)
implies
tan
/
g v
g
t
C
v
v
C
g v
ρ
ρ
ρ
−
−
= −
+
=
=
 
 
 
 
1
0
( )
tan
tan
g
v t
t
g
v
g
ρ
ρ
ρ
−




= −
−










 
 
We solve  v(t)  =  0  for  
1
0
1
tan
t
v
g
g
ρ
ρ
−

=




  and substitute in Eq. (17) for  y(t): 
 
 
 
(
)
(
)
(
)
(
)
1
1
0
0
max
1
0
2
1
0
0
2
0
max
cos tan
/
tan
/
1 ln
cos tan
/
1
1
ln sec tan
/
ln
1
1 ln 1
2
v
g
v
g
y
v
g
v
v
g
g
v
y
g
ρ
ρ
ρ
ρ
ρ
ρ
ρ
ρ
ρ
ρ
−
−
−
−
−
=
=
=
+


=
+




 
 
22. 
By an integration similar to the one in Problem 19, the solution of the initial value problem  
2
32
0.075
,
(0)
0
v
v
v
′ = −
+
=
  is 
 
 
 
 
 
( )
20.666tanh(1.54919 )
v t
t
= −
, 
 
 
so the terminal speed is 20.666 ft/sec.  Then a further integration with  y(0) = 0  gives 
 
 
 
 
( )
10000
13.333 ln(cosh(1.54919 ))
y t
t
=
−
. 
 
 
We solve  y(0) = 0  for  t = 484.57.  Thus the descent takes about 8 min 5 sec. 

 
Section 2.3 
101 
 
23. 
Before opening parachute: 
 
 
 
2
32
0.00075
,
(0)
0,
(0)
10000
( )
206.559tanh(0.154919 )
(30)
206.521 ft/sec
( )
10000
1333.33 ln(cosh(0.154919 )),
(30)
4727.30 ft
v
v
v
y
v t
t
v
y t
t
y
′ = −
+
=
=
= −
= −
=
−
=
 
 
 
After opening parachute: 
 
 
 
2
32
0.075
,
(0)
206.521,
(0)
4727.30
( )
20.6559tanh(1.54919
0.00519595)
( )
4727.30
13.3333ln(cosh(1.54919
0.00519595))
0 when
229.304
v
v
v
y
v t
t
y t
t
y
t
′ = −
+
= −
=
= −
+
=
−
+
=
=
 
 
 
Thus she opens her parachute after 30 sec at a height of 4727 feet, and the total  
 
time of descent is  30 + 229.304 = 259.304 sec,  about 4 minutes and 19.3 seconds.   
 
24. 
Let  M  denote the mass of the Earth.  Then 
 
(a) 
2
/
GM R
c
=
  implies  R  =  0.884×10−3 meters, about  0.88 cm; 
 
(b) 
)
(329320
2
/
G
M
R
c
=
implies  R  =  2.91×103 meters, about  2.91  kilometers.   
 
 
25. 
(a) 
The rocket's apex occurs when  
0.
v =
  We get the desired formula when we set   
 
 
v = 0  in Eq. (23), 
 
 
 
 
 
2
2
0
1
1
2
,
v
v
GM
r
R


=
+
−




 
 
 
and solve for  r. 
 
(b) 
We substitute  
0
v =
,  
5
10
r
R
=
+
 (100 km = 
5
10  m) and the mks values  
 
 
11
6.6726 10
,
G
−
=
×
 
24
6
5.975 10 ,
6.378 10
M
R
=
×
=
×
 in Eq. (23) and solve for 
 
 
0
1389.21 m/s
1.389 km/s.
v =
≈
 
 
(c) 
When we substitute  
0
(9/10) 2
/
v
GM R
=
 in the formula derived in part (a), we 
 
find that  max
100
/19.
r
R
=
  
 
26. 
By an elementary computation (as in Section 1.2) we find that an initial velocity of  
0
16
v =
 
ft/sec is required to jump vertically 4 feet high on earth.  We must determine whether this 
initial velocity is adequate for escape from the asteroid.  Let  r  denote the ratio of the radius  
 
of the asteroid to the radius 
3960
R =
 miles of the earth, so that 
 
 
 
 
  
1.5
1
.
3960
2640
r =
=
 

102 
Chapter 2 
 
Then the mass and radius of the asteroid are given by 
 
 
 
 
3
and
a
a
M
r M
R
rR
=
=
 
 
in terms of the mass  M  and radius  R  of the earth.  Hence the escape velocity from the  
 
asteroid's surface is given by 
 
 
 
3
0
2
2
2
a
a
a
a
GM
G r M
GM
v
r
r v
R
rR
R
⋅
=
=
=
=
 
 
in terms of the escape velocity  
0v  from the earth's surface.  Hence  
36680/ 2640
av ≈
 
 
13.9
≈
 ft/sec.  Since the escape velocity from this asteroid is thus less than the initial 
velocity of 16 ft/sec that your legs can provide, you can indeed jump right off this asteroid 
into space. 
 
 
 
 
 
27. 
(a) 
Substitution of  
2
2
0
2
/
/
v
GM R
k
R
=
=
 in Eq. (23) of the textbook gives 
 
 
 
 
2
.
dr
GM
k
v
dt
r
r
=
=
=
 
 
We separate variables and proceed to integrate: 
 
 
 
 
3/ 2
3/ 2
2
2
3
3
r dr
k dt
r
kt
R
=
⇒
=
+
∫
∫
 
 
(using the fact that  
when
0
r
R
t
=
=
).  We solve for  
(
)
2/3
3/ 2
2
3
( )
r t
kt
R
=
+
  and note that 
 
( )
as
.
r t
t
→∞
→∞ 
 
(b) 
If  
0
2
/
v
GM R
>
 then Eq. (23) gives 
 
 
 
2
2
0
2
2
.
dr
GM
GM
k
k
v
v
dt
r
R
r
r
α


=
=
+
−
=
+
>




 
 
Therefore, at every instant in its ascent, the upward velocity of the projectile in this part is 
greater than the velocity at the same instant of the projectile of part (a).  It's as though the 
projectile of part (a) is the fox, and the projectile of this part is a rabbit that runs faster.  
Since the fox goes to infinity, so does the faster rabbit. 
 
28. 
(a) 
Integration of  gives 
 
 
 
 
      
 
2
0
1
1
1
2 v
GM
r
r


=
−




 
 
and we solve for 
 
 
 
 
       
0
1
1
2
dr
v
GM
dt
r
r


=
= −
−




 
 

 
Section 2.3 
103 
 
taking the negative square root because  v < 0  in descent.  Hence 
 
 
 
 
 
2
0
0
0
(
cos
)
2
r
r
t
dr
r
r
GM
r
r
θ
⌠

⌡
= −
=
−
 
 
 
 
 
2
0
0
/ 2
2 cos
r
GM
r
d
θ
θ
=
∫
 
 
 
 
 
3/ 2
0
(
sin
cos )
2
r
GM
θ
θ
θ
=
+
 
 
 
 
 
2
1
0
0
0
0
cos
2
r
r
t
rr
r
r
GM
r
−


=
−
+




 
 
(b) 
Substitution of  
11
24
6
6.6726 10
,
5.975 10
kg,
6.378 10 m
G
M
r
R
−
=
×
=
×
=
=
×
, 
 
and  
6
0
10
r
R
=
+
  yields  t = 510.504, that is, about 
1
2
8  minutes for the descent to the  
surface of the earth.  (Recall that we are ignoring air resistance.) 
 
(c) 
Substitution of the same numeral values along with  
0
0
v =
 in the original  
 
differential equation of part (a) yields  
4116.42 m/s
4.116 km/s
v = −
≈−
 for the velocity at 
 
impact with the earth's surface where  
.
r
R
=
 
 
29. 
Integration of  
0
2 ,
(0)
0,
(0)
(
)
dv
GM
v
y
v
v
dy
y
R
= −
=
=
+
  gives 
 
 
 
 
 
2
2
0
1
1
2
2
GM
GM
v
v
y
R
R
=
−
+
+
 
 
 
which simplifies to the desired formula for  v2.  Then substitution of 
 
11
6.6726 10
,
G
−
=
×
 
24
6
5.975 10
kg,
6.378 10 m
M
R
=
×
=
×
  v = 0, and  v0 = 1 
 
yields an equation that we easily solve for  y = 51427.3, that is, about  51.427 km. 
 
 
30. 
When we integrate  
 
 
 
 
0
2
2 ,
(0)
,
(0)
(
)
e
m
dv
GM
GM
v
r
R
r
v
dr
r
S
r
′
= −
+
=
=
−
 
 
 
in the usual way and solve for  v,  we get 
 
 
 
 
2
0
2
2
2
2
.
e
e
m
m
GM
GM
GM
GM
v
v
r
R
r
S
R
S
=
−
−
+
+
−
−
 
 
 
The earth and moon attractions balance at the point where the right-hand side in the  
 
acceleration equation vanishes, which is when 

104 
Chapter 2 
 
 
 
 
 
 
.
e
e
m
M S
r
M
M
=
−
 
If we substitute this value of  r,  
22
6
7.35 10
kg,
384.4 10
m
M
S
=
×
=
×
, and the usual values 
of the other constants involved, then set  v = 0 (to just reach the balancing point), we can 
solve the resulting equation for  v0 = 11,109 m/s.   Note that this is only 71 m/s less  
than the earth escape velocity of 11,180 m/s, so the moon really doesn't help much. 
 
 
SECTION 2.4 
 
NUMERICAL APPROXIMATION:  EULER'S METHOD 
 
In each of Problems 1–10 we also give first the explicit form of Euler's iterative formula for the 
given differential equation  
( , )
y
f x y
′ =
.  As we illustrate in Problem 1, the desired iterations are 
readily implemented, either manually or with a computer system or graphing calculator.  Then we 
list the indicated values of  
1
2( )
y
 rounded off accurate  to 3 decimal places. 
 
1. 
For the differential equation  
( , )
y
f x y
′ =
 with  
( , )
,
f x y
y
= −
 the iterative formula of 
Euler's method is  yn+1 =  yn + h(−yn).  The TI-83 screen on the left  shows  a graphing 
calculator implementation of this iterative formula.   
 
 
 
 
After the variables  are initialized (in the first line), and the formula is entered, each press of 
the enter key carries out an additional step.  The screen on the right shows the results of 5 
steps from  x = 0  to  x = 0.5  with step size  h = 0.1 — winding up with  (0.5)
1.181.
y
≈
  
 
 
Approximate values 1.125 and 1.181;  true value 
1
2( )
y
≈1.213 
 
 
The following Mathematica instructions produce precisely this line of data. 
 
 
 
f[x_,y_] = -y;
g[x_] = 2 Exp[-x];

 
Section 2.4 
105 
h = 0.25;
x = 0;
y1 = y0;
Do[
k = f[x,y1];
(* the left-hand slope
*)
y1 = y1 + h*k;
(* Euler step to update y
*)
x = x + h,
(* update x
*)
{i,1,2} ]
h = 0.1;
x = 0;
y2 = y0;
Do[
k = f[x,y2];
(* the left-hand slope
*)
y2 = y2 + h*k;
(* Euler step to update y
*)
x = x + h,
(* update x
*)
{i,1,5} ]
Print[x,"
",y1,"
",y2,"
",g[0.5]]     
0.5
1.125
1.18098
1.21306
 
2. 
Iterative formula: 
yn+1 =  yn + h(2yn) 
             Approximate values 1.125 and 1.244;  true value 
1
2( )
y
≈1.359 
 
3. 
Iterative formula:   
yn+1 =  yn + h(yn + 1) 
 
Approximate values 2.125 and 2.221;  true value 
1
2( )
y
≈2.297 
 
4. 
Iterative formula:   
yn+1 = yn + h(xn − yn) 
 
Approximate values 0.625 and 0.681;  true value 
1
2( )
y
≈0.713 
 
5. 
Iterative formula:   
yn+1 =  yn + h(yn − xn − 1) 
 
Approximate values 0.938 and 0.889;  true value 
1
2( )
y
≈0.851 
 
6. 
Iterative formula:   
yn+1 =  yn + h(−2xnyn) 
 
Approximate values 1.750 and 1.627;  true value 
1
2( )
y
≈1.558 
 
7. 
Iterative formula:   
yn+1 =  yn + h(−3xn
2yn) 
 
Approximate values 2.859 and 2.737;  true value 
1
2( )
y
≈2.647 
 
8. 
Iterative formula:   
yn+1 =  yn + h exp(−yn) 
 
Approximate values 0.445 and 0.420;  true value 
1
2( )
y
≈0.405 
 
9. 
Iterative formula:   
yn+1 =  yn + h(1 + yn
2)/4 
 
Approximate values 1.267 and 1.278;  true value 
1
2( )
y
≈1.287 

106 
Chapter 2 
  
10. 
Iterative formula:   
yn+1 =  yn + h(2xnyn
2) 
 
Approximate values 1.125 and 1.231;  true value 
1
2( )
y
≈1.333 
              
 
The tables of approximate and actual values called for in Problems 11–16 were produced using the 
following MATLAB script (appropriately altered for each problem). 
 
% Section 2.4, Problems 11-16
x0 = 0;
y0 = 1;
% first run:
h = 0.01;
x = x0;
y = y0;
y1 = y0;
for
n = 1:100
y = y + h*(y-2);
y1 = [y1,y];
x = x + h;
end
% second run:
h = 0.005;
x = x0;
y = y0;
y2 = y0;
for
n = 1:200
y = y + h*(y-2);
y2 = [y2,y];
x = x + h;
end
% exact values
x = x0 : 0.2 : x0+1;
ye = 2 - exp(x);
% display table
ya = y2(1:40:201);
err = 100*(ye-ya)./ye;
[x; y1(1:20:101); ya; ye; err]
11.  
The iterative formula of Euler's method is   yn+1 =  yn + h(yn − 2),  and the exact solution is  
y(x)  =  2 − ex.  The resulting table of approximate and actual values is 
 
x 
0.0 
0.2 
0.4 
0.6 
0.8 
1.0 
y ( h=0.01) 
1.0000 
0.7798 
0.5111 
0.1833 
–0.2167 
–0.7048 
y  (h=0.005) 
1.0000 
0.7792 
0.5097 
0.1806 
–0.2211 
–0.7115 
y actual 
1.0000 
0.7786 
0.5082 
0.1779 
–0.2255 
–0.7183 
error 
0% 
–0.08% 
–0.29% 
–1.53% 
1.97% 
0.94% 
                             
12. 
Iterative formula:   
yn+1  =  yn + h(yn − 1)2/2 
 
Exact solution:   
y(x)  =  1 + 2/(2 − x) 
 

 
Section 2.4 
107 
x 
0.0 
0.2 
0.4 
0.6 
0.8 
1.0 
y ( h=0.01) 
2.0000 
2.1105 
2.2483 
2.4250 
2.6597 
2.9864 
y  (h=0.005) 
2.0000 
2.1108 
2.2491 
2.4268 
2.6597 
2.9931 
y actual 
2.0000 
2.1111 
2.2500 
2.4286 
2.6597 
3.0000 
error 
0% 
0.02% 
0.04% 
0.07% 
0.13% 
0.23% 
                            
13. 
Iterative formula:   
yn+1  =  yn + 2hxn
3/yn 
 
Exact solution:   
y(x)  =  (8 + x4)1/2 
 
x 
1.0 
1.2 
1.4 
1.6 
1.8 
2.0 
y ( h=0.01) 
3.0000 
3.1718 
3.4368 
3.8084 
4.2924 
4.8890 
y  (h=0.005) 
3.0000 
3.1729 
3.4390 
3.8117 
4.2967 
4.8940 
y actual 
3.0000 
3.1739 
3.4412 
3.8149 
4.3009 
4.8990 
error 
0% 
0.03% 
0.06% 
0.09% 
0.10% 
0.10% 
                            
14. 
Iterative formula:   
yn+1  =  yn + hyn
2/xn 
 
Exact solution:   
y(x)  =  1/(1 − ln x) 
 
x 
1.0 
1.2 
1.4 
1.6 
1.8 
2.0 
y ( h=0.01) 
1.0000 
1.2215 
1.5026 
1.8761 
2.4020 
3.2031 
y  (h=0.005) 
1.0000 
1.2222 
1.5048 
1.8814 
2.4138 
3.2304 
y actual 
1.0000 
1.2230 
1.5071 
1.8868 
2.4259 
3.2589 
error 
0% 
0.06% 
0.15% 
0.29% 
0.50% 
0.87% 
 
15. 
Iterative formula:   
yn+1  =  yn + h(3 − 2yn/xn) 
 
Exact solution:   
y(x)  =  x + 4/x2 
 
x 
2.0 
2.2 
2.4 
2.6 
2.8 
3.0 
y ( h=0.01) 
3.0000 
3.0253 
3.0927 
3.1897 
3.3080 
3.4422 
y  (h=0.005) 
3.0000 
3.0259 
3.0936 
3.1907 
3.3091 
3.4433 
y actual 
3.0000 
3.0264 
3.0944 
3.1917 
3.3102 
3.4444 
error 
0% 
0.019% 
0.028% 
0.032% 
0.033% 
0.032% 
 
16. 
Iterative formula:   
yn+1  =  yn + 2hxn
5/yn
2 
 
Exact solution:   
y(x)  =  (x6 − 37)1/3 
 
x 
2.0 
2.2 
2.4 
2.6 
2.8 
3.0 
y ( h=0.01) 
3.0000 
4.2476 
5.3650 
6.4805 
7.6343 
8.8440 
y  (h=0.005) 
3.0000 
4.2452 
5.3631 
6.4795 
7.6341 
8.8445 
y actual 
3.0000 
4.2429 
5.3613 
6.4786 
7.6340 
8.8451 
error 
0% 
–0.056% 
–0.034% 
–0.015% 
0.002% 
0.006% 
 

108 
Chapter 2 
The tables of approximate values called for in Problems 17–24 were produced using a MATLAB 
script similar to the one listed preceding the Problem 11 solution above. 
 
17. 
 
x 
0.0 
0.2 
0.4 
0.6 
0.8 
1.0 
y ( h=0.1) 
0.0000 
0.0010 
0.0140 
0.0551 
0.1413 
0.2925 
y  (h=0.02) 
0.0000 
0.0023 
0.0198 
0.0688 
0.1672 
0.3379 
y  (h=0.004) 
0.0000 
0.0026 
0.0210 
0.0717 
0.1727 
0.3477 
y  (h=0.0008) 
0.0000 
0.0027 
0.0213 
0.0723 
0.1738 
0.3497 
 
 
These data indicate that  y(1)  ≈  0.35,  in contrast with Example 5 in the text, where the 
initial condition is  y(0)  =  1. 
 
In Problems 18−24 we give only the final approximate values of  y  obtained using Euler's method 
with step sizes  h  =  0.1,  h  =  0.02,  h  =  0.004, and  h  =  0.0008. 
 
18. 
With  x0  =  0  and  y0  =  1,  the approximate values of  y(2)  obtained are: 
 
  
 
h    
0.1         
0.02    
0.004      
0.0008 
 
 
y   
1.6680   
1.6771   
1.6790   
1.6794 
 
19. 
With  x0  =  0  and  y0  =  1,  the approximate values of  y(2)  obtained are: 
 
 
 
h      
0.1      
0.02  
 
0.004    
0.0008 
 
 
y      
6.1831   
6.3653   
6.4022   
6.4096 
 
20. 
With  x0  =  0  and  y0  =  −1,  the approximate values of  y(2)  obtained are: 
 
 
 
h  
0.1   
 
0.02  
 
0.004   
0.0008 
 
 
y  
−1.3792 
 −1.2843  
−1.2649  
−1.2610   
 
21. 
With  x0  =  1  and  y0  =  2,  the approximate values of  y(2)  obtained are: 
 
 
 
h  
0.1    
 
0.02    
0.004         
0.0008 
 
 
y  
2.8508   
2.8681   
2.8716    
2.8723  
 
22. 
With  x0  =  0  and  y0  =  1,  the approximate values of  y(2)  obtained are: 
 
 
 
h   
0.1    
 
0.02      
0.004   
0.0008 
 
 
y 
6.9879   
7.2601   
7.3154   
7.3264 
 
23. 
With  x0  =  0  and  y0  =  0,  the approximate values of  y(1)  obtained are: 
 
 
 
h    
0.1         
0.02  
 
0.004     
0.0008 
 
 
y    
1.2262   
1.2300   
1.2306   
1.2307 
 

 
Section 2.4 
109 
24. 
With  x0  =  −1  and  y0  =  1,  the approximate values of  y(1)  obtained are: 
 
 
 
h  
0.1    
 
0.02       
0.004     
0.0008 
 
 
y  
0.9585     
0.9918  
0.9984   
0.9997 
 
25. 
Here  
( , )
32
1.6
f t v
v
=
−
  and  0
0
0,
0.
t
v
=
=
   
 
With  
0.01,
h =
 100 iterations of  
1
( ,
)
n
n
n
n
v
v
h f t v
+ =
+
 yield  (1)
16.014,
v
≈
 and 200 
 
iterations with 
0.005
h =
 yield  (1)
15.998.
v
≈
 Thus we observe an approximate velocity of  
 
16.0 ft/sec after 1 second — 80% of the limiting velocity of 20 ft/sec. 
 
With  
0.01,
h =
 200 iterations yield  (2)
19.2056,
v
≈
 and 400 iterations with 
0.005
h =
 
 
yield  (2)
19.1952.
v
≈
 Thus we observe an approximate velocity of 19.2 ft/sec after 2 
 
seconds — 96% of the limiting velocity of 20 ft/sec. 
 
26. 
Here  
2
( , )
0.0225
0.003
f t P
P
P
=
−
  and  0
0
0,
25.
t
P
=
=
   
 
With  
1,
h =
 60 iterations of  
1
( ,
)
n
n
n
n
P
P
h f t P
+ =
+
 yield  
(60)
49.3888,
P
≈
 and 120 
 
iterations with 
0.5
h =
 yield  
(60)
49.3903.
P
≈
 Thus we observe a population of 49 deer  
 
after 5 years — 65% of the limiting population of 75 deer. 
 
With  
1,
h =
 120 iterations yield  
(120)
66.1803,
P
≈
 and 240 iterations with 
0.5
h =
 yield  
 
(60)
66.1469.
P
≈
 Thus we observe a population of 66 deer after 10 years — 88% of the 
 
limiting population of 75 deer. 
 
27. 
Here  
2
2
( , )
1
f x y
x
y
=
+
−  and  
0
0
0,
0.
x
y
=
=
  The following table gives the 
 
approximate values for the successive step sizes  h  and corresponding numbers  n  of steps.  
 
It appears likely that (2)
1.00
y
=
 rounded off accurate to 2 decimal places. 
 
h 
0.1 
0.01 
0.001 
0.0001 
0.00001 
n 
20 
200 
2000 
20000 
200000 
y(2) 
0.7772 
0.9777 
1.0017 
1.0042 
1.0044 
 
28. 
Here  
2
1
2
( , )
f x y
x
y
=
+
  and  
0
0
2,
0.
x
y
= −
=
  The following table gives the 
 
approximate values for the successive step sizes  h  and corresponding numbers  n  of steps.  
 
It appears likely that (2)
1.46
y
=
 rounded off accurate to 2 decimal places. 
 
h 
0.1 
0.01 
0.001 
0.0001 
0.00001 
n 
40 
400 
4000 
40000 
400000 
y(2) 
1.2900 
1.4435 
1.4613 
1.4631 
1.4633 
 
 

110 
Chapter 2 
29. 
With step sizes  h  =  0.15,  h  =  0.03,  and  h  =  0.006  we get the following results: 
 
 
 
 
 
y with  
y with  
y with 
 
 
   x 
 
h=0.15  
h=0.03  
h=0.006 
 
 
     
−1.0 
 
1.0000  
1.0000  
1.0000 
 
 
 −0.7  
1.0472  
1.0512   
1.0521 
 
 
 −0.4  
1.1213  
1.1358  
1.1390 
 
 
 −0.1  
1.2826  
1.3612  
1.3835 
 
 
+0.2 
 
0.8900  
1.4711  
0.8210 
 
 
+0.5 
 
0.7460  
1.2808  
0.7192 
  
 
While the values for  h  =  0.15  alone are not conclusive, a comparison of the values of  y  
for all three step sizes with  x > 0  suggests some anomaly in the transition from negative to 
positive values of  x. 
 
30. 
With step sizes  h  =  0.1  and  h  =  0.01  we get the following results: 
 
   
 
 
 
y  with   
y  with 
   
 
 x   
 
h = 0.1  
h = 0.01 
 
  
 
0.0 
 
0.0000   
0.0000   
 
  
0.1 
 
0.0000   
0.0003   
 
 
0.2  
 
0.0010   
0.0025   
 
 
0.3 
 
0.0050   
0.0086 
 
 
  ⋅     
 
     ⋅     
     ⋅ 
 
 
 
  ⋅     
 
     ⋅     
     ⋅ 
 
 
 
  ⋅     
 
     ⋅     
     ⋅ 
 
 
 
1.8 
 
2.8200   
4.3308 
 
 
1.9 
 
3.9393   
7.9425   
 
 
2.0  
 
5.8521  
28.3926   
 
 
Clearly there is some difficulty near  x  =  2. 
 
31. 
With step sizes  h  =  0.1  and  h  =  0.01  we get the following results: 
 
 
 
 
 
y  with  
y  with 
 
 
  x  
 
h = 0.1  
h = 0.01 
 
 
 
0.0 
 
1.0000  
1.0000   
 
 
0.1 
 
1.2000  
1.2200   
 
 
0.2 
 
1.4428  
1.4967   
 
 
  ⋅     
 
     ⋅     
     ⋅ 
 
 
 
  ⋅     
 
     ⋅     
     ⋅ 
 
 
 
  ⋅     
 
     ⋅     
     ⋅ 
 
 
 
0.7 
 
4.3460   
6.4643 

 
Section 2.4 
111 
 
 
0.8 
 
5.8670  
11.8425   
 
 
0.9 
 
8.3349  
39.5010   
 
 
Clearly there is some difficulty near  x  =  0.9. 
 
 
 
SECTION 2.5 
 
A CLOSER LOOK AT THE EULER METHOD 
 
In each of Problems 1–10 we give first the predictor formula for  un+1  and then the improved Euler 
corrector for  yn+1.  These predictor-corrector iterations are readily implemented, either manually or 
with a computer system or graphing calculator (as we illustrate in Problem 1).  We give in each 
problem a table showing the approximate values obtained, as well as the corresponding values of 
the exact solution. 
 
 
1. 
un+1  =  yn + h(–yn) 
 
yn+1  =  yn + (h/2)[−yn − un+1] 
 
 
The TI-83 screen on the left above shows a graphing calculator implementation of this 
iteration.  After the variables are initialized (in the first line), and the formulas are entered, 
each press of the enter key carries out an additional step.  The screen on the right shows the 
results of 5 steps from  x = 0  to  x = 0.5  with step size  h = 0.1 — winding up with  
(0.5)
1.2142
y
≈
 — and we see the approximate values shown in the second row of the 
table below.   
 
x 
0.0 
0.1 
0.2 
0.3 
0.4 
0.5 
y with h=0.1 
2.0000 
1.8100 
1.6381 
1.4824 
1.3416 
1.2142 
y actual 
2.0000 
1.8097 
1.6375 
1.4816 
1.3406 
1.2131 
 
 

112 
Chapter 2 
 
2. 
un+1  =  yn + 2hyn 
 
yn+1  =  yn + (h/2)[2yn + 2un+1] 
 
 
x 
0.0 
0.1 
0.2 
0.3 
0.4 
0.5 
y with h=0.1 
0.5000 
0.6100 
0.7422 
0.9079 
1.1077 
1.3514 
y actual 
0.5000 
0.6107 
0.7459 
0.9111 
1.1128 
1.3591 
              
3. 
un+1  =  yn + h(yn + 1) 
 
yn+1  =  yn + (h/2)[(yn + 1) + (un+1 + 1)]  
 
x 
0.0 
0.1 
0.2 
0.3 
0.4 
0.5 
y with h=0.1 
1.0000 
1.2100 
1.4421 
1.6985 
1.9818 
2.2949 
y actual 
1.0000 
1.2103 
1.4428 
1.6997 
1.9837 
2.2974 
              
4. 
un+1  =  yn + h(xn − yn) 
 
yn+1  =  yn + (h/2)[(xn − yn) + (xn + h − un+1)] 
 
x 
0.0 
0.1 
0.2 
0.3 
0.4 
0.5 
y with h=0.1 
1.0000 
0.9100 
0.8381 
0.7824 
0.7416 
0.7142 
y actual 
1.0000 
0.9097 
0.8375 
0.7816 
0.7406 
0.7131 
            
5. 
un+1  =  yn + h(yn − xn − 1) 
 
yn+1  =  yn + (h/2)[(yn − xn − 1) + (un+1 − xn − h − 1)] 
 
 
 
x 
0.0 
0.1 
0.2 
0.3 
0.4 
0.5 
y with h=0.1 
1.0000 
0.9950 
0.9790 
0.9508 
0.9091 
0.8526 
y actual 
1.0000 
0.9948 
0.9786 
0.9501 
0.9082 
0.8513 
 
6. 
un+1  =  yn − 2xnynh 
 
yn+1  =  yn − (h/2)[2xnyn + 2(xn + h)un+1] 
 
 
x 
0.0 
0.1 
0.2 
0.3 
0.4 
0.5 
y with h=0.1 
2.0000 
1.9800 
1.9214 
1.8276 
1.7041 
1.5575 
y actual 
2.0000 
1.9801 
1.9216 
1.8279 
1.7043 
1.5576 
 
7. 
un+1  =  yn − 3xn
2yn h 
 
yn+1  =  yn − (h/2)[3xn
2yn + 3(xn + h)2un+1] 

 
Section 2.5 
113 
 
x 
0.0 
0.1 
0.2 
0.3 
0.4 
0.5 
y with h=0.1 
3.0000 
2.9955 
2.9731 
2.9156 
2.8082 
2.6405 
y actual 
3.0000 
2.9970 
2.9761 
2.9201 
2.8140 
2.6475 
 
8. 
un+1  =  yn + h exp(−yn) 
 
yn+1  =  yn + (h/2)[exp(−yn) + exp(−un+1)] 
 
x 
0.0 
0.1 
0.2 
0.3 
0.4 
0.5 
y with h=0.1 
0.0000 
0.0952 
0.1822 
0.2622 
0.3363 
0.4053 
y actual 
0.0000 
0.0953 
0.1823 
0.2624 
0.3365 
0.4055 
 
9. 
un+1  =  yn + h(1 + yn
2)/4 
 
yn+1  =  yn + h[1 + yn
2 + 1 + (un+1)2]/8 
 
x 
0.0 
0.1 
0.2 
0.3 
0.4 
0.5 
y with h=0.1 
1.0000 
1.0513 
1.1053 
1.1625 
1.2230 
1.2873 
y actual 
1.0000 
1.0513 
1.1054 
1.1625 
1.2231 
1.2874 
 
10. 
un+1  =  yn + 2xnyn
2 h 
 
yn+1  =  yn + h[xnyn
2 + (xn + h)(un+1)2] 
 
 
x 
0.0 
0.1 
0.2 
0.3 
0.4 
0.5 
y with h=0.1 
1.0000 
1.0100 
1.0414 
1.0984 
1.1895 
1.3309 
y actual 
1.0000 
1.0101 
1.0417 
1.0989 
1.1905 
1.3333 
 
 
The results given below for Problems 11–16 were computed using the following MATLAB script. 
 
% Section 2.5, Problems 11-16
x0 = 0;
y0 = 1;
% first run:
h = 0.01;
x = x0;
y = y0;
y1 = y0;
for
n = 1:100
u = y + h*f(x,y);
%predictor
y = y + (h/2)*(f(x,y)+f(x+h,u));
%corrector
y1 = [y1,y];
x = x + h;
end
% second run:
h = 0.005;
x = x0;
y = y0;
y2 = y0;

114 
Chapter 2 
for
n = 1:200
u = y + h*f(x,y);
%predictor
y = y + (h/2)*(f(x,y)+f(x+h,u));
%corrector
y2 = [y2,y];
x = x + h;
end
% exact values
x = x0 : 0.2 : x0+1;
ye = g(x);
% display table
ya = y2(1:40:201);
err = 100*(ye-ya)./ye;
x = sprintf('%10.5f',x), sprintf('\n');
y1 = sprintf('%10.5f',y1(1:20:101)), sprintf('\n');
ya = sprintf('%10.5f',ya), sprintf('\n');
ye = sprintf('%10.5f',ye), sprintf('\n');
err = sprintf('%10.5f',err), sprintf('\n');
table = [x; y1; ya; ye; err]
 
 
For each problem the differential equation  
( , )
y
f x y
′ =
  and the known exact solution  
( )
y
g x
=
 
are stored in the files  f.m  and  g.m — for instance, the files 
 
function
yp = f(x,y)
yp = y-2;
 
function ye = g(x,y)
ye = 2-exp(x);
 
for Problem 11.  (The exact solutions for Problems 11–16 here are given in the solutions for 
Problems 11–16 in Section 2.4.) 
 
11.  
x 
0.0 
0.2 
0.4 
0.6 
0.8 
1.0 
y ( h=0.01) 
1.00000 
0.77860 
0.50819 
0.17790 
–0.22551 
–0.71824 
y  (h=0.005) 
1.00000 
0.77860 
0.50818 
0.17789 
–0.22553 
–0.71827 
y actual 
1.00000 
0.77860 
0.50818 
0.17788 
–0.22554 
–0.71828 
error 
0.000% 
–0.000% 
–0.001% 
–0.003% 
0.003% 
0.002% 
                             
12.  
x 
0.0 
0.2 
0.4 
0.6 
0.8 
1.0 
y ( h=0.01) 
2.00000 
2.11111 
2.25000 
2.42856 
2.66664 
2.99995 
y  (h=0.005) 
2.00000 
2.11111 
2.25000 
2.42857 
2.66666 
2.99999 
y actual 
2.00000 
2.11111 
2.25000 
2.42857 
2.66667 
3.00000 
error 
0.0000% 
0.0000% 
0.0001% 
0.0001% 
0.0002% 
0.0004% 
 

 
Section 2.5 
115 
13.  
x 
1.0 
1.2 
1.4 
1.6 
1.8 
2.0 
y ( h=0.01) 
3.00000 
3.17390 
3.44118 
3.81494 
4.30091 
4.89901 
y  (h=0.005) 
3.00000 
3.17390 
3.44117 
3.81492 
4.30089 
4.89899 
y actual 
3.00000 
3.17389 
3.44116 
3.81492 
4.30088 
4.89898 
error 
0.0000% 
–0.0001%
–0.0001%
0.0001% 
–0.0002% –0.0002%
 
14.  
x 
1.0 
1.2 
1.4 
1.6 
1.8 
2.0 
y ( h=0.01) 
1.00000 
1.22296 
1.50707 
1.88673 
2.42576 
3.25847 
y  (h=0.005) 
1.00000 
1.22297 
1.50709 
1.88679 
2.42589 
3.25878 
y actual 
1.00000 
1.22297 
1.50710 
1.88681 
2.42593 
3.25889 
error 
0.0000% 
0.0002% 
0.0005% 
0.0010% 
0.0018% 
0.0033% 
 
15.  
x 
2.0 
2.2 
2.4 
2.6 
2.8 
3.0 
y ( h=0.01) 
3.000000 
3.026448 
3.094447 
3.191719 
3.310207 
3.444448 
y  (h=0.005) 
3.000000 
3.026447 
3.094445 
3.191717 
3.310205 
3.444445 
y actual 
3.000000 
3.026446 
3.094444 
3.191716 
3.310204 
3.444444 
error 
0.00000% 
–0.00002% 
–0.00002% 
–0.00002% 
–0.00002% 
–0.00002% 
 
16.  
x 
2.0 
2.2 
2.4 
2.6 
2.8 
3.0 
y ( h=0.01) 
3.000000 
4.242859 
5.361304 
6.478567 
7.633999 
8.845112 
y  (h=0.005) 
3.000000 
4.242867 
5.361303 
6.478558 
7.633984 
8.845092 
y actual 
3.000000 
4.242870 
5.361303 
6.478555 
7.633979 
8.845085 
error 
0.00000% 
0.00006% 
–0.00001% 
–0.00005% 
–0.00007% 
–0.00007% 
 
17. 
With  h  =     0.1:   
y(1)  ≈  0.35183 
 
With  h  =    0.02:   
y(1)  ≈  0.35030 
 
With  h  =   0.004:   
y(1)  ≈  0.35023 
 
With  h  =  0.0008:   
y(1)  ≈  0.35023 
 
      
The table of numerical results is 
 
 
 
 
y  with  
y  with   
y  with  
y  with 
 
 x    
 
h = 0.1  
h = 0.02  
h = 0.004 
h = 0.0008 
 
 
0.0 
 
0.00000 
0.00000  
0.00000  
0.00000 
 
0.2 
 
0.00300   
0.00268 
0.00267  
0.00267 
 
0.4  
 
0.02202   
0.02139  
0.02136  
0.02136 
 
0.6 
 
0.07344  
0.07249   
0.07245  
0.07245 
 
0.8  
 
0.17540  
0.17413  
0.17408  
0.17408 
 
1.0 
 
0.35183  
0.35030  
0.35023  
0.35023 
 

116 
Chapter 2 
In Problems 18−24 we give only the final approximate values of  y  obtained using the improved 
Euler method with step sizes  h  =  0.1,  h  =  0.02,  h  =  0.004, and  h  =  0.0008. 
 
18. 
With  h  =     0.1:   
y(2)  ≈  1.68043 
 
With  h  =    0.02:   
y(2)  ≈  1.67949 
 
With  h  =   0.004:   
y(2)  ≈  1.67946 
 
With  h  =  0.0008:   
y(2)  ≈  1.67946 
 
19. 
With  h  =     0.1:   
y(2)  ≈  6.40834 
 
With  h  =    0.02:   
y(2)  ≈  6.41134 
 
With  h  =   0.004:   
y(2)  ≈  6.41147 
 
With  h  =  0.0008:   
y(2)  ≈  6.41147 
 
20. 
With  h  =     0.1:   
y(2)  ≈  −1.26092 
 
With  h  =    0.02:   
y(2)  ≈  −1.26003 
 
With  h  =   0.004:   
y(2)  ≈  −1.25999 
 
With  h  =  0.0008:   
y(2)  ≈  −1.25999 
 
21. 
With  h  =     0.1:   
y(2)  ≈  2.87204 
 
With  h  =    0.02:   
y(2)  ≈  2.87245 
 
With  h  =   0.004:   
y(2)  ≈  2.87247 
 
With  h  =  0.0008:   
y(2)  ≈  2.87247 
 
22. 
With  h  =     0.1:   
y(2)  ≈  7.31578 
 
With  h  =    0.02:   
y(2)  ≈  7.32841 
 
With  h  =   0.004:   
y(2)  ≈  7.32916 
 
With  h  =  0.0008:   
y(2)  ≈  7.32920 
 
23. 
With  h  =     0.1:   
y(1)  ≈  1.22967 
 
With  h  =    0.02:   
y(1)  ≈  1.23069 
 
With  h  =   0.004:   
y(1)  ≈  1.23073 
 
With  h  =  0.0008:   
y(1)  ≈  1.23073 
 
24. 
With  h  =     0.1:   
y(1)  ≈  1.00006 
 
With  h  =    0.02:   
y(1)  ≈  1.00000 
 
With  h  =   0.004:   
y(1)  ≈  1.00000 
 
With  h  =  0.0008:   
y(1)  ≈  1.00000 
 
25. 
Here  
( , )
32
1.6
f t v
v
=
−
  and  0
0
0,
0.
t
v
=
=
   
 
With  
0.01,
h =
 100 iterations of   
 
 
1
2
1
1
1
2
( ,
),
(
,
),
(
)
2
n
n
n
n
h
k
f t v
k
f t
h v
hk
v
v
k
k
+
=
=
+
+
=
+
+
 

 
Section 2.5 
117 
 
yield  (1)
15.9618,
v
≈
 and 200 iterations with 
0.005
h =
 yield  (1)
15.9620.
v
≈
 Thus we 
 
observe an approximate velocity of 15.962 ft/sec after 1 second — 80% of the limiting  
 
velocity of 20 ft/sec. 
 
With  
0.01,
h =
 200 iterations yield  (2)
19.1846,
v
≈
 and 400 iterations with 
0.005
h =
 
 
yield  (2)
19.1847.
v
≈
 Thus we observe an approximate velocity of 19.185 ft/sec after 2 
 
seconds — 96% of the limiting velocity of 20 ft/sec. 
 
26. 
Here  
2
( , )
0.0225
0.003
f t P
P
P
=
−
  and  0
0
0,
25.
t
P
=
=
   
 
With  
1,
h =
 60 iterations of   
 
 
1
2
1
1
1
2
( ,
),
(
,
),
(
)
2
n
n
n
n
h
k
f t P
k
f t
h P
hk
P
P
k
k
+
=
=
+
+
=
+
+
 
 
yield  
(60)
49.3909,
P
≈
 and 120 iterations with 
0.5
h =
 yield  
(60)
49.3913.
P
≈
 Thus we  
 
observe an approximate population of 49.391 deer after 5 years — 65% of the limiting  
 
population of 75 deer. 
 
With  
1,
h =
 120 iterations yield  
(120)
66.1129,
P
≈
 and 240 iterations with 
0.5
h =
 yield  
 
(60)
66.1134.
P
≈
 Thus we observe an approximate population of 66.113 deer after 10 
 
years — 88% of the  limiting population of 75 deer. 
 
27. 
Here  
2
2
( , )
1
f x y
x
y
=
+
−  and  
0
0
0,
0.
x
y
=
=
  The following table gives the 
 
approximate values for the successive step sizes  h  and corresponding numbers  n  of steps.  
 
It appears likely that (2)
1.0045
y
=
 rounded off accurate to 4 decimal places. 
 
h 
0.1 
0.01 
0.001 
0.0001 
n 
20 
200 
2000 
20000 
y(2) 
1.01087 
1.00452 
1.00445 
1.00445 
 
28. 
Here  
2
1
2
( , )
f x y
x
y
=
+
  and  
0
0
2,
0.
x
y
= −
=
  The following table gives the 
 
approximate values for the successive step sizes  h  and corresponding numbers  n  of steps.  
 
It appears likely that (2)
1.4633
y
=
 rounded off accurate to 4 decimal places. 
 
h 
0.1 
0.01 
0.001 
0.0001 
n 
40 
400 
4000 
40000 
y(2) 
1.46620 
1.46335 
1.46332 
1.46331 
 
 
 
In the solutions for Problems 29 and 30 we illustrate the following general MATLAB ode solver. 
 
function
[t,y] = ode(method, yp, t0,b, y0, n)
%
[t,y] = ode(method, yp, t0,b, y0, n)
%
calls the method described by 'method' for the

118 
Chapter 2 
%
ODE 'yp' with function header
%
%
y' = yp(t,y)
%
%
on the interval
[t0,b]
with initial (column)
%
vector
y0.
Choices for method are 'euler',
%
'impeuler', 'rk' (Runge-Kutta), 'ode23', 'ode45'.
%
Results are saved at the endPoints of n subintervals,
%
that is, in steps of length
h = (b - t0)/n.
The
%
result
t
is an (n+1)-column vector from b to t1,
%
while
y
is a matrix with
n+1
rows (one for each
%
t-value) and one column for each dependent variable.
h = (b - t0)/n;
% step size
t = t0 : h : b;
t = t';
% col. vector of t-values
y = y0';
% 1st row of result matrix
for
i = 2 : n+1
% for i=2 to i=n+1
t0 = t(i-1);
% old t
t1 = t(i);
% new t
y0 = y(i-1,:)';
% old y-row-vector
[T,Y] = feval(method, yp, t0,t1, y0);
y = [y;Y'];
% adjoin new y-row-vector
end
To use the improved Euler method, we call as 'method' the following function. 
 
function [t,y] = impeuler(yp, t0,t1, y0)
%
%
[t,y] = impeuler(yp, t0,t1, y0)
%
Takes one improved Euler step for
%
%
y' = yprime( t,y ),
%
%
from t0
to
t1
with initial value
the
%
column vector
y0.
h = t1 - t0;
k1 = feval( yp, t0, y0
);
k2 = feval( yp, t1, y0 + h*k1 );
k
= (k1 + k2)/2;
t = t1;
y = y0 + h*k;
 
29. 
Here our differential equation is described by the MATLAB function 
 
function
vp = vpbolt1(t,v)
vp = -0.04*v - 9.8;
 
 
Then the commands 
 

 
Section 2.5 
119 
n = 50;
[t1,v1] = ode('impeuler','vpbolt1',0,10,49,n);
n = 100;
[t2,v2] = ode('impeuler','vpbolt1',0,10,49,n);
t = (0:10)';
ve = 294*exp(-t/25)-245;
[t, v1(1:5:51), v2(1:10:101), ve]
 
 
generate the table 
 
 
 
t 
 
with n = 50 
with n = 100 
  actual v 
0
49.0000
49.0000
49.0000
1
37.4722
37.4721
37.4721
2
26.3964
26.3963
26.3962
3
15.7549
15.7547
15.7546
4
5.5307
5.5304
5.5303
5
-4.2926
-4.2930
-4.2932
6
-13.7308
-13.7313
-13.7314
7
-22.7989
-22.7994
-22.7996
8
-31.5115
-31.5120
-31.5122
9
-39.8824
-39.8830
-39.8832
10
-47.9251
-47.9257
-47.9259
 
 
We notice first that the final two columns agree to 3 decimal places (each difference being  
 
than 0.0005).  Scanning the  n = 100 column for sign changes, we suspect that  v = 0  (at the  
bolt's apex) occurs just after  t = 4.5 sec.  Then interpolation between  t = 4.5  and  t = 4.6  
in the table 
 
[t2(40:51),v2(40:51)]
3.9000
6.5345
4.0000
5.5304
4.1000
4.5303
4.2000
3.5341
4.3000
2.5420
4.4000
1.5538
4.5000
0.5696
4.6000
-0.4108
4.7000
-1.3872
4.8000
-2.3597
4.9000
-3.3283
5.0000
-4.2930
 
 
indicates that  t = 4.56  at the bolt's apex.  Finally, interpolation in 
 
[t2(95:96),v2(95:96)]
9.4000
-43.1387
9.5000
-43.9445

120 
Chapter 2 
 
 
 
gives the impact velocity  v(9.41)  ≈  -43.22 m/s. 
 
30. 
Now our differential equation is described by the MATLAB function 
 
function
vp = vpbolt2(t,v)
vp = -0.0011*v.*abs(v) - 9.8;
 
 
Then the commands 
 
n = 100;
[t1,v1] = ode('impeuler','vpbolt2',0,10,49,n);
n = 200;
[t2,v2] = ode('impeuler','vpbolt2',0,10,49,n);
t = (0:10)';
[t, v1(1:10:101), v2(1:20:201)]
 
 
generate the table 
 
 
 
t 
with n = 100 
 
with n = 200 
 
  
0
49.0000
49.0000
1
37.1547
37.1547
2
26.2428
26.2429
3.
15.9453
15.9455
4
6.0041
6.0044
5
-3.8020
-3.8016
6
-13.5105
-13.5102
7
-22.9356
-22.9355
8
-31.8984
-31.8985
9
-40.2557
-40.2559
10
-47.9066
-47.9070
 
 
We notice first that the final two columns agree to 2 decimal places (each difference being  
less than 0.005).  Scanning the  n = 200 column for sign changes, we suspect that  v = 0  (at 
the bolt's apex) occurs just after  t = 4.6 sec.  Then interpolation between  t = 4.60 and   
t = 4.65 in the table 
 
[t2(91:101),v2(91:101)]
4.5000
1.0964
4.5500
0.6063
4.6000
0.1163
4.6500
-0.3737
4.7000
-0.8636
4.7500
-1.3536
4.8000
-1.8434
4.8500
-2.3332
4.9000
-2.8228

 
Section 2.5 
121 
4.9500
-3.3123
5.0000
-3.8016
 
 
indicates that  t = 4.61  at the bolt's apex.  Finally, interpolation in 
 
[t2(189:190),v2(189:190)]
9.4000
-43.4052
9.4500
-43.7907
 
 
 
gives the impact velocity  v(9.41)  ≈  −43.48 m/s. 
 
 
 
SECTION 2.6 
 
THE RUNGE-KUTTA METHOD 
 
Each problem can be solved with a "template" of computations like those listed in Problem 1.  We 
include a table showing the slope values  
1
2
3
4
,
,
,
k
k
k
k  and the xy-values at the ends of two 
successive steps of size  h = 0.25. 
 
1. 
To make the first step of size  h = 0.25  we start with the function defined by 
 
 
f[x_, y_] := -y 
 
and the initial values 
 
 
x = 0;
y = 2;
h = 0.25; 
 
and then perform the calculations  
 
k1 = f[x, y]
k2 = f[x + h/2, y + h*k1/2]
k3 = f[x + h/2, y + h*k2/2]
k4 = f[x + h, y + h*k3]
y
= y + h/6*(k1 + 2*k2 + 2*k3 + k4)
x
= x + h
in turn.  Here we are using Mathematica notation that translates transparently to standard 
mathematical notation describing the corresponding manual computations.  A repetition 
of this same block of calculations carries out a second step of size  h = 0.25.  The 
following table lists the intermediate and final results obtained in these two steps. 
 
k1 
k2 
k3 
k4 
x 
Approx. y 
Actual y 
–2 
–1/75 
–1.78125 
–1.55469 
0.25 
1.55762 
1.55760 
–1.55762 
–1.36292 
–1.38725 
–1.2108 
0.5 
1.21309 
1.21306 
 
 

122 
Chapter 2 
2. 
 
k1 
k2 
k3 
k4 
x 
Approx. y 
Actual y 
1 
1.25 
1.3125 
1.65625 
0.25 
0.82422 
0.82436 
1.64844 
2.06055 
2.16357 
2.73022 
0.5 
1.35867 
1.35914 
 
3. 
 
k1 
k2 
k3 
k4 
x 
Approx. y 
Actual y 
2 
2.25 
2.28125 
2.57031 
0.25 
1.56803 
1.56805 
2.56803 
2.88904 
2.92916 
3.30032 
0.5 
2.29740 
2.29744 
4. 
k1 
k2 
k3 
k4 
x 
Approx. y 
Actual y 
–1 
–0.75 
–0.78128 
–55469 
0.25 
0.80762 
0.80760 
–0.55762 
–0.36292 
–0.38725 
–0.21080 
0.5 
0.71309 
0.71306 
 
5. 
 
k1 
k2 
k3 
k4 
x 
Approx. y 
Actual y 
0 
–0.125 
–0.14063 
–0.28516 
0.25 
0.96598 
0.96597 
–28402 
–0.44452 
–0.46458 
–0.65016 
0.5 
0.85130 
0.85128 
      
6. 
 
k1 
k2 
k3 
k4 
x 
Approx. y 
Actual y 
0 
–0.5 
–0.48438 
–0.93945 
0.25 
1.87882 
1.87883 
–0.93941 
–1.32105 
–1.28527 
–1.55751 
0.5 
1.55759 
1.55760 
 
7. 
 
k1 
k2 
k3 
k4 
x 
Approx. y 
Actual y 
0 
–0.14063 
–0.13980 
–0.55595 
0.25 
2.95347 
2.95349 
–0.55378 
–1.21679 
–1.18183 
–1.99351 
0.5 
2.6475 
2.64749 
 
8. 
 
k1 
k2 
k3 
k4 
x 
Approx. y 
Actual y 
1 
0.88250 
0.89556 
0.79940 
0.25 
0.22315 
0.22314 
0.80000 
0.72387 
0.73079 
0.66641 
0.5 
0.40547 
0.40547 
 
9. 
 
k1 
k2 
k3 
k4 
x 
Approx. y 
Actual y 
0.5 
0.53223 
0.53437 
0.57126 
0.25 
1.13352 
1.13352 
0.57122 
0.61296 
0.61611 
0.66444 
0.5 
1.28743 
1.28743 
 
10. 
 
k1 
k2 
k3 
k4 
x 
Approx. y 
Actual y 
0 
0.25 
0.26587 
0.56868 
0.25 
1.06668 
1.06667 
0.56891 
0.97094 
1.05860 
1.77245 
0.5 
1.33337 
1.33333 
 
 

 
Section 2.6 
123 
The results given below for Problems 11–16 were computed using the following MATLAB script. 
 
% Section 2.6, Problems 11-16
x0 = 0;
y0 = 1;
% first run:
h = 0.2;
x = x0;
y = y0;
y1 = y0;
for
n = 1:5
k1 = f(x,y);
k2 = f(x+h/2,y+h*k1/2);
k3 = f(x+h/2,y+h*k2/2);
k4 = f(x+h,y+h*k3);
y = y +(h/6)*(k1+2*k2+2*k3+k4);
y1 = [y1,y];
x = x + h;
end
% second run:
h = 0.1;
x = x0;
y = y0;
y2 = y0;
for
n = 1:10
k1 = f(x,y);
k2 = f(x+h/2,y+h*k1/2);
k3 = f(x+h/2,y+h*k2/2);
k4 = f(x+h,y+h*k3);
y = y +(h/6)*(k1+2*k2+2*k3+k4);
y2 = [y2,y];
x = x + h;
end
% exact values
x = x0 : 0.2 : x0+1;
ye = g(x);
% display table
y2 = y2(1:2:11);
err = 100*(ye-y2)./ye;
x = sprintf('%10.6f',x), sprintf('\n');
y1 = sprintf('%10.6f',y1), sprintf('\n');
y2 = sprintf('%10.6f',y2), sprintf('\n');
ye = sprintf('%10.6f',ye), sprintf('\n');
err = sprintf('%10.6f',err), sprintf('\n');
table = [x;y1;y2;ye;err]
 
For each problem the differential equation  
( , )
y
f x y
′ =
  and the known exact solution  
( )
y
g x
=
 
are stored in the files  f.m  and  g.m — for instance, the files 
 
function
yp = f(x,y)
yp = y-2;
 

124 
Chapter 2 
and 
function ye = g(x,y)
ye = 2-exp(x);
 
for Problem 11.   
 
11.  
x 
0.0 
0.2 
0.4 
0.6 
0.8 
1.0 
y ( h=0.2) 
1.000000 
0.778600 
0.508182 
0.177894 
–0.225521 
–0.718251 
y  (h=0.1) 
1.000000 
0.778597 
0.508176 
0.177882 
–0.225540 
–0.718280 
y actual 
1.000000 
0.778597 
0.508175 
0.177881 
–0.225541 
–0.718282 
error 
0.00000% 
–0.00002% 
–0.00009% 
–0.00047% 
–0.00061% 
–0.00029% 
 
12.  
x 
0.0 
0.2 
0.4 
0.6 
0.8 
1.0 
y ( h=0.2) 
2.000000 
2.111110 
2.249998 
2.428566 
2.666653 
2.999963 
y  (h=0.1) 
2.000000 
2.111111 
2.250000 
2.428571 
2.666666 
2.999998 
y actual 
2.000000 
2.111111 
2.250000 
2.428571 
2.666667 
3.000000 
error 
0.000000% 
0.000002% 
0.000006% 
0.000014% 
0.000032% 
0.000080% 
 
13.  
x 
1.0 
1.2 
1.4 
1.6 
1.8 
2.0 
y ( h=0.2) 
3.000000 
3.173896 
3.441170 
3.814932 
4.300904 
4.899004 
y  (h=0.1) 
3.000000 
3.173894 
3.441163 
3.814919 
4.300885 
4.898981 
y actual 
3.000000 
3.173894 
3.441163 
3.814918 
4.300884 
4.898979 
error 
0.00000% 
–0.00001% 
–0.00001% 
–0.00002% 
–0.00003% 
–0.00003% 
 
14.  
x 
1.0 
1.2 
1.4 
1.6 
1.8 
2.0 
y ( h=0.2) 
1.000000 
1.222957 
1.507040 
1.886667 
2.425586 
3.257946 
y  (h=0.1) 
1.000000 
1.222973 
1.507092 
1.886795 
2.425903 
3.258821 
y actual 
1.000000 
1.222975 
1.507096 
1.886805 
2.425928 
3.258891 
error 
0.0000% 
0.0001% 
0.0003% 
0.0005% 
0.0010% 
0.0021% 
 
15.  
x 
2.0 
2.2 
2.4 
2.6 
2.9 
3.0 
y ( h=0.2) 
3.000000 
3.026448 
3.094447 
3.191719 
3.310207 
3.444447 
y  (h=0.1) 
3.000000 
3.026446 
3.094445 
3.191716 
3.310204 
3.444445 
y actual 
3.000000 
3.026446 
3.094444 
3.191716 
3.310204 
3.444444 
error 
0.000000% 
–0.000004% 
–0.000005% 
–0.000005% 
–0.000005% 
–0.000004% 
 
 
 

 
Section 2.6 
125 
16.  
x 
2.0 
2.2 
2.4 
2.6 
2.9 
3.0 
y ( h=0.2) 
3.000000 
4.243067 
5.361409 
6.478634 
7.634049 
8.845150 
y  (h=0.1) 
3.000000 
4.242879 
5.361308 
6.478559 
7.633983 
8.845089 
y actual 
3.000000 
4.242870 
5.361303 
6.478555 
7.633979 
8.845085 
error 
0.000000% 
–0.000221% 
–0.000094% 
–0.000061% 
–0.000047% 
–0.000039% 
 
17. 
With  h  =    0.2: 
y(1)  ≈  0.350258 
 
With  h  =    0.1:   
y(1)  ≈  0.350234 
 
With  h  =   0.05:  
y(1)  ≈  0.350232 
 
With  h  =  0.025:   
y(1)  ≈  0.350232 
 
 
 
The table of numerical results is 
 
 
 
    
y with        
y with        
y with        
y with 
 
 
x       
h = 0.2       
h = 0.1       
h = 0.05      
h = 0.025 
         
 
 
0.0  
0.000000  
0.000000  
0.000000  
0.000000 
 
 
0.2     0.002667      
0.002667      
0.002667      
0.002667 
 
 
0.4     0.021360      
0.021359      
0.021359      
0.021359 
 
 
0.6     0.072451      
0.072448      
0.072448      
0.072448 
 
 
0.8     0.174090      
0.174081      
0.174080      
0.174080 
 
 
1.0     0.350258      
0.350234      
0.350232      
0.350232 
 
 
In Problems 18−24 we give only the final approximate values of  y  obtained using the Runge-Kutta  
method with step sizes  h  =  0.2,  h  =  0.1,  h  =  0.05, and  h  =  0.025. 
 
18. 
With  h  =    0.2:   
y(2)  ≈  1.679513 
 
With  h  =    0.1:   
y(2)  ≈  1.679461 
 
With  h  =   0.05:   
y(2)  ≈  1.679459 
 
With  h  =  0.025:   
y(2)  ≈  1.679459 
 
19. 
With  h  =    0.2:   
y(2)  ≈  6.411464 
 
With  h  =    0.1:   
y(2)  ≈  6.411474 
 
With  h  =   0.05:   
y(2)  ≈  6.411474 
 
With  h  =  0.025:   
y(2)  ≈  6.411474 
 
20. 
With  h  =    0.2:   
y(2)  ≈  −1.259990 
 
With  h  =    0.1:   
y(2)  ≈  −1.259992 
 
With  h  =   0.05:   
y(2)  ≈  −1.259993 
 
With  h  =  0.025:   
y(2)  ≈  −1.259993 
 
21. 
With  h  =    0.2:   
y(2)  ≈  2.872467 
 
With  h  =    0.1:   
y(2)  ≈  2.872468 

126 
Chapter 2 
 
With  h  =   0.05:   
y(2)  ≈  2.872468 
 
With  h  =  0.025:   
y(2)  ≈  2.872468 
 
22. 
With  h  =    0.2:   
y(2)  ≈  7.326761 
 
With  h  =    0.1:   
y(2)  ≈  7.328452 
 
With  h  =   0.05:   
y(2)  ≈  7.328971 
 
With  h  =  0.025:   
y(2)  ≈  7.329134 
 
23. 
With  h  =    0.2:   
y(1)  ≈  1.230735 
 
With  h  =    0.1:   
y(1)  ≈  1.230731 
 
With  h  =   0.05:   
y(1)  ≈  1.230731 
 
With  h  =  0.025:   
y(1)  ≈  1.230731 
 
24. 
With  h  =    0.2:   
y(1)  ≈  1.000000 
 
With  h  =    0.1:   
y(1)  ≈  1.000000 
 
With  h  =   0.05:   
y(1)  ≈  1.000000 
 
With  h  =  0.025:   
y(1)  ≈  1.000000 
 
25. 
Here  
( , )
32
1.6
f t v
v
=
−
  and  0
0
0,
0.
t
v
=
=
   
 
With  
0.1,
h =
 10 iterations of  
 
 
1
1
1
2
1
2
2
1
1
3
2
4
3
2
2
1
1
2
3
4
1
6
( ,
),
(
,
),
(
,
),
(
,
),
(
2
2
),
n
n
n
n
n
n
n
n
n
n
k
f t v
k
f t
h v
hk
k
f t
h v
hk
k
f t
h v
hk
k
k
k
k
k
v
v
hk
+
=
=
+
+
=
+
+
=
+
+
=
+
+
+
=
+
 
 
 
yield  (1)
15.9620,
v
≈
 and 20 iterations with 
0.05
h =
 yield  (1)
15.9621.
v
≈
 Thus we 
 
observe an approximate velocity of 15.962 ft/sec after 1 second — 80% of the limiting  
 
velocity of 20 ft/sec. 
 
With  
0.1,
h =
 20 iterations yield  (2)
19.1847,
v
≈
 and 40 iterations with 
0.05
h =
  yield  
 
(2)
19.1848.
v
≈
 Thus we observe an approximate velocity of 19.185 ft/sec after 2 
 
seconds — 96% of the limiting velocity of 20 ft/sec. 
 
26. 
Here  
2
( , )
0.0225
0.003
f t P
P
P
=
−
  and  0
0
0,
25.
t
P
=
=
   
 
With  
6,
h =
 10 iterations of   
 
 
1
1
1
2
1
2
2
1
1
3
2
4
3
2
2
1
1
2
3
4
1
6
( ,
),
(
,
),
(
,
),
(
,
),
(
2
2
),
n
n
n
n
n
n
n
n
n
n
k
f t P
k
f t
h P
hk
k
f t
h v
hk
k
f t
h P
hk
k
k
k
k
k
P
P
hk
+
=
=
+
+
=
+
+
=
+
+
=
+
+
+
=
+
 
 
yield  
(60)
49.3915,
P
≈
 as do 20 iterations with 
3.
h =
 Thus we observe an approximate 
  
population of 49.3915 deer after 5 years — 65% of the limiting population of 75 deer. 

 
Section 2.6 
127 
 
With  
6,
h =
 20 iterations yield  
(120)
66.1136,
P
≈
 as do 40 iterations with 
3.
h =
 Thus we 
 
observe an approximate population of 66.1136 deer after 10 years — 88% of the limiting 
 
population of 75 deer. 
 
 
27. 
Here  
2
2
( , )
1
f x y
x
y
=
+
−  and  
0
0
0,
0.
x
y
=
=
  The following table gives the 
 
approximate values for the successive step sizes  h  and corresponding numbers  n  of steps.  
 
It appears likely that (2)
1.00445
y
=
 rounded off accurate to 5 decimal places. 
 
h 
1 
0.1 
0.01 
0.001 
n 
2 
20 
200 
2000 
y(2) 
1.05722 
1.00447 
1.00445 
1.00445 
 
 
28. 
Here  
2
1
2
( , )
f x y
x
y
=
+
  and  
0
0
2,
0.
x
y
= −
=
  The following table gives the 
 
approximate values for the successive step sizes  h  and corresponding numbers  n  of steps.  
 
It appears likely that (2)
1.46331
y
=
 rounded off accurate to 5 decimal places. 
 
h 
1 
0.1 
0.01 
0.001 
n 
4 
40 
00 
40000 
y(2) 
1.48990 
1.46332 
1.46331 
1.46331 
 
 
In the solutions for Problems 29 and 30 we use the general MATLAB solver ode that was listed 
prior to the Problem 29 solution in Section 2.5.  To use the Runge-Kutta method, we call as 
'method' the following function. 
 
function [t,y] = rk(yp, t0,t1, y0)
%
[t, y] = rk(yp, t0, t1, y0)
%
Takes one Runge-Kutta step for
%
%
y' = yp( t,y ),
%
%
from t0
to
t1
with initial value
the
%
column vector
y0.
h = t1 - t0;
k1 = feval(yp, t0
, y0
);
k2 = feval(yp, t0 + h/2, y0 + (h/2)*k1 );
k3 = feval(yp, t0 + h/2, y0 + (h/2)*k2 );
k4 = feval(yp, t0 + h
,y0 +
h *k3 );
k
= (1/6)*(k1 + 2*k2 + 2*k3 + k4);
t = t1;
y = y0 + h*k; 
 
 

128 
Chapter 2 
29. 
Here our differential equation is described by the MATLAB function 
 
function
vp = vpbolt1(t,v)
vp = -0.04*v - 9.8;
 
 
Then the commands 
 
n = 100;
[t1,v1] = ode('rk','vpbolt1',0,10,49,n);
n = 200;
[t2,v] = ode('rk','vpbolt1',0,10,49,n);
t = (0:10)';
ve = 294*exp(-t/25)-245;
[t, v1(1:n/20:1+n/2), v(1:n/10:n+1), ve]
 
 
generate the table 
 
 
 
t 
with n = 100 
with n = 200 
  actual v 
0
49.0000
49.0000
49.0000
1
37.4721
37.4721
37.4721
2
26.3962
26.3962
26.3962
3
15.7546
15.7546
15.7546
4
5.5303
5.5303
5.5303
5
-4.2932
-4.2932
-4.2932
6
-13.7314
-13.7314
-13.7314
7
-22.7996
-22.7996
-22.7996
8
-31.5122
-31.5122
-31.5122
9
-39.8832
-39.8832
-39.8832
10
-47.9259
-47.9259
-47.9259
 
We notice first that the final three columns agree to the 4 displayed decimal places.  
Scanning the last column for sign changes in  v, we suspect that  v = 0  (at the bolt's apex) 
occurs just after  t = 4.5 sec.  Then interpolation between  t = 4.55  and  t = 4.60  in the table 
 
[t2(91:95),v(91:95)]
4.5000
0.5694
4.5500
0.0788
4.6000
-0.4109
4.6500
-0.8996
4.7000
-1.3873 
 
 
 
indicates that  t = 4.56  at the bolt's apex.  Now the commands 
 
y = zeros(n+1,1);
h = 10/n;

 
Section 2.6 
129 
for j = 2:n+1
y(j) = y(j-1) + v(j-1)*h +
0.5*(-.04*v(j-1) - 9.8)*h^2;
end
ye = 7350*(1 - exp(-t/25)) - 245*t;
[t, y(1:n/10:n+1), ye]
 
 
generate the table 
 
 
 
t 
Approx  y 
Actual  y 
 
       
 
0
0
0
1
43.1974
43.1976
2
75.0945
75.0949
3
96.1342
96.1348
4
106.7424
106.7432
5
107.3281
107.3290
6
98.2842
98.2852
7
79.9883
79.9895
8
52.8032
52.8046
9
17.0775
17.0790
10
-26.8540
-26.8523
 
We see at least 2-decimal place agreement between approximate and actual values of  y.  
Finally, interpolation between  t = 9  and  t = 10  here suggests that  y = 0  just after  t = 9.4. 
Then interpolation between  t = 9.40  and  t = 9.45  in  the table 
 
[t2(187:191),y(187:191)]
9.3000
4.7448
9.3500
2.6182
9.4000
0.4713
9.4500
-1.6957
9.5000
-3.8829
indicates that the bolt is aloft for about 9.41 seconds. 
 
 
30. 
Now our differential equation is described by the MATLAB function 
 
function
vp = vpbolt2(t,v)
vp = -0.0011*v.*abs(v) - 9.8;
 
 
Then the commands 
 
n = 200;
[t1,v1] = ode('rk','vpbolt2',0,10,49,n);
n = 2*n;
[t2,v] = ode('rk','vpbolt2',0,10,49,n);

130 
Chapter 2 
t = (0:10)';
ve = zeros(size(t));
ve(1:5)= 94.388*tan(0.478837 - 0.103827*t(1:5));
ve(6:11)= -94.388*tanh(0.103827*(t(6:11)-4.6119));
[t, v1(1:n/20:1+n/2), v(1:n/10:n+1), ve]
 
 
generate the table 
 
 
 
t 
with n = 200 
with n = 400 
  actual v 
0
49.0000
49.0000
49.0000
1
37.1548
37.1548
37.1547
2
26.2430
26.2430
26.2429
3
15.9456
15.9456
15.9455
4
6.0046
6.0046
6.0045
5
-3.8015
-3.8015
-3.8013
6
13.5101
-13.5101
-13.5100
7
-22.9354
-22.9354
-22.9353
8
-31.8985
-31.8985
-31.8984
9
-40.2559
-40.2559
-40.2559
10
-47.9071
-47.9071
-47.9071
 
We notice first that the final three columns almost agree to the 4 displayed decimal places.  
Scanning the last colmun for sign changes in  v, we suspect that  v = 0  (at the bolt's apex) 
occurs just after  t = 4.6 sec.  Then interpolation between  t = 4.600  and  t = 4.625  in the 
table 
 
[t2(185:189),v(185:189)]
4.6000
0.1165
4.6250
-0.1285
4.6500
-0.3735
4.6750
-0.6185
4.7000
-0.8635 
 
 
 
indicates that  t = 4.61  at the bolt's apex.  Now the commands 
 
y = zeros(n+1,1);
h = 10/n;
for j = 2:n+1
y(j) = y(j-1) + v(j-1)*h + 0.5*(-.04*v(j-1) - 9.8)*h^2;
end
ye = zeros(size(t));
ye(1:5)= 108.465+909.091*log(cos(0.478837 -
0.103827*t(1:5)));
ye(6:11)= 108.465-909.091*log(cosh(0.103827
*(t(6:11)-4.6119)));
[t, y(1:n/10:n+1), ye]
 

 
Section 2.6 
131 
 
generate the table 
 
 
 
t 
Approx  y 
Actual  y 
 
       
 
0
0
0.0001
1
42.9881
42.9841
2
74.6217
74.6197
3
95.6719
95.6742
4
106.6232
106.6292
5
107.7206
107.7272
6
99.0526
99.0560
7
80.8027
80.8018
8
53.3439
53.3398
9
17.2113
17.2072
10
-26.9369
-26.9363
 
We see almost 2-decimal place agreement between approximate and actual values of  y.  
Finally, interpolation between  t = 9  and  t = 10  here suggests that  y = 0  just after  t = 9.4. 
Then interpolation between  t = 9.400  and  t = 9.425  in  the table 
 
[t2(377:381),y(377:381)]
9.4000
0.4740
9.4250
-0.6137
9.4500
-1.7062
9.4750
-2.8035
9.5000
-3.9055
indicates that the bolt is aloft for about 9.41 seconds. 
 

132 
Chapter 3 
CHAPTER 3 
  
LINEAR SYSTEMS AND MATRICES  
 
 
SECTION 3.1 
 
INTRODUCTION TO LINEAR SYSTEMS 
 
This initial section takes account of the fact that some students remember only hazily the method of 
elimination for 2 2
× and 3 3
×  systems.  Moreover, high school algebra courses generally 
emphasize only the case in which a unique solution exists.  Here we treat on an equal footing the 
other two cases — in which either no solution exists or infinitely many solutions exist.   
 
1. 
Subtraction of twice the first equation from the second equation gives  5
10,
y
−
= −
 so 
 
y = 2,  and it follows that  x = 3. 
 
2. 
Subtraction of three times the second equation from the first equation gives  5
15,
y = −
 so 
 
y = –3,  and it follows that  x = 5. 
 
3. 
Subtraction of  3/2  times the first equation from the second equation gives  1
3 ,
2
2
y =
 so 
 
y = 3,  and it follows that  x = –4. 
 
4. 
Subtraction of  6/5  times the first equation from the second equation gives  11
44 ,
5
5
y =
 
so  y = 4, and it follows that  x = 5. 
 
5. 
Subtraction of twice the first equation from the second equation gives  0
1,
=
 so no 
solution exists. 
 
6. 
Subtraction of  3/2  times the first equation from the second equation gives  0
1,
=
 so no 
solution exists. 
 
7. 
The second equation is  –2 times the first equation, so we can choose  y = t  arbitrarily.  
The first equation then gives  
10
4 .
x
t
= −
+
 
 
8. 
The second equation is  2/3  times the first equation, so we can choose  y = t  arbitrarily.  
The first equation then gives  
4
2 .
x
t
=
+
 
 
9. 
Subtraction of twice the first equation from the second equation gives  9
4
3.
y
z
−
−
= −
  
Subtraction of the first equation from the third equation gives  2
1.
y
z
+
=
  Solution of 

 
Section 3.1 
133 
these latter two equations gives  
1,
3.
y
z
= −
=
  Finally substitution in the first equation 
gives  x = 4. 
 
10. 
Subtraction of twice the first equation from the second equation gives  
3
5.
y
z
+
= −
  
Subtraction of twice the first equation from the third equation gives  
2
3.
y
z
−−
=
  
Solution of these latter two equations gives  
1,
2.
y
z
=
= −
  Finally substitution in the 
first equation gives  x = 3. 
 
11. 
First we interchange the first and second equations.  Then subtraction of twice the new 
first equation from the new second equation gives  
7,
y
z
−
=
  and subtraction of three 
times the new first equation from the third equation gives  2
3
18.
y
z
−
+
= −
  Solution of 
these latter two equations gives  
3,
4.
y
z
=
= −
  Finally substitution in the (new) first 
equation gives  x = 1. 
 
12. 
First we interchange the first and third equations.  Then subtraction of twice the new first 
equation from the second equation gives  7
3
36,
y
z
−
−
= −
  and subtraction of twice the 
new first equation from the new third equation gives  16
7
83.
y
z
−
−
= −
  Solution of these 
latter two equations gives  
3,
5.
y
z
=
=
  Finally substitution in the (new) first equation 
gives  x = 1. 
 
13. 
First we subtract the second equation from the first equation to get the new first equation 
2
3
0.
x
y
z
+
+
=
  Then subtraction of twice the new first equation from the second 
equation gives  3
2
0,
y
z
−
=
  and subtraction of twice the new first equation from the 
third equation gives  2
0.
y
z
−
=
  Solution of these latter two equations gives  
0,
0.
y
z
=
=
  Finally substitution in the (new) first equation gives  x = 0  also. 
 
14. 
First we subtract the second equation from the first equation to get the new first equation 
8
4
45.
x
y
z
+
−
=
  Then subtraction of twice the new first equation from the second 
equation gives  23
28
181,
y
z
−
+
= −
  and subtraction of twice the new first equation from 
the third equation gives  9
11
71.
y
z
−
+
= −
  Solution of these latter two equations gives  
3,
4.
y
z
=
= −
  Finally substitution in the (new) first equation gives  x = 5. 
 
15. 
Subtraction of the first equation from the second equation gives  4
2.
y
z
−
+
= −
  
Subtraction of three times the first equation from the third equation gives (after division 
by 2)  4
5/ 2.
y
z
−
+
= −
  These latter two equations obviously are inconsistent, so the 
original system has no solution. 
 
16. 
Subtraction of the first equation from the second equation gives  7
3
2.
y
z
−
= −
  
Subtraction of three times the first equation from the third equation gives (after division 
by 3)  7
3
10 /3.
y
z
−
= −
  These latter two equations obviously are inconsistent, so the 
original system has no solution. 
 

134 
Chapter 3 
17. 
First we subtract the first equation from the second equation to get the new first equation 
3
6
4.
x
y
z
+
−
= −
  Then subtraction of three times the new first equation from the second 
equation gives  7
16
15,
y
z
−
+
=
  and subtraction of five times the new first equation from 
the third equation gives (after division by 2)  7
16
35/ 2.
y
z
−
+
=
  These latter two 
equations obviously are inconsistent, so the original system has no solution. 
 
18. 
Subtraction of the five times the first equation from the second equation gives  
23
40
14.
y
z
−
−
= −
  Subtraction of eight times the first equation from the third equation 
gives  23
40
19.
y
z
−
−
= −
  These latter two equations obviously are inconsistent, so the 
original system has no solution. 
 
19. 
Subtraction of twice the first equation from the second equation gives  3
6
9.
y
z
−
=
  
Subtraction of the first equation from the third equation gives  
2
3.
y
z
−
=
 Obviously 
these latter two equations are scalar multiples of each other, so we can choose  z = t  
arbitrarily.  It follows first that  
3
2
y
t
=
+
 and then that  
8
3 .
x
t
=
+
 
 
20. 
First we subtract the second equation from the first equation to get the new first equation 
6
5.
x
y
z
−
+
= −
  Then subtraction of the new first equation from the second equation 
gives  5
5
25,
y
z
−
=
  and subtraction of the new first equation from the third equation 
gives 3
3
15.
y
z
−
=
  Obviously these latter two equations are both scalar multiples of the 
equation  
5,
y
z
−
=
 so we can choose  z = t  arbitrarily.  It follows first that  
5
y
t
=
+  and 
then that  
5 .
x
t
= −
 
 
21. 
Subtraction of three times the first equation from the second equation gives  3
6
9.
y
z
−
=
  
Subtraction of four times the first equation from the third equation gives  3
9
6.
y
z
−
+
= −
 
Obviously these latter two equations are both scalar multiples of the equation  
3
2,
y
z
−
=
 
so we can choose  z = t  arbitrarily.  It follows first that  
2
3
y
t
=
+
 and then that  
3
2 .
x
t
=
−
 
 
22. 
Subtraction of four times the second equation from the first equation gives  2
10
0.
y
z
+
=
  
Subtraction of twice the second equation from the third equation gives  
5
0.
y
z
+
=
 
Obviously the first of these latter two equations is twice the second one, so we can 
choose  z = t  arbitrarily.  It follows first that  
5
y
t
= −
 and then that  
4 .
x
t
= −
 
 
23. 
The initial conditions  (0)
3 and
(0)
8
y
y′
=
=
 yield the equations  
3 and 2
8,
A
B
=
=
 so  
3 and
4.
A
B
=
=
  It follows that  ( )
3cos2
4sin 2 .
y x
x
x
=
+
 
 
24. 
The initial conditions  (0)
5 and
(0)
12
y
y′
=
=
 yield the equations  
5 and 3
12,
A
B
=
=
 
so  
5 and
4.
A
B
=
=
  It follows that  ( )
5cosh3
4sinh3 .
y x
x
x
=
+
 
 
25. 
The initial conditions  (0)
10 and
(0)
20
y
y′
=
=
 yield the equations  
10 and
A
B
+
=
 
5
5
20
A
B
−
=
  with  solution  
7,
3.
A
B
=
=
  Thus  
5
5
( )
7
3
.
x
x
y x
e
e−
=
+
 

 
Section 3.1 
135 
 
26. 
The initial conditions  (0)
44 and
(0)
22
y
y′
=
=
 yield the equations  
44 and
A
B
+
=
 
11
11
22
A
B
−
=
  with  solution  
23,
21.
A
B
=
=
  Thus  
11
11
( )
23
21
.
x
x
y x
e
e−
=
+
 
 
27. 
The initial conditions  (0)
40 and
(0)
16
y
y′
=
= −
 yield the equations  
40 and
A
B
+
=
 
3
5
16
A
B
−
= −
  with  solution  
23,
17.
A
B
=
=
  Thus  
3
5
( )
23
17
.
x
x
y x
e
e−
=
+
 
 
28. 
The initial conditions  (0)
15 and
(0)
13
y
y′
=
=
 yield the equations  
15 and
A
B
+
=
 
3
7
13
A
B
+
= −
  with  solution  
23,
8.
A
B
=
= −
  Thus  
3
7
( )
23
8
.
x
x
y x
e
e
=
−
 
 
29. 
The initial conditions  (0)
7 and
(0)
11
y
y′
=
=
 yield the equations  
7 and
A
B
+
=
 
1
1
2
3
11
A
B
+
=
  with  solution  
52,
45.
A
B
=
= −
  Thus  
/ 2
/3
( )
52
45
.
x
x
y x
e
e
=
−
 
 
30. 
The initial conditions  (0)
41 and
(0)
164
y
y′
=
=
 yield the equations  
41 and
A
B
+
=
 
4
7
164
3
5
A
B
−
=
  with  solution  
81,
40.
A
B
=
= −
  Thus  
4 /3
7 /5
( )
81
40
.
x
x
y x
e
e−
=
−
 
 
31. 
The graph of each of these linear equations in  x  and  y  is a straight line through the 
origin (0, 0) in the xy-plane.  If these two lines are distinct then they intersect only at the 
origin, so the two equations have the unique solution  
0.
x
y
=
=
  If the two lines 
coincide, then each of the infinitely many different points  ( , )
x y  on this common line 
provides a solution of the system. 
 
32. 
The graph of each of these linear equations in  x, y, and z  is a plane in xyz-space.  If these 
two planes are parallel — that is, do not intersect — then the equations have no solution.  
Otherwise, they intersect in a straight line, and each of the infinitely many different 
points  ( , , )
x y z  on this line provides a solution of the system. 
 
33. 
(a) 
The three lines have no common point of intersection, so the system has no  
solution. 
 
(b) 
The three lines have a single point of intersection, so the system has a unique   
solution. 
 
(c) 
The three lines — two of them parallel — have no common point of intersection,  
so the system has no solution. 
 
(d) 
The three distinct parallel lines have no common point of intersection, so the  
system has no solution. 
 
(e) 
Two of the lines coincide and intersect the third line in a single point, so the  
system has a unique solution. 
 
(f) 
The three lines coincide, and each of the infinitely many different points  ( , , )
x y z  
on this common line provides a solution of the system. 
 

136 
Chapter 3 
34. 
(a) 
If the three planes are parallel and distinct, then they have no common point of  
intersection, so the system has no solution. 
 
(b) 
If the three planes coincide, then each of the infinitely many different points   
( , , )
x y z  of this common plane provides a solution of the system. 
 
(c) 
If two of the planes coincide and are parallel to the third plane, then the three  
planes have no common point of intersection, so the system has no solution. 
 
(d) 
If two of the planes intersect in a line that is parallel to the third plane, then the  
three planes have no common point of intersection, so the system has no solution. 
 
(e) 
If two of the planes intersect in a line that lies in the third plane, then each of the  
infinitely many different points ( , , )
x y z  of this line provides a solution of the system. 
 
(f) 
If two of the planes intersect in a line that intersects the third plane in a single 
point, then this point ( , , )
x y z  provides the unique solution of the system. 
 
 
 
SECTION 3.2 
 
MATRICES AND GAUSSIAN ELIMINATION 
 
Because the linear systems in Problems 1–10 are already in echelon form, we need only start at the 
end of the list of unknowns and work backwards. 
 
1. 
Starting with  
3
2
x =
  from the third equation, the second equation gives  
2
0,
x =
 and then 
the first equation gives  
1
1.
x =
  
 
2. 
Starting with  
3
3
x = −  from the third equation, the second equation gives  
2
1,
x =
 and 
then the first equation gives  
1
5.
x =
  
 
3. 
If we set  
3x
t
=  then the second equation gives  
2
2
5 ,
x
t
=
+
 and next the first equation 
gives  
1
13 11 .
x
t
=
+
  
 
4. 
If we set  
3x
t
=  then the second equation gives  
2
5
7 ,
x
t
=
+
 and next the first equation 
gives  
1
35
33 .
x
t
=
+
  
 
5. 
If we set  
4x
t
=  then the third equation gives  
3
5
3 ,
x
t
=
+
 next the second equation gives  
2
6
,
x
t
=
+
 and finally the first equation gives  
1
13
4 .
x
t
=
+
 
 
6. 
If we set  
3x
t
=  and  
4
4
x = − from the third equation, then the second equation gives  
2
11 3 ,
x
t
=
+
 and next the first equation gives  
1
17
.
x
t
=
+  
 

 
Section 3.2 
137 
7. 
If we set  
3x
s
=
 and  
4
,
x
t
=
 then the second equation gives  
2
7
2
7 ,
x
s
t
=
+
−
 and next 
the first equation gives  
1
3 8
19 .
x
s
t
=
−
+
 
 
8. 
If we set  
2x
s
=
 and  
4
,
x
t
=
 then the second equation gives  
3
10
3 ,
x
t
=
−
 and next the 
first equation gives  
1
25 10
22 .
x
s
t
= −
+
+
 
 
9. 
Starting with  
4
6
x =
 from the fourth equation, the third equation gives  
3
5,
x = −
 next the 
second equation gives  
2
3,
x =
 and finally the first equation gives  
1
1.
x =
 
 
10. 
If we set  
3x
s
=
 and  
5
,
x
t
=
 then the third equation gives  
4
5 ,
x
t
=
 next the second 
equation gives  
2
13
8 ,
x
s
t
=
−
 and finally the first equation gives  
1
63
16 .
x
s
t
=
−
 
 
In each of Problems 11–22, we give just the first two or three steps in the reduction.  Then we 
display a resulting echelon form  E  of the augmented coefficient matrix  A  of the given linear 
system, and finally list the resulting solution (if any).  The student should understand that the 
echelon matrix  E  is not unique, so a different sequence of elementary row operations may 
produce a different echelon matrix. 
 
11. 
Begin by interchanging rows 1 and 2 of  A.  Then subtract twice row 1 both from row 2 
and from row 3. 
 
1
2
3
1
3
2
5
0
1
0
2 ;
3,
2,
4
0
0
1
4
x
x
x




=
−
=
= −
=






E
 
 
12. 
Begin by subtracting row 2 of  A  from row 1.  Then subtract twice row 1 both from row 
2 and from row 3. 
 
1
2
3
1
6
4
15
0
1
0
3 ;
5,
3,
2
0
0
1
2
x
x
x
−
−




=
−
=
= −
=






E
 
 
13. 
Begin by subtracting twice row 1 of  A  both from row 2 and from row 3.  Then add row 
2 to row 3. 
 
1
2
3
1
3
3
13
0
1
2
3 ;
4
3 ,
3
2 ,
0
0
0
0
x
t
x
t
x
t




=
=
+
=
−
=






E
 
 
14. 
Begin by interchanging rows 1 and 3 of  A.  Then subtract twice row 1 from row 2, and 
three times row 1 from row 3. 

138 
Chapter 3 
 
1
2
3
1
2
2
9
0
0
1
7
;
5
2 ,
,
7
0
0
0
0
x
t
x
t
x
−
−
−




=
=
+
=
=






E
 
 
15. 
Begin by interchanging rows 1 and 2 of  A.  Then subtract three times row 1 from row 2, 
and five times row 1 from row 3. 
 
1
1
1
1
0
1
3
3 .
0
0
0
1




= 





E
  
The system has no solution. 
 
16. 
Begin by subtracting row 1 from row 2 of  A.  Then interchange rows 1 and 2. Next 
subtract twice row 1 from row 2, and five times row 1 from row 3. 
 
1
4
7
6
0
1
2
0 .
0
0
0
1
−
−




= 





E
 
The system has no solution. 
 
17. 
1
2
3
4
4
3
3
4
x
x
x
x
−
−
−
=
 
 
 
1
2
3
4
2
6
5
5
5
x
x
x
x
−
−
−
=
 
 
 
1
2
3
4
3
4
5
7
x
x
x
x
−
−
−
= −
 
 
Begin by subtracting twice row 1 from row 2 of  A, and three times row 1 from row 3. 
 
1
2
3
4
1
4
3
3
4
0
1
0
1
4 ;
3
2 ,
4
,
5
3 ,
0
0
1
3
5
x
t
x
t
x
t
x
t
−
−
−




=
−
−
=
−
= −+
=
−
=






E
 
 
18. 
Begin by subtracting row 3 from row 1 of  A.  Then subtract 3 times row 1 from row 2, 
and twice row 1 from row 3. 
 
1
2
3
4
1
2
4
13
8
0
0
1
4
3 ;
4
2
3 ,
,
3
4 ,
0
0
0
0
0
x
s
t
x
s
x
t
x
t
−
−
−
−




=
=
+
−
=
=
−
=






E
 
 
19. 
Begin by interchanging rows 1 and 2 of  A.  Then subtract three times row 1 from row 2, 
and four times row 1 from row 3. 

 
Section 3.2 
139 
 
1
2
3
4
1
2
5
5
7
0
1
2
3
5
;
3
,
5
2
3 ,
,
0
0
0
0
0
x
s
t
x
s
t
x
s
x
t
−
−
−




=
−
=
−−
=
+
−
=
=






E
 
 
20. 
Begin by interchanging rows 1 and 2 of  A.  Then subtract twice row 1 from row 2, and 
five times row 1 from row 3. 
 
1
2
3
4
5
1
3
2
7
3
9
0
1
3
7
2
7 ;
2
3 ,
1
2 ,
2
2 ,
,
0
0
1
2
0
2
x
t
x
s
t
x
s
x
s
x
t
−




=
−
=
+
= + −
=
+
=
=




−


E
 
 
21. 
Begin by subtracting twice row 1 from row 2, three times row 1 from row 3, and four 
times row 1 from row 4. 
 
1
2
3
4
1
1
1
0
6
0
1
5
1
20 ;
2,
1,
3,
4
0
0
1
0
3
0
0
0
1
4
x
x
x
x






=
=
=
=
=






E
 
 
22. 
Begin by subtracting row 4 from row 1.  Then subtracting twice row 1 from row 2, four 
times row 1 from row 3, and three times row 1 from row 4. 
 
1
2
3
4
1
2
4
0
9
0
1
6
1
21 ;
3,
2,
4,
1
0
0
1
0
4
0
0
0
1
1
x
x
x
x
−
−
−






=
=
= −
=
= −




−


E
 
 
23. 
If we subtract twice the first row from the second row, we obtain the echelon form  
 
3
2
1
0
0
2
k


= 

−


E
 
 
of the augmented coefficient matrix.  It follows that the given system has no solutions unless  
k = 2, in which case it has infinitely many solutions given by  
1
1
2
3 (1 2 ),
.
x
t
x
t
=
−
=
 
 
24. 
If we subtract twice the first row from the second row, we obtain the echelon form  
 
3
2
0
0
4
0
k


= 

−


E
 

140 
Chapter 3 
 
of the augmented coefficient matrix.  It follows that the given system has only the trivial 
solution  
1
2
0
x
x
=
=
   unless  k = 4, in which case it has infinitely many solutions given by  
2
1
2
3 ,
.
x
t
x
t
= −
=
 
 
25. 
If we subtract twice the first row from the second row, we obtain the echelon form  
 
3
2
11
0
4
1
k


= 

−
−


E
 
 
of the augmented coefficient matrix.  It follows that the given system has a unique solution 
if  
4,
k ≠
 but no solution if  k = 4. 
 
26. 
If we first subtract twice the first row from the second row, then interchange the two rows, 
and finally subtract 3 times the first row from the second row, then we obtain the echelon 
form  
1
1
2
0
1
3
7
k
k
−


= 

−


E
 
 
of the augmented coefficient matrix.  It follows that the given system has a unique solution 
whatever the value of  k. 
 
27. 
If we first subtract twice the first row from the second row, then subtract 4 times the first 
row from the third row, and finally subtract the second row from the third row , we obtain 
the echelon form  
1
2
1
3
0
5
5
1
0
0
0
11
k




= 



−


E
 
 
of the augmented coefficient matrix.  It follows that the given system has no solution unless 
k = 11, in which case it has infinitely many solutions with  
3x  arbitrary. 
 
28. 
If we first interchange rows 1 and 2, then subtract twice the first row from the second row, 
next subtract 7 times the first row from the third row, and finally subtract twice the second 
row from the third row , we obtain the echelon form  
 
1
2
1
0
5
1
2
0
0
0
2
3
b
a
b
c
a
b




=
−
−




−
−


E
 
 
of the augmented coefficient matrix.  It follows that the given system has no solution unless 
2
3 ,
c
a
b
=
+
 in which case it has infinitely many solutions with  
3x  arbitrary. 

 
Section 3.2 
141 
 
29. 
In each of parts (a)-(c), we start with a typical 2 2
×  matrix  A  and carry out two row  
successive operations as indicated, observing that we wind up with the original matrix  A. 
 
 
(a) 
(1/ ) 2
2
c R
cR
s
t
s
t
s
t
u
v
cu
cv
u
v






=
→
=












→
A
A   
 
 
(b) 
,
,
( 1
2)
( 1
2)
SWAP R R
SWAP R R
s
t
u
v
s
t
u
v
s
t
u
v






=
→
→
=












A
A  
 
 
(c) 
(
) 1
2
1
2
c R
R
cR
R
s
t
u
v
s
t
u
v
cu
s
cv
t
u
v
+
+
−






=
→
→
=






+
+






A
A  
 
 
Since we therefore can "reverse" any single elementary row operation, it follows that we can 
reverse any finite sequence of such operations — on at a time — so part (d) follows. 
 
 
30. 
(a) 
This part is essentially obvious, because a multiple of an equation that is satisfied is  
 
also satisfied, and the sum of two equations that are satisfied is one that is also satisfied. 
 
(b) 
Let us write  
1
1
2
1
2
,
,
,
,
n
n+
=
=
A
B B
B
B
A

 where each matrix  
1
k+
B
 is obtained  
 
from  
k
B  by a single elementary row operation (for  
1, 2,
,
k
n
=

).  Then it follows by  n   
applications of part (a) that every solution of the system  LS1  associated with the matrix  A1  
is also a solution of the system  LS2  associated with the matrix  A2.  But part (d) of Problem 
29 implies that  A1  also can be obtained by  A2  by elementary row operations, so by the 
same token every solution of  LS2  is also a solution of  LS1. 
 
 
 
 
SECTION 3.3 
 
REDUCED ROW-ECHELON MATRICES 
 
Each of the matrices in Problems 1-20 can be transformed to reduced echelon form without the 
appearance of any fractions.  The main thing is to get started right.  Generally our first goal is to get 
a 1 in the upper left corner of  A,  then clear out the rest of the first column.  In each problem we 
first give at least the initial steps, and then the final result  E.  The particular sequence of elementary 
row operations used is not unique; you might find  E  in a quite different way. 
 
1. 
2 3 1
1 2 2
1
2
1
2
1
0
3
7
0
1
0
1
R
R
R
R
−
−


















→
→
 
 

142 
Chapter 3 
2. 
1
2
2 2 1
1 2 2
3
7
1
2
1
2
1
0
2
5
2
5
0
1
0
1
R
R
R
R
R
R
−
−
−
























→
→
→
 
 
3. 
1
2
2 2 1
1 2 2
3
7
15
1
2
4
1
2
4
1
0
2
2
5
11
2
5
11
0
1
3
0
1
3
R
R
R
R
R
R
−
−
−
























→
→
→
 
 
4. 
2
1
1
2
3
7
1
3
7
1
1
12
10
5
2
8
2
5
9
2
5
9
R
R
R
R
−
−
−
−
−












−
−






→
→
 
 
( 1/29) 2
1 12
2
2 2 1
1
12
10
1
12
10
1
0
2
0
29
29
0
1
1
0
1
1
R
R
R
R
R
−
−
−
−
−












−
−
−






→
→
→
 
 
5. 
( 1) 2
2 2 1
1 2 2
1
2
11
1
2
11
1
2
11
1
0
5
2
3
19
0
1
3
0
1
3
0
1
3
R
R
R
R
R
−
−
−
−
−
−
−
















−
−
−
−








→
→
→
 
 
6. 
2 4 1
1 2
2
1
2
19
1
2
19
1
0
7
4
7
70
0
1
6
0
1
6
R
R
R
R
−
+
−
−












−
−
−






→
→
 
 
7. 
2
1
3 2 1
1
2
3
1
2
3
1
2
3
1
4
1
0
2
2
0
2
2
2
1
9
2
1
9
0
3
3
R
R
R
R
−
−












−
−












−






→
→
 
 
(1/2) 2
3 3 2
1 2 2
1
2
3
1
2
3
1
0
5
0
1
1
0
1
1
0
1
1
0
3
3
0
0
0
0
0
0
R
R
R
R
R
+
−












−
−
−












−






→
→
→
 
 
8. 
2 3 1
3
1
1
4
5
1
4
5
1
4
5
3
9
3
0
3
18
0
3
18
1
2
3
1
2
3
0
2
8
R
R
R
R
−
−
−
−
−
−
−
−












−












−
−






→
→
 
 
( 1/12) 3
2
3
3 2 2
1
4
5
1
4
5
1
0
0
0
1
10
0
1
10
0
1
0
0
2
8
0
0
12
0
0
1
R
R
R
R
R
−
−
−
−
−
−
−












→












−






→
→
→

 
 

 
Section 3.3 
143 
9. 
1
3
3 4 1
5
2
18
1
1
6
1
1
6
0
1
4
0
1
4
0
1
4
4
1
12
4
1 12
0
3
12
R
R
R
R
−
−
























−
−






→
→
 
 
3 3 2
1
2
1
1
6
1
0
2
0
1
4
0
1
4
0
0
0
0
0
0
R
R
R
R
+
−




















→
→
 
 
10. 
1
3
2 9 1
5
2
5
1
1
2
1
1
2
9
4
7
9
4
7
0
5
25
4
1
7
4
1
7
4
1
7
R
R
R
R
−
−
−












−
−
−
−












−
−
−






→
→
 
 
( 1/5) 2
3 4 1
3 3 2
1
1
2
1
1
2
1
0
3
0
5
25
0
1
5
0
1
5
0
3
15
0
3
15
0
0
0
R
R
R
R
R
−
−
+
−












−
−
→












−
−
−
−






→
→
→

 
 
11. 
( 1, 3)
2 2 1
3
9
1
1
3
6
1
3
6
2
6
7
2
6
7
0
0
19
1
3
6
3
9
1
3
9
1
SWAP R R
R
R
−
−
−
























−






→
→
 
 
(1/19) 2
3 3 1
3 19 2
1
3
6
1
3
6
1
3
0
0
0
19
0
0
1
0
0
1
0
0
19
0
0
19
0
0
0
R
R
R
R
R
−
−
−
−






























→
→
→

 
 
12. 
2 3 1
3 2 1
1
4
2
1
4
2
1
4
2
3
12
1
0
0
7
0
0
7
2
8
5
2
8
5
0
0
9
R
R
R
R
−
−
−
−
−
−
−
−












−












−
−






→
→
 
 
(1/7) 2
1
4
0
0
0
1
0
0
0
R
−




→





→

 
 
13. 
( 1, 2)
2 2 1
2
7
4
0
1
3
2
1
1
3
2
1
1
3
2
1
2
7
4
0
0
1
0
2
2
6
5
4
2
6
5
4
2
6
5
4
SWAP R R
R
R
−












−


















→
→
 

144 
Chapter 3 
 
2 2 1
1 3
2
1
3
2
1
1
0
0
3
0
1
0
2
0
1
0
2
0
0
1
2
0
0
1
2
R
R
R
R
−
−








−
→
−












→
→

 
 
14. 
2 2 1
3 2 1
1
3
2
5
1
3
2
5
1
3
2
5
2
5
2
3
0
1
2
7
0
1
2
7
2
7
7
22
2
7
7
22
0
1
3
12
R
R
R
R
−
−












−
−
−
−
−
−


















→
→
 
 
( 1) 2
3
2
1
3
2
5
1
0
0
4
0
1
2
7
0
1
0
3
0
0
1
5
0
0
1
5
R
R
R
−
+








−
−
−
→
−












→
→

 
 
15. 
( 1, 2)
2 2 1
2
2
4
2
1
1
4
3
1
1
4
3
1
1
4
3
2
2
4
2
0
4
12
4
2
7
19
3
2
7
19
3
2
7
19
3
SWAP R R
R
R
−
−
−
−
−












−
−
−












−
−
−






→
→
 
 
(1/4) 2
3 2 1
1
1
4
3
1
1
4
3
0
4
12
4
0
1
3
1
0
9
27
9
0
9
27
9
R
R
R
−
−
−
−
−








−
−








−
−




→
→
 
 
3 9 2
1
2
1
1
4
3
1
0
1
2
0
1
3
1
0
1
3
1
0
0
0
0
0
0
0
0
R
R
R
R
−
+
−
−
−








−
−












→
→
 
 
16. 
2 2 1
3 2 1
1
3
15
7
1
3
15
7
1
3
15
7
2
4
22
8
0
2
8
6
0
2
8
6
2
7
34
17
2
7
34
17
0
1
4
3
R
R
R
R
−
−












−
−
−
−
−
−


















→
→
 
 
( 1/2) 2
3
2
1
3 15
7
1
0
3
2
0
1
4
3
0
1
4
3
0
1
4
3
0
0
0
0
R
R
R
−
−
−








→












→
→

 
 
17. 
3 2 1
2
1
1
1
1
1
4
1
1
1
1
4
1
1
1
1
4
1
2
2
8
1
0
3
3
9
3
0
3
3
9
3
2
3
1
3
11
2
3
1
3
11
0
1
3
5
19
R
R
R
R
−
−
−
−
−
−
−
−












−
−
−
−
−
−
−












−
−
−






→
→
 

 
Section 3.3 
145 
 
( 1/3) 2
3
2
1
1
1
1
4
1
1
1
1
4
0
1
1
3
1
0
1
1
3
1
0
1
3
5
19
0
0
4
8
20
R
R
R
−
−
−
−
−
−








−
−
−
−








−
−




→
→
 
 
( 1/4) 3
1
2
1
1
1
1
4
1
0
0
2
3
0
1
1
3
1
0
1
0
1
4
0
0
1
2
5
0
0
1
2
5
R
R
R
−
−
−
−
−








−
−
→
−








−
−
−
−




→
→

 
 
18. 
3 2 1
2 2 1
1
2
5
12
1
1
2
5
12
1
1
2
5
12
1
2
3
18
11
9
0
7
28
35
7
0
7
28
35
7
2
5
26
21
11
2
5
26
21
11
0
9
36
45
9
R
R
R
R
−
−
−
−
−
−
−
−
−
−
−






























→
→
 
 
(1/7) 2
(1/7) 2
1
2
5
12
1
1
2
5
12
1
0
1
4
5
1
0
1
4
5
1
0
9
36
45
9
0
9
36
45
9
R
R
−
−
−
−
−
−




















→
→
 
 
(1/9) 3
3
2
1
2
5
12
1
1
0
3
2
3
0
1
4
5
1
0
1
4
5
1
0
1
4
5
1
0
0
0
0
0
R
R
R
−
−
−
−
−








→












→
→

 
 
19. 
( 1, 3)
2
7
10
19
13
1
0
2
1
3
1
3
4
8
6
1
3
4
8
6
1
0
2
1
3
2
7
10
19
13
SWAP R R
−
−








−
−
−
−








−
−




→
 
 
3 2 1
2
1
1
0
2
1
3
1
0
2
1
3
0
3
6
9
3
0
3
6
9
3
2
7
10
19
13
0
7
14
21
7
R
R
R
R
−
−








−
−
−
−








−
−
−
−




→
→
 
 
(1/3) 2
3 7 2
1
0
2
1
3
1
0
2
1
3
0
1
2
3
1
0
1
2
3
1
0
7
14
21
7
0
0
0
0
0
R
R
R
−








−
−
−
−








−
−




→
→
 
 
20. 
1
3
3
6
1
7
13
1
2
4
2
13
5
10
8
18
47
5
10
8
18
47
2
4
5
9
26
2
4
5
9
26
R
R
−
−
−
−




















→
 

146 
Chapter 3 
 
2 5 1
3 2 1
1
2
4
2
13
1
2
4
2
13
0
0
28
28
112
0
0
28
28
112
2
4
5
9
26
0
0
13
13
52
R
R
R
R
−
−
−
−
−
−
−
−




















→
→
 
 
(1/28) 2
3 13 2
1
2
4
2
13
1
2
0
2
3
0
0
1
1
4
0
0
1
1
4
0
0
13
13
52
0
0
0
0
0
R
R
R
−
−
−
−








→












→
→

 
 
In each of Problems 21–30, we give just the first two or three steps in the reduction.  Then we 
display the resulting reduced echelon form  E  of the augmented coefficient matrix  A  of the 
given linear system, and finally list the resulting solution (if any).   
 
21. 
Begin by interchanging rows 1 and 2 of  A.  Then subtract twice row 1 both from row 2 
and from row 3. 
 
1
2
3
1
0
0
3
0
1
0
2 ;
3,
2,
4
0
0
1
4
x
x
x




=
−
=
= −
=






E
 
 
22. 
Begin by subtracting row 2 of  A  from row 1.  Then subtract twice row 1 both from row 
2 and from row 3. 
 
1
2
3
1
0
0
5
0
1
0
3 ;
5,
3,
2
0
0
1
2
x
x
x




=
−
=
= −
=






E
 
 
23. 
Begin by subtracting twice row 1 of  A  both from row 2 and from row 3.  Then add row 
2 to row 3. 
 
1
2
3
1
0
3 14
0
1
2
3 ;
4
3 ,
3
2 ,
0
0
0
0
x
t
x
t
x
t
−




=
=
+
=
−
=






E
 
 
24. 
Begin by interchanging rows 1 and 3 of  A.  Then subtract twice row 1 from row 2, and 
three times row 1 from row 3. 
 
1
2
3
1
2
0
5
0
0
1
7 ;
5
2 ,
,
7
0
0
0
0
x
t
x
t
x
−




=
=
+
=
=






E
 
 

 
Section 3.3 
147 
25. 
Begin by interchanging rows 1 and 2 of  A.  Then subtract three times row 1 from row 2, 
and five times row 1 from row 3. 
 
1
0
2
0
0
1
3
0 .
0
0
0
1
−




= 





E
 
The system has no solution. 
 
26. 
Begin by subtracting row 1 from row 2 of  A.  Then interchange rows 1 and 2. Next 
subtract twice row 1 from row 2, and five times row 1 from row 3. 
 
1
0
1
0
0
1
2
0 .
0
0
0
1




= 





E
  
The system has no solution. 
 
27. 
1
2
3
4
4
3
3
4
x
x
x
x
−
−
−
=
 
 
 
1
2
3
4
2
6
5
5
5
x
x
x
x
−
−
−
=
 
 
 
1
2
3
4
3
4
5
7
x
x
x
x
−
−
−
= −
 
 
Begin by subtracting twice row 1 from row 2 of  A, and three times row 1 from row 3. 
 
1
2
3
4
1
0
0
2
3
0
1
0
1
4 ;
3
2 ,
4
,
5
3 ,
0
0
1
3
5
x
t
x
t
x
t
x
t




=
−
−
=
−
= −+
=
−
=






E
 
 
28. 
Begin by subtracting row 3 from row 1 of  A.  Then subtract 3 times row 1 from row 2, 
and twice row 1 from row 3. 
 
1
2
3
4
1
2
0
3
4
0
0
1
4
3 ;
4
2
3 ,
,
3
4 ,
0
0
0
0
0
x
s
t
x
s
x
t
x
t
−




=
=
+
−
=
=
−
=






E
 
 
29. 
Begin by interchanging rows 1 and 2 of  A.  Then subtract three times row 1 from row 2, 
and four times row 1 from row 3. 
 
1
2
3
4
1
0
1
1
3
0
1
2
3
5 ;
3
,
5
2
3 ,
,
0
0
0
0
0
x
s
t
x
s
t
x
s
x
t




=
−
=
−−
=
+
−
=
=






E
 
 

148 
Chapter 3 
30. 
Begin by interchanging rows 1 and 2 of  A.  Then subtract twice row 1 from row 2, and 
five times row 1 from row 3. 
 
1
2
3
4
5
1
0
0
0
3
2
0
1
0
1
2
1 ;
2
3 ,
1
2 ,
2
2 ,
,
0
0
1
2
0
2
x
t
x
s
t
x
s
x
s
x
t
−




=
−
=
+
= + −
=
+
=
=




−


E
 
 
31. 
(1/6) 3
(1/4) 2
2 5 3
1
2
3
1
2
3
1
2
3
1
2
3
0
4
5
0
4
5
0
4
0
0
1
0
0
0
6
0
0
1
0
0
1
0
0
1
R
R
R
R
−








































→
→
→
 
 
1 2 2
1 3 3
1
0
3
1
0
0
0
1
0
0
1
0
0
0
1
0
0
1
R
R
R
R
−
−




















→
→
 
 
32. 
If  
0,
ad
bc
−
≠
 then not both  a  and  b  can be zero.  If, for instance,  
0,
a ≠
 then 
 
 
(1/ ) 1
2
1
2
1
/
1
/
1
/
0
/
0
a R
R
cR
aR
a
b
b a
b a
b a
c
d
c
d
d
bc a
ad
bc
−
















−
−








→
→
→
 
 
(1/(
)) 2
1 ( / ) 2
1
/
1
0
0
1
0
1
ad bc R
R
b a R
b a
−
−












→
→
. 
 
33. 
If the upper left element of a 2 2
×  reduced echelon matrix is  1,  then the possibilities are  
1
0
1
*
and
,
0
1
0
0












  depending on whether there is a nonzero element in the second 
row.  If the upper left element is zero — so both elements of the second row are also 0, 
then the possibilities are  0
1
0
0
and
.
0
0
0
0












 
 
34. 
If the upper left element of a 3 3
×  reduced echelon matrix is  1,  then the possibilities are 
 
 
 
1
0
0
1
0
*
1
*
0
1
*
*
0
1
0 ,
0
1
* ,
0
0
1 ,
and
0
0
0 ,
0
0
1
0
0
0
0
0
0
0
0
0








































 
 
 
depending on whether the second and third row contain any nonzero elements.  If the 
upper left element is zero — so the first column and third row contain no nonzero 
elements — then use of the four 2 2
×  reduced echelon matrices of Problem 33 (for the 
upper right 2 2
×  submatrix of our reduced 3 3
×  matrix) gives the additional possibilities 

 
Section 3.3 
149 
 
 
 
0
1
0
0
1
*
0
0
1
0
0
0
0
0
1 ,
0
0
0 ,
0
0
0 ,
and
0
0
0 .
0
0
0
0
0
0
0
0
0
0
0
0








































 
 
35. 
(a) 
If  
0
0
(
,
)
x
y
  is a solution, then it follows that 
 
 
 
 
0
0
0
0
0
0
0
0
(
)
(
)
(
)
0
0,
(
)
(
)
(
)
0
0
a kx
b ky
k ax
by
k
c kx
d ky
k cx
dy
k
+
=
+
=
⋅
=
+
=
+
=
⋅
=
 
 
 
so   
0
0
(
,
)
kx ky
 is also a solution. 
 
(b) 
If  
1
1
( ,
)
x y
 and  
2
2
(
,
)
x
y
 are solutions, then it follows that 
 
 
 
 
1
2
1
2
1
1
2
2
1
2
1
2
1
1
2
2
(
)
(
)
(
)
(
)
0
0
0,
(
)
(
)
(
)
(
)
0
0
0
a x
x
b y
y
ax
by
ax
by
c x
x
d y
y
cx
dy
cx
dy
+
+
+
=
+
+
+
=
+
=
+
+
+
=
+
+
+
=
+
=
 
 
 
so   
1
2
1
2
(
,
)
x
x
y
y
+
+
 is also a solution. 
 
36. 
By Problem 32, the coefficient matrix of the given homogeneous 2 2
×  system is row-
equivalent to the 2 2
×  identity matrix.  Therefore, Theorem 4 implies that the given 
system has only the trivial solution. 
 
37. 
If  
0
ad
bc
−
=
 then, much as in Problem 32, we see that the second row of the reduced 
echelon form of the coefficient matrix is allzero.  Hence there is a free variable, and thus 
the given homogeneous system has a nontrivial solution involving a parameter  t. 
 
38. 
By Problem 37, there is a nontrivial solution if and only if 
 
 
 
2
(
2)(
3)
(2)(3)
12
(
4)(
3)
0,
c
c
c
c
c
c
+
−
−
=
−−
=
−
+
=
 
 
 
that is, either  c = 4  or  c = –3. 
 
39. 
It is given that the augmented coefficient matrix of the homogeneous 3 3
×  system has the 
form 
 
 
 
1
1
1
2
2
2
1
2
1
2
1
2
0
0 .
0
a
b
c
a
b
c
pa
qa
pb
qb
pc
qc








+
+
+


 
 
 
Upon subtracting both  p times row 1 and  q times row 2 from row 3, we get the matrix 
 

150 
Chapter 3 
 
 
 
 
1
1
1
2
2
2
0
0
0
0
0
0
a
b
c
a
b
c










 
 
 
corresponding to two homogeneous linear equations in three unknowns.  Hence there is at 
least one free variable, and thus the system has a nontrivial family of solutions. 
 
40. 
In reducing further from the echelon matrix  E  to the matrix  E*,  the leading entries of  
E  become the leading ones in the reduced echelon matrix  E*.  Thus the nonzero rows of  
E* come precisely from the nonzero rows of  E.  We therefore are talking about the same 
rows — and in particular about the same number of rows — in either case. 
 
 
 
SECTION 3.4 
 
MATRIX OPERATIONS 
 
The objective of this section is simple to state.  It is not merely knowledge of, but complete mastery 
of matrix addition and multiplication (particularly the latter).  Matrix multiplication must be 
practiced until it is carried out not only accurately but quickly and with confidence — until you can 
hardly look at two matrices  A  and  B  without thinking of "pouring" the ith row of  A  down the jth 
column of  B.  
 
1. 
3
5
1
0
9
15
4
0
5
15
3
4
2
7
3
4
6
21
12
16
18
5
−
−
−
−
−










+
=
+
=










−
−










 
 
2. 
2
0
3
2
3
1
10
0
15
6
9
3
16
9
18
5
3
1
5
6
7
1
5
5
25
30
21
3
15
26
22
15
−
−
−
−
−
−
−










−
=
+
=










−
−
−
−
−
−










 
 
3. 
5
0
4
5
10
0
16
20
26
20
2 0
7
4
3
2
0
14
12
8
12
6
3
1
7
4
6
2
28
16
22
18
−
−
−
−




















−
+
=
−
+
=
−




















−
−










 
 
4. 
2
1
0
6
3
4
7 4
0
3
5 5
2
1
5
2
7
0
7
9
−
−
−








−
+
−








−




 
 
 
14
7
0
30
15
20
44
22
20
28
0
21
25
10
5
53
10
26
35
14
49
0
35
45
35
21
94
−
−
−
−
−












=
−
+
−
=
−












−






 
 

 
Section 3.4 
151 
5. 
2
1
4
2
9
1
4
2
2
1
2
8
;
3
2
1
3
10
12
1
3
3
2
11
5
−
−
−
−
−
−










=
=










−










 
 
6. 
1
0
3
7
4
3
7
13
24
3
2
4
1
5
2
23
10
41
2
3
5
0
3
9
11
8
57
−
−
−
−










−
=










−
−





 
 
7
4
3
1
0
3
1
17
22
1
5
2
3
2
4
12
16
7
0
3
9
2
3
5
27
21
57
−
−
−
−










−
=










−
−





 
 
7. 
[
]
[
]
[
]
3
3
3
6
9
1
2
3
4
26 ;
4 1
2
3
4
8
12
6
6
5
10
15








=
=












 
 
8. 
3
0
3
0
3
0
9
1
0
3
21 15
1
0
3
1
4
;
1
4
7
20
13
2
5
4
35
0
2
5
4
6
5
6
5
16
25
38


















−
=
−
=
−












−
−












−






 
 
9. 
0
2
4
3
3
1
7
2
4
5
22
−










=






−






−
−




  but the product  
0
2
3
3
1
2
4
5
−








−



−


  is not defined. 
 
10. 
2
1
1
0
4
1
2
13
4
3
3
2
5
5
6
31
−
−





=
=





−
−





AB
  but the product  BA  is not defined. 
 
11. 
[
]
[
]
2
7
5
6
3
5
11 1
5
3
1
4
2
3


=
−
=


−


AB
  but the product  BA  is not defined. 
 
12. 
Neither product matrix  AB  or  BA  is defined. 
 
13. 
3
1
2
5
0
1
3
1
10
17
32
51
(
)
1
4
3
1
2
3
1
4
2
0
2
17











=
=
=











−
−
−
−
−











A BC
 
 
3
1
2
5
0
1
3
16
0
1
32
51
(
)
1
4
3
1
2
3
14
1
2
3
2
17











=
=
=











−
−
−
−
−
−











AB C
 

152 
Chapter 3 
14. 
(
)
[
]
[
]
[
]
2
5
6
13
2
1
2
1
3
3
1
5
23


−





=
−
=
−
=
−







−
−
−







A BC
 
 
(
)
[
]
[
]
[
]
2
5
6
6
2
1
7
9
3
3
1
5
5







=
−
=
=
−







−
−
−







AB C
 
 
15. 
(
)
[
]
[
]
2
0
3
3
12
15
1
1
2
0
3
4
5
2
2
8
10
1
4












=
−
=
=




















A BC
 
 
(
)
[
]
2
0
2
0
3
3
3
6
12
15
1
1
2
0
3
0
3
2
2
2
4
8
10
1
4
1
4






−









=
−
=
=











−














AB C
 
 
16. 
(
)
2
0
1
1
1
0
1
2
0
3
3
2
3
2
0
1
1
4



−
−





=







−









A BC
 
 
 
2
0
4
4
2
2
2
2
1
1
0
3
9
12
9
12
3
4
3
4
1
4
14
18
13 17
−
−
−




−
−
−






=
=
−
−
−






−
−
−






−
−
−




 
 
(
)
2
0
1
1
1
0
1
2
0
3
3
2
3
2
0
1
1
4




−
−







=







−











AB C
 
 
 
2
2
4
4
2
2
1
0
1
2
9
6
9
12
9
12
3
2
0
1
13
9
14
18
13 17
−
−
−
−




−






=
−
=
−
−
−












−
−
−
−




 
 
Each of the homogeneous linear systems in Problems 17–22 is already in echelon form, so it 
remains only to write (by back substitution) the solution, first in parametric form and then in 
vector form. 
 
17. 
3
4
1
2
,
,
5
4 ,
2
7
x
s
x
t
x
s
t
x
s
t
=
=
=
−
= −
+
 
 
(
)
(
)
5, 2,1,0
4,7,0,1
s
t
=
−
+
−
x
 
 
18. 
2
4
1
3
,
,
3
6 ,
9
x
s
x
t
x
s
t
x
t
=
=
=
−
= −
 
 
(
)
(
)
3,1,0,0
6,0, 9,1
s
t
=
+
−
−
x
 

 
Section 3.4 
153 
 
19. 
4
5
1
2
3
,
,
3
,
2
6 ,
8
x
s
x
t
x
s
t
x
s
t
x
s
t
=
=
= −
+
=
−
= −+
 
 
(
)
(
)
3,2, 1,1,0
1, 6,8,0,1
s
t
=
−
−
+
−
x
 
 
20. 
2
5
1
3
4
,
,
3
7 ,
2 ,
10
x
s
x
t
x
s
t
x
t
x
t
=
=
=
−
=
=
 
 
(
)
(
)
3,1,0,0,0
7,0,2,10,0
s
t
=
+
−
x
 
 
21. 
3
4
5
1
2
,
,
,
2
7 ,
2
3
4
x
r
x
s
x
t
x
r
s
t
x
r
s
t
=
=
=
=
−
−
= −
+
−
 
 
(
)
(
)
(
)
1, 2,1,0,0
2,3,0,1,0
7, 4,0,0,1
r
s
t
=
−
+
−
+
−
−
x
 
 
22. 
2
4
5
1
3
,
,
,
7
3 ,
2
x
r
x
s
x
t
x
r
s
t
x
s
t
=
=
=
=
−
−
=
+
 
 
(
)
(
)
(
)
1,1,0,0,0
7,0,1,1,0
3,0,2,0,1
r
s
t
=
+
−
+
−
x
 
 
23. 
The matrix equation  2
1
1
0
3
2
0
1
a
b
c
d





=










  entails the four scalar equations 
 
 
 
 
2
1
2
0
3
2
0
3
2
1
a
c
b
d
a
c
b
d
+
=
+
=
+
=
+
=
 
 
that we readily solve for  
2,
1,
3,
2.
a
b
c
d
=
= −
= −
=
  Hence the apparent inverse 
matrix of A,  such that  AB = I, is  
2
1 .
3
2
−


= 

−


B
  Indeed, we find that  BA = I   
as well.   
 
24. 
The matrix equation  3
4
1
0
5
7
0
1
a
b
c
d





=










  entails the four scalar equations 
 
 
 
 
3
4
1
3
4
0
5
7
0
5
7
1
a
c
b
d
a
c
b
d
+
=
+
=
+
=
+
=
 
 
that we readily solve for  
7,
4,
5,
3.
a
b
c
d
=
= −
= −
=
  Hence the apparent inverse 
matrix of A,  such that  AB = I, is  
7
4 .
5
3
−


= 

−


B
  Indeed, we find that  BA = I   
as well.   
 
25. 
The matrix equation  5
7
1
0
2
3
0
1
a
b
c
d





=










  entails the four scalar equations 

154 
Chapter 3 
 
 
 
 
5
7
1
5
7
0
2
3
0
2
3
1
a
c
b
d
a
c
b
d
+
=
+
=
+
=
+
=
 
 
that we readily solve for  
3,
7,
2,
5.
a
b
c
d
=
= −
= −
=
  Hence the apparent inverse 
matrix of A,  such that  AB = I, is  
3
7 .
2
5
−


= 

−


B
  Indeed, we find that  BA = I   
as well.   
 
26. 
The matrix equation  
1
2
1
0
2
4
0
1
a
b
c
d
−





=





−





  entails the four scalar equations 
 
 
 
 
2
1
2
0
2
4
0
2
4
1.
a
c
b
d
a
c
b
d
−
=
−
=
−
+
=
−
+
=
 
 
But the two equations in  a  and  c  obviously are inconsistent, because  ( 1)(1)
0,
−
≠
 and 
the two equations in  b  and  d  are similarly inconsistent.  Therefore the given matrix  A  
has no inverse matrix. 
 
27. 
1
1
1 1
2
2
2
2
3
3
3 3
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
n
n
n
n
a
b
a b
a
b
a b
a
b
a b
a
b
a b




















=















































 
 
Thus the product of two diagonal matrices of the same size is obtained simply by  
multiplying corresponding diagonal elements.  Then the commutativity of scalar 
multiplication immediately implies that  AB = BA  for diagonal matrices. 
 
28. 
The matrix power  
n
A   is simply the product  AAA
A

 of  n  copies of  A.   It follows 
(by associativity) that parentheses don't matter: 
 
 
 
copies
copies
copies
(
)(
)
(
)
r
s
r s
r
s
r s
+
+
=
=
=
A A
AAA
A
AAA
A
AAA
A
A



, 
 
 
the product of  r + s  copies of  A  in either case. 
 
29. 
1
0
(
)
(
)
(
)
(
) 0
1
a
b
a
d
ad
bc
a
d
ad
bc
c
d




+
−
−
=
+
−
−








A
I
 
 
 
2
2
2
2
(
)
(
)
(
)
(
)
a
ad
ad
bc
ab
bd
a
bc
ab
bd
ac
cd
ad
d
ad
bc
ac
cd
bc
d




+
−
−
+
+
+
=
=




+
+
−
−
+
+




 

 
Section 3.4 
155 
 
 
2
a
b
a
b
c
d
c
d



=
=






A  
 
30. 
If  
2
1
1
2


= 



A
 then  
4 and
3.
a
d
ad
bc
+
=
−
=
  Hence 
 
2
2
1
1
0
5
4
4
3
4
3
;
1
2
0
1
4
5






=
−
=
−
=












A
A
I
 
 
3
2
5
4
2
1
14
13
4
3
4
3
;
4
5
1
2
13
14






=
−
=
−
=












A
A
A
 
 
4
3
2
14
13
5
4
41
40
4
3
4
3
;
13
14
4
5
40
41






=
−
=
−
=












A
A
A
 
 
5
5
3
41
40
14
13
122
121
4
3
4
3
.
40
41
13
14
121 122






=
−
=
−
=












A
A
A
 
 
31. 
(a) 
If  
2
1
1
5
and
4
3
3
7
−




=
=




−




A
B
 then 
 
 
 
3
4
1
6
25
34
(
)(
)
1 10
7
4
71
34
−
−
−





+
−
=
=





−
−
−
−
−





A
B A
B
 
 
but 
 
 
 
2
2
8
5
16
40
8
45 .
20
13
24
64
44
51
−
−
−






−
=
−
=






−
−
−






A
B
 
 
(b) 
If  AB = BA  then 
 
 
 
2
2
2
2
(
)(
)
(
)
(
)
.
+
−
=
−
+
−
=
−
+
−
=
−
A
B A
B
A A
B
B A
B
A
AB
BA
B
A
B  
 
32. 
(a) 
If  
2
1
1
5
and
4
3
3
7
−




=
=




−




A
B
 then 
 
 
 
2
3
4
3
4
5
52
(
)
1 10
1 10
13
96





+
=
=





−
−
−





A
B
 
 
but 
 
 
2
2
8
5
2
1
1
5
16
40
2
2
20
13
4
3
3
7
24
64
8
5
1
3
16
40
22
41
2
.
20
13
5
1
24
64
14
79
−
−







+
+
=
+
+







−
−







−
−








=
+
+
=








−








A
AB
B
 

156 
Chapter 3 
 
(b) 
If  AB = BA  then 
 
 
 
2
2
2
2
(
)(
)
(
)
(
)
.
+
−
=
−
+
−
=
−
+
−
=
−
A
B A
B
A A
B
B A
B
A
AB
BA
B
A
B  
33. 
Four different 2 2
×  matrices  A  with  A2 = I  are 
 
 
 
1
0
1
0
1
0
1
0
,
,
, and
.
0
1
0
1
0
1
0
1
−
−
















−
−








 
 
34. 
If  
2
1
1
then
(0)
(0)
.
1
1
−


=
≠
=
−
=


−


A
0
A
A
I
0  
 
35. 
If  
2
2
1
then
(1)
(0)
.
2
1
−


=
≠
=
−
=


−


A
0
A
A
I
A  
 
36. 
If  
2
0
1
then
(0)
( 1)
.
1
0


=
≠
=
−−
=




A
0
A
A
I
I  
 
37. 
If  
2
0
1
then
(0)
(1)
.
1
0


=
≠
=
−
= −


−


A
0
A
A
I
I  
 
38. 
If  
0
1
1
0


=
≠




A
0 is the matrix of Problem 36 and  
0
1
1
0


=
≠


−


B
0  is the matrix 
of Problem 37, then  
2
2
( )
(
)
.
+
=
+ −
=
A
B
I
I
0  
 
39. 
If  Ax1 = Ax2 = 0, then 
 
 
 
(
)
(
)
(
)
( )
( )
1
1
2
2
1
1
2
2
1
2
.
c
c
c
c
c
c
+
=
+
=
+
=
A
x
x
Ax
Ax
0
0
0  
 
40. 
(a) 
If  Ax0 = 0  and  Ax1 = b, then 
(
)
0
1
0
1
.
+
=
+
=
+
=
A x
x
Ax
Ax
0
b
b  
 
(b) 
If  Ax1 = b  and  Ax2 = b, then 
(
)
1
2
1
2
.
−
=
−
=
−
=
A x
x
Ax
Ax
b
b
0  
 
41. 
If  AB = BA then 
 
 
 
(
)
(
)(
)
(
)(
)
3
2
2
2
2
+
=
+
+
=
+
+
+
A
B
A
B
A
B
A
B
A
AB
B
 
 
 
(
)
(
)
2
2
2
2
2
2
=
+
+
+
+
+
A A
AB
B
B A
AB
B
 
 
 
(
) (
)
3
2
2
2
2
3
2
2
=
+
+
+
+
+
A
A B
AB
A B
AB
B
 

 
Section 3.4 
157 
 
 
3
2
2
3
3
3
.
=
+
+
+
A
A B
AB
B  
 
 
To compute  (
)
4 ,
+
A
B
  write  (
)
(
)(
)
4
3
+
=
+
+
A
B
A
B
A
B
 and proceed similarly, 
substituting the expansion of  (
)
3
+
A
B
 just obtained. 
 
42. 
(a) 
Matrix multiplication gives 
2
3
0
0
4
0
0
0
0
0
0
and
0
0
0 .
0
0
0
0
0
0








=
=












N
N
 
 
(b) 
2
2
1
0
0
0
2
0
0
0
4
1
4
4
2
0
1
0
2 0
0
2
0
0
0
0
1
4
0
0
1
0
0
0
0
0
0
0
0
1
















=
+
+
=
+
+
=
























A
I
N
N
 
 
 
3
2
1
0
0
0
2
0
0
0
4
1
6
12
3
3
0
1
0
3 0
0
2
3 0
0
0
0
1
6
0
0
1
0
0
0
0
0
0
0
0
1
















=
+
+
=
+
+
=
























A
I
N
N
 
 
 
4
2
1
0
0
0
2
0
0
0
4
1
8
24
4
6
0
1
0
4 0
0
2
6 0
0
0
0
1
8
0
0
1
0
0
0
0
0
0
0
0
1
















=
+
+
=
+
+
=
























A
I
N
N
 
 
43. 
First, matrix multiplication gives  
2
2
1
1
6
3
3
1
2
1
3
6
3
3 .
1
1
2
3
3
6
−
−
−
−








=
−
−
=
−
−
=








−
−
−
−




A
A  Then 
 
 
3
2
2
3
3
3 3
9 ,
=
⋅
=
⋅
=
=
⋅
=
A
A
A
A A
A
A
A  
 
 
4
3
2
9
9
9 3
27 ,
=
⋅
=
⋅
=
=
⋅
=
A
A
A
A A
A
A
A  
 
and so forth. 
 
 
 
SECTION 3.5 
 
INVERSES OF MATRICES 
 
The computational objective of this section is clearcut — to find the inverse of a given invertible 
matrix.  From a more general viewpoint, Theorem 7 on the properties of nonsingular matrices 
summarizes most of the basic theory of this chapter. 
 

158 
Chapter 3 
In Problems 1–8 we first give the inverse matrix  
1
−
A  and then calculate the solution vector  x. 
 
1. 
1
3
2
3
2
5
3
;
4
3
4
3
6
2
−
−
−






=
=
=






−
−
−






A
x
 
 
2. 
1
5
7
5
7
1
26
;
2
3
2
3
3
11
−
−
−
−
−







=
=
=







−
−







A
x
 
 
3. 
1
6
7
6
7
2
33
;
5
6
5
6
3
28
−
−
−







=
=
=







−
−
−
−







A
x
 
 
4. 
1
17
12
17
12
5
25
;
7
5
7
5
5
10
−
−
−






=
=
=






−
−
−






A
x
 
 
5. 
1
4
2
4
2
5
8
1
1
1
;
5
3
5
3
6
7
2
2
2
−
−
−






=
=
=






−
−
−






A
x
 
 
6. 
1
6
7
6
7
10
25
1
1
1
;
3
4
3
4
5
10
3
3
3
−
−
−







=
=
=







−
−
−







A
x
 
 
7. 
1
7
9
7
9
3
3
1
1
1
;
5
7
5
7
2
1
4
4
4
−
−
−






=
=
=






−
−
−






A
x
 
 
8. 
1
10
15
10
15
7
25
1
1
1
;
5
8
5
8
3
11
5
5
5
−
−
−






=
=
=






−
−
−






A
x
 
 
In Problems 9–22 we give at least the first few steps in the reduction of the augmented matrix 
whose right half is the identity matrix of appropriate size.  We wind up with its echelon form, whose 
left half is an identity matrix and whose right half is the desired inverse matrix. 
 
9. 
2 4 1
1
2
5
6
1
0
1
1
1
1
1
1
1
1
4
5
0
1
4
5
0
1
0
1
4
5
R
R
R
R
−
−
−
−












−






→
→
 
 
1
1
2
1
0
5
6
5
6
;
thus
0
1
4
5
4
5
R
R
−
−
−
−




=




−
−




→
A
 
 
10. 
2 4 1
1
2
5
7
1
0
1
1
1
1
1
1
1
1
4
6
0
1
4
6
0
1
0
2
4
5
R
R
R
R
−
−
−
−












−






→
→
 

 
Section 3.5 
159 
 
7
2
1
5
5
2
2
(1/2) 2
1
2
1
1
1
1
1
0
3
6
7
1
;
thus
0
1
2
0
1
2
4
5
2
R
R
R
−
−
−
−
−






=






−
−
−






→
→
A
 
 
11. 
2 2 1
1
5
1
1
0
0
1
5
1
1
0
0
2
5
0
0
1
0
0
5
2
2
1
0
2
7
1
0
0
1
2
7
1
0
0
1
R
R
−








−
−
−












→
 
 
3 2 1
1
3
1
5
1
1
0
0
1
2
0
1
0
1
0
5
2
2
1
0
0
5
2
2
1
0
0
3
1
2
0
1
0
3
1
2
0
1
R
R
R
R
−
+
−








−
−
−
−
−
−








−
−
−
−
−
−




→
→
 
 
2 2
3
3 3 2
1
2
0
1
0
1
1
2
0
1
0
1
0
1
0
2
1
2
0
1
0
2
1
2
0
3
1
2
0
1
0
0
1
4
3
5
R
R
R
R
−
+
−
−








−
−








−
−
−
−
−




→
→
 
 
1
( 1) 3
1 2 2
1
0
0
5
2
5
5
2
5
0
1
0
2
1
2 ;
thus
2
1
2
0
0
1
4
3
5
4
3
5
R
R
R
−
−
−
−
−
−
−








−
=
−








−
−
−
−




→
→
A

 
 
12. 
2 2 1
1
3
2
1
0
0
1
3
2
1
0
0
2
8
3
0
1
0
0
2
1
2
1
0
3
10
6
0
0
1
3
10
6
0
0
1
R
R
−








−
−












→
 
 
3 2 1
2
3
1
3
2
1
0
0
1
3
2
1
0
0
0
2
1
2
1
0
0
1
1
1
1
1
0
1
0
3
0
1
0
1
0
3
0
1
R
R
R
R
−
−








−
−
−
−








−
−




→
→
 
 
1 3 2
3
2
1
3
2
1
0
0
1
0
0
18
2
7
0
1
1
1
1
1
0
1
0
3
0
1
;
0
0
1
4
1
2
0
0
1
4
2
2
R
R
R
R
−
−
−








−
−
→
−








−
−
−
−




→
→

 
 
1
18
2
7
thus
3
0
1
4
1
2
−
−




=
−




−
−


A
 
 
13. 
( 1, 2)
2
7
3
1
0
0
1
3
2
0
1
0
1
3
2
0
1
0
2
7
3
1
0
0
3
7
9
0
0
1
3
7
9
0
0
1
SWAP R R




















→
 

160 
Chapter 3 
 
2 2 1
3 3 1
1
3
2
0
1
0
1
3
2
0
1
0
0
1
1
1
2
0
0
1
1
1
2
0
3
7
9
0
0
1
0
2
3
0
3
1
R
R
R
R
−
−








−
−
−
−








−
−




→
→
 
 
1
3 2 2
1
0
0
13
42
5
13
42
5
0
1
0
3
9
1
;
thus
3
9
1
0
0
1
2
7
1
2
7
1
R
R
−
+
−
−
−
−








→
−
=
−








−
−




→
A

 
 
 
14. 
1
2
3
5
6
1
0
0
1
1
3
1
1
0
2
4
3
0
1
0
2
4
3
0
1
0
2
3
5
0
0
1
2
3
5
0
0
1
R
R
−
−




















→
 
 
2
3
3 2 1
1
1
3
1
1
0
1
1
3
1
1
0
0
1
2
0
1
1
0
1
2
0
1
1
2
3
5
0
0
1
0
1
1
2
2
1
R
R
R
R
−
−
−
−








−
−
−
−








−
−




→
→
 
 
1
3
2
1
0
0
11
7
9
11
7
9
0
1
0
4
3
3
;
thus
4
3
3
0
0
1
2
1
2
2
1
2
R
R
−
−
−
−
−
−








→
−
=
−








−
−




→
A

 
 
 
15. 
2
1
1
1
5
1
0
0
1
1
5
1
0
0
1
4
13
0
1
0
0
3
8
1
1
0
3
2
12
0
0
1
3
2
12
0
0
1
R
R
−








−












→
 
 
3 3 1
2 2 3
1
1
5
1
0
0
1
1
5
1
0
0
0
3
8
1
1
0
0
1
2
7
1
2
0
1
3
3
0
1
0
1
3
3
0
1
R
R
R
R
−
+








−
−








−
−
−
−
−
−




→
→
 
 
1
3
2
1
0
0
22
2
7
22
2
7
0
1
0
27
3
8
;
thus
27
3
8
0
0
1
10
1
3
10
1
3
R
R
−
+
−
−








→
−
=
−








−
−
−
−




→
A

 
 
 
16. 
2
1
1
3
3
1
0
0
1
3
3
1
0
0
1
1
2
0
1
0
0
2
1
1
1
0
2
3
3
0
0
1
2
3
3
0
0
1
R
R
+
−
−
−
−








−
−
−








−
−
−
−




→
 

 
Section 3.5 
161 
 
3 2 1
2
3
1
3
3
1
0
0
1
3
3
1
0
0
0
2
1
1
1
0
0
1
2
1
1
1
0
3
3
2
0
1
0
3
3
2
0
1
R
R
R
R
−
+
−
−
−
−








−
−
−








−
−




→
→
 
 
1
2
3
3
( 1/3( 3)
3 3
2
1
3
3
1
0
0
1
3
3
1
0
0
0
1
2
1
1
1
0
1
2
1
1
1
0
0
3
1
3
2
0
0
1
1
R
R
R
−
−
−
−
−
−








−
−








−
−
−
−




→
→
 
 
1
1
1
3
3
1
2
3
3
1 3 2
1
0
0
1
0
1
3
0
3
1
0
1
0
1
;
thus
1
3
1
3
0
0
1
1
1
3
2
R
R
−
+
−
−








−
−
−
=
−
−
−








−
−




→
→
A

 
 
17. 
2
1
1
3
0
1
0
0
1
3
0
1
0
0
1
2
1
0
1
0
0
1
1
1
1
0
0
2
2
0
0
1
0
2
2
0
0
1
R
R
+
−
−








−
−
−
−








−
−




→
 
 
( 1) 2
3 2 2
1
3
0
1
0
0
1
3
0
1
0
0
0
1
1
1
1
0
0
1
1
1
1
0
0
2
2
0
0
1
0
0
4
2
2
1
R
R
R
−
+
−
−








−
−
−
−








−
−
−




→
→
 
 
3
3
1
2
2
4
1
1
1
1
2
2
4
1
1
1
2
2
4
(1/4) 3
1
0
0
2
6
3
1
0
1
0
;
thus
2
2
1
4
0
0
1
2
2
1
R
−
−
−
−
−
−
−








→
−
−
−
=
−
−
−








−
−
−
−




→
A

 
 
 
18. 
2 3 1
1
2
2
1
0
0
1
2
2
1
0
0
3
0
1
0
1
0
0
6
5
3
1
0
1
1
2
0
0
1
1
1
2
0
0
1
R
R
−
−
−








−
−








−
−




→
 
 
2 5 3
3
1
1
2
2
1
0
0
1
2
2
1
0
0
0
6
5
3
1
0
0
1
5
2
1
5
0
1
0
1
0
1
0
1
0
1
0
1
R
R
R
R
−
−
−
−








−
−
−
−








−
−




→
→
 
 
1
2
2
5
5
5
3
6
1
5
5
5
(1/5) 3
3
2
1
2
2
1
0
0
1
0
0
0
1
5
2
1
5
0
1
0
1
0
1
;
0
0
5
3
1
6
0
0
1
R
R
R
−
−
−








−
−
→
−








−
−
−
−




→
→

 
 
1
1
2
2
1
thus
5
0
5
5
3
1
6
−
−




=
−




−
−


A
. 

162 
Chapter 3 
 
 
19. 
2
1
1
4
3
1
0
0
1
4
3
1
0
0
1
4
5
0
1
0
0
0
2
1
1
0
2
5
1
0
0
1
2
5
1
0
0
1
R
R
−








−












→
 
 
( 2, 3)
2 2 1
1
4
3
1
0
0
1
4
3
1
0
0
2
5
1
0
0
1
0
3
5
2
0
1
0
0
2
1
1
0
0
0
2
1
1
0
SWAP R
R
R
R
−








−
−
−








−
−




→
→
 
 
7
11
4
2
6
3
5
3
5
2
1
1
3
3
3
2
6
3
1
1
2
2
( 1/3) 2
(1/2) 3
1
4
3
1
0
0
1
0
0
0
1
0
0
1
0
;
0
0
2
1
1
0
0
0
1
0
R
R
−
−








−
→
−
−








−
−




→
→

 
 
1
21
11
8
1
thus
9
5
2
6
3
3
0
−
−




=
−
−




−


A
 
 
 
20. 
1
2
2
0
1
1
0
0
1
0
4
1
1
0
1
0
3
0
1
0
1
0
3
0
1
0
1
1
1
0
0
1
1
1
1
0
0
1
R
R
−
−
−
−




















→
 
 
( 2, 3)
3
1
1
0
4
1
1
0
1
0
4
1
1
0
1
0
3
0
1
0
0
1
5
1
1
1
0
1
5
1
1
0
1
0
3
0
1
0
SWAP R
R
R
R
−
−
−
−
−








−








−




→
→
 
 
3
1
7
7
3
2
7
7
1
2
7
7
(1/7) 3
3
1
1
0
4
1
1
0
1
0
0
0
0
1
5
1
1
1
0
1
0
1 ;
0
0
7
1
2
0
0
0
1
0
R
R
R
−
−
−








−
→
−
−








−
−




→
→

 
 
1
3
1
0
1
thus
2
3
7
7
1
2
0
−




=
−
−




−


A
 
 
 
21. 
( 1, 2)
0
0
1
0
1
0
0
0
1
0
0
0
0
1
0
0
1
0
0
0
0
1
0
0
0
0
1
0
1
0
0
0
0
1
2
0
0
0
1
0
0
1
2
0
0
0
1
0
3
0
0
1
0
0
0
1
3
0
0
1
0
0
0
1
SWAP R R
























→
 

 
Section 3.5 
163 
 
( 2, 3)
4 3 1
1
0
0
0
0
1
0
0
1
0
0
0
0
1
0
0
0
1
2
0
0
0
1
0
0
1
2
0
0
0
1
0
0
0
1
0
1
0
0
0
0
0
1
0
1
0
0
0
3
0
0
1
0
0
0
1
0
0
0
1
0
3
0
1
SWAP R
R
R
R
−




















−




→
→
 
 
2 2 3
1
0
0
0
0
1
0
0
0
1
0
0
2
0
1
0 ;
0
0
1
0
1
0
0
0
0
0
0
1
0
3
0
1
R
R
−




−






−


→
     
1
0
1
0
0
2
0
1
0
thus
1
0
0
0
0
3
0
1
−




−


= 



−


A
 
 
 
22. 
1
2
4
0
1
1
1
0
0
0
1
1
2
0
1
1
0
0
3
1
3
1
0
1
0
0
3
1
3
1
0
1
0
0
0
1
2
0
0
0
1
0
0
1
2
0
0
0
1
0
3
2
4
1
0
0
0
1
3
2
4
1
0
0
0
1
R
R
−
−
−
−
























→
 
 
2 3 1
4 3 1
1
1
2
0
1
1
0
0
1
1
2
0
1
1
0
0
0
4
9
1
3
4
0
0
0
4
9
1
3
4
0
0
0
1
2
0
0
0
1
0
0
1
2
0
0
0
1
0
3
2
4
1
0
0
0
1
0
5
10
1
3
3
0
1
R
R
R
R
−
−
−
−
−
−
−
−








−
−












−




→
→
2 3 3
3
2
1
1
2
0
1
1
0
0
1
1
2
0
1
1
0
0
0
1
3
1
3
4
3
0
0
1
3
1
3
4
3
0
0
1
2
0
0
0
1
0
0
0
1
1
3
4
4
0
0
5
10
1
3
3
0
1
0
5
10
1
3
3
0
1
R
R
R
R
−
−
−
−
−
−
−
−








−
−
−
−








−
−
−




−
−




→
→
 
 
4 5 2
1
0
0
0
1
1
1
0
0
1
0
0
0
2
1
2
;
0
0
1
0
0
1
1
1
0
0
0
1
3
3
5
1
R
R
−
−




−
−


→

−


−
−


→

 
1
1
1
1
0
0
2
1
2
thus
0
1
1
1
3
3
5
1
−
−




−
−


= 

−


−
−


A
 
 
In Problems 23–28 we first give the inverse matrix  
1
−
A  and then calculate the solution matrix  X. 
 
23. 
1
4
3
4
3
1
3
5
7
18
35
;
5
4
5
4
1
2
5
9
23
45
−
−
−
−
−







=
=
=







−
−
−
−
−
−







A
X
 
 
24. 
1
7
6
7
6
2
0
4
14
30
46
;
8
7
8
7
0
5
3
16
35
53
−
−
−
−







=
=
=







−
−
−
−
−







A
X
 
 

164 
Chapter 3 
25. 
1
11
9
4
11
9
4
1
0
3
7
14
15
2
2
1 ;
2
2
1
0
2
2
1
3
2
2
1
0
2
1
0
1
1
0
2
2
4
−
−
−
−














=
−
−
=
−
−
=
−
−














−
−
−
−
−







A
X
 
 
26. 
1
16
3
11
16
3
11
2
0
1
21
9
6
6
1
4 ;
6
1
4
0
3
0
8
3
2
13
2
9
13
2
9
1
0
2
17
6
5
−
−
−
−














=
−
−
=
−
−
=
−
−














−
−
−







A
X
 
 
27. 
1
7
20
17
7
20
17
0
0
1
1
17
20
24
13
0
1
1
;
0
1
1
0
1
0
1
1
1
1
1
2
6
5
2
6
5
1
0
1
0
5
6
7
4
−
−
−
−
−














=
−
=
−
=
−
−














−
−
−
−
−
−







A
X
 
 
28. 
1
5
5
10
5
5
10
2
1
0
2
5
5
10
1
8
8
15
;
8
8
15
1
3
5
0
8
8
15
7
24
23
45
24
23
45
1
1
0
5
24
23
45
13
−
−
−
−














= −
= −
−
= −














−
−
−
−
−
−
−







A
X
 
 
29. 
(a) 
The fact that  A–1  is the inverse of  A  means that  
1
1
.
−
−
=
=
AA
A A
I   That is, that 
when  A–1  is multiplied either on the right or on the left by  A,  the result is the identity  
matrix  I.  By the same token, this means that   A  is the inverse of  A–1. 
(b) 
1
1
1
1
1
1
1
1
(
)
(
)
(
)
.
n
n
n
n
n
n
−
−
−
−
−
−
−
−
=
⋅
⋅
=
⋅⋅
=
=
A
A
A
AA
A
A
I
A
I

  Similarly, 
1
(
)
,
n
n
−
=
A
A
I  so it follows that  
1
(
)n
−
A
 is the inverse of  
.
n
A  
 
30. 
1
1
1
1
1
1
,
−
−
−
−
−
−
⋅
=
⋅⋅
=
⋅⋅
=
ABC C B A
AB I B A
A I A
I  and we see is a similar way that 
 
1
1
1
.
−
−
−⋅
=
C B A
ABC
I  
 
31. 
Let  
1
0,
0, and
.
p
r
q
s
−
= −>
= −>
=
B
A
  Then 
 
 
 
 
1
1
1
(
) (
)
(because
,
0)
(
)
r
s
p
q
p
q
p
q
p q
p q
p q
r s
p q
−
−
−
−
+
−
+
−−
+
=
=
=
=
>
=
=
=
A A
A
A
A
A
B B
B
A
A
A
 
 
 
as desired, and  (
)
(
)
(
)
r
s
p
q
p
q
pq
pq
rs
−
−
−
−
=
=
=
=
=
A
A
B
B
A
A  similarly. 
 
32. 
Multiplication of  AB = AC on the left by  A–1  yields  B = C. 
 
33. 
In particular,  
j
j
=
Ae
e   where  
je   denotes the jth column vector of the identity matrix  I.  
Hence it follows from Fact 2 that  AI = I,  and therefore  A = I–1 = I. 
 

 
Section 3.5 
165 
34. 
The invertibility of a diagonal matrix with nonzero diagonal elements follows immediately 
from the rule for multiplying diagonal matrices (Problem 27 in Section 3.4).  The inverse of 
such a diagonal matrix is gotten simply by inverting each diagonal element. 
 
35. 
If the jth column of  A  is all zeros and  B  is any n n
×  matrix, then the jth column of  BA  is 
all zeros, so  
.
≠
BA
I   Hence  A  has no inverse matrix.  Similarly, if the ith row of  A  is all 
zeros, then so is the ith row of  AB. 
 
36. 
If  ad – bc = 0, then it follows easily that one row of  A  is a multiple of the other.  Hence the 
reduced echelon form of  A  is of the form  *
*
0
0






  rather than the 2 2
×  identity matrix.  
Therefore  A  is not invertible. 
 
37. 
Direct multiplication shows that  
1
1
.
−
−
=
=
AA
A A
I  
 
38. 
3
0
3
3
0
1
a
b
a
b
c
d
c
d





=
=










EA
 
 
39. 
11
12
13
11
12
13
21
22
23
21
22
23
31
32
33
31
11
32
12
33
13
1
0
0
0
1
0
2
0
1
2
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a










=
=










+
+
+





EA
 
 
40. 
11
12
13
21
22
23
21
22
23
11
12
13
31
32
33
31
32
33
0
1
0
1
0
0
0
0
1
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a
a










=
=















EA
 
 
41. 
This follows immediately from the fact that the ijth element of  AB  is the product of the ith 
row of  A  and the jth column of   B. 
 
42. 
Let  
ie  denote the ith row of  I. Then  
,
i
i
=
e B
B  the ith row of  B.  Hence the result in 
Problem 41 yields 
 
 
 
 
1
1
1
2
2
2
.
m
m
m


















=
=
=
=
























e
e B
B
e
e B
B
IB
B
B
e
e B
B



 
 
43. 
Let  
1
2
,
,
,
k
E E
E

  be the elementary matrices corresponding to the elementary row 
operations that reduce  A  to  B.  Then Theorem 5 gives  
1
2
1
k
k−
=
=
B
E E
E E A
GA

 where  
1
2
1.
k
k−
=
G
E E
E E

 

166 
Chapter 3 
 
44. 
This follows immediately from the result in Problem 43, because an invertible matrix is 
row-equivalent to the identity matrix. 
 
45. 
One can simply photocopy the portion of the proof of Theorem 7 that follows Equation (20).  
Starting only with the assumption that  A  and  B are square matrices with  AB = I,  it is 
proved there that  A  and  B  are then invertible. 
 
46. 
If  C = AB is invertible, so  C–1  exists, then  
1
1
(
)
and (
)
.
−
−
=
=
A BC
I
C A B
I   Hence the 
fact that  A  and  B  are invertible follows immediately from Problem 45. 
 
 
 
SECTION 3.6 
 
DETERMINANTS 
 
1. 
0
0
3
4
0
4
0
0
(3)
3 4 5
60
0
5
0
5
0
= +
=
⋅⋅
=
 
 
2. 
2
1
0
2
1
1
1
1
2
1
(2)
(1)
2(4 1)
(2
0)
4
1
2
0
2
0
1
2
= +
−
=
−
−
−
=
 
 
3. 
1
0
0
0
0
5
0
2
0
5
0
6
8
(1) 6
9
8
(5)
5(42
0)
210
3
6
9
8
0
7
0
10
7
4
0
10
7
= +
= −
= −
−
= −
 
 
4. 
5
11
8
7
5
11
8
3
2
6
23
5
8
( 3) 3
2
6
3( 4)
12(30
24)
72
0
0
0
3
3
6
0
4
0
0
4
0
17
−
= −−
−
=
−
= −
−
= −
−
 
 
5. 
0
0
1
0
0
2
0
0
0
0
3
0
2
0
0
0
0
0
0
3
0
3
0
1
2 0
0
4
2( 5)
2 5 3 4
120
0
0
0
3
0
0
0
0
4
0
4
5
0
0
0
0
0
0
4
0
5
0
0
0
5
0
0
0
= +
= +
=
+
=
⋅⋅⋅
=
 

 
Section 3.6 
167 
 
6. 
3
0
11
5
0
3
0
5
0
3
0
0
2
4
13
6
5
2
4
6
5
4
5
5
5( 2)
2
4
5
10( 3)
60
0
0
5
0
0
7
6
17
7
6
7
7
6
7
7
6
9
17
7
0
0
2
0
0
0
8
2
0
−
−
−
−
= +
=
−
−
= −
+
=
−
 
 
7. 
2 2 1
1
1
1
1
1
1
2
2
2
0
0
0
0
3
3
3
3
3
3
R
R
−
=
=
 
 
8. 
2
1
2
3
4
2
3
4
2
3
2
3
1
0
0
5
5
5(4
9)
25
3
2
3
2
7
3
2
7
R
R
+
−
−
=
= −
= −
−
=
 
 
9. 
3 2 1
3
2
5
3
2
5
3
5
0
5
17
0
5
17
2
5(6
0)
30
0
2
6
4
12
0
0
2
R
R
−
−
−
=
= +
=
−
=
−
 
 
10. 
1 3 2
3
6
5
0
0
7
1
2
1
2
4
1
2
4
( 7)
7( 5
4)
7
2
5
2
5
12
2
5
12
R
R
+
−
−
−
−
−
=
−
−
= + −
= −
−+
=
−
−
−
 
 
11. 
4 2 1
1
2
3
4
1
2
3
4
5
6
7
0
5
6
7
0
5
6
7
8
9
1 0
8
9
5
5 8
40
0
0
8
9
0
0
8
9
0
1
0
0
1
2
4
6
9
0
0
0
1
R
R
−
=
= +
= +
=
⋅
=
 
 
12. 
4 2 1
2
0
0
3
2
0
0
3
1
11 12
0
1
11
12
0
1
11
12
5
13
2 0
5
13
2
2 5
10
0
0
5
13
0
0
5
13
0
1
0
0
1
4
0
0
7
0
0
0
1
R
R
+
−
−
=
= +
= +
=
⋅
=
−
 
 
13. 
2
3
1 4 3
4
4
1
4
4
1
0
20
11
20
11
1
2
2
0
2
5
0
2
5
1
100
22
78
2
5
1
4
3
1
4
3
1
4
3
R
R
R
R
+
+
−
−
−
−
−
−
=
=
= +
=
−
=
 
 

168 
Chapter 3 
14. 
2 3 1
3 5 1
1
2
4
2
2
1
1
3
1
1
3
2
14
3
1
5
3
1
5
0
2
14
1
22
1
18
5
4
3
5
4
3
0
1
18
R
R
R
R
R
R
−
+
−
−
−
−
−
=
−
=
−
−
= +
= −
−
−
−
−
 
 
15. 
1 2 3
2 5 3
2
5
4
0
13 14
0
13
14
13
14
5
3
1
5
3
1
0
17
24
1
74
17
24
1
4
5
1
4
5
1
4
5
R
R
R
R
+
−
−
=
=
−
−
= +
= −
−
−
 
 
16. 
1 2 3
2 2 3
2
4
2
10
0
4
10
0
4
10
4
5
4
1
5
4
1
13
0
1
2
84
13
1
4
2
1
4
2
1
4
2
1
R
R
R
R
−
+
−
−
−
−
−
−
−
=
−
−
−
=
−
= −
=
−
−
−
−
 
 
17. 
2
1
3
1
3
1
2
3
3
1
2
3
3
1
4
3
3
4
3
3
0
4
3
3
0
4
3
3
2
4
4
4
2 0
1
7
8
2
1
1
3
0
4
4
4
4
3
2
0
0
1
0
4
3
2
0
4
3
2
R
R
R
R
R
R
+
+
−
−
−
−
−
=
=
−
−
−
=
−
−
=
−
−
−
−
−
−
−
−
−
−
−
−
−
 
 
18. 
2 9 1
3 3 1
3
1
1
4
4
1
1
4
4
1
1
2
2
1
2
2
0
1
2
2
0
1
2
2
1 9
11
1
0
29
19
135
3
3
1
4
0
9
11
1
1
3
2
0
1
4
0
1
3
2
0
1
3
2
R
R
R
R
R
R
+
−
−
−
−
−
−
=
=
−
−
=
−
=
−
−
−
−
−
−
−
−
−
−
 
 
19. 
2 2 1
3 2 1
1
0
0
3
1
0
0
3
1
2
0
1
0
0
0
1
2
0
0
1
2
0
1 3
2
9
3
4
9
39
2
3
2
3
0
3
2
9
3
3
3
3
3
3
0
3
3
3
0
3
3
3
C
C
R
R
+
+
−
−
−
=
=
−
=
=
−
−
−
−
−
−
−
−
 
 
20. 
2 2 1
2 2 1
4
1
3
1
1
2
1
1
1
2
1
1
3
1
5
3
1
5
2
1
3
3
0
3
1
5
1 1
2
3
5
0
13
79
0
1
2
3
0
1
2
3
6
1
3
3
0
8
1
4
2
4
0
6
1
3
R
R
R
R
R
R
R
R
−
+
+
+
−
−
−
−
−
=
=
−
=
−
=
−
−
−
−
−
−
 
 
21. 
3
4
2
4
3
2
1
1
1;
10,
7
5
7
1
7
5
1
x
y
∆=
=
=
=
=
= −
∆
∆
 
 
22. 
5
8
3
8
5
3
1
1
1;
1,
1
8
13
5
13
8
5
x
y
∆=
=
=
= −
=
=
∆
∆
 

 
Section 3.6 
169 
 
23. 
17
7
6
7
17
6
1
1
1;
2,
4
12
5
4
5
12
4
x
y
∆=
=
=
=
=
= −
∆
∆
 
 
24. 
11 15
10
15
11 10
1
1
1;
5,
3
8
11
7
11
8
7
x
y
∆=
=
=
=
=
= −
∆
∆
 
 
25. 
5
6
12
6
5
12
1
1
2;
6,
3
3
4
6
4
3
6
x
y
∆=
=
=
=
=
= −
∆
∆
 
 
26. 
6
7
3
7
6
3
1
1
1
2;
,
0
8
9
4
9
8
4
2
x
y
∆=
= −
=
=
=
=
∆
∆
 
 
27. 
1
5
2
2
1
2
2
1
1
1
5
3
96;
2
5
3
,
3
5
3
5
2
3
5
x
−
−
∆
=
−
=
=
−
−
=
∆
−
−
 
 
2
3
5
1
2
5
2
1
1
2
1
1
1
2
3
,
1
5
2
3
3
5
2
5
5
3
2
x
x
−
=
−
−
= −
=
−
= −
∆
∆
−
 
 
28. 
1
5
4
2
4
4
2
1
4
2
0
3
35;
2
0
3
,
7
2
1
1
1
1
1
x
−
−
∆
=
=
=
=
∆
−
−
 
 
2
3
5
4
2
5
4
4
1
3
1
2
2
2
3
,
2
0
2
7
7
2
1
1
2
1
1
x
x
−
=
=
=
=
∆
∆
−
 
 
29. 
1
3
1
5
3
1
5
1
4
4
3
23;
4
4
3
2,
1
0
5
2
0
5
x
−
−
−
−
∆
=
−
−
=
=
−
−
−
=
∆
−
−
 
 
2
3
3
3
5
3
1
3
1
1
4
4
3
3,
4
4
4
0
1
2
5
1
0
2
x
x
−
−
=
−
−
=
=
−
−
=
∆
∆
−
 

170 
Chapter 3 
30. 
1
1
4
2
3
4
2
1
1
4
2
1
56;
1
2
1
,
7
2
2
5
3
2
5
x
∆
=
=
=
= −
∆
−
−
−
−
−
 
 
2
3
1
3
2
1
4
3
1
9
1
2
4
1
1
,
4
2
1
14
7
2
3
5
2
2
3
x
x
=
=
=
=
∆
∆
−
−
−
−
 
 
31. 
1
2
0
5
3
0
5
1
8
4
5
3
14;
3
5
3
,
7
2
1
1
1
1
1
x
−
−
−
∆
=
−
=
=
−
= −
∆
−
 
 
2
3
2
3
5
2
0
3
1
10
1
1
4
3
3
,
4
5
3
7
7
2
1
1
2
1
1
x
x
−
−
−
=
= −
=
−
=
∆
∆
−
−
 
 
32. 
1
3
4
3
5
4
3
1
7
3
2
4
6;
7
2
4
,
3
3
2
1
3
2
1
x
−
−
∆
=
−
=
=
−
= −
∆
−
−
 
 
2
3
3
5
3
3
4
5
1
1
3
7
4
9,
3
2
7
8
3
3
1
3
2
3
x
x
−
=
=
=
−
=
∆
∆
−
 
 
33. 
1
4
4
4
1
det
4,
16
15
13
4 28
25
23
−




= −
=






A
A
 
 
34. 
1
2
3
12
1
det
35,
9
4
19
35 13
2
8
−
−
−




=
=
−
−




−


A
A
 
 
35. 
1
15
25
26
1
det
35,
10
5
8
35
15
25
19
−
−
−




=
=
−




−


A
A
 
 

 
Section 3.6 
171 
36. 
1
5
20
17
1
det
23,
10
17
11
23 1
4
8
−
−




=
=
−




−


A
A
 
 
37. 
1
11
14
15
1
det
29,
17
19
10
29
18
15
14
−
−
−




=
=
−




−
−


A
A
 
 
38. 
1
6
10
2
1
det
6,
15
21
6
6 12
18
6
−
−




=
=
−
−




−
−


A
A
 
 
39. 
1
21
1
13
1
det
37,
4
9
6
37
6
5
9
−
−
−
−




=
=




−
−


A
A
 
 
40. 
1
9
12
13
1
det
107,
11
21
4
107
15
20
14
−
−




=
=
−
−




−
−
−


A
A
 
 
41. 
If  
[
]
1
1
2
2
and


=
=




a
A
B
b
b
a
  in terms of the two row vectors of  A  and the two column 
vectors of  B, then  
1
1
1
2
2
1
2
2


= 



a b
a b
AB
a b
a b
,  so 
(
)
1
1
2
1
1
1
1
1
2
2
2
2
,
T
T
T
T
T
T
T






=
=
=










a b
a b
b
AB
a
a
B A
a b
a b
b
 
 
 
because the rows of  A  are the columns of  AT  and the columns of  B  are the rows of  BT. 
 
42. 
det
det
a
b
a
b
a
b
c
d
c
d
c
d
c
d


+


=
=
=
+




+
+
+




x
x
y
x
y
AB
y
x
y
x
y
x
y  
 
ac
ad
bc
bd
ad
bc
=
+
+
+
=
+
x
x
y
y
x
y
x
y
x
y
y
x  
 
(
)
(det
)(det
)
ad
bc
ad
bc
=
−
=
−
=
x
x
x
A
B
y
y
y
 

172 
Chapter 3 
 
43. 
We expand the left-hand determinant along its first column: 
 
 
 
(
)
(
)
(
)
(
)
(
)
(
)
11
12
13
21
22
23
31
32
33
11
12
23
22
13
21
12
33
32
13
31
12
23
22
13
11
12
23
22
13
21
12
33
32
13
31
12
23
22
13
11
12
13
21
22
23
31
32
33
ka
a
a
ka
a
a
ka
a
a
ka
a a
a a
ka
a a
a a
ka
a a
a a
k a
a a
a a
a
a a
a a
a
a a
a a
a
a
a
k a
a
a
a
a
a
=
−
−
−
+
−


=
−
−
−
+
−


=
 
 
44.  
We expand the left-hand determinant along its third row: 
 
 
(
)
(
)
(
)
(
)
(
)
(
)
21
22
23
11
12
13
31
32
33
31
22
13
23 12
32
21 13
23
11
33
21 13
22
11
31
23
12
22
13
32
23
11
21 13
33
22
11
21 13
11
12
13
21
22
23
31
32
33
a
a
a
a
a
a
a
a
a
a
a a
a a
a
a a
a a
a
a a
a a
a
a a
a a
a
a a
a a
a
a a
a a
a
a
a
k a
a
a
a
a
a
=
−
−
−
+
−


= −
−
−
−
+
−


=
 
 
45. 
We expand the left-hand determinant along its third column: 
 
 
 
(
)(
) (
)(
) (
)(
)
(
)
(
)
(
)
(
)
(
)
(
)
1
1
1
1
2
2
2
2
3
3
3
3
1
1
2 3
3 2
2
2
1 3
3 1
3
3
1 2
2 1
1
2 3
3 2
2
1 3
3 1
3
1 2
2 1
1
2 3
3 2
2
1 3
3 1
3
1 2
2 1
1
1
1
1
1
1
2
2
2
2
2
2
3
3
3
3
3
3
a
b
c
d
a
b
c
d
a
b
c
d
c
d
a b
a b
c
d
a b
a b
c
d
a b
a b
c a b
a b
c
a b
a b
c
a b
a b
d
a b
a b
d
a b
a b
d
a b
a b
a
b
c
a
b
d
a
b
c
a
b
d
a
b
c
a
b
d
+
+
+
=
+
−
−
+
−
+
+
−
=
−
−
−
+
−
+
−
−
−
+
−
=
+
 
 
 
 

 
Section 3.6 
173 
46. 
We expand the left-hand determinant along its first column: 
 
 
 
(
)(
) (
)(
) (
)(
)
(
)
(
)
(
)
(
)
(
)
(
)
1
1
1
1
2
2
2
2
3
3
3
3
1
1
2 3
3 2
2
2
1 3
3 3
3
3
1 2
2 1
1
2 3
3 2
2
1 3
3 3
3
1 2
2 1
1
2 3
3 2
2
1 3
3 3
3
1 2
2 1
1
1
1
1
1
1
2
2
2
2
2
2
3
3
3
3
3
3
a
kb
b
c
a
kb
b
c
a
kb
b
c
a
kb
b c
b c
a
kb
b c
c b
a
kb
b c
b c
a b c
b c
a
b c
c b
a
b c
b c
k b b c
b c
b
b c
c b
b b c
b c
a
b
c
b
b
d
a
a
b
c
k b
b
d
a
b
c
b
b
d
+
+
+
=
+
−
−
+
−
+
+
−


=
−
−
−
+
−




+
−
−
−
+
−


=
+
=
1
1
1
2
2
2
3
3
3
b
c
a
b
c
a
b
c
 
 
47. 
We illustrate these properties with 2 2
×  matrices  
and
.
ij
ij
a
b




=
=




A
B
 
 
(a) 
(
)
11
21
11
12
12
22
22
22
T
T
T
a
a
a
a
a
a
a
a




=
=
=








A
A  
 
(b) 
(
)
11
12
11
21
11
21
21
22
12
22
12
22
T
T
T
ca
ca
ca
ca
a
a
c
c
c
ca
ca
ca
ca
a
a






=
=
=
=












A
A  
 
(c) 
(
)
11
11
12
12
11
11
21
21
21
21
22
22
12
12
22
22
T
T
a
b
a
b
a
b
a
b
a
b
a
b
a
b
a
b
+
+
+
+




+
=
=




+
+
+
+




A
B
 
 
 
11
21
11
21
12
22
12
22
T
T
a
a
b
b
a
a
b
b




=
+
=
+








A
B  
 
48. 
The ijth element of  (
)T
AB
 is the jith element of  AB, and hence is the product of the jth 
row of  A  and the ith column of  B.  The ijth element of  
T
T
B A  is the product of the ith row 
of  
T
B  and the jth column of  
.
T
A
 Because transposition of a matrix changes the ith row to 
the ith column and vice versa, it follows that the ijth element of  
T
T
B A  is the product of the 
jth row of  A  and the ith column of  B.  Thus the matrices  (
)T
AB
 and  
T
T
B A  have the 
same ijth elements, and hence are equal matrices. 
 
49. 
If we write  
1
1
1
1
2
3
2
2
2
1
2
3
3
3
3
1
2
3
and
,
T
a
b
c
a
a
a
a
b
c
b
b
b
a
b
c
c
c
c
=
=
A
A
 then expansion of  A  along its 
first row and of  
T
A
 along its first column both give the result 
(
)
(
)
(
)
1
2 3
3 2
1
2 3
3 2
1
2 3
3 2 .
a b c
b c
b a c
a c
c a b
a b
−
+
−
+
−
 

174 
Chapter 3 
50. 
If  
2 =
A
A   then  
2 =
A
A , so  
(
)
2
1
0,
−
=
−
=
A
A
A
A
 and hence it follows 
immediately that either  
0 or
1.
=
=
A
A
 
 
51. 
If  
then
,
n
n =
=
A
0
A
0  so it follows immediately that  
.
=
A
0  
 
52. 
If  
1
T
−
=
A
A  then  
1
1
.
T
−
−
=
=
=
A
A
A
A
  Hence  
2
1,
=
A
 so it follows that  
1.
= ±
A
 
 
53. 
If  
1
−
=
A
P BP  then  
1
1
1
.
−
−
−
=
=
=
=
A
P BP
P
B P
P
B P
B  
 
54. 
If  A  and  B  are invertible, then  
0 and
0.
≠
≠
A
B
  Hence  
0,
=
≠
AB
A B
  so it 
follows that  AB is invertible.  Conversely,  AB  invertible implies that  
0,
=
≠
AB
A B
 
 
so it follows that both  
0 and
0,
≠
≠
A
B
 and therefore that both  A  and  B  are 
invertible.   
 
55. 
If either  
or
=
=
AB
I
BA
I  is given, then it follows from Problem 54 that  A  and  B  are 
both invertible because their product (one way or the other) is invertible.  Hence  A–1  exists.  
So if (for instance) it is  
=
AB
I   that is given, then multiplication by  A–1  on the right 
yields  
1.
−
=
B
A
 
 
56. 
The matrix  A–1  in part (a) and the solution vector  x  in part (b) have only integer entries 
because the only division involved in their calculation — using the adjoint formula for the 
inverse matrix or Cramer's rule for the solution vector — is by the determinant  
1.
=
A
 
 
57. 
If  
1
1
0
then
0
.
0
0
0
0
a
d
f
bc
cd
de
bf
b
e
ac
ae
abc
b
ab
−
−
−








=
=
−












A
A
  
 
58. 
The coefficient determinant of the linear system 
 
 
 
 
cos
cos
cos
cos
cos
cos
c
B
b
C
a
c
A
a
C
b
b
A
a
B
c
+
=
+
=
+
=
 
 
 
in the unknowns  {
}
cos , cos , cos
A
B
C  is 
 
 
 
 
 
0
0
2
.
0
c
b
c
a
abc
b
a
=
 

 
Section 3.6 
175 
Hence Cramer's rule gives 
 
 
 
2
3
2
2
2
2
1
cos
0
,
2
2
2
0
a
c
b
ab
a
ac
b
a
c
A
b
a
abc
abc
bc
c
a
−
+
−
+
=
=
=
 
 
whence  
2
2
2
2
cos .
a
b
c
bc
A
=
+
−
 
 
59. 
These are almost immediate computations. 
 
60. 
(a) 
In the 4 4
×  case, expansion along the first row gives 
 
 
 
2
1
0
0
2
1
0
1
1
0
2
1
0
1
2
1
0
2
1
2 1
2
1
0
2
1
2 1
2
1
,
0
1
2
1
1
2
0
1
2
0
1
2
0
1
2
0
0
1
2
=
−
=
−
 
 
 
so  
4
3
2
2
2(4)
(3)
5.
B
B
B
=
−
=
−
=
  The general recursion formula  
1
2
2
n
n
n
B
B
B
−
−
=
−
  
 
results in the same way upon expansion along the first row. 
 
(b) 
If we assume inductively that 
 
 
 
 
1
2
(
1) 1
and
(
2) 1
1,
n
n
B
n
n
B
n
n
−
−
=
−
+ =
=
−
+ =
−
 
 
 
then the recursion formula of part (a) yields 
 
 
 
 
1
2
2
2( )
(
1)
1.
n
n
n
B
B
B
n
n
n
−
−
=
−
=
−
−
=
+
 
 
61. 
Subtraction of the first row from both the second and the third row gives 
 
 
 
[
]
2
2
2
2
2
2
2
2
2
2
2
2
1
1
1
0
(
)(
)
(
)(
)
1
0
(
)(
)(
)
(
)(
)(
)
(
)(
) (
)
(
)
(
)(
)(
).
a
a
a
a
b
b
b
a
b
a
b
a c
a
c
a b
a
c
c
c
a
c
a
b
a c
a c
a
c
a b
a b
a
b
a c
a
c
a
b
a
b
a c
a c
b
=
−
−
=
−
−
−
−
−
−
−
=
−
−
+
−
−
−
+
=
−
−
+
−
+
=
−
−
−
 
 
62. 
Expansion of the 4 4
×  determinant defining  
( )
P y  along its 4th row yields 
 
 
 

176 
Chapter 3 
 
 
2
1
1
3
2
3
2
2
1
2
3
2
3
3
1
( )
1
( ,
,
)
1
x
x
P y
y
x
x
y V x x
x
x
x
=
+
=
+

 lower-degree terms in  y. 
 
Because it is clear from the determinant definition of  ( )
P y  that  
1
2
3
(
)
(
)
(
)
0,
P x
P x
P x
=
=
=
 the three roots of the cubic polynomial  
( )
P y  are  
1
2
3
,
,
.
x x
x   
The factor theorem therefore says that
1
2
3
( )
(
)(
)(
)
P y
k y
x
y
x
y
x
=
−
−
−
 for some constant  
k,  and the calculation above implies that 
 
 
 
1
2
3
3
1
3
2
2
1
( ,
,
)
(
)(
)(
).
k
V x x x
x
x
x
x
x
x
=
=
−
−
−
 
 
Finally we see that   
 
 
1
2
3
4
4
1
2
3
4
1
4
2
4
1
4
1
4
2
4
1
3
1
3
2
2
1
( ,
,
,
)
(
)
( ,
,
) (
)(
)(
)
(
)(
)(
)(
)(
)(
),
V x x
x x
P x
V x x x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
=
=
⋅
−
−
−
=
−
−
−
−
−
−
 
 
which is the desired formula for  
1
2
3
4
( ,
,
,
)
V x x x x
. 
 
 
63. 
The same argument as in Problem 62 yields 
 
 
 
1
2
1
1
2
1
( )
( ,
,
,
) (
)(
)
(
).
n
n
P y
V x x
x
y
x
y
x
y
x
−
−
=
⋅
−
−
⋅
⋅
−


 
 
Therefore 
 
 
1
2
1
2
1
1
2
1
1
1
2
1
( ,
,
,
)
(
)(
)
(
) ( ,
,
,
)
(
)(
)
(
)
(
)
(
).
n
n
n
n
n
n
n
n
n
n
n
i
j
i
j
n
i
j
i
j
V x x
x
x
x
x
x
x
x
V x x
x
x
x
x
x
x
x
x
x
x
x
−
−
−
−
>
>
=
−
−
⋅
⋅
−
=
−
−
⋅
⋅
−
−
=
−
∏
∏




 
 
 
64. 
(a) 
V(1, 2, 3, 4)  =  (4 – 1)(4 – 2)(4 – 3)(3 – 1)(3 – 2)(2 – 1)  =  12 
(b) 
V(–1, 2,–2, 3)  = 
 
 
(
) [
]
(
)
(
) (
)
(
)
(
)
3
1
3
2
3
2
2
1
2
2
2
1
240







−−
−
−−
−
−−
−
−
−−
=







 
 
 
 
 

 
Section 3.7 
177 
SECTION 3.7 
 
LINEAR EQUATIONS AND CURVE FITTING 
 
In Problems 1–10 we first set up the linear system in the coefficients  , ,
a b … that we get by 
substituting each given point  ( ,
)
i
i
x y  into the desired interpolating polynomial equation  
.
y
a
bx
=
+
+   Then we give the polynomial that results from solution of this linear system. 
 
1. 
( )
y x
a
bx
=
+
 
 
1
1
1
2,
3
so
( )
2
3
1
3
7
a
a
b
y x
x
b



=
⇒
= −
=
= −
+






 
 
2. 
( )
y x
a
bx
=
+
 
 
1
1
11
4,
7
so
( )
4
7
1
2
10
a
a
b
y x
x
b
−




=
⇒
=
= −
=
−




−




 
 
3. 
2
( )
y x
a
bx
cx
=
+
+
 
 
2
1
0
0
3
1
1
1
1
3,
0,
2
so
( )
3
2
1
2
4
5
a
b
a
b
c
y x
x
c








=
⇒
=
=
= −
=
−








−




 
 
4. 
2
( )
y x
a
bx
cx
=
+
+
 
 
2
1
1
1
1
1
1
1
5
0,
2,
3
so
( )
2
3
1
2
4
16
a
b
a
b
c
y x
x
x
c
−








=
⇒
=
=
=
=
+












 
 
5. 
2
( )
y x
a
bx
cx
=
+
+
 
 
2
1
1
1
3
1
2
4
3
5,
3,
1
so
( )
5
3
1
3
9
5
a
b
a
b
c
y x
x
x
c






=
⇒
=
= −
=
=
−
+









 
 
6. 
2
( )
y x
a
bx
cx
=
+
+
 
 
1
1
1
1
1
3
9
13
1
5
25
5
a
b
c
−
−








=
−












 

178 
Chapter 3 
 
2
10,
7,
2
so
( )
10
7
2
a
b
c
y x
x
x
⇒
= −
= −
=
= −
−
+
 
 
7. 
2
3
( )
y x
a
bx
cx
dx
=
+
+
+
 
 
1
1
1
1
1
1
0
0
0
0
1
1
1
1
1
1
2
4
8
4
a
b
c
d
−
−












=








−




 
 
(
)
2
3
4
4
1
0,
,
1,
so
( )
4
3
4
3
3
3
a
b
c
d
y x
x
x
x
⇒
=
=
=
= −
=
+
−
 
 
8. 
2
3
( )
y x
a
bx
cx
dx
=
+
+
+
 
 
1
1
1
1
3
1
0
0
0
5
1
1
1
1
7
1
2
4
8
3
a
b
c
d
−
−









=









 
 
3
5,
3,
0,
1
so
( )
5
3
a
b
c
d
y x
x
x
⇒
=
=
=
= −
=
+
−
 
 
9. 
2
3
( )
y x
a
bx
cx
dx
=
+
+
+
 
 
1
2
4
8
2
1
1
1
1
2
1
1
1
1
10
1
2
4
8
26
a
b
c
d
−
−
−








−
−




=












 
 
2
3
4,
3,
2,
1
so
( )
4
3
2
a
b
c
d
y x
x
x
x
⇒
=
=
=
=
=
+
+
+
 
 
10. 
2
3
( )
y x
a
bx
cx
dx
=
+
+
+
 
 
1
1
1
1
17
1
1
1
1
5
1
2
4
8
3
1
3
9
27
2
a
b
c
d
−
−








−




=








−




 
 
2
3
17,
5,
3,
2
so
( )
17
5
3
2
a
b
c
d
y x
x
x
x
⇒
=
= −
=
= −
=
−
+
−
 
 
In Problems 11–14 we first set up the linear system in the coefficients  ,
,
A B C   that we get by 
substituting each given point  ( ,
)
i
i
x y  into the circle equation  
2
2
Ax
By
C
x
y
+
+
= −
−
  (see  
Eq. (9) in the text).  Then we give the circle that results from solution of this linear system. 
 

 
Section 3.7 
179 
11. 
2
2
Ax
By
C
x
y
+
+
= −
−
 
 
1
1 1
2
6
6
1
72
6,
4,
12
7
5
1
74
A
B
A
B
C
C
−
−
−








=
−
⇒
= −
= −
= −








−




 
 
2
2
6
4
12
0
x
y
x
y
+
−
−
−
=
 
 
2
2
(
3)
(
2)
25
x
y
−
+
−
=
 
center  (3, 2)  and radius  5 
 
12. 
2
2
Ax
By
C
x
y
+
+
= −
−
 
 
3
4
1
25
5
10
1
125
6,
8,
75
9
12
1
225
A
B
A
B
C
C
−
−








=
−
⇒
=
= −
= −








−
−




 
 
2
2
6
8
75
0
x
y
x
y
+
+
−
−
=
 
 
2
2
(
3)
(
4)
100
x
y
+
+
−
=
 
center  (–3, 4)  and radius  10 
 
13. 
2
2
Ax
By
C
x
y
+
+
= −
−
 
 
1
0
1
1
0
5
1
25
4,
4,
5
5
4
1
41
A
B
A
B
C
C
−








−
=
−
⇒
=
=
= −








−
−
−




 
 
2
2
4
4
5
0
x
y
x
y
+
+
+
−
=
 
 
2
2
(
2)
(
2)
13
x
y
+
+
+
=
 
center  (–3, –2)  and radius  13  
 
14. 
2
2
Ax
By
C
x
y
+
+
= −
−
 
 
0
0
1
0
10
0
1
100
10,
24,
0
7
7
1
98
A
B
A
B
C
C








=
−
⇒
= −
= −
=








−
−




 
 
2
2
10
24
0
x
y
x
y
+
−
−
=
 
 
2
2
(
5)
(
12)
169
x
y
−
+
−
=
 
center  (5, 12)  and radius  13 
 
In Problems 15–18 we first set up the linear system in the coefficients  ,
,
A B C   that we get by 
substituting each given point  ( ,
)
i
i
x y  into the central conic equation  
2
2
1
Ax
Bxy
Cy
+
+
=   (see  
Eq. (10) in the text).  Then we give the equation that results from solution of this linear system. 
 

180 
Chapter 3 
15. 
2
2
1
Ax
Bxy
Cy
+
+
=  
 
0
0
25
1
1
1
1
25
0
0
1
,
,
25
25
25
25
25
25
1
A
B
A
B
C
C






=
⇒
=
= −
=









 
 
2
2
25
x
xy
y
−
+
=
 
 
16. 
2
2
1
Ax
Bxy
Cy
+
+
=  
 
0
0
25
1
1
7
1
25
0
0
1
,
,
25
100
25
100
100
100
1
A
B
A
B
C
C






=
⇒
=
= −
=









 
 
2
2
4
7
4
100
x
xy
y
−
+
=
 
 
17. 
2
2
1
Ax
Bxy
Cy
+
+
=  
 
0
0
1
1
199
1
0
0
1
1,
,
1
100
100
100
100
1
A
B
A
B
C
C






=
⇒
=
= −
=









 
 
2
2
100
199
100
100
x
xy
y
−
+
=
 
 
18. 
2
2
1
Ax
Bxy
Cy
+
+
=  
 
0
0
16
1
1
481
1
9
0
0
1
,
,
9
3600
16
25
25
25
1
A
B
A
B
C
C






=
⇒
=
= −
=









 
 
2
2
400
481
225
3600
x
xy
y
−
+
=
 
19. 
We substitute each of the two given points into the equation 
B
y
A
x
=
+
. 
 
1
1
5
2
3,
2 so
3
1
4
1
2
A
A
B
y
B
x





=
⇒
=
=
=
+









 
 
20. 
We substitute each of the three given points into the equation 
2 .
B
C
y
Ax
x
x
=
+
+
 

 
Section 3.7 
181 
 
2
1
1
1
2
1
1
8
16
2
20
10,
8,
16 so
10
2
4
41
1
1
4
4
16
A
B
A
B
C
y
x
x
x
C












=
⇒
=
=
= −
=
+
−

















 
 
 
In Problems 21 and 22 we fit the sphere equation  
2
2
2
2
(
)
(
)
(
)
x
h
y
k
z
l
r
−
+
−
+
−
=
 in the expanded 
form  
2
2
2
Ax
By
Cz
D
x
y
z
+
+
+
= −
−
−
 that is analogous to Eq. (9) in the text (for a circle). 
 
21. 
2
2
2
Ax
By
Cz
D
x
y
z
+
+
+
= −
−
−
 
 
4
6
15
1
277
13
5
7
1
243
2,
4,
6,
155
5
14
6
1
257
5
5
9
1
131
A
B
A
B
C
D
C
D
−










−





=
⇒
= −
= −
= −
= −





−





−
−





 
 
2
2
2
2
4
6
155
0
x
y
z
x
y
z
+
+
−
−
−
−
=
 
 
2
2
2
(
1)
(
2)
(
3)
169
x
y
z
−
+
−
+
−
=
 
center  (1, 2, 3)  and radius  13 
 
22. 
2
2
2
Ax
By
Cz
D
x
y
z
+
+
+
= −
−
−
 
 
11
17
17
1
699
29
1
15
1
1067
10,
14,
18,
521
13
1
33 1
1259
19
13
1
1
531
A
B
A
B
C
D
C
D
−










−





=
⇒
= −
=
= −
= −





−
−





−
−
−





 
 
2
2
2
10
14
18
521
0
x
y
z
x
y
z
+
+
−
+
−
−
=
 
 
2
2
2
(
5)
(
7)
(
9)
676
x
y
z
−
+
+
+
−
=
 center  (5, –7, 9)  and radius  26 
 
In Problems 23–26 we first take t = 0 in 1970 to fit a quadratic polynomial  
2
( )
.
P t
a
bt
ct
=
+
+
  
Then we write the quadratic polynomial  
( )
(
1970)
Q T
P T
=
−
 that expresses the predicted 
population in terms of the actual calendar year  T.   
 
23. 
2
( )
P t
a
bt
ct
=
+
+
 
 
1
0
0
49.061
1
10
100
49.137
1
20
400
50.809
a
b
c








=












 

182 
Chapter 3 
 
2
( )
49.061 0.0722
0.00798
P t
t
t
=
−
+
 
 
2
( )
31160.9
31.5134
0.00798
Q T
T
T
=
−
+
 
 
 
24. 
2
( )
P t
a
bt
ct
=
+
+
 
 
1
0
0
56.590
1
10
100
58.867
1
20
400
59.669
a
b
c








=












 
 
 
2
( )
56.590
0.30145
0.007375
P t
t
t
=
+
−
 
 
2
( )
29158.9
29.3589
0.007375
Q T
T
T
= −
+
−
 
 
 
25. 
2
( )
P t
a
bt
ct
=
+
+
 
 
1
0
0
62.813
1
10
100
75.367
1
20
400
85.446
a
b
c








=












 
 
 
2
( )
62.813 1.37915
0.012375
P t
t
t
=
+
−
 
 
2
( )
50680.3
50.1367
0.012375
Q T
T
T
= −
+
−
 
 
 
26. 
2
( )
P t
a
bt
ct
=
+
+
 
 
1
0
0
34.838
1
10
100
43.171
1
20
400
52.786
a
b
c








=












 
 
 
2
( )
34.838
0.7692
0.00641
P t
t
t
=
+
+
 
 
2
( )
23396.1 24.4862
0.00641
Q T
T
T
=
−
+
 
 
 
In Problems 27–30 we first take t = 0 in 1960 to fit a cubic polynomial  
2
3
( )
.
P t
a
bt
ct
dt
=
+
+
+
  
Then we write the cubic polynomial  
( )
(
1960)
Q T
P T
=
−
 that expresses the predicted population 
in terms of the actual calendar year  T.   
 
 
 

 
Section 3.7 
183 
27. 
2
3
( )
P t
a
bt
ct
dt
=
+
+
+
 
 
1
0
0
0
44.678
1
10
100
1000
49.061
1
20
400
8000
49.137
1
30
900
27000
50.809
a
b
c
d












=












 
 
 
2
3
( )
44.678
0.850417
0.05105
0.000983833
P t
t
t
t
=
+
−
+
 
 
6
2
3
( )
7.60554 10
11539.4
5.83599
0.000983833
Q T
T
T
T
= −
×
+
−
+
 
 
28. 
2
3
( )
P t
a
bt
ct
dt
=
+
+
+
 
 
1
0
0
0
51.619
1
10
100
1000
56.590
1
20
400
8000
58.867
1
30
900
27000
59.669
a
b
c
d












=












 
 
 
2
3
( )
51.619
0.672433
0.019565
0.000203167
P t
t
t
t
=
+
−
+
 
 
6
2
3
( )
1.60618 10
2418.82
1.21419
0.000203167
Q T
T
T
T
= −
×
+
−
+
 
 
29. 
2
3
( )
P t
a
bt
ct
dt
=
+
+
+
 
 
1
0
0
0
54.973
1
10
100
1000
62.813
1
20
400
8000
75.367
1
30
900
27000
85.446
a
b
c
d












=












 
 
 
2
3
( )
54.973
0.308667
0.059515
0.00119817
P t
t
t
t
=
+
+
−
 
 
6
2
3
( )
9.24972 10
14041.6
7.10474
0.00119817
Q T
T
T
T
=
×
−
+
−
 
 
30. 
2
3
( )
P t
a
bt
ct
dt
=
+
+
+
 
 
1
0
0
0
28.053
1
10
100
1000
34.838
1
20
400
8000
43.171
1
30
900
27000
52.786
a
b
c
d












=












 
 
 
2
3
( )
28.053
0.592233
0.00907
0.0000443333
P t
t
t
t
=
+
+
−
 
 
2
3
( )
367520
545.895
0.26975
0.0000443333
Q T
T
T
T
=
−
+
−
 

184 
Chapter 3 
In Problems 31–34 we take t = 0 in 1950 to fit a quartic polynomial 
2
3
4
( )
.
P t
a
bt
ct
dt
et
=
+
+
+
+
  
Then we write the quartic polynomial  
( )
(
1950)
Q T
P T
=
−
 that expresses the predicted 
population in terms of the actual calendar year  T.   
 
 
31. 
2
3
4
( )
.
P t
a
bt
ct
dt
et
=
+
+
+
+
 
 
1
0
0
0
0
39.478
1
10
100
1000
10000
44.678
1
20
400
8000
160000
49.061
1
30
900
27000
810000
49.137
1
40
1600
64000
2560000
50.809
a
b
c
d
e
















=
















 
 
 
2
3
4
( )
39.478
0.209692
0.0564163
0.00292992
0.0000391375
P t
t
t
t
t
=
+
+
−
+
 
 
8
6
2
3
4
( )
5.87828 10
1.19444 10
910.118
0.308202
0.0000391375
Q T
T
T
T
T
=
×
−
×
+
−
+
 
 
 
32. 
2
3
4
( )
.
P t
a
bt
ct
dt
et
=
+
+
+
+
 
 
1
0
0
0
0
44.461
1
10
100
1000
10000
51.619
1
20
400
8000
160000
56.590
1
30
900
27000
810000
58.867
1
40
1600
64000
2560000
59.669
a
b
c
d
e
















=
















 
 
 
2
3
6
4
( )
44.461 0.7651
0.000489167
0.000516
7.19167 10
P t
t
t
t
t
−
=
+
−
−
+
×
 
 
8
2
3
6
4
( )
1.07807 10
219185
167.096
0.056611
7.19167 10
Q T
T
T
T
T
−
=
×
−
+
−
+
×
 
 
 
33. 
2
3
4
( )
.
P t
a
bt
ct
dt
et
=
+
+
+
+
 
 
1
0
0
0
0
47.197
1
10
100
1000
10000
54.973
1
20
400
8000
160000
62.813
1
30
900
27000
810000
75.367
1
40
1600
64000
2560000
85.446
a
b
c
d
e
















=
















 
 
 
2
3
4
( )
47.197 1.22537
0.0771921
0.00373475
0.0000493292
P t
t
t
t
t
=
+
−
+
−
 
 
8
6
2
3
4
( )
7.41239 10
1.50598 10
1147.37
0.388502
0.0000493292
Q T
T
T
T
T
= −
×
+
×
−
+
−
 
 

 
Section 3.7 
185 
34. 
2
3
4
( )
.
P t
a
bt
ct
dt
et
=
+
+
+
+
 
 
1
0
0
0
0
20.190
1
10
100
1000
10000
28.053
1
20
400
8000
160000
34.838
1
30
900
27000
810000
43.171
1
40
1600
64000
2560000
52.786
a
b
c
d
e
















=
















 
 
 
2
3
4
( )
20.190 1.00003
0.031775
0.00116067
0.00001205
P t
t
t
t
t
=
+
−
+
−
 
 
8
2
3
4
( )
1.8296 10
370762
281.742
0.0951507
0.00001205
Q T
T
T
T
T
= −
×
+
−
+
−
 
 
35. 
Expansion of the determinant along the first row gives an equation of the form  
 
2
0
ay
bx
cx
d
+
+
+
=
 that can be solved for  
2
.
y
Ax
Bx
C
=
+
+
 If the coordinates of any  
one of the three given points  
1
1
2
2
3
3
( ,
), (
,
), (
,
)
x y
x
y
x
y
are substituted in the first row, then 
the determinant has two identical rows and therefore vanishes. 
 
36. 
Expansion of the determinant along the first row gives 
 
2
2
1
1
1
1
3
1
1
3
1
1
3
1
1
3
1
1
1
4
2
1
3
2
1
3
4
1
3
4
2
3
4
2
1
9
3
1
7
3
1
7
9
1
7
9
3
7
9
3
1
y
x
x
y
x
x
=
−
+
−
=  
 
 
 
 
 
2
2
4
12
14
0
y
x
x
−
+
−
+
=
. 
 
 
Hence  
2
2
6
7
y
x
x
=
−
+
  is the parabola that interpolates the three given points. 
 
37. 
Expansion of the determinant along the first row gives an equation of the form  
2
2
(
)
0,
a x
y
bx
cy
d
+
+
+
+
=
 and we get the desired form of the equation of a circle upon 
division by  a.  If the coordinates of any one of the three given points  
1
1
2
2
( ,
), (
,
),
x y
x
y
 and 
3
3
(
,
)
x
y
 are substituted in the first row, then the determinant has two identical rows and 
therefore vanishes. 
 
38. 
Expansion of the determinant along the first row gives 
 
 
 
2
2
1
25
3
4
1
125
5
10
1
225
9
12
1
x
y
x
y
+
−
=
−
 
 

186 
Chapter 3 
 
 
2
2
3
4
1
25
4
1
25
3
1
25
3
4
(
) 5
10
1
125
10
1
125
5
1
125
5
10
9
12
1
225
12
1
225
9
1
225
9
12
x
y
x
y
−
−
−
=
+
−
+
−
−
−
−
 
2
2
200(
) 1200
1600
15000
0.
x
y
x
y
=
+
+
−
−
=
 
 
 
Division by 200 and completion of squares gives  
2
2
(
3)
(
4)
100,
x
y
+
+
−
=
 so the circle has   
 
center  (–3, 4) and radius 10. 
 
 
39. 
Expansion of the determinant along the first row gives an equation of the form  
2
2
0,
ax
bxy
cy
d
+
+
+
=
 which can be written in the central conic form 
2
2
1
Ax
Bxy
Cy
+
+
=  upon division by  –d.  If the coordinates of any one of the three given 
points  
1
1
2
2
( ,
), (
,
),
x y
x
y
 and 
3
3
(
,
)
x
y
 are substituted in the first row, then the determinant 
has two identical rows and therefore vanishes. 
 
 
40. 
Expansion of the determinant along the first row gives 
 
 
 
2
2
1
0
0
16
1
9
0
0
1
25
25
25
1
x
xy
y
=   
 
 
2
0
16
1
0
16
1
0
0
1
0
0
16
0
0
1
9
0
1
9
0
1
9
0
0
25
25
1
25
25
1
25
25
1
25
25
25
x
xy
y
=
−
+
−
 
2
2
400
481
225
3600
0.
x
xy
y
=
−
+
−
=
 

 
Section 4.1 
187 
 
CHAPTER 4 
  
VECTOR SPACES 
 
 
 
The treatment of vector spaces in this chapter is very concrete.  Prior to the final section of the 
chapter, almost all of the vector spaces appearing in examples and problems are subspaces of 
Cartesian coordinate spaces of n-tuples of real numbers.  The main motivation throughout is the 
fact that the solution space of a homogeneous linear system  Ax = 0  is precisely such a 
"concrete" vector space. 
 
 
SECTION 4.1 
 
THE VECTOR SPACE R3 
 
Here the fundamental concepts of vectors, linear independence, and vector spaces are introduced in 
the context of the familiar 2-dimensional coordinate plane R2 and 3-space R3.  The concept of a 
subspace of a vector space is illustrated, the proper nontrivial subspaces of R3 being simply lines 
and planes through the origin.  
 
1. 
(2,5, 4)
(1, 2, 3)
(1,7, 1)
51
−
=
−
−
−
−
=
−
=
a
b
 
 
2
2(2,5, 4)
(1, 2, 3)
(4,10, 8)
(1, 2, 3)
(5,8, 11)
3
4
3(2,5, 4)
4(1, 2, 3)
(6,15, 12)
(4, 8, 12)
(2,23,0)
+
=
−
+
−
−
=
−
+
−
−
=
−
−
=
−
−
−
−
=
−
−
−
−
=
a
b
a
b
 
 
2. 
( 1,0,2)
(3,4, 5)
( 4, 4,7)
81
9
−
=
−
−
−
=
−
−
=
=
a
b
 
 
2
2( 1,0,2)
(3,4, 5)
( 2,0,4)
(3,4, 5)
(1,4, 1)
3
4
3( 1,0,2)
4(3,4, 5)
( 3,0,6)
(12,16, 20)
( 15, 16,26)
+
=
−
+
−
=
−
+
−
=
−
−
=
−
−
−
=
−
−
−
=
−
−
a
b
a
b
 
 
3. 
(2
3
5 )
(5
3
7 )
3
6
12
189
3 21
−
=
−
+
−
+
−
= −
−
+
=
=
a
b
i
j
k
i
j
k
i
j
k
 
 
2
2(2
3
5 )
(5
3
7 )
(4
6
10 )
(5
3
7 )
9
3
3
3
4
3(2
3
5 )
4(5
3
7 )
(6
9
15 )
(20
12
28 )
14
21
43
+
=
−
+
+
+
−
=
−
+
+
+
−
=
−
+
−
=
−
+
−
+
−
=
−
+
−
+
−
= −
−
+
a
b
i
j
k
i
j
k
i
j
k
i
j
k
i
j
k
a
b
i
j
k
i
j
k
i
j
k
i
j
k
i
j
k
 
 
4. 
(2
)
(
3 )
2
2
3
17
−
=
−
−
−
=
−
+
=
a
b
i
j
j
k
i
j
k
 
 
2
2(2
)
(
3 )
(4
2 )
(
3 )
4
3
3
4
3(2
)
4(
3 )
(6
3 )
(4
12 )
6
7
12
+
=
−
+
−
=
−
+
−
=
−−
−
=
−
−
−
=
−
−
−
=
−
+
a
b
i
j
j
k
i
j
j
k
i
j
k
a
b
i
j
j
k
i
j
j
k
i
j
k
 
 

188 
Chapter 4 
5. 
3
2 ,
=
v
u  so the vectors  u  and  v  are linearly dependent. 
 
6. 
(0,2)
(3,0)
(3 ,2 )
a
b
a
b
b
a
+
=
+
=
=
u
v
0  implies  a = b = 0, so the vectors  u  and  v  
are linearly independent. 
 
7. 
(2,2)
(2, 2)
(2
2 ,2
2 )
a
b
a
b
a
b
a
b
+
=
+
−
=
+
−
=
u
v
0 implies  a = b = 0, so the vectors  
u  and  v  are linearly independent. 
 
8. 
,
= −
v
u  so the vectors  u  and  v  are linearly dependent. 
 
In each of Problems 9–14, we set up and solve (as in Example 2 of this section) the system 
 
 
 
 
1
1
1
2
2
2
u
v
w
a
a
b
u
v
w
b





+
=
=
=










u
v
w  
 
to find the coefficient values  a  and  b  such that  
,
a
b
=
+
w
u
v  
 
9. 
1
1
1
3,
2 so
3
2
2
3
0
a
a
b
b
−



=
⇒
=
=
=
+



−



w
u
v  
 
10. 
3
2
0
2,
3 so
2
3
4
3
1
a
a
b
b




=
⇒
=
= −
=
−




−




w
u
v  
 
11. 
5
2
1
1,
2 so
2
7
3
1
a
a
b
b



=
⇒
=
= −
=
−






w
u
v  
 
12. 
4
2
2
3,
5 so
3
5
1
1
2
a
a
b
b
−




=
⇒
=
=
=
+




−
−




w
u
v  
 
13. 
7
3
5
2,
2 so
2
3
5
4
2
a
a
b
b




=
⇒
=
= −
=
−




−




w
u
v  
 
14. 
5
6
5
7,
5 so
7
5
2
4
6
a
a
b
b
−



=
⇒
=
=
=
+



−



w
u
v  
 
 
In Problems 15–18, we calculate the determinant  u
v
w  so as to determine (using Theorem 
4) whether the three vectors  u,  v,  and  w  are linearly dependent (det = 0) or linearly 
independent (det ≠ 0).  
 

 
Section 4.1 
189 
 
15. 
3
5
8
1
4
3
0
2
6
4
−
=
−
−
  so the three vectors are linearly dependent. 
 
16. 
5
2
4
2
3
5
0
4
5
7
−
−
=
−
  so the three vectors are linearly dependent. 
 
17. 
1
3
1
1
0
2
5
0
2
1
2
−
−
= −
≠
  so the three vectors are linearly independent. 
 
18. 
1
4
3
1
3
2
9
0
0
1
4
−
=
≠
−
  so the three vectors are linearly independent. 
 
In Problems 19–24, we attempt to solve the homogeneous system  
=
Ax
0 by reducing the 
coefficient matrix  
[
]
=
A
u
v
w   to echelon form  E.  If we find that the system has only the 
trivial solution  a = b = c = 0, this means that the vectors  u,  v,  and  w  are linearly independent.  
Otherwise, a nontrivial solution  
[
]
T
a
b
c
=
≠
x
0  provides us with a nontrivial linear 
combination  a
b
c
+
+
≠
u
v
w
0 that shows the three vectors are linearly dependent. 
 
19. 
2
3
0
1
0
3
0
1
2
0
1
2
1
1
1
0
0
0
−
−








=
−
→
−
=








−
−




A
E  
The nontrivial solution  a = 3,  b = 2,  c = 1  gives  3u + 2v + w  =  0,  so the three vectors 
are linearly dependent. 
 
20. 
5
2
4
1
0
2
5
3
1
0
1
3
4
1
5
0
0
0








=
→
−
=












A
E  
The nontrivial solution  a = –2,  b = 3,  c = 1  gives  –2u + 3v + w  =  0,  so the three 
vectors are linearly dependent. 
 
21. 
1
2
3
1
0
11
1
1
7
0
1
4
2
6
2
0
0
0
−








=
−
→
=








−




A
E 

190 
Chapter 4 
The nontrivial solution  a = 11,  b = 4,  c = –1  gives  11u + 4v – w  =  0,  so the three 
vectors are linearly dependent. 
 
22. 
1
5
0
1
0
0
1
1
1
0
1
0
0
3
2
0
0
1








=
→
=












A
E 
The system  Ax = 0  has only the trivial solution  a = b = c = 0, so the vectors  u,  v,  and  
w  are linearly independent.   
 
23. 
2
5
2
1
0
0
0
4
1
0
1
0
3
2
1
0
0
1








=
−
→
=








−




A
E 
The system  Ax = 0  has only the trivial solution  a = b = c = 0, so the vectors  u,  v,  and  
w  are linearly independent.   
 
24. 
1
4
3
1
0
0
4
2
3
0
1
0
5
5
1
0
0
1
−








=
→
=








−




A
E 
The system  Ax = 0  has only the trivial solution  a = b = c = 0, so the vectors  u,  v,  and  
w  are linearly independent.   
 
 
In Problems 25–28, we solve the nonhomogeneous system  
=
Ax
t   by reducing the augmented 
coefficient matrix  
[
]
=
A
u
v
w
t   to echelon form  E.  The solution vector   
[
]
T
a
b
c
=
x
 appears as the final column of  E, and provides us with the desired linear 
combination  
.
a
b
c
=
+
+
t
u
v
w  
 
25. 
1
3
1
2
1
0
0
2
2
0
1
7
0
1
0
1
2
1
2
9
0
0
1
3








=
−
−
−
→
−
=












A
E  
Thus  a = 2,  b = –1,  c = 3  so  t  =  2u – v + 3w. 
 
26. 
5
1
5
5
1
0
0
1
2
5
3
30
0
1
0
5
2
3
4
21
0
0
1
1








=
−
→
=








−
−
−
−




A
E  
Thus  a = 1,  b = 5,  c = –1  so  t  =  u + 5v – w. 
 

 
Section 4.1 
191 
 
27. 
1
1
4
0
1
0
0
2
4
2
4
0
0
1
0
6
3
2
1
19
0
0
1
1
−








=
−
→
=












A
E  
Thus  a = 2,  b = 6,  c = 1  so  t  =  2u + 6v + w. 
 
28. 
2
4
1
7
1
0
0
1
5
1
1
7
0
1
0
1
3
1
5
7
0
0
1
1








=
→
=








−




A
E  
Thus  a = 1,  b = 1,  c = 1  so  t  =  u + v + w. 
 
29. 
Given vectors  (0, , ) and (0, ,
)
y z
v w  in  V, we see that their sum  (0,
,
)
y
v z
w
+
+
 and the 
scalar multiple  (0, , )
(0,
,
)
c
y z
cy cz
=
 both have first component 0, and therefore are 
elements of  V. 
 
30. 
If  ( , , ) and ( , ,
)
x y z
u v w  are in  V, then 
 
 
 
(
)
(
)
(
)
(
)
(
)
0
0
0,
x
v
y
u
z
w
x
y
z
u
v
w
+
+
+
+
+
=
+
+
+
+ +
=
+
=
 
 
 
so their sum  (
,
,
)
x
u y
v z
w
+
+
+
 is in  V.  Similarly,   
 
(
)
(0)
0,
cx
cy
cz
c x
y
x
c
+
+
=
+
+
=
=
 
 
 
so the scalar multiple  (
,
,
)
cx cy cz  is in  V. 
 
31. 
If  ( , , ) and ( , ,
)
x y z
u v w  are in  V, then 
 
 
 
2(
)
(2 )
(2 )
(3 )
(3 )
3(
),
x
u
x
u
y
v
y
v
+
=
+
=
+
=
+
 
 
 
so their sum  (
,
,
)
x
u y
v z
w
+
+
+
 is in  V.  Similarly,  
 
2(
)
(2 )
(3 )
3(
),
cx
c
x
c
y
cy
=
=
=
  
 
so the scalar multiple  (
,
,
)
cx cy cz  is in  V. 
 
32. 
If  ( , , ) and ( , ,
)
x y z
u v w  are in  V, then 
 
 
 
(2
3 )
(2
3 )
2(
)
3(
),
z
w
x
y
u
v
x
u
y
v
+
=
+
+
+
=
+
+
+
 
 

192 
Chapter 4 
 
so their sum  (
,
,
)
x
u y
v z
w
+
+
+
 is in  V.  Similarly,  
 
(2
3 )
2(
)
3(
),
cz
c
x
y
cx
cy
=
+
=
+
  
 
so the scalar multiple  (
,
,
)
cx cy cz  is in  V. 
 
33. 
(0,1,0)  is in  V  but the sum  (0,1,0)
(0,1,0)
(0,2,0)
+
=
 is not in  V; thus  V  is not 
closed under addition.  Alternatively,  2(0,1,0)
(0,2,0)
=
 is not in  V,  so  V  is not 
closed under multiplication by scalars. 
 
34. 
(1,1,1)  is in  V,  but   
 
 
 
 
2(1,1,1)
(1,1,1)
(1,1,1)
(2,2,2)
=
+
=
 
 
 
is not, so  V  is closed neither under addition of vectors nor under multiplication by 
scalars. 
 
35. 
Evidently  V  is closed under addition of vectors.  However,  (0,0,1)  is in  V  but  
( 1)(0,0,1)
(0,0, 1)
−
=
−
 is not, so  V  is not closed under multiplication by scalars. 
 
36. 
(1,1,1)  is in  V, but   
 
 
 
 
2(1,1,1)
(1,1,1)
(1,1,1)
(2,2,2)
=
+
=
 
 
 
is not, so  V  is closed neither under addition of vectors nor under multiplication by 
scalars. 
 
37. 
Pick a  fixed element  u  in the (nonempty) vector space  V.  Then, with  c = 0,  the scalar 
multiple  
0
c
=
=
u
u
0  must be in  V.  Thus  V  necessarily contains the zero vector  0. 
 
38. 
Suppose  u  and  v  are vectors in the subspace  V  of  R3  and  a  and  b  are scalars.  Then  
au  and  bv  are in  V  because  V  is closed under multiplication by scalars.  But then it 
follows that the linear combination  a
b
+
u
v  is in  V  because  V  is closed under addition 
of vectors. 
 
39. 
It suffices to show that every vector  v  in  V  is a scalar multiple of the given nonzero 
vector  u  in  V.  If  u  and  v  were linearly independent, then — as illustrated in Example 
2 of this section — every vector in R2 could be expressed as a linear combination of  u 
and  v.  In this case it would follow that  V  is all of  R2 (since, by Problem 38, V is closed 
under taking linear combinations).  But we are given that  V  is a proper subspace of  R2, 
so we must conclude that  u  and  v  are linearly dependent vectors.  Since  
0,
≠
u
 it 
follows that the arbitrary vector  v  in  V  is a scalar multiple of  u,  and thus  V  is 
precisely the set of all scalar multiples of  u.  In geometric language,  the subspace  V  is 
then the straight line through the origin determined by the nonzero vector  u. 

 
Section 4.1 
193 
 
40. 
Since the vectors  u, v, w  are linearly dependent , there exist scalars  p, q, r  not all zero 
such that  
.
p
q
r
+
+
=
u
v
w
0   If  r = 0,  then  p  and  q  are scalars not both zero such that  
.
p
q
+
=
u
v
0   But this contradicts the given fact that  u  and  v  are linearly independent.  
Hence  r ≠ 0,  so we can solve for 
 
 
 
 
,
p
q
a
b
r
r
= −
−
=
+
w
u
v
u
v  
 
 
thereby expressing  w  as a linear combination of  u  and  v. 
 
41. 
If the vectors  u  and  v  are in the intersection  V  of the subspaces  V1  and  V2,  then   
 
their sum  u + v  is in  V1  because both vectors are in  V1,  and  u + v  is in  V2  because 
both are in  V2.  Therefore  u + v  is in  V,  and thus  V  is closed under addition of 
vectors.  Similarly, the intersection  V  is closed under multiplication by scalars, and is 
therefore itself a subspace. 
 
 
 
SECTION 4.2 
 
THE VECTOR SPACE Rn AND SUBSPACES 
 
The main objective in this section is for the student to understand what types of subsets of the vector 
space Rn of n-tuples of real numbers are subspaces — playing the role in Rn of lines and planes 
through the origin in R3.  Our first reason for studying subspaces is the fact that the solution space 
of any homogeneous linear system  Ax = 0 is a subspace of Rn. 
 
1. 
If  
1
2
1
2
( ,
,0) and
(
,
,0)
x x
y y
=
=
x
y
 are vectors in W, then their sum   
 
1
2
1
2
1
1
2
2
( ,
,0)
(
,
,0)
(
,
,0)
x x
y y
x
y x
y
+
=
+
=
+
+
x
y
 
 
and the scalar multiple 
1
2
(
,
,0)
c
cx cx
=
x
 both have third coordinate zero, and therefore are 
also elements of  W.  Hence  W  is a subspace of  R3. 
 
2. 
Suppose  
1
2
3
1
2
3
( ,
,
) and
(
,
,
)
x x
x
y y
y
=
=
x
y
 are vectors in W, so  
1
2
5
and
x
x
=
 
1
2
5
.
y
y
=
 
Then their sum  
1
1
2
2
3
3
1
2
3
(
,
,
)
( ,
,
)
x
y x
y
x
y
s s s
=
+
=
+
+
+
=
s
x
y
satisfies the same 
condition   
 
 
 
1
1
1
2
2
2
2
2
5
5
5(
)
5 ,
s
x
y
x
y
x
y
s
=
+
=
+
=
+
=
 
 
and thus is an element of  W.  Similarly, the scalar multiple 
1
2
3
(
,
,
)
c
cx cx cx
=
=
=
m
x
  
1
2
3
(
,
,
)
m m m
satisfies the condition  
1
1
2
2
2
(5
)
5(
)
5
,
m
cx
c
x
cx
m
=
=
=
=
 and hence is also an 
element of  W.  Therefore  W  is a subspace of  R3. 
 

194 
Chapter 4 
3. 
The typical vector in  W  is of the form  
1
3
( ,1,
)
x
x
=
x
 with second coordinate 1.  But the 
particular scalar multiple  
1
3
2
(2 ,2,2
)
x
x
=
x
 of such a vector has second coordinate  2
1,
≠
 
and thus is not in  W.  Hence  W  is not closed under multiplication by scalars, and 
therefore is not a subspace of  R3.  (Since  2x = x + x,  W is not closed under vector addition 
either.) 
 
4. 
The typical vector  
1
2
3
( ,
,
)
x x
x
=
x
 in  W  has coordinate sum  
1
2
3
x
x
x
+
+
 equal to 1.  But 
then the particular scalar multiple  
1
2
3
2
(2 ,2
,2
)
x
x
x
=
x
 of such a vector has coordinate  
sum   
1
2
3
1
2
3
2
2
2
2(
)
2(1)
2
1,
x
x
x
x
x
x
+
+
=
+
+
=
=
≠
  
 
and thus is not in  W.  Hence  W  is not closed under multiplication by scalars, and 
therefore is not a subspace of  R3.  (Since  2x = x + x,  W is not closed under vector addition 
either.) 
 
5. 
Suppose  
1
2
3
4
1
2
3
4
( ,
,
,
) and
(
,
,
,
)
x x
x x
y y
y
y
=
=
x
y
 are vectors in W, so   
 
1
2
3
4
1
2
3
4
2
3
4
0
and
2
3
4
0.
x
x
x
x
y
y
y
y
+
+
+
=
+
+
+
=
   
 
Then their sum  
1
1
2
2
3
3
4
4
1
2
3
4
(
,
,
,
)
( ,
,
,
)
x
y x
y
x
y x
y
s s s s
=
+
=
+
+
+
+
=
s
x
y
satisfies the 
same condition   
 
 
1
2
3
4
1
1
2
2
3
3
4
4
1
2
3
4
1
2
3
4
2
3
4
(
)
2(
)
3(
)
4(
)
(
2
3
4
)
(
2
3
4
)
0
0
0,
s
s
s
s
x
y
x
y
x
y
x
y
x
x
x
x
y
y
y
y
+
+
+
=
+
+
+
+
+
+
+
=
+
+
+
+
+
+
+
=
+
=
 
 
 
 
 
and thus is an element of  W.  Similarly, the scalar multiple 
1
2
3
4
(
,
,
,
)
c
cx cx cx cx
=
=
=
m
x
  
1
2
3
4
(
,
,
,
)
m m m m
satisfies the condition   
 
 
1
2
3
4
1
2
3
4
1
2
3
4
2
3
4
2
3
4
(
2
3
4
)
0,
m
m
m
m
cx
cx
cx
cx
c x
x
x
x
+
+
+
=
+
+
+
=
+
+
+
=
 
 
and hence is also an element of  W.  Therefore  W  is a subspace of  R4. 
 
6. 
Suppose  
1
2
3
4
1
2
3
4
( ,
,
,
) and
(
,
,
,
)
x x
x x
y y
y
y
=
=
x
y
 are vectors in W, so   
 
1
3
2
4
1
3
2
4
3
,
4
and
3
,
4
.
x
x
x
x
y
y
y
y
=
=
=
=
   
 
Then their sum  
1
1
2
2
3
3
4
4
1
2
3
4
(
,
,
,
)
( ,
,
,
)
x
y x
y
x
y x
y
s s s s
=
+
=
+
+
+
+
=
s
x
y
satisfies the 
same conditions  
 
 
 
 
1
1
1
3
3
3
3
3
2
2
2
4
4
4
4
4
3
3
3(
)
3 ,
4
4
4(
)
4
,
s
x
y
x
y
x
y
s
s
x
y
x
y
x
y
s
=
+
=
+
=
+
=
=
+
=
+
=
+
=
 

 
Section 4.2 
195 
 
 
and thus is an element of  W.  Similarly, the scalar multiple 
1
2
3
4
(
,
,
,
)
c
cx cx cx cx
=
=
=
m
x
  
1
2
3
4
(
,
,
,
)
m m m m
satisfies the conditions   
 
 
1
1
3
3
3
2
2
4
4
4
(3
)
3(
)
3
,
(4
)
4(
)
4
,
m
cx
c
x
cx
m
m
cx
c
x
cx
m
=
=
=
=
=
=
=
=
 
 
and hence is also an element of  W.  Therefore  W  is a subspace of  R4. 
 
7. 
The vectors  
(1,1) and
(1, 1)
=
=
−
x
y
 are in  W,  but their sum  
(2,0)
+
=
x
y
 is not, 
because  2
0 .
≠
  Hence  W  is not a subspace of R2. 
 
8. 
W  is simply the zero subspace  { }
0  of R2.  
 
9. 
The vector  
(1,0)
=
x
 is in  W,  but its scalar multiple  2
(2,0)
=
x
  is not, because  
2
2
(2)
(0)
4
1.
+
=
≠
  Hence  W  is not a subspace of R2. 
 
10. 
The vectors  
(1,0) and
(0,1)
=
=
x
y
 are in  W,  but their sum  
(1,1)
=
+
=
s
x
y
 is not, 
because  1
1
2
1.
+
=
≠
  Hence  W  is not a subspace of R2. 
 
11. 
Suppose  
1
2
3
4
1
2
3
4
( ,
,
,
) and
(
,
,
,
)
x x
x x
y y
y
y
=
=
x
y
 are vectors in W, so   
 
1
2
3
4
1
2
3
4
and
.
x
x
x
x
y
y
y
y
+
=
+
+
=
+
   
 
Then their sum  
1
1
2
2
3
3
4
4
1
2
3
4
(
,
,
,
)
( ,
,
,
)
x
y x
y
x
y x
y
s s s s
=
+
=
+
+
+
+
=
s
x
y
satisfies the 
same condition 
 
 
 
 
1
2
1
1
2
2
1
2
1
2
3
4
3
4
3
3
4
4
3
4
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
s
s
x
y
x
y
x
x
y
y
x
x
y
y
x
y
x
y
s
s
+
=
+
+
+
=
+
+
+
=
+
+
+
=
+
+
+
=
+
 
 
and thus is an element of  W.  Similarly, the scalar multiple 
1
2
3
4
(
,
,
,
)
c
cx cx cx cx
=
=
=
m
x
  
1
2
3
4
(
,
,
,
)
m m m m
satisfies the condition   
 
 
1
2
1
2
1
2
3
4
3
4
3
4
(
)
(
)
,
m
m
cx
cx
c x
x
c x
x
cx
cx
m
m
+
=
+
=
+
=
+
=
+
=
+
 
 
and hence is also an element of  W.  Therefore  W  is a subspace of  R4. 
 
12. 
The vectors  
(1,0,1,0) and
(0,2,0,3)
=
=
x
y
 are in  W  (because both products are 0 in 
each case)  but their sum  
(1,2,1,3)
=
+
=
s
x
y
 is not, because  1 2
3 4
2 but
3.
s s
s s
=
=
  
Hence  W  is not a subspace of R4. 
 

196 
Chapter 4 
13. 
The vectors  
(1,0,1,0) and
(0,1,0,1)
=
=
x
y
 are in  W  (because the product of the 4 
components is 0 in each case)  but their sum  
(1,1,1,1)
=
+
=
s
x
y
 is not, because  
1 2 3 4
1
0.
s s s s = ≠
  Hence  W  is not a subspace of R4. 
 
14. 
The vector  
(1,1,1,1)
=
x
 is in  W  (because all 4 components are nonzero)  but the multiple  
0
(0,0,0,0)
=
x
 is not.  Hence  W  is not a subspace of R4. 
 
 
In Problems 15–22, we first reduce the coefficient matrix  A   to echelon form  E in order to 
solve the given homogeneous system 
=
Ax
0. 
 
15. 
1
4
1
4
1
0
1
4
1
2
1
8
0
1
0
2
1
1
1
6
0
0
0
0
−
−








=
→
=












A
E 
Thus  
3
4
and
x
s
x
t
=
=  are free variables.  We solve for  
1
2
4
and
2 ,
x
s
t
x
t
= −−
= −
 so 
 
1
2
3
4
( ,
,
,
)
(
4 , 2 , , )
(
,0, ,0)
( 4 , 2 ,0, )
x x
x x
s
t
t s t
s
s
t
t
t
s
t
=
=
−−
−
=
−
+ −
−
=
+
x
u
v  
 
 
where  
( 1,0,1,0) and
( 4, 2,0,1).
=
−
=
−
−
u
v
 
 
16. 
1
4
3
7
1
0
1
5
2
1
1
7
0
1
1
3
1
2
3
11
0
0
0
0
−
−
−








=
−
→
=












A
E  
Thus  
3
4
and
x
s
x
t
=
=  are free variables.  We solve for  
1
2
5
and
3 ,
x
s
t
x
s
t
= −−
= −−
 
so 
 
1
2
3
4
( ,
,
,
)
(
5 ,
3 , , )
(
,
, ,0)
( 5 , 3 ,0, )
x x
x x
s
t
s
t s t
s
s s
t
t
t
s
t
=
=
−−
−−
=
−
−
+ −
−
=
+
x
u
v  
 
 
where  
( 1, 1,1,0) and
( 5, 3,0,1).
=
−−
=
−
−
u
v
 
 
17. 
1
3
8
1
1
0
1
2
1
3
10
5
0
1
3
1
1
4
11
2
0
0
0
0
−
−








=
−
−
→
−
=








−




A
E 
Thus  
3
4
and
x
s
x
t
=
=  are free variables.  We solve for  
1
2
2
and
3
,
x
s
t
x
s
t
=
−
= −
+
 
so 
 

 
Section 4.2 
197 
 
1
2
3
4
( ,
,
,
)
(
5 ,
3 , , )
( , 3 , ,0)
( 2 , ,0, )
x x x x
s
t
s
t s t
s
s s
t t
t
s
t
=
=
−−
−−
=
−
+ −
=
+
x
u
v
 
 
 
where  
(1, 3,1,0) and
( 2,1,0,1).
=
−
=
−
u
v
 
 
18. 
1
3
2
5
1
1
0
0
2
3
2
7
4
11
2
0
1
0
1
4
2
6
5
12
7
0
0
1
2
5
−
−
−








=
→
=








−
−




A
E  
Thus  
4
5
and
x
s
x
t
=
=  are free variables.  We solve for  
1
2
2
3 ,
4 ,
x
s
t
x
s
t
=
+
= −−
 
3
and
2
5 ,
x
s
t
= −
+
 so 
 
1
2
3
4
5
( ,
,
,
,
)
(2
3 ,
4 , 2
5 , , )
(2 ,
, 2 , ,0)
(3 , 4 ,5 ,0, )
x x x x x
s
t
s
t
s
t s t
s
s
s s
t
t
t
t
s
t
=
=
+
−−
−
+
=
−
−
+
−
=
+
x
u
v
 
 
 
where  
(2, 1, 2,1,0) and
(3, 4,5,0,1).
=
−−
=
−
u
v
 
 
19. 
1
3
5
6
1
0
1
0
2
1
4
4
0
1
2
0
1
3
7
1
0
0
0
1
−
−
−








=
−
→
=












A
E  
Thus  
3x
t
=  is a free variable and  
4
0.
x =
.  We solve for  
1
2
and
2 ,
x
t
x
t
= −
= −
 so 
 
1
2
3
4
( ,
,
,
)
(
, 2 , ,0)
x x x x
t
t t
t
=
=
−−
=
x
u  
 
 
where  
( 1, 2,1,0).
=
−−
u
 
 
20. 
1
5
1
8
1
0
0
5
2
5
0
5
0
1
0
3
2
7
1
9
0
0
1
2
−








=
−
→
−
=








−




A
E 
Thus  
4x
t
=
 is a free variable.  We solve for  
1
2
4
5 ,
3 , and
2 .
x
t
x
t
x
t
= −
=
= −
 so 
 
1
2
3
4
( ,
,
,
)
( 5 ,3 , 2 , )
x x x x
t
t
t t
t
=
=
−
−
=
x
u  
 
 
where  
( 5,3, 2,1).
=
−
−
u
 
 
21. 
1
7
2
3
1
0
0
3
2
7
1
4
0
1
0
2
3
5
1
5
0
0
1
4
−








=
−
→
−
=








−
−




A
E 

198 
Chapter 4 
Thus  
4x
t
=
 is a free variable.  We solve for  
1
2
4
3 ,
2 , and
4 .
x
t
x
t
x
t
= −
=
= −
 so 
 
1
2
3
4
( ,
,
,
)
( 3 ,2 , 4 , )
x x x x
t
t
t t
t
=
=
−
−
=
x
u 
 
 
where  
( 3,2, 4,1).
=
−
−
u
 
 
22. 
1
3
3
3
1
0
0
6
2
7
5
1
0
1
0
4
2
7
4
4
0
0
1
3








=
−
→
−
=








−




A
E  
Thus  
4x
t
=
 is a free variable.  We solve for  
1
2
4
6 ,
4 , and
3 .
x
t
x
t
x
t
= −
=
= −
 so 
 
1
2
3
4
( ,
,
,
)
( 6 ,4 , 3 , )
x x x x
t
t
t t
t
=
=
−
−
=
x
u 
 
 
where  
( 6,4, 3,1).
=
−
−
u
 
 
23. 
Let  u  be a vector in  W.  Then  0u  is also in  W.  But  0u  =  (0+0)u  =  0u + 0u, so upon 
subtracting  0u  from each side, we see that  0u = 0, the zero vector. 
 
24. 
(a) 
Problem 23 shows that  0u = 0   for every vector  u. 
 
(b) 
The fact that  c0  =  c(0 + 0)  =  c0 + c0  implies (upon adding –c0  to each side)  
 
 
that  c0 = 0. 
 
(c) 
The fact that  u + (–1)u  =  (1 + (–1))u  =  0u  =  0  means that  (–1)u = –u. 
 
25. 
If  W  is a subspace, then it contains the scalar multiples  au  and  bv,  and hence contains 
their sum  au + bv.  Conversely, if the subset  W  is closed under taking linear combinations 
of pairs of vectors, then it contains  (1)u + (1)v  =  u + v  and  (c)u + (0)v  =  cu,  and hence 
is a subspace.   
 
26. 
The sum of any two scalar multiples of  u  is a scalar multiple of  u,  as is any scalar 
multiple of a scalar multiple of  u.   
 
27. 
Let  a1u + b1v  and  a2u + b2v  be two vectors in  
{
}.
W
a
b
=
+
u
v
  Then the sum 
 
 
 
 
(a1u + b1v)  +  (a2u + b2v)  =  
1
2
1
2
(
)
(
)
a
a
b
b
+
+
+
u
v  
 
 
and the scalar multiple  
1
1
1
1
(
)
(
)
(
)
c a
b
ca
cb
+
=
+
u
v
u
v   are again scalar multiples of   
u  and  v,  and hence are themselves elements of  W.  Hence  W  is a subspace. 
 
28. 
If  u  and  v  are vectors in  W,  then  Au = ku  and  Av = kv.   It follows that 
 
 
 
A(au+bv)  =  a(Au) + b(Av)  =  a(ku) + b(kv)  =  k(au + bv), 
 

 
Section 4.2 
199 
 
 
so the linear combination  au + bv  of  u  and  v  is also in W.  Hence  W  is a subspace. 
 
29. 
If  Ax0 = b  and  y =  x – x0,  then 
 
 
 
 
Ay  =  A(x – x0)  =  Ax – Ax0  =  Ax  –  b. 
 
 
Hence it is clear that  Ay = 0  if and only if  Ax = b. 
 
30. 
Let  W  denote the intersection of the subspaces  U  and  V.  If  u  and  v  are vectors in  W,  
then these two vectors are both in  U  and  in  V.  Hence the linear combination  au + bv  is 
both in  U  and  in  V,  and hence is in the intersection  W,  which therefore is a subspace.  If  
U  and  V  are non-coincident planes through the origin if  R3,  then their intersection  W  is a 
line through the origin. 
 
31. 
Let  w1  and  w2  be two vectors in the sum  U + V.  Then  wi  =  ui + vi  where  ui  is in  U  
and  vi  is in  V  (i = 1, 2).  Then the linear combination 
 
 
 
aw1 + bw2  =  a(u1 + v1) + b(u2 + v2)  =  (au1 + bu2) +  (av1 + bv2) 
 
 
is the sum of the vectors  au1 + bu2  in  U  and  av1 + bv2   in  U,  and therefore is an element 
of  U + V.  Thus  U + V  is a subspace.  If  U  and  V  are noncollinear lines through the 
origin in R3, then  U + V  is a plane through the origin.      
 
 
 
SECTION 4.3 
 
LINEAR COMBINATIONS AND  
INDEPENDENCE OF VECTORS 
 
In this section we use two types of computational problems as aids in understanding linear 
independence and dependence.  The first of these problems is that of expressing a vector  w  as a 
linear combination of  k  given vectors  
1
2
,
,
,
k
v
v
v

 (if possible).  The second is that of 
determining whether  k  given vectors  
1
2
,
,
,
k
v
v
v

 are linearly independent.  For vectors in Rn, 
each of these problems reduces to solving a linear system of  n  equations in  k  unknowns.  Thus an 
abstract question of linear independence or dependence becomes a concrete question of whether or 
not a given linear system has a nontrivial solution. 
 
1. 
3
2
1
2
,
=
v
v  so the two vectors  v1  and  v2  are linearly dependent. 
 
2. 
Evidently the two vectors  v1  and  v2  are not scalar multiples of one another.  Hence they 
are linearly dependent. 
 
3. 
The three vectors  v1,  v2,  and  v3  are linearly dependent, as are any 3 vectors in R2.  The 
reason is that the vector equation  c1v1 + c2v2 + c3v3  =  0  reduces to a homogeneous linear 

200 
Chapter 4 
system of  2 equations in the 3 unknowns  
1
2
3
,
, and
,
c c
c  and any such system has a 
nontrivial solution.  
 
4. 
The four vectors  v1,  v2, v3,  and  v4  are linearly dependent, as are any 4 vectors in R3.  The 
reason is that the vector equation  c1v1 + c2v2 + c3v3 + c4v4  =  0  reduces to a homogeneous 
linear system of  3 equations in the 4 unknowns  
1
2
3
4
,
,
, and
,
c c
c
c  and any such system 
has a nontrivial solution.  
 
5. 
The equation  
1
1
2
2
3
3
c
c
c
+
+
=
v
v
v
0 yields   
 
1
2
3
1
2
3
(1,0,0)
(0, 2,0)
(0,0,3)
( , 2
,3 )
(0,0,0),
c
c
c
c
c
c
+
−
+
=
−
=
 
 
 
and therefore implies immediately that  
1
2
3
0.
c
c
c
=
=
=
  Hence the given vectors 
 
v1,  v2,  and  v3  are linearly independent. 
 
6. 
The equation  
1
1
2
2
3
3
c
c
c
+
+
=
v
v
v
0 yields   
 
1
2
3
1
2
3
2
3
3
(1,0,0)
(1,1,0)
(1,1,1)
(
,
,
)
(0,0,0).
c
c
c
c
c
c c
c c
+
+
=
+
+
+
=
 
 
 
But it is obvious by back-substitution that the homogeneous system 
 
 
 
 
 
1
2
3
2
3
3
0
0
0
c
c
c
c
c
c
+
+
=
+
=
=
 
has only the trivial solution  
1
2
3
0.
c
c
c
=
=
=
  Hence the given vectors 
 
v1,  v2,  and  v3  are linearly independent. 
 
7. 
The equation  
1
1
2
2
3
3
c
c
c
+
+
=
v
v
v
0 yields   
 
1
2
3
1
2
1
2
3
(2,1,0,0)
(3,0,1,0)
(4,0,0,1)
(2
3 ,
,
,
)
(0,0,0,0).
c
c
c
c
c c c c
+
+
=
+
=
 
 
Obviously it follows immediately that  
1
2
3
0.
c
c
c
=
=
=
  Hence the given vectors 
 
v1,  v2,  and  v3  are linearly independent. 
 
8. 
Here inspection of the three given vectors reveals that  
3
1
2,
=
+
v
v
v
 so the vectors 
 
v1,  v2,  and  v3  are linearly dependent. 
 
 
In Problems 9–16 we first set up the linear system to be solved for the linear combination 
coefficients  { },
ic
 and then show the reduction of its augmented coefficient matrix  A  to reduced 
echelon form  E. 

 
Section 4.3 
201 
 
9. 
1
1
2
2
c
c
+
=
v
v
w  
5
3
1
1
0
2
3
2
0
0
1
3
4
5
7
0
0
0








=
→
−
=








−




A
E 
We see that the system of 3 equations in 2 unknowns has the unique solution  
1
2
2,
3,
c
c
=
= −
  so  
1
2
2
3
.
=
−
w
v
v  
 
10. 
1
1
2
2
c
c
+
=
v
v
w  
3
6
3
1
0
7
1
2
1
0
1
4
2
3
2
0
0
0
−








=
−
−
→
=








−
−




A
E  
We see that the system of 3 equations in 2 unknowns has the unique solution  
1
2
7,
4,
c
c
=
=
  so  
1
2
7
4
.
=
+
w
v
v  
 
11. 
1
1
2
2
c
c
+
=
v
v
w  
7
3
1
1
0
1
6
3
0
0
1
2
4
2
0
0
0
0
5
3
1
0
0
0








−
−
−




=
→
=








−




A
E 
We see that the system of 4 equations in 2 unknowns has the unique solution  
1
2
1,
2,
c
c
=
= −
  so  
1
2
2
.
=
−
w
v
v  
 
12. 
1
1
2
2
c
c
+
=
v
v
w  
7
2
4
1
0
2
3
2
4
0
1
5
1
1
3
0
0
0
9
3
3
0
0
0
−








−
−




=
→
=




−




−




A
E  
We see that the system of 4 equations in 2 unknowns has the unique solution  
1
2
2,
5,
c
c
=
=
  so  
1
2
2
5
.
=
+
w
v
v  
 
13. 
1
1
2
2
c
c
+
=
v
v
w  
1
5
5
1
0
0
5
3
2
0
1
0
3
4
2
0
0
1








=
−
→
=








−
−




A
E  

202 
Chapter 4 
The last row of  E  corresponds to the scalar equation  
1
2
0
0
1,
c
c
+
=
 so the system of 3 
equations in 2 unknowns is inconsistent.  This means that  w  cannot be expressed as a 
linear combination of  v1  and  v2. 
 
14. 
1
1
2
2
3
3
c
c
c
+
+
=
v
v
v
w  
1
0
0
2
1
0
0
0
0
1
1
3
0
1
0
0
0
2
1
2
0
0
1
0
3
0
1
3
0
0
0
1








−
−




=
→
=




−




−




A
E  
The last row of  E  corresponds to the scalar equation  
1
2
3
0
0
0
1,
c
c
c
+
+
=
 so the system 
of 4 equations in 3 unknowns is inconsistent.  This means that  w  cannot be expressed as 
a linear combination of  v1, v2,  and  v3. 
 
15. 
1
1
2
2
3
3
c
c
c
+
+
=
v
v
v
w  
2
3
1
4
1
0
0
3
1
0
2
5
0
1
0
2
4
1
1
6
0
0
1
4








=
−
→
−
=








−




A
E 
We see that the system of 3 equations in 3 unknowns has the unique solution  
1
2
3
3,
2,
4,
c
c
c
=
= −
=
  so  
1
2
3
3
2
4
.
=
−
+
w
v
v
v  
 
16. 
1
1
2
2
3
3
c
c
c
+
+
=
v
v
v
w  
2
4
1
7
1
0
0
6
0
1
3
7
0
1
0
2
3
3
1
9
0
0
1
3
1
2
3
11
0
0
0
0








−




=
→
=




−








A
E  
We see that the system of 4 equations in 3 unknowns has the unique solution  
1
2
3
6,
2,
3,
c
c
c
=
= −
=
  so  
1
2
3
6
2
3
.
=
−
+
w
v
v
v  
 
 
In Problems 17–22,  
[
]
1
2
3
=
A
v
v
v
  is the coefficient matrix of the homogeneous linear 
system corresponding to the vector equation  
1
1
2
2
3
3
.
c
c
c
+
+
=
v
v
v
0    Inspection of the indicated 
reduced echelon form  E  of  A  then reveals whether or not a nontrivial solution exists. 
 
17. 
1
2
3
1
0
0
0
3
5
0
1
0
1
4
2
0
0
1








=
−
→
=












A
E 

 
Section 4.3 
203 
 
We see that the system of 3 equations in 3 unknowns has the unique solution  
1
2
3
0,
c
c
c
=
=
=
  so the vectors  
1
2
3
,
,
v
v
v   are linearly independent. 
 
18. 
2
4
2
1
0
3/ 5
0
5
1
0
1
1/5
3
6
3
0
0
0
−
−








=
−
→
−
=








−
−




A
E 
We see that the system of 3 equations in 3 unknowns has a 1-dimensional solution space.  
If we choose  
3
5
c =
 then  
1
2
3 and
1.
c
c
=
=
 Therefore  
1
2
3
3
5
.
+
+
=
v
v
v
0  
 
19. 
2
5
2
1
0
0
0
4
1
0
1
0
3
2
1
0
0
1
0
1
1
0
0
0








−




=
→
=




−




−




A
E 
We see that the system of 4 equations in 3 unknowns has the unique solution  
1
2
3
0,
c
c
c
=
=
=
  so the vectors  
1
2
3
,
,
v
v
v   are linearly independent. 
 
20. 
1
2
3
1
0
0
1
1
1
0
1
0
1
1
4
0
0
1
1
1
1
0
0
0












=
→
=




−








A
E  
We see that the system of 4 equations in 3 unknowns has the unique solution  
1
2
3
0,
c
c
c
=
=
=
  so the vectors  
1
2
3
,
,
v
v
v   are linearly independent. 
 
21. 
3
1
1
1
0
1
0
1
2
0
1
2
1
0
1
0
0
0
2
1
0
0
0
0








−
−




=
→
=












A
E  
We see that the system of 4 equations in 3 unknowns has a 1-dimensional solution space.  
If we choose  
3
1
c = − then  
1
2
1 and
2.
c
c
=
= −
 Therefore  
1
2
3
2
.
−
−
=
v
v
v
0  
 
22. 
3
3
5
1
0
7 /9
9
0
7
0
1
5/9
0
9
5
0
0
0
5
7
0
0
0
0












=
→
=








−




A
E  
We see that the system of 4 equations in 3 unknowns has a 1-dimensional solution space.  
If we choose  
3
9
c = − then  
1
2
7 and
5.
c
c
=
=
 Therefore  
1
2
3
7
5
9
.
+
−
=
v
v
v
0  

204 
Chapter 4 
 
23. 
Because  v1  and  v2  are linearly independent, the vector equation 
 
 
 
1
1
2
2
1
1
2
2
1
2
(
)
(
)
c
c
c
c
+
=
+
+
−
=
u
u
v
v
v
v
0  
 
 
yields the homogeneous linear system 
 
 
 
 
 
1
2
1
2
0
0.
c
c
c
c
+
=
−
=
 
 
It follows readily that  
1
2
0,
c
c
=
=
 and therefore that the vectors  u1  and  u2  are linearly 
independent. 
 
24. 
Because  v1  and  v2  are linearly independent, the vector equation 
 
 
 
1
1
2
2
1
1
2
2
1
2
(
)
(2
3
)
c
c
c
c
+
=
+
+
+
=
u
u
v
v
v
v
0  
 
 
yields the homogeneous linear system 
 
 
 
 
 
1
2
1
2
2
0
3
0.
c
c
c
c
+
=
+
=
 
 
Subtraction of the first equation from the second one gives  c2 = 0,  and then it follows 
from the first equation that  c2 = 0 also.  Therefore the vectors  u1  and  u2  are linearly 
independent. 
 
25. 
Because the vectors  
1
2
3
,
,
v
v
v   are linearly independent, the vector equation 
 
 
 
1
1
2
2
3
3
1
1
2
1
2
3
1
2
3
(
)
(
2
)
(
2
3
)
c
c
c
c
c
c
+
+
=
+
+
+
+
+
=
u
u
u
v
v
v
v
v
v
0  
 
 
yields the homogeneous linear system 
 
 
 
 
 
1
2
3
2
3
3
0
2
2
0
3
0.
c
c
c
c
c
c
+
+
=
+
=
=
 
 
It follows by back-substitution that  
1
2
3
0,
c
c
c
=
=
=
 and therefore that the vectors  
1
2
3
,
,
u u
u  are linearly independent. 
 
26. 
Because the vectors  
1
2
3
,
,
v
v
v   are linearly independent, the vector equation 
 
 
 
1
1
2
2
3
3
1
2
3
2
1
3
3
1
2
(
)
(
)
(
)
c
c
c
c
c
c
+
+
=
+
+
+
+
+
=
u
u
u
v
v
v
v
v
v
0  

 
Section 4.3 
205 
 
 
 
yields the homogeneous linear system 
 
 
 
 
 
2
3
1
3
1
2
0
0
0.
c
c
c
c
c
c
+
=
+
=
+
=
 
 
The reduction  
 
 
 
0
1
1
1
0
0
1
0
1
0
1
0
1
1
0
0
0
1








=
→
=












A
E  
 
 then shows that  
1
2
3
0,
c
c
c
=
=
=
 and therefore that the vectors  
1
2
3
,
,
u u
u  are linearly 
independent. 
 
27. 
If the elements of  S  are  
1
2
,
,
,
k
v
v
v

 with  
1
,
=
v
0  then we can take  
1
1
c =  and  
2
0.
k
c
c
=
=
=

  This choice gives coefficients  
1
2
,
,
,
k
c c
c

 not all zero such that  
1
1
2
2
.
k
k
c
c
c
+
+
+
=
v
v
v
0

  This means that the vectors  
1
2
,
,
,
k
v
v
v

 are linearly 
dependent. 
 
28. 
Because the set  S  of vectors  
1
2
,
,
,
k
v
v
v

 is linearly dependent, there exist scalars  
1
2
,
,
,
k
c c
c

 not all zero such that  
1
1
2
2
.
k
k
c
c
c
+
+
+
=
v
v
v
0

  If  
1
0,
k
m
c
c
+ =
=
=

 
then  
1
1
2
2
m
m
c
c
c
+
+
+
=
v
v
v
0

 with the coefficients  
1
2
,
,
,
m
c c
c

 not all zero.  This 
means that the vectors  
1
2
,
,
,
m
v
v
v

 comprising  T  are linearly dependent. 
 
29. 
If some subset of  S  were linearly dependent, then Problem 28 would imply immediately 
that  S  itself is linearly dependent (contrary to hypothesis). 
 
30. 
Let  W  be the subspace of  V  spanned by the vectors  
1
2
,
,
,
.
k
v
v
v

  Because  U  is a 
subspace containing each of these vectors, it contains every linear combination of 
 
1
2
,
,
,
.
k
v
v
v

  But  W  consists solely of such linear combinations, so it follows that  U  
contains  W. 
 
31. 
If  S  is contained in  span(T), then every vector in  S  is a linear combination of vectors in  
T.  Hence every vector in  span(S)  is a linear combination of linear combinations of 
vectors in  T.  Therefore every vector in  span(S)  is a linear combination of vectors in  T, 
and therefore is itself in  span(T).  Thus  span(S)  is a subset of  span(T).  
 
32. 
If  u  is another vector in  S  then the  k+1 vectors  
1
2
,
,
,
,
k
v
v
v
u

 are linearly 
dependent.  Hence there exist scalars  
1
2
,
,
,
,
k
c c
c
c

 not all zero such that  

206 
Chapter 4 
1
1
2
2
.
k
k
c
c
c
c
+
+
+
+
=
v
v
v
u
0

  If  c = 0  then we have a contradiction to the 
hypothesis that the vectors  
1
2
,
,
,
k
v
v
v

 are linearly independent.  Therefore  c ≠ 0,   
so we can solve for  u  as a linear combination of the vectors  
1
2
,
,
,
.
k
v
v
v

 
 
33. 
The determinant of the k
k
×
 identity matrix is nonzero, so it follows immediately from 
Theorem 3 in this section that the vectors  
1
2
,
,
,
k
v
v
v

 are linearly independent.   
 
34. 
If the vectors  
1
2
,
,
,
n
v
v
v

 are linearly independent, then by Theorem 2 the matrix    
[
]
1
2
n
=
A
v
v
v

  is nonsingular.  If  B  is another nonsingular  n n
×  matrix, then 
the product  AB  is also nonsingular, and therefore (by Theorem 2) has linearly 
independent column vectors. 
 
35. 
Because the vectors  
1
2
,
,
,
k
v
v
v

 are linearly independent, Theorem 3 implies that some 
k
k
×
 submatrix  A0  of  A  has nonzero determinant.  Let  A0  consist of the rows  
1
2
,
,
, k
i i
i

 of the matrix  A,  and let  C0  denote the  k
k
×
 submatrix consisting of the 
same rows of the product matrix  C = AB.  Then  C0 = A0B,  so  
0
0
0
=
≠
C
A
B
 
because (by hypothesis) the k
k
×
 matrix  B  is also nonsingular.  Therefore Theorem 3 
implies that the column vectors of  AB  are linearly independent. 
 
 
 
SECTION 4.4 
 
BASES AND DIMENSION FOR VECTOR SPACES 
 
A basis  {
}
1
2
,
,
,
k
v
v
v

 for a subspace  W  of Rn enables up to visualize  W  as a k-dimensional 
plane (or "hyperplane") through the origin in Rn.  In case W is the solution space of a 
homogeneous linear system, a basis for  W  is a maximal linearly independent set of solutions of 
the system, and every other solution is a linear combination of these particular solutions.   
 
1. 
The vectors  v1  and  v2  are linearly independent (because neither is a scalar multiple of 
the other) and therefore form a basis for R2. 
 
2. 
We note that  v2 = 2v1.  Consequently the vectors  
1
2
3
,
,
v
v
v  are linearly dependent, and 
therefore do not form a basis for R3. 
 
3. 
Any four vectors in R3 are linearly dependent, so the given vectors do not form a basis 
for R3. 
 
4. 
Any basis for R4 contains four vectors, so the given vectors  
1
2
3
,
,
v
v
v   do not form a 
basis for R4. 
 

 
Section 4.4 
207 
 
5. 
The three given vectors  
1
2
3
,
,
v
v
v   all lie in the 2-dimensional subspace  x1 = 0  of  R3.  
Therefore they are linearly dependent, and hence do not form a basis for R3. 
 
6. 
[
]
(
)
1
2
3
Det
1
0,
= −≠
v
v
v
 so the three vectors are linearly independent, and hence do 
form a basis for R3. 
 
7. 
[
]
(
)
1
2
3
Det
1
0,
= ≠
v
v
v
 so the three vectors are linearly independent, and hence do 
form a basis for R3. 
 
8. 
[
]
(
)
1
2
3
4
Det
66
0,
=
≠
v
v
v
v
 so the four vectors are linearly independent, and hence 
do form a basis for R4. 
 
9. 
The single equation  
2
5
0
x
y
z
−
+
=
 is already a system in reduced echelon form, with 
free variables  y  and  z.  With  
,
,
2
5
y
s
z
t
x
s
t
=
=
=
−
 we get the solution vector 
 
 
 
 
( , , )
(2
5 , , )
(2,1,0)
( 5,0,1).
x y z
s
t s t
s
t
=
−
=
+
−
 
 
 
Hence the plane  
2
5
0
x
y
z
−
+
=
 is a 2-dimensional subspace of  R3 with basis consisting 
of the vectors  
1
2
(2,1,0) and
( 5,0,1).
=
= −
v
v
 
 
10. 
The single equation  
0
y
z
−
=
 is already a system in reduced echelon form, with free 
variables  x  and  z.  With  
,
x
s
y
z
t
=
=
=  we get the solution vector 
 
 
 
 
( , , )
( , , )
(1,0,0)
(0,1,1).
x y z
s t t
s
t
=
=
+
 
 
 
Hence the plane  
0
y
z
−
=
 is a 2-dimensional subspace of  R3 with basis consisting of the 
vectors  
1
2
(1,0,0) and
(0,1,1).
=
=
v
v
 
 
11. 
The line of intersection of the planes in Problems 9 and 11 is the solution space of the 
system 
 
 
 
 
2
5
0
0.
x
y
z
y
z
−
+
=
−
=
 
 
 
This system is in echelon form with free variable  z = t.  With  y = t  and  x = –3t  we have 
the solution vector  ( 3 , , )
( 3,1,1).
t t t
t
−
=
−
  Thus the line is a 1-dimensional subspace of R3 
with basis consisting of the vector  v = (–3,1,1). 
 
12. 
The typical vector in R4 of the form  ( , , , )
a b c d  with  a
b
c
d
=
+
+
 can be written as   
 
(
, , , )
(1,1,0,0)
(1,0,1,0)
(1,0,0,1).
b
c
d b c d
b
c
d
=
+ +
=
+
+
v
 
 

208 
Chapter 4 
Hence the subspace consisting of all such vectors is 3-dimensional with basis consisting 
of the vectors 
1
2
3
(1,1,0,0),
(1,0,1,0), and
(1,0,0,1).
=
=
=
v
v
v
 
 
13. 
The typical vector in R4 of the form  ( , , , )
a b c d  with  
3
and
4
a
c
b
d
=
=
 can be written 
as   
(3 ,4 , , )
(3,0,1,0)
(0,4,0,1).
c
d c d
c
d
=
=
+
v
 
 
Hence the subspace consisting of all such vectors is 2-dimensional with basis consisting 
of the vectors 
1
2
(3,0,1,0) and
(0,4,0,1).
=
=
v
v
 
 
14. 
The typical vector in R4 of the form  ( , , , )
a b c d  with  
2
and
3
a
b
c
d
= −
= −
 can be 
written as   
( 2 , , 3 , )
( 2,1,0,0)
(0,0, 3,1).
b b
d d
b
d
=
−
−
=
−
+
−
v
 
 
Hence the subspace consisting of all such vectors is 2-dimensional with basis consisting 
of the vectors 
1
2
( 2,1,0,0) and
(0,0, 3,1).
= −
=
−
v
v
 
 
In Problems 15–26, we show first the reduction of the coefficient matrix  A  to echelon form  E. 
Then we write the typical solution vector as a linear combination of basis vectors for the 
subspace of the given system. 
 
15. 
1
2
3
1
0
11
2
3
1
0
1
7
−
−




=
→
=




−
−




A
E  
With free variable  
3
1
2
and
11 ,
7
x
t
x
t
x
t
=
=
=
 we get the solution vector  
(11 ,7 , )
(11,7,1).
t
t t
t
=
=
x
  Thus the solution space of the given system is 1-
dimensional with basis consisting of the vector  
1
(11,7,1).
=
v
 
 
16. 
1
3
4
1
0
11
3
8
7
0
1
5
−




=
→
=








A
E  
With free variable  
3
1
2
and with
11 ,
5
x
t
x
t
x
t
=
=
= −
 we get the solution vector  
(11 , 5 , )
(11, 5,1).
t
t t
t
=
−
=
−
x
  Thus the solution space of the given system is 1-
dimensional with basis consisting of the vector  
1
(11, 5,1).
=
−
v
 
 
17. 
1
3
2
4
1
0
11 11
2
5
7
3
0
1
3
5
−
−




=
→
=




−
−




A
E 
With free variables  
3
4
1
2
,
and with
11
11 ,
3
5
x
s
x
t
x
s
t
x
s
t
=
=
= −
−
= −
−
 we get the 
solution vector   
 
( 11
11 , 3
5 , , )
( 11, 3,1,0)
( 11, 5,0,1).
s
t
s
t s t
s
t
=
−
−
−
−
=
−
−
+
−
−
x
   

 
Section 4.4 
209 
 
Thus the solution space of the given system is 2-dimensional with basis consisting of the 
vectors  
1
2
( 11, 3,1,0) and
( 11, 5,0,1).
= −
−
= −
−
v
v
 
 
18. 
1
3
4
5
1
3
0
25
2
6
9
5
0
0
1
5




=
→
=




−




A
E 
With free variables  
2
4
1
3
,
and with
3
25 ,
5
x
s
x
t
x
s
t
x
t
=
=
= −
−
=
 we get the solution  
vector   
( 3
25 , ,5 , )
( 3,1,0,0)
( 25,0,5,1).
s
t s
t t
s
t
=
−
−
=
−
+
−
x
   
 
Thus the solution space of the given system is 2-dimensional with basis consisting of the 
vectors  
1
2
( 3,1,0,0) and
( 25,0,5,1).
= −
= −
v
v
 
 
19. 
1
3
8
5
1
0
3
4
2
1
4
11
0
1
2
3
1
3
3
13
0
0
0
0
−
−
−
−








=
−
→
=












A
E 
With free variables  
3
4
1
2
,
and with
3
4 ,
2
3
x
s
x
t
x
s
t
x
s
t
=
=
=
−
= −
−
 we get the 
solution vector   
 
(3
4 , 2
3 , , )
(3, 2,1,0)
( 4, 3,0,1).
s
t
s
t s t
s
t
=
−
−
−
=
−
+
−
−
x
   
 
Thus the solution space of the given system is 2-dimensional with basis consisting of the 
vectors  
1
2
(3, 2,1,0) and
( 4, 3,0,1).
=
−
= −
−
v
v
 
 
20. 
1
3
10
5
1
0
1
2
1
4
11
2
0
1
3
1
1
3
8
1
0
0
0
0
−
−
−








=
−
→
−
=








−




A
E 
With free variables  
3
4
1
2
,
and with
2 ,
3
x
s
x
t
x
s
t
x
s
t
=
=
=
−
= −
+  we get the solution 
vector   
 
(
2 , 3
, , )
(1, 3,1,0)
( 2,1,0,1).
s
t
s
t s t
s
t
=
−
−
+
=
−
+
−
x
   
 
Thus the solution space of the given system is 2-dimensional with basis consisting of the 
vectors  
1
2
(1, 3,1,0) and
( 2,1,0,1).
=
−
= −
v
v
 
 
21. 
1
4
3
7
1
0
1
5
2
1
1
7
0
1
1
3
1
2
3
11
0
0
0
0
−
−
−








=
−
→
=












A
E  

210 
Chapter 4 
With free variables  
3
4
1
2
,
and with
5 ,
3
x
s
x
t
x
s
t
x
s
t
=
=
= −−
= −−
 we get the solution 
vector   
 
(
5 ,
3 , , )
( 1, 1,1,0)
( 5, 3,0,1).
s
t
s
t s t
s
t
=
−−
−−
=
−−
+
−
−
x
   
 
Thus the solution space of the given system is 2-dimensional with basis consisting of the 
vectors  
1
2
( 1, 1,1,0) and
( 5, 3,0,1).
= −−
= −
−
v
v
 
 
22. 
1
2
3
16
1
2
0
5
2
4
1
17
0
0
1
7
1
2
3
26
0
0
0
0
−
−
−
−








=
−
→
=








−




A
E  
With free variables  
2
4
1
3
,
and with
2
5 ,
7
x
s
x
t
x
s
t
x
t
=
=
=
−
= −
 we get the solution  
vector   
(2
5 , , 7 , )
(2,1,0,0)
( 5,0, 7,1).
s
t s
t t
s
t
=
−
−
=
+
−
−
x
   
 
Thus the solution space of the given system is 2-dimensional with basis consisting of the 
vectors  
1
2
(2,1,0,0) and
( 5,0, 7,1).
=
= −
−
v
v
 
 
23. 
1
5
13
14
1
0
2
0
2
5
11 12
0
1
3
0
2
7
17
19
0
0
0
1
−








=
→
=












A
E  
With free variable  
3
1
2
4
and with
2 ,
3 ,
0
x
s
x
s
x
s
x
=
=
= −
=
 we get the solution  
vector  
(2 , 3 , ,0)
(2, 3,1,0).
s
s s
s
=
−
=
−
x
  Thus the solution space of the given system is 
1-dimensional with basis consisting of the vector  
1
(2, 3,1,0).
=
−
v
 
 
24. 
1
3
4
8
6
1
0
2
1
3
1
0
2
1
3
0
1
2
3
1
2
7
10
19
13
0
0
0
0
0
−
−








=
→
−
−
=








−
−




A
E 
With free variables  
3
4
5
1
2
,
,
and with
2
3 ,
2
3
x
r
x
s
x
t
x
r
s
t
x
r
s
t
=
=
=
= −
−−
=
+
− we 
get the solution vector   
 
   
( 2
3 ,2
3
, , , )
( 2,2,1,0,0)
( 1,3,0,1,0)
( 3, 1,0,0,1).
r
s
t
r
s
t r s t
r
s
t
=
−
−−
+
−
=
−
+
−
+
−
−
x
   
 
Thus the solution space of the given system is 3-dimensional with basis consisting of the 
vectors  
1
2
3
( 2,2,1,0,0),
( 1,3,0,1,0), and
( 3, 1,0,0,1).
= −
= −
= −
−
v
v
v
 
 

 
Section 4.4 
211 
 
25. 
1
2
7
9
31
1
2
0
2
3
2
4
7
11
34
0
0
1
1
4
3
6
5
11
29
0
0
0
0
0
−
−








=
−
→
−
=








−




A
E  
With free variables  
2
4
5
1
3
,
,
and with
2
2
3 ,
4
x
r
x
s
x
t
x
r
s
t
x
s
t
=
=
=
= −
+
−
=
−
 we get 
the solution vector   
 
( 2
2
3 , ,
4 , , )
( 2,1,0,0,0)
(2,0,1,1,0)
( 3,0, 4,0,1).
r
s
t r s
t s t
r
s
t
=
−
+
−
−
=
−
+
+
−
−
x
   
 
Thus the solution space of the given system is 3-dimensional with basis consisting of the 
vectors  
1
2
3
( 2,1,0,0,0),
(2,0,1,1,0), and
( 3,0, 4,0,1).
= −
=
= −
−
v
v
v
 
 
26. 
3
1
3
11
10
1
0
0
2
3
5
8
2
2
7
0
1
0
1
4
2
5
0
1 14
0
0
1
2
5
−
−








=
−
→
−
=








−
−
−




A
E  
With free variables  
4
5
1
2
3
,
and with
2
3 ,
4 ,
2
5
x
s
x
t
x
s
t
x
s
t
x
s
t
=
=
= −
+
=
−
=
+
 we get 
the solution vector   
 
( 2
3 ,
4 ,2
5 , , )
( 2,1,2,1,0)
(3, 4,5,0,1).
s
t s
t
s
t s t
s
t
=
−
+
−
+
=
−
+
−
x
   
 
Thus the solution space of the given system is 2-dimensional with basis consisting of the 
vectors  
1
2
( 2,1,2,1,0) and
(3, 4,5,0,1).
= −
=
−
v
v
 
 
27. 
If the vectors  
1
2
,
,
,
n
v
v
v

 are linearly independent, and  w  is another vector in V, then 
the vectors  
1
2
,
,
,
,
n
w v
v
v

 are linearly dependent (because no  n+1 vectors in the n-
dimensional vector space  V  are linearly independent).  Hence there exist scalars  
1
2
,
,
,
,
n
c c c
c

 not all zero such that 
 
 
 
 
 
1
1
2
2
.
n
n
c
c
c
c
+
+
+
+
=
w
v
v
v
0

 
 
 
If  c = 0  then the coefficients  
1
2
,
,
,
n
c c
c

 would not all be zero, and hence this equation 
would say (contrary to hypothesis) that the vectors  
1
2
,
,
,
n
v
v
v

 are linearly dependent.  
Therefore  c ≠ 0,  so we can solve for  w  as a linear combination of the vectors  
1
2
,
,
,
.
n
v
v
v

  Thus the linearly independent vectors  
1
2
,
,
,
n
v
v
v

 span  V,  and 
therefore form a basis for  V.   
 
28. 
If the  n  vectors in  S  were not linearly independent, then some one of them would be a 
linear combination of the others.  These remaining  n–1  vectors would then span the n-
dimensional vector space  V,  which is impossible.  Therefore the spanning set  S  is also 
linearly independent, and therefore is a basis for  V.   
 

212 
Chapter 4 
29. 
Suppose  
1
1
2
2
.
k
k
c
c
c
c
+
+
+
+
=
v
v
v
v
0

  Then  c = 0  because, otherwise, we could 
solve for  v  as a linear combination of the vectors  
1
2
,
,
,
.
k
v
v
v

  But this is impossible, 
because  v  is not in the subspace  W  spanned by  
1
2
,
,
,
.
k
v
v
v

  It follows that   
1
1
2
2
,
k
k
c
c
c
+
+
+
=
v
v
v
0

  which implies that  
1
2
0
k
c
c
c
=
=
=
=

 also, because the 
vectors  
1
2
,
,
,
k
v
v
v

 are linearly independent.  Hence we have shown that the  k+1  
vectors  
1
2
,
,
,
,
k
v v
v
v

 are linearly independent. 
 
30. 
Let  
{
}
1
2
,
,
,
k
S =
v
v
v

 be a linearly independent set of  k < n  vectors in  V.  If the 
vector  
1
k+
v
 in  V  is not in  W = span(S), then Problem 29 implies that the  k+1 vectors  
1
2
1
,
,
,
,
k
k+
v
v
v
v

 are linearly independent.  Continuing in this fashion, we can add one 
vector at a time until we have  n  linearly independent vectors in  V, which then form a 
basis for  V  that contains the original basis  S.   
 
31. 
If  
1
k+
v
 is a linear combination of the vectors  
1
2
,
,
,
,
k
v
v
v

 then obviously every linear 
combination of the vectors  
1
2
1
,
,
,
,
k
k+
v
v
v
v

 is also a linear combination of  
1
2
,
,
,
.
k
v
v
v

  But the former set of  k+1  vectors spans  V, so the latter set of  k  vectors 
also spans  V. 
 
32. 
If the spanning set  S  for  V  is not linearly independent, then some vector in  S  is a 
linear combination of the others.  But Problem 31 says that when we remove this 
dependent vector from  S,  the resulting set of one fewer vectors still spans  V.  
Continuing in this fashion, we remove one vector at a time from  S  until we wind up with 
a spanning set for  V  that is also a linearly independent set, and therefor forms a basis for  
V  that is contained by the original spanning set  S. 
 
33. 
If  S  is a maximal linearly independent set in  V,  the we see immediately that every other 
vector in  V  is a linear combination of the vectors in  S.  Thus  S  also spans  V, and is 
therefore a basis for  V. 
 
34. 
If the minimal spanning set  S  for  V  were not linearly independent, then (by Problem 
28) some vector  S  would be a linear combination of the others.  Then the set obtained 
from the minimal spanning set  S  by deleting this dependent vector would be a smaller 
spanning set for  S  (which is impossible).  Hence the spanning set  S  is also a linearly 
independent set, and therefore is a basis for  V. 
 
35. 
Let  
{
}
1
2
,
,
,
n
S =
v
v
v

  be a uniquely spanning set for  V.  Then the fact, that   
 
 
 
 
1
2
0
0
0
n
=
+
+
+
0
v
v
v

 
 
is the unique expression of the zero vector  0  as a linear combination of the vectors in  S, 
means that  S  is a linearly independent set of vectors.  Hence  S  is a basis for  V. 
 

 
Section 4.4 
213 
 
36. 
If  
1
2
,
,
,
k
a a
a

 are scalars, then the linear combination  
1
1
2
2
k
k
c
c
c
+
+
+
v
v
v

 — of the 
column vectors of the matrix in Eq. (12) having the k
k
×
 identity matrix as its "bottom" 
k
k
×
 submatrix — is a vector of the form  (
)
1
2
, ,
, ,
,
,
,
* *
*
k
a a
a


.  Hence this linear 
combination can equal the zero vector only if  
1
2
0.
k
a
a
a
=
=
=
=

  Thus the vectors  
1
2
,
,
,
k
v
v
v

 are linearly independent. 
 
 
 
SECTION 4.5 
 
ROW AND COLUMN SPACES 
 
Conventional wisdom (at a certain level) has it that a homogeneous linear system  
=
Ax
0  of  m  
equations in  n
m
>
 unknowns ought to have  n
m
−
 independent solutions.  In Section 4.5 of the 
text we use row and column spaces to show that this "conventional wisdom" is valid under the 
condition that the  m  equations are irredundant — meaning that the rank of the coefficient 
matrix  A  is  m  (so its  m  row vectors are linearly independent).  
 
In each of Problems 1–12 we give the reduced echelon form  E  of the matrix  A, a basis for the 
row space of  A, and a basis for the column space of  A. 
 
1. 
1
0
11
0
1
4
0
0
0




=
−






E
 
 
Row basis: 
  The first and second row vectors of  E. 
 
 
Column basis:   The first and second column vectors of  A. 
 
2. 
1
0
2
0
1
3
0
0
0




=
−






E
 
 
Row basis: 
  The first and second row vectors of  E. 
 
 
Column basis:   The first and second column vectors of  A. 
 
3. 
1
0
1
5
0
1
1
3
0
0
0
0




= 





E
 
 
Row basis: 
  The first and second row vectors of  E. 
 
 
Column basis:   The first and second column vectors of  A. 
 

214 
Chapter 4 
4. 
1
0
0
4
0
1
0
3
0
0
1
0




= 





E
 
 
Row basis: 
  The three row vectors of  E.  
 
Column basis:   The first three column vectors of  A. 
 
5. 
1
0
2
0
0
1
3
0
0
0
0
1
−




= 





E
 
 
Row basis: 
  The three row vectors of  E.  
 
Column basis:   The first, second, and fourth column vectors of  A. 
 
6. 
1
0
1
0
0
1
2
0
0
0
0
1




= 





E
 
 
Row basis: 
  The three row vectors of  E.  
 
Column basis:   The first, second, and fourth column vectors of  A. 
 
7. 
1
0
3
4
0
1
2
3
0
0
0
0
0
0
0
0
−






= 





E
 
 
Row basis: 
  The first two row vectors of  E. 
 
 
Column basis:   The first two column vectors of  A. 
 
8. 
1
0
1
0
0
1
2
0
0
0
0
1
0
0
0
0






= 





E
 
 
Row basis: 
  The first three row vectors of  E. 
 
 
Column basis:   The first, second, and fourth column vectors of  A. 
 

 
Section 4.5 
215 
 
9. 
1
0
0
3
0
1
0
2
0
0
1
4
0
0
0
0




−


= 





E
 
 
Row basis: 
  The first three row vectors of  E. 
 
 
Column basis:   The first three column vectors of  A. 
 
10. 
1
0
1
0
0
0
1
1
0
1
0
0
0
1
1
0
0
0
0
0






= 





E
 
 
Row basis: 
  The first three row vectors of  E. 
 
 
Column basis:   The first, second, and fourth column vectors of  A. 
 
11. 
1
0
2
1
0
0
1
1
2
0
0
0
0
0
1
0
0
0
0
0






= 





E
 
 
Row basis: 
  The first three row vectors of  E. 
 
 
Column basis:   The first, second, and fifth column vectors of  A. 
 
12. 
E is the same reduced echelon matrix as in Problem 11. 
 
Row basis: 
  The first three row vectors of  E. 
 
 
Column basis:   The first, second, and fifth column vectors of  A. 
 
In each of Problems 13–16 we give the reduced echelon form  E  of the matrix having the given 
vectors  
1
2
,
,
v
v … as its column vectors. 
 
13. 
1
0
1
0
1
2
0
0
0
0
0
0






= 





E
 
 
Linearly independent:   
1
2
and
v
v   
 

216 
Chapter 4 
14. 
1
5
2
5
1
0
2
0
1
1
0
0
0
0
0
0
0
0






= 





E
 
 
Linearly independent:   
1
2
and
v
v   
 
15. 
1
0
2
0
0
1
1
0
0
0
0
1
0
0
0
0




−


= 





E
 
 
Linearly independent:   
1
2
4
,
, and
v
v
v  
 
 
16. 
1
0
2
0
0
0
1
1
0
0
0
0
0
1
0
0
0
0
0
1




−


= 





E
 
 
Linearly independent:   
1
2
4
5
,
,
, and
v
v
v
v   
 
In each of Problems 17–20 the matrix  E  is the reduced echelon matrix of the matrix  
[
]
1
1
.
k
n
=
A
v
v
e
e


 
 
17. 
1
0
3
0
2
0
1
2
0
1
0
0
0
1
1
−




=
−


−




E
 
 
Basis vectors:   
1
2
2
,
,
v
v
e  
 
 
18. 
1
2
5
5
3
1
5
5
1
0
0
0
1
0
0
0
0
1
2
−




= 





E
 
 
Basis vectors:   
1
2
2
,
,
v
v
e  
 
 

 
Section 4.5 
217 
 
19. 
1
0
3
0
0
2
0
1
1
0
0
1
0
0
0
1
0
1
0
0
0
0
1
1
−




−


=
−




−


E
 
 
Basis vectors:   
1
2
2
3
,
,
,
v
v
e
e  
 
 
20. 
5
2
3
2
1
0
0
0
2
0
1
0
0
1
0
0
1
0
0
1
0
0
0
0
1
1
−




−


= 
−


−


E
 
 
Basis vectors:   
1
2
1
3
,
,
,
v
v
e
e  
 
 
In each of Problems 21–24 the matrix  E  is the reduced echelon form of the transpose  
T
A  of 
the coefficient matrix  
.
A  
 
21. 
1
0
2
0
1
1
0
0
0




= 





E
 
 
The first and second equations are irredundant. 
 
22. 
1
0
2
0
1
1
0
0
0
0
0
0






= 





E
 
 
The first and second equations are irredundant. 
 
23. 
1
0
2
0
0
1
1
0
0
0
0
1
0
0
0
0






= 





E
 
 
The first, second, and fourth equations are irredundant. 
 

218 
Chapter 4 
24. 
1
0
1
2
0
0
1
2
1
0
0
0
0
0
1




= 





E
 
 
The first, second, and fifth equations are irredundant. 
 
25. 
The row vectors of  A  are the column vectors of its transpose matrix  
,
T
A
 so 
 
 
 
rank(A)  =  row rank of  A  =  column rank of  
T
A  =  rank(
).
T
A
 
 
26. 
The rank of the  n
n
×
 matrix  A  is  n  if and only if its column vectors are linearly 
independent, in which case  det(
)
0
≠
A
 by Theorem 2 in Section 4.3, so it follows by 
Theorem 2 in Section 3.6 that  A  is invertible. 
 
27. 
The rank of the 3 5
×  matrix  A  is 3, so its column vectors  
1
1
5
,
,
,
a a
a
…
 span  
3.
R
  
Therefore any given vector  b  in  
3
R  can be expressed as a linear combination  
1
1
2
2
5
5
x
x
x
=
+
+
+
b
a
a
a

 of the column vectors of  A.  The column vector  x  whose 
elements are the coefficients in this linear combination  is then a solution of the equation  
.
=
Ax
b  
 
28. 
The rank of the 5 3
×  matrix  A  is 3, so its three column vectors  
1
1
3
,
,
a a a  are linearly 
independent.  Therefore any given vector  b  in  
5
R  can be expressed in at most one way 
as a linear combination  
1
1
2
2
3
3
x
x
x
=
+
+
b
a
a
a  of the column vectors of  A.  This means 
that the equation  
=
Ax
b  has at most one solution  
[
]
1
2
3
.
T
x
x
x
=
x
 
 
29. 
The rank of the m
n
×
 matrix  A  is at most  
,
m
n
<
 and therefore is less than the number  
n  of its column vectors.  Hence the column vectors  
1
1
,
,
,
n
a a
a
…
 of  A  are linearly 
dependent, so there exists a linear combination  
1
1
2
2
n
n
y
y
y
+
+
+
=
a
a
a
0

 with not all 
the coefficients being zero.  If   
[
]
1
2
T
n
x
x
x
=
x
…
 is one solution of the equation  
,
=
Ax
b  then  
(
)
,
+
=
+
=
+
=
A x
y
Ax
Ay
b
0
b  so  
+
x
y  is a second different solution.  
Thus solutions of the equation are not unique. 
 
30. 
The rank of the m
n
×
 matrix  A  is at most  
,
n
m
<
 and therefore is less than the number  
m  of its row vectors.  Hence the dimension of the column space of  A  is less than  m, so 
this column space is a proper subspace of  
.
m
R
 Hence there exists a vector  b  in  
m
R  
that is not a linear combination of the column vectors of  A.  This means that the equation  
=
Ax
b  has no solution. 
 
31. 
The rank of the m
n
×
 matrix  A  is  m  if and only if  A  has  m  linearly independent 
column vectors — in which case these  m  linearly independent column vectors constitute 
a basis for  
.
m
R
 Hence the rank of  A  is  m  if and only if its column vectors  

 
Section 4.5 
219 
 
1
1
,
,
,
n
a a
a
…
 span  
m
R  — in which case every vector  b  in  
m
R  can be expressed as a 
linear combination  
1 1
2
2
,
n
n
x
x
x
=
+
+
+
b
a
a
a

 so the equation  
=
Ax
b   has the solution  
[
]
1
2
.
T
n
x
x
x
=
x
…
 
 
 
32. 
The rank of the m
n
×
 matrix  A  is  n  if and only if  the n  column vectors  
1
1
,
,
,
n
a a
a
…
 
of  A  are linearly independent — in which a vector  b  in  
m
R  can be expressed in at 
most one way as a linear combination  
1 1
2
2
.
n
n
x
x
x
=
+
+
+
b
a
a
a

  This means that the 
equation  
=
Ax
b   has at most one solution  
[
]
1
2
.
T
n
x
x
x
=
x
…
 
 
 
33. 
Suppose that some linear combination of the  k  pivot column vectors  
1
1
,
,
,
k
p p
p
…
 in (8) 
equals the zero vector.  Denote by  
1
1
,
,
,
k
c c
c
…
 the coefficients in this linear 
combination.  Then the first  k  scalar components of the equation  
1
1
2
2
3
3
k
k
c
c
c
c
+
+
+
+
=
p
p
p
p
0

 yield the  k
k
×
 upper-triangular system  
 
 
 
 
1
1
2
21
3
31
1
2
2
3
32
2
3
3
3
0
0
0
0
k
k
k
k
k
k
k
k
c d
c p
c p
c p
c d
c p
c p
c d
c p
c d
+
+
+
+
=
+
+
+
=
+
+
=
=




 
 
 
where  
i j
p  (for  i
j
>
) denotes the jth element of the vector  
ip  and  
.
ii
i
p
d
=
 Because the 
leading entries  
1
1
,
,
,
k
d d
d
…
 are all nonzero, it follows by back-substitution that  
1
2
0.
k
c
c
c
=
=
=
=

 Therefore the column vectors are linearly independent. 
 
 
34. 
If no row interchanges are involved, then (for any k) the space spanned by the first  k  row 
vectors of  A  is never changed in the process of reducing  A  to the echelon matrix  E; 
this follows immediately from the proof of Theorem 2 in this section.  Hence the first  r  
row vectors of  A  span the r-dimensional space  Row(A), and therefore are linearly 
independent. 
 
 
35. 
Look at the  r  row vectors of the matrix  A  that are determined by its largest nonsingular  
r
r
×  submatrix.  Then Theorem 3 in Section 4.3 says that these  r  row vectors are 
linearly independent, whereas any  
1
r +  row vectors of  A  are linearly dependent. 
 
 
 

220 
Chapter 4 
SECTION 4.6 
 
ORTHOGONAL VECTORS IN 
n
R  
 
The generalization in this section, of the dot product to vectors in  
,
n
R
 enables us to flesh out the 
algebra of vectors in 
n
R  with the Euclidean geometry of angles and distance.  We can now refer to 
the vector space 
n
R  (provided with the dot product) as n-dimensional Euclidean space. 
 
1. 
1
2
(2)(3)
(1)( 6)
(2)(1)
(1)( 2)
6
6
2
2
0
⋅
=
+
−
+
+
−
=
−
+
−
=
v
v
 
 
1
3
(2)(3)
(1)( 1)
(2)( 5)
(1)(5)
6
1 10
5
0
⋅
=
+
−
+
−
+
=
−−
+
=
v
v
 
 
2
3
(3)(3)
( 6)( 1)
(1)( 5)
( 2)(5)
9
6
5 10
0
⋅
=
+ −
−
+
−
+ −
=
+
−
−
=
v
v
 
 
Yes, the three vectors are mutually orthogonal. 
 
2. 
1
2
(3)(6)
( 2)(3)
(3)(4)
( 4)(6)
18
6
12
24
0
⋅
=
+ −
+
+ −
=
−
+
−
=
v
v
 
 
1
3
(3)(17)
( 2)( 12)
(3)( 21)
( 4)(3)
51
24
63 12
0
⋅
=
+ −
−
+
−
+ −
=
+
−
−
=
v
v
 
 
2
3
(6)(17)
(3)( 12)
(4)( 21)
(6)(3)
102
36
84
18
0
⋅
=
+
−
+
−
+
=
−
−
+
=
v
v
 
 
Yes, the three vectors are mutually orthogonal. 
 
3. 
1
2
1
3
2
3
15 10
4
1
0,
15
0
32
17
0,
9
0
8
17
0
⋅
=
−
−
−=
⋅
=
+
−
+
=
⋅
=
+
+
−
=
v
v
v
v
v
v
 
 
Yes, the three vectors are mutually orthogonal. 
 
4. 
1
2
1
3
2
3
3
4
9
12
4
0,
6
4
12
2
4
0,
18
4
12
6
16
0
⋅
=
+
+
−
−
=
⋅
=
+
−
−
+
=
⋅
=
+
−
+
−
=
v
v
v
v
v
v
 
 
Yes, the three vectors are mutually orthogonal. 
 
In each of Problems 5–8 we write  
,
, and
.
CB
CA
AB
=
=
=
u
v
w



  Then we calculate  
,
a = u  
,
b = v   and  c = w   so as to verify that  
2
2
2.
a
b
c
+
=
 
 
5. 
2
2
2
(1,1,2, 1),
(1, 1,1,2),
(0,2,1, 3);
7,
7,
14
a
b
c
=
−
=
−
=
−
=
=
=
u
v
w
 
 
6. 
2
2
2
(3, 1,2,2),
(2,2, 3,1),
(1, 3,5,1);
18,
18,
36
a
b
c
=
−
=
−
=
−
=
=
=
u
v
w
 
 
7. 
2
2
2
(2,1, 2,1,3),
(3,2,2,2, 2),
( 1, 1, 4, 1,5);
19,
25,
44
a
b
c
=
−
=
−
= −−−
−
=
=
=
u
v
w
 
 
8. 
2
2
2
(3,2,4,5,7),
(7,5, 5,2, 3),
( 4, 3,9,3,10);
103,
112,
215
a
b
c
=
=
−
−
= −
−
=
=
=
u
v
w
 
 
The computations in Problems 5–8 show that in each triangle  ABC
∆
 the angle at  C  is a right 
angle.  The angles at the vertices  A  and  B  are then determined by the relations 

 
Section 4.6 
221 
 
 
cos
and
cos
.
AB AC
BA BC
A
B
AB AC
BA BC
⋅
⋅
⋅
⋅
∠=
= −
∠
=
= +
v w
u w
v w
u w
 
 


 
The fact that  
90
A
B
°
∠+ ∠
=
 then serves as a check on our numerical computations. 
 
9. 
1
1
1
1
7
1
7
1
cos
cos
45 ,
cos
cos
45
7 14
2
7 14
2
A
B
−
−
°
−
−
°
−








∠=
−
=
=
∠
=
+
=
=
















 
 
10. 
1
1
18
1
cos
cos
45 ,
18 36
2
A
−
−
°
−




∠=
−
=
=








 
 
1
1
18
1
cos
cos
45
18 36
2
B
−
−
°




∠
=
+
=
=








 
 
11. 
1
1
25
25
cos
cos
41.08 ,
44
25 44
A
−
−
°


−


∠
=
−
=
=








 
 
1
1
19
19
cos
cos
48.92
44
19 44
B
−
−
°




∠
=
=
=








 
 
12. 
1
1
112
112
cos
cos
43.80 ,
215
112 215
A
−
−
°


−


∠
=
−
=
=








 
 
1
1
103
103
cos
cos
46.20
215
103 215
B
−
−
°




∠
=
=
=








 
 
In each of Problems 13–22, we denote by  A  the matrix having the given vectors as its row 
vectors, and by  E  the reduced echelon form of  A.  From  E  we find the general solution of the 
homogeneous system  
=
Ax
0  in terms of parameters  , ,
.
s t …   We then get basis vectors  
1
2
,
,
u u … for the orthogonal complement  V ⊥ by setting each parameter in turn equal to  1  (and 
the others then equal to 0). 
 
13. 
[
]
2
3
1
1
2
3 ;
,
,
2
3
x
s
x
t
x
s
t
=
=
−
=
=
=
−
A
E
 
 
1
2
(2,1,0),
( 3,0,1)
=
=
−
u
u
  
 
14. 
[
]
2
3
1
1
5
3 ;
,
,
5
3
x
s
x
t
x
s
t
=
=
−
=
=
= −
+
A
E
 
 
1
2
( 5,1,0),
(3,0,1)
=
−
=
u
u
  
 
15. 
[
]
2
3
4
1
1
2
3
5 ;
,
,
,
2
3
5
x
r
x
s
x
t
x
r
s
t
=
=
−
−
=
=
=
=
+
−
A
E
 
 
1
2
3
(2,1,0,0),
(3,0,1,0),
( 5,0,0,1)
=
=
=
−
u
u
u
  
 

222 
Chapter 4 
16. 
[
]
2
3
4
1
1
7
6
9 ;
,
,
,
7
6
9
x
r
x
s
x
t
x
r
s
t
=
=
−
−
=
=
=
= −
+
+
A
E
 
 
1
2
3
( 7,1,0,0),
(6,0,1,0),
(9,0,0,1)
=
−
=
=
u
u
u
  
 
17. 
1
0
7
19
0
1
3
5
−


= 

−


E
 
 
3
4
2
1
,
,
3
5 ,
7
19
x
s
x
t
x
s
t
x
s
t
=
=
= −
+
=
−
 
 
1
2
(7, 3,1,0),
( 19,5,0,1)
=
−
=
−
u
u
  
 
18. 
1
0
12
16
0
1
3
7
−


= 

−


E
 
 
3
4
2
1
,
,
3
7 ,
12
16
x
s
x
t
x
s
t
x
s
t
=
=
= −
+
= −
+
 
 
1
2
( 12, 3,1,0),
(16,7,0,1)
=
−
−
=
u
u
  
 
19. 
1
0
13
4
11
0
1
4
3
4
−


= 

−
−


E
 
 
3
4
5
2
1
,
,
,
4
3
4 ,
13
4
11
x
r
x
s
x
t
x
r
s
t
x
r
s
t
=
=
=
=
−
+
= −
+
−
 
 
1
2
3
( 13,4,1,0,0),
(4, 3,0,1,0),
( 11,4,0,0,1)
=
−
=
−
=
−
u
u
u
  
 
20. 
1
0
5
12
19
0
1
1
4
7


= 

−
−
−


E
 
 
3
4
5
2
1
,
,
,
4
7 ,
5
12
19
x
r
x
s
x
t
x
r
s
t
x
r
s
t
=
=
=
=
+
+
= −
−
−
 
 
1
2
3
( 5,1,1,0,0),
( 12,4,0,1,0),
( 19,7,0,0,1)
=
−
=
−
=
−
u
u
u
  
 
21. 
1
0
1
0
0
0
1
1
0
1
0
0
0
1
1




= 





E
 
 
3
5
4
2
1
,
,
,
,
x
s
x
t
x
t
x
s
t
x
s
=
=
= −
= −−
= − 
 
1
2
( 1, 1,1,0,0),
(0, 1,0, 1,1)
=
−−
=
−
−
u
u
  
 

 
Section 4.6 
223 
 
22. 
1
0
2
1
0
0
1
1
2
0
0
0
0
0
1
−




=
−






E
 
 
3
4
5
2
1
,
,
0,
2 ,
2
x
s
x
t
x
x
s
t
x
s
t
=
=
=
=
−
= −
+  
 
1
2
( 2,1,1,0,0),
(1, 2,0,1,0)
=
−
=
−
u
u
  
 
23. 
(a) 
2
2
(
2
)
(
2
)
+
+
−
=
⋅
+
⋅
+
⋅
+
⋅
−
⋅
+
⋅
u
v
u
v
u u
u v
v v
u u
u v
v v  
 
 
 
 
2
2
2
2
2
=
+
=
⋅
+
⋅
u
v
u u
u u 
 
(b) 
2
2
(
2
)
(
2
)
4
+
−
−
=
⋅
+
⋅
+
⋅
−
⋅
−
⋅
+
⋅
=
⋅
u
v
u
v
u u
u v
v v
u u
u v
v v
u v  
 
24. 
Equation (15) in the text says that the given formula holds for  
2
k =
 vectors.  Assume 
inductively that it holds for  
1
k
n
=
− vectors.  Then 
 
 
 
2
2
2
1
2
1
1
2
1
n
n
n
n
−
−
+
+
+
=
+
+
+
v
v
v
v
v
v
v
v


 
 
 
 
 
 
(
)
2
2
2
2
1
2
1
n
n
−
=
+
+
+
+
v
v
v
v

 
 
 
as desired.  The case  
2
k =
 is used for the first equality here, and the case  
1
k
n
=
− for 
the second one. 
 
25. 
Suppose, for instance, that  
1
3
(1,0,0,0,0),
(0,0,1,0,0),
A
B
=
=
=
=
e
e
 and  
5
5
(0,0,0,0,1) in
.
C =
=
e
R   Then  
3
1
( 1,0,1,0,0)
AB =
−
= −
e
e

  and  
5
1
(0,0,1,0,0, 1).
AC =
−
=
−
e
e

  Then  
1
AB AC
⋅
=
 
  while  
2.
AB
AC
=
=


  It follows 
that  
1
2
cos
1/( 2)( 2)
, so
60 .
A
A
∠
=
=
∠=
°   Similarly,  
60 ,
B
C
∠
= ∠
=
°  so we see 
that  ABC
∆
 is an equilateral triangle. 
 
26. 
Because  
cos ,
θ
⋅
=
u v
u v
 it follows that  
⋅
=
u v
u v   if and only if  cos
1,
θ =
 in which 
case  
0
θ =
 so the two vectors are collinear. 
 
27. 
If the u  lines both in the subspace  V  and in its orthogonal complement  
,
V ⊥ then the 
vector  u  is orthogonal to itself.  Hence  
2
0,
u
⋅
=
=
u
u
 so it follows that  
.
=
u
0  
 
28. 
If  W  is the orthogonal complement of  V,  then every vector in  V  is orthogonal to every 
vector in  W.  Hence  V  is contained in  
.
W ⊥  But it follows from Equation (18) in this 
section that the two subspaces  V  and  W ⊥ have the same dimension.  Because one 
contains the other, they must therefore be the same subspace,  so  W
V
⊥=
 as desired. 
 

224 
Chapter 4 
29. 
If  u  is orthogonal to each vector in the set  S  of vectors, then it follows easily (using the 
dot product) that  u  is orthogonal to every linear combination of vectors in  S.  Therefore  
u  is orthogonal to  
Span( ).
V
S
=
 
 
30. 
If  
0
⋅
=
u v
  and  
+
=
u
v
0 then 
 
 
 
 
0
(
)
,
=
⋅
+
=
⋅
+
⋅
=
⋅
u
u
v
u u
u v
u u  
 
 
so it follows that  
,
=
u
0  and then  
+
=
u
v
0  implies that  
=
v
0 also. 
 
31. 
We want to show that any linear combination of vectors  
1
2
,
,
,
p
u u
u
…
 of vectors in  S  is 
orthogonal to every linear combination of vectors  
1
2
,
,
,
q
v
v
v
…
 in  T.  But if each  
iu  is  
 
orthogonal to each  
,
j
v
 so  
0,
i
j
⋅
=
u
v
 then it follows that 
 
 
(
) (
)
1
1
2
2
1
1
2
2
1
1
0,
p
q
p
p
q
q
i
j
i
j
i
j
a
a
a
b
b
b
a b
=
=
+
+
+
⋅
+
+
+
=
⋅
=
∑∑
u
u
u
v
v
v
u
v


 
 
so we see that the two linear combinations are orthogonal, as desired. 
 
32. 
Suppose that the linear combination  
1
1
2
2
1
1
2
2
,
a
a
b
b
+
+
+
=
u
u
v
v
0  and we want to deduce 
that all four coefficients  
1
2
1
2
,
,
,
a a
b b  must necessarily be zero.  For this purpose, write 
 
 
 
 
1
1
2
2
a
a
=
+
u
u
u           and          
1
1
2
2.
b
b
=
+
v
v
v
 
 
 
Then the vectors  u  and  v  are orthogonal by Problem 31, so by Problem 30 the fact that  
+
=
u
v
0  implies that 
 
 
 
        
1
1
2
2
a
a
=
+
=
u
u
u
0       and       
1
1
2
2
.
b
b
=
+
=
v
v
v
0  
 
 
Now the assumed linear independence of   {
}
1
2
,
u u
 implies that  
1
2
0,
a
a
=
=
  and the 
assumed linear independence of  {
}
1
2
,
v v
 implies that  
1
2
0.
b
b
=
=
  Thus we conclude 
that all four coefficients are zero, as desired. 
 
33. 
This is the same as Problem 32, except with   
 
 
 
1
1
2
2
k
k
a
a
a
=
+
+
+
u
u
u
u

       and      
1
1
2
2
.
m
m
b
b
b
=
+
+
+
v
v
v
v

 
 
34. 
It follows immediately from Problem 33 and from Equation (18) in the text that the union 
of a basis for the subspace  V  and a basis for its orthogonal complement  V ⊥ is a linearly 
independent set of  n  vectors, and is therefore a basis for the n-dimensional vector space  
.
n
R
 
 
 

 
Section 4.6 
225 
 
35. 
This is one of the fundamental theorems of linear algebra.  The nonhomogeneous system 
 
 
 
 
 
 
=
Ax
b  
 
is consistent if and only if the vector  b  is in the subspace  Col(
)
Row(
).
T
=
A
A
  But  b  
is in  Row(
)
T
A
 if and only if  b  is orthogonal to the orthogonal complement of  
Row(
)
T
A
.  But  Row(
)
Null(
),
T
T
⊥=
A
A
 which is the solution space of the 
homogeneous system 
 
 
 
 
 
 
.
T
=
A y
0  
 
Thus we have proved (as desired) that the nonhomogeneous system  
=
Ax
b  has a 
solution if and only if the constant vector  b  is orthogonal to every solution  y  of the 
nonhomogeneous system  
.
T
=
A y
0  
 
 
 
SECTION 4.7 
 
GENERAL VECTOR SPACES 
 
In each of Problems 1–12, a certain subset of a vector space is described.  This subset is a subspace 
of the vector space if and only if it is closed under the formation of linear combinations of its 
elements.  Recall also that every subspace of a vector space must contain the zero vector. 
 
1. 
It is a subspace of  M33, because any linear combination of diagonal 3 3
×  matrices — with 
only zeros off the principal diagonal — obviously is again a diagonal matrix. 
 
2. 
The square matrix  A  is symmetric if and only if  AT = A.  If  A  and  B  are symmetric 
3 3
×  matrices, then  (
)
,
T
T
T
c
d
c
d
c
d
+
=
+
=
+
A
B
A
B
A
B  so the linear combination  
c
d
+
A
B  is also symmetric.  Thus the set of all such matrices is a subspace.  
 
3. 
The set of all nonsingular 3 3
×  matrices does not contain the zero matrix, so it is not a 
subspace. 
 
4. 
The set of all singular 3 3
×  matrices is not a subspace, because the sum 
 
 
 
1
0
0
0
0
0
1
0
0
0
0
0
0
1
0
0
1
0
0
0
0
0
0
1
0
0
1












+
=


















 
 
 
of singular matrices is not singular. 
 
5. 
The set of all functions  
:
f
→
R
R  with  
(0)
0
f
=
 is a vector space, because if  
(0)
(0)
0
f
g
=
=
 then  (
)(0)
(0)
(0)
0
0
0.
a f
bg
a f
bg
a
b
+
=
+
=
⋅+ ⋅
=
 

226 
Chapter 4 
6. 
The set of all functions  
:
f
→
R
R  with  
(0)
0
f
≠
 is not a vector space, because it does 
not contain the zero function  
(0)
0.
f
≡
 
 
7. 
The set of all functions  
:
f
→
R
R  with  
(0)
0 and
(1)
1
f
f
=
=  is not a vector space.  For 
instance, if  
2
then
(1)
2 (1)
2 1
2
1,
g
f
g
f
=
=
=
⋅=
≠
 so  g  is not such a function.  Also, 
this set does not contain the zero function. 
 
8. 
A function  
:
f
→
R
R  such that  
(
)
( )
f
x
f x
−
= −
 is called an odd function.  Any linear 
combination  af
bg
+
 of odd functions is again odd, because 
 
 
 
(
)(
)
(
)
(
)
( )
( )
(
)( ).
a f
bg
x
a f
x
bg
x
a f x
bg x
a f
bg
x
+
−
=
−
+
−
= −
−
= −
+
 
 
 
Thus the set of all odd functions is a vector space. 
 
 
For Problems 9–12, let us call a polynomial of the form 
2
3
0
1
2
3
a
a x
a x
a x
+
+
+
 a "degree at most 3" 
polynomial. 
   
9. 
The set of all degree at most 3 polynomials with nonzero leading coefficient  
3
0
a ≠
 is not a 
vector space, because it does not contain the zero polynomial (with all coefficients zero). 
 
10. 
The set of all degree at most 3 polynomials not containing  x  or  x2  terms is a vector space, 
because any linear combination of such polynomials obviously is such a polynomial. 
 
11. 
The set of all degree at most 3 polynomials with coefficient sum zero is a vector space, 
because any linear combination of such polynomials obviously is such a polynomial. 
 
12. 
If the degree at most 3 polynomials  f  and  g  have all-integer coefficients, the linear 
combination  a f
b g
+
may have non-integer coefficient, because a  and  b  need not be 
integers.  Hence the set of all degree at most 3 polynomials having all-integer coefficients is 
not a vector space. 
 
13. 
The functions  sin
and cos
x
x  are linearly independent, because neither is a scalar 
multiple of the other.  (This follows, for instance, from the facts that  sin(0)
0, cos(0)
1
=
=  
and  sin( / 2)
1, cos( / 2)
0,
π
π
=
=
 noting that any scalar multiple of a function with a zero 
value must have the value 0 at the same point.) 
 
14. 
The functions  
and
x
x
e
xe are linearly independent, since obviously neither is a scalar 
multiple of the other (their ratios  
/
and
/
x
x
x
x
xe
e
x
e
xe
=
 neither being constants). 
 
15. 
If   
2
2
1
2
3
1
2
3
1
2
3
(1
)
(1
)
(1
)
(
)
(
)
0,
c
x
c
x
c
x
c
c
c
c
c x
c x
+
+
−
+
−
=
+
+
+
−
−
=
 

 
Section 4.7 
227 
 
 
then 
 
 
 
 
1
2
3
1
2
3
0.
c
c
c
c
c
c
+
+
=
−
=
=
 
 
 
It follows easily that  
1
2
3
0,
c
c
c
=
=
=
 so we conclude that the functions  (1
), (1
),
x
x
+
−
 
 
and  
2
(1
)
x
−
  are linearly independent. 
 
16. 
2
2
( 1) (1
)
(1) (
)
(1) (1
)
0,
x
x
x
x
−
⋅
+
+
⋅
+
+
⋅
−
=
 so the three given polynomials are linearly 
dependent. 
 
17. 
2
2
cos 2
cos
sin
x
x
x
=
−
  according to a well-known trigonometric identity.  Thus these 
three trigonometric functions are linearly dependent. 
 
18. 
If   
 
     
1
2
1
2
1
2
(2cos
3sin )
(4cos
5sin )
(2
4
)cos
(3
5
)sin
0
c
x
x
c
x
x
c
c
x
c
c
x
+
+
+
=
+
+
+
=
 
 
 
then the fact that  sin
and cos
x
x  are linearly independent (Problem 13) implies that 
 
1
2
1
2
2
4
3
5
0.
c
c
c
c
+
=
+
=
  It follows readily that  
1
2
0,
c
c
=
=
 so we conclude that the two 
original linear combinations of  sin
and cos
x
x  are linearly independent. 
 
19. 
Multiplication by  (
2)(
3)
x
x
−
−
 yields 
 
 
 
 
5
(
3)
(
2)
(
)
(3
2 ).
x
A x
B x
A
B x
A
B
−
=
−
+
−
=
+
−
+
 
 
 
Hence  
1 and 3
2
5,
A
B
A
B
+
=
+
=
 and it follows readily that   A = 3  and  B = –2. 
 
20. 
Multiplication by  
2
(
1)
x x −
 yields 
 
 
 
2
2
2
(
1)
(
1)
(
1)
(
)
(
)
.
A x
Bx x
Cx x
A
B
C x
A
B
C x
=
−
+
+
+
−
= −
+
−
+
+
+
 
 
 
Hence  
2,
0 and
0.
A
B
C
A
B
C
−
=
−
=
+
+
=
  It follows readily that   A = –2  and   
B = C = 1. 
 
21. 
Multiplication by  
2
(
4)
x x +
 yields 
 
 
 
 
2
2
2
8
(
4)
4
(
)
.
A x
Bx
Cx
A
Cx
A
B x
=
+
+
+
=
+
+
+
 
 
 
Hence  4
8,
0 and
0.
A
C
A
B
=
=
+
=
  It follows readily that   A = 2  and  B = –2. 
 

228 
Chapter 4 
22. 
Multiplication by  (
1)(
2)(
3)
x
x
x
+
+
+
 yields 
 
 
 
 
2
2
(
2)(
3)
(
1)(
3)
(
1)(
2)
(
)
(5
4
3 )
(6
3
2 ).
x
A x
x
B x
x
C x
x
A
B
C x
A
B
C x
A
B
C
=
+
+
+
+
+
+
+
+
=
+
+
+
+
+
+
+
+
 
 
Hence 
 
 
 
 
 
0
5
4
3
2
6
3
2
0,
A
B
C
A
B
C
A
B
C
+
+
=
+
+
=
+
+
=
 
 
 
and we solve these three equations for  A = –1,  B = 4,  and  C = –3. 
 
23. 
If  
( )
0
y
x
′′′
=
 then 
 
 
 
2
1
2
( )
( )
(0)
,
( )
( )
, and
( )
( )
(
)
,
y x
y
x dx
dx
A
y x
y x dx
Adx
Ax
B
y x
y x dx
Ax
B dx
Ax
Bx
C
′′
′′′
=
=
=
′
′′
=
=
=
+
′
=
=
+
=
+
+
∫
∫
∫
∫
∫
∫
 
 
 
 
where  A,  B,  and  C  are arbitrary constants of integration.  It follows that the function  
( )
y x  is a solution of the differential equation  
( )
0
y
x
′′′
=
  if and only if it is a quadratic (at 
most 2nd degree) polynomial.  Thus the solution space is 3-dimensional with basis  
{
}
2
1, ,
.
x x
 
 
24. 
If  
(4)( )
0
y
x =
 then 
 
 
 
(4)
2
1
2
2
2
1
1
1
2
6
2
( )
( )
(0)
,
( )
( )
,
( )
( )
(
)
, and
( )
( )
(
)
.
y
x
y
x dx
dx
A
y x
y
x dx
Adx
Ax
B
y x
y x dx
Ax
B dx
Ax
Bx
C
y x
y x dx
Ax
Bx
C dx
Ax
Bx
Cx
D
′′′
=
=
=
′′
′′′
=
=
=
+
′
′′
=
=
+
=
+
+
′
=
=
+
+
=
+
+
+
∫
∫
∫
∫
∫
∫
∫
∫
 
 
 
 
where  A,  B,  C,  and  D  are arbitrary constants of integration.  It follows that the function  
( )
y x  is a solution of the differential equation  
(4)( )
0
y
x =
  if and only if it is a cubic (at 
most 3rd degree) polynomial.  Thus the solution space is 4-dimensional with basis  
{
}
2
3
1, ,
,
.
x x
x
 
 
25. 
If  ( )
y x  is any solution of the second-order differential equation  
5
0
y
y
′′
′
−
=
 and  
( )
( ),
v x
y x
′
=
 then  ( )
v x  is a solution of the first-order differential equation  
( )
5 ( )
v x
v x
′
=
 
with the familiar exponential solution  
5
( )
.
x
v x
Ce
=
  Therefore 

 
Section 4.7 
229 
 
 
 
 
5
5
1
5
( )
( )
( )
.
x
x
y x
y x dx
v x dx
Ce
dx
Ce
D
′
=
=
=
=
+
∫
∫
∫
 
 
 
We therefore see that the solution space of the equation  
5
0
y
y
′′
′
−
=
 is 2-dimensional with 
basis  {
}
5
1,
.
x
e
 
 
26. 
If  ( )
y x  is any solution of the second-order differential equation  
10
0
y
y
′′
′
+
=
 and  
( )
( ),
v x
y x
′
=
 then  ( )
v x  is a solution of the first-order differential equation  
( )
10 ( )
v x
v x
′
= −
 with the familiar exponential solution  
10
( )
.
x
v x
Ce−
=
  Therefore 
 
 
 
10
10
1
10
( )
( )
( )
.
x
x
y x
y x dx
v x dx
Ce
dx
Ce
D
−
′
=
=
=
= −
+
∫
∫
∫
 
 
 
We therefore see that the solution space of the equation  
10
0
y
y
′′
′
+
=
 is 2-dimensional with 
basis  {
}
10
1,
.
x
e−
 
 
27. 
If we take the positive sign in Eq. (20) of the text, then we have  
2
2
2
v
y
a
=
+
 where   
( )
( ).
v x
y x
′
=
  Then   
2
2
2
2
2
1
, so
dy
dx
y
a
dx
dy
y
a


=
+
=




+
 
 
 
(taking the positive square root as in the text).  Then   
 
 
 
 
2
2
2
2
2
1
1
2
(
)
sinh
sinh
.
1
dy
a du
x
y
au
y
a
a u
a
du
y
u
b
b
a
u
−
−
=
=
=
+
+
=
=
+
=
+
+
⌠
⌠


⌡
⌡
⌠
⌡
 
 
 
It follows that   
 
 
 
(
)
( )
sinh(
)
sinh cosh
cosh sinh
cosh
sinh .
y x
a
x
b
a
x
b
x
b
A
x
B
x
=
−
=
−
=
+
 
 
28. 
We start with the second-order differential equation  
0
y
y
′′+
=
 and substitute  
( )
( ),
v x
y x
′
=
 so 
 
 
 
dv
dv dy
dv
y
v
y
dx
dy dx
dy
′′ =
=
=
= −
 

230 
Chapter 4 
 
as in Example 9 of the text.  Then  
,
vdv
y dy
= −
 and integration gives 
 
 
 
 
2
2
2
2
2
1
1
2
2
,
so
v
y
C
v
a
y
= −
+
=
−
 
 
 
(taking for illustration a positive value for the arbitrary constant  C).  Then 
 
 
2
2
2
2
2
1
, so
dy
dx
a
y
dx
dy
a
y


=
−
=




−
 
 
 
(taking the positive square root).  Then   
 
 
 
 
2
2
2
2
2
1
1
2
(
)
sin
sin
.
1
dy
a du
x
y
au
a
y
a
a u
du
y
u
b
b
a
u
−
−
=
=
=
−
−
=
=
+
=
+
−
⌠
⌠


⌡
⌡
⌠
⌡
 
 
 
It follows that   
 
 
 
(
)
( )
sin(
)
sin cos
cos sin
cos
sin .
y x
a
x
b
a
x
b
x
b
A
x
B
x
=
−
=
−
=
+
 
 
 
Thus the general solution of the 2nd-order differential equation  
0
y
y
′′+
=
 is a linear 
combination of  cos
and sin .
x
x   It follows that the solution space is 2-dimensional with 
basis  {
}
cos ,sin
.
x
x
 
 
29. 
(a) 
The verification in a component-wise manner that  V  is a vector space is the same as 
the verification that Rn is a vector space, except with vectors having infinitely many 
components rather than finitely many components.  It boils down to the fact that a linear 
combination of infinite sequences of real numbers is itself such a sequence, 
 
 
 
 
{ }
{
}
{
}
1
1
1 .
n
n
n
n
a
x
b
y
ax
by
∞
∞
∞
⋅
+
⋅
=
+
 
 
(b) 
If  
{0,
, 0,1, 0, 0,
}
n =
e

   is the indicated infinite sequence with  1  in the nth 
position, then the fact that   
 
 
 
1 1
2
2
1
2
{ ,
,
,
, 0, 0,
}
k
k
k
c
c
c
c c
c
+
+
+
=
e
e
e


  
 

 
Section 4.7 
231 
 
evidently implies that any finite set  
1
2
,
,
,
k
e e
e

 of these vectors is linearly independent.  
Thus V contains "arbitrarily large" sets of linearly independent vectors, and therefore is 
infinite-dimensional. 
 
30. 
(a) 
If   
1
2
1
2
,
and
n
n
n
n
n
n
n
n
n
x
x
x
y
y
y
z
ax
by
−
−
−
−
=
+
=
+
=
+
 for each  n,  then 
 
 
 
 
1
2
1
2
1
1
2
2
1
2
(
)
(
)
(
)
(
)
.
n
n
n
n
n
n
n
n
n
n
n
z
a x
x
b y
y
ax
by
ax
by
z
z
−
−
−
−
−
−
−
−
−
−
=
+
+
+
=
+
+
+
=
+
 
 
 
Thus  W  is a subspace of  V. 
 
(b) 
Let  
1
{1,0,1,1,2,3,5,
}
=
v
  be the element with  
1
2
1 and
0,
x
x
=
=
 and let 
2
{0,1,1,2,3,5,
}
=
v
  be the element with  
1
2
0 and
1.
x
x
=
=
  Then  v1  and  v2  form a 
basis for  W. 
 
31. 
(a) 
If  
1
1
1
z
a
ib
=
+
 and  
2
2
2
z
a
ib
=
+
,  then direct computation shows that 
 
 
1 1
2
2
1 1
2
2
1 1
2
2
1
1
2
2
1 1
2
2
1 1
2
2
(
)
( )
(
)
.
c a
c a
c b
b a
T c z
c z
c T z
c T z
c b
b a
c a
c a
+
−
−


+
=
+
= 

+
+


 
(b) 
If  
1
1
1
z
a
ib
=
+
 and  
2
2
2
z
a
ib
=
+
,  then  
1 2
1
2
1 2
1 2
2 1
(
)
(
)
z z
a a
bb
i a b
a b
=
−
+
+
 and  
direct computation shows that 
 
 
1
2
1 2
1 2
2 1
1 2
1
2
1 2
2 1
1
2
1 2
(
)
( ) (
)
.
a a
bb
a b
a b
T z z
T z T z
a b
a b
a a
bb
−
−
−


=
= 

+
−


 
 
(b) 
If  z
a
ib
=
+
  then 
 
 
 
2
2
1
1
.
a
bi
a
bi
z
a
bi a
bi
a
b
−
−
=
⋅
=
+
−
+
 
Therefore   
 
1
1
1
2
2
1
(
)
( ) .
a
b
a
b
T z
T z
b
a
b
a
a
b
−
−
−
−




=
=
=




−
+




 
 
 

232 
Chapter 5 
 
CHAPTER 5 
 
HIGHER-ORDER LINEAR DIFFERENTIAL EQUATIONS 
 
 
SECTION 5.1 
 
INTRODUCTION:  SECOND-ORDER LINEAR EQUATIONS 
 
In this section the central ideas of the theory of linear differential equations are introduced and 
illustrated concretely in the context of second-order equations.  These key concepts include 
superposition of solutions (Theorem 1), existence and uniqueness of solutions (Theorem 2), 
linear independence, the Wronskian (Theorem 3), and general solutions (Theorem 4).  This 
discussion of second-order equations serves as preparation for the treatment of nth order linear 
equations in Section 5.2.  Although the concepts in this section may seem somewhat abstract to 
students, the problems set is quite tangible and largely computational. 
 
In each of Problems 1–16 the verification that  y1  and  y2  satisfy the given differential equation 
is a routine matter.  As in Example 2, we then impose the given initial conditions on the general 
solution  y  =  c1y1 + c2y2.  This yields two linear equations that determine the values of the 
constants  c1  and  c2.  
 
1. 
Imposition of the initial conditions  (0)
0,
(0)
5
y
y′
=
=
 on the general solution  
1
2
( )
x
x
y x
c e
c e−
=
+
 yields the two equations  
1
2
1
2
0,
0
c
c
c
c
+
=
−
=
 with solution  
1
2
5/ 2,
5/ 2.
c
c
=
= −
  Hence the desired particular solution is  y(x)  =  5(ex - e-x)/2. 
  
 
 
 
2. 
Imposition of the initial conditions  (0)
1,
(0)
15
y
y′
= −
=
 on the general solution  
3
3
1
2
( )
x
x
y x
c e
c e−
=
+
 yields the two equations  
1
2
1
2
1, 3
3
15
c
c
c
c
+
= −
−
=
 with solution  
1
2
2,
3.
c
c
=
=
  Hence the desired particular solution is  y(x)  =  2e3x - 3e-3x.      
 
3. 
Imposition of the initial conditions  (0)
3,
(0)
8
y
y′
=
=
 on the general solution  
1
2
( )
cos2
sin2
y x
c
x
c
x
=
+
 yields the two equations  
1
2
3, 2
8
c
c
=
=
 with solution  
1
2
3,
4.
c
c
=
=
  Hence the desired particular solution is  y(x)  =  3 cos 2x + 4 sin 2x.   
 
 
4. 
Imposition of the initial conditions  (0)
10,
(0)
10
y
y′
=
= −
 on the general solution  
1
2
( )
cos5
sin5
y x
c
x
c
x
=
+
 yields the two equations  
1
2
10, 5
10
c
c
=
= −
 with solution  
1
2
3,
4.
c
c
=
=
  Hence the desired particular solution is  y(x)  =  10 cos 5x - 2 sin 5x. 
 

 
Section 5.1 
233 
5. 
Imposition of the initial conditions  (0)
1,
(0)
0
y
y′
=
=
 on the general solution  
2
1
2
( )
x
x
y x
c e
c e
=
+
 yields the two equations  
1
2
1
2
1,
2
0
c
c
c
c
+
=
+
=
 with solution  
1
2
2,
1.
c
c
=
= −
  Hence the desired particular solution is  y(x)  =  2ex - e2x.            
 
 
6. 
Imposition of the initial conditions  (0)
7,
(0)
1
y
y′
=
= − on the general solution  
2
3
1
2
( )
x
x
y x
c e
c e−
=
+
 yields the two equations  
1
2
1
2
7, 2
3
1
c
c
c
c
+
=
−
= − with solution  
1
2
4,
3.
c
c
=
=
  Hence the desired particular solution is  y(x)  =  4e2x + 3e-3x.          
 
7. 
Imposition of the initial conditions  (0)
2,
(0)
8
y
y′
= −
=
 on the general solution  
1
2
( )
x
y x
c
c e−
=
+
 yields the two equations  
1
2
2
2,
8
c
c
c
+
= −
−
=
 with solution  
1
2
6,
8.
c
c
=
= −
  Hence the desired particular solution is  y(x)  =  6 − 8e-x.             
 
 
8. 
Imposition of the initial conditions  (0)
4,
(0)
2
y
y′
=
= −
 on the general solution  
3
1
2
( )
x
y x
c
c e
=
+
 yields the two equations  
1
2
2
4, 3
2
c
c
c
+
=
= −
 with solution  
1
2
14/ 3,
2 /3.
c
c
=
=
  Hence the desired particular solution is  y(x)  =  (14 - 2e3x)/3. 
 
9. 
Imposition of the initial conditions  (0)
2,
(0)
1
y
y′
=
= − on the general solution  
1
2
( )
x
x
y x
c e
c x e
−
−
=
+
 yields the two equations  
1
1
2
2,
1
c
c
c
=
−
+
= − with solution  
1
2
2,
1.
c
c
=
=
  Hence the desired particular solution is  y(x)  =  2e-x + xe-x.             
 
 
10. 
Imposition of the initial conditions  (0)
3,
(0)
13
y
y′
=
=
 on the general solution  
5
5
1
2
( )
x
x
y x
c e
c xe
=
+
 yields the two equations  
1
1
2
3, 5
13
c
c
c
=
+
=
 with solution  
1
2
3,
2.
c
c
=
= −
  Hence the desired particular solution is  y(x)  =  3e5x - 2xe5x. 
 
11. 
Imposition of the initial conditions  (0)
0,
(0)
5
y
y′
=
=
 on the general solution  
1
2
( )
cos
sin
x
x
y x
c e
x
c e
x
=
+
 yields the two equations  
1
1
2
0,
5
c
c
c
=
+
=
 with solution  
1
2
0,
5.
c
c
=
=
  Hence the desired particular solution is  y(x)  =  5exsin x. 
 
12. 
Imposition of the initial conditions  (0)
2,
(0)
0
y
y′
=
=
 on the general solution  
3
3
1
2
( )
cos2
sin 2
x
x
y x
c e
x
c e
x
−
−
=
+
 yields the two equations  
1
1
2
2,
3
2
5
c
c
c
=
−
+
=
 with 
solution  
1
2
2,
3.
c
c
=
=
  Hence the desired particular solution is  y(x)  =   
 
e-3x(2 cos 2x + 3 sin 2x). 
 
13. 
Imposition of the initial conditions  (1)
3,
(1)
1
y
y′
=
=  on the general solution  
2
1
2
( )
y x
c x
c x
=
+
 yields the two equations  
1
2
1
2
3,
2
1
c
c
c
c
+
=
+
=  with solution  
1
2
5,
2.
c
c
=
= −
  Hence the desired particular solution is  y(x)  =  5x - 2x2.  
 
 

234 
Chapter 5 
14. 
Imposition of the initial conditions  (2)
10,
(2)
15
y
y′
=
=
 on the general solution  
2
3
1
2
( )
y x
c x
c x−
=
+
 yields the two equations  
1
2
1
2
4
/8
10, 4
3
/16
15
c
c
c
c
+
=
−
=
 with 
solution  
1
2
3,
16.
c
c
=
= −
  Hence the desired particular solution is  y(x)  =  3x2 - 16/x3.      
 
15. 
Imposition of the initial conditions  (1)
7,
(1)
2
y
y′
=
=
 on the general solution  
1
2
( )
ln
y x
c x
c x
x
=
+
 yields the two equations  
1
1
2
7,
2
c
c
c
=
+
=
 with solution  
1
2
7,
5.
c
c
=
= −
  Hence the desired particular solution is  y(x)  =  7x - 5x ln x. 
 
 
 
16. 
Imposition of the initial conditions  (1)
2,
(1)
3
y
y′
=
=
 on the general solution  
1
2
( )
cos(ln )
sin(ln )
y x
c
x
c
x
=
+
 yields the two equations  
1
2
2,
3.
c
c
=
=
  Hence the 
desired particular solution is  y(x)  =  2 cos(ln x) + 3 sin(ln x). 
 
17. 
If  
/
y
c x
=
 then  
2
2
2
2
2
/
/
(
1)/
0
y
y
c x
c
x
c c
x
′ +
= −
+
=
−
≠
  unless either  c = 0   
 
or  c = 1. 
 
18. 
If  
3
y
cx
=
 then  
3
2
4
4
6
6
6
yy
cx
cx
c x
x
′′ =
⋅
=
≠
 unless  
2
1.
c =
 
 
19. 
If  
1
y
x
= +
 then  
2
3/ 2
1/ 2
2
3/ 2
(
)
(1
)(
/ 4)
(
/ 2)
/ 4
0.
yy
y
x
x
x
x
−
−
−
′′
′
+
=
+
−
+
= −
≠
 
 
20. 
Linearly dependent, because 
 
 
 
 
 
f(x)  =  π  =  π(cos2x + sin2x)  =  π g(x) 
 
21. 
Linearly independent, because  
3
2
x
x x
= +
  if  x > 0,  whereas  
3
2
x
x x
= −
  if  x < 0. 
 
22. 
Linearly independent, because 1
(1
)
x
c
x
+
=
+
  would require that  c  =  1  with  x  =  0,  
but  c  =  0  with  x  =  -1.  Thus there is no such constant  c.   
 
23. 
Linearly independent, because  f(x)  =  +g(x)  if  x > 0,  whereas  f(x)  =  -g(x)  if  x < 0. 
 
24. 
Linearly dependent, because  g(x)  =  2 f(x). 
 
25. 
f(x)  =  exsin x  and  g(x)  =  excos x  are linearly independent, because  f(x)  =  k g(x)  
would imply that  sin x  =  k cos x,  whereas  sin x  and  cos x  are linearly independent. 
 
26. 
To see that  f(x) and  g(x)  are linearly independent, assume that  f(x)  =  c g(x),  and then 
substitute both  x  =  0  and  x  =  π/2. 
 
27. 
Let  L[y]  =  y″ + py′ + qy.  Then  L[yc]  =  0  and  L[yp]  =  f,  so 
 
 
 
 
 
L[yc + yp]  =  L[yc] + [yp]  =  0 + f  =  f. 
 

 
Section 5.1 
235 
28. 
If  y(x)  =  1 + c1cos x + c2sin x  then  y′(x)  =  -c1sin x + c2cos x,  so the initial conditions  
y(0)  =  y′(0)  =  -1  yield  c1  =  -2, c2  =  -1.  Hence  y  =  1 - 2 cos x - sin x. 
 
29. 
There is no contradiction because if the given differential equation is divided by  x2  to 
get the form in Equation (8) in the text, then the resulting functions  p(x)  =  -4/x  and  
q(x)  =  6/x2  are not continuous at  x  =  0. 
 
30. 
(a) 
3
2y
x
=
  and  
3
2y
x
=
  are linearly independent because  
3
3
x
c x
=
  would 
require that  c  =  1  with  x  =  1,  but  c  =  -1  with  x  =  -1.   
 
 
(b) 
The fact that  W(y1, y2)  =  0  everywhere does not contradict Theorem 3, because 
when the given equation is written in the required form 
 
 
 
 
 
 
y″ - (3/x)y′ + (3/x2)y  =  0, 
 
 
the coefficient functions  p(x)  =  -3/x  and  q(x)  =  3/x2  are not continuous at  x  =  0. 
 
31. 
W(y1, y2)  =  -2x  vanishes at  x  =  0,  whereas if  y1  and y2 were (linearly independent) 
solutions of an equation  y″ + py′ + qy  =  0  with  p  and  q  both continuous on an open 
interval  I  containing  x  =  0,  then Theorem 3 would imply that  W ≠ 0  on  I. 
 
32. 
(a) 
W  =  y1y2′ - y1′y2,  so 
 
 
           
AW' =  A(y1′y2′ + y1y2″ - y1″y2 - y1′y2′) 
 
 
     
 
 =  y1(Ay2″) - y2(Ay1″) 
 
 
     
 
=  y1(-By2′ - Cy2) - y2(-By1′ - Cy1) 
 
 
     
 
 =  -B(y1y2′ - y1′y2) 
 
       
 
 
 
and thus  AW' =  -BW. 
 
(b) 
Just separate the variables. 
 
(c) 
Because the exponential factor is never zero. 
 
In Problems 33–42 we give the characteristic equation, its roots, and the corresponding general 
solution. 
 
33. 
2
3
2
0;
1, 2;
r
r
r
−
+
=
=
     y(x)  =  c1ex + c2e2x  
 
 
 
34. 
2
2
15
0;
3,
5;
r
r
r
+
−
=
=
−
     y(x)  =  c1e-5x  +c2e3x 
 
35. 
2
5
0;
0,
5;
r
r
r
+
=
=
−
     y(x)  =  c1 + c2e-5x 
 
 
 
 

236 
Chapter 5 
36. 
2
2
3
0;
0,
3/ 2;
r
r
r
+
=
=
−
     y(x)  =  c1 + c2e-3x/2 
 
37. 
2
2
2
0;
1,
1/ 2;
r
r
r
−
−
=
=
−
     y(x)  =  c1e-x/2 + c2ex 
 
 
 
 
38. 
2
4
8
3
0;
1/ 2,
3/ 2;
r
r
r
+
+
=
= −
−
     y(x)  =  c1e-x/2 +c2e-3x/2 
 
39. 
2
4
4
1
0;
1/ 2,
1/ 2;
r
r
r
+
+
=
= −
−
     y(x)  =  (c1 + c2x)e-x/2 
 
 
 
 
40. 
2
9
12
4
0;
2/ 3,
2/3;
r
r
r
−
+
=
= −
−
     y(x)  =  (c1 + c2x)e2x/3 
 
41. 
2
6
7
20
0;
4/3, 5/ 2;
r
r
r
−
−
=
= −
     y(x)  =  c1e-4x/3 + c2e5x/2 
 
 
 
42. 
2
35
12
0;
4/7, 3/5;
r
r
r
−
−
=
= −
     y(x)  =  c1e-4x/7 + c2e3x/5 
 
In Problems 43–48 we first write and simplify the equation with the indicated characteristic 
roots, and then write the corresponding differential equation. 
 
43. 
2
(
0)(
10)
10
0;
r
r
r
r
−
+
=
+
=
10
0
y
y
′′
′
+
=
  
 
 
 
 
44. 
2
(
10)(
10)
100
0;
r
r
r
−
+
=
−
=
100
0
y
y′′ −
=
 
 
45. 
2
(
10)(
10)
20
100
0;
r
r
r
r
+
+
=
+
+
=
20
100
0
y
y
y
′′
′
+
+
=
  
 
 
 
46. 
2
(
10)(
100)
110
1000
0;
r
r
r
r
−
−
=
−
+
=
110
1000
0
y
y
y
′′
′
−
+
=
 
 
47. 
2
(
0)(
0)
0;
r
r
r
−
−
=
=
0
y′′ =
  
 
 
 
 
48. 
2
(
1
2)(
1
2)
2
1
0;
r
r
r
r
−−
−+
=
−
−
=
2
0
y
y
y
′′
′
−
−
=
 
 
49. 
The solution curve with  (0)
1,
(0)
6
y
y′
=
=
  is  
2
( )
8
7
x
x
y x
e
e
−
−
=
−
.  We find that  
( )
0
y x
′
=
  when  x = ln(7/4)  so  
2
4/7 and
16/ 49
x
x
e
e
−
−
=
=
.  It follows that 
 
(ln(7/ 4))
16/7
y
=
,  so the high point on the curve is  (ln(7/ 4)),16/7)
(0.56, 2.29)
≈
, 
 
which looks consistent with Fig. 3.1.6. 
 
50. 
The two solution curves with  (0)
and
(0)
y
a
y
b
=
=
  (as well as  
(0)
1
y′
= )  are 
 
 
 
 
 
 
2
2
(2
1)
(
1)
,
(2
1)
(
1)
.
x
x
x
x
y
a
e
a
e
y
b
e
b
e
−
−
−
−
=
+
−
+
=
+
−
+
 
 

 
Section 5.1 
237 
Subtraction and then division by  a - b  gives  
2
2
x
x
e
e
−
−
=
, so it follows that  x  =  -ln 2.  
Now substitution in either formula gives  y = -2,  so the common point of intersection is  
(-ln 2, -2). 
 
51. 
(a) 
The substitution  
ln
v
x
=
  gives 
 
 
 
 
1
dy
dy dv
dy
y
dx
dv dx
x dv
′ =
=
=
 
 
 
Then another differentiation using the chain rule gives 
 
 
 
 
2
2
2
2
2
2
2
1
1
1
1
1
.
d y
d
dy
d
dy
y
dx
dx
dx
dx
x dv
dy
d
dy
dv
dy
d y
x
dv
x dv
dv
dx
x
dv
x
dv




′′ =
=
=
⋅










= −
⋅
+
⋅
= −
⋅
+
⋅




 
 
 
Substitution of these expressions for  
and
y
y
′
′′ into Eq. (21) in the text then yields  
 
immediately the desired Eq. (22): 
 
 
 
 
2
2
(
)
0.
d y
dy
a
b
a
c y
dv
dv
+
−
+
=
 
 
 
 
(b) 
If the roots  1
2
and
r
r   of the characteristic equation of Eq. (22)  are real and  
 
 
distinct, then a general solution of the original Euler equation is  
 
 
 
 
( )
( )
1
2
1
2
1
2
1
2
1
2
1
2
( )
.
r
r
r v
r v
r
r
v
v
y x
c e
c e
c e
c
e
c x
c x
=
+
=
+
=
+
 
 
52. 
The substitution  
ln
v
x
=
 yields the converted equation  
2
2
/
0
d y dv
y
−
=
 whose 
 
characteristic equation  
2
1
0
r −=
 has roots  1
2
1 and
1.
r
r
=
= −
  Because  
,
ve
x
=
 the  
 
corresponding  general solution is 
 
 
 
 
   
2
1
2
1
.
v
v
c
y
c e
c e
c x
x
−
=
+
=
+
 
 
53. 
The substitution  
ln
v
x
=
 yields the converted equation  
2
2
/
/
12
0
d y dv
dy dv
y
+
−
=
 
 
whose  characteristic equation  
2
12
0
r
r
+
−
=
 has roots  1
2
4 and
3.
r
r
= −
=
  Because   
 
,
ve
x
=
the corresponding general solution is 
 
 
 
 
   
4
3
4
3
1
2
1
2
.
v
v
y
c e
c e
c x
c x
−
−
=
+
=
+
 
 
54. 
The substitution  
ln
v
x
=
 yields the converted equation  
2
2
4
/
4
/
3
0
d y dv
dy dv
y
+
−
=
 
 
whose  characteristic equation  
2
4
4
3
0
r
r
+
−
=
 has roots  1
2
3/ 2 and
1/ 2.
r
r
= −
=
   
 
Because  
,
ve
x
=
 the corresponding general solution is 

238 
Chapter 5 
 
 
 
 
   
3 / 2
/ 2
3/ 2
1/ 2
1
2
1
2
.
v
v
y
c e
c e
c x
c x
−
−
=
+
=
+
 
 
55. 
The substitution  
ln
v
x
=
 yields the converted equation  
2
2
/
0
d y dv =
 whose 
 
characteristic equation  
2
0
r =
 has repeated roots  1
2
,
0.
r r =
  Because  
ln ,
v
x
=
 the  
 
corresponding general solution is 
 
 
 
 
   
1
2
1
2 ln .
y
c
c v
c
c
x
=
+
=
+
 
 
56. 
The substitution  
ln
v
x
=
 yields the converted equation  
2
2
/
4
/
4
0
d y dv
dy dv
y
−
+
=
 
 
whose  characteristic equation  
2
4
4
0
r
r
−
+
=
 has roots  1
2
,
2.
r r =
  Because  
,
ve
x
=
 the  
 
corresponding general solution is 
 
 
 
 
   
2
2
2
1
2
1
2
(
ln ).
v
v
y
c e
c v e
x
c
c
v
=
+
=
+
 
 
 
 
SECTION 5.2 
 
GENERAL SOLUTIONS OF LINEAR EQUATIONS 
 
Students should check each of Theorems 1 through 4 in this section to see that, in the case   
n  =  2,  it reduces to the corresponding theorem in Section 5.1.  Similarly, the computational 
problems for this section largely parallel those for the previous section.  By the end of Section 
5.2 students should understand that, although we do not prove the existence-uniqueness theorem 
now, it provides the basis for everything we do with linear differential equations. 
 
The linear combinations listed in Problems 1–6 were discovered "by inspection" — that is, by 
trial and error. 
 
1. 
(5/2)(2x) + (-8/3)(3x2) + (-1)(5x - 8x2)  =  0 
 
 
2. 
(-4)(5) + (5)(2 - 3x2) + (1)(10 + 15x2)  =  0 
 
3. 
(1)(0) + (0)(sin x) + (0)(ex)  =  0 
 
4. 
(1)(17) + (-17/2)(2 sin2x) + (-17/3)(3 cos2x)  =  0,  because  sin2x + cos2x  =  1. 
 
5. 
(1)(17) + (-34)(cos2x) + (17)(cos 2x)  =  0,  because  2 cos2x  =  1 + cos 2x. 
 
6. 
(-1)(ex) + (1)(cosh x) + (1)(sinh x)  =  0,   because  cosh x  =  (ex + e-x)/2  and   
 
sinh x  =  (ex - e-x)/2. 
            

 
Section 5.2 
239 
7.    
2
1
0
1
2
2
0
0
2
x
x
W
x
=
=
   is nonzero everywhere. 
                 
8.        
2
3
2
3
6
2
3
2
3
2
4
9
x
x
x
x
x
x
x
x
x
x
e
e
e
W
e
e
e
e
e
e
e
=
=
  is never zero. 
 
9. 
W  =  ex(cos2x + sin2x)  =  ex ≠ 0 
 
10. 
W  =  x-7ex(x + 1)(x + 4)  is nonzero for  x > 0. 
 
11. 
W  =  x3e2x  is nonzero if  x ≠ 0. 
 
12. 
W  =  x-2[2 cos2(ln x) + 2 sin2(ln x)]  =  2x-2  is nonzero for  x > 0. 
 
In each of Problems 13-20 we first form the general solution 
 
 
 
 
 
y(x)  =  c1y1(x) + c2y2(x) + c3y3(x), 
 
then calculate  y′(x)  and  y″(x),  and finally impose the given initial conditions to determine the 
values of the coefficients  c1, c2, c3. 
 
13. 
Imposition of the initial conditions  (0)
1,
(0)
2,
(0)
0
y
y
y
′
′′
=
=
=
 on the general solution  
2
1
2
3
( )
x
x
x
y x
c e
c e
c e
−
−
=
+
+
 yields the three equations 
 
 
 
1
2
3
1
2
3
1
2
3
1,
2
2,
4
0
c
c
c
c
c
c
c
c
c
+
+
=
−
−
=
+
+
=
  
 
with solution  
1
2
3
4/3,
0,
1/3.
c
c
c
=
=
= −
  Hence the desired particular solution is  
given by  y(x)  =  (4ex - e-2x)/3.         
 
14. 
Imposition of the initial conditions  (0)
0,
(0)
0,
(0)
3
y
y
y
′
′′
=
=
=
 on the general solution  
2
3
1
2
3
( )
x
x
x
y x
c e
c e
c e
=
+
+
 yields the three equations 
 
 
 
1
2
3
1
2
3
1
2
3
1,
2
3
2,
4
9
0
c
c
c
c
c
c
c
c
c
+
+
=
+
+
=
+
+
=
  
 
with solution  
1
2
3
3/ 2,
3,
3/ 2.
c
c
c
=
= −
=
  Hence the desired particular solution is  
given by y(x)  =  (3ex - 6e2x + 3e3x)/2. 
 
15. 
Imposition of the initial conditions  (0)
2,
(0)
0,
(0)
0
y
y
y
′
′′
=
=
=
 on the general 
solution  
2
3
1
2
3
( )
x
x
x
y x
c e
c x e
c x e
=
+
+
 yields the three equations 

240 
Chapter 5 
 
 
 
 
1
1
2
1
2
3
2,
0,
2
2
0
c
c
c
c
c
c
=
+
=
+
+
=
  
 
 
with solution  
1
2
3
2,
2,
1.
c
c
c
=
= −
=
  Hence the desired particular solution is  given by 
 
y(x)  =  (2 - 2x + x2)ex.       
 
16. 
Imposition of the initial conditions  (0)
1,
(0)
4,
(0)
0
y
y
y
′
′′
=
=
=
 on the general solution  
2
2
1
2
3
( )
x
x
x
y x
c e
c e
c xe
=
+
+
 yields the three equations 
 
 
 
 
1
2
1
2
3
1
2
3
1,
2
4,
4
4
0
c
c
c
c
c
c
c
c
+
=
+
+
=
+
+
=
  
 
with solution  
1
2
3
12,
13,
10.
c
c
c
= −
=
= −
  Hence the desired particular solution is  
given by  y(x)  =  -12ex + 13e2x - 10xe2x. 
 
17. 
Imposition of the initial conditions  (0)
3,
(0)
1,
(0)
2
y
y
y
′
′′
=
= −
=
 on the general 
solution  
1
2
3
( )
cos3
sin3
y x
c
c
x
c
x
=
+
+
 yields the three equations 
 
 
 
 
1
2
3
2
3,
3
1,
9
2
c
c
c
c
+
=
= −
−
=
  
 
with solution  
1
2
3
29/9,
2/9,
1/3.
c
c
c
=
= −
= −
  Hence the desired particular solution is  
given by  y(x)  =  (29 - 2 cos 3x - 3 sin 3x)/9. 
 
18. 
Imposition of the initial conditions  (0)
1,
(0)
0,
(0)
0
y
y
y
′
′′
=
=
=
 on the general solution  
(
)
1
2
3
( )
cos
sin
x
y x
e
c
c
x
c
x
=
+
+
 yields the three equations 
 
 
 
 
1
2
1
2
3
1
3
1,
0,
2
0
c
c
c
c
c
c
c
+
=
+
+
=
+
=
  
 
 
with solution  
1
2
3
2,
1,
1.
c
c
c
=
= −
= −
  Hence the desired particular solution is  given  
 
by  y(x)  =  ex(2 - cos x - sin x). 
 
19. 
Imposition of the initial conditions  (1)
6,
(1)
14,
(1)
22
y
y
y
′
′′
=
=
=
 on the general 
solution  
2
3
1
2
3
( )
y x
c x
c x
c x
=
+
+
 yields the three equations 
 
 
 
 
1
2
3
1
2
3
2
3
6,
2
3
14,
2
6
22
c
c
c
c
c
c
c
c
+
+
=
+
+
=
+
=
  
 
 
with solution  
1
2
3
1,
2,
3.
c
c
c
=
=
=
  Hence the desired particular solution is  given by   
 
y(x)  =  x + 2x2 + 3x3.         
 
20. 
Imposition of the initial conditions  (1)
1,
(1)
5,
(1)
11
y
y
y
′
′′
=
=
= −
 on the general 
solution  
2
2
1
2
3
( )
ln
y x
c x
c x
c x
x
−
−
=
+
+
 yields the three equations 

 
Section 5.2 
241 
 
 
 
 
1
2
1
2
3
2
3
1,
2
5,
6
5
11
c
c
c
c
c
c
c
+
=
−
+
=
−
= −
  
 
 
with solution  
1
2
3
2,
1,
1.
c
c
c
=
= −
=
  Hence the desired particular solution is  given by   
 
y(x)  =  2x - x-2 + x-2ln x. 
 
In each of Problems 21-24 we first form the general solution 
 
           
 
y(x)  =  yc(x) + yp(x)  =  c1y1(x) + c2y2(x) + yp(x), 
 
then calculate  y′(x),  and finally impose the given initial conditions to determine the values of 
the coefficients  c1  and  c2. 
 
21. 
Imposition of the initial conditions  (0)
2,
(0)
2
y
y′
=
= −
 on the general solution  
1
2
( )
cos
sin
3
y x
c
x
c
x
x
=
+
+
 yields the two equations  
1
2
2,
3
2
c
c
=
+
= −
 with  
 
solution  
1
2
2,
5.
c
c
=
= −
  Hence the desired particular solution is  given by   
 
y(x)  =  2 cos x - 5 sin x + 3x. 
 
22. 
Imposition of the initial conditions  (0)
0,
(0)
10
y
y′
=
=
 on the general solution  
2
2
1
2
( )
3
x
x
y x
c e
c e−
=
+
− yields the two equations  
1
2
1
2
3
0, 2
2
10
c
c
c
c
+
−
=
−
=
 with  
 
solution  
1
2
4,
1.
c
c
=
= −
  Hence the desired particular solution is  given by   
 
y(x)  =  4e2x - e-2x - 3. 
 
23. 
Imposition of the initial conditions  (0)
3,
(0)
11
y
y′
=
=
 on the general solution  
3
1
2
( )
2
x
x
y x
c e
c e
−
=
+
−
 yields the two equations  
1
2
1
2
2
3,
3
11
c
c
c
c
+
−
=
−
+
=
 with  
 
solution  
1
2
1,
4.
c
c
=
=
  Hence the desired particular solution is  given by   
 
y(x)  =  e-x + 4e3x - 2. 
 
24. 
Imposition of the initial conditions  (0)
4,
(0)
8
y
y′
=
=
 on the general solution  
1
2
( )
cos
cos
1
x
x
y x
c e
x
c e
x
x
=
+
+
+  yields the two equations  
1
1
2
1
4,
1
8
c
c
c
+ =
+
+ =
 
with solution  
1
2
3,
4.
c
c
=
=
  Hence the desired particular solution is  given by   
 
y(x)  =  ex(3 cos x + 4 sin x) + x + 1. 
 
25. 
L[y]  =  L[y1 + y2]  =  L[y1] + L[y2]  =  f + g 
 
26. 
(a) 
y1  =  2  and  y2  =  3x  
(b) 
y  =  
1
2
y
y
+
 =  2 + 3x 
 
27. 
The equations   
 
 
 
 
c1 + c2x + c3x2  =  0,    c2 + 2c3x + 0, 
2c3  =  0 
 
 

242 
Chapter 5 
 
(the latter two obtained by successive differentiation of the first one) evidently imply —
by substituting  x = 0 — that  c1  =  c2  =  c3  =  0. 
 
28. 
If you differentiate the equation  
2
0
1
2
0
n
n
c
c x
c x
c x
+
+
+
+
=

 repeatedly,  n  times in 
succession, the result is the system  
 
 
 
 
2
0
1
2
0
n
n
c
c x
c x
c x
+
+
+
+
=

 
 
 
 
1
1
2
2
0
n
n
c
c x
nc x −
+
+
+
=

 
 
 
 
 
 
 
 
 
 
1
(
1)!
!
0
n
n
n
c
n c x
−
−
+
=
 
 
 
 
 
!
0
n
n c
=
 
 
 
of  n+1 equations in the  n+1 coefficients  
0
1
2
,
,
,
,
.
n
c
c c
c

  Upon substitution of   
 
x = 0,  the (k+1)st of these equations reduces to  !
0,
k
k c
=
 so it follows that all these 
coefficients must vanish. 
 
 
29. 
If  c0erx + c1xerx + ⋅⋅⋅ + cnxnerx  =  0,  then division by  erx  yields   
 
 
 
 
 
c0 + c1x + ⋅⋅⋅ + cnxn  =  0, 
 
 
so the result of Problem 28 applies. 
 
30. 
When the equation  x2y″ - 2xy′ + 2y  =  0  is rewritten in standard form 
 
       
 
 
 
y″ + (-2/x)y′ + (2/x2)y  =  0, 
 
 
the coefficient functions  p1(x)  =  -2/x  and  p2(x)  =  2/x2  are not continuous at  x  =  0.  
Thus the hypotheses of Theorem 3 are not satisfied. 
 
31. 
(a) 
Substitution of  x = a  in the differential equation gives  
( )
( )
( ).
y a
p y a
q a
′′
′
= −
−
 
 
 
(b) 
If  y(0)  =  1  and  y′(0)  =  0,  then the equation  y″ - 2y′ - 5y  =  0  implies that   
y″(0)  =  2y′(0) + 5y(0)  =  5. 
 
32. 
Let the functions  y1, y2, ⋅⋅⋅ , yn  be chosen as indicated.  Then evaluation at   
 
x  =  a  of the  (k - 1)st  derivative of the equation  c1y1 + c2y2 + ⋅⋅⋅ cnyn  =  0  yields   
 
ck  =  0.  Thus  c1  =  c2  =  ⋅⋅⋅  =  cn  =  0,  so the functions are linearly independent. 
 
33. 
This follows from the fact that 
 

 
Section 5.2 
243 
  
 
 
 
2
2
2
1
1
1
(
)(
)(
).
a
b
c
b
a c
b c
a
a
b
c
=
−
−
−
 
 
34. 
W(f1, f2, ⋅⋅⋅, fn)  =  V exp(rix),  and neither  V  nor  exp(rix)  vanishes.   
 
36. 
If  
1
y
vy
=
 then substitution of the derivatives 
 
 
 
1
1
1
1
1
,
2
y
vy
v y
y
vy
v y
v y
′
′
′
′′
′′
′ ′
′′
=
+
=
+
+
 
 
in the differential equation  
0
y
py
qy
′′
′
+
+
=
 gives 
 
 
 
[
]
[
]
[
]
[
]
1
1
1
1
1
1
1
1
1
1
1
1
2
0,
2
0.
vy
v y
v y
p vy
v y
q vy
v y
py
qy
v y
v y
pv y
′′
′ ′
′′
′
′
+
+
+
+
+
=
′′
′
′′
′ ′
′
+
+
+
+
+
=
 
 
But the terms within brackets vanish because  
1y  is a solution, and this leaves the  
 
equation 
 
 
 
 
(
)
1
1
1
2
0
y v
y
py
v
′′
′
′
+
+
=
 
 
that we can solve by writing 
 
 
 
 
1
1
1
( )
( )
2
2
1
1
2
ln
2ln
( )
ln
,
( )
( )
.
p x dx
p x dx
v
y
p
v
y
p x dx
C
v
y
C
e
v x
e
v x
C
dx
K
y
y
−
−
′′
′
′
′
= −
−
⇒
= −
−
+
′
∫
∫
′
=
⇒
=
+
⌠

⌡
∫
 
 
With  
1 and
0
C
K
=
=
 this gives the second solution 
 
 
 
 
( )
2
1
2
1
( )
( )
.
p x dx
e
y
x
y x
dx
y
−∫
=
⌠

⌡
 
 
37. 
When we substitute  
3
y
vx
=
 in the given differential equation and simplify, we get the 
 
separable equation  
0
xv
v
′′
′
+
=
 that we solve by writing 
 
 
 
 
1
ln
ln
ln
,
( )
ln
.
v
v
x
A
v
x
A
v
v x
A
x
B
x
′′
′
= −
⇒
= −
+
′
′ =
⇒
=
+
 
 
 
With  
1 and
0
A
B
=
=
 we get  ( )
ln
v x
x
=
 and hence  
3
2( )
ln .
y
x
x
x
=
 
 
 

244 
Chapter 5 
 
38. 
When we substitute  
3
y
vx
=
 in the given differential equation and simplify, we get the 
 
separable equation  
7
0
xv
v
′′
′
+
=
 that we solve by writing 
 
 
 
 
7
6
7
ln
7ln
ln
,
( )
.
6
v
v
x
A
v
x
A
A
v
v x
B
x
x
′′
′
= −
⇒
= −
+
′
′ =
⇒
= −
+
 
 
 
With  
6 and
0
A
B
= −
=
 we get  
6
( )
1/
v x
x
=
 and hence  
3
2( )
1/
.
y
x
x
=
 
 
 
39. 
When we substitute  
/ 2
x
y
ve
=
 in the given differential equation and simplify, we 
 
eventually get the simple equation  
0
v′′ =
 with general solution  ( )
.
v x
Ax
B
=
+
 
 
With  
1 and
0
A
B
=
=
 we get  ( )
v x
x
=
 and hence  
/ 2
2( )
.
x
y
x
x e
=
 
 
 
40. 
When we substitute  y
vx
=
 in the given differential equation and simplify, we get the 
 
separable equation  
0
v
v
′′
′
−
=
 that we solve by writing 
 
 
 
 
1
ln
ln ,
( )
.
x
x
v
v
x
A
v
v
Ae
v x
Ae
B
′′
′
=
⇒
=
+
′
′ =
⇒
=
+
 
 
 
With  
1 and
0
A
B
=
=
 we get  ( )
x
v x
e
=
 and hence  
2( )
.
x
y
x
xe
=
 
 
 
41. 
When we substitute  
x
y
v e
=
 in the given differential equation and simplify, we get the 
 
separable equation  (1
)
0
x v
xv
′′
′
+
+
=
 that we solve by writing 
 
 
 
 
 
 
 
 
 
 
 
 
1
1
ln
ln(1
)
ln ,
1
1
(1
)
( )
(1
)
(2
)
.
x
x
x
v
x
v
x
x
A
v
x
x
v
A
x e
v x
A
x e
dx
A
x e
B
−
−
−
′′
′
= −
= −+
⇒
= −
+
+
+
′
+
+
′ =
+
⇒
=
+
= −
+
+
∫
 
 
 
With  
1 and
0
A
B
= −
=
 we get  ( )
(2
)
x
v x
x e−
=
+
 and hence  
2( )
2
.
y
x
x
=
+
 
 
 
42. 
When we substitute  y
v x
=
 in the given differential equation and simplify, we get the 
 
separable equation  
2
(
1)
2
x x
v
v
′′
′
−
=
 that we solve by writing 

 
Section 5.2 
245 
 
 
 
 
 
 
 
 
 
 
 
 
2
2
2
2
2
2
1
1
,
(
1)
1
1
ln
2ln
ln(1
)
ln(1
)
ln ,
(1
)
1
1
1
( )
.
v
v
x x
x
x
x
v
x
x
x
A
A
x
v
A
v x
A
x
B
x
x
x
′′ =
= −
+
−
′
−
+
−
′ = −
+
+
+
−
+
−




′ =
=
−
⇒
=
−
−
+








 
 
 
With  
1 and
0
A
B
= −
=
 we get  ( )
1/
v x
x
x
=
+
 and hence  
2
2( )
1.
y
x
x
=
+
 
 
 
43. 
When we substitute  y
v x
=
 in the given differential equation and simplify, we get the 
 
separable equation  
2
2
(
1)
(2
4
)
x x
v
x
v
′′
′
−
=
−
 that we solve by writing 
 
 
 
 
 
 
 
 
 
 
 
 
2
2
2
2
2
2
4
2
1
1
,
(
1)
1
1
ln
2ln
ln(1
)
ln(1
)
ln ,
1
1
1
,
(1
)
2(1
)
2(1
)
1
1
1
( )
ln(1
)
ln(1
)
.
2
2
v
x
v
x x
x
x
x
v
x
x
x
A
A
v
A
x
x
x
x
x
v x
A
x
x
B
x
′′
−
=
= −
−
+
′
−
+
−
′ = −
−
+
−
−
+


′ =
=
+
+


−
+
−




=
−
+
+
−
−
+




 
 
 
With  
1 and
0
A
B
= −
=
 we get   
 
 
 
2
1
1
1
1
( )
ln(1
)
ln(1
)
( )
1
ln
.
2
2
2
1
x
x
v x
x
x
y
x
x
x
+
=
−
+
+
−
⇒
=
−
−
 
 
 
44. 
When we substitute  
1/ 2 cos
y
v x
x
−
=
 in the given differential equation and simplify, we 
 
eventually get the separable equation  (cos )
2(sin )
x v
x v
′′
′
=
 that we solve by writing 
 
 
 
 
 
 
 
 
 
 
 
 
2
2
2sin
ln
2ln cos
ln
lnsec
ln
,
cos
sec
( )
tan
.
v
x
v
x
A
x
A
v
x
v
A
x
v x
A
x
B
′′
′
=
⇒
= −
+
=
+
′
′ =
⇒
=
+
 
 
 
With  
1 and
0
A
B
=
=
 we get  ( )
tan
v x
x
=
 and hence   
 
 
 
 
1/ 2
1/ 2
2( )
(tan )(
cos )
sin .
y
x
x
x
x
x
x
−
−
=
=
 
 
 
 
 

246 
Chapter 5 
 
SECTION 5.3 
 
HOMOGENEOUS EQUATIONS WITH CONSTANT COEFFICIENTS 
 
This is a purely computational section devoted to the single most widely applicable type of 
higher order differential equations — linear ones with constant coefficients.  In Problems 1–20, 
we write first the characteristic equation and its list of roots, then the corresponding general 
solution of the given differential equation.  Explanatory comments are included only when the 
solution of the characteristic equation is not routine. 
 
1. 
(
)(
)
2
4
2
2
0;
2, 2;
( )
r
r
r
r
y x
−
=
−
+
=
= −
=  c1e2x + c2e-2x  
 
 
 
 
2. 
(
)
2
2
3
2
3
0;
0, 3/ 2;
( )
r
r
r
r
r
y x
−
=
−
=
=
=  c1 + c2e3x/2           
 
3. 
(
)(
)
2
3
10
5
2
0;
5, 2;
( )
r
r
r
r
r
y x
+
−
=
+
−
=
= −
=  c1e2x + c2e-5x     
 
 
 
4. 
(
)(
)
2
2
7
3
2
1
3
0;
1/ 2, 3;
( )
r
r
r
r
r
y x
−
+
=
−
−
=
=
=  c1ex/2 + c2e3x 
 
5. 
(
)
2
2
6
9
3
0;
3,
3;
( )
r
r
r
r
y x
+
+
=
+
=
= −
−
=  c1e-3x + c2xe-3x    
 
6. 
(
)
2
5
5
0;
5
5 / 2
r
r
r
+
+
=
= −±
 
 
y(x)  =  e-5x/2[c1exp(x 5 /2) + c2exp(-x 5 /2)] 
 
7. 
(
)
2
2
4
12
9
2
3
0;
3/ 2,
3/ 2;
( )
r
r
r
r
y x
−
+
=
−
=
= −
−
=  c1e3x/2 + c2xe3x/2 
 
8. 
(
)
2
6
13
0;
6
16 / 2
3
2 ;
( )
r
r
r
i
y x
−
+
=
=
±
−
=
±
=  e3x(c1cos 2x + c2sin 2x) 
 
 
9. 
(
)
2
8
25
0;
8
36 / 2
4
3 ;
( )
r
r
r
i
y x
+
+
=
= −±
−
= −
±
=  e-4x(c1cos 3x + c2sin 3x) 
 
10. 
(
)
4
3
3
5
3
5
3
0;
0, 0, 0,
3/5;
( )
r
r
r
r
r
y x
+
=
+
=
=
−
  =  c1 + c2x + c3x2 + c4e-3x/5 
 
 
11. 
(
)
2
4
3
2
2
8
16
4
0;
0, 0, 4, 4;
( )
r
r
r
r
r
r
y x
−
+
=
−
=
=
=  c1 + c2x + c3e4x + c4xe4x 
 
12. 
(
)
3
4
3
2
3
3
1
0;
0,1,1,1;
( )
r
r
r
r
r r
r
y x
−
+
−
=
−
=
=
=  c1 + c2ex + c3xex + c4x2ex 
 
 
13. 
(
)
2
3
2
9
12
4
3
2
0;
0,
2 /3,
2/3
r
r
r
r
r
r
+
+
=
+
=
=
−
−
 
 
y(x)  =  c1 + c2e-2x/3 + c3xe-2x/3 

 
Section 5.3 
247 
 
14. 
(
)(
)
4
2
2
2
3
4
1
4
0;
1,1,
2
r
r
r
r
r
i
+
−
=
−
+
=
= −
±
 
 
y(x)  =  c1ex + c2e-x + c3cos 2x + c4sin 2x 
 
15. 
(
)
2
4
2
2
2
2
4
8
16
4
(
2) (
2)
0;
2, 2,
2,
2
r
r
r
r
r
r
−
+
=
−
=
−
+
=
=
−
−
 
 
y(x)  =  c1e2x + c2xe2x + c3e-2x + c4xe-2x 
 
16. 
(
)
2
4
2
2
18
81
9
0;
3 ,
3
r
r
r
r
i
i
+
+
=
+
=
= ±
±
 
 
y(x)  =  (c1 + c2x)cos 3x + (c3 + c4x)sin 3x 
 
17. 
4
2
2
2
6
11
4
(2
1)(3
4)
0;
/
2,
2 /
3,
r
r
r
r
r
i
i
+
+
=
+
+
=
= ±
±
 
 
y(x)  =  c1cos(x/
2 ) + c2sin(x/
2 ) + c3cos(2x/
3 ) + c4sin(2x/
3 ) 
 
18. 
(
)(
)
4
2
2
16
4
4
0;
2, 2,
2
r
r
r
r
i
−
=
−
+
=
= −
±
 
 
y(x)  =  c1e2x + c2e-2x + c3cos 2x + c4sin 2x 
 
19. 
(
) (
)
(
)(
)
2
3
2
2
2
1
1
1
1
1
0;
1,
1,
1;
r
r
r
r r
r
r
r
r
+
−
−
=
−
+
−
=
−
+
=
=
−
−
 
 
y(x)  =  c1ex + c2e-x + c3xe-x  
 
20. 
r4 + 2r3 + 3r2 + 2r + 1  =  (r2 + r + 1)2  =  0;     (
)
(
)
1
3
/ 2,
1
3
/ 2
i
i
−±
−±
 
 
y  =  e-x/2(c1 + c2x)cos(x
3 /2) + e-x/2(c3 + c4x)sin(x
3 /2) 
 
21. 
Imposition of the initial conditions  (0)
7,
(0)
11
y
y′
=
=
 on the general solution  
3
1
2
( )
x
x
y x
c e
c e
=
+
 yields the two equations  
1
2
1
2
7,
3
11
c
c
c
c
+
=
+
=
 with solution  
1
2
5,
2.
c
c
=
=
  Hence the desired particular solution is  y(x)  =  5ex + 2e3x.  
 
 
 
22. 
Imposition of the initial conditions  (0)
3,
(0)
4
y
y′
=
=
 on the general solution  
(
)
(
)
/ 3
1
2
( )
cos
/
3
sin
/
3
x
y x
e
c
x
c
x
−


=
+

 yields the two equations  
1
1
2
3,
/3
/
3
4
c
c
c
=
−
+
=
 with solution  
1
2
3,
5 3.
c
c
=
=
  Hence the desired particular 
solution is  
(
)
(
)
/ 3
( )
3cos
/
3
5 3sin
/
3
.
x
y x
e
x
x
−


=
+

 
 
23. 
Imposition of the initial conditions  (0)
3,
(0)
1
y
y′
=
=  on the general solution  
(
)
3
1
2
( )
cos4
sin4
x
y x
e
c
x
c
x
=
+
 yields the two equations  
1
1
2
3, 3
4
1
c
c
c
=
+
=  with 
solution  
1
2
3,
2.
c
c
=
= −
  Hence the desired particular solution is   
 
y(x)  =  e3x(3 cos 4x - 2 sin 4x). 
 
 
 

248 
Chapter 5 
24. 
Imposition of the initial conditions  (0)
1,
(0)
1,
(0)
3
y
y
y
′
′′
=
= −
=
 on the general 
solution  
2
/ 2
1
2
3
( )
x
x
y x
c
c e
c e−
=
+
+
 yields the three equations  
 
 
 
  
1
2
3
2
3
2
3
1,
2
/ 2
1,
4
/ 4
3
c
c
c
c
c
c
c
+
+
=
−
= −
+
=
  
 
 
 
with solution  
1
2
3
7/ 2,
1/ 2,
4.
c
c
c
= −
=
=
  Hence the desired particular solution is   
 
y(x)  =  (-7 + e2x + 8e-x/2)/2. 
 
25. 
Imposition of the initial conditions  (0)
1,
(0)
0,
(0)
1
y
y
y
′
′′
= −
=
=  on the general 
solution  
2 /3
1
2
3
( )
x
y x
c
c x
c e−
=
+
+
 yields the three equations  
 
 
 
  
1
3
2
3
3
1,
2
/3
0,
4
/9
1
c
c
c
c
c
+
= −
−
=
=   
 
 
 
with solution  
1
2
3
13/ 4,
3/ 2,
9/ 4.
c
c
c
= −
=
=
  Hence the desired particular solution is   
 
y(x)  =  (-13 + 6x + 9e-2x/3)/4. 
 
 
 
26. 
Imposition of the initial conditions  (0)
1,
(0)
1,
(0)
3
y
y
y
′
′′
=
= −
=
 on the general 
solution  
5
5
1
2
3
( )
x
x
y x
c
c e
c xe
−
−
=
+
+
 yields the three equations  
 
 
 
  
1
2
2
3
2
3
3,
5
4,
25
10
5
c
c
c
c
c
c
+
=
−
+
=
−
=
  
 
 
 
with solution  
1
2
3
24/5,
9/5,
5.
c
c
c
=
= −
= −
  Hence the desired particular solution is   
 
y(x)  =  (24 - 9e-5x - 25xe-5x)/5. 
 
27. 
First we spot the root  r  =  1.  Then long division of the polynomial
3
2
3
4
r
r
+
−
   
 
by  r - 1  yields the quadratic factor  
2
2
4
4
(
2)
r
r
r
+
+
=
+
 with roots   
 
r  =  -2, -2.  Hence the general solution is  y(x)  =  c1ex + c2e-2x + c3xe-2x. 
 
28. 
First we spot the root  r  =  2.  Then long division of the polynomial  2r3 - r2 - 5r - 2   
 
by the factor  r - 2  yields the quadratic factor  2r2 + 3r + 1  =   (2r + 1)(r + 1)  with roots   
 
r  =  -1, -1/2.  Hence the general solution is  y(x)  =  c1e2x + c2e-x + c3e-x/2. 
 
29. 
First we spot the root  r  =  –3.  Then long division of the polynomial  
3
27
r +
 by   
r + 3  yields the quadratic factor  
2
3
9
r
r
−
+
  with roots  
(
)
3 1
3 / 2.
r
i
=
±
  Hence the 
general solution is  y(x)  =  c1e-3x + e3x/2[c2cos(3x
3 /2) + c3 sin(3x
3 /2)]. 
 
30. 
First we spot the root  r  =  -1.  Then long division of the polynomial   
 
 
 
 
 
 
r4 - r3 + r2 - 3r - 6  
 

 
Section 5.3 
249 
 
by   r + 1  yields the cubic factor   r3 - 2r2 + 3r - 6.  Next we spot the root  r  =  2,  and 
another long division yields the quadratic factor  r2 + 3  with roots  r  =  
3
i
±
.  Hence 
the general solution is  y(x)  =  c1e-x + c2e2x + c3cos x
3  + c4sin x
3 . 
 
31. 
The characteristic equation  r3 + 3r2 + 4r - 8  =  0  has the evident root  r  =  1,  and long 
division then yields the quadratic factor  r2 + 4r + 8  =  (r + 2)2 + 4  corresponding to the 
complex conjugate roots  -2 ± 2 i.  Hence the general solution is 
 
 
 
 
 
y(x)  =   c1ex + e-2x(c2cos 2x + c3sin 2x).  
 
32. 
The characteristic equation  r4 + r3 - 3r2 - 5r - 2  =  0  has root  r  =  2  that is readily 
found by trial and error,  and long division then yields the factorization 
 
 
 
 
 
 
(r - 2)(r + 1)3   =   0. 
 
 
Thus we obtain the general solution  y(x)  =   c1e2x + (c2 + c3x + c4x2)e-x. 
 
33. 
Knowing that  y  =  e3x  is one solution, we divide the characteristic polynomial   
 
r3 + 3r2 - 54  by  r - 3  and get the quadratic factor   
 
 
 
 
 
r2 + 6r + 18   =   (r + 3)2 + 9.  
 
 
Hence the general solution is  y(x)  =   c1e3x + e-3x(c2cos 3x + c3sin 3x). 
 
34. 
Knowing that  y  =  e2x/3  is one solution, we divide the characteristic polynomial   
 
3r3 - 2r2 + 12r - 8  by  3r - 2  and get the quadratic factor  r2 + 4.  Hence the general 
solution is 
 
 
 
 
y(x)  =   c1e2x/3 + c2cos 2x + c3sin 2x. 
 
35. 
The fact that  y  =  cos 2x  is one solution tells us that  r2 + 4  is a factor of the 
characteristic polynomial   
 
 
            
 
6r4 + 5r3 + 25r2 + 20r + 4.   
 
 
Then long division yields the quadratic factor  
2
6
5
1
(3
1)(2
1)
r
r
r
r
+
+
=
+
+
 with roots 
 
1/ 2,
1/3.
r = −
−
  Hence the general solution is 
 
 
           
 
y(x)  =   c1e-x/2 + c2e-x/3 + c3cos 2x + c4sin 2x 
 
36. 
The fact that  y  =  e-xsin x  is one solution tells us that  (r + 1)2 + 1  =  r2 + 2r + 2   
 
is a factor of the characteristic polynomial   
 
 
            
 
9r3 + 11r2 + 4r - 14.   
 

250 
Chapter 5 
 
Then long division yields the linear factor  9r - 7.  Hence the general solution is 
 
 
           
 
y(x)  =   c1e7x/9 + e-x(c2cos x + c3sin x). 
 
37. 
The characteristic equation is  
4
3
3(
1)
0
r
r
r r
−
=
−
=
,  so the general solution is 
2
( )
x
y x
A
Bx
Cx
De
=
+
+
+
.  Imposition of the given initial conditions yields the 
equations 
 
 
18,
12,
2
13,
7
A
D
B
D
C
D
D
+
=
+
=
+
=
=
 
 
with solution  
11,
5,
3,
7.
A
B
C
D
=
=
=
=
  Hence the desired particular solution is 
 
 
 
 
 
2
( )
11
5
3
7
x
y x
x
x
e
=
+
+
+
. 
 
38. 
Given that  r = 5  is one characteristic root, we divide  (r – 5)  into the characteristic 
polynomial  
3
2
5
100
500
r
r
r
−
+
−
  and get the remaining factor  
2
100
r +
.  Thus the  
 
general solution is 
 
 
 
 
5
( )
cos10
sin10
x
y x
Ae
B
x
C
x
=
+
+
. 
 
Imposition of the given initial conditions yields the equations 
 
 
 
0,
5
10
10,
25
100
250
A
B
A
C
A
B
+
=
+
=
−
=
 
 
with solution  
2,
2,
0.
A
B
C
=
= −
=
  Hence the desired particular solution is 
 
5
( )
2
2cos10
x
y x
e
x
=
−
. 
 
39. 
3
3
2
(
2)
6
12
8
r
r
r
r
−
=
−
+
−
,  so the differential equation is 
 
 
 
 
 
6
12
8
0
y
y
y
y
′′′
′′
′
−
+
−
=
. 
 
40. 
2
3
2
(
2)(
4)
2
4
8
r
r
r
r
r
−
+
=
−
+
−
,  so the differential equation is 
 
 
 
 
 
2
4
8
0
y
y
y
y
′′′
′′
′
−
+
−
=
. 
 
41. 
2
2
4
(
4)(
4)
16
r
r
r
+
−
=
−
,  so the differential equation is   
(4)
16
0
y
y
−
=
. 
 
 
 
 
42. 
2
3
6
4
2
(
4)
12
48
64
r
r
r
r
+
=
+
+
+
,  so the differential equation is 
 
 
 
 
 
(6)
(4)
12
48
64
0
y
y
y
y
′′
+
+
+
=
. 
 
44. 
(a) 
x  =  i, -2i      
 
(b) 
x  =  -i, 3i 

 
Section 5.3 
251 
 
45. 
The characteristic polynomial is the quadratic polynomial of Problem 44(b).  Hence the 
general solution is   
 
 
 
 
 
3
1
2
1
2
( )
(cos
sin )
(cos3
sin3 ).
ix
ix
y x
c e
c e
c
x
i
x
c
x
i
x
−
=
+
=
−
+
+
 
 
46. 
The characteristic polynomial is  
2
6
(
2 )(
3 )
r
ir
r
i r
i
−
+
=
+
−
 so the general solution is 
 
 
 
 
3
2
1
2
1
2
( )
(cos3
sin3 )
(cos2
sin 2 ).
ix
ix
y x
c e
c e
c
x
i
x
c
x
i
x
−
=
+
=
+
+
−
 
 
47. 
The characteristic roots are  
2
2
3
(1
3)
r
i
i
= ±
−+
= ±
+
 so the general solution is 
 
 
(
)
(
)
(1
3)
(1
3)
1
2
1
2
( )
cos 3
sin 3
cos 3
sin
3
i
x
i
x
x
x
y x
c e
c e
c e
x
i
x
c e
x
i
x
+
−
+
−
=
+
=
+
+
−
 
 
48. 
The general solution is  y(x)  =  Aex + Beαx + Ceßx  where  α  =  (-1 + i
3 )/2  and   
 
β  =  (-1 - i
3 )/2.  Imposition of the given initial conditions yields the equations 
 
 
 
 
 
2
2
1
0
0
A
B
C
A
B
C
A
B
C
α
β
α
β
+
+
=
+
+
=
+
+
=
 
 
 
that we solve for  A  =  B  =  C  =  1/3.  Thus the desired particular solution is given  
 
by  
(
)
( 1
3) / 2
( 1
3) / 2
1
3
( )
,
x
i
x
x
y x
e
e
e
−+
−−
=
+
+
 which (using Euler's relation) reduces to the 
given real-valued solution. 
 
49. 
The general solution is  y  =  Ae2x + Be-x + C cos x + D sin x.  Imposition of the given 
initial conditions yields the equations 
 
 
 
 
 
0
2
0
4
0
8
30
A
B
C
A
B
D
A
B
C
A
B
D
+
+
=
−
+
=
+
−
=
−
−
=
 
  
 
that we solve for  A  =  2,  B  =  -5,  C  =  3,  and  D  =  -9.  Thus 
 
 
 
 
 
y(x)  =  2e2x - 5e-x + 3 cos x - 9 sin x. 
 
50. 
If  
0
x >
 then the differential equation is  
0
y
y
′′ +
=
 with general solution  
cos
sin .
y
A
x
B
x
=
+
.  But if  
0
x <
 it is  
0
y
y
′′ −
=
 with general solution  
cosh
sin .
y
C
x
D
x
=
+
  To satisfy the initial conditions  
1
1
(0)
1,
(0)
0
y
y′
=
=
 we choose  

252 
Chapter 5 
1 and
0.
A
C
B
D
=
=
=
=
  But to satisfy the initial conditions  
2
2
(0)
0,
(0)
1
y
y′
=
=  we 
choose  
0 and
1.
A
C
B
D
=
=
=
=
  The corresponding solutions are defined by 
 
 
 
1
2
cos
if
0,
sin
if
0,
( )
( )
cosh
if
0;
sinh
if
0.
x
x
x
x
y x
y
x
x
x
x
x
≥
≥


=
=


≤
≤


 
 
51. 
In the solution of Problem 51 in Section 3.1 we showed that the substitution  
ln
v
x
=
 
 
gives 
 
 
   
1
dy
dy
y
dx
x dv
′ =
=
   and    
2
2
2
2
2
2
1
1
.
d y
dy
d y
y
dx
x
dv
x
dv
′′ =
= −
⋅
+
⋅
 
 
A further differentiation using the chain rule gives 
 
 
 
3
2
3
3
3
3
2
3
3
2
3
1
.
d y
dy
d y
d y
y
dx
x
dv
x
dv
x
dv
′′′ =
=
⋅
−
⋅
+
⋅
 
 
Substitution of these expressions for  
,
, and
y
y
y
′
′′
′′′  into the third-order Euler equation  
 
3
2
0
ax y
bx y
cx y
d y
′′′
′′
′
+
+
+
=
and collection of coefficients quickly yields  the desired  
 
constant-coefficient equation 
 
 
 
 
3
2
3
2
(
3 )
(
2 )
0.
d y
d y
dy
a
b
a
c
b
a
d y
dv
dv
dv
+
−
+
−
+
+
=
 
 
In Problems 52 through 58 we list first the transformed constant-coefficient equation, then its 
characteristic equation and roots, and finally the corresponding general solution with  
ln
v
x
=
 
and  
.
ve
x
=
 
 
52. 
2
2
2
9
0;
9
0;
3
d y
y
r
r
i
dv +
=
+
=
= ±
 
 
1
2
1
2
( )
cos(3 )
sin(3 )
cos(3ln )
sin(3ln )
y x
c
v
c
v
c
x
c
x
=
+
=
+
 
 
53. 
2
2
2
6
25
0;
6
25
0;
3
4
d y
dy
y
r
r
r
i
dv
dv
+
+
=
+
+
=
= −±
 
 
[
]
[
]
3
3
1
2
1
2
( )
cos(4 )
sin(4 )
cos(4ln )
sin(4ln )
v
y x
e
c
v
c
v
x
c
x
c
x
−
−
=
+
=
+
 
 
54. 
3
2
3
2
3
2
3
0;
3
0;
0, 0,
3
d y
d y
r
r
r
dv
dv
+
=
+
=
=
−
 
 
3
3
1
2
3
1
2
3
( )
ln
v
y x
c
c v
c e
c
c
x
c x
−
−
=
+
+
=
+
+
 
 
55. 
3
2
3
2
3
2
4
4
0;
4
4
0;
0, 2, 2
d y
d y
dy
r
r
r
r
dv
dv
dv
−
+
=
−
+
=
=
 
 
(
)
2
2
2
1
2
3
1
2
3
( )
ln
v
v
y x
c
c e
c ve
c
x
c
c
x
=
+
+
=
+
+
 

 
Section 5.3 
253 
56. 
3
3
3
0;
0;
0, 0, 0
d y
r
r
dv
=
=
=
 
 
2
2
1
2
3
1
2
3
( )
ln
(ln )
y x
c
c v
c v
c
c
x
c
x
=
+
+
=
+
+
 
 
57. 
3
2
3
2
3
2
5
5
0;
4
4
0;
0, 3
3
d y
d y
dy
r
r
r
r
dv
dv
dv
−
+
=
−
+
=
=
±
 
 
(
)
(3
3)
(3
3)
3
3
3
1
2
3
1
2
3
( )
v
v
y x
c
c e
c ve
c
x
c x
c x
−
+
−
+
=
+
+
=
+
+
 
 
58. 
3
2
3
2
3
2
3
3
0;
3
3
1
0;
1,
1,
1
d y
d y
dy
y
r
r
r
r
dv
dv
dv
+
+
+
=
+
+
+ =
= −
−
− 
 
2
1
2
1
2
3
1
2
3
( )
ln
(ln )
v
v
v
y x
c e
c ve
c v e
x
c
c
x
c
x
−
−
−
−

=
+
+
=
+
+

 
 
 
 
SECTION 5.4 
 
Mechanical Vibrations 
 
In this section we discuss four types of free motion of a mass on a spring — undamped, 
underdamped, critically damped, and overdamped.  However, the undamped and underdamped 
cases — in which actual oscillations occur — are emphasized because they are both the most 
interesting and the most important cases for applications. 
 
1. 
Frequency:  
0
/
16/ 4
2 rad /sec
1/
Hz
k m
ω
π
=
=
=
=
 
 
Period:  
0
2 /
2 / 2
sec
P
π ω
π
π
=
=
=
 
 
2. 
Frequency  
0
/
48/0.75
8 rad /sec
4/
Hz
k m
ω
π
=
=
=
=
   
 
Period:  
0
2 /
2 /8
/ 4 sec
P
π ω
π
π
=
=
=
 
 
3. 
The spring constant is  k  =  15 N/0.20 m  =  75 N/m.  The solution of  3x″ + 75x  =  0  
with  x(0)  =  0  and  x′(0)  =  -10  is  x(t)  =  -2 sin 5t.  Thus the amplitude is 2 m; the 
frequency is  
0
/
75/ 3
5 rad /sec
2.5/
Hz
k m
ω
π
=
=
=
=
; and the period is  2π/5 sec. 
  
4. 
(a) 
With  m  =  1/4 kg  and  k  =  (9 N)/(0.25 m)  =  36 N/m  we find that  ω0  =  12 
rad/sec.  The solution of  x″ + 144x  =  0  with  x(0)  =  1  and  x′(0)  =  -5  is 
 
 
 
 
 
x(t)  =  cos 12t - (5/12)sin 12t 
 
 
 
       
        =  (13/12)[(12/13)cos 12t - (5/13)sin 12t] 
 
 
 
 
x(t)  =  (13/12)cos(12t - α) 

254 
Chapter 5 
 
 
where  α  =  2π - tan-1(5/12)  ≈  5.8884. 
 
 
(b) 
C  =  13/12  ≈  1.0833 m  and  T  =  2π/12  ≈  0.5236 sec. 
 
5. 
The gravitational acceleration at distance  R  from the center of the earth is  g  =  GM/R2. 
According to Equation (6) in the text the (circular) frequency  ω  of a pendulum is given 
by  ω2  =  g/L  =  GM/R2L,  so its period is  p  =  2π/ω  =  2πR
/
.
L GM  
 
6. 
If the pendulum in the clock executes  n  cycles per day (86400 sec) at Paris, then its 
period is  p1  =  86400/n sec.  At the equatorial location it takes  24 hr 2 min 40 sec  =  
86560 sec  for the same number of cycles, so its period there is  p2  =  86560/n sec.  Now 
let  R1  =  3956 mi  be the Earth′s "radius" at Paris, and  R2  its "radius" at the equator.  
Then substitution in the equation  p1/p2  =  R1/R2  of Problem 5 (with  L1  =  L2) yields  
R2  =  3963.33 mi.  Thus this (rather simplistic) calculation gives 7.33 mi as the thickness 
of the Earth's equatorial bulge. 
 
7. 
The period equation  p  =  3960 100.10   =  (3960 + x) 100   yields  x  ≈  1.9795 mi  ≈  
10,450 ft  for the altitude of the mountain. 
 
8. 
Let  n  be the number of cycles required for a correct clock with unknown pendulum 
length  
1L  and period  
1p  to register  24 hrs  =  86400 sec, so  
1
86400.
np =
  The given 
clock with length  L2  =  30 in and period  
2p  loses 10 min = 600 sec per day, so  
2
87000.
np =
  Then the formula of Problem 5 yields   
 
 
 
 
 
1
1
1
2
2
2
86400 ,
87000
L
p
np
L
p
np
=
=
=
   
 
 
so  
2
1
(30)(86400/87000)
29.59
L =
≈
 in. 
 
10. 
The  F  =  ma  equation   ρπr2hx″  =  ρπr2hg - πr2xg  simplifies to 
 
 
 
 
 
 
x″ + (g/ρh)x  =  g. 
 
 
The solution of this equation with  x(0)  =  x′(0)  =  0  is 
 
 
 
 
 
 
x(t)  =  ρh(1 - cos ω0t) 
 
 
where  ω0  =  
/
.
g
h
ρ
  With the given numerical values of  ρ, h, and  g, the amplitude of 
oscillation is  ρh  =  100 cm  and the period is  p  =  2π
/
h g
ρ
 ≈  2.01 sec. 
 

 
Section 5.4 
255 
11. 
The fact that the buoy weighs  100 lb  means that  mg  =  100  so  m  =  100/32 slugs.  
The weight of water is  62.4 lb/ft3,  so the  F  =  ma  equation of Problem 10 is 
 
 
 
 
 
 
(100/32)x''  =  100 - 62.4πr2x. 
 
 
It follows that the buoy's circular frequency  ω  is given by 
 
 
 
 
 
 
ω2  =  (32)(62.4π)r2/100. 
 
 
But the fact that the buoy′s period  is  p  =  2.5 sec  means that  ω  =  2π/2.5.  Equating 
these two results yields  r  ≈  0.3173 ft  ≈  3.8 in. 
 
12. 
(a) 
Substitution of  Mr  =  (r/R)3M  in  Fr  =  -GMrm/r2  yields 
   
 
 
 
 
 
Fr  =  -(GMm/R3)r.   
 
 
(b) 
Because  GM/R3  =  g/R, the equation  mr'' =  Fr  yields the differential equation 
 
 
 
 
 
 
r'' + (g/R)r  =  0. 
 
 
(c) 
The solution of this equation with  r(0)  =  R  and  r'(0)  =  0  is  r(t)  =  Rcos ω0t  
where  ω0  =  
/
.
g R   Hence, with  g  =  32.2 ft/sec2  and  R  = (3960)(5280) ft,  we find 
that the period of the particle′s simple harmonic motion is 
 
 
 
 
p  =  2π/ω0  =  2π
/
R g   ≈  5063.10 sec  ≈  84.38 min. 
 
13. 
(a) 
The characteristic equation  
2
10
9
2
(5
2)(2
1)
0
r
r
r
r
+
+
=
+
+
=
  has roots  
2 /5,
1/ 2.
r = −
−
 When we impose the initial conditions  (0)
0,
(0)
5
x
x′
=
=
  on the 
general solution  
2 /5
/ 2
1
2
( )
t
t
x t
c e
c e
−
−
=
+
 we get the particular solution  
(
)
2 /5
/ 2
( )
50
.
t
t
x t
e
e
−
−
=
−
 
 
 
(b) 
The derivative  
(
)
/ 2
2 /5
2 /5
/10
( )
25
20
5
5
4
0
t
t
t
t
x t
e
e
e
e
−
−
−
−
′
=
−
=
−
=
 
 
when  
10 ln(5/ 4)
2.23144
t =
≈
.  Hence the mass's farthest distance to the right  
 
is given by  (10ln(5/ 4))
512/125
4.096
x
=
=
. 
 
14. 
(a) 
The characteristic equation  
2
2
2
25
10
226
(5
1)
15
0
r
r
r
+
+
=
+
+
=
  has roots  
(
)
1 15
/5
1/5
3 .
r
i
i
=
−±
= −
±
 When we impose the initial conditions  
(0)
20,
(0)
41
x
x′
=
=
  on the general solution  
(
)
/5
( )
cos3
sin3
t
x t
e
A
t
B
t
−
=
+
 we  
 
get  A = 20,  B = 15.  The corresponding particular solution is given by   

256 
Chapter 5 
/5
/5
( )
(20cos3
15sin3 )
25
cos(3
)
t
t
x t
e
t
t
e
t
α
−
−
=
+
=
−
  where  
1
tan (3/ 4)
0.6435
α
−
=
≈
. 
 
 
(b) 
Thus the oscillations are "bounded" by the curves  
/5
25
t
x
e−
= ±
  and  
 
the pseudoperiod of oscillation is  
2
/3
T
π
=
  (because  
3
ω =
). 
 
15. 
With damping   The characteristic equation  
2
(1/ 2)
3
4
0
r
r
+
+
=
 has roots  
2,
4.
r = −
−
  
When we impose the initial conditions  (0)
2,
(0)
0
x
x′
=
=
 on the general solution  
2
4
1
2
( )
t
t
x t
c e
c e
−
−
=
+
 we get the particular solution  x(t)  =  4e-2t - 2e-4t  that describes 
overdamped motion. 
 
Without damping   The characteristic equation  
2
(1/ 2)
4
0
r +
=
 has roots  
2
2.
r
i
= ±
  
When we impose the initial conditions  (0)
2,
(0)
0
x
x′
=
=
 on the general solution  
( )
cos(2 2 )
sin(2 2 )
u t
A
t
B
t
=
+
 we get the particular solution  ( )
2cos(2 2 )
u t
t
=
.  
The graphs of  ( ) and
( )
x t
u t   are shown in the following figure. 
 
 
 
16. 
With damping   The characteristic equation  
2
3
30
63
0
r
r
+
+
=
 has roots  
3,
7.
r = −
−
  
When we impose the initial conditions  (0)
2,
(0)
2
x
x′
=
=
 on the general solution  
3
7
1
2
( )
t
t
x t
c e
c e
−
−
=
+
 we get the particular solution  x(t)  =  4e-3t - 2e-7t  that describes 
overdamped motion. 
 
Without damping   The characteristic equation  
2
3
63
0
r +
=
 has roots  
21.
r
i
= ±
  
When we impose the initial conditions  (0)
2,
(0)
2
x
x′
=
=
 on the general solution  
( )
cos( 21 )
sin( 21 )
u t
A
t
B
t
=
+
 we get the particular solution   
 
 
 
2
22
( )
2cos( 21 )
sin( 21 )
2
cos( 21
0.2149)
21
21
u t
t
t
t
=
+
≈
−
. 
 
 
The graphs of  ( ) and
( )
x t
u t   are shown in the figure at the top of the next page. 
 
1
2
3
t
-2
2
x
u

 
Section 5.4 
257 
1
2
t
-2
2
x
u
 
 
17. 
With damping   The characteristic equation  
2
8
16
0
r
r
+
+
=
 has roots  
4,
4.
r = −
−
  
When we impose the initial conditions  (0)
5,
(0)
10
x
x′
=
= −
 on the general solution  
(
)
4
1
2
( )
t
x t
c
c t e−
=
+
 we get the particular solution  
4
( )
5
(2
1)
t
x t
e
t
−
=
+
 that describes 
critically damped motion. 
 
Without damping   The characteristic equation  
2
16
0
r +
=
 has roots  
4 .
r
i
= ±
  When 
we impose the initial conditions  (0)
5,
(0)
10
x
x′
=
= −
 on the general solution  
( )
cos(4 )
sin(4 )
u t
A
t
B
t
=
+
 we get the particular solution   
 
 
 
 
5
5
( )
5cos(4 )
sin(4 )
5 cos(4
5.8195)
2
2
u t
t
t
t
=
+
≈
−
. 
 
 
The graphs of  ( ) and
( )
x t
u t   are shown in the following figure. 
 
1
2
t
-5
5
x
u
 
 
18. 
With damping   The characteristic equation  
2
2
12
50
0
r
r
+
+
=
 has roots  
3
4 .
r
i
= −
±
  
When we impose the initial conditions  (0)
0,
(0)
8
x
x′
=
= − on the general solution  
(
)
3
( )
cos4
sin4
t
x t
e
A
t
B
t
−
=
+
 we get the particular solution  
3
3
( )
2
sin4
2
cos(4
3 / 2)
t
t
x t
e
t
e
t
π
−
−
= −
=
−
 that describes underdamped motion. 

258 
Chapter 5 
 
Without damping   The characteristic equation  
2
2
50
0
r +
=
 has roots  
5 .
r
i
= ±
  When 
we impose the initial conditions  (0)
0,
(0)
8
x
x′
=
= − on the general solution   
 
( )
cos(5 )
sin(5 )
u t
A
t
B
t
=
+
 we get the particular solution    
 
 
 
 
8
8
3
( )
sin(5 )
cos 5
5
5
2
u t
t
t
π


= −
=
−




. 
 
The graphs of  ( ) and
( )
x t
u t   are shown in the following figure. 
1
2 t
-1
1
x
u
 
19. 
The characteristic equation  
2
4
20
169
0
r
r
+
+
=
 has roots  
5/ 2
6 .
r
i
= −
±
  When we 
impose the initial conditions  (0)
4,
(0)
16
x
x′
=
=
 on the general solution   
 
(
)
5 / 2
( )
cos6
sin6
t
x t
e
A
t
B
t
−
=
+
we get the particular solution 
 
 
x(t)  =  
5 / 2
t
e−
[ 4 cos 6t + 13
3 sin 6t ]  ≈  1
313
3
5 / 2
t
e−
cos(6t - 0.8254) 
 
that describes underdamped motion. 
 
Without damping   The characteristic equation  
2
4
169
0
r +
=
 has roots  
13 / 2.
r
i
= ±
 
  
When we impose the initial conditions  (0)
4,
(0)
16
x
x′
=
=
 on the general solution   
 
( )
cos(13 / 2)
sin(13 / 2)
u t
A
t
B
t
=
+
we get the particular solution    
 
 
u(t)  =  
13
32
13
4cos
sin
2
13
2
t
t




+








  ≈  4
13
233cos
0.5517
13
2 t


−




. 
1
2 t
-4
4
x
u
 

 
Section 5.4 
259 
20.  
With damping  The characteristic equation  
2
2
16
40
0
r
r
+
+
=
 has roots  
4
2 .
r
i
= −
±
 
 
When we impose the initial conditions  (0)
5,
(0)
4
x
x′
=
=
 on the general solution   
 
(
)
4
( )
cos2
sin2
t
x t
e
A
t
B
t
−
=
+
we get the particular solution 
 
 
x(t)  =  e-4t(5 cos 2t + 12 sin 2t)  ≈  13 e-4tcos(2t - 1.1760) 
 
that describes underdamped motion. 
 
Without damping   The characteristic equation  
2
2
40
0
r +
=
 has roots  
2 5 .
r
i
= ±
 
  
When we impose the initial conditions  (0)
5,
(0)
4
x
x′
=
=
 on the general solution   
 
( )
cos(2 5 )
sin(2 5 )
u t
A
t
B
t
=
+
we get the particular solution   
 
 
 
u(t)  =  
(
)
(
)
2
5cos 2 5
sin 2 5
5
t
t
+
  ≈  
(
)
129 cos 2 5
0.1770
5
t −
. 
 
The graphs of  ( ) and
( )
x t
u t   are shown in the following figure. 
 
1
2 t
-5
5
x
u
 
 
21. 
With damping   The characteristic equation  
2
10
125
0
r
r
+
+
=
 has roots  
5
10 .
r
i
= −
±
  
When we impose the initial conditions  (0)
6,
(0)
50
x
x′
=
=
 on the general solution   
 
(
)
5
( )
cos10
sin10
t
x t
e
A
t
B
t
−
=
+
we get the particular solution 
 
 
x(t)  =  e-5t(6 cos 10t + 8 sin 10t)  ≈  10 e-5tcos(10t - 0.9273) 
 
that describes underdamped motion. 
 
Without damping   The characteristic equation  
2
125
0
r +
=
 has roots  
5 5 .
r
i
= ±
 
  
When we impose the initial conditions  (0)
6,
(0)
50
x
x′
=
=
 on the general solution   
 
( )
cos(5 5 )
sin(5 5 )
u t
A
t
B
t
=
+
we get the particular solution   
 
 
 
u(t)  =  
(
)
(
)
6cos 5 5
2 5sin 5 5
t
t
+
  ≈  
(
)
2 14 cos 5 5
0.6405
t −
. 
 
The graphs of  ( ) and
( )
x t
u t   are shown in the figure at the top of the next page. 
 
 

260 
Chapter 5 
1 t
-6
6
x
u
 
 
22. 
(a) 
With  m  =  12/32  =  3/8 slug,  c  =  3 lb-sec/ft, and  k  =  24 lb/ft,  the differential 
equation is equivalent to  3x″ + 24x′ + 192x  =  0.  The characteristic equation  
2
3
24
192
0
r
r
+
+
=
 has roots  
4
4 3 .
r
i
= −
±
  When we impose the initial conditions  
(0)
1,
(0)
0
x
x′
=
=
 on the general solution  
(
)
4
( )
cos4
3
sin4
3
t
x t
e
A
t
B
t
−
=
+
 we get  
 
the particular solution 
     
 
 
 
x(t)  =  e-4t[cos 4t
3  + (1/
3 )sin 4t
3 ] 
       
 
       
 
        =  (2/
3 )e-4t[(
3 /2)cos 4t
3  + (1/2)sin 4t
3 ] 
 
 
 
 
x(t)  =  (2/
3 )e-4tcos(4t
3  –
/6
π
). 
 
 
(b) 
The time-varying amplitude is  2/
3   ≈  1.15 ft;  the frequency is  4
3   ≈  6.93 
rad/sec;  and the phase angle is  
/6
π
. 
 
23. 
(a) 
With  m  =  100 slugs  we get  ω  =  
/100
k
.  But we are given that 
 
 
 
 
 
ω  =  (80 cycles/min)(2π)(1 min/60 sec)  =  8π/3, 
 
 
and equating the two values yields  k  ≈  7018 lb/ft. 
 
 
(b) 
With  ω1  =  2π(78/60) sec-1,  Equation (21) in the text yields  c  ≈  372.31 
lb/(ft/sec).  Hence  p  =  c/2m  ≈  1.8615.  Finally  e-pt  =  0.01  gives  t  ≈  2.47 sec. 
 
30. 
In the underdamped case we have 
 
 
 
 
x(t)  =  e-pt[A cos ω1t + B sin ω1t], 
 
          
x′(t)  =  -pept[A cos ω1t + B sin ω1t] + e-pt[-Aω1sin ω1t + Bω1cos ω1t]. 
 
 
The conditions  x(0)  =  x0,  x′(0)  =  v0  yield the equations  A  =  x0  and   
 
-pA + Bω1  =  v0,  whence  B  =  (v0 + px0)/ω1. 

 
Section 5.4 
261 
31. 
The binomial series   
 
 
 
(
)
2
3
(
1)
(
1)(
2)
1
1
2!
3!
x
x
x
x
α
α α
α α
α
α
−
−
−
+
=
+
+
+
+  
 
converges if  
1.
x <
  (See, for instance, Section 11.8 of Edwards and Penney, Calculus, 
6th edition, Prentice Hall, 2002.)  With  
1/ 2
α =
 and  
2 / 4
x
c
mk
= −
 in Eq. (21) of 
Section 5.4 in this text, the binomial series gives 
 
 
2
2
2
2
1
0
2
2
4
2
0
2
2
1
4
4
1
1
.
8
128
8
k
c
k
c
p
m
m
m
mk
k
c
c
c
m
mk
m k
mk
ω
ω
ω
=
−
=
−
=
−




=
−
−
−
≈
−









  
 
32. 
If  x(t)  =  Ce-ptcos(ω1t - α)  then 
 
 
 
 
x′(t)  =  -pCe-ptcos(ω1t - α) + Cω1e-ptsin(ω1t - α)  =  0 
 
 
yields  tan(ω1t - α)  =  -p/ω1. 
 
33. 
If  x1  =  x(t1)  and  x2  =  x(t2)  are two successive local maxima, then  ω1t2  =  ω1t1 + 2π  
so 
 
 
 
x1  =  C exp(-pt1) cos(ω1t1 - α), 
 
 
 
x2  =  C exp(-pt2) cos(ω1t2 - α)  =  C exp(-pt2) cos(ω1t1 - α). 
 
 
Hence  x1/x2  =  exp[-p(t1 - t2)], and therefore   
 
 
 
 
 
ln(x1/x2)  =  -p(t1 - t2)  =  2πp/ω1. 
 
34. 
With  t1  =  0.34  and  t2  =  1.17  we first use the equation  ω1t2  =  ω1t1 + 2π  from 
Problem 32 to calculate  ω1  =  2π/(0.83)  ≈  7.57 rad/sec.  Next, with  x1  =  6.73  and   
 
x2  =  1.46,  the result of Problem 33 yields   
 
 
 
 
 
p  =  (1/0.83) ln(6.73/1.46)  ≈  1.84.   
 
 
Then Equation (16) in this section gives 
 
 
 
 
 
c  =  2mp  =  2(100/32)(1.84)  ≈  11.51 lb-sec/ft, 
 
 
and finally Equation (21) yields 
 
 
 
 
 
k  =  (4m2ω1
2 + c2)/4m  ≈  189.68 lb/ft. 

262 
Chapter 5 
 
35. 
The characteristic equation  
2
2
1
0
r
r
+
+ =
 has roots  
1,
1.
r = −
−
  When we impose the 
initial conditions  (0)
0,
(1)
0
x
x′
=
=
 on the general solution  
(
)
1
2
( )
t
x t
c
c t e−
=
+
 we get 
the particular solution  
1( )
.
t
x t
t e−
=
 
 
36. 
The characteristic equation  
2
2
2
(1 10
)
0
n
r
r
−
+
+
−
=
 has roots  
1 10 .
n
r
−
= −±
  When we 
impose the initial conditions  (0)
0,
(1)
0
x
x′
=
=
 on the general solution 
 
 
 
(
)
(
)
1
1
( )
exp
1 10
exp
1 10
n
n
x t
c
t
c
t
−
−




=
−+
+
−−



  
 
we get the equations   
 
 
(
)
(
)
1
2
1
2
0,
1 10
1 10
1
n
n
c
c
c
c
−
−
+
=
−+
+ −−
=
 
 
 
with solution  
1
1
1
2
2
5 ,
2
5 .
n
n
n
n
c
c
−
−
=
=
  This gives the particular solution 
 
 
2
exp(10
)
exp( 10
)
( )
10
10
sinh(10
).
2
n
n
n
t
n
t
n
t
t
x t
e
e
t
−
−
−
−
−


−
−
=
=




 
 
37. 
The characteristic equation  
2
2
2
(1 10
)
0
n
r
r
−
+
+
+
=
 has roots  
1 10
.
n
r
i
−
= −±
  When we 
impose the initial conditions  (0)
0,
(1)
0
x
x′
=
=
 on the general solution 
 
 
 
 
(
)
(
)
( )
cos 10
sin 10
t
n
n
x t
e
A
t
B
t
−
−
−


=
+

  
 
we get the equations  
1
1
2
0,
10
1
n
c
c
c
−
=
−
+
=
 with solution  
1
2
0,
10 .
n
c
c
=
=
  This 
gives the particular solution  
3( )
10
sin(10
).
n
t
n
x t
e
t
−
−
=
 
 
38. 
2
sinh(10
)
lim
( )
lim 10
sinh(10
)
lim
and
10
n
n
t
n
t
t
n
n
n
n
t
x t
e
t
t e
t e
t
−
−
−
−
−
−
→∞
→∞
→∞
=
=
⋅
=
 
 
3
sin(10
)
lim
( )
lim 10
sin(10
)
lim
10
n
n
t
n
t
t
n
n
n
n
t
x t
e
t
t e
t e
t
−
−
−
−
−
−
→∞
→∞
→∞
=
=
⋅
=
, 
 
using the fact that  
0
0
lim(sin ) /
lim(sinh )/
0
θ
θ
θ
θ
θ
θ
→
→
=
=
 (by L'Hôpital's rule, for 
instance). 
 
 
 
 
 

 
Section 5.5 
263 
SECTION 5.5 
 
NONHOMOGENEOUS EQUATIONS AND  
THE METHOD OF UNDETERMINED COEFFICIENTS 
 
The method of undetermined coefficients is based on "educated guessing".  If we can guess 
correctly the form of a particular solution of a nonhomogeneous linear equation with constant 
coefficients, then we can determine the particular solution explicitly by substitution in the given 
differential equation.  It is pointed out at the end of Section 5.5 that this simple approach is not 
always successful — in which case the method of variation of parameters is available if a 
complementary function is known.  However, undetermined coefficients does turn out to work 
well with a surprisingly large number of the nonhomogeneous linear differential equations that 
arise in elementary scientific applications. 
   
In each of Problems 1–20 we give first the form of the trial solution  ytrial,  then the equations in 
the coefficients we get when we substitute  ytrial  into the differential equation and collect like 
terms, and finally the resulting particular solution  yp. 
 
1. 
3
trial
;
25
1;
x
y
Ae
A
=
=
yp  =  (1/25)e3x          
 
 
 
2. 
trial
;
2
4,
2
3;
y
A
Bx
A
B
B
=
+
−
−
=
−
=
yp  =  -(5 + 6x)/4 
 
3. 
trial
cos3
sin3 ;
15
3
0, 3
15
2;
y
A
x
B
x
A
B
A
B
=
+
−
−
=
−
=
 
 
 yp  =  (cos 3x - 5 sin 3x)/39   
 
4. 
trial
;
9
12
0, 9
3;
x
x
y
Ae
B xe
A
B
B
=
+
+
=
=
yp  =  (-4ex + 3xex)/9 
 
5. 
First we substitute  sin2x  =  (1 - cos 2x)/2  on the right-hand side of the differential 
equation.  Then: 
 
trial
cos2
sin2 ;
1/ 2,
3
2
1/ 2,
2
3
0;
y
A
B
x
C
x
A
B
C
B
C
=
+
+
=
−
+
= −
−
−
=
 
 
 yp  =  (13 + 3 cos 2x - 2 sin 2x)/26 
 
6. 
2
trial
;
7
4
4
0, 7
8
0, 7
1;
y
A
B x
C x
A
B
C
B
C
C
=
+
+
+
+
=
+
=
=
 
 
 yp  =  (4 - 56x + 49x2)/343        
 
7. 
First we substitute  sinh x  =  (ex - e-x)/2  on the right-hand side of the differential 
equation.  Then: 
 
trial
;
3
1/ 2,
3
1/ 2;
x
x
y
Ae
Be
A
B
−
=
+
−
=
−
= −
yp  =  (e-x - ex)/6  =  -(1/3)sinh x 
 

264 
Chapter 5 
8. 
First we note that  cosh 2x  is part of the complementary function  
c
1
2
cosh2
sinh2 .
y
c
x
c
x
=
+
.  Then: 
 
(
)
trial
cosh2
sinh2
;
4
0, 4
1;
y
x A
x
B
x
A
B
=
+
=
=
yp  =  (1/4)x sinh 2x 
 
9. 
First we note that  ex  is part of the  complementary function  yc  =  c1ex + c2e-3x.  Then: 
 
trial
(
)
;
3
1, 4
2
0, 8
1;
x
y
A
x B
Cx e
A
B
C
C
=
+
+
−
=
+
=
=
 
 
 yp  =  -(1/3) + (2x2 - x)ex/16. 
 
10. 
First we note the duplication with the complementary function  
c
1
2
cos3
sin3 .
y
c
x
c
x
=
+
 
 
Then: 
 
(
)
trial
cos3
sin3
;
6
2,
6
3;
y
x A
x
B
x
B
A
=
+
=
−
=
yp  =  (2x sin 3x - 3x cos 3x)/6   
 
11. 
First we note the duplication with the complementary function  
c
1
2
3
cos2
sin2 .
y
c x
c
x
c
x
=
+
+
  Then: 
 
(
)
trial
;
4
1, 8
3;
y
x A
B x
A
B
=
+
= −
=
yp  =  (3x2 - 2x)/8 
 
12. 
First we note the duplication with the complementary function  
c
1
2
3
cos
sin .
y
c x
c
x
c
x
=
+
+
  Then: 
 
(
)
trial
cos
sin
;
2,
2
0,
2
1;
y
Ax
x B
x
C
x
A
B
C
=
+
+
=
−
=
−
= −
 
 
 yp  =  2x + (1/2)x sin x 
 
13. 
(
)
trial
cos
sin
;
7
4
0,
4
7
1;
x
y
e
A
x
B
x
A
B
A
B
=
+
+
=
−
+
=
 
 
 yp  =  ex(7 sin x - 4 cos x)/65 
 
14. 
First we note the duplication with the complementary function  
(
)
(
)
c
1
2
3
4
.
x
x
y
c
c x e
c
c x e
−
=
+
+
+
  Then:  
 
(
)
2
trial
;
8
24
0, 24
1;
x
y
x
A
B x e
A
B
B
=
+
+
=
=
yp  =  (-3x2ex + x3ex)/24 
 
15. 
This is something of  a trick problem.  We cannot solve the characteristic equation  
5
4
5
1
0
r
r
+
−=
 to find the complementary function, but we can see that it contains no 
constant term (why?).  Hence the trial solution  
trial
y
A
=
 leads immediately to the 
particular solution  yp  =  -17. 
 
 
 
 
16. 
(
)
2
3
trial
;
x
y
A
B
Cx
Dx
e
=
+
+
+
 
 
9
5, 18
6
2
0, 18
12
0, 18
2;
A
B
C
D
C
D
D
=
+
+
=
+
=
=
 

 
Section 5.5 
265 
 
 yp  =  (45 + e3x - 6xe3x + 9x2e3x)/81 
 
17. 
First we note the duplication with the complementary function  
c
1
2
cos
sin .
y
c
x
c
x
=
+
 
 
Then:  
 
[
]
trial
(
)cos
(
)sin
;
y
x
A
Bx
x
C
Dx
x
=
+
+
+
 
 
2
2
0, 4
1, 2
2
1, 4
0;
B
C
D
A
D
B
+
=
=
−
+
=
−
=
 
 
 yp  =  (x2sin x - x cos x)/4 
 
18. 
First we note the duplication with the complementary function 
   
2
2
c
1
2
3
4
.
x
x
x
x
y
c e
c e
c e
c e
−
−
=
+
+
+
  Then:  
 
ytrial  =  x(Aex) + x(B + Cx) e2x;     6
1, 12
38
0, 24
1;
A
B
C
C
−
=
+
=
= −
 
 
yp  =  -(24xex - 19xe2x + 6x2e2x)/144 
 
19. 
First we note the duplication with the part  
1
2
c
c x
+
 of the complementary function 
  
(which corresponds to the factor  
2r  of the characteristic polynomial).  Then:  
 
ytrial  =  x2(A + Bx + Cx2);          4
12
1, 12
48
0, 24
3;
A
B
B
C
C
+
= −
+
=
=
 
 
yp  =  (10x2 - 4x3 + x4)/8 
 
20. 
First we note that the characteristic polynomial  
3r
r
−
 has the zero  r = 1  corresponding 
 
to the duplicating part  ex  of the complementary function.  Then: 
 
(
)
trial
;
7, 3
1;
x
y
A
x Be
A
B
=
+
−
=
=
yp  =  -7 + (1/3)xex 
 
 
 
 
In Problems 21–30 we list first the complementary function  yc,  then the initially proposed trial 
function  yi,  and finally the actual trial function  yp  in which duplication with the 
complementary function has been eliminated. 
 
21. 
(
)
c
1
2
cos
sin
;
x
y
e
c
x
c
x
=
+
      
 
(
)
i
cos
sin
x
y
e
A
x
B
x
=
+
 
 
(
)
p
cos
sin
x
y
x e
A
x
B
x
=
⋅
+
 
 
22. 
(
) (
) (
)
2
c
1
2
3
4
5
;
x
x
y
c
c x
c x
c e
c e−
=
+
+
+
+
 
 
(
) (
)
2
i
x
y
A
Bx
Cx
De
=
+
+
+
 
 
 
(
)
(
)
3
2
p
x
y
x
A
Bx
Cx
x
De
=
⋅
+
+
+
⋅
 
 
23. 
c
1
2
cos
sin ;
y
c
x
c
x
=
+
 
 
i
(
)cos2
(
)sin2
y
A
Bx
x
C
Dx
x
=
+
+
+
 
 
 
[
]
p
(
)cos2
(
)sin2
y
x
A
Bx
x
C
Dx
x
=
⋅
+
+
+
 

266 
Chapter 5 
24. 
3
4
c
1
2
3
;
x
x
y
c
c e
c e
−
=
+
+
 
 
3
i
(
)
(
)
x
y
A
Bx
C
Dx e−
=
+
+
+
 
 
 
3
p
(
)
(
)
x
y
x
A
Bx
x
C
Dx e−
=
⋅
+
+
⋅
+
 
 
25. 
2
c
1
2
;
x
x
y
c e
c e
−
−
=
+
 
 
2
i
(
)
(
)
x
x
y
A
Bx e
C
Dx e
−
−
=
+
+
+
 
 
 
2
p
(
)
(
)
x
x
y
x
A
Bx e
x
C
Dx e
−
−
=
⋅
+
+
⋅
+
 
 
26. 
(
)
3
c
1
2
cos2
sin2
;
x
y
e
c
x
c
x
=
+
 
 
3
3
i
(
)
cos2
(
)
sin2
x
x
y
A
Bx e
x
C
Dx e
x
=
+
+
+
 
 
 
3
3
p
(
)
cos2
(
)
sin 2
x
x
y
x
A
Bx e
x
C
Dx e
x


=
⋅
+
+
+

 
 
27. 
(
) (
)
c
1
2
3
3
cos
sin
cos2
sin2
y
c
x
c
x
c
x
c
x
=
+
+
+
 
(
) (
)
i
cos
sin
cos2
sin2
y
A
x
B
x
C
x
D
x
=
+
+
+
 
 
 
(
) (
)
p
cos
sin
cos2
sin 2
y
x
A
x
B
x
C
x
D
x
=
⋅
+
+
+



 
 
28. 
(
)
(
)
c
1
2
3
3
cos3
sin3
y
c
c x
c
x
c
x
=
+
+
+
 
 
(
)
(
)
2
2
i
cos3
sin3
y
A
Bx
Cx
x
D
Ex
Fx
x
=
+
+
+
+
+
 
 
 
(
)
(
)
2
2
p
cos3
sin3
y
x
A
Bx
Cx
x
D
Ex
Fx
x


=
⋅
+
+
+
+
+

 
 
29. 
(
)
2
2
2
c
1
2
3
4
5
x
x
x
y
c
c x
c x
e
c e
c e−
=
+
+
+
+
;      
 
(
)
2
2
i
x
x
x
y
A
Bx e
C e
De−
=
+
+
+
 
 
 
(
)
(
)
(
)
3
2
2
p
x
x
x
y
x
A
Bx e
x
C e
x
De−
=
⋅
+
+
⋅
+
⋅
 
 
30. 
(
)
(
)
c
1
2
3
4
x
x
y
c
c x e
c
c x e
−
=
+
+
+
  
 
(
)
(
)
2
2
i
p
cos
sin
y
y
A
Bx
Cx
x
D
Ex
Fx
x
=
=
+
+
+
+
+
 
 
In Problems 31–40 we list first the complementary function  yc,  the trial solution  ytr  for the 
method of undetermined coefficients, and the corresponding general solution  yg = yc + yp  where 
yp  results from determining the coefficients in  ytr  so as to satisfy the given nonhomogeneous 
differential equation.  Then we list the linear equations obtained by imposing the given initial 
conditions, and finally the resulting particular solution  y(x). 
 
31. 
c
1
2
tr
cos2
sin2 ;
y
c
x
c
x
y
A
Bx
=
+
=
+
 
 
g
1
2
cos2
sin2
/ 2
y
c
x
c
x
x
=
+
+
 

 
Section 5.5 
267 
 
 
 
1
2
1, 2
1/ 2
2
c
c
=
+
=
 
 
( )
cos2
(3/ 4)sin 2
/ 2
y x
x
x
x
=
+
+
 
 
32. 
2
c
1
2
tr
;
x
x
x
y
c e
c e
y
Ae
−
−
=
+
=
 
 
2
g
1
2
/6
x
x
x
y
c e
c e
e
−
−
=
+
+
 
 
1
2
1
2
1/ 6
0,
2
1/6
3
c
c
c
c
+
+
=
−
−
+
=
 
 
(
)
2
( )
15
16
/6
x
x
x
y x
e
e
e
−
−
=
−
+
 
 
33. 
c
1
2
tr
cos3
sin3 ;
cos2
sin2
y
c
x
c
x
y
A
x
B
x
=
+
=
+
 
 
g
1
2
cos3
sin3
(1/5)sin2
y
c
x
c
x
x
=
+
+
 
 
1
2
1, 3
2/5
0
c
c
=
+
=
 
 
(
)
( )
15cos3
2sin3
3sin2
/15
y x
x
x
x
=
−
+
 
 
34. 
(
)
c
1
2
tr
cos
sin ;
cos
sin
y
c
x
c
x
y
x
A
x
B
x
=
+
=
⋅
+
 
 
1
g
1
2
2
cos
sin
sin
y
c
x
c
x
x
x
=
+
+
 
 
1
1
2
2
1,
1;
( )
cos
sin
sin
c
c
y x
x
x
x
x
=
= −
=
−
+
 
 
35. 
(
)
c
1
2
tr
cos
sin
;
x
y
e
c
x
c
x
y
A
B x
=
+
=
+
 
 
(
)
g
1
2
cos
sin
1
/ 2
x
y
e
c
x
c
x
x
=
+
+ +
 
 
1
1
2
1
3,
1/ 2
0
c
c
c
+
=
+
+
=
 
 
(
)
( )
4cos
5sin
/ 2
1
/ 2
x
y x
e
x
x
x
=
−
+ +
 
 
36. 
(
)
2
2
2
2
c
1
2
3
4
tr
;
x
x
y
c
c x
c e
c e
y
x
A
B x
C x
−
=
+
+
+
=
⋅
+
+
 
 
2
2
2
4
g
1
2
3
4
/16
/ 48
x
x
y
c
c x
c e
c e
x
x
−
=
+
+
+
−
−
 
 
1
3
4
2
3
4
3
4
3
4
1,
2
2
1, 4
4
1/8
1,
8
8
1
c
c
c
c
c
c
c
c
c
c
+
+
=
−
+
=
+
−
= −
−
+
= − 
 
(
)
2
2
2
4
( )
234
240
9
33
12
4
/192
x
x
y x
x
e
e
x
x
−
=
+
−
−
−
−
 
 
37. 
(
)
(
)
2
c
1
2
3
tr
;
x
x
x
y
c
c e
c xe
y
x
A
x
B
Cx e
=
+
+
=
⋅
+
⋅
+
 
 
2
3
g
1
2
3
/ 2
/6
x
x
x
x
y
c
c e
c xe
x
x e
x e
=
+
+
+
−
+
 

268 
Chapter 5 
 
1
2
2
3
2
3
0,
1
0,
2
1
1
c
c
c
c
c
c
+
=
+
+
=
+
−
=
 
 
(
)
2
3
( )
4
24
18
3
/6
x
y x
x
e
x
x
x
=
+
+
−
+
−
+
 
 
38. 
(
)
c
1
2
tr
cos
sin
;
cos3
sin3
x
y
e
c
x
c
x
y
A
x
B
x
−
=
+
=
+
 
 
(
) (
)
g
1
2
cos
sin
6cos3
7sin3
/85
x
y
e
c
x
c
x
x
x
−
=
+
−
+
 
 
1
1
2
6/185
2,
21/85
0
c
c
c
−
=
−
+
−
=
 
 
(
) (
)
( )
176cos
197sin
6cos3
7sin3
/85
x
y x
e
x
x
x
x
−


=
+
−
+


 
 
39. 
(
)
(
)
2
c
1
2
3
tr
;
x
x
y
c
c x
c e
y
x
A
Bx
x
Ce
−
−
=
+
+
=
⋅
+
+
⋅
 
 
2
3
g
1
2
3
/ 2
/6
x
x
y
c
c x
c e
x
x
x e
−
−
=
+
+
−
+
+
 
 
1
3
2
3
3
1,
1
0,
3
1
c
c
c
c
c
+
=
−
+
=
−
=
 
 
(
)
2
3
( )
18
18
3
/ 6
(4
)
x
y x
x
x
x
x e−
=
−
+
−
+
+
+
 
 
40. 
c
1
2
3
4
tr
cos
sin ;
x
x
y
c e
c e
c
x
c
x
y
A
−
=
+
+
+
=
 
 
g
1
2
3
4
cos
sin
5
x
x
y
c e
c e
c
x
c
x
−
=
+
+
+
− 
 
1
2
3
1
2
4
1
2
3
1
2
4
5
0,
0,
0,
0
c
c
c
c
c
c
c
c
c
c
c
c
+
+
−
=
−
+
+
=
+
−
=
−
+
−
=
 
 
(
)
( )
5
5
10cos
20 / 4
x
x
y x
e
e
x
−
=
+
+
−
 
 
41. 
The trial solution  
2
3
4
5
tr
y
A
Bx
Cx
Dx
Ex
Fx
=
+
+
+
+
+
 leads to the equations 
 
 
 
 
2
2
6
24  
 0
2
2
6
24
120  
 0
2
3
12
60  
 0
2
4
20
 
 0
2
5  
 0
2
8
A
B
C
D
E
B
C
D
E
F
C
D
E
F
D
E
F
E
F
F
−
−
−
+
=
−
−
−
−
+
=
−
−
−
−
=
−
−
−
=
−
−
=
−
=
 
 
 
that are readily solve by back-substitution.  The resulting particular solution is 
 
 
 
y(x)  =  –255 - 450x + 30x2 + 20x3 + 10x4 - 4x5. 
 

 
Section 5.5 
269 
42. 
The characteristic equation  
4
3
2
2
0
r
r
r
r
−
−
−
−
=
  has roots  
1, 2,
r
i
= −
±   so the 
complementary function is  
2
c
1
2
3
4
cos
sin .
x
x
y
c e
c e
c
x
c
x
−
=
+
+
+
  We find that the 
coefficients satisfy the equations 
 
 
 
 
1
2
3
1
2
4
1
2
3
1
2
4
255
0
2
450
0
4
60
0
8
120
0
c
c
c
c
c
c
c
c
c
c
c
c
+
+
−
=
−
+
+
−
=
+
−
+
=
−
+
−
+
=
 
 
 
Solution of this system gives finally the particular solution  
c
p
y
y
y
=
+
 where  yp  is the 
particular solution of Problem 41 and 
 
 
 
 
2
c
10
35
210cos
390sin .
x
x
y
e
e
x
x
−
=
+
+
+
 
 
43. 
(a) 
3
cos3
sin3
(cos
sin )
x
i
x
x
i
x
+
=
+
  
 
 
3
2
2
3
cos
3 cos
sin
3cos sin
sin
x
i
x
x
x
x
i
x
=
+
−
−
 
 
When we equate real parts we get the equation 
 
 
 
(
)(
)
3
2
3
cos
3 cos
1
cos
4cos
3cos
x
x
x
x
x
−
−
=
−
 
and readily solve for  
3
3
1
4
4
cos
cos
cos3 .
x
x
x
=
+
  The formula for  
3
sin x  is derived 
similarly by equating imaginary parts in the first equation above. 
 
 
(b) 
Upon substituting the trial solution  
p
cos
sin
cos3
sin3
y
A
x
B
x
C
x
D
x
=
+
+
+
 
 
in the differential equation  
3
1
4
4
4
cos
cos3 ,
y
y
x
x
′′+
=
+
 we find that  A = 1/4, B = 0,  
 
C = –1/20, D = 0.  The resulting general solution is 
 
 
 
y(x)  =  c1cos 2x + c2sin 2x + (1/4)cos x - (1/20)cos 3x.  
 
44. 
We use the identity  
1
1
2
2
sin sin3
cos2
cos4 ,
x
x
x
x
=
−
  and hence substitute the trial 
solution  
p
cos2
sin 2
cos4
sin4
y
A
x
B
x
C
x
D
x
=
+
+
+
 in the differential equation  
 
1
1
2
2
cos2
cos4 .
y
y
y
x
x
′′
′
+
+
=
−
  We find that  A = –3/26, B = 1/13, C = –14/482,  
 
D = 2/141.  The resulting general solution is 
 
 
 
y(x)  =  e-x/2(c1 cos x
3 /2 + c2 sin x 3 /2) 
 
 
 
+ (-3 cos 2x + 2 sin 2x)/26 + (-15 cos 4x + 4 sin 4x)/482. 
 
45. 
We substitute 
        
 
 
sin4x  =  (1 - cos 2x)2/4 

270 
Chapter 5 
 
 
          =  (1 - 2 cos 2x + cos22x)/4  =  (3 - 4 cos 2x + cos 4x)/8 
 
 
on the right-hand side of the differential equation, and then substitute the trial solution 
 
 
p
cos2
sin 2
cos4
sin4
.
y
A
x
B
x
C
x
D
x
E
=
+
+
+
+
 We find that  A = –1/10, B = 0,  
 
C = –1/56, D = 0, E = 1/24.  The resulting general solution is 
 
 
 
y  =  c1cos 3x + c2sin 3x + 1/24 - (1/10)cos 2x - (1/56)cos 4x. 
   
46. 
By the formula for 
3
cos x  in Problem 43, the differential equation can be written as 
 
 
 
3
1
4
4
cos
cos3 .
y
y
x
x
x
x
′′ +
=
+
 
 
The complementary solution is  yc  =  c1cos x + c2sin x,  so we substitute the trial solution 
 
 
 
(
)
(
)
(
)
(
)
p
cos
sin
cos3
sin3
.
y
x
A
Bx
x
C
Dx
x
E
Fx
x
G
Hx
x
=
⋅
+
+
+
+
+
+
+







 
 
 
We find that  
3/16,
0,
3/16,
0,
1/32,
3/128,
0.
A
B
C
D
E
F
G
H
=
=
=
=
=
= −
=
=
 Hence 
the general solution is given by  y  =  yc + y1 + y2  where 
 
 
 
y1  =  (3x cos x + 3x2sin x)/16   and    y2  =  (3 sin 3x - 4x cos 3x)/128. 
 
In Problems 47–49 we list the independent solutions  
1
2
and
y
y  of the associated homogeneous 
equation, their Wronskian  
1
2
(
,
),
W
W y
y
=
 the coefficient functions   
 
 
2
1
1
2
( )
( )
( )
( )
( )
and
( )
( )
( )
y
x f x
y x f x
u x
dx
u
x
dx
W x
W x
= −
=
⌠
⌠


⌡
⌡
  
 
in the particular solution  
p
1
1
2
2
y
u y
u y
=
+
 of Eq. (32) in the text, and finally  yp  itself. 
 
47. 
y1  =  e-2x,    
 
y2  =  e-x,    
 
W  =  e-3x 
 
u1  =  -(4/3)e3x,    
u2  =  2e2x,    
 
yp  =  (2/3)ex 
 
48. 
y1  =  e-2x,    
 
y2  =  e4x,    
 
W  =  6e2x 
 
u1  =  -x/2,     
u2  =  -e-6x/12,    
 
yp  =  -(6x + 1)e-2x/12 
 
49. 
y1  =  e2x,    
 
y2  =  xe2x,    
 
W  =  e4x 
 
u1  =  -x2,    
 
u2  =  2x,    
 
yp  =  x2e2x 
 

 
Section 5.5 
271 
50. 
The complementary function is  y1  =  c1cosh 2x + c2sinh 2x, so the Wronskian is   
 
 
 
 
 
W  =  2 cosh22x - 2 sinh22x  =  2,  
 
 
so when we solve Equations (31) simultaneously for  
1
2
and
,
u
u
′
′   integrate each and 
substitute in  yp  =  y1u1 + y2u2,  the result is     
 
 
 
1
1
2
2
(cosh2 )
(sinh2 )(sinh2 )
(sinh2 )
(cosh2 )(sinh2 )
p
y
x
x
x dx
x
x
x dx
= −
+
∫
∫
. 
 
 
Using the identities  2 sinh2x  =  cosh 2x - 1  and  2 sinh x cosh x  =  sinh 2x,  we evaluate 
the integrals and find that 
 
 
 
yp  =  (4x cosh 2x - sinh 4x cosh 2x + cosh 4x sinh 2x)/16, 
 
 
yp  =  (4x cosh 2x - sinh 2x)/16. 
 
51. 
1
2
cos2 ,
sin 2 ,
2
y
x
y
x
W
=
=
=
 
 
Liberal use of trigonometric sum and product identities yields 
 
 
1
1
(cos5
5cos )/ 20,
(sin5
5sin )/ 20
u
x
x
u
x
x
=
−
=
−
 
 
yp  =  -(1/4)(cos 2x cos x - sin 2x sin x) + (1/20)(cos 5x cos 2x + sin 5x sin 2x)  
 
     =  -(1/5)cos 3x  (!) 
 
52.    y1  =  cos 3x,  
y2  =  sin 3x,     
W  =  3  
 
1
1
(6
sin6 )/36,
(1
cos6 )/ 36
u
x
x
u
x
= −
−
= −
+
 
 
yp  =  -(x cos 3x)/6 
 
53. 
y1  =  cos 3x,   
y2  =  sin 3x,   
W  =  3 
 
1u′  =  -(2/3)tan 3x,      
2u′   =  2/3 
 
yp  =  (2/9)[3x sin 3x + (cos 3x)ln cos3x ] 
 
54. 
y1  =  cos x,  
 
y2  =  sin x,  
 
W  =  1 
 
1u′  =  -csc x,   
2u′ =  cos x csc2x 
 
yp  =  -1 - (cos x) ln csc
cot
x
x
−
 
 
55. 
y1  =  cos 2x,     
y2  =  sin 2x,     
W  =  2 
 
1u′  =  -(1/2)sin2x sin 2x  =  -(1/4)(1 - cos 2x)sin 2x 

272 
Chapter 5 
 
2u′   =   (1/2)sin2x cos 2x  =   (1/4)(1 - cos 2x)cos 2x 
 
yp  =  (1 - x sin 2x)/8  
 
56. 
y1  =  e-2x,    
 
y2  =  e2x,     
 
W  =  4 
     
u1  =  -(3x - 1)e3x/36,    
u2  =  -(x + 1)e-x/4  
 
yp  =  -ex(3x + 2)/9 
 
57. 
With  y1  =  x,  y2  =  x-1,  and  f(x)  =  72x3,  Equations (31) in the text take the form 
 
 
 
 
 
x
1u′ + x-1
2u′   =  0, 
 
 
 
   
  
1u′ - x-2
2u′   =  72x3. 
 
 
 
Upon multiplying the second equation by  x  and then adding, we readily solve first for 
 
 
 
 
 
1u′  =  36x3, 
so 
u1  =  9x4 
 
and then 
 
 
 
2u′   =  -x2
1u′  =  -36x5, 
so 
u2  =  -6x6.  
 
 
Then it follows that 
 
 
 
 
yp  =  y1u1 + y2u2  =  (x)(9x4) + (x-1)(-6x6)  =  3x5. 
 
58. 
Here it is important to remember that — for variation of parameters — the differential 
equation must be written in standard form with leading coefficient  1.  We therefore 
rewrite the given equation with complementary function  yc  =  c1x2 + c2x3  as 
 
 
 
 
 
 
y″ - (4/x)y′ + (6/x2)y  =  x. 
 
 
Thus  f(x)  =  x, and  W  =  x4,  so simultaneous solution of Equations (31) as in Problem 
50 (followed by integration of  
1u′  and  
2u′ )  yields 
 
2
3
4
3
2
4
2
3
3
(1/ )
(ln
1).
p
y
x
x
x x
dx x
x
x x
dx
x
dx x
x dx
x
x
−
−
= −
⋅
⋅
+
⋅⋅
= −
+
=
−
∫
∫
∫
∫
 
 
59. 
y1  =  x2,   
 
y2  =  x2ln x,    
 
W  =  x3,    
 
f(x)  =  x2 
 
1u′  =  -x ln x,    
2u′   =  x 
 
yp  =  x4/4 
 

 
Section 5.5 
273 
60. 
1/ 2
1
,
y
x
=
 
 
3/ 2
2y
x
=
 
 
 
f(x)  =  2x-2/3;    
W  =  x  
 
5/6
1
12
/5,
u
x
= −
 
1/6
2
12
u
x−
= −
 
 
4/3
p
72
/5
y
x
= −
 
 
61. 
y1  =  cos(ln x),    
y2  =  sin(ln x),    
W  =  1/x,    
      
f(x)  =  (ln x)/x2 
 
u1  =  (ln x)cos(ln x) - sin(ln x) 
 
u2  =  (ln x)sin(ln x) + cos(ln x) 
 
yp  =  ln x   (!) 
 
62. 
y1  =  x,    
 
y2  =  1 + x2,    
 
W  =  x2 - 1,     
f(x)  =  1 
 
1u′  =  (1 + x2)/(1 - x2),    
2u′   =  x/(x2 - 1) 
 
yp  =  -x2 + x ln|(1 + x)/(1 - x)| + (1/2)(1 + x2)ln|1 - x2| 
 
63. 
This is simply a matter of solving the equations in (31) for the derivatives 
 
2
1
1
2
( ) ( )
( ) ( )
and
( )
( )
y
x f x
y x f x
u
u
W x
W x
′
′
= −
=
, 
 
 
integrating each, and then substituting the results in (32). 
 
64. 
Here we have  
1
2
( )
cos ,
( )
sin ,
( )
1,
( )
2sin
y x
x
y
x
x W x
f x
x
=
=
=
=
,  so (33) gives 
 
2
2
2
( )
(cos ) sin
2sin
(sin ) cos
2sin
(cos ) (1
cos2 )
(sin ) 2(sin ) cos
(cos )(
sin cos )
(sin )(sin
)
cos
(sin )(cos
sin
)
( )
cos
sin
p
p
y
x
x
x
x dx
x
x
x dx
x
x dx
x
x
xdx
x
x
x
x
x
x
x
x
x
x
x
y
x
x
x
x
= −
⋅
+
⋅
= −
−
+
⋅
= −
−
+
= −
+
+
= −
+
∫
∫
∫
∫
 
 
 
But we can drop the term  sin x  because it satisfies the associated homogeneous 
 
equation  
0.
y
y
′′+
=
 
 
 
 

274 
Chapter 5 
SECTION 5.6 
 
FORCED OSCILLATIONS AND RESONANCE 
 
1. 
Trial of  x  =  A cos 2t  yields the particular solution  xp  =  2 cos 2t.  (Can you see that —
because the differential equation contains no first-derivative term — there is no need to 
include a  sin 2t  term in the trial solution?)  Hence the general solution is 
 
 
 
 
 
x(t)  =  c1cos 3t + c2sin 3t + 2 cos 2t. 
 
 
The initial conditions imply that  c1  =  -2  and  c2  =  0,  so  x(t)  =  2 cos 2t - 2 cos 3t. 
 
The following figure shows the graph of  ( ).
x t  
π
3 π
5 π
t
-3
3
2π
 
2. 
Trial of  x  =  A sin 3t  yields the particular solution  xp  =  -sin 3t.  Then we impose the 
 
initial conditions  x(0)  =  x′(0)  =  0  on the general solution 
 
 
 
 
 
x(t)  =  c1cos 2t + c2sin 2t - sin 3t,   
 
 
and find that  x(t)  =  3
2 sin 2t - sin 3t.  The following figure shows the graph of  ( ).
x t  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
π
3 π
5 π
t
-2
2
2π

 
Section 5.6 
275 
3. 
First we apply the method of undetermined coefficients — with trial solution  
 
cos5
sin5
x
A
t
B
t
=
+
— to find the particular solution 
 
 
 
 
xp  =  3 cos 5t + 4 sin 5t   
 
 
 
     
(
)
3
4
5
cos5
sin5
5cos 5
5
5
t
t
t
β


=
+
=
−




 
 
 
where  β  =  tan-1(4/3)  ≈  0.9273.  Hence the general solution is 
 
 
 
 
x(t)  =  c1cos 10t + c2sin 10t + 3 cos 5t + 4 sin 5t. 
 
 
The initial conditions  x(0)  =  375,  x′(0)  =  0  now yield  c1  =  372  and  c2  =  -2,  so 
the part of the solution with frequency  ω  =  10  is 
 
 
 
xc  =  372 cos 10t - 2 sin 10t   
 
 
     
(
)
372
2
138388
cos10
sin10
138388
138388
138388 cos 10
t
t
t
α


=
−




=
−
   
 
      
where  α  =  2π - tan-1(1/186)  ≈  6.2778  is a fourth-quadrant angle.  The following 
 
figure shows the graph of  ( ).
x t  
π
t
-375
375
πê5
 
 
4. 
Noting that there is no first-derivative term, we try  
cos4
x
A
t
=
 and find the particular 
solution  
p
10cos 4 .  
x
t
=
Then imposition of the initial conditions on the general 
solution 
1
2
( )
cos5
sin5
10cos4
x t
c
t
c
t
t
=
+
+
 yields 
 
 
 
x(t)  =  (-10 cos 5t + 18 sin 5t) + 10 cos 4t  

276 
Chapter 5 
 
 
        
(
)
2
5cos5
9sin5
10cos4
t
t
t
=
−
+
+
  
 
 
        
5
9
2 106
cos5
sin5
10cos4
106
106
2 106 cos(5
)
t
t
t
t
α


=
−
+
+




=
−
 
 
 
where  α  =  π - tan-1(9/5)  ≈  2.0779  is a second-quadrant angle.  The following figure 
 
shows the graph of  ( ).
x t  
 
π
3 π
5 π
t
-30
30
2π
 
 
5. 
Substitution of the trial solution  
cos
x
C
t
ω
=
 gives  C  =  F0/(k - mω2).  Then 
imposition of the initial conditions  
0
(0)
,
(0)
0
x
x
x′
=
=
  on the general solution   
 
 
 
1
0
2
0
0
( )
cos
sin
cos
(where
/
)
x t
c
t
c
t
C
t
k m
ω
ω
ω
ω
=
+
+
=
 
 
 
gives the particular solution  x(t)  =  (x0 - C)cos ω0t + C cos ωt. 
   
6. 
First, let's write the differential equation in the form  
(
)
2
0
0
0
/
cos
,
x
x
F
m
t
ω
ω
′′ +
=
 which 
is the same as Eq. (13) in the text, and therefore has the particular solution  
p
0
0
0
(
/ 2
) sin
x
F
m
t
t
ω
ω
=
 given in Eq. (14).  When we impose the initial conditions  
0
(0)
0,
(0)
x
x
v
′
=
=
 on the general solution   
 
 
 
 
1
0
2
0
0
0
0
( )
cos
sin
(
/ 2
) sin
x t
c
t
c
t
F
m
t
t
ω
ω
ω
ω
=
+
+
 
 
 
we find that  
1
2
0
0
0,
/
.
c
c
v
ω
=
=
  The resulting resonance solution of our initial value 
problem is 
 
 
 
 
0
0
0
0
2
( )
sin
.
2
mv
F t
x t
t
m
ω
ω
+
=
 

 
Section 5.6 
277 
In Problems 7–10 we give first the trial solution  xp  involving undetermined coefficients  A  and  
B,  then the equations that determine these coefficients, and finally the resulting steady periodic 
solution  xsp.   In each case the figure shows the graphs of  
sp( )
x
t  and the adjusted forcing 
function  
1( )
( )/
.
F t
F t
mω
=
 
 
7. 
p
cos3
sin3 ;
5
12
10,
12
5
0
x
A
t
B
t
A
B
A
B
=
+
−
+
=
+
=
 
 
sp
50
120
10
5
12
10
( )
cos3
sin3
cos3
sin3
cos(3
)
169
169
13
13
13
13
x
t
t
t
t
t
t
α


= −
+
=
−
+
=
−




 
 
1
tan (12/5)
1.9656
α
π
−
=
−
≈
     (2nd quadrant angle) 
2 π t
-3
3
xsp
F1
 
 
8. 
p
cos5
sin5 ;
20
15
4,
15
20
0
x
A
t
B
t
A
B
A
B
=
+
−
+
= −
+
=
 
 
sp
16
12
4
4
3
4
( )
cos5
sin5
cos5
sin5
cos(5
)
125
125
25
5
5
25
x
t
t
t
t
t
t
α


=
−
=
−
=
−




 
 
1
2
tan (3/ 4)
5.6397
α
π
−
=
−
≈
     (4th quadrant angle) 
2 π t
-1
1
xsp
F1
 

278 
Chapter 5 
9. 
p
cos10
10sin5 ;
199
20
0,
20
199
3
x
A
t
t
A
B
A
B
=
+
−
+
=
+
= −
 
 
sp
60
597
( )
cos10
sin10
40001
40001
3
20
199
3
cos10
sin10
cos(10
)
40001
40001
40001
40001
x
t
t
t
t
t
t
α
= −
−


=
−
−
=
−




 
 
1
tan (199/ 20)
4.6122
α
π
−
=
+
≈
     (3rd quadrant angle) 
2 π t
-0.1
0.1
xsp
F1
 
10. 
p
cos10
10sin5 ;
97
30
8,
30
97
6
x
A
t
t
A
B
A
B
=
+
−
+
=
+
= −
 
 
sp
956
342
( )
cos10
sin10
10309
10309
2 257725
478
171
10
cos10
sin10
61cos(10
)
10309
793
257725
257725
x
t
t
t
t
t
t
α
= −
−


=
−
−
=
−




 
 
1
tan (171/ 478)
3.4851
α
π
−
=
+
≈
     (3rd quadrant angle) 
2 π t
-1
1
xsp
F1
 

 
Section 5.6 
279 
Each solution in Problems 11–14 has two parts.  For the first part, we give first the trial solution  
xp  involving undetermined coefficients  A  and  B,  then the equations that determine these 
coefficients, and finally the resulting steady periodic solution  xsp.  For the second part, we give 
first the general solution  x(t)  involving the coefficients  c1  and  c2  in the transient solution,  
then the equations that determine these coefficients, and finally the resulting transient solution  
tr
x  so that  
tr
sp
( )
( )
( )
x t
x
t
x
t
=
+
 satisfies the given initial conditions.  For each problem, the 
graph shows the graphs of both  
sp
( ) and
( ).
x t
x
t
 
 
11. 
p
cos3
sin3 ;
4
12
10,
12
4
0
x
A
t
B
t
A
B
A
B
=
+
−
+
=
+
=
 
 
(
)
sp
1
3
10
1
3
10
( )
cos3
sin3
cos3
sin3
cos 3
4
4
4
4
10
10
x
t
t
t
t
t
t
α


= −
+
=
−
+
=
−




 
 
1
tan (3)
1.8925
α
π
−
=
−
≈
     (2nd quadrant angle) 
 
(
)
2
9
1
1
2
sp
1
1
2
4
4
( )
cos
sin
( );
0,
2
0
t
x t
e
c
t
c
t
x
t
c
c
c
−
=
+
+
−
=
−
+
+
=
 
 
(
)
2
2
tr
2
1
7
50
1
7
( )
cos
sin
cos
sin
4
4
4
50
50
5
2
cos
4
t
t
t
x
t
e
t
t
e
t
t
e
t
β
−
−
−




=
−
=
−








=
−
 
 
1
2
tan (7)
4.8543
β
π
−
=
−
≈
     (4th quadrant angle) 
π
t
-0.5
0.5
xsp
x
 
 
12. 
p
cos5
sin5 ;
12
30
0,
30
12
10
x
A
t
B
t
A
B
A
B
=
+
−
=
+
= −
 
 
sp
25
10
( )
cos5
sin5
87
87
x
t
t
t
= −
−
 

280 
Chapter 5 
 
(
)
5 29
5
2
5
cos3
sin3
cos 3
87
29
29
3 29
t
t
t
α


=
−
−
=
−




 
 
1
tan (2/5)
3.5221
α
π
−
=
+
≈
     (3rd quadrant angle) 
 
(
)
3
1
2
sp
1
1
2
( )
cos2
sin2
( );
25/87
0,
3
2
50/87
0
t
x t
e
c
t
c
t
x
t
c
c
c
−
=
+
+
−
=
−
+
−
=
 
 
3
tr
50
125
( )
cos2
sin 2
174
174
t
x
t
e
t
t
−

=
+




 
 
(
)
3
3
25 29
2
5
25
cos2
sin2
cos 2
174
29
29
6 29
t
t
e
t
t
e
t
β
−
−


=
+
=
−




 
 
1
tan (5/ 2)
1.1903
β
−
=
≈
     (1st quadrant angle) 
π
t
-0.5
0.5
xsp
x
 
13. 
p
cos10
sin10 ;
74
20
600,
20
74
0
x
A
t
B
t
A
B
A
B
=
+
−
+
=
+
=
 
 
sp
11100
3000
( )
cos10
sin10
1469
1469
x
t
t
t
= −
+
 
 
(
)
300
37
10
300
cos10
sin10
cos 10
1469
1469
1469
1469
t
t
t
α


=
−
+
=
−




 
 
1
tan (10/37)
2.9320
α
π
−
=
−
≈
     (2nd quadrant angle) 
 
(
)
1
2
sp
( )
cos5
sin5
( );
t
x t
e
c
t
c
t
x
t
−
=
+
+
 
 
1
1
2
11100/1469
10,
5
30000/1469
c
c
c
−
=
−
+
= −
 
 
(
)
tr( )
25790cos5
842sin5
1469
t
e
x
t
t
t
−
=
−
 
 
 

 
Section 5.6 
281 
 
2 166458266
12895
421
cos5
sin5
1469
166458266
166458266
t
e
t
t
−

=
−




 
 
(
)
113314
2
cos 5
1469
t
e
t
β
−
=
−
 
 
1
2
tan (421/12895)
6.2505
β
π
−
=
−
≈
     (4th quadrant angle) 
 
π
t
-10
10
xsp
x
 
 
 
14. 
p
cos
sin ;
24
8
200,
8
24
520
x
A
t
B
t
A
B
A
B
=
+
+
=
−
+
=
 
 
(
)
sp
1
22
( )
cos
22sin
485
cos
sin
485cos
485
485
x
t
t
t
t
t
t
α


=
+
=
+
=
−




 
 
1
tan (22)
1.5254
α
−
=
≈
     (1st quadrant angle) 
 
(
)
4
1
2
sp
( )
cos3
sin3
( );
t
x t
e
c
t
c
t
x
t
−
=
+
+
 
 
1
1
2
1
30,
4
3
22
10
c
c
c
+
= −
−
+
+
= −
 
 
(
)
4
tr( )
31cos3
52sin3
t
x
t
e
t
t
−
=
−
−
 
 
(
)
4
4
31
52
3665
cos3
sin3
3665
cos 3
3665
3665
t
t
e
t
t
e
t
β
−
−


=
−
−
=
−




 
 
1
tan (52/31)
4.1748
β
π
−
=
+
≈
     (3rd quadrant angle) 
 
The figure at the top of the next page shows the graphs of  
sp
( ) and
( ).
x t
x
t
 
 
 

282 
Chapter 5 
π
2 π
t
-30
30
xsp
x
 
 
In Problems 15–18 we substitute ( )
( )cos
( )sin
x t
A
t
B
t
ω
ω
ω
ω
=
+
 into the differential equation 
0 cos
mx
cx
kx
F
t
ω
′′
′
+
+
=
with the given numerical values of  
0
,
,
, and
.
m c k
F   We give first 
the equations in  A  and  B  that result upon collection of coefficients of  cos
and sin
,
t
t
ω
ω  and 
then the values of  
( ) and
( )
A
B
ω
ω  that we get by solving these equations.  Finally,  
2
2
C
A
B
=
+
gives the amplitude of the resulting forced oscillations as a function of the 
forcing frequency  
,
ω  and we show the graph of the function  
( ).
C ω
 
 
15. 
2
2
(2
)
2
2,
2
(2
)
0
A
B
A
B
ω
ω
ω
ω
−
+
=
−
+
−
=
 
 
(
)
2
4
4
2 2
4
,
4
4
A
B
ω
ω
ω
ω
−
=
=
+
+
 
 
 
4
( )
2/
4
C ω
ω
=
+
  begins with  C(0) = 1  and steadily decreases as  ω  increases.   
 
Hence there is no practical resonance frequency. 
5
10 ω
1
C
 

 
Section 5.6 
283 
16. 
2
2
(5
)
4
10,
4
(5
)
0
A
B
A
B
ω
ω
ω
ω
−
+
=
−
+
−
=
 
 
(
)
2
2
4
2
4
10 5
40
,
25
6
25
6
A
B
ω
ω
ω
ω
ω
ω
−
=
=
+
+
+
+
 
2
4
( )
10/
25
6
C ω
ω
ω
=
+
+
  begins with  C(0) = 2  and steadily decreases as  ω  
increases.  Hence there is no practical resonance frequency. 
5
10 ω
1
2
C
 
 
 
17. 
2
2
(45
)
6
50,
6
(45
)
0
A
B
A
B
ω
ω
ω
ω
−
+
=
−
+
−
=
 
 
(
)
2
2
4
2
4
50 45
300
,
2025
54
2025
54
A
B
ω
ω
ω
ω
ω
ω
−
=
=
−
+
−
+
 
 
2
4
( )
50/
2025
54
C ω
ω
ω
=
−
+
  so, to find its maximum value, we calculate the 
derivative 
 
 
 
 
2
2
4
3/ 2
100
( 27
)
( )
.
(2025
54
)
C
ω
ω
ω
ω
ω
−
−
+
′
=
−
+
 
 
 
Hence the practical resonance frequency (where the derivative vanishes) is  
27
3 3.
ω =
=
  The graph of  
( )
C ω  is shown at the top of the next page. 
 
18. 
2
2
(650
)
10
100,
10
(650
)
0
A
B
A
B
ω
ω
ω
ω
−
+
=
−
+
−
=
 
 
(
)
2
2
4
2
4
100 650
1000
,
422500
1200
422500
1200
A
B
ω
ω
ω
ω
ω
ω
−
=
=
−
+
−
+
 
 
2
4
( )
100/
422500
1200
C ω
ω
ω
=
−
+
  so, to find its maximum value,  
 

284 
Chapter 5 
10
20
ω
1
C
 
 
 
 
we calculate the derivative 
 
 
 
 
2
2
4 3/ 2
200
( 600
)
( )
.
(422500
1200
)
C
ω
ω
ω
ω
ω
−
−
+
′
=
−
+
 
 
 
Hence the practical resonance frequency (where the derivative vanishes) is   
600
10 6.
ω =
=
 
25
50
ω
0.4
C
 
 
 
19. 
m  =  100/32 slugs  and  k  =  1200 lb/ft, so the critical frequency is  
0
/
k m
ω
=
  
384
=
 rad/sec  
384 / 2
3.12
π
=
≈
 Hz. 
 
 
20. 
Let the machine have mass  m.  Then the force  F  =  mg  =  9.8m  (the machine's weight)  
 
causes a displacement of  x  =  0.5 cm  =  1/200 meters, so Hooke's law   

 
Section 5.6 
285 
 
 
 
 
 
,
that is,
(1/ 200)
F
kx
mg
k
=
=
 
 
 
gives the spring constant is  k  =  200mg  (N/m).  Hence the resonance frequency is 
 
 
 
/
200
200
9.8
44.27 rad /sec
7.05 Hz
k m
g
ω =
=
≈
×
≈
≈
, 
 
 
which is about 423 rpm (revolutions per minute). 
 
21. 
If  θ  is the angular displacement from the vertical, then the (essentially horizontal) 
displacement of the mass is  x  =  Lθ,  so twice its total energy  (KE + PE)  is 
 
 
 
m(x')2 + kx2 + 2mgh  =  mL2(θ')2 + kL2θ2 + 2mgL(1 - cos θ)  =  C. 
 
 
Differentiation, substitution of  θ  ≈  sin θ,  and simplification yields 
 
 
 
 
 
 
θ''+ (k/m + g/L)θ  =  0 
 
so      
 
 
 
 
 
0
/
/
.
k m
g L
ω
=
+
 
 
22. 
Let  x  denote the displacement of the mass from its equilibrium position,  v  =  x′  its 
velocity, and  ω  =  v/a  the angular velocity of the pulley.  Then conservation of energy 
yields 
 
 
 
 
mv2/2 + Iω2/2 + kx2/2 - mgx  =  C. 
 
 
When we differentiate both sides with respect to  t  and simplify the result, we get the 
differential equation 
 
 
 
 
 
(m + I/a2)x″ + kx  =  mg. 
 
 
Hence  
(
)
2
/
/
.
k
m
I a
ω =
+
 
 
23. 
(a) 
In  ft-lb-sec  units we have  m  =  1000  and  k  =  10000,  so  
0
10
ω =
 rad/sec   
 
≈  0.50 Hz. 
 
 
(b) 
We are given that  
2
/ 2.25
ω
π
=
≈  2.79 rad/sec,  and the equation   
 
mx'' + kx  =  F(t)  simplifies to 
 
 
 
 
 
2
10
(1/ 4)
sin
.
x
x
t
ω
ω
′′ +
=
 
 
 
When we substitute  x(t)  =  A sin ωt  we find that the amplitude is 
 
 
 
 
 
(
)
2
2
/ 4 10
0.8854 ft
10.63 in.
A
ω
ω
=
−
≈
≈
 

286 
Chapter 5 
 
24. 
By the identity of Problem 43 in Section 5.5, the differential equation is 
 
 
 
 
 
(
)
0 3cos
cos3
/ 4.
mx
kx
F
t
t
ω
ω
′′+
=
+
 
 
 
Hence resonance occurs when either  
or 3
ω
ω  equals  
0
/
k m
ω
=
,  that is, when 
either  
0
0
or
/3.
ω
ω
ω
ω
=
=
 
 
25. 
Substitution of the trial solution  
cos
sin
x
A
t
B
t
ω
ω
=
+
 in the differential equation, and 
then collection of coefficients as usual yields the equations 
 
 
 
(
)
(
)
(
)
(
)
2
2
0
0,
k
m
A
c
B
c
A
k
m
B
F
ω
ω
ω
ω
−
+
=
−
+
−
=
 
 
 
with coefficient determinant  
(
)
(
)
2
2
2
k
m
c
ω
ω
∆=
−
+
 and solution  
(
)
0 / ,
A
c
F
ω
= −
∆ 
(
)
2
0 / .
B
k
m
F
ω
=
−
∆  Hence 
 
 
 
(
)
2
0
( )
sin
cos
sin
,
F
k
m
c
x t
t
t
C
t
ω
ω
ω
ω
ω
α


−
=
−
=
−


∆
∆
∆


 
 
 
where  
(
)
2
0 /
and sin
/
, cos
/
.
C
F
c
k
m
α
ω
α
ω
=
∆
=
∆
=
−
∆ 
 
26. 
Let  
2
2
2
2
0
0
0
and
1/
(
)
(
) .
G
E
F
k
m
c
ρ
ω
ω
=
+
=
−
+
   Then 
 
 
 
 
[
]
0
0
0
0
0
0
0
0
0
( )
cos(
)
sin(
)
cos(
)
sin(
)
cos
cos(
)
sin
sin(
)
( )
cos(
)
sp
sp
x
t
E
t
F
t
E
F
G
t
t
G
G
G
t
t
x
t
G
t
ρ
ω
α
ρ
ω
α
ρ
ω
α
ω
α
ρ
β
ω
α
β
ω
α
ρ
ω
α
β
=
−
+
−


=
−
+
−




=
−
+
−
=
−
−
 
 
 
where  
0
0
tan
/
.
F
E
β =
  The desired formula now results when we substitute the value 
of  ρ  defined above. 
 
27. 
The derivative of  
(
)
(
)
2
2
2
0
( )
/
C
F
k
m
c
ω
ω
ω
=
−
+
  is given by 
 
 
 
 
(
)
(
)
2
2
0
3/ 2
2
2
2
(
2
)
2(
)
( )
.
2
F
c
km
m
C
k
m
c
ω
ω
ω
ω
ω
−
+
′
= −


−
+




 

 
Section 5.6 
287 
 
 
(a) 
Therefore, if  
2
2
,
c
km
≥
 it is clear from the numerator that  
( )
0
C ω
′
<
  for all  ω,  
so  C(ω)  steadily decreases as  ω  increases. 
 
(b) 
But if  
2
2
,
c
km
<
 then the numerator (and hence
( )
C ω
′
) vanishes when
 
2
2
0
/
/ 2
/
.
m
k m
c
m
k m
ω
ω
ω
=
=
−
<
=
  Calculation then shows that 
 
 
 
 
(
)
3
2
0
3/ 2
3
2
16
(
2
)
(
)
0,
4
m
F m c
km
C
c
km
c
ω
−
′′
=
<
−
 
 
 
so it follows from the second-derivative test that  
(
)
m
C ω
 is a local maximum value. 
 
28. 
(a) 
The given differential equation corresponds to Equation (17) with  
2
0
.
F
mAω
=
   
It therefore follows from Equation (21) that the amplitude of the steady periodic 
vibrations at frequency  ω  is 
 
2
0
2
2
2
2
2
2
( )
.
(
)
(
)
(
)
(
)
F
mA
C
k
m
c
k
m
c
ω
ω
ω
ω
ω
ω
=
=
−
+
−
+
 
 
 
(b) 
Now we calculate 
 
 
 
 
(
)
(
)
2
2
2
3/ 2
2
2
2
2
(2
)
( )
,
mA
k
mk
c
C
k
m
c
ω
ω
ω
ω
ω


−
−


′
=


−
+




 
 
 
and we see that the numerator vanishes when 
 
 
 
 
2
0
2
2
2
2
.
2
2
k
k
mk
k
mk
c
m
mk
c
m
ω
ω


=
=
>
=


−
−


 
 
29. 
We need only substitute  
0
0
and
E
ac
F
ak
ω
=
=
 in the result of Problem 26. 
 
30. 
When we substitute the values  
4
2
/ ,
800,
7 10 ,
3000
v L m
k
c
ω
π
=
=
=
×
=
 and 
 
10,
0.05
L
a
=
=
in the formula of Problem 29, simplify, and square, we get the function 
 
 
 
(
)
(
)
2
2
2
4
4
2
2
25 9
122500
( )
16 16
64375
76562500
v
Csq v
v
v
π
π
π
+
=
−
+
 
 

288 
Chapter 5 
giving the square of the amplitude  C  (in meters) as a function of the velocity  v  (in 
meters per second).  Differentiation gives 
 
 
2
4
4
2
2
4
4
2
2
2
50
(9
245000
535937500)
( )
.
(16
64375
76562500)
v
v
v
Csq v
v
v
π
π
π
π
π
+
−
′
= −
−
−
 
 
Because the principal factor in the numerator is a quadratic in  v2,  it is easy to solve the 
equation  
( )
0
Csq v
′
=
 to find where the maximum amplitude occurs; we find that the 
only positive solution is  
14.36 m/sec
32.12 mi/hr.
v ≈
≈
  The corresponding 
amplitude of the car's vibrations is  
(14.36)
0.1364 m = 13.64 cm.
Csq
≈
 
 
 
 
 

 
Section 6.1 
289 
 
 
CHAPTER 6 
  
EIGENVALUES AND EIGENVECTORS 
 
 
SECTION 6.1 
 
INTRODUCTION TO EIGENVALUES 
 
In each of Problems 1–32 we first list the characteristic polynomial  ( )
p λ
λ
=
−
A
I   of the given 
matrix  A, and then the roots of  ( )
p λ  — which are the eigenvalues of  A.  All of the eigenvalues 
that appear in Problems 1–26 are integers, so each characteristic polynomial factors readily.  For 
each eigenvalue  
j
λ  of the matrix  A,  we determine the associated eigenvector(s) by finding a basis 
for the solution space of the linear system  (
)
.
j
λ
−
=
A
I v
0   We write this linear system in scalar 
form in terms of the components of  
[
] .
T
a
b
=
v

  In most cases an associated eigenvector is 
then apparent.  If  A  is a 2 2
×  matrix, for instance, then our two scalar equations will be multiples 
one of the other, so we can substitute a convenient numerical value for the first component  a  of  v  
and then solve either equation for the second component  b  (or vice versa). 
 
1. 
Characteristic polynomial:  
2
( )
5
6
(
2)(
3)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
2,
3
λ
λ
=
=
 
 
With  
1
2:
λ =
 
2
2
0
0
a
b
a
b
−
=


−
=

  
1
1
1

= 

v
 
 
With  
2
3:
λ
=
 
  
2
0
2
0
a
b
a
b
−
=


−
=

  
2
2
1

= 

v
 
 
2. 
Characteristic polynomial:  
2
( )
2
(
1)(
2)
p λ
λ
λ
λ
λ
=
−
−
=
+
−
 
 
Eigenvalues: 
1
2
1,
2
λ
λ
= −
=
 
 
With  
1
1:
λ = −
 
6
6
0
3
3
0
a
b
a
b
−
=


−
=

  
1
1
1

= 

v
 
 
With  
2
2:
λ
=
 
3
6
0
3
6
0
a
b
a
b
−
=


−
=

  
2
2
1

= 

v
 
 

290 
Chapter 6 
3. 
Characteristic polynomial:  
2
( )
7
10
(
2)(
5)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
2,
5
λ
λ
=
=
 
 
With  
1
2:
λ =
 
6
6
0
3
3
0
a
b
a
b
−
=


−
=

  
1
1
1

= 

v
 
 
With  
2
5:
λ
=
 
3
6
0
3
6
0
a
b
a
b
−
=


−
=

  
2
2
1

= 

v
 
 
4. 
Characteristic polynomial:  
2
( )
3
2
(
1)(
2)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
2,
5
λ
λ
=
=
 
 
With  
1
1:
λ =
  
3
3
0
2
2
0
a
b
a
b
−
=


−
=

  
1
1
1

= 

v
 
 
With  
2
2:
λ
=
 
2
3
0
2
3
0
a
b
a
b
−
=


−
=

  
2
3
2

= 

v
 
 
5. 
Characteristic polynomial:  
2
( )
5
4
(
1)(
4)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
1,
4
λ
λ
=
=
 
 
With  
1
1:
λ =
  
9
9
0
6
6
0
a
b
a
b
−
=


−
=

  
1
1
1

= 

v
 
 
With  
2
4:
λ
=
 
6
9
0
6
9
0
a
b
a
b
−
=


−
=

  
2
3
2

= 

v
 
 
6. 
Characteristic polynomial:  
2
( )
5
6
(
2)(
3)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
1,
4
λ
λ
=
=
 
 
With  
1
2:
λ =
 
4
4
0
3
3
0
a
b
a
b
−
=


−
=

  
1
1
1

= 

v
 
 
With  
2
3:
λ
=
 
3
4
0
3
4
0
a
b
a
b
−
=


−
=

  
2
4
3

= 

v
 
 
7. 
Characteristic polynomial:  
2
( )
6
8
(
2)(
4)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
2,
4
λ
λ
=
=
 

 
Section 6.1 
291 
 
 
With  
1
2:
λ =
 
8
8
0
6
6
0
a
b
a
b
−
=


−
=

  
1
1
1

= 

v
 
 
With  
2
4:
λ
=
 
6
8
0
6
8
0
a
b
a
b
−
=


−
=

  
2
4
3

= 

v
 
 
8. 
Characteristic polynomial:  
2
( )
3
2
(
2)(
1)
p λ
λ
λ
λ
λ
=
+
+
=
+
+
 
 
Eigenvalues: 
1
2
2,
1
λ
λ
= −
= − 
 
With  
1
2:
λ = −
 
9
6
0
12
8
0
a
b
a
b
−
=


−
=

 
1
2
3

= 

v
 
 
With  
2
1:
λ
= −
 
8
6
0
12
9
0
a
b
a
b
−
=


−
=

 
2
3
4

= 

v
 
 
9. 
Characteristic polynomial:  
2
( )
7
12
(
3)(
4)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
3,
4
λ
λ
=
=
 
 
With  
1
3:
λ =
  
5
10
0
2
4
0
a
b
a
b
−
=


−
=

 
1
2
1

= 

v
 
 
With  
2
4:
λ
=
 
4
10
0
2
5
0
a
b
a
b
−
=


−
=

 
2
5
2

= 

v
 
 
10. 
Characteristic polynomial:  
2
( )
9
20
(
4)(
5)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
4,
5
λ
λ
=
=
 
 
With  
1
4:
λ =
 
5
10
0
2
4
0
a
b
a
b
−
=


−
=

 
1
2
1

= 

v
 
 
With  
2
5:
λ
=
 
4
10
0
2
5
0
a
b
a
b
−
=


−
=

 
2
5
2

= 

v
 
 
11. 
Characteristic polynomial:  
2
( )
9
20
(
4)(
5)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
4,
5
λ
λ
=
=
 
 
With  
1
4:
λ =
 
15
10
0
21
14
0
a
b
a
b
−
=


−
=

 
1
2
3

= 

v
 
 
With  
2
5:
λ
=
 
14
10
0
21
15
0
a
b
a
b
−
=


−
=

 
2
5
7

= 

v
 

292 
Chapter 6 
 
12. 
Characteristic polynomial:  
2
( )
7
212
(
3)(
4)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
3,
4
λ
λ
=
=
 
 
With  
1
3:
λ =
  
10
15
0
6
9
0
a
b
a
b
−
=


−
=

 
1
3
2

= 

v
 
 
With  
2
4:
λ
=
 
9
15
0
6
10
0
a
b
a
b
−
=


−
=

 
2
5
3

= 

v
 
 
13. 
Characteristic polynomial:  
3
2
( )
3
2
(
1)(
2)
p λ
λ
λ
λ
λ λ
λ
= −
+
−
= −
−
−
 
 
Eigenvalues: 
1
2
3
0,
1,
2
λ
λ
λ
=
=
=
 
 
With  
1
0:
λ =
  
2
0
2
2
0
2
6
3
0
a
a
b
c
a
b
c
=


−
−
=


−
+
+
=

  
1
0
1
2




=
−






v
 
 
With  
2
1:
λ
=
  
0
2
3
0
2
6
2
0
a
a
b
c
a
b
c
=


−
−
=


−
+
+
=

  
2
0
1
3




=
−






v
 
 
With  
3
2:
λ
=
 
0
0
2
4
0
2
6
0
a
b
c
a
b
c
=


−
−
=


−
+
+
=

 
 
3
1
0
2


= 


v
 
 
14. 
Characteristic polynomial:  
3
2
( )
7
10
(
2)(
5)
p λ
λ
λ
λ
λ λ
λ
= −
+
−
= −
−
−
 
 
Eigenvalues: 
1
2
3
0,
2,
5
λ
λ
λ
=
=
=
 
 
With  
1
0:
λ =
  
5
0
4
4
2
0
2
12
6
0
a
a
b
c
a
b
c
=


−
−
=


−
+
+
=

  
1
0
1
2




=
−






v
 
 
With  
2
2:
λ
=
 
3
0
4
6
2
0
2
12
4
0
a
a
b
c
a
b
c
=


−
−
=


−
+
+
=

  
2
0
1
3




=
−






v
 
 
With  
3
5:
λ
=
 
0
0
4
9
2
0
2
12
0
a
b
c
a
b
c
=


−
−
=


−
+
+
=

  
3
1
0
2


= 


v
 
 

 
Section 6.1 
293 
 
15. 
Characteristic polynomial:  
3
2
( )
3
2
(
1)(
2)
p λ
λ
λ
λ
λ λ
λ
= −
+
−
= −
−
−
 
 
Eigenvalues: 
1
2
3
0,
1,
2
λ
λ
λ
=
=
=
 
 
With  
1
0:
λ =
  
2
2
0
2
2
0
2
2
3
0
a
b
a
b
c
a
b
c
−
=


−
−
=


−
+
+
=

  
1
1
1
0


= 


v
 
 
With  
2
1:
λ
=
  
2
0
2
3
0
2
2
2
0
a
b
a
b
c
a
b
c
−
=


−
−
=


−
+
+
=

  
2
2
1
1


= 


v
 
 
With  
3
2:
λ
=
 
2
0
2
4
0
2
2
0
b
a
b
c
a
b
c
−
=


−
−
=


−
+
+
=

 
 
3
1
0
2


= 


v
 
 
16. 
Characteristic polynomial:  
3
2
( )
4
3
(
1)(
3)
p λ
λ
λ
λ
λ λ
λ
= −
+
−
= −
−
−
 
 
Eigenvalues: 
1
2
3
0,
1,
3
λ
λ
λ
=
=
=
 
 
With  
1
0:
λ =
  
0
2
3
0
6
6
0
a
c
a
b
c
a
b
−
=


−
+
−
=


−
+
=

 
 
1
1
1
1


= 


v
 
 
With  
2
1:
λ
=
  
0
2
2
0
6
6
0
c
a
b
c
a
b
c
−
=


−
+
−
=


−
+
−
=

 
 
2
1
1
0


= 


v
 
 
With  
3
3:
λ
=
 
2
0
2
0
6
6
3
0
a
c
a
c
a
b
c
−
−
=


−
−
=


−
+
−
=

  
3
1
0
2
−




= 





v
 
 
17. 
Characteristic polynomial:  
3
2
( )
6
11
6
(
1)(
2)(
3)
p λ
λ
λ
λ
λ
λ
λ
= −
+
−
+
= −
−
−
−
 
 
Eigenvalues: 
1
2
3
1,
2,
3
λ
λ
λ
=
=
=
 
 
With  
1
1:
λ =
  
2
5
2
0
0
2
0
a
b
c
b
b
+
−
=


=


=

 
 
1
1
0
1


= 


v
 

294 
Chapter 6 
 
With  
2
2:
λ
=
 
5
2
0
0
0
2
0
a
b
c
b
c
+
−
=


=


−
=

 
 
2
1
1
2
−




= 





v
 
 
With  
3
3:
λ
=
 
5
2
0
0
2
2
0
b
c
b
b
c
−
=


−
=


−
=

  
 
3
1
0
0


= 


v
 
 
18. 
Characteristic polynomial:  
3
2
( )
6
11
6
(
1)(
2)(
3)
p λ
λ
λ
λ
λ
λ
λ
= −
+
−
+
= −
−
−
−
 
 
Eigenvalues: 
1
2
3
1,
2,
3
λ
λ
λ
=
=
=
 
 
With  
1
1:
λ =
  
0
0
6
7
2
0
12
15
4
0
a
b
c
a
b
c
=


−
+
+
=


−
−
=

  
1
1
0
3


= 


v
 
 
With  
2
2:
λ
=
 
0
6
6
2
0
12
15
5
0
a
a
b
c
a
b
c
−
=


−
+
+
=


−
−
=

  
2
0
1
3




=
−






v
 
 
With  
3
3:
λ
=
 
2
0
6
5
2
0
12
15
6
0
a
a
b
c
a
b
c
−
=


−
+
+
=


−
−
=

  
3
0
2
5




=
−






v
 
 
19. 
Characteristic polynomial:  
3
2
2
( )
5
7
3
(
1) (
3)
p λ
λ
λ
λ
λ
λ
= −
+
−
+
= −
−
−
 
 
Eigenvalues: 
1
2
3
1,
3
λ
λ
λ
=
=
=
 
 
With  
1
1:
λ =
  
2
6
2
0
0
0
0
0
a
b
c
+
−
=


=


=

 
 
1
1
0
1


= 


v
, 
2
3
1
0
−




= 





v
 
 
The eigenspace of  
1
1
λ =
 is 2-dimensional.  We get the eigenvector  v1  with  
0,
1,
b
c
=
=
 
 and the eigenvector  v2  with  
1,
0.
b
c
=
=
 
 
With  
3
3:
λ
=
 
6
2
0
2
0
2
0
b
c
b
c
−
=


−
=


−
=

  
 
3
1
0
0


= 


v
 
 
20. 
Characteristic polynomial:  
3
2
2
( )
4
5
2
(
1) (
2)
p λ
λ
λ
λ
λ
λ
= −
+
−
+
= −
−
−
 
 
Eigenvalues: 
1
2
3
1,
2
λ
λ
λ
=
=
=
 

 
Section 6.1 
295 
 
 
 
With  
1
1:
λ =
  
0
0
4
6
2
0
10
15
5
0
a
b
c
a
b
c
=


−
+
+
=


−
−
=

  
1
1
0
2


= 


v
, 
2
3
2
0


= 


v
 
 
The eigenspace of  
1
1
λ =
 is 2-dimensional.  We get the eigenvector  v1  with   
0,
2,
b
c
=
=
  and the eigenvector  v2  with  
2,
0.
b
c
=
=
 
 
With  
3
2:
λ
=
 
0
4
5
2
0
10
15
5
0
a
a
b
c
a
b
c
−
=


−
+
+
=


−
−
=

  
3
0
2
5




=
−






v
 
 
21. 
Characteristic polynomial:  
3
2
2
( )
5
8
4
(
1)(
2)
p λ
λ
λ
λ
λ
λ
= −
+
−
+
= −
−
−
 
 
Eigenvalues: 
1
2
3
1,
2
λ
λ
λ
=
=
=
 
 
With  
1
1:
λ =
  
3
3
0
2
2
0
0
a
b
c
a
b
c
c
−
+
=


−
+
=


=

 
 
1
1
1
0


= 


v
 
 
 
With  
2
2:
λ
=
 
2
3
0
2
3
0
0
0
a
b
c
a
b
c
−
+
=


−
+
=


=

 
 
2
3
2
0


= 


v
 
3
1
0
2
−




= 





v
 
 
The eigenspace of  
2
2
λ
=
 is 2-dimensional.  We get the eigenvector  v2  with   
2,
0,
b
c
=
=
  and the eigenvector  v3  with  
0,
2.
b
c
=
=
 
 
22. 
Characteristic polynomial:  
3
2
( )
3
2
(
1) (
2)
p λ
λ
λ
λ
λ
= −
+
+
= −
+
−
 
 
Eigenvalues: 
1
2
3
1,
2
λ
λ
λ
=
= −
=
 
 
With  
1
1:
λ = −
 
6
6
3
0
6
6
3
0
6
6
3
0
a
b
c
a
b
c
a
b
c
−
+
=


−
+
=


−
+
=

 
 
1
1
1
0


= 


v
, 
2
1
0
2
−




= 





v
 
 
The eigenspace of  
1
1
λ =
 is 2-dimensional.  We get the eigenvector  v1  with   
1,
0,
b
c
=
=
  and the eigenvector  v2  with  
0,
2.
b
c
=
=
 
 
With  
3
2:
λ
=
 
3
6
3
0
6
9
3
0
6
6
0
a
b
c
a
b
c
a
b
−
+
=


−
+
=


−
=

 
 
3
1
1
1


= 


v
 

296 
Chapter 6 
23. 
Characteristic polynomial:  
( )
(
1)(
2)(
3)(
4)
p λ
λ
λ
λ
λ
=
−
−
−
−
 
 
Eigenvalues: 
1
2
3
4
1,
2,
3,
4
λ
λ
λ
λ
=
=
=
=
 
 
With  
1
1:
λ =
  
2
2
2
0
2
2
0
2
2
0
3
0
b
c
d
b
c
d
c
d
d
+
+
=


+
+
=

+
=


=

 
 
1
1
0
0
0



= 


v
 
 
With  
2
2:
λ
=
 
2
2
2
0
2
2
0
2
0
2
0
a
b
c
d
c
d
c
d
d
−+
+
+
=


+
=

+
=


=

 
2
2
1
0
0



= 


v
 
 
With  
3
3:
λ
=
 
2
2
2
2
0
2
2
0
2
0
0
a
b
c
d
b
c
d
d
d
−
+
+
+
=


+
+
=

=


=

 
3
3
2
1
0



= 


v
 
 
With  
4
4:
λ
=
 
3
2
2
2
0
2
2
2
0
2
0
0
0
a
b
c
d
b
c
d
c
d
−
+
+
+
=


−
+
+
=

−+
=


=

 
4
4
3
2
1



= 


v
 
 
24. 
Characteristic polynomial:  
2
2
( )
(
1) (
3)
p λ
λ
λ
=
−
−
 
 
Eigenvalues: 
1
2
3
4
1,
3
λ
λ
λ
λ
=
=
=
=
 
 
With  
1
1:
λ =
  
4
0
4
0
2
0
2
0
c
c
c
d
=


=

=


=

 
 
1
1
0
0
0



= 


v
, 
2
0
1
0
0



= 


v
 
 
The eigenspace of  
1
1
λ =
 is 2-dimensional.  We note that  c = d = 0,  but  a  and  b  are  
arbitrary. 
 
With  
3
3:
λ
=
 
2
4
0
2
4
0
0
0
0
0
a
c
b
c
−
+
=


−
+
=

=


=

 
3
0
0
0
1



= 


v
, 
4
2
2
1
0



= 


v
 
 
The eigenspace of  
3
3
λ
=
 is 2-dimensional.  We get the eigenvector  v3  with   
0,
1,
b
c
=
=
  and the eigenvector  v2  with  
1,
0.
b
c
=
=
 

 
Section 6.1 
297 
 
 
25. 
Characteristic polynomial:  
2
2
( )
(
1) (
2)
p λ
λ
λ
=
−
−
 
 
Eigenvalues: 
1
2
3
4
1,
2
λ
λ
λ
λ
=
=
=
=
 
 
With  
1
1:
λ =
  
0
0
0
0
c
c
c
d
=


=

=


=

 
 
1
1
0
0
0



= 


v
, 
2
0
1
0
0



= 


v
 
 
The eigenspace of  
1
1
λ =
 is 2-dimensional.  We note that  c = d = 0,  but  a  and  b  are  
arbitrary. 
 
With  
3
2:
λ
=
 
0
0
0
0
0
0
a
c
b
c
−+
=


−+
=

=


=

  
3
0
0
0
1



= 


v
, 
4
1
1
1
0



= 


v
 
 
The eigenspace of  
3
2
λ
=
 is 2-dimensional.  We get the eigenvector  v3  with   
0,
1,
b
c
=
=
  and the eigenvector  v4  with  
1,
0.
b
c
=
=
 
 
 
26. 
Characteristic polynomial:  
 
4
2
2
2
( )
5
4
(
1)(
4)
(
1)(
1)(
2)(
2)
p λ
λ
λ
λ
λ
λ
λ
λ
λ
=
−
+
=
−
−
=
+
−
+
−
 
 
Eigenvalues: 
1
2
3
4
2,
1,
1,
2
λ
λ
λ
λ
= −
= −
=
=
 
 
With  
1
2:
λ = −
 
6
3
0
4
0
0
6
3
0
a
d
b
c
a
d
−
=


=

=


−
=

  
1
1
0
0
2



= 


v
 
 
With  
2
1:
λ
= −
 
5
3
0
3
0
0
0
6
4
0
a
d
b
a
d
−
=


=

=


−
=

  
2
0
0
1
0



= 


v
 
 
With  
3
1:
λ
=
  
3
3
0
0
2
0
6
6
0
a
d
b
c
a
d
−
=


=

−
=


−
=

  
3
1
0
0
1



= 


v
 

298 
Chapter 6 
 
With  
4
2:
λ
=
 
2
3
0
0
0
3
0
6
7
0
a
d
c
a
d
−
=


=

−
=


−
=

  
4
0
1
0
0



= 


v
 
 
27. 
Characteristic polynomial:  
2
( )
1
p λ
λ
=
+  
 
Eigenvalues: 
1
2
,i
i
λ
λ
= −
= +  
 
With  
1
:i
λ = −
 
0
0
i a
b
a
ib
+
=


−+
=

  
1
1
i
= 

v
 
 
With  
2
:i
λ
= +
 
 
0
0
i a
b
a
ib
−
+
=


−−
=

  
2
1
i
−


= 



v
 
 
28. 
Characteristic polynomial:  
2
( )
36
p λ
λ
=
+
 
 
Eigenvalues: 
1
2
6 ,
6
i
i
λ
λ
= −
= +
 
 
With  
1
6 :i
λ = −
 
6
6
0
6
6
0
i a
b
a
ib
−
=


+
=

 
1
1
i
−


= 



v
 
 
With  
2
6 :i
λ
= +
 
 6
6
0
6
6
0
i a
b
a
ib
−
−
=


−
=

 
2
1
i
= 

v
 
 
29. 
Characteristic polynomial:  
2
( )
36
p λ
λ
=
+
 
 
Eigenvalues: 
1
2
6 ,
6
i
i
λ
λ
= −
= +
 
 
With  
1
6 :i
λ = −
 
6
3
0
12
6
0
i a
b
a
ib
−
=


+
=

 
1
2
i
−


= 



v
 
 
With  
2
6 :i
λ
= +
 
 6
3
0
12
6
0
i a
b
a
ib
−
−
=


−
=

 
2
2
i
= 

v
 
 
30. 
Characteristic polynomial:  
2
( )
144
p λ
λ
=
+
 
 
Eigenvalues: 
1
2
12 ,
12
i
i
λ
λ
= −
= +
 
 
With  
1
12 :i
λ = −
 
12
12
0
12
12
0
i a
b
a
ib
−
=


+
=

 
1
1
i
−


= 



v
 
 
With  
2
12 :i
λ
= +
 
 12
12
0
12
12
0
i a
b
a
ib
−
−
=


−
=

 
2
1
i
= 

v
 

 
Section 6.1 
299 
 
31. 
Characteristic polynomial:  
2
( )
144
p λ
λ
=
+
 
 
Eigenvalues: 
1
2
12 ,
12
i
i
λ
λ
= −
= +
 
 
With  
1
12 :i
λ = −
 
12
24
0
6
12
0
i a
b
a
ib
+
=


−
+
=

 
1
2
1
i


= 



v
 
 
With  
2
12 :i
λ
= +
 
 12
24
0
6
12
0
i a
b
a
ib
−
+
=


−
−
=

 
2
2
1
i
−


= 



v
 
 
32. 
Characteristic polynomial:  
2
( )
144
p λ
λ
=
+
 
 
Eigenvalues: 
1
2
12 ,
12
i
i
λ
λ
= −
= +
 
 
With  
1
12 :i
λ = −
 
12
4
0
36
12
0
i a
b
a
ib
−
−
=


+
=

 
1
3
i
−


= 



v
 
 
With  
2
12 :i
λ
= +
 
 12
4
0
36
12
0
i a
b
a
ib
−
−
=


−
=

 
2
3
i

= 

v
 
 
33. 
If  
λ
=
Av
v  and we assume that  
1
1
n
n
λ
−
−
=
A
v
v  — meaning that  
1
n
λ − is an eigenvalue 
of  
1
n−
A
 with associated eigenvector  v,  then multiplication by  A  yields 
 
 
 
1
1
1
1
.
n
n
n
n
n
n
λ
λ
λ
λ
λ
−
−
−
−
=
⋅
=
⋅
=
⋅
=
⋅
=
A v
A A
v
A
v
Av
v
v  
 
 
Thus  
n
λ  is an eigenvalue of the matrix  
n
A  with associated eigenvector  v. 
 
34. 
By the remark following Example 6, any eigenvalue of an invertible matrix is nonzero.  If  
0
λ ≠
 is an eigenvalue of the invertible matrix  A  with associated eigenvalue  v,  then 
 
 
 
 
 
1
1
1
1
,
,
.
λ
λ
λ
λ
−
−
−
−
=
=
⋅
=
⋅
=
Av
v
v
A
v
A v
A v
v
 
 
 
Thus  
1
λ − is an eigenvalue of  
1
−
A  with associated eigenvector  v. 
 
35. 
(a) 
Note first that  (
)
(
)
T
T
λ
λ
−
=
−
A
I
A
I   because  
.
T =
I
I   Since the determinant of a 
square matrix equals the determinant of its transpose, it follows that   
 
.
T
λ
λ
−
=
−
A
I
A
I  
Thus the matrices  A  and  AT  have the same characteristic polynomial, and therefore have  
the same eigenvalues. 

300 
Chapter 6 
(b) 
Consider the matrix   
1
0
1
1


= 



A
  with characteristic equation  
2
(
1)
0
λ −
=
 and the 
single eigenvalue  
1.
λ =
  Then  
0
0
1
0


−
= 



A
I
  and it follows that the only associated 
eigenvector is a multiple of  [
]
0
1
.
T   The transpose  
1
1
0
1
T


= 



A
 has the same 
characteristic equation and eigenvalue, but we see similarly that its only eigenvector is a 
multiple of  [
]
1
0
.
T   Thus  A  and  AT  have the same eigenvalue but different 
eigenvectors. 
 
36. 
If the n n
×  matrix  
ij
a


= 

A
  is either upper or lower triangular, then obviously its 
characteristic equation is 
 
 
 
 
(
)(
)
(
)
11
22
0.
nn
a
a
a
λ
λ
λ
−
−
⋅
⋅
−
=

 
 
 
This observation makes it clear that the eigenvalues of the matrix  A  are its diagonal 
elements  
11
22
,
,
,
.
nn
a
a
a

 
 
37. 
If  
1
1
1
0
( 1)n
n
n
nc
c
c
λ
λ
λ
λ
−
−
−
=
−
+
+
+
+
A
I

,  then substitution of  
0
λ =
 yields 
 
0
0
c
=
−
=
A
I
A   for the constant term in the characteristic polynomial. 
 
38. 
The characteristic polynomial of the 2 2
×  matrix  
a
b
c
d


= 



A
  is  
(
)(
)
0,
a
d
bc
λ
λ
−
−
−
=
  that is,  
2
(
)
(
)
0.
a
d
ad
bc
λ
λ
−
+
+
−
=
  Thus the coefficient of  
λ   in the characteristic equation is  (
)
trace
.
a
d
−
+
= −
A  
 
39. 
If the characteristic equation of the n n
×  matrix  A  with eigenvalues  
1
2
,
,
,
n
λ λ
λ

 (not 
necessarily distinct) is written in the factored form 
 
 
 
 
 
1
2
(
)(
)
(
)
0,
n
λ
λ
λ
λ
λ
λ
−
−
⋅
⋅
−
=

 
 
then it should be clear that upon multiplying out the factors the coefficient of  
1
n
λ − will be  
(
)
1
2
.
n
λ
λ
λ
−
+
+
+

  But according to Problem 38, this coefficient also equals  (trace
).
−
A   
Therefore  
1
2
11
22
trace
.
n
nn
a
a
a
λ
λ
λ
+
+
+
=
=
+
+
A


 
 
40. 
We find that  trace A = 12  and  det A = 60,  so the characteristic polynomial of the given 
matrix  A  is  
 
 
 
 
3
2
1
( )
12
60.
p
c
λ
λ
λ
λ
= −
+
+
+
 
 

 
Section 6.1 
301 
 
 
Substitution of  
1
λ =   and   
31
67
47
(1)
7
15
13
24
7
15
7
p
−
=
−
=
−
=
−
−
A
I
 
 
yields  
1
47,
c = −
 so the characteristic equation of  A  is (after multiplication by –1) 
 
 
 
 
 
3
2
12
47
60
0.
λ
λ
λ
−
+
−
=
 
 
 
Trying  
1,
2,
3
λ = ±
±
±  (all divisors of 60) in turn, we discover the eigenvalue  
1
3.
λ =
 
 
Then division of the cubic by  (
3)
λ −
 yields 
 
 
 
 
 
2
9
20
(
4)(
5),
λ
λ
λ
λ
−
+
=
−
−
 
 
so the other two eigenvalues are  
2
3
4 and
5.
λ
λ
=
=
  We proceed to find the eigenvectors  
associated with these three eigenvalues. 
 
 
With  
1
3:
λ =
  
 
29
67
47
0
3
0
7
17
13
0
2
0
7
15
9
0
0
0
a
b
c
a
c
a
b
c
b
c
a
b
c
−
+
=
−
=




−
+
=
→
−
=




−
+
−
=
=


      
1
3
2
1


= 


v
 
 
 
With  
2
4 :
λ
=
 
 
28
67
47
0
(5/ 7)
0
7
18
13
0
0
7
15
10
0
0
0
a
b
c
a
c
a
b
c
b
c
a
b
c
−
+
=
−
=




−
+
=
→
−
=




−
+
−
=
=


 
2
5
7
7


= 


v
 
 
 
With  
3
5:
λ
=
 
 
27
67
47
0
(1/ 2)
0
7
19
13
0
(1/ 2)
0
7
15
11
0
0
0
a
b
c
a
c
a
b
c
b
c
a
b
c
−
+
=
+
=




−
+
=
→
−
=




−
+
−
=
=


 
3
1
1
2
−




= 





v
 
 
 
41. 
We find that  trace A = 8  and  det A = –60,  so the characteristic polynomial of the given 
matrix  A  is  
 
 
 
 
4
3
2
2
1
( )
8
60.
p
c
c
λ
λ
λ
λ
λ
=
−
+
+
−
 
 
 
Substitution of  
1,
(1)
det(
)
24
p
λ =
=
−
= −
A
I
 and  
1,
( 1)
det(
)
72
p
λ = −
−
=
+
= −
A
I
   
yields the equations 

302 
Chapter 6 
 
 
 
2
1
2
1
43,
21
c
c
c
c
+
=
−
= −
 
 
that we solve readily for  
1
2
32,
11.
c
c
=
=
  Hence the characteristic equation of  A  is 
 
 
 
 
 
4
3
2
8
11
32
60
0.
λ
λ
λ
λ
−
+
+
−
=
 
Trying  
1,
2
λ = ±
±
  in turn, we discover the eigenvalues  
1
2
2 and
2.
λ
λ
= −
=
  Then  
division of the quartic by  
2
(
4)
λ −
 yields 
 
 
 
 
 
2
8
15
(
3)(
5),
λ
λ
λ
λ
−
+
=
−
−
 
 
so the other two eigenvalues are  
3
4
3 and
5.
λ
λ
=
=
  We proceed to find the eigenvectors  
associated with these four eigenvalues. 
 
With  
1
2:
λ = −
 
 
 
24
9
8
8
0
(1/ 2)
0
10
5
14
2
0
0
10
10
10
0
(1/ 2)
0
29
9
3
13
0
0
0
a
b
c
d
a
d
a
b
c
d
b
a
c
d
c
d
a
b
c
d
−
−
−
=
−
=




−
−
+
=
=


→


+
−
=
−
=




−
−
−
=
=


      
1
1
0
1
2



= 


v
 
 
With  
2
2:
λ
=
 
 
 
20
9
8
8
0
0
10
9
14
2
0
(4/3)
0
10
6
10
0
0
29
9
3
17
0
0
0
a
b
c
d
a
d
a
b
c
d
b
d
a
c
d
c
a
b
c
d
−
−
−
=
−
=




−
−
+
=
−
=


→


+
−
=
=




−
−
−
=
=


      
2
3
4
0
3



= 


v
 
 
With  
3
3:
λ
=
 
 
 
19
9
8
8
0
(3/ 4)
0
10
10
14
2
0
(1/ 4)
0
10
5
10
0
(1/ 2)
0
29
9
3
18
0
0
0
a
b
c
d
a
d
a
b
c
d
b
d
a
c
d
c
d
a
b
c
d
−
−
−
=
−
=




−
−
+
=
−
=


→


+
−
=
−
=




−
−
−
=
=


      
3
3
1
2
4



= 


v
 
 
With  
4
5:
λ
=
 
 
 
17
9
8
8
0
0
10
12
14
2
0
0
10
3
10
0
0
29
9
3
20
0
0
0
a
b
c
d
a
d
a
b
c
d
b
d
a
c
d
c
a
b
c
d
−
−
−
=
−
=




−
−
+
=
−
=


→


+
−
=
=




−
−
−
=
=


       
4
1
1
0
1



= 


v
 
 
 

 
Section 6.2 
303 
 
SECTION 6.2 
 
DIAGONALIZATION OF MATRICES 
 
In Problems 1–28 we first find the eigenvalues and associated eigenvectors of the given n n
×   
matrix  A.  If  A  has  n  linearly independent eigenvectors, then we can proceed to set up the desired 
diagonalizing matrix  
[
]
1
2
n
=
P
v
v
v

  and diagonal matrix  D  such that  P–1AP = D.  If 
you write the eigenvalues in a different order on the diagonal of  D,  then naturally the eigenvector 
columns of  P  must be rearranged in the same order. 
 
1. 
Characteristic polynomial:  
2
( )
4
3
(
1)(
3)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
1,
3
λ
λ
=
=
 
 
With  
1
1:
λ =
  
4
4
0
2
2
0
a
b
a
b
−
=


−
=

  
1
1
1

= 

v
 
 
With  
2
3:
λ
=
 
  2
4
0
2
4
0
a
b
a
b
−
=


−
=

 
2
2
1

= 

v
 
 
1
2
1
0
,
1
1
0
3




=
=








P
D
 
 
2. 
Characteristic polynomial:  
2
( )
2
(
2)
p λ
λ
λ
λ λ
=
−
=
−
 
 
Eigenvalues: 
1
2
0,
2
λ
λ
=
=
 
 
With  
1
0:
λ =
  
6
6
0
4
4
0
a
b
a
b
−
=


−
=

  
1
1
1

= 

v
 
 
With  
2
2:
λ
=
 
 4
6
0
4
6
0
a
b
a
b
−
=


−
=

  
2
3
2

= 

v
 
 
1
3
0
0
,
1
2
0
2




=
=








P
D
 
 
3. 
Characteristic polynomial:  
2
( )
5
6
(
2)(
3)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
2,
3
λ
λ
=
=
 
 
With  
1
2:
λ =
 
3
3
0
2
2
0
a
b
a
b
−
=


−
=

  
1
1
1

= 

v
 

304 
Chapter 6 
 
With  
2
3:
λ
=
 
 2
3
0
2
3
0
a
b
a
b
−
=


−
=

  
2
3
2

= 

v
 
 
1
3
2
0
,
1
2
0
3




=
=








P
D
 
 
4. 
Characteristic polynomial:  
2
( )
3
2
(
1)(
2)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
1,
2
λ
λ
=
=
 
 
With  
1
1:
λ =
  
4
4
0
3
3
0
a
b
a
b
−
=


−
=

  
1
1
1

= 

v
 
 
With  
2
2:
λ
=
 
 3
4
0
3
4
0
a
b
a
b
−
=


−
=

  
2
4
3

= 

v
 
 
1
4
1
0
,
1
3
0
2




=
=








P
D
 
 
5. 
Characteristic polynomial:  
2
( )
4
3
(
1)(
3)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
1,
3
λ
λ
=
=
 
 
With  
1
1:
λ =
  
8
8
0
6
6
0
a
b
a
b
−
=


−
=

  
1
1
1

= 

v
 
 
With  
2
3:
λ
=
 
 6
8
0
6
8
0
a
b
a
b
−
=


−
=

  
2
4
3

= 

v
 
 
1
4
1
0
,
1
3
0
3




=
=








P
D
 
 
6. 
Characteristic polynomial:  
2
( )
3
2
(
1)(
2)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
1,
2
λ
λ
=
=
 
 
With  
1
1:
λ =
  
9
6
0
12
8
0
a
b
a
b
−
=


−
=

 
 
1
2
3

= 

v
 
 
With  
2
2:
λ
=
 
 8
6
0
12
9
0
a
b
a
b
−
=


−
=

 
 
2
3
4

= 

v
 
 
2
3
1
0
,
3
4
0
2




=
=








P
D
 

 
Section 6.2 
305 
 
7. 
Characteristic polynomial:  
2
( )
3
2
(
1)(
2)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
1,
2
λ
λ
=
=
 
 
With  
1
1:
λ =
  
5
10
0
2
4
0
a
b
a
b
−
=


−
=

 
 
1
2
1

= 

v
 
 
With  
2
2:
λ
=
 
 4
10
0
2
5
0
a
b
a
b
−
=


−
=

 
 
2
5
2

= 

v
 
 
2
5
1
0
,
1
2
0
2




=
=








P
D
 
 
8. 
Characteristic polynomial:  
2
( )
3
2
(
1)(
2)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
1,
2
λ
λ
=
=
 
 
With  
1
1:
λ =
  
10
15
0
6
9
0
a
b
a
b
−
=


−
=

 
 
1
3
2

= 

v
 
 
With  
2
2:
λ
=
 
 9
15
0
6
10
0
a
b
a
b
−
=


−
=

 
 
2
5
3

= 

v
 
 
3
5
1
0
,
2
3
0
2




=
=








P
D
 
 
9. 
Characteristic polynomial:  
2
2
( )
2
1
(
1)
p λ
λ
λ
λ
=
−
+
=
−
 
 
Eigenvalues: 
1
2
1,
1
λ
λ
=
=
 
 
With  
1
1:
λ =
  
4
2
0
2
0
a
b
a
b
−
=


−
=

  
1
2
1

= 

v
 
 
Because the given matrix  A  has only the single eigenvector  v1,  it is not diagonalizable. 
 
10. 
Characteristic polynomial:  
2
2
( )
4
4
(
2)
p λ
λ
λ
λ
=
−
+
=
−
 
 
Eigenvalues: 
1
2
2,
2
λ
λ
=
=
 
 
With  
1
2:
λ =
 
0
0
a
b
a
b
−
=


−
=

 
 
1
1
1

= 

v
 
 
Because the given matrix  A  has only the single eigenvector  v1,  it is not diagonalizable. 
 
 

306 
Chapter 6 
11. 
Characteristic polynomial:  
2
2
( )
4
4
(
2)
p λ
λ
λ
λ
=
−
+
=
−
 
 
Eigenvalues: 
1
2
2,
2
λ
λ
=
=
 
 
With  
1
2:
λ =
 
3
0
9
3
0
a
b
a
b
+
=


−
−
=

 
1
1
3
−


= 



v
 
 
Because the given matrix  A  has only the single eigenvector  v1,  it is not diagonalizable. 
 
12. 
Characteristic polynomial:  
2
2
( )
2
1
(
1)
p λ
λ
λ
λ
=
+
+
=
+
 
 
Eigenvalues: 
1
2
1,
1
λ
λ
= −
= − 
 
With  
1
1:
λ = −
 
12
9
0
16
12
0
a
b
a
b
+
=


−
−
=

 
1
3
4
−


= 



v
 
 
Because the given matrix  A  has only the single eigenvector  v1,  it is not diagonalizable. 
 
13. 
Characteristic polynomial:  
3
2
2
( )
5
8
4
(
1)(
2)
p λ
λ
λ
λ
λ
λ
= −
+
−
+
= −
−
−
 
 
Eigenvalues: 
1
2
3
1,
2,
2
λ
λ
λ
=
=
=
 
 
With  
1
1:
λ =
  
3
0
0
0
b
b
c
=


=


=

 
 
1
1
0
0


= 


v
 
 
With  
2
2:
λ
=
 
3
0
0
0
0
0
b
a
−
=


=


=

  
2
3
0
3
0 ,
1
1
0




=
=






v
v
 
 
The eigenspace of  
2
2
λ
=
 is 2-dimensional.  We get the eigenvector  v2  with   
0,
1,
b
c
=
=
  and the eigenvector  v3  with  
1,
0.
b
c
=
=
 
 
1
0
3
1
0
0
0
0
1 ,
0
2
0
0
1
0
0
0
2








=
=












P
D
 
 
14. 
Characteristic polynomial:  
3
2
2
( )
(
1)
p λ
λ
λ
λ
λ
= −
+
= −
−
 
 
Eigenvalues: 
1
2
3
0,
0,
1
λ
λ
λ
=
=
=
 
 
With  
1
0:
λ =
  
2
2
0
2
2
0
2
2
0
a
b
c
a
b
c
a
b
c
−
+
=


−
+
=


−
+
=

 
1
2
1
1
0 ,
1
2
0
−






=
=









v
v
 

 
Section 6.2 
307 
 
 
The eigenspace of  
1
0
λ =
 is 2-dimensional.  We get the eigenvector  v  with   
0,
2,
b
c
=
=
  and the eigenvector  v2  with  
1,
0.
b
c
=
=
 
 
With  
3
1:
λ
=
  
2
0
2
3
0
2
2
0
a
b
c
a
b
c
a
b
−
+
=


−
+
=


−
=

 
3
1
1
1


= 


v
 
 
 
 
1
1
1
0
0
0
0
1
1 ,
0
0
0
2
0
1
0
0
1
−








=
=












P
D
 
 
15. 
Characteristic polynomial:  
3
2
2
( )
2
(
1)
p λ
λ
λ
λ
λ λ
= −
+
−
= −
−
 
 
Eigenvalues: 
1
2
3
0,
1,
1
λ
λ
λ
=
=
=
 
 
With  
1
0:
λ =
  
3
3
0
2
2
0
0
a
b
c
a
b
c
c
−
+
=


−
+
=


=

 
1
1
1
0


= 


v
 
 
With  
2
1:
λ
=
  
2
3
0
2
3
0
0
0
a
b
c
a
b
c
−
+
=


−
+
=


=

 
2
3
1
3
0 ,
2
2
0
−






=
=









v
v
 
 
The eigenspace of  
2
2
λ
=
 is 2-dimensional.  We get the eigenvector  v2  with   
0,
2,
b
c
=
=
  and the eigenvector  v3  with  
2,
0.
b
c
=
=
 
 
1
1
3
0
0
0
1
0
2 ,
0
1
0
0
2
0
0
0
1
−








=
=












P
D
 
 
16. 
Characteristic polynomial:  
3
2
2
( )
5
7
3
(
1) (
3)
p λ
λ
λ
λ
λ
λ
= −
+
−
+
= −
−
−
 
 
Eigenvalues: 
1
2
3
1,
1,
3
λ
λ
λ
=
=
=
 
 
With  
1
1:
λ =
  
2
2
0
0
0
4
4
0
a
b
a
b
−
=


=


−
=

  
1
2
0
1
0 ,
1
1
0




=
=






v
v
 
 
The eigenspace of  
1
1
λ =
 is 2-dimensional.  We get the eigenvector  v2  with   
0,
1,
b
c
=
=
  and the eigenvector  v3  with  
1,
0.
b
c
=
=
 

308 
Chapter 6 
 
With  
3
3:
λ
=
 
2
0
2
0
4
4
2
0
b
b
a
b
c
−
=


−
=


−
+
−
=

  
3
1
0
2
−




= 





v
 
 
0
1
1
1
0
0
0
1
0 ,
0
1
0
1
0
2
0
0
3
−








=
=












P
D
 
 
17. 
Characteristic polynomial:  
3
2
( )
2
2
(
1)(
1)(
2)
p λ
λ
λ
λ
λ
λ
λ
= −
+
+
−
= −
+
−
−
 
 
Eigenvalues: 
1
2
3
1,
1,
2
λ
λ
λ
= −
=
=
 
 
With  
1
1:
λ = −
 
8
8
3
0
6
6
3
0
2
2
3
0
a
b
c
a
b
c
a
b
c
−
+
=


−
+
=


−
+
=

 
 
1
1
1
0


= 


v
 
 
With  
2
1:
λ
=
  
6
8
3
0
6
8
3
0
2
2
0
a
b
c
a
b
c
a
b
c
−
+
=


−
+
=


−
+
=

 
 
2
1
0
2
−




= 





v
 
 
With  
3
2:
λ
=
 
5
8
3
0
6
9
3
0
2
2
0
a
b
c
a
b
c
a
b
−
+
=


−
+
=


−
=

 
 
3
1
1
1


= 


v
 
 
1
1 1
1
0
0
1
0
1 ,
0
1
0
0
2
1
0
0
2
−
−








=
=












P
D
 
 
 
18. 
Characteristic polynomial:  
3
2
( )
6
11
6
(
1)(
2)(
3)
p λ
λ
λ
λ
λ
λ
λ
= −
+
−
+
= −
−
−
−
 
 
Eigenvalues: 
1
2
3
1,
2,
3
λ
λ
λ
=
=
=
 
 
With  
1
1:
λ =
  
5
5
2
0
4
4
2
0
2
2
2
0
a
b
c
a
b
c
a
b
c
−
+
=


−
+
=


−
+
=

 
 
1
1
1
0


= 


v
 
 
With  
2
2:
λ
=
 
4
5
2
0
4
5
2
0
2
2
0
a
b
c
a
b
c
a
b
c
−
+
=


−
+
=


−
+
=

 
 
2
1
0
2
−




= 





v
 

 
Section 6.2 
309 
 
 
With  
3
3:
λ
=
 
3
5
2
0
4
6
2
0
2
2
0
a
b
c
a
b
c
a
b
−
+
=


−
+
=


−
=

 
 
3
1
1
1


= 


v
 
 
1
1 1
1
0
0
1
0
1 ,
0
2
0
0
2
1
0
0
3
−








=
=












P
D
 
 
19. 
Characteristic polynomial:  
3
2
( )
6
11
6
(
1)(
2)(
3)
p λ
λ
λ
λ
λ
λ
λ
= −
+
−
+
= −
−
−
−
 
 
Eigenvalues: 
1
2
3
1,
2,
3
λ
λ
λ
=
=
=
 
 
With  
1
1:
λ =
  
0
2
3
0
4
4
0
b
c
a
b
c
a
b
−
=


−
+
−
=


−
+
=

 
 
1
1
1
1


= 


v
 
 
With  
2
2:
λ
=
 
0
2
2
0
4
4
0
a
b
c
a
b
c
a
b
c
−+
−
=


−
+
−
=


−
+
−
=

 
 
2
1
1
0


= 


v
 
 
With  
3
3:
λ
=
 
2
0
2
0
4
4
2
0
a
b
c
a
b
c
a
b
c
−
+
−
=


−
+
−
=


−
+
−
=

  
3
1
0
2
−




= 





v
 
 
1
1
1
1
0
0
1
1
0 ,
0
2
0
1
0
2
0
0
3
−








=
=












P
D
 
 
 
20. 
Characteristic polynomial:  
3
2
( )
13
52
60
(
2)(
5)(
6)
p λ
λ
λ
λ
λ
λ
λ
= −
+
−
+
= −
−
−
−
 
 
Eigenvalues: 
1
2
3
2,
5,
6
λ
λ
λ
=
=
=
 
 
With  
1
2:
λ =
 
0
0
6
9
2
0
6
15
2
0
a
b
c
a
b
c
=


−
+
+
=


−
−
=

  
1
1
0
3


= 


v
 
 
With  
2
5:
λ
=
 
3
0
6
6
2
0
6
15
5
0
a
a
b
c
a
b
c
−
=


−
+
+
=


−
−
=

  
2
0
1
3




=
−






v
 

310 
Chapter 6 
 
With  
3
6:
λ
=
 
4
0
6
5
2
0
6
15
6
0
a
a
b
c
a
b
c
−
=


−
+
+
=


−
−
=

  
3
0
2
5




=
−






v
 
 
1
0
0
2
0
0
0
1
2 ,
0
5
0
3
3
5
0
0
6








=
−
−
=












P
D
 
 
21. 
Characteristic polynomial:  
3
2
3
( )
3
3
1
(
1)
p λ
λ
λ
λ
λ
= −
+
−
+
= −
−
 
 
Eigenvalues: 
1
2
3
1,
1,
1
λ
λ
λ
=
=
=
 
 
With  
1
1:
λ =
  
0
0
0
b
a
b
a
b
a
−
=


−
=


−
=

 
 
1
2
0
1
0 ,
1
1
0




=
=






v
v
 
 
The eigenspace of  
1
1
λ =
 is 2-dimensional.  We get the eigenvector  v1  with   
0,
1,
b
c
=
=
  and the eigenvector  v2  with  
1,
0.
b
c
=
=
  Because the given matrix  A  has 
only two linearly independent eigenvectors, it is not diagonalizable. 
 
22. 
Characteristic polynomial:  
3
2
3
( )
3
3
1
(
1)
p λ
λ
λ
λ
λ
= −
+
−
+
= −
−
 
 
Eigenvalues: 
1
2
3
1,
1,
1
λ
λ
λ
=
=
=
 
 
With  
1
1:
λ =
  
2
0
0
5
7
2
0
a
b
c
a
b
a
b
c
−
+
=


−+
=


−
+
−
=

  
1
1
1
1


= 


v
 
The eigenspace of  
1
1
λ =
 is 1-dimensional.  Because the given matrix  A  has only one 
eigenvector, it is not diagonalizable. 
 
23. 
Characteristic polynomial:  
3
2
2
( )
4
5
2
(
1) (
2)
p λ
λ
λ
λ
λ
λ
= −
+
−
+
= −
−
−
 
 
Eigenvalues: 
1
2
3
1,
1,
2
λ
λ
λ
=
=
=
 
 
With  
1
1:
λ =
  
3
4
0
3
4
0
0
a
b
c
a
b
c
a
b
−
+
−
=


−
+
−
=


−+
=

 
 
1
1
1
1


= 


v
 

 
Section 6.2 
311 
 
 
With  
3
2:
λ
=
 
4
4
0
3
3
0
0
a
b
c
a
b
c
a
b
c
−
+
−
=


−
+
−
=


−+
−
=

 
 
2
1
1
0


= 


v
 
The given matrix  A  has only the two linearly independent eigenvectors  v1  and  v2,  and 
therefore is not diagonalizable. 
 
 
24. 
Characteristic polynomial:  
3
2
2
( )
5
8
4
(
1)(
2)
p λ
λ
λ
λ
λ
λ
= −
+
−
+
= −
−
−
 
 
Eigenvalues: 
1
2
3
1,
2,
2
λ
λ
λ
=
=
=
 
 
With  
1
1:
λ =
  
2
2
0
0
0
a
b
c
a
b
c
a
b
c
−
+
=


−
+
=


−+
+
=

 
 
1
1
1
0


= 


v
 
 
With  
2
2:
λ
=
 
2
0
2
0
0
a
b
c
a
b
c
a
b
−
+
=


−
+
=


−+
=

 
 
2
1
1
1


= 


v
 
The given matrix  A  has only the two linearly independent eigenvectors  v1  and  v2,  and 
therefore is not diagonalizable. 
 
 
25. 
Characteristic polynomial:  
2
2
( )
(
1) (
1)
p λ
λ
λ
=
+
−
 
 
Eigenvalues: 
1
2
3
4
1,
1,
1,
1
λ
λ
λ
λ
= −
= −
=
=
 
 
With  
1
1:
λ = −
 
2
2
0
2
2
0
0
0
0
0
a
c
b
c
−
=


−
=

=


=

  
1
2
0
1
0
1
,
0
1
1
0






=
=






v
v
 
 
The eigenspace of  
1
1
λ = − is 2-dimensional.  We get the eigenvector  v1  with   
0,
1,
c
d
=
=
  and the eigenvector  v2  with  
1,
0.
c
d
=
=
   
 
With  
3
1:
λ
=
  
2
0
2
0
2
0
2
0
c
c
c
d
−
=


−
=

−
=


−
=

 
 
3
4
0
1
1
0
,
0
0
0
0






=
=






v
v
 
 
The eigenspace of  
3
1
λ
=
 is also 2-dimensional.  We get the eigenvector  v3  with   
0,
1,
a
b
=
=
  and the eigenvector  v4  with  
1,
0.
a
b
=
=
   

312 
Chapter 6 
 
0
1
0
1
1
0
0
0
0
1
1
0
0
1
0
0
,
0
1
0
0
0
0
1
0
1
0
0
0
0
0
0
1
−








−




=
=












P
D
 
 
 
26. 
Characteristic polynomial:  
3
( )
(
1) (
2)
p λ
λ
λ
=
−
−
 
 
Eigenvalues: 
1
2
3
4
1,
1,
1,
2
λ
λ
λ
λ
=
=
=
=
 
 
With  
1
1:
λ =
  
0
0
0
0
d
d
d
d
=


=

=


=

 
 
1
2
3
0
0
1
0
1
0
,
,
1
0
0
0
0
0









=
=
=









v
v
v
 
The eigenspace of  
1
1
λ =
 is 3-dimensional, and  we have taken advantage of the fact that 
 we can select  a, b, and c  independently.   
 
With  
4
2:
λ
=
  
0
0
0
0
0
d
a
d
b
d
c
−
=


−
=

−
=


=

 
 
4
1
1
1
1



= 


v
 
 
0
0
1
1
1
0
0
0
0
1
0
1
0
1
0
0
,
1
0
0
1
0
0
1
0
0
0
0
1
0
0
0
2












=
=












P
D
 
 
 
27. 
Characteristic polynomial:  
3
( )
(
1) (
2)
p λ
λ
λ
=
−
−
 
 
Eigenvalues: 
1
2
3
4
1,
1,
1,
2
λ
λ
λ
λ
=
=
=
=
 
 
With  
1
1:
λ =
  
0
0
0
0
b
c
d
d
=


=

=


=

 
 
1
1
0
0
0



= 


v
 
The eigenspace of  
1
1
λ =
 is 1-dimensional, with only a single associated eigenvector.   

 
Section 6.2 
313 
 
 
With  
4
2:
λ
=
  
0
0
0
0
0
b
a
c
b
d
c
−
=


−
=

−
=


=

 
 
4
1
1
1
1



= 


v
 
The given matrix  A  has only the two linearly independent eigenvectors  v1  and  v4,  and 
therefore is not diagonalizable. 
 
28. 
Characteristic polynomial:  
2
2
( )
(
1) (
2)
p λ
λ
λ
=
−
−
 
 
Eigenvalues: 
1
2
3
4
1,
1,
2,
2
λ
λ
λ
λ
=
=
=
=
 
 
With  
1
1:
λ =
  
0
0
0
0
b
d
c
d
c
d
d
+
=


+
=

+
=


=

 
 
1
1
0
0
0



= 


v
 
The eigenspace of  
1
1
λ =
 is 1-dimensional, with only a single associated eigenvector.   
 
With  
3
2:
λ
=
  
0
0
0
0
0
b
a
d
c
b
d
d
−
+
=


−
+
=

=


=

 
3
1
1
1
0



= 


v
 
The eigenspace of  
3
2
λ
=
 is also 1-dimensional, with only a single associated eigenvector.  
Thus the given matrix  A  has only the two linearly independent eigenvectors  v1  and  v4,  
and therefore is not diagonalizable. 
 
29. 
If  A  is similar to  B  and  B is similar to  C,  so  A = P–1BP  and  B = Q–1CQ,  then 
 
 
 
A  =  P–1(Q–1CQ)P  =  (P–1Q–1)C(QP)  =  (QP)–1C(QP)  =  R–1CR 
 
 
with  R = QP,  so  A  is similar to  C. 
 
30. 
If  A  is similar to  B  so  A = P–1BP  then 
 
 
 
1
1
1
1
1
1
1
1
1
1
1
1
(
)(
)(
)
(
)(
)
(
) (
)
(
) (
)
( ) ( )
( ) ( )
n
n
−
−
−
−
−
−
−
−
−
−
−
−
=
⋅
⋅
=
⋅
⋅
=
⋅
⋅
=
A
P BP P BP P BP
P BP P BP
P B PP
B PP
B
PP
B PP
BP
P B I B I B
I B I BP
P B P



 
 
 
so we see that  An  is similar to  Bn.   

314 
Chapter 6 
 
31. 
If  A  is similar to  B  so  A = P–1BP  then  A–1  =  (P–1BP)–1  =  P–1B–1P,  so  A–1  is similar 
to  B–1.  
 
32. 
If  A  is similar to  B  so  A = P–1BP,  then  
1
1
1
−
−
=
=
=
P
P
P P
I
  so 
 
 
 
1
1
1
1
(
)
.
λ
λ
λ
λ
λ
−
−
−
−
−
=
−
=
−
=
−
=
−
A
I
P
A
I P
P
A
I P
P AP
P IP
B
I
 
 
 
Thus  A  and  B  have the same characteristic polynomial. 
 
33. 
If  A  and  B  are similar with  A = P–1BP,  then   
 
1
1
1
.
−
−
−
=
=
=
=
A
P BP
P
B P
P
B P
B  
 
Moreover, by Problem 32 the two matrices have the same eigenvalues, and by Problem 39 
in Section 6.1, the trace of a square matrix with real eigenvalues is equal to the sum of those 
eigenvalues.  Therefore  trace A = (eigenvalue sum) = trace B. 
 
34. 
The characteristic equation of the 2 2
×  matrix  
a
b
c
d


= 



A
  is  
2
(
)
(
)
0,
a
d
ad
bc
λ
λ
−
+
+
−
=
  and the discriminant of this quadratic equation is 
 
 
 
 
2
2
(
)
4(
)
(
)
4
.
a
d
ad
bc
a
d
bc
∆=
+
−
−
=
−
+
 
 
 
(a) 
If  
0,
∆>
  then  A  has two distinct eigenvalues and hence has two linearly  
independent eigenvectors, and is therefore diagonalizable. 
(b) 
If  
0,
∆<
  then  A  has no (real) eigenvalues and hence no real eigenvectors, and  
therefore is not diagonalizable. 
(c) 
Finally, note that 
0
∆=
 for both 
 
 
 
1
0
1
1
and
,
0
1
0
1




=
=








I
A
 
but  A  has only the single eigenvalue  
1
λ =   and the single eigenvector  
[
]
1
0
,
T
=
v
 and is  
therefore not diagonalizable. 
 
35. 
Three eigenvectors associated with three distinct eigenvalues can be arranged in six different 
orders as the column vectors of the diagonalizing matrix  
[
]
1
2
3
.
T
=
P
v
v
v
 

 
Section 6.2 
315 
 
36. 
The fact that the matrices  A  and  B  have the same eigenvalues (with the same 
multiplicities) implies that they are both similar to the same diagonal matrix  D  having these 
eigenvalues as its diagonal elements.  But two matrices that are similar to a third matrix are 
(by Problem 29) similar to one another. 
 
37. 
If  A = PDP–1  with  P  the eigenvector matrix of  A  and  D  its diagonal matrix of 
eigenvalues, then  
2
1
1
1
1
2
1
(
)(
)
(
)
.
−
−
−
−
−
=
=
=
A
PDP
PDP
PD P P DP
PD P
  Thus the same 
(eigenvector) matrix  P  diagonalizes  A2,  but the resulting diagonal (eigenvalue) matrix  D2  
is the square of the one for  A.  The diagonal elements of  D2  are the eigenvalues of  A2  and 
the diagonal elements of  D  are the eigenvalues of  A,  so the former are the squares of the 
latter. 
 
38. 
If the n n
×  matrix  A  has n linearly independent eigenvectors associated with the single 
eigenvalue  λ,  then  A = PDP–1 with  D = λI,  so  
1
1
(
)
.
λ
λ
λ
−
−
=
=
=
=
A
P
I P
PP
I
D  
 
39. 
Let the n n
×  matrix  A  have  k ≤ n  distinct eigenvalues  
1
2
,
,
,
.
k
λ λ
λ

  Then the definition 
of algebraic multiplicity and the fact that all solutions of the nth degree polynomial equation   
0
λ
−
=
A
I
  are real imply that the sum of the multiplicities of the eigenvalues equals  n,   
 
 
 
 
1
2
.
k
p
p
p
n
+
+
+
=

 
 
Now Theorem 4 in this section implies that  A  is diagonalizable if and only if   
 
 
 
 
1
2
k
q
q
q
n
+
+
+
=

 
 
where  
iq  denotes the geometric multiplicity of  
(
1,2,
, ).
i
i
k
λ
=

 But, because  
i
i
p
q
≥
 for  
each  
1,2,
,
i
k
=

, the two equations displayed above can both be satisfied if and only if   
i
i
p
q
=
 for each  i.   
 
 
 
SECTION 6.3 
 
APPLICATIONS INVOLVING  
POWERS OF MATRICES 
 
In Problems 1–10 we first find the eigensystem of the given matrix  A  so as to determine its 
eigenvector matrix  P  and its diagonal eigenvalue matrix  D.  Then we calculate the matrix  
power  A5 = PD5P–1. 
 
1. 
Characteristic polynomial:  
2
( )
3
2
(
1)(
2)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
1,
2
λ
λ
=
=
 

316 
Chapter 6 
 
With  
1
1:
λ =
  
2
2
0
0
a
b
a
b
−
=


−
=

  
1
1
1

= 

v
 
 
With  
2
2:
λ
=
 
 
2
0
2
0
a
b
a
b
−
=


−
=

  
2
2
1

= 

v
 
 
1
5
1
2
1
0
1
2
,
,
1
1
0
2
1
1
1
2
1
0
1
2
63
62
1
1
0
32
1
1
31
30
−
−






=
=
=






−






−
−






=
=






−
−






P
D
P
A
 
 
2. 
Characteristic polynomial:  
2
( )
2
(
1)(
2)
p λ
λ
λ
λ
λ
=
−
−
=
+
−
 
 
Eigenvalues: 
1
2
1,
2
λ
λ
= −
=
 
 
With  
1
1:
λ = −
 
6
6
0
3
3
0
a
b
a
b
−
=


−
=

  
1
1
1

= 

v
 
 
With  
2
2:
λ
=
 
 3
6
0
3
6
0
a
b
a
b
−
=


−
=

  
2
2
1

= 

v
 
 
1
5
1
2
1
0
1
2
,
,
1
1
0
2
1
1
1
2
1
0
1
2
65
66
1
1
0
32
1
1
33
34
−
−
−






=
=
=






−






−
−
−






=
=






−
−






P
D
P
A
 
 
3. 
Characteristic polynomial:  
2
( )
2
(
2)
p λ
λ
λ
λ λ
=
−
=
−
 
 
Eigenvalues: 
1
2
0,
2
λ
λ
=
=
 
 
With  
1
0:
λ =
  
6
6
0
4
4
0
a
b
a
b
−
=


−
=

  
1
1
1

= 

v
 
 
With  
2
2:
λ
=
 
 4
6
0
4
6
0
a
b
a
b
−
=


−
=

 
2
3
2

= 

v
 
 
1
5
1
3
0
0
2
3
,
,
1
2
0
2
1
1
1
3
0
0
2
3
96
96
1
2
0
32
1
1
64
64
−
−






=
=
=






−






−
−






=
=






−
−






P
D
P
A
 
 

 
Section 6.3 
317 
 
4. 
Characteristic polynomial:  
2
( )
3
2
(
1)(
2)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
1,
2
λ
λ
=
=
 
 
With  
1
1:
λ =
  
3
3
0
2
2
0
a
b
a
b
−
=


−
=

  
1
1
1

= 

v
 
 
With  
2
2:
λ
=
 
 2
3
0
2
3
0
a
b
a
b
−
=


−
=

  
2
3
2

= 

v
 
 
1
1
3
1
0
2
3
,
,
1
2
0
2
1
1
−
−






=
=
=






−






P
D
P
 
 
5
1
3
1
0
2
3
94
93
1
2
0
32
1
1
62
61
−
−






=
=






−
−






A
 
 
 
5. 
Characteristic polynomial:  
2
( )
3
2
(
1)(
2)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
1,
2
λ
λ
=
=
 
 
With  
1
1:
λ =
  
4
4
0
3
3
0
a
b
a
b
−
=


−
=

  
1
1
1

= 

v
 
 
With  
2
2:
λ
=
 
  
3
4
0
3
4
0
a
b
a
b
−
=


−
=

  
2
4
3

= 

v
 
 
1
5
1
4
1
0
3
4
,
,
1
3
0
2
1
1
1
4
1
0
3
4
125
124
1
3
0
32
1
1
93
92
−
−






=
=
=






−






−
−






=
=






−
−






P
D
P
A
 
 
 
6. 
Characteristic polynomial:  
2
( )
3
2
(
1)(
2)
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
1,
2
λ
λ
=
=
 
 
With  
1
1:
λ =
  
5
10
0
2
4
0
a
b
a
b
−
=


−
=

 
1
2
1

= 

v
 
 
With  
2
2:
λ
=
 
 4
10
0
2
5
0
a
b
a
b
−
=


−
=

 
2
5
2

= 

v
 

318 
Chapter 6 
 
1
5
2
5
1
0
2
5
,
,
1
2
0
2
1
2
2
5
1
0
2
5
156
310
1
2
0
32
1
2
62
123
−
−






=
=
=






−






−
−






=
=






−
−






P
D
P
A
 
 
 
7. 
Characteristic polynomial:  
2
( )
(
1)(
2)
p λ
λ
λ
= −
−
−
 
 
Eigenvalues: 
1
2
3
1,
2,
2
λ
λ
λ
=
=
=
 
 
With  
1
1:
λ =
  
3
0
0
0
b
b
c
=


=


=

 
 
1
1
0
0


= 


v
 
 
With  
2
2:
λ
=
 
 
3
0
0
0
0
0
b
a
−
=


=


=

  
2
3
0
3
0 ,
1
1
0




=
=






v
v
 
 
 
1
5
1
0
3
1
0
0
1
3
0
0
0
1 ,
0
2
0 ,
0
0
1
0
1
0
0
0
2
0
1
0
1
0
3
1
0
0
1
3
0
1
93
0
0
0
1
0
32
0
0
0
1
0
32
0
0
1
0
0
0
32
0
1
0
0
0
32
−
−












=
=
=


















−












=
=


















P
D
P
A
 
 
 
8. 
Characteristic polynomial:  
3
2
2
( )
4
5
2
(
1) (
2)
p λ
λ
λ
λ
λ
λ
= −
+
−
+
= −
−
−
 
 
Eigenvalues: 
1
2
3
1,
1,
2
λ
λ
λ
=
=
=
 
 
With  
1
1:
λ =
  
2
0
0
0
2
0
c
b
c
b
−
=


=


−
=

  
1
2
0
1
1 ,
0
2
0




=
=






v
v
 
 
With  
3
2:
λ
=
 
 
2
0
0
2
0
a
b
c
b
b
−−
+
=


−
=


−
=

 
3
1
0
1


= 


v
 

 
Section 6.3 
319 
 
 
1
5
0
1
1
1
0
0
0
1
0
1
0
0 ,
0
1
0 ,
1
2
1
2
0
1
0
0
2
0
2
1
0
1
1
1
0
0
0
1
0
1
62
31
1
0
0
0
1
0
1
2
1
0
1
0
2
0
1
0
0
32
0
2
1
0
62
32
−












=
=
=
−












−






−












=
−
=












−
−






P
D
P
A
 
 
 
9. 
Characteristic polynomial:  
2
( )
(
1)(
2)
p λ
λ
λ
= −
−
−
 
 
Eigenvalues: 
1
2
3
1,
2,
2
λ
λ
λ
=
=
=
 
 
With  
1
1:
λ =
  
3
0
0
0
c
b
b
c
−
=


=


=

  
1
1
0
0


= 


v
 
 
With  
2
2:
λ
=
 
 
3
0
0
0
0
0
a
b
c
−−
+
=


=


=

 
2
3
1
3
0 ,
1
1
0
−






=
=









v
v
 
 
 
1
5
1
1
3
1
0
0
1
3
1
0
0
1
,
0
2
0 ,
0
0
1
0
1
0
0
0
2
0
1
0
1
1
3
1
0
0
1
3
1
1
93
31
0
0
1
0
32
0
0
0
1
0
32
0
0
1
0
0
0
32
0
1
0
0
0
32
−
−
−












=
=
=


















−
−
−












=
=


















P
D
P
A
 
 
 
10. 
Characteristic polynomial:  
2
( )
(
1)(
2)
p λ
λ
λ
= −
−
−
 
 
Eigenvalues: 
1
2
3
1,
2,
2
λ
λ
λ
=
=
=
 
 
With  
1
1:
λ =
  
3
3
0
2
2
0
0
a
b
c
a
b
c
c
−
+
=


−
+
=


=

 
 
1
1
1
0


= 


v
 
 
With  
2
2:
λ
=
 
 
2
3
0
2
3
0
0
0
a
b
c
a
b
c
−
+
=


−
+
=


=

 
2
3
1
3
0 ,
2
2
0
−






=
=









v
v
 

320 
Chapter 6 
 
1
5
1
1
3
1
0
0
4
6
2
1
1
0
2 ,
0
2
0 ,
0
0
1
2
0
2
0
0
0
2
2
2
1
1
1
3
1
0
0
4
6
2
94
93
31
1
1
0
2
0
32
0
0
0
1
62
61
31
2
0
2
0
0
0
32
2
2
1
0
0
32
−
−
−
−












=
=
=












−






−
−
−
−














=
=
−














−







P
D
P
A
 
 
 
11. 
Characteristic polynomial:  
3
( )
(
1)(
1)
p λ
λ
λ
λ λ
λ
= −
+
= −
+
−
 
 
Eigenvalues: 
1
2
3
1,
0,
1
λ
λ
λ
= −
=
=
 
 
With  
1
1:
λ = −
 
2
0
6
6
2
0
21
15
5
0
a
a
b
c
a
b
c
=


+
+
=


−
−
=

  
1
0
1
3




=
−






v
 
 
With  
2
0:
λ
=
 
 
0
6
5
2
0
21
15
6
0
a
a
b
c
a
b
c
=


+
+
=


−
−
=

  
2
0
2
5




=
−






v
 
 
With  
3
1:
λ
=
   
0
0
6
4
2
0
21
15
7
0
a
b
c
a
b
c
=


+
+
=


−
−
=

  
3
1
42
87
−




=
−






v
 
 
 
1
10
0
0
1
1
0
0
36
5
2
1
2
42 ,
0
0
0 ,
39
3
1
3
5
87
0
0
1
1
0
0
0
0
1
1
0
0
36
5
2
1
0
0
1
2
42
0
0
0
39
3
1
78
5
2
3
5
87
0
0
1
1
0
0
195
15
6
−
−
−
−












=
−
−
−
=
=
−
−












−






−
−












=
−
−
−
−
−
=
−
−












−
−






P
D
P
A
 
 
 
12. 
Characteristic polynomial:  
2
2
( )
(1
)(
1)
(
1)(
1)
p λ
λ λ
λ
λ
=
−
−
= −
+
−
 
 
Eigenvalues: 
1
2
3
1,
1,
1
λ
λ
λ
= −
=
=
 
 
With  
1
1:
λ = −
 
12
6
2
0
20
10
4
0
2
0
a
b
c
a
b
c
c
−
−
=


−
−
=


=

  
1
1
2
0


= 


v
 

 
Section 6.3 
321 
 
 
With  
2
1:
λ
=
   
10
6
2
0
20
12
4
0
0
0
a
b
c
a
b
c
−
−
=


−
−
=


=

  
2
3
1
3
0 ,
5
5
0




=
=






v
v
 
 
 
1
10
1
1
3
1
0
0
25
15
5
1
2
0
5 ,
0
1
0 ,
0
0
1
5
0
5
0
0
0
1
10
5
2
1
1
3
1
0
0
25
15
5
1
0
0
1
2
0
5
0
1
0
0
0
1
0
1
0
5
0
5
0
0
0
1
10
5
2
0
0
1
−
−
−












=
=
=












−
−






−














=
=














−
−







P
D
P
A
 
 
 
13. 
Characteristic polynomial:  
3
( )
(
1)(
1)
p λ
λ
λ
λ λ
λ
= −
+
= −
+
−
 
 
Eigenvalues: 
1
2
3
1,
0,
1
λ
λ
λ
= −
=
=
 
 
With  
1
1:
λ = −
 
2
0
2
0
4
4
2
0
a
b
c
a
b
c
a
b
c
−
+
=


−
+
=


−
+
=

 
 
1
1
0
2
−




= 





v
 
 
With  
2
0:
λ
=
 
 
0
2
2
0
4
4
0
a
b
c
a
b
c
a
b
c
−
+
=


−
+
=


−
+
=

 
 
2
1
1
0


= 


v
 
 
With  
3
1:
λ
=
   
0
2
3
0
4
4
0
b
c
a
b
c
a
b
−+
=


−
+
=


−
=

 
 
3
1
1
1


= 


v
 
 
 
1
10
1
1
1
1
0
0
1
1
0
0
1
1 ,
0
0
0 ,
2
3
1
2
0
1
0
0
1
2
2
1
1
1
1
1
0
0
1
1
0
3
3
1
0
1
1
0
0
0
2
3
1
2
2
1
2
0
1
0
0
1
2
2
1
0
0
1
−
−
−
−












=
=
=
−
−












−






−
−
−












=
−
−
=
−












−






P
D
P
A
 
 
 
14. 
Characteristic polynomial:  
3
( )
(
1)(
1)
p λ
λ
λ
λ λ
λ
= −
+
= −
+
−
 
 
Eigenvalues: 
1
2
3
1,
0,
1
λ
λ
λ
= −
=
=
 

322 
Chapter 6 
 
With  
1
1:
λ = −
 
6
5
3
0
2
0
4
4
2
0
a
b
c
a
b
c
a
b
c
−
−
=


−
−
=


−
−
=

 
 
1
1
0
2


= 


v
 
 
With  
2
0:
λ
=
 
 
5
5
3
0
2
2
0
4
4
3
0
a
b
c
a
b
c
a
b
c
−
−
=


−
−
=


−
−
=

 
 
2
1
1
0


= 


v
 
 
With  
3
1:
λ
=
   
4
5
3
0
2
3
0
4
4
4
0
a
b
c
a
b
c
a
b
c
−
−
=


−
−
=


−
−
=

 
 
3
2
1
1


= 


v
 
 
 
1
1
1
2
1
0
0
1
1
1
0
1
1 ,
0
0
0 ,
2
3
1
2
0
1
0
0
1
2
2
1
−
−
−












=
=
=
−






−
−












P
D
P
 
 
10
1
1
2
1
0
0
1
1
1
3
3
1
0
1
1
0
0
0
2
3
1
2
2
1
2
0
1
0
0
1
2
2
1
0
0
1
−
−
−












=
−
=
−
−






−
−












A
 
 
 
15. 
2
2
( )
3
2 so
3
2
0
p λ
λ
λ
=
−
+
−
+
=
A
A
I
 
 
(
)
2
3
2
4
3
2
1
5
4
1
0
13
12
3
2
3
2
3
2
0
1
9
8
13
12
5
4
29
28
3
2
3
2
9
8
3
2
21
20
29
28
13
12
61
60
3
2
3
2
21
20
9
8
45
44
5
4
1
0
1
1
3
3
3
2
0
1
2
2
−
−
−






=
−
=
−
=






−
−






−
−
−






=
−
=
−
=






−
−
−






−
−
−






=
−
=
−
=






−
−
−






−



=
−
+
=
−
+


−


A
A
I
A
A
A
A
A
A
A
A
I
2
4
1
3
5
2


−



=






−






 
 
16. 
2
2
( )
3
2 so
3
2
0
p λ
λ
λ
=
−
+
−
+
=
A
A
I
 
 
2
3
2
6
10
1
0
16
30
3
2
3
2
2
3
0
1
6
11
16
30
6
10
36
70
3
2
3
2
6
11
2
3
14
27
−
−






=
−
=
−
=






−
−






−
−
−






=
−
=
−
=






−
−
−






A
A
I
A
A
A
 

 
Section 6.3 
323 
 
 
(
)
4
3
2
1
36
70
16
30
76
150
3
2
3
2
14
27
6
11
30
59
6
10
1
0
3
10
1
1
1
3
3
2
3
0
1
2
6
2
2
2
−
−
−
−






=
−
=
−
=






−
−
−






−
−








=
−
+
=
−
+
=








−
−








A
A
A
A
A
I
 
 
 
17. 
3
2
3
2
( )
5
8
4 so
5
8
4
p λ
λ
λ
λ
= −
+
−
+
−
+
−
+
=
A
A
A
I
0  
 
2
3
2
4
3
2
1
9
0
1
21
0
0
4
0 ,
5
8
4
0
8
0
0
0
4
0
0
8
1
45
0
5
8
4
0
16
0
0
0
16








=
=
−
+
=
















=
−
+
= 





A
A
A
A
I
A
A
A
A
 
 
(
)
1
2
2
3
0
1
1
5
8
0
1
0
4
2 0
0
1
−
−




=
−
+
=






A
A
A
I
 
 
 
18. 
3
2
3
2
( )
4
5
2 so
4
5
2
p λ
λ
λ
λ
= −
+
−
+
−
+
−
+
=
A
A
A
I
0 
 
2
3
2
4
3
2
1
6
3
1
14
7
0
1
0 ,
4
5
2
0
1
0
0
6
4
0
14
8
1
30
15
4
5
2
0
1
0
0
30
16
−
−








=
=
−
+
=








−
−




−




=
−
+
= 



−


A
A
A
A
I
A
A
A
A
 
 
(
)
1
2
2
2
1
1
1
4
5
0
2
0
2
2 0
2
1
−
−




=
−
+
=






A
A
A
I
 
 
 
19. 
3
2
3
2
( )
5
8
4 so
5
8
4
p λ
λ
λ
λ
= −
+
−
+
−
+
−
+
=
A
A
A
I
0  
 
2
3
2
1
9
3
1
21
7
0
4
0 ,
5
8
4
0
8
0
0
0
4
0
0
8
−
−








=
=
−
+
=












A
A
A
A
I
 

324 
Chapter 6 
 
4
3
2
1
45
15
5
8
4
0
16
0
0
0
16
−




=
−
+
= 





A
A
A
A
 
 
(
)
1
2
2
3
1
1
1
5
8
0
1
0
4
2 0
0
1
−
−




=
−
+
=






A
A
A
I
 
 
 
20. 
3
2
3
2
( )
5
8
4 so
5
8
4
p λ
λ
λ
λ
= −
+
−
+
−
+
−
+
=
A
A
A
I
0  
 
2
3
2
4
3
2
10
9
3
22
21
7
6
5
3 ,
5
8
4
14
13
7
0
0
4
0
0
8
46
45
15
5
8
4
30
29
15
0
0
16
−
−








=
−
=
−
+
=
−












−




=
−
+
=
−






A
A
A
A
I
A
A
A
A
 
 
(
)
1
2
1
3
1
1
1
5
8
2
4
1
4
2
0
0
1
−
−
−




=
−
+
=
−
−






A
A
A
I
 
 
 
21. 
3
3
( )
so
p λ
λ
λ
= −
+
−
+
=
A
A
0 
 
2
3
4
2
1
0
0
1
0
0
78
5
2 ,
6
5
2
195
15
6
21
15
6
1
0
0
78
5
2
195
15
6








=
−
−
=
=








−
−
−








=
=
−
−




−


A
A
A
A
A
 
 
Because  
0
λ =
 is an eigenvalue,  A  is singular and  A–1 does not exist. 
 
 
22. 
3
2
3
2
( )
1 so
p λ
λ
λ
λ
= −
+
+
−
−
+
+
−
=
A
A
A
I
0  
 
2
3
2
1
0
0
11
6
2
0
1
0
,
20
11
4
0
0
1
0
0
1
−
−








=
=
=
+
−
=
−
−
=












A
I
A
A
A
I
A  

 
Section 6.3 
325 
 
 
4
3
2
1
0
0
0
1
0
0
0
1




=
+
−
=
=






A
A
A
A
I 
 
1
2
11
6
2
20
11
4
0
0
1
−
−
−




= −
+
+
=
−
−
=






A
A
A
I
A  
 
23. 
3
3
( )
so
p λ
λ
λ
= −
+
−
+
=
A
A
0 
 
2
3
4
2
3
3
1
1
1 1
2
2
1 ,
2
2
1
0
0
1
4
4
1
3
3
1
2
2
1
0
0
1
−
−








=
−
=
=
−








−




−




=
=
−






A
A
A
A
A
 
 
Because  
0
λ =
 is an eigenvalue,  A  is singular and  A–1 does not exist. 
 
24. 
3
3
( )
so
p λ
λ
λ
= −
+
−
+
=
A
A
0 
 
2
3
4
2
3
3
1
5
5
3
2
2
1 ,
2
2
1
0
0
1
4
4
3
3
3
1
2
2
1
0
0
1
−
−
−
−








=
−
−
=
=
−
−








−
−




−
−




=
=
−
−






A
A
A
A
A
 
 
Because  
0
λ =
 is an eigenvalue,  A  is singular and  A–1 does not exist. 
 
 
In Problems 25–30 we first find the eigensystem of the given transition matrix  A  so as to 
determine its eigenvector matrix  P  and its diagonal eigenvalue matrix  D.  Then we determine how 
the matrix power  Ak = PDkP–1 behaves as  
.
k →∞  For simpler calculations of eigenvalues and 
eigenvectors, we write the entries of  A  in fractional rather than decimal form. 
 
25. 
Characteristic polynomial:  
2
9
4
1
( )
(
1)(5
4)
5
5
5
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
4
1,
5
λ
λ
=
=
 

326 
Chapter 6 
 
With  
1
1:
λ =
  
1
1
0
10
10
1
1
0
10
10
a
b
a
b

−
+
=


−
=

 
 
1
1
1

= 

v
 
 
With  
2
4 :
5
λ
=
 
 
1
1
0
10
10
1
1
0
10
10
a
b
a
b

+
=


+
=

 
 
2
1
1
−


= 



v
 
 
(
)
1
0
0
0
0
0
0
0
1
1
1
0
1
1
1
,
,
1
1
0
4/5
1 1
2
1
1
1
0
1
1
1
1
1
0
4/5
1 1
2
1
1
1
0
1
1
1 1
1/ 2
1
1
1
1
0
0
1 1
1 1
1/ 2
2
2
k
k
k
C
C
S
S
−
−






=
=
=






−






−





=
= 




−





−











→
=
=
+











−











P
D
P
x
A x
x
x
 
 
 
as  
.
k →∞  Thus the long-term distribution of population is 50% city, 50% suburban. 
 
 
26. 
Characteristic polynomial:  
2
9
4
1
( )
(
1)(5
4)
5
5
5
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
4
1,
5
λ
λ
=
=
 
 
With  
1
1:
λ =
  
3
1
0
20
20
3
1
0
20
20
a
b
a
b

−
+
=


−
=

  
1
1
3

= 

v
 
 
With  
2
4 :
5
λ
=
 
 
1
1
0
20
20
3
3
0
20
20
a
b
a
b

+
=


+
=

 
 
2
1
1
−


= 



v
 
 
(
)
1
0
0
0
0
0
0
0
1
1
1
0
1
1
1
,
,
3
1
0
4/ 5
3 1
4
1
1
1
0
1
1
1
3
1
0
4/ 5
3 1
4
1
1
1
0
1
1
1
1
1/ 4
1
1
3
1
0
0
3 1
3
3
3/ 4
4
4
k
k
k
C
C
S
S
−
−






=
=
=






−






−





=
= 




−





−











→
=
=
+











−











P
D
P
x
A x
x
x
 

 
Section 6.3 
327 
 
 
as  
.
k →∞  Thus the long-term distribution of population is 25% city, 75% suburban. 
 
27. 
Characteristic polynomial:  
2
8
3
1
( )
(
1)(5
3)
5
5
5
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
3
1,
5
λ
λ
=
=
 
 
With  
1
1:
λ =
  
1
3
0
4
20
1
3
0
4
20
a
b
a
b

−
+
=


−
=

 
 
1
3
5

= 

v
 
 
With  
2
3 :
5
λ
=
 
 
3
3
0
20
20
1
1
0
4
4
a
b
a
b

+
=


+
=

 
 
2
1
1
−


= 



v
 
 
1
3
1
1
0
1
1
1
,
,
5
1
0
3/5
5
3
8
−
−






=
=
=






−






P
D
P
 
 
0
0
3
1
1
0
1
1
1
5
1
0
3/5
5
3
8
k
k
k
−





=
= 




−





x
A x
x
 
 
(
)
0
0
0
0
0
3
1
1
0
1
1
3
3
3/8
1
1
5
1
0
0
5
3
5
5
5/8
8
8
C
C
S
S
−











→
=
=
+











−











x
 
 
 
as  
.
k →∞  Thus the long-term distribution of population is 3/8 city, 5/8 suburban. 
 
 
28. 
Characteristic polynomial:  
2
17
7
1
( )
(
1)(10
7)
10
10
10
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
7
1,
10
λ
λ
=
=
 
 
With  
1
1:
λ =
  
1
1
0
5
10
1
1
0
5
10
a
b
a
b

−
+
=


−
=

 
 
1
1
2

= 

v
 
 
With  
2
7 :
10
λ
=
 
 
1
1
0
10
10
1
1
0
5
5
a
b
a
b

+
=


+
=

 
 
2
1
1
−


= 



v
 

328 
Chapter 6 
 
(
)
1
0
0
0
0
0
0
0
1
1
1
0
1
1
1
,
,
2
1
0
7 /10
2
1
3
1
1
1
0
1
1
1
2
1
0
7 /10
2
1
3
1
1
1
0
1
1
1
1
1/3
1
1
2
1
0
0
2
1
2
2
2/3
3
3
k
k
k
C
C
S
S
−
−






=
=
=






−






−





=
= 




−





−











→
=
=
+











−











P
D
P
x
A x
x
x
 
 
 
as  
.
k →∞  Thus the long-term distribution of population is 1/3 city, 2/3 suburban. 
 
29. 
Characteristic polynomial:  
2
37
17
1
( )
(
1)(20
17)
20
20
20
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
17
1,
20
λ
λ
=
=
 
 
With  
1
1:
λ =
  
1
1
0
10
20
1
1
0
10
20
a
b
a
b

−
+
=


−
=

 
 
1
1
2

= 

v
 
 
With  
2
17 :
20
λ
=
 
 
1
1
0
20
20
1
1
0
10
10
a
b
a
b

+
=


+
=

 
 
2
1
1
−


= 



v
 
 
 
1
1
1
1
0
1
1
1
,
,
2
1
0
17/ 20
2
1
3
−
−






=
=
=






−






P
D
P
 
 
0
0
1
1
1
0
1
1
1
2
1
0
17 / 20
2
1
3
k
k
k
−





=
= 




−





x
A x
x
 
 
(
)
0
0
0
0
0
1
1
1
0
1
1
1
1
1/3
1
1
2
1
0
0
2
1
2
2
2/3
3
3
C
C
S
S
−











→
=
=
+











−











x
 
 
 
as  
.
k →∞  Thus the long-term distribution of population is 1/3 city, 2/3 suburban. 
 
 
30. 
Characteristic polynomial:  
2
33
13
1
( )
(
1)(20
13)
20
20
20
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
13
1,
20
λ
λ
=
=
 

 
Section 6.3 
329 
 
 
With  
1
1:
λ =
  
1
3
0
5
20
1
3
0
5
20
a
b
a
b

−
+
=


−
=

 
 
1
3
4

= 

v
 
 
With  
2
13 :
20
λ
=
 
 
3
3
0
20
20
1
1
0
5
5
a
b
a
b

+
=


+
=

 
 
2
1
1
−


= 



v
 
 
(
)
1
0
0
0
0
0
0
0
3
1
1
0
1
1
1
,
,
4
1
0
13/ 20
4
3
7
3
1
1
0
1
1
1
4
1
0
13/ 20
4
3
7
3
1
1
0
1
1
3
3
3/ 7
1
1
4
1
0
0
4
3
4
4
4/ 7
7
7
k
k
k
C
C
S
S
−
−






=
=
=






−






−





=
= 




−





−











→
=
=
+











−











P
D
P
x
A x
x
x
 
 
 
as  
.
k →∞  Thus the long-term distribution of population is 3/7 city, 4/7 suburban. 
 
 
In the following three problems, just as in Problems 25–30, we first write the elements of  A  in 
fractional rather than decimal form, with  r = 4/25 in Problem 31,  r = 7/40 in Problem 32, and 
r = 27/200 in Problem 33. 
 
31. 
Characteristic polynomial:  
2
9
4
1
( )
(
1)(5
4)
5
5
5
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
4
1,
5
λ
λ
=
=
 
With  
1
1:
λ =
  
2
1
0
5
2
4
1
0
25
5
a
b
a
b

−
+
=


−
+
=

 
 
1
5
4

= 

v
 
 
With  
2
4 :
5
λ
=
 
 
1
1
0
5
2
4
2
0
25
5
a
b
a
b

−
+
=


−
+
=

 
 
2
5
2

= 

v
 
 
1
5
5
1
0
2
5
1
,
,
4
2
0
4/5
4
5
10
−
−






=
=
=






−






P
D
P
 

330 
Chapter 6 
 
0
0
0
0
0
0
0
0
0
5
5
1
0
2
5
1
4
2
0
4/5
4
5
10
2.5
5
5
1
0
2
5
10
25
1
1
2
0.8
4
2
0
0
4
5
8
20
10
10
k
k
k
F
R
F
R
R
F
−





=
= 




−





−
−
−











→
=
=











−
−
−










x
A x
x
x
 
 
as  
.
k →∞  Thus the fox-rabbit population approaches a stable situation with  
0
0
2.5R
F
−
 
foxes and  
0
0
2
0.8
R
F
−
 rabbits. 
 
32. 
Characteristic polynomial:  
2
9
63
1
( )
(20
21)(4
3)
5
80
80
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
19
17
,
20
20
λ
λ
=
=
 
 
With  
1
21 :
20
λ =
 
9
1
0
20
2
27
3
0
200
20
a
b
a
b

−
+
=


−
+
=

  
1
10
9


= 



v
 
 
With  
2
3 :
4
λ
=
 
 
3
1
0
20
2
27
9
0
200
20
a
b
a
b

−
+
=


−
+
=

  
2
10
3


= 



v
 
 
1
0
0
10
10
21/ 20
0
3
10
1
,
,
9
3
0
3/ 4
9
10
60
10
10
21/ 20
0
3
10
1
9
3
0
3/ 4
9
10
60
k
k
k
−
−






=
=
=






−






−





=
= 




−





P
D
P
x
A x
x
 
 
(
)
(
)
0
0
0
0
0
10
10
1
0
3
10
30
100
1
21
1 1.05
9
3
0
0
9
10
27
90
60 20
60
10
1 1.05
(10
3
9
60
k
k
k
F
R
R
F
−
−










≈
=










−
−










=
−




x
 
when  k  is sufficiently large.  Thus the fox and rabbit populations are both increasing at 5% 
per year, with 10 foxes for each 9 rabbits. 
 
33. 
Characteristic polynomial:  
2
9
323
1
( )
(20
19)(20
17)
5
400
400
p λ
λ
λ
λ
λ
=
−
+
=
−
−
 
 
Eigenvalues: 
1
2
19
17
,
20
20
λ
λ
=
=
 

 
Section 6.3 
331 
 
 
With  
1
19 :
20
λ =
 
 
7
1
0
20
2
7
1
0
40
4
a
b
a
b

−
+
=


−
+
=

 
 
1
10
7


= 



v
 
 
With  
2
17 :
20
λ
=
 
 
1
1
0
4
2
7
0
40
20
a
b
a
b

−
+
=


−
+
=

7
  
2
2
1

= 

v
 
 
1
0
0
0
0
0
10
2
19/ 20
0
1
2
1
,
,
7
1
0
17 / 20
7
10
4
10
2
19/ 20
0
1
2
1
7
1
0
17 / 20
7
10
4
10
2
0
0
1
2
0
0
0
1
7
1
0
0
7
10
0
0
0
4
k
k
k
F
R
−
−






=
=
=






−






−





=
= 




−





−










→
=
=










−










P
D
P
x
A x
x
x
 
 
as  
.
k →∞  Thus the fox and rabbit population both die out. 
 
34. 
1
3
5
1
0
7
5
41
30
4
7
0
1
4
3
56
41
−
−
−






=
=
=






−
−
−






A
PDP
 
 
If  n  is even then  
n =
D
I   so  
1
1
.
n
n
−
−
=
=
=
A
PD P
PIP
I   If  n  is odd then 
 
1
.
n
n−
=
=
=
A
A
A
IA
A   Thus  
99
100
and
.
=
=
A
A
A
I  
 
35. 
The fact that each  
1, so
1,
λ
λ
=
= ±
 implies that  
n =
D
I  if  n  is even, in which case  
1
1
.
n
n
−
−
=
=
=
A
PD P
PIP
I  
 
36. 
We find immediately that  
2
3
2
4
3
2
, so
,
,
=
=
=
=
=
=
=
A
I
A
A A
IA
A A
A A
A
I  and so 
forth. 
 
37. 
We find immediately that  
2
3
2
4
3
2
, so
,
,
= −
=
= −
= −
=
= −
=
A
I
A
A A
IA
A A
A A
A
I  and 
so forth. 
 
38. 
If  
2
1
1
1
0
0
1
, then
,
1
0
0
1
0
0






=
=
+
=
+
=












A
I
B
B
0  so it follows that 

332 
Chapter 6 
 
1
1
2
1
2
1
(
)
(
1)
.
0
1
n
n
n
n
n
n
n
n n
n
−
−


=
+
=
+
+
−
+
=
+
= 



A
I
B
I
I
B
I
B
I
B

 
 
39. 
The characteristic equation of  A  is 
 
 
 
2
(
)(
)
(1
)(1
)
(
)
(
1)
(
1)[
(
1)],
p
q
p
q
p
q
p
q
p
q
λ
λ
λ
λ
λ
λ
−
−
=
−
−
=
−
+
+
+
−
=
−
−
+
−
 
 
 
so the eigenvalues of  A  are  
1
2
1 and
1.
p
q
λ
λ
=
=
+
−
 
 
40. 
The fact that the column sums of  A  are each 1 implies that the row sums of the transpose 
matrix  AT  are each 1, so it follows readily  that  ATv = v.  Thus  
1
λ =  is an eigenvalue of  
AT.  But  A  and  AT  have the same eigenvalues (by Problem 35 in Section 6.1). 

 
Section 7.1 
333 
 
CHAPTER 7 
 
LINEAR SYSTEMS OF  
DIFFERENTIAL EQUATIONS 
 
 
SECTION 7.1 
 
FIRST-ORDER SYSTEMS AND APPLICATIONS 
    
1. 
Let  
2
1
2
1
2
and
, so
7
3
.
x
x
x
x
x
x
x
x
x
t
′
′
′
′′
′
=
=
=
=
= −
−
+
   
Equivalent system: 
1x′   =  x2, 
2x′   =  -7x1 - 3x2 + t2 
   
2. 
Let  
1
2
1
3
2
4
3
,
,
,
, so
x
x
x
x
x
x
x
x
x
x
x
′
′
′
′′
′
′′′
=
=
=
=
=
=
=
(4)
4
3
6
cos3 .
x
x
x
x
x
t
′
′
′′
=
=
+
−
+
  
Equivalent system: 
1x′   =  x2,         
2x′   =  x3,         
3x′   =  x4,  
4x′   =  -x1 + 3x2 - 6x3 + cos 3t 
 
3. 
Let  
(
)
2
2
1
2
1
2
and
, so
1
/
.
x
x
x
x
x
x
x
t
x
tx
t


′
′
′
′′
′
=
=
=
=
=
−
−


   
Equivalent system: 
1x′   =  x2,   
t2
2x′   =  (1 - t2)x1 - tx2 
 
4. 
Let  
(
)
2
3
1
2
1
3
2
3
,
,
, so
5
3
2
ln
/
x
x
x
x
x
x
x
x
x
x
x
tx
t x
t
t
′
′
′
′′
′
′′′
′
′′
=
=
=
=
=
=
= −
−
−
+
.  
Equivalent system: 
1x′   =  x2,        
2x′   =  x3, 
t3
3x′   =  -5x1 - 3tx2 + 2t2x3 + ln t 
 
5. 
Let  
( )
2
1
2
1
3
2
3
,
,
, so
cos .
x
x
x
x
x
x
x
x
x
x
x
x
′
′
′
′′
′
′′′
′
=
=
=
=
=
=
=
+
 
Equivalent system: 
1x′   =  x2,    
2x′   =  x3,  
3x′   =  x2
2 + cos x1 
 
6. 
Let  
1
2
1
1
2
1
2
2
,
,
,
so
5
4 ,
4
5 .
x
x
x
x
x
y
y
y
y
y
x
x
x
y
y
y
x
y
′
′
′
′
′
′′
′
′′
=
=
=
=
=
=
=
=
−
=
= −
+
 
 
Equivalent system: 

334 
Chapter 7 
1x′   =  x2,     
2x′   =     5x1 - 4y1    
 
1y′  =  y2,        
2y′   =  -4x1 + 5y1 
 
7. 
Let  
2
2
3/ 2
1
2
1
1
2
1
2
,
,
,
so
/(
)
,
x
x
x
x
x
y
y
y
y
y
x
x
kx
x
y
′
′
′
′
′
′′
=
=
=
=
=
=
=
= −
+
 
 
2
2 3/ 2
2
/(
)
.
y
y
ky
x
y
′
′′
=
= −
+
 
Equivalent system: 
1x′   =  x2,         
2x′   =  
(
)
3/ 2
2
2
1
1
1
/
kx
x
y
−
+
 
 
1y′  =  y2,          
2y′   =  
(
)
3/ 2
2
2
1
1
1
/
ky
x
y
−
+
 
 
8. 
Let  
1
2
1
1
2
1
2
,
,
,
so
4
2
3 ,
x
x
x
x
x
y
y
y
y
y
x
x
x
y
x
′
′
′
′
′
′′
′
=
=
=
=
=
=
=
= −
+
−
 
 
2
3
2
cos .
y
y
x
y
y
t
′
′′
′
=
=
−
−
+
 
Equivalent system: 
 
1x′   =  x2,        
2x′   =  -4x1 + 2y1 - 3x2 
 
1y′  =  y2 ,          
2y′   =     3x1 -  y1 - 2y2 + cos t 
 
9. 
Let  
1
2
1
1
2
1
1
2
1
,
,
,
,
,
, so
x
x
x
x
x
y
y
y
y
y
z
z
z
z
z
′
′
′
′
′
′
=
=
=
=
=
=
=
=
=
 
 
2
3
2 ,
x
x
x
y
z
′
′′
=
=
−
+
2
2
4 ,
5
.
y
y
x
y
z
z
z
x
y
z
′
′′
′
′′
=
=
+
−
=
=
−
−
 
 
Equivalent system: 
 
1x′   =  x2,          
2x′   =  3x1 - y1 + 2z1 
 
1y′  =  y2,         
2y′   =   x1 +  y1 - 4z1 
 
1z′  =  z2,          
2z′   =  5x1 - y1 -  z1 
 
10. 
Let  
1
2
1
1
2
1
2
,
,
,
so
(1
),
x
x
x
x
x
y
y
y
y
y
x
x
x
y
′
′
′
′
′
′′
=
=
=
=
=
=
=
=
−
2
(1
).
y
y
y
x
′
′′
=
=
−
 
Equivalent system: 
 
1x′   =  x2,         
2x′   =  x1(1 - y1) 
 
1y′  =  y2 
2y′   =  y1(1 - x1) 
 
11. 
The computation  x''  =  y'  =  -x  yields the single linear second-order equation   
 
x'' + x  =  0  with characteristic equation  r2 + 1  =  0  and general solution 
 
 
 
 
 
x(t)  =  A cos t + B sin t. 
 
 
Then the original first equation  y  =  x'  gives 

 
Section 7.1 
335 
 
 
 
 
y(t)  =  B cos t - A sin t. 
 
 
The figure on the left below shows a direction field and typical solution curves (obviously 
 
circles?) for the given  system. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
12. 
The computation  x''  =  y'  =  x  yields the single linear second-order equation   
 
x'' - x  =  0  with characteristic equation  r2 - 1  =  0  and general solution 
 
 
 
 
 
x(t)  =  A et + B e-t. 
 
 
Then the original first equation  y  =  x'  gives 
 
 
 
 
 
y(t)  =  A et - B e-t. 
 
 
The figure on the right above shows a direction field and some typical solution curves of this 
 
system.  It appears that the typical solution curve is a branch of a hyperbola.   
 
13. 
The computation  x''  =  -2y'  =  -4x  yields the single linear second-order equation   
 
x'' + 4x  =  0  with characteristic equation  r2 + 4  =  0  and general solution 
 
 
 
 
 
x(t)  =  A cos 2t + B sin 2t. 
 
 
Then the original first equation  y  =  -x'/2  gives 
 
 
 
 
 
y(t)  =  -B cos 2t + A sin 2t. 
 
 
Finally, the condition  x(0)  =  1  implies that  A  =  1, and then the condition  y(0)  =  0  
gives  B  =  0.  Hence the desired particular solution is given by 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x
y
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x
y

336 
Chapter 7 
 
 
 
 
x(t)  =  cos 2t,  
y(t)  =  sin 2t. 
 
 
The figure on the left below shows a direction field and some typical circular solution 
 
curves for the given system. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
14. 
The computation  x''  =  10y'  =  -100x  yields the single linear second-order equation  
 
x'' + 100x  =  0  with characteristic equation  r2 + 100  =  0  and general solution 
 
 
 
 
 
x(t)  =  A cos 10t + B sin 10t. 
 
 
Then the original first equation  y  =  x'/10  gives 
 
 
 
 
 
y(t)  =  B cos 10t - A sin 10t. 
 
 
Finally, the condition  x(0)  =  3  implies that  A  =  3, and then the condition  y(0)  =  4  
gives  B  =  4.  Hence the desired particular solution is given by 
 
 
 
 
 
x(t)  =  3 cos 10t + 4 sin 10t,   
 
 
 
 
y(t)  =  4 cos 10t - 3 sin 10t. 
 
 
The typical solution curve is a circle.  See the figure on the right above. 
 
15. 
The computation  x''  =  y'/2  =  -4x  yields the single linear second-order equation   
 
x'' + 4x  =  0  with characteristic equation  r2 + 4  =  0  and general solution 
 
 
 
 
 
x(t)  =  A cos 2t + B sin 2t. 
 
 
Then the original first equation  y  =  2x'  gives 
 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x
y
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x
y

 
Section 7.1 
337 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x
y
 
 
 
 
y(t)  =  4B cos 2t - 4A sin 2t. 
 
 
The figure on the left below shows a direction field and some typical elliptical 
 
solution curves. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
16. 
The computation  x''  =  8y'  =  -16x  yields the single linear second-order equation   
 
x'' + 16x  =  0  with characteristic equation  r2 + 16  =  0  and general solution 
 
 
 
 
 
x(t)  =  A cos 4t + B sin 4t. 
 
 
Then the original first equation  y  =  x'/8  gives 
 
 
 
 
 
y(t)  =  (B/2)cos 4t - (A/2)sin 4t. 
     
 
 
The typical solution curve is an ellipse.  The figure on the right above shows a direction 
 
field and some typical solution curves. 
 
17. 
The computation  x''  =   y'  =  6 x - y  =  6 x - x'  yields the single linear second-order 
equation  x'' + x' - 6 x  =  0  with characteristic equation  r2 + r - 6  =  0  and characteristic 
roots  r  =  -3  and  2,  so the general solution 
 
 
 
 
 
x(t)  =  A e-3t + B e2t. 
 
 
Then the original first equation  y  =   x'  gives 
 
 
 
 
 
y(t)  =  -3A e-3t + 2B e2t. 
 
 
Finally, the initial conditions   
 
 
 
 
x(0)  =  A + B  =  1,   y(0)  =  -3A + 2B  =  2 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x
y

338 
Chapter 7 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x
y
 
imply that  A  =  0  and  B  =  1,  so the desired particular solution is given by 
 
 
 
 
 
x(t)  =  e-3t, 
 
y(t)  =  2 e2t. 
 
 
The figure on the left below shows a direction field and some typical solution curves. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
18. 
The computation  x''  =  -y'  =  -10x + 7y  =  -10x - 7x'  yields the single linear second-
order equation  x'' + 7x' + 10x  =  0  with characteristic equation  r2 + 7r + 10  =  0,  
characteristic roots  r  =  -2  and  -5,  and general solution 
 
 
 
 
 
x(t)  =  A e-2t + B e-5t. 
 
 
Then the original first equation  y  =  -x'  gives 
 
 
 
 
 
y(t)  =  2A e-2t + 5B e-5t. 
 
 
Finally, the initial conditions   
 
 
 
 
x(0)  =  A + B  =  2,     y(0)  =  2A + 5B  =  -7 
 
 
imply that  A  =  17/3,  B  =  -11/3,  so the desired particular solution is given by 
 
 
 
x(t)  =  (17 e-2t - 11 e-5t)/3,        
y(t)  =  (34e-2t – 55e-5t)/3. 
 
 
It appears that the typical solution curve is tangent to the straight line  
2 .
y
x
=
 See the 
 
right-hand figure above for a direction field and typical solution curves. 
 
19. 
The computation  x''  =  -y'  =  -13x - 4y  =  -13x + 4x'  yields the single linear second-
order equation  x'' - 4x' + 13x  =  0  with characteristic equation  r2 - 4r + 13  =  0  and 
characteristic roots  r  =  2 ± 3i,  hence the general solution is 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x
y

 
Section 7.1 
339 
 
 
 
 
x(t)  =  e2t(A cos 3t + B sin 3t). 
 
 
The initial condition  x(0)  =  0  then gives  A  =  0,  so  x(t)  =  B e2tsin 3t.  Then the original 
first equation  y  =  -x'  gives 
 
 
 
 
 
y(t)  =  -e2t(3B cos 3t + 2B sin 3t). 
 
 
Finally, the initial condition  y(0)  =  3  gives  B  =  -1,  so the desired particular solution is 
given by 
 
 
 
 
x(t)  =  -e2tsin 3t, 
y(t)  =  e2t(3 cos 3t + 2 sin 3t). 
 
 
The figure below shows a direction field and some typical solution curves. 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x
y
 
 
 
20. 
The computation  x''  =  y'  =  -9x + 6y  =  -9x + 6x'  yields the single linear second-order 
equation  x'' - 6 x' + 9 x  =  0  with characteristic equation  r2 - 6 r + 9  =  0  and repeated 
characteristic root  r  =  3, 3,  so its general solution is given by 
 
 
 
 
 
 
x(t)  =  (A + Bt)e3t. 
 
 
Then the original first equation  y  =  x'  gives 
 
 
 
 
 
 
y(t)  =  (3A + B + 3Bt)e3t. 
 
 
It appears that the typical solution curve is tangent to the straight line  
3 .
y
x
=
 The figure 
 
at the top of the next page shows a direction field and some typical solution curves. 

340 
Chapter 7 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x
y
 
 
 
21. 
(a) 
Substituting the general solution found in Problem 11 we get 
 
 
 
 
 
x2 + y2  =  (A cos t + B sin t)2 + (B cos t - A sin t)2 
 
 
 
    
 =  (A2 + B2)(cos2t + sin2t)  =  A2 + B2 
 
 
 
x2 + y2  =  C2, 
 
 
 
the equation of a circle of radius  C  =  (A2 + B2)1/2. 
 
 
 
(b) 
Substituting the general solution found in Problem 12 we get 
 
 
 
 
 
x2 - y2  =  (Aet + Be-t)2 - (Aet - Be-t)2  =  4AB, 
 
 
 
the equation of a hyperbola. 
 
22. 
(a) 
Substituting the general solution found in Problem 13 we get 
 
 
 
 
 
x2 + y2  =  (A cos 2t + B sin 2t)2 + (-B cos 2t + A sin 2t)2 
 
 
 
    
 =  (A2 + B2)(cos22t + sin22t)  =  A2 + B2 
 
 
 
x2 + y2  =  C2, 
 
 
 
the equation of a circle of radius  C  =  (A2 + B2)1/2. 
 
 
 
(b) 
Substituting the general solution found in Problem 15 we get 
 
 
 
16x2 + y2  =  16(A cos 2t + B sin 2t)2 + (4B cos 2t - 4A sin 2t)2   
 
 
 
    
    =  16(A2 + B2)(cos22t + sin22t)  =  16(A2 + B2) 

 
Section 7.1 
341 
 
 
 
16x2 + y2  =  C2, 
 
 
 
the equation of an ellipse with semi-axes  1  and  4.  
 
23. 
When we solve Equations (20) and (21) in the text for  e-t  and  e2t  we get 
 
 
 
 
2x - y  =  3Ae-t and 
 x + y  =  3Be2t. 
 
Hence 
 
 
 
(2x - y)2(x + y)  =  (3Ae-t)2(3Be2t)  =  27A2B  =  C. 
 
 
Clearly  y  =  2x  or  y  =  -x  if  C  =  0,  and expansion gives the equation   
 
4x3 - 3xy2 + y3  =  C. 
 
24. 
Looking at Fig. 7.1.9 in the text, we see that the first spring is stretched by  
1,
x  the second 
spring is stretched by  
2
1,
x
x
−
 and the third spring is compressed by  
2.
x   Hence Newton's 
second law gives  
1 1
1
1
2
2
1
(
)
(
)
m x
k x
k
x
x
′′ = −
+
−
  and  
2
2
2
2
1
3
2
(
)
(
).
m x
k
x
x
k x
′′ = −
−
−
 
 
25. 
Looking at Fig. 7.1.10 in the text, we see that  
 
 
 
1
1
2
1
2
1
2
1
sin
sin
tan
tan
/
(
)/
my
T
T
T
T
Ty
L
T y
y
L
θ
θ
θ
θ
′′= −
+
≈−
+
= −
+
−
, 
 
 
2
2
3
2
3
2
1
2
sin
sin
tan
tan
(
) /
/ .
my
T
T
T
T
T y
y
L
Ty
L
θ
θ
θ
θ
′′ = −
−
≈−
−
= −
−
−
 
 
We get the desired equations when we multiply each of these equations by  L/T and set  
/ .
k
mL T
=
 
 
26. 
The concentration of salt in tank i  is  
/100
i
i
c
x
=
 for  i = 1, 2, 3 and each inflow-outflow 
rate is  r = 10.  Hence 
 
 
 
(
)
1
1
1
3
1
3
10
,
x
rc
rc
x
x
′ = −
+
=
−
+
 
 
 
(
)
1
2
1
2
1
2
10
,
x
rc
rc
x
x
′ = +
−
=
−
 
 
 
(
)
1
3
2
3
2
3
10
.
x
rc
rc
x
x
′ = +
−
=
−
 
 
 
 
27. 
If  θ   is the polar angular coordinate of the point  (
)
,x y  and we write  
(
)
2
2
2
/
/
,
F
k
x
y
k r
=
+
=
 then Newton's second law gives 
 
 
 
2
3
cos
( /
)( / )
/
,
mx
F
k r
x r
kx r
θ
′′ = −
= −
= −
 
 
 
2
3
sin
( /
)( / )
/
,
my
F
k r
y r
ky r
θ
′′ = −
= −
= −
 

342 
Chapter 7 
28. 
If we write  (x', y')  for the velocity vector and  
( )
(
)
2
2
v
x
y
′
′
=
+
  for the speed, then  
(x'/v, y'/v)  is a unit vector pointing in the direction of the velocity vector, and so the 
components of the air resistance force  Fr  are given by  
 
 
 
 
 
Fr  =  -kv2(x'/v, y'/v)  =  (-kvx', -kvy'). 
 
29. 
If  
( , , )
x y z
=
r
 is the particle's position vector, then Newton's law  m ′′ =
r
F  gives 
 
 
 
(
)
,
,0 .
0
0
m
q
q x
y
z
qBy
qBx
qB
y x
B
′′
′
′
′
′
′
′
′
=
=
= +
−
=
−
i
j
k
r
v×B
i
j
 
 
and the characteristic equation  (r2 + 2)[(r2 + 2)2 - 2]  =  0  has roots  
2 and
i
±
 
2
2
i
±
±
. 
 
 
 
 
SECTION 7.2 
 
MATRICES AND LINEAR SYSTEMS 
 
1. 
2
3
2
3
4
2
2
3
3
4
2
3
4
2
3
2
3
4
6
4
8
1 8
18
1
2
12
32
(
)
3
4
3
3
4
8
3
4
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
′




−
+
+
−
+
−
+
+
−
+
′ =
=




+
−
+
+
+
−
+
+




AB
 
 
 
2
3
2
2
3
2
2
3
2
2
3
2
3
2
3
3
3
2
2
3
2
3
2
1
2
2
1
1
1
1
1
1
1
3
4
6
12
3
1
6
1
8
7
12
12
24
3
3
3
4
3
3
6
12
1 8
18
1
2
12
32
3
3
4
8
3
4
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
−




−
+
−








′
′
+
=
+








−
















−+
+ +
−
+
−
+
=
+




−+
−
−
+
+
−
+




−
+
+
−
+
=
+
−
+
+
A B
AB
3






 
 
2. 
3
2
4
3
3
3
2
9
3
2
2
(
)
3
3
3
24
2
12
24
2
t
t
t
t
t
t
t
t
e
t e
t
e
e
t e
t
t
t
e
t
e
−
−
−
−
−
′




+
+
+
+
−




′ =
=








+
−
+
+




AB
 
 

 
Section 7.2 
343 
 
 
2
2
3
2
2
2
3
3
3
1
2
3
0
1
0
0
2
0
2
2
8
0
3
3
8
1
3
6
3
2
3
2
9
3
2
2
3
6
3
24
9
3
2
12
24
2
t
t
t
t
t
t
t
t
t
t
t
t
e
t
e
t
t
e
t
e
t
t
t
t
t
e
e
t
t e
t
e
e
t e
t
t
e
t
e
−
−
−
−
−
−
−
−
















′
′
+
=
−
+ −
−
















−














+
+
−
+
+
−






=
−
+
=












+
+
+
+






A B
AB
 
 
3. 
0
3
0
,
( )
,
( )
3
0
0
x
t
t
y
−




=
=
=








x
P
f
 
 
4. 
3
2
0
,
( )
,
( )
2
1
0
x
t
t
y
−




=
=
=








x
P
f
 
 
5. 
2
2
4
3
,
( )
,
( )
5
1
t
x
e
t
t
y
t





=
=
= 




−
−





x
P
f
 
 
6. 
2
cos
,
( )
,
( )
sin
t
t
x
t
t
e
t
t
y
t
e
t
−


−



=
=
=





−





x
P
f
 
 
7. 
0
1
1
0
,
( )
1
0
1 ,
( )
0
1
1
0
0
x
y
t
t
z








=
=
=












x
P
f
 
 
8. 
2
3
0
0
,
( )
1
1
2
,
( )
0
0
5
7
0
x
y
t
t
z
−








=
=
=








−




x
P
f
 
 
9. 
2
3
3
4
1
,
( )
1
0
3 ,
( )
0
6
7
x
t
y
t
t
t
z
t
−










=
=
−
=










−





x
P
f
 
 

344 
Chapter 7 
10. 
2
3
1
0
,
( )
2
1 ,
( )
0
3
0
t
t
x
t
e
y
t
t
t
z
e
t
t
−


−






=
=
−
=












x
P
f
 
 
11. 
1
2
3
4
0
1
0
0
0
0
0
2
0
0
,
( )
,
( )
0
0
0
3
0
4
0
0
0
0
x
x
t
t
x
x















=
=
=

















x
P
f
 
 
12. 
1
2
2
3
3
4
0
1
1
0
0
0
0
1
1
,
( )
,
( )
1
0
0
1
1
1
0
0
x
x
t
t
t
x
t
x
t


















=
=
=




















x
P
f
 
 
13. 
2
3
2
2
( )
0
3
t
t
t
t
t
e
e
W t
e
e
e
=
=
≠
−
−
 
 
1
1
4
2
2
2
2
3
1
3
3
3
t
t
t
t
t
t
e
e
e
e
e
e
′








′ =
=
=
=








−
−
−
−
−








x
Ax  
 
2
2
2
2
2
2
2
2
4
2
2
3
1
2
t
t
t
t
t
t
e
e
e
e
e
e
′








′ =
=
=
=








−
−
−
−
−








x
Ax  
 
2
2
1
2
1
1
2
2
1
2
2
2
1
2
2
2
( )
3
3
t
t
t
t
t
t
t
t
c e
c e
e
e
t
c
c
c
c
c e
c e
e
e






+
=
+
=
+
= 





−
−
−
−






x
x
x
 
 
In most of Problems 14-22, we omit the verifications of the given solutions.  In each case, this is 
simply a matter of calculating both the derivative  
i′x  of the given solution vector and the product  
i
Ax   (where  A  is the coefficient matrix in the given differential equation)  to verify that  
i
i
′ =
x
Ax  (just as in the verification of the solutions  
1
2
and
x
x  in Problem 13 above). 
 
14. 
3
2
3
3
2
2
( )
5
0
3
t
t
t
t
t
e
e
W t
e
e
e
−
−
=
= −
≠
 
 
3
2
3
2
1
2
1
1
2
2
1
2
3
2
3
2
1
2
2
2
( )
3
3
t
t
t
t
t
t
t
t
c e
c e
e
e
t
c
c
c
c
c e
c e
e
e
−
−
−
−






+
=
+
=
+
= 





+






x
x
x
 

 
Section 7.2 
345 
15. 
2
2
2
2
( )
4
0
5
t
t
t
t
e
e
W t
e
e
−
−
=
=
≠
 
 
2
2
2
2
1
2
1
1
2
2
1
2
2
2
1
2
1
1
( )
1
5
5
t
t
t
t
t
t
c e
c e
t
c
c
c
e
c
e
c e
c e
−
−
−


+


=
+
=
+
= 



+




x
x
x
 
 
16. 
3
2
5
3
2
( )
0
2
t
t
t
t
t
e
e
W t
e
e
e
=
=
≠
−
−
 
 
3
2
3
2
1
2
1
1
2
2
1
2
3
2
1
2
1
1
( )
1
2
2
t
t
t
t
t
t
c e
c e
t
c
c
c
e
c
e
c e
c e


+




=
+
=
+
= 





−
−
−
−






x
x
x
 
 
 
17. 
2
5
3
2
5
3
( )
7
0
2
3
t
t
t
t
t
e
e
W t
e
e
e
−
−
−
=
=
≠
 
 
2
5
2
5
1
2
1
1
2
2
1
2
2
5
2
5
1
2
3
3
( )
2
3
2
3
t
t
t
t
t
t
t
t
c e
c e
e
e
t
c
c
c
c
c e
c e
e
e
−
−
−
−






+
=
+
=
+
= 





+






x
x
x
 
 
18. 
3
5
5
9
3
5
2
2
2
( )
2
0
2
16
0
t
t
t
t
t
t
t
t
t
e
e
e
W t
e
e
e
e
e
e
−
=
−
=
≠
 
 
3
5
1
2
3
3
5
5
1
1
2
2
3
3
1
2
3
1
3
3
5
1
2
3
2
2
2
2
2
2
( )
2
0
2
2
2
1
1
1
t
t
t
t
t
t
t
t
t
t
t
c e
c e
c e
t
c
c
c
c
e
c
e
c
e
c e
c e
c e
c e
c e


−
−
+












=
+
+
=
+
+
−
=
−














+
+







x
x
x
x
 
 
19. 
2
2
2
0
( )
0
3
0
t
t
t
t
t
t
t
e
e
W t
e
e
e
e
e
−
−
−
−
=
=
≠
−
−
 
 
2
1
2
2
2
1
1
2
2
3
3
1
2
3
1
3
2
1
2
3
1
1
0
( )
1
0
1
1
1
1
t
t
t
t
t
t
t
t
t
t
c e
c e
t
c
c
c
c
e
c
e
c
e
c e
c e
c e
c e
c e
−
−
−
−
−
−


+












=
+
+
=
+
+
=
+














−
−
−
−







x
x
x
x
 
 
1
1
2
0
1
1
1
2
1
0
1
1
2
1
1
0
1
t
t
e
e






′ =
=
=









x
Ax  

346 
Chapter 7 
 
2
2
1
0
1
1
1
0
1
0
1
0
1
1
1
0
1
t
t
e
e
−
−
−










′ =
=
=










−





x
Ax  
 
3
3
0
0
1
1
0
1
1
0
1
1
1
1
1
0
1
t
t
e
e−










′ =
−
=
=










−





x
Ax  
 
 
20. 
3
4
3
4
7
3
4
1
2
( )
6
3
2
84
0
13
2
t
t
t
t
t
t
t
e
e
W t
e
e
e
e
e
−
=
= −
≠
−
−
 
 
3
4
1
2
3
3
4
3
4
1
1
2
2
3
3
1
2
3
1
2
3
3
4
1
2
3
1
2
1
2
( )
6
3
2
6
3
2
13
2
1
13
2
t
t
t
t
t
t
t
t
c
c e
c e
t
c
c
c
c
c
e
c
e
c
c e
c e
c
c e
c e


−
+
−














=
+
+
=
+
+
=
+
+
















−
−
−
−
+








x
x
x
x
 
 
21. 
2
3
2
3
2
2
3
( )
2
0
2
0
t
t
t
t
t
t
t
t
t
e
e
e
W t
e
e
e
e
e
e
−
−
−
= −
−
−
=
≠
 
 
2
3
1
2
3
2
3
2
3
1
1
2
2
3
3
1
2
3
1
2
3
2
1
2
3
1
1
3
( )
2
1
1
2
2
1
0
2
t
t
t
t
t
t
t
t
t
t
t
c e
c e
c e
t
c
c
c
c
e
c
e
c
e
c e
c e
c e
c e
c e
−
−
−
−


+
+














=
+
+
=
−
+
−
+
−
=
−
−
−
















+








x
x
x
x
 
 
22. 
1
0
0
0
0
0
0
0
( )
0
0
1
0
0
0
3
2
2
0
0
2
0
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
W t
e
e
e
e
e
e
e
e
e
e
−
−
−
−
−
−
=
= −
= −
=
≠
−
−
−
 
 
1
4
3
1
2
3
4
2
4
1
3
1
0
0
1
0
0
1
0
( )
0
1
0
3
3
1
0
2
0
2
t
t
t
t
t
t
t
t
t
t
t
c e
c e
c e
t
c
e
c
e
c
e
c
e
c e
c e
c e
c e
−
−
−
−
−


+



















=
+
+
+
= 






+







−
−









x
 
 
In Problems 23–26 (and similarly in Problems 27–32) we give first the scalar components  
1
2
( ) and
( )
x t
x t  of a general solution, then the equations in the coefficients  
1
2
and
c
c  that are 

 
Section 7.2 
347 
obtained when the given initial conditions are imposed, and finally the resulting particular 
solution of the given system. 
 
23. 
3
2
3
2
1
1
2
2
1
2
( )
2
,
( )
3
t
t
t
t
x t
c e
c e
x t
c e
c e
−
−
=
+
=
+
 
 
1
2
1
2
3
2
3
2
1
2
2
0,
3
5
( )
2
2
,
( )
6
t
t
t
t
c
c
c
c
x t
e
e
x t
e
e
−
−
+
=
+
=
=
−
=
−
 
 
24. 
2
2
2
2
1
1
2
2
1
2
( )
,
( )
5
t
t
t
t
x t
c e
c e
x t
c e
c e
−
−
=
+
=
+
 
 
1
2
1
2
2
2
2
2
1
2
5,
5
3
( )
7
2
,
( )
7
10
t
t
t
t
c
c
c
c
x t
e
e
x t
e
e
−
−
+
=
+
= −
=
−
=
−
 
 
25. 
3
2
3
2
1
1
2
2
1
2
( )
,
( )
2
t
t
t
t
x t
c e
c e
x t
c e
c e
=
+
= −
−
 
 
1
2
1
2
3
2
3
2
1
2
11,
2
7
( )
15
4
,
( )
15
8
t
t
t
t
c
c
c
c
x t
e
e
x t
e
e
+
=
−
−
= −
=
−
= −
+
 
 
26. 
2
5
2
5
1
1
2
2
1
2
( )
3
,
( )
2
3
t
t
t
t
x t
c e
c e
x t
c e
c e
−
−
=
+
=
+
 
 
(
)
(
)
1
2
1
2
2
5
2
5
1
2
3
8,
2
3
0
8
48
( )
9
2
,
( )
7
7
t
t
t
t
c
c
c
c
x t
e
e
x t
e
e
−
−
+
=
+
=
=
−
=
−
 
 
27. 
3
5
5
3
5
1
1
2
3
2
1
3
3
1
2
3
( )
2
2
2
,
( )
2
2
,
( )
t
t
t
t
t
t
t
t
x t
c e
c e
c e
x t
c e
c e
x t
c e
c e
c e
=
−
+
=
−
=
+
+
 
 
1
2
3
1
3
1
2
3
3
5
5
3
5
1
2
3
2
2
2
0,
2
2
0,
4
( )
2
4
2
,
( )
2
2
,
( )
2
t
t
t
t
t
t
t
t
c
c
c
c
c
c
c
c
x t
e
e
e
x t
e
e
x t
e
e
e
−
+
=
−
=
+
+
=
=
−
+
=
−
=
+
+
 
 
28. 
2
2
2
1
1
2
2
1
3
3
1
2
3
( )
,
( )
,
( )
t
t
t
t
t
t
t
x t
c e
c e
x t
c e
c e
x t
c e
c e
c e
−
−
−
−
=
+
=
+
=
−
−
 
 
1
2
1
3
1
2
3
2
2
2
1
2
3
10,
12,
1
( )
7
3
,
( )
7
5
,
( )
7
8
t
t
t
t
t
t
c
c
c
c
c
c
c
x t
e
e
x t
e
e
x t
e
e
−
−
−
+
=
+
=
−
−
= −
=
+
=
+
=
−
 
 
29. 
2
3
2
3
2
1
1
2
3
2
1
2
3
3
1
2
( )
3
,
( )
2
,
( )
2
t
t
t
t
t
t
t
t
x t
c e
c e
c e
x t
c e
c e
c e
x t
c e
c e
−
−
−
=
+
+
= −
−
−
=
+
 
 
1
2
3
1
2
3
1
2
2
3
2
3
2
1
2
3
3
1,
2
2,
2
3
( )
9
3
5
,
( )
6
3
5
,
( )
6
3
t
t
t
t
t
t
t
t
c
c
c
c
c
c
c
c
x t
e
e
e
x t
e
e
e
x t
e
e
−
−
−
+
+
=
−
−
−
=
+
=
=
−
−
= −
+
+
=
−
 
 

348 
Chapter 7 
30. 
2
3
2
3
2
1
1
2
3
2
1
2
3
3
1
2
( )
3
,
( )
2
,
( )
2
t
t
t
t
t
t
t
t
x t
c e
c e
c e
x t
c e
c e
c e
x t
c e
c e
−
−
−
=
+
+
= −
−
−
=
+
 
 
1
2
3
1
2
3
1
2
2
3
2
3
2
1
2
3
3
5,
2
7,
2
11
( )
6
15
4
,
( )
4
15
4
,
( )
4
15
t
t
t
t
t
t
t
t
c
c
c
c
c
c
c
c
x t
e
e
e
x t
e
e
e
x t
e
e
−
−
−
+
+
=
−
−
−
= −
+
=
= −
+
−
=
−
+
= −
+
 
 
31. 
1
1
4
2
3
3
2
4
4
1
3
( )
,
( )
,
( )
3
,
( )
2
t
t
t
t
t
t
t
x t
c e
c e
x t
c e
x t
c e
c e
x t
c e
c e
−
−
−
=
+
=
=
+
=
−
 
 
1
4
3
2
4
1
3
1
2
3
4
1,
1,
3
1,
2
1
( )
3
2 ,
( )
,
( )
7
6 ,
( )
3
2
t
t
t
t
t
t
t
c
c
c
c
c
c
c
x t
e
e
x t
e
x t
e
e
x t
e
e
−
−
−
+
=
=
+
=
−
=
=
−
=
=
−
=
−
  
 
32. 
1
1
4
2
3
3
2
4
4
1
3
( )
,
( )
,
( )
3
,
( )
2
t
t
t
t
t
t
t
x t
c e
c e
x t
c e
x t
c e
c e
x t
c e
c e
−
−
−
=
+
=
=
+
=
−
 
 
1
4
3
2
4
1
3
1
2
3
4
1,
3,
3
4,
2
7
( )
13
12 ,
( )
3 ,
( )
40
36 ,
( )
13
6
t
t
t
t
t
t
t
c
c
c
c
c
c
c
x t
e
e
x t
e
x t
e
e
x t
e
e
−
−
−
+
=
=
+
=
−
=
=
−
=
=
−
=
−
 
 
33. 
(a)   
x2  =  tx1,  so neither is a constant multiple of the other. 
 
 
(b) 
W(x1, x2)  =  0,  whereas Theorem 2 would imply that  W ≠ 0  if  x1  and  x2  were 
independent solutions of a system of the indicated form. 
 
34. 
If  x12(t)  =  c x11(t)  and  x22(t)  =  c x21(t)  then  
 
 
 
W(t)  =    x11(t)x22(t) - x12(t)x21(t)  =  c x11(t)x21(t) -  cx11(t)x21(t)  =  0. 
 
35. 
Suppose  
11
22
12
21
( )
( )
( )
( )
( )
0.
W a
x
a x
a
x
a x
a
=
−
=
   Then the coefficient determinant of 
the homogeneous linear system  
1 11
2
12
1
21
2
22
( )
( )
0,
( )
( )
0
c x
a
c x
a
c x
a
c x
a
+
=
+
=
 
vanishes.  The system therefore has a non-trivial solution  
1
2
{ ,
}
c c
 such that  
1
1
2
2
( )
( )
.
c
a
c
a
+
=
x
x
0   Then  
1
1
2
2
( )
( )
( )
t
c
t
c
t
=
+
x
x
x
  is a solution of  ′ =
x
Px  such 
that  ( )
.
a =
x
0   It therefore follows (by uniqueness of solutions) that  ( )
,
t
≡
x
0  that is,  
1
1
2
2
( )
( )
0
c
t
c
t
+
≡
x
x
 with  
1
2
and
c
c  not both zero.  Thus the solution vectors  x1  and  
x2  are linearly dependent. 
 
36. 
The argument is precisely the same, except with  n  solution vectors each having  n  
component functions (rather than 2 solution vectors each having 2 component functions). 
 
37. 
Suppose that  
1
1
2
2
( )
( )
( )
.
n
n
c
t
c
t
c
t
+
+
+
≡
x
x
x
0

  Then the ith scalar component of this 
vector equation is   
1
1
2
2
( )
( )
( )
0.
i
i
n
in
c x
t
c x
t
c x
t
+
+
+
≡

  Hence the fact that the scalar 
functions  
1
2
( ),
( ),
,
( )
i
i
in
x
t
x
t
x
t

 are linear linearly independent implies that  

 
Section 7.2 
349 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
y2
1
2
0.
n
c
c
c
=
=
=

  Consequently the vector functions  
1
2
( ),
( ),
,
( )
n
t
t
t
x
x
x

 are linearly 
independent. 
 
 
 
SECTION 7.3 
 
THE EIGENVALUE METHOD 
FOR LINEAR SYSTEMS 
 
In each of Problems 1–16 we give the characteristic equation, the eigenvalues  λ1  and  λ2  of the 
coefficient matrix of the given system, the corresponding equations determining the associated 
eigenvectors  
T
T
1
1
1
2
2
2
[
]
and
[
] ,
a
b
a
b
=
=
v
v
  these eigenvectors, and the resulting scalar 
components  x1(t)  and  x2(t)  of a general solution  
1
2
1
1
2
2
( )
t
t
t
c
e
c
e
λ
λ
=
+
x
v
v
 of the system.   
 
1. 
Characteristic equation     
2
2
3
0
λ
λ
−
−
=
 
 
Eigenvalues   λ1  =  -1  and  λ2  =  3 
 
Eigenvector equations  
1
2
1
2
2
2
0
2
2
0
and
2
2
0
2
2
0
a
a
b
b
−










=
=










−










 
 
Eigenvectors  v1  =  [1    -1]T  and  v2  =  [1     1]T 
 
x1(t)  =     c1e-t + c2e3t,     x2(t)  =  -c1e-t + c2e3t 
 
The left-hand figure below shows a direction field and some typical solution curves 
 
for the system in Problem 1. 
 
 
 
 
 
 
 
 
 
 
 
 

350 
Chapter 7 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
y2
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
2. 
Characteristic equation     
2
3
4
0
λ
λ
−
−
=
 
 
Eigenvalues   λ1  =  -1  and  λ2  =  4 
 
Eigenvector equations  
1
2
1
2
3
3
0
2
3
0
and
2
2
0
2
3
0
a
a
b
b
−










=
=










−










 
 
Eigenvectors  v1  =  [1   -1]T  and  v2  =  [3     2]T 
 
x1(t)  =     c1e-t + 3c2e4t,     x2(t)  =  -c1e-t + 2c2e4t 
 
The right-hand figure at the bottom of the preceding page shows a direction field and 
 
some typical solution curves. 
 
3. 
Characteristic equation     
2
5
6
0
λ
λ
−
−
=
 
 
Eigenvalues   λ1  =  -1  and  λ2  =  6 
 
Eigenvector equations  
1
2
1
2
4
4
0
3
4
0
and
3
3
0
3
4
0
a
a
b
b
−










=
=










−










 
 
Eigenvectors  v1  =  [1   -1]T  and  v2  =  [4    3]T 
 
x1(t)  =     c1e-t + 4c2e6t,     x2(t)  =  -c1e-t + 3c2e6t 
 
The equations 
 
 
 
 
x1(0)  =    c1 + 4c2  =  1 
 
                    
 
x2(0)  = -c1 + 3c2  =  1 
 
 
yield  c1  =  -1/7  and  c2  =  2/7,  so the desired particular solution is given by 
 
 
 
 
x1(t)  =  1
7 (-e-t + 8e6t),     x2(t)  =  1
7 ( e-t + 6e6t).  
 
The left-hand figure below shows a direction field and some typical solution curves. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 
Section 7.3 
351 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
4. 
Characteristic equation     
2
3
10
0
λ
λ
−
−
=
 
 
Eigenvalues   λ1  =  -2  and  λ2  =  5 
 
Eigenvector equations  
1
2
1
2
6
1
0
1
1
0
and
6
1
0
6
6
0
a
a
b
b
−










=
=










−










 
 
Eigenvectors  v1  =  [1  -6]T  and  v2  =  [1    1]T 
 
 
x1(t)  =  c1e-2t + c2e5t,     x2(t)  =  -6c1e-2t + c2e5t 
  
The right-hand figure at the bottom of the preceding page shows a direction field and 
 
some typical solution curves. 
 
5. 
Characteristic equation     
2
4
5
0
λ
λ
−
−
=
 
 
Eigenvalues   λ1  =  -1  and  λ2  =  5 
 
Eigenvector equations  
1
2
1
2
7
7
0
1
7
0
and
1
1
0
1
7
0
a
a
b
b
−
−










=
=










−
−










 
 
Eigenvectors  v1  =  [1    1]T  and  v2  =  [7    1]T 
 
 
x1(t)  =  c1e-t + 7c2e5t,     x2(t)  =  c1e-t +   c2e5t 
 
The left-hand figure below shows a direction field and some typical solution curves. 
 
 
 
 
 
 
 
 
 
 
 
 
6. 
Characteristic equation     
2
7
12
0
λ
λ
−
+
=
 
 
Eigenvalues   λ1  =  3  and  λ2  =  4 

352 
Chapter 7 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
 
Eigenvector equations  
1
2
1
2
6
5
0
5
5
0
and
6
5
0
6
6
0
a
a
b
b










=
=










−
−
−
−










 
 
Eigenvectors  v1  =  [5   -6]T  and  v2  =  [1   -1]T 
 
 
x1(t)  =   5c1e3t + c2e4t,     x2(t)  = -6c1e3t - c2e4t 
 
 
The initial conditions yield  c1  =  -1  and  c2  =  6,  so 
 
 
 
 
x1(t)  =  -5e3t + 6e4t,     x2(t)  =  6e3t - 6e4t. 
   
 
 
The right-hand figure at the bottom of the preceding page shows a direction field and 
 
some typical solution curves. 
 
7. 
Characteristic equation     
2
8
9
0
λ
λ
+
−
=
 
 
Eigenvalues   λ1  =  1  and  λ2  =  -9 
 
Eigenvector equations  
1
2
1
2
4
4
0
6
4
0
and
6
6
0
6
4
0
a
a
b
b
−










=
=










−










 
 
Eigenvectors  v1  =  [1    1]T  and  v2  =  [2   -3]T 
 
 
 
x1(t)  =  c1et + 2c2e-9t,     x2(t)  =  c1et - 3c2e-9t 
 
  
The left-hand figure below shows a direction field and some typical solution curves. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

 
Section 7.3 
353 
8. 
Characteristic equation  λ2 + 4  =  0 
 
Eigenvalue  λ  =  2i 
 
Eigenvector equation  1
2
5
0
1
1
2
0
i
a
i
b
−
−



=



−−



 
 
Eigenvector  v  =  [5     1-2i]T 
 
2
5cos2
5 sin2
( )
(cos2
2sin2 )
(sin2
2cos2 )
i t
t
i
t
t
e
t
t
i
t
t
+


=
= 

+
+
−


x
v
 
 
x1(t)  =  5c1cos 2t + 5c2sin 2t 
 
x2(t)  =  c1(cos 2t + 2 sin 2t) + c2(sin 2t - 2 cos 2t) 
 
         =  (c1 - 2c2)cos 2t + (2c1 + c2)sin 2t 
 
 
The right-hand figure at the bottom of the preceding page shows a direction field and 
 
some typical solution curves. 
 
9. 
Characteristic equation   λ2 + 16  =  0 
 
Eigenvalue  λ  =  4i 
 
Eigenvector equation  2
4
5
0
4
2
4
0
i
a
i
b
−
−



=



−−



 
 
Eigenvector  v  =  [5     2-4i]T 
 
 
 
The real and imaginary parts of 
 
 
          
4
5cos4
5 sin4
( )
(2cos4
4sin4 )
(2sin4
4cos4 )
i t
t
i
t
t
e
t
t
i
t
t
+


=
= 

+
+
−


x
v
 
 
yield the general solution 
 
 
 
 
x1(t)  =  5c1cos 4t + 5c2sin 4t 
 
 
 
x2(t)  =  c1(2 cos 4t + 4 sin 4t) + c2(2 sin 4t - 4 cos 4t). 
 
 
The initial conditions  x1(0)  =  2  and  x2(0)  =  3  give  c1  =  2/5  and  c2  =  -11/20,  so 
the desired particular solution is 
 
 
           
x1(t)  =  2 cos 4t - 11
4 sin 4t 
 
          
x2(t)  =  3 cos 4t +  1
2 sin 4t. 
 
 
The left-hand figure at the top of the next page shows a direction field and some typical 
 
solution curves. 

354 
Chapter 7 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
10. 
Characteristic equation   λ2 + 9  =  0 
 
Eigenvalue  λ  =  3i 
 
Eigenvector equation  
3
3
2
0
9
3
3
0
i
a
i
b
−−
−



=



−



 
 
Eigenvector  v  =  [-2     3+3i]T 
 
          
3
2cos3
2 sin3
( )
(3cos3
3sin3 )
(3sin3
3cos3 )
it
t
i
t
t
e
t
t
i
t
t
−
−


=
= 

−
+
+


x
v
 
 
x1(t)  =  -2c1cos 3t - 2c2sin 3t 
 
x2(t)  =   c1(3 cos 3t - 3 sin 3t) + c2(3 cos 3t + 3 sin 3t) 
 
         =  (3c1 + 3c2)cos 3t + (3c2 - 3c1)sin 3t 
 
 
The right-hand figure above shows a direction field and some typical solution curves for 
 
this system. 
 
11.   
Characteristic equation   
2
2
5
0
λ
λ
−
+
=
 
 
Eigenvalue  λ  =  1 - 2i 
 
Eigenvector equation  2
2
0
2
2
0
i
a
i
b
−



=






 
 
Eigenvector  v  =  [1     i]T 
 
 
 
The real and imaginary parts of 

 
Section 7.3 
355 
 
 
    
 
x(t)  =  [1     i]T et(cos 2t - i sin 2t) 
 
       
  
        =  et [cos 2t    sin 2t]T + iet [-sin 2t     cos 2t]T 
 
 
yield the general solution 
 
 
        
 
x1(t)  =  et(c1cos 2t - c2sin 2t) 
 
        
 
x2(t)  =  et(c1sin 2t  + c2cos 2t). 
 
 
The particular solution with  x1(0)  =  0  and  x2(0)  =  4  is obtained with  c1  =  0  and   
 
c2  =  4,  so  
 
           
x1(t)  =  -4etsin 2t, 
 
x2(t)  =   4etcos 2t.  
 
 
The figure below shows a direction field and some typical solution  curves. 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
 
 
12. 
Characteristic equation   λ2 - 4λ + 8  =  0 
 
Eigenvalue   λ  =  2 + 2i 
 
Eigenvector equation  
1
2
5
0
1
1
2
0
i
a
i
b
−−
−



=



−



 
 
Eigenvector  v  =  [-5     1+2i]T  
 
(2 2 )
2
5cos2
5 sin2
( )
(cos2
2sin2 )
(sin2
2cos2 )
i t
t
t
i
t
t
e
e
t
t
i
t
t
+
−
−


=
=


−
+
+


x
v
 
 
x1(t)  =  e2t(-5c1cos 2t - 5c2sin 2t) 

356 
Chapter 7 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
 
x2(t)  =  e2t [c1(cos 2t - 2 sin 2t) + c2(2 cos 2t + sin 2t)] 
 
         =  e2t [(c1 + 2c2)cos 2t + (-2c1 + c2)sin 2t] 
 
 
The left-hand figure below shows a direction field and some typical solution curves. 
 
 
 
 
 
 
 
 
 
 
 
 
 
13. 
Characteristic equation   λ2 - 4λ + 13  =  0 
 
Eigenvalue  λ  =  2 - 3i 
 
Eigenvector equation  3
3
9
0
2
3
3
0
i
a
i
b
+
−



=



−+



 
 
Eigenvector  v  =  [3     1+i]T 
 
(2 3 )
2
3cos3
3 sin3
( )
(cos3
sin3 )
(cos3
sin3 )
i t
t
t
i
t
t
e
e
t
t
i
t
t
−
−


=
=


+
+
−


x
v
 
 
x1(t)  =  3e2t(c1cos 3t - c2sin 3t) 
 
x2(t)  =   e2t [(c1 + c2)cos 3t + (c1 - c2)sin 3t)]. 
 
 
The right-hand figure above shows a direction field and some typical solution curves. 
 
14. 
Characteristic equation  
2
2
5
0
λ
λ
−
+
=
 
 
Eigenvalue  λ  =  3 + 4i 
 
Eigenvector equation  
4
4
0
4
4
0
i
a
i
b
−
−



=



−



 

 
Section 7.3 
357 
 
Eigenvector  v  =  [1    -i]T 
 
(3 4 )
3
cos4
sin4
( )
sin4
cos4
i t
t
t
i
t
t
e
e
t
i
t
+
+


=
=


−


x
v
 
 
x1(t)  =  e3t(c1cos 4t + c2sin 4t) 
 
x2(t)  =  e3t(c1sin 4t - c2cos 4t) 
 
 
The figure below shows a direction field and some typical solution curves. 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
 
 
 
15. 
Characteristic equation   λ2 - 10λ + 41  =  0 
 
Eigenvalue  λ  =  5 - 4i 
 
Eigenvector equation  2
4
5
0
4
2
4
0
i
a
i
b
+
−



=



−+



 
 
Eigenvector  v  =  [5     2+4i]T 
 
(5 4 )
5
5cos4
5 sin4
( )
(2cos4
4sin4 )
(4cos4
2sin4 )
i t
t
t
i
t
t
e
e
t
t
i
t
t
−
−


=
=


+
+
−


x
v
 
 
x1(t)  =  5e5t(c1cos 4t - c2sin 4t) 
 
x2(t)  =   e5t [(2c1 + 4c2)cos 4t + (4c1 - 2c2)sin 4t)] 
 
 
The left-hand figure at the top of the next page shows a direction field and some typical 
 
solution curves. 
 

358 
Chapter 7 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
16. 
Characteristic equation   λ2 + 110λ +1000  =  0 
 
Eigenvalues   λ1  =  -10  and  λ2  =  -100 
 
Eigenvector equations  
1
2
1
2
40
20
0
50
20
0
and
100
50
0
100
40
0
a
a
b
b
−










=
=










−










 
 
Eigenvectors  v1  =  [1     2]T  and  v2  =  [2   -5]T  
 
 
x1(t)  =   c1e-10t + 2c2e-100t  
 
x2(t)  =  2c1e-10t - 5c2e-100t  
 
 
The right-hand figure above shows a direction field and some typical solution curves. 
 
17. 
Characteristic equation  
3
2
15
54
0
λ
λ
λ
−
+
−
=
 
 
Eigenvalues   λ1  =  9,   λ2  =  6,   λ3  =  0 
Eigenvector equations  
1
2
3
1
2
3
1
2
3
5
1
4
0
2
1
4
0
4
1
4
0
1
2
1
0 ,
1
1
1
0 ,
1
7
1
0
4
1
5
0
4
1
2
0
4
1
4
0
a
a
a
b
b
b
c
c
c
−
−
























−
=
=
=












−
−
























 
 
Eigenvectors  v1  =  [1   1   1]T,  
v2  =  [1  -2   1]T,   
v3  =  [1    0  -1]T 
 
 
x1(t)  =   c1e9t  +  c2e6t  +  c3 
 
x2(t)  =   c1e9t  - 2c2e6t 
 
x3(t)  =   c1e9t  +  c2e6t  -  c3  
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2

 
Section 7.3 
359 
18. 
Characteristic equation  
3
2
15
54
0
λ
λ
λ
−
+
−
=
 
 
Eigenvalues   λ1  =  9,   λ2  =  6,   λ3  =  0 
Eigenvector equations  
1
2
3
1
2
3
1
2
3
8
2
2
0
5
2
2
0
1
2
2
0
2
2
1
0 ,
2
1
1
0 ,
2
7
1
0
2
1
2
0
2
1
1
0
2
1
7
0
a
a
a
b
b
b
c
c
c
−
−
























−
=
=
=












−
























 
 
Eigenvectors  v1  =  [1   2   2]T,   
v2  =  [0    1  -1]T,   
v3  =  [4   -1  -1]T 
 
x1(t)  =   c1e9t              + 4c3 
 
x2(t)  =  2c1e9t  +  c2e6t  -  c3 
 
x3(t)  =  2c1e9t  -  c2e6t  -  c3  
 
 
19. 
Characteristic equation  
3
2
12
45
54
0
λ
λ
λ
−
+
−
+
=
 
 
Eigenvalues   λ1  =  6,   λ2  =  3,   λ3  =  3 
Eigenvector equations  
1
2
3
1
2
3
1
2
3
2
1
1
0
1 1 1
0
1 1 1
0
1
2
1
0 ,
1 1 1
0 ,
1 1 1
0
1
1
2
0
1 1 1
0
1 1 1
0
a
a
a
b
b
b
c
c
c
−
























−
=
=
=












−
























 
 
Eigenvectors  v1  =  [1    1   1]T,    
v2  =  [1  -2    1]T,   
v3  =  [1    0  -1]T 
 
 
 
x1(t)  =   c1e6t  +  c2e3t  +  c3e3t 
 
x2(t)  =   c1e6t  - 2c2e3t 
 
x3(t)  =   c1e6t  +  c2e3t  -  c3e3t  
 
 
20. 
Characteristic equation  
3
2
17
84
108
0
λ
λ
λ
−
+
−
+
=
 
 
Eigenvalues   λ1  =  9,   λ2  =  6,   λ3  =  2 
Eigenvector equations  
1
2
3
1
2
3
1
2
3
4
1
3
0
1 1
3
0
3
1
3
0
1
2
1
0 ,
1
1
1
0 ,
1
5
1
0
3
1
4
0
3
1
1
0
3
1
3
0
a
a
a
b
b
b
c
c
c
−
−
























−
=
=
=












−
−
























 
 
Eigenvectors  v1  =  [1    1    1]T,   
v2  =  [1  -2    1]T,   
v3  =  [1    0  -1]T 

360 
Chapter 7 
 
x1(t)  =   c1e9t  +  c2e6t  +  c3e2t 
 
x2(t)  =   c1e9t  - 2c2e6t 
 
x3(t)  =   c1e9t  +  c2e6t  -  c3e2t  
 
 
21. 
Characteristic equation  
3
0
λ
λ
−
+
=
 
 
Eigenvalues   λ1  =  0,   λ2  =  1,   λ3  =  -1 
Eigenvector equations  
1
2
3
1
2
3
1
2
3
5
0
6
0
4
0
6
0
6
0
6
0
2
1
2
0 ,
2
2
2
0 ,
2
0
2
0
4
2
4
0
4
2
5
0
4
2
3
0
a
a
a
b
b
b
c
c
c
−
−
−
























−
−
=
−
−
=
−
=












−
−
−
−
−
−
























 
 
Eigenvectors  v1  =  [6    2    5]T,    v2  =  [3    1    2]T,   
v3  =  [2    1    2]T  
  
x1(t)  =   6c1  +  3c2et  +  2c3e-t 
     
x2(t)  =   2c1  +   c2et  +   c3e-t 
      
x3(t)  =   5c1  +  2c2et  +  2c3e-t  
 
 
22. 
Characteristic equation  
3
2
2
5
6
0
λ
λ
λ
−
+
+
−
=
 
 
Distinct eigenvalues λ1  =  - 2,   λ2  =  1,   λ3  =  3 
Eigenvector equations  
1
2
3
1
2
3
1
2
3
5
2
2
0
2
2
2
0
0
2
2
0
5
2
2
0 ,
5
5
2
0 ,
5
7
2
0
5
5
5
0
5
5
2
0
5
5
0
0
a
a
a
b
b
b
c
c
c
























−
−
−
=
−
−
−
=
−
−
−
=




































 
Eigenvectors  v1  =  [0    1  -1]T,    v2  =  [1  -1    0]T, 
v3  =  [1  -1    1]T 
 
x1(t)  =                 c2et  + c3e3t 
 
x2(t)  =     c1e-2t - c2et - c3e3t 
 
x3(t)  =  -c1e-2t           + c3e3t 
 
 
23. 
Characteristic equation  
3
2
3
4
12
0
λ
λ
λ
−
+
+
−
=
 
 
Eigenvalues  λ1  =  2,  λ2  =  -2,  λ3  =  3 

 
Section 7.3 
361 
Eigenvector equations  
1
2
3
1
2
3
1
2
3
1
1
1
0
5
1
1
0
0
1
1
0
5
5
1
0 ,
5
1
1
0 ,
5
6
1
0
5
5
1
0
5
5
5
0
5
5
0
0
a
a
a
b
b
b
c
c
c
























−
−
−
=
−
−
−
=
−
−
−
=




































 
 
Eigenvectors  v1  =  [1  -1    0]T,    v2  =  [0    1  -1]T, 
v3  =  [1  -1    1]T 
 
 
 
x1(t)  =   c1e2t              + c3e3t 
 
x2(t)  = -c1e2t + c2e-2t - c3e3t 
 
x3(t)  =           - c2e-2t + c3e3t 
 
 
24. 
Characteristic equation  
3
2
4
4
0
λ
λ
λ
−
+
−
+
=
 
 
Eigenvalues  λ  =  1  and  λ  =  ±2i 
 
With  λ  =  1  the eigenvector equation   
 
 
 
1
1
1
1
1
1
0
4
4
1
0
4
4
1
0
a
b
c
−








−
−
−
=












    gives eigenvector  v1  =  [1  -1    0]T.  
 
To find an eigenvector  v  =  [a   b  c]T  associated with  λ  =  2i  we must find a nontrivial 
solution of the equations 
 
 
      
 
(2 - 2i)a +               b   -          c  =  0 
 
            
        -4a + (-3 - 2i)b  -           c  =  0 
 
               
          4a  +            4b + (2 - 2i)c  =  0. 
 
 
 
Subtraction of the first two equations yields 
 
 
 
 
 
(6 - 2i)a + (4 + 2i)b  =  0, 
 
 
so we take  a  =  2 + i  and  b  =  -3 + i.  Then the first equation gives  c  =  3 - i.   
 
Thus  v  =  [2+i    -3+i     3-i]T.  Finally 
 
 
 
(2 + i)e2it  =  (2 cos 2t - sin 2t) + i (cos 2t + 2 sin 2t) 
 
 
(3 - i)e2it  =  (3 cos 2t + sin 2t) + i (3 sin 2t - cos 2t), 
 
 
so the solution is 
 

362 
Chapter 7 
 
 
x1(t)  =   c1et + c2(2 cos 2t - sin 2t) + c3(cos 2t + 2 sin 2t) 
 
 
x2(t)  = -c1et - c2(3 cos 2t + sin 2t) + c3(cos 2t - 3 sin 2t) 
 
 
x3(t)  =             c2(3 cos 2t + sin 2t) + c3(3 sin 2t - cos 2t). 
 
 
25. 
Characteristic equation  
3
2
4
13
0
λ
λ
λ
−
+
−
=
 
 
Eigenvalues  λ  =  0  and  2 ± 3i 
 
With  λ  =  1  the eigenvector equation   
 
 
 
1
1
1
5
5
2
0
6
6
5
0
6
6
5
0
a
b
c








−
−
−
=












    gives eigenvector  v1  =  [1  -1    0]T.  
 
With  λ  =  2 + 3i  we solve  the eigenvector equation   
 
 
 
3
3
5
2
0
6
8
3
5
0
6
6
3
3
0
i
a
i
b
i
c
−






−
−−
−
=



−






     
to find the complex-valued eigenvector  v  =  [1+i    –2    2]T.  The corresponding 
complex-valued solution is  
 
 
(2 3 )
2
(cos3
sin3 )
(cos3
sin3
( )
2cos3
2 sin3
.
2cos3
2 sin3
i t
t
t
t
i
t
t
t
e
e
t
i
t
t
i
t
+
−
+
+




=
=
−
−


+




x
v
 
The scalar components of the resulting general solution are 
 
 
 
x1(t)  =   c1 +  e2t [(c2 + c3)cos 3t + (–c2 + c3)sin 3t] 
 
 
x2(t)  = -c1 + 2e2t(–c2cos 3t - c3sin 3t) 
 
 
x3(t)  =            2e2t(c2cos 3t + c3sin 3t) 
 
 
26. 
Characteristic equation  
3
2
4
6
0
λ
λ
λ
−
+
+
+
=
 
 
Eigenvalues  λ  =  3  and  λ  =  -1 ± i 
 
With  λ  =  3  the eigenvector equation   
 

 
Section 7.3 
363 
 
 
1
1
1
0
0
1
0
9
4
2
0
9
4
4
0
a
b
c








−
=




−
−








    gives eigenvector  v1  =  [4  9    0]T.  
 
With  λ  =  –1 + i  we solve  the eigenvector equation   
 
 
 
 
4
0
1
0
9
2
0
9
4
0
i
a
i
b
i
c
−






=



−






     
to find the complex-valued eigenvector  v  =  [1    2–i    –4+i ]T.  The corresponding 
complex-valued solution is  
 
 
 
( 1
)
cos
sin
( )
(2cos
sin )
( cos
2sin )
( 4cos
sin )
(cos
4sin )
i t
t
t
i
t
t
e
e
t
t
i
t
t
t
t
i
t
t
−+
−
+




=
=
+
+
−
+


−
−
+
−




x
v
  
 
 
with real and imaginary parts  x2(t)  and  x3(t).  Assembling the general solution   
 
x  =  c1x1 + c2x2 +c3x3,  we get the scalar equations 
 
 
 
x1(t)  =  4c1e3t + e-t [c2cos t + c3sin t] 
 
 
x2(t)  =  9c1e3t + e-t [(2c2 - c3)cos t  + (c2 + 2c3)sin t] 
 
 
x3(t)  =               e-t [(-4c2 + c3)cos t + (-c2 - 4c3)sin t]. 
 
 
Finally, the given initial conditions yield the values  c1  =  1,  c2  =  -4,  c3  =  1,  so the 
desired particular solution is 
 
 
 
 
x1(t)  =  4e3t - e-t(4 cos t -   sin t) 
 
 
 
x2(t)  =  9e3t - e-t(9 cos t + 2 sin t) 
 
 
 
x3(t)  =  17e-tcos t. 
 
27. 
The coefficient matrix 
 
 
 
 
0.2
0
0.2
0.4
−


=


−


A
 
 
 
has characteristic equation  
2
0.6
0.08
0
λ
λ
+
+
=
 with eigenvalues  λ1  =  -0.2  and   
 
λ2  =  -0.4.  We find easily that the associated eigenvectors are   v1  =  [1     1]T  and   
 
v2  =  [0     1]T,  so we get the general solution 
 
 
 
 
0.2
0.2
0.4
1
1
2
1
2
( )
,
( )
.
t
t
t
x t
c e
x t
c e
c e
−
−
−
=
=
+
 

364 
Chapter 7 
 
 
The initial conditions  
1
2
(0)
15,
(0)
0
x
x
=
=
  give  
1
2
15 and
15,
c
c
=
= −
 so we get  
 
 
 
 
x1(t)  =  15e-0.2t,     x2(t)  =  15e-0.2t - 15e-0.4t. 
 
To find the maximum value of  x2(t),  we solve the equation  
2( )
0
x t
′
=
  for  t = 5 ln 2, 
which gives the maximum value  x2(5 ln 2) =  3.75 lb. The following figure shows the 
graphs of  
1
2
( ) and
( ).
x t
x t  
 
0
5
10
15
20
0
5
10
15
t
x
x1 
x2 
 
 
 
28. 
The coefficient matrix 
 
 
 
 
0.4
0
0.4
0.25
−


=


−


A
 
 
 
has characteristic equation  
2
0.65
0.10
0
λ
λ
+
+
=
 with eigenvalues λ1  =  -0.4  and   
 
λ2  =  -0.25.  We find easily that the associated eigenvectors are  v1  =  [3   -8]T  and   
 
v2  =  [0     1]T,  so we get the general solution 
 
 
 
 
0.2
0.2
0.4
1
1
2
1
2
( )
3
,
( )
8
.
t
t
t
x t
c e
x t
c e
c e
−
−
−
=
= −
+
 
 
 
The initial conditions  
1
2
(0)
15,
(0)
0
x
x
=
=
  give  
1
2
5 and
40,
c
c
=
=
 so we get  
 
 
 
 
x1(t)  =  15e-0.4t,   
x2(t)  =  -40e-0.4t + 40e-0.25t. 
 

 
Section 7.3 
365 
 
To find the maximum value of  x2(t),  we solve the equation  
2( )
0
x t
′
=
  for   
tm = 20
8
3
5
ln , which gives the maximum value  
2(
)
6.85
m
x t
≈
 lb.  The following figure 
shows the graphs of  
1
2
( ) and
( ).
x t
x t  
 
0
5
10
15
20
0
5
10
15
t
x
x1 
x2 
 
 
 
 
29. 
The coefficient matrix 
 
 
 
 
0.2
0.4
0.2
0.4
−


=


−


A
 
 
 
has eigenvalues  λ1  =  0  and  λ2  =  -0.6,  with eigenvectors  v1  =  [2     1]T  and   
 
v2  =  [1   -1]T  that yield the general solution 
 
 
 
 
0.6
0.6
1
1
2
2
1
2
( )
2
,
( )
.
t
t
x t
c
c e
x t
c
c e
−
−
=
+
=
−
 
 
 
The initial conditions  
1
2
(0)
15,
(0)
0
x
x
=
=
  give  
1
2
5,
c
c
=
=
 so we get  
 
 
 
 
 
 
0.6
0.6
1
2
( )
10
5
,
( )
5
5
.
t
t
x t
e
x t
e
−
−
=
+
=
−
 
 
The figure at the top of the next page shows the graphs of  
1
2
( ) and
( ).
x t
x t  
 
 
 

366 
Chapter 7 
 
0
5
10
15
0
5
10
15
t
x
x1 
x2 
 
 
 
 
30. 
The coefficient matrix 
 
 
 
 
0.4
0.25
0.4
0.25
−


=


−


A
 
 
 
has eigenvalues  λ1  =  0  and  λ2  =  -0.65,  with eigenvectors  v1  =  [5     8]T  and   
 
v2  =  [1   -1]T  that yield the general solution 
 
 
 
 
0.65
0.65
1
1
2
2
1
2
( )
5
,
( )
8
.
t
t
x t
c
c e
x t
c
c e
−
−
=
+
=
−
 
 
 
The initial conditions  
1
2
(0)
15,
(0)
0
x
x
=
=
  give  
1
2
15/13,
120/13,
c
c
=
=
 so we get 
 
 
 
 
 
x1(t)  =  ( 75 + 120e-0.65t)/13 
 
 
 
 
x2(t)  =  (120 - 120e-0.65t)/13. 
 
The figure at the top of the next page shows the graphs of  
1
2
( ) and
( ).
x t
x t  
 
 

 
Section 7.3 
367 
0
5
10
15
0
5
10
15
t
x
x1 
x2 
 
 
 
31. 
The coefficient matrix 
 
 
 
 
1
0
0
1
2
0
0
2
3
−




=
−


−




A
 
 
 
has as eigenvalues its diagonal elements  λ1  =  -1,  λ2  =  -2,  and  λ3  =  -3.  We find 
readily that the associated eigenvectors are  v1  =  [1   1   1]T,   v2  =  [0   1   2]T,  and   
 
v3  =  [0   0   1]T.   The resulting general solution is solution is given by 
 
 
 
 
 
1
1
2
2
1
2
2
3
3
1
2
3
( )
( )
( )
2
.
t
t
t
t
t
t
x t
c e
x t
c e
c e
x t
c e
c e
c e
−
−
−
−
−
−
=
=
+
=
+
+
 
 
 
The initial conditions  
1
2
2
(0)
27,
(0)
(0)
0
x
x
x
=
=
=
  give  
1
3
2
27,
27,
c
c
c
=
=
= −
 so we 
get  
1
2
2
2
3
3
( )
27
( )
27
27
( )
27
54
27
.
t
t
t
t
t
t
x t
e
x t
e
e
x t
e
e
e
−
−
−
−
−
−
=
=
−
=
−
+
 
 
 
The equation  
3( )
0
x t
′
=
 simplifies to the equation 
 

368 
Chapter 7 
 
 
 
(
)(
)
2
3
4
1
3
1
1
0
t
t
t
t
e
e
e
e
−
−
−
−
−
+
=
−
−
=
 
 
with positive solution  
ln3.
mt =
  Thus the maximum amount of salt ever in tank 3 is  
3(ln3)
4
x
=
  pounds.  The figure below shows the graphs of  
1
2
3
( ),
( ), and
( ).
x t
x t
x t
 
 
0
5
0
5
10
15
20
25
t
x
x1 
x2 
x3 
 
 
 
32. 
The coefficient matrix 
 
 
 
 
3
0
0
3
2
0
0
2
1
−




=
−


−




A
 
 
 
has as eigenvalues its diagonal elements  λ1  =  -3,  λ2  =  -2,  and  λ3  =  -1.  We find 
readily that the associated eigenvectors are  v1  =  [1  -3    3]T,   v2  =  [0   -1    2]T,  and  
v3  =  [0    0    1]T.   The resulting general solution is solution is given by 
 
 
 
 
 
3
1
1
3
2
2
1
2
3
2
3
1
2
3
( )
( )
3
( )
3
2
.
t
t
t
t
t
t
x t
c e
x t
c e
c e
x t
c e
c e
c e
−
−
−
−
−
−
=
= −
−
=
+
+
 
 
 
The initial conditions  
1
2
2
(0)
45,
(0)
(0)
0
x
x
x
=
=
=
  give  
1
2
3
45,
135,
135,
c
c
c
=
= −
=
 
so we get  

 
Section 7.3 
369 
3
1
3
2
2
3
2
3
( )
45
( )
135
135
( )
135
270
135
.
t
t
t
t
t
t
x t
e
x t
e
e
x t
e
e
e
−
−
−
−
−
−
=
= −
+
=
−
+
 
 
 
The equation  
3( )
0
x t
′
=
 simplifies to the equation 
 
 
 
 
(
)(
)
2
3
4
1
3
1
1
0
t
t
t
t
e
e
e
e
−
−
−
−
−
+
=
−
−
=
 
 
with positive solution  
ln3.
mt =
  Thus the maximum amount of salt ever in tank 3 is  
3
20
(ln3)
x
=
  pounds.  The figure below shows the graphs of  
1
2
3
( ),
( ), and
( ).
x t
x t
x t
 
 
0
5
0
5
10
15
20
25
30
35
40
45
t
x
x1 
x2 
x3 
 
 
 
33. 
The coefficient matrix 
 
 
 
 
4
0
0
4
6
0
0
6
2
−




=
−


−




A
 
 
 
has as eigenvalues its diagonal elements  λ1  =  -4,  λ2  =  -6,  and  λ3  =  -2.  We find 
readily that the associated eigenvectors are  v1  =  [-1   -2    6]T,   v2  =  [0   -2    3]T,  
and  v3  =  [0    0    1]T.   The resulting general solution is solution is given by 
 

370 
Chapter 7 
 
 
 
 
4
1
1
4
6
2
1
2
4
6
2
3
1
2
3
( )
( )
2
2
( )
6
3
.
t
t
t
t
t
t
x t
c e
x t
c e
c e
x t
c e
c e
c e
−
−
−
−
−
−
= −
= −
−
=
+
+
 
 
 
The initial conditions  
1
2
2
(0)
45,
(0)
(0)
0
x
x
x
=
=
=
  give  
1
2
3
45,
45,
135,
c
c
c
= −
=
=
 so 
we get  
4
1
4
6
2
4
6
2
3
( )
45
( )
90
90
( )
270
135
135
.
t
t
t
t
t
t
x t
e
x t
e
e
x t
e
e
e
−
−
−
−
−
−
=
=
−
= −
+
+
 
 
 
The equation  
3( )
0
x t
′
=
 simplifies to the equation 
 
 
 
 
(
)(
)
4
2
2
2
3
4
1
3
1
1
0
t
t
t
t
e
e
e
e
−
−
−
−
−
+
=
−
−
=
 
 
with positive solution  
1
2 ln3.
mt =
  Thus the maximum amount of salt ever in tank 3 is  
1
2
3
20
( ln3)
x
=
  pounds.  The figure below shows the graphs of  
1
2
3
( ),
( ), and
( ).
x t
x t
x t
 
 
0
2
0
5
10
15
20
25
30
35
40
45
t
x
x1 
x2 
x3 
 
 
34. 
The coefficient matrix 
 
 
 
 
3
0
0
3
5
0
0
5
1
−




=
−


−




A
 

 
Section 7.3 
371 
 
has as eigenvalues its diagonal elements  λ1  =  -3,  λ2  =  -5,  and  λ3  =  -1.  We find 
readily that the associated eigenvectors are  v1  =  [-4   -6    15]T,   v2  =  [0   -4     5]T,  
and  v3  =  [0     0     1]T.   The resulting general solution is solution is given by 
 
 
 
 
 
 
3
1
1
3
5
2
1
2
3
5
3
1
2
3
( )
4
( )
6
4
( )
15
5
.
t
t
t
t
t
t
x t
c e
x t
c e
c e
x t
c e
c e
c e
−
−
−
−
−
−
= −
= −
−
=
+
+
 
 
 
The initial conditions  
1
2
2
(0)
40,
(0)
(0)
0
x
x
x
=
=
=
  give  
1
2
3
10,
15,
75,
c
c
c
= −
=
=
 so 
we get  
 
 
 
 
3
1
3
5
2
3
5
3
( )
40
( )
60
60
( )
150
75
75
.
t
t
t
t
t
t
x t
e
x t
e
e
x t
e
e
e
−
−
−
−
−
−
=
=
−
= −
+
+
 
 
 
The equation  
3( )
0
x t
′
=
 simplifies to the equation 
 
 
 
 
(
)(
)
4
2
2
2
5
6
1
5
1
1
0
t
t
t
t
e
e
e
e
−
−
−
−
−
+
=
−
−
=
 
 
with positive solution  
1
2 ln5.
mt =
  Thus the maximum amount of salt ever in tank 3 is 
1
2
3( ln5)
21.4663
x
≈
  pounds.  The figure below shows the graphs of  
1
2
( ),
( ),
x t
x t
 
3
and
( )
x t . 
 
 
0
4
0
5
10
15
20
25
30
35
40
t
x
x1 
x2 
x3 
 

372 
Chapter 7 
35. 
The coefficient matrix 
 
 
 
 
6
0
3
6
20
0
0
20
3
−




=
−


−




A
 
 
 
has characteristic equation  
3
2
29
198
(
18)(
11)
0
λ
λ
λ
λ λ
λ
−
−
−
= −
−
−
=
 with  
eigenvalues  λ0  =  0,  λ1  =  -18,  and  λ2  =  -11.  We find that associated eigenvectors 
are  v0  =  [10     3     20]T,   v1  =  [-1   -3     4]T,  and  v2  =  [-3   -2    5]T.   The 
resulting general solution is solution is given by 
 
 
 
 
 
18
11
1
0
1
2
18
11
2
0
1
2
18
11
3
0
1
2
( )
10
3
( )
3
3
2
( )
20
4
5
.
t
t
t
t
t
t
x t
c
c e
c e
x t
c
c e
c e
x t
c
c e
c e
−
−
−
−
−
−
=
−
−
=
−
−
=
+
+
 
 
 
The initial conditions  
1
2
2
(0)
33,
(0)
(0)
0
x
x
x
=
=
=
  give  
1
2
3
1,
55/7,
72/7,
c
c
c
=
=
= −
 
so we get  
(
)
(
)
(
)
18
11
1
1
7
18
11
1
2
7
18
11
1
3
7
( )
10
55
216
( )
3
165
144
( )
20
220
360
.
t
t
t
t
t
t
x t
e
e
x t
e
e
x t
e
e
−
−
−
−
−
−
=
−
−
=
−
−
=
+
−
 
 
Thus the limiting amounts of salt in tanks 1, 2, and 3 are 10 lb, 3 lb, and 20 lb.  The 
figure below shows the graphs of  
1
2
( ),
( ),
x t
x t
 
3
and
( )
x t . 
 
0
1
0
5
10
15
20
25
30
t
x
x1 
x2 
x3 
 

 
Section 7.3 
373 
36. 
The coefficient matrix 
 
 
 
 
1
1
2
2
1
1
2
5
1
1
5
2
0
0
0
−




=
−




−


A
 
 
 
has characteristic equation  
3
2
(6/5)
(9/ 20)
0
λ
λ
λ
−
−
−
=
 with  eigenvalues  λ0  =  0,   
 
λ1  =  -3(2 + i)/10,  and  λ2  =  -3(2 - i)/10.  The eigenvector equation 
 
 
 
 
 
1
1
2
2
1
1
2
5
1
1
5
2
0
0
0
0
0
0
a
b
c
−






−
=





−






 
 
 
associated with the eigenvalue  λ0  =  0  yields the associated eigenvector 
 
v0  =  [1    5/2    1]T and consequently the constant solution  
0
0
( )
.
t
≡
x
v  Then the 
eigenvector equation   
 
 
 
 
1
1
10
2
1
1
2
10
1
1
5
10
(1
3 )
0
0
(4
3 )
0
0
0
(1
3 )
0
i
a
i
b
i
c
+






+
=





+






 
 
 
associated with  λ1  =  -3(2 + i)/10  yields the complex-valued eigenvector 
 
v1  =  [-(1-3 i)/2     -(1+3 i)/2      1]T.  The corresponding complex-valued solution is 
 
     
   
(
)
(
)
(
)
(
)
( 6 3 ) /10
1
1
3 /5
( )
cos(3 /10)
3sin(3 /10)
3cos(3 /10)
sin(3 /10)
1
cos(3 /10)
3sin(3 /10)
3cos(3 /10)
sin(3 /10)
.
2
2cos(3 /10)
2 sin(3 /10)
i t
t
t
e
t
t
i
t
t
e
t
t
i
t
t
t
i
t
−−
−
=
−
+
+
+




=
−
−
+
−
+




−


x
v
 
 
 
The scalar components of resulting general solution  
0
0
1
1
2
1
Re(
)
Im(
)
c
c
c
=
+
+
x
x
x
x
 are 
given by 
 
 
(
)
(
)
(
)
(
)
[
]
3 /5
1
1
0
1
2
1
2
2
3 /5
5
1
2
0
1
2
1
2
2
2
3 /5
3
0
1
2
( )
3
cos(3 /10)
3
sin(3 /10)
( )
3
cos(3 /10)
3
sin(3 /10)
( )
cos(3 /10)
sin(3 /10) .
t
t
t
x t
c
e
c
c
t
c
c
t
x t
c
e
c
c
t
c
c
t
x t
c
e
c
t
c
t
−
−
−
=
+
−
+
+
+




=
+
−
−
+ −
+




=
+
−
 
 
 
When we impose the initial conditions  
1
2
2
(0)
18,
(0)
(0)
0
x
x
x
=
=
=
 we find that 
 
0
1
2
4,
4, and
8.
c
c
c
=
= −
=
This finally gives the particular solution 
 

374 
Chapter 7 
[
]
[
]
[
]
3 /5
1
3 /5
2
3 /5
3
( )
4
14cos(3 /10)
2sin(3 /10)
( )
10
10cos(3 /10)
10sin(3 /10)
( )
4
4cos(3 /10)
8sin(3 /10) .
t
t
t
x t
e
t
t
x t
e
t
t
x t
e
t
t
−
−
−
=
+
−
=
−
−
=
−
+
 
 
Thus the limiting amounts of salt in tanks 1, 2, and 3 are 4 lb, 10 lb, and 4 lb.  The figure 
below shows the graphs of  
1
2
( ),
( ),
x t
x t
 
3
and
( )
x t . 
 
0
5
10
0
5
10
15
t
x
x1 
x2 
x3 
 
 
 
37. 
The coefficient matrix 
1
0
2
1
3
0
0
3
2
−




=
−


−




A
 
 
 
has characteristic equation  
3
2
6
11
0
λ
λ
λ
−
−
−
=
 with  eigenvalues  λ0  =  0,  λ1  =  
3
2
i
−−
,  and  λ2  =  
.
3
2
i
−+
  The eigenvector equation 
 
 
 
 
 
1
0
2
0
1
3
0
0
0
3
2
0
a
b
c
−






−
=



−






 
 
 
associated with the eigenvalue  λ0  =  0  yields the associated eigenvector 

 
Section 7.3 
375 
 
v0  =  [6    2    3]T and consequently the constant solution  
0
0
( )
.
t
≡
x
v  Then the  
eigenvector equation   
 
 
 
 
2
2
0
2
0
1
2
0
0
0
0
3
1
2
i
a
i
b
c
i


+





=






+






 
 
 
associated with  λ1  =  3
2
i
−−
  yields the complex-valued eigenvector 
T
1
( 2
2)/3
( 1
2)/3
1
i
i


=
−+
−−


v
.  The corresponding complex-valued solution 
is  
 
 
      
(
)
(
)
(
)
(
)
( 3
2 )
1
1
3
( )
2cos(
2)
2 sin(
2)
2 cos(
2)
2sin(
2)
1
cos(
2)
2 sin(
2)
2 cos(
2)
sin(
2)
.
3
3cos(
2)
3 sin(
2)
i
t
t
t
e
t
t
i
t
t
e
t
t
i
t
t
t
i
t
−−
−
=


−
+
+
+




=
−
−
+
−
+




−




x
v
 
 
 
The scalar components of resulting general solution  
0
0
1
1
2
1
Re(
)
Im(
)
c
c
c
=
+
+
x
x
x
x
 are 
given by 
 
 
(
)
(
)
(
)
(
)
3
1
1
0
1
2
1
2
3
3
1
2
0
1
2
1
2
3
3
3
0
1
2
( )
6
2
2
cos(
2)
2
2
sin(
2)
( )
2
2
cos(
2)
2
sin(
2)
( )
3
cos(
2)
sin(
2) .
t
t
t
x t
c
e
c
c
t
c
c
t
x t
c
e
c
c
t
c
c
t
x t
c
e
c
t
c
t
−
−
−


=
+
−
+
+
+




=
+
−
−
+ −
+




=
+
−


 
 
 
When we impose the initial conditions  
1
2
2
(0)
55,
(0)
(0)
0
x
x
x
=
=
=
 we find that 
 
0
1
2
5,
15, and
45/
2.
c
c
c
=
= −
=
This finally gives the particular solution 
 
3
1
3
25
2
2
3
45
3
2
( )
30
25cos(
2)
10 2 sin(
2)
( )
10
10cos(
2)
2 sin(
2)
( )
15
15cos(
2)
2 sin(
2) .
t
t
t
x t
e
t
t
x t
e
t
t
x t
e
t
t
−
−
−


=
+
+




=
−
−




=
−
+


 
 
Thus the limiting amounts of salt in tanks 1, 2, and 3 are 30 lb, 10 lb, and 15 lb.  The 
figure at the top of the next page shows the graphs of  
1
2
( ),
( ),
x t
x t
 
3
and
( )
x t . 
 

376 
Chapter 7 
0
2
0
5
10
15
20
25
30
35
40
45
50
55
t
x
x1 
x2 
x3 
 
 
 
 
In Problems 38–41 the Maple command  with(linalg):eigenvects(A),  the Mathematica 
command  Eigensystem[A], or the MATLAB command  [V,D] = eig(A) can be used to 
find the eigenvalues and associated eigenvectors of the given coefficient matrix  A. 
 
38. 
Characteristic equation:  (λ - 1)(λ - 2)(λ - 3)(λ - 4)  =  0 
 
Eigenvalues and associated eigenvectors: 
 
 
 
λ  =  1,   
v   =  [1    -2       3    -4]T     
 
 
λ  =  2,   
v   =  [0       1    -3       6]T     
 
 
λ  =  3,   
v   =  [0       0       1     -4]T 
 
 
λ  =  4,   
v   =  [0       0       0       1]T 
 
 
 
Scalar solution equations: 
 
 
 
x1(t)  =     c1et  
 
 
x2(t)  = -2c1et +  c2e2t  
 
 
x3(t)  =   3c1et - 3c2e2t +  c3e3t  
 
 
x4(t)  = -4c1et + 6c2e2t - 4c3e3t + c4e4t 
 
 

 
Section 7.3 
377 
39. 
Characteristic equation:   (λ2 - 1)(λ2 - 4)  =  0 
 
Eigenvalues and associated eigenvectors: 
 
 
 
λ  =    1,   
v   =  [3    -2     4    1]T     
 
 
λ  = -1,   
v   =  [0     0     1    0]T     
 
 
λ  =    2,   
v   =  [0     1     0    0]T 
 
 
λ  = -2,   
v   =  [1    -1     0    0]T 
 
 
Scalar solution equations: 
 
 
 
x1(t)  =   3c1et                         + c4e-2t 
 
 
x2(t)  = -2c1et            +  c3e2t - c4e-2t 
 
 
x3(t)  =   4c1et + c2e-t   
 
 
x4(t)  =     c1et  
 
40. 
Characteristic equation:   (λ2 - 4)(λ2 - 25)  =  0 
 
Eigenvalues and associated eigenvectors: 
 
 
 
λ  =   2,   
v   =  [1    -3     0      0]T     
 
 
λ  =  -2,   
v   =  [0      3     0    -1]T     
 
 
λ  =   5,   
v   =  [0      0     1    -3]T 
 
 
λ  =  -5,   
v   =  [0      1     0      0]T 
 
 
Scalar solution equations: 
 
 
 
x1(t)  =     c1e2t  
 
 
x2(t)  = -3c1e2t + 3c2e-2t             - c4e-5t 
 
 
x3(t)  =                                 c3e5t  
 
 
x4(t)  =               -c2e-2t - 3c3e5t  
 
41. 
The eigenvectors associated with the respective eigenvalues  λ1  =  -3,  λ2  =  -6,   
 
λ3  =  10,  and  λ4  =  15  are 
 
                
 
v1  =  [  1     0     0    -1]T    
                
 
v2  =  [  0     1   -1       0]T    
                
 
v3  =  [-2     1     1    -2]T    
                
 
v4  =  [  1     2     2      1]T. 
 
 
Hence the general solution has scalar component functions 

378 
Chapter 7 
 
     
 
  
 
x1(t)  =    c1e-3t           - 2c3e10t  +   c4e15t   
 
      
 
x2(t)  =               c2e-6t +   c3e10t  + 2c4e15t   
 
      
 
x3(t)  =           - c2e-6t +   c3e10t  + 2c4e15t   
 
      
 
x4(t)  = -c1e-3t           - 2c3e10t  +   c4e15t . 
 
 
The given initial conditions are satisfied by choosing  c1  =  c2  =  0,  c3  =  -1,  and   
 
c4  =  1,  so the desired particular solution is given by 
 
                
 
x1(t)  =   2e10t +  e15t  =  x4(t)    
                
 
x2(t)  =  -e10t + 2e15t  =  x3(t)  . 
 
 
In Problems 42–50 we give a general solution in the form 
1
2
1
1
2
2
( )
t
t
t
c
e
c
e
λ
λ
=
+
+
x
v
v
 that 
exhibits explicitly the eigenvalues  
1
2
,
,
λ λ … and corresponding eigenvectors  
1
2
,
,
v
v … of the 
given coefficient matrix  A. 
 
42. 
2
5
1
2
3
3
1
2
( )
1
1
3
2
1
1
t
t
t
c
c
e
c
e










=
−
+
+
−















x
 
 
43. 
2
4
8
1
2
3
3
1
1
( )
1
1
1
5
1
3
t
t
t
t
c
e
c
e
c
e
−










=
−
+
+
−















x
 
 
44. 
3
6
12
1
2
3
3
7
5
( )
2
1
3
2
5
3
t
t
t
t
c
e
c
e
c
e
−










=
−
+
+
−















x
 
 
45. 
3
3
6
1
2
3
4
1
1
2
1
1
2
1
1
( )
1
1
1
2
1
1
1
1
t
t
t
t
c
e
c
c
e
c
e
−














−







=
+
+
+
−














−
−







x
 
 

 
Section 7.3 
379 
46. 
4
2
4
8
1
2
3
4
3
1
1
3
2
2
1
2
( )
1
2
1
3
1
1
1
3
t
t
t
t
t
c
e
c
e
c
e
c
e
−
















−








=
+
+
+
−
−
















−
−








x
 
 
47. 
3
3
6
9
1
2
3
4
2
1
2
1
2
2
1
1
( )
1
1
1
2
1
1
1
1
t
t
t
t
t
c
e
c
e
c
e
c
e
−














−







=
+
+
+
−














−
−







x
 
 
48. 
16
32
48
64
1
2
3
4
1
2
3
1
2
5
1
1
( )
1
1
1
2
2
1
2
3
t
t
t
t
t
c
e
c
e
c
e
c
e
















−








=
+
+
+
−
















−
−








x
 
 
49. 
3
3
6
9
1
2
3
4
5
1
0
1
0
2
0
3
7
1
0
( )
3
0
1
0
5
1
1
1
1
2
1
1
1
1
1
t
t
t
t
t
c
e
c
c
e
c
e
c
e
−


















=
+
+
+
+












−


















x
 
50. 
7
4
3
5
9
11
1
2
3
4
5
6
0
1
0
0
1
0
1
0
1
0
1
0
1
0
0
1
0
1
( )
1
0
1
0
0
1
0
1
0
1
0
1
1
1
1
0
1
0
t
t
t
t
t
t
c
e
c
e
c
e
c
e
c
e
c
e
−
−




























=
+
+
+
+
+







−














−





















x
t  
 
 
SECTION 7.4 
 
SECOND-ORDER SYSTEMS 
AND MECHANICAL APPLICATIONS 
 
This section uses the eigenvalue method to exhibit realistic applications of linear systems.  If a 
computer system like Maple, Mathematica, MATLAB, or even a TI-85/86/89/92 calculator is 

380 
Chapter 7 
available, then a system of more than three railway cars, or a multistory building with four or 
more floors (as in the project), can be investigated.  However, the problems in the text are 
intended for manual solution. 
 
Problems 1–7 involve the system 
 
            
 
 
m1x1″  =  -(k1 + k2)x1 +           k2x2 
            
 
 
m2x2″  =               k2x1 - (k2 + k3)x2 
 
with various values of  m1, m2  and  k1, k2, k3.  In each problem we divide the first equation by  m1  
and the second one by  m2  to obtain a second-order linear system  ′′ =
x
Ax  in the standard 
form of Theorem 1 in this section.  If the eigenvalues 
1
2
and
λ
λ  are both negative, then the 
natural (circular) frequencies of the system are  
1
1
2
2
and
,
ω
λ
ω
λ
=
−
=
−
  and — according to 
Eq. (11) in Theorem 1 of this section — the eigenvalues  
1
2
and
v
v  associated with 
1
2
and
λ
λ  
determine the natural modes of oscillations at these frequencies. 
 
1. 
The matrix  
2
2
2
2
−


= 

−


A
  has eigenvalues  
0
1
0 and
4
λ
λ
=
= − with associated 
eigenvalues  
T
T
0
1
[1
1]
and
[1
1] .
=
=
−
v
v
  Thus we have the special case described 
in Eq. (12) of Theorem 1, and a general solution is given by 
 
 
 
 
1
1
2
1
2
2
1
2
1
2
( )
cos2
sin2 ,
( )
cos2
sin2 .
x t
a
a t
b
t
b
t
x t
a
a t
b
t
b
t
=
+
+
+
=
+
−
−
 
 
 
The natural frequencies are  ω1  =  0  and  ω2  =  2.  In the degenerate natural mode with 
"frequency"  ω1  =  0  the two masses move by translation without oscillating.  At 
frequency  ω2  =  2  they oscillate in opposite directions with equal amplitudes. 
 
2. 
The matrix  
5
4
5
5
−


= 

−


A
  has eigenvalues  
1
2
1 and
9
λ
λ
= −
= − with associated 
eigenvalues  
T
T
1
2
[1
1]
and
[1
1] .
=
=
−
v
v
  Hence a general solution is given by 
 
 
 
 
1
1
2
1
2
2
1
2
1
2
( )
cos
sin
cos3
sin3 ,
( )
cos
sin
cos3
sin3 .
x t
a
t
a
t
b
t
b
t
x t
a
t
a
t
b
t
b
t
=
+
+
+
=
+
−
−
 
 
3. 
The matrix  
3
2
1
2
−


= 

−


A
  has eigenvalues  
1
2
1 and
4
λ
λ
= −
= − with associated 
eigenvalues  
T
T
1
2
[1
1]
and
[2
1] .
=
=
−
v
v
  Hence a general solution is given by 

 
Section 7.4 
381 
 
 
 
1
1
2
1
2
2
1
2
1
2
( )
cos
sin
2
cos2
2
sin2 ,
( )
cos
sin
cos2
sin2 .
x t
a
t
a
t
b
t
b
t
x t
a
t
a
t
b
t
b
t
=
+
+
+
=
+
−
−
 
 
 
The natural frequencies are  ω1  =  1  and  ω2  =  2.  In the natural mode with frequency  
ω1,  the two masses  m1  and  m2  move in the same direction with equal amplitudes of 
oscillation.  In the natural mode with frequency  ω2  they move in opposite directions 
with the amplitude of oscillation of  m1  twice that of  m2. 
 
4. 
The matrix  
3
2
2
3
−


= 

−


A
  has eigenvalues  
1
2
1 and
5
λ
λ
= −
= − with associated 
eigenvalues  
T
T
1
2
[1
1]
and
[1
1] .
=
=
−
v
v
  Hence a general solution is given by 
 
 
 
 
1
1
2
1
2
2
1
2
1
2
( )
cos
sin
cos
5
sin
5,
( )
cos
sin
cos
5
sin
5.
x t
a
t
a
t
b
t
b
t
x t
a
t
a
t
b
t
b
t
=
+
+
+
=
+
−
−
 
 
 
The natural frequencies are  
1
2
1 and
5.
ω
ω
=
=
  In the natural mode with frequency  
ω1,  the two masses  m1  and  m2  move in the same direction with equal amplitudes of 
oscillation.  At frequency  ω2  they move in opposite directions with equal amplitudes. 
 
5. 
The matrix  
3
1
1
3
−


= 

−


A
  has eigenvalues  
1
2
2 and
4
λ
λ
= −
= − with associated 
eigenvalues  
T
T
1
2
[1
1]
and
[1
1] .
=
=
−
v
v
  Hence a general solution is given by 
 
 
 
 
1
1
2
1
2
2
1
2
1
2
( )
cos
2
sin
2
cos2
sin2 ,
( )
cos
2
sin
2
cos2
sin2 .
x t
a
t
a
t
b
t
b
t
x t
a
t
a
t
b
t
b
t
=
+
+
+
=
+
−
−
 
 
 
The natural frequencies are  
1
2
2 and
2.
ω
ω
=
=
  In the natural mode with frequency  
ω1,  the two masses  m1  and  m2  move in the same direction with equal amplitudes of 
oscillation.  At frequency  ω2  they move in opposite directions with equal amplitudes. 
 
6. 
The matrix  
6
4
2
4
−


= 

−


A
  has eigenvalues  
1
2
2 and
8
λ
λ
= −
= − with associated 
eigenvalues  
T
T
1
2
[1
1]
and
[2
1] .
=
=
−
v
v
  Hence a general solution is given by 
 
 
 
 
1
1
2
1
2
2
1
2
1
2
( )
cos
2
sin
2
2
cos
8
2
sin
8,
( )
cos
2
sin
2
cos
8
sin
8.
x t
a
t
a
t
b
t
b
t
x t
a
t
a
t
b
t
b
t
=
+
+
+
=
+
−
−
 
 

382 
Chapter 7 
 
The natural frequencies are  
1
2
2 and
8.
ω
ω
=
=
  In the natural mode with frequency  
ω1,  the two masses  m1  and  m2  move in the same direction with equal amplitudes of 
oscillation.  In the natural mode with frequency  ω2  they move in opposite directions 
with the amplitude of oscillation of  m1  twice that of  m2. 
 
7. 
The matrix  
10
6
6
10
−


= 

−


A
  has eigenvalues  
1
2
4 and
16
λ
λ
= −
= −
 with associated 
eigenvalues  
T
T
1
2
[1
1]
and
[1
1] .
=
=
−
v
v
  Hence a general solution is given by 
 
 
 
 
1
1
2
1
2
2
1
2
1
2
( )
cos2
sin2
cos4
sin4 ,
( )
cos2
sin2
cos4
sin4 .
x t
a
t
a
t
b
t
b
t
x t
a
t
a
t
b
t
b
t
=
+
+
+
=
+
−
−
 
 
 
The natural frequencies are  ω1  =  2  and  ω2  =  4.  In the natural mode with frequency  
ω1,  the two masses  m1  and  m2  move in the same direction with equal amplitudes of 
oscillation.  At frequency  ω2  they move in opposite directions with equal amplitudes. 
 
 
8. 
Substitution of the trial solution  
1
1
2
2
cos5 ,
cos5
x
c
t
x
c
t
=
=
 in the system 
 
 
 
 
1
1
2
2
1
2
5
4
96cos5 ,
4
5
x
x
x
t
x
x
x
′′
′′
= −
+
+
=
−
 
 
 
yields  
1
2
5,
1,
c
c
= −
=
 so a general solution is given by 
 
 
 
1
1
2
1
2
2
1
2
1
2
( )
cos
sin
cos3
sin3
5cos5 ,
( )
cos
sin
cos3
sin3
cos5 .
x t
a
t
a
t
b
t
b
t
t
x t
a
t
a
t
b
t
b
t
t
=
+
+
+
−
=
+
−
−
+
 
 
Imposition of the initial conditions  
1
2
1
2
(0)
(0)
(0)
(0)
0
x
x
x
x
′
′
=
=
=
=
 now yields  
1
2
1
2
2,
0,
3,
0.
a
a
b
b
=
=
=
=
  The resulting particular solution is 
 
 
 
1
2
( )
2cos
3cos3
5cos5 ,
( )
2cos
3cos3
cos5 .
x t
t
t
t
x t
t
t
t
=
+
−
=
−
+
 
 
 
We have a superposition of three oscillations, in which the two masses move 
 
• in the same direction with frequency  ω1 = 1  and equal amplitudes; 
• in opposite directions with frequency ω2 = 3  and equal amplitudes; 
• in opposite directions with frequency ω3 = 5  and with the amplitude of 
motion of m1 being 5 times that of m2. 
 
 
 

 
Section 7.4 
383 
9. 
Substitution of the trial solution  
1
1
2
2
cos3 ,
cos3
x
c
t
x
c
t
=
=
 in the system 
 
 
 
 
1
1
2
2
1
2
3
2
,
2
2
4
120cos3
x
x
x
x
x
x
t
′′
′′
= −
+
=
−
+
 
 
 
yields  
1
2
3,
9,
c
c
=
= −
 so a general solution is given by 
 
 
 
1
1
2
1
2
2
1
2
1
2
( )
cos
sin
2
cos2
2
sin2
3cos3 ,
( )
cos
sin
cos2
sin2
9cos3 .
x t
a
t
a
t
b
t
b
t
t
x t
a
t
a
t
b
t
b
t
t
=
+
+
+
+
=
+
−
−
−
 
 
Imposition of the initial conditions  
1
2
1
2
(0)
(0)
(0)
(0)
0
x
x
x
x
′
′
=
=
=
=
 now yields  
1
2
1
2
5,
0,
4,
0.
a
a
b
b
=
=
= −
=
  The resulting particular solution is 
 
 
 
1
2
( )
5cos
8cos2
3cos3 ,
( )
5cos
4cos2
9cos3 .
x t
t
t
t
x t
t
t
t
=
−
+
=
+
−
 
 
 
We have a superposition of three oscillations, in which the two masses move 
 
• in the same direction with frequency  ω1 = 1  and equal amplitudes; 
• in opposite directions with frequency ω2 = 2  and with the amplitude of 
motion of m1 being twice that of m2; 
• in opposite directions with frequency ω3 = 3  and with the amplitude of 
motion of m2 being 3 times that of m1. 
 
 
10. 
Substitution of the trial solution  
1
1
2
2
cos ,
cos
x
c
t
x
c
t
=
=
 in the system 
 
 
 
 
1
1
2
2
1
2
10
6
30cos ,
6
10
60cos
x
x
x
t
x
x
x
t
′′
′′
= −
+
+
=
−
+
 
 
 
yields  
1
2
14,
16,
c
c
=
=
 so a general solution is given by 
 
 
 
1
1
2
1
2
2
1
2
1
2
( )
cos2
sin2
cos4
sin4
14cos ,
( )
cos2
sin2
cos4
sin4
16cos .
x t
a
t
a
t
b
t
b
t
t
x t
a
t
a
t
b
t
b
t
t
=
+
+
+
+
=
+
−
−
+
 
 
Imposition of the initial conditions  
1
2
1
2
(0)
(0)
(0)
(0)
0
x
x
x
x
′
′
=
=
=
=
 now yields  
1
2
1
2
1,
0,
15,
0.
a
a
b
b
=
=
= −
=
  The resulting particular solution is 
 
 
 
1
2
( )
cos2
15cos4
14cos ,
( )
cos2
15cos4
16cos .
x t
t
t
t
x t
t
t
t
=
−
+
=
+
+
 
 
 
We have a superposition of three oscillations, in which the two masses move 
 

384 
Chapter 7 
• in the same direction with frequency  ω1 = 1  and with the amplitude of 
motion of m2 being 8/7 times that of m1; 
• in the same direction with frequency ω2 = 2  and equal amplitudes; 
• in opposite directions with frequency ω3 = 4  and equal amplitudes. 
 
11. 
(a) 
The matrix  
40
8
12
60
−


= 

−


A
  has eigenvalues  
1
2
36 and
64
λ
λ
= −
= −
 with 
associated eigenvalues  
T
T
2
2
[2
1]
and
[1
3] .
=
=
−
v
v
  Hence a general solution is 
given by 
 
 
 
1
2
1
2
1
2
1
2
( )
2
cos6
2
sin6
cos8
sin8 ,
( )
cos6
sin6
3 cos8
3
sin8 .
x t
a
t
a
t
b
t
b
t
y t
a
t
a
t
b
t
b
t
=
+
+
+
=
+
−
−
 
 
 
The natural frequencies are  ω1  =  6  and  ω2  =  8.  In mode 1 the two masses oscillate in 
the same direction with frequency  ω1 = 6  and with the amplitude of motion of m1 being 
twice that of m2.  In mode 2 the two masses oscillate in opposite directions with 
frequency  ω2 = 8  and with the amplitude of motion of m2 being 3 times that of m1. 
 
 
(b) 
Substitution of the trial solution  
1
2
cos7 ,
cos7
x
c
t
y
c
t
=
=
 in the system 
 
 
 
 
40
8
195cos7 ,
12
60
195cos7
x
x
y
t
y
x
y
t
′′
′′
= −
+
−
=
−
−
 
 
 
yields  
1
2
19,
3,
c
c
=
=
 so a general solution is given by 
 
 
 
1
2
1
2
1
2
1
2
( )
2
cos6
2
sin6
cos8
sin8
19cos7 ,
( )
cos6
sin6
3 cos8
3
sin8
3cos7 .
x t
a
t
a
t
b
t
b
t
t
y t
a
t
a
t
b
t
b
t
t
=
+
+
+
+
=
+
−
−
+
 
 
Imposition of the initial conditions  (0)
19,
(0)
12,
(0)
3,
(0)
6
x
x
y
y
′
′
=
=
=
=
 now yields  
1
2
1
2
0,
1,
0,
0.
a
a
b
b
=
=
=
=
  The resulting particular solution is 
 
 
 
 
 
( )
2sin6
19cos7 ,
( )
sin6
3cos7 .
x t
t
t
y t
t
t
=
+
=
+
 
 
Thus the expected oscillation with frequency  ω2 = 8  is missing, and we have a 
superposition of (only two) oscillations, in which the two masses move 
 
• in the same direction with frequency  ω1 = 6  and with the amplitude of 
motion of m1 being twice that of m2; 
• in the same direction with frequency ω3 = 7  and with the amplitude of motion 
of m1 being 19/3 times that of  m2. 
 
 

 
Section 7.4 
385 
12. 
The coefficient matrix   
2
1
0
1
2
1
0
1
2
−




=
−


−




A
 has characteristic polynomial 
 
 
 
λ3 + 6λ2 + 10λ + 4  =  (λ + 2)(λ2 + 4λ + 2).   
 
Its eigenvalues  
1
2
3
2,
2
2,
2
2
λ
λ
λ
= −
= −−
= −+
  have associated eigenvectors 
T
T
T
1
2
3
[1
0
1] ,
[1
2
1] ,
[1
2
1] .
=
−
=
−
=
v
v
v
  Hence the system's three 
natural modes of oscillation have 
 
• Natural frequency  
1
2
ω =
  with amplitude ratios  1 : 0 : –1. 
• Natural frequency  
2
2
2
ω =
+
  with amplitude ratios  1:
2 : 1
−
. 
• Natural frequency  
2
2
2
ω =
−
  with amplitude ratios  1:
2 : 1. 
 
13. 
The coefficient matrix   
4
2
0
2
4
2
0
2
4
−




=
−


−




A
 has characteristic polynomial 
 
 
 
–λ3 – 12λ2 – 40λ – 32  =  –(λ + 4)(λ2 + 8λ + 8).   
 
Its eigenvalues  
1
2
3
4,
4
2 2,
4
2 2
λ
λ
λ
= −
= −−
= −+
  have associated eigenvectors 
T
T
T
1
2
3
[1
0
1] ,
[1
2
1] ,
[1
2
1] .
=
−
=
−
=
v
v
v
  Hence the system's three 
natural modes of oscillation have 
 
• Natural frequency  
1
2
ω =
  with amplitude ratios  1 : 0 : –1. 
• Natural frequency  
2
4
2 2
ω =
+
  with amplitude ratios  1:
2 : 1
−
. 
• Natural frequency  
2
4
2 2
ω =
−
  with amplitude ratios  1:
2 : 1. 
 
14. 
The equations of motion of the given system are 
 
 
 
 
 
    x1″  =  -50x1 + 10(x2 - x1) + 5 cos 10t 
 
 
 
 
m2x2″  =  -10(x2 - x1). 
 
 
When we substitute  x1  =  A cos 10t,  x2  =  B cos 10t  and cancel  cos 10t  throughout we 
get the equations 
      
      
     
 
-40A -                  10B  =  5 
 
       
 
        
-10A + (10 - 100m2)B  =  0. 
 
 
If  m2  =  0.1 (slug)  then it follows that  A  =  0,  so the mass  m1  remains at rest. 

386 
Chapter 7 
 15. 
First we need the general solution of the homogeneous system  x″  =  Ax with 
 
50
25/ 2
50
50
−


=


−


A
 
 
 
The eigenvalues of  A  are  λ1  =  -25  and  λ2  =  -75,  so the natural frequencies of the 
system are  ω1  =  5  and  ω2  =  5 3 .  The associated eigenvectors are  v1  =  [1     2]T  
and  v2  =  [1   -2]T,  so the complementary solution  xc(t)  is given by 
 
 
 
 
1
1
2
1
2
2
1
2
1
2
( )
cos5
sin5
cos5 3
sin5 3 ,
( )
2
cos5
2
sin5
2
cos5 3
2
sin5 3 .
x t
a
t
a
t
b
t
b
t
x t
a
t
a
t
b
t
b
t
=
+
+
+
=
+
−
−
 
 
 
When we substitute the trial solution  xp(t)  =  [c1      c2]Tcos 10t  in the nonhomogeneous 
system, we find that  c1  =  4/3  and  c2  =  -16/3,  so a particular solution  xp(t)  is 
described by 
 
 
 
 
x1(t)  =  (4/3)cos 10t,        x2(t)  =  -(16/3)cos 10t. 
 
 
Finally, when we impose the zero initial conditions on the solution  x(t)  =  xc(t) + xp(t)  
we find that  a1  =  2/3,  a2  =  0,  b1  =  -2,  and  b2  =  0.  Thus the solution we seek is 
described by 
 
 
 
 
x1(t)  =  2
3 cos 5t - 2 cos 5 3t  +  4
3 cos 10t 
 
 
 
x2(t)  =  4
3 cos 5t + 4 cos 5 3t  +  16
3 cos 10t. 
 
 
We have a superposition of two oscillations with the natural frequencies  ω1  =  5  and   
 
ω2  =  5 3   and a forced oscillation with frequency  ω  =  10.  In each of the two natural 
oscillations the amplitude of motion of  m2  is twice that of  m1,  while in the forced 
oscillation the amplitude of motion of  m2  is four times that of  m1. 
 
 
16. 
The characteristic equation of  A  is 
 
 
 
 
(-c1 - λ)(-c2 - λ) - c1c2  =  λ2 + (c1 + c2)λ  =  0, 
 
 
whence the given eigenvalues and eigenvectors follow readily. 
 
 
17. 
With  c1  =  c2  =  2,  it follows from Problem 16 that the natural frequencies and 
associated eigenvectors are  ω1  =  0,  v1  =  [1     1]T  and  ω2  =  2,  v2  =  [1   -1]T.   
 
Hence Theorem 1 gives the general solution 
 

 
Section 7.4 
387 
 
 
 
x1(t)  =  a1 + b1t + a2cos 2t + b2sin 2t 
 
 
 
x2(t)  =  a1 + b1t - a2cos 2t - b2sin 2t. 
 
 
The initial conditions   
1x′ (0)  =  v0,  x1(0)  =  x2(0)  =  
2x′ 0)  =  0  yield  a1  =  a2  =  0  and  
b1  =  v0/2,  b2  =  v0/4,  so 
 
 
 
 
 
x1(t)  =  (v0/4)(2t + sin 2t) 
 
 
 
 
x2(t)  =  (v0/4)(2t - sin 2t) 
 
 
while  x2 - x1  =  (v0/4)(-2 sin 2t) < 0,  that is, until  t  =  π/2.  Finally,  x1'(π/2)  =  0  and  
x2'(π/2)  =  v0. 
 
18. 
With  c1  =  6  and  c2  =  3,  it follows from Problem 16 that the natural frequencies and 
associated eigenvectors are  ω1  =  0,  v1  =  [1      1]T  and  ω2  =  3,  v2  =  [2    -1]T.   
 
Hence Theorem 1 gives the general solution 
 
 
 
 
x1(t)  =  a1 + b1t + 2a2cos 3t + 2b2sin 3t 
 
 
 
x2(t)  =  a1 + b1t -   a2cos 3t -  b2sin 3t. 
 
 
The initial conditions  
1x′ (0)  =  v0,  x1(0)  =  x2(0)  =  
2x′ (0)  =  0  yield  a1  =  a2  =  0  
and  b1  =  v0/3,  b2  =  v0/9,  so 
 
 
 
 
 
x1(t)  =  (v0/9)(3t + 2 sin 3t) 
 
 
 
 
x2(t)  =  (v0/9)(3t -   sin 3t) 
 
 
while  x2 - x1  =  (v0/9)(-3 sin 3t) < 0;  that is, until  t  =  π/3.  Finally, 
1x′ (π/3)  =  -v0/3  
and  
2x′ (π/3)  =  2v0/3. 
 
19. 
With  c1  =  1  and  c2  =  3,  it follows from Problem 16 that the natural frequencies and 
associated eigenvectors are  ω1  =  0,  v1  =  [1     1]T  and  ω2  =  2,  v2  =  [1    -3]T.   
 
Hence Theorem 1 gives the general solution 
 
 
 
 
x1(t)  =  a1 + b1t +   a2cos 2t +   b2sin 2t 
 
 
 
x2(t)  =  a1 + b1t - 3a2cos 2t - 3b2sin 2t. 
 
 
The initial conditions  
1x′ (0)  =  v0,  x1(0)  =  x2(0)  =  
2x′ (0)  =  0  yield  a1  =  a2  =  0  
and  b1  =  3v0/4,  b2  =  v0/8,  so 
 
 
 
 
 
x1(t)  =  (v0/8)(6t +    sin 2t) 
 
 
 
 
x2(t)  =  (v0/8)(6t - 3 sin 2t) 

388 
Chapter 7 
 
 
while  x2 - x1  =  (v0/8)(-4 sin 2t) < 0;  that is, until  t  =  π/2.  Finally,  
1x′ (π/2)  =  v0/2  
and  
2x′ (π/2)  =  3v0/2. 
 
 
20. 
With  c1  =  c3  =  4  and  c2  =  16  the characteristic equation of the matrix 
 
 
 
 
 
4
4
0
16
32
16
0
4
4
−




=
−


−




A
 
 
is 
 
 
 
λ3 + 40λ2 + 144λ  =  λ(λ + 4)(λ + 36)  =  0. 
 
 
The resulting eigenvalues, natural frequencies, and associated eigenvectors are 
 
 
 
 
λ1  =    0,  
ω1  =  0,   
v1  =  [1      1      1]T 
 
 
 
λ2  =  -4,  
ω2  =  2,   
v2  =  [1      0   -1]T 
 
 
 
λ3  =  -36, 
ω3  =  6,   
v3  =  [1    -8     1]T. 
 
 
Theorem 1 then gives the general solution 
 
 
 
x1(t)  =  a1 + b1t +  a2cos 2t +  b2sin 2t +  a3cos 6t  +  b3sin 6t 
 
 
x2(t)  =  a1 + b1t                                    - 8a3cos 6t - 8b3sin 6t 
 
 
x3(t)  =  a1 + b1t -  a2cos 2t -  b2sin 2t +  a3cos 6 t +  b3sin 6t. 
 
 
The initial conditons yield  a1  =  a2  =  a3  =  0  and  b1  =  4v0/9,  b2  =  v0 / 4,   
 
b3  =  v0/108,  so 
 
 
 
 
x1(t)  =  (v0/108)(48t + 27 sin 2t +   sin 6t) 
 
 
 
x2(t)  =  (v0/108)(48t                  - 8 sin 6t) 
 
 
 
x3(t)  =  (vo/108)(48t - 27 sin 2t +   sin 6t) 
 
while 
 
 
 
x2 - x1  =  -18(sin 2t)(3 - 2 sin32t) < 0, 
 
 
 
x3 - x2  =   -9(4 sin32t) < 0; 
 
 
that is, until  t  =  π/2.  Finally   
 
 
 
 
1x′  (π/2)  =  -v0/9,    
2x′ (π/2)  =  8v0/9,    
3x′ (π/2)  =  8v0/9. 
 
 
21. 
(a) 
The matrix 

 
Section 7.4 
389 
160/ 3
320/3
8
116
−


=


−


A
 
 
 
has eigenvalues  λ1  ≈  -41.8285 and  λ2  ≈  -127.5049,  so the natural frequencies are 
 
 
 
 
 
ω1  ≈   6.4675 rad/sec  ≈  1.0293 Hz 
 
 
 
 
ω2  ≈  11.2918 rad/sec  ≈  1.7971 Hz. 
 
 
(b) 
Resonance occurs at the two critical speeds 
 
 
 
 
 
v1  =  20ω1/π  ≈  41 ft/sec  ≈  28 mi/h   
 
 
 
 
v2  =  20ω2/π  ≈  72 ft/sec  ≈  49 mi/h. 
 
22. 
With  k1  =  k2  =  k  and  L1  =  L2  =  L/2  the equations in (42) reduce to 
 
 
            
 
mx'' =  -2kx   and  Iθ'' =  -kL2θ/2. 
 
 
The first equation yields  ω1  =  
2 /
k m   and the second one yields  ω2  =  
2 / 2 .
kL
I  
 
In Problems 23–25 we substitute the given physical parameters into the equations in (42): 
 
 
 
 
 
mx''  =      -(k1 + k2)x  +   (k1L1 - k2L2)θ 
 
 
 
 
 
Iθ''   =  (k1L1 - k2L2)x - (k1L1
2 + k2L2
2)θ 
 
As in Problem 21, a critical frequency of  ω rad/sec  yields a critical velocity of  v  =  20ω/π  
ft/sec. 
 
23. 
100
4000 ,
800
100000
x
x
θ
θ
′′
′′
= −
=
 
 
Obviously the matrix  
40
0
0
125
−


= 

−


A
  has eigenvalues  
1
2
40 and
125.
λ
λ
= −
= −
 
 
Up-and-down:  
ω1  =  
40 ,     
v1  ≈  40.26 ft/sec  ≈  27 mph 
 
Angular: 
 
ω2  =  125 ,    
v2  ≈  71.18 ft/sec  ≈  49 mph 
 
 
24. 
100
4000
4000
1000
4000
104000
x
x
x
θ
θ
θ
′′ = −
+
′′ =
−
 
 
The matrix  
40
40
4
104
−


= 

−


A
  has eigenvalues  
(
)
1
2
,
4
18
74 .
λ λ
=
−
±
 

390 
Chapter 7 
 
ω1  ≈   6.1311,   
v1  ≈  39.03 ft/sec  ≈  27 mph 
 
ω2  ≈  10.3155,   
v2  ≈  65.67 ft/sec  ≈  45 mph 
 
 
25. 
100
3000
5000
800
5000
75000
x
x
x
θ
θ
θ
′′ = −
−
′′ = −
−
 
 
The matrix  
30
50
25/ 4
375/ 4
−
−


= 

−
−


A
  has eigenvalues  
(
)
1
2
5
,
99
3401 .
8
λ λ
=
−
±
 
 
ω1  ≈  5.0424,   
v1  ≈  32.10 ft/sec  ≈  22 mph 
 
ω2  ≈  9.9158,   
v2  ≈  63.13 ft/sec  ≈  43 mph 
 
 
 
 
SECTION 7.5 
 
MULTIPLE EIGENVALUE SOLUTIONS 
 
In each of Problems 1–6 we give first the characteristic equation with repeated (multiplicity 2) 
eigenvalue  λ.  In each case we find that  
2
(
)
λ
−
=
A
I
0 .  Then  
T
[1
0]
=
w
 is a generalized 
eigenvector and  
(
)
λ
=
−
≠
v
A
I w
0  is an ordinary eigenvector associated with  λ.  We give 
finally the scalar component functions  x1(t),  x2(t)  of the general solution 
 
 
 
 
 
x(t)  =  c1veλt + c2(vt + w)eλt  
 
of the given system  x′  =  Ax. 
 
 
1. 
Characteristic equation 
λ2 + 6λ + 9  =  0 
 
Repeated eigenvalue  
λ  =  -3 
 
Generalized eigenvector 
w  =  [1     0]T 
 
 
(
)
1
1
1
1
1
1
0
1
λ




=
−
=
=




−
−
−




v
A
I w
 
 
x1(t)  =  ( c1 + c2 + c2t)e-3t 
 
x2(t)  =  (-c1      - c2t)e-3t. 
 
 
 
The left-hand figure at the top of the next page shows a direction field and typical 
 
solution curves. 
 
 

 
Section 7.5 
391 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
2. 
Characteristic equation 
λ2 - 4λ + 4  =  0 
 
Repeated eigenvalue    
λ  =  2 
 
Generalized eigenvector   
w  =  [1     0]T 
 
 
(
)
1
1
1
1
1
1
0
1
λ
−



=
−
=
=



−



v
A
I w
 
 
x1(t)  =  (c1 + c2 + c2t)e2t 
 
x2(t)  =  (c1 +        c2t)e2t. 
 
 
The right-hand figure above shows a direction field and typical solution curves. 
 
 
3. 
Characteristic equation   
λ2 - 6λ + 9  =  0 
 
Repeated eigenvalue    
λ  =  3 
 
Generalized eigenvector   
w  =  [ 1     0]T 
 
 
(
)
2
2
1
2
2
2
0
2
λ
−
−
−




=
−
=
=








v
A
I w
 
 
 
x1(t)  =  (-2c1 + c2 - 2c2t)e3t 
 
x2(t)  =  ( 2c1 +          2c2t)e3t. 
 
 
The figure at the top of the next page shows a direction field and typical solution curves. 
 

392 
Chapter 7 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
 
 
 
 
4. 
Characteristic equation   
λ2 - 8λ + 16  =  0 
 
Repeated eigenvalue    
λ  =  4 
 
Generalized eigenvector   
w  =  [ 1     0]T 
 
 
(
)
1
1
1
1
1
1
0
1
λ
−
−
−




=
−
=
=








v
A
I w
 
 
x1(t)  =  (-c1 + c2 - c2t)e4t 
 
x2(t)  =  ( c1 +          c2t)e4t. 
 
 
The left-hand figure below shows a direction field and typical solution curves. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2

 
Section 7.5 
393 
5. 
Characteristic equation   
λ2 - 10λ + 25  =  0 
 
Repeated eigenvalue    
λ  =  5 
 
Generalized eigenvector   
w  =  [1     0]T 
 
 
(
)
2
1
1
2
4
2
0
4
λ




=
−
=
=




−
−
−




v
A
I w
 
 
x1(t)  =  ( 2c1 + c2 + 2c2t)e5t 
 
x2(t)  =  (-4c1       - 4c2t)e5t. 
 
 
The right-hand figure at the bottom of the preceding page shows a direction field and 
 
typical solution curves. 
 
 
6. 
Characteristic equation   
λ2 - 10λ + 25  =  0 
 
Repeated eigenvalue    
λ  =  5 
 
Generalized eigenvector   
w  =  [ 1       0]T 
 
 
(
)
4
4
1
4
4
4
0
4
λ
−
−
−




=
−
=
=








v
A
I w
 
 
 
 
x1(t)  =  (-4c1 + c2 - 4c2t)e5t 
 
x2(t)  =  ( 4c1          + 4c2t)e5t. 
 
 
The figure below shows a direction field and typical solution curves. 
 
 
 
 
 
−5
−4
−3
−2
−1
0
1
2
3
4
5
−5
−4
−3
−2
−1
0
1
2
3
4
5
x1
x2
 

394 
Chapter 7 
In each of Problems 7–10 the characteristic polynomial is easily calculated by expansion along 
the row or column of  A  that contains two zeros.  The matrix  A  has only two distinct 
eigenvalues, so we write  
1
2
3
,
,
λ λ
λ  with either  
1
2
2
3
or
.
λ
λ
λ
λ
=
=
  Nevertheless, we find that it 
has 3 linearly independent eigenvectors  
1
2
,
v
v , and  v3.  We list also the scalar components  
x1(t), x2(t), x3(t)  of the general solution  
3
1
2
1
1
2
2
3
3
( )
t
t
t
t
c
e
c
e
c
eλ
λ
λ
=
+
+
x
v
v
v
of the system. 
 
 
7. 
Characteristic equation   
3
2
2
13
40
36
(
2) (
9)
λ
λ
λ
λ
λ
−
+
−
+
= −
−
−
 
 
Eigenvalues    
 
λ  =  2,  2,  9 
 
Eigenvectors    
 
[1    1    0]T,  [1    0    1]T,  [0    1    0]T  
 
x1(t)  =  c1e2t + c2e2t 
 
x2(t)  =  c1e2t           + c3e9t 
 
 
x3(t)  =              c2e2t 
 
8. 
Characteristic equation   
3
2
2
33
351
1183
(
13) (
7)
λ
λ
λ
λ
λ
−
+
−
+
= −
−
−
 
 
Eigenvalues    
 
λ  =  7,  13,  13 
 
Eigenvectors    
 
[2   -3    1]T,  [0    0    1]T,   [–1   1    0]T,   
 
x1(t)  =    2c1e7t             – c3e13t 
 
x2(t)  =  -3c1e7t            + c3e13t 
 
x3(t)  =      c1e7t + c2e13t 
 
9. 
Characteristic equation 
3
2
2
19
115
225
(
5) (
9)
λ
λ
λ
λ
λ
−
+
−
+
= −
−
−
 
 
Eigenvalues    
 
λ  =  5,  5,  9 
 
Eigenvectors    
 
[1    2    0]T,  [7    0    2]T,  [3    0    1]T  
 
x1(t)  =  c1e5t + 7c2e5t + 3c3e9t 
  
x2(t)  =  2c1e5t    
 
x3(t)  =            2c2e5t +  c3e9t 
 
10. 
Characteristic equation   
3
2
2
13
51
63
(
3) (
7)
λ
λ
λ
λ
λ
−
+
−
+
= −
−
−
 
 
Eigenvalues    
 
λ  =  3,  3,  7 
 
Eigenvectors   
  
[5   2   0]T,  [–3    0  1]T,  [2   1   0]T  
 
x1(t)  =  5c1e3t – 3c2e3t + 2c3e7t 
 
x2(t)  =  2c1e3t             +   c3e7t 
 
x3(t)  =               c2e3t  
 
 

 
Section 7.5 
395 
In each of Problems 11–14,  the characteristic equation is
3
2
3
3
3
1
(
1)
λ
λ
λ
λ
−
−
−
−
= −
+
. 
Hence λ  =  -1  is a triple eigenvalue of defect  2,  and we find that  
3
(
)
.
λ
−
=
A
I
0  In each 
problem we start with  
T
3
[1 0 0]
=
v
 and then calculate 
2
3
(
)
λ
=
−
v
A
I v  and  
1
2
(
)
0.
λ
=
−
≠
v
A
I v
  It follows that 
2
3
1
2
3
(
)
(
)
(
)
,
λ
λ
λ
−
=
−
=
−
=
A
I v
A
I
v
A
I v
0   so the vector  
v1  (if nonzero) is an ordinary eigenvector associated with the triple eigenvalue  λ.  Hence   
{v1, v2, v3} is a length 3 chain of generalized eigenvectors, and the corresponding general  
solution is described by 
 
 
 
x(t)  =  e-t [c1v1 + c2(v1 t + v2) + c3(v1 t2/2 + v2 t + v3)]. 
 
We give the scalar components  x1(t),  x2(t),  x3(t)  of  x(t).  
 
 
11. 
v1  =  [0   1   0]T,     v2  =  [-2  -1   1]T,     v3  =  [1   0   0]T 
 
x1(t)  =  e-t(-2c2 + c3 - 2c3 t) 
  
x2(t)  =  e-t(c1 - c2 + c2 t - c3 t + c3 t2/2) 
 
x3(t)  =  e-t(c2 + c3 t)  
 
 
12. 
v1  =  [1   1   0]T,      v2  =  [0   0   1]T,       v3  =  [1   0   0]T 
 
x1(t)  =  e-t(c1 + c3 + c2 t + c3 t2/2) 
  
x2(t)  =  e-t (c1 + c2 t + c3 t2/2) 
 
x3(t)  =  e-t (c2 + c3 t)   
 
 
 
13. 
Here we are stymied initially, because if  v3  =  [1   0   0]T  then  
3
(
)
λ
−
=
A
I v
0  does not  
 
qualify as a (nonzero) generalized eigenvector.  We there make a fresh start with 
 
v3  =  [0   1   0]T, and now we get the desired nonzero generalized eigenvectors upon 
 
successive multiplication by 
.
λ
−
A
I  
 
v1  =  [1   0   0]T,       v2  =  [0   2   1]T,         v3  =  [0   1   0]T 
 
x1(t)  =  e-t(c1 + c2 t + c3 t2/2) 
  
x2(t)  =  e-t(2c2 + c3 + 2c3 t) 
 
x3(t)  =  e-t(c2 + c3 t)  
 
 
14. 
v1  =  [5  -25  -5]T,     v2  =  [1  -5    4]T,      v3  =  [1   0   0]T 

396 
Chapter 7 
 
x1(t)  =  e-t(5c1 + c2 + c3 + 5c2 t + c3 t + 5c3 t2/2) 
 
x2(t)  =  e-t (-25c1 - 5c2 - 25c2 t - 5c3 t - 25c3 t2/2) 
 
x3(t)  =  e-t(-5c1 + 4c2 - 5c2 t + 4c3 t - 5c3 t2/2)  
 
In each of Problems 15–18,  the characteristic equation is
3
2
3
3
3
1
(
1)
λ
λ
λ
λ
−
+
−
+
= −
−
. 
Hence λ  =  1  is a triple eigenvalue of defect 1,  and we find that  
2
(
)
.
λ
−
=
A
I
0   First we find 
the two linearly independent (ordinary) eigenvectors  u1  and  u2  associated with  λ.   Then we 
start with  
T
2
[1 0 0]
=
v
 and calculate 
1
2
(
)
0.
λ
=
−
≠
v
A
I v
  It follows that 
2
1
2
(
)
(
)
,
λ
λ
−
=
−
=
A
I v
A
I
v
0   so  v1  is an ordinary eigenvector associated with  λ.  However,  
v1 is a linear combination of  u1  and  u2,  so  
1
te
v
 is a linear combination of the independent 
solutions  
.
1
2
and
t
t
e
e
u
u
.   But  {v1, v2} is a length 2 chain of generalized eigenvectors 
associated with  λ,  so  
1
2
(
)
t
t
e
+
v
v
 is the desired third independent solution.  The corresponding 
general solution is described by 
 
 
 
 
 
x(t)  =  et [c1u1 + c2u2 + c3(v1 t + v2)] 
 
We give the scalar components  x1(t), x2(t), x3(t)  of  x(t).  
 
 
15. 
u1  =  [3   -1    0]T      u2  =  [0    0    1]T  
 
v1  =  [-3   1    1]T      v2  =  [1    0    0]T  
 
x1(t)  =  et (3c1 + c3 - 3c3 t) 
  
x2(t)  =  et(-c1 + c3 t) 
 
x3(t)  =  et(c2 + c3 t)  
 
 
16. 
u1  =  [3   -2    0]T      u2  =  [3    0   -2]T  
 
v1  =  [0   -2    2]T      v2  =  [1    0    0]T  
 
x1(t)  =  et(3c1 + 3c2 + c3)  
  
x2(t)  =  et(-2c1 - 2c3 t) 
 
x3(t)  =  et(–2c2 + 2c3 t)  
 
 
17. 
u1  =  [2   0  -9]T      u2  =  [1  -3    0]T  
 
v1  =  [0   6  -9]T      v2  =  [0     1    0]T  
 
 
(Either  v2  =  [1     0    0]T  or  v2  =  [0     0    1]T  can be used also, but they 

 
Section 7.5 
397 
 
yield different forms of the solution than given in the book's answer section.) 
 
x1(t)  =  et(2c1 + c2)  
  
x2(t)  =  et(–3c2 + c3 + 6c3 t) 
 
x3(t)  =  et(-9c1 - 9c3 t)  
 
18. 
u1  =  [-1   0     1]T      u2  =  [-2   1    0]T  
 
v1  =  [0      1  -2]T      v2  =  [1      0    0]T  
 
x1(t)  =  et(-c1 – 2c2 + c3)  
  
x2(t)  =  et(c2 + c3 t) 
 
x3(t)  =  et(c1 - 2c3 t)  
 
19. 
Characteristic equation   
λ4 - 2λ2 + 1  =  0 
 
Double eigenvalue  λ  =  -1  with eigenvectors   
 
 
 
v1  =  [1   0   0   1]T   and   v2  =  [0   0   1   0]T. 
 
Double eigenvalue  λ  =  +1  with eigenvectors 
 
 
 
v3  =  [0   1   0  -2]T   and   v4  =  [1   0   3   0]T. 
 
General solution 
 
 
 
x(t)  =  e-t(c1v1 + c2v2) + et(c3v3 + c4v4) 
 
Scalar components 
 
 
 
x1(t)  =  c1e-t + c4et  
  
 
 
x2(t)  =  c3et 
 
 
 
x3(t)  =  c2e-t + 3c4et  
 
 
 
x4(t)  =  c1e-t - 2c3et 
 
20. 
Characteristic equation   
4
3
2
8
24
32
16
λ
λ
λ
λ
−
+
−
+
  =  (λ - 2)4  =  0 
 
Eigenvalue  λ  =  2  with multiplicity  4  and defect  3. 
 
 
We find that  
3
(
)
0
λ
−
≠
A
I
 but  
4
(
)
0.
λ
−
=
A
I
 We therefore start with   
v4  =  [0   0   0   1]T  and define  
3
4
(
)
,
λ
=
−
v
A
I v
 
2
3
(
)
,
λ
=
−
v
A
I v
2
3
(
)
,
λ
=
−
v
A
I v  and  
1
2
(
)
0.
λ
=
−
≠
v
A
I v
  This gives the length  4  chain  {v1,  v2,  v3,  v4}  with 
 
 
      
v1  =  [1    0    0    0]T        
v2  =  [0    1    0    0]T 
 
 
v3  =  [1    0    1    0]T        
v4  =  [0    0    0    1]T. 
 
 

398 
Chapter 7 
 
The corresponding general solution is given by 
 
 
 
x(t)  =  e-t [c1v1 + c2(v1 t + v2) + c3(v1 t2/2 + v2 t + v3) 
 
                      + c4(v1 t3/6 + v2 t2/2 + v3 t + v4)] 
 
 
 
with scalar components 
 
 
 
x1(t)  =  e2t(c1 + c3 + c2 t + c4 t + c3 t2/2 +c4 t3/6)  
  
 
x2(t)  =  e2t(c2 + c3 t + c4 t2/2) 
 
 
x3(t)  =  e2t(c3 + c4 t) 
 
 
x4(t)  =  e2t(c4). 
 
 
21. 
Characteristic equation   
4
3
2
4
6
4
1
λ
λ
λ
λ
−
+
−
+   =  (λ – 1)4  =  0 
 
Eigenvalue  λ  =  1  with multiplicity  4  and defect  2. 
 
 
We find that  
2
(
)
0
λ
−
≠
A
I
 but  
3
(
)
0.
λ
−
=
A
I
 We therefore start with   
v3  =  [1   0   0   0]T  and define  
2
3
(
)
λ
=
−
v
A
I v  and 
1
2
(
)
0,
λ
=
−
≠
v
A
I v
 thereby 
obtaining the length 3 chain  {v1,  v2,  v3}  with 
 
 
 
v1  =  [0   0   0   1]T,     v2  =  [-2  1  1  0]T,     v3  =  [1   0   0   0]T.        
 
 
 
Then we find the second ordinary eigenvector  v4  =  [0    0  1  0]T.  The corresponding 
 
general solution 
 
 
x(t)  =  et [c1v1 + c2(v1 t + v2) + c3(v1 t2/2 + v2 t + v3) + c4v4] 
 
has scalar components 
 
 
 
x1(t)  =  et(-2c2 + c3 - 2c3 t) 
  
 
x2(t)  =  et(c2 + c3 t) 
 
 
x3(t)  =  et(c2 + c4 + c3 t). 
 
 
x4(t)  =  et(c1 + c2 t + c3 t2/2.) 
 
 
22.  
Same eigenvalue and chain structure as in Problem 21, but with generalized eigenvectors 
 
 
 
v1  =  [1   0   0  -2]T        
v2  =  [3  -2   1  -6]T 
 
 
v3  =  [0   1   0    0]T         
v4  =  [1    0   0     0]T 
 
 
where  {v1,  v2,  v3}  is a length 3 chain and  v4  is an ordinary eigenvector.  The general 
solution  x(t)  defined as in Problem 21 has scalar components 
 

 
Section 7.5 
399 
 
 
x1(t)  =  et(c1 + 3c2 + c4 + c2 t + 3c3 t + c3 t2/2) 
  
 
x2(t)  =  et(-2c2 + c3 - 2c3 t) 
 
 
x3(t)  =  et(c2 + c3 t) 
 
 
x4(t)  =  et(-2c1 - 6c2 - 2c2 t -6c3 t  - c3 t2) 
 
In Problems 23 and 24 there are only two distinct eigenvalues  
1
2
and
.
λ
λ   However, the 
eigenvector equation  (
)
0
λ
−
=
A
I v
  yields the three linearly independent eigenvectors  v1, v2, 
and v3 that are given.  We list the scalar components of the corresponding general solution  
1
2
2
1
1
2
2
3
3
( )
.
t
t
t
t
c
e
c
e
c
e
λ
λ
λ
=
+
+
x
v
v
v
 
 
23. 
λ1  =  -1:   
{v1}  with  v1  =  [1   -1    2]T 
 
λ2  =   3:   
{v2}  with  v2  =  [4      0    9]T  and 
 
           
{v3}  with  v3  =  [0     2    1]T  
 
 
 
Scalar components 
 
 
 
 
x1(t)  =    c1e-t + 4c2e3t 
  
 
 
x2(t)  =  -c1e-t             +  2c3e3t 
 
 
 
x3(t)  =  2c1e-t + 9c2e3t +   c3e3t 
 
24. 
λ1  =  -2:   
{v1}  with  v1  =  [5     3  -3]T 
 
 
λ2  =   3:   
{v2}  with  v2  =  [4     0  -1]T  and 
 
           
{v3}  with  v3  =  [2  -1    0]T  
 
 
Scalar components 
 
 
 
 
x1(t)  =    5c1e-2t + 4c2e3t + 2c3e3t 
  
 
 
x2(t)  =    3c1e-2t                 -  c3e3t 
 
 
 
x3(t)  =  -3c1e-2t -  c2e3t  
 
In Problems 25, 26, and 28 there is given a single eigenvalue  λ  of multiplicity 3.  We find that  
2
(
)
0
λ
−
≠
A
I
 but  
3
(
)
0.
λ
−
=
A
I
 We therefore start with  v3  =  [1   0   0]T  and define   
2
3
(
)
λ
=
−
v
A
I v  and 
1
2
(
)
0,
λ
=
−
≠
v
A
I v
 thereby obtaining the length 3 chain  {v1,  v2,  v3}  of 
generalized eigenvectors based on the ordinary eigenvector  v1.  We list the scalar components of 
the corresponding general solution 
 
 
 
x(t)  =  c1v1
t
eλ  + c2(v1t + v2)
t
eλ  + c3(v1t2/2 + v2t + v3)
t
eλ . 

400 
Chapter 7 
25. 
{v1, v2, v3}  with 
   
 
v1  =  [-1   0  -1]T,   v2  =  [-4  -1  0]T,   
v3  =  [1   0   0]T 
 
Scalar components 
 
 
2
2
1
1
2
3
2
3
3
2
2
2
3
2
2
3
1
2
3
( )
(
4
4
/ 2)
( )
(
)
( )
(
/ 2)
t
t
t
x t
e
c
c
c
c t
c t
c t
x t
e
c
c t
x t
e
c
c t
c t
=
−
−
+
−
−
−
=
−
−
=
−
−
−
 
 
26. 
{v1, v2, v3}  with  
 
 
v1  =  [0    2    2]T,   
v2  =  [2    1  -3]T,   
v3  =  [1    0    0]T 
 
General solution 
 
 
3
1
2
3
3
3
2
2
1
2
2
3
3
3
2
3
1
2
2
3
3
( )
(2
2
)
( )
(2
2
)
( )
(2
3
2
3
)
t
t
t
x t
e
c
c
c t
x t
e
c
c
c t
c t
c t
x t
e
c
c
c t
c t
c t
=
+
+
=
+
+
+
+
=
−
+
−
+
 
 
27. 
We find that the triple eigenvalue  λ = 2  has the two linearly independent eigenvectors 
 
[1   1   0]T  and  [–1   0   1]T.  Next we find that  (
)
0
λ
−
≠
A
I
 but  
2
(
)
0.
λ
−
=
A
I
 We  
 
therefore start with  v2  =  [1   0   0]T  and define  
 
 
 
 
1
2
(
)
λ
=
−
=
v
A
I v
 
T
[ 5
3
8]
,
−
≠0  
 
thereby obtaining the length 2 chain  {v1,  v2}  of generalized eigenvectors based on the 
ordinary eigenvector  v1.  If we take  v3  =  [1   1   0]T,  then the general solution 
x(t)  =  e2t [c1v1 + c2(v1t + v2) + c3v3]  has scalar components 
 
 
2
1
1
2
3
2
2
2
1
2
2
3
1
2
( )
( 5
5
)
( )
(3
3
)
( )
(8
8
).
t
t
t
x t
e
c
c
c
c t
x t
e
c
c t
x t
e
c
c t
=
−
+
+
−
=
+
=
+
 
 
28. 
{v1, v2, v3}  with 
 
v1  =  [119  -289   0]T,   v2  =  [-17   34   17]T,    v3  =  [1   0   0]T 
 
General solution 
 
 
2
2
1
1
2
3
2
3
3
2
2
2
1
2
2
3
3
2
3
2
3
( )
(119
17
119
17
119
/ 2)
( )
( 289
34
289
34
289
/ 2)
( )
(17
17
)
t
t
t
x t
e
c
c
c
c t
c t
c t
x t
e
c
c
c t
c t
c t
x t
e
c
c t
=
−
+
+
−
+
=
−
+
−
+
−
=
+
 
 

 
Section 7.5 
401 
In Problems 29 and 30 the matrix  A  has two distinct eigenvalues  
1
2
and
λ
λ  each having 
multiplicity 2 and defect 1.  First, we select  v2  so that  
1
1
2
(
)
λ
=
−
≠
v
A
I v
0  but  
1
1
(
)
,
λ
−
=
A
I v
0  so  {v1, v2} is a length 2 chain based on  v1.  Next, we select  u2  so that  
1
1
2
(
)
λ
=
−
≠
u
A
I u
0  but  
1
1
(
)
,
λ
−
=
A
I u
0  so  {u1, u2} is a length 2 chain based on  u1.  We give 
the scalar components of the corresponding general solution 
 
 
 
x(t)  =  
1t
eλ [c1v1 + c2(v1t + v2)] + 
2 t
eλ [c3u1 + c4(u1t + u2)]. 
 
29. 
λ  = -1:  {v1, v2}  with   v1  =  [1  -3  -1  -2]T  and  v2  =  [0     1     0     0]T, 
 
λ  =   2:  {u1, u2}  with   u1  =  [0  -1     1     0]T  and  u2  =  [0     0     2     1]T 
 
Scalar components 
 
 
1
1
2
2
2
1
2
2
3
4
2
3
1
2
3
4
4
2
4
1
2
4
( )
(
)
( )
( 3
3
)
(
)
( )
(
)
(
2
)
( )
( 2
2
)
(
)
t
t
t
t
t
t
t
x t
e
c
c t
x t
e
c
c
c t
e
c
c t
x t
e
c
c t
e
c
c
c t
x t
e
c
c t
e
c
−
−
−
−
=
+
=
−
+
−
+
−
−
=
−
−
+
+
+
=
−
−
+
 
 
30. 
λ  = -1:  {v1, v2}  with  v1  =  [0     1  -1  -3]T  and  v2  =  [0     0     1     2]T, 
 
λ  =   2:  {u1, u2}  with  u1  =  [-1  0     0    0]T  and  u2  =  [0     0     3     5]T 
 
Scalar components 
 
 
2
1
3
4
2
1
2
2
3
1
2
2
4
2
4
1
2
2
4
( )
(
)
( )
(
)
( )
(
)
(3 )
( )
( 3
2
3
)
(5
)
t
t
t
t
t
t
x t
e
c
c t
x t
e
c
c t
x t
e
c
c
c t
e
c
x t
e
c
c
c t
e
c
−
−
−
=
−
−
=
+
=
−
+
−
+
=
−
+
−
+
 
 
31. 
We have the single eigenvalue  λ = 1  of multiplicity  4.  Starting with   
v3  =  [1    0    0    0]T,  we calculate 
2
3
(
)
λ
=
−
v
A
I v  and  
1
2
(
)
,
λ
=
−
≠
v
A
I v
0  and find 
that  
1
(
)
.
λ
−
=
A
I v
0   Therefore  {v1, v2, v3}  is a length 3 chain based on the ordinary 
eigenvector  v1.  Next, the eigenvector equation  (
)
λ
−
=
A
I v
0  yields the second linearly 
independent eigenvector  v4  =  [0    1    3    0]T.  With 
 
 
 
v1  =  [42   7  -21  -42]T,    
v2  =  [34   22  -10  -27]T,    
 
 
v3  =  [1    0    0    0]T     and    v4  =  [0    1    3    0] 
 
 
the general solution 
 
 
x(t)  =  et [c1v1 + c2(v1t + v2) + c3(v1t2/2 + v2t + v3) + c4v4] 

402 
Chapter 7 
 
has scalar components 
 
 
2
1
1
2
3
2
3
3
2
2
1
2
4
2
3
3
2
3
1
2
4
2
3
3
2
4
1
2
2
3
3
( )
(42
34
42
34
21
)
( )
(7
22
7
22
7
/ 2)
( )
( 21
10
3
21
10
21
/ 2)
( )
( 42
27
42
27
21
).
t
t
t
t
x t
e
c
c
c
c t
c t
c t
x t
e
c
c
c
c t
c t
c t
x t
e
c
c
c
c t
c t
c t
x t
e
c
c
c t
c t
c t
=
+
+
+
+
+
=
+
+
+
+
+
=
−
−
+
−
−
−
=
−
−
−
−
−
 
 
32. 
Here we find that the matrix  A  has five linearly independent eigenvectors: 
 
λ  =  2:   
eigenvectors  v1  =  [8    0  -3    1   0]T  and   v2  =  [1   0     0   0   3]T 
 
 
 
 
λ  =  3:   
eigenvectors  v3  =  [3  -2  -1    0   0]T,      v4  =  [2  -2    0  -3   0]T,   
 
 
 
 
 
v5  =  [1  -1    0    0   3]T 
 
The general solution 
 
 
 
x(t)  =  e2t(c1v1 + c2v2) + e3t(c3v3 + c4v4 + c5v5) 
 
has scalar components 
 
 
2
3
1
1
2
3
4
5
3
2
3
4
5
2
3
3
1
3
2
3
4
1
4
2
3
3
2
5
( )
(8
)
(3
2
)
( )
( 2
2
)
( )
( 3 )
(
)
( )
( )
( 3 )
( )
(3 )
(3 )
t
t
t
t
t
t
t
t
t
x t
e
c
c
e
c
c
c
x t
e
c
c
c
x t
e
c
e
c
x t
e
c
e
c
x t
e
c
e
c
=
+
+
+
+
=
−
−
−
=
−
+
−
=
+
−
=
+
 
 
33. 
The chain  {v1, v2}  was found using the matrices 
 
4
4
1
0
1
0
0
4
4
0
1
0
0
1
0
0
0
4
4
0
0
0
1
0
0
4
4
0
0
0
0
i
i
i
i
i
λ
−












−
=
→
−












A
I
 
 
 
 
and 
2
32
32
8
8
1
0
0
32
32
8
8
0
0
1
(
)
0
0
32
32
0
0
0
0
0
0
32
32
0
0
0
0
i
i
i
i
i
i
i
i
λ
−
−
−








−




−
=
→
−
−








−




A
I
 
 

 
Section 7.5 
403 
where  →   signifies reduction to row-echelon form.  The resulting real-valued solution 
vectors are 
 
 
 
x1(t)  =  e3t [   cos 4t       
 sin 4t      
  0         
  0     ]T 
 
 
x2(t)  =  e3t [-sin 4t       
 cos 4t       
  0         
  0     ]T 
 
 
x3(t)  =  e3t [   t cos 4t    
t sin 4t     
cos 4t    
sin 4t ]T 
 
 
x4(t)  =  e3t [-t sin 4t  
t cos 4t    
-sin 4t    
cos 4t ]T. 
 
 
34. 
The chain  {v1,v2}  was found using the matrices 
 
3
0
8
3
1
0
0
0
18
3
3
0
0
0
1
0
3
3
9
3
27
3
9
0
0
1
0
33
10
90
30
3
0
0
0
0
i
i
i
i
i
λ
−
−








−
−−
+




−
=
→
−
−
−
−
−








−




A
I
 
 
and 
 
  
2
36
6
54
48
18
18
1
0
3
54
108
18
144
54
0
1
9
10
3
3
(
)
54
18
18
162
54
0
0
0
0
198
60
6
540
18 180
0
0
0
0
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
i
λ
−
−
−
+
−
+
−
−








+
+
+




−
=
→
−
+








−
−
−
−
−




A
I
 
 
 
where  →   signifies reduction to row-echelon form.  The resulting real-valued solution 
vectors are 
 
 
x1(t)  =  e2t [         sin 3t 
 
3 cos 3t - 3 sin 3t 
 
 0 
   sin 3t  ]T 
 
x2(t)  =  e2t [      -cos 3t    
 
3 sin 3t + 3 cos 3t 
 
 0  
 -cos 3t ]T 
 
x3(t)  =  e2t [3 cos 3t + t sin 3t     (3t -10)cos 3t -(3t + 9)sin 3t       sin 3t 
  t sin3t  ]T 
 
x4(t)  =  e2t [-t cos 3t + 3 sin 3t   (3t + 9)cos 3t + (3t -10)sin 3t    -cos3t 
 -t cos3t]T. 
 
 
35. 
The coefficient matrix 
 
0
0
1
0
0
0
0
1
1
1
2
1
1
1
1
2






=
−
−




−
−


A
 
 
 
has eigenvalues 
 

404 
Chapter 7 
 
 
λ  =    0   with eigenvector   v1  =  [1     1     0     0]T 
 
 
λ  =  -1   with eigenvectors   v2  =  [1    0  -1     0]T  and  v3  =  [0     1     0  -1]T, 
 
 
λ  =  -2   with eigenvector   v4  =  [1  -1  -2     2]T. 
 
 
When we impose the given initial conditions on the general solution 
 
 
 
 
 
x(t)  =  c1v1 + c2v2e-t + c3v3e-t + c4v4e-2t 
 
 
we find that  c1  =  v0,  c2  =  c3  =  -v0,  c4  =  0.  Hence the position functions of the two 
masses are given by 
 
 
 
 
 
x1(t)  =  x2(t)  =  v0(1 - e-t). 
 
 
Each mass travels a distance  v0  before stopping. 
 
36. 
The coefficient matrix is the same as in Problem  35  except that  a44  =  -1.  Now the 
matrix  A  has the eigenvalue  λ  =  0  with eigenvector  v0  =  [1   1   0   0]T,  and the 
triple eigenvalue  λ  =  -1  with associated length 2 chain  {v1, v2, v3}  consisting of the 
generalized eigenvectors 
 
 
 
 
 
v1  =  [0    1      0    -1]T 
 
 
 
 
v2  =  [1    0    -1      1]T 
 
 
 
 
v3  =  [1    0      0      0]T. 
 
 
When we impose the given initial conditions on the general solution 
 
 
 
x(t)  =  c0v0 + e-t [c1v1 + c2(v1t + v2) + c3(v1t2/2 + v2t + v3)] 
 
 
we find that  c0  =  2v0,  c1  =  -2v0,  c2  =  c3  =  -v0.  Hence the position functions of the 
two masses are given by 
 
 
 
 
 
x1(t)  =  v0(2 - 2e-t - te-t), 
 
 
 
 
x2(t)  =  v0(2 - 2e-t - te-t - t2e-t/2). 
 
 
Each travels a distance  2v0  before stopping. 
 
In Problems 37–46 we use the eigenvectors and generalized eigenvectors found in Problems 23–32 
to construct a matrix  Q  such that  J = Q–1AQ  is a Jordan normal form of the given matrix  A. 
 
37. 
v1  =  [1   -1    2]T,     v2  =  [4      0    9]T,     v3  =  [0     2    1]T  
 
[
]
1
2
3
1
4
0
1
0
2
2
9
1




=
=
−






Q
v
v
v
 

 
Section 7.5 
405 
 
1
18
4
8
39
8
16
1
4
0
1
0
0
1
5
1
2
36
5
16
1
0
2
0
3
0
2
9
1
4
72
16
29
2
9
1
0
0
3
−
−
−
−
−












=
=
−
−
−
−
=






−
−
−












J
Q AQ
 
 
38. 
v1  =  [5     3  -3]T,     v2  =  [4     0  -1]T,     v3  =  [2  -1    0]T  
 
[
]
1
2
3
5
4
2
3
0
1
3
1
0




=
=
−


−
−




Q
v
v
v
 
 
1
1
2
4
28
50
100
5
4
2
2
0
0
3
6
11
15
33
60
3
0
1
0
3
0
3
7
12
15
30
57
3
1
0
0
0
3
−
−
−
−
−












=
=
−
=






−
−
−
−
−
−
−
−












J
Q AQ
 
 
39. 
v1  =  [-1   0  -1]T,     v2  =  [-4  -1  0]T,     v3  =  [1   0   0]T 
 
[
]
1
2
3
1
4
1
0
1
0
1
0
0
−
−




=
=
−


−




Q
v
v
v
 
 
1
0
0
1
2
17
4
1
4
1
2
1
0
0
1
0
1
6
1
0
1
0
0
2
1
1
4
1
0
1
2
1
0
0
0
0
2
−
−
−
−
−












=
=
−
−
−
=






−
−
−












J
Q AQ
 
 
40. 
v1  =  [0    2    2]T,     v2  =  [2    1  -3]T,     v3  =  [1    0    0]T 
 
[
]
1
2
3
0
2
1
2
1
0
2
3
0




=
= 

−




Q
v
v
v
 
 
1
0
3
1
5
1
1
0
2
1
3
1
0
1 0
2
2
1
3
0
2
1
0
0
3
1
8 8
4
4
3
2
1
2
3
0
0
0
3
−
−












=
=
−
=






−
−
−












J
Q AQ
 
 
41. 
v1  =  
T
[ 5
3
8] ,
−
     v2  =  [1     0     0]T,      v3  =  [1     1     0]T  
 
[
]
1
2
3
5
1
1
3
0
1
8
0
0
−




=
= 





Q
v
v
v
 

406 
Chapter 7 
 
 
 
1
0
0
1
3
5
5
5
1
1
2
1
0
1 8
8
8
3
1
3
3
0
1
0
2
0
8 0
8
3
8
8
10
8
0
0
0
0
2
−
−
−
−












=
=
−
−
=






−
−












J
Q AQ
 
 
42. 
v1  =  [119   -289     0]T,      v2  =  [-17    34    17]T,      v3  =  [1     0     0]T  
 
[
]
1
2
3
119
17
1
289
34
0
0
17
0
−




=
=
−






Q
v
v
v
 
 
1
0
1
2
15
7
4
119
17
1
2
1
0
1
0
0
17
34
16
11
289
34
0
0
2
1
289 289
119
51
17
7
5
0
17
0
0
0
2
−
−
−
−
−












=
=
−
−
=


















J
Q AQ
 
 
43. 
v1  =  [1  -3  -1  -2]T,           v2  =  [0     1     0     0]T, 
 
u1  =  [0  -1     1     0]T,          u2  =  [0     0    2     1]T  
 
[
]
1
2
1
2
1
1
0
0
0
3
1
1
0
1
0
1
2
2
0
0
1
1
0
0
0
1
1
1
2
1
0
0
0
1
1
0
0
0
1
1
2
7
4
6
11
3
1
1
0
0
1
0
0
3
0
1
2
5
1
1
3
1
0
1
2
0
0
2
1
2
0
0
1
6
2
2
6
2
0
0
1
0
0
0
2
−




−
−


=
= 

−


−


=
−
−
−












−
−
−
−
−
−






=
=






−
−
−
−






−
−
−






Q
v
v
u
u
J
Q AQ
 
 
44. 
v1  =  [0      1   -1   -3]T,          v2  =  [0     0     1     2]T, 
 
u1  =  [-1    0     0     0]T           u2  =  [0     0     3     5]T 
 
[
]
1
2
1
2
0
0
1
0
1
0
0
0
1
1
0
3
3
2
0
5
−






=
= 

−


−


Q
v
v
u
u
 
 
 
 

 
Section 7.5 
407 
 
 
1
0
1
0
0
2
1
2
1
0
0
1
0
1
1
0
0
0
4
5
3
0
3
5
3
1
0
0
0
0
1
0
0
1
0
0
0
0
13
22
12
1
1
0
3
0
0
2
1
0
1
2
1
0
27
45
25
3
2
0
5
0
0
0
2
−
=
−
−
−












−
−
−






=
=






−
−
−
−






−
−
−
−
−






J
Q AQ
 
 
 
45. 
v1  =  [42     7    -21   -42]T,    
v2  =  [34    22    -10    -27]T,    
 
v3  =  [1      0      0      0]T, 
 
v4  =  [0      1      3      0]T 
 
[
]
1
2
3
4
42
34
1
0
7
22
0
1
21
10
0
3
42
27
0
0






=
= 

−
−


−
−


Q
v
v
v
v
 
 
1
−
=
J
Q AQ  
 
0
81
27
76
2
1
2
1
42
34
1
0
0
126
42
42
0
3
5
3
7
22
0
1
1
2058
882
294
1764
0
13
22
12
21
10
0
3
2058
0
147
735
392
0
27
45
25
42
27
0
0
−
−
−








−
−




=
−
−
−
−
−








−
−
−
−
−
−




 
 
1
1
0
0
0
1
1
0
0
0
1
0
0
0
0
1






= 





 
 
 
46. 
v1  =  [8    0  -3    1   0]T,      v2  =  [1   0     0   0   3]T 
 
v3  =  [3  -2  -1    0   0]T,      v4  =  [2  -2    0  -3   0]T,        v5  =  [1  -1    0    0   3]T 
 
 
[
]
1
2
3
4
5
8
1
3
2
1
0
0
2
2
1
3
0
1
0
0
1
0
0
3
0
0
3
0
0
3




−
−
−




=
=
−
−


−






Q
v
v
v
v
v
 
      
 
 

408 
Chapter 7 
    
1
−
=
J
Q AQ  
9
0
27
6
3
11
1
26
6
3
8
1
3
2
1
48
3
138
30
15
0
3
0
0
0
0
0
2
2
1
1
27
0
78
18
9
9
0
24
6
3
3
0
1
0
0
3
3
0
9
3
1
3
0
9
5
1
1
0
0
3
0
48
3
138
30
16
48
3
138
30
18
0
3
0
0
3
−
−
−
−
−








−
−
−
−




=
−
−
−
−
−
−








−
−
−
−
−








−
−
−
−
−
−
−
−




 
   
1
1
0
0
0
1
1
0
0
0
1
0
0
0
0
1






=






J
 
 
 
 
SECTION 7.6 
 
NUMERICAL METHODS FOR SYSTEMS 
 
In Problems 1-8 we first write the given system in the form  
( , , ),
( , , ).
x
f t x y
y
g t x y
′
′
=
=
  
Then we use the template 
 
 
1
0
1
0
0
0
0
1
0
0
0
0
2
1
1
1
1
2
1
1
1
1
0.1;
( ,
,
);
( ,
,
)
( ,
,
);
( ,
,
)
h
t
t
h
x
x
h f t
x
y
y
y
h g t
x
y
x
x
h f t x y
y
y
h g t x y
=
=
+
=
+
=
+
=
+
=
+
 
 
(with the given values of   0
0
0
,
, and
t
x
y ) to calculate the Euler approximations  
1
(0.1),
x
x
≈
 
1
2
2
(0.1) and
(0.2),
(0.2)
y
y
x
x
y
y
≈
≈
≈
 in part (a).  We give these approximations and the 
actual values  
act
act
(0.2),
(0.2)
x
x
y
y
=
=
 in tabular form.  We use the template 
 
 
[
]
[
]
1
0
1
0
0
0
0
1
0
0
0
0
1
1
0
0
0
0
1
1
1
2
1
1
0
0
0
0
1
1
1
2
0.2;
( ,
,
);
( ,
,
)
( ,
,
)
( ,
,
)
( ,
,
)
( ,
,
)
h
t
t
h
u
x
h f t
x
y
v
y
h g t
x
y
x
x
h f t
x
y
f t u v
y
y
h g t
x
y
g t u v
=
=
+
=
+
=
+
=
+
+
=
+
+
 
 
to calculate the improved Euler approximations  
1
1
(0.2),
(0.2)
u
x
u
y
≈
≈
 and 
1
1
(0.2),
(0.2)
x
x
y
y
≈
≈
 in part (b).  We give these approximations and the actual values  
act
act
(0.2),
(0.2)
x
x
y
y
=
=
 in tabular form.  We use the template 
 

 
Section 7.6 
409 
 
1
0
0
0
1
0
0
0
1
1
1
1
1
1
2
0
0
1
0
1
2
0
0
1
0
1
2
2
2
2
2
2
1
1
1
1
1
1
3
0
0
2
0
2
3
0
0
2
0
2
2
2
2
2
2
2
4
0
0
3
0
3
4
0
0
3
0.2;
( ,
,
);
( ,
,
)
(
,
,
);
(
,
,
)
(
,
,
);
(
,
,
)
(
,
,
);
(
,
,
h
F
f t
x
y
G
g t
x
y
F
f t
h x
h F y
hG
G
g t
h x
h F y
hG
F
f t
h x
h F y
hG
G
g t
h x
h F y
hG
F
f t
h x
h F y
hG
G
g t
h x
h F y
=
=
=
=
+
+
+
=
+
+
+
=
+
+
+
=
+
+
+
=
+
+
+
=
+
+
(
)
(
)
0
3
1
0
1
2
3
4
1
0
1
2
3
4
)
2
2
;
2
2
6
6
hG
h
h
x
x
F
F
F
F
y
y
G
G
G
G
+
=
+
+
+
+
=
+
+
+
+
 
 
to calculate the intermediate slopes and Runge-Kutta approximations  
1
1
(0.2),
(0.2)
x
x
y
y
≈
≈
 for 
part (c).  Again, we give the results in tabular form. 
 
1. 
(a) 
x1 
y1 
x2 
y2 
xact 
yact 
0.4 
2.2 
0.88 
2.5 
1.0034 
2.6408 
 
 
 
(b) 
u1 
v1 
x1 
y1 
xact 
yact 
0.8 
2.4 
0.96 
2.6 
1.0034 
2.6408 
 
 
 
(c) 
F1 
G1 
F2 
G2 
F3 
G3 
F4 
G4 
4 
2 
4.8 
3 
5.08 
3.26 
6.32 
4.684 
x1 
y1 
xact 
yact 
 
 
 
 
1.0027 
2.6401 
1.0034 
2.6408 
 
 
 
 
 
 
2. 
(a) 
x1 
y1 
x2 
y2 
xact 
yact 
0.9 
–0.9 
0.81 
–0.81 
0.8187 
–0.8187 
 
(b) 
u1 
v1 
x1 
y1 
xact 
yact 
0.8 
–0.8 
0.82 
–0.82 
0.8187 
–0.8187 
 
 
 
(c) 
F1 
G1 
F2 
G2 
F3 
G3 
F4 
G4 
–1 
1 
–0.9 
0.9 
–0.91 
0.91 
–0.818 
0.818 
x1 
y1 
xact 
yact 
 
 
 
 
0.8187 
–0.8187 
0.8187 
–0.8187
 
 
 
 
 
 
3. 
(a) 
x1 
y1 
x2 
y2 
xact 
yact 
1.7 
1.5 
2.81 
2.31 
3.6775 
2.9628 

410 
Chapter 7 
 
 
 
(b) 
u1 
v1 
x1 
y1 
xact 
yact 
2.4 
2 
3.22 
2.62 
3.6775 
2.9628 
 
 
 
(c) 
F1 
G1 
F2 
G2 
F3 
G3 
F4 
G4 
7 
5 
11.1 
8.1 
13.57 
9.95 
23.102 
17.122 
x1 
y1 
xact 
yact 
 
 
 
 
3.6481 
2.9407 
3.6775 
2.9628 
 
 
 
 
 
 
4. 
(a) 
x1 
y1 
x2 
y2 
xact 
yact 
1.9 
–0.6 
3.31 
–1.62 
4.2427 
-2.4205 
 
 
 
(b) 
u1 
v1 
x1 
y1 
xact 
yact 
2.8 
–1.2 
3.82 
–2.04 
4.2427 
-2.4205 
 
 
 
(c) 
F1 
G1 
F2 
G2 
F3 
G3 
F4 
G4 
9 
–6 
14.1 
–10.2 
16.59 
–12.42 
26.442 
–20.94 
x1 
y1 
xact 
yact 
 
 
 
 
4.2274 
–2.4060 
4.2427 
-2.4205
 
 
 
 
 
 
5. 
(a) 
x1 
y1 
x2 
y2 
xact 
yact 
0.9 
3.2 
–0.52 
2.92 
-0.5793 
2.4488 
 
 
 
(b) 
u1 
v1 
x1 
y1 
xact 
yact 
–0.2 
3.4 
–0.84 
2.44 
-0.5793 
2.4488 
 
(c) 
F1 
G1 
F2 
G2 
F3 
G3 
F4 
G4 
–11 
2 
–14.2 
–2.8 
–12.44 
–3.12 
–12.856 
–6.704 
x1 
y1 
xact 
yact 
 
 
 
 
–0.5712 
2.4485 
-0.5793
2.4488 
 
 
 
 
 
 
6. 
(a) 
x1 
y1 
x2 
y2 
xact 
yact 
–0.8 
4.4 
–1.76 
4.68 
-1.9025 
4.4999 
 
 

 
Section 7.6 
411 
 
(b) 
u1 
v1 
x1 
y1 
xact 
yact 
–1.6 
4.8 
–1.92 
4.56 
-1.9025 
4.4999 
 
 
 
(c) 
F1 
G1 
F2 
G2 
F3 
G3 
F4 
G4 
–8 
4 
–9.6 
2.8 
–9.52 
2.36 
–10.848 
0.664 
x1 
y1 
xact 
yact 
 
 
 
 
–1.9029 
4.4995 
-1.9025
4.4999 
 
 
 
 
 
 
7. 
(a) 
x1 
y1 
x2 
y2 
xact 
yact 
2.5 
1.3 
3.12 
1.68 
3.2820 
1.7902 
 
 
 
(b) 
u1 
v1 
x1 
y1 
xact 
yact 
3 
1.6 
3.24 
1.76 
3.2820 
1.7902 
 
 
 
(c) 
F1 
G1 
F2 
G2 
F3 
G3 
F4 
G4 
5 
3 
6.2 
3.8 
6.48 
4 
8.088 
5.096 
x1 
y1 
xact 
yact 
 
 
 
 
3.2816 
1.7899 
3.2820 
1.7902 
 
 
 
 
 
 
8. 
(a) 
x1 
y1 
x2 
y2 
xact 
yact 
0.9 
–0.9 
2.16 
–0.63 
2.5270 
-0.3889 
 
 
 
(b) 
u1 
v1 
x1 
y1 
xact 
yact 
1.8 
–0.8 
2.52 
–0.46 
2.5270 
-0.3889 
 
 
 
(c) 
F1 
G1 
F2 
G2 
F3 
G3 
F4 
G4 
9 
1 
12.6 
2.7 
12.87 
3.25 
16.02 
5.498 
x1 
y1 
xact 
yact 
 
 
 
 
2.5320 
–0.3867 
2.5270 
-0.3889
 
 
 
 
 
 
In Problems 9-11 we use the same Runge-Kutta template as in part (c) of Problems 1–8 above, and 
give both the Runge-Kutta approximate values with step sizes  h  =  0.1  and  h  =  0.05,  and also 
the actual values. 
 

412 
Chapter 7 
9. 
With  h  =   0.1:   
x(1)  ≈  3.99261,   
y(1)  ≈  6.21770 
 
With  h  =  0.05:   
x(1)  ≈  3.99234,   
y(1)  ≈  6.21768 
 
Actual  values:   
x(1)  ≈  3.99232,   
y(1)  ≈  6.21768 
 
10. 
With  h  =   0.1:   
x(1)  ≈  1.31498,   
y(1)  ≈  1.02537 
 
With  h  =  0.05:   
x(1)  ≈  1.31501,   
y(1)  ≈  1.02538 
 
Actual  values:   
x(1)  ≈  1.31501,   
y(1)  ≈  1.02538 
 
11. 
With  h  =   0.1:   
x(1)  ≈  -0.05832,    
y(1)  ≈  0.56664 
 
With  h  =  0.05:   
x(1)  ≈  -0.05832,    
y(1)  ≈  0.56665 
 
Actual  values:   
x(1)  ≈  -0.05832,    
y(1)  ≈  0.56665 
 
12. 
We first convert the given initial value problem to the two-dimensional problem 
 
 
 
 
 
x'  =  y,     
 
x(0)  =  0, 
 
 
 
 
y'  =  -x + sin t, 
y(0)  =  0. 
 
 
Then with both step sizes  h  =  0.1  and  h  =  0.05  we get the actual value  x(1)  ≈  0.15058  
accurate to  5  decimal places. 
 
13. 
With  y  =  x'  we want to solve numerically the initial value problem 
 
 
           
 
x'  =  y,                
x(0)  =  0 
 
   
 
 
y'  =  -32 - 0.04y,     y(0)  =  288. 
 
 
When we run Program RK2DIM with step size  h  =  0.1  we find that the change of sign in 
the velocity  v  occurs as follows: 
 
 
 
 
 
 t  
 
   x  
 
   v           
 
 
 
 
7.6 
 
1050.2  
+2.8 
 
 
 
 
7.7 
 
1050.3   
-0.4 
 
 
Thus the bolt attains a maximum height of about 1050 feet in about 7.7 seconds. 
 
14.   
Now we want to solve numerically the initial value problem 
 
 
 
 
 
x'  =  y,  
 
 
x(0)  =  0, 
 
 
 
 
y'  =  -32 - 0.0002y2,  
y(0)  =  288. 
 
 
Running Program RK2DIM with step size  h  =  0.1,  we find that the bolt attains a 
maximum height of about 1044 ft in about 7.8 sec.  Note that these values are comparable to 
those found in Problem 13. 
   

 
Section 7.6 
413 
15. 
With  y  =  x',  and with  x  in miles and  t  in seconds, we want to solve numerically the 
initial value problem 
 
 
 
 
 
x'  =  y 
 
 
 
 
y'  =  -95485.5/(x2 + 7920x + 15681600) 
 
 
 
 
x(0)  =  0, 
 
y(0)  =  1. 
 
 
We find (running RK2DIM with  h  =  1) that the projectile reaches a maximum height of 
about 83.83 miles in about  168 sec  =  2 min 48 sec. 
 
16. 
We first defined the MATLAB function 
 
 
 
 
function
xp
=
fnball(t,x)
%
Defines the baseball system
%
x1′′′′
=
x′′′′
=
x3,
x3′′′′
=
-cvx′′′′
%
x2′′′′
=
y′′′′
=
x4,
x4′′′′
=
-cvy′′′′- g
%
with air resistance coefficient c.
g
=
32;
c
=
0.0025;
 
 
xp
=
x;
v
=
sqrt(x(3).^2) + x(4).^2);
xp(1)
=
x(3);
xp(2)
=
x(4);
xp(3)
=
-c*v*x(3);
xp(4)
=
-c*v*x(4) - g;
 
 
Then, using the n-dimensional program rkn with step size 0.1 and initial data 
corresponding to the indicated initial inclination angles, we got the following results: 
 
 
 
 
 
Angle   
Time  
Range 
 
 
 
 
 40           
 5.0        
 352.9 
 
 
 
 
 45           
 5.4        
 347.2 
 
 
 
 
 50           
 5.8        
 334.2 
 
 
We have listed the time to the nearest tenth of a second, but have interpolated to find the 
range in feet. 
 
17. 
The data in Problem 16 indicate that the range increases when the initial angle is decreased 
below  45o.  The further data 
 
 
 
 
 
Angle   
Range 
 
 
 
 
 41.0          
 352.1 
 
 
 
 
 40.5      
 352.6 

414 
Chapter 7 
 
 
 
 
 40.0      
 352.9 
 
        
  
 
 39.5         
 352.8 
 
        
 
 
 39.0        
 352.7 
 
      
 
 
 35.0        
 350.8 
 
 
indicate that a maximum range of about  353 ft  is attained with  α  ≈  40o. 
 
18. 
We "shoot" for the proper inclination angle by running program rkn (with  h  =  0.1) as 
follows: 
 
 
      
      
 
Angle        
Range 
 
         
  
 
 60          
 287.1 
 
         
  
  
 58            
 298.5 
 
           
  
57.5         
 301.1 
 
 
Thus we get a range of  300 ft  with an initial angle just under  57.5o. 
 
19. 
First we run program rkn (with  h =  0.1) with  v0  =  250 ft/sec  and obtain the following 
results: 
 
 
             
 
  t        
    x         
     y 
 
         
 
 
5.0        
457.43        
103.90 
 
         
 
 
6.0         
503.73         
  36.36 
 
 
Interpolation gives  x  =  494.4  when  y  =  50.  Then a run with  v0  =  255 ft/sec  gives the 
following results: 
  
                 
 
 
  t           
    x             
   y 
                
 
 
5.5         
486.75        
77.46 
                
 
 
6.0         
508.86        
41.62 
 
 
Finally a run with  v0  =  253 ft/sec  gives these results: 
      
              
    
 
  t           
    x             
   y 
               
  
 
5.5         
484.77        
75.44 
               
  
 
6.0         
506.82        
39.53 
 
 
Now  x  ≈  500 ft  when  y  =  50 ft.  Thus Babe Ruth's home run ball had an initial velocity 
of 253 ft/sec. 
 
20. 
A run of program rkn with  h  =  0.1  and with the given data yields the following results: 
 
            
 
   t   
  x     
  y    
  v         α 
            
 
 5.5       989     539      162     +0.95 
            
 
 5.6    1005     539      161    -0.18 
             
 
  . 
   . 
  . 
   . 
     . 

 
Section 7.6 
415 
             
 
  . 
   . 
  . 
   . 
     . 
             
 
  . 
   . 
  . 
   . 
     . 
             
 
  . 
   . 
  . 
   . 
     . 
           
 
11.5     1868        16       214       -52 
           
 
11.6     1881        -1       216       -53 
 
 
The first two lines of data above indicate that the crossbow bolt attains a maximum height of 
about 1005 ft in about 5.6 sec.  About 6 sec later (total time 11.6 sec) it hits the ground, 
having traveled about 1880 ft horizontally. 
 
21. 
A run with  h  =  0.1  indicates that the projectile has a range of about 21,400 ft  ≈  4.05 mi  
and a flight time of about 46 sec.  It attains a maximum height of about 8970 ft in about 17.5 
sec.  At time  t  ≈  23 sec  it has its minimum velocity of about  368 ft/sec.  It hits the ground 
(t ≈ 46  sec) at an angle of about  77° with a velocity of about 518 ft/sec. 

416 
Chapter 8 
 
CHAPTER 8 
 
MATRIX EXPONENTIAL METHODS 
 
 
SECTION 8.1 
 
In Problems 1–8 we first use the eigenvalues and eigenvectors of the coefficient matrix  A  to 
find first a  fundamental matrix  ΦΦΦΦ(t)  for the homogeneous system  x′  =  Ax.  Then we apply the 
formula 
 
             
 
 
x(t)  =  ΦΦΦΦ(t)ΦΦΦΦ(0)-1x0, 
 
to find the solution vector  x(t)  that satisfies the initial condition  x(0)  =  x0.  Formulas (11) and 
(12) in the text provide inverses of  2-by-2  and  3-by-3  matrices. 
 
1. 
Eigensystem: 
T
T
1
1
2
2
1,
[1
1] ;
3,
[1
1]
λ
λ
=
=
−
=
=
v
v
 
 
1
2
3
1
2
3
( )
t
t
t
t
t
t
e
e
t
e
e
e
e
λ
λ




Φ
=
= 



−


v
v
 
 
3
3
3
3
1
1
3
5
1
1
( )
1
1
2
2
2
5
t
t
t
t
t
t
t
t
e
e
e
e
t
e
e
e
e
−




+



=
⋅
⋅
=







−
−
−
+







x
 
 
2. 
Eigensystem: 
T
T
1
1
2
2
0,
[1
2] ;
4,
[1
2]
λ
λ
=
=
=
=
−
v
v
 
 
1
2
4
1
2
4
1
( )
2
2
t
t
t
t
e
t
e
e
e
λ
λ




Φ
=
= 



−


v
v
 
 
4
4
4
4
2
1
2
1
3
5
1
1
( )
2
1
1
4
4
2
2
6
10
t
t
t
t
e
e
t
e
e




+



=
⋅
⋅
=







−
−
−
−







x
 
 
 
3. 
Eigensystem: 
T
4 ,
[1
2
2]
i
i
λ =
=
+
v
 
 
cos4
2sin4
2cos4
sin4
( )
Re(
)
Im(
)
2cos4
2sin4
t
t
t
t
t
t
t
e
e
t
t
λ
λ
−
+




Φ
=
= 





v
v
 
 
cos4
2sin4
2cos4
sin4
0
2
0
5sin4
1
1
( )
2cos4
2sin4
2
1
1
4cos4
2sin4
4
4
t
t
t
t
t
t
t
t
t
t
−
+
−






=
⋅
⋅
=






−
−






x
 
 

 
Section 8.1 
417 
 
4. 
Eigensystem: 
T
T
1
2
1
2
2, 2;
{
,
} with
[1
1] ,
[1
0]
λ =
=
=
v
v
v
v
 
 
2
1
1
2
1 1
( )
(
)
1
t
t
t
t
t
e
t
e
e
t
λ
λ
+




Φ
=
+
=






v
v
v
 
 
2
2
1 1
0
1
1
1
( )
1
1
1
0
t
t
t
t
t
e
e
t
t
+
+





=
⋅
⋅
=





−





x
 
 
 
5. 
Eigensystem: 
T
3 ,
[ 1
3]
i
i
λ =
= −+
v
 
 
cos3
sin3
cos3
sin3
( )
Re(
)
Im(
)
3cos3
3sin3
t
t
t
t
t
t
t
e
e
t
t
λ
λ
−
−
−




Φ
=
= 





v
v
 
 
cos3
sin3
cos3
sin3
0
1
1
3cos3
sin3
1
1
( )
3cos3
3sin3
3
1
1
3cos3
6sin3
3
3
t
t
t
t
t
t
t
t
t
t
t
−
−
−
−







=
⋅
⋅
=







−
−
+







x
 
 
 
6. 
Eigensystem: 
T
5
4 ,
[1
2
2]
i
i
λ =
+
=
+
v
 
 
5
cos4
2sin4
2cos4
2sin4
( )
Re(
)
Im(
)
2cos4
2sin4
t
t
t
t
t
t
t
t
e
e
e
t
t
λ
λ
−
+




Φ
=
=






v
v
 
 
5
5
cos4
2sin4
2cos4
2sin4
0
2
2
cos4
sin4
1
( )
2
2cos4
2sin4
2
4
0
sin4
4
t
t
t
t
t
t
t
t
t
e
e
t
t
t
−
+
+






=
⋅
⋅
=






−






x
 
 
 
7. 
Eigensystem: 
 
T
T
T
1
1
2
2
3
3
0,
[6 2 5] ;
1,
[3 1 2] ;
1,
[2 1 2]
λ
λ
λ
=
=
=
=
= −
=
v
v
v
 
 
3
1
2
1
2
3
6
3
2
( )
2
5
2
2
t
t
t
t
t
t
t
t
t
e
e
t
e
e
e
e
e
e
e
λ
λ
λ
−
−
−






Φ
=
= 







v
v
v
 
 
6
3
2
0
2
1
2
12
12
2
( )
2
1
2
2
1
4
4
5
2
2
1
3
0
0
10
8
2
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
t
e
e
e
e
e
e
e
e
−
−
−
−
−
−




−
−
+
+








=
⋅
−
⋅
=
−+
+










−
−
+
+








x
 
 
 
8. 
Eigensystem: 
 
T
T
T
1
1
2
2
3
3
2,
[0 1
1] ;
1,
[1
1 0] ;
3,
[1
1 1]
λ
λ
λ
= −
=
−
=
=
−
=
=
−
v
v
v
 

418 
Chapter 8 
 
3
1
2
3
2
3
1
2
3
2
3
0
( )
0
t
t
t
t
t
t
t
t
t
t
e
e
t
e
e
e
e
e
e
e
e
λ
λ
λ
−
−






Φ
=
=
−
−






−


v
v
v
 
 
3
2
3
2
2
3
2
0
1
1
0
1
( )
0
1
1
0
0
1
1
1
1
t
t
t
t
t
t
t
t
t
t
t
e
e
e
t
e
e
e
e
e
e
e
e
−
−
−
−














=
−
−
⋅
−
−
⋅
=
−
+











−
−
−










x
 
 
 
In each of Problems  9-20  we first solve the given linear system to find two linearly 
independent solutions  x1  and  x2,  then set up the fundamental matrix  
[
]
1
2
( )
( )
( )
t
t
t
=
x
x
ΦΦΦΦ
,  
and finally calculate the matrix exponential  
1
( )
(0)
t
e
t
−
= Φ
Φ
A
. 
 
9. 
Eigensystem: 
T
T
1
1
2
2
1,
[1
1] ;
3,
[2
1]
λ
λ
=
=
=
=
v
v
 
 
1
2
3
1
2
3
2
( )
t
t
t
t
t
t
e
e
t
e
e
e
e
λ
λ




Φ
=
= 





v
v
 
 
3
3
3
3
3
3
1
2
2
2
2
2
1
1
2
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
e
e
−




−
+
−


=
=






−
−
+
−






A
 
 
 
10. 
Eigensystem: 
T
T
1
1
2
2
0,
[1
1] ;
2,
[3
2]
λ
λ
=
=
=
=
v
v
 
 
1
2
2
1
2
2
1
3
( )
1
2
t
t
t
t
e
t
e
e
e
λ
λ




Φ
=
= 





v
v
 
 
2
2
2
2
2
2
2
3
1
3
2
3
3
3
1
1
1
2
2
2
3
2
t
t
t
t
t
t
t
e
e
e
e
e
e
e
−




−+
−


=
=






−
−+
−






A
 
 
 
11. 
Eigensystem: 
T
T
1
1
2
2
2,
[1
1] ;
3,
[3
2]
λ
λ
=
=
=
=
v
v
 
 
1
2
2
3
1
2
2
3
3
( )
2
t
t
t
t
t
t
e
e
t
e
e
e
e
λ
λ




Φ
=
= 





v
v
 
 
2
3
2
3
2
3
2
3
2
3
2
3
2
3
3
2
3
3
3
1
1
2
2
2
3
2
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
e
e
−




−
+
−


=
=






−
−
+
−






A
 
 
 

 
Section 8.1 
419 
 
12. 
Eigensystem: 
T
T
1
1
2
2
1,
[1
1] ;
2,
[4
3]
λ
λ
=
=
=
=
v
v
 
 
1
2
2
1
2
2
4
( )
3
t
t
t
t
t
t
e
e
t
e
e
e
e
λ
λ




Φ
=
= 





v
v
 
 
2
2
2
2
2
2
3
4
4
3
4
4
4
1
1
3
3
3
4
3
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
e
e
−




−
+
−


=
=






−
−
+
−






A
 
 
13. 
Eigensystem: 
T
T
1
1
2
2
1,
[1
1] ;
3,
[4
3]
λ
λ
=
=
=
=
v
v
 
 
1
2
3
1
2
3
4
( )
3
t
t
t
t
t
t
e
e
t
e
e
e
e
λ
λ




Φ
=
= 





v
v
 
 
3
3
3
3
3
3
3
4
4
3
4
4
4
1
1
3
3
3
4
3
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
e
e
−




−
+
−


=
=






−
−
+
−






A
 
 
14. 
Eigensystem: 
T
T
1
1
2
2
1,
[2
3] ;
3,
[3
4]
λ
λ
=
=
=
=
v
v
 
 
1
2
2
1
2
2
2
3
( )
3
4
t
t
t
t
t
t
e
e
t
e
e
e
e
λ
λ




Φ
=
= 





v
v
 
 
2
2
2
2
2
2
4
3
2
3
8
9
6
6
3
2
3
4
12
12
9
8
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
e
e
−




−
+
−


=
=






−
−
+
−






A
 
 
15. 
Eigensystem: 
T
T
1
1
2
2
1,
[2
1] ;
2,
[5
2]
λ
λ
=
=
=
=
v
v
 
 
1
2
2
1
2
2
2
5
( )
2
t
t
t
t
t
t
e
e
t
e
e
e
e
λ
λ




Φ
=
= 





v
v
 
 
2
2
2
2
2
2
2
5
2
5
4
5
10
10
1
2
2
2
2
5
4
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
e
e
−




−
+
−


=
=






−
−
+
−






A
 
 
16. 
Eigensystem: 
T
T
1
1
2
2
1,
[3
2] ;
2,
[5
3]
λ
λ
=
=
=
=
v
v
 
 
1
2
2
1
2
2
3
5
( )
2
3
t
t
t
t
t
t
e
e
t
e
e
e
e
λ
λ




Φ
=
= 





v
v
 
 
2
2
2
2
2
2
3
5
3
5
9
10
15
15
2
3
2
3
6
6
10
9
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
e
e
−




−
+
−


=
=






−
−
+
−






A
 
  

420 
Chapter 8 
17. 
Eigensystem: 
T
T
1
1
2
2
2,
[1
1] ;
4,
[1
1]
λ
λ
=
=
−
=
=
v
v
 
 
1
2
2
4
1
2
2
4
( )
t
t
t
t
t
t
e
e
t
e
e
e
e
λ
λ




Φ
=
= 



−


v
v
 
 
2
4
2
4
2
4
2
4
2
4
2
4
1
1
1
1
1
1
2
2
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
e
e
−




+
−
+


=
⋅
=






−
−
+
+






A
 
 
18. 
Eigensystem: 
T
T
1
1
2
2
2,
[1
1] ;
6,
[1
1]
λ
λ
=
=
−
=
=
v
v
 
 
1
2
2
6
1
2
2
6
( )
t
t
t
t
t
t
e
e
t
e
e
e
e
λ
λ




Φ
=
= 



−


v
v
 
 
2
6
2
6
2
6
2
6
2
6
2
6
1
1
1
1
1
1
2
2
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
e
e
−




+
−
+


=
⋅
=






−
−
+
+






A
 
 
19. 
Eigensystem: 
T
T
1
1
2
2
5,
[1
2] ;
10,
[2
1]
λ
λ
=
=
−
=
=
v
v
 
 
1
2
5
10
1
2
5
10
2
( )
2
t
t
t
t
t
t
e
e
t
e
e
e
e
λ
λ




Φ
=
= 



−


v
v
 
 
5
10
5
10
5
10
5
10
5
10
5
10
1
2
2
4
2
2
1
1
2
1
5
5
2
2
2
4
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
e
e
−




+
−
+


=
⋅
=






−
−
+
+






A
 
 
20. 
Eigensystem: 
T
T
1
1
2
2
5,
[1
2] ;
15,
[2
1]
λ
λ
=
=
−
=
=
v
v
 
 
1
2
5
15
1
2
5
15
2
( )
2
t
t
t
t
t
t
e
e
t
e
e
e
e
λ
λ




Φ
=
= 



−


v
v
 
 
5
15
5
15
5
15
5
15
5
15
5
15
1
2
2
4
2
2
1
1
2
1
5
5
2
2
2
4
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
e
e
−




+
−
+


=
⋅
=






−
−
+
+






A
 
 
 
21. 
2
1
so
1
t
t
t
e
t
t
t
+
−


=
=
+
= 

−


A
A
0
I
A
 
 
 
22. 
2
1
6
4
so
9
1
6
t
t
t
e
t
t
t
+


=
=
+
= 

−
−


A
A
0
I
A
 
 

 
Section 8.1 
421 
 
23. 
2
3
2 2
2
1
1
so
1
2
0
0
1
t
t
t
t
t
e
t
t
t
t
t
t


+
−
−−


=
=
+
+
=
−
−






A
A
0
I
A
A
 
 
 
24. 
3
2 2
2
2
1
3
0
3
1
so
5
18
1
7
18
2
3
0
1
3
t
t
t
e
t
t
t
t
t
t
t
t
+
−




=
=
+
+
=
+
−


−




A
A
0
I
A
A
 
 
 
25. 
2
2
2
2
where
, so
(
)(
). Hence
t
t
t
t
e
e
e
e
t
=
+
=
=
=
+
A
I
B
A
I
B
B
0
I
I
B
 
 
2
2
2
2
4
4
35
5
,
( )
7
7
0
t
t
t
t
t
t
t
e
t e
e
t
e
e
e
+





=
=
=










A
A
x
 
 
 
26. 
2
7
7
7
where
, so
(
)(
). Hence
t
t
t
t
e
e
e
e
t
=
+
=
=
=
+
A
I
B
A
I
B
B
0
I
I
B
 
 
7
7
7
7
5
5
0
,
( )
10
10
55
11
t
t
t
t
t
t
e
e
t
e
e
t
t e
e






=
=
=






−
−
+






A
A
x
 
 
 
27. 
3
2 2
1
2
where
, so
(
)(
).
Hence
t
t
t
t
e
e e
e
t
t
=
+
=
=
=
+ +
A
I
B
A
I
B
B
0
I
I
B
 
 
2
2
2
(3
2 )
4
4
28
12
0
2
,
( )
5
5
12
0
0
6
6
t
t
t
t
t
t
t
t
t
e
t e
t
t
e
t
t
e
e
t e
t
e
e
t
e




+
+
+






=
=
=
+















A
A
x
 
 
 
28. 
3
5
5
2 2
1
2
5
where
, so
(
)(
).
Hence
t
t
t
t
e
e
e
e
t
t
=
+
=
=
=
+
+
A
I
B
A
I
B
B
0
I
I
B
B
 
 
5
5
5
5
2
5
5
5
2
0
0
40
40
10
0
,
( )
50
50
400
(20
150 )
30
60
60
2300
6000
t
t
t
t
t
t
t
t
t
e
e
t e
e
t
e
e
t
t
t
e
t e
e
t
t












=
=
=
+








+
+
+










A
A
x
 
 
 
29. 
4
2 2
3 3
1
1
2
6
where
, so
(
)(
).
Hence
t
t
t
t
e
e e
e
t
t
t
=
+
=
=
=
+
+
+
A
I
B
A
I
B
B
0
I
I
B
B
B
 
 

422 
Chapter 8 
2
2
3
2
3
2
2
1
1
2
3
6
4
6
4
1
9
12
4
1
0
1
6
3
6
1
9
6
,
( )
1
0
0
1
2
1
2
1
0
0
0
1
1
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
t
e
e
t
t




+
+
+
+
+
+






+
+
+





=
=
=





+














A
A
x
 
 
30. 
4
3
3
2 2
3 3
1
1
2
6
3
where
, so
(
)(
).
t
t
t
t
e
e
e
e
t
t
t
=
+
=
=
=
+
+
+
A
I
B
A
I
B
B
0
I
I
B
B
B
 
 
Hence 
 
3
3
2
2
2
3
2
2
3
1
0
0
0
1
1
6
1
0
0
1
1
6
,
( )
9
18
6
1
0
1
1 15
18
12
54
36
9
18
6
1
1
1
27
72
36
t
t
t
t
t
t
e
e
t
e
e
t
t
t
t
t
t
t
t
t
t
t
t
t
t










+





=
=
=
+
+
+










+
+
+
+
+
+





A
A
x
 
 
  
33. 
cosh
sinh
cosh
sinh
sinh
cosh
t
t
t
e
t
t
t
t


=
+
=




A
I
A
,  so the general solution of  ′ =
x
Ax   is 
 
1
2
1
2
cosh
sinh
( )
sinh
cosh
t
c
t
c
t
t
e
c
t
c
t
+


=
=


+


A
x
c
. 
 
34. 
Direct calculation gives  
2
4
= −
A
I ,  and it follows that  
3
4
4
and
16 .
= −
=
A
A
A
I  
 
Therefore 
 
2
3
4
5
2
4
3
5
1
2
4
4
16
16
2!
3!
4!
5!
(2 )
(2 )
1
(2 )
(2 )
1
(2 )
2!
4!
2
3!
5!
cos2
sin2
t
t
t
t
t
t
e
t
t
t
t
t
t
e
t
t
=
+
−
−
+
+
+




=
−
+
+
+
−
+
+








=
+
A
A
I
A
I
A
I
A
I
A
I
A


  
 
In Problems 35–40 we give first the linearly independent generalized eigenvectors  
1
2
,
,
,
n
u u
u

 
of the matrix  A  and the corresponding solution vectors  
1
2
( ),
( ),
,
( )
n
t
t
t
x
x
x

 defined by Eq. 
(34) in the text, then the fundamental matrix  
[
]
1
2
( )
( )
( )
( )
n
t
t
t
t
Φ
=
x
x
x

.  Finally we 
calculate the exponential matrix  
1
( )
(0) .
t
e
t
−
= Φ
Φ
A
 
 
35. 
T
T
1
2
3:
[4
0] ,
[0
1]
λ =
=
=
u
u
 
 
1
2
{
,
}
u u
is a length 2 chain based on the ordinary (rank 1) eigenvector  u1,  so   
 
u2  is a generalized eigenvector of rank 2. 

 
Section 8.1 
423 
 
 
(
)
1
1
2
2
2
( )
,
( )
(
)
t
t
t
e
t
e
t
λ
λ
λ
=
=
+
−
x
u
x
u
A
I u
 
 
3
1
2
4
4
( )
[
( )
( )]
0
1
t
t
t
t
t
e 

Φ
=
=




x
x
 
 
3
3
4
4
1
0
1
4
1
0
1
0
4
0
1
4
t
t
t
t
t
e
e
e






=
⋅
=












A
 
 
36. 
T
T
T
1
2
3
1:
[8
0
0] ,
[5
4
0] ,
[0
1
1]
λ =
=
=
=
u
u
u
 
 
1
2
3
{
,
,
}
u u
u
is a length 3 chain based on the ordinary (rank 1) eigenvector  u1,  so   
 
u2  and  u3  are generalized eigenvectors of ranks 2 and 3 (respectively). 
 
(
)
1
1
2
2
2
( )
,
( )
(
)
,
t
t
t
e
t
e
t
λ
λ
λ
=
=
+
−
x
u
x
u
A
I u
 
 
(
)
2
2
3
3
3
3
( )
(
)
(
)
/ 2
t
t
e
t
t
λ
λ
λ
=
+
−
+
−
x
u
A
I u
A
I u
 
 
2
1
2
3
8
5
8
5
4
( )
[
( )
( )
( )]
0
4
1
4
0
0
1
t
t
t
t
t
t
t
t
e
t


+
+


Φ
=
=
+






x
x
x
 
 
2
2
8
5
8
5
4
4
5
5
1
2
3
4
1
0
4
1
4
0
8
8
0
1
4
32
0
0
1
0
0
32
0
0
1
t
t
t
t
t
t
t
t
t
e
e
t
e
t




+
+
−
+








=
+
⋅
−
=


















A
 
 
37. 
1
T
1
1
1
1
2 :
[1
0
0] ,
( )
t
t
eλ
λ
=
=
=
u
x
u  
 
T
T
2
2
3
1:
[9
3
0] ,
[10
1
1]
λ
=
=
−
=
−
u
u
 
 
2
3
{
,
}
u
u
is a length 2 chain based on the ordinary (rank 1) eigenvector  u2,  so   
 
u3  is a generalized eigenvector of rank 2. 
 
(
)
2
2
2
2
3
3
2
3
( )
,
( )
(
)
t
t
t
e
t
e
t
λ
λ
λ
=
=
+
−
x
u
x
u
A
I u
 
 
2
1
2
3
9
(10
9 )
( )
[
( )
( )
( )]
0
3
(1
3 )
0
0
t
t
t
t
t
t
e
e
t e
t
t
t
t
e
t e
e


+


Φ
=
=
−
−




−


x
x
x
 
 
2
9
(10
9 )
3
9
13
1
0
3
(1
3 )
0
1
1
3
0
0
0
0
3
t
t
t
t
t
t
t
e
e
t e
e
e
t e
e


+






=
−
−
⋅
−
−






−
−






A
 

424 
Chapter 8 
 
(
)
2
2
2
3
3
13
9
13
0
3
0
0
t
t
t
t
t
t
t
t
e
e
e
t e
e
e
t e
e


−
+
−
−
+


= 





 
 
 
 
 
38. 
1
T
1
1
1
1
10 :
[4
1
0] ,
( )
t
t
eλ
λ
=
=
=
u
x
u  
 
T
T
2
2
3
5:
[50
0
0] ,
[0
4
1]
λ
=
=
=
−
u
u
 
 
2
3
{
,
}
u
u
is a length 2 chain based on the ordinary (rank 1) eigenvector  u2,  so   
 
u3  is a generalized eigenvector of rank 2. 
 
(
)
2
2
2
2
3
3
2
3
( )
,
( )
(
)
t
t
t
e
t
e
t
λ
λ
λ
=
=
+
−
x
u
x
u
A
I u
 
 
10
5
5
10
5
1
2
3
5
4
50
50
( )
[
( )
( )
( )]
0
4
0
0
t
t
t
t
t
t
e
e
t e
t
t
t
t
e
e
e




Φ
=
= 



−


x
x
x
 
 
10
5
5
10
5
5
4
50
50
0
50
200
1
0
4
1
4
16
50
0
0
0
0
50
t
t
t
t
t
t
t
e
e
t e
e
e
e
e








=
⋅
−
−






−
−






A
 
 
5
10
5
10
5
10
10
5
5
4
4
16
(16
50 )
0
4
4
0
0
t
t
t
t
t
t
t
t
t
e
e
e
e
t e
e
e
e
e


−
−
+


=
−






 
 
 
 
 
39. 
T
T
2
1
2
1:
[3
0
0
0] ,
[0
1
0
0]
λ
=
=
=
u
u
 
 
1
2
{
,
}
u u
is a length 2 chain based on the ordinary (rank 1) eigenvector  u1,  so   
 
u2  is a generalized eigenvector of rank 2. 
 
(
)
1
1
1
1
2
2
1
2
( )
,
( )
(
)
t
t
t
e
t
e
t
λ
λ
λ
=
=
+
−
x
u
x
u
A
I u
 
 
T
T
2
3
4
2 :
[144
36
12
0] ,
[0
27
17
4]
λ
=
=
=
u
u
 
 
3
4
{
,
}
u
u
is a length 2 chain based on the ordinary (rank 1) eigenvector  u3,  so   
 
u4  is a generalized eigenvector of rank 2. 
 
(
)
2
2
3
3
4
4
2
4
( )
,
( )
(
)
t
t
t
e
t
e
t
λ
λ
λ
=
=
+
−
x
u
x
u
A
I u
 
 
2
2
2
2
1
2
3
4
2
2
2
3
3
144
144
0
36
(27
36 )
( )
[
( )
( )
( )
( )]
0
0
12
(17
12 )
0
0
0
4
t
t
t
t
t
t
t
t
t
t
e
t e
e
t e
e
e
t e
t
t
t
t
t
e
t e
e




+


Φ
=
= 

+






x
x
x
x
 

 
Section 8.1 
425 
 
 
2
2
2
2
2
2
2
16
0
192
816
3
3
144
144
0
48
144
288
0
36
(27
36 )
1
0
0
4
17
48
0
0
12
(17
12 )
0
0
0
12
0
0
0
4
t
t
t
t
t
t
t
t
t
t
t
e
t e
e
t e
e
e
t e
e
e
t e
e
−








−
+




=
⋅


−


+










A
 
 
 
2
2
2
2
2
2
2
3
( 12
9 )
12
(51 18 )
( 51
36 )
0
3
3
6
( 6
9 )
0
0
3
0
0
0
t
t
t
t
t
t
t
t
t
t
t
t
t
t
e
t e
t e
t e
t e
t e
e
e
e
e
t e
e
t e
e


−
−
+
+
+ −
+


−
+
+ −+


= 







 
 
 
 
 
 
40. 
1
T
1
1
1
1
3:
[100
20
4
1] ,
( )
t
t
eλ
λ
=
=
=
u
x
u  
 
T
T
T
2
3
4
2 :
[16
0
0 0] ,
[0
4
0
0] ,
[0
1
1
0]
λ =
=
=
=
−
u
u
u
 
 
 
2
3
4
{
,
,
}
u
u
u
is a length 3 chain based on the ordinary (rank 1) eigenvector  u2,  so   
 
u3  and  u4  are generalized eigenvectors of ranks 2 and 3 (respectively). 
 
 
(
)
2
2
2
2
3
3
2
3
( )
,
( )
(
)
,
t
t
t
e
t
e
t
λ
λ
λ
=
=
+
−
x
u
x
u
A
I u
 
 
(
)
2
2
2
4
4
2
4
2
4
( )
(
)
(
)
/ 2
t
t
e
t
t
λ
λ
λ
=
+
−
+
−
x
u
A
I u
A
I u
 
 
 
3
2
2
2
2
3
2
2
1
2
3
4
3
2
3
100
16
16
8
20
0
4
( 1
4 )
( )
[
( )
( )
( )
( )]
4
0
0
0
0
0
t
t
t
t
t
t
t
t
t
t
e
e
t e
t e
e
e
t e
t
t
t
t
t
e
e
e




−+


Φ
=
= 







x
x
x
x
 
 
 
3
2
2
2
2
3
2
2
3
2
3
0
0
0
16
100
16
16
8
1
0
0
100
20
0
4
( 1
4 )
1
0
4
4
96
16
4
0
0
0
0
16
64
0
0
0
t
t
t
t
t
t
t
t
t
t
t
e
e
t e
t e
e
e
t e
e
e
e
e








−
−+




=
⋅


−






−






A
 
 
 
2
2
2
2
3
2
2
2
2
3
2
2
3
2
3
4
(4
8 )
100
(100
96
32 )
0
4
20
(20
16 )
0
0
4
4
0
0
0
t
t
t
t
t
t
t
t
t
t
t
t
t
e
t e
t
t
e
e
t
t
e
e
t e
e
t e
e
e
e
e


+
−
+
+


−
+


= 

−






 
 
 
 

426 
Chapter 8 
SECTION 8.2 
 
NONHOMOGENEOUS LINEAR SYSTEMS 
 
1. 
Substitution of the trial solution  
( )
,
( )
p
p
x
t
a
y
t
b
=
=
  yields the equations  
2
3
0, 2
2
0
a
b
a
b
+
+
=
+
−
=
  with solution  a = 7/3,  b = –8/3.  Thus we obtain the 
particular solution  ( )
7 /3,
( )
8/3
x t
y t
=
= −
. 
 
2. 
When we substitute the trial solution  
1
1
2
2
( )
,
( )
p
p
x
t
a
b t
y
t
a
b t
=
+
=
+
  and collect 
coefficients, we get the equations 
 
 
 
 
1
2
1
1
2
1
2
2
1
2
2
3
5
2
3
0
2
2
2.
a
a
b
b
b
a
a
b
b
b
+
+
=
+
=
+
=
+
=
 
 
We first solve the second pair for  
1
2
3/ 2,
1.
b
b
=
= −
  Then we can solve the first pair for 
1
2
1/8,
5/ 4.
a
a
=
= −
  This gives the particular solution 
 
 
 
 
1
1
( )
(1 12 ),
( )
(5
4 ).
8
4
x t
t
y t
t
=
+
= −
+
 
 
3. 
When we substitute the trial solution 
 
 
 
 
2
2
1
1
1
2
2
2
,
p
p
x
a
b t
c t
y
a
b t
c t
=
+
+
=
+
+
 
 
 
and collect coefficients, we get the equations 
 
 
 
1
2
1
1
2
1
1
2
1
2
2
1
2
2
1
2
3
4
3
4
2
3
4
0
3
2
3
2
2
3
2
1
0.
a
a
b
b
b
c
c
c
a
a
b
b
b
c
c
c
+
=
+
=
+
=
+
=
+
=
+
+
=
 
 
 
 
Working backwards, we solve first for  
1
2
2/3,
1/ 2,
c
c
= −
=
 then for  
1
2
10/ 9,
7/6,
b
b
=
= −
 and finally for  
1
2
31/ 27,
41/36.
a
a
= −
=
  This determines the 
particular solution  
( ),
( ).
p
p
x
t
y
t
  Next, the coefficient matrix of the associated 
homogeneous system has eigenvalues  
1
1
λ = − and  
2
6
λ =
 with eigenvectors  
T
1
[1
1]
=
−
v
 and  
T
2
[4
3] ,
=
v
 respectively, so the complementary solution is given 
by   
 
 
 
6
6
1
2
1
2
( )
4
,
( )
3
.
t
t
t
t
c
c
x t
c e
c e
x t
c e
c e
−
−
=
+
= −
+
 
 
 
 
When we impose the initial conditions  (0)
0,
(0)
0
x
y
=
=
  on the general solution  
 
( )
( )
( ),
( )
( )
( )
c
p
c
p
x t
x t
x
t
y t
y t
y
t
=
+
=
+
  we find that  
1
2
8/7,
1/756.
c
c
=
=
  This 
finally gives the desired particular solution 

 
Section 8.2 
427 
 
 
 
 
6
2
6
2
1
( )
( 864
4
868
840
504
)
756
1
( )
( 864
3
861
882
378
).
756
t
t
t
t
x t
e
e
t
t
y t
e
e
t
t
−
−
=
+
−
+
−
=
−
+
+
−
+
 
 
4. 
The coefficient matrix of the associated homogeneous system has eigenvalues  
1
5
λ = − 
and  
2
2
λ = − with eigenvectors  
T
1
[1
1]
=
v
 and  
T
2
[1
6] ,
=
−
v
 respectively, so the 
complementary solution is given by   
 
x t
c e
c e
y t
c e
c e
c
t
t
c
t
t
( )
,
( )
.
=
+
=
−
−
−
1
5
2
2
1
5
2
2
6
 
 
Then we try  
( )
,
( )
t
t
p
p
x
t
ae
y
t
be
=
=
  and find readily the particular solution  
3
1
12
4
( )
,
( )
t
t
p
p
x
t
e
y
t
e
= −
= −
.  Thus the general solution is 
 
5
2
5
2
3
1
1
2
1
2
12
4
( )
,
( )
6
.
t
t
t
t
t
t
x t
c e
c e
e
y t
c e
c e
e
−
−
=
+
−
=
−
−
 
 
Finally we apply the initial conditions  (0)
(0)
1
x
y
=
=   to determine  c1 = 33/28  and   
c2  = –2/21.  The resulting particular solution is given by 
 
5
2
5
2
1
1
( )
(99
8
7 ),
( )
(99
48
63 ).
84
84
t
t
t
t
t
t
x t
e
e
e
y t
e
e
e
−
−
=
−
−
=
+
−
 
 
5. 
The coefficient matrix of the associated homogeneous system has eigenvalues  
1
1
λ = − 
and  
2
5,
λ =
  so the nonhomogeneous term  
t
e−duplicates part of the complementary 
solution.   We therefore try the particular solution 
 
 
 
1
1
1
2
2
2
( )
,
( )
.
t
t
t
t
p
p
x
t
a
b e
c t e
y
t
a
b e
c t e
−
−
−
−
=
+
+
=
+
+
 
 
Upon solving the six linear equations we get by collecting coefficients after substitution 
of this trial solution into the given nonhomogeneous system, we obtain the particular 
solution 
1
1
( )
( 12
7
),
( )
( 6
7
).
3
3
t
t
t
x t
e
t e
y t
t e
−
−
−
=
−
−
−
=
−−
 
 
6. 
The coefficient matrix of the associated homogeneous system has eigenvalues  
(
)
1
2 7
89
λ =
±
 so there is no duplication.  We therefore try the particular solution 
 
 
 
 
1
1
2
2
.
( )
,
( )
t
t
t
t
p
p
x
t
b e
c t e
y
t
b e
c t e
=
+
=
+
   
 

428 
Chapter 8 
Upon solving the four linear equations we get by collecting coefficients after substitution 
of this trial solution into the given nonhomogeneous system, we obtain the particular 
solution 
1
1
( )
(91 16 )
,
( )
(25
16 )
256
32
t
t
x t
t e
y t
t e
= −
+
=
+
. 
 
7. 
First we try the particular solution 
 
 
 
1
1
2
2
.
( )
sin
cos ,
( )
sin
cos
p
p
x
t
a
t
b
t
y
t
a
t
b
t
=
+
=
+
 
 
 
Upon solving the four linear equations we get by collecting coefficients after substitution 
of this trial solution into the given nonhomogeneous system, we find that  
1
21/82,
a = −
 
1
2
2
25/82,
15/ 41,
12/ 41.
b
a
b
= −
= −
= −
  The coefficient matrix of the associated 
homogeneous system has eigenvalues  
1
1
λ =  and  
2
9
λ = − with eigenvectors  
T
1
[1
1]
=
v
 and  
T
2
[2
3] ,
=
−
v
 respectively, so the complementary solution is given 
by   
 
 
 
9
9
1
2
1
2
( )
2
,
( )
3
.
t
t
t
t
c
c
x t
c e
c e
y t
c e
c e
−
−
=
+
=
−
 
 
When we impose the initial conditions  x(0) = 1,  y(0) = 0,  we find that  
1
9/10
c =
 and  
2
83/ 410.
c =
  It follows that the desired particular solution  
,
c
p
c
p
x
x
x
y
y
y
=
+
=
+
 is 
given by 
9
9
1
( )
(369
166
125cos
105sin )
410
1
( )
(369
249
120cos
150sin ).
410
t
t
t
t
x t
e
e
t
t
y t
e
e
t
t
−
−
=
+
−
−
=
−
−
−
 
 
8. 
The coefficient matrix of the associated homogeneous system has eigenvalues  
2 ,i
λ = ±
 
so the complementary function involves  cos2
and sin 2 .
t
t  There being therefore no 
duplication, we substitute the trial solution 
 
 
 
1
1
2
2
( )
sin
cos ,
( )
sin
cos
p
p
x
t
a
t
b
t
y
t
a
t
b
t
=
+
=
+
   
 
 
into the given nonhomogeneous system.  Upon solving the four linear equations that 
result upon collection of coefficients, we obtain the particular solution 
 
1
1
( )
(17cos
2sin ),
( )
(3cos
5sin ).
3
3
x t
t
t
y t
t
t
=
+
=
+
 
 
9. 
Here the associated homogeneous system is the same as in Problem 8, so the 
nonhomogeneous term  cos 2t  term duplicates the complementary function.  We 
therefore substitute the trial solution   
 

 
Section 8.2 
429 
1
1
1
1
2
2
2
2
( )
sin2
cos2
sin2
cos2
( )
sin2
cos2
sin2
cos2
p
p
x
t
a
t
b
t
c t
t
d t
t
y
t
a
t
b
t
c t
t
d t
t
=
+
+
+
=
+
+
+
 
 
 
and use a computer algebra system to solve the system of 8 linear equations that results 
when we collect coefficients in the usual way.   This gives the particular solution 
 
1
1
( )
(sin2
2 cos2
sin2 ),
( )
sin 2 .
4
4
x t
t
t
t
t
t
y t
t
t
=
+
+
=
 
 
10. 
The coefficient matrix of the associated homogeneous system has eigenvalues  
3,
i
λ = ±
 
so there is no duplication.  Substitution of the trial solution 
 
1
1
2
2
( )
cos
sin ,
( )
cos
sin
t
t
t
t
p
p
x
t
a e
t
b e
t
y
t
a e
t
b e
t
=
+
=
+
 
 
 
yields the equations 
 
 
 
 
2
1
1
2
2
2
1
2
1
2
2
0
2
2
0
2
0
2
2
1.
a
b
a
a
b
b
a
a
b
b
+
=
−
+
+
=
−
=
−
−
+
=
 
 
 
The first two equations enable us to eliminate two of the variables immediately, and we 
readily solve for the values  
1
2
1
2
4/13,
3/13,
6/13,
2/13
a
a
b
b
=
=
= −
=
  that give the 
particular solution 
 
1
1
( )
(4cos
6sin ),
( )
(3cos
2sin ).
13
13
t
t
x t
e
t
t
y t
e
t
t
=
−
=
+
 
 
11. 
The coefficient matrix of the associated homogeneous system has eigenvalues  
1
0
λ =
 
and  
2
4,
λ =
  so there is duplication of constant terms.   We therefore substitute the 
particular solution 
 
 
 
 
1
1
2
2
( )
,
( )
p
p
x
t
a
b t
y
t
a
b t
=
+
=
+
  
 
 
and solve the resulting equations for  
1
2
1
2
2,
0,
2,
1.
a
a
b
b
= −
=
= −
=
 The eigenvectors 
of the coefficient matrix associated with the eigenvalues  
1
0
λ =
 and  
2
4
λ =
 are  
T
1
[2
1]
=
−
v
 and  
T
2
[2
1] ,
=
v
 respectively, so the general solution of the given 
nonhomogeneous system is given by 
 
 
 
 
4
4
1
2
1
2
( )
2
2
2
2 ,
( )
.
t
t
x t
c
c e
t
y t
c
c e
t
=
+
−
−
= −
+
+
 
 
 
 
When we impose the initial conditions  (0)
1,
(0)
1
x
y
=
= − we find readily that  
1
2
5/ 4,
1/ 4.
c
c
=
=
  This gives the desired particular solution 
 

430 
Chapter 8 
4
4
1
1
2
4
( )
(1
4
),
( )
( 5
4
).
t
t
x t
t
e
y t
t
e
=
−
+
=
−+
+
 
 
12. 
The coefficient matrix of the associated homogeneous system has eigenvalues  
1
0
λ =
 
and  
2
2,
λ =
  so there is duplication of constant terms in the first natural attempt.  We 
must multiply the t-terms by  t  and include all lower degree terms in the trial solution.  
Thus we substitute the the trial solution 
 
2
2
1
1
1
2
2
2
( )
,
( )
p
p
x
t
a
b t
c t
y
t
a
b t
c t
=
+
+
=
+
+
. 
 
 
The resulting six equations in the coefficients are satisfied by  
1
1
2
2
0,
a
b
a
b
=
=
=
=
  
1
2
1,
1.
c
c
=
= −
  This gives the particular solution  
2
2
( )
,
( )
.
x t
t
y t
t
=
= −
 
 
13. 
The coefficient matrix of the associated homogeneous system has eigenvalues  
1
1
λ =  and  
2
3,
λ =
  so there is duplication of  et terms.  We therefore substitute the trial solution 
 
1
1
2
2
( )
(
)
,
( )
(
)
.
t
t
p
p
x
t
a
b t e
y
t
a
b t e
=
+
=
+
 
 
 
This leads readily to the particular solution   
 
 
 
1
5
( )
(1
5 )
,
( )
.
2
2
t
t
x t
t e
y t
t e
=
+
= −
 
 
14. 
The coefficient matrix of the associated homogeneous system has eigenvalues  
1
0
λ =
 
and  
2
4,
λ =
  so there is duplication of both constant terms and  
4t
e  terms.   We therefore 
substitute the particular solution 
 
4
4
4
4
1
1
1
1
2
2
2
2
( )
,
( )
.
t
t
t
t
p
p
x
t
a
bt
c e
d t e
y
t
a
b t
c e
d t e
=
+
+
+
=
+
+
+
 
 
 
When we use a computer algebra system to solve the resulting system of 8 equations in 8 
unknowns, we find that  
2
2
and
a
c  can be chosen arbitrarily.  With both zero we get the 
particular solution 
 
(
)
(
)
4
4
4
1
( )
2
4
2
,
( )
2
.
8
2
t
t
t
t
x t
t
e
t e
y t
e
=
−+
−
+
=
−+
 
 
 
In Problems 15 and 16 the amounts  
1
2
( ) and
( )
x t
x t   in the two tanks satisfy the equations 
 
 
 
 
1
0
1 1
2
1 1
2
2
,
x
rc
k x
x
k x
k x
′
′
=
−
=
−
 
 

 
Section 8.2 
431 
where  
/
i
i
k
r V
=
  in terms of the flow rate  r,  the inflowing concentration  c0, and the volumes 
1
2
and
V
V  of the two tanks. 
 
15. 
(a) 
We solve the initial value problem 
 
 
 
1
1
1
2
1
2
2
20
/10,
(0)
0
/10
/ 20,
(0)
0
x
x
x
x
x
x
x
′ =
−
=
′ =
−
=
 
 
 
 
for  
/10
/10
/ 20
1
2
( )
200(1
),
( )
400(1
2
)
t
t
t
x t
e
x t
e
e
−
−
−
=
−
=
+
−
. 
 
(b) 
Evidently  
1
2
( )
200gal and
( )
400 gal as
.
x t
x t
t
→
→
→∞ 
 
(c) 
It takes about 6 min 56 sec for tank 1 to reach a salt concentration of 1 lb/gal, and 
about 24 min 34 sec for tank 2 to reach this concentration. 
 
16. 
(a) 
We solve the initial value problem 
 
 
 
1
1
1
2
1
2
2
30
/ 20,
(0)
0
/ 20
/10,
(0)
0
x
x
x
x
x
x
x
′ =
−
=
′ =
−
=
 
 
 
 
for  
/ 20
/10
/ 20
1
2
( )
600(1
),
( )
300(1
2
)
t
t
t
x t
e
x t
e
e
−
−
−
=
−
=
+
−
. 
 
(b) 
Evidently  
1
2
( )
600 gal and
( )
300 gal as
.
x t
x t
t
→
→
→∞ 
 
(c) 
It takes about 8 min 7 sec for tank 1 to reach a salt concentration of 1 lb/gal, and 
about 17 min 13 sec for tank 2 to reach this concentration. 
 
 
In Problems 17–34 we apply the variation of parameters formula in Eq. (28) of Section 8.2.  The 
answers shown below were actually calculated using the Mathematica code listed in the 
application material for Section 8.2.  For instance, for Problem 17 we first enter the coefficient  
matrix 
A = {{6,
-7},
{1,
-2}};
the initial vector 
x0 = {{0},
{0}};
and the vector 
f[t_] := {{60},
{90}};  

432 
Chapter 8 
of nonhomogeneous terms.  It simplifies the notation to rename Mathematica's exponential 
matrix function by defining 
 
 
exp[A_] := MatrixExp[A]
 
Then the integral in the variation of parameters formula is given by 
 
integral =
Integrate[exp[-A*s] . f[s], {s, 0, t}] // Simplify 
 
 
5
5
102
7
95
.
96
95
t
t
t
t
e
e
e
e
−
−


−
+
+


−
+
+


 
 
Finally the desired particular solution is given by 
 
solution =
exp[A*t] . (x0 + integral) // Simplify 
 
 
5
5
102
7
95
.
96
95
t
t
t
t
e
e
e
e
−
−


−
−


−
−


 
 
(Maple and MATLAB versions of this computation are provided in the applications manual that 
accompanies the textbook.) 
 
 
In each succeeding problem, we need only substitute the given coefficient matrix  A,  initial 
vector  x0, and the vector  f  of nonhomogeneous terms in the above commands, and then re-
execute them in turn.  We give below only the component functions of the final results.  
 
17. 
5
5
1
2
( )
102
95
7
,
( )
96
95
t
t
t
t
x t
e
e
x t
e
e
−
−
=
−
−
=
−
−
 
 
18. 
5
5
1
2
( )
68
110
75
7
,
( )
74
80
75
t
t
t
t
x t
t
e
e
x t
t
e
e
−
−
+
=
−
−
=
−
−
+
 
 
19. 
3
2
3
2
1
2
( )
70
60
16
54
,
( )
5
60
32
27
t
t
t
t
x t
t
e
e
x t
t
e
e
−
−
= −
−
+
+
=
−
−
+
 
 
20. 
2
2
3
2
2
3
1
2
( )
3
60
3
,
( )
6
30
6
t
t
t
t
t
t
x t
e
t e
e
x t
e
t e
e
−
−
=
+
−
= −
+
+
 
 
21. 
2
3
2
3
1
2
( )
14
15
,
( )
5
10
15
t
t
t
t
t
t
x t
e
e
e
x t
e
e
e
−
−
= −
−
+
= −
−
+
 
 
22. 
3
3
3
3
1
2
( )
10
7
10
5
,
( )
15
35
15
5
t
t
t
t
t
t
t
t
x t
e
t e
e
t e
x t
e
t e
e
t e
−
−
−
−
= −
−
+
−
= −
−
+
−
 
 
23. 
2
2
1
2
( )
3 11
8
,
( )
5
17
24
x t
t
t
x t
t
t
=
+
+
=
+
+
 

 
Section 8.2 
433 
24. 
1
2
1
( )
2
ln ,
( )
5
3
3ln
x t
t
t
x t
t
t
t
=
+ +
=
+
−
+
 
 
25. 
1
2
( )
1
8
cos
8sin ,
( )
2
4
2cos
3sin
x t
t
t
t
x t
t
t
t
= −+
+
−
= −
+
+
−
 
26. 
1
2
( )
3cos
32sin
17 cos
4 sin
( )
5cos
13sin
6 cos
5 sin
x t
t
t
t
t
t
t
x t
t
t
t
t
t
t
=
−
+
+
=
−
+
+
 
 
27. 
3
4
2
3
4
1
2
( )
8
6
,
( )
3
2
3
x t
t
t
x t
t
t
t
=
+
=
−
+
 
 
28. 
2
2
2
2
1
2
( )
7
14
6
4
ln ,
( )
7
9
3
ln
2 ln
2
ln
x t
t
t
t
t
x t
t
t
t
t
t
t
t
= −
+
−
+
= −
+
−
+
−
+
 
 
29. 
1
2
( )
cos
ln(cos )sin ,
( )
sin
ln(cos )cos
x t
t
t
t
t
x t
t
t
t
t
=
−
=
−
 
 
30. 
2
2
1
1
1
2
2
2
( )
cos2 ,
( )
sin2
x t
t
t
x t
t
t
=
=
 
 
31. 
2
3
2
1
2
3
( )
(9
4
)
,
( )
6
,
( )
6
t
t
t
x t
t
t
e
x t
t e
x t
t e
=
+
=
=
 
 
32. 
2
2
2
1
2
3
( )
(44
18 )
( 44
26 )
,
( )
6
( 6
6 )
,
( )
2
t
t
t
t
t
x t
t e
t e
x t
e
t e
x t
t e
=
+
+ −
+
=
+ −+
=
 
33. 
2
3
4
5
2
3
4
1
2
2
3
2
3
4
( )
15
60
95
12 ,
( )
15
55
15 ,
( )
15
20
( )
15
,
x t
t
t
t
t
x t
t
t
t
x t
t
t
x t
t
=
+
+
+
=
+
+
=
+
=
 
34. 
3
2
2
2
2
1
2
2
2
2
3
4
( )
4
(4
16
8
)
,
( )
3
(2
4 )
,
( )
(2
4
2
)
( )
(1
)
,
t
t
t
t
x t
t
t
t
e
x t
t
t e
x t
t
t
e
x t
t e
=
+
+
+
=
+
+
=
+
+
=
+
 
 
 
 
SECTION 8.3 
 
SPECTRAL DECOMPOSITION METHODS 
 
In Problems 1–20 here we want to use projection matrices to find fundamental matrix solutions 
of the linear systems given in Problems 1–20 of Section 7.3.  In each of Problems 1–16, the 
coefficient matrix  A  is 2 2
×  with  distinct eigenvalues  
1
2
and
.
λ
λ  We can therefore use the 
method of Example 1 in Section 8.3.  That is, if we define the projection matrices 
 
 
 
 
2
1
1
2
1
2
2
1
and
,
λ
λ
λ
λ
λ
λ
−
−
=
=
−
−
A
I
A
I
P
P
 
 
 
(1) 

434 
Chapter 8 
 
then the desired fundamental matrix solution of  the system  ′ =
x
Ax  is the exponential matrix 
 
 
 
 
 
1
2
1
2.
t
t
t
e
e
e
λ
λ
=
+
A
P
P   
 
 
 
(2) 
 
We use the eigenvalues  
1
2
and
λ
λ  given in the Section 7.3 solutions for these problems. 
 
1. 
1
2
1
2 ;
1,
3
2
1
λ
λ


=
= −
=




A
 
 
(
)
(
)
1
2
1
1
1 1
1
1
1
1
3
,
1
1
1 1
4
2
4
2
−




=
−
=
=
+
=




−
−




P
A
I
P
A
I
 
 
3
3
3
1
2
3
3
1
2
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
−
−
−
−
−


+
−
+
=
+
=


−
+
+


A
P
P
 
 
 
 
 
2. 
1
2
2
3 ;
1,
4
2
1
λ
λ


=
= −
=




A
 
 
(
)
(
)
1
2
2
3
3
3
1
1
1
1
4
,
2
3
2
2
5
5
5
5
−




=
−
=
=
+
=




−
−




P
A
I
P
A
I
 
 
4
4
4
1
2
4
4
2
3
3
3
1
5
2
2
3
2
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
−
−
−
−
−


+
−
+
=
+
=


−
+
+


A
P
P
 
 
 
 
 
3. 
1
2
3
4 ;
1,
6
3
2
λ
λ


=
= −
=




A
 
 
(
)
(
)
1
2
3
4
4
4
1
1
1
1
6
,
3
4
3
3
7
7
7
7
−




=
−
=
=
+
=




−
−




P
A
I
P
A
I
 
 
6
6
6
1
2
6
6
3
4
4
4
1
7
3
3
4
3
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
−
−
−
−
−


+
−
+
=
+
=


−
+
+


A
P
P
 
 
 
4. 
1
2
4
1 ;
2,
5
6
1
λ
λ


=
= −
=


−


A
 
 
(
)
(
)
1
2
1
1
6
1
1
1
1
1
5
,
2
6
6
6
1
7
7
7
7
−




=
−
=
=
+
=




−
−




P
A
I
P
A
I
 
 
2
5
2
5
2
5
1
2
2
5
2
5
6
1
7
6
6
6
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
−
−
−
−
−


+
−
+
=
+
=


−
+
+


A
P
P
 

 
Section 8.3 
435 
5. 
1
2
6
7 ;
1,
5
1
2
λ
λ
−


=
= −
=


−


A
 
 
(
)
(
)
1
2
1
7
7
7
1
1
1
1
5
,
1
7
1
1
6
6
6
6
−
−




=
−
=
=
+
=




−
−
−




P
A
I
P
A
I
 
 
5
5
5
1
2
5
5
7
7
7
1
6
7
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
−
−
−
−
−


−
+
−
=
+
=


−
+
−


A
P
P
 
 
 
6. 
1
2
9
5
;
3,
4
6
2
λ
λ


=
=
=


−
−


A
 
 
(
)
(
)
1
2
5
5
6
5
1
1
4
,
3
6
6
6
5
1
1
−
−




=
−
=
=
−
=




−
−
−




P
A
I
P
A
I
 
 
3
4
3
4
3
4
1
2
3
4
3
4
5
6
5
5
6
6
6
5
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e


−
+
−
+
=
+
= 

−
−


A
P
P
 
 
 
7. 
1
2
3
4 ;
9,
1
6
5
λ
λ
−


=
= −
=


−


A
 
 
(
)
(
)
1
2
2
2
3
2
1
1
1
1
,
9
3
3
3
2
10
5
10
10
−




=
−
=
=
+
=




−
−




P
A
I
P
A
I
 
 
9
9
9
1
2
9
9
2
3
2
2
1
5
3
3
3
2
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
−
−
−
−
−


+
−
+
=
+
=


−
+
+


A
P
P
 
 
 
8. 
1
2
1
5 ;
2 ,
2
1
1
i
i
λ
λ
−


=
= −
=


−


A
 
 
(
)
(
)
1
2
2
5
2
5
1
1
1
1
2
,
2
2
2
4
4
4
4
i
i
i
i
i
i
i
i
i
i
i
i
+
−
−




=
−
=
=
+
=




−
−
+
−




P
A
I
P
A
I
 
 
2
2
1
2
1
2
(cos2
sin 2 )
(cos2
sin 2 )
2cos2
sin 2
5sin 2
1
sin 2
2cos2
sin 2
2
t
it
it
e
e
e
t
i
t
t
i
t
t
t
t
t
t
t
−
=
+
=
−
+
+
+
−


=


−


A
P
P
P
P
 
 
 
9. 
1
2
2
5 ;
4 ,
4
4
2
i
i
λ
λ
−


=
= −
=




A
 
 
(
)
(
)
1
2
4
2
5
4
2
5
1
1
1
1
4
,
4
4
4
2
4
4
2
8
8
8
8
i
i
i
i
i
i
i
i
i
i
i
i
+
−
−




=
−
=
=
+
=




−
−
+
−




P
A
I
P
A
I
 

436 
Chapter 8 
 
4
4
1
2
1
2
(cos4
sin 4 )
(cos4
sin 4 )
4cos4
2sin 4
5sin 4
1
4sin 4
4cos4
2sin 4
4
t
it
it
e
e
e
t
i
t
t
i
t
t
t
t
t
t
t
−
=
+
=
−
+
+
+
−


=


−


A
P
P
P
P
 
 
 
10. 
1
2
3
2 ;
3 ,
3
9
3
i
i
λ
λ
−
−


=
= −
=




A
 
 
(
)
(
)
1
2
3
3
2
3
3
2
1
1
1
1
3
,
3
9
3
3
9
3
3
6
6
6
6
i
i
i
i
i
i
i
i
i
i
i
i
−
−
+




=
−
=
=
+
=




+
−
−
−




P
A
I
P
A
I
 
 
3
3
1
2
1
2
(cos3
sin3 )
(cos3
sin3 )
3cos3
3sin3
2sin3
1
9sin3
3cos3
3sin3
3
t
it
it
e
e
e
t
i
t
t
i
t
t
t
t
t
t
t
−
=
+
=
−
+
+
−
−


=


+


A
P
P
P
P
 
 
 
11. 
1
2
1
2 ;
1 2 ,
1
2
2
1
i
i
λ
λ
−


=
=
−
=
+




A
 
 
(
)
(
)
1
2
1
1
1
1
1
1
(1
2 )
,
(1 2 )
1
1
4
2
4
2
i
i
i
i
i
i
i
i
−




=
−
+
=
=
−
−
=




−
−




P
A
I
P
A
I
 
 
(1 2 )
(1 2 )
1
2
1
2
(cos2
sin 2 )
(cos2
sin 2 )
cos2
sin 2
sin 2
cos2
t
i t
i t
t
t
t
e
e
e
e
t
i
t
e
t
i
t
t
t
e
t
t
−
+
=
+
=
−
+
+
−


=




A
P
P
P
P
 
 
 
12. 
1
2
1
5 ;
2
2 ,
2
2
1
3
i
i
λ
λ
−


=
=
−
=
+




A
 
 
(
)
(
)
1
2
2
5
1
1
(2
2 )
2
4
4
2
5
1
1
(2
2 )
2
4
4
i
i
i
i
i
i
i
i
i
i
i
i
−
−


=
−
+
=


+
−


+


=
−
−
=


−
−


P
A
I
P
A
I
 
 
(2 2 )
(2 2 )
2
2
1
2
1
2
2
(cos2
sin 2 )
(cos2
sin 2 )
2cos2
sin 2
5sin 2
sin 2
2cos2
sin 2
2
t
i t
i t
t
t
t
e
e
e
e
t
i
t
e
t
i
t
t
t
t
e
t
t
t
−
+
=
+
=
−
+
+
−
−


=


+


A
P
P
P
P
 
 
13. 
1
2
5
9 ;
2
3 ,
2
3
2
1
i
i
λ
λ
−


=
=
−
=
+


−


A
 

 
Section 8.3 
437 
 
(
)
(
)
1
2
3
3
9
1
1
(2
3 )
2
3
3
6
6
3
3
9
1
1
(2
3 )
2
3
3
6
6
i
i
i
i
i
i
i
i
i
i
i
i
+
−


=
−
+
=


−
−


−


=
−
−
=


−
+


P
A
I
P
A
I
 
 
(2 3 )
(2 3 )
2
2
1
2
1
2
2
(cos3
sin3 )
(cos3
sin3 )
3cos3
sin3
9sin3
2sin3
3cos3
sin3
3
t
i t
i t
t
t
t
e
e
e
e
t
i
t
e
t
i
t
t
t
t
e
t
t
t
−
+
=
+
=
−
+
+
+
−


=


−


A
P
P
P
P
 
 
14. 
1
2
3
4 ;
3
4 ,
3
4
4
3
i
i
λ
λ
−


=
=
−
=
+




A
 
 
(
)
(
)
1
2
1
1
1
1
1
1
(3
4 )
,
(3
4 )
1
1
8
2
8
2
i
i
i
i
i
i
i
i
−




=
−
+
=
=
−
−
=




−
−




P
A
I
P
A
I
 
 
(3 4 )
(3 4 )
3
3
1
2
1
2
3
(cos4
sin 4 )
(cos4
sin 4 )
cos4
sin 4
sin 4
cos4
t
i t
i t
t
t
t
e
e
e
e
t
i
t
e
t
i
t
t
t
e
t
t
−
+
=
+
=
−
+
+
−


=




A
P
P
P
P
 
 
15. 
1
2
7
5 ;
5
4 ,
5
4
4
3
i
i
λ
λ
−


=
=
−
=
+




A
 
 
(
)
(
)
1
2
4
2
5
1
1
(5
4 )
4
4
2
8
8
4
2
5
1
1
(5
4 )
4
4
2
8
8
i
i
i
i
i
i
i
i
i
i
i
i
+
−


=
−
+
=


−
−


−


=
−
−
=


−
+


P
A
I
P
A
I
 
 
(5 4 )
(5 4 )
5
5
1
2
1
2
(cos4
sin 4 )
(cos4
sin 4 )
t
i t
i t
t
t
e
e
e
e
t
i
t
e
t
i
t
−
+
=
+
=
−
+
+
A
P
P
P
P  
 
5
4cos4
2sin 2
5sin 4
4sin 4
4cos4
2sin 2
4
t
t
t
t
e
t
t
t
+
−


=


−


 
 
16. 
1
2
50
20
;
100,
10
100
60
λ
λ
−


=
= −
= −


−


A
 
 
(
)
(
)
1
2
4
2
5
2
1
1
1
1
10
,
100
10
5
10
4
90
9
90
9
−




=
+
=
=
+
=




−
−




P
A
I
P
A
I
 
 
100
10
100
10
100
10
1
2
100
10
100
10
4
5
2
2
1
9
10
10
5
4
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
−
−
−
−
−
−
−
−
−
−


+
−
+
=
+
=


−
+
+


A
P
P
 
 

438 
Chapter 8 
In Problems 17, 18, and 20 the coefficient matrix  A  is 3 3
×  with distinct eigenvalues  
1
2
3
,
,
.
λ λ
λ   
Looking at Equations (7) and (3) in Section 8.3, we see that  
 
 
 
 
 
3
1
2
1
2
3
t
t
t
t
e
e
e
eλ
λ
λ
=
+
+
A
P
P
P   
 
 
 
(3) 
 
where the projection matrices are defined by 
 
 
2
3
1
3
1
2
1
2
3
1
2
1
3
2
1
2
3
3
1
3
2
(
)(
)
(
)(
)
(
)(
)
,
,
.
(
)(
)
(
)(
)
(
)(
)
λ
λ
λ
λ
λ
λ
λ
λ
λ
λ
λ
λ
λ
λ
λ
λ
λ
λ
−
−
−
−
−
−
=
=
=
−
−
−
−
−
−
A
I A
I
A
I A
I
A
I A
I
P
P
P
 (4) 
 
17. 
1
2
3
4
1
4
1
7
1 ;
0,
6,
9
4
1
4
λ
λ
λ




=
=
=
=






A
 
 
(
)(
)
(
)(
)
(
)(
)
1
2
3
1
0
1
1
1
6
9
0
0
0
54
2
1
0
1
1
2
1
1
1
0
9
2
4
2
18
6
1
2
1
1 1 1
1
1
0
6
1 1 1
27
3 1 1 1
−




=
−
−
=




−


−




=
−
−
=
−
−


−


−






=
−
−
=






P
A
I
A
I
P
A
I
A
I
P
A
I
A
I
 
 
6
9
6
9
6
9
6
9
6
9
6
9
6
9
1
2
3
6
9
6
9
6
9
3
2
2
2
3
2
1
2
2
4
2
2
2
6
3
2
2
2
3
2
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e


+
+
−
+
−+
+


=
+
+
=
−
+
+
−
+




−+
+
−
+
+
+


A
P
P
P
 
 
18. 
1
2
3
1
2
2
2
7
1 ;
0,
6,
9
2
1
7
λ
λ
λ




=
=
=
=






A
 
 
(
)(
)
1
16
4
4
1
1
6
9
4
1
1
54
18
4
1
1
−
−




=
−
−
=
−


−




P
A
I
A
I
 
 
(
)(
)
2
0
0
0
1
1
0
9
0
1
1
18
2 0
1
1




=
−
−
=
−


−
−




P
A
I
A
I
 

 
Section 8.3 
439 
 
(
)(
)
3
1
2
2
1
1
0
6
2
4
4
27
9 2
4
4




=
−
−
=






P
A
I
A
I
 
 
9
9
9
6
9
6
9
6
9
6
9
1
2
3
6
9
6
9
6
9
16
2
4
4
4
4
1
4
4
1 9
8
1 9
8
18
4
4
1 9
8
1 9
8
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e


+
−+
−+


=
+
+
=
−
+
+
+
−
+




−
+
−
+
+
+


A
P
P
P
 
 
 
19. 
1
2
3
4
1
1
1
4
1 ;
6,
3,
3
1
1
4
λ
λ
λ




=
=
=
=






A
 
Here we have the eigenvalue  
1
6
λ =
 of multiplicity 1 and the eigenvalue  
2
3
λ
=
 of 
multiplicity 2.  By Example 2 in Section 8.3, the desired matrix exponential is given by 
 
 
 
 
[
]
1
2
1
2
2
(
)
t
t
t
e
e
e
t
λ
λ
λ
=
+
+
−
A
P
P I
A
I
  
 
(5) 
 
where  P1  and  P2  are the projection matrices of  A  corresponding to the eigenvalues  
1
2
and
.
λ
λ   The reciprocal of the characteristic polynomial  
2
( )
(
6)(
3)
p λ
λ
λ
=
−
−
 has 
the partial fractions decomposition 
 
 
 
 
2
1
1
,
( )
9(
6)
9(
3)
p
λ
λ
λ
λ
=
−
−
−
 
 
so  
1
2
( )
1/9 and
( )
/9
a
a
λ
λ
λ
=
= −
 in the notation of Equation (25) in the text.  Therefore 
Equation (26) there gives 
 
 
(
)
2
2
1
1
2
1 1 1
1
1
( ) (
)
3
1 1 1 ,
9
3 1 1 1
a
λ




=
⋅
−
=
−
=






P
A
A
I
A
I
 
 
(
)
2
2
1
2
1
1
1
1
( ) (
)
6
1
2
1 .
9
3
1
1
2
a
λ
−
−




=
⋅
−
= −
−
=
−
−




−
−


P
A
A
I
A A
I
 
Finally, Equation (5) above gives 
 
 
(
)
3
6
3
6
3
6
6
3
3
6
3
6
3
6
1
2
3
6
3
6
3
6
3
1
(
3 )
2
.
3
2
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
t
e
e
e
e
e
e
e
e
e
e
e
e


+
−
+
−
+


=
+
+
−
=
−
+
+
−
+




−
+
−
+
+


A
P
P
I
A
I
 

440 
Chapter 8 
20. 
1
2
3
5
1
3
1
7
1 ;
2,
6,
9
3
1
5
λ
λ
λ




=
=
=
=






A
 
 
(
)(
)
1
1
0
1
1
1
6
9
0
0
0
28
2
1
0
1
−




=
−
−
=


−




P
A
I
A
I
 
 
(
)(
)
2
1
2
1
1
1
2
9
2
4
2
12
6
1
2
1
−




=
−
−
=
−
−


−
−




P
A
I
A
I
 
 
(
)(
)
3
1 1 1
1
1
2
6
1 1 1
21
3 1 1 1




=
−
−
=






P
A
I
A
I
 
 
2
6
9
6
9
2
6
9
2
6
9
6
9
6
9
6
9
1
2
3
2
6
9
6
9
2
6
9
3
2
2
2
3
2
1
2
2
4
2
2
2
6
3
2
2
2
3
2
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e
e


+
+
−
+
−
+
+


=
+
+
=
−
+
+
−
+




−
+
+
−
+
+
+


A
P
P
P
 
 
 
In Problems 21–30 here we want to use projection matrices to find fundamental matrix solutions 
of the linear systems given in Problems 1–10 of Section 7.5.  In each of Problems 21–26, the 
2 2
× coefficient matrix  A  has characteristic polynomial of the form  
2
1
( )
(
)
p λ
λ
λ
=
−
 and thus a 
single eigenvalue  
1λ  of multiplicity 2.  Consequently, Example 5 in Section 8.3 gives the 
desired fundamental matrix 
 
 
 
 
 
[
]
1
1
(
)
.
t
t
e
e
t
λ
λ
=
+
−
A
I
A
I
 
 
 
 
(6) 
 
21. 
1
2
1
;
3
1
4
λ
−


=
= −


−
−


A
 
 
[
]
3
3 1
(
3 )
1
t
t
t
t
t
e
e
t
e
t
t
−
−
+


=
+
+
=


−
−


A
I
A
I
 
 
22. 
1
3
1 ;
2
1
1
λ
−


=
=




A
 
 
[
]
2
2
1
(
2 )
1
t
t
t
t
t
e
e
t
e
t
t
+
−


=
+
−
=


−


A
I
A
I
 
 

 
Section 8.3 
441 
23. 
1
1
2 ;
3
2
5
λ
−


=
=




A
 
 
[
]
3
3 1 2
2
(
3 )
2
1
2
t
t
t
t
t
e
e
t
e
t
t
−
−


=
+
−
=


+


A
I
A
I
 
 
24. 
1
3
1 ;
4
1
5
λ
−


=
=




A
 
 
[
]
4
4
1
(
4 )
1
t
t
t
t
t
e
e
t
e
t
t
−
−


=
+
−
=


+


A
I
A
I
 
 
25. 
1
7
1 ;
5
4
3
λ


=
=


−


A
 
 
[
]
5
5
1 4
4
(
5 )
4
1
4
t
t
t
t
t
e
e
t
e
t
t
−
−


=
+
−
=


+


A
I
A
I
 
 
26. 
1
1
4 ;
5
4
9
λ
−


=
=




A
 
 
[
]
5
5
1
2
(
5 )
4
1 2
t
t
t
t
t
e
e
t
e
t
t
+


=
+
−
=


−
−


A
I
A
I
 
 
 
Each of the 3 3
×  coefficient matrices in Problems 27–30 has a characteristic polynomial of the 
form  
2
1
2
( )
(
)((
)
p λ
λ
λ
λ
λ
=
−
−
 yielding an eigenvalue  
1λ  of multiplicity 1 and an eigenvalue  
2
λ  of multiplicity 2.  We therefore use the method explained in Problem 19 above, and list here 
the results of the principal steps in the calculation of the fundamental matrix  
.
t
eA  
 
27. 
2
1
2
2
0
0
7
9
7 ;
( )
(
9)(
2) ;
9,
2
0
0
2
p λ
λ
λ
λ
λ




=
−
=
−
−
=
=






A
  
 
1
2
2
1
1
5
1
5
;
( )
,
( )
( )
49(
9)
49(
3)
49
49
a
a
p
λ
λ
λ
λ
λ
λ
λ
+
+
=
−
=
= −
−
−
  

442 
Chapter 8 
(
)
2
2
1
1
2
0
0
0
1
( ) (
)
2
1
1
1
49
0
0
0
a
λ




=
⋅
−
=
−
=
−






P
A
A
I
A
I
 
(
)(
)
2
2
1
1
0
0
1
( ) (
)
5
9
1
0
1
49
0
0
1
a
λ




=
⋅
−
= −
+
−
=
−






P
A
A
I
A
I
A
I
 
 
(
)
2
9
2
2
9
9
2
9
1
2
2
0
0
(
2 )
0
0
t
t
t
t
t
t
t
t
t
t
e
e
e
e
t
e
e
e
e
e
e




=
+
+
−
=
−
−
+






A
P
P
I
A
I
 
 
28. 
2
1
2
25
12
0
18
5
0 ;
( )
(
7)(
13) ;
7,
13
6
6
13
p λ
λ
λ
λ
λ




=
−
−
=
−
−
=
=






A
  
1
2
2
1
1
19
1
19
;
( )
,
( )
( )
36(
9)
49(
3)
36
36
a
a
p
λ
λ
λ
λ
λ
λ
λ
−
−
=
+
=
=
−
−
  
(
)
2
2
1
1
2
2
2
0
1
( ) (
)
13
3
3
0
36
1
1
0
a
λ
−
−




=
⋅
−
=
−
= 



−
−


P
A
A
I
A
I
 
(
)(
)
2
2
1
3
2
0
1
( ) (
)
19
7
3
2
0
36
1
1
1
a
λ




=
⋅
−
=
−
−
=
−
−






P
A
A
I
I
A
A
I
 
 
(
)
7
13
7
13
7
13
7
13
7
13
1
2
7
13
7
13
13
2
3
2
2
0
(
13 )
3
3
3
2
0
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
t
e
e
e
e
e
e
e
e
e


−
+
−
+


=
+
+
−
=
−
−




−
+
−
+


A
P
P
I
A
I
 
 
29. 
2
1
2
19
12
84
0
5
0 ;
( )
(
9)(
5) ;
9,
5
8
4
33
p λ
λ
λ
λ
λ
−




=
=
−
−
=
=




−


A
  
 
1
2
2
1
1
1
1
1
;
( )
,
( )
( )
16(
9)
16(
5)
16
16
a
a
p
λ
λ
λ
λ
λ
λ
λ
−
−
=
+
=
=
−
−
  

 
Section 8.3 
443 
(
)
2
2
1
1
2
6
3
21
1
( ) (
)
5
0
0
0
16
2
1
7
a
λ
−




=
⋅
−
=
−
= 



−


P
A
A
I
A
I
 
(
)(
)
2
2
1
7
3
21
1
( ) (
)
9
0
1
0
16
2
1
6
a
λ
−
−




=
⋅
−
=
−
−
= 



−
−


P
A
A
I
I
A
A
I
 
 
(
)
5
9
5
9
5
9
9
5
5
1
2
5
9
5
9
5
9
7
6
3
3
21
21
(
5 )
0
0
2
2
6
7
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
t
e
e
e
e
e
e
e


−
−
+
−
+


=
+
+
−
= 



−
−
+
−
+


A
P
P
I
A
I
 
 
30. 
2
1
2
13
40
48
8
23
24 ;
( )
(
7)(
3) ;
7,
3
0
0
3
p λ
λ
λ
λ
λ
−
−




=
−
−
=
−
−
=
=






A
  
1
2
2
1
1
1
1
1
;
( )
,
( )
( )
16(
7)
16(
3)
16
16
a
a
p
λ
λ
λ
λ
λ
λ
λ
+
+
=
−
=
= −
−
−
  
(
)
2
2
1
1
2
4
10
12
1
( ) (
)
3
2
5
6
16
0
0
0
a
λ
−
−




=
⋅
−
=
−
=
−
−






P
A
A
I
A
I
 
(
)(
)
2
2
1
5
10
12
1
( ) (
)
7
2
4
6
16
0
0
1
a
λ
−




=
⋅
−
= −
+
−
=
−






P
A
A
I
I
A
A
I
 
 
(
)
3
7
3
7
3
7
7
3
3
7
3
7
3
7
1
2
3
5
4
10
10
12
12
(
3 )
2
2
4
5
6
6
0
0
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
t
e
e
e
e
e
e
e


−
−
+
−


=
+
+
−
=
−
−
+
−






A
P
P
I
A
I
 
 
 
In Problems 31–40 we use the methods of this section to find the matrix exponentials that were 
given in in the statements of Problems 21–30 of Section 8.2.  Once  
t
eA  is known, the desired 
particular solution  ( )t
x
 is provided by the variation of parameters formula 
 
 
 
 
(
)
0
( )
(0)
( )
t
t
s
t
e
e
s ds
−
=
+∫
A
A
x
x
f
 
 
 
 
(7) 
 

444 
Chapter 8 
of Section 8.2.  We give first the calculation of the matrix exponential using projection matrices 
and then the final result, which we obtained in each case using a computer algebra system to 
evaluate the right-hand side in Equation (7) — as described in the remarks preceding Problems 
21–30 of Section 8.2.  We illustrate this highly formal process by giving intermediate results in 
Problems 31, 34, and 39.   
 
31. 
1
2
4
1 ,
1,
3
5
2
λ
λ
−


=
= −
=




A
 
 
(
)
(
)
1
2
1
1
5
1
1
1
1
1
3
,
5
5
5
1
4
4
4
4
−
−




=
−
=
=
+
=




−
−
−




P
A
I
P
A
I
 
 
3
3
3
1
2
3
3
5
1
4
5
5
5
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
e
e
−
−
−
−
−


−
+
−
=
+
=


−
+
−


A
P
P
 
 
2
2
0
18
(0)
,
( )
0
30
t
t
e
t
e



=
= 





x
f
 
 
3
3
2
3
3
3
2
3
5
18
15
3
1
( )
4
5
5
5
30
15
15
s
s
s
s
s
s
s
s
s
s
s
s
s
s
s
e
e
e
e
e
e
e
e
s
e
e
e
e
e
e
e
−
−
−
−
−
−
−





−
+
−
+
=
=





−
+
−
+





A f
 
 
3
3
3
3
0
0
0
15
3
14 15
(0)
( )
0
15
15
10 15
5
t
s
s
t
t
t
s
s
s
t
t
e
e
e
e
e
s ds
ds
e
e
e
e
−
−
−
−
−




+
−
+

+
=
+
=





+
−
+





⌠
⌡
∫
A
x
f
 
 
(
)
3
3
3
3
3
3
0
5
14 15
1
( )
(0)
( )
4
5
5
5
10 15
5
t
t
t
t
t
t
t
t
s
t
t
t
t
t
t
e
e
e
e
e
e
t
e
e
s ds
e
e
e
e
e
e
−
−
−
−
−
−
−



−
+
−
−
+
=
+
=



−
+
−
−
+



∫
A
A
x
x
f
 
 
2
3
2
3
14
15
( )
5
10
15
t
t
t
t
t
t
e
e
e
t
e
e
e
−
−


−
−
+
= 

−
−
+


x
 
 
32. 
With the same matrix exponential as in Problem 31, but with  
3
28
( )
.
20
t
t
e
t
e
−


= 



f
 
 
3
3
( 10
7 )
(10
5 )
( )
( 15
35 )
(15
5 )
t
t
t
t
t e
t e
t
t e
t e
−
−


−
−
+
−
= 

−
−
+
−


x
 
 
33. 
1
2
3
1 ,
0,
0
9
3
λ
λ
−


=
=
=


−


A
 
 
[
]
0
1 3
(
0 )
9
1 3
t
t
t
t
e
e
t
t
t
t
−
+
−


=
+
+
=
+
= 

−


A
I
A
I
I
A
 
(as in Problems 21-26) 

 
Section 8.3 
445 
 
3
7
(0)
,
( )
5
5
t


=
=




x
f
 
 
2
2
3 11
8
( )
5 17
24
t
t
t
t
t


+
+
= 

+
+


x
 
 
34. 
With  
t
eA   as in Problem 33, but with  
2
3
0
(1)
and
( )
.
7
1/
t
t



=
=






x
f
  Because   
0
1,
t =
 we use the general variation of parameters formula in Eq. (25) of Section 8.2. 
 
2
2
1 3
0
1/
( )
9
1 3
1/
3/
1/
s
s
s
s
e
s
s
s
s
s
s
−
−





=
=





−
+
+





A f
 
 
2
1
1
2
1
3
1/
1
ln
(1)
( )
9
4
7
3/
1/
2
3ln
1/
t
t
s
s
t
e
e
s ds
ds
s
s
t
t
−
−
−
+






+
=
+
=






−
+
+
−






⌠
⌡
∫
A
A
x
f
 
(
)
1
1 3
1 ln
( )
(1)
( )
9
1 3
2
3ln
1/
t
t
s
t
t
t
t
e
e
e
s ds
t
t
t
t
−
−
+
−
+



=
+
= 


−
+
−



∫
A
A
A
x
x
f
 
 
2
ln
( )
1
5
3
3ln
t
t
t
t
t
t
+ +




= 

+
−
+




x
 
 
35. 
1
2
2
5 ,
,
1
2
i
i
λ
λ
−


=
= −
=


−


A
 
 
(
)
(
)
1
2
1
2
5
1 2
5
1
1
1
1
,
1 2
1
2
2
2
2
2
i
i
i
i
i
i
i
i
i
i
i
i
+
−
−




=
−
=
=
+
=




−
−
+
−




P
A
I
P
A
I
 
 
1
2
1
2
(cos
sin )
(cos
sin )
t
it
it
e
e
e
t
i
t
t
i
t
−
=
+
=
−
+
+
A
P
P
P
P  
 
cos
2sin
5sin
sin
cos
2sin
t
t
t
t
t
t
+
−


= 

−


 ;          
0
4
(0)
,
( )
0
1
t
t



=
=






x
f
. 
 
The solution vector  
1 8
cos
8sin
( )
2
4
2cos
3sin
t
t
t
t
t
t
t
−+
+
−


= 

−+
+
−


x
  is derived by variation of 
parameters in the solution to Problem 25 of Section 8.2. 
 
36. 
With  
t
eA   as in Problem 35, but with  
3
4cos
(0)
and
( )
.
5
6sin
t
t
t



=
=






x
f
   

446 
Chapter 8 
 
3cos
32sin
17 cos
4 sin
( )
5cos
13sin
6 cos
5 sin
t
t
t
t
t
t
t
t
t
t
t
t
t
−
+
+


= 

−
+
+


x
 
 
37. 
1
2
3
1 ,
0,
0
9
3
λ
λ
−


=
=
=


−


A
 
 
[
]
0
1
2
4
(
0 )
1 2
t
t
t
t
e
e
t
t
t
t
−
+
−


=
+
+
=
+
= 

−


A
I
A
I
I
A
 
(as in Problems 21–26) 
 
2
0
36
(0)
,
( )
0
6
t
t
t



=
= 





x
f
 
 
3
4
2
3
4
8
6
( )
3
2
3
t
t
t
t
t
t


+
= 

−
+


x
 
 
38. 
With  
t
eA   as in Problem 37, but with  
1
4 ln
(1)
and
( )
.
1
1/
t
t
t




=
=




−




x
f
  The details of  
 
the variation of parameters process are similar to those shown in Problem 34 above. 
 
 
2
2
2
2
7 14
6
4
ln
( )
7
9
3
ln
2 ln
2
ln
t
t
t
t
t
t
t
t
t
t
t
t


−+
−
+
= 

−+
−
+
−
+


x
 
 
39. 
1
2
0
1 ,
,
1
0
i
i
λ
λ
−


=
= −
=




A
 
 
(
)
(
)
1
2
1
1
1
1
1
1
,
1
1
2
2
2
2
i
i
i
i
i
i
i
i
−




=
−
=
=
+
=




−
−




P
A
I
P
A
I
 
 
1
2
1
2
cos
sin
(cos
sin )
(cos
sin )
sin
cos
t
it
it
e
e
e
t
t
t
i
t
t
i
t
t
t
−
=
+
−


=
−
+
+
= 



A
P
P
P
P
 
0
sec
(0)
,
( )
0
0
t
t



=
=






x
f
 
 
cos
sin
sec
1
( )
sin
cos
0
tan
s
s
s
s
e
s
s
s
s
−





=
=





−
−





A f
 
 
0
0
0
1
(0)
( )
0
tan
ln(cos )
t
t
s
t
e
s ds
ds
s
t
−





+
=
+
=





−





⌠
⌡
∫
A
x
f
 

 
Section 8.3 
447 
 
(
)
0
cos
sin
( )
(0)
( )
sin
cos
ln(cos )
t
t
s
t
t
t
t
e
e
s ds
t
t
t
−
−



=
+
= 





∫
A
A
x
x
f
 
 
cos
ln(cos )sin
( )
sin
ln(cos )cos
t
t
t
t
t
t
t
t
t
−


= 

+


x
 
 
40. 
1
2
0
2 ,
2 ,
2
2
0
i
i
λ
λ
−


=
= −
=




A
 
 
(
)
(
)
1
2
1
1
1
1
1
1
2
,
2
1
1
4
2
4
2
i
i
i
i
i
i
i
i
−




=
−
=
=
+
=




−
−




P
A
I
P
A
I
 
 
2
2
1
2
1
2
cos2
sin 2
(cos2
sin 2 )
(cos2
sin 2 )
sin 2
cos2
t
it
it
e
e
e
t
t
t
i
t
t
i
t
t
t
−
=
+
−


=
−
+
+
= 



A
P
P
P
P
 
0
cos2
(0)
,
( )
0
sin 2
t
t
t
t
t



=
=






x
f
 
 
2
1
2
2
1
2
cos2
( )
sin 2
t
t
t
t
t


= 



x
 
 
Each of the 3 3
×  coefficient matrices in Problems 41 and 42 has a characteristic polynomial of 
the form  
2
1
2
( )
(
)((
)
p λ
λ
λ
λ
λ
=
−
−
 yielding an eigenvalue  
1λ  of multiplicity 1 and an 
eigenvalue  
2
λ  of multiplicity 2.  We therefore use the method explained in Problem 19 above, 
and list here the results of the principal steps in the calculation of the fundamental matrix  
.
t
eA  
 
41. 
2
1
3
39
8
16
36
5
16
;
( )
(
1)(
3) ,
1,
3
72
16
29
p λ
λ
λ
λ
λ
−




=
−
−
=
+
−
= −
=




−


A
  
1
2
2
1
1
7
1
7
;
( )
,
( )
( )
16(
1)
16(
3)
16
16
a
a
p
λ
λ
λ
λ
λ
λ
λ
−
−
=
+
=
=
+
−
  
(
)
2
2
1
1
2
9
2
4
1
( ) (
)
3
9
2
4
16
18
4
8
a
λ
−
−




=
⋅
−
=
−
=
−




−
−


P
A
A
I
A
I
 

448 
Chapter 8 
(
)(
)
2
2
1
10
2
4
1
( ) (
)
7
9
1
4
16
18
4
7
a
λ
−




=
⋅
−
=
−
+
=
−
−




−


P
A
A
I
I
A
A
I
 
 
(
)
3
3
3
3
3
3
3
1
2
3
3
3
9
10
2
2
4
4
(
3 )
9
9
2
4
4
18
18
4
4
8
7
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
t
e
e
e
e
e
e
e
e
e
e
e
e
−
−
−
−
−
−
−
−
−
−


−
+
−
+
−


=
+
+
−
=
−
−
−
+




−
+
−
+
−


A
P
P
I
A
I
 
 
42. 
2
1
3
28
50
100
15
33
60
;
( )
(
2)(
3) ,
2,
3
15
30
57
p λ
λ
λ
λ
λ




=
=
+
−
= −
=




−
−
−


A
  
1
2
2
1
1
8
1
7
;
( )
,
( )
( )
25(
1)
25(
3)
25
25
a
a
p
λ
λ
λ
λ
λ
λ
λ
−
−
=
+
=
=
+
−
  
(
)
2
2
1
1
2
5
10
20
1
( ) (
)
3
3
6
12
25
3
6
12
a
λ
−
−
−




=
⋅
−
=
−
=
−
−
−






P
A
A
I
A
I
 
(
)(
)
2
2
1
6
10
20
1
( ) (
)
8
2
3
7
12
25
3
6
11
a
λ




=
⋅
−
=
−
+
= 



−
−
−


P
A
A
I
I
A
A
I
 
 
(
)
2
3
2
3
2
3
2
3
2
3
2
3
2
3
1
2
2
3
2
3
2
3
5
6
10
10
20
20
(
3 )
3
3
6
7
12
12
3
3
6
6
12
11
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
e
e
e
e
e
e
e
t
e
e
e
e
e
e
e
e
e
e
e
e
−
−
−
−
−
−
−
−
−
−


−
+
−
+
−
+


=
+
+
−
=
−
+
−
+
−
+




−
−
−


A
P
P
I
A
I
 
 
In each of Problems 43 and 44, the given 3 3
× coefficient matrix  A  has characteristic 
polynomial of the form  
3
1
( )
(
)
p λ
λ
λ
=
−
 and thus a single eigenvalue  
1λ  of multiplicity 3.  
Consequently, Equations (25) and (26) in Section 8.3 of the text imply that  
1
1
( )
( )
1
a
b
λ
λ
=
=  and 
hence that the associated projection matrix  
1
.
=
P
I   Therefore Equation (35) in the text reduces 
(with  q = 1  and  m1 = 3) to 
 
 
 
 
1
2
2
1
1
1
2
(
)
(
)
.
t
t
e
e
t
t
λ
λ
λ


=
+
−
+
−


A
I
A
I
A
I
  
 
(8) 
 
43. 
2
1
2
17
4
1
6
1 ;
( )
(
2) ,
2
0
1
2
p λ
λ
λ
−




=
−
=
−
=






A
 

 
Section 8.3 
449 
 
Substitution of  A  and  
1
2
λ =
 into the formula in (8) above yields 
 
 
 
2
2
2
2
2
2
2
8
2
4
34
8
1
2
8
2
2
.
2
4
2
2
t
t
t
t
t
t
t
t
e
e
t
t
t
t
t
t
t


−
−
+
+
+


=
−
+




−
+
+


A
 
 
44. 
2
1
5
1
1
1
3
0 ;
( )
(
3) ,
3
3
2
1
p λ
λ
λ
−




=
=
−
=




−


A
 
 
Substitution of  A  and  
1
3
λ =
 into the formula in (8) above yields 
 
 
 
3
2
2
2
2
2
2
4
2
2
2
1
2
2
2
.
2
2
6
4
4
2
t
t
t
t
t
e
e
t
t
t
t
t
t
t
t
t
t
+
−




=
+
−
+




−
−
+
−
+


A
 
 
45. 
2
2
1
2
1
1
1
2
7
4
6
11 ;
( )
(
1) (
2) ,
1,
2
5
1
1
3
6
2
2
6
p λ
λ
λ
λ
λ
−
−




−
−


=
=
+
−
= −
=


−


−
−


A
 
Since  A  has two eigenvalues  
1
2
1 and
2
λ
λ
= −
=
 each of multiplicity 2, Equation (35) 
in the text reduces (with  q = m1 = m2 = 2) to 
 
 
 
 
[
]
[
]
1
2
1
1
2
2
(
)
(
)
.
t
t
t
e
e
t
e
t
λ
λ
λ
λ
=
+
−
+
+
−
A
P I
A
I
P I
A
I
  
(9) 
 
 
To calculate the projection matrices  P1  and  P2, we start with the partial fraction 
decomposition  
 
 
 
2
2
1
2
5
7
2
.
( )
27(
1)
27(
2)
p
λ
λ
λ
λ
λ
+
−
=
+
+
−
 
 
Then Equation (25) in the text implies that  
1( )
(2
5) / 27 and
a λ
λ
=
+
 
2( )
(7
2 )/ 27.
a λ
λ
=
−
  Hence Equation (26) yields 
 
2
1
1
0
0
0
3
1
1
2
1 (2
5 )(
)
1
0
0
0
27
2
0
0
0




−
−


=
+
+
= 

−


−


P
A
I A
I
 
 
and 

450 
Chapter 8 
2
2
0
0
0
0
3
0
1
2
1 (7
2 )(
2 )
.
1
0
1
0
27
2
0
0
1




−


=
−
−
= 





P
I
A A
I
 
 
When we substitute these eigenvalues and projection matrices in Eq. (9) above we get 
 
 
 
2
2
2
2
2
2
2
2
2
3
(3
2 )
(1 3 )
(1 3 )
2(3
1)
(2
)
.
(1
2 )
2
2
2
2
2
4
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
e
t e
t e
t e
e
t e
t e
t e
e
t
e
t e
e
e
t e
t e
t e
e
t e
t e
e
e
t e
t e
t e
e
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−
−


−


−
+
−
−
−
−
−
+
−


= 

−
+
+
−
−
+
+


−
+
−
−
+




A
 
 
46. 
4
1
35
12
4
30
22
8
3
19
;
( )
(
1) ,
1
10
3
0
9
27
9
3
23
p λ
λ
λ
−




−


=
=
−
=


−
−


−
−
−


A
 
Thus the given 4 4
× coefficient matrix  A  has characteristic polynomial of the form  
4
1
( )
(
)
p λ
λ
λ
=
−
 and thus a single eigenvalue  
1
1
λ =  of multiplicity 4.  Consequently, 
Equations (25) and (26) in Section 8.3 of the text imply that  
1
1
( )
( )
1
a
b
λ
λ
=
=  and hence 
that the associated projection matrix  
1
.
=
P
I   Therefore Equation (35) in the text reduces 
(with  q = 1  and  m1 = 4) to 
 
 
 
 
1
2
2
3
3
1
1
1
1
1
2
6
(
)
(
)
(
)
.
t
t
e
e
t
t
t
λ
λ
λ
λ


=
+
−
+
−
+
−


A
I
A
I
A
I
A
I
  
(10) 
 
 
 
When we substitute  A  and  
1
1
λ =   in this formula we get 
 
 
 
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
48
68
2
18
24
6
8
36
60
7
44
3
18
2
6
6
38
1
.
2
21
20
9
6
3
2
2
18
18
42
54
18
18
6
6
36
48
2
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
e
e
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t
t


+
+
−
−
+
+


+
−
−
+
+
+


=


−
−
+
−
−
+
−
−


−
−
+
−
−
−
−
+




A
 
 
In each of problems 47–50 we use the given values of  
1
2
3
,
, and
k k
k set up the second-order 
linear system  ′′ =
x
Ax  with coefficient matrix 
 
 
 
 
 
1
2
2
2
2
3
.
k
k
k
k
k
k
−
−


= 

−
−


A
 
 
We then calculate the particular solution 

 
Section 8.3 
451 
 
 
 
 
 
1
2
( )
t
t
t
e
e−
=
+
A
A
x
c
c  
 
 
 
 
(11) 
 
given by Theorem 3 with  
[
]
[
]
1
2
1
0
and
0
1
.
T
T
=
=
c
c
  Given the distinct eigenvalues  
1
2
,
λ λ  
and the projection matrices  P1, P2  of  A,  the matrix exponential needed in (11) is given by 
 
 
 
 
 
1
2
1
2.
t
t
t
e
e
e
λ
λ
=
+
A
P
P  
 
 
 
 
(12) 
 
47. 
2
1
2
5
4 ;
( )
10
9,
1,
9
4
5
p λ
λ
λ
λ
λ
−


=
=
−
+
= −
= −


−


A
 
 
(
)
(
)
1
2
1 1
1
1
1
1
1
1
9
,
1 1
1
1
10
2
10
2
−




=
+
=
=
+
=




−
−




P
A
I
P
A
I
 
 
1
2
3
3
3
1
2
1
2
3
3
1
2
it
it
it
it
t
t
t
it
it
it
it
it
it
e
e
e
e
e
e
e
e
e
e
e
e
e
λ
λ


+
−
=
+
=
+
=


−
+


A
P
P
P
P
 
 
(
) (
)
(
) (
)
3
3
1
2
3
3
cos
sin3
1
( )
cos
sin3
2
it
it
it
it
t
t
it
it
it
it
e
e
e
e
t
t
t
e
e
i
t
t
e
e
e
e
−
−
−


+
−
−
−






=
+
=
=
+






+
+
−






A
A
x
c
c
 
 
Note that  x(t)  is a linear combination of two motions — one in which the two masses  
move in the same direction with frequency 
1
1
ω =  and with equal amplitudes, and one in 
which they move in opposite directions with frequency 
2
3
ω =
 and with equal 
amplitudes. 
 
 
48. 
2
1
2
3
2 ;
( )
6
5,
1,
5
2
3
p λ
λ
λ
λ
λ
−


=
=
−
+
= −
= −


−


A
 
 
(
)
(
)
1
2
1 1
1
1
1
1
1
1
5
,
1 1
1
1
6
2
6
2
−




=
+
=
=
+
=




−
−




P
A
I
P
A
I
 
 
1
2
5
5
5
1
2
1
2
5
5
1
2
it
it
it
it
t
t
t
it
it
it
it
it
it
e
e
e
e
e
e
e
e
e
e
e
e
e
λ
λ


+
−
=
+
=
+
=




−
+


A
P
P
P
P
 
 
(
) (
)
(
) (
)
5
5
1
2
5
5
cos
sin
5
1
( )
cos
2
sin
5
it
it
it
it
t
t
it
it
it
it
e
e
e
e
t
t
t
e
e
i
t
t
e
e
e
e
−
−
−


+
−
−


−




=
+
=
=
+ 









+
+
−






A
A
x
c
c
 
 
 
Note that  x(t)  is a linear combination of two motions — one in which the two masses  

452 
Chapter 8 
move in the same direction with frequency 
1
1
ω =  and with equal amplitudes, and one in 
which they move in opposite directions with frequency 
2
5
ω =
 and with equal 
amplitudes. 
 
 
49. 
2
1
2
3
1
;
( )
6
8,
2,
4
1
3
p λ
λ
λ
λ
λ
−


=
=
−
+
= −
= −


−


A
 
 
(
)
(
)
1
2
1 1
1
1
1
1
1
1
4
,
2
1 1
1
1
6
2
6
2
−




=
+
=
=
+
=




−
−




P
A
I
P
A
I
 
 
1
2
2
2
2
2
2
2
1
2
1
2
2
2
2
2
1
2
it
it
it
it
t
t
t
it
it
it
it
it
it
e
e
e
e
e
e
e
e
e
e
e
e
e
λ
λ


+
−
=
+
=
+
=




−
+


A
P
P
P
P
 
 
(
) (
)
(
) (
)
2
2
2
2
1
2
2
2
2
2
cos
2
sin 2
1
( )
sin 2
2
cos
2
it
it
it
it
t
t
it
it
it
it
e
e
e
e
t
t
t
e
e
i
t
t
e
e
e
e
−
−
−


+
−
−


−




=
+
=
=
+










+
+
−






A
A
x
c
c
 
 
 
Note that  x(t)  is a linear combination of two motions — one in which the two masses  
move in the same direction with frequency 
1
2
ω =
 and with equal amplitudes, and one 
in which they move in opposite directions with frequency 
2
2
ω =
 and with equal 
amplitudes. 
 
 
 
50. 
2
1
2
10
6
;
( )
20
64,
4,
16
6
10
p λ
λ
λ
λ
λ
−


=
=
−
+
= −
= −


−


A
 
 
(
)
(
)
1
2
1 1
1
1
1
1
1
1
16
,
4
1 1
1
1
20
2
20
2
−




=
+
=
=
+
=




−
−




P
A
I
P
A
I
 
 
1
2
2
4
2
4
2
4
1
2
1
2
2
4
2
4
1
2
it
it
it
it
t
t
t
it
it
it
it
it
it
e
e
e
e
e
e
e
e
e
e
e
e
e
λ
λ


+
−
=
+
=
+
=


−
+


A
P
P
P
P
 
 
(
) (
)
(
) (
)
2
2
4
4
1
2
2
2
4
4
cos2
sin 4
1
( )
cos2
sin 4
2
it
it
it
it
t
t
it
it
it
it
e
e
e
e
t
t
t
e
e
i
t
t
e
e
e
e
−
−
−


+
−
−
−






=
+
=
=
+






+
+
−






A
A
x
c
c
 
 
 
Note that  x(t)  is a linear combination of two motions — one in which the two masses  
move in the same direction with frequency 
1
2
ω =
 and with equal amplitudes, and one in 
which they move in opposite directions with frequency 
2
4
ω =
 and with equal 
amplitudes. 
 

 
Section 9.1 
453 
 
 
CHAPTER 9 
 
NONLINEAR SYSTEMS AND PHENOMENA 
 
 
SECTION 9.1 
 
STABILITY AND THE PHASE PLANE 
 
1. 
The only solution of the homogeneous system  2
0,
3
0
x
y
x
y
−
=
−
=
 is the origin   
 
(0, 0).  The only figure among Figs. 9.1.11 through 9.1.18 showing a single critical point 
at the origin is Fig. 9.1.13.  Thus the only critical point of the given autonomous system 
is the saddle point (0, 0) shown in Figure 9.1.13 in the text. 
 
2. 
The only solution of the system  
0,
3
4
0
x
y
x
y
−
=
+
+
=
 is the point  (1, 1).  The only 
figure among Figs. 9.1.11 through 9.1.18 showing a single critical point at (1, 1) is Fig. 
9.1.15.  Thus the only critical point of the given autonomous system is the node (1, 1) 
shown in Figure 9.1.15 in the text. 
 
3. 
The only solution of the system  
2
3
0,
2
0
x
y
x
y
−
+
=
−
+
=
 is the point  (–1, 1).  The 
only figure among Figs. 9.1.11 through 9.1.18 showing a single critical point at (–1, 1) is 
Fig. 9.1.18.  Thus the only critical point of the given autonomous system is the stable 
center (-1, 1) shown in Figure 9.1.18 in the text.    
          
4. 
The only solution of the system  2
2
4
0,
4
3
0
x
y
x
y
−
−
=
+
+
=
 is the point  (1, –1).  The 
only figure among Figs. 9.1.11 through 9.1.18 showing a single critical point at (1, –1) is 
Fig. 9.1.12.  Thus the only critical point of the given autonomous system is the spiral 
point (1,-1) shown in Figure 9.1.12 in the text.  
 
5. 
The first equation 
2
1
0
y
−
=
 gives  y  =  1  or  y  =  -1  at a critical point.  Then the 
second equation  
2
0
x
y
+
=
 gives  x  =  -2  or  x  =  2,  respectively.  The only figure 
among Figs. 9.1.11 through 9.1.18 showing two critical points at (–2, 1) and (2, –1) is 
Fig. 9.1.11.  Thus the critical points of the given autonomous system are the spiral point 
(-2, 1) and the saddle point (2, 1) shown in Figure 9.1.11 in the text. 
 
6. 
The second equation 
2
4
0
x
−
=
 gives  x  =  2  or  x  =  -2  at a critical point.  Then the 
first equation  2
4
15
0
x
y
−
−
=
 gives  y  =  -2/5  or  x  =  2/3,  respectively.  The only 
figure among Figs. 9.1.11 through 9.1.18 showing two critical points at (–2, 2/3) and  
 
(2, –2/5) is Fig. 9.1.17.  Thus the critical points of the given autonomous system are the 
spiral point (-2, 2/3) and the saddle point (2,-2/5) shown in Figure 9.1.17 in the text. 

454 
Chapter 9 
   7. 
The first equation  
3
4
0
x
x
−
=
 gives   x  =  -2,  x  =  0,  or  x  =  2  at a critical point.  
 
Then the second equation  
2
0
x
y
−
=
 gives  y  =  -1,  y  =  0,  or  y  =  1,  respectively.  
 
The only figure among Figs. 9.1.11 through 9.1.18 showing three critical points at  
 
(–2, –1),  (0, 0), and (2, 1) is Fig. 9.1.14.  Thus the critical points of the given 
autonomous system are the spiral point (0, 0) and the saddle points (-2, 1) and (2, 1) 
shown in Figure 9.1.14 in the text. 
   
8. 
The second  
2
0
y
x
−
−
=
 equation gives  y  =  -x2  at a critical point.  Substitution of this 
in the first equation  
2
0
x
y
x
xy
−
−
+
=
 then gives  x - x3  =  0,  so  x  =  -1,  x  =  0,  or  
x  =  1.  The only figure among Figs. 9.1.11 through 9.1.18 showing three critical points 
at  
 
(–1, –1),  (0, 0), and (1, –1) is Fig. 9.1.16.  Thus the critical points of the given 
autonomous system are the spiral point (-1,-1), the saddle point (0, 0), and the node  
 
(1,-1) shown in Figure 9.1.16 in the text.   
  
In each of Problems 9-12 we need only set  x′  =  x″  =  0  and solve the resulting equation for  x. 
 
9. 
The equation  
3
2
4
(4
)
0
x
x
x
x
−
=
−
=
 has the three solutions  
0,
2.
x =
±
  This gives the 
three equilibrium solutions  x(t)  ≡  0,  x(t)  ≡  2,  x(t)  ≡  -2  of the given 2nd-order 
differential equation.  A phase plane portrait for the equivalent 1st-order system 
 
3
,
4
x
y
y
x
x
′
′
=
= −
+
 is shown in the figure below. We observe that the critical point  
 
(0,0)  in the phase plane appears to be a center, whereas the points  ( 2,0)
±
 appear to be 
 
saddle points. 
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
10. 
The equation  
3
2
4
(1
4
)
0
x
x
x
x
+
=
+
=
 has the single real solution  x = 0.  This gives the 
single equilibrium solution  x(t)  ≡  0  of the given 2nd-order differential equation.  A 

 
Section 9.1 
455 
phase plane portrait for the equivalent 1st-order system  
3
,
2
4
x
y
y
y
x
x
′
′
=
= −
−
−
 is 
shown in the figure below. We observe that the critical point  (0,0)  in the phase plane 
appears to be a spiral sink. 
 
 
 
 
−3
0
3
−5
0
5
x
y
 
 
11. 
The equation  4sin
0
x =
 is satisfied by  x
nπ
=
 for any integer  n.  Thus the given 2nd-
order equation has infinitely many equilibrium solutions:  x(t)  ≡  nπ  for any integer  n. 
 
A phase portrait  for the equivalent 1st-order system  
,
3
4sin
x
y
y
y
x
′
′
=
= −
−
 is shown 
 
below.  We observe that the critical point  (
,0)
nπ
 in the phase plane looks like a spiral 
 
sink if  n  is even, but a saddle point if  n  is odd. 
 
 
 
 
−2pi
−pi
0
pi
2pi
−2
0
2
x
y
 

456 
Chapter 9 
12. 
We immediately get the single solution  x = 0  and thus the single equilibrium solution 
 
x(t)  ≡  0.  A phase plane portrait for the equivalent 1st-order system  
 
2
,
(
1)
x
y
y
x
y
x
′
′
=
= −
−
−
 is shown below. We observe that the critical point (0,0)  in 
 
the phase plane looks like a spiral source, with the solution  curves emanating from this 
 
source spiraling outward toward a closed curve trajectory. 
 
 
 
 
−2
−1
0
1
2
−4
−2
0
2
4
x
y
 
 
In Problems 13–16, the given x- and y-equations are independent exponential differential 
equations that we can solve immediately by inspection. 
 
13. 
Solution:   
x(t)  =  x0e-2t,   y(t)  =  y0e-2t   
 
 
Then  
0
0
(
/
)
,
y
y
x
x
kx
=
=
 so the trajectories are straight lines through the origin.  Clearly  
( ),
( )
0
x t
y t →
 as  
,
t →+∞ so the origin is a stable proper node like the one shown 
below. 
 
 
 
 
−5
0
5
−5
0
5
x
y
 

 
Section 9.1 
457 
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−5
0
5
−5
0
5
x
y
14. 
Solution:   
x(t)  =  x0e2t,   y(t)  =  y0e-2t 
 
 
Then  
0
0
,
xy
x y
k
=
=
 so the trajectories are rectangular hyperbolas.  Thus the origin is an 
unstable saddle point like the one in the left-hand figure below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
15. 
Solution:   
x(t)  =  x0e-2t,   y(t)  =  y0e-t   
 
 
Then  
2
2
2
0
0
0
(
/
)(
)
,
t
x
x
y
y e
ky
−
=
=
 so the trajectories are parabolas of the form  
2,
x
ky
=
and clearly  ( ),
( )
0
x t
y t →
 as  
.
t →+∞   Thus the origin is a stable improper 
node like the one shown in the right-hand figure above. 
  
16. 
Solution:   
x(t)  =  x0et,   y(t)  =  y0e3t 
 
 
The origin is an unstable improper node.  The trajectories consist of the y-axis and curves 
of the form  y  =  kx3, departing from the origin as in the left-hand figure below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

458 
Chapter 9 
17. 
Differentiation of the first equation and substitution using the second one gives 
 
 
 
 
, so
0.
x
y
x
x
x
′′
′
′′
=
=
+
=
 
 
 
We therefore get the general solution 
 
 
  
 
x(t)  =  A cos t + B sin t 
 
 
 
y(t)  =  B cos t - A sin t          ( y
x′
=
). 
 
Then 
 
 
 
2
2
2
2
2
2
2
2
2
2
2
2
( cos
sin )
(
cos
sin )
(
)cos
(
)sin
.
x
y
A
t
B
t
B
t
A
t
A
B
t
A
B
t
A
B
+
=
+
+
−
=
+
+
+
=
+
 
 
 
Therefore the trajectories are clockwise-oriented circles centered at the origin, and the 
origin is a stable center as in the right-hand figure at the bottom of the preceding page.  
 
18. 
Elimination of  y  as in Problem 17 gives  
4
0,
x
x
′′ +
=
  so we get the general solution 
 
 
 
 
x(t)  =     A cos 2t +   B sin 2t, 
 
 
 
y(t)  = -2B cos 2t + 2A sin 2t        ( y
x′
= −
). 
 
 
 
It follows readily that   
 
 
2
2
2
2
2
2
2
2
4
4
4
, so
1
( / 2)
x
y
x
y
A
B
b
b
+
=
+
+
=
 
 
 
where  
2
2
2
4
4
.
b
A
B
=
+
  Hence the origin is a stable center like the one illustrated in the 
figure below, and the vertical semiaxis of each ellipse is twice its horizontal semiaxis. 
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 

 
Section 9.1 
459 
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−5
0
5
−5
0
5
x
y
19. 
Elimination of  y  as in Problem 17 gives  
4
0,
x
x
′′ +
=
  so we get the general solution 
 
 
 
 
x(t)  =  A cos 2t + B sin 2t, 
 
 
 
y(t)  =  B cos 2t - A sin 2t          (
1
2
y
x′
=
). 
 
 
Then  
2
2
2
2,
x
y
A
B
+
=
+
 so the origin is a stable center, and the trajectories are 
clockwise-oriented circles centered at (0, 0), as in the left-hand figure below. 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
20. 
Substitution of  y
x
′
′′
=
 from the first equation into the second one gives  
5
x
x
y
′′ = −
−
 
5
4 ,
x
x′
= −
−
 so  
4
5
0.
x
x
x
′′
′
+
+
=
  The characteristic roots of this 
equation are  
2
,
r
i
= −±
 so we get the general solution 
 
 
 
 
 
x(t)  =  e-2t(A cos t + B sin t),  
 
 
 
y(t)  =  e-2t[(-2A + B)cos t - (A + 2B)sin t] 
 
 
(the latter because  y
x′
=
).  Clearly ( ),
( )
0
x t
y t →
 as  
,
t →+∞  so the origin is an 
asymptotically stable spiral point with trajectories approaching  (0,0), as in the right-hand 
figure above. 
 
21. 
We want to solve the system 
 
 
 
 
2
2
2
2
(1
)
0
(1
)
0.
ky
x
x
y
kx
y
x
y
−
+
−
−
=
+
−
−
=
 
 
If we multiply the first equation by  –y  and the second one by  x, then add the two 
results, we get  
2
2
(
)
0.
k x
y
+
=
  It therefore follows that  x  =  y  =  0. 
 

460 
Chapter 9 
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−5
0
5
−5
0
5
x
y
22. 
After separation of variables, a partial-fractions decomposition gives 
 
 
 
2
1
1
1
(1
)
2(
1)
2(
1)
1
1
1
ln
ln(
1)
ln(
1)
,
2
2
2
dr
t
r
r
r
r
r
r
r
r


=
=
−
−


−
+
−


=
−
+
−
−
+
⌠
⌠

⌡
⌡
 
 
so 
 
 
 
2
2
2
ln
1
Cr
t
r
=
− 
 
 
(assuming that  r > 1, for instance).  The initial condition  
0
(0)
r
r
=
 then gives 
 
 
 
 
2
2
2
2
2
0
0
2
2
2
2
0
0
(
1)
(
1)
2
ln
, so
.
(
1)
(
1)
t
r
r
r
r
t
e
r
r
r
r
−
−
=
=
−
−
 
 
 
We now solve readily for 
 
 
 
 
2
2
2
2
0
0
2
2
2
2
2
2
0
0
0
0
.
(1
)
(1
)
t
t
t
r e
r
r
r e
r
r
r
e−
=
=
+
−
+
−
 
 
23. 
The equation  
/
/
dy dx
x y
= −
  separates to  
0,
x dx
y dy
+
=
  so  
2
2
.
x
y
C
+
=
  Thus 
the trajectories consist of the origin  (0, 0)  and the circles  x2 + y2  =  C > 0, as shown in 
the left-hand figure below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
24. 
The equation  
/
/
dy dx
x y
=
  separates to  
0,
y dy
xdx
−
=
  so  
2
2
.
y
x
C
−
=
  Thus the 
trajectories consist of the origin  (0, 0)  and the hyperbolas  y2 - x2  =  C, as shown in the 
right-hand figure above. 

 
Section 9.1 
461 
 
 
 
 
−5
0
5
−5
0
5
x
y
25. 
The equation  
/
/ 4
dy dx
x
y
= −
  separates to  
4
0,
x dx
y dy
+
=
  so  
2
2
4
.
x
y
C
+
=
  
Thus the trajectories consist of the origin  (0, 0)  and the ellipses  x2 + 4y2  =  C > 0, as 
shown in the left-hand figure below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
26. 
The equation  
3
3
/
/
dy dx
x
y
= −
  separates to  
3
3
0,
x dx
y dy
+
=
  so  
4
4
.
x
y
C
+
=
  
Thus the trajectories consist of the origin  (0, 0)  and the ovals of the form  x4 + y4  =  C, 
as illustrated in the right-hand figure above. 
 
27. 
If  φ(t)  =  x(t + γ)  and  ψ(t)  =  y(t + γ)  then 
 
 
 
φ′(t)  =  x′(t + γ)  =  y(t + γ)  =  ψ(t), 
 
but 
 
 
ψ(t)  =  y′(t + γ)  =  x(t + γ)⋅(t + γ)  =  t φ(t) + γ φ(t) ≠ t φ(t). 
 
28. 
If  φ(t)  =  x(t + γ)  and  ψ(t)  =  y(t + γ)  then 
 
 
 
φ′(t)  =  x′(t + γ)  =  F(x(t + γ),     y(t + γ))  =  F(φ(t), ψ(t)), 
 
and 
 
 
ψ′(t)  =  G(φ(t),ψ(t))   
 
 
similarly.  Therefore  φ(t)  and  ψ(t)  satisfy the given differential equations. 
 
 
SECTION 9.2 
 
LINEAR AND ALMOST LINEAR SYSTEMS 
 
In Problems 1–10 we first find the roots  λ1  and λ2  of the characteristic equation of the 
coefficient matrix of the given linear system.  We can then read the type and stability of the 
critical point (0,0) from Theorem 1 and the table of Figure 9.2.9 in the text. 
 
 
 
 
−4
0
4
−4
0
4
x
y

462 
Chapter 9 
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−5
0
5
−5
0
5
x
y
1. 
The roots  λ1  =  -1  and  λ2  =  -3  of the characteristic equation  
2
4
3
0
λ
λ
+
+
=
 are 
both negative, so  (0,0)  is an asymptotically stable node as shown on the left below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
2. 
The roots  λ1  =  2  and  λ2  =  3  of the characteristic equation  
2
5
6
0
λ
λ
−
+
=
 are both 
positive, so  (0,0)  is an unstable improper node as shown on the right above. 
 
3. 
The roots  λ1  =  -1  and  λ2  =  3  of the characteristic equation  
2
2
3
0
λ
λ
−
−
=
 have 
different signs, so  (0,0)  is an unstable saddle point as shown on the left below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
4. 
The roots  λ1  =  -2  and  λ2  =  4  of the characteristic equation  
2
2
3
0
λ
λ
−
−
=
 have 
different signs, so  (0,0)  is an unstable saddle point as shown on the right above. 
 
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−5
0
5
−5
0
5
x
y

 
Section 9.2 
463 
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−5
0
5
−5
0
5
x
y
5. 
The roots  λ1  =  λ2  =  -1  of the characteristic equation  
2
2
1
0
λ
λ
+
+ =
 are negative and 
equal, so  (0,0)  is an asymptotically stable node as in the left-hand figure below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
6. 
The roots  λ1  =  λ2  =  2  of the characteristic equation  
2
4
4
0
λ
λ
−
+
=
 are positive and 
equal, so  (0,0) is an unstable node as in the right-hand figure above. 
 
7. 
The roots  λ1, λ2  =  1 ± 2 i  of the characteristic equation  
2
2
5
0
λ
λ
−
+
=
 are complex 
conjugates with positive real part, so  (0,0)  is an unstable spiral point as shown in the 
left-hand figure below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
8. 
The roots  λ1, λ2  =  -2 ± 3 i  of the characteristic equation  
2
4
13
0
λ
λ
+
+
=
 are complex 
conjugates with negative real part, so  (0,0)  is an asymptotically stable spiral point as 
shown in the right-hand figure above. 
 
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−5
0
5
−5
0
5
x
y

464 
Chapter 9 
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−5
0
5
−5
0
5
x
y
9. 
The roots  λ1, λ2  =  ±2 i  of the characteristic equation  
2
4
0
λ +
=
 are pure imaginary, so  
(0,0)  is a stable (but not asymptotically stable) center as in the left-hand figure below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
10. 
The roots  λ1, λ2  =  ±3 i  of the characteristic equation  
2
9
0
λ +
=
 are pure imaginary, so  
(0,0)  is a stable (but not asymptotically stable) center as in the right-hand figure above. 
 
11. 
The Jacobian matrix  
1
2
3
4
−


= 

−


J
  has characteristic equation  
2
3
2
0
λ
λ
+
+
=
 
 
and eigenvalues  λ1 = -1,  λ2 = -2  that are both negative.  Hence the critical point   
 
(2, 1)  is an asymptotically stable node as in the left-hand figure below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
12. 
The Jacobian matrix  
1
2
1
4
−


= 



J
  has characteristic equation  
2
5
6
0
λ
λ
−
+
=
 
 
and eigenvalues  λ1 = 2,  λ2 = 3  that are both positive.  Hence the critical point   
 
(2,–3)  is an unstable node as in the right-hand figure above. 

 
Section 9.2 
465 
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−5
0
5
−5
0
5
x
y
13. 
The Jacobian matrix  
2
1
3
2
−


= 

−


J
  has characteristic equation  
2
1
0
λ −=
 
 
and eigenvalues  λ1 = -1,  λ2 = +1  having different signs.  Hence the critical point   
 
(2, 2)  is an unstable saddle point as in the left-hand figure below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
14. 
The Jacobian matrix  
1
1
3
1


= 

−


J
  has characteristic equation  
2
4
0
λ −
=
 
 
and eigenvalues  λ1 = -2, λ2 = 2  that are real with different signs.  Hence the critical 
point  (3, 4)  is an unstable saddle point as in the right-hand figure above. 
 
15. 
The Jacobian matrix  
1
1
5
3
−


= 

−


J
  has characteristic equation  
2
2
2
0
λ
λ
+
+
=
 
 
and eigenvalues  λ1, λ2  =  -1 ± i  that are complex conjugates with negative real part.  
Hence the critical point  (1, 1)  is an asymptotically stable spiral point as shown in the 
figure on the left below. 
 
 
 
 
 
 
 
 
 
 
 
 
 

466 
Chapter 9 
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−5
0
5
−5
0
5
x
y
16. 
The Jacobian matrix  
1
2
1
3
−


= 



J
  has characteristic equation  
2
4
5
0
λ
λ
−
+
=
 
 
and eigenvalues  λ1, λ2  =  2 ± i  that are complex conjugates with positive real part.  
Hence the critical point  (3, 2)  is an unstable spiral point as shown in the right-hand 
figure at the bottom of the preceding page. 
 
17. 
The Jacobian matrix  
1
5
1
1
−


= 

−


J
  has characteristic equation  
2
4
0
λ +
=
 and pure 
imaginary eigenvalues  λ1, λ2  =  ±2i.  Hence  (5/2,-1/2)  is a stable (but not 
asymptotically stable) center as shown on the left below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
18. 
The Jacobian matrix  
4
5
5
4
−


= 

−


J
  has characteristic equation  
2
9
0
λ +
=
 and pure 
imaginary eigenvalues  λ1, λ2  =  ±3i.  Hence  (-2,-1)  is a stable (but not asymptotically 
stable) center as shown on the right above. 
 
In each of Problems 19–28 we first calculate the Jacobian matrix  J  and its eigenvalues at (0,0) 
and at each of the other critical points we observe in our phase portrait for the given system.  
Then we apply Theorem 2 to determine as much as we can about the type and stability of each of 
these critical points of the given almost linear system. Finally we  a phase portrait that 
 
19. 
1
2
3
2
4
6
y
x
y
x
+
−+


= 

−
−−


J
 
 
At (0,0):  The Jacobian matrix  
1
3
4
6
−


= 

−


J
  has characteristic equation  
2
5
6
0
λ
λ
+
+
=
 
 
and eigenvalues  λ1 = -3,  λ2 = -2  that are both negative.  Hence  (0,0)  is an 
asymptotically stable node of the given almost linear system. 

 
Section 9.2 
467 
 
 
 
 
−2
0
2
−2
0
2
x
y
 
 
 
 
−3
0
3
−3
0
3
x
y
 
At (2/3, 2/5):  The Jacobian matrix  
9/5
5/3
18/5
20/3
−


= 

−


J
  has characteristic equation  
 
2
73
15
6
0
λ
λ
+
−
=
  and approximate eigenvalues  
1
2
5.89,
1.02
λ
λ
≈−
≈
 with different  
 
signs.  Hence  (2/3, 2/5)  is a saddle point. 
 
The left-hand figure below shows both these critical points. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
20. 
6
2
5
2
1
2
x
y
+
−


= 

−+


J
 
 
At (0,0):  The Jacobian matrix  
6
5
2
1
−


= 

−


J
  has characteristic equation  
2
5
4
0
λ
λ
−
+
=
 
 
and eigenvalues  λ1 = 1,  λ2 = 4  that are both positive.  Hence  (0,0)  is an unstable node 
of the given almost linear system. 
 
At (–1,–1):  The Jacobian matrix  
4
5
2
3
−


= 

−


J
  has characteristic equation  
 
2
2
0
λ
λ
−
−
=
  and eigenvalues  
1
2
1,
2
λ
λ
= −
=
 with different signs.  Hence (–1,–1) is a 
 
saddle point. 
 
At (–2.30,–1.70):  The Jacobian matrix  
1.40
5
2
4.40
−


≈

−


J
  has complex conjugate 
 
eigenvalues 
1
2
1.5 1.25 ,
1.5 1.25
i
i
λ
λ
≈−
+
≈−
−
 with negative real parts.  Hence  
 
(–2.30,–1.70) is a spiral sink. 
 
The figure on the right above shows these three critical points. 
 

468 
Chapter 9 
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−6
−4
−2
0
2
4
6
−6
−4
−2
0
2
4
6
x
y
21. 
1
2
2
2
2
3
2
3
x
y
y
x
+
+


= 

−
−−


J
 
 
At (0,0):  The Jacobian matrix  
1
2
2
2


= 

−


J
  has characteristic equation  
2
6
0
λ
λ
+
−
=
 
 
and eigenvalues  λ1 = –3,  λ2 = 2  with different signs.  Hence  (0,0)  is a saddle point of 
the given almost linear system. 
 
At (–0.51,–2.12):  The Jacobian matrix  
0.014
2.236
8.354
0.479
−
−


≈

−


J
  has complex conjugate 
 
eigenvalues 
1
2
0.25
4.32 ,
0.25
4.32
i
i
λ
λ
≈−
+
≈−
+
 with negative real parts.  Hence  
 
(–0.51,–2.12) is a spiral sink.  
 
The figure on the left below shows these two critical points. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
22. 
2
2
1
4
2
2
2
1
y
xy
xy
x


−
−
= 

+
−+


J
 
 
At (0,0):  The Jacobian matrix  
1
4
2
1


= 

−


J
  has characteristic equation  
2
9
0
λ −
=
 
 
and eigenvalues  λ1 = –3,  λ2 = 3  that have different signs.  Hence  (0,0)  is a saddle point 
of the given almost linear system. 
 
At ( 3.65, 0.59)
±
∓
:  The Jacobian matrix  
0.649
8.325
2.325
12.325


≈

−


J
  has positive real 
 
eigenvalues 
1
2
2.649,
10.325.
λ
λ
≈
≈
 Hence these critical points are both nodal sources. 
 
At ( 0.82, 5.06)
±
±
:  The Jacobian matrix  
24.649
4.325
10.325
0.325
−
−


≈

−


J
  has negative real 
 
eigenvalues 
1
2
22.649,
2.325.
λ
λ
≈−
≈−
 Hence these critical points are both nodal  
 
sinks. 
 
The figure on the right above shows these five critical points. 

 
Section 9.2 
469 
 
 
 
 
−3
−2
−1
0
1
2
3
−3
−2
−1
0
1
2
3
x
y
 
 
 
 
−5
0
5
−5
0
5
x
y
23. 
2
3
2
3
5
4
6
4
x
y


+
−
= 

−+


J
 
 
At (0,0):  The Jacobian matrix  
2
5
4
6
−


= 

−


J
  has characteristic equation  
2
4
8
0
λ
λ
+
+
=
 
 
and complex conjugate eigenvalues  
1
2
2
2 ,
2
2
i
i
λ
λ
= −+
= −−
  with negative real part.  
Hence  (0,0)  is a spiral sink of the given almost linear system. 
 
At ( 1.08, 0.68)
−
−
:  The Jacobian matrix  
5.495
5
4
7.276
−


≈

−


J
  has eigenvalues  
 
1
2
5.45,
3.67
λ
λ
≈−
≈
 with different signs. Hence ( 1.08, 0.68)
−
−
 is a saddle point. 
 
The figure on the left below shows these two critical points. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
24. 
2
2
2
2
5
2
3
3
5
2
3
xy
x
y
xy
x
y


+
−+
+
= 

+
+


J
 
 
At (0,0):  The Jacobian matrix  
5
3
5
0
−


= 



J
  has characteristic equation  
 
2
5
15
0
λ
λ
−
+
=
and complex conjugate eigenvalues  
1
2
2.5
2.96 ,
2.5
2.96
i
i
λ
λ
≈
+
≈
−
  
 
with positive real part.  Hence  (0,0)  is a spiral source of the given almost linear system. 
 
The figure on the right above shows this critical point. 
 
25. 
1
3
2
3
2
2
3
2
y
x
x
y
+
−+


= 

−
−−


J
 
 
At (0,0):  The Jacobian matrix  
1
2
2
3
−


= 

−


J
  has characteristic equation  
2
2
1
0
λ
λ
+
+ =
 
 
and equal negative eigenvalues  λ1 = –1,  λ2 = –1.  Hence  (0,0)  is either a nodal sink or a 
spiral sink of the given almost linear system. 

470 
Chapter 9 
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−0.2
0
0.2
−0.2
0
0.2
x
y
 
At (0.74, 3.28)
−
:  The Jacobian matrix  
8.853
0.226
0.516
3.568
−


≈



J
  has real eigenvalues 
 
1
2
8.86,
3.58
λ
λ
≈−
≈
 with different signs.  Hence (0.74, 3.28)
−
is a saddle point. 
 
At (2.47, 0.46)
−
:  The Jacobian matrix  
0.370
5.410
2.940
2.087
−


≈

−
−


J
  has complex conjugate  
 
eigenvalues 
1
2
1.23
3.89 ,
1.23
3.89
i
i
λ
λ
≈−
+
≈−
+
 with negative real part. Hence 
 
(2.47, 0.46)
−
 is a spiral sink. 
 
At (0.121,0.074) :  The Jacobian matrix  
1.222
1.636
1.758
3.148
−


≈

−


J
  has real eigenvalues  
 
1
2
2.34,
0.42
λ
λ
≈−
≈
 with different signs.  Hence (0.121,0.074) is a saddle point. 
 
The left-hand figure below shows clearly the first three of these critical points. The right- 
 
hand figure is a close-up near the origin with the final critical point now visible. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
26. 
3
2
2
2
2
3
1
3
x
y
y
x
−
−−


= 

−
−−


J
 
 
At (0,0):  The Jacobian matrix  
3
2
2
1
−


= 

−


J
  has characteristic equation  
2
2
1
0
λ
λ
−
+ =
 
 
and equal positive eigenvalues  λ1 = 1,  λ2 = 1.  Hence  (0,0)  is either a nodal source or a 
spiral source of the given almost linear system. 
 
At (0.203,0.253) :  The Jacobian matrix  
2.592
2.506
1.241
1.611
−


≈

−


J
  has real eigenvalues 
 
1
2
0.65,
1.63
λ
λ
≈−
≈
 with different signs.  Hence (0.203,0.253) is a saddle point. 

 
Section 9.2 
471 
 
At ( 0.231, 1.504)
−
−
:  The Jacobian matrix  
3.462
1.008
6.511
0.307


≈

−


J
  has real eigenvalues 
 
1
2
1.60,
4.76
λ
λ
≈−
≈
 with different signs.  Hence ( 0.231, 1.504)
−
−
is a saddle point. 
 
At (2.360,0.584) :  The Jacobian matrix  
1.721
3.168
0.247
8.081
−
−


≈

−
−


J
  has unequal negative   
 
eigenvalues 
1
2
7.96,
1.85
λ
λ
≈−
≈−
. Hence  (2.47, 0.46)
−
 is a nodal sink. 
 
The figure below shows these four critical points. 
 
 
 
 
−3
0
3
−3
0
3
x
y
 
 
 
27. 
3
3
1
4
1
2
2
2
1
4
x
y
x
y


+
−−
= 

−
−+


J
 
 
At (0,0):  The Jacobian matrix  
1
1
2
1
−


= 

−


J
  has characteristic equation  
2
1
0
λ + =
 
 
and equal positive eigenvalues  λ1 = –i,  λ2 = +i.  Hence  (0,0)  is either a center or a 
spiral point, but its stability is not determined by Theorem 2. 
 
At ( 0.254, 0.507)
−
−
:  The Jacobian matrix  
0.934
0.014
2.508
1.521


≈

−


J
  has real eigenvalues 
 
1
2
1.53,
0.95
λ
λ
≈−
≈
 with different signs.  Hence ( 0.254, 0.507)
−
−
is a saddle point. 
 
At ( 1.557, 1.637)
−
−
:  The Jacobian matrix  
14.087
4.273
5.113
16.532
−
−


≈



J
  has real eigenvalues 
 
1
2
13.36,
15.80
λ
λ
≈−
≈
 with different signs.  Hence ( 1.557, 1.637)
−
−
is a saddle point. 

472 
Chapter 9 
 
 
 
 
−2
0
2
−2
0
2
x
y
 
 
 
 
−0.6
0
0.6
−0.6
0
0.6
x
y
 
At ( 1.070, 1.202)
−
−
:  The Jacobian matrix  
3.905
1.403
4.141
7.940
−


≈

−


J
  has unequal negative  
  
eigenvalues 
1
2
9.07,
2.78
λ
λ
≈−
≈−
. Hence  ( 1.070, 1.202)
−
−
 is a nodal sink. 
 
The left-hand figure below shows these four critical points.  The close-up on the right  
 
suggests that the origin may (but may not) be a stable center. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
28. 
2
2
3
3
1
3
13
3
3
3
x
y
y
x


+
−+
= 

+
−+


J
 
 
At (0,0):  The Jacobian matrix  
3
1
13
3
−


= 

−


J
  has characteristic equation  
2
4
0
λ +
=
 
 
and equal positive eigenvalues  λ1 = –2i,  λ2 = +2i.  Hence  (0,0)  is either a center or a 
spiral point, but its stability is not determined by Theorem 2. 
 
At ( 0.121, 0.469)
−
−
:  The Jacobian matrix  
3.044
0.340
11.593
3.364
−


≈

−


J
  has real eigenvalues 
 
1
2
2.67,
2.35
λ
λ
≈−
≈
 with different signs.  Hence ( 0.121, 0.469)
−
−
is a saddle point. 
 
At (0.126,0.626) :  The Jacobian matrix  
3.048
0.176
14.878
2.621


≈

−


J
  has real eigenvalues 
 
1
2
3.05,
3.48
λ
λ
≈−
≈
 with different signs.  Hence (0.126,0.626) is a saddle point. 
 
At (5.132, 5.382)
−
:  The Jacobian matrix  
82.000
85.903
3.146
12.395


≈

−


J
  has unequal positive   
 
eigenvalues 
1
2
16.52,
77.87
λ
λ
≈
≈
. Hence  (5.132, 5.382)
−
 is a nodal source. 
 
The first three of these critical points are shown in the figure at the top of the next page. 

 
Section 9.2 
473 
 
 
 
 
−0.25
0
0.25
−1
0
1
x
y
 
 
 
 
−2
0
2
−2
0
2
x
y
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
29. 
1
1
2
1
x
−


= 

−


J
 
 
At (0,0):  The Jacobian matrix  
1
1
0
1
−


= 

−


J
  has characteristic equation  
2
1
0
λ −=
 and 
 
real eigenvalues 
1
2
1,
1
λ
λ
≈−
≈+  with different signs.  Hence (0,0) is a saddle point. 
 
At (1,1) :  The Jacobian matrix  
1
1
2
1
−


= 

−


J
  has characteristic equation  
2
1
0
λ + =
 and 
 
pure imaginary eigenvalues 
1
2
,
.
i
i
λ
λ
≈+
≈− Hence  (1,1)  is either a center or a spiral  
 
point, but its stability is not determined by Theorem 2. 
 
The left-hand figure below suggests that  (1,1)  is a stable center. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
−3
0
3
−3
0
3
x
y

474 
Chapter 9 
30. 
0
1
2
1
x


= 

−


J
 
 
At (1,1) :  The Jacobian matrix  
0
1
2
1


= 

−


J
  has characteristic equation  
2
2
0
λ
λ
+
−
=
 
 
and real eigenvalues 
1
2
2,
1
λ
λ
≈−
≈+  with different signs.  Hence (1,1)  is a saddle point. 
 
At (1, 1)
−
:  The Jacobian matrix  
0
1
2
1


= 

−
−


J
  has characteristic equation  
 
2
2
0
λ
λ
+
+
=
 and complex conjugate eigenvalues 
1
2
0.5 1.323 ,
0.5 1.323
i
i
λ
λ
≈−
+
≈−
−
 
 
with negative real part.  Hence (1,–1)  is a spiral sink as in the right-hand figure on the 
 
preceding page. 
 
31. 
2
0
2
3
1
y
x


= 

−


J
 
 
At (1,1) :  The Jacobian matrix  
0
2
3
1


= 

−


J
  has characteristic equation  
2
6
0
λ
λ
+
−
=
 
 
and real eigenvalues 
1
2
3,
2
λ
λ
= −
= +  with different signs.  Hence (1,1)  is a saddle point. 
At ( 1, 1)
−−
:  The Jacobian matrix  
0
2
3
1
−


= 

−


J
  has characteristic equation 
2
6
0
λ
λ
+
+
=
 and complex conjugate eigenvalues 
1
2
0.5
2.398 ,
0.5
2.398
i
i
λ
λ
≈−
+
≈−
−
  
with negative real part.  Hence (–1,–1)  is a spiral sink. 
These two critical points are shown in the figure below. 
 
 
 
 
 
−3
0
3
−3
0
3
x
y
 
 

 
Section 9.2 
475 
 
 
 
 
−3
0
3
−3
0
3
x
y
  32. 
1
2
y
x


= 

−


J
 
 
At (2,1):  The Jacobian matrix  
1
2
1
2


= 

−


J
  has characteristic equation  
2
4
0
λ
λ
+
−
=
 
 
and real eigenvalues 
1
2
2.56,
1.56
λ
λ
≈−
≈+
 with different signs.  Hence (1,1)  is a saddle 
 
point. 
At ( 2, 1)
−
−
:  The Jacobian matrix  
1
2
1
2
−
−


= 

−


J
  has characteristic equation 
2
3
4
0
λ
λ
+
+
=
 and complex conjugate eigenvalues 
1
1.5 1.323 ,i
λ ≈−
+
  
2
1.5 1.323i
λ ≈−
−
with negative real part.  Hence (–2,–1)  is a spiral sink. 
These two critical points are shown in the figure below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
33. 
The characteristic equation of the given linear system is 
 
 
 
 
 
 
(λ - ε)2 + 1  =  0 
 
 
 
with characteristic roots  λ1, λ2  =  ε ± i. 
 
 
(a) 
So if  ε < 0  then  λ1, λ2  are complex conjugates with negative real part,  and 
hence  (0, 0)  is an asymptotically stable spiral point. 
 
 
(b) 
If  ε  =  0  then λ1, λ2  =  ±i  (pure imaginary),  so  (0,0)  is a stable center. 
 
 
(c) 
If  ε > 0, the situation is the same as in (a) except that the real part is positive, so  
(0, 0)  is an unstable spiral point. 

476 
Chapter 9 
34. 
The characteristic equation of the given linear system is 
 
 
 
 
 
 
(λ + 1)2 - ε  =  0. 
 
 
(a) 
If  ε < 0  then  λ1, λ2  =   -1 ± i
ε
−.  Thus the characteristic roots are complex 
conjugates with negative real part, so it follows that  (0,0)  is an asymptotically stable 
spiral point. 
 
 
(b) 
If  ε  =  0  then the characteristic roots  λ1  =  λ2  =  -1  are equal and negative, so  
(0,0)  is an asymptotically stable node.  If  0 < ε < 1  then  λ1, λ2  =  -1 ± ε   are both 
negative, so  (0,0)  is an asymptotically stable improper node. 
 
35. 
(a) 
If  h  =  0  we have the familiar system  x′  =  y,  y′  =  -x  with circular trajectories 
about the origin, which is therefore a center. 
 
 
(b) 
The change to polar coordinates as in Example 6 of Section 9.1 is routine, 
yielding  r′  =  hr3  and  θ′  =  -1. 
 
 
(c) 
If  h  =  -1,  then  r′  =  -r3  integrates to give  2r2  =  1/(t + C)  where  C  is a 
positive constant, so clearly  
0
r →
  as  t →+∞,  and thus the origin is a stable spiral 
point. 
 
 
(d) 
If  h  =  +1,  then  r′  =  r3  integrates to give  2r2  =  -1/(t + C)  where  C  =  -B  
is a positive constant.  It follows that  2r2  =  1/(B - t),  so now  r  increases as  t  starts at 
0  and increases. 
 
36. 
(a) 
Again, the change of variables is essentially the same as in Example 6 of Section 
9.1. 
 
 
(b) 
If  ε  =  -a2  then the equation  r′  =  -r(a2 + r2)  integrates to give the equation 
 
2
2
2
2
ln
ln(
)
2
r
a
r
t
C
a
a
+
+
= −
+
 
 
 
that (after exponentiating) we readily solve for 
 
2
2
2
2
2
2
exp( 2
2
) .
1
exp( 2
2
)
a
ta
Ca
r
ta
Ca
−
−
=
−
−
−
 
 
 
This makes it clear that  
0
r →
  as  t →+∞,  so the origin is an asymptotically stable 
spiral point in this case. 
 
 
(c) 
If  ε  =  a2  then the equation  r′  =  r(a2 - r2)  integrates to give the equation 
 

 
Section 9.2 
477 
2
2ln
ln(
)
ln(
)
2
r
a
r
a
r
t
C
a
−
−
−
+
+
=
 
 
 
that (after exponentiating) we solve for 
 
2
2
2
2 .
1
exp( 2
2
)
a
r
ta
Ca
=
+
−
−
 
 
 
It therefore follows that  r
a
→
  as  t →+∞. 
 
37. 
The substitution  y  =  vx  in the homogeneous first-order equation 
 
3
3
3
3
(2
)
(
2
)
dy
y
x
y
dx
x x
y
−
=
−
 
 
yields 
4
3
.
2
1
dv
v
v
x dx
v
+
= −
−
 
 
 
Separating the variables and integrating by partial fractions, we get 
 
2
1
1
2
1
1
1
v
dx
dv
v
v
v
v
x
⌠
⌠



⌡
⌡
−


−
+
+
=
−


+
−
+


 
 
2
ln((
1)(
1))
ln
ln
ln
v
v
v
v
x
C
+
−
+
=
−
+
 
 
2
(
1)(
1)
Cv
v
v
v
x
+
−
+
=
 
 
3
1
.
Cv
v
x
+
=
 
               
 
Finally, the replacement  
/
v
y x
=
  yields  
3
3
.
x
y
Cxy
+
=
 
 
38. 
The roots of the characteristic equation  
2
0
T
D
λ
λ
−
+
=
  are given by 
 
 
 
 
 
 
2
1
2
4
,
.
2
T
T
D
λ λ
±
−
=
 
 
We examine the various possibilities individually. 
• If the point ( ,
)
T D  lies above the parabola  
2
4
T
D
=
 in the trace-determinant plane 
but off the D-axis, so the radicand  
2
4
T
D
−
 is negative, then 
1
2
and
λ
λ  have 

478 
Chapter 9 
nonzero imaginary part and nonzero real part  
/ 2.
T
 Hence we have a spiral source if  
0,
T >
 a spiral sink if  
0.
T <
 
• If the point ( ,
)
T D  lies on the positive D-axis, so  
0 but
0,
T
D
=
>
 then 
1
2
,
i D
λ
λ
=
=
 pure imaginary, so we have a stable center.  
• If the point ( ,
)
T D  lies beneath the T-axis, then 
(
)
2
1
1
2
2
,
4
T
T
D
λ λ =
±
+
 because  
0.
D <
  It follows that  
1
2
and
λ
λ  are real with different signs, so we have a saddle 
point. 
• If the point ( ,
)
T D  lies between the T-axis and the parabola  
2
4 ,
T
D
=
 then the 
radicand 
2
4
T
D
−
 is positive but less than  
2.
T
  It follows that 
1
2
and
λ
λ  are real 
and both have the same sign as  T,  so we have a nodal source if  
0,
T >
 a nodal sink 
if  
0.
T <
 
 
 
 
SECTION 9.3 
 
ECOLOGICAL APPLICATIONS:   
PREDATORS AND COMPETITORS 
 
1. 
200
4
4
2
150
2
y
x
y
x
−
−


= 

−
+


J
 
 
At (0,0) :  The Jacobian matrix  
200
0
0
150


= 

−


J
  has characteristic equation  
 
(200
)( 150
)
0
λ
λ
−
−
−
=
 and real eigenvalues 
1
2
150,
200
λ
λ
= −
=
 with different  signs.  
 
Hence (0,0)  is a saddle point of the linearized system  
200 ,
150 .
x
x
y
y
′
′
=
= −
 See the  
 
left-hand figure below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
−5
0
5
−5
0
5
x
y
 
 
 
 
−5
0
5
−5
0
5
u
v

 
Section 9.3 
479 
 
At (75,50):  The Jacobian matrix  
0
300
100
0
−


= 



J
  has characteristic equation  
 
2
30000
0
λ +
=
 and pure imaginary eigenvalues 
1
2
,
100
3.
i
λ λ = ±
  Hence (75,50)  is a 
 
stable center of the linearization  
300 ,
100 .
u
v v
u
′
′
= −
=
 See the right-hand figure at the 
 
bottom of the preceding page. 
 
2. 
Upon separation of variables, the equation  
 
 
 
 
 
150
2
( 150
2 )
200
4
(200
4 )
dy
y
xy
y
x
dx
x
xy
x
y
−
+
−
+
=
=
−
−
 
 
yields 
 
 
 
 
200
150
4
2
,
200ln
4
2
150ln
dy
dx
y
x
y
y
x
x
C




−
=
−








−
=
−
+
⌠
⌠

⌡
⌡
 
 
 
assuming that  ,
0.
x y >
 
 
3. 
The effect of using the insecticide is to replace  b  by  b + f  and  a  by  a - f  in the 
predator-prey equations, while leaving  p  and  q  unchanged.  Hence the new harmful 
population is  (b + f)/q  >  b/q =  xE,  and the new benign population is 
 
(a - f)/p  <  a/p  =  yE. 
 
Problems 4–7 deal with the competition system 
 
 
 
 
2
2
60
4
3
,
42
2
3
x
x
x
xy
y
y
y
xy
′
′
=
−
−
=
−
−
 
 
 
(2) 
 
that has Jacobian matrix  
60
8
3
3
.
3
42
4
3
x
y
x
y
y
x
−
−
−


= 

−
−
−


J
 
 
4. 
At (0,0)  the Jacobian matrix  
60
0
0
42


= 



J
  has characteristic equation  
 
(60
)(42
)
0
λ
λ
−
−
=
 and positive real eigenvalues 
1
2
42,
60.
λ
λ
=
=
  Hence(0,0)  is a 
 
nodal source of the linearized system  
60 ,
42 .
x
x
y
y
′
′
=
=
 
 
5. 
At (0,21)  the Jacobian matrix  
3
0
63
42
−


= 

−
−


J
  has characteristic equation  
 
( 3
)( 42
)
0
λ
λ
−−
−
−
=
 and negative real eigenvalues 
1
2
42,
3.
λ
λ
= −
= −
  Hence (0,21)  is 
 
a nodal sink of the linearized system  
3 ,
63
42
u
u v
u
v
′
′
= −
= −
−
. 
 

480 
Chapter 9 
 
 
 
 
−5
0
5
−5
0
5
u
v
6. 
At (15,0)  the Jacobian matrix  
60
45
0
3
−
−


= 

−


J
  has characteristic equation  
 
( 60
)( 3
)
0
λ
λ
−
−
−−
=
 and negative real eigenvalues 
1
2
60,
3.
λ
λ
= −
= −
  Hence (15,0)  is 
 
a nodal sink of the linearized system  
60
45 ,
3
u
u
v v
v
′
′
= −
−
= −
. 
 
7. 
At (6,12)  the Jacobian matrix  
24
18
36
24
−
−


= 

−
−


J
  has characteristic equation  
 
2
( 24
)
( 36)( 18)
0
λ
−
−
−−
−
=
 and real eigenvalues  
1
0,
24
18 2
λ
+
>
= −
 
 
2
0
24
18 2
λ
−
<
= −
  with different signs.  Hence (6,12)  is a saddle point of the 
 
linearized system  
24
18 ,
u
u
v
′ = −
−
36
24
v
u
v
′ = −
−
.  The figure on the left below 
 
illustrates this saddle point.  The figure on the right shows all four critical points of the 
 
system. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Problems 8–10 deal with the competition system 
 
 
 
 
2
2
60
3
4
,
42
3
2
x
x
x
xy
y
y
y
xy
′
′
=
−
−
=
−
−
 
 
 
(3) 
 
that has Jacobian matrix  
60
6
4
4
.
2
42
6
2
x
y
x
y
y
x
−
−
−


= 

−
−
−


J
 
 
8. 
At (0,14)  the Jacobian matrix  
4
0
28
42


= 

−
−


J
  has characteristic equation  
 
(4
)( 42
)
0
λ
λ
−
−
−
=
 and real eigenvalues  
1
42,
λ = −
 
2
4
λ =
  with different signs.  Hence 
 
(0,14)  is a saddle point of the linearized system  
4 ,
28
42
u
u v
u
v
′
′
=
= −
−
. 
 
 
 
 
0
5
10
15
20
0
5
10
15
20
x
y
(0,21) 
(6,12) 
(15,0) 

 
Section 9.3 
481 
 
 
 
 
−5
0
5
−5
0
5
u
v
 
 
 
 
0
5
10
15
20
0
5
10
15
20
x
y
(0,14) 
(12,6) 
(20,0) 
9. 
At (20,0)  the Jacobian matrix  
60
80
0
2
−
−


= 



J
  has characteristic equation  
 
( 60
)(2
)
0
λ
λ
−
−
−
=
 and real eigenvalues  
1
60,
λ = −
 
2
2
λ =
  with different signs.  Hence 
 
(20,0)  is a saddle point of the linearized system  
60
80 ,
2
u
u
v v
v
′
′
= −
−
=
. 
 
10. 
At (12,6)  the Jacobian matrix  
36
48
12
18
−
−


= 

−
−


J
  has characteristic equation  
 
( 36
)( 18
)
( 12)( 48)
0
λ
λ
−
−
−
−
−−
−
=
 and negative real eigenvalues 
1
2
,
.
27
3 73
λ
λ
= −
±
  
 
Hence (12,6)  is a nodal sink of the linearized system  
36
48 ,
u
u
v
′ = −
−
 
12
18
v
u
v
′ = −
−
.  
 
The figure on the left below illustrates this sink.  The figure on the right shows all four 
 
critical points of the system. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Problems 11–13 deal with the predator-prey system 
 
 
 
 
 
2
5
,
2
x
x
x
xy
y
y
xy
′
′
=
−
−
= −
+
 
 
 
(4) 
 
that has Jacobian matrix  
5
2
.
2
x
y
x
y
x
−
−
−


= 

−+


J
 
 
11. 
At (0,0)  the Jacobian matrix  
5
0
0
2


= 

−


J
  has characteristic equation  
 
(5
)( 2
)
0
λ
λ
−
−−
=
 and real eigenvalues  
1
2,
λ
−
=
 
2
5
λ =
  with different signs.  Hence 
 
(0,0)  is a saddle point of the linearized system  
5 ,
2 .
x
x
y
y
′
′
=
= −
 

482 
Chapter 9 
12. 
At (5,0) the Jacobian matrix  
5
5
0
3
−
−


= 



J
  has characteristic equation  
 
( 5
)(3
)
0
λ
λ
−−
−
=
 and real eigenvalues  
1
5,
λ
−
=
 
2
3
λ =
  with different signs.  Hence 
 
(5,0) is a saddle point of the linearized system  
5
5 ,
3
u
u
v v
v
′
′
= −
−
=
. 
 
13. 
At (2,3)  the Jacobian matrix  
2
2
3
0
−
−


= 



J
  has characteristic equation  
 
2
( 2
)(
)
(3)( 2)
2
6
0
λ
λ
λ
λ
−−
−
−
−
=
+
+
=
 and complex conjugate eigenvalues  
 
1
2
,
1
5
i
λ
λ
= −±
  with negative real part.  Hence (2,3)  is a spiral sink of the 
 
linearized system  
2
2 ,
3
u
u
v v
u
′
′
= −
−
=
 (illustrated below). 
 
 
 
 
−5
0
5
−5
0
5
u
v
 
 
 
Problems 14–17 deal with the predator-prey system 
 
 
 
 
 
2
2
2
,
4
x
x
x
xy
y
y
y
xy
′
′
=
−
−
=
−
+
 
 
 
(5) 
 
that has Jacobian matrix  
2
2
.
2
4
x
y
x
y
y
x
−
−
−


= 

−
+


J
 
 
14. 
At (0,0)  the Jacobian matrix  
2
0
0
4
−


= 

−


J
  has characteristic equation  
 
( 2
)( 4
)
0
λ
λ
−−
−−
=
 and negative real eigenvalues  
1
4,
λ
−
=
 
2
2.
λ
−
=
 Hence (0,0)  is a 
 
nodal sink of the linearized system  
2 ,
4 .
x
x
y
y
′
′
= −
= −
 
 

 
Section 9.3 
483 
15. 
At (0,4)  the Jacobian matrix  
6
0
4
4
−


= 



J
  has characteristic equation  
 
( 6
)(4
)
0
λ
λ
−−
−
=
 and real eigenvalues  
1
6,
λ
−
=
 
2
4
λ =
  with different signs.  Hence 
 
(0,4)  is a saddle point of the linearized system  
,
4
4
6
u
u v
u
v
′
′
= −
=
+
. 
 
16. 
At (2,0)  the Jacobian matrix  
2
2
0
2
−


= 

−


J
  has characteristic equation  
 
(2
)( 2
)
0
λ
λ
−
−−
=
 and real eigenvalues  
1
2,
λ
−
=
 
2
2
λ =
 with different signs.  Hence 
 
(2,0)  is a saddle point of the linearized system  
2
2 ,
2
u
u
v v
v
′
′
=
−
= −
. 
 
17. 
At (3,1)  the Jacobian matrix  
3
3
1
1
−


= 



J
  has characteristic equation  
 
2
(3
)(1
)
(1)( 3)
4
6
0
λ
λ
λ
λ
−
−
−
−
=
−
+
=
 and complex conjugate eigenvalues  
 
1
2
,
2
2
i
λ
λ
=
±
  with positive real part.  Hence (3,1)  is a spiral source of the 
 
linearized system  
3
3 ,
u
u
v
′ =
−
  v
u
v
′ =
+
 (illustrated below). 
 
 
 
 
−5
0
5
−5
0
5
u
v
 
 
 
Problems 18 and 19 deal with the predator-prey system 
 
 
 
 
 
2
,
5
x
x
xy
y
y
xy
′
′
=
−
= −
+
 
 
 
 
(7) 
 
that has Jacobian matrix  
2
.
5
y
x
y
x
−
−


= 

−+


J
 
 

484 
Chapter 9 
18. 
At (0,0)  the Jacobian matrix  
2
0
0
5


= 

−


J
  has characteristic equation  
 
(2
)( 5
)
0
λ
λ
−
−−
=
 and real eigenvalues  
1
5,
λ
−
=
2
2
λ =
  with different signs.  Hence 
 
(0,0)  is a saddle point of the linearized system  
2 ,
5 .
x
x
y
y
′
′
=
= −
 
 
19. 
At (5,2)  the Jacobian matrix  
0
5
2
0
−


= 



J
  has characteristic equation  
 
2
(
)(
)
(2)( 5)
10
0
λ
λ
λ
−
−
−
−
=
+
=
 and pure imaginary roots 
10,
i
λ = ±
 so the origin 
 
is a stable center for the linearized system  
5 ,
2
u
v v
u
′
′
= −
=
.  This is the indeterminate 
 
case, but the figure below suggests that (5,2)  is also a stable center for the 
 
original system in (7). 
 
 
 
 
−5
0
5
−5
0
5
u
v
 
 
 
Problems 20–22 deal with the predator-prey system 
 
 
 
 
2
3
,
5
x
x
x
xy
y
y
xy
′
′
= −
+
−
= −
+
 
 
 
 
(8) 
 
that has Jacobian matrix  
3
2
.
5
x
y
x
y
x
−+
−
−


= 

−+


J
 
 
20. 
At (0,0)  the Jacobian matrix  
3
0
0
5
−


= 

−


J
  has characteristic equation  
 
( 3
)( 5
)
0
λ
λ
−−
−−
=
 and negative real eigenvalues 
1
5,
λ
−
=
2
3
λ
−
=
.  Hence (0,0)  is a 
 
nodal sink of the linearized system  
3 ,
5 .
x
x
y
y
′
′
= −
= −
 

 
Section 9.3 
485 
21. 
At (3,0) the Jacobian matrix  
3
3
0
2
−


= 

−


J
  has characteristic equation  
 
(3
)( 2
)
0
λ
λ
−
−−
=
 and real eigenvalues  
1
2,
λ
−
=
 
2
3
λ =
 with different signs.  Hence 
 
(3,0) is a saddle point of the linearized system  
3
3 ,
2
u
u
v v
v
′
′
=
−
= −
. 
 
22. 
At (5,2)  the Jacobian matrix  
5
5
2
0
−


= 



J
  has characteristic equation  
 
2
(5
)(
)
(2)( 5)
5
10
0
λ
λ
λ
λ
−
−
−
−
=
−
+
=
 and complex conjugate eigenvalues  
 
(
)
1
1
2
2
,
5
15
i
λ λ
=
±
  with positive real part.  Hence (5,2)  is a spiral source of the 
 
linearized system  
5
5 ,
2
u
u
v v
u
′
′
=
−
=
 (illustrated below). 
 
 
 
 
−5
0
5
−5
0
5
u
v
 
 
 
Problems 23–25 deal with the predator-prey system 
 
 
 
 
2
7
,
5
x
x
x
xy
y
y
xy
′
′
=
−
−
= −
+
 
 
 
 
(9) 
 
that has Jacobian matrix  
7
2
.
5
x
y
x
y
x
−
−
−


= 

−+


J
 
 
23. 
At (0,0)  the Jacobian matrix  
7
0
0
5


= 

−


J
  has characteristic equation  
 
(7
)( 5
)
0
λ
λ
−
−−
=
 and real eigenvalues  
1
5,
λ
−
=
 
2
7
λ =
 with different signs.  Hence 
 
(0,0)  is a saddle point of the linearized system  
7 ,
5 .
x
x
y
y
′
′
=
= −
 
 

486 
Chapter 9 
24. 
At (7,0)  the Jacobian matrix  
7
7
0
2
−
−


= 



J
  has characteristic equation  
 
( 7
)(2
)
0
λ
λ
−−
−
=
 and real eigenvalues  
1
7,
λ
−
=
 
2
2
λ =
 with different signs.  Hence 
 
(7,0)  is a saddle point of the linearized system  
7
7 ,
2
u
u
v v
v
′
′
= −
−
=
. 
 
25. 
At (5,2)  the Jacobian matrix  
5
5
2
0
−
−


= 



J
  has characteristic equation  
 
2
( 5
)(
)
(2)( 5)
5
10
0
λ
λ
λ
λ
−−
−
−
−
=
+
+
=
 and complex conjugate eigenvalues  
 
(
)
1
1
2
2
,
5
15
i
λ λ
=
−±
  with negative real part.  Hence (5,2)  is a spiral sink of the 
 
linearized system  
5
5 ,
2
u
u
v v
u
′
′
= −
−
=
 (illustrated below). 
 
 
 
 
−5
0
5
−5
0
5
u
v
 
 
 
26. 
2
3
y
x
y
x
−
−


= 

−
−


J
 
 
At (0,0) :  The Jacobian matrix  
2
0
0
3


= 



J
  has characteristic equation  
2
5
6
0
λ
λ
−
+
=
 
 
and positive real eigenvalues 
1
2
2,
3
λ
λ
=
=
.  Hence (0,0)  is a nodal source. 
At (3,2) :  The Jacobian matrix  
0
3
2
0
−


= 

−


J
  has characteristic equation 
2
6
0
λ −
=
  
and real eigenvalues 
1
2
,
6
λ λ = ±
 with different signs.  Hence (3,2)  is a saddle point.   
If the initial point  
0
0
(
,
)
x
y
 lies above the southwest-northeast separatrix through (3,2) ,  

 
Section 9.3 
487 
 
 
 
 
0
5
0
5
x
y
(3,2) 
 
 
 
 
0
5
0
5
x
y
(3,2) 
(0,0) 
then  
( )
(
)
( ),
(0,
)
x t
y t
→
∞ as  
.
t →∞  But if  
0
0
(
,
)
x
y
 lies below this separatrix, then  
( )
(
)
( ),
( ,0)
x t
y t
→∞
 as  
.
t →∞ See the left-hand figure below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
27. 
2
4
2
3
y
x
y
x
−


= 

−


J
 
 
At (0,0) :  The Jacobian matrix  
4
0
0
3
−


= 

−


J
  has characteristic equation  
 
2
7
12
0
λ
λ
+
+
=
 and negative real eigenvalues 
1
2
4,
3
λ
λ
= −
= −.  Hence (0,0)  is a nodal 
 
sink. 
At (3,2) :  The Jacobian matrix  
0
6
2
0


= 



J
  has characteristic equation 
2
12
0
λ −
=
 and  
real eigenvalues 
1
2
,
2 3
λ λ = ±
  with different signs.  Hence (3,2)  is a saddle point.   
If the initial point  
0
0
(
,
)
x
y
 lies below the northwest-southeast separatrix through (3,2) , 
then 
( )
(
)
( ),
(0,0)
x t
y t
→
 as  
.
t →∞  But if  
0
0
(
,
)
x
y
 lies above this separatrix, then  
( )
(
)
( ),
( ,
)
x t
y t
→∞∞ as  
.
t →∞ See the right-hand figure above. 
 
28. 
2
16
2
4
y
x
y
x
−


= 

−
−


J
 
 
At (0,0) :  The Jacobian matrix  
16
0
0
4
−


= 



J
  has characteristic equation  
 
2
12
64
0
λ
λ
+
−
=
 and real eigenvalues 
1
2
16,
4
λ
λ
= −
=
 with opposite signs.  Hence 
 
(0,0)  is a saddle point. 

488 
Chapter 9 
At (4,8) :  The Jacobian matrix  
0
8
8
0


= 

−


J
  has characteristic equation 
2
64
0
λ +
=
 
and conjugate imaginary eigenvalues 
1
2
,
8i
λ λ = ±
.  This is the indeterminate case, but the 
figure in the answers section of the textbook indicates that (4,8)  is a stable center for the  
original nonlinear system.   
As  
,
t →∞  each solution point 
( )
(
)
( ),
x t
y t
 with nonzero initial conditions encircles the stable 
center (4,8)  periodically in a clockwise direction.  See the figure below. 
 
 
 
 
0
5
10
15
0
5
10
15
x
y
(4,8) 
(0,0) 
 
 
 
29. 
1
1
2
2
2
3
2
4
2
x
y
x
y
x
−
−
+
−


= 

−
−


J
 
 
At (0,0) :  The Jacobian matrix  
3
0
0
4


= 



J
  has characteristic equation  
 
2
7
12
0
λ
λ
−
+
=
 and positive real eigenvalues 
1
2
3,
4
λ
λ
=
=
.  Hence (0,0)  is a nodal 
 
source. 
 
At (3,0):  The Jacobian matrix  
3
2
3
0
2
−
−


= 

−


J
  has characteristic equation  
 
2
5
6
0
λ
λ
+
+
=
 and negative real eigenvalues 
1
2
3,
2
λ
λ
= −
= −.  Hence (3,0) is a nodal 
 
sink. 
At (2,2):  The Jacobian matrix  
2
1
4
0
−
−


= 

−


J
  has characteristic equation 
2
2
4
0
λ
λ
+
−
=
 and real eigenvalues 
1
2
3.2361,
1.2361
λ
λ
≈−
=
  with different signs.   
Hence (2,2) is a saddle point.   

 
Section 9.3 
489 
 
 
 
 
0
5
0
5
x
y
(0,0) 
(3,0) 
(2,2) 
 
 
 
 
0
5
10
0
5
10
x
y
(5,4) 
(0,0) 
(3,0) 
If the initial point  
0
0
(
,
)
x
y
 lies above the southwest-northeast separatrix through (2,2), 
then  
( )
(
)
( ),
(0,
)
x t
y t
→
∞ as  
.
t →∞  But if  
0
0
(
,
)
x
y
 lies below this separatrix, then  
( )
(
)
( ),
(3,0)
x t
y t
→
 as  
.
t →∞  See the left-hand figure below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
30. 
1
1
2
2
1
1
5
5
2
3
1
x
y
x
y
x
−
+
+


= 

−


J
 
 
At (0,0) :  The Jacobian matrix  
3
0
0
1


= 

−


J
  has characteristic equation  
 
2
2
3
0
λ
λ
−
−
=
 and real eigenvalues 
1
2
1,
3
λ
λ
= −
=
 of opposite sign.  Hence (0,0)  is a 
 
saddle point. 
 
At (3,0):  The Jacobian matrix  
3
2
3
0
2
−
−


= 

−


J
  has characteristic equation  
 
2
17
17
5
5
0
λ
λ
+
+
=
 and  negative real eigenvalues 
17
1
2
5
3,
λ
λ
= −
= −
.  Hence (3,0) is a 
 
nodal sink. 
At (5,4) :  The Jacobian matrix  
5
2
4
5
5
0
−


= 



J
  has characteristic equation 
2
5
2
0
λ
λ
+
−
=
 
and real eigenvalues 
1
2
5.3723,
0.3723
λ
λ
≈−
=
  with different signs.  Hence (5,4)  is a  
saddle point.   
If the initial point  
0
0
(
,
)
x
y
 lies above the northwest-southeast separatrix through (5,4) , 
then  
( )
(
)
( ),
( ,
)
x t
y t
→∞∞ as  
.
t →∞  But if  
0
0
(
,
)
x
y
 lies below this separatrix, then  
( )
(
)
( ),
(3,0)
x t
y t
→
 as  
.
t →∞  See the right-hand figure above. 
 

490 
Chapter 9 
31. 
1
1
4
4
2
3
2
x
y
x
y
x
−
−
+
−


= 

−


J
 
 
At (0,0) :  The Jacobian matrix  
3
0
0
2


= 

−


J
  has characteristic equation   
2
6
0
λ
λ
−
−
=
 
 
and real eigenvalues 
1
2
2,
3
λ
λ
= −
=
 of opposite sign.  Hence (0,0)  is a  saddle point. 
 
At (3,0):  The Jacobian matrix  
3
4
3
0
1
−
−


= 



J
  has characteristic equation  
 
2
2
3
0
λ
λ
+
−
=
 and real eigenvalues 
1
2
3,
1
λ
λ
= −
=   of opposite sign.  Hence (3,0) is a 
 
saddle point. 
At (2,4):  The Jacobian matrix  
1
2
2
4
0
−
−


= 



J
  has characteristic equation 
2
2
2
0
λ
λ
+
+
=
 and complex conjugate eigenvalues 
1
2
,
1
i
λ λ = −±  with negative real  
part.  Hence (2,4) is a spiral sink. 
As  
,
t →∞  each solution point 
( )
(
)
( ),
x t
y t
 with nonzero initial conditions approaches 
the spiral sink (2,4), as indicated by the direction arrows in the figure below. 
 
 
 
 
0
5
0
5
x
y
(0,0) 
(3,0) 
(2,4) 
 
 
32. 
6
30
4
4
6
60
x
y
x
y
x
y
−
+
+


= 

−
+


J
 
 
At (0,0) :  The Jacobian matrix  
30
0
0
60


= 



J
  has characteristic equation  
 
2
90
1800
0
λ
λ
−
+
=
 and positive real eigenvalues 
1
2
30,
60
λ
λ
=
=
.  Hence (0,0)  is a 
 
nodal source. 

 
Section 9.3 
491 
 
At (0,20) :  The Jacobian matrix  
50
0
80
60


= 

−


J
  has characteristic equation  
 
2
10
3000
0
λ
λ
+
−
=
 and real eigenvalues 
1
2
60,
50
λ
λ
= −
=
 of opposite sign.  Hence 
 
(0,20)  is a saddle point. 
 
At (10,0) :  The Jacobian matrix  
30
10
0
100
−


= 



J
  has characteristic equation  
 
2
70
3000
0
λ
λ
−
−
=
 and real eigenvalues 
1
2
30,
100
λ
λ
= −
=
 of opposite sign.  Hence 
 
(10,0)  is a saddle point. 
At (30,60) :  The Jacobian matrix  
90
30
240
180
−


= 

−


J
  has characteristic equation 
2
240
9000
0
λ
λ
+
+
=
 and negative real eigenvalues 
1
2
231.05,
38.95
λ
λ
≈−
= −
.  Hence  
(30,60)  is a nodal sink.   
As  
,
t →∞  each solution point 
( )
(
)
( ),
x t
y t
 with nonzero initial conditions approaches 
the nodal sink (30,60) .  See the figure below. 
 
 
 
 
0
25
50
0
25
50
75
100
x
y
(0,0) 
(10,0) 
(0,20) 
(30,60) 
 
 
 
33. 
6
30
4
4
6
60
x
y
x
y
x
y
−
+
+


= 

−
+


J
 
 
At (0,0) :  The Jacobian matrix  
30
0
0
80


= 



J
  has characteristic equation  
 
2
110
2400
0
λ
λ
−
+
=
 and positive real eigenvalues 
1
2
30,
80
λ
λ
=
=
.  Hence (0,0)  is a 
 
nodal source. 

492 
Chapter 9 
 
At (0,20) :  The Jacobian matrix  
10
0
40
80


= 

−


J
  has characteristic equation  
 
2
70
800
0
λ
λ
+
−
=
 and real eigenvalues 
1
2
80,
10
λ
λ
= −
=
 of opposite sign.  Hence 
 
(0,20)  is a saddle point. 
 
At (15,0) :  The Jacobian matrix  
30
15
0
110
−


= 



J
  has characteristic equation  
 
2
80
3300
0
λ
λ
−
−
=
 and real eigenvalues 
1
2
30,
110
λ
λ
= −
=
 of opposite sign.  Hence 
 
(15,0)  is a saddle point. 
At (4,22):  The Jacobian matrix  
8
4
44
88
−
−


= 

−


J
  has characteristic equation 
2
96
880
0
λ
λ
+
+
=
 and negative real eigenvalues 
1
2
85.736,
10.264
λ
λ
≈−
= −
.  Hence  
(4,22) is a nodal sink.   
As  
,
t →∞  each solution point 
( )
(
)
( ),
x t
y t
 with nonzero initial conditions approaches 
the nodal sink (4,22).  See the figure below. 
 
 
 
 
0
10
20
0
20
40
x
y
(0,0) 
(0,20) 
(15,0) 
(4,22) 
 
 
 
34. 
4
30
2
2
8
20
x
y
x
y
x
y
−
−
+
−


= 

−
+


J
 
 
At (0,0) :  The Jacobian matrix  
30
0
0
20


= 



J
  has characteristic equation  
 
2
50
600
0
λ
λ
−
+
=
 and positive real eigenvalues 
1
2
20,
30
λ
λ
=
=
.  Hence (0,0)  is a 
 
nodal source. 

 
Section 9.3 
493 
 
At (0,5):  The Jacobian matrix  
25
0
10
20


= 

−


J
  has characteristic equation  
 
2
5
500
0
λ
λ
−
−
=
 and real eigenvalues 
1
2
20,
25
λ
λ
= −
=
 of opposite sign.  Hence 
 
(0,5) is a saddle point. 
 
At (15,0) :  The Jacobian matrix  
30
15
0
50
−
−


= 



J
  has characteristic equation  
 
2
20
1500
0
λ
λ
−
−
=
 and real eigenvalues 
1
2
30,
50
λ
λ
= −
=
 of opposite sign.  Hence 
 
(15,0)  is a saddle point. 
At (
)
10,10 :  The Jacobian matrix  
20
10
20
40
−
−


= 

−


J
  has characteristic equation 
2
60
1000
0
λ
λ
+
+
=
 and complex conjugate eigenvalues 
1
2
,
30
10i
λ λ ≈−
±
 with  
negative real part.  Hence (
)
10,10  is a spiral sink.   
As  
,
t →∞  each solution point 
( )
(
)
( ),
x t
y t
 with nonzero initial conditions approaches 
the nodal sink (
)
10,10 .  See the figure below. 
 
 
 
 
0
10
20
0
10
20
x
y
(0,0) 
(0,5) 
(15,0) 
(10,10) 
 
 
 
SECTION 9.4 
 
NONLINEAR MECHANICAL SYSTEMS 
 
In each of Problems 1–4 we need only substitute the familiar power series for the exponential, 
sine, and cosine functions, and then discard all higher-order terms.  For each problem we give 
the corresponding linear system, the eigenvalues  λ1  and  λ2,  and the type of this critical point. 

494 
Chapter 9 
1. 
(
)
2
1
2
1
1
2
2
x
x
x
y
x
y
′ =
−
+
+
+
+
≈−
+

 
 
(
)
3
1
6
4
4
y
x
y
y
x
y
′ = −
−
−
+
≈−
−

 
The coefficient matrix  
1
2
1
4
−


= 

−
−


A
  has negative eigenvalues λ1 = -2  and   
λ2  = -3  indicating a stable nodal sink as illustrated in the figure below.  Alternatively,  
we can calculate the Jacobian matrix 
 
     
1
2
2
( , )
,
so
(0,0)
.
1
4
1
4cos
xe
x y
x
−


−


=
=




−
−
−
−




J
J
 
 
 
 
 
−10
0
10
−5
0
5
x
y
 
 
2. 
(
) (
)
3
3
1
1
6
6
2
2
x
x
x
y
y
x
y
′ =
−
+
+
−
+
≈
+


 
 
(
)
(
)
3
3
1
1
6
6
2
2
y
x
x
y
y
x
y
′ =
−
+
+
−
+
≈
+


 
The coefficient matrix  
2
1
1
2


= 



A
 has positive eigenvalues  λ1 = 1  and  λ2 = 3  
indicating an unstable nodal source.  Alternatively, we can calculate the Jacobian matrix 
 
     
2cos
cos
2
1
( , )
,
so
(0,0)
.
cos
2cos
1
2
x
y
x y
x
y




=
=








J
J
 
 
 
3. 
(
)
2
1
2
1
2
1
2
x
x
x
y
x
y
′ =
+
+
+
+
−
≈
+

 
 
(
)
2
1
2
8
1
1
8
y
x
y
y
x
y
′ =
+
+
+
+
−
≈
+

 

 
Section 9.4 
495 
 
 
 
 
−3
0
3
−3
0
3
x
y
The coefficient matrix  
1
2
8
1


= 



A
 has real eigenvalues  λ1 = -3  and  λ2 = 5  of 
opposite sign, indicating an unstable saddle point as illustrated in the left-hand figure  
below.  Alternatively, we can calculate the Jacobian matrix 
 
     
1
2
2
( , )
,
so
(0,0)
.
8
1
8
x
y
e
x y
e




=
=








J
J
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
4. 
The linear system is   x′  =   x - 2y,  y′  =  4x - 3y  because 
 
 
 
 
sin x cos y  =  (x - x3/3! + ⋅⋅⋅)(1 - y2/2! + ⋅⋅⋅)  =  
,
x +  
 
and  cos sin
x
y
y
≈
 similarly.  The coefficient matrix  
1
2
4
3
−


= 

−


A
  has complex 
conjugate eigenvalues  λ1,λ2 = -1 ± 2 i  with negative real part, indicating a stable  
spiral point as illustrated in the right-hand figure above.  Alternatively, we can calculate 
the Jacobian matrix 
 
cos cos
sin sin
2
1
2
( , )
,
so
(0,0)
.
3sin sin
4
3cos cos
4
3
x
y
x
y
x y
x
y
x
y
−
−
−




=
=




+
−
−




J
J
 
 
 
5. 
The critical points are of the form  (0, nπ)  where  n  is an integer, so we substitute   
 
,
x
u
=
  
.
y
v
nπ
=
+
  Then 
 
 
sin(
)
(cos
)
( 1)
.
n
u
x
u
v
n
u
n
v
u
v
π
π
′
′
=
= −
+
+
= −
+
= −
+ −
 
 
 
 
 
−4
0
4
−4
0
4
x
y

496 
Chapter 9 
 
Hence the linearized system at  (0, nπ)  is 
 
 
 
 
 
u′  =  -u ± v,   v′  =  2u 
 
where we take the plus sign if  n  is even, the minus sign if  n  is odd.  If  n  is even the 
eigenvalues are  λ1 = 1  and  λ2 = -2,  so  (0, nπ)  is an unstable saddle point.  If  n  is odd  
 
the eigenvalues are  λ1,λ2  =  (-1 ± i
7 )/2,  so  (0, nπ)  is a stable spiral point. 
 
 
 
 
−5
0
5
−3pi
−2pi
−pi
0
pi
2pi
3pi
x
y
 
 
Alternatively, we can start by calculating the Jacobian matrix 
1
cos
( , )
2
0
y
x y
−


= 



J
. 
 
At (0,
),
even
n
n
π
:  The Jacobian matrix  
1
1
2
0
−


= 



J
  has characteristic equation  
 
2
2
0
λ
λ
+
−
=
 and real eigenvalues 
1
2
2,
1
λ
λ
= −
=  of opposite sign.  Hence (0,
)
nπ  is a  
 
saddle point if  n  is even, as we see in the figure above. 
 
 
At (0,
),
odd
n
n
π
:  The Jacobian matrix  
1
1
2
0
−
−


= 



J
  has characteristic equation  
 
2
2
0
λ
λ
+
+
=
 and complex conjugate eigenvalues 
1
1
2
2
,
( 1
7)
i
λ λ =
−±
 with negative 
 
real.  Hence (0,
)
nπ  is a spiral sink if  n  is odd, as indicated in the figure. 
 
 
6. 
The critical points are of the form  (n, 0)  where  n  is an integer, so we substitute 
 
,
.
x
u
n
y
v
=
+
=
  Then 
 
 
sin (
)
cos
sin
( 1)
,
n
v
y
u
n
v
n
u
u
v
π
π
π
π
′
′
=
=
+
−
=
≈−
−
 
 
Hence the linearized system at  (n, 0)  is 

 
Section 9.4 
497 
 
 
 
 
 
u′  =    v,     v′  =  ±πu - v 
 
with coefficient matrix  
0
1
1
π


= 

±
−


A
  where we take the plus sign if  n  is even, the 
minus sign if  n  is odd.  The characteristic equation   
 
 
 
 
 
 
λ2 + λ - π  =  0 
 
 
has one positive and one negative root, so  (n, 0)  is an unstable saddle point if  n  is even. 
The equation   
 
 
 
 
 
λ2 + λ + π  =  0   
 
 
has complex conjugate roots with negative real part, so  (n, 0)  is a stable spiral point if  n  
is odd. 
 
 
 
 
−3
0
3
−4
0
4
x
y
 
 
Alternatively, we can start by calculating the Jacobian matrix  
0
1
( , )
cos
1
x y
x
π
π


= 

−


J
. 
 
At ( ,0),
even
n
n
:  The Jacobian matrix  
0
1
1
π


= 

−


J
  has characteristic equation  
 
2
0
λ
λ
π
+
−
=
 and real eigenvalues 
1
2
2.3416,
1.3416
λ
λ
≈−
≈
 of opposite sign.  Hence 
 
( ,0)
n
 is a saddle point if  n  is even, as we see in the figure above. 
 
 
At ( ,0),
odd
n
n
:  The Jacobian matrix  
0
1
1
π


= 

−
−


J
  has characteristic equation  
 
2
0
λ
λ
π
+
+
=
 and complex conjugate eigenvalues 
1
2
,
0.5 1.7005i
λ λ ≈−
±
 with negative 
 
real.  Hence ( ,0)
n
 is a spiral sink if  n  is odd, as we see in the figure. 

498 
Chapter 9 
7. 
The critical points are of the form  (nπ, nπ)  where  n  is an integer,  so we substitute   
 
,
.
x
u
n
y
v
n
π
π
=
+
=
+
  Then 
 
 
(
)
2
1
2
1
1
1
(
)
(
)
u v
u
x
e
u
v
u
v
u
v
−
′
′
=
=
−
=
−
+
−
+
−
+
≈−
+

, 
 
 
(
)
2sin
2sin cos
2( 1)
.
n
v
y
u
n
u
n
u
π
π
′
′
=
=
+
=
≈
−
 
   
Hence the linearized system at  (nπ, nπ)  is 
 
 
 
 
 
u′  =  -u + v,     v′  =  ±2u 
 
and has coefficient matrix  
1
1 ,
2
0
−


= 

±


A
  where we take the plus sign if  n  is even, the 
minus sign if  n  is odd.  With  n  even, The characteristic equation  
2
2
0
λ
λ
+
−
=
  has 
real roots λ1 = 1   and  λ2 = -2  of opposite sign,  so (nπ, nπ)  is an unstable saddle point.  
With  n  odd,  the characteristic equation  
2
2
0
λ
λ
+
+
=
  has complex conjugate 
eigenvalues are  λ1, λ2  =  (-1 ± i
7 )/2  with negative real part,  so  (nπ, nπ)  is a stable  
 
spiral point. 
 
 
 
 
−3pi
−2pi
−pi
0
pi
2pi
3pi
−3pi
−2pi
−pi
0
pi
2pi
3pi
x
y
 
 
 
Alternatively, we can start by calculating the Jacobian matrix  ( , )
2cos
0
x y
x y
e
e
x y
x
−
−


−
= 



J
. 
 
 
At (
,
),
even
n
n
n
π
π
:  The Jacobian matrix  
1
1
2
0
−


= 



J
  has characteristic equation  
 
2
2
0
λ
λ
+
−
=
 and real eigenvalues 
1
2
2,
1
λ
λ
= −
=  of opposite sign.  Hence (
,
)
n
n
π
π  is 
 
a saddle point if  n  is even, as we see in the figure above. 

 
Section 9.4 
499 
 
At (
,
),
odd
n
n
n
π
π
:  The Jacobian matrix  
1
1
2
0
−


= 

−


J
  has characteristic equation  
 
2
2
0
λ
λ
+
+
=
 and complex conjugate eigenvalues 
1
2
,
0.5
1.3229i
λ λ ≈−
±
 with negative 
 
real.  Hence (
,
)
n
n
π
π  is a spiral sink if  n  is odd, as we see in the figure. 
 
8. 
The critical points are of the form  (nπ, 0)  where  n  is an integer, so we substitute   
 
,
.
x
u
n
y
v
π
=
+
=
  Then 
 
 
3sin(
)
3sin cos
3( 1)
,
n
u
x
u
n
v
u
n
v
u
v
π
π
′
′
=
=
+
+
=
+
≈
−
+
 
 
 
sin(
)
2
sin cos
2
( 1)
2 ,
n
v
y
u
n
v
u
n
v
u
v
π
π
′
′
=
=
+
+
=
+
≈
−
+
 
   
Hence the linearized system at  (nπ, 0) is 
 
 
 
 
 
u′  =  ±3u + v,      v′  =  ±u + 2v 
 
with coefficient matrix  
3
1
1
2
±


= 

±


A
,  where we take the plus signs if  n  is even, the 
minus signs if  n  is odd.  If  n  is even then the characteristic equation  
2
5
5
0
λ
λ
−
+
=
 
has roots  λ1,λ2 = (5 ± 5 )/2  that are both positive, so  (nπ, 0)  is an unstable nodal 
source.  If n  is odd then the characteristic equation  
2
5
5
0
λ
λ
−
+
=
 has real roots   
 
λ1,λ2 = (-1 ±
21 )/2  with opposite signs, so  (nπ, 0)  is an unstable saddle point. 
 
 
 
 
−3pi
−2pi
−pi
0
pi
2pi
3pi
−4
0
4
x
y
 
 
 
Alternatively, we can start by calculating the Jacobian matrix  
3cos
1
( , )
cos
2
x
x y
x


= 



J
. 

500 
Chapter 9 
 
At (
,0),
even
n
n
π
:  The Jacobian matrix  
3
1
1
2


= 



J
  has characteristic equation  
 
2
5
5
0
λ
λ
−
+
=
 and positive real eigenvalues 
1
2
1.3812,
2.6180
λ
λ
≈
=
.  Hence (
,0)
nπ
 is 
 
a nodal source if  n  is even, as we see in the figure on the preceding page. 
 
 
At (
,0),
odd
n
n
π
:  The Jacobian matrix  
3
1
1
2
−


= 

−


J
  has characteristic equation  
 
2
5
0
λ
λ
+
−
=
 and real eigenvalues 
1
2
2.7913,
1.7913
λ
λ
≈−
=
 of opposite sign.  Hence 
 
(
,0)
nπ
 is a saddle point if  n  is odd, as we see in the figure. 
 
 
As preparation for Problems 9–11, we first calculate the Jacobian matrix 
 
 
 
 
2
0
1
( , )
cos
x y
x
c
ω


= 

−
−


J
  
of the damped pendulum system in (34) in the text.  At the critical point (
,0)
nπ
we have 
 
 
2
2
0
1
0
1
(
,0)
,
cos
n
n
c
c
π
ω
π
ω




=
=




−
−
±
−




J
 
where we take the plus sign if  n  is odd, the minus sign if  n  is even. 
 
9. 
If  n  is odd then the characteristic equation  
2
2
0
c
λ
λ
ω
+
−
=
  has real roots 
  
 
 
 
2
2
1
2
4
,
2
c
c
ω
λ λ
−±
+
=
 
 
with opposite signs, so  (nπ, 0)  is an unstable saddle point.   
 
10. 
If  n  is even then the characteristic equation  
2
2
0
c
λ
λ
ω
+
+
=
  has roots 
 
 
 
 
2
2
1
2
4
,
2
c
c
ω
λ λ
−±
−
=
. 
 
If  
2
2
4
c
ω
>
  then  λ1  and  λ2  are both negative so  (nπ, 0)  is a stable nodal sink.  
 
11. 
If  n  is even and  
2
2
4
c
ω
<
  then the two eigenvalues 
 
 
 
2
2
2
2
1
2
4
,
4
2
2
2
c
c
c
i
c
ω
λ λ
ω
−±
−
=
= −
±
−
 
 
are complex conjugates with negative real part, so  (nπ, 0)  is a stable spiral point. 
 

 
Section 9.4 
501 
 
Problems 12–16 call for us to find and classify the critical points of the first order-system 
,
( , )
x
y
y
f x y
′
′
=
= −
  that corresponds to the given equation  
( ,
)
0.
x
f x x
′′
′
+
=
  After finding 
the critical points  ( ,0)
x
  where  
( ,0)
0,
f x
=
 we first calculate the Jacobian matrix  ( , ).
x y
J
   
 
12. 
2
0
1
( , )
15
20
0
x y
x


= 

−


J
. 
 
At (0,0) :   The Jacobian matrix  
0
1
20
0


= 

−


J
  has characteristic equation  
 
2
20
0
λ +
=
 and pure imaginary eigenvalues 
1
2
,
20
i
λ λ = ±
 consistent with the stable 
 
center we see at (0,0) in Fig. 9.4.4 in the textbook. 
 
At ( 2,0) :
±
  The Jacobian matrix  
0
1
40
0


= 



J
  has characteristic equation  
 
2
40
0
λ −
=
 and real eigenvalues 
1
2
,
40
λ λ = ±
 of opposite sign, consistent with the 
 
saddle  points we see at ( 2,0)
±
 in Fig. 9.4.4. 
 
13. 
2
0
1
( , )
15
20
2
x y
x


= 

−
−


J
. 
 
At (0,0) :   The Jacobian matrix  
0
1
20
2


= 

−
−


J
  has characteristic equation  
 
2
2
20
0
λ
λ
+
+
=
 and complex conjugate eigenvalues 
1
2
,
1
19
i
λ λ = −±
 consistent with 
 
the spiral node we see at (0,0) in Fig. 9.4.6 in the textbook. 
 
At ( 2,0) :
±
  The Jacobian matrix  
0
1
40
2


= 

−


J
  has characteristic equation  
 
2
2
40
0
λ
λ
+
−
=
 and real eigenvalues 
1
2
,
1
41
λ λ = −±
 of opposite sign, consistent with 
 
the saddle points we see at ( 2,0)
±
 in Fig. 9.4.6. 
 
14. 
2
0
1
( , )
8
6
0
x y
x


= 

−


J
. 
 
At (0,0) :   The Jacobian matrix  
0
1
8
0


= 



J
  has characteristic equation   
2
8
0
λ −
=
 and 
 
real eigenvalues 
1
2
,
8
λ λ = ±
 of opposite sign, consistent with the saddle point we see at 
 
(0,0) in Fig. 9.4.12 in the textbook. 
 
At ( 2,0) :
±
  The Jacobian matrix  
0
1
16
0


= 

−


J
  has characteristic equation  
 
2
16
0
λ +
=
 and pure imaginary eigenvalues 
1
2
,
4 ,i
λ λ = ±
 consistent with the stable 
 
centers we see at ( 2,0)
±
 in Fig. 9.4.12. 

502 
Chapter 9 
 
15. 
0
1
( , )
2
4
0
x y
x


= 

−


J
. 
 
At (0,0) :   The Jacobian matrix  
0
1
4
0


= 

−


J
  has characteristic equation  
 
2
4
0
λ +
=
 and pure imaginary eigenvalues 
1
2
,
2 ,i
λ λ = ±
 consistent with the stable center 
 
we see at (0,0) in Fig. 9.4.13 in the textbook. 
 
At (4,0) :  The Jacobian matrix  
0
1
4
0


= 



J
  has characteristic equation 
2
4
0
λ −
=
 and 
 
real eigenvalues 
1
2
,
2
λ λ = ±  of opposite sign, consistent with the saddle point we see at 
 
(4,0)  in Fig. 9.4.13. 
 
 
16. 
2
4
0
1
( , )
4
15
5
0
x y
x
x


= 

−+
−


J
. 
 
At (0,0) :   The Jacobian matrix  
0
1
4
0


= 

−


J
  has characteristic equation  
 
2
4
0
λ +
=
 and pure imaginary eigenvalues 
1
2
,
2 ,i
λ λ = ±
 consistent with the stable center 
 
we see at (0,0) in Fig. 9.4.14 in the textbook. 
 
At ( 1,0) :
±
  The Jacobian matrix  
0
1
6
0


= 



J
  has characteristic equation 
2
6
0
λ −
=
 and 
 
real eigenvalues 
1
2
,
6
λ λ = ±
 of opposite sign, consistent with the saddle points we see 
 
at ( 1,0)
±
 in Fig. 9.4.14. 
 
At ( 2,0) :
±
  The Jacobian matrix  
0
1
24
0


= 

−


J
  has characteristic equation  
 
2
24
0
λ +
=
 and pure imaginary eigenvalues 
1
2
,
24,
i
λ λ = ±
 consistent with the stable 
 
centers we see at ( 2,0)
±
 in Fig. 9.4.14. 
 
 
17. 
2
15
4
0
1
( , )
5
2
x y
x


= 

−−
−


J
. 
 
At (0,0) :   The Jacobian matrix  
0
1
5
2


= 

−
−


J
  has characteristic equation  
 
2
2
5
0
λ
λ
+
+
=
 and complex conjugate eigenvalues 
1
2
,
1
2i
λ λ = −±
 with negative real 
 
part, consistent with the spiral sink we see in the left-hand figure at the top of the next 
 
page. 
 
 

 
Section 9.4 
503 
−5
0
5
−10
−5
0
5
10
x
y
−5
0
5
−5
0
5
x
y
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
18. 
2
15
4
0
1
( , )
5
4
x y
x
y


= 

−+
−


J
. 
 
At (0,0) :   The Jacobian matrix  
0
1
5
0


= 

−


J
  has characteristic equation   
2
5
0
λ +
=
 and 
 
pure imaginary eigenvalues 
1
2
,
5.
i
λ λ = ±
  This corresponds to the indeterminate case of 
 
Theorem 2 in Section 9.3, but is not inconsistent with the spiral sink we see at the origin 
 
in the figure on the right above. 
 
At ( 2,0) :
±
  The Jacobian matrix  
0
1
10
0


= 



J
  has characteristic equation 
2
10
0
λ −
=
 
 
and real eigenvalues 
1
2
,
10,
λ λ = ±
 consistent with the saddle points we see at ( 2,0)
±
 in 
 
the right-hand figure above. 
 
−5
0
5
−10
−5
0
5
10
x
y
 

504 
Chapter 9 
19. 
2
15
4
0
1
( , )
5
4
x y
x
y


= 

−−
−


J
. 
 
At (0,0) :   The Jacobian matrix  
0
1
5
0


= 

−


J
  has characteristic equation   
2
5
0
λ +
=
 and 
 
pure imaginary eigenvalues 
1
2
,
5.
i
λ λ = ±
  This corresponds to the indeterminate case of 
 
Theorem 2 in Section 9.3, but is not inconsistent with the spiral sink we see in the figure 
 
at the bottom of the preceding page. 
 
20. 
1
2
0
1
( , )
cos
x y
x
y


= 

−
−


J
. 
 
At (
,0),
even
n
n
π
:  The Jacobian matrix  
0
1
1
0


= 

−


J
  has characteristic equation  
 
2
1
0
λ + =
 and pure imaginary eigenvalues 
1
2
,
.i
λ λ = ±  This corresponds to the 
 
indeterminate case of  Theorem 2 in Section 9.3, but is not inconsistent with the spiral 
 
sinks we see in the figure below. 
 
At (
,0),
odd
n
n
π
:  The Jacobian matrix  
0
1
1
0


= 



J
  has characteristic equation  
 
2
1
0
λ −=
 and real eigenvalues 
1
2
,
1
λ λ = ±  of opposite sign, consistent with the saddle 
 
points we see in the figure. 
 
 
−3pi
−2pi
−pi
0
pi
2pi
3pi
−4
0
4
x
y
 
 
The statements of Problems 21–26 in the text include their answers and rather fully outline their 
solutions, which therefore are omitted here. 
 

 
Section 10.1 
505 
CHAPTER 10 
  
LAPLACE TRANSFORM METHODS 
 
 
SECTION 10.1 
 
LAPLACE TRANSFORMS AND INVERSE TRANSFORMS 
 
The objectives of this section are especially clearcut.  They include familiarity with the definition 
of the Laplace transform  L{f(t)}  =  F(s)  that is given in Equation (1) in the textbook, the direct 
application of this definition to calculate Laplace transforms of simple functions (as in Examples 
1–3), and the use of known transforms (those listed in Figure 10.1.2) to find Laplace transforms 
and inverse transforms (as in Examples 4-6).  Perhaps students need to be told explicitly to 
memorize the transforms that are listed in the short table that appears in Figure 10.1.2. 
1. 
0
2
2
2
0
0
}
{
(
,
)
1
1
1
(
1)
st
u
u
t
e
t dt
u
st
du
s dt
ue du
u
e
s
s
s
∞
−
−∞
−∞
⌠

⌡
=
= −
= −




=
=
−
=






∫
L
 
 
2. 
We substitute  u  =  -st  in the tabulated integral 
 
(
)
2
2
2
2
u
u
u e du
e
u
u
C
=
−
+
+
∫
 
      
(or, alternatively, integrate by parts) and get 
 
{ }
2
2
2
2
3
3
0
0
2
2
2 .
st
st
t
t
t
t
e
t dt
e
s
s
s
s
∞
∞
−
−
=




=
=
−
+
+
=








∫
L
 
 
3. 
{
}
3
1
3
1
(
3)
0
0
3
t
st
t
s
t
e
e
e
e
dt
e
e
dt
s
∞
∞
+
−
+
−
−
=
=
=
−
∫
∫
L
   
 
4. 
With  a  =  -s  and  b  =  1  the tabulated integral 
 
2
2
cos
sin
cos
au
au a
bu
b
bu
e
bu du
e
C
a
b
+


=
+


+


∫
 
yields 
{
}
2
2
0
0
(
cos
sin )
cos
cos
1
1
st
st
t
e
s
t
t
s
t
e
t dt
s
s
∞
−
∞
−
=


−
+
=
=
=


+
+


∫
L
. 

506 
Chapter 10 
5. 
 {
}
{
}
(
)
(
)
(
1)
(
1)
1
1
1
2
2
2
0
0
2
sinh
1
1
1
1
2
1
1
1
t
t
st
t
t
s
t
s
t
t
e
e
e
e
e
dt
e
e
dt
s
s
s
∞
∞
−
−
−
−
−
−
+
=
−
=
−
=
−


=
−
=


−
+
−


∫
∫
L
L
 
6. 
{
}
(
)
1
2
2
2
0
0
2
2
0
sin
sin
1
cos2
1
1
cos2
2sin 2
1 1
2
4
2
4
st
st
st
st
t
t
e
t dt
e
t dt
s
t
t
s
e
e
s
s
s
s
∞
∞
−
−
∞
−
−
=
=
=
−
−
+






=
−
−
⋅
=
−






+
+






∫
∫
L
 
 
7. 
{
}
1
1
0
0
1
1
( )
s
st
st
e
f t
e
dt
e
s
s
−
−
−
−


=
=
−
=




∫
L
 
 
8. 
{
}
2
2
2
1
1
( )
st
s
s
st
e
e
e
f t
e
dt
s
s
−
−
−
−


−
=
=
−
=




∫
L
 
 
 
9. 
{
}
1
2
0
1
( )
s
s
st
e
se
f t
e
t dt
s
−
−
−
−
−
=
=
∫
L
 
 
10. 
{
}
1
1
2
2
2
0
0
1
1
1
1
( )
(1
)
s
st
st
t
e
f t
t e
dt
e
s
s
s
s
s
s
−
−
−




=
−
=
−
−
−
=
−
+








∫
L
 
 
11. 
{
}
3/ 2
2
3/ 2
2
(3/ 2)
1
3
3
3
2
t
t
s
s
s
s
π
Γ
+
=
+ ⋅
=
+
L
 
  
12. 
{
}
5/ 2
3
7 / 2
4
7/ 2
2
(7/ 2)
3!
45
24
3
4
3
4
8
t
t
s
s
s
s
π
Γ
−
=
⋅
−
⋅
=
−
L
 
 
13. 
{
}
3
2
1
2
2
3
t
t
e
s
s
−
=
−
−
L
 
 
14. 
{
}
3/ 2
10
5/ 2
5/ 2
(5/ 2)
1
3
1
10
4
10
t
t
e
s
s
s
s
π
−
Γ
+
=
+
=
+
+
+
L
 
 
15. 
{
}
2
1
1 + cosh 5
25
s
t
s
s
=
+
−
L
 
 

 
Section 10.1 
507 
16. 
{
}
2
2
2
2
2
sin 2  
 cos 2
4
4
4
s
s
t
t
s
s
s
+
+
=
+
=
+
+
+
L
 
 
17. 
{
}
{
}
2
2
1
1 1
cos 2
1+cos4
2
2
16
s
t
t
s
s


=
=
+


+


L
L
 
 
18. 
{
}
{
}
2
2
1
1
6
3
sin3 cos 3
sin6
2
2
36
36
t
t
t
s
s
=
=
⋅
=
+
+
L
L
 
 
19. 
(
)
{
}
{
}
3
2
3
2
3
4
2
3
4
1
1!
2!
3!
1
3
6
6
1
1
3
3
3
3
t
t
t
t
s
s
s
s
s
s
s
s
+
=
+
+
+
=
+ ⋅
+ ⋅
+
=
+
+
+
L
L
 
 
20. 
Integrating by parts with  u  =  t,  dv  =  e-(s-1)tdt,  we get 
 
{ }
{ }
(
1)
0
0
(
1)
2
0
0
1
1
1
.
1
1
1
(
1)
t
st
t
s
t
s
t
st
t
te
e
te dt
te
dt
te
e
e dt
t
s
s
s
s
∞
∞
−
−
−
∞
−
−
∞
−
=
=


−
=
+
=
=


−
−
−
−


∫
∫
∫
L
L
 
 
21. 
Integration by parts with  u  =  t  and  dv  =   e-stcos 2t dt  yields 
 
{
}
(
)
{
}
{
}
(
)
2
0
0
2
2
2
2
2
2
2
2
1
cos2
cos2
cos2
2sin2
4
1
cos2
2
sin2
4
1
4
4 .
4
4
4
4
st
st
t
t
te
t dt
e
s
t
t
dt
s
s
t
t
s
s
s
s
s
s
s
∞
∞
−
−
=
= −
−
+
+
= −
−
+




+


−
−
= −
+
=


+
+
+


+
∫
∫
L
L
L
 
 
22. 
{
}
{
}
2
2
1
1
1
sinh 3
cosh6
1
2
2
36
s
t
t
s
s


=
−
=
−


−


L
L
 
 
23. 
1
1
3
4
4
3
1
6
1
2
2 t
s
s
−
−




=
⋅
=








  
  
L
L
 
 
24. 
1
1
1/ 2
3/ 2
3/ 2
1
2
2
2
2
t
t
s
s
π
π
π
π
−
−




=
⋅
=
⋅
=










  
  
L
L
 
                       
25. 
3/ 2
1
1
3/ 2
5/ 2
5/ 2
3
1
2
2
1
2
1
2
(5/ 2)
2
8
1
1
(5/ 2)
3
t
t
s
s
s
s
π
π
−
−

Γ


−
=
−
⋅
=
−
⋅
=
−




Γ
⋅




  
  
L
L
 
 

508 
Chapter 10 
26. 
1
5
1
5
t
e
s
−
−

= =


+


  
L
 
 
27. 
1
1
4
3
1
3
3
4
4
t
e
s
s
−
−




=
⋅
=




−
−




  
  
L
L
 
 
28. 
1
1
1
2
2
2
3
1
1
2
1
3
3cos2
sin2
4
4
2
4
2
s
s
t
t
s
s
s
−
−
−
+






=
⋅
+
⋅
=
+






+
+
+






  
  
  
L
L
L
 
 
29. 
1
1
1
2
2
2
5
3
5
3
5
3
sin3
3cos3
9
3
9
9
3
s
s
t
t
s
s
s
−
−
−
−






=
⋅
−⋅
=
−






+
+
+






  
  
  
L
L
L
 
 
30. 
1
1
1
2
2
2
9
9
2
9 sinh 2
cosh2
4
2
4
4
2
s
s
t
t
s
s
s
−
−
−
+






= −
⋅
−
= −
−






−
−
−






  
  
  
L
L
L
 
 
31. 
1
1
1
2
2
2
10
3
3
5
3
10
10cosh5
sinh5
25
25
5
25
5
s
s
t
t
s
s
s
−
−
−
−






= −
⋅
⋅
= −






−
−
−






  
  
  
L
L
+
L
+
 
 
32. 
3
1
3
2
2 (
3)
2
( )
s
e
u t
u t
s
−
−

⋅
=
−
=




  
L
          [See Example 8 in the textbook.] 
 
33. 
{
}
1
1
1
sin
2
2
ikt
ikt
e
e
kt
i
i
s
ik
s
ik
−


−


=
=
−




−
+




L
L
 
 
2
2
2
1
2
(because
1)
2
(
)(
)
ik
k
i
i
s
ik
s
ik
s
k
=
⋅
=
= −
−
−
+
 
 
34. 
{
}
2
2
2
2
1
1
1
1
2
sinh
2
2
2
kt
kt
e
e
k
k
kt
s
k
s
k
s
k
s
k
−


−


=
=
−
=
⋅
=




−
+
−
−




L
L
 
 
35. 
Using the given tabulated integral with  a = –s  and  b = k,  we find that 
 
 
{
}
(
)
2
2
0
0
cos
cos
cos
sin
st
st
t
e
kt
e
kt dt
s
kt
k
kt
s
k
∞
∞
−
−
=


=
=
−
+


+


⌠
⌡
L
 
 
(
)
0
2
2
2
2
2
2
lim
cos
sin
(
1
0)
.
st
t
e
e
s
s
kt
k
kt
s
k
s
k
s
k
s
k
−
→∞


=
−
+
−
−⋅+
⋅
=


+
+
+


 
 
 
 

 
Section 10.1 
509 
36. 
Evidently the function  
2
( )
sin(
)
t
f t
e
=
  is of exponential order because it is bounded;  
we can simply take  c = 0  and  M = 1  in Eq. (23) of this section in the text.  However, 
 
its derivative 
2
2
( )
2
cos(
)
t
t
f t
t e
e
′
=
 is not bounded by any exponential function  
ct
e , 
because  
2
2
/
as
.
t
ct
t
ct
e
e
e
t
−
=
→∞
→∞ 
 
37. 
( )
f t   =  1 - ua(t)  =  1 - u(t - a)  so   
 
 
 
 
 
 
 
 
 
{
}
{ }
{
}
1
1
( )
1
( )
(1
).
as
as
a
e
f t
u t
s
e
s
s
−
−
−
=
−
=
−
=
−
L
L
L
 
 
For the graph of  f,  note that  
( )
1
( )
1 1
0.
f a
u a
= −
= −=
 
 
38. 
( )
(
)
(
),
f t
u t
a
u t
b
=
−
−
−
so   
 
 
 
 
 
 
 
 
 
{
}
{
}
{
}
(
)
1
( )
( )
( )
.
as
bs
as
bs
a
b
e
e
f t
u t
u t
s
e
e
s
s
−
−
−
−
−
=
−
=
−
=
−
L
L
L
 
 
For the graph of  f,  note that  
( )
(0)
(
)
1
0
1
f a
u
u a
b
=
−
−
= −
=  because 
,
a
b
<
 but 
 
( )
(
)
(0)
1 1
0.
f b
u b
a
u
=
−
−
= −=
 
 
39. 
Use of the geometric series gives 
{
}
{
}
(
)
2
3
0
0
1
( )
(
)
1
ns
s
s
s
n
n
e
f t
u t
n
e
e
e
s
s
−
∞
∞
−
−
−
=
=
=
−
=
=
+
+
+
+
∑
∑

L
L
 
 
(
)
(
)
2
3
1
1
1
1
1
(
)
(
)
(
)
.
1
1
s
s
s
s
s
e
e
e
s
s
e
s
e
−
−
−
−
−
=
+
+
+
+
=
⋅
=
−
−

 
40. 
Use of the geometric series gives 
{
}
{
}
(
)
2
3
0
0
( 1)
1
( )
( 1)
(
)
1
n
ns
n
s
s
s
n
n
e
f t
u t
n
e
e
e
s
s
−
∞
∞
−
−
−
=
=
−
=
−
−
=
=
−
+
−
+
∑
∑

L
L
 
 
(
)
(
)
2
3
1
1
1
1
1
(
)
(
)
(
)
.
1
(
)
1
s
s
s
s
s
e
e
e
s
s
e
s
e
−
−
−
−
−
=
+ −
+ −
+ −
+
=
⋅
=
−−
+

 
41. 
By checking values at sample points, you can verify that  ( )
2 ( )
1
g t
f t
=
−  in terms of  
 
the square wave function 
( )
f t  of Problem 40.  Hence 
 
{
}
{
}
(
)
2
1
1
2
1 1
( )
2 ( )
1
1
1
1
1
s
s
s
s
e
g t
f t
s
s
e
s
e
s
e
−
−
−
−
−


=
−
=
−
=
−
=
⋅


+
+
+


L
L
 
 
(
)
(
)
/ 2
/ 2
1
/ 2
/ 2
/ 2
2
/ 2
/ 2
/ 2
/ 2
/ 2
1
2
1 1
1
1
1
s
s
s
s
s
s
s
s
s
s
s
s
e
e
e
e
e
e
s
e
e
s e
e
s
e
e
−
−
−
−
−
−
−
−
−
=
⋅
⋅
=
⋅
=
⋅
+
+
+
 

510 
Chapter 10 
 
1 sinh( / 2)
1 tanh
.
cosh( / 2)
2
s
s
s
s
s
=
⋅
=
 
 
42. 
Let's refer to  (
1, ]
n
n
−
  as an odd interval if the integer  n  is odd, and even interval if  n  
 
is even.  Then our function  ( )
h t   has the value  a  on odd intervals, the value  b  on even 
 
intervals.  Now the unit step function  
( )
f t   of  Problem 40 has the value  1  on odd 
 
intervals, the value  0  on even intervals.  Hence the function  (
) ( )
a
b f t
−
 has the value  
 
(
)
a
b
−
on odd intervals, the value  0  on even intervals.  Finally, the function  
 
(
) ( )
a
b f t
b
−
+
has the value  (
)
a
b
b
a
−
+
=
  on odd intervals, the value  b  on even  
 
intervals, and hence (
) ( )
( ).
a
b f t
b
h t
−
+
=
  Therefore 
 
 
{ ( )}
{(
) ( )}
{ }
.
(1
)
(1
)
s
s
s
a
b
b
a
be
L h t
L a
b f t
L b
s
e
s
s
e
−
−
−
−
+
=
−
+
=
+
=
+
+
 
 
 
 
 
SECTION 10.2 
 
TRANSFORMATION OF INITIAL VALUE PROBLEMS 
 
The focus of this section is on the use of transforms of derivatives (Theorem 1) to solve initial 
value problems (as in Examples 1 and 2).  Transforms of integrals (Theorem 2) appear less 
frequently in practice, and the extension of Theorem 1 at the end of Section 10.2 may be 
considered entirely optional (except perhaps for electrical engineering students). 
 
In Problems 1–10 we give first the transformed differential equation, then the transform  X(s)  of 
the solution, and finally the inverse transform  x(t)  of  X(s). 
 
1. 
[s2X(s) - 5s] + 4{X(s)}  =  0 
 
2
2
5
( )
5
4
4
s
s
X s
s
s
=
=
⋅
+
+
 
 
x(t)  =  L-1{X(s)}  =  5 cos 2t 
 
2. 
[s2X(s) - 3s - 4] + 9[X(s)]  =  0 
 
2
2
2
3
4
4
3
( )
3
9
9
3
9
s
s
X s
s
s
s
+
=
=
⋅
+
⋅
+
+
+
 
 
x(t)  =  L-1{X(s)}  =  3 cos 3t + (4/3)sin 3t 
 
3. 
[s2X(s) - 2] - [sX(s)] - 2[X(s)]  =  0 

 
Section 10.2 
511 
 
2
2
2
2
1
1
( )
2
(
2)(
1)
3
2
1
X s
s
s
s
s
s
s


=
=
=
−


−
−
−
+
−
+


 
 
x(t)  =  (2/3)(e2t - e-t) 
 
4. 
[s2X(s) - 2s + 3] + 8[s X(s) - 2] + 15[X(s)]  =  0 
 
2
2
13
7
1
3
1
( )
8
15
2
3
2
5
s
X s
s
s
s
s
+
=
=
⋅
−
⋅
+
+
+
+
 
 
x(t)   =  L-1{X(s)}  =  (7/2)e-3t - (3/2)e-5t  
  
5. 
[s2X(s)] + [X(s)]  =  2/(s2 + 4) 
 
2
2
2
2
2
2
1
1
2
( )
(
1)(
4)
3
1
3
4
X s
s
s
s
s
=
=
⋅
−
⋅
+
+
+
+
 
 
x(t)   =  (2 sin t - sin 2t)/3 
 
6. 
[s2X(s)] + 4[X(s)]  =  L{cos t}  =  s/(s2 + 1) 
 
2
2
2
2
2
1
1
( )
(
1)(
4)
3
1
3
4
s
s
X s
s
s
s
s
=
=
⋅
−
⋅
+
+
+
+
 
 
 
x(t)   =  L-1{X(s)}  =  (cos t - cos 2t)/3 
 
7. 
[s2X(s) - s] + [X(s)]  =  s/s2 + 9) 
 
(s2 + 1)X(s)  =  s + s/(s2 + 9)  =  (s3 + 10s)/(s2 + 9) 
 
2
2
2
2
2
10
9
1
( )
(
1)(
9)
9
1
8
9
s
s
s
s
X s
s
s
s
s
+
=
=
⋅
−
⋅
+
+
+
+
 
 
x(t)  =  (9 cos t - cos 3t)/8 
 
8. 
[s2X(s)] + 9[X(s)]  =  L{1}  =  1/s 
 
2
2
1
1 1
1
( )
(
9)
9
9
9
s
X s
s s
s
s
=
=
⋅
−
⋅
+
+
 
 
x(t)  =  L-1{X(s)}  =  (1 - cos 3t)/9 
 
9. 
s2X(s) + 4sX(s) + 3X(s)  =  1/s 
 
2
1
1
1 1
1
1
1
1
( )
(
4
3)
(
1)(
3)
3
2
1
6
3
X s
s s
s
s s
s
s
s
s
=
=
=
⋅
−
⋅
+
⋅
+
+
+
+
+
+
 
 
x(t)   =  (2 - 3e-t + e-3t)/6 

512 
Chapter 10 
  10. 
[s2X(s) - 2] + 3[sX(s)] + 2[X(s)]  =  L{t}  =  1/s2 
 
(s2 + 3s + 2)X(s)  =  2 + 1/s2  =  (2s2 + 1)/s2 
 
2
2
2
2
2
2
2
1
2
1
3 1
1
1
1
9
1
( )
3
(
3
2)
(
1)(
2)
4
2
1
4
2
s
s
X s
s
s
s
s
s
s
s
s
s
s
+
+
=
=
= −
⋅
+
⋅
+ ⋅
−
⋅
+
+
+
+
+
+
 
 
x(t)   =  L-1{X(s)}  =  (-3 + 2t + 12e-t - 9e-2t)/4 
 
11. 
The transformed equations are 
 
 
 
 
 
 
sX(s) - 1  =  2X(s) +  Y(s) 
 
 
 
 
sY(s) + 2  =  6X(s) + 3Y(s). 
 
 
We solve for the Laplace transforms 
 
 
 
 
 
5
1
( )
(
5)
s
X s
s s
s
−
=
=
−
 
 
 
 
 
Y(s)  =  
2
10
2
( )
.
(
5)
s
X s
s s
s
−
+
=
= −
−
 
 
 
Hence the solution is given by 
 
 
 
 
 
x(t)  =  1, 
 
y(t)  =  -2. 
 
12. 
The transformed equations are 
 
 
 
 
 
s X(s)  =  X(s) + 2Y(s) 
 
 
 
 
s Y(s)  =  X(s) + 1/(s + 1), 
 
 
which we solve for 
 
 
 
2
2
2
2
1
1
1
( )
3
(
2)(
1)
9
2
1
(
1)
X s
s
s
s
s
s


=
=
−
−⋅


−
+
−
+
+


 
 
 
2
2
1
1
1
1
1
( )
6
.
(
2)(
1)
9
2
1
(
1)
s
Y s
s
s
s
s
s


−
=
=
−
−⋅


−
+
−
+
+


 
 
 
Hence the solution is 
 
 
 
 
 
x(t)  =  (2/9)(e2t - e-t - 3t e-t) 
 
 
 
 
y(t)  =  (1/9)(e2t - e-t + 6t e-t). 
 

 
Section 10.2 
513 
13. 
The transformed equations are 
 
 
 
 
sX(s) + 2[sY(s) - 1] + X(s)  =  0 
 
 
 
sX(s) -  [sY(s) - 1] + Y(s)  =  0, 
 
 
which we solve for the transforms 
 
 
 
(
)
2
2
2
2
2
2
1
2
1/
3
( )
3
1
3
1/3
3
1/
3
X s
s
s
s
= −
= −
⋅
= −
⋅
−
−
−
 
 
 
(
)
(
)
2
2
2
2
2
2
3
1
1/3
1
1/
3
( )
3
1
1/3
3
1/
3
1/
3
s
s
s
X s
s
s
s
s
+
+
=
=
=
+
⋅
−
−
−
−
. 
 
Hence the solution is 
 
 
 
 
x(t)  =  (
)
(
)
2/
3 sinh
/
3
t
−
 
 
 
 
y(t)  =  
(
) (
)
(
)
cosh
/
3
1/
3 sinh
/
3
t
t
+
. 
  
14. 
The transformed equations are 
 
 
 
 
 
s2X(s) + 1 + 2X(s) + 4Y(s)  =  0 
 
 
 
 
s2Y(s) + 1 +   X(s) + 2Y(s)  =  0, 
 
 
which we solve for 
 
 
 
 
2
2
2
2
2
2
1
1
2
( )
2
3
(
4)
4
4
s
X s
s
s
s
s
−
+


=
=
⋅
−⋅


+
+


 
 
 
 
2
2
2
2
2
1
1
1
2
( )
2
3
.
(
4)
8
4
s
Y s
s
s
s
s
−
−


=
= −
⋅
+ ⋅


+
+


 
 
 
Hence the solution is  
 
            
 
 
x(t)  =   (1/4)(2t - 3 sin 2t) 
            
 
 
y(t)  =   (-1/8)(2t + 3 sin 2t). 
 
15. 
The transformed equations are 
 
 
 
 
[s2X - s] + [sX - 1] + [sY - 1] + 2X -  Y  =  0 
 
 
 
[s2Y - s] + [sX - 1] + [sY - 1] + 4X - 2Y  =  0, 
 
 
which we solve for 
 

514 
Chapter 10 
 
 
2
3
2
2
2
2
2
2
2
3
2
1 2
3
1 2
3
( )
3
3
3
3
3
3
(
3/ 2)
(3/ 4)
1 2
3/ 2
3 / 2
3
3
(
3/ 2)
( 3 / 2)
(
3/ 2)
( 3 / 2)
s
s
s
s
X s
s
s
s
s
s
s
s
s
s
s
s
s


+
+
+
+


=
=
+
=
+




+
+
+
+
+
+






+
=
+
+
⋅


+
+
+
+


 
 
 
3
2
3
2
2
2
2
2
4
1
28
9
2
15
( )
3
3
21
1
3
3
1
28
9
2
15
21
1
(
3/ 2)
3/ 4
s
s
s
s
Y s
s
s
s
s
s
s
s
s
s
s
s
−
−
+
+
+


=
=
−
+


+
+
−
+
+




+
=
−
+


−
+
+


 
 
 
2
2
2
2
1
28
9
3/ 2
3 / 2
2
8 3
.
21
1
(
3/ 2)
( 3 / 2)
(
3/ 2)
( 3 / 2)
s
s
s
s
s


+
=
−
+
⋅
+
⋅


−
+
+
+
+


 
 
 
Here we've used some fairly heavy-duty partial fractions (Section 7.3).  The transforms 
 
 
 
{
}
{
}
2
2
2
2
cos
,
sin
(
)
(
)
at
at
s
a
k
e
kt
e
kt
s
a
k
s
a
k
−
=
=
−
+
−
+
L
L
 
 
 
from the inside-front-cover table (with  
3/ 2,
3 / 2)
a
k
= −
=
 finally yield 
 
 
 
 
 
(
)
(
)
{
}
3 / 2
1
( )
2
cos
3 / 2
3sin
3 / 2
3
t
x t
e
t
t
−


=
+
+

  
 
 
(
)
(
)
{
}
3 / 2
1
( )
28
9
2cos
3 / 2
8 3sin
3 / 2
.
21
t
t
y t
e
e
t
t
−


=
−
+
+


 
 
16. 
The transformed equations are 
 
 
 
 
s X(s) - 1  =     X(s) + Z(s) 
 
 
 
s Y(s)        =     X(s) + Y(s) 
 
 
 
s Z(s)        =  -2X(s) - Z(s), 
 
 
which we solve for 
 
 
 
 
2
2
2
1
1
( )
(
1)(
1)
1
s
s
X s
s
s
s
−
+
=
=
−
+
+
 
 
 
 
2
2
1
1
( )
(
1)(
1)
1
1
s
s
Y s
s
s
s
s
+
=
=
−
−
+
−
+  
 
 
 
2
2
2
2
2
( )
.
(
1)(
1)
1
s
Z s
s
s
s
−
+
=
= −
−
+
+
 

 
Section 10.2 
515 
 
 
Hence the solution is 
 
 
      
 
x(t)  =  cos t + sin t 
 
      
 
y(t)  =  et - cos t 
 
      
 
z(t)  =  -2 sin t. 
 
17. 
(
)
3
3
3
0
0
1
1
( )
1
3
3
t
t
t
f t
e
d
e
e
τ
τ
τ
τ
=


=
=
=
−




∫
 
 
18. 
(
)
5
5
5
0
0
3
3
3
1
( )
5
5
t
t
t
f t
e
d
e
e
τ
τ
τ
τ
−
−
−
=


−
=
−
=
= 



∫
  
 
19. 
(
)
1
2
0
0
1
1
sin2
cos2
1
cos2
( )
4
4
t
t
t
f t
d
τ
τ τ
τ
=


−
=
−
=
= 



∫
 
 
20. 
(
)
(
)
1
3
0
0
2
1
1
2cos3
sin3
sin3
cos3
6sin3
cos3
1
( )
3
9
9
t
t
d
t
t
f t
τ
τ
τ
τ
τ
τ
=


+
−
=
−
+
=
= 



∫
 
 
 
21. 
[
]
0
0
0
0
sin
(1
cos )
sin
sin
( )
t
t
t
t dt
d
t
t
f t
d
τ
τ
τ
τ
τ
τ
τ
=


−
=
−
=
−
=
=




∫
∫
∫
  
 
22. 
(
)
1
3
0
0
1
1
sinh3
cosh3
cosh3
1
( )
9
9
t
t
t
f t
d
τ
τ τ
τ
=


=
−
=
= 



∫
 
 
 
23. 
[
]
0
0
0
0
sinh
(cosh
1)
sinh
sinh
( )
t
t
t
t dt
d
t
t
f t
d
τ
τ
τ
τ
τ
τ
τ
=


−
=
−
=
−
=
=




∫
∫
∫
 
 
 
24. 
(
)
(
)
2
2
2
0
0
1
1
2
1
( )
2
2
t
t
t
t
e
e
e
e
e
e
f t
d
τ
τ
τ
τ
τ
τ
−
−
−
−
−
−
=


−
−
+
=
−
+
=
= 



∫
 
 
25. 
With  f(t)  =  cos kt  and  F(s)  =  s/(s2 + k2),  Theorem 1 in this section yields 
 
 
 
L{-k sin kt}  =  L{f′ (t)}  =  sF(s) - 1  
2
2
2
2
2
1
,
s
k
s s
k
s
k
=
⋅
−
= −
+
+
 
 
 
so division by  -k  yields  L{sin kt}  =  k/(s2 + k2). 
 
 

516 
Chapter 10 
26. 
With  f(t)  =  sinh kt  and  F(s)  =  k/(s2 - k2),  Theorem 1 yields 
 
 
 
L{f′ (t)}  =  L{k cosh kt}  =  ks/(s2 - k2)  =  sF(s), 
 
 
so it follows upon division by  k  that  L{cosh kt}  =  s/(s2 - k2). 
 
27. 
(a)  
With  f(t)  =  tneat  and  f′ (t)  =  ntn-1eat + atneat,  Theorem 1 yields 
 
 
 
 
 
L{ntn-1eat + atneat}  =  s L{tneat} 
 
so 
 
 
 
 
n L{tn-1eat}  =  (s - a)L{tneat} 
 
and hence 
 
 
 
 
{
}
{
}
1
.
n
at
n
at
n
t e
t
e
s
a
−
=
−
L
L
 
 
 
(b) 
{
}
{ }
2
1
1
1
1
1:
(
)
at
at
n
t e
e
s
a
s
a s
a
s
a
=
=
=
⋅
=
−
−
−
−
L
L
 
 
 
{
}
{
}
2
2
3
2
2
1
2!
2 :
(
)
(
)
at
at
n
t e
t e
s
a
s
a
s
a
s
a
=
=
=
⋅
=
−
−
−
−
L
L
 
 
 
{
}
{
}
3
2
3
4
3
3
2!
3!
3:
(
)
(
)
at
at
n
t e
t e
s
a
s
a
s
a
s
a
=
=
=
⋅
=
−
−
−
−
L
L
 
 
And so forth. 
 
28. 
Problems 28 and 30 are the trigonometric and hyperbolic versions of essentially the same 
computation.  For Problem 30 we let  f(t)  =  t cosh kt,  so  f(0)  =  0.  Then 
 
  
 
 
 
( )
f t
′
  =  cosh kt + kt sinh kt 
 
 
 
 
( )
f
t
′′
=  2k sinh kt + k2t cosh kt, 
 
 
and thus  f′ (0)  =  1,  so Formula (5) in this section yields 
 
 
 
 
L{2k sinh kt + k2t cosh kt}  =  s2L{t cosh kt} - 1,  
 
 
 
2
2
2
k
k s
k
⋅
−
  +  k2F(s)  =  s2F(s) - 1. 
 
We readily solve this last equation for 
 
 
 
L{t cosh kt}  =  F(s)  =  
(
)
2
2
2
2
2
.
s
k
s
k
+
−
 
 
29. 
Let   f(t)  =  t sinh kt,  so  f(0)  =  0.  Then 

 
Section 10.2 
517 
 
  
 
 
 
( )
f t
′
  =  sinh kt + kt cosh kt 
 
 
 
 
( )
f
t
′′
=  2k cosh kt + k2t sinh kt, 
 
 
and thus  f′ (0)  =  0,  so Formula (5) in this section yields 
 
 
 
 
L{2k cosh kt + k2t sinh kt}  =  s2L{sinh kt},  
 
 
 
2
2
2
s
k s
k
⋅
−
  +  k2F(s)  =  s2F(s). 
 
We readily solve this last equation for 
 
 
 
L{t cosh kt}  =  F(s)  =  
(
)
2
2
2
2
.
ks
s
k
−
 
30. 
See Problem 28. 
 
31. 
Using the known transform of  sin kt  and the Problem 28 transform of  t cos kt, we obtain 
 
 
(
)
(
)
2
2
2
3
3
2
2
3
2
2
1
1
sin
cos
2
2
2
k
k
s
k
kt
kt
kt
k
k
s
k
k
s
k
−


−
=
⋅
−
⋅


+


+
L
 
 
 
(
)
(
)
(
)
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
2
1
1
1
2
1
2
2
s
k
k
k
s
k
k
s
k
s
k
s
k


−


=
−
=
⋅
=


+
+
+
+


 
 
32. 
If  f(t)  =  u(t - a),  then the only jump in  f(t)  is  j1  =  1  at  t1  =  a.  Since  f(0)  =  0  and 
f′ (t)  =  0,  Formula (21) in this section yields  
 
 
 
 
 
0  =  s F(s) - 0 - eas(1). 
 
 
Hence  L{u(t - a)}  =  F(s)  =  s-1e-as. 
 
33. 
( )
( )
( )
(
)
(
),
a
b
f t
u t
u t
u t
a
u t
b
=
−
=
−
−
−
so the result of Problem 32 gives 
 
 
 
{
}
{
}
{
}
( )
(
)
(
)
.
as
bs
as
bs
e
e
e
e
f t
u t
a
u t
b
s
s
s
−
−
−
−
−
=
−
−
−
=
−
=
L
L
L
 
 
34. 
The square wave function of Figure 7.2.9 has a sequence  {tn}  of jumps with  tn  =  n  
and  jn  =  2(-1)n  for  n  =  1, 2, 3, ... .  Hence Formula (21) yields 
 
 
 
 
 
0  =  s F(s) - 1 - 
1
2( 1) .
ns
n
n
e
∞
−
=
⋅
−
∑
 
 
It follows that 

518 
Chapter 10 
  
 
    
            s F(s)  =  1 + 2 
1
( 1)n
ns
n
e
∞
−
=
−
∑
 
 
    
                     =  -1 + 2(1 - e-s + e-2s - e-3s +  ⋅ ⋅ ⋅ ) 
 
    
                     =  -1 + 2/(1 + e-s) 
 
  
                     =  (1 - e-s)/(1 + e-s) 
 
 
                     =  (es/2 - e-s/2)/(es/2 + e-s/2) 
 
 
         s F(s)  =  tanh(s/2), 
 
      
because  2 cosh(s/2)  =  es/2 + e-s/2  and  2 sinh(s/2)  =  es/2 - e-s/2. 
 
35. 
Let's write  ( )
g t  for the on-off function of this problem to distinguish it from the square 
wave function of Problem 34.  Then comparison of Figures 7.2.9 and 7.2.10 makes it 
clear that  
(
)
1
2
( )
1
( ) ,
g t
f t
=
+
  so (using the result of Problem 34) we obtain 
  
 
 
/2
/2
/2
/2
/2
/2
1
1
1
1
1
( )
( )
tanh
1
2
2
2
2
2
2
s
s
s
s
s
s
s
e
e
e
G s
F s
s
s
s
s
e
e
e
−
−
−
−


−
=
+
=
+
=
+
⋅


+


 
 
 
(
)
1
1
1
2
1
1
.
2
1
2
1
1
s
s
s
s
e
s
e
s
e
s
e
−
−
−
−


−
=
+
=
⋅
=


+
+
+


 
 
36. 
If  g(t)  is the triangular wave function of Figure 7.2.11 and  f(t)  is the square wave 
function of Problem 34, then  
( )
( ).
g t
f t
′
=
  Hence Theorem 1 and the result of Problem 
34 yield 
 
      
 
{
}
( )
g t
′
L
  =  s L{g(t)} - g(0), 
 
                
F(s)  =  s G(s),               (because  g(0) = 0) 
 
      
 
L{g(t)}  =  s-1F(s)  =  s-2tanh(s/2). 
 
37. 
We observe that  
(0)
0
f
=
 and that the sawtooth function has jump  –1  at each of the 
points  
1, 2, 3,
.
nt
n
=
=
   Also,  
( )
1
f t
′
≡wherever the derivative is defined.  Hence  
Eq. (21) in this section gives 
 
 
( )
( )
( )
1
0
1
1
1
1
,
1
ns
ns
ns
n
n
s F s
e
s F s
e
s F s
s
e
∞
∞
−
−
−
=
=
=
+
=
−+
=
−+
−
∑
∑
 
 
using the geometric series  
0
1/(1
)
n
n
x
x
∞
=
=
−
∑
  with  
.
s
x
e−
=
  Solution for  F(s)  gives 

 
Section 10.2 
519 
 
 
(
)
(
)
2
2
1
1
1
1
( )
.
1
1
s
s
s
e
F s
s
s
s
s
e
s
e
−
−
−
=
+
−
=
−
−
−
 
 
 
SECTION 10.3 
 
TRANSLATION AND PARTIAL FRACTIONS 
 
This section is devoted to the computational nuts and bolts of the staple technique for the 
inversion of Laplace transforms — partial fraction decompositions.  If time does not permit 
going further in this chapter, Sections 10.1–10.3 provide a self-contained introduction to Laplace 
transforms that suffices for the most common elementary applications. 
 
1. 
L{t4}  =  
5
24
s ,    so   L{t4eπ t}  =  
5
24
(
)
s
π
−
 
 
2. 
L{t3/2}  =  
5/2
3
,
4s
π
   so  L{t3/2 e–4t} =  
5/2
3
.
4(
4)
s
π
+
 
 
3. 
L{sin 3πt}  =  
2
2
3
,
9
s
π
π
+
   so  L{e-2tsin 3πt}  =  
2
2
3
.
(
2)
9
s
π
π
+
+
 
 
4. 
cos2
cos 2
8
4
t
t
π
π




−
=
−








  =  
(
)
1
cos2
sin2
2
t
t
+
 
 
cos2
8
t
π




−








L
  =  
2
1
2
4
2
s
s
+
+
 
 
(
)
(
)
/2
2
2
1/ 2
2
1
1
2
5
cos2
8
4
4
17
2
2
1/ 2
4
t
s
s
e
t
s
s
s
π
−
+
+


+


−
=
=




+
+


+
+


L
 
 
5. 
2
3
3
1
3
( )
, so
( )
2
4
2
2
2
t
F s
f t
e
s
s
=
=
⋅
=
−
−
 
 
6. 
(
)
2
2
3
2
3
(
1)
2
1
2
( )
, so
( )
(
1)
(
1)
(
1)
t
t
t
s
F s
f t
te
t e
e
t
t
s
s
s
−
−
−
+
−
=
=
−
=
−
=
−
+
+
+
 
 
7. 
(
)
2
1
( )
2
F s
s
=
+
,   so   f(t)  =  t e-2t 
 
8. 
(
)
2
2
( )
2
1
s
F s
s
+
=
+
+
,   so   f(t)  =  e-2tcos t 

520 
Chapter 10 
9. 
(
)
(
)
2
2
3
7
4
( )
3
,
2
3
16
3
16
s
F s
s
s
−
=
⋅
+
⋅
−
+
−
+
   so   f(t)  =  e3t[3 cos 4t + (7/2)sin 4t] 
 
10. 
(
)
(
)
2
2
2
3
1
2
3
( )
9
3
2
16
2 /3
16/ 9
s
s
F s
s
s
−
−
=
=
⋅
−
+
−
+
 
 
(
)
(
)
(
)
(
)
2
2
2
2
2
2/ 3
5
4 /3
9
36
2/ 3
4/ 3
2 /3
4 /3
s
s
s
−
=
⋅
−
⋅
−
+
−
+
 
 
2 /3
1
4
4
( )
8cos
5sin
36
3
3
t
t
t
f t
e


=
−




 
 
11. 
1
1
1
1
( )
,
4
2
4
2
F s
s
s
=
⋅
−
⋅
−
+
   so   
(
)
2
2
1
1
( )
sinh2
4
2
t
t
f t
e
e
t
−
=
−
=
 
 
12. 
1
1
( )
2
3
,
3
F s
s
s
=
⋅
+ ⋅
−
   so   
3
( )
2
3
t
f t
e
=
+
 
 
13. 
2
5
1
1
( )
3
5
, so
( )
3
5
2
5
t
t
F s
f t
e
e
s
s
−
−
=
⋅
−⋅
=
−
+
+
 
 
14. 
2
1
1
1
( )
2
3
, so
( )
2
3
1
2
t
t
F s
f t
e
e
s
s
s
−
=
⋅
−⋅
+
=
−
+
+
−
 
  
15. 
(
)
5
2
1
1
1
1
1
( )
1
5
, so
( )
1
5
25
5
25
t
F s
f t
t
e
s
s
s


=
−⋅
−⋅
+
=
−−
+


−


 
 
16. 
(
) (
)
(
)
(
)
2
2
2
2
1
1
2
5
2
5
( )
125
3
2
3
2
3
2
F s
s
s
s
s
s
s


=
=
+
−
+




+
−
+
−
+
−


 
 
(
)
(
)
3
2
1
( )
2
5
2
5
125
t
t
f t
e
t
e
t
−


=
+
+
−+

 
  
17. 
2
2
2
2
1
1
1
1
2
2
( )
8
4
4
16
4
4
F s
s
s
s
s




=
−
=
−




−
+
−
+




 
 
(
)
1
( )
sinh2
sin2
16
f t
t
t
=
−
 
 
18. 
(
)
(
)
(
)
2
3
4
1
1
48
64
( )
4
4
4
4
F s
s
s
s
s
=
+
+
+
−
−
−
−
 

 
Section 10.3 
521 
 
4
2
3
32
( )
1 12
24
3
t
f t
e
t
t
t


=
+
+
+




 
 
19. 
(
)(
)
2
2
2
2
2
2
1
2
1
2
4
( )
3
1
4
1
4
s
s
s
s
F s
s
s
s
s
−
−
−
+


=
=
+


+
+
+
+


 
 
(
)
1
( )
2cos
sin
2cos2
2sin 2
3
f t
t
t
t
t
=
−
−
+
+
 
20. 
(
)
(
) (
)
(
)
(
)
2
2
2
2
2
2
1
1
1
1
2
1
2
( )
32
2
2
2
2
2
2
4
F s
s
s
s
s
s
s
s


=
=
=
+
−
+




+
−
−
+
+
−
−


 
 
(
)
(
)
2
2
1
( )
1
2
1
2
32
t
t
f t
e
t
e
t
−


=
+
+
−+

 
 
21. 
First we need to find  ,
,
,
A B C D  so that 
 
 
 
 
(
)
(
)
2
2
2
2
2
2
3
.
2
2
2
2
2
2
s
As
B
Cs
D
s
s
s
s
s
s
+
+
+
=
+
+
+
+
+
+
+
 
 
When we multiply both sides by the quadratic factor  
2
2
2
s
s
+
+
  and collect 
coefficients, we get the linear equations 
 
 
 
 
 
2
3
0
2
2
0
2
1
0
0
B
D
A
B
C
A
B
A
−
−
+
=
−
−
−
=
−
−
+
=
−
=
 
 
 
which we solve for  
0,
1,
2,
1.
A
B
C
D
=
=
= −
=
  Thus 
 
 
(
)
(
)
(
)
(
)
(
)
2
2
2
2
2
2
2
2
1
2
1
1
1
1
( )
2
3
.
1
1
1
1
1
1
1
1
1
1
s
s
F s
s
s
s
s
s
−
+
+
=
+
=
−
⋅
+ ⋅
+
+
+
+






+
+
+
+
+
+






 
 
We now use the inverse Laplace transforms given in Eq. (16) and (17) of Section 10.3 — 
supplying the factor  
t
e− corresponding to the translation  
1
s
s
→
+  — and get 
 
 
(
)
(
)
1
1
1
( )
sin
2
sin
3
sin
cos
5sin
2 sin
3 cos
.
2
2
2
t
t
f t
e
t
t
t
t
t
t
e
t
t
t
t
t
−
−


=
−
⋅
+ ⋅
−
=
−
−




 
 
22. 
First we need to find  A, B, C, D  so that 
 

522 
Chapter 10 
 
 
 
(
)
(
)
3
2
2
2
2
2
2
2
.
4
4
5
4
4
5
4
4
5
s
s
As
B
Cs
D
s
s
s
s
s
s
−
+
+
=
+
−
+
−
+
−
+
 
 
 
When we multiply each side by the quadratic factor (squared) 5 we get the identity  
 
 
 
 
2s3 - s2  =  (As + B)(4s2 - 4s + 5) + Cs + D. 
 
 
When we substitute the root  s  =  1/2 + i  of the quadratic into this identity, we find that  
C  =  -3/2  and  D  =  - 5/4.  When we first differentiate each side of the identity and then 
substitute the root, we find that  A  =  1/2  and B  =  1/4. Writing 
 
 
 
 
 
4s2 - 4s + 5  =  4[(s - 1/2)2 + 1], 
 
it follows that 
 
 
 
(
)
(
)
(
)
(
)
1
1
2
2
2
2
2
1
1
2
2
1
3
4
1
1
( )
.
8
32
1
1
s
s
F s
s
s
−
+
−
+
=
⋅
−
⋅
−
+


−
+


 
 
Finally the results 
 
 
 
 
 
L-1{2s/(s2 + 1)2}  =  t sin t 
  
 
 
 
L-1{2/(s2 + 1)2}  =  sin t - t cos t 
 
 
of Eqs. (16) and (17) in Section 10.3, together with the translation theorem, yield 
 
 
 
(
)
(
)
(
)
(
)
/ 2
/ 2
1
3
1
4
1
( )
cos
sin
sin
sin
cos
8
32 2
32 2
1
8
4
cos
4
3 sin
.
64
t
t
f t
e
t
t
t
t
t
t
t
e
t
t
t
t


=
⋅
+
−
⋅
−
⋅
−




=
+
+
−




 
 
23. 
3
4
4
2
2
2
2
1
,
4
2
2
2
2
2
s
s
a
s
a
s
a
s
as
a
s
as
a
−
+


=
+


+
−
+
+
+


 
 
 
and  s2 ± 2as + 2a2  =  (s ± a)2 + a2,  so it follows that 
 
 
 
(
)
3
1
4
4
1
cos
cosh
cos
.
4
2
at
at
s
e
e
at
at
at
s
a
−
−

=
+
=


+


L
 
 
24. 
4
4
2
2
2
2
2
1
,
4
4
2
2
2
2
s
a
a
s
a
a
s
as
a
s
as
a


=
−


+
−
+
+
+


 
 
 
and  s2 ± 2as + 2a2  =  (s ± a)2 + a2,  so it follows that 
 

 
Section 10.3 
523 
 
 
(
)
3
1
4
4
2
2
1
1
sin
sinh
sin
.
4
4
2
at
at
s
e
e
at
at
at
s
a
a
a
−
−

=
−
=


+


L
 
 
25. 
4
4
2
2
2
2
1
4
4
2
2
2
2
s
s
s
s
a
a
s
as
a
s
as
a


=
−


+
−
+
+
+


 
 
2
2
2
2
2
2
2
2
1
,
4
2
2
2
2
2
2
2
2
s
a
a
s
a
a
a
s
as
a
s
as
a
s
as
a
s
as
a
−
+


=
+
−
+


−
+
−
+
+
+
+
+


 
 
 
and  s2 ± 2as + 2a2  =  (s ± a)2 + a2,  so it follows that 
 
 
 
(
)
(
)
(
)
(
)
1
4
4
1
(cos
sin
)
cos
sin
4
4
1
1
1
sin
cos
2
2
2
1
cosh
sin
sinh
cos
.
2
at
at
at
at
at
at
s
e
at
at
e
at
at
s
a
a
e
e
at
e
e
at
a
at
at
at
at
a
−
−
−
−




=
+
−
−




+




=
+
+
−




=
+
L
 
 
26. 
4
4
3
2
2
2
2
1
1
2
2
4
8
2
2
2
2
s
a
s
a
s
a
a
s
as
a
s
as
a
−+
+


=
+


+
−
+
+
+


 
 
3
2
2
2
2
2
2
2
2
1
,
8
2
2
2
2
2
2
2
2
s
a
a
s
a
a
a
s
as
a
s
as
a
s
as
a
s
as
a
−
+


=
−
+
+
+


−
+
−
+
+
+
+
+


 
 
 
and  s2 ± 2as + 2a2  =  (s ± a)2 + a2,  so it follows that 
 
 
 
(
)
(
)
(
)
(
)
1
4
4
3
3
3
1
( cos
sin
)
cos
sin
4
8
1
1
1
sin
cos
4
2
2
1
cosh
sin
sinh
cos
.
4
at
at
at
at
at
at
s
e
at
at
e
at
at
s
a
a
e
e
at
e
e
at
a
at
at
at
at
a
−
−
−
−




=
−
+
+
+




+




=
+
−
−




=
−
L
 
 
In Problems 27–40 we give first the transformed equation, then the Laplace transform  
( )
X s  of 
the solution, and finally the desired solution  ( ).
x t  
 
27. 
[s2X(s) - 2s - 3] + 6[sX(s) - 2] + 25X(s)  =  0 
 
(
)
(
)
2
2
2
2
15
3
9
4
( )
2
6
25
4
3
16
3
16
s
s
X s
s
s
s
s
+
+
=
=
⋅
+
⋅
+
+
+
+
+
+
 
 
x(t)  =  e-3t[2 cos 4t + (9/4)sin 4t] 

524 
Chapter 10 
28. 
2
2
( )
6
( )
8
( )
s X s
sX s
X s
s
−
+
=
 
 
2
2
1 1
1
2
( )
(
6
8)
4
4
2
X s
s s
s
s
s
s


=
=
+
−


−
+
−
−


 
 
(
)
4
2
1
( )
1
2
4
t
t
x t
e
e
=
+
−
 
 
 
29. 
2
2
3
( )
4
( )
s X s
X s
s
−
=
 
 
(
)
2
2
2
2
3
3
1
1
( )
4
4
4
X s
s
s
s
s


=
=
−


−
−


 
 
 
(
)
3
3
3
( )
sinh 2
sinh2
2
8
4
8
x t
t
t
t
t
=
−
=
−
 
  
30. 
2
1
( )
4
( )
8
( )
1
s X s
sX s
X s
s
+
+
=
+  
 
(
)(
)
(
)
(
)
2
2
2
2
1
1
1
3
( )
5
1
4
8
1
4
8
1
1
2
1
2
5
1
2
2
4
2
4
s
X s
s
s
s
s
s
s
s
s
s
s
+


=
=
−


+
+
+
+
+
+




+
=
−
−
⋅




+
+
+
+
+


 
 
2
1
( )
2
(2cos2
sin2 )
10
t
t
x t
e
e
t
t
−
−


=
−
+

 
 
31. 
[s3X(s) - s - 1] + [s2X(s) - 1] - 6[sX(s)]  =  0 
 
3
2
2
1
5
1
6
( )
6
15
3
2
s
X s
s
s
s
s
s
s
+


=
=
−
−
+


+
−
+
−


 
 
 
(
)
3
2
1
( )
5
6
15
t
t
x t
e
e
−
=
−−
+
 
 
32. 
4
3
( )
( )
0
s X s
s
X s


−
−
=


 
 
3
4
2
2
1
( )
1
2
1
1
s
s
s
X s
s
s
s


=
=
+


−
+
−


 
 
(
)
1
( )
cos
cosh
2
x t
t
t
=
+
 
 

 
Section 10.3 
525 
33. 
[s4X(s) - 1] + X(s)  =  0 
 
4
1
( )
1
X s
s
=
+
 
 
 
 
It therefore follows from Problem 26 with  
4 1/ 4
1/
2
a =
=
that 
 
 
 
1
( )
cosh
sin
sinh
cos
.
2
2
2
2
2
t
t
t
t
x t


=
−




 
 
34. 
[s4X(s) - 2s2 + 13] + 13[s2X(s) - 2] + 36 X(s)  =  0 
 
2
4
2
2
2
2
13
1
1
( )
13
36
4
9
s
X s
s
s
s
s
+
=
=
+
+
+
+
+
 
 
1
1
( )
sin 2
sin3
2
3
x t
t
t
=
+
 
   
35. 
4
2
( )
1
8
( )
16
( )
0
s X s
s X s
X s


−
+
+
=


 
 
(
)
2
4
2
2
1
1
( )
8
16
4
X s
s
s
s
=
=
+
+
+
 
 
(
)
1
( )
sin2
2 cos2
16
x t
t
t
t
=
−
  
(by Eq. (17) in Section 10.3) 
 
36. 
4
2
1
( )
2
( )
( )
2
s X s
s X s
X s
s
+
+
=
−
 
 
(
)(
)
(
)
2
2
4
2
2
1
1
1
2
5(
2)
( )
25
2
1
2
2
1
1
s
s
X s
s
s
s
s
s
s


+
+


=
=
−
−


−
+
−
+
+
+


 
 
(
)
2
2
1
1
1
( )
cos
2sin
5
sin
10
sin
cos
25
2
2
1
2
(10
2)cos
(5
14)sin
50
t
t
x t
e
t
t
t
t
t
t
t
e
t
t
t
t
−


=
−
−
−⋅
−
⋅
−






=
+
−
−
+


 
 
37. 
(
)
2
2
1
( )
2
4
( )
13
( )
1
s X s
sX s
X s
s


−
+
+
=


+
 
 
(
)
2
2
2
2
2
2
1/(
1)
2
4
13
( )
4
13
(
1)
4
13
s
s
s
X s
s
s
s
s
s
+
+
+
+
=
=
+
+
+
+
+
 
 
 

526 
Chapter 10 
 
2
2
2
2
2
1
1
5
98
50
1
(
1)
(
2)
9
1
1
5
2
3
32
50
1
(
1)
(
2)
9
(
2)
9
s
s
s
s
s
s
s
s
s


+
=
−
+
+


+
+
+
+




+
=
−
+
+
+
⋅


+
+
+
+
+
+


 
 
2
1
( )
( 1
5 )
(cos3
32sin3 )
50
t
t
x t
t e
e
t
t
−
−


=
−+
+
+

 
 
38. 
[
]
2
2
( )
1
6
( )
1
18
( )
4
s
s X s
s
sX s
X s
s


−
+
+
−
+
=


+
 
 
(
)(
)
2
2
2
2
2
2
5
( )
6
18
4
6
18
5
1
7
12
7
54
6
18
170
4
6
18
s
s
X s
s
s
s
s
s
s
s
s
s
s
s
s
s
+
=
+
+
+
+
+
+
+
+
+


=
+
−


+
+
+
+
+


 
 
(
)
(
)
2
2
2
2
2
1
7
12
163
796
170
4
6
18
1
7
12
163(
3)
307
( )
170
4
3
9
3
9
s
s
s
s
s
s
s
X s
s
s
s
+
+


=
+


+
+
+




+
+
=
+
+




+
+
+
+
+


 
 
(
)
(
)
3
1
1
( )
7cos2
6sin2
489cos3
307sin3
170
510
t
x t
t
t
e
t
t
−
=
+
+
+
 
 
39. 
9
6cos3 ,
(0)
(0)
0
x
x
t
x
x
′′
′
+
=
=
=
 
 
2
2
6
( )
9
( )
9
s
s X s
X s
s
+
=
+
 
 
(
)
2
2
6
( )
9
s
X s
s
=
+
 
 
1
( )
6
sin3
sin3
2 3
x t
t
t
t
t
=
⋅
=
⋅
 
(by Eq. (16) in Section 10.3) 
 
 
The graph of this resonance is shown in the figure at the top of the next page. 
 
 

 
Section 10.3 
527 
 
8 p t
-20
20
x=+t
x=-t
 
 
40. 
/5
2
226
0.4
9.04
6
cos3
5
25
t
x
x
x
x
x
e
t
−
′′
′
′′
′
+
+
=
+
+
=
 
 
2
2
2
226
6(
1/5)
( )
5
25
(
1/5)
9
s
s
s
X s
s
+


+
+
=


+
+


 
 
2
2
6(
1/5)
( )
(
1/5)
9
s
X s
s
+
=


+
+


 
 
/5
( )
sin3
t
x t
t e
t
−
=
 
 
(by Eq. (16) in Section 10.3) 
 
 
 
 
SECTION 10.4 
 
DERIVATIVES, INTEGRALS, AND  
PRODUCTS OF TRANSFORMS 
 
This section completes the presentation of the standard "operational properties" of Laplace 
transforms, the most important one here being the convolution property  L{f*g}  =  L{f}⋅L{g},  
where the convolution  f*g  is defined by  
 
 
 
 
 
0
* ( )
( ) (
)
.
t
f
g t
f x g t
x dx
=
−
∫
 
 
Here we use  x  rather than  τ  as the variable of integration; compare with Eq. (3) in Section 10.4 
of the textbook 
 
 

528 
Chapter 10 
1. 
With  
( )
and
( )
1
f t
t
g t
=
=   we calculate  
 
 
 
 
2
2
0
0
1
1
*1
1
.
2
2
x t
t
x
t
x
dx
x
t
=
=


=
⋅
=
=




∫
 
 
2. 
With  
( )
and
( )
at
f t
t
g t
e
=
=
  we calculate   
 
 
 
(
)
0
0
2
2
2
2
0
*
(with
)
(
1)
(integral formula #46 inside back cover)
(
1)
(
1)
1
*
t
t
at
a t x
at
ax
at
at
u
u
at
u
at
at
x t
ax
at
x
t e
x e
dx
e
x e
dx
u
du
e
e
e
ue du
u
ax
a
a
a
e
u
e
a
e
e
ax
e
at
e
a
a
t e
−
−
−
−
−
−
−
−
=
−
−
=
=
⋅
=
⋅




=
−
−
=
= −










=
−






=
−
−
=
−
−
+




⌠⌡
∫
∫
∫
(
)
2
1
1 .
at
at
e
at
a
=
−
−
 
 
3. 
To compute  
0
(sin )*(sin )
sin sin(
)
,
t
t
t
x
t
x dx
=
−
∫
  we first apply the identity  
  
sin A sin B  =  [cos(A - B) - cos(A + B)]/2.  This gives 
 
 
 
[
]
(
)
0
0
0
(sin )*(sin )
sin sin(
)
1
cos(2
)
cos
2
1 1 sin(2
)
cos
2 2
1
(sin )*(sin )
sin
cos
.
2
t
t
x t
x
t
t
x
t
x dx
x
t
t dx
x
t
x
t
t
t
t
t
t
=
=
=
−
=
−
−


=
−
−




=
−
∫
∫
 
  
4. 
To compute  
2
2
0
*cos
cos(
)
,
t
t
t
x
t
x dx
=
−
∫
  we first substitute   
 
 
 
 
cos(t - x)  =  cos t cos x + sin t sin x,   
 
 
and then use the integral formulas 
 
      
 
 
2
2
cos
sin
2 cos
2sin
x
x dx
x
x
x
x
x
C
=
+
−
+
∫
 
 
 
 
2
2
sin
cos
2 sin
2cos
.
x
x dx
x
x
x
x
x
C
= −
+
+
+
∫
 

 
Section 10.4 
529 
 
 
 
from #40 and #41 inside the back cover of the textbook.  This gives 
 
 
 
2
2
0
2
2
0
0
2
0
2
0
2
*cos
(cos cos
sin sin )
(cos )
cos
(sin )
sin
(cos )
sin
2 cos
2sin
(sin )
cos
2 sin
2cos
*cos
2(
sin ).
t
t
t
x t
x
x t
x
t
t
x
t
x
t
x dx
t
x
xdx
t
x
xdx
t
x
x
x
x
x
t
x
x
x
x
x
t
t
t
t
=
=
=
=
=
+
=
+


=
+
−




+
−
+
+


=
−
∫
∫
∫
 
 
5. 
[ ]
(
)
0
0
0
*
t
t
x t
at
at
ax
a t x
at
at
at
x
e
e
e e
dx
e dx
e
x
t e
=
−
=
=
=
=
=
∫
∫
 
 
6. 
(
)
(
)
0
0
*
t
t
at
bt
ax
b t x
bt
a b x
e
e
e e
dx
e
e
dx
−
−
=
=
∫
∫
 
 
(
)
(
)
(
)
0
1
x t
bt
a b t
a b x
at
bt
bt
x
e
e
e
e
e
e
a
b
a
b
a
b
=
−
−
=
−


−
=
=
=


−
−
−


 
 
7. 
(
)
3
3
3
3
0
1
( )
1*
*1
1
1
3
t
t
t
x
t
f t
e
e
e
dx
e
=
=
=
⋅
=
−
∫
 
 
8. 
(
)
0
1
1
1
( )
1*
sin2
sin 2
1
cos2
2
2
4
t
f t
t
x dx
t
=
=
=
−
⌠⌡
 
 
9. 
0
1
1
( )
sin3 *sin3
sin3 sin3(
)
9
9
t
f t
t
t
x
t
x dx
=
=
−
∫
 
 
[
]
(
)
0
2
0
0
2
0
0
1
sin3
sin3 cos3
cos3 sin3
9
1
1
sin3
sin3 cos3
cos3
sin 3
9
9
1
1
1
1
1
sin3
sin 3
cos3
sin6
9
6
9
2
6
1
( )
sin3
3 cos3
54
t
t
t
x t
x t
x
x
x
t
x
t
x dx
t
x
xdx
t
xdx
t
x
t
x
x
f t
t
t
t
=
=
=
=
=
−
=
−






=
−
−












=
−
∫
∫
∫
 
 
10. 
0
1
( )
*(sin
)/
sin
(
)
t
f t
t
kt
k
kx
t
x dx
k
=
=
⋅
−
∫
 

530 
Chapter 10 
 
3
0
0
1
sin
sin
sin
t
t
t
kt
kt
kxdx
x
kxdx
k
k
k
−
=
−
=
∫
∫
 
 
11. 
0
( )
cos2 *cos2
cos2 cos2(
)
t
f t
t
t
x
t
x dx
=
=
−
∫
 
 
(
)
(
)
0
2
0
0
2
0
0
cos2
cos2 cos2
sin2 sin2
(cos2 )
cos 2
(sin2 )
cos2 sin2
1
1
1
(cos2 )
sin4
(sin2 )
sin 2
2
4
4
1
( )
sin2
2 cos2
4
t
t
t
x t
x t
x
x
x
t
x
t
x dx
t
x dx
t
x
xdx
t
x
x
t
x
f t
t
t
t
=
=
=
=
=
+
=
+






=
+
+












=
+
∫
∫
∫
 
 
12. 
f(t)  =  (e-2tsin t)*(1)
2
2
0
1
sin
1
(cos
2sin )
5
t
x
t
e
x dx
e
t
t
−
−


=
=
−
+


∫
  
 
13. 
(
)
3
3(
)
0
( )
*cos
cos
t
t
t x
f t
e
t
x e
dx
−
=
= ∫
 
 
(
)
(
)
3
3
0
3
3
0
3
cos
3cos
sin
(byintegral formula #50)
10
1
( )
3
3cos
sin
10
t
t
x
x t
x
t
x
t
e
e
x dx
e
e
x
x
f t
e
t
t
−
=
−
=
=


=
−
+




=
−
+
∫
 
  
14. 
0
( )
cos2 *sin
cos2 sin(
)
t
f t
t
t
x
t
x dx
=
=
−
∫
 
 
(
)
0
0
0
cos2 (sin cos
cos sin )
(sin )
cos2 cos
cos
cos2 sin
t
t
t
x
t
x
t
x dx
t
x
xdx
t
x
x dx
=
−
=
−
∫
∫
∫
 
 
(
)
(
)
(
)
(
)
0
0
1
1
(sin )
cos3
cos
cos
sin3
sin
2
2
1
( )
cos
cos2
3
t
t
t
x
x dx
t
x
x dx
f t
t
t
=
+
−
−
=
−
∫
∫
 
 
15. 
(
)
(
)
2
2
2
3
6
{ sin }
{sin }
9
9
d
d
s
t
t
t
ds
ds
s
s


= −
= −
=


+


+
L
L
 
 

 
Section 10.4 
531 
16. 
(
)
(
)
2
2
2
2
3
2
2
2
2
2 (
12)
{ cos2 }
{cos2 }
4
4
d
d
s
s s
t
t
t
ds
ds
s
s
−


=
=
=


+


+
L
L
 
 
17. 
L{e2tcos 3t}   =  (s - 2)/(s2 - 4s + 13) 
 
L{te2tcos 3t}  =  -(d/ds)[(s - 2)/(s2 - 4s + 13)]  =  (s2 - 4s - 5)/(s2 - 4s + 13)2 
 
18. 
L{sin2t}  =  L{(1 - cos 2t)/2}  =  2/s(s2 + 4) 
 
L{e-tsin2t}  =  2/[(s + 1)(s2 + 2s + 5)] 
 
L{te-tsin2t}  =  -(d/ds)[2/((s + 1)(s2 + 2s + 5))]   
 
 
         =  2(3s2 + 6s + 7)/[(s + 1)2(s2 + 2s + 5)2] 
 
19. 
1
1
1
2
sin
1
tan
tan
tan
1
2
s
s
t
ds
s
s
t
s
s
π
∞
∞
−
−
−
⌠
⌡






=
=
=
−
=






+




L
 
 
20. 
{
}
2
1
1
cos2
, so
4
s
t
s
s
−
=
−
+
L
 
 
2
2
2
1
1
cos2
4
ln
ln
4
4
s
s
s
t
s
s
ds
s
s
t
s
s
∞
∞
⌠

⌡




−
+






−
=
=
=












+




+






L
 
 
 
21. 
{
}
3
1
1
1
, so
3
t
e
s
s
−
=
−
−
L
 
 
3
1
1
1
3
ln
ln
3
3
t
s
s
e
s
s
ds
t
s
s
s
s
∞
∞


−
−








=
−
=
=










−
−










⌠⌡
L
 
      
22. 
{
}
2
1
1
2
, so
1
1
1
t
t
e
e
s
s
s
−
−
=
−
=
−
+
−
L
 
 
1
1
1
1
ln
ln
1
1
1
1
t
t
s
s
e
e
s
s
ds
t
s
s
s
s
∞
∞
−


−
−
+








=
−
=
=










−
+
+
−










⌠⌡
L
 
 
23. 
{
}
(
)
1
1
2
2
1
1
1
1
1
2sinh2
( )
( )
2
2
t
t
t
f t
F s
e
e
t
t
s
s
t
t
−
−
−


′
= −
= −
−
= −
−
= −


−
+


L
L
 
 
24. 
{
}
(
)
1
1
2
2
1
1
2
2
2
( )
( )
cos2
cos
1
4
s
s
f t
F s
t
t
t
t
s
s
t
−
−

′
= −
= −
−
=
−


+
+


L
L
 
 

532 
Chapter 10 
25. 
{
}
(
)
1
1
2
3
2
1
1
2
1
1
1
( )
( )
2cos
1
2
3
t
t
s
f t
F s
e
e
t
t
t
s
s
s
t
−
−
−


′
= −
= −
−
−
=
+
−


+
+
−


L
L
 
 
26. 
{
}
(
)
2
1
1
2
1
1
3
sin3
( )
( )
2
9
t
e
t
f t
F s
t
t
t
s
−
−
−



′
= −
= −
−
=


+
+




L
L
 
 
27. 
{
}
3
1
1
2
1
1
2/
( )
( )
1 1/
s
f t
F s
t
t
s
−
−

−
′
= −
= −


+


L
L
 
 
(
)
1
1
3
2
2
1
2
1
2 1
cos
1
s
t
t
s
s
t
s
s
t
−
−




=
=
−
=
−




+
+




L
L
 
 
28. 
An empirical approach works best with this one.  We can construct transforms with 
powers of  (s2 + 1)  in their denominators by differentiating the transforms of  sin t  and   
 
cos t.  Thus,   
 
 
 
{
}
(
)
2
2
2
1
2
sin
1
1
d
s
t
t
ds
s
s


= −
=


+


+
L
 
 
 
 
{
}
(
)
2
2
2
2
1
cos
1
1
d
s
s
t
t
ds
s
s
−


= −
=


+


+
L
 
 
 
 
{
}
(
)
(
)
2
3
2
2
3
2
2
1
2
6
cos
.
1
1
d
s
s
s
t
t
ds
s
s


−
−


= −
=


+
+


L
 
 
 
From the first and last of these formulas it follows readily that 
 
 
 
 
(
)
(
)
1
2
3
2
1
sin
cos
.
8
1
s
t
t
t
t
s
−


=
−


+




L
 
 
 
Alternatively, one could work out the repeated convolution 
 
 
 
 
(
)
1
3
2
(cos )*(sin *sin ).
1
s
t
t
t
s
−


=


+




L
 
 
29. 
-[s2X(s) - x′(0)]′ - [s X(s)]′ - 2[s X(s)] + X(s)  =  0 
 
s(s + 1)X'(s) + 4s X(s)  =  0           
(separable) 

 
Section 10.4 
533 
 
X(s)  =  
4
(
1)
A
s +
  with  A  ≠  0 
 
x(t)   =  Ct3e-t  with   C  ≠  0 
   
30. 
-[s2X(s) - x'(0)]′ - 3[s X(s)]′ - [s X(s)] + 3X(s)  =  0 
 
-(s2 + 3s)X'(s) - 3s X(s)  =  0    
(separable) 
 
X(s)  =  
3
(
3)
A
s +
  with  A  ≠  0 
 
x(t)   =  Ct2e-3t with  C  ≠  0 
 
31. 
-[s2X(s) - x'(0)]′ + 4[s X(s)]′ - [s X(s)] -4[X(s)]′ + 2X(s)  =  0 
 
(s2 - 4s + 4)X'(s)+(3s - 6)X(s)  =  0     (separable) 
 
(s - 2)X'(s)+ 3X(s)  =  0 
 
X(s)  =  
3
(
2)
A
s −
  with   A  ≠  0 
 
x(t)   =  Ct2e2t  with   C  ≠  0 
 
32. 
-[s2X(s) - x'(0)]′ - 2[s X(s)]′ - 2[s X(s)] - 2X(s)  =  0 
 
-(s2 + 2s)X' (s) - (4s + 4)X(s)  =  0    (separable) 
 
X(s)  =  
2
2
2
2
1
1
1
1
(
2)
2
(
2)
A
C
s
s
s
s
s
s


=
−
−
−


+
+
+


 
 
x(t)  =  C(1 - t - e-2t - te-2t)  with  C  =  -A/4  ≠  0 
 
33. 
-[s2X(s) - x(0)]′ - 2[s X(s)] - [X(s)]′  =  0 
 
(s2 + 1)X'(s)+ 4s X(s)  =  0     (separable) 
 
X(s)  =  
2
2
(
1)
A
s +
  with  A  ≠  0 
 
x(t)  =  C(sin t - t cos t)  with  C  ≠  0 
 
34. 
-(s2 + 4s + 13)X'(s) - (4s + 8)X(s)  =  0 
 
X(s)  =  
2
2
2
2
(
4
13)
(
2)
9
C
C
s
s
s
=
+
+


+
+


 

534 
Chapter 10 
 
It now follows from Problem 31 in Section 10.2 that   
 
 
 
 
x(t)  =  Ae-2t(sin 3t - 3t cos 3t)  with  A  ≠  0. 
 
35. 
1
0
1
1
1
*
(
1)
t
t
t x
e
e
dx
s
s
t
x
π
π
−
−

=
=
⋅


−


⌠⌡
L
 
 
(
)
2
2
0
0
1
2
2
erf
t
t
t
t
u
u
t
e
e
e
udu
e
du
e
t
u
π
π
−
−
=
⋅
⋅
=
=
⌠⌡
∫
 
 
 
36. 
s2X(s) + 4X(s)  =  F(s) 
 
X(s)  =  
2
1
2
( )
2
4
F s
s
⋅
+
 
 
x(t)   =  
0
1
1
( )*sin 2
(
)sin 2
2
2
t
f t
t
f t
d
τ
τ τ
=
−
∫
 
 
37. 
2
( )
2
( )
( )
( )
s X s
sX s
X s
F s
+
+
=
 
 
2
1
( )
( ) (
1)
X s
F s
s
=
⋅
+
 
 
0
( )
*
( )
(
)
t
t
x t
te
f t
e
f t
d
τ
τ
τ
τ
−
−
=
=
−
∫
 
 
38. 
2
( )
4
( )
13
( )
( )
s X s
sX s
X s
F s
+
+
=
 
 
2
2
( )
1
3
( )
( )
4
13
3
(
2)
9
F s
X s
F s
s
s
s
=
=
⋅
+
+
+
+
 
 
(
)
2
2
0
1
1
( )
( )*
sin3
sin3
3
3
t
t
x t
f t
e
t
e
f t
d
τ
τ
τ τ
−
−
=
=
−
∫
 
 
 
 
SECTION 10.5 
 
PERIODIC AND PIECEWISE CONTINUOUS  
INPUT FUNCTIONS 
 
In Problems 1 through 10, we first derive the inverse Laplace transform  
( ) of
( )
f t
F s  and then 
show the graph of  
( ).
f t  
 

 
Section 10.5 
535 
1. 
{ }
3
( )
s
F s
e
t
−
=
L
  so  Eq. (3b) in Theorem 1 gives  
 
 
 
0 if
3,
( )
(
3) (
3)
3 if
3.
t
f t
u t
t
t
t
<

=
−
⋅
−
= −
≥

 
3
t
fHtL
 
 
2. 
0 if
1,
( )
(
1) (
1)
(
3) (
3)
1 if 1
3,
2 if
3.
t
f t
t
u t
t
u t
t
t
t
<


=
−
−
−
−
−
=
−
≤<


≥

 
1
3
t
2
fHtL
 
3. 
{
}
2
( )
s
t
F s
e
e
−
−
=
L
  so  
2(
1)
2(
1)
0 if
1,
( )
(
1)
if
1.
t
t
t
f t
u t
e
e
t
−
−
−
−
<

=
−
⋅
= 
≥

 
1
t
1
fHtL
 

536 
Chapter 10 
4. 
2
2
( )
{ }
{ }
s
s
F s
e
t
e e
t
−
−
=
−
L
L
so 
 
 
1
2
2
1
1
0 if
1,
( )
(
1)
(
2)
if 1
2,
if
2.
t
t
t
t
t
t
f t
e u t
e e
u t
e
t
e
e
t
−
−
−
−
<


=
−
−
−
=
≤<


−
≥

 
1
2
t
-10
-5
1
fHtL
 
 
5. 
( )
{sin }
s
F s
e
t
π
−
=
L
  so   
 
 
0 if
,
( )
(
) sin(
)
(
)sin
sin
if
.
t
f t
u t
t
u t
t
t
t
π
π
π
π
π
<

=
−
⋅
−
= −
−
= −
≥

 
 
p
3 p
5 p t
-1
1
fHtL
 
 
 
6. 
( )
{cos
}
s
F s
e
t
π
−
=
L
  so   
 
 
0 if
1,
( )
(
1) cos (
1)
(
1)cos
cos
if
1.
t
f t
u t
t
u t
t
t
t
π
π
π
<

=
−
⋅
−
= −
−
= −
≥

 
 
7. 
2
( )
{sin }
{sin }
s
F s
t
e
t
π
−
=
−
L
L
  so   
 
 
[
]
sin
if
2 ,
( )
sin
(
2 )sin(
2 )
1
(
2 ) sin
0 if
2 .
t
t
f t
t
u t
t
u t
t
t
π
π
π
π
π
<

=
−
−
−
=
−
−
= 
≥

 

 
Section 10.5 
537 
The left-hand figure below is the graph for Problem 6 on the preceding page, and the right-hand 
figure is the graph for Problem 7. 
 
 
 
 
 
 
 
 
 
 
 
 
 
8. 
2
( )
{cos
}
{cos
}
s
F s
t
e
t
π
π
−
=
−
L
L
  so   
 
 
[
]
cos
if
2,
( )
cos
(
2)cos (
2)
1
(
2) cos
0 if
2.
t
t
f t
t
u t
t
u t
t
t
π
π
π
π
<

=
−
−
−
=
−
−
= 
≥

 
2
t
-1
1
fHtL
 
 
9. 
3
( )
{cos
}
{cos
}
s
F s
t
e
t
π
π
−
=
+
L
L
  so   
 
 
[
]
cos
if
3,
( )
cos
(
3)cos (
3)
1
(
3) cos
0 if
3.
t
t
f t
t
u t
t
u t
t
t
π
π
π
π
<

=
+
−
−
=
−
−
= 
≥

 
3
t
-1
1
fHtL
 
1
2
3
4
5
t
-1
1
fHtL
p
2 p
t
-1
1
fHtL

538 
Chapter 10 
10. 
2
( )
{2cos2 }
{2cos2 }
s
s
F s
e
t
e
t
π
π
−
−
=
+
L
L
  so   
 
 
[
]
( )
2 (
)cos2(
)
2 (
2 )cos2(
2 )
0 if
or
2 ,
2
(
)
(
2 ) cos2
2cos2
if
2 .
f t
u t
t
u t
t
t
t
u t
u t
t
t
t
π
π
π
π
π
π
π
π
π
π
=
−
−
−
−
−
<
≥

=
−
−
−
= 
≤<

 
 
p
2 p
t
-2
2
fHtL
 
 
11. 
(
)
3
3
2
2
2
( )
2
(
3) 2 so
( )
1
.
s
s
f t
u t
F s
e
e
s
s
s
−
−
=
−
−
⋅
=
−
=
−
 
 
12. 
(
)
3
3
1
( )
(
1)
(
4) so
( )
.
s
s
s
s
e
e
f t
u t
u t
F s
e
e
s
s
s
−
−
−
−
=
−
−
−
=
−
=
−
 
 
13. 
( )
[1
(
2 )]sin
sin
(
2 )sin(
2 ) so
f t
u t
t
t
u t
t
π
π
π
=
−
−
=
−
−
−
 
 
2
2
2
2
2
1
1
1
( )
.
1
1
1
s
s
e
F s
e
s
s
s
π
π
−
−
−
=
−
⋅
=
+
+
+
 
 
14. 
( )
[1
(
2)]cos
cos
(
2)cos (
2) so
f t
u t
t
t
u t
t
π
π
π
=
−
−
=
−
−
−
 
 
(
)
2
2
2
2
2
2
2
2
1
( )
.
s
s
s
e
s
s
F s
e
s
s
s
π
π
π
−
−
−
=
−
⋅
=
+
+
+
 
 
15. 
( )
[1
(
3 )]sin
sin
(
3 )]sin(
3 ) so
f t
u t
t
t
u t
t
π
π
π
=
−
−
=
+
−
−
 
 
3
3
2
2
2
1
1
( )
.
1
1
1
s
s
e
e
F s
s
s
s
π
π
−
−
+
=
+
=
+
+
+
 
 
16. 
( )
[ (
)
(
2 )]sin 2
(
)sin2(
)
(
2 )sin2(
2 ) so
f t
u t
u t
t
u t
t
u t
t
π
π
π
π
π
π
=
−
−
−
=
−
−
−
−
−
 
 
(
)
(
)
2
2
2
2
2
2
( )
.
4
4
s
s
s
s
e
e
F s
e
e
s
s
π
π
π
π
−
−
−
−
−
=
−
⋅
=
+
+
 
 

 
Section 10.5 
539 
17. 
( )
[ (
2)
(
3)]sin
(
2)sin (
2)
(
3)sin (
3) so
f t
u t
u t
t
u t
t
u t
t
π
π
π
=
−
−
−
=
−
−
+
−
−
 
 
(
)
(
)
2
3
2
3
2
2
2
2
( )
.
s
s
s
s
e
e
F s
e
e
s
s
π
π
π
π
−
−
−
−
+
=
+
⋅
=
+
+
 
 
18. 
( )
[ (
3)
(
5)]cos
(
3)sin
(
3)
(
5)sin
(
5) so
2
2
2
t
f t
u t
u t
u t
t
u t
t
π
π
π
=
−
−
−
=
−
−
+
−
−
 
 
(
)
(
)
3
5
3
5
2
2
2
2
2
/ 2
( )
.
/ 4
4
s
s
s
s
e
e
F s
e
e
s
s
π
π
π
π
−
−
−
−
+
=
+
⋅
=
+
+
 
 
19. 
If
( )
1 then
( )
(
1)
(
1)
(
1) so
g t
t
f t
u t
t
u t
g t
=
+
=
−
⋅
=
−
⋅
−
 
 
2
2
1
1
(
1)
( )
( )
{
1}
.
s
s
s
s
e
s
F s
e G s
e L t
e
s
s
s
−
−
−
−
+


=
=
+
=
⋅
+
=




 
 
20.  
If
( )
1
g t
t
= + then  
[
]
( )
1
(
1)
(
1)
(
1) (
1)
(
1) so
f t
u t
t
u t
t
u t
g t
u t
=
−
−
+
−
=
−
−
−
+
−
 
 
2
2
2
2
1
1
1
1
1
( )
( )
.
s
s
s
s
s
e
e
e
F s
e
G s
e
s
s
s
s
s
s
s
−
−
−
−
−
−


=
−
⋅
+
=
−
⋅
+
+
=




 
 
21. 
If
( )
1 and
( )
2
g t
t
h t
t
= +
= +
  then   
 
 
[
]
[
]
( )
1
(
1)
(2
)
(
1)
(
2
2
(
1)
2 (
1)
2 (
2)
(
2)
2 (
1) (
1)
2 (
1)
2 (
2)
(
2) (
2)
f t
t
u t
t
u t
u t
t
t u t
u t
u t
t u t
t
u t
g t
u t
u t
u t
h t
=
−
−
+
−
−
−
−
=
−
−
+
−
−
−
+
−
=
−
−
−
+
−
−
−
+
−
−
 
 
so 
 
 
(
)
2
2
2
2
2
2
2
1
1
1
1
2
2
1
2
( )
2
.
s
s
s
s
s
e
e
e
F s
e
e
s
s
s
s
s
s
s
s
−
−
−
−
−
−




=
−
+
+
−
+
+
=








 
 
22. 
f(t)  =  [u1(t) - u2(t)] t3  =  u1(t)g(t - 1) - u2(t)h(t - 2)   where   
 
 
 
 
g(t)  =  (t + 1)3  =  t3 + 3t2 + 3t + 1, 
 
 
 
h(t)  =  (t + 2)3  =  t3 + 6t2 + 12t + 8.  
 
It follows that 
 
 
F(s)  =  e-sG(s) - e-2sH(s) 
 
 
         =  [(s3 + 3s2 + 6s + 6)e-s - (8s3 + 12s2 + 12s + 6)e-2s]/s4. 
 
23. 
With  
( )
1 and
1
f t
p
=
= , Formula (6) in the text gives 
 
 
 
 
1
1
0
0
1
1
1
{1}
1
.
1
1
t
st
st
s
s
t
e
e
dt
e
e
s
s
=
−
−
−
−
=


=
⋅
=
−
=


−
−


∫
L
 

540 
Chapter 10 
24. 
With  f(t)  =  cos kt  and  p  =  2π/k,  Formula (6) and the integral formula 
 
 
 
 
2
2
cos
sin
cos
at
at a
bt
b
bt
e
bt dt
e
C
a
b
+


=
+


+


∫
 
 
give 
 
 
 
2
/
2
/
0
2
/
2
/
2
2
0
2
/
0
2
/
2
2
2
2
1
{cos
}
cos
1
1
cos
sin
1
1
(
)
.
1
k
st
s k
t
k
st
s k
t
s k
s k
kt
e
kt dt
e
s
kt
k
kt
e
e
s
k
s
s
e
e
s
e
s
k
s
k
π
π
π
π
π
π
−
−
=
−
−
=
−
−
−
=
⋅
−
−
+




=




−
+




−




=
−
−
=




−
+
+




∫
L
 
 
 
 
 
25. 
With  p  =  2a  and  f(t)  =  1  if  0 ≤ t ≤ a,  f(t)  =  0  if   a < t ≤ 2a,  Formula (6) gives 
 
 
 
 
2
2
0
0
1
1
{ ( )}
1
1
1
t a
st
a
st
as
as
t
e
f t
e
dt
e
e
s
=
−
−
−
−
=


=
⋅
=
−


−
−


∫
L
 
 
 
 
(
)(
)
(
)
1
1
.
1
1
1
as
as
as
as
e
s
e
e
s
e
−
−
−
−
−
=
=
−
+
+
 
 
26. 
With  p  =  a  and  f(t)  =  t/a,  Formula (6) and the integral formula 
(
1)
u
u
ue du
u
e
=
−
∫
 
(with  u
st
= −
) give 
 
 
 
(
)
(
)
0
0
1
1
{ ( )}
1
1
as
a
st
u
as
as
u
du
f t
e
t dt
e
s
s
a
e
a
e
−
−
−
−



=
⋅
=
⋅−
−



−
−



⌠⌡
∫
L
 
 
 
 
(
)
(
) (
)
2
2
0
0
1
1
1
1
1
as
as
u
u
as
as
e udu
u
e
as
e
as
e
−
−
−
−


=
=
−


−
−
∫
 
 
 
 
(
) (
)
(
)
2
2
1
1
1
1
.
1
1
as
as
as
as
e
as
e
as
as
e
s
e
−
−
−
−


=
−
−
+
=
−


−
−
 
 
27. 
G(s)  =  {
}
/
( )
t a
f t
−
L
  =  (1/as2) - F(s).  Now substitution of the result of Problem 26 
in place of  F(s)  immediately gives the desired transform. 
 
28. 
This computation is very similar to the one in Problem 26, except that  p = 2a: 
 
2
2
0
0
1
1
{ ( )}
1
1
as
a
st
u
as
as
u
du
f t
e
t dt
e
e
e
s
s
−
−
−
−



=
⋅
=
⋅−
−



−
−



⌠⌡
∫
L
 
 
 
 
(
)
(
) (
)
2
2
2
2
0
0
1
1
1
1
1
as
as
u
u
as
as
e udu
u
e
s
e
s
e
−
−
−
−


=
=
−


−
−
∫
 

 
Section 10.5 
541 
 
 
 
(
) (
)
(
)
2
2
2
2
1
1
(1
)
1
1
.
1
1
as
as
as
as
e
as
as
e
s
e
s
e
−
−
−
−
−
+


=
−
−
+
=


−
−
 
 
29. 
With  p  =  2π/k  and  f(t)  =  sin kt  for 0 ≤ t ≤ π/k  while  f(t)  =  0  for  π/k ≤ t ≤ 2π/k,  
Formula (6) and the integral formula 
 
 
 
 
2
2
sin
cos
sin
at
at a
bt
b
bt
e
bt dt
e
C
a
b
−


=
+


+


∫
 
 
give 
 
 
 
/
2
/
0
1
{ ( )}
sin
1
k
st
s k
f t
e
kt dt
e
π
π
−
−
=
⋅
−
∫
L
 
 
 
 
/
2
/
2
2
0
1
sin
cos
1
t
k
st
s k
t
s
kt
k
kt
e
e
s
k
π
π
=
−
−
=
−
−




=




−
+




 
 
 
 
( )
/
2
/
2
2
(
)
1
1
s k
s k
e
k
k
e
s
k
π
π
−
−


−−
=


−
+


 
 
 
 
(
)
(
)(
)(
)
(
)(
)
/
/
/
2
2
2
2
/
1
.
1
1
1
s k
s k
s k
s k
k
e
k
e
e
s
k
s
k
e
π
π
π
π
−
−
−
−
+
=
=
−
+
+
+
−
 
 
30. 
( )
( )
( )
( )
(
/ ) (
/ ),
h t
f t
g t
f t
u t
k f t
k
π
π
=
+
=
+
−
−
so Problem 29 gives 
 
 
(
)
(
) (
)(
)
/
/
/
/ 2
/
2
2
/
/ 2
2
2
/
( )
( )
( )
1
( )
1
1
1
1
s k
s k
s k
s
k
s k
s k
s
k
s k
H s
F s
e
F s
e
F s
k
k
e
e
e
s
k
e
e
s
k
e
π
π
π
π
π
π
π
π
−
−
−
−
−
−
=
+
=
+
+
=
+
⋅
=
⋅
⋅
+
−
+
−
 
 
 
/ 2
/ 2
2
2
/ 2
/ 2
2
2
2
2
cosh(
/ 2 )
coth
.
sinh(
/ 2 )
2
s
k
s
k
s
k
s
k
k
e
e
k
s
k
k
s
s
k
e
e
s
k
s
k
s
k
k
π
π
π
π
π
π
π
−
−
+
=
⋅
=
=
+
−
+
+
 
 
In Problems 31–42, we first write and transform the appropriate differential equation.  Then we 
solve for the transform of the solution, and finally inverse transform to find the desired solution. 
 
31. 
x'' + 4x  =  1 - u(t – π) 
 
s2X(s) + 4X(s)  =  1
s
e
s
π
−
−
 
 
X(s)  =  (
)
(
)
2
2
1
1
1
1
4
4
4
s
s
e
s
e
s
s
s s
π
π
−
−
−


=
−
−


+
+


 
 
x(t)  =  (1/4)[1 - u(t – π)][1 - cos 2(t - π)]  =  (1/2)[1 - u(t – π)]sin2t 
 
The graph of  the position function ( )
x t  is shown at the top of the next page. 

542 
Chapter 10 
p
t
1
2
xHtL
 
 
32. 
x'' + 5x' + 4x  =  1 - u(t – 2) 
 
s2X(s) + 5s X(s) + 4X(s)  =  
2
1
s
e
s
−
−
 
 
X(s)  =  (
)
2
2
1
5
4
s
e
s s
s
−
−
+
+
  =  (1 - e-2s)G(s) 
 
where 
 
 
(
)
4
1
3
4
1
1
( )
, so
( )
3
4
.
12
1
4
12
t
t
G s
g t
e
e
s
s
s
−
−


=
−
+
=
−
+


+
+


 
 
It follows that 
  
 
( ) if
2,
( )
( )
(
2) (
2)
( )
(
2) if
2.
g t
t
x t
g t
u t
g t
g t
g t
t
<

=
−
−
−
= 
−
−
≥

 
 
2
4
t
0.1
0.2
xHtL
 
 
 
33. 
x'' + 9x  =  [1 - u(t – 2π)]sin t 

 
Section 10.5 
543 
p
2 p
t
-0.1
0.1
xHtL
 
X(s)  =  (
)(
)
(
)
2
2
2
2
2
2
1
1
1
1
1
8
1
9
1
4
s
s
e
e
s
s
s
s
π
π
−
−
−


=
−
−


+
+
+
+


 
 
x(t)   =  [
]
1
1
1
(
2 )
sin
sin3
8
3
u t
t
t
π


−
−
−




 
 
The left-hand figure below show the graph of this position function. 
 
 
 
 
 
 
 
 
 
 
34. 
x'' + x  =  [1 - u(t – 1)] t  
1
(
1) (
1),
where
( )
1
u t
f t
f t
t
=
−
−
−
=
+  
 
s2X(s) + X(s)  =  
2
2
2
1
1
1
1
( )
s
s
e G s
e
s
s
s
s
−
−

−
=
−
+




 
 
It follows that 
 
 
 
2
2
2
2
2
2
2
1
(
1)
( )
(
1)
(
1)
1
1
1
(1
)
(1
) ( )
( )
1
1
s
s
s
s
s
e
s
X s
s
s
s
s
s
e
e
e
G s
e H s
s
s
s
s
−
−
−
−
−
+
=
−
+
+




=
−
−
−
−
=
−
−




+
+




 
 
where  g(t)  =  t - sin t,  h(t)  =  1 - cos t.  Hence 
      
 
 
 
x(t)  =  g(t) - u(t – 1)g(t - 1) - u(t – 1)h(t - 1) 
 
and so 
 
 
 
x(t)  =  t - sin t  if t < 1, 
 
 
 
x(t)  =  -sin t + sin(t - 1) + cos(t - 1)  if  t > 1. 
 
 
 
The right-hand figure above shows the graph of this position function. 
 
35. 
x″ + 4x′ + 4x  =  [1 - u(t – 2)]t  =  t - u(t – 2)g(t – 2)  where  ( )
2
g t
t
= +
 
 
(s + 2)2X(s)  =  
2
2
2
1
2
1
s
e
s
s
s
−

−
+




 
1
1 + 2 p
1 + 4 p t
-0.5
0.5
xHtL

544 
Chapter 10 
 
 
(
)
(
)
2
2
2
2
2
1
2
1
( )
2
2
s
s
X s
e
s
s
s
s
−
+
=
−
+
+
 
 
(
)
(
)
2
2
2
2
2
1
1
1
1
1
1
1
1
1
3
4
2
4
2
2
2
s
e
s
s
s
s
s
s
s
s
−




=
−
+
+
+
−
+
−
−








+
+
+
+




 
 
x(t)  =  (1/4){-1 + t + (1 + t)e-2t + u(t –2)[1 – t + (3t - 5)e-2(t-2)]} 
 
               
2
4
t
1
4
xHtL
 
 
 
36. 
x'' + 4x  =  f(t),       x(0)  =  x'(0)  =  0 
 
 
(
)
(
)
(
)
2
4 1
4
( )
1
s
s
e
s
X s
s
e
π
π
−
−
−
+
=
+
  
 
(by Example 5 of Section 10.5) 
 
(
)
2
1
4
8
4
( )
( 1)n
n s
n
s
X s
e
s
s
π
∞
−
=
+
=
+
−
∑
  
(as in Eq. (10) of Section 10.5) 
 
Now let 
 
 
 
1
2
2
4
( )
1
cos2
2sin
.
(
4)
g t
t
t
s s
−

=
=
−
=


+


L
 
 
Then it follows that 
 
 
2
2
1
1
( )
( )
2
( 1)
( ) (
)
2sin
4
( 1)
( )sin
.
n
n
n
n
n
n
x t
g t
u
t g t
n
t
u
t
t
π
π
π
∞
∞
=
=
=
+
−
−
=
+
−
∑
∑
 
 
Hence 
 
 
 
2
2
2sin
if 2
(2
1) ,
( )
2sin
if (2
1)
2
.
t
n
t
n
x t
t
n
t
n
π
π
π
π

≤<
+
= −
−
≤<

 
 

 
Section 10.5 
545 
 
Consequently the complete solution 
 
 
 
 
 
( )
2 sin sin
x t
t
t
=
 
 
 
is periodic, so the transient solution is zero.  The graph of  ( ) :
x t
 
 
 
2 p
4 p
6 p t
-2
2
xHtL
 
 
 
 
37. 
x'' + 2x' + 10x  =  f(t),      x(0)  =  x'(0)  =  0 
 
 
 
As in the solution of Example 7 we find first that 
 
 
 
(
)
2
1
10
20
2
10
( )
( 1)
,
n
n s
n
s
s
X s
e
s
s
π
∞
−
=
+
+
=
+
−
∑
 
 
so 
 
 
 
2
2
1
10
10( 1)
( )
2
.
(
2
10)
(
2
10)
n
n s
n
e
X s
s s
s
s s
s
π
−
∞
=
−
=
+
+
+
+
+
∑
 
 
If 
 
 
 
(
)
1
2
10
1
( )
1
3cos3
sin3 ,
3
(
1)
9
t
g t
e
t
t
s
s
−
−




=
=
−
+




+
+






L
 
 
then it follows that 
 
 
 
 
1
( )
( )
2
( 1)
( ) (
).
n
n
n
x t
g t
u
t g t
n
π
π
∞
=
=
+
−
−
∑
 
 
 
The graph of  ( )
x t  appears at the top of the next page. 
 

546 
Chapter 10 
2 p
4 p
6 p
t
-2
2
xHtL
 
 
 
38. 
If the function  ( )
x t  satisfies the initial value problem 
 
 
 
 
0
1
( ),
( )
,
( )
mx
cx
kx
F t
x a
b
x a
b
′′
′
′
+
+
=
=
=
 
 
 
for  t
a
≥
  and  ( )
0
x t =
 for  
,
t
a
<
 then we may write  ( )
(
) (
)
x t
u t
a z t
a
=
−
−
 where the 
 
function  ( )
z t  satisfies the initial value problem   
 
 
 
 
0
1
(
),
(0)
,
( )
.
mz
cz
kz
F t
a
z
b
z a
b
′′
′
′
+
+
=
+
=
=
 
 
 
Then  
( )
{ ( )}
Z s
z t
= L
  satisfies the equation 
 
 
 
(
)
(
)
(
)
2
0
1
0
( )
( )
( )
{ (
)}.
m s Z s
sb
b
c sZ s
b
k Z s
F t
a
−
−
+
−
+
=
+
L
 
 
(*) 
 
Now 
 
 
( )
{ ( )}
{ (
) (
)}
( )
as
X s
x t
u t
a z t
a
e
Z s
−
=
=
−
−
=
L
L
 
 
 
by Theorem 1 in Section 10.5.  Substitution of  
( )
( )
as
Z s
e X s
=
 into Eq. (*) then gives the 
 
desired result. 
 
39. 
When we substitute the inverse Laplace transforms  ( ),
( ),
( )
a t
b t
c t   given at the 
 
beginning of part (c), we get   
 
 
 
(
)
(
)
0
1
2
1
0
1
4
( )
( )
( )
( )
4cos4
2sin4
sin 4
4
4cos4
2sin4
.
t
v t
b a t
b b t
c t
e
b
t
t
b
t
t
t
−
=
+
+
=
+
+
+
−
−




 
 
 
Similarly, Theorem 1 in this section gives 

 
Section 10.5 
547 
 
 
 
[
]
{
}
[
]
(
)
(
)
1
0
1
0
1
2(
)
1
0
1
4
2(
)
( )
( )
( )
( )
(
)
(
)
(
)
(
)
4cos4(
)
2sin4(
)
sin4(
)
4
4cos4(
)
2sin4(
)
(
).
s
t
t
w t
L
e
c A s
c B s
C s
u t
c a t
c b t
c t
e
c
t
t
c
t
e
t
t
u t
π
π
π
π
π
π
π
π
π
π
π
π
π
−
−
−
−
−
=
+
−
=
−
−
+
−
−
−
=
−
+
−
+
−
−


−
−
−
−
⋅
−

 
 
 
where as usual  (
)
( )
u t
u
t
π
π
−
=
 denotes the unit stop function at  .
π   Then the four 
 
continuity equations listed in part (c) yield the equations 
 
 
 
 
2
2
2
0
0
1
1
2
2
2
0
0
1
1
1
,
,
1
,
e
b
e
c
e
b
c
e
c
e
b
e
c
b
π
π
π
π
π
π
−
−
−
−
−
−
+ −
=
=
−+
=
=
  
 
 
that we solve readily for 
 
 
 
2
0
0
1
1
2
1
0.996372,
0.
1
e
b
c
b
c
e
π
π
−
= −
=
≈−
=
=
+
 
 
 
Finally, these values for the coefficients yield 
 
 
 
(
)
(
)
2(
)
2
2
( )
1
2cos4
sin4
1
0.9981
2cos4
sin4
,
1
t
t
e
v t
t
t
e
t
t
e
π
π
−
−
−
=
−
+
≈
−
+
+
 
 
 
 
(
)
(
)
2(
2 )
2
2(
)
( )
1
2cos4
sin4
(
)
1
1
0.9981
2cos4
sin4
(
).
t
t
e
w t
t
t
u t
e
e
t
t
u t
π
π
π
π
π
−
−
−
−


= −
−
+
−


+




≈−
−
+
−


 

548 
Chapter 11 
CHAPTER 11 
 
POWER SERIES METHODS 
 
 
SECTION 11.1 
 
INTRODUCTION AND REVIEW OF POWER SERIES 
 
The power series method consists of substituting a series  y = Σcnxn  into a given differential 
equation in order to determine what the coefficients  {cn}  must be in order that the power series 
will satisfy the equation.  It might be pointed out that, if we find a recurrence relation in the form  
cn+1  =  φ(n)cn,  then we can determine the radius of convergence  ρ  of the series solution directly 
from the recurrence relation, 
1
1
lim
lim
.
( )
n
n
n
n
c
c
n
ρ
φ
→∞
→∞
+
=
=
 
 
In Problems 1–10 we give first that recurrence relation that can be used to find the radius of 
convergence and to calculate the succeeding coefficients  
1
2
3
,
,
,
c c
c  in terms of the arbitrary 
constant  c0.  Then we give the series itself 
 
1. 
1
;
1
n
n
c
c
n
+
=
+
   it follows that  
0 and
lim(
1)
!
n
n
c
c
n
n
ρ
→∞
=
=
+
= ∞. 
   
2
3
4
2
3
4
0
0
0
( )
1
1
2
6
24
1!
2!
3!
4!
x
x
x
x
x
x
x
x
y x
c
x
c
c e




=
+
+
+
+
+
=
+
+
+
+
+
=










 
 
2. 
1
4
;
1
n
n
c
c
n
+
=
+
   it follows that  
0
4
1
and
lim
!
4
n
n
n
c
n
c
n
ρ
→∞
+
=
=
= ∞. 
   
3
4
2
0
2
2
3
3
4
4
4
0
0
32
32
( )
1
4
8
3
4
4
4
4
4
1
1!
2!
3!
4!
x
x
x
y x
c
x
x
x
x
x
x
c
c e


=
+
+
+
+
+






=
+
+
+
+
+
=






 
 
3. 
(
)
1
3
;
2
1
n
n
c
c
n
+
= −
+
   it follows that  
(
)
(
)
0
1
3
2
1
and
lim
2
!
3
n
n
n
n
n
c
n
c
n
ρ
→∞
−
+
=
=
= ∞. 
   
2
3
4
0
3
9
9
27
( )
1
2
8
16
128
x
x
x
x
y x
c 

=
−
+
−
+
−





 
 
 

 
Section 11.1 
549 
 
2
2
3
3
4
4
3 / 2
0
0
2
3
4
3
3
3
3
1
1!2
2!2
3!2
4!2
x
x
x
x
x
c
c e−


=
−
+
−
+
−
=





 
 
4. 
When we substitute  y  =  Σcnxn  into the equation  y' + 2xy  =  0,  we find that 
 
 
 
[
]
1
1
2
0
(
2)
2
0.
n
n
n
n
c
n
c
c
x
∞
+
+
=
+
+
+
=
∑
 
 
Hence  c1  =  0 — which we see by equating constant terms on the two sides of this 
equation — and  
2
2
.
2
n
n
c
c
n
+
= −
+
  It follows that   
 
 
1
3
5
odd
0
c
c
c
c
=
=
=
=
=

   and   
0
2
( 1)
.
!
k
k
c
c
k
−
=
 
 
Hence  
 
 
2
4
6
2
4
6
2
0
0
0
( )
1
1
2
3
1!
2!
3!
x
x
x
x
x
x
y x
c
x
c
c e−




=
−
+
−
+
=
−
+
−
+
=










 
 
and  
.
ρ = ∞ 
 
5. 
When we substitute  y  =  Σcnxn  into the equation  
2 ,
y
x y
′ =
 we find that 
 
 
 
[
]
1
1
2
3
0
2
(
3)
0.
n
n
n
n
c
c x
n
c
c
x
∞
+
+
=
+
+
+
−
=
∑
 
 
Hence  c1  =  c2  =  0 — which we see by equating constant terms and  x-terms on the two 
sides of this equation — and  
3
.
3
nc
c
n
=
+
  It follows that   
 
 
c3k+1  =  c3k+2  =  0     and    
0
0
3
.
3 6
(3 )
!3
k
k
c
c
c
k
k
=
=
⋅⋅
⋅

 
 
Hence  
 
 
3
3
6
9
3
6
9
(
/3)
0
0
0
2
3
( )
1
1
.
3
18
162
1!3
2!3
3!3
x
x
x
x
x
x
x
y x
c
c
c e




=
+
+
+
+
=
+
+
+
+
=










 
 
and  
.
ρ = ∞ 
 
6. 
1
;
2
n
n
c
c +
=
   it follows that  
0 and
lim2
2.
2
n
n
n
c
c
ρ
→∞
=
=
=
 
   
2
3
4
0
( )
1
2
4
8
16
x
x
x
x
y x
c 

=
+
+
+
+
+





 

550 
Chapter 11 
 
2
3
4
0
0
0
2
1
2
2
2
2
2
1
2
x
x
x
x
c
c
c
x
x










=
+
+
+
+
+
=
=










−












−

 
 
7. 
1
2
;
n
n
c
c
+
=
   it follows that  
0
1
1
2
and
lim
.
2
2
n
n
n
c
c
ρ
→∞
=
=
=
 
   
(
)
2
3
4
0
( )
1
2
4
8
16
y x
c
x
x
x
x
=
+
+
+
+
+
 
 
(
) (
)
(
)
(
)
2
3
4
0
0 1
2
2
2
2
1
2
c
c
x
x
x
x
x


=
+
+
+
+
+
=


−

 
 
8. 
1
(2
1)
;
2
2
n
n
n
c
c
n
+
−
= −
+
   it follows that  
2
2
lim
1.
2
1
n
n
n
ρ
→∞
+
=
=
−
 
   
2
3
4
0
5
( )
1
2
8
16
128
x
x
x
x
y x
c 

=
+
−
+
−
+





 
 
Separation of variables gives  
0
( )
1
.
y x
c
x
=
+
 
 
9. 
1
(
2)
;
1
n
n
n
c
c
n
+
+
=
+
   it follows that  
0
(
1)
nc
n
c
=
+
  and  
1
lim
1.
2
n
n
n
ρ
→∞
+
=
=
+
 
   
(
)
2
3
4
0
( )
1
2
3
4
5
y x
c
x
x
x
x
=
+
+
+
+
+ 
 
 
Separation of variables gives  
0
2
( )
.
(1
)
c
y x
x
=
−
 
 
10. 
1
(2
3)
;
2
2
n
n
n
c
c
n
+
−
=
+
   it follows that  
2
2
lim
1.
2
3
n
n
n
ρ
→∞
+
=
=
−
 
   
2
3
4
0
3
3
3
( )
1
2
8
16
128
x
x
x
x
y x
c 

=
−
+
+
+
+





 
 
Separation of variables gives  
3/ 2
0
( )
(1
)
.
y x
c
x
=
−
 
 
In Problems 11–14 the differential equations are second-order, and we find that the two initial 
coefficients  c0  and  c1  are both arbitrary.  In each case we find the even-degree coefficients in 
terms of  c0  and the odd-degree coefficients in terms of  c1.  The solution series in these 
problems are all recognizable power series that have infinite radii of convergence. 
 
11. 
1
;
(
1)(
2)
n
n
c
c
n
n
+
=
+
+
   it follows that  
0
2
(2 )!
k
c
c
k
=
  and  
1
2
1
.
(2
1)!
k
c
c
k
+
=
+
 
 
2
4
6
3
5
7
0
1
0
1
( )
1
cosh
sinh
2!
4!
6!
3!
5!
7!
x
x
x
x
x
x
y x
c
c
x
c
x
c
x




=
+
+
+
+
+
+
+
+
+
=
+










 

 
Section 11.1 
551 
 
12. 
1
4
;
(
1)(
2)
n
n
c
c
n
n
+
=
+
+
   it follows that  
2
0
2
2
(2 )!
k
k
c
c
k
=
  and  
2
1
2
1
2
.
(2
1)!
k
k
c
c
k
+
=
+
 
 
4
6
3
5
7
2
0
1
2
4
2
2
4
( )
1
2
3
45
3
15
315
x
x
x
x
x
y x
c
x
c
x




=
+
+
+
+
+
+
+
+
+










 
 
2
4
6
3
5
7
1
0
(2 )
(2 )
(2 )
(2 )
(2 )
(2 )
1
(2 )
2!
4!
6!
2
3!
5!
7!
x
x
x
c
x
x
x
c
x




=
+
+
+
+
+
+
+
+
+










 
 
1
0 cosh2
sinh2
2
c
c
x
x
=
+
 
 
13. 
 
1
9
;
(
1)(
2)
n
n
c
c
n
n
+
= −
+
+
  it follows that  
2
0
2
( 1) 3
(2 )!
k
k
k
c
c
k
−
=
  and  
2
1
2
1
( 1) 3
.
(2
1)!
k
k
k
c
c
k
+
−
=
+
 
 
2
4
6
3
5
7
0
1
9
27
81
3
27
81
( )
1
2
8
80
2
40
560
x
x
x
x
x
x
y x
c
c
x




=
−
+
−
+
+
−
+
−
+










 
 
2
4
6
3
5
7
1
0
(3 )
(3 )
(3 )
(3 )
(3 )
(3 )
1
(3 )
2!
4!
6!
3
3!
5!
7!
x
x
x
c
x
x
x
c
x




=
−
+
−
+
+
−
+
−
+










 
 
1
0 cos3
sin
3
c
c
x
x
=
+
 
 
14. 
When we substitute  y  =  Σcnxn  into  y'' + y − x  =  0  and split off the terms of degrees 0 
and 1, we get 
 
 
(2c2 + c0) + (6c3 + c1 − 1) x + 
2
2
[(  
 1)(  
 2)
 
]
= 0. 
n
n
n
n
n
n
c
c
x
∞
+
=
+
+
+
∑
 
 
Hence  
0
1
2
3
2
1
,
, and
for
2.
2
6
(
1)(
2)
n
n
c
c
c
c
c
c
n
n
n
+
−
= −
= −
= −
≥
+
+
  It follows that 
 
 
(
)
(
)
2
4
6
3
5
7
0
0
1
1
2
4
6
3
5
7
0
1
( )
1
2!
4!
6!
3!
5!
7!
1
1
2!
4!
6!
3!
5!
7!
x
x
x
x
x
x
y x
c
c
c x
c
x
x
x
x
x
x
x
c
c
x




=
+
−
+
−
+
+
+
−
−
+
−
+












=
+
−
+
−
+
+
−
−
+
−
+












 
 
 
0
1
cos
(
1)sin .
x
c
x
c
x
=
+
+
−
 
 
15. 
Assuming a power series solution of the form  y  =  Σcnxn,  we substitute it into the 
differential equation  
0
xy
y
′ +
=
 and find that  (n + 1)cn  =  0  for all  n  ≥  0.  This 
implies that  cn  =  0  for all  n  ≥  0,  which means that the only power series solution of 
our differential equation is the trivial solution  ( )
0.
y x ≡
 Therefore the equation has no 
non-trivial power series solution. 
 

552 
Chapter 11 
16. 
Assuming a power series solution of the form  y  =  Σcnxn,  we substitute it into the 
differential equation  2xy
y
′ =
 and find that  2
n
n
nc
c
=
  for all  n  ≥  0.  This implies that  
0
0
1
1
2
2
0
, 2
, 4
,
,
c
c
c
c
c
c
=
=
=
  and hence that cn  =  0  for all  n  ≥  0,  which means that 
the only power series solution of our differential equation is the trivial solution  ( )
0.
y x ≡
 
Therefore the equation has no non-trivial power series solution. 
 
17. 
Assuming a power series solution of the form  y  =  Σcnxn,  we substitute it into the 
differential equation  
2
0.
x y
y
′ +
=
  We find that  c0  =  c1  =  0  and that  cn+1  =  −ncn  for  
n  ≥  1, so it follows that  cn  =  0  for all  n  ≥  0.  Just as in Problems 15 and 16, this 
means that the equation has no non-trivial power series solution. 
   
18. 
When we substitute and assumed power series solution  y  =  Σcnxn  into  x3y'  =  2y,  we 
find that  c0  =  c1  =  c2  =  0  and that  cn+2  =  ncn/2  for  n  ≥  1.  Hence  cn  =  0  for all  
n ≥ 0,  just as in Problems 15–17. 
 
In Problems 19–22 we first give the recurrence relation that results upon substitution of an 
assumed power series solution  y  =  Σcnxn  into the given second-order differential equation.  
Then we give the resulting general solution, and finally apply the initial conditions  
0
(0)
y
c
=
 
and  
1
(0)
y
c
′
=
 to determine the desired particular solution. 
 
19. 
2
2
2
0
1
2
2
2
1
2
( 1) 2
( 1) 2
for
0, so
and
.
(
1)(
2)
(2 )!
(2
1)!
k
k
k
k
n
n
k
k
c
c
c
c
n
c
c
n
n
k
k
+
+
−
−
= −
≥
=
=
+
+
+
 
 
2
2
4
4
6
6
2
3
4
5
6
7
0
1
2
2
2
2
2
2
( )
1
2!
4!
6!
3!
5!
7!
x
x
x
x
x
x
y x
c
c
x




=
−
+
−
+
+
−
+
−
+









  
 
0
1
(0)
0 and
(0)
3,
c
y
c
y′
=
=
=
=
so 
 
 
 
2
3
4
5
6
7
2
2
2
( )
3
3!
5!
7!
x
x
x
y x
x


=
−
+
−
+





 
 
 
 
3
5
7
3
(2 )
(2 )
(2 )
3
(2 )
sin2 .
2
3!
5!
7!
2
x
x
x
x
x


=
−
+
−
+
=





 
   
20. 
2
2
2
0
1
2
2
2
1
2
2
2
for
0, so
and
.
(
1)(
2)
(2 )!
(2
1)!
k
k
n
n
k
k
c
c
c
c
n
c
c
n
n
k
k
+
+
=
≥
=
=
+
+
+
 
 
2
2
4
4
6
6
2
3
4
5
6
7
0
1
2
2
2
2
2
2
( )
1
2!
4!
6!
3!
5!
7!
x
x
x
x
x
x
y x
c
c
x




=
+
+
+
+
+
+
+
+
+









  
 
0
1
(0)
2 and
(0)
0,
c
y
c
y′
=
=
=
=
so 
 
 
 
2
4
6
(2 )
(2 )
(2 )
( )
2 1
2cosh2 .
2!
4!
6!
x
x
x
y x
x


=
+
+
+
+
=





 
 

 
Section 11.1 
553 
21. 
1
1
0
1
2
for
1; with
(0)
0 and
(0)
1,
(
1)
n
n
n
nc
c
c
n
c
y
c
y
n n
−
+
−
′
=
≥
=
=
=
=
+
we obtain 
 
2
3
4
5
6
1
1
1
1
1
1
1
1,
,
,
,
.
2
6
3!
24
4!
120
5!
c
c
c
c
c
=
=
=
=
=
=
=
=
  Evidently  
1
,
(
1)!
nc
n
=
−
  so 
 
 
3
4
5
2
3
4
2
( )
1
.
2!
3!
4!
2!
3!
4!
x
x
x
x
x
x
x
y x
x
x
x
x
xe


=
+
+
+
+
+
=
+
+
+
+
+
=






 
 
22. 
1
1
0
1
2
for
1; with
(0)
1 and
(0)
2,
(
1)
n
n
n
nc
c
c
n
c
y
c
y
n n
−
+
−
′
= −
≥
=
=
=
= −
+
we obtain 
 
3
4
5
2
3
4
5
4
2
2
2
4
2
2,
,
,
.
3
3!
3
4!
15
5!
c
c
c
c
=
= −
= −
=
=
= −
= −
  Apparently  
2 ,!
n
nc
n
= ±
  so 
 
 
(
)
(
)
(
)
(
)
(
)
2
3
4
5
2
2
2
2
2
( )
1
2
.
2!
3!
4!
5!
x
x
x
x
x
y x
x
e−
= −
+
−
+
−
+
=

 
 
23. 
c0  =  c1  =  0  and the recursion relation   
 
 
 
 
 
(n2 − n + 1)cn + (n − 1)cn−1  =  0   
 
 
for  n  ≥  2  imply that  cn  =  0  for  n  ≥  0.  Thus any assumed power series solution 
 
y  =  Σcnxn  must reduce to the trivial solution  ( )
0.
y x ≡
 
 
 
 
 
24. 
(a) 
The fact that  ( )
y x   =  (1 + x)α  satisfies the differential equation   
 
(1
)
x y
y
α
′
+
=
  follows immediately from the fact that  
1
( )
(1
)
.
y x
x α
α
−
′
=
+
 
 
(b) 
When we substitute  y  =  Σcnxn  into the differential equation  (1
)
x y
y
α
′
+
=
  we 
get the recurrence formula 
 
 
 
 
1
(
)
.
1
n
n
n c
c
n
α
+
−
=
+
cn+1  =  (α − n)cn/(n + 1).   
 
 
Since  c0  =  1  because of the initial condition  y(0)  =  1,  the binomial series (Equation 
(12) in the text) follows. 
 
 
(c) 
The function  (1 + x)α  and the binomial series must agree on  (−1, 1)  because of 
the uniqueness of solutions of linear initial value problems. 
  
25. 
Substitution of  
0
n
n
n c x
∞
=
∑
 into the differential equation  y
y
y
′′
′
=
+
 leads routinely — 
 
via shifts of summation to exhibit  
nx -terms throughout — to the recurrence formula 
 
 
 
 
 
2
1
(
2)(
1)
(
1)
,
n
n
n
n
n
c
n
c
c
+
+
+
+
=
+
+
 

554 
Chapter 11 
 
and the given initial conditions yield  
0
0
1
1
0
and
1
.
c
F
c
F
=
=
=
=
 But instead of 
 
proceeding immediately to calculate explicit values of further coefficients, let us first 
 
multiply the recurrence relation by  !
n .  This trick provides the relation 
 
 
 
 
 
2
1
(
2)!
(
1)!
!
,
n
n
n
n
c
n
c
n c
+
+
+
=
+
+
 
 
 
that is, the Fibonacci-defining relation  
2
1
n
n
n
F
F
F
+
+
=
+
 where  
!
,
n
n
F
n c
=
 so we see that  
 
/ !
n
n
c
F
n
=
  as desired. 
 
26. 
This problem is pretty fully outlined in the textbook.  The only hard part is squaring the 
power series: 
 
 
 
(
)
2
3
5
7
9
11
3
5
7
9
11
1
c x
c x
c x
c x
c x
+
+
+
+
+
+   
 
 
 
(
)
(
)
(
)
(
)
2
4
2
6
8
3
3
5
3 5
7
2
10
12
5
3 7
9
5 7
3 9
11
2
2
2
2
2
2
2
2
2
x
c x
c
c
x
c c
c
x
c
c c
c
x
c c
c c
c
x
=
+
+
+
+
+
+
+
+
+
+
+
+ 
 
 
 
27. 
(b)  The roots of the characteristic equation  r3  =  1  are  r1  =  1,  r2  =  α  =   
 
(−1 + i
3 )/2,  and  r3  =  β  =  (−1 − i
3 )/2.  Then the general solution is 
 
 
 
 
 
( )
.
x
x
x
y x
Ae
Be
Ce
α
β
=
+
+
                 
 
 
(*) 
 
 
Imposing the initial conditions, we get the equations 
 
 
 
 
 
A +    B +    C  =    1 
 
 
 
 
A +  αB +  βC  =    1 
 
 
 
 
A + α2B + β2C  =  −1. 
 
 
The solution of this system is  A  =  1/3,  B  =  (1 − i
3 )/3,  C  =  (1 + i
3 )/3. 
 
Substitution of these coefficients in (*) and use of Euler's relation  eiθ  =   
 
cos θ + i sin θ  finally yields the desired result. 
 
 
 
SECTION 11.2 
 
POWER SERIES SOLUTIONS 
 
Instead of deriving in detail the recurrence relations and solution series for Problems 1 through 
15, we indicate where some of these problems and answers originally came from.  Each of the 
differential equations in Problems 1−10 is of the form 

 
Section 11.2 
555 
 
     
 
 
 
 
(Ax2 + B)y'' + Cxy' + Dy  =  0 
 
with selected values of the constants  A, B, C, D.  When we substitute  y  =  Σcnxn,  shift indices  
where appropriate, and collect coefficients,  we get 
 
 
 
[
]
2
0
(
1)
(
1)(
2)
0.
n
n
n
n
n
n
An n
c
B n
n
c
Cnc
Dc
x
∞
+
=
−
+
+
+
+
+
=
∑
 
Thus the recurrence relation is 
 
 
 
 
2
2
(
)
for
0.
(
1)(
2)
n
n
An
C
A n
D
c
c
n
B n
n
+
+
−
+
= −
≥
+
+
 
It yields a solution of the form 
 
 
 
 
 
y  =  c0 yeven + c1 yodd 
 
where  yeven  and  yodd  denote series with terms of even and odd degrees, respectively.  The even-
degree series  
2
4
0
2
4
c
c x
c x
+
+
+ converges (by the ratio test) provided that 
 
 
 
 
 
 
2
2
2
lim
1.
n
n
n
n
n
c
x
Ax
c x
B
+
+
→∞
=
<
 
 
Hence its radius of convergence is at least 
/
B A
ρ =
,  as is that of the odd-degree series  
3
4
1
3
5
c x
c x
c x
+
+
+.  (See Problem 6 for an example in which the radius of convergence is, 
surprisingly, greater than  
/
B A .) 
 
In Problems 1–15 we give first the recurrence relation and the radius of convergence, then the 
resulting power series solution. 
 
1. 
2
0
2
4
1
3
4
1;
;
;
n
n
c
c
c
c
c
c
c
c
ρ
+
=
=
=
=
=
=
=
=


 
 
2
2
1
0
1
0
1
2
0
0
( )
1
n
n
n
n
c
c x
y
c
x
c
x
x
x
∞
∞
+
=
=
+
=
+
=
−
∑
∑
 
 
2. 
0
1
2
2
2
1
1
( 1)
( 1)
;
2;
;
2
2
2
n
n
n
n
n
n
n
n
c
c
c
c
c
c
ρ
+
+
−
−
= −
=
=
=
 
 
2
2
1
0
1
0
0
( 1)
( 1)
( )
2
2
n
n
n
n
n
n
n
n
x
x
y
c
c
x
+
∞
∞
=
=
=
−
+
−
∑
∑
 
 
 
3. 
2
;
;
(
2)
n
n
c
c
n
ρ
+
= −
= ∞
+
 

556 
Chapter 11 
 
0
0
2
1
1
2
1
( 1)
( 1)
;
(2 )(2
2)
4 2
!2
( 1)
( 1)
(2
1)(2
1)
5 3
(2
1)!!
n
n
n
n
n
n
n
c
c
c
n
n
n
c
c
c
n
n
n
+
−
−
=
=
−
⋅
⋅⋅
−
−
=
=
+
−
⋅
⋅⋅
+


 
 
2
2
1
0
1
0
0
( 1)
( 1)
( )
!2
(2
1)!!
n
n
n
n
n
n
n
x
x
y
c
c
x
n
n
+
∞
∞
=
=
=
−
+
−
+
∑
∑
 
 
 
4. 
2
4
1
;
2
n
n
n
c
c
n
ρ
+
+
= −
=
+
 
 
2
0
0
0
2
2
2
6
4
2
2
( 1)
( 1) (
1)
2
2
2
4
2
2
n
n
n
n
n
n
c
c
c
n
c
n
n
+
+






=
−
−
⋅
⋅−
−
=
−
=
−
+






−







 
 
2
0
1
2
3
2
1
7
5
2
3
( 1)
2
1
2
1
5
3
3
n
n
n
n
n
c
c
c
n
n
+
+
+






=
−
−
⋅
⋅−
−
=
−






+
−







 
 
2
2
1
0
1
0
0
1
( 1) (
1)
( 1) (2
3)
( )
3
n
n
n
n
n
n
y
c
n
x
c
n
x
x
∞
∞
+
=
=
=
−
+
+
−
+
∑
∑
 
 
 
5. 
2
2
4
6
;
3;
0
3(
2)
n
n
nc
c
c
c
c
n
ρ
+
=
=
=
=
=
=
+

 
 
1
2
1
1
2
1
2
3
3
1
3(2
1) 3(2
1)
3(5) 3(3)
(2
1)3
n
n
n
n
c
c
c
n
n
n
+
−
−
=
⋅
⋅
⋅
⋅
=
+
−
+

 
 
2
1
0
1
0
( )
(2
1)3
n
n
n
x
y
c
c
x
n
+
∞
=
=
+
+
∑
 
 
6. 
2
(
3)(
4)
(
1)(
2)
n
n
n
n
c
c
n
n
+
−
−
=
+
+
 
The factor  (
3)
n −
  in the numerator yields  
5
7
9
0,
c
c
c
=
=
=
=

 and the factor  (
4)
n −
 
yields  
6
8
10
0.
c
c
c
=
=
=
=

  Hence  yeven and yodd are both polynomials with radius of  
convergence  
.
ρ = ∞ 
 
2
4
3
0
1
(1
6
)
(
)
( )
y
c
x
x
c x
x
x
=
+
+
+
+
 
 
7. 
2
2
(
4)
;
3
3(
1)(
)
2
n
n
n
c
c
n
n
ρ
+
−
= −
≥
+
+
 
The factor  (
4)
n −
 yields  
6
8
10
0,
c
c
c
=
=
=
=

  so  yeven  is a 4th-degree polynomial.  
We find first that  
3
1
5
1
/ 2 and
/120
c
c
c
c
= −
=
, and then for 
3
n ≥
 that 

 
Section 11.2 
557 
 
[
]
[
]
2
2
2
2
1
5
2
2
2
1
1
2
(2
5)
(2
7)
1
3(2 )(2
1)
3(2
2)(2
1)
3(6)(7)
(2
5)!!
(2
5)!!
( 1)
9 ( 1)
3
(2
1)(2
1)
7 6 120
3 (2
1)!
n
n
n
n
n
n
n
c
c
n
n
n
n
n
n
c
c
n
n
n
+
−
−





−
−
=
−
−
⋅
⋅−
=





+
−
−





−
−
=
−
⋅
=
⋅−
+
−
⋅
⋅⋅
+


 
 
 
 
2
2
4
3
5
2
1
0
1
3
8
8
1
1
[(2
5)!!] ( 1)
1
9
( )
3
27
2
120
(2
1)! 3
n
n
n
n
n
y
c
x
x
c
x
x
x
x
x
n
∞
+
=


−
−


=
−
+
+
−
+
+




+




∑
 
 
8. 
2
(
4)(
4)
;
2
2(
1)(
2)
n
n
n
n
c
c
n
n
ρ
+
−
+
=
≥
+
+
 
We find first that  
3
1
5
1
5
/ 4 and
7
/32
c
c
c
c
= −
=
, and then for 
3
n ≥
 that 
 
2
1
5
1
1
2
2
1
(2
5)(2
3)
(2
7)(2
1)
1 9
2(2 )(2
1)
2(2
2)(2
1)
2(6)(7)
(2
5)!!(2
3)(2
1)
9 7
5!
7 (2
5)!!(2
3)!!
4
2
(2
1)(2 )
7 6
32
7 5 3 32
2 (2
1)!
(2
5)!!(2
3)
n
n
n
n
n
n
n
n
c
c
n
n
n
n
n
n
n
c
n
n
c
n
n
n
n
n
c
+
−
+





−
+
−
+
⋅
=
⋅
⋅
=





+
−
−





−
+
+
⋅
⋅
−
+
=
⋅
=
⋅
⋅
+
⋅
⋅⋅
⋅⋅
+
−
+
=



1
!!
2 (2
1)!
n
c
n +
 
 
(
)
2
4
3
5
2
1
0
1
3
5
7
(2
5)!!(2
3)!!
1
4
2
( )
4
32
(2
1)! 2
n
n
n
n
n
y
c
x
x
c
x
x
x
x
x
n
∞
+
=


−
+
=
−
+
+
−
+
+


+


∑
 
 
9. 
2
(
3)(
4)
1
;
(
1)(
2)
n
n
n
n
c
c
n
n
ρ
+
+
+
=
=
+
+
 
 
2
0
0
(2
1)(2
2)
(2
1)(2 )
3 4
1 (
1)(2
1)
(2
1)(2 )
(2
3)(2
2)
1 2
2
n
n
n
n
n
c
c
n
n
c
n
n
n
n
+
+
−
⋅
=
⋅
⋅
⋅
=
+
+
−
−
−
⋅

 
 
2
1
1
1
(2
2)(2
3)
(2 )(2
1)
4 5
1 (
1)(2
3)
(2 )(2
1)
(2
2)(2
1)
2 3
3
n
n
n
n
n
c
c
n
n
c
n
n
n
n
+
+
+
+
⋅
=
⋅
⋅
⋅
=
+
+
+
−
−
⋅

 
 
2
2
1
0
1
0
0
1
( )
(
1)(2
1)
(
1)(2
3)
3
n
n
n
n
x
y
c
n
n
x
c
n
n
x
∞
∞
+
=
=
=
+
+
+
+
+
∑
∑
 
 
10. 
2
(
4)
;
3(
1)(
2)
n
n
n
c
c
n
n
ρ
+
−
= ∞
= −
+
+
 
The factor  (
4)
n −
 yields  
6
8
10
0,
c
c
c
=
=
=
=

  so  yeven  is a 4th-degree polynomial.   
We find first that  
3
1
5
1
/ 6 and
/360
c
c
c
c
=
=
, and then for 
3
n ≥
 that 

558 
Chapter 11 
2
1
5
2
1
2
2
1
1
(2
5)
(2
3)
1
3(2
1)(2 ) 3(2
1)(2
2)
3(7)(6)
(2
5)!!( 1)
3
(2
1)(2 )
(7)(6) 360
3
5!
(2
5)!!( 1)
(2
5)!!( 1)
3
360
3 (2
1)(2 )
(7)(6) 5!
3 (2
1)!
n
n
n
n
n
n
n
n
n
c
c
n
n
n
n
n
c
n
n
n
n
c
c
n
n
n
+
−
−
−
−
−
−
−
=
⋅
⋅
⋅
+
−
−
−
−
=
⋅
=
+
⋅
⋅
⋅
−
−
−
−
=
⋅
⋅
=
⋅
+
⋅
⋅
⋅
+



 
 
2
4
3
5
2
1
0
1
3
2
1
1
1
(2
5)!!( 1)
( )
1
3
3
27
6
360
(2
1)! 3
n
n
n
n
n
x
y
c
x
x
c
x
x
x
x
n
∞
+
=


−
−


=
+
+
+
+
+
+




+




∑
 
 
11. 
2
2(
5)
;
5(
1)(
2)
n
n
n
c
c
n
n
ρ
+
−
=
= ∞
+
+
 
The factor  (
5)
n −
 yields  
7
9
11
0,
c
c
c
=
=
=
=

  so  yodd  is a 5th-degree polynomial.   
We find first that  
2
1
4
0
6
0
,
/10 and
/ 750,
c
c
c
c
c
c
= −
=
=
 and then for 
4
n ≥
 that 
 
2
6
3
0
3
3
1
0
3
2(2
7)
2(2
5)
2(1)
5(2 )(2
1) 5(2
2)(2
3)
5(8)(7)
2
(2
7)!!
5
(2 )(2
1)
(8)(7) 750
5
6!
2 (2
7)!!
2 (2
7)!!
15
2
750 5 (2 )(2 )
(8)(7) 6!
5 (2 )!
n
n
n
n
n
n
n
n
n
c
c
n
n
n
n
n
c
n
n
n
n
c
c
n
n
n
−
−
−
−
=
⋅
⋅
⋅
−
−
−
−
=
⋅
=
−
⋅
⋅
⋅
−
−
=
⋅
⋅
=
⋅
⋅
⋅
⋅
⋅



 
 
3
5
4
6
2
2
1
0
4
4
4
(2
7)!! 2
( )
1
15
15
375
10
750
(2 )! 5
n
n
n
n
x
x
x
x
n
y x
c
x
c
x
x
n
∞
=




−
=
−
+
+
−
+
+
+








∑
 
 
12. 
3
;
2
n
n
c
c
n
ρ
+
= ∞
=
+
 
 
When we substitute  y  =  Σcnxn  into the given differential equation, we find first that 
 
2
0,
c =
  so the recurrence relation yields  
5
8
11
0
c
c
c
=
=
=
=

 also. 
 
3
3
1
0
1
1
0
( )
1
2 5
(3
1)
! 3
n
n
n
n
n
x
x
x
y
c
c
n
n
+
∞
∞
=
=


=
+
+


⋅⋅
⋅
−


∑
∑

 
 
13. 
3
;
3
n
n
c
c
n
ρ
+
= ∞
= −
+
 
 
When we substitute  y  =  Σcnxn  into the given differential equation, we find first that 
 
2
0,
c =
  so the recurrence relation yields  
5
8
11
0
c
c
c
=
=
=
=

 also. 
 
3
3
1
0
1
0
0
( 1)
( 1)
( )
! 3
1 4
(3
1)
n
n
n
n
n
n
n
x
x
x
y
c
c
n
n
+
∞
∞
=
=
−
−
=
+
⋅⋅
⋅
+
∑
∑

 

 
Section 11.2 
559 
14. 
3
;
(
2)(
3)
n
n
c
c
n
n
ρ
+
= ∞
= −
+
+
 
 
When we substitute  y  =  Σcnxn  into the given differential equation, we find first that 
 
2
0,
c =
  so the recurrence relation yields  
5
8
11
0
c
c
c
=
=
=
=

 also.  Then 
 
0
3
0
1
1
1
( 1)
,
(3 )(3
1) (3
3)(3
4)
3 2
3
! (3
1)(3
4)
5 2
n
n
n
c
c
c
n
n
n
n
n
n
n
−
−
−
−
=
⋅
⋅
⋅
=
−
−
−
⋅
⋅
−
−
⋅
⋅⋅


 
 
1
3
1
1
1
1
1
( 1)
.
(3
1)(3 ) (3
2)(3
3)
4 3
3
! (3
1)(3
2)
4 1
n
n
n
c
c
c
n
n
n
n
n
n
n
+
−
−
−
−
=
⋅
⋅
⋅
=
+
−
−
⋅
⋅
+
−
⋅
⋅⋅


 
 
3
3
1
0
1
1
0
( 1)
( 1)
( )
1
3
! 2 5
(3
1)
3
! 1 4
(3
1)
n
n
n
n
n
n
n
n
x
x
x
y
c
c
n
n
n
n
+
∞
∞
=
=


−
−
=
+
+


⋅⋅⋅
⋅
−
⋅⋅⋅
⋅
+


∑
∑


 
 
15. 
4
;
(
3)(
4)
n
n
c
c
n
n
ρ
+
= ∞
= −
+
+
 
 
When we substitute  y  =  Σcnxn  into the given differential equation, we find first that 
2
3
0,
c
c
=
=
  so the recurrence relation yields  
6
10
0
c
c
=
=
=

 and  
7
11
0
c
c
=
=
=

  also.  
Then 
 
0
4
0
1
1
1
( 1)
,
(4 )(4
1) (4
4)(4
5)
4 3
4
! (4
1)(4
5)
5 3
n
n
n
c
c
c
n
n
n
n
n
n
n
−
−
−
−
=
⋅
⋅
⋅
=
−
−
−
⋅
⋅
−
−
⋅
⋅⋅


 
 
1
3
1
1
1
1
1
( 1)
.
(4
1)(4 ) (4
3)(4
4)
5 4
4
! (4
1)(4
3)
9 5
n
n
n
c
c
c
n
n
n
n
n
n
n
+
−
−
−
−
=
⋅
⋅
⋅
=
+
−
−
⋅
⋅
+
−
⋅
⋅⋅


 
 
4
4
1
0
1
1
1
( 1)
( 1)
( )
1
4
! 3 7
(4
1)
4
! 5 9
(4
1)
n
n
n
n
n
n
n
n
x
x
x
y
c
c
x
n
n
n
n
+
∞
∞
=
=




−
−
=
+
+
+




⋅⋅⋅
⋅
−
⋅⋅⋅
⋅
+




∑
∑


 
 
16. 
The recurrence relation is  
2
1
for
1.
1
n
n
n
c
c
n
n
+
−
= −
≥
+
  The factor  (
1)
n −
 in the 
numerator yields  
3
5
7
0.
c
c
c
=
=
=
=

  When we substitute  y  =  Σcnxn  into the given  
 
differential equation, we find first that  
2
0,
c
c
=
 and then the recurrence relation gives 
 
 
1
2
2
0
2
3
2
5
3
1
( 1)
.
2
1
2
3
5
3
2
1
n
n
n
n
c
c
c
n
n
n
−
−
−
−
= −
⋅−
⋅
⋅−
⋅−
=
−
−
−

 
 
Hence 
 
 
(
)
4
6
8
2
1
0
3
5
7
1
1
0
0
1
0
( )
1
3
5
7
1
tan
.
3
5
7
x
x
x
y x
c x
c
x
x
x
x
c x
c
c x x
c x
c
x
x
−


=
+
+
−
+
−
+






=
+
+
−
+
−
+
=
+
+






 
 
With  c0  =  y(0)  =  0  and  c1  =  y'(0)  =  1  we obtain the particular solution  y(x)  =  x. 

560 
Chapter 11 
17. 
The recurrence relation 
 
 
 
 
2
(
2)
(
1)(
2)
n
n
n
c
c
n
n
+
−
= −
+
+
 
yields  c2  =  c0  =  y(0)  =  1  and  c4  =  c6  =  ⋅⋅⋅  =  0.  Because  c1  =  y'(0)  =  0,  it 
follows also that  c1  =  c3  =  c5  =  ⋅⋅⋅  =  0.  Thus the desired particular solution is   
 
y(x)  =  1 + x2. 
 
18. 
The substitution  t  =  x − 1  yields  y'' + ty' + y  =  0,  where primes now denote 
differentiation with respect to  t.  When we substitute  y  =  Σcntn  we get the recurrence 
relation   
 
 
 
 
2
.
2
n
n
c
c
n
+
= −
+
 
 
for  n  ≥  0, so the solution series has radius of convergence  
.
ρ = ∞.  The initial 
 
conditions give  c0  =  2  and  c1  =  0,  so  codd  =  0  and it follows that  
 
 
2
4
6
2 1
,
2
2 4
2 4 6
t
t
t
y


=
−
+
−
+


⋅
⋅⋅



 
 
 
2
4
6
2
0
(
1)
(
1)
(
1)
( 1) (
1)
( )
2 1
2
.
2
2 4
2 4 6
!2
n
n
n
n
x
x
x
x
y x
n
∞
=


−
−
−
−
−
=
−
+
−
+
=


⋅
⋅⋅


∑

 
 
19. 
The substitution  t  =  x − 1  yields  (1 – t2)y'' – 6ty' – 4y  =  0,  where primes now denote 
differentiation with respect to  t.  When we substitute  y  =  Σcntn  we get the recurrence 
relation   
 
 
 
 
2
4
.
2
n
n
n
c
c
n
+
+
=
+
 
 
for  n  ≥  0, so the solution series has radius of convergence  
1,
ρ =
 and therefore 
converges if  –1 < t < 1.  The initial conditions give  c0  =  0  and  c1  =  1,  so  ceven  =  0  
and 
 
 
 
2
1
1
2
3 2
1
7 5
2
3.
2
1 2
1
5 3
3
n
n
n
n
c
c
n
n
+
+
+
+
=
⋅
⋅
⋅
⋅
=
+
−

  
 
Thus 
 
 
2
1
2
1
0
0
1
1
(2
3)
(2
3)(
1)
,
3
3
n
n
n
n
y
n
t
n
x
∞
∞
+
+
=
=
=
+
=
+
−
∑
∑
 
 
and the x-series converges if  0 < x < 2. 
 
20. 
The substitution  t  =  x − 3  yields  (t2 + 1)y'' − 4ty' + 6y  =  0,  where primes now denote 
differentiation with respect to  t.  When we substitute  y  =  Σcntn  we get the recurrence 
relation 
 
 
 
 
2
(
2)(
3)
(
1)(
2)
n
n
n
n
c
c
n
n
+
−
−
= −
+
+
 

 
Section 11.2 
561 
 
for  n  ≥  0.  The initial conditions give  c0  =  2  and  c1  =  0.  It follows that  codd  =  0,  
 
c2  =  −6  and  c4  =  c6  =   =  0,  so the solution reduces to  
 
 
 
 
 
y  =  2 − 6t2  =  2 − 6(x − 3)2. 
 
21. 
The substitution  t  =  x + 2  yields  (4t2 + 1)y''  =  8y,  where primes now denote 
differentiation with respect to  t.  When we substitute  y  =  Σcntn  we get the recurrence 
relation 
 
 
 
 
2
4(
2)
(
2)
n
n
n
c
c
n
+
−
= −
+
 
 
for  n  ≥  0.  The initial conditions give  c0  =  1  and  c1  =  0.  It follows that  codd  =  0,  
 
c2  =  4  and  c4  =  c6  =   =  0,  so the solution reduces to  
 
 
 
 
 
y  =  2 + 4t2  =  1 + 4(x + 2)2. 
 
22. 
The substitution  t  =  x + 3  yields  (t2 – 9)y'' + 3ty' − 3y  =  0,  with primes now denoting 
differentiation with respect to  t.  When we substitute  y  =  Σcntn  we get the recurrence 
relation 
 
 
 
 
2
(
3)(
1)
9(
1)(
2)
n
n
n
n
c
c
n
n
+
+
−
=
+
+
 
 
for  n  ≥  0.  The initial conditions give  c0  =  0  and  c1  =  2.  It follows that  ceven  =  0   
 
and  c3  =  c5  =  ⋅⋅⋅  =  0,  so 
 
 
 
 
 
y  =  2t  =  2x + 6. 
 
In Problems 23–26 we first derive the recurrence relation, and then calculate the solution series  
1( )
y x  with  
0
1
1 and
0,
c
c
=
=
 the solution series  
2( )
y
x  with  
0
1
0 and
1.
c
c
=
=
 
 
23. 
Substitution of  y  =  Σcnxn  yields 
 
 
[
]
0
2
1
2
1
2
(
1)(
2)
0,
n
n
n
n
n
c
c
c
c
n
n
c
x
∞
−
+
=
+
+
+
+
+
+
=
∑
 
 
so 
 
 
1
2
0
2
1
,
for
1.
2
(
1)(
2)
n
n
n
c
c
c
c
c
n
n
n
−
+
+
= −
= −
≥
+
+
 
 
2
3
4
3
4
5
1
2
( )
1
;
( )
2
6
24
6
12
120
x
x
x
x
x
x
y x
y
x
x
=
−
−
+
+
=
−
−
+
+

 
 
24. 
Substitution of  y  =  Σcnxn  yields 
 
 
[
]
2
1
2
1
2
2
(
1)
(
1)(
2)
0,
n
n
n
n
n
c
c
n n
c
n
n
c
x
∞
−
+
=
−
+
+
+
−
+
+
=
∑
 

562 
Chapter 11 
 
 
 
so 
 
 
1
2
2
(
1)
0,
for
1.
(
1)(
2)
n
n
n
c
n n
c
c
c
n
n
n
−
+
+
+
=
=
≥
+
+
 
 
3
5
6
3
4
5
1
2
( )
1
;
( )
3
5
45
3
6
5
x
x
x
x
x
x
y x
y
x
x
=
+
+
+
+
=
+
+
+
+

 
 
25. 
Substitution of  y  =  Σcnxn  yields 
 
 
[
]
2
3
2
1
2
2
2
6
(
1)
(
1)(
2)
0,
n
n
n
n
n
c
c x
c
n
c
n
n
c
x
∞
−
−
+
=
+
+
+
−
+
+
+
=
∑
 
 
so 
 
 
2
1
2
3
2
(
1)
0,
for
2.
(
1)(
2)
n
n
n
c
n
c
c
c
c
n
n
n
−
−
+
+
−
=
=
= −
≥
+
+
 
 
4
7
8
4
5
7
1
2
( )
1
;
( )
12
126
672
12
20
126
x
x
x
x
x
x
y x
y
x
x
=
−
+
+
+
=
−
−
+
+

 
 
26. 
Substitution of  y  =  Σcnxn  yields 
 
 
[
]
2
3
2
3
4
2
5
4
1
2
4
2
6
12
(2
20 )
(
1)(
2)
(
1)(
2)
0,
n
n
n
n
n
c
c x
c x
c
c x
c
n
n
c
n
n
c
x
∞
−
−
+
=
+
+
+
+
+
+
−
−
+
+
+
=
∑
 
 
so 
 
 
4
1
2
3
4
5
2
(
1)(
2)
0,
for
4.
(
1)(
2)
n
n
n
c
n
n
c
c
c
c
c
c
n
n
n
−
−
+
+
−
−
=
=
=
=
= −
≥
+
+
 
 
6
9
12
7
10
13
1
2
29
41
( )
1
;
( )
30
72
3960
42
90
6552
x
x
x
x
x
x
y x
y
x
x
=
−
+
−
+
=
−
+
−
+

 
 
27. 
Substitution of  y  =  Σcnxn  yields 
 
 
[
]
0
2
1
3
2
2
2
2
(2
6
)
2
(
1)
(
1)(
2)
0,
n
n
n
n
n
c
c
c
c x
c
n
c
n
n
c
x
∞
−
+
=
+
+
+
+
+
+
+
+
+
=
∑
 
 
so 
 
 
0
1
2
2
3
2
2
(
1)
,
,
for
2.
2
3
(
1)(
2)
n
n
n
c
c
c
n
c
c
c
c
n
n
n
−
+
+
+
= −
= −
= −
≥
+
+
 
 
With  
0
1
(0)
1 and
(0)
1,
c
y
c
y′
=
=
=
= − we obtain 
 
 
2
3
4
5
6
7
8
9
29
13
143
31
( )
1
.
2
3
24
30
720
630
40320
22680
x
x
x
x
x
x
x
x
y x
x
=
−
−
+
−
+
+
−
−
+
+    

 
Section 11.2 
563 
 
Finally,  x = 0.5  gives 
 
 
 
(0.5)
1
0.5
0.125
0.041667
0.002604
0.001042
0.000629
0.000161
0.000014
0.000003
(0.5)
0.415562
0.4156.
y
y
=
−
−
+
−
+
+
−
−
+
+
≈
≈
 
 
28. 
When we substitute  y  =  Σcnxn  and  
( 1)
/ !
x
n
n
e
x
n
−=
−
∑
  and then collect coefficients 
 
 of the terms involving  1,  x,  x2,  and  x3,  we find that 
 
 
0
0
1
1
0
1
2
3
4
5
3
2
,
,
,
.
2
6
12
120
c
c
c
c
c
c
c
c
c
c
−
+
= −
=
=
= −
 
With the choices  
0
1
0
1
1,
0 and
0,
1
c
c
c
c
=
=
=
=  we obtain the two series solutions 
 
2
3
5
3
4
5
1
2
( )
1
and
( )
.
2
6
40
6
12
60
x
x
x
x
x
x
y x
y
x
x
=
−
+
−
+
=
−
+
−
+

  
 
29. 
When we substitute  y  =  Σcnxn  and  
2
cos
( 1)
/(2 )!
n
n
x
x
n
=
−
∑
  and then collect  
 
coefficients of the terms involving  
2
6
1, ,
,
,
,
x x
x

  we obtain the equations 
 
 
0
2
1
3
4
3
5
2
0,
6
0,
12
0,
2
20
0,
c
c
c
c
c
c
c
+
=
+
=
=
−
+
=
 
 
 
2
4
6
3
5
6
2
4
6
8
1
1
5
30
0,
9
42
0,
12
4
1
1
14
56
0.
360
2
c
c
c
c
c
c
c
c
c
c
−
+
=
−
+
=
−
+
−
+
=
 
Given  
0
1
and
,
c
c  we can solve easily for  
2
3
8
,
,
,
c
c
c

 in turn. With the choices  
0
1
0
1
1,
0 and
0,
1
c
c
c
c
=
=
=
= we obtain the two series solutions 
 
2
6
8
3
5
7
1
2
13
13
( )
1
and
( )
.
2
720
40320
6
60
5040
x
x
x
x
x
x
y x
y
x
x
=
−
+
+
+
=
−
−
−
+

  
 
30. 
When we substitute  y  =  Σcnxn  and  sin x  =  Σ (−1)nx2n+1/(2n + 1)!,  and then collect 
 
 coefficients of the terms involving  
2
5
1, ,
,
,
,
x x
x

  we obtain the equations 
 
 
1
0
1
2
1
2
3
2
3
4
2
0,
2
6
0,
3
12
0,
6
c
c
c
c
c
c
c
c
c
c
+
+
=
+
+
=
−
+
+
+
=
 
 
 
2
1
3
3
4
5
4
5
6
4
20
0,
5
30
0.
3
120
2
c
c
c
c
c
c
c
c
c
−
+
+
+
=
−
+
+
+
=
 
Given  
0
1
and
,
c
c  we can solve easily for  
2
3
6
,
,
,
c
c
c

 in turn. With the choices  
0
1
0
1
1,
0 and
0,
1
c
c
c
c
=
=
=
= we obtain the two series solutions 

564 
Chapter 11 
-3
3
x
-100
100
y
H4
H5
 
2
3
5
6
2
4
5
6
1
2
7
( )
1
and
( )
.
2
6
60
180
2
18
360
900
x
x
x
x
x
x
x
x
y x
y
x
x
=
−
+
−
+
+
=
−
+
−
+
+

  
 
33. 
Substitution of  y  =  Σcnxn  in Hermite's equation leads in the usual way to the recurrence 
 
formula 
 
 
 
 
2
2(
)
.
(
1)(
2)
n
n
n c
c
n
n
α
+
−
= −
+
+
 
 
 
Starting with  
0
1,
c =
 this formula yields 
 
 
 
2
3
2
4
6
2
2
(
2)
2
(
2)(
4)
,
,
,
.
2!
4!
6!
c
c
c
α
α α
α α
α
−
−
−
= −
= +
= −
…  
 
 
Starting with  
1
1,
c =
 it yields 
 
 
 
2
3
3
5
7
2(
1)
2 (
1)(
3)
2 (
1)(
3)(
5)
,
,
,
.
3!
5!
7!
c
c
c
α
α
α
α
α
α
−
−
−
−
−
−
= −
= +
= −
…  
 
 
This gives the desired even-term and odd-term series  
1
2
and
.
y
y  If  α  is an integer, 
 
then obviously one series or the other has only finitely many non-zero terms.  For 
 
instance, with  
4
α =
 we get 
 
 
 
(
)
2
2
4
2
4
4
2
1
2 4
2
4 2
4
1
( )
1
1
4
16
48
12
2
24
3
12
y x
x
x
x
x
x
x
⋅
⋅⋅
=
−
+
=
−
+
=
−
+
, 
 
and with  
5
α =
 we get 
 
       
(
)
2
3
5
3
5
5
3
2
2 4
2
4 2
4
4
1
( )
32
160
120 .
6
120
3
15
120
y
x
x
x
x
x
x
x
x
x
⋅
⋅⋅
=
−
+
=
−
+
=
−
+
 
 
 
The figure below shows the interlaced zeros of the 4th and 5th Hermite polynomials.   
 
 
 
 
 
 
 
 
 
 
 
 
 

 
Section 11.2 
565 
34.  
Substitution of  y  =  Σcnxn  in the Airy equation leads upon shift of index and collection 
 
of terms to 
 
 
 
 
[
]
2
2
1
1
2
(
1)(
2)
0.
n
n
n
n
c
n
n
c
c
x
∞
+
−
=
+
+
+
−
=
∑
 
 
 
The identity principle then gives  
2
0
c =
 and the recurrence formula 
 
 
 
 
 
3
.
(
2)(
3)
n
n
c
c
n
n
+
=
+
+
 
 
Because of the "3-step" in indices, it follows that  
2
5
8
11
0.
c
c
c
c
=
=
=
=
=

  Starting 
 
with  
0
1,
c =
 we calculate 
 
 
 
3
6
9
1
1
1
1 4
1 4
1 4 7
,
,
,
.
2 3
3!
3! 5 6
6!
6! 8 9
9!
c
c
c
⋅
⋅
⋅⋅
=
=
=
=
=
=
=
⋅
⋅⋅
⋅⋅
…  
 
 
Starting with  
1
1,
c =
 we calculate 
 
 
 
4
7
10
1
2
2
2 5
2 5
2 5 8
,
,
,
.
3 4
4!
4! 6 7
7!
7! 9 10
10!
c
c
c
⋅
⋅
⋅⋅
=
=
=
=
=
=
⋅
⋅⋅
⋅⋅
…  
 
 
 
 
 
Evidently we are building up the coefficients 
 
 
 
 
3
3
1
1 4
(3
2)
2 5
(3
1)
and
(3 )!
(3
1)!
k
k
k
k
c
c
k
k
+
⋅⋅
−
⋅⋅
−
=
=
+


 
 
 
that appear in the desired series for  
1
2
( ) and
( ).
y x
y
x   Finally, the Mathematica  
 
commands 
 
 
A@1D = 1
6 ; A@k_D :=
A@k −1D
3 k H3 k −1L
B@1D = 1
12 ; B@k_D :=
B@k −1D
3 k H3 k + 1L
n = 40;
y1 = 1+ ‚
k=1
n
A@kD x3 k;
y2 = x + ‚
k=1
n
B@kD x3 k+1;
yA =
y1
32ê3 GammaA 2
3 E
−
y2
31ê3 GammaA 1
3 E
;
yB =
y1
31ê6 GammaA 2
3 E
+
y2
3−1ê6 GammaA 1
3 E
;
Plot@ 8yA, yB<, 8x, −13.5, 3<, PlotRange →8−0.75, 1.5<D; 
 
 

566 
Chapter 11 
 
-10
-5
x
-0.5
1
y
AiHxL
BiHxL
 
 
produce the figure above.  But with  
50
n =
 (instead of  
40
n =
) terms we get a figure that is 
visually indistinguishable from Figure 11.2.3 in the textbook. 
 
 
 
 
SECTION 11.3 
 
FROBENIUS SERIES SOLUTIONS 
 
1. 
Upon division of the given differential equation by  x  we see that  P(x)  =  1 − x2  and  
Q(x)  =  (sin x)/x.  Because both are analytic at  x  =  0  — in particular,  (sin )/
1
x
x →  
as  
0
x →
 because  
 
 
 
 
2
1
2
2
4
6
0
1
sin
1
( 1)
( 1)
1
(2
1)!
(2
1)!
3!
5!
7!
n
n
n
n
n
n
x
x
x
x
x
x
x
x
n
n
+
∞
∞
=
=
−
−
=
=
=
−
+
−
+
+
+
∑
∑
 
 
— it follows that  x  =  0  is an ordinary point. 
 
2. 
Division of the differential equation by  x  yields 
 
 
 
 
1
0.
xe
y
xy
y
x
−
′′
′
+
+
=
 
 
Because the function 
 
 
 
 
1
2
3
0
1
1
1
1
1
!
!
2!
3!
4!
x
n
n
n
n
e
x
x
x
x
x
x
x
n
n
−
∞
∞
=
=


−
=
−
=
=
+
+
+
+




∑
∑
 
 
is analytic at the origin,  we see that  x  =  0  is an ordinary point. 
 
3. 
When we rewrite the given equation in the standard form of Equation (3) in  
this section, we see that  p(x)  =  (cos x)/x  and  q(x)  =  x.  Because  (cos
)/
x
x →∞ as  
0
x →
  it follows that  p(x)  is not analytic, so  x  =  0  is an irregular singular point. 

 
Section 11.3 
567 
4. 
When we rewrite the given equation in the standard form of Equation (3), we have  p(x)  
=  2/3  and  q(x)  =  (1 − x2)/3x.  Since  q(x)  is not analytic at the origin,  x  =  0  is an 
irregular singular point. 
 
5. 
In the standard form of Equation (3) we have  p(x)  =  2/(1 + x)  and  q(x)  =  3x2/(1 + x).  
Both are analytic, so  x  =  0  is a regular singular point.  The indicial equation is 
 
 
 
 
 
r(r − 1) + 2r  =  r2 + r  =  r(r + 1)  =  0, 
 
 
so the exponents are  r1  =  0  and r2  =  −1. 
 
6. 
In the standard form of Equation (3) we have  p(x)  =  2/(1 − x2)  and  q(x)  =   
 
−2/(1 − x2), so  x  =  0  is a regular singular point with  p0  =  2  and q0  =  −2.  The 
indicial equation is r2 + r − 2  =  0,  so the exponents are  r  =  −2, 1. 
 
7. 
In the standard form of Equation (3) we have  p(x)  =  (6 sin x)/x  and  q(x)  =  6,  so   
 
x  = 0  is a regular singular point with  p0  =  q0  =  6.  The indicial equation is  r2 + 5r + 6  
=  0,  so the exponents are  r1  =  −2  and  r2  =  −3. 
  
8. 
In the standard form of Equation (3) we have  p(x)  =  21/(6 + 2x)  and  q(x)  =  
 
9(x2 − 1)/(6 + 2x),  so  x  =  0  is a regular singular point with  p0  =  7/2  and  q0  =  −3/2. 
The indicial equation simplifies to  2r2 + 5r − 3  =  0,  so the  exponents are  r  =  −3, 1/2. 
 
9. 
The only singular point of the differential equation  
2
0
1
1
x
x
y
y
y
x
x
′′
′
+
+
=
−
−
 is  x  =  1.  
Upon substituting  t  =  x − 1,  x  =  t + 1  we get the transformed equation 
2
1
(
1)
0,
t
t
y
y
y
t
t
+
+
′′
′
−
−
=
 where primes now denote differentiation with respect to  t.  
In the standard form of Equation (3) we have  ( )
(1
)
p t
t
= −
+
  and  
2
( )
(1
) .
q t
t
t
= −
+
  
Both these functions are analytic, so it follows that  x  =  1  is a regular singular point of 
the original equation. 
   
10. 
The only singular point of the differential equation  
2
2
1
0
1
(
1)
y
y
y
x
x
′′
′
+
+
=
−
−
 is   
 
x  =  1.  Upon substituting  t  =  x − 1,  x  =  t + 1  we get the transformed equation 
2
2
1
0,
y
y
y
t
t
′′
′
+
+
=
 where primes now denote differentiation with respect to  t.  In the 
standard form of Equation (3) we have  ( )
2
p t
≡
  and  ( )
1.
q t
≡
  Both these functions 
are analytic, so it follows that  x  =  1  is a regular singular point of the original equation. 
 
11. 
The only singular points of the differential equation  
2
2
2
12
0
1
1
x
y
y
y
x
x
′′
′
−
+
=
−
−
 are  
 
x  =  +1  and  x  =  –1. 
 

568 
Chapter 11 
 
x  =  +1:  Upon substituting  t  =  x − 1,  x  =  t + 1  we get the transformed equation 
2(
1)
12
0,
(
2)
(
2)
t
y
y
y
t t
t t
+
′′
′
+
−
=
+
+
 where primes now denote differentiation with respect to  
t.  In the standard form of Equation (3) we have  
2(
1)
( )
2
t
p t
t
+
=
+
  and  
12
( )
.
2
t
q t
t
= −+
  
Both these functions are analytic at  t = 0, so it follows that  x  =  +1  is a regular singular 
point of the original equation. 
 
 
x  =  –1:  Upon substituting  t  =  x + 1,  x  =  t – 1  we get the transformed equation 
2(
1)
12
0,
(
2)
(
2)
t
y
y
y
t t
t t
−
′′
′
+
−
=
−
−
 where primes now denote differentiation with respect to  
t.  In the standard form of Equation (3) we have  
2(
1)
( )
2
t
p t
t
−
=
−
  and  
12
( )
.
2
t
q t
t
= −−
  
Both these functions are analytic at  t = 0, so it follows that  x  =  –1  is a regular singular 
point of the original equation. 
 
12. 
The only singular point of the differential equation  
3
3
3
0
2
(
2)
x
y
y
y
x
x
′′
′
+
+
=
−
−
 is   
 
x  =  2.  Upon substituting  t  =  x − 2,  x  =  t + 2  we get the transformed equation 
3
3
3
(
2)
0,
t
y
y
y
t
t
+
′′
′
+
+
=
 where primes now denote differentiation with respect to  t.  In 
the standard form of Equation (3) we have  ( )
3
p t
≡
  and  
3
(
2)
( )
.
t
q t
t
+
=
  Because  q  
is not analytic at  t = 0, it follows that  x  =  2  is an irregular singular point of the original 
equation. 
 
13. 
The only singular points of the differential equation  
1
1
0
2
2
y
y
y
x
x
′′
′
+
+
=
−
+
 are  
 
x  =  +2  and  x  =  –2. 
 
 
x  =  +2:  Upon substituting  t  =  x − 2,  x  =  t + 2  we get the transformed equation 
1
1
0,
4
y
y
y
t
t
′′
′
+
+
=
+
 where primes now denote differentiation with respect to  t.  In the 
standard form of Equation (3) we have  ( )
4
t
p t
t
=
+
  and  ( )
.
q t
t
=
  Both these 
functions are analytic at  t = 0, so it follows that  x  =  +2  is a regular singular point of the 
original equation. 
 
 
x  =  –2:  Upon substituting  t  =  x + 2,  x  =  t – 2  we get the transformed equation 
1
1
0,
4
y
y
y
t
t
′′
′
+
+
=
−
 where primes now denote differentiation with respect to  t.  In the 

 
Section 11.3 
569 
standard form of Equation (3) we have  ( )
1
p t
≡
  and  
2
( )
.
4
t
q t
t
=
−
  Both these 
functions are analytic at  t = 0, so it follows that  x  =  –2  is a regular singular point of the 
original equation. 
 
14. 
The only singular points of the differential equation  
2
2
2
2
2
2
9
4
0
(
9)
(
9)
x
x
y
y
y
x
x
+
+
′′
′
+
+
=
−
−
 
are  x  =  +3  and  x  =  –3. 
 
 
x  =  +3:  Upon substituting  t  =  x − 3,  x  =  t + 3  we get the transformed equation 
2
2
2
2
2
2
2
2
6
13
6
18
0,
(
6)
(
6)
t
t
t
t
y
y
y
t
t
t
t
+
+
+
+
′′
′
+
+
=
+
+
 where primes now denote differentiation with 
respect to  t.  Because  
2
2
2
6
13
( )
(
6)
t
t
p t
t t
+
+
=
+
  is not analytic at  t = 0, it follows that  x  =  3  
is an irregular singular point of the original equation. 
 
 
x  =  –3:  Upon substituting  t  =  x + 3,  x  =  t – 3  we get the transformed equation 
2
2
2
2
2
2
2
2
6
13
6
18
0,
(
6)
(
6)
t
t
t
t
y
y
y
t
t
t
t
−
+
−
+
′′
′
+
+
=
−
−
 where primes now denote differentiation with 
respect to  t.  Because  
2
2
2
6
13
( )
(
6)
t
t
p t
t t
−
+
=
−
  is not analytic at  t = 0, it follows that  x  =  –3  
is an irregular singular point of the original equation. 
 
15. 
The only singular point of the differential equation  
2
2
2
4
2
0
(
2)
(
2)
x
x
y
y
y
x
x
−
+
′′
′
−
+
=
−
−
 is   
 
x  =  2.  Upon substituting  t  =  x − 2,  x  =  t + 2  we get the transformed equation 
2
4
4
0,
t
t
y
y
y
t
t
+
+
′′
′
−
+
=
 where primes now denote differentiation with respect to  t.  In 
the standard form of Equation (3) we have  ( )
(
4)
p t
t
= −
+
  and  ( )
4.
q t
t
=
+
  Both 
these functions are analytic, so it follows that  x  =  2  is a regular singular point of the 
original equation. 
 
16. 
The only singular points of the differential equation  
3
2
3
2
1
0
(1
)
(1
)
x
y
y
y
x
x
x
x
+
′′
′
+
+
=
−
−
 
are  x  =  0  and  x  =  1. 
 
 
x  =  0:  In the standard form of Equation (3) we have  
2
3
2
( )
(1
)
x
p x
x
x
+
=
−
  and  
1
( )
.
1
q x
x
=
−
  Since  p  is not analytic at  x = 0,  it follows that  x = 0  is an irregular 
singular point. 

570 
Chapter 11 
 
 
x  =  1:  Upon substituting  t  =  x – 1,  x  =  t + 1  we get the transformed equation 
3
2
3
5
0,
(
1)
(
1)
t
t
y
y
y
t
t
+
′′
′
−
−
=
+
+
 where primes now denote differentiation with respect  
 
to  t.  Both  
3
(3
5)
( )
(
1)
t
t
p t
t
+
≡−
+
  and  
3
2
( )
(
1)
t
q t
t
= −
+
 are analytic at  t = 0, so it follows 
that  x  =  1  is a regular singular point of the original equation. 
 
Each of the differential equations in Problems 17−20 is of the form 
 
                
 
 
 
Axy'' + By' + Cy  =  0 
 
with indicial equation  Ar2 + (B − A)r  =  0.  Substitution of  y  =  Σcnxn+r  into the differential  
equation yields the recurrence relation 
 
 
 
 
1
2
(
)
(
)(
)
n
n
C c
c
A n
r
B
A n
r
−
= −
+
+
−
+
 
for  n  ≥  1.  In these problems the exponents  r1  =  0  and  r2  =  (A − B)/A  do not differ by an 
integer, so this recurrence relation yields two linearly independent Frobenius series solutions 
when we apply it separately with  r  =  r1  and with  r  =  r2. 
 
17. 
With exponent  1
0:
r =
   
1
2
4
2
n
n
c
c
n
n
−
= −
−
 
 
(
)
2
2
3
0
1
0
( 1)
( )
1
cos
2
24
720
(2 )!
n
n
n
x
x
x
x
y x
x
x
n
∞
=
−


=
−
+
−
+
=
=




∑

 
 
With exponent  2
1 :
2
r =
   
1
2
4
2
n
n
c
c
n
n
−
= −
+
 
 
(
)
2
1
2
3
1/ 2
2
0
( 1)
( )
1
sin
6
120
5040
(2
1)!
n
n
n
x
x
x
x
y
x
x
x
n
+
∞
=
−


=
−
+
−
+
=
=


+


∑

 
 
18. 
With exponent  1
0:
r =
   
1
2
2
n
n
c
c
n
n
−
=
+
 
 
2
3
4
0
1
0
( )
1
3
30
630
22680
!(2
1)!!
n
n
x
x
x
x
x
y x
x
n
n
∞
=


=
+
+
+
+
+
=


+


∑

 
 
With exponent  2
1 :
2
r = −
   
1
2
2
n
n
c
c
n
n
−
=
−
 
 
2
3
4
1/ 2
2
1
1
( )
1
1
6
90
2520
!(2
1)!!
n
n
x
x
x
x
y
x
x
x
n
n
x
∞
−
=




=
+
+
+
+
+
=
+




−




∑

 
 

 
Section 11.3 
571 
 
19. 
With exponent  1
0:
r =
   
1
2
2
3
n
n
c
c
n
n
−
=
−
 
 
2
3
4
0
1
2
( )
1
1
2
18
360
!(2
3)!!
n
n
x
x
x
x
y x
x
x
x
n
n
∞
=


=
−
−
−
−
−
= −
−


−


∑

 
 
With exponent  2
3 :
2
r =
   
1
2
2
3
n
n
c
c
n
n
−
=
+
 
 
2
3
4
3/ 2
3/ 2
2
1
( )
1
1
3
5
70
1890
83160
!(2
3)!!
n
n
x
x
x
x
x
y
x
x
x
n
n
∞
=




=
+
+
+
+
+
=
+




+




∑

 
 
20. 
With exponent  1
0:
r =
   
1
2
2
3
n
n
c
c
n
n
−
= −
−
 
 
2
3
4
0
1
1
( 1) 2
( )
1
1
5
60
1320
! 2 5
(3
1)
n
n
n
n
x
x
x
x
y x
x
x
n
n
∞
=


−
=
−
+
−
+
−
= +


⋅⋅⋅
⋅
−


∑


 
 
With exponent  2
1 :
3
r =
   
1
2
2
3
n
n
c
c
n
n
−
= −
+
 
 
2
3
4
1/ 3
1/3
2
0
( 1) 2
( )
1
2
14
210
5460
! 1 4
(3
1)
n
n
n
n
x
x
x
x
x
y
x
x
x
n
n
∞
=


−
=
−
+
−
+
−
=


⋅⋅⋅
⋅
+


∑


 
 
The differential equations in Problems 21–24 are all of the form 
 
 
 
 
 
Ax2y'' + Bxy' +(C + Dx2)y  =  0 
 
 
 
(1) 
with indical equation 
 
 
 
 
φ(r)  =  Ar2 + (B − A)r + C  =  0. 
 
 
 
(2) 
Substitution of  y  =  Σcnxn+r  into the differential equation yields 
 
 
 
[
]
1
0
1
2
2
( )
(
1)
(
)
0.
r
r
n r
n
n
n
r c x
r
c x
r
n c
D c
x
φ
φ
φ
∞
+
+
−
=
+
+
+
+
+
=
∑
  
 
(3) 
 
In each of Problems 21–24 the exponents  r1  and  r2  do not differ by an integer.  Hence when 
we substitute either  r  =  r1  or  r  =  r2  into Equation (*) above, we find that  c0  is arbitrary 
because ( )r
φ
 is then zero, that  c1  =  0 — because its coefficient  (
1)
r
φ
+
 is then nonzero — 
and that 
 
 
2
2
2
(
)
(
)
(
)(
)
n
n
n
Dc
Dc
c
r
n
A n
r
B
A n
r
C
φ
−
−
= −
= −
+
+
+
−
+
+
 
 
 
(4) 
 
for  n  ≥  2.  Thus this recurrence formula yields two linearly independent Frobenius series 
solutions when we apply it separately with  r  =  r1  and with  r  =  r2. 
 

572 
Chapter 11 
21. 
With exponent  1
1:
r =
   
2
1
2
0,
(2
3)
n
n
c
c
c
n
n
−
=
=
+
 
 
2
4
6
2
1
1
1
( )
1
1
7
154
6930
! 7 11
(4
3)
n
n
x
x
x
x
y x
x
x
n
n
∞
=




=
+
+
+
+
=
+




⋅⋅
⋅
⋅
+




∑


 
 
With exponent  2
1 :
2
r = −
   
2
1
2
0,
(2
3)
n
n
c
c
c
n
n
−
=
=
−
 
 
4
6
2
1/ 2
2
2
1
1
( )
1
1
10
270
! 1 5
(4
3)
n
n
x
x
x
y
x
x
x
n
n
x
∞
−
=




=
+
+
+
+
=
+




⋅⋅⋅
⋅
−




∑


 
 
22. 
With exponent  1
3 :
2
r =
   
2
1
2
0,
(2
5)
n
n
c
c
c
n
n
−
=
= −
+
 
 
2
4
6
2
3/ 2
3/ 2
1
1
( )
1
1
9
234
11934
! 9 13
(4
5)
n
n
x
x
x
x
y x
x
x
n
n
∞
=




=
−
+
−
+
=
+




⋅⋅
⋅
⋅
+




∑


 
 
With exponent  2
1:
r = −
   
2
1
2
0,
(2
5)
n
n
c
c
c
n
n
−
=
= −
−
 
 
4
6
8
1
2
1
2
2
2
2
1
( 1)
( )
1
1
6
126
5544
! 3 7
(4
5)
n
n
n
x
x
x
x
y
x
x
x
x
x
n
n
−
∞
−
=




−
=
+
−
+
−
+
=
+
+




⋅⋅⋅
⋅
−




∑


 
 
23. 
With exponent  1
1 :
2
r =
   
2
1
0,
(6
7)
n
n
c
c
c
n
n
−
=
=
+
 
 
2
2
4
6
1/ 2
1
1
1
( )
1
2
! 19 31
(12
7)
38
4712
1215696
n
n
n
x
x
x
x
x
x
y x
n
n
∞
=




+
=
+
+
+
+
=




⋅
⋅
⋅
⋅
+




∑


 
 
With exponent  2
2 :
3
r = −
   
2
1
0,
(6
7)
n
n
c
c
c
n
n
−
=
=
−
 
 
2
2
4
6
2/3
2 /3
2
1
( )
1
1
2
! 5 17
(12
7)
10
680
118320
n
n
n
x
x
x
x
x
y
x
x
n
n
∞
−
−
=




=
+
+
+
+
+
=




⋅⋅
⋅
⋅
−




∑


 
 
24. 
With exponent  1
1 :
3
r =
   
2
1
0,
(3
1)
n
n
c
c
c
n
n
−
=
= −
+
 
 
2
4
6
2
1/3
3
1
1
( 1)
( )
1
1
14
728
82992
2
! 7 13
(6
1)
n
n
n
n
x
x
x
x
y x
x
x
n
n
∞
=




−
=
−
+
−
+
=
+




⋅⋅
⋅
⋅
+




∑


 
 
With exponent  2
0:
r =
   
2
1
0,
(3
1)
n
n
c
c
c
n
n
−
=
= −
−
 
 
2
2
4
6
0
2
1
( 1)
1
( )
1
2
! 5 11
(6
1)
10
440
44880
n
n
n
n
x
x
x
x
y
x
x
n
n
∞
=


−
+
=
−
+
−
+
=


⋅⋅
⋅
⋅
−


∑


 
 

 
Section 11.3 
573 
25. 
 With exponent  1
1 :
2
r =
   
1
2
n
n
c
c
n
−
= −
 
 
2
3
4
/ 2
1/ 2
1
0
( 1)
( )
1
!2
2
8
48
384
n
n
x
n
n
x
x
x
x
x
x
x e
y x
x
n
∞
−
=


−
=
=
−
+
−
+
−
=




∑

 
 
With exponent  2
0:
r =
   
1
2
1
n
n
c
c
n
−
= −
− 
 
2
3
4
0
2
1
( 1)
1
( )
1
(2
1)!!
3
15
105
n
n
n
x
x
x
x
y
x
x
x
n
∞
=
−


+
=
−
+
−
+
−
=


−


∑

 
                
26. 
With exponent  1
1 :
2
r =
   
2
1
0,
n
n
c
c
c
n
−
=
=
 
 
2
2
2
4
6
8
/ 2
1/ 2
1
0
( )
1
!2
2
8
48
384
n
x
n
n
x
x
x
x
x
e
y x
x
x
x
n
∞
=


=
=
+
+
+
+
+
=




∑

 
 
With exponent  2
0:
r =
   
2
1
2
0,
2
1
n
n
c
c
c
n
−
=
=
− 
 
2
4
6
8
2
0
2
1
2
4
8
16
2
( )
1
1
3
21
231
3465
3 7
(4
1)
n
n
n
x
x
x
x
x
y
x
x
n
∞
=


=
+
+
+
+
+
=
+


⋅⋅
⋅
−


∑


                
 
The differential equations in Problems 27–29 (after multiplication by  x) and the one in Problem 
31 are of the same form (1) above as those in Problems 21–24.  However, now the exponents  r1  
and  r2  =  r1 − 1  do differ by an integer.  Hence when we substitute the smaller exponent  r  =  r2  
into Equation (3), we find that  c0  and  c1  are both arbitrary, and that  cn  is given  (for n  ≥  2)  
by the recurrence relation in (4). Thus the smaller exponent  r2  yields the general solution  
0
1
1
2
( )
( )
( )
y x
c y x
c y
x
=
+
  in terms of the two linearly independent Frobenius series solutions 
1
2
( ) and
( ).
y x
y
x  
27. 
Exponents  1
2
0 and
1;
r
r
=
= − with  
2
9
1:
(
1)
n
n
c
r
c
n n
−
= −
= −
−
 
 
2
4
6
3
5
7
0
1
9
27
81
3
27
81
( )
1
2
8
80
2
40
560
c
x
x
x
c
x
x
x
y x
x
x
x




=
−
+
−
+
+
−
+
−
+









  
 
2
4
6
3
5
7
0
1
9
81
729
27
243
2187
1
3
2
24
720
3
6
120
5040
c
x
x
x
c
x
x
x
x
x
x




=
−
+
−
+
+
−
+
−
+









  
 
0
1
cos3
1
sin3
( )
3
x
x
y x
c
c
x
x
=
+
 
 
The figure at the top of the next page shows the graphs of the independent solutions 
1
2
cos3
sin3
( )
and
( )
.
x
x
y x
y
x
x
x
=
=
 

574 
Chapter 11 
2 p
4 p
x
-1
1
y
y1
y2
 
 
28. 
Exponents  1
2
0 and
1;
r
r
=
= − with  
2
4
1:
(
1)
n
n
c
r
c
n n
−
= −
=
−
 
 
4
6
3
5
7
2
0
1
2
4
2
2
4
( )
1
2
3
45
3
15
315
c
x
x
c
x
x
x
y x
x
x
x
x




=
+
+
+
+
+
+
+
+
+









  
 
2
4
6
3
5
7
0
1
4
16
96
8
32
128
1
2
2
24
720
2
6
120
5040
c
x
x
x
c
x
x
x
x
x
x




=
+
+
+
+
+
+
+
+
+









  
 
0
1
cosh2
1
sinh2
( )
2
x
x
y x
c
c
x
x
=
+
 
 
The figure below shows the graphs of the independent solutions 
 
1
2
cosh2
sinh2
( )
and
( )
.
x
x
y x
y
x
x
x
=
=
 
 
1
2
x
2
4
6
8
y
y1
y2
 
 

 
Section 11.3 
575 
29. 
Exponents  1
2
0 and
1;
r
r
=
= − with  
2
1:
4 (
1)
n
n
c
r
c
n n
−
= −
= −
−
 
 
2
4
6
3
5
7
0
1
( )
1
8
384
46080
24
1920
322560
c
x
x
x
c
x
x
x
y x
x
x
x




=
−
+
−
+
+
−
+
−
+









  
 
2
4
6
3
5
7
0
1
2
4
6
3
5
7
2
1
2
2
2
24
2
720
2
2
6
2
120
2
5040
c
x
x
x
c
x
x
x
x
x
x




=
−
+
−
+
+
−
+
−
+




⋅
⋅
⋅
⋅
⋅
⋅





  
 
0
1
2
( )
cos
sin
2
2
c
x
c
x
y x
x
x
=
+
 
 
The figure below shows the graphs of the independent solutions 
 
1
2
cos
/ 2
sin
/ 2
( )
and
( )
.
x
x
y x
y
x
x
x
=
=
 
 
2 p
4 p
x
-0.5
0.5
1
y
y1
y2
 
 
 
30. 
The given differential equation 
3
4
0
xy
y
x y
′′
′
−
+
=
 has indicial equation  
2
2
(
2)
0,
r
r
r r
−
=
−
=
 so its exponents are  1
2
2 and
0.
r
r
=
=
  Taking  r = 0,  
 
substitution of the power series  
0
n
n
n
y
c x
∞
=
= ∑
 gives 
 
 
2
3
4
5
1
3
0
4
1
5
2
6
6
7
8
3
7
4
8
5
9
2
(4
8
)
(4
15 )
(4
24
)
(4
35
)
(4
48 )
(4
63 )
0.
c
c x
c
c
x
c
c x
c
c x
c
c x
c
c x
c
c x
−
+
+
+
+
+
+
+
+
+
+
+
+
+
+
=

 
 
 
We see that  
1
3
0
c
c
=
=
 and 
 
 
 
 
4
4
for
4.
(
2)
n
n
c
c
n
n n
−
= −
≥
−
 
 
Hence the odd subscripts all vanish, and we obtain 

576 
Chapter 11 
 
 
4
8
12
6
10
14
2
0
2
( )
1
2
24
720
6
120
5040
x
x
x
x
x
x
y x
c x
c
x




=
−
+
−
+
+
−
+
−
+









  
 
 
2
2
0
2
( )
cos
sin
.
y x
c
x
c
x
=
+
 
 
The figure below shows the graphs of the independent solutions 
 
2
2
1
2
( )
cos
and
( )
sin
.
y x
x
y
x
x
=
=
 
 
p
2
p
x
-1
1
y
y2
y1
 
 
31. 
The given differential equation 
2
2
4
4
(3
4
)
0
x y
xy
x
y
′′
′
−
+
−
=
 has indicial equation  
2
4
8
3
(2
3)(2
1)
0,
r
r
r
r
−
+
=
−
−
=
 so its exponents are  1
2
3/ 2 and
1/ 2.
r
r
=
=
 
 
With  r = 3/2,  the recurrence relation  
2 / (
1)
n
n
c
c
n n
−
=
−
  yields the general solution 
 
 
 
2
4
6
3
5
7
1/ 2
1/ 2
0
1
( )
1
2
24
720
6
120
5040
x
x
x
x
x
x
y x
c x
c x
x




=
+
+
+
+
+
+
+
+
+









  
 
 
0
1
( )
cosh
sinh .
y x
c
x
x
c
x
x
=
+
 
 
The figure below shows the graphs of the independent solutions 
 
1
2
( )
cosh
and
( )
sinh .
y x
x
x
y
x
x
x
=
=
 
 
1
x
1
y
y1
y2
 

 
Section 11.3 
577 
32. 
The two indicial exponents are  r1  =  1  and  r2  =  −1/2.   
 
With  r1  =  1:  Substitution of  
n
n
y
x
c x
= ∑
 in the differential equation yields 
 
 
 
2
3
4
4
6
1
0
2
2
3
3
4
4
6
(5
)
14
(
27
)
(2
44
)
(3
65 )
0.
c
c x
c x
c
c x
c
c
x
c
c x
−
+
+
+
+
+
+
+
+
=

 
Hence we see that  
1
0 / 5
c
c
=
  and  
2
3
4
5
0.
c
c
c
c
=
=
=
=
  Thus the series terminates 
and we obtain the polynomial solution 
 
 
 
2
1( )
1
.
5
5
x
x
y x
x
x


=
+
=
+




 
With  r2  =  −1/2:  We substitute  
1/ 2
n
n
y
x
c x
−
=
∑
 and obtain the Frobenius solution 
 
 
2
3
4
2
1
5
15
5
( )
1
.
2
8
48
384
x
x
x
x
y
x
x


=
−
−
−
+
+





 
Remark:  The Mathematica DSolve function yields the two closed form solutions  
1( )
y x   
and 
 
 
(
)
(
)
1/2
/2
2
3( )
4
2
1 erf
.
2
2
x
x
y x
x
e
x
x
x x
π
−
−
=
+
−
+
+
 
Inquiring minds naturally want to know!  The Mathematica Series command reveals 
the answer that  
1
2
3
2
( )
( ).
y
x
y x
= −
 
 
33. 
Exponents  1
2
1/ 2 and
1
r
r
=
= −.  With each exponent we find that  c0  is arbitrary and  
 
we can solve recursively for  cn  in terms of  cn–1. 
 
 
2
3
4
1
11
11
671
9577
( )
1
20
224
24192
387072
x
x
x
x
y x
x 

=
+
−
+
−
+




  
 
3
4
2
2
1
10
7
( )
1 10
5
9
18
x
x
y
x
x
x
x


=
+
+
+
−
+




  
 
34. 
Exponents  1
2
1 and
1/ 2.
r
r
=
= −
  With each exponent we find that  c1 = 0 and we can  
 
solve recursively for  cn  in terms of  cn–2. 
 
 
2
4
6
1
37
( )
1
42
1320
2494800
x
x
x
y x
x

=
−
+
−
−




  
 
2
4
6
2
1
7
19
7661
( )
1
24
3200
43545600
x
x
x
y
x
x


=
−
+
−
+




  
 

578 
Chapter 11 
35. 
Substitution of  
r
n
n
y
x
c x
= ∑
 into the differential equation yields a result of the form 
 
 
 
1
1
0
(
)
(
)
0,
r
r
r
rc x
x
x
−
+
−
+
+
+
=



 
 
so we see immediately that  
0
0
c ≠
 implies that  r = 0.  Then substitution of the power 
 
series  
n
n
y
c x
= ∑
 yields 
 
 
 
2
4
0
1
1
2
2
3
3
4
(
)
(4
2
)
(9
3 )
(16
4
)
0
c
c
c
c x
c
c x
c
c
x
−
+
−
+
−
+
−
+
=

 
Evidently  
1,
n
n
c
nc −
=
  so if  c0 = 1  it follows that  
!
nc
n
=
  for  
1.
n ≥
  But the series  
!
n
n x
∑
has zero radius of convergence, and hence converges only if  x = 0.  We 
therefore conclude that the given differential equation has no nontrivial Frobenius series 
solution. 
 
36. 
(a) 
Substitution of  
r
n
n
y
x
c x
= ∑
 into the differential equation 
2
0
x y
Ay
By
′′
′
+
+
=
 
 
yields a result of the form 
 
 
 
1
1
0
(
)
(
)
0,
r
r
r
Arc x
x
x
−
+
+
+
+
=



 
 
so we see immediately that  
0
A ≠
 and 
0
0
c ≠
 imply that  r = 0.   
 
(b) 
Substitution of  
r
n
n
y
x
c x
= ∑
 into the differential equation 
3
0
x y
Axy
By
′′
′
+
+
=
 
 
yields a result of the form 
 
 
 
1
2
0
(
)
(
)
(
)
0,
r
r
r
Ar
B c x
x
x
+
+
+
+
+
+
=



 
 
so we see immediately that 
0
0
c ≠
 implies that  r = –B/A.    
 
(c) 
Substitution of  
r
n
n
y
x
c x
= ∑
into the differential equation 
3
2
0
x y
Ax y
By
′′
′
+
+
=
 
 
yields a result of the form 
 
 
 
1
2
0
(
)
(
)
0,
r
r
r
Bc x
x
x
+
+
+
+
+
=



 
 
which is impossible because both 
0
0
c ≠
 and  
0
B ≠
.  It follows that no Frobenius series  
 
can satisfy this equation. 
 
37. 
Substitution of  
r
n
n
y
x
c x
= ∑
 into the differential equation  
3
0
x y
y
y
′′
′
−
+
=
 
 
yields a result of the form 
 
 
 
2
1
2
0
(
1)
(
)
(
)
0,
r
r
r
r
c x
x
x
+
+
−
+
+
+
=



 
 
so it follows that  r = 1.    But then substitution of  
n
n
y
x
c x
= ∑
 into the differential  
 
equation yields  
 
 
 
2
3
4
5
6
1
2
3
4
5
4
9
16
25
0,
c x
c x
c x
c x
c x
+
+
+
+
+
=

 

 
Section 11.3 
579 
 
so it follows that  
1
2
3
4
0.
c
c
c
c
=
=
=
=
=

  Hence 
0
( )
,
y x
c x
=
 
 
38. 
Exponents  1
2
1/ 2 and
1/ 2;
r
r
=
= −
 with  
2
1/ 2 :
(
1)
n
n
c
r
c
n n
−
= −
= −
−
 
 
2
4
6
3
5
7
0
1
( )
1
2
24
720
6
120
5040
c
x
x
x
c
x
x
x
y x
x
x
x




=
−
+
−
+
+
−
+
−
+









  
 
2
4
6
3
5
7
0
1
1
2!
4!
6!
3!
5!
7!
c
x
x
x
c
x
x
x
x
x
x




=
−
+
−
+
+
−
+
−
+









  
 
0
1
cos
sin3
( )
x
x
y x
c
c
x
x
=
+
 
 
39. 
Exponents  1
2
1 and
1;
r
r
=
= −
 with  
2
1
1:
0,
(
2)
n
n
c
r
c
c
n n
−
= +
=
= −
+
 
 
2
4
6
8
0
( )
1
8
192
9216
737280
x
x
x
x
y x
c x

=
−
+
−
+
−




  
 
2
4
6
8
0
2
4
6
8
1
2 1!2!
2 2!3!
2 3!4!
2 4!5!
x
x
x
x
c x

=
−
+
−
+
−




  
 
If  c0 = 1/2, then 
 
 
 
2
1
0
( 1)
( )
( )
.
2
!(
1)
2
n
n
n
x
x
y x
J
x
n n
∞
=
−


=
=


+


∑
 
Now, consider the smaller exponent  r2 = –1.  A Frobenius series with  r = –1 is of the 
form 
1
0
n
n
n
y
x
c x
∞
−
=
=
∑
 with  
0
0.
c ≠
  However, substitution of this series into Bessel's  
equation of order 1 gives 
 
 
 
2
3
5
1
0
1
3
2
4
3
5
(
3 )
(
8
)
(
15 )
0,
c
c x
c
c x
c
c
x
c
c x
−
+
+
+
+
+
+
+
+
=

 
 
so it follows that  c0 = 0, after all.  Thus Bessel's equation of order 1 does not have a 
Frobenius series solution with leading term  c0x–1.  However, there is a little more here 
that meets the eye.  We see further that  c2  is arbitrary and that  
1
0 and
c =
 
2 / (
2) for
2.
n
n
c
c
n n
n
−
=
−
>
 It follows that our assumed Frobenius series  
1
0
n
n
n
y
x
c x
∞
−
=
=
∑
  actually reduces to 
 
 
2
4
6
8
2
( )
1
8
192
9216
737280
x
x
x
x
y x
c x

=
−
+
−
+
−




 . 
But this is the same as our series solution obtained above using the larger exponent 
r = +1 (calling the arbitrary constant  c2  rather than  c0). 

580 
Chapter 11 
 
 
 
SECTION 11.4 
 
BESSEL'S EQUATION 
 
Of course Bessel's equation is the most important special ordinary differential equation in 
mathematics, and every student should be exposed at least to Bessel functions of the first kind.   
 
1. 
2
2
1
0
2
2
2
2
1
1
( 1)
( 1) 2
( )
1
2
( !)
2
( !)
m
m
m
m
x
m
m
m
m
x
m x
J
x
D
m
m
−
∞
∞
=
=


−
−
′
=
+
=




∑
∑
 
 
2
1
1
2
1
2
1
2
1
1
0
( 1)
( 1)
2
(
1)!( !)
2
( )!(
1!)
m
m
m
m
m
m
m
m
x
x
m
m
m
m
−
+
+
∞
∞
−
+
=
=
−
−
=
=
−
+
∑
∑
 
 
2
1
1
2
1
0
( 1)
( )
2
( )!(
1!)
m
m
m
m
x
J x
m
m
+
∞
+
=
−
= −
= −
+
∑
 
 
2. 
(a) 
2
1
2
1
2
1
2
2
2
n
n
n
+
−
−




Γ
=
⋅Γ








 
 
 
2
1 2
3
2
3
2
2
2
n
n
n
−
−
−


=
⋅
⋅Γ



 
 
 
2
1 2
3
3 1
1
2
2
2 2
2
n
n
−
−


=
⋅
⋅
⋅
⋅
Γ⋅





 
 
 
(2
1)(2
3)
3 1
(2
1)!!
2
2
n
n
n
n
n
π
π
−
−
⋅
⋅⋅
−
=
⋅
=

 
 
(b) 
1
2
1
2
2
2
1
1/2
2
1
2
1
3
0
0
2
( 1)
2
( 1)
( )
! 2
(2
1)!!
2
!
(
)2
m
m
m
m
m
m
m
m
m
x
x
J
x
x
m
m
m
m
π
+
+
∞
∞
+
−
−
+
=
=
−
−
=
=
+
Γ
+
∑
∑
 
2
1
0
2
( 1)
(2 4
2 )(1 3
(2
1))
m
m
m
x
x
m
m
π
+
∞
=
−
=
⋅⋅
⋅
⋅⋅
⋅
+
∑


 
2
1
0
2
( 1)
2 sin
(2
1)!
m
m
m
x
x
x
m
x
π
π
+
∞
=
−
=
=
+
∑
 
1/2
2
( )
cos
J
x
x
x
π
−
=
  similarly 
 
3. 
(a) 
2
3
2
3
1 3
4
3
4
3
3
3
3
3
m
m
m
m
m
+
−
−
−






Γ
+
= Γ
=
⋅
⋅Γ












 

 
Section 11.4 
581 
 
 
3
1 3
4
5 2
2
2 5 8
(3
1)
2
3
3
3 3
3
3
3
m
m
m
m
−
−
⋅⋅
⋅
−




=
⋅
⋅
⋅
⋅
⋅Γ
=
Γ










 
 
(b) 
2
1/3
1/3
2
1/3
0
0
( 1)
( / 2)
( 1) 3
( )
! (
2/3) 2
(2/3)
! 2 3 8
(3
1)
m
m
m
m
m
m
m
x
x
x
J
x
m
m
m
m
−
−
∞
∞
−
=
=
−
−


=
=


Γ
+
Γ
⋅⋅⋅⋅
⋅
−


∑
∑

 
 
4. 
With  p  =  1/2  in Equation (26) in the text we have  
    
 
 
 
(
)
(
)
3/ 2
1/ 2
1/ 2
3
1
1
2
2
( )
( )
( )
sin
cos
1
2
2
sin
cos
sin
cos
J
x
J
x
J
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
π
π
π
π
−
=
−
=
−
=
−
=
−
 
 
5. 
Starting with  p  =  3  in Equation (26) we get 
 
 
 
4
3
2
2
1
2
1
0
1
2
2
2
0
1
2
3
6
6 4
( )
( )
( )
( )
( )
( )
24
2
6
1
( )
( )
( )
24
8(6
)
( )
( )
J
x
J
x
J
x
J
x
J x
J
x
x
x
x
J x
J
x
J x
x
x
x
x
x
J
x
J x
x
x


=
−
=
−
−







=
−
−
−






−
−
=
+
 
 
8. 
When we carry out the differentiations indicated in Equations (22) and (23) in the text, 
we get 
 
 
 
      
1
1
1
1
( )
( )
( ),
( )
( )
( ).
p
p
p
p
p
p
p
p
p
p
p
p
p x
J
x
x J
x
x J
x
p x
J
x
x
J
x
x J
x
−
−
−−
−
+
′
+
=
′
−
+
= −
 
 
When we solve these two equations for 
( )
p
J
x
′
  we get Equations (24) and (25) in the text. 
 
9. 
Γ(p + m + 1)  =  (p + m)(p + m − 1)⋅
⋅
 (p + 2)(p + 1)Γ(p + 1),  so 
 
 
2
0
2
0
( 1)
( )
! (
1)
2
( / 2)
( 1)
.
(
1)
!(
1)(
2)
(
) 2
m
p
m
p
m
m
p
m
m
x
J
x
m
p
m
x
x
p
m
p
p
p
m
+
∞
=
∞
=
−


=


Γ
+
+


−


=


Γ
+
+
+
⋅
⋅
+


∑
∑

 
 
10. 
Substitution of the power series of Problem 9 yields 
 

582 
Chapter 11 
 
 
5/ 2
5/ 2
5
2
1/ 2
1/ 2
(
)
(
)
(
)
(
)
( )
(
)
(
)
(
)
(
)
x
A
x
B
x
A
B
y x
x
x
C
x
D
x C
D
−
−
+
+
+
+
+
+
=
⋅
=
+
+
+
+
+
+







  
 
 
 
where  A  =  1/(25/2Γ(7/2)),  B  =  1/(2−5/2Γ(−3/2),)  C  =  1/(21/2Γ(3/2)),  and  
 
D  =  (1/2−1/2)Γ(1/2).  Hence 
 
 
 
1/ 2
2
5/ 2
(
)
(
)
0
2
(1/ 2)
2
(1/ 2)
( )
0
3.
(
)
(
)
0
2
( 3/ 2)
(4/3) (1/ 2
A
B
B
y
C
D
D
−
−
+
+
+
⋅
Γ
Γ
=
=
=
=
=
+
+
+
⋅
Γ −
Γ




 
 
In Problems 11–18 we use a conspicuous dot i to indicate our choice of  u  and  dv  in the 
integration by parts formula  
.
u dv
uv
vdu
=
−
∫
∫
i
  We use repeatedly the facts (from Example 
1) that  
0
1
( )
( )
xJ
x dx
xJ x
C
=
+
∫
  and  
1
0
( )
( )
.
J x dx
J
x
C
= −
+
∫
 
 
11. 
2
0
0
( )
( )
x J
x dx
x xJ
x dx
=
∫
∫i
 
 
2
1
1
( )
( )
x J x
x J x dx
=
−∫i
 
 
(
)
2
1
0
0
( )
( )
( )
x J x
xJ
x
J
x dx
=
−−
+∫
 
 
2
1
0
0
( )
( )
( )
x J x
xJ
x
J
x dx
C
=
+
−
+
∫
 
 
12. 
3
2
0
0
( )
( )
x J
x dx
x
xJ
x dx
=
∫
∫
i
 
 
3
2
1
1
( )
2
( )
x J x
x
J x dx
=
−∫
i
 
 
(
)
3
2
1
0
0
( )
2
( )
2
( )
x J x
x J
x
xJ
x dx
=
−
−
+ ∫
 
3
2
3
2
1
0
1
1
0
( )
2
( )
4
( )
(
4 )
( )
2
( )
x J x
x J
x
xJ x
C
x
x J x
x J
x
C
=
+
−
+
=
−
+
+
 
 
13. 
4
3
0
0
( )
( )
x J
x dx
x xJ
x dx
=
∫
∫
i
 
 
4
3
1
1
( )
3
( )
x J x
x J x dx
=
−∫
i
 
 
(
)
4
3
1
0
0
( )
3
( )
3
( )
x J x
x J
x
x xJ
x dx
=
−
−
+ ∫i
 
 
(
)
4
3
2
1
0
1
1
( )
3
( )
9
( )
( )
x J x
x J
x
x J x
x J x dx
=
+
−
−∫i
 
 
(
)
4
3
2
1
0
1
0
0
( )
3
( )
9
( )
9
( )
( )
x J x
x J
x
x J x
xJ
x
J
x dx
=
+
−
+
−
+∫
 
 
4
2
3
1
0
0
(
9
)
( )
(3
9 )
( )
9
( )
x
x
J x
x
x J
x
J
x dx
C
=
−
+
−
+
+
∫
 
 
14. 
1
1
0
0
( )
( )
( )
( )
xJ x dx
x J x dx
xJ
x
J
x dx
C
=
= −
+
+
∫
∫
∫
i
 
 
15. 
2
2
1
1
( )
( )
x J x dx
x
J x dx
=
∫
∫
i
 

 
Section 11.4 
583 
 
2
2
0
0
0
1
( )
2
( )
( )
2
( )
x J
x
xJ
x dx
x J
x
xJ x
C
= −
+
= −
+
+
∫
 
 
16. 
3
3
1
1
( )
( )
x J x dx
x J x dx
=
∫
∫
i
 
 
3
0
0
( )
3
( )
x J
x
x xJ
x dx
= −
+ ∫i
 
 
(
)
3
2
0
1
1
( )
3
( )
( )
x J
x
x J x
x J x dx
= −
+
−∫i
 
 
(
)
3
2
0
1
0
0
( )
3
( )
3
( )
( )
x J
x
x J x
xJ
x
J
x dx
= −
+
−
−
+∫
 
 
3
2
0
1
0
(
3 )
( )
3
( )
3
( )
x
x J
x
x J x
J
x dx
C
=
−
+
+
−
+
∫
 
 
17. 
4
4
1
1
( )
( )
x J x dx
x
J x dx
=
∫
∫
i
 
 
4
2
0
0
( )
4
( )
x J
x
x
xJ
x dx
= −
+ ∫
i
 
 
(
)
4
3
2
0
1
1
( )
4
( )
2
( )
x J
x
x J x
x
J x dx
= −
+
−∫
i
 
 
(
)
4
3
2
0
1
0
0
( )
4
( )
8
( )
2
( )
x J
x
x J x
x J
x
xJ
x dx
= −
+
−
−
+ ∫
 
 
4
2
3
0
1
(
8
)
( )
(4
16 )
( )
x
x
J
x
x
x J x
C
=
−
+
+
−
+
 
 
18. 
With  p = 1,  Eq. (23) in the text gives  
1
1
2
1
( )
( )
.
x J
x dx
x J x
C
−
−
= −
+
∫
  Hence 
 
 
(
)
1
2
2
1
1
1
1
1
1
1
( )
( )
( )
( )
( )
( )
.
J
x dx
x x J
x dx
x
x J x
x J x
J x
x J x dx
−
−
−
−
=
=
−
+
= −
+
∫
∫
∫
∫
i
 
 
But Eq. (26) with  p = 1  gives  
[
]
1
1
1
0
2
2
( )
( )
( ) ,
x J x
J
x
J
x
−
=
+
 so 
 
 
1
1
2
1
0
2
2
2
( )
( )
( )
( )
.
J
x dx
J x
J
x dx
J
x dx
= −
+
+
∫
∫
∫
 
 
Finally, we can solve this last equation for 
 
 
2
1
0
( )
2
( )
( )
.
J
x dx
J x
J
x dx
C
= −
+
+
∫
∫
 
 
Problems 19–30 are routine applications of the theorem in this section.  In each case it is 
necessary only to identify the coefficients  A, B, C  and the exponent  q  in the differential 
equation 
 
 
 
 
 
2
(
)
0.
q
x y
Axy
B
Cx
y
′′
′
+
+
+
=
 
 
 
 
(1) 
Then we can calculate the values 
 
 
 
2
(1
)
4
1
2
,
,
,
2
2
A
B
A
q
C
k
p
q
q
α
β
−
−
−
=
=
=
=
 
 
(2) 

584 
Chapter 11 
and finally write the general solution    
 
 
 
 
1
2
( )
(
)
(
)
p
p
y x
x
c J
kx
c J
kx
α
β
β
−


=
+

  
 
 
(3) 
specified in Theorem 1 on solutions in terms of Bessel functions.  This is a "template procedure" 
that we illustrate only in a couple of problems. 
 
19. 
We have  
1,
1,
1,
2
A
B
C
q
= −
=
=
=
  so 
 
 
2
(1 ( 1))
4(1)
1 ( 1)
2
2 1
1,
1,
1,
0,
2
2
2
2
k
p
α
β
−−
−
−−
=
=
=
=
=
=
=
=
 
 
so our general solution is   y(x)  =  x[c1J0(x) + c2Y0(x)],  using  Y0(x)  because  p = 0  is an  
 
integer. 
 
 
 
20. 
y(x)  =  x−1[c1J1(x) + c2Y1(x)] 
 
21. 
y(x)  =  x[c1J1/2(3x2) + c2J−1/2(3x2)] 
 
 
22. 
y(x)  =  x3[c1J2(2x1/2) + c2Y2(2x1/2)] 
 
23. 
To match the given equation with Eq. (1) above, we first divide through by the leading  
 
coefficient 16 to obtain the equation 
 
 
 
 
2
3
5
5
1
0
3
36
4
x y
xy
x
y


′′
′
+
+ −
+
=




 
 
with  
5/3,
5/36,
1/ 4, and
3.
A
B
C
q
=
= −
=
=
  Then 
 
    
2
(1 5/3)
4( 5/36)
1 5/3
1
3
2 1/ 4
1
1
,
,
,
,
3
3
2
3
3
3
3
k
p
α
β
−
−
−
−
=
= −
=
=
=
=
=
 
 
so our general solution is   y(x)  =  x−1/3[c1J1/3(x3/2/3) + c2J−1/3(x3/2/3)]. 
 
24. 
y(x)  =  x−1/4[c1J0(2x3/2) + c2Y0(2x3/2)] 
 
25. 
y(x)  =  x−1[c1J0(x) + c2Y0(x)]  
 
 
26. 
y(x)  =  x2[c1J1(4x1/2) + c2Y1(4x1/2)] 
 
27. 
y(x)  =  x1/2[c1J1/2(2x3/2) + c2J−1/2(2x3/2)] 
 

 
Section 11.4 
585 
28. 
y(x)  =  x−1/4[c1J3/2(2x5/2/5) + c2J−3/2(2x5/2/5)] 
 
29. 
y(x)  =  x1/2[c1J1/6(x3/3) + c2J−1/6(x3/3)] 
 
30. 
y(x)  =  x1/2[c1J1/5(4x5/2/5) + c2J−1/5(4x5/2/5)]                                                 
 
31. 
We want to solve the equation  xy'' + 2y' + xy  =  0.  If we rewrite it as 
 
 
 
 
 
 
x2y'' + 2xy' + x2y  =  0 
 
 
then we have the form in Equation (1) with  A  =  2,  B  =  0,  C  =  1,  and   
 
q  =  2.  Then Equation (2) gives  α  =  −1/2,  β  =  1,  k  =  1,  and  p  =  1/2,  so by 
Equation (3) the general solution is 
 
 
 
[
]
(
)
1/ 2
1
1/ 2
1
1/ 2
1/ 2
1
2
1
2
( )
( )
( )
2
2
cos
sin
1
cos
sin
y x
x
c J
x
c J
x
x
c
x
c
x
x
x
a
x
a
x
x
π
π
−
−
−
=
+


=
+




=
+
 
 
(with  
2/
i
i
a
c
π
=
),  using Equations (19) in Section 11.4. 
 
33. 
The substitution 
 
 
 
 
2
2
( )
,
u
u
u
y
y
u
u
u
′
′
′′
′
= −
=
−
 
 
immediately transforms  y'  =  x2 + y2  to  u'' + x2u  =  0.  The equivalent equation 
 
 
 
 
 
 
x2u'' + x4u  =  0 
 
 
is of the form in (1) with  A  =  B  =  0,  C  =  1,  and  q  =  4.  Equations (2) give  α  =  
1/2,  β  =  2,  k  =  1/2,  and  p  =  1/4,  so the general solution is 
 
       
 
 
 
u(x)  =  x1/2[c1J1/4(x2/2) + c2J−1/4(x2/2)]. 
To compute  u'(x),  let  z  =  x2/2  so  x  =  21/2z1/2.  Then Equation (22) in Section 11.4  
with  p  =  1/4  yields 
 
 
 
(
)
(
)
1/ 2
2
1/ 4
1/ 4
1/ 4
1/ 4
(
/ 2)
2
( )
d
d
dz
x
J
x
z
J
z
dx
dz
dx
=
⋅
 

586 
Chapter 11 
 
 
 
1/ 4
1/ 4
3/ 4
1/ 2
1/ 4
2
3/ 2
2
3/ 4
3/ 4
1/ 4
2
( )
2
(
/ 2)
(
/ 2).
2
dz
z
J
z
dx
x
J
x
x
x
J
x
−
−
−
=
⋅
=
⋅
⋅
=
 
 
Similarly, Equation (23) in Section 11.4 with  p  =  −1/4  yields 
 
 
(
)
(
)
1/ 2
2
1/ 4
1/ 4
3/ 2
2
1/ 4
1/ 4
3/ 4
(
/ 2)
2
( )
(
/ 2).
d
d
dz
x
J
x
z
J
z
x
J
x
dx
dz
dx
−
−
=
⋅
= −
 
 
Therefore 
 
 
 
 
 u'(x)  =  x3/2[c1J−3/4(x2/2) − c2J3/4(x2/2)]. 
 
 
It follows finally that the general solution of the Riccati equation  y′  =  x2 + y2  is 
 
 
 
 
2
2
1
1
3/ 4
3/ 4
2
2
2
2
1
1
1/ 4
1/ 4
2
2
(
)
(
)
( )
(
)
(
)
J
x
c J
x
u
y x
x
u
c J
x
J
x
−
−
′
−
= −
=
⋅
+
 
 
 
where the arbitrary constant is  c  =  c1/c2. 
 
34. 
Substitution of the series expressions for the Bessel functions in the formula for  y(x)  in  
 
Problem 33 yields 
 
 
 
 
(
)
(
)
(
)
(
)
(
)
(
)
(
)
(
)
3/ 4
3/ 4
2
2
1
1
2
2
1/ 4
1/ 4
2
2
1
1
2
2
1
1
( )
1
1
A
x
c B
x
y x
x
cC
x
D
x
−
−
+
−
+
=
⋅
+
+
+




 
 
where each pair of parentheses encloses a power series in  x  with constant term  1,  and 
 
     
 
 
A  =  2−3/4/Γ(7/4)          
B  =  23/4/Γ(1/4) 
      
 
 
C  =  2−1/4/Γ(5/4)           
D  =  21/4/Γ(3/4). 
 
 
Multiplication of numerator and denominator by  x1/2  and a bit of simplification gives 
 
 
 
 
(
)
(
)
(
)
(
)
3/ 4
3
3/ 4
1/ 4
1/ 4
2
1
2
1
( )
.
2
1
2
1
Ax
c B
y x
cCx
D
−
−
+
−
+
=
+
+
+




 
 
 
 
 
It now follows that 
 
 
 
(
)
1/ 2
3/ 4
3/ 4
1/ 4
1/ 4
2
2
/ (1/ 4)
2
(3/ 4)
(0)
2
.
2
2
/ (3/ 4)
(1/ 4)
cB
y
c
D
−
Γ
−
Γ
=
=
= −
⋅
Γ
Γ
     
 (*) 

 
Section 11.4 
587 
 
 
(a) 
If  y(0)  =  0  then (*) gives  c  =  0  in the general solution formula of Problem 33. 
 
 
(b) 
If  y(0)  =  1  then (*) gives  c  =  −Γ(1/4)/2Γ(3/4).  More generally, (*) yields the 
formula 
 
 
 
( )
( )
( )
( )
2
2
3
1
1
1
3/ 4
0
3/ 4
4
2
4
2
2
2
3
1
1
1
1/ 4
0
1/ 4
4
2
4
2
2
(
)
(
)
( )
2
(
)
(
)
J
x
y
J
x
y x
x
J
x
y
J
x
−
−
Γ
+
Γ
=
⋅Γ
−
Γ
 
 
 
 
for the solution of the initial value problem 
 
 
 
 
 
y′  =  x2 + y2,     
y(0)  =  y0. 
      

588 
Appendix A 
APPENDIX A 
 
EXISTENCE AND UNIQUENESS OF SOLUTIONS 
 
 
In Problems 1–12 we apply the iterative formula 
 
1
( ,
( ))
x
n
n
a
y
b
f t y t
dt
+
=
+∫
 
 
to compute successive approximations  {yn(x)}  to the solution of the initial value problem 
 
                
 
     y′  =  f (x, y), 
 
y(a)  =  b. 
 
starting with  y0(x)  =  b. 
 
1. 
y0(x)  =  3 
 
y1(x)  =  3 + 3x 
 
y2(x)  =  3 + 3x + 3x2/2 
 
y3(x)  =  3 + 3x + 3x2/2 + x3/2 
 
y4(x)  =  3 + 3x + 3x2/2 + x3/2 + x4/8 
 
y(x)   =  3 - 3x + 3x2/2 + x3/2 + x4/8 + ⋅⋅⋅  =  3ex   
 
 
2. 
y0(x)  =  4 
 
y1(x)  =  4 - 8x 
 
y2(x)  =  4 - 8x + 8x2 
 
y3(x)  =  4 - 8x + 8x2 - (16/3)x3 
 
y4(x)  =  4 - 8x + 8x2 - (16/3)x3 + (8/3)x4 
 
y(x)   =  4 - 8x + 8x2 - (16/3)x3 + (8/3)x4 - ⋅⋅⋅  =  4e-2x 
 
 
3. 
y0(x)  =  1 
 
y1(x)  =  1 - x2 
 
y2(x)  =  1 - x2 + x4/2 
 
y3(x)  =  1 - x2 + x4/2 - x6/6 
 
y4(x)  =  1 - x2 + x4/2 - x6/6 + x8/24 

 
Appendix A 
589 
 
 
y(x)   =  1 - x2 + x4/2 - x6/6 + x8/24 - ⋅⋅⋅  =  exp(-x2) 
 
4. 
y0(x)  =  2 
 
y1(x)  =  2 + 2x3 
 
y2(x)  =  2 + 2x3 + x6 
 
y3(x)  =  2 + 2x3 + x6 + (1/3)x9 
 
y4(x)  =  2 + 2x3 + x6 + (1/3)x9 + (1/12)x12 
 
y(x)   =  2 + 2x3 + x6 + (1/3)x9 + (1/12)x12 + ⋅⋅⋅  =  2 exp(x3) 
 
 
5. 
y0(x)  =  0 
 
y1(x)  =  2x 
 
y2(x)  =  2x + 2x2 
 
y3(x)  =  2x + 2x2 + 4x3/3 
 
y4(x)  =  2x + 2x2 + 4x3/3 + 2x4/3 
 
y(x)   =   2x + 2x2 + 4x3/3 + 2x4/3 + ⋅⋅⋅  =   e2x - 1    
 
 
6. 
y0(x)  =  0 
 
y1(x)  =  (1/2)x2 
 
y2(x)  =  (1/2)x2 + (1/6)x3 
 
y3(x)  =  (1/2)x2 + (1/6)x3 + (1/24)x4 
 
y4(x)  =  (1/2)x2 + (1/6)x3 + (1/24)x4 + (1/120)x5  
 
y(x)   =  (1/2!)x2 + (1/3!)x3 + (1/4!)x4 + (1/5!)x5 + ⋅⋅⋅  =  ex - x - 1 
 
 
7. 
y0(x)  =  0 
 
y1(x)  =  x2 
 
y2(x)  =  x2 + x4/2 
 
y3(x)  =  x2 + x4/2 + x6/6 
 
y4(x)  =  x2 + x4/2 + x6/6 + x8 /24 
 
y(x)   =  x2 + x4/2 + x6/6 + x8/24 + ⋅⋅⋅  =  exp(x2) - 1 
 
 
 

590 
Appendix A 
8. 
y0(x)  =  0 
 
y1(x)  =  2x4 
 
y2(x)  =  2x4 + (4/3)x6 
 
y3(x)  =  2x4 + (4/3)x6 + (2/3)x8  
 
y4(x)  =  2x4 + (4/3)x6 + (2/3)x8 + (4/15)x10 
 
y(x)   =  2x4 + (4/3)x6 + (2/3)x8 + (4/15)x10 + ⋅⋅⋅  =  exp(2x2) - 2x2 - 1 
 
 
9. 
y0(x)  =  1 
 
y1(x)  =  (1 + x) + x2/2 
 
y2(x)  =  (1 + x + x2) + x3/6 
 
y3(x)  =  (1 + x + x2 + x3/3) + x4/24 
 
y(x)   =  1 + x + x2 + x3/3 + x4/12 + ⋅⋅⋅  =  2ex - 1 - x 
  
 
10. 
y0(x)  =  0 
 
y1(x)  =  x + (1/2)x2 + (1/6)x3 + (1/24)x4 + ⋅⋅⋅  =  ex - 1  
 
y2(x)  =  x +        x2 + (1/3)x3 + (1/12)x4 + ⋅⋅⋅  =  2ex - x - 2 
 
y3(x)  =  x +         x2 + (1/2)x3 +  (1/8)x4 + ⋅⋅⋅  =  3ex - (1/2)x2 - 2x - 3 
 
y(x)    =  x +         x2 + (1/2)x3 + (1/6)x4 + ⋅⋅⋅  =   xex  
 
 
11. 
y0(x)  =  1 
 
y1(x)  =  1 + x 
 
y2(x)  =  (1 + x + x2) + x3/3 
 
y3(x)  =  (1 + x + x2 + x3) + 2x4/3 + x5/3 + x6/9 + x7/63 
 
y(x)   =  1 + x + x2 + x3 + x4 + ⋅⋅⋅  =  1/(1 - x) 
 
 
12. 
y0(x)  =  1 
 
y1(x)  =  1 + (1/2)x 
 
y2(x)  =  1 + (1/2)x + (3/8)x2 +  (1/8)x3 +  (1/64)x4 
 
y3(x)  =  1 + (1/2)x + (3/8)x2 + (5/16)x3 + (13/64)x4 + ⋅⋅⋅ 
 
y(x)   =  1 + (1/2)x + (3/8)x2 + (5/16)x3 + (35/128)x4 + ⋅⋅⋅  =  (1 - x)-1/2 
 

 
Appendix A 
591 
 
13. 
0
0
( )
1
( )
1
x t
y t




=




−




 
 
 
1
1
( )
1 3
( )
1 5
x t
t
y t
t
+




=




−+




 
 
 
2
1
2
2
2
1
2
2
( )
1 3
( )
1 5
x t
t
t
y t
t
t


+
+


=




−+
−




 
 
 
2
3
1
1
3
2
3
2
3
5
1
3
2
6
( )
1 3
( )
1 5
x t
t
t
t
y t
t
t
t


+
+
+


=




−+
−
+




       
 
 
14. 
0
1
1
1
( )
0
1
1
!
n
n
n
t
t
n
∞
=





=










∑
x
 
 
0
1
0
1
!
(
1)!
1
0
!
n
n
n
n
n
n
t
t
n
n
t
n
∞
∞
=
=
∞
=




−



=









∑
∑
∑
 
 
1
1
0
t
t
t
e
t e
e


=





 
 
(1
)
( )
t
t
t e
t
e


+
=




x
 
 
 
 
 
16. 
y0(x)  =  0 
 
y1(x)  =  (1/3)x3 
 
y2(x)  =  (1/3)x3 + (1/63)x7 
 
y3(x)  =  (1/3)x3 + (1/63)x7 + (2/2079)x11 + (1/59535)x15 
 
 
Then  y3(1)  ≈  0.350185,  which differs by only 0.0134% from the Runge-Kutta 
approximation  y(1)  ≈  0.350232.  As a denouement we may recall from the result of 
Problem 16 in Section 8.6 that the exact solution of our initial value problem here is 
 

592 
Appendix A 
 
 
 
 
 
(
)
(
)
2
1
3/ 4
2
2
1
1/ 4
2
( )
J
x
y x
x
J
x
−
=
⋅
 
 
 
so the exact value at  x  =  1  is  
 
 
             
 
( )
( )
1
3/ 4
2
1
1/ 4
2
( )1
0.35023 18443.
J
y
J−
=
≈
 

