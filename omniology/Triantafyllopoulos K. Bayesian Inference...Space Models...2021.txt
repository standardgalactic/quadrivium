Springer Texts in Statistics
Kostas Triantafyllopoulos
Bayesian 
Inference 
of State Space 
Models
Kalman Filtering and Beyond

Springer Texts in Statistics
Series Editors
G. Allen, Department of Statistics, Rice University, Houston, TX, USA
R. De Veaux, Department of Mathematics and Statistics, Williams College,
Williamstown, MA, USA
R. Nugent, Department of Statistics, Carnegie Mellon University, Pittsburgh, PA,
USA

Springer Texts in Statistics (STS) includes advanced textbooks from 3rd- to 4th-year
undergraduate courses to 1st- to 2nd-year graduate courses. Exercise sets should be
included. The series editors are currently Genevera I. Allen, Richard D. De Veaux,
and Rebecca Nugent. Stephen Fienberg, George Casella, and Ingram Olkin were
editors of the series for many years.
More information about this series at http://www.springer.com/series/417

Kostas Triantafyllopoulos
Bayesian Inference of State
Space Models
Kalman Filtering and Beyond

Kostas Triantafyllopoulos
School of Mathematics
University of Shefﬁeld
Shefﬁeld, UK
ISSN 1431-875X
ISSN 2197-4136
(electronic)
Springer Texts in Statistics
ISBN 978-3-030-76123-3
ISBN 978-3-030-76124-0
(eBook)
https://doi.org/10.1007/978-3-030-76124-0
Mathematics Subject Classiﬁcation: 62F15, 62M10, 62M20, 91B84, 93E03, 93E11, 62P05, 62P20,
62P30
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland
AG 2021
This work is subject to copyright. All rights are solely and exclusively licensed by the Publisher, whether
the whole or part of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse
of illustrations, recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and
transmission or information storage and retrieval, electronic adaptation, computer software, or by similar
or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication
does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant
protective laws and regulations and therefore free for general use.
The publisher, the authors, and the editors are safe to assume that the advice and information in this book
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or
the editors give a warranty, expressed or implied, with respect to the material contained herein or for any
errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional
claims in published maps and institutional afﬁliations.
This Springer imprint is published by the registered company Springer Nature Switzerland AG.
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland

Preface
The discovery and development of state space models and the Kalman ﬁlter have
their roots in the dynamical and control systems research communities. The Kalman
ﬁlter was proposed initially as an alternative to the Wiener-Kolmogorov estimation
theory after Kalman applied state variables to the ﬁltering problem. Soon after its
conception, the Kalman ﬁlter was associated with signiﬁcant real-data application
such as the Apollo project at the Ames Research Centre at NASA. The Kalman
ﬁlter was soon discovered by the statistics and econometrics research communities,
which were able to exploit the ﬂexibility of the state space formulation in the quest to
describe dynamic systems and to use the ﬁlter as a powerful forecasting framework.
Bayesian inference and forecasting were key areas of development in the 1980s
and 1990s. By that time, the state space models and the Kalman ﬁlter were found
to be extremely popular in a wide range of applied science, including statistics,
engineering, economics, environmetrics and biology, to name but a few. Partly due
to the availability of computer advancement, over the last 20 years, there has been
an increasing interest in multivariate linear Gaussian, non-linear and non-Gaussian
modelling and related state space methods. This is facilitated by deploying Bayesian
computation, in particular sequential Monte Carlo and Markov chain Monte Carlo
methods, but also by other estimation procedures such as the unscented Kalman
ﬁlter and related algorithms.
The principle idea of this book is to bring together the above models with their
statistical inference and make them available to a broad audience. Teaching time
series and state space modelling for over 15 years at the University of Shefﬁeld
has motivated me to take up this book project. During these years, I have met and
collaborated with a number of applied scientists sharing a keen interest in state space
models. Some of these models can be generated by a natural phenomenon such
as met in engineering or environmetrics and some can be generated by a socio-
economic structure such as in ﬁnance and its applications. The book is written
from a statistician’s perspective, and it uses a number of data sets to illustrate
the methods from a wide range of disciplines. The ﬁrst six chapters discuss state
space methods and Bayesian inference for general use; the last two chapters of the
book focus on ﬁnance and dynamical systems. On one hand, economics and ﬁnance
v

vi
Preface
have been a steady ﬂow of motivation and development of state space methods,
and on the other hand, dynamical systems is the key subject area where the story
of the Kalman ﬁlter began. Furthermore, the text aims to widespread state space
methods by developing suitable software to enable the reader to apply the algorithms
using the data sets of the book, but also using their own data sets. We have created
the package BTSA (Bayesian Time Series Analysis), available via the contributed
package CRAN website within the environment for statistical computing R (https://
www.r-project.org). The package includes most functions and data sets used in
Chaps. 1–6; moreover, R commands incorporated in the text is believed to help
understanding and implementing the algorithms once the BTSA package is installed.
The book assumes a basic technical background of linear algebra, probability,
and statistics. This is about second year university level and is reviewed in Chap. 2.
The textbook can be used as a one-semester course on linear Gaussian state space
methods by covering Chaps. 1–4, perhaps with some inclusion of multivariate state
space models in Chap. 5. Alternatively, the book can cover the basic theory of linear
models in Chap. 3 and then move on to non-linear and non-Gaussian models in
Chap. 6, perhaps by including some parts of Chaps. 7 and 8. The textbook is aimed
at students at the higher end of undergraduate or graduate level and it is also aimed
at scientists and doctoral students for self-study.
Shefﬁeld, UK
Kostas Triantafyllopoulos
June 2021

Acknowledgements
This book would not be possible without the encouragement and input of Nick
Bingham. I am indebted to him for our discussions in numerous occasions in
Shefﬁeld and in London. I am grateful to several colleagues and friends as well
as graduate students for their feedback and support. In particular, I thank Dave
Applebaum, Peter Young, Guy Nason, Clive Anderson, Andrew Harvey, Alan
Zinober, Osman Tokhi, Giovanni Montana, Tata Subba Rao, Maurice Priestley,
Attilio Meucci, John Fry, Jeremy Oakley, and Daniel Molinari. Special thanks
are due to Jeff Harrison who introduced me to state space models and taught me
Bayesian forecasting.
I am grateful to the Springer team and in particular to Joerg Sixt and Remi Lodh
who offered me great support during the long period of this project. They have been
very patient and have well accommodated my pace of work.
Finally, I would like to thank my family who has been very supportive and has
encouraged me to complete the project.
vii

Contents
1
State Space Models ..........................................................
1
1.1
Introduction ............................................................
1
1.1.1
Time Series ....................................................
1
1.1.2
Examples of Time Series Data................................
2
1.2
Water Tank Dynamics and the State Space Model ...................
3
1.3
Examples of State Space Models .....................................
7
1.3.1
Forecasting Air-Pollution Levels .............................
7
1.3.2
Tracking a Ship ................................................
9
1.3.3
Stochastic Volatility ...........................................
11
1.3.4
Hookean Spring Force Dynamics ............................
13
1.4
A Short History of the Kalman Filter .................................
15
1.5
Layout of the Book ....................................................
19
2
Matrix Algebra, Probability and Statistics................................
21
2.1
Vectors, Matrices and Basic Operations ..............................
21
2.2
Vector and Matrix Differentiation.....................................
24
2.2.1
Background and Notation .....................................
24
2.2.2
Differentiation of Linear and Quadratic Forms ..............
26
2.2.3
Differentiation of Determinant and Trace ....................
28
2.2.4
Optimisation, Integration and Limits .........................
31
2.3
Probability and Distribution Theory ..................................
34
2.3.1
Random Vectors and Probability Distributions ..............
34
2.3.2
Common Discrete Distributions ..............................
37
2.3.3
Common Continuous Distributions...........................
41
2.4
Statistics................................................................
48
2.4.1
Principle Set-Up and Objectives ..............................
48
2.4.2
Maximum Likelihood Estimation: The EM Algorithm......
49
2.4.3
Bayesian Inference ............................................
51
2.5
Exercises ...............................................................
55
ix

x
Contents
3
The Kalman Filter ...........................................................
63
3.1
From Regression to the State Space Model ..........................
63
3.1.1
Ordinary Least Squares .......................................
63
3.1.2
Recursive Least Squares ......................................
67
3.1.3
The State Space Model........................................
71
3.2
Filtering ................................................................
73
3.2.1
A First Derivation of the Kalman Filter ......................
73
3.2.2
A Second Derivation of the Kalman Filter ...................
79
3.3
Smoothing..............................................................
83
3.3.1
Fixed-Interval Smoothing .....................................
83
3.3.2
The Lag-One Covariance Smoother ..........................
88
3.4
Forecasting .............................................................
92
3.5
Steady State of the Kalman Filter.....................................
96
3.5.1
Observability ..................................................
96
3.5.2
Steady State of the Local Level Model .......................
98
3.5.3
Steady State of Linear State Space Models .................. 100
3.6
Exercises ............................................................... 104
4
Model Speciﬁcation and Model Performance............................. 111
4.1
Speciﬁcation of Model Components.................................. 112
4.1.1
Trend State Space Models .................................... 112
4.1.2
Superposition of State Space Models......................... 120
4.1.3
Fourier Form Seasonal Models ............................... 124
4.1.4
Trend-Seasonal Models ....................................... 131
4.1.5
Time-Varying Regression ..................................... 135
4.1.6
Time-Varying Autoregressions ............................... 139
4.2
Decomposition of State Space Models ............................... 141
4.2.1
Historical Note and Motivation ............................... 141
4.2.2
Rational Canonical Form ..................................... 142
4.2.3
Decomposition of Linear State Space Models ............... 147
4.2.4
Turkey Data Revisited......................................... 151
4.3
Estimation of Hyperparameters ....................................... 156
4.3.1
Maximum Likelihood Estimation ............................ 156
4.3.2
Speciﬁcation of Zt Using Discount Factors.................. 165
4.3.3
Estimation of σ 2: Conjugate Bayesian Estimation .......... 167
4.4
Error Analysis.......................................................... 174
4.5
Prior Speciﬁcation ..................................................... 180
4.5.1
Prior Speciﬁcation of β0 ...................................... 181
4.5.2
Prior Speciﬁcation of σ 2 ...................................... 184
4.6
Automatic Sequential Monitoring .................................... 186
4.6.1
Model Monitoring ............................................. 186
4.6.2
Speciﬁcation of Alternative Models .......................... 190
4.6.3
Monitoring for the Tobacco total sales data—CP6 .......... 193
4.7
Exercises ............................................................... 197

Contents
xi
5
Multivariate State Space Models ........................................... 209
5.1
The Kalman Filter ..................................................... 209
5.2
Model Speciﬁcation and Design ...................................... 213
5.3
Steady State of the Multivariate Local Level Model ................. 216
5.4
Error Analysis.......................................................... 221
5.5
Covariance Estimation in State Space Models ....................... 223
5.5.1
Variance Estimation ........................................... 223
5.5.2
Covariance Structure and Matrix-Variate
Probability Distributions ...................................... 227
5.5.3
The Multivariate Scaled Observational Model............... 229
5.6
Forecasting Pollution Time Series .................................... 234
5.7
Markov Chain Monte Carlo Inference ................................ 240
5.7.1
Bayesian Inference and the Gibbs Sampler .................. 240
5.7.2
The Forward Filtering Backward Sampling Scheme ........ 244
5.7.3
Unknown Variances-Covariances............................. 247
5.8
Exercises ............................................................... 254
6
Non-Linear and Non-Gaussian State Space Models ..................... 263
6.1
General Model Formulation........................................... 264
6.2
Dynamic Generalised Linear Models................................. 265
6.2.1
Model Deﬁnition .............................................. 265
6.2.2
Count Time Series ............................................. 268
6.2.3
Categorical Time Series ....................................... 270
6.2.4
Continuous Proportions ....................................... 271
6.2.5
Decomposition of Dynamic Generalised Linear Models .... 273
6.3
Other Non-Gaussian and Non-linear Models......................... 274
6.4
Inference for the General State Space Model ........................ 276
6.5
Power Local Level Models ............................................ 277
6.5.1
Motivation and Main Model Structure ....................... 277
6.5.2
Poisson-Gamma and Exponential-Gamma Models.......... 279
6.6
Approximate Inference ................................................ 282
6.6.1
Motivation and Methodology ................................. 282
6.6.2
Tracking a Ship ................................................ 284
6.6.3
The Extended Kalman Filter .................................. 285
6.6.4
The Unscented Kalman Filter................................. 287
6.7
Sequential Monte Carlo Inference .................................... 290
6.7.1
Monte Carlo Integration....................................... 290
6.7.2
Importance Sampling.......................................... 291
6.7.3
Sequential Importance Sampling ............................. 293
6.7.4
Choice of the Importance Function........................... 297
6.7.5
Example 1: Multinomial Time Series ........................ 300
6.7.6
Example 2: Bearings-Only Tracking Revisited .............. 302
6.7.7
Example 3: Non-Linear Time Series ......................... 304

xii
Contents
6.7.8
Static Parameter Estimation................................... 306
6.7.8.1
Introduction and Initial Studies..................... 306
6.7.8.2
Liu and West Particle Filter......................... 306
6.7.9
Case Study: Analysis of Asthma Data........................ 312
6.8
Markov Chain Monte Carlo Inference ................................ 316
6.8.1
Metropolis-Hastings Algorithm .............................. 317
6.8.2
MCMC for Dynamic Generalised Linear Models ........... 320
6.9
Dynamic Survival Models............................................. 325
6.9.1
Proportional Hazards Model .................................. 325
6.9.2
Dynamic Survival Model ..................................... 326
6.10
Exercises ............................................................... 329
7
The State Space Model in Finance ......................................... 341
7.1
Regression with Autocorrelated Errors ............................... 342
7.2
Stationarity and Autoregressive Models .............................. 345
7.2.1
Stationarity and Causality..................................... 345
7.2.2
Stationarity Conditions for AR(2) ............................ 349
7.2.3
Stationarity Conditions for AR(3) ............................ 350
7.3
Univariate Stochastic Volatility Models .............................. 354
7.3.1
Returns and Volatility ......................................... 354
7.3.2
Stochastic Volatility Model ................................... 355
7.3.3
MCMC Inference of Stochastic Volatility Models........... 357
7.3.4
Particle Filter Inference of Stochastic Volatility Models .... 361
7.3.5
Particle Filter Inference of Stochastic Volatility
Models with Asymmetric Returns ............................ 363
7.4
Multivariate Stochastic Volatility Models ............................ 369
7.4.1
Motivation and General Overview............................ 369
7.4.2
Wishart Autoregressive Stochastic Volatility Models ....... 372
7.4.3
Portfolio Optimisation and Asset Allocation ................ 379
7.4.3.1
Problem Statement .................................. 379
7.4.3.2
Unconstrained Portfolio Selection ................. 382
7.4.3.3
Constrained Portfolio Selection .................... 383
7.5
Pairs Trading ........................................................... 388
7.5.1
Introduction and Basic Concept .............................. 388
7.5.2
State Space Models for Mean-Reverted Spreads ............ 388
7.5.3
Time-Varying Autoregressive Models
for Trading-Spreads ........................................... 390
7.6
Exercises ............................................................... 396
8
Dynamic Systems and Control ............................................. 403
8.1
Dynamic Systems...................................................... 404
8.1.1
Basic Principles................................................ 404
8.1.2
Linear Systems ................................................ 405
8.1.3
Laplace Transform ............................................ 407
8.2
State Space Representation of Dynamic Systems .................... 411
8.2.1
State Variables and State of a System ........................ 411

Contents
xiii
8.2.2
Continuous-Time State Space Model......................... 412
8.2.3
Solution of the State Differential Equation .................. 416
8.2.4
Discrete-Time State Space Model ............................ 417
8.3
System Stability ....................................................... 420
8.3.1
Deﬁnitions ..................................................... 420
8.3.2
Stability of Linear Systems ................................... 422
8.3.3
Stability of Non-Linear Systems.............................. 428
8.3.3.1
Lyapunov Indirect Method ......................... 428
8.3.3.2
Lyapunov Direct Method ........................... 431
8.4
Continuous-Time Kalman Filter ...................................... 435
8.4.1
Discrete-Time Kalman Filter ................................. 436
8.4.2
Kalman–Bucy Filter ........................................... 437
8.4.3
Observability and Convergence............................... 447
8.4.4
Extended Kalman–Bucy Filter................................ 453
8.5
Feedback Control ...................................................... 455
8.5.1
The PID-Controller............................................ 456
8.5.2
Twin Rotor Static Rig for Air-Vehicle Testing ............... 460
8.6
Exercises ............................................................... 465
References......................................................................... 477
Index ............................................................................... 491

Acronyms
AR
Autoregressive (model, parameters)
ARIMA
Autoregressive integrated moving average (model)
c.d.f.
Cumulative distribution function
DGLM
Dynamic generalised linear model
EKF
Extended Kalman ﬁlter
EM
Expectation maximisation (algorithm)
FFBS
Forward ﬁltering backward sampling (algorithm)
i.i.d.
Independent and identically distributed (random variables)
GARCH
Generalised autoregressive conditional heteroskedastic models
GLM
Generalised linear model
MCMC
Markov chain Monte Carlo
MAD
Mean absolute deviation
MGARCH
Multivariate generalised autoregressive conditional heteroskedastic
models
MIMO
Multiple input multiple output (dynamic system)
MSE
Mean squared error
MSSE
Mean squared standardised error
MSOP
Multivariate scaled observation precision model
OLS
Ordinary least squares
p.d.f.
Probability density function
PID
Proportional integral derivative (controller)
PF-I
Particle ﬁlter algorithm I (standard particle ﬁlter)
PF-II
Particle ﬁlter algorithm II (Liu and West particle ﬁlter)
p.m.f.
Probability mass function
RLS
Recursive least squares
SISO
Single input single output (dynamic system)
SOP
Scaled observational precision model
TRMS
Twin rotor multi-input multi-output system
UKF
Unscented Kalman ﬁlter
WAR
Whishart autoregressive process
WN
White noise (process)
xv

Chapter 1
State Space Models
This chapter introduces time series, the state space model (although a more formal
treatment is given in Chap. 3) and Kalman ﬁltering. We start by deﬁning and giving
some examples of time series data. Section 1.2 discusses a data driven problem from
hydro-dynamics, which motivates our ﬁrst encounter with the state space model.
To appreciate the wealth of applications that the state space model holds, Sect. 1.3
provides several examples from environmetrics, navigation, economics and physics.
Section 1.4 gives a historical account of the Kalman ﬁlter and the chapter concludes
by giving a brief content description.
1.1
Introduction
1.1.1
Time Series
In many subject areas, such as engineering, economics, biology, environmetrics,
data collected are frequently collected over time. Such data, known as time series,
may arise as the result of the data collection process (we may collect data in a
daily, or hourly frequency) and interest is focused in understanding the dynamics
of such data as well as forecasting future time series values. Examples of time
series include: daily prices of ﬁnancial assets, monthly marriage ﬁgures, quarterly
product sales, daily temperatures in a particular city, annual precipitation levels of a
lake and so forth. In all these examples, the time in which the data are collected is
important, as it introduces a particular correlation or dependence structure between
measurements or observations. In order to understand such data, it is necessary
to consider statistical models that take into account time in the aforementioned
dependence structure. The study of such models is known as time series analysis
and has been discussed in many textbooks, see e.g. Brockwell and Davis (1991),
Shumway and Stoffer (2017) and Lindsey (2004).
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2021
K. Triantafyllopoulos, Bayesian Inference of State Space Models, Springer Texts
in Statistics, https://doi.org/10.1007/978-3-030-76124-0_1
1

2
1
State Space Models
To establish notation, we refer to time as t and to the time series observation at t
as yt or as y(t) (see below). In most situations t will belong to a discrete set (such as
the natural numbers t = 1, 2, 3 . . .) and in this respect the collection of observations
yt, for all t = 1, 2, . . ., denoted by {yt, t = 1, 2, . . .} or simply {yt} deﬁnes a
discrete-time time series. For example, t may represent days, months or years (as
in examples above). In some cases t belongs to a continuous set (e.g. the closed
interval [0, 1]); then the time series at t is denoted by y(t) (to make explicit that t is
continuous) and so we may write {y(t), t ∈[0, 1]} or {y(t)} for a continuous-time
time series. In this book we will primarily study discrete-time time series, unless
otherwise stated. The objectives of time series analysis are
1. to build statistical models (known as time series models) that describe and
understand the dynamics of observed time series data,
2. based on an observed collection of data, to forecast future values of the time
series.
Both (1) and (2) adopt a time series model, but while (1) aims at ﬁnding a model
that describes a collection of data, (2) adopts the model in order to forecast future
data.
A general class of time series models and one that this book is focused on, known
as state space models, suggests that at each time t the observations yt are related
to the states at time t, which in turn are related to the states at t −1. Thus, the
observation is a function of the states, and the way in which the states move in their
space, hence the name state space (time series) models.
1.1.2
Examples of Time Series Data
Time series data typically comprise trend, seasonal components and their combina-
tion. This section describes three examples of time series data, which are revisited
later in Chap. 4.
•
Trend (Aluminium prices). Figure 1.1 depicts spot prices of aluminium over
the time period 4 January 2005 to 31 October 2005. Aluminium, which is a
non-ferrous metal, trades daily at the London metal exchange, for information of
which the reader is referred to http://www.lme.com/. The data of Fig. 1.1, which
exclude bank holidays and weekends, show initially some random ﬂuctuation,
followed by an upward linear trend (March–April), followed by a linear fall
(May–June), followed by some random ﬂuctuation (June–July), followed by
some increasing and then decreasing trend (August–September), and ﬁnally
followed by a linear trend (October).
•
Seasonal (Quarter temperatures at Shefﬁeld).
Figure 1.2 shows averaged temperatures collected for each quarter at Weston
Park, Shefﬁeld, UK, for unspeciﬁed years. This data set shows clear evidence of
seasonality (or cyclic variation), as the values of the 1st Quarter of each year are

1.2
Water Tank Dynamics and the State Space Model
3
Aluminium price (per tonne)
Trading day
US dollars per tonne
1700
2
4
6
8
10
1750
1800
1850
1900
1950
2000
Fig. 1.1 Aluminium prices (US$ per tonne). The integers in the time axis indicate months in 2005
similar (lower values in the ﬁgure) and of course they are such due to the effect
of the winter months in the ﬁrst quarter. Likewise, the third quarter of each year
is responsible for the higher temperature values, being inﬂuenced by the summer
months.
1.2
Water Tank Dynamics and the State Space Model
In this section we describe a mechanism that generates a linear state space model.
We consider a simple experiment used to measure the level of water in a tank.
Figure 1.3 shows a water tank, which allows a constant ﬂow of water entering the
tank from the left side with constant ﬂow rate 6 litres per min and leaving the tank on
the bottom right side at ﬂow rate 5 litres per min. The objective of the experiment
is to measure the level L of the water in the course of time. The ﬁrst observation
we make is that the level is not constant as the water coming to the tank creates
disturbance affecting the level of the water. Secondly, the water leaving the tank has
lower ﬂow rate than the ﬂow rate entering the tank. Assuming water mass per litre is

4
1
State Space Models
Quarterly averaged temperatures in Sheffield
Quarter
Degrees in Celsius
5
0
10
20
30
40
50
60
10
15
Fig. 1.2 Quarterly mean temperature in Shefﬁeld
Lt
5 L/min
6 L/min
0.1 kg/L
Lt
Fig. 1.3 Water tank dynamics
constant, this means that in the long run we expect the level to increase by 1 litre per
min. If there was no disturbance due to water entering the tank, the volume in the
tank at time t is ℓLt = ℓL0+t, where ℓis the length of the base of the tank and L0 is
the initial level of the water (assumed to be higher than the higher point of the right
leave point of the tank). The above equation can be written as ℓLt = ℓLt−1 + 1,
starting from ℓL1 = ℓL0 + 1. With the disturbance generated by the water falling
into the tank we postulate that ℓLt ≈ℓLt−1 +1. This in words says that the volume

1.2
Water Tank Dynamics and the State Space Model
5
of the tank at time t (in min) is close to the volume of the tank at time t −1 plus
1 litre. This can be modelled by introducing a sequence of random variables ζt, so
that
Lt = Lt−1 + 1
ℓ+ ζt,
(1.1)
where ζt is a i.i.d. sequential of random variables with zero mean and some variance
Z. For this model we have E(Lt) = E(Lt−1) + 1/ℓand Var(Lt) ≥Var(Lt−1).
Consider now that an observer is measuring the level Lt. This may be achieved
automatically by placing a ﬂoat in the tank. This will create an extra source of
uncertainty on the level of the water. A possible model for the observed level yt
suggests that yt is expected to be equal to the actual (unobserved) level Lt inﬂated
by noise ϵt, caused by the ﬂoat. Hence the measurement equation is
yt = Lt + ϵt,
(1.2)
where ϵt is an i.i.d. sequence of random variables with zero mean and variance σ 2.
Initially a value for L0 (the level as time t = 0 should be set); alternatively it
is possible to consider that L0 is a random variable, if we wish to specify an initial
distribution for it (this speciﬁcation will be a useful consideration, if the engineer
is not certain about the initial value L0). Measurement model (1.2) together the
evolution model (1.1) and the initial speciﬁcation of L0 deﬁne a state space model.
The unobserved signal Lt is the state at time t and the observation yt is a linear
function of Lt. Again collecting water ﬂoat measurement data y1, . . . , yn we can
estimate the unknown water tank ﬂoat at each time Lt.
Before we proceed with the deﬁnition of the general state space model, we
need to establish some notation. Suppose that x represents a p-dimensional column
vector, i.e.
x =
⎡
⎢⎢⎢⎣
x1
x2
...
xp
⎤
⎥⎥⎥⎦,
where xi is the ith element of the vector, i = 1, 2, . . ., p. With ⊤denoting
transposition, we write x⊤= [x1, x2, . . . , xp] for a row vector; note that with
this notation x can be compactly written as x = [x1, x2, . . . , xp]⊤. A p × p
matrix X is a tabular display, which places p column vectors [x11, x21, . . . , xp1]⊤,
[x12, x22, . . . , xp2]⊤, . . ., [x1p, x2p, . . . , xpp]⊤one after the other, i.e. assigning the
element xij at position (i, j). As is evident from the above, we use boldface to
distinguish a matrix from a scalar or a vector. In a probabilistic setting, we deal with
random variables (for univariate variables) and random vectors (for multivariate
variables), more information on which can be found in Chap. 2. For a p-dimensional

6
1
State Space Models
column vector y, the notation y ∼N(μ, V) implies that y follows the multivariate
Gaussian distribution with mean vector μ and with covariance matrix V. More
details about matrix algebra and statistics relevant to the contents of this book are
provided in Chap. 2.
In general, if the p-dimensional state column vector at time t is denoted by βt,
then a linear state space model may be described by equations
yt = x⊤
t βt + ϵt
and
βt = Ftβt−1 + ζt,
(1.3)
where xt is a p-dimensional column design vector, Ft is a p×p transition matrix and
the error sequences ϵt and ζt may be assumed to be independent, with zero mean; in
many applications xt = x and Ft = F are time-invariant, but the general case allows
for more ﬂexibility. It is assumed that the sequences {ϵt} and {ζt} are independent
(i.e. ϵt is independent of ϵs and ζt is independent of ζs, for any t ̸= s) and that
ϵt and ζt are independent of β0, for any t. The model is completely determined if
distributions for the innovations ϵt and ζt as well as distribution of the initial state
β0 are speciﬁed.
If Gaussian distributions are assumed for ϵt, ζt and for β0, model (1.3) is known
as Gaussian linear state space model, and it can be described by
yt | βt ∼N(x⊤
t βt, σ 2)
and
βt | βt−1 ∼N(Ftβt−1, Z),
(1.4)
where yt | βt denotes the conditional distribution of yt given βt (a formal deﬁnition
is given in Chap. 2), σ 2 is the variance of ϵt and Z is the covariance matrix of ζt.
Expression (1.4) allows us to extend the Gaussian linear state space model (1.4)
to non-linear and non-Gaussian state space models. Indeed, we will say that the
time series {yt} is generated by a general (including linear Gaussian and non-
linear and non-Gaussian) state space model, if yt can be described by the following
distributions
p(yt | βt),
p(βt | βt−1)
and
p(β0).
(1.5)
This, very general, model setting assumes a distribution of yt, given some states,
a distribution of βt, given the previous state βt−1 and an initial state distribution
p(β0). It is implicitly assumed that given βt, yt is conditionally independent of
past observations and states yt−1, yt−2, . . . and of βt−1, βt−2, . . ., but also of future
observations and states yt+1, yt+2, . . . and βt+1, βt+2, . . .; in other words, the
present state βt holds all information from past and future data and states relevant
to the understanding and knowledge of yt. Likewise, given βt−1, βt is conditionally
independent of βt−2, βt−3, . . .. Simply put, we say that given the present (state at
time t), the past and the future are conditionally independent. More information
about this independence structure can be found in West and Harrison (1997). It is
worth noting that the above description ﬁts the purposes of state space models for
discrete and roughly equally spaced observed data. An example of a continuous-
time state space model is given in Sect. 1.3.4 and further discussed in the context

1.3
Examples of State Space Models
7
of dynamical systems in Sect. 8.4. In the sequel we give some illustrative examples
showing the application of state space models to real-life situations.
1.3
Examples of State Space Models
This section describes some situations motivated by real-life problems, which can
be modelled with a state space model. It illustrates some of the many subject areas
that state space models ﬁnd application.
1.3.1
Forecasting Air-Pollution Levels
Air pollution consists of the introduction of chemicals, particulate matter and
biological materials into the atmosphere, causing severe damage to the environment.
Many of the main air pollutants are contributing to the greenhouse effect, which is
considered to be the main human made factor that affects climate change.
Nitric oxide (NO), one of the most prominent air pollutants, is emitted from
high temperature combustion, and also produced naturally during thunderstorms by
electrical discharge. Figure 1.4 shows NO levels (in mg/m3) together with levels
of % humidity, mean daily temperature (in ◦C), and wind speed (in m/s); the
measurements of these variables are collected daily covering January to December
2001 and they are provided by one of the sensors sites of the air-pollution networks
of Athens.
One of the objectives is to be able to use the covariates (here denoted by x1t—
humidity, x2t—temperature and x3t—wind speed) in order to forecast future values
of the NO levels (denoted by yt). Such information may be vital in issuing warning
messages to the community, should the pollution levels be expected to rise, e.g.
by preventing old people, and in particular those with respiratory related health
problems, access particular areas of the city. Another objective may be to establish
pollution trends and dynamics, so as to assess whether anti-pollution measures work
and assist policy makers.
A ﬁrst model is a simple regression model of x1t, x2t, x3t on the response variable
yt, given by
yt = β0 + β1x1t + β2x2t + β3x3t + ϵt,
(1.6)
where ϵt is an independent sequence, following a Gaussian distribution with zero
mean and some variance σ 2, i.e. ϵt ∼N(0, σ 2). The coefﬁcient β0 is the intercept
and β1, β2, β3 are the coefﬁcients of the covariates x1t, x2t, x3t. We can ﬁt this
model by using standard regression methods, see e.g. Bingham and Fry (2010).

8
1
State Space Models
NO (response)
Humidity
Temperature
2
2001.0
2001.2
2001.4
2001.6
2001.8
2002.0
4
6
8
10
10
20
30
40 50 60 70 80 90
5
10
15
20
5
Wind speed
Day
Pollution data with covariates
Fig. 1.4 Air-pollution levels of NO2 and three covariates (humidity, temperature and wind speed)
If we deﬁne the state vector
βt =
⎡
⎢⎢⎣
β0
β1
β2
β3
⎤
⎥⎥⎦,
then model (1.6) can be put in state space form by writing
yt = [1, x1t, x2t, x3t]
⎡
⎢⎢⎣
β0
β1
β2
β3
⎤
⎥⎥⎦+ ϵt = x⊤
t βt + ϵt,
(1.7)
and
βt = βt−1,
(1.8)
for all t, with probability 1, i.e. βt = βt−1 = · · · = β1 = β.

1.3
Examples of State Space Models
9
It can be argued that model (1.6) is insufﬁcient, because although the response
variable and covariate are time-varying, the βi coefﬁcients are time-invariant (for
i = 0, 1, 2, 3). Sometimes such a model is referred to as static regression model,
because its coefﬁcients do not depend on time. However, as it is evidenced by
Fig. 1.4, the humidity and temperature covariates (x1t and x2t) are changing over
time and thus the coefﬁcients βi should be time-varying.
A simple regression model with time-varying coefﬁcients, known also as
dynamic regression model, is to adopt (1.7), but to replace (1.8) by
βt = βt−1 + ζt.
(1.9)
where ζt is an independent sequence and ζt follows a four-dimensional Gaussian
distribution with zero mean vector and some covariance matrix. Equation (1.9)
implies that βt ≈βt−1, but the shock ζt allows for some local variation in the
βt coefﬁcients. Equations (1.7) and (1.9) deﬁne a Gaussian linear state space model
(assuming that a Gaussian distribution is set for β0).
1.3.2
Tracking a Ship
We consider the classical bearings-only tracking problem of tracking a ship being
observed from a constant (not moving) observation position. State space models
have been proposed for tracking various objects since the late 70s, see e.g. Aidala
(1979); for a recent discussion of this problem see Fearnhead (2002) and Särkkä
(2013). Figure 1.5 depicts, with solid points, the position of the ship (in x −y
coordinates), at each time t. At each time t, and for each of the points mentioned
above, angular data of the ship’s position is obtained. The objective is, using this
data, to project future positions and thus to track the movement of the ship.
From Fig. 1.5 we have that tan(θt) = yt/xt, where xt is the x coordinate of the
ship at time t, yt is the y coordinate of the ship at time t and θt is the respective
angle. From this we have that θt = arctan(yt/xt) and it can be postulated that the
angular data we observe are inﬂated by noise, thus the observation model is
zt = arctan
yt
xt
	
+ ϵt.
(1.10)
In this model we only can observe θt inﬂated by noise, i.e. we observe zt. Thus θt
and xt, yt are assumed unobserved or hidden processes.
In order to provide a model for zt, we need to set a model for the dynamics or
unobserved coordinates xt and yt. First we postulate that the derivative of xt at t,
denoted by ˙xt, is close to the derivative at t −1, i.e. ˙xt ≈˙xt−1. This is interpreted
as describing a model when the ship will not have abrupt moves in the x coordinate.

10
1
State Space Models
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
0.0
0.5
1.0
1.5
2.0
Bearings−only tracking
x
y
Tt
yt
xt
Fig. 1.5 Bearings-only tracking
Similarly we postulate that ˙yt ≈˙yt−1. Finally, we can see that the x position at time
t can be determined by xt ≈xt−1 + ˙xt−1, which originates from
˙xt−1 ≈˙xt ≈xt
t ,
where xt = xt −xt−1 and t = t −(t −1) = 1. A similar formula applies for the
y-coordinate, that is yt ≈yt−1 + ˙yt−1. It is worth noting that time t is considered
to be discrete (as data is obtained at discrete times) and in this sense the derivatives
(with respect to time) are merely described as ratios xt = xt −xt−1 and yt.
Putting the above together, we can deﬁne a state vector
βt =
⎡
⎢⎢⎣
xt
yt
˙xt
˙yt
⎤
⎥⎥⎦,
which with the above evolutions of xt, yt, ˙xt, ˙yt implies
βt =
⎡
⎢⎢⎣
xt
yt
˙xt
˙yt
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
1 0 1 0
0 1 0 1
0 0 1 0
0 0 0 1
⎤
⎥⎥⎦
⎡
⎢⎢⎣
xt−1
yt−1
˙xt−1
˙yt−1
⎤
⎥⎥⎦+
⎡
⎢⎢⎣
ζ1t
ζ2t
ζ3t
ζ4t
⎤
⎥⎥⎦,

1.3
Examples of State Space Models
11
0.0
0.2
0.4
0.6
0.8
1.0
−0.2
0.0
0.2
0.4
0.6
0.8
1.0
Bearings−only tracking (simulated route)
x
y
Observer
Fig. 1.6 Bearings-only tracking (simulated route)
or
βt = Fβt−1 + ζt.
(1.11)
Finally, from the deﬁnition of βt, the observation model (1.10) can be written as
zt = arctan
[0, 1, 0, 0]βt
[1, 0, 0, 0]βt
	
+ ϵt.
(1.12)
Model (1.12)–(1.11) is a non-linear state space model. The evolution model (1.11)
is linear, but the observation model (1.12) is non-linear. If Gaussian distributions are
placed on the innovations ϵt, ζt and on the initial state β0, then the above model is a
conditionally Gaussian non-linear state space model. Following a similar approach
as in Berzuini and Gilks (2001), Fig. 1.6 shows a simulated smooth trajectory of the
ship in the x −y plane.
1.3.3
Stochastic Volatility
The subject of dynamic change of ﬁnancial asset prices has been a core interest
of ﬁnance over a very long time. Such assets can be share prices and other stocks

12
1
State Space Models
trading in global stock markets, or indices such as the Standard and Poor 500 index
or international exchange rates, such as the exchange rate of the British pound
with the US dollar and so forth. Unfortunately, forecasting asset prices is nearly
impossible because prices are exposed to excessive variability, which severely
affects forecast performance.
Suppose that pt denotes the price at time t of an asset (or the value of an index
or exchange rate) and deﬁne the logarithmic returns, known also as log-returns, as
yt = log pt −log pt−1. We note that if pt is similar to pt−1, then yt ≈0, and yt will
be high when pt is large compared to pt−1 or yt will be low when pt will be low
compared to pt−1. The conditional variance of the returns yt, known as volatility,
is a measure of the variability of the share prices and hence a measure of the risk
associated in forecasting the returns. For example, the 2008 credit crisis resulted
in high volatility in most assets, which in turn reﬂected the increased uncertainty
associated with investment decisions. It is now well known that volatility estimation
plays a crucial role in constructing portfolios of assets in risk management.
Figure 1.7 shows log-returns of 1776 trading days of IBM share prices. We
observe that the returns ﬂuctuate around zero, but at the start of the time series the
returns are particularly volatile. This simple picture illustrates that returns should
ﬂuctuate around zero and that their variance or volatility is time-varying. Thus, a
plausible model is to assume that
yt = exp(ht/2)ϵt,
(1.13)
where ϵt is independent of ϵs (t ̸= s), ϵt ∼N(0, 1) and ht is some unobserved
component, which follows an autoregressive process
ht −μ = φ(ht−1 −μ) + ωt,
ωt ∼N(0, σ 2
ω),
(1.14)
where μ is the mean of ht, φ is an autoregressive coefﬁcient and some variance
σ 2
ω. An initial Gaussian distribution is set for h0. The unobserved process ht is the
logarithm of the volatility Var(yt | ht) = exp(ht).
Model (1.13)–(1.14) basically postulates that given ht, yt follows a Gaussian
distribution with zero mean and variance, which is the volatility exp(ht), where ht
follows an autoregressive process with mean μ. This model is known as a stochastic
volatility model, as it provides a framework for the estimation of the volatility
exp(ht), via the stochastic process ht; for more details on stochastic volatility the
reader is referred to Tsay (2002, §10.7).
We can put the above model in state space form as follows. Deﬁne the bivariate
state vector βt = [ht, 1]⊤to be state at time t. Now Eq. (1.13) can be written as
yt | βt ∼N[0, exp([1, 0]βt)],
(1.15)

1.3
Examples of State Space Models
13
Returns of IBM share prices
Trading day
Return
0
500
1000
1500
-30
-20
-10
0
10
20
30
Fig. 1.7 Returns of IBM share prices
and Eq. (1.14) can be written as
βt =

 ht
1

=

 φ μ(1 −φ)
0
1
 
 ht−1
1

+

 ωt
0

= Fβt−1 + ζt
(1.16)
Equations (1.15)–(1.16) deﬁne a Gaussian non-linear state space model, where the
observation model (1.15) is non-linear in βt, while the transition model (1.16) is
linear.
1.3.4
Hookean Spring Force Dynamics
Consider a simple mechanical system describing the motion of an object in one-
dimension (translational mode). Suppose that the object has mass m and it moves

14
1
State Space Models
Fig. 1.8 Spring single-mass
system, including a spring
and damping
m
u
horizontally on a plane and attached to a wall on a spring, sometimes referred to
as Hookean spring (see Fig. 1.8). If y(t) is the position of the object at time t (here
t is continuous), then according to Newton’s laws of motion y(t) is driven by the
differential equation
m d2y(t)
dt2
+ k1
dy(t)
dt
+ k2y(t) = u(t),
(1.17)
where dy(t)/dt = ˙y(t) is the velocity of the object at t (the ﬁrst derivative of the
position y(t)), d2y(t)/dt2 is the acceleration (the second derivative of y(t)), u(t) is
an applied force at t the constants k1 is the damping or viscous friction constant and
k2 is the spring constant. The linear restoring force is −k2y(t) and the friction force
is −k1 ˙y(t). This model and its derivation are discussed in Anand (1984, pp. 18–19)
and illustrated in Fig. 1.8.
We can represent the above differential equation in state space form by deﬁning
the state vector
x(t) =

 y(t)
˙y(t)

and writing down the position y(t) as
y(t) = [1, 0]

y(t)
˙y(t)

= Hx(t),
(1.18)
with transition equation driven by (1.17)
˙x(t) =

 0
1
−k2
m −k1
m

x(t) +

 0
1
m

u(t).
(1.19)
It is easy to observe that (1.18) and (1.19) give the differential equation (1.17).

1.4
A Short History of the Kalman Filter
15
Now suppose that an experiment is conducted whereby measurements of the
position y(t), for some points of time t are collected. In this case it is expected
that y(t) will be inﬂated by noise, due to
1. measurement error;
2. the differential equation (1.17) not perfectly describing the system.
As a result it is natural to keep the transition (1.19) and to adopt an observation
equation
y(t) = Hx(t) + ϵ(t),
(1.20)
where ϵ(t) is an error term measuring discrepancies between the observed y(t)
and the theoretical signal Hx(t) driven by (1.17). The transition (1.19) is basically
a deterministic transition equation, which describes the dynamical system, while
uncertainty is passed onto y(t) via the innovation or error term ϵ(t). Model (1.19)–
(1.20) is a continuous-time state space model, which is considered in more detail in
Sect. 8.4.
Having discussed some detailed numerical examples we now give a historical
account of the development of the Kalman ﬁlter.
1.4
A Short History of the Kalman Filter
Least Squares: Gauss and Plackett
The state space model can be regarded as an extremely useful extension of
regression models. Therefore, it is natural to think that estimation of the state space
model shares some common ground with least squares regression (Bingham & Fry,
2010). Least squares regression was discovered independently by Adrien-Marie
Legendre (Legendre, 1805) and by Carl Friedrich Gauss (Gauss, 1809). Although
Gauss claimed he had discovered the method much earlier than 1809, it seems that
Legendre is credited with the discovery of least squares, while the probabilistic
treatment of the errors (today usually referred to as residuals) is due to Gauss. The
debate of the priority of least squares has been one of the most famous in the history
of mathematics and statistics and it is discussed in detail in Stigler (1986). Even
in Gauss’s ﬁrst published account in 1809 we ﬁnd his original idea of assigning
a probability distribution to the errors; he reﬁned his theory substantially in a
series of papers, which appear collectively under the title “Theoria combinationis
observationum erroribus minimis obnoxiae” in 1821, (Gauss, 1821/23/26). In those
papers he presents a systematic and probabilistic treatment of least squares methods
with application to astronomy and geodesy. It is here that Gauss effectively assigns
the exponential exp(−x2) (normal distribution) to describe the evolution of the
errors x. Gauss goes on to assign a uniform prior to the parameters and to obtain
a normal posterior distribution of the parameters. In doing this he gives the ﬁrst

16
1
State Space Models
account of Bayesian estimation in least squares. As Büuhler (1981, p. 140) observes
“Least squares were Gauss’s indispensable theoretical tool in experimental research;
increasingly, he came to see it as the most important witness to the connection
between mathematics and nature”. Based on this view, Gauss was ahead of his time
and had the capacity of a modern applied mathematician and statistician.
After Gauss several scientists contributed on the development of least squares,
such as Pierre-Simon Laplace (on least squares computation), George Udny Yule
(on relating least squares to correlation), Sir Francis Galton and Karl Pearson (on
regression and correlation); reviews of the developments of least squares can be
found in Stigler (1986) and in Aldrich (1998). Although the least squares discovery
was the ﬁrst mathematical attempt to build an optimal model based on observed
data, regression remained moderately explored in the nineteenth century and in
the beginning of the twentieth century; Robin Lewis Plackett in 1950 rediscovered
least squares and established regression analysis as we know it now (Plackett, 1950,
1991). Plackett, ahead of his time, derived a recursive estimation approach, known
as recursive residuals, which enables the recursive calculation of the least squares
solution. Plackett’s path-breaking work had two important implications: on the
applied side large data sets could be handled with notable ﬂexibility (by performing
a small number of recursive calculations), and on the theoretical side his work set a
framework for the derivation of more complex estimation procedures.
The Filtering Problem: Kolmogorov and Wiener
The modern axiomatic treatment of probability theory is attributed to Russian math-
ematician Andrey Nikolaevich Kolmogorov (1903–1987). Kolmogorov’s research
interests span a wide range of mathematical topics, including probability theory,
topology, intuitionistic logic, turbulence, classical mechanics and computational
complexity. Kolmogorov worked on stochastic processes and in 1941 he gave a
solution to the problem of optimal estimation of a discrete-time stationary stochastic
process (Kolmogorov, 1941).
At the same time independently of Kolmogorov, Norbert Wiener (1894–1964)
was working on the equivalent problem for continuous-time stationary stochastic
processes. In 1942 he completed his work on smoothing stationary time series,
known today as Wiener ﬁlter, but his work was only published post-war in 1949
(Wiener, 1949). In 1942 a classiﬁed report with Wiener’s method appeared with the
nickname “the yellow peril” because of the colour of the cover and the difﬁculty of
the subject. Wiener derived the solution of the least squares errors in a continuous-
time stationary process as a function of the autocorrelation functions of the signal
and the noise. Together with Kolmogorov, Wiener is credited with introducing the
term “ﬁltering” in time series or stochastic processes. Filtering is used for the
operation of removing noise from a process inﬂated by noise. Today, the term “de-
noising” is also used, for such a ﬁltering operation.

1.4
A Short History of the Kalman Filter
17
The Kalman Filter: Kalman
Rudolf Emil Kalman was born in 19 May 1930 in Budapest. Kalman received his
bachelor’s and master’s degrees from MIT in electrical engineering, in 1953 and
1954, respectively. In 1955 Kalman obtained a position at Columbia University as a
graduate student and lecturer. He then developed strong research interests in systems
theory and systems dynamics. He was interested in algebraic methods and he is
credited for ﬁnding the algebraic expression of observability and controllability of
a dynamical system, see e.g. Grewal and Andrews (2015).
Although the state space form of a time-varying system was known since 1956
(Halcombe Laning & Battin, 1956), it was not connected with the ﬁltering problem
mentioned above; see also Zadeh and Desoer (1963). In 1958 Kalman had the idea to
use state variables and the linear state space model for the Wiener ﬁltering problem.
Although the Wiener ﬁlter is applied to continuous-time processes, Kalman ﬁrst
considered discrete-time processes. In order to be able to derive the equivalent to the
Wiener ﬁlter using the state space form in discrete time, Kalman equated expectation
with projection, after he read Loève’s book on probability theory (Loève, 1955).
The use of projections has been a central element in the derivation of the new
ﬁlter, known as the Kalman ﬁlter, which was published in a mechanical engineering
journal in 1960 (Kalman, 1960). Kalman’s new ﬁlter had two important elements:
(a) it used the state state space form (which is regarded today as a very advantageous
consideration as it can describe a large number of physical phenomena) and (b) it
did not require the assumption of stationarity (which is signiﬁcant as most real-life
systems are not stationary). Just as Plackett’s recursive estimation was ahead of his
time, so was Kalman’s method, as it was able to deal with non-stationary processes.
Kalman considers the state space model (1.3) where the states βt represent
some physical entities of the system (usually they represent an ideal theoretic
state of the system—sometimes driven by differential or difference equations—
while the observations yt represent noisy versions of the states, which are subject
to measurement error). Then Kalman provides an optimal ﬁlter, provided that the
design vector xt and the transition matrix Ft as well as the variance of ϵt and the
covariance matrix of ζt are known and speciﬁed by the user. Kalman suggested
that these model components may be known by the system or by past experiments
and he did not study how they may be speciﬁed or estimated from the data. Later
on when the Kalman ﬁlter was applied in economics (see the discussion below),
the states were considered as unobserved or hidden components, not necessarily
assigned to physical entities, which assist on understanding the generating process
of the observations. In this approach the problem of specifying or estimating the
components xt and Ft as well as the variance and covariance components mentioned
above, becomes more crucial as there is weak or no information provided by
the physical/socio-economic system (other than the observed data) to help the
identiﬁcation of these components. This difference between Kalman’s state space
modelling framework and later applications of the Kalman ﬁlter often is not made
clear. In cases where the model components xt and Ft are unknown and subject to
estimation, the Kalman ﬁlter is not optimal in the sense that Kalman has proved,

18
1
State Space Models
because the additional estimation of such components introduce certain limitations
and biases. On one hand this has led in certain cases to misuse of the Kalman ﬁlter,
and in other cases it has motivated the development and extension of Kalman-type
algorithms, such as the expectation maximisation algorithm or sequential Monte
Carlo methods. Both of these approaches are discussed in detail in Chaps. 4 and 5
in this book.
Kalman’s method was not received without controversy. He was not able to
publish his seminal paper in an electrical or systems engineering journal, and people
who attended his talks found it hard to realise the potential of the Kalman ﬁlter.
However, Stanley F. Schmidt from the Ames Research Centre of NASA was able
to see its importance when Kalman explained it to him in a visit in 1960. Schmidt
was the ﬁrst to implement the Kalman ﬁlter for the trajectory estimation and control
problems for the Apollo project. He then soon discovered what is now known as
the “extended Kalman ﬁlter”, which is basically a linearisation of observation and
state functions to deal with non-linearities and is discussed in Chap. 5. In the 1960s
apart from the work of Schmidt and his colleagues, several people were involved in
application and developments related to the Kalman ﬁlter, most notably Kalman and
Bucy (1961), Raunch et al. (1965), Schweppe (1965) and Young (1968, 1969). Since
then the Kalman ﬁlter and its generalisations have been applied widely in science
and in real-life applications, e.g. in navigation systems, in digital ﬁlters, systems
engineering, time series forecasting and control.
Kalman is currently emeritus professor in three universities. Kalman received
the 2008 Charles Stark Draper Prize “for the development and dissemination of the
optimal digital technique (known as the Kalman Filter) that is pervasively used to
control a vast array of consumer, health, commercial and defence products”.
Bayesian Forecasting: Jones, Harrison and Stevens
Although the state space model has been known to engineers since 1956 (Halcombe
Laning & Battin, 1956), statisticians and economists did not seem to exploit it.
John Fraser Muth (1930–2005), an eminent economist known as the father of the
rational expectations revolution in economics, introduced in 1960 the local level
model (see Sect. 1.2 above), and gave its relationship with the popular exponentially
weighted moving average forecasting procedure Muth (1960). In the 60s the closest
effort of statistical ﬁltering of the state space model was the attempt of Richard
H. Jones in 1966 (Jones, 1966). Jones introduced Kalman ﬁltering to the statistics
and econometrics scientiﬁc communities and he applied it in order to estimate the
parameters of Muth’s exponential smoothing model. He is also the ﬁrst to provide a
derivation of the Kalman ﬁlter based on conditional Gaussian distribution theory as
opposed to projections adopted by Kalman. Jeff P. Harrison almost independently
was arriving at the same line of research, with some preliminary results in his
exponential smoothing 1967 paper (Harrison, 1967), which was generalised later
by Godolphin and Harrison (1975). However, these studies did not realise their
potential, perhaps, due to the technological and computational limitations of the
1960s.

1.5
Layout of the Book
19
Jeff Harrison met C. F. Stevens at Imperial Chemical Industries (ICI) where
they worked together on a series of papers. They ﬁrst observed that many different
types of time series (especially non-stationary time series, exhibiting trend and
seasonal variation) could be described by state variables and indeed by state space
models. This important observation led to the adoption of the Kalman ﬁlter (as this
was developed for non-stationary processes) and had a signiﬁcant advantage over
competitive time series methods, based upon the assumption of stationarity, e.g.
Box-Jenkins methods (Box et al., 2008). In 1971 Harrison and Stevens published
their ﬁrst account of state space modelling for time series data (Harrison & Stevens,
1971). They adopted a derivation of the Kalman ﬁlter similar to that of Jones, but
made the important observation that the state variables could incorporate many
familiar time series models; this came under the title Bayesian forecasting, because
the Bayes theorem was used to provide the forecast distribution. This new approach
offered an array of new possibilities utilising Bayesian statistics, which at the time
was undergoing rapid development. Some of these possibilities were explored in
their seminal paper in 1976 (Harrison & Stevens, 1976) which was read before
the Royal Statistical Society. It is worth mentioning that in the early 70s several
economists used the Kalman ﬁlter for inventory forecasting and control (see the
introduction of Morrison and Pike (1977) for references). In particular, in 1977,
independently of Harrison and Stevens, Morrison and Pike (1977) rediscovered
the Kalman ﬁlter as a general estimation procedure of non-stationary time series
forecasting.
In the 80s many scientists realised the potential of state space modelling using
the Kalman ﬁlter. Among many authors, A.C. Harvey and his co-authors published
articles in 1980 and 1981 that demonstrate state space models and the Kalman ﬁlter
(Harvey et al., 1980; Harvey, 1981). In 1984 Harvey showed how the Kalman ﬁlter
can provide a uniﬁed estimation methodology for stationary and non-stationary time
series (Harvey, 1984); he was one of the ﬁrst to point out the correspondence of state
space models and the Box-Jenkins autoregressive moving average models. Soon
after in 1989 Harvey published his book on structural models and the Kalman ﬁlter
(Harvey, 1989), which is known to have educated generations of statisticians, since
1989. The growth of state space models is reﬂected by textbooks and monographs,
such as Anderson and Moore (1979), West and Harrison (1997) [ﬁrst published in
1989] and later Grewal and Andrews (2015) and Durbin and Koopman (2012).
1.5
Layout of the Book
The aim of the book is to introduce state space models and the Kalman ﬁlter and to
illustrate its wide application in science and commerce. The book aims to present
a concise yet self-contained treatment of state space models with applications in
many different disciplines. Throughout the book we adopt the Bayesian paradigm
for estimation and forecasting, as this is judged to be the modern statistical
approach which beneﬁts from the high-performancecomputational power. However,

20
1
State Space Models
in places we discuss frequentist-based inference, such as least squares and maximum
likelihood estimation. The layout of the book is as follows.
Chapter 2 provides the mathematical background related to Kalman ﬁlter,
including matrix algebra, analysis, probability and statistics. In this chapter we
summarise the main results which are necessary for the reader to develop the
technical arguments that follow in Chap. 3.
Chapter 3 introduces the state space model and develops ﬁltering and smoothing
estimation methodologies, including the Kalman ﬁlter, as well as forecasting. We
motivate the state space model by considering it as an extension of the linear
regression model. The chapter describes a package of the programming language
for statistical computing R, which is used throughout the book. Two proofs of the
Kalman ﬁlter are given, each of which provides different insight into the structure
of the ﬁlter. Throughout the chapter examples illustrate the applicability of the
estimation algorithms.
Chapter 4 discusses further topics on the implementation of linear state space
models. We start by discussing an array of useful state space forms of real-life
situations, such as time series comprising trend, seasonal, autoregressive and time-
varying regression components. These are discussed with particular data in mind
and the Kalman ﬁlter is applied to provide forecasting solutions. Then maximum
likelihood and related concepts are described to provide a way of estimating or
specifying parameters of the models. Error analysis and diagnostic checks as well
as prior speciﬁcation are considered in some detail. The chapter concludes by
discussing model monitoring and intervention analysis.
Chapters 5 and 6 discuss models that go beyond the Kalman ﬁlter. The aim of
these chapters is to give an account of modern statistical methodologies for state
space models and therefore to illustrate recent trends of research in this area. These
include covariance estimation of multivariate state space models, non-linear and
non-Gaussian state space models, and sequential Monte Carlo estimation methods.
Chapters 7 and 8 discuss the application of state space methods in ﬁnance and
in dynamical systems. While ﬁnance and economics paid particular attention to
the Kalman ﬁlter, as noted earlier, systems engineering is where the Kalman ﬁlter
was discovered. As a result these major areas of application of the Kalman ﬁlter
and related methods are considered in Chaps. 7 and 8. The selection of illustrative
examples presented in those two chapters aim to showcase the applicability and
contribution of the state space models to these areas.

Chapter 2
Matrix Algebra, Probability
and Statistics
This chapter offers notation and the necessary background for the development of
state space methods that follows. The background lies on three basic areas, matrix
algebra, probability and statistics. We start with matrix algebra in Sect. 2.1; we
develop in some detail vector and matrix differentiation, while other elements of
more standard matrix algebra are just mentioned. Section 2.3 discusses probability
and distribution theory relevant to the needs of the book. This section aims to
establish notation and to remind to the reader the notion of distribution theory
relevant to ﬁltering and state space modelling. Several examples of discrete and
continuous distributions, which will be used in later chapters, are presented. Sec-
tion 2.4 discusses the ideas behind statistics necessary for the chapters that follow.
The maximum likelihood principle is introduced and the expectation maximisation
(EM) algorithm is discussed in detail. The chapter concludes with an introduction
to Bayesian inference.
2.1
Vectors, Matrices and Basic Operations
We assume that the reader is familiar with calculus of one and several variables,
with matrix algebra and with basic probability and statistics. For detailed coverage
of calculous of one and several variables the reader is referred to Spivak (1995)
and to Lang (1987), respectively. Matrix algebra and matrix analysis are discussed
in Magnus and Neudecker (1988), Harville (1997) and Horn and Johnson (2013).
Below we establish some basic notation and highlight a few important concepts. We
assume that the reader is familiar with matrix addition and multiplication, inverse of
a matrix, symmetric and positive deﬁnite matrices, trace of a square matrix and the
determinant of a square matrix.
Scalars and vectors are denoted by small letters, e.g. a, b, c, while matrices are
denoted by boldface capital letters, e.g. A, B, C. Sets are denoted by capital letters,
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2021
K. Triantafyllopoulos, Bayesian Inference of State Space Models, Springer Texts
in Statistics, https://doi.org/10.1007/978-3-030-76124-0_2
21

22
2
Matrix Algebra, Probability and Statistics
e.g. A = {a, b, c} and R denotes the set of real numbers. An m × n matrix A is
usually denoted by A = (aij)i=1,...,m;j=1,...,n, where aij is the ij-th element of A,
m is the number of rows and n is the number of columns; sometimes we simply
write A = (aij), if the range of i, j is implied. If m = n A is usually referred
to as a square matrix. Unless otherwise stated, we will assume that A is a matrix
with elements from the real ﬁeld. A matrix with zero elements (aij = 0, for all
i, j) is referred to as the zero-matrix and is denoted by 0; a square matrix with
aii = 1 and aij = 0, for i ̸= j and m = n is known as the identity matrix and
is denoted by I. A diagonal matrix is a matrix with diagonal elements a11, . . . , ann
and aij = 0, for i ̸= j; usually we write A = diag(a11, . . . , ann) or A = diag(a),
where a is a column vector a = [a11, . . . , ann]⊤and sometimes we may write
diag(A) to denote a diagonal matrix with diagonal elements the diagonal elements
of a matrix A. A symmetric matrix A = (aij)i,j=1,2,...,n is a n × n square matrix
with aij = aji, for all i, j = 1, 2, . . . , n. A non-negative deﬁnite matrix is a matrix
A with x⊤Ax ≥0, for any vector x. If x⊤Ax > 0, for all non-zero vectors x, then A
is called positive deﬁnite. In statistics symmetric and positive deﬁnite matrices play
a signiﬁcant role as they represent the variance and covariance structure of random
vectors (see Sect. 2.3).
The inverse of an n × n non-singular matrix A is denoted by A−1, the trace of
an n × n matrix A is denoted by trace(A), the determinant of A is demoted by |A|.
In the sections below we discuss in some detail vector and matrix differentiation,
optimisation and limit of matrices. Below we list some of the properties of matrix
operations.
1. Integer powers of a matrix. Consider a square matrix A. The power of order k
of A, denoted as Ak, is deﬁned to be the product
Ak = AA · · · A



k−times
= Ak−1A = AAk−1,
for some integer k > 0, while for k = 0 we deﬁne A0 = I.
2. Determinant of a matrix. Associated with any n × n matrix A there is a scaler,
known as the determinant of A and denoted by |A|. For a full deﬁnition of the
determinant the reader is referred to Harville (1997, page 177). Here we just
mention two of the properties of determinants.
a. For any constant c, it is |cA| = cn|A|;
b. For two n×n matrices A and B, it is |AB| = |A||B| (in words: the determinant
of the product of two matrices is equal to the product of the determinant of
the two matrices).
3. Trace of a matrix. Associated with any square matrix A = (aij) is a scalar,
called the trace of A, which is denoted by trace(A) and deﬁned as
trace(A) = a11 + a22 + · · · + ann =
n

i=1
aii.

2.1
Vectors, Matrices and Basic Operations
23
We give two basic properties of the trace of a matrix
a. For any n × n matrices A = (aij) and B = (bij), we have
trace(A + B) = trace(A) + trace(B).
b. For two n × n matrices A and B we have
trace(AB) = trace(BA).
4. The vec, vech and the Kronecker product.
For an m×n matrix A the vec operator rearranges the elements of A into a vector
by stacking the columns of A one after the other. For example, if A = (aij) =
[a1, a2, . . . , an], where ai = [a1i, a2i, . . . , ami]⊤represents the i-th column of
A, for i = 1, 2, , . . . , n, then
vec(A) =
⎡
⎢⎢⎢⎣
a1
a2
...
an
⎤
⎥⎥⎥⎦
which is an mm × 1 vector.
The Kronecker product of an m×n matrix A and a p×q matrix B is the mp×nq
matrix deﬁned by
A ⊗B = (aijB).
For example, for n = m = p = q = 2 we have
A ⊗B =

 a11B a12B
a21B a22B

=
⎡
⎢⎢⎣
a11b11 a11b12 a12b11 a12b12
a11b21 a11b22 a12b21 a12b22
a21b11 a21b12 a22b11 a22b12
a21b21 a21b22 a22b21 a22b22
⎤
⎥⎥⎦.
A few properties of the vec and Kronecker operations are listed below
a. If A, B and C are matrices so that the product ABC is deﬁned, then
vec(ABC) = (C⊤⊗A)vec(B).
When matrix A is symmetric, then since aij = aji not all elements of the vector
vec(A) are distinct. In such a case we can obtain a vectored rearrangement of

24
2
Matrix Algebra, Probability and Statistics
A by stacking columns of A with distinct elements only and this is denoted as
vetch(A). For example, for m = n = 2 we have
vech

 a11 a12
a12 a22

=
⎡
⎣
a11
a12
a22
⎤
⎦.
2.2
Vector and Matrix Differentiation
2.2.1
Background and Notation
In this section we describe the notion of vector and matrix partial derivatives,
necessary for the development of this book. We will restrict our attention to two
cases (1) partial derivatives of scalar function of a vector x and (2) partial derivatives
of scalar function of a symmetric matrix X. We denote with Rn the cartesian product
Rn = R × R × · · · × R, so that Rn contains vectors x = [x1, x2, . . . , xn]⊤, with
xi ∈R, for i = 1, 2, . . . , n. For a more detailed treatment of matrix calculus the
reader is referred to Magnus and Neudecker (1988) and Harville (1997).
1. It is assumed that a function f (·) of the vector x is continuously differentiable
at an interior vector point c in the domain D (a subset of Rn); for a precise
deﬁnition of differentiability the reader is referred to Magnus and Neudecker
(1988) and Harville (1997). We shall write f (x) to denote the value of f (·) at
point x and usually it will be assumed that D = Rn. The partial derivative of
f (x) (deﬁned at an interior point of a subset of D) with respect to xi, denoted by
∂f (x)/∂xi, is the scalar derivative of f (x) = f (x1, . . . , xi, . . . , xn) when this is
viewed as a function of xi alone and all xj ̸= xi are viewed as constants, where
x = [x1, . . . , xn]⊤. The partial derivative of f (x) with respect to x, denoted
by ∂f (x)/∂x is deﬁned to be the vector with elements the respective partial
derivatives ∂f (x)/∂xi, i.e.
∂f (x)
∂x
=
⎡
⎢⎢⎢⎣
∂f (x)/∂x1
∂f (x)/ ∂x2
...
∂f (x)/∂xn
⎤
⎥⎥⎥⎦.
Some special derivatives used in this book are covered in Sect. 2.2.2.

2.2
Vector and Matrix Differentiation
25
In the same way we can deﬁne second and higher order partial derivatives of
f (x). The second partial derivative of f (x), denoted as ∂2f (x)/∂x∂x⊤is the
transpose of the ﬁrst partial derivative of ∂f (x)/∂x, i.e.
∂2f (x)
∂x∂x⊤=
⎡
⎢⎢⎢⎣
∂2f (x)/∂x2
1
∂2f (x)/∂x1∂x2 · · · ∂2f (x)/∂x1∂xn
∂2f (x)/∂x2∂x1
∂2f (x)/∂x2
2
· · · ∂2f (x)/∂x2∂xn
...
...
...
...
∂2f (x)/∂xn∂x1 ∂2f (x)/∂xn∂x2 · · ·
∂2f (x)/∂x2
n
⎤
⎥⎥⎥⎦,
assuming that all ∂2f (x)/∂xi∂xj are deﬁned, for i, j = 1, . . . , n.
2. For the purposes of partial derivatives of a function of matrices, we consider f (·)
to be a continuously differentiable function on an n × n matrix X and we write
f (X) for the value of f (·) at X; we note that the value of f (X) is a real number.
The domain of such a function is a subset D of all matrices with real elements,
usually denoted by Rn×n. This is basically a special case of (1) as X can be
rearranged as a long vector (by stacking all column vectors of X). However, for
the purposes of matrix calculation and convenience in the presentation we retain
the matrix notation. Since X has n2 elements f (X) can be viewed as a function
of n2 variables. If, however, some of the elements of X are not distinct, e.g. when
X is a symmetric matrix, then we need to consider only the distinct elements in
the differentiation of f (X).
Writing X = (xij) for an unrestricted matrix of variables, we deﬁne the partial
derivative matrix of f (X) as the matrix with ij-th element the partial derivative
of f (X) with respect to xij, deﬁned at an interior point of D, i.e.
∂f (X)
∂X
=
⎡
⎢⎢⎢⎣
∂f (X)/∂x11 ∂f (X)/∂x12 · · · ∂f (X)/∂x1n
∂f (X)/∂x21 ∂f (X)/∂x22 · · · ∂f (X)/∂x2n
...
...
...
...
∂f (X)/∂xn1 ∂f (X)/∂xn2 · · · ∂f (X)/∂xnn
⎤
⎥⎥⎥⎦.
If X is symmetric, this logic does not work, since there are only n(n + 1)/2
distinct elements in X (out of the possible n2). In such a case X is rearranged
into a [n(n + 1)/2] × 1 column vector x = vech(X), as discussed in the previous
section. Now the partial derivative of f (X) can be formed as the vector partial
derivative with respect to x, which then is rearranged as a symmetric matrix to
form ∂f (X)/∂X.
Dealing with case (2) we will also need to deﬁne a matrix-valued function F(·) =
(fkl)k=1,2,...,q;l=1,2,...,s deﬁned on a matrix of variables X = (xij) (unrestricted
or restricted). In such a case we write F(X) for the value of F(·) on matrix X;
the domain D of F(·) is all n × n real-valued matrices (if X is unrestricted) or
D can be deﬁned as above for symmetric matrices. Each constituent function
fkl(X) of the matrix F(X) is a scalar-valued function on the matrix X and it is
assumed to be continuously differentiable at an interior point of D. Then the

26
2
Matrix Algebra, Probability and Statistics
partial derivative of F(X) with respect to xij is deﬁned to be the matrix
∂F(X)
∂xij
=
⎡
⎢⎢⎢⎣
∂f11(X)/∂xij ∂f12(X)/∂xij · · · ∂f1s(X)/∂xij
∂f21(X)/∂xij ∂f22(X)/∂xij · · · ∂f2s(X)/∂xij
...
...
...
...
∂fq1(X)/∂xij ∂fq2(X)/∂xij · · · ∂fqs(X)/∂xij
⎤
⎥⎥⎥⎦.
2.2.2
Differentiation of Linear and Quadratic Forms
We consider here the partial derivatives of a linear form
f (x) = a⊤x =
n

i=1
aixi
and a quadratic form
g(x) = x⊤Ax =
n

i=1
n

k=1
aikxixk,
where a = [a1, a2, . . . , an]⊤is a vector of constants, A = (aij) is an n × n matrix
of constants and x = [x1, x2, . . . , xn]⊤.
The partial derivative of f (x) with respect to xj is
∂f (x)
∂xj
=
∂
∂xj
n

i=1
aixi =
n

i=1
ai
∂xi
∂xj
= aj,
(2.1)
since
∂xi
∂xj
=

1
if i = j
0
if i ̸= j
.
Recasting (2.1) in matrix form, we obtain
∂(a⊤x)
∂x
= a.
(2.2)

2.2
Vector and Matrix Differentiation
27
Moving on now to the quadratic form g(x) we have
∂g(x)
∂xj
=
∂
∂xj
n

i=1
n

k=1
aikxixk
=
∂
∂xj
 n

i=1
ai1xix1 + · · · +
n

i=1
ai,j−1xixj−1 +
n

i=1
ai,j+1xixj+1
+ · · · +
n

i=1
ainxixn +

i̸=j
aijxixj + ajjx2
j
⎞
⎠
= aj1x1 + . . . aj,j−1xj−1 + aj,j+1xj+1 + · · · + ajnxn
+

i̸=j
aijxixj + 2ajjxj
=
n

k=1
ajkxk +
n

i=1
aijxi.
Recasting this in matrix form we obtain
∂(x⊤Ax)
∂x
= (A + A⊤)x,
(2.3)
since the j-th element of the vector Ax is n
k=1 ajkxk and the j-th element of the
vector A⊤x is n
i=1 aijxi.
Next we compute the second partial derivative matrix of the quadratic form g(x).
As mentioned in the previous section, this will be the n×n matrix with ij-th element
∂2g(x)/∂xlxj, for l, j = 1, . . . , n.
We have
∂2(x⊤Ax)
∂xl∂xj
=
∂
∂xj

∂(x⊤Ax)
∂xl

=
∂
∂xj
 n

i=1
ailxi +
n

k=1
alkxk

=
n

i=1
ail
∂xi
∂xj
+
n

k=1
alk
∂xk
∂xj
= ajl + alj
and recasting this in matrix form we obtain
∂2(x⊤Ax)
∂x∂x⊤
= A + A⊤.
(2.4)

28
2
Matrix Algebra, Probability and Statistics
If A is a symmetric matrix, then the partial derivatives (2.3) and (2.4) simplify to
∂(x⊤Ax)
∂x
= 2Ax
and
∂2(x⊤Ax)
∂x∂x⊤
= 2A.
(2.5)
This equation is applied in Sect. 3.1.1 in order to derive the least squares solution in
regression.
2.2.3
Differentiation of Determinant and Trace
Below we provide formulae for the partial derivatives of the logarithm of the
determinant of a symmetric matrix and of the trace; both of these are used in the
maximisation step of the EM algorithm in Sect. 4.3.1.
Differentiation of the Logarithm of the Determinant Consider X to be an n × n
non-singular symmetric matrix and |X| to demote the determinant of X. First we
derive a formula for ∂log |X|/∂X.
Very closely related to the determinant is the cofactor matrix. Let Xij be an (n −
1) × (n −1) submatrix of X (a submatrix of X is a matrix whose elements are also
elements of X) obtained by striking out the row and column that contain the element
xij, i.e. the i-th row and the j-th column. The signed determinant (−1)i+j|Xij|
is called the cofactor of xij and is denoted by ξij. A fundamental property of the
cofactors is that
|X| = xi1ξi1 + xi2ξi2 + · · · + xinξin =
n

j=1
xijξij
(2.6)
and this can be used to compute the determinant of a matrix.
The n×n matrix consisting of elements ξji in its ij-th element (i.e. the transpose
of the matrix whose ij-th element is the cofactor ξij is called the adjoint matrix and
is denoted by adj(X). A fundamental property of adj(X) relates this matrix to the
inverse matrix X−1 and it is given below
X−1 = 1
|X|adj(X).
(2.7)
For the proof of this result the reader is referred to Harville (1997, page 192).
From Eq. (2.6) we have that
∂|X|
∂xij
=
n

k=1
ξik
∂xik
∂xij

2.2
Vector and Matrix Differentiation
29
and since X is symmetric, so is the adjoint matrix adj(X) = (ξij). Hence from
Eq. (2.7) it is
∂|X|
∂xij
= trace

adj(X) ∂X
∂xij

= trace

|X|X−1 ∂X
∂xij
	
= |X|trace

X−1 ∂X
∂xij
	
.
Deﬁne ui to be the n × 1 vector with a unit in the i-th position and elsewhere zeros,
i.e.
ui = [0, . . . , 0, 1, 0, . . . , 0]⊤.
We can see that since X is symmetric (i.e. xij = xji), then
∂X
∂xij
=

uiu⊤
i ,
i = j
uiu⊤
j + uju⊤
i ,
j < i
,
(2.8)
i.e. a matrix having a unit at the ii-th position and elsewhere zero, if i = j and a
matrix having two units at positions ij and ji and elsewhere zeros, if j < i.
Now using the chain rule of differentiation for scalar functions
∂log |X|
∂xij
=
1
|X|
∂|X|
∂xij
= trace

X−1 ∂X
∂xij
	
=
⎧
⎨
⎩
trace

X−1uiu⊤
i

,
i = j
trace

X−1uiu⊤
j

+ trace

X−1uju⊤
i

,
j < i
=

u⊤
i X−1ui,
i = j
u⊤
j X−1ui + u⊤
i X−1uj,
j < i
=

x(−1)
ii
,
i = j
2x(−1)
ij
,
j < i
,
where X−1 = (x(−1)
ij
). Recasting this to matrix form we obtain
∂log |X|
∂X
= 2X−1 −diag(X−1),
(2.9)
where diag(X−1) denotes a diagonal matrix with diagonal elements x(−1)
11
,
x(−1)
22
, . . . , x(−1)
nn
.
Differentiation of the Trace In this part we aim to provide a formula for
∂trace(AX−1)/∂X, where A is an n × n matrix of constants and X = (xij) is as
before an n × n non-singular symmetric matrix of variables.

30
2
Matrix Algebra, Probability and Statistics
Consider F(X) a matrix-valued function of X. Then for each xij element of X it
is
∂trace[F(X)]
∂xij
= trace

∂F(X)
∂xij

.
(2.10)
To show this, we write fij (X) to be the ij-th element function (in X) of F(X), i.e.
F(X) = (fij (X)). Then
∂trace[F(X)]
∂xij
= ∂f11(X)
∂xij
+ ∂f22(X)
∂xij
+ · · · + ∂fnn(X)
∂xij
= trace

∂F(X)
∂xij

,
as required.
Next we show that if F(X) is an n×n matrix of functions, then with the deﬁnition
of A = (aij) above, we have
∂AF(X)
∂xij
= A∂F(X)
∂xij
.
(2.11)
This follows by simply writing AF(X) =
n
k=1 aikfkj(X)

and consequently
∂AF(X)
∂xij
=
 n

k=1
aik
∂fkj(X)
∂xij
!
= A∂F(X)
∂xij
.
Also, for two matrix-valued functions F(X) and G(X) deﬁned on the same domain
D, so that the matrix product F(X)G(X) is deﬁned, we have the usual multiplicative
law of differentiation
∂F(X)G(X)
∂xij
= ∂F(X)
∂xij
G(X) + F(X)∂G(X)
∂xij
.
(2.12)
To show this ﬁrst write F(X) = (fij(X)) and G(X) = (gij(X)) so that F(X)G(X) =
n
k=1 fik(X)gkj(X)

. Then
∂F(X)G(X)
∂xij
=
 n

k=1
∂fik(X)
∂xij
gkj(X) +
n

k=1
fik(X)∂gkj(X)
∂xij

= ∂F(X)
∂xij
G(X) + F(X)∂G(X)
∂xij
.
Now we use result (2.12) to show
∂X−1
∂xij
= −X−1 ∂X
∂xij
X−1.
(2.13)

2.2
Vector and Matrix Differentiation
31
We start by the usual equation XX−1 = I and take partial derivatives in both sides
∂X
∂xij
X−1 + X∂X−1
∂xij
= 0,
or
∂X−1
∂xij
= −X−1 ∂X
∂xij
X−1.
Finally, combining (2.10), (2.11), (2.13) together with (2.8) we obtain
∂trace(AX−1)
∂xij
= trace
∂AX−1
∂xij
	
= trace

A

−X−1 ∂X
∂xij
X−1
	
=

−trace(AX−1uiu⊤
i X−1),
i = j
−trace[AX−1(uiu⊤
j + uju⊤
i )X−1],
j < i
=

−u⊤
i X−1AX−1ui,
i = j
−u⊤
j X−1AX−1ui −u⊤
i X−1AX−1uj,
j < i
=

−cii,
i = j
−cji −cij,
j < i
,
where X−1AX−1 = C = (cij). This equation can be written in matrix form as
∂trace(AX−1)
∂X
= −C −C⊤+ diag(C).
When A is symmetric, the above formula simpliﬁes to
∂trace(AX−1)
∂X
= −2X−1AX−1 + diag(X−1AX−1).
(2.14)
2.2.4
Optimisation, Integration and Limits
Optimisation Many statistical problems involve ﬁnding the maximum or min-
imum of a function f (x) of a vector x = [x1, x2, . . . , xn]⊤; for example, in
Sect. 3.1.1 we are interested in maximising the likelihood function in the context
of ordinary regression. Assuming that f (x) is continuously differentiable in the
domain D ∈Rn, then the possible maximum/minimum is identiﬁed by solving the
equation
∂f (x)
∂x
= 0.

32
2
Matrix Algebra, Probability and Statistics
The solution x = x∗of this equation gives what is known as stationary point. If the
second partial derivative evaluated at this point is a positive deﬁnite matrix (negative
deﬁnite matrix), then x∗is the required minimum (maximum).
For example, consider the function
f (x) = x⊤Ax + 2a⊤x + c,
where A is an n × n positive deﬁnite matrix of knowns, a and c are n-dimensional
vectors of knowns and x is an n-dimensional vector of variables.
From derivatives (2.5) and (2.2) we have
∂f (x)
∂x
= 2Ax + 2a
and equating this to zero we obtain x∗= −A−1a. Here we note that since A is
positive deﬁnite it is also non-singular, hence A−1 exists.
From (2.5) the second partial derivative matrix is
∂2f (x)
∂x∂x⊤= 2A,
which is a positive deﬁnite matrix, hence x∗is a minimum. The minimum value of
f (x) is
f (x∗) = (−Aa)⊤A(−A−1a) + 2a⊤(−A−1a) + c = −a⊤A−1a + c.
Integration In this section we give a brief discussion on integration of scalar
functions of argument a vector or a matrix. Suppose that f (x) is a scalar function of
argument a vector x = [x1, . . . , xn]⊤. We assume that f (x) is continuous in each
interior point of D (a subset of Rn). Then the multiple integral of f (x) over D is
denoted by
"
D
f (x) dx =
" "
· · ·
"
D
f (x1, x2, . . . , xn) dx1 dx2 · · · dxn.
It is outside the scope of this book to discuss a technical development of multiple
integrals. For a formal deﬁnition and calculus of several variables, the reader is
referred to Lang (1987); an excellent treatment of calculus of one variable is given
in Spivak (1995). Similarly, multiple integrals of a scalar function f (X) of a matrix
X may be considered and the notation
"
D
f (X) dX

2.2
Vector and Matrix Differentiation
33
will be adopted, where D is the domain of f (X). Note that when X is a symmetric
matrix, the integral needs to be amended to include only the variables that are
distinct. Following standard notation we still keep the above notation, but it is
understood that integration is carried over the n(n + 1)/2 distinct elements of X.
Limit of a Sequence of Matrices A sequence of square matrices is a collection of
matrices A1, A2, . . ., indexed by t = 1, 2, . . .. We write At for the t-th term of the
sequence. In order to form the limit of At as t →∞, we need ﬁrst to introduce the
notion of norm or distance for matrices. The norm of a matrix (usually referred to
as matrix norm) is denoted by ∥· ∥and is a function of any m × n matrix A that
satisﬁes the following conditions
1. ∥A ∥≥0 ;
2. ∥A ∥= 0, if and only if A = 0;
3. cA = |c| ∥A ∥, where c is a scalar and |c| denotes the modulus of c;
4. ∥A + B ∥≤∥A ∥+ ∥B ∥, for any m × n matrices ∥A ∥and ∥B ∥.
Some matrix norms also satisfy the property
∥AB ∥≤∥A ∥∥B ∥,
for any n × n matrices A and B.
For example, the Euclidean norm for any vector a (a matrix with n = 1) is
deﬁned as
∥a ∥=

a2
1 + a2
2 + · · · + a2
m
1/2
=

a⊤a
1/2
,
where a = [a1, a2, . . . , am]⊤.
The Frobenius norm is a generalisation of the Euclidean norm to matrices and is
deﬁned for any m × n matrix A = (aij) as
∥A ∥=
⎛
⎝
m

i=1
n

j=1
a2
ij
⎞
⎠
1/2
=
%
trace(A⊤A)
&1/2
.
Having deﬁned the matrix norm, we can deﬁne the distance between two matrices
A and B as d =∥A −B ∥. Note that in case of n = 1, this deﬁnition gives the
well known Euclidean distance between two vectors a = [a1, a2, . . . , am]⊤and
b = [b1, b2, . . . , bm]⊤
d =
'
(a1 −b1)2 + (a2 −b2)2 + · · · + (am −bm)2.

34
2
Matrix Algebra, Probability and Statistics
The distance of two vectors or matrices are used to measure convergence of iterative
algorithms, e.g. in the context of the EM algorithm discussed in Sect. 2.4.2 below
and in Sect. 4.3.1.
The sequence of matrices A1, A2, . . ., sometimes written as {At} is said to
converge to a limiting matrix A, if and only if for any ε > 0, there exists some
t0 > 0 such that for any t > t0 it is
∥At −A ∥< ε.
This deﬁnition extends immediately the deﬁnition of a limit of sequence of real
numbers by replacing scalars by matrices and moduli by norms; for more details
on limits of one variable the reader is referred to Spivak (1995). Matrix norms are
covered in detail in the classic text of matrix analysis (Horn & Johnson, 2013).
2.3
Probability and Distribution Theory
2.3.1
Random Vectors and Probability Distributions
Probability and statistics study uncertainty. Uncertainty arises when possible out-
comes of an experiment, or a phenomenon in general, are uncertain. For example,
the future movements of shares in the stock market are uncertain; likewise the
possible increase or decrease in global temperature, which may be accounted for
an indicator of climate change, are uncertain. Probability provides the mathematical
notion for describing such phenomena, by introducing random outcomes responsi-
ble for the underlying uncertainty. Statistics adopts probability models with the aim
to make inference based on observed data.
It is assumed that the reader is familiar with the basic notions of probability,
with random vectors and with probability distributions and with their properties.
Below we provide a brief summary of some of the basic deﬁnitions and properties
necessary for establishing notation.
1. A p-dimensional random vector, demoted by X is a vector whose elements are
random variables; we shall write
X =
⎡
⎢⎢⎢⎣
X1
X2
...
Xp
⎤
⎥⎥⎥⎦.
Clearly when p = 1, X is reduced to a random variable. If the values of Xi
are discrete (the domain of Xi is a discrete set), then X is known as a discrete

2.3
Probability and Distribution Theory
35
random vector, while if the domain of Xi is a continuous set, then X is known as
a continuous random vector.
2. Associated with X is its joint cumulative distribution function (c.d.f.) deﬁned as
FX(x) = FX(x1, x2, . . . , xp) = P(X1 ≤x1, X2 ≤x2, . . . , Xp ≤xp),
which is the probability of the event A = {X1 ≤x1} ∩{X2 ≤x2} ∩· · · ∩{Xp ≤
xp}, a subset of Rp.
If X is discrete we deﬁne the joint probability mass function (p.m.f.) of X as
pX(x) = pX(x1, x2, . . . , xp) = P(X1 = x1, X2 = x2, . . . , Xp = xp),
(2.15)
the probability of the event A = {X1 = x1} ∩{X2 = x2} ∩· · · ∩{Xp = xp},
where A ∩B denotes the intersection of the events A and B.
If X is continuous, we deﬁne the joint probability density function (p.d.f.) of X
is
pX(x1, x2, . . . , xp) =
∂pFX1X2···Xp(x1, x2, . . . , xp)
∂x1∂x2 · · · ∂xp
.
(2.16)
It follows that
FX(x) =
" x1
−∞
" x2
−∞
· · ·
" xp
−∞
pX(u1, u2, . . . , up) du1 du2 · · · dup
(2.17)
and a similar formula applies for discrete random vectors, if we replace the
integrals by sums. When p = 1 and X is continuous the above formulae simplify
to
pX(x) = dFX(x)
dx
and
FX(x) =
" x
−∞
pX(u) du.
Equations (2.15)–(2.17) indicate that knowledge of the p.m.f. or p.d.f. implies
knowledge of the c.d.f. and vice versa.
3. The marginal distribution of Xi is deﬁned by integrating out the rest Xj (j ̸= i)
random variables, i.e.
pXi(xi) =
" ∞
−∞
pX(x1, x2, . . . , xp) dx1 · · · dxi−1 dxi+1 · · · dxp
and similarly we deﬁne the marginal c.d.f. of Xi. If X is discrete there is an
analogous deﬁnition of the marginal p.m.f. where the above integral is replaced
by a sum.
We deﬁne the conditional p.d.f. (p.m.f. if discrete) as the ratio of the joint
p.d.f. (p.m.f. if discrete) and the marginal p.d.f (p.m.f. if discrete), e.g. if X =

36
2
Matrix Algebra, Probability and Statistics
[X1, X2]⊤is continuous, then the conditional p.d.f. of X1, given X2 = x2 is
deﬁned as
pX1|X2(x1 | x2) = pX(x1, x2)
pX2(x2) .
The random variables X1, X2, . . . , Xp are said to be independent, if their joint
p.d.f. (or p.m.f. if they are discrete) can be written as a product of their marginals,
i.e.
pX(x1, x2, . . . , xp) = pX1(x1)pX2(x2) · · · pXp(xp).
If the random variables X1, X2, . . . , Xp are not independent, then they are said
to be dependent.
4. If X is continuous then the expectation of X is deﬁned as
E(X) =
"
Rp xpX(x1, x2, . . . , xp) dx1 dx2 · · · dxp
and if X is discrete the above integral is replaced by a sum.
For any continuous random vectors X, Y with conditional p.d.f. pX|Y (x | y) we
deﬁne the conditional expectation of X, given Y = y as the expectation of X,
with respect to the conditional density X | Y = y, i.e.
E(X | Y = y) =
"
Rx
xpX|Y (x | y) dx,
for any value y of Y, where Rx is the domain of pX|Y (x | y).
5. The covariance matrix of X is
Var(X) = E[X −E(X)][X −E(X)]⊤
and the covariance of two random vectors X and Y is
Cov(X, Y) = E[X −E(X)][Y −E(Y)]⊤.
The following two properties are referred to as the tower properties and are useful
when we can calculate expectations of variances of X | Y, but not directly of X.
For any random vectors X and Y we have
a. E(X) = E[E(X | Y)];
b. Var(X) = E[Var(X | Y)] + Var[E(X | Y)].
Property (a) is used to derive the independence of the residuals in Theorem 4.2
(Sect. 4.4).

2.3
Probability and Distribution Theory
37
2.3.2
Common Discrete Distributions
In this section we discuss four discrete distributions, the Poisson, the binomial,
the negative binomial and the multinomial distribution. Some of these distributions
are used to formulate discrete-response state space models, such as the dynamic
generalised linear models of Sect. 6.2.The binomial distribution is also discussed
in Sect. 2.4.3. For simplicity in the notation we drop the subscript X in the p.m.f.
pX(x), i.e. we write p(x) where reference to the random variable X is implied.
Poisson Distribution Let X be a discrete random variable taking values
0, 1, 2, 3, . . .. If its p.m.f. is given by
p(x) = P(X = x) = exp(−λ)λx
x! ,
x = 0, 1, 2, . . . .
then X is said to follow the Poisson distribution, written X ∼Pois(λ), for λ > 0.
The mean and the variance of X is
E(X) = Var(X) = λ.
Figure 2.1 shows the p.m.f. of the Poisson distribution, for λ = 2.
0
2
4
6
8
10
0.00
0.05
0.10
0.15
0.20
0.25
p.m.f. of the Poisson distribution
x
p(x)
Fig. 2.1 Probability mass function of the Poisson distribution

38
2
Matrix Algebra, Probability and Statistics
Binomial Distribution The random variable X with p.m.f.
p(x) = P(X = x) =
n
x
	
πx(1 −π)n−x,
x = 0, 1, 2, . . . , n
is said to follow the binomial distribution of size n and probability π; we write
X ∼Binom(n, π). The binomial coefﬁcient is deﬁned by
n
x
	
=
n!
x!(n −x)!.
The distribution is generated as the probability of the sum of n independent trials,
each following the Bernoulli distribution with p.m.f. πx(1 −π)1−x, where x = 0, 1
(here P(X = 0) = π and P(X = 1) = 1 −π).
The mean and variance of the binomial distribution are
E(X) = nπ
and
Var(X) = nπ(1 −π).
Figure 2.2 shows the p.m.f. of the binomial distribution, for n = 10 and π = 0.6.
0
2
4
6
8
10
0.00
0.05
0.10
0.15
0.20
0.25
p.m.f. of the binomial distribution
x
p(x)
Fig. 2.2 Probability mass function of the binomial distribution

2.3
Probability and Distribution Theory
39
Negative Binomial Distribution The negative binomial distribution is generated
as the distribution of the number of successes in independent Bernoulli trials before
a ﬁxed number of failures λ occur. More speciﬁcally, X is said to follow the negative
binomial distribution, if its p.m.f. is
p(x) = P(X = x) =
x + λ −1
x
	
(1 −π)λπx,
x = 0, 1, 2, 3, . . .,
where π is the probability of success of each Bernoulli trial. We shall write
X ∼NegBinom(λ, π) to indicate that X follows the negative binomial distribution
with number of failures λ and probability of success π. More generally the negative
binomial p.m.f. p(x) is deﬁned for real-valued λ > 0, although in this case the
above genesis of the distribution does not apply.
The mean and variance of X are
E(X) =
πλ
1 −π
and
Var(X) =
πλ
(1 −π)2 .
We observe that
Var(X) = E(X)
1 −π > E(X),
and so the negative binomial distribution is suitable for describing over-dispersed
data, i.e. data which variance is larger than its mean.
Figure 2.3 shows the p.m.f. of the negative binomial distribution, with π = 0.6
and λ = 8.
Multinomial Distribution The multinomial is a generalisation of the binomial
distribution to accommodate for several (more than two) categories. Suppose that
we have k ≥2 categories and in each category i we have a ﬁxed probability of
success πi, with π1+π2+· · ·+πk = 1. Let n be the total number of trials or counts
and let Xi be the random variable that records the number of success in category i,
for i = 1, 2, . . ., k and X1 + X2 + · · · + Xk = n. With these deﬁnitions the random
vector X = [X1, X2, . . . , Xk]⊤is said to follow the multinomial distribution, if its
joint p.m.f. is given by
p(x) = P(X1 = x1, X2 = x2, . . . , Xk = xk) =
n!
x1!x2! · · · xk!πx1
1 πx2
2 · · · πxk
k .
By means of notation we use X ∼Multin(n, π), where π = [π1, π2, . . . , πk]⊤.
We observe that if k = 2 this distribution is reduced to the binomial distribution,
since X1+X2 = n or X2 = n−X1 and π1+π2 = 1 or π2 = 1−π1. We note that X
is only random in k −1 variables, because we can always write Xk = n −k−1
i=1 Xi

40
2
Matrix Algebra, Probability and Statistics
0
2
4
6
8
10
0.02
0.04
0.06
0.08
0.10
0.12
0.14
p.m.f. of the negative binomial distribution
x
p(x)
Fig. 2.3 Probability mass function of the negative binomial distribution
and πk = 1 −k−1
i=1 πi (e.g. in the binomial distribution k = 2 there is one random
variable X1.
The mean vector and the covariance matrix of X are
E(X) = n
⎡
⎢⎢⎢⎣
π1
π2
...
πk
⎤
⎥⎥⎥⎦
and
Var(X) = n
⎡
⎢⎢⎢⎣
π1(1 −π1)
−π1π2
· · ·
−π1πk
−π1π2
π2(1 −π2) · · ·
−π2πk
...
...
...
...
−π1πk
−π2πk
· · · πk(1 −πk)
⎤
⎥⎥⎥⎦.

2.3
Probability and Distribution Theory
41
2.3.3
Common Continuous Distributions
In this subsection we discuss the main continuous distributions, namely Gaussian
or normal, gamma and inverse gamma, beta, continuous uniform and the Student
t distributions. Most of Chaps. 3 and 4 make use of the multivariate Gaussian
distribution (Sect. 2.4.3 includes an example on Bayesian regression using the
Gaussian distribution); the gamma and Student t distributions are discussed in
Sect. 4.3.3.
Gaussian or Normal Distribution First we discuss the univariate version of the
Gaussian distribution. Let X be a continuous random variable. If its p.d.f. is
p(x) =
1
√
2πσ
exp

−(x −μ)2
2σ 2

,
x ∈R,
where σ 2 > 0, then X is said to follow the Gaussian distribution with mean μ and
variance σ 2; we write X ∼N(μ, σ 2).
Figure 2.4 shows the p.d.f. and the c.d.f. of the Gaussian distribution with μ = 0
and σ 2 = 1, i.e. X ∼N(0, 1).
Moving on to the multivariate Gaussian distribution, let X = [X1, . . . , Xp]⊤
denote a random vector. X is said to follow the multivariate Gaussian or normal
distribution, with notation X ∼N(μ, V), if its p.d.f. is given by
p(x) =
1
(2π)p/2|V|1/2 exp

−1
2(x −μ)⊤V−1(x −μ)

,
x ∈Rp,
where μ = [μ1, μ2, . . . , μp]⊤is the mean vector of X and V is the covariance
matrix of X. We note that if p = 1, this is reduced to the above univariate Gaussian
distribution with V = σ 2.
Figure 2.5 shows the p.d.f. p(x, y) of the Gaussian distribution above with x1 =
x, x2 = y,
μ =

0
0

and
V =

 1 0.8
0.8 1

.
Gamma Distribution The positive random variable X > 0 is said to follow the
gamma distribution with parameters α, β > 0, if its p.d.f. is given by
p(x) =
βα
(α)xα−1 exp(−βx),
x > 0,

42
2
Matrix Algebra, Probability and Statistics
-3
-2
-1
0
1
2
3
0.0
0.1
0.2
0.3
0.4
p.d.f. of N(0,1)
x
p(x)
-3
-2
-1
0
1
2
3
0.0
0.2
0.4
0.6
0.8
1.0
c.d.f. of N(0,1)
x
F(x)
Fig. 2.4 Probability density function and cumulative distribution function of a normal distribution
N(0, 1)
where (α) denotes the gamma function of argument α deﬁned by
(α) =
" ∞
0
uα−1 exp(−u) du.
If α = ν/2 and β = 1/2, the distribution is known as the chi-square distribution
with ν degrees of freedom, where ν is a positive real number.
The mean and the variance of X are
E(X) = α
β
and
Var(X) = α
β2 .
Figure 2.6 shows the p.d.f.’s of three gamma distributions, namely G(1, 1),
G(2, 1) and G(5, 1).

2.3
Probability and Distribution Theory
43
x
-3
-2
-1
0
1
2
3
y
-3
-2
-1
0
1
2
3
p(x,y)
0.00
0.05
0.10
0.15
0.20
0.25
p.d.f. of the bivariate normal distribution
Fig. 2.5 Probability density function of the bivariate normal distribution
Closely related to the gamma distribution is the inverse gamma distribution. Let
X ∼G(α, β), then the random variable Y = 1/X is said to follow the inverse
gamma distribution, with p.d.f.
p(y) =
βα
(α)
1
yα+1 exp

−β
y
	
,
y > 0.
We shall write that Y ∼IG(α, β).
The mean and the variance of Y is
E(Y) =
β
α −1,
for α > 1 and
Var(Y) =
β2
(α −1)2(α −2),
for α > 2.

44
2
Matrix Algebra, Probability and Statistics
0
2
4
6
8
10
0.0
0.2
0.4
0.6
0.8
p.d.f. of the gamma distribution
x
G(1,1)
G(2,1)
G(5,1)
p(x)
Fig. 2.6 Probability density function of the gamma distribution
Beta Distribution The random variable 0 ≤X ≤1 is said to follow the beta
distribution, if its p.d.f. is given by
p(x) = (α + β)
(α)(β)xα−1(1 −x)β−1,
0 ≤x ≤1,
where α, β > 0. By means of notation we write X ∼Beta(α, β).
The mean and the variance of X are
E(X) =
α
α + β
and
Var(X) =
αβ
(α + β)2(α + β + 1).
Figure 2.7 shows the p.d.f.’s of three beta distributions, namely Beta(0.5, 0.5),
Beta(2, 2.5) and Beta(5, 1).
Uniform Distribution The random variable X follows the continuous uniform
distribution, if its p.d.f. is given by
p(x) =

1
b−a ,
a ≤x ≤b
0,
otherwise

2.3
Probability and Distribution Theory
45
0.0
0.2
0.4
0.6
0.8
1.0
0
1
2
3
4
p.d.f. of the beta distribution
x
p(x)
Beta(0.5,0.5)
Beta(2,2.5)
Beta(5,1)
Fig. 2.7 Probability density function of the beta distribution
for any a < b. We will use the notation X ∼U(a, b) to indicate that X follows the
uniform distribution with parameters a and b.
The mean of X is
E(X) = a + b
2
,
and the variance of X is
Var(X) = (b −a)2
12
.
Figure 2.8 shows the p.d.f. of U(−1, 1).
Student t Distribution We start with the univariate case. The random variable X
is said to follow the Student t distribution, if its p.d.f. is
p(x) =
νν/2

ν+1
2

√π
 ν
2

σ

ν + (x −μ)2
σ 2
−(ν+1)/2
,
x ∈R,

46
2
Matrix Algebra, Probability and Statistics
-2
-1
0
1
2
0.0
0.2
0.4
0.6
0.8
1.0
p.d.f. of uniform U(-1,1)
x
p(x)
Fig. 2.8 Probability density function of the uniform distribution
where ν > 0, μ and σ 2 > 0 are the parameters of the distribution. By means of
notation we write X ∼t(ν, μ, σ 2). The parameter ν > 0 is known as the degrees of
freedom.
The mean of X is
E(X) = μ,
for ν > 1 and the variance of X is
Var(X) = νσ 2
ν −2,
for ν > 2. If 0 < ν ≤2 the variance is not deﬁned; an example of a distribution with
undeﬁned mean and variance is the Cauchy distribution, obtained as the Student t
distribution for ν = 1.
Figure 2.9 shows the p.d.f. of Student t distribution with 3 and 10 degrees of
freedom as compared with a Gaussian N(0, 1) distribution. We observe that the
Student t distribution has heaver tails than the Gaussian and that the smaller the
degrees of freedom the heavier the tails are. In fact we can see that as ν →∞, the

2.3
Probability and Distribution Theory
47
-3
-2
-1
0
1
2
3
0.0
0.1
0.2
0.3
0.4
p.d.f. of the Student t distribution
x
p(x)
N(0,1)
t(3,0,1)
t(10,0,1)
Fig. 2.9 Probability density function of the Student t distribution
p.d.f. of the Student t distribution converges to that of a Gaussian distribution (see
Exercise 2.10).
Now consider a random vector X = [X1, X2, . . . , Xp]⊤. X is said to follow the
multivariate Student t distribution with ν > 0 degrees of freedom, mode or location
vector μ and scale covariance matrix V, if its density is
p(x) =
νν/2
 ν+p
2

πp/2
 ν
2

|V|1/2
%
ν + (x −μ)⊤V−1(x −μ)
&−(ν+p)/2
.
In terms of notation we write X ∼t(ν, μ, V).
The mean vector of X is
E(X) = μ,
for ν > 1 and the covariance matrix of X is
Var(X) =
ν
ν −2V,
for ν > 2.

48
2
Matrix Algebra, Probability and Statistics
We observe that for p = 1 and V = σ 2, we obtain the univariate Student t
distribution, with p.d.f. given above.
As in the univariate case, the multivariate Student t distribution has heavier tails
than the multivariate Gaussian distribution N(μ, V), controlled by the degrees of
freedom ν (the smaller ν the heavier the tails). As ν →∞the Student t p.d.f.
converges to the p.d.f. of the normal N(μ, V).
2.4
Statistics
2.4.1
Principle Set-Up and Objectives
Statistics is concerned with quantifying and managing uncertainty in observational
studies, may these be controlled experiments, or socio-economic or physical
phenomena. With observational study broadly we mean studies based on observed
outcomes, which are uncertain. A good introductory treatment of Statistics can be
found in Trosset (2009).
Uncertainty arises in all walks of life. In climate change, for example, the
potential increase of the global temperature is hugely uncertain, as is the extent
to this increase attributed to human-made actions. In a physical system the output
signal may be uncertain due to measurement error and in economics ﬂuctuations of
asset prices are uncertain due to market and investors’ movements.
Considering a vector x = [x1, x2, . . . , xn]⊤of n observed or recorded mea-
surements we can postulate that uncertainty around the values of x is generated
by x being a particular realisation of a random vector X = [X1, X2, . . . , Xn]⊤.
Thus, it is natural to think that the probability distribution of X will summarise the
uncertainty around x and thus it may be used to describe the generating process of
x and to forecast future values of x. This distribution will typically depend upon
some parameter vector θ, which is responsible for the shape of the distribution of
X. We write p(x | θ) to indicate the p.d.f. of X (if X is continuous) or the p.m.f.
of X (if X is discrete). Statistical inference is concerned about estimating θ, based
on the observed data x1, x2, . . . , xn and hence provide forecasts of future values of
x, based on this observed data. Within the above model-based framework two main
estimation approaches may be deployed
1. Maximum likelihood inference (frequentist statistics); and
2. Posterior inference (Bayesian statistics).
In (1) we consider that θ is a ﬁxed, but known quantity and estimation procedures
largely involve maximum likelihood analysis, see e.g. Sect. 2.4.2 below. In (2)
θ is assumed to be random and estimation procedures involve the derivation of
the conditional distribution of θ, given the data x; Sect. 2.4.3 discusses Bayesian
inference and gives two examples for illustration purposes.

2.4
Statistics
49
2.4.2
Maximum Likelihood Estimation: The EM Algorithm
The likelihood function has a central role on the development of estimators in
statistical inference. The likelihood function, a function of the unknown param-
eter or parameter vector θ, is just the joint distribution of the random sample
X1, X2, . . . , Xn, given θ, i.e.
L(θ; x) = p(x1, x2, . . . , xn | θ),
where x = [x1, x2, . . . , xn]⊤. The likelihood function is a (deterministic) function
of θ, which gives a measure of how likely is θ for a given sample x1, x2, . . . , xn. If
θ is not very likely then L(θ; x) should be small, while if it is likely the value of
L(θ; x) should be large. Thus, say for two values θ1 and θ2 of θ the inequality
L(θ1; x) > L(θ2; x)
will favour θ1 as being more likely than θ2, for this sample. This naturally leads us
to choose the value θ that maximises the likelihood function, hence the maximum
likelihood principle. Usually, for computational efﬁciency, we choose to maximise
the logarithm of the likelihood, known as log-likelihood function, written as
ℓ(θ; x) = log L(θ; x).
In many situations it is hard to ﬁnd the maximum of the likelihood function.
The expectation maximisation (EM) algorithm, originally developed in Dempster
et al. (1977) and further discussed in many textbooks, see e.g. Fahrmeir and Tutz
(2001), is a popular choice of an indirect maximisation algorithm of the likelihood
L(θ; x). The EM algorithm is an iterative algorithm, which consists of two steps:
in the E-step the conditional expectation of the log-likelihood function is computed,
given the past sample values and the current estimate of θ, and in the M-step a new
estimate of θ is computed that maximises the expected log-likelihood function from
the E-step. Below we provide description and the foundations of the EM algorithm,
which is then used in Sect. 4.3.1 to derive the EM algorithm for state space models.
Our aim is to maximise L(θ; x) with respect to θ. Consider an unobserved
discrete random vector Z and denote with Rz the domain of the p.m.f. of Z. We
can express L(θ; x) in terms of Z as
L(θ; x) = p(x | θ) =

z∈Rz
p(x, z | θ).

50
2
Matrix Algebra, Probability and Statistics
Notice that this is the marginal distribution of X, after we sum out Z. Then the EM
algorithm is
1. Initialise ˆθ(0);
2. E-step: calculate the conditional expectation
Q(θ | ˆθ(k)) = E[log L(θ; x, z) | x, ˆθ(k)];
3. M-step: ﬁnd the maximum
ˆθ(k+1) = arg max
θ
Q(θ | ˆθ(k));
4. Update k →k + 1 and repeat steps (2)-(3) until convergence (see below).
As k →∞, ˆθ(k) converges to the maximum likelihood estimate ˆθ of L(θ; x). In
practice the algorithm terminates when ˆθ(k+1) and ˆθ(k) are close to each other, hence
convergence is assumed. The rule to check for convergence is if the Euclidean norm
of ˆθ(k+1) −ˆθ(k) is smaller to a pre speciﬁed tolerance, i.e.
∥ˆθ(k+1) −ˆθ(k) ∥< Tol.
Usually we set Tol = 0.001 or smaller.
Before we prove the correctness of the algorithm we give the Gibbs inequality.
For any two discrete distributions with p.m.f.’s p(x) and q(x), respectively, we have

x∈Rx
p(x) log p(x) ≥

x∈Rx
p(x) log q(x),
(2.18)
with equality if and only if p(x) = q(x), for all x ∈Rx, where Rx is the domain of
p(x).
To prove this we use the well known inequality log x ≤x −1, for any x > 0.

x∈Rx
p(x) log q(x)
p(x) ≤

x∈Rx
p(x)

 q(x)
p(x) −1

=

x∈Rx
q(x) −

x∈Rx
p(x)
=

x∈Rx
q(x) −1 ≤0
and so 
x∈Rx p(x) log p(x) ≥
x∈Rx p(x) log q(x).

2.4
Statistics
51
Now we prove the correctness of the EM algorithm. From the deﬁnition of the
joint distribution p(x, z | θ) = p(z | x, θ)p(x | θ) we have
p(x | θ) = p(x, z | θ)
p(z | x, θ)
and so
log p(x | θ) = log p(x, z | θ) −log p(z | x, θ)
=

z∈Rz
p(z | x, ˆθ(k)) log p(x, z | θ)



expectation of
logp(x,z|θ)
−

z∈Rz
p(z | x, ˆθ(k)) log p(z | x, θ)



expectation of
logp(z|x,θ)
= Q(θ | ˆθ(k)) + G(θ | ˆθ(k)).
Then
log p(x | θ) −log p(x | ˆθ(k)) = Q(θ | ˆθ(k)) −Q( ˆθ(k) | ˆθ(k))
+G(θ | ˆθ(k)) −G( ˆθ(k) | ˆθ(k)).
Now applying the Gibbs inequality (2.18) with p(x) = p(z | x, ˆθ(k)) and q(x) =
p(z | x, θ), we obtain
G(θ | ˆθ(k)) ≥G( ˆθ(k) | ˆθ(k)).
Hence
log p(x | θ) −log p(x | ˆθ(k)) ≥Q(θ | ˆθ(k)) −Q( ˆθ(k) | ˆθ(k)).
From this inequality, an improvement in Q (Q(θ | ˆθ(k)) ≥Q( ˆθ(k) | ˆθ(k))) results in
an improvement in L(θ; x) = log p(x | θ) (log p(x | θ) ≥p(x | ˆθ(k))).
As we obtain in the next iteration ˆθ(k+1 as the maximum of Q(θ | ˆθ(k)), an
improvement in L(θ; x) is achieved. As a result, as k →∞, ˆθ(k) converges to the
maximum likelihood estimate ˆθ.
2.4.3
Bayesian Inference
Bayesian statistics has been developed extensively over the past three decades, in
particular the advance of computationally intensive estimation methods have made
the Bayesian paradigm a very attractive estimation approach. Excellent expositions
of Bayesian methods can be found in O’Hagan and Forster (2004), Leonard and Hsu
(1999), Gamerman and Lopes (2006) and Robert (2007), among others.

52
2
Matrix Algebra, Probability and Statistics
In Bayesian inference unknown parameters are assumed to form a random
vector θ. The distribution p(θ) of θ prior to observing data is known as the prior
distribution of θ and reﬂects the prior belief we may have before observing the
data. Apart from this prior belief, we are going to adopt the model formulation
of Sect. 2.4.1, i.e. that the data generating process is described by the distribution
p(x | θ). In other words the conditional distribution p(x | θ) is a model statement
which asserts that if we know the parameter vector θ, then we know the distribution
of the data p(x | θ) = p(x1, . . . , xn | θ). In our notation, p(x | θ) = L(θ; x) is just
the likelihood function of θ. The principle building block in Bayesian inference is
the Bayes theorem, which states that the conditional distribution of θ given the data
x is given by
p(θ | x) = p(x | θ)p(θ)
p(x)
,
or simply
p(θ | x) ∝L(θ; x)p(θ),
(2.19)
where 1/p(x) is known as the proportionality constant. The term p(θ | x) is the
posterior distribution of θ, because it is the distribution of θ after (a posteriori)
the data x is observed. Sometimes p(θ | x) is referred to as the updated belief
or posterior belief and the likelihood L(θ; x) referred to as the evidence the data
provides. The marginal distribution p(x) of X is the forecast distribution of X, i.e.
p(x) =
"

p(x, θ) dθ =
"

p(x | θ)p(θ) dθ,
where  is the domain of θ (if X is discrete the integral above is replaced by
a relevant sum). In many situations the computation of p(x) is not available in
closed form, since integration of high dimensional integrals becomes very quickly
intractable. In such cases simulation-based inference is usually adopted, in particular
sequential Monte Carlo and Markov chain Monte Carlo methods; the former
is discussed in this book in Sect. 6.7 and the latter is discussed in Sect. 5.7
(introduction to MCMC and Gibbs sampling) and in Sect. 6.8 (Metropolis-Hastings
algorithm). Book-length treatment of MCMC methods can be found in Gamerman
and Lopes (2006) and Robert (2007). Below two examples are provided to illustrate
the utility and application of Bayesian analysis.
Example 2.1 (Bayesian Regression) Consider the linear model
yi = x⊤
i β + ϵi,
where yi denotes a scaler response variable, xi is a p-dimensional vector containing
p covariates or explanatory variables and ϵi denotes an i.i.d. random variable,
usually assumed to follow the normal distribution N(0, σ 2), for some variance

2.4
Statistics
53
σ 2 and for i = 1, . . . , n. This model is revisited in Sect. 3.1, where regression
is discussed from a least squares and maximum likelihood standpoints. A detailed
discussion of Bayesian analysis for the linear model is given in Press (1989, Chapter
5) and in O’Hagan and Forster (2004, Chapter 11). This model is usually cast in
matrix form as
y = Xβ + ϵ,
where y = [y1, y2, . . . , yn]⊤, ϵ = [ϵ1, ϵ2, . . . , ϵn]⊤and
X =
⎡
⎢⎢⎢⎣
x⊤
1
x⊤
2...
x⊤
n
⎤
⎥⎥⎥⎦.
Thus, conditionally on β, y follows a normal distribution
y | β ∼N(Xβ, σ 2I).
(2.20)
Let us consider that the prior distribution of β is normal, given by
β ∼N( ˜β, R),
(2.21)
where the prior expectation ˜β and the prior covariance matrix R of β are assumed
known.
From (2.20) and (2.21) by applying Bayes theorem (2.19) the posterior distribu-
tion of β is
p(β | y) ∝p(y | β)p(β)
∝exp
(
−1
2
%
(y −Xβ)⊤(y −Xβ)/σ 2 + (β −˜β)⊤R−1(β −˜β)
&)
∝exp

−1
2(β −ˆβ)⊤P−1(β −ˆβ)

,
where
ˆβ = P(X⊤y/σ 2 + R−1 ˜β)
and
P−1 = R−1 + X⊤X/σ 2.
(2.22)
Hence the posterior distribution of β is β | y ∼N( ˆβ, P). Therefore, credible
intervals and other a posteriori features can be extracted from this distribution.
We note that if R−1 = 0, then P = σ 2(X⊤X)−1 (assuming that X is of full
rank p) and so the posterior mean of β is equal to ˆβ = (X⊤X)−1X⊤y, which is the
least squares and maximum likelihood estimates of β; see the relevant discussion in

54
2
Matrix Algebra, Probability and Statistics
Sect. 3.1. In this case (R−1 = 0) the elements of R converge to inﬁnity and prior
(2.21) is an improper uniform distribution; for a related discussion see O’Hagan
and Forster (2004, Chapter 11). In practice we may set a large covariance matrix,
say R = 1000I, so that R−1 ≈0. This is known as weakly informative prior
speciﬁcation and is discussed in Sect. 4.5 and in O’Hagan and Forster (2004) and
Robert (2007).
By writing R−1 = P−1 −X⊤X/σ 2 from (2.22) and substituting it in ˆβ we obtain
ˆβ = ˜β + PX⊤
σ 2 (y −X ˜β),
(2.23)
or in words that the posterior mean ˆβ of β is equal to the prior mean ˜β plus a gain
factor K = PX⊤/σ 2 times the residual e = y −X ˜β. Here X ˜β is the prediction of
y (hence their difference is the residual e). Equation (2.23) is important, as we will
see in Sect. 3.2 it is generalised to provide the celebrated Kalman ﬁlter within the
context of state space and time series modelling.
Example 2.2 (Beta-Binomial Model) Consider that θ = π denotes a probability of
success of independent trails, such that
X | π ∼Binom(n, π)
follows a binomial distribution with probability of success π and size n. Suppose
that a prior distribution for π is the beta distribution
π ∼Beta(2, 3).
By applying Bayes rule (2.19) we have that the posterior distribution of π given
X = x is proportional to
p(π | X = x) ∝p(x | π)p(π)
∝πx+2−1(1 −π)n+3−x−1,
which is proportional to a beta distribution with parameters x +2 and n+3 −x, i.e.
π | X = x ∼Beta(x + 2, n + 3 −x).
For example, if n = 5 and x is observed to be equal to 4, then
E(π | X = 4) = 6
10.
In this case we observe that the posterior mean of π is larger than the prior mean of
π, which is E(π) = 2/5.

2.5
Exercises
55
The forecast distribution of X can be computed as
p(x) =
" 1
0
p(x | π)p(π) dπ
=
(5)
(2)(3)
n
x
	 " 1
0
πx+2−1(1 −π)n+3−x−1 dπ
= 10
n
x
	(x + 2)(n + 3 −x)
(n + 5)
= 10(x + 1)(x + 2)(n −x + 1)(n −x + 2)(n −x + 3)
(n + 1)(n + 2)(n + 3)(n + 3)(n + 4)(n + 5)
,
where we have used (x) = x(x −1) = x!, for x integer. Also from the posterior
beta distribution π | X = x ∼Beta(x + 2, n + +3 −x), with
* 1
0 p(π | x) dπ = 1
or
" 1
0
(x + 2 + n + 3 −x)
(x + 2)(n + 3 −x)πx+2−1(1 −π)n+3−x−1 dπ = 1,
it follows that
" 1
0
πx+2−1(1 −π)n+3−x−1 dπ = (x + 2)(n + 3 −x)
(n + 5)
.
As it is evident, in this example, it is harder to compute p(x) than it is to compute
the posterior p(π | x). The above two examples illustrate the use of conjugate prior
distributions, having the property that the posterior distribution has the same form
as the prior, only differing on their respective parameters (e.g. in Example 2.1 both
the prior and the posterior of β are normal distributions and in Example 2.2 both
the prior and the posterior are beta distributions). The conjugate prior distributions
have been criticised as being limited, see e.g. Robert (2007, Chapter 3), but they are
certainly a worthy consideration in recursive estimation of time series, because they
facilitate a sequential prior to posterior updating over time.
2.5
Exercises
1. Show that for any non-singular n × n matrices A and B the following is true
(A + B)−1 = B−1(A−1 + B−1)−1A−1.
2. If I is the n × n identity matrix, show that trace(cI) = cn. Hence show that
trace(0) = 0.

56
2
Matrix Algebra, Probability and Statistics
3. Show that trace(ABC) = trace(CAB) = trace(BCA).
4. Let X be a symmetric matrix of variables. Evaluate the partial derivatives
∂trace(AXkB)
∂X
,
∂log |AXkB|
∂X
and
∂trace(AX−1B)
∂X
,
where k is a positive integer and A, B are any matrices with constants.
5. For a n × n matrix A and for any non-zero n-dimensional vector x show that
∥A ∥= |x⊤Ax|,
is a matrix norm, where | · | denotes modulus.
If limk→∞Ak = 0, use the above formula to show
∞

k=0
Ak = (I −A)−1.
6. The random variable X follows the geometric distribution, if its p.m.f. is
p(x) = P(X = x) = (1 −π)xπ,
x = 0, 1, 2, . . .
This distribution is generated as the number of failures until the ﬁrst success in
independent Bernoulli trials each having probability of success π.
Show that, for integer x, the c.d.f. of X is
F(x) = 1 −(1 −π)x+1.
Show that the expectation and the variance of X are
E(X) = 1 −π
π
and
Var(X) = 1 −π
π2
.
Hint: for E(X): differentiate both sides of
∞

x=0
(1 −π)xπ = 1,
with respect to π. A similar argument can be applied for the variance.
7. For any n, x > 0 show
(n + x)
x!(n)
=
n + x −1
x
	
.

2.5
Exercises
57
8. Let X be a random variable that follows the negative binomial distribution X ∼
NegBinom(λ, π), for some known λ > 0 and probability π. Show that
λ + x −1
x
	
=
x + λ −1
λ −1
	
hence the p.m.f. of X can be written as
p(x) = P(X = x) =
λ + x −1
x
	
(1 −π)λπx,
x = 0, 1, 2, . . .
9. The random variable X follows the Laplace distribution, if its p.d.f. is given by
p(x) = 1
2b exp

−|x −μ|
b
	
,
x ∈R,
where μ is a location parameter and b > 0 is a scale parameter. Show that the
c.d.f. of X is
F(x) =

1
2 exp
 x−μ
b

,
x < μ
1 −1
2 exp

−x−μ
b

,
x ≥μ
10. The random variable X follows the Pareto distribution with shape α > 0 and
scale β > 0, if its p.d.f. is
p(x) =
 αβα
xα+1 ,
x ≥β
0,
x < β
Show that the c.d.f. of X is
F(x) =
⎧
⎨
⎩
1 −

β
x
α
,
x ≥β
0,
x < β
Show that the expectation of X is
E(X) =

∞,
α ≤1
αβ
α−1,
α > 1
11. Let p(x) be the p.d.f. of the normal distribution N(0, 1) and qν(x) be the p.d.f.
of the Student t distribution with ν degrees of freedom t(ν, 0, 1). Using the
limit
lim
n→∞
(n + α)
(n)nα
= 1,

58
2
Matrix Algebra, Probability and Statistics
for any α > 0, show that
lim
ν→∞qν(x) = p(x),
i.e. the Student t p.d.f. converges to the N(0, 1) p.d.f. as ν →∞.
Hint: Make use of the well known limit
lim
n→∞

1 + α
n
n
= exp(α),
for any α ∈R.
12. Let X and Y be any continuous random vectors. Show
Cov(X, Y) = E(XY ⊤) −E(X)E(Y)⊤.
13. Let X, Y and Z be any continuous random vectors. Show
Cov(X, Y) = E[Cov(X, Y | Z)] + Cov[E(X | Z), E(Y | Z)].
14. Suppose that the random variables X and Y follow a joint Gaussian distribution

X
Y

∼N

 μx
μy

,
 
σ 2
x σxy
σxy σ 2
y
!+
,
where μx is the expectation of X, μy is the expectation of Y, σ 2
x is the variance
of X, σ 2
y is the variance of Y and σxy is the covariance of X and Y.
Show that the joint p.d.f. of X and Y can be written as
pXY (x, y) =
1
2πσxσy
'
1 −ρ2
× exp
 
−
σ 2
y (x −μx)2 −2ρσxσy(x −μx)(y −μy) + σ 2
x (y −μy)2
2σ 2x σ 2y (1 −ρ2)
!
.
Show that the marginal distributions of X and Y are
X ∼N(μx, σ 2)
and
Y ∼N(μx, σ 2).
Show that if X and Y are independent random variables, then Cov(X, Y) = 0.
The converse claim is not generally true. However, if X, Y are jointly normally
distributed, then this is true. Prove this claim, i.e. if the joint distribution of
X, Y is Gaussian as above, then Cov(X, Y) = 0 implies that X and Y are
independent.

2.5
Exercises
59
15. Suppose that the random vector X = [X1, X2, . . . , Xk]⊤follows the multi-
nomial distribution with size n = k
i=1 Xi and probability vector π
=
[π1, π2, . . . , πk]⊤, i.e.
X ∼Multin(n, π).
Show that the marginal distribution of X1 is the binomial distribution
X1 ∼Binom(n, π1)
and the conditional distribution of the random vector [X2, . . . , Xk]⊤, given
X1 = x1 is
[X2, . . . , Xk]⊤| X1 = x1 ∼Multin

n −x1,

p2
1 −p1
, . . . ,
pk
1 −p1
⊤
.
16. Three random variables have joint p.d.f.
pXYZ(x, y, z) =
 c
xy exp(−yz),
1 < x, y < 2,
z > 0
0,
otherwise
a. Show that the constant c is c =
2
log 2.
b. Find the marginal joint p.d.f. of [X, Y]⊤, and the marginal p.d.f.’s of X and
Y.
Show that X and Y are independent, but X, Y and Z are not independent.
c. Calculate the mean and variance of X and Y. Also calculate the mean vector
of W = [X, Y]⊤and the covariance matrix of W.
d. For 1 < x, y < 2, ﬁnd the joint distribution function FXY (x, y) of [X, Y]⊤
and calculate the probability P(X ≤3/2, Y ≤4/3).
17. Consider an independent random sample X1, X2, . . . , Xn, where Xi is gener-
ated from a Poisson distribution, with rate λ, i.e. Xi ∼Pois(λ). Show that the
maximum likelihood estimate of λ is
ˆλ = 1
n
n

i=1
xi,
where x1, x2, . . . , xn are the observed values of X1, X2, . . . , Xn.
18. Consider an independent random sample X1, X2, . . . , Xn, where Xi is gener-
ated from the binomial distribution Xi ∼Binom(m, π), for some m. Show that

60
2
Matrix Algebra, Probability and Statistics
the maximum likelihood estimate of π is
ˆπ =
1
mn
n

i=1
xi,
where x1, x2, . . . , xn are the observed values of X1, X2, . . . , Xn.
19. Consider an independent random sample X1, X2, . . . , Xn, where Xi is gener-
ated from the geometric distribution with probability of success π (see Exercise
2.7). Show that the maximum likelihood estimate of π is
ˆθ =
n
n + n
i=1 xi
,
where x1, x2, . . . , xn are the observed values of X1, X2, . . . , Xn.
20. Consider an independent random sample X1, X2, . . . , Xn, where Xi is gener-
ated from the inverse Gaussian distribution, with p.d.f.
pXi(xi) =
,
θ
2πx3
i
exp

−θ(xi −μ)2
2μ2xi
	
,
xi > 0,
μ, θ > 0.
Assuming that μ is known, show that the maximum likelihood estimate of θ is
ˆθ =
nμ2
n
i=1(xi −μ)2x−1
i
,
where x1, x2, . . . , xn are the observed values of X1, X2, . . . , Xn.
21. The distribution of data X, given parameter λ > 0, is Poisson
X | λ ∼Pois(λ).
If, for some α and β, the prior of λ is gamma
λ ∼G(α, β),
then
a. show that the posterior distribution of λ is gamma, i.e.
λ | X = x ∼G(α + x, β + 1),
where x is the observed value of X;
b. show that the forecast distribution of X is negative binomial
X ∼NegBinom

α,
1
β + 1
	
.

2.5
Exercises
61
22. Suppose that, given probability of success π, the distribution of data X is the
geometric distribution of Exercise 2.7. If the prior of π is beta
π ∼Beta(α, β),
for some α and β, then
a. show that the posterior distribution of π is beta
π | X = x ∼Beta(α + 1, β + x),
where x is the observed value of X;
b. show that the forecast distribution of X is
p(x) =
αβ(β + 1) · · · (β + x)
(α + β)(α + β + 1) · · · (α + β + x + 1).
23. Given λ > 0, the data X follows the exponential distribution with p.d.f.
p(x | λ) =

λ exp(−λx),
x ≥0
0,
x < 0
If the prior of λ is gamma
λ ∼G(α, β),
for some α and β, then
a. show that the posterior distribution of λ is gamma
λ | X = x ∼G(α + 1, β + x),
where x is the observed value of X;
b. show that the forecast distribution of X is
p(x) =

αβα
(β+x)α+1 ,
x ≥0
0,
x < 0

Chapter 3
The Kalman Filter
This chapter introduces the linear state space model and discusses ﬁltering,
smoothing and forecasting. Section 3.1 motivates the state space model as a natural
extension of the usual multiple regression model, which adopts ordinary least
squares and maximum likelihood estimation methods. In Sect. 3.1.1, we give a brief
review of these estimation methods, and for completeness purposes we provide the
full derivations. These derivations provide technical motivation for the following.
Section 3.1.2 discusses recursive estimation of regression with the emphasis placed
on local estimation, leading to recursive least squares. The deﬁnition of the state
space model follows in Sect. 3.1.3. Filtering is discussed in Sect. 3.2, where two
derivations of the Kalman ﬁlter are given. Smoothing and forecasting are discussed
in the next two sections, and the chapter concludes with coverage of observability
and the steady state of linear time-invariant state space models.
3.1
From Regression to the State Space Model
3.1.1
Ordinary Least Squares
In this section we brieﬂy describe regression methods for linear models, a detailed
account of which is given in Bingham and Fry (2010); see also Sect. 2.4.3. Suppose
that observations y1, y2, . . . , yn become available over time t = 1, 2, . . . , n, for
some positive integer n. In some situations, the time index t may represent a ﬁnite
discrete set {a1, . . . , an}, which is equivalent to {1, 2, . . ., n}, i.e. there is a one-
to-one mapping from elements of {a1, . . . , an} to {1, 2, . . ., n}. For example, ai
may represent years, or quarters, or any other, suitably deﬁned discrete objects
(not necessarily representing time). It is further assumed that {a1, . . . , an} is, at
least approximately, an equally spaced set, i.e. that at −at−1 is the same for all
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2021
K. Triantafyllopoulos, Bayesian Inference of State Space Models, Springer Texts
in Statistics, https://doi.org/10.1007/978-3-030-76124-0_3
63

64
3
The Kalman Filter
t = 2, 3, . . ., n. For convenience, in what follows we will work with a time index
{1, 2, . . ., n}, but the above discussion motivates the more general case.
In the context of regression, suppose that we have p variables (also indexed by
time), xit (i = 1, . . ., p), which form a column vector xt = (x1t, . . . , xpt)⊤, where
⊤denotes transposition. We wish to express a relationship between yt and xt, and
thus we form the linear regression model
yt = x1tβ1 + · · · + xptβp + ϵt = x⊤
t β + ϵt,
(3.1)
where β = (β1, . . . , βp)⊤denotes a p-variate vector of regression coefﬁcients and
ϵt is the error or innovation term of the above model, accounting for the distance
between yt and x⊤
t β. According to the Gauss–Markov conditions (Bingham &
Fry, 2010), {ϵt} is a sequence of independent random variables (ϵt is independent
of ϵs, for any t ̸= s) with zero mean and common variance σ 2; {ϵt} is referred
to as a white noise process, see e.g. Brockwell and Davis (1991), and we write
ϵt ∼WN(0, σ 2). The purpose of regression is to estimate β, based on a realised
collection of observations y1:n = {y1, . . . , yn}. This estimation can be carried out
in several equivalent ways (in Sect. 2.4.3, we describe the Bayesian estimation), but
the standard one is by minimising the sum of squares
S(β) =
n

t=1
(yt −x⊤
t β)2.
(3.2)
To facilitate the calculations, it is useful to write model (3.1) in matrix form as
y =
⎡
⎢⎢⎢⎣
y1
y2
...
yn
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
x⊤
1
x⊤
2...
x⊤
n
⎤
⎥⎥⎥⎦β +
⎡
⎢⎢⎢⎣
ϵ1
ϵ2
...
ϵn
⎤
⎥⎥⎥⎦= Xβ + ϵ.
Then, assuming that X is of full rank, the well known solution that minimises S(β)
gives the estimator of β as
ˆβ = (X⊤X)−1X⊤y =
 n

t=1
xtx⊤
t
−1
n

t=1
xtyt.
(3.3)
For completeness purposes, we give the proof next. We wish to minimise
S(β) = ϵ⊤ϵ = (y −Xβ)⊤(y −Xβ) = y⊤y −2β⊤X⊤y + β⊤X⊤Xβ.

3.1
From Regression to the State Space Model
65
Using (2.3) and (2.5), the ﬁrst partial derivative of S(β) with respect to β is
∂S(β)
∂β
= −2X⊤y + 2X⊤Xβ,
which for β = ˆβ satisﬁes the equation
∂S( ˆβ)
∂ˆβ
= 0 ⇒ˆβ = (X⊤X)−1X⊤y,
given that X is of full rank, so that the inverse of X⊤X exists.
Thus ˆβ is a stationary vector, and we can use Eq. (2.5) to verify that its second
partial derivative is a positive deﬁnite matrix, i.e.
∂2S(β)
∂β∂βT = 2X⊤X.
Thus, the sum of squares S(β) is minimised at ˆβ.
So far, no assumption has been made about the distribution of the sequence {ϵt}.
If one is prepared to accept that, additionally to the white noise assumption of {ϵt},
ϵt (t = 1, . . . , n) follows a normal distribution with zero mean and variance σ 2, i.e.
ϵt ∼N(0, σ 2), then the maximum likelihood estimation of β and σ 2 is available and
given as follows. From the model deﬁnition (3.1) and the white noise assumption
ϵt ∼N(0, σ 2), we can write down the distribution of yt given the parameters β and
σ 2 as
yt | β, σ 2 ∼N(x⊤
t β, σ 2).
Since {ϵt} is a white noise, it follows that, given β and σ 2, y1, . . . , yn are
independent.
The likelihood function of β and σ 2 is the joint distribution of y1, . . . , yn, given
these parameters, which by using the above two facts is
L(β, σ 2; y1:n) = p(y1, . . . , yn | β, σ 2)
=
n
-
t=1
p(yt | β, σ 2)
(from the independence of y1, . . . , yn)
=
n
-
t=1
1
√
2πσ
exp

−(yt −x⊤
t β)2
2σ 2

=
1
(2π)n/2σ n exp
 
−1
2σ 2
n

t=1
(yt −x⊤
t β)2
!
,

66
3
The Kalman Filter
and the log-likelihood function of β and σ 2 is
ℓ(β, σ 2; y1:n) = log L(β, σ 2; y1:n)
= −n log
√
2π −n
2 log σ 2 −
1
2σ 2
n

t=1
(yt −x⊤
t β)2.
(3.4)
In order to ﬁnd ˆβ and ˆσ 2 that maximise (3.4), ﬁrst we maximise it with respect to β
and then with respect to σ 2.
The partial ﬁrst derivative of ℓ(·) with respect to β is
∂ℓ(β, σ 2; y1:n)
∂β
= 1
σ 2
n

t=1
xt(yt −x⊤
t β),
from which by equating it to zero, we obtain ˆβ exactly as in (3.3).
For σ 2, we have
∂ℓ(β, σ 2; y1:n)
∂σ 2
= −n
2σ 2 +
1
2σ 4
n

t=1
(yt −x⊤
t β)2,
which after evaluating it at β = ˆβ, and solving the equation ∂ℓ( ˆβ, ˆσ 2; y1:n)/∂ˆσ 2 =
0, yields
ˆσ 2 = 1
n
n

t=1
(yt −x⊤
t ˆβ)2.
(3.5)
It is of some interest to express the estimator (3.5) in terms of X and y only. By
expanding (3.5) and recalling the deﬁnitions of y and X above, we can readily see
that
ˆσ 2 = n−1
 n

t=1
y2
t −
n

t=1
ytx⊤
t ˆβ −ˆβ⊤
n

t=1
xtyt + ˆβ⊤
n

t=1
xtx⊤
t ˆβ

= n−1(y⊤y −y⊤X ˆβ −ˆβX⊤y + ˆβ⊤X⊤X ˆβ)
= n−1y⊤(I −X(X⊤X)−1X⊤)y,
(3.6)
after using ˆβ = (X⊤X)−1X⊤y. We note that in the above maximum likelihood
estimators ˆσ 2, it is usual to replace n by n −p, which makes ˆσ 2 an unbiased
estimator.

3.1
From Regression to the State Space Model
67
The above notion of the estimation of β is known as ordinary least squares
(OLS), because all observations y1, . . . , yn have on average the same contribution
on ˆβ. This means that for large n, distant observations (such as y1 or y2) have the
same weight on ˆβ as the more recent observations (such as yn or yn−1). This is
usually not desirable when the data exhibit a time-dependence structure or when a
localised estimation of β is required. For example, considering share prices of the
stock market as yt, the estimate of the price of today is likely to depend more on the
related price of yesterday, but not as much on the price of last month. Thus, we wish
to put more weight at more recent observations in the estimation of ˆβ.
3.1.2
Recursive Least Squares
Motivated by the discussion above, we consider model (3.1), but here we replace
S(β) in (3.2) by the weighted or discounted sum of squares
S(β) =
n−1

j=0
δj(yn−j −x⊤
n−jβ)2,
(3.7)
where δ is a discount or forgetting factor (assumed known), satisfying 0 < δ ≤1,
and the weights δj have a discounting effect for j = 0, 1, . . .. First of all, we note
that δ = 1 returns the sum of squares of OLS above, but if δ < 1, the above sum
puts more weight to the observations yn, yn−1 and places less emphasis upon distant
observations. This can be seen if we expand the above sum as
S(β) = (yn −x⊤
n β)2 + δ(yn−1 −x⊤
n−1β)2 + · · · + δn−1(y1 −x⊤
1 β)2
and we note that δj ≈0, for sufﬁciently large j.
The memory of this model is deﬁned by the geometric series
n−1

j=0
δj = 1 + δ + δ2 + · · · + δn−1 = 1 −δn
1 −δ ,
since, at each occasion j, we forget at a rate of δj. If 0 < δ < 1, the above sum
converges to (1 −δ)−1, as n converges to inﬁnity. Thus, for δ = 1 (OLS), the
memory is equal to inﬁnity (in this case we do not forget any data in the estimation
of β), but if say δ = 0.5, then the memory is equal to 2 (which we can think of as
using only the two most recent observations in the calculation of the new ˆβ).

68
3
The Kalman Filter
The calculation of ˆβ is the result of the minimisation of (3.7), which can
be obtained by direct differentiation. However, the expression of ˆβ may follow
immediately from OLS if we rewrite the model in compact form as
y =
⎡
⎢⎢⎢⎣
δ(n−1)/2y1
...
δ1/2yn−1
yn
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
δ(n−1)/2x⊤
1
...
δ1/2x⊤
2
x⊤
n
⎤
⎥⎥⎥⎦β +
⎡
⎢⎢⎢⎣
ϵ1
...
ϵn−1
ϵn
⎤
⎥⎥⎥⎦= Xβ + ϵ.
Then it is easy to see that the ordinary sum of squares for the above model coincides
with the weighted sum of squares (3.7). Thus, the estimator of β now becomes
ˆβ = (X⊤X)−1X⊤y =
⎛
⎝
n−1

j=0
δjxn−jx⊤
n−j
⎞
⎠
−1 n−1

j=0
δjxn−jyn−j.
(3.8)
Again we observe that for δ = 1, we obtain the OLS solution as a special case. For
δ < 1, we put larger weight on yn, yn−1 and xn, xn−1 than on more distant yi, xi,
e.g. y1, x1.
Next, we express ˆβn and ˆσ 2 recursively, leading to recursive least squares (RLS).
It is important to note that in time series applications, one is interested in computing
ˆβt, for each time point t = 1, . . . , n, for example, to enable real-time forecasting. In
the classical application of linear models and regression (see e.g. Bingham and Fry
(2010)), one would have to compute the inverse of X⊤X for each time t, but here
we develop ˆβt from the previously computed ˆβt−1, for t = 1, . . . , n.
We start with some deﬁnitions. For each t, we deﬁne
Ht =
t−1

i=0
δixt−ix⊤
t−i = xtx⊤
t + δHt−1,
ht =
t−1

i=0
δixt−iyt−i = xtyt + δht−1.
Also, deﬁne
et = yt −x⊤
t ˆβt−1
to be the one-step ahead forecast error or residual (the difference of the forecast
x⊤
t ˆβt−1 from the observed value yt) and
Kt = H−1
t
xt.
The next theorem establishes recursive estimation of β and σ 2.

3.1
From Regression to the State Space Model
69
Theorem 3.1 With the above model deﬁnitions, at each time t = 1, . . . , n, we have
the following:
1. The least squares and maximum likelihood estimator of β is
ˆβt = ˆβt−1 + Ktet;
2. The maximum likelihood estimator ˆσ 2
t of σ 2 is given by the recursions nt ˆσ 2
t =
nt−1 ˆσ 2
t−1 + rtet and nt = nt−1 + 1, with n0 = 0;
3. The recursive updating of Pt = H−1
t
is
Pt = 1
δ

I −
Pt−1xtx⊤
t
δ + x⊤
t Pt−1xt
	
Pt−1,
where Kt = Ptxt, et = yt −x⊤
t ˆβt−1 is the one-step prediction error, rt = yt −x⊤
t ˆβt
is the posterior or residual error and initial values for ˆβ0, P0 and ˆσ 2
0 are assumed
known.
Proof First we prove (1). Using the least squares estimator ˆβt = H−1
t
ht, we have
ˆβt −ˆβt−1 = H−1
t
ht −H−1
t−1ht−1
= H−1
t
(δht−1 + xtyt) −H−1
t−1ht−1
= (δH−1
t
−H−1
t−1)ht−1 + H−1
t
xtyt
= H−1
t
xtyt −H−1
t
xtx⊤
t H−1
t−1ht−1
= H−1
t
xt(yt −x⊤
t H−1
t−1ht−1)
= H−1
t
xt(yt −x⊤
t ˆβt−1)
= Ktet.
Proceeding with the proof of (2), we use the maximum likelihood estimator ˆσ 2
t =
n−1
t
y⊤(I −X(X⊤X)−1X⊤)y, given in (3.6), with t = nt = nt−1 + 1, for n0 = 0.
Then,
nt ˆσ 2
t = y⊤y −y⊤X ˆβt
=
t−1

i=0
y2
t−i −h⊤
t ˆβt
=
t−2

i=0
y2
t−1−i −h⊤
t−1 ˆβt−1 + y2
t −h⊤
t ˆβt + h⊤
t−1 ˆβt−1
= nt−1 ˆσ 2
t−1 + y2
t −ytx⊤
t ˆβt −h⊤
t−1Ktet
= nt−1 ˆσ 2
t−1 + (yt −h⊤
t Kt)et

70
3
The Kalman Filter
= nt−1 ˆσ 2
t−1 + (yt −x⊤
t ˆβt)et
= nt−1 ˆσ 2
t−1 + rtet.
For the proof of (3), ﬁrst we establish that the matrix Pt−1xtx⊤
t Pt is symmetric.
Indeed, from the deﬁnition of Pt = H−1
t
, Pt and Pt−1 are symmetric, since Ht and
Ht−1 are both symmetric and
Pt−1xtx⊤
t Pt = Pt−1(P−1
t
−δP−1
t−1)Pt = Pt−1 −δPt
= Pt(P−1
t
−δP−1
t−1)Pt−1 = Ptxtx⊤
t Pt−1,
since Ht −δHt−1 = xtx⊤
t .
Again, from the deﬁnition Pt = H−1
t
and the recursion Ht = xtx⊤
t + δHt−1, we
obtain
Pt = (δP−1
t−1 + xtx⊤
t )−1 = [(δI + xtx⊤
t )P−1
t−1]−1 = Pt−1(δI + xtx⊤
t Pt−1)−1
so
Pt−1 = Pt(δI + xtx⊤
t Pt−1)
so
Ptxt = (δ + x⊤
t Pt−1xt)−1Pt−1xt
so
Pt−1 −δPt = (δ + x⊤
t Pt−1xt)−1Pt−1xtx⊤
t Pt−1
so
Pt = 1
δ

I −
Pt−1xtx⊤
t
δ + x⊤
t Pt−1xt
	
Pt−1,
as required.
⊓⊔
Theorem 3.1 provides key results. If one speciﬁes prior values for ˆβ0, P0 and
ˆσ 2
0 , then for the computation of the estimators ˆβt and ˆσ 2
t , one needs only to save
the quantities at time t −1 ˆβt−1 and ˆσ 2
t−1. Moreover, there is no matrix inversion
needed for this algorithm to run. Indeed, the recursion of Pt in (3) allows the
computation of Kt = H−1
t
xt = Ptxt, which appears in (1) and (2) of the theorem,
without performing any matrix inversion. If we write the updating of the maximum
likelihood of σ 2 recursively, we obtain
nn ˆσ 2
n = nn−1 ˆσ 2
n−1 + rnen = nn−2 ˆσn−2 + rn−1en−1 + rnen = · · ·
= n0 ˆσ 2
0 +
n

t=1
rtet,
and so with n0 = 0, ˆσ 2
n is the average of the product of the residual and prediction
errors, i.e.
ˆσ 2
n = 1
n
n

t=1
rtet.

3.1
From Regression to the State Space Model
71
Theorem 3.1 gives the recursive least squares (RLS) algorithm, which has been used
extensively in signal processing, see e.g. Haykin (2001) or Cowan and Grant (1985,
Section 3.2). For δ = 1, the RLS algorithm provides a recursive application of OLS,
which is useful when the inversion of X⊤X is not possible or it is likely to introduce
computational instabilities. Recursive versions of the OLS is introduced in 1950 by
Plackett (1950) and further explored in many studies; for a recent exposition, the
reader is referred to Young (2011). The RLS algorithm is summarised below.
Recursive least squares
1. Initial values ˆβ0, P0, n0, ˆσ 2
0 and δ;
2. For each time t ≥1,
Pt = 1
δ

I −
Pt−1xtx⊤
t
δ + x⊤
t Pt−1xt
	
Pt−1;
3. For each t, the estimator of βt is ˆβt = ˆβt−1 + Ktet,
where et = yt −x⊤
t ˆβt−1 and Kt = Ptxt;
4. For each t, estimator ˆσ 2
t of ˆσ 2 is given by nt ˆσ 2 = nt−1 ˆσ 2
t−1 + rtet,
where nt = nt−1 + 1 and rt = yt −x⊤
t ˆβt.
3.1.3
The State Space Model
Considering the RLS model of the previous section, we observe that β appears to
be time-invariant, but the introduction of the discount factor δ introduces forgetting
factor, and so it makes β (or rather the estimate of it) adaptable to local ﬂuctuations
of the data. As a result, it is natural to think as β evolving over time. The globally
time-invariant β of the usual regression of Sect. 3.1.1 can be written as βn = βn−1 =
· · · = β1 = β0 = β or βt = βt−1, for each t, and β0 = β. This allows us to motivate
an ‘almost’ time-invariant setting, as βt ≈βt−1, which again can be described with
an evolution equation βt = βt−1 + ζt, where ζt is a white noise process. Here, since
ζt is a random variable, βt is also random and is known as a state vector. We can
then propose a model
yt = x⊤
t βt + ϵt
(observation model),
(3.9a)
βt = βt−1 + ζt
(transition model),
(3.9b)
where we may assume that ϵt and ζt are independent. As we will see later, under
some speciﬁcation of the covariance matrix of ζt, this model proposes exactly the

72
3
The Kalman Filter
same estimation recursions as Theorem 3.1 for the RLS. Thus, with respect to
estimation, we can establish that the above model is equivalent to the RLS, in the
sense of producing the same estimators ˆβt and ˆσ 2
t . Model (3.9a)–(3.9b) deﬁnes a
linear state space model. We note that the observations yt are related linearly to
the states βt via the observation model and βt are linearly linked to βt−1. The
transition model describes the transition of the states from t −1 to t, and in this
case, βt is a random walk. Model (3.9a)–(3.9b) is known as dynamic or time-varying
regression, and it has been proposed for much data in economics and in other areas,
see e.g. Pankratz (1991), West and Harrison (1997, Chapter 3) and Commandeur
and Koopman (2007). If we set xt = 1, for all t, i.e.
yt = βt + ϵt
and
βt = βt−1 + ζt,
then the above model is known as local level model or random walk plus noise
model, and it has played a key role on the development of state space models, see
Harrison (1967), Harrison and Stevens (1976) and Harvey (1989) among others.
For this model, we observe that βt = E(yt | βt), deﬁned to be the level of the time
series, is local, expressed by the random walk transition of βt, hence the name ‘local
level’.
The general linear state space model considers model (3.9a)–(3.9b) but replaces
the random walk of βt by a more general Markov chain, i.e.
yt = x⊤
t βt + ϵt
(observation model),
(3.10a)
βt = Ftβt−1 + ζt
(transition model),
(3.10b)
where xt is a p ×1 vector, βt is a p ×1 vector and Ft is a p ×p matrix. The Markov
property of (3.10b) implies that given βt−1, the distribution of βt does not depend on
past states βt−2, βt−3 . . .. In other words, given the present βt, the future βt+k and
the past βt−j are conditionally independent, for any k, j. The vector xt is referred to
as the design vector, the matrix Ft is known as the transition or state matrix and the
independent white noise sequences ϵt and ζt are known as innovations; sometimes
ϵt is referred to as observation innovation and ζt as state innovation.
In the above model, it may be of interest setting out the distributions of the
innovations ϵt and ζt as univariate and multivariate Gaussian, i.e.
ϵt ∼N(0, σ 2)
and
ζt ∼N(0, Z),
(3.11)
where σ 2 is an observation variance and Z is a p × p transition covariance matrix.
The variance σ 2 and the covariance matrix Z may be time-varying, i.e. σ 2
t and
Zt, and this consideration may be useful in some situations, e.g. in ﬁnance, σ 2
t
may represent volatility. Some of these considerations will be explored in later
chapters, but for now we will operate with a time-invariant observation variance
σ 2
t = σ 2, while we will allow the transition covariance matrix Zt to be time-varying.
An excellent introduction to state space models can be found in Durbin (2004);

3.2
Filtering
73
book-length treatments of state space models include Jazwinski (1970), Anderson
and Moore (1979), Harvey (1989), West and Harrison (1997), Commandeur and
Koopman (2007) and Petris et al. (2009).
Model (3.10a)–(3.10b) is fully speciﬁed if a prior or initial Gaussian distribution
for β0 is set, i.e.
β0 ∼N( ˆβ0|0, P0|0),
(3.12)
for some mean vector ˆβ0|0 and some covariance matrix P0|0.
In the following three sections, we discuss the estimation of βt forward in
time (known as ﬁltering), estimation backward in time (known as smoothing) and
forecasting. Given a working data set y1:t = {y1, . . . , yt}, ﬁltering refers to the
estimation of βt, given y1:t, smoothing refers to the prediction of βt and yt, given
y1:n for t = 1, 2, . . ., n, and forecasting refers to the prediction of βt+k and yt+k,
given y1:t, for some positive integer k.
3.2
Filtering
3.2.1
A First Derivation of the Kalman Filter
We discuss two forms (with two separate proofs) of the ﬁltering algorithm, known
as the Kalman ﬁlter. As it is common in important results, other proofs have
been provided; some of these proofs have opened paths for interesting statistical
estimation theories and applications. The interested reader should consult Duncan
and Horn (1972), Hartigan (1969) and Eubank (2006). A review of the Kalman
ﬁlter can be found in Meinhold and Singpurwalla (1983). An account of the
Kalman ﬁlter from an econometrics perspective can be found in Pollock (2003). An
alternative proof of the ﬁlter for stationary processes is proposed in Priestley and
Rao (1975). The algorithm, which is given below, proposes recursive application
of the conditional or posterior distribution of βt (conditioned upon data y1:t) from
the respective conditional or posterior distribution of βt−1 (conditioned upon data
y1:t−1), for all time t starting at t = 1.
Theorem 3.2 (Kalman Filter) Consider the state space model (3.10a)–(3.10b)
together with the error or innovations distribution (3.11) and the initial distribution
(3.12). Then, for each time t = 1, . . ., n, the following apply:
1. The forecast distribution of βt at time t −1 is βt | y1:t−1 ∼N( ˆβt|t−1, Pt|t−1),
where ˆβt|t−1 = Ft ˆβt−1|t−1 and Pt|t−1 = FtPt−1|t−1F⊤
t + Zt.
2. The posterior distribution of βt at time t is βt | y1:t ∼N( ˆβt|t, Pt|t), where ˆβt|t =
ˆβt|t−1 + Ktet, ˆyt|t−1 = x⊤
t ˆβt|t−1, et = yt −ˆyt|t−1, qt|t−1 = x⊤
t Pt|t−1xt + σ 2,
Kt = Pt|t−1xt/qt|t−1 and Pt|t = Pt|t−1 −qt|t−1KtK⊤
t .

74
3
The Kalman Filter
Proof The proof is inductive. We note that distribution (2) is valid for t = 0, since
this is just the assumed initial distribution (3.12). Let us assume that (2) is valid for
t −1, so that βt−1 | y1:t−1 ∼N( ˆβt−1|t−1, Pt−1|t−1). Then from transition equation
(3.10b), we have
E(βt | y1:t−1) = FtE(βt−1 | y1:t−1) = Ft ˆβt−1|t−1 = ˆβt|t−1
and
Var(βt | y1:t−1) = FtVar(βt−1 | y1:t−1)F⊤
t + Zt = FtPt−1|t−1F⊤
t + Zt = Pt|t−1,
since βt−1 and ζt are independent as βt−1 can be written as a linear combination
of ζt−1, ζt−2, . . . , ζ1 and ζs is independent of ζt, for any s ̸= t. The above
establishes the mean vector and the covariance matrix of βt | y1:t−1. Since βt is
a linear combination of βt−1 and ζt, both of which follow Gaussian distributions, it
follows that βt | y1:t−1 follows a Gaussian distribution with mean vector ˆβt|t−1 and
covariance matrix Pt|t−1, as given above. This establishes the distribution for part
(1).
Proceeding now to (2), we ﬁrst note that the distribution of yt | y1:t−1 is
Gaussian with mean ˆyt|t−1 = x⊤
t ˆβt|t−1 and variance qt|t−1 = x⊤
t Pt|t−1xt + σ 2.
This follows from the observation model (3.10a) and the distribution of βt in part
(1). Consequently, we form the joint distribution of βt and yt given y1:t−1, as

 βt
yt

| y1:t−1 ∼N
(
 ˆβt|t−1
ˆyt|t−1

,

 Pt|t−1
ct
c⊤
t
qt|t−1
)
,
where ct is the covariance of βt and yt (given y1:t−1), which is
ct = Cov(βt, yt | y1:t−1) = Cov(βt, x⊤
t βt + ϵt | y1:t−1) = Pt|t−1xt,
since βt is independent of ϵt, as βt can be written as a linear combination of
ζt, ζt−1, . . . , ζ1 and ϵt is independent of ζs, for any t, s.
Now form the joint distribution of βt −Ktyt and yt as

βt −Ktyt
yt

| y1:t−1 ∼N
(
 ˆβt|t−1 −Kt ˆyt|t−1
ˆyt|t−1

,

 Pt|t−1 −qt|t−1KtK⊤
t
0
0⊤
qt|t−1
)
,
since
Var(βt −Ktyt | y1:t−1) = Pt|t−1 −qt|t−1KtK⊤
t −2Ktx⊤
t Pt|t−1
= Pt|t−1 −qt|t−1KtK⊤
t

3.2
Filtering
75
and
Cov(βt −Ktyt, yt | y1:t−1) = Pt|t−1xt −Ktqt|t−1 = 0,
from the deﬁnition of Kt = Pt|t−1xt/qt|t−1. Thus, given y1:t−1, βt −Ktyt and yt
are conditionally independent (since they are uncorrelated having a joint Gaussian
distribution), and so by denoting by p(·) the respective probability density functions,
we have
p(βt −Ktyt | y1:t) = p(βt −Kt | y1:t−1),
which implies that the distribution of βt | y1:t is Gaussian. Independence also
implies
E(βt −Ktyt | y1:t) = E(βt −Ktyt | y1:t−1) ⇒ˆβt|t = E(βt | y1:t) = ˆβt|t−1 + Ktet
and
Var(βt −Ktyt | y1:t) = Var(βt −Ktyt | y1:t−1)
⇒Pt|t = Var(βt | y1:t) = Pt|t−1 −qt|t−1KtK⊤
t .
This establishes βt | y1:t ∼N( ˆβt|t, Pt|t).
⊓⊔
Some comments are in order.
•
We start with some notational clariﬁcations: ˆβt|t−1 is the mean E(βt | y1:t−1), i.e.
the forecast of βt at time t, given data up to time t −1. When yt is observed, the
data set is updated to y1:t, and then ˆβt|t is the mean E(βt | y1:t). In other words,
the subscript t | t −1 indicates forecast at time t, given information y1:t−1, and
the subscript t | t indicates ﬁltered estimate at time t, given information y1:t.
In a similar vein, ˆyt|t−1 is the one-step ahead forecast of yt (given information
up to t −1), and et is the one-step prediction error (the difference of the above
prediction from the observed value of yt). Forecasting will be covered in more
detail in Sect. 3.4.
•
The distribution p(yt | βt) is the likelihood of βt based on the single observation
yt; this is required because Theorem 3.2 suggests a recursive application sequen-
tially over time (see also the last comment below). The distribution p(βt | y1:t−1)
is the prior distribution at time t, meaning it is the distribution of βt, given the past
y1:t−1 and prior of observing yt at time t. The posterior distribution of βt at time
t is the distribution of βt after (a posteriori) yt and the past y1:t−1 are observed.
The Kalman ﬁlter relies upon the speciﬁcation of the distribution of an initial
state vector β0; this distribution is referred to as prior distribution because it is
the distribution of β0 prior of observing any data. Note the difference between
the prior distribution of β0 and the prior distribution of βt at time t.

76
3
The Kalman Filter
•
The vector Kt is known as the Kalman gain; its name originates from the fact
that after multiplying it by et and adding it to the forecast of βt, we obtain the
posterior estimate of βt ( ˆβt|t = ˆβt|t−1 + Ktet).
•
The above theorem provides an algorithm that works recursively: with starting
distribution (3.12), we can obtain ˆβ1|0, P1|0, and by observing y1, we obtain
ˆβ1|1, P1|1, and this completes a full cycle of the algorithm. Then we compute
ˆβ2|1, P2|1, and upon observing y2, we compute ˆβ2|2, P2|2 and so forth. The power
of the algorithm lies in the fact that at each time t, in order to compute ˆβt|t and
Pt|t, we only need to store the current observation yt and the respective posterior
estimates at t −1, i.e. ˆβt−1|t−1 and Pt−1|t−1.
A Note on Statistical Computing
For computation purposes, we use the programming environment R ( https://
www.r-project.org). One of the most important features of R is the numerous
packages available for free. These can be accessed via the Contributed
Packages website: http://cran.r-project.org/web/packages/. A package can
be installed via the Packages tab in the R console and then loaded in
the current working directory from the same tab. We have developed the
package BTSA (Bayesian Time Series Analysis), which performs Bayesian
computation for state space models and includes many of the R functions
used in the text. The package has a manual, which is downloaded for free in
the link http://cran.r-project.org/web/packages/BTSA/BTSA.pdf.
Example 3.1 (Annual Temperatures of Central England)
We consider a historical
time series, consisting of average annual temperatures (◦C) in central England for
the decades 1663–1674 to 1993–2002. Annual values are calculated from monthly
data by totaling the monthly values and dividing by 12. This series is based on a
famous compilation in 1974 by meteorologist Gordon Manley of monthly mean
temperatures for the UK West-Central Midlands, 1659–1973, see Manley (1974).
The data for the earliest years, before introduction of the thermometer, are based on
careful research in documentary sources such as old diaries. Manley draws attention
to the fact that the data values before 1723 are much less reliable than the later
values. Manley’s original series has now been expanded to give daily values from
1723 to the present. The series is one of the longest consistent records of temperature
in existence for anywhere in the world.
There are many questions of interest, particularly in connection with climate
change, including whether there are any regularities in temperature ﬂuctuations,
whether there is evidence of a consistent rise in temperature going beyond natural
ﬂuctuations and so forth. Part of the data are shown by the solid points in Fig. 3.1.
In this example we are interested in setting up a state space model for this data
set and applying the Kalman ﬁlter, e.g. in order to forecast the temperature values of
future dates or to describe changes in the level or the mean of the temperatures over

3.2
Filtering
77
time. By looking at the dynamics of the data, we observe that it ﬂuctuates around
some level, but there is clear evidence of local evolution, e.g. the temperatures up
to 1750 seem to have much more uncertainty around the level and the temperatures
after 1900 seem to have a slight increasing trend. This local evolution suggests that
a local level model may be a reasonable representation of the data. Thus we use the
model
yt = βt + ϵt
(observation model),
(3.13a)
βt = βt−1 + ζt
(transition model),
(3.13b)
where yt denotes the temperature at time t, βt is the level of the series and the
remaining terms of the model are as in model (3.10a)–(3.10b). Here we have p = 1,
so that βt is scalar, and we have used β0 ∼N(9, 1000), σ 2 = 1 and Z = 10.
The value of ˆβ0|0 = 9 is motivated by the fact that the mean annual temperature
is believed to ﬂuctuate around 9 ◦C. The variance P0|0 = 1000 suggests a large
uncertainty in this initial belief of the mean temperature. The values of σ 2 and Z are
chosen here somewhat arbitrarily, but they can be estimated by maximum likelihood
methods; for more details on this approach, see Chap. 4. The following commands
in R were used to read the data and to ﬁt the above model:
> # read data
> temp <- read.table("temp.txt")
> temp <- temp[,2]
> # fit local level model
> fit <- bts.filter(temp, x0=1, F0=1, obsvar=1, Z0=10,
+ beta0=9, P0=1000, DISO=FALSE, VAREST=FALSE)
Figure 3.1 plots the ﬁrst 100 points of the data (solid points) with its forecasts,
which are the estimated states ˆβt|t−1. From Fig. 3.1, we observe that the forecasts
generally follow closely the time series values yt. The estimated level ˆβt|t ﬂuctuates
around its mean 9.190. However, there are some poor forecasts, notably for t = 82
(year 1740), the forecast mean is ˆy82|1:81 = 9.252, while the observation for that
year is y82 = 6.84. This causes the forecast at t = 83 (Year 1741) to be extremely
poor ( ˆy83|1:82 = 7.042, with observation y83 = 9.3). Figure 3.1 is produced using
the R commands:
> # define time series objects to be plotted
> tempts <- ts(temp[1:100], start=1659, frequency=1)
> pred <- ts(fit$FittedMean[1:100], start=1659, frequency=1)
> # Time series plot
> ts.plot(pred,lty=2, col=2, main=expression("Annual central
+ England temperatures with forecasts"),ylab="Degrees in Celsius",
+ xlab="Year", ylim=c(6.7,10.5) )
> points(tempts, pch=20)
> points(pred, pch=4, col=2)
> legend("bottomleft",c("Observations","Forecast mean"),
+ pch=c(20, 4), col=c(1,2))

78
3
The Kalman Filter
Annual central England temperatures with forecasts
Year
Degrees in Celsius
1660
1680
1700
1720
1740
1760
7
8
9
10
Observations
Forecast mean
Fig. 3.1 Temperature values of central England (solid points) and their forecasts (dashed
lines/ticks)
It is of some interest to calculate the forecast variance qt = x⊤
t Pt|t−1xt + σ 2 =
Pt|t−1 + σ 2. This is provided in the bts.filter command of the btw package
as
> q <- fit$FittedVar
The ﬁrst value of q is q1|0 = 1011, the second drops to q2|1 = 11.99901, the third is
q3|2 = 11.91666 and then qt|t−1 = 11.91608 is time-invariant for any t ≥4. Thus
after t = 3, the forecast variance qt converges to 11.91608. The same convergence
result applies for the ﬁltered variance Pt|t, i.e. Pt|t = 0.91608, for t ≥4. This
desirable phenomenon, of stable ﬁltered variances, is common in a wide class of
state space models and is discussed in some detail in Sect. 3.5 and also in Sect. 4.5.

3.2
Filtering
79
3.2.2
A Second Derivation of the Kalman Filter
In some situations, the Gaussian assumption in the innovation terms ϵt and ζt of
the state space model (3.10a)–(3.10b) may be dropped. In such a case, ϵt and ζt
are only partially speciﬁed via their mean and variances, but their distribution is
unspeciﬁed. This may be the result of lack of support for the data and the transition
equation to follow Gaussian distributions, or it may reﬂect the modeller’s reluctance
to specify a Gaussian distribution for ϵt and ζt. For such cases, the recursions of
ˆβt|t−1, Pt|t−1, ˆβt|t, Pt|t of Theorem 3.2 still hold. In other words, by relaxing the
assumption of normality of the innovations of the state space model, we lose the
speciﬁcation of the conditional and predictive distributions, but we retain the ﬁrst
two moments as a means of ﬁltering. This remarkable result is presented in the next
theorem.
Theorem 3.3 In the state space model (3.10a)–(3.10b), suppose that the distribu-
tion assumption of the innovations ϵt and ζt is dropped, i.e. we only assume that
E(ϵt) = 0, Var(ϵt) = σ 2, E(ζt) = 0 and Var(ζt) = Zt, with σ 2 and Zt as deﬁned in
(3.10a)–(3.10b). We assume that the elements of the design vector xt of (3.10a) are
linearly independent. If the estimator ˆβt|t of βt is required to be linear in yt and to
minimise the sum of squares S = n
t=1(yt −x⊤
t βt)2 subject to the minimisation of
the cost function E[(βt −ˆβt|t)⊤(βt −ˆβt|t)], then it is given by ˆβt|t = ˆβt|t−1 + Ktet,
where ˆβt|t−1, Kt and et are as in Theorem 3.2. The minimum covariance matrix of
βt is given by the recursion Pt|t = Pt|t−1 −qt|t−1KtK⊤
t , where qt|t−1 is deﬁned as
in Theorem 3.2.
Proof First note that given ˆβt−1|t−1 and Pt−1|t−1 at time t −1, the recursions for
ˆβt|t−1 and Pt|t−1 follow directly from part (1) of Theorem 3.2.
Suppose we wish to obtain an estimator of βt that is linear in yt, that is ˆβt|t =
at + Ktyt, for some at and Kt (to be speciﬁed later). Then we can write
ˆβt|t = a∗
t + Ktet,
(3.14)
with a∗
t = at −Kt ˆyt|t−1, et = yt −ˆyt|t−1 and ˆyt|t−1 as in Theorem 3.2. We will
show that for some Kt, if ˆβt|t is required to minimise the sum of squares
S =
n

t=1
(yt −x⊤
t βt)2,
(3.15)

80
3
The Kalman Filter
then a∗
t = Ft ˆβt−1|t−1 = ˆβt|t−1. To prove this, ﬁrst deﬁne
y =
⎡
⎢⎢⎢⎣
y1
y2
...
yn
⎤
⎥⎥⎥⎦,
X =
⎡
⎢⎢⎢⎣
x⊤
1
0 · · · 0
0 x⊤
2 · · · 0
...
...
...
...
0
0 · · · x⊤
n
⎤
⎥⎥⎥⎦,
β =
⎡
⎢⎢⎢⎣
β1
β2
...
βn
⎤
⎥⎥⎥⎦,
ϵ =
⎡
⎢⎢⎢⎣
ϵ1
ϵ2
...
ϵn
⎤
⎥⎥⎥⎦,
e =
⎡
⎢⎢⎢⎣
e1
e2
...
en
⎤
⎥⎥⎥⎦,
K =
⎡
⎢⎢⎢⎣
K1 0 · · · 0
0 K2 · · · 0
...
...
...
...
0
0 · · · Kn
⎤
⎥⎥⎥⎦.
Then we can write the observation model (3.10a) as y = Xβ + ϵ and the sum of
squares (3.15) as
S(β) = (y −Xβ)⊤(y −Xβ),
and from the assumed linear form (3.14), we have ˆβ = a∗+ Ke, where a∗⊤=
[(a∗
1)⊤, . . . , (a∗
n)⊤]. We will show that a∗= b∗, where b∗= E(β) = β∗⊤=
[ ˆβ⊤
1|0, . . . , ˆβ⊤
n|n−1]. With the above ˆβ, the sum of squares can be written as
S ≡S( ˆβ) = (y −Xa∗−XKe)⊤(y −Xa∗−XKe)
= (y −Xa∗)⊤(y −Xa∗) −2(y −Xa∗)⊤XKe
+e⊤K⊤X⊤XKe,
which is minimised when E(y −Xa∗) = 0. To see this, ﬁrst set z = y −Xa∗,
and then notice that the function f (z) = z⊤z −2z⊤c1 + c2 is equal to S, if c1 =
XKe and c2 = e⊤K⊤X⊤XKe (constants not depending on a∗). Now, using vector
differentiation, we have
d f (z)
d z
= 2Iz −2c1,
which is equal to zero when z = c1. The second derivative of f (z) is equal to
d2 f (z)
d zd zT = 2I,
which is a positive deﬁnite matrix, and hence the stationary vector z = c1 minimises
f (z). Thus, the value of a∗that minimises S satisﬁes the equation y −Xa∗= XKe,
or E(y −Xa∗) = XKE(e) = 0, since E(e) = 0.
This implies E(y) = Xa∗= XE(β) = Xb∗. With the deﬁnition of X, a∗and b∗,
this in turn implies x⊤
t c = p
i=1 xtici = 0, where xt = (x1t, . . . , xtp)⊤and c =

3.2
Filtering
81
(c1, . . . , cp)⊤and c = a∗
t −b∗
t . Since the elements of xt are linearly independent,
it follows that c = 0, and hence a∗
t = b∗
t , for all t = 1, . . . , n. Thus, a∗
t = ˆβt|t−1,
and from (3.14), we have
ˆβt|t = ˆβt|t−1 + Ktet,
(3.16)
for some value of Kt to be deﬁned. From the deﬁnition of Pt|t, we have that
Pt|t = E[(βt −ˆβt|t)(βt −ˆβt|t)⊤]
= E{[βt −ˆβt|t−1 −Kt(x⊤
t βt + ϵt −x⊤
t ˆβt|t−1)]
×[βt −ˆβt|t−1 −Kt(x⊤
t βt + ϵt −x⊤
t ˆβt|t−1)]}⊤
= E[(I −Ktx⊤
t )(βt −ˆβt|t−1)(βt −ˆβt|t−1)⊤(I −xtK⊤
t )
+ϵ2
t KtK⊤
t ]
= (I −Ktx⊤
t )Pt|t−1(I −xtK⊤
t ) + σ 2KtK⊤
t
= Pt|t−1 −Ktx⊤
t Pt|t−1 −Pt|t−1xtK⊤
t + qt|t−1KtK⊤
t ,
(3.17)
where qt|t−1 = x⊤
t Pt|t−1xt + σ 2, since βt and ϵt are independent, as βt can be
written as a linear combination of the innovation vectors ζt, . . . , ζ1 and ϵt and ζs are
independent for any t, s.
The covariance matrix Pt|t in (3.17) is given as a function of Kt and so the
minimum Pt|t is achieved by minimising the cost function
E[(βt −ˆβt|t)⊤(βt −ˆβt|t)] = trace{E[(βt −ˆβt|t)(βt −ˆβt|t)⊤]} = trace(Pt|t),
with respect to Kt.
By applying the trace to (3.17), we get
trace(Pt|t) = trace(Pt|t−1) −trace(Ktx⊤
t Pt|t−1) −trace(Pt|t−1xtK⊤
t )
+trace(qt|t−1KtK⊤
t )
= trace(Pt|t−1) −trace(x⊤
t Pt|t−1Kt) −trace(KtPt|t−1xt)
+qt|t−1trace(KtK⊤
t )
= trace(Pt|t−1) −2x⊤
t Pt|t−1Kt + qt|t−1trace(KtK⊤
t ),
and thus Kt is the solution of the matrix equation
∂trace(Pt|t)
∂Kt
= −2Pt|t−1xt + 2qt|t−1Kt = 0,

82
3
The Kalman Filter
where ∂trace(Pt|t)/∂Kt denotes the partial derivative of the trace of Pt|t with respect
to Kt. Solving the above equation, we obtain Kt = Pt|t−1xt/qt|t−1. The quantity
Kt is optimal in the sense that among all linear estimators ˆβt|t, (3.16) minimises
E[(βt −ˆβt|t)⊤(βt −ˆβt|t)]. With Kt = Pt|t−1xt/qt|t−1, from (3.17), the minimum
covariance matrix Pt|t becomes Pt|t = Pt|t−1 −qt|t−1KtKT
t .
⊓⊔
Theorem 3.3 provides important results. It validates the recursions of ˆβt|t
and Pt|t, even in situations where the modeller is reluctant to specify Gaussian
distributions for the innovations ϵt and ζt. Even if one is happy to accept the
Gaussian assumption of the innovations, Theorem 3.3 shows that ˆβ1|1, . . . ˆβn|n
minimise the sum of squares subject to the minimisation of the cost function
E[(βt −ˆβt|t)⊤(βt −ˆβt|t)], for each t. This is equivalent in the minimisation of
n

t=1
(yt −x⊤
t βt)2 + μ
n

t=2
(βt −Ftβt−1)⊤(βt −Ftβt−1),
for some μ ≥0. Derivation of the optimal ˆβt under this approach is known as
ﬂexible least squares (FLS) and it is derived in Kalaba and Tesfatsion (1988) and
further developed in Tesfatsion and Kalaba (1989). This approach returns exactly the
Kalman ﬁlter recursion of ˆβt|t, as it is shown in Montana et al. (2009). The parameter
μ controls the magnitude of the distance βt −Ftβt−1 and in Montana et al. (2009)
it is shown that μ is related to the covariance matrix of ζt via Zt = μ−1I. However,
it turns out that the Kalman ﬁlter setting is more general than that of the FLS, as it
enables a more general speciﬁcation for Zt, i.e. components of ζt not having equal
variances μ−1 and zero covariances.
In the rest of this book, unless otherwise stated, we will be assuming the
Gaussian distributions for the innovations, but we should bear in mind that this
assumption may be relaxed as discussed above. The following is a summary of the
Kalman ﬁltering algorithm under the assumption of Gaussian distributions of the
innovations.
Kalman Filter
1. Prior distribution at t = 0: β0 ∼N( ˆβ0|0, P0|0);
2. Posterior distribution of βt−1 at time t −1:
βt−1 | y1:t−1 ∼N( ˆβt−1|t−1, Pt−1|t−1);
3. Prior distribution of βt at time t −1:
βt | y1:t−1 ∼N( ˆβt|t−1, Pt|t−1),
where ˆβt|t−1 = Ft ˆβt−1|t−1 and Pt|t−1 = FtPt−1|t−1F⊤
t + Zt;
4. Posterior distribution at time t:
(continued)

3.3
Smoothing
83
βt | y1:t ∼N( ˆβt|t, Pt|t), where
ˆβt|t = ˆβt|t−1 + Ktet,
Pt|t = Pt|t−1 −qt|t−1KtK⊤
t ,
ˆyt|t−1 = x⊤
t ˆβt|t−1,
et = yt −ˆyt|t−1,
qt|t−1 = x⊤
t Pt|t−1xt + σ 2,
Kt = Pt|t−1xt/qt|t−1.
3.3
Smoothing
In this section we consider estimation of the states βt and of the observations yt,
given information y1:n = {y1, . . . , yn}, for t = 1, 2, . . . , n; this is known as the
ﬁxed-interval smoothing problem, because n is ﬁxed. The distributions of βt | y1:n
and yt | y1:n are called the smoothed state and observation distributions, as they
are the distributions smoothed by data y1:n; they are provided in the next theorem.
Smoothing is an important development of the theory and application of state space
models and has been discussed, among others, in Anderson and Moore (1979),
Catlin (1989), De Jong (1989), Harvey (1989), Koopman (1993) and Durbin and
Koopman (2012). The classic ﬁxed-interval smoothing algorithm that follows was
derived in 1965 by Raunch et al. (1965). We also prove the recurrence updating of
the lag-one covariance smoother discussed in Shumway and Stoffer (2017).
3.3.1
Fixed-Interval Smoothing
Theorem 3.4 (Fixed-Interval Smoothing) In the state space model (3.10a)–
(3.10b) with information y1:n = {y1, . . . , yn}, the following smoothing distributions
apply:
1. For each t
= 1, . . . , n, the smoothed state distribution is βt
| y1:n
∼
N( ˆβt|n, Pt|n), where ˆβt|n =
ˆβt|t + Lt( ˆβt+1|n −ˆβt+1|t) and Pt|n = Pt|t +
Lt(Pt+1|n −Pt+1|t)L⊤
t , with Lt = Pt|tF⊤
t+1P−1
t+1|t and ˆβt|t, ˆβt+1|t, Pt|t, Pt+1|t
being calculated via the Kalman ﬁlter (Theorem 3.2).
2. For each t = 1, . . . , n −1, the smoothed observation distribution is yt | y1:n ∼
N( ˆyt|n, qt|n), where ˆyt|n = x⊤
t ˆβt|n and qt|n = x⊤
t Pt|nxt + σ 2.
Proof First we prove part (1) of the theorem. The proof proceeds by induction
(backwards in time) for t = 1, 2, . . ., n. For t = n, the stated distribution of
βt | y1:n is just the posterior distribution βn | y1:n of Theorem 3.2. Suppose that
the theorem is true for t + 1 (t ≤n −1), i.e. the smoothed state distribution of βt+1
is βt+1 | y1:n ∼N( ˆβt+1|n, Pt+1|n), for some known ˆβt+1|n, Pt+1|n. The smoothed

84
3
The Kalman Filter
state distribution of βt is deﬁned as the marginal distribution of (βt, βt+1) if βt+1 is
integrated out, i.e.
p(βt | y1:n) =
"
Rp p(βt, βt+1 | y1:n) dβt+1
=
"
Rp p(βt | βt+1, y1:n)p(βt+1 | y1:n) dβt+1.
(3.18)
The second term in the integral of (3.18) is the Gaussian distribution above, assumed
by induction. In the ﬁrst term, we apply the Bayes theorem
p(βt | βt+1, y1:n) = p(y | βt, βt+1, y1:t)p(βt | βt+1, y1:t)
p(y | βt+1, y1:t)
,
where y = (yt+1, . . . , yn). Now, given βt+1, y is independent of βt. Intuitively, this
works since βt precedes βt+1 and so βt is ‘embedded’ in βt+1. More mathemat-
ically, we can show the independence by noting that y | βt, βt+1 is a Gaussian
distribution (from the observation model (3.10a)) and noting that Cov(y, βt
|
βt+1, y1:t) = 0, because each element of y can be written as a linear combination
of βt+1. This establishes the independence and so the two terms with y in the above
equation cancel out. Thus, applying the Bayes theorem for the remaining term, we
obtain
p(βt | βt+1, yt) ∝p(βt+1 | βt, y1:t)p(βt | y1:t).
Now we know from the transition model (3.10b) that βt+1 | βt, yt ∼N(Ft+1βt,
Zt+1) and from the Kalman ﬁlter (Theorem 3.2) that βt | y1:t ∼N( ˆβt|t, Pt|t). Then
we form the joint distribution of βt and βt+1, given y1:t as

 βt
βt+1

| y1:t ∼N
(
ˆβt|t
ˆβt+1|t

,

 Pt|t
ct
c⊤
t
Pt+1|t
)
,
where the covariance ct is
ct = Cov(βt, βt+1 | y1:t) = Cov(βt, Ft+1βt + ζt+1 | y1:t)
= Var(βt | y1:t)F⊤
t+1 = Pt|tF⊤
t+1.
As a result, in a similar way as in Theorem 3.2, we obtain the conditional distribution
of βt | βt+1, y1:t as βt | βt+1, y1:t ∼N( ˆβ∗
t|n, P∗
t|n), with
ˆβ∗
t|n = ˆβt|t + Lt(βt+1 −ˆβt+1|t),
P∗
t|n = Pt|t −LtPt+1|tL⊤
t ,

3.3
Smoothing
85
where Lt is as deﬁned in the theorem. From these two equations, the mean vector
and the covariance matrix of βt | y1:n are calculated using the tower properties (see
Sect. 2.3.1) as
ˆβt|n = E(βt | y1:n) = E[E(βt | βt+1, y1:n) | y1:n]
= E[ ˆβt|t + Lt(βt+1 −ˆβt+1|t) | y1:n]
= ˆβt|t + Lt( ˆβt+1|n −ˆβt+1|t)
and
Pt|n = E[Var(βt | βt+1, y1:n) | y1:n] + Var[E(βt | βt+1, y1:n) | y1:n]
= E(Pt|t −LtPt+1|tL⊤
t | y1:n)
+Var[ ˆβt|t + Lt(βt+1 −ˆβt+1|t) | y1:n]
= Pt|t −LtPt+1|tL⊤
t + LtPt+1|nL⊤
t
= Pt|t + Lt(Pt+1|n −Pt+1|t)L⊤
t .
The distribution of βt | y1:n is Gaussian because from (3.18) this is deﬁned as the
marginal of a joint Gaussian distribution (of βt and βt+1). This settles part (1).
Part (2) follows immediately from the observation model (3.10a) and part (1).
The mean and variance of yt, given y1:n, are
ˆyt|n = E(yt | y1:n) = E(x⊤
t βt + ϵt | y1:n) = x⊤
t ˆβt|n
and
qt|n = Var(yt | y1:n) = Var(x⊤
t βt + ϵt | y1:n) = x⊤
t Pt|nxt + σ 2,
since βt is independent of ϵt. Since the distributions of ϵt and of βt, given y1:n, are
both Gaussian, it follows that the distribution of yt | y1:n is also Gaussian, and this
completes the proof.
⊓⊔
We note that a (1 −α)% smoothing interval for yt, based on information y1:n, is
obtained as ˆyt|n ± z1−α/2√qt|n, where z1−α/2 denotes the (1 −α/2)%-quantile of
the standard Gaussian distribution N(0, 1). The quantity ˆyt|n of the second part of
the theorem is known as the smoothed forecast mean, or just smoothed forecast at
time t, based on information y1:n = {y1, . . . , yn}.
The above theorem proposes an algorithm that works recursively backward in
time. At time n, we obtain βn | y1:n ∼N( ˆβn|n, Pn|n) via the Kalman ﬁlter. Then
we obtain backward in time the distributions βn−1 | y1:n, βn−2 | y1:n and so on,
up to β1 | y1:n, which are used to obtain the smoothed distributions yt | y1:n. The
algorithm is summarised below.

86
3
The Kalman Filter
Fixed-Interval Smoothing
For any t = 1, 2, . . . , n:
1. Initial state distribution at t = n: βn | y1:n ∼N( ˆβn|n, Pn|n), where ˆβn|n
and Pn|n are computed by the Kalman ﬁlter (Theorem 3.2).
2. Smoothed state distribution, for t = n −1, n −2, . . . , 1:
βt | y1:n ∼N( ˆβt|n, Pt|n), where
ˆβt|n = ˆβt|t + Lt( ˆβt+1|n −ˆβt+1|t),
Pt|n = Pt|t + Lt(Pt+1|n −Pt+1|t)L⊤
t ,
with Lt = Pt|tF⊤
t+1P−1
t+1|t and ˆβt|t, ˆβt+1|t, Pt|t, Pt+1|t being calculated by
the Kalman ﬁlter.
3. Smoothed observation distribution, for t = 1, 2, . . . , n −1:
yt | y1:n ∼N( ˆyt|n, qt|n),
where ˆyt|n = x⊤
t ˆβt|n and qt|n = x⊤
t Pt|nxt + σ 2.
Example 3.2 (Annual Temperature Example Continued)
In Example 3.1, we com-
puted forecasts ˆyt|t−1 of observations yt, for the annual temperature data for central
England. In this example, we compute the smooth estimates yt|n = x⊤
t ˆβt|n of yt, for
the adopted local level model (3.13a)–(3.13b) of Example 3.1, where t = 1, . . . , 343
and n = 344 (corresponding to the years 1659, 1660, . . ., 2002). Figure 3.2 plots
the ﬁrst 100 values of the smooth estimates ˆyt|n (t = 1, . . . , n−1) (dashed line with
stars), together with the forecasts ˆyt|t−1 (t = 1, . . . , n) (dotted line with ticks) and
the observed data (solid points). This plot is produced by the R commands
> # temp and pred is defined previously
> fit.s <- bts.smooth(temp, x0=1, F0=1, obsvar=1, Z0=10,
+ beta0=9, P0=1000, DISO=FALSE)
> smooth1 <- ts(fit.s$SmoothMean[1:100],
start=1659, frequency=1)
> ts.plot(smooth1, lty=2, col=4,main=expression("Temperatures
+ with forecasts and smooth estimates"),xlab="Year",
+ ylab="Degrees Celsius",ylim=c(6.7,10.5))
> #lines(smooth1, lty=2)
> points(tempts, pch=20)
> points(pred, pch=4, col=2)
> points(smooth1, pch=8, col=4)
> legend("bottomleft",c("Observations","Forecast mean",
+ "Smooth estimate"), pch=c(20, 4, 8), col=c(1,2, 4))
> abline(v=1740, lty=3)
It is expected that the smooth estimates of yt will be considerably closer to the
observations yt than the forecasts, since they are using all observations y1, . . . , y344.

3.3
Smoothing
87
Temperatures with forecasts and smooth estimates
Year
Degrees Celsius
1660
1680
1700
1720
1740
1760
7
8
9
10
Observations
Forecast mean
Smooth estimate
Fig. 3.2 Smoothed estimates (dashed lines/stars), forecasts (dotted lines/ticks) and actual obser-
vations (solid points) for the temperature data
At a ﬁrst glance, a plot of these means shows little difference to the forecast
means ˆyt|t−1. However, a more careful examination reveals that the smoothed
forecasts are much more accurate than the forecasts, which are based on ﬁltering,
and lag behind the data by one time point. This effect is much more prominent for
the ‘extreme’ observations. For example, the observation in year 1740 is 6.84 ◦C.
The smoothed estimate is 7.212 ◦C, but the forecast is 9.252 ◦C. This happens
because the forecast is prior to the observation of t = 82 (corresponding to year
1740), and thus it takes into account only past observations y81, y80 . . ., which are
much higher than y82; for example, y81 = 9.2 ◦C and y80 = 9.81 ◦C. In contrast, for
ˆy82|n the smooth estimate of y82, all years are taken into account, resulting in much
more accurate estimation. This is clearly depicted by the vertical line in Fig. 3.2,
from which we see that in year 1740 the actual observation and the smoothed
estimate are close, but the respective ﬁltered forecast is far from these; the forecast
that appears to be close to the observation refers to the next time point, year 1741.

88
3
The Kalman Filter
A second observation is that the forecast of y83 = 9.3 ◦C is equal to 7.04 ◦C,
which again is very inaccurate. This is due to the fact that this forecast is affected by
the low value of y82 = 6.84 ◦C; we can observe that most forecasts lag behind the
original observations by one time point. This effect is more prominent in extreme
observations, such as y82 as discussed above, and it is a characteristic of most
forecasting systems. The smoothed forecasts avoid this lagging and produce more
accurate forecasts, but the price to pay is that they require the availability of all
data. Thus, smoothing is not suitable for real-time forecasting, which requires at
each time to forecast the observation at the next time point when the entire data
are not available. Smoothing is then more useful when all data are available, and
used routinely, in order to describe trends or to ﬁt a model to historical data;
sometimes it is used as a pre-processing tool for a wider data analysis. In some
studies, forecasting is referred to as out of sample estimation (as the estimation is
carried out for observations not belonging to the sample), and smoothing is referred
to as in-sample estimation (as the entire sample is used for the estimation).
3.3.2
The Lag-One Covariance Smoother
In this section, the lag-one covariance smoother is discussed, which gives a sequen-
tial updating of the lag-one covariance matrix backward in time. This is useful in the
derivation and computation of the expectation maximisation (EM) algorithm (used
in maximum likelihood estimation) as discussed in detail in Sect. 4.3.1.
Theorem 3.5 (Lag-One Covariance Smoothing) In the state space model
(3.10a)–(3.10b) with information y1:n = {y1, . . . , yn}, deﬁne the lag-one covariance
matrix Pt,t−1|n = Cov(βt, βt−1 | yi:n). This can be computed backwards in time
t = n, n −1, . . . , 3, 2, according to
1. Pn,n−1|n = (I −Knx⊤
n )FnPn−1|n−1, where Kn is the Kalman gain and Pn−1|n−1
is computed by the Kalman ﬁlter (Theorem 3.2);
2. Pt−1,t−2|n = Pt−1|t−1 + Lt−1(Pt,t−1|n −FtPt−1|t−1)L⊤
t−2, for t = 2, . . . , n,
where Pt−1|t−1 is computed by the Kalman ﬁlter (Theorem 3.2) and Lt−1 and
Lt−2 are computed by the ﬁxed-interval smoothing algorithm (Theorem 3.4).
Proof First we prove (1). Write down the joint distribution of βn, βn−1 and yn,
given information y1:n−1:
⎡
⎣
βn
βn−1
yn
⎤
⎦| y1:n−1 ∼N
⎧
⎨
⎩
⎡
⎣
ˆβn|n−1
ˆβn−1|n−1
ˆyn|n−1
⎤
⎦,
⎡
⎣
Pn|n−1
FnPn−1|n−1
Pn|n−1xn
Pn−1|n−1F⊤
n
Pn−1|n−1
Pn−1|n−1F⊤
n xn
x⊤
n Pn|n−1
x⊤
n FnPn−1|n−1
qn|n−1
⎤
⎦
⎫
⎬
⎭,

3.3
Smoothing
89
where Cov(βn, βn−1
|
y1:n−1)
=
Cov(Fnβn−1 + ζn, βn−1
|
y1:n−1)
=
FnPn−1|n−1, Cov(βn, yn
|
y1:n−1)
=
Cov(βn, x⊤
n βn + ϵn
|
y1:n−1)
=
Pn|n−1xn, and Cov(βn−1, yn | y1:n−1) = Cov(βn−1, x⊤
n βn + ϵn | y1"n−1) =
Cov(βn−1, x⊤
n Fnβn−1 + x⊤
n ζn + ϵn | y1:n−1) = Pn−1|n−1F⊤
n xn.
By applying the conditional result of Theorem 3.2, we have that the covariance
matrix of the state vector (β⊤
n , β⊤
n−1)⊤, given information y1:n−1 and yn (or
equivalently given y1:n), is
Var

 βn
βn−1

| y1:n
	
=
 
Pn|n
Pn,n−1|n
P⊤
n,n−1|n Pn−1|n
!
=

Pn|n−1
FnPn−1|n−1
Pn−1|n−1F⊤
n
Pn−1|n−1

−q−1
n|n−1

Pn|n−1xn
Pn−1|n−1F⊤
n xn

×
%
x⊤
n Pn|n−1, x⊤
n FnPn−1|n−1
&
,
from which we obtain
Pn,n−1|n = FnPn−1|n−1 −q−1
n|n−1Pn|n−1xnx⊤
n FnPn−1|n−1
= (I −Knx⊤
n )FnPn−1|n−1,
as required.
Proceeding now to (2), ﬁrst we deﬁne
ˆβ∗
t|s = βt −ˆβt|s,
(3.19)
for any t, s = 1, . . . , n.
First notice that ˆβ∗
t|s and y = [y1, . . . , ys]⊤are independent. From the tower
property, it follows that ˆβ∗
t|s and y are uncorrelated, i.e.
E( ˆβ∗
t|sy⊤) = E[E( ˆβ∗
t|sy⊤| y) | y] = E[{E(βt | y) −ˆβt|s}y⊤| y] = 0
= E( ˆβ∗
t|s)E(y)⊤.
Since the distribution of βt given y is Gaussian, ˆβ∗
t|s and y are independent.
An implication of that independence is
Pt−1,t−2|n = E( ˆβ∗
t−1|n ˆβ∗⊤
t−2|n | y1:n) = E( ˆβ∗
t−1|n ˆβ∗⊤
t−2|n),
(3.20)
and so in the following we use unconditional expectations to prove the recursion of
Pt−1,t−2|n.

90
3
The Kalman Filter
From Eq. (3.19) and from the smoothing recursion of ˆβt|n of Theorem 3.4, we
can see that
ˆβ∗
t−1|n = βt−1 −ˆβt−1|n
= βt−1 −[ ˆβt−1|t−1 + Lt−1( ˆβt|n −ˆβt|t−1)]
= βt−1 −ˆβt−1|t−1 + Lt−1[βt −ˆβt|n −(βt −ˆβt|t−1)]
= ˆβ∗
t−1|t−1 + Lt−1( ˆβ∗
t|n −ˆβ∗
t|t−1),
which can be written as
ˆβ∗
t−1|n + Lt−1 ˆβt|n = ˆβ∗
t−1|t−1 + Lt−1( ˆβ∗
t|n −ˆβ∗
t|t−1 + ˆβt|n)
= ˆβ∗
t−1|t−1 + Lt−1Ft ˆβt−1|t−1,
(3.21)
since ˆβ∗
t|n −ˆβ∗
t|t−1 + ˆβt|n = βt −ˆβ∗
t|t−1 = ˆβt|t−1 = Ft ˆβt−1|t−1.
Now we multiply ˆβ∗
t−1|n by ˆβT
t−2|n (which is provided by (3.21) for time t −2)
and taking expectations
Pt−1,t−2|n + Lt−1E( ˆβt|n ˆβ⊤
t−1|n)L⊤
t−2 + Lt−1E( ˆβt|n ˆβ∗⊤
t−2|n) + E( ˆβ∗
t−1|n ˆβ⊤
t−1|n)L⊤
t−2
= E( ˆβ∗
t−1|t−1 ˆβ∗⊤
t−2|t−2) + Lt−1FtE( ˆβt−1|t−1 ˆβ∗⊤
t−2|t−2)
+E( ˆβ∗
t−1|t−1 ˆβt−2|t−2)F⊤
t−1L⊤
t−2 + Lt−1FtE( ˆβt−1|t−1 ˆβ⊤
t−2|t−2)F⊤
t−1L⊤
t−2.
(3.22)
In the rest of the proof, we calculate the expectations in (3.22). Firstly, we note
that
E( ˆβt|n ˆβ∗⊤
t−2|n) = E( ˆβ∗
t−1|n ˆβ⊤
t−1|n) = E( ˆβ∗
t−1|t−1 ˆβ⊤
t−2|t−2) = 0.
This can be established by using the tower property of expectations, e.g. for the ﬁrst
expectation
E( ˆβt|n ˆβ∗⊤
t−2|n) = E[E{ ˆβt|n(βt−2 −ˆβt−2|n) | y1:n} | y1:n]
= ˆβt|n[E(βt−2 | y1:n) −ˆβt−2|n] = 0.
Similarly, one obtains the other two expectations.
The next step is to obtain a recursion for E( ˆβ∗
t−1|t−1 ˆβ∗⊤
t−2|t−2). From the Kalman
ﬁlter recursion of ˆβt−1|t−1, we have
ˆβ∗
t−1|t−1 = βt−1 −ˆβt−1|t−1
= βt−1 −ˆβt−1|t−2 −Kt−1(yt−1 −x⊤
t−1 ˆβt−1|t−2)

3.3
Smoothing
91
= ˆβ∗
t−1|t−2 −Kt−1(x⊤
t−1βt−1 + ϵt−1 −x⊤
t−1 ˆβt−1|t−2)
= ˆβ∗
t−1|t−2 −Kt−1x⊤
t−1 ˆβ∗
t−1|t−2 −Kt−1ϵt−1,
and substituting this into E( ˆβ∗
t−1|t−1 ˆβ∗⊤
t−2|t−2), we obtain
E( ˆβ∗
t−1|t−1 ˆβ∗⊤
t−2|t−2) = E( ˆβ∗
t−1|t−2 ˆβ∗⊤
t−2|t−2) −Kt−1x⊤
t−1E( ˆβ∗
t−1|t−2 ˆβ∗⊤
t−2|t−2)
−Kt−1E(ϵt−1 ˆβ∗⊤
t−2|t−2)
= Pt−1,t−2|t−2 −Kt−1x⊤
t−1Pt−1,t−2|t−2,
(3.23)
since ϵt−1 and ˆβ∗
t−2|t−2 are independent.
From the recursion of ˆβ∗
t−1|t−1 by subtracting βt−1 from both sides of that
recursion, we see that
ˆβt−1|t−1 = ˆβt−1|t−2 + Kt−1x⊤
t−1 ˆβ∗
t−1|t−2 + Kt−1ϵt−1
(3.24)
and so
E( ˆβt−1|t−2 ˆβ∗⊤
t−2|t−2) = Kt−1x⊤
t−1E( ˆβ∗
t−1|t−2 ˆβ∗⊤
t−2|t−2)
= Kt−1x⊤
t−1Pt−1,t−2|t−2.
(3.25)
Also,
E( ˆβt|n ˆβ⊤
t−1|n) = E(βt −ˆβ∗
t|n)(βt−1 −ˆβ∗⊤
t−1|n)
= E(βtβ⊤
t−1) −Pt,t−1|n
= E(Ftβt−1 + ζt)(Ft−1βt−2 + ζt−1)⊤−Pt,t−1|n
= FtE(βt−1β⊤
t−2)F⊤
t−1 + FtZ −Pt,t−1|n,
(3.26)
and using (3.24),
E( ˆβt−1|t−1 ˆβ⊤
t−2|t−2) = E( ˆβt−1|t−2 + Kt−1x⊤
t−1 ˆβ∗
t−1|t−2 + Kt−1ϵt−1) ˆβ⊤
t−2|t−2
= E( ˆβt−1|t−2 ˆβ⊤
t−2|t−2)
= E(βt−1 −ˆβ∗
t−1|t−2)(βt−2 −ˆβ∗
t−2|t−2)⊤
= E( ˆβt−1 ˆβ⊤
t−2) −Pt−1,t−2|t−2,
(3.27)
as E(βt−1 ˆβ∗⊤
t−2|t−2) = E( ˆβ∗
t−1|t−2β⊤
t−2) = Pt−1,t−2|t−2.

92
3
The Kalman Filter
We substitute (3.23), (3.25), (3.26) and (3.27) in (3.22), which after some algebra
yields
Pt−1,t−2|n = Lt−1(Pt,t−1|n −FtPt−1|t−1)L⊤
t−2 + Pt−1|t−1L⊤
t−2,
after using
Pt|t = Pt|t−1 −qtKtK⊤
t
= (I −Ktx⊤
t )Pt|t−1,
from the Kalman ﬁlter.
⊓⊔
Theorem 3.5 is useful in the computation of the expectation maximisation (EM)
algorithm, in Chap. 4, for the evaluation of maximum likelihood estimates.
3.4
Forecasting
With data y1:t = {y1, . . . , yt}, the forecasting problem involves the derivation of
the distributions of βt+k and yt+k, known also as k-step ahead forecast state and
observation distributions, respectively. The positive integer k is known as the lead
time of the forecast and the maximum value it takes is known as the forecast horizon.
To the following we assume that the transition matrix Ft = F is time-invariant; this
consideration is met in most practical models (e.g. for all models in Sect. 4.1) and is
imposed here for simpliﬁcation and elaboration purposes (the proof of the general
result is analogous to the time-invariant case and is left to the reader as an exercise).
Theorem 3.6 In the state space model (3.10a)–(3.10b) with transition matrix Ft =
F and with information y1:t = {y1, . . . , yt}, the following apply.
1. The k-step ahead forecast state distribution is given by βt+k
|
y1:t
∼
N( ˆβt+k|t, Pt+k|t), with ˆβt+k|t = Fk ˆβt|t and
Pt+k|t = FkPt|t(Fk)⊤+
k−1

j=0
FjZt+k−j(Fj)⊤,
where ˆβt|t and Pt|t are computed by the Kalman ﬁlter (Theorem 3.2).
2. The k-step ahead forecast observation distribution is given by yt+k | y1:t ∼
N( ˆyt+k|t, qt+k|t), where ˆyt+k|t = x⊤
t+k ˆβt+k|t and qt+k|t = x⊤
t+kPt+k|txt+k + σ 2.
Proof Suppose that at time t with information y1:t, we have obtained, from an
application of the Kalman ﬁlter, the ﬁltered distribution βt | y1:t ∼N( ˆβt|t, Pt|t).

3.4
Forecasting
93
First we derive the predictive distribution of βt+k given y1:t. To this end, we need
to express βt+k as a function of βt. Applying recurrently the state equation (3.10b),
we have
βt+k = Fβt+k−1 + ζt+k
= F(Fβt+k−2 + ζt+k−1) + ζt+k
= · · ·
= Fkβt +
k−1

j=0
Fjζt+k−j.
Now, using this expression, the mean vector and the covariance matrix of βt+k | y1:t
are
ˆβt+k|t = E(βt+k | y1:t) = FkE(βt | y1:t) = Fk ˆβt|t
and
Pt+k|t = Var(βt+k | y1:t)
= FkVar(βt | y1:t)(Fk)⊤+
k−1

j=0
FjVar(ζt+k−j | y1:t)(Fj)⊤,
which returns the stated covariance matrix, if we note that Var(βt | y1:t) = Pt|t,
Var(ζt) = Zt. Since βt+k is a linear combination of the random vectors βt and ζt’s,
all of which follow Gaussian distributions, the distribution of βt+k | y1:t will also
be Gaussian, and this completes the proof for βt+k.
The stated form of the predictive distribution of yt+k | y1:t follows immediately
by writing down the observation equation yt+k = x⊤
t+kβt+k + ϵt+k and applying the
distribution of βt+k | y1:t. This derivation is left to the reader as an exercise and is
complete by parallel to the derivation of the smoothed distribution of yt | y1:n in
Theorem 3.4 of the previous section.
⊓⊔
Some comments are in order.
•
The observation forecast distribution (the distribution of yt+k | y1:t) is usually
referred as the k-step ahead forecast distribution or simply the forecast distribu-
tion. The state forecast distribution (the distribution of βt+k | y1:t) is referred to
as the forecast state distribution.
•
The mean ˆyt+k|t of the forecast distribution is a function of k = 1, 2, 3, . . . and
is known as a forecast function. Its form is important because it can be used to
classify different models aimed at forecasting. For example, the forecast function
of a linear trend model is a straight line and that of a seasonal model exposes a
cyclic variation (for detailed considerations and related proofs, see Sect. 4.1 of

94
3
The Kalman Filter
the next chapter). For a time-invariant transition matrix Ft = F (which is the case
in many applied models), the forecast function takes the form
ˆyt+k|t = x⊤
t+kFk ˆβt|t.
(3.28)
•
We note that if Zt = Z is time-invariant, the covariance matrix Pt+k|t of βt+k
takes the attractive form
Pt+k|t = FkPt(Fk)⊤+
k−1

j=0
FjZ(Fj)⊤.
•
Recalling that in the Kalman ﬁlter (Theorem 3.2), we compute ˆβt|t−1 and Pt|t−1,
we note that these quantities are the mean vector and covariance matrix of the
one-step forecast state distribution of βt, given y1:t−1. Likewise, ˆyt|t−1 and qt|t−1
are the mean and variance of the one-step forecast observation distribution of yt,
given y1:t−1.
•
A (1 −α)% forecast interval for yt+k, based on information y1:t, is obtained as
ˆyt+k|t ± z1−α/2√qt+k|t, where z1−α/2 denotes the (1 −α/2)%-quantile of the
standard Gaussian distribution N(0, 1).
•
We note that Theorem 3.6 suggests a recursive algorithm: at each time t, we
compute ˆβt|t and Pt|t by the Kalman ﬁlter, and then we calculate ˆβt+k|t, Pt+k|t,
ˆyt+k|t and qt+k|t. This algorithm is summarised below.
Forecasting
For any t ≥2:
1. Initial state distribution at t: βt | y1:t ∼N( ˆβt|t, Pt|t),
where ˆβt|t and Pt|t are calculated by the Kalman ﬁlter (Theorem 3.2).
2. k-step forecast state distribution: βt+k | y1:t ∼N( ˆβt+k|t, Pt+k|t), where
ˆβt+k|t = Fk ˆβt|t
and
Pt+k|t = FkPt(Fk)⊤+
k−1

j=0
FjZt+k−j(Fj)⊤.
3. k-step forecast observation distribution: yt+k | y1:t ∼N( ˆyt+k|t, qt+k|t),
where ˆyt+k|t = x⊤
t+k ˆβt+k|t and qt+k|t = x⊤
t+kPt+k|txt+k + σ 2.
Example 3.3 (Annual Temperature Example Continued)
In Examples 3.1 and 3.2,
we computed ﬁltered and smoothed estimates ˆβt|t of the level βt, for the annual
temperature data for central England. In this example, we compute predictions for
the actual temperatures yt and the level βt. In particular, we are interested in 1-year,

3.4
Forecasting
95
2-year and 3-year ahead predictions at t = n = 344 (corresponding to year 2002);
in other words, we are interested in temperature predictions for the years 2003, 2004
and 2005, based on the data up to 2002. In R this is implemented by the command:
> # temp is defined previously
> forecast <- bts.predict(temp, x0=1, F0=1, obsvar=1, Z0=10,
+ beta0=9, P0=1000, DISO=FALSE, VAREST=FALSE, kmax=3)
The above command creates the object forecast with the values of ˆy344+k|344
and q344+k|344, for k = 1, 2, 3. These values are returned by
> forecast$ForMean
[[1]]
[1] 10.54656
[[2]]
[1] 10.54656
[[3]]
[1] 10.54656
for the forecast mean and
> forecast$ForVar
[[1]]
[1] 11.91608
[[2]]
[1] 21.91608
[[3]]
[1] 31.91608
for the forecast variance.
Thus, ˆy345|344 = ˆy346|344 = ˆy347|344 = 10.54656 and q345|344 = 11.91608,
q346|344 = 21.91608 and q347|344 = 31.91608. In other words, all three prediction
means are equal to 11.9 ◦C (1 dp accuracy), but the respective prediction variances
increase with k = 1, 2, 3. The increase of variance is expected, as given information
y1:344, the further we look into the future, the more uncertainty is added, e.g.
q344+k|344 < q344+j|344, for k < j, and the effect is magniﬁed by the magnitude of
the difference j −k. This is a property shared by any state space model. The equality
of the prediction means is, however, particular to the local level model and in fact
is its characteristic. Finally, based on the above R output, we can easily compute
predictive intervals, e.g. a 95% 2-step ahead predictive interval for y346 is
ˆy346|344 ± z1−0.05/2√q346|344 ≈10.547 ± 1.96
√
21.916 = (1.371, 19.723),
where z1−0.05/2 ≈1.96 is calculated in R using the command qnorm(0.975).
Here, we observe that the relatively large prediction variance has resulted in a too
wide prediction interval. As k increases (and the forecast variance increases), the
prediction intervals will widen and the forecasts will become more uncertain.

96
3
The Kalman Filter
3.5
Steady State of the Kalman Filter
An important feature of the state estimator of the Kalman ﬁlter ˆβt is that after some
time its ﬂuctuation is steady. This is important in control systems (see Chap. 8)
where the states include input signals and the observations output signals. One of
the aims in the design of a control system is to obtain a stable output signal, provided
that the input signals are stable. For a class of state space models (with time-invariant
components), the ﬂuctuations of the estimated states become time-invariant, and
hence the states are steady; this is known as the steady state of the model and it can
be thought of as the system being in an ‘equilibrium’ state. The key to arrive at the
steady state is to show that the sequence of the posterior covariance matrices of the
states (Var(βt | y1:t) = Pt) converges to some matrix P. The steady state of state
space models is discussed in detail in Balakrishnan (1984, Section 4.2) and in Chan
and Guo (1991, Section 3.3). This section provides the details of the convergence
of Pt; we start by discussing the concept of observability, which is interesting in its
own right and will be revisited in Chap. 8.
3.5.1
Observability
Consider the linear state space model (3.10a)–(3.10b), where the design vector xt =
x and the transition matrix Ft = F are assumed to be time-invariant. There are many
state space models in this class, which can generate or describe useful time series as
several examples in the next chapter (Sect. 4.1) indicate.
Informally, observability relates to whether the states of the model can be
determined from the observed data. More formally, suppose that observations
y1, . . . , yn are obtained for some n, and assume that the observation innovations
ϵ1, . . . , ϵn and the state innovations ζ1, . . . , ζn are known. With this set-up, we seek
to derive some condition to ensure that β1, . . . , βn are uniquely determined.
From the state equation (3.10b), write
βt = Ft−1β1 +
t−2

i=0
Fiζt−i,
(3.29)
and from the observation equation (3.10a), write
yt = x⊤Ft−1β1 +
t−2

i=0
x⊤Fiζt−i + ϵt.
(3.30)

3.5
Steady State of the Kalman Filter
97
If we set
y′
t = yt −
t−2

i=0
x⊤Fiζt−i −ϵt,
then (3.30) implies
y′
t = x⊤Ft−1β1,
t = 1, . . . , n.
(3.31)
This is a system of n linear equations (in β1), from which β1 may be determined.
Then any βt, for t ≥2, can be determined using (3.29).
The system of equations (3.31) has a unique solution (in β1) if the zero solution
is the unique solution of the homogeneous system of equations x⊤Ft−1z = 0, t =
1, . . . , n (in the p×1 vector z). Since z has dimension p ≤n, the above is equivalent
to x⊤Fi−1z = 0 having unique zero solution, for i = 1, . . . , p. This in turn is
equivalent to the p × p matrix
O =
⎡
⎢⎢⎢⎣
x⊤
x⊤F
...
x⊤Fp−1
⎤
⎥⎥⎥⎦
(3.32)
being invertible or having full rank p. If this is the case, we can determine
β1, . . . , βn from the data y1, . . . , yn, and we will say that the states are observable.
The matrix O is known as the observability matrix, and when it is of full rank it
suggests a one-to-one relationship between the observations and the states; in such
a case, the state space model is said to be observable. Observability may be used as
a guide to determine the minimum order of the state vector βt to ensure this one-
to-one correspondence between states and observations, hence to reduce redundant
dimensionality.
Example 3.4 (Local Level Model) Consider the local level model
yt = βt + ϵt
and
βt = βt−1 + ζt,
(3.33)
where the white noise processes {ϵt} and {ζt} are mutually independent and
independent of the initial state β0. This model is obviously observable, since the
observability matrix is O = 1 (here p = 1), which of course has full rank.
Example 3.5 Consider now the following state space model, which is described in
detail in Sect. 4.1.1:
yt = [1, 0]

β1t
β2t

+ ϵt = x⊤βt + ϵt,

98
3
The Kalman Filter

 β1t
β2t

=

1 1
0 1
 
β1,t−1
β2,t−1

+

 ζ1t
ζ2t

= Fβt−1 + ζt,
with the usual assumptions on the innovations ϵt and ζt.
This state space model is observable, since the observability matrix
O =

1 0
1 1

is of full rank p = 2.
Now suppose that in the above model, the transition matrix is
F =

λ 0
0 μ

,
for some constants λ and μ. Then the observability matrix of this new model is
O =

 1 0
λ 0

,
which rank is 1 < 2 = p, and hence this model is not observable.
By writing β = [β1t, β2t]⊤and ζt = [ζ1t, ζ2t]⊤, we see
yt = β1t + ϵt,
β1t = λβ1,t−1 + ζ1t
and
β2t = μβ2,t−1 + ζ2t,
from which we observe that β2t does not affect yt and is completely redundant
(assuming that the covariance matrix of ζt is a diagonal matrix, so that β1t and β2t
are uncorrelated). Thus, it is reasonable to suggest that the above model is reduced
to the model
yt = βt + ϵt
and
βt = λβt−1 + ζt,
where the dimension of the state vector βt is reduced from 2 to 1. We can easily
verify that this model is now observable. Such a reduction in state dimensions may
be useful, in particular having in mind forecasting of future observations, but if
interest lies in the state β2t, it may be useful to keep it in the model.
3.5.2
Steady State of the Local Level Model
Consider the local level model, deﬁned by (3.33), where Var(ζt) = Z is time-
invariant. From the Kalman ﬁlter (Theorem 3.2), we have recursions for the
posterior mean ˆβt|t and the posterior variance Pt|t of βt. With this set-up in place,

3.5
Steady State of the Kalman Filter
99
we will show that the sequence of variances {Pt|t} converges to a limit, which is
independent of the prior P0|0 and is given by
P = lim
t→∞Pt|t = Z
2
⎛
⎝
,
1 + 4σ 2
Z
−1
⎞
⎠.
First we show that this limit exists. To this end, we show that the sequence {Pt|t} is
bounded and monotonic.
From Theorem 3.2 with xt = Ft = 1 (local level model), the posterior variance
Pt|t is
Pt|t = Pt|t−1 −K2
t qt|t−1 = Pt|t−1 −
P 2
t|t−1
qt|t−1
= Pt|t−1σ 2
qt|t−1
= Ktσ 2,
(3.34)
where we have used Kt = Pt|t−1/qt|t−1 and qt|t−1 = Pt|t−1 + σ 2 (Theorem 3.2).
From (3.34), it follows that 0 ≤Pt|t ≤σ 2, and hence {Pt|t} is bounded, because
0 ≤Kt =
Pt|t−1
Pt|t−1 + σ 2 ≤1,
with
σ 2 ≥0.
For the monotonicity, ﬁrst we prove
P −1
t|t = P −1
t|t−1 + σ −2.
Indeed, we have

P −1
t|t−1 + σ −2−1
=
σ 2Pt|t−1
σ 2 + Pt|t−1
= Ktσ 2 = Pt|t.
Consequently,
P −1
t|t −P −1
t−1|t−1 = P −1
t|t−1 −P −1
t−1|t−2
= Pt−1|t−1 −Pt−2|t−2
Pt|t−1Pt−1|t−2
= Ct

P −1
t−1|t−1 −P −1
t−2|t−2

,
where
Ct = Pt−1|t−1Pt−2|t−2
Pt|t−1Pt−1|t−2
> 0.

100
3
The Kalman Filter
By applying that formula repeatedly, we have
P −1
t|t −P −1
t−1|t−1 = CtCt−1 · · · C2

P −1
1|1 −P −1
0|0

.
Hence, P −1
t|t
≥P −1
t−1|t−1, for all t, if P −1
1|1 ≥P −1
0|0 ; likewise, P −1
t|t
< P −1
t−1|t−1, for
all t, if P −1
1|1 < P −1
0|0 . Thus, the sequence {P −1
t|t } is either increasing or decreasing
(depending on the sign of P −1
1|1 −P −1
0|0 ) and so it is monotonic.
Since {P −1
t|t } is monotonic, it follows that the sequence of variances {Pt|t} is
monotonic too, and as it is bounded, its limit limt→∞Pt|t exists. From (3.34) by
taking limits and using Pt|t−1 = Pt−1|t−1 + Z, we have
P = (P + Z)σ 2
P + Z + σ 2
or
P 2 + ZP −Zσ 2 = 0.
By keeping only the non-negative solution of this quadratic equation (since P ≥0
as it is the limit of a variance), we have
P = −Z +
√
Z2 + 4Zσ 2
2
= Z
2
⎛
⎝
,
1 + 4σ 2
Z
−1
⎞
⎠,
as required. It is clear by the formula of P that it does not depend on the initial or
prior value of P0|0; this value of P0|0 can affect only whether {Pt|t} is increasing or
decreasing.
The steady state of the Kalman ﬁlter is obtained by replacing Pt|t in the recursion
of ˆβt|t by its limit P, i.e.
ˆβt|t = ˆβt−1|t−1 +
P + Z
P + Z + σ 2 (yt −ˆβt−1|t−1).
3.5.3
Steady State of Linear State Space Models
In this section we consider the steady state of the state space model (3.10a)–(3.10b),
where the design vector xt = x, the transition matrix Ft = F and the transition
covariance matrix Zt = Z are assumed to be time-invariant. The following theorem
states the main result, that is that under mild conditions, the limit of the posterior
covariance matrix Pt|t = Var(βt | y1:t) exists and does not depend on the prior
covariance matrix P0|0 of β0. This is a fundamental result in state space theory; see

3.5
Steady State of the Kalman Filter
101
e.g. Balakrishnan (1984, Section 4.2), Chan and Guo (1991, Section 3.3) and West
and Harrison (1997).
Before we give the main theorem, ﬁrst we give some preliminary discussion on
the convergence of non-negative deﬁnite matrices. Write A ≥0 to denote that an
n × n matrix A is non-negative deﬁnite. For some n × n matrices A ≥0 and B ≥0,
we write A ≥B to denote that A −B ≥0. Likewise, we deﬁne A > 0 if A is
positive deﬁnite and A > B to denote that A −B > 0. Based on this notion, a
sequence of non-negative matrices is said to be bounded if M1 ≤At ≤M2, for
some matrices M1 and M2, for all t; note that all non-negative deﬁnite matrices are
bounded below by M1 = 0. The sequence of non-negative deﬁnite matrices {At} is
known to be increasing (equiv. decreasing) if there is some t0 such that At ≥At−1
(equiv. At ≤At−1), for any t ≥t0. If {At} is either increasing or decreasing, it
is said to be monotonic. If {At} is bounded and monotonic, then by extending to
matrices a classical result of real-valued arithmetic sequences, it follows that its
limit A exists, i.e. limt→∞At = A.
Theorem 3.7 Consider the state space model (3.10a)–(3.10b) with constant design
vector xt = x, transition matrix Ft = F and transition covariance matrix Zt =
Z. If this model is observable, then the sequence of posterior covariance matrices
Var(βt | y1:t) = Pt|t converges to a limit P, which does not depend on the prior
covariance matrix P0|0.
Proof This proof mimics the proof of Harrison (1997). According to (1) above, we
need to prove that the sequence of posterior covariance matrices {Pt|t} is bounded
and monotonic, and hence it is convergent. For any t ≥p, we can deﬁne the vector
Yt = [yt−p+1, yt−p+2, . . . , yt]⊤. If we expand βt in the transition equation (3.10b),
we obtain
βt = Fp−1βt−p+1 +
p−2

i=1
Fiζt−i.
(3.35)
Then, with the deﬁnition of Yt above and from the deﬁnition of the observability
matrix O, we have
Yt =
⎡
⎢⎢⎢⎣
x⊤
x⊤F
...
x⊤Fp−1
⎤
⎥⎥⎥⎦βt−p+1 +
⎡
⎢⎢⎢⎣
ϵt−p+1
x⊤ζt−p+2 + ϵt−p+2
...
p−2
i=0 x⊤Fiζt−i + ϵt
⎤
⎥⎥⎥⎦= Oβt−p+1 + Et.
Now, since the model is observable, O has full rank, and hence βt−p+1 = O−1Yt −
O−1Et, and substituting this into (3.35), we obtain
βt = Fp−1O−1Yt + ωt,

102
3
The Kalman Filter
where ωt = p−2
i=0 Fiζt−i −Fp−1O−1Et. We note that ωt has a bounded covariance
matrix C = Var(Et), which is a function of σ 2 and Z.
We will show that 0 ≤Pt|t ≤C. Indeed, as Pt|t is a covariance matrix, it is
non-negative deﬁnite matrix, hence Pt|t ≥0. From the deﬁnition of yt, conditioning
on y1:t implies conditioning on yt. Hence
Pt|t = Var(βt | y1:t) ≤Var(βt | Fp−1O−1Yt) = Var(ωt) = C.
This establishes that the sequence {Pt|t} is bounded.
Proceeding now to monotonicity, deﬁne the information ˜yd:t
= {βd, yd+1,
. . . , yt}, which includes the state vector βd and data yd+1 up to and including yt, for
any d = 0, 1, . . ., t −1. From the tower property (5b) (Sect. 2.3), we have
Var(βt | y1:t) = E[Var(βt | ˜yd:t, y1:t) | y1:t] + Var[E(βt | ˜yd:t, y1:t) | y1:t].
(3.36)
Note that ˆβt|t is a linear function of ˆβd|d, yd+1, . . . , yt and that given ˜yd:t, βd is
known. Then, we have
E(βt | ˜yd:t, y1:t) = E(βt | ˜yd:t) =
t−d+1

i=0
bt−d,iyt−i + Bt−dβd,
(3.37)
for some vectors bt−d,i and matrix Bt−d. For any 0 ≤d ≤t −1, we write P∗
t|t =
Var(βt | ˜y0:t); P∗
t|t does not depend on the actual values of ˜y0:t, but only on the time
t. Then from (3.37), we have
E[Var(βt | ˜yd:t) | y1:t] = Var(βt | ˜yd:t) = Var(βt−d | ˜y0:t−d) = P∗
t−d|t−d.
All state space models can be classiﬁed in the following three cases:
1. P0|0 = P∗
0|0 so that P0|0 = 0 and y1:t ≡˜y0:t.
Using (3.36), we obtain
P∗
t|t = E[Var(βt | ˜yd:t) | ˜y0:t] + Var[E(βt | ˜yd:t) | ˜y0:t]
= P∗
t−d|t−d + Var(Bt−dβd | ˜y0:t)
(3.38)
≥P∗
t−d|t−d.
Thus the sequence {P∗
t|t} is monotonic (non-increasing), and from Pt|t = Var(βt |
y1:t) = Var(βt | ˜y0:t) = P∗
t|t, it follows that {Pt|t} is monotonic too. Since {Pt|t}
is bounded and monotonic, it follows that limt→∞Pt|t = limt→∞P∗
t|t exists.
Equation (3.38) implies
lim
t→∞Var(Bt−dβd | ˜y0:t) = 0.
(3.39)

3.5
Steady State of the Kalman Filter
103
2. Let now P0|0 > 0 (positive deﬁnite) and σ 2 > 0 and Z > 0. First we see that
from (3.39),
Var((Bt−dβd | y1:t) = E[Var(Bt−dβd | ˜y0:t) | y1:t]
+Var[E(Bt−dβd | ˜y0:t) | y1:t]
→0
as t →∞.
This together with (3.36) and (3.38) implies
Pt|t = Var(βt | y1:t)
= E[Var(βt | ˜yd:t) | y1:t] + Var[E(βt | ˜yd:t) | y1:t]
= P∗
t−d|t−d + Var(Bt−dβd | y1:t) →P∗.
3. Finally, let σ 2Z ≯0 or that either σ 2 = 0 or Z is positive semi-deﬁnite (a non-
negative deﬁnite matrix, which is not positive deﬁnite). Deﬁne σ 2(z) = σ 2 + z
and Z(z) = Z + zI, for some 0 ≤z < 1. We have the following:
a. The limit limt→∞P∗
t|t(0) exists from (1).
b. From (2), the limit limt→∞Pt|t(z) = P∗(z) exists for all 0 < z < 1 because
σ 2(z) > 0 and Z(z) > 0.
c. {Pt|t(z)} is bounded, continuous in z and monotonic in z. Thus, as t →∞,
Pt|t(z) converges uniform ally to P(z) and
lim
t→∞Pt|t = lim
t→∞lim
z→∞Pt|t(z) = lim
z→∞P∗(z) = P∗(0) = P∗.
To sum up the above proves that in each case limt→∞Pt|t exists and it is equal to
limt→∞P∗
t|t = P∗. This implies that the limit of Pt|t does not depend on the initial
prior P0|0.
⊓⊔
Some comments are in order.
1. With the conditions of Theorem 3.7, the limit P satisﬁes the algebraic Riccati
equation
P = FPF⊤+ Z + [x⊤(FPF⊤+ Z)x + σ 2]−1(FPF⊤+ Z)xx⊤(FPF⊤+ Z),
which is a direct consequence of the posterior covariance updating of Pt|t and
the existence of limt→∞Pt|t = P. This solution may be solved analytically in
simple cases, such as in the local level model of Sect. 3.5.2, but in general one
needs to resort to numerical methods for the calculation of P.

104
3
The Kalman Filter
2. With the conditions of Theorem 3.7, it follows that the following limits exist and
do not depend on the prior covariance matrix P0|0:
a. limt→∞Pt|t−1 = FPF⊤+ Z;
b. limt→∞qt|t−1 = q = x⊤(FPF⊤+ Z)x + σ 2;
c. limt→∞Kt = K = q−1(FPF⊤+ Z)F.
3. The steady state of the Kalman ﬁlter is
ˆβt|t = F ˆβt−1|t−1 + K(yt −x⊤F ˆβt−1|t−1),
just by replacing Pt|t by its limit P in ˆβt|t.
3.6
Exercises
1. For a time series {yt}, we ﬁt a state space model with p = 1, xt = 1, Ft = 1,
σ 2 = 200 and Zt = 10. Given that the ﬁltered distribution at t is βt | y1:t ∼
N(300, 40):
a. write down the observation and transition equations of the state space model.
b. what are the two-step ahead forecast distribution for βt+2 | y1:t and the
predictive distribution for the sum S | y1:t, where S = yt+1 + yt+2?
c. show that Cov(βt+2, S) = 110 and hence, or otherwise, obtain the joint
distribution of (βt+2, S)T .
2. Consider the time series {yt} generated by the state space model with xt = 1,
Ft = λ, σ 2, Zt = Z, where the variances σ 2 and Z and the constant λ are all
known. Deﬁne the time series
zt = yt −λyt−1.
a. Write down the observation and evolution equations of the state space model
of yt.
b. By obtaining the mean and the variance of zt together with the autocovari-
ances Cov(zt, zt−k), for integer k or otherwise, deﬁne the joint probability
distribution of the time series {zt}.
3. A simple model for the number ut of unemployed people in a region in month t
is as follows. It ignores discreteness and supposes that each month a proportion
α, (0 < α < 1), of the unemployed ﬁnd work, so that
ut = (1 −α)ut−1 + nt,

3.6
Exercises
105
where nt is the number becoming newly unemployed during month t. In turn,
nt is assumed to vary around a constant number ν according to
nt = ν + ηt,
where {ηt} is a sequence of independent Gaussian innovations N(0, σ 2
η ).
Because of statistical difﬁculties, ut is never recorded exactly: the recorded
number of unemployed in month t, yt, is related to it by
yt = ut + ϵt,
where {ϵt} is a sequence of independent Gaussian innovations N(0, σ 2
ϵ ).
a. Show that if βt = (ut, ν)⊤, the system can be described by
yt = x⊤
t βt + ϵt
and
βt = Ftβt−1 + ζt,
where xt is a constant vector, Ft is a constant matrix and ζt is a random
vector. Give the values of xt and Ft, and write down the mean vector and
covariance matrix of ζt.
b. Show that, if α and ν are known, the Kalman Filter prediction equations
imply that the one-step forecast ˆut+1|t of the number of people unemployed
at time t + 1 given an estimate ˆut|t of the number unemployed at time t is
ˆut+1|t = (1 −α)ˆut|t + ν.
c. Suppose it is known that α = 0.05, ν = 0.2 and σ 2
ϵ
= σ 2
η = 0.005,
where units of measurement are millions of unemployed. At time t = 0, it is
estimated that u0 = 0.7 with estimation variance 0.01. Use this information
to predict the value of U1, and give the standard deviation of the associated
prediction error.
d. If the number of unemployed at time t = 1 were subsequently recorded
as y1 = 0.85, would your prediction of u1 need to be revised upwards or
downwards, and by how much? Give reasons for your answer.
4. A company trades 10 products, with the i-th product projected to give a return
rit at time t, for i = 1, 2, . . ., 10. The company believes that each of these
returns rit follows an autoregressive process
rit = 0.9ri,t−1 + ζit,
where ζit is a white noise with variance 1, ζit ∼N(0, 1), and ζit is independent
of ζjt, for any i ̸= j.

106
3
The Kalman Filter
Due to a data recording error, rit is not available. However, the aggregate return
can be observed subject to additive noise, according to the model
yt =
10

i=1
rit + ϵt,
where ϵt is a white noise with variance 1, ϵt ∼N(0, 1), and it is assumed that
ϵt is independent of ζit, for any t and for any i.
a. Deﬁne the state
βt =
10

i=1
rit.
Show that yt follows a state space model
yt = xβt + ϵt
βt = Fβt−1 + ζt,
and determine x, F, ζt and the variance of ζt.
b. A prior distribution for β0 is set as
β0 ∼N(0, 100).
If the ﬁrst observation is y1 = 2, perform the Kalman ﬁlter iteration for
t = 1 and obtain the posterior distribution of
β1 | {y1 = 2}.
c. Using the result in (b), obtain a 95% predictive interval for y2.
d. Describe brieﬂy what is the likely effect on the posterior distribution of βt
(for large t), if the prior distribution of β0 changes from (i) β0 ∼N(0, 1) to
(ii) β0 ∼N(0, 1000).
5. It is well known that an economy’s growth as measured by gross domestic
product (GDP) is related to unemployment rate. Arthur Okun studied how much
GDP is likely to fall, if unemployment increased by a certain level. Let yt
denote the GDP growth of the UK economy at time t, and let xt denote the
unemployment rate at time t. A simple regression between the two can reveal
the likely decrease of the GDP growth, for an increase of the unemployment
rate. However, a more elaborate analysis considers the following dynamic
regression model:
yt = α + γtxt + ϵt,

3.6
Exercises
107
where α is a static intercept, ϵt is a Gaussian white noise with variance 1 and γt
is a time-varying slope, which follows the autoregressive model
γt = 0.3γt−1 + νt,
with νt a Gaussian white noise with variance 2. It is further assumed that ϵt and
νs are independent for any t, s and that γ0 is independent of νt, for any t.
a. Deﬁne the state vector
βt =

 α
γt

.
Write the above model in state space form,
yt = L⊤
t βt + κt,
βt = Fβt−1 + ζt,
and determine the design vector Lt and the evolution matrix F. Write down
κt and ζt and obtain their distributions.
b. The above state space model is ﬁtted to data of length n. The posterior
distribution of βn, given information y1:n = {y1, . . . , yn}, is
βn | y1:n ∼N
(
−1.5
3

,

 1 0
0 10
)
.
If xn+1 = 0.5 and yn+1 = 1, then obtain the posterior distribution p(βn+1 |
y1:n+1) of βn+1, given information y1:n+1. Provide a 95% credible interval
for γn+1, given y1:n+1.
6. Prove theoretically the claim of Example 3.3, that the k-step ahead forecast
mean in a local level model does not depend on k and that the k-step forecast
variance is increasing with k. In particular, considering the local level model:
yt = βt + ϵt
and
βt = βt−1 + ζt,
where ϵt and ζt are independent, ϵt ∼N(0, σ 2) and ζt ∼N(0, Z), show that
the k-step ahead forecast mean and variance of yt+k are
ˆyt+k|t = ˆβt|t
and
qt+k|t = Pt|t + σ 2 + kZ,
for any k = 1, 2, . . .. Thus, show that for ﬁxed t, limk→∞qt+k|t = ∞. What do
you learn about the local level model forecast ability? Explain why the above
local level model is also referred to as steady forecasting model.

108
3
The Kalman Filter
7. Using R, simulate 200 values of the state space model with p = 3. Using a
simulated data y1, . . . , y200, calculate in R the ﬁltered mean vector ˆβt|t and the
covariance matrix Pt|t. Make a plot of the one-step ahead predictions ˆyt|t−1
against the actual data yt, and comment on the goodness of ﬁt. Using R,
calculate a 99% prediction interval of y201, based on data y1:200.
8. The following table gives 20 observations from a time series {yt}:
yt
t = 1 −10
10 11 11 9
7 9 5
8 8 10
t = 11 −20 12 11 12 13 10 9 11 12 8 9
a. Put the data in R and make a time series plot of the data.
b. In R, ﬁt a local level model with σ 2 = 1, Z = 1, ˆβ0|0 = 0 and P0|0 = 100,
and provide ﬁltered and smoothed estimates of the level βt. How do the
ﬁltered estimates compare to the smoothed estimates of the level?
c. Produce one-step forecasts at each time point t, and comment on the
goodness of ﬁt.
d. Repeat (b)–(c) with Z = 10 and comment.
9. In the context of the state space model (3.10a)–(3.10b), prove that the posterior
covariance matrix Pt|t can alternatively be updated via the recursion
P−1
t|t = P−1
t|t−1 + xtx⊤
t /σ 2,
where Pt|t−1 is given by the Kalman ﬁlter (Theorem 3.2). Thus, provide an
alternative recursion for the Kalman ﬁlter.
10. In the local level model of Exercise 3.5, show that the smoothed variance Pt|n
can be approximated as
Pt|n = LZ + L2Pt+1|n,
where L the limit of Lt (see Theorem 3.4) is equal to
L = (
√
Z + 4σ 2 −
√
Z)2
4σ 2
.
Expand Pt|n above, and take its limit as t →∞to show that the smoothed
variance converges approximately to
lim
t→∞Pt|n =
4σ 2Z(
√
Z + 4σ 2 −
√
Z)2
16σ 4 −(
√
Z + 4σ 2 −
√
Z)4 .

3.6
Exercises
109
11. Suppose that the time series {yt} is generated by the local level model
yt = βt + ϵt
and
βt = βt−1 + ζt,
where ϵt and ζt are independent, ϵt ∼N(0, σ 2) and ζt ∼N(0, Z).
Based on observed data y1:n = {y1, y2, . . . , yn}, let ˆβt|n denote the smoothed
mean of βt at time t and ˆβt|t denote the posterior mean of βt at time t.
a. Show that
| ˆβt|n −ˆβt|t| <
n

i=t+1
|ei|
and
| ˆβt|n −ˆβt+1|n| <
n

i=t+1
|ei|,
where ei is the residual at time i = t + 1, . . . , n.
b. If
|ei| < 1
n2 ,
for each i, then show that ˆβt|n converges to ˆβt|t as n →∞.
Give reasoning to the following statement: ‘As t is closer to n we expect the
smoothed mean ˆβt|n to be closer to the posterior mean ˆβt|t; as t is far apart
from n, then ˆβt|n will be much more accurate compared to ˆβt|t’.
12. Consider the state space model (3.10a)–(3.10b) with
xt =

 γ
0

,
Ft =

1 λ
0 1

and
Zt =

 Z1 0
0 Z2

,
for some γ, λ ∈R and Z1, Z2 ≥0.
Show that if γ ̸= 0 and λ ̸= 0, then the limit of Pt|t exists, as t →∞.
13. Consider the observable state space model
yt = xβt + ϵt
and
βt = Fβt−1 + ζt,
where ϵt and ζt are independent, ϵt ∼N(0, σ 2) and ζt ∼N(0, Z). Assume
as usual the initial distribution β0 ∼N( ˆβ0|0, P0|0), for some known mean ˆβ0|0
and variance P0|0.
Show that the limit of the posterior variance Pt|t = Var(βt | y1:t) exists and is
equal to
lim
t→∞Pt|t =
σ 2
2x2F 2

1
(px2 −F 2 + 1)2 + 4px2F 2 + F 2 −px2 −1

,
where p = Z/σ 2. Observe that for x = F = 1, the above result reduces to the
steady state of the local level model (see Sect. 3.5.2 ).

Chapter 4
Model Speciﬁcation and Model
Performance
The previous chapter studies estimation procedures for the general state space
model, assuming that the design vector xt, the transition matrix Ft, the observation
variance σ 2 and the transition covariance matrix Zt, as well as the prior mean vector
ˆβ0|0 and the prior covariance matrix P0|0, are all known. This chapter discusses how
these components may be chosen, either estimated using the data or speciﬁed by the
user and how their choice may affect the performance of the model.
The successful application of the Kalman ﬁlter and the related estimation
procedures of Chap. 3 require careful speciﬁcation of these components. Some of
these (xt and Ft) are usually implied by the desired model, while others (such as σ 2
and Zt) are harder to specify. For the former, we give several particular models
in Sect. 4.1, which reveal some of the wealth of state space models. Examples
include trend, seasonal, dynamic regression, autoregression and regression with
autocorrelated errors. The inverse problem that of decomposing a given state space
model to simpler component state space models is discussed in Sect. 4.2.2.
Even though the above components may be implied by a particular state space
model, they are likely to depend on hyperparameters. More generally, any of
the model components may depend on hyperparameters, whose estimation plays
a critical role in the application of the Kalman ﬁlter. In Sect. 4.3 we discuss
three approaches: maximum likelihood estimation (aimed at general application),
speciﬁcation of Zt using discount factors and estimation of σ 2 using Bayesian
conjugate methods. After all these components are speciﬁed, model performance
can be judged by using residual or error analysis. This is the subject of Sect. 4.4.
Section 4.5 discusses prior speciﬁcation, i.e. speciﬁcation of ˆβ0|0 and P0|0, as well as
of any other relevant prior quantities. Finally, Sect. 4.6 discusses automatic model
monitoring, with the emphasis placed on outlier detection and sequential model
performance.
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2021
K. Triantafyllopoulos, Bayesian Inference of State Space Models, Springer Texts
in Statistics, https://doi.org/10.1007/978-3-030-76124-0_4
111

112
4
Model Speciﬁcation and Model Performance
4.1
Speciﬁcation of Model Components
Suppose we wish to set up a state space model (3.10a)–(3.10b) as deﬁned in
Sect. 3.1.3. In the implementation of this model and the application of the Kalman
ﬁlter or the other estimation algorithms, presented in Chap. 3, we need to specify the
model components xt, Ft, σ 2 and Zt (see Sect. 3.1.3). As already noted in Chap. 3,
some of these components may be time-invariant and according to what type of
data we wish to model, xt and Ft (the design vector and the transition matrix,
respectively) will take particular forms. For example, for the local level model of
Sect. 3.1.3 we have xt = Ft = 1. In other situations, such as in dynamic regression,
xt will include known covariates, to which yt is related, and thus in model (3.9a)–
(3.9b) we know xt and we set Ft = I to deﬁne a random walk evolution for the
states βt. In the next sections we describe particular forms of state space models,
which reveal particular forms of the components xt and Ft.
4.1.1
Trend State Space Models
Trend state space models refer to models that are capable of analysing data that are
expected or believed to follow a trend. The term “trend” here is understood as a
polynomial function in time t, e.g. a straight line, a quadratic and cubic. Data that
can be analysed using trend models may include economic time series, or other data
that exhibit growth or decline over the course of time.
Example 4.1 (Aluminium Prices Data) Figure 4.1 depicts spot prices of aluminium
over the time period 4 January 2005 to 31 October 2005. Aluminium, a non-
ferrous metal, trades daily at the London metal exchange, for information in
which the reader is referred to http://www.lme.com/. Figure 4.1 graphs aluminium
prices, excluding bank holidays and weekends, and shows initially some random
ﬂuctuation, followed by an upward linear trend (March–April), followed by a
linear fall (May–June), followed by some random ﬂuctuation (June–July), followed
by some increasing and then decreasing trend (August–September), and ﬁnally
followed by a linear trend (October).
Linear Growth Model
The ﬁrst state space model we consider is the so-called linear growth or local linear
trend state space model. This model employs the state space model (3.10a)–(3.10b)
with design vector xt and transition matrix Ft, given by
xt = x =

1
0

and
Ft = F =

 1 1
0 1

.

4.1
Speciﬁcation of Model Components
113
Aluminium price (per tonne)
Trading day
US dollars per tonne
2
4
6
8
10
1700
1750
1800
1850
1900
1950
2000
Fig. 4.1 Aluminium prices (US$ per tonne). The integers in the time axis indicate months in 2005
Thus, by writing the state vector as βt = [β1t, β2t]⊤and the transition innovations
as ζt = [ζ1t, ζ2t]⊤, the model can be written as
yt = x⊤βt + ϵt = [1, 0]

β1t
β2t

+ ϵt = β1t + ϵt,
(4.1a)
βt =

β1t
β2t

=

1 1
0 1
 
 β1,t−1
β2,t−1

+

 ζ1t
ζ2t

,
β1t = β1,t−1 + β2,t−1 + ζ1t,
(4.1b)
β2t = β2,t−1 + ζ2t,
(4.1c)
where as usual ϵt ∼N(0, σ 2), ζt ∼N(0, Zt), with
Zt = Z = Var

 ζ1t
ζ2t

=

 z11,t z12,t
z12,t z22,t

,

114
4
Model Speciﬁcation and Model Performance
where z11,t is the variance of ζ1t, z22,t is the variance of ζ2t and z12,t is the
covariance of ζ1t and ζ2t.
Some comments are in order. The linear growth model is deﬁned by Eqs. (4.1a)–
(4.1c): basically the observations yt ﬂuctuate around β1t—the locally linear level of
the time series—hence the name of the model. The level β1t follows a linear function
(in t) plus random error. To see this write down recursively β1t by replacing β1,t−1
from (4.1b) and β2,t−1 from (4.1c) to get
β1t = β1,t−1 + β2,t−1 + ζ1t
= β1,t−2 + 2β2,t−2 + ζ1t + ζ1,t−1 + ζ2,t−1
= β1,t−3 + 3β2,t−3 + ζ1t + ζ1,t−1 + ζ1,t−2 + ζ2,t−1 + 2ζ2,t−2
= · · ·
= β1,0 + tβ2,0



Linear function
+
t
i=1
ζ1i +
t−1

j=1
jζ2,t−j.



Random error
Thus, we think of yt as ﬂuctuating randomly around the level β1t, which in itself
ﬂuctuates randomly around a linear function of t.
Example 4.2 (Aluminium Prices Data Example Continued) Using the Kalman ﬁlter
we have ﬁtted a linear growth model to the aluminium price data of Example 4.1.
We have used σ 2 = 1 and
Zt =

10 0
0 2

.
First of all we note that Zt is time-invariant and we write Zt = Z. Secondly, we
have assumed that the components β1t and β2t are independent (hence z12,t = 0)
and the variance of ζ1t is larger than that of ζ2t. Also, we have chosen an initial state
β0 =

 β1,0
β2,0

∼N
(
 1800
0

,

 1000
0
0
1000
)
.
From historical data is known that the mean of (yt) ﬂuctuates around 1800 US
dollars. Thus, since β1t is the level of the series (E(yt | β1t) = β1t), a sensible choice
is to set ˆβ1,0|0 to its historical value, i.e. 1800, while ˆβ2,0|0 can take an arbitrary
value (here we have set it to ˆβ2,0|0 = 1). The prior covariance matrix P0|0 is set to
be proportional to the identity matrix (again consistent with a priori independence
of the two components β1,0 and β2,0; the large variances of β1,0 and β2,0 reﬂect on
the associated uncertainty on the speciﬁcation of ˆβ0, prior to observing the data.

4.1
Speciﬁcation of Model Components
115
One-step forecasts againist aluminium prices
Trading day
US dollars per tonne
2
4
6
8
10
1700
1800
1900
2000
Observations
Forecast mean
Fig. 4.2 One-step forecasts of the linear growth model (dashed lines) against the aluminium prices
(solid points)
Figure 4.2 (in next page) plots one-step forecasts of the aluminium price data
described above. The R code used is given below (NB: need ﬁrst to load the R
package gplots).
> # time series data
> alum1 <- read.table("alum.txt")
> alum <- alum1[,2]
> # fit linear trend
> fit <- bts.filter(alum, x0=c(1,2), F0=matrix(c(1,0,1,1),2,2),
+ obsvar=1, Z0=matrix(c(10,0,0,2),2,2), beta0=c(1800,1),
+ P0=1000*diag(2), DISO=FALSE, VAREST=FALSE )
> # define time series objects to be plotted
> alumts <- ts(alum1[,2], start=c(1,4), frequency=22)
> pred <- ts(fit$FittedMean, start=c(1,4), frequency=22)

116
4
Model Speciﬁcation and Model Performance
> # time series plot
> ts.plot(pred, lty=2, col=2, main=expression("One-step forecasts
+ against aluminium prices"),
+ xlab="Trading day",ylab="US dollars per tonne")
> points(alumts, pch=20)
> points(pred, pch=4, col=2)
> legend("bottomright",c("Observations","Forecast mean"),
+ pch=c(20, 4), col=c(1,2))
From Fig. 4.2 we observe that the model seems to ﬁt the data well (the one-step
ahead forecasts seem to match the data well).
Returning to model (4.1a)–(4.1c), we can observe that, based on a data set y1:t =
{y1, . . . , yt}, the forecast function ˆyt+k|t (see Eq. (3.28) in the previous chapter) is
a linear function in k. First from the deﬁnition of F we have
Fk =

 1 k
0 1

.
We prove this by induction. First note that F1 = F and then write
Fk = Fk−1F =

 1 k −1
0
1
 
 1 1
0 1

=

 1 k
0 1

.
From the Kalman ﬁlter we have that βt | y1:t ∼N( ˆβt|t, Pt|t), with ˆβt|t =
[ ˆβ1,t|t, ˆβ2,t|t]⊤. Then from the deﬁnition of the forecast function (see Theorem 3.6)
we obtain
ˆyt+k|t = x⊤
t+kFk ˆβt|t
= [1, 0]

1 k
0 1
 
 ˆβ1,t|t
ˆβ2,t|t

= ˆβ1,t|t + ˆβ2,t|tk,
which is a linear function in k (or a straight line with intercept ˆβ1,t|t and slope ˆβ2,t|t).
Example 4.3 (Aluminium Prices Data Example Continued)
Continuing on the
aluminium prices Example 4.2, we can extract the posterior mean vector at t = 210
(corresponding to the last time point, 31 October 2005), using the R command
> fit$PostMean[[210]]
[,1]
[1,] 1959.51481
[2,]
15.08425
Thus, the forecast function is
ˆy210+k|210 = 1959.51 + 15.08k,
k = 1, 2, . . .

4.1
Speciﬁcation of Model Components
117
2
4
6
8
10
1980
2000
2020
2040
2060
2080
2100
Forecast function for the linear growth model
Lead time (k)
Forecast function
Fig. 4.3 Forecast function for the linear growth model at t = 210
which is plotted in Fig. 4.3, for k = 1, 2, . . . , 10, by using the R commands
> x <- 1959.51 + (1:10) * 15.08
> plot(x, pch=4, xlab="Lead time (i)", ylab="Forecast function",
+
main=expression("Forecast function for the linear growth
+
model"))
We observe that for relatively low values of k, the forecasts are too high
(compared to the past data), which make them unrealistic. As a result, for the
aluminium prices data considered here, a linear growth model is suitable only for
k = 1 (one-step ahead forecasting).
Polynomial Trend State Space Models
The linear growth trend model can be generalised to trend models following higher
order polynomials than linear functions, similar state space models with extensions
are discussed in Godolphin and Harrison (1975) and Godolphin and Stone (1980).
Indeed, the most general model, known as (p −1)-th order polynomial trend model,

118
4
Model Speciﬁcation and Model Performance
employs the state space model (3.10a)–(3.10b) with design vector xt and transition
matrix Ft, given by
xt = x =
⎡
⎢⎢⎢⎣
1
0
...
0
⎤
⎥⎥⎥⎦
and
Ft = F =
⎡
⎢⎢⎢⎣
1 1 0 · · · 0
0 1 1 · · · 0
... ... ... ... ...
0 0 0 · · · 1
⎤
⎥⎥⎥⎦.
(4.2)
If we write βt = [β1t, . . . , βpt]⊤and ζt = [ζ1t, . . . , ζpt]⊤, then in analogy with the
linear growth model, we can write the polynomial trend model as
yt = x⊤βt + ϵt = β1t + ϵt,
(4.3a)
βjt = βj,t−1 + βj+1,t−1 + ζjt,
j = 1, . . . , p −1
(4.3b)
βpt = βp,t−1 + ζpt,
(4.3c)
Usually Zt is set to be diagonal, i.e.
Zt = Var(ζt) = Z =
⎡
⎢⎢⎢⎣
Z1 0 · · · 0
0 Z2 · · · 0
...
... ...
...
0
0 · · · Zp
⎤
⎥⎥⎥⎦,
where Zi is the variance of ζit, for i = 1, . . . , p.
We can observe that model (4.3a)–(4.3c), reduces to the linear growth model
of Eqs. (4.1a)–(4.1c), if p = 2. If p = 3, the 2nd-order polynomial trend model
is known as quadratic growth or quadratic trend. Higher order polynomial trend
models are rarely used in practice, but the general polynomial model given above
offers a generic approach for their study and their understanding.
One important property of the (p −1)-th order polynomial trend model is that
its forecast function is a (p −1)-order polynomial (notice that in the linear growth
this is a straight line, in the quadratic growth this is a quadratic and so forth). Before
we give the general proof we discuss the forecast function of the quadratic growth
(p = 3).
Recall ﬁrst that the forecast function is given by ˆyt+k|t = x⊤
t+kFk ˆβt|t, see
Eq. (3.28) in Sect. 3.4. Then, in analogy with the linear growth model, we can see
that
Fk =
⎡
⎣
1 k k(k −1)/2
0 1
k
0 0
1
⎤
⎦.

4.1
Speciﬁcation of Model Components
119
The proof of this result is done by induction (similarly as in the linear growth
model); for the general proof see below (p. 119).
Then, by writing ˆβt|t = [ ˆβ1,t|t, ˆβ2,t|t, ˆβ3,t|t]⊤, the forecast function is
ˆyt+k|t = x⊤
t+kFk ˆβt|t
= [1, 0, 0]
⎡
⎣
1 k k(k −1)/2
0 1
k
0 0
1
⎤
⎦
⎡
⎣
ˆβ1,t|t
ˆβ2,t|t
ˆβ3,t|t
⎤
⎦
= ˆβ1,t|t +

ˆβ2,t|t −
ˆβ3,t|t
2

k +
ˆβ3,t|t
2
k2,
which is a quadratic in k.
Returning to the general case of the (p −1)-th polynomial trend model, we show
that its forecast function is a (p −1)-order polynomial in k. First we show that with
the transition matrix F deﬁned in Eq. (4.2) above, we have
Fk =
⎡
⎢⎢⎢⎢⎢⎢⎣
1
k
1
 k
2

· · ·
 k
p−1

0 1 k
1
 · · ·  k
p−2

0 0
1 · · ·
 k
p−2

...
...
...
...
...
0 0
0 · · ·
1
⎤
⎥⎥⎥⎥⎥⎥⎦
,
(4.4)
where
k
i
	
= 0,
for i > k.
The proof is by induction. From the deﬁnition of F, it is trivial to check that (4.4)
is true for k = 1. Assuming that (4.4) is true for k, we will show that it is also true
for k + 1. We have
Fk+1 = FkF
=
⎡
⎢⎢⎢⎢⎢⎢⎣
1
k
1
 k
2

· · ·
 k
p−1

0 1 k
1
 · · ·  k
p−2

0 0
1 · · ·
 k
p−2

...
...
...
...
...
0 0
0 · · ·
1
⎤
⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎣
1 1 0 · · · 0
0 1 1 · · · 0
0 0 1 · · · 0
...
...
... ... ...
0 0 0 · · · 1
⎤
⎥⎥⎥⎥⎥⎦

120
4
Model Speciﬁcation and Model Performance
=
⎡
⎢⎢⎢⎢⎢⎢⎣
1 1 +
k
1
 k
1

+
k
2

· · ·
 k
p−2

+
 k
p−1

0
1
1 +
k
1

· · ·
 k
p−3

+
 k
p−2

0
0
1
· · ·
 k
p−4

+
 k
p−3

...
...
...
...
...
0
0
0
· · ·
1
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
1
k+1
1
 k+1
2

· · ·
k+1
p−1

0
1
k+1
1

· · ·
k+1
p−2

0
0
1
· · ·
k+1
p−2

...
...
...
...
...
0
0
0
· · ·
1
⎤
⎥⎥⎥⎥⎥⎥⎦
,
because for each i = 1, 2, . . . , p we have
 k
i −1
	
+
k
i
	
=
k!
(i −1)!(k −i)!

1
k + 1 −i + 1
i
	
=
(k + 1)!
i!(k + 1 −i)! =
k + 1
i
	
.
Thus, (4.4) is true for any k ≥1.
Now write the posterior mean at time t as ˆβt|t = [ ˆβt|t,1, . . . , ˆβt|t,p]⊤. With Fk in
place, the k-step forecast function of the polynomial trend model is
ˆyt+k|t = x⊤Fk ˆβt|t
= [1, 0, 0, . . ., 0]
⎡
⎢⎢⎢⎢⎢⎢⎣
1
k
1
 k
2

· · ·
 k
p−1

0 1
k
1

· · ·
 k
p−2

0 0
1 · · ·
 k
p−2

...
...
...
...
...
0 0
0 · · ·
1
⎤
⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎣
ˆβt|t,1
ˆβt|t,2
ˆβt|t,3
...
ˆβt|t,p
⎤
⎥⎥⎥⎥⎥⎥⎦
=
p

i=1
ˆβt|t,i
 k
i −1
	
= c1t + c2tk + c3tk2 + · · · + cptkp−1,
where the coefﬁcients cit depend on ˆβt|t, but not on k. The examples of linear growth
(p = 2) and quadratic trend (p = 3) give expressions of the values of cit.
4.1.2
Superposition of State Space Models
An important model building tool, known as the superposition of state space models,
suggests that complex models are built as the sum of simple state space models.

4.1
Speciﬁcation of Model Components
121
State space superpositions are discussed in detail in West and Harrison (1997,
Section 6.2.1) or in Petris (2010, Section 3.2).
Consider N time series {yit} (i = 1, . . . , N), each of which following a state
space model, deﬁned by equations
yit = x⊤
it βit + ϵit,
ϵit ∼N(0, σ 2
i ),
(4.5a)
βit = Fitβi,t−1 + ζit,
ζit ∼N(0, Zit),
(4.5b)
with the initial state βi,0 ∼N( ˆβi,0|0, Pi,0|0), for some mean vector ˆβi,0|0 and
covariance matrix Pi,0|0. For each i, the innovations ϵit and ζit are assumed
individually and mutually independent (as in the deﬁnition of the state space model
in Sect. 3.1.3). Furthermore, it is assumed that the N models are independent, i.e.
ϵit is independent of ϵjs, for any i, j = 1, . . . , N and for any t, s = 1, . . ., and ζit
is independent of ζjs, for any i, j = 1, . . . , N and for any t, s = 0, 1, . . ..
Then the time series {yt} deﬁned as the sum of y1t, . . . , yNt,
yt =
N

i=1
yit,
(4.6)
follows a state space model (3.10a)–(3.10b), with state vector βt and innovations ϵt
and ζt, deﬁned by
βt =
⎡
⎢⎢⎢⎣
β1t
β2t
...
βNt
⎤
⎥⎥⎥⎦,
ϵt =
N

i=1
ϵit,
ζt =
⎡
⎢⎢⎢⎣
ζ1t
ζ2t
...
ζNt
⎤
⎥⎥⎥⎦.
The design vector xt and the transition matrix Ft of yt are
xt =
⎡
⎢⎢⎢⎣
x1t
x2t
...
xNt
⎤
⎥⎥⎥⎦,
Ft =
⎡
⎢⎢⎢⎣
F1t
0 · · ·
0
0 F2t · · ·
0
...
...
...
...
0
0 · · · FNt
⎤
⎥⎥⎥⎦.
Finally, from the deﬁnitions of ϵt and ζt and the independence assumption, it follows
that
σ 2 =
n

i=1
σ 2
i
and
Zt =
⎡
⎢⎢⎢⎣
Z1t
0 · · ·
0
0 Z2t · · ·
0
...
...
...
...
0
0 · · · ZNt
⎤
⎥⎥⎥⎦.

122
4
Model Speciﬁcation and Model Performance
The proof of the above result follows by noticing that from (4.6) and the individual
N models the observation equation of yt is
yt =
N

i=1

x⊤
it βit + ϵit

= [x⊤
1t, x⊤
2t, . . . , x⊤
Nt]
⎡
⎢⎢⎢⎣
β1t
β2t
...
βNt
⎤
⎥⎥⎥⎦+
N

i=1
ϵit = x⊤
t βt + ϵt,
with xt, βt, ϵt as deﬁned earlier. Also from the transition equation of the individual
models (4.5b) βit = Fitβi,t−1 + ζit, we have
βt =
⎡
⎢⎢⎢⎣
β1t
β2t
...
βNt
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
F1t
0 · · ·
0
0 F2t · · ·
0
...
...
...
...
0
0 · · · FNt
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
β1,t−1
β2,t−1
...
βN,t−1
⎤
⎥⎥⎥⎦+
⎡
⎢⎢⎢⎣
ζ1t
ζ2t
...
ζNt
⎤
⎥⎥⎥⎦
= Ftβt−1 + ζt,
which establishes the transition equation of the model for yt.
An important property of the superposition described above is that the k-step
forecast distribution of yt can be obtained by adding separately the respective
forecast distributions of the N individual models. In particular, the forecast function
of yt is the sum of the forecast functions of y1t, . . . , yNt. This follows from (4.6) by
taking expectations:
ˆyt+k|t = E(yt+k | y1:t) = E
 N

i=1
yi,t+k | y1:t

=
N

i=1
E(yi,t+k | yi,1:t)
=
N

i=1
ˆyi,t+k|t,
(4.7)
where ˆyi,t+k|t is the forecast function of the time series yit, for i = 1, . . ., N. In
a similar way and by using the assumption of independence of the N individual
models, it follows that the k-step forecast variance of yt is the sum of the forecast
variances of the N individual models, i.e. qt+k|t = N
i=1 qi,t+k|t. Since yt is
a sum of y1t, . . . , yNt, each of which follows a Gaussian forecast distribution,
the distribution of yt+k | y1:t is Gaussian too, thus we have the result yt+k |
y1:t
∼N( ˆyt+k|t, qt+k|t), for k = 1, 2, . . .. These results are very important
for forecasting; according to the above, we can build complex forecast functions
by composing forecast functions of simple individual models (such as trend and
seasonal models, see the following sections). An important consequence is that
if there is a deterioration in model performance (e.g. experiencing high forecast

4.1
Speciﬁcation of Model Components
123
errors), the modeller needs to look at the individual models and ﬁx the problem
only for those component models that are responsible.
The above principle of superposition is relevant to the so-called structural time
series models, which comprise a superposition of several individual models, for
more details of which the reader is referred to Harvey (1989) or Durbin and
Koopman (2012).
Example 4.4 Suppose we have data that we believe is comprised of local level
or random variation and linear trend. Such a data set could be for example, the
aluminium prices of Example 4.1, where in the start of the series a local level
variation seems more persistent, followed by a linear trend. In such a case we could
consider for yt (the price per tonne of aluminium), the observation equation
yt = [x1t, x⊤
2t]

β1t
β2t

+ ϵt =

1, 1, 0

⎡
⎣
β1t
β1,2t
β2,2t
⎤
⎦+ ϵt = β1t + β1,2t + ϵt
(4.8)
and transition equation
βt =
⎡
⎣
β1t
β1,2t
β2,2t
⎤
⎦=
⎡
⎣
1 0 0
0 1 1
0 0 1
⎤
⎦
⎡
⎣
β1,t−1
β1,2,t−1
β2,2,t−1
⎤
⎦+
⎡
⎣
ζ1t
ζ1,2t
ζ2,2t
⎤
⎦.
We note that the ﬁrst unit in xt = x = [1, 1, 0]⊤and the top left unit in the transition
matrix
Ft = F =
⎡
⎣
1 0 0
0 1 1
0 0 1
⎤
⎦
correspond to the local level component model, with transition β1t = β1,t−1 + ζ1t.
The sub-vector [1, 0]⊤of x and the sub-matrix

 1 1
0 1

of F correspond to the linear growth component model, with transition

 β1,2t
β2,2t

=

 1 1
0 1
 
β1,2,t−1
β2,2,t−1

+

 ζ1,2t
ζ2,2t

.
Finally, from (4.8), we see that yt is a sum of a local level (β1t) and a linear growth
component (β1,2t).

124
4
Model Speciﬁcation and Model Performance
4.1.3
Fourier Form Seasonal Models
A seasonal time series is a time series which exhibits some periodicity, i.e. it
includes patterns that, subject to random error, are repeating over a period of time.
The term “seasonality” is used as in many applications, this period represents a sea-
sonal cycle, e.g. quarter, month or annum. Figure 4.4 shows averaged temperatures
collected for each quarter at Weston Park, Shefﬁeld, UK, for unspeciﬁed years. This
data set shows clear evidence of seasonality, as the values of the 1st Quarter of
each year are similar (lower values in the ﬁgure) and of course they are such due
to the effect of the winter months in the ﬁrst quarter. Likewise, the third quarter of
each year is responsible for the higher temperature values, being inﬂuenced by the
summer months.
There are several types of state space models that describe seasonality. One is
described in the seminal paper of Harrison and Stevens (1976), and it makes use
of cyclical transition matrices; for a detailed discussion of this approach the reader
is referred to West and Harrison (1997, Section 8.2). A second popular approach
of modelling seasonality, within the state space framework, is by representing the
seasonal process by a Fourier series. An early study on this area is given in Harrison
Quarterly averaged temperatures in Sheffield
Quarter
Degrees in Celsius
0
10
20
30
40
50
60
5
10
15
Fig. 4.4 Quarterly mean temperature in Shefﬁeld

4.1
Speciﬁcation of Model Components
125
(1965) and more recent expositions include Harvey (1989), Harvey (2004) and West
and Harrison (1997, Section 8.4). Below, we discuss this approach in some detail.
There are many textbooks discussing Fourier analysis; for an introductory
treatment the reader is referred to Dyke (1999). Formally, a deterministic function
(or sequence, if t is integer) f (·) is periodic with period T , if f (t + T ) = f (t),
for all t. A typical example is a trigonometric function, such as the sine or the
cosine, which have period 2π, i.e. sin(x + 2π) = sin(x). A stochastic process {yt}
is periodic or seasonal with cycle or period T , if the distribution of yt+T is the same
as the distribution of yt. In a nutshell Fourier analysis tells us that periodic stochastic
processes are represented as a weighted sum (possible an inﬁnite sum) of sines and
cosines plus random noise. So even if it is not exact, our function can probably be
accurately reconstructed using a small number of sines and cosines. This sum is then
recast in state space form to provide the required state space model. The technical
details are as follows.
Any deterministic periodic function in L2 (the space of all functions satisfying
*
A |f (t)|2 dt
<
∞, where A is the domain of f (·)), such as f (·) above,
can be represented as a Fourier series, for information of which and details of
convergence see Dyke (1999) or Rudin (1976, Chapter 8). Under some conditions
of convergence, see (Rudin, 1976, Chapter 8) for details, f (t) can be represented by
the Fourier series
a0 +
∞

i=1
[ai cos(iωt) + bi sin(iωt)] ,
where the coefﬁcients a0, ai, bi are known as the Fourier coefﬁcients and they are
calculated as integrals (if t is continuous) or as inﬁnite sums (if t is discrete) of
f (t); for details see Dyke (1999) or Rudin (1976, Chapter 8). Thus, f (t) can be
approximated by the ﬁnite sum SN(t)
SN(t) = a0 +
N

i=1
[ai cos(iωt) + bi sin(iωt)] ,
where a0, a1, . . . , aN and b1, . . . , bN are complex numbers and ω = 2π/T is the
frequency.
In order to be able to approximate a stochastic process {yt} with a Fourier form,
we construct SN(t) by adding noise to it. Since SN(t) is a ﬁnite sum, yt can be
constructed as the superposition of N component state space models; these are
known as harmonic state space models and are described below. The ith time series
yit follows a harmonic state space model, if it is given by Eqs. (4.5a)–(4.5b), with
components
xit = x =

 1
0

and
Fit = Fi =

cos(iω) sin(iω)
−sin(iω) cos(iω)

.
(4.9)

126
4
Model Speciﬁcation and Model Performance
Here yit (i = 1, . . . , N) represents the term ai cos(iωt)+bi sin(iωt) plus noise. To
see this ﬁrst note that with xit as above and from the state space model of yit, we
have
yit = x⊤
it βit + ϵit = βi,1,t + ϵit,
(4.10)
with βit = [βi,1,t, βi,2,t]⊤. Similarly, with Fi as above and from the transition
equation (4.5b) we can write

 βi,1,t
βi,2,t

=

cos(iω) sin(iω)
−sin(iω) cos(iω)
 
 βi,1,t−1
βi,2,t−1

+

 ζi,1,t
ζi,2,t

,
where ζit = [ζi,1,t, ζi,2,t]⊤. This separates out into two equations,
βi,1,t = cos(iω)βi,1,t−1 + sin(iω)βi,2,t−1 + ζi,1,t,
(4.11)
βi,2,t = −sin(iω)βi,1,t−1 + cos(iω)βi,2,t−1 + ζi,1,t.
(4.12)
By iterating these two equations and substituting (4.12) into (4.11), we obtain
βi,1,t = [cos2(iω) −sin2(iω)]βi,1,t−2 + 2 sin(iω) cos(iω)βi,2,t−2 + error
= cos(2iω)βi,1,t−2 + sin(2iω)βi,2,t−2 + error
= · · ·
= cos(iωt)βi,1,0 + sin(iωt)βi,2,0 + error,
(4.13)
where the term error indicates a function of the ζt’s which represents some noise.
From Eqs. (4.10) and (4.13) we see that yit is equal to ai cos(iωt)+bi sin(iωt) plus
noise, where ai = βi,1,0 and bi = βi,2,0.
In order to proceed to the state space representation of the seasonal time series
{yt}, yt is constructed as the superposition of the N harmonic state space models
plus a local level model for a0, i.e. yt = N
i=0 yit, where y0t follows a local level
model and N is deﬁned by
N =
( T/2,
if T is even
(T −1)/2, if T is odd
(4.14)
In case that iω = π (known as the Nyquist frequency), the component state space
model for yit is reduced to
xNt = xN = 1,
FNt = FN = −1,

4.1
Speciﬁcation of Model Components
127
because the transition matrix deﬁned above for iω = π gives
FN =

 −1
0
0 −1

and the second row implies that βN,2,t does not have any contribution to yNt.
Putting all these together, yt is deﬁned by the state space model (3.10a)–(3.10b),
with design vector and transition matrix deﬁned by
xt = x =
⎡
⎢⎢⎢⎢⎢⎣
1
x1
x2
...
xN
⎤
⎥⎥⎥⎥⎥⎦
,
Ft = F =
⎡
⎢⎢⎢⎢⎢⎣
1 0
0 · · · 0
0 F1 0 · · · 0
0 0 F2 · · · 0
...
...
... ...
...
0 0
0 · · · FN
⎤
⎥⎥⎥⎥⎥⎦
,
(4.15)
where N is deﬁned by (4.14) and, for 0 < iω < π, xi, Fi are given by equation
(4.9), while for iω = π, xN = 1, FN = −1, for i = 1, . . . , N. The top unit
element of x and the top left unit element of F correspond to the local level state
space model, used for the estimation of a0. This local level may be replaced by
some other suitable state space model, e.g. a linear growth model, as discussed in
Sect. 4.1.4.
The above state space model is known as the full-effects Fourier form model;
similar models are discussed in West and Harrison (1997, Section 8.6) and Harvey
(2004). We can see that the dimension of x is equal to p = T (using the local level
model for the description of the level of the series). This follows as for odd T , there
are (T −1)/2 seasonal components x2, x3, . . . , xN and each xi is a bivariate vector,
so that p = T −1 + 1 = T . Likewise, we can see that when T is even, there are
(T −2)/2 bivariate vectors xi plus a scale xN (for the Nyquist frequency) plus the
local level component amounting to N = T −2 + 1 + 1 = T .
From the above it is clear that in some cases, in particular when the period T
takes a large value, the full-effects model, deﬁned above, is not practical to use,
because the dimension p is too large. For example, suppose that yt represents a time
series measured at daily frequency and exhibiting annual seasonality. In this case
T = p = 365, implying that the state vector βt has dimension 365 × 1 and the
transition matrix Ft has dimension 365 × 365. These dimensions appear to be too
large, and although modern computing systems can handle computations with such
dimensions well, it seems reasonable to make an effort to reduce the value of p.
The high dimension of βt implies higher uncertainty about the speciﬁcation of the
distribution of ζt (in particular regarding the transition covariance matrix Zt) and
high uncertainty around the estimation of βt. Such a dimensionality reduction may
be carried out by simply replacing N by N1 << N and thus resulting in what is
known a reduced Fourier form model. The choice of N1 is done by experimentation
(or using error analysis criteria). More details of reduced Fourier state space models
can be found in West and Harrison (1997, Section 8.6.6).

128
4
Model Speciﬁcation and Model Performance
Example 4.5 (Shefﬁeld Temperature Data)
We consider the data of the Shefﬁeld
temperatures {yt} described in the start of this section; see Fig. 4.4. These are
quarterly data comprising of averaged daily temperatures (in ◦C). Since the data
are quarterly, the period is T = 4 and the frequency is ω = 2π/4 = π/2. For this
data we propose a local level full seasonal Fourier state space model, so that yt is
deﬁned by equations (3.10a)–(3.10b) with
xt = x =
⎡
⎢⎢⎣
1
1
0
1
⎤
⎥⎥⎦
and
Ft = F =
⎡
⎢⎢⎣
1
0 0
0
0
0 1
0
0 −1 0
0
0
0 0 −1
⎤
⎥⎥⎦.
The units on the top of x and top left of F correspond to the local level, while the
sub-vector [1, 0, 1]T and the sub-matrix
⎡
⎣
0 1
0
−1 0
0
0 0 −1
⎤
⎦
correspond to the seasonal variation.
The observation variance and the transition covariance matrix are set to σ 2 = 1
and Zt = Z = 100I, while the initial state is set to β0 ∼N{[0, 0, 0, 0]T , 1000I}.
Figure 4.5 shows the one-step forecasts ˆyt|t−1 against the actual values of yt, for
t = 1, . . . , 64. We observe that the estimates follow closely the data, except of the
ﬁrst four observations. These four observations may be considered as a training data
set, which are required for the model to adapt to the data; it is remarkable to note
that only four observations are needed for this training stage, after which the model
seems to ﬁt well to the data. To ﬁt this model in R, we used the commands
> # load Sheffield temperatures data
> sheftemq <- scan("Sheftemq.txt")
> # define transition matrix
> F1 <- matrix(c(1))
> F2 <- matrix(c(0,-1,1,0),2,2)
> F3 <- matrix(c(-1),1)
> F0 <- blockDiagMat(F1,F2,F3)
> # fit the state space model
> fit <- bts.filter(sheftemq, x0=c(1,1,0,1), F0=F0,
+ Z0=100*diag(4), obsvar=1, beta0=rep(0,4), P0=1000*diag(4),
+ DISO=FALSE, VAREST=FALSE)
# time series plot
> pred <- ts(fit$FittedMean)
> ts.plot(pred, lty=2, col=2, main=expression("One-step forecasts
+ of the temperatures in Sheffield"),xlab="Quarter",

4.1
Speciﬁcation of Model Components
129
One-step forecasts of the temperatures in Sheffield
Quarter
Degrees in Celsius
0
10
20
30
40
50
60
0
5
10
15
Observations
Forecast mean
Fig. 4.5 Smoothed predictions (dashed line) against the actual average temperatures (solid line)
+ ylab="Degrees in Celsius")
> points(sheftemq, pch=20)
> points(pred, pch=4, col=2)
> legend("bottomright",c("Observations","Forecast mean"),
+ pch=c(20, 4), col=c(1,2))
We close this section by deriving the forecast function ˆyt+k|t of the seasonal time
series yt. Suppose that a collection of data y1:t = {y1, . . . , yt} is obtained. Based
on this information, using the Kalman ﬁlter we can obtain the posterior mean vector
of βt, ˆβ⊤
t|t = [ ˆβ0,t|t, ˆβ⊤
1,t|t, . . . , ˆβ⊤
N,t|t], where ˆβi,t|t = [ ˆβi,1,t|t, ˆβi,2,t|t]T , being the
posterior mean vector of βit and ˆβ0,t|t being the posterior mean of β0t. First we
derive the forecast function of each individual model. To this end, ﬁrst we prove
that with the deﬁnition of Fi as above, we have
Fk
i =

cos(kiω) sin(kiω)
−sin(kiω) cos(kiω)

.
(4.16)

130
4
Model Speciﬁcation and Model Performance
The proof is inductive. First note that (4.16) is true for k = 2. This is done by direct
matrix multiplication, i.e.
F2
i = FiFi =

cos(2iω) sin(2iω)
−sin(2iω) cos(2iω)

.
Suppose now that (4.16) is true for k −1. Next we prove that (4.16) is true for k. We
have
Fk
i = Fk−1
i
Fi =

cos(k −1)iω sin(k −1)iω
−sin(k −1)iω cos(k −1)iω
 
cos(iω) sin(iω)
−sin(iω) cos(iω)

=

cos(k −1)iω cos(iω) −sin(k −1)iω sin(iω)
−sin(k −1)iω cos(iω) −cos(k −1)iω sin(iω)
cos(k −1)iω sin(iω) + sin(k −1)iω cos(iω)
cos(k −1)iω cos(iω) −sin(k −1)iω sin(iω)

,
which validates (4.16), if we write down the following trigonometric formulae
cos(kiω) = cos[(k −1)iω + iω] = cos(k −1)iω cos(iω) −sin(k −1)iω sin(iω),
sin(kiω) = sin[(k −1)iω + iω] = cos(k −1)iω sin(iω) + sin(k −1)iω cos(iω).
After establishing (4.16), the forecast function of each component yit is
yi,t+k|t = x⊤
i,t+kFk ˆβi,t|t
= [1, 0]

cos(kiω) sin(kiω)
−sin(kiω) cos(kiω)
 
 ˆβi,1,t|t
ˆβi,2,t|t

= cos(kiω) ˆβi,1,t|t + sin(kiω) ˆβi,2,t|t.
Thus, using (4.7), the forecast function of yt = N
i=1 yit is
ˆyt+k|t = ˆy0,t+k|t +
N

i=1
ˆyi,t+k|t = β0,t|t +
N

i=1
%
cos(kiω) ˆβi,1,t|t + sin(kiω) ˆβi,2,t|t
&
,
since the forecast function of the local level model is ˆy0,t+k|t = ˆβ0,t|t, where E(β0t |
y1:t) = ˆβ0,t|t.

4.1
Speciﬁcation of Model Components
131
4.1.4
Trend-Seasonal Models
The previous section describes seasonal time series, i.e. time series with a repeating
pattern (subject to noise). In many practical situations, this pattern is combined
with some trend or other irregular pattern, examples of such data are given among
others in Pole et al. (1994). An example is the classical airline passenger data,
introduced in Brown (1962) and used in many textbooks, including the classic work
of Box et al. (2008). Figure 4.6 plots this data, consisting of numbers of passengers
(in thousands) carried by international airlines each month, from January 1949 to
December 1960. A close look at the data reveals a clear annual seasonality, with
increasing trend. The seasonality is expected since summer months attract usually
more passengers than winter months and the trend reﬂects airlines’ efforts over the
years to attract more passengers and to grow their business. It is curious to observe
that the seasonality has a time-varying amplitude, in fact after around January 1955,
the amplitude of the seasonality increases considerably.
In order to propose a state space model for such data, we will assume that {yt}, the
time series of interest, comprises of trend or seasonal or any other patterns, which
are additive and can be modelled individually with a separate state space model. For
example, we may assume that
yt = y1t + y2t + y3t,
where y1t represents a trend, y2t seasonal variation and y3t local level or irregular
variation. We will refer to these yit as components and their related state space
Airline passenger data
Months
Number of passengers (in thousands)
1950
1952
1954
1956
1958
1960
100
200
300
400
500
600
Fig. 4.6 Numbers of passengers carried in international airlines

132
4
Model Speciﬁcation and Model Performance
models as component models. It is then natural to think that y1t can be modelled
with a trend state space model (as in Sect. 4.1.1), y2t with a Fourier form state
space model (as in Sect. 4.1.3, usually not including the local level component
in (4.15)) and y3t as a local level model. Consequently, the state space model for
yt is the superposition of these three components (Sect. 4.1.2). This approach of
superimposing simple component models, in order to build a complex larger model
is one of the advantages of the state space form, also known as structural time series
model, see e.g. Harvey (1989). Of course, the general theory is trivially extended to
a ﬁnite set of N component models, i.e. yt = N
i=1 yit, although in practice it is
of interest to keep N low and to identify meaningful components, such as those
described above.
Example 4.6 (Turkey Sales Data)
In order to illustrate the trend-seasonal state
space model, we consider data comprising quarterly turkey sales from autumn 1974
until summer 1982. The data which are described in more detail in Pole et al. (1994,
page 270) are shown in Fig. 4.7 (solid points). We observe that the data exhibit
seasonal variation of period T = 4 and an increasing trend. Based on the above
discussion a plausible model for yt (the number of turkey sales at time t) is the
superposition of a linear trend and a full-effects Fourier form model. Thus, the
model for yt has observation equation
yt = 
1, 0, 1, 0, 1

⎡
⎢⎢⎢⎢⎢⎣
β1,1,t
β1,2,t
β2,1,t
β2,2,t
β2,3,t
⎤
⎥⎥⎥⎥⎥⎦
+ ϵt = x⊤
t βt + ϵt
and transition equation
⎡
⎢⎢⎢⎢⎢⎣
β1,1,t
β1,2,t
β2,1,t
β2,2,t
β2,3,t
⎤
⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎣
1 1
0 0
0
0 1
0 0
0
0 0
0 1
0
0 0 −1 0
0
0 0
0 0 −1
⎤
⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎣
β1,1,t−1
β1,2,t−1
β2,1,t−1
β2,2,t−1
β2,3,t−1
⎤
⎥⎥⎥⎥⎥⎦
+
⎡
⎢⎢⎢⎢⎢⎣
ζ1,1,t
ζ1,2,t
ζ2,1,t
ζ2,2,t
ζ2,3,t
⎤
⎥⎥⎥⎥⎥⎦
,
where the state vector is βt
= [β1,1,t, β1,2,t, β2,1,t, β2,2,t, β2,3,t]⊤and ζt
=
[ζ1,1,t, ζ1,2,t, ζ2,1,t, ζ2,2,t, ζ2,3,t]⊤. The horizontal lines indicate the two different
components, the trend with state vector β1t = [β1,1,t, β1,2,t]⊤and transition matrix

 1 1
0 1


4.1
Speciﬁcation of Model Components
133
and the seasonal with state vector β2t = [β2,1,t, β2,2,t, β2,3,t]⊤and transition matrix
⎡
⎣
0 1
0
−1 0
0
0 0 −1
⎤
⎦.
For the analysis that follows we have set β0 ∼N(0, 1000I), where 0 indicates the
5 ×1 zero-vector and as usual I is the identity matrix; we have also set σ 2 = 10 and
Zt = Z = 100I. Figure 4.7 shows the one-step forecasts ˆyt|t−1 (dashed lines with
ticks), the 95% forecast intervals ˆyt|t−1 ± z1−0.05/2√qt|t−1 (dashed-dotted lines),
the smoothed forecasts ˆyt|n (dotted lines) and the actual observations (solid points),
where z1−0.05/2 is the 95% quantile of the standard normal distribution N(0, 1)
and qt|t−1 is the one-step forecast variance at time t. We observe that most of the
data lie inside the forecast intervals, except for some observations at the start of
One-step forecasting for the turkey data
Quarter
Number of sales
1974
1976
1978
1980
1982
0
200
400
600
800
Observations
Forecast mean
95% prediction interval
Fig. 4.7 One-step forecasting and smoothing for the turkey data

134
4
Model Speciﬁcation and Model Performance
the series and a couple towards the end. Some observations are quite close to the
forecast mean, while others are closer to the interval, indicating some drop in the
forecast performance. The observations that are outside of the forecast intervals
in the start of the data should not cause concern, because the model needs some
time to learn and early points of time can be considered as a training data set. The
smoothed forecast shows an overall evolution of the time series, which indicates a
linear slowly increasing trend. The R commands for ﬁtting the model and producing
the above plot are given below.
> # read data
> turkey <- scan("turkey.txt")
> # define state space model
> x0 <- c(1,0,1,0,1)
> F1 <- matrix(c(1,0,1,1),2,2)
> F2 <- matrix(c(0,-1,1,0),2,2)
> F3 <- matrix(c(-1),1,1)
> F0 <- blockDiagMat(F1, F2, F3)
> Z0 <- 100*diag(5)
> obsvar <- 10
> beta0 <- rep(0,5)
> P0 <- 1000*diag(5)
> # fit model
> fit <- bts.filter(turkey, x0=x0, F0=F0, Z0=Z0,
+ beta0=beta0, P0=P0, DISO=FALSE, VAREST=FALSE)
> # calculate prediction intervals
> pred <- ts(fit$FittedMean,start=c(1974,1), frequency=4)
> t <- 1
> predL <- updt(list(), fit$FittedMean[[t]]-
+ 1.96*sqrt(fit$FittedVar[[t]]) )
> predU <- updt(list(), fit$FittedMean[[t]]+
+ 1.96*sqrt(fit$FittedVar[[t]]) )
> for(t in 2:35){
>
predL[[t]] <- fit$FittedMean[[t]]-
+
1.96*sqrt(fit$FittedVar[[t]])
>
predU[[t]] <- fit$FittedMean[[t]]+
+
1.96*sqrt(fit$FittedVar[[t]])
>
}
> predL <- ts(predL, start=c(1974,1), frequency=4)
> predU <- ts(predU, start=c(1974,1), frequency=4)
> turkeyts <- ts(turkey, start=c(1974,1), frequency=4)
> # time series plot
> ts.plot(pred, lty=2, main=expression("One-step forecasting
+ for the turkey data"),xlab="Quarters",
+ ylab="Number of sales",lwd=1)
> lines(predL, lwd=1,lty=3)
> lines(predU, lwd=1,lty=3)
> points(turkeyts, pch=20)
> points(pred, pch=4, col=2)
> legend("bottomright",c("Observations","Forecast mean",
+ "95% prediction interval"), pch=c(20, 4, 1), col=c(1,2,4))

4.1
Speciﬁcation of Model Components
135
4.1.5
Time-Varying Regression
We have already discussed regression models in Sects. 2.4.3 and 3.1.1, also
covered in detail in Bingham and Fry (2010). Time-varying regression models are
regression models whose parameters or coefﬁcients are time-varying and typically
slowly evolving. Such models are used routinely in economics, where regression
coefﬁcients correspond to dynamic covariates and are expected to change over time,
and in other social science ﬁelds such as politics, see e.g. Beck (1983). A number of
theoretical developments with applications are discussed in Kalaba and Tesfatsion
(1988), Tesfatsion and Kalaba (1989), Pankratz (1991), Rao (2000), Commandeur
and Koopman (2007) and in Montana et al. (2009). In this section we brieﬂy describe
the basic formulation of time-varying regression using state space models.
The time-varying regression is introduced in this book as a special form of the
state space model in Sect. 3.1.3. Indeed, the model is deﬁned by
yt = x1tβ1t + x2tβ2t + · · · + xptβpt + ϵt = x⊤
t βt + ϵt,
(4.17)
where yt is a response variable, xit is the ith time-varying covariate, βit is the
ith time-varying regression coefﬁcient and ϵt is the usual white noise innovation
series. Here, xt = [x1t, . . . , xpt]⊤is the design vector, comprising all time-varying
covariates and βt = [β1t, . . . , βpt]⊤is the vector of time-varying coefﬁcients.
Each of βit is assumed to vary or evolve according to a random walk, i.e. βit =
βi,t−1 + ζit, or equivalently βt = βt−1 + ζt, where ζt ∼N(0, Zt) and Zt is a
diagonal covariance matrix, whose diagonal elements are the respective variances
of ζ1t, . . . , ζpt, i.e.
Zt =
⎡
⎢⎢⎢⎣
Z1t
0 · · ·
0
0 Z2t · · ·
0
...
...
...
...
0
0 · · · Zpt
⎤
⎥⎥⎥⎦.
Other evolutions of βit may be considered, but the random walk effectively
captures the slow evolution of the coefﬁcients, expressed as βit ≈βi,t−1; see also
the relevant discussion in Sect. 3.1.3. Model (4.17) does not include an intercept;
if an intercept is required, this can be embedded into the above formulation by
setting the ﬁrst covariate equal to one, i.e. x1t = 1. We can observe that a static
or time-invariant regression model can be obtained by the above model, just by
setting βit = βi,t−1, for all i and for all t, i.e. by setting Zt = 0. Model (4.17) is
very ﬂexible, in the sense that some parameters may be time-varying and some may
be static; this can be achieved by setting Zit = 0, for the static coefﬁcients, and
Zit > 0, for the time-varying coefﬁcients.
Given a working data set y1:t = {y1, . . . , yt} and a set of covariates x1t, . . . , xpt,
estimation and forecasting of model (4.17) follows immediately by the ﬁltering,

136
4
Model Speciﬁcation and Model Performance
smoothing and forecasting algorithms of Chap. 3, after setting the transition matrix
Ft equal to the identity I.
Example 4.7 (Pollution Data)
In this example we consider data consisting of a
response variable yt with values of the pollutant nitric oxide NO (in milligrams per
square meter), together with measurements of three covariates temperature (in 0C),
humidity (%) and wind speed (in meters per second); these covariates are denoted
by x1t, x2t, x3t, respectively. This data set is collected on a daily frequency over a
period of one year, from 1 January 2001 until 31 December 2001, and is part of
a larger data set, which will be discussed later. The data, obtained by one of 16
pollution monitoring stations in the city of Athens, is plotted in Fig. 4.8.
It is postulated that yt is related to xit; e.g. in the summer months when the
temperature is high, the value of NO is also expected to be high. There are several
interesting questions we may ask: can we use the values of the covariates, in order
to forecast future values of NO? Is NO affected by all three covariates, and if it is, in
what extent? Can we issue warning signals by projecting when the values of NO will
exceed health thresholds, based on forecasts of the three covariates? We can answer
these questions (or part of them) by building a regression model. Our starting point
NO (response)
Humidity
Temperature
2
4
6
8
10
10
20
30
40 50 60 70 80 90
5
10
15
20
5
Wind speed
Pollution data with covariates
2001.0
2001.2
2001.4
2001.6
2001.8
2002.0
Day
Fig. 4.8 Air-pollution levels of NO2 and three covariates (humidity, temperature and wind speed)

4.1
Speciﬁcation of Model Components
137
is to consider the static regression model
yt = β0 + β1x1t + β2x2t + β3x3t + ϵt,
ϵt ∼N(0, 1).
This model can be trivially obtained by the time-varying regression model (4.17), if
we set Zt = 0. Here we use the analysis produced by R, using the lm function:
> # read data
> poll <- read.table("Pollution.txt")
> # variables 1-3 indicate time,
> # variables 4-6 are the 3 covariates,
> # variables 7-9 are 3 responses
> # define response NO
> y <- poll[,9]
> # define covariates
> x <- poll[,4:6]
> # fit static linear regression
> lm(y ~ x[,1] + x[,2] + x[,3] )
This returns the estimates of βi as ˆβ0 = 3.07625, ˆβ1 = 0.03142, ˆβ2 = −0.04442
and ˆβ3 = −0.43174 ( ˆβi are the traditional least squares estimates produced by the
static regression model). A Bayesian analysis of the above statistic model can also
be produced by using the commands
> # define the model
> x0 <- cbind(rep(1,365),x[,1],x[,2],x[,3])
> x1 <- list(); for (i in 1:365) x1 <- updt (x1,
x0[i,])
> F0 <- diag(4)
> Z0 <- matrix(0, 4, 4)
> beta0 <- rep(0,4)
> P0 <- 1000*diag(4)
> # fit the model
> fit0 <- bts.filter(y, x0=x1, F0=F0, beta0=beta0, P0=P0,
+ Z0=matrix(0,nrow=4,ncol=4), obsvar=1, ONEX=F, DISO=FALSE,
+ VAREST=FALSE)
The ﬁrst two commands deﬁne the design vector xt including the intercept and the
three covariates, the next command deﬁnes the transition matrix Ft = I and the
following command deﬁnes a zero covariance transition matrix Zt = ), so that
βt = βt−1, for all t, or that βt = β (time-invariant regression). The remaining
commands deﬁne the prior mean β0 = [2, 0, 0, 0]⊤and the prior covariance matrix
P0|0 = 1000I. The values of the elements of ˆβ0|0 are chosen somewhat arbitrarily;
the rationale here is to set all prior coefﬁcient means to zero, except for the intercept;
prior to observing the data we have E(yt) = 2 (this value is known from historical
data or past studies). Applying the above static regression model produces identical
posterior means of β0, β1, β2, β3 with the respective least squares estimates of the
standard regression model mentioned above.
However, since the data are collected over time, it is natural to consider that the
coefﬁcients βi change over time; Fig. 4.8 indicates clearly that the response and the
covariates are time-dependent. Thus, a second model is the time-varying regression
yt = β0t + β1tx1t + β2tx2t + β3tx3t + ϵt,
ϵt ∼N(0, 1),

138
4
Model Speciﬁcation and Model Performance
-0.5
-0.3
-0.1
0.1
Intercept
0.0
0.1
0.2
0.3
Humidity
-0.2
0.0
0.2
0.4
Temperature
-1.0
-0.6
-0.2
Wind speed
Posterior mean of the time-varying coefficients
2001.0
2001.2
2001.4
2001.6
2001.8
2002.0
Day
Fig. 4.9 Posterior means of the four time-varying coefﬁcients for the pollution data
where now each βit follows a random walk, i.e. βit = βi,t−1 + ζit and we set ζit ∼
N(0, 10), to allow βit to exhibit some variation around its zero mean. The prior
distribution of β0 = [β0,0, β1,0, β2,0, β3,0]⊤is set to β0 ∼N{[2, 0, 0, 0]⊤, 100I} as
before.
Figure 4.9 shows the posterior means of the four coefﬁcients βit. We observe
that these estimates indicate a clear time-varying effect, and it would be wrong to
assume them to be static. For ﬁtting the time-varying model and for Fig. 4.9 the
following R code was used:
> # define and fit the model
> # x1, F0, beta0, P0 as defined above
> Z0 <- 10*diag(4)
> fit <- bts.filter(y, x0=x1, F0=F0, Z0=Z0, beta0=beta0, P0=P0,
+ obsvar=1, ONEX=F, DISO=FALSE, VAREST=FALSE)
> # time series plot

4.1
Speciﬁcation of Model Components
139
> m <- ts(fit$m, names=c("Intercept","Humidity","Temperature",
+
"Wind speed"), start=c(2001,0), frequency=365)
> plot.ts(m, main=expression("Posterior mean of the
+
time-varying coefficients"),xlab="Day")
4.1.6
Time-Varying Autoregressions
Autoregressive models are popular time series models and are covered in most time
series textbooks, see e.g. Box et al. (2008) or Shumway and Stoffer (2017). They
form the basic model blocks of time-dependent data and are closely associated
with the development of time series analysis. In this section we describe their
basic structure and discuss how they can be analysed using state space models.
Section 7.2 further discusses autoregressive models and their relation to stationarity.
The Kalman ﬁlter can be used for inference of time-varying moving average models,
such as discussed in Triantafyllopoulos and Nason (2007, 2009), but these models
are not discussed further in this book. It is worthwhile to note that a moving average
model can be seen as an inﬁnite-order (large-order for practical modelling reasons)
autoregressive model; see e.g. Box et al. (2008) for more discussion on this topic.
Suppose that {yt} is a time series which possesses some time-dependentstructure.
This means that the current value of yt is likely to depend on previous values
yt−1, yt−2, . . .. Perhaps the simplest way to describe this dependence is via a
linear regression model, in which the covariates are lagged values of yt, hence
the name autoregressive model—literally regressing yt against itself. Formally, an
autoregressive model of order d, abbreviated as AR(d), is deﬁned by
yt = φ1yt−1 + φ2yt−2 + · · · + φdyt−d + εt,
εt ∼N(0, σ 2
ε ),
(4.18)
where φ1, φ2, . . . , φd are the static or time-invariant AR parameters or coefﬁcients,
εt is a white noise process with some variance σ 2
ε and d is a positive integer. This
model is referred to as the static AR model, or just as AR model, for simplicity.
We can put model (4.18) in state space form by deﬁning the observation model
as
yt = [1, 0, . . ., 0]βt = x⊤
t βt
(4.19)
and the transition model as
βt =
⎡
⎢⎢⎢⎣
yt
yt−1
...
yt−d+1
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
φ1 φ2 · · · φd−1 φd
1
0 · · ·
0
0
...
... ...
...
...
0
0 · · ·
1
0
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
yt−1
yt−2
...
yt−d
⎤
⎥⎥⎥⎦+
⎡
⎢⎢⎢⎣
εt
0
...
0
⎤
⎥⎥⎥⎦
= Fβt−1 + ζt,

140
4
Model Speciﬁcation and Model Performance
with
Ft = F =
⎡
⎢⎢⎢⎣
φ1 φ2 · · · φd−1 φd
1
0 · · ·
0
0
...
... ...
...
...
0
0 · · ·
1
0
⎤
⎥⎥⎥⎦
and
ζt =
⎡
⎢⎢⎢⎣
εt
0
...
0
⎤
⎥⎥⎥⎦.
We note that ζt is random only in one variable (in εt), and so the related distribution
of ζt is a singular normal distribution, i.e. ζt ∼N(0, Zt), with
Zt = Z =
⎡
⎢⎢⎢⎣
σ 2
ε 0 · · · 0
0 0 · · · 0
...
... ... ...
0 0 · · · 0
⎤
⎥⎥⎥⎦.
The above state space representation of model (4.18) is the classical one and
is discussed in many textbooks, see e.g. Brockwell and Davis (1991), Kitagawa
and Gersch (1996) and De Jong and Penzer (2004) among others. It is important
to note that after model (4.18) is cast in state space form, the Kalman ﬁlter
provides a powerful tool for estimation and forecasting. In particular, R uses this
representation, in order to compute the exact likelihood function of model (4.18)
(see the help pages of the function arima). A second point of interest is that a
general and popular class of time series models, namely autoregressive integrated
moving average (ARIMA) models, can be described in state space form, see
Brockwell and Davis (1991) for details. As a result state space provides a very
general time series model and the Kalman ﬁlter (with its extensions) provides an
extremely useful modelling framework.
It should be appreciated that there are several state space representations of model
(4.18). A second one is
yt = x⊤
t β + ϵt,
(4.20)
where xt now includes all lagged values yt−i and β is the vector with coefﬁcients
φi, i.e.
xt =
⎡
⎢⎢⎢⎣
yt−1
yt−2
...
yt−d
⎤
⎥⎥⎥⎦
and
β =
⎡
⎢⎢⎢⎣
φ1
φ2
...
φd
⎤
⎥⎥⎥⎦
and ϵt = εt, with σ 2 = σ 2
ε .
This model is basically a static regression model. It has the advantage that
estimation of β (via Kalman ﬁltering) results in estimation of φi, while in the state

4.2
Decomposition of State Space Models
141
space representation (4.19) the φi’s are included in matrix F, hence the Kalman ﬁlter
does not provide estimation of the φi’s. In such a case the φi’s can be estimated by
maximum likelihood methods, as described in Sect. 4.3.
The model formulation (4.20) motivates the situation in which the coefﬁcients
φi are allowed to vary with time, following similar thinking to that of Sect. 4.1.5
in linear regression. According to this, we adopt (4.20), but replace the static vector
of coefﬁcients β by a time-varying βt = [φ1t, φ2t, . . . , φdt]⊤, so that each of φit
follows a random walk evolution, or some other suitable Markovian evolution. This
model, which is known as time-varying autoregressive model of order d, is deﬁned
by
yt =
d

i=1
φityt−i + ϵt = x⊤
t βt + ϵt
and
βt = βt−1 + ζt,
(4.21)
where
xt =
⎡
⎢⎢⎢⎣
yt−1
yt−2
...
yt−d
⎤
⎥⎥⎥⎦,
β =
⎡
⎢⎢⎢⎣
φ1t
φ2t
...
φdt
⎤
⎥⎥⎥⎦
and Zt, the covariance matrix of ζt is a diagonal matrix, with each element in the
main diagonal of Zt being the variance of ζit, with ζt = [ζ1t, ζ2t, . . . , ζdt]⊤. Similar
models are discussed in West et al. (1999), Lundbergh et al. (2003), Triantafyllopou-
los (2007b), Triantafyllopoulos (2011b), Triantafyllopoulos and Montana (2011)
and Prado and West (2010) among others. A time-varying autoregressive model
applied in the context of pairs trading in ﬁnance is discussed in Sect. 7.5.3.
4.2
Decomposition of State Space Models
4.2.1
Historical Note and Motivation
The problem of representing time series as sum of simpler (component) time
series has been studied in the literature at least since the work of Yule (1927) and
Davis (1941). The classical decomposition of a time series yt considers an additive
structure,
yt = Tt + St + rt,
where Tt denotes the trend, St denotes the seasonal or periodic variation and rt
denotes the random or irregular component. In the classical decomposition, starting

142
4
Model Speciﬁcation and Model Performance
with some observations y1, . . . , yn, estimated values ˆTt, ˆSt and ˆrt of Tt, St and rt
are obtained, for t = 1, . . ., n, so that we can write yt ≈
ˆTt + ˆSt + ˆrt. The
procedure is based on trend estimation using the technique of moving averages
and then estimating the seasonal component. Finally the random component is
effectively what is left if the trend and seasonal components are accounted for. Such
a breakdown of time series into simpler components is helpful in understanding the
data and proposing suitable models, also known as components time series models.
More information is provided in most time series textbooks, see e.g. Whittle (1984,
Chapter 8). The same approach can work with a multiplicative decomposition, if
the time series and its three components (trend, seasonal and random) are positive,
yt = TtStrt so that the logarithm of yt admits an additive decomposition. In R
the classical decomposition (additive or multiplicative) can be applied by using the
command decompose.
Hilmer and Tiao (1982) propose a model-based approach to decomposition
assuming an autoregressive integrated moving average (ARIMA) model for the
generating process of the data. West (1997) proposes a methodology for decom-
posing a time series signal which is cast in state space form, into component
state space models. This methodology is based on the similarity of the transition
matrix F, using Jordan forms. In that article an autoregressive model of order 20 is
decomposed into several quasi cyclical components. Godolphin and Johnson (2003)
and Godolphin and Triantafyllopoulos (2006) propose a decomposition based on the
rational canonical decomposition of F. The proposed decomposition of component
state space models can be regarded as the inverse process of superposition discussed
in Sect. 4.1.2. This approach, which is described in the next sections, uses as
building block the companion matrix.
4.2.2
Rational Canonical Form
This section provides the matrix algebra background necessary for the development
of the theory of decomposition of Sect. 4.2.3.
Let p(x) be a monic polynomial of order n
p(x) = a0 + a1x + · · · + an−1xn−1 + xn,
(4.22)
where a0, a1, . . . , an−1 are known coefﬁcients of the real ﬁeld. Associated to p(x)
is a matrix, known as companion matrix, deﬁned as
Cp = C(p) =
⎡
⎢⎢⎢⎢⎢⎣
0
1
0
· · ·
0
0
0
1
· · ·
0
...
...
...
...
...
0
0
0
· · ·
1
−a0 −a1 −a2 · · · −an−1
⎤
⎥⎥⎥⎥⎥⎦
.
(4.23)

4.2
Decomposition of State Space Models
143
For n = 1, by convention, the companion matrix Cp = −a0, with the associated
polynomial p(x) = a0 + x. The companion matrix has the following interesting
properties.
1. Characteristic polynomial. The characteristic polynomial of Cp is equal to
p(x), i.e. |xI −Cp| = p(x), where | · | denotes determinant.
To prove this use induction for n. For n = 1 the characteristic polynomial is
|x −Cp| = x + a0 and the statement is true. For n = 2 we have
|xI −Cp| =
2222
x
−1
a0 x + a1
2222 = a0 + a1x + x2 = p(x).
Suppose that the statement that the characteristic polynomial of Cp is equal to
(4.22) for order n −1. We shall prove the statement for n.
|xI −Cp| =
22222222222
x −1 0 · · ·
0
0
x −1 · · ·
0
...
...
...
...
...
0
0
0 · · ·
−1
a0 a1 a2 · · · x + an−1
22222222222
.
We shall expand this determinant using the cofactors of the ﬁrst column. We have
|xI −Cp| = x
22222222222
x −1 · · ·
0
0
x · · ·
0
...
...
...
...
0
0 · · ·
−1
a1 a2 · · · x + an−1
22222222222
+(−1)n+1a0
22222222222
−1 0 · · · 0
0
x −1 · · · 0
0
...
...
...
...
...
0
0 · · · −1 0
0
0 · · · 0 −1
22222222222
= x(a1 + a2x + · · · + an−1xn−2 + xn−1) + (−1)n+1a0(−1)n−1
= a0 + a1x + a2x2 + · · · + an−1xn−1 + xn.
2. Similarity condition. Two n × n matrixes A and B are said to be similar if there
exists a non-singular n × n matrix S, so that SAS−1 = B. The following theorem
provides conditions to ensure that an n × n matrix is similar to Cp.

144
4
Model Speciﬁcation and Model Performance
Theorem 4.1 Let A be an n × n matrix and Cp be an n × n companion matrix
as deﬁned above. Then the following two statements are equivalent.
a. There exists a vector v ∈Rn such that the row vectors v⊤, v⊤A, v⊤A2, . . .,
v⊤An−1 form a basis of Rn.
b. There exists an n × n non-singular matrix S so that SAS−1 = Cp.
Proof First suppose (a) holds true and prove (b). Deﬁne
S =
⎡
⎢⎢⎢⎣
v⊤
v⊤A
...
v⊤An−1
⎤
⎥⎥⎥⎦.
From (a) we know that the rows of S are independent, hence S is invertible. We
will prove SA = SCp. The i-th row of the matrix SA is v⊤Ai−1, for i = 1, . . . , n.
Let a = [a0, a1, . . . , an−1]⊤and let ei = [0, . . ., 0, 1, 0, . . . , 0]⊤be the vector
with a unit at the i-th element and all other elements equal to 0. We can write
CpS =
⎡
⎢⎢⎢⎢⎢⎣
e⊤
2
e⊤
3...
e⊤
n
−a
⎤
⎥⎥⎥⎥⎥⎦
S =
⎡
⎢⎢⎢⎢⎢⎣
v⊤A
v⊤A2
...
v⊤An−1
−a⊤S
⎤
⎥⎥⎥⎥⎥⎦
,
because the row vector e⊤
i S is equal to the i-th row of S, which is v⊤Ai−1. Hence
to show SA = CpS it sufﬁces to show
v⊤An = −a⊤S.
(4.24)
Write a as a = a0e1 + a1e2 + · · · + an−1en. Then
a⊤S = (a0e1 + a1e2 + · · · + an−1en)⊤S
= a0e⊤
1 S + a1e⊤
2 S + · · · + an−1e⊤
n S
= a0v⊤+ a1v⊤A + · · · + an−1v⊤An−1
= v⊤(a0I + a1A + · · · + an−1An−1)
= −v⊤An,
where the last equation follows from an application of the Cayley-Hamilton
theorem, or
O = p(A) = a0I + a1A + · · · + an−1An−1 + An.

4.2
Decomposition of State Space Models
145
A proof of the Cayley-Hamilton theorem can be found in Jacobson (1953).
This establishes (4.24) and so SA = CpS is true. From this and the invertibility
of S, it follows SAS−1 = Cp.
Now suppose (b) holds true and prove (a). Deﬁne v⊤= e⊤
1 S to be the
ﬁrst row vector of S. We prove that with this choice of v the row vectors
v⊤, v⊤A, . . . , v⊤An−1 form a basis of Rn. We have
SA =
⎡
⎢⎢⎢⎢⎢⎢⎣
e⊤
1 SA
e⊤
2 SA
...
e⊤
n−1SA
e⊤
n SA
⎤
⎥⎥⎥⎥⎥⎥⎦
and
CpS =
⎡
⎢⎢⎢⎢⎢⎣
e⊤
2 S
e⊤
3 S
...
e⊤
n S
−a⊤S
⎤
⎥⎥⎥⎥⎥⎦
.
From (b) we have SA = CpS and by equating terms we get e⊤
1 SA = e⊤
2 S,
e⊤
2 SA = e⊤
3 S, . . . , e⊤
n−1SA = e⊤
n S, e⊤
n SA = −a⊤S. This implies that the row
vectors v⊤, v⊤A, . . . , v⊤An−1 can be expressed as
v⊤= e⊤
1 S
(by construction)
v⊤A = e⊤
1 SA = e⊤
2 S
v⊤A2 = (v⊤A)A = e⊤
2 SA = e⊤
3 S
...
v⊤An−1 = (v⊤An−2)A = e⊤
n−1SA = e⊤
n S,
or in short
v⊤Ai = e⊤
i+1S,
for
i = 0, 1, . . . , n −1.
(4.25)
In order to prove v⊤, v⊤A, . . . , v⊤An−1 are independent row vectors, we
consider the linear combination
c1v⊤+ c2v⊤A + · · · + cnv⊤An−1 = 0,
for some c1, . . . , cn ∈R. From Eq. (4.25) and the invertibility assumption of S
we have
c1e⊤S + c2e⊤
2 S + · · · + cne⊤
n S = 0
(c1e⊤
1 + c2e2 + · · · + cne⊤
n )S = 0
c1e⊤
1 + c2e2 + · · · + cne⊤
n = 0,

146
4
Model Speciﬁcation and Model Performance
which is satisﬁed only for c1 = c2 = · · · = cn = 0, since e1, e2, . . . , en form a
basis of Rn. Hence v⊤, v⊤A, . . . , v⊤An−1 are independent.
To show that v⊤, v⊤A, . . . , v⊤An−1 form a basis of Rn we need to show that any
row vector u of Rn can be written as a linear combination of these vectors. Since
e1, e2, . . . , en is a basis of Rn the row vector, there exists some non-zero scalars
λ1, λ2, . . . , λn so that
u⊤S−1 = λ1e⊤
1 + λ2e⊤
2 + · · · + λne⊤
n
= (λ1e⊤
1 S + λ2e⊤
2 S + · · · + λne⊤
n S)S−1
= (λv⊤+ λ2v⊤A + · · · + λnv⊤An−1)S−1.
Hence u⊤= λv⊤+ λ2v⊤A + · · · + λnv⊤An−1.
Since the vectors v⊤, v⊤A, . . . , v⊤An−1 are independentand generate any vector
of Rn, they form a basis of Rn and the proof of (a) is completed.
⊓⊔
3. The minimal polynomial m(x) of a matrix A is deﬁned as the polynomial of least
degree satisfying m(A) = O; see e.g. (Jacobson, 1953, p. 98) and (Horn and
Johnson, 2013, Chapter 3). The minimal polynomial of C(p) is equal to p(x).
It follows that C(p) is a non-derogatory matrix (the minimal and characteristic
polynomials are identical). The minimal polynomial can be factorised as follows
m(x) = pm1
1 (x)pm2
2 (x) · · · pmk
k (x),
(4.26)
where pi(x) are irreducible polynomials of degree di and m1d1+· · ·+mkdk = n.
It follows that pi(x) are the elementary divisors of m(x).
Consider now a matrix A, with characteristic polynomial p(x) = |xI −A, given
by (4.22), where a0, a1, . . . , an−1 are given as functions of the elements of A. If
condition (a) of Theorem 4.1 is satisﬁed, then A will be similar to a companion
matrix. The minimal polynomial m(x) of this matrix will have the form of (4.26).
Each of the elementary divisors pi(x) of m(x) will correspond to a companion
matrix C(pi), for i = 1, 2, . . . , k. It follows that the matrix A is similar to C the
direct sum of companion matrixes C(p1), . . . , C(pk), hence C is a n × n block
diagonal matrix
C =
⎡
⎢⎢⎢⎣
C(p1)
O
· · ·
O
O
C(p2) · · ·
O
...
...
...
...
O
O
· · · C(pk)
⎤
⎥⎥⎥⎦.
(4.27)
This is known as the rational canonical decomposition of A; for more details see
Jacobson (1953, Chapter 3) and Horn and Johnson (2013, Chapter 3).

4.2
Decomposition of State Space Models
147
4.2.3
Decomposition of Linear State Space Models
Consider the state space model (3.10a)–(3.10b) as deﬁned in Sect. 3.1.3, or
yt = μt + ϵt = x⊤βt + ϵt,
(4.28)
βt = Fβt−1 + ζt,
(4.29)
where μt is the mean response and ζt ∼N(0, Z). It is assumed that the components
x, F and Z are time-invariant.
Assumption 1 To what follows we will assume that the model is observable or that
the p × p observability matrix O in (3.32) has full rank p. Observability in state
space models is discussed in some detail in Sect. 3.5.1. This implies that the row
vectors x⊤, x⊤F, . . . , x⊤Fp−1 are linearly independent and hence they form a basis
of the column vector space C(O). It also follows that C(O) is a cyclic space, with x
being its generator. Hence F is non-derogatory. As a result the minimal polynomial
of F is equal to its characteristic polynomial
(λ) = |λI −F| = φ0 + φ1λ + · + φp−1λp−1 + λp,
for some real coefﬁcients φ0, φ1, . . . , φp−1.
Suppose that (λ) can be expressed as a product of ℓrelatively prime factors
(λ) = 1(λ)2(λ) · · · ℓ(λ),
for ℓ≤p. The factors j(λ) are powers of factors from the system of the
elementary divisors of (λ).
With the assumption of observability (Assumption 1) we have that condition
(1) of Theorem 4.1 is satisﬁed and so F is similar to a companion matrix.
More speciﬁcally, F is similar to a direct sum of companion matrices, each one
corresponding to the factor j(λ). So
SFS−1 = C = C(1) ⊕C(2) ⊕· · · ⊕C(ℓ),
for some non-singular similarity matrix S.
Our aim is to deﬁne a linear transformation of the state vector βt to a new state
vector γt, so that the mean response μt is decomposed to a sum of ℓcomponents
χ(1)
t
, . . . , χ(ℓ)
t
, each of which following a state space model, or
μt = χ(1)
t
+ χ(2)
t
+ · · · + χ(ℓ)
t
,
(4.30)
χ(j)
t
= e⊤
1 γjt,
(4.31)
γjt = C(j)γj,t−1 + ξjt,
(4.32)

148
4
Model Speciﬁcation and Model Performance
for some ξjt to be deﬁned, where e1 = [1, 0, . . ., 0]⊤is the pj × 1 column vector
with a unit as its ﬁrst element and elsewhere zero, and the dimension of the vector
is implicit. Here γjt is a state vector and should not be confused with the natural
parameter γt of the dynamic generalised linear model (see Eq. (6.4) of Sect. 6.2).
In order to form the transformation, for j = 1, . . . , ℓ, we deﬁne the pj × pj
matrix
j =
⎡
⎢⎢⎢⎢⎣
x⊤
j
x⊤
j C(j)
...
x⊤
j C(j)pj −1
⎤
⎥⎥⎥⎥⎦
,
(4.33)
where p1 + · · · + pℓ= p and x⊤
j is the 1 × pj row component vector of the matrix
x⊤S−1 = [x⊤
1 , x⊤
2 , . . . , x⊤
ℓ].
Subsequently we deﬁne the p × p matrix  to be the direct sum of 1, . . . , ℓ, or
 = 1 ⊕2 ⊕· · · ⊕ℓ.
(4.34)
With these deﬁnitions in place we have the following lemma, which is instru-
mental in the decomposition (4.32) of the state vector βt.
Lemma 4.1 With the deﬁnitions of C and  as in (4.27) and (4.34), C and 
commute.
Proof Since both C and  are block diagonal matrices it sufﬁces to prove that the
pj × pj matrices j and C(j) commute, for j = 1, 2, . . . , ℓ. First we will show
that j can be expressed as a polynomial of C(j) as
j = xj,1I + xj,2C(j) + · · · + xj,pj C(j)pj −1,
(4.35)
where x⊤
j
= [xj,1, xj,2, . . . , xj,pj ]. To show this ﬁrst we consider the matrix
polynomial
p[C(j)] = xj,1I + xj,2C(j) + · · · + xj,pj C(j)pj −1.
Deploying induction for i we shall prove the following statement P(i)
P(i) :
e⊤
i p[C(j)] = x⊤
j C(j)i−1,
for any 1 ≤i ≤pj.

4.2
Decomposition of State Space Models
149
For i = 1 and the deﬁnition of the companion matrix C(j) (see Eq. (4.23)) we
have
e⊤
1 C(j)k−1 = e⊤
1 C(j)C(j)k−2 = e⊤
2 C(j)k−2 = · · · = e⊤
k ,
for k = 1, . . . , pj. Hence
e⊤
1 p[C(j)] = xj,1e⊤
1 + xj,2e⊤
2 + · · · + xj,pj e⊤
pj = x⊤
j ,
which proves P(1).
Suppose now that statement P(i) is true for some 1 ≤i ≤pj −1. We shall prove
the statement holds true for i + 1. We have
e⊤
i+1p[C(j)] = e⊤
i C(j)p[C(j)]
= e⊤
i p[C(j)]C(j)
= x⊤
j C(j)i−1C(j)
= x⊤
j C(j)i+1−1,
since p[C(j)] and C(j) commute. Hence P(i + 1) holds true and the statement
is true for any i. This implies that
j =
⎡
⎢⎢⎢⎢⎣
x⊤
j
x⊤
j C(j)
...
x⊤
j C(j)pj −1
⎤
⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎣
e⊤
1
e⊤
2...
e⊤
pj
⎤
⎥⎥⎥⎥⎦
p[C(j)] = p[C(j)],
which proves (4.35).
With (4.35) established we see
jC(j) = C(j)j
and so j and C(j) commute.
⊓⊔
Coming back to the original state space model (4.28)–(4.29) we deﬁne the p × 1
state vector γt as γt = Sβt. This deﬁnition implies
SFβt−1 = SFS−1Sβt−1
= CSβt−1
= CSβt−1
= Cγt−1,
where Lemma 4.1 is used.

150
4
Model Speciﬁcation and Model Performance
By left multiplying the state equation (4.29) we have
γt = Sβt = SFβt−1 + Sζt = Cγt−1 + ξt,
where ξt = Sζt ∼N(0, SZS⊤⊤).
If we now write γt = [γ1t, γ2t, . . . , γℓ,t]⊤and ξt = [ξ1t, ξ2t, . . . , ξℓ,t]⊤and
taking into account that C is the direct sum of C(1), . . . , C(ℓ), it follows that
γjt = C(j)γj,t−1 + ξjt,
which is Eq. (4.32).
Considering now the linear predictor ηt we have
μt = x⊤
t βt = x⊤S−1Sβt
= [x⊤
1 , x⊤
2 , . . . , x⊤
ℓ]Sβt
= [e⊤
1 1, e⊤
1 2, . . . , e⊤
1 ℓ]Sβt
= [e⊤
1 , e⊤
1 , . . . , e⊤
1 ]Sβt
= [e⊤
1 , e⊤
1 , . . . , e⊤
1 ]
⎡
⎢⎢⎢⎣
γ1t
γ2t
...
γℓ,t
⎤
⎥⎥⎥⎦
=
ℓ

j=1
e⊤
1 γjt = χ(1)
t
+ χ(2)
t
+ · · · + χ(ℓ)
t
,
which give Eqs. (4.30)–(4.31). Hence we have established that the linear predictor
ηt has the decomposition of Eqs. (4.30)–(4.32).
Some comments are in order.
1. If the polynomials j(λ) are relative prime factors, the decomposition is known
as the irreducible decomposition, see Godolphin and Johnson (2003). Otherwise,
j(λ) will be a polynomial obtained by elementary operations from the system
of the elementary divisors of (λ).
2. There is some interest to establish whether χ(i)
t
is independent of χ(j)
t
, for all t
and for all i ̸= j. If this is the case, the resulting decomposition is referred to
as independent decomposition. This property is useful if we wish to compute the
variance of ηt = ℓ
j=1 χ(j)
t
, so that Cov(χ(i)
t , χ(j)
t
) = 0.
From (4.31), χ(i)
t
is independent of χ(j)
t
, if γit is independent of γjt. From (4.32)
and the direct sum C = C(1) ⊕· · · ⊕C(ℓ), it follows that γit is independent
of γjt, if the innovations ξit and ξjt are independent, for i ̸= j. The deﬁnition
ξt = Sζt implies that ξit and ξjt are independent when SZS⊤has the same

4.2
Decomposition of State Space Models
151
block diagonal structure as . This is satisﬁed if Z and S are direct sums
Z = Z1 ⊕· · · ⊕Zℓ
and
S = S1 ⊕· · · ⊕Sℓ,
for some pj × pj matrices Zj and Sj, j = 1, . . . , ℓ.
3. An application of this model is in forecasting. Consider the linear state space
model (3.10a)–(3.10b), where the design vector xt = x, the transition matrix
Ft = F and the innovation variances are all time-invariant. Suppose that at
time t the posterior distribution of βt, given data y1:t is obtained from the
Kalman ﬁlter (Theorem 3.2 in Sect. 3.2) and hence the posterior mean ˆβt|t is
computed. From decomposition (4.30)–(4.32) and the transformation of βt we
can compute ˆγt|t = S ˆβt|t. This can then decomposed to obtain ˆγj,t|t, where
ˆγ ⊤
t|t = [ ˆγ ⊤
1,t|t, . . . , ˆγ ⊤
ℓ,t|t]. As a result the k-step ahead forecast mean of the
observation yt+k is given by
ˆyt+k|t = ˆχ(1)
t+k|t + ˆχ(2)
t+k|t + · · · + ˆχ(ℓ)
t+k|t,
ˆχ(j)
t+k|t = e⊤
1 ˆγj,t+k|t
and
ˆγj,t+k|t = C(j)k ˆγj,t|t,
after using the standard result of the k-step ahead forecast mean of state space
models (see Theorem 3.6 of Sect. 3.4). This has the interesting application that if
a state space model is decomposed as above, the forecasts are also decomposed
into a sum of ℓforecasts. Therefore, if the forecast performance is poor, perhaps
evidenced by some outliers, the modeller may concentrate to ﬁx a particular
model component (trend, seasonal) rather than dealing with the overall model
which will be more complex.
4.2.4
Turkey Data Revisited
We revisit the Turkey data, discussed in Example 4.6 of Sect. 4.1.4. There a linear
Gaussian state space model was ﬁtted with design vector and transition matrix
x =
⎡
⎢⎢⎢⎢⎢⎣
1
0
1
0
1
⎤
⎥⎥⎥⎥⎥⎦
and
F =
⎡
⎢⎢⎢⎢⎢⎣
1 1 0
0
0
0 1 0
0
0
0 0 0 −1
0
0 0 1
0
0
0 0 0
0 −1
⎤
⎥⎥⎥⎥⎥⎦
(4.36)
This model is essentially the superposition of two independent state space models,
a linear growth and a seasonal component model, with period 4. This model is ﬁtted
in Sect. 4.6 and Fig. 4.7 illustrates its forecast performance.

152
4
Model Speciﬁcation and Model Performance
Below we obtain the rational canonical decomposition of this model. The
characteristic polynomial of F is
(λ) = |λI −F| = 1 −λ −λ4 + λ5
(4.37)
and the eigenvalues of F are 1 (multiplicity 2) and −1, ±i (multiplicity 1).
The irreducible factorisation of (4.37) is
(λ) = (λ −1)2(λ + 1)(λ2 + 1),
(4.38)
with the elementary divisors of (λ) being λ −1, λ + 1 and λ2 + 1.
Each of the polynomials 1(λ) = (λ −1)2, 2(λ) = (λ + 1) and 3(λ) =
(λ2 + 1) corresponds to companion matrices C(1), C(2), C(3), hence F is
similar to the direct sum of companion matrices
C = C(1) ⊕C(2) ⊕C(3) =
⎡
⎢⎢⎢⎢⎢⎣
0 1 0
0
0
−1 2 0
0
0
0 0 0
1
0
0 0 1 −1
0
0 0 0
0 −1
⎤
⎥⎥⎥⎥⎥⎦
.
(4.39)
We can see that the yt can be decomposed to two models
yt = χ(1)
t
+ χ(2)
t
+ ϵt,
where χ(1)
t
is a trend component
χ(1)
t
= [1, 0]γ (1)
t
and
γ (1)
t
=

0 1
−1 2

γ (1)
t−1 + ξ1t
(4.40)
and χ(2)
t
is a seasonal component
χ(2)
t
= [1, 0, 0]γ (2)
t
and
γ (2)
t
=
⎡
⎣
0
1
0
1 −1
0
0
0 −1
⎤
⎦γ (2)
t−1 + ξ2t.
It can be shown (see Exercise 5) that the trend component can be written as
χ(1)
t
= [1, 0]γ (3)
t
and
γ (3)
t
=

 1 1
0 1

γ (3)
t−1 + ξ3t,
(4.41)
for some innovations ξ3t, which are given as linear functions of the innovations
ξ11, . . . , ξ1t.

4.2
Decomposition of State Space Models
153
We can see that models (4.40) and (4.41) are identical and as a result the
transition matrix F in (4.36) is identical to the matrix C, if the block C(1) is
replaced by the Jordan block
J =

 1 1
0 1

.
Notice that both matrices C(1) and J have a unit eigenvalue of multiplicity two and
they have the same characteristic polynomial |λI −C(1)| = |λI −J| = (λ −1)2.
It follows that the state space model of Sect. 4.6, which was the superposition of
a trend and a seasonal component, is obtained by the irreducible decomposition
proposed in the previous section.
Consider now the (non-irreducible) factorisation
(λ) = (λ −1)2(λ3 + λ2 + λ + 1),
which follows directly from (4.38) by expanding the seasonal factor corresponding
to the term (λ + 1)(λ2 + 1).
This time yt is decomposed to two components yt = χ(1)
t
+ χ(2)
t
+ ϵt, the trend
with is given by (4.40) and the seasonal given by
χ(2)
t
= [1, 0, 0]γ (2)
t
and
γ (2)
t
=
⎡
⎣
0
1
0
0
0
1
−1 −1 −1
⎤
⎦γ (2)
t−1 + ξ2t.
Hence, F is similar to the matrix C given by
C =
⎡
⎢⎢⎢⎢⎢⎣
0 1
0
0
0
−1 2
0
0
0
0 0
0
1
0
0 0
0
0
1
0 0 −1 −1 −1
⎤
⎥⎥⎥⎥⎥⎦
.
The similarity matrix of F and C is
S =
⎡
⎢⎢⎢⎢⎢⎣
1 −1
0
0
0
1
0
0
0
0
0
0 −1 −1 −1
0
0
1 −1
1
0
0
1
1 −1
⎤
⎥⎥⎥⎥⎥⎦
as it can be veriﬁed that SFS−1 = C.

154
4
Model Speciﬁcation and Model Performance
In order to establish whether this is an independent decomposition we need to
calculate matrix  (see point (3) of p. 150; see also Eq. (4.33) for the deﬁnition
of ). Recall that x⊤S−1 = [x⊤
1 , x⊤
2 ], which is needed for the computation of j,
j = 1, 2. We have
S−1 =
⎡
⎢⎢⎢⎢⎢⎣
0 1
0
0
0
−1 1
0
0
0
0 0
0
1
2
1
2
0 0 −1
2 −1
2
0
0 0 −1
2
0 −1
2
⎤
⎥⎥⎥⎥⎥⎦
and so x⊤S−1 = [0, 1, −1/2, 1/2, 0]⊤.
Hence
1 =

x⊤
1
x⊤
1 C(1)

=

0 1
−1 2

and
2 =
⎡
⎣
x⊤
2
x⊤
2 C(′
2)
x⊤
2 C(′
2)2
⎤
⎦=
⎡
⎣
−1
2
1
2
0
0 −1
2
1
2
−1
2 −1
2 −1
⎤
⎦,
where ′
2(λ) = λ3 + λ2 + λ + 1. Therefore
 = 1 ⊕2 =
⎡
⎢⎢⎢⎢⎢⎣
0 1
0
0
0
−1 2
0
0
0
0 0 −1
2
1
2
0
0 0
0 −1
2
1
2
0 0 −1
2 −1
2 −1
⎤
⎥⎥⎥⎥⎥⎦
.
With the choice of Z = 100I, the covariance matrix of ζt (see the analysis of the
turkey data in Sect. 4.1.4), the condition of independence (point (3), p. 150) is met.
Alternatively we can see that
SZS⊤⊤=
⎡
⎢⎢⎢⎢⎢⎣
100 100
0
0
0
100 200
0
0
0
0
0
200 −100
0
0
0 −100
200 −100
0
0
0 −100
200
⎤
⎥⎥⎥⎥⎥⎦
,
which clearly shows that the two components γ (1)
t
and γ (2)
t
are uncorrelated and
hence independent as the vector γ ⊤
t
= [γ (1)⊤
t
, γ (2)⊤
t
] follows a normal distribution.

4.2
Decomposition of State Space Models
155
Forecast decomposition for the turkey data
Quarters
Number of sales
1974
1976
1978
1980
1982
-200
0
200
400
600
800
Trend
Seasonal
Forecast mean
Fig. 4.10 Decomposition for the turkey data. Shown are one-step ahead forecast mean of the trend
component ˆχ(1)
t
(solid line and solid points), one-step forecast mean of the seasonal component
ˆχ(2)
t
(dashed line and triangle points) and the overall forecast mean of yt, which is equal to ˆχ(1)
t
+
ˆχ(2)
t
(dotted line and cross points)
This means that the k-step forecast variance of yt+k is decomposed into the
respective forecast variances of the trend and seasonal components.
Figure 4.10 gives an illustration of the decomposition as far as forecasting is
concerned. Shown is the one-step ahead forecast mean of yt, ˆyt|t−1 = E(yt | y1:t−1)
decomposed as the sum of the forecast mean of the trend component ˆχ(1)
t
=
E(χ(1)
t
| y1:t−1) (solid lines and solid points) and the one-step ahead forecast
mean of the seasonal component ˆχ(2)
t
= E(χ(2)
t
| y1:t−1) (dashed lines and triangle
points). The forecast means ˆχ(1)
t
+ ˆχ(2)
t
match exactly those of ˆyt|t−1 provided by
the application of the Kalman ﬁlter (see Fig. 4.7). Figure 4.10 suggests that the
amplitude of the seasonal cycle is stable in the quarters between 1976 and 1980,
while increasing after 1980.

156
4
Model Speciﬁcation and Model Performance
4.3
Estimation of Hyperparameters
In the previous sections we dealt with the speciﬁcation of xt and Ft, for some
popular state space models. In general, even if we know xt and Ft, these may
depend on some unknown hyperparameters. In addition to these σ 2 and Zt (the
observation variance and the transition covariance matrix) may be either unknown
or depend also on some unknown hyperparameters. The successful application of
the Kalman ﬁlter and related algorithms invokes the choice or speciﬁcation of these
hyperparameters.Perhaps, the most popular approach for their speciﬁcation is to use
the maximum likelihood principle, i.e. to choose the hyperparameters that maximise
the log-likelihood function. Below we describe this approach, together with two
other popular approaches for specifying the transition covariance matrix Zt and
estimating the observation variance σ 2.
4.3.1
Maximum Likelihood Estimation
Denote by θ the vector of hyperparameters, so that xt, Ft, σ 2 and Zt (or a subset of
these components) may depend on θ. We will further assume that θ includes time-
invariant hyperparameters. One simple example is to consider θ = σ 2, where σ 2 is
the observation variance (see the deﬁnition of the state space model in Sect. 3.1.3).
Another example is to consider that the design vector is xt = [φ, 0]T and the
transition matrix is
Ft =

1 ψ
0 1

,
for some hyperparameters φ and ψ, subject to estimation or speciﬁcation. This may
be suitable for a linear trend model with smooth trend (closer to the local level) if
0 ≤ψ < 1 and abrupt trend if ψ > 1. We observe that if we deﬁne θ = [φ, ψ]⊤,
then xt and Ft depend on θ. In this set-up another desirable option would be to
include σ 2 (the observational variance) in θ, i.e. θ = [φ, ψ, σ 2]⊤. A third example
is the static AR model (4.19) of Sect. 4.1.6, in which the AR coefﬁcients φ1, . . . , φd
and the variance σ 2
ν may be considered as hyperparameters; so we can write θ =
[φ1, . . . , φd, σ 2
ε ]⊤.
Returning to the general case, after θ is deﬁned to include any hyperparameters
subject to estimation, the likelihood function of θ based on a collection of data
y1:n = {y1, . . . , yn} is
L(θ; y1:n) = p(y1, . . . , yn | θ)
= p(yn | y1:n−1, θ)p(y1, . . . , yn−1 | θ)

4.3
Estimation of Hyperparameters
157
= · · ·
=
n
-
t=1
p(yt | y1:t−1, θ),
where p(y1 | y1:0, θ) ≡p(y1 | θ) by deﬁnition. Now we note that given θ, the
density p(yt | y1:t−1, θ) is just the one-step forecast distribution at time t, which
is given by the Kalman ﬁlter as yt | y1:t−1, θ ∼N( ˆyt|t−1, qt|t−1), where ˆyt|t−1
and qt|t−1 are implicitly conditional on θ. Substituting this Gaussian density to the
above likelihood we obtain
L(θ; y1:n) =
n
-
t=1
1
'2πqt|t−1
exp

−(yt −ˆyt|t−1)2
2qt|t−1

=
1
(2π)n/2
 n
-
t=1
q−1/2
t|t−1

exp
 
−1
2
n

t=1
(yt −ˆyt|t−1)2
qt|t−1
!
and the log-likelihood is
ℓ(θ; y1:n) = −n
2 log(2π) −1
2
n

t=1
log qt|t−1 −1
2
n

t=1
(yt −ˆyt|t−1)2
qt|t−1
.
Maximisation of ℓ(·) usually cannot be performed analytically, as ℓ(·) is a non-
linear function on θ, even in the simple case of θ = σ 2. Such a maximisation may be
performed using iterative numerical methods, such as the Newton-Raphson method,
or the more sophisticated expectation maximisation (EM) algorithm, both discussed
in Shumway and Stoffer (2017). Direct maximisation may be appropriate if the
dimension of θ is small, but when θ includes many parameters, the maximisation
algorithm is likely to be stack to some local maxima of the likelihood. Compared
to the direct maximisation the EM algorithm provides a more sophisticated efﬁcient
maximisation procedure and is discussed next; for a background discussion of the
EM algorithm see Sect. 2.4.2.
The EM-algorithm The EM algorithm for state space models was ﬁrst discussed
in Shumway and Stoffer (1982); for a general description of the EM algorithm
see Sect. 2.4.2. Consider the state space model (3.10a)–(3.10b) with information
y1:n = {y1, . . . , yn}, where Zt = Z is time-invariant and the hyperparameter vector
θ includes the distinct elements of Z, σ 2, the prior mean of β0, ˆβ0|0, and the distinct
elements of the prior covariance matrix of β0, P0|0. We write
θ = [σ 2, vech(Z)⊤, ˆβ⊤
0|0, vech(P0|0)⊤]⊤,
where vech(Z) denotes the column stacking vector of the distinct elements of Z (see
Sect. 2.1).

158
4
Model Speciﬁcation and Model Performance
The likelihood function of θ based on the observed data y1:n and the unobserved
data (consisting of the states) β0:n = (β⊤
0 , β⊤
1 , . . . , β⊤
n )⊤is
L(θ; y1:n, β0:n) = p(y1, . . . , yn, β0, β1, . . . , βn | θ)
= p(y1, . . . , yn | β0, β1, . . . , βn, θ)p(β1, . . . , βn | θ)
=
n
-
t=1
p(yt | βt, θ)
n
-
t=1
p(βt | βt−1, θ)p(β0 | θ)
and so the log-likelihood of θ is
ℓ(θ; y, β) = −n
2 log σ 2 −
1
2σ 2
n

t=1
(yt −x⊤
t βt)2
−n
2 log |Z| −1
2
n

t=1
(βt −Ftβt−1)⊤Z−1(βt −Ftβt)
−1
2 log |P0|0| −1
2(β0 −ˆβ0|0)⊤P−1
0|0(β0 −ˆβ0|0),
(4.42)
where from the observation equation (3.10a) we have yt | βt, θ ∼N(x⊤
t βt, σ 2),
from the transition equation (3.10b) we have βt | βt−1, θ ∼N(Ftβt−1, Z) and from
the initial distribution (3.12) we have β0 | θ ∼N( ˆβ0|0, P0|0).
In the E-step we calculate the quantity
Q(θ | θ(i)) = E[ℓ(θ; y1:n, β0:n) | y1:n, θ(i)],
the conditional expectation of the log-likelihood function of θ, conditioned upon the
observed data y1:n and the current estimate θ(i).
Deﬁne
S1 = E
 
−n
2 log σ 2 −
1
2σ 2
n

t=1
(yt −x⊤
t βt)2 | y1:n, θ(i)
!
,
S2 = E
 
−n
2 log |Z| −1
2
n

t=1
(βt −Ftβt−1)⊤Z−1(βt −Ftβt)at)2 | y1:n, θ(i)
!
,
S3 = E

−1
2 log |P0|0| −1
2(β0 −ˆβ0|0)⊤P−1
0|0(β0 −ˆβ0|0)at)2 | y1:n, θ(i)

,
so that Q(θ | θ(i)) = S1 + S2 + S3. In the sequel we calculate S1, S2, S3.

4.3
Estimation of Hyperparameters
159
From the deﬁnition of S1 above we have
S1 = −n
2 log σ 2 −
1
2σ 2
n

t=1
E
%
(yt −x⊤
t βt)2 | y1:n, θ(i)&
.
(4.43)
Now by expanding the square in the expectation term and taking expectations, we
obtain
E
%
(yt −x⊤
t βt)2 | y1:n, θ(i)&
= E
%
y2
t + (x⊤
t βt)2 −2ytx⊤
t βt | y1:n, θ(i)&
= y2
t −2ytx⊤
t E(βt | y1:n, θ(i)) + x⊤
t xtE(β⊤
t βt | y1:n, θ(i))
= y2
t −2ytx⊤
t ˆβt|n + x⊤
t xt
n

j=1
(pjj,t|n + ˆβ2
j,t|n)
= y2
t −2ytx⊤
t ˆβt|n + x⊤
t ˆβt|n ˆβ⊤
t|nxt + x⊤
t xttrace(Pt|n)
= (yt −x⊤
t ˆβt|n)2 + x⊤
t Pt|nxt,
(4.44)
where
E(β⊤
t βt | y1:n, θ(i)) = E
⎛
⎝
n

j=1
β2
jt | y1:n, θ(i)
⎞
⎠=
n

j=1
E(β2
jt | y1:n, θ(i))
=
n

j=1
%
Var(βjt | y1:n, θ(i)) + E(βjt | y1:n, θ(i))2&
=
n

j=1
(pjj,t|n + ˆβ2
j,t|n)
= ˆβ⊤
t|n ˆβt|n + trace(Pt|n)
and we have used ˆβt|n = [ ˆβ1,t|n, . . . , ˆβp,t|n]⊤= E(βt | y1:n, θ(i)) and Pt|n =
{pjk,t|n, j, k = 1, . . . , p} = Var(βt | y1:n, θ(i)), provided by the ﬁxed-interval
smoothing algorithm of Sect. 3.3 (Theorem 3.4).
Substituting (4.44) into (4.43) we obtain
S1 = −n
2 log σ 2 −
1
2σ 2
n

t=1
(yt −x⊤
t ˆβt|n)2 −
1
2σ 2 x⊤
t Pt|nxt.
(4.45)

160
4
Model Speciﬁcation and Model Performance
Moving on to S2, from its deﬁnition above, we have
S2 = −n
2 log |Z| −1
2
n

t=1
E
%
(βt −Ftβt−1)⊤Z−1(βt −Ftβt−1) | y1:n, θ(i)&
.
(4.46)
In order to evaluate the expectation, as before, we expand the terms and taking
expectations
E
%
(βt −Ftβt−1)⊤Z−1(βt −Ftβt−1) | y1:n, θ(i)&
= E(β⊤
t Z−1βt | y1:n, θ(i))
−2E(β⊤
t−1F⊤
t Z−1βt | y1:n, θ(i)) + E(β⊤
t−1F⊤
t Z−1Ftβt | y1:n, θ(i))
(4.47)
These three expectations are
E(β⊤
t Z−1βt | y1:n, θ(i)) = E
%
trace(β⊤
t Z−1βt) | y1:n, θ(i)&
= E
%
trace(βtβ⊤
t Z−1) | y1:n, θ(i)&
= trace
%
E(βtβ⊤
t | y1:n, θ(i))Z−1&
= trace
%
(Pt|n + ˆβt|n ˆβ⊤
t|n)Z−1&
,
E(β⊤
t−1F⊤
t Z−1βt | y1:n, θ(i)) = trace
%
E(βtβ⊤
t−1 | y1:n, θ(i))F⊤
t Z−1&
= trace
%
[E[(βt −ˆβt|n)(βt−1 −ˆβt−1|n)⊤| y1:n, θ(i)]
+E(βt | y1:n, θ(i))E(β⊤
t−1 | y1:n, θ(i))]F⊤
t Z−1&
= trace
%
(Pt,t−1|n + ˆβt|n ˆβ⊤
t−1|n)F⊤
t Z−1&
and
E(β⊤
t−1F⊤
t Z−1Ftβt−1 | y1:n, θ(i)) = trace
%
E(βt−1β⊤
t−1 | y1:n, θ(i))F⊤
t Z−1Ft
&
= trace
%
(Pt−1|n + ˆβt−1|n ˆβ⊤
t−1|n)F⊤
t Z−1Ft
&
.
By substituting the three expectations above to (4.47) and (4.46) we obtain
S2 = −n
2 log |Z| −1
2
n

t=1
trace
%
(Pt|n + ˆβt|n ˆβ⊤
t|n −2(Pt,t−1|n + ˆβt|n ˆβ⊤
t−1|n)F⊤
t
+Ft(Pt−1|n + ˆβt−1|n ˆβ⊤
t−1|n)F⊤
t )Z−1&

4.3
Estimation of Hyperparameters
161
= −n
2 log |Z| −1
2
n

t=1
trace
%
{( ˆβt|n −Ft ˆβt−1|n)( ˆβt|n −Ft ˆβt−1|n)⊤+
Pt|n −Pt,t−1|nF⊤
t −FtP⊤
t,t−1|n + FtPt−1|nF⊤
t }Z−1&
.
(4.48)
Finally, from the deﬁnition of S3 we have
S3 = −1
2 log |P0|0| −1
2E
%
(β0 −ˆβ0|0)⊤P−1
0|0(β0 −ˆβ0|0) | y1:n, θ(i)&
.
(4.49)
The expectation term can be written as
E
%
(β0 −ˆβ0|0)⊤P−1
0|0(β0 −ˆβ0|0) | y1:n, θ(i)&
= E(β⊤
0 P−1
0|0β0 | y1:n, θ(i)) −2 ˆβ⊤
0|0P−1
0|0E(β0 | y1:n, θ(i)) + ˆβ⊤
0|0P−1
0|0 ˆβ0|0.
Now
E(β⊤
0 P−1
0|0β0 | y1:n, θ(i)) = trace
%
E(β0β⊤
0 | y1:n, θ(i))P−1
0|0
&
= trace
%
(P0|n + ˆβ0|n ˆβ⊤
0|n)P−1
0|0
&
and so replacing these expectations in (4.49) we obtain
S3 = −1
2 log |P0|0| −1
2trace
%
(( ˆβ0|n −ˆβ0|0)( ˆβ0|n −ˆβ0|0)⊤+ P0|n)P−1
0|0
&
.
(4.50)
The E-step is completed by noting that
Q(θ | θ(i)) = S1 + S2 + S3,
where S1, S2, S3 are computed by (4.45), (4.48), (4.50).
Moving on to the M-step we ﬁrst note that S1 = S1(σ 2) is a function of σ 2 only,
not depending on Z, ˆβ0|0 and P0|0. Likewise S2 is a function of Z only and S3 is a
function of ˆβ0|0 and P0|0 only. Thus in the M-step we have
∂S1
∂θ = ∂S1
∂σ 2 = −n
2σ 2 +
1
2σ 4
n

t=1
%
(yt −x⊤
t ˆβt|n)2 + x⊤
t Pt|nxt
&
and equating this to zero we ﬁnd
ˆσ 2 = 1
n
n

t=1
%
(yt −x⊤
t ˆβt|n)2 + x⊤
t Pt|nxt
&
.
(4.51)

162
4
Model Speciﬁcation and Model Performance
For S2 we have
∂S2
∂θ =
∂S2
∂vech(Z) = −n
2
∂log |Z|
∂vech(Z) −1
2
n

t=1
trace(AtZ−1)
∂vech(Z)
= −n
2
%
2Z−1 −diag(Z−1)
&
−1
2
n

t=1
[−2Z−1AtZ−1 + diag(Z−1AtZ−1)],
where
At = ( ˆβt|n −Ft ˆβt−1|n)( ˆβt|n −Ft ˆβt−1|n)⊤+ Pt|n −Pt,t−1|nF⊤
t −FtP⊤
t,t−1|n
+FtPt−1|nF⊤
t .
Now, equating ∂S2/∂θ to zero we obtain
n
2
%
2 ˆZ−1 −diag( ˆZ−1)
&
= 1
2
n

t=1
[−2 ˆZ−1At ˆZ−1 + diag( ˆZ−1At ˆZ−1)]
or
n

t=1
ˆZ−1At ˆZ−1 = n ˆZ−1
or
ˆZ = 1
n
n

t=1
At = 1
n
n

t=1

( ˆβt|n −Ft ˆβt−1|n)( ˆβt|n −Ft ˆβt−1|n)⊤
+Pt|n −Pt,t−1|nF⊤
t −FtP⊤
t,t−1|n + FtPt−1|nF⊤
t

.
Moving on to S3, simultaneous estimation of ˆβ0|0 and P0|0 is not available.
Speciﬁcation of these quantities outside of the EM algorithm is discussed in some
detail in Sect. 4.5. Following a similar treatment as that adopted in Shumway and
Stoffer (2017), ˆβ0|0 can be set equal to ˆβ0|n and P0|0 can be optimised so as to
maximise S3. Following a similar maximisation approach as that in S2, we conclude
that
ˆP0|0 = 1
n
%
( ˆβ0|n −ˆβ0|0)( ˆβ0|n −ˆβ0|0)⊤+ P0|n
&
.
Summing up, after the M-step we update the iteration vector
ˆθ(i+1) = [ˆσ 2, vech( ˆZ)⊤, ˆβ⊤
0|0, vech(ˆP0|0)⊤]⊤,

4.3
Estimation of Hyperparameters
163
and the algorithm proceeds with the E-step and M-step conditioned upon ˆθ(i+1).
The EM-algorithm is summarised below.
EM Algorithm for State Space Models
In the state space model (3.10a)–(3.10b) with information y1:n = {y1, . . . , yn}
the maximum likelihood estimate of the parameter vector
θ = [σ 2, vech(Z)⊤, ˆβ⊤
0|0, vech(P0|0)⊤]⊤,
is approximately ˆθ(N), where ˆθ(i) is iteratively computed as follows:
1. Initial estimate θ(0) =
%
(ˆσ 2)(0), vech( ˆZ(0))⊤, ( ˆβ(0)
0|0)⊤, vech(ˆP(0)
0|0)⊤&⊤
.
2. For each i = 0, 1, 2, . . . , N −1:
a. For each t = 0, 1, . . ., n Compute ˆβt|n, Pt|n, conditioned upon θ(i);
b. Compute
(ˆσ 2)(i+1) = 1
n
n

t=1
%
(yt −x⊤
t ˆβt|n)2 + x⊤
t Pt|nxt
&
;
ˆZ(i+1) = 1
n
n

t=1

( ˆβt|n −Ft ˆβt−1|n)( ˆβt|n −Ft ˆβt−1|n)⊤
+Pt|n −Pt,t−1|nF⊤
t −FtP⊤
t,t−1|n + FtPt−1|nF⊤
t

;
ˆβ(i+1)
0|0
= ˆβ0|n;
ˆP(i+1)
0|0
= 1
n
%
( ˆβ0|n −ˆβ0|0)( ˆβ0|n −ˆβ0|0)⊤+ P0|n
&
.
c. Set ˆθ(i+1) =
%
(ˆσ 2)(i+1), vech( ˆZ(i+1))⊤, ( ˆβ(i+1)
0|0
)⊤, vech(ˆP(i+1)
0|0
)⊤&⊤
.
Some comments are in order.
•
In step 2(a) the quantities ˆβt|n and Pt|n are the respective smoothed mean vector
and covariance matrix of βt, given θ = ˆθ(i). These are provided routinely by the
ﬁxed-interval smoothing theorem (Theorem 3.4).
•
If estimation of the initial mean vector ˆβ0|0 and covariance matrix P0|0 are not
required, then θ contains only the observation variance σ 2 and the transition
covariance matrix Z. As noted earlier, ˆβ0|0, P0|0 can be selected a priori by the
modeller, as discussed in Sect. 4.5.

164
4
Model Speciﬁcation and Model Performance
•
The EM algorithm can be used to estimate the design and transition components
xt = x and Ft = F, if those are time-invariant. However, for simplicity we have
not included this consideration in the above version of the EM algorithm. In this
book we propose that these components be speciﬁed according to each model
adoption.
•
The EM-algorithm terminates at N iterations when ˆθ(i+1) is very close to ˆθ(i),
for any i ≥N. Basically, this indicates that ˆθ(i) has converged to θ. The above
closeness is usually checked empirically by ensuring that the Eucledian distance
of θ(i+1) and θ(i) is smaller than some tolerance limit (for several iterations i),
i.e.
∥ˆθ(i+1) −ˆθ(i) ∥=
%
( ˆθ(i+1) −ˆθ(i))⊤( ˆθ(i+1) −ˆθ(i))
&1/2
< Tol,
where Tol is the tolerance limit, usually 0.001 or smaller. Discussion of the
termination of the algorithm and of further results on the asymptotic properties
of the maximum likelihood can be found in Shumway and Stoffer (2017) and in
Hannan and Deistler (1988).
For implementation in R, we use the function bts.EM of the package bts. The
command below provides maximum likelihood estimates of the observation and
transition variances σ 2 and Z of the local level model used for the annual central
temperatures of England example.
# needs data temp
> fit <- bts.EM( temp, x0=1, F0=1, Sigma0=1, Z0=1,
+ beta0=1, P0=1000, k=10 )
This function requires the argument temp (the data) and a list of components
(here xt = 1 and Ft = 1) are speciﬁed for the local level, as well as the prior mean
β0|0 = 1 and prior variance P0|0 = 1000 of β0. The values of Sigma0=1 and Z0=1
are the initial values σ 2(0) and Z(0) of σ 2 and Z. The function returns the estimated
values σ 2(i) and Z(i) of σ 2 and Z as well as the log-likelihood value of σ 2, Z at
each iteration i and they are shown in Table 4.1, for the ﬁrst ﬁve iterations.
We observe that the log-likelihood stabilises to the value of −309.9480 after just
two iterations and the estimated values of σ 2 and Z are 0.2923737 and 0.006257308;
the algorithm has converged after just three iterations.
To explore more the likelihood estimation Fig. 4.11 shows the contour plot of
the log=likelihood (left panel) and the log-likelihood of just σ 2 when Z = 0.006
Table 4.1 EM algorithm for
the estimation of σ 2 and Z
for the annual England
temperatures
Iteration (i)
σ (i)
Z(i)
Log-likelihood
0
1
1
–
1
0.2923771
0.02082655
−311.5735
2
0.2923737
0.006257376
−309.9480
3
0.2923737
0.006257308
−309.9480
5
0.2923737
0.006257308
−309.9480

4.3
Estimation of Hyperparameters
165
0.5
1.0
1.5
2.0
2.5
0.05
0.10
0.15
0.20
0.25
0.30
Contour plot of the log-likelihood
2
Z
0.0
0.5
1.0
1.5
2.0
-1600
-1400
-1200
-1000
-800
-600
-400
Log-likelihood function
2
log-likelihood
 =0.292 (Z=0.006)
LL=-309.9259
2
Fig. 4.11 Contour plot and marginal likelihood of the annual England temperature data)
(right panel). The contour plot shows that the maximum is obtained on the white-
shaded area, agreeing with the results provided from the EM algorithm. Because
it is difﬁcult to visualise the exact maximum of the log-likelihood in that white-
shaded area, the right panel of Fig. 4.11 shows the log-likelihood of σ 2 when Z
is estimated as 0.006. We observe that the log-likelihood is maximised for ˆσ 2 =
0.292 with a corresponding maximum likelihood at −309.9259, which again agree
with the results of the EM algorithm shown in Table 4.1. In order to obtain the
contour plot we had to run the Kalman ﬁlter many times and this results in a very
slow approach to ﬁnding the maximum; indeed this approach is used here only for
visualisation purposes, while we recommend the application of the EM algorithm,
which is remarkably faster and more accurate.
4.3.2
Speciﬁcation of Zt Using Discount Factors
Out of the possible hyperparameters that require speciﬁcation, the transition covari-
ance matrix Zt is of particular interest. If Zt is time-invariant and if its dimensions
are small (e.g. as in the examples above), then maximum likelihood may be applied.
However, one may observe that as Zt is a p × p covariance matrix, there are
p(p + 1)/2 distinct elements to be speciﬁed, for each t. Indeed, note that such a
matrix may be written as
Zt =
⎡
⎢⎢⎢⎣
Z11,t Z12,t · · · Z1p,t
Z12,t Z22,t · · · Z2p,t
...
...
...
...
Z1p,t Z2p,t · · · Zpp,t
⎤
⎥⎥⎥⎦,

166
4
Model Speciﬁcation and Model Performance
so that Zij,t = Zji,t and the distinct elements are the p elements of the main
diagonal plus half of p2 −p remaining elements, or p + (p2 −p)/2 = p(p + 1)/2.
We observe that the problem of the speciﬁcation of Zij,t is inﬂated by the dimension
p. Even for relatively low values of p, e.g. p = 5, there are too many elements to
specify (for p = 5 there are 15 distinct elements to specify). Furthermore, it is likely
that over time Zt will fail to be time-invariant; the inclusion of the time-index in Zt
allows for different stochastic evolutions of the unobserved states βt, since Zt is
the covariance matrix of ζt = βt −Ftβt−1 (see the transition equation (3.10b)). In
other words Zt controls the stochastic magnitude of change of βt from Ftβt−1 and
as such, Zt is likely to change with the course of time. The assumption of a time-
invariant Zt = Z (adopted in the previous section) is usually done for convenience
and it may be valid only for short periods of time.
For these reasons a practical approach of the speciﬁcation of Zt is required.
Consider ﬁrst the dynamic (or time-varying) regression state space model (3.9a)–
(3.9b) and see that the Kalman ﬁlter recursions for ˆβt|t and Pt|t are exactly the same
as those of the recursive least squares (RLS) algorithm, described in Sect. 3.1.2, if
we set σ 2 = 1 and
Zt = δ−1(1 −δ)Pt−1|t−1,
(4.52)
where δ is the discount factor of the RLS and Pt−1|t−1 is the covariance matrix
of βt−1, given information y1:t−1. To see this just write down the Kalman ﬁlter
recursions for the above state space model, i.e.
ˆβt|t = ˆβt|t−1 + ktet,
Pt|t = Pt|t−1 −KtK⊤
t /qt|t−1
Kt = Pt|t−1xt/qt|t−1,
qt|t−1 = x⊤
t Pt|t−1xt + 1,
Pt|t−1 = Pt−1|t−1 + Zt
and et is the residual at time t. Then replacing Zt as in (4.52) and σ 2 = 1 we obtain
the recursions of the RLS, with ˆβt|t = ˆβ and Pt|t = Pt.
It is important to explain the contribution of the discount factor δ in (4.52). We
ﬁrst note from the discussion of Sect. 3.1.2 that 0 < δ ≤1. If δ = 1, this reduces
Zt to zero and basically this implies βt = βt−1, with probability 1, for all t, i.e.
βt = β is time-invariant and model (3.9a)–(3.9b) reduces to an ordinary regression
model, as its parameter vector β is time-invariant (the transition equation of the state
space model vanishes). In this case the Kalman ﬁlter recursions (with Zt = 0) and
the RLS recursions (with λ = 1) reduce to the well-known ordinary least squares
(OLS), presented in Sect. 3.1.1.
On the other extreme when δ approaches zero, the factor (1 −δ)/δ tends to
inﬁnity, which means that Zt introduces erratic shocks on the evolution of βt. In
any case values close, but less than one should considered, typically in the range
[0.7, 0.999], as argued by West and Harrison (1997, Chapter 6) and their co-authors.

4.3
Estimation of Hyperparameters
167
Motivated by the above discussion, and considering the general state space model
(3.10a)–(3.10b), Zt may be speciﬁed using a forgetting factor λ as
Zt = δ−1(1 −δ)FtPt−1|t−1F⊤
t .
(4.53)
We can observe that Zt of (4.53) is reduced to Zt of (4.52), if we set Ft = I (i.e.
in the above time-varying regression model). Similar comments as above apply for
the behaviour of Zt for extreme values of δ (at zero and at one). By specifying Zt
using a discount factor, we reduce a problem of speciﬁcation of p(p+1)/2 elements
to just a single element (the discount factor). Furthermore, we automatically make
Zt time-varying, since it depends on the time-varying component FtPt−1|t−1F⊤
t ,
which is the covariance matrix of Ftβt−1|t−1, given information y1:t−1. Unlike the
maximum likelihood approach of the previous section (which requires a full set of
data y1:n), the approach using discount factors makes the speciﬁcation of Zt suitable
for on-line application (if δ is chosen). In the implementation of complex state space
models, more than one discount factor may be used (for an example of this see
Sect. 4.1.4); for more information about such models and the concept of discounting
in the speciﬁcation of Zt the reader is referred to West and Harrison (1997) and to
references therein.
4.3.3
Estimation of σ 2: Conjugate Bayesian Estimation
In the previous sections the hyperparameter vector θ is assumed implicitly to be a
vector of constants, subject to estimation. Within a Bayesian framework, one may
assume that θ is a random vector and a priori distribution may be chosen for θ, with
density function say p(θ). Then, given a set of observed data y1:n = {y1, . . . , yn},
the posterior p(θ | y1:n) is provided by the formula
p(θ | y1:n) ∝p(y1:n | θ)p(θ) = p(y1, . . . , yn | θ)p(θ)
= p(yn | θ, y1:n−1)p(y1, . . . , yn−1 | θ)p(θ)
= p(yn | θ, y1:n−1)p(θ | y1:n−1).
This formula may be applied sequentially. At time t = 1 starting at a prior p(θ),
the posterior density p(θ | y1) is proportional to p(y1 | θ) (the likelihood using
the single observation y1) times the prior p(θ). Then at t = 2, the posterior density
p(θ | y1:2) is proportional to p(y2 | θ, y1) (the one-step forecast density which,
conditional on θ, is available from the Kalman ﬁlter) times the posterior at time
t = 1, p(θ | y1), which is equal to the prior distribution of θ at time t = 2 (i.e. before
observing y2). This process is repeated over time, giving the sequential updating
p(θ | y1:t) ∝p(yt | θ, y1:t−1)p(θ | y1:t−1),
(4.54)

168
4
Model Speciﬁcation and Model Performance
for any t = 1, . . . , n. In Eq. (4.54) p(yt | θ, y1:t−1) is the one-step forecast
distribution of yt, given θ, which is provided by the Kalman ﬁlter and is a Gaussian
distribution, and p(θ | y1:t−1) is the posterior distribution of θ at time t −1, which
is provided by Eq. (4.54), if we start from an initial prior p(θ).
The above framework can only provide the posterior distribution of θ up to
a proportionality constant. This proportionality constant involves integration over
complex non-linear functions and usually in high dimensions. Typically, for most
cases, this means no closed calculations and thus for the evaluation of p(θ | y1:t),
one may have to resort to simulation-based methods, such as Markov chain Monte
Carlo or particle ﬁltering, or approximations. Such approaches are discussed in
many textbooks, see e.g. Gamerman and Lopes (2006) and Petris et al. (2009,
Section 4.4).
In this section, in the very special, but important, case of θ
= 1/σ 2, we
discuss conjugate Bayesian estimation, which does not need to rely on simulation
or numerical approximations.
We start by considering state space model (3.10a)–(3.10b), where σ 2 = Var(ϵt)
is subject to estimation and the transition covariance matrix is scaled by σ 2, so that
Var(ζt) = Zt = σ 2Z∗
t for known covariance matrix Z∗
t . Thus, the current working
model can be written as
yt = x⊤
t βt + ϵt,
ϵt ∼N(0, σ 2),
(4.55a)
βt = Ftβt−1 + ζt,
ζt ∼N(0, σ 2Z∗
t ).
(4.55b)
Furthermore, the prior (initial) covariance matrix of β0 is also scaled by σ 2, i.e.
Var(β0) = σ 2P∗
0|0, where P∗
0|0 is assumed known. This model, which is known as
scaled observational model, is described in some detail in West and Harrison (1997,
Section 4.5); some generalisations of this model are given in Triantafyllopoulos and
Harrison (2008).
Deﬁne θ = 1/σ 2 and assume that initially θ follows a gamma distribution with
parameters n0/2 and d0/2, written as
θ = 1
σ 2 ∼G
n0
2 , d0
2
	
.
(4.56)
Suppose that at time t −1, the posterior distribution of θ is
θ | y1:t−1 ∼G
nt−1
2
, dt−1
2
	
,
(4.57)
for some known values of nt−1 and dt−1.
Note that conditionally on θ (or on σ 2), from the Kalman ﬁlter (see Theorem 3.2
in Sect. 3.2) it is yt | θ, y1:t−1 ∼N( ˆyt|t−1, σ 2q∗
t|t−1), with ˆyt|t−1 as in the above
theorem and q∗
t|t−1 = x⊤
t P∗
t|t−1xt + 1. Thus, conditionally on σ 2 all recursions

4.3
Estimation of Hyperparameters
169
of σ 2P∗
t|t and σ 2P∗
t|t−1 follow from an application of the Kalman ﬁlter, where the
recursions of P∗
t|t and P∗
t|t−1 are provided by Theorem 3.2.
Then, applying formula (4.54) we obtain
p(θ | y1:t) ∝p(yt | θ, y1:t−1)p(θ | y1:t−1)
∝
√
θ exp
 
−(yt −ˆyt|t−1)2θ
2q∗
t|t−1
!
θnt−1/2−1 exp

−dt−1θ
2
	
= θ(nt−1+1)/2−1 exp

−1
2
 
(yt −ˆyt|t−1)2
q∗
t|t−1
+ dt−1
!
θ
+
,
so that p(θ | y1:t) is proportional to a gamma distribution with parameters nt/2 and
dt/2, or
θ | y1:t ∼G
nt
2 , dt
2
	
,
(4.58)
where
nt = nt−1 + 1
and
dt = dt−1 +
e2
t
q∗
t|t−1
,
(4.59)
and as usual et = yt −ˆyt|t−1 is the residual at time t.
Equations (4.56), (4.57) and (4.58) prove by induction the gamma posterior
distribution (4.58) of θ | y1:t. Indeed, for t = 1, (4.57) is just the assumed prior
(4.56).
Considering estimation of βt, we ﬁrst observe that conditionally on θ, the
posterior distribution of βt is given by βt
| θ, y1:t
∼N( ˆβt|t, σ 2P∗
t|t), where
ˆβt|t and P∗
t|t are provided by the Kalman ﬁlter (see Theorem 3.2 in Section 3.2).
Consequently, the posterior distribution of βt is found by integrating out θ from the
joint distribution of βt and θ, i.e.
p(βt | y1:t) =
"
Rp p(βt, θ | y1:t) dθ
=
"
Rp p(βt | θ, y1:t)p(θ | y1:t) dθ
∝
"
Rp θp/2 exp

−1
2(βt −ˆβt|t)⊤P∗−1
t|t (β −ˆβt|t)θ

×θnt/2−1 exp

−dtθ
2
	
dθ

170
4
Model Speciﬁcation and Model Performance
=
"
Rp θ(nt+p)/2−1
× exp
(
−1
2
%
(βt −ˆβt|t)⊤P∗−1
t|t (βt −ˆβt|t) + dt
&
θ
)
dθ.
Recall that if a random variable X follows a gamma distribution, X ∼G(α, β), then
" ∞
0
xα−1 exp(−βx) dx = (α)
βα .
(4.60)
By applying this formula for α = (nt +p)/2 and β = 2−1(βt −ˆβt|t)⊤P∗−1
t|t (βt −
ˆβt|t) + dt, we have that
p(βt | y1:t) ∝
%
(βt −ˆβt|t)⊤P∗−1
t|t (βt −ˆβt|t) + dt
&−(nt+p)/2
.
By deﬁning St = dt/nt, the above density is proportional to a multivariate t
distribution βt | y1:t ∼t(nt, ˆβt|t, Pt|t), with nt degrees of freedom, location vector
ˆβt|t and scale matrix Pt|t, where Pt|t = StP∗
t|t. Similarly, it can be established that
βt | y1:t−1 ∼t(nt−1, ˆβt|t−1, Pt|t−1) and yt | y1:t−1 ∼t(nt−1, ˆyt|t−1, qt|t−1), with
Pt|t−1 = St−1P∗
t|t−1, qt|t−1 = St−1q∗
t|t−1 = x⊤
t Pt|t−1xt + St−1 and as mentioned
earlier the recursions of P∗
t|t, P∗
t|t−1 and q∗
t|t−1 are provided by the Kalman ﬁlter.
This shows that
Pt|t = StP∗
t|t =
St
St−1
(Pt|t−1 −KtK⊤
t qt|t−1).
Furthermore, we can write dt = ntSt and from (4.59) we obtain
ntSt = nt−1St−1 + St−1e2
t
qt|t−1
,
which can be simpliﬁed further to give
ntSt = nt−1St−1 + rtet,
(4.61)
where rt = yt −x⊤
t ˆβt|t. To establish this recursion, write
rt = yt −x⊤
t ˆβt|t = yt −x⊤
t ˆβt|t−1 −x⊤
t Ktet = (1 −x⊤
t Kt)et
and observe that
1 −x⊤
t Kt = 1 −x⊤
t Pt|t−1xt/qt|t−1 = qt|t−1 −x⊤
t Pt|t−1xt
qt|t−1
= St−1
qt|t−1
.

4.3
Estimation of Hyperparameters
171
Some comments are in order.
•
First note that since 1/σ 2 | y1:t ∼G(nt/2, dt/2), it follows that, given y1:t, σ 2
follows an inverse gamma distribution with scale and shape parameters nt/2 and
dt/2, i.e. σ 2 | y1:t ∼IG(nt/2, dt/2). A point estimate of σ 2 can be taken as
the mode of IG(nt/2, dt/2), which from the properties of the inverse gamma
distribution (see Chap. 2) is
ˆσ 2
t = mode(σ 2 | y1:t) =
dt/2
nt/2 + 1 =
ntSt
nt + 2.
(4.62)
We note that for large t, the ratio nt/(nt + 2) is close to one, hence ˆσ 2
t ≈St; the
posterior distribution of βt and the forecast distribution of yt are approximately
Gaussian.
•
For the estimation of σ 2 formula (4.61) coincides with the formula providing
maximum likelihood estimation in recursive least squares (see Theorem 3.1 in
Sect. 3.1.2). Obviously, (4.61) refers to a more general model (e.g. when Ft is
not equal to the identity matrix). Moreover, the above approach of Bayesian
estimation for σ 2 provides much more information than maximum likelihood
estimation, e.g. it offers the availability of credible bounds based on the gamma
distribution.
•
It is worthwhile pointing out that using Eq. (4.61) the point estimate ˆσ 2
t can be
calculated recursively.
•
We can see that the evaluation of the Kalman gain is unaffected by the estimation,
i.e. K∗
t = Kt. Indeed
K∗
t =
P∗
t|t−1xt
q∗
t|t−1
=
St−1P∗
t|t−1xt
St−1q∗
t|t−1
= Pt|t−1xt
qt|t−1
= Kt.
Below is a summary of the algorithm.
Scaled Observational Precision (SOP)
1. Prior distributions at t = 0:
β0 ∼t(n0, ˆβ0|0, P0|0) and σ −2 ∼G(n0/2, n0S0/2);
2. Posterior distribution of βt−1 at time t −1:
βt−1 | y1:t−1 ∼t(nt−1, ˆβt−1|t−1, Pt−1|t−1);
3. Prior distribution of βt at time t:
βt | y1:t−1 ∼t(nt−1, ˆβt|t−1, Pt|t−1),
where ˆβt|t−1 = Ft ˆβt−1|t−1 and Pt|t−1 = FtPt−1|t−1F⊤
t + Zt;
(continued)

172
4
Model Speciﬁcation and Model Performance
4. Posterior distributions at time t:
βt | y1:t ∼t(nt, ˆβt|t, Pt|t) and σ −2 | y1:t ∼G(nt/2, ntSt/2), where
ˆβt|t = ˆβt|t−1 + Ktet,
Pt|t =
St
St−1

Pt|t−1 −qt|t−1KtK⊤
t

,
nt = nt−1 + 1
and
ntSt = nt−1St−1 + rtet,
ˆyt|t−1 = x⊤
t ˆβt|t−1,
et = yt −ˆyt|t−1,
rt = yt −x⊤
t ˆβt|t,
Kt = Pt|t−1xt/qt|t−1
qt|t−1 = x⊤
t Pt|t−1xt + St−1.
We note that in the application of the above algorithm P0|0 and Zt are speciﬁed
without any reference to P∗
0|0, Z∗
t and to S0. Without loss of generality, P0|0 is set,
as in the Kalman ﬁlter algorithm (see also Sect. 4.5) and Zt is set via maximum
likelihood or via discount factors. It turns out that the above approach to the
estimation of σ 2 combined with specifying Zt by forgetting factors as in Sect. 4.3.2
provides an attractive methodology for estimating/specifying the hyperparameters
σ 2 and Zt. This is illustrated in the example below.
Example 4.8 (Annual Temperature Example Continued)
We consider again the
annual temperatures in England, discussed in Example 3.1. In that example a local
level model, given by Eqs. (3.13a) and (3.13b), was ﬁtted with a somewhat arbitrary
choice of σ 2 = 1 and Z = 10. In this section we reﬁt the model using the
observational scaled model, for the estimation of σ 2, and employing forgetting
factors to specify Zt.
To implement the model in R, we used the function sop.ss available from the
book website.
> # read data
> # need temp
> # fit SOP model with delta=0.95
> fit1 <- bts.filter(temp, x0=1, F0=1, delta=0.95,
+ beta0=9, P0=1000, n0=1/100, S0=1)
> # fit SOP model with delta=0.8
> fit2 <- bts.filter(temp, x0=1, F0=1, delta=0.8,
+ beta0=9, P0=1000, n0=1/100, S0=1)
> # time series plot
> pred1 <- ts(fit1$FittedMean, start=1659, frequency=1)
> pred2 <- ts(fit2$FittedMean, start=1659, frequency=1)
> tempts<-ts(temp, start=1659, frequency=1)
> par(mfrow=c(2,1))
> ts.plot(tempts,main=expression("SOP model
+ with discount factor 0.95"), xlab="Year",
+ ylab="Degrees in Celsius")
> lines(pred1, lty=2,lwd=2, col=2)
> legend("bottomright",c("Observations","Forecast mean"),

4.3
Estimation of Hyperparameters
173
+ pch=c(20, 1), col=c(1,2))
> ts.plot(tempts,main=expression("SOP model
+ with discount factor 0.8"), xlab="Year",
+ ylab="Degrees in Celsius")
> lines(pred2, lty=2,lwd=2, col=2)
> legend("bottomright",c("Observations","Forecast mean"),
+ pch=c(20, 1), col=c(1,2))
Figure 4.12 shows the one-step forecast means ˆyt|t−1 (for values of the discount
factor δ = 0.95 and δ = 0.8) against the actual data. We observe that when δ =
0.95, the forecasts are smooth, not being able to follow closely the dynamics of
the time series; for δ = 0.8, the forecasts are more adaptive following better the
local ﬂuctuations of the time series. Figure 4.13 shows the estimate St of σ 2, plotted
against the actual time series data of the temperatures. We observe that at the start St
ﬂuctuates much more than in later years, for which it is remarkably small. We also
observe that the evolution of St follows ﬂuctuations of the observed data (as shown
in the top panel of Fig. 4.13), e.g. near the year 1750 there seems to be an outlier
in the data and this is reﬂected in St by a high estimated observation variance. This
pinpoints one of the advantages of the SOP model: unlike the maximum likelihood
SOP model with discount factor 0.95
Year
Degrees in Celsius
1650
1700
1750
1800
1850
1900
1950
2000
7
8
9
10
Observations
Forecast mean
SOP model with discount factor 0.8
Year
Degrees in Celsius
1650
1700
1750
1800
1850
1900
1950
2000
7
8
9
10
Observations
Forecast mean
Fig. 4.12 One-step forecast means (dashed lines) of temperature values of central England (solid
lines)

174
4
Model Speciﬁcation and Model Performance
Annual central temperatures of England
Year
Degrees in Celsius
1650
1700
1750
1800
1850
1900
1950
2000
7
8
9
10
Estimate of the observation variance
Year
Variance
1650
1700
1750
1800
1850
1900
1950
2000
0.0
0.1
0.2
0.3
0.4
Fig. 4.13 One-step forecasts of the observation variance of central England temperatures
estimation, it can capture local effects in the variance as well as in the mean of
the data, while the likelihood approach (similarly as in least squares estimation)
only captures an overall optimum model performance. The R code for producing
Fig. 4.13 is
> par(mfrow=c(2,1))
> ts.plot(tempts, xlab="Year", ylab="Degrees in Celsius",
+ main=expression("Annual central temperatures of England"))
> var1 <- ts(fit1$ObsVar, start=1659, frequency=1)
> ts.plot(var1, xlab="Year", ylab="Variance",
+ main=expression("Estimate of the observation variance"))
4.4
Error Analysis
In the above sections we have seen how a state space model can be built, how the
design vector xt and the transition matrix Ft can be chosen and how the observation
variance σ 2 and the transition covariance matrix Zt may be estimated or speciﬁed.
Furthermore, we have seen how hyperparameters included in these models may be

4.4
Error Analysis
175
estimated. In this section we deal with the goodness of ﬁt of a chosen model and
with the closely related area of model choice.
We start by exploring the goodness of ﬁt problem, known variously as error
analysis or as residual analysis. We will suppose we have speciﬁed a state space
model (3.10a)–(3.10b) and that the above model components (xt, Ft, σ 2, Zt) have
been chosen or estimated, based on an observed data set y1:t = {y1, . . . , y1:n},
for some positive integer n. We will also assume that the prior mean vector ˆβ0|0
and covariance matrix P0|0 (and perhaps the prior of 1/σ 2) have been chosen or
estimated; for a related discussion see Sect. 4.5. Error analysis attempts to answer
the question of how well the model explains the data. The model performance is
usually understood in terms of forecast accuracy. If the model is a good ﬁt to the
data, then the forecasts should be close to the observed data. Consequently, measures
of goodness of ﬁt are usually based on the residuals or one-step forecast errors,
deﬁned as the difference of the one-step forecasts ˆyt|t−1 from the observations yt,
i.e.
et = yt −ˆyt|t−1,
(4.63)
Hence their analysis (residual or error analysis) is used to assess the goodness of
model ﬁt.
The following theorem provides some properties of the residuals.
Theorem 4.2 In the state space model (3.10a)–(3.10b) and with the deﬁnitions of
the Kalman ﬁlter recursions (Theorem 3.2) for some data y1:n = {y1, . . . , yn}, the
following apply for the residuals.
1. Given y1:t−1, the distribution of the residuals is et | y1:t−1 ∼N(0, qt|t−1), where
qt|t−1 is the forecast variance of yt, provided by the Kalman ﬁlter.
2. e1, . . . , en are independent.
3. With the deﬁnitions of et and q|t−1 as above,
n

t=1
e2
t
qt|t−1
∼χ2
n,
where χ2
n denotes the chi-square distribution with n degrees of freedom.
Proof (1) follows by noting that the one-step forecast distribution of yt is yt |
y1:t−1 ∼N( ˆyt|t−1, qt|t−1), see Theorem 3.2.
For (2), ﬁrst we prove that et is uncorrelated with any function ht
=
h(y1, . . . , yt−1) of y1, . . . , yt−1. From (1) we have E(et | y1:t−1) = 0, and so
using the tower property (5a) we have E(et) = 0. Then using again the tower
property
Cov(et, ht) = E(etht) = E[E(etht | y1:t−1)] = E[htE(et | y1:t−1)] = 0.

176
4
Model Speciﬁcation and Model Performance
Note that from (4.63), et is a function of yt, yt−1, . . . , y1, since ˆyt|t−1 is a
function of yt−1, . . . , y1. Thus, by replacing ht = et−s, for any s = 1, . . . , t −1,
we have that et and et−s are uncorrelated, and since from (1) they are normally
distributed, they are also independent. By repeating this result, for each t, the
independence of e1, . . . , et follows.
From (1) we have that et/√qt|t−1 ∼N(0, 1) and so e2
t /qt|t−1 ∼χ2
1. Since
e1, . . . , en are independent from (2), the sum n
t=1 e2
t /qt|t−1 follows the stated chi-
square distribution.
⊓⊔
The above theorem provides important information that can be used to form an
error analysis. The following gives a summary: From (1), the mean of et is zero. So
an informal criterion of goodness of ﬁt is to plot the residuals over time. If the ﬁt
is good, the residuals should ﬂuctuate around 0. But because the variance of et is
qt|t−1, which can vary over time, it is better to work with the standardised residuals,
deﬁned as
e∗
t =
et
√qt|t−1
,
which, from the proof of (3) in Theorem 4.2, follow a N(0, 1) standard normal
distribution. Again a plot of e∗
t should not reveal any structure, e∗
t should ﬂuctuate
around zero having variance 1. So, in order to assess the goodness of ﬁt, we have
the following:
•
Plot e∗
t against 95% credible bounds (or more generally, against (1−α)% credible
bounds). For a good ﬁt, approximately 5% or α% of et should lie outside the
bounds.
•
Compute the mean of squared residuals or errors (MSE), the mean of squared
standardised residuals or errors (MSSE), and the mean absolute deviation
(MAD), deﬁned by
MSE = 1
n
n

t=1
e2
t ,
MSSE = 1
n
n

i=1
e∗2
t ,
MAD = 1
n
n

t=1
|et|,
respectively. For a good ﬁt, MSE and MAD should be close to 0, while MSSE
should be close to 1. The MSE and MAD have been used extensively in signal
processing (Haykin, 2001) and in econometrics (Harvey, 1989), but they do
not take into account the variance of the forecasts qt|t−1. MSSE does take this
variance into account, but it is usually harder to interpret it, in particular it is hard
to distinguish the effects of the residual mean from the residual variance. For
example, if the value of MSSE is 1.5 (higher than 1), we do not know whether
this is due to high average residuals or too low variance qt|t−1. Likewise, it is
hard to interpret differences between say values of MSSE equal to 0.8 and 1.2.
As a result, usually MSSE is presented together with MSE or MAD. Sometimes
MSSE is avoided, because it is very hard to forecast accurately the variance and
its mis-speciﬁcation may lead to several types of bias.

4.4
Error Analysis
177
•
Since the residuals e1, . . . , en are independent, see (2) of Theorem 4.2, another
goodness of ﬁt tool is to assess whether they are not correlated or autocorrelated.
This can be done by plotting the autocorrelation function (ACF), for several
lags (this plot is known as a correlogram), for a discussion of the ACF and its
theoretical properties the reader is referred to Box et al. (2008) or to Shumway
and Stoffer (2017). In short, the ACF is a sequence, each value of which
comprises the sample correlations of et+k and et, for a lag k = 1, 2, . . .. If the
residuals are uncorrelated, all values of the ACF should lie within ±1.96/√n.
More formal tests exist and they can be found in the above references. In R, the
ACF and the correlogram plot can be obtained by using the function acf.
•
Finally, based on part (3) of Theorem 4.2, we can assess whether overall the
residuals are low to see whether the sum of (e∗2
t
follows a chi-square distribution
with n degrees of freedom, for example one may compare the observed sum with
the 95% quantile of χ2
n. This test is relevant to the popular portmanteau test of
Box and Pierce (see Box et al. (2008)), aimed at ARMA models.
Example 4.9 (Turkey Example Continued)
We revisit Example 4.1.4 of the turkey
sales data. We are assuming that the trend-seasonal model described in that
example is ﬁtted in R and the objects fit$f and q (referring to ˆyt|t−1 and qt|t−1,
respectively) are obtained (see p. 134 for the R code). Here, we examine the quality
of the ﬁt, using the error analysis described above. The residuals and standardised
residuals are computed in R using the commands
> # need turkey (for the data) and object fit (fitted Kalman filter)
> pred <- ts(fit$FittedMean,start=c(1974,1), frequency=4)
> predVar <- ts(fit$FittedVar, start=c(1974,1), frequency=4)
> # define residuals
> e <- q <- rep(NA,35)
> for(t in 1:35){
+ e[t] <- turkey[t]-fit$FittedMean[[t]]
+ q[t] <- fit$FittedVar[[t]]
+ }
> estar <- e/sqrt(q)
The left panel of Fig. 4.14 plots the standardised residuals e∗
t together with the
95% credible bound at ±1.96 of the standard normal distribution. Moving on to the
independence check for the residuals, the left Fig. 4.14 is the correlogram of the
standardised residuals. We observe that all values of the ACF (the value of the ACF
at lag k = 0 is always equal to 1) are within the 95% credible bounds, and so we
conclude that the standardised residuals appear to be uncorrelated.
The R code used for Fig. 4.14 is
> # plot of the stand residuals
> par(mfrow=c(1,2))
> ts.plot(estar, main=expression("Standardized residuals
+ for the turkey data"),xlab="Quarters",ylab="Residual")
> points(estar, pch=20)
> abline(h=1.96, lty=3)
> abline(h=-1.96, lty=3)
> acf(estar,main=expression("ACF of the standardized residuals"))

178
4
Model Speciﬁcation and Model Performance
Standardized residuals for the turkey data
Quarters
Residual
0
5
10
15
20
25
30
35
-4
-2
0
2
0
5
10
15
-0.2
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
ACF of the standardized residuals
Fig. 4.14 Residuals (left panel) and correlogram of the residuals (right panel) for the turkey data
We can see that the mean of the residuals is close to 0, but the variance is above
3, e.g. in R
> mean(estar)
[1] 0.01101288
> var(estar)
[1] 3.143806
The proportion of outliers (exceeding the 95% credible bounds of N(0, 1)) is
22.86%, which is too high (normally we would expect only a 5% of e∗
t to exceed
the bounds). This can be checked easily in R by using the command
> # proportion of outliers of residuals
> length(estar[abs(estar)>1.96])/length(estar)
[1] 0.2285714
As we observe in Fig. 4.14 most of the outliers appear in the start of the data. One
option would be to discard the ﬁrst say 10 observations, accounting them to the
learning stage of the model. If we apply this, the proportion of outliers falls to
8%, still quite high. This may be an indicator that the forecast variance qt|t−1 is
underestimated (providing a smaller divider in e∗
t than it should be). In turn, this
could be the cause of a mis-speciﬁcation of the observation variance σ 2. If, for
example σ 2 is underestimated, this will result in underestimation of qt|t−1.
The MSE, MSSE and MAD are computed as
> # MSE
> mean(e^2)
[1] 11196.55
> # MSSE
> mean(estar^2)

4.4
Error Analysis
179
[1] 3.054104
> # MAD
> mean(abs(e))
[1] 76.38005
We note the MSE and MAD appear to be too large and it is hard to make any
interpretation, based only on this. This is because they both depend on the scale of
the observations {yt}. The MSSE does not suffer from this effect, but here it appears
to be very high, reﬂecting the miss-speciﬁcation or underestimation of qt|t−1.
Finally, checking overall the residuals we have that 35
t=1(e∗
t )2 = 106.111, while
the one-sided 95% quantile of the chi-square distribution with 35 degrees of freedom
is only 49.802 (provided by the command qchisq(0.95, 35)). This implies
that the overall quality of ﬁt is poor, producing some large absolute residuals. When
referenced against χ2
25 (excluding the ﬁrst 10 residuals as suggested earlier), the
result is clearly signiﬁcant at conventional levels—the p-value is 0.00336.
The above error analysis and model ﬁt assessment are based on the assumptions
of Theorem 4.2, which again adopts the assumptions of the Kalman ﬁlter algorithm
(see Theorem 3.2 in Sect. 3.2). In particular, the normality assumption is used
in all parts (1)–(3) in Theorem 4.2. If model hyperparameters are estimated, e.g.
via maximum likelihood or via conjugate Bayesian estimation, then the normality
of the residuals et is either approximate, or it is lost. When we estimate the
hyperparameters using the maximum likelihood principle, we can consider the
residuals conditional on the maximum likelihood estimates. A similar approach
can be followed when we specify the transition matrix Zt using forgetting factors.
When we use the Bayesian conjugate inference for the estimation of the observation
variance σ 2, we know that, unconditionally on σ 2, the forecast distribution of yt
is a Student t distribution, i.e. yt | y1:t−1 ∼t(nt−1, ˆyt|t−1, qt|t−1), where nt−1
are the degrees of freedom, ˆyt|t−1 is the mode and qt|t−1 is the scale of the above
t distribution, see also Sect. 4.3.3. We note that in this case ˆyt|t−1 is the forecast
mean (since the mode is the same as the mean of the t distribution), but the forecast
variance is nt−1(nt−1 −2)−1qt|t−1 and not qt|t−1 (as it is in the Kalman ﬁlter).
Based on the above, related to parts (1)–(2) of Theorem 4.2, we have
1. The distribution of the residual et is et | y1:t−1 ∼t(nt−1, 0, qt|t−1).
2. The residuals e1, . . . , en are uncorrelated.
(1) follows immediately from the deﬁnition of yt and the t distribution of yt | y1:t−1.
Thus, the standardised residual e∗
t
= et/√qt|t−1 follows a standard Student t
distribution with nt−1 degrees of freedom, i.e. e∗
t | y1:t−1 ∼t(nt−1, 0, 1). This
implies that E(e∗
t | y1:t−1) = 0 and Var(e∗
t | y1:t−1) = nt−1(nt−1 −2)−1, for
nt−1 > 2, or inﬁnity otherwise. Thus, the three performance measures MSE, MAD
and MSSE are computed as above, but now the value of MSSE should be compared
to nt−1(nt−1 −2)−1, instead of 1, which was the case for the normal distribution
discussed above. From the distribution of e∗
t we can calculate (1 −α)% credible
bounds of e∗
t , given by ±tnt−1,1−α/2, where tnt−1,1−α/2 is the (1 −α/2)-quantile of

180
4
Model Speciﬁcation and Model Performance
the t distribution for nt−1 degrees of freedom. In R we can use the function qt for
the quantile of the t distribution, e.g. for nt−1 = 10 and α = 0.05, we have
> qt(df=10, 1-0.05/2)
[1] 2.228139
so that a 95% credible bound for e∗
t is [−2.228, 2.228]. One point to note is that
in this case the credible bounds for the standardised residuals are time-varying,
starting at wider intervals and converging to the time-invariant bounds of the normal
distribution, e.g. we can check that t100000,1−0.05/2 = 1.959988, which is very close
to 1.959964, the respective quantile using the normal distribution, provided in R by
qnorm(1-0.05/2). We observe that for early points of time the credible bounds
are much wider using the Student t distribution, and this reﬂects the additional
uncertainty in the early period in the estimation of σ 2. With the course of time, more
data become available, and the estimation of σ 2 becomes more accurate, and thus the
credible bounds approach the limiting credible bounds of the normal distribution.
This is theoretically justiﬁed as the probability density function of the Student t
distribution converges to that of the normal distribution as t →∞or νt →∞. The
proof of (2) is the same as that in Theorem 4.2.
4.5
Prior Speciﬁcation
The estimation procedures described in Chaps. 3 and 4, namely the Kalman ﬁlter,
smoothing, forecasting and the algorithm of the SOP model, require us to specify
values of the elements of ˆβ0 and P0|0 in the prior state distribution
β0 ∼N( ˆβ0|0, P0|0),
(4.64)
as well as values of n0 and d0 in the prior distribution of θ = 1/σ 2
θ ∼G
n0
2 , d0
2
	
.
(4.65)
The success of the above mentioned estimation algorithms depend in some degree
on the choice of the above quantities. Their choice is known as prior speciﬁcation.
The problem of prior speciﬁcation is also known as initialisation, a detailed account
of which can be found in Durbin and Koopman (2012, Chapter 5). The main idea
is that the initial state β0 is composed of some stochastic components with known
joint distribution and by some other elements that may be deterministic and not
of interest. Then the Kalman ﬁlter and smoothing ﬁlters, presented in the previous
chapter, can be re-formulated as functions of the above structure of the initial state
β0; for more details the reader is referred to Koopman (1997) and Durbin and
Koopman (2012, Chapter 5). In our experience the inﬂuence of the priors above
is small, in particular when there is a “reasonable” amount of data available. As

4.5
Prior Speciﬁcation
181
we have shown in Theorem 3.7 (Sect. 3.5.3) for a wide class of models, for which
the design vector xt = x and the transition matrix Ft = F are time-invariant, the
posterior covariance matrix Pt|t convergesvery rapidly (as t →∞) and the resulting
limiting matrix is independent of the prior covariance matrix of β0. In the sequel we
describe practical speciﬁcations for β0 and σ 2, and we illustrate their sensitivity.
4.5.1
Prior Speciﬁcation of β0
We begin with the speciﬁcation of ˆβ0|0 and P0|0. ˆβ0|0 reﬂects the prior “beliefs”
we may have on β0, P0|0 on the associated uncertainty around this belief. For
example, in the local level model of Sect. 3.1.3, βt represents the (conditional)
level of the time series yt, i.e. βt = E(yt | βt), and so β0 represents the level of
data prior to t = 1, should this have been observed. Thus, it is reasonable to set
ˆβ0|0 what we would expect the level of such “prior data” would be. This may be
done using historical data, or simply ˆβ0|0 may represent our rough belief. In this
case P0|0 is a variance and setting P0|0 close to 0 a strong statement about ˆβ0|0 is
made, i.e. the uncertainty of β0 around its mean ˆβ0|0 is small. This is sometimes
expressed by deﬁning the precision of β0 as the inverse of P0|0; a large precision
P −1
0|0 implies small uncertainty around ˆβ0|0. On the other hand, if we are not certain
(if for example our prior beliefs are based on little prior knowledge or information),
then P0|0 should be large (or equivalently the precision P −1
0|0 should be small). This
is illustrated in Fig. 4.15, where the density functions of three normal distributions
are plotted β0 ∼N(0, 0.025), β0 ∼N(0, 1) and β0 ∼N(0, 4). We notice that as
-4
-2
0
2
4
0.0
0.2
0.4
0.6
0.8
Prior normal distribution
0
Probability density function
N(0,0.25)
N(0,1)
N(0,4)
Fig. 4.15 Prior distribution of β0

182
4
Model Speciﬁcation and Model Performance
the variance gets smaller the density concentrates around the zero mean, but as the
variance gets larger the uncertainty around the zero mean belief is increasing. In
most examples considered in so far we have set the variance equal to 1000, to reﬂect
a vague prior variance speciﬁcation with increased uncertainty around ˆβ0|0 (it will
be rare that we have precise prior information).
Moving on to other state space models, a similar approach is followed, i.e. ˆβ0|0 is
a prior belief of what β0 is expected or postulated to be (perhaps by using historical
or past data) and P0|0 is set to be proportional to the identity, a popular choice
being P0|0 = 1000I. This implies that the diagonal elements of P0|0, which are the
prior variances of βi,0 (β0 = [β1,0, . . . , βp,0]⊤), are very large (reﬂecting on high
uncertainty on the speciﬁcation of ˆβi,0), while the off-diagonal elements of P0|0 are
zero (reﬂecting a lack of information on the correlation of βi,0 and βj,0, for i ̸= j).
For example, in Example 4.2 of aluminium prices in Sect. 4.1.1, we used
β0|0 =

1800
1

and
P0|0 =

1000
0
0
1000

.
In this case, the level is β1t = E(yt | βt), which a priori (at t = 0) is expected
to be around $1800, while β2,0, which takes part in the evolution of the trend, see
e.g. Eq. (4.1c) of the linear growth model, is set to 1. The uncertainty around this
prior belief is set as high, by specifying that the variances of β1t and β2t are equal to
1000, while their covariance is zero (this is supported in the absence of information
that would suggest β1,0 and β2,0 to be correlated). The value of 1000 is customary;
any large number would sufﬁce, such that P−1
0|0 ≈0 (precision matrix is near zero).
This approach of prior speciﬁcation for ˆβ0|0 and P0|0 is known as weakly
informative prior speciﬁcation, as there is little information we feed in to the system,
basically coming from ˆβ0|0. However, sometimes even this information may not
be available. For example the practitioner may not have historical data or may be
reluctant to specify such a prior. In this case, just setting ˆβ0|0 = 0 will work well.
The explanation is as follows. Suppose that the “true” value of ˆβ0|0 = c ̸= 0 is
different from the zero vector and that we miss-specify it by “wrongly” setting
ˆβ0|0 = 0. At t = 1, after y1 is observed, the “correct” posterior mean ˆβ1|1 is
ˆβ1|1 = F1c + K1e1. Now, x⊤
1 F1c must be close to y1 (since c is the true prior
mean) and so e1 = y1 −x⊤
1 F1c ≈0. Thus, ˆβ1|1 = F1c, and the Kalman gain
Kt here does not play a crucial role as e1 ≈0. Now, if we set ˆβ0|0 = 0, we have
ˆβ1|1 = K1e1 = K1y1, since c = 0 here. Thus, in this case our posterior mean is a
linear function of y1, and it will adapt to y1 using the Kalman gain K1. Projecting
this to a few more observations, it follows that the posterior mean using the “wrong”
prior mean will converge to that using the “correct” prior mean. In other words, the
posterior mean ˆβt|t will quickly adapt to observed data and its dependence upon the
prior will quickly diminish.
This effect is illustrated in Fig. 4.16, which plots the one-step forecast mean
ˆyt|t−1 of the data yt (solid points), using the prior mean ˆβ0|0 = [1800, 1]⊤(solid line

4.5
Prior Speciﬁcation
183
Effect of prior mean in forecasting aluminium prices
Trading day (January 2005)
US dollars per tonne
5
10
15
20
1800
1820
1840
1860
Fig. 4.16 Effect of the prior mean ˆβ0|0 in the forecasting of the aluminium prices
and stars) and the zero prior mean ˆβ0|0 = [0, 0]⊤(dashed line and ticks). We observe
that initially the forecasts (using the zero prior) are very far from the respective
forecasts using the “more informative prior” ˆβ0|0 = [1800, 1]⊤. But, after only
a few points, the two forecasts converge to each other (after time t = 8 the two
forecasts are nearly inseparable). This is more clearly seen in the following table,
which tabulates the forecasts of each prior together with the original data (Table 4.2).
Moving on to the speciﬁcation of the prior covariance matrix P0|0, Fig. 4.17
shows the one-step forecast variance qt|t−1 produced using P0|0 = 1000I (solid
line and points), P0|0 = I (dashed line and ticks) and P0|0 = 0.001I (dotted
line and stars). This is a numerical justiﬁcation of the convergence of Pt|t and
its independence of P0|0 established in Theorem 3.7. We observe that the three
variances converge very quickly: after t
= 8, the three lines coincide. The
conclusion is that in this example, convergence is remarkably fast, and effectively
time points 1–9 could be considered as a training mode for the model to adapt. If
this is considered so, the prior mean vector ˆβ0|0 and the prior covariance matrix
P0|0 are not critical for the performance of the model. However, we note that the
above convergence, which is a phenomenon that applies in all state space models
with time-invariant components xt = x, Ft = F, Zt = Z and σ 2 (see Theorem 3.7),
will not apply generally, i.e. when these components are time-varying, as in the
regression models of Sect. 4.1.5. In such situations, the priors ˆβ0|0 and P0|0 will still
adapt quickly to the data but the forecast variance or the posterior covariance matrix
will not converge to stable values.
The study of the convergence of the posterior covariance matrix Pt|t, which is
considered in Exercise 3.7 (Chap. 3) for the local level model, has been the topic of
much of theoretical research in the past decades. The topic is interesting, because

184
4
Model Speciﬁcation and Model Performance
Table 4.2 Observed aluminium prices (left column), one-step forecast mean using the relatively
“informative” prior (middle column) and one-step forecast mean using the zero prior (right
column)
t
yt
ˆyt|t−1 with ˆβ0|0 = [1800, 1]⊤
ˆyt|t−1 with ˆβ0|0 = [0, 0]⊤
1
1835.000
1801.000
0.000
2
1810.000
1852.890
2746.569
3
1809.000
1786.135
1810.328
4
1829.000
1796.361
1806.862
5
1819.000
1828.788
1834.682
6
1827.000
1817.344
1820.929
7
1836.000
1827.619
1829.864
8
1844.500
1839.489
1840.912
9
1832.000
1849.834
1850.741
10
1829.500
1832.674
1833.252
11
1824.500
1828.326
1828.695
12
1848.000
1822.097
1822.333
13
1837.000
1852.533
1852.684
14
1847.000
1838.662
1838.759
15
1859.000
1850.114
1850.176
16
1811.000
1865.019
1865.059
17
1835.000
1802.608
1802.633
18
1827.000
1832.593
1832.609
19
1863.000
1824.818
1824.828
20
1866.000
1871.042
1871.048
it implies that for a very general class of state space models, posterior and forecast
variances will converge to stable forms. Thus in the Kalman ﬁlter recursion of ˆβt|t,
Pt|t can be replaced by its limit P, leading to what is known the steady state. What
is important in prior speciﬁcation is that this limit does not depend on the priors
ˆβ0|0 and P0|0 (see also Exercise 3.7). More details on the steady state of state space
models can be found in Jazwinski (1970, Chapter 7), Anderson and Moore (1979,
p. 77), Whittle (1984, p. 113), Chan et al. (1984) and in Harvey (1989, p. 119).
Triantafyllopoulos (2007a) proves the convergence of Pt|t when Zt is time-varying
and is speciﬁed using multiple forgetting factors (see Sect. 4.3.2).
4.5.2
Prior Speciﬁcation of σ 2
In this section suppose that σ 2 (the observation variance) is unknown and subject
to the conjugate Bayesian estimation of Sect. 4.3.3. We discuss the speciﬁcation of
the prior degrees of freedom n0 and the prior d0 in (4.65). Starting with the degrees
of freedom, it is desirable to set n0 ≈0, because for a transition matrix Ft = I
the estimator St = dt/nt (see also Eq. (4.61)) is the maximum likelihood estimator

4.5
Prior Speciﬁcation
185
Effect of prior variance to the forecast variance
Trading day (January 2005)
Forecast variance
5
10
15
20
10
15
20
25
P0|0=1000I
P0|0=I
P0|0=0.001I
Fig. 4.17 Effect of the prior covariance matrix P0|0 in the one-step forecast variance of the
aluminium prices
of σ 2 (for more details on this see the relevant discussion on p. 171). Obviously,
for the prior gamma distribution (4.65) of θ = 1/σ 2 to be deﬁned one must have
n0 > 0. In any case the degrees of freedom n0 are not crucial for the performance
of the estimator St, as nt = nt−1 + 1 = n0 + t (see Sect. 4.3.3) and nt converges
to inﬁnity as t →∞(not depending on n0). However, for early time points it is
recommended to use the setting n0 ≈0 and indeed this is followed in Sect. 4.3.3 by
setting n0 = 1/1000.
Once n0 has been set, the speciﬁcation of d0 commences by noticing that d0 =
n0S0. Thus, by setting a prior for S0, this implies a prior value of d0. However, it
may be difﬁcult to estimate σ 2 prior to observing the data. As before, it turns out
that the choice of S0 is not important, as the estimator St of σ 2 converges to a stable
value as t →∞independently of the choice of S0. Next we prove this argument.
From Eq. (4.58) in Sect. 4.3.3, the posterior distribution of 1/σ 2 is the gamma
distribution G(nt/2, dt/2). Thus the posterior distribution of σ 2 is an inverted
gamma distribution, i.e. σ 2 | y1:t ∼IG(nt/2, dt/2), from which we have that
the posterior variance of σ 2 is
Var(σ 2 | y1:t) =
2d2
t
(nt −1)2(nt −2) =
2(n0 + t)2S2
t
(n0 + t −1)2(n0 + t −2),
(4.66)
for nt > 2, where it is used dt = νtSt and nt = n0 + t. With the proposed prior
degrees of freedom n0 = 1/1000, the above variance is ﬁnite for t ≥2, while for
t = 1 it is inﬁnite.

186
4
Model Speciﬁcation and Model Performance
We can establish that as t →∞, the variance Var(σ 2 | y1:t) tends to zero.
To arrive to this result, notice that the ﬁrst part of the numerator in (4.66) is a
polynomial in t of order 2, while the denominator is a polynomial of order 3 and the
sequence {St} is bounded. To see this, we prove that if St−1 is bounded, then St is
bounded too (the boundedness of {St} follows by indication since S0 is bounded).
First observe that with the deﬁnitions of rt and et (see p. 170), we have
rtet = (1 −x⊤
t Kt)e2
t =

1 −x⊤
t Pt|t−1xt
qt|t−1
	
e2
t = St−1e2
t
qt|t−1
,
which is bounded, since e2
t , qt|t−1 are bounded and by our hypothesis St−1 is
bounded too. Then, re-writing recursion (4.61) as
St =

1 −
1
n0 + t
	
St−1 +
rtet
n0 + t ,
we have that St is bounded, because it is a sum of two bounded sequences.
Therefore, Var(σ 2 | y1:t) tends to zero as t →∞and this means that as t increases,
the density function of σ 2 | y1:t concentrates about its mode (4.62) asymptotically
degenerating.
4.6
Automatic Sequential Monitoring
4.6.1
Model Monitoring
So far we have described error analysis and hyperparameter estimation or speciﬁ-
cation, for a single state space model (see Sects. 4.3 and 4.4). In other words, given
observed data y1:n = {y1, . . . , yn}, for some n, we may propose a state space model
and assess the goodness of ﬁt as described in Sect. 4.4. However, in many real-life
situations a chosen state space model is subject to continuous assessment, i.e. at each
time t a decision needs to be made on whether the current model, denoted by M0,
is adequate against an alternative model, denoted by MA. There may be reasons to
doubt M0 in favour of MA, for example in the presence of outliers, or systemic
deterioration of the model performance of M0 as compared to MA. Therefore a
quantitative toolkit is required to compare the two models at each time t and to
propose, if required, possible modes of corrective action. The model comparison
part of such an analysis is known as model monitoring and the corrective action
is known as intervention analysis. This relates to diagnostics and outlier detection,
topics which have received some considerable attention in the literature, see e.g.
Harvey and Koopman (1992), McCulloch and Tsay (1993), Shephard (1994b),
Chib and Tiwari (1994) and Atkinson et al. (1997). Below we describe monitoring
based on Bayes factors, introduced by West (1986) and subsequently developed

4.6
Automatic Sequential Monitoring
187
in West and Harrison (1986), West and Harrison (1997, Chapter 11) , Salvador and
Gargallo (2003) and Salvador and Gargallo (2004); an alternative approach to model
diagnostics and intervention analysis is given in De Jong and Penzer (1998). A
similar development as that we follow is presented in the master’s thesis of Molinari
(2009). In the context of statistical quality control Bersimis et al. (2007) discuss
process monitoring using control charts.
We start by discussing the monitoring procedure in general terms, assuming
that the current model M0 is the state space model (3.10a)–(3.10b), where the
components xt, Ft, σ 2 and Zt together with the priors ˆβ0|0 and P0|0 have been
estimated, speciﬁed or selected, as discussed in the sections above. It is also
assumed that the alternative model MA is in the form of the state space model
(3.10a)–(3.10b), with model components speciﬁed. Thus, there is no uncertainty on
the parameters within each of the two models; there is, however, between-model
uncertainty. At each time t, a decision of the most adequate between two models
is required. This task is typically utilising the cumulative Bayes factor, which is
deﬁned as the ratio of the joint forecast distribution of the two models. In short, the
model that produces largest forecast distribution for a given collection of data up to
time t is thought to perform better with respect to its forecast ability.
More formally, deﬁne Bt(k) the cumulative Bayes factor as
Bt(k) = p(yt, yt−1, . . . , yt−k+1 | y1:t−k, M0)
p(yt, yt−1, . . . , yt−k+1 | y1:t−k, MA),
for k = 1, 2, . . ., t.
The value of k indicates how many past observations are included in the joint
distributions above. For k
= 1 only the forecast distribution of the current
observation yt is used, while for k = t, the forecast distribution of the entire past
y1, y2, . . . , yt is used. For k = 1, Bt(1) is just reduced to the ratio of the one-step
forecast distributions of yt, i.e.
Bt(1) = p(yt | y1:t−1, M0)
p(yt | y1:t−1, MA),
which sometimes is referred to as the Bayes factor of M0 against MA. Here we
make the convention that y1:0 does not include any past observations, so that Bt(k)
is deﬁned for k = 1 and k = t. Note for example that under M0, y1 | y1:0 ≡y1 ∼
N( ˆy1|0, q1|0), where ˆy1|0 and q1|0 are the one-step forecast mean and variance of y1,
computed using only the prior mean vector and covariance matrix ˆβ0|0 and P0|0 of
β0 (provided by the Kalman ﬁlter).
Bayes factor Bt(1) enables us to compare the one-step forecast distribution of
M0 and MA evaluated at the observed value of yt. When Bt(1) > 1, then M0 is
thought to have a better forecast performance at time t, as its forecast density at the
observed value yt is larger than that of MA. This, will be discussed in some detail
later, but ﬁrst we give a simple example to illustrate this point.

188
4
Model Speciﬁcation and Model Performance
Example 4.10 Consider two state space models M0 and MA that have produced
the respective forecast distributions at time t:
yt | y1:t−1, M0 ∼N(10, 9)
and
yt | y1:t−1, MA ∼N(10 + λ, 9),
where λ > 0 measures positive deviations from the mean 10 of the forecast
distribution of M0. In fact the two forecast distributions differ only via the value
of λ. It is of interest to examine for which values of λ, M0 is preferred to M0 in
terms of forecast performance.
The Bayes factor of M0 against MA is
Bt(1) = p(yt | y1:t−1, M0)
p(yt | y1:t−1, MA)
=
(2π)−1/23−1 exp[−18−1(yt −10)2]
(2π)−1/23−1 exp[−18−1(yt −10 −λ)2]
= exp[−18−1{2λ(yt −10) −λ2}].
Thus, λ, M0 is preferred at time t, if Bt(1) = exp[−18−1{2λ(yt −10) −λ2}] > 1
or by taking logarithms, if −18−1{2λ(yt −10) −λ2} > 0, which implies λ >
2(yt −10). For example, if λ = 2 and yt was observed to be yt = 10.5, then
λ = 2 > 2 × (10.5 −10), hence model λ, M0 is thought to be a better model
than λ, MA, as it produces a larger forecast distribution evaluated at the observation
yt = 10.5.
Returning at the cumulative Bayes factor, Bt(k) may be computed by using the
following recursion:
Bt(k) = Bt(1)Bt−1(k −1),
(4.67)
for k = 2, 3, . . . , t.
Indeed, from the deﬁnition of Bt(k) we obtain
Bt(1)Bt−1(k −1) = p(yt | y1:t−1, M0)p(yt−1, . . . , yt−k+1 | y1:t−k, M0)
p(yt | y1:t−1, MA)p(yt−1, . . . , yt−k+1 | y1:t−k, MA)
= p(yt, yt−1, . . . , yt−k+1 | y1:t−k, M0)
p(yt, yt−1, . . . , yt−k+1 | y1:t−k, MA)
= Bt(k).
Iterating recursion (4.67) we obtain
Bt(k) = Bt(1)Bt−1(1)Bt−2(k −2) · · · Bt−k+1(1) =
t-
i=t−k+1
Bi(1),

4.6
Automatic Sequential Monitoring
189
for k = 1, 2, . . . , t. We can see that Bt(k) is the product of k Bayes factors Bi(1),
hence the name cumulative Bayes factor.
If, for some time t, Bt(1) < 1, we have some evidence of yt being an outlier
(as the forecast distribution evaluated at yt under M0 is smaller compared to the
respective distribution under M0). If, on the other hand, Bt(1) > 1, this would imply
that yt is not an outlier, while Bt(1) = 1 would give no evidence for or against yt
being an outlying observation. As we will see later, monitoring is not only concerned
with the detection of outliers; a model may well deteriorate because of systemic poor
performance. If Bt(t) > 1, this does not mean that model M0 is acceptable. To see
this, suppose that t = 10 and Bi(1) = 2, for i = 1, 2, 3, 4, 5, 6, while Bi(1) = 1/2,
for i = 7, 8, 9, 10. Then the cumulative Bayesian factor is B10(10) = 260.54 = 4 >
1, but clearly for i = 7, 8, 9, 10 the model is not acceptable with Bi(1) < 1.
In order to detect the most likely point of change, we need to identify the most
recent group of incompatible consecutive observations by minimising Bt(k), with
respect to k. The next theorem, due to West (1986), settles this minimisation.
Theorem 4.3 Let Lt = min
1≤k≤t Bt(k), with L1 = B1(1). Then Lt can be computed
by the recursion
Lt = Bt(1) min{1, Lt−1},
for t ≥2.
The minimum at time t is taken at k = kt, with Lt = Bt(kt), where the positive
integers kt are updated by
kt =
( 1 + kt−1, if Lt−1 < 1
1,
if Lt−1 ≥1 ,
t ≥2,
with k1 = 1.
Proof From the deﬁnition of Lt and from Eq. (4.67), we have
Lt = min
(
Bt(1), min
2≤k≤t Bt(k)
)
= min
(
Bt(1), min
2≤k≤t[Bt(1)Bt−1(k −1)]
)
= Bt(1) min
(
1, min
2≤k≤t Bt−1(k −1)
)
= Bt(1) min
(
1,
min
1≤j≤t−1Bt−1(j)
)
= Bt(1) min{1, Lt−1}.
To establish the recursion for kt, we examine separately the cases Lt ≥1 and Lt <
1. If Lt−1 ≥1, then min{1, Lt−1} = 1 and so Lt = Bt(1), with kt = 1. If Lt−1 <

190
4
Model Speciﬁcation and Model Performance
1, then min{1, Lt−1} = Lt−1, hence Lt = Bt(1)Lt−1. From (4.67) this implies
Bt(kt) = Bt(1)Bt−1(kt−1) = Bt(1 + kt−1), from which the recursion kt = 1 + kt−1
follows.
⊓⊔
Theorem 4.3 provides key results. The sequence {Lt} is used to perform continual
monitoring of model M0.
•
If at some t > 0, Lt−1 < 1, there is possible evidence for deterioration in M0,
which started kt−1 steps backwards in time.
•
If at some t > 0, Lt−1 ≥1, then evidence exists in favour of M0 and any
possible evidence against M0 should be based on Lt = Bt(1), if such value is
small. Then one needs to look at Lt:
If τ ≤Lt < 1,
M0
is accepted;
If Lt < τ,
M0
is rejected.
Usually the threshold τ is set around 0.1 or 0.2. If Lt < τ, we need to further
consider the value of kt, in particular:
– If kt = 1, then a single observation yt has activated the monitoring signal.
If yt is thought to be an outlier, then no further action should be considered;
perhaps one may remove this observation in calculating ﬁltered estimates and
forecasts, for t + 1, t + 2, . . ..
– If kt > 1, this is evidence suggesting deterioration of M0, which started kt
steps backward in time.
This procedure can be applied for any time t, providing an assessment of M0 against
the alternative MA.
4.6.2
Speciﬁcation of Alternative Models
We turn our attention to the speciﬁcation of the alternative model. In the application
of the monitoring procedure described above, the models M0 and MA need to be
speciﬁed. M0 is the current model and is determined according to the analysis
described in Sects. 4.1–4.5. Once the current model is ﬁtted, the standardised
residuals e∗
t are formed and if the model is good, this should follow the standard
Gaussian distribution N(0, 1) (or the standard Student t distribution, if the observa-
tion variance σ 2 is estimated by the data); in Sect. 4.4 there is a detailed discussion
of the standardised residuals. The alternative model MA measures deviations from
M0 and its purpose is to quantify how far from N(0, 1) the standardised residuals
may be. Thus, it is natural to consider
MA :
e∗
t | y1:t−1 ∼N(μ, δ2),

4.6
Automatic Sequential Monitoring
191
where μ is a mean-shift (measuring deviations from the zero mean of M0) and δ2 a
variance-shift (measuring deviations from the unit variance of M0).
Based on this speciﬁcation, the Bayes factor Bt(1) of M0 against MA is
Bt(1) = p(e∗
t | y1:t−1, M0)
p(e∗t | y1:t−1, M0)
=
(2π)−1/2 exp(−2−1e∗2
t )
(2πδ2)−1/2 exp[−(2δ2)−1(y∗t −μ)2]
= δ exp

(e∗
t −μ)2 −δ2e∗2
t
2δ2

.
Given the observed value of yt, we have the observed standardised residual e∗
t , hence
for the evaluation of Bt(1), we need to know the values of μ and δ. Obviously, if
μ and δ are too close to 0 and 1, respectively, then the two models M0 and M0
may be indistinguishable. We note that in general, small values of e∗
t in modulus are
expected to result in validating model M0, while large (in modulus) values of e∗
t are
associated with rejecting M0 in favour of MA. As a result, we can set up μ and δ
in such a way that they be consistent with the smallest values that would suggest
rejection of M0.
For example, suppose that e∗
t = 1.65 is observed to be the 95% quantile of the
N(0,1) distribution, so as the probability that |e∗
t | ≤1.65 is equal to 0.90. The
value 1.65 for the standardised residual is considered to be small enough, so that
the values of μ and δ of the Gaussian distribution N(μ, δ2) of the alternative model
MA should be chosen so that the Bayes factor is close to 1 (i.e. since |e∗
t = 1.65
is considered to be small enough both models M0 and MA should have similar
forecast performance, hence Bt(1) ≈1). Likewise, ﬁxing μ and δ as above, if
we consider e∗
t = 2.33, the 99% quantile of the N(0, 1) distribution, as being an
extreme value for N(0, 1) (or an unlikely value under model M0), then we can
suggest the value of the threshold τ = Bt(1), so that any value of the Bayes factor
below τ would classify yt (which is used to compute e∗
t ) as a potential outlier.
Table 4.3 shows values of the Bayes factor Bt(1) ≡Bt(1)[μ, δ], for ﬁve possible
alternative models M(j)
A , for j = 1, 2, 3, 4, 5. Each of these models assumes a
Gaussian distribution N(μ, δ2), for some values of μ and δ. The proportions in the
brackets indicate the % quantile of the N(0, 1) distribution, i.e. 1.65 is the 95.1%
quantile of N(0, 1) (rounded in two decimal places). Model 1 considers a variance
2.58 while the mean is equal to 0 and so in comparison with the N(0, 1) of the
current model M0, it assesses departures from the variance.
Models 2 and 3 assess positive departures from the mean of M0 and Models 4
and 5 assess negative departures from the mean of M0. From Table 4.3, we see that
for e∗
t = 1.65, all models return a Bayes factor close to 1 (Model 1 slightly less
than 1, Models 2 and 4 exactly equal to 1 and Models 3 and 5 over 1); the values of
μ and δ for each model are chosen to be consistent with those Bayes factor and to
yield an acceptable forecast performance of model M0. Looking over the rows of

192
4
Model Speciﬁcation and Model Performance
Table 4.3 Bayes factors Bt(1) = Bt(1)[μ, δ] of the current model M0 against ﬁve alternative
models M(j)
A , for j = 1, 2, 3, 4, 5
Bt(1)[μ, δ]
Model
e∗
t = 1.65
e∗
t = 2.33
e∗
t = 2.40
e∗
t = 2.58
M(j)
A
μ
δ
(95.1%)
(99%)
(99.2%)
(99.5%)
1
0
2.58
0.81
0.26
0.22
0.15
2
3.61
1
1.75
0.15
0.12
0.06
3
3.70
1.46
1.00
0.15
0.12
0.07
Bt(1)[μ, δ]
Model
e∗
t = −1.65
e∗
t = −2.33
e∗
t = −2.40
e∗
t = −2.58
M(j)
A
μ
δ
(5%)
(1%)
(0.8%)
(0.5%)
4
−3.61
1
1.75
0.15
0.12
0.06
5
−3.70
1.46
1.00
0.15
0.12
0.07
the table, we observe that the Bayes factor lowers as e∗
t gets large, indicating lack
of support for M0. These values of the Bayes factor are used to deﬁne the threshold
τ for the outlier detection step when Bt(1) < τ. In the following we use τ = 0.12
and so with the alternative models 2–4, any value yt with |e∗
t | > 2.4 would be
classiﬁed as an outlier. However, we note that the signal detection rule is not just a
mere consideration of extreme standardised residuals e∗
t ; for example under model
1, an observation yt with respective e∗
t = 2.58 has a Bayes factor equal to 0.15 and
thus yt is not classiﬁed as an outlier (as 0.15 > 0.12), but considering models 2 and
3 yt is classiﬁed as an outlier, as the respective Bayes factor is equal to 0.07 (lower
than 0.12).
After the alternative models M(j)
A are set up as above and the threshold τ = 0.12
is been ﬁxed, we need to consider the signal rules. As mentioned in the previous
section, the monitor signals when Lt < τ (if kt = 1 this is due to yt as a potential
outlier and is equivalent to Bt(1) < τ; while if kt > 1, then deterioration of model
M0 started kt steps backward in time). In addition to those two signals, we consider
two more signalling rules: (a) when there are too many successive outliers (two such
outliers are considered as the threshold to warrant lack of support for M0) and (b)
when τ ≤Lt < 1 without being lower than the threshold τ, but the corresponding
value of kt is too large (here this is set to kt = 4). The rationale of (a) is that
an occasional outlier (responsible for triggering Bt(1) < τ) may not warrant a
problem with, but two or more successive outliers are likely to be the result of a
poor forecast performance of M0. The rationale of (b) is that even if τ ≤Lt < 1,
the relatively large value of kt suggests a tendency for deterioration, which may
later develop further to a more clear signal (e.g. an outlier); given τ ≤Lt < 1, a
threshold of kt = 4 is applied in what follows, i.e. four observations backward in
time drive a relatively low value of Lt. Table 4.4 summarises the signal rules that
may be triggered by any of the alternative models M(j)
A , j = 1.2.3.4.5, described
earlier.

4.6
Automatic Sequential Monitoring
193
Table 4.4 Signal rules of the monitoring procedure
Signal
Meaning
Condition
1
Potential outlier
Bt(1) ≤τ or Lt < τ and kt = 1
2
Tendency of deterioration
τ ≤Lt < 1 and kt ≥4
3
Model deterioration
Lt < τ and kt ≥2
4
At least two consecutive outliers
Bt−1(1) < τ and Bt(1) < τ
According to Table 4.4 more than one signals may be issued at a particular
time. For example, if Signal 4 is issued, then clearly Signal 1 is issued too.
Considering this and the ﬁve alternative models, at any time t, we might have several
simultaneous signals from the monitor. The intervention policy of the next section,
will be determined by the maximum number of recent observations giving rise to
a signalling event, throughout all the alternative models considered. To summarise
the monitoring procedure, we have the current model M0, a state space model,
with sequential ﬁtting, produces the standardised residuals e∗
t . Setting up the ﬁve
alternative models as in Table 4.3 and considering the signalling rules of Table 4.4,
at each time t, either we assess model M0 as acceptable, or we issue a signal. In
the latter case corrective action may be required, or we may decide to take no action
(e.g. in Signal 1 of 4.4). If corrective action is decided, this is known as intervention
analysis, and is discussed in the next section. We close this section with an example
illustrating the above monitoring procedure.
4.6.3
Monitoring for the Tobacco total sales data—CP6
We illustrate the monitoring procedure described above, by considering a real data
set, consisting of monthly total sales (in some standard scale) of UK tobacco and
related products in the period 1955 to 1959. The data, described in more detail
in West and Harrison (1997, Chapter 11), are depicted in Fig. 4.18. We observe
that the data follow an upward linear growth trend, but there are some potential
outliers together with several structural changes. For example, the 12th observation,
corresponding to December of 1955, is a clear outlying observation. There seem to
be two main structural changes. The ﬁrst is on January 1957 (25th observation), as
we can see that the observations following this observation have a much increased
level from the observations up to December 1956. Likewise, the observations
following January 1958 exhibit a level change compared to those observations up
to December 1957. These three points of time (December 1955, January 1957 and
January 1958) are depicted in Fig. 4.18 by the circles.
Therefore, it is expected that a linear growth model without a monitoring scheme
will not perform well over those structural changes and outliers. The linear growth
state space model was formally discussed in Sect. 4.1.1; according to this if yt is
the value of the CP6 time series at time t, then the model is given by Eqs. (4.1a)–

194
4
Model Speciﬁcation and Model Performance
CP6 total sales
Month
1955
1956
1957
1958
1959
1960
700
800
900
1000
Fig. 4.18 Tobacco CP6 sales data. The circles indicate possible outliers
(4.1c). We have set up the model as the scaled observation precision (SOP) model,
so as to be able to estimate the observation variance σ 2, according to the Bayesian
estimation described in Sect. 4.3.3 and the covariance matrix Zt speciﬁed using the
discount factor δ = 0.8 (see Sect. 4.3.2 for the full speciﬁcation of this covariance
matrix using discount factors). Finally, we use vague or weakly informative priors
for the mean vector and the covariance matrix of the initial state vector β0, i.e.
ˆβ0|0 = [0, 0]⊤, P0|0 = 1000I, S0 = 1, n0 = 1, where, following standard notation,
ˆβ|0 = E(β0), P0|0 = Var(β0), n0 are the prior degrees of freedom and S0 is the prior
estimate of σ 2. For more details on the prior speciﬁcation the reader is referred to
Sect. 4.5.
Figure 4.19 plots one-step forecast means (dashed line) with 95% predictive
intervals together with the observed data. We see that in the start of the time series
the model seems to forecast well the data (the predictive intervals are very tight
and most of the observations lie inside them). But at time point t = 12 there
seems to be an outlier (this is indicated in Fig. 4.18 by a circle), after which the
model deteriorates as we see that the forecast mean is consistently higher than

4.6
Automatic Sequential Monitoring
195
One-step forecasting for the CP6 data
Month
1955
1956
1957
1958
1959
1960
400
500
600
700
800
900
1000
1100
Observations
Forecast mean
95% prediction interval
4
12
25
Fig. 4.19 One-step forecast mean with corresponding 95% predictive intervals, for the tobacco
CP6 data
the observations and the forecast intervals are a lot wider, which suggests that the
forecast variance has considerably increased.
We apply the monitoring procedure of the above section in order to detect which
observations cause the poor forecast performance. We use the ﬁve alternative models
of Table 4.3 and the four signals of Table 4.4. The analysis below is performed in R
by ﬁrst obtaining the standardised residuals using the SOP model
# Fit data using the SOP model
> fit <- bts.filter(y, x0=c(1,0), F0=matrix(c(1,0,1,1),2,2),
+ delta=0.8, beta0=c(500,0),
P0=1000*diag(2))
# standardised residuals
> f <- as.numeric(fit$FittedMean)
> Q <- as.numeric(fit$FittedVar)
> res.std <- (y-f) / sqrt(Q)

196
4
Model Speciﬁcation and Model Performance
For the monitoring part we use the function monitor, which returns the values of
Lt, kt and the signals, for Models 1–5 (see Table 4.3).
# Monitoring using alternative Model 1
> mod1 <- monitor(res.std, 0, 2.58)
# Monitoring using alternative Model 2
> mod2 <- monitor(res.std, 3.61, 1)
# Monitoring using alternative Model 3
> mod3 <- monitor(res.std, 3.70, 1.46)
# Monitoring using alternative Model 4
> mod4 <- monitor(res.std, -3.61, 1)
# Monitoring using alternative Model 5
> mod5 <- monitor(res.std, -3.70, 1.46)
The summary of the signals are presented in Table 4.5. Some comments are in
order. First of all we notice that no model issues Signal 4 (at least two consecutive
outliers). This is expected, as it appears that the model adjusts reasonably to the data
after an outlier. Signal 2 and 3 are relevant (2 signals tendency for deterioration and
3 model deterioration). Signal 3 is issued for a lot of times indicating that the model
seems to deteriorate for long periods; for such times signal 2 is not issued as much,
because it is suppressed by Signal 3. The model deterioration is not necessarily too
negative for this model, but it is suggestive that the model can be improved. Signal
1 is issued at points of time 4, 12 and 25. Indeed the most prominent outlier of the
data is at point of time 12, with a standardised residual e∗
12 = 12.176 (this is issued
by Models 2, 3 and 5). At point of time t = 25 is another outlier, which is picked
by Model 2 (the respective standardised residual is e∗
25 = 4.017). These two outliers
can be guessed from Fig. 4.19. The monitoring algorithm picks another outlier
at time t = 4 (Models 4 and 5 issue Signal 1, with corresponding standardised
residual equal to e∗
4 = −3.920). In Fig. 4.19 the time-points t = 4, 12, 25, which
correspond to outliers, are indicated on these observations. We remark that the third
circle of point t = 37 (January 1958) of Fig. 4.18 is not an outlier; we see from
Fig. 4.19 that this observation is marginally falling out of the predictive interval and
has standardised residual e∗
t = 2.322.
Table 4.5 Monitoring for the CP6 data set; shown are time-points, which Model j (see Table 4.3)
has issued a signal i, from the range of signals of Table 4.4
Signal
Model 1
Model 2
Model 3
Model 4
Model 5
1
−
12, 25
12
4
4, 12
2
−
−
28
−
22
3
4 −60
9, 13, 14, 26
9, 13 −27
5
13 −21
4
−
−
−
−
−

4.7
Exercises
197
4.7
Exercises
1. Find the state space form of the autoregressive moving average model of orders
2 and 1 ARMA(2,1):
yt −μ = φ1(yt−1 −μ) + φ2(yt−2 −μ) + εt + ψ1εt−1,
where μ is the mean of yt, φi are the autoregressive (AR) coefﬁcients, ψ1 is the
moving average (MA) coefﬁcient and εt is white noise with variance σ 2
ε . For
extensive coverage of this model the reader is referred to Brockwell and Davis
(1991) or Box et al. (2008).
2. Motivated from Exercise 4.1 ﬁnd a state space representation of the autoregres-
sive moving average model of orders m, q ARMA(m, q):
yt −μ = φ1(yt−1 −μ) + · · · + φm(yt−m −μ) + εt + ψ1εt−1 + · · · + ψqεt−q,
where μ is the mean of yt, φi are the autoregressive (AR) coefﬁcients, ψ1 is the
moving average (MA) coefﬁcient and εt is white noise with variance σ 2
ε . For
extensive coverage of this model the reader is referred to Brockwell and Davis
(1991) or Box et al. (2008). Thus, suggest a possible estimation procedure using
state space methods; explain how the parameters φi and ψj may be estimated.
3. A company sets up a time series model for the yield yt of an investment at time
t as
yt = ψtθt + αyt−1 + εt,
where θt = θt−1+ηt and εt = 0.9εt−1+νt. Here, ψt is a time-varying covariate,
θt and α are regression and autoregression coefﬁcients and the innovations ηt
and νt are assumed to be independent, each following a white noise process. It
is further assumed that ηt is independent of α, for all t.
a. Deﬁne the state vector
βt =
⎡
⎣
θt
α
εt
⎤
⎦
and use it to express yt in state space form, i.e.
yt = xtβt + ϵt
and
βt = Fβt−1 + ζt,
hence determine xt, F and deﬁne the innovations of the model ϵt and ζt.

198
4
Model Speciﬁcation and Model Performance
b. Suppose this model was ﬁtted to data y1, . . . , yn. With information y1:n =
{y1, . . . , yn}, suppose that the posterior distributions of θn and α were
θn | y1:n ∼N(1, 10)
and
α | y1:n ∼N(1, 2).
With information y1:n,
show that the one-step ahead forecast mean ˆyn+1|n of yn+1 is
ˆyn+1|n = yn + ψn+1;
and that the two-step ahead forecast mean ˆyn+2|n of yn+2 is
ˆyn+2|n = yn + ψn+2 −ψn+1.
4. Consider that a time series {yt} is generated from an ARIMA(1,1,1) model, so
that
yt −yt−1 = α(yt−1 −yt−2) + ϵt + γ ϵt−1,
where α is the AR parameter, γ is the MA parameter and {ϵt} is a Gaussian
white noise sequence with variance equal to 1.
Deﬁne the state vector
βt =
⎡
⎣
yt
yt−1
ϵt
⎤
⎦.
a. Write down a state space representation for yt, i.e. express yt as a state space
model:
yt = x⊤βt + δt,
βt = Fβt−1 + ζt.
and hence determine the components x, F, δt and ζt, and write down the
distributions of δt and ζt.
b. Suppose that at time t = 2, the posterior distribution of β2 is
β2 | y1:2 ∼N
⎧
⎨
⎩
⎡
⎣
0
1
0
⎤
⎦,
⎡
⎣
0 0 0
0 0 0
0 0 1
⎤
⎦
⎫
⎬
⎭,
where y1:2 = {y1 = 1, y2 = 0} denotes the information available at time
t = 2.

4.7
Exercises
199
c. If y3 = 1, perform a step of the Kalman ﬁlter and hence derive the posterior
distribution of
β3 | y1:3,
where y1:3 = {y1 = 1, y2 = 0, y3 = 1}.
Given information y1:3, ﬁnd the posterior distribution of ϵ3.
5. In the context of Sect. 4.2.4 show that the trend component model (Eq. (4.40))
χ(1)
t
= [1, 0]γ (1)
t
and
γ (1)
t
=

0 1
−1 2

γ (1)
t−1 + ξ1t
can be written as (see Eq. (4.41))
χ(1)
t
= [1, 0]γ (3)
t
and
γ (3)
t
=

1 1
0 1

γ (3)
t−1 + ξ3t,
for some innovations ξ3t, which are given as linear functions of the innovations
ξ11, . . . , ξ1t.
6. Consider the local level model
yt = βt + ϵt
and
βt = βt−1 + ζt,
with the usual assumptions of ϵt
and ζt. For observed data y1:t
=
{y1, . . . , yt}:
a. Using the Kalman ﬁlter (Theorem 3.2), show that the posterior distribution
of ϵt is ϵt | y1:t ∼N[(1 −Kt)et, Ktσ 2], where Kt is the Kalman gain and
σ 2 is the variance of ϵt.
b. A time series zt follows an integrated autoregressive moving average model
of orders m, 1, q (ARIMA(m, 1, q)), if the ﬁrst order difference zt −zt−1
follows the ARMA(m, q) of Exercise 4.2. For the time series yt of Exercise
4.3 prove
yt −yt−1 = et −(1 −Kt−1)et−1,
so that yt is an ARIMA(0,1,1) type model. Is it exactly an ARIMA(0,1,1)
and if not why? How can we justify the argument that yt basically is an
ARIMA(0,1,1)?

200
4
Model Speciﬁcation and Model Performance
c. Prove
ˆβt|t = Ktyt + (1 −Kt) ˆβt−1|t−1,
which is an EWMA (exponentially weighted moving average). Then, give
an interpretation of Kt.
7. Suppose that for a time series yt a time-varying polynomial regression model
is ﬁrst considered:
yt = β0t + β1t + β2tt2 + β3tt3 + ϵt,
where β0t, β1t, β2t, β3t are dynamic regression coefﬁcients and ϵt is a white
noise process with variance. If βit are evolving according to a random walk,
then write down yt in state space form and determine the components of the
model (i.e. xt, Ft, σ 2, Zt).
8. For some data yt with covariate xt, we consider a simple static regression model
yt = β0 + β1xt + εt,
(Model 1)
where εt is white noise with variance 1.
An alternative model is considered, with autocorrelated errors, i.e. εt is not
a white noise:
yt = β0 + β1xt + εt
and
εt = φεt−1 + νt,
(Model 2)
where φ is an autoregressive coefﬁcient (assumed to lie in the unit circle) and
νt is white noise with variance 2.
Based on some data y1:t = {y1, . . . , yt}, ﬁnd the form of the forecast function
ˆyt+k|t = E(yt+k | y1:t), for each model and prove that when φ ≈0 or when
k →∞the two models are equivalent. Thus, suggest in which case model 2 is
expected to perform better than model 1.
9. For the data of Exercise 3.7 (Chap. 3) carry out an error analysis and comment
on the quality of the model ﬁt.
10. The following table (source: Cooper and Harrison (1997)) shows the number
of ﬁve-year-old (yt) and four-year-old (xt) cattle that are conﬁrmed as having
bovine spongiform encephalopathy (BSE) at a speciﬁc quarter. It is postulated
that a simple regression model will help to forecast yt (numbers of ﬁve-year-old
cattle suffering from BSE) using xt (number of four-year-old conﬁrmed as BSE
at the same quarter). It will also be useful in identifying whether the relationship
has changed over the years.

4.7
Exercises
201
Qtr1
Qtr2
Qtr3
Qtr4
Year
yt
xt
yt
xt
yt
xt
yt
xt
1989
559
139
486
209
590
346
904
536
1990
1172
570
837
586
904
694
1185
831
1991
1338
1178
1090
1037
1532
1192
2394
1497
1992
2821
2027
2172
1861
2989
2543
4620
3634
1993
4831
4654
3907
4035
3618
3934
2809
2558
1994
2099
1992
1304
1338
1204
1342
1256
1220
1995
1075
1048
849
923
777
846
641
558
1996
484
472
310
430
252
417
–
439
1997
–
475
–
331
–
182
–
–
Fit an appropriate state space model up to the 4th Quarter of 1996 and
assess the evidence of time-varying regression coefﬁcients (or change of the
relationship over time). Provide the one-step ahead forecasts of yt, for the 4th
Quarter of 1996 and the ﬁrst three quarters of 1997. Can you forecast yt for the
4th Quarter of 1997?
11. The following table shows the turkey sales data described in Sect. 4.1.4; they
consist of number of sales (in thousands) of quarterly turkey chick sales from
autumn 1974 up to the summer of 1983.
Year
Qtr1
Qtr2
Qtr3
Qtr4
1974
131.7
1975
322.6
285.6
105.7
80.4
1976
285.1
347.8
68.9
203.3
1977
375.9
415.9
65.8
177.0
1978
438.3
463.2
136.0
192.2
1979
442.8
509.6
201.2
196.0
1980
478.6
688.6
259.8
352.5
1981
508.1
701.5
325.6
305.9
1982
422.2
771.0
329.3
384.0
1983
472.0
852.0
a. In the state space model that is proposed in p. 134, suppose that the
observation variance σ 2 and the transition covariance matrix Zt = Z are
unknown. Use the EM-algorithm to estimate σ 2 and Z and then plot the
one-step forecast mean of the data, together with the respective 95% forecast
bounds, using the estimated values of σ 2 and Z. Comment on the quality of
forecasting compared to that of the state space model used in p. 134.
b. Fit the scaled observational model (SOP) of Sect. 4.3.3, where the transition
covariance matrix Zt is speciﬁed with a discount factor δ. Experiment with
values of δ = 0.99, 0.8, 0.5, 0.1. Perform an error analysis and choose the

202
4
Model Speciﬁcation and Model Performance
optimal value of δ. Compare the estimated values of σ 2 and Zt with those in
(a) estimated by the EM-algorithm and comment.
12. The air passenger data consist of numbers of passengers (in thousands) carried
by international airlines each month, from January 1949 to December 1960.
The data are described in Sect. 4.1.4 and are plotted in Fig. 4.6. The data
can be found in R by uploading the library MASS and looking at the data set
AirPassengers; in the R console type
> library(MASS)
> data(AirPassengers)
> y <- AirPassengers
Find a suitable state space model and ﬁt it to the air passenger data. Perform an
error analysis and give an assessment of the ﬁt of the chosen model.
13. Quarterly earnings (US dollars) per Johnson and Johnson share in the period
1960–1980 are available in R by executing the following commands
> library(MASS)
> data(JohnsonJohnson)
> y <- JohnsonJohnson
The data are reported in Shumway and Stoffer (2017). Suggest a suitable state
space model and analyse this data using this model. Assess the goodness of ﬁt
and provide 95% forecast intervals for the quarters of 1981.
14. Yearly averages above 570ft of the levels of lake Huron in the period 1875–
1972 are available in R by executing the following commands
> library(MASS)
> data(LakeHuron)
> y <- LakeHuron
The question here is whether there is any regularity in the ﬂuctuations, and if
so how to describe it, and forecast levels. Fit an appropriate state space model
for this data set. Using both smoothed and ﬁltered estimates of the mean level,
assess the evidence that the mean level of the lake has changed over the years.
15. Twenty-four observations consisting of annual number of telephone calls made
(in millions of calls) in Belgium in the period 1950–1973 are available in R by
executing the following commands
> library(MASS)
> data(phones)
> y <- phones
The data set is in the object y$calls, while y$year includes the years.
Suggest a state space model for this data set. Provide a plot with the one-
step forecasts against the actual data and perform an error analysis in order
to evaluate the goodness of the ﬁt.

4.7
Exercises
203
16. Hundred observations consisting of measurements of the annual ﬂow of the
river Nile at Aswan in the period 1871–1970 are available in R by executing
the following commands
> library(MASS)
> data(Nile)
> y <- Nile
The data are ﬁrst reported in Cobb (1978)[Table 1, p. 249]. There appears to be
a drop in the level of the annual ﬂow near year 1898. Fit a suitable state space
model. See if your model can detect the change-point of the level mentioned
above.
17. Seventy-two observations consisting of monthly totals of accidental deaths in
the USA in the period of 1973–1978 available in R by executing the following
commands
> library(MASS)
> data(USAccDeaths)
> y <- USAccDeaths
The data are reported in Brockwell and Davis (1991). Suggest a state space
model for this data set. Provide a plot with the one-step forecasts against the
actual data and perform an error analysis in order to evaluate the goodness of
the ﬁt.
18. Monthly average air temperatures at Nottingham Castle (in degrees Fahrenheit)
in the period 1920–1939 are available in R by executing the following
commands
> library(MASS)
> data(nottem)
> y <- nottem
The data are reported in Anderson (1976). Suggest a state space model for this
data set. Fit the model to the data and perform an error analysis in order to
evaluate the goodness of the ﬁt.
19. One hundred and fourteen observations consisting of annual numbers of
lynx trappings for 1821–1934 in Canada are available in R by executing the
following commands
> library(MASS)
> data(lynx)
> y <- lynx
The data are reported in Brockwell and Davis (1991).
a. Suggest a state space model for this data set. Fit the model to the data and
perform an error analysis in order to evaluate the goodness of the ﬁt.
b. A closer look at the data reveals that the histogram of the observation is
right-skewed. Suggest a state space model on log yt, where yt denotes the
value of the annual lynx trappings at time t. Fit this model and make see if
it ﬁts better than the model in part (a).

204
4
Model Speciﬁcation and Model Performance
20. Two hundred and eighty-nine observations on annual numbers of sunspots from
1700 to 1988 are available in R by executing the following commands
> library(MASS)
> data(sunspot.year)
> y <- sunspot.year
The data is reported in Tong (1996). Suggest a state space model for this data.
Fit the model to the data and assess the goodness of ﬁt.
21. Monthly time series data (source: Harvey (1989)) consisting of monthly totals
of car drivers killed or seriously injured in the period January 1969 to December
1984 are available in R by executing the following commands
> library(MASS)
> data("drivers")
> y <- drivers
It is interesting to describe and quantify the form of variation here. Under-
standing/quantiﬁcation could enable the value of road safety measures to be
assessed. From the plot of the data there is an evident seasonal element, but
how consistent is it? Various road safety measures have been introduced during
the period (for example, the compulsory wearing of helmets by motor-cyclists
in 1973–1974 and of seat belts for car drivers and front-seat passengers on 31
January 1983). How large an effect did they have?
Analyse this data set by building a state space model and assess the forecast
performance of this model.
22. The following data contains the number of hectolitres of whisky produced each
month in UK between 1980 and 1987.
1980
1981
1982
1983
1984
1985
1986
1987
Jan
34.6
53.5
31.5
10.4
10.7
17.1
12.3
11.7
Feb
59.1
67.9
57.4
50.6
54.7
33.4
35.7
32.5
Mar
82.5
50.5
61.9
73.6
78.3
90.7
91.1
52.1
Apr
9.3
6.6
7.1
8.7
7.5
7.6
7.6
14.0
May
12.2
12.3
12.4
16.2
12.9
16.8
14.4
21.5
Jun
19.5
18.5
21.9
23.4
17.6
21.7
22.3
30.6
Jul
28.5
24.0
19.7
20.9
23.5
25.7
24.3
32.3
Aug
29.3
29.6
26.8
27.2
26.9
29.6
28.1
29.0
Sep
35.1
34.6
30.9
31.4
26.9
32.2
34.5
35.2
Oct
58.9
53.8
49.7
50.2
56.2
56.3
53.8
53.6
Nov
79.8
73.3
72.4
82.8
73.8
78.2
77.9
80.6
Dec
52.8
52.6
55.9
49.3
44.8
51.6
54.2
53.0
a. Find an appropriate state space model to describe the data;
b. Provide the one-step forecasts at each time and plot them against the data;
c. Carry out an error analysis and comment on the performance of the chosen
model.

4.7
Exercises
205
23. Consider the state space model (3.10a)–(3.10b), with
xt =
⎡
⎢⎢⎣
zt
1
0
0
⎤
⎥⎥⎦
and
F =
⎡
⎢⎢⎣
1 0 0 0
0 1 1 0
0 0 1 1
0 0 0 1
⎤
⎥⎥⎦,
where zt is a time-varying covariate.
Give a name of this model and suggest what type of time series data this model
may be useful for.
24. Consider the state space model (3.10a)–(3.10b), with
x =

1
0

and
F =

 1 λ
0 1

,
for some constant λ.
a. Give an expression of the forecast function of this model and suggest what
type of time series data this model may be useful for. Give an interpretation
of λ (e.g. by examining the effect several values of λ have in the forecast
function) and suggest how λ can be estimated given some observed data
y1, . . . , yn.
b. (Overparameterisation). A state space model is overparameterised if its
forecast function is equal to the forecast function of another state space
model with fewer parameters. Show that the above state space model is
overparameterised when λ = 0 and that it can be reduced to the local level
model.
25. At each time t, It denotes the lead indicator for a company’s sales St. The
following time-varying regression model is suggested to relate yt the quarterly
change in St to xt the quarterly change in It−2:
yt = xtβt + ϵt
and
βt = βt−1 + ζt,
where ϵt is white noise with variance 1, ζt is a white noise with variance 10,
and both ϵt, ζt are normally distributed.
a. Show that Pt|t the posterior variance of βt satisﬁes
1
Pt|t
=
1
Pt−1|t−1 + 10 + x2
t .
b. If x1 = 4, x2 = 4, y1 = 12, y2 = 11 and the prior of β0 is β0 ∼N(2, 0.81),
then use the result above to calculate the posterior means ˆβ1|1, ˆβ2|2 and the
posterior variances P1|1, P2|2.

206
4
Model Speciﬁcation and Model Performance
c. Using (b) obtain the one-step forecast mean of y3 = 9 and the associated
residual. Comment on the quality of this forecast.
d. If instead of β0 ∼N(2, 0.81) the prior distribution of β0 is set to either of
the following:
i. β0 ∼N(10, 0.81) or
ii. β0 ∼N(2, 100),
comment on whether you expect an improvement on forecasting and the
general model performance for all yt.
e. Suggest how the model performance can be improved.
26. In the scaled observational precision (SOP) model (4.55a)–(4.55b) of
Sect. 4.3.3 prove the following ﬁxed-interval smoothing algorithm:
a. Initial state distributions at t = n: βn | y1:n ∼t(nn, ˆβn|n, Pn|n) and σ −2 |
y1:n ∼G(nn/2, nnSn/2), where ˆβn|n, Pn|n, νn and Sn are computed by the
SOP algorithm of Sect. 4.3.3.
b. Smoothed state distribution, for t = 1, 2, . . . , n −1:
βt | y1:n ∼t(nn, ˆβt|n, Pt|n), where
ˆβt|n = ˆβt|t + Lt( ˆβt+1|n −ˆβt+1|t),
Pt|n = Sn
St
%
Pt|t + Lt(StS−1
n Pt+1|n −Pt+1|t)L⊤
t
&
,
with Lt = Pt|tF⊤
t+1P−1
t+1|t and ˆβt|t, ˆβt+1|t, Pt|t, Pt+1|t being calculated by
the SOP algorithm.
c. Smoothed observation distribution, for t = 1, 2, . . . , n −1:
yt
|
y1:n
∼
t(nn, ˆyt|n, qt|n), where ˆyt|n
=
x⊤
t ˆβt|n and qt|n
=
Sn(x⊤
t Pt|nxt/St + 1).
27. Show that the polynomial trend model with design vector and transition matrix
deﬁned as in (4.2) is observable.
28. Consider the state space model (3.10a)–(3.10b), with
xt = x =
⎡
⎢⎢⎢⎣
a1
a2
...
ap
⎤
⎥⎥⎥⎦
and
Ft = F =
⎡
⎢⎢⎢⎣
λ 1 0 · · · 0
0 λ 1 · · · 0
...
...
... ... ...
0 0 0 · · · λ
⎤
⎥⎥⎥⎦,
where a1, . . . , ap, λ are constants, satisfying a2
1 + · · · + a2
p ̸= 0 (at least one
of aj is non-zero); notice that F is a Jordan block matrix. Suppose that Zt, the
transition covariance matrix of the model, is speciﬁed using a discount factor δ.
a. If σ 2 > 0 and the prior covariance matrix P0|0 is non-singular, then show
that the posterior covariance matrix Pt|t is non-singular, for all t = 1, 2, . . . .

4.7
Exercises
207
b. If a1 ̸= 0 and λ2 > δ (together with the conditions in (a)) show that the limit
of P−1
t|t exists and is not depending on P0.
c. With the conditions of (a) and (b), show that the kl-th element p(−1)
kl
of
the precision limiting matrix P−1 = limt→∞P−1
t|t satisﬁes the following
equation
p(−1)
kl
= δ
k

i=1
l
j=1
(−1)k+l−i−jλi+j−k−l−2p(−1)
ij
+ akal/σ 2,
for k, l = 1, . . . , p.
29. a. In the context of Exercise 4.21 show that the precision covariance matrix
P−1
t|t of the (p −1)-th order polynomial trend model of Sect. 4.1.1 when the
transition covariance matrix is speciﬁed with a discount factor converges to
a matrix.
b. In the context of Exercise 4.21 consider a state space model (3.10a)–(3.10b),
with
x =
⎡
⎣
1
1
1
⎤
⎦,
F =
⎡
⎣
0.8 1
0
0 0.8 1
0
0 0.8
⎤
⎦
and σ 2 = 5.
i. Find the range of δ so that limt→∞P−1
t|t exists.
ii. If δ = 0.5, then calculate the limiting posterior covariance matrix P =
limt→∞Pt|t.
30. Show that, for λ ̸= 0, the forecast function of the state space model of Exercise
4.20 is
ˆyt+k|t =
p

i=1
i

j=1

k
i −j
	
λk−i+jaj ˆβt|t,i,
where ˆβt|t = [ ˆβt|t,1, . . . , ˆβt|t,p]⊤.
If a1 = 1 and aj = 0, for all j > 1, show that the above forecast function
reduces to
ˆyt+k|t =
p

i=1
 k
i −1
	
λk−i+1 ˆβt|t,i,
If, in addition λ = 1 show that the above forecast function reduces to the
forecast function of the (p −1)-th polynomial trend model of Sect. 4.1.1. Thus,
we have generalised the polynomial trend models to allow for any non-zero λ.

208
4
Model Speciﬁcation and Model Performance
31. Consider the local level model
yt = βt + ϵt
and
βt = βt−1 + ζt,
where ϵt ∼N(0, σ 2) and ζt ∼N(0, Zt), and the innovations are as usual
individually and mutually independent and independent of the assumed prior
β0 ∼N( ˆβ0|0, P0|0). Suppose that information y1:n = (y1, . . . , yn) is available,
for observed time series y1, . . . , yn and for some positive integer n.
If Zt is modelled with a discount factor δ, show that, for t = 1, . . . , n −1, the
recursions of the smoothed mean ˆβt|n and the smoothed variance Pt|n can be
simpliﬁed as
ˆβt|n = (1 −δ) ˆβt|t + δ ˆβt+1|n
and
Pt|n = (1 −δ)Pt|t + δ2Pt+1|n,
where ˆβt|t and Pt|t are the posterior mean and variance of βt, provided by
the Kalman ﬁlter. Thus, the smoothed mean ˆβt|n is an EWMA (exponentially
weighted moving average) of the sequence of posterior means ˆβ1|1, . . . , ˆβn|n.
Use this fact to interpret the role of δ in the dynamical behaviour of ˆβt|n.

Chapter 5
Multivariate State Space Models
This chapter studies multivariate Gaussian state space models, aimed at situations
where several time series are observed at each time t. The foundation of the
chapter is an extension of the univariate state space models of Chaps. 3 and 4 to
the multivariate case. This is achieved in a relatively painless way by replacing
scalar components with vectors and vector components with matrices in the main
univariate state space model of Chap. 3. Particular emphasis in this chapter is placed
on the estimation of the covariance matrices of the innovation terms of the model,
which can be exploited in order to estimate the cross-correlation of the several time
series observed at each time.
Section 5.1 introduces the multivariate state space model and discusses the
Kalman ﬁlter for this extended class of state space models. Model design and error
analysis follow in Sects. 5.2 and 5.4 and they are developed in parallel with the
univariate case (Chap. 4). Section 5.5 considers in detail covariance estimation
and in particular provides two generalisations of the scaled observational precision
(SOP) univariate model of Sect. 4.3.3. The next section provides an illustrative
example of a trivariate time series consisting of pollution variables in the wider area
of Athens. Section 5.7 develops Markov chain Monte Carlo estimation methods for
the multivariate state space model.
5.1
The Kalman Filter
So far we have assumed that the response time series yt is scalar, i.e. we are
interested on a single time series. There are many situations that instead we are
interested in modelling several time series jointly. Modelling each series separately
is not desirable, because it is usually of interest to estimate the interdependence
or correlation structure between the component time series. To set up notation we
consider d time series y1t, y2t, . . . , ydt, for some integer d ≥1 and t = 1, 2, . . ..
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2021
K. Triantafyllopoulos, Bayesian Inference of State Space Models, Springer Texts
in Statistics, https://doi.org/10.1007/978-3-030-76124-0_5
209

210
5
Multivariate State Space Models
We form the vector time series
yt =
⎡
⎢⎢⎢⎣
y1t
y2t
...
ydt
⎤
⎥⎥⎥⎦
and we are interested in setting up a state space model that can describe the
stochastic dynamics and variation of yt. Sometimes the scalar time series {yit} is
referred to as component time series, because the element yit is a component of the
vector yt at each time t.
A multivariate state space model for yt generalises the univariate state space
model (3.10a)–(3.10b) by setting
yt = x⊤
t βt + ϵt
(observation model),
(5.1a)
βt = Ftβt−1 + ζt
(transition model),
(5.1b)
where xt is a p×d design matrix, βt is a p×1 state vector and Ft is a p×p transition
matrix. The innovation vectors ϵt and ζt are assumed to follow multivariate Gaussian
distributions, i.e.
ϵt ∼N(0, )
and
ζt ∼N(0, Zt),
(5.2)
where  is a d × d covariance matrix and Zt is a p × p covariance matrix.
The innovation sequences {ϵt} and {ζt} are each assumed to be independent as
well as mutually independent, i.e. E(ϵtϵ⊤
s ) = 0, E(ζtζ ⊤
s ) = 0, for any t ̸= s,
and E(ϵtζ ⊤
t ) = 0, for any t, s. The model is complete by specifying the initial
distribution of β0, which is assumed to be independent of {ϵt} and {ζt}, as
β0 ∼N( ˆβ0|0, P0|0),
(5.3)
for some p × 1 prior vector ˆβ0|0 and p × p prior covariance matrix P0|0.
Some comments are in order.
•
Model (5.1a)–(5.1b) provides a complete generalisation of model (3.10a)–
(3.10b); indeed we can observe that for d = 1, yt = y1t is a scalar time series,
xt = xt is a p × 1 vector,  = σ 2 is a variance and (5.1a)–(5.1b) are reduced to
(3.10a)–(3.10b).
•
If xt is a matrix of time-varying covariates and Ft = I, then (5.1a)–(5.1b)
describes a time-varying regression model for a vector of time series yt. This in
turn is a direct generalisation of the time-varying regression model for univariate
time series (3.9a)–(3.9b) described in Sect. 3.1.3.
•
If p = d, xt = Ft = I, then the state space model (5.1a)–(5.1b) describes yt to
exhibit local variation around the level vector βt, which generalises the univariate

5.1
The Kalman Filter
211
local level model of Sect. 3.1.3; this model may be referred to as multivariate
local level model.
•
From the above points it becomes clear that, within the state space model (5.1a)–
(5.1b), all models of Sect. 4.1 can be extended to accommodate a vector of
observations yt.
•
If we denote by xit the i-th column of xt (i = 1, 2, . . . , d) so that
xt = [x1t, x2t, . . . , xdt] ,
then we can write the observation equation (5.1a) as
⎡
⎢⎢⎢⎣
y1t
y2t
...
ydt
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
x⊤
1t
x⊤
2t...
x⊤
dt
⎤
⎥⎥⎥⎦βt +
⎡
⎢⎢⎢⎣
ϵ1t
ϵ2t
...
ϵdt
⎤
⎥⎥⎥⎦
where ϵt = [ϵ1t, ϵ2t, . . . , ϵdt]⊤. Thus, from the state model (5.1a)–(5.1b) to d
we can write
yit = x⊤
it βt + ϵt,
ϵit ∼N(0, σii),
(5.4a)
βt = Ftβt−1 + ζt,
ζt ∼N(0, Zt),
(5.4b)
where σii is the ii-th element of . First notice that for all yit (i = 1, 2, . . . , d),
the transition equation (5.4b), hence the above d state space models are not inde-
pendent, because estimation of one model (ﬁxing yit) will inﬂuence estimation
of another model (ﬁxing yjt, for i ̸= j). Secondly, notice that the system of
the d models (5.4a)–(5.4b) is not able to take into account the effects of the
covariances of ϵit and ϵjt (the off-diagonal elements of ), which imply an effect
of the correlation of yit and yjt. Therefore, when we observe time series that are
correlated, it is then incorrect to model each of them using a state space model
of the form (5.4a)–(5.4b); in such situations we need to apply the multivariate
state space model (5.1a)–(5.1b), which explicitly deﬁne the inter-dependence of
y1t, y2t, . . . , ydt.
With the deﬁnition of the state space model (5.1a)–(5.1b) the Kalman ﬁlter (used
in Sect. 3.2 for ﬁltering of univariate time series) is updated for multivariate time
series as follows.
Theorem 5.1 (Kalman Filter) Consider the state space model (5.1a)–(5.1b)
together with the error or innovations distribution (5.2) and the initial distribution
(5.3). Then, for each time t = 1, . . . , n, the following apply:
1. The forecast distribution of βt at time t −1 is βt | y1:t−1 ∼N( ˆβt|t−1, Pt|t−1),
where ˆβt|t−1 = Ft ˆβt−1|t−1 and Pt|t−1 = FtPt−1|t−1F⊤
t + Zt.

212
5
Multivariate State Space Models
2. The posterior distribution of βt at time t is βt | y1:t ∼N( ˆβt|t, Pt|t), where ˆβt|t =
ˆβt|t−1 + Ktet, ˆyt|t−1 = x⊤
t ˆβt|t−1, et = yt −ˆyt|t−1, Qt|t−1 = x⊤
t Pt|t−1xt + ,
Kt = Pt|t−1xtQ−1
t|t−1 and Pt|t = Pt|t−1 −KtQt|t−1K⊤
t .
The proof of this result is very similar to that of Theorem 3.2 and is left to the reader
as an exercise.
Some comments are in order. Theorem 3.2 for a univariate state space model is
obtained as a special case of Theorem 5.1, for d = 1. If d ≥2, the Kalman gain Kt
is a p × d matrix and the forecast variance Qt|t−1 is now a d × d covariance matrix.
Many of the aspects of univariate state space modelling discussed in Chap. 4 can be
extended to the multivariate case. Below we point out several of these extensions.
•
Fixed-interval smoothing.
For each t
= 1, . . . , n, the smoothed state distribution is: βt
| y1:n
∼
N( ˆβt|n, Pt|n), where ˆβt|n =
ˆβt|t + Lt( ˆβt+1|n −ˆβt+1|t) and Pt|n = Pt|t +
Lt(Pt+1|n −Pt+1|t)L⊤
t , with Lt = Pt|tF⊤
t+1P−1
t+1|t and ˆβt|t, ˆβt+1|t, Pt|t, Pt+1|t
being calculated via the Kalman ﬁlter (Theorem 5.1). Similarly, the smoothed
observation distribution is: yt | y1:n ∼N( ˆyt|n, Qt|n), where ˆyt|n = x⊤
t ˆβt|n
and Qt|n = x⊤
t Pt|nxt + . These results reduce to Theorem 3.4 when d = 1
(univariate case).
•
Forecasting. Assuming that the transition matrix Ft = F is time-invariant and
with information y1:t = {y1, . . . , yt}, the k-step ahead forecast state distribution
is given by βt+k | y1:t ∼N( ˆβt+k|t, Pt+k|t), with ˆβt+k|t = Fk ˆβt|t and
Pt+k|t = FkPt|t(Fk)⊤+
k−1

j=0
FjZt+k−j(Fj)⊤,
where ˆβt|t, Pt|t are computed by the Kalman ﬁlter (Theorem 5.1).
Similarly, the k-step ahead forecast observation distribution is given by
yt+k | y1:t ∼N( ˆyt+k|t, Qt+k|t), where ˆyt+k|t = x⊤
t+k ˆβt+k|t and Qt+k|t =
x⊤
t+kPt+k|txt+k + . As in Chap. 3 the forecast mean vector ˆyt+k|t = E(yt+k |
y1:t) (if viewed as a function of k = 1, 2, 3, . . .) is known as the forecast function
and can play an important role in the model design.
Below is a summary of the Kalman ﬁlter.
Kalman Filter
1. Initial distribution at t = 0: β0 ∼N( ˆβ0|0, P0|0);
2. Posterior distribution of βt−1 at time t −1:
βt−1 | y1:t−1 ∼N( ˆβt−1|t−1, Pt−1|t−1);
(continued)

5.2
Model Speciﬁcation and Design
213
3. Prior distribution of βt at time t −1:
βt | y1:t−1 ∼N( ˆβt|t−1, Pt|t−1),
where ˆβt|t−1 = Ft ˆβt−1|t−1 and Pt|t−1 = FtPt−1|t−1F⊤
t + Zt;
4. Posterior distribution at time t:
βt | y1:t ∼N( ˆβt|t, Pt|t), where
ˆβt|t = ˆβt|t−1 + Ktet,
Pt|t = Pt|t−1 −KtQt|t−1K⊤
t ,
ˆyt|t−1 = x⊤
t ˆβt|t−1,
et = yt −ˆyt|t−1,
Qt|t−1 = x⊤
t Pt|t−1xt + ,
Kt = Pt|t−1xtQ−1
t|t−1.
5.2
Model Speciﬁcation and Design
This section discusses speciﬁcation of the design matrix xt, the transition matrix Ft
as well as speciﬁcation or estimation of the observation covariance matrix  and
the transition covariance matrix Zt.
Speciﬁcation of xt and Ft. In the core of model speciﬁcation and design is the
speciﬁcation or selection of the design matrix xt, the transition matrix Ft, the
observation covariance matrix  and the transition covariance matrix Zt. Leaving
aside these two covariance matrices (their speciﬁcation is discussed later), the
components xt and Ft characterise the forecast function yt+k||t (assuming ˆβt|t being
calculated), hence their speciﬁcation (or estimation) plays a critical role for ﬁltering,
forecasting and smoothing. Noting the state space breakdown of yt into d univariate
state space models y1t, . . . , ydt as in (5.4a)–(5.4b), we can think of choosing each
row x⊤
it of x⊤
t to describe each of the scalar time series yit. This can be facilitated as
in Chap. 4 (see e.g. Sect. 4.1), but here we note that the state vector βt is common
for all d state space models, hence the dynamics of β driven by the transition matrix
Ft must be the same for all d models). For example, consider a bivariate time series
yt = [y1t, y2t]⊤, for which we consider a bivariate state space model (5.1a)–(5.1b).
Suppose that both y1t and y2t represent a linear trend (linear growth), but they
may differ in their variability, i.e. the components of the observation and transition
variances. Then a possible speciﬁcation for xt and Ft is
xt =

 1 1
0 0

and
Ft =

 1 1
0 1


214
5
Multivariate State Space Models
so that both
y1t = [1, 0]βt + ϵ1t
and
y2t = [1, 0]βt + ϵ2t,
represent linear growth state space models, with common transition equation
βt =

 1 1
0 1

βt−1 + ζt,
where ϵt = [ϵ1t, ϵ2t]⊤.
This approach will not work if y1t and y2t represent structurally different state
space models, e.g. if y1t represents linear growth, while y2t represents a seasonal
time series. This is because their respective state space vectors will not be the same;
they will be driven by different transition matrices and hence will exhibit different
dynamics (see e.g. the different state representations in Sect. 4.1). In such a case it
may be worth modelling each yit separately using a univariate state space model.
Speciﬁcation of  and Zt. Apart from the speciﬁcation of the design and transition
matrices xt and Ft, the estimation and forecasting provided by the Kalman ﬁlter are
subject to the speciﬁcation of the observation covariance matrix  (the covariance
matrix of the observation innovation vector ϵt) and the transition covariance matrix
Zt (the covariance matrix of the state innovation vector ζt). Zt may be speciﬁed
using discount factors, as in Sect. 4.3.2, i.e. setting up Zt as in Eq. (4.53).
Alternatively, if Zt = Z is time-invariant, it can be estimated from the data, together
with  by using the EM algorithm. The EM algorithm is very similar to that of the
univariate case (see p. 158). Indeed, with the multivariate state space model (5.1a)–
(5.1b), the log-likelihood function (4.42) is upgraded to
ℓ(θ; y, β) = −n
2 log || −1
2
n

t=1
(yt −x⊤
t βt)⊤−1(yt −x⊤
t βt)
−n
2 log |Z| −1
2
n

t=1
(βt −Ftβt−1)⊤Z−1(βt −Ftβt)
−1
2 log |P0|0| −1
2(β0 −ˆβ0|0)⊤P−1
0|0(β0 −ˆβ0|0),
(5.5)
where now θ is the vector including the unknown parameters of , Z, ˆβ0|0, P0|0. A
similar procedure to the EM algorithm for univariate state space models involves the
expectation(E-step) and differentiation (M-step) leading to the following recursions
of the EM algorithm.

5.2
Model Speciﬁcation and Design
215
EM Algorithm for Multivariate State Space Models
In the state space model (5.1a)–(5.1b) with information y1:n = {y1, . . . , yn}
the maximum likelihood estimate of the parameter vector
θ = [vech(), vech(Z)⊤, ˆβ⊤
0|0, vech(P0|0)⊤]⊤,
is approximately ˆθ(N), where ˆθ(i) is iteratively computed as follows:
1. Initial estimate
θ(0) =
%
vech( ˆ
(0))⊤, vech( ˆZ(0))⊤, ( ˆβ(0)
0|0)⊤, vech(ˆP(0)
0|0)⊤&⊤
.
2. For each i = 0, 1, 2, . . . , N −1:
a. For each t = 0, 1, . . ., n Compute ˆβt|n, Pt|n, conditioned upon θ(i);
b. Compute
ˆ
(i+1) = 1
n
n

t=1
%
(yt −x⊤
t ˆβt|n)(yt −x⊤
t ˆβt|n)⊤+ x⊤
t Pt|nxt
&
;
ˆZ(i+1) = 1
n
n

t=1

( ˆβt|n −Ft ˆβt−1|n)( ˆβt|n −Ft ˆβt−1|n)⊤
+Pt|n −Pt,t−1|nF⊤
t −FtP⊤
t,t−1|n + FtPt−1|nF⊤
t

;
ˆβ(i+1)
0|0
= ˆβ0|n;
ˆP(i+1)
0|0
= 1
n
%
( ˆβ0|n −ˆβ0|0)( ˆβ0|n −ˆβ0|0)⊤+ P0|n
&
;
c. Set
ˆθ(i+1) =
%
vech( ˆ
(i+1))⊤, vech( ˆZ(i+1))⊤, ( ˆβ(i+1)
0|0
)⊤, vech(ˆP(i+1)
0|0
)⊤&⊤
.
The proof of this version of the EM algorithm is very similar to that in the
univariate case (see Sect. 4.3.1 in Chap. 4); we note that the proof of ˆ is obtained
in a similar way as that of ˆZ in the univariate case (Sect. 4.3.1). The same stopping
rules can be applied as in the EM algorithm for the univariate case.
Finally, we brieﬂy discuss about the steady state of multivariate state space
models.

216
5
Multivariate State Space Models
Steady State of the Kalman Filter Considering the state space model (5.1a)–
(5.1b) with time-invariant components xt
= x, Ft
= F and Zt
= Z, then
Theorem 3.7 is easily extended to the multivariate case. Thus, the limit of the
posterior covariance matrix Pt|t exists and does not depend on the prior covariance
matrix P0|0. The proof is almost identical to that of Theorem 3.7, the modiﬁcations
taking care that yt is known a vector and Qt|t−1 is a covariance matrix (replacing the
variance qt|t−1). The steady state of the Kalman ﬁlter replaces Pt|t in ˆβt|t by its limit
P, hence enabling signiﬁcant computational savings. The next section considers the
multivariate local level model, for which an explicit expression of the limit of the
posterior covariance matrix is available.
5.3
Steady State of the Multivariate Local Level Model
In Sect. 3.5.2 the steady state of the Kalman ﬁlter for univariate local level models
was studied; in effect the limit of the posterior variance of the states, obtained from
the Kalman ﬁlter, was derived. The concept of the steady state for multivariate state
space models provides a complete analogue of that for univariate models, discussed
in Sect. 3.5. In essence under certain conditions the posterior covariance matrix
of the state vector converges to a stable matrix, which can replace the posterior
covariance matrix in the recursions of the Kalman ﬁlter providing computational
savings in the application of the Kalman ﬁlter. In the following we consider a slight
generalisation of the local level state space model and we derive in close form the
limit of the covariance matrix of the state vector.
Before we proceed with the description of the local level model, we brieﬂy
discuss square root of symmetric matrices. We only discuss here the square root
based on the spectral decomposition of a symmetric matrix; other approaches are
also possible, e.g. based on the Choleski decomposition. Suppose that X is a
symmetric matrix with elements from the real ﬁeld. Then we can write
X = ⊤,
(5.6)
where  is the diagonal matrix with its diagonal including the eigenvalues of
X and  is the matrix consisting of the respective normalised eigenvectors; the
normalisation concerns restricting the eigenvectors to have a unit Eucledean norm.
This implies that the matrix  is orthogonal, or ⊤ = I For the proof of (5.6) the
reader is referred to Horn and Johnson (2013) and Harville (1997).
Suppose now that X is a covariance matrix, so that it is symmetric and positive
deﬁnite. It follows that the eigenvalues of X are real and strictly positive and so we
can deﬁne the symmetric square root matrix of X as the matrix
X1/2 = 1/2⊤,

5.3
Steady State of the Multivariate Local Level Model
217
or in words, the matrix whose eigenvalues are the square root of the eigenvalues of
X. From this deﬁnition and Eq. (5.6) it is easy to verify that
X1/2X1/2 = 1/2⊤1/2⊤= ⊤= X,
since the matrix  is orthogonal. The inverse of X1/2 will be denoted by X−1/2 and
is the covariance matrix with eigenvalues equal to the inverse of the square root of
the eigenvalues of X.
Returning to the local level model, consider that d-dimensional observation
vector time series {yt} is generated by the state space model
yt = βt + ϵt
and
βt = φβt−1 + ζt,
(5.7)
where φ is a known scalar, ϵt is a white noise process, ζt is a white noise process,
ϵt is independent of ζs, for any t, s. Moreover, the distribution of the observation
vector ϵt is a d-dimensional Gaussian distribution with zero mean vector and some
covariance matrix , written as ϵt ∼N(0, ). Likewise, the distribution of ζt is
ζt ∼N(0, 1/2Z∗1/2), where here 1/2 denotes the symmetric square root matrix
of , based on the spectral decomposition of symmetric matrices (see above). The
above factorisation of the covariance matrix of ζt, i.e. Var(ζt) = Z = 1/2Z∗1/2
proposes a suitable proportionality between  and Z and is considered because it
facilitates estimation of , which is developed in Triantafyllopoulos (2011a). The
prior covariance matrix of β0 is also scaled in the same way, hence Var(β0) =
P0|0 = 1/2P∗
0|01/2, so that the prior distribution of β0 is
β0 ∼N( ˆβ0|0, 1/2P∗
0|01/2),
for some known d × d covariance matrix P∗
0|0. In the discussion of this section we
assume that  is known; its estimation is studied in Triantafyllopoulos (2011a).
Strictly speaking model (5.7) is a local level when φ = 1, but here we expand the
deﬁnition by considering a slightly wider class of state space models, for any value
of φ. In particular, we remark the following:
1. If φ = 0, then model (5.7) is reduced to yt = ϵt +ζt, which is essentially a white
noise with covariance matrix  + Z.
2. If φ = 1, then model (5.7) is the traditional local level model; the level βt follows
is a random walk process.
3. If |φ| < 1, then the level βt follows a multivariate autoregressive process of order
one, with AR parameter matrix φI.
4. If |φ| > 1, the model behaves similarly as a local level, but the level evolution
expanding erratically, depending on the value of φ.
The following theorem gives the main result, the convergence of the posterior
covariance matrix Pt|t.

218
5
Multivariate State Space Models
Theorem 5.2 In the state space model (5.7) with the prior P∗
0|0 = p0Ip, for a
known constant p0 > 0, the limit of the sequence of posterior covariance matrices
{Pt|t} exists and it is given by
P = lim
t→∞Pt|t = 1/2P∗1/2,
where
P∗=
1
2φ2

3
(Z∗+ (1 −φ2)I)2 + 4Z∗41/2
−Z∗−(1 −φ2)I

,
for φ ̸= 0 and P∗= Z∗(Z∗+ I)−1, for φ = 0.
The principles of boundedness, monotonicity and convergence of a sequence of
matrices (in particular covariance matrices) were discussed in Sect. 3.5.3. Here we
show that if A > 0 and B > 0 are two positive deﬁnite matrices, such that A−B > 0
is a positive deﬁnite matrix (this is written as A > B, as discussed in Sect. 3.5.3),
then A−1 < B−1. Indeed, note that A −B > 0 implies that there is a positive
deﬁnite matrix C such that A = B + C. Now from the property B−1 −A−1 =
A−1(A −B)B−1 we have that B−1 −A−1 > 0, since A−1 > 0, A −B > 0
and B−1 > 0. Hence B−1 > A−1. A book length discussion on matrix analysis
with particular emphasis to covariance matrices can be found in the classic textbook
Horn and Johnson (2013).
With this result in place, the existence of the limit of Pt|t is proven in the next
lemma.
Lemma 5.1 With the assumptions of Theorem 5.2, the sequence of d × d positive
deﬁnite matrices {Pt} is convergent.
Proof With the prior of β0 and the Kalman ﬁlter, we will show that Pt|t
=
1/2P∗
t|t1/2, hence the limit of Pt|t exists if and only if the limit of P∗
t|t
exists, where P∗
t|t is updated by the Kalman ﬁlter as follows. First we note that
Pt|t−1 = 1/2(P∗
t−1|t−1 + Z∗)1/2 = 1/2P∗
t|t−11/2 and the Kalman gain is
Kt = Pt|t−1Q−1
t|t−1 = 1/2K∗
t −1/2, where Qt|t−1 = 1/2(P∗
t|t−1 + I)1/2 =
1/2Q∗
t|t−11/2 is used. Thus, the posterior covariance matrix of βt is Pt|t =
1/2P∗
t|t1/2, where
P∗
t|t = P∗
t|t−1 −K∗Q∗
t|t−1K∗
t
= P∗
t|t−1(I −Q∗−1
t|t−1P∗
t|t−1)
= P∗
t|t−1Q∗
t|t−1(Q∗
t|t−1 −P∗
t|t−1)
= P∗
t|t−1Q∗
t|t−1.

5.3
Steady State of the Multivariate Local Level Model
219
First suppose that φ = 0. Then P∗
t|t−1 = Z∗, for all t, and so P∗
t|t = Z∗(Z∗+I)−1,
which of course is convergent.
Suppose now that φ ̸= 0. To prove the existence of the limit of {P∗
t|t} It sufﬁces
to prove that {P∗
t|t} is bounded and monotonic. Clearly, 0 ≤P∗
t|t and since φ2 > 0
and Z∗is positive deﬁnite 0 < P∗
t|t, for all t > 0. Since (P∗
t|t−1 + I)−1 > 0,
(P∗
t|t−1 + I −P∗
t|t−1)(P∗
t|t−1 + I)−1 > 0 ⇒P∗
t|t = P∗
t|t(P∗
t|t−1 + I)−1 < I and so
0 < P∗
t|t < I.
For the monotonicity it sufﬁces to prove that, if P∗−1
t−1|t−1 > P∗−1
t−2|t−2 (equivalent
P∗−1
t−1|t−1 < P∗−1
t−2|t−2), then P∗−1
t|t
> P∗−1
t−1|t−1 (equivalent P∗−1
t|t
< P∗−1
t−1 ). From
P∗−1
t−1|t−1 > P∗−1
t−2|t−2 we have P∗
t−1|t−1 < P∗
t−2|t−2 ⇒P∗
t|t−1 < P∗
t−1|t−2 ⇒P∗−1
t|t
>
P∗−1
t−1|t−2 ⇒P∗−1
t|t
−P∗−1
t−1|t−1 = P∗−1
t|t−1 −P∗−1
t−1|t−2 > 0, since P∗−1
t|t
= (P∗
t|t−1 +
I)P∗−1
t|t−1 = I + P∗−1
t|t−1. With an analogous argument we have that if P∗−1
t−1|t−1 <
P∗−1
t−2|t−2, then P∗−1
t|t
−P∗−1
t−1|t−1 < 0, from which the monotonicity follows.
⊓⊔
The next lemma proves a property, which is used to derive a closed form expression
of the limit of {P∗
t|t} below.
Lemma 5.2 Let {P∗
t|t} be the sequence of Lemma 5.1. Then, with Z∗as in
Lemma 5.1, the limiting matrix P∗= limt→∞P∗
t|t commutes with Z∗.
Proof First we prove that if P∗
t−1|t−1 commutes with Z∗, then P∗
t|t also commutes
with Z∗. Indeed from P∗
t|t = (φ2P∗
t−1|t−1 + Z∗)(φ2P∗
t−1|t−1 + Z∗+ I)−1 we have
that P∗−1
t|t
= I + (φ2P∗
t−1|t−1 + Z∗)−1 and then
P∗−1
t|t Z∗−1 = Z∗−1 + (φ2Z∗P∗
t−1|t−1 + Z∗2)−1
= Z∗−1 + (φ2P∗
t−1|t−1Z∗+ Z∗2)−1 = Z∗−1P∗−1
t|t
which implies that Z∗P∗
t|t = (P∗−1
t|t Z∗−1)−1 = (Z∗−1P∗−1
t|t )−1 = P∗
t|tZ∗and so P∗
t|t
and Z∗commute. Because P∗
0|0 = p0I, P0|0 commutes with Z∗and so by induction
it follows that the sequence of matrices {Pt|t, t ≥0} commutes with Z∗. Since
P∗= limt→∞P∗
t|t exists (Lemma 5.1) we have
P∗Z∗= lim
t→∞(P∗
t|tZ∗) = lim
t→∞(Z∗P∗
t|t) = Z∗P∗
and so P∗commutes with Z∗.
⊓⊔
Finally, we can give the proof of Theorem 5.2.
Proof (Proof of Theorem 5.2) From Lemma 5.1 we know that the limit of Pt|t =
1/2P∗
t|t1/2 exists, hence it is
P = lim
t→∞Pt|t = 1/2P∗1/2,

220
5
Multivariate State Space Models
where P∗= limt→∞P∗
t|t, which exists by Lemma 5.1. The rest of the proof concerns
the derivation of P∗.
If φ = 0, then from Lemma 5.1 we have P∗
t|t = P∗= Z∗(Z∗+ I)−1. Let
φ ̸= 0; from Lemma 5.1 we have that P∗exists and from Lemma 5.2 we have that
P∗and Z∗commute. From P∗
t|t = (φ2P∗
t−1|t−1 + Z∗)(P∗
t−1|t−1 + Z∗+ I)−1 we
have P∗= (φ2P∗+ Z∗)(φ2P∗+ Z∗+ I)−1 from which we get the equation P∗2 +
φ−2P∗(Z∗+ I −φ2I) −φ−2Z∗= 0. In order to solve this matrix equation for P∗,
we complete the square, by using the result that P∗and Z∗commute (Lemma 5.2).
Thus
P∗2 +
1
2φ2 P∗(Z∗+ (1 −φ2)I) +
1
2φ2 (Z∗+ (1 −φ2)I)P∗
+ 1
4φ4 (Z∗+ (1 −φ2)I)2 −
1
4φ4 (Z∗+ (1 −φ2)I)2 −Z∗= 0
or

P∗+
1
2φ2 (Z∗+ (1 −φ2)I)
	2
=
1
4φ4 (Z∗+ (1 −φ2)I)2 + Z∗
or
P∗=
1
2φ2

3
(Z∗+ (1 −φ2)I)2 + 4Z∗41/2
−Z∗−(1 −φ2)Ip

,
after rejecting the negative deﬁnite root.
⊓⊔
Theorem 5.2 generalises results for the univariate local level, discussed in
Sect. 3.5.2. Indeed, we observe that for d = 1 and if we set φ = 1 (local level
model), σ 2 =  and Z = σ 2Z∗we obtain that the limiting covariance matrix P is
P = lim
t→∞Pt|t = σ 2P ∗= σ 2
2
'
Z∗2 + 4Z∗−Z∗
= Z
2
⎛
⎝
,
1 + 4σ 2
Z
−1
⎞
⎠,
which is the same as in Sect. 3.5.2. Indeed, it can be observed that the proof for the
multivariate case parallels the proof for the univariate case in Sect. 3.5.2. However,
if the proposed scaling of Z = 2Z∗1/2 (the proportionality of  and Z) is not
considered, then the expression of P in closed form in Theorem 5.2 is no more
available.
Based on the above discussion and on the Kalman ﬁlter (Theorem 5.1) the
steady state of the multivariate local level considered above replaces Pt|t by its limit
1/2P∗1/2 in ˆβt|t or
ˆβt|t = φ ˆβt−1|t−1 + 1/2K∗−1/2et,
where et = yt −φ ˆβt−1|t−1 and
K∗= lim
t→∞K∗
t = (P∗+ Z∗)(P∗+ Z∗+ I)−1.

5.4
Error Analysis
221
We note that P∗as well as K∗depend on φ, Z∗and , hence P∗and K∗can be
calculated before any data is collected (as long as the covariance matrices Z∗and
, and φ are known a priori). This introduces important computational savings,
especially for large values of d of the dimension of yt. Indeed, we observe that there
is only one matrix inversion required that of the matrix P∗+ Z∗+ I involved in
the calculation of K∗; instead the application of the Kalman ﬁlter (Theorem 5.1)
requires a matrix inverse for each time t.
5.4
Error Analysis
In the above section we have described how the design matrix xt, the transition
matrix Ft as well as the covariances  and Zt may be speciﬁed or estimated,
considering the multivariate state space model (5.1a)–(5.1b); more detailed dis-
cussion on sequential estimation of  follows in Sect. 5.5 below. Here, assuming
that the matrices xt, the transition matrix Ft as well as the covariances  and Zt
are estimated or speciﬁed, we consider model assessment in the lines of residual
analysis of Sect. 4.4.
The residual vector (or one-step ahead forecast errors) et are deﬁned by
et = yt −ˆyt|t−1
(5.8)
where ˆyt|t−1 is the one-step ahead forecast mean vector of yt, which is provided
recursively by the Kalman ﬁlter (Theorem 5.1). The goodness of ﬁt is assessing
whether the forecasts ˆyt|t−1 are close enough to the observation vectors, or whether
the residuals et are close to zero. The following result provides a generalisation of
Theorem 4.2 and provides the main properties of the residuals.
Theorem 5.3 In the state space model (5.1a)–(5.1b) and with the deﬁnitions of
the Kalman ﬁlter recursions (Theorem 5.1) for some data y1:n = {y1, . . . , yn}, the
following apply for the residuals.
1. Given y1:t−1, the distribution of the residuals is et | y1:t−1 ∼N(0, Qt|t−1) (a
d-variate Gaussian distribution), where Qt|t−1 is the forecast covariance matrix
of yt, provided by the Kalman ﬁlter.
2. e1, . . . , en are independent.
3. With the deﬁnitions of et and Q|t−1 as above,
n

t=1
e⊤
t Q−1
t|t−1et ∼χ2
nd,
where χ2
nd denotes the chi-square distribution with nd degrees of freedom.

222
5
Multivariate State Space Models
Proof (1) follows immediately from the deﬁnition of et by noting that the one-step
forecast distribution of yt is yt | y1:t−1 ∼N( ˆyt|t−1, Qt|t−1), see Theorem 5.1. The
proof of (2) is identical to that of Theorem 4.2 except that now et is a residual vector,
while in Theorem 4.2 et was a scalar. Moving on to the proof of (3) we note that from
part (1) we have e∗
t = Q−1/2
t|t−1et ∼N(0, I), so that e∗⊤
t
e∗
t = e⊤
t Q−1
t|t−1et follows a
chi-square distribution with d degrees of freedom, where Q−1/2
t|t−1 denotes the inverse
of square root matrix, based on spectral decomposition theorem (see Sect. 5.3 for
the deﬁnition of square root matrix). Now, since e1, . . . , en are independent (from
part (2)), this implies that
n

t=1
e∗⊤
t
e∗
t =
n

t=1
e⊤
t Q−1
t|t−1et ∼χ2
nd
and the proof is completed.
⊓⊔
From the proof of the above theorem we see that if we deﬁne by
e∗
t = Q−1/2
t|t−1et
the standardised residuals, the following properties apply.
1. e∗
t ∼N(0, I);
2. e∗
1, . . . , e∗
n are independent;
3. For each t e∗
it and e∗
jt are independent and eit
∼N(0, 1), where e∗
t
=
[e∗
1t, e∗
2t, . . . , e∗
dt]⊤.
Property (1) says that e∗
t follows a Gaussian distribution with zero mean vector
and identity covariance matrix. This means that the elements of e∗
t are independent
(property (3)) and e∗
t is independent of e∗
s , for t ̸= s (property (2)). These properties
of e∗
t may be used to construct formal or informal diagnostic checks to assess the
goodness of ﬁt. Informal analysis may include:
•
Histograms or normal probability plots to check whether e∗
it follows a Gaussian
distribution.
•
A plot of eit against time t together with ±1.96 credible intervals of the N(0, 1)
distribution. For a good ﬁt we would expect about 5% of residuals to lie outside
the intervals.
•
Plots of the autocorrelation function (ACF) on e∗
i1, e∗
i2, . . . , e∗
i,n to check whether
e∗
i1, e∗
i2, . . . , e∗
in are independent, for a ﬁxed i = 1, 2, . . . , d. For independence
we would expect the autocorrelations in all lags of the residuals to lie inside the
credible intervals ±1.96/√n.
Furthermore, more formal tests may be developed by using part (3) of Theorem 5.3,
for example for a good model ﬁt the value X2 = n
t=1 e∗⊤
t
e∗
t should be smaller or
equal to the 95% quantile of the chi-square distribution χ2
nd.

5.5
Covariance Estimation in State Space Models
223
Other than the above model diagnostics, measures of goodness of ﬁt may
be considered. These include the mean square error (MSE), mean of squared
standardised residuals (MSSE) and mean absolute deviation (MAD), all being in
line with the respective measures discussed in Sect. 4.4 for univariate state space
models. These three measures are deﬁned as
MSE = 1
n
n

t=1
%
e2
1t, e2
2t, . . . , e2
dt
&⊤
,
MSSE = 1
n
n

t=1
%
e∗2
1t , e∗2
2t , . . . , e∗2
dt
&⊤
,
MAD = 1
n
n

t=1
[|e1t|, |e2t|, . . . , |edt|]⊤,
where it should be noted that, in contrast to the univariate case, the MSE, MSSE and
MAD are now d-dimensional vectors. For a good model ﬁt MSE and MAD should
be close to the zero vector [0, 0, . . ., 0]⊤, while the MSSE should be close to the
unit vector [1, 1, . . ., 1]⊤.
5.5
Covariance Estimation in State Space Models
5.5.1
Variance Estimation
The problem of estimating  and Zt in the state space model (5.1a)–(5.1b) is known
as covariance estimation (of state space models). As discussed above, one solution
is to use the EM algorithm to estimate  and Zt = Z, if Zt = Z is assumed
to be time-invariant. In this section and in the next section we will assume that
Zt is known or is speciﬁed using discount factors and we discuss inference for .
Unfortunately,a similar analysis as in the univariate case for the scaled observational
model (SOP), discussed in Sect. 4.3.3, for the state space model (5.1a)–(5.1b) is not
available. In the univariate case the variance of the observation innovation ϵt is σ 2
and the transition covariance matrix Zt = σ 2Z∗
t is scaled by σ 2, for some covariance
matrix Z∗
t .
In this section we consider a multivariate generalisation of the SOP model of
Sect. 4.3.3, whereby the observation and transition covariance matrices  and Zt
are known up to a scaling factor (or variance) σ 2, i.e.
 = σ 2V
and
Zt = σ 2Z∗
t ,
(5.9)
where V is a known d × d covariance matrix and Z∗
t is a known p × p covariance
matrix. As stated above Z∗
t may be speciﬁed using a discount factor. A ﬁrst
consideration for V is to be proportional to the identity matrix; more advanced
settings may include specifying V as a diagonal matrix or including in V some
common correlation structure for all its off-diagonal elements. Any of these settings

224
5
Multivariate State Space Models
may be done using historical data or considering a priori beliefs of the component
time series.
Consider the state space model (5.1a)–(5.1b), with  and Zt as in (5.9), where
the prior covariance matrix of β0 is also scaled by σ 2, i.e.
β0 ∼N( ˆβ0|0, σ 2P∗
0|0),
for some known covariance matrix P∗
0|0. Furthermore, we assume that the prior
distribution of 1/σ 2 = θ is a gamma distribution
θ = 1
σ 2 ∼G
n0
2 , d0
2
	
,
where n0 and d0 are known positive values. This model provides a ﬁrst generalisa-
tion of the univariate SOP model of Sect. 4.3.3, which is obtained from the above
model formulation for d = 1 and V = 1. The derivation of the posterior distribution
of θ and βt, given y1:t, follows that of the univariate SOP model in Sect. 4.3.3.
First of all we observe that conditionally on θ (or on σ 2), the prior distribution of
βt | θ, y1:t−1, the forecast distribution of yt | θ, y1:t−1 and the posterior distribution
of βt | θ, y1:t are given by the Kalman ﬁlter (Theorem 5.1) as
βt−1 | θ, y1:t−1 ∼N( ˆβt|t−1, σ 2P∗
t|t−1),
yt | θ, y1:t−1 ∼N( ˆyt|t−1, σ 2Q∗
t|t−1),
(5.10)
βt | θ, y1:t ∼N( ˆβt|t, σ 2P∗
t|t),
(5.11)
where ˆβt|t−1 = Ft ˆβt−1|t−1, P∗
t|t−1 = FtP∗
t−1|t−1F⊤
t , ˆyt|t−1 = x⊤
t ˆβt|t−1, Q∗
t|t−1 =
x⊤
t P∗
t|t−1xt + V, ˆβt|t = ˆβt|t−1 + Ktet, Kt = Pt|t−1xtQ−1
t|t−1 and et = yt −ˆyt|t−1.
Suppose that at time t −1, the posterior distribution of θ is
θ | y1:t−1 ∼G
nt−1
2
, dt−1
2
	
,
for some nt−1 and dt−1. This prior is combined with (5.10) to give the posterior
distribution of θ at t
p(θ | y1:t) ∝p(yt | θ, y1:t−1)p(θ | y1:t−1)
∝θd/2 exp

−1
2e⊤
t Q∗−1
t|t−1etθ
	
θnt−1/2−1 exp

−dt−1θ
2
	
= θ(nt−1+d)/2−1 exp

−1
2(e⊤
t Q∗−1
t|t−1et + dt−1)θ

,

5.5
Covariance Estimation in State Space Models
225
so that θ | y1:t is proportional to the gamma distribution
θ | y1:t ∼G
nt
2 , dt
2
	
,
where nt = nt−1 + d and dt = dt−1 + e⊤
t Q∗−1
t|t−1et.
Making use of the conditional on θ posterior distribution of βt (5.11), by
integrating out θ, we obtain the posterior distribution of βt as
p(βt | y1:t) =
"
Rp p(βt, θ | y1:t) dθ
=
"
Rp p(βt | θ, y1:t)p(θ | y1:t) dθ
∝
"
Rp θp/2 exp

−1
2(βt −ˆβt|t)⊤P∗−1
t|t (β −ˆβt|t)θ

×θnt/2−1 exp

−dtθ
2
	
dθ
=
"
Rp θ(nt+p)/2−1
× exp
(
−1
2
%
(βt −ˆβt|t)⊤P∗−1
t|t (βt −ˆβt|t) + dt
&
θ
)
dθ
∝
%
(βt −ˆβt|t)⊤P∗−1
t|t (βt −ˆβt|t) + dt
&−(nt+p)/2
.
which is obtained from the gamma integral (4.60).
Thus, the posterior distribution of βt at time t is proportional to the multivariate
Student t distribution
βt | y1:t ∼t(nt, ˆβt|t, Pt|t),
where Pt|t = StP∗
t|t and St = dt/nt.
Similarly we see that βt | y1:t−1 ∼t(nt−1, ˆβt|t−1, Pt|t−1) and yt | y1:t−1 ∼
t(nt−1, ˆyt|t−1, Qt|t−1), where Pt|t−1 = St−1P∗
t|t−1 and Qt|t−1 = St−1Q∗
t|t−1 =
x⊤
t Pt|t−1xt + St−1V. From these equations and the recursion of P∗
t|t given above we
obtain the recursion of Pt|t as
Pt|t = StP∗
t|t =
St
St−1
(Pt|t−1 −KtQt|t−1K⊤
t ).

226
5
Multivariate State Space Models
If we deﬁne rt = yt −x⊤
t ˆβt|t−1 and we substitute the Kalman ﬁlter recursion
ˆβt|t = ˆβt|t−1 + Ktet in rt, we observe that
rt = yt −x⊤
t ˆβt|t−1 −x⊤
t Ktet = (I −x⊤
t Kt)et = (I −x⊤
t Pt|t−1xtQ−1
t|t−1)et
= (Qt|t−1 −x⊤
t Pt|t−1xt)Q−1
t|t−1et = St−1VQ−1
t|t−1et.
Hence, by using St = dt/nt, the recursion of dt above can be written as
ntSt = nt−1St−1 + r⊤
t V−1et.
Below is a summary of the algorithm.
Multivariate Scaled Observational Precision I (MSOP-I)
In the state space model (5.1a)–(5.1b), with  and Zt as in (5.9), the following
apply:
1. Prior distributions at t = 0:
β0 ∼t(n0, ˆβ0|0, P0|0) and σ −2 ∼G(n0/2, n0S0/2);
2. Posterior distribution of βt−1 at time t −1:
βt−1 | y1:t−1 ∼t(nt−1, ˆβt−1|t−1, Pt−1|t−1);
3. Prior distribution of βt at time t:
βt | y1:t−1 ∼t(nt−1, ˆβt|t−1, Pt|t−1),
where ˆβt|t−1 = Ft ˆβt−1|t−1 and Pt|t−1 = FtPt−1|t−1F⊤
t + Zt;
4. Posterior distributions at time t:
βt | y1:t ∼t(nt, ˆβt|t, Pt|t) and σ −2 | y1:t ∼G(nt/2, ntSt/2), where
ˆβt|t = ˆβt|t−1 + Ktet,
Pt|t =
St
St−1

Pt|t−1 −KtQt|t−1K⊤
t

,
nt = nt−1 + d
and
ntSt = nt−1St−1 + r⊤
t V−1et,
ˆyt|t−1 = x⊤
t ˆβt|t−1,
et = yt −ˆyt|t−1,
rt = yt −x⊤
t ˆβt|t,
Kt = Pt|t−1xtQ−1
t|t−1
Qt|t−1 = x⊤
t Pt|t−1xt + St−1V.
In this application of the above model, apart from the speciﬁcation of the model
components xt, Ft and Zt discussed in Sect. 5.2, the covariance matrix V must
be speciﬁed. The obvious option is V = I, but this is limited as it postulates
that ϵit is independent of ϵjt, for i ̸= j and Var(ϵ1t) = Var(ϵ2t) = · · · =
Var(ϵdt) = σ 2, where ϵt = [ϵ1t, ϵ2t, . . . , ϵdt]⊤is the observation innovation
vector. In other words, given the states βt, the component time series yit and yjt
are conditionally independent and also they are homoscedastic (they have the same

5.5
Covariance Estimation in State Space Models
227
variance). This is usually not supported in practice, and although specifying V as a
diagonal matrix with different elements in its diagonal would resolve the problem of
homoscedasticity, the problem of independence of yit and yjt still remains. Usually,
we resort to multivariate modelling, speciﬁcally with the aim to estimate cross-
dependencies among the component time series of yt. One possibility to address
this point is to estimate V by employing the EM algorithm (described in Sect. 5.2).
For this to commence there is no need to consider scaling , Z and P0|0 by σ 2,
since  and Zt = Z (if the transition matrix is assumed to be time-invariant) can
be estimated directly by the EM algorithm; in this case all distributions involved
are Gaussian. However, the disadvantage is that the EM algorithm relies upon
smoothing estimation and hence real-time estimation and forecasting, in the sense of
Kalman ﬁlter, is not available. Given the generalisation of the SOP model discussed
above, it would be desirable to have a similar algorithm where we could scale the
matrices Zt and P0|0 by the observation matrix . If that were possible, then we
should be able to replace the gamma prior distribution of σ −2 with a matrix-variate
distribution appropriate to describe covariance matrices. This is discussed in the
next section.
5.5.2
Covariance Structure and Matrix-Variate Probability
Distributions
In the previous section, matrices Zt and P0|0 were scaled by the variance σ 2 in
order to facilitate closed form estimation within the Gaussian, gamma and Student
t family of distributions. If  is a d × d covariance matrix, this scaling is generally
not any more available, because Zt is a p × p covariance matrix, e.g.  and Zt
cannot be multiplied, if p ̸= d. Even in the special case of d = p, it is not
possible to set Zt = Z∗
t , because in this speciﬁcation Zt is not a symmetric
matrix. This problem has attracted considerable interest; early efforts include the
formulation of a new multivariate state space model, developed initially by Harvey
(1986) and Quintana and West (1987) and further discussed in Harvey (1989), West
and Harrison (1997) and in Triantafyllopoulos (2008b). This new state space model,
which generalises the SOP model of Sects. 4.3.3 and 5.5.1, allows for a particular
scaling making use of matrix-variate Gaussian distributions. The formulation of
Quintana and West (1987) proposes Bayesian estimation of  based on a Wishart
prior for the precision matrix (in an analogous way as in the SOP univariate model),
while Harvey (1986) discusses maximum likelihood estimation of . Other efforts
of covariance estimation of the multivariate state space model include the expo-
nentially weighted regression models of Triantafyllopoulos and Pikoulas (2002);
Triantafyllopoulos (2006b), covariance estimation for the general state space model
(5.1a)–(5.1b) Triantafyllopoulos and Harrison (2008); Triantafyllopoulos (2007b)
and covariance estimation for the multivariate local level model when xt = Ft = I
(Triantafyllopoulos, 2011a).

228
5
Multivariate State Space Models
In the sequel we describe the model formulation of Harvey (1986) and we discuss
Bayesian and maximum likelihood estimation for ; this discussion is based on
Triantafyllopoulos (2008a,b); related models are discussed in West and Harrison
(1997) and in Prado and West (2010).
Before we start we give a discussion on matrix-variate normal and inverse
Wishart distributions, necessary for the deﬁnition and development of the related
state space models. We have already seen the deﬁnition of a multivariate normal
distribution in Sect. 2.3.3 and used throughout in Chaps. 3 and 4. The matrix-variate
normal distribution is a generalisation of the multivariate normal distribution to a
random matrix. Let X1, . . . , Xd be p-dimensional column random vectors and form
the p × d random matrix X = [X1, X2, . . . , Xd]. The random matrix X is said to
follow the matrix-variate normal distribution if its density is
p(X) = c1 exp
(
−1
2trace[(X −M)⊤P−1(X −M)−1]
)
,
where c1 = (2π)−dp/2|P|−d/2||−p/2, M is a p × d mean matrix and P and 
are p × p and d × d covariance matrices respectively. In terms of notation we will
write X ∼N(M, P, ); sometimes P is referred to as left covariance matrix and 
as right covariance matrix. We observe that for d = 1 we obtain the multivariate
distribution of Sect. 2.3.3 and for p = d = 1 we obtain the univariate normal
distribution. A basic property of the above distribution is that if X ∼N(M, P, ),
then the random vector Y = vec(X) follows a multivariate normal distribution Y ∼
N[vec(M),  ⊗P], where vec(·) is the column stacking vector operation and ⊗
denotes the Kronecker product, both of which are discussed in Sect. 2.1. Based on
this property and the properties of the multivariate normal distribution it follows that
M is the mean matrix of X and that  ⊗P is the covariance matrix of Y.
Related to the above normal distribution is the inverse Wishart distribution. A
d×d random covariance matrix (symmetric and positive deﬁnite)  is said to follow
the inverse Wishart distribution with n degrees of freedom and scale covariance
matrix S, if its density is
p() = c2||−(n+d+1)/2 exp

−1
2trace(S−1)

,
where c2 = 2−nd/2d(n/2)−1|S|n/2 is the proportionality constant, n > d −1
and d(·) is the multivariate gamma function. By way of notation we write  ∼
IW(n, S). Since the density function p(X) integrates to 1, it follows that
"
>0
||−(n+d+1)/2 exp

−1
2trace(S−1)

d = 2nd/2d(n/2)|S|−n/2.
(5.12)

5.5
Covariance Estimation in State Space Models
229
The distribution of the inverse of  is the well-known Wishart distribution,
written as −1 ∼W(n, S−1), with density
p(−1) = c3||(n−d−1)/2 exp

−1
2trace(S−1)

,
where c3 = 2−nd/2d(n/2)−1||n/2 and n > d −1. The Wishart distribution can
be seen as a generalisation of the gamma distribution and the inverse Wishart as a
generalisation of the inverse gamma distribution; see Sect. 2.3.3 for a discussion of
the gamma and inverse gamma distributions. Finally, we give the deﬁnition of the
matrix-variate Student t distribution. A p × d random matrix X is said to follow the
matrix-variate t distribution with mean M, spread covariances matrices P and S and
degrees of freedom v, if its density is given by
p(X) = c4|I + (X −M)P−1(X −M)⊤S−1|−(n+p+d−1)/2,
where c4 = d[(n + p + d −1)/2]π−dp/2d[(n + d −1)/2]−1|P|−d/2|S|−p/2. By
way of notation we write X ∼t(n, M, P, S). We observe that for d = 1 the above
is reduced to the multivariate t distribution of Sect. 2.3.3. A detailed discussion of
matrix-variate distributions such as the normal, the t and the inverse Wishart can be
found in Gupta and Nagar (1999).
5.5.3
The Multivariate Scaled Observational Model
Returning to the state space models, suppose that yt is a d-dimensional observation
vector and consider the multivariate state space model
y⊤
t = x⊤
t βt + ϵ⊤
t
(observation model),
(5.13a)
βt = Ftβt−1 + ζ t
(transition model),
(5.13b)
where xt is a p-dimensional vector, βt is a p × d state matrix and Ft is a p ×
p transition matrix. The d-dimensional observation innovation ϵt and the p × d
state innovation ζ t are assumed independent for any t, ϵt is independent of ϵs, ζ t
is independent of ζ s, for any t ̸= s and ϵt follows a d-dimensional multivariate
Gaussian distribution and ζ t follows a p × d matrix Gaussian distribution, written
ϵt ∼N(0, )
and
ζ t ∼N(0, Z∗
t , ),
so that the vector vec(ζ t) follows the pd-dimensional Gaussian distribution
vec(ζ t) ∼N(0, Zt) ≡N(0,  ⊗Z∗
t ).
The state space model (5.13a)–(5.13b) is known as seemingly unrelated equa-
tions model (Harvey, 1986) or common components model (Harvey, 1986), but here

230
5
Multivariate State Space Models
we name it as multivariate scaled observational precision model (MSOP), because
the model is scaled by the observation precision covariance matrix −1 and for
d = 1 (univariate case) the model is reduced to the univariate SOP model discussed
in Section 4.3.3.
For the state space model (5.13a)–(5.13b) the following prior speciﬁcation is
adopted
β0 |  ∼N( ˆβ0|0, P0|0, )
and
 ∼IW(n0, n0S0),
(5.14)
for some known p×d mean matrix ˆβ0|0, a p×p left covariance matrix P0|0, a d ×d
scale covariance matrix n0S0 and degrees of freedom n0 > d −1. The following
theorem provides inference for the MSOP model (5.13a)–(5.13b).
Theorem 5.4 In the state space model (5.13a)–(5.13b), with the priors (5.14), for
any t = 1, 2, . . . , n the following apply.
1. Conditionally on , the one-step ahead forecast distribution of yt and the
posterior distribution of βt are
yt | , y1:t−1 ∼N( ˆyt|t−1, qt|t−1)
and
βt | , y1:t ∼N( ˆβt|t, Pt|t, ),
where ˆyt|t−1 = ˆβ
⊤
t|t−1xt, qt|t−1 = x⊤
t Pt|t−1xt + 1, ˆβt|t = ˆβt|t−1 + Kte⊤
t and
Pt|t = Pt|t−1−qt|t−1KtK⊤
t , with ˆβt|t−1 = Ft ˆβt−1|t−1, Pt|t−1 = FtPt−1|t−1F⊤
t +
Zt, Kt = q−1
t|t−1Pt|t−1xt and et = yt −ˆyt|t−1.
2. The posterior distribution of  is  | y1:t ∼IW(nt, ntSt), with nt = nt−1 + 1
and ntSt = nt−1St−1 + rte⊤
t , where rt = yt −ˆβ
⊤
t|txt.
3. Unconditionally of , the one-step forecast distribution of yt and the posterior
distribution of βt are yt | y1:t−1 ∼t(nt−1 −d + 1, ˆyt|t−1, qt|t−1nt−1St) and
βt | y1:t ∼t(nt −d + 1, ˆβt|t, Pt|t, ntSt).
Proof First we prove (1). Suppose that at time t −1 the posterior distribution of
βt−1 is βt−1 | , y1:t−1 ∼N( ˆβt−1|t−1, Pt−1|t−1, ), for some known ˆβt−1|t−1 and
Pt−1|t−1. This combined to the transition and observation equations (5.13a)–(5.13b)
give the distributions βt | , y1:t−1 ∼N( ˆβt|t−1, Pt|t−1, ) and yt | , y1:t−1 ∼
N( ˆyt|t−1, qt|t−1), with ˆβt|t−1, Pt|t−1, ˆyt|t−1 and qt|t−1 as stated in the theorem.
Given , model (5.13a)–(5.13b) can be written as a multivariate state space
model (5.1a)–(5.1b). Indeed, apply the vec operation
yt = vec(y⊤
t ) = (I ⊗x⊤
t )vec(βt) + ϵt,
ϵt ∼N(0, ),
with transition
vec(βt) = (I ⊗Ft)vec(βt−1) + vec(ζ t),
vec(ζ t) ∼N(0,  ⊗Zt),

5.5
Covariance Estimation in State Space Models
231
which is in the form of (5.1a)–(5.1b). From the prior distribution vec(β0) ∼
N(0,  ⊗P0|0) and the Kalman ﬁlter (Theorem 5.1) we have that the posterior
distribution of vec(βt) is vec(βt) | , y1:t ∼N[vec( ˆβt|t),  ⊗Pt|t], so that
βt | y1:t ∼N( ˆβt|t, Pt|t, ), with ˆβt|t and Pt|t as stated in the theorem.
Proceeding now to (2) by applying the Bayes theorem we have
p( | y1:t) ∝p(yt | , y1:t−1)p( | y1:t−1)
∝||−1/2 exp
(
−
1
2qt|t−1
%
(yt −ˆyt|t−1)⊤−1(yt −ˆyt|t−1)
&)
×||−(nt−1+d+1)/2 exp

−1
2trace(nt−1St−1−1)

∝||−(nt−1+1+d+1)/2 exp
(
−1
2trace[(q−1
t|t−1ete⊤
t + nt−1St−1)−1]
)
= ||−(nt−1+1+d+1)/2 exp
(
−1
2trace[(rte⊤
t + nt−1St−1)−1]
)
,
since
rt = yt −ˆβ
⊤
t|t−1xt −etK⊤
t xt = (1 −K⊤
t xt)et =
et
qt|t−1
.
Hence  | y1:t follows an inverse Wishart distribution,  | y1:t ∼IW(nt, ntSt),
with nt = nt−1 + 1 and ntSt = nt−1St−1 + rte⊤
t .
By combining the results in (1) and (2) we can integrate out  in order to
ﬁnd the posterior and forecast distributions unconditionally of . For the posterior
distribution of βt we have
p(βt | y1:t) =
"
>0
p(βt,  | y1:t) d
=
"
>0
p(βt | , y1:t)p( | y1:t) d
∝
"
>0
||−p/2 exp
(
−1
2trace[(βt −ˆβt)P−1
t|t (βt −ˆβt)⊤−1]
)
×||−(nt+d+1)/2 exp

−1
2trace(ntSt−1)

d
=
"
>0
||−(nt+p+d+1)/2
× exp
(
−1
2trace[(βt −ˆβt)P−1
t|t (βt −ˆβt)⊤+ ntSt]−1]
)
d
∝|(βt −ˆβt)P−1
t|t (βt −ˆβt)⊤+ ntSt|−(nt+p)/2,
(5.15)

232
5
Multivariate State Space Models
which is computed by (5.12), if we set n = nt + p and S = (βt −ˆβt)P−1
t|t (βt −
ˆβt)⊤+ ntSt. We can see that (5.15) is proportional to
p(βt | y1:t) ∝|I + n−1
t
(βt −ˆβt)P−1
t|t (βt −ˆβt)⊤S−1
t
|−(nt−d+1+p+d−1)/2,
which is proportional to a matrix Student t density, hence βt | y1:t ∼t(nt −
d + 1, ˆβt|t, Pt|t, ntSt), as required. The proof of the forecast distribution of yt
unconditional of  is very similar to that of the posterior distribution of βt, given
above, and it is omitted.
⊓⊔
Some comments are in order.
•
For d = 1 (yt is scalar time series and  = σ 2 is reduced to a scalar variance)
Theorem 5.4 provides similar results to those of Sect. 4.3.3 for the univariate SOP
model; the differences being on the parameterisation of the gamma and inverse
gamma distributions.
•
From the inverse Wishart posterior distribution of  we can extract estimators
such as the posterior mean or the posterior mode, i.e.
E( | y1:t) =
ntSt
nt −d −1
(nt > d +1)
and
mode( | y1:t) =
ntSt
nt + d + 1.
•
From the updating of St it follows that for large t the posterior mean of  is
approximately
E( | y1:t) ≈1
t
t
i=1
rie⊤
i ,
or in words that the estimator of  is the average of {r1e⊤
1 , . . . , rte⊤
t }.
•
Given information y1:n = {y1, y2, . . . , yn}, for some positive integer n, the
maximum likelihood estimator of  is
ˆ = 1
n
n

t=1
rte⊤
t .
Indeed, the log likelihood function of  is
ℓ(; y1:n) = log p(y1, y2, . . . , yn | )
= log
n
-
t=1
p(yt | , y1:t−1)

5.5
Covariance Estimation in State Space Models
233
= −dn
2 log(2π) −d
2
n

t=1
log qt|t−1 −n
2 log ||
−1
2
n

t=1
q−1
t|t−1trace(ete⊤
t −1).
From Eqs. (2.9) and (2.14) we have
∂ℓ(; y1:n)
∂
= −n−1 + n
2diag(−1)
−1
2
n

t=1
q−1
t|t−1
%
−2−1ete⊤
t −1 + diag(−1ete⊤
t −1)
&
.
Equating this to zero, we obtain the matrix equation
n ˆ
−1 =
n

t=1
q−1
t|t−1 ˆ
−1ete⊤
t ˆ
−1,
which solution is
ˆ = 1
n
n

t=1
q−1
t|t−1ete⊤
t = 1
n
n

t=1
rte⊤
t ,
with rt as deﬁned in Theorem 5.4 above.
It can be shown that the second partial derivative of ℓ(; y1:n) with respect to
 is a negative deﬁnite matrix, hence ˆ maximises the log-likelihood function;
for a proof of this result the reader is referred to Triantafyllopoulos (2008b).
Below a summary of the MSOP algorithm is given.
Multivariate Scaled Observation Model II (MSOP-II)
In the state space model (5.13a)–(5.13b), for each t
= 1, 2, . . . , n the
following apply:
1. Prior distributions at t = 0:  ∼IW(n0, n0S0) and β0 ∼t(n0 −d +
1, ˆβ0|0, P0|0, n0S0), for some n0, S0, ˆβ0|0 and P0|0.
2. The one-step ahead distribution of yt is yt | y1:t−1 ∼t(nt−1 −d +
1, ˆyt|t−1, nt−1qt|t−1St−1) and the posterior distribution of βt is βt | y1:t ∼
t(nt −d + 1, ˆβt|t, Pt|t, ntSt),
where ˆyt|t−1 = ˆβ
⊤
t|t−1xt, qt|t−1 = x⊤
t Pt|t−1xt + 1, ˆβt|t = ˆβt|t−1 + Kte⊤
t
(continued)

234
5
Multivariate State Space Models
and Pt|t = Pt|t−1 −qt|t−1KtK⊤
t , with ˆβt|t−1 = Ft ˆβt−1|t−1, Pt|t−1 =
FtPt−1|t−1F⊤
t + Zt, Kt = q−1
t|t−1Pt|t−1xt and et = yt −ˆyt|t−1.
3. The posterior distribution of  is  | y1:t ∼IW(nt, ntSt), with nt =
nt−1 + 1 and ntSt = nt−1St−1 + rte⊤
t , where rt = yt −ˆβ
⊤
t|txt.
5.6
Forecasting Pollution Time Series
In this section we consider a larger data set than that of Example 4.7, which
considers values of the pollutant nitric oxide NO over a course of 1 year. Here we
look at three pollutants, ozone (O3), nitrogen dioxide (NO2) and nitric oxide (NO)
all measured in milligrams per square metre. The data are daily observations for 2
years covering the period 1 January 2001 to 31 December 2002 (732 observations in
total). We denote with y1t the observation of O3 at time t, with y2t the observation of
NO2 at time t, with y3t the value of NO at time t and we form the observation vector
yt = [y1t, y2t, y3t]⊤. The data, obtained by one of 16 pollution monitoring stations
in the city of Athens, is plotted in Fig. 5.1; missing data were imputed by regression
and moving average methods and are indicated in Fig. 5.1 by the straight lines. In
addition to the observations {yt}, the measurements of the covariates: temperature
(in ◦C), humidity (%) and wind speed (in metres per second) are available; these
covariates are denoted by x1t, x2t, x3t, respectively. The aim of this example is to
propose a model for the vector time series yt, which will be capable of forecasting
future values of yt as well as estimating the correlations of ozone, nitrogen dioxide
and nitric oxide over time.
By comparing this data set with that of Example 4.7 we see that the NO
observations considered in Chap. 4 covered only a year, hence it was not possible
to explore the possibility of the values being affected by annual seasonality. Indeed,
it is clear from Fig. 5.1 that the observations of yit (i = 1, 2, 3) exhibit annual
seasonality, which is most notable for the ozone. Therefore, a plausible state space
model should include three time-varying covariates (temperature, humidity and
wind speed), linear trend and seasonal components. Thus, the proposed model
for yt combines time-varying regression (see e.g. Sect. 4.1.5) and trend-seasonal
components (see e.g. Sect. 4.1.4). Below we discuss the model in more detail.
Let βt be a time-varying 15×3 unobserved state matrix for some positive integer
d which drives the dynamics of yt in the following state space model
yt = R1t + R2t + R3t + Tt + st + ϵt = β⊤
t xt + ϵt,
(5.16)
so that yt comprises three dynamic regression components Rit = β⊤
it xit, a trend
component Tt = β⊤
4t[1, 0]⊤, a seasonal component st = β⊤
5t[1, 0, 1, 0, 1, 0, 1, 0,

5.6
Forecasting Pollution Time Series
235
40
60
80 100
140
O3
0
20
40
60
80
100
NO2
5
10
15
20
25
2001.0
2001.5
2002.0
2002.5
2003.0
NO
Time
Time series plot of 3 pollutants
Fig. 5.1 Daily observations of ozone O3, dyadic oxide NO2 and monoxide NO over a period of 2
years
1, 0]⊤and a random innovation term ϵt, where β⊤
t = [β⊤
1t, β⊤
2t, β⊤
3t, β⊤
4t, β⊤
5t]. The
model (5.16) can be written as
y⊤
t = x⊤
t βt + ϵ⊤
t
and
βt = Fβt−1 + ζ t,
(5.17)
with design vector xt and the transition matrix F
xt =
⎡
⎢⎣x⊤
1t, x⊤
2t, x⊤
3t



covariates
, 1, 0

trend
, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0



seasonal
⎤
⎥⎦
⊤
,

236
5
Multivariate State Space Models
F =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
I 0 0
0
0
0
0
0 J 0
0
0
0
0
0 0 F1 0
0
0
0
0 0 0 F2 0
0
0
0 0 0
0 F3 0
0
0 0 0
0
0 F4 0
0 0 0
0
0
0 F5
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
where F is a block diagonal matrix with components I for the identity matrix, J for
the transition matrix of the linear growth model, responsible for the trend variation,
and Fi (i = 1, 2, 3, 4, 5) for the harmonic component, responsible for the seasonal
variation, i.e.
J =

1 1
0 1

and
Fi =

cos(iω) sin(iω)
−sin(iω) cos(iω)

.
The above state space model is a multivariate time-varying regression model with
trend-seasonal components, for the seasonal variation of which, a reduced form state
space representation of the full Fourier expansion is used. For this data the cycle
is c = 365 (daily data with annual seasonality) with frequency 2π/c = ω; here
for computational efﬁciency, we use only the ﬁrst 5 harmonics out of a total of
(c −1)/2 = 182, hence the reduced form.
The distributions of ϵt and ζ t are multivariate and matrix-variate Gaussian, i.e.
ϵt ∼N(0, ) and ζ t ∼N(0, Zt, ), where  is a 3 × 3 observation covariance
matrix subject to estimation and the 15 × 15 transition covariance matrix Zt is
speciﬁed by using a discount factor δ. The prior distribution of β0 is also a matrix-
variate Gaussian distribution, i.e. β0 ∼N( ˆβ0|0, P0|0, ), for some P0|0. The prior
distribution of  is an inverse Wishart distribution with n0 degrees of freedom and
scale matrix n0S0, written as  ∼IW(n0, n0S0).
In R we can specify the above model components by using the commands
> # read data
> data <- read.table("dataPollution.txt")
> # use the first 732 time points and the first 3 variables
> y <- data[1:732,4:6]
> # create design vector
> h<-5
> des <- matrix(0, 2922, 3+2+2*h)
> des[,1] <- y[,1]
> des[,2] <- y[,2]
> des[,3] <- y[,3]
> des[,seq(4,2*h+4,2)] <- 1
> x1 <- list(); for(i in 1:732) x1 <- updt(x1, des[i,])
> # define transition matrix
> w <- 2*pi/365

5.6
Forecasting Pollution Time Series
237
> BD <- blockDiagMat(diag(3),Jtrend(1))
>
for(k in 1:h){
>
BD <- blockDiagMat(BD, Jseasonal(k,w))
>
}
We have applied the MSOP-II algorithm described above, with values of the
hyperparameters: δ = 0.98, ˆβ0|0 = 0, P0|0 = 1000I, n0 = 10, S0 = 0.1I. Some
uncertainty about the speciﬁcation of these parameters may arise; the following
comments may be useful for general application. The reliance of the discount factor
is suggested because Zt is a 15 × 15 covariance matrix and estimating it by the EM
algorithm could be very inefﬁcient; in addition to that it is desirable that Zt is time-
varying (as is the case when we specify it with a discount factor) because this allows
for the variance in the evolution of the states to change over time. Overall we achieve
to specify a 15 × 15 covariance matrix just by specifying a scalar, the discount
factor δ. Several values of this discount factor may be considered and tuned using
measures of goodness of ﬁt (e.g. MSE, MSSE, MAD or the likelihood function).
Typically, values of δ close, but less than, one should be considered and here we have
found that δ = 0.98 works well. For more details on the speciﬁcation of transition
covariance matrices using discount factors see the discussion in Sect. 4.3.2 and West
and Harrison (1997). The speciﬁcation of ˆβ0|0 = 0 is motivated by convenience,
since ˆβ0|0 is a 15 × 3 matrix. As we have seen in Sect. 4.5 for univariate state
space models, the speciﬁcation of ˆβ0|0 does not play a crucial role in estimation
and forecasting; instead the model is adaptive and very quickly corrects its ability to
forecast accurately, as evidenced by Table 4.2 of Sect. 4.5. Following the discussion
in Sect. 4.5 and throughout the book, a weakly informative prior covariance matrix
P0|0 = 1000I is chosen, reﬂecting high uncertainty around the zero mean matrix
of β0. The values of the degrees of freedom n0 and the scale matrix S0 are picked
so that n0S0 = I and n0 (the degrees of freedom) must be larger than p −1 = 2
for the inverse Wishart distribution to exist; here we have picked n0 = 10 and
S0 = 10−1I. This implies that a prior point estimate of  (the prior mode of ) is
n0S0/(n0 + p + 1) = 10−1I/14 ≈0.7I.
After the above prior settings are in place, we apply the MSOP-II algorithm to
the data. The model is ﬁtted in R using the command
> fit <- bts.msop(y, x1, F0=BD, beta0=matrix(0, 15, 3),
+ n0=10,S0=0.1*diag(3), delta=0.99)
The standardised residuals (not shown here) ﬂuctuate around zero, although those
for NO indicate some structure on the plot, which suggests they the residuals for
y3t (NO) are not independent. Comparing them with the credible limits ±1.96
of the N(0, 1) we observe that there are 6.84% outliers in O3, 6.55% outliers in
NO2 and 4.56% in NO; this suggests that O3 and NO2 slightly underestimate the
observation variance, while NO overestimates the respective variance (we would
expect to obtain 5% outliers for a perfect ﬁt). This can be further explored by looking

238
5
Multivariate State Space Models
0
50
100
150
O3
0
20 40 60 80
NO2
0
2
4
6
8
2001.0
2001.5
2002.0
2002.5
2003.0
NO
Time
Estimated variance
Fig. 5.2 Estimated variances of O3, NO2 and NO
at the values of the MSE, MMSE and MAD, which are
MSE =
⎡
⎣
243.233
96.223
7.819
⎤
⎦,
MSSE =
⎡
⎣
1.637
1.895
1.340
⎤
⎦,
MAD =
⎡
⎣
11.651
6.959
1.574
⎤
⎦.
Figure 5.2 shows the posterior modes of the observation variances σii, where
 = (σij )i,j=1,2,3. We observe that after 3 months the variance estimates seem to
stabilise to constant values, with O3 having the largest variation and NO having the
smallest variation. The R commands used to extract this plot are given below:
# plot of estimated variances
> var1 <- var2 <- var3 <- rep(0,732)
> for(t in 1:732){
+ var1[t] <- fit$ObsVar[[t]][1,1]
+ var2[t] <- fit$ObsVar[[t]][2,2]
+ var3[t] <- fit$ObsVar[[t]][3,3]
+ }
> x <- cbind(var1,var2,var3)
> xts <- ts(x, start=c(2001,0), frequency=365,
+ names=c("O3","NO2","NO"))
> plot.ts(xts, main=expression("Estimated variance"))
The cross-correlation of the three time series (O3, NO2 and NO) may be explored
in the ﬁrst place by estimating their correlation matrix, which is
⎡
⎣
1
−0.343 −0.406
−0.343
1
0.638
−0.406 0.638
1
⎤
⎦

5.6
Forecasting Pollution Time Series
239
Estimated cross-correlation
Time
Correlation
2001.0
2001.5
2002.0
2002.5
2003.0
-1.0
-0.5
0.0
0.5
Correlation of O3 and NO2
Correlation of O3 and NO
Correlation of NO2 and NO
Fig. 5.3 Estimated cross-correlations of O3, NO2 and NO
This suggests that O3 and NO2 and O3 and NO are negatively correlated, while NO2
and NO are positively correlated. Of course such correlation estimates are based on
the sample correlations, which fail to take into account the dynamics of the data
and in particular the validity of sample statistics is based both on the availability
of large amounts of data and on the assumption that this data is stationary. Here,
with the availability of 732 observations and with the apparent non-stationarity of
the time series data, these assumptions seem to be violated. Thus, one should not
rely on sample statistics in order to estimate covariance and correlation matrices
in this case. In addition to this the inferred correlations of the MSOP-II algorithm
offer the signiﬁcant advantage of on-line correlation estimates. Figure 5.3 shows the
estimated correlations of the observation matrix . We observe that the correlations
of NO2 and NO with O3 are negative and very close to each other, while the
correlation of NO2 with NO is close to 0.6 mark. These results somehow agree
with the sample cross-correlations, but they are more valid as they explicitly make
use of the dynamic state space model. The following R code was used to produce
Fig. 5.3:
> # plot of cross-correlations
> cor1 <- cor2 <- cor3 <- rep(0,732)
> for(t in 1:732){
+ cor1[t] <- fit$ObsVar[[t]][1,2] /
+
sqrt( fit$ObsVar[[t]][1,1] * fit$ObsVar[[t]][2,2] )
+ cor2[t] <- fit$ObsVar[[t]][1,3] /
+
sqrt( fit$ObsVar[[t]][1,1] * fit$ObsVar[[t]][3,3] )
+ cor3[t] <- fit$ObsVar[[t]][2,3] /
+
sqrt( fit$ObsVar[[t]][2,2] * fit$ObsVar[[t]][3,3] )
+ }

240
5
Multivariate State Space Models
> x <- cbind(cor1,cor2,cor3)
> xts <- ts(x, start=c(2001,0), frequency=365)
> ts.plot(xts[,1],xts[,2],xts[,3],lty=1:3,
+ main=expression("Estimated cross-correlation"),
+ ylab="Correlation")
> smartlegend( x="right", y= "bottom", inset=0,
+ legend =c(expression("Correlation of O3 and NO2"),
+ expression("Correlation of O3 and NO"),
+ expression("Correlation of NO2 and NO")),
lty=c(1,2,3) )
5.7
Markov Chain Monte Carlo Inference
5.7.1
Bayesian Inference and the Gibbs Sampler
In this section we introduce the ideas of Markov chain Monte Carlo (MCMC)
estimation for a general purpose probability model and Sects. 5.7.2 and 5.7.3 discuss
MCMC procedures, speciﬁcally tailored to Gaussian state space models.
In most statistical problems we need to estimate probabilities or expectations of
some target distribution, say p(x), of some random vector X, deﬁned in Rk, for
integer k ≥1. Such probabilities and expectations may be expressed as integrals
(assuming that X is continuous for simplicity, but replacing Riemann integrals by
sums or Lebesgue integrals), e.g. the expectation of X is E(X) =
*
Rk xp(x) dx or
the probability that X belongs to some set A ⊂Rk is P(X ∈A) =
*
A p(x) dx.
The computation of such integrals is usually difﬁcult because typically these will be
high dimensional integrals and the distribution p(·) will be complicated. Additional
complications in the computation may arise if A is complex. For all those reasons
the evaluation of the above integrals will not be available in closed form. However,
if we are able to draw a sample from p(·), say x(1), x(2), . . . , x(N), then we can
approximate E(X) by N−1 N
i=1 x(i), which in essence is known as Monte Carlo
estimation. In words, instead of evaluating the integrals, we approximate them by
sample statistics (mean, variance or proportions) of simulated vectors, randomly
sampled from the target distribution. From the law of large numbers we know that
as N →∞, N−1 N
i=1 x(i) will converge in probability to the true value of E(X).
Now consider the probability model whereby observations y are generated by
a probability distribution p(y | θ), conditional on some parameter vector θ. This
distribution is the likelihood function of θ, based on y. Now suppose that we place
a prior on θ, p(θ), and we make use of the Bayes theorem to obtain the posterior
distribution of θ, i.e.
p(θ | y) ∝p(y | θ)p(θ)
(5.18)
(see also the relevant discussion of Sect. 2.4.3). If we can draw a random sample
from p(θ | y), then we can use Monte Carlo methods to estimate expectations
or probabilities of the posterior distribution of θ. Procedures to simulate a random

5.7
Markov Chain Monte Carlo Inference
241
sample from a given distribution are available, but they are limited to relatively
simple forms of distributions. Such forms include most known distributions, some
of which are mentioned in Sects. 2.3.2 and 2.3.3, with simulation procedures
being based upon simulation of the uniform distribution. For more details on these
procedures the reader is referred to Gamerman and Lopes (2006, Chapter 1). For
complex posterior distributions, such as those arising from sequential application
of the Bayes theorem, the above simulation procedures are not suitable. Moreover,
Bayes rule (5.18) suggests that the posterior distribution p(θ | y) is only available
up to a proportionality constant c = 1/p(y), which computation involves the
integral p(y) =
*
Rk p(y | θ)p(θ) dθ. The computation of this integral is usually
difﬁcult or not possible, except in very special cases. Hence drawing a sample from
p(θ | y) may not be possible.
The principle idea of Markov chain Monte Carlo (MCMC) estimation is to
propose sampling from a Markov chain (see deﬁnition below), which converges
to the posterior p(θ | y); then assuming convergence, the random sample we draw
from the chain will also be drawn from p(θ | y). Thus, the task is to construct
an appropriate Markov chain so that (a) it converges to the posterior distribution
p(θ | y) and (b) a random sample can be drawn from the chain. Below we provide a
brief discussion of Markov chains, necessary to the development of this book. For a
detailed treatment relevant to MCMC methods the reader is referred to Gamerman
and Lopes (2006, Chapter 4) and to references therein.
A stochastic process is deﬁned as a collection of random vectors over time; if
the random vectors are collected in discrete-time we speak of a sequence of random
vectors and this is the situation we will be concerned with in this book; for a detailed
treatise of stochastic processes the reader is referred to Doob (1955). For example
the time series (yt, t ≥1) discussed throughout the book as well as the state process
(βt, t ≥0) are examples of stochastic processes. For the purposes of the Markov
chains discussed in this section, each member of the sequence (a random vector) is
denoted by θ(i), i = 0, 1, . . .. Each vector θ(i) is known as a state and the vector
space of the values of θ(i) is known as the state space and is denoted by S; the
state space should not be confused with the state space model, but below we draw
some similarities. This space may be discrete S = {1, 2, 3, 4, . . .} or continuous
S = Rk. In what follows we will assume that S is discrete, but similar results
apply for continuous state spaces (Gamerman & Lopes, 2006, Chapter 4). A Markov
chain is a stochastic process so that, given the present, the future and the past are
conditionally independent. This property can be written as
P(θ(i+1) ∈Ai+1 | θ(i) = x, θ(i−1) ∈Ai−1, . . . , θ(0) ∈A0) =
P(θ(i+1) ∈Ai+1 | θ(i) = x),
for a particular value x of θ(i), where Ai is a subset of the state space. This indicates
that the event {θ(i+1) ∈Ai+1} depends only on the state of the Markov chain at
time i (observed value θ(i) = x) and not on past values of θ(i−1), θ(i−2), . . . , θ(0).
A simple example of a Markov chain is the random walk θ(i+1) = θ(i) + ϵi, where

242
5
Multivariate State Space Models
ϵi is a white noise process. This is a Markov chain as, given θ(i), θ(i+1) and θ(i−s)
are conditionally independent, for 0 ≤s ≤i. A real-life example of a Markov
chain is the price of an asset traded in the stock market: for a given a share price of
today, the price of tomorrow will not depend on the price the share had yesterday
or the day before. Many more examples of Markov chains are given in Gamerman
and Lopes (2006, Chapter 4). The state vectors β1, β2, . . . of the transition equation
(5.1b) deﬁne a Markov chain, since given the present vector βt, the past βt−1 is
independent of the future βt+1. The same property can be applied to the entire state
space model, including the observations in Eq. (5.1a). This provides a justiﬁcation
of the name of the state space model.
Associated with a Markov chain is the transition matrix, which is deﬁned as the
matrix whose rs-th element is the probability prs = P(θ(i+1) = s | θ(i) = r),
which is the probability of the chain moving from state r (at time i) to state s (at
time i +1). Usually this probability will depend on i, but in this discussion the chain
is assumed to be homogeneous, in which case prs does not depend on i, but only
on r and s; the transition matrix is denoted by P. One of the main utilities of the
transition matrix is that of convergence of the chain. Under certain weak conditions
(see e.g. Gamerman and Lopes (2006, Chapter 4)), as i →∞the chain reaches its
stationary distribution π(·) deﬁned as

r∈S
π(r)prs = π(s),
for s ∈S.
From this equation we can see that πP = π, which suggests that once the chain has
marginal distribution π at time n, then π is the marginal distribution of the chain for
any time larger than n, hence the convergence. This has important implications for
MCMC, because if we know that the chain converges to the posterior distribution
p(θ | y), then when the chain has reached its stationary distribution π, then we
have π(θ) ≡p(θ | y). Thus, if we simulate from a Markov chain after it reaches
its marginal stationary distribution we have a simulation from the target distribution
p(θ | y). The task then reduces to the construction of a suitable Markov chain.
We close this introductory section by discussing the most popular class of Markov
chains known as Gibbs sampling. This will be used in subsequent Sects. 5.7.2
and 5.7.3 to construct Markov chains for state space models.
The Gibbs sampling MCMC scheme originates from the Gibbs distribution in the
context of mechanical statistics, discussed in detail in Geman and Geman (1984).
Below we give the Gibbs sampling algorithm; for more details and examples the
reader is referred to Gamerman and Lopes (2006, Chapter 5) and Robert (2007)
and to references therein. Suppose that θ = [θ1, θ2, . . . , θk]⊤is a k-dimensional
parameter vector (typically it will be associated to the multi-dimensional posterior
distribution p(θ | y) derived by (5.18)).

5.7
Markov Chain Monte Carlo Inference
243
Gibbs Sampler
1. Initialise the iteration counter i = 0, with
θ(0) = [θ(0)
1 , θ(0)
2 , . . . , θ(0)
k ]⊤.
2. Obtain a set of vectors θ(i)
= [θ(i)
1 , θ(i)
2 , . . . , θ(i)
k ]⊤from θ(i−1) by
sampling one value θ(i)
j
(j = 1, 2, . . . , k) according to
θ(i)
1
∼p(θ1 | θ(i−1)
2
, θ(i−1)
3
, . . . , θ(i−1)
k−1 , θ(i−1)
k
)
θ(i)
2
∼p(θ2 | θ(i)
1 , θ(i−1)
3
, . . . , θ(i−1)
k−1 , θ(i−1)
k
)
...
θ(i)
k
∼p(θk | θ(i)
1 , θ(i)
2 , θ(i)
3 , . . . , θ(i)
k−1)
3. Set the counter i = i + 1 and go to step (2) until convergence.
The algorithm assumes that we can sample from the distributions p(θj | θ−j),
where θ−j is the k −1-dimensional vector including the elements of θ except θj,
for j = 1, 2, . . . , k. We note that the simulated vector θ(i) is a draw from a Markov
chain, because by the Gibbs sampler above θ(i) depends only on θ(i−1) and not
on past iterations θ(i−2), θ(i−3), . . . , θ(0). When convergence is reached we obtain
samples from the stationary distribution π of the chain. If the target distribution
we want to sample from is the posterior p(θ | y), then we need to condition the
distributions in the Gibbs sampler to y, hence at each iteration i we shall sample
θ(i)
j
from the conditional distribution p(θj | θ(i)
1 , . . . , θ(i)
j−1, θ(i−1)
j+1 , . . . , θ(i−1)
k
, y).
It is worthwhile to note that we do not need to know the stationary distribution
π(·) of the chain; instead, convergence is assessed by conducting informal and
formal tests, based only on the simulated values θ(i). It is a usual practice to run
the chain for a considerable length of time to train on the data; this length is known
as burn-in and a typical value is 1000 iterations, but this value will be problem-
speciﬁc. After the burn-in period it is a usual practice to run the chain for as long
as is needed and convergence diagnostics can conﬁrm that the chain has converged.
If this is the case we can plot summaries of the simulations, e.g. mode, histograms,
or quantiles of θ(i). Informal convergence diagnostics can be based on generating
multiple chains and assess whether simulations from those look similar. Perhaps
the simplest way to assess convergence is to judge whether θ(i) constitute a sample
from a stationary distribution (the distribution π(·) of the chain). Hence graphical
methods of assessing this include the plot of θ(i) against i, known as the trace plot,
and the plot of the autocorrelation function (ACF) against lags 1, 2, 3, . . ., known
as the correlogram. If the chain has reached convergence, we would expect that

244
5
Multivariate State Space Models
the trace plot indicates no structure, i.e. the mean and the variance of θ(i) not to
depend on i; likewise all values of the ACF should lie inside the ±2/√N −tB
credible intervals, where N is the total number of iterations and tB is the burn-in
length. The trace plot checks whether blocks or shifted segments of the simulated
vectors θ(i) appear to have the same distribution (at least having the same mean
and variance), while the correlogram checks whether the simulated vectors θ(i),
θ(j) are uncorrelated, for i ̸= j. More details on informal and formal convergence
diagnostics are discussed in Gamerman and Lopes (2006, §5.4).
5.7.2
The Forward Filtering Backward Sampling Scheme
Coming back to the context of multivariate state space models, consider model
(5.1a)–(5.1b), where the covariance matrices  and Zt = Z (time-invariant) are
unknown and subject to estimation. As before the aim is to estimate the state vectors
βt and these covariance matrices, provided observed data y1:n = {y1, . . . , yn}. As
we have seen earlier, this task may be performed by using the EM algorithm, as
discussed in Sect. 5.2, but here we are interested in performing Bayesian inference
using the Gibbs sampler. In this section we consider that  and Z are known and
hence interest is solely focused on the estimation of βt, given y1:n. The general case,
which considers estimation of  and Z is discussed in Sect. 5.7.3.
Since  and Z are known the ﬁxed-interval smoothing applies (see p. 212) and so
the distribution of βt, given β−t and y1:n is obtained as multivariate Gaussian. Since
we can sample from π(βt | β−t), this provides a single step of the Gibbs sampler
where it is noted that at time t = n we sample from the posterior βn | y1:n, which by
the Kalman ﬁlter (see Theorem 5.1) is again Gaussian. This approach was proposed
by Carlin et al. (1992) together with extensions to non-linear and non-Gaussian
state space models. Unfortunately, this approach can be very inefﬁcient, because the
prior correlation imposed in the system of state vectors β = [β⊤
1 , β⊤
2 , . . . , β⊤
n ]⊤
is largely transferred to the posterior state vectors β | y1:n. The aforementioned
chain correlation together with the high dimensional state space imposed by the time
series length n introduces convergence problems in the Gibbs sampler and slows it
down considerably. This issue is explained below and it is motivated by a relevant
discussion in Gamerman and Lopes (2006, §5.5.2).
Consider that θ = [θ1, θ2]⊤follows a bivariate Gaussian distribution
θ =

θ1
θ2

∼N
(
 2
3

,

 1 ρ
ρ 1
)
,
where ρ is the correlation of θ1 and θ2. It follows that the conditional distributions
are
θ1 | θ2 ∼N[2 + ρ(θ2 −3), 1 −ρ2]
θ2 | θ1 ∼N[3 + ρ(θ1 −2), 1 −ρ2].

5.7
Markov Chain Monte Carlo Inference
245
Contour plot
2
1
2
0
1
2
3
4
5
0
1
2
3
4
5
6
=-0.5
Contour plot
0
1
2
3
4
5
0
1
2
3
4
5
6
1
=-0.97
Fig. 5.4 Contour plots of bivariate Gaussian distributions with correlation ρ = −0.5 (left panel)
and ρ = −0.97 (right panel); shown are draws from Gibbs sampler for the ﬁrst 20 iterations
We initialise the Gibbs sampler at [0, 0]⊤, i.e. θ(0) = [θ(0)
1
= 0, θ(0)
2
= 0]⊤
and consequently we successively simulate θ(i)
1
from θ1 | θ(i−1)
2
and θ(i)
2
from
θ2 | θ(i)
1 , for i = 1, 2, . . . , 1000. We repeat this process for two values of the
correlation coefﬁcient ρ, ﬁrst with a moderate correlation ρ = −0.5 and second
with a correlation very close to −1, ρ = −0.97. Figure 5.4 shows contour plots in
both cases with the ﬁrst 20 iterations being plotted. We observe that for ρ = −0.5
(left panel of Fig. 5.4) the ﬁrst iteration is inside the 5% probability ellipsis of the
contour, while for ρ = −0.97 (right panel of Fig. 5.4) it takes a hefty 15 iterations
for θ(i) to get inside the 5% probability ellipsis. We note that although it has taken
about 15 iterations for this chain to reach the 5% probability region, the chain moves
much slower towards the mean [2, 3]⊤than in the case of ρ = −0.5. This indicates
that high absolute correlation between θ1 and θ2 introduces signiﬁcant delays in the
convergence.
Returning to the state space model we note that βt is likely to be highly correlated
with βt−1, because in the transition equation (5.1b) the values of Z are usually small.
Indeed, we note that if Z = 0, then βt is perfectly correlated with βt−1; it is not
reasonable to suggest the values of Z to be large, because this would imply erratic
changes in the dynamics of the state vector. Thus, the, relatively, small values of
Z introduce high absolute correlation between βt and βt−1. It turns out that the
conditional distribution βt | β−t, y1:n, from which we need to draw β(i)
t
in the
Gibbs sampling proposal of Carlin et al. (1992) is likely to introduce computational
inefﬁciency and convergence delays.

246
5
Multivariate State Space Models
As a result alternative Gibbs sampling schemes are proposed in the literature;
indeed, Carter and Kohn (1994) and Fruhwirth-Schnatter (1994b) independently
proposed a block application of Gibbs sampling, which is considerably more stable
and orders of magnitude faster than the above scheme, as reported in Shephard
(1994b). According to this instead of sampling from βt
| β−t, y1:n, we can
successively sample from just βt | βt+1, y1:n. This is possible because we can write
p(β1, β2, . . . , βn | y1:n) =
n−1
-
t=1
p(βt | βt+1, . . . , βn, y1:n)p(βn | y1:n)
=
n−1
-
t=1
p(βt | βt+1, y1:n)p(βn | y1:n)
(5.19)
=
n−1
-
t=1
p(βt | βt+1, y1:t)p(βn | y1:n),
(5.20)
where (5.19) is obtained since given βt+1, βt and βt+2, . . . , βn are conditionally
independent (i.e. given the present, the past and the future are conditionally
independent). For the same reason given yt, βt and yt+1, . . . , yn are conditionally
independent, hence we have (5.20) (a similar argument was also used in the proof
of Theorem 3.4 in Sect. 3.3).
From an application of the Kalman ﬁlter, the posterior distribution of βn at time
t = n is βn | y1:n ∼N( ˆβn|n, Pn|n), where ˆβn|n and Pn|n are calculated recursively
as in Theorem 5.1. For univariate state space models (d = 1) the distribution of
βt | βt+1, y1:t was established in Theorem 3.4; the modiﬁcation for the multivariate
case (d ≥1) are minor. It turns out in the multivariate case the distribution of
β | βt+1, y1:t is βt | βt+1, y1:t ∼N[ ˆβt|t+1(βt+1), Pt|t+1(βt+1)], where
ˆβt|t+1(βt+1) = ˆβt|t + Lt(βt+1 −ˆβt+1|t),
Pt|t+1(βt+1) = Pt|t −LtPt+1|tL⊤
t ,
with Lt = Pt|tF⊤
t+1P−1
t+1|t and ˆβt|t, ˆβt+1|t, Pt|t and Pt+1|t provided by the Kalman
ﬁlter. Note that here we have made explicit the dependence of ˆβt|t+1(βt+1) on βt+1,
while Pt|t+1(βt+1) does not depend on βt+1.
Equation (5.20) suggests that, in order to simulate from p(β1, . . . , βn | y1:n),
at each iteration i of the Gibbs sampler, we need to draw β(i)
n
from a N( ˆβn|n, Pn|n)
(forward ﬁltering step) and then for t = n−1, n−2, . . . , 1 we need to draw β(i)
t
from
N[ ˆβt|t+1(β(i)
t+1), Pt|t+1(β(i)
t+1)] (backward sampling step). The algorithm is known as
forward ﬁltering backward sampling (FFBS). This sampling scheme beneﬁts from
sampling βt at each time t, conditional on the state one time ahead (βt+1) instead
of conditioning βt on the whole β−t. The FFBS algorithm is schematically given
below.

5.7
Markov Chain Monte Carlo Inference
247
Forward Filtering Backward Sampling (Known Covariance Matrices)
In the state space model (5.1a)–(5.1b) with  and Z and the prior of β0 as in
the Kalman ﬁlter (Theorem 5.1) the following steps provide Gibbs sampling
of the state vectors:
1. Run the Kalman ﬁlter for t = 1, 2, . . . , n and obtain ˆβt+1|t, ˆβt|t, Pt|t−1 and
Pt|t.
2. For i ≥1, draw a vector β(i)
n
from N( ˆβn|n, Pn|n).
3. For
each
t
=
n −1, n −2, . . . , 1
draw
state
β(i)
t
from
N[ ˆβt|t+1(β(i)
t+1), Pt|t+1(β(i)
t+1)], where
ˆβt|t+1(βt+1) = ˆβt|t + Lt(βt+1 −ˆβt+1|t),
Pt|t+1(βt+1) = Pt|t −LtPt+1|tL⊤
t ,
and Lt = Pt|tF⊤
t+1P−1
t+1|t.
4. Set the counter i = i + 1 and go to step (2) until convergence.
Some comments are in order. Firstly, note that the FFBS algorithm does not
require an initialisation of the state vector β(0)
t
. In other words, the Kalman ﬁlter
provides a learned procedure for the initialisation of β(i)
n . Secondly, the covariance
matrix Pt|t+1(βt+1) = Pt|t+1 does not depend on βt+1 and can be provided by the
Kalman ﬁlter in step 1. This can result in signiﬁcant computational savings, as only
the computation of the mean vector βt|t+1(β(i)
t+1) requires to know the simulated
vector β(i)
t+1.
5.7.3
Unknown Variances-Covariances
This section considers the state space model (5.1a)–(5.1b), where now the covari-
ance matrix  of the innovation vector ϵt and the covariance matrix Z of the
innovation vector ζt are unknown and subject to estimation. Initially, the FFBS
algorithm proposed in Carter and Kohn (1994) and Fruhwirth-Schnatter (1994b)
considered univariate time series. Carter and Kohn (1994) placed improper priors on
the observation and transition variances, resulting in proper inverse gamma priors
for these variances; these authors assumed that the transition covariance matrix is
known up to a variance component, which is subject to estimation. On the other
hand, Fruhwirth-Schnatter (1994b) introduced the d-inverse gamma state space
model, whereby the variance of the scalar observation innovation is gamma and
the covariance of the transition innovation vector Z is diagonal, each element of
its main diagonal independently following a priori an inverse gamma distribution.

248
5
Multivariate State Space Models
The d-inverse gamma state space model is implemented within the dlm package in
R, see e.g. Petris et al. (2009, §4.5). Here we describe the more general approach
where the priors of both  and Z are inverse Wishart, allowing us to learn for the
correlation between elements of ϵt and ζt, respectively. Gibbs sampling for the d-
inverse gamma model is described in Exercise 11 and a summary of the algorithm
is given in page 260.
The general Gibbs sampler described in Sect. 5.7.1 can be applied in blocks of
parameters, i.e. if we are interested in sampling from the posterior distribution of
[θ, ψ]⊤, where θ is a vector of parameters and ψ is a vector or matrix containing
hyperparameters, then we need to sample from θ | ψ, y and from ψ | θ, y. In order
to apply this modiﬁcation ﬁrst we set θ = [β⊤
1 , . . . , β⊤
n ]⊤and ψ = [, Z] and then
we note that the FFBS scheme of the previous section provides a sampling scheme
from βt, given the hyperparameters  and Z. Therefore from (5.20) we have
p(β1:n | , Z, y1:n) =
n−1
-
t=1
p(βt | βt+1, , Z, y1:t)p(βn | , Z, y1:n),
(5.21)
where we use β1:n for the joint state vectors β1:n = {β1, β2, . . . , βn}.
Moving on to the prior structure of the hyperparameters , Z we assume that
a priori they are independent and that each of which has an inverse Wishart prior
distribution, i.e.
p() = c2||−(ν+d+1)/2 exp

−1
2trace(S−1)

,
(5.22)
p(Z) = c2|Z|−(ν+p+1)/2 exp

−1
2trace(SZZ−1)

,
(5.23)
where S and SZ are prior scale matrices, ν are the prior degrees of freedom and
c2 is the proportionality constant (the expression of c2 is given in Sect. 5.5.2 where
the inverse Wishart distribution is discussed). These distributions are abbreviated
as  ∼IW(n, S) and Z ∼IW(n, SZ); for a more detailed discussion on the
inverse Wishart distribution see also Sect. 5.5.2. Then the conditional distribution of
, given Z, β1:n and y1:n is
p( | Z, β1:n, y1:n) = p(, Z, β1:n, y1:n)
= p(y1:n | β1:n, , Z)p(β1:n | , Z)p()p(Z)
=
n
-
t=1
p(yt | βt, )
n
-
t=1
p(βt | βt−1, Z)p()p(Z)
(5.24)
∝
n
-
t=1
||−1/2 exp

−1
2trace
3
(yt −x⊤
t βt)(yt −x⊤
t βt)⊤−14

5.7
Markov Chain Monte Carlo Inference
249
×||−(ν+d+1)/2 exp

−1
2trace(S−1)

= ||−(ν+n+d+1)/2 exp
 
−1
2trace
 n

t=1
(yt −x⊤
t βt)(yt −x⊤
t βt)⊤+ S
+!
,
which is proportional to the inverse Wishart distribution
 | Z, β1:n, y1:n ∼IW
 
ν + n,
n

t=1
(yt −x⊤
t βt)(yt −x⊤
t βt)⊤+ S
!
.
(5.25)
We have used the assumption that a priori  and Z are independent, hence
p(, Z) = p()p(Z). Also, Eq. (5.24) shows that, given β1:n and y1:n, the
covariances matrices  and Z are conditionally independent.
Similarly, we can see that the conditional distribution of Z, given β1:n, y1:n and
 is
p(Z | , β1:n, y1:n) = p(Z, , β1:n, y1:n) ∝
n
-
t=1
p(βt | βt−1, Z)p(Z)
= |Z|−(ν+n+p+1)/2
× exp
 
−1
2trace
 n

t=1
(βt −Ftβt−1)(βt −Ftβt−1)⊤+ SZ
+
Z−1
!
,
which is proportional to the inverse Wishart distribution
Z | , β1:n, y1:n ∼IW
 
ν + n,
n

t=1
(βt −Ftβt−1)(βt −Ftβt−1)⊤+ SZ
!
.
(5.26)
From the above discussion, the full conditional distributions are given by (5.21),
(5.25) and (5.26). Hence the FFBS algorithm for unknown covariance matrices 
and Z are given below.
Forward Filtering Backward Sampling (Unknown Covariance Matrices)
In the state space model (5.1a)–(5.1b) with the prior of β0 as in the Kalman
ﬁlter (Theorem 5.1) and the priors of  and Z as in (5.22) and (5.23), the
following steps provide Gibbs sampling of the state vectors and the covariance
matrices:
(continued)

250
5
Multivariate State Space Models
1. Initialisation: draw (0) from (5.22) and Z(0) from (5.23).
2. For iteration i ≥1, set  = (i−1) and Z = Z(i−1).
a. Run the Kalman ﬁlter for t = 1, 2, . . . , n and obtain ˆβt+1|t, ˆβt|t, Pt|t−1
and Pt|t.
b. Draw a vector β(i)
n
from N( ˆβn|n, Pn|n).
c. For each t
=
n −1, n −2, . . . , 1
draw state β(i)
t
from
N[ ˆβt|t+1(β(i)
t+1), Pt|t+1(β(i)
t+1)], where
ˆβt|t+1(βt+1) = ˆβt|t + Lt(βt+1 −ˆβt+1|t),
Pt|t+1(βt+1) = Pt|t −LtPt+1|tL⊤
t ,
and Lt = Pt|tF⊤
t+1P−1
t+1|t.
d. Draw (i) from
IW
 
ν + n,
n

t=1
(yt −x⊤
t β(i)
t )(yt −x⊤
t β(i)
t )⊤+ S
!
and Z(i) from
IW
 
ν + n,
n

t=1
(β(i)
t
−Ftβ(i)
t−1)(β(i)
t
−Ftβ(i)
t−1)⊤+ SZ
!
where β(i)
0
is drawn from a N( ˆβ0|0, P0|0).
3. Set the counter i = i + 1 and go to step (2) until convergence.
Example 5.1 (Production Time Series) In this section we consider a bivariate time
series consisting of 276 observation vectors yt
= [y1t, y2t]⊤of temperatures
measured at two components (y1t is the temperature of Component 3 and y2t of
Component 4) during the process of a production of a plastic mould. This is part
of a larger data set (considering 5 components) that is studied in Pan and Jarrett
(2004) and also in Triantafyllopoulos (2006a). Large levels of the temperatures
during the production process indicate hazards and may prompt relevant action.
The objective of the above studies is to propose a control mechanism that can signal
large temperatures using statistical process control methods. Pan and Jarrett (2004)
demonstrate that the estimation of the covariance matrices (such as  and Z in the
context and notation of this book) plays a crucial role in the detection of out of
control signals. In this section we use a bivariate local level model for yt and we

5.7
Markov Chain Monte Carlo Inference
251
30
40
50
60
Component 3
-30
-25
-20
-15
-10
0
50
100
150
200
250
Component 4
Time
Production data
Fig. 5.5 Plot of the production time series yt = [y1t, y2t]⊤
provide smoothed estimates of the level βt as well as estimates of the observation
and transition covariance matrices  and Z.
Figure 5.5 plots the data (the top panel shows y1t the temperatures of Component
1 and the lower panel shows the temperatures y2t of Component 2). We observe that
each component time series exhibits local variation around the level, which suggests
that a local level is a plausible model. Moreover, histograms of each component
indicate that the normality assumption of the data is broadly satisﬁed. Figure 5.5
also indicates that y1t increases steadily for up to about t = 140 and then it seems to
drop a degree 0C compared to the start of the process, while y2t seems more stable
over time. The proposed model is
yt = βt + ϵt
and
βt = βt−1 + ζt,
where βt = [β1t, β2t]⊤is a bivariate state vector and the innovation vectors ϵt
and ζt satisfy the usual conditions, stated in several places in the book, e.g. as in
model (5.1a)–(5.1b). Initially we assume that β0 ∼N([0, 0]⊤, 1000I) for a weak
prior speciﬁcation on β0, while the inverse Wishart priors (5.22) and (5.23) of  =
Var(ϵt) and Z = Var(ζt) are used, where ν = 10, d = p = 2 and S = SZ = I.
These settings suggest weak prior knowledge on  and Z, but if prior knowledge is
available this may be incorporated easily by specifying S and Z as non-diagonal
covariance matrices. In our experience, even such a prior information is available,
there is little loss, if any, by considering the setting proposed in this section; see also
the discussion in Sect. 4.5.

252
5
Multivariate State Space Models
With the above set-up in place we run the forward ﬁltering backward sampling
(FFBS) algorithm described earlier in this section. The following commands are
used to ﬁt the model in R:
> # read data
> pro <- read.table("productiondata.txt")
> ypro <- as.matrix(pro[,3:4])
> # fit the local level model
> fit <- bts.ffbs(y=ypro, v=10, m=5000)
The Gibbs algorithm runs for 5000 iterations, which was judged enough for con-
vergence and the ﬁrst 1000 iterations were used for the burn-in and were excluded
from any further computations. This convergence is backed by the trace plots of
the simulated values of β(i)
1t and β(i)
2t , shown for iterations i = 1001, . . ., 5000
in Fig. 5.6. Indeed, we observe that β(i)
1t and β(i)
2t are stationery and they are also
uncorrelated (this can be checked by looking at the correlogram of β(i)
jt , j = 1, 2).
This ﬁgure is produced using the R code:
> # plot of estimated beta’s
> par(mfrow=c(2,1))
> ts.plot(ts(fit$beta[276,1,1001:5000],start=1001,
+ frequency=1),main=expression(paste(beta[1])),
+ xlab="Iteration",ylab="")
> ts.plot(ts(fit$beta[276,2,1001:5000],start=1001,
+ frequency=1),main=expression(paste(beta[2])),
+ xlab="Iteration",ylab="")
Figure 5.7 shows the histograms of the estimated variances 11 and 22, for  =
(ij)i,j=1,2 as well as the estimated variances Z11 and Z22 for Z = (Zij)i,j=1,2.
1
2
Iteration
1000
2000
3000
4000
5000
30
50
70
Iteration
1000
2000
3000
4000
5000
-35
-25
-15
Fig. 5.6 Trace plot of the level βt = [β1t, β2t]⊤of the time series; shown are the simulated values
β(i)
1t (top panel) and β(i)
2t (low panel) for iterations i = 1001, . . . , 5000

5.7
Markov Chain Monte Carlo Inference
253
Histogram of 
11
11
Frequency
20
40
60
80
100
120
140
0
400
800 1200
22
10
20
30
40
50
60
Histogram of Z11
Z11
Frequency
50
100
150
0 200
600
1000
Histogram of Z22
Z22
20
30
40
50
60
70
80
Frequency
0
400
800 1200
Frequency
0 200
600
Histogram of 
22
Fig. 5.7 Histograms of the simulated variances 11, 22, Z11 and Z22
The modes of the estimated correlation coefﬁcients in  and Z were −0.832 and
−0.825, respectively. This indicates signiﬁcant negative correlation between y1t and
y2t. Assuming that  and Z are diagonal matrices, as it is the case in the d-inverse
gamma state space models of Carter and Kohn (1994) and Fruhwirth-Schnatter
(1994b) is not appropriate; here the inverse Wishart priors offer the advantage of
estimating the correlation coefﬁcients of ϵ1t, ϵ2t and ζ1t, ζ2t, where ϵt = [ϵ1t, ϵ2t]⊤
and ζt = [ζ1t, ζ2t]⊤. The following R code was used for Fig. 5.7:
> # plot of simulated variances
> Sigma <- Z <- array(0, dim=c(2,2,5000))
> for (i in 1001:5000){
+ Sigma[,,i] <- fit$Sigma[[i]]
+ Z[,,i] <- fit$Z[[i]]
+ }
> par(mfrow=c(2,2))
> hist(Sigma[1,1,1001:5000],main=expression(paste("Histogram
+ of ", Sigma[11])), xlab=expression(Sigma[11]) )
> hist(Sigma[2,2,1001:5000],main=expression(paste("Histogram
+ of ", Sigma[22])), xlab=expression(Sigma[22]) )
> hist(Z[1,1,1001:5000],main=expression(paste("Histogram
+ of ",Z[11])), xlab=expression(Z[11]) )
> hist(Z[2,2,1001:5000],main=expression(paste("Histogram
+ of ",Z[22])), xlab=expression(Z[22]) )

254
5
Multivariate State Space Models
Correlation coefficient
Frequency
-0.9
-0.8
-0.7
-0.6
-0.5
0
200
400
600
800
1000
1200
1400
Correlation coefficient
Z
Frequency
-0.9
-0.8
-0.7
-0.6
-0.5
0
500
1000
1500
Fig. 5.8 Histograms of the simulated correlations (left panel for  and right panel for Z)
The estimated correlation of ϵ1t and ϵ2t (corresponding to the observation
covariance matrix ) and the correlation of ζ1t and ζ2t (corresponding to the
covariance matrix Z) is visualised in Fig. 5.8. The R code used here is:
> # plot of simulated correlations
> par(mfrow=c(1,2))
> hist( Sigma[1,2,1001:5000] /
+ sqrt( Sigma[1,1,1001:5000] * Sigma[2,2,1001:5000] ),
+ main=expression("Correlation coefficient"),
+ xlab=expression(Sigma) )
> hist( Z[1,2,1001:5000] /
+ sqrt( Z[1,1,1001:5000] * Z[2,2,1001:5000] ),
+ main=expression("Correlation coefficient"), xlab="Z")
5.8
Exercises
1. Suppose that you want to forecast a bivariate time series yt = [y1t, y2t]⊤
consisting of a linear trend y1t and a local level y2t. Write down two state space
models for yt of the form of model (5.1a)–(5.1b), with design matrices
a.
xt =

1 0
0 1

;

5.8
Exercises
255
b.
xt =
⎡
⎣
1 0
0 0
0 1
⎤
⎦
i.e. determine the form of the transition matrices, the observation covariance
matrices and the transition covariance matrices.
2. (Aggregate forecasting). Suppose that the d-dimensional time series vector
yt = [y1t, . . . , ytd]⊤is modelled with the multivariate scaled observational
precision state space model (5.13a)–(5.13b) of Sect. 5.5.3. Deﬁne the aggregate
time series of ‘totals’ Tt = d
i=1 yit = 1⊤
d yt, where 1d = [1, . . . , 1]⊤is the d-
dimensional vector of units. Show that Tt follows a univariate state space model
with observation equation
Tt = x⊤
t γt + υt,
υt ∼N(0, 1⊤
d 1d)
and transition equation
γt = Ftγt−1 + ωt,
ωt ∼N(0, 1⊤
d 1dZt),
where xt is the design vector, Ft is the transition matrix,  is the observation
covariance matrix and Zt is the transition left covariance matrix of the
model (5.13a)–(5.13b). Deﬁne γt, υt and ωt in terms of the state matrix and
innovations of the state space model of yt.
3. A marketing company is running a pricing assessment for 3 of its products
A, B and C. The company adopts a multivariate state space model in order to
forecast the prices of these three products. Let y1t be the price of product A at
time t, y2t the price of product B at time t, y3t the price of product C at time t
and write yt = [y1t, y2t, y3t]⊤. The one-step forecast of these products at time
t + 1 is ˆyt+1|t = [3, 2, 5]⊤(in £) with associated forecast covariance matrix
Qt+1|t = diag(0.5, 2, 1). The company asserts that the total price of the three
products at time t + 1 should be Tt+1 = 9. Obtain 99% marginal prediction
intervals of y1t, y2t, y3t, given that Tt+1 = 9. Based on these intervals suggest
whether the company should revise downwards or upwards the prices of A, B
and C as compared to the forecasts 3, 2 and 5 respectively.
4. Consider a d × 1 random vector Y and a p × 1 random vector X having a joint
dp-dimensional multivariate normal distribution

 X
Y

∼N
(
 mX
mY

,

 VX C
C⊤VY
)
,
where mX is the mean vector of X, mY is the mean vector of Y, VX is
the covariance matrix of X, C is the covariance of X and Y, and VY is the
covariance matrix of Y.

256
5
Multivariate State Space Models
a. Deﬁne K = CV−1
Y
and show that X −KY is uncorrelated with Y. Find the
distribution of X −KY.
b. Using (a) show that the conditional distribution of X, given Y = y, for a
particular value y of Y is
X | Y = y ∼N[mX + K(y −mY ), VX −KVY K⊤].
c. Use this result to prove Theorem 5.1 (Kalman ﬁlter).
5. In the context of Exercise 4 suppose that X and Y are only partially speciﬁed in
terms of their means and variances, without specifying their joint distribution.
If we write X ∼[mX, VX] this implies that the mean vector of X is mX and its
covariance matrix is VX. For the joint partial speciﬁcation of X and Y we write

X
Y

∼
(
 mX
mY

,

 VX C
C⊤VY
)
,
where mX, mY , VX, VY , C are as in Exercise 4.
Two random vectors Z and W are said to be second order independent if
E(Z | W = w) = E(Z)
and
Var(Z | W = w) = Var(Z),
for any value w of W. We write Z ⊥2 W to denote that Z and W are 2nd order
independent.
a. Show that if Z and W are mutually independent, then Z ⊥2 W. Show that
the reverse is not always true.
b. With K deﬁned as in Exercise 4, show that if X −KY ⊥2 Y, then the mean
vector and the covariance matrix of the conditional distribution of X | Y = y
are given by
X | Y = y ∼[mX + K(y −mY ), VX −KVYK⊤].
c. Now consider the state space model (5.1a)–(5.1b) where the Gaussian
assumption of the innovations ϵt and ζt is dropped and the model be partially
speciﬁed via the innovations’ mean vectors and covariance matrices, i.e.
ϵt ∼(0, ) and ζt ∼(0, Zt). Use (b) to show
βt | y1:t ∼( ˆβt|t, Pt|t),
where ˆβt|t and Pt|t are given by updating recurrences exactly the same
as those provided by the Kalman ﬁlter of Theorem 5.1. Thus extend the
Kalman ﬁlter in cases that the modeller is reluctant to specify the Gaussian
distribution for the innovations.

5.8
Exercises
257
6. Triantafyllopoulos and Harrison (2008). In the context of Exercise 5 suppose
that the covariance matrices VX and VY are scaled by an unknown variance σ 2.
Hence, X and Y are partially speciﬁed by their mean vectors and covariance
matrices as

 X
Y

∼
(
mX
mY

, σ 2

VX C
C⊤VY
)
,
where mX, mY , VX, VY , C are as in Exercise 5.
a. Now with ⊥2 denoting second order independence as deﬁned in Exercise 5
above, assuming X −KY ⊥2 Y | σ 2, show
X | σ 2, Y = y ∼[μX + K(y −μY ), σ 2(VX −KVY K⊤)],
where K = CV−1
Y .
b. Let T be a non-linear function of Y, often taken as
T = (Y −μY )⊤V−1
Y (Y −μY ).
Deﬁne κ to be α times the variance of T | σ 2, for some α > 0. Assume that
σ 2 −LT ⊥2 Y, κ, with
T | σ 2, κ ∼(σ 2, κ/α)
and
Cov(T, σ 2 | κ) = Var(σ 2 | κ),
where L = α/(η + α) and σ 2 | κ ∼(ˆσ 2, κ/η, which is η/α times as precise
as the conditional distribution of T , for some known ˆσ 2, α and η.
Show that

 σ 2
T

∼
(
 ˆσ 2
ˆσ 2

, κ
η

 1
1
1 (η + α)/α
)
.
Using σ 2 −LT ⊥2 Y | κ, with L as above, show
σ 2 | κ, T = τ ∼
η ˆσ 2 + ατ
η + α
,
κ
η + α
	
.
Using the tower law of expectations show that
X | Y = y ∼

μX + K(y −μY ), η ˆσ 2 + ατ
η + α
(VX −KVYK⊤)

,
where τ = (y −μY )V−1
Y (y −μY ).

258
5
Multivariate State Space Models
c. Now suppose that the joint distribution of X and Y is Gaussian, so that

 X
Y

∼N
(
mX
mY

, σ 2

VX C
C⊤VY
)
,
and assume that νs/σ 2 follows a chi-square distribution with ν degrees of
freedom, i.e. νs/σ 2 ∼χ2
ν , for some ν, s > 0.
Writing T = (Y −μy)⊤V−1
Y (Y −μY ), show
X | Y = y ∼t

ν + p, μx + K(y −μY ), νs + τ
ν + p

VX −KVY K⊤
,
νs + τ
σ 2
| Y = y ∼χ2
ν+p,
τ = (y −μY )⊤V−1
Y (y −μY ),
for some y observed vector of Y and t(·) denotes a Student t distribution.
d. Compare the posterior mean and variance of σ 2 of approaches (b) and (c)
above. In particular ﬁnd a value for α in (b) so that E(X | Y = y) and
Var(X | Y = y) are the same under (b) and (c).
Adopting this value of α show that
E(σ 2 | Y = y, approach (c) ) −E(σ 2 | Y = y, approach (b) )
=
(p −1)νs
(ν −2)(ν + p −2),
hence establish that the posterior means of σ 2 under (b) and (c) are different.
Explore further the impact of the differences of the estimation of σ 2 by
considering the posterior variances of σ 2 under (b) and (c).
e. In the context of state space models, set X = βt (state vector at t) and Y = yt
(observation vector at t) and obtain a version of the results in (b) and (c) for
state space models. Write down explicitly your state space model under (b)
and under (c) and comment on their differences.
7. New York air quality (source Chambers et al. (1983)). Measurements of wind
speed and temperature are observed in daily frequency over the period 1 May
to 30 September 1973 in New York. The data is available in R by executing the
following commands
> library(MASS)
> data(airquality)
> y <- airquality[,3:4]
It is suggested that air quality reﬂects the levels of these two variables. Use
a state space model to jointly model the effects and provide prediction of the
wind speed and the temperature. Your analysis should include estimating the
correlation of the two variables as well as assessing the goodness of ﬁt by
considering appropriate error analysis.

5.8
Exercises
259
8. Longley’s macroeconomic data set (source Longley (1967)). The data set
comprise of annual measurements on six economic variables: gross national
product (GNP) deﬂator, GNP, number of unemployed, number of people in the
armed forces, ‘noninstitutionalized’ population ≥14 years of age and number
of employed, from 1947 to 1962. The data is available in R by executing the
following commands
> library(MASS)
> data(longley)
> y <- longley
Discuss the data commenting on any interesting features they provide. Consider
the four variables: variables GNP, number of unemployed, number of people in
the armed forces and number of employed and suggest a state space model to
describe these four variables. Fit the model in R and estimate the observation
covariance matrix.
9. Petroleum rock samples (source BP Research, image analysis by Ronit Katz).
48 rock measurements on 3 variables from a petroleum reservoir are made. The
variables are: (1) area of pores space, in pixels out of 256 by 256, (2) perimeter
in pixels and (3) perimeter per sqrt(area). The data are sampled in 12 main time-
occasions and 4 cross-sections. The time units are not known, but are believed
to be equally spaced and of high frequency. The data i is available in R by
executing the following commands
> library(MASS)
> data(rock)
> y <- rock[,1:3]
Fit a trivariate state space model to the data. Estimate the 3 × 3 observation and
transition covariance matrices using a suitable Gibbs sampling procedure.
10. Prove the EM algorithm for multivariate state space models, which is sum-
marised on page 215.
11. d-inverse gamma state space model. In the state space model (5.1a)–(5.1b) sup-
pose that the observation covariance matrix  and the time-invariant transition
covariance matrix Zt = Z are diagonal, written as  = diag(σ11, σ22, . . . , σdd)
and Z = diag(z11, z22, . . . , zpp), for some variances σii and zjj and i =
1, 2, . . . , d; j = 1, 2, . . . , p.
We assume that σii is independent of σkk, for i ̸= k, zjj is independent of zll,
for j ̸= l and σii is independent of zjj, for any i, j. The prior of β0 is as in the
Kalman ﬁlter (Theorem 5.1) and inverse gamma priors are assumed for σii and
zjj, i.e.
σii ∼IG(νi, S,ii)
and
zjj ∼IG(wj, SZ,jj),
(5.27)
for some parameters νi, S,ii, wi, SZ,jj.

260
5
Multivariate State Space Models
In the context of forward ﬁltering backward sampling scheme, show that the
conditional posterior distributions of σii and zjj are
σii | Z, β1:n, y1:n ∼IG
 
n
2 + νi, 1
2
n

t=1
(yit −x⊤
it βt)2 + S,ii
!
,
zjj | , β1:n, y1:n ∼IG
 
n
2 + wj, 1
2
n

t=1
(βjt −F ⊤
jt βt−1)2 + SZ,jj
!
,
where yt = [y1t, . . . , ydt]⊤, x⊤
t
= [x1t, . . . , xpt], βt = [β1t, . . . , βpt]⊤and
F⊤
t = [F1t, . . . , Fpt].
Hence obtain the forward ﬁltering backward sampling algorithm for the d-
inverse gamma state space model, given below:
Forward Filtering Backward Sampling (d-Inverse Gamma Model)
In the state space model (5.1a)–(5.1b) with the prior of β0 as in the Kalman
ﬁlter (Theorem 5.1) and the priors of σii and zjj as in (5.27) the following
steps provide Gibbs sampling of the state vectors and the variances:
a. Initialisation: draw σ (0)
ii
and z(0)
jj from (5.27) and obtain (0) and Z(0).
b. For iteration k ≥1, set  = (k−1) and Z = Z(k−1).
i. Run the Kalman ﬁlter for t = 1, 2, . . ., n and obtain ˆβt+1|t, ˆβt|t,
Pt|t−1 and Pt|t.
ii. Draw a vector β(i)
n
from N( ˆβn|n, Pn|n).
iii. For each t
=
n −1, n −2, . . ., 1 draw state β(i)
t
from
N[ ˆβt|t+1(β(i)
t+1), Pt|t+1(β(i)
t+1)], where
ˆβt|t+1(βt+1) = ˆβt|t + Lt(βt+1 −ˆβt+1|t),
Pt|t+1(βt+1) = Pt|t −LtPt+1|tL⊤
t ,
and Lt = Pt|tF⊤
t+1P−1
t+1|t.
iv. For i = 1, 2, . . ., d, draw σ (k)
ii
from
IG
 
n
2 + νi, 1
2
n

t=1
(yit −x⊤
it β(k)
t
)2 + S,ii
!
(continued)

5.8
Exercises
261
and for j = 1, 2, . . . , p, draw z(k)
jj from
IG
 
n
2 + wj, 1
2
n

t=1
(β(k)
jt −F ⊤
jt β(k)
t−1)2 + SZ,jj
!
where β(k)
0
is drawn from a N( ˆβ0|0, P0|0). Set
(k) = diag
%
σ (k)
11 , σ (k)
22 , . . . , σ (k)
dd
&
,
Z(k) = diag
%
z(k)
11 , z(k)
22 , . . . , z(k)
pp
&
.
c. Set the counter k = k + 1 and go to step (b) until convergence.

Chapter 6
Non-Linear and Non-Gaussian State
Space Models
This chapter discusses Bayesian inference for non-linear and non-Gaussian state
space models. The chapter considers a general model formulation, which includes
as special case the linear and Gaussian state space models, discussed in Chaps. 3–5,
and allows for generalisation aimed at wide application. Dynamic generalised linear
models and conditionally Gaussian models are discussed in some detail. The power
local level model is presented for historical reasons as a relatively limited modelling
setup which allows conjugate Bayesian inference. Moving away from its limitations
we discuss approximate inference and the extended Kalman ﬁlter. Simulation-based
estimation is considered in detail focusing upon sequential Monte Carlo methods
and Markov chain Monte Carlo methods.
Section 6.1 introduces the general models and provides their motivation starting
from linear Gaussian state space models. Dynamic generalised linear models are
described in detail in Sect. 6.2. Special cases include models for counts, categorical
data and continuous proportions. Other non-linear and non-Gaussian models, such
as stochastic volatility and bearings-only tracking models described in Sect. 6.3.
The power local level models are discussed in Sect. 6.5; this is a class of models
allowing for conjugate inference, albeit is a very restricted class of models. Special
interesting cases include the Poisson-gamma and the exponential-gamma models.
The extended Kalman ﬁlter is described for approximate inference in Sect. 6.6.
Essentially a Taylor series expansion is used and the Kalman ﬁlter is used to
provide approximation of the posterior distribution of the states. Sequential Monte
Carlo methods are discussed in detail in Sect. 6.7. In detail there is consideration
of the choice of the importance function (Sect. 6.7.4) and of the problem of
the estimation of static-parameters (Sect. 6.7.8). Various examples are used to
illustrate the algorithms including bearings-only tracking data, simulations from a
conditionally Gaussian model and forecasting of counts of schoolchildren suffering
from asthma. Section 6.8 discusses MCMC inference for dynamic generalised linear
models. The chapter concludes by discussing dynamic survival models in Sect. 6.9.
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2021
K. Triantafyllopoulos, Bayesian Inference of State Space Models, Springer Texts
in Statistics, https://doi.org/10.1007/978-3-030-76124-0_6
263

264
6
Non-Linear and Non-Gaussian State Space Models
6.1
General Model Formulation
So far in this book we have studied state space models, which are Gaussian (the
distributions of the observations given the states and the distribution of the states
given past states are Gaussian) and the observations are linear functions of the states.
This is formally described by the two conditional distributions
p(yt | βt) ≡N(x⊤
t βt, )
and
p(βt | βt−1) ≡N(Ftβt−1, Zt),
(6.1)
which are immediately obtained from the observation and transition equations
(5.1a)–(5.1b) with the innovation distributions (5.2), where the components xt, Ft,
 and Zt are described in Sect. 5.1. The model is complete when we specify the
prior distribution of β0, which is again Gaussian, i.e. β0 ∼N( ˆβ0|0, P0|0), for some
known prior mean vector and prior covariance matrix ˆβ0|0 and P0|0).
However, as we have already seen in Chap. 1 many data exhibit a non-linear
relationship between the observations and the states and are not supported by the
linear structure implicit in the Gaussian distributions of (6.1). In the bearings only
ship tracking example of Sect. 1.3.2 the distribution of the observations given the
states is non-linear, see Eq. (1.12); in the stochastic volatility example discussed in
Sect. 1.3.3 again observation and state are linked via a non-liner relationship.
These models can be described by the so-called conditionally Gaussian state
space models, that is given the states, the distribution of the observations is Gaussian
and given past states the distribution of the present state is Gaussian, but now the
linearity is dropped. This can be expressed as
yt = f (βt) + ϵt
and
βt = g(βt−1) + ζt,
(6.2)
where f (·) is generally a non-linear function on βt and g(·) is a non-linear function
on βt−1 and the innovations ϵt and ζt follow the usual assumptions (each of ϵt and
ζt is a white noise and ϵt is independent of ζt). It is also assumed that both ϵt and
ζt are independent of β0, which follows some Gaussian distribution. Clearly, if we
set f (βt) = x⊤
t βt and g(βt−1) = Ftβt−1, then we obtain the usual linear Gaussian
state space model (6.1).
The state space model (6.2) is known as conditionally Gaussian, because given
βt the distribution of yt is Gaussian and also given βt−1, the distribution of βt is
Gaussian, i.e.
p(yt | βt) ≡N[f (βt), ]
and
p(βt | βt−1) ≡N[g(βt−1), Zt],
where  and Zt are the covariance matrices of ϵt and ζt, respectively.
The class of non-linear state space models described above assumes that the
distributions of yt | βt and βt | βt−1 are Gaussian. However, there are situations
where these assumptions are violated, in particular the distribution of yt, given
βt (sometimes referred to as the response distribution) may not be Gaussian.

6.2
Dynamic Generalised Linear Models
265
For example yt may be discrete-valued, describing counts or observations of
a categorical variable, or continuous-valued, describing proportions or positive
processes. In all these examples the support of yt is not the real-hyperplane Rd,
and as a result the d-dimensional Gaussian distribution for yt | βt is inappropriate.
Motivating examples of such time series data may be medical counts of patients that
visit their family doctor observed over time, proportions of world car manufacturing
volume over time and so forth. Such models may exhibit a linear or non-linear
relationship between yt and βt. As a result we can extend the model deﬁnition of
(6.2) to account for non-Gaussian distributions. The general non-linear and non-
Gaussian state space model is deﬁned by specifying the distributions
p(yt | βt),
p(βt | βt−1)
and
p(β0).
(6.3)
Thus, this general state space model speciﬁes the distribution of yt | βt (response
distribution), the distribution of βt | βt−1 (transition distribution) and the distribu-
tion of β0 (initial or prior distribution). In addition to the distributional speciﬁcation
(6.3) we will assume that given the present βt, the past βt−i and the future βt+j are
conditionally independent (i.e. that βt carries all information relevant to the present);
this is known as the Markov property of the state space model. This assumption
together with (6.3) deﬁnes a very wide class of models. Sections 6.2 and 6.3 aim
to give some particular examples of possible general state space models, but there
might be other models not discussed here.
6.2
Dynamic Generalised Linear Models
6.2.1
Model Deﬁnition
The generalised linear model (GLM), proposed originally by Nelder and Wedder-
burn (1972) as a generalisation to linear models, including regression and analysis
of variance, in order to deal with non-Gaussian observations. The framework of
the GLM revolutionised statistical inference and application as evidenced in the
monographs (McCullagh & Nelder, 1989; Fahrmeir & Tutz, 2001). The GLM
framework basically considers that observations are generated by a response
distribution belonging to the natural exponential family of distributions. Then the
mean response (the mean of the observations given some parameters) is transformed
to the linear predictor by the so-called link function. This achieves to transform the
mean of the observations (which distribution is non-Gaussian and can be discrete
or continuous distribution) into the linear predictor, which takes values in Rd and
can be assumed to follow a multivariate Gaussian distribution. Hence inference can
follow parallel estimation steps to the standard linear models, for which the link
function is the identity function and the observations follow a Gaussian distribution.

266
6
Non-Linear and Non-Gaussian State Space Models
The dynamic generalised linear model (DGLM) is an extension of the GLM by
assuming that the parameters of the exponential family as well as the regression
coefﬁcients that take part in the linear predictor are time-varying. In particular,
the DGLM considers that the response distribution is a member of the exponential
family with time-varying parameters and the mean response is mapped via the link
function to the linear predictor, which in turn follows a state space model (see below
for a technical description). This representation was ﬁrst considered in West et al.
(1985) and later on adopted in Fahrmeir (1992) and is described below.
Let {yt} be a d-dimensional time series, generated by the multivariate exponential
family of distributions
p(yt | γt) = exp
( 1
at
%
γ ⊤
t z(yt) −b(γt)
&
+ c(yt)
)
,
(observation model)
(6.4)
where γt is the natural d-dimensional parameter vector, at is a possible time-varying
parameter not depending on yt or γt, b(·) is a twice differentiable function, c(·)
is a function that depends on yt, but not on γt. The function z(·), usually taken
as the identity function z(yt) = yt, is a deterministic function of yt, necessary to
consider to express several distributions in the form (6.4) (see the examples below).
Distribution (6.4) may depend on some other hyperparameters θ; this will become
clear in a case by case situation as the examples that follow illustrate.
Given γt, we can express the mean response vector and the covariance matrix of
z(yt) as derivatives of the function b(·). For the mean, ﬁrst observe that *
Rd p(yt |
γt) dyt = 1 and take partial derivatives in both sides:
0 =
"
Rd
∂
∂γt
exp
( 1
at
%
γ ⊤
t z(yt) −b(γt)
&
+ c(yt)
)
dyt
= 1
at
"
Rd

z(yt) −∂b(γt)
∂γt

exp
( 1
at
%
γ ⊤
t z(yt) −b(γt)
&
+ c(yt)
)
,
which implies E[z(yt) | γt] = ∂b(γt)/∂γt.
For the covariance matrix of z(yt) we start from
*
Rd p(yt | γt) dyt = 1 and we
obtain
0 =
∂2
∂γt∂γ ⊤
t
"
Rd exp
( 1
at
%
γ ⊤
t z(yt) −b(γt)
&
+ c(yt)
)
dyt
=
∂
∂γ ⊤
t
( 1
at
"
Rd exp

 1
at

γ ⊤
t z(yt) −b(γt)

+ c(yt)

dyt −1
at
∂b(γt)
∂γt
)

6.2
Dynamic Generalised Linear Models
267
= 1
at
"
Rd
(
z(yt)z(yt)⊤−z(yt)∂b(γt)
∂γt
)
exp
( 1
at
%
γ ⊤
t z(yt) −b(γt)
&
+ c(yt)
)
dyt
−1
at
∂2b(γt)
∂γt∂γ ⊤
t
= 1
at
E[z(yt)z(yt)⊤] −1
at
∂b(γt)
∂γt
E[z(yt)]⊤−1
at
∂2b(γt)
∂γt∂γ ⊤
t
,
which implies
E[z(yt)z(yt)⊤] =

∂b(γt)
∂γt
2
+ ∂2b(γt)
∂γt∂γ ⊤
t
.
Hence, given γt, the covariance matrix of z(yt) is
Var[z(yt) | γt] = E[z(yt)z(yt)⊤| γt] −E[(z(yt) | γt]E[z(yt) | γt]⊤= ∂2b(γt)
∂γt∂γ ⊤
t
.
Returning to the deﬁnition of the DGLM, the mean response vector μt = E(yt |
γt) is mapped into the linear predictor ηt via the link function
g(μt) = ηt
(6.5)
and the linear predictor ηt is assumed to follow a state space model
ηt = x⊤
t βt
and
βt = Ftβt−1 + ζt,
ζt ∼N(0, Zt),
(6.6)
where xt is a p × d design matrix, βt is a p-dimensional state vector, Ft is a p × p
transition matrix and ζt is a white noise vector with covariance matrix Zt. In words
the mean response vector μt which domain is a restricted subset of Rd is mapped
into the unrestricted real ﬁeld Rd via the link function g(·).
Furthermore, it is assumed that ζt is independent of the initial or prior state β0,
which follows a Gaussian distribution:
β0 ∼N( ˆβ0|0, P0|0),
(6.7)
for some prior mean vector ˆβ0|0 and covariance matrix P0|0. The link function g(·) is
assumed to be a bijection, so that g−1(·) the inverse of g(·) exists and (6.5) implies
μt = g−1(ηt). To summarise the DGLM is deﬁned by Eqs. (6.4)–(6.7).
Note that conditional on the state βt, the mean response μt = g−1(x⊤
t βt) is
precisely known and so we can write the response distribution as p(yt | βt), because
the natural parameter vector γt is given as a deterministic function of βt. Hence,
we may express (6.4) as p(yt | βt) and the state distribution as p(βt | βt−1) ≡
N(Ftβt−1, Zt), which together with the prior (6.7) are in the form of the general

268
6
Non-Linear and Non-Gaussian State Space Models
state space model (6.3). Below we provide example of speciﬁc DGLMs, which are
suitable of modelling frequently met non-Gaussian data.
6.2.2
Count Time Series
Count time series data are met in many ﬁelds: in medicine they may be count
of medical contacts of patients recorded over time, in economics they may be
counts of passengers carried in an airline over time and so forth. The two most
basic distributions describing count data are the Poisson and the negative binomial
distributions, for a description of which the reader is referred to Sect. 2.3.2. A more
detailed treatment of count time series is discussed in Kedem and Fokianos (2002).
Suppose that {yt} is generated by a Poisson distribution with rate λt > 0, i.e.
p(yt | λt) = exp(−λt)λyt
t
yt! ,
yt = 0, 1, 2, . . ..
(6.8)
We can write this distribution as
p(yt | λt) = exp(ytγt −λt −log yt!),
which is in the form of (6.4), with a = 1, z(yt) = yt, γt = log λt, b(γt) = λt =
exp(γt) and c(yt) = −log yt!.
The canonical link g(μt) = γt = log λt together with the transition equation
provide
ηt = logλt = x⊤
t βt
(6.9)
βt = Ftβt−1 + ζt,
ζt ∼N(0, Zt),
(6.10)
where βt is a p-dimensional state vector, Ft is a p × p transition matrix, ζt is a
p-dimensional innovation vector following a Gaussian distribution with zero mean
vector and covariance matrix Zt. As usual a Gaussian distribution is assumed for
the initial state β0. Thus, the model consists of Eqs. (6.8)–(6.10) together with the
prior distribution of β0.
The Poisson model above imposes the assumption that, given λt, the mean and
the variance of yt are equal, i.e. E(yt | λt) = Var(yt | λt) = λt. In many situations
this is not the case, in particular interest is placed when the variance of the data is
larger than the mean. In such a situation the data is known to be over-dispersed and
can be better modelled with the negative binomial distribution as detailed below; the
negative binomial distribution is discussed in Sect. 2.3.2.

6.2
Dynamic Generalised Linear Models
269
Suppose that that {yt} is generated by a negative binomial distribution
p(yt | πt) =
yt + λt −1
yt
	
(1 −πt)λtπyt
t ,
yt = 0, 1, 2, . . . ,
(6.11)
where λt > 0 the number of failures before the ytth success is assumed known and
πt is the probability of success at time t; see also the description of the negative
binomial distribution in Sect. 2.3.2.
The above model can be written as
p(yt | πt) = exp

ytγt + λt log(1 −πt) + log
yt + λt −1
yt
	
,
where z(yt) = yt, the natural parameter is γt = log πt and b(γt) = −λt log(1 −
πt) = −λt log(1 −eγt).
The mean response is
μt = ∂b(γt)
∂γt
=
λteγt
1 −eγt =
λtπt
1 −πt
,
conﬁrming the mean of the negative binomial distribution, given in Sect. 2.3.2.
Thus, the logarithmic link can be applied to map μt > 0 to the real line. This
results in the link and transition equations
ηt = log
 λtπt
1 −πt
	
= x⊤
t βt
(6.12)
βt = Ftβt−1 + ζt,
ζt ∼N(0, Zt),
(6.13)
with xt, βt, Ft, ζt and Zt as deﬁned for the Poisson model above.
The negative binomial distribution is obtained as a mixture of a Poisson
distribution when the rate λ follows a gamma distribution. For example, dropping
the time index t, for convenience, the probability mass function of the negative
binomial distribution is obtained from the gamma mixture
pNB(y) =
" ∞
0
pPois(y; λ)pGa(λ; α, β) dλ
=
" ∞
0
exp(−λ)λy
y!
βα
(α)λα−1 exp(−βλ) dλ
= (y + α)
y!(α)
βα
(β + 1)y+α =
y + α −1
y
	
(1 −π)απy,
where pPois(y; λ) denotes the probability mass function of the Poisson distribution
with rate λ, pGa(λ; α, β) denotes the density function of the gamma distribution
with parameters α, β = (1 −π)π−1 and (·) denotes the gamma function.

270
6
Non-Linear and Non-Gaussian State Space Models
Hence one can regard the negative binomial model as a Poisson model when
λ ∼Ga[α, (1 −π)π−1]. It also follows that for large α the Poisson distribution
is obtained by the negative binomial, as in this case the mean and the variance of
the gamma distribution are approximately the same. For more details on the many
Poisson mixture models the reader is referred to Karlis and Xekalaki (2005) and to
references therein.
6.2.3
Categorical Time Series
Suppose that the series {yt} follows a binomial distribution (see also Sect. 2.3.2)
with probability mass function
p(yt|πt) =
λt
yt
	
πyt
t (1 −πt)λt−yt,
yt = 0, 1, . . . , λt,
(6.14)
where πt is a random variable which denotes the probability of success at time t and
λt is a known positive integer at time t. Then
p(yt|πt) = exp

yt log

πt
1 −πt
	
+ λtlog (1 −πt) + log
λt
yt
	
= exp
(
λt

yt
λt
γt −log (1 + eγt)

+ log
λt
yt
	)
.
This implies that z(·) is the proportion z(yt) = yt/λt and that the natural parameter
γt = log{πt/(1 −πt)}. In this case b(γt) = log(1 + eγt), conﬁrming that πt =
E[z(yt)|πt] = b′(γt) = eγt/(1 + eγt) = λtπt. The link function is g(μt) = γt and
so the canonical link and transition equations are
ηt = log

πt
1 −πt
	
= x⊤
t βt,
(6.15)
βt = Ftβt−1 + ζt,
ζt ∼N(0, Zt).
(6.16)
The above binomial model can be generalised in order to accommodate for multi-
categorical data. Considering k ≥2 categories, let yit denote the count or total
measurement of a quality characteristic observed in category i = 1, 2, . . . , k at time
t. Denote with πit the cell probability that the random variable yit is equal to the
observed count. Fix λt = y1t + · · · + ykt to be total count and π1t + · · · + πkt = 1,
for some known positive integer λt. The joint p.m.f. of yt = [y1t, . . . , yk−1,t]⊤is
p(yt) =
λt!
5k
i=1 yit!
k-
i=1
πyit
it ,
(6.17)

6.2
Dynamic Generalised Linear Models
271
which deﬁnes the multinomial distribution and is discussed in some detail in Chap-
ter 3 of Fahrmeir and Tutz (2001); see also the relevant discussion in Sect. 2.3.2.
The above p.m.f. may be written as
p(yt) = exp
 k−1

i=1
yit log πit +

λt −
k−1

i=1
yit

log

1 −
k−1

i=1
πit
!
λt!
5k
i=1 yit!
= exp

λt
 k−1

i=1
yit log
πit
1 −k−1
i=1 πit
+ log

1 −
k−1

i=1
πit
!+
λt!
5k
i=1 yit!
,
which is in the form of (6.4), with at
=
λ−1
t
, z(yt)
=
λ−1
t
yt, γt
=
[γ1t, . . . , γk−1,t]⊤, γit = log

πit

1 −k−1
i=1 πit
−1
and b(γt) = log

1 −k−1
i=1
eγit

.
The k −1 dimensional linear predictor vector ηt maps the mean vector E(yt) via
the canonical link and transition equations
ηt =
⎡
⎢⎢⎢⎢⎢⎢⎣
log
π1t
1−k−1
i=1 πit
log
π2t
1−k−1
i=1 πit
...
log
πk−1,t
1−k−1
i=1 πit
⎤
⎥⎥⎥⎥⎥⎥⎦
= x⊤
t βt,
(6.18)
βt = Ftβt−1 + ζt,
ζt ∼N(0, Zt).
(6.19)
Here xt is a p × (k −1) design matrix, βt is the p-dimensional state vector, Ft is
the p × p transition matrix and Zt is the p × p transition covariance matrix. We
note that for two categories k = 2 the multinomial model (6.17)–(6.19) reduces
to the binomial model (6.14)–(6.16). Hence the multinomial model is a direct
generalisation of the binomial model and is suitable for modelling multi-categorical
data.
6.2.4
Continuous Proportions
In Sect. 6.2.3 we discuss models for categorical data, which may be used to make
inference for proportions, e.g. by considering the proportion yt/λt in the binomial
model (6.14). Sometimes this is referred to as discrete proportion, because it is
based on discrete observations yt and the totals λt. In this set-up the total λt is
assumed known and the focus of the inference is placed on the count yt. However,
we may wish to model directly the proportion, for example if such a proportion

272
6
Non-Linear and Non-Gaussian State Space Models
is observed rather than the counts. In other situations we may wish to make
inference regarding some probability, not necessarily being a proportion, or any
other measurable quantity which takes values in the interval [0, 1]. For convenience
such measurements are known as continuous proportions, although as noted above,
strictly speaking, they may not be restricted to proportions.
Consider that yt denotes observations taking values in the interval [0, 1], for any
time t. A natural distribution to describe such observations is the beta distribution,
hence the observation model is
p(yt | α1t, α1t) = (α1t + α2t)
(α1t)(α2t)yα1t−1
t
(1 −yt)α2t−1,
(6.20)
where α1t, α2t > 0 are time-varying parameters and (·) is the gamma function; the
beta distribution is discussed in Sect. 2.3.3.
Without loss in clarity, we omit the conditioning on αit in the density (6.20). This
beta distribution can be written as
p(yt) = exp

α1t log yt −log (α1t + α2t)
(α1t)(α2t) + (α2t −1) log(1 −yt) −log yt

,
which is in the form of (6.4), with at = 1, z(yt) = log yt, γt = α1t, b(γt) =
−log[(γt)−1(α2t)−1(γt + α2t)], c(yt) = (α2t −1) log(1 −yt) −log yt.
Given α1t, α2t the mean of yt is μt = E(yt | α1t, α2t) = α1t(α1t + α2t)−1 and so
the logarithmic link can be used, leading to the link and transition equations
ηt = log

α1t
α1t + α2t
	
= x⊤
t βt
(6.21)
βt = Ftβt−1 + ζt,
ζt ∼N(0, Zt),
(6.22)
with the usual deﬁnitions of βt, ζt, Ft and Zt.
The state space model (6.20)–(6.22) can be generalised to account for several
correlated proportions. Considering k ≥2 categories, let yt = [y1t, . . . , yk−1,t]⊤
be a vector of k −1 continuous proportions and αt = [α1t, . . . , αkt]⊤be a vector
of k positive parameters. The joint effects of y1t, . . . , yk−1,t can be described by
the Dirichlet distribution, which is a generalisation of the beta distribution and its
density is
p(yt | αt) =
1
D(αt)
k−1
-
i=1
yαit−1
it

1 −
k−1

i=1
yit
αkt−1
,
(6.23)

6.2
Dynamic Generalised Linear Models
273
where D(αt) denotes the Dirichlet function, which can be expressed as functions of
gamma functions
D(αt) =
5k
i=1 (αit)

k
i=1 αit
.
This distribution can be expressed as
p(yt | αt) = exp
 k−1

i=1
αit log yit −log D(αt) + (αkt −1) log

1 −
k−1

i=1
yit

−
k−1

i=1
log yit
!
,
which is in the form of (6.4), with at = 1, z(yt) = [log y1t, . . . , log yk−1,t]⊤, γt =
[α1t, . . . , αk−1,t]⊤, b(γt) = log D(αt) and c(yt) = (αkt −1) log

1 −k−1
i=1 yit

−
k−1
i=1 log yit.
It can be shown that, conditional on αt, the mean of yt
is μt
=
[μ1t, . . . , μk−1,t]⊤, with μit = αit(α1t + · · · + αkt)−1. As a result the logarithmic
link can be used to map the mean μit to the real line, leading to the link and
transition equations
ηt =
⎡
⎢⎢⎢⎢⎢⎣
log
α1t
k
i=1 αit
log
α2t
k
i=1 αit
...
log
αk−1,t
k
i=1 αit
⎤
⎥⎥⎥⎥⎥⎦
= x⊤
t βt
(6.24)
βt = Ftβt−1 + ζt,
ζt ∼N(0, Zt).
(6.25)
We note that for k = 2 categories the above model reduces to the beta model (6.20)–
(6.22).
6.2.5
Decomposition of Dynamic Generalised Linear Models
Decomposition of linear and Gaussian state space models is discussed in Sect. 4.2.2.
Based on the assumption of observability, the mean response μt of the model
(3.10a)–(3.10b) is decomposed into a sum of component state space models. This
approach can be extended to the class of dynamic generalised model (6.4)–(6.6) (see
Sect. 6.2.1). We will assume that the model is observable, or that by extending the

274
6
Non-Linear and Non-Gaussian State Space Models
deﬁnition of linear state space models (see Sect. 3.5.1) that the rank of the p × p
observability matrix
O =
⎡
⎢⎢⎢⎣
x⊤
x⊤F
...
x⊤Fp−1
⎤
⎥⎥⎥⎦
is p. With this assumption in place we have that the linear predictor ηt is
decomposed into a sum of ℓcomponent state space models
ηt = χ(1)
t
+ χ(2)
t
+ · · · + χ(ℓ)
t
,
(6.26)
χ(j)
t
= e⊤
1 γjt,
(6.27)
γjt = C(j)γj,t−1 + ξjt,
j = 1, . . . , ℓ,
(6.28)
with model components γjt, e1, C(j) and ξjt deﬁned as in Sect. 4.2.2. The
decomposition of the Gaussian state space model of Sect. 4.2.2 is obtained as a
special case of the above decomposition, since in that case ηt = μt (the link function
g(μt) is the identity function).
The decomposition (6.26)–(6.28) implies that
E(yt | γt) = μt = g−1 
χ(1)
t
+ χ(2)
t
+ · · · + χ(ℓ)
t

.
For example if the logarithmic link g(μt) = log μt is used (Poisson, gamma,
exponential, inverse gamma), then
E(yt | γt) =
ℓ
-
j=1
exp

χ(j)
t

and the decomposition can be thought of as multiplicative.
6.3
Other Non-Gaussian and Non-linear Models
In Sects. 6.2.2, 6.2.3 and 6.2.4 dynamic generalised linear models are described for
speciﬁc types of non-Gaussian time series data, i.e. counts, categorical observations
and proportions. The list is easily extended to other types of data, in which
observation model can be described by any member of the exponential family (6.4).
Some further examples are provided in the exercises in the end of the chapter.
However, data may not be described by a distribution that belongs to the exponential

6.3
Other Non-Gaussian and Non-linear Models
275
family. We have already met two such examples in Chap. 1. In particular, the state
space model (1.15)–(1.16) of Sect. 1.3.3 is a conditional Gaussian state space model,
since, conditional on the states βt, the return series yt follows a Gaussian distribution
yt | βt ∼N[0, exp([1, 0]βt)],
(6.29)
where the bivariate state vector is βt = [ht, 1]⊤and ht is the logarithm of the
volatility; see Sect. 1.3.3 for details. Conditionally on the past states βt−1, the
distribution of βt is Gaussian: βt | βt−1 ∼N(Fβt−1, Z), for some transition matrix
F and covariance matrix Z. In Sect. 1.3.3 the motivation for this model is discussed
in some detail.
Another conditionally Gaussian state space model is described in Sect. 1.3.2. In
particular, given states βt, the observations zt (angular process) follow a Gaussian
distribution
zt | βt ∼N

arctan
[0, 1, 0, 0]βt
[1, 0, 0, 0]βt
	
, σ 2

,
(6.30)
for some variance σ 2. Given past states βt−1, βt follows a Gaussian distribution:
βt | βt−1 ∼N(Fβt−1, Z), for some transition matrix F, which is provided in (1.11)
and some covariance matrix Z.
Finally we give an example of a non-Gaussian and non-linear time series model,
which is not conditionally Gaussian and does not belong to the class of dynamic
generalised linear models (DGLM). Consider the above stochastic volatility model,
but replace the Gaussian distribution in Eq. (6.29) by a Student t distribution, so that
yt | βt ∼t[ν, 0, exp([1, 0]βt)],
(6.31)
where ν > 0 denotes the degrees of freedom, and the evolution of βt follows the
usual linear and Gaussian law, described above, i.e. βt = Fβt−1 + ζt. This state
space model is not conditionally Gaussian, since given βt, the distribution of yt is
a Student t distribution, and it is not a DGLM, since the Student t distribution is
not a member of the exponential family of distributions. Nevertheless, this is a more
plausible stochastic volatility model than the one described earlier and in Sect. 1.3.3,
because it enables yt to have heavy tails (depending on the value of ν), which is
a desirable property, since ﬁnancial returns typically exhibit heavier tails than the
Gaussian distribution.
In the following sections we describe inference for non-linear and non-Gaussian
state space models; the list is not exhaustive and it covers exact inference for a
restricted class of models (Sect. 6.5), approximate inference for a wide class of
models (Sect. 6.6) and simulation-based inference (Sect. 6.7). We start by describing
ﬁrst the general formulation for estimation and forecasting.

276
6
Non-Linear and Non-Gaussian State Space Models
6.4
Inference for the General State Space Model
Consider the general non-linear and non-Gaussian state space model (6.3) and let
y1:t = (y1, . . . , yt) be a collection of observations. Suppose that at time t −1 the
posterior distribution p(βt−1 | y1:t−1) of βt−1 is known. Then the prior distribution
of βt is
p(βt | y1:t−1) =
"
A
p(βt | βt−1)p(βt−1 | y1:t−1) dβt−1,
(6.32)
where A, the domain of βt, is a subset of Rp. The distribution of p(βt | βt−1) is
the transition model in (6.3) and the distribution p(βt−1 | y1:t−1) is assumed to be
known. Hence the integral may be computed.
Given information y1:t−1, the one-step forecast distribution of yt is provided by
the integral
p(yt | y1:t−1) =
"
B
p(yt | βt)p(βt | y1:t−1) dβt−1,
(6.33)
where B is the domain of yt. The distribution p(yt | βt) is provided by the
observation model in (6.3) and the distribution p(βt | y1:t−1) is provided by (6.32).
Hence p(yt | y1:t−1) may be computed by the above integral.
When yt is observed, the collection of data y1:t−1 is updated to include yt, i.e.
y1:t = (y1, . . . , yt) and by an application of the Bayes theorem
p(βt | y1:t) = p(yt | βt)p(βt | y1:t−1)
p(yt | y1:t−1)
,
(6.34)
the posterior distribution of βt can be obtained. Starting at time t = 0 with the
assumed prior p(β0), this process is repeated sequentially to obtain the posterior
distributions p(βt | y1:t), for any t = 1, 2, . . .. For example in the linear and
Gaussian state space model (3.10a)–(3.10b) integrals (6.32) and (6.33) are obtained
in closed form and together with (6.34) provide the Kalman ﬁlter recursions of
Theorem 3.2.
However, moving away from the linear and Gaussian state space model, integrals
(6.32) and (6.33) are not available in closed form and this prevents the calculation
of the posterior distribution of βt in (6.34). There might be only special and limited
models for which the above calculations will be obtained in closed form. For the
general and often most interesting cases we shall resort to approximations or to
simulation-based inference.

6.5
Power Local Level Models
277
6.5
Power Local Level Models
6.5.1
Motivation and Main Model Structure
In this section we brieﬂy describe the class of the so-called power local level models,
which were ﬁrst proposed by Smith (1979) and Harvey and Fernandes (1989) and
primarily initiated research efforts on non-Gaussian state space modelling. These
models are further developed in Smith (1981) and Smith and Miller (1986), but
their applicability is somewhat limited to state transitions that resemble a random
walk process. These models are similar in nature with the work of Gamerman et al.
(2013) who propose a new class of non-Gaussian state space models constructed in
such a way to allow exact computation of the marginal likelihood. This approach
deploys the gamma-beta conjugacy, used also in Smith and Miller (1986) and in
Shephard (1994a), but extends it in order to accommodate a wide class of response
distributions.
The idea of Bayesian inference with a prior-posterior facility for non-Gaussian
models is developed in the late 1970s with the path-breaking work of Diaconis and
Ylvisaker (1979). These authors adopt the so-called conjugate prior for independent
observations generated by a response distribution in the exponential family.
Considering the general state space model (6.3) Smith (1979) motivates transi-
tion laws based on the random walk of the Gaussian linear state space model, deﬁned
by
yt = βt + ϵt
and
βt = βt−1 + ζt,
where ϵt ∼N(0, σ 2) and ζt ∼N(0, Zt), for some variances σ 2 and Zt and
remaining assumptions as in the state space model (3.10a)–(3.10b). For this model,
adopting the discounting approach to specify Zt as in Sect. 4.3, the prior distribution
of βt+1 in the Kalman ﬁlter (see Theorem 3.2) can be written as
p(βt = β | y1:t−1) =
1
'2πPt|t−1
exp

−(β −ˆβt|t−1)2
2Pt|t−1
+
= ct
 
1
'2πPt−1|t−1
exp

−(β −ˆβt−1|t−1)2
2Pt−1|t−1
+!δ
= ctp(βt−1 = β | y1:t−1)δ,
(6.35)
where Pt|t−1 = Pt−1|t−1/δ is used, for a discount factor 0 < δ ≤1, and the
constant ct = δ1/2(2πPt−1|t−1)−(1−δ)/2 does not depend on β. Equation (6.35)
indicates that, given information y1:t−1, the prior distribution of βt is ﬂatter than
the posterior distribution of βt−1, which reﬂects on the increased uncertainty, i.e.
Var(βt | y1:t−1) = Pt−1|t−1 + Zt = Pt−1|t−1/δ ≥Pt−1|t−1 = Var(βt −1 | y1:t−1).

278
6
Non-Linear and Non-Gaussian State Space Models
Moving on to the non-Gaussian model (6.3), Smith (1979) deﬁnes the power
local level models as a dynamic model whose transition density p(βt | βt−1)
satisﬁes
p(βt = β | y1:t−1) = ctp(βt−1 = β | y1:t−1)δ,
(6.36)
for some deterministic (constant) ct and a discount factor 0 < δ ≤1. The law (6.36)
suggests that, conditional on information y1:t−1, the prior of βt is ﬂatter than the
posterior of βt−1. It turns out that for a wide class of observation models p(yt | βt)
of (6.3), one does not need to know precisely the value of the constant ct, as this
is implied by the structure of (6.36). Such a modelling framework is discussed here
by considering that p(yt | βt) is a member of the exponential family (6.4) and is
detailed as follows.
First note that through the link function g(·) of Eq. (6.5) the prior and posterior
distributions of βt yield prior and posterior distributions of the natural parameter
γt. Hence we work with γt, as it is more convenient to form the prior distribution.
Suppose that at time t −1, the posterior distribution of γt−1 is
p(γt−1 = γ | y1:t−1) = κ(rt−1, st−1) exp[r⊤
t−1γ −st−1b(γ )],
(6.37)
for some parameter vector rt−1 and scalar st−1, where b(γ ) is provided in the
observation model equation (6.4) and κ(rt−1, st−1) is the proportionality constant,
i.e.
κ(rt−1, st−1) =

"
A
exp{r⊤
t−1γ −st−1b(γ )} dγ
−1
and A being the domain of γ .
At time t, the prior of γt is obtained by adopting prior (6.36) with the posterior
(6.37) as
p(γt = γ | y1:t−1) = ctκ(rt−1, st−1)δ exp[δr⊤
t−1γ −δst−1b(γ )].
This prior distribution is known as conjugate prior having the property that prior
p(γt = γ | y1:t−1) and posterior p(γt−1 = γ | y1:t−1) belong to the same
family of distributions; we shall write γt | y1:t−1 ∼CP(δrt−1, δst−1) to denote
this distribution. Conjugate prior distributions for the exponential family were
introduced in Diaconis and Ylvisaker (1979) and are discussed in Robert (2007).
At time t as the observation yt becomes available, the posterior distribution of γt
is updated by an application of the Bayes theorem
p(γt | y1:t) ∝p(yt+1 | γt)p(γt | y1:t−1)
∝exp
z(yt)
at
+ δrt−1
	⊤
γt −
 1
at
+ δst−1
	
b(γt)
+
= exp[r⊤
t γt −stb(γt)].

6.5
Power Local Level Models
279
This establishes that rt = a−1
t
z(yt) + δrt−1, st = a−1
t
+ δst−1, so that γt | y1:t ∼
CP(rt, st). Assuming some prior values for r0, s0, the recursions of rt and st above,
together with the prior (6.36) and the posterior (6.37) provide a sequential algorithm
over time t = 1, 2, . . .. In the next section two speciﬁc models are used to illustrate
the application of this algorithm.
We close this section by discussing a key result of the power local level model.
Theorem 6.1 Let the time series {yt} follow the power local level model governed
by (6.36). Let the prior and the posterior distributions of the state vector βt be
differentiable and unimodal. Then, given information y1:t, the mode of βt+1 is the
same as the mode of βt.
Proof Let ˆβt be the mode of βt, given y1:t. From Eq. (6.36) we obtain
∂log p(βt+1 = β)
∂β
= δ ∂log p(βt = β)
∂β
and since ˆβt is the mode of βt we get
∂log p(βt+1 = β)
∂β
2222
β= ˆβt
= 0,
hence ˆβt is also the mode of βt+1.
⊓⊔
Some comments are in order. Theorem 6.1 provides a key property of the power
local level model. Basically is suggests that for a wide class of differentiable and
unimodal prior and posterior distributions, the mode is invariant going from time t
to t +1 with the same information. This proposes a local level evolution of the states
βt, which resembles that of the random walk in the Gaussian local level model, see
Sect. 3.1.3. The name local level originates by this local level evolution of the states,
while the word power reﬂects the power law in (6.36). In the Gaussian local level
model the mode invariance is the same as a mean invariance, written as E(βt+1 |
y1:t) = E(βt | y1:t) and the power law (6.36) in this case is given by (6.35). Below
we discuss a power local level for count data and we verify Theorem 6.1 for that
model.
6.5.2
Poisson-Gamma and Exponential-Gamma Models
Consider the Poisson model (6.8) of Sect. 6.2.2. Suppose that at time t the posterior
of λt is a gamma distribution λt−1 | y1:t−1 ∼G(αt−1, βt−1), for some αt−1, βt−1 >
0; here βt−1 is just the second parameter (known as rate) of the gamma distribution
and should not be confused with the states of the state space model. Then, applying

280
6
Non-Linear and Non-Gaussian State Space Models
the power law (6.36), we get that the prior of λt is
p(λt = λ | y1:t−1) = ctp(λt−1 = λ | y1:t−1)δ
= ct
 
βαt−1
t−1
(αt−1)λαt−1−1 exp(−βt−1λ)
!δ
∝λδαt−1+1−δ−1 exp(−δβt−1λ),
so that the prior λt is the gamma distribution λt | y1:t−1 ∼G(δαt−1 +1−δ, δβt−1).
Upon observing yt, the posterior distribution of λt is revised using Bayes theorem
as
p(λt | y1:t) ∝p(yt | λt)p(λt | y1:t−1)
∝λδαt−1+1−δ+yt−1
t
exp{(δβt−1 + 1)λt},
so that λt | y1:t ∼G(αt, βt), with
αt = δαt−1 + 1 −δ + yt
and
βt = δβt−1 + 1.
Before we proceed with forecasting, we verify Theorem 6.1 for this model. By
noting that the mode of a random variable following the gamma distribution G(α, β)
is (α −1)/β, we have
mode(λt+1 | y1:t) = δ(αt −1)
δβt
= αt −1
βt
= mode(λt | y1:t),
which establishes the mode invariance as we are moving from time t to t + 1 with
the same information y1:t. Note that the conditions of Theorem 6.1 are met as the
density of the gamma distribution is differentiable and unimodal.
With the posterior distribution of λt in place, the one-step forecast distribution of
yt+1 is
p(yt+1 | y1:t) =
" ∞
0
p(yt+1 | λt+1)p(λt+1 | y1:t) dλt+1
=
(δβt)δαt+1−δ
(δαt + 1 −δ)yt+1!
" ∞
0
λδαt+1−δ−1 exp[−(δβt + 1)λt+1] dλt+1
=
(δβt)δαt+1−δ(δαt + 1 −δ + yt+1)
(δαt + 1 −δ)yt+1!(δβt + 1)δαt+1−δ+yt+1
=
n + y −1
y
	 
a
1 + a
	n 
1
1 + a
	y
,

6.5
Power Local Level Models
281
with n = δαt + 1 −δ, y = yt+1 and a = δβt. Here we have made use of the gamma
integral of Eq. (4.60) and
(n + y)
y!(n)
=
n + y −1
y
	
,
see also Exercises 7 and 8. Hence the one-step forecast distribution of yt+1 is a
negative binomial distribution yt+1 | y1:t ∼NegBinom(n, a).
So far we have adopted the power law (6.36), which implies a local-level type
evolution of λt, but an explicit transition of λt is not derived. Such evolution of λt
is supported (see Exercise 5) by the multiplicative evolution
λt = λt−1ξt
δ
,
(6.38)
where λt−1 | y1:t−1 ∼G(αt−1, βt−1), ξt is a random variable, which is independent
of λt−1 and follows the beta distribution ξt ∼Beta[δαt−1, (1 −δ)αt−1]. This
evolution was ﬁrst proposed in Smith and Miller (1986) and further deployed in
Shephard (1994a) for a non-Gaussian state space model with exponential or gamma
responses; a similar model is described below.
Suppose that non-negative observations are collected over time. Such data may
be records of athletes, such as those discussed in Smith and Miller (1986), which are
non-negativeand take values in [0, +∞). We can also motivate data of this sort from
many ﬁelds, such as environmetrics, where observations may represent pollutant or
temperature readings, or economics, where observations may represent volatility
(all this data take non-negative values). Returning to the records, a plausible model
to describe the non-negative time series yt is the exponential model, so that given a
state λt, the response yt is assumed to follow an exponential distribution with rate
λt, or
p(yt | λt) = λt exp(−λtyt),
for some λt > 0. Assuming that at time t −1 the posterior distribution of λt−1 is
a gamma distribution, λt−1 | y1:t−1 ∼G(αt−1, βt−1), for some known parameters
αt−1, βt−1 > 0, we can apply the power law as above and obtain exactly the same
expressions of the prior and posterior distribution of λt in the Poisson model above,
i.e. the posterior distribution of λt is λt | y1:t ∼G(αt, βt), with αt = δαt−1+yt and
βt = δβt−1 + 1. This is because the same gamma distribution for λt is applied in
both models. Consequently, the transition law (6.38) is established, as is discussed
in Smith and Miller (1986); see also Exercise 5. With the posterior of λt in place,

282
6
Non-Linear and Non-Gaussian State Space Models
we can derive the one-step ahead forecast distribution of yt+1 as
p(yt+1 | y1:t) =
" ∞
0
p(yt+1 | λt+1)p(λt+1 | y1:t) dλt+1
= (δβt + yt+1)δαt+2−δ
(δαt + 2 −δ)
,
the full derivation of which is left to the reader as an exercise.
6.6
Approximate Inference
6.6.1
Motivation and Methodology
In this section we discuss approximate inference for a conditional Gaussian state
space model (6.2). The non-linear functions f (·) and g(·) of model (6.2) are
approximated by a ﬁrst order Taylor expansion, and hence approximating the non-
linear model (6.2) as a linear and Gaussian one.
Consider the state space model (6.2) where the observation covariance matrix
Var(ϵt) =  and the transition covariance matrix Var(ζt) = Zt are assumed known.
Suppose that at time t −1 the posterior mean vector of βt−1 is approximated as
ˆβt−1|t−1 ≈E(βt−1 | y1:t−1) and it is available. The function g(βt−1) can be
approximated using a Taylor expansion around the vector ˆβt−1|t−1 as
g(βt−1) ≈g( ˆβt−1|t−1) + ∂g(βt−1)
∂βt−1
2222
βt−1= ˆβt−1|t−1
(βt−1 −ˆβt−1|t−1)
after ignoring second and higher order terms. Thus, the transition equation of βt in
(6.2) is approximated as
βt ≈∂g(βt−1)
∂βt−1
2222
βt−1= ˆβt−1|t−1
βt−1 + νt + ζt,
(6.39)
where νt = g( ˆβt−1|t−1) −[∂g(βt−1)/∂βt−1]βt−1= ˆβt−1|t−1 ˆβt−1|t−1. Now we can see
that the prior mean vector of βt is approximated as ˆβt|t−1 = E(βt | y1:t−1) ≈
[∂g(βt−1)/∂βt−1]βt−1= ˆβt−1|t−1 ˆβt−1|t−1 + νt = g( ˆβt−1|t−1).
Provided the availability of ˆβt|t−1 as above, we use a second Taylor expansion
around ˆβt|t−1 to approximate f (βt) in the observation equation as
f (βt) ≈f ( ˆβt|t−1) + ∂f (βt)
∂βt
2222
⊤
βt= ˆβt|t−1
(βt −ˆβt|t−1),

6.6
Approximate Inference
283
after ignoring second and higher order terms as before. Thus, the observation
equation of model (6.2) is approximated as
yt = ∂f (βt)
∂βt
2222
⊤
βt= ˆβt|t−1
βt + μt + ϵt,
(6.40)
where μt = f ( ˆβt|t−1) −[∂f (βt)/∂βt]⊤
βt= ˆβt|t−1
ˆβt|t−1.
The linear state space model (6.39)–(6.40) is an approximation of the non-linear
model (6.2). Indeed we can write
yt ≈x⊤
t βt + εt
and
βt ≈Ftβt−1 + ηt,
(6.41)
where the design matrix xt and the transition matrix Ft are equal to
xt = ∂f (βt)
∂βt
2222
βt= ˆβt|t−1
and
Ft = ∂g(βt−1)
∂βt−1
2222
βt−1= ˆβt−1|t−1
,
and the innovations εt and ηt have mean vectors μt and νt and covariance matrices
 and Zt, respectively, i.e. εt ∼N(μt, ) and ηt ∼N(νt, Zt). The state space
model (6.41) is very similar to the multivariate models of Chap. 5 (see model
(5.1a)–(5.1b)), the only difference being the non-zero mean vectors of εt and ηt.
The Kalman ﬁlter used to estimate the state vectors βt in Chap. 5 can be updated
to accommodate for a non-zero mean of the innovations εt and ηt. It is relatively
easy to verify that the Kalman ﬁlter recursions of Theorem 5.1 are still applied if we
modify ˆβt|t−1 and ˆyt|t−1 as
ˆβt|t−1 = Ft ˆβt−1|t−1 + νt
and
ˆyt|t−1 = x⊤
t ˆβt|t−1 + μt,
where μt and νt are the mean vectors of εt and ηt deﬁned above. Thus, with the
linearised state space model (6.41) we can obtain the posterior distribution of βt
given y1:t as well as we can routinely forecast future values of yt+h, for some h ≥1.
Some comments are in order. We observe that in the linear case f (βt) = x⊤
t βt
and g(βt−1) = Ftβt−1. In this case the derivatives of f (βt) and g(βt−1) yield just xt
and Ft, respectively, and hence μt = 0, νt = 0. This implies that the approximations
are exact as expected.
When at least one of f (βt) and g(βt−1) are non-linear the above approximation
comes into play. In most practical situations g(βt−1) will still be linear, as it
describes a viable Markov evolution which may well be linear. As a result we may
have f (βt) to be non-linear on βt, but g(βt−1) = Ftβt−1 being linear on βt−1. The
empirical motivation here could be that it is hard to anticipate or specify a priori a
non-linear relationship of the unobserved state evolution {βt}, while we shall have
more information on the observation linking the data {yt} with the states {βt}.

284
6
Non-Linear and Non-Gaussian State Space Models
6.6.2
Tracking a Ship
In this section we consider the bearings-only tracking problem, described in some
detail in Sect. 1.3.2. In Sect. 6.3, it is shown that zt, the time series deﬁned as
zt = arctan(xt/yt), where xt is the position of the ship in the x-axis at time t and
yt its position in the y-axis at time t, follows a conditionally Gaussian state space
model (6.2) with
f (βt) = arctan
[0, 1, 0, 0]βt
[1, 0, 0, 0]βt
	
and the four-dimensional state vector βt, which is deﬁned in Sect. 6.3, follows a
random walk so that Ft = I.
In order to use the approximate inference of Sect. 6.6.1 above, we need the partial
derivative of f (βt) with respect to βt. By using the chain rule of differentiation we
obtain
∂f (βt)
∂βt
=
 
1 +
[0, 1, 0, 0]βt
[1, 0, 0, 0]βt
	2!−1
([1, 0, 0, 0]βt)−1
×
∂[0, 1, 0, 0]βt
∂βt
−∂[1, 0, 0, 0]βt
∂βt
[0, 1, 0, 0]βt
	
=
3
([1, 0, 0, 0]βt)2 + ([0, 1, 0, 0]βt)24−1
⎡
⎢⎢⎣
0 −1 0 0
1 0 0 0
0 0 0 0
0 0 0 0
⎤
⎥⎥⎦βt
= (2β⊤
t βt)−1
⎡
⎢⎢⎣
0 −1 0 0
1 0 0 0
0 0 0 0
0 0 0 0
⎤
⎥⎥⎦βt
Thus, using the ﬁrst order Taylor expansion of f (βt) around ˆβt|t−1, the observa-
tion equation is approximated as
zt ≈
ˆβ⊤
t|t−1
2 ˆβ⊤
t|t−1 ˆβt|t−1
⎡
⎢⎢⎣
0 1 0 0
−1 0 0 0
0 0 0 0
0 0 0 0
⎤
⎥⎥⎦βt + εt,
(6.42)

6.6
Approximate Inference
285
where εt ∼N(μt, σ 2) and
μt = arctan

[0, 1, 0, 0] ˆβt|t−1
[1, 0, 0, 0] ˆβt|t−1

−(2 ˆβ⊤
t|t−1 ˆβt|t−1)−1 ˆβ⊤
t|t−1
⎡
⎢⎢⎣
0 1 0 0
−1 0 0 0
0 0 0 0
0 0 0 0
⎤
⎥⎥⎦ˆβt|t−1
The random walk transition is βt = βt−1 + ζt, where ζt ∼N(0, Z), for some
covariance matrix Z. This transition together with the observation equation (6.42)
provide the linearised state space model of the non-linear model (1.10)–(1.11),
where we have used F = I. In this model σ 2 and Z are assumed known and an initial
state β0 ∼N( ˆβ0|0, P0|0) is considered. With this setting in place the Kalman ﬁlter
applies providing an approximate posterior mean vector ˆβt|t and covariance matrix
Pt|t. This approximate estimation algorithm beneﬁts from the rich availability of
estimation in linear state space models, e.g. σ 2 and Z can be estimated using the
forward ﬁltering backward sampling MCMC scheme, described in Sect. 5.7.
6.6.3
The Extended Kalman Filter
Historical note. The extended Kalman ﬁlter (EKF) was ﬁrst developed in the
signiﬁcant work of Stanley F. Schmidt at the Ames Research Centre at NASA.
In 1960 Kalman visited Schmidt to present his approach of sequential ﬁltering
(Kalman, 1960). Schmidt and his colleagues were interested in Kalman’s work
because the new methodology was able to solve sequentially the ﬁltering problem,
without relying on stationarity. However, the assumption of normality seemed to
be an obstacle for the target application, part of the Apollo project. Schmidt and
his colleagues modiﬁed the Kalman ﬁlter to what is now known as the extended
Kalman ﬁlter. McGee and Schmidt (1985) and Schmidt (1981) discuss the story
around the discovery of the EKF and how it was applied for the Apollo project.
From dynamic systems point of view the EKF is discussed in Sect. 8.4.4; see also
Grewal and Andrews (2010).
Conditionally Gaussian state space models (6.2), as described above, is a large
class of non-linear state models. However, this class of models is limited to
Gaussian innovations forcing the response yt to be conditionally Gaussian. Such
an assumption restricts the applicability of these models, as the distribution of
many time series exhibit departure from normality. For example, in Sect. 6.2 we
describe dynamic generalised linear models (DGLM), with response belonging
to the exponential family of distributions. It is therefore necessary to consider
non-Gaussian time series analysis; the power local level models of Sect. 6.5 is a
ﬁrst attempt towards this direction. However, the power local level is restricted
to transitions of the states around a local level and do not permit more general
transitions, such as those considered in the previous chapters for the Gaussian

286
6
Non-Linear and Non-Gaussian State Space Models
models or those for the DGLM. In Sect. 6.7 we discuss modern Monte Carlo
inference for such models; in this section we provide a simple solution to the non-
Gaussian and non-linear state space model estimation, which is known as extended
Kalman ﬁltering. EKF is described and further applied in Fahrmeir (1992) and in
Fruhwirth-Schnatter (1994a) among other studies; a book length discussion can be
found in Fahrmeir and Tutz (2001).
Consider the general state space model (6.3), where for simplicity we shall
assume that the transition equation is linear and Gaussian, i.e.
βt = Ftβt−1 + ζt,
ζt ∼N(0, Zt),
(6.43)
exactly as in the Gaussian case discussed in detail in the previous chapters.
We shall be interested in observations generated by a non-linear and non-
Gaussian model and in particular we consider that conditionally on a state βt, yt
follows some distribution with mean vector f (βt) and some covariance matrix
Vt, which may depend on βt. Extended Kalman ﬁltering considers a rough
approximation of that distribution by a Gaussian distribution with mean vector
f (βt) and covariance matrix Vt. Hence, the response distribution approximation
states that
yt ≈f (βt) + ϵt,
ϵt ∼N(0, Vt),
(6.44)
so that
E(yt | βt) = f (βt)
and
Var(yt | βt) = Vt.
The working model is the conditional Gaussian state space model (6.43)–(6.44), for
which the theory of Sect. 6.6.1 may be applied. As a result the extended Kalman
ﬁlter (EKF) proposes two approximations: in the ﬁrst the non-Gaussian response
distribution is approximated by a Gaussian distribution matching the mean vector
and the covariance matrix of the non-Gaussian one; in the second approximation
the non-linear function f (βt) is approximated by a ﬁrst order Taylor series in order
to linearise the model and hence the Kalman ﬁlter may then be applied. Care must
be applied as non-linearities in f (βt) and poor approximation of the distribution of
ytβt by its ﬁrst two moments might result in signiﬁcant errors and poor performance
of the Kalman ﬁlter. Below we give a basic example illustrating the applicability of
EKF.
For example consider the Poisson time series (6.8) described in Sect. 6.2.2. From
the Poisson distribution (see also Sect. 2.3.2) we have
E(yt | βt) = f (βt) = exp(x⊤
t βt)
and
Vt = exp(x⊤
t βt)
where xt is the design vector and βt is the state vector following the transition
equation βt = Fβt−1 + ζt and the usual assumptions and component deﬁnitions
described in (6.8). Here, as yt is scalar, xt is a column vector and Vt, which depends

6.6
Approximate Inference
287
implicitly on βt, is a variance. Thus, the Poisson model (6.8) is approximated by the
conditionally Gaussian state space model
yt ≈f (βt) + ϵt = exp(x⊤
t βt) + ϵt,
ϵt ∼N(0, Vt),
and βt = Fβt−1 + ζt. Proceeding to the approximation of f (βt) as described in
Sect. 6.6.1 we have
∂f (βt)
∂βt
= exp(x⊤
t βt)xt
Following the theory of conditionally Gaussian in Sect. 6.6.1 suppose that at time
t −1 the posterior distribution of βt−1 is approximated by a N( ˆβt−1|t−1, Pt|t−1),
for some mean vector ˆβt−1|t−1 and covariance matrix Pt|t−1. From the transition
equation of βt we obtain the approximate prior mean vector ˆβt|t−1 and covariance
matrix Pt|t−1 of βt, from the Kalman ﬁlter recursions (see Theorem 5.1 of Chap. 5).
With these moments in place, yt is approximated by the Gaussian linear state
space model
yt ≈exp(x⊤
t ˆβt|t−1)x⊤
t βt + εt,
(6.45)
where εt ∼N(μt, ˆVt), with
μt = exp(x⊤
t ˆβt|t−1)(1 −x⊤
t ˆβt|t−1)
and
ˆVt = exp(x⊤
t ˆβt|t−1)
and βt follows the linear transition βt = Fβt−1 + ζt. Model (6.45) together with the
transition of βt provide a linear and Gaussian state space model, an approximation
of the non-linear and non-Gaussian state space model (6.8).
6.6.4
The Unscented Kalman Filter
The extended Kalman ﬁlter described above is able to deal with non-linear ﬁltering,
but it is reported to have large cumulative state and forecast errors, which may lead
to poor performance overall (Wan & Van Der Merwe, 2000). This is particularly
prevalent when complex non-linearities in the function f (·) are observed, in a way
that ﬁrst-order Taylor series approximation is a poor approximation of the system.
Efforts to deal with the non-linear modelling, but go beyond the extended
Kalman ﬁlter, usually involve non-linear ﬁlter heuristics. These methods usually
deploy either the standard Kalman ﬁlter or the extended Kalman ﬁlter, coupled
with heuristic features in order to deal with system non-linearities, see e.g. Saab
(2004). One of the standard approaches is the introduction of so-called sigma points
and associated weights, which are chosen in such a way so that to concentrate
around the high-probability regions of the posterior distribution of the states. The

288
6
Non-Linear and Non-Gaussian State Space Models
choice of these points and weights is very much the topic of current research and
computational implementation efforts, see e.g. Saab (2004), Ponomareva and Date
(2013), Radhakrishnan et al. (2018), Pakrashi and Namee (2019) and references
therein. Since its discovery the unscented transformation and unscented Kalman
ﬁlter have been extended and enriched by improving its performance (usually by
making a clever determination of the sigma points), see e.g. Julier (2002), Julier and
Uhlmann (2004) and references mentioned above. The UKF is used in sequential
Monte Carlo (see Sect. 6.7 below) combined with Markov chain Monte Carlo steps
in order to choose more accurately the importance function (Van Der Merwe et al.,
2001).
The unscented Kalman ﬁlter (UKF) aims to improve on the second moment
approximation (mean and variance) of the EKF described above. The UKF, intro-
duced by Julier and Uhlmann (1997), uses the so-called unscented transformation
in order to calculate approximations of the mean vector and covariance matrix of
the posterior distribution of the states. While, the EKF uses a ﬁrst order Taylor
expansion to approximate the non-linear state space by a linear one, the UKF
introduces sigma points and weights from a high probability region of the posterior
distribution of the states in close proximity of the posterior mean of the states.
In its original version Julier and Uhlmann (1997) consider ﬁrst the unscented
transformation,which is basically approximating the mean and variance of a random
variable, which undergoes a non-linear transformation. the UT is achieved in such a
way that the sample mean and sample variance of the transformed random variable
match the true mean and variance. Suppose that the p-dimensional column random
vector x has sample mean vector ¯x and sample covariance matrix Vx. We wish to
approximate the mean vector and covariance matrix of the random vector y = f (x),
where f (·) is a non-linear function. The random vector x may be approximated by
a cloud of 2n + 1 points
x(0) = ¯x,
x(i) = ¯x +
√
n + κV1/2
x,i ,
x(i+n) = ¯x −
√
n + κV1/2
x,i ,
with associated weights
w0 =
κ
n + κ ,
wi = wi+n =
1
2(n + κ),
where V1/2
x,i denotes the i-th column of the symmetric square root matrix of Vx
(i = 1, . . . , n), for some κ ∈R.
Then for the random vector y, cloud points, mean and variance approximations
are computed as
y(j) = f [(x(j)],
j = 1, . . . , 2n,
¯y =
2n

j=0
wjy(j),
(6.46)

6.6
Approximate Inference
289
Vy =
2n

j=0
wj[y(j) −¯y][y(j) −¯y]⊤.
Some comments are in order.
1. Assuming that the cloud values x(j) accurately describe the distribution of x and
the sample mean ¯x is close to E(x), then approximations of the mean vector and
covariance matrix of y are accurate up to some degree. The algorithm is designed
so that ¯y matches the sample mean of y (evaluated at the sigma points) and hence
in comparison to EKF the mean estimation is more accurate.
2. The above algorithm avoids approximating f (·) as the EKF does. Instead it
evaluates the sigma points from the distribution of x and hence it avoids making
approximation errors of f (·) such as those in EKF.
3. In the description above we have used the symmetric square root for V1/2
x . Any
other suitable matrix square root may be used, such as based on the Choleski
decomposition.
4. If f (·) is a linear function, say y = Ax, for some matrix A, then both the mean
vector and the covariance matrix of y are exact, or ¯y = A¯x and Vy = AVxA⊤.
5. The algorithm requires ﬁne-tuning of the parameter κ. If κ < 0, then the
algorithm can return a negative deﬁnite matrix Vy. In this case modiﬁcations
of the above algorithm is required to ensure that Vy is non-negative deﬁnite; for
more details the reader is referred to Julier and Uhlmann (1997, 2004).
The UKF considers the above unscented transformation applied at the states at
each point of time. We shall consider the conditionally Gaussian state space model
(6.2), although it is possible to describe the algorithm for the more general non-
linear model (6.3) of Sect. 6.1.
Suppose that at time t −1 the posterior mean vector ˆβt−1|t−1 and the posterior
covariance matrix Pt−1|t−1 are available. We apply the above UT (6.46), with x =
βt−1, ¯x = ˆβt−1|t−1, Vx = Pt−1|t−1. Hence we generate 2n points β(j)
t−1.
In the prediction step we approximate the mean vector and the covariance matrix
of βt (suing the non-linear function g(βt−1) of the state equation) and of yt (using
the non-linear function f (·) of the observation equation). So for βt we have
β(j)
t|t−1 = g[β(j)
t−1],
ˆβt|t−1 =
2n

j=0
wiβ(j)
t|t−1,
Pt|t−1 =
2n

j=0
wi
%
β(j)
t|t−1 −ˆβt|t−1
& %
β(j)
t|t−1 −ˆβt|t−1
&⊤

290
6
Non-Linear and Non-Gaussian State Space Models
and for yt we have
y(j)
t|t−1 = f [β(j)
t|t−1],
ˆyt|t−1 =
2n

j=0
wiy(j)
t|t−1,
Qt|t−1 =
2n

j=0
wi
%
y(j)
t|t−1 −ˆyt|t−1
& %
y(j)
t|t−1 −ˆyt|t−1
&⊤
The covariance between βt and yt is approximated as
Ct = Cov(βt, yt) =
2n

j=0
wi
%
β(j)
t|t−1 −ˆβt|t−1
& %
y(j)
t|t−1 −ˆyt|t−1
&⊤
.
When observation yt becomes available, the algorithm updates the mean vector ˆβt|t
and the covariance matrix Pt|t as
ˆβt = ˆβt|t−1 + Kt(yt −ˆyt|t−1)
and Pt|t = Pt|t−1 −KtQt|t−1K⊤
t , where the UKF gain Kt = CtQ−1
t|t−1. Note that
recursions of ˆβt|t and Pt|t are very similar to the standard Kalman ﬁlter, except that
here ˆβt|t−1, ˆyt|t−1, Pt|t−1 and Kt are computed using the sigma points. It should
be noted that the above recursions starting from ˆβt−1|t−1, complete an iteration of
the UKF. This suggests a sequential algorithm starting from the prior β0, with given
mean vector ˆβ0|0 and covariance matrix P0|0.
One of the advantages of the UKF is that the sigma points generated at each point
of time are deterministic and easy to set for high dimensions, hence EKF has been
proposed for high dimensional studies of non-linear systems. Monte Carlo methods
and sequential Monte Carlo (see Sect. 6.7 below) at each point of time simulate a
random sample and these methods are known to diverge for high dimensional data,
for a discussion see Petris et al. (2009).
6.7
Sequential Monte Carlo Inference
6.7.1
Monte Carlo Integration
Monte Carlo is a popular yet simple procedure for the approximation of an integral
of a given continuous function. Suppose we wish to compute the integral
I =
"
A
f (x)p(x) dx,

6.7
Sequential Monte Carlo Inference
291
where f (·) is a continuous function and p(·) is a density function deﬁned on some
domain A. We can regard the above integral as the expectation E[f (X)], where X is
the random vector having density function p(x). If we are able to generate a sample
from p(·), say x(i), for i = 1, . . . , N, then we can approximate I = E[f (X)] as
ˆI = 1
N
N

i=1
f (x(i)).
From the central limit theorem, we know that ˆI converges almost surely to the true
expectation I = E[f (X)]. In many applications, it will be difﬁcult to simulate from
p(x), as p(x) may be too complex. Another issue arises in Bayesian inference
whereby p(x) is a posterior distribution of X, given some data y and typically is
available only up to a proportionality constant c. Indeed writing p(x | y) for this
posterior density, by applying Bayes theorem we have
p(x | y) = cp(y | x)π(x),
where p(y | x) is the likelihood of X with data y, π(x) is the prior distribution of
X and
c =

"
A
p(y | x)π(x)
−1
.
For most applications c will not be available in closed form. As a result, p(x | y)
is only available up to a proportionality constant and obtaining a sample from this
posterior is even harder. This poses additional obstacles for simulating directly from
p(·).
6.7.2
Importance Sampling
In order to overcome the above difﬁculties a procedure known as importance
sampling is deployed. The basic idea is that instead of simulating from p(x) or
p(x | y), which might be difﬁcult or even impossible as described above, we
simulate from a convenient distribution g(x), known as importance density or
importance function and then we calculate some weights to make the necessary
adjustment. To detail the computations we can write I as
I =
"
A

f (x)p(x)
g(x)

g(x) dx = E[w(x)f (x)],
where the weight function w(x) = p(x)/g(x) and it is assumed that g(·) has the
same domain as p(·) and that g(x) ̸= 0, for x ∈A. Following the ideas of Monte

292
6
Non-Linear and Non-Gaussian State Space Models
Carlo approximation in Sect. 6.7.1 we can approximate I by
ˆI = 1
N
N

i=1
w(i)f (x(i)),
(6.47)
where w(i) = p(x(i))/g(x(i)), for a sample x(1), . . . , x(N) from g(x).
The above approximation ˆI relies on the availability of p(·) or p(x | y), as
p(·) will usually represent a posterior distribution. As it is common in Bayesian
inference p(·) can be readily known only up to a proportionality constant (see also
the discussion in Sect. 6.7.1), the weights w(i) may not be available. However, it
turns out that the Monte Carlo approximation ˆI can accommodate this, hence not
requiring to compute the proportionality constant.
Suppose that p(x) = cq(x), where c is the proportionality constant and q(x) is a
known function. Redeﬁne the weights as w(x) = q(x)/g(x), so that the weights of
(6.47) are now equal to p(x)/g(x) = cq(x)/g(x) = cw(x). Noting this and setting
f (x) = 1 in (6.47) we obtain
1 = 1
N
N

i=1
cw(i)
or
c
N

i=1
w(i) = N.
Now from (6.47) for any f (x) we have
ˆI =
N
i=1 cw(i)f (x(i))
N
i=1 cw(i)
=
N

i=1
˜w(i)f (x(i)),
(6.48)
where ˜w(i) are known as the standardised weights and are deﬁned as
˜w(i) =
w(i)
N
i=1 w(i) ,
i = 1, . . . , N,
(6.49)
having the property N
i=1 ˜w(i) = 1. The above proposes an algorithm combining
importance sampling and Monte Carlo. In brief, for the approximation of I,
•
Simulate N values x(1), . . . , x(N) from the importance density g(x)
•
Compute the (non-standardised) weights w(i) = q(x(i))/g(x(i))
•
Get standardised weights ˜w(i) using (6.49)
•
Approximate I using (6.48)
By picking appropriate functions f (·) we can approximate mean, variance and
other statistics of X. For example for f (x) = x the algorithm approximates ˆx the
mean of X, while for f (x) = (x −ˆx)2, the algorithm approximates the variance
of X. The distribution of X can be approximated by the Dirac delta function, some
details of which are given below.

6.7
Sequential Monte Carlo Inference
293
The Dirac delta (or δ) is function deﬁned on the real line which is zero
everywhere except at point zero and has integral over the real line equal to one.
We can think of δ(·) as a density function with an inﬁnitely high spike around zero
and area below this spike equal to one, while everywhere else it is zero. This is the
reason why δ is usually referred to as a point mass distribution. Formally δ(x) is
deﬁned as
δ(x) =

+∞,
x = 0
0,
x ̸= 0
and can be regarded as the limit of a sequence of N(0, σ 2) densities when σ →0,
i.e.
δ(x) = lim
σ→0
1
√
2πσ
exp

−x2
2σ 2
	
.
Suppose we simulate N independent particles x(1), x(2), . . . , x(N) from some
distribution p(x). Then an empirical distribution of x is given by
ˆp(x) = 1
N
N

i=1
δ(x −x(i)).
This basically suggest that p(x) is approximated by the sample mean of the Dirac
point mass at each particle; for more details see Doucet et al. (2001, Chapter 1).
6.7.3
Sequential Importance Sampling
Consider the general non-linear and non-Gaussian model formulation (6.3). Our
aim is to apply importance sampling sequentially over time, in order to approximate
the posterior distribution p(βt | y1:t). In parallel with the deﬁnition of y1:t =
{y1, . . . , yt}, it is convenient to deﬁne β1:t = {β1, . . . , βt} in order to include the
history of all state vectors up to and including time t. Denote by p(β1:t | y1:t) the
posterior density function of β1:t given y1:t and note the required p(βt | y1:t) is just
the marginal distribution of βt and can be extracted from p(β1:t | y1:t). By using
Bayes theorem we have
p(β1:t | y1:t) = p(βt | β1:t−1, y1:t)p(β1:t−1 | y1:t)
∝p(yt | βt, β1:t−1, y1:t−1)p(βt | β1:t−1, y1:t−1)
×p(yt | β1:t−1, y1:t−1)p(β1:t−1 | y1:t−1)
∝p(yt | βt)p(βt | βt−1)p(β1:t−1 | y1:t−1),
(6.50)

294
6
Non-Linear and Non-Gaussian State Space Models
The last line (6.50) is obtained, because given βt, past states and observations
β1:t−1 and y1:t−1 are conditionally independent of the present yt, hence p(yt |
βt, β1:t−1, y1:t−1) = p(yt | βt). Likewise given βt−1, the present state βt is
conditionally independent of the past history β1:t−2 and y1:t−1 and so we have
p(βt | β1:t−1, y1:t−1) = p(βt | βt−1). This follows from the basic Markovian
property of the state space model (6.3), i.e. that given the present, the past and the
future are conditionally independent.
In general we will not be able to sample from the posterior p(β1:t | y1:t) for
the reasons outlined in Sect. 6.7.1. Hence, we can apply importance sampling as
described in Sect. 6.7.2, appropriately modiﬁed to cater for sequential application.
Following the ideas of importance sampling, we shall sample the states from a
importance function or density g(·), deﬁned on the same domain as the required
posterior p(β1:t
| y1:t) . This importance function may not necessarily be a
probability density function, but in most practical cases and for the purposes of
this book we shall assume that g(·) is a density function, and hence it satisﬁes
g(β1:t | y1:t) = g(βt | β1:t−1, y1:t)g(β1:t−1 | y1:t)
∝g(βt | βt−1, yt)g(β1:t−1 | y1:t−1),
(6.51)
where we have assumed that g(βt | β1:t−1, y1:t) = g(βt | βt−1, yt). We remark that
this equality does not follow from the Markovian property of the state space model,
because now the importance function g(·) is a density outside the deﬁnition of the
state space model and hence is not required to satisfy that equality.
The next step is to deﬁne the weights and to recover a sequential calculation from
t −1 to t, for each time t = 1, 2, , . . .. Recall from Sect. 6.7.2 that the importance
weights deﬁned as the ratio of the posterior density over the importance function, or
wt = p(β1:t | y1:t)
g(β1:t | y1:t) ,
which by using Eqs. (6.50) and (6.51) results in
wt ∝p(yt | βt)p(βt | βt−1)
g(βt | βt−1, yt)
p(β1:t−1 | y1:t−1)
g(β1:t−1 | y1:t−1)
= p(yt | βt)p(βt | βt−1)
g(βt | βt−1, yt)
wt−1.
This formula suggests calculating the sampled importance weights w(i)
t
at time t as
w(i)
t
=
p(yt | β(i)
t )p(β(i)
t
| β(i)
t−1)
g(β(i)
t
| β(i)
t−1, yt)
w(i)
t−1,
i = 1, . . ., N,
(6.52)

6.7
Sequential Monte Carlo Inference
295
provided that we have sampled β(i)
t
from g(βt | β(i)
t−1, yt) and that β(i)
t−1 and w(i)
t−1
are sampled at time t −1. The density p(yt | βt) is the likelihood of βt using the
single observation yt and p(βt | βt−1) is the prior of βt (prior distribution of βt,
given βt−1), both of which are available from the state space model deﬁnition (6.3).
Hence, with the availability of the sampled states β(i)
t , β(i)
t−1, the past sample weights
w(i)
t−1 and the importance function, the sampled weights w(i)
t
may be calculated using
(6.52).
Once w(i)
t
are available the standardised weights may be computed by
˜w(i)
t
=
w(i)
t
N
i=1 w(i)
t
,
i = 1, . . . , N.
For each time t, once the standardised weights are obtained we approximate the
posterior density p(β1:t | y1:t) by a weighted sum of Dirac functions (see Sect. 6.7.2
for its deﬁnition)
ˆp(β1:t | y1:t) =
N

i=1
˜w(i)
t δ(β1:t −ˆβ1:t).
(6.53)
In a sequential application at each time t interest is focused on the state βt, rather
than the entire past of states β1:t. Hence the posterior (marginal) distribution of βt
given y1:t is approximated as
ˆp(βt | y1:t) =
N

i=1
˜w(i)
t δ(βt −ˆβt),
where
ˆβt =
N

i=1
˜w(i)
t β(i)
t .
It follows that from the sample of the states β(1)
t
, . . . , β(N)
t
we can obtain any
statistics we wish, e.g. its mode, median, quantiles or the empirical distribution.
The above discussion suggests a sequential algorithm: at each point of time t, a
sample β(1)
t
, . . . , β(N)
t
is drawn from the importance density g(βt | β(i)
t−1, yt), the
weights are computed by (6.52) and then are normalised and ﬁnally the posterior
distribution of βt is approximated according to (6.53). However, in application it is
usually observed that only a small number of particles have positive weights, which
makes for poor Monte Carlo estimation as it is based on a few particles only. To

296
6
Non-Linear and Non-Gaussian State Space Models
alleviate for this issue researches have proposed a resampling step. The effective
sample size, deﬁned as
Neff =
1
N
i=1( ˜w(i)
t )2 ,
is used to decide whether resampling is needed. In one extreme if all particles have
equal weight 1/N, then Neff = N (in this case no resampling is needed as all
weights are positive); in the other extreme if only one particle has weight 1 and
the rest are equal to 0, then Neff = 1 (in this case resampling is needed). Hence
1 ≤Neff ≤N and the closer Neff is to N the more particles have non-zero weights
and participate in the Monte Carlo estimation of the states. As a result a threshold
N0 may be picked, so that after the calculation of Neff resampling is applied if
Neff < N0; typical values for N0 include N0 = N/2 or N0 = N/3.
The most common resampling strategy is known as multinomial resampling
and is brieﬂy described below. Assume that at time t we have sampled the states
β(1)
t
, . . . , β(N)
t
and have computed the standardised weights ˜w(i)
t . Suppose we have
decided to move to a resampling step (assuming Neff < N as discussed above). First
we draw a sample i1, i2, . . . , iN of size N from the discrete distribution P(βt =
β(i)
t ) = ˜w(i)
t
and then we relabel the sample β(i)
t
= β
(ij )
t
, for i = 1, 2, . . . , N.
Finally, the weights are updated to equal weights by ˜w(i)
t
= N−1 and the algorithm
continues to the next time point t + 1. There are various other schemes available for
resampling, the most popular being residual, stratiﬁed and systematic resampling;
for more information the reader is referred to the review of Douc et al. (2005)
and Chopin and Papaspiliopoulos (2020) and to references therein. The above
mentioned sequential algorithm, combining sequential importance sampling with
resampling, is known as sequential Monte Carlo or particle ﬁltering. For the former,
Monte Carlo is discussed earlier in Sect. 6.7.1 and its relationship with sequential
importance sampling (SIS) discussed in Sect. 6.7.3 is apparent. The latter originates
by the signal processing literature where at a given time t a particle is generated
β(i); each simulated state is seen as a particle and the SIS algorithm in Sect. 6.7.3
proposes the framework of updating the particles over time. Below a summary of
the basic particle ﬁlter algorithm is given.
Particle Filter Algorithm I (PF-I)
In the state space model (6.3) for each t = 1, 2, . . ., n the following apply:
1. Simulate N particles β(1)
0 , . . . , β(N)
0
from the prior p(β0).
2. a. For any t = 1, 2, . . . , n simulate β(1)
t
, . . . , β(N)
t
from the importance
function g(βt | β(i)
t−1, yt).
(continued)

6.7
Sequential Monte Carlo Inference
297
b. Calculate the weights:
w(i)
t
= p(yt | β(i)
t )p(β(i)
t
| β(i)
t−1)
g(β(i)
t
| β(i)
t−1, yt)
w(i)
t−1,
i = 1, . . . , N.
c. Standardise the weights:
˜w(i)
t
=
w(i)
t
N
i=1 w(i)
t
,
i = 1, . . ., N.
d. Resampling step. Calculate the effective sample size
Neff =
1
N
i=1( ˜w(i)
t )2 .
Set threshold N0 = N/2 or N0 = N/3. If Neff < N0, then resample.
Multinomial resampling: Draw a sample i1, i2, . . . , iN of size N
from the discrete distribution P(βt = β(i)
t ) = ˜w(i)
t
and then relabel
the sample β(i)
t
= β(ij )
t
, for i = 1, 2, . . . , N. Finally, the weights are
updated to equal weights by ˜w(i)
t
= N−1.
3. Approximate the posterior p(βt | y1:t) by
ˆp(βt | y1:t) =
N

i=1
˜w(i)
t δ(βt −ˆβt),
where
ˆβt =
N

i=1
˜w(i)
t β(i)
t .
6.7.4
Choice of the Importance Function
The particle ﬁlter algorithm of the previous section depends on particles been
generated from the importance density g(βt | β(i)
t−1, yt). Hence, before the algorithm
may be applied, a choice of this density needs to be made. The main requirement for
the density g(·) is to have the same support as the posterior distribution p(βt | y1:t).
Since β(i)
t
is simulated from g(·) it is natural to think that the domains of g(·) and

298
6
Non-Linear and Non-Gaussian State Space Models
p(·) must match. Two choices for g(·) stand out: the suboptimal importance density
and the optimal importance density and are described below.
Suboptimal Importance Density (Bootstrap Filter) This is perhaps the simplest
choice for the importance function, according to which g(βt | βt−1, yt) = p(βt |
βt−1), so that the importance function is just the prior of βt. With this choice of the
importance density, the weights of (6.52) are updated as w(i)
t
= p(yt | β(i)
t )w(i)
t−1;
the resulting particle ﬁlter is known as bootstrap ﬁlter and is discussed in Gordon
et al. (1993) and in Doucet et al. (2001). The advantage of using the bootstrap ﬁlter
is simplicity, as it is usually easy to simulate from the prior p(βt | βt−1). The
disadvantage is that g(·) does not depend on the observation yt, but only on the
states; hence the name suboptimal importance density. This choice will be suitable
for many non-linear state space models, but it may not be appropriate for highly
non-linear systems.
Optimal Importance Density Out of all possible importance functions that take
into account states and observations, there is one which stands out and this is the
probability density of βt, given βt−1 and yt, so that g(βt | βt−1, yt) = p(βt |
βt−1, yt). This importance function, introduced in Zaritskii et al. (1975), is optimal
in a sense of minimising the variance of the importance weights over the set of all
importance functions. This optimality due to Doucet et al. (2000) is established in
the following theorem.
Theorem 6.2 Conditionally upon β(i)
t−1 and y1:t, the importance function p(βt |
β(i)
t−1, yt) minimises the variance of the importance weights w(i)
t , in the set of all
importance functions g(βt | β(i)
t−1, yt).
Proof We will show that for the importance function p(βt
|
β(i)
t−1, yt) the
importance weights have zero variance.
Using (6.52) the variance of w(i)
t
over all importance functions g(βt | β(i)
t−1, yt)
is
Var(w(i)
t ) = E

w(i)2
t

−E

w(i)
t
2
=
"
A

w(i)
t
2
g(βt | β(i)
t−1, yt) dβt −

"
A
w(i)
t g(βt | β(i)
t−1, yt) dβt
2
=

w(i)
t−1
2
 "
A
p(yt | βt)2p(βt | β(i)
t−1)2
g(βt | β(i)
t−1, yt)
dβt −p(yt | β(i)
t−1)2
!
,
(6.54)
where A is the domain of βt.

6.7
Sequential Monte Carlo Inference
299
If we now choose g(βt | βt−1, yt) = p(βt | βt−1, yt), then we have
"
A
p(yt | βt)2p(βt | β(i)
t−1)2
p(βt | β(i)
t−1, yt)
dβt =
"
A
p(yt | βt)p(βt | β(i)
t−1)p(yt | β(i)
t−1) dβt
= p(yt | β(i)
t−1)2
and so from (6.54) we have Var(w(i)
t ) = 0, for the importance function p(βt |
βt−1, yt).
⊓⊔
The optimal importance function discussed above is deployed in Chen and Liu
(1996), Doucet et al. (2001), Harvey et al. (2004), Chopin and Papaspiliopoulos
(2020) and in references therein. For the optimal importance function to work one
needs to be able to draw a sample from it. In many state space models, this is not
possible because if we are able to sample from p(βt | βt−1, yt) usually we should be
able to sample from the posterior p(βt | y1:t). Between the suboptimal importance
function (the prior distribution of βt) and the optimal importance function (the
conditional distribution of βt, given βt−1 and yt), there are other importance
functions that can be used. These functions will be easier to sample than the optimal
importance function, and will improve on the suboptimal importance function by
incorporating observations yt in the importance density. Below we brieﬂy describe
a popular choice.
Consider the conditionally Gaussian state space model
yt = f (βt) + ϵt
and
βt = Fβt−1 + ζt,
(6.55)
where ϵt ∼N(0, σ 2) and ζt ∼N(0, Z), for some known observation variance
σ 2 and some transition covariance matrix Z and the function f (·) is known. Our
objective is to obtain an approximation of the optimal importance function p(βt |
βt−1, yt).
Following a similar approach as that of Sect. 6.6.1, we use a ﬁrst order Taylor
approximation of f (βt) around the state vector βt−1 in order to linearise the state
space model (6.55) as
yt ≈x⊤
t βt + μt + ϵt
and
βt = Fβt−1 + ζt,
where μt = f (Fβt−1) −[∂f (βt)/∂βt]⊤
βt=Fβt−1Fβt−1 and
xt = ∂f (βt)
∂βt
2222
βt=Fβt−1
.
Note that conditional on βt−1, μt is a known function.

300
6
Non-Linear and Non-Gaussian State Space Models
Write down the approximate conditional distribution of βt and yt, given βt−1, as

βt
yt
 22βt−1 ∼N
(
Fβt−1
x⊤
t Fβt−1 + μt

,

 Z
Zxt
x⊤
t Z x⊤
t Zxt + σ 2
)
.
Hence the approximate posterior distribution of βt, given βt−1 and yt is
βt | βt−1, yt ∼N

Fβt−1 + Zxt(yt −x⊤
t Fβt−1 −μt)
x⊤
t Zxt + σ 2
, Z −Zxtx⊤
t Z
σ 2

.
(6.56)
Considering the conditionally Gaussian model (6.55) we can use the particle ﬁlter
algorithm PF-I (see p. 296) where the importance function g(βt | βt−1, yt) is the
Gaussian density (6.56). This importance function is expected to a better choice
than the prior p(βt | βt−1) and may well approximate the optimal importance
function p(βt | βt−1, yt). With the breadth of models incorporated within (6.55),
this choice of the importance function is popular, in particular provided that it is
easy to simulate the particles from a multivariate normal distribution.
6.7.5
Example 1: Multinomial Time Series
We consider the multinomial dynamic model (6.17)–(6.19) of Sect. 6.2.3. We
simulate 100 bivariate states βt = [β1t, β2t]⊤from a random walk βt = βt−1 + ζt,
with ζt ∼N(0, I), which result in 100 simulated probabilities
log
π1t
1 −π1t −π2t
= β1t
and
log
π2t
1 −π1t −π2t
= β2t
and π3t = 1 −π1t −π2t. These probabilities are used to simulate 100 observation
vectors y1, . . . , y100 from the multinomial distribution (6.17), with size λt = 10.
These observations are used in order to estimate the probabilities πit and hence
illustrate the performance of the bootstrap ﬁlter, for this model when we know the
true model.
# simulate 100 observations from the model
# Generate random walk
> y <- sim.multinom(100, d=3, size=10, sd=1)
We have used the bootstrap ﬁlter with 1000 particles and multinomial resam-
pling. Figure 6.1 shows the probabilities πit together with posterior modes of the
approximation ˆp(πit), i = 1, 2, 3 and t = 1, . . . , 100. We remark that the posterior
modes are very close to the original simulated probabilities. This is remarkable,
considering the simplicity and speed of the bootstrap ﬁlter.

6.7
Sequential Monte Carlo Inference
301
0
20
40
60
80
100
0.0
0.1
0.2
0.3
0.4
Estimation of probability
Time
1
0
20
40
60
80
100
0.0
0.2
0.4
0.6
0.8
1.0
Estimation of probability
Time
2
0
20
40
60
80
100
0.0
0.2
0.4
0.6
0.8
1.0
Estimation of probability
Index
3
True
Estimated
Fig. 6.1 Posterior modes (crosses) of ˆp(πit) in the multinomial dynamic model (6.17)–(6.19),
together with the original simulated probabilities (circles)
# run the bootstrap filter
> fit <- bts.multinom(y$obs, size=10, N=1000, sd=1)
# extract estimated probabilities
> estimated.probs <- fit$prob
The following R code is used to make the plot of Fig. 6.1.
# Plot of estimated probabilities against true probabilities
> par(mfrow=c(2,2))
> plot(probabilities[,1],xlab="Time",ylab=expression(pi[1]),
+ main=expression("Estimation of probability"))
> points(estimated.probs[,1],col="red",pch=4) # bootstrap estimates
> plot(probabilities[,2],xlab="Time",ylab=expression(pi[2]),
+ main=expression("Estimation of probability"))
> points(estimated.probs[,2],col="red",pch=4) # bootstrap estimates
> plot(probabilities[,3],ylab=expression(pi[3]),
+ main=expression("Estimation of probability"))
> points(estimated.probs[,3],xlab="Time",col="red",pch=4)

302
6
Non-Linear and Non-Gaussian State Space Models
> plot(1,1,type="n",xaxt="n",yaxt="n",ylab="",xlab="")
> legend("topleft",c("True", "Estimated"),pch=c(1,4),
+ col=c("black","red"))
6.7.6
Example 2: Bearings-Only Tracking Revisited
In this section we revisit the bearings-only tracking example discussed in
Sects. 1.3.2 and 6.3. We aim to track a moving target (a ship) in the x −y
plane. Observations zt = arctan(yt/xt) + ϵt are generated by Eq. (1.10), while
the states βt = (xt, yt, ˙xt, ˙yt)⊤follow the Markov process (1.11). For full details
and the motivation of this model the reader is referred to Sect. 1.3.2 . We remark
that the bearings-only tracking problem discussed above has notable similarities
to object-tracking, which within the signal processing community has received
considerable attention. This includes single or multiple tracking, spatial tracking and
is closely related to GPS tracking and video processing, with applications to video
surveillance, sport events, forensic science drone and air trafﬁc control, see e.g.
Gordon et al. (1993), Mihaylova et al. (2014) and references therein. For this kind
of problems, Bayesian inference based on simulation has been proven successful
and popular, as is evidenced in Hue et al. (2002), Angelova and Mihaylova (2008),
Andrieu et al. (2010) and in the many references of the overview of Punchihewa
et al. (2018). In the sequel we simulate a simple data set on our bearings-only
tracking problem in order to illustrate the Bootstrap ﬁlter discussed earlier.
We simulate two trajectories of the ship from the model of Sect. 1.3.2; we
generate 50 (xt, yt) vectors from model (1.10)–(1.11), with
Var(ϵt) = σ 2
ϵ
and
Z = Var(ζt) =
⎡
⎢⎢⎢⎣
0 0 0
0
0 0 0
0
0 0 σ 2
ζ
0
0 0 0 σ 2
ζ
⎤
⎥⎥⎥⎦.
The ﬁrst trajectory is simulated with σ 2
ϵ = 2 and σ 2
ζ = 0.0000001 and the second
trajectory is simulated with σ 2
ϵ = 0.1 and σ 2
ζ = 0.00001. These settings are similar
to those used in Gilks and Berzuini (2001) and Fearnhead (2002). The R code for
trajectory 1 is
# simulate trajectory 1
> z1 <- sim.tracking(50, eta=2, tao=0.0000001)
# fit the model
> fit1 <- bts.tracking(z$z, N=100, eta=2, tao=0.0000001)
# compute the modes
> beta1 <- beta2 <- rep(0, 50)
> for(t in 1:50){ beta1[t] <- Mode(fit1$beta[,1,t])}
> for(t in 1:50){ beta2[t] <- Mode(fit1$beta[,2,t])}

6.7
Sequential Monte Carlo Inference
303
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
17.0
17.5
18.0
18.5
19.0
19.5
20.0
Tracking of a ship: (a) trajectory 1
x
y
-0.6
-0.5
-0.4
-0.3
-0.2
-0.1
0.0
16.5
17.0
17.5
18.0
18.5
19.0
19.5
20.0
Tracking of a ship: (b) trajectory 2
x
y
Fig. 6.2 Tracking of a ship. Shown are true positions xt, yt (circles) of the ship together with their
respective posterior modes (crosses), for each trajectory
The R code for trajectory 2 is
# simulate trajectory 2
> z2 <- sim.tracking(50, eta=0.1, tao=0.00001)
> fit2 <- bts.tracking(z4$z, N=100, eta=0.1, tao=0.00001)
# compute the modes
beta3 <- beta4 <- rep(0, 50)
for(t in 1:50){ beta3[t] <- Mode(fit2$beta[,1,t])}
for(t in 1:50){ beta4[t] <- Mode(fit2$beta[,2,t])}
The bootstrap ﬁlter is applied, so that at each time t we simulate 100 particles
from the prior p(βt | βt−1) ≡N(Fβt−1, Z), where F is the transition matrix of
Eq. (1.11). Multinomial resampling is used when the effective sample size is Neff <
50/2 = 25; see Sect. 6.7.4 for a discussion of the bootstrap ﬁlter. Figure 6.2 shows
the posterior mode of (xt, yt)⊤plotted against the true simulated values of (xt, yt)⊤,
for each trajectory. The true values are depicted by a circle, while the estimated
values are depicted by a cross. We observe that the estimated values are quite close
to the true simulated values, indicating the tracking performance of the particle ﬁlter.
It is possible to plot empirical densities and credible intervals on the xt, yt positions.
The R code for the plot of Fig. 6.2 is given below.
# plot of x-y trajectories with estimates
> par(mfrow=c(1,2))
>
> plot(z1$x, z1$y, xlab="x", ylab="y",
+ main=expression("Tracking of a ship: (a) trajectory 1"),
+ xlim=c(min(beta1),max(beta1)), ylim=c(min(beta2),max(beta2)) )

304
6
Non-Linear and Non-Gaussian State Space Models
> points(beta1, beta2, col=2, pch=3)
>
> plot(z2$x, z2$y, xlab="x", ylab="y",
+ main=expression("Tracking of a ship: (b) trajectory 2"),
+ xlim=c(min(beta3,z2$x),max(beta3,z2$x)),
+ ylim=c(min(beta4,z2$y),max(beta4,z2$y)) )
> points(beta3, beta4, col=2, pch=3)
6.7.7
Example 3: Non-Linear Time Series
In this section we consider ﬁltering from a non-Gaussian and non-linear time series
model. This model, which was introduced in Kitagawa (1987), was subsequently
used extensively in order to illustrate ﬁltering algorithms for non-Gaussian time
series; among other references the reader can ﬁnd discussions of this model in Carlin
et al. (1992), Kitagawa (1998), Godsill et al. (2004) and Andrieu et al. (2010).
The state space model is generated by
yt = β2
t
20 + ϵt
and
βt = αβt−1 +
γβt−1
1 + β2
t−1
+ δ cos[1.2(t −1)] + ζt,
where ϵt and ζt independently follow Gaussian distributions, i.e. ϵt ∼N(0, σ 2) and
ζt ∼N(0, Z); it is also assumed that ϵt, ζt are independent of the initial state β0,
which is assumed to follow a Gaussian distribution too, i.e. β0 ∼N(0, 10).
This model is conditionally Gaussian as we can see
yt | βt ∼N
β2
t
20, σ 2
	
,
βt | βt−1 ∼N
 
αβt−1 +
γβt−1
1 + β2
t−1
+ δ cos(1.2t −1.2), Z
!
.
Following Godsill et al. (2004) we simulate 50 states β1, . . . , β50 and observa-
tions y1, . . . , y50 from this model with α = 0.5, γ = 25, δ = 15, σ 2 = 8 and
Z = 10. The bootstrap ﬁlter is applied, so that, at each time t ≥1, states β(i)
t
are simulated from the prior βt | β(i)
t−1 ∼N[0.5β(i)
t−1 + 25β(i)
t−1(1 + β(i)2
t−1)−1 +
15 cos(1.2t −1.2), 10], with i = 1, . . . , N (here we have used N = 1000 particles
and resampling is applied if the effective sample size is smaller than 500 particles).
Figure 6.3 shows the true simulated states βt (solid line and solid dots) together with
posterior modes (dashed line and crosses), together with 95% posterior credible
intervals. We observe that 94% of the simulated states fall within the credible
intervals; there are only three points lying outside them: these are states β5 =
−24.823, β45 = −22.953 and β50 = −9.310. The posterior modes are generally
close to the simulated states, with the exception of some points of time towards the

6.7
Sequential Monte Carlo Inference
305
State estimation
Time
State
0
10
20
30
40
50
-30
-20
-10
0
10
20
30
Fig. 6.3 Non-linear state estimation. Shown are the simulated states together with posterior mode
and 95% credible intervals
end of the series (times t = 43, 44, 45). This ﬁt provides better estimation than the
extended Kalman ﬁlter of Sect. 6.6.3, and can be further improved if instead of the
bootstrap ﬁlter, the particles are generated from an approximation of the optimal
importance function. Exercise 13 discusses one option of such an approximation.
# simulate the data
> obs <- sim.nonlinear(50, alpha=0.5,delta=15, sigma=8, Z=10)
# fit the model
> fit <- bts.nlm.filter(obs$obs,alpha=0.5,delta=15,N=1000,
+ sigma=8, Z=10)
# prepare for plotting
> mode1 <- UQ <- LQ <- rep(0,50)
> for(t in 1:50){
>
mode1[t] <- Mode(fit1$state[t,])
>.
UQ[t] <- quantile(fit1$state[t,], probs=0.975)
>.
LQ[t] <- quantile(fit1$state[t,], probs=0.025)
> }
# plot the data and the estimates
> ts.plot(ts(obs1$state), ts(mode1), ts(UQ), ts(LQ),
+ lty=c(1,2,4,4), col=c(1,2,4,4),
+ main=expression("State estimation"), ylab="State")
> points(obs1$state, pch=20)
> points(mode1, pch=4)

306
6
Non-Linear and Non-Gaussian State Space Models
6.7.8
Static Parameter Estimation
6.7.8.1
Introduction and Initial Studies
The basic particle ﬁlter algorithm (PF-I algorithm on p. 296) assumes that all
unknown parameters subject to estimation are placed into the state vector βt,
which is time-dependent. Hence the algorithm cannot treat static parameters, such
as variances or other time-invariant hyperparameters. Let θ denote the vector of
such static hyperparameters. In order to allow inference for θ, one possibility is to
introduce a “static” evolution θt = θt−1, with θ1 = θ and to incorporate θt into the
state vector βt. This has the ﬂaw that sampling from θt is essentially the same as
sampling from θ1, hence we do not learn as time increases. For example observe
that sampling θ(i)
t
from the importance function p(θt | θ(i)
t−1, yt) implies that the
sampled value of θ(i)
t
is necessarily equal to θ(i)
t−1, for all t (as θt = θt−1), hence
θ(i)
t
= θ(i)
1
(essentially we sample θ from the prior).
In order to overcome this problem Gordon et al. (1993) propose that θt follows
an artiﬁcial evolution, such that
θt = θt−1 + ηt,
(6.57)
where ηt ∼N(0, Wt), for some covariance matrix Wt. As before, θt is incorporated
in βt. In this setting at time t we are sampling from θt and hence the above problem
is overcome. However, we have now introduced an artiﬁcial evolution of the static
parameters θ. In Gordon et al. (1993) it is proposed that a small covariance matrix of
ηt will result in a slow evolution for θt, i.e. θt ≈θt−1. Hence, we may set Wt = cI,
where the constant c should be close to 0 and can be set using discount factors (see
e.g. the discussion in Sect. 4.3.2). Nevertheless, this approach has the disadvantage
that we are choosing to model static parameters as slowly varying time-varying
parameters.
Storvik (2002), considering this problem, proposes that θ is sampled by a
conjugate Bayesian analysis and sufﬁcient statistics. This algorithm is somewhat
limited in the sense that it requires the existence of sufﬁcient statistics. Gilks
and Berzuini (2001) and Fearnhead (2002) discuss MCMC-based particle ﬁlter
algorithms with leading application the bearings-only tracking problem. Here, we
describe the Liu and West ﬁlter (Liu & West, 2001), which is simpler and faster than
the above MCMC algorithms and is a general-purpose algorithm dealing with the
static-parameter problem discussed above.
6.7.8.2
Liu and West Particle Filter
Consider ﬁrst the case of known static parameters θ. The algorithm makes use of
the so-called auxiliary particle ﬁlter, proposed by Pitt and Shephard (1999). Next
we describe the auxiliary particle ﬁlter. In the general model (6.3) suppose that at

6.7
Sequential Monte Carlo Inference
307
time t −1 the posterior p(βt−1 | y1:t−1 is approximated by ˆp(βt−1 | y1:t−1) =
N
i=1 ˜w(i)
t−1δ(βt−1 −ˆβ), where ˆβt−1 = N−1 n
i=1 ˜w(i)
t−1β(i)
t−1 is the Monte Carlo
mean. With the availability of information yt, the posterior of βt is approximated as
p(βt | y1:t) ∝p(yt | βt)p(βt | y1:t−1
= p(yt | βt)
"
A
p(βt | βt−1)p(βt−1 | y1:t−1) dβt−1
≈
N

i=1
˜w(i)
t−1p(βt | β(i)
t−1)p(yt | βt),
where A is the domain of βt.
For each i = −1, 2, . . . , N we select μ(i)
t
a prior estimate of βt; this can be the
prior mode or prior mean of βt, given β(i)
t−1. If μ(i)
t
is a good estimate of βt, then the
weight
g(i)
t
∝w(i)
t−1p(yt | μ(i)
t )
should be large, suggesting that β = μ(i)
t
is consistent with the datum yt. The
algorithm proceeds by ﬁrst sampling an indicator variable j with probability
proportional to g(i)
t
and then sampling a state β(j)
t
from the prior p(βt | β(j)
t−1).
Based on these auxiliary variables a new weight is computed as
w(j)
t
= p(yt | β(j)
t
)
p(yt | μ(j)
t
)
and the algorithm proceeds to the next j. This creates a set of simulated states
β(j1)
t
, . . . , β(jN)
t
. More details of the algorithm are to be found in Pitt and Shephard
(1999) and in the many articles which cite it.
Considering now the static parameters θ, let p(θ) denote the prior distribution
of θ. In what follows we shall assume that θ is scalar, but the extension of θ being
a vector is trivial. We shall be interested in the approximation of the joint posterior
distribution of (βt, θ)⊤. The prior distribution of the states and the likelihood are
conditional on θ. The joint posterior of βt and θ at time t is
p(βt, θ | y1:t) ∝p(yt | βt, θ)p(βt, θ | y1:t−1)
= p(yt | βt, θ)p(βt | θ, y1:t−1)p(θ | y1:t−1).
Hence we have to deal with the posterior of θ at time t −1.
Liu and West (2001) consider ﬁrst Kernel density estimation for the posterior of
θ given y1:t−1. At time t −1 and with information y1:t−1, suppose we have obtained
Monte Carlo samples θ(t−1,j)
t
with weights w(j)
t−1 which approximate the density

308
6
Non-Linear and Non-Gaussian State Space Models
p(θ | y1:t−1’ the superscript t −1 is included to make explicit the dependence
of θ(j) to t −1. Write ¯θ and Vt−1 the Monte Carlo vector mean and covariance
matrix of θ given y1:t−1. The smooth Kernel density we consider here is a mixture
of normal distributions with mixing weights w(j)
t−1 so that
p(θ | y1:t−1) ≈
N

j=1
w(j)
t−1fθ(m(j)
t−1, h2Vt−1),
(6.58)
where fθ(m, V) denotes the density of a multivariate normal distribution with mean
vector m and covariance matrix V.
In order to specify mt−1 one idea is to set m(j)
t−1 = θ(t−1,j), i.e. to centre
the location of fθ around the simulated value θ(t−1,j). However, this has the
disadvantage of an over-dispersed density, with Var(θ | y1:t−1) = (h2 + 1)Vt−1.
Indeed
E(θ | y1:t−1) =
N

j=1
w(j)
t−1m(j)
t−1 =
N

j=1
w(j)
t−1θ(t−1,j) = mt−1
and
Var(θ | y1:t−1) =
N

j=1
w(j)
t−1
%
Var(θ | m(j)
t−1, h2Vt−1) + θ(t−1,j)(θ(t−1,j)⊤
−E(θ | y1:t−1)E(θ | y1:t−1)⊤&
=
N

j=1
w(j)
t−1h2Vt−1 +
N

j=1
w(j)
t−1(θ(t−1,j)(θ(t−1,j))⊤−mt−1m⊤
t−1)
= (h2 + 1)Vt−1.
In order to resolve this problem Liu and West propose replacing m(j)
t−1 = θ(t−1,j) by
m(j)
t−1 = αθ(t−1,j) + (1 −α) ¯θ,
(6.59)
where α =
√
1 −h2.
To see this note that
E(θ | y1:t−1) =
N

j=1
w(j)
t−1m(j)
t−1 = α
N

j=1
w(j)
t−1θ(t−1,j) + (1 −α)
N

j=1
w(j)
t−1 ¯θ = ¯θ

6.7
Sequential Monte Carlo Inference
309
and
Var(θ | yt−1) =
N

j=1
w(j)
t−1h2Vt−1 +
N

j=1
w(j)
t−1[m(j)
t−1(m(j)
t−1)⊤−¯θ ¯θ⊤]
= h2Vt−1 +
N

j=1
w(j)
t−1[αθ(t−1,j) + (1 −α) ¯θ][αθ(t−1,j) + (1 −α) ¯θ]⊤
−¯θ ¯θ⊤
= (α2 + h2)Vt−1 = Vt−1,
using α2 + h2 = 1.
Hence, with m(j)
t−1 as in (6.59) the Monte Carlo mean vector ¯θ and covariance
matrix Vt−1 are preserved in the mixture density. The kernel location m(j)
t−1 is a
exponentially weighted average of the simulated θ(t−1,j) and the Monte Carlo mean
¯θ; the smoothing parameter h controls how close m(j)
t−1 is to ¯θ and can be chosen
using discount factors.
In order to proceed to the posterior p(θ | y1:t) Liu and West adopt the artiﬁcial
evolution (6.57), but modify it appropriately in order to deal with the loss of
information incurred by the covariance of ηt. First notice that from the evolution
(6.57) the Monte Carlo approximation of the density p(θt | y1:t−1) is a kernel
density
p(θt | y1:t−1) ≈
N

j=1
w(j)
t−1fθt (θ(j)
t−1, Wt)
where fθt (m, V) denotes a Gaussian density with mean vector m and covariance
matrix V and θ(j)
t−1 is the sample obtained at time t −1 from the density p(θt−1 |
y1:t−1).
The above-mentioned loss of information is the result of (6.57) and with the
usual assumption that θt−1 and ηt are independent, Var(θt | y1:t−1) = Var(θt−1 |
yt−1) + Wt, hence there is a loss of information coming from ti1 to t with
information y1:t−1. This loss of information is depicted by the increased variance
Var(θt | y1:t−1) ≥Var(θt−1 | yt−1) and is quantiﬁed by the covariance matrix
Wt. Hence Wt = 0 corresponds to a static θt = θt−1 = θ, as ηt = 0 in (6.57) ,
with probability 1. However, as we wish to keep the evolution (6.57) so that we can
update the particle ﬁlter from one time to another, we can modify the assumption of
independence between θt−1 and ηt in order to cater for the time-invariance of θ. Let
us assume that θt−1 and ηt have a non-zero covariance Cov(θt−1, ηt); we can set this
covariance so that Var(θt | y1:t−1) = Var(θt−1 | y1:t−1) in order to accommodate

310
6
Non-Linear and Non-Gaussian State Space Models
for the loss of information described above. Indeed
Var(θt | y1:t−1) = Var(θt−1 | y1:t−1) + Wt + 2Cov(θt−1, ηt)
Hence, the speciﬁcation Cov(θt−1, ηt) = −2−1Wt ensures the property Var(θt |
y1:t−1) = Var(θt−1 | y1:t−1) = Vt−1 required for the time-invariance of the
parameter vector θ. With this in place we can write down the join distribution of
θt, given θt−1 and y1:t−1 as

 θt
θt−1

| y1:t−1 ∼N
(
 ¯θ
¯θ

,

Vt−1
AtVt−1
Vt−1A⊤
t
Vt−1
)
,
where ¯θ and Vt−1 are the Monte Carlo mean vector and covariance matrix of θt−1
and from the covariance AtVt−1 = Cov(θt, θt−1 | y1:t−1) = Cov(θt−1 + ηt, θt−1 |
y1:t−1) = Vt−1 −1
2Wt, the matrix At is determined as At = I −1
2WtV−1
t−1. From
the above joint distribution of θt and θt−1, we deduce that the condition distribution
of θt, given θt−1 is
θt | θt−1 ∼N( ¯θ + At(θt −¯θ), Vt−1 −AtVt−1A⊤
t )
Consequently, we can choose a discount or forgetting factor δ in order to specify
Wt, which is then used to propose a speciﬁcation for At. With the discounting
approach discussed in detail in Sect. 4.3.2, we can set Wt = (1−δ)δ−1Vt−1, which
results in
At = I −δ−1(1 −δ)Vt−1V−1
t−1/2 = 3δ −1
2δ
I = αI,
Hence the shrinkage parameter h in Eq. (6.58) is determined by
h2 = 1 −α2 = 1 −
3δ −1
2δ
	2
.
With these equations in place the conditional distribution is simpliﬁed to
θt | θt−1 ∼N(αθt−1 + (1 −α) ¯θ, h2Vt−1),
(6.60)
which is used to approximate the mixture (6.58). Assuming that at time t −1 we
have a sample θ(j)
t−1, then θt | θ(j)
t−1 ∼N(m(j)
t−1, h2Vt−1) is the Gaussian density
fθ(m(j)
t−1, h2Vt−1) in the kernel density (6.58). Hence, we have used the artiﬁcial
evolution (6.57) employed with the covariance structure described above in order to
obtain the conditional distribution (6.60) and update the sample of θ from time t −1
to time t. To the following we give a summary of Liu and West algorithm.

6.7
Sequential Monte Carlo Inference
311
Particle Filter Algorithm II (PF-II)
In the state space model (6.3) for each t = 1, 2, . . ., n the following apply:
1. Simulate N particles (β(1)
0 , θ(1)
0 , . . . , β(N)
0
, θ(N)
0
) from the prior p(β0, θ).
This might be facilitated by simulating θ(j)
0
= θ(j) from the prior p(θ) and
β(j)
0
from p(β0 | θ(j)
0 ).
2. a. For each i = 1, 2, . . ., N calculate prior point estimates μ(j)
t
of βt and
m(j)
t
of θ as
μ(j)
t
= E(βt | β(j)
t−1, θ(j)
t−1)
and
m(j)
t
= αθ(j)
t−1 + (1 −α) ¯θt−1,
where α is the smoothing parameter and ¯θt−1 is the Monte Carlo mean
of θ(1)
t−1, . . . , θ(N)
t−1.
b. Sample an auxiliary index variable k from the set {1, 2, . . ., N}, with
probability proportional to
g(k)
t
∝w(k)
t−1p(yt | μ(k)
t , m(k)
t−1).
c. Sample a new parameter vector θ(k)
t
from the k-th component of the
mixture,
θ(k)
t
∼N(m(k)
t−1, h2Vt−1)
where h2 = 1 −α2.
d. Sample a single state vector β(k)
t
from the state distribution
p(βt | β(k)
t−1, θ(k)
t
).
e. Compute the corresponding weight
w(k)
t
= p(yt | β(k)
t
, θ(k)
t
)
p(yt | μ(k)
t , m(k)
t )
.
f. Repeat Steps (b)-(e) to obtain a set of posterior approximations
(β(j)
t
, θ(j)
t
), for i = 1, 2, . . . , N.

312
6
Non-Linear and Non-Gaussian State Space Models
6.7.9
Case Study: Analysis of Asthma Data
In this section we discuss in some detail a case study, reported in Triantafyllopoulos
et al. (2019), which illustrates the use and utility of the models and methods
described in the previous sections. We consider data consisting of daily medical
contacts for schoolchildren aged between 5 and 16 years old who suffered from
asthma over a seven-year period between 1999 and 2005 in England. This data,
reported in Julious et al. (2011), are depicted in Fig. 6.4 (top panel). The lower panel
of this ﬁgure shows weekly counts of medical contacts and this is the primary data
set we consider in this section. The main reason for this aggregation is to account
for the weekend effect. A primary interest related to these data involves short-term
forecasting of the count of asthma patients. This can provide vital input in hospital
bed availability and requirements as well as hospital staff availability and planning
of resources.
Figure 6.4 suggests that the weekly data appear to be a non-stationary time series.
There appears to be some evidence of seasonality, but this is not persistent and
modelling it in the dynamic model did not provide an improvement. We consider
Plot of daily medical contacts (per 100)
Time (days)
0
500
1000
1500
2000
2500
0
2
4
6
8
10
Plot of weekly total medical contacts (per 100)
Time (weeks)
0
100
200
300
15
25
35
Fig. 6.4 Daily and weekly total medical contacts for asthmatic children

6.7
Sequential Monte Carlo Inference
313
the Poisson and the negative binomial dynamic models, discussed in Sect. 6.2.2.
The Poisson model consists of observation (6.8) and transition (6.10), i.e.
yt | βt ∼Poisson[exp(βt)]
and
βt = βt−1 + ζt,
where ζt ∼N(0, Z). Here the rate of the Poisson distribution is λt = exp(βt) (the
canonical logarithmic link is used) and the static hyperparameter of the model is
the state variance Z. The random walk evolution of the states is motivated by weak
evidence of stationarity, supported from Fig. 6.4 and from autocorrelation plots, not
reported here.
The negative binomial dynamic model consists of observation (6.11) and transi-
tion (6.13), i.e.
yt | βt ∼NegBinomial

λt = λ,
exp(βt)
1 + exp(βt)

and
βt = βt−1 + ζt,
where the logarithmic link is used, the probability of success is πt = exp(βt)[1 +
exp(βt)]−1 and the static parameters are λ and Z. More details about these models
are provided in Sect. 6.2.2.
The Liu and West ﬁlter (hereinafter LW) discussed in Sect. 6.7.8 is applied to the
asthma weekly time series data with the proposed models. We have used throughout
N = 1000 particles and a high discount factor δ = 0.995, which corresponds to
α ≈0.997 and h ≈0.071. Liu and West (2001) discuss Gaussian mixtures for the
prior of each of the hyperparameters (see also Sect. 6.7.8). For parameters where
support is not the real line these authors make use of transformations to map the
support of these parameters to the real line, e.g. for the variance Z, one can work
with log Z. In this section we consider a gamma prior for Z (for both Poisson and
negative binomial), i.e. Z ∼G(2, 0.1). For the size λ of the negative binomial we
consider three possibilities (a) a gamma prior λ ∼G(2, 0.1), (b) a uniform prior
λ ∼U(0, 50) and (c) a uniform prior for λ−1, λ−1 ∼U(0, 1). In (a) the gamma
prior is unbounded from above to allow large values of λ; moreover, this gamma
prior is a weakly informative prior with prior mode 10 and prior variance 200. In
(b) the non-informative prior is bounded above, but a large value 50 is chosen; here
the prior mean is 25 and the variance is 208.33. In (c) the non-informative prior for
λ−1 gives the Poisson model when λ−1 = 0 in the boundary.
Figure 6.5 exhibits the ﬁnal 105 observations of the real data together with one-
week-ahead forecasting by using the LW algorithm for the Poisson and the negative
binomial models. The LW with Poisson model gives a number of forecasts closer to
the real data than does the negative binomial, but for some observations the negative
binomial model outperforms the Poisson model.
For the three negative binomial models, Fig. 6.6 shows the estimates of the
parameters λ and Z (here all data points considered 1–365). We see that all three
priors for λ considered here produce estimates of λ in the bound (0, 2.5), for all
t. This indicates that forecasts generated by the negative binomial model have left
skewed distributions with the variance being larger than the mean. We observe from

314
6
Non-Linear and Non-Gaussian State Space Models
Real data versus forecasts
Time (weeks 261-365)
Total weekly medical contacts (per 100)
0
20
40
60
80
100
0
10
20
30
40
50
Fig. 6.5 Real data (black solid line with solid points) against one step ahead forecasts for the
Poisson model (red dashed line with cross), and negative binomial model (blue dotted line with
circle)
Fig. 6.6 that the state variance Z (gamma prior model) is more stable after about 200
time points compared to the other two models. Moreover, the credible bounds of Z
(gamma prior model) are the most narrow with their values not exceeding the value
of 5 and be consistently less than 4 after 200 time points. Figure 6.7 shows posterior
mode and credible bounds of the state variance Z under the Poisson model. We
observe that after 200 time points the mode is quite stable and the credible bounds
do not exceed the value of 2. The low estimated values of the dispersion parameter
λ in Fig. 6.6 put forward the negative binomial model and provide evidence against
the Poisson (we would expect λ to be large to favour the Poisson). A close look at
Fig. 6.5 reveals that at the start of the series some of the negative binomial forecasts
are poor, while towards the end the negative binomial provides some impressive
forecasts (t = 105).
Finally, Fig. 6.8 shows histograms of the count for both the Poisson and the
negative binomial models. The histograms are picked at three points of time (t =
8, 70, 105) to reﬂect on the performance of the two models at different times; plotted
are the true observations (vertical lines). We remark that for some points of time the
Poisson model is better (e.g. for t = 8, corresponding to week 267) and at some

6.7
Sequential Monte Carlo Inference
315
Time (weeks)
Size
0
100
200
300
0.5
1.0
1.5
2.0
(a) gamma prior of size
(b) uniform prior of size
(c) uniform prior of inverse of size
(a) gamma prior of size
State variance
2
4
6
8
10
(b) uniform prior of size
8
10
12
14
16
(c) uniform prior of inverse of size
10 20 30 40 50 60 70
Size
0.5
1.0
1.5
2.0
Size
0.5
1.0
1.5
2.0
Time (weeks)
0
100
200
300
Time (weeks)
0
100
200
300
Time (weeks)
0
100
200
300
Time (weeks)
0
100
200
300
Time (weeks)
0
100
200
300
State variance
State variance
Fig. 6.6 Posterior estimates of the size λ and state variance Z under the three priors of λ: (a)
gamma prior, (b) uniform prior and (c) uniform prior for λ−1. Shown are posterior modes with
95% credible bounds
State variance estimation (Poisson model)
Time (weeks)
State variance
0
100
200
300
0
1
2
3
4
5
6
Fig. 6.7 Posterior estimates of the state variance Z using the Poisson model; shown are the
posterior mode and 95% credible bounds
points the negative binomial model is better (e.g. for t = 105, corresponding to
week 365). Both models are reasonable and provide good forecast performance, but
there is little support for symmetric histograms for the data (we split the data in
time-intervals of length 40 and we found that they were skewed).

316
6
Non-Linear and Non-Gaussian State Space Models
Poisson
t=8
Frequency
20
30
40
50
0
100
200
300
Neg. binomial
t=8
Frequency
0
20
40
60
80
100
120
140
0 50
150
250
Poisson
t=70
Frequency
10
20
30
40
50
0
100
200
300
Neg. binomial
t=70
Frequency
0
50
100
150
0
100
300
Poisson
t=105
Frequency
20
30
40
50
0
100 200 300
Neg. binomial
t=105
Frequency
0
50
100
150
0
100 200 300
Fig. 6.8 Empirical predictive densities of the Poisson model (left panel) and the negative binomial
model (right panel). Densities are plotted at three points of time t = 8, 70, 105 and the observed
counts are depicted by the vertical lines
6.8
Markov Chain Monte Carlo Inference
There are a number of Markov chain Monte Carlo (MCMC) procedures aimed
at Bayesian inference of non-linear and non-Gaussian state space models. These
procedures tend to be model-speciﬁc and there is not a general procedure. For
example, Carlin et al. (1992) propose a Gibbs sampling algorithm for the model
of Sect. 6.7.7. For the class of dynamic generalised linear models, which includes a
wide number of popular models (Sect. 6.2), Gamerman (1998) develops MCMC
procedure based on Metropolis-Hastings and Gibbs sampling; this procedure is
discussed in Gamerman and Lopes (2006) and is described below.

6.8
Markov Chain Monte Carlo Inference
317
6.8.1
Metropolis-Hastings Algorithm
In this section we describe the basic notion of Metropolis-Hastings MCMC
estimation procedure. Consider the problem of sampling from a target distribution
with density π(θ) of some random vector θ; in Bayesian inference this typically will
be a posterior distribution. Assuming this is a complicated distribution to sample
from MCMC proposes sampling from a Marko chain whose stationary distribution
is π(·); see Sect. 5.7 for a discussion of the basic notion of MCMC and for a
discussion of the Gibbs sampler.
The basic idea of Metropolis-Hastings algorithms is to use a kernel density to
simulate states of a Markov chain, instead of sampling from the target density
π(·), which is complicated. To the following we discuss how this kernel may be
chosen. Let p(θ, φ) be a kernel so that it deﬁnes a Markov chain whose stationary
distribution is π(θ). One way to achieve this is by adopting the condition
π(θ)p(θ, φ) = π(φ)p(φ, θ),
for all θ and φ. This condition deﬁnes a reversible chain whose stationary distribu-
tion is π(θ); for details see Gamerman and Lopes (2006, Section 4.6).
The density kernel p(θ, φ) consists of a transition kernel q(θ, φ) and of a
probability α(θ, φ) so that
p(θ, φ) = q(θ, φ)α(θ, φ).
(6.61)
There is a positive probability for the chain to remain at the current value θ
p(θ, θ) = P(chain remains at current value θ)
= 1 −P(chain moves from θ to φ,
φ ̸= θ)
= 1 −
"
A
q(θ, φ) dφ > 0,
where A is the domain of θ.
Equation (6.61) deﬁnes a density kernel, which describes the distribution of
moving the chain from the current value θ to φ. Speciﬁcally, for any subset B of
A we have
p(θ, φ ∈B) =

1 −
*
A q(θ, φ) dφ +
*
B q(θ, φ) dφ,
θ ∈B
*
B q(θ, φ) dφ,
θ /∈B
(6.62)
Hastings proposed to deﬁne α(θ, φ) as
α(θ, φ) = min
(
1, π(φ)q(φ, θ)
π(θ)q(θ, φ)
)
(6.63)

318
6
Non-Linear and Non-Gaussian State Space Models
so that the transition kernel q(θ, φ) deﬁnes a reversible chain. Algorithms adopt-
ing Eqs. (6.62)–(6.63) are known as Metropolis-Hastings algorithms, hereinafter
referred to as M-H. The basic M-H algorithm is described below:
1. Set an initial value for θ(0). Set the counter j = 1.
2. For each j = 1, 2, . . ., N
a. Generate a proposal state φ∗from the density kernel q(θ(j−1), φ).
b. Evaluate the acceptance probability α(θ(j−1), φ∗), using (6.63).
c. Draw a single value u from a Uniform distribution U(0, 1). If u
<
α(θ(j−1), φ∗), then the proposal φ∗is accepted and we set θ(j) = φ∗. If
u ≥α(θ(j−1), φ∗), the proposal φ∗is rejected and the chain remains at state
θ(j−1); in this case we set θ(j) = θ(j−1).
It can be shown that as N →∞the chain is simulated from the stationary
distribution π(θ). The algorithm was ﬁrst proposed by Metropolis et al. (1953)
and further extended by Hastings (1970), hence its name as Metropolis-Hastings
algorithm.
For the application of this algorithm the kernel q(θ, φ) has to be chosen. A typical
choice suggests that q is symmetric, so that q(θ, φ) = q(φ, θ). This choice, initially
proposed by Metropolis et al. (1953), (6.63), simpliﬁes to
α(θ, φ) = min
(
1, π(φ)
π(θ)
)
,
(6.64)
which does not depend on q. Equation (6.64) offers a simple interpretation. Suppose
that the chain is at state θ(j−1), for some iteration j −1. A new proposal φ∗is
generated from q, according to the algorithm above. If π(φ∗) is small in comparison
to π(θ(j−1)), the move is rejected and the acceptance probability α, which is the
ratio π(φ∗)/π(θ(j−1)), should be small. This indicates that φ∗comes from an area
of low probability in π(·) and θ(j−1) is more plausible value for the chain. If the ratio
π(φ∗)/π(θ(j−1)) is large, then φ∗is accepted and the chain moves from θ(j−1) to
φ∗(the proposal φ∗is accepted).
In order to apply the algorithm a kernel q(θ, φ) has to be chosen. This has to
be a density which is easy to simulate from. The most common choice, which
was originally proposed in Metropolis et al. (1953), is the random walk choice.
According to this φ∗is generated from φ∗= θ(j) = θ(j−1) + wj, where wj is
a random variable following a normal distribution N(0, V ), for some variance V
(other symmetric distributions such a Student t may be used). In other words φ∗is
generated from an N(θ(j−1), V ). The variance V is crucial in the application of the
algorithm. A large value of V will result in large transition proposals from θ(j−1)
to φ∗and these are likely to generate very low acceptance rates. This can cause
delays of the algorithm and even convergence problems of the chain. If the variance
V is small, then the value of φ∗is close to θ(j−1), which is likely to result in high
acceptance rates. This in turn may cause delays as the chain moves very slowly
and will require a large number of iterations to achieve convergence. There is not

6.8
Markov Chain Monte Carlo Inference
319
an optimal acceptance rate, but several authors have reported that rates in the range
10–15% work best. Hence after some experimentation the variance V can be chosen
to achieve a desirable acceptance rate. So far we have assumed that θ is scalar. If θ
is a vector, the above discussed are valid with small modiﬁcations.
Next we give a toy example to illustrate the M-H algorithm. Suppose we wish to
simulate a sample from a gamma distribution θ ∼G(2, 3), or from target density
π(θ) = 4.5θ exp(−3θ), for θ > 0. We remark that M-H algorithm should only be
used for distributions that direct sampling is not available, but in this case we use
this example for illustration.
We apply the M-H algorithm with arbitrary initial value θ(0) = 3, using a random
walk kernel, with V = 1. We have used N = 10,000 iterations and the ﬁrst 1000
iterations are used for training or burn in. Figure 6.9 shows the trace plot (the plot
of the simulated values of θ(j), for j = 1, 2, . . ., 10,000) and the histogram of θ(j),
j = 1001, 1002, , . . ., 10,000. The ﬁrst 1000 values θ(j), depicted in the top panel
of the ﬁgure by the vertical line, are used for training the chain and removed from
the histogram in the lower panel. The gamma density is plotted and we remark that
Simumalted values of the chain
Iteration
0
2000
4000
6000
8000
10000
0.0
1.0
2.0
3.0
Histogram of the simulated values
Density
0.0
0.5
1.0
1.5
2.0
2.5
3.0
0.0
0.4
0.8
Fig. 6.9 Trace plot (top panel) and histogram (lower panel) of simulations using the M-H
algorithm. The target distribution is a gamma G(2, 3) and is depicted in the lower panel with
red line. The vertical line in the top panel depicts the burn in period at 1000 iterations

320
6
Non-Linear and Non-Gaussian State Space Models
the simulated values of the chain approximate well the true density function of the
gamma distribution.
6.8.2
MCMC for Dynamic Generalised Linear Models
Consider the dynamic generalised linear model (DGLM) deﬁned by Eqs. (6.4)–(6.6)
together with the prior (6.7) placed on β0. Suppose that the covariance variance
Zt = Z is time-invariant and an inverse Wishart prior is placed on Z, i.e. Z ∼
IW(ν, S), for some degrees of freedom ν and some scale matrix S. For more details
about the DGLM see the discussion of Sect. 6.2. The discussion below is based on
Gamerman (1998), but other approaches are available, see e.g. Shephard and Pitt
(1997). Book-length coverage of MCMC for DGLMs can be found in Gamerman
and Lopes (2006, Section 6.5.3) and Fahrmeir and Tutz (2001, Section 8.3).
Suppose we have a collection of observations y = (y1, y2, . . . , yn)⊤and we
wish to obtain approximations of the posterior distribution of βt | y and Z | y, for
each t = 1, 2, . . ., n. Let β⊤= (β⊤
1 , . . . , β⊤
n ) be a vector, which includes all state
vectors from t = 1 to t = n. The joint posterior distribution of β and Z is
p(β, Z | y) ∝p(y | β, Z)p(β | Z)p(Z)
=
n
-
t=1
p(yt | βt)
n
-
t=1
p(βt | βt−1, Z)p(Z)
(6.65)
Isolating block β we have
p(β | y) ∝
n
-
t=1
p(yt | βt)
n
-
t=1
p(βt | βt−1, Z)p(Z)
∝exp
 n

t=1
1
at
%
γ ⊤
t z(yt) + b(γt)
&
−1
2
n

t=1
(βt −Ftβt−1)⊤Z−1(βt −Ftβt−1)
+
,
(6.66)
where p(yt | βt) is the exponential family density (6.4) and p(βt
| βt−1, Z
is a multivariate normal density implied by the state evolution, βt | βt−1, Z ∼
N(Fβt−1, Z).

6.8
Markov Chain Monte Carlo Inference
321
Isolating block βt, for t = 1, . . . , n −1 we have
p(βt | y) ∝p(yt | βt)p(βt | βt−1, Z)p(βt+1 | βt, Z)
∝exp
( 1
at
%
γ ⊤
t z(yt) + b(γt)
&
−1
2(βt −Ftβt−1)⊤Z−1(βt −Ftβt−1)
−1
2(βt+1 −Ft+1βt)⊤Z−1(βt+1 −Ft+1βt)
)
(6.67)
while for t = n the posterior of βn is
p(βn | y) ∝p(ynβn)p(βn | βn−1, Z) ∝exp
( 1
an
%
γ ⊤
n z(yn) + b(γn)
&
−1
2(βn −Fnβn−1)⊤Z−1(βn −Fnβn−1)
)
.
(6.68)
Finally, from (6.65) the posterior of Z is
p(Z | y) ∝
n
-
t=1
p(βt | βt−1, Z)p(Z)
∝
n
-
t=1
|Z|−1/2 exp
(
−1
2trace
%
(βt −Ftβt−1)(βt −Ftβt−1)⊤Z−1&)
×|Z|−(ν+p+1)/2 exp
(
−1
2trace

SZ−1)
= |Z|−(ν+n+p+1)/2
× exp

−1
2trace
 n

t=1
(βt −Ftβt−1)(βt −Ftβt−1)⊤+ S
!
Z−1
+
,
which is proportional to the inverse Wishart distribution
Z | y ∼IW
 
ν + n,
n

t=1
(βt −Ftβt−1)(βt −Ftβt−1)⊤+ S
!
.
(6.69)
The states may be sampled all together in the block β, using posterior (6.66) or using
the individual posteriors (6.67) and (6.68), for each time t. None of these posteriors
are known distributions, from which we can sample and hence for the sampling
of the states we have to resort to a Metropolis-Hastings algorithm. Assuming we
have sampled the states βt, the covariance matrix Z can be sampled in a Gibbs
step, since we can easily sample from the inverse Wishart distribution (6.69). Hence

322
6
Non-Linear and Non-Gaussian State Space Models
the proposed algorithm is a so-called hybrid algorithm, which combines Gibbs and
Metropolis-Hastings sampling. Speciﬁcally, conditionally on an iteration of a Gibbs
step for Z we can use a M-H step and sample the states βt (either all together in
the block β or one by one for each time t). The random walk chain is not proven
to have good performance as a proposal distribution, see e.g. the discussion in
Gamerman and Lopes (2006, Section 6.5.3). Instead, the proposal distribution of
β (or βt if sampling βt individually) can be based on the smoothed distribution
of β | y (or βt | y, if we sample βt individually) assuming the response yt is
Gaussian, with matching mean and variance as the true distribution of p(yt | γt).
These distributions provided by the ﬁxed-interval smoothing (see Theorem 3.4 at
Sect. 3.3.1) are multivariate normal and are easy to sample from. An alternative
approach is to use as proposal distribution a multivariate normal distribution, with
moments provided by the approximations of West et al. (1985); see also the review
of Triantafyllopoulos (2009).
The algorithm, which is summarised below, is essentially a Metropolis within
Gibbs algorithm. The convergence of a hybrid algorithm and related aspects of
its performance are discussed in Gamerman and Lopes (2006, Chapter 6) and in
references therein.
MCMC Algorithm for the DGLM
In the dynamic generalised linear model (6.4)–(6.6), with the priors on β0 and
Z as above, the following apply:
1. Set initial values of the states β(0)⊤= [β(0)⊤
1
, . . . , β(0)⊤
n
] and covariance
matrix Z(0). Set the iteration counter to j = 1.
2. For each iteration j = 1, . . . , N, draw β∗from the proposal density pro-
vided by an application of the ﬁxed-interval smoothing (see Theorem 3.4
at Sect. 3.3.1), assuming that y | β is Gaussian with matching moments
the moments of p(y | β) of (6.4).
3. Calculate the acceptance probability α(β(j−1), β∗) and draw a single u
from a uniform distribution U(0, 1). If u < α(β(j−1), β∗), the proposal β∗
is accepted and we set β(j) = β∗, otherwise the move is rejected and we
set β(j) = β(j−1).
4. Draw Z(j) from the inverse Wishart distribution (6.69) where βt = β(j)
t
obtained from Step 3.
If the states are updated individually, then steps 2 and 3 are replaced by
2′ For each iteration j = 1, . . ., N, draw β∗
t from the proposal density pro-
vided by an application of the ﬁxed-interval smoothing (see Theorem 3.4
at Sect. 3.3.1), assuming that yt | βt is Gaussian with matching moments
the moments of p(yt | βt) of (6.4).
(continued)

6.8
Markov Chain Monte Carlo Inference
323
3′ Calculate the acceptance probability α(β(j−1)
t
, β∗
t ) and draw a single ut
from a uniform distribution U(0, 1). If ut < α(β(j−1), β∗
t ), the proposal
β∗
t is accepted and we set β(j)
t
= β∗
t , otherwise the move is rejected and
we set β(j)
t
= β(j−1)
t
.
Some comments are in order. First of all the algorithm provides in-sample
estimation for the states βt, i.e. the approximation of the densities p(βt | y)
are the smoothed densities, while p(Z | y) is the posterior distribution of Z. If
approximations of the posterior distribution of p(βt | y1:t) are required, then the
algorithm has to be applied repeatedly over time. Likewise a single application of
the algorithm can provide approximation of the forecast distribution p(yn+k | y),
for some integer k. If forecasts are required sequentially over time, the algorithm
has to be applied repeatedly and this can cause the algorithm to be slow.
It might be desirable to update the block β at once at each iteration, hence adopt
steps 2 and 3 in the above algorithm. This can be effective as at each iteration we
compute the acceptance probability once. However, if the dimension of the state
vector βt is medium or high or if the length of the data n is medium or large, then
β will be high dimensional and the M-H step is likely to experience convergence
problems. Random walk chains are not advisable for the proposal distribution, as
they create highly correlated states, which result in slow convergence. A second
difﬁculty related to calibrating the chain in order to obtain optimal acceptance rates.
The approximate ﬁxed interval smoothing for the proposal distribution is a good
option. Another possibility, proposed in Shephard and Pitt (1997), is to combine
independent chains and chains from the prior distribution of the states.
We conclude this section by considering a simple simulation study in illustrate
estimation based on the MCMC scheme of this section. We simulate 70 observations
from the dynamic Poisson model (6.8)–(6.10), i.e.
yt | βt ∼Poisson[exp(βt)]
and
βt = βt−1 + ζt,
where ζt ∼N(0, Z). The states βt, which here are the log rates of the Poisson,
are simulated by a random walk with initial state simulated by β0 ∼N(0, 10)
and a state variance Z = 2.5. The top left panel of Fig. 6.10 shows the simulated
states (solid lines). For the estimation of the states and the state variance, we have
used the block hybrid MCMC scheme described above. A random walk chain and
a Gaussian proposal are used: experimentation has led to set the variance of the
proposal distribution equal to 0.6 in order to achieve an acceptance probability equal
to 28.53% (the small variance allows for small moves of the chain, which works here
as βt is univariate and is unimodal). The chain is run for 10,000 iterations, and the
ﬁrst 1000 are used as burn-in and the last 1000 are used for illustration purposes.

324
6
Non-Linear and Non-Gaussian State Space Models
Smooth estimates of the states
Time
States
0
10
20
30
40
50
60
70
-1
0
1
2
3
State variance
Time
State variance
0
10
20
30
40
50
60
70
0
1
2
3
4
5
Histogram of the states at t=48
State
Frequency
-2
-1
0
1
2
0
200
400
600
800
Histogram of the state variance at t=48
State variance
Frequency
0
20
40
60
80
100
0
200 400 600 800
Fig. 6.10 MCMC estimation for the dynamic Poisson model. Top left panel (estimation of βt):
smoothed mode (dotted line) and true states (solid line). Top right panel (estimation of Z): posterior
mode (solid line), 95% credible bounds (dashed line) and true value (horizontal line). Bottom
panels: histogram of smooth estimates of β48 (shown is the true value of β48 = 1.5284, depicted
by the vertical line, and histogram of posterior estimate of Z at t = 48; the vertical line indicate
the true value Z = 2.5
Trace plots and their correlograms (not shown here) indicate convergence of the
chain. Figure 6.10 shows smoothed estimates of the states (top left panel), posterior
mode of the state variance Z, together with 95% credible intervals (top right panel),
histogram of the estimated state β48 at time t = 48 and histogram of the state
variance Z at t = 48. We remark that the smooth estimates of the states seems to
follow well the simulated states, the posterior mode of the Z is close to the true
value Z = 2.5, although it does seem to slightly overestimate the variance.

6.9
Dynamic Survival Models
325
6.9
Dynamic Survival Models
6.9.1
Proportional Hazards Model
Over the past 50 years survival modelling has been developed extensively in
medicine (Martinussen & Scheike, 2006; van Houwelingen & Putter, 2012), eco-
nomics (Gamerman & West, 1987; Djeundje & Crook, 2019) and other disciplines
(Cox, 1972; Cox & Oakes, 1984; Collett, 2003). Survival analysis is focused around
the survival function
S(t) = P(T > t),
for some random variable T denoting survival time. Hence the survival function at
time t is the probability T exceeding t. We consider that T is generated by a density
function f (·), with cumulative distribution function F(·), so that S(t) = 1 −F(t).
Associated with the survival function is the hazard function λ(t) deﬁned as
λ(t) = lim
t→0
P(t < T ≤t + t | T > t)
t
.
It follows that
λ(t) = f (t)
S(t) ,
S(t) = exp

−
" t
0
λ(u) du
	
,
f (t) = λ(t) exp

−
" t
0
λ(u) du
	
.
Of particular interest is the case of T following an exponential distribution, which
is discussed next.
Assuming that T follows an exponential distribution T ∼Exp(λ), with density
function
f (t) = λ exp(−λt),
then it is easy to show that the associated hazard function is constant, i.e.
λ(t) = λ
and the survival function is
S(t) = exp(−λt).

326
6
Non-Linear and Non-Gaussian State Space Models
Often observations of survival times T = t are observed in discrete time. Usually,
discrete time points t0, t1, . . . , ts−1 are picked and time t ≥0 is partitioned into s
intervals of time I1, I2, . . . , Is, deﬁned as I1 = [t0, t1), I2 = [t1, t2), . . . , Is =
[ts−1, ∞), for some s > 1. Survival times are then observed within these intervals
of time.
The basic model of Cox (1972) considers a hazard function
λ(t) = λ0(t) exp(x⊤β),
(6.70)
where λ0(t) is a baseline hazard function, x is a vector of p covariates or x =
[x1, . . . , xp]⊤and β is a p-dimensional coefﬁcient vector subject to estimation. This
model is known as proportional hazards model, as the covariates x affect the hazard
only by a proportionality factor (Cox, 1972). Other approaches for the modelling
of the hazard function include the use of generalised linear models such as logistic
regression and Poisson regression; see e.g. the review of Kearns et al. (2019).
6.9.2
Dynamic Survival Model
Time-varying covariates are discussed in Cox and Oakes (1984) who develop
partial-likelihood estimation introduced in Cox (1975) to deal with time-dependent
covariates; see also Kedem and Fokianos (2002) for a discussion of partial likeli-
hood in the context of generalised linear modelling. Gamerman (1991) extended the
above models to incorporate time-varying effects of the coefﬁcients β, by replacing
this parameter vector by a time-varying vector of coefﬁcients β(t). Hence (6.70) is
replaced by
λ(t) = exp
 
β0(t) +
p

k=1
x⊤
k βk(t)
!
= exp[z⊤β(t)],
(6.71)
where z⊤= [1, x⊤] and β0(t) denotes the log-baseline. A piecewise exponential
distribution is considered, where hazard function λ(t) is a step-function, or
λ(t) =
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎩
λ1,
t ∈I1 = [t0, t1],
...
...
λi,
t ∈Ii = (ti−1, ti],
...
...
λs,
t ∈Is = (ts−1, ∞),

6.9
Dynamic Survival Models
327
with corresponding coefﬁcients β(t), which are allowed to vary according to a
random walk within each interval Ii, or
β0(t) = β0i,
t ∈Ii,
(6.72)
βk(t) = βki,
t ∈Ii,
(6.73)
for i = 1, . . . , s and k = 1, . . . , p. Gamerman (1991) and Hemming and Shaw
(2002) consider a random walk evolution for β0t and βki, i.e.
β0i = β0,i−1 + ζ0i,
ζit ∼N(0, Z0),
(6.74)
βki = βk,i−1 + ζki,
ζki ∼N(0, Zk),
(6.75)
for some variances Z0 and Zk. This is supported by considering that locally we
would expect E(βki) = E(βk,i−1), but with increased uncertainty, hence the random
walk evolution. It is assumed that βki and βlj are independent for any k ̸= l and for
any i, j.
A Gaussian prior distribution is set for β0t and βki, i.e.
β0i ∼N( ˆβ0i, P0i)
and
βki ∼N( ˆβki, Pki),
(6.76)
for some known means ˆβ0i, ˆβki and variances P0i, Pki, for each i = 1, . . . , N.
The dynamic survival model adopts hazard function λ(t) of (6.72) (together
with the piece-wise exponential structure), which is equivalent to T following an
exponential distribution T ∼Exp(λ(t)). The states in (6.72)–(6.73) attain evolution
equations (6.74)–(6.75) and the model is completed by specifying the priors (6.76).
In survival analysis it is very common to experience censoring. If for some units
the event we are measuring has occurred then we know the exact waiting time and
there is no censoring. If, however, the event has not occurred all we know is that
the waiting time exceeds the observation time. This is the case of censoring. For
example, imagine that we collect time to death in a cancer study. If we know that
patient i died at time t∗
i in the interval [ti, ti+1), we have no censoring (as we know
the time up to death). If, however, the patient has not died in the interval [ti, ti+1), all
we know is that death time t∗≥ti+1. There are various mechanisms of censoring,
the most common being Type I, Type II and random censoring; here we brieﬂy
discuss random censoring, but for a more in-depth discussion the reader is referred
to Fahrmeir and Tutz (2001, Chapter 9) and in Collett (2003). In random censoring
each unit is labelled either a lifetime Ti or a censoring time Ci, both of which are
assumed to be random variables. We then observe Yi = min(Ti, Ci) and an indicator
variable δi, which tells us whether an observation is terminated by death (Yi = Ti)
or by censoring (Yi = Ci).

328
6
Non-Linear and Non-Gaussian State Space Models
Suppose that we observe n units, with survival function S(t) and associated
density p(t) and hazard λ(t). If we observe unit i for time ti. If the unit died at
ti, then its contribution to the likelihood function is
Li = f (ti) = S(ti)λ(ti).
On the other hand, if the unit survives at ti, then its contribution to the likelihood is
just its survival function, or
Li = S(ti).
We can combine the two events in the likelihood function, which is given by
L =
n
-
i=1
Li =
n
-
i=1
λ(ti)δiS(ti),
(6.77)
where δi = 1, if Ti is observed (lifetime is observed) and δi = 0, if Ci is observed
(censoring is observed).
For the piece-wise exponential model described above the hazard is a piece-
wise constant function which changes at each interval Ii. Let the interval at which
censoring occurred for observation i is denoted by Imi+1. The contribution of
observation i to the likelihood is broken into the probability of surviving each
interval (up to interval Imi+1) conditionally on surviving at the previous interval.
Hence
S(ti) =
mi
-
j=1
P(T > tj | T > tj−1)P(T > ti |> tmi)
and from (6.77) the likelihood function is
L =
n
-
i=1
mi
-
j=1
P(T > tj | T > tj−1)P(T > ti > tmi)λ(ti)δi.
(6.78)
Fix t > tj−1 (j = 1, . . . , mi). Then the survival function in interval Ij is
P(T > t | T > tj−1) = exp
 
−
" t
tj−1
λ(u) du
!
= exp
 
−
" t
tj−1
exp(z⊤βj) du
!
= exp[−exp(z⊤βj)(t −tj−1)],

6.10
Exercises
329
where βj = [β0j, β1j, . . . , βpj]⊤. Hence likelihood (6.78) is
L =
n
-
i=1
exp
⎡
⎣−
mi

j=1
exp(z⊤
i βj)(tj −tj−1)
⎤
⎦exp[−exp(z⊤
i βmi+1)(ti −tmi]
× exp(z⊤
i βmi+1δi)
= exp
⎡
⎣−
n

i=1
mi

j=1
exp(z⊤
i βj)(tj −tj−1) −
n

i=1
exp(z⊤
i βmi+1)(ti −tmi)
+
n

i=1
z⊤
i βmi+1δi
!
.
Suppose data {t0, t1, . . . , ts−1} on s survival times are available. We wish to
estimate the coefﬁcients β(t) so as to provide an estimate of the hazard function
λ(t). Maximum likelihood estimation is possible, but will need to resort to
numerical methods; for a discussion see Fahrmeir and Tutz (2001, Chapter 9). Most
of the literature seems to focus on Bayesian estimation instead.
Gamerman and West (1987) and Gamerman (1991) propose approximate
Bayesian inference based on the approach of West et al. (1985). Wilson and
Farrow (2017) adopt a Bayes linear kinematics approach for inference of dynamic
survival modelling and apply their model to survival times of leukaemia patients.
Fahrmeir (1994) propose a penalised likelihood estimation approach, leading to
Kalman-type smoothing algorithms; see also Fahrmeir and Tutz (2001, Chapter 9)
for this approach. Hemming and Shaw (2002, 2005) and Wagner (2011) propose
inference based on Markov chain Monte Carlo (MCMC) methods. A comparison
between the Bayes linear estimation of Gamerman (1991) and MCMC inference
with the focus on medical application is given in He et al. (2010). A dynamic
cured fraction model is developed in Kearns et al. (2021) and is shown to improve
extrapolations in the hazard function of curative treatments, whilst being robust to
model misspeciﬁcation.
6.10
Exercises
1. Consider that the time series {yt} is generated by the gamma distribution yt |
αt, βt ∼G(αt, βt), for some parameters αt and βt. Show that yt belongs to the
exponential family of distributions (6.4), with γt = −βt, at = 1, z(yt) = yt,
b(γt) = −αt log βt and c(yt) = (αt −1) log yt −log (αt), where (·) denotes
the gamma function. Observe that for αt = 1 the exponential distribution is
obtained, i.e. yt | βt ∼Exp(βt).

330
6
Non-Linear and Non-Gaussian State Space Models
2. Extend the exponential family (6.4) to accommodate for a matrix-variate time
series as follows. Let yt be a matrix-variate time series. We shall say that
the distribution of p(yt | γ t) deﬁnes the natural matrix-variate exponential
family of distribution if vec(yt) attains the exponential form (6.4) with natural
parameter vector vec(γ t) and where, for simplicity, z(·) is assumed to be
the identity function. Show that the matrix-variate exponential family can be
written as
p(yt | γ t) = exp
( 1
at
[trace(γ ⊤
t yt) −b(γ t)] + c(yt)
)
,
where the functions b(·) and c(·) map the matrices γ t and yt, respectively, to
the real line.
3. Consider that the p×p matrix-variate time series {yt} is generated by a Wishart
distribution, with density function
p(yt | n, t) = 2−np/2|t|−n/2
p(n/2)
|yt|(n−p−1)/2 exp

−1
2trace(−1
t
yt)

,
where n > p −1 are the degrees of freedom, t is the scale covariance
parameter matrix and p(·) denotes the multivariate gamma function. The
Wishart distribution is discussed in Sect. 5.5.2.
Show that the above Wishart distribution belongs to the matrix-variate
exponential family of Exercise 2, with γt = −2−1−1
t
, b(γ t) = 2−1n log |t|
and c(yt) = 2−1(n −p −1) log |yt| −2−1np log 2 −log p(n/2).
4. In the context of the power local level model of Sect. 6.5 show that if δ = 1
prior (6.36) implies that βt = ψt(β0), for some deterministic function ψt(·),
i.e. the state βt depends stochastically only on β0.
As a special case of the above consider the Gaussian local level model yt =
βt + ϵt and βt = βt−1 + ζt, where ϵt ∼N(0, σ 2) and ζt ∼N(0, Zt), for some
variances σ 2 and Zt and remaining assumptions as in the state space model
(3.10a)–(3.10b). Adopting the discounting approach of Eq. (6.35) for δ = 1,
establish that yt = β0 + ϵt, i.e. this model is reduced to a static simple linear
regression model.
5. Consider the Poisson-gamma local level model of Sect. 6.5.2. Deﬁne the
transition
λt = λt−1ξt
δ
,
(6.79)
where λt−1 | y1:t−1 ∼G(αt−1, βt−1), ξt is a random variable, which is
independent of λt−1 and follows the beta distribution ξt ∼Beta[δαt−1, (1 −
δ)βt−1], for some discount factor δ. Show that
λt | y1:t−1 ∼G(δαt−1, δβt−1).

6.10
Exercises
331
Hence establish that transition (6.79) yields exactly the same prior distribution
λt | y1:t−1 ∼G(δαt−1, δβt−1), which is the result of the power law (6.36).
6. Consider that the categorical time series yt is modelled with a binomial model
p(yt | πt) =
nt
yt
	
πyt
t (1 −πt)nt−yt,
yt = 0, 1, 2, . . . , nt
for some known integer nt > 0. Let the posterior distribution of πt−1 given
y1:t−1 be a beta distribution, πt−1 | y1:t−1 ∼Beta(αt−1, βt−1), for some known
αt−1, βt−1 > 0. In the context of power local level models adopt a discount
factor δ.
a. Show that the prior distribution of πt, given y1:t−1 is a beta distribution πt =
π | y1:t−1 ∼Beta(δαt−1 −δ + 1, δβt−1 −δ + 1).
b. Upon yt being observed, show that the posterior distribution of πt, given
y1:t = (yt, y1:t−1) is a beta distribution πt | y1:t ∼Beta(αt, βt), where
αt = δαt−1 −δ + 1 + yt and βt = δβt−1 −δ + 1 + nt −yt.
c. Given information y1:t, show that the one-step forecast distribution of yt+1
is
p(yt+1 | y1:t) = (δβt + yt+1)δαt+2−δ
(δαt + 2 −δ)
,
where αt and βt are computed as above.
7. Suppose that the time series yt representing continuous proportion follows a
beta distribution yt | βt ∼Beta(1, βt), so that
p(yt | βt) = βt(1 −yt)βt−1,
0 ≤yt ≤βt,
for some βt > 0. Assume that at time t −1 the posterior distribution of βt−1 is
a gamma distribution with known parameters dt−1 and gt−1, i.e. βt−1 = β ∼
G(dt−1, gt−1). Adopt power local level models for a known discount factor
δ.
a. Show that the prior distribution of βt
= β given y1:t−1 is a gamma
distribution βt = β | y1:t−1 ∼G(δdt−1 −δ + 1, δgt−1.
b. Given observation yt, show that the posterior distribution of βt a gamma
distribution, i.e. βt = β | y1:t ∼G(dt, gt), where dt = δdt−1 −δ + 2 and
gt = δgt−1 −log(1 −yt).
8. Let yt be a time series deﬁned on an interval [0, βt], for some time-varying
parameter βt > 0. Suppose that, given βt, yt follows a uniform distribution, so
that
p(yt | βt) = 1
βt
,
0 ≤yt ≤βt.

332
6
Non-Linear and Non-Gaussian State Space Models
Assume that at time t −1, the posterior distribution of βt−1 = β is a Pareto
distribution (see also Exercise 10) with density function
p(βt−1 = β | y1:t−1) =
dt−1gdt−1
t−1
βdt−1+1 ,
β ≥gt−1,
for some known parameters dt−1, gt−1 > 0. We shall write βt−1 = β | y1:t−1 ∼
Pareto(dt−1, gt−1) to denote this distribution. Within the context of power local
level modelling adopt a discount factor δ.
a. Show that the prior distribution of βt = β given information y1:t−1 is a
pareto distribution, βt = β | y1:t−1 ∼Pareto(δdt−1 + δ −1, gt−1).
b. Upon observing yt update the information as y1:t = (y1:t−1, yt). Show that,
given y1:t, the posterior distribution of βt = β is a Pareto distribution βt |
y1:t ∼Pareto(dt, gt), where dt = δdt−1 + δ −1 and gt = max{yt, gt−1}.
9. Consider the dynamic Poisson model
yt | λt ∼Poisson(λt),
so that the log rate follows a random walk model
log λt = βt = βt−1 + ζt,
where ζt ∼N(0, Z), for some variance Z.
Show that given λt−1, the rate λt follows a log-normal distribution, with
density function
p(λt | λt−1) =
λt−1
λtZ
√
2π
exp
(
−(log λt −log λt−1)2
2Z
)
.
Show that, given λt−1, the mean and the variance of λt are
E(λt | λt−1) = λt−1 exp
Z
2
	
and
Var(λt | λt−1) = λ2
t−1[exp(Z) −1] exp(Z).
10. Consider that the random vector X = [X1, . . . , Xk]⊤follows the Dirichlet
distribution with parameter vector α = [α1, . . . , αk]⊤. The density function of
X is
p(x) =
1
D(α)
k-
i=1
xαi−1
i
,

6.10
Exercises
333
where D(α) is the Dirichlet function and k
i=1 xi = 1; this distribution is
discussed in Sect. 6.2.4.
a. Show that for k = 2 (beta distribution), the mode of X1 is (α1 −1)/(α1 +
α2 −2).
b. Show that for k = 3, the modes of X1, X2 are (α1 −1)/(α1 + α2 + α3 −3)
and (α2 −1)/(α1 + α2 + α3 −3), respectively.
c. Deduce that for any k ≥2, the mode of Xi is
αi −1
k
j=1 αj −k
,
for i = 1, . . . , k −1.
11. Consider that the time series {yt} is generated from a multinomial distribution
with a probability vector πt = [π1t, . . . , πkt]⊤on k categories, with joint
probability mass function
p(yt | πt) =
λt!
5k
i=1 yit!
k-
i=1
πyit
it ,
where λt = k
i=1 yit and k
i=1 πit = 1. This distribution is described in
Sects. 2.3.2 and 6.2.3.
Suppose that at time t −1 the posterior distribution of πt−1 is a Dirichlet
distribution, written as πt−1 = π ∼Dir(αt−1), so that its density is
p(πt−1 = π | y1:t−1) =
1
D(αt−1)
k-
i=1
παi,t−1−1
j
,
where π = [π1, . . . , πk]⊤, αt−1 = [α1,t−1, . . . , αk,t−1]⊤and D(·) denotes the
Dirichlet function. This distribution is discussed in more detail in Sect. 6.2.4.
a. Upon observing yt, show that the posterior distribution of πt = π, given y1:t
is πt = π | y1:t ∼Dir(αt), where
αit = δαi,t−1 + 1 −δ + yit,
with αt = [α1t, . . . , αkt]⊤.
b. Using the posterior distribution of πt = π and the prior distribution of
πt+1 = π, given information y1:t, verify that the mode of πt+1 = π is
equal to the mode of πt = π.

334
6
Non-Linear and Non-Gaussian State Space Models
HINT: you may use the result of Exercise 10.
c. Show that the one-step forecast distribution of yt+1 is
p(yt+1 | y1:t) =
λt+1!D(α∗
t+1 + yt+1)
5k
i=1 yi,t+1!D(α∗
t+1)
,
where α∗
t+1 = [α∗
1,t+1, . . . , α∗
k,t+1]⊤and α∗
i,t+1 = δαit + 1 −δ.
12. Consider the binomial model (6.14)–(6.16) for the categorical time series yt
with size λt (see model (6.14)–(6.16) for details). Suppose that at time t
the prior mean vector of βt, ˆβt|t−1, is known. Show that this model can be
approximated by the linear and Gaussian model with observation equation
yt ≈
λt exp(x⊤
t ˆβt|t−1)
[1 + exp(x⊤
t ˆβt|t−1)]2 x⊤
t βt + εt,
where xt is the design vector of the linear predictor ηt = x⊤
t βt (see model
(6.14)–(6.16) for a full description of the binomial state space model), εt ∼
N(μt, Vt), with
μt =
λt exp(x⊤
t ˆβt|t−1)
[1 + exp(x⊤
t ˆβt|t−1)]2
%
1 + exp(x⊤
t ˆβt|t−1) −x⊤
t ˆβt|t−1
&
and
Vt =
λt exp(x⊤
t ˆβt|t−1)
[1 + exp(x⊤
t ˆβt|t−1)]2 .
13. Consider the conditionally Gaussian state space model of Sect. 6.7.7, given by
equations
yt = β2
t
20 + ϵt
and
βt = αβt−1 +
γβt−1
1 + β2
t−1
+ δ cos[1.2(t −1)] + ζt,
where ϵt and ζt independently follow Gaussian distributions, i.e. ϵt ∼N(0, σ 2)
and ζt ∼N(0, Z); it is also assumed that ϵt, ζt are independent of the initial
state β0, which is assumed to follow a Gaussian distribution too, i.e. β0 ∼
N(0, 10).

6.10
Exercises
335
a. Show that conditionally on βt−1 the mean vector and covariance matrix of
[βt, yt]⊤are
μt =

 ct
dt

,
Mt =

Z
c3
t + 3ctZ
c3
t + 3ctZ
Vt

,
where
ct = αβt−1 +
γβt−1
1 + β2
t−1
+ δ cos(1.2t −1.2),
dt = c2
t + Z
20
and
Vt = 3Z2 + 2ctZ
400
+ σ 2.
b. Assuming that given βt−1, the joint distribution of βt and yt is Gaussian,
show the conditional distribution of βt | βt−1, yt is N(d∗
t , V ∗
t ), with mean
and variance
d∗
t = ct + c3
t + 3ctZ
Vt
(yt −dt),
V ∗
t = Z −(c3
t + 3ctZ)2
Vt
.
c. Hence propose a particle ﬁlter with states β(i)
t
are sampled from the
importance function q(βt | βt−1, yt) ≡N(d∗
t , V ∗
t ).
14. Consider the conditionally Gaussian model of Exercises 13.
a. Simulate 100 states β1, . . . , β100 and 100 observations y1, . . . , y100 from
this model using α = 0.5, γ = 25, δ = 15, σ 2 = 8 and Z = 10.
b. Deﬁne the vector of static parameters θ = [α, γ, δ, σ 2, Z]⊤and suppose
you do not know these values from (1) above. Set the following priors for
the elements of θ:
α ∼U(0, 1)
γ ∼G(2, 0.1),
δ ∼G(1, 0.1),
σ 2 ∼IG(3, 10),
and
Z ∼IG(3, 50).
Fit the Liu and West particle ﬁlter (Algorithm PF-II on p. 311) and provide
credible bounds for the states βt and for the elements of θ.
15. Kitagawa (1987) proposes a binary process in order to model the number of
daily occurrences of rainfall over 1 mm in Tokyo (1983–1984). The following
data is a weekly aggregation of this data.

336
6
Non-Linear and Non-Gaussian State Space Models
Week 1
Week 2
Week 3
Week 4
January
4
0
4
2
February
1
2
3
3
March
2
4
6
8
April
5
5
7
2
May
4
2
5
4
June
2
7
9
11
July
4
5
10
3
August
0
2
7
2
September
3
5
10
7
October
1
5
7
3
November
2
2
4
1
December
0
1
3
3
Make an analysis of this data using a dynamic Poisson or a dynamic negative
binomial model. You will need to suggest a transition model for the states of
your state space model. You will also need to specify priors for the initial state
and the hyperparameters of your model.
16. The data aids available in the package dobson consist of 20 observations on
counts of cases of AIDS patients in Australia, sampled over quarters from 1984
to 1988. The data can be accessed in R using the commands:
> library(dobson)
> data(aids)
> attach(aids)
a. Consider the dynamic Poisson model
yt | λt ∼Poisson(λt),
(6.80)
log λt = log λt−1 + ζt,
ζt ∼N(0, Z),
(6.81)
for some variance Z. Fit this model to the data using the Liu and West ﬁlter
(Algorithm PF-II on p. 311) with a static parameter θ = Z. Use a gamma
prior for Z, i.e. Z ∼G(0.1, 0.1) (giving mean E(Z) = 1 and variance
Var(Z) = 10).
b. A more careful analysis reveals that this data is over-dispersed. A simple
analysis shows that the sample mean of the counts is 15.643, while the
sample variance is 224.555. This casts doubt over the choice of the above
Poisson model. Extend this model by considering that
yt
c ∼Poisson(λt),
(6.82)

6.10
Exercises
337
where c > 0 is some constant and λt is driven by evolution (6.81) of part
(a). Show that
E(yt) = cλt
and
Var(yt) = c2λt
and show for c > 1 this model is suitable for over-dispersed data.
i. Show that by choosing c = 14.3511 we can deal with over-dispersion
and use a Liu and West ﬁlter (Algorithm PF-II on p. 311) with a static
parameter θ = Z (see the same gamma prior for Z as in part (a)).
Comment on its performance compared to the model of part (a).
ii. Consider model (6.82) together with evolution (6.81), where now c
is subject to estimation. Fit this model using the Liu and West ﬁlter
(Algorithm PF-II on p. 311), with a static parameter vector θ = (c, Z)⊤.
Choose a gamma prior for Z as in part (a) and experiment on prior
distribution c from (1) c ∼G(0.1, 0.1) and (2) c −1 ∼G(0.1, 0.1). In
prior (1) we allow c to be smaller than one (leading to under-dispersion),
c = 1 (leading to no over/under dispersion) and c > 1 (leading to over-
dispersion). In prior (2) c > 1 is sampled from a gamma distribution plus
1 (hence referring to over-dispersion). Experiment with these priors and
comment on their performance with relevance to part (b-i) and part (a).
17. The data aihrio available in the package pgam in R consist of counts of
hospital admissions outcomes in Universidade do Estado do Rio de Janeiro,
Rio de Janeiro, Brazil. The data set gives hospital admissions over 11 different
outcomes collected over time length of 365 days. Available are also air quality
covariates, including temperature, humidity and rainfall. This data set is a
reduced data set from the source: Secretary for the Environment of the Rio de
Janeiro City, Brazilian Ministry of Defence and Brazilian Ministry of Health.
The data can be accessed in R using the commands:
> library(pgam)
> data(aihrio)
> attach(aihrio)
Consider a dynamic Poisson model
yt | λt ∼Poisson(λt),
log λt = β0t + x1tβ1t + x2tβ2t + x3tβ3t
βit = βi,t−1 + ζ1i,
ζit ∼N(0, Zi),
i = 0, 1, 2, 3,
where yt denotes the count of admission ITRESP65 (this is the ﬁrst variable of
admissions) x1t is the maximum temperature at day t, x2t is the humidity of day
t and x3t is the total rainfall at time t. Here we may assume that ζit and ζjt are
independent for i ̸= j and a normal prior is set for βi,0 ∼N(0, 100). Fit this

338
6
Non-Linear and Non-Gaussian State Space Models
model using the Liu and West particle ﬁlter PF-II (see p. 311). You will have to
set suitable priors for the estimation of the hyperparameters Z1, Z2, Z3.
18. In Exercise 15 observations consisting of annual number of telephone calls
made in Belgium were considered. Make the histogram or otherwise of this data
to demonstrate that the data are highly skewed, suggesting that an exponential
distribution might describe the data better than the Gaussian assumption,
considered in the Gaussian state space model of Exercise 15. Suggest a suitable
non-Gaussian state space model with the exponential distribution as a response
and re-analyse the data using this model.
19. In Exercises 21 data consisting of monthly totals of car drivers killed or
seriously injured were considered. Re-analyse the data suggesting a non-
Gaussian state space model. Compare the performance of this state space model
with your analysis in Exercise 21.
20. Hundred observations of annual total ﬂow from the river Nile are collected from
1871 to 1970 (source: Durbin and Koopman (2012)). The data are available in
R via the library MASS:
> library(MASS)
> data(Nile)
> y <- Nile
This data set was considered in Exercise 16 in Chap. 4. Suggest a suitable non-
Gaussian state space model to analyse this data.
21. Hundred observations are collected on internet usage per minute (source:
Makridakis et al. (1998)). The data are available in R via the library MASS:
> library(MASS)
> data(WWWusage)
> y <- WWWusage
Make the histogram of this data or otherwise establish that a Gaussian state
space model is not appropriate to describe this data. Suggest a non-Gaussian
state space model and use it to analyse this data.
22. One hundred and ﬁfty-three daily observations of ozone from May to Septem-
ber in New York are collected (source Rousseeuw and Leroy (1987, p. 86,
Table 6)). Ozone reﬂects on air-quality, see e.g. Bersimis and Triantafyllopoulos
(2020). Collected are also daily measurements on solar radiation, wind speed
and temperature. The data are available in R via the library MASS:
> library(MASS)
> data(airquality)
Note that this data set was considered in Exercise 7 of Chap. 5. Suggest
a suitable non-Gaussian state space model with Ozone as the response
and variables Solar.R, Wind and Temp as time-varying covariates. See
?airquality for a description of the data. Fit this model to the data and
provide credible intervals for the time-varying coefﬁcients of the covariates.
23. In an experiment in Sweden the effect of speed limit is studied. Drivers were
given the option of speed limit and the count of accidents were recorded (source

6.10
Exercises
339
Svenson (1981); the data are also discussed in Venables and Ripley (2002)).The
data consists of 184 daily data, with recorded count of accidents and a binary
variable whether or not speed limit was applied. The data are available in R via
the library MASS:
> library(MASS)
> data(Traffic)
Suggest a suitable non-Gaussian state space model for this data set. Fit the
model to the data and provide an estimate of the probability of the speed limit
being applied. Based on your analysis do you think the speed limit has a positive
effect in the drivers’ performance with the view to reduce accidents?

Chapter 7
The State Space Model in Finance
The application of the state space model to economics and ﬁnance has been in the
forefront of development of the Kalman ﬁlter and related algorithms. From the
local level model, introduced in 1960 by John Muth (1960), to the textbooks of
Andrew Harvey (1989), the state space model has played a key role in ﬁnancial
econometrics. This chapter aims to give some of the applications of the Kalman
ﬁlter to ﬁnance in order to illustrate its contribution to ﬁnance.
We begin in Sect. 7.1 by considering the problem of regression with autocor-
related error structure. This problem is known from the 1960s, with the work of
Zellner and Tiao (1964). It is shown how a state space model can accommodate
the inclusion of autocorrelated errors in a regression model. Section 7.2 discusses
stationarity and causality in autoregressive models. This section does not relate
directly to state space models, but it is necessary for the development of Sects. 7.3
and 7.5, which follow. In Exercise 10, stationarity conditions are used in order to
determine tradable periods, within the context of statistical arbitrage. In Sects. 7.2.2
and 7.2.3, stationarity conditions are derived in the space of autoregressive coef-
ﬁcients. Stochastic volatility models are discussed in Sect. 7.3; the state space
model has been very successful in describing volatility as a stochastic process using
conditionally Gaussian state space models (see also Sects. 1.3.3 and 6.3). Section 7.3
discusses Bayesian inference of univariate stochastic volatility models, consisting
of MCMC inference (Sect. 7.3.3) and particle ﬁlter-based inference (Sects. 7.3.4
and 7.3.5). In particular, Sect. 7.3.4 considers sequential Monte Carlo estimation for
the same volatility model for which MCMC is discussed in Sect. 7.3.3. Section 7.3.5
considers a stochastic volatility model with returns exhibiting skewness and heavy
tails and discusses sequential Monte Carlo inference for that model. Multivariate
stochastic volatility models are discussed in Sect. 7.4. We start by extending
some of the univariate models, and in Sect. 7.4.2 we discuss in some detail
Wishart autoregressive processes that are used to describe the stochastic process
of the volatility. The problem of asset allocation and optimal portfolio selection
is discussed in Sect. 7.4.3; this includes unconstrained and constrained portfolio
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2021
K. Triantafyllopoulos, Bayesian Inference of State Space Models, Springer Texts
in Statistics, https://doi.org/10.1007/978-3-030-76124-0_7
341

342
7
The State Space Model in Finance
strategies, and data consisting of the common constituents of the Dow Jones Average
Industrial index are used for illustration purposes. Statistical arbitrage, and in
particular a strategy known as pairs trading, is discussed in Sect. 7.5: the basic idea
is to take advantage of relative mispricing of two assets and aid decision-making
for proﬁtable trades. This is facilitated by detecting mean-reversion over time using
state space modelling and is discussed in some detail in that section.
7.1
Regression with Autocorrelated Errors
In regression modelling, the well known Gauss–Markov assumptions state that the
errors are independent or at least uncorrelated, see e.g. Bingham and Fry (2010).
Early work in the statistics literature involves the relaxation of this assumption,
by assuming that the errors are inter-dependent and estimating their time-invariant
correlation by maximum likelihood techniques, see e.g. McGilchrist and Sandland
(1979). In economic data, it is very common that after a regression model is ﬁtted,
the residuals are in fact autocorrelated. This phenomenon is important because
failure to deal with such autocorrelations may lead to poor model ﬁt. This problem
is known to economists as the time series problem in regression, and there are many
studies devoted to it, see e.g. Zellner and Tiao (1964) and Beach and MacKinnon
(1978). Most work in the aforementioned literature is considering that the error
terms in regression are following an AR(1) time series model. In this section we
show that a general class of regression models with autocorrelated errors can be put
in state space form.
Consider ﬁrst the simple linear regression model with autocorrelated errors,
deﬁned by
yt = β0 + β1x1t + εt,
(7.1)
where εt follows an autoregressive model of order one, abbreviated as AR(1), i.e.
εt = φεt−1 + νt,
νt ∼N(0, σ 2
ν ).
(7.2)
Here, yt is the response variable, x1t is a time-varying covariate, β0 and β1 are static
coefﬁcients (intercept and slope) and φ1 is the AR coefﬁcient. The sequence {νt} is a
white noise and so if φ = 0, the above model reduces to the usual simple regression
with independent errors. If, on the other hand φ ̸= 0, then εt and εs are dependent or
correlated, for t ̸= s. For a complete treatise of autoregressive time series models,
the reader is referred to Box et al. (2008) and Brockwell and Davis (1991).

7.1
Regression with Autocorrelated Errors
343
Model (7.1)–(7.2) can be put in state space form if we write
yt = [1, x1t, 1]
⎡
⎣
β0
β1
εt
⎤
⎦= x⊤
t βt
(7.3)
and
βt =
⎡
⎣
β0
β1
εt
⎤
⎦=
⎡
⎣
1 0 0
0 1 0
0 0 φ1
⎤
⎦
⎡
⎣
β0
β1
εt−1
⎤
⎦+
⎡
⎣
0
0
νt
⎤
⎦
= Fβt−1 + ζt.
We note that, with the deﬁnition of the state space model (3.10a)–(3.10b), ϵt = 0
(with probability 1) or σ 2 = 0.
The above discussion motivates a more general model (time-varying regression
with autocorrelated errors), deﬁned by time-varying regression equation
yt = β0t + β1tx1t + · · · + βptxpt + εt,
(7.4)
together with the autocorrelated error equation
εt = φ1εt−1 + · · · + φdεt−d + νt,
νt ∼N(0, σ 2
ν ),
where x1t, . . . , xpt are p time-varying covariates, φ1, . . . , φd are d static AR
coefﬁcients and {νt} is a white noise sequence. We assume that βit follows a random
walk, for i = 0, 1, . . . , p. This model can be written in state space form with
transition equation
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
β0t
β1t
...
βpt
εt
εt−1
...
εt−d+1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
1 0 · · · 0 0
0 · · · 0
0 1 · · · 0 0
0 · · · 0
... ... ... ...
...
... ... ...
0 0 · · · 1 0
0 · · · 0
0 0 · · · 0 φ1 φ2 · · · φd
0 0 · · · 0 1
0 · · · 0
...
... ... ...
...
... ... ...
0 0 · · · 0 0
0 · · · 0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
β0,t−1
β1,t−1
...
βp,t−1
εt−1
εt−2
...
εt−d
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
+
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
ζ0t
ζ1t
...
ζpt
νt
0
...
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
or βt = Fβt−1 + ζt and with observation equation
yt = [1, x1t, . . . , xpt, 1, 0, . . . , 0]βt = x⊤
t βt.

344
7
The State Space Model in Finance
The covariance matrix of ζt is given by
Zt =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
Z0t
0 · · ·
0
0 0 · · · 0
0 Z1t · · ·
0
0 0 · · · 0
...
...
...
...
...
... ... ...
0
0 · · · Zpt 0 0 · · · 0
0
0 · · ·
0
σ 2
ν 0 · · · 0
0
0 · · ·
0
0 0 · · · 0
...
...
...
...
...
... ... ...
0
0 · · ·
0
0 0 · · · 0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
We can see model (7.3) is a special case of the above model, if we set p = 1
and d = 1. If we set φ1 = φ2 = · · · = φd = 0, then εt = νt is an i.i.d. sequence,
and this reduces the model to a time-varying regression model with independent
errors, discussed in Sect. 4.1.5 above. If we set Z0t = Z1t = · · · = Zpt = 0, then
βit = βi,t−1, for all i, and the model is reduced to a static regression model with
autocorrelated errors. Some coefﬁcients βjt may be static (by setting Zjt = 0), but
other coefﬁcients βkt may be time-varying (by setting Zkt > 0), e.g. this may be the
case, if static covariates may be included.
Example 7.1 (IBM and Intel Share Prices)
In this example we consider historical
prices of IBM and Intel Corporation share prices (in US$). These shares trade at the
Dow Jones Industrial Index and are provided by http://ﬁnance.yahoo.com/.The data
are recorded in daily frequency (excluding weekends) from 18 June 2001 to 17 June
2003 and they are depicted in Fig. 7.1. We observe the two share prices are evolving,
following a similar pattern, but Intel prices appear to have larger variance throughout
time. This similar pattern is closely linked to cointegration, for a discussion of which
see Engle and Granger (1987).
It is believed that since both IBM and Intel operate in similar markets, their prices
will be related in some way. The ﬁrst model we consider is the static regression
model of Intel share price at time t (covariate x1t) on the IBM share price at t
(response yt), given by
yt = β0 + β1x1t + εt,
εt ∼N(0, 1).
This model assumes that {εt} is a white noise (independent errors). Using ordinary
linear regression, we obtain the estimates of β0 and β1 as ˆβ0 = 39.667 and ˆβ1 =
2.159. The validity of the independence assumption of {εt} can be measured by the
residuals, which, if the above mentioned assumption is valid and the model ﬁt is
good (see e.g. Bingham and Fry (2010)), should form an independent or at least
uncorrelated sequence as well.

7.2
Stationarity and Autoregressive Models
345
60
80
100
120
IBM
15
20
25
30
35
2002.0
2002.5
2003.0
2003.5
Intel
Year
Share prices of IBM and Intel Corp.
Fig. 7.1 IBM and Intel share prices
Motivated from this observation, we consider a static model with autocorrelated
errors, that is, model (7.1)–(7.2). For this model, we have used φ1 = 0.8 and
σ 2
ν = 10. For the initial state β1, we have used β1 ∼N(0, 0.001I). Figure 7.2 plots
the one-step forecasts using the above model with autocorrelated errors, together
with the one-step forecasts from the previous model with independent errors and
the actual prices of IBM. Clearly, the model with autocorrelated errors produces
forecasts much closer to the observed, while the other model fails to provide
reasonable forecasts after 2002.
7.2
Stationarity and Autoregressive Models
7.2.1
Stationarity and Causality
The notion of stationarity has been central to time series analysis and econometrics.
Stationarity is a characteristic of some stochastic processes, which studied how

346
7
The State Space Model in Finance
Forecasts with independent and with autocorrelated errors
Year
Share prices (in USD)
2002.0
2002.5
2003.0
2003.5
60
80
100
120
Data
Forecast with i.i.d. errors
Forecast with AR errors
Fig. 7.2 Forecasts using linear regression with independent (i.i.d.) errors and with autocorrelated
(AR) errors for the IBM–Intel data
stable is a stochastic process. In particular, a stochastic process {yt} is said to be
strictly stationary, if the joint distribution of (yt1, yt2, . . . , ytk)⊤is the same as the
joint distribution of (yt1+h, yt2+h, . . . , ytk+h)⊤, for any selection of points of time
t1, . . . , tk and some shift h. This suggests that the stochastic process is stable as
the distribution of the stochastic process over any subset of time is the same, i.e.
y1, y2 has the same distribution with y1001, y1002. An important implication of this
is that the mean E(yt), the variance Var(yt) and the covariance Cov(yt, yt+h) do
not depend on time t. As strict stationarity is very restrictive to be attained by real-
life processes, a weaker form of stationarity is often employed. According to this,
a process {yt} is said to be weakly stationary or second-order stationary if E(yt),
Var(yt) and Cov(yt, yt+h) do not depend on time t, see e.g. Brockwell and Davis
(2016, Chapter 2).

7.2
Stationarity and Autoregressive Models
347
Example 7.2 (AR(1) Model) We consider the autoregressive model of order one,
abbreviated as AR(1), deﬁned as
yt = φyt−1 + ϵt,
where {ϵt} is a white noise process (independently and identically distributed, with
zero mean and some variance σ 2). For |φ| < 1, this process can be written as
yt =
∞

j=0
φjϵt−j.
(7.5)
Using this form, it is easy to verify that the mean of yt is E(yt) = 0, the variance is
Var(yt) =
∞

j=0
φ2Var(ϵt−j) =
σ 2
1 −φ2
and the covariance is
Cov(yt, yt+h) = E(ytyt+h) = σ 2
∞

j=0
φjφj+h = σ 2φh
1 −φ2 ,
for h > 0. Hence, the process {yt} is weakly stationary for |φ| < 1. If |φ| > 1, the
representation (7.5) is not valid. In this case it is possible to express yt as a series
of ϵt+s, for s > 0 and to show that {yt} is still stationary (for a proof see Brockwell
and Davis (2016, Chapter 2)). If φ = ±1, then {yt} is non-stationary (note that for
φ = 1 the model is reduced to a random walk model). However, as it is not desirable
to express yt as a function of ϵt+s, for s > 0, we shall restrict our focus to |φ| < 1.
This guarantees stationarity, and it ensures that from (7.5) yt is written as a linear
combination of ϵt−s, for s ≥0.
As it is desirable that yt is expressed as a linear combination of present and past
elements of ϵt−s,
The above discussion of the AR(1) model motivates the notion of causality,
which is closely related to stationarity. Consider the general autoregressive model
of order p, abbreviated as AR(p), deﬁned as
yt = φ1yt−1 + · · · + φpyt−p + ϵt,
(7.6)

348
7
The State Space Model in Finance
where φi are p AR coefﬁcients and {ϵt} is a white noise sequence with variance σ 2.
If there is an inﬁnite linear representation of yt in terms of ϵt−s, for s ≥0 as such
yt =
∞

j=0
ψjϵt−j,
for some known coefﬁcients ψj, then it is said that {yt} is causal. In other words,
this means that yt can be determined by past and present values of ϵt. Hence for
the AR(1) model discussed above, if |φ| < 1, the model is causal and stationary. A
central question in time series analysis is to give conditions on the space of the AR
parameters to ensure stationarity and causality of model (7.6). The answer to this
question is provided by the zeroes of the so-called characteristic polynomial
φ(z) = 1 −φ1z −φ2z2 −· · · −φpzp,
(7.7)
where z is a complex-valued argument.
Indeed, model (7.6) is stationary if the roots ρj of φ(z) satisfy ρj ̸= ±1, and
it is causal if |ρj| > 1, for any j = 1, . . ., p (perhaps including multiple roots).
For a proof of this fundamental result, the reader is referred to Brockwell and Davis
(1991), Brockwell and Davis (2016, Chapter 3). It follows that the condition |ρj| >
1 ensures that model (7.6) is causal and stationary. For example (7.2), φ(z) = 1−φz
and the single root is ρ = 1/φ. Hence the condition |ρ| > 1 of causality coincides
with the condition |φ| < 1, which was established in Eq. (7.5). From the above
discussion, it is clear that in order to establish causality and stationarity of the AR(p)
model, the roots of the polynomial (7.7) need to be computed for speciﬁc values of
φ1, . . . , φp.
There has been a signiﬁcant amount of literature dealing with the problem of
deriving causality conditions for model (7.6) or conditions to establish that the roots
of φ(z) lie outside the unit circle in the complex plain. According to Chipman
(1950, pp. 370–371), who provides a historical account of this topic, Schur and
Cohn have developed a set of conditions for all roots of φ(z) to lie outside the
unit circle in the complex plain. The algorithm, which is known as the Schur–Cohn
algorithm, avoids the direct calculation of the roots of φ(z), which for large p
may not be possible. Instead, it proposes a number of inequalities based on the
calculation of determinants of matrices with dimensions which increase at each
step. Samuelson (1941) and Wise (1956) have independently developed effectively
identical conditions for causality and stationarity of model (7.6), which avoid the
computation proposed by Schur and Cohn. Their conditions consist of a number of
iterative inequalities involving the coefﬁcients φ1, . . . , φp. However, the iterative
nature of these inequalities is criticised by Barndorff-Nielsen and Schou (1973).
For cases of AR(2) and AR(3), it is possible to derive simple conditions to ensure
the roots of φ(z) lie outside the unit circle. Other than for education purposes,
the advantage of these conditions is that they give us a vision of the causality and

7.2
Stationarity and Autoregressive Models
349
stationarity region for these popular models. In the next sections we discuss these
conditions and provide in detail their derivations.
7.2.2
Stationarity Conditions for AR(2)
Consider the autoregressive model of order two (AR(2)), given by (7.6). Causality
and stationarity are implied for this model, if the roots of the characteristic
polynomial
φ(x) = 1 −φ1x −φ2x2
(7.8)
lie outside the unit circle. For any pair of φ1 and φ2, one can ﬁnd the roots of φ(x)
and see whether they lie outside the unit circle in the complex plane. However,
a more elaborate way is to ﬁnd a causality and stationarity region implied from
|x| > 1 and involving only φ1 and φ2 so that there will be no need to compute
the two roots of φ(x) each time. We shall prove that the necessary and sufﬁcient
conditions for the causality and stationarity of AR(2) are
φ1 + φ2 < 1
(7.9)
−φ1 + φ2 < 1
(7.10)
|φ2| < 1.
(7.11)
These conditions are proven in Priestley (1981), Box et al. (2008) and Shumway and
Stoffer (2017, pp. 89–90), and we shall follow a similar but slightly more detailed
proof here.
Necessity First we shall show that if the model is causal and stationary (or that the
roots of (7.8) lie outside the unit circle), then conditions (7.9)–(7.11) are satisﬁed.
Set z = 1/x so that (7.8) becomes φ(z)∗= z2 −φ1z −φ2, and from the causality
assumption we have |ρ1,2| < 1, where ρi are the two roots of φ(z)∗. From the
binomial, the two roots are ρ1,2 = (φ1 ±
'
φ2 + 4φ2)/2 and so we have ρ1ρ2 =
−φ2. Hence, |φ2| = |ρ1||ρ2| < 1, and hence (7.11) is satisﬁed. Also,
φ1 + φ2 = ρ1 + ρ2 −ρ1ρ2 = ρ1(1 −ρ2) + ρ2 < 1,
as ρ1 < 1 and 1 −ρ2 > 0. Hence, (7.9) is satisﬁed. Likewise,
−φ1 + φ2 = −ρ1 −ρ2 −ρ1ρ2 = −ρ1(1 + ρ2) −ρ2 < 1,
as −ρ1 < 1 and 1 + ρ2 > 0. Hence, (7.10) is satisﬁed too.

350
7
The State Space Model in Finance
Sufﬁciency Now we shall show that conditions (7.9)–(7.11) are sufﬁcient for the
stationarity and causality of AR(2) or that if they are satisﬁed, the roots of (7.8) lie
outside the unit circle.
First assume that φ2
1 + 4φ2 ≥0 (so that the roots ρ1 and ρ2 are real). We shall
show |ρi| < 1, for i = 1, 2. If φ1 ≥−
1
φ2
1 + 4φ2, then |ρ1| = (φ1+
1
φ2
1 + 4φ2)/2.
The proof is by contradiction. Suppose that |ρ1| ≥1, then φ1 +
1
φ2
1 + 4φ2 ≥2
or φ2
1 + 4φ2 ≥(2 −φ1)2, which implies φ1 + φ2 ≥1. This contradicts condition
(7.9), hence ρ1| < 1. If φ1 < −
1
φ2
1 + 4φ2, then |ρ1| = −(φ1 +
1
φ2
1 + 4φ2)/2,
and assuming as before |ρ1| ≥1, we obtain
1
φ2
1 + 4φ2 ≤−φ1 −2 ≤0, which
is again a contradiction, as φ1 > −2. Hence, in any case, |ρ1| < 1. The proof of
|ρ2| < 1 is similar and is left to the reader as an exercise.
Suppose now that φ2
1 +4φ2 < 0 (the roots ρ1 and ρ2 are complex and conjugate).
Since ρ1 and ρ2 are conjugate, they have the same modulus and so it sufﬁces to show
|ρ1| < 1 only. We notice that ρ1 = φ1/2 + i
1
−φ2
1 −4φ2/2. Then |ρ1| = √−φ2,
with φ2 < 0. Thus, |ρ1|2 = −φ2 = |φ2| < 1, from condition (7.11). This completes
the proof. Figure 7.3 shows the stationarity region of the AR(2) model.
7.2.3
Stationarity Conditions for AR(3)
Consider the autoregressive model of order two (AR(3)), given by (7.6). Causality
and stationarity are implied for this model, if the roots of the characteristic
polynomial
φ1 + φ2 + φ3 < 1,
(7.12)
−φ1 + φ2 −φ3 < 1,
(7.13)
φ3(φ3 −φ1) −φ2 < 1,
(7.14)
|φ3| < 1.
(7.15)
These conditions are stated without proof in Barndorff-Nielsen and Schou (1973, p.
409). A proof of this result may be derived directly from the Schur–Cohn criterion or
by using the Samuelson conditions (Samuelson, 1941) and is provided in Okuguchi
and Irie (1990). Below we provide an alternative proof, which is motivated by the
proof for the AR(2) model in Sect. 7.2.2.
We show that conditions (7.12)–(7.15) are necessary and sufﬁcient for the
stationarity of {yt} generated by an AR(3) model. We ﬁrst give some preliminary
material used in the proof.

7.2
Stationarity and Autoregressive Models
351
-2
-1
0
1
2
-1.0
-0.5
0.0
0.5
1.0
Stationarity region of AR(2)
2
1
Fig. 7.3 Stationarity region of the AR(2) model
Let φ(x) = 1 −φ1x −φ2x2 −φ3x3 be the characteristic polynomial (in the
complex-valued x). The time series {yt} is stationary if and only if the roots of φ(x)
lie outside the unit circle or equivalently if the roots of
z3 −φ1z2 −φ2z −φ3 = 0
(7.16)
are within the unit circle, where z = x−1.
We give the correspondence of the roots ρ1, ρ2 and ρ3 of (7.16) and the
coefﬁcients φ1, φ2 and φ3. We write (7.16) as
(z −ρ1)(z −ρ2)(z −ρ3) = 0
and expand it to get
z2 −(ρ1 + ρ2 + ρ3)z2 + (ρ1ρ2 + ρ1ρ3 + ρ2ρ3)z −ρ1ρ2ρ3 = 0.
(7.17)

352
7
The State Space Model in Finance
If we compare Eqs. (7.16) and (7.17), we obtain
φ1 = ρ1 + ρ2 + ρ3,
(7.18)
φ2 = −ρ1ρ2 −ρ1ρ3 −ρ2ρ3,
(7.19)
φ3 = ρ1ρ2ρ3.
(7.20)
Necessity We show that if {yt} is stationary, then (7.12)–(7.15) are satisﬁed. Under
the assumption of stationarity, we have |ρi| < 1 for all i = 1, 2, 3, which from
(7.20) immediately implies condition (7.15).
Since p = 3, either ρ1, ρ2 and ρ3 are all real, or one of them is real and the other
two are conjugate complex roots. First consider ρ1, ρ2 and ρ3 are real.
φ1 + φ2 + φ3 = ρ1 + ρ2 + ρ3 −ρ1ρ2 −ρ1ρ3 + ρ1ρ2ρ3
= ρ1(1 −ρ2) + ρ3(1 −ρ2) −ρ1ρ3(1 −ρ2) + ρ2
= (1 −ρ2)(ρ1 + ρ3 −ρ1ρ3) + ρ2
(7.21)
< 1 −ρ2 + ρ2 = 1,
since |ρ2| < 1 and
ρ1 + ρ3 −ρ1ρ3 = ρ1(1 −ρ3) + ρ3 < 1,
as
|ρ1| < 1.
Similarly for (7.13), we have
−φ1 + φ2 −φ3 = −ρ1 −ρ2 −ρ3 −ρ1ρ2 −ρ2ρ3 −ρ1ρ3 −ρ1ρ2ρ3
= −ρ1(1 + ρ2) −ρ3(1 + ρ2) −ρ1ρ3(1 + ρ2) −ρ2
= (1 + ρ2)(−ρ1 −ρ3 −ρ1ρ3) −ρ2
(7.22)
< 1 + ρ2 −ρ2 = 1,
since |ρ2| < 1 and
−ρ1 −ρ3 −ρ1ρ3 = −ρ1(1 + ρ3) −ρ3 < 1,
as
|ρ1| < 1.
Finally, for (7.13), we have
φ3(φ3 −φ1) −φ2 = ρ1ρ2ρ3(ρ1ρ2ρ3 −ρ1 −ρ2 −ρ3) + ρ1ρ2 + ρ1ρ3 + ρ2ρ3
= (1 −ρ1ρ3)(ρ1ρ2 −ρ1ρ2
2ρ3 + rho2ρ3) + ρ1ρ3
= (1 −ρ1ρ3)[ρ1ρ2(1 −ρ2ρ3) + ρ2ρ3] + ρ1ρ3
(7.23)
< 1 −ρ1ρ3 + ρ1ρ3 = 1,

7.2
Stationarity and Autoregressive Models
353
since |ρ1ρ3| < 1 and
ρ1ρ2(1 −ρ2ρ3) + ρ2ρ3 < 1,
as
|ρ1ρ2| < 1.
Now suppose that there are two conjugate complex roots and one real root.
Without loss of generality, suppose that ρ2 is real and ρ1 and ρ3 are the two
complex roots. Write ρ1 = a + bi and ρ3 = a −bi, for some real a.b, where i
denotes the imaginary unit. We have ρ1 + ρ3 −ρ1ρ3 = 2a −a2 −b2 < 1, since
|ρ1| =
√
a2 + b2 < 1; hence, from (7.21), we have φ1 + φ2 + φ3 < 1. Similarly,
from −ρ1−ρ3−ρ1ρ3 = −2a−a2−b2 < 1 and (7.22), we obtain −φ1+φ2−φ3 < 1.
Also,
ρ1ρ2(1 −ρ2ρ3) + ρ2ρ3 = ρ2(a + bi)[(1 −ρ2(a −bi)] + ρ2(a −bi)
= 2ρ2a −(ρ2a)2 −(ρ2b)2 < 1,
since ρ2 is real and (ρ2a)2+(ρ2b)2 < 1. Thus from (7.23), it is φ3(φ3−φ1)−φ2 < 1.
This proves (7.12)–(7.15) for complex roots.
Sufﬁciency Now we prove that if conditions (7.12)–(7.15) are satisﬁed, then {yt}
is stationary. From condition (7.15) and Eq. (7.20), at least one of |ρ1|, |ρ2| and |ρ3|
must be strictly less than one. Without loss of generality, suppose |ρ2| < 1.
Consider ﬁrst the case of real roots ρ1, ρ2 and ρ3. Assume that {yt} were not
stationary, that is, |ρ1| ≥1 or |ρ3| ≥1. If ρ3 > 1, then ρ1 + ρ3(1 −ρ1) ≥
ρ1+1−ρ1 = 1, and hence from (7.21), we have φ1+φ2+φ3 ≥1, which contradicts
condition (7.12). If ρ3 < −1, then −ρ1 −ρ3(1 + ρ1) ≥−ρ1 + 1 + ρ1 = 1, and
hence from (7.22), we have −φ1 +φ2 −φ3 ≥1, which contradicts condition (7.13).
By interchanging the roles of ρ1 and ρ3, we obtain that |ρ1| ≥1 contracts either
(7.12) or (7.13). Hence, it is necessarily |ρ1| < 1, |ρ2| < 1 and |ρ3| < 1, i.e. {yt} is
stationary.
Consider now the case of two conjugate complex roots. As before and without
loss of generality, we assume that ρ1 and ρ3 are complex, while ρ2 is real. Write
as before ρ1 = a + bi and ρ3 = a −bi. As before, from condition (7.15) and
|φ3| = |ρ1||ρ2||ρ3| < 1, we have that at least one of ρ1, ρ2 and ρ3 has modulus
less than one; without loss of generality assume |ρ2| < 1. Suppose that it was
|ρ1| = |ρ3| =
√
a2 + b2 ≥1. From (7.23), we have
φ3(φ3 −φ1) −φ2 = (1 −a2 −b2)[2ρ2a −(ρ2a)2 −(ρ2b)2] + a2 + b2.
(7.24)
Put u = a2 + b2, A = 2ρ2a −(ρ2a)2 −(ρ2b)2 and B = (1 −u)A + u. Since
u ≥1, if A ≤1, we have B ≥1. We note that for A ≤0, (1 −u)A ≥0 and so
B = (1 −u)A + u ≥1, since u ≥1. If 0 < A ≤1, then (1 −A)u ≤1 −A or
B = (1 −u)A + u ≥1. We can see that A > 1 is not possible. Indeed with the
deﬁnition of A as above, we have
(ρ2a −1)2 = 1 + ρ2
2a2 −2ρ2a ≥−ρ2
2b2
or
A = 2ρ2a −ρ2
2a2 −ρ2
2b2 ≤1.

354
7
The State Space Model in Finance
Thus, from (7.24), we have φ3(φ3 −φ1) −φ2 ≥1, which contradicts (7.14). Hence
|ρ1| < 1, |ρ2| < 1 and |ρ3| < 1, i.e. {yt} is stationary.
7.3
Univariate Stochastic Volatility Models
7.3.1
Returns and Volatility
In ﬁnance interest frequently lies on the valuation and price of ﬁnancial assets. An
asset can be a share or stock trading in the stock market, or a commodity, or some
other ﬁnancial instrument. An investor might be interested in a particular asset or
a number of assets and wishing to hold a portfolio of the most proﬁtable assets.
Focusing on a single asset, it is long claimed that the prices of assets follow a
random walk process, with variance which is erratically increasing; this is the so-
called random walk hypothesis, see e.g. Cootner (1964) and Fama (1965). The large
variance of the random walk over time has the implication that the forecast variance
of a future price of the asset is very high and so forecasts are totally unreliable; see
e.g. Example 3.3 and Exercise 6. Instead it is much more common to work on the
return of an asset. Let pt denote the price of an asset at time t, and let us assume
we sample pt at equally spaced intervals (usually at daily frequency). The simple
return of the asset is
y(s)
t
= pt −pt−1,
suggesting that yt is the shock needed to be added to pt−1 to give pt. An alternative
to the simple returns is the so-called geometric returns deﬁned as
y(g)
t
= pt −pt−1
pt−1
.
Finally, widely used are the logarithmic returns (or log-returns) deﬁned as
y(l)
t
= log pt −log pt−1.
Using the well known identity, log(x + 1) ≈x, for small x. If pt/pt−1 −1 is small,
then y(l)
t
≈y(g)
t
. Hence statistical analysis using log-returns will provide similar
results to analysis using geometric returns. The above deﬁnition of the log-returns
suggests the model pt = pt−1 exp[y(l)
t ], while that of the geometric returns suggests
the model pt = (yt + 1)pt−1.
The returns using any of the deﬁnitions above are expected to have mean close to
zero, as it is expected that historically pt is close to pt−1; this is more pronounced
when we sample the returns at daily frequency. The variance of the returns, which
is known as volatility, plays an important role in ﬁnancial decisions and has been on

7.3
Univariate Stochastic Volatility Models
355
the centre of ﬁnancial econometrics over the past 50 years. For the purposes of this
chapter, we shall deﬁne the volatility at time t, as the conditional variance of yt, i.e.
σ 2
t = Var(yt | σ 2
t ),
where yt denotes the return at time t. Properties of returns and volatility are the
subject of many studies, sometimes referred to as stylised facts of the returns and
volatility. The following is a short summary, and for more information the reader is
referred to Tsay (2002, Chapter 1).
1. the historical mean of the returns is very close to zero;
2. the returns have heavy tails, typically heaver than the Gaussian and Student t
distributions;
3. the distribution of the returns is asymmetric, typically following a left skew
distribution;
4. the volatility is time-varying;
5. the volatility is observed in clusters, i.e. there are periods of time with a certain
level of volatility.
Skewness in the returns suggests that positive and negative returns are not equally
likely. In periods of market decline (as for example in the credit crunch of 2008),
investors lose conﬁdence and negative returns exhibit low frequency; instead, in
periods of growth, investments increase and the positive returns are more likely.
The characteristics of skewness are studied by many econometricians, see e.g.
Bakshi et al. (2003) and the references therein. The tails of the returns are heavier
than the Gaussian and the Student t distributions. Hence there is signiﬁcant mass
under negative and positive returns of considerable magnitude, in either side. This
is demonstrated empirically in many studies and theoretically in others, see e.g.
Bingham and Kiesel (2002). For a detailed discussion of the characteristics of
returns and their distribution the reader is referred to Tsay (2002, Chapter 1).
7.3.2
Stochastic Volatility Model
Engle (1982) and Bollerslev (1986) introduced the generalised autoregressive
conditional heteroskedastic (GARCH) models to estimate the volatility σ 2
t . GARCH
and their numerous generalisations assume that the volatility is a function of the
lagged squared returns. Let yt denote the log-returns and σ 2
t the volatility at time
t, and let {ϵt} be a sequence of independent innovations. The GARCH speciﬁcation
sets
yt = σtϵt,
ϵt ∼N(0, 1)

356
7
The State Space Model in Finance
and
σ 2
t = α0 + α1y2
t−1 + · · · + αpy2
t−p + β1σ 2
t−1 + · · · + βqσ 2
t−q,
(7.25)
for some positive integers p and q and some parameters αi and βj with α0 > 0 and
p
i=1 αi + q
j=1 βj < 1. Given a set of observed returns y1, . . . , yn, estimates of
αi and βj may be obtained by maximising the log-likelihood function
log p(y1, . . . , yn | αi, βj) = −n
2 log(2π) −1
2
n

t=1
log σ 2
t −1
2
n

t=1
y2
t
σ 2
t
,
where σ 2
t is given in (7.25). Since σ 2
t is a deterministic function of αi and βj, we
can readily obtain the maximum likelihood estimate of σ 2
t by plugging in (7.25) the
maximum likelihood estimates of αi and βj. In this speciﬁcation the values of p, q
are assumed known, but it may be possible to be estimated from the data. Other
speciﬁcations of the GARCH model involve a number of improvements including
replacing the Gaussian distribution of the innovations ϵt by a Student t distribution.
For a good review of GARCH-type volatility models, the reader is referred to Tsay
(2002).
As pointed out in Harvey et al. (1994), the GARCH family of volatility models
suffers from three drawbacks: (1) the volatility is given as a deterministic function
of past squared returns, (2) it is not parsimonious as it includes many parameters and
the likelihood maximisation might suffer from local maxima and (3) it does not offer
good generalisations to multivariate models, without the compromise of the curse
of dimensionality (too many parameters). As a result in the 90s efforts were devoted
to developing alternative models, which would overcome the above drawbacks. The
idea of treating the volatility σ 2
t as a stochastic process was advocated by a number
of authors, see e.g. Harvey et al. (1994) and Jacquier et al. (1994). Both of these
studies adopt the stochastic volatility model described in Sects. 1.3.3 and 6.3, but
they develop different inference. In the sequel we shall discuss the basic model
adopted by many authors, see e.g. Jacquier et al. (1994) and Kim et al. (1998).
Consider that log-returns {yt} are generated from the model
yt = exp(ht/2)ϵt,
ϵt ∼N(0, 1),
(7.26a)
ht −μ = φ(ht−1 −μ) + ωt.
ωt ∼N(0, σ 2
ω),
(7.26b)
where {ϵt} is an independent sequence of innovations, {ωt} is an independent
sequence of innovations and ϵt is independent of ωs, for any t, s. The model can
be cast in state space form as in Sect. 1.3.3. From the observation model (7.26a), the
returns are distributed as
yt | ht ∼N

0, exp(ht)

;

7.3
Univariate Stochastic Volatility Models
357
hence, ht is the logarithm of the volatility at time t. From the evolution (7.26b), the
log-volatility ht follows an autoregressive model of order one, for a discussion of
which see Example 7.2. Following the discussion of this example, the unconditional
distribution of this model is
ht | μ, φ, σω ∼N

μ,
σ 2
ω
1 −φ2

,
for −1 < φ < 1. The hyperparameters of this model are μ (the mean of ht), φ (the
autoregressive coefﬁcient) and σ 2
ω (the variance of the innovations ωt). The model
is completed by setting a prior distribution for h0, i.e. h0 ∼N(m, C), for some
parameters m and C, which may depend on the hyperparameters.
By taking logarithms in the square returns y2
t , Eq. (7.26a) can be written as
log y2
t = ht + log ϵ2
t ,
ϵ2
t ∼χ2
1.
(7.27)
This process linearises the non-Gaussian state space model (7.26a)–(7.26b). The
squared innovations ϵ2
t follow a chi square distribution with one degree of freedom.
As it is pointed out in Harvey et al. (1994, page 250), the mean and variance of the
random variable log ϵ2
t are approximately equal to -1.27 and π2/2, respectively.
The derivation of these moments makes use of approximations of the digamma
and trigamma functions, see Exercise 3. Hence, Harvey et al. (1994) propose the
following state space model
log y2
t = −1.27 + ht + ξt,
ht = μ(1 −φ) + φht−1 + ωt,
ωt ∼N(0, σ 2
ω),
where ξt follows a shifted log-gamma distribution, with zero mean and variance
π2/2. Assuming that μ, φ and σ 2
ω are known, the extended Kalman ﬁlter may
be applied and is used to calculate the likelihood function conditional on these
hyperparameters; for a detailed discussion of the extended Kalman ﬁlter see
Sect. 6.6. The hyperparameters μ, φ and σ 2
ω are estimated by quasi-maximum
likelihood estimation. One of the most attractive properties of this model is that
it can be easily generalised to the multivariate case when yt forms a vector of
log-returns of several assets; for more details, the reader is referred to Harvey
et al. (1994). In the next section we discuss Markov chain Monte Carlo estimation
(MCMC) inference essentially proposed in Jacquier et al. (1994).
7.3.3
MCMC Inference of Stochastic Volatility Models
Consider that log-returns are generated from model (7.26a)–(7.26b), and let θ =
[μ, φ, σ 2
ω]⊤be the vector of hyperparameters. Given a set of observed returns

358
7
The State Space Model in Finance
y1, . . . , yn, we want to estimate the log-volatility process {ht} and the hyperpa-
rameters μ, φ and σ 2
ω.
Write y = [y1, . . . , yn]⊤the vector of all observations (returns) and h =
[h1, . . . , hn]⊤the vector of all log-volatilities. Following a Gibbs sampling scheme,
we wish to sample from the conditional distributions
1. h, conditionally on y and μ, φ and σ 2
ω;
2. μ, φ, conditionally on y, h and σ 2
ω, and σ 2
ω, conditionally on y, h, μ and φ.
Step (2) is simpler and we start with that. First observe that from Eq. (7.26b),
conditionally on h and y and μ, φ and σ 2
ω are independent; hence, we drop y from
step (2). Conditionally on h, (7.26b) can be seen as a linear model, with observation
ht, intercept μ(1 −φ), slope φ and innovation variance σ 2
ω. This model can be
written compactly as h = Xβ + ω, where β = [μ(1 −φ), φ]⊤and
X =
⎡
⎢⎢⎢⎣
1
h0
1
h1
...
...
1 hn−1
⎤
⎥⎥⎥⎦,
ω =
⎡
⎢⎢⎢⎣
ω1
ω2
...
ωn
⎤
⎥⎥⎥⎦
so that ω ∼N(0, σ 2
ωI). Conditionally on σ 2
ω, the posterior distribution of β is β |
h, σ 2
ω ∼N( ˆβ, P), where ˆβ and P are provided by Eq. (2.22).
For the estimation of σ 2
ω, we consider an inverse gamma prior, i.e.
σ 2
ω ∼IG
ν
2, S
2
	
,
for some known ν and S. Then the posterior distribution of 1/σ 2
ω is
p
 1
σ 2ω
| h, μ, φ
	
∝p(h | μ, φ, σ 2
ω)p
 1
σ 2ω
	
∝
 1
σ 2ω
	(ν+1)/2
exp
(
−1
2
%
(h −Xβ)⊤(h −Xβ) + S
&)
so that
σ 2
ω | h, μ, φ ∼IG
ν∗
2 , S∗
2
	
,
(7.28)
with
ν∗= ν + 1
and
S∗= S + (h −Xβ)⊤(h −Xβ).

7.3
Univariate Stochastic Volatility Models
359
Step (2) suggests that conditionally on a sample of h and σ 2
ω, we can sample μ and
φ using the bivariate Gaussian distribution above, and then conditionally on h, μ
and φ, we can sample σ 2
ω using the inverse gamma distribution (7.28).
Moving on to step (1), we need to provide the conditional distribution of the
log-volatilities h, given y and μ, φ and σ 2
ω. This is more involved, because this
conditional distribution is not easy to sample from. In this step we need to resort to
a Metropolis move. We start by looking at the above conditional distribution.
For any 1 ≤t ≤n −1, we have
p(ht | ht−1, ht+1, yt, θ) ∝p(yt | ht)p(ht | ht−1, θ)p(ht+1 | ht, θ)
=
1
'
2π exp(ht)
exp

−
y2
t
2 exp(ht)

1
√
2πσω
× exp
(
−1
2σ 2ω
%
(ht −μ(1 −φ) −φht−1)2
+(ht+1 −μ(1 −φ) −φht)2&4
(7.29)
∝exp

−1
2

ht +
y2
t
exp(ht)
	
−(1 + φ2)
2σ 2ω
(ht −λt)2

,
(7.30)
where we have completed the square in (7.29), resulting in
λt = μ(1 −φ)2 + (1 −φ)(ht+1 + ht−1)
1 + (1 −φ)2
.
For t = n, we have
p(hn | hn−1, yn, θ) ∝p(yn | hn)p(hn | hn−1, θ)
∝exp
(
−1
2

hn +
y2
n
exp(hn)
+(hn −μ(1 −φ) −φhn−1)2&4
.
(7.31)
It is not easy to sample from distributions (7.30) and (7.31) because of the
denominator of the fractions y2
t / exp(ht) and y2
n/ exp(hn). Hence, in order to sample
from these distributions, we need to resort to a Metropolis step. The general
Metropolis–Hastings algorithm is described in Sect. 6.8.1 and is discussed in
Gamerman and Lopes (2006, Section 4.6). In order to apply the Metropolis step
here, we need to choose a proposal kernel, from which we can sample a draw h(j)
t
,
for each time t. There are two ways this can be achieved: (a) we can simulate h(j)
t
from the prior distribution ht | ht−1, | μ, φ, σ 2
ω and deploy rejection sampling to

360
7
The State Space Model in Finance
select h(j)
t
or to keep h(j−1)
t
and (b) we can use a random walk chain h(j)
t
=
h(j−1)
t
+ wj to sample h(j)
t
and then adopt an accept/reject step as in Sect. 6.8.1
(for a deﬁnition of wj see p. 318). In scheme (a), we create an independent chain,
and the Markov property is guaranteed by the simple accept/reject step; general
discussion on independent chains in Metropolis is given in Gamerman and Lopes
(2006, Section 6.3.3) and discussion in the context of stochastic volatility is given
in Jacquier et al. (1994).
The proposed scheme (with (a) or (b)) proposes a hybrid MCMC algorithm,
which cycles through between the Gibbs step (1) and the Metropolis step (2), and is
outlined below.
MCMC Algorithm for the Stochastic Volatility Model
In the stochastic volatility model (7.26a)–(7.26b), with the priors on μ, φ and
σ 2
ω as above, the following apply:
1. Set initial values of μ(0), φ(0) and σ 2(0)
ω
.
Set initial values of log-volatilities h(0)
0 , h(0)
1 , . . . , h(0)
n . For each time
t = 1, 2, . . . , n and for i, j = 1, 2, . . ., N:
a. Generate h∗from the proposal N(h(j−1)
t
, V ), for some variance V .
b. Calculate
the
acceptance
probability
α(h(j−1)
t
, h∗)
=
min(1, p(h∗)/p(h(j−1)
t
), where p(h(j−1)
t
) is calculated using (7.30)
and (7.31), conditionally on μ = μ(i−1), φ = φ(i−1) and σ 2(i−1)
ω
. Draw
a single u from a uniform distribution U(0, 1). If u < α(h(j−1)
t
, h∗),
the proposal h∗is accepted and we set h(j)
t
= h∗, otherwise the move
is rejected and we set h(j)
t
= h(j−1)
t
.
2. Conditionally
on
σ 2(i−1)
ω
,
draw
β(i)
=
[μ(i), φ(i)]⊤
from
N( ˆβ(i−1), P(i−1)), where ˆβ(i−1) and P(i−1) are provided by (2.22) if
we set h = h(i−1) using the linear model of p. 358.
3. Conditionally on μ(i) and φ(i), draw σ 2(i)
ω
from the inverted gamma
distribution (7.28).
Some comments are in order. Step 1 above (the Metropolis step) is indicated
by (a) and (b) in the above algorithm and generate the log-volatilities for given
hyperparameters μ, φ and σ 2
ω. Step 2 (Gibbs sampling) is indicated by (1)–(3) in
the algorithm above. Hence, this is a hybrid MCMC algorithm, for a discussion of
which the reader is referred to Gamerman and Lopes (2006).

7.3
Univariate Stochastic Volatility Models
361
7.3.4
Particle Filter Inference of Stochastic Volatility Models
In this section we shall present two stochastic volatility models and we shall discuss
sequential Monte Carlo inference for both of them.
Consider model (7.26a)–(7.26b), and let θ = [μ, φ, σ 2
ω]⊤be the vector of
hyperparameters as before. The prior of ht, given ht−1 and θ, follows from (7.26b)
as
ht | ht−1, θ ∼N[μ(1 −φ) + φht−1, σ 2
ω].
(7.32)
Assume initial value for the log-volatilities h(i)
0
(these may be set initially or
simulated from a Gaussian distribution with zero mean and some variance). Given
θ, we can simulate h(i)
t
from prior (7.32) (Bootstrap ﬁlter) and yt | h(i)
t , θ ∼
N[0, exp(ht)]. We can then apply the Bootstrap ﬁlter (see Sect. 6.7.4).
However, in practice θ will not be known and subject to estimation. Two possible
approaches are the approaches of Storvik (2002) and Liu and West (2001). The
resulting Storvik ﬁlter is similar to step (2) of the MCMC stochastic volatility
algorithm described in the previous section and is brieﬂy described in Sect. 6.7.8.
The Liu and West ﬁlter is described in detail in Sect. 6.7.8.2. The Liu and West ﬁlter
(Particle Filter Algorithm II) is summaried on p. 311.
For the application of the Liu and West ﬁlter, we have chosen the following
priors:
h0 ∼N(0, 10),
μ ∼N(0, 10),
φ ∼U(−1, 1)
and
σ 2
ω ∼G(2, 2).
Some comments on these priors are in order. The prior of the log-volatility h0 at
t = 0 is set to be Gaussian with zero mean and variance 10. The zero mean reﬂects
weak belief on whether the log-volatility is positive or negative and the variance of
10 reﬂects moderate uncertainty around this. Similar comments apply to the choice
of the prior distribution of μ, the mean of h0. From the condition of stationarity
−1 < φ < 1 of the AR coefﬁcient φ, a uniform distribution U(−1, 1) is chosen.
This simple consideration is a non-informative prior speciﬁcation for φ. Finally, the
gamma prior distribution of σ 2
ω is chosen so that the prior mean of σ 2
ω is equal to
one (which seems a moderate/small value) with associated variance 1/2.
In the application of the Liu and West ﬁlter, we consider Gaussian mixtures for
the estimation of μ, φ and σ 2
ω. Since the support of σ 2
ω is [0, ∞) and the support of
φ is (−1, 1), in the mixtures, we use log σ 2
ω and log[(1 −φ)/(1 + φ)], which both
are R.
We ﬁt the above model to the log-returns of the IBM closing of Sect. 1.3.3.
The data, plotted in Fig. 1.7, consist of 1776 log-return observations sampled at
daily frequency (trading days). The Liu and West ﬁlter is ﬁtted using the above
priors and 1000 particles at each point of time. Following some experimentation,
we use δ = 0.995 the value of the discount factor (used to compute the smoothing
factor α = (3δ −1)/(2δ) of mean of each mixture, see p. 311). This corresponds

362
7
The State Space Model in Finance
Time
Volatility
0
500
1000
1500
0
50
150
250
Time
Mean
0
500
1000
1500
0
1
2
3
4
Time
Variance
0
500
1000
1500
0.3
0.5
0.7
0.9
Time
AR coefficient
0
500
1000
1500
0.0
0.2
0.4
0.6
0.8
Fig. 7.4 Posterior mode of volatilities exp(ht) and hyperparameters μ (mean), σ 2
ω (variance) and
φ (AR coefﬁcient)
to a value of the smoothing parameter α = 0.997. Figure 7.4 shows the modes
of the posterior samples of the log-volatilities ht (top left panel), the mean μ (top
right panel), the variance σ 2
ω (bottom left panel) and the AR coefﬁcient φ (bottom
right). The posterior modes of μ, σ 2
ω and φ converge to stable values; the average
of μ is 4.016, of σ 2
ω is 0.331 and of φ is 0.8 (rounded to 3 decimal points). These
stable values validate the choice we have made of these hyperparameters to be time-
invariant. The value of φ conﬁrms that the process {ht} is stationary, but with quite
high autocorrelation structure. At each point of time, we can calculate histograms
or empirical distributions of the posterior sample of ht, μ, σ 2
ω and φ and so we
can compute posterior credible intervals from these samples. Figure 7.5 shows the
histograms of h1776, μ, σ 2
ω and φ at time t = 1776. Hence we can use Fig. 7.6 to
zoom out and see the big picture (estimation over time) and Fig. 7.5 to zoom in and
study the posterior distribution of the parameters at a particular point of time.

7.3
Univariate Stochastic Volatility Models
363
Volatility
Frequency
0
100
200
300
400
500
0
100
300
500
Mean
Frequency
4.055
4.065
4.075
4.085
0
20
60
100
140
Variance
Frequency
0.304
0.308
0.312
0
50
100
150
AR coefficient
Frequency
0.842
0.846
0.850
0.854
0
50
100
150
200
Fig. 7.5 Histograms at t = 1776 of volatilitiy exp(h1776) and hyperparameters μ (mean), σ 2
ω
(variance) and φ (AR coefﬁcient)
7.3.5
Particle Filter Inference of Stochastic Volatility Models
with Asymmetric Returns
One disadvantage of the models discussed above is the Gaussian distribution
assumed for the log-returns in (7.26a). As is discussed in Sect. 7.3.1, ﬁnancial
returns have heavy tails (typically heavier than the normal distribution) and are
skewed and not symmetric. The asymmetry of the returns reﬂects upon the fact that
negative returns have different probability mass than positive returns. Hence, the
normal or Gaussian distribution assumed for the returns is not appropriate. The need
for considering asymmetric and heavy tailed distribution for returns is discussed in
the ﬁnance literature, see e.g. Bingham and Kiesel (2002), Bingham and Kiesel
(2004) and Ass and Haff (2006) among others.
A suitable asymmetric distribution is the skew Student t distribution of Fernan-
dez and Steel (1998); this distribution is suitable for modelling ﬁnancial returns,
because it incorporates fat tails and asymmetry. In the sequel we shall brieﬂy
describe it. Suppose that a random variable ϵ following a symmetric distribution,

364
7
The State Space Model in Finance
-40
-20
0
20
40
0.00
0.02
0.04
0.06
0.08
Empirical density of log-returns
N = 1776  Bandwidth = 0.9732
Density
Fig. 7.6 Empirical density of the IBM log-returns: there appears to be slight positive skewness
e.g. the standard Student t distribution with ν > 0 degrees of freedom, with density
function
f (ϵ) =


ν+1
2

√νπ
 ν
2


1 + ϵ2
ν
	−(ν+1)/2
.
Fernandez and Steel (1998) introduce a distribution with density p(x) as the
asymmetric or skew version of f (·)
p(ϵ | γ ) =
2
γ + 1
γ

f
 ϵ
γ
	
I[0,∞](ϵ) + f (γ ϵ)I(−∞,0)(ϵ)

,
(7.33)
where γ ̸= 0 is a parameter which controls the skewness of the distribution and
IA(ϵ) denotes the indicator function, so that IA(ϵ) = 1, if ϵ ∈A and is zero
otherwise, where A is a subset of the domain of f (·). Equation (7.33) suggests
that if ϵ ≥0, the p(ϵ | γ ) is the symmetric density f (·) scaled by γ , while if ϵ < 0,
p(ϵ | γ ) is the symmetric density f (·) scaled by 1/γ . In particular, (7.33) implies

7.3
Univariate Stochastic Volatility Models
365
that
p(ϵ | γ ) = p

−ϵ | 1
γ
	
,
so that by inverting γ we gain the mirror image of p(ϵ) around zero.
We observe that by setting γ = 1, Eq. (7.33) implies p(ϵ | γ = 1) = f (ϵ).
Hence, γ = 1 returns the symmetric Student t distribution.
We shall show that
P(ϵ ≥0 | γ )
P(ϵ < 0 | γ ) = γ 2.
(7.34)
This clearly indicates that the mass allocated left of ϵ = 0 and the mass allocated
on the right of ϵ = 0 are unequal (they are equal if and only if γ = 1).
To prove (7.34), ﬁrst note that
P(ϵ ≥0 | γ ) =
" ∞
0
p(u) du =
2
γ + 1
γ
" ∞
0
f
 u
γ
	
du.
(7.35)
On the other hand,
P(ϵ < 0 | γ ) =
" 0
−∞
p(u) du =
2
γ + 1
γ
" 0
−∞
f (γ u) du.
We apply the following change of variable γ u = s/γ , so that
P(ϵ < 0 | γ ) =
2
γ + 1
γ
1
γ 2
" ∞
0
f
 s
γ
	
ds,
(7.36)
since f (·) is a symmetric distribution. Combining (7.35) and (7.36), we obtain
(7.34) as required.
Let k be a positive integer. The k-th (raw) moment of ϵ, given γ , is
E(ϵk | γ ) =
2
γ + 1
γ

γ k+1 + (−1)k
γ k+1
	
2
" ∞
0
ukf (u)d du.
(7.37)
To prove this, ﬁrst we write
E(ϵk | γ ) =
" ∞
−∞
p(ϵ | γ ) dγ
=
2
γ + 1
γ

" ∞
0
ϵkf
 ϵ
γ
	
dϵ +
" 0
−∞
ϵkf (γ ϵ) dϵ

.
(7.38)

366
7
The State Space Model in Finance
With the change of variable ϵ/γ = u, the ﬁrst integral of (7.38) becomes
" ∞
0
ϵkf
 ϵ
γ
	
dϵ = γ k+1
" ∞
0
ukf (u) du.
(7.39)
With the change of variable γ ϵ = s, the second integral of (7.38) is
" 0
−∞
ϵkf (γ ϵ) dϵ =
1
γ k+1
" 0
−∞
skf (s) ds = (−1)k
γ k+1
" ∞
0
skf (s) ds.
(7.40)
Substituting (7.39) and (7.40) into (7.38), we obtain (7.37) .
Using the well known moments of the Student t distribution, we have that E(ϵk |
γ ) = 0, if k is odd. If k is even, using (7.37), the k-th (raw) moment of ϵ is
E(ϵk | γ ) =
2
γ + 1
γ

γ k+1 +
1
γ k+1
	
νk/2
√p
 ν
2

k + 1
2
	

ν −k
2
	
,
where 0 < k < ν. If k ≥ν, the moment does not exist. It follows that E(ϵ | γ ) = 0
and
Var(ϵ | γ ) = E(ϵ2 | γ ) =
2(γ 6 + 1)ν
γ 2(γ 2 + 1)(ν −2),
(7.41)
for ν > 2.
A measure of skewness γM based on the mode, due to Arnold and Groeneveld
(1995), is deﬁned as
γM = 1 −2F(M),
where F(·) is the cumulative distribution function and M is the mode of a
unimodal distribution. Arnold and Groeneveld (1995) propose this measure to order
continuous distributions according to their skewness. The mode of the skew t
distribution of (7.33) is M = 0 (since f (ϵ) has mode 0). We observe that from
* 0
−∞f (u) du = 1/2, if we apply the change of variable γ ϵ = u, we get
1 −4γ
" 0
−∞
f (γ ϵ) dϵ = −1.
Now from this equation, we obtain
γM = 1 −2F(0) = 1 −
4γ
γ 2 + 1
" 0
−∞
f (γ ϵ) dϵ = γ 2 −1
γ 2 + 1.
(7.42)

7.3
Univariate Stochastic Volatility Models
367
For γ ∈(0, ∞), the function γM(γ ) is strictly increasing (in γ ) and γM ∈(−1, 1).
We note that when γ ≈0, then γM ≈−1; when γ →∞, then γM ≈1. For γ = 1
(symmetric distribution), we have γM = 0; positive skewness is implied if γM > 0
and negative skewness is implied if γM < 0. For more details and properties of γM,
the reader is referred to Arnold and Groeneveld (1995) and Fernandez and Steel
(1998).
We turn our attention to the stochastic volatility model (7.26a)–(7.26b). As
before, let yt be the log-return at time t. We shall reconsider the Gaussian
assumption of Eq. (7.26a) and we shall replace it by a skew t distribution. Hence,
we redeﬁne the stochastic volatility model as
yt = exp(ht/2)ϵt,
ϵt ∼STν,
(7.43a)
ht −μ = φ(ht−1 −μ) + ωt.
ωt ∼N(0, σ 2
ω),
(7.43b)
where STν denotes a skew t distribution with ν degrees of freedom and with density
(7.33). The assumptions of process {ht} are as in (7.26b), but we note that ht is not
the log-volatility in model (7.43a)–(7.43b). Indeed, for ν > 2, from Eq. (7.41), the
volatility of yt (the conditional variance of the log-returns) is
σ 2
t = Var(yt | γ, ht, ν) = 2(γ 6 + 1)ν exp(ht)
γ 2(γ 2 + 1)(ν −2) .
(7.44)
The vector of hyperparameters is now θ = (μ, φ, σ 2
ω, ν, γ )⊤. In the application of
the Liu and West particle ﬁlter (Sect. 6.7.8.2), the priors of μ, φ and σ 2
ω are the same
as in Sect. 7.3.4. For the degrees of freedom ν, we can set a gamma prior. However,
as commented below, estimating the degrees of freedom this way due to the fat tails
of the log-returns may result in an estimate ˆν < 2. In this case the volatility (7.44)
does not exist. Although some other measure of the volatility can be considered (e.g.
replacing the ratio ν/(ν −2) in (7.44) with some ‘suitable’ constant, it is generally
recommended to avoid such an approach. In the implementation of this model for
the IBM log-returns below, we specify ν = 3, so that it is relatively low in order
to capture fat tails and allow Var(yt | γ, ht, ν) to exist. It remains then to set the
prior of γ . We set a gamma prior on γ , i.e. γ ∼G(0.1, 0.1), so that E(γ ) = 1 and
Var(γ ) = 10. This prior suggests that our prior belief of the returns is centred on a
symmetric distribution (γ = 1), with variance 10.
Figure 7.6 plots the empirical density of the IBM log-returns. This ﬁgure
indicates slight positive skewness (the mass of the positive values of the density is
larger than that of the negative values, indicating asymmetry). We ﬁt the stochastic
volatility model (7.43a)–(7.43b) for this data. Figure 7.7 plots the posterior mode of
volatility, together with modes of hyperparameters μ (mean), σ 2
ω (variance), φ (AR
coefﬁcient) and γ (skewness parameter). These hyperparameters converge to stable
values: the average of μ is 2.355, of σ 2
ω is 0.514, of φ is 0.759 and of γ is 2.886. The
degrees of freedom are set to ν = 3, so that the variance of yt (hence the volatility)
exists.

368
7
The State Space Model in Finance
The estimate volatility plotted on the top right panel of Fig. 7.7 is
ˆσ 2
t = 3( ˆγ 6 + 1) exp(ˆht)
ˆγ 2( ˆγ 2 + 1)
,
where ˆγ = 2.886, ν = 3 and ˆht is the mode of h(1)
t , . . . , h(1000)
t
, for each point
of time t. The mean (taken over time) of the posterior modes of the skewness
parameter γ (2.886) suggests that the log-returns exhibit small positive skewness,
which agrees with the shape of the distribution of the log-returns in Fig. 7.6. The
skewness measure based on the mode of (7.42) is equal to 0.786, which again
agrees with positive skewness. A formal comparison between the skew t and the
Gaussian model (7.26a)–(7.26b) is not performed; however, we expect that the
skew t model to perform better, as it incorporates a certain degree of fatness in
the tails and asymmetry of the returns distribution. Figure 7.8 shows the histograms
of volatility ˆσ 2
1776 and hyperparameters μ (mean), σ 2
ω (variance), φ (AR coefﬁcient)
and γ (skewness parameter).
Figure 7.7 shows that the estimated volatility seems to pick higher peaks of the
log-returns in the model incorporating asymmetry. We observe that in high volatile
Time
Log-returns
0
500
1000
1500
-30
-10
10
30
Time
Volatility
0
500
1000
1500
0
2000
5000
Time
Mean
0
500
1000
1500
0.0
1.0
2.0
Time
Variance
0
500
1000
1500
0.5
0.7
0.9
1.1
Time
AR coefficient
0
500
1000
1500
-0.2
0.2
0.6
Time
Skewness parameter
0
500
1000
1500
0.5
1.5
2.5
3.5
Fig. 7.7 Log-returns (top left), posterior mode of volatilities ˆσ 2
t (top right) and posterior modes
of hyperparameters μ (mean), σ 2
ω (variance), φ (AR coefﬁcient) and γ (skewness parameter)

7.4
Multivariate Stochastic Volatility Models
369
Volatility
Frequency
0
50
100
0
50
100
200
Mean
Frequency
2.37
2.38
2.39
2.40
2.41
2.42
2.43
0 50
150
250
Variance
Frequency
0.475
0.480
0.485
0.490
0.495
0.500
0
50
150
AR coefficient
Frequency
0.69
0.70
0.71
0.72
0.73
0
50
150
250
Skewness parameter
Frequency
2.998
3.000
3.002
3.004
3.006
0
50
100 150
Fig. 7.8 Histograms at t = 1776 of volatility σ 2
t and hyperparameters μ (mean), σ 2
ω (variance), φ
(AR coefﬁcient) and γ (skewness parameter)
periods, such as in the beginning of the series (see top left panel of Fig. 7.7), the
estimated volatility from the skew t model is considerably larger than that of the
Gaussian model (compare Figs. 7.7 and 7.6). In periods of low volatility, the two
methods are more comparable, see e.g. the histograms of the estimated volatility
at t = 1776 (Figs. 7.5 and 7.8). Although a formal comparison between the two
models is not performed, our analysis for this data set favours strongly the model
with the incorporation of skew t distribution for the log-returns.
7.4
Multivariate Stochastic Volatility Models
7.4.1
Motivation and General Overview
Section 7.3 discussed inference for univariate stochastic volatility models. These
models consider a scalar returns time series (or the returns of a single asset).
However, in practice we are usually interested in the volatility and inter-dependence

370
7
The State Space Model in Finance
of several assets, for example, to enable asset allocation and optimise portfolio
performance (Markowitz, 1959; Aguilar & West, 2000; Han, 2006; Brandt & Santa-
Clara, 2006). The recognition that assets and other ﬁnancial instruments populate
ﬁnancial markets and are therefore subject to market restrictions, co-dependences
and socio-economic and political change. Hence, it is important to study returns as
vector time series and their conditional covariance matrix as their volatility. To set
our notation, consider that we hold p > 1 assets and at time t the i-th constituent
return (log-return or geometric return, see Sect. 7.3.1) is denoted by yit. We shall
deﬁne the vector return at time t as
yt =
⎡
⎢⎣
y1t
...
ypt
⎤
⎥⎦.
(7.45)
The conditional covariance matrix of yt
t = Var(yt | t)
is known as the volatility matrix.
The volatility has been the centre of a large body of research over the past
40 years (Liesenfeld & Richard, 2003; Asai et al., 2006; Yu & Meyer, 2006).
This is because t holds important information about the uncertainty of assets
over time (the diagonal element of t is the marginal volatility) and the cross-
correlation of the returns, which is important in the construction of portfolio
allocation (Markowitz, 1959; Han, 2006; Brandt & Santa-Clara, 2006).
As in univariate volatility models, there are two main classes of volatility
models, the multivariate generalised autoregressive conditional heteroskedasticity
(MGARCH) and the multivariate stochastic volatility models. MGARCH models,
which are reviewed in Bauwens et al. (2006), usually adopt a maximum likelihood
inference. One of the challenges they face is the so-called curse of dimensionality,
because there are too many parameters to estimate and likelihood maximisation
might prove to be challenging and in risk to be affected by local maxima.
Another challenge affecting the models is the restriction on the parameter space
so that to make sure that the volatility matrix is a non-negative deﬁnite symmetric
matrix (i.e. covariance matrix). In order to overcome these challenges, clever
model speciﬁcations have been suggested, which trade-off model complexity and
dimensionality reduction. The most notable studies are the conditional correlation
speciﬁcation of Engle (2002) and the improvement of this model, the orthogonal
GARCH speciﬁcation of Van Der Weide (2002). We shall brieﬂy describe the above
GO-GARCH to get an idea of what is the modelling set-up for these models.
Consider that a p-dimensional log-return vector yt, deﬁned in (7.45), is observed.
It is assumed that yt follows a multivariate normal distribution, with zero mean
vector and covariance matrix, the volatility t, or yt ∼N(0, t). These authors
make the assumption that yt is governed by a linear combination of uncorrelated

7.4
Multivariate Stochastic Volatility Models
371
economic components xt, or yt = Zxt, where Z is a p×q parameter matrix and xt is
a q-dimensional column vector consisting of q independent component time series.
If Ht = diag(h1,t, . . . , hq,t) denotes the volatility matrix of xt = [x1t, . . . , xqt]⊤,
then Van Der Weide (2002) considers a univariate GARCH(r, s) for each of the
components xit, i = 1, . . . , q. For example, for r = s = 1, the GARCH
speciﬁcation for xit is
hit = (1 −αi −βi) + αiy2
i,t−1 + βihi,t−1,
where αi and βi are the parameters for the i-th GARCH model of xit. This
speciﬁcation deﬁnes the volatility model for Ht, and hence the volatility matrix t
of yt is t = ZHtZ⊤. Estimation of Z and h1t, . . . , hqt is carried out by maximum
likelihood estimation, for details of which the reader is referred to Van Der Weide
(2002).
Other speciﬁcations of multivariate GARCH are available, including Bayesian
inference of GARCH models, see e.g. Vrontos et al. (2003), Virbickaite et al. (2015)
and Iqbal and Triantafyllopoulos (2019) among others.
Multivariate stochastic volatility models consider that the volatility (covariance)
matrix t of yt is a stochastic process. There are generally two main classes of
model speciﬁcations: (a) extensions of the univariate stochastic volatility model
(Sect. 7.3) as reported in Chib et al. (2006) and (b) models that use a suitable
stochastic process for t.
Below we shall brieﬂy describe a simpliﬁed version of the model speciﬁcation of
Chib et al. (2006). In our speciﬁcation we do not include jumps considered by Chib
et al. (2006). Let us denote yt = [y1t, ypt]⊤be the log-returns vector and consider
the model
yt = Bft + ut,
where ft is a q-dimensional vector of factors (q < p), and B = (bij)i,j=1,...,q is a
parameter matrix, with bij = 0, for j > i and bii = 1. The vector of innovations
ut = [u1t, . . . , upt]⊤has the following speciﬁcation. Each uit follows a Student t
distribution and uit is independent of ujt, for i ̸= j, with the hierarchical structure
uit =
ϵit
√λit
,
λit ∼G
νi
2 , νi
2

,
where ϵt = [ϵ1t, . . . , ϵpt]⊤is independent of ft = [f1t, . . . , fqt]⊤, each of which
follows multivariate Gaussian distributions with zero mean vectors and covariance
matrices Vt and Dt, or ϵt ∼N(0, Vt) and ft ∼N(0, Qt) and ϵt is independent of
ft. The covariance matrices Vt and Dt are speciﬁed by
diag(Vt, Dt) = diag[exp(h1t), . . . , exp(hp+q,t)],

372
7
The State Space Model in Finance
where hjt is an autoregressive process
hjt −μj = φj(hj,t−1 −μj) + ζjt,
ζjt ∼N(0, σ 2
j )
(7.46)
and ζit is independent of ζjt, for i ̸= j and j = 1, . . . , p + q. The parameters of
this model are B, νi, hjt, μj, φj and σ 2
j , for i = 1, . . ., p and j = 1, . . ., p + q.
Let β be the number of parameters of B after imposing the restriction on its
elements (see above). Chib et al. (2006) show that sampling β and ft in one
block, conditionally on the other parameters and then sampling these parameters
conditioned on B and ft is ineffective and computationally slow for large values of
p and q. Conditionally on B, λj, y, the model can be decomposed into p univariate
conditionally Gaussian state space models, with observation model
yit | B, λj ∼N(biDtb⊤
i + λit exp(hit)),
(7.47)
where bi = [bi1, . . . , biq] is the i-th row vector of B and hit are speciﬁed as in
(7.46), for i = 1, . . . , p.
Hence we can draw samples of hjt, μj, φj and σ 2
j from each of the above
univariate conditionally Gaussian state space models; note that model (7.46)–(7.47)
is very similar to the univariate model (7.26a)–(7.26b), for which MCMC was
discussed in Sect. 7.3.3. The quantity λjt can be sampled easily by using the gamma
prior once hit is sampled. Chib et al. (2006) discuss how B can be sampled once
we have sampled other parameters, and for the full details the reader is referred to
that reference. One of the advantages of this MCMC algorithm is that it devolves
covariance sampling to a number of univariate sampling. This makes it scalable
to both dimensions p and q. Hence it has been successful dealing with high
dimensional returns.
In the next section we describe two stochastic volatility models, which model
the volatility matrix t of the returns as a stochastic process directly (and not via
log-volatilities as in the model above).
7.4.2
Wishart Autoregressive Stochastic Volatility Models
Considering the univariate stochastic volatility model (7.26a)–(7.26b) is natural,
since we can always deﬁne σ 2
t
= Var(yt) = exp(ht). In the multivariate case,
however, when yt is a vector, it is more challenging to deﬁne t in a similar way.
While Chib et al. (2006) deﬁne the volatilities (diagonal elements of t) separately,
their overall hierarchical model structure may not be always desirable to adopt.
Ishihara et al. (2016) propose a different generalisation of model (7.26a)–(7.26b)
using the matrix exponential, see also Chiu et al. (1996). All these approaches
are based on the log-volatility being modelled with a Gaussian or other symmetric
distribution. This is basically adopted so as to address the issue of the restrictions
of t, being a symmetric and positive deﬁnite (or more generally a non-negative

7.4
Multivariate Stochastic Volatility Models
373
deﬁnite) matrix. It has been therefore of interest to propose a variance–covariance
stochastic process for t.
Shephard (1994a) proposes variance stochastic process to describe the evolution
of univariate volatility. His local scale models assume a Gaussian model for the
returns
yt | φt ∼N(0, φ−1
t
),
(7.48)
where the volatility σ 2
t = Var(yt | φt) = φ−1
t
is speciﬁed in terms of the precision
of the returns φt.
The precision φt follows a variance (local scale) law
φt = δ−1φt−1ηt,
(7.49)
where δ is a discount factor and ηt follows independently of φt−1 a beta distribution
ηt ∼B[δνt−1, (1 −δ)νt−1],
(7.50)
with νt−1 being some degrees of freedom. Placing a prior gamma distribution on
φt−1, it follows that the posterior distribution of φt is a gamma distribution, and
from (7.48) it follows that, unconditionally of φt, the returns follow a Student t
distribution. Also, it follows that the posterior distribution of the volatility σ 2
t is
an inverse gamma distribution. This model borrows the gamma variance law (7.49)
ﬁrst proposed in Smith and Miller (1986) and then used in Harvey and Fernandes
(1989); in this book this variance law is detailed in Sect. 6.5.2 and in Exercise 5 (p.
330). The variance law (7.49)–(7.50) deﬁnes a random walk type evolution, in the
sense that
E(φt | φt−1) = φt−1
and
Var(φt | φt−1) = (1 −δ)φ2
t−1
δ(νt−1 + 1)
and hence the name local scale model. Unlike model (7.26a)–(7.26b), which
proposes an autoregressive type evolution of the volatility, model (7.48)–(7.50)
proposes a local level or random walk type evolution for the volatility. This might be
unacceptable in the long run (as volatility is expected to be mean stationary), but in
the short term (locally), this setting can work. An attractive feature of model (7.48)–
(7.50) is that it is analytically tractable and hence no approximation or simulation
steps involved.
In the mid 1990s, there were efforts led by Harald Uhlig to generalise the gamma
variance law of Smith and Miller (1986) and Shephard (1994a) to the multivariate
case. The Wishart distribution was the obvious candidate to replace the gamma
distribution of the precision matrix t = −1
t
, where t is the volatility matrix of
a returns vector yt. The multivariate beta distribution was already known and some
results between the Wishart and multivariate beta are reported in Khatri and Pillai
(1965) and Muirhead (1982). However, Uhlig (1994) observed that the Wishart-beta

374
7
The State Space Model in Finance
conjugacy of Muirhead (1982) implied that the degrees of freedom increased with
no bound over time with the serious consequence that the mean of the precision
to go to inﬁnity. Uhlig (1994) realised that in order to preserve the degrees of
freedom similarly as in (7.49)–(7.50), one needs to replace the multivariate beta
by the singular multivariate beta distribution. Hence he re-established the Wishart-
beta covariance law for a singular multivariate beta distribution and he proved a
number of important results in Uhlig (1994). This work, of signiﬁcant theoretical
and practical consideration, has led to a number of papers that have improved
the arguments put forward by Uhlig (1994) and solved a conjecture by Uhlig
(Díaz-García & Gutiérrez, 1997, 1998); see also Konno (1988). In the context of
stochastic volatility, Uhlig (1997) made use of the Wishart–singular beta conjugacy;
his method involved a simulation step in order to estimate autoregressive parameters
of the volatility stochastic process, but his approach is fast due to the conjugacy
mentioned above.
This body of research has led to the so-called Wishart autoregressive processes
(WAR), see e.g. Bru (1991), Philipov and Glickman (2006), Gourieroux et al.
(2009), Triantafyllopoulos (2008b, 2011b, 2012, 2014), Hata and Sekine (2013),
Bäuerle and Li (2013) and Yu et al. (2017) among others.
In the sequel we describe the model of Triantafyllopoulos (2012). Consider that,
at time t, the log-return vector yt follows a p-variate Gaussian distribution with
mean vector μ and covariance matrix t, i.e.
yt = μ + 1/2
t
ϵt,
ϵt ∼N(0, I),
(7.51)
where 1/2
t
denotes the square root matrix of t, and the sequence of {ϵt} follows
a p-dimensional Gaussian white noise process with unit diagonal variances (here I
denotes the p × p identity matrix).
Deﬁne the precision matrix t = −1
t
(assuming that matrix t is positive
deﬁnite). t is assumed to follow a Wishart autoregressive process based on Uhlig’s
random walk representation (Uhlig, 1994). Initially it is assumed that 0 follows a
Wishart distribution with some known degrees of freedom n0 > p −1 and scale
matrix F0, written as 0 ∼W(n0, F0) (see Sect. 5.5.2 for a discussion of the
Wishart and inverse Wishart distributions). The transition model for t is deﬁned
by
t = kAU(t−1)⊤βtU(t−1)A⊤+ t,
(7.52)
where k is a constant to be determined, A is a p×p autoregressive parameter matrix,
t is a p × p symmetric non-negative deﬁnite matrix and U(t−1) denotes the
upper triangular matrix of the Choleski decomposition of the matrix t−1. Matrix
βt follows a singular multivariate beta distribution with parameters a/2 and b/2 to
be speciﬁed.

7.4
Multivariate Stochastic Volatility Models
375
Triantafyllopoulos (2012) sets t = 0, which is also used in Uhlig (1994, 1997),
but it might be not appropriate in the long run as t →∞, because the above
autoregressive structure means that t will concentrate around the zero matrix.
However, for the local scale models discussed here, this issue is not a problem.
The autoregressive (AR) feature (or characterisation) of model (7.52) is depicted by
noticing
E(t | t−1) = kAU(t−1)⊤E(βt)U(t−1)A⊤
= At−1A⊤,
where E(βt) = k−1I. The parameters a an b of the bets distribution are conveniently
chosen (a is a function of δ and b = 1) so that E(βt) = k−1I. For the random walk
model Uhlig (1994) shows that βt has to follow a singular beta distribution for this
to be possible, in order to have b < p −1 (because for a non-singular distribution b
is greater than p −1 (Muirhead, 1982)).
Given data y1:t = {y1, . . . , yt}, we wish to provide the posterior distribution
of the volatility matrix t. Triantafyllopoulos (2012) adopts a two-step approach
for inference. In Step 1 the posterior distribution p(t | A, y1:t) of the precision
matrix t is provided. This is facilitated using the conjugacy of the beta and
Wishart distributions, under the evolution (7.52). In Step 2 the AR parameter
matrix A is estimated by maximising the log-posterior function; for this to end,
Triantafyllopoulos (2012) proposes a Newton–Raphson method; for a discussion
on posterior mode estimation, the reader is referred to Fahrmeir and Tutz (2001,
Section 8.3.1). Details of both steps are provided in the sequel.
Conditionally on A, assume that t−1 has the posterior distribution t−1 |
A, y1:t−1 ∼W(n + p −1, Ft−1), where Ft−1 implicitly depends on A and
n = (1 −δ)−1, for a discount or forgetting factor 0 < δ < 1. Starting at t = 1,
this is consistent with the prior of 0, if we set n0 = n + p −1. If we specify
a = δ(1 −δ)−1 + p −1 and b = 1, we see from Uhlig (1994) that k−1A−1t |
A, y1:t−1 ∼W(δn + p −1, Ft−1), or t | A, y1:t−1 ∼W(δn + p −1, kAFt−1A⊤).
From the above, it is E(t−1 | A, y1:t−1) = (n+p−1)Ft−1 and E(t | A, y1:t−1) =
(δn + p −1)kAFt−1A⊤, and so by equalising these two expectations, we obtain
k = n + p −1
δn + p −1 =
δ(1 −p) + p
δ(2 −p) + p −1.
Under the above setting, this value of k guarantees the autoregressive property of
the model, expressed by E(t | A, y1:t−1) = AE(t−1 | A, y1:t−1)A⊤.
We note that a > p −1, but 1 = b < p −1, the latter of which being responsible
for the singularity of the beta distribution. The singular beta density, being deﬁned
on the Stiefel manifold, replaces the determinant of I−βt (which is zero) by the only
positive eigenvalue of that matrix (due to b = 1). On the other hand, the determinant
of βt remains positive as a > p −1, and thus all p eigenvalues of βt are positive;

376
7
The State Space Model in Finance
this beta distribution is discussed in Uhlig (1994) and Díaz-García and Gutiérrez
(1997, 1998).
Having established the prior t | A, y1:t−1 ∼W(δn + p −1, kAFt−1A⊤), the
posterior distribution follows by a similar argument as in Triantafyllopoulos (2008b)
t | A, y1:t ∼W(n + p −1, Ft),
(7.53)
where et = yt −μ is the residual vector and Ft = (ete⊤
t + (kAFt−1A⊤))−1. From
the above reference, the one-step forecast distribution of yt is a p-variate Student t
distribution with δn degrees of freedom and spread matrix δ−1n−1(kAFt−1A⊤)−1,
i.e. yt | A, y1:t−1 ∼tp(δn, μ, δ−1n−1(kAFt−1A⊤)−1). This completes step 1
(conditional inference on the AR matrix A.
Moving on to step 2, from the joint prior density f (t, A | y1:t−1) = f (t |
A, y1:t−1)f (A | y1:t−1) and from an application of Bayes theorem for (t, A), we
have f (t, A | y1:t) ∝f (yt | t)f (t | A, y1:t−1)f (A | y1:t−1), so that
f (A | y1:t) ∝f (A|y1:t−1)
"
f (yt | t)f (t | A, y1:t−1) dt.
(7.54)
From the forecast distribution of yt, the integral of (7.54) is
"
f (yt | t)f (t | A, y1:t−1) dt ∝|ete⊤
t + (kAFt−1A⊤)−1|−(δn+p)/2,
and so
f (A | y1:t) ∝f (A)
t-
j=1
|eje⊤
j + (kAFj−1A⊤)−1|−(δn+p)/2,
where f (A) is the prior density of A. The prior density of A is assumed to be a
matrix-variate Gaussian distribution, i.e.
A ∼N(MA, VA, WA),
(7.55)
where MA = E(A) is the prior mean matrix and VA and WA are p × p left and
right covariance matrices; see Gupta and Nagar (1999) for a detailed account on
the matrix normal distribution, and Sect. 5.5.2 discusses matrix-variate Gaussian
distributions. Given the above references, (7.55) implies that vec(A) follows a
p2-dimensional multivariate distribution with mean vector vec(A) and covariance
matrix WA ⊗VA, where vec(·) denotes the column stacking operator of an
unrestricted matrix and ⊗denotes the Kronecker product of two matrices.
In order to ﬁnd the mode ˆA of the posterior f (A | y1:t), we note that the
matrix equation ∂f (A | y1:t)/∂A = 0 (with respect to A) does not appear to
admit an analytical solution. Thus, we approximate the true mode ˆA, by employing

7.4
Multivariate Stochastic Volatility Models
377
the Newton–Raphson method, according to which at each time t, for iteration
i = 1, 2, . . ., we compute ˆA(i) using the formula
vec( ˆA(i)) = vec( ˆA(i−1)) +
 ∂2 log f (A | y1:t)
∂vec(A)∂vec(A)⊤
	−1 2222
A= ˆA(i−1)
∂log f (A | y1:t)
∂vec(A)
2222
A= ˆA(i−1),
(7.56)
where ˆA(0) is initially given and vec(·) denotes the column stacking operator of an
unrestricted matrix. Under some regulatory conditions (Shumway & Stoffer, 2017),
the algorithm converges to the true mode ˆA.
The log-posterior of A is
log f (A | y1:t) = log c + log f (A) −δn + p
2
t
j=1
log |eje⊤
j + (kAFj−1A⊤)−1|,
where c is the proportionality constant of f (A | y1:t).
From the prior density (7.55) of A, we have
∂log f (A | y1:t)
∂vec(A)
= −(W−1
A ⊗V−1
A )(vec(A) −vec(MA))
−k(δn + p)
t
j=1

(Fj−1 ⊗eje′
j)vec(kAFj−1A⊤eje⊤
j + I)−1)A
−(Fj−1 ⊗I)vec(kAFj−1A⊤)−1A
	
.
(7.57)
To obtain the Hessian matrix of (7.56), we differentiate (7.57), i.e.
∂2 log f (A | y1:t)
∂vec(A)∂vec(A)⊤= −W−1
A ⊗V−1
A + k(δn + p)
t
j=1

(Fj−1 ⊗eje⊤
j )
×(kFj−1A⊤eje⊤
j + A−1)−1 ⊗(kFj−1A⊤eje⊤
j + A−1)−1
×((eje⊤
j ⊗kFj−1)Kp −A−1 ⊗A−1) −(Fj−1 ⊗I)(k−1A⊤−1Fj−1)
⊗(k−1A⊤−1Fj−1)((I ⊗kFj−1)Kp)
	
,
(7.58)
where Kp is the p2 × p2 vec-permutation matrix, i.e. vec(A⊤) = Kpvec(A). For
the proof of (7.57) and (7.58), the reader is referred to Triantafyllopoulos (2012).
Hence in step 2 the posterior mode ˆA(i) is obtained by the iterative procedure of
the Newton algorithm (7.56). Convergence is achieved when the Frobenius matrix
norm between two successive iterations is less than a given tolerance threshold, or

378
7
The State Space Model in Finance
∥ˆA(i) −ˆA(i−1) ∥F ≤Tol, where ∥X ∥F =
1n
i=1
m
j=1 x2
ij is the Frobenius norm
of an n × m matrix X = (xij) and Tol is a pre-speciﬁed tolerance threshold.
We illustrate the above methodology with data consisting of ﬁve foreign
exchange rates vis-`a-vis the US dollar. The exchange rates are the Canadian dollar
(CAD), Euro (EUR), Japanese Yen (JPY), British pound (GBP) and Australian
dollar (AUD), all expressed as a number of units of the foreign currency per US
dollar. The sample period runs from 4 January 1999 until 31 December 2009
and corresponds to 2760 observations, sampled at daily frequencies. This data
set was obtained from the Paciﬁc Exchange Rate Service of the University of
British Columbia (http://fx.sauder.ubc.ca/). The data is transformed to log returns.
In the ﬁrst two years (4 January 1999 to 31 December 2001), we use the data
for pre-processing purposes, in order to obtain sample estimates for μ and 0.
Then, starting at 2 January 2002, we run the volatility algorithm, in order to obtain
forecasts of the volatility matrix.
Figure 7.9 shows the absolute returns together with the out of sample predicted
marginal volatilities (the diagonal elements of the predicted volatility matrix ˆt,
conditioned upon information y1:t−1 sequentially for t = 1, . . . , N starting at
2 January 2002), and Fig. 7.10 shows the out of sample predicted correlations.
Figure 7.9 indicates the good out of sample forecasting performanceof the volatility,
while Fig. 7.10 shows the dynamics of the correlation. Figure 7.11 shows the
estimates of the diagonal elements of A = (Aij)i,j=1,...,5. We note that A11 and A55
indicate a structural change after 2008, which highlights the abrupt increase in the
volatility at that period, being evident by the left panel of Fig. 7.9 for CAD (relevant
to A11) and AUD (relevant to A55). We also note that initially, the values of Aii are
centred around one (A indicates the autocorrelation of the precision process {t}).
In Fig. 7.11, we see that the Aii’s gradually increase, and after 2003 the estimated
values of Aii are centred around 16.4, although for more conclusive comments
one needs to look at the off-diagonal elements of A too. For the Newton–Raphson
algorithm, we have used a stoppage tolerance Tol = 0.0001, and this was achieved
for a minimum of 4 iterations and a maximum of 10 iterations.
One of the advantages of this model is that step 1 is completed using the
conjugacy between the Wishart and the singular beta distribution and step 2 may
require only a small number of iterations for the Newton algorithm to converge (here
only 10 iterations were needed). Hence, there is no simulation step involved, and as a
result the model is scalable. It can handle a large number of dimensions p, although
it is expected that with the number of dimensions the number of iterations of the
Newton algorithm will increase. As a rule of thumb experimentation shows that if
the dimension of the vector of the returns is p, the number of iterations required is
about 2p.
A disadvantage of the above algorithms is that they make the assumption of
the multivariate normal distribution for the returns. As discussed in Sects. 7.3.1
and 7.3.4, this assumption may not hold true in practice and should be replaced by
a suitable multivariate skew t distribution or some other asymmetric distribution
with fat tails. As the skew t distribution of Fernandez and Steel (1998) does not

7.4
Multivariate Stochastic Volatility Models
379
0.00
0.02
0.04
CAD
0.00
0.02
0.04
EUR
0.00
0.02
0.04
JPY
0.02
0.04
GBP
0.00
0.04
0.00
0.08
2002
2004
2006
2008
AUD
trading day
0.00
0.03
0.06
CAD
0.00
0.03
0.06
EUR
0.00
0.03
0.06
JPY
0.00
0.03
0.06
GBP
0.00
0.10
0.20
2002
2004
2006
2008
AUD
trading day
Absolute returns and predicted marginal volatilities
Fig. 7.9 Absolute returns and standard deviations of the out of sample predicted volatility, with
δ = 0.7
generalise in the multivariate case, a candidate is the skew t distributions of Azzalini
and Capitanio (2003); see also Parisi and Liseo (2018).
7.4.3
Portfolio Optimisation and Asset Allocation
7.4.3.1
Problem Statement
In this section we discuss the classical mean–variance portfolio construction
(Markowitz, 1952, 1959; Lintner, 1965). Following the seminal work of Markowitz
(1952), a large amount of research is devoted to the construction, selection and
assessment of optimal portfolio and risk management, see e.g. Han (2006); Soyer

380
7
The State Space Model in Finance
-0.5
0.0
0.5
CAD-EUR
-0.5
0.0
0.5
CAD-JPY
-0.5
0.0
0.5
CAD-GBP
-0.5
0.0
0.5
1.0
CAD-AUD
-0.5
0.0
0.5
2002
2004
2006
2008
EUR-JPY
Time
-0.4
0.0
0.4
0.8
EUR-GBP
-0.4 0.0
0.4
0.8
EUR-AUD
-0.5
0.0
0.5 1.0
JPY-GBP
-1.0
0.0
0.5
JPY-AUD
-0.5
0.0
0.5
2002
2004
2006
2008
GBP-AUD
Time
Cross-correlation
Fig. 7.10 Out of sample predictions of the cross-correlations between the ﬁve exchange rates,
with δ = 0.7
and Tanyeri (2006); Adcock (2007, 2010) for some recent contributions. Book-
length coverage of asset allocation techniques and risk management can be found
in Meucci (2005) and Schulmerich et al. (2015). Below we discuss the two basic
portfolio selection strategies due to Markowitz (1952; 1959), but we apply them
sequentially over time as in Aguilar and West (2000) and Soyer and Tanyeri (2006).
Suppose that we hold p assets, so that asset i is associated with log-returns yit,
i = 1, . . ., p. For example, these may be the 30 constituents of the Dow Jones
Industrial Average index or the subset of the S&P500 index. We deﬁne the vector
of log-returns yt = [y1t, . . . , ytp]⊤, as discussed in Sect. 7.4.1 above. Adopting
a multivariate volatility model, we obtain an estimate of μ = E(yt) and of the

7.4
Multivariate Stochastic Volatility Models
381
Out of sample estimates of A
trading day
2002
2004
2006
2008
15.6
15.8
16.0
16.2
16.4
16.6
16.8
A11
A22
A33
A44
A55
Fig. 7.11 Out of sample estimates of the diagonal elements Aii of A = {Aij}, with δ = 0.7
volatility matrix t, as discussed in the previous sections. We deﬁne the portfolio
returns
rt =
p

i=1
wiyit = w⊤yt,
where w = [w1, . . . , wp]⊤is a vector of p weights associated with the p assets. It is
assumed that p
i=1 wi = w⊤1p = 1, where 1p = [1, . . ., 1]⊤. Sometimes we may
assume that all weights are non-negative, but the optimisation procedures described
below do allow for negative weights. A negative weight is usually associated with
short-selling an asset. The portfolio selection problem consists of choosing weights
w in an optimal way; this usually means either minimising the portfolio variance
Var(rt) or maximising the portfolio returns E(rt). Below we discuss two possible
strategies, the unconstrained portfolio (UP) and the constrained portfolio (CP).

382
7
The State Space Model in Finance
7.4.3.2
Unconstrained Portfolio Selection
In the UP problem, we minimise the portfolio variance
σ 2
t = Var(rt) = Var(w⊤yt) = w⊤tw,
(7.59)
subject to the constraint that w⊤μ = m, where m is a target portfolio mean. This
portfolio selection minimises the portfolio variance or volatility given a certain value
for the expected return. It is also equivalent of maximising the expected portfolio
return E(rt), given a ﬁxed target value for the portfolio variance.
We will use the optimisation technique using Lagrange multipliers. Let λ be a
Lagrange multiplier and deﬁne the function
L(w, λ) = 1
2w⊤tw + λ(m −w⊤μ).
The partial derivatives of L with respect to w and λ are
∂L
∂w = tw −λμ
and
∂L
∂λ = m −w⊤μ.
Equalising the partial derivatives to zero, we obtain
w = λ−1
t
μ,
(7.60)
w⊤μ = m.
(7.61)
Substituting w of (7.60) into (7.61), we solve for λ as
λ =
m
μ⊤−1
t
μ
,
and putting this back in (7.60), we obtain the optimal weight as
w = m−1
t
μ
μ⊤−1
t
μ
.
(7.62)
However, one of the disadvantages of this approach is that it does not guarantee that
the weights sum to 1, since
w⊤1p = mμ⊤t1p
μ⊤−1
t
μ
,
which is equal to 1, if μ = m1p, but in general p
i=1 wi ̸= 1. One possible solution
is to set μ = m1p; this is not a good choice as it sets the expectation of the return

7.4
Multivariate Stochastic Volatility Models
383
E(yit) equal to m, for each i = 1, . . . , p. Another solution would be to calculate
w = [w1, . . . , wp]⊤and then to recalculate (adjust) wp = 1 −p−1
i=1 wi. However,
this might be problematic too, as there is no guarantee that wp will be non-negative.
The minimum portfolio variance is
σ 2
t = w⊤−1
t
w =
m2
μ⊤−1
t
μ
,
and if μ = m1p, then σ 2
t = (1⊤
p −1
t
1p)−1.
7.4.3.3
Constrained Portfolio Selection
Moving on to the constraint portfolio (CP), we minimise the portfolio variance
(7.59) subject to the constraints w⊤μ = m and w⊤1p = 1. We deﬁne the function
L(w, λ1, λ2) = 1
2w⊤tw + λ1(m −w⊤μ) + λ2(1 −w⊤1p),
where λ1 and λ2 are Lagrange multipliers. The partial derivatives set to zero lead to
tw −λ1μ −λ21p = 0,
(7.63)
m −w⊤μ = 0,
(7.64)
1 −w⊤= 0.
(7.65)
From (7.63), we solve for w,
w = λ1−1
t
μ + λ2−1
t
1p.
(7.66)
We solve the system of equations (7.64)–(7.65) for λ1 and λ2 and then put them
back to (7.66).
From (7.64), we have
w⊤μ = λ1μ⊤−1
t
μ + λ2μ−1
t
= m
and
w⊤1p = λ1μ⊤−1
t
1p + λ21⊤
p −1
t
1p.
We can write these two simultaneous equations as a linear system

 a b
b c
 
λ1
λ2

=

 m
1

,

384
7
The State Space Model in Finance
where a = μ⊤−1
t
μ, b = μ⊤−1
t
1p and c = 1⊤
p −1
t
1p. The solution of λ1 and λ2
is
λ1 = cm −b
ac −b2 =
m1⊤
p −1
t
1p −μ⊤−1
t
1p
(μ⊤−1
t
μ)(1⊤p −1
t
1p) −(μ⊤−1
t
1p)2 ,
λ2 = a −bm
ac −b2 =
μ⊤−1
t
μ −mμ⊤−1
t
1p
(μ⊤−1
t
μ)(1⊤p −1
t
1p) −(μ⊤−1
t
1p)2 .
Hence from (7.66), the optimal weight vector under CP is
w = −1
t
m(1⊤
p −1
t
1p)μ −(μ⊤−1
t
1p)μ + (μ⊤−1
t
μ)1p −m(μ⊤−1
t
1p)1p
(μ⊤−1
t
μ)(1⊤p −1
t
1p) −(μ⊤−1
t
1p)2
.
(7.67)
In the application of the above portfolio selection strategies, ﬁrst we adopt a
model for the returns yt, such as those described in Sects. 7.4.1 and 7.4.2. Hence we
obtain estimates ˆμ and ˆt of the mean vector μ and of the volatility matrix t, for
any t = 1, 2, . . ., n. In a ﬁrst reading, ˆμ might be obtained as the historical mean
of the returns and ˆt might be the mode of the posterior distribution of . These
quantities are loaded into Eqs. (7.62) and (7.67) to get the UP and CP weights and
hence to determine the proportion of asset to be allocated to the portfolio (assuming
equal transaction costs along the range of the assets).
For illustration purposes we consider a data set consisting of the common
constituents of the Dow Jones Industrial Average index over the period of 18 June
2001 to 4 September 2009. There are 30 assets included in the index and their
closing prices are observed at each trading day (excluding weekends and bank
holidays). The data is transformed into log-returns yt and the ﬁrst 637 observation
returns (corresponding to a period of 18 June 2001 to 31 December 2003) are used
in order to obtain the historical value ˆμ as the estimate of μ. The average (over the
30 assets) of this mean is −0.0001912098. We then ﬁt the Wishart autoregressive
volatility model of Sect. 7.4.2 for times t = 638 −2066 (corresponding to 1
January 2004 to 4 September 2009). The reader will notice that this period of time
includes the start of the 2008 global ﬁnancial crises triggered by the sub-prime
mortgage crises in US. Hence, a portfolio performance is likely to be affected by
high volatile and uncertain times. The estimated volatility ˆt is obtained using
the Wishart volatility model: this estimate is the mode of the posterior distribution
t | A = ˆA(i), y1:t ∼IW(n+29, Ft) (the inverse Wishart distribution with degrees
of freedom n + 29 and scale matrix Ft), where n = (1 −δ)−1 and i is the iteration
point of the Newton at convergence; for more details see Eq. (7.53).
Given the mean vector ˆμ and the covariance matrices ˆt, we ﬁt the unconstrained
portfolio (UP) and the constrained portfolio (CP), for two values of the discount
factor δ = 0.7 and δ = 0.95. A measure of the performance of the chosen
allocation is the average risk, deﬁned as ¯R = 1700−1 n
t=1 w(t)⊤ˆtw(t), where

7.4
Multivariate Stochastic Volatility Models
385
% portfolio cumulative returns
trading day
2004
2005
2006
2007
2008
2009
0
2
4
6
CP,
=0.7
UP,
=0.7
CP,
=0.95
UP,
=0.95
Fig. 7.12 Cumulative returns for the Dow Jones data; shown are constrained portfolio (CP) and
unconstrained portfolio (UP) using discount factors δ = 0.7 and δ = 0.95
w(t) is vector of weights at time t = 1, . . . , 1700 (corresponding to times from 638
to 2067 or from 1 January 2004 to 4 September 2009). A visual way to appreciate
the portfolio performance is the plot of the cumulative portfolio returns, deﬁned
by r(c)
t
= t
i=1 rj = t
j=1 w⊤yj, for t = 1, . . . , 1700. Figure 7.12 plots the
cumulative returns for the two portfolio selection (UP and CP) for the two values of
the discount factor δ. The ﬁrst observation is that the UP and the CP in each case
provide very similar asset allocation, with the cumulative returns being very close
to each other (under a ﬁxed value of δ). The portfolio under the low discount factor
(δ = 0.7) produces consistently higher cumulative returns and has therefore superior
performance compared to the other portfolio. We conclude that the constrained
portfolio where the volatility is estimated using δ = 0.7 is the best performer for
this data set. The average risks using the model with δ = 0.7 are 0.02449 (CP) and
0.02297 (UP) and using the model with δ = 0.95 are 0.039 (CP) and 0.0365 (UP);
included are also the average risks for the equal weight portfolio – also known as
naive portfolio – 0.552 (model with δ = 0.7) and 0.769 (model with δ = 0.95).
These results conﬁrm that the volatility model with δ = 0.7 provides lower average
risk compared to the model using δ = 0.95. There is little difference between the

386
7
The State Space Model in Finance
Alcoa
trading day
% weight
2004
2006
2008
-0.5
0.0
0.5
1.0
Intel
trading day
% weight
2004
2006
2008
-0.5
0.5
1.5
McDonald's Corp.
trading day
% weight
2004
2006
2008
-1.0
0.0
1.0
Coca Cola
trading day
% weight
2004
2006
2008
-1
0
1
2
British Airways
trading day
% weight
2004
2006
2008
-1.5
-0.5
0.5
CASCO
trading day
% weight
2004
2006
2008
-0.5
0.5
1.5
2.5
IBM
trading day
% weight
2004
2006
2008
-1.5
-0.5
0.5
Bank of America
trading day
% weight
2004
2006
2008
0
1
2
3
American Express
trading day
% weight
2004
2006
2008
-0.5
0.5
1.5
2.5
Fig. 7.13 Portfolio weights of 9 assets under the CP portfolio (δ = 0.7)
performance of the CP and UP in the risk, but here the UP has slightly lower average
risk. As expected the naive portfolio allocation provides higher risk.
Figure 7.13 shows the estimated portfolio weights over time for 9 assets, for
the CP where the volatility is estimated using δ = 0.7. The unconstrained and
constrained optimisation procedures described above do not impose the assumption
that wi ≥0. Hence, negative weights can appear, e.g. in the UP, a negative weight is
likely to occur either due to negative covariances or due to negative returns. Usually,
a negative portfolio corresponds to investing less at the given proportion, i.e. short-
selling the given asset. If such a strategy is not desired, then the optimisation of the
portfolio should include the additional constraint that wi ≥0. There are practical
strategies that allow more delicate constraints to be included such that wi ≥di,
where di is some margin and di > 0. For this and more strategies, the reader is
referred to Meucci (2005) and Schulmerich et al. (2015).

7.4
Multivariate Stochastic Volatility Models
387
0
5
10
15
20
-0.010
-0.005
0.000
0.005
0.010
Efficient frontier
Portfolio volatility
Portfolio return
Fig. 7.14 Efﬁcient frontier plot for the Dow Jones data. Shown are the portfolio returns as a
function to the portfolio volatility
The efﬁcient frontier shows a number of optimal portfolios that maximise the
expected portfolio return for a given level or risk (or square root of the portfolio
volatility) or minimise the risk for a given portfolio return (Markowitz, 1952, 1959;
Lintner, 1965). Figure 7.14 plots the efﬁcient frontier for the Dow Jones data, using
a CP strategy, where the volatility is estimated using a discount factor δ = 0.7.
Shown is the average of the volatility portfolio 1700−1 1700
t=1 w(t)⊤ˆtw(t) for a
given target portfolio return m. This ﬁgure shows the range of optimal portfolios
(on the curve) for a range of target returns. As we can see when the average risk
tends to zero, the return is also close to zero. While as the target return increases the
risk increases. The plot is useful in identifying maximum return for a given risk. In
practice a risk level may be speciﬁed (usually a range of risk which the investor will
be comfortable to accept) and a maximum return should be identiﬁed. More details
of similar portfolio strategies can be found in Meucci (2005) and Schulmerich et al.
(2015) and the references therein.

388
7
The State Space Model in Finance
7.5
Pairs Trading
7.5.1
Introduction and Basic Concept
Statistical arbitrage consists of a collection of trading strategies based on statistics
and econometrics with the aim to return proﬁt to an investor. Pairs trading is a
market-neutral trading philosophy, which exploits a very basic trading rule in the
stock market: buy low and short-sell high. Market-neutral strategies consist of
trading rules that do not depend on the overall performance of the stock market
or other ﬁnancial markets. Such strategies are generally focusing on the relative
movements of selected assets and therefore are not dependent on the overall
performance of the markets.
The idea behind pairs trading can be traced back in the 1930s Cowles 3rd
and Jones (1937), but it appeared formally in the 1980s with the work of Nunzio
Tartaglia and his quantitative group at Morgan Stanley investment bank. Algo-
rithmic pairs trading deploys trading strategies and related decision-making that
can be implemented in the computer without human intervention. Recently, there
has been a growing interest in pairs trading and in related market-neutral trading
approaches, see Elliott et al. (2005), Gatev et al. (2006), Zhang and Zhang (2008),
Triantafyllopoulos and Montana (2011) and Montana et al. (2009). Book-length
discussion of pairs trading is also available Vidyamurthy (2004), Pole (2007). A
recent chapter devoted to the implementation of pairs trading can be found in Nolan
and Lang (2015, Chapter 6).
Considering the spread of two assets A and B, deﬁned as the difference of the
prices of A and B, pairs trading assumes that the spread attains an equilibrium or
that the spread in the long run reverts to its historical mean. The main idea behind
pairs trading is to propose trades based upon the relative temporary mispricing of
the two assets. For example, suppose that the equilibrium of the spread is $10 (US
dollars) and today the two assets trade at $40 and $10, or with spread 40−10=30.
Then, pairs trading suggests to go short (or short-sell) asset A (as this is likely to be
overpriced at $40) and to go long (or buy) asset B (as this is likely to be underpriced
at $10). If the spread reverts to its mean, the price of asset A will decrease and/or
the price of asset B will increase, either of which can return a healthy proﬁt.
7.5.2
State Space Models for Mean-Reverted Spreads
In this section we brieﬂy describe the model-based approach inference and pre-
diction of pairs trading following Elliott et al. (2005) and Triantafyllopoulos and
Montana (2011). Consider two assets A and B, and write pA
t the price of asset A
at time t and pB
t the price of asset B at time t. We shall consider these prices are
observed at a daily frequency, but lower frequency may be considered with few

7.5
Pairs Trading
389
modiﬁcations. We form the spread of these two assets as
yt = pA
t −pB
t .
(7.68)
The concept of pairs trading described in Sect. 7.5.1 is based on the assumption
of mean-reversion of the spread yt. Mean-reversion suggests that the mean of yt
is not time-dependent, for any t > t0, for some time point t0. That means that
after some time t0, the spread reaches some equilibrium level. The interpretation
of mean-reversion in this context is that if asset A is overpriced compared to asset
B (positive spread) at time t, then at some later time t + k the positions will be
reversed (asset B will be overpriced compared to A, negative spread), for some
k > 0. In this set-up at t, we can open a trading position to go short on asset A
and go long on B, so that at time t + k we can close the position and realise proﬁt.
Mean-reversion is closely related to stationarity (see Sect. 7.2), but mean-reversion
is a weaker condition, because it does not require that the variance be time-invariant.
For example, the stochastic volatility model (7.26a)–(7.26b) is mean-reverted, as
its mean is zero, but it is not weakly stationary, as its variance exp(ht) is time-
dependent.
The principle idea of Elliott et al. (2005) is to deploy a time series model for the
spread yt, which estimation will enable discovery of mean-reversion. In particular,
these authors consider a state process xt, which is generated by mean-reversion, so
that
xt −xt−1 = a −bxt−1 + ωt,
(7.69)
where 0 < b < 2 and a is an unrestricted real number and the initial state is x0. The
restriction on b is imposed, to ensure stationarity of xt. The innovation series {ωt}
is assumed to be a white noise (i.i.d. with zero mean and some variance σ 2
ω), and it
is further assumed to be Gaussian. We can rearrange (7.69) to
xt = a + (1 −b)xt−1 + ωt,
(7.70)
so that xt is an autoregressive model of order one, with some non-zero mean. This
can also be written xt −μ = φ(xt−1 −μ) + ωt, where φ = (1 −b) and a =
μ(1 −φ) = μb, so that xt −μ is the zero-mean AR(1) model of section (7.5). It
follows that μ = a/b, which is the equilibrium mean of xt. Together with the state
process xt, Elliott et al. (2005) consider that the spread yt is a noisy version of xt or
yt = xt + ϵt,
(7.71)
where ϵt is a Gaussian white noise with variance σ 2
ϵ , which is assumed to be
independent of ωt, for all t. Model (7.70)–(7.71) is a state space model, with state
xt and observation yt. Assuming a Gaussian prior for x0 and based on a collection
of observations {y1, . . . , yn}, we can estimate a and b and hence establish whether
0 < b < 2, so as to justify mean-reversion for this model.

390
7
The State Space Model in Finance
A simple trading rule based on model (7.70)–(7.71) is outlined next. If the spread
yt+1 was known at time t, it would be easy to make a decision as to which asset to
short-sell and which to buy. If say, we knew that yt < yt+1, we could anticipate
that the price of A was likely to increase at t + 1 and/or the price of B was likely
to decrease at t + 1 (relative to their prices at t). As a result at time t, we could buy
asset A and short-sell B. At t +1, with yt+1 > yt, we would realise a proﬁt when we
close the position, if asset A was sold and B was bought (minus transaction costs).
However, at time t, the spread yt+1 is not known, and hence we resort to
forecasting it. Let ˆyt+1 = ˆpA
t+1 −ˆpB
t+1 denote the one-step ahead forecast mean
of the spread yt+1 at time t.
Suppose that we wish to open a trading position at time t. We ﬁrst check whether
the spread is expected to be mean-reverted at t + 1, i.e. we see whether 0 < ˆb < 2.
If ˆb < 0 or ˆb ≥2, we decide not to trade and so we do not open a position at t. If
0 < ˆb < 2, we open a trading position according to the rule: buy a unit of A and
short-sell a unit of B, if ˆyt+1 −h > yt, and short-sell a unit of A and buy a unit
of B, if ˆyt+1 + h < yt. Here h > 0 is a margin that allows some uncertainty to
guarantee that the unknown yt+1 at time t falls in the range [ ˆyt+1 −h, ˆyt+1 + h].
For example, suppose that at time t, the spread is equal to yt = 20 and that we
project that at time t + 1 the spread prediction goes up to ˆyt+1 = 21. As there is
uncertainty around this prediction, it is equally likely that the true value of yt+1 be
23 (2 units higher than yt) or 19 (one unit lower than yt), each of which returns a
different trading rule (buy/sell or sell/buy); in particular the latter (yt+1 = 19 < yt)
can result in a loss, if we implement the rule yt > ˆyt+1. For this reason, introducing
h prevents this happening. In this simple example, if we operate with h as 10% of
ˆyt+1 or 2.1, then ˆyt+1 −h = 18.9 < 20 = yt and so we will not open the position:
buy A and short-sell B. Likewise ˆyt+1 + h = 22.1 > 20 = yt and so we do not
open the position: short-sell A and buy B. In such a case, we make the decision not
to open a trading position at t, because the predicted ˆyt+1 does not create a safe
margin in the spread to allow for a probable proﬁt. We can see that the lower the
value of h, the more transactions we operate (we are more exposed to risk), and the
higher the value of h, the less transactions we operate (we are more conservative).
For more information on this strategy, the reader is referred to Triantafyllopoulos
and Han (2013); other strategy procedures are described in Nolan and Lang (2015,
Chapter 6).
7.5.3
Time-Varying Autoregressive Models
for Trading-Spreads
The above model can be extended in various ways. First, the deﬁnitions of the spread
(7.68) may not serve a number of practical situations. For example, the data set in
Fig. 7.15 shows historical values of SouthWest Airlines and Exxon Mobile share
prices. We notice that the spread yt = pA
t −pB
t exhibits high variability, which can

7.5
Pairs Trading
391
SoutWest Airlines and Exxon Mobil prices
SoutWest Airlines
Exxon Mobil
Jan96
0
10
20
30
40
50
60
70
–40
–20
0
Jan96 Jan98 Jan00 Jan02 Jan04 Jan06
Jan98
Jan00
Jan02
Jan04
Jan06
Fig. 7.15 SouthWest Airlines and Exxon Mobile share prices
cause problems in modelling with a Gaussian state space model described above.
This may be overcome by considering the log-spread yt as yt = log pA
t −log pB
t ,
which is the logarithm of the ratio of the prices of the two assets. However, still
the state space model (7.69)–(7.71) might be inadequate if the spread exhibits clear
lack of mean-reversion as well as mean-reversion periods, as in Fig. 7.15. This is
caused ﬁrstly by the constancy of the parameters a and b and secondly because the
spread is too complex to be described by a simple state space model for all times
t. In Triantafyllopoulos and Montana (2011), this issue is overcome by considering
the spread as
yt = pA
t −α −βpB
t ,
(7.72)
where α and β are the intercept and the slope of the linear model if we regress
pA
t
against pB
t ; here, A is the SouthWest Airlines and B the Exxon Mobile.
Cointegration is the term used when a linear combination of two non-stationary
time series (here pA
t and pB
t ) is weakly stationary. In its most simple form, a linear
model is ﬁtted as
pA
t = α + βpB
t + yt
(7.73)
and pA
t and pB
t are cointegrated, if the residual yt is a weakly stationary time series.
In the classical analysis of cointegration, a hypothesis test is set to test whether {yt}
is weakly stationary or not. For example, the Dickey–Fuller distribution (Dickey &
Fuller, 1979) is used to construct the cointegration test following Engle and Granger
(1987) and Phillips and Perron (1988). Since then there is a host of publications
related to cointegration; from a frequentist standpoint, we signal out the Johansen
test Johansen (1991), and from a Bayesian standpoint we signal out Strachan and
Inder (2004). In the context of pairs trading, the residual yt of the linear model

392
7
The State Space Model in Finance
in (7.73) is the spread of the two assets. Instead of testing whether {yt} is weakly
stationary, we aim to establish for which periods of time {yt} is mean-reverted and
this is achieved by ﬁtting the state space models (7.70)–(7.71) or the one described
below.
Coming back to Fig. 7.15, we observe that up to January 2004, the spread seems
to be stable (the two share prices appear to be parallel up to 2004). However,
after that point of time, SouthWest Airlines see their prices increase, while Exxon
Mobile share prices remain relatively stable. This is clearly depicted in the inset
plot, which shows the difference xA
t −xB
t ; we see that up to January 2004, spread
(7.68) ﬂuctuates around its equilibrium level, but after that date the spread decreases
dramatically. This observation suggests that mean-reversion is lost after January
2004, and hence we can speak of periods of mean-reversion. In the search of
detecting such periods, the parameters a and b in the state space model above (see
e.g. (7.69)) should be time-varying, hence able to capture the local performance of
the spread. Moving towards this direction, Triantafyllopoulos and Montana (2011)
consider the time-varying autoregressive model
yt = At + Btyt−1 + ϵt,
(7.74)
At = φ1At−1 + ζ1t,
Bt = φ2Bt−1 + ζ2t,
where φ1 and φ2 are the AR coefﬁcients, usually being assumed to satisfy |φi| < 1
so that At and Bt may be weakly stationary processes.
Setting βt = [At, Bt]⊤and ct = [1, yt−1]⊤, the model can be expressed in state
space form,
yt = c⊤
t βt + ϵt,
(7.75a)
βt = Fβt−1 + ζt,
(7.75b)
with F = diag(φ1, φ2) and error structure governed by the observation error ϵt ∼
N(0, σ 2
ϵ ) and the evolution error vector ζt = [ζ1t, ζ2t)′ ∼N(0, σ 2
ϵ Vt), for some
covariance matrix Vt = {Vij,t}i,j=1,2. It is assumed that the innovation series {ϵt}
and {ζt} are individually and mutually independent and they are also independent of
the initial state vector β0.
As noted earlier mean-reversion for model (7.69)–(7.71) is ensured if 0 < b < 2.
For model (7.75a)–(7.75b), the following theorem establishes conditions of mean-
reversion.
Theorem 7.1 If {yt} is generated from model (7.75a)–(7.75b), then, conditionally
on a realised sequence B1, . . . , Bt, {yt} is mean-reverting if one of the two
conditions applies:
(a) φ1 = φ2 = 1, Vt = O and |B0| < 1;
(b) |φ1| < 1 and |φ2| < 1, Vt is bounded and |Bt| < 1, for all t ≥t0 and for some
integer t0 > 0.

7.5
Pairs Trading
393
Before we prove this theorem we make some comments. If At = A and Bt = B,
which is achieved by setting φ1 = φ2 = 1 and Vt = O, model (7.75a)–(7.75b)
reduces to the standard AR(1) model and Theorem 7.1 reduces to the standard
stationarity condition |B| < 1 (Example 7.2). The theorem allows At = A to
be time-invariant and Bt to be time-varying; this is obtained if we set φ1 = 1,
V11,t = V12,t = 0, |φ2| < 1 and V22,t > 0 (similarly we can have At time-
varying and Bt = B to be time-invariant). Moreover, following the approach of
Elliott et al. (2005), estimates ˆBt of Bt can be used to check the mean-reversion or
| ˆBt| < 1, for all t > t0 for case (b) of Theorem 7.1. However, this fails to take into
account the uncertainty around the estimate of Bt and so in Triantafyllopoulos and
Montana (2011) it is proposed that posterior bounds of Bt are ﬁrst calculated and
are required to be less than one in absolute value. Hence this procedure allows for
online checking of mean-reversion.
Proof of Theorem 7.1 With φ1 = φ2 = 1 and Vt = O, the state space model
(7.75a) reduces to the AR model yt = A + Byt−1 + ϵt, where At = A and Bt = B
and it is trivial to verify that {yt} is mean-reverting if |B0| < 1, see also Example 7.2.
This completes (a).
Proceeding now to (b), from the AR model for At, we note that E(At) = 0. From
(7.75a), write yt recursively as
yt = At + Btyt−1 + ϵt = At + BtAt−1 + BtBt−1yt−2 + Btϵt−1 + ϵt = · · ·
= y1
t-
i=2
Bi +
t−3

j=0
j-
i=0
Bt−iAt−j−1 + At +
t−3

j=0
j-
i=0
Bt−iϵt−j−1 + ϵt.
We write B1:t = {B1, . . . , Bt}, for t = 1, . . ., n. Since {ϵt} is a white noise, we have
E(yt | B1:t) = y1
t-
i=2
Bi.
(7.76)
This is a convergent series if |Bt| < 1, for all t > t0, for some positive integer t0.
To see this ﬁrst write x(1)
t
= 5t
i=2 Bi, which is a decreasing series as |x(1)
t+1/x(1)
t
| =
|Bt+1| < 1. Also {x(1)
t
} is bounded as |x(1)
t
| = 5t
i=2 |Bi| < 1 and so {x(1)
t
} is
convergent.
For the variance of yt, we have
Var(yt | B1:t) = Var(At) +
t−3

j=0
j-
i=0
B2
t−iVar(At−j−1) +
t−3

j=0
j-
i=0
B2
t−iVar(ϵt−j−1)
+Var(ϵt) +
t−3

j=0
j-
i=0
Bt−iCov(At, At−j−1)

394
7
The State Space Model in Finance
≤σ 2
ϵ + σ 2
ϵ V11
1 −φ2
1
+

σ 2
ϵ V11
1 −φ2
1
+ σ 2
ϵ
 t−3

j=0
j-
i=0
B2
t−i
(7.77)
+ σ 2
ϵ V11
1 −φ2
1
t−3

j=0
φj+1
1
j-
i=0
Bt−i,
where it is used that
Var(At) ≤σ 2
ϵ V11
1 −φ2
1
and
Cov(At, At−j−1) ≤σ 2
ϵ V11
1 −φ2
1
,
for V11,t ≤V11, since from the hypothesis Vt is bounded, and so there exists some
V11 > 0 so that V11,t ≤V11.
Now we show that the series x(2)
t
=
t−3
j=0
5j
i=0 B2
t−i and x(3)
t
=
t−3
j=0 φj+1
1
5j
i=0 Bt−i are both convergent. For the former series we note that
given |Bt| < 1, we can ﬁnd some B so that |Bt| < |B| < 1, from which it follows
that
|x(2)
t
| ≤
t−3

j=0
j-
i=0
|Bt−i| ≤
t−3

j=0
j-
i=0
|B| =
t−3

j=0
|B|j+1,
which is proportional to a geometric series that converges for |B| < 1, and since
x(2)
t
is a positive series, it follows that {x(2)
t
} is convergent.
For the series {x(3)
t
}, we follow an analogous argument, i.e. for B satisfying
|Bt| < |B| < 1, we obtain
|x(3)
t
| ≤
t−3

j=0
|φ1B|j+1,
which shows that x(3)
t
is convergent as t−3
j=0 |φ1B|j+1 is a geometric series with
|φ1B| < 1 and x(3)
t
is a positive series.
With these convergence results in place, the convergence of Var(yt | B1:t) is
obvious. Given, B1, . . . , Bt, we have shown that the mean and the variance of {yt}
are convergent and so {yt} is mean-reverting.
⊓⊔
We ﬁt the state space model (7.75a)–(7.75b) to the SouthWest Airlines and
Exxon Mobile data set of Fig. 7.15. Spread (7.72) is computed at each point of
time t using the recursive least squares algorithm (see e.g. Sect. 3.1.2). For the
application of the state space model (7.75a)–(7.75b), we have used the SOP model
of Sect. 4.3, where matrix Vt is speciﬁed with two discount factors δ1 and δ2. After
some experimentation with log-likelihood optimisation, we have selected values

7.5
Pairs Trading
395
2002
2003
2004
2005
0.0
0.2
0.4
0.6
0.8
1.0
1.2
Posterior Estimation of |Bt|
Time
2002
2003
2004
2005
-6
-4
-2
0
2
4
6
8
XOM-LUV Spread
Time
Spread
Fig. 7.16 Exxon Mobile (XOM) and SouthWest Airlines (LUV) spread. The top panel shows
posterior mean (dashed line) and absolute credible bounds of Bt (dashed/dotted lines), and the
lower panel shows observed spread (solid line) and forecast mean (dashed line) with 95% forecast
interval (dotted/dashed lines)
φ1 = 0.1, φ2 = 0.99839, δ1 = 0.992 and δ2 = 0.995; details of this are provided in
Triantafyllopoulos and Montana (2011). Figure 7.16 plots absolute posterior means
together with 95% credible bounds of Bt (top panel) and one-step ahead forecast
mean and 95% forecast interval of the spread yt (lower panel); for illustration
purposes only the last 731 points of time are shown, covering the period of 1 January
2002 to 30 November 2004. The horizontal line on the top panel indicates the
threshold of one, to which | ˆBt| and its bound are compared. We can see that towards
the end of 2004, ˆBt exceeds the threshold, and hence the model detects lack of mean-
reversion at this point of time. This is depicted in the lower panel as the observed
spread is clearly out of the forecast interval in that period of time, suggesting that the
spread moves away from the forecast mean. The forecast performance is reasonable

396
7
The State Space Model in Finance
for up to January 2004 with most observed values of the spread lying within the
forecast interval.
7.6
Exercises
1. Consider the autoregressive model
yt = αyt−1 +
1
3 −α
	
yt−2 + ϵt,
where ϵt is a white noise process. Show that if −1/3 < α < 4/3, this model is
weakly stationary and causal.
2. Show that the autoregressive model
yt = 0.2yt−1 −0.5yt−2 + 0.4yt−3 + ϵt
is weakly stationary and causal model, where ϵt is a white noise process.
3. Consider a random variable X, which follows the gamma distribution with
parameters α and β, with density function
p(x) =
βα
(α)xα−1 exp(−βx),
where (α) is the gamma function with argument α.
a. Show that the density function of Y = log X is
p(y) =
βα
(α) exp

αy −β exp(y)

.
b. Show that the moment generating function of Y is
MY (z) = (α + z)
(α)βα .
c. Use (b) to verify that the mean and the variance of Y are
E(Y) = ψ(α) −log β
and
Var(Y) = dψ(α)
dα
,
where ψ(α) is the digamma function with argument α and dψ(α)/ dα is the
trigamma function with argument α.

7.6
Exercises
397
d. Use these results in the context of the stochastic volatility model of p. 357
(see also Eq. (7.27)) in order to show that
E(log ϵ2
t ) = −1.270363
and
Var(log ϵ2
t ) = π2
2 .
You may use the functions digamma and trigamma in R to evaluate the
digamma and the trigamma functions at speciﬁc arguments.
4. Consider the stochastic volatility model
yt = exp(ht/2)ϵt,
ϵt ∼N(0, 1),
ht −0.2 = 0.9(ht−1 −0.2) + ωt.
ωt ∼N(0, 1),
where ϵt is a white noise process, which is independent of ωt, for all t.
a. Write down the steps of the Bootstrap particle ﬁlter algorithm (see
Sect. 6.7.4) for this model.
b. Simulate 200 log-volatilities h1, . . . , h200 and 200 log-returns y1, . . . , y200
from this model.
c. Fit the Bootstrap ﬁlter algorithm and provide histograms of the approximate
posterior distribution of the log-volatilities at times t = 50, 100, 150, 200.
Plot one-step ahead forecast modes with 95% forecast intervals of yt against
the observed values of yt. Hence, comment on the performance of the
Bootstrap ﬁlter for this model.
5. Consider the stochastic volatility model of Exercise 4.
a. Apply the MCMC algorithm (7.3.3) to the simulated data of Exercise 4.
Assuming that μ = 0.2, φ = 0.9 and σ 2
ω = 1 were unknown, draw samples
of h(j)
t
, μ(j), φ(j) and σ 2(i)
ω
, for t = 1, . . . , 200; j = 1, . . . , 10,000.
b. Determine how h(j)
t
, μ(j), φ(j) and σ 2(j)
ω
are compared to the true values of
ht, μ = 0.2, φ = 0.9 and σ 2
ω = 1.
c. Compare the approximate posteriors at times t = 50, 100, 150, 200, and
hence provide a comparison between the MCMC algorithm and the Boot-
strap ﬁlter.
6. The data in the table below show closing prices (in US dollar) of IBM shares,
covering a period from 2 January 2002 to 28 March 2002.

398
7
The State Space Model in Finance
January
Closing price
February
Closing price
March
Closing price
02/01
121.5
01/02
108
01/03
103.02
03/01
123.66
04/02
106.8
04/03
105.9
04/01
125.6
05/02
106.3
05/03
105.67
07/01
124.05
06/02
106.63
06/03
106.3
08/01
124.7
07/02
103.91
07/03
103.71
09/01
124.49
08/02
104.99
08/03
105.09
10/01
122.14
11/02
107.38
11/03
105.24
11/01
120.31
12/02
106.57
12/03
108.5
14/01
118.05
13/02
108.07
13/03
107.18
15/01
118.85
14/02
107.89
. 14/03
106.6
16/01
117.4
15/02
102.89
15/03
106.79
17/01
119.9
19/02
101.3
18/03
106.35
18/01
114.25
20/02
99.31
20/03
105.5
22/01
110.5
21/02
96.38
21/03
106.78
23/01
107.9
22/02
98.45
22/03
105.6
24/01
108.72
25/02
98.3
25/03
103.56
25/01
109.28
26/02
97.15
26/03
102.9
28/01
108.15
27/02
97.83
27/03
103.39
29/01
103
28/02
98.12
28/03
104
30/01
105.55
31/01
107.89
a. Convert the data to log-returns and plot a histogram of the log-returns.
b. Fit the stochastic volatility model (7.26a)–(7.26b) using the MCMC algo-
rithm (7.3.3).
7. A collection of 2780 daily observations of returns of the Standards and Poors
500 Index is available in R by executing the commands:
> library(MASS)
> data("SP500")
> y <- SP500
a. Perform an exploratory data analysis of this data set. Produce summary
statistics and a histogram of this data set.
b. Fit the stochastic volatility model (7.26a)–(7.26b) using the MCMC algo-
rithm (7.3.3), and draw samples for the volatility exp(ht) and the hyperpa-
rameters μ, φ and σ 2
ω of this model.
8. The stochastic volatility model (7.26a)–(7.26b) assumes that the mean of the
returns yt is zero. The mean of the returns is expected to be very close to
zero, and in some ﬁnancial applications it may play an important role, e.g.
in asset allocation and portfolio optimisation. In many volatility models, the
mean is calculated using historical returns and subtracted from the returns as
necessary. Model (7.26a)–(7.26b) can be extended to allow for a drift in the

7.6
Exercises
399
mean. Consider the model
yt = mt + exp(ht/2)ϵt,
ϵt ∼N(0, 1),
(7.78)
mt = x⊤
t βt
and
βt = Fβt−1 + ζt,
(7.79)
ht −μ = φ(ht−1 −μ) + ωt,
ωt ∼N(0, σ 2
ω),
(7.80)
where mt, the mean of yt, follows a state space model, with design vector xt,
state βt, transition matrix F and innovation vector ζt. It may be assumed that ζt
is independent of ωt and ωt, for all t. We signal out three speciﬁcations for the
above state space model for mt:
a. mt = m is a historical mean of returns.
b. mt follows the autoregressive speciﬁcation
mt = γ0 +
p

i=0
γiyt−i,
where γ0 is an intercept and γ1, . . . , γp are AR coefﬁcients.
c. mt follows a time-varying autoregressive speciﬁcation
mt = γ0,t +
p

i=0
γityt−i,
where γit follows random walk evolution, or γit = γi,t−1 + ζit, for some
innovations ζit such that ζit is independent of ζjt, for i ̸= j and i, j =
1, . . . , p. We may further assume that ζit ∼N(0, Zi), for some variances
Zi.
For each of the speciﬁcations (a)–(c) above, propose an MCMC algorithm for
the estimation of mt, ht, μ, φ and σ 2
ω in model (7.78)–(7.80). This should extend
the hybrid MCMC algorithm 7.3.3.
9. Extend the stochastic volatility model (7.26a)–(7.26b) to the multivariate case
(Harvey et al., 1994, Section 3). Suppose you observe a vector of returns
yt = [y1t, . . . , ypt]⊤, where yit is the log-return of the i-th asset at time t.
The univariate model (7.26a)–(7.26b) can be extended by considering
yit = exp(hit/2)ϵit,
hit −μi = φi(hi,t−1 −μi) + ωit.
ωit ∼N(0, σ 2
ω,i),
where ωt = [ω1t, . . . , ωpt]⊤, ϵt = [ϵit, . . . , ϵpt]⊤. In this speciﬁcation ωit and
ωjt are independent, for i ̸= j, and ϵt follows a multivariate normal distribution
with zero mean vector and covariance matrix .

400
7
The State Space Model in Finance
a. Show that
Var(yit | hit) = exp(hit)σii
Cov(yit, yjt | hit, hjt) = exp(hit/2) exp(hjt/2)σij,
so that the correlation of yit and yjt is
Cor(yit, yjt | hit, hjt) =
σij
√σiiσjj
,
where σij is the (ij)-th element of the covariance matrix . Hence, this
model relates to the constant conditional correlation multivariate GARCH
model, introduced in Bollerslev (1990) and further discussed in Bauwens
et al. (2006).
b. Write down the steps of an MCMC algorithm similar to algorithm (7.3.3)
for the estimation of ht, μi, φi, σωi and .
10. Extend the state space model (7.70)–(7.71) for modelling the spread yt as
follows. Consider that the state process xt of (7.70) follows an autoregressive
model of order 2, deﬁned by
xt = φ0 + φ1yt−1 + φ2yt−2 + ωt,
(7.81)
where φ1 and φ2 are the AR coefﬁcients, φ0 is the intercept and ωt is a white
noise as deﬁned in (7.70). We shall assume that yt follows the observation
equation (7.71).
a. Cast model (7.81)–(7.71) in state space form. Deﬁne the state vector βt =
[1, xt, xt−1]⊤, and write the model in the form
yt = c⊤
t βt + ϵt
and
βt = Fβt−1 + ζt,
and hence determine the design vector ct, the transition matrix F and the
innovations vector ζt.
b. Suppose that for a set of observed spreads y1, . . . , yn, we have estimates of
βt and of F, the latter may depend on the parameters φi, for i = 0, 1, 2.
Explain how ˆF the estimate of F may be computed.
c. Using the results of Sect. 7.2.2, explain how ˆF may be used in order to
identify periods of mean-reversion, and hence determine tradable periods.
11. Historical daily closing prices of Pepsi Corporation Inc (PEP) and Coca-Cola
Company (KO) are available from the website of Yahoo Finance!:
https://uk.ﬁnance.yahoo.com (this is the UK website; for people outside the
UK, a Google search of ‘Yahoo Finance!’ will ﬁnd the correct website. In order
to download the data, visit the above website and search for the abbreviations
‘PEP’ and ‘KO’ and then look at historical data and set 5-year period on daily

7.6
Exercises
401
prices. This will download daily prices over a 5-year window for each company
separately. We recommend to work with closing prices, but other options are
available. The closing prices of the two companies should be brought together
on a single spreadsheet, from which one may obtain their spread. Follow the
above procedure to download closing prices of the two assets.
a. Compute the simple spread yt = pA
t −pB
t , where A and B denote the two
companies.
b. Compute the log-spread yl
t = log pA
t −log pB
t .
c. Compute the cointegration spread yc
t = pA
t −α −βpB
t , where α and β are
determined by recursive least squares estimation.
Perform an exploratory data analysis for each of (a)-(c) by providing summary
statistics and histograms of the spreads. Which spread do you think will be
more suitable to ﬁt the time-varying model of Sect. 7.5.3?
12. In the context of Exercise 11, ﬁt the state space model (7.75a)–(7.75b) using
the spread you have identiﬁed in Exercise 11 as more suitable. Identify tradable
periods, and provide the one-step ahead forecasts of the spread.
13. Consider two assets (1) and (2) and denote their prices at time t by p(1)
t
and
p(2)
t
, respectively. Deﬁne their spread as st = p(1)
t
−p(2)
t
, for t = 1, 2, . . ..
Consider the trading rule; if st > 0, then go long 2 and go short 1, if st < 0,
then go long 1 and go short 2 and if st = 0, then take no action.
a. Deﬁne the returns r(i)
t
= p(i)
t
−p(i)
t−1, for i = 1, 2. Deﬁne the spread on the
returns
s∗
t = r(1)
t
−r(2)
t
= st −st−1.
Show that the trading rule described above is equivalent to
•
If s∗
t + st−1 > 0, go short 1 / long 2.
•
If s∗
t + st−1 < 0, go long 1 / short 2.
•
If s∗
t + st−1 = 0, no action.
b. Consider now the log-returns
r(i)
t
= log p(i)
t
−log p(i)
t−1,
i = 1, 2,
and as before deﬁne the spread on the returns
s∗
t = r(1)
t
−r(2)
t
.
Show that the trading rule is now equivalent to
•
If s∗
t > log p(2)
t−1 −log p(1)
t−1, go short 1 / long 2.
•
If s∗
t < log p(2)
t−1 −log p(1)
t−1, go long 1 / short 2.
•
If s∗
t = log p(2)
t−1 −log p(1)
t−1, no action.

402
7
The State Space Model in Finance
c. The geometric returns are deﬁned as
r(i)
t
= p(i)
t
−p(i)
t−1
p(i)
t−1
= p(i)
t
p(i)
t−1
−1,
i = 1, 2.
Using again the return spread
s∗
t = r(1)
t
−r(2)
t
,
show that the trading rule is now equivalent to
•
if (s∗
t + 1 + r(2)
t
)(1 + r(2)
t
) >
p(1)
t−1
p(2)
t−1
, go short 1 / long 2.
•
if (s∗
t + 1 + r(2)
t
)(1 + r(2)
t
) <
p(1)
t−1
p(2)
t−1
, go long 1 / short 2.
•
if (s∗
t + 1 + r(2)
t
)(1 + r(2)
t
) =
p(1)
t−1
p(2)
t−1
, no action.

Chapter 8
Dynamic Systems and Control
State space models have played a signiﬁcant role in the development of dynamic
systems. Dynamic systems are usually driven by a system of differential equations
and the state space framework has been used to represent and identify a dynamic
system. Indeed the state space representation of a dynamic system reduces higher
order linear differential equations to a system of ﬁrst-order differential equations,
with which solution is simple. Central to the study of a dynamic system is the
notion of stability, which effectively studies the dynamic behaviour of the system
for small perturbation of states and inputs of this system. The compact form of state
space systems is used to study the stability of dynamic systems. More importantly
checking the stability of linear systems is reduced to obtaining the eigenstructure of
components of this system. For non-linear systems indirect and direct Lyapunov
criteria are used to study the stability of these systems. In 1960 R. E. Kalman
published his seminal paper on the Kalman ﬁlter, (Kalman, 1960) and in 1961
R. E. Kalman and R. S. Bucy published a continuous-time version of the ﬁlter,
known as Kalman–Bucy ﬁlter, (Kalman & Bucy, 1961). The Kalman–Bucy ﬁlter
can be regarded as a Wiener ﬁlter with time-varying parameters, but it beneﬁts
by not making the assumption of stationarity. Hence the Kalman–Bucy ﬁlter has
provided a good estimation approach to describe continuous-time systems, which
might be non-stationary. More importantly the ﬁlter is able to describe complex
systems which are subject to uncertainty and noise, see e.g. Schweppe (1973) and
Yedavalli (2016).
We begin by describing dynamic systems in Sect. 8.1. For linear systems driven
by linear differential equations, their solution can be obtained by using Laplace
transforms as described in Sect. 8.1.3. Section 8.2 introduces the state of a system
and develops state representation of a system. Focusing on linear systems central
to this is the solution of the state differential equation in Sect. 8.2.3. We discuss
discrete-time and continuous-time systems and we discuss how a continuous-time
system can be discretised. System stability is discussed in Sect. 8.3. Stability of
linear systems is discussed via the eigenstructure of the state matrix and stability
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2021
K. Triantafyllopoulos, Bayesian Inference of State Space Models, Springer Texts
in Statistics, https://doi.org/10.1007/978-3-030-76124-0_8
403

404
8
Dynamic Systems and Control
of non-linear systems is discussed via Lyapunov’s criteria (indirect and direct
methods). The Kalman–Bucy ﬁlter is discussed in Sect. 8.4. We start with the
discrete-time Kalman ﬁlter (also discussed throughout in this book) and then we
move on to describe the continuous-time Kalman–Bucy ﬁlter. The convergence
of the error covariance matrix and the resulting steady state of continuous-time
systems are discussed in Sect. 8.4.3. Section 8.4.4 considers an extension of the
Kalman–Bucy ﬁlter, known as extended Kalman ﬁlter which aims to apply the ﬁlter
to non-linear systems. Very closely connected to the description of dynamic systems
is the concept of control. Section 8.5 discusses feedback control and in particular
the popular proportional, integral, derivative (PID) controller. Finally, Sect. 8.5.2
considers a case study of control of a twin rotor experimental rig system.
8.1
Dynamic Systems
8.1.1
Basic Principles
A system is a collection of components, which interact with each other in order to
perform some purposeful operation. This operation is known as the behaviour of the
system. A system is usually evolving over time, hence it is sometimes referred to as
dynamic system. In most practical situations the components of the system consist
of m input variables, denoted by xi(t) (t ∈T1) and d output variables yj(t) (t ∈T2),
for i = 1, . . ., m and j = 1, . . . , d and sets T1 and T2 subsets of the real ﬁeld. In
many situation we shall have T1 = T2. If T1 and T2 are discrete sets, the system is
referred to as discrete-time system; if the input and output signals are continuous-
time signals, then the system is known as continuous-time system. In this chapter
we shall discuss both discrete-time and continuous-time modelling together, unless
stated otherwise. We shall write x(t) = [x1(t), . . . , xm(t)]⊤the input vector for
t ∈T1 and y(t) = [y1(t), . . . , yp(t)]⊤the output vector, for t ∈T2. The operation
or transformation of the system is a mathematical mapping F(·), which transforms
x(t) to y(t), i.e.
y(t) = F[x(t), t ∈T1](t),
t ∈T2,
hence it is a mapping from the m-dimensional vector space of inputs to the p-
dimensional vector space of outputs. For further information on dynamic systems
the reader is referred to Ogata (1970); linear systems are covered in detail in Zadeh
and Desoer (1979).
Example 8.1 (Position of a Moving Vehicle) Consider a moving vehicle, with speed
v(t) at time t, for some time t ∈T1 = [t0, t1], where t0 is a starting time and t1 is
the ﬁnish-time. In this interval of time, the vehicle’s position y(t) is
y(t) =
" t
t0
v(τ) dτ + y(t0),
t0 < t < t1,

8.1
Dynamic Systems
405
where y(t0) is the initial position of the vehicle. This is a continuous-time dynamic
system with input v(t), output y(t) and transformation
F[v(t),
t ∈T1](t) =
" t
t0
v(τ) dτ + y(t0).
Given the input function v(t) and the initial position y(t0), calculation of the above
integral can provide the output function y(t).
8.1.2
Linear Systems
As it is evident from Example 8.1 the transformation operator F(·) plays an
important role in the behaviour of a system. A wide class of systems, known as
Linear Systems are described below.
A system is said to be linear on T2 if for all t ∈T2 it is
F[ax](t) = aF[x](t)
and
F[x1 + x2](x) = F[x1](t) + F[x2](t),
for inputs x1 and x2 and for a constant a.
It is trivial to see that with y(t0) = 0, the system of Example 8.1 is linear.
However, for y(t0) ̸= 0, the system is not linear.
The following theorem provides an important property of linear systems. First
we introduce the notion of the impulse response of a system. The impulse signal or
impulse response is the output of the system, if a certain input pulse is applied. The
impulse response provides the reaction of the system for a short-pulse input. The
impulse response h(t, t0) is the value of the output, for an input equal to the Dirac
delta function δ(t −t0) (see Sect. 6.7.2), for a discrete-time system the Dirac delta is
replaced by the Kronecker delta, deﬁned as δ(t, t0) = 1, for t = t0 and δ(t, t0) = 0,
for t ̸= t0.
Theorem 8.1 A single-input, single-output system is linear if and only if for any
input x(t) the output y(t) has the following expressions
y(t) =
"
T1
x(τ)h(t, τ) dτ,
for continuous-time system,
(8.1)
y(t) =

τk∈T1
x(τk)h(t, τk),
for discrete-time system,
(8.2)
where h(t, t0) is the impulse response function deﬁned above and F(·) in the
continuous-time system is assumed to be a continuous function in x.

406
8
Dynamic Systems and Control
Proof The proof mimics the proof of Minkler and Minkler (1993, Chapter 3).
Following these authors we shall give the proof for the continuous-time case. The
discrete-time case follows readily by replacing integration by ﬁnite sums.
First we shall prove sufﬁciency, so that if Eq. (8.1) holds true (continuous-time
case), then the system is linear. This is trivial to show by the deﬁnition of the linear
system above and basic integration properties, and is left to the reader as an exercise.
Moving on, we shall prove necessity, so that if the system is linear, then it has
the representation (8.1) (continuous-time case). Since the system is linear we have
F[x(t0)δ(τ −t0)](t) = x(t0)F[δ(τ −t0)](t) = x(t0)h(t, t0),
using the deﬁnition of the impulse response. It then follows that
"
T1
x(t0)h(t, t0) dt0 =
"
T1
F[x(t0)δ(τ −t0)](t) dt0
=
lim
max
i
|t0,i|→0

i
F[x(t0,i)δ(τ −t0,i), τ ∈T1](t)t0,i
= F
⎡
⎣
lim
max
i
|t0,i|→0

i
x(t0,i)δ(τ −t0,i)t0,i, τ ∈T1
⎤
⎦(t)
= F

"
T1
x(t0)δ(t −t0) dt0, τ ∈T1

(t)
= F[x(τ), τ ∈T1](t) = y(t).
⊓⊔
The theorem above is presented for a single input x(t) and a single output y(t). The
theorem holds true in the vector case when x(t) is a m × 1 vector of inputs and y(t)
a d × 1 vector of outputs; the modiﬁcations are relatively straightforward and for a
detailed discussion the reader is referred to Minkler and Minkler (1993, pp. 74–75).
Below we discuss two classes of dynamic systems, namely incrementally linear and
time-invariant linear systems.
We have noted above that Example 8.1 is a linear system if the starting position
of the vehicle is y(t0) = 0. The deﬁnition of linear systems above does not allow for
F being a linear function of the form F[ax + b](t), for b ̸= 0. A dynamic system,
with F(·), which satisﬁes
F[ax + b](t) = aF[x](t) + b
and
F[x1 + x2](x) = F[x1](t) + F[x2](t),
for any inputs x1, x2 ∈T1 and any constants a, b, is known as incrementally linear
system. In order to explain the name of this deﬁnition, consider an incrementally
linear system with F[ax + b](t) = aF[x](t) + b. We can decompose the output
signal y(t) = F[x(t), t ∈T1](t), as y(t) = z(t) + b, where z(t) is an output

8.1
Dynamic Systems
407
with transformation operator F′[ax(t), t ∈T1](t) = aF′[x(t), t ∈T1](t), for
t ∈T2. Hence y(t) is equal to the output from a linear system plus the constant
b, hence the name incrementally linear. We can see that the system of Example 8.1
is incrementally linear as we can see that b = y(t0). Many of the properties of linear
systems are shared by incrementally linear systems. For example, Theorem 8.1
can be extended to accommodate an incrementally linear system. In this case
for a single-input single-output system, Eq. (8.1) is replaced by y(t) = g(t) +
*
T1 x(τ)h(t, τ) dτ (continuous-time case), where g(t) is a function reﬂecting on the
constant b of the system. A similar equation applies for the case of discrete-time
systems and as in liner systems these are extended to accommodate systems with
vector input and vector output. Because incrementally linear systems are met in
practice more often than linear systems and they still share many properties, some
authors use the term linear system to actually mean incrementally linear system and
we shall adopt this convention in this chapter.
We complete this section by brieﬂy discussing time-invariant systems. A system,
with transformation operator F[x(t), t ∈T1](t) is said to be time-invariant (or
stationary) if y(t) = F[x(t), t ∈T1](t) is equal to y(t −t0) = F[x(t −t0), t −t0 ∈
T1](t), for any t0 < t. In other words, the output signal y(t) is time-invariant
and is determined by y(t0) = F[x(t0)](t0). In a time-invariant system we have
F[δ(τ −t0), τ −t0 ∈T1](t) = h(t −t0) = h(t, t0), the impulse response of the
system. From Theorem 8.1 the system is linear if and only if
y(t) =
"
T1
x(τ)h(t −τ) dτ,
for continuous-time system,
y(t) =

τk∈T1
x(τk)h(t −τk),
for discrete-time system.
8.1.3
Laplace Transform
The transformation mapping F(·) of a dynamic system relates the input of the
system to the output of the system. This mapping is usually described by a
differential or integral equation (for a continuous-time system) or by a difference
equation (for a discrete-time system); see e.g. various examples of Robinson (2012).
In Example 8.1 at time t the position of the vehicle y(t) is given by the integral of the
velocity of the vehicle plus the initial position y(0). Hence, in order to determine the
position y(t) the above integral must be computed or approximated. In general, once
F is determined, a system engineer usually desires to solve a differential equation
in order to answer the main questions of the system. These questions may involve
to determine the stability of the system over time and provide values of the output
y(t) for small changes of the values of the input vector x(t). For linear systems, the
differential equation(s) may be solved by employing the Laplace transform (time
domain) or the discrete Fourier transform (frequency domain); for more information

408
8
Dynamic Systems and Control
the reader is referred to Ogata (1970), Oppenheim and Willsky (1983) and Robinson
(2012). Below we describe the method of Laplace transforms and we show how it
can be used to solve linear differential equations.
Given a continuous function f (t), for t ≥0, the Laplace transform of f (t) is a
function F(s) with domain the complex plain, deﬁned by
F(s) = L[f ](s) =
" ∞
0
f (t)e−st dt,
s ∈C.
(8.3)
Some authors call this the one-sided Laplace transform, deﬁned in [0, ∞) and the
(two-sided) Laplace transform, if the limits in the integral are −∞and +∞. In this
section we shall consider functions deﬁned for t ≥0 and we shall call (8.3) as the
Laplace transform.
Function f (t) is said to be the inverse Laplace transform of F(s) and can be
deﬁned by the integral
f (t) =
1
2πi
lim
N→∞
" γ +iN
γ −iN
F(s)est ds,
with the integration is done along Re(s) = γ (the real part of s) in the complex
plain. More details about the deﬁnition and conditions of the convergence of these
integrals are given in Dyke (1999).
Some basic properties of the Laplace transform are given below. For the functions
below it is implicitly assumed that their domain is [0, ∞).
1. Linearity. If f (t) and g(t) are functions, and a, b are any real numbers, then
L[af + bg](s) = aL[f ](s) + bL[g](s).
2. Differentiation. If L[f ](s) and L[f ′](s) exist, for some function f (t), then
L[f ′](s) = sL[f ](s) −f (0).
3. Integration. If f (t) is a continuous function, then
L

" t
0
f (τ) dτ

= 1
s L[f ](s).
4. Convolution. Let f1(t), f2(t) be non-negative valued functions, with convolution
g(t) = (f1(t) ∗f2(t)) =
" ∞
0
f1(τ)f2(t −τ) dτ =
" ∞
0
f1(t −τ)f2(τ). dτ.
Then, the Laplace transform of g(t) is equal to F1(s)F2(s). By deﬁnition (8.3) it
follows that g(t) is the inverse Laplace transform of F1(s)F2(s).

8.1
Dynamic Systems
409
Consider now the linear system generated by the differential equation
dny
dtn + an−1
dn−1y
dtn−1 + · · · + a1
dy
dt + a0y = bm
dmu
dtm + · · · + du
dt + b0u,
(8.4)
with
initial
conditions
y(0), y′(0), . . . , y(n−1)(0),
u(0), u′(0), . . . , u(m−1)(0),
where y = y(t) is the output function, u = u(t) is a known input function,
ai, bj are real numbers (i = 1, . . . , n; j = 1, . . ., m) and m ≤n.
This differential equation can be solved by taking Laplace transforms in (8.4)
and using property (2). Indeed applying (2) repeatedly we have
L

dkf
dtk

(s) = skL[f ](s) −sk−1f (0) −sk−2f ′(0) −· · · −f (k−1)(0).
Gathering terms for all values of k = 1, 2, . . . , n we obtain Y(s) the Laplace
transform of y as a function of U(s) the Laplace transform of u as
p(s)Y(s) −r(s) = q(s)U(s) −ℓ(s),
(8.5)
where p(s), q(s) are polynomial functions on s, deﬁned as
p(s) = a0 + a1s + · · · + an−1sn−1 + sn,
q(s) = b0 + b1s + · · · + bmsm
and the functions r(s), ℓ(s) are
r(s) =
n−1

i=0
n

k=i+1
aksk−1−iy(i)(0),
an = 1
ℓ(s) =
m−1
i=0
m
k=i+1 bksk−1−isk−1−iu(i)(0),
m ≥1
0,
m = 0
Solving (8.5) for Y(s) we obtain the Laplace transform of y as
Y(s) = r(s) −ℓ(s)
p(s)
+ q(s)
p(s)U(s).
(8.6)
The ﬁrst fraction of the right hand side of (8.6) is a proper rational function, which
depends only on initial conditions. The second term is the convolution of h(t) and
u(t), where h(t) is the inverse Laplace transformation of q(s)/p(s) and u(t) is the
inverse Laplace transformation of U(s).

410
8
Dynamic Systems and Control
Let g(t) be the inverse Laplace transform of [r(s)−ℓ(s)]/p(s), then the solution
of (8.4) can be written as
y(t) = g(t) +
" ∞
0
h(τ)u(t −τ) dτ.
This shows that (8.4) is an incrementally linear system, with impulse response
function h(t) given by
h(t) = L−1

 q(s)
p(s)

.
The Laplace transform of h(t)
H(s) = q(s)
p(s)
is called the system transfer function of the (incrementally) linear system (8.4).
Using these results it follows that the solution of the differential equation (8.4)
involves computation of Laplace transforms. Laplace transforms of some useful
functions are tabulated, see e.g. Minkler and Minkler (1993, Chapter 4). See
Exercise 1 for the calculation of the Laplace transform of two useful functions.
Example 8.2 (Hookean Spring Force Dynamics) Consider the Hookean spring
force example of Sect. 1.3.4, describing the motion of an object, which is attached
to a wall on a spring. The position of the object y(t) at time t follows the differential
equation
m d2y(t)
dt2
+ k1
dy(t)
dt
+ k2y(t) = u(t),
(8.7)
where dy(t)/dt is the velocity of the object at t, u(t) is an applied force at t and
the constants k1, k2 are the viscous friction coefﬁcient and the spring constant,
respectively. The system is shown below in Fig. 8.1.
Fig. 8.1 Spring single-mass
system, including a spring
and damping
m
u

8.2
State Space Representation of Dynamic Systems
411
Let Y(s) and U(s) be the Laplace transforms of (8.7). Suppose that the initial
conditions are
dy(t)
dt
2222
t=0
= y(0) = u(0) = 0.
(8.8)
The Laplace transform of (8.7) is
Y(s) = q(s)
p(s)U(s) =
1
ms2 + k1s + k2
U(s),
since r(s) −ℓ(s) = 0 from the initial conditions. Thus, the system transfer function
is
H(s) =
1
ms2 + k1s + k2
and g(t) = 0 (again from the initial conditions).
If we set in (8.7) m = 1, k1 = 2, k2 = 1 and u(t) = e−t, then we have U(s) =
(s + 1)−1 and H(s) = (s2 + 2s + 1)−1 = (s + 1)−2. Hence the Laplace transform
of y is
Y(s) = H(s)U(s) =
1
(s + 1)3 .
From Exercise 1 we see that the inverse Laplace transform of Y(s) is
y(t) = 1
2e−tt2,
which is the solution of (8.7) under the initial conditions (8.8).
8.2
State Space Representation of Dynamic Systems
8.2.1
State Variables and State of a System
Cambridge dictionary deﬁnes state as ‘a condition or way of being that exists at a
particular time’. A state variable of a dynamic system is a variable of the system,
used to describe the mathematical state of a dynamic system. According to Minkler
and Minkler (1993) in dynamic systems a state of a system is the smallest collection
of variables so that their knowledge at time t = t0 together with knowledge of
input variables at all times t ≥t0 completely determine the system for any t ≥t0,
assuming no external force is applied to the system.

412
8
Dynamic Systems and Control
Example 8.3 (Hookean Spring Force Revisited) Consider the Hookean spring force
example 8.2 above, where the position of the object y(t) is generated by the
differential equation (8.7). The state of this system x(t) can be represented by the
vector comprising y(t) and u(t), or
x(t) =

y(t)
u(t)

,
so that knowledge of x(t), for t ≥t0 determines the system.
8.2.2
Continuous-Time State Space Model
In general, in continuous-time systems, we shall write x(t) the state vector, where
x(t) implicitly depends on x0 = x(t0). In discrete-time systems we shall write
xk, where again xk depends implicitly on xk0. The state space representation of a
dynamic system is a set of two equations involving states: in the system state the
ﬁrst derivative ˙x of the state vector x is given as a function of x, input vector u and
time t, so that
˙x = f (x, u, t),
(8.9)
for some function f (·) and x = x(t) is implicit. The second equations, known as
observation equation, links observations y = y(t) to the state vector x
y = g(x, u, t),
(8.10)
where g(·) is a suitable function. These functions may incorporate innovations, as
discussed below for the linear state space model.
Equations (8.9)–(8.10) deﬁne a state space model, which can represent or
describe a dynamic system. It is implicitly understood that u = u(t) is known for all
t ≥t0 and that x0 = x(t0) is known at time t = t0. Usually it is required to solve the
differential equation (8.9) for x(t). We shall denote by φ(t, x0) the general solution
of (8.9), which is a function of time t and also depends on the initial condition
x0 = x(0); in Sect. 8.2.3 we provide this solution for linear systems.
Linear systems are represented by linear state space models, so that the functions
f (·) and g(·) are linear functions. In particular the following observation and system
equations deﬁne a linear state space model or representation of a linear system
˙x(t) = Fx(t) + Gu(t) + ζ(t)
(8.11a)
y(t) = Hx(t) + ϵ(t),
(8.11b)

8.2
State Space Representation of Dynamic Systems
413
where ζ(t) and ϵ(t) are random innovations. In a deterministic system ζ(t) =
ϵ(t) = 0, with probability one. In practical situations these innovations are needed
to cater for observations and states exhibiting uncertainty. In the state space model
(8.11a)–(8.11b) the matrices F, G and H are time-invariant and in this case the
model is known as time-invariant linear state space model; if at least one of these
matrices are time-dependent the model is called time-varying state linear space
model. For most of what follows we shall work with time-invariant linear state
space models. Note that if the output y(t) is a scalar, then H = H is a row vector.
Likewise, if the input u is scalar, then G = G is a column vector. We shall treat
these components as matrices to cover generality and hence use boldface, but the
reader should remember that some may be vectors.
Example 8.4 (Hookean Spring Force Dynamics) In the context of Example 8.3
write the state vector x(t) as
x(t) =

 x1(t)
x2(t)

with x1(t) = y(t) (the position of the object at time t) and x2(t) = ˙y(t) = ˙x1(t).
From the differential equation (8.7) we have
˙x(t) =

 ˙x1(t)
˙x2(t)

=

 0
1
−k1
m −k2
m
 
x1(t)
x2(t)

+

 0
1
m

u(t)
= Fx(t) + Gu(t),
(8.12)
where ˙x2(t) = ¨x1(t) = ¨y(t).
Also
y(t) = x1(t) = [1, 0]

x1(t)
x2(t)

= Hx(t).
(8.13)
Equations (8.12)–(8.13) deﬁne an invariant linear state space model.
Example 8.5 Consider the dynamic system, which is described by the differential
equation
d3y
d t3 −4d2y
d t2 + dy
d t + 2y = u1 −2u2,
(8.14)
where the time t is implicit in all functions. In order to write this model in state
space form we deﬁne y = x1, ˙y = x2, ¨y = x3 and ...y = ˙x3. From this and the
differential equation (8.14) we obtain
˙x3 = 4 ˙x2 −˙x1 −2x1 + u1 −2u2 = 4x3 −x2 −2x1 + u1 −2u2.

414
8
Dynamic Systems and Control
Hence the system equation is
˙x =
⎡
⎣
˙x1
˙x2
˙x3
⎤
⎦=
⎡
⎣
0
1 0
0
0 1
−2 −1 4
⎤
⎦
⎡
⎣
x1
x2
x3
⎤
⎦+
⎡
⎣
0 0
0 0
1 −2
⎤
⎦

 u1
u2

= Fx + Gu
and
y = x1 = [1, 0, 0]
⎡
⎣
x1
x2
x3
⎤
⎦= Hx.
In general, consider a linear system with input u = u(t) and output y = y(t) is
generated by the differential equation
dny
d tn + a1
dn−1y
d tn−1 + · · · + an−1
dy
d t + any = u,
(8.15)
where ai are real-valued coefﬁcients, i = 1, 2, . . . , n. A state space representation
of this system can be obtained if we deﬁne the state vector
x =
⎡
⎢⎢⎢⎣
x1
x2
...
xn
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
y
y(1)
...
y(n−1)
⎤
⎥⎥⎥⎦,
where y(i) denotes the i-th derivative of the function y (i = 1, 2, . . . , n). With this
deﬁnition in place, the system equation is
˙x =
⎡
⎢⎢⎢⎣
x1
x2
...
xn
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
0
1
0
· · ·
0
0
0
1
· · ·
0
...
...
...
...
...
−an −an−1 −an−2 · · · −a1
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎣
x1
x2
...
xn
⎤
⎥⎥⎥⎦+
⎡
⎢⎢⎢⎣
0
0
...
1
⎤
⎥⎥⎥⎦u
= Fx + Gu
(8.16)
and the measurement or observation equation is
y = [1, 0, . . ., 0]
⎡
⎢⎢⎢⎣
x1
x2
...
xn
⎤
⎥⎥⎥⎦= Hx.
(8.17)

8.2
State Space Representation of Dynamic Systems
415
m1
m2
k2
k1
u
y1
y2
Fig. 8.2 Double-object spring. The two objects are connected with a spring, while the ﬁrst object
is attached to the wall with a damper
Equations (8.16)–(8.17) deﬁne the state space representation of the linear system
described by the differential equation (8.15). Note that matrix F is a companion
matrix, which is discussed in some detail in Sect. 4.2.2.
Example 8.6 (Two Objects Connected with a Spring and Damper) Consider two
objects connected via a spring, where the ﬁrst object is connected via a damp on the
wall (see Fig. 8.2). Object 1 (with mass m1) is connected to the wall via a damper,
with damping coefﬁcient k1. On the other end Object 1 is attached to a spring with
coefﬁcient k2, which other end is connected to Object 2 (with mass m2). A force
u(t) is applied on Object 2 and the output of this system is the positions y1(t) and
y2(t) of the two objects.
This system can be described by the system of differential equations
m1
d2y1(t)
dt2
+ k1
dy1(t)
dt
+ k2[y1(t) −y2(t)] = 0
m2
d2y2(t)
dt2
+ k2[y2(t) −y1(t)] = u(t).
This can be written as
¨y1 = −k1
m1
˙y −k2
m1
y1 + k2
m1
y2,
¨y2 = −k2
m2
y2 + k2
m2
y1 + u
m2
.
If we deﬁne the state vector
x =
⎡
⎢⎢⎣
˙y1
y1
˙y2
y2
⎤
⎥⎥⎦,

416
8
Dynamic Systems and Control
then the state space representation of this system is
˙x =
⎡
⎢⎢⎣
¨y1
˙y1
¨y2
˙y2
⎤
⎥⎥⎦=
⎡
⎢⎢⎢⎣
−k1
m1 −k2
m1 0
k2
m1
1
0
0
0
0
k2
m2
0 −k2
m2
0
0
1
0
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎣
˙y1
y1
˙y2
y2
⎤
⎥⎥⎦+
⎡
⎢⎢⎢⎣
0
0
1
m2
0
⎤
⎥⎥⎥⎦u
= Fx + Gu
(8.18)
and
y =

 0 1 0 0
0 0 0 1

⎡
⎢⎢⎣
˙y1
y1
˙y2
y2
⎤
⎥⎥⎦= Hx.
(8.19)
8.2.3
Solution of the State Differential Equation
In this section we give the solution of the state differential equation ˙x(t) = Fx(t) +
Gu(t) + ζ(t) of the time-invariant state space model (8.11a)–(8.11b).
Theorem 8.2 Consider the time-invariant state space model (8.11a)–(8.11b) with
the initial condition x(t0), for some t0. The solution of the state differential equation
(8.11a) is given by
x(t) = exp[F(t −t0)]x(t0) +
" t
t0
exp[F(t −τ)][Gu(τ) + ζ(τ)] dτ.
(8.20)
Proof The proof is by direct differentiation with respect to t. With the matrix
exponential of a square matrix A, deﬁned by exp(A) = ∞
n=0(1/n!)An, we obtain
˙x(t) = F exp[F(t −t0)]x(t0) + d
dt exp(Ft)
" t
t0
exp(−Fτ)C(τ) dτ
= F
(
exp[F(t −t0)] +
" t
t0
exp[F(t −τ)]C(τ) dτ
)
+ C(t)
= Fx(t) + C(τ),
where C(t) = Gu(t) + ζ(t).
⊓⊔
Some comments are in order. The matrix (t, t0) = exp[F(t −t0)] is called state
transition matrix and it satisﬁes ˙(t, t0) = F(t, t0) and (t0, t0) = I. With this in

8.2
State Space Representation of Dynamic Systems
417
place the solution x(t) of (8.20) can be written as
x(t) = (t, t0)x(t0) +
" t
t0
(t, τ)[Gu(τ) + ζ(τ)] dτ.
(8.21)
Under some conditions (8.21) is the solution of the time-varying state differential
equation (when F(t) and G(t) are time-varying matrices) where now G is replaced
by G(τ) and (t, t0) is a suitable matrix satisfying certain conditions; for details
the reader is referred to Minkler and Minkler (1993, Chapter 4).
As was earlier mentioned we can ﬁnd the solution the differential equation
driving the dynamics of a system using the Laplace or Fourier transforms. The
appeal of Theorem 8.2 is that it can provide the solution of high dimensional linear
systems or systems driven by high-order differential equations.
8.2.4
Discrete-Time State Space Model
The above discussed can be applied to discrete-time dynamic systems. First we shall
deﬁne the discrete-time state space representation of a system and then we will
provide the version of Theorem 8.2 for discrete-time.
Consider an equally spaced partition of an interval of the real line [t0, tN],
consisting of time points t0, t1, . . . , tk, . . . , tN. There are N + 1 points in total,
with equal length t = tk+1 −tk, for k = 0, 1, . . ., N −1. This implies that
tk+1 = (k + 1)t. The discrete-time equivalent to the continuous-time state space
model (8.9)–(8.10) is
x[(k + 1)t] = f (x[kt], u[kt]),
y[kt] = g(x[kt], u[kt]),
for suitable functions f (·) and g(·). It is also understood that the initial state x(t0)
is known.
A linear system may be represented by a discrete-time and time-invariant linear
state space model
x[(k + 1)t] = Fx(kt) + Gu(kt) + ζk,
(8.22a)
y(kt) = Hx(kt) + ϵk,
(8.22b)
where matrices F, G and H are time-varying and ζk, ϵt are innovations. If some of F,
G or H are time-varying the model is called time-varying linear state space model.
Here, the innovations are assumed to be white noise and independent of each other.
The initial state x(t0) is assumed to be known. The model speciﬁcation is completed
by specifying the error distributions of ζk and ϵk; we shall discuss these in Sect. 8.4.1
below.

418
8
Dynamic Systems and Control
State space model (8.22a)–(8.22b) can be used to approximate the continuous-
time model (8.11a)–(8.11b). Consider the partition of [t0, tN] considered above and
take tk+1 = (k + 1)t. From solution (8.21) for x(t) evaluated at t = tk
x[(k + 1)t] = [(k + 1)t, k]x(kt) +
" (k+1)t
kt
[(k + 1)t, τ][Gu(τ) + ζ(τ)] dτ.
(8.23)
We assume that u(τ) changes slowly with respect to t; this can be supported by
considering t short enough. Hence, we assume u(τ) ≈u(k), for kt ≤τ ≤
(k + 1)t. Combining this with (8.23) we obtain
x[(k + 1)t] = F∗x(kt) + G∗u(kt) + ζk,
(8.24)
where
F∗= [(k + 1)t, kt]
G∗=
" (k+1)t
kt
[(k + 1)t, τ]G dτ,
ζk =
" (k+1)t
kt
[(k + 1)t, τ]ζ(τ) dτ.
The observation equation is given by
y(kt) = Hx(kt) + ϵk,
(8.25)
where ϵk = ϵ(kt).
The discrete-time linear state space model (8.24)–(8.25) is a discrete analogue of
the continuous-time model (8.11a)–(8.11b) and can be used to approximate it.
Example 8.7 Consider the continuous-time linear system having the state space
representation
˙x =

 ˙x1
˙x2

=

 1 λ
0 1
 
 x1
x2

+

 1
1

u = Fx + Gu,
y = [1, −1]

x1
x2

= Hx,
where u is a scalar input, for some constant λ. In order to discretise this model and
write down the discrete-time state space analogue we need to evaluate the matrices
F∗and G∗(ζk = 0, since ζ(τ) = 0).

8.2
State Space Representation of Dynamic Systems
419
First we compute F∗. From the deﬁnition of F it is easy to verify that the n-th
power of F is
Fn =

 1 nλ
0 1

.
This may be proven by induction. Using this and the matrix exponential Taylor
expansion we have
ecF =
 
1 + c + c2
2! + · · · λc + 2λc2
2! + · · ·
0
1 + c + c2
2! + · · ·
!
=

ec λcec
0
ec

,
(8.26)
for some constant c.
Putting c = t we obtain
F∗= [(k + 1)t, kt] = etF =

et λtet
0
et

.
From the matrix exponential (8.26) and using c = (k + 1)t −τ we have
G∗=
" (k+1)t
kt
e[(k+1)t−τ]F dτ

 1
1

=

I1 I2
0 I1
 
 1
1

,
(8.27)
where I1 and I2 are the integrals evaluated below
I1 =
" (k+1)t
kt
e(k+1)t−τ dτ =
%
−e(k+1)t−τ&(k+1)t
kt
= et −1
and
I2 = λ
" (k+1)t
kt
[(k + 1)t −τ]e(k+1)t−τ dτ
= λ(k + 1)t(et −1) + λ
" (k+1)t
kt
τde(k+1)t−τ
= λ(k + 1)t(et −1) + λ
%
τe(k+1)t−τ&(k+1)t
kt
−λ
" (k+1)t
kt
e(k+1)t−τ dτ
= λtet −λet + 1,
where integration by parts was used.

420
8
Dynamic Systems and Control
Putting I1 and I2 in (8.27) we obtain G∗as
G∗=

 et(1 + λt −λ)
et −1

.
The discrete-time state space model is
x[(k + 1)t] = F∗x(kt) + G∗u =
 
et λtet
0
et
!
x(kt) +
 
et(1 + λt −λ)
et −1
!
u
y(kt) = [1, −1]x(kt).
Finally, we provide the equivalent of the solution of xk for discrete-time systems.
Consider the time-invariant state space representation (8.22a)–(8.22b) and set xk =
x(kt), for t = 1. For ﬁxed t the discrete set {t0, t1, t2, . . . , tN} is equivalent
to {k0, k0 + 1, . . . , k0 + N}, where k0 = t0. We shall work with the set {k0, k0 +
1, . . . , k0 + N} where t is implicit. With this in place, model (8.22a)–(8.22b) can
be written as
xk+1 = Fxk + Guk + ζk,
(8.28a)
yk = Hxk + ϵk,
(8.28b)
where the initial state is x(k0) is assumed known.
For this state space model the difference state equation (8.28a) has solution
xk = Fk−k0xk0 +
k−k0−1

j=0
Fj(Guk−j−1 + ζk−j−1)
and is the discrete-time equivalent to the solution (8.20) of the differential state
equation (8.11a).
8.3
System Stability
8.3.1
Deﬁnitions
The concept of stability of a system is concerned with the behaviour of the system
for a certain amount of input (Bacciotti, 2019). It relates to the basic principle of
facilitating bounded energy in the output, for bounded energy in the input. The so-
called bounded input bounded output (BIBO) stability requires that if the input is
bounded, then the output should be bounded too; details and conditions of BIBO
stability are given in Minkler and Minkler (1993, Section 3.4). Introductions to

8.3
System Stability
421
stability in dynamic systems can be found in Sastry (1999), Zinober (2001), Ding
(2013), Guo and Han (2018) and Bacciotti (2019).
In this section we discuss stability under the state space representation of a
system.
Consider the continuous-time system represented by Eqs. (8.9)–(8.10). State
space system stability studies the dynamic behaviour of the state vector over time,
for small perturbations of the state and the input functions (sometimes we focus on
the states and consider a so-called free or undriven system, with u(t) = 0). Hence
we operate with a state differential equation
˙x = f (x, u = 0, t).
(8.29)
A state xe = x(te) of (8.29) is called an equilibrium state if x(t) = xe, for any
t ≥te, or in words: after equilibrium time te the state vector is constant and equal
to xe. From (8.29) it follows that f (xe, u = 0) = 0, as
˙xe = lim
h→0
x(te + h) −xe
h
= 0,
(8.30)
since x(te + h) = xe, as te + h > te.
System stability studies the dynamic behaviour of the solution φ(t, x0) of (8.29),
with initial condition x0. More speciﬁcally, we are interested to know how close to
xe the solution φ(t, x0) is, provided x0 is chosen to be close to xe. In this case we
have
Deﬁnition 8.1 An equilibrium state xe of (8.29) is stable at time t0, if for every
ε > 0 there exists δ(ε, t0) > 0 such that ∥φ(t, x0)−xe ∥≤ε for all t ≥t0, provided
that the initial state x0 satisﬁes ∥x0 −xe ∥≤δ(ε, t0), where ∥· ∥is a suitable vector
norm (usually the Euclidean norm) and φ(t, x0) is the general solution of (8.29).
An equilibrium state xe is stable if it stable at all points t0. According to this
deﬁnition, if the initial state is chosen to be in a neighbourhood of the stable
equilibrium state xe, then φ(t, x0) will also be in a neighbourhood of xe.
Note that Deﬁnition 8.1 does not imply that φ(t, x0) converges to xe as t →
∞. It simply suggests that φ(t, x0) is bounded in a neighbourhood of xe. The next
deﬁnition in addition to an equilibrium state being stable it requires it to be the limit
of the solution φ(t, x0) of the differential equation (8.29).
Deﬁnition 8.2 An equilibrium state xe of (8.29) is asymptotically stable if it is
stable (Deﬁnition 8.1) and if there exists a β-neighbourhoodof xe, with ∥x0−xe ∥≤
β(t0), so that for any κ > 0 there exists t1(t0, κ) with ∥φ(t, x0) −xe ∥≤κ, for all
t ≥t0 + t1(t0, κ).
In this deﬁnition we start again by placing x0 in a neighbourhood of xe, but now for
all t ≥t0 + t1(t0, κ), the solution φ(t, x0) converges to xe as t →∞.
The dependency of t0 on δ, β and t1 in Deﬁnitions 8.1 and 8.2 can be dropped
in order to provide stronger deﬁnitions of stability which are known as uniform

422
8
Dynamic Systems and Control
stability (Deﬁnition 8.1 if we drop t0 dependence from δ) and uniform asymptotic
stability (if we drop t0 from the dependence of β and t1). Finally, we give the
deﬁnition of stability of a system.
Deﬁnition 8.3 The free or undriven system generated by the differential equation
(8.29) is stable, asymptotically stable or uniformly asymptotically stable, if the zero-
equilibrium state xe = 0 is stable, asymptotically stable or uniformly asymptotically
stable, respectively.
8.3.2
Stability of Linear Systems
The theory of stability is focused primarily on linear systems and these will be
discussed ﬁrst. A book-length coverage of stability for linear systems can be found
in Ding (2013) and Bacciotti (2019) and in the references therein.
Example 8.8 Consider the ﬁrst-order system with differential equation
˙x = Fx(t) + Gu(t),
(8.31)
where F and G are scalars. For a zero input u(t) = 0, let xe = 0 be an equilibrium
state. The solution of (8.31) is x(t) = eFtx(0), for t0 = 0. Hence, the state xe = 0
is unstable if F > 0 and stable if F ≤0. In particular, xe is stable if F = 0 and
asymptotically stable if F < 0.
Consider now the ﬁrst-order discrete system, with difference equation
xk = Fxk−1 + Guk−1,
(8.32)
where F and G are scalars as before. For the zero input uk−1 = 0 let xe = 0 be an
equilibrium state. The solution of (8.32) is xk = F kx0. Hence, the state xe = 0 is
unstable if |F| > 1 and stable if |F| ≤1. In particular, xe is stable if F = ±1 and
asymptotically stable if |F| < 1.
Consider now the linear system represented by (8.11a)–(8.11b), with perhaps
a time-varying matrix F(t). The state differential equation is reduced to ˙x =
F(t)x(t), given the zero-vector input u(t) = 0, so that the system is free or
undriven. The general solution (8.21) of the state differential equation satisfy
x(t) = (t, t0)x(t0), where (t, t0) is discussed in Sect. 8.2.3. The following
theorem provides conditions of stability for this system.
Theorem 8.3 The linear system represented by (8.11a)–(8.11b) is uniformly
asymptotically stable if and only if
∥(t, t0) ∥≤a1e−a2(t−t0),
for some constants a1, a2 > 0.

8.3
System Stability
423
For the proof of this theorem the reader is referred to Kalman and Bertram (1960).
To the following we shall use the term asymptotically stable to describe a system
which is uniformly asymptotically stable.
When the linear system is time-invariant, so that F(t) = F is time-invariant,
then linear system (8.11a)–(8.11b), then (t, t0) = exp[F(t −t0)]. The following
theorem gives necessary and sufﬁcient conditions for the stability of such a system.
Theorem 8.4 Consider the time-invariant linear system (8.11a)–(8.11b), with
F(t) = F, G(t) = G and H(t) = H. Assume that the matrix F is diagonalisable. The
undriven system (u(t) = 0) is asymptotically stable if and only if the eigenvalues of
F have negative real parts.
Let λ1, . . . , λp be the eigenvalues of F, with λj = aj + ibj, where aj and bj are
the real and imaginary parts of λj and i is the imaginary unit of the complex plain.
Then according to Theorem 8.4
1. If a1, . . . , ap < 0, then the system is asymptotically stable.
2. If a1, . . . , ap ≤0, then the system is stable.
3. If there is at least one k such that ak > 0, then the system is unstable.
Proof of Theorem 8.4 Consider the linear and time-invariant system (8.11a)–
(8.11b), where F is diagonalisable and u(t) = 0 for stability. This means we
can write F = TT−1, where L = diag(λ1, . . . , λp) is the diagonal matrix, with
the eigenvalues of F in its diagonal (not necessarily distinct) and T is the p × p
matrix with columns the corresponding standardised eigenvectors of F. Hence we
can write
eF(t−t0) =
∞

n=0
(t −t0)n
n!
Fn
=
∞

n=0
(t −t0)n
n!
TnT−1
= Te(t−t0)T−1,
(8.33)
since T does not depend on n in the inﬁnite sum. Now write λj = aj + ibj, where
aj and bj are the real and imaginary parts of the complex eigenvalue λj and i is
the imaginary unit. The j-th eigenvalue of e(t−t0) can be written as cjedji, where
cj = e(t−t0)aj and dj = (t −t0)bj, both implicitly depending on t. With ∥· ∥the
Euclidean matrix norm on the complex plain, from (8.33) we obtain
∥eF(t−t0) ∥≤∥T ∥∥T−1 ∥∥e(t−t0) ∥.
(8.34)

424
8
Dynamic Systems and Control
Also since e(t−t0) is a diagonal matrix we have
∥e(t−t0) ∥= ∥diag(c1, . . . , cp)diag(ed1i, . . . , edpi) ∥
≤∥diag(c1, . . . , cp) ∥∥diag(ed1i, . . . , edpi) ∥
=
1
c2
1 + · · · + c2p
1
|ed1i|2 + · · · + |edpi|2
=
7
8
8
9p
p

j=1
e2(t−t0)aj .
Hence from (8.34) it follows
∥eF(t−t0) ∥≤
7
8
8
9p
p

j=1
e2(t−t0)aj .
From this equation we have the following conclusion
1. If a1, . . . , ap < 0, the system is asymptotically stable, as limt→∞eF(t−t0) = 0.
2. If a1, . . . , ap ≤0, then the system is stable.
3. If there is k such that ak > 0, for at least one k ∈{1, . . . , p}, then the system is
unstable. The limit limt→∞eF(t−t0) does not exist.
⊓⊔
As an illustration of this assertion, consider the time-invariant linear system
(8.11a)–(8.11b) and suppose that the system matrix F has one eigenvalue λ, with
non-negative real part, i.e. λ = a + ib, with a ≥0. We will show that the system is
not stable, or that
lim
t→∞∥eF(t−t0)x(t∗) ∥=

∥x∗∥,
if a = 0,
∞,
if a > 0,
(8.35)
where x(t∗) is the eigenvector corresponding to λ.
Since x(t∗) is the eigenvector of F corresponding to the eigenvalue λ we have
Fx(t∗) = λx(t∗). This implies
Fnx(t∗) = Fn−1[Fx(t∗)] = λFn−1x(t∗) = · · · = λnx(t∗),
for any n = 0, 1, 2, . . .. This shows that the eigenvalue of Fn is λn. Then using the
matrix exponential expansion
eF(t−t0)x(t∗) =
∞

n=0
(t −t0)n
n!
Fnx(t∗) =
∞

n=0
λn(t −t0)n
n!
x(t∗) = eλ(t−t0)x(t∗).

8.3
System Stability
425
With λ = a + ib, we get
∥eF(t−t0)x(t∗) ∥= |eλ(t−t0)| ∥x(t∗) ∥= ea(t−t0) ∥x(t∗) ∥,
after using |eib(t−t0)| = 1, from Euler’s formula.
As t →∞, ea(t−t0) converges to 1 (a = 0) or to ∞(a > 0) and this together
with ∥x(t∗) ∥> 0 proves (8.35).
Example 8.9 (Spring Force Dynamics Revisited) We revisit Example 8.4 of the
spring force dynamics. In that example a time-invariant state matrix
F =

 0
1
−k1
m −k2
m

was proposed, where k1 is the viscus friction coefﬁcient, k2 is the spring constant
and m is the mass of the object. Assume that k1, k2 and m satisfy k2
2 −4k1m < 0.
In order to see whether this system is asymptotically stable, we shall calculate the
eigenvalues of F. The characteristic polynomial |F−λI| = 0 has two complex roots
λ1,2 = −k2
2m ±
1
4mk1 −k2
2
2m
i.
The real parts of λ1,2 are both negative (−k2/(2m)) < 0 and so the system is
asymptotically stable, under the condition k2
2 −4mk1 < 0.
Minkler and Minkler (1993, Section 4.3.2) show that BIBO stability is equivalent
to state space system stability. More speciﬁcally, they show that a time-invariant
linear system (8.11a)–(8.11b) is BIBO stable, if and only if it is asymptotically
stable. The state space representation of a time-invariant linear system provides an
important tool to establish stability of a linear system. For time-invariant model
computing the eigenvalues of F is signiﬁcantly easier than working with integrals
involved in BIBO stability. This illustrates the usefulness and versatility of the state
space representation of linear systems.
Example 8.10 (RLC Electric Circuit)
Consider a LRC electric circuit, consisting
of a voltage source or battery (V), a capacitor (C), a resistor (R) and an inductor (L),
all serially connected; for a circuit diagram see Fig. 8.3.
Let u(t) be the input voltage of the battery, x1(t) be the current and x2(t) the
voltage of the capacitor. According to Kirchhoff’s voltage law, the total voltage of
the system in the battery u(t) is equal to the sum of the amount of voltage in the
three units, or
u(t) −VR −VL −VC = u(t) −Rx1(t) −L˙x1(t) −x2(t) = 0,
where R is the effective resistance of the combined load, source and component,
L is the inductance of the inductor and C is the capacitance of the capacitor. Here

426
8
Dynamic Systems and Control
Fig. 8.3 RLC electric circuit.
Shown are the voltage source
(V), the capacitor (C), the
resistor (R) and the inductor
(L), all serially connected
C
R
L
V
we have used VR = Rx1(t) and VL = L˙x(t) (from Kirchhoff’s law). Also from
Kirchhoff’s law for the current we have
x2(t) = VC = u(0) + 1
C
" t
0
x1(τ) dτ,
hence
x1(t) = Cx2(t).
If we deﬁne the state vector x(t) = [x1(t), x2(t)]⊤we have
˙x(t) =

 −R
L −1
L
−1
C
0

x(t) +

 1
L
0

u(t) = Fx(t) + Gu(t).
(8.36)
Suppose we are interested in the current x1(t) = y(t) as output of the system. Hence
we write
y(t) = [1, 0]x(t) = Hx(t).
(8.37)
Equations (8.36)–(8.37) deﬁne a linear system for the RLC circuit described above.
In order to study the stability of system (8.36)–(8.37) we need to calculate the
eigenvalues of F. Solving |F −λI| = 0 we ﬁnd the eigenvalues
λ1,2 = 1
2L

−R ±
:
R2 −4L
C

.

8.3
System Stability
427
•
Case I. If R2 −4L/C ≥0, then there are two (or one double) real roots
λ1 = 1
2L

−R −
:
R2 −4L
C

< 0
λ2 = 1
2L

−R +
:
R2 −4L
C

.
Since R2 −4L/C < R2, it follows that
'
R2 −4L/C < R, and so λ2 < 0 too.
•
Case II. If R2 −aL/C < 0, there are two conjugate complex roots
λ1,2 = 1
2L

−R ± i
:
4L
C −R2

,
with real parts −R/L < 0.
Hence, in either case the system has eigenvalues with negative real parts and from
Theorem 8.4 the system is asymptotically stable.
We remark that the above results hold for discrete-time systems (8.28a)–
(8.28b), with minor modiﬁcations. Deﬁnitions 8.1–8.3 are unchanged, with the
only modiﬁcation that φ(t, x0) is the solution of the difference equation (8.28a).
Considering the time-invariant linear system (8.28a)–(8.28b) and for zero input
u = 0 the state difference equation is xk = Fk−k0x0. If matrix F is diagonalisable,
then the system is asymptotically stable, if and only if the eigenvalues of F lie
inside the unit circle, or |λj| < 1, for j = 1, . . ., p. This result, which is the
district analogue of Theorem 8.4, is schematically proven as follows. Since F is
diagonalisable, we can write F = TT−1, where  is the diagonal matrix with the
eigenvalues of F in its diagonal and T is the matrix with columns the standardised
eigenvectors of F. This implies Fk = TkT−1. Then
∥Fk ∥≤∥T ∥∥T−1 ∥∥k ∥
= ∥T ∥∥T−1 ∥
1
|λ1|2k + · · · + |λp|2k,
which tends to the zero matrix, if limk→∞|λj|2k, for all j = 1, . . . , p. Hence
the system is asymptotically stable if and only if |λj| < 1, for all j = 1, . . . , p.
Note that stability for discrete-time time-invariant systems relates to causality and
stationarity for time series, see e.g. Sect. 7.2.

428
8
Dynamic Systems and Control
8.3.3
Stability of Non-Linear Systems
Stability theory studies the dynamic behaviour of dynamic systems for small per-
turbations of the states and inputs from equilibrium values. Aleksandr Mikhailovich
Lyapunov (6 June 1857–3 November 1918) has made signiﬁcant contributions to
the theory of differential equations and in particular stability theory of dynamical
systems, among other ﬁelds including mathematical physics and probability theory.
For a review of his contributions in mathematics the reader is referred to Smirnov
(1992) and Parks (1992) among others. In the context of this chapter, we discuss
the indirect Lyapunov method (also known as ﬁrst kind Lyapunov method) and the
direct Lyapunov method (also known as second kind Lyapunov method). Among
the many studies, which highlight the importance of stability theory of non-linear
systems, we signal out Zinober (1994), Sastry (1999), Zinober (2001), Ding (2013)
and Guo and Han (2018).
8.3.3.1
Lyapunov Indirect Method
Consider the continuous-time system (8.9)–(8.10) or
˙x = f (x(t), u(t)),
(8.38a)
y(t) = g(x(t), u(t)),
(8.38b)
for some known smooth functions f (·) and g(·). Here, unlike system (8.9)–(8.10)
we have allowed g(˙) in the measurement equation to depend on the input u(t). The
objective of stability theory is to investigate the dynamic behaviour of the system
for small perturbations of the input and state functions
u(t) = u(t) −ue
and
x(t) = x(t) −xe,
(8.39)
where ue is the equilibrium of the input function and xe is the equilibrium of the
state.
We start with Lyapunov’s indirect method. The basic idea of this method is to
linearise the non-linear model and study the stability of the linearised system in
order to make inference for the stability of the non-linear model. Suppose that xe is
an equilibrium state, so that f (xe, ue) = 0.
From Eq. (8.39) we get
˙x(t) = ˙x(t) −˙xe
= f (x(t) + xe, u(t) + ue)
≈∂f
∂x (xe, ue)x(t) + ∂f
∂u(xe, ue)u(t)
= Fx(t) + Gu(t).
(8.40)

8.3
System Stability
429
Similarly, for the measurement equation (8.38b), we obtain
y(t) ≈∂g
∂x (xe, ue)x(t) + ∂g
∂u(xe, ue)u(t)
= Hx(t) + Lu(t),
(8.41)
where y(t) = y(t) −g(xe, ue) is the perturbation of the output from the
equilibrium. It follows that the perturbations x(t) (state), y(t) (output) and
u(t) (input) are approximately ruled by the linearised system (8.40)–(8.41).
Lyapunov’s indirect method involves the following steps.
1. Consider the non-linear system (8.38a) with f (·) differentiable, u(t) = 0 and
xe = 0 (zero-equilibrium state). In this case the system is ˙x = f (x, u = 0).
2. Approximate the non-linear system by the linear system (8.40), which can be
written as ˙x = Fx, with F as in (8.40).
3. If the linear system ˙x = Fx is asymptotically stable, then the state xe = 0
is asymptotically stable for the non-linear system ˙x = f (x, u = 0) (at a
neighbourhood of xe = 0).
4. If the linear system ˙x = Fx is unstable, then the non-linear system ˙x = f (x, u =
0) is also unstable.
5. If the linear system ˙x = Fx is stable, nothing can be said about the stability of
the equilibrium state xe = 0 for the non-linear system ˙x = f (x, u = 0).
This suggests whether a non-linear system is asymptotically stable or unstable, can
be checked by considering the corresponding linear system. If, however, the linear
system is stable only (i.e. one or more of the eigenvalues of F are zero), then the
linear system cannot be used to check the stability of the non-linear system. In this
case we need to resort to the direct method of Lyapunov (see below).
Example 8.11 Simple gravity pendulum Consider a simple gravity pendulum of
Fig. 8.4. An object at the one end of a massless rod is suspended from a pivot and
is allowed to swing freely. Due to gravity, the object oscillates towards the vertical
(dashed) line at its equilibrium point.
The input of this system is the gravity force u(t) = mg, where m is the mass
of the object and g is Newton’s gravitational constant. The angular displacement
y = y(t) is the output of the system, ˙y(t) is the angular velocity, ¨y(t) is the
angular acceleration and I = mℓ2 is the rational inertia, where ℓis the length of
the pendulum. From Newton’s second law for rotation (torque is equal to inertia
times angular acceleration) if we assume that there is no friction, it follows that
−mg sin θℓ= mℓ2 d2θ
dt2 .
For θ = y(t) and assuming friction is present, this law is written as
mℓ2 ¨y(t) = −ℓmg sin y(t) −k ˙y(t),

430
8
Dynamic Systems and Control
Fig. 8.4 Simple pendulum
θ
g
θ
mg sin θ
mg cos θ
where k is the friction constant. Hence the following non-linear differential equation
is obtained
¨y(t) = −g
ℓsin y(t) −
k
mℓ2 ˙y(t).
(8.42)
We shall put this differential equation in state space form.
Deﬁne the state vector x = [x1, x2]⊤, with x1 = y and x2 = ˙x1 = ˙y. From
Eq. (8.42) we obtain the non-linear system
˙x(t) =

 ˙x1(t)
˙x2(t)

=

 f1(x)
f2(x)

=
 
x2
−g
ℓsin x1 −
k
mℓ2 x2
!
= f (x, u),
(8.43)
y(t) = [1, 0]x = Hx.
(8.44)
We remark that this is a non-linear system (the state equation ˙x = f (x, u) is non-
linear due to sin y).
In order to check stability of this system we will use Lyapunov’s indirect method.
We shall linearise system (8.43)–(8.44) and investigate the stability of the linear
model. The Jacobian matrix of f (x) is
J(x1, x2) =
 
0
1
−g
ℓcos x1 −k
mℓ2
!
.
At the equilibrium state xe = [0, 0]⊤, the linearised dynamic model is
˙x(t) =

 0
1
−g
ℓ−c

x(t) = Ft,
(8.45)
y(t) = Hx(t),
(8.46)

8.3
System Stability
431
where c = km−1ℓ−2. The eigenvalues of F are
λ1,2 = 1
2

−c ±
:
c2 −4g
ℓ

.
If c2 −4g/ℓ≥0, there are two (or one double) real roots (root). λ1 = 2−1(−c −
'
c2 −4g/ℓ) < 0 and λ1 = 2−1(−c +
'
c2 −4g/ℓ) < 0 too, as c >
'
c2 −4/ℓ.
If c2 −4g/ℓ< 0, there are two conjugate complex eigenvalues λ1,2 = 2−1(−c ±
i√4g/ℓ−c. The real part of λ1,2 is −c/2 < 0. Hence, in any case the eigenvalues
of F have negative real parts and from Theorem 8.4 the linear system (8.45)–(8.46)
is asymptotically stable. From Lyapunov’s indirect method, it follows that the non-
linear system (8.43)–(8.44) is asymptotically stable too, or that the zero state xe =
[0, 0]⊤is asymptotically stable.
Consider now the equilibrium state xe = [π, 0]⊤. At this state the linearised
system is
˙x(t) =

 0 1
g
ℓ−c

x(t) = Fx(t).
The eigenvalues of F are
λ1,2 = 1
2

−c ±
:
c2 + 4g
ℓ

.
Here c2 + 4g/ℓ> 0 always, hence there are two distinct real eigenvalues λ1 =
2−1(−c −
'
c2 + 4g/ℓ) < 0, but λ2 = 2−1(−c +
'
c2 + 4g/ℓ) > 0, as c <
'
c2 + 4g/ℓ. The equilibrium state xe = [π, 0]⊤of the linear system is unstable (as
one eigenvalue is negative and the other one is positive) and so by Lyapunov’s ﬁrst
method, xe is unstable state for the non-linear system too.
8.3.3.2
Lyapunov Direct Method
We are now moving on to discuss Lyapunov’s direct method for the stability of
non-linear systems. Suppose that a system has a state differential equation
˙x = f (x)
(8.47)
and xe be an equilibrium state, so that f (xe) = 0.
Consider a scalar function V (x), which is continuously differentiable or V ∈C1,
where C1 denotes the set of functions, with continuous ﬁrst derivatives. V is said to
be positive deﬁnite (positive semi-deﬁnite) in a neighbourhood D(xe, r) of xe, if (a)
V (xe) = 0 and (b) V (x) > 0 (V (x) ≥0) and (c) all sublevel sets of V are bounded,

432
8
Dynamic Systems and Control
for all x ∈D(xe, r) and x ̸= xe, where r denotes the radius of the neighbourhood.
Condition (c) is equivalent to V (x) →∞as x →∞. The function V is said to be
negative deﬁnite (negative semi-deﬁnite) if −V is positive deﬁnite (positive semi-
deﬁnite) in D(xe, r). The function V is said to be indeﬁnite, if it is neither positive
deﬁnite (positive semi-deﬁnite) nor negative deﬁnite (negative semi-deﬁnite). For
example, if A is a symmetric and positive deﬁnite matrix, then V (x) = x⊤Ax is a
positive deﬁnite function.
Write fi(x) the i-th constituent of the vector-valued function f (x), so that
f (x) =
⎡
⎢⎢⎢⎣
f1(x)
f2(x)
...
fp(x)
⎤
⎥⎥⎥⎦,
where each fi(x) is a scalar function with domain a subset of Rp. From the chain
rule of differentiation we get
˙V (t) = dV
dt =
p

i=1
∂V
∂xi
∂xi
∂t =
p

i=1
∂V
∂xi
fi(x(t)).
(8.48)
If ˙V (x) regraded as function of x, ˙V (x) is the derivative of V along the system
trajectories. The following theorem provides Lyapunov’s direct method for the
stability of system (8.47).
Theorem 8.5 (Lyapunov’s Direct Method) In the non-linear system (8.47), with
equilibrium vector xe, the following apply
1. If there exists a scalar function V (x) ∈C1 so that V (x) is positive deﬁnite in
a neighbourhood D(xe, r) and ˙V (x) is negative semi-deﬁnite in D(xe, r), then
state xe is stable and if xe = 0, system (8.47) is stable.
2. If there exists a scalar function V (x) ∈C1 so that V (x) is positive deﬁnite in a
neighbourhood D(xe, r) and ˙V (x) is negative deﬁnite in D(xe, r), then state xe
is asymptotically stable and if xe = 0, system (8.47) is asymptotically stable.
Proof First we prove (1). From V (x) > 0, V is bounded below. Also as ˙V ≤0, V
is decreasing function with V (x(0)) an upper bound. Also
V (x(t)) = V (x(0)) +
" t
0
˙V (x(τ)) dτ ≤V (x(0)).
So the trajectory x belongs to the set x ∈{z ∈Rp : V (z) ≤V (0)}, which is
bounded. Because V has bounded sublevel sets, it follows that x must be bounded
in a neighbourhood D(xe, r). Hence xe is stable.
Proceeding now to (2), ﬁrst note that V (xe) = 0 and from (8.48) it is ˙V (xe) =
0, since at equilibrium vector xe it is f (xe) = 0; see also Eq. (8.30). Since V is

8.3
System Stability
433
bounded below (by zero) and decreasing, it follows that limt→∞V (x(t)) = V ∗≥0
exists. We will prove that V ∗= 0. Suppose that V ∗> 0. V is a continuous function
in x and it is zero at xe (V (xe) = 0) and so with V ∗> 0 there would exist a
neighbourhood D(xe, s) in which trajectory x(t) never enters (0 = V (xe) < V ∗≤
V (t)). Since ˙V is continuous function, with ˙V (x) < 0 and ˙V (xe) = 0, there would
exist c > 0 such that ˙V ≤−c, for all x. Hence
V (x(t)) = V (x(0)) +
" t
0
˙V (x(τ)) dτ ≤V (x(0)) −ct
and V (x(t)) would become negative at some ﬁnite time. This is a contradiction to
the assumption that V is positive deﬁnite function. Hence V ∗= 0.
Since V is decreasing with limt→∞V (t) = 0 and V (x) = 0, for xe only, it
follows that limt→∞x(t) = xe. This together with the fact that xe is stable from (1),
prove that xe is asymptotically stable.
⊓⊔
Some comments are in order. In the application of Theorem 8.5 a candidate
positive deﬁnite function V is proposed, usually involving some constants to be
speciﬁed. Then these constants may be speciﬁed in order to satisfy ˙V < 0 or
˙V ≤0 and so establish asymptotic stability or stability. A function V , which satisﬁes
the conditions of Theorem 8.5 is known as Lyapunov function. Studying stability
for non-linear systems using the direct method involves ﬁnding suitable Lyapunov
functions. The next two examples illustrate this point.
Example 8.12 Consider the dynamic system
˙x1 = −x1 + 6x2,
˙x2 = −x1 −x3
2,
with equilibrium xe = [0, 0]⊤.
Consider the function V (x) = x2
1+cx2
2, where c > 0 is subject to speciﬁcation. It
is easy to verify that V is a positive deﬁnite function, i.e. V (x) > 0 and V (xe) = 0.
We shall specify c so that ˙V (x) < 0. Indeed
˙V (x) = [2x1, 2cx2]

−x1 + 6x2
−x1 −x3
2

= −2x2
1 + (12 −2c)x1x2 −2cx4
2.
If we set c = 6, we have
˙V (x) = −2x2
1 −12x4
2 < 0,
so that ˙V is a negative deﬁnite function. From Theorem 8.5 it follows that xe =
[0, 0]⊤is asymptotically stable (or that the system is asymptotically stable).

434
8
Dynamic Systems and Control
The next example studies the stability of the popular Lorenz system, see Lorenz
(1963).
Example 8.13 (Lorenz System)
A non-linear system of differential equations was
proposed by Lorenz (1963) to approximate ﬂuid heating in the atmosphere. In fact
Lorenz considered a case study of a horizontal ﬂuid layer which is heated from
below. The warmer ﬂuid from the bottom side of the layer rises and convection
currents occur. Let x, y and z be the coordinates of the layer at R3 Euclidean space.
The Lorenz differential equations are
˙x = σ(y −x),
(8.49a)
˙y = ρx −y −xz,
(8.49b)
˙z = xy −βz,
(8.49c)
where σ, ρ and β are some positive constants. This model has a complex dynamic
behaviour and is extensively used in the literature as an example in chaos theory, see
e.g. Hirsch et al. (2012). In this example we study the stability of system (8.49a)–
(8.49c), for 0 < ρ < 1, which results in relatively simple dynamics of the system.
For example, setting σ = 10, ρ = 28 and β = 8/3 results in a chaotic behaviour
(see Fig. 8.5 for two realisations of the system). The Lorenz system (also known as
Lorenz attractor) is discussed in many textbooks as a non-linear system, which can
generate a chaotic dynamic behaviour, see e.g. Ding (2013, pp. 21–24).
We consider a candidate Lyapunov function
V = a1x2 + a2y2 + a3z2,
where the constants a1, a2 and a3 are to be determined so that V qualiﬁes for a
Lyapunov function. The ﬁrst derivative of V is
˙V = [2a1x, 2a2y, 2a3z]
⎡
⎣
σ(y −x)
ρx −y −xz
xy −βz
⎤
⎦
= −2a1σx2 −2a2y2 −2a3βz2 + 2(a1σ + a2ρ)xy + 2(a3 −a2)xyz.
If we set a2 = a3 = 1 and a1 = 1/σ we obtain
˙V = −2[x2 + y2 + βz2 −(1 + ρ)xy]
= −2
 
x −1 + ρ
2
y
	2
+

1 −
1 + ρ
2
	2
y2 + βz2
!
.
(8.50)
Since 0 < ρ < 1, it is 0 < (1 + r)/2 < 1, which implies ˙V < 0 in (8.50). That
means ˙V is a negative deﬁnite function and so V is a Lyapunov function. From

8.4
Continuous-Time Kalman Filter
435
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.4
0.8
Lorenz system, =10, =0.9, =8/3
y
z
-20
-10
0
10
20
0
10
20
30
40
Lorenz system, =10, =28, =8/3
y
z
Fig. 8.5 Plot of Lorenz systems: the top panel shows the system with σ = 10, ρ = 0.9, β = 8/3
discussed in this example and the lower panel plots the same system for ρ = 28
Theorem 8.5 the Lorenz system above is asymptotically stable, under the condition
0 < ρ < 1. Figure 8.5 plots two instances of the Lorenz system (8.49a)–(8.49c). The
ﬁrst instance (top panel) uses σ = 10, ρ = 0.9 and β = 8/3; we observe that due
to ρ being between 0 and 1, the dynamics of this system are simple. This system is
shown above to be asymptotically stable. The system in the bottom panel of Fig. 8.5
shows the second instance of the system for σ = 10, ρ = 28 and β = 8/3. This
is a considerably more complex system, which is chaotic. As ρ (and perhaps σ and
β) is allowed to increase (starting from lower values) the system can describe ﬂuid
heating over time, as described originally in Lorenz (1963).
8.4
Continuous-Time Kalman Filter
In this section we brieﬂy discuss the Kalman ﬁlter for discrete-time linear systems
(Sect. 8.4.1) and then we use it in order to prove the Kalman ﬁlter for continuous-
time linear systems, also known as the Kalman–Bucy ﬁlter (Sect. 8.4.2). Following
the seminal papers (Kalman, 1960; Kalman & Bucy, 1961), these ﬁlters have
been extensively discussed in the literature, as evidenced by inﬂuential textbooks

436
8
Dynamic Systems and Control
(Anderson & Moore, 1979; Minkler & Minkler, 1993) and (Grewal & Andrews,
2015). We start with the discrete-time Kalman ﬁlter.
8.4.1
Discrete-Time Kalman Filter
We consider the discrete-time linear system having the state space representation
(8.28a)–(8.28b), which is given below for convenience
xk+1 = Fkxk + ζk,
(8.51a)
yk = Hkxk + ϵk,
(8.51b)
where the initial state is x0 is must be speciﬁed, see Eq. (8.53) below.. In this
representation the input uk = 0 or uk is absorbed into the state vector xk, see
e.g. Exercise 3. The components Fk and Hk are assumed known and the innovation
sequences ζk and ϵk are assumed to be white noises and uncorrelated, i.e. E(ζk) = 0,
E(ϵk) = 0 and
E(ζkζ ⊤
s ) = δksZk,
E(ϵkϵ⊤
s ) = δksk
and
E(ζtϵ⊤
s ) = 0,
(8.52)
for any k, s, where δks denotes the Kronecker delta (δks = 1 if k = s, and 0
otherwise). In addition we may assume that ζk and ϵk are Gaussian and so we may
write
ζk ∼N(0, Z)
and
ϵk ∼N(0, ).
The initial state is assumed to follow a normal distribution
x0 ∼N(ˆx0|0, P0|0),
(8.53)
for some mean vector ˆx0|0 and covariance matrix P0|0. If x0 = ˆx0|0 is known with
no uncertainty, then P0|0 = 0. The prior or initial distribution (8.53) allows for
uncertainty around the mean ˆx0|0 of x0.
With the output observations y1:k+1 = (y1, . . . , yk+1) the Kalman ﬁlter provides
estimation of the states xk+1 via the conditional distribution
xk+1 | yk+1 ∼N(ˆxk+1|k+1, Pk+1|k+1),
(8.54)
where ˆxk+1|k+1 and Pk+1|k+1 are calculated sequentially by the recursions
ˆxk+1|k+1 = Fk ˆxk|k + Kk+1(yk+1 −Hk+1Fk ˆxk|k)
(8.55)
Kk+1 = Pk+1|kH⊤
k+1(Hk+1Pk+1|kH−1
k+1 + k+1)−1
(8.56)

8.4
Continuous-Time Kalman Filter
437
Pk+1|k = FkPk|kF⊤
k + Zk
(8.57)
Pk+1|k+1 = (I −Kk+1Hk+1)Pk+1|k
(8.58)
Some comments are in order.
1. Equations (8.54) with recursions (8.55)–(8.58) consist of the Kalman ﬁlter for
discrete-time systems. The proof of this is given by Theorem 3.2 (see Sect. 3.2)
if we replace xt, βt and t (Sect. 3.2) by Hk, xk and k, respectively (assuming that
yk is scalar, univariate Kalman ﬁlter). If yk is a vector, then the reader is referred
to the multivariate Kalman ﬁlter (Theorem 5.1, in Sect. 5.1).
2. The proof of Theorem 3.2 makes use of normal distribution theory, in order to
derive the conditional distribution (8.54). The Kalman ﬁlter recursions (8.55)–
(8.58) are valid, even if we drop the normality assumption of the innovations but
we keep the error structure assumptions (8.52). For the proof of the Kalman ﬁlter
recursions if the normality assumption is dropped see Theorem 3.3.
8.4.2
Kalman–Bucy Filter
We consider the continuous-time linear system having the state space representation
˙x(t) = F(t)x(t) + ζ(t),
(8.59a)
y(t) = H(t)x(t) + ϵ(t),
(8.59b)
where ζ(t) and ϵ(t) are random innovations and the inputs are absorbed into the
states as discussed in the discrete-time system in Sect. 8.4.1 above.
Some discussion should be devoted on the deﬁnition of the innovation functions
ζ(t) and ϵ(t). White noise in continuous-time can be deﬁned by several ways. The
most rigorous considers white noise as the derivative of Brownian motion. The
Brownian motion is the continuous-time analogue of random walk and hence its
derivative (with analogue ﬁrst-order difference of random walk) can be deﬁned as
a white noise process. However, under the Lebesgue-Stieltjes integration (Carter &
van Brunt, 2000), the Brownian motion is nowhere differentiable along its path. The
deﬁnition of its derivative calls upon consideration of Îto integral and stochastic
calculus, for a good treatise see Applebaum (2011) and Stroock (2018). As it is
out of the scope of this book to cover stochastic calculus, we shall adopt the less-
rigorous approach of the deﬁnition of ζ(t) and ϵ(t), which is adopted by several
engineering and signal-processing textbooks, see e.g. Schweppe (1968) and Minkler
and Minkler (1993). According to this a formal deﬁnition of the distributions of
ζ(t) and ϵ(t) is left unspeciﬁed; instead a continuous-time analogue of assumptions

438
8
Dynamic Systems and Control
(8.52) is adopted, or E(ζ(t)) = 0, E(ϵ(t)) = 0 and
E(ζ(t)ζ ⊤(t + τ)) = δ(τ)Z(t),
E(ϵ(t)ϵ⊤(t + τ)) = δ(τ)(t)
(8.60)
and
E(ζ(t)ϵ⊤(t + τ)) = 0,
(8.61)
where δ(t) is the Dirac function. These assumptions indicate that ζ(t) is uncorre-
lated of ζ(t + τ), for τ ̸= 0, ϵ(t) is uncorrelated of ϵ(t + τ), and that ζ(t) and ϵ(s)
are uncorrelated for any t, s. It follows that Var(ζ(t)) = Z(t) and Var(ϵ(t)) = (t).
For the initial state x(t0) = x0 we assume it is random and uncorrelated to both
ζ(t) and ϵ(t) and it has a Gaussian prior distribution
x0 ∼N(ˆx(t0), P(t0)),
(8.62)
for some known mean vector ˆx(t0) and covariance matrix P(t0). Moreover, we can
accommodate a deterministic x0, if we set P(t0) = 0.
We shall assume that F(t), H(t), Z(t) and (t) are known continuous functions.
We shall also assume that (t) is positive deﬁnite matrix (note that if y(t) is scalar
function, then (t) > 0). With all these assumptions the following theorem provides
the Kalman–Bucy ﬁlter, see Kalman and Bucy (1961), Anderson (1971), Grewal and
Andrews (2015), and Johnson and Núnez (2014).
Theorem 8.6 (Kalman–Bucy
Filter) In
the
continuous-time
linear
system
(8.59a)–(8.59b) with the error structure (8.60)–(8.61) and with the prior of x0
as in (8.62), the estimate ˆx(t) of the state vector x(t) and the corresponding error
covariance matrix P(t) satisfy the following differential equations
˙ˆx(t) = F(t)ˆx(t) + K(t)[y(t) −H(t)ˆx(t)],
(8.63)
K(t) = P(t)H ⊤(t)(t)−1,
(8.64)
˙P(t) = F(t)P(t) + P(t)F⊤(t) −P(t)H⊤(t)(t)−1H(t)P(t) + Z(t).
(8.65)
The proof of Kalman and Bucy (1961) is based on the orthogonality principle
(theory of projections) and hence they derived the differential equation (8.63) by
generalising the Wiener–Hopf equation, Wiener and Hopf (1931), Crowdy and Luca
(2014) and the references therein. The proof below is based on discretising the
continuous-time system, using the Kalman-ﬁlter for discrete-time and then taking
the limit of the time-interval to tend to zero.
Proof The proof is by discretising the linear system using the discrete-time linear
system (8.51a)–(8.51b), where t = kt (see also Sect. 8.2.4 of how we can obtain
a discrete approximation of the continuous-time linear system). When t tends to
0, the discrete-time system converges to the continuous-time linear system. Hence
we deﬁne
ˆx(t) = lim
t→0 ˆxk
and
P(t) = lim
t→0 Pk+1,

8.4
Continuous-Time Kalman Filter
439
where ˆxk = ˆxk|k and Pk+1 = Pk+1|k+1 are the mean vector and covariance matrix of
xk, given y1:k in the discrete-time system. From Sect. 8.2.4 we obtain the discrete-
time system (8.51a)–(8.51b), with
xk = x(kt),
Fk = [(k + 1)t, kt],
yk = y(kt),
ζk =
" (k+1)t
kt
[(k + 1)t, τ]ζ(τ) dτ,
Hk = H(kt), ϵk = ϵ(kt),
where (·) is the state transition matrix deﬁned in Sect. 8.2.4.
The next step is to show the following useful results:
1. ζk and ϵk are uncorrelated and their covariances are approximately equal to
Zk ≈tFkZ(kt)F⊤
k ,
k ≈(kt)/t.
2. For t = kt we have
F(t) = lim
t→0
Fk −I
t
.
(8.66)
To prove (1) we get
E(ζkϵ⊤
ℓ) = E
" (k+1)t
kt
[(k + 1)t, τ]ζ(τ) dτϵ⊤
ℓ
+
=
" (k+1)t
kt
[(k + 1)t, τ]E
3
ζ(τ)ϵ⊤
ℓ
4
dτ
=
" (k+1)t
kt
[(k + 1)t, τ]E(ζ(τ))E(ϵ⊤
ℓ) dτ
= 0,
since ζ(t) is uncorrelated of ϵ(t). This proves that ζk and ϵk are uncorrelated too.
The covariance matrix of ζk is
Var(ζk) = Var
" (k+1)t
kt
[(k + 1)t, τ]ζ(τ) dτ
+
=
" (k+1)t
kt
[(k + 1)t, τ]Z(τ)[(k + 1)t, τ]⊤dτ
≈t[(k + 1)t, τ]Z(τ)[(k + 1)t, τ]⊤,

440
8
Dynamic Systems and Control
using the approximation
" a+t
a
f (x) dx ≈tf (t),
for some a and for small length t, where f (·) is a continuous function.
Likewise for ϵk we ﬁrst approximate ϵk as
ϵk = ϵ(kt) ≈1
t
" (k+1)t
kt
ϵ(τ) dτ
and then we take the covariance matrix
Var(ϵk) ≈
1
t2
" (k+1)t
kt
(τ) dτ ≈(kt)
t
.
This completes the proof of (1).
Moving on to the proof of (2) we ﬁrst recall that the state transition matrix
(t, t1) satisﬁes the matrix equation ˙(t, t1) = F(t)(t, t1), for some t1; see
Sect. 8.2.3. Solving this equation for F(t) and setting t1 = kt we obtain
F(t) = ˙(t, t1)−1(t, t1) = lim
t→0
(t + t, t1) −(t, t1)
t
−1(t, t1)
= lim
t→0
(kt + t, kt) −(t1, t1)
t
−1(t1, t1)
= lim
t→0
Fk −I
t
,
as (t1, t1) = I. This settles the proof of (2).
Proceeding now to the rest of the proof from Eq. (8.66) we have
Fk ≈tF(kt) + I,
(8.67)
which is substituted in ˆxk+1|k+1 = ˆxk of the discrete-time system (8.55)
ˆxk+1 −ˆxk
t
= F(kt)ˆxk + Kk+1
t [yk+1 −Hk+1(tF(kt) + I)ˆxk]
= F(kt)ˆxk + Kk+1
t (yk+1 −Hk+1Fk ˆxk).
Now write this with k = t and allow k and t to vary
ˆxk+1 −ˆxk
t
= F(t)ˆxk + Kk+1
t [(y(t + t) −H(t + t)(t + t, t)ˆxk]

8.4
Continuous-Time Kalman Filter
441
and by taking limits as t tends to zero we obtain
˙ˆx(t) = lim
t→0
ˆxk+1 −ˆxk
t
= F(t)ˆxk +

lim
t→0
Kk+1
t
	
[y(t) −H(t)ˆxk].
(8.68)
Now we need to deal with the limit of Kk+1/t. From the deﬁnition of the
Kalman gain Kk+1 (8.56) in the discrete-time system we get
Kk+1 = Pk+1|kH⊤(t + t)

H(t + t)Pk+1|kH⊤(t + t) + (t + t)
t
−1
= tPk+1|kH⊤(t + δt)[tH(t + t)Pk+1|kH⊤(t + t) + (t + t)]−1.
We can observe that
lim
t→0 Pk+1|k = lim
t→0 Pk|k = lim
t→0 E[(x(t) −ˆx(t))(x(t) −ˆx(t))⊤] = P(t).
Hence from Kk+1 above we have
K(t) = lim
t→0
Kk+1
t
= P(t)H⊤(t)(t)−1.
If we substitute K(t) into (8.68) we obtain (8.63) as required.
Finally, we will prove Eq. (8.65). From the recursion of Pk+1|k+1 for the discrete-
time system (see Eq. (8.58)) and using Fk as in (8.67) we obtain
Pk+1 = Pk+1|k+1 = Pk+1|k −Kk+1Hk+1Pk+1|k
= FkPk|kF⊤
k + Zk −Kk+1Hk+1Pk+1|k
= (I + tF(t)Pk(I + tF(t))⊤+ tFkZ(t)F⊤
k −Kk+1Hk+1Pk+1|k.
Rearranging this equation we get
Pk+1 −Pk
t
= F(t)Pk+PkF⊤(t)+tF(t)PkF⊤(t)+FkZ(t)F⊤
k −Kk+1
t H(t +t)Pk+1|k.
By taking the limit as t →0 we obtain
˙P(t) = lim
t→0
Pk+1 −Pk
t
= F(t)P(t) + P(t)F⊤(t) −P(t)H⊤(t)(t)−1H(t)P(t) + Z(t)
and the proof is completed.
⊓⊔
Some comments are in order. By close observation of Eqs. (8.63) and (8.65)
(continuous-time) and recursions (8.55) and (8.58) (discrete-time) we see that the
latter can be expressed as difference (discrete time) equations while the former are

442
8
Dynamic Systems and Control
differential equations (continuous time). In both systems if we have a single output
(i.e. y(t) or yk are scalars), then there is no inversion involved in the computation
of the Kalman ﬁlter. The stability of the Kalman–Bucy ﬁlter has attracted some
considerable attraction. An early study on this topic is conducted in Anderson
(1971) and a recent one in Kulikov and Kulikova (2018).
The differential equation (8.65) is a Riccati matrix equation and can be solved in
closed form only in special cases. In particular, it can be solved in closed form when
there are no quadratic terms on the right hand side of the equation. We can see that
this is achieved when (a) H(t) = 0 (noise-only measurement equation: y(t) = ϵ(t))
or (b) when Z(t) = 0 (noise-free system equation: ˙x(t) = F(t)x(t)). We discuss
ﬁrst case (b).
Consider the continuous-time time-invariant linear system
˙x(t) = Fx(t),
y(t) = Hx(t) + ϵ(t),
where the covariance matrix (t) =  is time-invariant and P(t0) is known and
positive deﬁnite. The differential equation (8.65) can be written as
P(t)−1 ˙P(t)P(t)−1 = P(t)−1F + F⊤P(t)−1 −H⊤−1H.
(8.69)
If we differentiate the equality P(t)−1P(t) = I we have
0 = dP(t)−1P(t)
dt
= dP(t)−1
dt
P(t) + P(t)−1 ˙P(t)
or
dP(t)−1
dt
= −P(t)−1 ˙P(t)P(t)−1.
(8.70)
Substitute now (8.70) into (8.69)
dP(t)−1
dt
= −P(t)−1F −F⊤P(t)−1 + H⊤−1H.
The solution of this differential equation is
P(t)−1 =
" t
t0
e−F⊤(t−w)H⊤−1He−F(t−w) dw + e−F⊤(t−t0)P(t0)−1e−F(t−t0)
= eF⊤t
" t
t0
eF⊤wH⊤−1HeFw dwe−Ft + e−F⊤(t−t0)P(t0)−1e−F(t−t0).
(8.71)

8.4
Continuous-Time Kalman Filter
443
To prove this result, we differentiate (8.71) with respect to t, or
dP(t)−1
dt
= −F⊤e−F⊤t
" t
t0
eF⊤wH⊤−1HeFw dwe−Ft + e−F⊤teF⊤tH⊤−1HeFte−Ft
−e−F⊤t
" t
t0
eF⊤wH⊤−1HeFw dwe−FtF −F⊤e−F⊤(t−t0)P(t0)−1e−F(t−t0)
−e−F⊤(t−t0)P(t0)−1eF(t−t0)F
= −F⊤

" t
t0
e−F⊤(t−w)H⊤−1He−F(t−w) dw + e−F⊤(t−t0)P(t0)−1eF(t−t0)

−

" t
t0
e−F⊤(t−w)H⊤−1He−F(t−w) dw + e−F⊤(t−t0)P(t0)−1eF(t−t0)

F
+H⊤−1H
= −F⊤P(t)−1 −P(t)−1F + H⊤−1H.
Equation (8.71) can be written as
P(t)−1 =
" t−t0
0
e−F⊤wH⊤−1He−Fw dw+e−F⊤(t−t0)P(t0)−1e−F(t−t0).
(8.72)
The solution of P(t) may be obtained by inverting P(t)−1 from (8.72).
If all eigenvalues of F have positive real parts, then
P = lim
t→∞P(t) =

" ∞
0
e−F⊤wH⊤−1He−Fw dw
−1
,
(8.73)
since
lim
t→∞e−F⊤(t−t0) = lim
t→∞e−F(t−t0) = 0.
If the system is stable (all eigenvalues of F have negative real parts) we have
P(t) =

" t−t0
0
e−F⊤wH⊤−1He−Fw dw + e−F⊤(t−t0)P(t0)−1e−F(t−t0)
−1
=

e−F⊤(t−t0)
(" t−t0
0
eF⊤(t−t0−w)H⊤−1HeF(t−t0−w) dw + P(t0)−1
)
e−F(t−t0)
−1
= eF(t−t0)

" t−t0
0
eF⊤wH⊤−1HeFw dw + P(t0)−1
−1
eF⊤(t−t0).

444
8
Dynamic Systems and Control
Since limt→∞eF(t−t0) = 0 it follows that
P = lim
t→∞P(t) = 0.
Hence we have proven that if the system is stable, the error covariance matrix P(t)
converges to the zero matrix as t →∞.
Consider now case (a) where H = 0, so that the system is
ˆx(t) = Fx(t) + ζ(t),
(8.74a)
y(t) = ϵ(t),
(8.74b)
where ζ(t) and ϵ(t) satisfy assumptions (8.60)–(8.61) and the innovation covariance
matrices Z(t) = Z and (t) =  are time-invariant. In this case the error covariance
differential equation is
dP(t)
dt
= FP(t) + P(t)F⊤+ Z,
which has solution
P(t) =
" t
t0
eF(t−w)ZeF⊤(t−w) dw + eF(t−t0)P(t0)eF⊤(t−t0)
=
" t−t0
0
eFwZeFT w dw + eF(t−t0)P(t0)eF⊤(t−t0).
(8.75)
The proof of this is very similar to the proof of (8.71) and is left to the reader as
an exercise. Notice that in the system (8.74a)–(8.74b) measurements y(t) do not
provide any information about the states x(t). Another way we can see this case is
when H is non-zero, but now  is equal to inﬁnity. In such a case the measurements
y(t) vary erratically around the state x(t) and as before (in the case studied above
when H = 0) there is no meaningful information the measurements can provide to
the states. In practice we can consider a situation where  is very large instead of
inﬁnity and this case might be of interest if the state differential equation is subject
to noise, hence Z must be included. On the other hand, if the state differential
equation has small noise (can be assumed as equal to zero) and focus is placed
on the measurement or sensor noise (via covariance matrix ), then case (b) should
be considered as described above. Exercise 21 studies a linear system which is in
case (a). Below we give an example illustrating case (b), Z = 0 and  > 0.
Example 8.14 (Example 8.7 Revisited) Consider the linear system of Example 8.7
where now the measurement equation includes an error term, i.e.
y(t) = Hx(k) + ϵ(k),
ϵ(t) ∼N(0, σ 2),

8.4
Continuous-Time Kalman Filter
445
with λ = 1, u = 0, σ 2 = 1, t0 = 0 and P(0) = 2−1I. From Eq. (8.72) the inverse of
P(t) is
P(t)−1 =
" t
0
exp
(
−w

 1 0
1 1
) 
 1 −1
−1 1

exp
(
−w

 1 1
0 1
)
dw
+1
2 exp
(
−t

 1 0
1 1
)
exp
(
−t

1 1
0 1
)
.
(8.76)
Using the equalities of the matrix exponential (see also Example 8.7)
ecF = ec

 1 c
0 1

,
for some constant c and exp(F)⊤= exp(F⊤), we have that the integrated part of
(8.76) is
I =
" t
0
e−2w

 1
0
−w 1
 
 1 −1
−1 1
 
 1 −w
0
1

dw
=
" t
0

e−2w
−(w + 1)e−2w
−(w + 1)e−2w e−2w(w2 + w + 1)

dw
=

 I1 I2
I2 I3

.
These three integrals I1, I2 and I3 are calculated below
I1 =
" t
0
e−2w dw =

1
2e−2w
t
0
= 1
2(1 −e−2t).
I2 and I3 are calculated by applying successive integration by parts as
I2 = −
" t
0
(w + 1)e−w dw = 1
2te−2t −3
2(1 −e−2t)
and
I3 =
" t
0
(w2 + w + 1)e−2w dw = 1 −e−2t −t(t + 2
2
e−2t.
The details of the derivations of integrals I2 and I3 are omitted and are left as an
exercise for the reader.

446
8
Dynamic Systems and Control
The non-integrated part of (8.76) is
exp
(
−t

 1 0
−t 1
)
exp
(
−t

 1 −t
0 1
)
= e−2t

 1
−t
−t t2 + 1

.
Substituting this and I into (8.76) we get
P(t)−1 =

1
2
1
2(3e−2t −1)
1
2(3e−2t −1) 1 −1
2e−2t(2 −t2).

(8.77)
Hence matrix P(t) is computed by inverting P(t)−1 as
P(t) =
2
1 + (4 + t2)e−2t −9e−4t

2 −(2 −t2)e−2t 1 −3e−2t
1 −3e−2t
1

.
(8.78)
Note that the limit P−1 = limt→∞P(t)−1 is obtained by (8.77) as
P−1 = lim
t→∞P(t)−1 =

1
2
−1
2
−1
2
1

.
This can be used to obtain the limit P of P(t) as
P = lim
t→∞P(t) = (P−1)−1 =

4 2
2 2

.
This can be calculated by taking the limit of P(t) from (8.78), but it is simpler to
work out the limit via P−1 as above. Note that as F has a single eigenvalue λ = 1,
with positive real part, the system is not stable. The limit P may be directly obtained
by (8.73). Here we chose to do the full calculations in order to obtain P(t), which is
of interest in its own right.
The steady state of ˆxt is obtained when the Kalman gain K(t) is replaced by its
limit K, in the state differential equation
˙ˆx(t) = (F −KH)ˆx(t) + Ky(t),
(8.79)
where K
= limt→∞K(t) = PH ⊤/σ 2 is the limit of the Kalman gain. In
Exercise 19 we explore the steady state x(t) for this example. The steady state of
time-invariant linear systems is further discussed in Sect. 8.4.3 below.
Figure 8.6 plots the variances P11,t, P22,t (diagonal elements of matrix P(t) as
in Eq. (8.78), and the covariance P12,t (off-diagonal elements of P(t)), for time
t ∈[0, 5]. Plotted are also the limit values of P = {P12}, with P11 = 4, P12 =
P22 = 2 (indicated by the horizontal lines in Fig. 8.6). We remark that convergence
is exponentially fast and in principle from about t = 4, the error covariance matrix

8.4
Continuous-Time Kalman Filter
447
0
1
2
3
4
5
-2
-1
0
1
2
3
4
5
Asymptotic performance of the error covariance matrix
Time (t)
P(t)
Fig. 8.6 Asymptotic performance of the error covariance matrix P (t) = {Pij,t}i,j=1,2. The plot
shows P11,t (solid line), P12,t (dashed line), P22,t (dotted line), together with their limits P11 = 4,
P12 = P22 = 2
has reached its limit. The next section explores the limit of the error covariance
matrix P(t) for time-invariant continuous-time state space systems.
8.4.3
Observability and Convergence
Kalman introduced the notions of observability and controllability, in order to
provide the asymptotic performance of the Kalman ﬁlter (for discrete-time systems)
and the Kalman–Bucy ﬁlter (for continuous-time systems). Several textbooks
discuss in detail observability and controllability of systems, see e.g. Minkler and
Minkler (1993),
A system is observable when its states x(t) can be estimated by the output or
measurements y(t). In other words, in an observable systems if we have perfect
knowledge of the measurements we should be able to compute the states. If the
system is not observable there will be some states, which are not possible to estimate
from the measurements.

448
8
Dynamic Systems and Control
Consider the time-invariant linear system
˙x(t) = Fx(t),
(8.80a)
y(t) = Hx(t),
(8.80b)
where x(t) is a p × 1 state vector, F is a p × p state matrix, y(t) is a d × 1
measurements vector and H is a 1 × p row vector (here the output y(t) is a scalar
function). Note that noise terms may be included, but for the notions of observability
we shall not consider them.
Example 8.15 Consider system (8.80a)–(8.80b), with
F =

 −2 0
0 −1

and
H = [0, 1].
The solution of the state differential is
x(t) =

 x1(t)
x2(t)

=

 x1(t0)e−2(t−t0)
x2(t0)e−(t−t0)

and the measurement equation implies
y(t) = Hx(t) = x2(t).
Hence knowledge of measurements y(t) gives no information about the state x1(t).
We cannot make inference for x1(t) based on measurements y(t). We can only learn
about x2(t) from y(t). Hence, the state vector x(t) is not observable in this case.
It follows we can reduce the dimension of the state vector, so that the system be
observable. Consider the linear system
˙x2(t) = −x2(t),
y(t) = x2(t).
This system has output y(t) = x2(t) as above and x2(t) = x2(t0)e−(t−t0). In this
system knowledge of y(t) provides knowledge of the state x2(t), hence this system
is observable.
Theorem 8.7 Consider the linear system (8.80a)–(8.80b). This system is observ-
able if and only if the p × p observability matrix
O =
⎡
⎢⎢⎢⎣
H
HF
...
HFp−1
⎤
⎥⎥⎥⎦
has full rank p.

8.4
Continuous-Time Kalman Filter
449
For Example 8.15, the observability matrix is
O =

 H
HF

=

0 1
0 −1

,
which has rank 1 and so system is not observable. The reduced system has
observability matrix (here is reduced to a scalar) O = H = 1, which has rank 1
and the system is observable.
Proof of Theorem 8.7 The continuous-time linear system can be approximated by
the discrete-time linear system (8.24)–(8.25), with G = 0. The state matrix of this
system is
F∗= ((k + 1)t, kt) = eFt.
(8.81)
We shall prove that system (8.24)–(8.25) is observable if and only if the observabil-
ity matrix
O∗=
⎡
⎢⎢⎢⎣
H
HF∗
...
HF∗p−1
⎤
⎥⎥⎥⎦
has rank p. From equation
⎡
⎢⎢⎢⎣
y(kt)
y[(k + 1)t]
...
y[(k + p −1)t]
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
H
HF∗
...
HF∗p−1
⎤
⎥⎥⎥⎦x(kt),
it follows that x(kt) can be determined from the outputs y[(k +j)t], if and only
if matrix O∗has full rank p. If this is the case the states are obtained by
x(kt) = O∗−1y∗,
where y∗= [y(kt)], y[(k + 1)t], . . ., y[(k + p −1)t]⊤.
It remains to show that when O∗has rank p, then O has rank p too. With the
deﬁnition of F∗as in (8.81) we show that the row vectors H, HF, . . ., HFp−1 are
linearly independent. Since O∗is of full rank p, it follows that the row vectors
H, HeFt, . . . , HeFt(p−1) are linearly independent. Hence equation
λ1H + λ2HeFt + · · · + λpHeFt(p−1) = 0
(8.82)

450
8
Dynamic Systems and Control
implies λ1 = · · · = λp = 0. If we differentiate (8.82) with respect to t and take
the limit as t →0, it follows that
λ∗
1H + λ∗
2HF + · · · + λ∗
pHFp−1 = 0,
implies λ∗
1 = · · · = λ∗
p = 0, for λ∗
j = jλj and j = 1, . . . , p. This shows that O is
of full rank p and the proof is completed.
⊓⊔
Some comments are in order.
1. Suppose that F is diagonalisable, so that it has the representation F = TT−1,
where  is the diagonal matrix with diagonal elements the eigenvalues of
F and T be the matrix with columns the standardised eigenvectors of F.
Consider the set of row vectors H, HF, . . . , HFp−1 (the rows of the observ-
ability matrix O. For constants μ1, . . . , μp, equality p−1
i=0 μi+1HFi
= 0
implies HT p−1
i=0 μi+1i
=
0. With HT
=
[a1, . . . , ap], the vectors
H, HF, . . . , HFp−1 are linearly independent if and only if the determinant
D =
2222222222
a1 a1λ1 · · · a1λp−1
1
a2 a2λ2 · · · a2λp−1
2
...
...
...
...
ap apλp · · · apλp−1
p
2222222222
is non-zero. This determinant is equal to D = (a1a2 · · · ap)pV , where V is the
Vandermonde determinant. Hence
D =
p
-
i=1
ap
i
-
1≤i,j≤p
(λj −λi),
where λ1, . . . , λp are the eigenvalues of F. For a discussion of this determinant
and details on its evaluation see Horn and Johnson (2013).
It follows that D ̸= 0, if and only if a1, . . . , ap ̸= 0 and λi ̸= λj, for i ̸= j
(F has distinct eigenvalues). In this case system (8.80a)–(8.80b) is observable,
since linear independence of the row vectors H, HF, . . . , HFp−1 implies that
the observability matrix O is of full rank p.
2. From the proof of Theorem 8.7 if follows that the discrete-time time-invariant
system
xk+1 = Fxk,
yk = Hxk,

8.4
Continuous-Time Kalman Filter
451
is observable if and only if the observability matrix
O =
⎡
⎢⎢⎢⎣
H
HF
...
HFp−1
⎤
⎥⎥⎥⎦
has full rank p. The proof of this is already done in the proof of Theorem 8.7,
if we equate F∗with F and write xk = x(kt) and yk = y(kt). A further
discussion on the observability for discrete-time state space models is discussed
in Sect. 3.5.1.
As we have seen in Sect. 8.4.2 if a linear time-invariant system is asymptotically
stable and it has a zero state covariance matrix Z = 0, then the limit of the error
covariance matrix P(t) is the zero matrix P = 0. Additionally, in Sect. 8.4.2 it was
shown that if Z = 0 and the state matrix F has eigenvalues with positive real parts
(unstable system), then the error covariance matrix P(t) convergences to a non-zero
limit matrix P ̸= 0.
Example 8.14 shows that in an unstable, linear time-invariant system, the limit of
P(t) exists and is equal to P > 0 (strictly positive deﬁnite symmetric matrix). For
this example, the convergenceof the error covariance matrix is illustrated in Fig. 8.6.
For linear systems, since the Kalman–Bucy ﬁlter inception, the convergence of
P(t) is studied extensively, see e.g. Kalman and Bucy (1961), Jazwinski (1969),
Jazwinski (1970), Fitzgerald (1971) and Anderson and Moore (1979) among others.
Restricting our attention to linear time-invariant systems, the following theorem
gives the main result; more extensive convergence results for time-varying systems
are provided in the references above.
Theorem 8.8 Consider the single output (y(t) being a scalar output) linear time-
invariant system (8.59a)–(8.59b), where the components F(t) = F, H(t) = H,
Z(t) = Z and (t) = σ 2 are time-invariant (hence the system is a time-invariant
linear system). Consider the error structure and prior information as in Theorem 8.6
and assume that the system is observable. With these assumptions in place the limit
of the error covariance matrix P(t) exists, i.e.
lim
t→∞P(t) = P
and is independent of the prior covariance matrix P(t0).
Proof We shall discretise the continuous-time system (8.59a)–(8.59b) as in the
proof of Theorem 8.6. The discrete-time system has measurements yk = y(kt)
and states xk = x(kt), where t = tk+1 −tk and k = 0, 1, 2, . . .. The discrete
system is given by (8.22a)–(8.22b), see Sect. 8.2.4 for a full description of the
discrete system.

452
8
Dynamic Systems and Control
We establish that for the discrete-time system above, the limit of its error
covariance matrix Pk exists limk→∞Pk = P and is independent of P0 = P(t0). To
prove this ﬁrst note that since the continuous-time system is observable, it follows
that the discrete-time system is observable too (see point (2) on p. 450). Secondly
the discrete-time system is a time-invariant system too and as such limk→∞Pk = P;
for the proof of this see Theorem 3.7 in Sect. 3.5.3.
Returning now to the continuous-time system (8.59a)–(8.59b) we have
lim
t→∞P(t) = lim
k→∞lim
t→0 Pk = lim
t→0 lim
k→∞Pk = P,
which does not depend on P(t0).
⊓⊔
Some comments are in order. Under the assumptions of Theorem 8.8, the Kalman
gain K(t) also converges to a limit K, i.e. limt→∞K(t) = limt→∞P(t)H ⊤/σ 2 =
PH ⊤/σ 2 = K. From the Kalman–Bucy ﬁlter (Theorem 8.6) the limiting value P
may be computed by solving the algebraic Riccati equation
FP + PF⊤−PH ⊤HP/σ 2 + Z = 0.
(8.83)
If we replace K(t) by its limit K In the state differential equation of ˆx(t)
(Theorem 8.8) we obtain the steady state differential equation as
˙ˆx(t) = Fx(t) + K[y(t) −H ˆx(t)]
= (F −KH ⊤)ˆx(t) + Ky(t).
This representation has the important implication that, from Theorem 8.2 the
solution of the state differential equation is
x(t) = e(F−KH ⊤)(t−t0)x(t0) +
" t
t0
e(F−KH ⊤)(t−τ)Ky(τ) τ.
The steady state of a system is very useful consideration as it expedites considerably
the computation, as P(t) and K are only computed once. Furthermore, the task of
solving the differential equation of P(t) is reduced to solving the algebraic Riccati
equation (8.83). These considerations might be helpful in particular when both Z
and H are non-zero, in which case the algebraic Riccati equation (8.83) can be
solved using numerical methods.
These results complement convergence results and the steady state of discrete-
time models discussed in some detail in Sect. 3.5.3. (see also Sect. 3.5.2 for steady
state of the local level model). For discrete-time systems convergence of Riccati
algebraic equations are studied in Chan et al. (1984), see also Anderson and Moore
(1979) and Sect. 3.5.3 of this book.

8.4
Continuous-Time Kalman Filter
453
8.4.4
Extended Kalman–Bucy Filter
Systems considered earlier in Sects. 8.4.1,8.4.2 and 8.4.3 are linear systems. These
systems enable the optimal estimation of the states, using the Kalman-Buce ﬁlter
and under the assumption of observability the convergence of the error covariance
system leads to the steady state of the system. However, many systems are non-
linear; some examples are discussed in Sect. 8.3.3, see also Sastry (1999), Zinober
(2001), Hirsch et al. (2012) and Ding (2013) among others. The problem of lack
of linearity and Gaussianity in the Kalman–Bucy ﬁlter was ﬁrst realised by S. F.
Schmidt and his team who were working on applying the Kalman ﬁlter for the
Apollo project. A historical perspective of the Kalman ﬁlter and its application
to the Apollo project is provided in Grewal and Andrews (2010). These authors
discuss how Schmidt’s team realised the limitations of applying the Kalman–Bucy
ﬁlter in the presence of non-linearities. Schmidt’s team proposed linearising the
non-linear system and reported excellent tracking performance, which beneﬁtted
the Apollo project and helped the widespread application and utility of the Kalman-
Busy ﬁlter. Schmidt has written an account of events led his team discovering the
extended Kalman ﬁlter, see Schmidt (1981) and McGee and Schmidt (1985). Since
then the so-called extended Kalman ﬁlter has been used extensively as reported in
Kappl (1971), Ljung (1979), Morris and Sterling (1979), Schmidt (1981), McGee
and Schmidt (1985), Grewal et al. (1991), Grewal and Andrews (2015) and in
the references therein. We remark that in this book, in Sect. 8.3.3.1 we have
already described linearising a non-linear system, in the context of Lyapunov’s
indirect method of stability. The extended Kalman ﬁlter for discrete-time systems
is discussed in Sect. 6.6. In this section we describe the basic form of the extended
Kalman ﬁlter for continuous-time systems.
Consider a non-linear system, which states x(t) are generated by a non-linear
differential equation inﬂated with noise ζ(t), or
˙x(t) = f (x(t), ζ(t)),
(8.84)
where ζ(t) is a white noise process, which may be assumed to be Gaussian, with
covariance matrix Z(t).
The measurements y(t) are assumed to follow a linear equation
y(t) = H(t)x(t) + ϵ(t),
(8.85)
where ϵ(t) is a Gaussian white noise process with covariance matrix (t). This
system assumes innovations (process and measurement) ζ(t) and ϵ(t) to satisfy
conditions (8.60)–(8.61). It is also assumed that x0 follows a Gaussian prior
distribution as in (8.62). Equations (8.84)–(8.85) deﬁne a non-linear system, which
measurements follow a linear relationship. It is possible to extend the system to
having measurements, which are linked to the states with a non-linear equation too,
but here for simplicity we assume linearity in (8.85).

454
8
Dynamic Systems and Control
Motivated from the state differential equation of the Kalman–Bucy ﬁlter we
consider the non-linear
˙ˆx(t) = f (ˆx(t), ζ(t) = 0) + K(t)[y(t) −H(t)ˆx(t)],
(8.86)
where ˆx(t) is the estimator of x(t)/ Note that, if f (x, ζ) is a linear function in x
and ζ, then systems (8.84)–(8.85) are reduced to a linear model and in this case the
proposed state differential equation (8.86) reduced to (8.63) (Kalman–Bucy ﬁlter,
see Theorem 8.6).
The error we make when considering (8.86) is
e(t) = x(t) −ˆx(t)
which by (8.86) is
˙e(t) = ˙x −˙ˆx(t)
= f (x(t), ζ(t)) −f (ˆx(t), 0) −K(t)[y(t) −H(t)ˆx(t)]
= F(e(t), ˆx(t), ζ(t)) −K(t)H(t)e(t),
(8.87)
where F(e(t), ˆx(t), ζ(t)) = (x(t), ζ(t)) −f (ˆx(t), 0).
We linearise (8.87) around current estimate ˆx(t)
˙e(t) = F(0, ˆx(t), 0) + ∂F
∂e
2222
(e,x,ζ)=(0,ˆx,0)
e(t) + ∂F
∂ζ
2222
(e,x,ζ)=(0,ˆx,0)
ζ(t) −K(t)H(t)e(t)
= ¯F(t)e(t) + ˜F(t)ζ(t) −K(t)H(t)e(t),
where F(0, ˆx(t), 0) = 0 and
¯F(t) = ∂F
∂e
2222
(e,x,ζ)=(0,ˆx,0)
= ∂f
∂x
2222
(x,ζ)=(ˆx,0)
˜F(t) = ∂F
∂ζ
2222
(e,x,ζ)=(0,ˆx,0)
= ∂f
∂ζ
2222
(x,ζ)=(ˆx,0)
.
With this approximation in place the extended Kalman ﬁlter differential equations
are
˙ˆx(t) = f (ˆx(t), 0) + K(t)[y(t) −H(t)ˆx(t)],
(8.88)
K(t) = P(t)H⊤(t)(t)−1,
(8.89)
˙P(t) = ¯F(t)P(t) + P(t)¯F⊤(t) −P(t)H⊤(t)(t)−1H(t)P(t) + ˜F(t)Z(t)˜F(t)⊤.
(8.90)

8.5
Feedback Control
455
Some comments are in order.
1. If f (x(t), ζ(t)) = F(t)x(t) + ζ(t), where here F(t) is a system matrix, then
(8.88)–(8.90) reduce to the Kalman–Bucy ﬁltering equations (see Theorem 8.6).
2. It is possible to incorporate a non-linear function in the measurement equation
(8.85) so that
y(t) = h(x(t), ϵ(t)).
In this case the resulting ﬁlter includes the partial derivatives
∂h
∂x
2222
(x,ϵ)=( ˆx,0)
and
∂h
∂ϵ
2222
(x,ϵ)=( ˆx,0)
evaluated at the current estimate ˆx(t) and ϵ = 0.
3. In this section we considered the continuous-time extended Kalman ﬁlter. In the
discrete-time extended Kalman ﬁlter, discussed in Sect. 6.6, ﬁrst we compute
estimated states ˆxk at point kt and then ∂f/∂x, ∂f/∂ζ are evaluated at ˆxk. This
means that
∂f
∂x
2222
x=ˆxk
and
∂f
∂ζ
2222
x=ˆxk
are used in order to compute ˆxk+1 at point (k + 1)t. As a result, in the discrete-
time version we can compute the sequence ˆx1, . . . , ˆxk, . . . sequentially. This is
considerably simpler and more efﬁcient compared to the continuous-time system,
where ¯F(t), ˜F(t) are combined in the differential equations (8.88)–(8.90) and
cannot be computed separately. This observation suggests the extended Kalman
ﬁlter for the continuous-time system is not very practical. In applications the
continuous-time system is ﬁrst discretised and then the discrete-time extended
Kalman ﬁlter is used.
8.5
Feedback Control
In this section we discuss feedback control, an essential part of practicing dynamic
systems in engineering, see e.g. Biernson (1989), Zinober (2001), Tokhi and Azad
(2008), Johnson and Moradi (2010), Stevens et al. (2016), Graf (2016) and Franklin
et al. (2018) among others. We start by describing the basic framework of control
and in particular of the popular proportional,integral, derivative controller, known as
PID-controller (Franklin et al., 2018). Section 8.5.2 gives an illustration of control,
for a twin rotor experimental rig, which can be used to test aircraft movement
stability.

456
8
Dynamic Systems and Control
8.5.1
The PID-Controller
Consider a continuous-time system (8.9)–(8.10) , which might be single input single
output (SISO) or multiple input multiple output (MIMO). In this section we shall be
concerned with univariate measurements, or that the output y(t) is scalar. Feedback
control for MIMO systems is more challenging, because output variables may
interact. In many situations the output y(t) is measured subject to considerable noise
or other undesirable effects, e.g. long-term oscillations or instabilities reﬂecting
large uncertainty. Figure 8.7 plots simulated stable process (panel (a)) and unstable
process (panel (b)) together with the desirable or reference output indicated by the
straight lines in each panel. We see that the stable process in (a) after the ﬁrst 20
points is rather close to the reference output (ﬁxed at x = 20, whereas the process
Stable process
Time
x
0
10
20
30
40
10
12
14
16
18
20
Unstable process
Time
y
0
10
20
30
40
10
15
20
25
b
a
Fig. 8.7 Example of stable process (a) and unstable process (b). The reference signal is denoted
in both cases with the red line

8.5
Feedback Control
457
in (b) exhibits considerable instability with high levels of noise around the reference
mark of y = 20.
Control theory studies a mathematical device, known as controller, which
enables the process stabilisation starting from a process that would be unstable
if no action is taken. There are effectively two kinds of control under which a
controller may operate: open loop and closed loop. A simple example of control
is the house-boiler which provides a household with heating. The boiler may be
activated manually whenever heating is needed. In this case there is no control and
the temperature can reach high levels or low levels and only manual interventions
can be made. If a timer is used, heating is turned on automatically at a speciﬁc
duration, e.g. in the morning or at night. A system operating with the timer is an
example of open-loop control. The boiler turns on / off according to a pre-speciﬁed
setting, which does not depend on the amount of heating in the building. If there is
a thermostat used, then the boiler is automatically turned on when the temperature
is below some pre-speciﬁed level, say 18◦C. In this case, the temperature of the
building is fed back to the boiler and the boiler will stop when the temperature of
18◦C is reached. This is an example of a closed-loop feedback control, in which the
amount of heating in the building is fed into the boiler via the thermostat. Closed-
loop feedback control is met in many engineering designs, as the amount of the
output signal is fed back into the system. Below we shall brieﬂy describe the PID-
controller, which is perhaps one of the most popular controllers used.
The set-point or reference output denoted by r(t) is a desired signal, which the
system aim to get close to. Hence we can measure the error e(t) as the difference of
the output y(t) from our system from the reference signal, i.e. e(t) = r(t) −y(t). If
e(t) = 0, then we have achieved the desired signal and there is no need for control.
If e(t) is large in absolute value, then a control signal u(t) is deployed. The popular
PID-controller is deﬁned as a function of e(t) and given by
u(t) = kpe(t) + ki
" t
0
e(τ) dτ + kd
de(t)
dt
,
(8.91)
where kp, ki and kd are constants. This control comprises three elements, the
proportional one kpe(t) (P), the integral one ki
* t
0 e(τ) dτ (I) and the derivative one
kdde/dt (D), hence the name PID-controller. Equation (8.91) can be written as
u(t) = kp

e(t) + 1
Ti
" t
0
e(τ) dτ + Td
de(t)
dt

,
(8.92)
where Ti is known as the integral time and Td as the derivative time, with ki =
kp/Ti, kpTd = kd.
The proportional term works in a similar way as the term K(t)[y(t) −H(t)ˆx(t)]
of Eq. (8.63) in the Kalman–Bucy ﬁlter (see Theorem 8.6). It aims to move the
output towards minimising the error e(t). If we set ki = 0 and kd = 0, then the
controller includes only the P term, but this is frequently not enough as the output
signal can oscillate retaining always a constant error e(t). The I term improves the

458
8
Dynamic Systems and Control
controller as it basically sums the errors over time. It has the property that if we
use the P and I terms together, the process output agrees with the reference when
the system reaches the steady state. This argument can be shown as follows. Assume
that the system at time ts has reached the stead state, so that u(t) = us and e(t) = es,
for an t ≥ts. We shall prove this argument by the method of contradiction. Assume
that es ̸= 0. Then from (8.91) we have
us = kpes + ki
" t
0
es dτ = kpes + kiest.
In this equation, the right hand side us is time-invariant (as the system is in steady
state) and the right hand side depends on t, which is a contradiction. Hence it must
be es = 0. The D part of the controller can improve stability in the transient
state. The constants kp, ki and kd can be tuned so as to maximise the efﬁciency
of the algorithm or minimise e(t) for short time path. PID feedback control exhibits
notable similarities to the discrete-based feedback adjustment in process monitoring
as described in Box et al. (2009) and Triantafyllopoulos et al. (2005).
The following diagram schematically illustrates the feedback control algorithm.
At a particular time, y is available and with the reference signal r e is computed.
This is then entered into the PID-controller and the control signal u is computed
using (8.91). This is then inputted into the system and the signal y is produced. This
is then ﬁltered via the measurements and fed back into the node so as the new value
of e is computed and so forth.
Controller
System
u
Measurements
r
e
x
−
y
Consider a continuous-time linear system (8.4.2)–(8.4.2) and assume that the
system is time-invariant, i.e.
˙x(t) = Fx(t) + Gu(t)
and
y(t) = Hx(t),
(8.93)
where the innovations ζ(t) and ϵ(t) are set to be zero with probability one. Here
we assume that y(t) is scalar, hence H is a row vector. Suppose we are applying
the above PID feedback control. Write Y(s), X(s), U(s), R(s), E(s) the Laplace
transforms of y(t), x(t), u(t), r(t), e(t) and C(s), M(s) are the transfer functions
of ut (the controller) and y(t) (measurements), respectively. For a discussion of
Laplace transforms and transfer functions see Sect. 8.1.3.

8.5
Feedback Control
459
From properties of the Laplace transform (Sect. 8.1.3) we have
Y(s) = X(s)U(s)
(8.94)
U(s) = C(s)E(s)
(8.95)
E(s) = R(s) −M(s)Y(s).
(8.96)
From (8.94) and (8.95) we have
E(s) =
Y(s)
X(s)C(s),
which is put to (8.96) to give the solution
Y(s) =
X(s)C(s)
1 + X(s)C(s)M(s)R(s).
(8.97)
Hence the transfer function of the closed-loop feedback control is
H(s) =
X(s)C(s)
1 + X(s)C(s)M(s).
Fine tuning of the constants kp, ki, kd is required for the feedback control to work
properly. The example gives an illustration for the choice of these constants leading
to perfect control.
Example 8.16 Consider the ﬁrst-order linear system (8.93), where F, G and H =
G/F are scalars. The transfer function H (X)(s) of x(t) and the transfer function
H (Y)(s) of y(t) are
H (X)(s) =
G
s −F =
A
1 + sT
and
H (Y)(s) =
1
1 + sT ,
where T = −1/F, A = GF −1 and F ̸= 0. From (8.91) if we take the Laplace
transform we have
U(s) = C(s)E(s) =

kp + ki
1
s + kds
	
E(s)
= k

1 + 1
sTi
	
(1 + sTd)E(s),
where Ti and Td are the integral and derivative times, deﬁned in (8.92) and k is a
constant. By expanding this it follows that
kp = k

1 + Td
Ti
	
,
ki = k
Ti
and
kd = kTd.

460
8
Dynamic Systems and Control
We will show that if we choose k = A−1, Ti = T and Td = T , then the control is
perfect so that e(t) = 0. To this end we need to show y(t) = r(t) or Y(s) = R(s).
From (8.97) we need to show 1 + C(s)X(c)M(s) = X(s)C(s), or
M(s) = 1 −
1
C(s)X(s).
With the values of k, Ti and Td stated above, we have
1 −
1
C(s)X(s) = 1 −

 1
A

1 + 1
sT
	
(1 + sT )
A
1 + sT
−1
=
1
1 + sT = M(s)
and so y(t) = r(t).
8.5.2
Twin Rotor Static Rig for Air-Vehicle Testing
In this section we give an illustration of closed-loop feedback control, based on
Triantafyllopoulos et al. (2009). The experimental rig is a twin rotor multi-input
multi-output platform, designed by FeedbackInstruments (1996) for experimental
use. The platform has many similarities with the motion of the normal helicopter
and as a result it can be used as a static-platform for the design and testing of air-
vehicles (Seddon & Newman, 2011).
The platform, which is schematically shown in Fig. 8.8, consists of a beam
pivoted on its base in such a way that it can rotate freely in both the horizontal
and vertical planes. At both ends of the beam there are two rotors, the main and
tail rotors, driven by DC motors. The rotation of the main rotor produces a lifting
Fig. 8.8 Schematic illustration of the twin rotor MIMO system

8.5
Feedback Control
461
force allowing the beam to rise vertically making a rotation around pitch axis. This
vertical movement of the beam makes an elevation angle with respect to pitch plane.
While, the tail rotor which is smaller than the main rotor is used to make the beam
turn left or right around yaw axis producing a rotational angle . A counterbalance
arm with a weight at its end is ﬁxed to the beam at the pivot. The state of the beam
is described by four process variables: horizontal and vertical angles measured by
position sensors ﬁtted at the pivot, and two corresponding angular velocities. Either
or both axes of rotation can be locked by means of two locking screws, provided for
physically restricting the horizontal or vertical plane TRMS rotation.
In a normal helicopter, changing the angle of attack of the blades controls the
aerodynamic force. However, the TRMS is constructed in such a way that the angle
of attack is ﬁxed. In this case, the aerodynamic force is controlled by varying the
speed of the DC motors. Therefore, the control inputs are supply voltages of the DC
motors. A change in the voltage value results in a change of the rotational speed of
the propeller, which in turn results in a change of the corresponding position of the
beam . The input voltage is limited to ±10 volts.
The experimental designed by FeedbackInstruments (1996), is shown in Fig. 8.9
and was used by our colleagues within the Department of Automatic Control and
Systems Engineering at the University of Shefﬁeld. We can see the beam with the
two rotors, the DC adaptor and the PC, controlling the voltage that can be inputted
in order to activate the system.
A number of studies published for this experimental set-up include Ahmad et al.
(2001), Ahmad et al. (2002) and Chalupa et al. (2015) among others. In this study
we have focused on a single input u(t) (in voltage) and a single output y(t), which
Fig. 8.9 The twin rotor experimental rig used at Shefﬁeld University

462
8
Dynamic Systems and Control
1.7
1.8
1.9
2.0
2.1
Input
0.2
0.4
0.6
0.8
1.0
0
200
400
600
800
1000
Output
Time
TRMS data
Fig. 8.10 Data from the TRMS system. Top panel shows the input (in volts) and the lower panel
shows the output values, sampled every 10 s
is the motion of the tail rotor, translated in voltage too and recorded in the computer
using the MATLAB/SIMULINK package. The system has the capability to act as a
single rotor device (as we use it here) or as originally constructed as a twin rotor.
The tail rotor used is indicated in Fig. 8.9 by the orange indicators (if seen in black
and white is the rotor near the wall).
Figure 8.10 plots the data (1000 time points with a sample frequency of 10 s).
The top panel of the plot shows the input signal and the bottom panel shows the
output. The plot suggests that the output appears to be unstable, with oscillations
repeated randomly.
A linear system is adopted and is described in the sequel. The continuous-
time system is discretized using tk = k = 10k, for k = 0, 1, . . .. Following
Triantafyllopoulos et al. (2009) we adopt a linear regression model, with time-
varying components for yk = y(tk)
yk =
8

i=1
yk−ixi +
8

j=1
uk−jxj + ϵk,

8.5
Feedback Control
463
where x1, . . . , x16 are time-invariant coefﬁcients and ϵk is a Gaussian white noise
with variance σ 2, which is assumed to be uncorrelated of xi. This model can be put
in state space form
yk = Hkx + ϵk,
ϵk ∼N(0, σ 2),
(8.98)
where Hk = [yk−1, . . . , yk−8, uk−1, . . . , uk−8] and x = [x1, . . . , x16]⊤is the state
vector.
In the ﬁrst phase of analysis we ﬁt this model to the data. After some experimen-
tation we chose to include 8 lagged terms yk−i and uk−j. Our criteria of goodness of
ﬁt were to minimise the mean squared error (MSE) and maximise the log-likelihood
function. The variance of σ 2 was estimated using the Bayesian conjugate approach
of Sect. 4.3.3. We have implemented the model with a time-varying state vector
xk = Fxk−1 + ζt, but that introduced more ﬂuctuations on the predictions of yk,
while from Fig. 8.10 the output signal is clearly smooth. Hence we adopt model
(8.98). Figure 8.11 shows the one-step ahead forecast errors (left panel) and the
One-step forecast errors
Time
Forecast error
0
200
400
600
800
-0.02
-0.01
0.00
0.01
0.02
0.03
0.04
0.05
Mean squared error (MSE)
Time
MSE
0
200
400
600
800
0.00
0.01
0.02
0.03
0.04
0.05
Fig. 8.11 One-step forecast errors (left panel) and mean squared error plotted over time (right
panel)

464
8
Dynamic Systems and Control
MSE over time. We see that excluding the ﬁrst few errors, they are small with range
between ±0.02 and the MSE is low tending to zero (for example, for k = 200, the
MSE is 0.0017. The average value of the MSE is 0.0024. The overall mean absolute
deviation (MAD) is equal to 0.0089. We conclude that the performance of the model
is very good indicating that (8.98) is a good representation of the system.
The next phase of the analysis is to see whether the system will beneﬁt by
adopting a feedback control strategy. For this to end we have instructed a step-signal
as a reference signal and run the model with no feedback incorporated. Figure 8.12
plots the amplitude of the signal y(t) together with the reference signal, for an open-
loop system (no feedback control). We see that the signal oscillates persistently
indicating lack of stability and only reaches steady state after considerable time. The
vibration of the TRMS dominates the system indicating poor tracking performance
of the open-loop approach. Next we apply the closed-loop feedback control using
the PID-controller described in Sect. 8.5.1.
The performance of the feedback controller is assessed in terms of time domain
performance objectives (overshoot, rise-time, settling-time and steady state error) in
comparison to system performance in the open loop without control. The controlled
output (elevation angle) is expected to have low overshoot, quick settling time of
the residual oscillation and reasonably fast speed of response. Figure 8.13 shows
the amplitude of the signal against the reference signal when feedback control is
applied. The controller demonstrates superior performance in comparison to the
system response without controller (i.e. open-loop conﬁguration) in tracking the
Fig. 8.12 Open-loop system response (no feedback control is applied). The step function indicates
the reference signal

8.6
Exercises
465
0
20
40
60
80
100
-0.2
0
0.2
0.4
0.6
0.8
1
1.2
Time (sec)
Amplitudes
 
 
Refernce signal
Sys response with PID
Fig. 8.13 Closed-loop system response (feedback control is applied). The step function indicates
the reference signal
reference signal. Its response was characterised by relatively small overshoot, fast
rise time and consistent settling time. A smooth system response was observed with
no signiﬁcant overshoot (0.039%) and fast rise time of 6.93 s. The system response
with this controller settled within 12.77 s with a steady state error of 2.02% recorded
at the settling time. The system paired with the closed-loop feedback controller
returns a smooth signal and is clearly a stable system.
8.6
Exercises
1. a. Show that the Laplace transform of f (t) = e−attn is
L[f (t)](s) =
n!
(s + a)n+1 ,
for Re(s) > −a.
b. Show that the Laplace transform of g(t) = e−at sin(ωt) is
L[g(t)](s) =
ω
(s + a)2 + ω2 ,
where Re(s) > −a.

466
8
Dynamic Systems and Control
2. Consider the linear system having the state space representation
˙x = Fx + Gu
and
y = Hx,
for some known components F, G and H.
Deﬁne the state z = Px, where P is a non-non-singular square matrix. Find
a state space representation of y using the state z, i.e.
˙z = F∗z + G∗u
and
y = H∗z,
and identify the components F∗, G∗and H∗.
3. Consider the continuous-time linear system
˙x(t) = F(t)x(t) + G(t)u(t) + ζ(t),
y(t) = H(t)x(t) + L(t)u(t) + ϵ(t),
where u(t) is the input of the system, y(t) is the output of the system and
the components F(t), G(t), L(t) and L(t) are assumed known functions.
Suppose that the input functions are generated by the differential equation
˙u(t) = φx(t) + ψ, for some constants φ and ψ. Deﬁne the state vector
x∗(t) =

 x(t)
u(t)

.
Find a state space representation of the system using the state vector x∗(t), i.e.
˙x∗(t) = F∗(t)x∗(t) + ζ ∗(t),
y(t) = H∗(t)x∗(t) + ϵ∗(t),
and identify the components F∗(t), H∗(t) and deﬁne the innovation functions
ζ ∗(t) and ϵ∗(t). Hence show that by using the state vector x∗(t) you can
incorporate the input u(t) into the states.
4. Consider the linear system
˙x =
⎡
⎣
1 0
0
0 −1 0
0 0 −4
⎤
⎦x +
⎡
⎣
1 −2
−1 1
0
1
⎤
⎦u,
y = [0, 1, 1]x,
where x = [x1, x2, x3]⊤is the state vector and u = [u1, u2]⊤is a vector of
inputs.

8.6
Exercises
467
a. Show that the system is not stable.
b. Deﬁne the state
z =

 x2
x3

.
Find a state space representation for the system using the state vector z and
show that this system is stable.
5. Consider the matrix exponential of some square matrix F deﬁned as
eF =
∞

n=0
Fn
n! .
a. Show that
(eF)⊤= eF⊤.
b. If F and G are p × p matrices, show that in general
eF+G ̸= eFeG.
6. A vehicle experiencing force f (t) = ma(t) in the interval t0, T ], where m is
the mass of the vehicle, for some bivariate vector a. If p(t) = [p1(t), p2(t)]⊤
denotes the position of the vehicle at time t with coordinates p1(t) and p2(t),
then the system is described by the following differential equation
dp(t)
dt
= f
m.
(8.99)
a. Show that the general solution of (8.99), with initial conditions p(t0) and
˙p(t0) is given by
p(t) = p(t0) + ˙p(t0)(t −t0) + 1
m
" t
t0
" s
t0
f (τ) dτ ds.
b. Deﬁne the state vector
x(t) =
⎡
⎢⎢⎣
˙p1(t)
˙p2(t)
p1(t)
p2(t)
⎤
⎥⎥⎦.

468
8
Dynamic Systems and Control
Find a state space representation of the system with measurements p(t) and
states x(t), i.e. write the system in the form
˙x(t) = Fx(t) + Gu(t),
p(t) = Hx(t)
and identify the components F, G, H and the input function u(t).
7. Consider a RC electric circuit, consisting of a voltage source or battery (V),
capacitor (C) and a resistor (R), all serially connected; for a circuit diagram see
Fig. 8.14. Let u(t) be the total voltage of the battery and x(t) be the voltage of
the capacitor, where R is the effective resistance of the combined load, source
and component and C is the capacitance.
a. Use Kirchhoff’s second law (total voltage) to derive the differential equation
˙x(t) = −1
CR x(t) +
1
CR u(t).
(8.100)
b. If the output y(t) = x(t) is the voltage of the capacitor, write down a state
space representation of this system.
c. Show that this system is stable.
d. Suppose that the input voltage u(t) follows the sinusoidal function
u(t) = A sin ωt,
where A is the amplitude and ω is the angular frequency.
Fig. 8.14 RC electric circuit.
Shown are the voltage source
(V), the capacitor (C) and the
resistor (R), all serially
connected
C
R
V

8.6
Exercises
469
Show that the solution of (8.100) is
x(t) =

x(0) +
ACRω
1 + ω2C2R2

exp

−t
CR
	
+ A(sin ωt −CR cos ωt)
1 + ω2C2R2
.
Hence for large t, the output voltage of the capacitor is approximately equal
to
x(t) ≈A(sin ωt −CR cos ωt)
1 + ω2C2R2
.
8. Consider the linear system
˙x(t) =

 0 −1
2 −2

x(t)
and
y(t) = [1, 1]x(t),
with
x(0) =

 x1(0)
x2(0)

.
a. Without making reference to part (b) below, show that this system is
asymptotically stable.
b. Find the eigenvalues and eigenvectors of
F =

 0 −1
2 −2

and use Eq. (8.33) to show
eFt =

 2e−t −e−2t
−e−t + e−2t
2e−t −2e−2t −e−t + 2e−2t

.
c. Use (b) to derive the solution of the state differential equation as xt =
[x1(t), x2(t)]⊤, with
x1(t) = x1(0)(2e−t −e−2t) + x2(0)(−e−t + e−2t),
x2(t) = x1(0)(2e−t −2e−2t) + x2(0)(−e−t + 2e−2t),
hence verify the asymptotic stability of part (a) by taking the limit of x(t)
when t →∞.

470
8
Dynamic Systems and Control
9. Consider the linear system
˙x(t) =

 1 0
1 −1

x(t)
and
y(t) = [1, 1]x(t),
with
x(0) =

 x1(0)
x2(0)

.
a. Without making reference to part (b) below, show that this system is
unstable.
b. Follow a similar procedure as that of Exercise 9 to show that the solution of
xt = [x1(t), x2(t)]⊤is
x1(t) = x1(0)et,
x2(t) = x1(0)
2
et +

x2(0) −x1(0)
2
	
e−t.
10. Consider the non-linear system of Example 8.12 (p. 433). Show this system is
asymptotically stable using Lyapunov’s indirect method.
11. Consider the Lorenz system (8.49a)–(8.49c) of Example 8.13, with σ = 10,
ρ = 0.9 and β = 8/3. Using Lyapunov’s indirect method show that the system
is stable around the origin (x, y, z) = (0, 0, 0).
12. Consider the system generated by the non-linear differential equation
d2y(t)
dt2
= cos y(t) −3
2π y(t) −α dy(t)
dt
,
for some constant α.
a. Find the state space representation of this system.
b. Show that the equilibrium point of this system is xe = [π/3, 0]⊤, where
x = [x1, x2]⊤denotes the state vector of this system.
c. Identify the range of values of α, for which the system is asymptotically
stable around xe.
13. Consider the two-object system (8.18)–(8.19) of Example 8.6. Show that the
system is stable, but not asymptotically stable.
14. Consider the system generated by the differential equations
d2y1(t)
dt2
+ α1
dy1(t)
dt
+ α2y1(t) = u1 + α3u2
dy2(t)
dt
+ α4y2(t) + α3
y1(t)
dt
= α6u1,

8.6
Exercises
471
where u1, u2 are inputs, y1(t), y2(t) are the outputs and α1, α2, α3, α4, α5 and
α6 are known constants.
Deﬁne the state vector
x =
⎡
⎣
y1
˙y1
y2
⎤
⎦.
a. With y = [y1, y2]⊤the output vector, write down this system in state space
form, or
˙x = Fx + Gu,
y = Hx
and determine the matrices F, G, H and the input vector u.
b. If α2 ̸= 0 and α4 ̸= 0, show that the equilibrium point is
xe =

u1 + α3u2
α2
, 0, −α6u1
α4
⊤
.
c. If u1 = u2 = 0, α4 ̸= 0, α1, α2 > 0, show that
i. If α4 < 0, the system is asymptotically stable.
ii. If α4 > 0, the system is unstable.
15. Consider Example 8.9 of the spring-mass attached on a wall. Assume that the
position of the object attached to the spring observed subject to noise ϵ(t),
which satisﬁes the conditions of (8.60).
a. If k2
2 −4k1m < 0, where m is the mass of the spring and k1, k2 are the
friction coefﬁcient and the spring constant, respectively, then show that the
limit of the error covariance matrix (Kalman–Bucy ﬁlter) P(t) is the zero
matrix, as t →∞. Hence, show that ˆx(t), the estimate of x(t) at the steady
state satisﬁes
ˆx(t) =
∞

n=0
(t −t0)n
n!

 0
1
−k1 −k2
n
x(t0),
where x(t0) is the initial state vector.
b. If t0 = 0, k1 = 2, k2 = 3 and m = 2gr, then show ˆx(t) = [ˆx1(t), ˆx2(t)]⊤of
part (a) has components
ˆx1(t) = x1(0)(2e−3t −e−2t) + x2(0)(e−3t −e−2t),
ˆx2(t) = x1(0)(2e−2t −2e−3t) + x2(0)(2e−2t −e−3t),
where x(0) = [x1(0), x2(0)]⊤is the initial state vector.

472
8
Dynamic Systems and Control
16. Consider Example 8.14 and assume that observations y(t) = c are constant, for
some c.
a. Using P = limt→∞P(t) ﬁnd K the limit of the Kalman gain K(t) as t →
∞.
b. Using (a) show that the differential equation of x(t) at steady state satisﬁes
˙ˆx(t) = (F −KH)ˆx(t) + Kc.
c. Write

−1 3
0 1
n
=

 f11(n) f12(n)
f21(n) f22(n)

,
for some sequences fij (n). Show that the solution of the differential equation
of part (b) is given as an inﬁnite series
ˆx(t) = −2c
∞

n=0
tn
(n + 1)n!

 f11(n)
f21(n)

.
17. Consider the linear system
˙x(t) = −9x(t) + 3u(t),
(8.101)
y(t) = 3x(t),
(8.102)
for some input function u(t), state x(t) and output y(t).
a. Show that the transfer function of this system is
H(s) =
9
9 + s ,
where s ∈C.
b. Suppose now that measurements y(t) are observed subject to noise, hence
Eq. (8.101) is replaced by
y(t) = 3x(t) + ϵ(t),
ϵ(t) ∼N(0, 1),
(8.103)
where ϵ(t) satisﬁes condition (8.60). At time t0 = 0 let the initial distribution
of x(t0) be x(0) ∼N(1, 10) and assume that x is uncorrelated of ϵ(t), for
all t. Use the Kalman–Bucy ﬁlter to answer the following.
i. Show that the error variance P(t) is
P(t) =
10
6e18t −5

8.6
Exercises
473
and hence verify that P = limt→∞P(t) = 0. Justify P = 0, without
making reference of P(t) given above.
ii. If the input function is a step function
u(t) =

k,
tk ≤t < ∞
0,
otherwise
,
with k > 0, for some time tk > 0. Show that at steady state the estimate
of x(t) is given by
ˆx(t) = e−9t + k
3
%
1 −e9(tk−t)&
.
Hence show that as t →∞the estimate ˆx(t) of the state x(t) converges
to k/3.
18. Consider the linear system (8.101)–(8.103) of Exercise 17. The continuous-
time system is discretised using tk = kt, with k = 0, 1, . . . , N −1.
a. Simulate a path of xk and yk, for N = 100 and t = 0.2.
b. Using the discrete Kalman ﬁlter, provide the posterior distribution of xk,
given data y1:k.
c. Plot the posterior mean E(xk | y1:k) against the simulated values xk, for
k = 1, . . ., 99. Comment on the performance of this model based on this
plot.
19. Consider the continuous-time time-invariant system of Example 8.14.
a. Using Eq. (8.79) show that the stead-state differential equation is
˙ˆx(t) =

−1 3
0 1

ˆx(t) +

 2
0

y(t).
b. Diagonalise matrix

 −1 3
0 1

and hence show
exp
(
 −1 3
0 1

t
)
=

e−t 3
2et −3
2e−t
0
et

.

474
8
Dynamic Systems and Control
c. Use part (b) to show that with ˆx(t) = [ˆx1(t), ˆx2(t)]⊤, the solutions ˆx1(t) and
ˆx2(t) of the differential equation of part (a) satisfy
ˆx1(t) = e−t ˆx1(0) + 3
2(et −e−t)ˆx2(0) + 2
" t
0
eτ−ty(τ) dτ,
ˆx2(t) = et ˆx2(0),
where ˆx1(0) and ˆx2(0) are the initial estimates of x1(t) and x2(t) at t = 0,
where x(t) = [x1(t), x2(t)]⊤.
20. Consider the linear system
˙x1(t) = −x1(t) + 6x2(t),
˙x2(t) = −x1(t) + 4x2(t),
y(t) = x1(t) + x2(t) + ϵ(t),
where ϵ(t) ∼N(0, 1) and it satisﬁed the error structure (8.60)–(8.61). Assume
that the system is initialised at time t0 = 0 with error covariance matrix P(0) =
I.
a. Diagonalise the matrix
F =

 −1 6
−1 4

and show that
e−Fw =

3e−w −2e−2w −6e−w + 6e−2w
e−w −e−2w
−2e−w + 3e−2w

.
b. Using part (a) and the Kalman–Bucy ﬁlter determine the elements of P−1(t)
(the inverse of the error covariance matrix of xt = [x1(t), x2(t)]⊤).
c. Using (b) or otherwise show that the limit P of P(t) is
P = lim
t→∞P(t) = 1
8

17 11
11 9

.
d. Show that the solution of the state differential equation (at steady state) is
ˆx1(t) =
7
2e−2t −5
2e−t
	 
ˆx1(0) + 6
" t
0
e−2τy(τ) dτ −5
2
" t
0
e−τy(τ)

+

−5
2e−2t + 5
2e−t
	 
ˆx2(0) + 6
" t
0
e−2τy(τ) dτ −7
2
" t
0
e−τy(τ)


8.6
Exercises
475
and
ˆx2(t) =
7
2e−2t −7
2e−t
	 
ˆx1(0) + 6
" t
0
e−2τy(τ) dτ −5
2
" t
0
e−τy(τ)

+

−5
2e−2t + 7
2e−t
	 
ˆx2(0) + 6
" t
0
e−2τy(τ) dτ −7
2
" t
0
e−τy(τ)

,
where xt[x1(t), x2(t)]⊤and ˆx(0) = [ˆx1(0), ˆx2(0)]⊤is the initial estimate of
x(t).
21. Consider the one-dimensional linear system
˙x(t) = −cx(t) + ζ(t),
ζ(t) ∼N(0, σ 2
Z),
y(t) = ϵ(t),
ϵ(t) ∼N(0, σ 2
ϵ ),
where c > 0, the innovation functions ζ(t) and ϵ(t) satisfy assumptions (8.60)–
(8.61) and σ 2
Z, σ 2
ϵ are known positive variances.
a. Show that this system is asymptotically stable.
b. Show that the error variance is equal to
P(t) = σ 2
Z
2c +
 
P(t0) −σ 2
Z
2c
!
e−2c(t−t0),
where the system is initialised at t0, with error variance P(t0) > 0.
c. Using two different ways show that the limit P of P(t) is
P = lim
t→∞P(t) = σ 2
Z
2c .
d. Hence show that if P(t0) < σ 2
ϵ /(2c), then P(t) is increasing function; if
P(t0) > σ 2
ϵ /(2c), then P(t) is decreasing function; if P(t0) = σ 2
ϵ /(2c),
then P(t) = σ 2
ϵ /(2c), for all t ≥t0.

References
Adcock, C. J. (2007). Measuring portfolio performance using a modiﬁed measure of risk. Journal
of Asset Management, 7(6), 388–403.
Adcock, C. J. (2010). Asset pricing and portfolio selection based on the multivariate extended
skew-Student-t distribution. Annals of Operations Research, 176(1), 221–234.
Aguilar, O., & West, M. (2000). Bayesian dynamic factor models and portfolio allocation. Journal
of Business and Economic Statistics, 18(3), 338–357.
Ahmad, S. M., Chipperﬁeld, A. J., & Tokhi, M. O. (2001). Parametric modelling and dynamic
characterization of a two-degree-of-freedom twin-rotor multi-input multi-output system. Pro-
ceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering,
215(2), 63–78.
Ahmad, S. M., Chipperﬁeld, A. J., & Tokhi, M. O. (2002). Dynamic modelling and open-loop
control of a twin rotor multi-input multi-output system. Proceedings of the Institution of
Mechanical Engineers, Part I: Journal of Systems and Control Engineering, 216(6), 477–496.
Aidala, V. I. (1979). Kalman ﬁlter behaviour in bearings-only tracking applications. IEEE
Transactions on Aerospace and Electronic Systems, 15, 29–39.
Aldrich, J. (1998). Doing least squares: perspectives from Gauss and Yule. International Statistical
Review, 66, 61–81.
Anand, D. K. (1984). Introduction to control systems (2nd ed.). London: Pergamon Press.
Anderson, B. D. O. (1971). Stability properties of Kalman-Bucy ﬁlters. Journal of the Franklin
Institute, 291(2), 137–144.
Anderson, B. D. O., & Moore, J. B. (1979). Optimal ﬁltering. Englewood Cliffs, NJ: Prentice Hall.
Anderson, O. D. (1976). Time series analysis and forecasting: The Box-Jenkins approach.
Butterworths. Series R.
Andrieu, C., Doucet, A., & Holenstein, R. (2010). Particle Markov chain Monte Carlo methods.
Journal of the Royal Statistical Society Series B, 72(3), 269–342.
Angelova, D., & Mihaylova, L. (2008). Extended object tracking using Monte carlo methods. IEEE
Transactions on Signal Processing, 56(2), 825–832.
Applebaum, D. (2011). Lévy processes and stochastic calculus (2nd ed.). Cambridge: Cambridge
University Press.
Arnold, B. C., & Groeneveld, R. A. (1995). Measuring skewness with respect to the mode. The
American Statistician, 49, 34–38.
Asai, M., McAleer, M., & Yu, J. (2006). Multivariate stochastic volatility: a review. Economtric
Reviews, 25(2-3), 145–175.
Ass, K., & Haff, I. H. (2006). The generalised hyperbolic skew Student’s t-distribution. Journal of
Financial Econometrics, 4, 275–309.
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2021
K. Triantafyllopoulos, Bayesian Inference of State Space Models, Springer Texts
in Statistics, https://doi.org/10.1007/978-3-030-76124-0
477

478
References
Atkinson, A. C., Koopman, S. J., & Shephard, N. (1997). Detecting shocks: Outliers and breaks in
time series. Journal of Econometrics, 80(2), 387–422.
Azzalini, A., & Capitanio, A. (2003). Distributions generated by perturbation of symmetry with
emphasis on a multivariate skew t-distribution. Journal of the Royal Statistical Society Series
B, 65(2), 367–389.
Bacciotti, A. (2019). Stability and control of linear systems (Vol. 185). New York: Springer.
Bakshi, G., Kapadia, N., & Madan, D. (2003). Stock return characteristics, skew laws and the
differential pricing of individual equity options. The Review of Financial Studies, 16(1), 101–
143.
Balakrishnan, A. V. (1984). Kalman ﬁltering theory. New York: Optimization Software Inc.
Barndorff-Nielsen, O., & Schou, G. (1973). On the parameterization of autoregressive models by
partial autocorrelations. Journal of Multivariate Analysis, 3, 408–419.
Bäuerle, N., & Li, Z. (2013). Optimal portfolios for ﬁnancial markets with Wishart volatility.
Journal of Applied Probability, 50(4), 1025–1043.
Bauwens, L., Laurent, S., & Rombouts, J. V. K. (2006). Multivariate GARCH models: a survey.
Journal of Applied Econometrics, 21, 79–109.
Beach, C. M., & MacKinnon, J. G. (1978). A maximum likelihood procedure for regression with
autocorrelated errors. Econometrica, 46, 51–58.
Beck, N. (1983). Time-varying parameter regression models. American Journal of Political
Science, 27, 557–600.
Bersimis, S., Psarakis, S., & Panaretos, J. (2007). Multivariate statistical process control charts: an
overview. Quality and Reliability Engineering International, 23(5), 517–543.
Bersimis, S., & Triantafyllopoulos, K. (2020). Dynamic non-parametric monitoring of air-quality.
Methodology and Computing in Applied Probability, 22, 1457–1479.
Berzuini, C., & Gilks, W. (2001). Sequential Monte Carlo methods in practice. In A. Doucet, N. de
Freitas, & N. Gordon (Eds.), Statistics for engineering and information science (pp. 117–138).
New York: Springer.
Biernson, G. (1989). Principles of feedback control: Feedback system design. New York: Wiley.
Bingham, N. H., & Fry, J. M. (2010). Regression: Linear models in statistics. New York: Springer.
Bingham, N. H., & Kiesel, R. (2002). Semi-parametric modelling in ﬁnance: theoretical founda-
tions. Quantitative Finance, 2, 241–250.
Bingham, N. H., & Kiesel, R. (2004). Risk-neutral valuation: Pricing and hedging of ﬁnancial
derivatives (2nd ed.). New York: Springer.
Bollerslev, T. (1986). Generalized autoregressive conditional heteroskedasticity. Journal of Econo-
metrics, 31, 307–327.
Bollerslev, T. (1990). Modelling the coherence in short-run nominal exchange rates: A multivariate
generalized Arch model. The Review of Economics and Statistics, 72(3), 498–505.
Box, G. E. P., Jenkins, G. M., & Reinsel, G. C. (2008). Time series analysis: Forecasting and
control (4th ed.). New York: Wiley.
Box, G. E. P., Luceño, A., & del Carmen Paniagua-Quinones, M. (2009). Statistical control by
monitoring and adjustment (2nd ed.). New York: Wiley.
Brandt, M. W., & Santa-Clara, P. (2006). Dynamic portfolio selection by augmenting the asset
space. The Journal of Finance, 61, 2187–2217.
Brockwell, P. J., & Davis, R. A. (1991). Time series: Theory and methods (2nd ed.). New York:
Springer.
Brockwell, P. J., & Davis, R. A. (2016). Introduction to time series and forecasting (3rd ed.). New
York: Springer.
Brown, R. G. (1962). Smoothing, forecasting and prediction of discrete time series. Englewood
Cliffs, NJ: Prentice-Hall.
Bru, M. (1991). Wishart processes. Journal of Theoretical Probability, 4, 725–751.
Büuhler, W. K. (1981). Gauss: A biographical study. New York: Springer.
Carlin, B. P., Polson, N. G., & Stoffer, D. S. (1992). A Monte Carlo approach to nonnormal and
nonlinear state-space modeling. Journal of the American Statistical Association, 87, 493–500.

References
479
Carter, C. K., & Kohn, R. (1994). On Gibbs sampling for state space models. Biometrika, 81,
541–553.
Carter, M., & van Brunt, B. (2000). The Lebesgue-Stieltjes integral: Practical introduction. New
York: Springer.
Catlin, D. E. (1989). Estimation, control, and the discrete Kalman filter. New York: Springer.
Chalupa, P., P˘rikryl, J., & No´vak, J. (2015). Modelling of twin rotor mimo system. Procedia
Engineering, 100, 249–258.
Chambers, J. M., Cleveland, W. S., Kleiner, B., & Tukey, P. A. (1983). Graphical methods for data
analysis. Belmont, CA: Wadsworth.
Chan, H.-F., & Guo, L. (1991). Identiﬁcation and stochastic adaptive control. Boston: Birkhäuser.
Chan, S. W., Goodwin, G. C., & Sin, K. S. (1984). Convergence properties of the Riccati difference
equation in optimal ﬁltering of nonstabilizable systems. IEEE Transactions in Automatic
Control, 29, 10–18.
Chen, R., & Liu, J. S. (1996). Predictive updating methods with application to Bayesian
classiﬁcation. Journal of the Royal Statistical Society Series B, 58, 397–415.
Chib, S., Nardari, F., & Shephard, N. (2006). Analysis of high dimensional multivariate stochastic
volatility models. Journal of Econometrics, 134, 341–371.
Chib, S., & Tiwari, R. C. (1994). Outlier detection in the state space model. Statistics and
Probability Letters, 20(2), 143–148.
Chipman, J. S. (1950). The multisector multiplier. Econometrica, 18(4), 355–374.
Chiu, T. Y. M., Leonard, T., & Tsui, K.-W. (1996). The matrix-logarithmic covariance model.
Journal of the American Statistical Association, 91(433), 198–210.
Chopin, N., & Papaspiliopoulos, O. (2020). An introduction to sequential Monte Carlo. New York:
Springer.
Cobb, G. W. (1978). The problem of the Nile: conditional solution to a change-point problem.
Biometrika, 65, 243–251.
Collett, D. (2003). Modelling survival data in medical research (2nd ed.). New York: Chapman
and Hall.
Commandeur, J. J. F., & Koopman, S. J. (2007). An introduction to state space time series analysis.
Oxford: Oxford University Press.
Cooper, J. D., & Harrison, P. J. (1997). A Bayesian approach to modelling the observed bovine
spongiform encephalopathy epidemic. Journal of Forecasting, 16, 355–374.
Cootner, P. H. (1964). The random character of stock market prices. Cambridge, MA: MIT Press.
Cowan, C. F. N., & Grant, P. M. (1985). Adaptive filters. Englewood Cliffs, NJ: Prentice-Hall.
Cowles 3rd, A., & Jones, H. E. (1937). Some a posteriori probabilities in stock market action.
Econometrica, 5, 280–294.
Cox, D. R. (1972). Regression models and life-tables (with discussion). Journal of the Royal
Statistical Society Series B, 34, 187–220.
Cox, D. R. (1975). Partial likelihood. Biometrika, 62, 269–275.
Cox, D. R., & Oakes, D. (1984). Analysis of survival data. New York: Chapman and Hall.
Crowdy, D. G., & Luca, E. (2014). Solving Wiener-Hopf problems without kernel factorization.
Proceedings of the Royal Society A, 470(2170).
Davis, H. T. (1941). The analysis of economic time series, cowles commission monograph no. 6.
Bloomington, Indiana: Principia Press.
De Jong, P. (1989). Smoothing and interpolation with the state-space model. Journal of the
American Statistical Association, 84, 1085–1088.
De Jong, P., & Penzer, J. R. (1998). Diagnosing shocks in time series. Journal of the American
Statistical Association, 93, 796–806.
De Jong, P., & Penzer, J. R. (2004). The ARMA model in state space form. Statistics and
Probability Letters, 70, 119–125.
Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood from incomplete data
via the em algorithm. Journal of the Royal Statistical Society Series B, 39, 1–38.
Diaconis, P., & Ylvisaker, D. (1979). Conjugate priors for exponential families. Annals of Statistics,
7, 269–281.

480
References
Díaz-García, J. A., & Gutiérrez, J. R. (1997). Proof of the conjectures of H. Uhlig on the singular
multivariate beta and the jacobian of a certain matrix transformation. Annals of Statistics, 25,
2018–2023.
Díaz-García, J. A., & Gutiérrez, J. R. (1998). Singular matrix beta distribution. Journal of
Multivariate Analysis, 99, 637–648.
Dickey, D., & Fuller, W. (1979). Distribution of the estimators for autoregressive time series with
a unit root. Journal of the American Statistical Association, 74(366), 427–431.
Ding, Z. (2013). Nonlinear and adaptive control systems (Vol. 84). IET Control Engineering Series.
Djeundje, V. B., & Crook, J. (2019). Dynamic survival models with varying coefﬁcients for credit
risks. European Journal of Operational Research, 16(1), 319–333.
Doob, J. L. (1955). Stochastic processes. New York: Wiley.
Douc, R., Cappe, O., & Moulines, E. (2005). Comparison of resampling schemes for particle
ﬁltering. In Image and Signal Processing Analysis.
Doucet, A., de Freitas, N., & Gordon, N. (2001). Sequential Monte Carlo methods in practice.
New York: Springer.
Doucet, A., Godsill, S., & Andrieu, C. (2000). On sequential monte carlo sampling methods for
Bayesian ﬁltering. Statistics and Computing, 10, 197–208.
Duncan, D. B., & Horn, S. D. (1972). Linear dynamic recursive estimation from the viewpoint of
regression analysis. Journal of the American Statistical Association, 67, 815–821.
Durbin, J. (2004). Introduction to state space time series analysis. In A. C. Harvey, S. J. Koopman,
& N. Shephard (Eds.), State space and unobserved componet models: Theory and applications
(pp. 3–25). Cambridge: Cambridge University Press.
Durbin, J., & Koopman, S. J. (2012). Time series analysis by state space methods (2nd ed.). Oxford:
Oxford University Press.
Dyke, P. P. G. (1999). An introduction to Laplace transforms and Fourier series. New York:
Springer.
Elliott, R. J., Hoek, J. V. D., & Malcolm, W. P. (2005). Pairs trading. Quantitative Finance, 5,
271–276.
Engle, R. (1982). Autoregressive conditional heteroscedasticity with estimates of the variance of
united kingdom inﬂation. Econometrica, 50, 987–1007.
Engle, R., & Granger, C. (1987). Co-integration and error correction: representation, estimation
and testing. Econometrica, 55(2), 251–276.
Engle, R. F. (2002). Dynamic conditional correlation: a simple class of multivariate generalized
autoregressive conditional heteroskedasticity models. Journal of Business and Economic
Statistics, 20, 339–350.
Engle, R. F., & Granger, C. W. J. (1987). Co-integration and error-correction: representation,
estimation and testing. Econometrica, 55, 251–276.
Eubank, R. L. (2006). A Kalman filter primer. New York: Chapman and Hall.
Fahrmeir, L. (1992). Posterior mode estimation by extended Kalman ﬁltering for multivariate
generalised linear models. Journal of the American Statistical Association, 87, 501–509.
Fahrmeir, L. (1994). Dynamic modelling and penalized likelihood estimation for discrete time
survival data. Biometrika, 81(2), 317–330.
Fahrmeir, L., & Tutz, G. (2001). Multivariate statistical modelling based on generalized linear
models. New York: Springer.
Fama, E. F. (1965). Random walks in stock market prices. Financial Analysts Journal, 21(5), 55–
59.
Fearnhead, P. (2002). Markov chain Monte Carlo, sufﬁcient statistics, and particle ﬁlters. Journal
of Computational and Graphical Statistics, 11, 848–862.
FeedbackInstruments. (1996). Twin Rotor MIMO System Manual 33–007–0 [Computer software
manual]. Sussex, UK.
Fernandez, C., & Steel, M. F. J. (1998). On Bayesian modeling of fat tails and skewness. Journal
of the American Statistical Association, 93, 359–371.
Fitzgerald, R. J. (1971). Divergence of the kalman ﬁlter. IEEE Transactions in Automatic Control,
AC-16, 736–747.

References
481
Franklin, G. F., Powell, J. D., & Emami-Naeini, A. (2018). Feedback control of dynamic systems
(7th ed.). Pearson.
Fruhwirth-Schnatter, S. (1994a). Applied state space modelling of non-Gaussian time series using
integration-based Kalman ﬁltering. Statistics and Computing, 4, 259–269.
Fruhwirth-Schnatter, S. (1994b). Data augmentation and dynamic linear models. Journal of Time
Series Analysis, 15, 183–202.
Gamerman, D. (1991). Dynamic Bayesian models for survival data. Journal of the Royal Statistical
Society Series C, 40(1), 63–79.
Gamerman, D. (1998). Markov chain Monte Carlo for dynamic generalised linear models.
Biometrika, 85, 215–227.
Gamerman, D., & Lopes, H. F. (2006). Markov chain Monte Carlo: Stochastic simulation for
Bayesian inference (2nd ed.). New York: Chapman and Hall.
Gamerman, D., dos Santos, T. R., & Franco, G. C. (2013). A non-Gaussian family of state space-
models with exact marginal likelihood. Journal of Time Series Analysis, 34, 625–645.
Gamerman, D., & West, M. (1987). An application of dynamic survival models in unemployment
studies. The Statistician, 36, 269–274.
Gatev, E., Goetzmann, W. N., & Rouwenhorst, K. G. (2006). Pairs trading: Performance of a
relative-value arbitrage rule. Review of Financial Studies, 19(3), 797–827.
Gauss, C. F. (1809). Theoria Motus Corporum Celestium (English translation by C.H. Davis
(1857). Reprinted, 1963). New York: Dover Publications.
Gauss, C. F. (1821/23/26). Theoria Combinutionis Observurionum Erroribus Minirnus Obnoxiue,
in two parts with a supplement. reprinted with an english translation and notes by G.W. Stewart,
(1995). Philadelphia: SIAM.
Geman, S., & Geman, D. (1984). Stochastic relaxation, gibbs distributions and the Bayesian
restoration of images. IEEE Transactions on Pattern Analysis and Machine Intelligence, 6,
721–741.
Gilks, W. R., & Berzuini, C. (2001). Following a moving target – Monte Carlo inference for
dynamic Bayesian models. Journal of the Royal Statistical Society Series B, 63(1), 127–146.
Godolphin, E. J., & Harrison, P. J. (1975). Equivalence theorems for polynomial projecting
predictors. Journal of the Royal Statistical Society Series B, 37, 205–215.
Godolphin, E. J., & Johnson, S. E. (2003). Decomposition of time series dynamic linear models.
Journal of Time Series Analysis, 24, 513–527.
Godolphin, E. J., & Stone, J. M. (1980). On the structural representation for polynomial-projecting
predictor models based on the Kalman ﬁlter. Journal of the Royal Statistical Society Series B,
42, 35–45.
Godolphin, E. J., & Triantafyllopoulos, K. (2006). Decomposition of time series models in state-
space form. Computational Statistics and Data Analysis, 50, 2232–2246.
Godsill, S., Doucet, A., & West, M. (2004). Monte Carlo smoothing for nonlinear time series.
Journal of the American Statistical Association, 99(465), 156–168.
Gordon, N. J., Salmond, D. J., & Smith, A. F. M. (1993). Novel approach to nonlinear/non-
Gaussian Bayesian state estimation. IEE-Proceedings-F, 140, 107–113.
Gourieroux, C., Jasiak, J., & Sufana, R. (2009). The Wishart autoregressive process of multivariate
stochastic volatility. Journal of Econometrics, 150, 167–181.
Graf, J. (2016). PID control fundamentals paperback. Sinus Engineering.
Grewal, M. S., & Andrews, A. P. (2010). Applications of Kalman ﬁltering in aerospace 1960 to the
present: Historical perspectives. IEEE Control Systems Magazine, 30(3), 69–78.
Grewal, M. S., & Andrews, A. P. (2015). Kalman filtering: Theory and practice using MATLAB
(4th ed.). New York: Wiley.
Grewal, M. S., Henderson, V., & Miyasako, R. (1991). Application of Kalman ﬁltering to the
calibration and alignment of inertial navigation systems. IEEE Transactions in Automatic
Control, 36(1), 4–14.
Guo, S., & Han, L. (2018). Stability and control of nonlinear time-varying systems. New York:
Springer.
Gupta, A. K., & Nagar, D. K. (1999). Matrix variate distributions. New York: Chapman and Hall.

482
References
Halcombe Laning Jr., J., & Battin, R. H. (1956). Random processes in automatic control. New
York: McGraw-Hill.
Han, Y. (2006). Asset allocation with a high dimensional latent factor stochastic volatility model.
The Review of Financial Studies, 19(1), 237–271.
Hannan, E. J., & Deistler, M. (1988). The statistical theory of linear systems. New York: Wiley.
Harrison, P. J. (1965). Short-term sales forecasting. Applied Statistics, 15, 102–139.
Harrison, P. J. (1967). Exponential smoothing and short-term forecasting. Management Science,
13, 821–842.
Harrison, P. J. (1997). Convergence and the constant dynamic linear model. Journal of Forecasting,
16, 287–292.
Harrison, P. J., & Stevens, C. (1971). A Bayesian approach to short-term forecasting. Operations
Research Quarterly, 22, 341–362.
Harrison, P. J., & Stevens, C. (1976). Bayesian forecasting (with discussion). Journal of the Royal
Statistical Society Series B, 38, 205–247.
Hartigan, J. A. (1969). Linear Bayesian methods. Journal of the Royal Statistical Society Series B,
31, 446–454.
Harvey, A. C. (1981). The Kalman ﬁlter and its applications in econometrics and time series
analysis. Methods of Operations Research, 44, 3–18.
Harvey, A. C. (1984). A uniﬁed view of statistical forecasting procedures. Journal of Forecasting,
3, 245–275.
Harvey, A. C. (1986). Analysis and generalisation of a multivariate exponential smoothing model.
Management Science, 32, 374–380.
Harvey, A. C. (1989). Forecasting, structural time series and the Kalman ﬁlter. Cambridge:
Cambridge University Press.
Harvey, A. C. (2004). Tests for cycles. In A. C. Harvey, S. J. Koopman, & N. Shephard (Eds.), State
space and unobserved component models: Theory and applications (pp. 102–119). Cambridge:
Cambridge University Press.
Harvey, A. C., & Fernandes, C. (1989). Time series models for count or qualitative observations.
Business and Econmic Statistics, 7, 407-417.
Harvey, A. C., Gardner, G., & Phillips, G. D. A. (1980). An algorithm for exact maximum
likelihood estimation of autoregressive-moving average models by means of Kalman ﬁltering.
Applied Statistics, 29, 311–322.
Harvey, A. C., & Koopman, S. J. (1992). Diagnostic checking of unobserved-components time
series models. Journal of Business and Economic Statistics, 10(4), 377–389.
Harvey, A. C., Koopman, S. J., & Shephard, N. (2004). State space and unobserved component
models: Theory and applications. Cambridge: Cambridge University Press.
Harvey, A. C., Ruiz, E., & Shephard, N. (1994). Multivariate stochastic variance models. Review
of Economic Studies, 61, 247–264.
Harville, D. A. (1997). Matrix Algebra from a Statistician’s perspective. New York: Springer.
Hastings, W. K. (1970). Monte Carlo sampling methods using Markov chains and their applica-
tions. Biometrika, 57, 97–109.
Hata, H., & Sekine, J. (2013). Risk-sensitive asset management under a Wishart autoregressive
factor model. Journal of Mathematical Finance, 3, 222-229.
Haykin, S. (2001). Adaptive filter theory (4th ed.). New Jersey: Prentice Hall.
He, J., McGee, D. L., & Niu, X. (2010). Application of the Bayesian dynamic survival model in
medicine. Statistics in Medicine, 29, 347–360.
Hemming, K., & Shaw, J. E. H. (2002). A parametric dynamic survival model applied to breast
cancer survival times. Journal of the Royal Statistical Society Series C, 51(4), 421–435.
Hemming, K., & Shaw, J. E. H. (2005). A class of parametric dynamic survival models. Lifetime
Data Analysis, 11, 81–98.
Hilmer, S. C., & Tiao, G. C. (1982). An arima-model-based approach to seasonal adjustment.
Journal of the American Statistical Association, 77, 63–70.
Hirsch, M. W., Smale, S., & Devaney, R. L. (2012). Differential equations, dynamical systems, and
an introduction to chaos. Academic Press.

References
483
Horn, R. A., & Johnson, C. R. (2013). Matrix analysis (2nd ed.). Cambridge: Cambridge University
Press.
Hue, C., Cadre, J. P. L., & Pérez, P. (2002). Sequential Monte Carlo methods for multiple target
tracking and data fusion. IEEE Transactions on Signal Processing, 50(2), 309–325.
Iqbal, F., & Triantafyllopoulos, K. (2019). Bayesian inference of multivariate rotated GARCH
models with skew returns. Communications in Statistics - Simulation and Computation.
Ishihara, T., Omori, Y., & Asai, M. (2016). Matrix exponential stochastic volatility with cross
leverage. Computational Statistics and Data Analysis, 100, 331–350.
Jacobson, N. (1953). Lectures in abstract Algebra. New York: Van Nostrand.
Jacquier, E., Polson, N. G., & Rossi, P. E. (1994). Bayesian analysis of stochastic volatility models.
Journal of Business and Economic Statistics, 12(4), 371–389.
Jazwinski, A. H. (1969). Adaptive ﬁltering. Automatica, 5, 475–485.
Jazwinski, A. H. (1970). Stochastic processes and filtering theory. New York: Academic Press.
Johansen, S. (1991). Estimation and hypothesis testing of cointegration vectors in Gaussian vector
autoregressive models. Econometrica, 59(6), 1551–1580.
Johnson, M. A., & Moradi, M. H. (2010). PID control: New identiﬁcation and design methods.
New York: Springer.
Johnson, R., & Núnez, C. (2014). The Kalman-Bucy ﬁlter revisted. Discrete and Continuous
Dynamical Systems, 34(10), 4139–4153.
Jones, R. H. (1966). Exponential smoothing for multivariate time series. Journal of the Royal
Statistical Society Series B, 28, 241–251.
Julier, S. J. (2002). The scaled unscented transformation. In Proceedings of the 2002 American
Control Conference.
Julier, S. J., & Uhlmann, J. K. (1997). A new extension of the Kalman ﬁlter to nonlinear systems. In
Proceedings of AeroSense: The 11th International Symposium on Aerospace/Defence Sensing,
Simulation and Controls.
Julier, S. J., & Uhlmann, J. K. (2004). Unscented ﬁltering and nonlinear estimation. In Proceedings
of the IEEE (Vol. 92, pp. 401–422).
Julious, S. A., Campbell, M. J., Bianchi, S. M., & Murray-Thomas, T. (2011). Seasonality of
medical contacts in school-aged children with asthma: association with school holidays. Public
Health, 125, 769–776.
Kalaba, R., & Tesfatsion, L. (1988). The ﬂexible least squares approach to time-varying linear
regression. Journal of Economic Dynamics and Control, 12, 43–48.
Kalman, R. E. (1960). A new approach to linear ﬁltering and prediction problems. Journal of Basic
Engineering, 82, 35–45.
Kalman, R. E., & Bertram, J. E. (1960). Control system analysis and design via the second method
of Lyapunov. I. Continuous-time systems. Journal of Basic Engineering, 82, 371–393.
Kalman, R. E., & Bucy, R. S. (1961). New results in linear ﬁltering and prediction theory. Journal
of Basic Engineering, 83(1), 95–108.
Kappl, J. J. (1971). Nonlinear estimation via Kalman ﬁltering. IEEE Transactions on Aerospace
and Electronic Systems, AES-7(1), 79–84.
Karlis, D., & Xekalaki, E. (2005). Mixed Poisson distribution. International Statistical Review,
73(1), 35–58.
Kearns, B., Stevenson, M. D., Triantafyllopoulos, K., & Manca, A. (2019). Generalized linear
models for ﬂexible parametric modeling of the hazard function. Medical Decision Making, 39,
867–878.
Kearns, B., Stevenson, M. D., Triantafyllopoulos, K., & Manca, A. (2021). The extrapolation
performance of survival models for data with a cure fraction: a simulation study. Value in Health
(in press). https://doi.org/10.1016/j.jval.2021.05.009
Kedem, B., & Fokianos, K. (2002). Regression models for time series analysis. New York: Wiley.
Khatri, C. G., & Pillai, K. C. S. (1965). Some results on the non-central multivariate beta
distribution. Annals of Mathematical Statistics, 36, 1511–1520.
Kim, S., Shephard, N., & Chib, S. (1998). Stochastic volatility: Likelihood inference and
comparison with ARCH models. The Review of Economic Studies, 65(3), 361–393.

484
References
Kitagawa, G. (1987). Non-Gaussian state-space modelling of nonstationary time series (with
discussion). Journal of the American Statistical Association, 82, 1032–1063.
Kitagawa, G. (1998). A self-organizing state-space model. Journal of the American Statistical
Association, 93, 1203–1215.
Kitagawa, G., & Gersch, W. (1996). Smoothness priors analysis of time series. New York: Springer.
Kolmogorov, A. N. (1941). Stationary sequences in Hilbert space (in Russian). Moscow University
Mathematics Bulletin, 2(6), 228–271.
Konno, Y. (1988). Exact moments of the multivariate F and beta distributions. Journal of the Japan
Statistical Society, 18, 123–130.
Koopman, S. J. (1993). Disturbance smoother for state space models. Biometrika, 80, 117–126.
Koopman, S. J. (1997). Exact initial Kalman ﬁltering and smoothing for non-stationary time series
models. Journal of the American Statistical Association, 92, 1630–1638.
Kulikov, G. Y., & Kulikova, M. V. (2018). Stability analysis of extended, cubature and unscented
Kalman ﬁlters for estimating stiff continuous–discrete stochastic systems. Automatica, 90, 91–
97.
Lang, S. (1987). Calculus of several variables (3rd ed.). New York: Springer.
Legendre, A. M. (1805). Nouvelles Méthodes pour la Détermination des Orbites des Comètes.
Paris: F. Didot.
Leonard, T., & Hsu, J. S. J. (1999). Bayesian methods. Cambridge: Cambridge University Press.
Liesenfeld, R., & Richard, J.-F. (2003). Univariate and multivariate stochastic volatility models:
estimation and diagnostics. Journal of Empirical Finance, 10, 505–531.
Lindsey, J. K. (2004). Statistical analysis of stochastic processes in time. Cambridge: Cambridge
University Press.
Lintner, J. (1965). The valuation of risk assets and the selection of risky investments in stock
portfolios and capital budgets. Review of Economics and Statistics, 47(1), 13–37.
Liu, J., & West, M. (2001). Sequential Monte Carlo Methods in practice. In D. A., de Freitas N.,
& G. N. (Eds.), chap. Combined parameter and state estimation in simulation-based ﬁltering.
New York: Springer.
Ljung, L. (1979). Asympotic behaviour of the extended Kalman ﬁlter as a parameter estimator for
linear systems. IEEE Transactions in Automatic Control, AC-24, 36–50.
Loève, M. (1955). Probability theory. Van Nostrand Company Inc.
Longley, J. W. (1967). An appraisal of least-squares programs from the point of view of the user.
Journal of the American Statistical Association, 62, 819–841.
Lorenz, E. N. (1963). Deterministic nonperiodic ﬂow. Journal of the Atmospheric Sciences, 20,
130–141.
Lundbergh, S., Teräsvirta, T., & van Dijk, D. (2003). Time-varying smooth transition autoregres-
sive models. Journal of Business and Economic Statistics, 21, 104–121.
Magnus, J. R., & Neudecker, H. (1988). Matrix differential calculus with applications in statistics
and econometrics. New York: Wiley.
Makridakis, S., Wheelwright, S. C., & Hyndman, R. J. (1998). Forecasting: methods and
applications. New York: Wiley.
Manley, G. (1974). Central England temperatures: monthly means 1659 to 1973. Quarterly Journal
of the Royal Meteorological Society, 100, 389–405.
Markowitz, H. M. (1952). Portfolio selection. The Journal of Finance, 7(1), 77–91.
Markowitz, H. M. (1959). Portfolio selection: Efﬁcient diversiﬁcation of investments. New York:
Wiley.
Martinussen, T., & Scheike, T. H. (2006). Dynamic regression models for survival data. New York:
Springer.
McCullagh, P., & Nelder, J. A. (1989). Generalised linear models (2nd ed.). New York: Chapman
and Hall.
McCulloch, R. E., & Tsay, R. S. (1993). Bayesian inference and prediction for mean and variance
shifts in autoregressive time series. Journal of the American Statistical Association, 88(423),
968–978.

References
485
McGee, L. A., & Schmidt, S. F. (1985, November). Discovery of the Kalman ﬁlter as a practical
tool for aerospace and industry. NASA Technical Memorandum 86847.
McGilchrist, C. A., & Sandland, R. L. (1979). Recursive estimation of the general linear model
with dependent errors. Journal of the Royal Statistical Society Series B, 41, 65–68.
Meinhold, R. J., & Singpurwalla, N. D. (1983). Understanding the Kalman ﬁlter. The American
Statistician, 37, 123–127.
Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., & Teller, E. (1953). Equations
of state calculations by fast computing machine. Journal of Chemical Physics, 21, 1087–1091.
Meucci, A. (2005). Risk and asset allocation. New York: Springer.
Mihaylova, L., Carmi, A. Y., Septier, F., & Gning, A. (2014). Overview of Bayesian sequential
Monte Carlo methods for group andextended object tracking. Digital Signal Processing, 25,
1–16.
Minkler, G., & Minkler, J. (1993). Theory and application of Kalman filtering. Magellan Book
Company.
Molinari, D. A. (2009). Monitoring and adaptation in time series models, MSc thesis, School of
Mathematics and Statistics, University of Shefﬁeld.
Montana, G., Triantafyllopoulos, K., & Tsagaris, T. (2009). Flexible least squares for temporal
data mining and statistical arbitrage. Expert Systems with Applications, 36, 2819–2830.
Morris, A. S., & Sterling, M. J. H. (1979). Model tuning using the extended Kalman ﬁlter.
Electronics Letters, 15, 201–202.
Morrison, G. W., & Pike, D. H. (1977). Kalman ﬁltering applied to statistical forecasting.
Management Science, 23, 768–774.
Muirhead, R. J. (1982). Aspects of multivariate statistical theory. New York: Wiley.
Muth, J. F. (1960). Optimal properties of exponentially weighted forecasts. Journal of the American
Statistical Association, 55, 299–305.
Nelder, J. A., & Wedderburn, R. W. M. (1972). Generalised linear models. Journal of the Royal
Statistical Society Series A, 135, 370–384.
Nolan, D., & Lang, D. T. (2015). Data science in R: A case studies approach to computational
reasoning and problem solving. CRC Press.
Ogata, K. (1970). Modern control engineering. Englewood Cliffs, NJ: Prentice-Hall.
O’Hagan, A., & Forster, J. J. (2004). Bayesian inference (Kendall’s advanced theory of statistics:
Volume 2B) (2nd ed.). London: Arnold.
Okuguchi, K., & Irie, K. (1990). The Schur and Samuelson conditions for a cubic equation. The
Manchester School of Economic and Social Science, 58(4), 414–418.
Oppenheim, A., & Willsky, A. (1983). Signals and systems. Englewood Cliffs, NJ: Prentice Hall.
Pakrashi, A., & Namee, B. M. (2019). Kalman ﬁlter-based heuristic ensemble (kfhe): A new
perspective on multi-class ensemble classiﬁcation using Kalman ﬁlters. Information Sciences,
485, 456–485.
Pan, X., & Jarrett, J. (2004). Applying state space to SPC: monitoring multivariate time series.
Journal of Applied Statistics, 31, 397–418.
Pankratz, A. (1991). Forecasting with dynamic regression models. New York: Wiley.
Parisi, A., & Liseo, B. (2018). Objective Bayesian analysis for the multivariate skew-t model.
Statistical Methods and Applications, 27, 277–295.
Parks, P. C. (1992). A. M. Lyapunov’s stability theory - 100 years on. IMA Journal of Mathematical
Control and Information, 9(4), 275–303.
Petris, G. (2010). An R package for dynamic linear models. Journal of Statistical Software, 36,
1–16.
Petris, G., Petrone, S., & Campagnoli, P. (2009). Dynamic linear models with R. New York:
Springer.
Philipov, A., & Glickman, M. E. (2006). Multivariate stochastic volatility via Wishart processes.
Journal of Business and Economic Statistics, 24, 313–328.
Phillips, P., & Perron, P. (1988). Testing for a unit root in time series regression. Biometrika, 75(2),
335–346.

486
References
Pitt, M. K., & Shephard, N. (1999). Filtering via simulation: auxiliary particle ﬁlters. Journal of
the American Statistical Association, 94(446), 590–599.
Plackett, R. L. (1950). Some theorems in least squares. Biometrika, 37, 149–157.
Plackett, R. L. (1991). Regression analysis. Oxford: Oxford University Press.
Pole, A. (2007). Statistical arbitrage. Algorithmic trading insights and techniques. Wiley Finance.
Pole, A., West, M., & Harrison, P. J. (1994). Applied Bayesian forecasting and time series analysis.
New York: Chapman and Hall.
Pollock, D. S. G. (2003). Recursive estimation in econometrics. Computational Statistics and Data
Analysis, 44, 37–75.
Ponomareva, K., & Date, P. (2013). Higher order sigma point ﬁlter: a new heuristic for nonlinear
time series ﬁltering. Applied Mathematics and Computation, 221, 662–671.
Prado, R., & West, M. (2010). Time series: Modeling, computation, and inference. New York:
Chapman and Hall.
Press, S. J. (1989). Bayesian statistics: Principles, models, and applications. New York: Wiley.
Priestley, M. B. (1981). Spectral analysis and time series, volume 1: Univariate time series.
London: Academic Press.
Priestley, M. B., & Rao, T. S. (1975). The estimation of factor scores and Kalman ﬁltering for
discrete parameter stationary processes. International Journal of Control, 21, 971–975.
Punchihewa, Y. G., Vo, B.-T., Vo, B.-N., & Kim, D. Y. (2018). Multiple object tracking in unknown
backgrounds with labeled random ﬁnite sets. IEEE Transactions on Signal Processing, 66(11),
3040–3055.
Quintana, J. M., & West, M. (1987). An analysis of international exchange rates using multivariate
DLM. The Statistician, 36, 275–281.
Radhakrishnan, R., Yadav, A., Date, P., & Bhaumik, S. (2018). A new method for generating sigma
points and weights for nonlinear ﬁltering. IEEE Control Systems Letters, 2(3), 519–524.
Rao, M. J. M. (2000). Estimating time-varying parameters in linear regression models using a
two-part decomposition of the optimal control formulation. Sankhy¯a Series B, 62, 433–447.
Raunch, H. E., Tung, F., & Streibel, C. T. (1965). Maximum likelihood estimators of linear
dynamic systems. American Institute of Aeronautics and Astronautics Journal, 3, 1445–1450.
Robert, C. P. (2007). The Bayesian choice: From decision-theoretic foundations to computational
implementation (2nd ed.). New York: Springer.
Robinson, R. C. (2012). An introduction to dynamical systems: Continuous and discrete (2nd ed.).
Pearson Education Inc.
Rousseeuw, P. J., & Leroy, A. M. (1987). Robust regression and outlier detection. New York:
Wiley.
Rudin, W. (1976). Principles of mathematical analysis (3rd ed.). New York: McGraw-Hill.
Saab, S. S. (2004). A heuristic Kalman ﬁlter for a class of nonlinear systems. IEEE Transactions
in Automatic Control, 49(12), 2261–2265.
Salvador, M., & Gargallo, P. (2003). Automatic selective intervention in dynamic linear models.
Journal of Applied Statistics, 30(10), 1161–1184.
Salvador, M., & Gargallo, P. (2004). Automatic monitoring and intervention in multivariate
dynamic linear models. Computational Statistics and Data Analysis, 47(3), 401-431.
Samuelson, P. A. (1941). Conditions that the roots of a polynomial be less than unity in absolute
value. Annals of Mathematical Statistics, 12, 360–364.
Särkkä, S. (2013). Bayesian filtering and smoothing. Cambridge: Cambridge University Press.
Sastry, S. (1999). Nonlinear systems: Analysis, stability, and control (Vol. 10). New York: Springer.
Schmidt, S. F. (1981). The Kalman ﬁlter: Its recognition and development for aerospace applica-
tions. Journal of Guidance and Control, 4(1), 4–7.
Schulmerich, M., Leporcher, Y.-M., & Eu, C.-H. (2015). Applied asset and risk management. New
York: Springer.
Schweppe, F. C. (1965). Evaluation of likelihood signals for Gaussian signals. IEEE Transactions
on Information Theory, 11, 61–70.
Schweppe, F. C. (1968). Recursive stateestimation:unknownbut bounded errors and system inputs.
IEEE Transactions in Automatic Control, AC-13(1), 22–28.

References
487
Schweppe, F. C. (1973). Uncertain dynamic systems. Englewood Cliffs, NJ: Prentice Hall.
Seddon, J. M., & Newman, S. (2011). Basic Helicopter aerodynamics (3rd ed.). New York: Wiley.
Shephard, N. (1994a). Local scale models: state space alternative to integrated GARCH processes.
Journal of Econometrics, 60, 181–202.
Shephard, N. (1994b). Partial non-Gaussian state space models. Biometrika, 81, 115–131.
Shephard, N., & Pitt, M. K. (1997). Likelihood analysis for non-Gaussian measurement time series.
Biometrika, 84, 653–667.
Shumway, R. H., & Stoffer, D. S. (1982). An approach to time series smoothing and forecasting
using the EM algorithm. Journal of Time Series Analysis, 3, 253–264.
Shumway, R. H., & Stoffer, D. S. (2017). Time series analysis and its applications: With R
examples (4th ed.). New York: Springer.
Smirnov, V. I. (1992). Biography of A. M. Lyapunov. International Journal of Control, 55(3),
775–784.
Smith, J. Q. (1979). A generalisation of the Bayesian steady forecasting model. Journal of the
Royal Statistical Society Series B, 41, 375–387.
Smith, J. Q. (1981). The multiparameter steady model. Journal of the Royal Statistical Society
Series B, 43, 256–260.
Smith, R. L., & Miller, J. E. (1986). A non-Gaussian state space model with application to
prediction of records. Journal of the Royal Statistical Society Series B, 48, 79–88.
Soyer, R., & Tanyeri, K. (2006). Bayesian portfolio selection with multi-variate random variance
models. Journal of Operational Research, 171, 977–990.
Spivak, M. (1995). Calculus (3rd ed.). Cambridge: Cambridge University Press.
Stevens, B. L., Lewis, F. L., & Johnson, E. N. (2016). Aircraft control and simulation: Dynamics,
controls design, and autonomous systems. New York: Wiley.
Stigler, S. M. (1986). The history of statistics. Cambridge, MA: Harvard University Press.
Storvik, G. (2002). Particle ﬁlters for state-space models with the presence of unknown static
parameters. IEEE Transactions on Signal Processing, 50, 281–290.
Strachan, R., & Inder, B. (2004). Bayesian analysis of the error correction model. Journal of
Econometrics, 123, 307–325.
Stroock, D. W. (2018). Elements of stochastic calculus and analysis. New York: Springer.
Svenson, A. (1981). On the goodness-of-ﬁt test for the multiplicative poisson model. Annals of
Statistics, 9, 697–704.
Tesfatsion, L., & Kalaba, R. (1989). Time-varying linear regression via ﬂexible least squares.
Computers and Mathematics with Applications, 17, 1215–1245.
Tokhi, O. M., & Azad, A. K. M. (2008). Flexible robot manipulators: Modelling, simulation and
control. The Institution of Engineering and Technology.
Tong, H. (1996). Non-linear time series. Oxford: Clarendon Press.
Triantafyllopoulos, K. (2006a). Multivariate control charts based on Bayesian state space models.
Quality and Reliability Engineering International, 22, 693–707.
Triantafyllopoulos, K. (2006b). Multivariate discount weighted regression and local level models.
Computational Statistics and Data Analysis, 50, 3702–3720.
Triantafyllopoulos, K. (2007a). Convergence of discount time series dynamic linear models.
Communications in Statistics - Theory and Methods, 36, 2117–2127.
Triantafyllopoulos, K. (2007b). Covariance estimation for multivariate conditionally Gaussian
dynamic linear models. Journal of Forecasting, 26, 551–569.
Triantafyllopoulos, K. (2008a). Missing observation analysis for matrix-variate time series data.
Statistics and Probability Letters, 78, 2647–2653.
Triantafyllopoulos, K. (2008b). Multivariate stochastic volatility with Bayesian dynamic linear
models. Journal of Statistical Planning and Inference, 138, 1021–1037.
Triantafyllopoulos, K. (2009). Inference of dynamic generalised linear models: on-line computa-
tion and appraisal. International Statistical Review, 77, 439–450.
Triantafyllopoulos, K. (2011a). Real-time covariance estimation for the local level model. Journal
of Time Series Analysis, 32, 93–107.

488
References
Triantafyllopoulos, K. (2011b). Time-varying vector autoregressive models with stochastic volatil-
ity. Journal of Applied Statistics, 38, 369–382.
Triantafyllopoulos, K. (2012). Multivariate stochastic volatility modelling using Wishart autore-
gressive processes. Journal of Time Series Analysis, 33, 48–60.
Triantafyllopoulos, K. (2014). Multivariate stochastic volatility estimation using particle ﬁlters.
In M. Akritas, S. Lahiri, & D. Politis (Eds.), Topics in nonparametric statistics. Springer
proceedings in mathematics and statistics (Vol. 74, pp. 335–345). New York: Springer.
Triantafyllopoulos, K., Aldebrez, F. M., Zinober, A. S. I., & Tokhi, M. O. (2009). Bayesian
dynamic modelling and tracking control for ﬂexible manoeuvring systems. In 2009 3rd
International Conference on Signals, Circuits and Systems (pp. 1–6).
Triantafyllopoulos, K., Godolphin, J. D., & Godolphin, E. J. (2005). Process improvement in
the microelectronic industry by state-space modelling. Quality and Reliability Engineering
International, 21, 465–475.
Triantafyllopoulos, K., & Han, S. (2013). Detecting mean reverted patterns in algorithmic pairs
trading. In P. Latorre Carmona, J. S. Sánchez, & A. L. Fred (Eds.), Mathematical methodologies
in pattern recognition and machine learning (pp. 127–147). New York: Springer.
Triantafyllopoulos, K., & Harrison, P. J. (2008). Posterior mean and variance approximation for
regression and time series problems. Statistics: A Journal of Theoretical and Applied Statistics,
42, 329–350.
Triantafyllopoulos, K., & Montana, G. (2011). Dynamic modeling of mean-reverting spreads for
statistical arbitrage. Computational Management Science, 8, 23–49.
Triantafyllopoulos, K., & Nason, G. P. (2007). A Bayesian analysis of moving average processes
with time-varying parameters. Computational Statistics and Data Analysis, 52, 1025–1046.
Triantafyllopoulos, K., & Nason, G. P. (2009). A note on state-space representations of locally
stationary wavelet time series. Statistics and Probability Letters, 79, 50–54.
Triantafyllopoulos, K., & Pikoulas, J. (2002). Multivariate Bayesian regression applied to the
problem of network security. Journal of Forecasting, 21, 579–594.
Triantafyllopoulos, K., Shakandli, M., & Campbell, M. J. (2019). Count time series prediction
using particle ﬁlters. Quality and Reliability Engineering International, 35, 1445–1459.
Trosset, M. W. (2009). An introduction to statistical inference and its applications with R. Chapman
and Hall.
Tsay, R. S. (2002). Analysis of financial time series. New York: Wiley.
Uhlig, H. (1994). On singular Wishart and singular multivariate beta distributions. Annals of
Statistics, 22, 395–405.
Uhlig, H. (1997). Bayesian vector autoregressions with stochastic volatility. Econometrica, 65,
59–73.
Van Der Merwe, R., Doucet, A., de Freitas, N., & Wan, E. A. (2001). The unscented particle ﬁlter.
In T. G. D. Todd K. Leen & V. Tresp (Eds.), Advances in neural information processing systems
(Vol. 13).
Van Der Weide, R. (2002). GO-GARCH: a multivariate generalised orthogonal GARCH model.
Journal of Applied Econometrics, 17, 549–564.
van Houwelingen, H., & Putter, H. (2012). Dynamic prediction in clinical survival analysis. CRC
Press.
Venables, W. N., & Ripley, B. D. (2002). Modern applied statistics with S-PLUS (4th ed.). New
York: Springer.
Vidyamurthy, G. (2004). Pairs trading. Wiley Finance.
Virbickaite, A., Ausín, M. C., & Galeano, P. (2015). Bayesian inference methods for univariate and
multivariate GARCH models: a survey. Journal of Economic Surveys, 29(1), 76–96.
Vrontos, I. D., Dellaportas, P., & Politis, D. N. (2003). A full-factor multivariate GARCH model.
Econometrics Journal, 6(2), 312-334.
Wagner, H. (2011). Bayesian estimation and stochastic model speciﬁcation search for dynamic
survival models. Statistics and Computing, 21, 231–246.

References
489
Wan, E. A., & Van Der Merwe, R. (2000). The unscented Kalman ﬁlter for nonlinear estimation. In
Proceedings of the IEEE 2000 Adaptive Systems for Signal Processing, Communications, and
Control Symposium.
West, M. (1986). Bayesian model monitoring. Journal of the Royal Statistical Society Series B, 48,
70–78.
West, M. (1997). Time series decomposition. Biometrika, 84, 489–494.
West, M., & Harrison, P. J. (1986). Monitoring and adaptation in Bayesian forecasting models.
Journal of the American Statistical Association, 81, 741–750.
West, M., & Harrison, P. J. (1997). Bayesian forecasting and dynamic models (2nd ed.). New York:
Springer.
West, M., Harrison, P. J., & Migon, H. S. (1985). Dynamic generalised linear models and Bayesian
forecasting (with discussion). Journal of the American Statistical Association, 80, 73–97.
West, M., Prado, R., & Krystal, A. D. (1999). Evaluation and comparison of EEG traces: latent
structure in nonstationary time series. Journal of the American Statistical Association, 94, 375–
387.
Whittle, P. (1984). Prediction and Regulation by linear least-square methods (2nd ed.). Oxford:
Blackwell.
Wiener, N. (1949). Extrapolation, Interpolation and smoothing of stationary time series with
engineering applications. Cambridge, MA: MIT Press.
Wiener, N., & Hopf, E. (1931). Über eine klasse singulärer integralgleichungen. Sem-Ber Preuss
Akad Wiss, 31, 696–706.
Wilson, K. J., & Farrow, M. (2017). Bayes linear kinematics in a dynamic survival model.
International Journal of Approximate Reasoning, 80, 239–256.
Wise, J. (1956). Stationarity conditions for stochastic processes of the autoregressive and moving-
average type. Biometrika, 48, 216–219.
Yedavalli, R. K. K. (2016). Robust control of uncertain dynamic systems: A linear state space
approach. New York: Springer.
Young, P. C. (1968). The use of linear regression and related procedures for the identiﬁcation of
dynamic processes. In 7th Symposium of Adaptive Processes. IEEE.
Young, P. C. (1969). The differential equation error method of process parameter estimation
(Unpublished doctoral dissertation). Cambridge, England: University of Cambridge.
Young, P. C. (2011). Recursive estimation and time-series analysis: An introduction for the student
and practitioner (2nd ed.). New York: Springer.
Yu, J., & Meyer, R. (2006). Multivariate stochastic volatility models: Bayesian estimation and
model comparison. Economtric Reviews, 25, 361–384.
Yu, P. L. H., Li, W. K., & Ng, F. C. (2017). The generalized conditional autoregressive Wishart
model for multivariate realized volatility. Journal of Business and Economic Statistics, 35(4),
513–527.
Yule, G. U. (1927). On a method of investigating periodicities in disturbed series with special
reference to Wolfer’s sunspot numbers. Philosophical Transactions, Royal Society, 226, 267–
298.
Zadeh, L., & Desoer, C. (1979). Linear system theory. Huntington, NY: Krieger Publishing
Company.
Zadeh, L. A., & Desoer, C. A. (1963). Linear system theory: The state space approach. New York:
McGraw Hill.
Zaritskii, V. S., Svetnik, V. B., & Shimelevich, L. I. (1975). Monte Carlo technique in problems of
optimal data processing. Automation and Remote Control, 12, 95–103.
Zellner, A., & Tiao, G. C. (1964). Bayesian analysis of the regression model with autocorrelated
errors. Journal of the American Statistical Association, 59, 763-778.
Zhang, H., & Zhang, Q. (2008). Trading a mean reverting asset: buy low and sell high. Automatica,
44, 1511–1518.
Zinober, A. S. I. (1994). Variable Structure and Lyapunov Control. In A. S. I. Zinober (Ed.), chap.
An introduction to sliding mode variable structure control (Vol. 193). New York: Springer.
Zinober, A. S. I. (2001). Nonlinear and adaptive control (Vol. 281). New York: Springer.

Index
A
Aluminium prices, 112, 114, 116
Annual temperatures of central England, 76,
86, 94, 172
Approximate inference
extended Kalman ﬁlter, 285
tracking a ship, 284
unscented Kalman ﬁlter, 287
Approximate inference of non-Gaussian and
non-linear models, 282
Asset allocation, 379
Dow Jones time series, 386
Asthma data, 312
Autoregression, 139
state space representation, 139
time-varying, 139
Autoregressive model, 345
B
Bayesian inference
MCMC, 240
Bearings-only tracking, 302
Bias, 176
C
Categorical time series, 270, 271
Companion matrix, 143
Conditionally Gaussian model, 264
Conditionally Gaussian time series, 275
Continuous proportions, 272
Continuous-time Kalman ﬁlter, 435, 437
Continuous-time state space model
discrete approximation, 417
discretisation of, 417
Convergence of the posterior covariance
matrix, 100
Count time series, 268
asthma data, 312
negative binomial model, 269
Poisson model, 268
Covariance estimation, 223, 227
D
Decomposition of dynamic generalised linear
models, 273
Differential equations, 407
Laplace transform, 407
Differentiation
determinant, 28
matrix, 24
quadratic form, 26
trace, 28
vector, 24
Dirac delta, 292
Discount factor, 67, 71, 111, 165, 166
Distribution
asymmetric, 363
beta distribution, 272
binomial, 270
conditional, 36
continuous
beta, 44
gamma, 41
Gaussian/normal, 41
inverse gamma, 43
Student t, 45
uniform, 44
© The Author(s), under exclusive license to Springer Nature Switzerland AG 2021
K. Triantafyllopoulos, Bayesian Inference of State Space Models, Springer Texts
in Statistics, https://doi.org/10.1007/978-3-030-76124-0
491

492
Index
Dirichlet, 272
discrete
binomial, 38
multinomial, 39
negative binomial, 39
Poisson, 37
exponential family, 266
inverse Wishart, 372
joint distribution function, 36
joint probability density function, 36
marginal, 35
multinomial, 271
negative binomial, 269
Poisson, 268
singular multivariate beta, 373
skew-t distribution, 363
Wishart, 372
Wishart - beta conjugacy, 373
Dynamic Dirichlet model, 272
Dynamic generalised linear models, 265, 272
categorical time series, 270, 271
count time series, 268
decomposition of, 273
Markov chain Monte Carlo, 320
MCMC, 320
Dynamic models
state space representation, 412, 417
survival model, 325
two-objects spring example, 415
Dynamic survival model, 325, 326
proportional hazard, 325
Dynamic systems, 404
basic principles, 404
Hookean spring example, 410, 413
impulse response, 406
Laplace transform, 407
linear systems, 405
Lorenz system, 434
solution of the state differential equation,
416
stability, 422
state of, 411
state variable, 411
system stability, 420
E
Error analysis, 175, 221, 238
Error measures, 176, 222
mean absolute deviation, 176, 222
mean squared, 176
mean squared standardised, 176, 222
mean square error, 222
Estimation of observation variance, 167
multivariate models, 223
Exponential family of distributions, 266
Exponential-model model, 281
Extended Kalman ﬁlter, 285
extended Kalman-Bucy ﬁlter, 453
F
Feedback control, 455, 456, 460
PID controller, 456
twin-rotor example, 460
FFBS algorithm, 249
production time series, 250
Filtering, 73, 211
Filtering heuristics, 287
unscented Kalman ﬁlter, 287
Fixed-interval smoothing, 83
Flexible least squares, 82
Forecast
distribution, 92
function, 93
mean, 93
Forecasting, 92, 212
summary, 94
Forgetting factor, 67, 165
Forward ﬁltering backward sampling algorithm
production time series, 250
summary, 249
G
General inference of state space models, 276
Gibbs sampling, 240, 247
H
Hyperparameters, 156
maximum likelihood estimation, 156
I
IBM and Intel share prices, 344
Importance function
choice of, 297
Importance sampling, 291
Impulse response, 406
Initialisation, 180
Inverse Wishart distribution, 228
K
Kalman-Bucy ﬁlter, 435, 437
asymptotic behaviour, 452
convergence, 452

Index
493
extended Kalman-Bucy ﬁlter, 453
Kalman ﬁlter, 73, 79
continuous-time Kalman ﬁlter, 435, 437
discrete-time Kalman ﬁlter, 436
extended Kalman-Bucy ﬁlter, 453
extended Kalman ﬁlter, 285
history of, 15
Kalman-Bucy ﬁlter, 435, 437
minimum least squares estimation, 79
of multivariate models, 211
summary, 82, 213
unscented Kalman ﬁlter, 287
Kalman gain, 76, 212
L
Least squares
ﬂexible, 82
Linear systems, 405
Hookean spring example, 410
impulse response, 406
Laplace transform, 407
stability, 422
Liu and West particle ﬁlter, 310
Local level model, 5, 72, 98
convergence, 98
steady state, 98
Lorenz system, 434
Lyapunov function, 431
M
Markov chain Monte Carlo, 240, 316
basic principles, 240
dynamic generalised linear models, 320
forward ﬁltering backward sampling
algorithm, 247
general principles, 316
Gibbs sampling, 240
Metropolis-Hastings, 316
state space models
correlation issue, 244
forward ﬁltering backward sampling
algorithm, 245
Gibbs sampling, 245
stochastic volatility model, 357
Matrix
differentiation, 24
limit, 33
norm, 33
power, 22
random, 35
Maximum likelihood estimation of
hyperparameters
direct maximisation, 156
EM-algorithm, 157, 214
of multivariate models, 214
R implementation, 164
MCMC, 240, 247
dynamic generalised linear models, 320
FFBS algorithm, 245
production time series, 250
Metropolis-Hastings algorithm, 316
Multi-categorical time series, 271
Multinomial time series, 300
Multivariate scaled observational precision
model (MSOP), 229
pollution levels, 234
Multivariate state space model
Wishart distribution, 228
Multivariate stochastic volatility model, 369
FX time series, 378
N
Non-Gaussian time series
multinomial example, 300
Non-linear state space model, 264
Non-linear time series example, 304
O
Observability, 447
of continuous-time state space model, 447
deﬁnition, 96
examples, 97
Observation variance, 167
Ordinary least squares, 63
P
Pairs trading, 388
basic concept, 388
Exxon Mobil and SouthWest airlines time
series, 394
time-varying autoregressive model, 390
Particle ﬁlter, 290
algorithm, 296
asthma data, 312
Liu and West ﬁlter, 306
multinomial example, 300
non-linear time series example, 304
static parameter estimation, 306
stochastic volatility model, 361, 363
tracking example, 302
Point mass distribution, 292
Poisson-gamma model, 279
Pollution levels, 136

494
Index
Polynomial trend models, 117
Portfolio
constrained portfolio, 383
Dow Jones time series, 386
efﬁcient frontier, 386
selection, 379
unconstrained portfolio, 382
Power local level model, 277
deﬁnition, 277
exponential-gamma model, 281
Poisson-gamma model, 279
Prior speciﬁcation, 180
of observation variance, 184
of the states, 181
Probability
deﬁnition, 34
Q
Quarterly Shefﬁeld temperatures, 128
R
Random variable
independent, 36
Random vector, 35
distribution, 36
expectation, 36
tower property, 36
Recursive least squares (RLS), 67
maximum likelihood estimation, 68
Regression, 64
autocorrelated errors, 342
dynamic, 135
economic time series, 342
IBM and Intel example, 344
time-varying, 135
Residuals, 175, 222
analysis, 175, 222
properties, 175, 222
Returns, 354
asymmetric, 363
characteristics, 354
cumulative portfolio returns, 384
multivariate, 369
portfolio returns, 379, 384
stylised facts, 354
S
Scaled observational precision model (SOP),
167, 224, 229
multivariate, 229
Seasonal time series, 124
state space representation, 126
Sequential Monte Carlo, 290, 294
asthma data, 312
importance function, 297
importance sampling, 291
Liu and West ﬁlter, 306
multinomial example, 300
non-linear time series example, 304
static parameter estimation, 306
stochastic volatility model, 361, 363
Storvik ﬁlter, 306
tracking example, 302
Sequential Monte Carlo algorithm, 296
Skew returns, 363
Smoothing, 83, 212
ﬁxed-interval, 83, 212
lag-one covariance smoother, 88
summary, 85
Speciﬁcation of model components, 112
Speciﬁcation of transition matrix, 165
Stability, 420, 422
basic concept, 420
of linear systems, 422
Lorenz system, 434
Lyapunov direct method, 431
Lyapunov indirect method, 428
non-linear systems, 428
pendulum, 429
State of a system, 411
State space
covariance estimation, 247
non Gaussian model, 264
State space model
approximate inference, 282
conditionally Gaussian model, 264
continuous time, 412
covariance estimation, 223, 227
deﬁnition, 2, 6, 72, 210
design vector, 72
discrete-time, 417
dynamic generalised linear model, 265
examples
pollution levels, 7
stochastic volatility, 12
tracking a ship, 9
exponential family, 265
extended Kalman ﬁlter, 285
Fourier form, 125
motivation, 5
multivariate, 210
non-linear model, 264
pairs trading, 388
seasonal, 125
forecast function, 129

Index
495
solution of the state differential equation,
416
stability of non-linear systems, 428
steady state, 100, 216
stochastic volatility, 355
superposition, 121
system stability, 420
transition matrix, 72
trend, 112
forecast function, 116
linear growth model, 112
polynomial model, 119
polynomial trend models, 117
quadratic trend model, 119
trend-seasonal, 131
two-objects spring example, 415
unscented Kalman ﬁlter, 287
variance estimation, 223, 227
State variable, 411
Stationarity, 345, 349, 350
autoregressive model, 345, 350
autoregressive model of order two, 349
Stationarity conditions, 349
autoregressive model of order three, 350
autoregressive model of order two, 349
Statistical arbitrage, 388
Statistics
Bayesian, 51
EM algorithm, 49
maximum likelihood estimation, 49
Steady state, 216
of linear state space model, 100
local level model, 98
of multivariate local level model, 216
Stochastic volatility model, 275, 354, 355
asymmetric returns, 363
Markov chain Monte Carlo estimation, 357
MCMC algorithm, 360
MCMC inference, 357
multivariate, 369
particle ﬁlter estimation, 361
sequential Monte Carlo estimation, 361
skew returns, 363
univariate model, 354, 355
Sum of squares, 64
discounted, 67
weighted, 67
Superposition of state space models, 121
Survival
dynamic, 326
time-varying covariates, 326
Survival model, 325
dynamic, 325
System stability
RLC electric circuit, 425
T
Time series, 1, 2
Time-varying autoregression, 139, 390
Time-varying regression, 135
Tracking a ship, 284, 302
Trend models, 112
Turkey sales, 132, 151, 177
V
Variance estimation, 223
W
Water tank dynamics, 5
Wishart autoregressive process, 372, 373
Wishart autoregressive volatility model, 372
Wishart distribution, 228
Wishart process, 373

