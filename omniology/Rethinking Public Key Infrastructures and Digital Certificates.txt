Rethinking 
Public Key Infrastructures 
and Digital Certificates Building in Privacy
Stefan A. Brands 

Rethinking Public Key Infrastructures and Digital Certiﬁcates


Rethinking Public Key Infrastructures and Digital Certiﬁcates
Building in Privacy
Stefan A. Brands
The MIT Press
Cambridge, Massachusetts
London, England

c⃝2000 Stefan A. Brands
All rights reserved. No part of this book may be reproduced in any form by any
electronic or mechanical means (including photocopying, recording, or information
storage and retrieval) without permission in writing from the publisher.
Library of Congress Cataloging-in-Publication Data
Brands, Stefan A.
Rethinking public key infrastructures and digital certiﬁcates : building in privacy /
Stefan A. Brands.
p. cm.
Includes bibliographical references and index.
ISBN 0-262-02491-8 (alk. hc)
1. Computer networks—Security measures. 2. Computer network protocols. 3.
Data encryption (Computer science). 4. Computer security. I. Title.
TK5105.59 B73 2000
005.8—dc21
00-032866

Dedicated to the memory of Petr ˇSvestka


Contents
Foreword
xi
Preface
xiii
Summary
xvii
List of Figures
xxiii
1
Introduction
1
1.1
Digital certiﬁcates and PKIs
. . . . . . . . . . . . . . . . . . . . .
1
1.1.1
From paper-based to digital certiﬁcates
. . . . . . . . . . .
1
1.1.2
Identity certiﬁcates . . . . . . . . . . . . . . . . . . . . . .
3
1.1.3
Central database paradigm . . . . . . . . . . . . . . . . . .
6
1.1.4
Attribute certiﬁcates
. . . . . . . . . . . . . . . . . . . . .
9
1.1.5
Certiﬁcate revocation and validation . . . . . . . . . . . . .
13
1.1.6
Smartcard integration . . . . . . . . . . . . . . . . . . . . .
15
1.2
Privacy issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
1.2.1
Privacy dangers . . . . . . . . . . . . . . . . . . . . . . . .
20
1.2.2
Previous privacy-protection efforts and their shortcomings .
25
1.2.3
Desirable privacy properties . . . . . . . . . . . . . . . . .
30
1.3
Outlook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
32
1.3.1
Basic building blocks . . . . . . . . . . . . . . . . . . . . .
32
1.3.2
Additional privacy techniques . . . . . . . . . . . . . . . .
34
1.3.3
Security techniques . . . . . . . . . . . . . . . . . . . . . .
35
1.3.4
Smartcard integration . . . . . . . . . . . . . . . . . . . . .
37
1.3.5
Security and privacy guarantees . . . . . . . . . . . . . . .
39
1.3.6
Applicability . . . . . . . . . . . . . . . . . . . . . . . . .
40
2
Cryptographic Preliminaries
41
2.1
Notation, terminology, and conventions
. . . . . . . . . . . . . . .
41
2.1.1
Basic notation
. . . . . . . . . . . . . . . . . . . . . . . .
41

viii
CONTENTS
2.1.2
Algorithms, security parameters, and probability . . . . . .
42
2.1.3
Interactive algorithms and protocols . . . . . . . . . . . . .
44
2.1.4
Attack models
. . . . . . . . . . . . . . . . . . . . . . . .
45
2.1.5
Security reductions and the random oracle model . . . . . .
48
2.2
One-way functions
. . . . . . . . . . . . . . . . . . . . . . . . . .
49
2.2.1
Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
2.2.2
The DL function . . . . . . . . . . . . . . . . . . . . . . .
51
2.2.3
The RSA function
. . . . . . . . . . . . . . . . . . . . . .
56
2.3
Collision-intractable functions . . . . . . . . . . . . . . . . . . . .
58
2.3.1
Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . .
58
2.3.2
The DLREP function . . . . . . . . . . . . . . . . . . . . .
59
2.3.3
The RSAREP function . . . . . . . . . . . . . . . . . . . .
62
2.3.4
Comparison . . . . . . . . . . . . . . . . . . . . . . . . . .
65
2.4
Proofs of knowledge
. . . . . . . . . . . . . . . . . . . . . . . . .
66
2.4.1
Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . .
66
2.4.2
Security for the prover . . . . . . . . . . . . . . . . . . . .
67
2.4.3
Proving knowledge of a DL-representation
. . . . . . . . .
71
2.4.4
Proving knowledge of an RSA-representation . . . . . . . .
75
2.5
Digital signatures . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
2.5.1
Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
2.5.2
From proofs of knowledge to digital signature schemes . . .
79
2.5.3
Digital signatures based on the DLREP function
. . . . . .
81
2.5.4
Digital signatures based on the RSAREP function . . . . . .
84
2.6
Digital certiﬁcates . . . . . . . . . . . . . . . . . . . . . . . . . . .
86
2.6.1
Deﬁnition of public-key certiﬁcates . . . . . . . . . . . . .
86
2.6.2
Deﬁnition of secret-key certiﬁcates
. . . . . . . . . . . . .
87
2.6.3
Comparison . . . . . . . . . . . . . . . . . . . . . . . . . .
89
2.7
Bibliographic notes . . . . . . . . . . . . . . . . . . . . . . . . . .
90
3
Showing Protocols with Selective Disclosure
91
3.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
3.2
How to commit . . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
3.3
Formulae with zero or more “AND” connectives . . . . . . . . . . .
93
3.3.1
Technique based on the DLREP function
. . . . . . . . . .
93
3.3.2
Technique based on the RSAREP function
. . . . . . . . .
105
3.4
Formulae with one “NOT” connective . . . . . . . . . . . . . . . .
108
3.4.1
Technique based on the DLREP function
. . . . . . . . . .
108
3.4.2
Technique based on the RSAREP function
. . . . . . . . .
118
3.5
Atomic formulae connected by “OR” connectives . . . . . . . . . .
119
3.5.1
Technique based on the DLREP function
. . . . . . . . . .
119
3.5.2
Technique based on the RSAREP function
. . . . . . . . .
123
3.6
Demonstrating arbitrary Boolean formulae . . . . . . . . . . . . . .
123

CONTENTS
ix
3.6.1
Technique based on the DLREP function
. . . . . . . . . .
123
3.6.2
Technique based on the RSAREP function
. . . . . . . . .
126
3.7
Optimizations and extensions . . . . . . . . . . . . . . . . . . . . .
128
3.8
Bibliographic notes . . . . . . . . . . . . . . . . . . . . . . . . . .
130
4
Restrictive Blind Issuing Protocols
131
4.1
Restrictive blinding . . . . . . . . . . . . . . . . . . . . . . . . . .
131
4.2
Practical constructions
. . . . . . . . . . . . . . . . . . . . . . . .
134
4.2.1
Restrictive blinding based on the DLREP function
. . . . .
135
4.2.2
Restrictive blinding based on the RSAREP function . . . . .
139
4.2.3
Comparison . . . . . . . . . . . . . . . . . . . . . . . . . .
140
4.3
Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
146
4.3.1
Completeness . . . . . . . . . . . . . . . . . . . . . . . . .
146
4.3.2
Privacy for the receiver . . . . . . . . . . . . . . . . . . . .
147
4.3.3
Security for the Certiﬁcate Authority
. . . . . . . . . . . .
149
4.3.4
Additional properties . . . . . . . . . . . . . . . . . . . . .
160
4.4
Parallelization of protocol executions . . . . . . . . . . . . . . . . .
162
4.4.1
Masking the initial witness . . . . . . . . . . . . . . . . . .
163
4.4.2
Swapping exponents in the veriﬁcation relation . . . . . . .
166
4.5
Other certiﬁcate schemes . . . . . . . . . . . . . . . . . . . . . . .
171
4.5.1
DSA-like certiﬁcates . . . . . . . . . . . . . . . . . . . . .
171
4.5.2
Certiﬁcates based on Chaum-Pedersen signatures . . . . . .
175
4.6
Bibliographic notes . . . . . . . . . . . . . . . . . . . . . . . . . .
178
5
Combining Issuing and Showing Protocols
181
5.1
Integration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
181
5.1.1
Making the match
. . . . . . . . . . . . . . . . . . . . . .
181
5.1.2
Coping with delegation . . . . . . . . . . . . . . . . . . . .
185
5.2
Privacy improvements for certiﬁcate holders . . . . . . . . . . . . .
189
5.2.1
Issuing protocol techniques . . . . . . . . . . . . . . . . . .
189
5.2.2
Showing protocol techniques . . . . . . . . . . . . . . . . .
191
5.3
Privacy improvements for certiﬁcate veriﬁers
. . . . . . . . . . . .
193
5.4
Limited-show certiﬁcates . . . . . . . . . . . . . . . . . . . . . . .
197
5.4.1
Static one-show certiﬁcates . . . . . . . . . . . . . . . . . .
197
5.4.2
Dynamic one-show certiﬁcates . . . . . . . . . . . . . . . .
201
5.4.3
Increasing the threshold
. . . . . . . . . . . . . . . . . . .
207
5.5
Security improvements . . . . . . . . . . . . . . . . . . . . . . . .
208
5.5.1
Beneﬁts of encoding identiﬁers
. . . . . . . . . . . . . . .
208
5.5.2
How to discourage lending . . . . . . . . . . . . . . . . . .
211
5.5.3
Non-repudiation
. . . . . . . . . . . . . . . . . . . . . . .
212
5.5.4
How to discourage discarding . . . . . . . . . . . . . . . .
213
5.5.5
Guarding the secret key of the Certiﬁcate Authority . . . . .
213

x
CONTENTS
5.6
Bibliographic notes . . . . . . . . . . . . . . . . . . . . . . . . . .
216
6
Smartcard Integration
219
6.1
Shortcomings of the smartcard-only paradigm . . . . . . . . . . . .
219
6.1.1
Privacy dangers . . . . . . . . . . . . . . . . . . . . . . . .
219
6.1.2
Other shortcomings . . . . . . . . . . . . . . . . . . . . . .
223
6.2
Combining smartcards and software-only devices . . . . . . . . . .
224
6.2.1
Beneﬁts . . . . . . . . . . . . . . . . . . . . . . . . . . . .
225
6.2.2
How not to cope with subliminal channels . . . . . . . . . .
227
6.3
Secure smartcard integration . . . . . . . . . . . . . . . . . . . . .
230
6.3.1
Technique based on the DLREP function
. . . . . . . . . .
230
6.3.2
Technique based on the RSAREP function
. . . . . . . . .
236
6.4
Privacy protection . . . . . . . . . . . . . . . . . . . . . . . . . . .
238
6.4.1
Inﬂow prevention . . . . . . . . . . . . . . . . . . . . . . .
239
6.4.2
Outﬂow prevention . . . . . . . . . . . . . . . . . . . . . .
240
6.4.3
Prevention of other data leakage channels . . . . . . . . . .
242
6.4.4
Restricting the level of privacy protection . . . . . . . . . .
245
6.5
Other techniques
. . . . . . . . . . . . . . . . . . . . . . . . . . .
247
6.5.1
Implementation in low-cost smartcards
. . . . . . . . . . .
248
6.5.2
Returning certiﬁcates . . . . . . . . . . . . . . . . . . . . .
250
6.5.3
How to discourage remote lending . . . . . . . . . . . . . .
251
6.5.4
Bearer certiﬁcates . . . . . . . . . . . . . . . . . . . . . . .
252
6.5.5
Loose ends . . . . . . . . . . . . . . . . . . . . . . . . . .
253
6.6
Bibliographic notes . . . . . . . . . . . . . . . . . . . . . . . . . .
254
Epilogue: The Broader Perspective
257
References
273
Index
307
Curriculum Vitae
315

Foreword
Stefan Brands’ Ph.D. thesis, updated and published here in book form, makes major
contributions to the state of the art of achieving privacy in an electronic world.
Whit Difﬁe and Susan Landau, in their excellent book Privacy on the Line, pro-
claim:
“Privacy encompasses the right to control information about ourselves,
including the right to limit access to that information. ...The right to
privacy means the right to enjoy solitude, intimacy and anonymity.”
Yet today, the identity and on-line behavior of individuals is routinely recorded; users
often have little knowledge of or control over such surveillance.
While encryption may protect your credit card number from a wiretapper, it does
not prevent the merchant who receives and legitimately decrypts your credit card
number from selling it, misusing it, or using it to link the current transaction to a
dossier of your previous transactions.
Similarly, conventional public-key digital signatures and certiﬁcates can provide
reliable identiﬁcation over a network, so that users can authenticate a merchant’s web
site and vice versa. An adversary can not impersonate a user, or set up a fraudulent
web site, without defeating the digital signature scheme or stealing a secret key. But
once you have been reliably identiﬁed by your digital signature and corresponding
certiﬁcate you have lost any hope of remaining anonymous or preventing merchants
from cross-linking their records about you.
In cyberspace, the most dangerous threat to your privacy is not a wiretapper, but
the other party to your transaction.
While privacy can be enhanced by appropriate legislation and regulation, work-
able technical approaches, when they can be found, are often more effective. Com-
pare laws against “peeping toms” to window shades!
This book provides new cryptographiccommunication and transaction techniques
so that users can limit the information provided to another party to a bare mini-
mum. For example, a user can remain anonymous while still reliably convincing
an information provider that he is a paid subscriber. Moreover, the user’s sessions

xii
FOREWORD
are “unlinkable”—the information provider cannot even tell if the (anonymous) user
currently logged in is the same as the user who logged into some previous session.
Brands’ techniques allow an organization or service to issue “credentials” to a
user that the user may show anonymously in later sessions. To protect his anonymity
maximally, the user may choose to show only a selected portion of any credential he
has been issued. To achieve such anonymity, the issuing process is cleverly “blinded”
so that the issuer can not identify the user in the later sessions. The issuer may, if
he wishes, issue a modiﬁed “limited-use” credential that the user can use at most a
given number of times. Many extensions and variations are described and discussed.
The cryptographic techniques presented are novel and powerful. They are based
on familiar cryptographic foundations such as RSA and the discrete logarithm prob-
lem. Brands has invented fascinating new ways of representing certiﬁcates and cre-
dentials, and proves the security of his techniques using standard cryptographic as-
sumptions.
Brands explains clearly how his new privacy-protecting techniques relate to elec-
tronic cash, public-key infrastructures, and smart cards. He also speaks eloquently
about the importance of privacy from a larger perspective, and argues against privacy-
defeating techniques such as “key escrow.”
This book, for both its conceptual framework and technical elaboration, is an
important landmark in the evolution of privacy-enhancing technology.
Ronald L. Rivest
Webster Professor of Electrical Engineering and Computer Science
MIT EECS Department
April 30, 2000

Preface
The real danger is the gradual erosion of individual lib-
erties through the automation, integration, and intercon-
nection of many small, separate recordkeeping systems,
each of which alone may seem innocuous, even benevo-
lent, and wholly justiﬁable.
— Privacy Protection Study Commission, Personal Pri-
vacy in an information Society, July 1977
Paper-based communication and transaction mechanisms are being replaced by elec-
tronic mechanisms at a breath-taking pace. On the one hand, this transition improves
security and efﬁciency, and opens up a mind-boggling range of new opportunities.
On the other, it greatly increases the scope for identity fraud and erodes privacy in a
manner unimaginable just a couple of decades ago. If the prevailing ideas about how
to secure the global information highway are left unchallenged, then it will not take
long before everyone is forced to communicate and transact in what will be the most
pervasive electronic surveillance tool ever built.
What this book is about
This book proposes highly practical cryptographic building blocks that can be used
to design privacy-protecting electronic communication and transaction systems. The
new techniques allow individuals, groups, and organizations to communicate and
transact securely, in such a way that at all times they can determine for themselves
when, how, and to what extent information about them is revealed to others, and
to what extent others can link or trace this information. At the same time, the new
techniques minimize the risk of identity fraud, overcome many of the efﬁciency and
security shortcomings of the currently available mechanisms, and offer a myriad of
beneﬁts to organizations. They can be implemented in low-cost smartcards without
cryptographic coprocessors, admit elliptic curve implementations with short keys,
and encompass today’s views about digital certiﬁcates and public key infrastructures
as a special case.

xiv
PREFACE
The new techniques are beneﬁcial in any authentication-based communication or
transaction environment in which there is no strict need to identify certiﬁcate holders
at each and every occasion. The only acceptable role, if any, for identity certiﬁcates
in such environments is to facilitate registration in case certiﬁcate applicants must
be identiﬁed; this is similar to the way in which drivers’ licenses and passports are
traditionally used to acquire a permit or some other kind of authentication proof.
Any subset of the presented techniques (with the exception of those with con-
ﬂicting objectives) can be applied in combination. This facilitates a cookbook ap-
proach towards designing electronic communication and transaction systems. Ap-
plications of special interest include, but are not limited to: electronic cash; digi-
tal pseudonyms for public forums and virtual communities (such as Internet news
groups and chat rooms); access control (to Virtual Private Networks, subscription-
based services, Web sites, databases, buildings, and so on); digital copyright protec-
tion (anonymous certiﬁcates permitting use of works); electronic voting; electronic
patient ﬁles; electronic postage; automated data bartering (integration with standard-
ization efforts such as P3P is easy); online auctions; ﬁnancial securities trading; pay-
per-view tickets; public transport ticketing; electronic food stamps; road-toll pricing;
national ID cards (but with privacy); permission-based marketing; Web site person-
alization; multi-agent systems; collaborative ﬁltering (i.e., making recommendations
to one person based on the opinions of like-minded persons); medical prescriptions;
gift certiﬁcates; loyalty schemes; and, electronic gambling. The design of speciﬁc
applications is outside the scope of this book, though.
How the book is organized
Chapter 1 examines the role and the importance of digital certiﬁcates in communica-
tion and transaction mechanisms. It evaluates the major trends, and points out their
security, efﬁciency, and privacy shortcomings. It also contains an outline of the tech-
niques in the remainder of the book. While it is not necessary to read this chapter to
understand the remainder of the book, much of the motivation would be missed.
Chapter 2 gives an overview of preliminary cryptographicnotions and techniques,
and introduces several new cryptographic primitives that are central to the construc-
tions in the remaining chapters.
Chapter 3 presents certiﬁcate showing protocol techniques that enable the selec-
tive disclosure of personal (and other) data, and analyzes their privacy and security
properties. This chapter should not be read without ﬁrst reading at least parts of
Chapter 2.
Chapter 4 presents certiﬁcate issuing protocol techniques that enable an issuer
to encode attributes into certiﬁed key pairs that are unlinkable and untraceable in all
other respects, and analyzes their security. This chapter builds on Chapter 2, but may
be read independently of Chapter 3.
Chapter 5 describes how to combine the showing protocol techniques of Chap-

PREFACE
xv
ter 3 with the issuing protocol techniques of Chapter 4, and introduces a variety of
additional techniques to improve privacy and security. For instance, software-only
techniques are described for implementing limited-show certiﬁcates and for discour-
aging certiﬁcate holders from lending their certiﬁcates. This chapter builds on Chap-
ters 2, 3, and 4.
Chapter 6 shows how to lift the techniques of the preceding three chapters to a
setting in which certiﬁcate holders use smartcards or other tamper-resistant devices.
Many security, efﬁciency, and functionality beneﬁts are realized in this setting with-
out adding complexity and without downgrading privacy. We also show how to tune
our smartcard-enhanced protocols to accommodate any degree of privacy desired.
The material in this chapter draws on all four preceding chapters.
The Epilogue argues that privacy is best protected by supplementing privacy-
enhancing techniques (such as those developed in this book) with legislative mea-
sures. To support this claim it is shown how non-technical approaches toward pri-
vacy fail. The popular approach of “key escrow” is examined as well, and it is argued
that this approach does nothing but mislead individuals into believing that they have
privacy.
Acknowledgments
This book is an updated version of my self-published dissertation of September 1999.
The unconventional history of how that dissertation came about can be found in the
acknowledgments section of the dissertation, and is not repeated here.
My thanks go to my parents Jan and Bea, and to Vera and her parents Wil and
Wim, for their support and encouragement throughout the years.
I am indebted to Professor Richard Gill, who in 1991 brought me in contact with
the subject of cryptography and through his enthusiasm and encouragement got me
hooked.
My gratitude also goes to Professors Ron Rivest, Claus Schnorr, and Adi Shamir,
for taking place in my thesis reading committee and providing helpful suggestions
and comments. Dr. Berry Schoenmakers of Eindhoven University of Technology also
provided insightful comments on the draft dissertation.
Finally, I thank all those individuals and organizations around the world who
are contributing in a positive manner to protect privacy. Your efforts, ranging from
Internet discussions and press clippings to extensive resource archives and in-depth
studies, have been an important source of inspiration to my work.
Stefan Brands
Montreal
April 30, 2000


Summary
Introduction
Paper-based communication and transaction mechanisms are being replaced by au-
tomated transaction mechanisms at a breath-taking pace. Traditional security mech-
anisms such as photographs, paper-based certiﬁcates, and handwritten signatures are
rapidly becoming outdated: they require physical transport or proximity, are increas-
ingly vulnerable to counterfeiting and unauthorized duplication, and can be stolen,
extorted, or irreversibly destroyed. The enormous potential of communicating and
transacting in cyberspace (including the Internet, e-mail, cable TV, and mobile phone
networks such as GSM) and in the physical world (by means of smartcards and hand-
held computers) can only be unlocked if the new communication and transaction
mechanisms are adequately safeguarded.
Digital certiﬁcates are by far the most promising technique for safeguarding elec-
tronic communications and transactions. Just like passports, diplomas, drivers’ li-
censes, and other traditional certiﬁcates, they can specify any kind of data. Digi-
tal certiﬁcates are no more than cryptographically protected sequences of zeros and
ones, and so they can be transferred electronically to any place on earth (and in space)
without noticeable loss in time or costly human intervention. Digital certiﬁcates offer
unprecedented security: even if all the computing power on earth could be tapped, it
would take millions of years to forge a digital certiﬁcate.
Digital certiﬁcates are already widely used on the Internet, to authenticate e-mail,
Web servers, and software. The most popular Web browsers have built-in capabil-
ities for storing, sending, and verifying digital certiﬁcates. Digital certiﬁcates are
also playing an increasingly important role in electronic payments, access control (to
Web sites, databases, etcetera), digital copyright protection, electronic voting, elec-
tronic patient ﬁles, and so on. Around the world, transport organizations, municipal-
ities, health care providers, ﬁnancial institutions, and other inﬂuential organizations
are planning to provide their customers with digital certiﬁcates that will be the sole
means of participating in their systems. In the near future, digital certiﬁcates may
be built into any device or piece of software that must be able to communicate se-
curely with other devices or with individuals. This includes mobile phones, watches,
televisions, cars, and conceivably even computerized household appliances.

xviii
SUMMARY
The problem
While their prospects look bright and shiny, digital certiﬁcates have a dark side that
has received surprisingly little attention thus far. Unless drastic measures are taken, it
will not take long before everyone is forced to communicate and transact in what will
be the most pervasive electronic surveillance tool ever built. Each digital certiﬁcate
can be traced uniquely to the person to whom it has been issued (or to the device
in which it has been incorporated) and can be followed around instantaneously and
automatically as it moves through the system. Even digital certiﬁcates that do not ex-
plicitly specify the identity of their holder can be traced in a trivial manner, because
the string of zeros and ones that makes up a digital certiﬁcate for security reasons
must be unique; digital certiﬁcates in this respect offer no more privacy than Social
Security numbers, credit card numbers, and health registration numbers. On the ba-
sis of these unique serial numbers, which will travel along whenever an individual
engages in a communication or a transaction, organizations and individuals can com-
pile extremely detailed personal dossiers. The dossiers can be compiled and linked
without human intervention, can be dynamically updated in near real time, and will
contain minute information about a person’s ﬁnancial situation, medical history and
constitution, lifestyle, habits, preferences, movements, and so on. Any digital signa-
tures made by certiﬁcate holders can be added to their dossiers; they form self-signed
statements that cannot be repudiated. With the cost of digital storage space dropping
all the time, all dossiers will be stored potentially forever.
Furthermore, digital certiﬁcates can be misused to deny a certiﬁcate holder ac-
cess to services, and to block his or her communication attempts in real time. For
example, certiﬁcate blacklists can be built into Internet routers. Also, transaction-
generated data conducted with target certiﬁcates can be ﬁltered out by surveillance
tools, and delivered electronically to law enforcement and other third parties for ex-
amination or immediate action. Online certiﬁcate validation services even enable
central authorities to learn in real time who communicates with whom and to falsely
deny access.
These exceptional surveillance powers will be enjoyed not only by all the orga-
nizations that a person directly communicates or transacts with, but also by a myriad
of private and public organizations that routinely acquire dossiers, by unscrupulous
employees, by hackers, by law enforcement and intelligence agencies, and by all or-
ganizations that issue digital certiﬁcates. Typical representatives of the latter group
will be ﬁnancial institutions, governments (local, state, and federal), insurance com-
panies, health care providers, post ofﬁces, public transport organizations, and con-
sumer credit bureaus.
Smartcards exacerbate the privacy problems. As Moreno, the inventor of the ﬁrst
generation of smartcards, remarked, smartcards have the potential to become “Big
Brother’s little helper.” It is almost impossible to verify that a smartcard does not
leak personal data stored inside the card, and different applications can all share the
same card data without the consent of the cardholder.

SUMMARY
xix
The solution
This book analyzes and documents the privacy dangers of digital certiﬁcates. On the
basis of the ﬁndings, practical digital certiﬁcates are constructed that preserve privacy
without sacriﬁcing security. The new certiﬁcates function in much the same way as
cash, stamps, cinema tickets, subway tokens, and so on: anyone can establish the
validity of these certiﬁcates and the data they overtly specify, but no more than just
that. A “demographic” certiﬁcate, for instance, can specify its holder’s age, income,
marital status, and residence, all digitally tied together in an unforgeable manner.
The new certiﬁcates are not only much more secure and efﬁcient than their non-
electronic counterparts, but also much more powerful. For instance, each certiﬁcate
holder can decide for him or herself, depending on the circumstances, which property
to disclose of the data encoded into a digital certiﬁcate. This goes beyond the analogy
of using a marking pen to cross out data ﬁelds on a paper-based certiﬁcate; a certiﬁ-
cate holder can prove that he or she is either over 65 or under 18, for instance, with-
out revealing which is the case. More generally, certiﬁcate holders can demonstrate
any satisﬁable proposition from proposition logic, where the atomic propositions are
linear relations in the encoded data; any other information remains unconditionally
hidden.
Also, a certiﬁcate can be presented in such a manner that no evidence is left at
all of the transaction; this is much like waving a passport when passing customs.
Alternatively, it can be presented in such a manner that the only information left is
self-authenticating evidence of a message or a part of the disclosed property; this is
much like presenting a paper-based certiﬁcate with crossed-out data ﬁelds so that a
photocopy can be made. Furthermore, the self-authenticating evidence can be limited
to designated parties.
The new techniques enable certiﬁcate issuers to discourage lending of personal
certiﬁcates. An issuer of gender certiﬁcates (needed to gain access to gender-speciﬁc
online forums, say) could encode into each certiﬁcate not only a bit indicating the
gender of the designated receiver, but also the credit card number or some other
secret of the receiver. While certiﬁcate holders can hide their built-in secrets when
they show their certiﬁcates, it is not possible to show a certiﬁcate without knowing
the built-in secret. Therefore, certiﬁcate holders cannot lend their certiﬁcates without
revealing their secrets.
Another useful technique makes it possible for a central authority to compute
all the data that have been encoded into a certiﬁcate once that certiﬁcate is shown
more than a predetermined number of times. In particular, a built-in identiﬁer can be
computed even if the certiﬁcate holder never discloses any of the built-in data when
showing his or her certiﬁcates. This magical security property holds even when the
certiﬁcate holder is free at each occasion to choose the property that he or she demon-
strates when presenting the certiﬁcate. It allows the certiﬁcate issuer to trace and
contain fraud with limited-show certiﬁcates (such as subway tokens and electronic
coins), to (further) discourage unauthorized lending and copying of personal certiﬁ-

xx
SUMMARY
cates, and to discourage the destruction of unfavorable certiﬁcates (such as a mark
for drunk driving or late payment).
Yet another technique enables a certiﬁcate issuer to refresh a previously issued
certiﬁcate without knowing the encoded data. The unknown encoded data can even
be updated before it is recertiﬁed. By way of example, a doctor could issue a pre-
scription to a patient for 20 doses of a penicillin cure. Each time the patient visits
a drugstore to collect some of the doses, the drugstore can verify that the patient is
still eligible and can decrement the number of remaining penicillin doses. On the
other hand, no drugstore can determine the total number of doses prescribed or the
number remaining at the time of a visit, nor can different visits by the same patient be
linked. Using our certiﬁcation techniques, the patient could even pay for each dose
in untraceable electronic cash and receive a digital receipt that could be used to get
reimbursed by his or her health insurance company.
We also describe techniques to improve the privacy of organizations. In partic-
ular, we show how an organization can verify a certiﬁcate in such a manner that it
receives self-authenticating evidence that proves that the certiﬁcate has been shown
but unconditionally hides all or an arbitrary part of the property that has been demon-
strated. In applications where organizations submit the certiﬁcates they receive to a
central authority, to enable the latter to compute statistics or to combat fraud, this
property prevents the central authority from learning which information an organi-
zation’s customers disclosed. Organizations cannot provide false information to the
central authority, but in the case of disputes they can always reveal additional infor-
mation about the demonstrated properties.
All these and other software-only techniques can be implemented in tamper-
resistant smartcards. The smartcard offers strong protection against loss, theft, ex-
tortion, lending, copying, and discarding of certiﬁcates, and can restrain its holder
from other undesired behavior. More generally, the smartcard can be used either
to strengthen our software-only security provisions or to add security features that
software-only techniques cannot enable at all. Also, the presence of the smartcard
removes the need for online authorization or frequent distribution of certiﬁcate re-
vocation lists. At the same time, the smartcard can be prevented from learning the
certiﬁcates of its holder, the information encoded into the certiﬁcates, and even the
properties that are demonstrated when showing digital certiﬁcates. In addition, any
data leakage by or to the smartcard can be blocked. The cardholder can even prevent
his or her smartcard from developing information that would help the card issuer to
retroactively trace the cardholder’s transactions should the card’s contents become
available to the card issuer. Transactions can be completed within as little as 1/20-
th of a second by a standard 8-bit smartcard processor, so that road-toll pricing and
other demanding applications are entirely feasible.
Our techniques protect privacy in the strongest possible sense: even if all orga-
nizations (including those that issue certiﬁcates and those that verify them) conspire
and have inﬁnite computing resources, and issue smartcards that are programmed

SUMMARY
xxi
in adverse manners, they cannot learn more about (honest) certiﬁcate holders than
the assertions they voluntarily demonstrate. Different actions by the same certiﬁcate
holder cannot be linked, unless the certiﬁcate holder consents and cooperates.
Our certiﬁcation techniques are advantageous not only to individuals, but also to
organizations: they prevent certiﬁcate issuers and other central parties from compet-
ing unfairly; they minimize the need to consult certiﬁcate revocation lists or online
certiﬁcate validation services; they minimize the scope for law enforcement intru-
sions on databases; they minimize the need to protect online databases against intru-
sions by hackers and insiders; they reduce the scope for discrimination and identity
fraud; they foster fair competition with respect to the collection and use of personal
data; they are the cheapest and most effective way to comply with most of the fair in-
formation principles of privacy legislation and codes of conduct; they improve trans-
action ﬁnality; and, they cultivate goodwill among customers.
The presented techniques could help stimulate the public acceptance of smart-
cards, because low-cost smartcards without cryptographic coprocessors can be used
and smartcards cannot be misused for the purpose of surveillance. They could even
stimulate the growth of electronic commerce by providing a ﬁrm grounding for up-
coming digital signature legislation. Namely, secret keys protected by smartcards
(or other tamper-resistant devices) with biometric protection are not vulnerable to
theft, extortion in cyberspace, and unauthorized use, and can therefore be reliably
associated with a particular individual.


List of Figures
3.1
Generic protocol for demonstrating formula (3.3). . . . . . . . . . . . .
99
3.2
Protocol for Example 3.3.9. . . . . . . . . . . . . . . . . . . . . . . . .
104
3.3
Generic protocol for demonstrating formula (3.3), with v replacing q.
.
107
3.4
Protocol for Example 3.3.16. . . . . . . . . . . . . . . . . . . . . . . .
109
3.5
Generic protocol for demonstrating formula (3.4). . . . . . . . . . . . .
114
3.6
Protocol for Example 3.4.7. . . . . . . . . . . . . . . . . . . . . . . . .
117
3.7
Protocol for Example 3.5.5. . . . . . . . . . . . . . . . . . . . . . . . .
124
3.8
Protocol for Example 3.6.4. . . . . . . . . . . . . . . . . . . . . . . . .
127
4.1
DLREP-based scheme I.
. . . . . . . . . . . . . . . . . . . . . . . . .
137
4.2
DLREP-based scheme II. . . . . . . . . . . . . . . . . . . . . . . . . .
138
4.3
RSAREP-based scheme I.
. . . . . . . . . . . . . . . . . . . . . . . .
141
4.4
RSAREP-based scheme II. . . . . . . . . . . . . . . . . . . . . . . . .
142
4.5
RSAREP-based scheme I without use of trapdoor information. . . . . .
144
4.6
Immunization I of RSAREP-based scheme I.
. . . . . . . . . . . . . .
165
4.7
Immunization II of DLREP-based scheme I. . . . . . . . . . . . . . . .
167
4.8
Immunization II of RSAREP-based scheme II. . . . . . . . . . . . . . .
172
4.9
DSA-like scheme. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
174
4.10 Scheme based on Chaum-Pedersen signatures. . . . . . . . . . . . . . .
177


Chapter 1
Introduction
In this chapter we examine the role and the importance of digital certiﬁcates in com-
munication and transaction mechanisms. We discuss the main developments and
point out their security, efﬁciency, and privacy shortcomings. Next we examine the
meager previous efforts to protect privacy in public key infrastructures. Amongst
others, we show that the popular suggestion to offer privacy by issuing pseudony-
mous certiﬁcates is not only insecure in almost all situations, but also ineffective to
protect privacy. On the basis of the previous ﬁndings we list basic desirable privacy
properties. Finally, we outline how the techniques that will be developed in later
chapters meet these and other privacy properties and at the same time help overcome
the security and efﬁciency problems.
1.1
Digital certiﬁcates and PKIs
1.1.1
From paper-based to digital certiﬁcates
Individuals and organizations often have a legitimate need to verify the identity or
other attributes of the individuals they communicate or transact with. The traditional
method for demonstrating that one meets certain qualiﬁcations is to disclose one
or more paper-based certiﬁcates. As deﬁned in the third edition of the American
Heritage Dictionary of the English Language, a certiﬁcate is “a document testifying
to the truth of something.” Photographs, handwritten signatures, and physical cues
help the veriﬁer to establish the identity of the holder of a certiﬁcate. Embedded
security features (such as special paper, watermarks, ink that appears different when
viewed from different angles, and microprinted words and other detail that is hard to
replicate) serve to protect against counterfeiting and unauthorized duplication.
Since the advent of computers and telecommunication networks, paper-based
transaction mechanisms are being replaced by electronic transaction mechanisms at

2
INTRODUCTION
a breath-taking pace. Many forces drive this unstoppable transition:
• The theft, loss, or destruction of a paper-based certiﬁcate coincides with the
theft, loss, or destruction of at least part of its value. It may be expensive,
difﬁcult, or impossible to obtain a new copy from the issuer.
• Paper-based certiﬁcates are subject to wear and tear, add to the depletion of
forests, are costly to handle, and in many situations are inefﬁcient. Electronic
certiﬁcates can be manufactured, distributed, copied, veriﬁed, and processed
much more efﬁciently and at lesser cost.
• Paper-based certiﬁcates are not suitable to convey negative qualiﬁcations of
their holders. An individual carrying a certiﬁcate attesting to the fact that he
or she has been in prison, say, can simply discard the certiﬁcate. Sometimes
negative qualiﬁcations can be tied in with positive ones (e.g., a mark for drunk
driving on a driver’s license), but this measure is not always an option.
• Cyberspace (the conglomeration of networks that enable remote communica-
tion, including the Internet, e-mail, cable TV, and mobile phone networks such
as GSM) offers huge beneﬁts over face-to-face communications and transac-
tions in the physical world. Many of the beneﬁts cannot be realized using
paper-based certiﬁcates, however, since these require physical transport.
• The public at large can avail itself at modest cost of ever-advancing desktop
reprographic equipment. A nationwide study conducted in 1998 by U.S. cor-
porate investigation ﬁrm Kessler & Associates found resume and credential
fraud to be of “almost epidemic proportions.” Counterfeiting rarely requires
perfection; it usually sufﬁces to produce something that will pass casual hu-
man inspection. Ultimately, the counterfeiting threat can be overcome only
by moving to certiﬁcates that are cryptographically secured and that can be
veriﬁed with 100 percent accuracy by computers.
In many applications, symmetric cryptographic techniques are inappropriate: they
require a trusted third party to set up a secret key for any two parties that have not
communicated previously, and cannot offer non-repudiation. Thus, there is a fun-
damental need for public key cryptography. Public key cryptography enables the
parties in a system to digitally sign and encrypt their messages. When two parties
that have not communicated before want to establish an authenticated session, they
need merely fetch the public key of the other; there is no need for a trusted third party
to mediate every transaction.
In their seminal paper [136] on public key cryptography, Difﬁe and Hellman
pointed out the problem of authenticating that a public key belongs to an entity. They
suggested using secure online repositories with entries that specify name–key bind-
ings. In 1978, Kohnfelder [238] proposed to avoid this potential bottleneck by having

1.1 DIGITAL CERTIFICATES AND PKIS
3
a trusted entity, called the Certiﬁcate Authority1 (CA), vouch for the binding between
a public key and its holder. A digital certiﬁcate is a signed assertion about a public
key. More speciﬁcally, it is a digital signature of the CA that binds a public key
to some other piece of information, in Kohnfelder’s case the name of the legitimate
holder of the public key. This enables all system participants to verify the name–key
binding of any presented certiﬁcate by applying the public key of the CA. There is
no need to involve the CA in the veriﬁcation process; veriﬁcation can be off-line.
A public key infrastructure (PKI), also called key management infrastructure, is
an infrastructure for a distributed environmentthat centers around the distribution and
management of public keys and digital certiﬁcates. It is widely recognized that PKIs
are an essential ingredient for secure electronic communications and transactions in
open environments. See, for instance, Feghhi, Williams, and Feghhi [167], Ford and
Baum [172], Froomkin [177], Lewis [251], and Zimits and Montano [395].
The CA can be made responsible not only for certifying public keys and authen-
ticating certiﬁcate applicants, but also for notarizing electronic documents, resolving
disputes, and keeping track of revoked keys. Some or all of these functions may be
managed by separate trusted parties. For instance, the registration and approval of
certiﬁcate applicants may be done by a separate Registration Authority.
In practice, a PKI can have multiple CAs, so that certiﬁcate applicants and veri-
ﬁers need not trust a single CA. CAs can certify the public keys of other CAs, and
in this manner arbitrary CA structures can be formed. This gives rise to such notions
as certiﬁcate chains, bridge CA’s, and cross certiﬁcation; see Burr [68]. Our tech-
niques enable anyone to be the issuer of their own digital certiﬁcates, and all issuers
can coexist in a single PKI. We will not address multi-CA PKIs, though, because the
techniques for these are straightforward and largely orthogonal to the techniques that
we will develop in this book. For simplicity, we will always assume that each PKI
has only a single CA, unless explicitly stated otherwise.
Also for simplicity, we will often equate certiﬁcate holders with individuals, and
certiﬁcate veriﬁers with organizations. More generally, the entities that retrieve, hold,
show, verify, or otherwise operate on certiﬁcates may be software programs, hard-
ware devices, or anything else that can perform the required logical steps.
1.1.2
Identity certiﬁcates
An object identiﬁer is any data string that can readily and uniquely be associated
with the object. What Kohnfelder called a digital certiﬁcate is better referred to as
an identity certiﬁcate, because it binds a public key to a person identiﬁer, such as a
credit card number, a “true name,” a ﬁngerprint, a Social Security number, or a health
registration number.
The X.509 certiﬁcate framework [216] is the best known example of identity
certiﬁcates. In 1988, the International Telecommunications Union (formerly the In-
1In recent years the term Trusted Third Party (TTP) has gained in popularity.

4
INTRODUCTION
ternational Consultative Committee on Telephone and Telegraphy) started working
on X.509. X.509v1 was designed to certify the public keys of principals that are
uniquely named in X.500 [80, 195, 385], an online database listing globally unique
names; an entry in an X.500 directory can be a person, a device, or anything else that
can be assigned a “Distinguished Name.” X.509v2, released in 1993, provided for a
more ﬂexible choice of identiﬁers. X.509v3, announced in June 1997 (see [218] for
amendments), greatly improved the ﬂexibility of X.509 certiﬁcates, by providing for
a generic mechanism to extend certiﬁcates. Also, X.509v3 allows the use of local
names in certiﬁcates, acknowledging that a global naming scheme is unworkable.
Numerous (draft) standards and CA products have been developed based on the
X.509 framework. X9.55 [8, 11], for example, is an ANSI-adopted standard devel-
oped by the American Bankers Association that is similar to X.509 but targeted at
the ﬁnancial services industry. Another effort is PKIX [4, 114], a draft standard by
the Internet Engineering Task Force (IETF) to make X.509v3 certiﬁcates suitable for
the Internet.2 Other implementations of X.509 certiﬁcates include Privacy Enhanced
Mail [86, 230] (PEM, an IETF e-mail standard proposal), Fortezza (the standard for
secure e-mail and ﬁle encryption in the U.S. defense system), Secure/Multipurpose
Internet Mail Extensions [140, 141] (S/MIME, an e-mail standard proposed by RSA
Security), Secure Socket Layer version 3.0 [174] (SSL, developed by Netscape to
support server and client authentication and session encryption), and Secure Elec-
tronic Transactions [257] (SET, proposed by MasterCard and Visa for securing card-
not-present credit card transactions).
Also, virtually all the pilot PKI projects conducted by 24 U.S. federal agencies
(including the NSA, the IRS, the FBI, the U.S. Department of Defense, and the So-
cial Security Administration) as part of the Federal Public Key Infrastructure [163]
(FPKI) use X.509v3 certiﬁcates, with application-dependent extensions.
For in-
stance, the U.S. Department of Defense is building a PKI “to ensure the authenticity
of digital signatures on contracting documents, travel vouchers, and other forms that
obligate taxpayer funds, to authenticate users of information systems, and protect
the privacy of transactions over networks;” see the DoD Public Key Infrastructure
Program Management Ofﬁce [138, 139] for details.
Another U.S. federal PKI plan based on X.509v3 certiﬁcates is Access Certiﬁ-
cates for Electronic Services [377, 378] (ACES), which will provide for public elec-
tronic access to government services and information. Furthermore, the Department
of Justice, the Department of Defense, the NSA, and NASA formed a government-
industry consortium called Security Proof Of Concept Keystone (SPOCK); its goal
is to demonstrate commercial and federal PKI solutions in cooperation with security
technology providers. According to the National Institute of Standards and Technol-
ogy (NIST), which is responsible for U.S. federal computer security, the FPKI will
be knit together from these and other PKI efforts.
2IBM and its Lotus Development subsidiary in July 1998 started making the source code for their
PKIX implementation Jonah available to the public, to promote applications based on PKIX.

1.1 DIGITAL CERTIFICATES AND PKIS
5
Other jurisdictions that are in advanced stages of planning federal PKIs include
the United Kingdom (its CLOUD COVER initiative is aimed to stimulate the growth
of a government-wide PKI), Australia (the Australian Public Key Authentication
Framework, PKAF for short, will result from the Gatekeeper federal infrastructure
program and efforts by the Certiﬁcation Forum of Australia), Canada (in 1995, the
Treasury Board endorsed a project called GOC PKI, for Government of Canada Pub-
lic Key Infrastructure), and Hong Kong (in November 1999, the Hong Kong postal
service started issuing identity certiﬁcates to most of the 6.5 million residents). All
these efforts are compatible with the X.509v3 standard. For a snap-shot overview
as of July 1999 of the PKI initiatives in 26 member countries of the Organisation
for Economic Co-operation and Development (OECD, an international organization
consisting of 29 primarily industrialized countries), see the Working Party on Infor-
mation Security and Privacy [296] of the OECD.
Dozens of developers around the world specialize in CA products involving iden-
tity certiﬁcates, most of them based on X.509. Among the major players are VeriSign,
Baltimore Technologies, Entrust Technologies, and Thawte Consulting (acquired in
February 2000 by VeriSign). In recent years a host of companies joined them in
their race to capture the identity certiﬁcate market (either products or services),
including ABAecom, ActivCard, BelSign, Brokat, Celo Communications, Certco,
CertiSign, Chrysalis-ITS, Cryptomathic, GTE CyberTrust, Cylink, Digital Signature
Trust Company, Entegrity Solutions, EuroSign, EuroTrust, Frontier Technologies,
Gemplus, GlobalSign, Internet Dynamics, Identrus, InterClear, KeyPOST, KeyWit-
ness, Litronic, RSA Security, Sonera SmartTrust, Spyrus, Sun Certiﬁcate Authori-
ties, Utimaco, ValiCert, Xcert International, and Zergo. Also, major corporations
including American Express, AT&T, Canada Post, CompuSource, Equifax, Hewlett-
Packard, IBM, Lotus Development, Microsoft, Motorola, Netscape, and Novell all
support the X.509 digital certiﬁcate standard.3 To accelerate the adoption of iden-
tity certiﬁcates, Baltimore Technologies, Entrust Technologies, IBM, Microsoft, and
RSA Security in December 1999 founded an alliance that has since been joined by
over 40 other companies.
Another well-known scheme based on identity certiﬁcates is Pretty Good Pri-
vacy [69, 396] (PGP). PGP certiﬁcates bind a public key to a common name and an
e-mail address. PGP is based on a different metric of authentication (see Levien and
Aiken [250] and Reiter and Stubblebine [321]) than X.509: anyone in the PGP “Web
of Trust” can certify keys.
As these developments show, identity certiﬁcates are widely perceived as a fun-
damental technology for secure electronic communications and transactions. Market
surveys conﬁrm this. A study released in March 2000 by the Radicati Group, for
instance, estimates that the market for CA software for identity certiﬁcates will grow
from over 368 million U.S. dollar in revenues by year end 2000 to over 1.5 billion
U.S. dollar by 2004. Another survey by IDC expects the market to grow to 1.3 billion
3Most companies offer services and products based on the CA toolkits of a select few.

6
INTRODUCTION
U.S. dollar in 2003.
Identity certiﬁcates will also play a major role in the many plans outside cy-
berspace to migrate to chipcards. A chipcard is a plastic card that has the shape and
thickness of a conventional credit card, and that contains one or more embedded in-
tegrated circuits. Around the world, public transport organizations, municipalities,
health care providers, ministry departments, ﬁnancial institutions, and other inﬂuen-
tial organizations are planning to provide all their customers with a chipcard that will
be the sole means of participating in their systems. Due to the storage and computa-
tion limitations of current chipcard technologies, identity certiﬁcates do not yet have
a prominent place in many of these plans. However, over time the move towards
digital certiﬁcates is inevitable, for security reasons; see Section 1.1.6 for details.
1.1.3
Central database paradigm
In many applications with a need for authentication, organizations are not (primarily)
interested in the identity of a key holder, but in the conﬁrmation of previous contacts,
the afﬁliation of the key holder to a group, the authenticity of personal data of the
key holder, the eligibility or capability of the key holder to perform certain actions,
and so on. Identity certiﬁcates can be used by organizations as authenticated pointers
into central database entries that contain the relevant data, and thus support any such
authentication needs. This central database paradigm allows organizations to consult
any databases they are interested in, to update database entries as they see ﬁt, and to
securely maintain negative data about system participants. It also enables organiza-
tions to build proﬁles of individuals for the purpose of inventory management, direct
marketing, and so on.
It is easy to see why the use of identity certiﬁcates in conjunction with central
database look-up has become the model of choice: until recently, it was expensive or
impractical to resort to decentralized computing and distributed databases. The cen-
tralized model, however, has many drawbacks for organizations and other certiﬁcate
veriﬁers:
• The transaction process requires a sufﬁcient delay to identify and correct frauds
and other undesirable conditions. This may result in organizations being un-
able to serve as many customers as they could otherwise.
• Because certiﬁcate holders are not ensured that their transactions will be autho-
rized, signiﬁcant uncertainty is introduced in the transaction process. Requests
may be rejected on the basis of erroneous or irrelevant data, or simply because
the online connection fails due to peak load, a natural disaster, or otherwise.
(The chances of an off-line terminal failing are much slimmer, and moreover
the certiﬁcate veriﬁer may take immediate action to overcome the problem.)
• In case the verifying agents of an organization are geographically distributed,
central database veriﬁcation may be expensive (because of telecommunica-

1.1 DIGITAL CERTIFICATES AND PKIS
7
tions cost or the difﬁculty of dealing with peak load) or simply not an option
because of the absence of network connections.
• Requests for central database look-up may be dishonored for any reason and
may be expensive (especially if databases are operated by commercial organi-
zations such as consumer reporting bureaus).
• It is increasingly difﬁcult for organizations to protect their online databases
against intrusions by hackers and insiders. This exposes organizations to inci-
dents that might incur legal liability or hurt their reputation.
• The trend is for governments to require organizations that handle personal
data4 to adhere to (legal or self-enforced) privacy standards. Signiﬁcant com-
pliance costs are involved with personnel training, making databases accessible
to external auditors, and so on.
• The possession of data about the personal preferences and lifestyle of individ-
uals enables organizations to discriminate against their customers in all kinds
of ways. This increases the scope for false complaints and legislative actions.
It is ironic that digital certiﬁcates today are considered by many to be a secure way to
provide access to personal data stored in central databases. The practice of looking
up data in real time in a central database goes against the philosophy behind digi-
tal certiﬁcates, which is to allow off-line veriﬁcation of digital signatures. In many
PKIs it is a waste of efﬁciency to use digital certiﬁcates in combination with central
database look-up; one might as well do away with digital certiﬁcates altogether and
simply check the validity of public keys in a central database. Indeed, Wheeler and
Wheeler [388] and the Accredited Standards Committee X9 [3] for this reason pro-
pose a return to the online key repository model of Difﬁe and Hellman. (This model
cannot protect the privacy of certiﬁcate holders, though, as we will see later on.)
The central database paradigm is even less desirable from the perspective of in-
dividuals:
• Individuals can be discriminated against on the basis of data that is not rele-
vant for the situation at hand. Such discrimination could go about without the
individual being aware of the source of the discrimination, the nature of the
data used against him or her, or even the mere fact of the discrimination. A
qualiﬁed job applicant may be rejected just because some manager who both-
ered to consult a few databases (such as Internet newsgroup archives) cannot
relate to his or her lifestyle. Likewise, individuals soliciting a loan or anyone
of a myriad of other services may ﬁnd their applications turned down because
somewhere in the process someone discriminated against them, or in favor of
others, on the grounds of irrelevant data.
4The OECD deﬁnes [294] personal information as “any information relating to an identiﬁed or identi-
ﬁable individual (data subject).”

8
INTRODUCTION
Material damage may result when personal data is accessed with malicious in-
tent. Stalkers, murderers, and extortioners use address information from credit
reports and other sources that reveal consumer data to track down their vic-
tims. Blackmailers persuade their victims by threatening to reveal sensitive
personal data, and kidnappers and robbers plan when to strike by following
the whereabouts of their victims. Many criminals are not concerned about tar-
geting a particular individual, but instead select their victims on the basis of
their proﬁle; robbers and blackmailers mainly target wealthy singles, and po-
litical aggressors are often interested in individuals with particular political or
religious convictions.
• When data records do not reﬂect an individual’s true situation, perfectly eligi-
ble individuals may end up losing their insurances, loans, housing, jobs, repu-
tations, and so on. Errors are far from uncommon. For instance, the sixth study
of the U.S. Public Interest Research Group [314] on credit report accuracy and
privacy issues found that 29% of U.S. credit reports contain serious errors that
could result in the denial of credit, loans, or jobs, and that altogether 70% of
credit reports contain mistakes. Data in central databases may not reﬂect an
individual’s true situation for a number of reasons:
– A substantial portion of all captured data is outdated. One cannot reason-
ably expect individuals to inform all database operators each time their
personal circumstances change; individuals in developed countries are
stored on average in roughly a 1000 databases, most of which are un-
known to them.
– Another portion contains information that was composed by drawing in-
correct inferences from other sources of data.
– Whenever data is conveyed orally or in writing, errors are bound to be
made when the data is translated into machine-readable form.
– Data stored in databases may be modiﬁed or destroyed by hackers and
other outsiders. With the rise of the Internet, the risks are increasing
dramatically. Hackers almost routinely gain access to databases, both
commercial and governmental, and are rarely prevented from erasing or
modifying data records without leaving a trace. In an infamous hack in
the mid 1980s, a hacker broke into the databases of Experian (one of
the three largest U.S. credit bureaus) to peak into the credit records of
Ronald Reagan, and discovered 63 other requests for Reagan’s records,
all logged on the same day.
– Data stored in databases may be modiﬁed or destroyed by authorized
database users and other insiders. Any organization of substantial size is
bound to have employees who are willing to accept bribes or have mali-
cious intentions of their own. A 1998 survey [215] by the Computer Se-

1.1 DIGITAL CERTIFICATES AND PKIS
9
curity Institute found that the attack that was by far the most reported by
its respondents (520 security practitioners in U.S. corporations, govern-
ment agencies, ﬁnancial institutions, and universities) was unauthorized
access by employees.
– Misbehavior by identity thieves often ends up registered in the database
entries of their victims. The incidence of identity fraud has been rising
dramatically since the mid eighties. Since 1996, calls on identity theft
have been the number one topic on the hotline of the U.S. Privacy Rights
Clearinghouse. For details on identity fraud, see Cavoukian [78], the
Federal Trade Commission [164], the General Accounting Ofﬁce [183],
Givens [186], and the U.S. National Fraud Center [392].
Since errors spread throughout the system and accumulate as data is dissem-
inated and merged, victims may ﬁnd themselves affected by the same errors
over and over again.
• Individuals have lost all control over how personal data in databases is becom-
ing available to others. Collectors of personal data are always tempted to sell
the data or to provide access to it in other ways (thousands of information re-
sellers already offer their services over the Internet to anyone willing to pay),
information brokers and private investigators resort to trickery (“pretexting”)
to obtain all kinds of personal data, and most countries around the world have
laws that require database maintainers to provide access to law enforcement
when presented with a court order or a warrant. Also, personal data increas-
ingly becomes available to others by error. In recent years the popular press
has reported on numerous cases whereby commercial organizations (such as
providers of free e-mail services, credit bureaus, and Internet merchants) as
well as government organizations (including social security administrations,
law enforcement, and taxation authorities) inadvertently released sensitive per-
sonal data to the wrong parties or to the public at large.
In many cases it is virtually impossible for victims to seek and obtain redress. The
basis or source of discrimination, misuse, or other harmful actions may never become
known in the ﬁrst place, and even if it does, it may be very hard to repudiate the
action.
1.1.4
Attribute certiﬁcates
In the early 1990s, the idea of attribute certiﬁcates gained interest. An attribute
certiﬁcate binds a public key to one or more attributes, which X.501 [81] (also known
as ISO/IEC 9594-2) deﬁnes as “information of any type.”5
5This terminology makes sense when considering the dictionary meaning of “attribute.” The third
edition of the American Heritage Dictionary of the English Language deﬁnes an attribute as “a quality or
characteristic inherent in or ascribed to someone or something.”

10
INTRODUCTION
Attribute certiﬁcates are a generalization of identity certiﬁcates (an identiﬁer is
just one of inﬁnitely many attributes), and have naturally evolved from them. Indeed,
identity certiﬁcates typically specify other data than just a person identiﬁer and a
public key. For instance, an X.509v3 certiﬁcate also speciﬁes a version number, a
serial number (for revocation purposes), a signature algorithm identiﬁer, a CA name,
a validity period, a subject name, a CA signature algorithm identiﬁer, a subject public
key algorithm identiﬁer, and (optional) CA and subject identiﬁers and extensions.
However, identity certiﬁcates typically contain no other personal data than a person
identiﬁer.
From now on we reserve the term attribute certiﬁcates to refer to digital cer-
tiﬁcates that serve primarily to enable veriﬁers to establish attributes other than the
identity of the key holder (such as access rights, authorities, adherence to standards
or legal requirements, privileges, permissions, capabilities, preferences, assets, de-
mographic information, and policy speciﬁcations).
Attribute certiﬁcates have important advantages over identity certiﬁcates:
• It is inconvenient for millions of individuals to make a physical appearance
before CAs. In November 1998, market researcher INTECO Corp. found that
only 64% of Internet users would be willing to appear in person to have their
identity veriﬁed for a digital certiﬁcate. For many types of attribute certiﬁcates,
there is no need to show up in person at a CA.
• It is typically much harder, more error-prone, and more costly for a CA to
establish a person’s identity than to establish authorities and other personal
attributes. In PKIs where organizations are interested only in non-identity at-
tributes, not including identities can therefore bring substantial savings in cost
and time, and can reduce the risk of identity fraud.
• Identity certiﬁcation may expose a CA to much greater liability. Typically,
only government agencies and major organizations such as credit bureaus and
ﬁnancial institutions are in a good position to take on the role of establishers of
identity.6 Indeed, Kaufman Winn and Ellison [228] argue that the CA cannot
legally make users liable for actions for which they cannot reasonably be ex-
pected to control the risks and losses, because PKIs cannot subsume risk at the
technical level. (The latter observation is also at the heart of critiques against
6Recent market developments are in line with this. In December 1998, for instance, the government
of Ontario, representing over a third of Canada’s citizens, announced that it will issue identity certiﬁcates
to its 11 million residents. Identrus [376], a joint venture set up in October 1998 by eight international
banks, issues identity certiﬁcates for business-to-business electronic commerce. Equifax Secure, a divi-
sion of Equifax (one of the three major U.S. consumer credit bureaus), in May 1999 announced an identity
certiﬁcate service that matches information provided by individuals against data from Equifax Credit In-
formation Services and other consumer and business information sources, to establish identity in real
time. Strassman and Atkinson [363] propose that the U.S. Department of Motor Vehicles issue identity
certiﬁcates.

1.1 DIGITAL CERTIFICATES AND PKIS
11
identity-based PKIs by Geer [182], Kaufman Winn [227], Gladman, Ellison,
and Bohm [187], Guida [200], and Ellison and Schneier [148].7)
• As Garﬁnkel [181, Chapter 4] explains, the approach of creating a society in
which every person can be held accountable for his or her own actions by
replacing anonymity (i.e., the privacy of identity) with absolute identity is fun-
damentally ﬂawed. Identity will have to be established on the basis of legacy
paper-based systems, and thus will inherit their insecurity. Also, identities may
erroneously or maliciously be swapped or forged. Criminals who manage to
steal identity certiﬁcates or to assume the identities of unwitting people will
be able to misuse certiﬁcates in cyberspace on a global scale, while their vic-
tims take the blame. Punishment of the wrong individuals will make others
reluctant to participate.
• In PKIs in which communicating or transacting parties have not established a
prior relation, certiﬁcate veriﬁers will primarily be interested in the privileges
and other non-identity attributes of certiﬁcate holders. If an individual’s certiﬁ-
cate includes all the attributes that a veriﬁer needs to know in order to locally
decide what action to take, many of the drawbacks of central database look-up
are overcome.
Placing the data that would otherwise be listed in central database entries into at-
tribute certiﬁcates is most natural in closed PKIs. A closed PKI is a PKI which has
one issuer and clear contractual relationships between the issuer, certiﬁcate appli-
cants, and veriﬁers. Closed PKIs are much more viable than open PKIs, where each
certiﬁcate serves to establish authenticity in a potentially unbounded number of ap-
plications, since it is much easier to determine the risks and liabilities in a closed
PKI. Moreover, organizations typically are not willing to let others issue certiﬁcates
on their behalf, for commercial and liability reasons.
An early proposal for attribute certiﬁcates is due to Brands [54], in 1993. This
proposal aims to protect the privacy of certiﬁcate holders, and forms the basis for
many of the techniques that will be developed in this book. Conceptually, it builds on
paradigms developed by Chaum [87, 88, 93, 107] in the period 1985–1992. Chaum
advocated the use of credentials, which he deﬁned [93] as “statements concerning
an individual that are issued by organizations, and are in general shown to other
organizations.” Chaum’s credentials are not attribute certiﬁcates, though; they are
digitally signed random messages that do not include a public key. For a discussion
of the drawbacks of Chaum’s approach, see Section 1.2.2.
In 1996, Blaze, Feigenbaum, and Lacy [33] also argued in favor of attribute cer-
tiﬁcates that do not reveal identity. Their focus is not on digital certiﬁcates, though,
but on the design of a trust management system (called PolicyMaker) that enables
7Be warned that several of the fears and doubts that Ellison and Schneier [148] raise are in no way
speciﬁc to PKIs.

12
INTRODUCTION
veriﬁers to make decisions when presented with attributes and a request for access
to a service. (See Blaze, Feigenbaum, Ioannidis, and Keromytis [32] for details of
PolicyMaker and KeyNote, a related trust management system designed speciﬁcally
for making Boolean decisions based on attribute certiﬁcates.) A similar trust man-
agement system is REFEREE [116], which forms the basis of the DSig [115] ini-
tiative of the World Wide Web Consortium; DSig is a proposed standard format for
making digitally-signed, machine-readable assertions about a particular information
resource. All these developments are orthogonal to, and can be used in conjunction
with, the techniques that we will develop in this book.
A standardization effort for attribute certiﬁcates is the Simple Public Key Infras-
tructure [151] (SPKI). SPKI rejects not only the identity focus of the X.509 frame-
work, but also its use of global names and its hierarchic certiﬁcation structure; see
Ellison [147, 149] for details on the SPKI design philosophy. In April 1997, SPKI
merged with the Simple Distributed Security Infrastructure [324] (SDSI). SDSI is a
PKI proposal by Rivest and Lampson; it is based on local names spaces, and centers
around public keys rather than individuals. SPKI/SDSI 2.0 [152] combines the SDSI
local names spaces and the SPKI focus on attribute certiﬁcates.
Tokeneer [319, 320], a PKI proposal by the NSA, heavily relies on attribute cer-
tiﬁcates as well, mainly because in federal agency applications immediate connectiv-
ity to a trusted authentication server is not always possible.
In 1997, VeriSign announced that it would personalize its digital ID’s with a zip
code, age, gender, and personal preferences, to facilitate integration with the Open
Proﬁling Standard [209] (OPS). OPS was announced in November 1997 by Netscape,
Fireﬂy Network, and VeriSign as a framework for the automated transport of personal
data of individuals to Web sites. The idea of OPS is that an individual enters his or
her personal data once, after which it is stored in the form of a Personal Proﬁle in
encrypted form on his or her personal computer. Some or all of the personal data in
a Proﬁle may be digitally certiﬁed. A set of rules is then used to determine how and
when the data can be disclosed to online services. In 1998, the Platform for Privacy
Preferences [393] (P3P) of the World Wide Web Consortium subsumed OPS. P3P
allows Web sites and visitors to automatically negotiate a degree of privacy, based
on the privacy practices of the Web site and privacy preferences speciﬁed by the
individual in his or her browser.
Several PKI proposals use signed attribute objects that are in fact not true attribute
certiﬁcates, because they do not bind attributes to a public key. This approach is
followed in X.509v3 extensions, and has been adopted amongst others by Netscape’s
Transport Layer Security (TLS) 3.1 and X9.57 of the American Bankers Association.
An X.509v3 “attribute certiﬁcate” has the same syntax as an X.509v3 certiﬁcate, but
has a null public key; to prevent replay, it has an embedded link to a standard X.509
identity certiﬁcate, the public key of which is used for authentication. A key holder
may have multiple of these signed attribute objects associated with the same identity
certiﬁcate. Advantages of this approach are that the attributes do not increase the size

1.1 DIGITAL CERTIFICATES AND PKIS
13
of the identity certiﬁcate, and attributes can be refreshed independently of the identity
certiﬁcate. RSA’s PKCS #6 [330] embeds X.509 certiﬁcates into a structure that
adds additional attributes before the whole package is signed, to provide backward
compatibility with X.509 certiﬁcates; the resulting structure is a genuine attribute
certiﬁcate.
Note that the validity period of an attribute certiﬁcate may not exceed that of the
attribute with the shortest validity period. For instance, if an attribute speciﬁes the
age of a person, then any certiﬁcate in which that attribute is speciﬁed should not
have an expiry date that extends beyond the person’s next birthday. In this particular
example, the problem can be removed by encoding the date of birth instead of age,
but this is not always possible. In other words, there is an incentive to use short-lived
certiﬁcates (i.e., certiﬁcates with short validity periods).
1.1.5
Certiﬁcate revocation and validation
Certiﬁcates are valid until they expire, unless they are revoked beforehand. Many
things can happen that require the revocation of a certiﬁcate. For example, the secret
key may be lost or irreversibly destroyed, the certiﬁcate holder may cease operation,
the certiﬁcate holder’s identiﬁer may need to be updated due to a name change, one
of the (other) attributes in the certiﬁcate may have become invalid, or the secret key
may have been compromised. It is not necessarily the certiﬁcate holder who desires
to revoke a certiﬁcate. For example, when a company ﬁres an employee, it is often
necessary to revoke all his or her access privileges. Also, a certiﬁcate holder who
uses a limited-show certiﬁcate (e.g., a discount coupon or a public transit ticket)
more times than allowed must be stopped from continuing the fraud.
While revocation is an exceptional circumstance, the task of veriﬁers to check
the revocation status of unexpired certiﬁcates unfortunately is not. They must ei-
ther have the certiﬁcate status validated online (at the time of the communication
or transaction) or regularly download a digitally signed update of a blacklist called
the Certiﬁcate Revocation List (CRL). In both cases the status of certiﬁcates must be
maintained by the CA (or by a special Revocation Authority). Note that the certiﬁcate
revocation or validation data must itself be authenticated.
X.509v1 and PEM rely on the distribution of full CRLs. X.509v2 introduced the
notion of delta-CRLs, which are in essence CRL updates. In X.509v3, the set of all
issued certiﬁcates is subdivided into fragments that each have their own CRL; each
X.509v3 certiﬁcate has a pointer to the CRL fragment that indicates its revocation
status (“CRL Distribution Points”). See Perlman and Kaufman [300], van Oorschot,
Ford, Hillier, and Otway [292], and Adams and Zuccherato [5] for related proposals.
As an alternative to the CRL approach of X.509v3, the PKIX working group is
standardizing an online validation method, called the Online Certiﬁcate Status Pro-
tocol [270] (OCSP), for time-critical applications. ACES rejects the CRL approach
altogether in favor of an online validation check, to facilitate a “pay as you go” busi-

14
INTRODUCTION
ness model; the idea is that federal agencies pay a certiﬁcate validation fee each time
they rely on certiﬁcates issued by commercial CAs for authentication.
Online certiﬁcate validation avoids the need for veriﬁers to manage their own
versions of a CRL and to deal with certiﬁcates they are not interested in, but suffers
from all the problems of the central database paradigm. One of the primary problems
is scalability to large communities, not in the least because responses to queries must
be authenticated by the trusted central database. In fact, in many PKIs (especially
those with just one CA) it makes little sense to use digital certiﬁcates in combination
with online certiﬁcate validation; organizations or the CA might as well keep copies
of public keys on ﬁle. Improvements of the basic mechanism for online certiﬁcate
validation have been proposed (see Kocher [235], Micali [268], Aiello, Lodha, and
Ostrovsky [7], and Naor and Nissim [273]), but these do not remove the main prob-
lems.
Distribution of CRLs (or their updates), is more attractive in many respects, but
creates a lag between the time a certiﬁcate becomes invalid and when it appears on
the next CRL update. If validity periods are long, CRLs will grow and additional
computing resources are needed for searching and storing them.
Either way, certiﬁcate revocation seriously reduces the ﬁnality of secure com-
munications and transactions. In 1994, the MITRE Corporation [27] estimated that
the yearly running expenses of an authentication infrastructure derive almost entirely
from administrating revocation. Its cost estimates are based on the distribution of
full CRLs, but would be similar for CRL updates, and probably worse for online cer-
tiﬁcate validation. Another serious problem is that revocation requires secure time
stamping, because otherwise one can simply backdate signatures. (Likewise, veriﬁers
need a secure clock to verify the expiry dates or validity windows of certiﬁcates.)
PGP leaves it to key holders themselves to notify their correspondents in case
their keys are to be revoked, and relies on the revocation information to propagate.
This approach works well in small communities, but is not workable in large-scale
PKIs where key holders have transient relations.
In the currently prevailing certiﬁcate paradigm, certiﬁcates are long-lived; va-
lidity periods are typically in the order of many months or even years. The use of
long-lived certiﬁcates is often taken for granted, presumably for historical reasons:
getting multiple copies of a paper-based certiﬁcate whenever desired is not a feasi-
ble option. However, with today’s computers and electronic networks, getting 100
certiﬁcates is hardly less efﬁcient than getting a single one, and one can always re-
connect with the issuer to download a new batch of certiﬁcates. In many cases,
issuing certiﬁcates with short validity periods is sufﬁcient to deal with the revocation
problem, as Kaufman [226] and others observed. Elaborating on this observation,
Stubblebine [365] proposed to include recency information (validity windows) and
freshness policies within certiﬁcates, to reduce the importance of timely revocation
information. (See McDaniel and Jamin [260] for a related proposal.) Rivest [323]
proposed to abolish certiﬁcate revocation altogether, by having the certiﬁcate holder

1.1 DIGITAL CERTIFICATES AND PKIS
15
supply all the evidence needed by the veriﬁer to check the validity of a certiﬁcate;
freshness is achieved by showing a more recently issued certiﬁcate.8 SDSI 2.0 for
this reason uses no revocation mechanism at all. Diversinet, which provides what
it calls digital permits (similar to the X.509v3 construct for “attribute” certiﬁcates),
also follows this approach.9 Clearly, the model of short-lived certiﬁcates ﬁts well
with many types of limited-show certiﬁcates. In Chapters 5 and 6 we will see that the
paradigm of short-lived limited-show certiﬁcates has many other beneﬁts over that of
long-lived unlimited-show certiﬁcates.
Note that revocation is not needed when a secret key has been destroyed or its
holder voluntarily ceases operation, assuming the certiﬁcate served only for authen-
tication purposes and certiﬁcate holders act only on their own behalf.10
1.1.6
Smartcard integration
Everything discussed thus far applies to certiﬁcates implemented in software-only
computing devices. These devices may be obtained on the open market and may be
modiﬁed freely by their holders; they do not contain any tamper-resistant compo-
nents that serve to protect the security interests of their issuer. Examples are desktop
computers, notebooks, palmtop computers, cellular telephones, and smart watches.
Software-only implementations have many advantages: mass-scale software is cheap
(software needs to be written only once), can be manufactured in-house by any soft-
ware producer, and is easy to distribute over the Internet and other networks (no need
for physical transportation); any individual can issue his or her own certiﬁcates (low
start-up cost); and, it is relatively easy to verify claims about the operation of the
software.
Nevertheless, software-only implementations are not preferable in most PKIs. A
distinct problem is theft. If the secret key of a certiﬁcate is generated and stored on
a personal computer or the like, it is virtually impossible to prevent its compromise,
loss, disclosure, modiﬁcation, or unauthorized use. Gutmann [204], for instance,
in 1997 found that “no Microsoft Internet product is capable of protecting a user’s
keys from hostile attack,” due to design and implementation ﬂaws. Shamir and van
Someren [348] note that software run by an attacker (in the form of a virus or a Trojan
horse, or simply from a ﬂoppy during lunch-time) may be able to rapidly detect
cryptographic keys stored on a PC by scanning for data sections with unusually high
entropy. Encrypting the secret key does not overcome the problem: encrypting it
using a password is vulnerable to a brute force attack, and in any case the secret key
must at some stage be in the clear to be usable.
8McDaniel and Rubin [261] argue that this approach is not preferable over CRLs in all circumstances.
9A Diversinet certiﬁcate attests to the binding between a public key and an anonymous identiﬁer that
can be uniquely linked to centrally maintained identity information and other attributes; see Brown [64].
10In contrast, a public key used for encryption should be revoked when the secret key is lost, but there
is no satisfactory way to do this securely. Another secret key must be established to enable authenticated
communication with the CA; this shifts the problem but does not overcome it.

16
INTRODUCTION
Also, in many PKIs participants are not allowed to lend, share, or give away their
certiﬁcates. Software-only devices cannot protect against this. Examples of per-
sonal certiﬁcates are driver’s licenses, diplomas, subscriptions, electronic passports,
and employee badges. To limit transferability, Lessig and Resnick [249] suggest to
include location data (such as an IP address) in certiﬁcates or to make certiﬁcates
traceable (so that abusers can be punished); both methods offer inadequate security,
though, and destroy privacy. For some odd reason, the lending problem is not widely
acknowledged, as witnessed by the limited amount of work done to protect against
it.
A convenient way to protect against these and other risks is to store secret keys
on a smartcard. This is a chipcard that contains a microprocessor that is capable of
making arithmetic decisions.11 Smartcards can process data in intelligent manners,
by taking actions based on secret data that never needs to leave the card. Memory
access and input/output are guarded against unauthorized access, and the card can
disable itself after a false PIN has been entered several times. (Alternatively, the
card can store an electronic representation of its holder’s ﬁngerprint, and match this
against a ﬁngerprint entered on a trusted card reader or directly on the card.) Tam-
pering with a smartcard in order to get to its contents can set off an alarm in the card
that blocks it or overwrites the memory contents with all zeros (a process known as
zeroization).
Implementations based on tamper-resistant smartcards offer a multitude of ben-
eﬁts, many of which have systematically been overlooked by PKI researchers and
developers:
• It is easy to protect smartcards against viruses and Trojan horses aimed at cap-
turing their secret keys.
• If the smartcard has an access control mechanism (PIN, password, or other-
wise), certiﬁcates cannot be shown by smartcard thieves and other parties not
authorized by the card’s legitimate holder.
• If the smartcard has an access control mechanism that scans a biometric of the
card holder (e.g., his or her ﬁngerprint), certiﬁcate holders can be prevented
from lending their personal certiﬁcates.
• The tamper-resistance can prevent certiﬁcate holders from making copies of
limited-show certiﬁcates. In software-only implementations, the only way to
protect against fraud with limited-show certiﬁcates is to require online clearing
with a central party for all transactions.
11The term smartcard is used differently by different organizations. The deﬁnition of smartcards used by
ISO 7816-1 of the International Organization for Standardization, and applied by the Smart Card Forum,
includes memory cards. It stands to reason that organizations aiming to promote and commercialize a new
technology prefer to use a single term as broadly as possible. However, a memory card can hardly be said
to be “smart,” even if it has hardwired logic.

1.1 DIGITAL CERTIFICATES AND PKIS
17
• If the smartcard has a tamper-resistant internal clock, the burden of checking
the expiry date of a certiﬁcate can be moved from the certiﬁcate veriﬁer to
the smartcard, with the latter refusing to (help) show a certiﬁcate if the date
is outside of its validity period. This avoids the need for certiﬁcate veriﬁers
to run a secure clock that cannot be reset by an attacker to a time within the
validity period.
• If the smartcard has a tamper-resistant internal clock, it can add a timestamp
to any digital signatures made when showing certiﬁcates.
• If the smartcard has a tamper-resistant internal clock, it can limit the number
of certiﬁcate showings within a given time period; this may be desirable for
certain types of certiﬁcates or CA liability arrangements.
• Certiﬁcates that specify negative qualiﬁcations can be discarded only by muz-
zling the smartcard. The smartcard can then enter into suspension mode, so
that its holder can no longer show any certiﬁcates.
• More generally, the smartcard can locally decide whether its holder may en-
gage in certain transactions, and can prevent undesired behavior.
• Certiﬁcate holders cannot fall victim to extortioners in cyberspace who (pos-
sibly anonymously) extort them into transmitting their certiﬁed key pairs to
them; an extortioner cannot reasonably expect his or her victim to be able to
break the tamper-resistance of the smartcard.
• The smartcard can prevent its holder from helping remote parties (over a radio
link or the like) to gain access to services for which they do not have the proper
certiﬁcates themselves. (Details will be provided in Section 6.5.3.)
• The smartcard can do internal book-keeping in the interest of its issuer, such
as keep track of an electronic cash balance. It could even keep a log of all
transactions, which could be inspected by law enforcement agents that have a
court order. Of course, any reliance on smartcard book-keeping is acceptable
only when the damage that can result from tampering with a card’s contents is
outweighed by the cost of breaking the card’s tamper-resistance.
• The vulnerability of secret keys stored in software-only devices makes it dif-
ﬁcult to reliably associate a digital signature with a particular individual. This
makes the legal status of digital signatures doubtful, which in turn hampers
the progress of electronic commerce. Tamper-resistant devices for certiﬁcate
holders help give digital signatures a ﬁrm legal grounding.
• The need to rely on revocation mechanisms greatly reduces. The latency and
scalability problems of software-only CRL distribution are largely overcome:

18
INTRODUCTION
the risk of theft is minimized (assuming the presence of an access control
mechanism), it takes signiﬁcant time to physically extract keys from stolen
smartcards, and a card holder’s capabilities can be revoked by taking back the
smartcard. Consequently, there should rarely be a need for online certiﬁcate
validation and the expected size of CRLs (assuming certiﬁcates are used only
for authentication) is zero. In many closed smartcard-based PKIs, the validity
of certiﬁcates can even be made the liability of the CA.
• Smartcards offer portability.
• Smartcards have a clear psychological advantage over software-only imple-
mentations.
In sum, there are many reasons to prefer smartcard-based implementations over
software-only implementations. Of course, any other tamper-resistant hardware de-
vices may be used instead. Although smartcards are a natural choice in many situ-
ations, other embodiments may be more appropriate for securely implementing an
internal battery, a clock, a live access control mechanism, or other desirable fea-
tures. One interesting alternative is the iButton12 produced by Dallas Semiconductor.
For concreteness, however, throughout this book we will always refer to smartcards
whenever there is a need for tamper-resistant devices for certiﬁcate holders.
One of the most successful smartcard-based PKI implementations is Fortezza.
Other smartcard-based PKIs relying on identity certiﬁcates are Chip-Secure Elec-
tronic Transactions [20] (C-SET) and version 2.0 of SET. Pretty Good Privacy and
Schlumberger Electronic Transactions in April 1997 announced a strategic alliance
for the development and marketing of PGP-enhanced smartcards. VeriSign in Novem-
ber 1999 announced to bundle its Class 1 Digital IDs with Litronic’s NetSign, a
technology that integrates Netscape Communicator with smartcards for increased
portability. Identrus and GTE CyberTrust have announced similar plans. In June
1999, Gemplus Software (a division Gemplus) announced GemSAFE Enterprise, a
smartcard solution intended to integrate seamlessly with X.509 and other popular
certiﬁcate standards and products. In the same month, eFed, Entrust Technologies,
and NDS Americas demonstrated a smartcard-based PKI procurement solution for
the federal marketplace, based on X.509 certiﬁcates. More recently, in November
1999, the U.S. Department of Defense announced that it will use smartcards in its
PKI plans, in order to securely identify military, civilian and contractor employees
when they gain access to its buildings, computers, Internet and private networks, and
so on; by the end of 2000 a roll-out of some 4 million smardcards will begin.
12The iButton is a 16mm computer chip housed in a stainless steel can, which can be afﬁxed to a
ring, key fob, wallet, watch, or badge. The cryptographic iButton version contains a microprocessor and
high-speed 1024-bit coprocessor for public-key cryptographic operations, runs a Java virtual machine,
has 6 kilobytes of SRAM that will zeroize its contents in case of an attempted physical compromise, and
transfers data at up to 142 kilobits per second.

1.1 DIGITAL CERTIFICATES AND PKIS
19
ACES also foresees an important role for identity certiﬁcates stored on smart-
cards. According to the U.S. Federal Card Services Task Force [161], the goal of the
U.S. government is “to adopt an interoperable multi-application smart card that will
support a wide range of governmentwide and agency-speciﬁc services. This goal sets
the target for every federal employee to carry a smart card that can be used for mul-
tiple purposes – travel, small purchases, identiﬁcation, network and building access,
and other ﬁnancial and administrative purposes– by the year 2001. [...] This plan
calls for a smart card based extended ID authentication function to support multi-
ple applications based on public key technology using the standard X.509v.3 digital
certiﬁcate and authentication framework as an operating model.”
One of the few smartcard-based PKI proposals speciﬁcally designed for attribute
certiﬁcates is NSA’s Tokeneer [320]. As its authors [319] note, there is an urgent
need to minimize the amount of data transferred both to and from the smartcard:
“In the case where the certiﬁcate is stored in a token (such as a smart-
card), storage area may be a critical factor. Each certiﬁcate requires at
least one signature. The size of the signature depends on the exact signa-
ture algorithm being used (128 bytes in the case of a 1024 bit RSA sig-
nature). Adding other data ﬁelds and ASN.1 encoding overhead, each
certiﬁcate can be on the order of several hundred bytes. [...] In sys-
tems where I/O throughput is a factor (especially in smartcard based
systems where I/O may be limited to 9600 baud/second) the data size of
the certiﬁcate may be a concern. Separating the certiﬁcate into several
certiﬁcates will be beneﬁcial only if transfer is limited to one certiﬁcate
per service request. Separating attributes into several different certiﬁ-
cates may also be detrimental to overall system performance if multiple
certiﬁcates are required.”
The computation, communication, and storage burden is frequently cited as one
of the main reasons why smartcard implementations of certiﬁcate mechanisms are
stalling. Indeed, current proposals all require sophisticated smartcards with large
EEPROM13 and cryptographic coprocessors. Efﬁciency considerations are of prime
importance in smartcard implementations, especially for short-lived and limited-
show certiﬁcates. The addition of complex circuitry and software is expensive and
can easily lead to new weaknesses in the internal defense mechanisms. Also, with
smartcard components already cramming for space, adding circuitry adversely af-
fects reliability. A “dead” card inconveniences and frustrates its holder, and can have
dramatic consequences in medical and other applications.
The techniques that we will develop in this book overcome all these problems.
13EEPROM, or Electrically Erasable Programmable Read Only Memory, is non-volatile memory that
enables data to be erased by discharging gates electrically.

20
INTRODUCTION
1.2
Privacy issues
The efﬁciency and security problems of certiﬁcate revocation and smartcards are
not the only shortcomings of the current proposals for PKIs and certiﬁcation mecha-
nisms. In this section we examine the privacy dangers, and discuss the meager efforts
that have been undertaken to protect privacy. On the basis of this analysis we then
list desirable privacy properties for digital certiﬁcates and PKIs.
1.2.1
Privacy dangers
As deﬁned by Westin [387], (information) privacy is the claim of individuals, groups,
or institutions to determine for themselves when, how, and to what extent information
about them is communicated to others.14 It is a fundamental postulate of this book
that if the current visions about the global PKI (i.e., the collection of all regional,
national, and international PKIs) turn into reality, then everyone will be forced to
transact and communicate in what will be the most pervasive electronic surveillance
tool ever built. (Surveillance is the act of systematically monitoring, tracking, or
assessing the actions of individuals.)
To apprehend the magnitude of the privacy problem, consider the following as-
pects:
• All the communications and transactions of an individual in a PKI can be
linked on the basis of his or her identity certiﬁcates. In this manner, dossiers
can automatically be compiled for each individual about his or her habits, be-
havior, movements, preferences, characteristics, and so on. Many parties enjoy
this dossier forming capability:
– The CA sees the certiﬁcates it issues, and typically sees them again once
they are shown or at a later moment. This enables the CA to trace and link
all communications and transactions of each key holder. Reasons why
the CA may get to see the certiﬁcates that are shown to veriﬁers include:
the veriﬁers in the PKI may belong to the same entity as the CA (closed
system); veriﬁers may be incited to deposit a copy of the transcript of
each transaction they engage in (e.g., to enable detection of certiﬁcate
forgery or fraud with limited-show certiﬁcates, or to support commercial
goals); and, veriﬁers may resort by default to online certiﬁcate validation
with the CA.15
14Westin’s deﬁnition is frequently cited in the academic literature and in court decisions, and forms the
basis for the U.S. Privacy Act of 1974 (for an overview, see, e.g., the Ofﬁce of Technology [285, Chapter
1]) and similar legislation in many other developed countries around the world (see the Global Internet
Liberty Campaign [153] and Rotenberg [329]).
15Today’s PKIs seldomly require certiﬁcate veriﬁers to deposit their transcripts to the CA, but this can
be expected to change as the awareness of the security beneﬁts grows.

1.2 PRIVACY ISSUES
21
– Each veriﬁer can store all the certiﬁcates that are presented to it, and can
link them on the basis of their key holder identiﬁers, public keys, or CA
signatures. Different veriﬁers can exchange and link their data on the
same basis. Developments are underway to streamline the latter process.
For instance, the Information Content & Exchange protocol (ICE), an-
nounced by the ICE working group in June 1998, provides organizations
with a standardized automated method for exchanging personal data ob-
tained through P3P and other mechanisms. Another planned standard,
the Customer Proﬁle Exchange (CPEX), announced in November 1999,
is intended to take automated exchange and integration of personal data
to an even further level. The eXtensible Markup Language (XML), de-
signed by the World Wide Web Consortium, will play an important role
in these initiatives.
– In case the communications or transactions of key holders are not se-
curely encrypted, wiretappers see the same information as veriﬁers. If
they can wiretap the certiﬁcate issuing process as well, they can learn ev-
erything the CA knows. One particularly nasty aspect is that the certiﬁed
public key of at least one of the two parties in a transaction or communi-
cation is always sent in the clear to bootstrap a secure session.
Parties that actively monitor the Internet and other telecommunication
infrastructures, or at least have the capability to do so, include govern-
ment agencies (international wiretapping efforts include Echelon16 and
Enfopol17), non-proﬁt organizations (such as the Internet Archive, which
stores over 14 terrabytes of information gathered from news groups, Web
pages, and other publicly accessible Internet sites), and commercial en-
terprises (e.g., Internet routers, Internet service providers, and the com-
mercial offshoot of the Internet Archive). The U.S. Communications As-
sistance for Law Enforcement Act [145, 159, 160, 286] and similar leg-
islation [359] in other countries require the telecommunications industry
to build wiretapping capabilities into their infrastructures.
• The CA can trivially link each dossier to the identity of each individual. For
veriﬁers and wiretappers, linking dossiers to identities typically is straightfor-
ward as well: either separate entries or the aggregated contents of a dossier
reveal the identity, or the match can be made in another way (e.g., on the basis
16Echelon is an international surveillance system that taps into most of the world’s non-military satellite,
radio, and land-based communications systems. It is operated by the United States in cooperation with
Great Britain, Canada, New Zealand, and Australia. Echelon systematically scans e-mail, fax, cellular,
telex, and telephone communications for keywords, to identify and extract messages deemed of interest.
See [75, 206, 207, 308] for details.
17The Council of the European Union and the FBI have been cooperating since 1992 on a plan for
intercepting all mobile phone calls, Internet communications, and fax and pager messages in Europe.
See [129, 262, 344, 362] for details.

22
INTRODUCTION
of voice or facial recognition or by tracing the source of an Internet connec-
tion). Sending your digital certiﬁcate offers no more privacy than sending your
Social Security number or credit card number.
Worse, all the dossiers that are compiled by linking and tracing the actions
of participants in one PKI can be tied to the dossiers compiled in other PKIs.
In the original X.509 proposal, each key holder would be assigned a globally
unique identiﬁer, providing a highly convenient method to link the actions of
key holders across different PKIs. The SPKI authors [151] rightfully note
that this “would constitute a massive privacy violation and would probably
be rejected as politically impossible.” The use of local names, as in SDSI,
makes it more difﬁcult to link transactions across different PKIs, but clearly
with today’s network resources and linking power the barrier that is raised is
low; after all, local names and other kinds of identiﬁers are strongly correlated
to true names. In any case, different local names of the same individual can all
be linked when CAs cooperate.
• Attribute certiﬁcates worsen the problem, since the dossiers that CAs, veriﬁers,
and wiretappers can compile are often even more intrusive. Attribute certiﬁ-
cates that do not specify explicit identiﬁers can be linked and traced as easily as
identity certiﬁcates, on the basis of their public key or the signature of the CA.
(The same holds for X.509v3 “attribute” certiﬁcates and Diversinet’s digital
permits, in spite of the latter’s claim18 that its digital certiﬁcates assure “total
anonymity and privacy by separating authorization credentials into permits;”
protection against unsophisticated wiretappers is a far cry from privacy, and
can simply be achieved by line encryption.) Also, each CA gets to learn all the
attributes of each certiﬁcate applicant, because otherwise it cannot or will not
issue a certiﬁcate. Some CA service providers, such as Thawte Certiﬁcation,
are promoting PKI models whereby a single CA validates all the attributes of a
certiﬁcate applicant, to avoid cumbersome veriﬁcation procedures; this further
increases the power of the CA.
Ellison [150] states: “Because SPKI certiﬁcates will carry information that,
taken together over all certiﬁcates, might constitute a dossier and therefore a
privacy violation, each SPKI certiﬁcate should carry the minimum information
necessary to get a job done.” Indeed, SPKI certiﬁcates are not programmable;
they have 5 exactly ﬁelds (Issuer, Subject, Delegation, Authorization, Validity
Dates). A noble sacriﬁce, but one that one would prefer to avoid; in many
PKIs, everyone beneﬁts when more attributes can be encoded.
• Any digital signatures that are made by certiﬁcate holders can be added to
their dossiers. They form self-signed statements that cannot be repudiated,
18At www.dvnet.com/about us/what we do.htm, last checked March 30, 2000.

1.2 PRIVACY ISSUES
23
proving to the whole world who is the originator of a message. As Directorate-
General XIII of the European Commission [137] notes, “Digital signatures
could even bring signiﬁcant law enforcement beneﬁts as they allow for exam-
ple messages to be attributed to a particular reader and/or sender.” In the words
of Walsh [386], a former deputy director-general of the Australian equivalent
of the NSA, “If you ever allow people to get near authentication keys you’ll
corrupt the administration of justice.”
In a similar manner, anyone who gets to see a digital certiﬁcate, either by
wiretapping a communication or by consulting online certiﬁcate repositories
or CRLs, has convincing evidence that the identity and any other attributes
signed by the CA belong together. Obtaining this information is often per-
fectly legitimate even for outsiders; many schemes (e.g., X.509 and PGP) store
certiﬁcates in mail servers or other public depositories. The American Bar As-
sociation [9] states: “Publication of a certiﬁcate which has not been accepted
by the subscriber may disclose an identiﬁcation, business relationship, or other
fact which the purported subscriber wishes to keep conﬁdential, and may have
a right to keep conﬁdential under applicable privacy law.” Clearly, accepting
subscribers have similar concerns.
• Any uniquely identifying data in a certiﬁcate (such as a key holder identiﬁer,
the public key, or the CA’s signature) can be misused to deny a key holder
access to PKI services, and to block his or her communication attempts in
real time. For example, blacklists can be built into Internet routers. Similarly,
transaction-generated data conducted with target public keys can be ﬁltered out
by surveillance tools, and electronically delivered to third parties for examina-
tion or immediate action. More generally, entire groups can be discriminated
against on the basis of attributes encoded into their certiﬁcates.
• Revocation mechanisms cause additional privacy problems. CRLs (or their
updates) are distributed to all veriﬁers, and potentially to anyone who requests
them. In this manner, entities can collect data about key holders they have
never communicated or transacted with. Furthermore, the CA can falsely add
public keys to its CRL, to block the communications and transactions of tar-
geted certiﬁcate holders. (The methods of Kocher [235], Micali [268], Aiello,
Lodha, and Ostrovsky [7], and Naor and Nissim [273] do not protect against
false claims of the CA that a certiﬁcate has been revoked; they protect merely
against a misbehaving Revocation Authority that gets authenticated revocation
information from an honest CA.19)
19An improvement would be for blacklists to list the (serial numbers of) certiﬁed public keys together
with a “suicide note,” a revocation message signed using the secret key. This approach, which is applied
in PGP, cannot be used when the secret key is lost, while preparing a suicide note in advance is not an
adequate solution.

24
INTRODUCTION
Online certiﬁcate validation services are even worse: they allow anyone to
verify not only negative data but also positive data, and enable the Revocation
Authority to falsely deny access to certiﬁcate holders and to learn in real time
who communicates with whom. This cripples the privacy of certiﬁcate veriﬁers
as well.
• The integration of smartcards exacerbates the privacy problem. Moreno, the
inventor of the ﬁrst generation of smartcards in the early seventies, warned
that smartcards have the potential to become “Big Brother’s little helper.” The
tamper-resistance of a smartcard shields its internal operations from its holder.
It is difﬁcult or even impossible to verify that a card does not leak personal data
and other attributes that may be stored inside the card. Leakage may take place
by exploiting the van Eck effect,20 by sending out or receiving radio signals,
by sending along additional data when engaging in a protocol, by encoding
information in message ﬁelds or random numbers speciﬁed in the protocol, by
timing the delay before transmitting a message, or by halting at a speciﬁc step
of a protocol. Also, the smartcard issuer (typically the CA from which the
holder obtains certiﬁcates) can program the card in such a manner that it will
lock its holder out of services upon receiving a signal from (the terminal of) a
certiﬁcate veriﬁer or another party. See Section 6.1.1 for details.
As more and more personal data is stored inside smartcards, individuals will
be mislead into believing that they have control over their own data. Con-
sumer protection agencies such as the Privacy Commissioner of Canada [287]
and the Privacy Commissioner of the Commonwealth of Australia [311] have
already expressed great concern. See also Cavoukian, Johnston, and Dun-
can [79], Clarke [117], Connolly [120], Fancher [158], Schwartz [343], and
Wright [394].
Since the surveillance of automated transaction systems is more surreptitious than
wiretapping, it has even greater potential to law enforcement and intelligence agen-
cies. Transaction-generated data trails can readily be picked up by computers, stored
in databases, searched for patterns of activity, processed to distill proﬁles, and merged
and matched with census data, credit report data, postal codes, car registrations, birth
certiﬁcates, and so on. Moreover, transactions need not be monitored in real time;
once stored, data trails are permanent for the record and can be examined at any
time. Indeed, as NIST’s FPKI chairman Burr [68] notes: “Archives provide a long
term storage of CA ﬁles and records. The life time of CAs may be relatively short.
But it may be important to verify the validity of signatures on very old documents.
CAs must make provisions to store the information needed to verify the signatures of
20Microprocessors, keyboards, computer monitors, serial cables, printers, and other peripheral devices
all emit electromagnetic radiation that passes over large distances and through solid walls, and that can be
remotely captured and viewed; see van Eck [379] for the (purposely incomplete) paper that brought this
phenomenon to the attention of the public.

1.2 PRIVACY ISSUES
25
its users, in archives that will be able to make the data available at a much later date,
perhaps several decades later.”
Hardly surprising, individuals are feeling increasingly threatened. A survey con-
ducted in April 1998 by Louis Harris & Associates and Westin for Privacy & Ameri-
can Business and Price Waterhouse found that 87% of American computer users are
concerned about threats to their personal privacy. The threats do not merely pertain
to abuse by the private sector. Indeed, as Singleton [356] points out, “Although both
private and government databases can be abused, the abuse of government databases
poses a more serious threat for one reason: government controls the courts, the po-
lice, and the army.” Commercial organizations have a commercial self-interest in
protecting the privacy of individuals, and often are less interested in the behavior of
identiﬁed persons than government agencies. Moreover, the surveillance technolo-
gies used by governments are typically more advanced and covert than those used
by the private sector. In an inﬂuential study conducted in 1996, the U.S. National
Research Council [278] “acknowledges the concerns of many law-abiding individu-
als about government surveillance. It believes that such concerns and the questions
they raise about individual rights and government responsibilities must be taken se-
riously. It would be inappropriate to dismiss such individuals as paranoid or overly
suspicious.”
ACES and other government PKIs without privacy-protection measures intrude
even more on privacy than the national ID cards that many developed countries are
considering in order to combat tax evasion, social security fraud, illegal immigra-
tion, insurance fraud, fraudulent work authorization documents, and so on. These
plans have already lead to public outcry in the United States, Great Britain, Canada,
New Zealand, Australia, and other countries. See Privacy International [312] for an
overview of (proposed) national ID cards around the world.
1.2.2
Previous privacy-protection efforts and their shortcomings
Surprisingly, the issue of privacy in PKIs has received virtually no attention. Most
certiﬁcation technologies and standardization efforts do not deal with the issue at all,
or only allow users to encrypt their communications and transactions at the transport
layer. Conﬁdentiality is a weak privacy measure, though. As Baker [18], then chief
council for the NSA, remarked: “The biggest threats to our privacy in a digital world
come not from what we keep secret but from what we reveal willingly. [...] Re-
stricting these invasions of privacy is a challenge, but it isn’t a job for encryption.
Encryption can’t protect you from the misuse of data you surrendered willingly.”
The European Commission [137] recommends that individuals be allowed to ob-
tain digital certiﬁcates that specify a pseudonym, unless the law speciﬁes that true
names must be used. This approach is supported by the OECD Cryptographic Policy
Guidelines [295] and by the European Privacy Directive [157].21 Pseudonymous cer-
21The European Privacy Directive is an extensive set of privacy guidelines established in 1995 by the

26
INTRODUCTION
tiﬁcates are recommended also by, amongst others, Birch [31], Gladman, Ellison, and
Bohm [187], Hill and Hosein [211], and Standards Australia [361]. PKI efforts that
provide for pseudonymous certiﬁcates include X.509v3 (certain agents may protect
their identity through the use of role-titles; “residential persons” do not enjoy this ca-
pability, though), PEM (pseudonymous certiﬁcates can be retrieved through so-called
Persona CAs), SDSI (its free-form identity certiﬁcate syntax allows the speciﬁcation
of pseudonyms), VeriSign’s Digital IDs (VeriSign issues identity certiﬁcates with
anonymous identiﬁers), and PGP (users can specify false email addresses). Clearly,
pseudonymous certiﬁcates that can only be obtained by certiﬁcate applicants who
identify themselves to the CA offer no better privacy than Social Security numbers
and credit card numbers; at least their issuer can readily follow them around and
trace them to the identity of their holder. The alternative of anonymous registration
of certiﬁcate applicants offers better privacy, but unfortunately suffers from serious
drawbacks:
• It may be very difﬁcult to register without being identiﬁed by cameras or per-
sonnel, or via one’s IP address. Typically it is easier to realize an anonymous
channel when showing a certiﬁcate than when retrieving the certiﬁcate, espe-
cially in the physical world. Identiﬁcation in any one interaction with the CA
results in one’s communications and actions becoming traceable.
• Anonymous registration does nothing to prevent linkability of all the commu-
nications and transactions of certiﬁcate holders. To overcome this problem,
each certiﬁcate must be retrieved anonymously on a separate occasion, with a
signiﬁcant random delay between each retrieval to prevent linkability by the
CA. Not only is this impractical, it also prevents certiﬁcate applicants from
building a reputation with the CA. In particular, the CA cannot distinguish
frequent from infrequent certiﬁcate applicants and cannot lock out fraudulent
users.
• Many types of certiﬁcates, in particular personal certiﬁcates, are issued only
to identiﬁed applicants. Even if the CA certiﬁes only personal attributes that
do not identify the certiﬁcate holder, such as age and marital status, often the
only way for the CA to verify the attributes is by establishing the applicant’s
identity and using this to look up the attributes in a trusted database.
• Non-repudiation and recovery of lost or stolen certiﬁcates are hard to imple-
ment.
• It is hard or even impossible to protect against basic forms of fraud, including
unauthorized lending, copying, and discarding of certiﬁcates. Many applica-
European Union, requiring the 15 member states to harmonize their national laws to protect personal
information. It has taken effect in October 1998, and applies to commercial as well as governmental
information processing. Numerous non-EU countries have adopted privacy policies that are in alignment
with the European approach; see Davies [130].

1.2 PRIVACY ISSUES
27
tions require mechanisms through which misbehaving key holders can be iden-
tiﬁed, so that they can be locked out from further participation and possibly be
sued for damages. Traceability also serves to discourage those contemplating
fraud. Anonymously issued certiﬁcates do not offer these security measures,
in fact the CA cannot even contain the damages due to fraud.
• It is impossible to purchase certiﬁcates from the CA while remaining anony-
mous, unless one can pay using hard cash or a privacy-protecting electronic
cash system.
These drawbacks make anonymous registration of certiﬁcate applicants a highly un-
desirable course of action in the vast majority of PKIs (unless one resorts to the
cryptographic techniques that will be developed Section 5.5.1).
OPS and P3P are erroneously hailed as technical solutions to the privacy prob-
lem. They make it much easier to obtain personal data from individuals, and can be
abused by service providers to turn away or discriminate against persons who do not
want to disclose their identity and other personal data; in this manner they compel
people to give up their privacy. The Data Protection Working Party of the European
Union [214] criticized P3P on the grounds that it seeks to “formalise lower common
standards,” and that it “could mislead EU-based operators into believing that they
can be discharged of certain of their legal obligations (e.g. granting individual users
a right of access to their data) if the individual user consents to this as part of the
on-line negotiation.”
VeriSign issues certiﬁcates that contain encrypted attributes that can be unlocked
only by veriﬁers that meet the qualiﬁcations necessary to receive the required de-
cryption key from a trusted third party. This encryption measure does not reduce the
surveillance capabilities of the most powerful parties in any way, nor does it prevent
anyone from linking and tracing all the actions of each certiﬁcate holder.
Another attempt to protect privacy is for the CA to digitally sign (salted) one-
way hashes of attributes, instead of (the concatenation of) the attributes themselves.
When transacting or communicating with a veriﬁer, the certiﬁcate holder can selec-
tively disclose only those attributes needed.22 This generalizes the dual signature
technique applied in SET [257].
Although certiﬁcate holders now have some con-
trol over which attributes they reveal to veriﬁers, they are forced to leave behind
digital signatures. Furthermore, they are seriously restricted in the properties they
can demonstrate about their attributes; Boolean formulae, for instance, are out of the
question. Worse, nothing prevents the CA and others from tracing and linking all the
communications and transactions of each certiﬁcate holder.
Ellison [150] states: “Because one use of SPKI certiﬁcates is in secret balloting
and similar applications, an SPKI certiﬁcate must be able to assign an attribute to a
blinded signature key.” Blind signatures are a concept introduced by Chaum for the
22Lamport [244] proposed this hashing construct in the context of one-time signatures. When there are
many attributes, they can be organized in a hash tree to improve efﬁciency, following Merkle [267].

28
INTRODUCTION
purpose of anonymous electronic cash [91, 92, 96] and credential mechanisms [87,
93, 107].23 While they can be used to overcome several of the drawbacks associated
with anonymous registration of certiﬁcate applicants, they are not suitable to design
attribute certiﬁcates:
• Because users can fully blind all the certiﬁcate data they obtain from the CA,
it is not possible for the CA to encode person identiﬁers that must be disclosed
in certain circumstances but may remain hidden in others.
• For the same reason, the CA cannot encode expiry dates into certiﬁcates. At
best it can use a different signing key for different certiﬁcate issuances, and
declare in advance when each issuance will become invalid.
• More generally, the blinding prevents the CA from encoding attributes into
a certiﬁcate. It is possible to represent each combination of attribute values
by a different signing key of the CA, but this seriously limits the number of
attributes that can be encoded and their value ranges, and moreover an exhaus-
tive list of the meanings associated with all possible signature types must be
published in advance.24
• Certiﬁcate holders cannot selectively disclose their attributes, since veriﬁers
need to know which public key of the CA to apply to verify a certiﬁcate. A
blind signature guarantees absolute anonymity and untraceability; it does not
enable one to negotiate a degree of privacy.
• Chaum’s credentials must all be created by the same party; different organiza-
tions who wish to issue credentials must all rely on this central party to do the
factual issuance.
• Chaum’s cash and credential mechanisms rely heavily on a real-time connec-
tion with a central party during each transaction. The requirement of online
clearing and central database look-up during each transaction strikes against
the philosophy behind digital certiﬁcates.
23A blind signature scheme enables a receiver to obtain a signed message from a signature issuer in
such a manner that the signed message is statistically independent from the issuer’s view in the protocol
execution.
24In Chaum’s proposal for RSA signatures, the signer uses the same RSA modulus but a different
public exponent vi (speciﬁcally, the i-th odd prime in sequence) to issue blind signatures that represent
the i-th message in a public list. A variation would be for the CA to declare merely that the signing of
a particular message requires as the public signature exponent the nearest prime exceeding the message
(when viewing its binary representation as an integer), but this is impractical as well: a coding scheme
must be applied to ensure that messages have sufﬁciently large Hamming distance, and generating and
verifying a (new) signature type in addition to the normal workload requires (possibly a great many)
applications of a primality test.

1.2 PRIVACY ISSUES
29
• Chaum’s credentials do not have a built-in secret key to authenticate actions
performed with them, and so the problem of replay arises. To prevent re-
play, the credential holder must authenticate the showing of a credential to
an organization by applying the secret key of a digital pseudonym established
(previously or at the same time) with that organization.
• Certiﬁcates that contain unfavorable attributes (i.e., attributes that the holder
would prefer to hide, such as a mark for drunk driving) can simply be discarded
by their holder. In many cases it is impractical to require all certiﬁcate holders
to obtain and show attributes that indicate the absence of unfavorable attributes.
• Blind signatures cannot prevent or discourage the unauthorized lending of cer-
tiﬁcates. This drawback by itself renders the blinding technique useless for the
majority of certiﬁcate applications.
• An extortioner can digitally extort certiﬁcates by forcing the victim to retrieve
certiﬁcates for which the extortioner instead of the victim supplies the blinded
messages. The victim merely signs the certiﬁcate request and passes the re-
sponses of the issuer on to the extortioner. The extortioner can subsequently
at his or her leisure show the certiﬁcate. At no stage is there a need for phys-
ical proximity or a physical communication or delivery channel,25 and so the
extortioner can remain untraceable throughout.
• Chaum’s smartcard techniques require smartcards with cryptographic copro-
cessors and plenty of memory, to guarantee that the required operations can be
performed in reasonable time.
• More seriously, Chaum’s smartcard techniques are not secure. Since attributes
are encoded by the smartcard rather than by the CA, physical compromise of a
smartcard enables its holder to forge attributes, and to lend, give away, or dis-
tribute copies of new certiﬁcates. The CA cannot trace fraud, and containment
can only be accomplished by suspending the entire system. See Section 6.2.2
for details.
• Chaum’s technique [90, 98] for one-show certiﬁcates makes high computation
and communication demands on both the issuer and the receiver. Furthermore,
it does not extend to limited-show certiﬁcates, does not admit zero-knowledge
proofs, and cannot be migrated to a setting with smartcards without further
25The extortioner can transmit from behind a computer that is part of a network located behind a ﬁrewall,
use some a computer at an Internet cafe or a public library, deploy anonymous remailers, pseudonymous
remailers, or Mixmaster remailers (see Goldberg, Wagner, and Brewer [190] for an overview), or use
anonymity or pseudonymous services like Janus [35], Babel [203], Crowds [322], Freedom [189], and
Onion Routing [368]. Also, most Internet access providers dynamically assign IP addresses to each client
session; these identify only the host name of the computer used by the access provider to establish the
session.

30
INTRODUCTION
degrading efﬁciency. Also, it does not give certiﬁcate holders the ability to
selectively disclose information about attributes.
In spite of their unsuitability for digital certiﬁcates and PKIs, Chaum’s paradigms and
methodologies provide valuable insight in how the privacy problems of PKIs may be
overcome.
The certiﬁcation mechanisms that will be presented in this book overcome all the
problems mentioned in this section.
1.2.3
Desirable privacy properties
In many situations there is no need to disclose one’s identity. For example, when a
police agent stops an individual for speeding, all that the ofﬁcer normally needs to
know is whether the individual has a valid driver’s license. When requesting entry
to a gaming parlor it sufﬁces to demonstrate one’s age or year of birth. Likewise,
a county database service may merely need to know that someone requesting a ﬁle
is a resident. More generally, in many PKIs the use of identity is no more than a
way of adding a level of indirection to the veriﬁer’s authentication algorithm; recall
Section 1.1.3.
Even in PKIs where one would expect only identiﬁed actions, there may be a
need for the ability to hide identity; the MITRE Corporation [27, page D-14], for
instance, points out an application where an undercover FBI agent must ﬁle a report
from a remote computer.
In today’s computerized world we cannot expect others to protect our privacy. In
order to protect privacy, we must operate under the following assumptions:
• (Persistence) Whenever data about certiﬁcate holders can be collected, it will
be collected and stored indeﬁnitely (if only because not collecting data that can
so easily be collected must be considered a waste of resources). Every piece of
information that is electronically submitted is there for the public record, even
though the sender rarely intends the data to endure forever.
• (Loss of Control) Once made available, disclosed data will inevitably be used
for purposes (not necessarily known at the time of the collection) beyond the
purpose for which it was disclosed. Underlying this assumption is the premise
that the mere existence of something is sufﬁcient to tempt people to use it
in whatever way they see ﬁt to suit their needs and desires. The public and
private sector will inevitably ﬁnd new uses to improve the efﬁciency, security,
or reach of their operations; foregoing opportunities can easily result in a loss
of competitive edge. Law enforcement agencies will inevitably seek access to
the data in the belief that it will help their investigative practices.
• (Linkability) Data disclosed in one transaction will inevitably be linked to data
disclosed in other transactions (if not for reasons related to security then for

1.2 PRIVACY ISSUES
31
marketing, inventory management, or efﬁciency purposes), unless the cost of
linking outweighs the beneﬁts. With the trend or at least the capability of
organizations to merge their databases at ever decreasing cost, it is naive to
believe that linkable data that is submitted to different locations will remain
unlinked.
To empower individuals to control their own data, PKIs must meet a number of basic
privacy goals:
• Without the ability to remain anonymous, individuals have no control over
their own privacy. Anonymity serves as the base case for privacy. In many sit-
uations, anonymity does more than serve privacy. If there is one thing that can
be learned from the dramatic rise in identity fraud, it is that the use of person
identiﬁers more often enables than prevents fraud. Disciplines such as treat-
ments for medical conditions have long acknowledged that misuse can only
be prevented through patient anonymity. The explosive rise of identity fraud
in recent years illustrates that the same should hold true for most transaction
mechanisms.
• Forcing individuals to use fully anonymous communication and transaction
methods is almost as much an invasion on privacy as the other way around.
Different individuals have disparate privacy preferences; surveys by Equifax
and Louis Harris & Associates indicate that about 55% of people are privacy
“pragmatists,” who are willing to trade personal data depending on a number
of factors, including the beneﬁts they will receive in return. Another important
reason not to hardwire absolute anonymity into communication and transac-
tion systems is that in many situations anonymity does not beneﬁt anyone. In
recognition of these facts, privacy-enhancing digital certiﬁcation mechanisms
should not make the property of anonymity invariant, but should enable each
individual to decide for him or herself how much data to disclose in each trans-
action; this is called the selective disclosure paradigm.
• Anonymity of each transaction by itself is a necessary but insufﬁcient condi-
tion to prevent linking of different transactions; any correlation that exists in
the transcripts of any two protocol executions, for instance in the form of a
public key, may be used to link them. Without unlinkability individuals cannot
control how much data they actually disclose, since the aggregate information
learned by linking different transactions will typically reveal much more than
the data items that were willingly disclosed on each separate occasion. With-
out control over the degree of linkability, the paradigm of selective disclosure
loses its power with each new disclosure. In particular, if a person is identiﬁed
in a single transaction, then all his or her past and future transactions become
traceable. Unlinkability is essential to prevent gradual erosion of privacy.

32
INTRODUCTION
• In case a certiﬁcate holder authenticates his or her certiﬁcate showings by
means of a digital signature, he or she leaves a permanent self-authenticating
record that can be veriﬁed by anyone. This gives coercive powers to the re-
ceiver and anyone else who sees the signed statement. If transactions are un-
traceable, little harm may come from this, but there is always the possibility
that signed data disclosed in one anonymous transaction can be linked to later
transactions in which an identiﬁer is revealed. For this reason, it is desirable
that individuals can authenticate messages and attribute data in a manner that
does not leave a self-authenticating record.
• Given the enormous security beneﬁts offered by smartcard-based implemen-
tations, there is an urgent need to preserve all these privacy properties in this
setting. In particular, smartcards should be unable to leak personal data and
other attributes stored inside, and should be unable to learn any information
from the outside world other than what their holders consent to. These prop-
erties should hold in the strongest possible sense, namely in the presence of
CAs that have access to cryptographic backdoors and conspire with certiﬁcate
veriﬁers.
In Chapters 2 to 6 we will develop cryptographic techniques that meet these privacy
objectives and overcome the security and efﬁciency problems in Section 1.1. In the
next section we give an overview of these techniques.
1.3
Outlook
1.3.1
Basic building blocks
Throughout the rest of the book the term “digital certiﬁcate” will always refer to the
CA’s signature only; it does not include the public key or any information associated
with it by the CA’s signature. This convention is not mainstream26 but makes it easier
to distinguish between various cryptographic objects.
We start in Chapter 2 with an overview of the cryptographic preliminaries needed
to understand the material in the other chapters. Several new primitives will be in-
troduced that play a fundamental role in the other chapters. In particular, we intro-
duce two functions that are one-way and collision-intractable, and for both we design
practical techniques for proving knowledge of an inverse and for constructing digital
signatures. We also introduce a new kind of digital certiﬁcates.
In Chapters 3 and 4 we develop two basic building blocks:
• A certiﬁcate issuing protocol with the following properties:
26Many publications consider a certiﬁcate to be the data structure comprised of the CA’s signature, the
public key it certiﬁes, and any information assigned to that public key.

1.3 OUTLOOK
33
– The receiver receives an unforgeable triple of the form (secret key, public
key, certiﬁcate). The (secret key, public key) of the triple is a key pair for
use by the receiver, while the certiﬁcate is digital signature of the issuer,
made using its own secret key.
– The receiver can ensure that the (public key, certiﬁcate) pair of the triple
is fully blinded. (Consequently, at least part of the secret key is blinded
as well, since the public key corresponds uniquely to the secret key.)
– The receiver cannot blind a non-trivial blinding-invariant part of the se-
cret key of the triple. In this blinding-invariant part, the issuer can encode
an arbitrary number of attributes.
• A certiﬁcate showing protocol with the following properties:
– To show a retrieved triple, the receiver discloses the (public key, cer-
tiﬁcate) pair and uses the secret key of the triple to authenticate a mes-
sage. (This authentication serves at the very least to prevent replay.) The
authentication mechanism allows the receiver to avoid leaving behind a
self-authenticating record.
– The authentication mechanism is such that the receiver not only authen-
ticates the message, but also demonstrates a property of the attributes
encoded into its certiﬁed key pair. The receiver has full control over
which property is demonstrated: it can be any satisﬁable proposition from
proposition logic, where the atomic propositions are relations that are lin-
ear in the encoded attributes. Any other information about the attributes
remains unconditionally hidden.
An automated negotiation mechanism such as that of OPS/P3P could be used
to implement the negotiation process in the showing protocol.
The certiﬁcate showing protocol techniques will be developed in Chapter 3 and the
issuing protocol techniques in Chapter 4. In Section 5.1 we will show how to seam-
lessly combine the issuing and showing protocol techniques, without adding com-
plexity and without compromising security or privacy.
The new certiﬁcates function in much the same way as do cash, stamps, cinema
tickets, subway tokens, and so on: anyone can establish the validity of certiﬁcates
and the non-identity data they certify, but no more than just that. A “demograph-
ic” certiﬁcate, for instance, can certify its holder’s age, income, marital status, and
residence, all neatly tied to one public key by means of a single digital signature
of the certiﬁcate issuer. Because the attributes are encoded into the certiﬁcate ap-
plicant’s secret key, certiﬁcate holders can decide for themselves, depending on the
circumstances, which attributes to disclose. This goes beyond the analogy of using
a marking pen to cross out data ﬁelds on a paper-based certiﬁcate; for instance, the

34
INTRODUCTION
holder of a demographic certiﬁcate can prove that he or she is either over 65 or un-
der 18, without revealing which is the case or anything else. Furthermore, actions
involving different certiﬁcates cannot be linked on any other basis than by what is
explicitly disclosed.
The basic building blocks are highly practical. They can be based on the RSA
assumption as well as on the Discrete Logarithm assumption, and admit elliptic curve
implementations with short public keys. The communication and computation com-
plexity of the issuing protocol are virtually independent of the number of attributes
encoded into a certiﬁed key pair, and the showing protocol is almost as efﬁcient as
protocols that cannot provide selective disclosure.
1.3.2
Additional privacy techniques
Section 5.2 is devoted to additional techniques to improve privacy for certiﬁcate hold-
ers:
• (Anonymous updating) In many cases one’s right to access a service comes
from a pre-existing relationship in which identity has already been established.
We provide a technique that enables an individual to anonymously present a
certiﬁed public key for updating to the CA. The CA can recertify the attributes,
or updated versions of them, without needing to know their current values. A
special application is to prevent the CA from learning the entire set of attributes
of a certiﬁcate applicant. Different CAs can even certify different attributes for
the same certiﬁed key pair.
• (Simulatable certiﬁcate information) To prevent online certiﬁcate repositories
from serving as data warehouses containing indisputable information about
certiﬁcate holders, so-called secret-key certiﬁcates (developed in Section 2.6)
may be used. These certiﬁcates allow anyone to generate directory entries
that are indistinguishable from the entries that list certiﬁcates issued by the
CA, yet offer the same basic security. Secret-key certiﬁcates also have the
advantage that a showing protocol execution is entirely zero-knowledge when
the attribute property is demonstrated in zero-knowledge.
• (Hiding participation in a PKI) Using secret-key certiﬁcates, users can simulate
certiﬁed public keys for PKIs in which they do not or may not participate.
They can prove to be a participant of (at least) one out of many PKIs or to have
attributes certiﬁed by a subset of several CAs, without revealing more. This
reduces the scope for discrimination on the basis of one’s (lack of) PKI access
rights.
• (Selective disclosure for multiple attribute certiﬁcates) Rather than encoding
many attributes into a single certiﬁed key pair, it may be preferable to distribute
them across multiple certiﬁed key pairs. This helps avoid the aggregation of

1.3 OUTLOOK
35
an individual’s attributes by a single CA, improves efﬁciency, and removes the
need to update certiﬁcates more frequently than otherwise needed. Our selec-
tive disclosure techniques can be applied not only to attributes encoded into a
single certiﬁed key pair, but also to attributes in different key pairs (possibly
certiﬁed by different CAs). Likewise, different certiﬁcate holders can jointly
demonstrate that their combined attributes meet certain properties.
• (Self-linkability) Certiﬁcate holders can anonymously prove in a simple vari-
ation of the showing protocol to be the originator of a plurality of showing
protocol executions. As a special application, we show how to enable certiﬁ-
cate holders in the showing protocol to build up reputations with organizations.
In Section 5.3 we will describe techniques to improve the privacy of certiﬁcate ver-
iﬁers. Speciﬁcally, we will show how to perform the showing protocol in such a
manner that the veriﬁer receives a signed statement that proves that a certiﬁcate has
been shown but unconditionally hides all or part of the attribute property that has
been demonstrated. In applications where veriﬁers submit their showing protocol
transcripts to the CA, for instance to enable the CA to detect and combat fraud, this
property prevents the CA from learning which formulae the veriﬁers require their
customers to demonstrate. At the same time, veriﬁers are unable to provide false
information to the CA.
Our use of certiﬁed public keys has two side beneﬁts: a secure session can be
established without enabling wiretappers to identify the session initiator from its cer-
tiﬁed public key, and fraudulent CAs cannot falsely revoke certiﬁed public keys that
are used only once.
1.3.3
Security techniques
In Section 5.4 we will show how to combine our issuing and showing protocols in
such a manner that either one of the following two properties is achieved:
• (Unlimited-show certiﬁcates) Even if a certiﬁcate is shown an arbitrary number
of times, the information that is revealed is no more than the aggregate infor-
mation that is willingly disclosed in each of the individual showing protocol
executions. (Multiple showings of the same certiﬁcate are all linkable, though;
a certiﬁed public key in effect is a digital pseudonym.)
• (Limited-show certiﬁcates) If and only if a certiﬁcate is shown more than a
predetermined number of times, the aggregate information that is revealed al-
lows the computation of the entire secret key of the certiﬁcate holder (and in
particular all the encoded attributes). The threshold can be arbitrarily set.
The limited-show property holds even if the certiﬁcate holder is free to choose the
attribute property that it demonstrates in each showing protocol execution, and can be

36
INTRODUCTION
combined with the veriﬁer privacy technique described in Section 5.3. (That is, the
CA will be able to trace perpetrators regardless of whether certiﬁcate veriﬁers hide a
part of the formulae demonstrated.) Even conspiring certiﬁcate holders and veriﬁers
cannot defeat the limited-show property.
The limited-show technique is highly practical: to compute one of the hidden at-
tributes (for instance an identity attribute) in case of fraud, even in a military-strength
implementation a “footprint” of a mere 60 bytes must be stored per showing protocol
transcript, regardless of the complexity of the formula demonstrated and the number
of encoded attributes.
In Section 5.5 we will show how to apply the limited-show techniques to dis-
courage unauthorized lending and copying of certiﬁcates, and the deliberate discard-
ing of certiﬁcates that contain attributes that the certiﬁcate holder does not want to
show. These security techniques do not require tamper-resistant devices for certiﬁ-
cate holders, nor do they require online certiﬁcate validation. When issuing gender
or age certiﬁcates for gaining access to Internet discussion groups or Web sites, for
instance, the issuer can encode into each certiﬁed key pair not only the designated re-
ceiver’s gender or age, but also some information that the receiver would like to keep
secret (such as his or her credit card information, redeemable electronic coins, or an
account access key). While the certiﬁcate holder can hide this secret when showing
the certiﬁcate (by using our selective disclosure techniques), the certiﬁcate cannot be
shown without actually knowing the encoded secret; lending therefore requires the
certiﬁcate holder to give away the secret.
Furthermore, we show in Section 5.5 how to achieve non-repudiation for limited-
show certiﬁcates, to prevent the CA from framing certiﬁcate holders by falsely claim-
ing that limited-show certiﬁcates have been shown too many times. The evidence of
fraud can be obtained in the form of a self-signed confession, and can be made un-
conditionally convincing. A particularly surprising feat is that the non-repudiation
techniques can be made to work even when certiﬁcate applicants are anonymous to
the certiﬁcate issuer.
We also describe in Section 5.5 measures to protect against leakage and misuse of
the CA’s secret key, including measures to cope with attackers with inﬁnite comput-
ing power (to prevent PKI meltdown). Another technique described in Section 5.5
concerns digital bearer certiﬁcates; these hide or do not contain any attributes that
can be uniquely traced or linked to one person or to a select group.
Our techniques are not complementary to the currently prevailing ideas about
digital certiﬁcates and PKIs, but encompass them as a special case. By way of exam-
ple we will show in Section 5.5.1 how to encapsulate X.509v3 certiﬁcates. The new
techniques are beneﬁcial in any authentication-based communication or transaction
environment in which there is no strict need to identify certiﬁcate holders at each and
every occasion. The only acceptable role for X.509 and other identity certiﬁcates
in such environments is to facilitate registration in case certiﬁcate applicants must
be identiﬁed to the CA, similar to the way in which drivers’ licenses and passports

1.3 OUTLOOK
37
are traditionally used to acquire a permit or some other kind of authentication proof;
even for this purpose, however, our certiﬁcates can be used.
In none of the techniques in this book do certiﬁcate veriﬁers need tamper-resistant
devices.
1.3.4
Smartcard integration
All our techniques can be applied not only in the setting of software-only devices, but
also in a setting where certiﬁcate holders in addition to a software-only device hold
a smartcard. In Chapter 6 we ﬁrst describe the many shortcomings of smartcard-
only implementations, and list the advantages of combining smartcards with user-
controlled software-only computers. We then show how to securely lift the software-
only techniques of the preceding chapters to the smartcard setting in such a manner
that the following privacy properties are guaranteed:
• The smartcard cannot learn the (public key, certiﬁcate) pair of its holder’s cer-
tiﬁed key pairs, and cannot learn any encoded attributes its holder desires to
keep secret.
• The smartcard cannot learn the property that is demonstrated in the showing
protocol. In particular, regardless of the complexity of the formula demon-
strated and the number of attributes encoded into a certiﬁed key pair, the smart-
card performs exactly the same protocol. The smartcard cannot even decide
whether multiple invocations of its assistance are for the purpose of showing
the same certiﬁcate or different certiﬁcates, and can be prevented from learning
any information on the number of certiﬁcates issued to its holder.
• All possible data leakages by and to the smartcard are prevented. This includes
not only leakages that can be detected, but also subliminal channels. Conse-
quently, the veriﬁer learns nothing beyond the status of the formula(e) demon-
strated; it cannot even distinguish whether the certiﬁcate holder is assisted by
a smartcard or uses merely a software-only device.
• The smartcard can be prevented from developing any data that is statistically
correlated to data known to the outside world (in particular, to the CA and
certiﬁcate veriﬁers), so that even the contents of a returned smartcard that has
been adversely programmed cannot reveal any information about the commu-
nications and transactions conducted by its holder (other than an upper bound
on the number of showing protocol executions).
In this manner, the task of each smartcard is reduced to the absolute minimum,
namely to protect the most basic security interests of the certiﬁcate issuer and its
holder. This is desirable not only in light of privacy, but also for efﬁciency and secu-
rity.

38
INTRODUCTION
Our techniques accommodate situations in which the smartcard’s task is deliber-
ately broadened, for the purpose of controlling to which parties a certiﬁcate can be
shown, which properties may be demonstrated, and so on. For instance, it may be
desirable for individuals that their smartcard can assist in the showing protocol only
when the designated veriﬁer provides an identiﬁer; as will be shown in Section 6.4.4,
this sufﬁces to protect against extortion attacks conducted over networks. Also, in
some high-risk PKIs law enforcement may need the ability to trace the past actions
of a designated certiﬁcate holder (but only with that person’s awareness). In general,
the smartcard can be prevented from learning anything beyond what it is expressly
supposed to learn in order to perform a well-deﬁned task known to its holder. This
sufﬁces to accommodate any legitimate needs to reduce the attainable privacy level.
The certiﬁcate issuing and showing protocols for software-only devices in Chap-
ters 3 to 5 are a self-contained subset of the smartcard-enhanced protocols. An impor-
tant advantage of this architecture is that all the security protections of the software-
only system apply in the (presumably hypothetical) case that the tamper-resistance of
a large number of smartcards is compromised overnight. It also enables PKI imple-
mentations in which some certiﬁcate holders hold software-only devices and others
use smartcards. In particular, a PKI can be introduced as a software-only system and
migrate gradually to a smartcard-enhanced system as the demand rises for greater
efﬁciency, functionality, and security.
The computation and storage requirements for the smartcard do not depend on the
number of encoded attributes or the complexity of the demonstrated formulae. Our
smartcard techniques can even be implemented using low-cost 8-bit smartcards with
limited memory and no cryptographic coprocessor, as will be shown in Section 6.5.1.
This minimizes the cost for all parties, and allows manufacturers to devote the bulk
of smartcard logic to improved tamper-resistance measures.
Different PKIs can make use of the same smartcard without being able to inter-
change personal data (unless the card holder consents). Certiﬁcate applications can
be built on top of widely available smartcards that provide only basic identiﬁcation
or signature functionality.
When limited-show short-lived certiﬁcates are issued, the need to rely on (timely)
revocation greatly reduces, and so our smartcard techniques also help overcome the
cost, efﬁciency, and privacy problems of off-line and online certiﬁcate revocation and
validation mechanisms. (Revocation of encryption keys can be avoided by randomly
generating one-time encryption keys afresh at the start of each authenticated session.)
In Section 6.5 we show how certiﬁcate holders can securely return to the CA
any retrieved certiﬁcates that have not yet been shown, how to discourage certiﬁcate
holders from using their certiﬁcates to help remote parties gain access to services
for which they do not hold the proper certiﬁcates themselves, how to design secure
bearer certiﬁcates with optimal privacy, and how to prevent organizations and other
veriﬁers from discriminating against certiﬁcate holders who do not disclose their
built-in identiﬁers.

1.3 OUTLOOK
39
1.3.5
Security and privacy guarantees
All the techniques can be based on the RSA assumption as well as on the Discrete
Logarithm assumption, and admit elliptic curve implementations with short public
keys. Many of the security aspects can rigorously be proved equivalent to the security
of either one of these assumptions in the so-called random oracle model.
All the privacy properties are guaranteed in the strongest possible sense: even if
all the veriﬁers, smartcards, and CAs conspire in an active attack, are given inﬁnite
computing power, and jointly establish secret information in an preparatory phase,
they cannot learn more than what can be inferred from the assertions that are volun-
tarily demonstrated in executions of the showing protocol. Consequently, individuals
can prevent secondary use of their attribute data and can at all times ensure the cor-
rectness, timeliness, and relevance of their own data. At the same time, the risk of
identity fraud is minimized.
While this information-theoreticalprivacy guarantee is very strong, it is important
to realize that computational privacy would be unsatisfactory:
• The infeasibility assumption at the heart of breaking computational privacy
is based on a speciﬁc distribution of the system parameters and key material
generated by the CA. It may be hard or even impossible to verify that these
are indeed generated in accordance with the proper probability distribution. A
clever method of generating the system parameters or the key material may
enable the CA to trace communications and transactions with modest compu-
tational effort.
• Another danger of computational privacy is that one or two decades from now
it may be entirely practical for CAs to retroactively trace any or all of today’s
communications and transactions. The expected advances in algorithmics and
progression in sheer computing power27 will make it possible then to break
implementations based on key sizes deemed sufﬁciently strong today, without
needing a polynomial-time attacking algorithm. Indeed, virtually all the cryp-
tographic systems in use today employ keys that for efﬁciency reasons are as
small as possible; these key sizes do not guarantee invulnerability for more
than a decade.
In either of these two cases, the resulting level of privacy-intrusion may be much
more damaging than that of PKIs without any form of privacy to begin with, because
certiﬁcate holders will be less inhibited in their actions.
The difference between computational and information-theoreticalprivacy can be
viewed as follows. With computational privacy all the secrets of individuals end up
27In 1965, Moore predicted that the number of components on integrated circuits would double every
year for ten years. In 1975 he predicted a doubling every two years instead of every year. Thus far,
Moore’s prediction has been remarkably accurate. It is anticipated that by the year 2010 we will be down
to atomic dimensions.

40
INTRODUCTION
in the outside world, encrypted under a public key. Information-theoretical privacy
guarantees that the secrets do not get out there in the ﬁrst place.
In a practical implementation of a design that offers information-theoretical pri-
vacy, certiﬁcate holders should be given the freedom to select their own method of
generating the random numbers needed to protect their own privacy. Those who
desire the strongest privacy level should use random bits produced by a noise gen-
erator (post-processed by arithmetical methods to remove correlations), while others
may be comfortable using pseudorandom bit generators or other methods that offer
at most computational privacy. The fundamental difference with a system that has
computational privacy hardwired into its design is that each certiﬁcate holder is free
to choose or produce his or her own source of randomness, including the security
parameters and seed values for pseudorandom generators.
For a general discussion of the difference between privacy-protecting methods
and methods that merely create the illusion of privacy, see the Epilogue.
Our techniques do not protect against wiretapping and trafﬁc analysis, but allow
the modular adoption of session encryption, anonymous remailers, and other mea-
sures as an additional layer. Techniques to prevent wiretapping and trafﬁc analysis
are largely platform dependent and not necessarily based on cryptography. Note also
that conﬁdentiality can be trivially achieved once the authenticity problem is solved;
the authenticity proof can include a public key to be used for encryption. The in-
dependence of encryption is good design practice in any case, and avoids regulatory
issues such as export controls.
1.3.6
Applicability
Our techniques facilitate a cookbook approach towards designing electronic com-
munication and transaction systems. Applications of special interest include, but
are not limited to: electronic cash; digital pseudonyms for public forums and vir-
tual communities (such as Internet news groups and chat rooms); access control (to
Virtual Private Networks, subscription-based services, Web sites, databases, build-
ings, and so on); digital copyright protection (anonymous certiﬁcates permitting use
of works); electronic voting; electronic patient ﬁles; electronic postage; automated
data bartering (integration with standardization efforts such as P3P is easy); online
auctions; ﬁnancial securities trading; pay-per-view tickets; public transport ticket-
ing; electronic food stamps; road-toll pricing; national ID cards (but with privacy);
permission-based marketing; Web site personalization; multi-agent systems; collabo-
rative ﬁltering (i.e., making recommendations to one person based on the opinions of
like-minded persons); medical prescriptions; gift certiﬁcates; loyalty schemes; and,
electronic gambling. The design of speciﬁc applications is outside the scope of this
book, but is relatively straightforward in many cases.

Chapter 2
Cryptographic Preliminaries
In this chapter we review all the basic cryptographic primitives needed in the rest of
the book: one-way and collision-intractable functions, proofs of knowledge, digital
signatures, and public-key certiﬁcates. We introduce two new functions that are one-
way and collision-intractable, and for both design practical techniques for proving
knowledge of an inverse and for constructing digital signatures. These functions are
central to our constructions of issuing and showing protocols in the next two chapters.
We also introduce a new kind of digital certiﬁcates, called secret-key certiﬁcates; the
beneﬁts of these will become clear in Chapters 4 and 5.
2.1
Notation, terminology, and conventions
2.1.1
Basic notation
The notation “x := y” means that the value of y is assigned to x. Typically, y is
an arithmetic expression. The “=” symbol denotes equality; upon x := y we have
x = y.
Whenever we say that a number is chosen “at random” from a set V , we imply
a uniform distribution over the set V , independent of the probability distributions of
any other variables explicitly considered in the same context. Within a ﬁgure, the
notation x ∈R V is used to denote the same.
All the constructions in this book are based on elementary algebra. The notation
Zt denotes the ring of integers modulo t and Z
∗
t its multiplicative group, and GFt
denotes the ﬁnite ﬁeld with t elements. Computations involving numbers in a ﬁnite
ring or in a multiplicative group must always be interpreted as computations in these
structures. For example, if x, y ∈Z
∗
t , then “xy” stands for xy mod t. In cases where
we consider arithmetic involving exponents, the modulo operator is often made ex-
plicit for greater certainty. In mathematical proofs, an element in Zt or in Z
∗
t may

42
CRYPTOGRAPHIC PRELIMINARIES
be interpreted in the algebraic sense of denoting a congruence class, but in construc-
tions of algorithms and protocols it always represents a unique number between 0
and t −1, usually encoded in binary. In particular, if x, y ∈Zt, then “x = y” means
that x and y are the same number, not merely that they are congruent modulo t.
For any x ∈Z and any y ∈N, x mod y denotes the number x∗∈{0, . . ., y−1}
such that x∗−x is an integer multiple of y. In keeping with mathematical tradition,
the mod operator acts on the entire arithmetic expression preceding it, unless paren-
theses specify otherwise. For instance, a + b mod y stands for (a + b) mod y.
The notation div is deﬁned by x = x mod y + y (x div y), for any x ∈Z and
any y ∈N. Parentheses indicate the arithmetic expression on which div operates.
The notation “|X|” can have three different meanings. If X is a set, then |X|
denotes the size of X, i.e., the number of elements in X; if X is a number in R, then
|X| denotes its absolute value; and if X is by deﬁnition a positive integer then |X|
denotes its binary size (length). The appropriate meaning will always be clear from
the context.
2.1.2
Algorithms, security parameters, and probability
An algorithm is a procedure that, on given some input, always halts after a ﬁnite
number of steps. For concreteness, intractability assumptions are always stated in
the uniform complexity model, and we construct algorithms that can be formalized
by Turing machines.1 Thus, all algorithms have a read-only input tape, a work tape,
and a write-only output tape. Probabilistic algorithms in addition have a random tape
containing their coin ﬂips. Once the computation of an algorithm comes to a halt, its
ﬁnite-state control enters into either an accept or reject state; correspondingly, the
algorithm is said to accept or reject. In addition, it may have written an output onto
the cells of its output tape; A(x) denotes the output of algorithm A on input x. If A is
probabilistic, then A(x) is a random variable whose probability distribution is taken
over the coin ﬂips of A; that is, A(x) deﬁnes a probability space of output strings.
We write x := A(y) or A(y) = x to specify that x is generated by running algorithm
A on input y.
A security parameter is a number that is taken from an inﬁnite subset of the set
of positive integers. Security parameters are used to measure the time and space
complexity of an algorithm, the binary sizes of algorithm inputs and outputs, success
probabilities, and security levels. Although multiple security parameters may be
speciﬁed for any one protocol or system, for simplicity all the protocols and systems
in this book make reference to only a single security parameter, denoted by k. The
notation 1k denotes k encoded in unary.
For inputs of the same binary size, the possible outputs of an algorithm are all
1It would be easy to rephrase our constructions and security reductions in the non-uniform complexity
model of Boolean circuits, since they do not hinge on the use of polynomial-size advice strings that cannot
be computed in polynomial time.

2.1 NOTATION, TERMINOLOGY, AND CONVENTIONS
43
assumed to be of the same binary size; this can be achieved by the standard practice
of padding.
As is common in the cryptographic literature, we measure the running time of
an algorithm in terms of elementary algebraic operations, typically modular multi-
plications, instead of in terms of the number of transitions of the Turing machine’s
read-write head. The terms feasible and infeasible have the standard complexity-
theoretical meaning: feasible computations are those that can be performed in time
polynomial2 in k, while infeasibility corresponds to superpolynomial running time3
(which includes subexponential and exponential running time). Whenever we speak
of a polynomial-time algorithm, it may be either deterministic or probabilistic.
A function f : N →[0, 1] is negligible in k if f(k) is smaller than the inverse
of any polynomial in k, for all sufﬁciently large k; it is non-negligible if there exists
a positive integer c such that f(k) is greater than 1/kc, for all sufﬁciently large k;
and, it is overwhelming if 1 −f(·) is negligible. (Note that a function can be neither
negligible nor non-negligible.) An intractable problem is one that cannot be solved
in polynomial time with non-negligible probability of success.
The notation Pk(Ek) denotes the probability of event Ek. For probability spaces
S1, S2, . . ., the notation
Pk(Ek(x1, x2, . . .) | x1 := S1; x2 := S2; . . .)
denotes the probability that the event Ek(x1, x2, . . .) holds when each xi is chosen,
in the given order, from the corresponding probability space Si.
An expected polynomial-time algorithm is a probabilistic algorithm whose ex-
pected running time (over its coin ﬂips) is polynomial for any input. By running a
probabilistic polynomial-time algorithm that has non-negligible success probability
ϵ(k) an expected number of k/ϵ(k) times, one can construct an expected polynomial-
time algorithm that has overwhelming success probability.
A language over an alphabet is a subset of the set of all ﬁnite strings of symbols
from that alphabet. If A is a probabilistic algorithm and L a language, then the col-
lection {A(x)}x∈L is an ensemble of random variables. Two ensembles {A(x)}x∈L
and {B(x)}x∈L are perfectly indistinguishable if, for all x ∈L, the random variables
A(x) and B(x) have the same distribution. They are statistically indistinguishable
(or almost-perfectly indistinguishable) on L if for all x ∈L of binary size k their
statistical difference

α
 Pk(A(x) = α) −Pk(B(x) = α)

2A function f(·) is polynomial in k if there exists a positive integer c such that f(k) ≤kc for all
sufﬁciently large k.
3A function f(·) is superpolynomial in k if for all positive integers c, f(k) ≥kc for all sufﬁciently
large k.

44
CRYPTOGRAPHIC PRELIMINARIES
is negligible in k.4 Finally, they are computationally indistinguishable on L if, for all
polynomial-time algorithms D with Boolean output (representing accept or reject),
and for all x ∈L of binary size k,
 Pk(D(y) = 1 | y := A(x)) −Pk(D(y) = 1 | y := B(x))

is negligible in k.
2.1.3
Interactive algorithms and protocols
An algorithm may consist of two or more interactive algorithms that communicate
according to one or more stepwise descriptions called protocols. Interacting parties
in this book are always modeled as interactive algorithms. Formally, an interactive
algorithm is a Turing machine enhanced with a communication tape and a read-only
common input tape. A pair of interactive algorithms share their communication tapes,
for exchanging messages, and their common input tapes. The work tape and random
tape of each algorithm are private to the algorithm, and their private input tapes enable
each to make use of auxiliary input, also known as private input; this may be present
initially, or computed as protocol executions are taking place.
More generally, there can be any number of interactive algorithms communicat-
ing with each other in an arbitrary fashion. This can easily be formalized by endow-
ing each interactive algorithm with a set of communication and common input tapes
for any other algorithm it needs to be able to communicate with. Correspondingly,
protocols may be deﬁned among more than two parties. In general, any collection
of interactive algorithms can be viewed as a single (interactive or non-interactive)
algorithm.
With P and V denoting two interactive algorithms, (P, V) denotes the protocol
performed by them, and < P, V> denotes the two algorithms viewed as a single
(interactive or non-interactive)algorithm. The input of < P, V> is the initial contents
of their common input tape, and the output of < P, V> is the concatenation of the
contents on the output tapes of P and V. Usually at most one of P and V is deﬁned
to produce an output.
A move in a protocol is a message transfer from one interactive algorithm to
another; a round is two consecutive moves. After the last move in a protocol, the re-
ceiving algorithm checks a (protocol) veriﬁcation relation in order to decide whether
to accept or reject. Additional veriﬁcations may be applied in intermediate stages. A
protocol is said to be non-interactive if it consists of a single move, and interactive if
it has more. None of the protocols in this book have more than two rounds.
4The practical interpretation of this is that an inﬁnitely powerful algorithm that is restricted to taking
polynomially many samples cannot distinguish between the two distributions; such an algorithm can infer
the same information from either distribution. Note that perfect indistinguishability corresponds to zero
statistical difference.

2.1 NOTATION, TERMINOLOGY, AND CONVENTIONS
45
Protocols are sometimes depicted in ﬁgures, together with a description of the
preliminary stage for setting up keys and other prerequisite information. Within a
ﬁgure, the actions performed by an interactive algorithm are all displayed in the same
column, with a label on top indicating the algorithm that performs the actions. A
move is shown in the form of an arrow from the transmitter to the receiver, with the
message that is transferred displayed on top of the arrow. Protocol ﬁgures should
be read from top to bottom. Any additional data that is displayed in a column that
contains one or more message transmittals, such as a public key, is also considered
known to both communicating parties.
The transcript of a protocol executed by two interactive algorithms is the entire
ordered sequence of messages exchanged between them until one of them halts.
The view of an interactive algorithm in a protocol execution is an ordered set con-
sisting of all the information that the algorithm has “seen” in the protocol execution.
This comprises the protocol transcript, as well as the common input, any private in-
put, and its own coin ﬂips (if any). An accepting view of an interactive algorithm
is the view of that algorithm in a protocol execution in which it accepts. Usually at
least one of the algorithms in a protocol will be probabilistic, in which case the view
is a random variable deﬁned by the coin ﬂips in the protocol. By parameterizing over
all possible protocol executions an ensemble of random variables is obtained, and so
we can consider indistinguishability of protocol views.
With P and V denoting two interactive algorithms, VP(aux1)(x; aux2) denotes
V’s output when interacting with P on common input x, auxiliary input aux1 to P
and auxiliary input aux2 to V. When there is no auxiliary input to V, we simply
write VP(aux)(x). In either case, for ﬁxed inputs this is a random variable, whose
probability distribution is taken over the coin ﬂips (if any) of P and V.
The notation K(x; A) denotes the output of algorithm K on input x, when having
write access to the random tape and the private input tape of algorithm A that in
all other respects behaves as a black box to K. The standard method for extracting
knowledge from an algorithm A is to rewind A for the same tape conﬁgurations but
different queries. By means of oracle replay in the so-called random oracle model,
which we discuss shortly, it may be possible to extract secrets even if rewinding is
not an option, even though it is unclear in this case how to properly deﬁne knowledge
outside the random oracle model. (See Assumption 4.3.9 for an example.)
2.1.4
Attack models
An honest interactive algorithm does not deviate from its behavior speciﬁed in the
protocol description, and does not engage in any other actions. In particular, it fol-
lows the protocol description in all protocol executions in which it engages.
An attacker is an interactive algorithm that may deviate from its prescribed ac-
tions, for instance by deviating from its actions in the speciﬁed protocols or by wire-
tapping the protocol executions of others. When assessing the security of a new

46
CRYPTOGRAPHIC PRELIMINARIES
cryptographic construction, we typically view the subset of all parties that deviate
from the prescribed protocol(s) (either cooperative or non-cooperative) as a single
algorithm, which we then use as a subroutine for an algorithm to solve a supposedly
intractable problem. A collection of attackers that may but need not share all their
tapes is referred to as an adversary.5
In assessing whether a protocol satisﬁes a property of interest, one must consider
not only the computing power of the attackers, but also the ﬂexibility they have in
engaging in executions of the protocol. Among the factors contributing to whether
an adversary can break a presumed property of a protocol are the following:
• The extent to which multiple executions of the same protocol, or of different
protocols, can be interleaved. Parallel executions of a protocol are more efﬁ-
cient than sequential executions, not only in the number of moves but also in
that some additional operations (such as line encryption) may be applied once
on all the moves that occur concurrently. On the other hand, parallelization
may enable an adversary to compute information that it could not compute
otherwise.
The most powerful attack model is that of arbitrary composition of protocols
or protocol executions; here, the adversary can adaptively (depending on its
protocol views in the past) decide at each stage which moves of one protocol
execution to interleave with which moves of another protocol execution (not
necessarily of the same protocol), and in what manner.
• The number of protocol executions attackers are able to engage in.6 A passive
attacker is not allowed to interact at all, but can wiretap protocol executions that
take place by honest parties; an active attacker is allowed to engage in protocol
executions. In all our protocol descriptions in this book honest parties are
assumed to be polynomial-time, and so even an inﬁnitely powerful adversary
can never engage in more than polynomially many protocol executions.
• The computing power given to the adversary. All the privacy results in this
book are proved under the assumption that attackers have inﬁnite computing
power. Digital signatures, on the other hand, can be proved unforgeable only
against attackers that are polynomially bounded.
5The protocol executions of an attacker that operates in isolation may be wiretapped by other attackers
and in this manner add to their power; for this reason isolated attackers must be considered part of the
adversary. The attempt to circumvent this by encrypting all message transfers is not satisfactory. First, it
is unreasonable to characterize parties that do not properly encrypt their own messages as attackers of the
system. Second, it would be poor design practice to let the requirement for session encryption interfere
with the design of the system core and the analysis of systemic security.
6For example, in Section 5.4 we will construct proofs of knowledge in which the prover does not leak
any information about its secret key when performing the protocol once, but multiple protocol executions
using the same public key leak the entire secret key.

2.1 NOTATION, TERMINOLOGY, AND CONVENTIONS
47
The power of an adversary with unlimited resources is not restricted to com-
putations before or after a protocol execution; at each step, it may use inﬁnite
computing time to compute its next message. While this model may seem un-
realistic, in the Turing machine model it makes perfect sense: the running time
of an interactive algorithm is determined by the number of state transitions de-
ﬁned by the transition function, and so the time taken by one machine does not
affect the running time of the other. Moreover, the model of inﬁnite computing
power serves as a useful abstraction to model the complete absence of one-way
functions (see Section 2.2) and other intractable computational tasks. When a
construction is proved invulnerable against an inﬁnitely powerful adversary,
there is no need to worry about attackers that have embedded cryptographic
trapdoors or have come up with a cryptographic breakthrough.
The ﬁrst two of these factors are under the control of the honest party that is being
attacked. It can determine which protocol executions to perform sequentially and
how many executions it engages in.
The aggregate view of an interactive algorithm in multiple executions of the same
or of different protocols is the collection of its views in the individual protocol exe-
cutions. The ordering of the components of the aggregate view is naturally deﬁned
by the fashion in which the protocol executions are interleaved.
Following Feige, Fiat, and Shamir [168], A denotes an honest interactive algo-
rithm, 
A denotes an attacker with polynomially bounded resources, and 
A denotes
an attacker with unbounded computing resources. Attack algorithms 
A and 
A may
but need not deviate from the protocol description, and can engage in as many proto-
col executions as they desire, conﬁned only by the limitations imposed by the other
parties in the protocols they engage in. For instance,
VP(aux1)(x; aux2)
denotes V’s output after interacting with P, whereby V can query P as if it were an
oracle; in particular, V’s output may be the result of a phase in which V engages in a
plurality of protocol executions. In contrast,
VP(aux1)(x; aux2)
always refers to a single execution of the protocol.
In analyzing whether a certain property holds for an honest party in a protocol,
it is always assumed that the party aborts an execution of the protocol as soon as the
other party (parties) deviates from the description of the protocol in a manner that
is detectable with certainty by the honest party. The interpretation of “detectable”
depends on the veriﬁcation relations and other actions speciﬁed in the description
of the protocol, as well as on actions that we always assume implicitly. Speciﬁ-
cally, it is implicit in protocol descriptions that the parties to a protocol always apply

48
CRYPTOGRAPHIC PRELIMINARIES
range-checking to numbers supposed to be in an algebraic structure. For examples of
attacks that become possible when a party inadvertently does not apply range check-
ing, see Bleichenbacher [34] and Anderson and Vaudenay [14]. Arithmetic relations
that must apply to these numbers (i.e., veriﬁcation relations) are always mentioned
explicitly. In some case it is necessary to perform group membership tests; see Sec-
tion 2.4.3 for an example. Deviation by the other party from a speciﬁed probability
distribution, though, does not constitute a reason to abort a protocol execution.
2.1.5
Security reductions and the random oracle model
Since the emphasis in this book is on practicality, exact security is of importance.
Suppose that a problem P is conjectured to be intractable: problem instances of
size k cannot be solved with non-negligible success probability ϵ(k) in fewer than
rP (k) steps, for some superpolynomial running-time function rP (·). To prove the
infeasibility of a cryptanalytic attack on a new protocol construction, we construct an
algorithm A that can solve problem instances of size k of problem P in polynomial
time, with success probability negligibly close to ϵ(k), by making no more than poly-
nomially many subroutine calls to a black-box algorithm B that can feasibly solve
instances of the new construction. Suppose that, for inputs of size k, B runs in time
fB(k), and A makes fA(k) calls to B, using gA(k) additional processing steps for
each call and hA(k) additional one-time processing steps. The functions gA(·) and
hA(·) are polynomials, typically of low degree. The total running time rAB(k) of A
and B is equal to
fA(k)

fB(k) + gA(k)

+ hA(k).
If fB(·) is polynomially bounded there exists a positive integer k0 such that
rAB(k) < rP (k)
∀k ≥k0,
contradicting the presumed intractability of problem P. But what practical assur-
ances on the parameter sizes for the new construction can we infer from the proof
reduction? We obtain a contradiction only for security parameter sizes that exceed
k0, and so it is desirable that k0 be as small as possible. Hereto the functions fA(·),
gA(·) and hA(·) should all be as small as possible. In situations of practical interest
fB(k) typically exceeds hA(k) by far, and so fA(·) is the dominating contribution
to the total running time. We therefore equate the overhead factor of a security re-
duction with the (expected) number of calls to algorithm B. A security reduction is
tight if the overhead factor is a (small) constant, and optimal tightness is achieved
when the overhead factor is negligibly close 1. For any given security level, a tight
reduction allows one to implement the new construction using smaller parameter
sizes than would be allowed by a non-tight reduction. Because practicality is an im-
portant objective of this book, we strive for tight security reductions throughout. In
practice it is recommended to choose k in such a manner that an adversary needs

2.2 ONE-WAY FUNCTIONS
49
an expected number of at least 280 elementary operations to break the construction
at hand. (Imagine a supercomputer that can do 1 elementary operation each pico-
second, and that 300 of these are running in parallel; it would take over 128 years to
cycle through all 280 operations.)
Sometimes the security of a new construction can be proved only in the random
oracle model. In this model, a function that is believed hard to invert may be idealized
by substituting applications of the function by calls to a random oracle. The oracle,
on input an element in the domain of the function, produces a random output in the
range of the function, to be interpreted as the outcome of the function. Of course,
multiple oracle queries with the same input produce the same output. The success
probability of the resulting security reduction is taken over the space of all random
functions. Cannetti, Goldreich, and Halevi [76] concocted example constructions
that are provably secure in the random oracle model but provably insecure when the
oracle is instantiated using any function. Therefore, the ability to give a security
reduction in the random oracle model in general does not imply that a successful
attack requires the exploitation of a weakness in the function that is being idealized.
Nevertheless, in the “natural” cryptographic constructions that arise in practice, and
in particular in this book, provable security in the random oracle model is believed to
be a relevant measure of security. Most of the constructions in this book are amenable
to security proofs in the random oracle model.
2.2
One-way functions
2.2.1
Deﬁnition
From now on we are mainly interested in functions f(·) that can be expressed as an
inﬁnite collection of functions, {fi(·)}i∈V . Each fi(·) operates on a ﬁnite domain,
Di, and V is an enumerable inﬁnite index set, with i uniquely specifying Di. A
description of f(·) entails specifying V and the mapping fi(·). Any collection of
functions {fi(·)}i∈V can be represented by a single function f(·) that operates on an
inﬁnite domain, by deﬁning
f(i, x) := (i, fi(x)),
and so the two notions can be used interchangeably.
Informally, a one-way function is a function that is easy to compute, but com-
puting inverses is difﬁcult on average. To formalize this notion, we require an in-
stance generator for the function. An instance generator for a collection of functions,
{fi(·)}i∈V , is a pair (I, D) of probabilistic polynomial-time algorithms, operating as
follows:
• I takes as input 1k, and outputs an index i ∈V of binary size l(k), where l(·)
is a ﬁxed polynomial; and

50
CRYPTOGRAPHIC PRELIMINARIES
• D takes as input the output i of I, and outputs an element x in the domain
Di of fi(·). (Elements in Di may occur with zero probability as an output of
D(i).)
The output of (I, D) is (i, x). We will simply write (i, x) ∈V × Di to denote that
ﬁrst i is taken from V and then x is taken from Di. (Although this is not the standard
Cartesian product, no confusion can arise.)
Deﬁnition 2.2.1. A collection of functions, {fi(·)}i∈V , is (strongly) one-way over
an instance generator (I, D) if and only if the following two properties hold:
1. (Computable in one direction) There exists a deterministic polynomial-time
algorithm that, on input any (i, x) ∈V × Di, outputs fi(x); and
2. (Uninvertable in the other direction) For any polynomial-time algorithm A, the
probability function deﬁned by
Pk

fi(A(i, fi(x))) = fi(x) | i := I(1k); x := D(i)

is negligible in k.
Whenever we say that a function f(·) is one-way, we mean that the collection
of functions that it represents is one-way, in the above sense. In case the instance
generator is clear from the context, we will not mention it explicitly.
Note that functions with superpolynomial range are always one-way when ideal-
ized in the random oracle model.
If {fi(·)}i∈V is one-way over (I, D), then (I, D) is said to be an invulnerable
instance generator for {fi(·)}i∈V . The usefulness of the notion of invulnerability
(originating from Abadi, Allender, Broder, Feigenbaum, and Hemachandra [1]) be-
comes apparent when reducing the problem of inverting a function that is conjectured
to be one-way to the problem of breaking a new construction, to prove the security
of the latter. Instead of specifying a particular instance generator for the conjectured
one-way function, it is sometimes possible to make the same security reduction work
for all invulnerable instance generators; this makes the resulting security statement
much stronger. All the security reductions in this book are of this form. Note that if
an instance generator is invulnerable for a function, then so are all instance generators
with a computationally indistinguishable output distribution.
A commitment function enables a sender to commit to a secret, in such a manner
that the receiver cannot determine the secret until the sender opens the commitment,
while the sender cannot open the commitment to reveal a different secret than that
originally committed to. A one-way permutation can serve as a commitment function
that is unconditionally secure for the receiver and computationally secure for the

2.2 ONE-WAY FUNCTIONS
51
sender. Hereto the sender embeds its secret into the hard-core bits7 of an otherwise
randomly chosen argument x to a one-way permutation f(·).
We now discuss two well-known functions that are widely believed to be one-
way. Their one-wayness is crucial to the security of all the constructions in this
book.
2.2.2
The DL function
The output of an instance generator (I, D) for a DL function, deﬁned below, satisﬁes
the following format:
• On input 1k, with k ≥2, I generates a pair (q, g), satisfying the following
properties:
– q is a prime number of binary size k that uniquely speciﬁes a group of
order q, from now on denoted by Gq. Without loss of generality, the
group operation is assumed to be multiplication.
– g is a generator of Gq.
• On input (q, g), D generates an element x in Zq.
A DL function is a collection of functions, {fi(·)}i∈{(q,g)}, deﬁned as follows:
fq,g : x →gx.
The number x is called the discrete logarithm of gx with respect to g. Note that
different algebraic constructions for Gq give rise to different DL functions.
Under what conditions is a DL function one-way? If the construction of Gq is
such that multiplication in Gq is feasible, then fq,g(x) can be feasibly computed by
means of repeated squaring (see Menezes, van Oorschot, and Vanstone [266, Sec-
tion 14.6]), possibly in combination with additional preprocessing.8 The hardness
of inverting a DL function depends on the construction of Gq and on the instance
generator (I, D). The following two constructions are widely believed to give rise to
a one-way DL function.
(Subgroup construction) Gq is a subgroup of Z
∗
p, where p is a prime such that
q | (p −1) and |p| is polynomial in k. The following instance generator is
believed to be invulnerable:
7If f(·) is one-way, then there must exist a Boolean predicate of the bits of the argument of f(·) that
is at least somewhat hard to compute when given f(x). A Boolean predicate b(·) is said to be hard-core
for f(·) if b(·) can be computed in polynomial time, but no probabilistic polynomial-time algorithm can
compute bi(x) from fi(x) with success probability non-negligibly greater than 1/2. More generally,
several bits are said to be (simultaneously) hard-core for f(·) if no polynomial-time algorithm can extract
any information about these bits of x when given fi(x).
8Alternatively, addition chains or other techniques may be used. For overviews and comparisons of
exponentiation methods, see Knuth [232, Subsection 4.6.3], Menezes, van Oorschot, and Vanstone [266,
Chapter 14.6], von zur Gathen and N¨ocker [383], Gordon [196], and O’Connor [280].

52
CRYPTOGRAPHIC PRELIMINARIES
• q is generated at random from the set of all primes of binary size k, using
a primality test. The number p is the ﬁrst prime in the sequence aq + 1,
for successive (even) integer values a, starting from a ﬁxed positive inte-
ger a0 that is “hard-wired” into I; heuristic evidence suggests that only
polynomially many values of a need to be tested (see Wagstaff [384]).
It is not known how to test primality in deterministic polynomial time.
A polynomial-time primality test with negligible error probability may
be used instead, though, because its outputs are computationally indistin-
guishable.
• g is generated at random from Gq \ {1}. This can be accomplished by
taking g := f (p−1)/q, for a random f ∈Z
∗
p, and testing that g ̸= 1.
(There is only one subgroup with order q.) Other distributions are not
necessarily improper, but results of Bleichenbacher [34] and Anderson
and Vaudenay [14] for groups of non-prime order suggest that a random
selection is preferred.
• x is best chosen at random from Zq. This maximizes its entropy, and
allows one to prove the hardness of inverting assuming the seemingly
weaker assumption that any polynomial-time algorithm for inverting the
DL function has non-negligible error probability. In particular, either this
choice is successful or the DL-function cannot be one-way at all.
Alternatively, one ﬁrst generates a random prime p and checks whether q =
(p −1)/a0 is a prime, repeating this process until a prime q is found. Another
variation is to generate a random composite with known prime factorization
(see Bach [16]), and to test whether its increment by one is a prime, p; if this is
the case, then with high probability the binary size of the largest prime factor
of p −1 is proportional to |p|. (In this case |q| should be allowed to be linear
in k.)
Primes p of a special form may provide even better protection against attacks.
For instance, it is believed preferable to generate p subject to the restriction
that (p −1)/2q contains only prime factors greater than q. Other reasons for
generating p of a special form are related to security issues of protocols that
operate in Gq; see Section 2.4.3.
In practical applications it is often important that the pair (p, q) do not contain
a trapdoor that enables the rapid computation of discrete logarithms. Although
no trapdoor constructions are known in the public literature that cannot be
feasibly detected (and, therefore, tested for), conﬁdence can be increased by
using an instance generator that generates q and p in a pseudorandom manner,
starting from a seed value that must be output as well by the instance generator;
see Federal Information Processing Standards no. 186 [277, Appendix 2]. In
addition, a succinct proof may be output for proving that g has been generated
using a pseudorandom process.

2.2 ONE-WAY FUNCTIONS
53
(Elliptic curve construction) Gq is an elliptic curve of order q over a ﬁnite ﬁeld.
(See Menezes [263] for an introduction to elliptic curves as applied in cryp-
tography.) It is common to take Zp as the underlying ﬁeld, for a prime p
such that |p| is polynomial in k. The following three instance generators are
believed to be invulnerable:
• Select a (probable) prime p, and randomly try elliptic curve coefﬁcients
until a curve of prime order is found. (The process could be sped up by
allowing |q| to be linear in k.) The elliptic curve coefﬁcients must be
speciﬁed as part of the output of the instance generator. Generate g and
x at random from Gq \ {1} and Zq, respectively.
• Alternatively, the coefﬁcients determining the elliptic curve are hard-
wired into the instance generator, and p and q of the appropriate form
are sought by trial and error. The numbers g and x are generated at ran-
dom from Gq \ {1} and Zq, respectively.
• Another possibility is to generate an elliptic curve of prime order together
with a generator g, using an algorithm of Koblitz [234]. As before, x is
best chosen at random from Zq.
Alternatively, one can generate elliptic curves over a ﬁeld of the form GF2m
instead of over Zp; as we will see shortly, this offers practical advantages.
Any uncertainty about the presence of a trapdoor can be removed in the manner
described for the subgroup construction.
Other constructions have been proposed, but these are considerably more difﬁcult to
understand and have not been scrutinized by more than a few experts. See Biehl,
Meyer, and Thiel [28] and the references therein for constructions in real-quadratic
number ﬁelds, and Koblitz [233] for a construction in groups obtained from Jacobians
of hyperelliptic curves.
The prime q need not be generated at random, if only the underlying ﬁeld is
chosen in a substantially random manner. A smart choice for q enables one to speed
up the reduction modulo q. Example choices for q are 2127 −1 (a Mersenne prime)
or, more generally, 2a ± b, for small b. Furthermore, in some applications it may be
useful to use the same q in combination with multiple primes pi, all chosen at random
subject to the condition q | (pi −1).
With the exception of the technique described in Section 4.4.1, none of the con-
structions in this book depend on the manner in which Gq is constructed. In general,
we merely need the following assumption to be true.
Assumption 2.2.2. There exists a DL function that has an invulnerable instance gen-
erator.
From now on we will use the notation (IDL, DDL) to denote an invulnerable in-
stance generator for “the” DL function. Although speciﬁc embodiments may have

54
CRYPTOGRAPHIC PRELIMINARIES
additional outputs, such as p, elliptic curve coefﬁcients, a compact proof that g has
been generated at random, and information evidencing that no trapdoor has been built
in, for concreteness we will always assume that the output of (IDL, DDL) is (q, g, x).
We will also assume that (q, g) is always properly formed, meaning that q is a prime
and g a generator of Gq, but will never make any assumptions about the probability
distribution of the outputs of (IDL, DDL).
The one-wayness of a function is an asymptotic property. For overviews of al-
gorithms to compute discrete logarithms, see Odlyzko [281] and McCurley [259].
In practice, the binary size of the parameters must be selected such that adequate
security for the application at hand is offered. For instance, the parameter sizes for
a digital signature that is to have legal meaning several decades from now must be
much greater than for an identiﬁcation protocol that only seeks to withstand replay
attacks. Currently recommended parameter sizes for the DL function are as follows:
(Subgroup construction) To compute discrete logarithms in Gq, one can either
work in Gq or proceed indirectly9 by computing discrete logarithms with re-
spect to generators of Z
∗
p.
The best known algorithms for computing discrete logarithms in Z
∗
p all have
subexponential running time. In May 1998, Joux and Lercier computed a dis-
crete logarithm modulo a 299-bit prime using a network of Pentium PRO 180
MHz personal computers and a total of 4 months of CPU time. Odlyzko [282]
states that primes p should be at least 1024 bits even for moderate security,
and at least 2048 bits for anything that should remain secure for a decade.10
This recommendation is based on the presumption that future progress in algo-
rithmic and hardware capabilities will be along the lines witnessed in the past.
According to Silverman [353], it has been estimated that for large k, breaking
a discrete logarithm of k −30 bits takes about the same time as factoring a k-
bit composite that is the product of two random primes of approximately equal
binary size, but Odlyzko [283] recommends to ignore this difference when
choosing parameter sizes.
In Gq itself, only exponential-time algorithms are known, with running time
O(√q). Shoup [352] proved in his so-called generic string encoding model
that algorithms with a better performance than O(√q) operations must make
use of the structure of Gq, suggesting that a universal subexponential-time
inverting algorithm that works for any construction of Gq cannot exist. As-
suming that the best algorithms for computing discrete logarithms in Gq have
running time O(√q), a 160-bit prime q offers the same security level as a 1024-
bit p; see Menezes [264]. Odlyzko [282] recommends primes q of 200 bits for
9With (p −1)/q polynomial in k, the infeasibility of computing discrete logarithms in Gq follows
from that in Z
∗
p.
10This overturns an earlier recommendation of Odlyzko [283] to use 1024-bit primes for long-term
security (i.e., at least the next two decades) and 768-bit primes for medium-term security.

2.2 ONE-WAY FUNCTIONS
55
long-term security. Lenstra and Verheul [247] are more optimistic; for security
until the year 2020 they recommend using primes p of at least 1881 bits and
primes q of at least 151 bits.
(Elliptic curve construction) As with the subgroup construction, the fastest meth-
ods known for computing discrete logarithms in Gq require O(√q) steps.
When so-called supersingular curves are used, one can invert the DL func-
tion indirectly (by computing discrete logarithms in the underlying ﬁeld Zpor
an extension of it) in subexponential time, and the binary size of p must be
comparable to that in the subgroup construction; see Menezes, Vanstone, and
Okamoto [265]. A linear-time algorithm for so-called trace-1 elliptic curves
was announced in September 1997 independently by Smart [357] and by Satoh
and Araki [335]. Both cases occur with negligible probability for randomly
chosen curves, and can easily be detected. For randomly generated curves
only exponential-time algorithms are known, taking O(√p) steps. Barring
algorithmic breakthroughs, numbers in the base and numbers in the ring of ex-
ponents can therefore be taken of the same binary size; this is a huge efﬁciency
improvement over the subgroup construction.
In May 1998, a Certicom elliptic curve challenge over a ﬁeld Zp with a 97-bit
prime p was solved after 53 days of distributed computation using more than
1200 computers from at least 16 countries. In a whitepaper [85], Certicom
estimates that a 160-bit prime p offers the same security as factoring a 1024-
bit composite, and that a 210-bit prime p compares with factoring a 2048-bit
composite. More recently, Lenstra and Verheul [247] estimated that a 139-
bit p and a 1024-bit composite or a 160-bit p and a 1375-bit composite offer
computationally equivalent security. They estimate that, for security until the
year 2020, key sizes of at least 161 bits should be used if no cryptanalytic
progress is expected, and at least 188 bits to “obviate any eventualities.”
Assuming again that subexponential-time inverting algorithms do not exist,
working over a ﬁeld of the form GF2m offers signiﬁcant advantages. VLSI cir-
cuits have been designed that can rapidly perform operations in these ﬁelds; see
Agnew, Mullin, and Vanstone [6] for a VLSI implementation of GF2155. Even
in general software environments, the use of GF2m offers performance advan-
tages over Zp. Wiener [390] estimates that m should be in the range 171–180
to make computing discrete logarithms as hard as factoring 1024-bit compos-
ites. In his analysis, Wiener assumes the strongest attack known: a parallel
collision search attack using a fully pipelined chip for elliptic curve additions
over GF2m. In April 2000, a team led by Harley, Doligez, de Rauglaudre,
and Leroy broke an elliptic curve challenge for m = 108 after four months
of distributed computation using 9500 computers; the estimated workload for
solving a 163-bit challenge is about 100 million times larger.

56
CRYPTOGRAPHIC PRELIMINARIES
The belief in the strength of short moduli for the elliptic curve construction is not
ubiquitous. Odlyzko [282] warns that “it might be prudent to build in a considerable
safety margin against unexpected attacks, and use key sizes of at least 300 bits, even
for moderate security needs.” Several renowned cryptographers have even expressed
disbelief that the complexity of the discrete logarithm problem for elliptic curves is
more than subexponential.
2.2.3
The RSA function
The output of an instance generator (I, D) for the RSA function, deﬁned below, sat-
isﬁes the following format:
• On input 1k, with k ≥4 and k even, algorithm I generates a pair (n, v),
satisfying the following properties:
– n is the product of binary size k of two primes, p and q.
– v is a number smaller than n that is co-prime to ϕ(n), where ϕ(·) is
Euler’s phi-function.
• On input (n, v), algorithm D generates an element x in Z
∗
n.
The RSA function is a collection of functions, {fi(·)}i∈{n,v}, deﬁned as follows:
fn,v : x →xv.
Under what conditions is the RSA function one-way? Clearly, the RSA function can
be evaluated efﬁciently, using repeated squaring or addition chain techniques. Note
that the exponent is ﬁxed instead of the base number; this makes repeated squaring
less and addition chains more attractive than in the case of the DL function. The
following instance generator is believed to be invulnerable:
• p and q are chosen at random11 from the set of primes of binary size k/2, using
a (probabilistic) primality test. In case p and q are generated after v has been
determined, a test for gcd(ϕ(n), v) = 1 can be used to decide whether to keep
(p, q) or to repeat the experiment.
• v can be chosen in an almost arbitrary fashion, including an invariant choice
hard-wired into I. Certain choices must be avoided, such as (n, v) such that
v−1 mod ϕ(n) < n0.292 (see Wiener [389] and Boneh and Durfee [36]), but
bad choices are believed to be detectable and so they can be easily avoided.
In fact, they should occur with negligible probability if v and n are generated
independently at random.
11Rivest and Silverman [326] argue that for practical purposes using random primes is as secure as
using primes of a special form.

2.2 ONE-WAY FUNCTIONS
57
• x is best chosen at random from Z
∗
n, for the same reasons as with the DL
function. In particular, either this choice is successful or the RSA function
cannot be one-way at all.
Other methods for generating (n, v) have been proposed, all differing in the distri-
bution according to which p and q are generated; see, for example, Boneh [37] and
Kaliski and Robshaw [225].
Although v may be an arbitrary small constant or a composite, in the rest of this
book we are interested only in primes v that are superpolynomial in k. The reasons
for this will become apparent in Section 2.4.4 and in the next two chapters.
Assumption 2.2.3. There exists an invulnerable instance generator for the RSA func-
tion that outputs primes v that are superpolynomial in k.
Boneh and Venkatesan [40] proved that breaking RSA with small v cannot be
equivalent to factoring n under algebraic reductions unless factoring is easy, but their
result does not apply to superpolynomialv. Consequently, it may well be the case that
there exists an invulnerable instance generator such that inverting the RSA function
is as hard as factoring.
From now on we use the notation (IRSA, DRSA) to denote an invulnerable instance
generator for the RSA function that outputs primes v superpolynomial in k. Its output
is (n, v, x), and we will always assume that (n, v) is always properly formed, mean-
ing that v is a prime that is co-prime to ϕ(n). In practice, additional outputs may
be speciﬁed, such as a succinct proof demonstrating that (n, v) is properly formed.
(In the applications in this book, the proof that v is co-prime to ϕ(n) will always be
implicitly given by the party that generates v, as a side consequence of its protocol
executions; see Section 4.2.3.) Moreover, in Sections 4.2.2 and 4.4.2 we will con-
struct protocols on the basis of an invulnerable instance generator that provides the
prime factorization of n as “side information.” We will never make any assumptions
about the probability distribution of the outputs of (IRSA, DRSA).
The fastest known algorithms for inverting the RSA function all proceed by fac-
toring n; for an overview, see Bressoud [61]. They have subexponential running time
and have been used successfully to factor composites of up to 512 bits.12 Shamir’s
TWINKLE device [345] brings 512-bit moduli within reach of a single device. Ac-
cording to Odlyzko [282], “even with current algorithms, within a few years it will
be possible for covert efforts (involving just a few people at a single institution, and
thus not easily monitored) to crack 768 bit RSA moduli in a year or so.” Lenstra and
Shamir [246] estimate that it would take 5000 TWINKLE devices connected by a
fast network to 80 000 standard Pentium II computers in order to factorize a 768 bit
composite within 6 months. Odlyzko [282] projects that “even 1024 bit RSA moduli
12RSA-155, which has 512 bits and is the product of two 78-digit primes, was factored in August 1999
using the Number Field Sieve algorithm. The effort used the equivalent of roughly 8000 mips years, and
involved 292 desktop computers and a Cray C916 supercomputer. See Cavallar et al. [77] for details.

58
CRYPTOGRAPHIC PRELIMINARIES
might be insecure for anything but short-term protection.” Lenstra and Verheul [247]
recommend using RSA moduli of at least 1881 bits for security until the year 2020,
and Odlyzko [282] recommends to use at least 2048-bit moduli. Silverman [353],
however, argues that these estimates are highly unrealistic on the grounds that taking
the total number of computing cycles on the Internet as a model of available com-
puting power ignores memory and accessibility problems. In particular, he strongly
disagrees with the conclusion of Lenstra and Verheul [247] that 1024 bit moduli are
insecure after 2002, and estimates that 1024 bit moduli will remain secure for at least
20 years and 768 bit moduli for perhaps another 10 years.
The requirement that v be superpolynomial can be met in practice by taking the
binary size of v similar to that of q in the DL function; at least 160 bits is recom-
mended, and 200 bits is preferable. As in the case of q, v need not be chosen at
random. In particular, a smart choice for v enables a faster reduction modulo v.
2.3
Collision-intractable functions
2.3.1
Deﬁnition
In practical applications, it is often required of a function that it be infeasible to
compute two arguments that are mapped to the same outcome. Formally:
Deﬁnition 2.3.1. A collection of functions, {fi(·)}i∈V , is collision-intractable over
an instance generator (I, D) if and only if the following two properties hold:
1. (Computable in one direction) There exists a deterministic polynomial-time
algorithm that, on input any (i, x) ∈V × Di, outputs fi(x); and
2. (Collision-intractable in the other direction) For any polynomial-time algo-
rithm A, the probability function deﬁned by
Pk

A(i) = (x, y) such that x, y ∈Di, x ̸= y, fi(x) = fi(y) | i := I(1k)

is negligible in k.
Note that the coin ﬂips of algorithm D are irrelevant. We may therefore say that
the function is collision-intractable over I.
For many-to-one functions, collision-intractability is non-trivial and is a stronger
property than one-wayness. Note that functions with superpolynomial range are al-
ways collision-intractable when idealized in the random oracle model.
A non-trivial collision-intractable function f(·) can serve as a commitment func-
tion that is unconditionally secure for the sender and computationally secure for the
receiver. The straightforward implementation whereby the sender commits to x by
sending fi(x) is unsatisfactory, though: the distribution of x in general will dif-
fer from the distribution for which one-wayness is guaranteed, and even if it is the

2.3 COLLISION-INTRACTABLE FUNCTIONS
59
same there is no guarantee that no partial information leaks. This problem can be
ﬁxed by using a function f(·) with special uniformity properties. (We omit a for-
mal deﬁnition, because it is irrelevant for the purposes of this book.) The candidate
collision-intractable functions that will be introduced in the next two sections meet
these properties and are at the heart of all the constructions in the remainder of this
book.
2.3.2
The DLREP function
We refer to the collection of functions considered in this section as the DLREP func-
tion. The output of an instance generator (I, D) for the DLREP function satisﬁes the
following format:
• On input 1k, with k ≥2, algorithm I generates a tuple
(q, g1, . . . , gl)
satisfying the following properties:
– q is a prime number of binary size k that uniquely speciﬁes a group Gq
of order q.
– g1, . . . , gl are elements of Gq, for an integer l ≥1, and gl ̸= 1. The
integer l can be hard-wired into I, but may also be determined by I itself,
depending on its input; in the latter case l may be polynomial in k. (Since
l can be inferred from the output of (I, D), it is not made explicit in I’s
output.)
• On input (q, g1, . . . , gl), algorithm D generates a tuple
(x1, . . . , xl),
with x1, . . . , xl ∈Zq.
A DLREP function is a collection of functions, {fi(·)}i∈{q,g1,...,gl}, deﬁned as fol-
lows:
fq,g1,...,gl : (x1, . . . , xl) →
l
i=1
gxi
i ,
with domain (Zq)l. The tuple (x1, . . . , xl) is called a DL-representation of h :=
l
i=1 gxi
i
with respect to (g1, . . . , gl). The tuple (0, . . . , 0) is a DL-representation of
1 with respect to any tuple (g1, . . . , gl); we call this the trivial DL-representation. We
simply call (x1, . . . , xl) a DL-representation of h in case (g1, . . . , gl) is clear from
the context. Note that we do not require the gi’s to be generators, in contrast to g in
the DL function, nor do we require the gi’s to be different from one another.

60
CRYPTOGRAPHIC PRELIMINARIES
The DLREP function is a generalization of the DL function. As with the DL
function, different constructions for Gq give rise to different DLREP functions. The
following construction is of special importance to our later constructions in this book.
Construction 2.3.2. Given an invulnerable instance generator (IDL, DDL) for the DL
function, construct an instance generator (IDLREP, DDLREP) for the DLREP function as
follows:
• On input 1k, with k ≥2, IDLREP calls IDL, on input 1k, to obtain a pair (q, g).
IDLREP generates l −1 exponents, y1, . . . , yl−1, at random from Zq, and com-
putes gi = gyi, for all i ∈{1, . . . , l −1}. IDLREP sets gl := g, and outputs
q, (g1, . . . , gl). (Alternatively, if the construction of Gq is such that it is easy to
generate random elements from Gq without knowing an element in Gq, IDLREP
may generate random g1, . . . , gl−1 directly.)
• DDLREP generates xl at random from Zq. The other elements, x1, . . . , xl−1, may
all be generated in an arbitrary manner.
Proposition 2.3.3. If (IDL, DDL) is invulnerable, then the DLREP function is one-way
and collision-intractable over (IDLREP, DDLREP).
Proof. The DLREP function is easy to compute, using l exponentiations and l −1
multiplications. (More efﬁcient methods are discussed shortly.)
The DLREP function is trivially one-way if l = 1. For the case l ≥2, note that
if (x1, . . . , xl) is a DL-representation of h ∈Gq with respect to (g1, . . . , gl), then
x := 	l−1
i=1 xiyi+xl mod q is the discrete logarithm of h with respect to g; therefore,
an efﬁcient algorithm for inverting the DL function can be constructed from one for
inverting the DLREP function.
Collision-intractability is vacuously true for the case l = 1. Consider now the
case l ≥2. If (x1, . . . , xl) and (y1, . . . , yl) are any two different DL-representations
of the same number, then (x1 −y1 mod q, . . . , xl −yl mod q) is a non-trivial DL-
representation of 1. Consequently, if we can ﬁnd collisions then we can ﬁnd a non-
trivial DL-representation of 1, at virtually no overhead. We may therefore assume
that we are given an algorithm B that, on input (q, (g1, . . . , gl)) generated by IDLREP,
outputs a non-trivial DL-representation of 1 in at most t steps, with success probabil-
ity ϵ. We construct an algorithm A that, on input ((q, g), h), computes logg h mod q,
as follows:
Step 1. A generates 2l −2 random numbers, r1, . . . , rl−1, s1, . . . , sl−1 ∈Zq. A
sets
gi := hrigsi
∀i ∈{1, . . . , l −1},
and gl := g. A then feeds (q, (g1, . . . , gl)) to B.
Step 2. A receives (x1, . . . , xl) from B, and checks whether or not it is a non-trivial
DL-representation of 1. If it is not, then A halts.

2.3 COLLISION-INTRACTABLE FUNCTIONS
61
Step 3. If 	l−1
i=1 rixi = 0 mod q, then A halts.
Step 4. A computes
−(
l−1

i=1
sixi + xl)(
l−1

i=1
rixi)−1 mod q,
and outputs the result.
It is easy to verify that the output in Step 4 is equal to logg h mod q, and that the total
running time is O(l k) plus the running time of B. We now determine the success
probability of A.
Because the joint distribution of (g1, . . . , gl), generated in Step 1, is the same
as that induced by the output of IDLREP, the transition from Step 2 to Step 3 occurs
with probability ϵ. To determine the probability that the transition from Step 3 to
Step 4 takes place, we observe that there exists an integer j ∈{1, . . . , l −1} such
that xj ̸= 0 mod q (because B’s output is non-trivial). Therefore, there are exactly
ql−2 “bad” tuples (r1, . . . , rl−1) ∈(Zq)l−1, for which 	l−1
i=1 rixi = 0 mod q: for
any choice of (r1, . . . , rj−1, rj+1, . . . , rl−1), the remaining number, rj, exists and is
uniquely determined because q is a prime. The tuple (r1, . . . , rl−1) is unconditionally
hidden from B, owing to the randomness of the si’s and the fact that g is a generator
of Gq, and it is therefore independent of B’s output. Any choice of (r1, . . . , rl−1) is
equally likely to have been made by A, and so the probability of having chosen a bad
tuple is ql−2/ql−1 = 1/q.
Because Step 4 takes place only if Step 3 is successful, and Step 3 takes place
only if Step 2 is successful, the overall success probability of A is ϵ(1 −1/q).
The proof reduction is optimally tight. Because the inﬂuence of l on the running time
overhead is merely linear in the security parameter, using the parameter sizes recom-
mended for the DL function to implement the DLREP function results in roughly
the same security level. In particular, a prime q of 200 bits should offer long-term
protection against collision-ﬁnding attempts.
Note that Proposition 2.3.3 also applies if gl is generated at random; Construc-
tion 2.3.2 is simply more general.
The number xl need not be generated at random. Construction 2.3.2, however,
is all we need for our purposes in this book. From now on, (IDLREP, DDLREP) always
denotes an invulnerable instance generator that has been constructed from an invul-
nerable instance generator (IDL, DDL) for the DL function in the manner of Construc-
tion 2.3.2. Of course, it is permitted to use any instance generator with a distribution
that is indistinguishable from that generated by (IDLREP, DDLREP).
The constructed DLREP function can be used by a sender to commit to l −1
attributes, (x1, . . . , xl−1). As we will show in Chapter 3, this commitment function
has a special property: the sender can gradually open its commitment to an inﬁnitely

62
CRYPTOGRAPHIC PRELIMINARIES
powerful receiver, and in intermediate stages demonstrate all sorts of properties about
the attributes without leaking additional information about them.
The method described in the proof of Proposition 2.3.3 for computing the DLREP
function is polynomial-time, but is not very practical for large l in case (some of) the
xi’s are large or randomly chosen. For l ≥2, one can evaluate l
i=1 gxi
i
much more
efﬁciently by using simultaneous repeated squaring with a single precomputed table
whose 2l −1 entries consist of the products of the numbers in the non-empty subsets
of {g1, . . . , gl}. See Knuth [232, Exercises 27 and 39 of Section 4.6.3].
Several variations and optimizations of this basic technique exist. For example,
one can process t > 1 exponent bits at once; the size of the precomputed table then
increases by a factor close to 2(t−1)l, while the number of multiplications decreases
by a factor of t and the number of squarings remains unaffected. For large l one can
break up the computation into a number of blocks: with 1 < j ≤l, the product
l
i=1 gxi
i
can be computed using d = ⌈l/j⌉precomputed tables, using simultane-
ous repeated squaring for each of the d subproducts and multiplying the subproduct
results.
Alternatively, one can apply vector addition chain techniques; see, for instance,
Coster [121].
2.3.3
The RSAREP function
We refer to the collection of functions considered in this section as the RSAREP func-
tion. The output of an instance generator (I, D) for the RSAREP function satisﬁes
the following format:
• On input 1k, with k ≥4 and k even, algorithm I generates a tuple
(n, v, g1, . . . , gl)
satisfying the following properties:
– n is the product of binary size k of two primes, p and q.
– v is a prime smaller than n that is co-prime to ϕ(n).
– g1, . . . , gl are elements of Z
∗
n, for an integer l ≥0. The integer l can be
hard-wired into I but may also be determined by I itself, depending on
its inputs; in the latter case l may be polynomial in k.
• On input (n, v, g1, . . . , gl), algorithm D generates a tuple
(x1, . . . , xl+1),
with x1, . . . , xl ∈Zv and xl+1 ∈Z
∗
n.

2.3 COLLISION-INTRACTABLE FUNCTIONS
63
The RSAREP function is a collection of functions, {fi(·)}i∈{n,v,g1,...,gl}, deﬁned as
follows:
fn,v,g1,...,gl : (x1, . . . , xl, xl+1) →
l
i=1
gxi
i xv
l+1,
with domain (Zv)l × Z
∗
n. The tuple (x1, . . . , xl, xl+1) is an RSA-representation of
h := l
i=1 gxi
i xv
l+1 with respect to (g1, . . . , gl, v). The tuple (0, . . . , 0, 1) is an RSA-
representation of 1 with respect to any tuple (g1, . . . , gl, v); we call this the trivial
RSA-representation. We simply call (x1, . . . , xl, xl+1) an RSA-representation of h
in case (g1, . . . , gl, v) is clear from the context. Note that we do not require the gi’s
to be different or to have large order.
While a tuple (y1, . . . , yl, yl+1) ∈Z
l × Z
∗
n satisfying
h =
l
i=1
gyi
i yv
l+1
is not an RSA-representation in case one of y1, . . . , yl is not in Zv, it is easy to check
that the normalized form
(y1 mod v, . . . , yl mod v,
l
i=1
gyidivv
i
yl+1)
is an RSA-representation of h. In practice, it may sometimes be more efﬁcient to
use (y1, . . . , yl, yl+1) directly in a computation, instead of ﬁrst normalizing it; this
avoids one multi-exponentiation. On the other hand, normalization is desirable for
the purpose of implementing simultaneous repeated squaring or related techniques.
The following construction is of special importance to our later constructions in
this book.
Construction 2.3.4. Given an invulnerable instance generator (IRSA, DRSA) for the
RSA function, construct an instance generator (IRSAREP, DRSAREP) for the RSAREP func-
tion as follows:
• On input 1k, with k ≥4 and k even, IRSAREP calls IRSA, on input 1k, to obtain
a pair (n, v). IRSAREP generates l random numbers, g1, . . . , gl, from Z
∗
n, and
outputs n, v, (g1, . . . , gl).
• DRSAREP generates xl+1 at random from Z
∗
n. The other elements, x1, . . . , xl,
may all be generated from Zv in an arbitrary manner.
Proposition 2.3.5. If (IRSA, DRSA) is invulnerable, then the RSAREP function is one-
way and collision-intractable over (IRSAREP, DRSAREP).

64
CRYPTOGRAPHIC PRELIMINARIES
Proof. The RSAREP function is easy to compute, using l + 1 exponentiations and
l multiplications. (For practicality, one can apply the techniques mentioned in Sec-
tion 2.3.2 to l
i=1 gxi
i , and multiply xv
l+1 into the result.)
The RSAREP function is trivially one-way if l = 0. For the case l ≥1, note that
from an RSA-representation of h ∈Z
∗
n with respect to (g1, . . . , gl, v) it is easy to
compute the v-th root of h, assuming one knows the v-th root of each gi; from this
observation it is easy to see how an efﬁcient inverting algorithm for the RSA function
can be constructed from one from the RSAREP function.
Collision-intractability is vacuously true for the case l = 0. Consider now the
case l ≥1. If (x1, . . . , xl, xl+1) and (y1, . . . , yl, yl+1) are any two different RSA-
representations of the same number, then
(x1 −y1 mod v, . . . , xl −yl mod v,
l
i=1
g(xi−yi)divv
i
xl+1y−1
l+1)
is a non-trivial RSA-representation of 1. Consequently, if we can ﬁnd collisions
then we can ﬁnd a non-trivial RSA-representation of 1, at modest cost. We may
therefore assume that we are given an algorithm B that, on input (n, v, (g1, . . . , gl))
generated by IRSAREP, outputs a non-trivial RSA-representation of 1 in at most t steps,
with success probability ϵ. We construct an algorithm A that, on input ((n, v), h),
computes h1/v, as follows:
Step 1. A generates l random numbers, r1, . . . , rl ∈Zv, and l random numbers,
s1, . . . , sl ∈Z
∗
n. A sets
gi := hrisv
i
∀i ∈{1, . . ., l},
and feeds (n, v, (g1, . . . , gl)) to B.
Step 2. A receives (x1, . . . , xl, xl+1) from B, and checks whether or not it is a non-
trivial RSA-representation of 1. If it is not, then A halts.
Step 3. If 	l
i=1 rixi = 0 mod v, then A halts.
Step 4. Using the extended Euclidean algorithm, A computes integers e, f ∈Z
satisfying
e (
l

i=1
rixi) + fv = 1.
A then computes
hf(xl+1
l
i=1
sxi
i )−e,
and outputs the result.

2.3 COLLISION-INTRACTABLE FUNCTIONS
65
It is easy to verify that the output in Step 4 is equal to h1/v, and that the total running
time is O(l|v|) plus the running time of B. We now determine the success probability
of A.
Because the joint distribution of (g1, . . . , gl), generated in Step 1, is the same
as that of the output of IRSAREP, the transition from Step 2 to Step 3 occurs with
probability ϵ. To determine the probability that the transition from Step 3 to Step
4 takes place, we observe that there exists an integer j ≤l such that xj ̸= 0 mod v
(because B’s output is non-trivial).
Therefore, there are exactly vl−1 “bad” tu-
ples (r1, . . . , rl) ∈(Zv)l, for which 	l
i=1 rixi = 0 mod v: for any choice of
(r1, . . . , rj−1, rj+1, . . . , rl), the remaining number, rj, exists and is uniquely de-
termined because v is a prime. The tuple (r1, . . . , rl) is unconditionally hidden from
B, owing to the randomness of the si’s and the fact that v is co-prime to ϕ(n), and
it is therefore independent of B’s output. Any choice of (r1, . . . , rl) is equally likely
to have been made by A, and so the probability of having chosen a bad tuple is
vl−1/vl = 1/v.
Because Step 4 takes place only if Step 3 is successful, and Step 3 takes place
only if Step 2 is successful, the overall success probability of A is ϵ(1 −1/v).
The proof reduction is optimally tight, and so using the parameter sizes recommended
for the RSA function to implement the RSAREP function results in roughly the same
security level. In particular, taking a 2048-bit n and 200-bit v should sufﬁce for
long-term security.
As in the case of the DLREP function, Construction 2.3.4 is not the only one
for which Proposition 2.3.5 can be proved, but it sufﬁces for our purposes in this
book. From now on, (IRSAREP, DRSAREP) always denotes an invulnerable instance gen-
erator constructed from an invulnerable instance generator (IRSA, DRSA) for the RSA
function in the manner of Construction 2.3.4. Of course, it is permitted to use any
instance generator with a distribution that is indistinguishable from that generated by
(IRSAREP, DRSAREP).
The constructed RSAREP function can be used by a sender to commit to l at-
tributes, (x1, . . . , xl). We will show in Chapter 3 how the sender can gradually and
selectively open its commitment to an inﬁnitely powerful receiver, and more gener-
ally can demonstrate all sorts of properties about its attributes without leaking addi-
tional information about them.
2.3.4
Comparison
It is clear that the DLREP function and the RSAREP function have much in common,
and indeed most constructions in this book can be based on either function. There
are some notable differences, though:
• In the RSAREP function the factorization of n can serve as a trapdoor, enabling
the computation of arbitrary RSA-representations for any number in Z
∗
n. The

66
CRYPTOGRAPHIC PRELIMINARIES
DLREP function is not known to have a trapdoor.
• In the RSAREP function, v can be arbitrarily small or be a ﬁxed constant
(hard-wired into the instance generator). It is easy to see that Proposition 2.3.5
remains valid for these choices (but the reduction is no longer optimally tight).
Similar choices do not exist for the DLREP function, because the infeasibility
of collision-ﬁnding is directly related to the binary size of q.
As a result, the RSAREP function offers greater ﬂexibility. As we will see in the next
section, though, a large v is desirable to construct highly practical showing protocols,
and so the second advantage of the RSAREP function is not of interest to us.
For our purposes in this book the DLREP function is usually preferable, for rea-
sons related to practicality:
• The DLREP function can be evaluated faster than the RSAREP function.
• The DL-representation takes less storage space than the RSA-representation
for the same security level, assuming that exponents are smaller than numbers
in the base.
• Assuming the elliptic curve construction for Gq resists subexponential-time
inverting algorithms, storage of numbers in Gq requires signiﬁcantly less space
than storage of numbers in Z
∗
n for the same security level, and computations
involving base numbers are much faster.
Moreover, as we will see in the next section, the real-time operations needed to
prove knowledge of a DL-representation are much fewer than in the case of an RSA-
representation, because all exponentiations can be precomputed.
2.4
Proofs of knowledge
2.4.1
Deﬁnition
With (i, x) denoting the output of an instance generator for a function {fi(·)}i∈V ,
and with i understood, fi(x) may be called a public key and x a secret key (or witness)
corresponding to the public key. A key pair consists of a secret key and a public key.
The outputs of algorithm I form the system parameters, and the process of running
D and forming the public key is referred to as the key set-up.13
The public key uniquely corresponds to the secret key, but unless fi(·) is a per-
mutation there may be many secret keys corresponding to each public key. On input
i and the public key, it is infeasible to compute a corresponding secret key if and
13This deﬁnition in terms of collections of one-way functions is not standard, but makes sense in our
situation as well as in most other cases that consider only polynomially bounded key holders.

2.4 PROOFS OF KNOWLEDGE
67
only if the function is one-way over (I, D). Moreover, if the function is collision-
intractable over (I, D), no party that is given i can feasibly generate a public key for
which it knows two corresponding secret keys.
We now come to the notion of a proof of knowledge, originating from Gold-
wasser, Micali, and Rackoff [193]. Informally, this is a protocol by means of which
one party can convince another that it “knows” a secret key corresponding to its pub-
lic key.
Deﬁnition 2.4.1. A proof of knowledge (P, V) for a function {fi(·)}i∈V is a proto-
col performed by a pair of interactive polynomial-time algorithms. P is called the
prover and V is called the veriﬁer. The protocol (P, V) must satisfy the following
two properties:
• (Completeness) For all k, for all (i, x) ∈V × Di,
Pk

VP(x)(i, fi(x)) accepts

= 1.
The probability is taken over the coin ﬂips (if any) of V and P.
• (Soundness) There exists an expected polynomial-time algorithm K, called a
knowledge extractor, such that for all P, for all constants c > 0, for all (i, x) ∈
V × Di with |i| sufﬁciently large, and for all auxiliary inputs aux,
 Pk

V P(aux)(i, fi(x)) accepts

−Pk

fi(K((i, fi(x)), aux; P)) = fi(x)
 
is smaller than 1/kc.
Loosely speaking, the two properties state that the prover can convince the veri-
ﬁer if and only if the prover knows a secret key corresponding to its public key.14
The simplest proof of knowledge is one in which P sends x to V, whereupon V
checks its correspondence to the public key by applying fi(·). For our purposes in
this book, however, P should not reveal its secret key. protocol.
2.4.2
Security for the prover
Soundness is a formalization of security for V. Many ﬂavors of security for P have
been studied in the literature. We now examine the four most useful ones.
14Deﬁnition 2.4.1 originates from Feige and Shamir [169]. Bellare and Goldreich [22] provided a more
general deﬁnition of proof of knowledge that takes into account provers that have superpolynomial com-
puting power. We do not consider this alternative deﬁnition here, since it is considerably more complex
and the presented one is adequate for our purposes.

68
CRYPTOGRAPHIC PRELIMINARIES
Deﬁnition 2.4.2. A proof of knowledge (P, V) for f(·) is computationally zero-
knowledge if there exists an expected polynomial-time algorithm S, called a sim-
ulator, such that for all V and for all auxiliary inputs aux, the two ensembles

VP(x)((i, fi(x)); aux)

(i,x)∈V ×Di
and

S((i, fi(x)), aux; V)

(i,x)∈V ×Di
are computationally indistinguishable.
Equivalently, the views of V in protocol executions with P can be simulated with
indistinguishable probability distribution.
In a similar manner one can deﬁne statistical and perfect zero-knowledge; in these
cases the simulator must be able to output protocol transcripts that are statistically
indistinguishable from, or identically distributed to, the protocol transcripts that a
veriﬁer with unlimited computing power sees when interacting with P. Statistical
and perfect zero-knowledge are meaningful notions in case fi(·) is not a permutation;
even though V can compute all secret keys corresponding to P’s public key, it cannot
ﬁnd out more about which one is known to P than what is known in advance.
It is possible to construct protocols that are zero-knowledge when protocol exe-
cutions are performed sequentially, but that leak the secret key of the prover in case
attackers are able to engage in parallel executions of the protocol; see Feige and
Shamir [169] for an example.
The zero-knowledge property states that a misbehaving V (with either polynomial
or unlimited computing power, depending on the ﬂavor) cannot learn any information
beyond what it can infer from merely the system parameters and P’s public key. A
weaker notion, which will be very useful in Chapter 3 to prove the unforgeability of
digital signature schemes in the random oracle model, is the following.
Deﬁnition 2.4.3. A proof of knowledge (P, V) for a function f(·) is (computation-
ally, statistically, perfectly) honest-veriﬁer zero-knowledge if there exists an expected
polynomial-time simulator S such that the two ensembles

VP(x)((i, fi(x)))

(i,x)∈V ×Di
and

S((i, fi(x)); V)

(i,x)∈V ×Di
are (computationally, statistically, perfectly) indistinguishable.
The following notion (due to Feige and Shamir [169]) is also weaker than zero-
knowledge, but in many applications it is at least as useful.
Deﬁnition 2.4.4. A proof of knowledge (P, V) for a function f(·) is statistically
witness-indistinguishable if, for any x1, x2 ∈Di such that fi(x1) = fi(x2), and
for any auxiliary input aux to V, the two ensembles deﬁned by
VP(x1)((i, fi(x1)); aux)
and
VP(x2)((i, fi(x2)); aux),
respectively, are statistically indistinguishable.

2.4 PROOFS OF KNOWLEDGE
69
In other words, V cannot learn any information about which particular secret
key is applied by P. In a similar manner one can deﬁne computational and per-
fect witness-indistinguishable proofs of knowledge. More generally, one can deﬁne
witness-indistinguishability for protocols that are not proofs of knowledge.
A proof of knowledge for a permutation is trivially witness-indistinguishable; this
is an uninteresting property because it holds even for protocols in which P transmits
its secret key to V. Later in this section, and more importantly in Chapter 3, we will
introduce witness-indistinguishable proofs of knowledge for many-to-one functions.
The following proposition is due to Feige and Shamir [169].
Proposition 2.4.5. Witness-indistinguishability is preserved under arbitrary compo-
sition of protocols.
This property, which does not hold for zero-knowledge, applies not only to dif-
ferent executions of the same protocol but also to executions of different witness-
indistinguishable protocols.
In contrast to the properties of completeness, soundness, (general and honest-
veriﬁer) zero-knowledge, and witness-indistinguishability, the last notion of security
for P discussed here is deﬁned only over the output distribution of a speciﬁc instance
generator.
Deﬁnition 2.4.6. A proof of knowledge (P, V) for a function f(·) is witness-hiding
over the instance generator (I, D) for f(·) if there exists an expected polynomial-
time algorithm W, called a witness extractor, such that for all veriﬁers V, for all
constants c > 0, for all sufﬁciently large k, and for all auxiliary inputs aux,
 Pk

fi(VP(x)(i, fi(x); aux)) = fi(x) | i := I(1k); x := D(i)

−Pk

fi(W((i, fi(x), aux); V)) = fi(x)
 < 1/kc.
The witness-hiding property states that V, after having engaged in (at most) poly-
nomially many protocol executions with P, cannot compute an entire secret key that
corresponds to P’s public key, unless it already knew or could compute such a se-
cret key before any protocol executions with P were performed. The latter case is
not interesting, and so we will refer to proofs of knowledge over vulnerable instance
generators as being trivial witness-hiding. Note that non-trivial witness-hiding does
not exclude the possibility that V can uniquely determine half of the bits of P’s se-
cret key, say, once it has engaged in sufﬁciently many protocol executions. Due to
the soundness property, however, non-trivial witness-hiding offers adequate security
in most applications of proofs of knowledge.
The following proposition also originates from Feige and Shamir [169].
Proposition 2.4.7. Let (I, D) be an instance generator for a function f(·) such that
the following two properties hold for each y in the range of fi(·):

70
CRYPTOGRAPHIC PRELIMINARIES
• y has at least two preimages in the domain Di of fi(·); and
• conditional on the event that D(i) outputs an element in the preimage set of
y, none of the preimages of y has overwhelming probability of being output by
D(i).
Then the following holds: if (P, V) is a computationally witness-indistinguishable
proof of knowledge for f(·), and f(·) is collision-intractable over (I, D), then (P,
V) is non-trivially witness-hiding over (I, D).
To prove this result, suppose that V outputs a secret key corresponding to P’s
public key, after having engaged in polynomially many protocol executions. Ow-
ing to the witness-indistinguishability property this key differs with non-negligible
probability from the secret key used by P. Therefore, the algorithm < P, V> ﬁnds
collisions for the function with non-negligible success probability.
Note that the key set-up and the process of generating the system parameters do
not enter the deﬁnition of proofs of knowledge. Deﬁnition 2.4.1 simply assumes
correct formation. When designing a system, care must be exercised as to which
party controls algorithms I and D:
• The process of generating the system parameters must be controlled by the
party or parties to whom improperly formed system parameters pose a secu-
rity threat. For example, if V runs I then it may be able to embed trapdoor
information so that it can feasibly compute a secret key corresponding to the
public key of P; whether this is a threat to the security of P depends on the
application at hand. On the other hand, if P runs I, P may be able to deter-
mine system parameters for which it can ﬁnd collisions. Again, whether or not
this is a problem depends on the application at hand; for a situation in which
P should not run I by itself, see Chapter 3.
Any interests of V and P can be met by letting a trusted party run I. Using
cryptographic multi-party computation techniques (see, for instance, Chaum,
Crepeau, and Damg˚ard [89] and Chaum, Damg˚ard, and van de Graaf [106]), it
is possible for V and P to create a “virtual” trusted party to run I. Although
multi-party computation techniques are not practical in general, in all the con-
structions in this book they can be implemented in a practical manner. For
instance, with the RSA-based constructions that we will present there is no
need for the prover to prove that n is the product of two primes of equal size,
and the proof that v is co-prime to ϕ(n) is a by-product of the certiﬁcate is-
suing protocol. More generally, correct formation by one of V and P in our
constructions can always be proved by providing an additional output evidenc-
ing that the process has taken as input a source of randomness substantially
outside of its control.
• Normally the key set-up is performed by P, to make sure that its secret key
does not become known to V. In some applications, V and P should jointly

2.4 PROOFS OF KNOWLEDGE
71
perform this process, by means of an interactive protocol. For example, Chap-
ter 4 addresses the situation where the CA ensures that a part of the secret key
generated for a receiver contains pre-approved attributes, while the receiver
ensures that the CA cannot learn its entire secret key.
We now introduce practical proofs of knowledge for both the DLREP function and
the RSAREP function. These will be central to our constructions of issuing and
showing protocols in the next two chapters.
2.4.3
Proving knowledge of a DL-representation
Consider any instance generator for the DLREP function. P’s public key is h :=
l
i=1 gxi
i . In order to prove knowledge of a DL-representation of h with respect to
(g1, . . . , gl), P and V perform the following protocol steps:
Step 1. P generates at random l numbers w1, . . . , wl ∈Zq. It then sends a :=
l
i=1 gwi
i
to V. The number a is called the initial witness.
Step 2. P computes l responses, responsive to a challenge c ∈Zs of V, where
1 < s ≤q, according to ri := cxi + wi mod q, for i = 1, . . . , l, and sends
them to V. (The role of s and the process of forming c will be discussed
shortly.)
V accepts if and only if the veriﬁcation relation l
i=1 gri
i h−c = a holds.
Note that both a and the left-hand side of the veriﬁcation relation can be rapidly
computed using simultaneous repeated squaring.
A variation is for P in Step 1 to send a one-way hash of a; V must then check
whether this number is equal to the hash of l
i=1 gri
i h−c. Also, if V knows yi :=
logg gi, for some generator g and all i ∈{1, . . ., l}, then the veriﬁcation relation can
be collapsed to
g
	l
i=1 yirih−c = a.
We will not consider these variations any further.
The integer s in Step 2 must be known to both P and V. It may be determinis-
tically related to the system parameters (e.g., a predetermined rounded fraction of q,
or q itself). Alternatively, it may be speciﬁed as part of the process of generating the
system parameters or P may specify it when informing V of its public key.
The challenge c need not be generated at random, nor need it be generated by V.
Nevertheless, we will always refer to it as V’s challenge, because it determines the
security for V.
The protocol description is generic in the sense that the binary size of s and the
process of generating c have yet to be speciﬁed. Also, we have not yet stated any
requirements for the instance generator.

72
CRYPTOGRAPHIC PRELIMINARIES
Proposition 2.4.8. (P, V) is complete and perfectly witness-indistinguishable, re-
gardless of the binary size of s and the process of generating V’s challenge.
Proof. Completeness follows from
l
i=1
gri
i h−c
=
l
i=1
gcxi+wi
i
h−c
=
(
l
i=1
gxi
i )c(
l
i=1
gwi
i )h−c
=
hcah−c
=
a.
To prove witness-indistinguishability, we will show that any view of V could have
resulted from any secret key of P, with equal probability. Suppose P used secret key
(x∗
1, . . . , x∗
l ). In Step 1 it would have sent
a∗:=
l
i=1
gw∗
i
i
to V, and in Step 3 it would have sent responses r∗
i := cx∗
i + w∗
i mod q, for i ∈
{1, . . ., l}. From ri = r∗
i mod q it follows that w∗
i = ri −cx∗
i mod q, for i =
1, . . . , l, and since P’s responses make V accept it follows that
a∗
=
l
i=1
gw∗
i
i
=
l
i=1
gri−cx∗
i
i
=
l
i=1
gri
i (
l
i=1
gx∗
i
i )−c
=
(hca) h−c
=
a.
Since the wi’s are chosen at random from Zq, the view perfectly hides which secret
key has been used, and the claimed result follows.
Soundness and security for P depend on the binary size of s and the process of
generating c. Furthermore, for the property of witness-hiding we need to specify an
instance generator. Assuming that c is chosen at random by V, and becomes known
to P only after P has chosen its initial witness a, the following security implications
hold:

2.4 PROOFS OF KNOWLEDGE
73
(Large s) If s is superpolynomial in k, then the protocol is a proof of knowledge as
is; no repetitions are needed to achieve soundness. It is easy to prove that it
is honest-veriﬁer zero-knowledge: the simulator generates r1, . . . , rl and c at
random, and computes a := l
i=1 gri
i h−c. The following two cases describe
conditions under which (P, V) is witness-hiding over (IDLREP, DDLREP):
• In case V in advance knows (x1, . . . , xl−1) with overwhelming probabil-
ity, but has no a priori information about xl, the protocol is believed to be
witness-hiding over (IDLREP, DDLREP). It is easy to prove that the case of ar-
bitrary l is as secure as the special case l = 1, which is the Schnorr proof
of knowledge [337]. In his generic string encoding model, Shoup [352]
proved that an active attacker in the Schnorr proof of knowledge cannot
learn enough information to be able to subsequently prove knowledge of
P’s secret key by itself. In other words, the Schnorr proof of knowledge
is witness-hiding in the generic string encoding model, a result that can
easily be adapted to the case of arbitrary l.
• In case l ≥2 and V cannot identify (x1, . . . , xl−1) in advance with over-
whelming probability (i.e., V has non-negligible uncertainty about the
tuple), it follows from Propositions 2.3.3, 2.4.7, and 2.4.8 that the proto-
col is provably (non-trivially) witness-hiding over (IDLREP, DDLREP).
In either case, the protocol can be made zero-knowledge by prepending a
fourth move in which V commits to its challenge; the required strength of
the commitment depends on whether or not V is polynomially bounded.15 Al-
ternatively, P and V determine V’s challenge in a mutually random fashion.
(Small s) If s is polynomial in k, then the protocol steps must be repeated polyno-
mially many times in order to result in a sound protocol. (V accepts if and only
if it accepts in each iteration.) Two cases can be discerned:
• Sequential repetitions result in a zero-knowledge proof of knowledge.
• Parallel repetitions do not result in a zero-knowledge proof of knowledge.
They are believed, however, to result in a proof of knowledge that is
witness-hiding over (IDLREP, DDLREP). (This can be proved in case l ≥2
and V initially has non-negligible uncertainty about (x1, . . . , xl−1).) A
zero-knowledge protocol can be obtained by prepending a fourth move
in the manner described for the case of large s.
We will not consider the case of small s any further in this book, because the resulting
protocols are signiﬁcantly less efﬁcient. In later chapters, we will often take s := q.
15As noted by Bellare (personal communication, January 8, 1999), the commitment may not be of the
form gα
i hc, for some i ∈{1, . . . , l} and random α ∈Zq, since this would allow an attacker to always
convince V without knowing a DL-representation of h. A commitment of the form gc
i hα should be ﬁne,
although it is unclear how to prove the soundness property.

74
CRYPTOGRAPHIC PRELIMINARIES
The most practical way to obtain a protocol that is provably witness-hiding is to
set l = 2, to generate x2 at random from Zq, and to set x1 equal to the outcome of
a coin ﬂip (not necessarily unbiased); the resulting three-move protocol (with large
s) is an optimization of Okamoto’s extension [288, page 36] of the Schnorr proof
of knowledge. Taking l > 2 does not improve the provability of the witness-hiding
property and only makes the protocol less efﬁcient; for this reason the situation l > 2
has never been considered in the literature. In Chapter 3, however, we will see that
there are legitimate reasons for resorting to l > 2.
The security results for P hold only assuming that the system parameters are
formed by running IDLREP. Depending on the application at hand, both P and V may
have security interests in seeing to it that the system parameters are formed in this
manner. For example, if P is allowed to generate at least one gi by itself, after V
has formed the remaining ones, P can easily construct colliding secret keys. For our
purposes in Chapter 3 it sufﬁces that V, or a party trusted by V, runs IDLREP. Additional
outputs may be sent to P to prove that random or pseudorandom bits have been used
in the process, and a proof of primality of q may be included.
Furthermore, depending on the application, it may be necessary for P and V to
check membership in Gq of certain numbers:
• If P can get way with a public key h that is not a member of Gq, then a
corresponding secret key does not exist, yet P may be able to make V accept
with non-negligible probability. Burmester [67] pointed out for the Schnorr
proof of knowledge that P can convince V with probability 1/2 by multiplying
in a non-trivial square root of unity; the same attack applies in the general case.
This issue, which applies not only to the subgroup construction but also to the
elliptic curve construction, will also play a role in Chapter 3.
To circumvent the problem, V should check that P’s public key h is a member
of Gq. This one-time check can take place off-line, before the protocol takes
place, and is especially practical in applications in which the same public key is
used in many protocol executions. If Gq is a subgroup of a commutative group
of order o, and q divides o but q2 does not divide o, then the check hq = 1
sufﬁces to verify membership in Gq; see Herstein [210, Corollary on page 62].
It can also be shown that the check hq = 1 sufﬁces to prove membership in
case Gq is not a subgroup of a cyclic group, provided the veriﬁer accepts the
protocol execution; cf. Verheul and Hoyle [382].
In the digital certiﬁcate constructions in Chapters 4, 5, and 6, the problem does
not play a role.
• Lim and Lee [252] showed that, in the subgroup construction for Gq, it may
in general be dangerous for the prover to apply its secret key to base numbers
supplied by the veriﬁer without ﬁrst checking that these are indeed members
of Gq. Two ways around this are the following:

2.4 PROOFS OF KNOWLEDGE
75
– The prover can check membership in Gq of each supplied base number a
to which it is to apply its secret exponent.
– One can use a prime p such that (p −1)/2q contains only prime factors
greater than q. This circumvents the need to perform real-time member-
ship veriﬁcations.
In this book the issue is avoided altogether, because in our protocol construc-
tions the prover never applies its secret key to base numbers supplied by the
other party.
2.4.4
Proving knowledge of an RSA-representation
Consider any instance generator for the RSA function. P’s public key is h :=
l
i=1 gxi
i xv
l+1. In order to prove knowledge of an RSA-representation of h with
respect to (g1, . . . , gl, v), P and V perform the following protocol steps:
Step 1. P generates at random l numbers w1, . . . , wl ∈Zv and a random number
wl+1 ∈Z
∗
n, and sends the initial witness a := l
i=1 gwi
i wv
l+1 to V.
Step 2. P computes l + 1 responses, responsive to a challenge c ∈Zs, where 1 <
s ≤v, as follows:
ri
:=
cxi + wi mod v
∀i ∈{1, . . ., l},
rl+1
:=
l
i=1
g(cxi+wi)divv
i
xc
l+1wl+1
P then sends r1, . . . , rl, rl+1 to V. (The role of s and the process of forming c
will be discussed shortly.)
V accepts if and only if the veriﬁcation relation
l
i=1
gri
i rv
l+1h−c = a
holds.
Note that a, rl+1 and the left-hand side of the veriﬁcation relation can all be com-
puted almost completely using simultaneous repeated squaring with a single precom-
puted table, since (g1, . . . , gl, h) are all ﬁxed; only the v-th powers occurring in these
expressions have to be multiplied separately into the products.
Proposition 2.4.9. (P, V) is complete and perfectly witness-indistinguishable, re-
gardless of the binary size of s and the process of generating V’s challenge.

76
CRYPTOGRAPHIC PRELIMINARIES
Soundness and security for P depend on the binary size of s and the process of
generating c. Furthermore, for the property of witness-hiding we need to specify an
instance generator. In case c is chosen at random by V, and becomes known to P
only after it has chosen its initial witness a, we have similar security implications as
described for the case of the DLREP function. We mention only the following two
cases, both for s superpolynomial in k:
• In case V knows (x1, . . . , xl) with overwhelming probability, but does not
know xl+1, the protocol is believed to be witness-hiding over (IRSAREP, DRSAREP),
even though this has yet to be proved. The special case l = 0 is the Guillou-
Quisquater proof of knowledge [201, 202]. (Recall that v is a prime that is
superpolynomial in k.)
• In case l ≥1 and V initially has non-negligible uncertainty about (x1, . . . , xl),
it follows from Propositions 2.3.5, 2.4.7, and 2.4.9 that the protocol is provably
(non-trivially) witness-hiding over (IRSAREP, DRSAREP).
There is no point in using s > v: if P can respond to c then it can also respond to
c + jv, for any integer j. In later chapters, we will frequently take s := v.
The most practical way to obtain a protocol that is provably witness-hiding is to
set l = 1, to generate x2 at random from Z
∗
n, and to set x1 equal to the outcome of a
coin ﬂip (not necessarily unbiased); the resulting three-move protocol (with large s)
is an optimization of Okamoto’s extension [288, page 39] of the Guillou-Quisquater
proof of knowledge. As in the case of the DLREP function, we will show in Chapter 3
that there are legitimate reasons for resorting to l > 1.
A four-move zero-knowledge proof of knowledge can be obtained by prepending
a move in which V commits to c. One way to form the commitment is by encod-
ing c into the hard-core bits of the commitment function of H˚astad, Schrift, and
Shamir [208]; another is to use the RSAREP function.
As in the case of the proof of knowledge for the DLREP function, the above
security results hold only assuming that the system parameters are indeed formed by
running IRSAREP. Note that v need not be a prime or be co-prime to ϕ(n) to make the
protocol secure, assuming one is willing to restrict the set from which the gi’s and
xl+1 and wl+1 are chosen.16 In light of the goal that will be pursued in Chapter 3,
though, we will only consider the choices for v and n made here.
16For example, the protocol is a witness-hiding proof of knowledge if n is a Blum integer, v = 2, the
gi’s, xl+1, and wl+1 are all quadratic residues, and the protocol moves are repeated polynomially many
times. One can also consider a modiﬁcation similar to that of Feige, Fiat, and Shamir [168], in which n is
a Blum integer and P randomly multiplies ±1 into rl+1 and a. Yet another choice is v = 2t, for t such
that v is superpolynomial in k; although the prover can convince the veriﬁer with success probability 1/2j
if it knows an RSA-representation of the 2j-th power of h for some j, the protocol can be proved secure
against an active impersonator, relative to the factoring assumption (cf. Shoup [351] and Schnorr [338]).

2.5 DIGITAL SIGNATURES
77
2.5
Digital signatures
2.5.1
Deﬁnition
Informally, a digital signature is the electronic analogue of a handwritten signature.
A digital signature on a message can be veriﬁed by anyone without the help of the
signer, by applying the public key of the signer, but only the signer can compute
signatures on valid messages, by applying its secret key. The following deﬁnition
formalizes this.
Deﬁnition 2.5.1. A digital signature scheme consists of a function {fi(·)}i∈V , an
invulnerable instance generator (I, D), two message sets M = {Mi}i∈V and
M∗= {M∗
i }i∈V , a Boolean predicate pred(·) that can be evaluated in polyno-
mial time, and a protocol (P, V) performed by a pair of interactive polynomial-time
algorithms. P is called the signer, V the receiver, and (P, V) the (signature) issuing
protocol. (P, V) must satisfy the following two properties:
• (Signature generation) For all (i, x) ∈V × Di and for all m∗∈M∗
i , if
(m, σ) := VP(x)((i, fi(x)), m∗)
then m ∈Mi and m is a superstring17 of m∗, and the probability function
deﬁned by
Pk

pred(i, fi(x), m, σ) = 1

is overwhelming in k.
The pair (m, σ) is called a signed message, and σ is P’s digital signature on
m.
• (Unforgeability) For any t ≥0, the following holds. The probability (taken
over (I, D) and the coin ﬂips of V and P) that V, after having engaged in up
to t protocol executions with P, outputs at least t + 1 distinct signed messages
(with messages in M) is negligible in k.
The digital signature scheme is said to be unforgeable over (I, D).
Whenever the instance generator is clear from the description of the signature
scheme, we will simply say that the signature scheme is unforgeable.
Note that the capability to obtain two different signatures on the same message
by engaging in a single execution of the protocol with the signer is not considered to
17That is, the binary string m∗can be obtained by pruning bits from the binary string m. For instance,
any m is a superstring of the null string. Further examples are described shortly. Deﬁnition 2.5.1 could
be generalized by considering messages m that have other relations to m∗(e.g., m is a preimage under a
one-way function of m∗), but this is outside of the scope of the book.

78
CRYPTOGRAPHIC PRELIMINARIES
fall under the scope of forgery. This convention is arbitrary, and adopted here merely
for concreteness.
Deﬁnition 2.5.1 is based on the standard deﬁnition of Goldwasser, Micali, and
Rivest [194], but differs in a few respects. The standard deﬁnition is not suitable to
describe blind signature schemes and other schemes with interactive issuing proto-
cols, including those that we will design in Chapter 4. Also, it includes the processes
of generating the system parameters and the key set-up, but not a notion of security
for the signer; this is opposite to the way the deﬁnition of proofs of knowledge is
structured, and does not reﬂect the common basis of both notions. The deﬁnition
given here is adequate for our purposes.18
The role of the auxiliary common input m∗in Deﬁnition 2.5.1 differs depending
on the type of signature scheme:
• In the most widely considered digital signatures in the cryptographic literature,
the signature issuing protocol is non-interactive, M equals M∗, and m∗is
equal to the message m. In this case, the unforgeability property implies that
the receiver cannot obtain a signature on a message that the signer has not seen
and knowingly signed.
• In the case of blind signatures (see Chaum [91, 92, 93, 94, 95, 96, 99, 100]), m∗
is always the empty string and m is generated at random by V. Speciﬁcally, a
blind digital signature scheme is a digital signature scheme with the additional
property that the signed message (m, σ) obtained by V by interacting with P
is statistically independent of P’s view in the protocol execution. (Weaker
ﬂavors are possible. The weakest ﬂavor is that in which P cannot correlate
signed messages to its views of protocol executions.)
• In Section 4.2 we will construct issuing protocols in which the message m
is chopped up into polynomially many message blocks, x1, . . . , xl, α. In this
case, m∗equals the concatenation of x1, . . . , xl; the remaining message block,
α, is generated secretly at random by V.
As with the witness-hiding and zero-knowledge properties for proofs of knowledge,
the unforgeability property for digital signatures depends on a number of factors that
have been described in Section 2.1.4. Speciﬁcally, the resistance of a digital signa-
ture scheme to forgery is inﬂuenced by the maximum number of protocol executions
in which V can engage and by the degree to which the protocol executions can be
interleaved. In addition, unforgeability depends on how, when, and by which party
the message m∗is formed.
18A variation of Deﬁnition 2.5.1 is to move the unforgeability property outside of the deﬁnition (just
like witness-hiding is not a part of the deﬁnition of a proof of knowledge), and instead to complement the
“completeness” property (signature generation) by a “weak soundness” property that states that (P, V)
results in a signed message with probability 1 only if P knows a secret key corresponding to its public key
fi(x). This introduces the problem of deﬁning what it means for a non-interactive algorithm to “know”
information.

2.5 DIGITAL SIGNATURES
79
An attack can proceed in several manners. In a successful key-only attack or
forgery from scratch, V is able to forge signed messages without being given the op-
portunity to interact with P. At the other end of the spectrum is the adaptively chosen
message attack, in which V has the freedom to choose all its contributions (e.g., mes-
sages, blinding factors, challenges) to each execution of the issuing protocol with P
in a manner that may depend on its aggregate view in all the protocol executions up
to that point; V can use P as an oracle, and is limited only by the level of interleaving
of protocol executions that P allows.
A successful forgery may be due to a leakage of P’s secret key x; in this case V
is able to forge P’s signature on any message. Such a total break can be prevented
by using a signature issuing protocol that is non-trivially witness-hiding. V need not
necessarily know P’s secret key, however, to be able to forge a signed message. For
instance, once V has obtained a number of signed messages it may be able to alge-
braically combine these in such a manner that an additional signed message results.
In general, we will need to protect against existential forgery; in this case V is able to
forge one signed message, for a message not necessarily of its own choice or under
its control. The unforgeability property of digital signatures states that existential
forgery is infeasible, even under an adaptively chosen message attack.
2.5.2
From proofs of knowledge to digital signature schemes
We now describe a general construction for converting a proof of knowledge into
a digital signature scheme. Consider hereto a proof of knowledge for a one-way
function f(·) that has the following structure:
Step 1. P generates a randomly distributed initial witness a. It sends a, which may
in general be a vector of numbers, to V.
Step 2. V generates a substantially random challenge, c ∈Zs, with s superpolyno-
mial in the security parameter k. It sends the challenge, which may represent
a concatenation of several challenge numbers, to P.
Step 3. P computes a response, r, as the outcome of a function of its secret key, the
challenge and the coin ﬂips used to construct a. It sends the response, which
may in general be a vector of numbers, to V.
V applies a Boolean polynomial-time computable predicate pred(·) to the system
parameters, P’s public key, P’s initial witness, its own challenge, and P’s response,
and accepts if and only if the outcome of the predicate is 1.
We refer to proofs of knowledge of this structure as Fiat-Shamir type proofs of
knowledge, because the following technique for converting them into digital signa-
ture schemes was ﬁrst proposed (for a particular instance) by Fiat and Shamir [171].
Note that the proofs of knowledge described in Section 2.4 are of this type.

80
CRYPTOGRAPHIC PRELIMINARIES
The conversion into a digital signature scheme is brought about by replacing the
role of V by a “virtual” veriﬁer. This is accomplished by computing V’s challenge
according to c := Hi(m, a), where m ∈Mi is any message and H(·) is a sufﬁciently
strong (see page 84 for details) one-way hash function that must be speciﬁed together
with the system parameters or the public key of P. The signature on m is deﬁned
to be σ := (a, r), and anyone can verify it by computing c and applying pred(·).
Because the digital signature on m is obtained by means of an issuing protocol that
is derived from a proof of knowledge, it is also called a signed proof.
As a general rule, from a security perspective it is recommended to hash along all
the information that V needs to check anyway to verify the signed proof, including the
public key, algorithm identiﬁers, and purpose speciﬁers. (They may all be assumed
to be part of the message, m.)
Note that the properties of witness-indistinguishable and witness-hiding are pre-
served under the conversion.
In case m is known to P at the start of the protocol, for instance because M is
the empty set or V provides m before learning a, P can compute c := Hi(m, a) by
itself, and the issuing protocol can be non-interactive; P simply sends (a, r) to V. It is
conjectured that the non-interactive signature scheme is unforgeable if the signature
issuing protocol is witness-hiding. Modeling H(·) as a random oracle, Pointcheval
and Stern [307] proved the following unforgeability result.
Proposition 2.5.2. Suppose that the binary sizes of the outputs of fi(·) and Hi(·)
are linear19 in k and let (I, D) be an invulnerable instance generator for f(·). If a
Fiat-Shamir type proof of knowledge for f(·) is honest-veriﬁer zero-knowledge, then
its conversion to a non-interactive signature scheme is unforgeable over (I, D) in the
random oracle model.
This result holds even under an adaptively chosen message attack whereby the
signer engages in polynomially many protocol executions that are arbitrarily inter-
leaved.
In case V wants to hide (at least) the message m from P, it must supply c itself.
In this case the protocol remains interactive and the conditions of Proposition 2.5.2
are insufﬁcient to prove unforgeability in the random oracle model. By generalizing
a result due to Pointcheval [305], which is an optimization of a result of Pointcheval
and Stern [306], it is possible to prove the following result.
Proposition 2.5.3. Suppose that the binary sizes of the outputs of fi(·) and Hi(·)
are linear in k. Let (I, D) be such that the condition in Proposition 2.4.7 holds, and
suppose that f(·) is collision-intractable over (I, D). If a Fiat-Shamir type proof
of knowledge for f(·) is computationally witness-indistinguishable and the prover
performs no more than polylogarithmically20 many protocol executions, then its con-
19In fact, we merely need that 2−|Hi(·)| is negligible in k.
20A function f(·) is polylogarithmic in k if there exists a positive integer c such that f(k) ≤(log k)c
for all sufﬁciently large k.

2.5 DIGITAL SIGNATURES
81
version to an interactive signature scheme is unforgeable over (I, D) in the random
oracle model.
This result holds under an adaptively chosen message attack, and the protocol
executions may be arbitrarily interleaved.
If it were only for the ability of V to hide m from P, the interactive variant of the
signature scheme would hardly be interesting. Okamoto and Ohta [289] showed that
it is possible for V, in interactive signature schemes derived from witness-hiding Fiat-
Shamir type proofs of knowledge, to perfectly blind the issuing protocol, provided
that certain properties hold. These properties, collectively referred to as commuta-
tive random self-reducibility, apply to virtually all practical Fiat-Shamir type proofs
of knowledge proposed to date, including those described in Section 2.4. In case
the condition in Proposition 2.5.3 holds, we obtain blind signature schemes that are
provably secure in the random oracle model. However, as explained in Section 1.2.2,
Chaum’s blinding techniques are unsuitable for our purposes.
We now show how to construct practical digital signature schemes from our
proofs of knowledge for the DLREP function and the RSAREP function.
2.5.3
Digital signatures based on the DLREP function
In Section 2.4.3 we investigated two variations for proving knowledge of a DL-
representation: one in which s is small and the protocol steps are repeated in parallel
polynomially many times, and the other in which no repetitions are needed because
s is superpolynomial in k. Both protocols are readily seen to be Fiat-Shamir type
proofs of knowledge, and can be converted into a digital signature scheme by apply-
ing the described technique. As mentioned in Section 2.4.3 we will not consider the
case of small s, for reason of practicality. Consider now the case of large s. Let H(·)
be a one-way hash function, deﬁned by
Hq,gl(·) : Mq,gl × Gq →Zs.
A description of Hq,gl(·) must be speciﬁed together with the system parameters or
P’s public key. The deﬁnition of Hi(·) and Mi may also depend on (g1, . . . , gl−1),
P’s public key, and any other information that is speciﬁed before protocol execu-
tions take place; for notational reasons we do not make this explicit in the notation.
In practice the outputs of Hq,gl(·) will usually be t-bit strings, for some t with 2t
(possibly much) smaller than s.
P’s digital signature on a message m is a vector (a, r1, . . . , rl) such that the
relation
l
i=1
gri
i h−Hq,gl (m,a) = a

82
CRYPTOGRAPHIC PRELIMINARIES
holds. Alternatively, one can deﬁne the signature to be (c, r1, . . . , rl), and the signa-
ture veriﬁcation relation is
c = Hq,gl(m,
l
i=1
gri
i h−c).
Since a signature of either one type is readily computed from one of the other type,
the security for P is not affected. Differences exist in terms of efﬁciency, though:
• Using (c, r1, . . . , rl) is favorable in case the subgroup construction is used to
construct Gq, because the storage complexity of c is smaller than that of a.
In particular, using the parameter sizes recommended in Section 2.2.2, many
hundreds of bits are saved.
• Using (a, r1, . . . , rl) may be preferable when t > 1 digital signatures need to
be veriﬁed. With (ai, r1i, . . . , rli) denoting P’s digital signature on message
mi, for all i ∈{1, . . . , t}, V sets α1 := 1 and generates α2, . . . , αt at random
from a set V ⊆Zq. V then computes
ci := Hq,gl(mi, ai)
∀i ∈{1, . . . , t},
and veriﬁes the compound veriﬁcation relation
l
i=1
g
	t
j=1 αjrij
i
h−	t
i=1 αici =
t
i=1
aαi
i .
It is easy to prove that if the compound veriﬁcation relation holds, then the
probability that all t signatures are valid is at least 1 −1/|V |. Since the left-
hand side of the compound veriﬁcation relation can be rapidly computed using
simultaneous repeated squaring with a single precomputed table, this batch-
veriﬁcation technique is a substantial improvement over verifying all t digital
signatures separately.21
The security of the digital signature scheme depends on which party speciﬁes c:
(Non-interactive issuing protocol) Proposition 2.5.2 can be applied, since the proof
of knowledge is honest-veriﬁer zero-knowledge.
Proposition 2.5.4. If (IDL, DDL) is invulnerable, and the binary size of outputs
of Hi(·) is linear in k, then non-interactively issued signed proofs are provably
unforgeable over (IDLREP, DDLREP) in the random oracle model, for any distribu-
tion of (x1, . . . , xl−1).
21For large t it is more efﬁcient to randomly partition the t veriﬁcation relations into a suitable number
of “buckets,” and apply batch-veriﬁcation to each bucket. Cf. Bellare, Garay, and Rabin [21].

2.5 DIGITAL SIGNATURES
83
We stress that this result holds even in case (x1, . . . , xl−1) is known in advance
to V with overwhelming probability, if only xl is a random secret.
The special case l = 1 is the Schnorr signature scheme [337]. Note that P in
the non-interactive issuing protocol need not transmit a to V; it can be recov-
ered from c and P’s responses.
(Interactive issuing protocol) By applying Proposition 2.5.3 we obtain the follow-
ing result.
Proposition 2.5.5. Let l ≥2 and suppose that V initially has non-negligible
uncertainty about (x1, . . . , xl−1). If the DL function used to implement the
DLREP function is one-way, the binary size of outputs of Hi(·) is linear in k,
and P does not perform more than polylogarithmically many executions of the
issuing protocol, then interactively issued signed proofs are provably unforge-
able over (IDLREP, DDLREP) in the random oracle model, for any distribution of
(x1, . . . , xl−1).
On the basis of this result22 We make the following assumption, which will be
needed in Chapter 4.
Assumption 2.5.6. There exists a hash function H∗(·) and a message set M =
{Mi}i∈{q,gl} with Mq,gl ⊇Gq such that interactively issued signed proofs
are unforgeable over (IDLREP, DDLREP).
It is easy to prove that this assumption holds for all l ≥1 if it holds for l = 1,
for the same choice of hash function.
In accordance with the blinding technique of Okamoto and Ohta [289], V can
blind the issuing protocol by performing the following action after Step 1 of the
proof of knowledge. It generates l + 1 random numbers, α0, . . . , αl ∈Zq, and
computes a′ := ahα0 l
i=1 gαi
i , c′ := Hq,gl(m, a′), and c := c′ + α0 mod q.
It then sends its challenge c to P. Upon receiving P’s responses, r1, . . . , rl, V
computes r′
i := ri + αi mod q, for all i ∈{1, . . . , l}. It is easy to verify that
(a′, r′
1, . . . , r′
l), or (c′, r′
1, . . . , r′
l) for that matter, is P’s digital signature on
m. Moreover, if V chooses m at random and accepts then the signed message
is statistically independent of P’s view in the protocol execution. However,
there are no practical advantages in using this scheme over Chaum’s RSA-
based blind signature scheme [91, 92] (with small v), unless one trusts an el-
liptic curve implementation with short system parameters. Furthermore, as
22In their “random oracle + generic” security model, Schnorr and Jakobsson [339] prove a sharp secu-
rity bound for the unforgeability of interactively issued Schnorr signatures, assuming sequential protocol
executions. They also showed that parallel attacks that beat the success rate of sequential attacks must
solve the problem of ﬁnding an intersection point of a subset of randomized hyperplanes. Proposition 2.5.5
can be proved for all l ≥1 under the same assumption in a similar manner.

84
CRYPTOGRAPHIC PRELIMINARIES
explained in Section 1.2.2, Chaum’s blinding paradigm is unsuitable for our
purposes. In Chapter 3 we will introduce more intricate blinding techniques
that result in all sorts of previously unattainable results.
In practice, one-wayness of H(·) is not enough for unforgeability over (IDLREP, DDLREP).
Existential forgery of non-interactively issued Schnorr signatures, for instance, is
feasible in case two messages m1, m2 exist such that, for random (a1, a2) ∈Gq×Gq,
it is feasible to compute with non-negligible success probability a third message m
and two integers α, β such that the following correlation holds:
αHq,gl(m1, a1) + βHq,gl(m2, a2) = Hq,gl(m, aα
1 aβ
2) mod q.
In the interactive case, H(·) must be even stronger. To guarantee unforgeability in
practice, H(·) must be correlation-intractable, meaning that it is infeasible to com-
pute correlations like the one displayed. (Note that functions with superpolynomial
range are always correlation-intractable when idealized in the random oracle model.)
Because it is unclear how to formalize the notion of correlation-intractability in a
useful way, we will from now on always speak of a sufﬁciently strong one-way func-
tion whenever we need a correlation-intractable function. In practice, hash functions
such as SHA-I or RIPEMD-160 should sufﬁce.23
Schnorr [337] suggests for his signature scheme that a one-way hash function
with 10-byte outputs should sufﬁce for long-term practical security. There seems to
be no reason not to allow this choice for arbitrary l in the non-interactive case. In
the interactive case this should hold as well, assuming that P does not respond to
V’s challenge in case the delay between sending the initial witness and receiving the
challenge exceeds a short time bound. To be on the safe side, it is strongly recom-
mended to always use a sufﬁciently strong collision-intractable hash function with
at least 20-byte outputs. This choice is also preferred in light of the more intricate
signed proofs that will be described in Chapter 3.
2.5.4
Digital signatures based on the RSAREP function
Consider the case of s superpolynomial in k in the proof of knowledge in Sec-
tion 2.4.4, for a prime v superpolynomial in k and co-prime to ϕ(n). Let H(·) be a
one-way hash function, deﬁned by
Hn,v(·) : Mn,v × Z
∗
n →Zs.
The deﬁnition of Hi(·) and Mi may also depend on (g1, . . . , gl), P’s public key, and
any other information that is speciﬁed before protocol executions take place.
23Note that these are not inﬁnite collections of functions: they act on messages of any size, but their
outputs are of ﬁxed size.

2.5 DIGITAL SIGNATURES
85
P’s digital signature on a message m is a vector (a, r1, . . . , rl+1) such that the
veriﬁcation relation
l
i=1
gri
i rv
l+1h−Hn,v(m,a) = a
holds. This form lends itself to batch-veriﬁcation. Alternatively, and more compactly,
one can deﬁne the signature to be (c, r1, . . . , rl+1), and the corresponding signature
veriﬁcation relation is
c = Hn,v(m,
l
i=1
gri
i rv
l+1h−c).
Again, this does not affect the security for P.
As with the DLREP function, we distinguish two cases:
(Non-interactive issuing protocol) Proposition 2.5.2 can be applied, since the proof
of knowledge is honest-veriﬁer zero-knowledge.
Proposition 2.5.7. If (IRSA, DRSA) is invulnerable, and the binary size of out-
puts of Hi(·) is linear in k, then non-interactively issued signed proofs are
provably unforgeable over (IRSAREP, DRSAREP) in the random oracle model, for
any distribution of (x1, . . . , xl).
The special case l = 1 is the Guillou-Quisquater signature scheme [201,
202].24
(Interactive issuing protocol) Proposition 2.5.3 can be invoked to prove the follow-
ing result.
Proposition 2.5.8. Let l ≥1 and suppose that V initially has non-negligible
uncertainty about (x1, . . . , xl). If the RSA function used to implement the
RSAREP function is one-way, the binary size of outputs of Hi(·) is linear in k,
and P does not perform more than polylogarithmically many executions of the
issuing protocol, then interactively issued signed proofs are provably unforge-
able over (IRSAREP, DRSAREP) in the random oracle model, for any distribution of
(x1, . . . , xl).
Based on this result, we make the following assumption.
Assumption 2.5.9. There exists a hash function H∗(·) and a message set M =
{Mi}i∈{n,v} with Mn,v ⊇Z
∗
n such that interactively issued signed proofs are
unforgeable over (IRSAREP, DRSAREP).
24Four years earlier, Shamir [346] described essentially the same signature scheme, with the irrelevant
difference that V’s hashed challenge appears as the exponent of a instead of h. This scheme also pre-
dates the paper of Fiat and Shamir [171] to which the conversion technique in Section 2.5.2 is generally
attributed.

86
CRYPTOGRAPHIC PRELIMINARIES
It is easy to prove that the assumption holds for all l ≥0 if it holds for l = 0,
for the same choice of hash function.
V can blind the issuing protocol, in accordance with the technique of Okamoto
and Ohta [289], by performing the following action after Step 1 of the proof
of knowledge. It generates l + 1 random numbers, α0, . . . , αl ∈Zv and
a random number αl+1 ∈Z
∗
n, and computes a′ := ahα0 l
i=1 gαi
i αv
l+1,
c′ := Hn,v(m, a′), and c := c′+α0 mod v. It then sends its challenge, c, to P.
Upon receiving P’s responses, r1, . . . , rl+1, V computes r′
i := ri +αi mod v,
for all i ∈{1, . . . , l}, and r′
l+1 := rl+1
l
i=1 g(ri+αi) div v
i
αl+1. It is easy to
verify that (a′, r′
1, . . . , r′
l+1), or (c′, r′
1, . . . , r′
l+1) for that matter, is P’s digi-
tal signature on m. Moreover, if V generates m at random and accepts then
the signed message is statistically independent of P’s view in the protocol
execution. However, there is no practical advantage over Chaum’s blind sig-
nature scheme [91, 92], which is much more efﬁcient because small v may be
taken. Furthermore, as explained in Section 1.2.2, Chaum’s blinding paradigm
is unsuitable for our purposes. In Chapter 3 we will introduce more intricate
blinding techniques that offer all sorts of beneﬁts.
In practice, H(·) must be a sufﬁciently strong one-way hash function. Similar con-
siderations as in the case of the DLREP function apply to the binary size of the
outputs of H(·). Although in the interactive issuing protocol 10-byte outputs should
be sufﬁciently secure when used in combination with a time-out, it is recommended
to always use a sufﬁciently strong collision-intractable hash function with at least
20-byte outputs. In particular, this will be necessary in Chapter 3.
2.6
Digital certiﬁcates
2.6.1
Deﬁnition of public-key certiﬁcates
Finally, we get to a formal deﬁnition of digital certiﬁcates. We start with the tradi-
tional deﬁnition, which is a special case of the deﬁnition of digital signatures.
Deﬁnition 2.6.1. A public-key certiﬁcate scheme is a digital signature scheme with
the extra property that the message m speciﬁes at least a public key p of V, for which
V knows a corresponding secret key, s.
The pair (p, σ) is called a certiﬁed public key, σ is P’s digital certiﬁcate on m,
and the triple (s, p, σ) is called a certiﬁed key pair. P is also referred to as the
Certiﬁcate Authority (CA).
V’s key pair may be generated either before or during the protocol execution.
In the case of conventional identity certiﬁcates (see Section 1.1.2), the message
m is the concatenation of p and at least a key holder identiﬁer. In the case of attribute

2.6 DIGITAL CERTIFICATES
87
certiﬁcates other attributes are concatenated, either along with the identiﬁer or instead
of the identiﬁer.
As mentioned already in Section 1.3.1, our use of the term “digital certiﬁcate”
differs from the mainstream use of the term, which considers a certiﬁcate to be the
data structure comprised of the CA’s signature, the public key it certiﬁes, and any
information assigned to that public key. Our convention makes it easier to distinguish
between various cryptographic objects.
The deﬁnition of the key pair (s, p) for V may be the same as that of the key
pair (x, fi(x)) for P, but need not; it may even be completely unrelated. Likewise,
completely different instance generators may be used.
2.6.2
Deﬁnition of secret-key certiﬁcates
We now introduce a new kind of certiﬁcates that differ from public-key certiﬁcates
in that anyone can generate certiﬁed public keys without the assistance of P, but
certiﬁed key pairs remain unforgeable. The formal deﬁnition is as follows.
Deﬁnition 2.6.2. A secret-key certiﬁcate scheme is a digital signature scheme with
the additional property that there exists another Boolean predicate, pred∗(·), that
can also be evaluated in polynomial time, such that:
• The message m, on which V obtains a signature σ in an execution of the issuing
protocol with P, is a secret key of V. This secret key corresponds to a public
key p of V such that
pred∗(i, fi(x), p, σ) = 1.
• There exists an expected polynomial-time algorithm S, called a certiﬁcate sim-
ulator, that, on input (i, fi(x)), outputs a pair (p∗, σ∗) with a probability dis-
tribution that is indistinguishable from the probability distribution of (p, σ).
As in the deﬁnition of a public-key certiﬁcate, σ is called P’s digital certiﬁcate on
V’s public key, the pair (p, σ) is called a certiﬁed public key, and the triple (m, p, σ)
is called a certiﬁed key pair.
The output distribution of the certiﬁcate simulator may be computationally, sta-
tistically, or perfectly indistinguishable.
Example 2.6.3. P runs IRSA to obtain a pair (n, v) together with the factorization
of n, which serves as its secret key. This enables P to compute RSA digital signa-
tures [325]. Its RSA signature on a message m is σ := fn,v(m)1/v mod n, where
f(·) is a sufﬁciently strong one-way function.
This signature scheme can be converted into a secret-key certiﬁcate scheme by
viewing the pair (m, fn,v(m)) as a key pair for V. If we take f(·) to be the DL
function implemented using the subgroup construction (i.e., fn,v(m) = gm mod p,

88
CRYPTOGRAPHIC PRELIMINARIES
for some prime p that is not much smaller than n), then it is easy to build a certiﬁcate
simulator with indistinguishable outputs. The simulator picks a random b ∈Z
∗
n
and checks whether bv mod n is an element of Gq; it repeats this experiment until
successful, and then outputs the pair (bv mod n, b).
How can a secret-key certiﬁcate be veriﬁed? In applications of practical inter-
est, V will use its public key p in a subsequent showing protocol without disclosing
the secret key m, and so certiﬁed public keys cannot be veriﬁed by applying pred(·).
Also, applying pred∗(·) to (p, σ) does not prove that the certiﬁed public key has been
issued by P, in view of the simulation property. Instead, veriﬁcation of V’s certiﬁed
public key takes place indirectly. Namely, the ability of V to perform a “crypto-
graphic action” with respect to its public key attests to the fact that V knows a secret
key corresponding to its public key, and this in turn convinces that the certiﬁcate has
been issued by P. Since there is no point in using public-key certiﬁcates without per-
forming some cryptographic action that attests to the possession of a corresponding
secret key, secret-key certiﬁcates offer the same basic functionality as do public-key
certiﬁcates.25 The following two cryptographic actions in the showing protocol will
be of particular interest to us:
1. V performs a zero-knowledge proof of knowledge of a secret key correspond-
ing to its public key. If V can successfully perform the proof, then the veriﬁer
is convinced not only that V knows a secret key corresponding to the public
key, by virtue of the soundness property, but also that the certiﬁcate has been
issued by P. However, the transcript of the protocol execution does not con-
vince anyone else of either one of these facts; the entire protocol execution is
zero-knowledge. (This is an advantage over public-key certiﬁcates, for which
the showing protocol is zero-knowledge in its entirety only when V proves
possession of a certiﬁcate by means of a zero-knowledge proof as well.)
In Example 2.6.3, V can prove knowledge of the secret key corresponding to
its public key gm by using the Schnorr proof of knowledge or its 4-move zero-
knowledge variant.
2. V digitally signs a message. Given the message, the digital signature of V, and
the certiﬁed public key of V, anyone is able to verify not only that the digital
signature is genuine, but also that it was indeed made with respect to a public
key certiﬁed by P.
In Example 2.6.3, V can sign a message using the Schnorr signature scheme;
in the random oracle model, these signatures can be issued only by a party that
knows the secret key.
25This idea is reminiscent of Shamir’s [346] self-certiﬁed public keys, the goal of which is to avoid
the need for an explicit certiﬁcate. Hereto the CA forms the public key of each applicant as a redundant
message that encodes the applicant’s identity, and issues a corresponding secret key to the applicant; key
pairs should be unforgeable.

2.6 DIGITAL CERTIFICATES
89
Note that a third cryptographic action can be performed: decrypting a message that
has been encrypted with V’s public key. In Example 2.6.3, V can decrypt messages
that have been encrypted under its public key gm by means of, for instance, the
ElGamal encryption scheme [146] in Gq. Since decryption requires knowledge of
the secret key, the party that encrypted the message is ensured that either V’s public
key has been certiﬁed by P or V cannot decrypt. In the remainder of this book
we will not be interested in the case of encryption; public keys for (hybrid) session
encryption can always be formed at random at the start of an authenticated session.
2.6.3
Comparison
Secret-key certiﬁcates have several advantages over public-key certiﬁcates:
• They appear to be much better suited to design certiﬁcate issuing protocols
with the following property: V is able to blind the certiﬁed public key but not
a non-trivial part of its secret key. See Chapter 4 for details.
• A certiﬁed public key does not serve as signed evidence that its holder has been
issued a certiﬁcate by the CA. This property is preserved if certiﬁed key pairs
are used only to perform zero-knowledge proofs.
• The ability to simulate certiﬁed public keys enables individuals to hide in
which of several PKIs they are participating. See Section 5.2 for details.
• Knowledge of certiﬁed public keys (obtained from repositories or otherwise)
cannot help in attacking the certiﬁcate scheme of the CA.
On the other hand, care has to be taken when combining an interactive secret-key
certiﬁcate issuing protocol with a showing protocol. Suppose a certiﬁcate simulation
algorithm exists that outputs certiﬁed public keys for which the certiﬁcate simulation
algorithm and P together know a corresponding secret key. Then an attacker may
be able in the showing protocol to perform a cryptographic action with respect to a
simulated public key by delegating part of the action to P; see Section 5.1.2 for an
example.
Successful delegation to executions of protocols other than the certiﬁcate issuing
protocol can simply be prevented by having P use independently generated keys for
different tasks. Key separation is recommended practice anyway; see, e.g., Kelsey,
Schneier, and Wagner [229]. To assess for a given application whether a crypto-
graphic action can be delegated to an execution of the issuing protocol, it must be
investigated whether certiﬁed public keys can be simulated in such a way that the
cryptographic action in the showing protocol can be performed by using P as an ora-
cle. In the certiﬁcate schemes that will be developed in this book, delegation is never
a problem; see Section 5.1.2 for details.

90
CRYPTOGRAPHIC PRELIMINARIES
2.7
Bibliographic notes
The historical background of the DLREP function in Section 2.3.2 is quite diverse.
In 1987, Chaum, Evertse, and van de Graaf [108] considered the case where all
gi’s are random elements from Z
∗
p, and claimed that inverting is infeasible when
elements from the domain are generated at random (hardly a useful instance gener-
ator). Chaum and Crepeau [60], Chaum and van Antwerpen [110], Chaum [101],
Boyar, Kurtz, and Krentel [44], Pedersen [298], van Heijst and Pedersen [380], and
Okamoto [288] all designed schemes based on the special case l = 2. Chaum, van
Heijst, and Pﬁtzmann [111, 112] studied collision-intractability for the special case
of ﬁxed l, with gi’s in a group of prime order; their reduction is not tight, though, and
takes exponential time for l polynomial in k. In 1993, Brands [46] examined the one-
wayness and the collision-intractability of the DLREP function for arbitrary l polyno-
mial in k, and provided a tight reduction to prove its collision-intractability; the over-
head factor is approximately 2. Bellare, Goldreich, and Goldwasser [23] modiﬁed the
reduction to simplify its analysis, but the overhead is slightly larger. Pﬁtzmann [301],
elaborating on the reduction of Chaum, van Heijst, and Pﬁtzmann [111, 112], gave
the ﬁrst (fairly intricate) optimally tight reduction. The proof of Proposition 2.3.3
is similar to a simpler reduction by Schoenmakers [342], but differs in the assump-
tion on the distribution of the gi’s (for reasons that will become clear in Chapter 3).
Construction 2.3.2 is new.
The RSAREP function in Section 2.3.3 was introduced by Brands [54]. Previ-
ously only the case l = 1 appeared, in proofs of knowledge (see Okamoto [288])
and implicitly in some proofs of security (see, e.g., Guillou and Quisquater [201]).
Construction 2.3.4 and Proposition 2.3.5 appear here for the ﬁrst time.
The notion of secret-key certiﬁcates is due to Brands [56]; see also Brands [52,
53]. Deﬁnition 2.6.2 has not appeared previously. The possibility of delegation was
ﬁrst noted by Schoenmakers (personal communication, May 1995), in the context of
the electronic coin system of Brands [49].

Chapter 3
Showing Protocols with
Selective Disclosure
In this chapter we present highly ﬂexible and practical showing protocol techniques
that enable the holder of an arbitrary number of attributes to selectively disclose
properties about them; any other information remains unconditionally hidden. All the
techniques can be based on the DLREP function as well as on the RSAREP function.
The demonstrations can take several forms, including zero-knowledge proofs and
signed proofs. Signed proofs are provably unforgeable in the random oracle model
under the mere assumption that there exists an invulnerable instance generator for the
DL function or the RSA function. We do not yet make the connection with digital
certiﬁcate issuing protocols; this will be the topic of Chapters 4 and 5.
3.1
Introduction
Consider a polynomial-time prover P that has committed, by means of a commitment
function, to one or more attributes that are (represented by) elements of a ﬁnite ring.
P is to demonstrate to a veriﬁer V that its attributes satisfy a satisﬁable formula from
proposition logic, where the atomic propositions are relations that are linear in the
attributes. By way of example, let x1, x2, x3 denote P’s attributes, and consider the
formula

(F1
AND F2) OR (NOT F3
AND F4)

AND NOT F5
(3.1)
where
F1
=
(x1 + 2x2 −10x3 = 13)
F2
=
(x2 −4x3 = 5)

92
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
F3
=
(x1 + 3x2 + 5x3 = 7)
F4
=
(3x1 + 10x2 + 18x3 = 23)
F5
=
(x1 −8x2 + 11x3 = 5)
We require that the computations of V when interacting with P can be performed
in polynomial time, but V is given inﬁnite computing power in its attempts to learn
additional information about P’s attributes. The goal is to ensure that P does not
reveal to V any information about its attributes beyond the validity of the formula.
Regardless of the commitment function used, a constant-round zero-knowledge
argument for this task can be constructed by reducing the formula to an instance of
the NP-complete language Directed Hamiltonian Cycle and applying a protocol due
to Feige and Shamir [170]. Alternatively, the formula can be reduced to an instance
of the NP-complete language SAT and then subjected to a slightly more efﬁcient
protocol due to Bellare, Jakobsson, and Yung [24]. The resulting protocols are highly
impractical, though, because statements must be encoded into Boolean circuits and
auxiliary commitments must be used for each gate.
In the remainder of this chapter we show that truly practical techniques exist
when P commits to its attributes in a special manner. Assuming parameter sizes sufﬁ-
cient to guarantee long-term security, the new techniques allow P to non-interactively
demonstrate example formula (3.1) by sending a mere 275 bytes to V. Forming and
verifying the proof both require fewer than 940 modular multiplications of numbers
in Gq or Z
∗
n.
In the next section we describe how P should commit. We then introduce tech-
niques for demonstrating formulae of special forms. Finally, in Section 3.6 we show
how to combine these techniques to demonstrate arbitrary Boolean formulae.
3.2
How to commit
Our proof techniques require P to commit to its attributes by means of either the
DLREP function or the RSAREP function:
• To base the security on the hardness of inverting the DL function, the attributes
must all be (represented by) numbers in Zq, and P computes h := l
i=1 gxi
i .
The system parameters and P’s secret key must be generated in accordance
with Construction 2.3.2, based on any invulnerable instance generator for the
DL function. Recall from Construction 2.3.2 that (xl, . . . , xl−1) may have an
arbitrary distribution, but P must generate xl at random from Zq.
• To base the security on the hardness of inverting the RSA function, the at-
tributes must all be (represented by) numbers in Zv, and P computes h :=
l
i=1 gxi
i xv
l+1, where xl+1 ∈Z
∗
n. The system parameters and P’s secret
key must be generated in accordance with Construction 2.3.4, based on any

3.3 FORMULAE WITH ZERO OR MORE “AND” CONNECTIVES
93
invulnerable instance generator for the RSA function. Recall from Construc-
tion 2.3.4 that (x1, . . . , xl) may have an arbitrary distribution, but P must gen-
erate xl+1 at random from Z
∗
n.
In either case, h is referred to as the public key of P. Recall that l may be polynomial
in the security parameter.
In case the security is based on the RSA function, there is a clean separation
between the role of the attributes and that of xl+1. This is not the case when the
DL function is used, because one of the attributes must be chosen at random, and it
will rarely make sense in practice to demonstrate a property about a random number.
Nevertheless, the distinction is merely a notational one. If one insists on allowing
(x1, . . . , xl) to have an arbitrary distribution, then P should form h := l+1
i=1 gxi
i ,
where gl+1 is a generator of Gq and P generates xl+1 at random from Zq. We stick
to the former notation, because it sometimes makes sense to demonstrate that the
random xl is unequal to zero; see Section 5.1.1.
As explained in Section 2.4, algorithms IDLREP and IRSAREP must be run by V, by a
party trusted by V and P, or by means of a secure multi-party protocol between V and
P. In any case, it must be ensured that P cannot know more than one representation
of h. On the basis of Propositions 2.3.3 and 2.3.5 it is easily seen how to accomplish
this.
To avoid unduly repetition, throughout this chapter we detail our techniques for
the case where the DLREP function is used to commit to P’s attributes; for the
RSAREP function we clarify only the differences. We also assume from now on
that l ≥2 when the DLREP function is used, for obvious reasons.
3.3
Formulae with zero or more “AND” connectives
We ﬁrst consider the situation in which P is to demonstrate a satisﬁable formula with
zero or more “AND” connectives and no other logical connectives.
3.3.1
Technique based on the DLREP function
Without loss of generality, assume that P is to demonstrate that the DL-representation
it knows of h with respect to (g1, . . . , gl) satisﬁes the following system of t ≥0
independent linear relations:





α11
. . .
α1,l−t
1
0
. . .
0
α21
. . .
α2,l−t
0
1
. . .
0
...
...
...
...
...
...
...
αt1
. . .
αt,l−t
0
0
. . .
1










xπ(1)
xπ(2)
...
xπ(l)




=





b1
b2
...
bt




mod q.
(3.2)
The coefﬁcients αij are elements of Zq, and π(·) is a permutation of {1, . . ., l}.
Clearly, any satisﬁable system of linear relations in x1, . . . , xl can be described in

94
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
this form: if a system of linear relations contains dependent relations, it can be re-
duced to a system of independent linear relations, denoted in number by t here; then
the matrix of coefﬁcients can be brought into row canonical form, using Gaussian
elimination; and, ﬁnally, by applying a suitable permutation π(·), the columns of the
matrix of coefﬁcients can be interchanged, arriving at the system displayed above.
(In a practical implementation the latter step may be omitted, but here we need π(·)
also to enable a generic description and analysis of the technique.)
If t = l then V can verify the applicability of the formula without communicat-
ing with P, by solving for the xi’s and checking that they form a preimage to h.
Therefore we may assume that t < l.
Representing atomic propositions by linear relations over Zq, system (3.2) cor-
responds to the following Boolean formula:
(b1 = α11xπ(1) + · · · + α1,l−txπ(l−t) + xπ(l−t+1) mod q) AND . . .
. . . AND (bt = αt1xπ(1) + · · · + αt,l−txπ(l−t) + xπ(l) mod q).
(3.3)
The special case t = 0 corresponds to the “empty” formula, TRUE. Although P’s
attributes obviously satisfy this formula, it may certainly make sense to demonstrate
it, as will become clear in the next three chapters.
Our technique for demonstrating formula (3.3) is based on the following result.
Proposition 3.3.1. P can prove knowledge of a DL-representation of
(
t
i=1
gbi
π(l−t+i))−1h
with respect to

gπ(1)
t
i=1
g−αi1
π(l−t+i), . . . , gπ(l−t)
t
i=1
g−αi,l−t
π(l−t+i)

if and only if it knows a set of attributes that satisﬁes the formula (3.3).
Proof. If (x1, . . . , xl) satisﬁes the formula (3.3), then
h
=
l
i=1
g
xπ(i)
π(i)
(∗)
=
(
l−t

i=1
g
xπ(i)
π(i) )(
t
i=1
g
bi−	l−t
j=1 αijxπ(j)
π(l−t+i)
)
(∗∗)
=
(
t
i=1
gbi
π(l−t+i))(gπ(1)
t
i=1
g−αi1
π(l−t+i))xπ(1) · · · (gπ(l−t)
t
i=1
g−αi,l−t
π(l−t+i))xπ(l−t),

3.3 FORMULAE WITH ZERO OR MORE “AND” CONNECTIVES
95
and so the DL-representation that P can prove knowledge of is (xπ(1), . . . , xπ(l−t)).
(We will refer to the marked derivation steps later on.)
To prove the converse, suppose that P convinces V with non-negligible success
probability. According to Deﬁnition 2.4.1, there exists a polynomial-time knowledge
extractor K that outputs with non-negligible success probability a DL-representation
(y1, . . . , yl−t). By expanding the relation
(
t
i=1
gbi
π(l−t+i))−1h =
l−t

i=1
(gπ(i)
t
j=1
g−αji
π(l−t+j))yi,
it is seen that
(y1, . . . , yl−t, b1 −
l−t

j=1
α1jyj mod q, . . . , bt −
l−t

j=1
αtjyj mod q)
is a DL-representation of h with respect to (gπ(1), . . . , gπ(l)). This must be the DL-
representation (xπ(1), . . . , xπ(l)) known to P, because P must know at least one
such DL-representation to perform the proof of knowledge (otherwise K can be used
directly to compute DL-representations), and if this were different then < P, K>
could be used to invert the DL function (see Proposition 2.3.3).
It remains to check that the DL-representation satisﬁes the formula (3.3). From
the left-hand side of the matrix equation (3.2) it follows, for all i ∈{1, . . ., t}, that
l−t

j=1
αijxπ(j) + xπ(l−t+i)
=
l−t

j=1
αijyj + (bi −
l−t

j=1
αijyj)
=
bi mod q.
This completes the proof.
While the expressions appearing in this proposition are somewhat intimidating, the
process of deriving them is simple and can easily be performed by pencil and paper
using the following three steps:
1. As can be seen in the ﬁrst part of the proof of Proposition 3.3.1 and in particular
in the derivation step marked by (∗), we ﬁrst substitute into P’s commitment
h := l
i=1 gxi
i
the t expressions for xπ(l−t+1), . . . , xπ(l) that must hold if the
formula (3.3) holds true.
2. We then group together the terms that are raised to a constant power, and col-
lect terms for each of the variables xπ(1), . . . , xπ(l−t); see the derivation step
marked by (∗∗).
3. Finally, we divide both sides by the product of all constant powers.

96
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
Example 3.3.9 will illustrate the process.
By substitution into Proposition 3.3.1 it is immediately seen that the demonstra-
tion of the formula TRUE corresponds to proving knowledge of a DL-representation
of h with respect to (g1, . . . , gl). According to the proof of Proposition 3.3.1, this
property holds in general.
Corollary 3.3.2. Regardless of the formula demonstrated by P, the proof of knowl-
edge in Proposition 3.3.1 is also a proof of knowledge of a DL-representation of h
with respect to (g1, . . . , gl).
The importance of this simple result will become clear in Section 5.5.2, where
we show how to discourage certiﬁcate lending, and in Section 6.3, where we show
how to lift the demonstration technique to the smartcard setting.
Consider now a setting in which V requests P to demonstrate a plurality of for-
mulae of the form (3.3), not necessarily all the same. Clearly, with each new formula
that is demonstrated for the same h, V learns additional information about P’s at-
tributes.
Deﬁnition 3.3.3. In an adaptively chosen formula attack, V may select at the start
of each new protocol execution which formula is to be demonstrated by P. Protocol
executions may be arbitrarily interleaved, in any way dictated by V. In case V re-
quests a formula that does not apply to P’s attributes, P informs V of this fact either
by not responding before a time-out or by sending a predetermined ﬁxed message;
otherwise P demonstrates the formula to V. In either case, V learns the status of the
formula, namely whether it is true or false with respect to P’s attributes.
We are interested in determining whether V can learn more about P’s attributes
than what can be learned from only the status of the requested formulae and V’s a
priori information (the probability distribution from which P’s attributes have been
drawn). That is, do protocol executions leak additional information about P’s at-
tributes?
The following proposition provides a sufﬁcient condition to guarantee that what-
ever V can compute about P’s attributes, it can also compute using only its a priori
information and the status of the requested formulae.
Proposition 3.3.4. Let P only demonstrate formulae in which xl does not appear,
using a proof of knowledge as described in Proposition 3.3.1 with the property that
it is statistically witness-indistinguishable. For any distribution of (x1, . . . , xl−1),
whatever information V in an adaptively chosen formula attack can compute about
(x1, . . . , xl−1) can also be computed using merely its a priori information and the
status of the formulae requested.
Proof. Without loss of generality we concentrate on the formulae that P demon-
strates by means of a proof of knowledge. Consider ﬁrst the demonstration of a
single formula. If xπ(j) does not appear in the formula, for some j ∈{1, . . . , l −t},

3.3 FORMULAE WITH ZERO OR MORE “AND” CONNECTIVES
97
then the j-th column in the matrix on the left-hand side of system (3.2) contains all
zeros, and it follows that
t
i=1
g−αij
π(l−t+i) = 1.
As a consequence, in Proposition 3.3.1 the number gπ(j) appears separately in the
tuple with respect to which P proves knowledge of a DL-representation. Since in
our case xl does not appear in the formulae demonstrated, it follows that, in a single
formula demonstration, P proves knowledge of a DL-representation (y1, . . . , yj, xl)
of a number in Gq with respect to a tuple (g∗
1, . . . , g∗
j , gl), for some integer j ≥0
and numbers g∗
1, . . . , g∗
j in Gq that depend on the formula demonstrated. The set
{y1, . . . , yj} is a subset of {x1, . . . , xl−1}. Since gl is a generator of Gq, for any
tuple (y1, . . . , yj) ∈(Zq)j there is exactly one xl such that (y1, . . . , yj, xl) is the
DL-representation that P proves knowledge of. Because the proof of knowledge is
witness-indistinguishable, and xl has been chosen at random by P, it follows that
no information is revealed about y1, . . . , yj. Consequently, no information is leaked
about (x1, . . . , xl−1) beyond the status of the formula.
To complete the proof, we apply Proposition 2.4.5, according to which the (ar-
bitrarily interleaved) demonstration of many formulae, each by means of a witness-
indistinguishable proof, is also witness-indistinguishable.
The witness-indistinguishability condition in Proposition 3.3.4 is not only sufﬁcient,
but also necessary. For example, if l ≥3 and t < l −1, and P performs the proof of
knowledge by disclosing xπ(l−t) and proving knowledge of a DL-representation of
(
t
i=1
gbi
π(l−t+i))−1h(gπ(l−t)
t
i=1
g−αi,l−t
π(l−t+i))−xπ(l−t)
with respect to

gπ(1)
t
i=1
g−αi1
π(l−t+i), . . . , gπ(l−t−1)
t
i=1
g−αi,l−t−1
π(l−t+i)

,
then obviously V learns information that may not have been computable from its a
priori information and the status of the formula. From this counterexample it is also
seen that it does not sufﬁce for the proof of knowledge in Proposition 3.3.4 to be
witness-hiding.
A practical implementation of the proof of knowledge in Proposition 3.3.4 can be
realized by substituting the proof of knowledge described in Section 2.4.3; according
to Proposition 2.4.8 it is perfectly witness-indistinguishable. An important beneﬁt of
using this protocol is that the resulting expressions can be expanded, so that P and
V can use a single precomputed table for simultaneous repeated squaring, regardless

98
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
of the formulae demonstrated. Other advantages of this particular choice of protocol
will become clear in Sections 3.5, 6.3, and 6.4.
The resulting (generic) protocol steps are as follows:
Step 1. P generates at random l −t numbers, w1, . . . , wl−t ∈Zq, and computes
a :=
l−t

i=1
gwi
π(i)
t
i=1
g
−	l−t
j=1 αijwj
π(l−t+i)
.
P then sends the initial witness a to V.
Step 2. P computes a set of responses, responsive to V’s challenge c ∈Zs, as
follows:
ri := cxπ(i) + wi mod q
∀i ∈{1, . . ., l −t}.
P then sends (r1, . . . , rl−t) to V.
V computes
rl−t+i := bic −
l−t

j=1
αijrj mod q
∀i ∈{1, . . ., t},
and accepts if and only if the veriﬁcation relation
l
i=1
gri
π(i)h−c = a
holds.
For later reference, in Sections 5.4 and 6.3, this protocol is depicted in Figure 3.1.
The exponents in the expressions in Step 1 and in the veriﬁcation relation, respec-
tively, can be rapidly computed from the matrix of coefﬁcients in (3.2), by taking
the inner products of the matrix rows and the random numbers, and of the matrix
rows and the responses, respectively. Note that the communication complexity of the
protocol decreases as the number of “AND” connectives increases.
As with the proof of knowledge in Section 2.4.3, the above protocol description is
generic in the sense that the binary size of s and the process of generating c have not
been speciﬁed. To obtain a proof of knowledge, c should be generated in a substan-
tially random manner and become known to P only after it has computed its initial
witness.
The following property will be of importance in Section 3.5.
Proposition 3.3.5. The protocol obtained by implementing the proof of knowledge
in Proposition 3.3.4 by means of the proof of knowledge described in Section 2.4.3 is
honest-veriﬁer zero-knowledge.

3.3 FORMULAE WITH ZERO OR MORE “AND” CONNECTIVES
99
P
V
SYSTEM PARAMETERS
(q, g1, . . . , gl) := IDLREP(1k)
KEY SET-UP
Attributes: x1, . . . , xl−1 ∈Zq
xl ∈R Zq
Secret key: (x1, . . . , xl)
Public key:
h := l
i=1 gxi
i
PROTOCOL
w1, . . . , wl−t ∈R Zq
a := l−t
i=1 gwi
π(i)
t
i=1 g
−	l−t
j=1 αijwj
π(l−t+i)
a
−−−−−−−−−→
c
←−−−−−−−→
∀i ∈{1, . . . , l −t} :
ri := cxπ(i) + wi mod q
r1, . . . , rl−t
−−−−−−−−−→
∀i ∈{1, . . . , t} :
rl−t+i := bic −	l−t
j=1 αijrj mod q
l
i=1 gri
π(i)h−c ?= a
Figure 3.1: Generic protocol for demonstrating formula (3.3).

100
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
Proof. To simulate the view of the honest veriﬁer, the simulator picks the challenge
c ∈Zs according to the same distribution as the honest veriﬁer. It then selects
r1, . . . , rl−t at random from Zq, and computes rl−t+1, . . . , rl as would V in the
protocol. Finally, it computes a such that the veriﬁcation relation holds true:
a :=
l
i=1
gri
π(i)h−c.
It is easy to check that the resulting view, (a, c, r1, . . . , rl−t), is identically distributed
to the view of the honest veriﬁer.
Corollary 3.3.2 suggests that all the considerations in Sections 2.4.3 and 2.5.3 ap-
ply. Special care must be taken, though, because both h and the tuple with respect
to which knowledge of a DL-representation is demonstrated depend on the partic-
ular formula that is demonstrated. This does not pose any problems for the zero-
knowledge proof mode, which in light of the techniques that will be introduced in
Section 6.3 is best realized by prepending a move in which V commits to its chal-
lenge. Caution must be exercised in case of signed proofs, though. Details follow.
To obtain a signed proof, V’s challenge c is generated as a sufﬁciently strong
one-way hash of at least a, in accordance with the Fiat-Shamir technique described
in Section 2.5.2. To enable provability in the random oracle model, we will from
now on always assume implicitly that the hash function produces outputs linear in k.
The signed proof consists of (a, (r1, . . . , rl−t)) or of (c, (r1, . . . , rl−t)), and if the
protocol is non-interactive then P can omit sending either a or c to V, since V can
recover it. If a message m is hashed along, then the signed proof also serves as a
digital signature of P on m. Proposition 3.3.4 still applies, since the hashing does
not affect the property of witness-indistinguishability; signed proofs unconditionally
hide all attribute information that was not explicitly disclosed. The unforgeability of
signed proofs is guaranteed computationally, as follows.
Proposition 3.3.6. Suppose that the proof of knowledge in Proposition 3.3.4 is re-
alized by substituting the witness-indistinguishable proof of knowledge described in
Section 2.4.3, and that V’s challenge is formed by hashing at least a. If the DL func-
tion used to implement P’s commitment is one-way, then non-interactively issued
signed proofs are provably unforgeable in the random oracle model, regardless of
the formula(e) demonstrated and the distribution of (x1, . . . , xl−1).
The proof follows by application of Proposition 2.5.2, in light of Corollary 3.3.2
and Proposition 3.3.5. We stress that Proposition 3.3.6 holds even in case of an
adaptively chosen formula attack (and, if messages are hashed along, an adaptively
chosen message attack), as do all the other unforgeability results in this chapter.
Assuming that P performs no more than polylogarithmically many protocol exe-
cutions, and that the status of the formulae requested by V still leaves non-negligible

3.3 FORMULAE WITH ZERO OR MORE “AND” CONNECTIVES
101
uncertainty about (x1, . . . , xl−1), it can be shown that Proposition 3.3.6 holds true
even for interactively issued signed proofs. However, once V has requested sufﬁ-
ciently many formulae to be able to determine (x1, . . . , xl−1) with overwhelming
probability, it is unclear how to prove unforgeability in the random oracle model; we
in effect end up with the question of whether interactively issued Schnorr signatures
are unforgeable, which is believed true but has yet to be proved. To prove unforge-
ability of interactively issued signed proofs in general, we must relate the security
proof to the construction of Proposition 2.5.5.
Proposition 3.3.7. Let l ≥3, let xl−1 be the outcome of a random coin ﬂip by P,
and let P only demonstrate formulae in which both xl−1 and xl do not appear. Sup-
pose that the proof of knowledge in Proposition 3.3.1 is realized by substituting the
witness-indistinguishable proof of knowledge described in Section 2.4.3, and that
V’s challenge is formed by hashing at least a. If the DL function used to imple-
ment P’s commitment is one-way, and P performs no more than polylogarithmically
many formula demonstrations, then interactively issued signed proofs are provably
unforgeable in the random oracle model, regardless of the formula(e) demonstrated
and the distribution of (x1, . . . , xl−2).
The proof follows from Proposition 2.5.3. It is not hard to show that the result
holds even for an unbiased coin ﬂip, if only the uncertainty about the outcome is
non-negligible.1 Note that xl−1 need not take on the values 0 and 1; any set of
values, of any size, will do, if only xl−1 does not take on one particular value with
overwhelming probability.
By blinding its challenge, V can perfectly blind the signed proof, in the manner
described in Section 2.5. Since this proof mode is of no use in this book, we omit the
details.
Propositions 3.3.6 and 3.3.7 tell us that the number of signed proofs computable
by V cannot exceed the number of protocol executions performed by P, except with
negligible probability. For some applications this is all we need, but in other ap-
plications it is not. An entirely different (and new) issue is the unmodiﬁability of
signed proofs: it should be infeasible to construct a signed proof for a formula that
does in fact not apply to P’s representation. Unless special precaution is taken, a
signed proof convinces only that P knows a DL-representation of h with respect to
(g1, . . . , gl). As an example, if h = gx1
1 gx2
2 , and formulae of the form x2 = b mod q
are to be demonstrated, for arbitrary b ∈Zq, then P can set a := gw1
1 gw2
2 , for ran-
dom w1 and w2, and b := x2 + w2/Hq,g2(m, a) mod q. In case the signed proof is
to be issued interactively, this requires P to conspire with V, because normally the
formula will be determined prior to executing the protocol. If, on the other hand, P
1In a practical implementation one would likely not bother to introduce the extra coin ﬂip xl−1, since
the beneﬁt that comes from it appears to be only of a theoretical nature; the unforgeability property of
interactively issued signed proofs is believed to hold even if it is omitted.

102
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
is to non-interactively issue a signed proof for demonstrating a formula of its own
choice, then it does not need the assistance of V.
One measure to ensure that a signed proof convinces of which formula has been
demonstrated is to restrict all the matrix entries (the αij’s and the bi’s) that specify
the formulae requested to sets V such that |V |/q is negligible in k (e.g., sets of size
√q). The set V may differ for each formula coefﬁcient. This measure, however,
restricts the range of formulae that P can demonstrate. The following measure does
not have this drawback.
Proposition 3.3.8. Non-interactively (interactively) issued signed proofs are prov-
ably unmodiﬁable in the random oracle model, subject to the conditions of Proposi-
tion 3.3.6 (Proposition 3.3.7), in case a uniquely identifying description of the for-
mula is hashed along when forming V’s challenge.
To form a uniquely identifying description of the formula (3.3), one can concate-
nate, in a predetermined order, the αij’s and the bi’s. In case t and l are not ﬁxed as
part of the system, they must be part of the formula description as well.
In other words, when presented with h, a formula description F, an (optional)
message m, and a signed proof (c, r1, . . . , rl−t), any veriﬁer can convince itself
that the signed proof has been computed by a prover (possibly a group of parties)
that applied its knowledge of a DL-representation of h, and that the prover demon-
strated that its DL-representation satisﬁes F. To this end, the veriﬁer must compute
rl−t+1, . . . , rl in the manner speciﬁed in Figure 3.1 and verify that
c = Hq,gl(m, F,
l
i=1
gri
π(i)h−c).
In practice, one may prefer to apply both measures in combination, that is, to
hash along the formula description as well as to restrict all the formula coefﬁcients
to small sets.
It is important to note that unmodiﬁability does not exclude the possibility for V
to end up with a signed proof that convinces only of a part of the formula demon-
strated by P. In particular, by hashing along the formula TRUE (if P allows this) and
lumping together P’s responses, V can hide almost entirely the formula that has been
demonstrated. This property enables V to protect its own privacy in applications in
which it routinely submits its protocol transcripts to a central authority. Details will
be provided in Section 5.3.
Preferably, h is hashed along as well when forming V’s challenge. Micali and
Reyzin [269] show in a general setting that this defeats attacks in practical imple-
mentations whereby the hash function is designed by an adversary in an attempt to
enable forgery in an otherwise secure signature scheme. More importantly for our
purposes, hashing h along is mandatory in situations where h is not ﬁxed but may be
chosen in a fairly arbitrary manner by P; this is the case when our showing protocol

3.3 FORMULAE WITH ZERO OR MORE “AND” CONNECTIVES
103
techniques are combined with certiﬁcate issuing protocols in which the receiver is
in control of generating its public key. For this reason we will from now on always
hash along h in our protocol descriptions. As noted in Section 2.5.2, from the point
of view of security it is strongly recommended anyway to hash along any other data
that the veriﬁer of a signed proof must apply.
To illustrate the preceding techniques, we now present a practical example.
Example 3.3.9. Suppose P has three attributes x1, x2, x3 ∈Zq, selected according
to an arbitrary probability distribution, and is to demonstrate by means of a non-
interactively issued signed proof to V that the following formula holds:
(x1 + 2x2 −10x3 = 13) AND (x2 −4x3 = 5).
Rewriting this formula in the form (3.2), we get the formula
(x1 = 2x3 + 3) AND (x2 = 4x3 + 5).
To demonstrate this formula, P generates a random x4 ∈Zq, and forms the commit-
ment h := 4
i=1 gxi
i . If the formula holds true, then by substitution we get
h
=
gx1
1 gx2
2 gx3
3 gx4
4
=
g2x3+3
1
g4x3+5
2
gx3
3 gx4
4 ,
and by collecting the constant powers, as well as the variable powers for each of
x2, x3, we obtain
h
=
(g3
1g5
2)(g2
1g4
2g3)x3gx4
4 .
Finally, by dividing both sides by g3
1g5
2, we arrive at
(g3
1g5
2)−1h = (g2
1g4
2g3)x3gx4
4 .
Consequently, P can prove knowledge of a DL-representation of h/(g3
1g5
2) with re-
spect to (g2
1g4
2g3, g4). According to Proposition 3.3.1, this is also sufﬁcient to con-
vince V. By substituting the proof of knowledge described in Section 2.4.3, and
expanding the resulting expressions, we obtain the protocol depicted in Figure 3.2.
Here, m denotes an arbitrary message agreed on between the parties and F denotes
a description uniquely identifying the formula demonstrated. The message is op-
tional, and typically its inclusion serves primarily to protect against replay; hereto
m should contain a random number, a counter, or a sufﬁciently accurate estimate of
the time and date. Other information, such as an identiﬁer of V or a public key to be
used for session encryption, may be incorporated as well.
The security of the protocol for P follows from the fact that x4 has been chosen
at random and does not appear in the formula demonstrated. Speciﬁcally, assum-
ing that the underlying DL function is one-way, it follows from Propositions 3.3.4

104
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
P
V
SYSTEM PARAMETERS
(q, g1, g2, g3, g4) := IDLREP(1k)
KEY SET-UP
Attributes: x1, x2, x3 ∈Zq
x4 ∈R Zq
Secret key: (x1, . . . , x4)
Public key:
h := 4
i=1 gxi
i
Additional information:
Hq,g4(·)
PROTOCOL
w1, w2 ∈R Zq
a := g2w1
1
g4w1
2
gw1
3 gw2
4
c := Hq,g4(h, m, F, a)
r1 := cx3 + w1 mod q
r2 := cx4 + w2 mod q
c, r1, r2
−−−−−−→
c ?= Hq,g4(h, m, F,
g2r1+3c
1
g4r1+5c
2
gr1
3 gr2
4 h−c)
Figure 3.2: Protocol for Example 3.3.9.

3.3 FORMULAE WITH ZERO OR MORE “AND” CONNECTIVES
105
and 3.3.8 that the signed proof is unforgeable and unmodiﬁable in the random oracle
model. Moreover, it does not leak more information about (x1, x2, x3) than the valid-
ity of the formula; this holds even if P demonstrates arbitrarily many other formulae
involving only x1, x2, x3, and V can adaptively choose in each protocol execution
which formula is to be demonstrated and which message is to be signed. As a conse-
quence, P is ensured that the data disclosed in all its showing protocol executions is
no more than the aggregate of the information explicitly disclosed in each individual
execution.
In accordance with the proof of Proposition 3.3.4, the powers of g4 are cleanly
“separated” from the other products of powers, because x4 does not appear in the
formula demonstrated. In particular, the computations corresponding to the powers
of g4 can all be performed by proving knowledge of the discrete logarithm of gx4
4
with respect to g4, using the Schnorr proof of knowledge. This property, which can
easily be seen to hold in general, will be of major importance in Sections 6.3 and 6.4,
where it is shown how to lift the techniques of this chapter to the smartcard setting.
3.3.2
Technique based on the RSAREP function
To base the proof technique on the hardness of inverting the RSA function, con-
sider P having to demonstrate the system of linear relations (3.2). As described
in Section 3.2, in this case P commits to the attributes (x1, . . . , xl) by means of
h := gx1
1 · · · gxl
l xv
l+1, where xl+1 is chosen at random from Z
∗
n.
The proof of the following proposition is similar to that of Proposition 3.3.1.
Proposition 3.3.10. P can prove knowledge of an RSA-representation of
(
t
i=1
gbi
π(l−t+i))−1h
with respect to

gπ(1)
t
i=1
g−αi1
π(l−t+i), . . . , gπ(l−t)
t
i=1
g−αi,l−t
π(l−t+i), v

if and only if it knows a set of attributes that satisﬁes the formula.
The RSA-representation P can prove knowledge of is (xπ(1), . . . , xπ(l−t), xl+1).
Corollary 3.3.11. Regardless of the formula demonstrated by P, the proof of knowl-
edge in Proposition 3.3.10 is also a proof of knowledge of an RSA-representation of
h with respect to (g1, . . . , gl, v).
The proof of the following result is similar to that of Proposition 3.3.4.

106
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
Proposition 3.3.12. Let P demonstrate formulae using a proof of knowledge as de-
scribed in Proposition 3.3.10 with the extra property that it is statistically witness-
indistinguishable. For any distribution of (x1, . . . , xl), whatever information V in an
adaptively chosen formula attack can compute about (x1, . . . , xl) can also be com-
puted using merely its a priori information and the status of the formulae requested.
As in the case of the DLREP function, it is beneﬁcial to implement the proof of
knowledge in Proposition 3.3.10 using the witness-indistinguishable proof of knowl-
edge of Section 2.4.4. The resulting expressions can be expanded, so that P and
V can use a single precomputed table for simultaneous repeated squaring, regard-
less of the formulae demonstrated. This is straightforward, and so we refrain from
a detailed stepwise description of the resulting protocol. For later reference, in Sec-
tions 5.4 and 6.3, the protocol is depicted in Figure 3.3. Note that V may alternatively
apply the mod v operator to each of rl−t+1, . . . , rl, and multiply the corresponding
“junk” factor,
t
i=1
g
(bic−	l−t
j=1 αijrj)divv
π(l−t+i)
,
into rl+1 before applying the veriﬁcation relation.
It is easy to see that the protocol is honest-veriﬁer zero-knowledge. The following
three propositions are straightforward analogues of results stated for the DLREP-
based setting, and can be proved in a similar manner.
Proposition 3.3.13. Suppose that the proof of knowledge in Proposition 3.3.12 is re-
alized by substituting the witness-indistinguishable proof of knowledge described in
Section 2.4.4, and that V’s challenge is formed by hashing at least a. If the RSA
function used to implement P’s commitment is one-way, then non-interactively is-
sued signed proofs are unforgeable in the random oracle model, regardless of the
formula(e) demonstrated and the distribution of (x1, . . . , xl).
Proposition 3.3.14. Let l ≥2, let xl be the outcome of a random coin ﬂip by P,
and let P only demonstrate formulae in which xl does not appear. Suppose that
the proof of knowledge in Proposition 3.3.10 is realized by substituting the witness-
indistinguishable proof of knowledge described in Section 2.4.4, and that V’s chal-
lenge is formed by hashing at least a. If the RSA function used to implement P’s
commitment is one-way, and P does not perform more than polylogarithmically
many formula demonstrations, then interactively issued signed proofs are provably
unforgeable in the random oracle model, regardless of the formula(e) demonstrated
and the distribution of (x1, . . . , xl−1).
The remarks made about the coin ﬂip in Proposition 3.3.7 apply here as well.
Proposition 3.3.15. Non-interactively (interactively) issued signed proofs are prov-
ably unmodiﬁable in the random oracle model, subject to the conditions of Propo-
sition 3.3.13 (Proposition 3.3.14), in case a uniquely identifying description of the
formula is hashed along when computing V’s challenge.

3.3 FORMULAE WITH ZERO OR MORE “AND” CONNECTIVES
107
P
V
SYSTEM PARAMETERS
(n, v, g1, . . . , gl) := IRSAREP(1k)
KEY SET-UP
Attributes: x1, . . . , xl ∈Zv
xl+1 ∈R Z
∗
n
Secret key: (x1, . . . , xl, xl+1)
Public key:
h := l
i=1 gxi
i xv
l+1
PROTOCOL
w1, . . . , wl−t ∈R Zv
wl+1 ∈R Z
∗
n
a := l−t
i=1 gwi
π(i)
t
i=1 g
−	l−t
j=1 αijwj
π(l−t+i)
wv
l+1
a
−−−−−−−−−−−−−→
c
←−−−−−−−−−−−→
∀i ∈{1, . . . , l −t} :
ri := cxπ(i) + wi mod v
rl+1 := l−t
j=1(gπ(j)
t
i=1 g
−αij
π(l−t+i))(cxπ(j)+wj)divvxc
l+1wl+1
r1, . . . , rl−t, rl+1
−−−−−−−−−−−−−→
∀i ∈{1, . . . , t} :
rl−t+i := bic −	l−t
j=1 αijrj
l
i=1 gri
π(i)rv
l+1h−c ?= a
Figure 3.3: Generic protocol for demonstrating formula (3.3), with v replacing q.

108
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
As with the DLREP function, the alternative measure of restricting all the matrix
entries used to specify the Boolean formulae to sets V such that |V |/q is negligible in
k, instead of hashing along F, restricts the range of formulae that P can demonstrate.
Example 3.3.16. Suppose that P has three attributes x1, x2, x3 ∈Zv, and is to
demonstrate by means of an interactively issued signed proof to V that the formula in
Example 3.3.9 holds. By applying the technique of Proposition 3.3.10, substituting
the proof of knowledge described in Section 2.4.4 and expanding the resulting expres-
sions, we obtain the protocol depicted in Figure 3.4. Assuming that the underlying
RSA function is one-way, and P performs no more than polylogarithmically many
protocol executions, in the random oracle model the signed proof is unforgeable and
unmodiﬁable. Moreover, it does not leak more information about (x1, x2, x3) than
the validity of the formula; this holds even if P demonstrates arbitrarily many other
formulae about its attributes.
As in Example 3.3.9, m denotes an (optional) message agreed on between the
parties and F denotes a description uniquely identifying the formula demonstrated.
Examples of data that could be included in m are a nonce to protect against replay,
an identiﬁer of V, a public key to be used for session encryption, and a free-form
message.
When forming c, the description of any other formula that is implied by F may
be hashed along instead of F itself. In addition, if the protocol is performed inter-
actively, V can blind a. In Section 5.3 we will show how this enables V to uncon-
ditionally hide (any part of) the formula that has been demonstrated. However, P
and V cannot form a signed proof for a formula that does not apply to P’s RSA-
representation, according to the property of unmodiﬁability.
A notable aspect of the protocol is that the computations for the numbers that
are raised to the power v can all be performed by proving knowledge of the v-th
root of xv
5, using the Guillou-Quisquater proof of knowledge. More generally, the
computations involving x4 and x5 can be performed by proving knowledge of an
RSA-representation of gx4
4 xv
5 with respect to (g4, v). This clean separation can easily
be seen to hold in general, and will be of major importance in Sections 6.3 and 6.4.
3.4
Formulae with one “NOT” connective
We now show how to demonstrate satisﬁable formulae from proposition logic with
zero or more “AND” connectives, exactly one “NOT” connective, and no other con-
nectives.
3.4.1
Technique based on the DLREP function
Any consistent system consisting of zero or more independent linear relations and
one linear inequality (i.e., a linear relation where “=” is replaced by “̸=”) can be

3.4 FORMULAE WITH ONE “NOT” CONNECTIVE
109
P
V
SYSTEM PARAMETERS
(q, g1, g2, g3, g4, g5) := IRSAREP(1k)
KEY SET-UP
Attributes: x1, x2, x3 ∈Zq
x4 ∈R {0, 1}
x5 ∈R Z
∗
n
Secret key: (x1, . . . , x4, x5)
Public key:
h := 4
i=1 gxi
i xv
5
Additional information:
Hn,v(·)
PROTOCOL
w1, w2 ∈R Zv
w3 ∈R Z
∗
n
a := g2w1
1
g4w1
2
gw1
3 gw2
4 wv
3
a
−−−−−−−→
c := Hn,v(h, m, F, a)
c
←−−−−−−−
r1 := cx3 + w1 mod v
r2 := cx4 + w2 mod v
r3 := (g2
1g4
2g3)(cx3+w1)divvg(cx4+w2)divv
4
xc
5w3
r1, r2, r3
−−−−−−−→
c ?= Hn,v(h, m, F,
g2r1+3c
1
g4r1+5c
2
gr1
3 gr2
4 rv
3h−c)
Figure 3.4: Protocol for Example 3.3.16.

110
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
written as a system of linear relations by introducing a non-zero difference term,
ϵ ∈Z
∗
q. Using Gaussian elimination, the system can be represented by the matrix
equation





α11
. . .
α1,l−t
1
0
. . .
0
α21
. . .
α2,l−t
0
1
. . .
0
...
...
...
...
...
...
αt1
. . .
αt,l−t
0
0
. . .
1










xπ(1)
xπ(2)
...
xπ(l)




=





b1 −f1ϵ
b2 −f2ϵ
...
bt −ftϵ




,
(3.4)
where t ≥1. (Example 3.4.7 will clarify the process.) The coefﬁcients αij are
elements of Zq, and f1, . . . , ft are numbers in Zq, not all equal to 0 mod q. Clearly,
it can always be ensured that f1, say, is equal to 1. We may assume that t ≤l, because
if t = l+1 then V can verify the applicability of the formula without communicating
with P.
Our technique for demonstrating the Boolean formula that corresponds to the
system (3.4) is based on the following result. Recall that P commits to the attributes
(x1, . . . , xl) by means of h := l
i=1 gxi
i .
Proposition 3.4.1. P can prove knowledge of a DL-representation of
t
i=1
gfi
π(l−t+i)
with respect to
 t
i=1
gbi
π(l−t+i)h−1, gπ(1)
t
i=1
g−αi1
π(l−t+i), . . . , gπ(l−t)
t
i=1
g−αi,l−t
π(l−t+i)

if and only if it knows a set of attributes that satisﬁes the system (3.4).
Proof. If (x1, . . . , xl) satisﬁes system (3.4), then
h
=
l
i=1
g
xπ(i)
π(i)
=
(
l−t

i=1
g
xπ(i)
π(i) )(
t
i=1
g
bi−fiϵ−	l−t
j=1 αijxπ(j)
π(l−t+i)
)
=
(
t
i=1
gbi
π(l−t+i))(gπ(1)
t
i=1
g−αi1
π(l−t+i))xπ(1) · · · (gπ(l−t)
t
i=1
g−αi,l−t
π(l−t+i))xπ(l−t) ·
(
t
i=1
g−fi
π(l−t+i))ϵ.

3.4 FORMULAE WITH ONE “NOT” CONNECTIVE
111
By dividing both sides of the equation by h, as well as by (t
i=1 g−fi
π(l−t+i))ϵ, we see
that (t
i=1 gfi
π(l−t+i))ϵ equals
((
t
i=1
gbi
π(l−t+i))h−1)(gπ(1)
t
i=1
g−αi1
π(l−t+i))xπ(1) · · · (gπ(l−t)
t
i=1
g−αi,l−t
π(l−t+i))xπ(l−t).
Since ϵ ̸= 0 mod q, both sides can be raised to the power δ, where δ denotes ϵ−1 mod
q. From this we see that the DL-representation that P can prove knowledge of is
(δ, xπ(1)δ mod q, . . . , xπ(l−t)δ mod q).
To prove the converse, suppose that P convinces V with non-negligible success prob-
ability. There exists a polynomial-time knowledge extractor K that outputs with non-
negligible success probability a DL-representation (y0, . . . , yl−t). From the fact that
t
i=1 gfi
π(l−t+i) equals
(
t
i=1
gbi
π(l−t+i)h−1)y0(gπ(1)
t
i=1
g−αi1
π(l−t+i))y1 · · · (gπ(l−t)
t
i=1
g−αi,l−t
π(l−t+i))yl−t
it follows that
hy0 =
l−t

i=1
gyl−t
π(i)
t
i=1
g
biy0−fi−	l−t
j=1 αijyj
π(l−t+i)
.
If y0 = 0 mod q then
(y1, . . . , yl−t, −f1 −
l−t

j=1
α1jyj mod q, . . . , −ft −
l−t

j=1
αtjyj mod q)
(3.5)
is a DL-representation of 1 with respect to (gπ(1), . . . , gπ(l)), and two cases can be
distinguished:
• If this is the trivial DL-representation, then y1, . . . , yl−t, f1, . . . , ft must all
be zero, in addition to y0. But this is a contradiction, because t ≥1 and at
least one of f1, . . . , ft is unequal to 0 mod q, by virtue of the presence of one
“NOT” connective.
• If this is a non-trivial DL-representation of 1, then < P, V> has computed a
DL-representation of 1 other than the trivial one. (If P does not know a rep-
resentation of h then K can be used directly to compute DL-representations.)
According to Proposition 2.3.3 this contradicts the assumption that the DL
function is one-way.

112
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
Therefore, y0 ̸= 0 mod q, and it follows that (y1y−1
0 , . . . , yl−ty−1
0 , b1 −f1y−1
0
−
y−1
0
	l−t
j=1 α1jyj, . . . , bt−fty−1
0 −y−1
0
	l−t
j=1 αtjyj) is a DL-representation of h with
respect to (gπ(1), . . . , gπ(l)). This must be the DL-representation (xπ(1), . . . , xπ(l)),
for the same reason as in the proof of Proposition 3.3.1.
It remains to check that the DL-representation satisﬁes the formula (3.4). From
the left-hand side of the matrix equation (3.4) it follows, for all i ∈{1, . . ., t}, that
l−t

j=1
αijxπ(j) + xπ(l−t+i)
=
l−t

j=1
αij(yjy−1
0 ) + bi −fiy−1
0
−y−1
0
l−t

j=1
αijyj
=
y−1
0
l−t

j=1
αijyj + bi −fiy−1
0
−y−1
0
l−t

j=1
αijyj
=
bi −fiy−1
0
mod q.
Since y0 ̸= 0 mod q, this is equal to the i-th entry in the vector on the righthand side;
note that we have y−1
0
= ϵ mod q. This completes the proof.
As in the case of Proposition 3.3.1, the expressions appearing in this proposition are
fairly intimidating, but the process of deriving them is simple. In addition to the
two steps of substitution and regrouping by collecting terms, we now also collect the
terms that are raised to the power ϵ and move the resulting expression to the left-hand
side. Example 3.4.7 will illustrate the process.
The following property is implicit in the proof of Proposition 3.4.1, and will be
of major importance in Sections 5.5.2 and 6.3.
Corollary 3.4.2. Regardless of the formula demonstrated by P, the proof of knowl-
edge in Proposition 3.4.1 is also a proof of knowledge of a DL-representation of h
with respect to (g1, . . . , gl).
We now extend the category of adaptively chosen formula attacks deﬁned in Deﬁ-
nition 3.3.3. This time V may request the demonstration of formulae of the form (3.3)
as well as of the form (3.4).
Proposition 3.4.3. Let P only demonstrate formulae in which xl does not appear,
using a proof of knowledge as described in Proposition 3.4.1 with the property that
it is statistically witness-indistinguishable. For any distribution of (x1, . . . , xl−1),
whatever information V in an adaptively chosen formula attack can compute about
(x1, . . . , xl−1) can also be computed using merely its a priori information and the
status of the formulae requested.
Proof. Consider ﬁrst the demonstration of a single formula. If xl does not appear in
the formula (3.4), then in Proposition 3.4.1 the generator gl appears separately in the
tuple with respect to which P proves knowledge of a DL-representation. In particu-
lar, P proves knowledge of a DL-representation (ϵ−1 mod q, y1, . . . , yj, xlϵ−1 mod

3.4 FORMULAE WITH ONE “NOT” CONNECTIVE
113
q) of a number in Gq with respect to a tuple (g∗
0, . . . , g∗
j , gl), for some j ∈{0, . . . , l−
1} and numbers g∗
0, . . . , g∗
j in Gq that depend on the formula demonstrated. The set
{y1, . . . , yj} is a subset of
{x1ϵ−1 mod q, . . . , xl−1ϵ−1 mod q}.
Clearly, xlϵ−1 mod q is uniformly distributed over Zq, because xl has been chosen
at random by P and ϵ−1 ̸= 0 mod q. Since gl is a generator of Gq, for any tuple
(y1, . . . , yj) ∈(Zq)j and for any ϵ ∈Z
∗
q there is exactly one xl such that (ϵ−1 mod
q, y1, . . . , yj, xlϵ−1 mod q) is the DL-representation that P proves knowledge of.
Because the proof of knowledge is witness-indistinguishable, and xl has been cho-
sen at random by P, it follows that no information is revealed about (x1, . . . , xl−1)
beyond the status of the formula. In particular, no information about ϵ leaks.
The rest of proof is as in Proposition 3.3.4.
A practical implementation of the proof of knowledge in Proposition 3.4.3 can be
realized by substituting the perfect witness-indistinguishable proof of knowledge
described in Section 2.4.3, and expanding the resulting expressions. The resulting
(generic) protocol steps are as follows:
Step 1. P generates at random l−t+1 numbers, w0, . . . , wl−t ∈Zq, and computes
a := h−w0
l−t

i=1
gwi
π(i)
t
i=1
g
biw0−	l−t
j=1 αijwj
π(l−t+i)
.
P then sends the initial witness a to V.
Step 2. Let δ := ϵ−1 mod q. P computes a set of responses, responsive to V’s
challenge c ∈Zs, as follows:
r0
:=
cδ + w0 mod q,
ri
:=
cxπ(i)δ + wi mod q
∀i ∈{1, . . ., l −t}.
P then sends (r0, . . . , rl−t) to V.
V computes
rl−t+i := bir0 −fic −
l−t

j=1
αijrj mod q
∀i ∈{1, . . . , t},
and accepts if and only if the veriﬁcation relation
l
i=1
gri
π(i)h−r0 = a

114
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
P
V
SYSTEM PARAMETERS
(q, g1, . . . , gl) := IDLREP(1k)
KEY SET-UP
Attributes: x1, . . . , xl−1 ∈Zq
xl ∈R Zq
Secret key: (x1, . . . , xl)
Public key:
h := l
i=1 gxi
i
PROTOCOL
w0, . . . , wl−t ∈R Zq
a := h−w0 l−t
i=1 gwi
π(i)
t
i=1 g
biw0−	l−t
j=1 αijwj
π(l−t+i)
a
−−−−−−−−−→
c
←−−−−−−−→
δ := ϵ−1 mod q
r0 := cδ + w0 mod q
∀i ∈{1, . . . , l −t} :
ri := cxπ(i)δ + wi mod q
r0, . . . , rl−t
−−−−−−−−−→
∀i ∈{1, . . . , t} :
rl−t+i := bir0 −fic −	l−t
j=1 αijrj mod q
l
i=1 gri
π(i)h−r0 ?= a
Figure 3.5: Generic protocol for demonstrating formula (3.4).

3.4 FORMULAE WITH ONE “NOT” CONNECTIVE
115
holds.
For later reference, in Sections 5.4 and 6.3, the protocol is depicted in Figure 3.5.
As with the proof of knowledge in Section 2.4.3, the protocol description is generic
in the sense that the binary size of s and the process of generating c have not yet been
speciﬁed.
The following proposition will be of importance in Section 3.5, and can be proved
in a manner similar to the proof of Proposition 3.3.5.
Proposition 3.4.4. The protocol obtained by implementing the proof of knowledge
in Proposition 3.4.3 by means of the proof of knowledge described in Section 2.4.3 is
honest-veriﬁer zero-knowledge.
As suggested by Corollary 3.4.2, the propositions of Section 2.4.3 apply, with
the obvious modiﬁcations. Special care must be taken with respect to signed proofs,
though. By way of example, consider h := gx1
1 gx2
2 , and assume that a formula of the
form x1 ̸= αx2 + β mod q must be demonstrated. The veriﬁcation relation is
gαr1+βr2−c
1
gr1
2 = hr2a.
Now, suppose that c is formed by hashing a and possibly h but not a description of the
formula. In sharp contrast to the situation in Section 3.3.1, where signed proofs for
which the formula description is not hashed along still serve as proofs of knowledge
of a DL-representation of h, the triple (c, r1, r2) does not serve as a signed proof of
knowledge of a DL-representation of h with respect to (g1, g2). To come up with
(h, a) and (c, r1, r2) that meet the veriﬁcation relation, one can pick any h ∈Gq, set
a := h−r2gw1
1 gw2
2
for any (r2, w1, w2) ∈Zq × Zq × Z
∗
q, set c := Hq,g2(h, a), set
r1 := w2, and compute α := (w1 + c −βr2)r−1
1
mod q for any β ∈Zq. To get
around this, a description of the demonstrated formula must be hashed along. (The
alternative is to restrict the matrix entries used to specify the formula to sets V such
that |V |/q is negligible in k.) In the following two propositions, F denotes a unique
description of the formula demonstrated.
Proposition 3.4.5. Suppose that the proof of knowledge in Proposition 3.4.3 is re-
alized by substituting the witness-indistinguishable proof of knowledge described
in Section 2.4.3, and that V’s challenge is formed by hashing at least (a, F). If
the DL function that is used to implement P’s commitment is one-way, then non-
interactively issued signed proofs are provably unforgeable and unmodiﬁable in the
random oracle model, regardless of the formula(e) demonstrated and the distribution
of (x1, . . . , xl−1).
The proof follows by application of Proposition 2.5.2, in light of Corollary 3.4.2
and Proposition 3.4.4.
Proposition 3.4.6. Let l ≥3, let xl−1 be the outcome of a random coin ﬂip by
P, and let P only demonstrate formulae in which both xl−1 and xl do not appear.

116
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
Suppose that the proof of knowledge in Proposition 3.4.1 is realized by substitut-
ing the witness-indistinguishable proof of knowledge described in Section 2.4.3, and
that V’s challenge is formed by hashing at least (a, F). If the DL function used to
implement P’s commitment is one-way, and P performs no more than polylogarith-
mically many formula demonstrations, then interactively issued signed proofs are
provably unforgeable and unmodiﬁable in the random oracle model, regardless of
the formula(e) demonstrated and the distribution of (x1, . . . , xl−2).
As before, if h is not ﬁxed but may be chosen in a substantially arbitrary manner
by P, then h should be hashed along when forming V’s challenge.
According to the unmodiﬁability property, P and V cannot construct a signed
proof for a formula that does in fact not apply to P’s DL-representation. On the
other hand, as we will show in Section 5.3, it is possible for V to obtain a signed
proof for any formula F ′ implied by F, while being convinced itself of F.
We end with a practical example.
Example 3.4.7. Suppose P has three attributes x1, x2, x3 ∈Zq, and is to demon-
strate by means of a non-interactively issued signed proof to V that the following
formula holds:
NOT(x1 + 3x2 + 5x3 = 7) AND (3x1 + 10x2 + 18x3 = 23).
With ϵ denoting 7 −(x1 + 3x2 + 5x3) mod q, this formula is equivalent to the state-
ment that there exists an ϵ ̸= 0 such that
(x1 = 1 + 4x3 −10ϵ) AND (x2 = 2 −3x3 + 3ϵ).
To demonstrate this formula, P generates a random x4 ∈Zq, and forms the commit-
ment h := 4
i=1 gxi
i . If the formula holds true, then by substitution we get
h
=
gx1
1 gx2
2 gx3
3 gx4
4
=
g1+4x3−10ϵ
1
g2−3x3+3ϵ
2
gx3
3 gx4
4 ,
and by regrouping in three manners (according to constants, variables, and ϵ), we
obtain
h
=
(g1
1g2
2)(g4
1g−3
2 g3)x3gx4
4 (g−10
1
g3
2)ϵ.
Finally, we divide both sides by h, as well as by (g−10
1
g3
2)ϵ, and raise both sides to
the power ϵ−1 mod q, arriving at
g10
1 g−3
2
=
(g1
1g2
2h−1)1/ϵ(g4
1g−3
2 g3)x3/ϵgx4/ϵ
4
.
Therefore, P can prove knowledge of a DL-representation of g10
1 g−3
2
with respect
to the triple (g1
1g2
2h−1, g4
1g−3
2 g3, g4). According to Proposition 3.4.1, this is also

3.4 FORMULAE WITH ONE “NOT” CONNECTIVE
117
P
V
SYSTEM PARAMETERS
(q, g1, g2, g3, g4) := IDLREP(1k)
KEY SET-UP
Attributes: x1, x2, x3 ∈Zq
x4 ∈R Zq
Secret key: (x1, . . . , x4)
Public key:
h := 4
i=1 gxi
i
Additional information:
Hq,g4(·)
PROTOCOL
w1, w2, w3 ∈R Zq
a := gw1+4w2
1
g2w1−3w2
2
gw2
3 gw3
4 h−w1
c := Hq,g4(h, m, F, a)
ϵ := 7 −(x1 + 3x2 + 5x3) mod q
δ := ϵ−1 mod q
r1 := cδ + w1 mod q
r2 := cx3δ + w2 mod q
r3 := cx4δ + w3 mod q
c, r1, r2, r3
−−−−−−−−→
c ?= Hq,g4(h, m, F,
gr1+4r2−10c
1
g2r1−3r2+3c
2
gr2
3 gr3
4 h−r1)
Figure 3.6: Protocol for Example 3.4.7.

118
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
sufﬁcient to convince V. By substituting the proof of knowledge described in Sec-
tion 2.4.3, and expanding the resulting expressions, we obtain the protocol depicted
in Figure 3.6.
The security of the protocol for P follows from the fact that x4 has been chosen
at random and does not appear in the formula demonstrated. Speciﬁcally, assuming
that the underlying DL function is one-way, in the random oracle model the signed
proof is unforgeable and unmodiﬁable. Moreover, it does not leak more information
about (x1, x2, x3) than the validity of the formula; this holds even if P demonstrates
arbitrarily many other formulae (with x4 not appearing in any of these).
A noteworthy aspect of the protocol is that the computations corresponding to the
powers of g4 can all be performed by proving knowledge of the discrete logarithm of
(gx4
4 )1/ϵ with respect to g4, using the Schnorr proof of knowledge, because x4 does
not appear in the formula demonstrated. This property can easily be seen to hold in
general, and will be of great importance in Sections 6.3 and 6.4.
3.4.2
Technique based on the RSAREP function
To base the technique on the hardness of inverting the RSA function, consider P
having to demonstrate formula (3.4), with “mod v” replacing “mod q,” and ϵ ∈
Z
∗
v. Recall that P commits to (x1, . . . , xl) by means of h := gx1
1 · · · gxl
l xv
l+1.
Proposition 3.4.8. P can prove knowledge of an RSA-representation of
t
i=1
gfi
π(l−t+i)
with respect to
 t
i=1
gbi
π(l−t+i)h−1, gπ(1)
t
i=1
g−αi1
π(l−t+i), . . . , gπ(l−t)
t
i=1
g−αi,l−t
π(l−t+i), v

if and only if it knows a set of attributes that satisﬁes the system (3.4).
Proof. If (x1, . . . , xl) satisﬁes the system (3.4), then by regrouping expressions it is
seen that
(
t
i=1
gfi
π(l−t+i))ϵ
equals
(
t
i=1
gbi
π(l−t+i)h−1) (gπ(1)
t
i=1
g−αi1
π(l−t+i))xπ(1) · · · (gπ(l−t)
t
i=1
g−αi,l−t
π(l−t+i))xπ(l−t)xv
l+1.

3.5 ATOMIC FORMULAE CONNECTED BY “OR” CONNECTIVES
119
Because inequality holds, ϵ ̸= 0 mod v and so P can compute integers e, f ∈Z
such that e ϵ + fv = 1, by using the extended Euclidean algorithm. (This can be
always be done, because v is prime.) It follows that

e mod v, exπ(1) mod v, . . . , exπ(l−t) mod v, z

is the RSA-representation sought for, where z denotes the expression
(
t
i=1
gbi
π(l−t+i)h−1)edivv
l−t

j=1

gπ(j)
t
i=1
g−αij
π(l−t+i)
(exπ(j))divv
xe
l+1(
t
i=1
gfi
π(l−t+i))f.
The proof of the converse is similar to the second part of the proof of Proposi-
tion 3.4.1, with the additional application of normalizations where needed.
The protocol can be efﬁciently implemented by using the proof of knowledge de-
scribed in Section 2.4.4 and expanding the resulting expressions. The direct analogue
of Proposition 3.4.3 can be proved, as well as the unforgeability and unmodiﬁability
of signed proofs (assuming at least a and F are hashed along when forming c). Since
the necessary adaptations are straightforward, a further description is omitted.
3.5
Atomic formulae connected by “OR” connectives
We now show how P can demonstrate Boolean formulae in which subformulae, of
either one of the two forms discussed in the previous sections, are connected by zero
or more “OR” connectives.
3.5.1
Technique based on the DLREP function
The following deﬁnition deﬁnes the basic building block for the technique in this
section.
Deﬁnition 3.5.1. An atomic formula is one in which linear relations over Zq are
connected by zero or more “AND” connectives and at most one “NOT” connective.
Any atomic formula can be described either by system (3.2) or by system (3.4).
Consequently, any atomic formula applying to P’s attributes can be demonstrated
using either the method described in Section 3.3 or that described in Section 3.4.
Consider now the situation in which P is to demonstrate a satisﬁable Boolean
formula F of the form
F = F1 OR . . . OR Fj,
(3.6)
for some j ≥1 that may be polynomial in the security parameter k.
Each of
F1, . . . , Fj is an atomic formula. If F holds true for P’s attributes, then at least

120
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
one of the j atomic subformulae holds true, but V should not be able to learn which
one(s). Suppose that (at least) Ft holds true, for some t ∈{1, . . ., j}.
In the following protocol for demonstrating F, it is assumed that atomic formulae
are demonstrated by substituting the witness-indistinguishable proof of knowledge
described in Section 2.4.3 into the proof of knowledge in either Proposition 3.3.1 or
Proposition 3.4.1 (whichever is appropriate):
Step 1. Using the honest-veriﬁer zero-knowledge simulator that exists according to
Proposition 3.3.5 or 3.4.4, P generates j−1 transcripts of subformulae demon-
strations for F1, . . . , Ft−1, Ft+1, . . . , Fj. For each i ∈{1, . . . , j} \ {t}, the
simulated proof for formula Fi involves a random self-chosen challenge that
we denote by ci, an initial witness, and one or more self-chosen responses. For
subformula Ft, P generates an initial witness in the manner speciﬁed by the
standard protocol for demonstrating an atomic formula (to prepare for a gen-
uine proof). P then sends all j initial witnesses, referred to as its initial witness
set, to V.
Step 2. V generates a random challenge c ∈Zs, and sends it to P.
Step 3. P forms j response sets, as follows. P computes ct := c −	
i̸=t ci mod
s. Responsive to challenge ct, P computes its responses corresponding to
the demonstration of Ft, in the manner described in Step 2 of the protocol
in either Section 3.3 or Section 3.4 (whichever is appropriate). For each of
the remaining j −1 subformulae, P uses the self-chosen responses from the
simulated formulae demonstrations prepared in Step 1. P then sends all j
response sets and (c1, . . . , cj) to V.
V veriﬁes that c = 	j
i=1 ci mod s. If this veriﬁcation holds, then for each of the j
atomic subformulae it applies the veriﬁcation relation for that subformula. Specif-
ically, V veriﬁes the demonstration of Fi by applying the veriﬁcation relation that
applies in the standard protocol for demonstrating Fi, using the i-th initial witness
and response set provided by P and the challenge ci. V accepts if and only if the j
challenges sum up correctly and all j veriﬁcation relations hold; together, these j +1
veriﬁcation relations make up the veriﬁcation process for the demonstration of F.
Note that the protocol encompasses the protocols of Sections 3.3 and 3.4 as spe-
cial cases.
Proposition 3.5.2. In the protocol for demonstrating F, assume that P only demon-
strates formulae F in which xl does not appear. The following properties hold:
(a) The protocol is complete and sound.
(b) The protocol is a proof of knowledge of a DL-representation of h with respect
to the tuple (g1, . . . , gl).

3.5 ATOMIC FORMULAE CONNECTED BY “OR” CONNECTIVES
121
(c) For any distribution of (x1, . . . , xl−1), whatever information V in an adap-
tively chosen formula attack 2 can compute about (x1, . . . , xl−1) can also be
computed using merely its a priori information and the status of the formulae
requested.
Proof. We only sketch the proof here; the details are easy to ﬁll in.
(a) Completeness is veriﬁed straightforwardly. Soundness follows from the con-
dition that the ci’s have to sum up to V’s challenge c, so that P cannot simulate the
demonstration for all j subformulae. For at least one subformula P has to use a chal-
lenge that it cannot anticipate: it must perform a genuine proof of knowledge for that
subformula. Because the demonstration of an atomic subformula is a sound proof of
knowledge, P can do this only if the subformula indeed holds true for its attributes;
in other words, if F holds true.
(b) The soundness of the protocol for demonstrating F implies that at least one of
the atomic subformulae holds true for P’s attributes. According to Corollaries 3.3.2
and 3.4.2, the proof of knowledge for this atomic subformula is also a proof of knowl-
edge of a DL-representation of h with respect to (g1, . . . , gl).
(c) The third claim follows from the perfect simulatability of the j −1 subfor-
mulae demonstrations and the fact that the relation 	j
i=1 ci = c mod s reveals no
information on which j −1 challenges have been self-chosen by P, regardless of the
manner in which c is formed.
Care must be taken in a practical implementation that the subformula for which a
genuine proof is performed cannot be deduced by timing the delay between sending
V’s challenge and receiving the j response sets.
To obtain a signed proof, V’s challenge c should be generated as a sufﬁciently
strong one-way hash of at least the j initial witnesses, a description of F, and an
(optional) message m. If h is not ﬁxed, then it should be hashed along as well.
The signed proof consists of (c1, . . . , cj) and the j response sets, or of the j initial
witnesses and the j response sets. If the protocol is performed non-interactively then
P need not send either its initial witness set or its j challenges to V, since they can
be recovered by V.
Proposition 3.5.3. In Proposition 3.5.2, if the DL function used to implement P’s
commitment is one-way, and V’s challenge is formed by hashing at least all j ini-
tial witnesses and F, then non-interactively issued signed proofs are provably un-
forgeable and unmodiﬁable in the random oracle model, regardless of the formula(e)
demonstrated and the distribution of (x1, . . . , xl−1).
Proposition 3.5.4. Let l ≥3, let xl−1 be the outcome of a random coin ﬂip by P, and
let P only demonstrate formulae in which both xl−1 and xl do not appear. If the DL
function used to implement P’s commitment is one-way, V’s challenge is formed by
2This time, V may request the demonstration of any Boolean formula of the form (3.6).

122
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
hashing at least all j initial witnesses and F, and P performs no more than polylog-
arithmically many formula demonstrations, then interactively issued signed proofs
are provably unforgeable and unmodiﬁable in the random oracle model, regardless
of the formula(e) demonstrated and the distribution of (x1, . . . , xl−2).
Again, the remarks made about the coin ﬂip in Proposition 3.3.7 apply here as
well.
If j ≥2 in formula (3.6) the protocol is non-trivially witness-indistinguishable,
and in Proposition 3.5.4 we can omit the requirement that xl−1 be random and do not
appear in the formulae demonstrated by P.
The protocol for demonstrating F admits several variations. For example:
• The relation 	j
i=1 ci = c mod s can be replaced by any other relation with
the property that, for any c, the selection of any j −1 challenges uniquely
determines the remaining challenge. For example, for s a prime one can use
j
i=1 ci = c mod s or, if s is a power of 2, ⊕j
i=1ci = c, where ⊕denotes the
bitwise exclusive-or operator.
• Instead of simulating all but one of the subformula demonstrations, P could
perform a genuine proof of knowledge for all subformulae that hold true and
simulate the demonstration only for those that do not hold true.
Both variations bring no noteworthy performance gain, and we will see in Section 6.3
that they are disadvantageous when lifting the formulae demonstration techniques to
the smartcard setting. Moreover, in Sections 5.3 and 5.4.2 we will show that the
relation 	j
i=1 ci = c mod q can be exploited to improve efﬁciency and privacy in
applications where V must relay signed proofs to the CA. For these reasons we will
not consider the two variations any further.
Example 3.5.5. Suppose P has three attributes x1, x2, x3 ∈Zq, and is to demon-
strate by means of a non-interactively issued signed proof to V that the following
formula holds:

(x1 + 2x2 −10x3 = 13) AND (x2 −4x3 = 5)

OR

NOT(x1 + 3x2 + 5x3 = 7) AND (3x1 + 10x2 + 18x3 = 23)

Assume for concreteness that
(x1 + 2x2 −10x3 = 13) AND (x2 −4x3 = 5)
holds, and that
NOT(x1 + 3x2 + 5x3 = 7) AND (3x1 + 10x2 + 18x3 = 23)

3.6 DEMONSTRATING ARBITRARY BOOLEAN FORMULAE
123
does not necessarily hold. To demonstrate the formula, P generates a random x4 ∈
Zq, and forms the commitment h := 4
i=1 gxi
i . As we have seen in Example 3.3.9,
to demonstrate the ﬁrst subformula P proves knowledge of a DL-representation
of h/(g3
1g5
2) with respect to (g2
1g4
2g3, g4).
According to Example 3.4.7, the sec-
ond subformula requires a proof of knowledge of a DL-representation of g10
1 g−3
2
with respect to (g1g2
2h−1, g4
1g−3
2 g3, g4); P simulates this demonstration, using a
self-chosen challenge and self-chosen responses. The resulting protocol is depicted
in Figure 3.7. Here, m denotes an (optional) message and F denotes a descrip-
tion uniquely identifying the formula demonstrated. The signed proof consists of
(c1, c2, r1, r2, r3, r4, r5). Assuming that the underlying DL function is one-way, in
the random oracle model the signed proof is unforgeable and unmodiﬁable. More-
over, it does not leak more information about (x1, x2, x3) than the validity of the
formula; this holds even if P demonstrates arbitrarily many other formulae.
3.5.2
Technique based on the RSAREP function
Adaptation to the difﬁculty of inverting the RSA function poses no particular difﬁ-
culties, and is therefore omitted.
3.6
Demonstrating arbitrary Boolean formulae
We are now prepared for the ﬁnal step: demonstrating arbitrary satisﬁable Boolean
formulae.
3.6.1
Technique based on the DLREP function
Suppose P is to demonstrate an arbitrary Boolean formula that applies to its at-
tributes. Without loss of generality, we assume that F is of the conjunctive normal
form,
F = F1 AND . . . AND Fj,
(3.7)
for some j ≥1 that may be polynomial in k, where each of F1, . . . , Fj are atomic
subformulae of the form (3.6). The indices j here and in formula (3.6) do not bear
any relation to one another. Likewise, each subformula may be composed of an arbi-
trary and distinct number of subformulae. The issue of writing an arbitrary Boolean
formula in the form (3.7) is outside of the scope of this book.
Our technique for demonstrating F is as follows. F holds true for P’s attributes
if and only if F1, . . . , Fj all hold true. To demonstrate F, P demonstrates each of
F1, . . . , Fj by means of the proof of knowledge described in the previous section,
subject to the following two constraints:
• All j protocol executions are performed in parallel; and

124
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
P
V
SYSTEM PARAMETERS
(q, g1, g2, g3, g4) := IDLREP(1k)
KEY SET-UP
Attributes: x1, x2, x3 ∈Zq
x4 ∈R Zq
Secret key: (x1, . . . , x4)
Public key:
h := 4
i=1 gxi
i
Additional information:
Hq,g4(·)
PROTOCOL
w1, w2, c2, r3, r4, r5 ∈R Zq
a1 := g2w1
1
g4w1
2
gw1
3 gw2
4
a2 := gr3+4r4−10c2
1
g2r3−3r4+3c2
2
gr4
3 gr5
4 h−r3
c := Hq,g4(h, m, F, a1, a2)
c1 := c −c2 mod s
r1 := c1x3 + w1 mod q
r2 := c1x4 + w2 mod q
c1, c2, (r1, r2, r3, r4, r5)
−−−−−−−−−−−−−−−−−→
c := c1 + c2 mod s
c ?= Hq,g4(h, m, F, g2r1+3c1
1
g4r1+5c1
2
gr1
3 gr2
4 h−c1,
gr3+4r4−10c2
1
g2r3−3r4+3c2
2
gr4
3 gr5
4 h−r3)
Figure 3.7: Protocol for Example 3.5.5.

3.6 DEMONSTRATING ARBITRARY BOOLEAN FORMULAE
125
• V’s challenge is the same in all j protocol executions.
V accepts if and only if it accepts P’s demonstration of each of the j subformulae.
Although the two constraints are not strictly necessary, they are preferable in
light of efﬁciency and, more importantly, for the purpose of lifting the protocol to the
smartcard setting, as we will see in Section 6.3. Also, the constraints are desirable
for the purpose of forming signed proofs.
The following proposition follows straightforwardly from Proposition 3.5.2 and
the fact that using the same challenge for all subformulae does not increase P’s cheat-
ing probability.
Proposition 3.6.1. In the protocol for demonstrating F, assume that P only demon-
strates formulae F in which xl does not appear. The following properties hold:
(a) The protocol is complete and sound.
(b) The protocol is a proof of knowledge of a DL-representation of h with respect
to the tuple (g1, . . . , gl).
(c) For any distribution of (x1, . . . , xl−1), whatever information V in an adap-
tively chosen formula attack 3 can compute about (x1, . . . , xl−1) can also be
computed using merely its a priori information and the status of the formulae
requested.
The proof is straightforward. (A description of what is essentially the knowledge
extractor required to prove soundness is contained in the proof of Proposition 5.4.1.)
To obtain a signed proof, V’s challenge c should be generated as a sufﬁciently
strong one-way hash of the j initial witness sets, a description of F, and an (op-
tional) message m. In case h is not ﬁxed a priori, it should be hashed along as well.
The signed proof consists all P’s challenge and response sets, or equivalently of all
P’s initial witness sets and response sets. (As before, instead of hashing along a de-
scription of F one may alternatively restrict all the matrix entries to sets V such that
|V |/q is negligible in k.)
Proposition 3.6.2. In Proposition 3.6.1, if the DL function used to implement P’s
commitment is one-way, and V’s challenge is formed by hashing at least all ini-
tial witnesses and F, then non-interactively issued signed proofs are provably un-
forgeable and unmodiﬁable in the random oracle model, regardless of the formula(e)
demonstrated and the distribution of (x1, . . . , xl−1).
Proposition 3.6.3. Let l ≥3, let xl−1 be the outcome of a random coin ﬂip by P,
and let P only demonstrate formulae F in which both xl−1 and xl do not appear.
If the DL function used to implement P’s commitment is one-way, V’s challenge is
formed by hashing at least all initial witnesses and F, and P performs no more than
3This time, V may request the demonstration of any Boolean formula of the form (3.7).

126
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
polylogarithmically many formula demonstrations, then interactively issued signed
proofs are provably unforgeable and unmodiﬁable in the random oracle model, re-
gardless of the formula(e) demonstrated and the distribution of (x1, . . . , xl−2).
The remarks about the coin ﬂip in Proposition 3.3.7 apply here as well.
We now posses all the machinery for P to demonstrate the example formula (3.1)
in Section 3.1.
Example 3.6.4. Suppose P has three attributes x1, x2, x3 ∈Zq, selected accord-
ing to an arbitrary probability distribution, and is to demonstrate by means of a
non-interactively issued signed proof to V that the example formula (3.1) holds true.
Assume for concreteness that
(x1 + 2x2 −10x3 = 13) AND (x2 −4x3 = 5)
holds. In Example 3.5.5 we have seen how to demonstrate the subformula appearing
before the third “AND” connective. In accordance with Section 3.4, P demonstrates
the remaining part by proving knowledge of a DL-representation of g1 with respect
to (g5
1h−1, g8
1g2, g−11
1
g3, g4). By merging the two protocols in accordance with the
technique described in this section, we obtain the protocol depicted in Figure 3.8.
As before, m denotes a message and F denotes a description uniquely identifying
formula (3.1). Examples of data that could be included in m are a nonce to protect
against replay, an identiﬁer of V, a public key to be used for session encryption,
and a free-form message. The signed proof consists of (c1, c2, r1, . . . , r9). Assuming
that the underlying DL function is one-way, in the random oracle model the signed
proof is unforgeable and unmodiﬁable. Moreover, it does not leak more information
about (x1, x2, x3) than the validity of the formula; this holds even if P demonstrates
arbitrarily many other formulae about its attributes.
The performance estimates at the end of Section 3.1 are readily obtained. Namely,
according to Section 2.2.2, 200-bit challenges and responses sufﬁce for long-term
security. Both P and V, to perform their computations in Gq, can use a precom-
puted table that contains the 31 products of the numbers in the non-empty subsets of
{g1, . . . , g4, h}. Performance can be pushed to the limit by using an elliptic curve
implementation with 20-byte base numbers, but beware of the reservations expressed
in Section 2.2.2. Also, the computational burden for V can be reduced by a factor
of almost 3 by having P send along (a1, a2, a3) (one of c1, c2 may be left out) and
applying batch-veriﬁcation, in the manner described in Section 2.5.3.
3.6.2
Technique based on the RSAREP function
Again, adaptation to the difﬁculty of inverting the RSA function poses no particular
difﬁculties.

3.6 DEMONSTRATING ARBITRARY BOOLEAN FORMULAE
127
P
V
SYSTEM PARAMETERS
(q, g1, g2, g3, g4) := IDLREP(1k)
KEY SET-UP
Attributes: x1, x2, x3 ∈Zq
x4 ∈R Zq
Secret key: (x1, . . . , x4)
Public key:
h := 4
i=1 gxi
i
Additional information:
Hq,g4(·)
PROTOCOL
w1, . . . , w6, c2, r3, r4, r5 ∈R Zq
a1 := g2w1
1
g4w1
2
gw1
3 gw2
4
a2 := gr3+4r4−10c2
1
g2r3−3r4+3c2
2
gr4
3 gr5
4 h−r3
a3 := g5w3+8w4−11w5
1
gw4
2 gw5
3 gw6
4 h−w3
c := Hq,g4(h, m, F, a1, a2, a3)
c1 := c −c2 mod s
r1 := c1x3 + w1 mod q
r2 := c1x4 + w2 mod q
δ := ϵ−1 mod q
r6 := cδ + w3 mod q
r7 := cx2δ + w4 mod q
r8 := cx3δ + w5 mod q
r9 := cx4 + w6 mod q
c1, c2, (r1, . . . , r9)
−−−−−−−−−−−−−→
c := c1 + c2 mod s
c ?= Hq,g4(h, m, F,
g2r1+3c1
1
g4r1+5c1
2
gr1
3 gr2
4 h−c1,
gr3+4r4−10c2
1
g2r3−3r4+3c2
2
gr4
3 gr5
4 h−r3,
g5r6+8r7−11r8−c
1
gr7
2 gr8
3 gr9
4 h−r6)
Figure 3.8: Protocol for Example 3.6.4.

128
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
3.7
Optimizations and extensions
Modulo a small constant factor, the communication and computation complexity of
our proof techniques for atomic formulae are the same as for proofs with full disclo-
sure. In the latter case, P would simply transmit (x1, . . . , xl) to V, and digitally sign
V’s challenge message using the Schnorr or Guillou-Quisquater signature scheme,
say. Thus, our selective disclosure techniques for atomic formulae achieve privacy
essentially for free.
This extreme efﬁciency does not hold when our techniques are used to demon-
strate formulae of the form (3.6) or (3.7), although the increase in communication
and computation complexity is only linear in the number of logical connectives. We
now describe a slight optimization of our techniques for these two cases. To demon-
strate an atomic formula, our techniques have P demonstrate knowledge of a secret
key corresponding to a public key, where the deﬁnition of the public key and of
what constitutes a secret key both depend on the formula demonstrated; see Proposi-
tions 3.3.1 and 3.4.1. In this interpretation, “complex” propositions of the form
“I know a secret key corresponding to public key h and it satisﬁes formula F”
(with h ﬁxed a priori and F atomic) are mapped to simple propositions of the form
“I know a secret key corresponding to public key hi,”
where the “distorted” public key hi is not ﬁxed a priori but derived from h in a
formula-dependent manner, and the deﬁnition of what constitutes a secret key corre-
sponding to hi also depends on F. Cramer, Damg˚ard, and Schoenmakers [123] show
how to demonstrate monotone Boolean formulae over such simple propositions.4
Since the witness-indistinguishable proof of knowledge in Section 2.4.3 satisﬁes their
requirements [123, Corollary 14], their technique can be applied here. The idea is
to dictate the restrictions, according to which P generates its self-chosen challenges
from the challenge message, in accordance with a secret-sharing construction due
to Benaloh and Leichter [25] for the access structure deﬁned by the “dual” of the
formula. Since this technique does not require F to be expressed in the conjunctive
normal form (3.7), the resulting proof of knowledge may be more compact. On the
downside, lifting the optimized demonstration protocols to the smartcard setting (see
Chapter 6) is not always possible without signiﬁcantly increasing the complexity of
the protocol. Therefore, we will not consider this optimization any further.
Another optimization is for V to batch-process all the veriﬁcation relations, one
for each atomic (sub)subformula, in the manner described in Section 2.5.3. Batch-
veriﬁcation may also be applied to the veriﬁcation of multiple protocol executions.
It is possible to use our showing protocol techniques in such a manner that P
can rapidly demonstrate possession of t out of u “qualitative” attributes, for any
4De Santis, Di Crescenzo, Persiano, and Yung [334] independently devised a similar technique.

3.7 OPTIMIZATIONS AND EXTENSIONS
129
t ≤u ≤l. Namely, if each of x1, . . . , xu is guaranteed to be either 1 or 0, then P
can simply demonstrate that 	u
i=1 xi = t mod q. In Chapter 5 we will see that the
guarantee that each xi is either 0 or 1 can come from a CA that encodes the attribute
values into P’s key pair.
The atomic propositions for which Boolean formulae can be demonstrated can be
extended beyond linear relations:
• A technique of Damg˚ard [127] can be adapted to our scenario in order to
demonstrate polynomial relations. Demonstration of
xγ1
1 + β2xγ2
2 + · · · + βkxγl
l = β1 mod q
requires P to spawn in the order of 	l
i=1 γi auxiliary commitments, and to
perform two basic proofs of knowledge for each of these. (Either a proof of
knowledge of a representation or a proof of equality of two secrets; the latter
can be handled using a protocol of Chaum and Pedersen [109] that will also be
used in Section 4.5.2.) This is practical only for low-degree polynomials.5
• Brickell, Chaum, D˚amgard, and van de Graaf [63] show how to demonstrate
that a secret is contained in an interval. Their technique, which can be adapted
to our scenario, is not very practical because it requires polynomially many
repetitions of a three-move protocol with binary challenges. Moreover, the
interval for which P must perform the proof must be three times larger than
the interval one is interested in, to avoid leakage of information (so that P is
actually demonstrating a different statement).
An improvement is due to Schoenmakers [342]. With h = gx1
1 gα
2 , say, to
demonstrate that x1 ∈{0, . . ., 2t −1} the prover discloses t auxiliary commit-
ments
h0 := gb1
1 gα1
2 , . . . , ht−1 := gbt
1 gαt
2 .
The bi’s satisfy 	t−1
i=0 bi2i = x1 and the αi’s are chosen at random subject to
the condition
α =
t−1

i=0
αi2i mod q.
The prover proves that each bi ∈{0, 1}, using our technique in Section 3.5,
and the veriﬁer in addition checks that
t−1

i=0
h2i
i = h.
Generalization to arbitrary intervals is accomplished by proving that x1 is in
the intersection of two appropriately shifted intervals, each of length a power
5Fujisaka and Okamoto [179] proposed another technique that is equally impractical and less elegant.

130
SHOWING PROTOCOLS WITH SELECTIVE DISCLOSURE
of 2. This technique requires the prover to spawn a number of auxiliary com-
mitments that is linear in the size of the interval, and to perform essentially two
Schnorr proofs of knowledge for each of these.
Demonstrating an atomic proposition in both cases involves a serious amount of over-
head, and the practical relevance of demonstrating polynomial relations is unclear.
Therefore we will not consider these techniques any further.
3.8
Bibliographic notes
The technique in Section 3.3 for demonstrating a single linear relation is due to
Brands [54]. The general techniques for demonstrating arbitrary Boolean proposi-
tions, for atomic propositions that are linear relations, originate from Brands [45],
with a summary in Brands [55]. None of the formal security statements and their
proofs have appeared elsewhere previously, nor have the examples.
The suggestion in Section 3.7 to adapt a technique of Damg˚ard [127] to demon-
strate polynomial relations is due to Brands [55], and was later on used by Camenisch
and Stadler [70, 73].
They [74] also rediscovered the simple technique in Sec-
tion 5.2.2 for demonstrating properties of the attributes encoded into different key
pairs, due to Brands [46, page 22] (see also Brands [54]); the resulting proof system
is signiﬁcantly less practical and ﬂexible, though.
The techniques in this chapter have numerous applications that do not necessar-
ily involve digital certiﬁcates. For example, the techniques in Sections 3.3 and 3.4
can be used to improve the undeniable signature scheme of Chaum, van Heijst, and
Pﬁtzmann [111, 112]. The technique in Section 3.5, which was inspired by a tech-
nique of Schoenmakers [340] to prove knowledge of a secret key corresponding to at
least one of two public keys, has been applied by Cramer, Franklin, Schoenmakers,
and Yung [124] and Cramer, Gennaro, and Schoenmakers [125] to design “key es-
crow” electronic voting schemes (see the Epilogue). Other applications that need not
involve digital certiﬁcates but could beneﬁt from our showing protocol techniques
include fair exchange of digital signatures, incremental signing, digital watermark-
ing, private information retrieval, and distributed database querying. In the remaining
chapters we will conﬁne ourselves to applications involving digital certiﬁcation.

Chapter 4
Restrictive Blind Issuing
Protocols
In this chapter we introduce a new notion, called restrictive blinding, to enable the
CA to encode attributes into certiﬁed key pairs that are unlinkable and untraceable
in all other respects. We design various practical restrictive blind certiﬁcate issuing
protocols, for DLREP-based certiﬁcates as well as for RSAREP-based certiﬁcates,
and analyze their security. This chapter builds on Chapter 2, but may be read inde-
pendently of Chapter 3. In Chapter 5 we will show how to combine the issuing and
showing protocol techniques.
4.1
Restrictive blinding
Informally, a restrictive blind certiﬁcate scheme is a digital certiﬁcate scheme (see
Section 2.6) with the following properties:
• If V and P both follow the protocol, then V obtains a certiﬁed key pair
(s, p, cert(p)).
The pair (s, p) is a key pair of V, and cert(p) is P’s (secret-key or public-key)
digital certiﬁcate on V’s public key p.
• The certiﬁed public key (p, cert(p)) obtained by V by interacting with P is
statistically independent from P’s view in the protocol execution.
• If P follows the protocol, then V cannot forge certiﬁed key pairs.
• If V obtains a certiﬁed key pair (s, p, cert(p)), then with overwhelming prob-
ability the secret key s contains at least one attribute encoded by P.

132
RESTRICTIVE BLIND ISSUING PROTOCOLS
The last property is the hardest to formalize. To understand the meaning of “encod-
ing at least one attribute,” consider by way of example a scenario in which V is to
receive P’s certiﬁcate on a public key deﬁned by the RSAREP function (see Sec-
tion 2.3.3). If P is to encode (x1, . . . , xl) into the secret key V will know for the
public key l
i=1 gxi
i xv
l+1 it will end up with, then V must be unable to modify these
l attributes as part of its blinding operations; we say that part of V’s secret key (the
ﬁrst l positions) is blinding-invariant. Note that P’s ability to encode (x1, . . . , xl)
into V’s secret key does not contradict the requirement that V is able to blind its cer-
tiﬁed public key (p, cert(p)), assuming that V can generate xl+1 at random from Z
∗
n.
The difﬁculty resides in how to meet all four properties.
In general, P may encode attributes into V’s secret key in an arbitrary fashion. All
that matters is that the blinding-invariant part of V’s secret key can be described by
a polynomial-time computable (non-constant) function from the space of secret keys
into the space of attributes. For example, suppose that V can obtain P’s certiﬁcate on
a public key of the form l
i=1 gαxi+β
i
xv
l+1, for random blinding factors α, β ∈Zv,
but not on other forms. Then P can still encode l −2 attributes in an independent
manner into V’s secret key, since x∗
i := (xi −xl)(xl−1 −xl)−1 mod v remains
unchanged for all i ∈{1, . . ., l −2}). (More generally, the invariance applies under
linear transformations.) For another example, see Proposition 4.3.15. If, on the other
hand, V can obtain P’s certiﬁcate on a public key of the form l
i=1 gxi+αi
i
xv
l+1, for
random blinding factors α1, . . . , αl ∈Zv, then P cannot encode anything into V’s
secret key.
P need not necessarily know the attributes it encodes into V’s secret key; know-
ing a one-way image may sufﬁce, as we will see in Section 5.2.1. This general-
ization enables P to “update” previously encoded attributes without knowing their
current values. For this reason, in the deﬁnition of restrictive blinding we will not
be concerned with who determines, knows, or generates the attributes that are to be
encoded; of importance is only the existence of a blinding-invariant part in the secret
key that V will end up with.
We are now prepared for a formal deﬁnition.
Deﬁnition 4.1.1. A restrictive blind certiﬁcate scheme is a digital certiﬁcate scheme
with the following additional properties:
• (Blinding of the certiﬁed public key) If V follows the protocol and accepts,
then V obtains a certiﬁed key pair (s, p, cert(p)) such that the certiﬁed pub-
lic key (p, cert(p)) is statistically independent from P’s view in the protocol
execution.
• (Blinding-invariant part) There exists a non-constant function {Invi(·)}i∈V
that can be evaluated in polynomial time, such that the following two proper-
ties hold if P follows the protocol:

4.1 RESTRICTIVE BLINDING
133
– Let s denote the secret key of the certiﬁed key pair obtained by V. Then
Invi(s) = tuple, where tuple is the attribute tuple encoded by P.
– Let s1, . . . , st∗denote the secret keys of any t∗certiﬁed key pairs obtained
by V after engaging in t ≥t∗protocol executions, and let tuplej denote
the attribute tuple P intended to encode into V’s certiﬁed key pair in the
j-th protocol execution, for all j ∈{1, . . . , t}. For all j∗∈{1, . . ., t∗},
there exists j ∈{1, . . . , t} such that the following two properties hold
with overwhelming probability:
∗Invi(sj∗) = tuplej.
∗The multiplicity of Invi(sj∗) is no greater than the multiplicity of
tuplej.
We will say that a restrictive blind certiﬁcate issuing protocol execution is per-
formed with respect to (x1, . . . , xl) if (x1, . . . , xl) is the attribute tuple that P intends
to encode into V’s certiﬁed key pair in that particular protocol execution.
The second part of the deﬁnition may seem overly complex, but is needed to cap-
ture the case where V consists of a plurality of receivers. Namely, operating under
the assumption that an adversary can passively monitor the protocol executions of
honest receivers, it must be infeasible for the adversary to beneﬁt from this informa-
tion by being able to compute a certiﬁed key pair for which the secret key encodes
an attribute tuple that P intended to encode only in the secret key of one of the moni-
tored honest receivers.1 It is not hard to see that the deﬁnition captures this scenario,
regardless of how protocol executions are interleaved. Note that there is no problem
if V can swap attribute tuples that P encodes in different protocol executions with V.
Deﬁnition 4.1.1 encompasses both public-key certiﬁcates and secret-key certiﬁ-
cates. Note that restrictive blinding of secret-key certiﬁcates is not a special case of
Chaum’s blind signature paradigm [91, 92, 93, 94, 95, 96, 99, 100]: P’s certiﬁcate
is not a digital signature on V’s public key but only on V’s secret key, which by
deﬁnition cannot be blinded.
The notion of restrictive blinding also differs from Chaum’s notion of one-show
blinding [90, 98]. The latter concerns a property of an issuing protocol in combina-
tion with a showing protocol, while restrictive blinding is a property of the issuing
protocol only. In particular, restrictive blinding has nothing to do with restricting the
number of times a certiﬁcate may be shown. One special use of restrictive blinding
is to construct practical one-show blind signature schemes (see Section 5.4), but its
general applicability is much broader.
Deﬁnition 4.1.1 describes the strongest possible case of blinding; not even a CA
with unlimited resources can create a correlation between the certiﬁed public keys
1In a practical situation, session encryption can prevent monitoring of protocol executions, but the
security of the session encryption method depends not only on the receiver. Moreover, as a general design
principle it is undesirable to make the security of two different building blocks, that serve different goals,
depend on each other.

134
RESTRICTIVE BLIND ISSUING PROTOCOLS
it issues and its views in the issuing protocol. A weaker ﬂavor would be one where
linking is merely computationally infeasible, but as explained in Section 1.3.5 this is
unsatisfactory.
In practical applications, it will often be desirable that V’s secret key cannot be
computed by a party that gets to learn V’s certiﬁed public key and also knows P’s
view in the originating issuing protocol. This property is not part of the deﬁnition,
but holds for all the constructions in this chapter.
Two generic approaches are known to design restrictive blind certiﬁcate schemes:
• One can use any “ordinary” blind signature issuing protocol, and have the re-
ceiver use a zero-knowledge proof to prove to the issuer that it has properly
encoded the attributes into its “challenge” message, before the issuer returns
its ﬁnal response. According to Goldreich, Micali, and Wigderson [191], zero-
knowledge proofs exist for all languages in the complexity class NP.
• Techniques from the ﬁeld of secure multi-party computations can be used,
along the lines of Juels, Luby, and Ostrovsky [224]. (See also Damg˚ard [126]
and Pﬁtzmann and Waidner [303].)
Both approaches result in highly impractical protocols. A more efﬁcient approach is
to run polynomially many copies of an ordinary blind signature protocol in parallel,
and have the signer complete a randomly chosen run of the protocol only when the
receiver shows correct formation of the “challenge” messages it submitted in all the
other protocol runs. This approach is still far from practical, though, and in fact does
not qualify: the attributes cannot be encoded in polynomial time with overwhelming
success probability. Note also that the improved issuing protocol of Chaum’s ad hoc
one-show blind signature scheme [98, 90] does not meet Deﬁnition 4.1.1.
The objective of this chapter is to design secure restrictive blind issuing proto-
cols that are truly practical, and that enable the CA to encode polynomially many
attributes without affecting the size of certiﬁed public keys.
4.2
Practical constructions
In this section we design four practical restrictive blind certiﬁcate schemes. The
ﬁrst two of these are based on the DLREP function, the latter two on the RSAREP
function. All schemes are for issuing secret-key certiﬁcates. We will extensively
analyze the schemes in the next section.
In Chapter 5 we will combine the showing protocols of the previous chapter with
the issuing protocols designed here. Because the receiver in the issuing protocol will
be the prover (signer) in the showing protocol, in the rest of this chapter we denote
the CA by P0 and the receiver by V0, to avoid confusion with the (P, V) notation
used in Chapter 3.

4.2 PRACTICAL CONSTRUCTIONS
135
4.2.1
Restrictive blinding based on the DLREP function
DLREP-based scheme I
Let (IDL, DDL) be any invulnerable instance generator for the DL function, and let
(q, g0) denote the output of IDL on input 1k. P0 feeds (q, g0) to DDL to obtain x0, and
computes h0 := gx0
0 . P0 then generates l ≥1 random numbers y1, . . . , yl ∈Zq, for
some l of its own choice, and computes gi := gyi
0 , for all i ∈{1, . . . , l}.
The system parameters are (q, g0). The public key of P0 is
h0, (g1, . . . , gl),
and its secret key is
x0, (y1, . . . , yl).
In addition, a correlation-intractable hash function H(·) = {Hi(·)}i∈{(q,g0)}, such
that Hq,g0(·) maps its outputs into Zs (for some s superpolynomial in k), is decided
on. A concise description of Hq,g0(·) is published along with the public key. Al-
though not made explicit in the notation, Hq,g0(·) may (and preferably does) depend
also on P0’s public key and any other information speciﬁed before protocol execu-
tions take place. (Alternatively, in each application of the hash function all such
static information is hashed along.) We will address the issue of selecting H(·) in
Section 4.3.3 when analyzing the security of the scheme.
The restrictive blind issuing protocol (P0, V0) is a proof of knowledge such that
V0 obtains a blinded public key, h′ ∈Gq, and a blinded certiﬁcate (c′
0, r′
0) ∈Zs×Zq
of P0 on h′. The pair (c′
0, r′
0) is deﬁned to be a certiﬁcate of P0 on h′ if and only if
the veriﬁcation relation
c′
0 = Hq,g0(h′, gr′
0
0 (h0h′)−c′
0)
holds. The secret key of V0 is a DL-representation, (x1, . . . , xl, α1), of h′ with re-
spect to (g1, . . . , gl, g0). The numbers x1, . . . , xl ∈Zq are encoded by P0 into V0’s
secret key, and in particular are known to P0; they form the blinding-invariant part
of V0’s secret key. Because V0 generates α1 at random, only V0 knows a secret key
corresponding to h′ (see Proposition 2.3.3). Moreover, h′ is statistically uncorrelated
to (x1, . . . , xl), regardless of the distribution of (x1, . . . , xl).
With h denoting l
i=1 gxi
i , an execution of the certiﬁcate issuing protocol with
respect to (x1, . . . , xl) is deﬁned as follows:
Step 1. P0 generates a random number w0 ∈Zq, and sends a0 := gw0
0
to V0.
Step 2. V0 generates three random numbers α1, α2, α3 ∈Zq. V0 computes h′ :=
hgα1
0 , c′
0 := Hq,g0(h′, gα2
0 (h0h)α3a0), and sends c0 := c′
0 + α3 mod q to P0.
Step 3. P0 sends r0 := c0(x0 + 	l
i=1 xiyi) + w0 mod q to V0.

136
RESTRICTIVE BLIND ISSUING PROTOCOLS
V0 accepts if and only if gr0
0 (h0h)−c0 = a0. If this veriﬁcation holds, V0 computes
r′
0 := r0 + α2 + c′
0α1 mod q.
We restrict P0 in the following manner. It may perform protocol executions with
respect to the same (x1, . . . , xl) in parallel, but must perform executions that involve
different attribute tuples sequentially. (The reason for this restriction will be clariﬁed
in Section 4.3.3. In Section 4.4 we will show how to get around the restriction.) The
resulting scheme is depicted in Figure 4.1.
When forming c′
0 in Step 2, V0 may hash along additional information, such as
a public key to be used for session encryption in a showing protocol or one or more
initial witnesses for the showing protocol. The advantages of including the latter will
become clear in Section 5.4.
DLREP-based scheme II
The following variation of DLREP-based scheme I is somewhat less efﬁcient, but
as Proposition 4.3.7 will show admits a better proof of unforgeability in the random
oracle model. The required modiﬁcations are minimal, and so we only describe these:
• P0 generates an additional random number f ∈Gq, which it publishes along
with the other public key data. It also generates an additional random number
t ∈{0, 1}, serving as additional secret key information to P0, and forms h0
according to h0 := gx0
0 f t. No further changes are needed in the key set-up.
• A certiﬁcate of P0 on h′ is redeﬁned to be a triple, (c′
0, r′
0, r′
1) ∈Zs×Zq ×Zq
such that
c′
0 = Hq,g0(h′, gr′
0
0 f r′
1(h0h′)−c′
0)
The deﬁnition of a key pair for V0 is not changed, nor is that of the blinding-
invariant part.
• In Step 1 of the certiﬁcate issuing protocol, P0 generates an additional random
number w1 ∈Zq, and forms a0 according to a0 := gw0
0 f w1. In Step 2 of
the protocol, V0 generates an additional random number α4 ∈Zq, and mul-
tiplies f α4 into the second argument to Hq,g0(·) when computing c′
0. In Step
3 of the protocol, P0 computes an additional response, r1, according to r1 :=
c0t + w1 mod q, and sends this along to V0. Finally, V0 accepts if and only if
gr0
0 f r1(h0h)−c0 = a0, and in addition blinds r1 to r′
1 := r1 + α4 mod q.
The requirement that P0 may not interleave protocol executions with respect to dif-
ferent attribute tuples still applies.
The resulting scheme is depicted in Figure 4.2.

4.2 PRACTICAL CONSTRUCTIONS
137
P0
V0
SYSTEM PARAMETERS
(q, g0) := IDL(1k)
KEY SET-UP
x0 := DDL(q, g0)
y1, . . . , yl ∈R Zq
Secret key: x0, (y1, . . . , yl)
h0 := gx0
0
gi := gyi
0 ∀i ∈{1, . . . , l}
Public key:
h0, (g1, . . . , gl)
Additional information:
Hq,g0(·)
PROTOCOL
w0 ∈R Zq
a0 := gw0
0
a0
−−→
α1, α2, α3 ∈R Zq
h′ := hgα1
0
c′
0 := Hq,g0(h′, gα2
0 (h0h)α3a0)
c0 := c′
0 + α3 mod q
c0
←−−
r0 := c0(x0 + 	l
i=1 xiyi) + w0 mod q
r0
−−→
gr0
0 (h0h)−c0 ?= a0
r′
0 := r0 + α2 + c′
0α1 mod q
Figure 4.1: DLREP-based scheme I.

138
RESTRICTIVE BLIND ISSUING PROTOCOLS
P0
V0
SYSTEM PARAMETERS
(q, g0) := IDL(1k)
KEY SET-UP
x0 := DDL(q, g0)
t ∈R {0, 1}
y1, . . . , yl ∈R Zq
Secret key: (x0, t), (y1, . . . , yl)
f ∈R Gq
h0 := gx0
0 ft
gi := gyi
0 ∀i ∈{1, . . . , l}
Public key:
(f, h0), (g1, . . . , gl)
Additional information:
Hq,g0(·)
PROTOCOL
w0, w1 ∈R Zq
a0 := gw0
0 fw1
a0
−−−−−→
α1, α2, α3, α4 ∈R Zq
h′ := hgα1
0
c′
0 := Hq,g0(h′, gα2
0 (h0h)α3fα4a0)
c0 := c′
0 + α3 mod q
c0
←−−−−−
r0 := c0(x0 + 	l
i=1 xiyi) + w0 mod q
r1 := c0t + w1 mod q
r0, r1
−−−−−→
gr0
0 fr1(h0h)−c0 ?= a0
r′
0 := r0 + α2 + c′
0α1 mod q
r′
1 := r1 + α4 mod q
Figure 4.2: DLREP-based scheme II.

4.2 PRACTICAL CONSTRUCTIONS
139
4.2.2
Restrictive blinding based on the RSAREP function
RSAREP-based scheme I
Let (IRSA, DRSA) be any invulnerable instance generator for the RSA function, and
let (n, v) denote the output of IRSA on input 1k. We assume that IRSA outputs the
prime factorization (p, q) of n as “side information” for P0. P0 feeds (n, v) to DRSA
to obtain x0, and computes h0 := xv
0. P0 then generates l ≥1 random numbers
g1, . . . , gl ∈Z
∗
n.
The system parameters are (n, v). The public key of P0 is
h0, (g1, . . . , gl),
and its secret key is the prime factorization of n. In addition, a one-way hash function
H(·) = {Hi(·)}i∈{(n,v)}, such that Hn,v(·) maps its outputs into Zs (for some s
superpolynomial in k), is decided on. A concise description of Hn,v(·) is published
along with the public key. Although not made explicit in the notation, its speciﬁcation
may depend on P0’s public key and any other information speciﬁed before protocol
executions take place. We will address the issue of selecting H(·) in Section 4.3.3.
Our restrictive blind issuing protocol (P0, V0) is a proof of knowledge such that
V0 obtains a blinded public key, h′ ∈Z
∗
n, and a blinded certiﬁcate (c′
0, r′
0) ∈Zs×Z
∗
n
of P0 on h′. The pair (c′
0, r′
0) is deﬁned to be a certiﬁcate of P0 on h′ if and only if
the veriﬁcation relation
c′
0 = Hn,v(h′, (r′
0)v(h0h′)−c′
0)
holds. The secret key of V0 is an RSA-representation, (x1, . . . , xl, α1), of h′ with
respect to (g1, . . . , gl, v). The numbers x1, . . . , xl ∈Zv are encoded by P0 into V0’s
secret key; they form the blinding-invariant part of V0’s secret key. Because V0 gen-
erates α1 at random, h′ is uncorrelated to (x1, . . . , xl), regardless of the distribution
of (x1, . . . , xl).
With h denoting l
i=1 gxi
i , an execution of the certiﬁcate issuing protocol with
respect to (x1, . . . , xl) is deﬁned as follows:
Step 1. P0 generates a random number a0 ∈Z
∗
n, and sends it to V0.
Step 2. V0 generates two random numbers α1, α2 ∈Z
∗
n and a random number α3 ∈
Zv. V0 computes h′ := hαv
1, c′
0 := H(h′, αv
2(h0h)α3a0), and sends c0 :=
c′
0 + α3 mod v to P0.
Step 3. P0 sends r0 := ((h0h)c0a0)1/v to V0. (Note that P0 can compute v-th roots
of arbitrary numbers in Z
∗
n, because it knows the prime factorization of n.)
V0 accepts if and only if rv
0(h0h)−c0 = a0. If this veriﬁcation holds, V0 computes
r′
0 := r0α2αc′
0
1 (h0h)(c′
0+α3)divv.

140
RESTRICTIVE BLIND ISSUING PROTOCOLS
As with both DLREP-based schemes, P0 may perform protocol executions with re-
spect to the same (x1, . . . , xl) in parallel, but may not interleave executions that
involve different attribute tuples. (In Section 4.4 we will show how to get around this
restriction.) The resulting scheme is depicted in Figure 4.3.
When forming c′
0 in Step 2, V0 may hash along additional information, such as
a public key for session encryption or one or more initial witnesses for a subsequent
showing protocol. Inclusion of the latter will be pursued further in Section 5.4.
RSAREP-based scheme II
The following variation of RSAREP-based scheme I is somewhat less efﬁcient, but
admits a better proof of unforgeability in the random oracle model. The modiﬁcations
to RSAREP-based scheme I are the following:
• P0 generates an additional random number f ∈Z
∗
n, which it publishes along
with its other public key data. No further changes are needed in the key set-up.
• A certiﬁcate of P0 on h′ is redeﬁned to be a triple, (c′
0, r′
0, r′
1) ∈Zs×Z
∗
n×Zv
such that
c′
0 = Hn,v(h′, (r′
0)vf r′
1(h0h′)−c′
0)
The deﬁnition of a key pair for V0 is not changed, nor is that of the blinding-
invariant part.
• In Step 2 of the protocol, V0 generates an additional random number α4 ∈Zv,
and multiplies f α4 into the second argument to Hn,v(·) when computing c′
0.
In Step 3 of the protocol, P0 generates a random number r1 ∈Zv, computes
r0 according to r0 := ((h0h)c0a0/f r1)1/v, and sends r0 along to V0. Finally,
V0 accepts if and only if rv
0f r1(h0h)−c0 = a0, and computes
r′
0 := r0α2αc′
0
1 (h0h)(c′
0+α3)divvf (r1+α4)divv
and r′
1 := r1 + α4 mod v.
The requirement that P0 may not interleave protocol executions with respect to dif-
ferent attribute tuples still applies.
The resulting scheme is depicted in Figure 4.4.
4.2.3
Comparison
The constructions based on the DLREP function and on the RSAREP function follow
exactly the same design principle. This may not be readily clear from the descrip-
tions, because P0 in the RSAREP-based variants makes use of trapdoor information,
which is not available in the DLREP-based variants. To appreciate the underlying
design principle, observe that P0 need not make use of trapdoor information in the

4.2 PRACTICAL CONSTRUCTIONS
141
P0
V0
SYSTEM PARAMETERS
(n, v) := IRSA(1k)
KEY SET-UP
Secret key: factorization of n
h0, g1, . . . , gl ∈R Z
∗
n
Public key:
h0, (g1, . . . , gl)
Additional information:
Hn,v(·)
PROTOCOL
a0 ∈R Z
∗
n
a0
−−→
α1, α2 ∈R Z
∗
n
α3 ∈R Zv
h′ := hαv
1
c′
0 := Hn,v(h′, αv
2(h0h)α3a0)
c0 := c′
0 + α3 mod v
c0
←−−
r0 := ((h0h)c0a0)1/v
r0
−−→
rv
0(h0h)−c0 ?= a0
r′
0 := r0α2α
c′
0
1 (h0h)(c′
0+α3)divv
Figure 4.3: RSAREP-based scheme I.

142
RESTRICTIVE BLIND ISSUING PROTOCOLS
P0
V0
SYSTEM PARAMETERS
(n, v) := IRSA(1k)
KEY SET-UP
Secret key: factorization of n
f, h0, g1, . . . , gl ∈R Z
∗
n
Public key:
(f, h0), (g1, . . . , gl)
Additional information:
Hn,v(·)
PROTOCOL
a0 ∈R Z
∗
n
a0
−−−−−→
α1, α2 ∈R Z
∗
n
α3, α4 ∈R Zv
h′ := hαv
1
c′
0 := Hn,v(h′, αv
2(h0h)α3fα4a0)
c0 := c′
0 + α3 mod v
c0
←−−−−−
r1 ∈R Zv
r0 := ((h0h)c0a0/fr1)1/v
r0, r1
−−−−−→
fr1rv
0(h0h)−c0 ?= a0
r′
0 := r0α2α
c′
0
1 (h0h)(c′
0+α3)divvf(r1+α4)divv
r′
1 := r1 + α4 mod v
Figure 4.4: RSAREP-based scheme II.

4.2 PRACTICAL CONSTRUCTIONS
143
RSAREP-based schemes. In RSAREP-based scheme I, we hereto make the follow-
ing modiﬁcations:
• Instead of generating h0, g1, . . . , gl at random, P0 generates l + 1 random
numbers x0, y1, . . . , yl from Z
∗
n, and computes h0 := xv
0 and gi := yv
i , for all
i ∈{1, . . . , l}. (More generally, P0 may set x0 := DRSA(n, v).)
• In Step 1 of the issuing protocol, P0 generates a0 according to a0 := wv
0, for a
random w0 ∈Z
∗
n.
• In Step 3 of the issuing protocol, P0 computes r0 as follows:
r0 := (x0
l
i=1
yxi
i )c0w0.
The resulting scheme is depicted in Figure 4.5. Similar modiﬁcations can be made
to RSAREP-based scheme II. With these modiﬁcations, it is easily seen that the
DLREP-based and the RSAREP-based schemes are all based on the same design
principle:
P0 interactively issues a signed proof of knowledge of a secret key corre-
sponding to the joint public key h0h, using one of the proofs of knowl-
edge described in Sections 2.4.3 and 2.4.4. V0 blinds not only a0 and
P0’s response(s), but also h.
In all four schemes, h0h or h may be thought of as the auxiliary common input m∗
in Deﬁnition 2.5.1. Note that for both DLREP-based scheme II and RSAREP-based
scheme II the issuing protocols are provably witness-hiding. (In particular, even after
P0 has performed polynomially many protocol executions, arbitrarily interleaved and
possibly with respect to all valid attribute tuples, its secret key provably cannot leak.)
Not using the trapdoor information in the RSAREP-based schemes has several
advantages:
• Multiple provers can all operate with respect to the same (n, v), generated by
a trusted party or by means of a secure multi-party protocol (see Boneh and
Franklin [39] and Poupard and Stern [309]).
• The binary sizes of v and c may be much smaller than the binary sizes of the
prime factors of n. This reduces P0’s computational burden.
• P0 can be split into many sub-provers that all hold a share of the public key,
and that must all contribute to issue a certiﬁed key pair to V0. Using RSAREP-
based scheme I, for instance, the i-th sub-prover could hold h0i := xv
0i, with
l
i=1 h0i = h0, and could be in charge of generating yi. The contribution of
the i-th sub-prover to the issuing protocol would be an initial witness a0i :=

144
RESTRICTIVE BLIND ISSUING PROTOCOLS
P0
V0
SYSTEM PARAMETERS
(n, v) := IRSA(1k)
KEY SET-UP
x0 := DRSA(n, v)
y1, . . . , yl ∈R Z
∗
n
Secret key: x0, (y1, . . . , yl)
h0 := xv
0
gi := yv
i ∀i ∈{1, . . . , l}
Public key:
h0, (g1, . . . , gl)
Additional information:
Hn,v(·)
PROTOCOL
w0 ∈R Z
∗
n
a0 := wv
0
a0
−−→
α1, α2 ∈R Z
∗
n
α3 ∈R Zv
h′ := hαv
1
c′
0 := Hn,v(h′, αv
2(h0h)α3a0)
c0 := c′
0 + α3 mod v
c0
←−−
r0 := (x0
l
i=1 yxi
i )c0w0
r0
−−→
rv
0(h0h)−c0 ?= a0
r′
0 := r0α2α
c′
0
1 (h0h)(c′
0+α3)divv
Figure 4.5: RSAREP-based scheme I without use of trapdoor information.

4.2 PRACTICAL CONSTRUCTIONS
145
wv
0i and a response r0i := (x0iyxi
i )c0w0i; the product of all the individual
witnesses is the initial witness expected by V0, and likewise for the responses.
The technique of sharing P0’s secret key can also be applied to the DLREP-based
issuing protocols (and the other protocols that will be described later in this chap-
ter). It is even possible to extend the technique to provide for arbitrary secret shar-
ing, requiring one of several predetermined subsets to cooperate in order to perform
the role of P0. For relevant secret-sharing techniques, see Pedersen [299], Cere-
cedo, Matsumoto, and Imai [84], Gennaro, Jarecki, Krawczyk, and Rabin [184], and
Takaragi, Miyazaki, and Takahashi [369]. Also, the number of entities that share
P0’s secret key could be increased so that multiple entities are needed to approve
each attribute. In a practical implementation, the sub-provers could take the form of
tamper-resistant computing devices stored in independently guarded locations. This
not only provides optimal protection against (insider and outsider) theft and extortion
of P0’s secret key, but it can also ensure that different device operators must approve
the same attributes that are to be encoded into a certiﬁed key pair.2
Using the trapdoor information in the RSAREP-based schemes also has a couple
of advantages:
• It avoids the exponentiation in Step 1 of the protocol.
• P0 does not need to remember or reconstruct in Step 3 a secret number that it
generated in Step 1, which is an advantage when implementing the protocol.
(P0 still needs to access its secret key, of course.) The protocol can even be
turned into a two-move protocol by having V0 form a0 by feeding at least an
identiﬁer for V0 and a nonce into a sufﬁciently strong one-way function. (V0
must send the nonce along with its challenge to P0, so that P0 can check its
freshness.)
• P0 can perform the issuing protocol without knowing (x1, . . . , xl); it merely
needs to know h. This property enables P0 to recertify a previously certiﬁed
public key, without knowing its blinding-invariant part. During the process,
P0 can even update one or more of the xi values. (Details will be provided in
Section 5.2.1.)
In the RSAREP-based schemes, V0 cannot verify by itself that v is co-prime to ϕ(n).
However, if the prime v is not co-prime to ϕ(n), then P0 cannot respond to V’s
challenge c0 with probability at least 1−1/v. In other words, V0 becomes convinced
with overwhelming probability of the proper formation of (n, v) by engaging in a
single execution of the certiﬁcate issuing protocol.
2Issuer fraud is a serious threat, as witnessed for instance by the 250 employees of the Department
of Motor Vehicles of California who in 1998 were found to have issued over 25 000 genuine-looking but
fraudulent licenses in a two-year period.

146
RESTRICTIVE BLIND ISSUING PROTOCOLS
In Step 2 of all four certiﬁcate schemes, V0 can perform all the required exponen-
tiations in a preprocessing stage; its real-time computational burden in each protocol
amounts to one modular multiplication and one application of the hash function. This
makes the schemes highly practical.
The main advantage of the DLREP-based variants over the RSAREP-based vari-
ants is that the computation of P0’s response(s) does not involve any exponentiations.
In highly demanding applications, this enables the CA to serve more receivers us-
ing cheaper equipment, especially when using an elliptic curve implementation with
short system parameters.
4.3
Analysis
In this section we analyze the certiﬁcate schemes of the previous section. We will
prove that all four schemes are restrictive blind certiﬁcate schemes, under plausible
cryptographic assumptions.
To avoid unnecessary duplication of security statements and proof reductions,
a detailed analysis is provided only of RSAREP-based scheme I. The analysis of
the other three schemes is highly similar, and so for these we merely point out the
differences.
Throughout this section it is assumed that the system parameters, (q, g0) and
(n, v), respectively, are properly formed.
4.3.1
Completeness
The statements in this section hold for any choice of H(·).
Proposition 4.3.1. When interacting with P0, V0 in RSAREP-based scheme I ac-
cepts.
Proof. This follows immediately from the manner in which P0 computes r0 in Step
3 and the veriﬁcation relation applied by V0.
Proposition 4.3.2. For any P0, if V0 in RSAREP-based scheme I accepts, then
(x1, . . . , xl, α1), h′, (c′
0, r′
0)
is a certiﬁed key pair.
Proof. Clearly, (x1, . . . , xl, α1) is an RSA-representation of h′ with respect to the
tuple (g1, . . . , gl, v). To show that (c′
0, r′
0) is a certiﬁcate of P0 on h′, note that V0 in
Step 2 of the issuing protocol computes c′
0 := Hn,v(h′, αv
2(h0h)α3a0). It therefore

4.3 ANALYSIS
147
sufﬁces to prove that (r′
0)v(h0h′)−c′
0 = αv
2(h0h)α3a0 for the assignments made by
V0. This can be seen as follows:
(r′
0)v(h0h′)−c′
0
=
(r0α2αc′
0
1 (h0h)(c′
0+α3) divv)v(h0hαv
1)−c′
0
=
(r0α2(h0h)(c′
0+α3) divv)v(h0h)−c′
0
=
rv
0αv
2(h0h)v ((c′
0+α3) divv)(h0h)−c′
0
(⋆)
=
((h0h)c0a0) αv
2(h0h)v((c′
0+α3) divv)(h0h)−c′
0
=
(h0h)(c′
0+α3 mod v)+v ((c′
0+α3) divv)a0αv
2(h0h)−c′
0
=
(h0h)c′
0+α3αv
2(h0h)−c′
0a0
=
αv
2(h0h)α3a0.
The substitution (⋆) is allowed because V0 accepts only if rv
0(h0h)−c0 = a0.
In a like manner, the direct analogues of these two propositions can be proved for the
other three certiﬁcate schemes in Section 4.2.
4.3.2
Privacy for the receiver
The statements in this section address the protocol ( P0, V0), and hold for any choice
of H(·).
Lemma 4.3.3. In RSAREP-based scheme I, for any properly formed system param-
eters, any certiﬁed public key, any (x1, . . . , xl), and any possible view of P0 in an
execution of the issuing protocol with respect to (x1, . . . , xl) in which V0 accepts,
there is exactly one set of random choices that V0 could have made in that execution
of the issuing protocol such that V0 would end up with a certiﬁed key pair containing
that particular certiﬁed public key.
Proof. Consider any tuple (x1, . . . , xl) and any certiﬁed public key h′, (c′
0, r′
0). With
h denoting l
i=1 gxi
i , the response r0 of P0 is such that rv
0(h0h)−c0 = a0, since V0
accepts. Deﬁne the following two sets:
Views ( P0)
=
{(a0, c0, r0) | a0, r0 ∈Z
∗
n and c0 ∈Zv such that
rv
0(h0h)−c0 = a0}
Choices (V0)
=
{(α1, α2, α3) | α1, α2 ∈Z
∗
n and α3 ∈Zv}.
We will show that for all P0-view ∈Views ( P0) exactly one triple (α1, α2, α3) ∈
Choices (V0) exists such that P0-view corresponds to an execution of the issuing
protocol in which V0 receives the certiﬁed public key (h′, (c′
0, r′
0)).

148
RESTRICTIVE BLIND ISSUING PROTOCOLS
Suppose that P0-view corresponds to the issuing of h′, (c′
0, r′
0). We determine
the numbers α1, α2, α3 that must have been chosen by V0. First, α1 is determined
from h, h′ as
α1 := (h′ h−1)1/v.
Note that α1 exists and is uniquely deﬁned, since v is co-prime to ϕ(n). Next, α3 is
determined from c0, c′
0 according to
α3 := c0 −c′
0 mod v.
Finally, the choices for α1 and α3, together with r0, r′
0 and c′
0, uniquely determine
α2 as
α2 := r′
0(r0αc′
0
1 (h0h)(c′
0+α3) divv)−1.
For these choices of the three variables all the assignments and veriﬁcations in
the execution of the issuing protocol would be satisﬁed by deﬁnition, except maybe
for the assignment
c′
0 := Hn,v(h′, αv
2(h0h)α3a0)
that must have been made by V0. To prove that this assignment holds as well, note
that
c′
0 = Hn,v(h′, (r′
0)v(h0h′)−c′
0)
by deﬁnition of a certiﬁed public key. Therefore the proof is complete if
(r′
0)v(h0h′)−c′
0 = αv
2(h0h)α3a0
for the choices for α1, α2, and α3 made above. This can be derived exactly as in
the proof of Proposition 4.3.2, considering that the substitution (⋆) is allowed here
because P0-view ∈Views ( P0).
Lemma 4.3.3 does not necessarily hold in the case of improperly formed system
parameters. In particular, if v is not co-prime to ϕ(n) then a substantial part of the
views of P0 cannot be matched with a substantial part of the certiﬁed public keys.
This is not a problem, though, as we saw in Section 4.2.3.
Proposition 4.3.4. For any properly formed system parameters in RSAREP-based
scheme I, if V0 follows the issuing protocol and accepts, then it obtains a certiﬁed
key pair comprising a perfectly blinded certiﬁed public key, regardless of the behavior
of P0.
Proof. This is an immediate consequence of Lemma 4.3.3 and the fact that V0 gen-
erates its triples (α1, α2, α3) at random from Choices (V0).

4.3 ANALYSIS
149
The same result can be proved for the other three certiﬁcate schemes described in
Section 4.2.
In Chapter 5 we will make the connection with the showing protocols in Chapter 3
and show that that the above privacy result holds even when V0 selectively discloses
any property of the encoded attributes. That is, any certiﬁcate that V0 shows in the
showing protocol execution could have originated (with uniform probability) from
any of the issuing protocol executions in which P0 encoded attributes that satisfy the
formula disclosed by V0.
4.3.3
Security for the Certiﬁcate Authority
In this section we address the protocol (P0, V0), by analyzing the properties of un-
forgeability and restrictive blinding.
Unforgeability
We study the unforgeability of RSAREP-based scheme I in the strongest possible
attack model. All our unforgeability results hold even if V0 can engage in poly-
nomially many executions of the issuing protocol, can arbitrarily interleave protocol
executions, and may select an arbitrary attribute tuple (x1, . . . , xl) at the start of each
new protocol execution.
The following lemma holds for any choice of H(·).
Lemma 4.3.5. If the Guillou-Quisquater proof of knowledge with s := v is witness-
hiding, then V0 in RSAREP-based scheme I cannot output with non-negligible suc-
cess probability a non-trivial RSA-representation of 1 with respect to (g1, . . . , gl, v).
Proof. Suppose that V0, after engaging in t executions of the issuing protocol, out-
puts a non-trivial RSA-representation of 1 with respect to (g1, . . . , gl, v), with non-
negligible probability ϵ. We construct a polynomial-time interactive algorithm V for
extracting the witness of P in the Guillou-Quisquater proof of knowledge, as follows.
Let (n, v) denote the system parameters in the Guillou-Quisquater proof of knowl-
edge, and hGQ the public key of P. V simulates P0 with the help of the protocol
executions of P, by performing the following steps:
Step A. (Simulate the key set-up for P0.) Select a random index j ∈{1, . . ., l} and
l + 1 random numbers x0, y1, . . . , yl ∈Z
∗
n. Set h0 := xv
0, gi := yv
i , for all
i ∈{1, . . ., l} \ {j}, and gj := hGQyv
j . The simulated public key of P0 is
h0, (g1, . . . , gl).
Step B. (Simulate P0 in issuing protocol executions with respect to (x1, . . . , xl).)
Step 1. Receive a from P. Generate a random number α ∈Z
∗
n and pass
a0 := axjαv mod n on to V0.

150
RESTRICTIVE BLIND ISSUING PROTOCOLS
Step 2. Receive c0 from V0, and pass c := c0 on to P.
Step 3. Receive r from P, and pass
r0 := rxj(x0
l
i=1
yxi
i )c0α
on to V0.
Repeat this simulation until t executions of the issuing protocol have been
performed.
Step C. Check if V0 has output a non-trivial RSA-representation, (u1, . . . , ul, ul+1),
of 1. If not, then halt.
Step D. If uj = 0 mod v, then halt.
Step E. Compute integers e, f ∈Z such that euj + fv = 1, using the extended Eu-
clidean algorithm. (This can always be done, because v is a prime.) Compute
hf
GQ(
l
i=1
yui
i ul+1)−e
and output the result.
It is easy to see that the public key in Step A is generated with the same proba-
bility distribution as that by which P0 generates its public key. Note that this is the
case regardless of the probability distribution of hGQ.
The response that is computed by V in the simulated issuing protocol is the same
as the response that P0 would compute:
rv
0
=
(rxj(x0
l
i=1
yxi
i )c0α)v
=
(rv)xj(xv
0
l
i=1
(yv
i )xi)c0αv
(⋆)
=
(hc
GQa)xjαvxvc0
0
(

i∈{1,...,l}\{j}
gxi
i )c0yvcxj
j
=
(hGQyv
j )cxj(axjαv)hc0
0 (

i∈{1,...,l}\{j}
gxi
i )c0
=
(gxj
j )c0a0hc0
0 (

i∈{1,...,l}\{j}
gxi
i )c0
=
(h0h)c0a0,

4.3 ANALYSIS
151
where the substitution (⋆) is allowed because the response of P satisﬁes rvh−c
GQ = a.
Since α is chosen at random from Z
∗
n, a0 is randomly distributed over Z
∗
n regardless
of xj. From this it follows that the view of V0 in the simulated issuing protocol
has the same distribution as when V0 interacts with P0, regardless of the probability
distributions of (x1, . . . , xl), its challenges, and hGQ. Therefore V moves from Step
C to Step D with probability ϵ.
Because j is chosen at random by V, and is uncorrelated to the view of V0 in the
issuing protocol, uj ̸= 0 mod v in Step D with probability at least 1/l. (Not all ui
can be zero, because v is co-prime to ϕ(n).)
The output of V in Step E is equal to h1/v
GQ :
(hf
GQ(
l
i=1
yui
i ul+1)−e)v
=
hfv
GQ (
l
i=1
(yv
i )uiuv
l+1)−e
=
h1−euj
GQ
yujv
j
(

i∈{1,...,l}\{j}
gui
i uv
l+1)−e
=
hGQ(hGQyv
j )−euj(

i∈{1,...,l}\{j}
gui
i uv
l+1)−e
=
hGQ(guj
j )−e(

i∈{1,...,l}\{j}
gui
i uv
l+1)−e
=
hGQ(
l
i=1
gui
i uv
l+1)−e
=
hGQ1−e
=
hGQ.
In all, the probability that V can compute the secret key of P is at least ϵ/l. Since
l is polynomial in k, this probability is non-negligible if ϵ is non-negligible. This
contradicts the assumption.
Note that the reduction is tight only if l is a (small) constant; it is not clear how to
achieve tightness for arbitrary l polynomial in k.
We are now prepared for the main result.
Proposition 4.3.6. If Assumption 2.5.9 is true, then a hash function H(·) exists such
that RSAREP-based scheme I is unforgeable.
Proof. Take H(·) equal to the hash function H∗(·) deﬁned in Assumption 2.5.9. Sup-
pose that V0 obtains t + 1 certiﬁed key pairs with non-negligible success probability
ϵ after engaging in t executions of the certiﬁcate issuing protocol, for some t ≥0.
We construct a polynomial-time (interactive) algorithm V that can forge signatures
in the interactive Guillou-Quisquater signature scheme.

152
RESTRICTIVE BLIND ISSUING PROTOCOLS
Let (n, v) denote the system parameters in the Guillou-Quisquater proof of knowl-
edge, and hGQ the public key of P. V simulates P0 with the help of the protocol
executions of P, by performing the following steps:
Step A. (Simulate the key set-up for P0.) Generate a random number x0 ∈Z
∗
n and
set h0 := hGQxv
0. Generate l random numbers y1, . . . , yl ∈Z
∗
n, and com-
pute gi := yv
i , for all i ∈{1, . . ., l}. The simulated public key of P0 is
h0, (g1, . . . , gl).
Step B. (Simulate P0 in issuing protocol executions with respect to (x1, . . . , xl).)
Step 1. Receive a from P, and pass a0 := a on to V0.
Step 2. Receive c0 from V, and pass c := c0 on to P.
Step 3. Receive r from P, and pass r0 := r(x0
l
i=1 yxi
i )c0 on to V0.
Repeat this simulation until t executions of the issuing protocol have been
performed.
Step C. Check if V has t+1 distinct certiﬁed key pairs on its tapes. If not, then halt.
Step D. For each of these t + 1 certiﬁed key pairs, ((x1, . . . , xl, α1), h′, (c′
0, r′
0)),
compute c∗:= c′
0, r∗:= r′
0(x0
l
i=1 yxi
i α1)−c′
0, and m := h′, and output the
signed message (m, (c∗, r∗)).
It is easy to see that the public key in Step A is generated with the same probabil-
ity distribution as that by which P0 generates its public key. The response that is
computed by V in the simulated issuing protocol is the same as the response that P0
would compute:
rv
0
=
(r(x0
l
i=1
yxi
i )c0)v
=
rvxc0v
0
((
l
i=1
(yv
i )xi)c0
(⋆)
=
(hc
GQa)xcv
0 (
l
i=1
gxi
i )c0
=
(hGQxv
0)cahc0
=
(h0h)c0a0,
where the substitution (⋆) is allowed because the response of P satisﬁes rvh−c
GQ =
a. It follows that the view of V0 in the simulated issuing protocol has the same
distribution as when V0 interacts with P0, regardless of the probability distributions

4.3 ANALYSIS
153
of its challenges, (x1, . . . , xl), and hGQ. Therefore, V moves from Step C to Step D
with probability ϵ.
We next show (i) that the output of V consists of t+1 messages with correspond-
ing Guillou-Quisquater signatures, and (ii) that these signed messages are all distinct
with overwhelming probability. Property (i) follows from
c∗
=
c′
0
(⋆)
=
Hn,v(h′, (r′
0)v(h0h′)−c′
0)
(⋆⋆)
=
Hn,v(m, (r∗)vh−c∗
GQ ).
The substitution (⋆) is allowed by deﬁnition of a certiﬁcate, and substitution (⋆⋆)
follows from
(r′
0)v(h0h′)−c′
0)
=
(r∗(x0
l
i=1
yxi
i α1)c′
0)v(h0
l
i=1
gxi
i αv
1)−c′
0
=
(r∗)vxc′
0v
0
(
l
i=1
(yv
i )xiαv
1)c′
0h−c′
0
0
(
l
i=1
gxi
i αv
1)−c′
0
=
(r∗)v(h0x−v
0 )−c′
0
=
(r∗)vh−c∗
GQ .
To prove property (ii), consider any two certiﬁed key pairs,
(x1, . . . , xl, α1), h′, (c′
0, r′
0)
and
(x∗
1, . . . , x∗
l , α∗
1), h∗, (c∗
0, r∗
0).
The corresponding signed messages, as computed by V in Step D, are equal to
h′, (c′
0, r′
0((h′)1/v)−c′
0)
and
h∗, (c∗
0, r∗
0((h∗)1/v)−c∗
0).
Suppose that these two signed messages are the same. From h′ = h∗and c′
0 = c∗
0 it
follows that r′
0 = r∗
0. Furthermore, if (x1, . . . , xl, α1) and (x∗
1, . . . , x∗
l , α∗
1) are not
the same, then
(x1 −x∗
1 mod v, . . . , xl −x∗
l mod v,
l
i=1
g(xi−x∗
i )divv
i
α1/α∗
1)

154
RESTRICTIVE BLIND ISSUING PROTOCOLS
is a non-trivial RSA-representation of 1. According to Lemma 4.3.5, this contradicts
Assumption 2.5.9. Consequently, if the two signed messages are the same, then the
two certiﬁed key pairs are the same, and therefore property (ii) holds as well.
To complete the proof, observe that an execution of the simulated issuing protocol
constitutes exactly one execution of the protocol with P. In all, V can compute
t + 1 Guillou-Quisquater signed messages from t protocol executions with P with
probability ϵ. If ϵ is non-negligible, this contradicts Assumption 2.5.9.
Similar reductions can be made for the other three certiﬁcate schemes in Section 4.2.
Because DLREP-based scheme II and RSAREP-based scheme II are non-trivially
witness-indistinguishable, we get the following results by application of Proposi-
tion 2.5.3.
Proposition 4.3.7. Assume that P0 performs no more than polylogarithmically many
protocol executions, and that the binary size of the outputs of Hg,g0(·) is linear in k.
If (IDL, DDL) is invulnerable for the DL function, then DLREP-based scheme II is
unforgeable in the random oracle model, for any distribution of (x1, . . . , xl).
Proposition 4.3.8. Assume that P0 performs no more than polylogarithmically many
protocol executions, and that the binary size of the outputs of Hn,v(·) is linear in k.
If (IRSA, DRSA) is invulnerable for the RSA function, then RSAREP-based scheme II is
unforgeable in the random oracle model, for any distribution of (x1, . . . , xl).
These results hold even in case V0 may arbitrarily interleave the protocol execu-
tions and P0 encodes different attribute tuples of V0’s choice.
Blinding-invariance
To study the restrictive blinding property, we slightly weaken the attack model by
assuming that (x1, . . . , xl) is formed independently of h0. In most applications this
requirement is naturally met, especially if P0 selects (x1, . . . , xl).
The following assumption states that the only manner to generate a pair h, (c, r)
for which c = Hn,v(h, rvh−c) is by forming h as the v-th power of some known
x ∈Z
∗
n. That is, if an algorithm could output such a transcript, then with “modest”
extra effort it could also compute h1/v mod n.
Assumption 4.3.9. There exists a hash function H∗(·) = {H∗
i (·)}i∈{n,v} and an
expected polynomial-time algorithm K, such that for any polynomial-time algorithm
A, for all constants c > 0, and for all sufﬁciently large k,
 Pk

A(n, v) = (h, c, r) such that c = H∗
n,v(h, rvh−c) | (n, v) := IRSA(1k)

−Pk

K((n, v), (h, c, r); A) = β ∈Z
∗
n such that βv = h
  < 1/kc.

4.3 ANALYSIS
155
This assumption can be proved in the random oracle model by using the oracle
replay technique of Pointcheval and Stern [307].3
Proposition 4.3.10. If Assumption 4.3.9 holds, then a hash function H(·) exists such
that the following holds for all l ≥1 and all (x1, . . . , xl). Let (x1, . . . , xl) be
formed independently of h0, (g1, . . . , gl), and be the same in all protocol executions
of RSAREP-based scheme I. If V0, after engaging in polynomially many protocol ex-
ecutions with respect to (x1, . . . , xl), outputs a certiﬁed key pair comprising a secret
key (x∗
1, . . . , x∗
l , α1), then
(x∗
1, . . . , x∗
l ) = (x1, . . . , xl)
with overwhelming probability.
Proof. Suppose that V0, after t protocol executions, outputs with non-negligible suc-
cess probability ϵ a certiﬁed key pair comprising a secret key (x∗
1, . . . , x∗
l , α1) for
which (x∗
1, . . . , x∗
l ) differs from (x1, . . . , xl). Using a proper choice for H(·), we
show how to use algorithm K in Assumption 4.3.9 to construct a polynomial-time
algorithm A for inverting the RSA function, thereby obtaining a contradiction.
Let (IRSA, DRSA) denote any invulnerable instance generator for the RSA function.
On input k, this instance generator outputs a triple (n, v, x). Algorithm A, on input
(n, v, hRSA := xv), performs the following steps:
Step A. (Simulate the key set-up for P0.) Generate l random numbers, r1, . . . , rl ∈
Zv, and l random numbers, s1, . . . , sl ∈Z
∗
n. Set
gi := hri
RSAsv
i
∀i ∈{1, . . . , l}.
With h denoting l
i=1 gxi
i , generate a random number x0 ∈Z
∗
n, and compute
h0 := xv
0h−1. (Since (x1, . . . , xl) is generated independently of h0, we may
assume that it is generated before (h0, g1, . . . , gl) is generated.) The simulated
public key of P0 is h0, (g1, . . . , gl). In addition, deﬁne H(·) according to
Hn,v : (a, b) →H∗
n,v(h0a, b),
for all a, b ∈Z
∗
n, where H∗(·) is the hash function in Assumption 4.3.9.
Step B. (Simulate P0 in issuing protocol executions with respect to (x1, . . . , xl).)
Step 1. Generate a random number w0 ∈Z
∗
n. Compute a0 := wv
0, and send
a0 to V0.
3Because A is non-interactive, it is unclear how to formalize knowledge extraction outside of the
random oracle model. The intuition is that if A would keep a “history” tape that contains a copy of
everything it has written on its work tape (but with previous contents never overwritten), then K should be
able to extract knowledge from A by looking at the history tape and A’s input tape and random tape.

156
RESTRICTIVE BLIND ISSUING PROTOCOLS
Step 2. Receive c0 from V0.
Step 3. Compute r0 := xc0
0 w0, and send r0 to V0.
Repeat this simulation until t executions of the issuing protocol with V0 have
been performed.
Step C. Check if V0 has output a certiﬁed key pair (x∗
1, . . . , x∗
l , α1), h′, (c′
0, r′
0) for
which (x∗
1, . . . , x∗
l ) does not equal (x1, . . . , xl). If this is not the case, then
halt.
Step D. If 	l
i=1 ri(xi −x∗
i ) = 0 mod v, then halt.
Step E. Run algorithm K on input (n, v) and (h′, (c′
0, r′
0)), using < A, V0> as a
black-box algorithm. If K does not output β ∈Z
∗
n such that βv = h′ mod n,
then halt.
Step F. Using the extended Euclidean algorithm, compute integers e, f ∈Z satisfy-
ing
e(
l

i=1
ri(xi −x∗
i )) + fv = 1.
(This can always be done, because v is prime.) Compute
hf
RSA(α1x0β−1
l
i=1
sxi−x∗
i
i
)e,
and output the result.
By deﬁnition of the key generation of A in Step A, the public key in Step A is simu-
lated with the same probability distribution as that by which P0 generates its public
key, regardless of the distribution of hRSA and (x1, . . . , xl). The response that is com-
puted by A in the simulated issuing protocol is the same as the response that P0
would compute:
rv
0
=
(xc0
0 w0)v
=
(xv
0)c0wv
0
=
(h0h)c0a0.
It follows that the view of V0 in the simulated issuing protocol has the same distri-
bution as that provided by P0, regardless of the probability distribution by which V0
generates its challenges. Therefore, Step D is reached by supposition with probability
ϵ.
The tuple (r1, . . . , rl) is unconditionally hidden from V0, due to the randomness
of the si’s and the fact that v is co-prime to ϕ(n), and it is therefore independent of

4.3 ANALYSIS
157
(x∗
1, . . . , x∗
l ). Because (r1, . . . , rl) is also independent of (x1, . . . , xl), the transition
from Step D to Step E takes place with probability 1 −1/v.
Because of the deﬁnition of H(·), we can infer from Assumption 4.3.9 that the
output β of K in Step E satisﬁes
βv = h0h′ = h0
l
i=1
gx∗
i
i αv
1
with non-negligible probability. Therefore, the transition from Step E to Step F takes
place with non-negligible probability.
According to the key pair construction in Step A we also have
xv
0 = h0h = h0
l
i=1
gxi
i .
From these two relations we get
(x0β−1)v
=
l
i=1
gxi−x∗
i
i
(αv
1)−1
=
l
i=1
(hri
RSAsv
i )xi−x∗
i (αv
1)−1
=
h
	l
i=1 ri(xi−x∗
i )
RSA
(
l
i=1
sxi−x∗
i
i
α−1
1 )v
and so
(α1x0β−1
l
i=1
sx∗
i −xi
i
)v = h
	l
i=1 ri(xi−x∗
i )
RSA
.
From this it follows that the output of A in Step F is equal to h1/v
RSA , with overwhelming
probability:

hf
RSA(α1x0β−1
l
i=1
sxi−x∗
i
i
)ev
=
hfv
RSA

(α1x0β−1
l
i=1
sxi−x∗
i
i
)ve
=
h
1−e(	l
i=1 ri(xi−x∗
i ))
RSA
(h
	l
i=1 ri(xi−x∗
i )
RSA
)e
=
hRSA.
The overall success probability of A is (1 −1/v)ϵ times the (non-negligible) success
probability of algorithm K. If ϵ is non-negligible, then (IRSA, DRSA) is not invulnerable
for the RSA function. Therefore (x∗
1, . . . , x∗
l ) = (x1, . . . , xl) with overwhelming
probability.

158
RESTRICTIVE BLIND ISSUING PROTOCOLS
The result holds regardless of the fashion in which protocol executions with respect
to the same attribute tuple are interleaved.
The hash function deﬁned in the proof of Proposition 4.3.10 is not the same as
that in the proof of Proposition 4.3.6. In practice, any sufﬁciently strong one-way
hash function should sufﬁce for both propositions. (Another approach is to adjust
Assumption 4.3.9.)
A similar result can be proved for the other three certiﬁcate schemes described
in Section 4.2. In all four schemes, P0 is effectively proving knowledge of a rep-
resentation of the joint public key h0h, by means of a protocol that we know from
Section 2.4 to be honest-veriﬁer zero-knowledge. Since c0 as formed by V0 is ran-
domly distributed, wiretappers cannot infer anything from the protocol executions
of honest receivers. More generally, the blinding-invariance property remains valid
even if V0 can wiretap the issuing as well as the showing protocol executions of hon-
est parties, assuming that these use their certiﬁed key pairs only in zero-knowledge
showing protocols.
The following negative result shows that Proposition 4.3.10 cannot easily be gen-
eralized.
Proposition 4.3.11. If P0 performs protocol executions in parallel with respect to
different attribute tuples, then V0 can obtain a certiﬁed key pair for which the putative
restrictive blinding-invariant part is not equal to any of these tuples.
Proof. Suppose that P0 performs its protocol executions with respect to t > 1 dif-
ferent attribute tuples, (x11, . . . , xl1), . . . , (x1t, . . . , xlt). In the following attack, V0
engages in parallel in t protocol executions, each with respect to one of the tuples.
Assume without loss of generality that the j-th protocol execution is with respect to
the tuple (x1j, . . . , xlj) and let hj := l
i=1 gxij
i
, for all j ∈{1, . . . , t}.4
Step 1. V0 obtains t numbers, a01, . . . , a0t ∈Z
∗
n from P0, by engaging in Step 1 of
all t protocol executions.
Step 2. V0 chooses t numbers, α1, . . . , αt ∈Zv, subject to 	t
i=1 αi = 1 mod v.
V0 computes
h′ :=
t
i=1
hαi
i
and
c′
0 := Hn,v(h′,
t
i=1
a0i).
For all i ∈{1, . . ., t}, V0 then computes c0i := αic′
0 mod v and sends c0i to
P0 in Step 2 of the i-th protocol execution.
4The ordering of protocol executions assumed here follows for instance from the time order in which
V0 processes the ﬁrst message of each protocol execution.

4.3 ANALYSIS
159
Step 3. V0 obtains t numbers, r01, . . . , r0t ∈Z
∗
n from P0, by engaging in Step 3 of
all t protocol executions.
If V0 accepts in all t protocol executions, it computes
r′
0 :=
t
i=1
r0i(h0hi)(αic′
0)divvh
−((	t
i=1 αi)divv)
0
.
(The additional operations needed to blind the certiﬁed key pair have been left out
only for reason of clarity; they are easy to incorporate.)
If the t responses of P0 are all correct, then (c′
0, r′
0) is a certiﬁcate of P0 on h′:
(r′
0)v
=
 t
i=1
r0i(h0hi)(αic′
0)divvh
−((	t
i=1 αi)divv)
0
v
=
t
i=1
rv
0i(h0hi)v((αic′
0)divv)h
−v((	t
i=1 αi)divv)
0
=
t
i=1
(h0hi)c0ia0i(h0hi)v((αic′
0)divv)h
−v((	t
i=1 αi)divv)
0
=
t
i=1
(h0hi)αic′
0 mod va0i(h0hi)v((αic′
0)divv)h
−v((	t
i=1 αi)divv)
0
=
t
i=1
(h0hi)αic′
0a0ih
−v((	t
i=1 αi)divv)
0
=
(h
	t
i=1 αi
0
)c′
0
t
i=1
hαic′
0
i
a0ih
−v((	t
i=1 αi)divv)
0
=
(h
	t
i=1 αi mod v
0
)c′
0
t
i=1
(hαi
i )c′
0a0i
=
hc′
0
0 (h′)c′
0
t
i=1
a0i
=
(h0h′)c′
0
t
i=1
a0i.
From
h′ =
l
j=1
g
	t
i=1 αixij
j

160
RESTRICTIVE BLIND ISSUING PROTOCOLS
it is clear that V0 can obtain a certiﬁed key pair for which the secret key does not
contain any of the t attribute tuples with respect to which the protocol executions
have been performed.
In fact, if t > l then V0 can target any attribute tuple it desires, assuming a certain
linear independence property; see Proposition 4.3.15 for details.
The attack in the proof of Proposition 4.3.11 requires V0 to engage in parallel
executions of the issuing protocol, because each of the t challenges of V0 depends on
all t initial witnesses. In case P0 does not perform protocol executions with respect to
different attribute tuples in parallel, it seems that V0 can only obtain certiﬁed key pairs
that comprise one of the t tuples with respect to which the protocol executions have
been performed. This isolation property is formalized by the following assumption.
Assumption 4.3.12. There exists a hash function H(·) such that the following holds
for all l, t ≥1. Let t attribute tuples,
(x11, . . . , xl1), . . . , (x1t, . . . , xlt),
be formed. Let (x∗
1, . . . , x∗
l , α) denote the secret key of a certiﬁed key pair computed
by V0 in RSAREP-based scheme I after engaging in polynomially many protocol
executions with respect to tuples (x1i, . . . , xli), i ∈{1, . . . , t} of its own choice
(possibly adaptively chosen). If P0 does not perform protocol executions with respect
to distinct attribute tuples in parallel, then with overwhelming probability there exists
i ∈{1, . . ., t} such that (x∗
1, . . . , x∗
l ) = (x1i, . . . , xli). More generally, the second
property in Deﬁnition 4.1.1 holds.
For DLREP-based scheme II and RSAREP-based scheme II, the analogous as-
sumption can be proved in the random oracle model, provided that P0 performs no
more than polylogarithmically many protocol executions. Note that the assumption
does not forbid protocol executions with respect to the same attribute tuple to be
performed in parallel.
4.3.4
Additional properties
P0 knows the numbers (x1, . . . , xl) that end up in the secret key of V0. Once P0
gets to see h′ and for some reason (for instance because x1 is an identiﬁer that V0
discloses in the showing protocol) is able to link it to the protocol execution in which
it was certiﬁed, it can compute h′/h = αv
1. According to Proposition 4.3.4, α1 is
uncorrelated to the view of P0 in ( P0, V0). In Section 2.2.3 we have seen that if any
DRSA leads to a one-way RSA function, then a random choice for α1 certainly will.
From this we get the following result.
Corollary 4.3.13. If (IRSA, DRSA) is invulnerable for the RSA-function, and does not
output the factorization of n as side information, then P0 cannot compute the secret

4.3 ANALYSIS
161
key of V0 from the certiﬁed public key of V0 even if P0 knows the encoded attribute
tuple (x1, . . . , xl).
Therefore, only V0 can feasibly perform a (signed) proof of knowledge of a se-
cret key corresponding to its certiﬁed public key(s). Note that the interests of P0
and V0 are aligned, because (IRSA, DRSA) needs to be invulnerable to guarantee the
unforgeability of certiﬁed key pairs. If the issuing protocol is combined with one of
the RSAREP-based showing protocols of Chapter 3, and V0 does not disclose at least
part of the encoded attribute tuple, then not even P0 will be able to determine V0’s
secret key. The latter property is desirable to achieve non-repudiation, especially in
the case of limited-show certiﬁcates; see Section 5.5.3 for details.
A similar result holds for the other three certiﬁcate schemes constructed in Sec-
tion 4.2. The DLREP-based schemes have the advantage that a trapdoor is not known
to exist, so that P0 may generate the system parameters by itself.
The following property clariﬁes the nature of the certiﬁcate scheme.
Proposition 4.3.14. RSAREP-based scheme I is a secret-key certiﬁcate scheme.
Proof. We construct a polynomial-time simulation algorithm S that generates cer-
tiﬁed public keys with the same probability distribution as that according to which
they are generated in the issuing protocol between P0 and V0. On given as input
n, v, h0, (g1, . . . , gl) and Hn,v(·), S generates two random numbers α2, α3 ∈Z
∗
n,
computes h := h−1
0 αv
2, c0 := Hn,v(h, αv
3) and r0 := αc0
2 α3, and outputs the pair
h, (c0, r0). The output of S is a certiﬁed public key:
c0
=
Hn,v(h, αv
3)
=
Hn,v(h, (r0α−c0
2
)v)
=
Hn,v(h, rv
0(αv
2)−c0)
=
Hn,v(h, rv
0(h0h)−c0).
Since v is co-prime to ϕ(n), and α2 and α3 in Step 1 are chosen at random from Z
∗
n,
the output distribution of A is identical to that of certiﬁed public keys issued to V0
by P0.
The other three schemes described in Section 4.2 are secret-key certiﬁcate schemes
as well. For the advantages of this property, see Section 2.6 and Section 5.2.2.
For any of the certiﬁcate schemes in Section 4.2, a limited degree of paralleliza-
tion can be achieved without any modiﬁcations. Observe that the crux of the proof
of Proposition 4.3.10 is that (P0, V0) is a proof of knowledge of the v-th root of h0h,
but not of the v-th root of h0. Elaborating on this observation, we can obtain the
following result.
Proposition 4.3.15. There exists a hash function H(·) such that the following holds.
Let (x∗
1, . . . , x∗
l , α) denote the secret key of a certiﬁed key pair computed by V0 in

162
RESTRICTIVE BLIND ISSUING PROTOCOLS
RSAREP-based scheme I after engaging in polynomially many protocol executions
(that may be arbitrarily interleaved) with respect to attribute tuples (x1i, . . . , xli),
for i ∈{1, . . . , t}, of its own choice, subject to the restriction that the tuples are
formed independently of h0. If Assumption 4.3.9 holds, then for all l, t ≥1, with
overwhelming probability (1, x∗
1, . . . , x∗
l ) is contained in the linear span of the t
vectors (1, x1i, . . . , xli), for i ∈{1, . . . , t}. In particular, if t ≤l the second property
in Deﬁnition 4.1.1 holds.
In other words, if P0 performs protocol executions with respect to up to t ≤l
independent tuples in parallel, it can still encode l −t + 1 attributes into the secret
key of each certiﬁed key pair that V0 ends up with. The same holds for the DLREP-
based schemes. This immunization technique is not very practical, though, because
the degree of parallelization depends on l and the number of attributes to be encoded.
In the next section we show how to guarantee security in the presence of arbitrary
parallelization.
4.4
Parallelization of protocol executions
Whether or not the measure of not running protocol executions with respect to dif-
ferent attribute tuples in parallel poses a performance bottleneck depends on the ap-
plication at hand. Sequential protocol executions need not be inefﬁcient, because P0
can send out a0 for a new protocol execution as soon as it has received the challenge
c0 for the current protocol execution. To prevent queuing, P0 should abort an ex-
ecution of the issuing protocol if a predetermined time lag between the transmittal
of a0 and the reception of c0 is exceeded; the receiver must then try again in a later
protocol execution. Assuming that requests for protocol executions arrive in accor-
dance with a Poisson process, this strategy is the M/D/1 model with feedback known
from queueing theory. The feedback may be purposely limited by P0, to shut out
parties that frequently exceed the permitted time lag. Furthermore, executions of the
certiﬁcate issuing protocol can be scheduled to take place at a convenient time and
can be repeated if necessary. Also, remember that protocol executions with respect
to the same attribute tuple may always be performed in parallel.
The ability to arbitrarily interleave protocol executions offers two beneﬁts in
highly demanding applications:
• The role of P0 can be performed by distributed processors that need not com-
municate or synchronize; they merely need access to the same secret key.
• Receivers can go off-line between Step 1 and Step 2, in principle for as long
as they please. P0 in Step 1 could even send to V0 an authenticated encryption
of the random bits it used to form its initial witness, and have V0 return it in
Step 2. (Obviously, P0 must prevent replay.) In the RSAREP-based protocols

4.4 PARALLELIZATION OF PROTOCOL EXECUTIONS
163
V0 may even form a0 on its own as the output of a sufﬁciently strong one-way
function, as pointed out in Section 4.2.3.
In the following two sections we describe two techniques to “immunize” the certiﬁ-
cate schemes of Section 4.2 against parallel mode attacks. Both immunizations admit
arbitrary parallelization, and do not affect the deﬁnition of the system parameters and
P0’s public key; only the deﬁnition of a certiﬁcate changes slightly.
4.4.1
Masking the initial witness
Our ﬁrst immunization technique aims to destroy the multiplicative relation in the
initial witnesses that is exploited by V0 in Step 2 of the parallel mode attack of Propo-
sition 4.3.11. It applies to both DLREP-based schemes and to both RSAREP-based
schemes.
Concretely, to enable full parallelization of protocol executions in RSAREP-
based scheme I, we have P0 send fn,v(a0) instead of a0 in Step 1 of the issuing
protocol. The function {fi(·)}i∈{(n,v)} must satisfy the following two requirements:
1. For random a0, b0 ∈Z
∗
n, it is easy to compute fn,v(a0b0) from fn,v(a0) and
b0.
2. For random a0, b0 ∈Z
∗
n, it is infeasible to compute a triple
α ̸= 0 mod v, β ̸= 0 mod v, fn,v(aα
0 bβ
0)
from fn,v(a0) and fn,v(b0).
The ﬁrst requirement ensures that V0 can retrieve certiﬁed public keys in exactly
the same manner as in the original issuing protocol, while the second requirement
prevents parallel mode attacks based on the exploitation of multiplicative properties.
The second requirement may be weakened by having P0 time the delay between
sending out a0 and receiving c0, aborting when a predetermined time bound is ex-
ceeded; it then sufﬁces that triples α ̸= 0 mod v, β ̸= 0 mod v, fn,v(aα
0 bβ
0) cannot
be computed within the imposed time bound. Note that we do not require that the
computation of fn,v(aα
0 ) from fn,v(a0) be infeasible.
Correspondingly, the following modiﬁcations must be made to RSAREP-based
scheme I:
• The pair (c′
0, r′
0) is redeﬁned to be a certiﬁcate of P0 on h′ if and only if
c′
0 = Hn,v(h′, fn,v((r′
0)v(h0h′)−c′
0)).
• In Step 1 of the issuing protocol, P0 sends fn,v(a0) instead of a0.

164
RESTRICTIVE BLIND ISSUING PROTOCOLS
• In Step 2 of the issuing protocol, V0 computes c′
0 according to
c′
0 := Hn,v(h′, fn,v(αv
2(h0h)α3a0)).
V0 can compute c′
0 by virtue of the ﬁrst requirement for f(·).
• V0 accepts if and only if fn,v(rv
0(h0h)−c0) is equal to the number provided by
P0 in Step 1.
Note that the deﬁnition of a key pair for V0 is not affected; only the deﬁnition of a
certiﬁcate is changed. The resulting scheme is depicted in Figure 4.6.
Proposition 4.4.1. If f(·) is one-to-one, then the immunized RSAREP-based scheme
I is at least as secure as the original scheme.
The proof is trivial: the security of the immunized scheme is easily seen to reduce
to that of the original scheme in case it is feasible to invert f(·).
Assumption 4.4.2. There exists a function f(·) and a hash function H(·) such that
the issuing protocol of the immunized RSAREP-based scheme I is restrictive blind
with blinding-invariant part (x1, . . . , xl), even when protocol executions with respect
to different attribute tuples are arbitrarily interleaved.
A concrete suggestion for a one-to-one function f(·) satisfying our two require-
ments is the following. Let M be a random prime such that n divides M −1, and let
F be a random element of order n in Z
∗
M. Deﬁne
fn,v : a0 →F a0 mod M
∀a0 ∈Z
∗
n.
It is easy to see that the ﬁrst requirement for f(·) is met. Whether the second require-
ment is met depends on the hardness of the Difﬁe-Hellman problem [136]; this is the
problem of computing gab, on input (g, ga, gb) for random a, b and a random group
element g of large order. It is widely believed that there exist groups in which the
ability to solve the Difﬁe-Hellman problem is polynomial-time equivalent to the abil-
ity to compute discrete logarithms; see Maurer and Wolf [258] for partial evidence.
Proposition 4.4.3. Suppose there exist positive integers (α, β) and a polynomial-
time algorithm that, on given as input a randomly chosen tuple (n, M, F) of the
speciﬁed format and a pair (F a0 mod M, F b0 mod M) for randomly chosen a0, b0
in Z
∗
n, outputs F aα
0 bβ
0 mod M with non-negligible success probability. Then the
Difﬁe-Hellman problem in groups Z
∗
M, with M of the speciﬁed form, is tractable.
The proof of this proposition makes use of standard techniques, and is therefore
omitted.
Proposition 4.4.3 does not sufﬁce to prove the second requirement, because it per-
tains only to algorithms that compute F aα
0 bβ
0 mod M for ﬁxed (α, β). Nevertheless,
it provides evidence in favor of f(·) meeting the second requirement.

4.4 PARALLELIZATION OF PROTOCOL EXECUTIONS
165
P0
V0
SYSTEM PARAMETERS
(n, v) := IRSA(1k)
KEY SET-UP
Secret key: factorization of n
h0, g1, . . . , gl ∈R Z
∗
n
Public key:
h0, (g1, . . . , gl)
Additional information:
Hn,v(·), fn,v(·)
PROTOCOL
a0 ∈R Z
∗
n
a∗
0 := fn,v(a0)
a∗
0
−−→
α1, α2 ∈R Z
∗
n
α3 ∈R Zv
h′ := hαv
1
c′
0 := Hn,v(h′, fn,v(αv
2(h0h)α3a0))
c0 := c′
0 + α3 mod v
c0
←−−
r0 := ((h0h)c0a0)1/v
r0
−−→
fn,v(rv
0(h0h)−c0) ?= a∗
0
r′
0 := r0α2α
c′
0
1 (h0h)(c′
0+α3)divv
Figure 4.6: Immunization I of RSAREP-based scheme I.

166
RESTRICTIVE BLIND ISSUING PROTOCOLS
This immunization technique also applies to the other three certiﬁcate schemes
described in Section 4.2. Its drawback is decreased performance: V0 cannot precom-
pute the application of fn,v(·) in Step 2, and certiﬁcates are larger and more costly
to verify. Furthermore, an elliptic curve implementation of the immunized DLREP-
based schemes seems out of the question.
4.4.2
Swapping exponents in the veriﬁcation relation
The second immunization technique applies to both DLREP-based schemes as well
as to RSAREP-based scheme II, and fully preserves their efﬁciency. On the down-
side, it does not apply to RSAREP-based scheme I, and it is unclear how to prove
unforgeability in the random oracle model.
The required modiﬁcations are the result of swapping the position of the chal-
lenge with that of (one of) the response(s) in the veriﬁcation relation. In the case of
DLREP-based scheme I, the certiﬁcate veriﬁcation relation
c′
0 = Hq,g0(h′, gr′
0
0 (h0h′)−c′
0),
becomes
c′
0 = Hq,g0(h′, gc′
0
0 (h′)r′
0).
The secret key of V0 is redeﬁned to be a DL-representation of h′ with respect to
(g1, . . . , gl, h0), instead of with respect to (g1, . . . , gl, g0). No changes are needed
to the process of generating the system parameters. The issuing protocol is modiﬁed
correspondingly, as follows:
Step 1. P0 generates a random number w0 ∈Zq, and sends a0 := gw0
0
to V0.
Step 2. V0 generates three random numbers α1 ∈Z
∗
q and α2, α3 ∈Zq. V0 com-
putes h′ := (h0h)α1, c′
0 := Hq,g0(h′, gα2
0 (h0h)α3a0), and sends c0 := c′
0 −
α2 mod q to P0.
Step 3. P0 sends r0 := (w0 −c0)/(x0 + 	l
i=1 xiyi) mod q to V0.5
V0 accepts if and only if gc0
0 (h0h)r0 = a0. If this veriﬁcation holds, V0 computes
r′
0 := (r0 + α3)/α1 mod q. The resulting scheme is depicted in Figure 4.7.
It is easy to verify that the protocol is complete, and that (c′
0, r′
0) is a secret-key
certiﬁcate of P0 on h′. Excluding public keys h′ that are equal to 1, the following
result can be proved in a manner similar to the proof of Proposition 4.3.4.
5To guarantee that P0 can always perform Step 3, the attribute tuple that is encoded must satisfy
(x0 + 	l
i=1 xiyi) ̸= 0 mod q. Since ﬁnding a tuple for which equality hold should be infeasible for
V0 there is no need to check for this.

4.4 PARALLELIZATION OF PROTOCOL EXECUTIONS
167
P0
V0
SYSTEM PARAMETERS
(q, g0) := IDL(1k)
KEY SET-UP
x0 := DDL(q, g0)
y1, . . . , yl ∈R Zq
Secret key: x0, (y1, . . . , yl)
h0 := gx0
0
gi := gyi
0 ∀i ∈{1, . . . , l}
Public key:
h0, (g1, . . . , gl)
Additional information:
Hq,g0(·)
PROTOCOL
w0 ∈R Zq
a0 := gw0
0
a0
−−→
α1 ∈Z
∗
q
α2, α3 ∈R Zq
h′ := (h0h)α1
c′
0 := Hq,g0(h′, gα2
0 (h0h)α3a0)
c0 := c′
0 −α2 mod q
c0
←−−
r0 := (w0 −c0)/(x0 + 	l
i=1 xiyi) mod q
r0
−−→
gc0
0 (h0h)r0 ?= a0
r′
0 := (r0 + α3)/α1 mod q
Figure 4.7: Immunization II of DLREP-based scheme I.

168
RESTRICTIVE BLIND ISSUING PROTOCOLS
Proposition 4.4.4. For any properly formed system parameters in the immunized
DLREP-based scheme I, if V0 follows the issuing protocol and accepts, then it obtains
a certiﬁed key pair comprising a perfectly blinded certiﬁed public key, regardless of
the behavior of P0.
Obtaining a certiﬁcate on h′ = 1 seems infeasible; it implies the ability to com-
pute a number c0 ∈Zq such that Hq,g0(1, gc0
0 ) = c0. However, there is no need
to make an assumption to this effect, since this case can be recognized and declared
invalid.
While it would seem that the unforgeability of the modiﬁed certiﬁcate scheme
can be proved in a manner similar to the proof of Proposition 4.3.6, this is not the
case. Nevertheless, unforgeability is believed to hold for the modiﬁed scheme as
well.
We now arrive at the crucial difference with DLREP-based scheme I. The parallel
mode attack described in the proof of Proposition 4.3.11 does not apply, because V0
in Step 2 has to solve linear relations in terms of the responses of P0, which it cannot
anticipate at that time.
Assumption 4.4.5. There exists a hash function H(·) such that in the immunized
DLREP-based scheme I the following holds for all l, t ≥1. Let t attribute tuples,
(x11, . . . , xl1), . . . , (x1t, . . . , xlt),
be formed. Suppose that V0, after engaging in polynomially many protocol execu-
tions (arbitrarily interleaved) with respect to tuples (x1i, . . . , xli), i ∈{1, . . ., t}
of its own choice (possibly adaptively chosen), outputs a certiﬁed key pair com-
prising a secret key (x∗
1, . . . , x∗
l , α1). With overwhelming probability, there exists
i ∈{1, . . ., t} such that (x∗
1, . . . , x∗
l ) = (α1x1i mod q, . . . , α1xli mod q). More
generally, the second property in Deﬁnition 4.1.1 holds.
Assuming that public keys equal to 1 are declared invalid, it follows that α1 ̸= 0,
and so
(x∗
1/α1 mod q, . . . , x∗
l /α1 mod q) = (x1i, . . . , xli).
The following argument gives some insight as to why the assumption should hold.
If we restrict ourselves in Assumption 4.4.5 to protocol executions that involve the
same (x1, . . . , xl), which is formed independently of h0, then the proof of Proposi-
tion 4.3.10 applies in virtually the same manner, assuming the DL-based analogue to
Assumption 4.3.9. Therefore, attacks must exploit the parallel nature of the issuing
protocol with respect to different attribute tuples, if they are to have a non-negligible
success probability. In the following, we consider only “algebraic” attacks on the
parallel version of the issuing protocol. We restrict ourselves to the case l = 1; it is
easy to prove that if Assumption 4.4.5 holds for l = 1 then it also holds for general l.
Furthermore, we consider only two parallel executions of the issuing protocol, each

4.4 PARALLELIZATION OF PROTOCOL EXECUTIONS
169
with respect to a different blinding-invariant number; the argument can easily be gen-
eralized. Finally, we assume that V0 cannot compute with non-negligible probability
of success a non-trivial representation of 1 with respect to (g0, g1, h0). (It is easy to
prove that logg0 h0 and logg0 g1 do not leak.)
Denote by x10 and x11 ̸= x10 mod q, respectively, the putative blinding-invariant
parts corresponding to each of the parallel two executions of the certiﬁcate issuing
protocol. The goal of V0 is to obtain a certiﬁed public key h′ ̸= 1, (c0, r0) and a
secret key (β0, β1) for h′ such that
β0 ̸= x10β1 mod q
and
β0 ̸= x11β1 mod q.
Knowing (c0, r0) such that
c0 = Hq,g0(h′, gc0
0 (h′)r0)
is equivalent to knowing (a0, r0) such that
g
Hq,g0 (h′,a0)
0
(h′)r0 = a0.
Therefore, the attack target is a triple (β0, β1), h′ = gβ0
1 hβ1
0 , (a0, r0) such that
gc0
0 (gβ0
1 hβ1
0 )r0 = a0, where c0 denotes Hq,g0(gβ0
1 hβ1
0 , a0). Raising the veriﬁcation
relations for each of the two protocol executions to the powers γ0 and γ1, respec-
tively, and multiplying the results, we obtain
gγ0c00+γ1c01
0
hγ0r00+γ1r01
0
gγ0x10r00+γ1x11r01
1
= aγ0
00aγ1
01.
V0 must determine a pair β0, β1, and numbers γ0, γ1, c00, c01 for which the informa-
tion provided by P0 can be combined into a pair (a0, r0) such that
gc0
0 gβ0r0
1
hβ1r0
0
= a0,
where c0 = Hq,g0(gβ0
1 hβ1
0 , a0).
Assume ﬁrst that V0 computes a0 := aγ0
00aγ1
01, for γ0, γ1 ̸= 0 mod q that need not
be explicitly known at the time c00 and c01 have to be provided. V0 must ensure that
gγ0c00+γ1c01
0
hγ0r00+γ1r01
0
gγ0x10r00+γ1x11r01
1
= gc0
0 gβ0r0
1
hβ1r0
0
.
Assume furthermore that γ0 and γ1 are computable by V0 once the attack has been
completed successfully (a plausible assumption given the algebraic nature of the at-
tack). It follows from the assumption that V0 cannot compute a non-trivial represen-
tation of 1 with respect to (g0, g1, h0) that V0 has to (implicitly) solve the following
three relations,
γ0x10r00 + γ1x11r01 = β0r0 mod q,
γ0r00 + γ1r01 = β1r0 mod q,
γ0c00 + γ1c01 = c0 mod q,

170
RESTRICTIVE BLIND ISSUING PROTOCOLS
for (γ0, γ1, β0, β1, c00, c01) and r0. It seems that (γ0, γ1, β0, β1, c00, c01) must be
committed to before r00 and r01 are provided; only r0 can be computed afterwards.
Since r0 can be computed by V0 after r00 and r01 have been received, it may seem
that there are many workable choices for γ0, γ1, β0, β1. This is not true, however,
since V0 has to solve, in terms of γ0, γ1, β0, β1, a single relation that does not involve
r0 but does involve r00 and r01. Multiplying both sides of γ0r00+γ1r01 = β1r0 mod
q by β0/β1 mod q, and subtracting the result from γ0x10r00+γ1x11r01 = β0r0 mod
q, we get
(γ0 (x10 −β0/β1)) r00 + (γ1 (x11 −β0/β1)) r01 = 0 mod q.
Because r00 and r01 cannot be anticipated, and because β0/β1 mod q cannot be
equal to both x10 and x11, the only workable non-zero choices for γ0, γ1, β0, β1 seem
to be to take γ0 = A00r−1
00 mod q and γ1 = A01r−1
01 mod q, or γ0 = A00r01 mod q
and γ1 = A01r00 mod q, for some suitable constants A00 and A01 that may depend
on β0 and β1. To argue that V0 cannot compute a := aγ0
00aγ1
01 for such a choice for
γ0, γ1, we focus on the third relation, γ0c00 + γ1c01 = c0 mod q. (After all, it is
not completely inconceivable that a can be computed in this way before r00 and r01
become known, since r00 and r01 are known to satisfy the two veriﬁcation relations.)
Even if a could be computed, the fact that c0 is the outcome of a sufﬁciently strong
one-way hash function applied to a0 implies that its value cannot be expressed in
terms of r00 and r01. (Note that c0 = Hq,g0(gβ0
1 hβ1
0 , aγ0
00aγ1
01) should imply, by virtue
of the strength of the hash-function, that c0 cannot be chosen as an algebraic func-
tion of β0, β1, γ0, γ1; this trivially holds in the random oracle model.) Consequently,
γ0c00 + γ1c01 = c0 mod q can only be solved for values c00 and c01 that are ex-
pressed in terms of r00, r01. Because c00 and c01 have to be provided by V0 before
r00 and r01 become known, workable choices for γ0 and γ1 should be infeasible.
We assumed in this argument that V0 computes a0 := aγ0
00aγ1
01. The information
contained in
gγ0c00+γ1c01
0
hγ0r00+γ1r01
0
gγ0x10r00+γ1x11r01
1
can be combined into gc0
0 (gβ0
1 hβ1
0 )r0 in a more general way. The most general form
seems to be a0 := aγ0
00aγ1
01gδ0
1 gδ1
1 hδ2
0 for smart choices for δ0, δ1, δ2. Assuming again
that it is infeasible to compute with non-negligible probability of success a non-
trivial representation of 1 with respect to (g0, g1, h0), we can derive three relations
similar to those previously displayed. From the ﬁrst two of these we can again derive
one relation that involves r00 and r01 but not r0, and that relation must be solved
(implicitly) for γ0, γ1, β0, β1. The only way to arrive at a relation in which γ0 and
γ1 are not expressions in terms of r00, r01 (for which the preceding argument ap-
plies) seems to be to choose δ0, δ1 such that γ0r00 + γ1r01 + δ1 = β0r0 mod q and
γ0x10r00 +γ1x11r01 +δ0 = β1r0 mod q are linearly dependent in r0; in that case r0
cannot be made to drop out of the equations. Such choices for δ0, δ1 seem to require
expressions in terms of r00 and r01 that cannot be anticipated.

4.5 OTHER CERTIFICATE SCHEMES
171
This completes our argument as to why Assumption 4.4.5 should hold. Unfor-
tunately, it is unclear how to prove Assumption 4.4.5, even in the random oracle
model.
A similar immunization applies to DLREP-based scheme II; we simply swap
the position of the challenge in the veriﬁcation relation with that of one of the two
responses. The immunization technique does not apply to RSAREP-based scheme
I, since it does not have a response that appears as an exponent in the veriﬁcation
relation. It can be applied to RSAREP-based scheme II, though, but not without a
twist. Redeﬁne a certiﬁcate of P0 on h′ ∈Z
∗
n to be a triple, (c′
0, r′
0, r′
1) ∈Zs ×
Z
∗
n × Zv such that
c′
0 = Hn,v(h′, (r′
0)vf c′
0(h′)−r′
1).
V0’s secret key now is an RSA-representation of h′ with respect to (g1, . . . , gl, h0, v).
In the modiﬁed issuing protocol, V0 can blind h = l
i=1 gxi
i
to h′ = (h0h)βαv
1, for
arbitrary β ∈Zv and α1 ∈Z
∗
n. While in an application this general blinding form
must be taken into account, for unlinkability it sufﬁces for V0 to simply ﬁx β = 1,
say, and use a random α1. The resulting issuing protocol is depicted in Figure 4.8.
(Alternatively, P0 can perform this protocol without using the factorization of n,
similar as described in Section 4.2.3. The protocol can be converted into a two-move
protocol in the manner pointed out in Section 4.2.3.) Now, from h′ one cannot infer
that β ̸= 0 mod v, yet this choice must be prevented. We can get around this by
having V0 in the showing protocol demonstrate that β ̸= 0 mod v, as part of the
formula it is demonstrating: see Section 5.1.1 for details.
4.5
Other certiﬁcate schemes
The certiﬁcate schemes in Sections 4.2 and 4.4 are all based on the digital signature
schemes discussed in Sections 2.5.3 and 2.5.4. As in many areas of cryptography, it is
of interest to have alternatives based on different underlying assumptions, instead of
placing all bets on one horse. In this section we describe two such alternatives. Both
alternatives are believed to be secure even when protocol executions with respect to
different attribute tuples are arbitrarily interleaved.
4.5.1
DSA-like certiﬁcates
The system parameter generation and the key set-up for this scheme are the same as
for DLREP-based scheme I. It is preferable that H(·) do not map arguments to zero,
but since this event should have negligible probability anyway there is no need to
make an assumption to this effect.
For a ∈Gq, let a denote a mod q. In the DSA [277], a signature standard
originally proposed in 1994 by the U.S. National Institute of Standards and Tech-
nology, a signature on a message m with respect to a public key h0 = gx0
0
is a pair

172
RESTRICTIVE BLIND ISSUING PROTOCOLS
P0
V0
SYSTEM PARAMETERS
(n, v) := IRSA(1k)
KEY SET-UP
Secret key: factorization of n
f, h0, g1, . . . , gl ∈R Z
∗
n
Public key:
(f, h0), (g1, . . . , gl)
Additional information:
Hn,v(·)
PROTOCOL
a0 ∈R Z
∗
n
a0
−−−−−→
α1, α2 ∈R Z
∗
n
α3, α4 ∈R Zv
h′ := h0hαv
1
c′
0 := Hn,v(h′, αv
2f−α3(h′)−α4a0)
c0 := c′
0 + α3 mod v
c0
←−−−−−
r1 ∈R Zv
r0 := ((h0h)r1a0/fc0)1/v
r0, r1
−−−−−→
fc0rv
0(h0h)−r1 ?= a0
r′
0 := r0αr1
1 α2f−((c′
0+α3)divv)(h′)−((r1+α4)divv)
r′
1 := r1 + α4 mod v
Figure 4.8: Immunization II of RSAREP-based scheme II.

4.5 OTHER CERTIFICATE SCHEMES
173
(a0, r0) ∈Zq × Zq such that
(g
Hq,g0 (m)/r0
0
ha0/r0
0
) mod q = a0.
The DSA makes the following speciﬁc choices: Gq is constructed using the subgroup
construction, q is a 160-bit prime, and Hq,g0(·) is set equal to SHA-I [276].
We modify the DSA scheme by applying a cyclic left shift to the role of the
exponents, (Hq,g0(m), r0, a0), in the DSA veriﬁcation relation.6 A certiﬁcate of P0
on a public key h′ ̸= 1 is deﬁned to be a pair (a′
0, r′
0) ∈Zq × Zq such that
(g
a′
0/c′
0
0
(h′)r′
0/c′
0) mod q = a′
0,
where c′
0 = Hg,g0(h0, a′
0). The presence of a′
0 in Hq,g0(h0, a′
0) is not mandatory, but
is believed preferable. The secret key of V0 is a DL-representation of h′ with respect
to (g1, . . . , gl, h0).
Let h denote l
i=1 gxi
i . The issuing protocol is as follows:
Step 1. P0 generates a random number w0 ∈Zq, and sends a0 := gw0
0
to V0.
Step 2. V0 generates a random number α1 ∈Z
∗
q and two random numbers α2, α3 ∈
Zq. It computes h′ := (h0h)α1, a′
0 := aα2
0 (h0h)α3, and c′
0 := Hq,g0(h′, a′
0).
Finally, V0 sends c0 := c′
0α2a0a′
0
−1 mod q to P0.
Step 3. P0 sends r0 := (x0 + 	l
i=1 xiyi)−1(c0w0 −a0) mod q to V0. (To guar-
antee that P0 can always perform Step 3, (x1, . . . , xl) must satisfy (x0 +
	l
i=1 xiyi) ̸= 0 mod q.)
V0 accepts if and only if ga0/c0
0
(h0h)r0/c0 = a0. If this veriﬁcation holds, V0 com-
putes r′
0 := α−1
1 (r0a0−1a′
0 + c′
0α3) mod q. The resulting scheme is depicted in
Figure 4.9.
It is easy to verify that the protocol is a proof of knowledge (the probability
that the inverses of a0 and a′
0 are deﬁned is overwhelming) and that (a′
0, r′
0) is a
secret-key certiﬁcate of P0 on h′. As with the schemes in Section 4.4.2, it is unclear
how to reduce the unforgeability of the underlying signature scheme to that of the
new scheme, but unforgeability is believed to hold nevertheless. Furthermore, if V0
follows the issuing protocol and accepts then it obtains a certiﬁed key pair comprising
a perfectly blinded certiﬁed public key.
Assumption 4.4.5 should apply here as well. Following the argument in Sec-
tion 4.4.2, we arrive at three relations that differ only in that γ0c00 + γ1c01 =
c0 mod q is replaced by γ0a00 + γ1a01 = a0 mod q, where a0 = aγ0c00
00
aγ1c01
01
.
6Camenisch, Piveteau, and Stadler [72] applied another shift of the exponents, in order to construct an
ordinary DSA-like blind signature scheme in Chaum’s sense. Their shift does not give rise to a restrictive
blind certiﬁcate scheme that is secure in parallel mode.

174
RESTRICTIVE BLIND ISSUING PROTOCOLS
P0
V0
SYSTEM PARAMETERS
(q, g0) := IDL(1k)
KEY SET-UP
x0 := DDL(q, g0)
y1, . . . , yl ∈R Zq
Secret key: x0, (y1, . . . , yl)
h0 := gx0
0
gi := gyi
0 ∀i ∈{1, . . . , l}
Public key:
h0, (g1, . . . , gl)
Additional information:
Hq,g0(·)
PROTOCOL
w0 ∈R Zq
a0 := gw0
0
a0
−−→
α1 ∈R Z
∗
q
α2, α3 ∈R Zq
h′ := (h0h)α1
a′
0 := aα2
0 (h0h)α3
c′
0 := Hq,g0(h′, a′
0)
c0 := c′
0α2a0a′
0
−1 mod q
c0
←−−
r0 := (x0 + 	l
i=1 xiyi)−1(c0w0 −a0) mod q
r0
−−→
ga0/c0
0
(h0h)r0/c0 ?= a0
r′
0 := α−1
1 (r0a0−1a′
0 + c′
0α3) mod q
Figure 4.9: DSA-like scheme.

4.5 OTHER CERTIFICATE SCHEMES
175
The latter relation seems even harder to handle, although it is unclear how to prove
this intuition.
A drawback of this DSA-like certiﬁcate scheme over the immunized DLREP-
based scheme I in Section 4.4.2 is that V0 cannot precompute the exponentiation aα2
0
in Step 2.
Although the DSA makes the explicit choice Gq ⊂Z
∗
p, an elliptic curve imple-
mentation may be used instead. Indeed, the elliptic curve analog of the DSA, called
the ECDSA, has been adopted as a standard by ISO, by ANSI, by IEEE, and by
NIST; see Johnson and Menezes [223] for an overview. Since numbers in Gq are
represented by coordinate pairs, and base numbers occur also as exponents, a secure
mapping is needed from base numbers to numbers in Zq. One solution is to use the
ﬁrst coordinate; this is the approach taken in the ECDSA.
4.5.2
Certiﬁcates based on Chaum-Pedersen signatures
The following scheme differs from all the other certiﬁcate schemes in this chapter in
that public-key certiﬁcates are issued, not secret-key certiﬁcates. The system param-
eter generation and the key set-up for this scheme are the same as for DLREP-based
scheme I.
Chaum and Pedersen [109] presented a digital signature scheme that can be
viewed as an entangled application of two Schnorr protocol executions; it is an op-
timization of a protocol due to Chaum, Evertse, and van de Graaf [108, Protocol
4]. A signature on a message m with respect to a public key h0 = gx0
0
is a triple
(z, c0, r0) ∈Gq × Zs × Zq such that
c0 = Hq,g0(m, z, gr0h−c0
0
, mr0z−c0).
Chaum and Pedersen deﬁned Gq using the subgroup construction, but an elliptic
curve implementation is permitted as well. They also described how to construct a
blind issuing protocol for their signatures. The interactive Chaum-Pedersen proto-
col is a Fiat-Shamir type proof of knowledge of both logg0 h0 and logm z that also
demonstrates that these two discrete logarithms are equal. For the purpose of ordi-
nary blind signatures, though, the Chaum-Pedersen scheme does not have advantages
over the Schnorr signature scheme.
The situation is different for the restrictive blind certiﬁcate scheme that we will
now construct from their signature scheme by applying our techniques. Deﬁne a
certiﬁcate of P0 on a public key h′ ̸= 1 to be a triple, (z′, c′
0, r′
0) ∈Gq × Zs × Zq
such that
c′
0 = Hq,g0(h′, z′, gr′
0
0 h−c′
0
0
, (h′)r′
0(z′)−c′
0).
The secret key of V0 is a DL-representation (x1, . . . , xl, α1) of h′ with respect to
(g1, . . . , gl, h0), with P0 encoding x1, . . . , xl ∈Zq into V0’s secret key. As before,
let h denote l
i=1 gxi
i . V0 this time needs to know z := (h0h)x0. Hereto P0 must

176
RESTRICTIVE BLIND ISSUING PROTOCOLS
either compute z for V0 or publish (gx0
1 , . . . , gx0
l , hx0
0 ) along with its public key; in
the latter case, V0 can compute z by itself.
The issuing protocol is as follows:
Step 1. P0 generates a random number w0 ∈Zq, and sends a0 := gw0
0
and b0 :=
(h0h)w0 to V0.
Step 2. V0 generates a random number α1 ∈Z
∗
q and two random numbers α2, α3 ∈
Zq.
V0 computes h′ := (h0h)α1, z′ := zα1, a′
0 := hα2
0 gα3
0 a0, b′
0 :=
(z′)α2(h′)α3bα1
0 , c′
0 := Hq,g0(h′, z′, a′
0, b′
0), and sends c0 := c′
0 + α2 mod q
to P0.
Step 3. P0 sends r0 := c0x0 + w0 mod q to V0.
V0 accepts if and only if gr0
0 h−c0
0
= a0 and (h0h)r0z−c0 = b0. If this veriﬁcation
holds, then V0 computes r′
0 := r0 + α3 mod q. (Alternatively, V0 ﬁrst computes
r′
0 and then checks whether (g0h′)r′
0(h0z′)−c′
0 = a′
0b′
0.) The resulting scheme is
depicted in Figure 4.10.
It is easy to verify that the protocol is a Fiat-Shamir type proof of knowledge,
and that (z′, r′
0, c′
0) is a certiﬁcate of P0 on h′ if V0 accepts. The witness-hiding
property can be argued in the same manner as with the Schnorr proof of knowledge,
but no proof is known. The unforgeability of certiﬁcates follows directly from the
unforgeability of blind Chaum-Pedersen signatures and the fact that V0 cannot know
two different DL-representations of the same public key. Proving the latter fact is
trivial: P0 can perform the protocol without knowing a non-trivial DL-representation
of 1 with respect to (g1, . . . , gl, h0), and in particular it may generate g1, . . . , gl at
random.
Excluding public keys h′ equal to 1, it can be shown that V0 obtains a certiﬁed key
pair comprising a perfectly blinded certiﬁed public key. Finally, Assumption 4.4.5 is
believed to apply.
This certiﬁcate scheme has several drawbacks in comparison to DLREP-based
schemes I and II and their immunization described in Section 4.4.2:
• Certiﬁcates are larger and more costly to verify.
• V0’s computation of bα1
0
in Step 2 of the issuing protocol cannot be prepro-
cessed.
• It is not clear how to prove the property of restrictive blinding even when only
sequential protocol executions involving the same attribute tuple are consid-
ered.
• The scheme is a public-key certiﬁcate scheme; certiﬁed public keys cannot be
simulated.

4.5 OTHER CERTIFICATE SCHEMES
177
P0
V0
SYSTEM PARAMETERS
(q, g0) := IDL(1k)
KEY SET-UP
x0 := DDL(q, g0)
y1, . . . , yl ∈R Zq
Secret key: x0, (y1, . . . , yl)
h0 := gx0
0
g1, . . . , gl ∈R Gq
Public key:
h0, (g1, . . . , gl)
Additional information:
Hq,g0(·), z := (h0h)x0
PROTOCOL
w0 ∈R Zq
a0 := gw0
0
b0 := (h0h)w0
a0, b0
−−−−−→
α1 ∈Z
∗
q
α2, α3 ∈Zq
h′ := (h0h)α1
z′ := zα1
a′
0 := hα2
0 gα3
0 a0
b′
0 := (z′)α2(h′)α3bα1
0
c′
0 := Hq,g0(h′, z′, a′
0, b′
0)
c0 := c′
0 + α2 mod q
c0
←−−−−−
r0 := c0x0 + w0 mod q
r0
−−−−−→
gr0
0 h−c0
0
?= a0
(h0h)r0z−c0 ?= b0
r′
0 := r0 + α3 mod q
Figure 4.10: Scheme based on Chaum-Pedersen signatures.

178
RESTRICTIVE BLIND ISSUING PROTOCOLS
On the upside, P0 can perform the issuing protocol without knowing (x1, . . . , xl).
This has several advantages:
• P0 can certify attributes without needing to know them. Hereto V0 forms h as
its commitment to attributes x1, . . . , xl−1 (the number xl must be generated
at random to unconditionally hide the l −1 attributes) and at the start of the
issuing protocol presents this to P0 together with a proof of knowledge of a
DL-representation with respect to (g1, . . . , gl).
• More generally, P0 can certify attributes of which it knows no more than a
property demonstrated by V0. V0 can demonstrate this property when present-
ing h by using the showing protocol techniques, for instance by sending along
a signed proof.
• P0 can recertify previously certiﬁed attributes without knowing their values;
see Section 5.2.1 for details. (It cannot update their values, though; for this an
RSAREP-based issuing protocol is needed.)
• It is possible to protect against framing attempts by parties with unlimited com-
puting resources; see Section 5.5.3 for details.
Whether these advantages are desirable depends on the application at hand.
Another advantage is that the delegation strategy (see Section 2.6) is excluded
altogether, because public-key certiﬁcates are used. This is not the case for the cer-
tiﬁcate issuing schemes based on secret-key certiﬁcates, as Section 5.1.2 will show.
4.6
Bibliographic notes
The notion of restrictive blinding in Section 4.1 originates from Brands [46, 48].
Deﬁnition 4.1.1 appears here for the ﬁrst time.
The four certiﬁcate schemes in Section 4.2 originate from Brands [54]. The case
l = 2 of DLREP-based scheme I was introduced by Brands [49] for the purpose of
withdrawing electronic coins with embedded identiﬁers in an off-line electronic cash
system. The case l = 1 of RSAREP-based scheme I was analyzed by Brands [51].
The security proofs presented in Section 4.3.3 are stronger than those in [49, 51], in
that the reductions are based on any invulnerable instance generator instead of one
speciﬁc distribution.
The immunization technique described in Section 4.4.1 is due to Brands [50].
The immunized DLREP-based schemes in Section 4.4.2 are a generalization of a
withdrawal protocol devised by Schoenmakers [341] in the context of electronic cash.
The immunization described in Section 4.4.2 of RSAREP-based scheme II, which
is based on a new twist, appears here for the ﬁrst time; previously, the immunization
technique of Schoenmakers was believed not to apply to RSAREP-based schemes.

4.6 BIBLIOGRAPHIC NOTES
179
The DSA-based certiﬁcate scheme described in Section 4.5.1 has not previously
appeared in the academic literature.
Brands [46, 48] introduced the special case l = 2 of the scheme in Section 4.5.2,
for the purpose of designing an off-line electronic cash scheme. Cramer and Peder-
sen [122] subsequently used this scheme to modify a protocol by Chaum and Ped-
ersen [109]; the slightly more general form used by them was already considered
by Brands [46, page 27 & 28]. Radu, Govaerts, and Vandewalle [316] proposed a
variation to make the scheme provably witness-hiding, but their variation does not
improve the overall security of the scheme.


Chapter 5
Combining Issuing and
Showing Protocols
In this chapter we show how to seamlessly combine the showing protocol techniques
of Chapter 3 with the issuing protocol techniques of Chapter 4, without adding com-
plexity and without compromising security or privacy. We develop additional privacy
techniques, for both certiﬁcate holders and certiﬁcate veriﬁers, and design limited-
show certiﬁcates that reveal all the encoded attributes in case of fraud. We also design
software-only techniques that enable the CA to discourage a variety of frauds.
5.1
Integration
Consider a PKI with one CA, many certiﬁcate holders (provers), and many veriﬁers.
To gain access to a secure “service” provided by a veriﬁer V, P must demonstrate
to V its possession of a certiﬁcate of the CA on attributes that meet certain criteria.
The CA will issue a certiﬁcate to P only after the latter has authenticated itself or
proved its right to obtain such a certiﬁcate. Clearly, the CA can non-interactively
issue an ordinary digital signature on a public key h of P constructed as described in
Chapter 3, but this does not offer any privacy with respect to the CA. In this section
we show how to combine the showing protocol techniques of Chapter 3 with the
issuing protocol techniques of Chapter 4.
5.1.1
Making the match
The case of DLREP-based scheme I or II or the immunization in Section 4.4.1
Suppose that the CA (playing the role of P0) uses DLREP-based scheme I or II, or
their immunization described in Section 4.4.1. P (playing the role of V0) obtains a

182
COMBINING ISSUING AND SHOWING PROTOCOLS
certiﬁcate of the CA on a public key h′ of the form
gx1
1 · · · gxl
l gα1
0 ,
where x1, . . . , xl ∈Zq are the encoded attributes and α1 ∈Zq is a random number
chosen by P. P can subsequently demonstrate to V a property about the encoded
attributes, in the manner described in Chapter 3. The perfect ﬁt of the issuing and
showing protocols is illustrated by the dual role now played by the blinding factor α1:
it ensures that h′ is uncorrelated to the view of the CA in the issuing protocol, and also
that P in the showing protocol does not reveal anything about the encoded attributes
beyond the validity of the formula it demonstrates (see Proposition 3.6.1(c)).
It is not hard to prove the following generalization of Proposition 4.3.4.
Proposition 5.1.1. Suppose that P follows the issuing protocol and uses the result-
ing certiﬁed key pair in a showing protocol execution in which it demonstrates some
property of the encoded attributes. The view that V can obtain could have originated
(with uniform probability) from any one of the issuing protocol executions in which
P0 encoded attributes that P0 knows satisfy this particular property.
This result applies even when P0 and V conspire throughout, and applies also to
the other protocol combinations considered in this section.
The case of the other DLREP-based schemes in Chapter 4
The match between the showing protocol techniques and the other DLREP-based
issuing protocols described in Chapter 4 seems more problematic at ﬁrst. P obtains
a certiﬁcate on a public key h′ of the form
(gx1
1 · · · gxl
l h0)α1,
where α1 ∈Z
∗
q is a random number chosen by P. The blinding factor this time
spreads across all exponents. This does not limit the applicability of our showing
protocol techniques in any way, though. There are two approaches:
• If α1 ̸= 0 mod q (which is required) then
h−1
0
= gx1
1 · · · gxl
l (h′)−1/α1,
and so P can demonstrate Boolean formulae for the DL-representation that
it knows of h−1
0
with respect to (g1, . . . , gl, h′). Although h′ is not a ﬁxed
generator speciﬁed by the CA, the security properties are not adversely af-
fected. Namely, the ability to prove knowledge of a DL-representation of h−1
0
with respect to (g1, . . . , gl, h′) implies the ability to prove knowledge of a DL-
representation of h′ with respect to (g1, . . . , gl, h0). Proposition 3.6.1(b) is
easily seen to apply. The showing protocol techniques and results in Chapter 3

5.1 INTEGRATION
183
apply without change, because the distribution of −1/α1 mod q is statistically
indistinguishable from the uniform distribution over Zq. Note that P’s abil-
ity to demonstrate a Boolean formula, and thus to prove knowledge of a DL-
representation of h−1
0
with respect to (g1, . . . , gl, h′), implicitly demonstrates
that α1 ̸= 0 mod q (much as in Section 3.4.1).
• The above twist of considering DL-representations of h−1
0
with respect to
(g1, . . . , gl, h′) is not necessary. Consider h′ = gx1α1
1
· · · gxlαl
l
hα1
0 . Let z0 :=
α1, and let zi denote xiα1 mod q, for all i ∈{1, . . ., l}. V can verify that
α1 ̸= 0 mod q by checking that h′ ̸= 1, and so demonstrating that x1 =
βx2+γ mod q, say, is equivalent to demonstrating that z1 = βz2+γz0 mod q.
This we can handle by using our demonstration technique for linear relations.
It is easy to see that any Boolean formula can be handled in this manner.
As will be shown in Section 5.1.2, both approaches have unique security implications
with respect to the delegation strategy in case they are combined with a secret-key
certiﬁcate issuing protocol that admits arbitrary parallelization.
The second approach results exactly in the ﬁrst approach if we have P in addition
demonstrate that z0 ̸= 0, as part of the formula it is to demonstrate. In the example,
the formula would become (z1 = βz2 + γz0) AND NOT(z0 = 0). Of course, V in
that case need no longer check that h′ ̸= 1.
Since P0 in the issuing protocol in Section 4.5.2 need not know the attributes it
encodes, certiﬁcate holders can enjoy even greater privacy.
The case of RSAREP-based scheme I or II or the immunization in Section 4.4.1
To encode attributes x1, . . . , xl ∈Zv into a certiﬁed key pair for P, the CA and P
engage in RSAREP-based scheme I or II or their immunization described in Sec-
tion 4.4.1. P obtains a certiﬁcate of the CA on a public key h′ of the form
gx1
1 · · · gxl
l αv
1,
where α1 ∈Z
∗
n is a random number chosen by P, playing the same dual role as in
the case of the DLREP-based schemes. The rest is clear.
The case of the immunized RSAREP-based scheme II in Section 4.4.2
Finally, in the second immunization of RSAREP-based scheme II, described in Sec-
tion 4.4.2, P obtains a certiﬁcate on a public key h′ of the form
gx1β
1
· · · gxlβ
l
hβ
0αv
1.
In the showing protocol, P must demonstrate that β ̸= 0 mod v. If β ̸= 0 mod v,
then the RSA-representation P knows of h−1
0
with respect to ((h′)−1, g1, . . . , gl, v)
is
(e mod v, x1, . . . , xl, z),

184
COMBINING ISSUING AND SHOWING PROTOCOLS
where e, f ∈Z satisfy eβ+fv = 1, and z is the product of αe
1 and the powers of l+2
junk factors resulting from normalization. It is easy to see that proving knowledge
of an RSA-representation of h−1
0
with respect to ((h′)−1, g1, . . . , gl, v) sufﬁces to
demonstrate β ̸= 0 mod v; this is a simple application of the technique described in
Section 3.4.2. Therefore, according to the equivalent of Proposition 3.6.1(b) for the
RSAREP function, P demonstrates β ̸= 0 mod v as a by-product of demonstrating
any Boolean formula for the RSA-representation it knows of h−1
0
with respect to
((h′)−1, g1, . . . , gl, v). Alternatively, and more efﬁciently, P simply demonstrates
that β = 1 mod v as part of the formula it is demonstrating; there is no need to hide
β.
Remarks
In many PKIs, only the ability to demonstrate Boolean formulae involving the at-
tributes (i.e., not the more general form of linear relations) is required. In these PKIs
the CA can encode attributes that contain more than |q| or |v| bits of information,
such as digitally encoded photographs. Consider by way of example a certiﬁcate on
a DLREP-based public key of the form
g
Fq,gl (x1)
1
· · · g
Fq,gl (xl−1)
l−1
gxl
l .
Assuming that Fq,gl(·) is a collision-intractable hash function with outputs smaller
than q, P can demonstrate that xi = β, for some β ∈N, by demonstrating that
Fq,gl(xi) = Fq,gl(β). Likewise, demonstrating that xi ̸= β can be done by demon-
strating that Fq,gl(xi) ̸= Fq,gl(β). The usefulness of this variation is limited if the
CA sees the attributes it encodes, because attributes with large entropy are in effect
identiﬁers that facilitate tracing and linking when disclosed; however, as we will
show in Section 5.2.1, the CA can encode attributes without knowing their values.
In another variation, following Merkle [267] (see also Section 5.4.3), attributes
are incorporated in a hash tree. For example, with x2 chosen at random from Zq,
the number x1 in gx1
1 gx2
2 , could be the root of a Merkle hash tree. To reveal some
of the attributes in the tree, P discloses node values from which the root value can
be reconstructed. This approach improves efﬁciency (and enables limited selective
disclosure, assuming P hashes along a random salt for each attribute to prevent an
exhaustive search), but many of the techniques in this book no longer apply.
For efﬁciency reasons, in practice V0 may prefer to skip the veriﬁcation of P0’s
response(s) in the issuing protocol. P0 cannot leak more than a single bit of informa-
tion to V, owing to V0’s blinding operations. Because V cannot determine whether
P0 or V0 is the source of incorrect certiﬁcate data supplied in the showing protocol,
it has no choice but to reject incorrect data. Therefore, if P0’s response in the issuing
protocol is incorrect then V0 will ﬁnd out in the showing protocol.
From now on we will always assume that the public key h′ of the certiﬁcate
holder is hashed along when determining V’s challenge c in a signed proof.

5.1 INTEGRATION
185
5.1.2
Coping with delegation
As noted in Section 2.6, care must be taken when the CA issues secret-key certiﬁ-
cates. P may be able to use a simulated certiﬁed public key in the showing protocol
and delegate part of the requested action to the CA in an execution of the issuing
protocol.
Example 5.1.2. Consider the immunized DLREP-based certiﬁcate scheme I in Sec-
tion 4.4.2. To simulate a certiﬁed public key, P generates a number β ∈Zq, sets
h′ := gβ
0 , and computes a corresponding certiﬁcate. To issue a signed proof of the
formula TRUE, say, P must be able to come up with a ∈Gq and r1, . . . , rl+1 ∈Zq
such that
l
i=1
gri
i hrl+1
0
= (h′)ca
and
c = Hq,gl(h′, a, . . .).
Hereto P engages in an execution of the certiﬁcate issuing protocol with the CA, in
the following manner. Upon receiving a0, P sets a := a0, c := Hq,gl(h′, a, . . .),
and sends the challenge c0 := −βc mod q to the CA. Upon receiving r0 from the
CA, P sets ri := xir0 mod q, for all i ∈{1, . . ., l}, and rl+1 := r0. (Additional
blinding operations can be applied to a, c0, and r0, . . . , rl+1.) It is easy to verify that
the result convinces V. Note that this works also if the hash function in the showing
protocol is different from that used in the issuing protocol.
The delegation strategy in this example is without security consequences, be-
cause P demonstrates a formula that pertains to the attributes (x1, . . . , xl) that the
CA “encodes” in the protocol execution to which P delegates the cryptographic ac-
tion. In effect, P simply follows a shortcut that circumvents the need to compute a
as a product of powers of g1, . . . , gl, h0. In most circumstances this shortcut is not
preferable: it requires an online connection with the CA at the time of the showing
protocol execution; simulated certiﬁed public keys cannot be reused; and, for inter-
active showing protocols, timing of issuing and showing protocol executions would
reveal the link between them.
When using the certiﬁcate issuing protocol in Section 4.5.2, the possibility of del-
egation simply does not arise, because public-key certiﬁcates are issued. Whenever
delegation is harmless, though, there is no reason to prefer public-key certiﬁcates. In
fact, secret-key certiﬁcates are preferable for reason of their greater efﬁciency, prov-
able security, and privacy. (The privacy beneﬁts will be clariﬁed in Section 5.2.2.)
In the remainder of this section we examine for all the secret-key certiﬁcate issuing
protocols in Chapter 4 whether P can abuse delegation to demonstrate a formula that
does not apply to the attributes that the CA encodes in the issuing protocol execution
with P. We will show that in many situations the delegation strategy is not possi-
ble at all, and in those cases where it cannot be prevented it can easily be rendered
harmless.

186
COMBINING ISSUING AND SHOWING PROTOCOLS
The case of the four issuing schemes in Section 4.2
Assumption 5.1.3. For any of the four secret-key certiﬁcate schemes in Section 4.2,
if V accepts a formula demonstration by P, then P must have engaged in an issu-
ing protocol execution in which the CA encoded an attribute tuple that satisﬁes the
formula.
In other words, delegation may be feasible, but it does not enable P to pretend to
have attributes for which it cannot (at the same moment) obtain a certiﬁcate from the
CA. We now argue why this should be true.
Consider ﬁrst DLREP-based certiﬁcate scheme I in Section 4.2.1. According to
the DL-based analogue to Assumption 4.3.9, the only way to simulate a certiﬁed pub-
lic key is to set h′ := h−1
0 gβ
0 , for some β ∈Zq. Assume for the moment that the CA
uses the same attribute tuple (x1, . . . , xl) in all protocol executions. In the same man-
ner as in Proposition 4.3.10, the role of the CA in these protocol executions with P
can be simulated by generating a random γ ∈Zq and setting h0 := h−1gγ
0, on input
l+1 random numbers g0, . . . , gl ∈Gq. Now, the demonstration of a Boolean formula
by means of the showing protocol techniques of Chapter 3 is a proof of knowledge
of a DL-representation (y0, . . . , yl) of h′ with respect to (g0, g1, . . . , gl); see Propo-
sition 3.6.1(b). (For signed proofs, the validity of Proposition 3.6.1(b) follows from
the DL-based analogue to Assumption 4.3.9.) From the four relations
h
=
gx1
1 · · · gxl
l
h′
=
h−1
0 gβ
0
h0
=
h−1gγ
0
h′
=
gy0
0 gy1
1 · · · gyl
l ,
we get
gβ−γ
0
gx1−y1
1
· · · gxl−yl
l
= 1.
Thus, a polynomial-time collision-ﬁnding algorithm for the DLREP function can
be constructed, unless β = γ mod q and yi = xi mod q, for all i ∈{1, . . ., l}.
Therefore, any choice for β should result in P demonstrating a property for a DL-
representation
(β −γ mod q, x1, . . . , xl)
of h′ with respect to (g0, g1, . . . , gl). This is the same as what P can demonstrate by
simply following the issuing and the showing protocol.
When issuing protocol executions are run with respect to different attribute tuples,
the CA can no longer be simulated by setting h0 := h−1gγ
0. However, the fact
that these protocol executions cannot be run in parallel is believed to ensure that the
security argument remains valid; the situation is reminiscent of that in Section 4.3.3.
The security argument can be easily generalized to the scenario considered by
Proposition 4.3.15, which provides a limited degree of parallelization of protocol
executions with respect to different attribute tuples.

5.1 INTEGRATION
187
Interestingly, DLREP-based certiﬁcate scheme I seems to admit delegation only
when the challenge c0 in the veriﬁcation relation of the issuing protocol appears at the
same position as V’s challenge c in the veriﬁcation relation of the showing protocol.
In particular, delegation is believed to be infeasible for atomic formulae without a
“NOT” connective: the veriﬁcation relations for these formulae have V’s challenge
situated as an exponent of the “wrong” base number.
The same considerations apply to the other three secret-key certiﬁcate schemes
in Section 4.2.
The case of the immunized DLREP-based scheme I in Section 4.4.2
In case all protocol executions involve the same attribute tuple, the security argument
for DLREP-based scheme I this time results in the relation
gβ−y0γ
0
gy0x1−y1
1
· · · gy0xl−yl
l
= 1.
Consequently, any choice for β should result in P demonstrating a property for a
DL-representation
((β/γ)x1 mod q, . . . , (β/γ)xl mod q, β/γ mod q)
of h′ with respect to (g1, . . . , gl, h0); this is the same as what P can demonstrate by
simply following the issuing and the showing protocol. On the basis of this, it seems
that any delegation strategy with undesirable security consequences must exploit the
ability of P to engage in parallel in two (or more) issuing protocol executions with
respect to distinct attribute tuples.
Consider now the following parallel delegation strategy, involving two parallel
issuing protocol executions with respect to different tuples. The veriﬁcation relation
in the i-th issuing protocol execution, for i ∈{0, 1}, is
gc0i
0
= (h0gx1i
1
· · · gxli
l
)r0ia0i.
P can combine the information obtained in the two issuing protocol executions into
information that satisﬁes the combined veriﬁcation relation
h−(γ0r00+γ1r01)
0
gγ0c00+γ1c01
0
l
i=1
g−(γ0xi0r00+γ1xi1r01)
i
= aγ0
00aγ1
01,
for some γ0, γ1 ∈Zq of its own choice. According to the DL-based analogue to
Assumption 4.3.9, the only way to simulate a certiﬁed public key is to set h′ := gβ
0 ,
for some β ∈Zq. According to Figure 3.1, the veriﬁcation relation in the showing
protocol for an atomic formula without a “NOT” connective is of the form
hr0
0 (gβ
0 )−c
l
i=1
gri
i = a.

188
COMBINING ISSUING AND SHOWING PROTOCOLS
Consequently, P in the issuing protocol executions can choose c00 and c01 subject
to γ0c00 + γ1c01 = −βc mod q. With a := aγ0
00aγ1
01, P can use the responses in
the two issuing protocol executions to satisfy the veriﬁcation relation in the show-
ing protocol, by setting r0 := −(γ0r00 + γ1r01) mod q and, for all i ∈{1, . . ., l},
ri := −(γ0xi0r00 + γ1xi1r01) mod q. Now, if the showing protocol execution is
to demonstrate the formula TRUE, P does not gain anything by this strategy. For
any other atomic formula without a “NOT” connective, the responses r1, . . . , rl must
satisfy at least one linear relation. Since the responses r00, r01 are outside of P’s
control, in the sense that they should be as unpredictable as two independent random
variables, P can satisfy this linear relation only if it may select the formula coefﬁ-
cients by itself. In that case, the parallel delegation strategy enables P to pretend to
have certiﬁed attributes that it in fact has never been issued.
Either of the following two measures is believed to sufﬁce to make the parallel
delegation strategy harmless:
• A description of the formula F is hashed along when forming V’s challenge
in the showing protocol. With c = Hq,gl(gβ
0 , aγ0
00aγ1
01, F, . . .), it should be in-
feasible to determine c as an algebraic function of β, γ0, γ1 and the formula
coefﬁcients. (This is provably true in the random oracle model.) Therefore, it
seems that P, upon receiving (a00, a01), has no choice but to select (β, γ0, γ1)
and the formula coefﬁcients before forming c. The rest of the security argu-
ment is similar to that in Section 4.4.2 for the restrictive blinding property of
the immunized DLREP-based scheme I; the only workable choices seem to be
those that result in formulae that P can demonstrate by following the issuing
and showing protocols.
• All the matrix entries (coefﬁcients) that specify the Boolean formulae are re-
stricted to sets V such that |V |/q is negligible in k. (The set V may differ
for each formula coefﬁcient.) The idea is that it should be infeasible to come
up with (β, γ0, γ1) and admissible formula coefﬁcients (favorable to P) that
satisfy the linear relations. (Note that c = Hq,gl(gβ
0 , aγ0
00aγ1
01, . . .) must be sat-
isﬁed as well.) For security reasons, it is recommendable to apply this measure
in combination with the preceding measure.
These measures were also recommended in Chapter 3 to guarantee unmodiﬁability
of signed proofs for atomic formulae without a “NOT” connective. (Recall, though,
that they are not always necessary to guarantee unforgeability of signed proofs.)
For atomic formulae that contain one “NOT” connective, the delegation strat-
egy (be it the sequential or the parallel variant) is believed to be infeasible alto-
gether, without any additional measures; V’s challenge in the veriﬁcation relations
for these formulae is an exponent of the wrong base numbers. As we have seen in
Section 5.1.1, in the showing protocol P must demonstrate anyway that α1 ̸= 0; in
case it does so as part of the formula that it is demonstrating to V, the whole formula

5.2 PRIVACY IMPROVEMENTS FOR CERTIFICATE HOLDERS
189
demonstration will always include a “NOT” connective. In other words, the issue
of delegation can be circumvented altogether by requiring that P always demon-
strate Boolean formulae for the DL-representation it knows of h−1
0
with respect to
(g1, . . . , gl, h′), rather than having V check that h′ ̸= 1 and having P demonstrate
formulae without “NOT” connectives.
The case of the remaining secret-key certiﬁcate schemes
The observations with respect to the immunized DLREP-based scheme I in Sec-
tion 4.4.2 apply also to the immunized RSAREP-based scheme II in Section 4.4.2
and to the DSA-like scheme in Section 4.5.1.
Finally, in the case of the immunized issuing protocols described in Section 4.4.1,
the application of the function f(·) to the CA’s initial witness in the issuing protocol
is believed to make the delegation infeasible altogether.
5.2
Privacy improvements for certiﬁcate holders
In this section we describe various techniques to improve privacy for certiﬁcate hold-
ers.
5.2.1
Issuing protocol techniques
Users are free to obtain a single batch of certiﬁcates from the CA and to thereafter
never again retrieve new ones. In effect, a certiﬁed public key is a digital pseudonym.
All communications and transactions conducted using the same pseudonym are link-
able. In applications such as online discussion groups, this allows certiﬁcate holders
to build a reputation with respect to each of their pseudonyms. For reason of pri-
vacy, however, it will often be desirable to use each certiﬁcate only a limited number
of times. In applications where there is no need to build a reputation, single use is
optimal. It also has advantages in other respects, as we have seen in Section 1.1.
Issuing many certiﬁcates to each applicant does not signiﬁcantly raise the burden
for the CA, if only identiﬁers and other attributes need not be veriﬁed out-of-band
each time. The following two methods facilitate the recurring issuance of certiﬁcates
to the same certiﬁcate applicant:
• (Account-based method) The certiﬁcate applicant opens an account with the
CA, and registers under a person identiﬁer (see Section 1.1.2) or a pseudonym.
The account holder uses an account key (or, if a digital pseudonym is used, the
secret key of the pseudonym) to authenticate its requests for new certiﬁcates.
Standard authentication techniques can protect against replay and, if desired,
ensure non-repudiation.

190
COMBINING ISSUING AND SHOWING PROTOCOLS
If the attributes of each account holder are recorded in a database entry as-
sociated with the account, then the CA need not verify them more than once.
Account holders can minimize the information the CA can learn about their
certiﬁcate showing behavior by retrieving certiﬁcates in batches.
• (Account-less method) The certiﬁcate holder proves the right to retrieve new
certiﬁcates by showing to the CA a previously retrieved certiﬁcate (not nec-
essarily of the same type or issued by the same CA). In this manner, the CA
can be assured of the authenticity of relevant attributes (identity or otherwise)
without needing to keep an account database.
This model does away with the account database by having each user port his
or her own database entries, digitally certiﬁed by the CA for security. At the
very least, the account-less method is natural for refreshing previously issued
certiﬁcates. More generally, it ﬁts well with the philosophy behind digital
certiﬁcates to minimize the reliance on central databases; see Section 1.1.3.
In many PKIs it is more efﬁcient to issue many short-lived certiﬁcates than to issue
a few long-lived certiﬁcates and apply online certiﬁcate validation. By front-loading
the handling of certiﬁcates and issuing certiﬁcates in batches, the CA greatly reduces
the number of accesses to a central database. Also, certiﬁcate issuing can easily be
scheduled, and in case of a communication or computation fault the same actions
can be repeated until successful. Note that even in a PKI with long-lived certiﬁcates,
the CA must be prepared to reissue certiﬁcates; certiﬁcates may be lost, stolen, or
corrupted, and must be refreshed upon expiry.
The account-based method allows certiﬁcate holders to remain anonymous in
the issuing protocol, by registering under a pseudonym and using an anonymous
channel to retrieve certiﬁcates. Unlinkability of certiﬁcate retrievals can be achieved
by opening multiple anonymous accounts. Full unlinkability, however, is feasible
only when using the account-less approach. Hereto certiﬁcate applicants must be able
to obtain attribute certiﬁcates that can be used to authenticate their right to retrieve
new certiﬁcates.
The account-less approach also enables a certiﬁcate holder to anonymously have
a previously issued certiﬁcate recertiﬁed by the CA. Anonymous refreshing of a
certiﬁcate can be accomplished using any of the RSAREP-based certiﬁcate issuing
schemes or the DLREP-based scheme described in Section 4.5.2. Suppose in the
DLREP-based scheme that the CA is presented with h′ := (gx1
1 · · · gxl
l h0)α1, a cer-
tiﬁcate on h′, and (optionally) a signed proof (or another kind of proof) that discloses
some property of the attributes (to enable P0 to certify unknown attributes that it
knows satisfy a certain property) or at least authenticates the request. If the CA
agrees to use h′ in the new issuing protocol execution (in the role of h0h), the certiﬁ-
cate holder can obtain a certiﬁcate on (h′)β = (h0h)α1β, for a random β ̸= 0 mod q.
The associativity of raising numbers in Gq to a power ensures that the encoded at-
tributes remain intact. Note that different CAs, each with their own signing key, can

5.2 PRIVACY IMPROVEMENTS FOR CERTIFICATE HOLDERS
191
perform different recertiﬁcation stages, assuming they all operate in the same group
Gq.
The CA can update the attributes of anonymous certiﬁcate holders before recerti-
fying them, without knowing the current attribute values. Consider hereto RSAREP-
based scheme I. V0 receives a certiﬁcate on a public key h′ of the form gx1
1 . . . gxl
l αv
1,
for a random α1 ∈Z
∗
n. Before recertiﬁcation, the CA multiplies h′ by l
i=1 gui
i ,
where u1, . . . , ul ∈Zv represent the update values. This technique applies also to
RSAREP-based scheme II and the immunized RSAREP-based schemes described in
Section 4.4. The updating technique does not work when a hash function F(·) is
applied to the attributes (as described at the end of Section 5.1.1), and does not work
for the DLREP-based schemes.
A special application of anonymous updating is to prevent the CA from learning
the entire set of attributes of a certiﬁcate applicant. Attributes that can be assigned to
a certiﬁcate applicant without requiring the applicant to disclose his or her identity
can be encoded in successive anonymous executions of the issuing protocol, in each
of which the certiﬁcate issued in the previous protocol execution is updated. To
prevent linking by timing, there must be ample time between successive updates.
Having different CAs certify different attributes further improves privacy.
5.2.2
Showing protocol techniques
To limit the privacy-invading powers of parties who build proﬁles from lists of cer-
tiﬁed public keys (obtained from certiﬁcate repositories or compiled by monitoring
network trafﬁc), one can use secret-key certiﬁcates and have certiﬁcate holders per-
form only zero-knowledge proofs. In this manner, nobody is able to obtain digitally
signed evidence about the attributes of PKI participants.
Secret-key certiﬁcates can also reduce the scope for discrimination on the basis
of (the lack of) one’s right to participate in a PKI. Certiﬁed public keys obtained from
a CA in one PKI can be combined with simulated certiﬁed public keys for other PKIs
in an execution of the showing protocol, to prove knowledge of a secret key (more
generally, an attribute property) for at least one of the certiﬁed public keys; the “OR”
technique of Cramer, Damg˚ard, and Schoenmakers [123] applies straightforwardly
to our showing protocol techniques.
Instead of performing a zero-knowledge proof or issuing a signed proof, P in
the showing protocol can also issue a designated-veriﬁer proof. This notion, due to
Chaum [102], guarantees that P’s proof is convincing only to a designated veriﬁer;
this reduces the scope for privacy-invasive practices. (See Jakobsson, Sako, and Im-
pagliazzo [219] and Krawczyk and Rabin [241] for improved constructions.) The
idea is for P to perform its demonstration by proving knowledge of a secret key cor-
responding to its own public key or to one of the designated veriﬁer, using a witness-
indistinguishable proof of knowledge. Hereto our showing protocol techniques can
be straightforwardly combined with the “OR” technique of Cramer, Damg˚ard, and

192
COMBINING ISSUING AND SHOWING PROTOCOLS
Schoenmakers [123]. The resulting protocol transcript does not convince anyone
but the veriﬁer, because the veriﬁer can generate transcripts with indistinguishable
probability distribution. An inherent drawback of designated-veriﬁer proofs is that
V must be prevented from using a secret key that is known only to a group of ver-
iﬁers. To overcome this attack, veriﬁers must either make a physical appearance in
a Faraday cage (to have their public key certiﬁed) or a trusted party must securely
issue a secret key to each veriﬁer (e.g., by providing a smartcard that stores the key);
both approaches have obvious drawbacks. In most PKIs either a signed proof or a
zero-knowledge proof will be the preferred choice.
Our showing protocol techniques enable certiﬁcate holders to demonstrate prop-
erties of attributes that have been encoded into different certiﬁed key pairs. Limiting
the number of attributes per certiﬁcate reduces the need to have attributes recertiﬁed
(attributes with clearly distinct lifetimes can be encoded into different certiﬁed key
pairs), improves efﬁciency,1 and improves privacy when attributes are certiﬁed by
different CAs. Any Boolean formula pertaining to the attributes in an arbitrary num-
ber of certiﬁed public keys can be demonstrated by applying our showing protocol
techniques to the appropriate product of powers of the public keys, provided that
the attributes speciﬁed in atomic formulae are all exponents of the same generator.
For example, in the DLREP-based setting, with h = l
i=1 gxi
i
and h∗= l
i=1 gx∗
i
i ,
demonstrating that α1x1 + x∗
1 = α2 mod q, say, can be done by proving knowledge
of a DL-representation of hα1h∗g−α2
1
with respect to (g2, . . . , gl). Depending on the
certiﬁcate issuing scheme, for each public key an additional proof of knowledge of a
representation may need to be performed, for security reasons. To prove knowledge
of a representation of each of many public keys h1, . . . , ht, knowledge of a represen-
tation of the product h1
t
i=2 hαi
i
may be proved, for α2, . . . , αt generated at random
from a large set. Either the αi’s are generated by application of a sufﬁciently strong
one-way hash function to h1, . . . , ht and the initial witness of the prover, or the pro-
tocol is performed interactively and V generates the αi’s at random after receiving
the initial witness.
This technique can be applied not only by a single certiﬁcate holder, but also
by multiple certiﬁcate holders who wish to jointly demonstrate that their combined
attributes meet certain criteria, without pooling their attributes. It can even be applied
to certiﬁcates issued by different CAs, assuming all CAs operate in the same group;
in DLREP-based scheme I, for instance, each CA may have its own x0, but Gq and
at least some of the generators should be the same.
The technique is less practical when P is to demonstrate a formula that involves
attributes that are exponents of different gi’s in different certiﬁed key pairs. Auxiliary
1Attributes that are rarely shown in combination are best encoded into different certiﬁed key pairs.
Other approaches to shorten certiﬁcates include: use of elliptic curve implementations, removing infor-
mation from certiﬁcates, using better data encoding rules, and ensuring that certiﬁcate veriﬁers can derive
the certiﬁcate holder’s public key from its identiﬁer and the CA’s public key (Certicom’s applies this
approach in its “bullet” certiﬁcates).

5.3 PRIVACY IMPROVEMENTS FOR CERTIFICATE VERIFIERS
193
commitments must then be spawned and additional relations must be proved, much
as described in Section 3.7. In many PKIs, though, only the ability to demonstrate
Boolean formulae involving the attributes (i.e., not the more general form of linear
relations) is of interest; for these formulae, our showing protocol techniques readily
apply to the attributes encoded into (arbitrarily many) different certiﬁed key pairs.
In some PKIs it is desirable that certiﬁcate holders can anonymously prove to be
the originator of several showing protocol executions. This gives them the power to
control the degree to which their communications and transactions can be linked. If
the CA encodes into each certiﬁed key pair an attribute x1 (possibly a random num-
ber) that is unique to the certiﬁcate applicant (applicants may provide gx1
1
or other
suitable commitments to hide their x1 from the CA), certiﬁcate holders can provide
indisputable linking information for arbitrarily many public keys, h1, . . . , ht, as fol-
lows. After the initial witnesses have been ﬁxed, V generates t numbers, α1, . . . , αt,
at random from a set V ⊆Zq, subject to the condition 	t
i=1 αi = 0 mod q. It is
easy to show that if P can prove knowledge of a representation of t
i=1 hαi
i
with
respect to a tuple that does not contain g1, then the probability of successful cheating
is at most 1/|V |. The αi’s may be generated as the output of a sufﬁciently strong
one-way hash function to P’s initial witnesses. The same technique applies to the
RSAREP-based protocols.
A special application of the latter technique are credential systems in which cer-
tiﬁcate holders are to build pseudonymousreputations in the showing protocol. Using
our techniques, certiﬁcate holders can establish digital pseudonyms with organiza-
tions; the pseudonyms can be thought of as anonymous accounts. To ensure that
certiﬁcates can be shown only to organizations at which one has a pseudonym, we
have the CA (or different CAs) encode a key holder identiﬁer (e.g., a random number)
into each pseudonym and attribute certiﬁcate. With h = gI
1gα
0 , say, denoting a per-
son’s pseudonym at an organization, and h∗= gI∗
1
l
i=2 gxi
i
an attribute certiﬁcate,
Boolean formulae of h∗/h with respect to tuples in which g1 does not appear can be
demonstrated only if I = I∗mod q. Seperate proofs of knowledge of a representa-
tion of h∗and h may be needed; for h this would naturally be done when registering
or using the pseudonym with the organization.
Using our techniques it is also straightforward for several certiﬁcate holders to
jointly demonstrate that their showing protocol executions did not all originate from
the same certiﬁcate holder, or for one certiﬁcate holder to show that he or she was
not involved in a fraudulent transaction; see Section 5.5.1 for details on the latter.
5.3
Privacy improvements for certiﬁcate veriﬁers
In many PKIs, certiﬁcate veriﬁers (must) submit their showing protocol transcripts to
the CA (or another central authority), either online or off-line. This enables the CA to
detect fraud with limited-show certiﬁcates, to keep track of the number of customers

194
COMBINING ISSUING AND SHOWING PROTOCOLS
served by V, to gather statistics on how often a certain attribute property is disclosed,
or to perform other administrative tasks.
For competitive or other reasons, V may want to hide from the CA all or part
of the formulae demonstrated. On the other hand, with the possible exception of
closed PKIs in which veriﬁers are tamper-resistant terminals representing the security
interests of the CA, the CA is unlikely to trust veriﬁers with truthfully submitting
summary indications of the required information. That is, V should not be able to
provide false information to the CA.
As an example application, consider an untraceable electronic coin system with
“earmarks.” Each electronic coin is a certiﬁed key pair encoding an attribute x1 that
speciﬁes (at least) the expiry date and the denomination of the coin, and attributes
x2, . . . , xl that specify personal data (such as age, gender, hobbies, income, marital
status, and perhaps the identity of the coin holder). To make a payment, the payer
discloses x1 to the shop. Depending on the conditions, the payer may in addition de-
cide to disclose some of x2, . . . , xl, for example to get a discount. To get its account
credited, the shop deposits the coin to the bank. The shop is required to deposit a
signed proof (to enable the bank to detect and trace double-spending) that discloses
x1 (to enable the bank to determine the redeemable amount), but the personal data
that the shop acquired from the payer is none of the bank’s business.
We now show how V can obtain a signed proof that hides all or part of the formula
demonstrated by P, while V itself becomes convinced of the entire formula.
Consider ﬁrst the case in which P interactively demonstrates to V an atomic for-
mula F of the form (3.2), in the manner depicted in Figure 3.1 and subject to the con-
ditions of Proposition 3.3.7. Let F ∗be any atomic formula obtained from F by prun-
ing “AND” connectives from F (i.e., by deleting rows from the left-hand side matrix
in (3.2)). We claim that V can obtain a signed proof that serves as self-authenticating
evidence that F ∗applies to P’s DL-representation but that unconditionally hides all
other information about F. The basic idea is for V to hash along a description of F ∗
instead of F when determining c, and to make it appear as if some of rl−t+1, . . . , rl
were provided by P. For instance, the signed proof (c, (r1, . . . , rl−t+1)) corresponds
to the formula F ∗that is the result of deleting the ﬁrst row of the left-hand side matrix
in (3.2), assuming that a description of F ∗is hashed along instead of F when form-
ing c. This signed proof does not unconditionally hide all other information about
F, though, because rl+1 does not have an independent random distribution; for any
choice of l −t elements of the tuple (b1, α11, . . . , α1,l−t), the remaining element is
uniquely deﬁned. To take care of this aspect, V must randomize rl−t+1 by adding
a random element β ∈Zq; this must be compensated by hashing along agβ
π(l−t+1)
instead of a when forming c.
More generally, with P demonstrating to V a formula F of the form (3.2), the
following protocol steps result:
Step 1. (This step is identical to Step 1 of the protocol in Section 3.3.) P generates

5.3 PRIVACY IMPROVEMENTS FOR CERTIFICATE VERIFIERS
195
at random l −t numbers, w1, . . . , wl−t ∈Zq, and computes
a :=
l−t

i=1
gwi
π(i)
t
i=1
g
−	l−t
j=1 αijwj
π(l−t+i)
.
P then sends the initial witness a to V.
Step 2. V decides on F ∗by deleting rows from the left-hand side matrix in (3.2).
Without loss of generality, we assume that F ∗is the result of pruning the ﬁrst
t∗≤t rows.
V generates at random t∗blinding factors β1, . . . , βt∗∈Zq, and computes
a∗:= a t∗
i=1 gβi
π(l−t+i). V then forms c := Hq,gl(h, m, F ∗, a∗), for some
(optional) message m, and sends c to P.
Step 3. (This step is identical to Step 2 of the protocol in Section 3.3.) P computes
a set of responses, responsive to V’s challenge c ∈Zs, as follows:
ri := cxπ(i) + wi mod q
∀i ∈{1, . . ., l −t}.
P then sends (r1, . . . , rl−t) to V.
As in the protocol in Section 3.3, V computes
rl−t+i := bic −
l−t

j=1
αijrj mod q
∀i ∈{1, . . ., t},
and accepts the demonstration of F if and only if the veriﬁcation relation
l
i=1
gri
π(i)h−c = a
holds. If V accepts, it computes r∗
l−t+i := rl−t+i+βi mod q, for all i ∈{1, . . ., t∗},
and outputs the signed proof
c, rπ−1(1), . . . , rπ−1(l−t), r∗
π−1(l−t+1), . . . , r∗
π−1(l−t+t∗).
The CA (or anyone else) accepts the signed proof if and only if
c = Hq,gl(h, m, F ∗,
l−t

i=1
g
rπ−1(i)
i
t∗

i=1
g
r∗
π−1(i)
l−t+i h−c).
Note that if t∗= t then the signed proof hides F in its entirety.
According to Proposition 3.6.3, if V’s challenge is formed by hashing at least h,
any initial witnesses, and a unique description of a formula F, then a signed proof

196
COMBINING ISSUING AND SHOWING PROTOCOLS
serves as self-authenticating evidence that P knows (knew) a representation of h, and
that P’s representation satisﬁes the formula F. It follows that V can hide an arbitrary
part of the formula demonstrated, but cannot obtain a signed proof for a formula that
does not apply to P’s representation: F ∗is implied by the formula F demonstrated
by P in the showing protocol execution from which the signed proof resulted.
The same technique applies to atomic formulae of the form (3.4). Peculiarly,
though, V can only obtain signed proofs for formulae F ∗obtained by pruning linear
equalities from F ∗; it is unclear how to prune the linear inequality.
More generally, if P interactively demonstrates an arbitrary formula F of the
form (3.7), then V can obtain a signed proof for any formula that is obtained by
pruning one or more of the j subformulae of F. Hereto V simply omits hashing
along the initial witness sets for those subformulae when forming c.
In sum, when P is interactively demonstrating to V a formula F of the form (3.7),
V can obtain a signed proof for any formula F ∗that is obtained from the formula F
demonstrated by P by pruning “AND” connectives. The signed proof uncondition-
ally hides all other information about F. How much V may hide in the signed proof
it deposits to the CA could depend on the policies set by the latter.
In case P wants to prevent V from obtaining a signed proof for a formula other
than the formula F it is demonstrating to V, it must form c itself by hashing along
a description of F. More generally, P can ensure that V obtains a signed proof
that convinces of a formula F ∗obtained from F by pruning “AND” connectives by
hashing along a description of F ∗itself (and possibly a∗instead of a, for blinding
factors supplied by V).
In case of disputes, it may be desirable that V can “open up” the signed proof
to prove that P demonstrated F, not just F ∗. Hereto V should form c by hashing
along a commitment to (the hidden part of) F, and save the blinding factors it used in
Step 2 (in order to reconstruct those responses of P that it blinded). P has leverage
to settle disputes as well: it can always prove to the CA to be the originator of the
signed proof, by revealing h and proving knowledge of a corresponding secret key.
An efﬁciency improvement is possible in case P demonstrates a formula F of
the form (3.6) containing only atomic subformulae of the form (3.2), and V wants to
obtain a signed proof that hides F entirely. Let s := q. With l
i=1 grit
π(i)h−ct = at
denoting the veriﬁcation relation for the t-th atomic subformula, for t ∈{1, . . . , j},
we have
l
i=1
g
	t
j=1 rij
π(i)
h−c =
t
i=1
ai.
Consequently, c together with the responses in this compound veriﬁcation relation
form a signed proof for the formula TRUE. V must hash along a := t
i=1 ai (instead
of all ai’s) and a description of the formula TRUE when determining c. There is no
need for blinding factors or interaction.
Our techniques thus far do not enable V to obtain a signed proof for any formula

5.4 LIMITED-SHOW CERTIFICATES
197
F ∗implied by F. To get around this limitation, P should submit two proofs to V:
a signed proof that discloses the minimal information required by the CA (perhaps
just the formula TRUE) and a proof (not necessarily a signed proof) that discloses
the formula V is interested in. A drawback of this approach is increased computation
and communication complexity.
All the techniques in this section apply straightforwardly to the RSAREP-based
showing protocols.
5.4
Limited-show certiﬁcates
In this section we show how to ensure that the CA (or another central party to which
showing protocol transcripts are submitted) can compute all the attributes encoded
into a certiﬁed key pair once the certiﬁcate is shown more than a predetermined
number of times. Beneﬁts of this technique will be explained in Section 5.5.
5.4.1
Static one-show certiﬁcates
Consider the setting in Chapter 3. Suppose that P engages in a showing protocol
execution, demonstrating a Boolean formula F for its DL-representation of h with
respect to (g1, . . . , gl). We do not care whether P gives a signed proof, a zero-
knowledge proof, or otherwise. We claim the following.
Proposition 5.4.1. Suppose that formulae are demonstrated using the showing pro-
tocol described in Section 3.6.1. If P demonstrates the same formula twice using the
same public key, responsive to any two different challenges of V but with respect to
the same initial witness (sets), then with overwhelming probability P’s secret key can
be efﬁciently computed from the two accepting views of V.
Proof. To prove the claim, we consider the following four cases for the formula F
that is demonstrated:
Case 1. F is an atomic formula consisting of zero or more “AND” connectives and
no other connectives, in the form (3.3). Recall from Figure 3.1 that the veriﬁ-
cation relation in the protocol for demonstrating F is
l
i=1
gri
π(i)h−c = a,
where a is the initial witness. The veriﬁcation relation with respect to a chal-
lenge c∗̸= c mod s is
l
i=1
gr∗
i
π(i)h−c∗= a.

198
COMBINING ISSUING AND SHOWING PROTOCOLS
Division of the two relations results in
hc−c∗= gr1−r∗
1
π(1)
· · · grl−r∗
l
π(l)
,
and from s ≤q it follows that
h = g(r1−r∗
1 )/(c−c∗)
π(1)
· · · g(rl−r∗
l )/(c−c∗)
π(l)
.
The DL-representation ((r1−r∗
1)/(c−c∗) mod q, . . . , (rl−r∗
l )/(c−c∗) mod
q) can be efﬁciently computed from the two views of V. With overwhelm-
ing probability, this DL-representation is P’s secret key, (xπ(1), . . . , xπ(l)).
Namely, according to Corollary 3.3.2 P must know at least one secret key, and
if this is different then < P, V> is a collision-ﬁnding algorithm for the DLREP
function used to implement P’s commitment; according to Proposition 2.3.3
this contradicts the assumption that the underlying DL function is one-way.
Case 2. F is an atomic formula consisting of zero or more “AND” connectives, one
“NOT” connective, and no other connectives, in the form (3.4). Recall from
Figure 3.5 that the veriﬁcation relation in the protocol for demonstrating F is
l
i=1
gri
π(i)h−r0 = a.
The veriﬁcation relation with respect to a challenge c∗̸= c mod s is
l
i=1
gr∗
i
π(i)h−r∗
0 = a.
Division of the two relations results in
hr0−r∗
0 = gr1−r∗
1
π(1)
· · · grl−r∗
l
π(l)
.
If r0 = r∗
0 mod q, then
(r1 −r∗
1 mod q, . . . , rl −r∗
l mod q)
is a DL-representation of 1 with respect to (gπ(1), . . . , gπ(l)), and two cases
can be distinguished:
• If this is a non-trivial DL-representation of 1, then < P, V> has found a
DL-representation of 1 other than the trivial one. According to Proposi-
tion 2.3.3 this contradicts the assumption that the DL function is one-way.

5.4 LIMITED-SHOW CERTIFICATES
199
• If this is the trivial DL-representation, then ri = r∗
i mod q for all i ∈
{1, . . ., l}. Recall that V computes (rl−t+1, . . . , rl) from (r0, . . . , rl−t)
according to
rl−t+i := bir0 −fic −
l−t

j=1
αijrj mod q
∀i ∈{1, . . . , t},
where t ≥1. From the linearity of these t responses it follows that
fi(c −c∗) = 0 mod q, for all i ∈{1, . . ., t}. From s ≤q it follows
that c ̸= c∗mod q, and so f1, . . . , ft are all zero. This contradicts the
presence of one “NOT” connective.
Therefore, with overwhelming probability r0 ̸= r∗
0 mod q. It follows that
((r1 −r∗
1)/(r0 −r∗
0) mod q, . . . , (rl −r∗
l )/(r0 −r∗
0) mod q)
is a DL-representation of h with respect to (gπ(1), . . . , gπ(l)). The same argu-
ment as in Case 1 completes the proof.
Case 3. F is a formula connecting atomic subformulae by zero or more “OR” con-
nectives and no other connectives, in the form (3.6). According to the protocol
in Section 3.5, V accepts if and only if c = 	j
i=1 ci mod s and the veriﬁcation
relations for all the atomic subformulae hold. Let c∗denote the challenge of V
in the second protocol execution involving the same initial witness (set), and
c∗
i the challenge used by P for the i-th subformulae in that protocol execution.
We have 	t
i=0 c∗
i = c∗mod s. From c∗̸= c mod s it follows that there exists
at least one i such that c∗
i ̸= ci mod s. This index i corresponds to an atomic
subformula that P has demonstrated twice with respect to the same initial wit-
ness but different challenges. We are now in Case 1 or 2, and refer to these
cases for the completion of the proof.
Case 4. F is an arbitrary Boolean formula, in the form (3.7). According to the pro-
tocol in Section 3.6, V accepts if and only if it accepts P’s demonstration of
each of the j subformulae. We can therefore consider P’s demonstration of
any one of these subformulae, and apply the proof of Case 3.
This completes the proof.
The same result can be proved for the RSAREP-based showing protocols.
Based on Proposition 5.4.1 it is straightforward to construct a showing protocol
that protects P’s privacy if and only if P does not use the same certiﬁed public key
more than once. P must hereto commit already in the certiﬁcate issuing protocol to
the initial witness (sets) that it will use in the showing protocol, so that the CA can
certify these along. Speciﬁcally, for any of the restrictive blind certiﬁcate issuing

200
COMBINING ISSUING AND SHOWING PROTOCOLS
protocols in Chapter 4, P (i.e., V0) must hash along its initial witness (sets) for the
showing protocol when computing c′
0 in Step 2 of the issuing protocol.
It is natural to think of h (or h′, in the notation used in the issuing protocols in
Chapter 4) together with the initial witness (sets) of P as a one-time public key of
P. Any two showing protocol executions by P, with respect to the same one-time
public key but different challenges, reveal its secret key. In case P non-interactively
issues signed proofs, the use of different challenges can be forced by having P hash
along a unique message m when forming V’s challenge; if the hash function used to
form V’s challenge is collision-intractable, it is infeasible to compute two different
messages that are mapped to the same challenge, regardless of any additional inputs
to the hash function. Note that m need not be generated at random: Proposition 5.4.1
does not require V’s challenge to satisfy a particular probability distribution. In a
practical implementation, m could be the concatenation of an identiﬁer for V (e.g., a
true name, a local name, a pseudonym, or a public key) and a nonce.2
The limited-show technique applies even if the certiﬁcate veriﬁer uses the tech-
nique in Section 5.3 to hide (part of) the formulae demonstrated, regardless of the
strategy of P and V.
The proof of Proposition 5.4.1 makes use of the fact that < P, V> cannot com-
pute a collision for the DL function used to implement P’s commitment. When com-
bining the showing protocol with a certiﬁcate issuing protocol, we must see to it that
this remains true. For the certiﬁcate schemes in Section 4.2 and the immunization
in Section 4.4.1, P’s inability to learn a non-trivial representation of 1 follows from
Lemma 4.3.5. (Recall that we needed this property to prove blinding-invariance.)
For the public-key certiﬁcate scheme in Section 4.5.2 the property follows from the
fact that the CA need not know a non-trivial DL-representation of 1 to perform the
issuing protocol. The other schemes in Chapter 4 are believed to meet the desired
property as well.
The delegation strategy is never an issue. P cannot use the delegation strategy to
show a number of certiﬁcates that exceeds the number of issuing protocol executions
it would need to engage in; “forgery” is not possible. In fact, even if a secret-key cer-
tiﬁcate issuing protocol is used that admits delegation, reuse of a simulated certiﬁed
public key is not possible because the CA uses an independent random initial witness
in each protocol execution.
The most obvious application of limited-show certiﬁcates is to implement certiﬁ-
cates that by their very nature may be shown only a limited number of times, such
as food stamps, subway tokens, and electronic coins. In Section 5.5 we will see that
limited-show certiﬁcates are advantageous also to prevent fraud with other types of
certiﬁcates, such as personal certiﬁcates.
2The nonce may be a sequence number, a random number provided by V, or a sufﬁciently accurate
estimate of the time and date of the demonstration; in the latter case the showing protocol can be non-
interactive, assuming P can determine the time without the assistance of V.

5.4 LIMITED-SHOW CERTIFICATES
201
In many PKIs, only one encoded attribute need be computable in case of fraud.
Of special interest is the case where one of the encoded attributes is an identiﬁer
of P, which normally need not be shown but must be computable when a limited-
show certiﬁcate is shown too many times. Instead of storing the entire protocol view,
in this case it is more efﬁcient to store those exponents that correspond, in the ex-
panded form of the veriﬁcation relation, to h, g1, . . . , gl. For instance, to be able to
compute xπ(i) in case a formula of the form (3.3) is demonstrated twice, for some
i ∈{1, . . ., l}, it sufﬁces to store (c, ri) in each showing protocol execution. Accord-
ing to Subsections 2.2.2 and 2.2.3, 25-byte exponents sufﬁce for long-term security,
which makes our one-show certiﬁcate technique highly practical.
In a typical PKI implementation, there will be many veriﬁers. To enable detec-
tion of reuse of a one-show certiﬁcate, veriﬁers should deposit (relevant data of) the
transcripts of their showing protocol executions to the CA (or another central party),
in a timely fashion. (Either in real-time during certiﬁcate validation or batched at
a convenient moment later on.) Veriﬁers that the CA trusts (such as tamper-proof
veriﬁer devices issued by the CA) may accept zero-knowledge demonstrations and
deposit only the minimal data needed by the CA, but all others must receive and
deposit signed proofs on challenges for which a nonce has been hashed along. The
latter group of veriﬁers must be incited to perform the deposit. How to accomplish
this depends on the PKI at hand. Incentives may be either positive (e.g., a ﬁnancial
reward for each deposited transcript) or negative (e.g., a penalty in case audits reveal
a discrepancy between the number of customers serviced and the number of tran-
scripts deposited). In some applications, it may be in the best interest of the veriﬁers
themselves to faithfully perform the deposit, for instance if a successful attack leads
to damages to their own organization.
By making use of its knowledge of yi = loggl gi, for all i ∈{1, . . . , l −1},
the CA can speed up the veriﬁcation of transcripts of showing protocol executions.
Instead of verifying whether
l
i=1
gri
i h−c = a,
say, the CA can simply verify whether
g
	l−1
i=1 yiri+rl
l
h−c = a.
Also, the CA can apply batch-veriﬁcation to verify one or multiple transcripts, as
described in Section 2.5.3.
5.4.2
Dynamic one-show certiﬁcates
With the static one-show certiﬁcate technique in Section 5.4.1, P must anticipate
in the certiﬁcate issuing protocol which formula it will demonstrate in the showing

202
COMBINING ISSUING AND SHOWING PROTOCOLS
protocol. Depending on the application, this may or may not be a drawback. For
instance, the design of a privacy-protecting electronic coin system may be such that
each coin encodes two attributes, one to specify (at least) the coin expiry date and
the coin denomination and the other to specify the identity of the coin owner; the
formula for the showing protocol (payment) would always require the disclosure of
just the ﬁrst attribute. In many PKIs, however, the requirement that the formula
must be anticipated is inconvenient or even unrealistic. Typically, the formula to be
demonstrated will depend on the veriﬁer or its service, and P does not know in ad-
vance which service of which veriﬁer it will want to get access to. In the case of
unlimited-show certiﬁcates, P can postpone the moment of computing its initial wit-
ness (sets) until Step 1 of the showing protocol, but this cannot be accomplished for
limited-show certiﬁcates. We now show how to get around this. Again, we assume
the setting of Chapter 3, and detail the technique only for the DLREP-based showing
protocols.
Atomic formulae without “NOT” connectives
Consider ﬁrst the case that P is to demonstrate an atomic formula of the form (3.3),
using the showing protocol depicted in Figure 3.1. In Step 2 of the issuing protocol,
instead of generating the initial witness in a formula-dependent manner, P simply
computes a := l
i=1 gwi
i , for random w1, . . . , wl ∈Zq. In the showing protocol, P
in addition sends to V a set of t correction factors, e1, . . . , et, all in Zq. These serve
to adjust a, in such a manner that the DL-representation known to P of the adjusted
a is suitable to complete the demonstration in the same manner as in the original
protocol. Speciﬁcally, the adjusted a is computed as
a/
t
i=1
gei
π(l−t+i).
By applying the protocol of Figure 3.1 and expanding the resulting terms, the follow-
ing (generic) protocol steps result:
Step 1. P computes t correction factors, as follows:
ei := wπ(l−t+i) +
l−t

j=1
αijwπ(j) mod q
∀i ∈{1, . . ., t}.
P then sends its one-time public key (h, a) and (e1, . . . , et) to V.
Step 2. P computes a set of responses, responsive to V’s challenge c ∈Zs, as
follows:
ri := cxπ(i) + wπ(i) mod q
∀i ∈{1, . . . , l −t}.
P then sends (r1, . . . , rl−t) to V.

5.4 LIMITED-SHOW CERTIFICATES
203
V computes
rl−t+i := ei + bic −
l−t

j=1
αijrj mod q
∀i ∈{1, . . ., t},
and accepts if and only if
l
i=1
gri
π(i)h−c = a.
Assuming s is large and c is generated in a substantially random manner and after
the data in Step 1 has been sent, it is easy to prove that V is convinced if and only
if P’s attributes satisfy the formula (3.3). Furthermore, all the considerations in
Section 3.3.1 apply, with the obvious modiﬁcations. Notably, assuming that all the
correction factors are hashed along as well when forming c, Propositions 3.3.6, 3.3.7,
and 3.3.8 all hold.
Suppose now that P reuses the one-time public key (h, a), demonstrating a for-
mula of the form (3.3) that need not be the same as in the ﬁrst demonstration. Clearly,
the proof of Case 1 in Proposition 5.4.1 applies as is. Consequently, if the two demon-
strations are performed responsive to different challenges, then with overwhelming
probability all the attributes of P can be efﬁciently computed from the two accepting
views of V.
V can limit the class of atomic formulae that P is able to demonstrate by imposing
restrictions on the number, the position, or the form of the correction factors that
P may use. Complete anticipation of the formula corresponds to the extreme case
where P is not allowed to use any correction factors; this is the case of static one-
show certiﬁcates. The CA can encode restrictions on the correction factors into one
of the xi’s (e.g., as part of a CA policy attribute), which P must then disclose to V in
the showing protocol as part of the formula it is demonstrating.
The technique in Section 5.3 can be applied as well. Only those correction factors
that correspond to F ∗should be hashed along when forming c. For dispute settle-
ment, V should in addition hash along a commitment to both the hidden part of F
and the remaining correction factors.
Arbitrary atomic formulae
The situation is slightly more complex in case P must be able to demonstrate any
atomic formula. This time, we have P in Step 2 of the issuing protocol hash along an
initial witness a := h−w0 l
i=1 gwi
i , for random w0, . . . , wl ∈Zq. To demonstrate a
formula of the form (3.4), P in Step 1 of the showing protocol of Figure 3.5 must be
allowed to reveal t correction factors, (e1, . . . , et), to adjust a to
a/
t
i=1
gei
π(l−t+i).

204
COMBINING ISSUING AND SHOWING PROTOCOLS
To demonstrate a formula of the form (3.3), P in Step 1 of the showing protocol
depicted in Figure 3.1 must this time be allowed to reveal t + 1 correction factors, to
adjust a to
a/he0
t
i=1
gei
π(l−t+i),
because the exponent −w0 of h must be canceled as well. For both cases, it is easy
to describe the resulting protocol. This time, the proof of Case 1 in Proposition 5.4.1
does not apply, because V’s challenge in the veriﬁcation relation for the demonstra-
tion of an atomic formula with a “NOT” connective does not appear as a power of h.
Speciﬁcally, the veriﬁcation relation for an atomic formula of the form (3.4) is
l−t

i=1
gri
π(i)
t
i=1
g
ei+bir0−fic−	l−t
j=1 αijrj
π(l−t+i)
= hr0a
and that for an atomic formula of the form (3.3) with matrix coefﬁcients α∗
ij is
l−t∗

i=1
gr∗
i
π(i)
t∗

i=1
g
e∗
i +b∗
i c∗−	l−t∗
j=1 α∗
ijr∗
j
π(l−t∗+i)
= hc∗+e∗
0a.
If r0 = c∗+ e∗
0 mod q, and cancellation takes place also for the exponents to all
gi’s (otherwise a non-trivial DL-representation of 1 is obtained; cf. Case 2 of Propo-
sition 5.4.1), then the DL-representation of h with respect to (g1, . . . , gl) cannot be
computed even though c∗may differ from c. Indeed, if P is allowed to select V’s
challenge in an arbitrary manner, subject only to the condition that it has to be unique
in each formula demonstration, it is not hard to construct a one-time public key (h, a),
two atomic formulae, two different challenge messages, and two protocol transcripts
for which total cancellation takes place.
We can get around this in a natural manner, by requiring V’s challenge message
to be a sufﬁciently strong hash of at least (h, a), a unique formula description, and the
correction factors (in a unique order). Under this condition, which is needed anyway
to prove the unforgeability and unmodiﬁability of signed proofs in the random oracle
model (see Section 3.4.1), the following holds: if any two atomic formula demon-
strations are performed responsive to different challenges, then with overwhelming
probability all the attributes of P can be efﬁciently computed from the two accept-
ing views of V. Under the conditions of Proposition 3.3.6 and 3.3.7, respectively, this
can be proved in the random oracle model for both non-interactively and interactively
issued signed proofs.
Atomic formulae connected by “OR” connectives
Another treacherous aspect enters when P must be able to demonstrate any formula
of the form (3.6), in such a manner that any two demonstrations involving the same

5.4 LIMITED-SHOW CERTIFICATES
205
one-time public key disclose all the encoded attributes. The simplest approach is
for P to simulate all but one of the subformulae demonstrations, in the manner de-
scribed in Section 3.5.1, and to hash along in Step 2 of the issuing protocol an initial
witness formed in the same formula-independent manner as in the case of atomic
formulae. This fails, however, because V can infer from a single showing protocol
execution which subformula demonstration is genuine. Using the same a for each
subformula demonstration, and providing random correction factors for those sub-
formulae demonstrations that are simulated, does not work either: if j ≥2 then
V can compute P’s representation from a single execution of the showing proto-
col. Yet another ﬂawed approach is for P to use a one-time public key of the form
(h, a1, . . . , aj∗), where j∗≥j: this requires P to know an upper bound on j, the
number of “OR” connectives in the formula to be demonstrated.
All these problems can be avoided by introducing an extra constraint in the show-
ing protocol described in Section 3.5.1. Let
a := h−w0
l
i=1
gwi
i
be the master initial witness that P in Step 2 of the issuing protocol incorporates into
its one-time public key, and let ai denote the initial witness used in the demonstration
of subformula Fi, for all i ∈{1, . . . , j}. For each of the j subformula demonstra-
tions, we have P reveal up to l correction factors to adjust the initial witness ai
for that subformula demonstration, as described previously. P could do without the
use of correction factors in the j −1 subformula demonstrations that are simulated,
but they are needed to hide from V which subformula demonstration is genuine; the
zero-knowledge simulator must generate the required number of correction factors at
random (as many as would be needed in a genuine proof). The extra constraint is that
the product of the j adjusted initial witnesses must equal the master initial witness, a.
P can easily meet this constraint, since ai in each of the j −1 simulated subformulae
demonstrations is generated in such a manner that P knows a DL-representation with
respect to (g1, . . . , gl, h); therefore, P can determine the remaining set of correction
factors (for the subformula that requires a genuine proof) by comparing the represen-
tation it knows of a with that of the product of the j −1 adjusted initial witnesses. V
must verify the extra constraint as part of its veriﬁcation process.
To obtain a signed proof, V’s challenge should be formed by hashing at least
(h, a, F) and all correction factors (in a unique order). Under the conditions of
Proposition 3.3.6 and 3.3.7, respectively, it can be proved in the random oracle model
that both non-interactively and interactively issued signed proofs are unforgeable and
unmodiﬁable. If the CA does not trust V, the latter will need to relay the entire tran-
script of the showing protocol to the CA.
Why does this work? By aggregating the j veriﬁcation relations (one for each
subformula demonstration), V can obtain a compound veriﬁcation relation of the

206
COMBINING ISSUING AND SHOWING PROTOCOLS
form
l
i=1
gyi
i = hy0a.
Each yi, for i ∈{0, . . ., l}, is an arithmetic expression that involves subformulae co-
efﬁcients, responses (at most one from each subformula demonstration), and perhaps
correction factors and V’s challenge. Suppose now that P reuses its one-time public
key (h, a). This time, V obtains a compound veriﬁcation relation
l
i=1
gy∗
i
i
= hy∗
0 a.
From the two compound veriﬁcation relations, the DL-representation that P knows
of h can be extracted, unless P has managed to perform its two protocol executions
in such a manner that yi = y∗
i mod q for all i ∈{0, . . ., l}. If V’s challenge is
formed by hashing at least (h, a, F) and all correction factors, then it is infeasible to
effect this cancellation, assuming only that V’s challenge differs in the two showing
protocol executions; this result can be proved in the random oracle model.
An anomaly occurs in case none of the atomic subformulae involve a “NOT”
connective. In this case, V need not hash along a description of F and the correction
factors. If 	j
i=1 ci = c mod q, it follows from the constraint on the adjusted initial
witnesses that V can obtain a compound relation of the form
l
i=1
gyi
i
= hca.
With c being a sufﬁciently strong hash of at least (h, a), the unforgeability of this
compressed signed proof of knowledge of a DL-representation of h follows as in
the case of Propositions 3.3.6 and 3.3.7. By applying the technique described in
Section 5.3, V can unconditionally hide which formula F has been demonstrated
(from the space of all formulae that connect atomic subformula without “NOT” con-
nectives by zero or more “OR” connectives), yet V itself becomes convinced of F
during the showing protocol. In case (h, a) is reused in a showing protocol execution
involving a different c, the CA can extract P’s DL-representation of h. Sending only
(h, c, y1, . . . , yl) to the CA is preferable also for reason of efﬁciency.
Arbitrary Boolean formulae
Finally, consider the case where P must be able to demonstrate any formula F of the
form (3.7). The one-show certiﬁcate technique for formulae of the form (3.6) applies
here as well. This time, the product of all the adjusted initial witnesses, one for each
atomic subsubformula in F, must equal the master initial witness, a. Aggregation

5.4 LIMITED-SHOW CERTIFICATES
207
of all the veriﬁcation relations, one for each subformula demonstration, results in a
compound veriﬁcation relation of the form
l
i=1
gyi
i = hy0a.
Assuming V’s challenge is formed by hashing at least (h, a, F) and all correction
factors, reuse of (h, a) with respect to a different c enables the computation of P’s
DL-representation of h. Again, this result can be proved in the random oracle model.
Note that only (y0, yi) needs to be stored to be able to compute xi from P’s
DL-representation upon reuse of (h, a), regardless of the formula demonstrated. To
be able to detect reuse, in addition the CA must store a hash of (h, a, cert(h, a)).
A hash function that is second-preimage resistant may be used (i.e., for a random
input, it is infeasible to ﬁnd another input that maps to the same output). In practice,
simply storing the 10 most signiﬁcant bytes of h, say, should be adequate, assuming
that it is agreed on that no certiﬁcate applicant retrieves multiple certiﬁcates on the
same public key. According to Section 2.2.2, 25-byte exponents should sufﬁce for
long-term security, which makes our technique for dynamic one-show certiﬁcates
highly practical: per showing protocol transcript a mere 60 bytes need to be stored,
regardless of the formula demonstrated.
The dynamic one-show certiﬁcate technique can be applied in a straightforward
manner to the RSAREP-based issuing and showing protocols. In this case, the CA
will be able to compute P’s attributes (x1, . . . , xl) as well as xl+1 upon redemon-
stration of the same formula.
5.4.3
Increasing the threshold
There is nothing magical about a threshold value of 1. To ensure that P’s representa-
tion can be computed if and only if P performs more than t demonstrations using the
same certiﬁed public key, for a predetermined positive integer t, P’s t-time public
key should comprise t master initial witnesses. When performing the i-th execution
of the showing protocol, using the same t-time public key, P uses the i-th master
initial witness. Alternatively, to obscure in the current showing protocol execution
how many showing protocol executions have already been performed using the same
public key, P uses a master initial witness that it randomly chooses out of those not
yet used. The pigeon-hole principle ensures that any t + 1 demonstrations lead to the
reuse of a master initial witness. From the corresponding two views P’s representa-
tion can be computed.
For large thresholds, it is more efﬁcient to use Merkle’s tree authentication tech-
nique [267]. Hereto P builds a binary tree with the master initial witnesses in the
leaves. Each node value in the level just above the leaves is computed by compress-
ing the entries in the leaves below it, using a collision-intractable hash function. All

208
COMBINING ISSUING AND SHOWING PROTOCOLS
the other node values are computed by compressing the child node values. The value
of the root node together with h′ serves as the t-time public key; it must be hashed
along in Step 2 of the issuing protocol. In the showing protocol, P must reveal the
particular master initial witness it intends to use in the formula demonstration, to-
gether with ⌈2log t⌉nodes to enable V to compute its way back to the root node and
verify the certiﬁcate.
If V (or the CA) consents, t-show certiﬁcates can be turned on the spot into i-
show certiﬁcates for any i ∈{1, . . . , t}, by ﬁxing a subset of size i of master initial
witnesses that may be used in the showing protocol. Also, a t-show certiﬁcate may be
converted into an unlimited-show certiﬁcate, by allowing P in the showing protocol
to use initial witnesses other than those comprised in its t-time public key. By way of
example, consider the technique in Section 5.3 and suppose the CA is interested only
in being able to trace certiﬁcate holders who show their certiﬁcates too many times.
P supplies two proofs to V: a signed proof demonstrating the formula TRUE and a
proof demonstrating the formula V is interested in. The signed proof must use one
of the (master) initial witnesses committed to in Step 2 of the issuing protocol, while
the other proof may make use of freshly generated initial witnesses and need not be
a signed proof.
5.5
Security improvements
In this section we introduce techniques to improve security, without resorting to
smartcards or other tamper-resistant devices for certiﬁcate holders. Among others,
we show how to discourage lending, copying, and discarding of certiﬁcates, and how
to achieve non-repudiation for limited-show certiﬁcates. Most of these software-only
techniques are based on the limited-show certiﬁcation technique of Section 5.4. We
also provide measures to protect against leakage and misuse of the CA’s secret key.
5.5.1
Beneﬁts of encoding identiﬁers
Certiﬁed key pairs that do not contain information that can be uniquely traced or
linked to one person or to a select group are sometimes called digital bearer cer-
tiﬁcates. They are the digital equivalent of paper-based bearer certiﬁcates, such as
currency and bearer bonds. Anyone may obtain them, show them, and pass them
around. Bearer certiﬁcates are the opposite of personal certiﬁcates, which are gen-
erally issued only to parties that meet certain criteria. The simplest way for the CA
to create digital bearer certiﬁcates is to issue blind signatures on public keys. An
improved approach is to use restrictive blinding, to enable the CA to encode basic
attributes (such as use limitations, expiry dates, and veriﬁer policies) and to provide
the ability of selective disclosure.
By deﬁnition, non-personal certiﬁcates must be limited-show certiﬁcates; other-
wise everyone could simply use the same certiﬁcate. This requirement is at odds with

5.5 SECURITY IMPROVEMENTS
209
the ability of computers to instantaneously copy digital certiﬁcates in large numbers
at virtually no cost, and to freely distribute them over electronic networks at the speed
of light. Fraud with digital bearer certiﬁcates and other limited-show certiﬁcates im-
plemented in software-only devices can be prevented only by clearing all showing
protocol executions online with a central party. For each authorization request, this
party (typically the CA) must consult an online database that keeps track of the num-
ber of times a presented certiﬁcate has already been shown. Online clearing suffers
from the drawbacks in Section 1.1.3. The scalability problem is even worse, since
the process of checking the occurrence of a certiﬁcate in the database is inherently
sequential; queries may not be performed in parallel, and the online database may not
be distributed. In many PKIs, though, it sufﬁces for the CA to strongly discourage
fraud and to be able quickly contain it. Using our technique in Section 5.4, it is pos-
sible to realize these security goals and to do away with the need for online clearing.
Hereto the CA must personalize all limited-show attribute certiﬁcates by encoding
into each certiﬁed key pair an attribute identifying the certiﬁcate applicant. Consider
the security beneﬁts:
• A certiﬁcate holder who shows a limited-show certiﬁcate more times than al-
lowed can be traced by computing the built-in identiﬁer from the transcripts
of the showing protocol executions. This enables the CA to stop the fraud
by listing the abused certiﬁcate on a CRL and by blocking further retrieval
of certiﬁcates from account. In addition, if the identiﬁer can be linked to the
identity of the certiﬁcate holder, it may be possible to sue for damages and to
prevent the perpetrator from continuing to participate in the system. Of course,
traceability of perpetrators often also serves as a powerful deterrent.
• This technique can be made to work even for anonymous accounts. Traced
perpetrators can be prevented from opening new anonymous accounts, from
which new limited-show certiﬁcates can be retrieved, by limiting the number
of anonymous accounts to one per certiﬁcate applicant. Hereto a special entity
should issue digital pseudonyms with an embedded identiﬁer, that can each
be used to open one anonymous account. If personal account pseudonyms are
issued in such a manner that the recertiﬁcation technique described in Sec-
tion 5.2.1 applies, the limited-show property remains intact.
• The number of anonymous accounts need not be limited to one per certiﬁcate
applicant. In case a traced perpetrator refuses to reveal any other anonymous
accounts he or she may have opened, the CA can require all system participants
(e.g., the next time they retrieve certiﬁcates) to demonstrate that the identiﬁer
built into their account pseudonym is not that of the perpetrator. Hereto the
showing protocol technique in Section 3.4 can be used. This is not an extra
burden, since applicants must use their account pseudonym anyway to authen-
ticate account access requests.

210
COMBINING ISSUING AND SHOWING PROTOCOLS
• In the same manner, a perpetrator can be stopped from using any other digital
certiﬁcates that may have been issued to him or her. For example, an adminis-
trator of a pseudonymous chat box can require each participant to digitally sign
his or her next message in such a manner that the signed proof demonstrates
that the pseudonym is not that of an identiﬁed misbehaving participant. (The
alternative of issuing only one-show certiﬁcates is not always desirable.)
• More generally, to verify that t public keys, h1, . . . , ht, are not all owned by
the same certiﬁcate applicant, the veriﬁer generates t numbers, α1, . . . , αt at
random from a set V that is a subset of Zq, subject to the condition 	t
i=1 αi =
0 mod q. Let attribute x1 be unique to the certiﬁcate applicant. A cheating
prover can prove knowledge of a DL-representation of g1 with respect to a
tuple that contains t
i=1 hαi
i
with success probability at most 1/|V |, but an
honest group of provers can always (jointly) convince the veriﬁer. (The same
technique applies to the RSAREP-based constructions.)
Stronger fraud discouragement without resorting to online clearing requires the use
of smartcards or other tamper-resistant devices; for details, see the next chapter.
In sum, even though in regular communications and transactions there may be no
need for certiﬁcate holders to show identiﬁers, it is beneﬁcial the CA for to encode
them anyway into their certiﬁed key pairs.
There is no need for the CA to encode globally unique identiﬁers; they should
merely be unique within the domain of the PKI. Identiﬁers need not even be deter-
mined using an out-of-band method: an identiﬁer may be a random number or a
pseudonym known to the CA. In cases where a true name is to be used, the CA may
require registrants to present an X.509 or other identity certiﬁcate; the CA can copy
and paste the subject names from these certiﬁcates into the certiﬁcates it issues.
The current standards for identity certiﬁcates can easily be encapsulated. To en-
capsulate an X.509v3 certiﬁcate, for instance, the CA can take x1 to be (a collision-
intractable hash of) the concatenation of all the ﬁelds except the subject’s X.500 name
(i.e., the format version, serial number, the CA’s certiﬁcation algorithm identiﬁer, the
CA’s X.500 name, the validity period, and the certiﬁcate holder’s public key and the
algorithm with which it is to be used), and x2 the certiﬁcate holder’s X.500 name.
The remaining xi’s can specify additional attributes, such as X.509v3 extensions. In
the certiﬁcate showing protocol, the certiﬁcate holder must disclose (the preimage
of) x1, and may be required to demonstrate properties about the other attributes. To
ensure that the data encoded into x1 does not serve as a unique identiﬁer, the entropy
of at least the validity period and any extension ﬁelds must be restricted. Further-
more, the serial number should be set to a hash of the (certiﬁed) public key, since this
is what is posted on a CRL; alternatively, it is set to zero, since veriﬁers can compute
the hash themselves if needed.3
3ANSI draft standard X9.68 for mobile devices proposes to shorten X.509 certiﬁcates by assigning to
each certiﬁcate an implicit serial number formed by hashing the certiﬁcate; this matches our approach.

5.5 SECURITY IMPROVEMENTS
211
A non-technical objection to the inclusion of identiﬁers into certiﬁed key pairs is
that organizations and other veriﬁers may incite certiﬁcate holders to disclose their
built-in identiﬁers, for example by giving discounts to customers who disclose their
identiﬁers or by refusing to serve anonymous certiﬁcate holders. Privacy legislation
should be adopted that prohibits such discrimination in PKIs where there is no strict
need for identiﬁcation; PKI legislation is needed anyway, so this is not an unrea-
sonable course of action. In Section 6.5.5 we will show how to make it technically
infeasible for certiﬁcate holders to disclose their identiﬁer attributes.
5.5.2
How to discourage lending
It should not be possible for certiﬁcate holder to lend (i.e., distribute copies of) their
personal certiﬁcates, such as driver’s licenses and diplomas, to others. To discourage
lending of certiﬁed key pairs for personal certiﬁcates that are used in face-to-face
situations, the CA could encode biometric identiﬁers into certiﬁed key pairs, such
as digitized photographs, ﬁngerprints, or retina scans. Privacy legislation should
specify when identity disclosure may be required; preferably, veriﬁers may require
disclosure of visual identiﬁers only in rare cases, sampled at random. Fairness can
be enforced by using a cryptographic (biased) coin ﬂipping protocol to determine
whether a biometric identiﬁer must be disclosed.
For improved security and privacy, the CA could encode into each certiﬁed key
pair a plurality of personal characteristics, such as eye color, gender, height, and skin
type. Each of these by itself is not a person identiﬁer, but sufﬁciently many taken
as a group are. In the showing protocol the veriﬁer could then request the certiﬁcate
holder to disclose a random subset of the built-in personal characteristics. Again,
fairness can be achieved by means of (biased) coin ﬂipping, to determine the size
and the elements of the subset that must be disclosed.
Another measure for the CA to discourage lending of certiﬁed key pairs is to
encode into each certiﬁed key pair an attribute that the certiﬁcate holder wants to
remain conﬁdential. Examples are the identity of the certiﬁcate holder (his or her
reputation may be damaged when the borrower discloses the attribute), the secret key
of a key pair used to sign messages (such as a PGP secret key), or a redeemable elec-
tronic token of signiﬁcant value. (It should not be possible, though, for a certiﬁcate
holder to revoke a key or a token within the period that lending is to be discour-
aged.) According to Proposition 3.6.1(b), the demonstration of any Boolean formula
requires knowledge of the entire secret key. Consequently, the lender must reveal to
the borrower all the attributes, including the conﬁdential attribute, even though the
borrower may be interested only in some of the other attributes. This measure may be
combined with the previous measure, but applies also to personal certiﬁcates that are
not restricted to face-to-face situations. By way of example, consider digital gender
certiﬁcates needed to gain access to certain online discussion groups, or “over 18”
certiﬁcates to gain access to adult-oriented Web sites. By encoding along the credit

212
COMBINING ISSUING AND SHOWING PROTOCOLS
card data of the legitimate receiver into his or her certiﬁcates, the issuer can ensure
that the receiver cannot lend (or give out copies of) the certiﬁcate without disclosing
the credit card data; at the same time, privacy is not compromised because the re-
ceiver itself can hide the data when showing the certiﬁcate.4 The CA need not know
the conﬁdential attributes it encodes: it can apply our updating or (re)certiﬁcation
technique described in Section 5.2.1 to a public key presented by the certiﬁcate ap-
plicant (corresponding to the secret the applicant wants to remain conﬁdential).
Yet another measure to discourage lending is for the CA to issue all personal
certiﬁcates in the form of limited-show certiﬁcates.5 This subjects a lender to the
risk that the borrower uses his or her certiﬁed key pair more times than allowed,
which would result in the lender being traced (and held responsible). It also reduces
the number of times the certiﬁcate holder can continue to use the certiﬁed key pair
him or herself. This measure may be applied in conjunction with the measure in the
previous paragraph, applies also to certiﬁcates that by their nature may be shown an
unlimited number of times (before expiry), and works particularly well in conjunction
with short validity periods (which are more natural for limited-show certiﬁcates; see
Section 1.1.5).
Stronger protection against lending requires smartcards; see Section 6.5.3.
5.5.3
Non-repudiation
To prevent the CA from framing certiﬁcate holders by falsely claiming abuse of
limited-show certiﬁcates, consider a variation of the DLREP-based scheme described
in Section 4.5.2. Before issuing certiﬁed key pairs to V0, P0 requires V0 to provide
h∗:= gI
1, for a random I ∈Zq, and to prove knowledge of logg1 h∗without reveal-
ing I; V0 can apply the Schnorr proof of knowledge or its zero-knowledge variation.
In addition, V0 may be required to sign a statement to agree to the consequences of
the use of h∗; this can be combined with the proof of knowledge by giving a signed
proof of logg1 h∗. If the proof is convincing (it need only be performed once), P0
multiplies the desired gi-powers into h∗, and uses the result as the number h in the
issuing protocol to issue to V0 one or more limited-show certiﬁcates. If a certiﬁcate
is shown more times than allowed, I can be computed. Assuming that (q, g1, I) has
been generated by an invulnerable instance generator, I serves as compact undeniable
evidence of fraud.
The evidence can be made unconditionally convincing. Hereto the CA should
4This valuable property cannot be ensured by simply certifying a one-way hash structure of the at-
tributes (such as the concatenation of one-way images of all the attribute values). The resulting certiﬁcates
can be shown without needing to know all the attribute values themselves.
5To prevent linkability of showing protocol executions, certiﬁcate holders must use their certiﬁcates
only a limited number of times anyway, and the CA might as well exploit this by issuing limited-show
certiﬁcates with built-in identiﬁers. The burden of issuing 100 copies (and new ones when needed) is
hardly greater than the burden of issuing a single copy, especially if the CA uses a DLREP-based issuing
protocol that admits preprocessing of all exponentiations.

5.5 SECURITY IMPROVEMENTS
213
require V0 to register using a number h∗of the form gI
1gβ
2 , for an arbitrary I and a
random β ∈Zq. V0 must prove knowledge of a DL-representation of h∗with respect
to (g1, g2); again, this need only be done once. In case of fraud, the CA can compute
I, β, which serve as unconditionally undeniable evidence; assuming that g1, g2 ̸= 1,
the CA cannot frame V0, no matter how it generates the system parameters and its
public key.
This non-repudiation technique works also in conjunction with anonymous ac-
counts: h∗serves as the account pseudonym, which the certiﬁcate applicant must
acquire from an account pseudonym issuer (possibly by showing an X.509 certiﬁcate
or another type of identity certiﬁcate) and uses to authenticate account requests.
To apply the non-repudiation technique to an RSAREP-based certiﬁcate scheme,
V0 should preferably register using a number h∗of the form gI
1βv.
5.5.4
How to discourage discarding
To discourage certiﬁcate holders from discarding certiﬁed key pairs that encode unfa-
vorable attributes, the CA can encode favorable attributes into the same certiﬁed key
pairs. For instance, information on late payments could be encoded into a member-
ship certiﬁcate for a health club or the like, and marks for drunk driving into a driver’s
license certiﬁcate. Note that the updating technique described in Section 5.2.1 can be
put to use here.
This measure does not work when the attributes encoded into the certiﬁed key
pairs of a certiﬁcate applicant change over time and become less favorable to the
applicant. To limit the ability of certiﬁcate holders to reuse old certiﬁed key pairs
that encode attributes that are more favorable, the CA should encode short validity
periods. Alternatively, or preferably in addition, the CA could issue only limited-
show certiﬁcates.
The strongest possible protection in software-only implementations is to issue
only one-show certiﬁcates, and to ensure that certiﬁcate holders cannot show more
than one certiﬁcate at any time. This can be achieved by having the CA recertify (and
update) one-show certiﬁcates only when they are shown in executions of the showing
protocol. This requires all veriﬁers to have an online connection with the CA, and
applies only to certiﬁcates for which the decision as to how to update attributes relies
solely on the data disclosed in the showing protocol.
Stronger protection requires the use of smartcards or other tamper-resistant de-
vices. These can be programmed to show certiﬁcates in the order in which they were
retrieved, and can enter a suspension mode in case of tampering.
5.5.5
Guarding the secret key of the Certiﬁcate Authority
In this section we describe measures to guard the CA’s secret key. Whether any or all
of these measures are actually necessary depends on the PKI at hand.

214
COMBINING ISSUING AND SHOWING PROTOCOLS
Elementary measures
To enforce personnel to behave according to guidelines, organizational controls are
needed. Examples are security clearance and background checks for new employees,
auditing, strict manufacturing and software development procedures, separation of
staff responsibilities, frequent change of assignments, and controlled initialization,
personalization, and distribution of devices. A discussion of these and other controls
is outside the scope of this book.
To raise the barrier to gaining access to the CA’s secret key, it is best generated
and stored within the conﬁnes of a tamper-resistant device and never revealed to the
outside world (including the legitimate operators). This prevents CA personnel from
being extorted or tempted to misuse the key themselves.6 The device could even be
programmed such as to restrain the rate of certiﬁcate issuing to a single person or
location in a given time frame.
For CA devices, it is entirely cost-effective and feasible to achieve very strong
tamper-resistance, because in contrast to smartcards there are no tight size and cost
constraints. CA devices can be made tamper-evident, can be riveted at a secured
location, and can maintain unmodiﬁable audit logs revealing the exact date and time
of each task performed. Preferably, they meet at least security level 3 of FIPS 140-
2 [275], a U.S. federal standard on the security of cryptographic modules and a de
facto industry standard for commercial devices. Adherence to the Common Criteria
for Information Technology Security Evaluations (a voluntary international process
for developing test requirements, intended to replace ITSEC and other like standards)
is recommendable as well.
In addition, it may be desirable to distribute the CA’s secret key across multiple
tamper-resistant devices, and to use secret-sharing techniques to enable designated
subsets to perform the required cryptographic actions without leaking their respec-
tive shares.7 Techniques for shared signature generation are well-known in the cryp-
tographic literature, and can readily be adapted to the issuing protocols described in
Chapter 4; see also Section 4.2.3. The secret key of each tamper-resistant device is
best generated in a mutually random and veriﬁable manner between the device and
its legitimate operators; this can be accomplished through standard cryptographic
techniques.
To cope with cryptanalytic attacks on the CA’s secret key, the system design
should be based on strong underlying cryptographic primitives that have been pub-
licly scrutinized by experts for decades (such as factoring or computing discrete log-
6Jakobsson and Yung [220], in the context of electronic cash, proposed to make each certiﬁcate fully
traceable and clear each certiﬁcate showing online with a central party whenever the CA’s secret key
has leaked or coins have been extorted. This approach leads to severe system disruption, destroys privacy,
does nothing to make extortion less attractive or to prevent it from reoccurring, and does not protect against
insider abuse.
7CertCo and Spyrus, contracted in May 1997 by MasterCard and Visa to manufacture the CA system
for SET [257], were the ﬁrst to adopt this technique in practice.

5.5 SECURITY IMPROVEMENTS
215
arithms). The techniques in this book are believed to meet this criterion. Rather than
using key sizes that are just a little beyond reach of currently known algorithms, key
sizes should be as large as possible without causing a serious performance devalua-
tion. In this respect, an elliptic curve implementation with keys that are not too short
offers a distinct advantage. The CA should update to larger key sizes on a regular
basis, and be prepared to do so in short term.
Stronger measures
When much is at stake, the CA should (in addition to the previous measures) enforce
deposit of all showing protocol transcripts (not necessarily online), and continuously
compare the number of certiﬁcates issued against that of certiﬁcates deposited. It
appears that none of today’s commercial certiﬁcate systems offer this provision, but
this will likely change once the parallels between digital certiﬁcate systems and elec-
tronic cash systems are widely acknowledged.
This measure is not very effective in a large-scale PKI, because suspicion of
forgery does not arise until the number of forged certiﬁcates approaches the number
of issued certiﬁcates that have not yet been shown. The situation can be improved
by taking into account the issued and disclosed attributes of each certiﬁcate. That
is, for each attribute property disclosed the CA should maintain a separate category
and compare a running count of each category with the number and combination of
attributes issued. In an electronic coin system, for instance, the bank should monitor
per coin denomination and per coin version.
In high-risk PKIs, the CA could encode random numbers from small sets into the
attribute certiﬁcates it issues. Certiﬁcate holders are in full control over the secrecy
of these attributes, but in case of strong suspicion of forgery, the CA can turn up the
heat by requiring veriﬁers to demand certiﬁcate holders to reveal (part of) the encoded
random numbers; the CA should then announce that it will no longer honor deposits
from veriﬁers that do not abide by these rules. (Legislation should specify the condi-
tions under which such a revision of deposit rules is legitimate.) In this way, the CA
can dynamically shift between a positive list and a negative list approach; in the worst
case, certiﬁcate holders are required to disclose a built-in identiﬁer each time. (In this
fashion, our techniques cover the entire range between privacy-protecting certiﬁcates
and identity certiﬁcates.)
In a similar manner, the CA can dynamically set conditions for which types of
certiﬁcates may be accepted off-line and which require its on-line approval.
Even stronger measures
In the presence of an attacker with “inﬁnite” computing power, these measures are
insufﬁcient. A quantum computer, for instance, would be able to compute discrete
logarithms and factorize in about the same time as it takes to exponentiate large

216
COMBINING ISSUING AND SHOWING PROTOCOLS
numbers; see Shor [350]. Since forgery by an attacker with unlimited computing
power can never be prevented, the primary defense line is to contain the damages.
The ultimate containment measure, if all else fails, is system suspension. The CA
should make sure either that its certiﬁcate issuance is no longer accepted or that it
can recognize and reject forged certiﬁcates during online certiﬁcate validation. The
CA can still accept online executions of the certiﬁcate showing protocol by requir-
ing certiﬁcate holders to disclose the identiﬁers that have been encoded into their
certiﬁcates.
In addition, depending on the nature of the PKI, it may be necessary that all au-
thentic outstanding digital certiﬁcates can be securely redeemed, to prevent a melt-
down scenario. This fall-back mechanism must be secure even in the presence of an
attacker with unlimited computing power. Preferably the fall-back mechanism can
be implemented by means of a protocol that does not require certiﬁcate holders to
show up in person at the CA. To this end, the software-only return protocol that will
be described in Section 6.5.2 can be used.
5.6
Bibliographic notes
The techniques in Section 5.1.1 originate from Brands [54]. For an application, see
Brands [46, 48]; here, the issuing protocol serves to issue electronic coins that encode
an attribute representing the coin denomination (and possibly also an expiry date and
other data that must always be disclosed to payees) and an identiﬁer attribute that
can be computed if and only if the coin is double-spent (using the static one-show
blinding technique).
The discussion of the delegation strategy in Section 5.1.2 is based on Brands [53].
The parallel delegation strategy described for the case of the immunized DLREP-
based scheme I in Section 4.4.2 was discovered by Schoenmakers [341, footnote 1];
the proposed measures to make this strategy ineffective are new, though. (In light of
this Schoenmakers’ remark on the insecurity of the second method of Brands [47]
for exchange rates must be nuanced. In fact, in the issuing and showing protocol de-
scribed by [47] the problem does not arise in the ﬁrst place because parallel protocol
executions by different account holders are excluded.)
The anonymous recertiﬁcation and updating techniques in Section 5.2.1 were in-
troduced by Brands [54], together with an application of the updating technique to
anonymous accounts in the off-line electronic cash system of Brands [46, 48]. Subse-
quently, Brickell, Gemmell, and Kravitz [62, 240] applied the anonymous updating
technique for the purpose of online change-making in the off-line electronic cash
system of Brands [48].
The techniques described in Section 5.2.2 are all based on Brands [54]. The ap-
plication to credential systems predates a credential system proposed by Chen [113],
which has many drawbacks over our proposal: Chen’s system offers only compu-

5.6 BIBLIOGRAPHIC NOTES
217
tational unlinkability, does not handle attribute certiﬁcates and selective disclosure,
does not offer traceability of fraud with limited-show credentials, does not provide
for smartcard extensions (whereas we can apply the techniques that will be developed
in the next chapter), and uses an issuing protocol that is inferior to that described in
Section 4.5.2.
The techniques in Section 5.3 appear here for the ﬁrst time.
The static and dynamic limited-show certiﬁcation techniques in Section 5.4 are
based on Brands [45]. Some details have been ﬁlled in, and the formal security
statements and their proofs are new.
Most of the security improvements in Section 5.5 originate from Brands [54].
The idea of discouraging lending of certiﬁed key pairs by encoding a special secret
that the certiﬁcate holder wants to remain conﬁdential (see Section 5.5.2) was in-
spired by the following remark by Garﬁnkel [180] about identity certiﬁcates: “While
a few dozen guys might get together and share a single username and password for
a cybersex site, there is no way that any of these clowns will let the others share his
digital ID’s secret key, which will also unlock his bank account and credit cards.” The
same observation has been used by Dwork, Lotspiech, and Naor [142], by Goldreich,
Pﬁtzmann, and Rivest [192], by Sander and Ta-Shma [333] (to discourage lending in
the electronic cash system of Brands [46, 48]), and by Lysyanskaya, Rivest, Sahai,
and Wolf [253]8 in the context of digital pseudonyms. However, none of these pub-
lications consider the remote lending problem that we will address in Section 6.5.3.
The non-repudiation technique in Section 5.5.3 originates from Brands [46, 48],
where it was applied in the context of off-line electronic cash.
8The techniques in this book offer a much better solution; the advantages are the same as the advantages
over the credential system of Chen [113].


Chapter 6
Smartcard Integration
In this chapter we show how to implement our certiﬁcate issuing and showing pro-
tocol techniques in smartcards. We realize all the smartcard beneﬁts listed in Sec-
tion 1.1.6, without adding complexity and without downgrading security or privacy.
We also show how to tune our protocols in the smartcard-enhanced setting to accom-
modate any degree of privacy desired.
6.1
Shortcomings of the smartcard-only paradigm
As we have seen in Section 1.1.6, smartcard-based implementations of PKI mecha-
nisms offer numerous advantages over software-only implementations. Many of the
beneﬁts do not exist, though, when certiﬁcates are implemented entirely in smart-
cards. In this section we describe the shortcomings of smartcard-only implementa-
tions.
6.1.1
Privacy dangers
In a brochure [358], the Smart Card Forum states: “Smart card technology, if prop-
erly designed and implemented, can enhance both the fact and the perception of the
individual’s ability to exercise a much greater degree of control over personal in-
formation than is the case with any comparable delivery system.” While it is true
that smartcards enhance the perception of privacy, perception and fact are two very
different things:
• The smartcard systems currently in use do nothing to prevent organizations
from linking and tracing all communications and transactions by the same
cardholder. For security reasons, they operate by transmitting in each trans-
action a unique card identiﬁer that can be linked to central database entries
that hold all kinds of identiﬁable personal data.

220
SMARTCARD INTEGRATION
• A smartcard, or any other tamper-resistant device for that matter, operates as
a black box to anyone but its manufacturer; its inner workings cannot be scru-
tinized or modiﬁed by its holder. (Most outsiders are not capable of breaking
into smartcards to determine their internal behavior, and detected attempts to
break in may result in criminal charges.) Smartcards can be programmed to
operate as Trojan horses, offering convenience to their holders while at the
same time covertly sending out their personal data.
The idea that government agencies may cause organizations to build in backdoors
into devices is not far-fetched, as history reveals:
• In the early eighties the U.S. Justice Department misappropriated PROMIS, a
software program developed by Inslaw Inc. that facilitated the integration of all
sorts of databases. The U.S. intelligence community incorporated a backdoor
and sold the modiﬁed version to intelligence organizationsand banks in over 80
foreign countries; see Fricker [175], Kimery [231], Kunkin [243], Leon [248],
and the Washington Weekly [372].
• In the mid eighties, the NSA worked together with Systematics, a major sup-
plier of software for back ofﬁce clearing and wire transfers, to introduce back-
doors in much of the banking software supplied to U.S. ﬁnancial institutions;
see Grabbe [197] and Russell [332].
• In 1995, Der Spiegel and The Baltimore Sun reported that the NSA since 1957
had a secret deal with the Swiss cryptography company Crypto AG, under
which Crypto AG built backdoor access into its encryption products; see Bam-
ford [19, Chapter 8], Global Network Navigator [188], Strehle [364], the Bal-
timore Sun [371], and Madsen [254].
• In 1996, Walsh, a former deputy of the Australian Security Intelligence Organ-
isation (ASIO, the Australian equivalent of the NSA), conducted an inﬂuential
study [386] about Australian cryptography policy. In the uncensored version
of the report, Walsh recommended: “Authority should be created for the AFP,
the NCA and ASIO to alter proprietary software so that it performs additional
functions to those speciﬁed by the manufacturer. [...] The software (or more
rarely the hardware) may relate to communication, data storage, encoding, en-
cryption or publishing devices. [...] some modiﬁcations may [...] create an
intelligent memory, a permanent set of commands not speciﬁed in the program
written by the manufacturer or a remote switching device with a capacity to
issue commands at request. [...] In the event of an equipment or software
malfunction or failure to perform to full speciﬁcation, an investigation of a
complaint could lead to discovery of the modiﬁcation. The issue of liability of
the Commonwealth may then potentially arise.”

6.1 SHORTCOMINGS OF THE SMARTCARD-ONLY PARADIGM
221
Covert data exchange between a tamper-resistant device and the outside world can
take place through a number of channels. Two obvious channels are the following:
• The device can covertly send out or receive data by exploiting the van Eck
effect or simply by sending out or receiving radio signals. We call this the
physical broadcast channel. It is a particular problem in case of contactless
smartcards, which can communicate over much larger distances than com-
monly believed. For instance, On Track Innovation Ltd. markets a contactless
smartcard that it claims can communicate with a reader over a distance of up
to 30 meters; the card can be remotely “revised, expanded and changed, and
new applications can be added, without having to replace the card itself.”
• Another channel becomes available when the device is engaged in a protocol
execution with another device. Along with the data speciﬁed by the protocol,
the device can leak out data. Alternatively, data can be leaked by changing the
format of the messages as speciﬁed by the protocol; stop bits can be ﬂipped,
message ﬁelds set to values outside of speciﬁed ranges, and so on. We call this
the piggyback channel.
The following channels are more surreptitious:
• In case a device engages in an interactive protocol, one or more bits of infor-
mation can be leaked by halting during the protocol execution. For instance,
by deciding whether or not to respond to a challenge before a time-out the de-
vice can leak one bit. More generally, in a protocol with t rounds, one of t + 1
preestablished messages can be leaked. This is called the halting channel (also
known as the stopping channel).
• In a similar manner, a device can leak out bits of information by timing the
delay before transmitting a message; this is called the timing channel. In con-
trast to the halting channel, this requires the device to have access to a timer.
(This can be as simple as resetting a counter value in a chip register when a
message is received, and sending out a response message when the counter
reaches zero.) If messages are transmitted over a reliable channel with known
performance characteristics, many bits can be leaked without noticeable de-
lays.
• A related channel is the computation error channel. Here, a device deliberately
causes one of its response messages to be incorrect. The fact whether or not
a response is correct can be used to leak one bit of data, while an incorrect
response can leak as many bits as its binary size.
Even more surreptitious are subliminal channels, ﬁrst studied by Simmons [354, 355]
in the setting of two prisoners who want to hatch an escape plan but can only com-
municate via a warden. Here, the data transmitted complies with all the range limi-
tations, format speciﬁcations, and veriﬁcation relations speciﬁed by the protocol, but

222
SMARTCARD INTEGRATION
the manner in which the data is formed does not. In particular, data is leaked in such
a manner that not even an interposed observer can distinguish a legitimate protocol
execution from one in which bits are leaked. Following Chaum [97], we distinguish
two subliminal channels:
• Any data that is subliminally leaked by a device is called outﬂow. The data
can be leaked by encoding covert message bits in any data that may be chosen
by the device. If the device encrypts its covert messages under a random key
known only to the receiving device, an observer with unlimited computing
power will not be able to tell the difference with a truly random number.
• Any data that is subliminally leaked to a device is called inﬂow. In the showing
protocols in Chapter 3, the veriﬁer can encode a covert message into the part of
its challenge message that serves to protect against replay, possibly encrypted
under a mutually known key. Any other data that is hashed along and under
the control of the veriﬁer can also be misused to cause inﬂow.
Certiﬁcate holders will in general be more concerned about outﬂow than inﬂow. Out-
ﬂow can reveal their device identiﬁer, access control code, communication and trans-
action history, attributes, data from other applications running on the same device,
and so on. The device does not need to know with whom it is communicating; it
can simply leak out the data with each protocol execution, possibly encrypted under
a key of the intended recipient. Outﬂow gives veriﬁers and other parties the power
to discriminate against certiﬁcate holders and to follow certiﬁcate holders around in
real time.
Outﬂow is particularly powerful when triggered by inﬂow. For example, a re-
ceiving device could transmit its device identiﬁer, so that the smartcard can decide
whether or not to leak data. New rule speciﬁcations can be uploaded dynamically
by means of inﬂow, and the certiﬁcate holder’s device can be queried in an arbitrary
manner.
When outﬂow is prevented, inﬂow is less of a problem, but even then it poses
dangers:
• Inﬂow messages can cause the smartcard to enter a state of suspension or to
default in other ways. For example, an inﬂow message could say “If the device
identiﬁer is #134522, then abort.” Errors can be made to occur that appear
random to the device holder.
• In cases where the device is expected to send out at least one message, it can
always respond to inﬂow queries by means of the halting channel.
• When the smartcard is returned to its issuer, either to be replaced or for an-
other reason, the card issuer can read out all the inﬂow collected by the card
during the time it was in the hands of its holder. (The card issuer may for in-
stance make the card dump its memory contents by entering a special access

6.1 SHORTCOMINGS OF THE SMARTCARD-ONLY PARADIGM
223
code.) In this manner, the card issuer may be able to retroactively trace all the
communications and transactions of the individual.
Inﬂow is most powerful when receiving devices are tamper-resistant as well.
The trend to store multiple applications on a single smartcard increases the scope
for privacy invasion. It is impossible for anyone but the card issuing organizations
to verify that different pieces of personal data are used only by the application for
which they were collected.
The disparity between perception and fact makes the smartcard-only model ex-
tremely dangerous, especially since the interests of card issuers are not aligned with
those of individuals. Even if the issuer and the manufacturer(s) of the smartcards
could be trusted, implementing our issuing and showing protocol techniques entirely
in tamper-resistant smartcards would not preserve privacy. Namely, most of today’s
smartcards can produce only pseudorandom numbers, on the basis of a random seed
value that must be installed by (or under the supervision of) the issuer, to guarantee
its uniqueness, randomness, and secrecy. Therefore, the issuer can compute all the
pseudorandom numbers used by each device during its lifetime. Even if the issuer
were to state that it does not know the seed values, or that its tamper-resistant devices
produce random numbers by post-processing bits sampled from an internal “true”
randomness source (such as a noise diode), this statement cannot be publicly veri-
ﬁed. Also, the quality of a noise generator or other hardware methods for generating
random numbers cannot be guaranteed.
Privacy concerns are one of the main reasons why smartcard implementations
worldwide are stalling. As Schwartz [343] notes, “Ultimately, smart cards will not
be able to succeed if consumers do not trust them. If the tracking ability of the
cards weighs greater in the minds of consumers than convenience, the cards will not
succeed in the market.”
6.1.2
Other shortcomings
In addition to these serious privacy problems, there are other reasons to believe that
the smartcard-only paradigm is inadequate and dangerous:
• Great care must be taken that the addition of complex circuitry and software
does not introduce weaknesses in the tamper-resistance characteristics of the
hardware. The cost of developing and incorporating new circuitry and software
is much greater in the case of smartcards than in environments where tamper-
resistance is not a concern. The ability to protect smartcards hinges on having
enough capability and space for a software solution.
• With smartcard components already cramming for space, adding circuitry ad-
versely affects smartcard reliability. A “dead” card at the very least inconve-
niences and frustrates its holder, and in many applications the consequences

224
SMARTCARD INTEGRATION
can be quite dramatic. If multiple applications are stored on the same card, its
holder may all of a sudden be locked out of a number of services.
• Because of size constraints, there will always be serious limitations to the func-
tionality that can be squeezed into a smartcard. The amount of smartcard mem-
ory needed to keep track of a detailed log of all uses of a certiﬁcate (for the
convenience of its holder) is substantial. The display and keyboard sizes of a
so-called “super smartcard” are adequate only for communication of the most
rudimentary data.
• The smartcard must be relied on to protect the security interests of its holder.
Since standard smartcards do not have their own display and keyboard, user
identiﬁcation data must be entered on a terminal communicating with the card,
and this terminal must be trusted not to capture the user’s identiﬁcation data.
Likewise, any results that the card wants to communicate to its holder must be
displayed on the terminal. The result is that a variety of fake-terminal attacks
become possible. Even with a super smartcard there is no way for cardholders
to verify that the data entered into and displayed by their card is the same as
that processed and output by the card.
• If the secret keys of certiﬁcate holders are generated inside a smartcard, there
is no way to verify that they are generated in such a manner that others cannot
guess them. In particular, as we have seen in the previous section, it is very
hard to guarantee that the CA cannot reconstruct all the secret keys. This makes
the legal status of digital signatures highly doubtful.
• Card issuers for security reasons will need to migrate to a new tamper-resistant
chip design every couple of years. During the renewal period, the individual is
unable to use his or her certiﬁed key pairs, and is inconvenienced by the loss
of the functionality stored on the card.
In sum, smartcards are far from the most logical place to install additional circuitry
and software intended to expand functionality for the card holder.
In spite of the pitfalls, the security advantages of smartcards are so great that
smartcards should not be abandoned. We now examine how to overcome the short-
comings of the smartcard-only model and realize all the beneﬁts described in Sec-
tion 1.1.6.
6.2
Combining smartcards and software-only devices
A smartcard is not a stand-alone computing device; by its very nature, it can operate
only in combination with another device. Indeed, most smartcards do not have their
own power source. In many communication and transaction settings, smartcards are

6.2 COMBINING SMARTCARDS AND SOFTWARE-ONLY DEVICES
225
naturally used in conjunction with user-controlled software-only computing devices.
For example, to use a smartcard over the Internet, it will have to be connected to a
desktop computer, notebook, handheld, or otherwise.
The integration of smartcards and software-only computing devices (such as PCs,
notebooks, and handhelds) is already well underway. Standardization efforts by ma-
jor industry consortiums include the PC/SC Workgroup [297] and the OpenCard
Framework[293]. Smartcard readers for PCs come in many forms: as a serial port
add-on, embedded into the keyboard, as a device connected to the keyboard port,
plugging into a ﬂoppy drive, combined with a modem, or as a PC Card. Prices are
dropping rapidly owing to new design methods. In October 1998, Microsoft an-
nounced Smart Cards for Windows (subsequently renamed to Windows for Smart
Cards), an 8-bit multi-application operating system for low-cost smart cards with 8
kilobytes of ROM, designed to extend the desktop computer environment into smart-
card use.1
6.2.1
Beneﬁts
Combining smartcards with user-controlled software-only computers offers many ad-
vantages:
• Fake terminal attacks can be prevented. If the user’s computer has a keyboard
and a display, the user can enter his or her password, PIN, or biometric using
the keyboard, and can read out any transaction information from the comput-
er’s display; there is no need to rely on someone else’s device for interacting
with one’s own smartcard.
• With a proper design, most of the computational and storage burden of the
smartcard can be moved to the user-controlled computer, which can be much
more powerful. In particular, high-strength public key cryptographic tech-
niques may become entirely feasible using low-cost smartcards without cryp-
tographic coprocessors. (See Section 6.5.1 for an example.)
• As a consequence of the fact that fake terminal attacks need not be prevented
and sophisticated public-key cryptographic techniques are entirely feasible,
veriﬁers do not need tamper-resistant terminals that represent the security inter-
ests of a CA.2 This makes it much easier to become an acceptor of certiﬁcates.
• Any individual or software or hardware manufacturer can make or provide its
own functional or other enhancements for the user’s computer and sell them
on the open market; this is an attractive feature for all parties alike.
1Users of Windows NT 5.0, for instance, can gain network access by presenting an X.509v3 certiﬁcate
stored on a smartcard.
2In today’s electronic purse systems and other off-line smartcard systems based on symmetric cryptog-
raphy, veriﬁer terminals must be strongly tamper-resistant to protect a master key that enables reconstruc-
tion of all smartcard secret keys.

226
SMARTCARD INTEGRATION
• The user’s computer can safeguard the secret keys of the user, and can make,
store (for the purpose of non-repudiation), and verify any digital signatures.
It can also keep its own chronological transaction log, and allow the user to
review and print it. Special software could provide certiﬁcate management
functions, such as help the user track his or her own transactions and categorize
them. The transaction data could automatically ﬂow into a software program,
so that the user need never key in any data. For improved conﬁdentiality, any
sensitive data stored on the user’s computer can be encrypted using a password-
derived secret key.
• Schneier and Shostack [336] discuss the security ramiﬁcations of the fact that
many different parties are involved with manufacturing and handling smart-
cards. Among other measures, they argue that a prime candidate for improve-
ment is to place the user interface under the control of the user. This ﬁts per-
fectly with the model considered here.
Compact operating systems, open source code, independent code reviews, digital
certiﬁcation of source code and executables, open market availability, and anti-virus
software all contribute to the trust that users can place in the software running on
their own computer.
Ideally, desktop computers are used only as devices to communicate over the
Internet and to run application software, and the user-controlled computer is in the
form of a personal digital assistant (PDA) or similar handheld device. The handheld
device enables its holder to port his or her certiﬁed key pairs, and is better suited
as a medium to run trusted code. Access to the Internet by PDAs is on the rise.
In 1998, Semico Research predicted that the sales of small portable computers will
reach 7.5 billion dollars in the year 2003, and the Yankee Group estimated that by
2002 there will be over 21 million subscribers of mobile, wireless access to the Inter-
net. Companies including Microsoft and 3COM have already announced smartcard
enhancements for handheld devices.
By interposing their computer between the smartcard and the outside world, users
can straightforwardly prevent certain data leakages:
• The user’s computer can prevent the smartcard from covertly sending out data
using physical broadcast. In cyberspace, there should rarely be a need to pro-
tect against the emission or reception of radio signals or electromagnetic radia-
tion, especially when communications and transactions are untraceable. Com-
munications and transactions in the physical world, however, require protec-
tion by means of physical shielding. General measures to protect against van
Eck monitoring are expensive and mostly classiﬁed, but effective solutions are
available for smartcards and other user devices. For instance, Cord Technolo-
gies, Inc. ships a low-cost electromagnetic shield slightly larger than a smart-
card, which (according to its claims) closely approximates a Faraday Cage; by
blocking low frequency magnetic ﬁelds and radiofrequency communication,

6.2 COMBINING SMARTCARDS AND SOFTWARE-ONLY DEVICES
227
it prevents an inserted chipcard from communicating with a card reader and
from receiving the electrical power needed to operate. Handhelds and other
software-only devices could have such protection built into their smartcard
slots.
• Software on the user’s computer can verify all the data passing to and from the
smartcard. It can do range checks, check veriﬁcation relations, and so on. Snif-
fer programs can intercept data sent to communication ports and compare this
with speciﬁed data formats, allowing the user’s computer to detect the exis-
tence of a piggyback channel.3 More generally, software running on the user’s
computer can sift any data before passing it on, or simply halt a transmission
in case data ﬁelds do not comply with the protocol speciﬁcations.
Thus, the integration of smartcards and other tamper-resistant user devices with user-
controlled computers provides a natural environment to protect against data leakages
that are efﬁciently detectable. From now on, we will assume that the smartcard-
enhanced systems that we will develop prevent such data leakages.
6.2.2
How not to cope with subliminal channels
Simmons [354, 355] and Desmedt, Goutier, and Bengio [135, Section 5] showed
how to use randomization to destroy subliminal channels, in a general setting. In
1988, Chaum [97] proposed very similar techniques to prevent inﬂow and outﬂow
in the setting of consumer transactions, particularly electronic cash. Chaum’s smart-
card techniques [97, 103, 109] have numerous drawbacks, though, that make them
unsuitable for practical use.
By far the most serious shortcoming relates to security: the systemic security
breaks down completely when an attacker succeeds in compromising the tamper-
resistance of a single smartcard. The problem is Chaum’s reliance on blind signature
protocols. Anyone who extracts the secret key of a smartcard can copy and lend
out certiﬁcates at will. The blinding makes it hard or even impossible to detect the
fraud, even if all the showing protocol executions involve the online participation of
the CA. Even if fraud could be detected, its source cannot be traced and the fraud
cannot be contained in any other way than by suspending the operation of the entire
system: distribution of CRLs and online certiﬁcate validation do not help, because
the attacker cannot be stopped from retrieving new certiﬁcates.
The security problem is worsened by the way in which Chaum encodes attribute
information. Instead of having the CA encode attributes by cryptographic techniques
(blind signatures cannot accomplish this), Chaum simply has the smartcard digitally
sign statements about attributes the CA has stored in its memory. This ﬂawed ap-
proach is central to all Chaum’s work, as witnessed for instance by the following:
3In this manner, engineers in May 1995 discovered that Microsoft’s Registration Wizard covertly sent
the entire directory structure of the user’s hard drive to Microsoft.

228
SMARTCARD INTEGRATION
• Chaum [97, page 16] proposes that the tamper-resistant device “sign state-
ments requested by C that T checks are true based on credential data it main-
tains.”
(Here, C denotes the user-controlled computer, and T the tamper-
resistant device.)
• Chaum [88] states: “When the young Bob graduates with honors in medieval
literature, for example, the university registrar gives his representative a digi-
tally signed message asserting his academic credentials. When Bob applies to
graduate school, [...] his representative asks its observer to sign a statement
that he has a B.A. cum laude and that he qualiﬁes for ﬁnancial aid based on at
least one of the university’s criteria (but without revealing which ones). The
observer, which has veriﬁed and stored each of Bob’s credentials as they come
in, simply checks its memory and signs the statement if it is true.” (Chaum
uses the terms “observer” and “representative” to refer to the smartcard and
the user-controlled computer, respectively.)
• In the same manner, Chaum [88] deals with negative statements, such as felony
convictions, license suspensions, or statements of pending bankruptcy: “Once
the observer has registered a negative credential, an organization can ﬁnd out
about it simply by asking the observer (through the representative) to sign a
message attesting to its presence or absence. Although a representative could
muzzle the observer, it could not forge an assertion about the state of its cre-
dentials.”
• In his smartcard-enhanced electronic cash systems [41, 103], Chaum gives
each consumer smartcard the power to mint electronic money. Each smart-
card stores electronic cash in the form of a counter value maintained in a chip
register. For example, one hundred electronic dollars spendable up to cent
granularity would be represented by a counter value of 10 000. To make a pay-
ment, a smartcard ﬁlls out the payable amount using a blinded electronic check
and decreases its register value correspondingly.4
Consequently, the physical compromise of a single smartcard not only enables the
attacker to anonymously ﬂood the system with (copies of) untraceable certiﬁcates,
but also to pretend to possess certiﬁcates for arbitrary attributes. Depending on the
application, this can result in enormous damages. For instance, in a ﬁnancial appli-
cation the attacker may claim to have been issued digital bearer bonds worth huge
sums of money, and may be able to impersonate people by assuming arbitrary identity
attributes.
Chaum’s blind trust in the tamper-proofness of smartcards is puzzling. Decades
of experience have provided strong evidence that absolute tamper-proofness will
4Electronic purse systems based on symmetric cryptography also work this way, but the complete lack
of privacy at least ensures that fraud can be contained.

6.2 COMBINING SMARTCARDS AND SOFTWARE-ONLY DEVICES
229
likely never be fully realizable. Kocher [236], Anderson and Kuhn [12, 13], Boneh,
DeMillo, and Lipton [38], and Biham and Shamir [29] discuss low-cost physical at-
tacks that do not require direct physical access to the smartcard’s internals. The most
powerful non-invasive attack is Differential Power Analysis, due to Kocher, Jaffe,
and Jun [237], in which the attacker gathers information correlated to secret keys by
using statistical analysis and error correction techniques. Invasive physical attacks
require days or weeks in a specialized laboratory and are much more costly to under-
take, but they are also much harder to protect against. Microprobe workstations and
other sophisticated equipment can be used to physically damage a smartcard chip in
a controlled manner. See Kuhn [242, Section 1.2] and K¨ommerling and Kuhn [239]
for an overview of equipment to attack chips at the hardware level, and Biham and
Shamir [30] for an invasive attack based on destroying a single wire of a carefully
chosen memory cell using a laser beam. Even though manufacturers work hard to
improve smartcard tamper-resistance, mass production smartcards will likely never
be able to withstand invasive physical attacks for more than a couple of years follow-
ing their release. New sophisticated apparatus will appear, and existing apparatus is
being improved all the time. Organized crime can hire expertise comparable to that
in national laboratories, and sophisticated tools are increasingly becoming accessi-
ble to hackers and undergraduate students at technical universities. K¨ommerling and
Kuhn [239] “see no really effective short-term protection against carefully planned
invasive tampering involving focused ion-beam tools.” They note that storage of se-
crets in battery-backed SRAM is highly effective to protect against invasive attacks
(through zeroization), but this technology is not feasible for smartcards.
In a 1997 interview, Chaum [104] claimed: “On-line, software-only techniques
sometimes become rather elaborate, whereas if you have a tamper-resistant device,
you can do things in a relatively simple way.” We now know, though, that the practice
of relying solely on smartcard tamper-resistance is not acceptable. As Kocher, Jaffe,
and Jun [237] point out with respect to Differential Power Analysis, the best way
to deal with smartcard vulnerability is to design cryptographic systems under the
assumption that secret key information will leak. In light of this, we will operate
in this chapter under the assumption that smartcard tamper-resistance is a matter of
economics. At the very least, we need the following security features:
• Each smartcard must have a unique independent secret key. (In practice, com-
putational independence sufﬁces, and so this principle is not violated by using
diversiﬁed secret keys.)
• To guarantee that a smartcard design will be able to survive widespread physi-
cal compromise of smartcards, the design must provide for the ability to detect,
trace and contain fraud even if all smartcards are compromised. That is, the
smartcard-enhanced system should have all the security features of a secure
software-only system. (This also facilitates a seamless migration path from
software-only devices to a setting where certiﬁcate holders also hold smart-

230
SMARTCARD INTEGRATION
cards, or vice versa.)
• Any sound smartcard system requires a strategy for migrating from one gener-
ation of smartcards to the next, to keep up with advances in smartcard tamper-
ing.
Chaum’s smartcard techniques have yet another drawback: they cannot prevent the
smartcard from storing data that the CA can use retroactively to trace transactions,
once it gains access to the contents of the device. Any unique random number known
to both the smartcard and the veriﬁer in the showing protocol execution can be used
to trace the transaction. Cramer and Pedersen [122] modiﬁed Chaum’s protocols to
prevent the smartcard and the veriﬁer from developing common coin ﬂips, i.e., mutu-
ally known information that is statistically correlated, other than inﬂow and outﬂow.
A drawback of their protocol is that both the smartcard and the user’s computer must
perform several real-time exponentiations that cannot be preprocessed, and the is-
suing protocol consists of 10 moves. More seriously, the modiﬁed protocol does
nothing to overcome the security problems of Chaum’s techniques, and in fact de-
grades security even further. An anonymous extortioner in cyberspace can force an
individual to retrieve certiﬁcates for which the extortioner supplies the blinding fac-
tors, and can subsequently show these by requiring the victim to assist in performing
the showing protocol execution. The extortioner can blind any data from and to the
veriﬁer before relaying it, and in this manner can remain untraceable at all times to
anyone including the victim.5 When certiﬁcates represent money or other signiﬁcant
value that veriﬁers can redeem from the CA, this perfect crime exposes certiﬁcate
holders to unacceptable risk.
In the remainder of this chapter we show how to overcome all these problems.
6.3
Secure smartcard integration
In this section we show how to overcome the security and efﬁciency shortcomings
described in the previous section. The goal is to ensure that the user-controlled com-
puter cannot show a certiﬁcate without the assistance of the smartcard. This will lay
the foundation for the privacy techniques in Section 6.4.
6.3.1
Technique based on the DLREP function
We replace P in the showing protocols of Chapter 3 by < S, U>. S denotes the
smartcard and U the user’s software-only computer. S and U must be conﬁgured
in such a manner that any protocol data to and from S ﬂows through U. The system
5A simpler form of this extortion strategy applies in the software-only setting, where the extortioner
needs the “assistance” of the victim only in the issuing protocol. In the special case of electronic cash, this
is known as “payee untraceability.”

6.3 SECURE SMARTCARD INTEGRATION
231
parameters and the public key h are generated as described in Section 3.2, and atomic
propositions are demonstrated as depicted in Figures 3.1 and 3.5.
According to Proposition 3.6.1(b), the demonstration of a satisﬁable Boolean for-
mula is a proof of knowledge of a DL-representation of h with respect to (g1, . . . , gl).
From this we immediately obtain the following result.
Proposition 6.3.1. If (x1, . . . , xl) is shared between S and U in such a manner that
U cannot compute with non-negligible success probability a DL-representation of
h := l
i=1 gxi
i
with respect to (g1, . . . , gl), then U cannot demonstrate any Boolean
formula without the assistance of S.
Note that S’s assistance is required even to demonstrate formulae in which its
share of the DL-representation does not appear, and in particular to demonstrate the
formula TRUE.
Any manner of sharing the DL-representation of h will do; all that matters is that
U cannot compute the entire representation by itself. Not all sharing methods are
equally suitable, though. Non-linear sharing makes it difﬁcult for S to assist U in the
showing protocol in any other manner than by providing to U its share of the repre-
sentation. The resulting showing protocol would be insecure, since U can reuse h in
subsequent formula demonstrations without needing S’s assistance. The following
construction shows how (x1, . . . , xl) may be shared securely and efﬁciently.
Proposition 6.3.2. Suppose that x1 is generated at random from Zq, and is known
to S but not to U. Regardless of the distribution of (x2, . . . , xl), < S, U> can demon-
strate to V any Boolean formula of the form (3.7) in which x1 does not appear, in
such a manner that:
• The only task that S performs in each formula demonstration is one execution
of the Schnorr proof of knowledge, in which it proves knowledge of x1 to U.
• The view of V when interacting with < S, U> is the same as it would be when
interacting with P.
Proof. Let h = hShU, where hS = gx1
1
and hU = l
i=2 gxi
i . To show how the
demonstration of a formula takes place, we consider four cases:
Case 1. F is an atomic formula consisting of zero or more “AND” connectives and
no other connectives, in the form (3.3). We assume the permutation π(·) of
{1, . . . , l} has 1 as a ﬁxed point. If x1 does not appear in the formula to be
demonstrated by < S, U>, then the 1-st column in the matrix on the left-hand
side of the system (3.2) contains all zeros.
To compute a in Step 1 of the showing protocol, S generates a random number
w1 ∈Zq, computes aS := gw1
1 , and sends aS to U. U generates l −t −1

232
SMARTCARD INTEGRATION
random numbers, w2, . . . , wl−t ∈Zq, and computes
a := aS
l−t

i=2
gwi
π(i)
t
i=1
g
−	l−t
j=2 αijwj
π(l−t+i)
.
To compute the l −t responses in Step 2, U sends V’s challenge c to S. S
computes rS := cx1 + w1 mod q, and sends rS to U. U sets r1 := rS, and
computes the other l −t −1 responses as speciﬁed in Step 2 of the protocol
(P, V).
Clearly, the task performed by S is exactly an execution of the Schnorr proof
of knowledge, in which it proves knowledge of logg1 hS to U, and the view of
V is the same as it would be in (P, V).
Case 2. F is an atomic formula consisting of zero or more “AND” connectives, one
“NOT” connective, and no other connectives, in the form (3.4). As in Case 1,
with the permutation π(·) having 1 as a ﬁxed point, if x1 does not appear in the
formula to be demonstrated then the 1-st column in the matrix on the left-hand
side of the system (3.4) contains all zeros.
To compute a in Step 1 of the showing protocol, S generates a random number
w1 ∈Zq, computes aS := gw1
1 , and sends aS to U. U generates l −t random
numbers, w0, w2, . . . , wl−t ∈Zq, and computes
a := aδ
S h−w0
l−t

i=2
gwi
π(i)
t
i=1
g
biw0−	l−t
j=2 αijwj
π(l−t+i)
.
To compute the l −t + 1 responses in Step 2, U sends V’s challenge c to
S. S computes rS := cx1 + w1 mod q, and sends rS to U. U computes
r1 := rSδ mod q, and computes the other l −t responses as speciﬁed in Step
2 of the protocol (P, V).
Again, the two claimed properties can easily be seen to hold.
Case 3. F is a formula connecting atomic subformulae by zero or more “OR” con-
nectives and no other connectives, in the form (3.6). Recall from Section 3.5
that P simulates all but one of the subformula demonstrations, even if multi-
ple subformulae hold true. The advantage of this is now clear: U needs the
assistance of S only for the one subformulae demonstration that cannot be
simulated, using the method of either Case 1 or Case 2.
Case 4. F is an arbitrary Boolean formula, in the form (3.7). Recall from Section 3.6
that V’s challenge is the same for all j subformula demonstrations. The advan-
tage of this is now clear: each of the j subformulae that must be demonstrated

6.3 SECURE SMARTCARD INTEGRATION
233
contains (at least) 1 subsubformulathat holds true, yet S need only perform one
execution of the Schnorr proof of knowledge to provide its assistance. Speciﬁ-
cally, U can use S’s response rS for each of the j subformula demonstrations,
using the method of either Case 1 or Case 2.
This completes the proof.
This construction works regardless of whether V is to receive a signed proof, a 4-
move zero-knowledge proof, or otherwise.
Note that U can precompute all the required exponentiations, except for the op-
eration of raising aS to the power δ in Case 2 of the proof. In case U does not know
the formula to be demonstrated until it communicates with V, it does not help for S
to provide its initial witness well before the start of the showing protocol execution.
In many practical applications δ will be small, and the burden of raising aS to the
power δ is insigniﬁcant. In PKIs where speed is of utmost importance, U may pre-
fer to avoid the exponentiation of aS altogether by simply multiplying c by δ before
passing it on to S.6 A drawback of the latter approach is that V cannot encode infor-
mation into its challenge that is intended for S, because U modiﬁes it before passing
it on. In Section 6.4 we will see why this may be undesirable.
The construction in Proposition 6.3.2 ensures not only that S need not provide
its assistance for each (sub)subformula, but also lays the foundation for U’s privacy.
Note, for example, that S does not need to know h, l, the attributes (x2, . . . , xl), or
the formula to be demonstrated. Section 6.4 will elaborate on this observation.
Security follows from the following result.
Proposition 6.3.3. If the Schnorr proof of knowledge is witness-hiding, then U in
the construction in Proposition 6.3.2 needs the assistance of S in the t-th formula
demonstration with respect to h, for any integer t.
In other words, the only way to get around S is to physically break its tamper-
resistance and extract x1. The formal proof of this security result proceeds by gener-
ating g2, . . . , gl all as random powers of g1. From a successful formula demonstration
in which U does not use the assistance of S, a DL-representation of h with respect
to (g1, . . . , gl) can be extracted. With overwhelming success probability this can be
converted into S’s secret key x1, resulting in a contradiction. (For signed proofs, we
need to assume the random oracle model.)
In a practical implementation one might care to ensure that g1 ̸= 1, but from a
theoretical viewpoint there is no need to exclude this possibility.
In case U is allowed to use the same h in arbitrarily many showing protocol
executions, a construction for S that offers weaker security than Proposition 6.3.3
6Extra operations may be needed to make this work. Consider for example a formula connecting two
atomic subformulae, both with a “NOT” connective, by an “AND” connective. With δ1 denoting the δ for
the ﬁrst subformula and δ2 that for the second, U computes γ such that cδ1 + γ = cδ2 and adjusts for γ
when computing a and its responses for the ﬁrst subformula.

234
SMARTCARD INTEGRATION
clearly will not do. The property that the assistance of S is needed after arbitrarily
many protocol executions is desirable, however, even in case of public keys for which
S refuses to further assist U once it has assisted in a predetermined number of show-
ing protocol executions. Namely, it allows S to use the same x1 as its contribution
to arbitrarily many different public keys, rather than having to use a new random x1
for each. (As we will see in Section 6.4.3, this approach also improves privacy.) S’s
share x1 can be regarded as its secret key, and hS as its “public” key.
An even stronger security result can be proved by letting S perform an execution
of Okamoto’s extension of the Schnorr proof of knowledge [288, page 36], or more
efﬁciently its optimization described in Section 2.4.3.
Proposition 6.3.4. Let l ≥2, and suppose that x1 is generated at random from Zq,
that x2 is the outcome of a random coin ﬂip, and that (x1, x2) is known to S but not
to U. Regardless of the distribution of (x3, . . . , xl), < S, U> can demonstrate to V
any Boolean formula of the form (3.7) in which x1 and x2 do not appear, in such a
manner that:
• The only task that S performs in each formula demonstration is one execu-
tion of the three-move proof of knowledge described in Section 2.4.3, in which
it proves knowledge to U of a DL-representation of gx1
1 gx2
2
with respect to
(g1, g2).
• The view of V when interacting with < S, U> is the same as it would be when
interacting with P.
The construction is readily apparent when studying the construction in the proof
of Proposition 6.3.2. Because S’s proof of knowledge is provably witness-hiding,
Proposition 6.3.3 can be proved under the weaker assumption that the DL function
used to implement the commitment to (x1, . . . , xl) is one-way. In a practical imple-
mentation one might care to ensure that g1, g2 ̸= 1, but from a theoretical viewpoint
there is no need to exclude this possibility.
In addition, it is possible to prove the following result.
Proposition 6.3.5. If the DL function is one-way, and S performs no more than poly-
logarithmically many executions of its protocol with U, then signed proofs of formula
demonstrations with respect to h are unforgeable by U in the random oracle model,
regardless of the distribution of (x3, . . . , xl).
The same should be true for the construction of Proposition 6.3.2, but it is unclear
how to prove this.
It is straightforward to combine our smartcard-enhanced showing protocols with
any of the DLREP-based certiﬁcate issuing protocols described in Chapter 4. In case
unlimited-show certiﬁcates are issued, S is not needed in the issuing protocol; the
CA simply looks up (or reconstructs) the secret key of S, and encodes that into the
certiﬁed key pair it issues. In the case of limited-show certiﬁcates, U in Step 2 of

6.3 SECURE SMARTCARD INTEGRATION
235
the issuing protocol must hash along its (master) initial witness (set) for the showing
protocol, and so S must provide (each) aS already at this stage. (Providing the initial
witnesses in an early stage is desirable anyway, to enable U to precompute as many
exponentiations as possible.) In addition, S must keep track of the number of times it
has cooperated in demonstrating a formula with respect to a limited-show certiﬁcate,
and refuse to cooperate more times than allowed. In practice, limiting the number of
times a certiﬁcate can be shown is trivial: for each of its initial witnesses, S responds
just once anyway.
Implementing our limited-show techniques in smartcards offers two security lay-
ers: showing a certiﬁcate more times than allowed is not possible without physically
extracting the smartcard’s secret key, and perpetrators (who manage to physically
extract the secret keys from their smartcards and then commit fraud) can be traced.
Thus, we get both the tamper-resistance protection and the software-only protection.
In the case of dynamic limited-show certiﬁcates (see Section 5.4.2), the correction
factors can all be determined by U, as desired.
Any linear sharing method other than the methods in Propositions 6.3.2 and 6.3.4
can be used, with the obvious modiﬁcations. Different sharing methods may each
have their own advantages, depending on other design aspects. For instance, when
using DLREP-based scheme I or II, it may be preferable to let (x1, . . . , xl−1) be
known to U and let xl be the sum of a secret key of S and the random blinding
factor α1 chosen by U in the issuing protocol; this enables the CA to encode l −1
attributes into each certiﬁed key pair,7 instead of only l −2. Another advantage is
that it is signiﬁcantly easier to guarantee that a secret key of a certiﬁed key pair is
generated secretly at random, and therefore that the device holder is the only one in
possession of the secret key; it does not matter if another party can guess or determine
the share of the secret key that is generated by one of the two devices, as long as the
other device generates (part of) its share at random. Consequently, the legal status of
digital signatures is easier to establish than in the software-only and smartcard-only
paradigms.
In general, for any or all i ∈{1, . . ., l}, one can set xi = αixiS + βixiU mod q,
for any αi, βi ∈Zq, where xiS is S’s share and xiU that of U.
When combining our smartcard-enhanced showing protocols with a secret-key
certiﬁcate issuing protocol, the delegation strategy is never an issue. The simple
software-only measures described in Section 5.1.2, if necessary at all, sufﬁce to en-
sure that U cannot abuse delegation in order to circumvent the assistance of S in the
showing protocol, even in those cases where delegation is not prevented but merely
made harmless.
It is worth noting that S can provide its assistance in alternative manners that dif-
fer from a Schnorr proof of knowledge or the related proofs of knowledge described
7When a limited-show certiﬁcate is shown more times than allowed, this sharing method does not
allow the CA to trace the perpetrator by computing the secret key of S. To achieve this property, one of
x1, . . . , xl−1 should be an identiﬁer.

236
SMARTCARD INTEGRATION
in Section 2.4.3. For instance, in the construction of Proposition 6.3.2 we may re-
place the veriﬁcation relation of the Schnorr proof of knowledge, grS
1
= hc
SaS, by
one that is closely related to that of the DSA signature scheme: grS
1
= haS
S ac
S. S
must then compute its response as rS := cw1 +x1aS mod q; it is easy to modify the
actions of U correspondingly.
6.3.2
Technique based on the RSAREP function
For commitments based on the RSAREP function, the direct analogue of Proposi-
tion 6.3.1 applies. Speciﬁcally, if (x1, . . . , xl+1) is shared between S and U in such
a manner that U cannot compute with non-negligible success probability an RSA-
representation of h := l
i=1 gxi
i xv
l+1 with respect to (g1, . . . , gl, v), then U cannot
demonstrate any Boolean formula without the assistance of S. The technique of let-
ting x1 be a secret key of S and gx1
1
its public key is not recommendable, though.8
An efﬁcient construction that achieves security for S is the following.
Proposition 6.3.6. Suppose that xl+1 is generated at random from Z
∗
n, and is known
to S but not to U. Regardless of the distribution of (x1, . . . , xl), < S, U> can demon-
strate to V any formula of the form (3.7), in such a manner that:
• The only task that S performs in each formula demonstration is one execution
of the Guillou-Quisquater proof of knowledge, in which it proves knowledge of
xl+1 to U.
• The view of V when interacting with < S, U> is the same as it would be when
interacting with P.
Proof. Let h = hShU, where hS = xv
l+1 and hU = l
i=1 gxi
i . To show how the
demonstration of a formula takes place, we consider four cases:
Case 1. F is an atomic formula consisting of zero or more “AND” connectives and
no other connectives, in the form (3.3). To compute a in Step 1 of the showing
protocol, S generates a random number wl+1 ∈Z
∗
n, computes aS := wv
l+1,
and sends aS to U. U generates l −t random numbers, w1, . . . , wl−t ∈Zv,
and computes
a := aS
l−t

i=1
gwi
π(i)
t
i=1
g
−	l−t
j=1 αijwj
π(l−t+i)
.
8The following proof of knowledge, proposed by Girault [185] (see also Poupard and Stern [310]),
is conjectured to be witness-hiding: S sends an initial witness gw1
1
to U, receives a challenge c, and
sends the response cx1 + w1 (no modular reduction) to U. Unfortunately, the response size in a practical
implementation is much larger than |v| bits.

6.3 SECURE SMARTCARD INTEGRATION
237
To compute the l −t + 1 responses in Step 2, U sends V’s challenge c to S. S
computes rS := xc
l+1wl+1, and sends rS to U. U sets
rl+1 := rS
l−t

j=1
(gπ(j)
t
i=1
g−αij
π(l−t+i))(cxπ(j)+wj)divv,
and computes the other l −t responses in the manner speciﬁed in Step 2 of the
protocol (P, V).
The task performed by S is exactly an execution of the Guillou-Quisquater
proof of knowledge, in which it proves knowledge of the v-th root of hS to U,
and the view of V is the same as it would be in (P, V).
Case 2. F is an atomic formula consisting of zero or more “AND” connectives, one
“NOT” connective, and no other connectives, in the form (3.4). It is easy to see
that S can provide its assistance in the same manner as in Case 1, and again
the two claimed properties are readily seen to hold.
Case 3. As in Case 3 of the proof of Proposition 6.3.2.
Case 4. As in Case 4 of the proof of Proposition 6.3.2.
This completes the proof.
This construction works regardless of whether V is to receive a signed proof, a 4-
move zero-knowledge proof, or otherwise.
Proposition 6.3.7. If the Guillou-Quisquater proof of knowledge is witness-hiding,
then U in the construction in Proposition 6.3.6 needs the assistance of S in the t-th
formula demonstration with respect to h, for any integer t.
Assuming that interactively issued Guillou-Quisquater signatures are unforge-
able, one can also prove that if S follows the protocol, then signed proofs of formula
demonstrations with respect to h are unforgeable by U, regardless of the distribution
of (x1, . . . , xl).
As with the DLREP-based variants, stronger provability can be achieved by let-
ting S perform an execution of Okamoto’s extension of the Guillou-Quisquater proof
of knowledge [288, page 39], or more efﬁciently its optimization described in Sec-
tion 2.4.4.
Proposition 6.3.8. Let l ≥1, and suppose that x1 is the outcome of a random coin
ﬂip, that xl+1 is generated at random from Z
∗
n, and that (x1, xl+1) is known to S but
not to U. Regardless of the distribution of (x2, . . . , xl), < S, U> can demonstrate
to V any Boolean formula of the form (3.7) in which x1 does not appear, in such a
manner that:

238
SMARTCARD INTEGRATION
• The only task that S performs in each formula demonstration is one execution
of the three-move proof of knowledge described in Section 2.4.4, in which it
proves knowledge to U of an RSA-representation of gx1
1 xv
l+1 with respect to
(g1, v).
• The view of V when interacting with < S, U> is the same as it would be when
interacting with P.
This time, Proposition 6.3.7 can be proved under the weaker assumption that the
RSA function used to implement the commitment is one-way. In addition, if the
RSA function is one-way and S performs no more than polylogarithmically many
executions of the protocol with U, signed proofs of formula demonstrations with
respect to h are unforgeable by U in the random oracle model, regardless of the
distribution of (x2, . . . , xl).
Other ways to share (x1, . . . , xl+1) can be used as well. In general, for any or
all i ∈{1, . . . , l}, one can use the linear sharing xi = αixiS + βixiS mod v and
the multiplicative sharing xl+1 = xαl+1
S
xβl+1
U
, for any αi, βi. A sharing method that
ﬁts well when combining the showing protocol with one of the RSA-based issuing
protocols described in Chapter 4 is to let (x1, . . . , xl) be the attributes of U, and let
xl+1 be the product of the secret key of S and the blinding factor α1 used by U in the
certiﬁcate issuing protocol (x1 may be either an identiﬁer of U or a part of the secret
key of S). Indeed, if the construction of Proposition 6.3.6 is used in combination with
an RSAREP-based issuing protocol, U for reason of privacy may not let S determine
the blinding factor α1.
The same considerations as described in Section 6.3.1 apply when combining
the showing protocol techniques with one of the issuing protocols in Chapter 3. In
particular, the delegation strategy is never an issue.
6.4
Privacy protection
In Section 6.1.1 we have seen that there are many ways in the smartcard-enhanced
setting to get around the privacy protections of the showing protocol. The techniques
that we will develop in this section build on top of those developed in the previous
section and enable U to prevent inﬂow, outﬂow, and even the development of com-
mon coin ﬂips. They also ensure that the leakage through the halting, timing, and
computation error channels is at most 1 bit in total; this is the best result achiev-
able. Furthermore, the smartcard cannot learn any information about the formulae
demonstrated, and cannot determine the number of encoded attributes or whether or
not certiﬁcates are limited-show; all it can learn is (an upper bound on) the number
of times its holder has engaged in a showing protocol execution.
All the privacy guarantees hold in the strongest possible sense, namely in the
presence of conspiring S, CA, and V that have unlimited computing resources and

6.4 PRIVACY PROTECTION
239
may establish secret information in an preparatory phase (e.g., a strategy for deviating
from the protocol and keys for authenticating and encrypting covert messages). We
also show how to tune our smartcard techniques to design systems for which one or
more of the privacy protections cannot be achieved, while guaranteeing that U can
verify and control any information exchanged by S and V.
The security accomplishments of the previous section are fully preserved by the
new techniques.
6.4.1
Inﬂow prevention
Inﬂow cannot occur in any of the certiﬁcate issuing protocols, since the smartcard
does not receive any messages from the CA. In the smartcard-enhanced showing
protocols in Section 6.3, the only possibility for inﬂow is V’s challenge, c. If the
demonstration is in the form of a zero-knowledge proof, the entire s-bit data channel
(as well as part of V’s commitment) can be used for inﬂow. Even in signed proofs,
there may be ample opportunity for V to cause inﬂow. In this case, V’s challenge is
the result of the application of a sufﬁciently strong one-way hash function to certain
data that may be at least somewhat under the control of V, such as a nonce (e.g.,
a random number or an estimate of the time and date) or a random number γ as in
Section 5.3. Any such data ﬁelds can be misused by V to encode a covert message,
possibly encrypted under a key known to S.
Proposition 6.4.1. In the construction of Proposition 6.3.2, U can prevent inﬂow at
the cost of essentially one additional exponentiation, which can be precomputed. S
must now accept any challenge in Zq, but the tasks of S and V remain unchanged in
all other respects.
Proof. As in the proof of Proposition 6.3.2, we distinguish four cases:
Case 1. F is an atomic formula consisting of zero or more “AND” connectives and
no other connectives, in the form (3.3). U proceeds as in Case 1 of the proof
of Proposition 6.3.2, but when computing a from aS it also multiplies in a
factor hβ
S, for a randomly chosen β ∈Zq. Furthermore, instead of sending
V’s challenge c to S, U sets cS := c + β mod q and sends cS to S. No further
changes are needed.
Case 2. F is an atomic formula consisting of zero or more “AND” connectives, one
“NOT” connective, and no other connectives, in the form (3.4). U proceeds as
in Case 2 of the proof of Proposition 6.3.2, but when computing a from aS it
also multiplies in a factor hβδ
S , for a randomly chosen β ∈Zq. Furthermore,
instead of sending V’s challenge c to S, U sets cS := c + β mod q and sends
cS to S. No further changes are needed.
Case 3. F is a formula connecting atomic subformulae by zero or more “OR” con-
nectives and no other connectives, in the form (3.6). U proceeds as in Case 3

240
SMARTCARD INTEGRATION
of the proof of Proposition 6.3.2, applying the modiﬁcation of either Case 1 or
Case 2.
Case 4. F is an arbitrary Boolean formula, in the form (3.7). U proceeds as in Case
4 of the proof of Proposition 6.3.2, with the restriction that it uses the same
random choice of β when forming a in each of the atomic subsubformulae
for which a genuine proof is due. This ensures that the same blinded form
of V’s challenge works for all subsubformulae demonstrations for which S’s
assistance is needed.
Because β is chosen at random, there can be no inﬂow.
This inﬂow prevention technique can also be applied to the construction in Proposi-
tion 6.3.4, and more generally to showing protocols based on any other kind of linear
sharing discussed in Section 6.3. It can also readily be adapted to prevent inﬂow in
any of the RSAREP-based smartcard-enhanced showing protocols in Section 6.3.2.
An even simpler technique to prevent inﬂow is to let U and V jointly develop V’s
challenge, in such a manner that it cannot contain covert message bits chosen by V.
This approach is not recommendable, though. It increases the number of message
exchanges between U and V, and makes it harder to encode meaningful data into
V’s challenge message (for the purpose of a signed proof). Also, the approach is
not always practical. For example, in the technique described in Section 5.3, V must
form a commitment γ; randomizing this requires the commitment function to be of a
number-theoreticnature (e.g., a DLREP or RSAREP function), which excludes much
faster alternatives. Another unique and important advantage of our inﬂow prevention
technique is that it destroys other data leakage channels as a by-product, as we will
see in Section 6.4.3.
6.4.2
Outﬂow prevention
Outﬂow cannot occur in any of the certiﬁcate issuing protocols, since the CA does
not receive any messages from S. In the showing protocols there is some opportunity
for outﬂow, through the response(s) provided by S. If V in the smartcard-enhanced
showing protocols in Section 6.3 knows S’s share of the representation of h, then S
can encode its outﬂow message in the “random” number(s) that it uses to compute
aS, possibly encrypted under a key of V or of the CA. For example, in the construc-
tion of Proposition 6.3.2 or 6.3.6, U demonstrates an atomic formula without “NOT”
connectives by passing S’s response rS on to V, enabling V to extract S’s covert
message by computing w1. In practice, V can guess S’s share with non-negligible
success probability if it knows the list of all smartcard secret keys. It could even de-
termine the correct secret key by verifying whether w1 satisﬁes a redundancy pattern
or the like.
This outﬂow method does not work if an atomic formula with a “NOT” connec-
tive is demonstrated, because U applies δ to rS before passing it on. According to

6.4 PRIVACY PROTECTION
241
Proposition 3.4.3, if xl (or, in the RSAREP-based protocol, U’s share of xl+1) is a
random number that does not occur in the formula, then the demonstration does not
leak any information about δ. S can still cause outﬂow if δ has smaller entropy than
a random number in Zq or Zv; this will be the case in most practical applications. In
fact, S can ﬁrst leak δ (without knowing it), by generating aS in a manner known to
V, and in subsequent demonstrations with the same h (if any) use the full response
channel for outﬂow.
Also, if the formula that is demonstrated is of the form (3.7), then V may learn in-
formation about which of the atomic subsubformula are valid. For each of the atomic
subsubformulae for which U requires S’s assistance, V sees either rS or rSδi for
some δi, and can check for correlations. (See the construction of Proposition 6.3.2.)
Proposition 6.4.2. Suppose that U generates xl at random from Zq and only demon-
strates formulae in which xl does not appear. In the construction of Proposition 6.3.2,
U can prevent outﬂow at the cost of essentially one additional exponentiation, which
can be precomputed. The tasks of S and V remain unchanged.
Proof. As in the proof of Proposition 6.3.2, we distinguish four cases:
Case 1. F is an atomic formula consisting of zero or more “AND” connectives and
no other connectives, in the form (3.3). U proceeds as in Case 1 of the proof
of Proposition 6.3.2, but when computing a from aS it also multiplies in a
factor gγ
1, for a randomly chosen γ ∈Zq. Furthermore, instead of passing
S’s response rS on to V, it sets r1 := rS + γ mod q. No further changes are
needed.
Case 2. F is an atomic formula consisting of zero or more “AND” connectives, one
“NOT” connective, and no other connectives, in the form (3.4). U proceeds as
in Case 2 of the proof of Proposition 6.3.2, but when computing a from aS it
also multiplies in a factor gγ
1, for a randomly chosen γ ∈Zq. Furthermore, U
computes r1 := rSδ + γ mod q. No further changes are needed.
Case 3. F is a formula connecting atomic subformulae by zero or more “OR” con-
nectives and no other connectives, in the form (3.6). U proceeds as in Case 3
of the proof of Proposition 6.3.2, applying the modiﬁcation of either Case 1 or
Case 2.
Case 4. F is an arbitrary Boolean formula, in the form (3.7). U proceeds as in Case
4 of the proof of Proposition 6.3.2. (For each atomic subsubformula for which
a genuine proof is due, U uses an independently generated γ.)
Because the γ’s are chosen at random, there can be no outﬂow.
Because S cannot cause outﬂow, accepting views of V when interacting with U
are perfectly indistinguishable from those that result when interacting with P in the
showing protocols in Chapter 3. This immediately leads to the following results.

242
SMARTCARD INTEGRATION
Corollary 6.4.3. If U follows the construction described in the proof of Proposi-
tion 6.4.2, then Proposition 3.6.1(c) holds, regardless of the behavior of S and any
joint initial set-up by S and V.
Corollary 6.4.4. If U follows the construction described in the proof of Proposi-
tion 6.4.2, then Proposition 3.6.2 and 3.6.3 both hold, regardless of the behavior of
S and any joint initial set-up by S and V.
In Section 6.3.1 we already saw that these security results are true assuming S
follows the protocol but U need not. In most applications both types of results are
desirable: S should prevent U and V from forging signed proofs and from making
them appear to pertain to formulae that do not apply, while U should prevent S and
V from framing its holder by forming a signed proof that U did not originate.
The same outﬂow prevention technique can be applied to the construction in
Proposition 6.3.4, and more generally to any other kind of linear sharing discussed in
Section 6.3. In cases where S provides more than one response to U, the latter must
independently randomize each of these responses, and the corresponding adjustments
must be made when forming a. It is also straightforward to apply the outﬂow preven-
tion technique to any of the RSAREP-based smartcard-enhanced showing protocols
discussed in Section 6.3.2.
Our outﬂow prevention technique actively prevents outﬂow by randomizing data
on the ﬂight. It is much more powerful than the approach of Chaum [103], which
can only detect outﬂow after the fact with low probability. It is also highly preferable
over Chaum’s [97, 109] other outﬂow prevention technique (also applied by Cramer
and Pedersen [122]), which in our situation would proceed by letting S and U form
aS in a mutually random manner by means of a coin ﬂipping protocol. This would
seriously degrade the communication and computation complexity, and would pre-
vent the optimization that will be introduced in Section 6.5.1. Another important
advantage of our outﬂow prevention technique is that other data leakage channels are
destroyed as a by-product, as we will now show.
6.4.3
Prevention of other data leakage channels
Inﬂow and outﬂow prevention are orthogonal measures. U can prevent both inﬂow
and outﬂow by randomizing V’s challenge c as well as any responses provided by S,
and multiplying the corresponding expressions into a when forming aS. Assuming
simultaneous repeated squaring, the computational cost for demonstrating an atomic
formula is approximately one exponentiation that can be precomputed.
Our issuing and showing protocols in Chapters 3 and 4 by their very design
greatly reduce the scope for leakage of covert messages: no interaction takes place
between S and the CA, and the interaction between S and V is minimal. What’s
more, the application of our inﬂow and outﬂow prevention techniques is so power-
ful that any other data leakage channels in the issuing and showing protocols are
destroyed as a by-product:

6.4 PRIVACY PROTECTION
243
• The smartcard learns virtually nothing:
– S cannot learn U’s attributes, nor how many are encoded by the CA,
regardless of the behavior of V. S cannot even learn the gi’s that it does
not use itself, unless they are known in advance. (In Section 6.5.1 we
will describe an optimization in which S merely learns q and a secret
seed value to generate pseudorandom numbers.)
– When interacting with U, S cannot learn any information about the for-
mula that is demonstrated, regardless of the behavior of V. This holds
even if U issues a signed proof and a unique description of the formula
is hashed along when computing V’s challenge. S cannot even learn the
message that it helps sign.
– S cannot learn whether it is assisting in showing a limited-show certiﬁ-
cate or an unlimited-show certiﬁcate, regardless of the behavior of V,
assuming S in both cases provides its initial witness in advance (e.g.,
during the corresponding issuing protocol). (Note, though, that U cannot
show a limited-show certiﬁcate more times than allowed, because S uses
a new random initial witness in each showing protocol execution.) Like-
wise, S cannot decide whether multiple invocations of its assistance are
for the purpose of showing the same certiﬁcate or different certiﬁcates.
– S cannot even learn any information on the number of certiﬁcates issued
to U, since U can query S even if it has not been issued any certiﬁcates.
(This practice is not recommendable when limited-show certiﬁcates rep-
resent value, such as in an electronic cash system.)
In other words, all that S can learn about the actions of its holder is an upper
bound on the number of showing protocol executions.
• The veriﬁer learns virtually nothing either (beyond the status of the formulae
demonstrated):
– V cannot decide from its accepting views in protocol executions whether
or not P is assisted by a smartcard, regardless of the behavior of S. In
PKIs in which certiﬁcate applicants may but need not hold a smartcard,
this reduces the scope for discrimination and improves privacy.
– The computation error channel is destroyed as a by-product of our out-
ﬂow prevention technique: S cannot leak more than 1 bit. Therefore, U
may skip the veriﬁcation of S’s response(s), thereby circumventing the
need for an exponentiation that cannot be precomputed. This holds even
if S provides more than one response to U’s challenge: the independent
randomization applied by U prevents V from learning any information
about how many or which of U’s responses were formed using an incor-
rect response supplied by S.

244
SMARTCARD INTEGRATION
– Owing to the minimal interaction required in our smartcard-enhanced
protocols, S can leak at most 1 bit using the halting channel, assuming U
does not engage in a showing protocol execution until after it has obtained
aS. This holds even if U interactively issues a signed proof or performs
a 4-move zero-knowledge demonstration. No bits at all can be leaked
when U non-interactively issues a signed proof to V.
– To prevent the timing channel, U should time the delay between incoming
and outgoing messages exchanged between the S and the other device.
If the delay exceeds a reasonable time bound, U aborts the protocol exe-
cution; otherwise it ﬁrst adds its own delay to ensure that the total delay
time is approximately constant. What makes this approach truly practical
for the DLREP-based protocols is that S and V need never perform any
exponentiations that cannot be precomputed. (An upper bound on com-
putation time will be much looser for time-consuming operations, and
increases the delay that must be added.) As with the halting channel, the
minimal interaction in our protocols ensures that at most 1 bit can leak.
It is easy to see that S can leak at most 1 bit in total to V via the halting channel,
the computation error channel, and the timing channel. This is the best result
that can be achieved, since S can always cause a protocol execution to abort
by not providing its response(s) to U. In practice the maximum leakage will
be signiﬁcantly less than 1 bit, since there will be other possible causes for
incorrect responses to V or protocol abortion, such as incorrect behavior by
U or a communication failure. In fact, any attempt by S to leak bits through
the halting channel or the computation error channel is futile, since it leaves V
unconvinced of the formula demonstrated.
Even common coin ﬂips are prevented as a by-product. It is not hard to prove that
if U follows the issuing and showing protocols, then the views of S are statistically
independent from the accepting views of the 
CA and V, regardless of the formulae
demonstrated by U. Thus, physical access to the contents of a smartcard does not
help the 
CA in cooperation with all veriﬁers to retroactively trace and link communi-
cations and transactions; all that can be learned is what certiﬁcate holders willingly
disclose in executions of the showing protocol. More importantly, the card cannot
leak information even if it could send out radio signals.
In general, however, it is impossible without breaking the tamper-resistance to
verify that a smartcard does not have a sense of time, place, temperature, sound,
or anything else that can be exploited by the CA once it gains physical access to
the contents of the card. For instance, ultra-thin batteries that meet the required
physical dimensions for smartcards are expected to become widely available within
a few years. In light of this, a much more effective approach is for certiﬁcate holders
to never return their smartcards to the CA (or anyone else) in the ﬁrst place. This
simple measure protects privacy in the strongest possible manner. In Section 6.5.1

6.4 PRIVACY PROTECTION
245
we will show that our DLREP-based issuing and showing protocols can be efﬁciently
implemented using low-cost smartcards without a cryptographic coprocessor. These
cards might as well be destroyed, archived, or thrown away by their holders once
their physical security has become outdated or their expiry date has been reached;
there are no valid ﬁnancial excuses for the CA to demand them returned.
An alternative is to enable cardholders to zeroize the contents of their smartcards
before returning them. By feeding S a (pseudo)randomly generated ﬁle as large as
S’s memory, and requiring S to output the ﬁle, U can force S to overwrite its memory
contents. S can be programmed to perform this action only if U also provides it with
a MAC of the CA on a hash of the random ﬁle. Forensic experts may still be able
to reconstruct the previous memory contents, though, and sting operations are not
prevented (some cards may be given more memory than publicly speciﬁed).
We will now show that there are other persuasive reasons to prefer the model of
not returning cards over the prevention of common coin ﬂips.
6.4.4
Restricting the level of privacy protection
As we have seen in Section 6.2.2, U’s ability to prevent S and V from developing
common coin ﬂips can be misused by an anonymous extortioner. When certiﬁcates
represent signiﬁcant value, it is in U’s own interest that this level of privacy cannot
be achieved. In case an extortioner strikes, this would enable U to ﬁnd out how and
where the extorted certiﬁcates have been misused, by comparing the common coin
ﬂips stored by the smartcard with the views of all the veriﬁers; in case the CA stores
a copy of the relevant parts of all the showing protocol transcripts, this task is easy to
accomplish with the cooperation of the CA. In an electronic coin system, for instance,
this tracing ability strongly discourages the extortioner from making a large payment
to his or her own account or to that of an accomplice; the extortioner will have little
choice but to spend the money on goods or services that he or she can receive while
remaining untraceable.
Even more effectively, by designing the showing protocol in such a manner that
the veriﬁer’s challenge contains a veriﬁer identiﬁer that cannot be hidden from S, the
victim of an extortioner can determine in real time to which veriﬁer(s) the extortioner
is showing his or her certiﬁcates, since the identiﬁers must pass in unencrypted form
through the user-controlled computer. This enables the victim to immediately notify
the veriﬁer that a fraud is going on, and so it will be very hard for the extortioner to
proﬁt from his or her crime. Veriﬁer traceability by the certiﬁcate holder is desirable
anyway, for many reasons: the certiﬁcate may need to obtain a digital receipt from
the veriﬁer in the showing protocol; the certiﬁcate holder may need the ability to
complain about bad goods or services, or at least to warn others about the behavior
of an unscrupulous service provider or to have an investigation instigated; and, absent
veriﬁer traceability it is impossible to recover (if needed) should the connection with
the veriﬁer become permanently lost during the showing protocol execution. It is

246
SMARTCARD INTEGRATION
important to note that in this approach only the originator of the showing protocol
execution has the power to trace the veriﬁer. To prevent smartcards from locking
their holders out of legitimate transactions to designated veriﬁers, smartcards should
learn only a salted hash or an encryption of the veriﬁer’s identity.
In high-risk PKIs, this approach may be exploited to give law enforcement the
ability to trace the actions of a designated cardholder. Requirements should be in
place to ensure that a court order or search warrant must be presented to the desig-
nated cardholder, so that the cardholder can challenge the investigation. Although a
certiﬁcate holder can falsely claim that his or her smartcard has been lost, broken, or
stolen, this does not invalidate the approach. To most honest certiﬁcate applicants,
the inconvenience of having to obtain a new smartcard to retrieve new certiﬁcates is
sufﬁcient reason to refrain from false claims. Furthermore, the police can resort to
traditional investigative techniques to locate a card claimed to have been lost, and
to forensic methods to retrieve the memory contents of a smartcard that has been
wrecked. Any audit logs by the user-controlled computer could be examined as well.
Also, if the CA requires timely reporting of the loss or theft of smartcards, it would
be suspect if an individual claims to have lost control over his or her smartcard right
after a court order was presented.
It may be cumbersome for law enforcement to make a physical presence to gain
access to the contents of a device. Moreover, physical access takes away the device
holder’s control over which parts of the transaction log are being inspected. It is
possible to give authorized third parties the ability to remotely (over a network) query
the contents of the smartcards of designated certiﬁcate holders. When presented
with a digitally signed electronic search warrant (or court order) demanding that
a part of the transaction log be disclosed (e.g., all transactions above a speciﬁed
threshold, all the transactions to a designated organizations, or the ten most recent
transactions), the user’s computer checks the warrant’s authenticity and contents,
passes the query on to the smartcard, receives the requested information from the
smartcard (authenticated using a MAC or a digital signature), checks the supplied
data against its own copy of the transaction log, and passes it onward to the requesting
party only if the veriﬁcation holds.9
More generally, there may be a legitimate need for S to know information other
than (just) the veriﬁer’s identity, to decide whether or not to assist U in performing the
showing protocol execution. For instance, S may need to know (part of) the formula
demonstrated, (part of) the message it is helping to sign, or the type of veriﬁer to
which a signed proof is to be issued. To accommodate these and other legitimate
needs for restricting the level of privacy, we reject the goal of preventing common
coin ﬂips and instead open up (in a controlled manner) one communication channel
from V to S: V’s challenge message, c. To prevent U from altering c before passing
it on to S, we have S form by itself the challenge message it will respond to, by
9MAC outﬂow can be prevented by using commitments, while randomization or deterministic signa-
ture generation sufﬁce for digital signatures.

6.5 OTHER TECHNIQUES
247
applying a sufﬁciently strong (publicly known) one-way hash function to the data
provided by U. For example, if U is to issue a signed proof to V, the protocol (S,
U) should be such that S computes c by applying Hi(·) to data provided by U. This
forces U to provide (h, a, F, m) and any other data to be included in the hash.
To guarantee that S learns only the minimum information needed, we use chal-
lenge semantics based on hash structures. If, for example, S should be able to learn
only the message m in a signed proof, V’s challenge message could be set equal to
Hi(Fi(h, a, F), m), where F(·) and H(·) may be the same hash function. When S
provides responses only to challenges c formed by itself by applying Hi(·) to data
provided by U, the latter is forced to provide at least Fi(h, a, F) and m to S. To
improve privacy, U may hash along a random salt when applying Fi(·). (Formally,
F(·) should be a commitment function that unconditionally hides the data; a DLREP
function can be used.) More generally, c can be deﬁned as an arbitrary structure of
nested hashes of data ﬁelds, and the role of S in forming c can be arbitrarily deﬁned
as well. In case of a dispute, the hash structure can be opened selectively.
Note that U cannot block a message transfer from V to S without blocking the
entire showing protocol execution. On the other hand, U can unconditionally pre-
vent inﬂow and outﬂow, and can at all times see and control the common coin ﬂips
developed by V and S.
Another beneﬁt of rejecting the goal of preventing coin ﬂips is related to attacks
on U. If S sees the message it is helping to sign and shows this on a display of its
own, and waits for its holder to accord its next step through an on-board key pad, then
a virus or a Trojan horse attack on U cannot trick S into signing a false message.
This technique of combining inﬂow and outﬂow protection with “controlled com-
mon coin ﬂips” sufﬁces to accommodate most legitimate needs to reduce the level of
privacy attainable. It does not, however, enable the veriﬁer in the showing protocol
to distinguish whether or not the prover’s demonstration is conducted using the assis-
tance of a smartcard. This capability may be needed in case of high-risk limited-show
certiﬁcates for which the techniques in Section 5.5 to trace and contain fraud offer
inadequate security. One way to enable this capability is for the CA to encode into
each certiﬁed key pair a “policy attribute” that indicates at least whether or not the
veriﬁer should resort to online certiﬁcate authorization. This policy attribute must
always be disclosed when performing a demonstration. (Any other data that must
always be disclosed, such as a certiﬁcate expiration date, can be encoded into the
same attribute.)
6.5
Other techniques
In this section we describe how to implement our DLREP-based techniques using
low-cost smartcards. We also design a protocol that enables certiﬁcate holders to re-
turn to the CA any retrieved certiﬁcates that have not yet been shown. Furthermore,

248
SMARTCARD INTEGRATION
we show how to discourage certiﬁcate holders from using their certiﬁcates to help
remote parties gain access to services for which they do not hold the proper certiﬁ-
cates themselves. Finally, we design secure bearer certiﬁcates with optimal privacy
and address some loose ends.
6.5.1
Implementation in low-cost smartcards
The cheapest and most widely available smartcards contain a simple 8-bit micro-
processor that can perform a DES operation in software in about 4 milliseconds. A
single modular multiplication as needed in public-key cryptographic operations takes
many minutes, and may not even ﬁt in memory. (RAM is typically between 124 and
1024 bytes, EEPROM between 1 and 16 kilobytes, and ROM between 4 and 16 kilo-
bytes.) Even can today’s fastest coprocessor smartcards cannot compute more than
3 full RSA exponentiations per second, assuming a 1024-bit modulus and no use of
the Chinese Remainder Theorem.10
Moreover, cryptographic coprocessors decrease reliability, are more vulnerable
to timing attacks (see Lenoir [245]), take up precious space, and add about three to
ﬁve dollars to the cost of each smartcard.
When using our DLREP-based techniques, two noteworthy optimizations are
available:
• An elliptic curve implementation over a ﬁeld of the form GF2m, with m ≈
160, guarantees that a conventional 8-bit smartcard microprocessor can rapidly
perform a high-strength public-key exponentiation in Gq. For instance, the
Schlumberger Multiﬂex smartcard used in the ﬁrst smartcard-based pilot of
SET [257] can compute an elliptic-curve DSA signature in exactly one sec-
ond, using a 163-bit modulus; this chip contains an 8-bit Motorola chip with
240 bytes of RAM, 8 kilobytes of EEPROM, and 12 kilobytes of ROM. Since
the Schnorr proof of knowledge requires virtually the same operations as the
DSA scheme, the same performance in a low-cost smartcard can be achieved
when using our techniques. For details on implementing elliptic curves in
smartcards, see Certicom [85].
• The bulk of the workload of S can be shifted to the CA, by having the latter
instead of the former provide aS to U; this removes the need for S to perform
any exponentiations. The CA can provide aS during the execution of the issu-
ing protocol in which it issues the certiﬁed key pair that uses aS. Alternatively,
the CA provides a great many aS-values at once to U, possibly whenever the
latter makes a request. The only remaining task for S in an execution of the
showing protocol is to compute a linear relation over Zq and perhaps a few
10In November 1999, Bull and other major hardware manufacturers demonstrated a smartcard that can
perform the exponentiation in less than 350 milli-seconds. Their design features a RISC 32-bit processor,
64 kilobytes of EEPROM, 96 kilobytes of ROM, and 4 kilobytes of RAM.

6.5 OTHER TECHNIQUES
249
hashes. Even the cheapest of 8-bit smartcards can compute dozens of such re-
sponses within a second. Note that this optimization does not require the use
of elliptic curves.
To implement the latter optimization, the CA and S must share the list of random
numbers that S will deploy. In practice these numbers may be generated in a pseu-
dorandom fashion from a seed value that is known to both S and the CA, which the
CA may form by diversifying a smartcard identiﬁer using a master key. (The use
of pseudorandom numbers is recommendable also to avoid physical attacks on noise
generators.) The preferred method of generating pseudorandom numbers depends on
certain characteristics of the certiﬁcates:
• In case certiﬁcates are shown in the order in which they are retrieved, S can
regenerate in constant time and space its contributions to the secret keys of up
to 2t certiﬁed key pairs by storing merely a t-bit index for the pseudorandom
number generator, and incrementing this upon each successful showing of a
certiﬁcate. The DSS [277, Appendix 3] speciﬁes two algorithms for generat-
ing pseudorandom numbers in Zq for use with the DSA. Both algorithms feed
a secret seed value and the previous pseudorandom number into a one-way
function in order to derive the next pseudorandom number. Since U in a prac-
tical implementation need merely store some 40 bytes per certiﬁed key pair,
regardless of the number of attributes encoded into it, the user’s computer and
the smartcard can retrieve and store a number of certiﬁed key pairs that is, for
all practical purposes, virtually unlimited.
• In PKIs where the showing order of limited-show certiﬁcates may be unrelated
to the certiﬁcate retrieval order, it is preferable to generate each new pseudo-
random number by feeding the seed value and an increment of an index value
to a sufﬁciently strong one-way hash function, to facilitate random addressing.
S must keep track of all the indices for which it has already provided its assis-
tance, because it may not respond to two different challenges using the same
initial witness. The indices may be known to U, and form a convenient manner
for U to query S in the showing protocol: the CA in the issuing protocol can
provide U with the indices used to generate the pseudorandom contributions
of S, and when U needs to show a certiﬁcate it can send S the corresponding
index in order to have S regenerate its random contribution to the secret key of
the appropriate certiﬁed key pair.
Having the CA instead of S provide aS to U also allows U’s holder to leave S at a
safe place during certiﬁcate retrieval, for improved protection against theft. Another
advantage is that the same smartcard can be used for different PKIs, in fact even
for applications not known at the time of card issuance. Hereto each CA should
use the same q and preferably a different g1, and the pseudorandom numbers of

250
SMARTCARD INTEGRATION
each smartcard should be generated by feeding an additional CA identiﬁer into the
pseudorandom generator.
Card performance can be pushed to the limit by either speeding up or circum-
venting the memory-intensive reduction modulo q that must be performed by S. To
achieve the former, one should use a modulus q of the form 2t ± B, for small B. To
circumvent the modular reduction altogether, a technique due to Shamir [347] can be
applied. The idea is to replace the computation of cx1 + w1 mod q by the computa-
tion of cx1 + w1 + tq, for t chosen at random from a suitable range; the result can be
computed and output one byte after another by using a double convolution process.
6.5.2
Returning certiﬁcates
According to Proposition 6.3.1, the loss or theft of a smartcard prevents its holder
from showing his or her certiﬁcates, in spite of any access control mechanism that
may prevent others from operating the smartcard. In many PKIs it is desirable that
any previously retrieved certiﬁcates that have not yet been shown can be returned
to CA. The existence of a certiﬁcate return protocol would give the victims of lost,
stolen, or crashed smartcards the opportunity to recover value that might be asso-
ciated with their certiﬁcates. It also enables the CA to publish the certiﬁcates on
an update of its CRL, and in this manner prevents attackers able to get around the
smartcard access control mechanism from using the certiﬁed key pairs.
A return protocol may also be useful in the unlikely event that the cryptography
is broken (see Section 5.5.5); since the CA can keep a positive list at certiﬁcate is-
suing time, even an adversary with unlimited computing power cannot return forged
certiﬁcates. (In this particular case, it is recommended that each certiﬁcate appli-
cant initially establish a secret key or a one-time pad with the CA, for the purpose of
symmetric encryption and authentication of data sent in the return protocol.)
Furthermore, a return protocol is useful to resolve permanently lost connections
between a certiﬁcate holder and a veriﬁer; if the transcripts of all the showing pro-
tocol executions are deposited with the CA, fault tolerance can be implemented by
returning the certiﬁcate to the CA so that the latter can ﬁnd out whether the veriﬁer
has received the certiﬁcate.
Other uses of a certiﬁcate return protocol include: to exchange expired certiﬁcates
for fresh ones; to cancel a transaction that has already been performed; and, to have
recourse to the CA if a smartcard enters into suspension mode or produces an error.
Returning a certiﬁcate to the CA is easy, assuming certiﬁcate holders keep backup
copies of their certiﬁed public keys (and, for secret-key certiﬁcates, their share of
the corresponding secret keys). Backups can be stored conveniently on the user-
controlled computer, on a ﬂoppy disc, in encrypted form in a cyberspace “strongbox,”
or in any other manner deemed secure by the certiﬁcate holder.
To perform the actual return of a certiﬁcate, U transmits the certiﬁed public key to
the CA. In case of a secret-key certiﬁcate, U must also provide the CA with sufﬁcient

6.5 OTHER TECHNIQUES
251
information to enable it to determine S’s secret key, and must prove knowledge of
its share of the secret key of the certiﬁed key pair. To return a certiﬁcate obtained
using DLREP-based scheme I, for instance, U sends h′, (c′
0, r′
0) to the CA and proves
knowledge of a DL-representation of h′/hS. In the proof of knowledge, U may
selectively disclose properties about the encoded attributes, as in an execution of the
showing protocol.
Note that this return protocol is software-only: it does not involve the cooperation
of the smartcard. This is desirable not only to cope with loss, theft, and destruction
of smartcards, but also for certiﬁcate holders who have never been issued a smartcard
at all.
It is desirable, both for secret-key and for public-key certiﬁcates, that U always
provide the CA with a signed proof on a message stating the reason it is returning a
certiﬁcate. If the CA stores this signed message in a database, any disputes that may
arise later on can be resolved.
In case U is to be reimbursed in some way or another, and executions of the
showing protocol need not be authorized online, the CA may prefer to delay reim-
bursement until it is certain that the returned certiﬁcate has not been shown.
Care must be taken that a thief cannot return the certiﬁcate data stored on stolen
backups for his or her own beneﬁt. In an off-line electronic coin system, for instance,
the CA should best redeem an account holder for a returned coin by crediting his or
her account.
6.5.3
How to discourage remote lending
In Section 5.5.2 we presented software-only measures to discourage lending of cer-
tiﬁed key pairs. For stronger protection, certiﬁcate holders should be required to use
smartcards with a biometric access control mechanism. In a face-to-face situation the
veriﬁer can visually inspect that the biometric data is properly entered. In general,
a liveness detection mechanism is needed to prevent unauthorized cardholders from
using biometric templates; a cardholder’s ﬁngerprints, for instance, may be all over
his or her smartcard. (The same measure also protects against loss and theft.)
This leaves open the possibility of remote lending. Here, the holder of a cer-
tiﬁed key pair provides the “borrower” with the certiﬁed public key, and assists in
the showing protocol execution by providing the required responses. The lender can
provide his or her assistance over a radio link or a network such as the Internet. Re-
mote lending is similar to the anonymous extortion attack described in Section 6.2.2,
with the difference that the borrower voluntarily cooperates with the lender and may
not be interested in hiding his or her identity and transaction details from the lender.
(Remote lending differs also from the “maﬁa fraud” studied ﬁrst by Desmedt [134];
in the latter, the prover is not aware that the protocol execution is being relayed.)
In communications and transactions that are not face-to-face, remote lending can-
not be prevented, regardless of whether privacy-protecting certiﬁcates or fully trace-

252
SMARTCARD INTEGRATION
able identity certiﬁcates are used. Indeed, the “lender” might as well perform the
entire showing protocol execution and simply relay the provided service or goods to
the “borrower.” In many PKIs this is not considered a security problem, especially
not if lending occurs only incidentally; it may even be a feature. In PKIs where
large-scale lending is to be discouraged, the CA could issue limited-show certiﬁcates
and establish one account per certiﬁcate applicant (see Section 5.2.1). Large-scale
lenders will then be exposed because of their abnormal demand for certiﬁcates. An-
other measure is to charge a fee per certiﬁcate issued, so that a large-scale lender
faces the problem of being compensated for the cost of his or her service without
risking exposure.11 A further measure to discourage large-scale lending is to pro-
gram each smartcard in such a manner that it will only respond to a challenge when
its biometric access control mechanism detects the live presence of the cardholder.
In face-to-face situations, additional measures are available. The CA could en-
code biometric characteristics and apply the measure described in Section 5.5.2.
Even better, remote lending can be prevented altogether by having V bound its dis-
tance to the true certiﬁcate holder. The idea is for S and V in the showing protocol to
rapidly exchange a series of random bits. Each bit of S is to be sent out immediately
after receiving a bit from V. To ensure that S cannot simply send out its i-th bit
before receiving the i-th bit of V, the i-th bit of S must depend on the i-th bit of V.
One way to accomplish this is to require S to send bits chosen in such a manner that
the exclusive-or of these bits and those provided by V equals a previously established
binary string. After the rapid bit exchange has taken place, S’s binary string must be
authenticated using the secret key of the certiﬁed key pair; one way to accomplish
this is to hash along the binary string when forming V’s challenge. V accepts if and
only if the authentication is correct and its distance to the smartcard is sufﬁciently
small. To compute an upper bound on the distance, V takes the maximum of the
delay times between sending out its i-th bit and receiving the i-th bit of S; this en-
sures that the cheating probability decreases exponentially fast in the number of bits
exchanged. What makes this approach practical is that today’s electronics can easily
handle timings of a few nanoseconds, and light can travel only about 30cm during
one nanosecond. Even the timing between two consecutive periods of a 50 MgHz
clock allows light to travel only three meters and back. It is easy to integrate this
distance bounding technique with the techniques described in Sections 6.3 and 6.4.
The smartcard techniques in this section may be used in addition to the software-
only techniques in Section 5.5.2, rather than serving as a replacement.
6.5.4
Bearer certiﬁcates
As we have seen in Section 5.5.1, strong fraud prevention for software-only bearer
certiﬁcates requires online clearing. The closest we can come to realizing the digital
11A business model relying on certiﬁcate prepayment has other advantages as well in many circum-
stances, and is naturally based on the issuance of limited-show certiﬁcates.

6.5 OTHER TECHNIQUES
253
equivalent of paper-based bearer certiﬁcates is to implement digital certiﬁcates using
smartcards, to ensure that each certiﬁcate can be at only one place at any moment in
time.
Consider the following design of a digital bearer certiﬁcate system. The CA en-
dows each smartcard with a unique card identiﬁer and a secret key (possibly derived
by diversifying the card identiﬁer using a master secret key). Anyone can purchase
one or more of these smartcards via a myriad of retail outlets, without needing to
identify. Each smartcard can be used to open an anonymous account with the CA,
by communicating with the CA in cyberspace. To enable the CA to associate the
secret key of a smartcard with the account opened, the user’s computer sends the
card identiﬁer to the CA, possibly together with a MAC of the smartcard on a chal-
lenge message of the CA. The CA issues only limited-show certiﬁcates, and encodes
into each certiﬁed key pair the secret key of the applicant’s smartcard. Retrieval
and showing of digital certiﬁcates take place using the techniques described in Sec-
tions 6.3 and 6.4. The additional option available to smartcard holders is to sell, lend,
or otherwise transfer their cards to others. For protection against theft, smartcards
should have an access control mechanism (based on a PIN, a password, or a biomet-
ric) that can be changed only when authorized by the current holder. Veriﬁers may
accept digital certiﬁcates without needing online authorization by the CA, but are
required to deposit transcripts of their showing protocol executions. If a smartcard
holder manages to physically extract the card’s secret key and show certiﬁcates more
times than allowed, the CA can compute the smartcard identiﬁer, close the corre-
sponding account, and blacklist the certiﬁcates using its CRL. This ensures that the
perpetrator can continue only by physically compromising another smartcard.
This design offers adequate security assuming that the average cost of physically
extracting the secret key from a smartcard exceeds the expected proﬁt that can be
made until the CRL update has been distributed and the account closed. At the same
time, the privacy of users is maximally protected: their showing protocol executions
are untraceable and unlinkable, and their certiﬁcate retrievals anonymous.
In PKIs with high-risk certiﬁcates, it is preferable that the perpetrators them-
selves can be traced, to stop them from opening new accounts and perhaps also to
recover some of the losses. Hereto our smartcard techniques should be combined
with the personalization techniques described in Section 5.5. This does not preclude
the possibility of anonymous withdrawal of certiﬁcates, as we have seen.
6.5.5
Loose ends
To prevent organizations and other veriﬁers from discriminating against certiﬁcate
holders who do not disclose their built-in identiﬁer, the secret key of a smartcard
should serve as the cardholder’s identiﬁer. The link between the cardholder’s identity
and the smartcard’s identiﬁer can be made either when the card is issued or when the
account is opened. With this approach, the privacy interests of the cardholder and the

254
SMARTCARD INTEGRATION
security interests of the CA are perfectly aligned; identity bartering is out, because
cardholders cannot disclose the identiﬁers that have been encoded into their certiﬁed
key pairs.
In some situations it may be desirable that certiﬁcate holders can demonstrate
not to be the originator of a transaction. The technique described in Section 5.5.1 to
accomplish this is not in conﬂict with that of the previous paragraph. Namely, it is
possible for < S, U> to demonstrate that the secret key of S is not equal to the secret
key of one or more perpetrator smartcards. Consider by way of example the setting of
Proposition 6.3.2. With h := l
i=1 gxi
i , the goal is for U (with the assistance of S) to
demonstrate that x1 ̸= y mod q, for some y ∈Zq, without U learning the secret key
x1 of S. Hereto S demonstrates to U that x1 ̸= y mod q by means of our standard
interactive showing protocol for atomic formulae with a “NOT” connective: S sends
aS := (gy
1/hS)w1 to U, receives V’s challenge c from U, and responds by sending
r := cδ + w1 mod q, where δ := 1/(y −x1) mod q. It is not hard to see that U can
perform its part of the protocol with respect to V if U would know gw1
2 , . . . , gw1
l . U
would then form
a := aS(gy
1/hS)γ1
l
i=2

(gw1
i )wigγi
i

for random w2, . . . , wl ∈Zq and random γ1, . . . , γl ∈Zq, and compute r1 :=
r + γ1 mod q and ri := rwi + γi mod q, for all i ∈{2, . . . , l}. (If desired, U can
be allowed to blind c before passing it on, as detailed in Section 6.4.2.) Having S
compute and provide gw1
2 , . . . , gw1
l
to U would result in serious overhead to S, but as
with the technique in Section 6.5.1 this burden can be moved to the CA. Alternatively,
assuming that demonstrating a property of S’s secret key is an exceptional task, S
could store a precomputed tuple (w1, gw1
1 , . . . , gw1
l ) into its memory. Knowledge of
gw1
2 , . . . , gw1
l
is believed to be of no help in attacking the protocol performed by S;
these numbers are essentially Difﬁe-Hellman keys.
The technique described in Section 5.5.3 can be applied straightforwardly to
achieve non-repudiation. For example, I can be formed as the sum of the secret
key of S and a random secret of U. Alternatively, non-repudiation can be based
on the tamper-resistance of the smartcard: if smartcards are tamper-evident, then a
smartcard holder can prove his or her innocence by showing that the smartcard has
not been tampered with in an attempt to physically extract the secret key.
6.6
Bibliographic notes
The smartcard techniques in Sections 6.3 and 6.4 originate from Brands [54]. The
presentation ﬁlls in some details that were previously only hinted at, and the for-
mal statements of security and their proofs appear here for the ﬁrst time.
Prior
to Brands [54], Brands [46, 48] applied a special case of the smartcard techniques

6.6 BIBLIOGRAPHIC NOTES
255
for the purpose of designing a secure off-line electronic coin system; coin payment
requires the demonstration of the formula TRUE, and the static one-show blind-
ing technique ensures that the bank can trace a doublespender who has defeated the
tamper-resistance of his or her smartcard. In a variation [46, 58], the bank encodes
an additional attribute into each coin to specify its denomination and expiry date.
The method in Section 6.5.1 for avoiding exponentiation by the smartcard is due
to Brands [57]. Naccache, M’Ra¨ıhi, Vaudenay and Raphaeli [271, Section 6] pro-
posed a similar method in a different context (“use-and-throw coupons” for smart-
cards).
The return protocol in Section 6.5.2 is similar to a protocol designed by Pﬁtzmann
and Waidner [304] for the purpose of loss-tolerance in the electronic coin system of
Brands [48]. New is the observation that certiﬁcate return is useful for many other
purposes.
The distance bounding technique in Section 6.5.3 originates from Chaum [97],
with improvements by Brands and Chaum [59].
Finally, the technique in Section 6.5.4 is based on Brands [54].


Epilogue: The Broader
Perspective
An idealist believes the short run doesn’t count. A cynic
believes the long run doesn’t matter. A realist believes
that what is done or left undone in the short run deter-
mines the long run.
— Sydney J. Harris, quoted in Reader’s Digest
In this epilogue we discuss a number of alternative approaches towards privacy, and
show how they fail. On the basis of this analysis, we argue that privacy-enhancing
technologies (such as those developed in this book) complemented by legislative
measures provide the best way to protect privacy and guarantee security.
The limitations of privacy legislation
In many countries, particularly in Europe, the prevailing approach to protect privacy
is privacy legislation. Legislation can discourage systematical abuse by the private
sector, but is insufﬁcient in all other cases:
• The key paradigm of legislation is to make undesired actions a crime and to
prosecute them. This hardly deters criminals who commit their crimes using
computers: in today’s networked environment they can operate over large dis-
tances and remain virtually untraceable, making it difﬁcult to enforce laws and
to prosecute suspects.
• In an age where organizations can communicate and transact with individuals
all over the world through telecommunication infrastructures, global harmo-
nization of privacy laws is imperative. This, however, is a daunting task that
may never be accomplished at all due to cultural differences.

258
EPILOGUE: THE BROADER PERSPECTIVE
• Attempts to stop organizations from using privacy-invading practices that are
in conﬂict with privacy legislation can easily take many years. For example, in
August 1998 the U.S. Federal Trade Commission ﬁnally succeeded in ordering
Trans Union (one of the three largest U.S. credit bureaus) to stop distributing
and selling target marketing lists based on consumer-credit data for unautho-
rized purposes; the original charge that Trans Union’s sale of target marketing
lists violated the Fair Credit Reporting Act dated back to 1992.
• Privacy laws put the burden upon individuals to protect their own data, but
the complexity and diversity of privacy laws makes it almost impossible for
individuals to be aware of their privacy rights. Privacy laws encompass in-
ternational laws, constitutional laws, case law, and federal, state, and local
legislation. According to StateNet, the number of privacy bills introduced in
U.S. state legislatures exceeded 8500 in 1997 alone.
• The language of privacy legislation is necessarily broad, even when applicable
only to a certain industry sector. This makes it difﬁcult to interpret a piece
of privacy legislation in the context of a given communication or transaction
mechanism. Consequently, it is hard for data collectors and auditors alike to
determine whether privacy legislation has been lived up to. To illustrate the
point, the deﬁnition of personal data by the European Privacy Directive [157]
considers anonymous and pseudonymous data to be different from personal
data, but it is unclear where to draw the line. Reidenberg and Schwartz [318]
study the degrees to which different E.U. countries and institutions view this
data different from personal data, and conclude: “For on-line services, the de-
termination of whether particular information relates to an ’identiﬁable person’
is unlikely to be straightforward.”
• New technologies develop much faster than law. With each new consumer
technology it can take many years to understand its privacy implications and
develop adequate new policies. Even seemingly simple issues, such as whether
issuers of electronic cash fall within the deﬁnition of “ﬁnancial institutions”
of the U.S. Right to Financial Privacy Act of 1978, are hard to decide. As
Oleinick [290, Chapter 7] points out, “What this policy lag means for our so-
ciety is that the Judiciary is always struggling to extrapolate old laws to cover
new technologies, that the Legislature is engaged in continual policy analysis
of new technologies once the new technology has created a policy issue, and
that the Executive is always struggling to mandate effective Federal policy to
regulate agency usage of new technologies.”
• Laws cannot protect against the theft or modiﬁcation by hackers of personal
data stored in computer databases, nor against misuse by employees and other
individuals authorized to access databases. Netsolve Inc. analyzed over half a
million security alarms from May to September of 1997, and found that “every

EPILOGUE: THE BROADER PERSPECTIVE
259
one of its electronic commerce customers suffered at least one serious network
attack per month. [...] The attacks stem from external sources seeking to gain
root access to a site’s network. Once they gain that access, they possibly could
download customer lists, change ﬁles, access new product information, destroy
data or transfer funds from the ﬁnance system.” Insider abuse accounts for
the majority of Internet security incidents reported to the CERT Coordination
Center from 1989 to 1995; see Howard [213] for an analysis.
• Requirements to allow individuals to give notice, to request consent, and to
correct inaccurate information in their ﬁles may be technically impractical for
organizations, and may be difﬁcult to carry out while at the same time ade-
quately restricting employee access.
• New laws frequently exempt earlier provisions in law for the purpose of in-
creasing the surveillance power of the government. For instance, the 1996
amendments to the U.S. Fair Credit Reporting Act of 1971 preempt provisions
of stronger state credit reporting laws by permitting the subsidiaries of a parent
company to share information without the consumer’s permission or govern-
ment regulation; see the Center for Public Integrity [83] for details. More
generally, even in democratic societies there is the realistic threat that privacy
laws will be amended, changed, exempted, overturned, or simply ignored.
Privacy legislation can actually contribute to degrading privacy. Where individuals at
the time of data collection felt protected by privacy laws, they are likely to have been
less inhibited in their behavior than they would have been otherwise. The harmful
consequences of privacy intrusions in these cases may be more serious than had the
individuals not been given the illusion of privacy in the ﬁrst place. Furthermore, to
check compliance with privacy legislation it is unavoidable that regular audits be per-
formed on the databases of organizations; this increases the accessibility of personal
data records, which broadens the scope for abuse. For instance, government agencies
may abuse privacy laws to gain access to the databases of target organizations.
The ineffectiveness of self-regulation
The approach of privacy through self-regulation, deﬁned by the Federation of Euro-
pean Direct Marketing [166] as regulation imposed by practitioners on practitioners,
and heavily promoted by the United States, is even less effective. Marketers and
other data miners have major commercial incentives to use personal data in any way
they see ﬁt. Large proﬁts can be made by using and selling consumer proﬁles, and
so any sane person would consider it a serious waste of resources to not put personal
data that has already been collected to new business uses. Since organizations can
rarely be held liable to compensate consumers for damages caused by the misuse of

260
EPILOGUE: THE BROADER PERSPECTIVE
personal data, not in the least because individuals often have no clue as to the ori-
gin of privacy breaches, organizations are incited to stay on the edge of what would
invoke immediate regulatory action.
Another problem is that self-regulation requires the participation of the entire
industry, but this is an unrealistic goal: new companies may prefer not to comply,
companies that agree to guidelines may in fact not comply with them, and there will
always be short-term incentives to ignore voluntary privacy measures. As Canada’s
Task Force on Electronic Commerce [370] points out, this can “undermine fair com-
petition in the marketplace, creating an unlevel playing ﬁeld. It can also erode con-
sumer conﬁdence in an entire industry and create further confusion about rights and
rules.”
Also, self-regulation does nothing to protect against the abuse of private-sector
and government databases by government ofﬁcials and agencies. In fact, adopting
privacy principles that explicitly state that law enforcement will not be given access
to personal data are in violation of the law in most developed countries.
Most of today’s self-regulation initiatives provide only the possibility of opt-out;
they do not require explicit customer consent to use or distribute personal informa-
tion. Many organizations are actively lobbying to prevent opt-in from happening.
In discussing the amendments to the U.S. Fair Credit Reporting Act, the Acting
Comptroller of the Currency [391] said: “I have even heard of people getting two
separate notiﬁcations covering different types of information, requiring two sepa-
rate letters to opt out. Such techniques may fall within the letter of the law, but they
certainly fall short of its spirit.” Furthermore, none of the industry self-regulation ini-
tiatives have an adequate enforcement mechanism, a method for consumers to access
their own data, or a way of correcting errors that may have occurred in the transcrip-
tion, transmission, or compilation of their personal information. Rotenberg [327]
warns that self-regulation has “made it harder for us to focus on the larger questions
of a coherent privacy policy. [...] Where once there was an understanding that in-
dividuals should have the right to get access to their own data, to inspect it, and to
correct it, now those who favor self-regulation believe it is necessary only to provide
access to a privacy policy.”
Surveys consistently conﬁrm the ineffectiveness of self-regulation. See, for in-
stance, surveys conducted by or on behalf of the Center for Democracy and Technol-
ogy [82], the Electronic Privacy Information Center [143, 144], the European Com-
mission [315], the Federal Deposit Insurance Corporation [162], the Federal Trade
Commission [165], and OMB Watch [291]. For other critiques, see the American
Civil Liberties Union [10], Budnitz [65, 66], Clarke [118], Rotenberg [327, 328],
and Varney [381].
Industry privacy violations conﬁrm that self-regulation is just a smoke screen.
Here is a small sample of recent privacy violations:
• In 1998, the U.S. Federal Trade Commission found that Web portal Geocities
was selling demographic information collected from its millions of customers

EPILOGUE: THE BROADER PERSPECTIVE
261
(provided when they signed up for free homepages) to advertisers, even though
its online assurance pledged that it would not do so. Ironically, Geocities re-
ceived a privacy label from TRUSTe (an organization that regulates Internet
privacy policies for over 500 companies and gives out privacy seals to con-
forming Web sites) while it was being investigated by the Federal Trade Com-
mission.
• In January 1999, the chief executive ofﬁcer of Sun Microsystems (a prominent
member organization of the U.S. Online Privacy Alliance) called consumer
privacy a “red herring,” and proclaimed “You have zero privacy anyway. Get
over it.”
• In March 1999, TRUSTe decided that Microsoft (one of TRUSTe’s largest
benefactors) would not be audited for its practice of embedding traceable se-
rial numbers (covertly captured by Microsoft when customers registered their
Windows 98 software) into all documents created with Word and Excel.
• One month later, the BBBOnLine Privacy Program (similar to that of TRUSTe)
rewarded a privacy seal to Equifax (one of the three largest U.S. credit bu-
reaus), which in the years before repeatedly breached basic privacy principles.
• In May 1999, the Federal Trade Commission settled with Liberty Financial
Companies; the company’s Young Investor Web site falsely represented that
personal data collected from children in a survey would be maintained “totally
anonymous,” yet it stored all the data in an identiﬁable manner.
• In November 1999, DoubleClick, which serves over 1300 Web sites with tar-
get banner advertisements, acquired market researcher Abacus Direct, which
collects data from 1100 merchandise catalog companies. DoubleClick’s goal
was to correlate the shopping and browsing habits of Internet users with their
names and addresses, in spite of its Internet privacy policy that promised that
all collected data would be anonymous.12
• Also in November 1999, it came to light that RealNetworks was surreptitiously
gathering data about the listening activities of users of its music software, and
that it recorded this data into a central database. TRUSTe did not revoke Real-
Networks’ privacy seal.
Since its inception in 1996, TRUSTe has investigated hundreds of privacy violations
but has not revoked a single privacy seal.
The latest privacy contempt are infomediaries, a business model devised by Hagel
and Singer [205]. Startups such as Enonymous, Lumeria, PopularDemand, Privacy-
Bank, Privada, PrivaSeek, InterOmni, and @YourCommand aim to become one-stop
12DoubleClick’s stock took a huge hit after the news became public, and the Federal Trade Commission
and several states started an investigation. Hereupon, DoubleClick announced to suspend its plans.

262
EPILOGUE: THE BROADER PERSPECTIVE
brokers of personal data by persuading individuals to funnel all their transactions
through their company. The infomediary’s sole goal is to earn revenue by selling the
personal data of their customers to marketers. The business strategy to lure unwitting
individuals into placing all their data and trust in them is to promise them a piece of
the revenue and to post a privacy policy.
The fallacy of key escrow
Anyone who considers “key escrow” as a way of protecting privacy is, of course, in
a state of sin. On a fundamental level, there can be no mistake about this. West-
in’s [387] widely accepted deﬁnition of privacy (see Section 1.2.1) clearly requires
that individuals themselves are in control over their own information. Key escrow
(also known under such names as “key recovery,” “revocable privacy,” “controlled
anonymity,” or “trustee-based tracing”) takes away this control completely, and there-
fore offers zero privacy. Splitting the ability to recover the secrets of an individual
among multiple key escrow authorities (using secret-sharing) does not change this
fact, not even if there would be a gazillion authorities that would pledge to notify
individuals before reconstructing their secrets.
On a more practical level, all key escrow systems have the following dangers in
common:
• As the NSA [279] (of all parties) warned, law enforcement agents and ofﬁcials
operating key escrow centers could well pose the greatest threat to a key escrow
encryption system. Clearly, the same objection holds for any other kind of key
escrow system. Abelson, Anderson, Bellovin, Benaloh, Blaze, Difﬁe, Gilmore,
Neumann, Rivest, Schiller, and Schneier [2] note that insider abuse “can even
become institutionalized within a rogue company or government.”
• On a related note, judicial knowledge and consent may easily be circumvented.
Epstein [154] warns that any key escrow system “cuts out the notice and knock
provisions that must be satisﬁed before a warrant could be executed. It vests
vast powers in third-party agents who have neither the incentive nor knowledge
to contest any government intrusion. It presupposes uniform good faith by
public ofﬁcials and overlooks the major costs of even a tiny number of ofﬁcial
misdeeds or mistakes.” Also, it will be difﬁcult for courts to enforce the time-
limits of a warrant.
• The key escrow authorities become a highly visible target to criminals who
seek to trace or decrypt the communications and transactions of certain targets.
They may be able to obtain the key shares of their interest through bribery,
hacking, or extortion.
In the words of Rivest, in his letter of June 1997 to the senators of the Senate Com-
merce and Judiciary Committees, “Putting key recovery into cryptography is like

EPILOGUE: THE BROADER PERSPECTIVE
263
soaking your ﬂame-retardant materials in gasoline – you risk a catastrophic failure of
the exact sort you were trying to prevent.”
Other general objections to key escrow include the following:
• As Directorate-General XIII of the European Commission [137] points out, “if
citizens and companies have to fear that their communication and transactions
are monitored with the help of key access or similar schemes unduly enlarging
the general surveillance possibility of government agencies, they may prefer
remaining in the anonymous off-line world and electronic commerce will just
not happen.”
• Once a key escrow system is in place, the case for weakening the rules under
which escrow access may be gained will gradually be weakened. Already, the
FBI and law enforcement agencies in other democratic countries are seeking to
gain access to personal data records without needing a court order or a search
warrant.
• Key escrow systems may not be legitimate. The Ofﬁce of Technology Assess-
ment, in its 1985 evaluation [284] of the FBI’s National Crime Information
Center, pointed out that “ﬁrst amendment rights could be violated to the extent
a national computer-based surveillance system was used to monitor the lawful
and peaceful activities or associations of citizens or if it were to have the effect
of discouraging such activities or associations. Fourth amendment rights could
be violated if the surveillance amounted to an unreasonable search and seizure
of personal information. And, [...] ﬁfth amendment rights to due process
could be violated if such surveillance was conducted without ﬁrst establishing
probable cause or reasonable suspicion and without serving advance notice on
the subject individual.” Key escrow systems reverse the presumption that in-
dividuals are free until they pose a threat of material harm, and are likely to
violate all three amendments on the same grounds. See also Sullivan [366].
In recent years, cryptographers have worked ﬁercely to replace privacy-protecting
systems by key escrow systems:
• The ﬁrst area that fell victim is electronic voting. Following several propos-
als that guaranteed unconditional privacy, Cohen and Fischer [119] and Be-
naloh and Yung [26] introduced key escrow electronic voting. Virtually all
electronic voting schemes proposed since then are key escrow systems; for re-
cent achievements, see Cramer, Franklin, Schoenmakers, and Yung [124] and
Cramer, Gennaro, and Schoenmakers [125].
Surprisingly, the transition from privacy-protecting electronic voting schemes
to key escrow voting schemes has gone by almost unnoticed and unchallenged.
This is because key escrow electronic voting was not proposed to enable law
enforcement to trace votes, but as a way to achieve the property of “universal

264
EPILOGUE: THE BROADER PERSPECTIVE
veriﬁability;” the terminology “key escrow” never entered the electronic vot-
ing vocabulary. It is not clear, though, that universal veriﬁability is such an
important property that it is worthwhile to sacriﬁce privacy, nor has it been
proved that privacy and universal veriﬁability cannot be achieved at the same
time.
Another issue worth mentioning in this context is that the key escrow voting
schemes that achieve information-theoretical “untraceability” (with respect to
other parties than the key escrow authorities) require the voter to encrypt each
of his or her votes for each of the key escrow authorities. The more efﬁcient
schemes achieve only computational untraceability: anyone who can feasibly
solve (an instance of) the underlying hard problem can trace all votes without
the involvement of the key escrow authorities. For a discussion of the draw-
backs of computational privacy, see Section 1.3.5.
• The approach of key escrow is most widely associated with public key encryp-
tion. See Denning and Branstad [132] for a taxonomy of key escrow encryp-
tion systems, and Denning [131] for descriptions of 33 proposed key escrow
encryption products and proposals. (Many others have been proposed since the
latter reference.)
The security beneﬁt pursued in this case is the ability to wiretap the con-
versations of criminals in (near) real time. Numerous publications and tes-
timonies, though, convincingly argue that key escrow encryption will cause
much more harm than good. See, for instance, Abelson et al. [2], Bowden and
Akdeniz [43], Epstein [154], Froomkin [176], Nathan Associates [274], the
NSA [279], Shearer and Gutmann [349], the U.S. National Research Coun-
cil [278], Walsh [386], and a 1998 background report [15] for the Danish Min-
istry of Research and Information Technology.
• The most recent area that has fallen victim is electronic cash. Starting with
Chaum [105], a ﬂoodgate of papers on key escrow electronic cash opened:
Brickell, Gemmell, and Kravitz [62], Stadler, Piveteau, and Camenisch [360],
Camenisch, Maurer, and Stadler [70, 71], Fujisaki and Okamoto [178], Jakob-
sson and Yung [220, 221, 222], Davida, Frankel, Tsiounis, and Yung [128],
Radu, Govaerts, and Vandewalle [317], Frankel, Tsiounis, and Yung [173,
374], Nakayama, Moribatake, Abe, and Fujisaki [272], and many others.
Here, the primary excuse to squander privacy has been to combat money laun-
dering. However, money laundering concerns can be addressed effectively
without giving up privacy by (prudently) applying one or more of the following
measures: placing limits on amounts; ensuring payee traceability (by the payer
only); limiting off-line transferability; limiting the issuance of electronic cash
to regulated institutions; disallowing anonymous accounts; issuing only per-
sonalized paying devices; identifying payers in high-value transactions; and,

EPILOGUE: THE BROADER PERSPECTIVE
265
checking the identity of parties who convert other forms of money into elec-
tronic cash.
Other excuses for key escrow have been to deal with theft or extortion of the
bank’s secret key, and to deal with attackers with “inﬁnite” computing power.
In Section 5.5.5, however, we have seen that these are not valid excuses ei-
ther to destroy privacy. Also, in Section 6.4.4 we have shown how to combat
extortion of the certiﬁed key pairs of certiﬁcate holders.13
Furthermore, the proposed key escrow electronic cash systems that circumvent
involvement of the key escrow authorities in the withdrawal protocol achieve
only computational “untraceability” (with respect to other parties than the key
escrow authorities).14
Much of the key escrow work sports exaggerated and even downright ignorant state-
ments about how privacy will hurt individuals, organizations, and societies at large.
Some comfort may be derived from the observation that most authors of key escrow
papers in all likelihood had little more on their minds than the urge to publish yet
another paper. Waving the key escrow magic wand is the quickest way to success
whenever more honorable approaches to improve a line of research are unsuccessful.
By radically changing the model to key escrow, the researcher all of a sudden ﬁnds
him or herself in the luxurious position of being able to claim and glorify new secu-
rity beneﬁts and features. At the same time, the key escrow smoke screen enables the
researcher to downplay the annihilation of privacy by claiming that the new system
provides “balanced” privacy; many authors do not even shy away from claiming that
their key escrow systems “preserve” or even “improve” privacy.
This down-to-earth explanation of why key escrow approach has been running
rampant does not make the trend any less disquieting or harmful, though. If nothing
else, the key escrow work has resulted in greatly eroded levels of awareness among
fresh researchers of the meaning and importance of privacy.
Some proponents of the key escrow approach argue that the assumption of an
anonymous channel (over which to send blind signatures, say) is essentially as strong
as the assumption that the key escrow authorities will not pool together their key
shares, “because” anonymous channels also rely on some kind of threshold assump-
tion. (Indeed, the electronic voting schemes of Chaum [94] and Bos [42, Chapter 3]
rely on a “mix” network.) This argument does not hold water, though. In the physi-
cal world, covert mass surveillance of identiﬁed individuals is completely infeasible;
13In another proposal by Pﬁtzmann and Sadeghi [302], each user plays the role of the key escrow
authorities by him or herself. The drawback of this proposal is that payments are only computationally
untraceable. On the upside, the proposal works also in software-only settings. The same technique can be
used to protect against extortion of certiﬁed key pairs in our software-only setting.
14Another drawback is that virtually all the proposed key escrow cash systems require payments to be
online to guarantee prior restraint of double-spending or do not address any of the privacy issues associated
with smartcards (see Chapter 6). The only exception is a system proposed by Camenisch, Maurer, and
Stadler [71], which hereto uses techniques developed in this book.

266
EPILOGUE: THE BROADER PERSPECTIVE
an anonymous channel may be as easy as dropping a letter in a mailbox or walking
to a nearby ofﬁce. In cyberspace, alternative means are available, as we have seen
in Section 1.2.2. The trend of wireless connection through handhelds could make
it even easier to escape identiﬁcation. Even if senders over the Internet use meth-
ods that enable others to trace their actions without their assistance, it may be very
hard, costly, or time-consuming to examine and link the records of Internet access
providers and other organizations. The parties that need to be approached to enable
tracing may differ in each circumstance, may be in different jurisdictions, may not
keep any records at all, and may have no intention of breaching the privacy vows
they made to their customers. At the very least, automated key recovery and routine
tracing are not an option.
More importantly, and this is the crucial difference with key escrow, users are
free to choose for themselves which mechanism and which (and how many) parties
they will use for each communication or transaction. With key escrow, in contrast,
all system participants are forced to deliver the ability to instantly recover all their
secrets to a single set of authorities that they cannot choose freely, and that are under
a legal obligation to keep records and cooperate when subpoenaed or presented with
a court order or a warrant.
Privacy is protected only if each individual is able at all times to control and
determine for him or herself which parties, if any, are capable of recovering a secret.
If a user decides to give up some of that control, that is his or her choice, but it should
not be hardwired into the design of the system.
The beneﬁts of privacy-enhancing technologies
Oleinick [290, Chapter 4] rightfully notes that “The transfer of control over personal
information that occurs in a disclosure of personal information is a transfer of power.”
Privacy protection requires that each individual has the power to decide how his or
her personal data is collected and used, how it is modiﬁed, and to what extent it
can be linked; only in this way can individuals remain in control over their personal
data. The techniques developed in this book demonstrate that these goals can be
achieved through the use of privacy-enhancing technologies that are entirely feasible
and secure.
When designing abuse protection techniques, it is of fundamental importance that
any user secret can be computed only with the consent of that user (unless perhaps if
he or she commits a crime). The security techniques described in this book, notably
in Section 5.5 and in Section 6.4.4, all meet this objective. In particular, in Sec-
tion 5.5.1 we have described techniques for self-revocable unlinkability and untrace-
ability: certiﬁcate holders can prove to have been the originator of a showing protocol
execution, can provide evidence to have been the originator of multiple transactions
without disclosing their identity, and can prove that they were not involved in certain

EPILOGUE: THE BROADER PERSPECTIVE
267
transactions.
Organizations often claim that restrictions to the ﬂow of personally identiﬁable
information hinder their ability to use up-to-date personal information for the purpose
of reducing identity fraud. Privacy-enhanced PKIs overcome this objection, and in
fact offer a myriad of beneﬁts to organizations:
• The need to consult Certiﬁcate Revocation Lists or online certiﬁcate validation
services is minimized.
• CAs and other central parties cannot learn data about the customers of certiﬁ-
cate veriﬁers, and so they cannot compete unfairly. (Organizations typically
pay, through discounts or otherwise, to learn the identity and other personal
data of customers.)
• The scope for identity fraud and other abuses is minimized.
• Industry-wide adoption of privacy-enhanced PKIs fosters fair competition with
respect to the collection and use of personal data. (Organizations can only
learn and link data with the consent of the certiﬁcate holders to whom the data
pertains.)
• The need to protect online databases against intrusions by hackers and insiders
is minimized.
• Guaranteed privacy protection makes consumers feel much more comfortable
to engage in electronic transactions. Likewise, privacy cultivates goodwill,
which is a distinct competitive advantage.
• The trend is for regulations to require mechanisms for assuring adherence of
privacy standards. This will signiﬁcantly raise compliance costs to industry.
(See, for example, the Masons Study [256] on compliance with the European
Privacy Directive.) The use of privacy-enhanced PKIs enables individuals to
reveal only the minimum information needed to complete a transaction, and
thus minimizes the burden on industry to demonstrate adherence to privacy
standards.
• More generally, privacy-enhanced PKIs are the cheapest and most effective
way to comply with as many of the privacy principles of codes of conduct and
privacy legislation as possible, since their restrictions and requirements do not
apply to anonymous information. In a 1998 report [133], the U.S. Department
of Commerce set out the following nine speciﬁc characteristics of effective
self-regulation for privacy online: awareness, choice, data security, data in-
tegrity, consumer access, accountability, veriﬁcation, consumer recourse, and
consequences. Our techniques enable one to implement the ﬁrst seven of these

268
EPILOGUE: THE BROADER PERSPECTIVE
in the strongest possible sense. They also facilitate automated dispute resolu-
tion (non-repudiation), which greatly helps to realize the privacy characteris-
tics of consumer recourse and consequences.
• The scope for law enforcement intrusions on the data records of organizations
is minimized; there will be little to infer.
• Transaction ﬁnality is improved.
• The scope for discrimination is greatly reduced.
Adoption of the techniques in this book could also stimulate the public acceptance
of smartcards, because smartcards cannot be misused for the purpose of surveillance.
Our techniques are desirable even from an economic viewpoint, because they can
be implemented using low-cost smartcards without cryptographic coprocessors. Fur-
thermore, tamper-resistant devices for certiﬁcate holders are unavoidable if digital
signatures are to have a ﬁrm legal grounding.
What needs to be done
It is time to stop tolerating (let alone promoting) seal programs, infomediaries, key
escrow systems, and other misleading practices towards privacy. Schemes in which
users do not have control over their own personal data offer zero privacy. No smoke
and mirrors can change this fact.
While privacy-enhancing PKIs minimize the need for legislative intervention,
they cannot remove the need for privacy legislation altogether. Privacy legislation is
needed to set the general boundaries of what kinds of personal data may be bartered
for what purposes,15 what attribute types may be encoded, under what circumstances
(if any) a veriﬁer may refuse access to the holder of a valid certiﬁcate, on what
grounds (if any) a CA may refuse certiﬁcate requests or applicants, and so on. Leg-
islation may also be needed to mandate organizations to delete personal data that has
been voluntarily disclosed to them as soon as it has fulﬁlled the purpose to which
the individual consented.16 Furthermore, legislation is needed to provide a right to
judicial remedies, and to enable prosecution of fraudulent behavior (means of re-
dress). Privacy-enhanced PKIs should be the norm, with the kinds of linking and
tracing information that may be bartered (and other issues that technology cannot
resolve) deﬁned by (preferably overarching) privacy legislation. See the American
Civil Liberties Union [10], Clarke [118], and Marx [255, Table II] for discussions of
15As we have seen in Section 6.5.5, smartcards can prevent identity bartering, but this is not sufﬁcient.
16A precedent for such legislation has been set in 1997 by the Privacy Commissioner of Sweden, who
instructed American Airlines operating in Europe to delete all health and medical details on Swedish
passengers after each ﬂight unless explicit consent could be obtained; both the District Court and the
Court of Appeal have rejected actions by American Airlines.

EPILOGUE: THE BROADER PERSPECTIVE
269
the kinds of privacy provisions that are desirable. One tantalizing idea that has been
put forward is to give individuals property rights over their personal information.
Several inﬂuential organizations have in recent years made the case for building
privacy into electronic communication and transaction mechanisms. For example:
• In 1995, the NII Task Force [313] stated that “Privacy should not be addressed
as a mere afterthought, once personal information has been acquired. Rather,
information users should explicitly consider the impact on privacy in the very
process of designing information systems and in deciding whether to acquire
or use personal information in the ﬁrst place.”
• In 1996, the Working party on Illegal and Harmful Content on the Internet in
its report [155] for the Council of Europe stated: “Anonymous use of the Inter-
net takes a number of forms: anonymous browsing, anonymous publishing of
content on the World Wide Web, anonymous e-mail messages and anonymous
posting of messages to newsgroups. In accordance with the principle of free-
dom of expression and the right to privacy, use of anonymity is legal. [...] A
user should not be required to justify anonymous use.”
• Also in 1996, the International Working Group on Data Protection in Telecom-
munications [217] stated its conviction that “it is necessary to develop techni-
cal means to improve the users privacy on the Net. [...] In general users
should have the opportunity to access the Internet without having to reveal
their identity where personal data are not needed to provide a certain service.
[...] Anonymity is an essential additional asset for privacy protection on the
Internet. Restrictions on the principle of anonymity should be strictly limited
to what is necessary in a democratic society without questioning the principle
as such.”
• In 1997, an advisory committee of the European Commission to the European
Parliament [156] recommended that “Technological developments and take-up
promotion projects in European Union R&D programmes should concentrate
on providing a wide range of interoperable, compatible electronic commerce
building-blocks. [...] They should favour technologies which minimise the
need for personal data and thus enhance the protection of the right to privacy
of consumers (privacy enhancing technologies).”
• Also in 1997, the Working Party of the European Union [373] declared that
“where the user can choose to remain anonymous off-line, that choice should
also be available on-line. [...] The ability to choose to remain anonymous
is essential if individuals are to preserve the same protection for their privacy
on-line as they currently enjoy off-line. [...] The principle that the collection
of identiﬁable personal data should be limited to the minimum necessary must
be recognized in the evolving national and international laws dealing with the

270
EPILOGUE: THE BROADER PERSPECTIVE
Internet. It should also be embodied in codes of conduct, guidelines and other
‘soft law’ instruments that are developed. Where appropriate this principle
should specify that individual users be given the choice to remain anonymous.”
• In October 1997, Directorate-General XIII of the European Commission [137]
warned that privacy safeguards are needed because otherwise “digital signa-
tures could be abused as an efﬁcient instrument for tracing individual on-line
consumption patterns and communication or for intercepting, recording or mis-
using documents or messages.”
• In 1998, the Group of Experts on Information Security and Privacy [198], in
their background report for an OECD Ministerial Conference, noted: “Privacy
enhancing technologies should not be seen as primarily novel technical devel-
opments or as additions to existing systems. Rather, they should be seen as
a matter of design philosophy: one that encourages (in appropriate circum-
stances) the removal of identiﬁers linked to personal data thereby anonymising
the data.”
• A 1998 draft paper [375] by the U.S. government states: “If electronic com-
merce is to realize its enormous potential consumers must be conﬁdent that
their personal information is protected against misuse. Electronic commerce
in the next century will thrive only to the extent that individuals’ privacy is
protected. [...] Technology will offer solutions to many privacy concerns in
the online environment, and will serve as an important tool to protect privacy.”
• Also in 1998, the Steering Committee of the Federal Public Key Infrastruc-
ture [163] warned that “for many applications, identity-based authentication is
not only unnecessary, it may be inappropriate. Agencies will need to consider
carefully which applications require user authentication (e.g., to protect pri-
vate information). In many instances, such as downloading forms, anonymous
transactions are appropriate.”
• In October 1998, the governments of the member countries of the OECD [199]
declared that “they will take the necessary steps, within the framework of their
respective laws and practices, to ensure that the OECD Privacy Guidelines are
effectively implemented in relation to global networks, and in particular [...]
encourage the use of privacy-enhancing technologies.”
Nevertheless, countries have yet to establish a climate that allows privacy-enhancing
technologies to ﬂourish. Without efforts to fund and promote the development and
adoption of privacy-enhancing technologies, and without the enactment of laws that
forbid the use of privacy-invading technologies in communication and transaction
applications in which there is no strict need to establish identity, the above statements
are nothing more than hollow phrases.

EPILOGUE: THE BROADER PERSPECTIVE
271
Unfortunately, the beneﬁts of protecting privacy by means of technological mea-
sures are not widely acknowledged. Several countries have drafted, or are in the
process of drafting, legislation that requires public keys to be bound to true names
or traceable pseudonyms. As Baker and Yeo [17] point out, “The effect of these
provisions will be to make it more difﬁcult, if not impossible, to establish the legal
validity of non-identity certiﬁcates and to enforce transactions that are authenticated
by non-identity certiﬁcates.”
The widespread adoption of automated transaction systems that lack any provi-
sions to protect privacy is a very dangerous trend. As Swire [367] points out, “The
systems in place in one period can have a powerful effect on what systems will de-
velop in subsequent periods. [...] Once the costs of the database and infrastructure
are already incurred for initial purposes, then additional uses may be cost-justiﬁed
that would not otherwise have been.” Holmes [212] notes that “the danger to demo-
cratic countries is not that they will openly embrace totalitarianism. It is [...] that
they will unwittingly, almost imperceptibly, and with the best of intentions, allow
themselves to drift so far in that direction that the ﬁnal step will then be but a small
one.” Chaum [104] observes that the current situation “does not want to go halfway
in between. It really has a natural tendency to ﬂip into one of two extreme positions.”
For a compelling case of how only architectures of freedom can prevent tyrannies,
see Rummel [331].
Today, the foundations for the communication and transaction technologies of
this century are being laid. Digital certiﬁcates will be hardwired into all operating
systems, network protocols, Web browsers, chipcards, application programs, and so
on. To avert the doom scenario of a global village founded wholly on inescapable
identiﬁcation technologies, it is imperative that we rethink our preconceived ideas
about security and identity—and build in privacy before the point of no return has
been reached.


References
[1] M. Abadi, E. Allender, A. Broder, J. Feigenbaum, and L. Hemachandra. On
generating solved instances of computational problems. In S. Goldwasser,
editor, Advances in Cryptology–CRYPTO ’88, volume 403 of Lecture Notes in
Computer Science, pages 297–310. Springer-Verlag, 1988.
[2] Hal Abelson, Ross Anderson, Steven M. Bellovin, Josh Benaloh, Matt Blaze,
Whitﬁeld Difﬁe, John Gilmore, Peter G. Neumann, Ronald L. Rivest, Jef-
fery I. Schiller, and Bruce Schneier. The risks of key recovery, key escrow,
and trusted third party encryption. World Wide Web Journal, 2(3):241–257,
1997. Also in: Report in Centre for Democracy and Technology Policy Post,
Vol. 3, no. 6, May 21, 1997. A revised edition appeared June 1998.
[3] Accredited Standards Committee X9. American National Standard X9.59-
199x: Electronic Commerce for the Financial Services Industry: Account-
Based Secure Payment Objects. Working Draft # 17, January 1999.
[4] C. Adams and S. Farrell. Internet X.509 public key infrastructure certiﬁcate
management protocols. Internet Draft of the PKIX Working Group, May 1998.
[5] Carlisle Adams and Robert Zuccherato. A general, ﬂexible approach to cer-
tiﬁcate revocation. Entrust white paper, June 1998.
[6] G.B. Agnew, R.C. Mullin, and S.A. Vanstone. An implementation of elliptic
curve cryptosystems over F2155. IEEE Journal on Selected Areas in Commu-
nications, 11(5):804–813, June 1993.
[7] William Aiello, Sachin Lodha, and Rafail Ostrovsky. Fast digital identity re-
vocation. In Hugo Krawczyk, editor, Advances in Cryptology–CRYPTO ’98,
Lecture Notes in Computer Science, pages 137–152. Springer-Verlag, 1998.
[8] American Bankers Association. X9.45-199x: Enhanced management controls
using digital signatures and attribute certiﬁcates. Working draft, June 1997.

274
REFERENCES
[9] American Bar Association. Digital signature guidelines; legal infrastructure
for certiﬁcation authorities and secure electronic commerce, August 1996.
ISBN 1-57073-250-7.
[10] American Civil Liberties Union. Elements of effective self regulation for the
protection of privacy and questions related to online privacy. Letter to Ms.
Jane Cofﬁn, Ofﬁce of International Affairs, National Telecommunications and
Information Administration, July 1998.
[11] American National Standards Institute. American National Standards Com-
mittee X.9.55-1995: Public key cryptography for the ﬁnancial services indus-
try, 1995.
[12] Ross Anderson and Markus Kuhn. Tamper resistance - a cautionary note. In
Second USENIX Workshop on Electronic Commerce, pages 1–11, Oakland,
California, November 1996. USENIX Association. ISBN 1-880446-83-9.
[13] Ross Anderson and Markus Kuhn. Low cost attacks on tamper resistant de-
vices. In Security Protocols, 5th International Workshop, Paris, France, vol-
ume 1361 of Lecture Notes in Computer Science, pages 125–136. Springer-
Verlag, April 1997.
[14] Ross Anderson and Serge Vaudenay. Minding your p’s and q’s. In Kwangjo
Kim and Tsutomu Matsumoto, editors, Advances in Cryptology–ASIACRYPT
’96, volume 1163 of Lecture Notes in Computer Science, pages 26–35.
Springer-Verlag, 1996.
[15] Arthur Andersen Computer Risk Management. Report on companies’ use of
encryption & evaluations re. monitorable encryption systems. Background re-
port for the Danish Ministry of Research and Information Technology, Febru-
ary 1998.
[16] Eric Bach. How to generate factored random numbers. SIAM J. Computing,
17(2):179–193, April 1988.
[17] Stewart Baker and Matthew Yeo. Survey of international electronic and digital
signature initiatives. Steptoe & Johnson LLP, Internet Law and Policy Forum,
version of April 14, 1999.
[18] Stewart A. Baker. Don’t worry be happy – why Clipper is good for you. Wired
2.06, 1996.
[19] James Bamford.
The Puzzle Palace: A Report on America’s Most Secret
Agency. Houghton Mifﬂin, Boston, 1982.
[20] Banksys / Groupement des Cartes Bancaires. Interoperable C-SET: Protocol
speciﬁcation. Deliverable: D 6.1, Issue 2, Version 0, November 1997.

REFERENCES
275
[21] Mihir Bellare, Juan A. Garay, and Tal Rabin. Fast batch veriﬁcation for mod-
ular exponentiation and digital signatures, June 1998. Extended abstract in:
Advances in Cryptology – Proceedings of Eurocrypt 98, Lecture Notes in
Computer Science Vol. 1403, K. Nyberg ed., Springer-Verlag, 1998.
[22] Mihir Bellare and Oded Goldreich. On deﬁning proofs of knowledge. In
Ernest F. Brickell, editor, Advances in Cryptology–CRYPTO ’92, volume 740
of Lecture Notes in Computer Science, pages 390–420. Springer-Verlag, 1992.
[23] Mihir Bellare, Oded Goldreich, and ShaﬁGoldwasser. Incremental cryptogra-
phy: The case of hashing and signing. In Yvo G. Desmedt, editor, Advances in
Cryptology–CRYPTO ’94, volume 839 of Lecture Notes in Computer Science,
pages 216–233. Springer-Verlag, 1994.
[24] Mihir Bellare, Markus Jakobsson, and Moti Yung.
Round-optimal zero-
knowledge arguments based on any one-way function. In Walter Fumy, editor,
Advances in Cryptology–EUROCRYPT ’97, volume 1233 of Lecture Notes in
Computer Science, pages 280–305. Springer-Verlag, 1997.
[25] J. Benaloh and J. Leichter. Generalized secret sharing and monotone functions.
In S. Goldwasser, editor, Advances in Cryptology–CRYPTO ’88, volume 403
of Lecture Notes in Computer Science, pages 27–35. Springer-Verlag, 1988.
[26] J. Benaloh and M. Yung. Distributing the power of a government to enhance
the privacy of voters. In Proceedings of the 5th Symposium on Principles of
Distributed Computing, pages 52–62, New York, August 1986. ACM.
[27] Shimshon Berkovits, Santosh Chokhani, Judith A. Furlong, Jisoo A. Geiter,
and Jonathan C. Guild. Public Key Infrastructure study. Final Report for
the National Institute of Standards and Technology. Task performed by The
MITRE Corporation, McLean, Virginia, April 1994.
[28] Ingrid Biehl, Bernd Meyer, and Christoph Thiel.
Cryptographic protocols
based on real-quadratic a-ﬁelds. In Kwangjo Kim and Tsutomu Matsumoto,
editors, Advances in Cryptology–ASIACRYPT ’96, volume 1163 of Lecture
Notes in Computer Science, pages 15–25. Springer-Verlag, 1996.
[29] Eli Biham and Adi Shamir. The next stage of differential fault analysis: How
to break completely unknown cryptosystems. Distributed on October 30th,
1996.
[30] Eli Biham and Adi Shamir. Differential fault analysis of secret key cryptosys-
tems. In Burton S. Kaliski Jr., editor, Advances in Cryptology–CRYPTO ’97,
volume 1294 of Lecture Notes in Computer Science, pages 513–525. Springer-
Verlag, 1997.

276
REFERENCES
[31] David Birch. Exploiting Privacy Enhancing Technologies. Proceedings of UK
Data Protection ’99 IIR, London, July 1999. Draft of 5/7/99.
[32] M. Blaze, J. Feigenbaum, J. Ioannidis, and A. Keromytis. The role of trust
management in distributed system security. In J. Vitek and C. Jensen, editors,
Secure Internet Programming: Security Issues for Distributed and Mobile Ob-
jects, volume 1603 of Lecture Notes in Computer Science, pages 185–210.
Springer, 1999.
[33] Matt Blaze, Joan Feigenbaum, and Jack Lacy. Decentralized trust manage-
ment. In Proceedings of the 17th Symposium on Security and Privacy, pages
164–173, Los Alamitos, 1996. IEEE Computer Society Press.
[34] Daniel Bleichenbacher. Generating ElGamal signatures without knowing the
secret key. In Ueli Maurer, editor, Advances in Cryptology–EUROCRYPT ’96,
volume 1070 of Lecture Notes in Computer Science, pages 10–18. Springer-
Verlag, 1996.
[35] Daniel Bleichenbacher, Eran Gabber, Phil Gibbons, and Yossi Matias. On
personalized yet anonymous interaction. Manuscript 1997.
[36] D. Boneh and G. Durfee. Cryptanalysis of RSA with private key d less than
n0.292. In Advances in Cryptology–EUROCRYPT ’99, volume 1592 of Lecture
Notes in Computer Science, pages 1–11. Springer-Verlag, 1999.
[37] Dan Boneh. Twenty years of attacks on the RSA cryptosystem. Notices of the
American Mathematical Society, 46(2):203–213, 1999.
[38] Dan Boneh, Richard A. DeMillo, and Richard J. Lipton. On the importance of
checking cryptographic protocols for faults. In Walter Fumy, editor, Advances
in Cryptology–EUROCRYPT ’97, volume 1233 of Lecture Notes in Computer
Science, pages 37–51. Springer-Verlag, 1997.
[39] Dan Boneh and Matthew Franklin. Efﬁcient generation of shared RSA keys.
In Burton S. Kaliski Jr., editor, Advances in Cryptology–CRYPTO ’97, volume
1294 of Lecture Notes in Computer Science, pages 425–439. Springer-Verlag,
1997.
[40] Dan Boneh and Ramarathnam Venkatesan. Breaking RSA may be easier than
factoring. In Kaisa Nyberg, editor, Advances in Cryptology–EUROCRYPT
’98, volume 1233 of Lecture Notes in Computer Science, pages 59–71.
Springer-Verlag, 1998.
[41] J.N.E. Bos and D. Chaum. SmartCash: a practical electronic payment system.
Technical Report CS-R9035, Centrum voor Wiskunde en Infomatica, August
1990.

REFERENCES
277
[42] Jurjen N.E. Bos. Practical Privacy. PhD thesis, Centrum voor Wiskunde en
Informatica, March 1992. In: Veriﬁcation of RSA Computations on a Small
Computer, pages 103–116.
[43] Caspar Bowden and Yaman Akdeniz. Cryptography and democracy: Dilem-
mas of freedom. Liberating Cyberspace: Civil Liberties, Human Rights, and
the Internet, pages 81–125, 1999.
[44] Joan Boyar, S.A. Kurtz, and M.W. Krentel. A discrete logarithm implemen-
tation of perfect zero-knowledge blobs. Journal of Cryptology, 2(2):63–76,
1990.
[45] Stefan Brands. Cryptographic methods for demonstrating satisﬁable formulas
from propositional logic. Patent PCT/NL96/00413. Filed November 1995.
[46] Stefan Brands. An efﬁcient off-line electronic cash system based on the repre-
sentation problem. Technical Report CS-R9323, Centrum voor Wiskunde en
Informatica, April 1993.
[47] Stefan Brands. Off-line cash transfer by smart cards. Technical Report CS-
R9455, Centrum voor Wiskunde en Informatica, September 1994. Also in:
Proceedings of the First Smart Card Research and Advanced Application Con-
ference (October 1994), France, pages 101–117.
[48] Stefan Brands. Untraceable off-line cash in wallet with observers. In Dou-
glas R. Stinson, editor, Advances in Cryptology–CRYPTO ’93, volume 911,
pages 302–318. Springer-Verlag, 1994.
[49] Stefan Brands. Off-line electronic cash based on secret-key certiﬁcates. In
R. Baeza-Yates, E. Goles, and P.V. Goblete, editors, Proceedings of the Second
International Symposium of Latin American Theoretical Informatics, volume
911, pages 131–166. Springer-Verlag, 1995.
[50] Stefan Brands. Restrictive blind issuing of secret-key certiﬁcates in parallel
mode. Technical Report CS-R9523, Centrum voor Wiskunde en Informatica,
March 1995.
[51] Stefan Brands. Restrictive blinding of secret-key certiﬁcates. In Louis C.
Guillou and Jean-Jacques Quisquater, editors, Advances in Cryptology–
EUROCRYPT ’95, volume 921 of Lecture Notes in Computer Science, pages
231–247. Springer-Verlag, 1995.
[52] Stefan Brands. Secret-key certiﬁcates. Technical Report CS-R9510, Centrum
voor Wiskunde en Informatica, February 1995.
[53] Stefan Brands.
Secret-key certiﬁcates (continued).
Technical Report CS-
R9555, Centrum voor Wiskunde en Informatica, June 1995.

278
REFERENCES
[54] Stefan Brands.
Privacy-protected transfer of electronic information.
U.S.
Patent ser. no. 5,604,805, February 1997. Filed August 1993.
[55] Stefan Brands. Rapid demonstration of linear relations connected by Boolean
operators. In Walter Fumy, editor, Advances in Cryptology–EUROCRYPT ’97,
volume 1233 of Lecture Notes in Computer Science, pages 318–333. Springer-
Verlag, 1997.
[56] Stefan Brands. Secret-key certiﬁcates. U.S. Patent ser. no. 5,606,617, February
1997. Filed October 1994.
[57] Stefan Brands. Secure cryptographic methods for electronic transfer of infor-
mation. U.S. Patent ser. no. 5,668,878, September 1997. Filed August 1995.
[58] Stefan Brands. Electronic cash. In Mikhail J. Atallah, editor, Algorithms and
Theory of Computation Handbook, chapter 44. CRC Press LLC, November
1998. ISBN 0-8493-2649-4.
[59] Stefan Brands and David Chaum. Distance-bounding protocols. In Tor Helle-
seth, editor, Advances in Cryptology–EUROCRYPT ’93, volume 765 of Lec-
ture Notes in Computer Science, pages 344–359. Springer-Verlag, 1994.
[60] G. Brassard, D. Chaum, and C. Cr´epeau.
Minimum disclosure proofs of
knowledge. Journal of Computer and System Sciences, 37(2):156–189, 1988.
[61] D.M. Bressoud. Factorization and Primality Testing. Springer-Verlag, New
York, 1989.
[62] Ernest Brickell, Peter Gemmell, and David Kravitz. Trustee-based tracing
extensions to anonymous cash and the making of anonymous change. In Pro-
ceedings of the 6th Annual Symposium on Discrete Algorithms, pages 457–
466, 1995.
[63] Ernest F. Brickell, David Chaum, Ivan B. Damg˚ard, and Jeroen van de Graaf.
Gradual and veriﬁable release of a secret. In Carl Pomerance, editor, Advances
in Cryptology–CRYPTO ’87, volume 293 of Lecture Notes in Computer Sci-
ence, pages 156–166. Springer-Verlag, 1988.
[64] Murray J. Brown.
Secure wireless messaging: A new approach to digital
certiﬁcates. Wireless Magazine, October 1998.
[65] Mark E. Budnitz. Industry self-regulation of internet privacy: The sound of
one hand clapping. Computers, Freedom & Privacy 1999, April 6–8, Wash-
ington DC.
[66] Mark E. Budnitz. Privacy protection for consumer transactions in electronic
commerce: Why self-regulation is inadequate. 49 S. Caro. L. Rev. 847, 1998.

REFERENCES
279
[67] Mike Burmester. A remark on the efﬁciency of identiﬁcation schemes. In I.B.
Damg˚ard, editor, Advances in Cryptology–EUROCRYPT ’90, volume 473 of
Lecture Notes in Computer Science, pages 493–495. Springer-Verlag, 1991.
[68] W. E. Burr. Public key infrastructure (PKI) technical speciﬁcations: Part A -
technical concept of operations. Working draft TWG-98-59, September 1998.
[69] J. Callas, L. Donnerhacke, H. Finney, and R. Thayer.
OpenPGP message
format. Network Working Group, Request for Comments no. 2440, November
1998.
[70] Jan Camenisch. Group Signature Schemes and Payment Systems Based on the
Discrete Logarithm Problem. PhD thesis, ETH, 1998. Reprinted as Vol. 2 in
ETH Series in Information Security and Cryptography, edited by Ueli Maurer,
Hartung-Gorre Verlag, Konstanz, ISBN 3-89649-286-1.
[71] Jan Camenisch, Ueli Maurer, and Markus Stadler. Digital payment systems
with passive anonymity-revokingtrustees. Journal of Computer Security, 5(1),
1997. Abbridged version in: Computer Security – ESORICS 96, Vol. 1146,
pages 33–43, Springer-Verlag.
[72] Jan Camenisch, Jean-Marc Piveteau, and Markus Stadler. Blind signatures
based on the discrete logarithm problem. In Alfredo De Santis, editor, Ad-
vances in Cryptology–EUROCRYPT ’94, volume 950 of Lecture Notes in
Computer Science, pages 428–432. Springer-Verlag, 1995.
[73] Jan Camenisch and Markus Stadler. Efﬁcient group signature schemes for
large groups.
In Burton S. Kaliski Jr., editor, Advances in Cryptology–
CRYPTO ’97, volume 1294 of Lecture Notes in Computer Science, pages 410–
424. Springer-Verlag, 1997.
[74] Jan Camenisch and Markus Stadler.
Proof systems for general statements
about discrete logarithms. Technical Report TR 260, Institute for Theoretical
Computer Science, ETH Z¨urich, March 1997.
[75] Duncan Campbell. Interception capabilities 2000. Report to the Director Gen-
eral for Research of the European Parliament (Scientiﬁc and Technical Options
Assessment programme ofﬁce) on the development of surveillance technology
and risk of abuse of economic information, April 1999.
[76] Ran Canetti, Oded Goldreich, and Shai Halevi. The random oracle method-
ology, revisited. In Proc. 30th ACM Symp. on Theory of Computing. ACM
Press, 1998.
[77] Stefania Cavallar, Bruce Dodson, Arjen K. Lenstra, Walter Lioen, Peter L.
Montgomery, Brian Murphy, Herman te Riele, Karen Aardal, Jeff Gilchrist,

280
REFERENCES
G´erard Guillerm, Paul Leyland, Jo¨el Marchand, Francois Morain, Alec Muf-
fett, Chris Putnam, Craig Putnam, and Paul Zimmermann. Factorization of a
512-bit RSA modulus. To appear in: Proceedings of Eurocrypt 2000.
[78] Ann Cavoukian. Identity theft: Who’s using your name?
Information and
Privacy Commissioner of Ontario, Canada, June 1997.
[79] Ann Cavoukian, Catherine Johnston, and David Duncan. Smart, optical and
other advanced cards: How to do a privacy assessment. Joint report of the
Information and Privacy Commissioner of Ontario and the Advanced Card
Technology Association of Canada, 1996.
[80] CCITT. Recommendation X.500: The directory–overview of concepts, mod-
els and services, 1988.
[81] CCITT. Recommendation X.501: The directory–models, 1988.
[82] Center for Democracy and Technology. Policy vs. practice; a progress report
on federal government privacy notice on the world wide web, April 1999.
[83] Center for Public Integrity. Nothing sacred: The politics of privacy, July 1998.
ISBN: 1882583-12-4.
[84] M. Cerecedo, T. Matsumoto, and H. Imai. Efﬁcient and secure multiparty
generation of digital signatures based on discrete logarithms. IEICE Trans.
Fundamentals E76-A(4), pages 532–545, April 1993.
[85] Certicom. The elliptic curve cryptosystem for smart cards. Whitepaper no. 7,
May 1998.
[86] B. Chalks. Privacy enhancement for Internet electronic mail – part IV: Key
certiﬁcation and related services. RFC 1424-C, February 1993.
[87] D. Chaum. Showing credentials without identiﬁcation: Transferring signa-
tures between unconditionally unlinkable pseudonyms.
In J. Seberry and
J. Pieprzyk, editors, Advances in Cryptology–AUSCRYPT ’90, volume 453 of
Lecture Notes in Computer Science, pages 246–264. Springer-Verlag, 1990.
[88] D. Chaum. Achieving electronic privacy. Scientiﬁc American, 267(2):96–101,
August 1992.
[89] D. Chaum, C. Crepeau, and I. Damg˚ard. Multi-party unconditionally secure
protocols. In Proc. 20th ACM Symp. on Theory of Computing, pages 11–19,
Chicago, 1988. ACM Press.
[90] D. Chaum, A. Fiat, and M. Naor. Untraceable electronic cash. In S. Gold-
wasser, editor, Advances in Cryptology–CRYPTO ’88, volume 403 of Lecture
Notes in Computer Science, pages 319–327. Springer-Verlag, 1988.

REFERENCES
281
[91] David Chaum. Blind signatures for untraceable payments. In R.L. Rivest,
A. Sherman, and D. Chaum, editors, Advances in Cryptology–CRYPTO ’82,
pages 199–203. Plenum Press, 1983.
[92] David Chaum. Blind signature system. In D. Chaum, editor, Advances in
Cryptology–CRYPTO ’83, page 153, New York, 1984. Plenum Press.
[93] David Chaum. Security without identiﬁcation: Transaction systems to make
Big Brother obsolete. Communications of the ACM, 28(10):1030–1044, Oc-
tober 1985.
[94] David Chaum. Blind signature systems. U.S. Patent ser. no. 4,759,063, July
1988. Filed August 1983.
[95] David Chaum. Blind unanticipated signature systems. U.S. Patent ser. no.
4,759,064, July 1988. Filed October 1985.
[96] David Chaum. Privacy protected payments: Unconditional payer and/or payee
untraceability. In D. Chaum and I. Schaum¨uller-Bichl, editors, SMART CARD
2000, pages 69–93. Elsevier Science Publishers B.V. (North-Holland), 1989.
[97] David Chaum.
Card-computer moderated systems.
U.S. Patent ser. no.
4,926,480, May 1990. Filed May 1988.
[98] David Chaum.
One-show blind signature systems.
U.S. Patent ser. no.
4,987,593, January 1991. Filed April 1990. Continuation of abandoned ap-
plication Ser. No. 07/168,802, ﬁled March 1988.
[99] David Chaum.
Selected-exponent signature systems.
U.S. Patent ser. no.
4,996,711, February 1991. Filed June 1989.
[100] David Chaum. Unpredictable blind signature systems. U.S. Patent ser. no.
4,991,210, February 1991. Filed May 1989.
[101] David Chaum. Zero-knowledge undeniable signatures. In I.B. Damg˚ard, edi-
tor, Advances in Cryptology–EUROCRYPT ’90, volume 473 of Lecture Notes
in Computer Science, pages 458–464. Springer-Verlag, 1991.
[102] David Chaum. Designated-conﬁrmer signature systems. U.S. Patent ser. no.
5,373,558, December 1994. Filed May 1993.
[103] David Chaum. Optionally moderated transaction systems. U.S. Patent ser. no.
5,276,736, January 1994. Filed July 1992.
[104] David Chaum. David Chaum on electronic commerce: How much do you
trust Big Brother? IEEE Internet Computing, pages 8–16, November 1997.

282
REFERENCES
[105] David Chaum. Limited-traceability systems. U.S. Patent ser. no. 5,712,913,
January 1998. Filed February 1994.
[106] David Chaum, Ivan B. Damg˚ard, and Jeroen van de Graaf. Multiparty compu-
tations ensuring privacy of each party’s input and correctness of the result. In
Carl Pomerance, editor, Advances in Cryptology–CRYPTO ’87, volume 293
of Lecture Notes in Computer Science, pages 87–119. Springer-Verlag, 1988.
[107] David Chaum and Jan-Hendrik Evertse. A secure and privacy-protecting pro-
tocol for transmitting personal information between organizations. In A.M.
Odlyzko, editor, Advances in Cryptology–CRYPTO ’86, volume 263 of Lec-
ture Notes in Computer Science, pages 118–168. Springer-Verlag, 1987.
[108] David Chaum, Jan-Hendrik Evertse, and Jeroen van de Graaf. An improved
protocol for demonstrating possession of a discrete logarithm and some gen-
eralizations. In D. Chaum and W.L. Price, editors, Advances in Cryptology–
EUROCRYPT ’87, volume 304 of Lecture Notes in Computer Science, pages
127–141. Springer-Verlag, 1987.
[109] David Chaum and Torben Pryds Pedersen. Wallet databases with observers. In
Ernest F. Brickell, editor, Advances in Cryptology–CRYPTO ’92, volume 740
of Lecture Notes in Computer Science, pages 89–105. Springer-Verlag, 1992.
[110] David Chaum and Hans van Antwerpen. Undeniable signatures. In G. Bras-
sard, editor, Advances in Cryptology–CRYPTO ’89, volume 435 of Lecture
Notes in Computer Science, pages 212–216, 1990.
[111] David Chaum, Eug`ene van Heijst, and Birgit Pﬁtzmann. Cryptographically
strong undeniable signatures, unconditionally secure for the signer. Technical
report, University of Karlsruhe, February 1991. Interner Bericht 1/91.
[112] David Chaum, Eug`ene van Heijst, and Birgit Pﬁtzmann.
Cryptographi-
cally strong undeniable signatures, unconditionally secure for the signer. In
J. Feigenbaum, editor, Advances in Cryptology–CRYPTO ’91, volume 576 of
Lecture Notes in Computer Science, pages 470–484. Springer-Verlag, 1992.
[113] Lidong Chen. Access with pseudonyms. In Ed Dawson and Jovan Golic,
editors, Cryptography: Policy and Algorithms, number 1029 in Lecture Notes
in Computer Science, pages 232–243. Springer-Verlag, 1995.
[114] S. Chokhani and W. Ford. Internet public key infrastructure certiﬁcate policy
and certiﬁcation practices framework. Internet Draft of the PKIX Working
Group, work in progress, September 1997.
[115] Yang-hua Chu, Philip DesAutels, Brian LaMacchia, and Peter Lipp. PICS
signed labels (DSig) 1.0 speciﬁcation. W3C Recommendation, May 1998.

REFERENCES
283
[116] Yang-hua Chu, J. Feigenbaum, B. LaMacchia, P. Resnick, and M. Strauss.
REFEREE: Trust management for Web applications. World Wide Web Jour-
nal, 2:127–139, 1997.
[117] Roger Clarke. Chip-based ID: Promise and peril. Invited Address to a Work-
shop on ’Identity cards, with or without microprocessors: Efﬁciency versus
conﬁdentiality’, at the International Conference on Privacy, Montreal, 23-26
September 1997.
[118] Roger Clarke. Internet privacy concerns conﬁrm the case for intervention.
Communications of the ACM, 42(2), February 1999. Version of 14 October
1998.
[119] J. Cohen and M. Fischer. A robust and veriﬁable cryptographically secure
election scheme. In Proceedings of 26th Symposium on Foundations of Com-
puter Science, pages 372–382, New York, October 1985. IEEE Computer So-
ciety.
[120] Chris Connolly. Smart cards: Big Brother’s little helpers. Technical Report 66,
Privacy Committee of New South Wales, August 1995. Also in: First Aus-
tralian Computer Money Day, Newcastle, March 28, 1996.
[121] M.J. Coster. Some algorithms on addition chains and their complexity. Tech-
nical Report CS-R9024, Centrum voor Wiskunde en Informatica, June 1990.
[122] R.J.F. Cramer and T.P. Pedersen. Improved privacy in wallets with observers.
In Tor Helleseth, editor, Advances in Cryptology–EUROCRYPT ’93, volume
765 of Lecture Notes in Computer Science, pages 329–343. Springer-Verlag,
1994.
[123] Ronald Cramer, Ivan Damg˚ard, and Berry Schoenmakers. Proofs of partial
knowledge and simpliﬁed design of witness hiding protocols.
In Yvo G.
Desmedt, editor, Advances in Cryptology–CRYPTO ’94, volume 839 of Lec-
ture Notes in Computer Science, pages 174–187. Springer-Verlag, 1994.
[124] Ronald Cramer, Matthew Franklin, Berry Schoenmakers, and Moti Yung.
Multi-authority secret-ballot elections with linear work. In Ueli Maurer, edi-
tor, Advances in Cryptology–EUROCRYPT ’96, volume 1070 of Lecture Notes
in Computer Science, pages 72–83. Springer-Verlag, 1996.
[125] Ronald Cramer, Rosario Gennaro, and Berry Schoenmakers. A secure and
optimally efﬁcient multi-authority election scheme. In Walter Fumy, editor,
Advances in Cryptology–EUROCRYPT ’97, volume 1233 of Lecture Notes
in Computer Science, pages 103–118. Springer-Verlag, 1997. Also in: Euro-
pean Transactions on Telecommunications, Vol. 8, No. 5., September/OCtober
1997, pages 481-490.

284
REFERENCES
[126] I.B. Damg˚ard. Payment systems and credential mechanisms with provable
security against abuse by individuals. In S. Goldwasser, editor, Advances in
Cryptology–CRYPTO ’88, volume 403 of Lecture Notes in Computer Science,
pages 328–335. Springer-Verlag, 1988.
[127] Ivan Bjerre Damg˚ard. Practical and provably secure release of a secret. In Tor
Helleseth, editor, Advances in Cryptology–EUROCRYPT ’93, volume 765 of
Lecture Notes in Computer Science, pages 200–217. Springer-Verlag, 1994.
[128] George Davida, Yair Frankel, Yiannis Tsiounis, and Moti Yung. Anonymity
control in e-cash systems. In Rafael Hirschfeld, editor, Financial Cryptogra-
phy ’97, volume 1318. Springer-Verlag, February 1997.
[129] Simon Davies. Europe plans huge spy web. Telegraph Online, January 7,
1999.
[130] Simon Davies. Europe to U.S.: No privacy, no trade. Wired magazine, May
1998.
[131] Dorothy E. Denning. Descriptions of key escrow systems. Companion docu-
ment to [132]. Version of February 26, 1997.
[132] Dorothy E. Denning and Dennis K. Branstad. A taxonomy for key recovery
encryption systems. Version of May 11, 1997. Revision of “A Taxonomy of
Key Escrow Encryption,” Communications of the ACM, Vol. 39, No. 3, March
1996, pages 34–40.
[133] Department of Commerce of the National Telecommunications and Informa-
tion Administration. Elements of effective self regulation for protection of
privacy. Federal Register, 63(108):30729–30732,June 1998. Draft discussion
paper.
[134] Yvo Desmedt. Major security problems with the “unforgeable” (Feige)-Fiat-
Shamir proofs of identity and how to overcome them.
In SecuriCom ’88,
SEDEP Paris, pages 15–17, 1988.
[135] Yvo Desmedt, Claude Goutier, and Samy Bengio. Special uses and abuses
of the Fiat-Shamir passport protocol. In Carl Pomerance, editor, Advances in
Cryptology–CRYPTO ’87, volume 293 of Lecture Notes in Computer Science,
pages 16–20. Springer-Verlag, 1988.
[136] W. Difﬁe and M. Hellman. New directions in cryptography. IEEE Transac-
tions on Information Theory, IT-11(6):644–654, November 1976.
[137] Directorate-General XIII of the European Commission. Ensuring security and
trust in electronic communication; towards a European framework for digi-
tal signatures and encryption. Communication to the European Parliament,

REFERENCES
285
the Council, the Economic and Social Committee and the Committee of the
Regions. COM (97) 503, October 1997.
[138] DoD Public Key Infrastructure Program Management Ofﬁce. Public Key In-
frastructure roadmap for the Department of Defense. Version 3.0, October
1999.
[139] DoD Public Key Infrastructure Program Management Ofﬁce. X.509 Certiﬁ-
cate Policy for the Department of Defense. Version 5.0, December 1999.
[140] S. Dusse, P. Hoffman, B. Ramsdell, and J. Weinstein. S/MIME version 2
certiﬁcate handling. Network Working Group, Request for Comments no.
2312, March 1998.
[141] S. Dusse, P. Hoffman, R. Ramsdell, L. Lundblade, and L. Repka. S/MIME
version 2 message speciﬁcation. Network Working Group, Request for Com-
ments no. 2311, March 1998.
[142] Cynthia Dwork, Jeffrey Lotspiech, and Moni Naor.
Digital signets: Self-
enforcing protection of digital information.
In Proc. 28th ACM Symp. on
Theory of Computing. ACM Press, 1996.
[143] Electronic Privacy Information Center. Surfer beware: Personal privacy and
the Internet, June 1997.
[144] Electronic Privacy Information Center. Surfer beware II: Notice is not enough,
June 1998.
[145] Electronic Surveillance Task Force. Communications privacy in the digital
age. Interim Report of the Digital Privacy and Security Working Group, June
1997.
[146] Taher ElGamal. A public key cryptosystem and a signature scheme based on
discrete logarithms. IEEE Transactions on Information Theory, IT-31:469–
472, July 1985.
[147] Carl Ellison.
Establishing identity without certiﬁcation authorities.
6th
USENIX Security Symposium, San Jose, July 1996.
[148] Carl Ellison and Bruce Schneier. Ten risks of PKI: What you’re not being told
about Public Key Infrastructure. Computer Security Journal, 16(1), 2000.
[149] Carl M. Ellison. What do you need to know about the person with whom
you are doing business? Written testimony before the House of Science and
Technology Subcommittee Hearing on “Signatures in a Digital Age”, October
1997.

286
REFERENCES
[150] Carl M. Ellison. SPKI requirements. Internet draft, October 1998.
[151] Carl M. Ellison, Bill Frantz, Butler Lampson, Ron Rivest, Brian M. Thomas,
and Tatu Ylonen. SPKI certiﬁcate theory. Internet draft, work in progress,
November 1998.
[152] Carl M. Ellison, Bill Frantz, Butler Lampson, Ron Rivest, Brian M. Thomas,
and Tatu Ylonen.
Simple Public Key Certiﬁcate.
Internet draft, work in
progress, 1998.
[153] EPIC and Privacy International. Privacy and human rights: An international
survey of privacy laws and practice. Released by Global Internet Liberty Cam-
paign. Primary authors: David Banisar and Simon Davies, October 1998.
[154] Richard A. Epstein. Testimony before the Senate Judiciary Subcommittee on
the Constitution, Federalism and Property Rights. Hearings on “Privacy in the
Digital Age: Encryption and Mandatory Access”, March 1998.
[155] European Commission. Report of the Working Party on Illegal and Harmful
Content on the Internet, November 1996.
[156] European Commission. A European initiative in electronic commerce. Com-
munication to the European Parliament, the Council, the Economic and Social
Committee and the Committee of the Regions, April 1997. COM(97) 157.
[157] European Parliament. Directive 95/46/EC of 24 October 1995 on the protec-
tion of individuals with regard to the processing of personal data and on the
free movement of such data. Ofﬁcial Journal of the European Communities,
pages 31–45, November 1995.
[158] Carol H. Fancher. Smart cards: As potential applications grow, computers in
the wallet are making unobtrusive inroads. Scientiﬁc American, pages 40–45,
August 1996.
[159] Federal Bureau of Investigation. The Digital Telephony and Privacy Improve-
ment Act, March 1994.
[160] Federal Bureau of Investigation. The Digital Telephony and Privacy Improve-
ment Act (update), June 1994.
[161] Federal Card Services Task Force. Federal smart card implementation plan;
”the future is in the cards”. Electronic Processes Initiatives Committee, Jan-
uary 1998.
[162] Federal Deposit Insurance Corporation. Online privacy of consumer personal
information, August 1998.

REFERENCES
287
[163] Federal Public Key Infrastructure Steering Committee.
Access with trust.
Government Information Technology Services Board, Ofﬁce of Management
and Budget, September 1998.
[164] Federal Trade Commission. Consumer Identity Fraud meeting. Ofﬁcial Tran-
script Proceedings before the Federal Trade Commission, August 1996. Wash-
ington, D.C.
[165] Federal Trade Commission. Privacy online: A report to Congress, June 1998.
[166] Federation of European Direct Marketing. Codes of practice, direct marketing
and on-line services, November 1997.
[167] Jalal Feghhi, Peter Williams, and Jalil Feghhi. Digital Certiﬁcates : Applied
Internet Security. Addison-Wesley, October 1998. ISBN 0201309807.
[168] Uriel Feige, Amos Fiat, and Adi Shamir. Zero knowledge proofs of identity.
Journal of Cryptology, 1(2):77–94, 1988.
[169] Uriel Feige and Adi Shamir. Witness indistinguishable and witness hiding
protocols. In Proc. 22nd ACM Symp. on Theory of Computing, pages 416–
426, May 1990.
[170] Uriel Feige and Adi Shamir. Zero-knowledge proofs of knowledge in two
rounds. In G. Brassard, editor, Advances in Cryptology–CRYPTO ’89, volume
435 of Lecture Notes in Computer Science, pages 526–544. Springer-Verlag,
1990.
[171] Amos Fiat and Adi Shamir. How to prove yourself: Practical solutions to
identiﬁcation and signature problems. In A.M. Odlyzko, editor, Advances in
Cryptology–CRYPTO ’86, volume 263 of Lecture Notes in Computer Science,
pages 186–194. Springer-Verlag, 1987.
[172] Warwick Ford and Michael Baum. Secure Electronic Commerce : Building
the Infrastructure for Digital Signatures and Encryption. Prentice Hall, April
1997. ISBN: 0134763424.
[173] Yair Frankel, Yiannis Tsiounis, and Moti Yung. “Indirect discourse proofs”:
Achieving efﬁcient fair off-line e-cash. In Kwangjo Kim and Tsutomu Mat-
sumoto, editors, Advances in Cryptology–ASIACRYPT ’96, volume 1163 of
Lecture Notes in Computer Science, pages 286–300. Springer-Verlag, 1996.
[174] Alan O. Freier, Philip Karlton, and Paul C. Kocher. The SSL protocol, version
3.0. Internet draft, Netscape Communications, November 1996.
[175] Richard L. Fricker. The INSLAW octopus, March 1993.

288
REFERENCES
[176] A. Michael Froomkin. It came from Planet Clipper: The battle over crypto-
graphic key ”escrow”. Page 15 of the 1996 Law of Cyberspace issue of the
University of Chicago Legal Forum.
[177] A. Michael Froomkin. The essential role of trusted third parties in electronic
commerce. Oregon Law Review, 75(1):49–115, 1996.
[178] E. Fujisaki and Tatsuaki Okamoto. Practical escrow cash system. In Proceed-
ings of the 1996 Cambridge Workshop on Security Protocols, pages 33–48.
Springer-Verlag, June 1996.
[179] Eiichiro Fujisaki and Tatsuaki Okamoto. Statistical zero knowledge proto-
cols to prove modular polynomial relations. In Burton S. Kaliski Jr., editor,
Advances in Cryptology–CRYPTO ’97, volume 1294 of Lecture Notes in Com-
puter Science, pages 16–30. Springer-Verlag, 1997.
[180] Simson Garﬁnkel. The downside of digital IDs. Hotwired, October 9, 1996.
[181] Simson L. Garﬁnkel. 2048: Privacy, identity, and society in the next century.
Unpublished book, 1997.
[182] Dan Geer. Risk management is where the money is. Forum on Risks to the
Public in Computers and Related Systems, ACM Committee on Computers and
Public Policy, 20(6), November 1998.
[183] General Accounting Ofﬁce. Identity fraud: Information on prevalence, cost,
and Internet impact is limited. Brieﬁng Report, May 1998. GAO/GGD-98-
100BR.
[184] Rosario Gennaro, Stanislaw Jarecki, Hugo Krawczyk, and Tal Rabin. Robust
threshold DSS signatures. In N. Koblitz, editor, Advances in Cryptology–
CRYPTO ’96, volume 1109 of Lecture Notes in Computer Science, pages 354–
371. Springer-Verlag, 1996.
[185] Marc Girault. Self-certiﬁed public keys. In D.W. Davies, editor, Advances
in Cryptology–EUROCRYPT ’91, volume 547 of Lecture Notes in Computer
Science, pages 490–497. Springer-Verlag, 1992.
[186] Beth Givens. Identity theft – how it happens, its impact on victims, and legisla-
tive solutions. Presentation of the Privacy Rights Clearinghouse, May 1997.
[187] Brian Gladman, Carl Ellison, and Nicholas Bohm. Digital signatures, certiﬁ-
cates & electronic commerce. Version 1.1, June 1999.
[188] Global Network Navigator. The seduction of Crypto AG: How the NSA held
the keys to a top-selling encryption machine, 1997.

REFERENCES
289
[189] Ian Goldberg and Adam Shostack. Freedom network 1.0 architecture. Zero-
Knowledge Systems, Inc. white paper, November 1999.
[190] Ian Goldberg, David Wagner, and Eric A. Brewer. Privacy-enhancing tech-
nologies for the Internet. In COMPCON ’97. IEEE, February 1997.
[191] Oded Goldreich, Silvio Micali, and Avi Wigderson. Proofs that yield nothing
but their validity or all languages in NP have zero-knowledge proof systems.
Journal of the ACM, 38(1):691–729, 1991.
[192] Oded Goldreich, Birgit Pﬁtzmann, and Ronald L. Rivest. Self-delegation with
controlled propagation - or - what if you lose your laptop. In Hugo Krawczyk,
editor, Advances in Cryptology–CRYPTO ’98, Lecture Notes in Computer Sci-
ence, pages 153–168. Springer-Verlag, 1998.
[193] ShaﬁGoldwasser, Silvio Micali, and Charles Rackoff. The knowledge com-
plexity of interactive proof systems. SIAM Journal on Computing, 18(1):186–
208, February 1989.
[194] ShaﬁGoldwasser, Silvio Micali, and Ronald L. Rivest. A digital signature
scheme secure against adaptive chosen-message attacks. SIAM Journal on
Computing, 17(2):281–308, April 1988.
[195] David Goodman and Colin Robbins. Understanding LDAP & X.500. Dis-
tributed by the European Electronic Messaging Association, Version 2.0, Au-
gust 1997.
[196] Daniel M. Gordon.
A survey of fast exponentiation methods.
Journal of
Algorithms, 27:129–146, April 1998.
[197] J. Orlin Grabbe. The White House “Big Brother” data base & how Jackson
Stephens precipitated a banking crisis, 1997.
[198] Group of Experts on Information Security and Privacy. Draft background
report for the ministerial declaration in the protection of privacy on global
networks. Background report for the OECD Ministerial Conference on 7-9
October 1998 in Ottawa, Canada, September 1998.
[199] Group of Experts on Information Security and Privacy. Draft ministerial dec-
laration on the protection of privacy on global networks. Scheduled for trans-
mission to the OECD Ministerial Conference of 7–9 October 1998 in Ottawa,
Canada, September 1998.
[200] Richard A. Guida. Truth about PKI isn’t always common knowledge. GCN
Spotlight, May 3, 1999.

290
REFERENCES
[201] Louis C. Guillou and Jean-Jacques Quisquater. A practical zero-knowledge
protocol ﬁtted to security microprocessors minimizing both transmission and
memory. In C.G. G¨unther, editor, Advances in Cryptology–EUROCRYPT ’88,
volume 330 of Lecture Notes in Computer Science, pages 123–128. Springer-
Verlag, 1988.
[202] Louis Claude Guillou and Jean-Jacques Quisquater. A “paradoxical” identity-
based signature scheme resulting from zero-knowledge. In S. Goldwasser,
editor, Advances in Cryptology–CRYPTO ’88, volume 403 of Lecture Notes in
Computer Science, pages 216–231. Springer-Verlag, 1988.
[203] C. G¨ulc¨u and G. Tsudik. Mixing email with Babel. Symposium on Network
and Distributed System Security, San Diego, February 1996.
[204] Peter Gutmann. How to recover private keys for Microsoft Internet Explorer,
Internet Information Server, Outlook Express, and many others - or - where
do your encryption keys want to go today?, 1997.
[205] John Hagel and Mark Singer. Net Worth: Shaping Markets When Customers
Make the Rules. Harvard Business Press, 1999.
[206] Nicky Hager. Exposing the global surveillance system. CovertAction Quar-
terly, pages 11–17, 1996.
[207] Nicky Hager. Secret Power - New Zealand’s Role in the International Spy
Network. Craig Potton Publishing, Nelson, New Zealand, 1996.
[208] J. H˚astad, A.W. Schrift, and A. Shamir.
The discrete logarithm modulo a
composite hides O(n) bits. JCSS, 47(3):376–404, 1993.
[209] Pat Hensley, Max Metral, Upendra Shardanand, Donna Converse, and Mike
Myers. Proposal for an Open Proﬁling Standard. Submitted to W3C, June
1997.
[210] I.N. Herstein. Topics in Algebra. John Wiley & Sons, New York, 2 edition,
1975. ISBN 0-471-02371-X.
[211] Austin Hill and Gus Hosein. The privacy risks of public key infrastructures.
Presented at the 21st Data Protection Commissioner’s Conference in Hong
Kong, September 13, 1999.
[212] Robert Holmes. Privacy: Philosophical foundations and moral dilemmas. In
Proceedings of the 16th International Conference on Data Protection–Facing
Dilemmas, September 1994.
[213] John D. Howard. An Analysis Of Security Incidents On The Internet, 1989 –
1995. PhD thesis, Carnegie Mellon University, April 1997.

REFERENCES
291
[214] P. J. Hustinx. Platform for Privacy Preferences (P3P) and the Open Proﬁl-
ing Standard (OPS). Adopted by the Data Protection Working Party of the
European Union on 16 June, 1998.
[215] Computer Security Institute. 1998 computer crime and security survey. Con-
ducted by CSI with the participation of the San Francisco ofﬁce of the FBI’s
International Computer Crime Squad, March 1998.
[216] International Telecommunication Union. ITU-T recommendation X.509, in-
formation technology – open systems interconnection – the directory: Authen-
tication framework, June 1997.
[217] International Working Group on Data Protection in Telecommunications. Data
protection and privacy on the Internet – report and guidance. Adopted at the
20th Meeting in Berlin (“Budapest - Berlin Memorandum”), November 1996.
[218] ITU & ISO/IEC. Working document on amendments for certiﬁcate extensions,
January 1998. Collaborative meeting on the Directory, Phoenix Arizona.
[219] Markus Jakobsson, Kazue Sako, and Russell Impagliazzo. Designated veriﬁer
proofs and their applications. In Ueli Maurer, editor, Advances in Cryptology–
EUROCRYPT ’96, volume 1070 of Lecture Notes in Computer Science, pages
143–154. Springer-Verlag, 1996.
[220] Markus Jakobsson and Moti Yung. Revokable and versatile electronic money.
In Third ACM Conference on Computer and Communications Security, pages
76–87. ACM Press, 1996.
[221] Markus Jakobsson and Moti Yung. Applying anti-trust policies to increase
trust in a versatile e-money system. Financial Cryptography ’97, February
1997.
[222] Markus Jakobsson and Moti Yung. Distributed “magic ink” signatures. In
Walter Fumy, editor, Advances in Cryptology–EUROCRYPT ’97, volume 1233
of Lecture Notes in Computer Science, pages 450–464. Springer-Verlag, 1997.
[223] Don Johnson and Alfred Menezes. The Elliptic Curve Digital Signature Al-
gorithm (ECDSA). Technical Report CORR 99-34, University of Waterloo,
Canada, Dept. of C&O, August 1999.
[224] Ari Juels, Michael Luby, and Rafail Ostrovsky. Security of blind digital signa-
tures. In Burton S. Kaliski Jr., editor, Advances in Cryptology–CRYPTO ’97,
volume 1294 of Lecture Notes in Computer Science, pages 150–164. Springer-
Verlag, 1997.
[225] Burt Kaliski and Matt Robshaw. The secure use of RSA. CryptoBytes, 2(3),
1995.

292
REFERENCES
[226] C. Kaufman. DASS - distributed authentication security service. Network
Working Group, Request for Comments no. 1507, September 1993.
[227] Jane Kaufman Winn. Couriers without luggage: Negotiable instruments and
digital signatures. South Carolina Law Review, 49(4), 1998.
[228] Jane Kaufman Winn and Carl Ellison. Regulating the use of electronic au-
thentication procedures by US consumers in the global electronic marketplace.
Comment P994312 to the Federal Trade Commission, March 1999.
[229] John Kelsey, Bruce Schneier, and David Wagner. Protocol interactions and the
chosen protocol attack. Security Protocols Workshop, Cambridge, 1997.
[230] S. Kent. Privacy enhancement for Internet electronic mail – part II: Certiﬁcate-
based key management. RFC 1422, February 1993.
[231] Anthony L. Kimery. Big Brother wants to look into your bank account. Wired
Magazine, December 1993.
[232] Donald E. Knuth. Seminumerical Algorithms, volume 2 of The Art of Com-
puter Programming, pages 441–462. Addison-Wesley Publishing Company, 2
edition, 1981. ISBN 0-201-03822-6.
[233] N. Koblitz. A family of Jacobians suitable for discrete log cryptosystems. In
S. Goldwasser, editor, Advances in Cryptology–CRYPTO ’88, volume 403 of
Lecture Notes in Computer Science, pages 94–99. Springer-Verlag, 1988.
[234] Neil Koblitz. Elliptic curve implementation of zero-knowledge blobs. Journal
of Cryptology, 4(3):207–213, 1991.
[235] Paul Kocher. Quick introduction to Certiﬁcate Revocation Trees (CRTs). Val-
iCert whitepaper, 1997.
[236] Paul C. Kocher. Timing attacks on implementations of Difﬁe-Hellman, RSA,
DSS and other systems.
In N. Koblitz, editor, Advances in Cryptology–
CRYPTO ’96, volume 1109 of Lecture Notes in Computer Science, pages 104–
113. Springer-Verlag, 1996.
[237] Paul C. Kocher, Joshua Jaffe, and Benjamin Jun. Differential Power Analy-
sis. In Michael Wiener, editor, Advances in Cryptology–CRYPTO ’99, volume
1666 of Lecture Notes in Computer Science, pages 388–397. Springer-Verlag,
1999.
[238] Loren M. Kohnfelder. Towards a practical public-key cryptosystem. Master’s
thesis, MIT Laboratory for Computer Science, May 1978.

REFERENCES
293
[239] Oliver K¨ommerling and Markus G. Kuhn.
Design principles for tamper-
resistant smartcard processors. In Proceedings of the USENIX Workshop on
Smartcard Technology (Smartcard ’99), pages 9–20. USENIX Association,
May 1999. ISBN 1-880446-34-0.
[240] David W. Kravitz, Peter S. Gemmell, and Ernest F. Brickell. Off-line com-
patible electronic cash method and system. U.S. Patent ser. no. 5,832,089,
November 1998. Filed June 1995.
[241] Hugo Krawczyk and Tal Rabin. Chameleon hashing and signatures, Septem-
ber 1997.
[242] Markus Kuhn. Sicherheitsanalyse eines Mikroprozessors mit Busverschl¨us-
selung. Master’s thesis, Friedrich-Alexander-Universit¨at Erlangen-N¨urnberg,
July 1996.
[243] Art Kunkin. The Octopus Conspiracy: Has the U.S. been spying on your bank
accounts? World Wide Free Press, 1996.
[244] L. Lamport. Constructing digital signatures from a one-way function. Techni-
cal Report CSL–98, SRI International, October 1979.
[245] Peter Lenoir. Timing attack on classical RSA using Montgomery multiplica-
tions. Rump session of CRYPTO ’97, August 1997.
[246] Arjen K. Lenstra and Adi Shamir. Analysis and optimization of the TWINKLE
factoring device. To appear in: Proceedings of Eurocrypt 2000.
[247] Arjen K. Lenstra and Eric R. Verheul. Selecting cryptographic key sizes. Pro-
ceedings of the 2000 International Workshop on Practice and Theory in Public
Key Cryptography (PKC2000), Melbourne, Australia, January 2000. An ear-
lier version appeared in: PricewaterhouseCoopers Cryptographic Centre of
Excellence (CCE) Quarterly Journal, autumn ’99 issue.
[248] Garby Leon. Inslaw, the continuing caper, 1996.
[249] Lawrence Lessig and Paul Resnick. The constitutionality of mandated access
control: A model. Circulating Draft 4, April 14, 1999. Earlier version in:
Proceedings of the Telecommunications Policy Research Conference (1998).
[250] R. Levien and A. Aiken. Attack resistant trust metrics for public key certiﬁca-
tion. In Proceedings of the 7th USENIX Security Symposium. USENIX Press,
January 1998.
[251] Jamie Lewis. Public Key Infrastructure architecture. The Burton Group, Net-
work Strategy Report, July 1997.

294
REFERENCES
[252] Chae Hoon Lim and Pil Joong Lee. A key recovery attack on discrete log-
based schemes using a prime order subgroup. In Burton S. Kaliski Jr., editor,
Advances in Cryptology–CRYPTO ’97, volume 1294 of Lecture Notes in Com-
puter Science, pages 249–263. Springer-Verlag, 1997.
[253] Anna Lysyanskaya, Ronald Rivest, Amit Sahai, and Stefan Wolf. Pseudonym
systems. To appear in: Proceedings of SAC 99, 1999.
[254] Wayne Madsen. Crypto AG: The NSA’s Trojan Whore? CovertAction Quar-
terly, Winter 1998, no. 63.
[255] Gary T. Marx. Privacy and technology. Revision of paper in The World and I,
September 1990 and Telektronik January 1996.
[256] Masons Sollicitors and Privy Council Agents. Handbook on cost effective
compliance with Directive 95/46/EC, 1998.
[257] MasterCard & Visa. SET secure electronic transaction speciﬁcation, version
1.0. Book 1: Business Description, Book 2: Programmer’s Guide, Book 3:
Formal Protocol Deﬁnition, May 1997.
[258] Ueli M. Maurer and Stefan Wolf.
Difﬁe-Hellman oracles.
In N. Koblitz,
editor, Advances in Cryptology–CRYPTO ’96, volume 1109 of Lecture Notes
in Computer Science, pages 268–282. Springer-Verlag, 1996.
[259] Kevin S. McCurley. The discrete logarithm problem. In Proc. of Symposia
in Applied Mathematics: Cryptography and Computational Number Theory,
volume 42, pages 49–74. American Mathematical Society, August 1990.
[260] P. D. McDaniel and S. Jamin. Windowed certiﬁcate revocation. Technical Re-
port Technical Report CSE-TR-413-99, Dept. of Electrical Engineering and
Computer Science, University of Michigan, November 1999. Also in: Pro-
ceedings of IEEE Infocom 2000. IEEE, March 2000. Tel Aviv, Israel.
[261] P. D. McDaniel and A. Rubin. A response to ‘can we eliminate certiﬁcate
revocation lists?’. Technical Report Technical Report 99.8.1, AT&T Research
Labs, 1999. Also in: Financial Cryptography 2000, February 2000, Anguilla.
[262] Niall McKay. Europe is listening. Wired News, December 2, 1998.
[263] A.J. Menezes. Elliptic Curve Public Key Cryptosystems. Kluwer Academic
Publishers, New York, 1993.
[264] Alfred Menezes. Elliptic curve cryptosystems. RSA Laboratories, 1(2), 1995.
CryptoBytes.

REFERENCES
295
[265] Alfred Menezes, Scott Vanstone, and Tatsuaki Okamoto. Reducing elliptic
curve logarithms to logarithms in a ﬁnite ﬁeld. In Proc. 23rd ACM Symp. on
Theory of Computing, pages 80–89, New Orleans, 1991. ACM Press.
[266] Alfred J. Menezes, Paul C. van Oorschot, and Scott A. Vanstone. Handbook
of Applied Cryptography. CRC Press, New York, 1997.
[267] Ralph C. Merkle. A digital signature based on a conventional encryption func-
tion. In Carl Pomerance, editor, Advances in Cryptology–CRYPTO ’87, vol-
ume 293 of Lecture Notes in Computer Science, pages 369–378. Springer-
Verlag, 1988.
[268] Silvio Micali. Efﬁcient certiﬁcate revocation. Technical Report TM-542, Lab-
oratory of Computer Science, Massachusetts Institute of Technology, Novem-
ber 1995.
[269] Silvio Micali and Leonid Reyzin. Signing with partially adversarial hashing.
MIT Laboratory for Computer Science, Februari 27, 1998.
[270] M. Myers, R. Ankney, A. Malpani, S. Galperin, and C. Adams. Internet public
key infrastructure Online Certiﬁcate Status Protocol – OCSP. IETF Draft,
August 1998.
[271] David Naccache, David M’Ra¨ıhi, Serge Vaudenay, and Dan Raphaeli. Can
D.S.A. be improved? – complexity trade-offs with the digital signature stan-
dard. In Alfredo De Santis, editor, Advances in Cryptology–EUROCRYPT ’94,
volume 950 of Lecture Notes in Computer Science, pages 77–85. Springer-
Verlag, 1995.
[272] Yasushi Nakayama, Hidemi Moribatake, Masayuki Abe, and Eichiro Fujisaki.
An electronic money scheme; a proposal for a new electronic money scheme
which is both secure and convenient. IMES Discussion paper series, Bank of
Japan, June 1997. Discussion Paper No. 97-E-4.
[273] Moni Naor and Kobbi Nissim. Certiﬁcate revocation and certiﬁcate update.
Technical report, Weizmann Institute of Science, January 1999. Preliminary
version in: Proceedings of the 7th USENIX Security Symposium, 1998.
[274] Nathan Associates Inc. The cost of government-drivenkey escrow encryption,
June 1998. Prepared by the Family, Industry, and Community Economics
group, and commissioned by the Business Software Alliance.
[275] National Institute of Standards and Technology. FIPS PUB 140-2: Security re-
quirements for cryptographic modules. Federal Information Processing Stan-
dard Publication, U.S. Department of Commerce, January 11, 1994. (Super-
sedes FIPS PUB 140-1 of January 1994).

296
REFERENCES
[276] National Institute of Standards and Technology. Secure hash standard (SHA),
April 1995. Federal Information Processing Standards Publication, FIPS PUB
180-1.
[277] National Institute of Standards and Technology. Digital signature standard
(DSS). Federal Information Processing Standards Publication, FIPS PUB 186-
1, December 1998.
[278] National Research Council. Cryptography’s role in securing the information
society. Prepublication copy, May 1996. Kenneth Dam and Herbert Lin, Edi-
tors.
[279] National Security Agency. Threat and vulnerability model for key recovery.
Unofﬁcial NSA document, February 18, X3, 1998.
[280] L. O’Connor. An analysis of exponentiation based on formal languages. In
Jacques Stern, editor, Advances in Cryptology–EUROCRYPT ’99, Lecture
Notes in Computer Science. Springer, 1999.
[281] A. M. Odlyzko. Discrete logarithms in ﬁnite ﬁelds and their cryptographic
signiﬁcance. In T. Beth, N. Cot, and I. Ingemarsson, editors, Advances in
Cryptology–EUROCRYPT ’84, volume 209 of Lecture Notes in Computer Sci-
ence, pages 224–314. Springer-Verlag, 1985.
[282] Andrew Odlyzko. Discrete logarithms: The past and the future. Version of
July 18, 1999. To appear in: Designs, Codes, and Cryptography (1999).
[283] Andrew M. Odlyzko. The future of integer factorization. Technical Report 2,
RSA Laboratories, July 1995.
[284] Ofﬁce of Technology Assessment. Federal government information technol-
ogy: Electronic surveillance and civil liberties. U.S. Congress, Ofﬁce of Tech-
nology Assessment, OTA-CIT-293, Washington, DC: U.S. Government Print-
ing Ofﬁce, October 1985.
[285] Ofﬁce of Technology Assessment. Electronic record systems and individual
privacy, June 1986. OTA-CIT-296 (Washington, DC: U.S. Government Print-
ing Ofﬁce).
[286] Ofﬁce of Technology Assessment. Electronic surveillance in a digital age,
July 1995. OTA-BP-ITC-149 (Washington, DC: U.S. Government Printing
Ofﬁce).
[287] Ofﬁce of the Privacy Commissioner of Canada. Privacy framework for smart
card applications, July 1996.

REFERENCES
297
[288] Tatsuaki Okamoto. Provably secure and practical identiﬁcation schemes and
corresponding signature schemes. In Ernest F. Brickell, editor, Advances in
Cryptology–CRYPTO ’92, volume 740 of Lecture Notes in Computer Science,
pages 31–53. Springer-Verlag, 1992.
[289] Tatsuaki Okamoto and Kazuo Ohta. Divertible zero knowledge interactive
proofs and commutative random self-reducibility.
In J.-J. Quisquater and
J. Vandewalle, editors, Advances in Cryptology–EUROCRYPT ’89, volume
434 of Lecture Notes in Computer Science, pages 134–149. Springer-Verlag,
1989.
[290] Lewis Willian Oleinick. Computerized Governmental Database Systems con-
taining Personal Information and the Right to Privacy. PhD thesis, University
of Texas at Austin, December 1993.
[291] OMB Watch. A delicate balance: The privacy and access practices of federal
government World Wide Web sites, June 1998. ISBN: 1882583-12-4.
[292] Paul Van Oorschot, Warwick Ford, Stephen Hillier, and Josanne Otway.
Method for efﬁcient management of Certiﬁcate Revocation Lists (CRLs) and
update information. U.S. Patent ser. no. 5,699,431, December 1997. Filed
November 1995.
[293] OpenCard Consortium. OpenCard framework general information web docu-
ment. IBM Germany, October 1998. Second Edition.
[294] Organisation for Economic Co-operation and Development. Recommendation
of the Council concerning guidelines governing the protection of privacy and
transborder ﬂows of personal information, September 1980.
[295] Organisation for Economic Co-operation and Development. Cryptography
policy guidelines, March 1997.
[296] Organisation for Economic Co-operation and Development. Inventory of ap-
proaches to authentication and certiﬁcation in a global networked society.
Document of the Working Party on Information Security and Privacy, October
1999.
[297] PC/SC Workgroup. Interoperability speciﬁcation for ICCs and personal com-
puter systems, part 1–8. Revision 1.0, December 1997.
[298] Torben Pryds Pedersen. Distributed Provers and Veriﬁable Secret Sharing
Based on the Discrete Logarithm Problem. PhD thesis, Aarhus University,
March 1992. DAIMI PB–388.

298
REFERENCES
[299] Torben Pryds Pedersen. Non-interactive and information-theoretic secure ver-
iﬁable secret sharing.
In J. Feigenbaum, editor, Advances in Cryptology–
CRYPTO ’91, volume 576 of Lecture Notes in Computer Science, pages 129–
140. Springer-Verlag, 1992.
[300] Radia J. Perlman and Charles Kaufman. Method of issuance and revocation
of certiﬁcates of authenticity used in public key networks and other systems.
U.S. Patent ser. no. 5,261,002, November 1993. Filed March 1992.
[301] Birgit Pﬁtzmann. Fail-Stop Signature Schemes. PhD thesis, Institut f¨ur Infor-
matik, Universit¨at Hildesheim, May 1994.
[302] Birgit Pﬁtzmann and Ahmad-Reza Sadeghi. Self-escrowed cash against user
blackmailing. 4th International Conference on Financial Cryptography (FC
’00), to be published by Springer-Verlag, February 2000. An earlier German
version appeared in: Verl¨assliche IT-Systeme, GI-Fachtagung VIS ’99.
[303] Birgit Pﬁtzmann and Michael Waidner. How to break and repair a “provably
secure” untraceable payment system. In J. Feigenbaum, editor, Advances in
Cryptology–CRYPTO ’91, volume 576 of Lecture Notes in Computer Science,
pages 338–350. Springer-Verlag, 1992.
[304] Birgit Pﬁtzmann and Michael Waidner. Strong loss tolerance of electronic
coin systems. ACM Transactions on Computer Systems, 15(2):194–213, May
1997. Extended version appeared as: Hildesheimer Informatik-Berichte15/95,
University of Hildesheim, June 1995.
[305] David Pointcheval. Les Preuves de Connaissance et leurs Preuves de S´ecurit´e.
PhD thesis, University of Caen, December 1996.
[306] David Pointcheval and Jacques Stern.
Provably secure blind signature
schemes. In Kwangjo Kim and Tsutomu Matsumoto, editors, Advances in
Cryptology–ASIACRYPT ’96, volume 1163 of Lecture Notes in Computer Sci-
ence, pages 252–265. Springer-Verlag, 1996.
[307] David Pointcheval and Jacques Stern. Security proofs for signature schemes.
In Ueli Maurer, editor, Advances in Cryptology–EUROCRYPT ’96, volume
1070 of Lecture Notes in Computer Science, pages 387–398. Springer-Verlag,
1996.
[308] Patrick S. Poole. Echelon: America’s spy in the sky. Fourth installment in the
Free Congress Foundation/Center for Technology Policy’s The Privacy Papers
series, October 1998.
[309] Guillaume Poupard and Jacques Stern. Generation of shared RSA keys by two
parties. In Advances in Cryptology–ASIACRYPT ’91, volume 1514 of Lecture
Notes in Computer Science, pages 11–24. Springer-Verlag, 1998.

REFERENCES
299
[310] Guillaume Poupard and Jacques Stern. Security analysis of a practical “on
the ﬂy” authentication and signature generation. In Kaisa Nyberg, editor, Ad-
vances in Cryptology–EUROCRYPT ’98, volume 1403 of Lecture Notes in
Computer Science, pages 422–436. Springer-Verlag, 1998.
[311] Privacy Commissioner of the Commonwealth of Australia. Smart cards: Im-
plications for privacy. Information Paper No. 4, December 1995.
[312] Privacy International. Identity Cards: Frequently asked questions, August
1996.
[313] Privacy Working Group. Privacy and the National Information Infrastructure:
Principles for providing and using personal information, June 1995. Publi-
cation of the Information Policy Committee of the Information Infrastructure
Task Force.
[314] Public Interest Research Group. Mistakes do happen: Credit report errors
mean consumers lose, March 1998.
[315] Charles D. Raab, Colin J. Bennett, Robert M. Gellman, and Nigel Waters.
Application of a methodology designed to assess the adequacy of the level of
protection of individuals with regard to processing personal data: test of the
method of several categories of transfer - ﬁnal report. Study carried out for the
European Commission. Tender No. XV/97/18/D, September 1998.
[316] Cristian Radu, Rene Govaerts, and Joos Vandewalle. A restrictive blind sig-
nature scheme with applications to electronic cash. In P. Horster, editor, Pro-
ceedings of the IFIP TC6/TC11 international conference on communications
and multimedia security II, pages 196–207. Chapman and Hall, 1996.
[317] Cristian Radu, Rene Govaerts, and Joos Vandewalle. Efﬁcient electronic cash
with restricted privacy. In Rafael Hirschfeld, editor, Financial Cryptography
’97, volume 1318. Springer-Verlag, February 1997.
[318] Joel R. Reidenberg and Paul M. Schwartz. Data protection law and on-line
services: Regulatory responses. Study prepared as part of the project “Vie
priv´ee et soci´et´ee de l information: Etude sur les probl`emes pos´es par les
nouveaux services en ligne en mati`ere de protection des donn´ees et de la vie
priv´ee,” commissioned by Directorate General XV of the Commission of the
European Communities, December 1998.
[319] Lawrence A. Reinert and Stephen C. Luther. Tokeneer; user authentication
techniques using public key certiﬁcates. Part 1: Certiﬁcate options. National
Security Agency, Central Security Service, R22 INFOSEC Engineering, De-
cember 1997.

300
REFERENCES
[320] Lawrence A. Reinert and Stephen C. Luther. Tokeneer; authentication proto-
col for smartcards. National Security Agency, Central Security Service, R22
INFOSEC Engineering, January 1998.
[321] M. Reiter and S. Stubblebine. Toward acceptable metrics of authentication.
In Proceedings of the 1997 IEEE Symposium on Security and Privacy, pages
10–20, Oakland, CA, May 1997. IEEE.
[322] Michael K. Reiter and Aviel D. Rubin. Crowds: Anonymity for Web trans-
actions. ACM Transactions on Information and System Security, April 1998.
Also as: DIMACS 95-15, June 1997, AT&T Labs–Research, Murray Hill,
New Jersey.
[323] Ronald L. Rivest. Can we eliminate certiﬁcate revocation lists?
In Rafael
Hirschfeld, editor, Financial Cryptography ’98, volume 1465, February 1998.
[324] Ronald L. Rivest and Butler Lampson. SDSI - a Simple Distributed Security
Infrastructure. Working document deﬁning SDSI version 1.1., October 1996.
[325] Ronald L. Rivest, A. Shamir, and L. Adleman. A method for obtaining dig-
ital signatures and public-key cryptosystems. Communications of the ACM,
21(2):120–126, February 1978.
[326] Ronald L. Rivest and Robert D. Silverman. Are “strong” primes needed for
RSA? Submitted draft, November 1998.
[327] Marc Rotenberg. Communications privacy. Prepared Statement Before the
Subcommittee on Courts and Intellectual Property of the House Committee on
the Judiciary, United States of House of Representatives, Washington, D.C.,
March 26, 1998.
[328] Marc Rotenberg. On the European Union Data Directive and Privacy. Tes-
timony and Statement for the Record Before the Committee on International
Relations, U.S. House of Representatives, May 7, 1998.
[329] Marc Rotenberg, editor. The Privacy Law Sourcebook: United States Law,
International Law, and Recent Developments. Electronic Privacy Information
Center, 1998.
[330] RSA Laboratories. PKCS #6: Extended-certiﬁcate syntax standard. Version
1.5, November 1993.
[331] R. J. Rummel.
Death by Government: Genocide and Mass Murder in
the Twentieth Century. Transaction Publishers, New Jersey, 1994. ISBN:
1560009276.

REFERENCES
301
[332] Dick Russell.
Spook wars in cyberspace–is the FBI railroading Charles
Hayes?, June 1997.
[333] Tomas Sander and Amnon Ta-Shma.
Flow control: A new approach for
anonymity control in electronic cash systems. In Financial Cryptography ’99.
Springer-Verlag, February 1999.
[334] Alfredo De Santis, Giovanni De Crescenzo, Giuseppe Persiano, and Moti
Yung. On monotone formula closure of SZK. In Proc. 35th IEEE Symp.
on Foundations of Comp. Science, pages 454–465, Santa Fe, 1994.
[335] T. Satoh and K. Arako. Fermat quotients and the polynomial time discrete log
algorithm for anomalous elliptic curves. Preprint, 1997.
[336] Bruce Schneier and Adam Shostack. Breaking up is hard to do: Modeling
security threats for smart cards. First USENIX Symposium on Smart Cards,
USENIX Press, 1999.
[337] Claus P. Schnorr. Efﬁcient signature generation by smart cards. Journal of
Cryptology, 4:161–174, 1991.
[338] Claus P. Schnorr.
Security of 2t-root identiﬁcation and signatures.
In
N. Koblitz, editor, Advances in Cryptology–CRYPTO ’96, volume 1109 of
Lecture Notes in Computer Science, pages 143–156. Springer-Verlag, 1996.
[339] Claus P. Schnorr and Markus Jakobsson. Security of discrete log cryptosys-
tems in the random oracle + generic model. Presented at the Conference on
The Mathematics of Public-Key Cryptography, The Fields Institute, Toronto,
Canada, June 1999.
[340] Berry Schoenmakers.
Efﬁcient proofs of Or.
Unpublished manuscript,
September 1993.
[341] Berry Schoenmakers. An efﬁcient electronic payment system withstanding
parallel attacks. Technical Report CS-R9522, Centrum voor Wiskunde en In-
formatica, March 1995.
[342] Berry Schoenmakers. Sharp interval proofs and other predicates. Submitted
for publication, February 1997.
[343] Ari Schwartz. Smart cards at the crossroads: Authenticator or privacy invader?
At Home With Consumers, 19(3), December 1998.
[344] Scientiﬁc and Technological Options Assessment. An appraisal of technolo-
gies of political control. STOA Interim Study (PE 166.499), September 1998.

302
REFERENCES
[345] Adi Shamir. Factoring large numbers with the TWINKLE device. EURO-
CRYPT ’99 rump session talk. Extended abstract distributed on May 5, 1999.
[346] Adi Shamir. Identity-based cryptosystems and signature schemes. In G.R.
Blakley and D.C. Chaum, editors, Advances in Cryptology–CRYPTO ’84, vol-
ume 196 of Lecture Notes in Computer Science, pages 47–53. Springer-Verlag,
1985.
[347] Adi Shamir.
Memory efﬁcient variants of public-key schemes for smart
card applications.
In Alfredo De Santis, editor, Advances in Cryptology–
EUROCRYPT ’94, volume 950 of Lecture Notes in Computer Science, pages
445–449. Springer-Verlag, 1995.
[348] Adi Shamir and Nicko van Someren. Playing hide and seek with stored keys.
In Financial Cryptography ’99. Springer-Verlag, February 1999.
[349] Jenny Shearer and Peter Gutmann. Government, cryptography, and the right
to privacy. Journal of Universal Computer Science, 2(3), March 1996.
[350] Peter W. Shor. Algorithms for quantum computation: Discrete logarithms and
factoring. In Proc. 26th ACM Symp. on Theory of Computing, pages 124–134,
Santa Fe, 1994. IEEE.
[351] Victor Shoup. On the security of a practical identiﬁcation scheme. In Ueli
Maurer, editor, Advances in Cryptology–EUROCRYPT ’96, volume 1070 of
Lecture Notes in Computer Science, pages 344–353. Springer-Verlag, 1996.
[352] Victor Shoup. Lower bounds for discrete logarithms and related problems.
In Walter Fumy, editor, Advances in Cryptology–EUROCRYPT ’97, volume
1233 of Lecture Notes in Computer Science, pages 256–266. Springer-Verlag,
1997.
[353] Robert D. Silverman. A cost-based security analysis of symmetric and asym-
metric key lengths. News and Advice Bulletin, (13), April 2000.
[354] Gustavus J. Simmons. The Prisoners’ Problem and the subliminal channel.
In D. Chaum, editor, Advances in Cryptology–CRYPTO ’83, pages 51–67.
Plenum Press, 1984.
[355] Gustavus J. Simmons.
The subliminal channel and digital signature.
In
T. Beth, N. Cot, and I. Ingemarsson, editors, Advances in Cryptology–
EUROCRYPT ’84, volume 209 of Lecture Notes in Computer Science, pages
364–378. Springer-Verlag, 1985.
[356] Solveig Singleton. Privacy as censorship – a skeptical view of proposals to
regulate privacy in the private sector. Cato Policy Analysis, January 1998.

REFERENCES
303
[357] Nigel Smart. The discrete logarithm problem on elliptic curves of trace one.
Internal Note at Hewlett-Packard Laboratories, 1997.
[358] Smart Card Forum. Consumer privacy and smart cards - a challenge and an
opportunity. Prepared by the Legal & Public Policy Committee, 1997.
[359] South African Law Commission. Review of security legislation; the Intercep-
tion and Monitoring Prohibition Act (ACT no. 127 of 1992). Discussion Paper
78, Project 105, November 1998. ISBN 0-621-28847-0.
[360] Markus Stadler, Jean-Marc Piveteau, and Jan Camenisch. Fair blind signa-
tures. In Louis C. Guillou and Jean-Jacques Quisquater, editors, Advances
in Cryptology–EUROCRYPT ’95, volume 921 of Lecture Notes in Computer
Science, pages 209–219. Springer-Verlag, 1995.
[361] Standards Australia. Strategies for the implementation of a Public Key Au-
thentication Framework (PKAF) in Australia. PKAF Report, Miscellaneous
Publication SAA MP75-1996, October 1996.
[362] Statewatch. European Union & FBI launch global surveillance system. Report,
January 1997.
[363] Marc Strassman and Robert D. Atkinson. Jump-starting the digital economy
(with department of motor vehicles-issued digital certiﬁcates). Policy Brief-
ing of the Democratic Leadership Council & The Progressive Policy Institute,
June 1999.
[364] Res Strehle. Verschl¨usselt - Der Fall Hans Be¨uhler. Werd Verlag, Z¨urich,
1994. U.S. Library of Congress #: DS318.84.B84S77 1994.
[365] S. Stubblebine. Recent-secure authentication: Enforcing revocation in dis-
tributed systems. In Proceedings of the 1995 IEEE Symposium on Research in
Security and Privacy, pages 224–234, May 1995.
[366] Kathleen M. Sullivan. Testimony on behalf of Americans for Computer Pri-
vacy before the Senate Judiciary Subcommittee on the Constitution, Federal-
ism and Property Rights. Hearings on “Privacy in the Digital Age: Encryption
and Mandatory Access”, March 1998.
[367] Peter P. Swire.
Financial privacy and the theory of high-tech government
surveillance. Draft of September 24, 1998.
[368] Paul Syverson, D. Goldschlag, and M. Reed. Anynonymous connections and
onion routing. In Symposium on Security and Privacy. IEEE, 1997.

304
REFERENCES
[369] Kazuo Takaragi, Kunihiko Miyazaki, and Masashi Takahashi. A threshold
digital signature issuing scheme without secret communication. Presented at
the November 1998 meeting of the IEEE P1363 Working Group, November
1998.
[370] Task Force on Electronic Commerce. The protection of personal information –
building Canada s information economy and society. Industry Canada/Justice
Canada, January 1998.
[371] The Baltimore Sun. NSA’s crypto sting. Issue of December 10, 1995.
[372] The Washington Weekly. NSA, CIA, and U.S. NAVY all use PROMIS soft-
ware. Published in the March 31, 1997 issue.
[373] The Working Party on the Protection of Individuals with regard to the pro-
cessing of personal data. Recommendation 3/97; anonymity on the Internet.
Discussion paper adopted by the Working Party on 3 December 1997 at the
8th meeting.
[374] Yiannis S. Tsiounis. Efﬁcient Electronic Cash: New Notions and Techniques.
PhD thesis, Northeastern University, June 1997.
[375] United States Government. Privacy and electronic commerce. Draft, June
1998.
[376] U.S. Federal Reserve. Order approving notices to engage in nonbanking ac-
tivities. Press release, November 10, 1999.
[377] U.S. General Services Administration. Access Certiﬁcates for Electronic Ser-
vices (ACES). Draft Request for Proposals, Solicitation Number TIBA98003,
Ofﬁce of Governmentwide Policy, Federal Technology Service, March 1998.
[378] U.S. General Services Administration and Federal Telecommunications Ser-
vice and Ofﬁce of Information Security. Access Certiﬁcates for Electronic
Services (ACES). Request For Proposals, January 1999.
[379] Wim van Eck. Electromagnetic radiation from video display units: An eaves-
dropping risk? Computers & Security, 4, 1985.
[380] E. van Heijst and T.P. Pedersen. How to make efﬁcient fail-stop signatures.
In R.A. Rueppel, editor, Advances in Cryptology–EUROCRYPT ’92, volume
658 of Lecture Notes in Computer Science, pages 366–377. Springer-Verlag,
1993.
[381] Christine Varney. You call this self-regulation? Wired News, June 9, 1998.

REFERENCES
305
[382] Eric R. Verheul and Marc P. Hoyle. Tricking the Chaum-Pedersen protocol.
Submitted for publication, August 1997.
[383] J. von zur Gathen and M. N¨ocker. Exponentiation in ﬁnite ﬁelds: Theory
and practice. Proc. AAECC-12, pages 88–113, 1997. To appear in: Springer
LNCS.
[384] S. S. Wagstaff Jr. Greatest of the least primes in arithmetic progression hav-
ing a given modulus. Mathematics of Computation, 33(147):1073–1080, July
1979.
[385] M. Wahl. A summary of the X.500(96) user schema for use with LDAPv3.
Network Working Group, Request for Comments no. 2256, December 1997.
[386] Gerard Walsh. Review of policy relating to encryption technologies. Publica-
tion suppressed by the Australian Attorney-General’s Department in February
1997, censored version released to the Electronic Frontier Association under
the Freedom of Information Act, June 1997.
[387] Alan Westin. Privacy and Freedom. New York: Atheneum, 1967.
[388] A. Wheeler and L. Wheeler. Internet Public Key Infrastructure: PKI Account
Authority Digital Signature Infrastructure, November 1998.
[389] Michael J. Wiener. Cryptanalysis of short RSA secret exponents. IEEE Trans-
actions on Information Theory, 36:553–558, 1990.
[390] Michael J. Wiener.
Performance comparison of public-key cryptosystems.
CryptoBytes, 4(1):1–5, 1998.
[391] Julie L. Williams. Remarks before the Banking Roundtable Lawyers Coun-
cil, on the treatment of conﬁdential customer information and privacy issues,
Washington, D.C., May 8, 1998.
[392] Norman A. Willox. Identity theft: Authentication as a solution. National
Fraud Center, Inc., March 2000.
[393] World Wide Web Consortium. Platform for Privacy Preferences (P3P) Syntax
Speciﬁcation. Second public W3C Working Draft, edited by M. Marchiori and
D. Jaye, July 1998.
[394] Tom Wright. Smart cards. Publication of the Information and Privacy Com-
missioner of Ontario, April 1993.
[395] Eric C. Zimits and Christopher Montano. Public Key Infrastructure: Unlock-
ing the Internet’s economic potential. IStory, 3(2), April 1998. The Hambrecht
and Quist Internet Research Group.

306
REFERENCES
[396] Phil R. Zimmerman. The Ofﬁcial PGP User’s Guide. MIT Press, Boston,
1995.

Index
account, 189
account-based issuing protocol, 189
account-less issuing protocol, 190
ACES, 4, 13, 18, 25
active attack, 46
adaptively chosen formula attack, 96
adaptively chosen message attack, 79
addition chain, 51, 56
adversary, 46
algorithm, 42
adversary, 46
attacker, 45
active, 46
inﬁnitely powerful, 46, 92, 215–
216
passive, 46
black-box, 45, 48
honest, 45
interactive, 44
simulator, 68, 87, 100, 205
anonymity, 11, 31, 34, 190
anonymous
account, 190, 209, 216
attribute recertiﬁcation, 34, 145,
209
certiﬁcate issuing
drawbacks of, 190, 209
channel, 265–266
extortioner, 17, 230, 245, 251
issuing of smartcard, 252–253
refreshing of attributes, 190
updating of attributes, 34, 191,
212, 216
anonymous channel, 265–266
anonymous registration
drawbacks of, 26
atomic formula, 119
attack
active, 46
adversary, 46
fake-terminal, 224
model, 45–48
on digital signatures, 78–79
adaptively chosen message at-
tack, 79
existential forgery, 79
forgery from scratch, 79
key-only attack, 79
total break, 79
passive, 46
attacker, 45
active, 46
inﬁnitely powerful, 46, 92, 215–
216
passive, 46
attribute, 9
attribute certiﬁcate, 9–13
privacy dangers of, 20–25
recertiﬁcation of, 34, 145, 209
refreshing of, 190
SPKI, 12, 22, 27
SPKI/SDSI 2.0, 15

308
INDEX
Tokeneer, 12, 19
updating of, 34, 191, 212, 216
batch-veriﬁcation, 82, 85, 126, 128,
201
blind signatures, 27, 78, 81, 83, 208
drawbacks of, 28, 227
restrictive, 131–179
security in random oracle model,
81
technique of Okamoto and Ohta,
81, 83, 86
blinding-invariant, 33, 132
C-SET, 18
central database paradigm, 6
drawbacks of, 6–9
certiﬁcate
attribute, see attribute certiﬁcate
digital, see digital certiﬁcate
identity, see identity certiﬁcate
paper-based, 1, 208, 253
Certiﬁcate Authority, 3
certiﬁcate issuing protocol, 32
restrictive blind, 131–179
certiﬁcate showing protocol, 33
with selective disclosure, 27, 31,
35, 91–130
certiﬁed key pair, 86
extortion of, 17, 145, 230, 245,
251
certiﬁed public key, 86
challenge
of the veriﬁer, 71
self-chosen, 120, 128
semantics, 247
Chaum-Pedersen signatures, 175
chipcard, 6
collision-intractable function, 58–59
commitment
function, 50, 58, 61, 65, 76, 91
opening a, 50, 61, 65
common coin ﬂips, 230, 244, 245
drawbacks of preventing, 230
completeness, 67
composition of protocols, 46, 69
computation error channel, 221, 243
computing device
software-only, 15, 225
tamper-resistant
iButton, 18
smartcard, see smartcard
correction factor, 202–204
correlation-intractable function, 84
credential, 11, 28, 228
credit report accuracy, 8
CRL, 13, 17, 23, 209, 210, 250, 253
drawbacks of, 14
cryptographic action, 88
cryptographic coprocessor, 248
performance of, 248
cyberspace, 2
systematical monitoring of, 21
data leakage
computation error channel, 221,
243
Faraday Cage, 192, 226
halting channel, 221, 244
physical broadcast channel, 221
piggyback channel, 221, 227
subliminal channel, 37, 221, 227
inﬂow, 222, 239–240
outﬂow, 222, 240–242
timing channel, 221, 244
van Eck effect, 24, 221, 226
delta-CRL, 13
designated-veriﬁer proof, 191
Difﬁe-Hellman problem, 164
digital bearer certiﬁcate, 208, 253
digital certiﬁcate, 3, 86–89
attribute, 9–13
bearer, 208, 253
discarding, 2, 17, 26, 213
extortion, 17, 230, 245, 251

INDEX
309
identity, 3–5
issuing protocol, 32
account-based, 189
account-less, 190
restrictive blind, 131–179
lending, 211–212
remote, 251–252
limited-show, 13, 35, 197–208
overruling of, 208
long-lived, 14, 190
one-show, 197–207
dynamic, 201–207
static, 197–201
personal, 16, 26, 208, 211
privacy dangers of, 20–25
pseudonymous, 25, 26
public-key, 86
returning a, 250–251
revocation of, 13–15, 17, 20, 23
secret-key, 34, 87–89
short-lived, 13, 15, 19, 38, 190
showing protocol, 33
with selective disclosure, 27,
31, 35, 91–130
unlimited-show, 35, 208, 234
validation, 13, 190
digital pseudonym, 35, 189, 209
digital signature, 77–86
blind, see blind signatures
Chaum-Pedersen, 175
DSA, 171, 236, 249
elliptic curve DSA, 175
Guillou-Quisquater, 85
of the Fiat-Shamir type
in random oracle model, 80
restrictive blind, 131–179
RSA, 87
Schnorr, 83
signed proof, 80
unforgeability of, 77
discarding certiﬁcates, 2, 17, 26, 213
distance bounding, 252, 255
DL function, 51–56
DL-representation, 59
proving knowledge of, 71–75
trivial, 59
DLREP function, 59–62, 90
compared to RSAREP function,
65–66
proof of knowledge for, 71–75
drawbacks
of anonymous certiﬁcate issuing,
190, 209
of anonymous registration, 26
of blind signatures, 28, 227
of central database paradigm, 6–
9
of certiﬁcate revocation, 14
of computational privacy, 39
of designated-veriﬁerproofs, 192
of identity certiﬁcates, 10, 20–25,
31
of key escrow, 262–266
of preventing common coin ﬂips,
230
of privacy legislation, 257–259
of self-regulation, 259–262
of smartcard-only setting, 219–
224
DSA, 171, 236, 249
elliptic curve variant, 175
DSig, 12
ECDSA, 175
Echelon, 21
Enfopol, 21
European Privacy Directive, 25n
exact security, 48
extortion attack, 17, 230, 245, 251
protection against, 145, 265
factoring problem, 55, 57
fake-terminal attack, 224
Faraday Cage, 192, 226

310
INDEX
Fiat-Shamir type proof of knowledge,
79
forgery from scratch, 79
formula
atomic, 119
status of, 96
Fortezza, 4, 18
FPKI, 4, 24, 270
function, 42
collision-intractable, 58–59
commitment, 50, 58, 61, 65, 76,
91
correlation-intractable, 84
DL, 51
DLREP, 59–62
idealized, 49
inﬁnite collection, 49
index set for, 49
instance generator for, 49
invulnerable, 50
negligible, 43
non-negligible, 43
one-way, 49–58
sufﬁciently strong, 84
overwhelming, 43
RSA, 56–58
RSAREP, 62–65
generic description (of protocol), 71,
98, 113, 115, 202
group of prime order, 51–53
elliptic curve construction, 53
subgroup construction, 51
Guillou-Quisquaterproof of knowledge,
76
Guillou-Quisquater signatures, 85
halting channel, 221, 244
handheld device
PDA, 226
honest algorithm, 45
honest-veriﬁer zero-knowledge, 68
iButton, 18n
ICE, 21
idealized function, 49
identiﬁer, 3
identity certiﬁcate, 3–5
PGP, 5, 14, 18, 26
privacy dangers of, 20–25
SDSI 1.0, 12, 22, 26
X.509, 3, 210
ACES, 4, 13, 18, 25
C-SET, 18
Fortezza, 4, 18
FPKI, 4, 24, 270
PEM, 4
PKIX, 4, 13
S/MIME, 4
SET, 4, 18, 27, 248
identity fraud, 9, 10, 31
immunization, 162–171
index set, 49
indistinguishable
computationally, 44
perfectly, 43
statistically, 43
inﬂow, 222, 239–240
infomediaries, 261
initial witness, 71
master, 205
set, 120
instance generator, 49
invulnerable, 50
for the DL function, 51–54
for the DLREP function, 60–
61
for the RSA function, 56–57
for the RSAREP function, 63–
65
interactive algorithm, 44
Internet Archive, 21
interval proof, 129–130
intractable problem, 43
invulnerable instance generator, 50

INDEX
311
issuing protocol, 32
account-based, 189
account-less, 190
restrictive blind, 131–179
key escrow, 262–266
electronic cash, 264
electronic voting, 263
encryption, 264
key pair, 66
certiﬁed, 86
key set-up, 66, 70
key-only attack, 79
knowledge extractor, 67, 95, 111
language, 43
computationally indistinguishable,
44
perfectly indistinguishable, 43
statistically indistinguishable, 43
lending of certiﬁcate, 211–212
remote, 251–252
limited-show certiﬁcate, 13, 35, 197–
208
overruling of, 208
linkability, 26, 30, 35, 189, 190, 212,
253
long-lived certiﬁcate, 14, 190
long-term security, 201, 207
low-cost smartcards, 225, 248–250
metric of authentication, 5
move, 44
national ID card, 25
negligible function, 43
non-negligible function, 43
non-negligible uncertainty, 73
non-repudiation, 26, 189, 212–213
normalized form, 63
OCSP, 13
OECD Policy Guidelines, 25n
one-show certiﬁcate, 197–207
dynamic, 201–207
static, 197–201
one-time public key, 200
one-way function, 49–58
online certiﬁcate validation, 13
drawbacks of, 14
OCSP, 13
OpenCard Framework, 225
OPS, 12, 27
privacy dangers of, 27
outﬂow, 222, 240–242
overwhelming function, 43
overwhelming probability, 43
P3P, 12, 21, 27
privacy dangers of, 27
paper-based certiﬁcate, 1, 208, 253
passive attack, 46
PC/SC Workgroup, 225
PDA, 226
PEM, 4
perfect crime, 230
personal certiﬁcate, 16, 26, 208, 211
PGP, 5, 14, 18, 26
physical broadcast channel, 221
piggyback channel, 221, 227
PKI, 3
PKIX, 4, 13
Jonah implementation of, 4
PolicyMaker, 11
polylogarithmic running time, 80n
privacy
dangers, see privacy dangers
deﬁnition of, 20, 262
European Privacy Directive, 25n
legislation, 257–259
OECD Policy Guidelines, 25n
pragmatist, 31
ways to protect, 257–271
privacy dangers
of central databases, 7–9

312
INDEX
of digital certiﬁcates, 20–25
of key escrow, 262–266
of OPS/P3P, 27
of self-regulation, 259–262
of smartcards, 24, 219–223
privacy-enhancing technologies (ben-
eﬁts), 266–268
probability
negligible, 43
non-negligible, 43
overwhelming, 43
proof of knowledge, 66–71
completeness, 67
convert into digital signature, 79–
81
designated-veriﬁer, 191
Guillou-Quisquater, 76
knowledge extractor, 67, 95, 111
of the Fiat-Shamir type, 79
Schnorr, 73
signed, 80
soundness, 67
witness-hiding, 69
witness-indistinguishable, 68–69
zero-knowledge, 68
honest-veriﬁer, 68
protocol, 44
accepting view, 45
arbitrary composition of, 46, 69
certiﬁcate issuing, 32, 131–179
certiﬁcate showing, 33, 37, 91–
130
generic description of, 71, 98, 113,
115, 202
immunization, 162–171
move, 44
round, 44
transcript, 45
veriﬁcation relation, 44
view, 45
witness-indistinguishable, 68–69
zero-knowledge, 68
honest-veriﬁer, 68
pseudonymous certiﬁcates, 25, 26
drawbacks of, 26
PEM, 4
PGP, 26
SDSI, 12, 22, 26
X.509v3, 26
pseudorandom generator, 249
public key, 66
one-time, 200
self-certiﬁed, 88
public key infrastructure, 3
public-key certiﬁcate scheme, 86
random oracle model, 49, 50, 58, 80,
84
REFEREE, 12
refreshing a certiﬁcate, 190
remote lending, 251–252
repeated squaring, 51, 56
reputation, 7, 8, 26, 189, 211
restrictive blinding, 131–179
returning a certiﬁcate, 250–251
revocation, 13–15, 17, 20, 23, 38
CRL, 13, 17, 23, 209, 210, 250,
253
delta-CRL, 13
drawbacks of, 14
online validation, 13
round, 44
RSA
function, 56–58
signature scheme, 87
RSA-representation, 63
proving knowledge of, 75–76
trivial, 63
RSAREP function, 62–65
compared to DLREP function, 65–
66
proof of knowledge for, 75–76
running time, 43
polylogarithmic, 80n

INDEX
313
superpolynomial, 43n
S/MIME, 4
Schnorr proof of knowledge, 73
Schnorr signature scheme, 83
SDSI, 12, 22, 26
secret key, 66
secret-key certiﬁcate scheme, 87
delegation strategy in, 185–189
simulator in, 87
security
long-term, 201, 207
parameter, 42
reduction, 48–49
exact, 48
optimal tightness, 48
overhead factor, 48
tight, 48
self-certiﬁed public key, 88
self-regulation, 259–262
SET, 4, 18, 27, 248
C-SET, 18
short-lived certiﬁcate, 13, 15, 19, 38,
190
showing protocol, 33
t out of u, 128
adaptively chosen formula attack,
96
Boolean formula, 119–128
interval enclosure, 129–130
linear inequality, 108–119
linear relation, 93–108
polynomial relation, 129
with selective disclosure, 27, 31,
35, 91–130
signed message, 77
signed proof, 80, 102
unforgeability of, 77
unmodiﬁability of, 101
simulator
in secret-key certiﬁcates, 87
in zero-knowledgeproofs, 68, 100
simultaneous repeated squaring, 62, 63
Smart Cards for Windows, 225
smartcard, 15–19, 38, 219–255
anonymous issuing of, 252–253
low-cost, 225, 248–250
non-privacy dangers of, 19, 223–
224
physical attacks, 29, 228, 253
privacy dangers of, 24, 219–223
security advantages of, 16–18
Smart Cards for Windows, 225
standardization
OpenCard Framework, 225
PC/SC Workgroup, 225
tamper-resistance, 223, 228
with cryptographic coprocessor,
248
performance of, 248
smartcard-only paradigm
drawbacks of, 219–224
software-only computing device, 15,
225
soundness (of proof of knowledge), 67
SPKI, 12, 22, 27
SPKI/SDSI 2.0, 15
status (of a formula), 96
subliminal channel, 37, 221, 227
inﬂow, 222, 239–240
outﬂow, 222, 240–242
sufﬁciently strong one-way function,
84
superpolynomial running time, 43n
surveillance, 20
system parameters, 66
properly formed, 54, 57, 70
tamper-resistant computing device, 16–
18, 220, 221
iButton, 18
smartcard, see smartcard
timing channel, 221, 244
TLS, 12

314
INDEX
Tokeneer, 12, 19
traceability, 28, 31, 226, 228, 253
transcript (of protocol), 45
trust management system
PolicyMaker, 11
REFEREE, 12
uncertainty (non-negligible), 73
unforgeabilityof signature scheme, 77
unlimited-showcertiﬁcate, 35, 208, 234
unlinkability, 26, 30, 31, 189, 190, 212,
253
self-revocable, 266
unmodiﬁability (of signed proof), 101
untraceability, 28, 31, 226, 228, 253
self-revocable, 266
updating a certiﬁcate, 191
van Eck effect, 24, 221, 226
vector addition chain, 62
veriﬁcation relation, 44
compound, 82, 205–207
view, 45
accepting, 45
aggregate, 47
witness
extractor, 69
initial, 71
witness-hiding proof of knowledge, 69
witness-indistinguishableprotocol, 68–
69
X.500, 4, 210
X.501, 9
X.509, 3, 210
ACES, 4, 13, 18, 25
extensions, 12
Fortezza, 4, 18
FPKI, 4, 24, 270
PEM, 4
PKIX, 4, 13
S/MIME, 4
SET, 4, 18, 27, 248
C-SET, 18
version 1, 4, 13
version 2, 4, 13
version 3, 4, 10, 12, 13, 210
X9, 7
X9.55, 4
X9.57, 12
zero-knowledge, 68
honest-veriﬁer, 68
simulator, 68, 100
zeroization, 16

Curriculum Vitae
Stefan Brands was born in Utrecht, the Netherlands. He completed his undergraduate
studies in Mathematics at the University of Utrecht in August of 1991, and was afﬁl-
iated from February 1992 until February 1996 with the Center for Mathematics and
Computer Science (CWI) in Amsterdam. The electronic cash system he published
in April 1993 (and improved and extended later on) forms the basis of a full-ﬂedged
system implemented and tested by CAFE, an ESPRIT project with 13 academic and
commercial member organizations from seven European countries.
In 1995 and 1996 Stefan was invited to present his work at various research in-
stitutes abroad, including ETH (Z¨urich), MIT (Boston), ENS (Paris), AT&T (New
Jersey), IBM (Z¨urich), Johann Wolfgang Goethe–University (Frankfurt am Main),
University of San Diego (UCSD), and University of Hildesheim. He also served
on the program committees of Eurocrypt ’96, CARDIS 1996, the second USENIX
Workshop on Electronic Commerce, and Eurocrypt ’99.
Stefan is the holder of eight international patents on electronic cash and digital
certiﬁcates.
In January 1997 he joined DigiCash in Amsterdam as a senior cryptographer and
its Distinguished Scientist, as part of a licensing arrangement aimed at implement-
ing and commercializing his electronic cash techniques. He resigned a year before
DigiCash went bankrupt, leaving the company in June 1998.
Following this, Stefan completed his dissertation and worked on an upcoming
book on electronic money. His doctorate was awarded on October 4, 1999, by Eind-
hoven University of Technology. The Thesis Reading Committee consisted of Pro-
fessors Ron Rivest, Claus Schnorr, and Adi Shamir.
In February 2000, Stefan made an exclusive licensing arrangement with Zero-
Knowledge Systems, Inc., and joined the company as a senior cryptographer and
its Distinguished Scientist. He currently lives and works in Montreal and can be
reached at brands@zeroknowledge.com or through his personal homepage
www.xs4all.nl/∼brands.


