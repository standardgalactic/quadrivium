
Stochastic Thermodynamics


Stochastic Thermodynamics
An Introduction
LUCA PELITI &
SIMONE PIGOLOTTI
PRINCETON UNIVERSITY PRESS
Princeton and Oxford

Copyright c⃝2021 by Princeton University Press
Princeton University Press is committed to the protection
of copyright and the intellectual property our authors entrust
to us. Copyright promotes the progress and integrity of
knowledge. Thank you for supporting free speech and the
global exchange of ideas by purchasing an authorized edition
of this book. If you wish to reproduce or distribute any part of
it in any form, please obtain permission.
Requests for permission to reproduce material from this work
should be sent to permissions@press.princeton.edu
Published by Princeton University Press,
41 William Street, Princeton, New Jersey 08540
6 Oxford Street, Woodstock, Oxfordshire OX20 1TR
press.princeton.edu
All Rights Reserved
Library of Congress Control Number 2021936619
ISBN 978-0-691-20177-1
ISBN (e-book) 978-0-691-21552-5
British Library Cataloging-in-Publication Data is available
Editorial: Ingrid Gnerlich and Arthur Werneck
Production Editorial: Jill Harris
Text Design: Carmina Alvarez
Jacket Design: Wanda España
Production: Jacqueline Poirier
Publicity: Matthew Taylor and Amy Stewart
Copyeditor: Jennifer McClain
Jacket art: Shutterstock
This book has been composed in Minion Pro and Universe LT Std
Printed on acid-free paper. ∞
Printed in the United States of America
10 9 8 7 6 5 4 3 2 1

Wenn sich die hier zu behandelnde Bewegung samt den für sie
zu erwartenden Gesetzmäßigkeiten wirklich beobachten läßt,
so ist die klassische Thermodynamik schon für mikroskopisch
unterscheidbare Räume nicht mehr als genau gültig anzusehen
und es ist dann eine exakte Bestimmung der wahren Atomgröße
möglich.
If the motion discussed here can actually be observed (together
with the laws relating to it that one would expect to ﬁnd), then
classical thermodynamics can no longer be looked upon as
applicable with precision to bodies even of dimensions distin-
guishable in a microscope, and an exact determination of the
actual atomic dimensions is then possible.
—Albert Einstein, Ann. Physik 322 (8): 549 (1905)


Contents
Foreword
xi
Preface
xiii
Acknowledgments
xv
Notation
xvii
CHAPTER 1
Motivation
1
1.1
What is stochastic thermodynamics?
1
1.2
Why does it work and why is it useful?
3
1.3
Plan of the work
3
CHAPTER 2
Basics
6
2.1
Thermodynamics
6
2.2
Thermodynamic efﬁciency
11
2.3
Free energy and nonequilibrium free energy
12
2.4
Statistical mechanics
15
2.5
Stochastic dynamics
19
2.6
Master equations
21
2.7
Trajectories of master equations
24
2.8
Fokker-Planck equation (*)
26
2.9
Langevin equation (*)
29
2.10 Information
32
2.11 Further reading
35
2.12 Exercises
36
CHAPTER 3
Stochastic Thermodynamics
38
3.1
The system
38
3.2
Work and heat in stochastic thermodynamics
40
3.3
Mesoscopic and calorimetric heat (*)
42
3.4
ATP hydrolysis by myosin
44
3.5
General reservoirs
46
3.6
Stochastic entropy
47

viii
Contents
3.7
Stochastic entropy and entropy production in a manipulated
two-level system
48
3.8
Average entropy production rate
50
3.9
Network theory of nonequilibrium steady states (*)
51
3.10 Stochastic chemical reactions
53
3.11 Linear response theory (*)
55
3.12 More on coarse graining (*)
58
3.13 Continuous systems (*)
62
3.14 Further reading
64
3.15 Exercises
65
CHAPTER 4
Fluctuation Relations
67
4.1
Irreversibility and entropy production
67
4.2
Integral ﬂuctuation relation
69
4.3
Dragged particle on a ring
70
4.4
Back to linear response theory (*)
73
4.5
Detailed ﬂuctuation relation
76
4.6
The Jarzynski and Crooks relations
78
4.7
Instantaneous quench
80
4.8
Fluctuation relations in practice
81
4.9
Adiabatic and nonadiabatic entropy production
and the Hatano-Sasa relation
82
4.10 Systems with odd-parity variables
84
4.11 Trajectory probability for Langevin equations (*)
86
4.12 Fluctuation relation for the Langevin equation (*)
87
4.13 Brownian particle in a time-dependent harmonic
potential (*)
89
4.14 Brownian motion with inertia (*)
92
4.15 Hamiltonian systems (*)
94
4.16 Further reading
100
4.17 Exercises
101
CHAPTER 5
Thermodynamics of Information
104
5.1
A brief history
104
5.2
Back to nonequilibrium free energy
106
5.3
Information in stochastic thermodynamics
107
5.4
The Sagawa-Ueda relation
109
5.5
The Mandal-Jarzynski machine
110
5.6
Copying information
112
5.7
Information cost in sensing
115
5.8
Information reservoirs
122
5.9
Fluctuation relations with information reservoirs (*)
125
5.10 Further reading
127
5.11 Exercises
128
CHAPTER 6
Large Deviations: Theory and Practice
130
6.1
Large deviations in a nutshell
130
6.2
Currents, trafﬁc, and other observables
134
6.3
Large deviations and ﬂuctuation relations
137

Contents
ix
6.4
Fluctuation theorem for currents (*)
138
6.5
Tilting
140
6.6
Michaelis-Menten reaction scheme
142
6.7
Fluctuation relations in a model of kinesin (*)
146
6.8
Cloning (*)
151
6.9
Levels of large deviations (*)
154
6.10 Further reading
158
6.11 Exercises
158
CHAPTER 7
Experimental Applications
160
7.1
The hairpin as a paradigm
160
7.2
A simpler model
161
7.3
Equilibrium free energies from nonequilibrium
manipulations
162
7.4
Maxwell demons
167
7.5
Landauer principle
167
7.6
Further reading
171
CHAPTER 8
Developments
172
8.1
Stochastic efﬁciency
172
8.2
Uncertainty relations
176
8.3
Applications of uncertainty relations
180
8.4
First-passage times
181
8.5
Fully irreversible processes
185
8.6
Optimal protocols
187
8.7
Martingales
191
8.8
Random time
195
8.9
Population genetics
197
8.10 Further reading
202
8.11 Exercises
203
CHAPTER 9
Perspectives
204
Appendixes
207
A.1
Convex functions and the Jensen inequality
207
A.2
Legendre transformation
211
A.3
Probabilities and probability distributions
213
A.4
Generating functions and cumulant generating
functions
214
A.5
Ergodic properties of Markov processes
217
A.6
Gillespie algorithm
219
A.7
Derivation of the Fokker-Planck equation
220
A.8
Ito formula and Stratonovich-Ito mapping
222
A.9
Basis of the cycle space
224
A.10 Actions and trajectory probabilities for
Langevin equations
225
A.11 The Bennett-Crooks estimator for the
free-energy difference
226

x
Contents
A.12 Cauchy-Schwarz inequality
228
A.13 Bound for the current rate function
229
Bibliography
233
Author Index
241
Index
245

Foreword
If Sadi Carnot’s Reﬂections on the Motive Power of Fire (1824) marks the starting point
of thermodynamics as a ﬁeld of scientiﬁc inquiry, then this ﬁeld is now nearly two cen-
turies old. Its key elements—heat and work, entropy, thermodynamic potentials, the
ﬁrst and second laws—were in place by the late nineteenth century. This historical fact
ofen conveys the sense that, while thermodynamics provides an undeniably powerful
framework for scientists and engineers, there is nothing new to discover within the ﬁeld
itself.
Another familiar conception about thermodynamics is that it is inherently a ﬁeld
about macroscopic systems. In this view, statistical mechanics seeks to explain how
thermodynamic properties arise from the interactions of vastly many atoms and
molecules, but the properties themselves, and notions such as heat, work, and entropy,
are inherently macroscopic.
The past few decades have seen much exciting research that goes against the grain
of these two conceptions of thermodynamics. A growing community of physicists and
chemists, theorists and experimentalists, take seriously the idea of applying thermo-
dynamic principles to individual microscopic systems. Some of the impetus for this
development comes from biology, where experimental data has led to a distinctly
mechanical picture of biomolecules such as kinesin, myosin, and ATP synthase. These
and similar molecules and molecular complexes are now frequently discussed, not
generically as chemicals interacting with other chemicals within a living cell, but more
pointedly as devices that consume fuel while they proceed through operating cycles that
are not far diﬀerent from those of macroscopic machines. Indeed, these biomolecules
are ofen referred to as molecular machines or motors.
A parallel development has been the discovery of far-from-equilibrium ﬂuctuation
relations that express the second law of thermodynamics in a manner that focuses on
random ﬂuctuations, revealing unexpected features and symmetries of these ﬂuctua-
tions. These relations, together with more recent developments, contradict the notion
that everything important in thermodynamics was discovered long ago.
Stochastic thermodynamics has emerged as a framework for describing how ther-
modynamic laws apply to individual mesoscopic systems, particularly away from
equilibrium. The very name of this framework acknowledges that randomness is a
deﬁning feature of dynamics at these scales, where characteristic energies are on the
order of kBT. A central aim of stochastic thermodynamics is to deﬁne basic thermody-
namic concepts, such as heat, work, and entropy production, at the level of individual,
randomly ﬂuctuating trajectories.
The tools of stochastic thermodynamics are now widely applied in a variety of phys-
ical, chemical, and biological contexts, and there is a vigorous push to extend the ﬁeld

xii
Foreword
into the realm of quantum mechanics. While excellent review and pedagogical articles
have appeared, the need exists for a textbook on stochastic thermodynamics, at a level
appropriate for a graduate-level course or as a reference for researchers wishing to enter
the ﬁeld.
In Stochastic Thermodynamics: An Introduction, Luca Peliti and Simone Pigolotti—
both active scientists who have made important contributions to the ﬁeld—aim to
“provide a pedagogical introduction to stochastic thermodynamics for graduate stu-
dents in physics.” They succeed in accomplishing this goal and more, as this book
provides a comprehensive reference to the most important facets of current research
related to stochastic thermodynamics.
Afer a review of background material, the book lays out the central features of
stochastic thermodynamics in chapter 3 and then discusses ﬂuctuation relations in
chapter 4. These chapters represent the original core of the ﬁeld, and they highlight a
key concept: the connection between thermodynamic irreversibility and statistical irre-
versibility. The former is quantiﬁed in terms of entropy production or dissipated work;
the latter by comparing the probability of observing a particular sequence of events
with that of observing the same events in time-reversed order. It is this connection
that allows one to assign entropy production to individual, ﬂuctuating trajectories.
The book’s subsequent chapters are devoted to an array of topics, including the ther-
modynamic implications of mesoscale information processing, large deviation theory,
experimental investigations of stochastic thermodynamics, and the recently discovered
thermodynamic uncertainty relations. Each chapter ends by pointing interested readers
to further references, and provides exercises that are indispensable for readers wishing
to master the subject.
Stochastic Thermodynamics: An Introduction provides an excellent and welcome
resource for the graduate student wishing to learn about this active new ﬁeld, for the
lecturer teaching a course on the subject, and for the researcher seeking a detailed
reference for the current state of the ﬁeld. As Peliti and Pigolotti acknowledge in the
preface, stochastic thermodynamics has developed rapidly. I expect that as it continues
to develop, this book will serve as a standard reference and introduction to the ﬁeld.
Christopher Jarzynski
College Park, Maryland, March 2020

Preface
The mesoscopic world is attracting a growing scientiﬁc interest. Technological minia-
turization permits the construction of smaller and smaller devices, whose performance
is limited by thermal ﬂuctuations. In biology, proteins are a remarkable example of
machines performing complex tasks at the nanoscale. Stochastic thermodynamics has
emerged as a powerful framework to describe the thermodynamics of systems at these
scales.
We are both interested in statistical mechanics and theoretical biophysics, and we
have quite naturally ended up gravitating toward stochastic thermodynamics. During
this journey, we have witnessed that more and more junior researchers are becom-
ing interested in stochastic thermodynamics and its applications. However, these
researchers face a substantial entry barrier. One reason for this diﬃculty is that stochas-
tic thermodynamics has developed really quickly, particularly following important
breakthroughs such as the discovery and understanding of ﬂuctuation theorems.
We have confronted this problem by teaching stochastic thermodynamics at the
graduate level. This book gathers the fruits of our experience. We hope that our book
eases approaching stochastic thermodynamics and facilitates cross-fertilization with
other ﬁelds of physics and biology.
Luca Peliti and Simone Pigolotti
Onna, Okinawa, October 2019


Acknowledgments
This book would not have been possible without many discussions we had over the
course of the years with our collaborators, friends, and colleagues: Erik Aurell, Andre
Barato, John Bechoefer, Stefano Bo, Daniel Busiello, Antonio Celani, Massimo Cencini,
Davide Chiuchiù, Massimiliano Esposito, Jean-Baptiste Fournier, Alberto Imparato,
Jean-François Joanny, Frank Jülicher, Ryoichi Kawai, Tetsuya J. Kobayashi, Florent
Krzakala, Jorge Kurchan, David Lacoste, Amos Maritan, Carlos Mejía-Monasterio,
Paolo Muratore-Ginanneschi, Izaak Neri, Matteo Polettini, Jacques Prost, Lorenzo
Pucci, Andrea Puglisi, Riccardo Rao, Édgar Roldán, Lamberto Rondoni, Pablo Sartori,
Udo Seifert, Ken Sekimoto, Gatien Verley, Angelo Vulpiani, and Frédéric van Wijlandt.
These discussions signiﬁcantly deepened our understanding of stochastic thermody-
namics and motivated us to write this book. We fondly remember Christian van den
Broeck, whose untimely death saddened us deeply. LP is grateful to Stefano Ruﬀo and
Lamberto Rondoni for inviting him to lecture on the subject, respectively at SISSA and
at the Turin Politecnico, an opportunity that helped structure the pedagogical trail we
followed in this book.
We are especially grateful to Massimiliano Esposito, Akira Kawano, Andrea Puglisi,
Édgar Rolda´n, Pablo Sartori, José Vila Chã Losa, and in particular to John Bechoe-
fer, Giuseppe Gaeta, Ken Sekimoto, and Shoichi Toyabe for a critical reading of our
manuscript. Special thanks are due to two anonymous readers and to Todd Gingrich
for their careful reading and precious suggestions. We thank Bill Stern for proofread-
ing and especially Jennifer McClain for copyediting. We feel deeply honored by Chris
Jarzynski, who wrote the foreword to our book.
We have beneﬁted all along from the assistance and suggestions of Princeton Uni-
versity Press. We warmly thank Arthur Werneck, Jill Harris, and in particular Ingrid
Gnerlich, who closely followed this project from the beginning.
SP wishes to dedicate this book to Viola, who was born halfway through the writing
and has been a constant source of joy ever since. He thanks Kate for her constant sup-
port and his parents, Marcello and Cristina. LP is grateful to Raya for her support and
patience and to Margherita and Mira for everything.


Notation
≍
Leading exponential order.
u = (ux)
Entire vector with components ux.
(expression)xx′
Matrix element xx′ of expression.
⟨. . .⟩
Average over probability distributions.
⟨. . .⟩F and ⟨. . .⟩B
Average over forward and backward process.
∂X
∂Y
!
Z
Partial derivative of X with respect to Y at Z ﬁxed.
∂f
∂x
""""
x=0
Partial derivative of f with respect to x, evaluated at
x = 0.
#
f (x) · dx,
#
f (x) ◦dx
Ito and Stratonovich integrals of f (x).
a(x)
Static observable, expressed as a function of the
trajectory x.
Aα
Aﬃnity of cycle α.
⃗B
Magnetic ﬁeld.
(Cα)
Set of fundamental cycles.
Cαβ(t)
Correlation function.
D
Diﬀusion coeﬃcient.
dxx′
Coeﬃcient of a jump observable. Cost of phenotype
switching.
DKL(p∥q)
Kullback-Leibler divergence of distributions p and q.
E, S, W, Q, P
Macroscopic (deterministic) energy, entropy, work,
heat, pressure.
F
Equilibrium free energy.
Fneq
Nonequilibrium free energy.
F(x, t)
Force acting on a Brownian particle.
gαβ
Generalized friction coeﬃcient.
h
Planck constant (h = 6.626 07015 · 10−34 m2 kg s−1
(exact)).
H(S) or H(p)
Shannon entropy of system S with distribution
p = (px) .
H(S1, S2)
Joint Shannon entropy of S1 and S2.
H(S1|S2)
Conditional Shannon entropy of S1 given S2.
H(pr, r; λ)
Hamiltonian.
ixy
Stochastic mutual information.
I(x)
Rate (Cramér) function.

xviii
Notation
I(S1 : S2)
Mutual information of S1 and S2.
Jxx′(t), J(x, t)
Probability current (discrete, continuous).
Jthr
Threshold current.
J (x), j(x)
Integrated empirical current, empirical current.
js
Empirical entropy production rate.
kxx′
Rate of jump from state x′ to state x.
kout
x
Escape rate kout
x
= $
x′ kx′x.
¯kxx′,%kxx′
Information-mediated jump rate and its reverse.
kB
Boltzmann constant
(kB = 1.380 649 · 10−23 m2 kg s−2K−1 (exact)).
Kαβ(t, t′), Kαβ(t)
Linear response function.
Lxx′, L
Generator of dynamics (discrete, continuous).
Lxx′(q)
Generator of tilted dynamics.
NA
Avogadro number (NA = 6.022 14076 · 1023 mol−1
(exact)).
nxx′(x)
Number of jumps from x′ to x in the trajectory x.
Nx
Weight of the phenotypic trajectory x.
px, p(x)
Probability of x, probability density of x.
px(t), p(x; t)
Probability of x at time t (discrete, continuous).
px|y, p(x|y)
Conditional probability of x given y (discrete,
continuous).
px;t|x′;t′, p(x; t|x′; t′)
Conditional probability of x at time t, given the state
x′ at time t′.
peq
x , peq(x)
Equilibrium probability (discrete, continuous).
pst
x , pst(x)
Stationary probability (discrete, continuous).
pr, r
Particle momentum and location (1D).
⃗pr, ⃗r
Particle momentum and coordinates (vectors in
physical space).
Px, P(x)
Trajectory probability density (discrete, continuous
states).
Px Dx
Inﬁnitesimal trajectory probability.
q, Q
Stochastic and average heat. Positive if released to
the reservoir.
qxx′
Mesoscopic heat released during a jump.
r
Probability of a binary variable.
rx
Division rate of phenotype x.
Rxx′(x), Rxx′
Number and average rate of information-mediated
transitions.
¯s
Inﬁmum of the entropy production.
S(x; λ)
Action.
sa, sna
Adiabatic and nonadiabatic entropy production.
sres, Sres
Stochastic and average entropy released in the
reservoir.
Sstat
Statistical entropy.
ssys
x , Ssys
Stochastic and average system entropy.
stot, Stot
Stochastic and average total entropy production.
˙stot, ˙Stot
Stochastic (instantaneous) and average entropy
production rate.

Notation
xix
T
Absolute temperature.
%t, %x,%λ
Reverse time, backward trajectory, backward
protocol.
t0, tf
Initial and ﬁnal time.
T
Duration of time interval T = tf −t0.
Tfp, tfp
First-passage time: extensive (Tfp) and intensive
(tfp = Tfp/ |Jthr|).
T
Time-ordered product.
trnd
Random time.
tstop
Stopping time.
txx′
Traﬃc between x′ and x.
U(x, λ)
Potential energy.
v(x, t), D(x, t)
Drif and diﬀusion coeﬃcients, respectively, of a
Brownian particle.
w
Mesoscopic (stochastic) work. Positive if done on
the system.
wdiss
Dissipated work (wdiss = w −%F).
W(t)
Wiener process.
W
Number of microstates.
x
Mesoscopic state (mesostate).
x = (x(t))
Trajectory.
Z (Zgc)
Canonical (grand canonical) partition function.
β
1/kBT.
γ
Rate of information-mediated transitions.
δ(x)
Dirac delta.
δK
xx′
Kronecker delta.
δxx′
Driving from x′ to x.
%X
Change of the state function X (energy, entropy, etc.)
ϵx
Mesoscopic (ﬂuctuating) energy of mesostate x.
ϵξ
Energy of a microscopic state.
ε
Small positive quantity.
ζ
Parameter in the Mandal-Jarzynski model
(ζ = tanh(mg %h/2kBT)).
η
Stochastic eﬃciency (η = −sin/sout).
ηS
Eﬃciency (ηS = −Sin/Sout).
ηC
Carnot eﬃciency (ηC = 1).
ηth
Thermal eﬃciency (ηth = −W/Ehot).
ηth
C
Thermal Carnot eﬃciency (ηth
C = 1 −Tcold/Thot).
θ
Parameter of a Poisson distribution.
κxx′
Empirical jump rate.
λ = (λ(t))
Manipulation protocol.
[λ]
Manipulation path.
λ, λmax
Eigenvalue, maximal eigenvalue.
/
Population growth rate.
µ
Chemical potential.
µP
Mobility of a Brownian particle.
ν
Number of cycles in a graph.
νxx′
Empirical frequency of jumps from x′ to x.

xx
Notation
ρ
Number of cell divisions in a lineage.
ξ
Microscopic state (microstate).
˜ξ
Time-reversed image of ξ: If ξ = (pr, r), ˜ξ = (−pr, r).
ξ(t)
White noise.
σ(x, t)
Coeﬃcient of the noise.
˜σ 2
x
Scaled variance of x.
τy, fy
Empirical dwell time and empirical frequency in y.
φ(j)
x (q, t)
Generating function of the variable j conditioned to
ﬁnal state x.
φ(q) or φ(j)(q)
Generating function of variable j.
5(q) or 5(j)(q)
Cumulant generating function of variable j.
ψ(q) or ψ(j)(q)
Scaled cumulant generating function of j.
ωxx′
Intrinsic rate of jumps between x and x′.
8x
Phase-space region associated with mesostate x.

Stochastic Thermodynamics


CHAPTER 1
Motivation
Stochastic thermodynamics has become an established branch of nonequilibrium sta-
tistical physics. On the theoretical side, it has been discovered that the behavior of
mesoscopic systems is governed by surprisingly general relations. Rapid advances
in experimental techniques are leading to tests of these relations by manipulating
mesoscopic physical systems.
Perhaps as a consequence of this fast development, some aspects of stochastic
thermodynamics might seem obscure to noninitiates. Key results in stochastic thermo-
dynamics, such as ﬂuctuation relations, are so general that one might wonder what the
underlying physical assumptions really are. In a broader perspective, it might be diﬃcult
to understand how the simplicity of stochastic thermodynamics relates to the daunt-
ing complexity of traditional nonequilibrium statistical physics. Preliminary answers to
these questions are presented in this chapter. We conclude the chapter with an overview
of the book structure.
1.1
What is stochastic thermodynamics?
In its simplest form, stochastic thermodynamics is a thermodynamic theory for
mesoscopic, nonequilibrium physical systems interacting with equilibrium heat reser-
voirs.
It is useful to dissect this deﬁnition:
• Thermodynamic theory. As the name suggests, stochastic thermodynamics
draws a correspondence between mesoscopic stochastic dynamics and macro-
scopic thermodynamics. This correspondence is sketched in ﬁg. 1.1.
• Mesoscopic, nonequilibrium physical systems. Stochastic thermodynamics deals
with mesoscopic systems. For our aims, a mesoscopic system is a physical
system characterized by energy diﬀerences among its states on the order of
the thermal energy kBT, where kB is the Boltzmann constant and T is the
temperature. Prominent examples of mesoscopic systems are colloidal parti-
cles, macromolecules, nanodevices, or systems of chemical reactions at very
low densities. Mesoscopic systems can be driven out of equilibrium by an
external manipulation, for example, by varying in time the temperature or
by controlling them with optical tweezers. More generally, all physical sys-
tems that can be described by stochastic evolution equations, where the noise

2
Chapter 1
MICROSCOPIC
mechanics
MESOSCOPIC
stochastic dynamics
MACROSCOPIC
thermodynamics
stochastic
thermodynamics
statistical
mechanics
coarse graining
Figure 1.1. Relation between statistical mechanics, coarse-graining techniques, and
stochastic thermodynamics. (Inspired by Sekimoto [153].)
models interactions with a heat reservoir, fall into the scope of stochastic
thermodynamics.
• Interacting. The stochasticity of mesoscopic systems results from interactions
with one or multiple reservoirs. Ofen one does not know the details of these
interactions, and the functional form of the noise is dictated by general physical
assumptions. Importantly, we always neglect the interaction energy between
the system and the bath.
• Equilibrium heat reservoirs. We assume that reservoirs relax very quickly to
equilibrium compared to the timescales of mesoscopic systems. Therefore, on
these timescales, reservoirs are eﬀectively always at equilibrium. This timescale
separation is key to the simplicity of stochastic thermodynamics. In many
cases, this assumption can be justiﬁed by a coarse-graining procedure.
Provocatively, one could say that Einstein’s paper on Brownian motion was the ﬁrst
paper in history complying with our deﬁnition of stochastic thermodynamics. Indeed,

Motivation
3
Einstein considered the stochastic dynamics of a mesoscopic colloid and used it to draw
far-reaching conclusions for the thermodynamics of general nonequilibrium systems.
1.2
Why does it work and why is it useful?
Stochastic thermodynamics associates thermodynamic quantities with mesoscopic
physical systems, whose evolution is described by stochastic dynamics, and pre-
dicts their properties. This task is considerably simpler than the general problem in
nonequilibrium statistical physics, i.e., that of deriving macroscopic dynamics from a
“fundamental” microscopic description.
In particular, several fundamental problems that arise in nonequilibrium statistical
physics do not even appear in stochastic thermodynamics. One example is understand-
ing how the irreversible nature of macroscopic thermodynamics systems emerges from
microscopic dynamics. This conceptual issue is known as Loschmidt’s paradox and has
puzzled physicists since the dawn of thermodynamics. Afer all, macroscopic systems
are made of a large number of elementary particles, and these particles evolve accord-
ing to microscopic equations that are time-reversible. It is nowadays established that
the solution to the Loschmidt paradox originates from the large number of degrees
of freedom of thermodynamic systems. However, a rigorous derivation of irreversible
macroscopic dynamics starting from reversible microscopic dynamics has proved to
be rather diﬃcult and has been carried out without simplifying assumptions only for
a limited number of idealized systems. This diﬃculty does not arise in stochastic ther-
modynamics, since the stochastic equations that constitute its starting point are already
irreversible.
At this point, one might wonder whether stochastic thermodynamics might be too
simple to be really interesting. In particular, one question is, In which approxima-
tion do real mesoscopic physical systems satisfy the hypotheses of stochastic ther-
modynamics? Although theoretical arguments can partially answer this question, an
ultimate response can only come from experiments. Stochastic thermodynamics has
been successfully employed to measure equilibrium free energies from nonequilibrium
measurements, and the range of mesoscopic physical systems that are experimentally
controllable keeps growing. It is our hope that these experiments will clarify how safe it
is to apply stochastic thermodynamics to generic mesoscopic systems and which aspects
have to be treated with special care.
Due to its simplifying assumptions, stochastic thermodynamics circumvents many
technical subtleties of kinetic theory. In this respect, it might appear that it provides less
interesting challenges for mathematical physics. However, stochastic thermodynamics
has proved to be an interesting playground for advanced mathematical tools to analyze
stochastic processes, including control theory, large deviations, and probability mea-
sures in the space of trajectories. As shown in this book, these tools are precious to shed
light on the nature of nonequilibrium mesoscopic processes.
1.3
Plan of the work
The main goal of this book is to provide a pedagogical introduction to stochas-
tic thermodynamics for graduate students in physics. Our book is structured so that
it can be used as a textbook for a graduate course or for independent study. To this
aim, we mark those sections of the book that contain more advanced material with the

4
Chapter 1
notation (∗). These sections can be skipped to ease a ﬁrst reading or to use the book for
a course covering basic concepts only.
Relevant bibliography is collected in the “Further reading” sections at the end of
each chapter. These sections refer to works where results discussed in the chapter were
originally presented, along with other useful references to deepen the study of speciﬁc
topics.
One of the best ways to learn a subject is by problem solving. Following this phi-
losophy, we have included an exercise section to complement most chapters. Some
of these exercises are meant to be solved with paper and pen, whereas others require
computer simulations. These latter exercises assume that the reader is familiar with
basic computer programming (in any language). For reasons of space, we do not intro-
duce numerical algorithms other than particularly relevant ones, such as the Gillespie
algorithm. As with sections, some exercises are marked with a (∗), to warn the reader
that their solution is particularly challenging or that it requires concepts from a starred
section.
Chapter 2 provides a brief overview of the theories upon which stochastic ther-
modynamics is built: thermodynamics, statistical mechanics, the theory of stochastic
processes, and information theory. This overview is far from exhaustive due to rea-
sons of space. We focus on aspects of these theories of more relevance for stochastic
thermodynamics. To avoid overburdening the book with the complexities of stochastic
calculus, we mainly focus on physical systems with discrete states that can be described
by master equations. Throughout the book, sections requiring knowledge of stochastic
processes with continuous state space are always starred.
Chapter 3 introduces the basic concepts of stochastic thermodynamics. We dis-
cuss how work, heat, and entropy can be consistently introduced at the level of single
stochastic trajectories of systems described by master equations. We show that these
quantities satisfy relations that are analogous to the ﬁrst and second laws of traditional
thermodynamics. Particular emphasis is given to the physical interpretation of these
quantities.
Chapter 4 is devoted to ﬂuctuation relations, which are perhaps the most celebrated
results in stochastic thermodynamics. The connection between entropy production and
statistical irreversibility is the core concept of this chapter. We exploit this connection
to introduce ﬂuctuation relations in a uniﬁed framework.
Chapter 5 discusses manipulation of information at the mesoscopic level. In the ﬁrst
part of the chapter, we introduce counterintuitive physical aspects of information pro-
cessing, such as Maxwell demons and the Landauer cost of erasing information. In the
rest of the chapter, we show how stochastic thermodynamics clariﬁes these concepts,
both in general and in the context of concrete examples.
Chapter 6 is devoted to large deviation theory. Once conﬁned to pure mathematics
and statistics, large deviation theory has risen as a fundamental tool in statistical physics
and beyond. Many current developments in stochastic thermodynamics heavily rely on
large deviation theory. In this chapter, we introduce the theory and discuss its main
applications in stochastic thermodynamics.
Chapter 7 presents key experimental results in stochastic thermodynamics. A focus
of this chapter is how ﬂuctuation theorems allow for estimating equilibrium free
energy from nonequilibrium measurements. We also discuss other groundbreaking
experiments that have tested manipulation of information at the mesoscopic level.

Motivation
5
Chapter 8 presents a collection of developments of stochastic thermodynamics in
several directions. Sections of this chapter are rather independent of each other and
provide an introduction to more recent research topics. We have not marked with a
(∗) sections and exercises of this chapter; however, most of the material should be
considered as advanced.
Chapter 9 presents perspectives on open issues and future directions.

CHAPTER 2
Basics
The prerequisites for stochastic thermodynamics are laid down in this chapter. In par-
ticular, we brieﬂy review the thermodynamics of macroscopic systems, the statistical
description of their behavior, both static and dynamic, and some basic concepts of infor-
mation theory. We take advantage of this preliminary material to introduce most of the
notation used in the rest of the book.
2.1
Thermodynamics
Stochastic thermodynamics describes thermodynamic processes taking place in
small systems in contact with reservoirs. Before going any further, we need to specify
what we mean by “thermodynamic processes” and “reservoirs,” and to introduce other
main concepts in traditional thermodynamics.
In its basic form, thermodynamics deals with systems that are made up of a very
large number of particles and are in thermodynamic equilibrium, in the sense that
their macroscopically observable properties, like density, pressure, etc., do not change
with time. It is a common observation that many materials, kept isolated from the
environment, reach sooner or later a state characterized by constant values of macro-
scopic properties. Importantly, systems that reach such an equilibrium state by diﬀerent
manipulations behave from then on in the same way, from the point of view of ther-
modynamics. Thermodynamic equilibrium wipes out previous history. For example, the
thermodynamic behavior of two glasses of water with the same density at the same pres-
sure does not depend on whether one of the two has been prepared by melting an ice
cube in a glass of water at a higher temperature, while the other has simply kept the
state it had when ﬂowing out of the tap. There are exceptions to this rule: some systems,
such as structural glasses, keep memory of past manipulations. Their thermodynamic
behavior is more complex (and controversial). We do not deal with them.
The state of a thermodynamic system is characterized by a judiciously chosen, small
set of macroscopically observed properties: its composition, its mass, its volume, the
pressure acting on it, etc. In thermodynamics, knowledge of the values of these quan-
tities in a given equilibrium state is suﬃcient to predict their values afer the system
undergoes a thermodynamic transformation. In this sense, traditional thermodynamics
is deterministic.
For example, we consider a cylinder closed by a piston, holding a simple ﬂuid, i.e., a
ﬂuid composed of a single chemical species. For such a system, the number n of moles

Basics
7
of the ﬂuid (or the number of particles N = n NA, where NA ≈6.02 · 1023 is Avogadro’s
number), the volume V of the cylinder, and the pressure P applied by the piston are a
complete set of thermodynamic observables.
Thermodynamics deals with two main kinds of transformations:
Adiabatic transformations. In adiabatic transformations, energy is exchanged be-
tween the system and the environment only in the form of work. This means that the
system is thermally isolated, i.e., enclosed by walls that do not allow the exchange
of heat. Values of observables like pressure, volume, etc. can be mechanically altered.
In our example, this means that the walls of the cylinder do not allow any uncon-
trolled interaction with the surroundings, and only the position of the piston can
be changed. We then let the piston rest in the new position, and we wait until the
system reaches a new equilibrium state. The motion of the piston can be very slow
(quasi-static transformation) or abrupt, meaning that the intermediate states are not
necessarily equilibrium states. In either case, the transformation brings the system
from one equilibrium state to a new equilibrium state, whose properties depend on
the details of the transformation.
Heat exchange. In the case of heat exchange, the system interacts in an uncontrolled
way with another thermodynamic system, for example, a similar container with
nonisolating walls. We say that the two systems are put “in contact.” This interaction
in general involves energy exchange between the two systems. In this case, we must
specify which macroscopic variables are kept constant, because it is not possible in
general to keep, e.g., both the volume and the pressure constant.
Any transformation can be decomposed into a succession of (possibly inﬁnitesimal)
adiabatic transformations and heat exchanges.
We now consider two systems S1 and S2 that are put in contact with a much larger
system S0, one afer the other, in such a way that they both reach equilibrium. We
assume that S0 is so large that its thermodynamic state is not signiﬁcantly aﬀected by
being put in contact with either S1 or S2, whereas the thermodynamic states of S1 or
S2 may in principle change. Experience shows that if, afer this procedure, S1 and S2
are put in contact with each other, their thermodynamic states remain unaltered. This
observation is summarized by the zeroth law of thermodynamics:
Two systems, each in thermodynamic equilibrium with a third one, are in equi-
librium with each other.
The zeroth law of thermodynamics allows us to deﬁne a quantity ! that assumes the
same value in systems in thermodynamic equilibrium with one another. This quantity
can be made observable if we put these systems in touch with a reference system T, small
enough not to perturb their equilibrium state, and then measure a macroscopic quantity
(e.g., the volume) of T. The system T is called thermometer, and ! is an “empirical
temperature.” We call the large system S0 a heat reservoir characterized by a given
value of !.
In general, there are multiple ways to perform a thermodynamic transformation
from one equilibrium state to another. For example, we can increase the pressure of
a ﬂuid with a ﬁxed value of V by putting it in contact with a heat reservoir at an empir-
ical temperature !, or by letting an electrical current go through a resistor immersed
in it, until a thermometer reads the same value of !. According to our postulates, the
system reaches the same equilibrium state in all these cases. In particular, the energy

8
Chapter 2
contained in the system (its internal energy) is the same. In an adiabatic transfor-
mation, conservation of energy imposes that the change "E in the internal energy
between the initial and the ﬁnal state must be equal to the work Wad performed on
the system:
"E = Ef −E0 = Wad.
(2.1)
We use in this book the convention that work is considered positive if it is per-
formed on the system and negative if it is performed by the system. In macro-
scopic thermodynamic systems, the internal energy E is extensive, i.e., it is propor-
tional to the size of the system (as measured by V or N, as long as the density is
ﬁxed).
In a nonadiabatic transformation between two equilibrium states, the work W per-
formed on the system is in general diﬀerent from Wad. Therefore, a certain amount
of energy exchanged by interactions between the system and its surroundings is not
taken into account in W. We identify this energy Q with the heat exchanged in the
transformation. We thus have
Q = W −"E.
(2.2)
With this convention, Q is positive if it is released by the system and negative if it is pro-
vided to the system. Equation (2.2) embodies the ﬁrst law of thermodynamics, which
may be expressed as follows:
The change of the internal energy of a system is equal to the diﬀerence between
the work done on it and the heat released by it.
Our sign convention for work and heat is the opposite of that commonly used
in traditional thermodynamics, but it turns out to be the most natural in stochas-
tic thermodynamics. The reason is that, historically, thermodynamics originated from
the study of thermal engines, and the emphasis was on the conversion of heat into
work. Conversely, in stochastic thermodynamics, one is usually interested in describing
dissipative systems, which convert work into heat.
The internal energy E is one of the macroscopic observables. For a simple ﬂuid,
knowledge of n, P, and V allows one to evaluate E. It is possible to invert this relation
to express, e.g., P or ! as a function of n, V, and E.
Given an equilibrium state E0 of a thermodynamic system, there are states E that
cannot be reached from E0 via an adiabatic transformation, while the inverse transfor-
mation E −→E0 is possible. In this sense, thermodynamic systems possess an intrinsic
irreversibility. A main goal of thermodynamics is to characterize the set of states that can
be reached from a given state by an arbitrary combination of adiabatic transformations
and heat exchanges.
The irreversibility of thermodynamic transformations is characterized by the con-
cept of entropy. The entropy S is a function of the thermodynamic state of an
equilibrium system. The irreversibility of thermodynamic transformations is captured
by the second law of thermodynamics:
The total entropy of a thermally isolated system cannot decrease.
The entropy S has the following properties:
Additivity. If a system is made up of several subsystems S1, . . . , Sk, . . . , each at equi-
librium, the entropy of the total system is equal to the sum of the entropies of the
subsystems:

Basics
9
S
!"
Sk
#
=
$
k
S(Sk).
(2.3)
As a consequence of additivity, the entropy of a homogeneous system is extensive, i.e.,
it is proportional to the system size. This implies that, upon rescaling the other exten-
sive observables, such as the number of particles, the volume, the internal energy,
etc., by a factor λ > 0, one has
S(λE, λV, λN) = λS(E, V, N).
(2.4)
Monotonicity. S increases as E increases when all other variables are kept constant.
This property holds for the vast majority of practical cases. There exist some intrigu-
ing systems where S can decrease with E, but we do not deal with them in this
book.
Concavity. Entropy is a concave function. This means that, given two equilibrium
states E0 = (N, V0, E0) and E1 = (N, V1, E1) of the same system and any real num-
ber α between 0 and 1, the intermediate state Eα characterized by (N, (1 −α)V0 +
αV1, (1 −α)E0 + αE1) satisﬁes
S(Eα) ≥(1 −α)S(E0) + αS(E1),
0 ≤α ≤1.
(2.5)
Properties of concave and convex functions are summarized in appendix A.1.
The second law of thermodynamics also implies several important properties of
thermodynamic systems:
Temperature. Systems in thermal equilibrium with each other share the same value of
the quantity
1
T = ∂S
∂E,
(2.6)
if the other extensive quantities (N, V, etc.) are kept constant. To prove this result, we
consider two systems S1 and S2 in contact with each other and adiabatically insu-
lated from their surroundings. Their total energy E = E1 + E2 is ﬁxed. If they are in
mutual equilibrium, their total entropy cannot grow upon exchanging energy in the
form of heat. Thus, at equilibrium, we have
∂(S1(E1) + S2(E −E1))
∂E1
= 1
T1
−1
T2
= 0.
(2.7)
Therefore, T acts as the empirical temperature ! that we deﬁned before. The
monotonicity of S implies that T cannot be negative for the cases we consider.
Heat exchange. If two systems in contact with each other do not exchange work, the
system with a larger value of T provides heat to the system with a smaller value of T.
We call E1 and E2 the initial internal energies of the two systems and T1 and T2 their
initial temperatures. Afer being in contact for some time, they reach equilibrium at
energy values E′
1 and E′
2. The total entropy is given by

10
Chapter 2
S = S1(E′
1) + S2(E′
2) ≤S1(E1) + E′
1 −E1
T1
+ S2(E2) + E′
2 −E2
T2
= S1(E1) + S2(E2) +
%
E′
1 −E1
& ' 1
T1
−1
T2
(
,
(2.8)
where we use the concavity of S and the fact that E1 + E2 = E′
1 + E′
2. The second law
imposes that
S1(E′
1) + S2(E′
2) ≥S1(E1) + S2(E2)
(2.9)
and therefore
%
E′
1 −E1
& ' 1
T1
−1
T2
(
≥0.
(2.10)
Thus, if E′
1 −E1 > 0, we have 1/T1 > 1/T2, which corresponds to T1 < T2: the body
with higher T releases energy to that with lower T. This means that T behaves as
a temperature scale: hotter bodies are characterized by larger values of T, and heat
ﬂows naturally from them to colder bodies. This fact is summarized by the Clausius
statement of the second law of thermodynamics:
Heat can never pass from a colder to a warmer body without some other
change, connected therewith, occurring at the same time.
In fact, T deﬁned in this way coincides with the absolute temperature scale and is
called the temperature from now on.
As an illustration of these ideas, we consider a cylinder containing n moles of an
ideal gas. An ideal gas is a ﬂuid in which the pressure P, the volume V, the number of
particles N, and the temperature T satisfy the equation of state
P = N kBT
V
.
(2.11)
We change the volume of the gas by an inﬁnitesimal quantity dV by performing on it
an inﬁnitesimal amount of work
dW = −P dV.
(2.12)
If the gas is thermally isolated, we have dE = −P dV. It turns out that the internal energy
of an ideal gas depends only on its temperature T. Thus we obtain
∂E
∂V
(
T
= ∂E
∂V
(
S
+ ∂E
∂S
(
V
∂S
∂V
(
T
= 0,
(2.13)
where ∂X/∂Y)Z is the partial derivative of X with respect to Y, taken at constant Z. By
combining eqs. (2.12) and (2.6), we obtain
∂E
∂V
(
S
= −P;
∂E
∂S
(
V
= T.
(2.14)

Basics
11
Therefore,
∂S
∂V
(
T
= P
T .
(2.15)
If the volume V of the system changes from V0 to Vf at constant T, its entropy S chan-
ges by
"S =
) Vf
V0
dV P
T = NkB
) Vf
V0
dV
V = N kB ln Vf
V0
.
(2.16)
Therefore, if Vf > V0, the transformation V0 −→Vf, but not its reverse, can take place
in a thermally isolated system.
Another facet of these postulates is the Kelvin-Planck statement of the second law:
It is impossible to devise a cyclically operating heat engine, the only eﬀect of which
is to absorb energy in the form of heat from a single thermal reservoir and to
deliver an equivalent amount of work.
Indeed, such a device would produce negative entropy during a cycle. To show that, we
imagine enclosing the device and the reservoir with a wall, so that the entire system is
thermally isolated. During the cycle, the device transfers a positive amount W of work
to the environment and reduces the internal energy of the reservoir by the same amount.
Since the entropy of the device does not change and the entire system is isolated, the
total entropy change is Sres = −W/T < 0, in contradiction with the second law.
2.2
Thermodynamic efﬁciency
An important application of thermodynamics is the study of engines and their eﬃ-
ciency. We generally call an engine a physical machine that operates cyclically and
converts one form of energy into another. Historically, the most important example
is heat engines, i.e., machines that cyclically convert heat into work. The Kelvin state-
ment of the second law of thermodynamics implies that heat engines must necessarily
operate using at least two heat reservoirs at diﬀerent temperatures Thot and Tcold, with
Thot > Tcold.
We consider a heat engine that is alternately put in contact with two heat reservoirs.
During each cycle, the system receives an amount of energy Ehot from the hot reservoir
and releases an amount of energy Ecold to the cold one. At the end of the cycle, the
engine returns to the same state it had at the beginning of the cycle. Therefore, the
work W = Ecold −Ehot performed on the engine in a cycle is equal to the net total heat
released to the reservoirs (remember our sign convention!). The total change in entropy
in a cycle, Stot, is given by the change "Ssys of the entropy of the system plus the entropy
change Sres of the reservoirs:
Stot = "Ssys + Sres.
(2.17)
Here and in the following we denote with "X the change of a state function X. The
entropy change of the reservoir Sres is not a state function, since the internal energy and
thus the energy of a reservoir can change without altering its temperature. Therefore,
neither is Stot a state function. In a cycle, "Ssys vanishes, whereas the entropy of the
reservoirs changes by
Sres = −Ehot
Thot
+ Ecold
Tcold
≥0.
(2.18)

12
Chapter 2
The extracted work attains its maximum when the entropy increase Scold of the reservoir
at lower temperature is the opposite of the entropy decrease Shot of the reservoir at
higher temperature:
Scold = Ecold
Tcold
≥−Shot = Ehot
Thot
.
(2.19)
This condition implies
−W ≤Ehot
'
1 −Tcold
Thot
(
.
(2.20)
Traditionally, the thermal eﬃciency ηth of a heat engine is deﬁned as the ratio between
the extracted work and the energy absorbed from the hot reservoir:
ηth = −W
Ehot
.
(2.21)
Equation (2.20) implies that the maximal thermal eﬃciency is determined by the
temperatures of the hot and cold reservoirs, independent of the amount of energy
exchanged during a cycle:
ηth ≤ηth
C = 1 −Tcold
Thot
,
(2.22)
where ηth
C is the thermal Carnot eﬃciency.
It is interesting to consider more general engines whose energy currencies are not
limited to work and heat. This is especially true in stochastic thermodynamics, where
information can also be exchanged for work. To deal with these more general engines,
we deﬁne the eﬃciency ηS in terms of entropy rather than energy. To this aim, we con-
sider an engine operating between two arbitrary reservoirs. During a cycle, the engine
extracts an amount Sin of entropy from a reservoir and releases an amount Sout of
entropy to another reservoir. In this framework, we deﬁne the eﬃciency as
ηS = −Sin
Sout .
(2.23)
With this deﬁnition of eﬃciency, eq. (2.22) becomes
ηS ≤ηC,
(2.24)
where in this case the Carnot eﬃciency is simply
ηC = 1.
(2.25)
This deﬁnition of eﬃciency allows us to characterize engines operating between two
arbitrary reservoirs.
2.3
Free energy and nonequilibrium free energy
The thermodynamic behavior of a system is identiﬁed once we know the expres-
sion of the internal energy E as a function of entropy S, particle number N, volume
V, and other thermodynamically relevant observables. If the system is put in contact

Basics
13
with a heat reservoir at temperature T, its internal energy E and entropy S are deter-
mined by the interaction with the reservoir. In this case, it is convenient to express the
thermodynamic properties in terms of T rather than S. Since T = ∂E/∂S (where the
other thermodynamic observables are kept constant), this change of variable can be
achieved via a Legendre transformation. Properties of the Legendre transformation are
summarized in appendix A.2. The free energy is deﬁned as the opposite of the Legendre
transform of the internal energy:
F(T, N, V) = E(S, N, V, . . .) −T S,
(2.26)
where S is expressed as a function of T and of the other observables as the solution of
the equation
∂E
∂S
(
N,V,...
= T,
(2.27)
and the dots stand for possible other thermodynamic observables. In the following, for
simplicity, we limit ourselves to the basic observables S, V, and N. Given F(T, N, V),
the entropy S is given by
S(T, N, V) = −∂F
∂T
(
N,V
,
(2.28)
whereas the pressure is given by
P = −∂F
∂V
(
T,N
.
(2.29)
Therefore, the free energy fully describes the thermodynamic state, in the sense that it
permits us to reconstruct all thermodynamic observables. Functions with this property
are called thermodynamic potentials. Applying the symmetry of partial derivatives
of F to relations like eqs. (2.28) and (2.29), we obtain other useful relations between
thermodynamic quantities, such as
∂2F
∂V ∂T
(
N
= −∂S
∂V
(
T
=
∂2F
∂T ∂V
(
N
= −∂P
∂T
(
V
.
(2.30)
Such equalities are known as Maxwell relations. In particular, one can use these rela-
tions to show that the equation of state of an ideal gas implies that its entropy depends
on T and V in the form S(T, V) = NkB ln V + S0(T), where S0(T) does not depend
on V.
We now consider a system initially at equilibrium with values S, N, and V of the
thermodynamic observables that is brought to a new equilibrium by putting it in touch
with a heat reservoir at temperature T. In the new equilibrium state, the free energy
has the value F(T, N, V) and the value of the entropy satisﬁes eq. (2.28). During equi-
libration, energy is exchanged as heat with the reservoir and as work with the external
environment. We wish to characterize this exchange.
By the second law, the total entropy change of the system plus the reservoir cannot
be negative:
Stot = "Ssys + Sres ≥0.
(2.31)

14
Chapter 2
We call W the work performed on the system and Q the heat released to the reservoir.
The ﬁrst law imposes that
"E = W −Q = W −T Sres,
(2.32)
where we use the fact that the heat reservoir is always at equilibrium at temperature T.
As a consequence of eqs. (2.31) and (2.32), we obtain
W ≥"E −T "Ssys.
(2.33)
Therefore, the equilibrium state can be identiﬁed as the one in which the expression
E −T S attains its minimum. Evaluating the equilibrium value S of the system entropy
at this minimum, we retrieve the condition given by eq. (2.27). The value of E −T S
at its minimum is equal to the free energy F at temperature T. Mathematically, this
result descends from the fact that Legendre transforms satisfy a variational principle
(cf. eq. (A.29)). These results justify deﬁning the nonequilibrium free energy by
Fneq(T, S, N, V) = E(S, N, V) −T S
(2.34)
for arbitrary values S of the entropy. The equilibrium free energy F is then obtained by
the variational principle
F(T, N, V) = min
S
Fneq(T, S, N, V).
(2.35)
The nonequilibrium free energy is not a thermodynamic potential. One reason is that
it simultaneously depends on some quantities characterizing the system (such as S) and
others that characterize the reservoir (such as T). We deﬁned Fneq for a system initially
at equilibrium, for which S is thermodynamically deﬁned and which is brought out
of equilibrium by allowing its contact with a heat reservoir. We discuss in section 5.2
a generalization of nonequilibrium free energy to mesoscopic systems prepared in an
arbitrary nonequilibrium state.
There exist thermodynamic potentials other than the free energy. They diﬀer in the
thermodynamic quantities that are kept ﬁxed by external reservoirs. For example, the
appropriate thermodynamic potential for a system in contact with a heat reservoir and
kept at a ﬁxed pressure P is the Gibbs free energy
G(T, P, N) = E + P V −TS,
(2.36)
where E, V, and S are expressed as functions of T, P, N. Beyond heat reservoirs, we can
also consider particle reservoirs, which are able to exchange with the system an unlim-
ited amount of particles of a given chemical species without changing their properties
and while remaining at thermodynamic equilibrium. They are characterized by the val-
ues T of their absolute temperature and µ of their chemical potential. The chemical
potential µ of a system with free energy F that can exchange a single chemical species
is given by
µ = ∂F
∂N
(
T,V
,
(2.37)

Basics
15
where N is the number of molecules of the considered species. For a system containing
a single chemical species at ﬁxed temperature T and pressure P, the chemical potential
is equal to the Gibbs free energy per particle:
µ(T, P) = G(T, P, N)
N
.
(2.38)
For systems exchanging multiple chemical species, a distinct chemical potential can be
assigned to each one of them. Each chemical potential is deﬁned by a formula similar
to eq. (2.37) in which we keep constant the number of molecules of all exchangeable
species but one, and take the derivative with respect to that one. By the same reasoning
we followed for the free energy, it can be shown that equilibrium in the presence of
particle reservoirs corresponds to the minimum of
'(E, T, V, µ1, N1, µ2, N2, . . .) = E −TS −
$
i
µiNi,
(2.39)
where the sum runs over all exchanged chemical species.
2.4
Statistical mechanics
Statistical mechanics links the microscopic description of a macroscopic system at
equilibrium to its thermodynamic behavior. We consider a macroscopic system and
assume for simplicity that its microscopic states ξ (also called microstates) are dis-
crete, ξ ∈{1, 2, . . .}. Macroscopically, the thermodynamic equilibrium state is identiﬁed
by the values of macroscopic observables, like the internal energy E, the volume V,
the number of particles N, etc. At the microscopic level, the system incessantly and
rapidly changes its microstate according to its dynamics. Therefore, we cannot do bet-
ter than assign it a statistical state, i.e., a probability distribution over the microstates.
We denote by pξ the probability of a discrete microstate ξ. If the variables ξ are con-
tinuous, the probability density is denoted by p(ξ). In either case, we denote by
*
f (ξ)
+
the expectation of the function f (ξ) over the probability distribution of ξ. We also use
the notations peq
ξ and
*
f (ξ)
+eq whenever we want to stress that a probability distribu-
tion corresponds to thermodynamic equilibrium. We brieﬂy review the properties of
probability distributions in appendix A.3.
The fundamental postulate of statistical mechanics stipulates that an isolated sys-
tem at thermodynamic equilibrium can be found with equal probability in any of the
microstates ξ compatible with given values of the thermodynamic observables, and that
the thermodynamic entropy S is related to the number W of the microstates that satisfy
this condition by the relation
S = kB ln W.
(2.40)
Here kB is the Boltzmann constant:
kB ≈1.384 · 10−23 J/K.
(2.41)
This probability distribution over the microstates is known as the microcanonical dis-
tribution (or microcanonical ensemble). The term ensemble is used to stress that we
are eﬀectively replacing a single system and its detailed dynamical behavior with a

16
Chapter 2
large collection of statistically identical systems, such that their distribution over the
microstates is constant in time—in agreement with thermodynamic equilibrium at
the macroscopic level. This change of description is appropriate if the system is large
enough. This condition is formalized by the thermodynamic limit, in which one imag-
ines the size of the system (measured by the number of particles N) to go to inﬁnity,
keeping constant the ratios V/N, E/N, ..., of extensive variables.
Starting from the microcanonical distribution, one can show that the equilibrium
state of a system in equilibrium with a reservoir at temperature T is described by the
Maxwell-Boltzmann (or canonical) distribution (or canonical ensemble)
peq
ξ = e−ϵξ/kBT
Z
,
(2.42)
where ϵξ is the energy of microstate ξ and the denominator is the partition function
Z =
$
ξ
e−ϵξ/kBT.
(2.43)
The partition function is related to the free energy F by
F = −kBT ln Z.
(2.44)
This relation allows us to write the equilibrium distribution peq in the form
peq
ξ = e(F−ϵξ)/kBT.
(2.45)
One of the simplest thermodynamic systems is the ideal gas. An ideal gas is made
of N point-like particles of mass m that interact weakly, so that their potential energy is
negligible compared to their kinetic energy. The state of a particle i is identiﬁed by its
momentum ⃗pr,i and its position ⃗ri. In evaluating the partition function, we have to take
into account that the particles are not distinguishable. Thus the partition function must
be multiplied by a factor 1/N!, because conﬁgurations that diﬀer only by the exchange
of particles should not be considered diﬀerent. In order to make the expression of Z
dimensionless, we introduce an elementary phase-space volume h for each degree of
freedom, where h is Planck’s constant. This value is chosen to make a connection with
the behavior of quantum systems. Using Stirling’s approximation for the factorial, we
obtain
F = −kBT ln Z = −kBT ln 1
N!
)
N
,
i=1
-
d⃗ri d⃗pr,i
h3
exp
.
−
p2
r,i
2mkBT
/0
= NkBT ln
-
N
e V
'
h2
2πmkBT
(3/20
,
(2.46)
where e = 2.7818 . . . is the basis of natural logarithms. The chemical potential µ is
obtained by taking the derivative of F with respect to N, as shown in eq. (2.37):

Basics
17
µ = ∂F
∂N
(
T,V
= kBT ln N
V + µ(0),
(2.47)
where µ(0) denotes terms that are independent of the concentration.
Values of thermodynamic observables can be obtained by taking appropriate deriva-
tives of the partition function. For example, the equation of state is obtained by taking
the derivative of F, as expressed by eq. (2.46), with respect to V:
P = −∂F
∂V
(
T,N
= kBT ∂ln Z
∂V
(
T,N
= N kBT
V
.
(2.48)
Similarly, deﬁning Z(β) = 1
ξ e−βϵξ , we have
∂ln Z
∂β
2222
β=1/kBT
= −1
Z
$
ξ
ϵξ e−ϵξ/kBT = −⟨ϵ⟩eq .
(2.49)
We identify the average ⟨ϵ⟩eq with the thermodynamic value E of the internal energy.
On the one hand, taking a further derivative, we obtain
∂2 ln Z(β)
∂β2
2222
β=1/kBT
=
*
ϵ2+eq −
%⟨ϵ⟩eq&2 ≥0.
(2.50)
On the other hand, an explicit evaluation of the derivatives yields
∂2 ln Z(β)
∂β2
2222
β=1/kBT
= kBT2 ∂⟨ϵ⟩eq
∂T
(
N,V,...
.
(2.51)
Comparing eqs. (2.50) and (2.51), we obtain
kBT2 ∂⟨ϵ⟩eq
∂T
(
N,V,...
=
*
ϵ2+eq −
%⟨ϵ⟩eq&2 .
(2.52)
This relation expresses a thermodynamic derivative (on the lef-hand side) in terms
of a microscopic ﬂuctuation (on the right-hand side). It is an elementary example of
relations that are collectively known as ﬂuctuation-dissipation relations. Importantly,
eq. (2.52) tells us that the variance of the distribution of ϵ grows proportionally to its
average, and therefore to the system size. Therefore, the relative uncertainty on the
energy
3*
ϵ2+eq −
%⟨ϵ⟩eq&2
⟨ϵ⟩eq
=
4
kBT2
%⟨ϵ⟩eq&2
∂⟨ϵ⟩eq
∂T
(
N,V,...
(2.53)
scales like the inverse square root of the system size. As a consequence, also taking into
account the smallness of kB, energy ﬂuctuations are negligible for macroscopic systems.
Thus, although statistical mechanics describes systems with probability distributions at

18
Chapter 2
the microscopic level, its predictions are deterministic at the macroscopic level. This is
also true for macroscopic systems out of equilibrium.
If a system is in contact with reservoirs exchanging extensive quantities other than
energy, averages and ﬂuctuations of these other quantities can be evaluated following
a similar strategy. We consider, for example, a system exchanging energy and parti-
cles with a reservoir characterized by a temperature T and a chemical potential µ. The
equilibrium distribution of such a system is given by the grand canonical ensemble
peq
ξ = 1
Zgc e−(ϵξ−µNξ)/kBT,
(2.54)
where we deﬁne the grand canonical partition function as a function of α and β
Zgc =
$
ξ
eαNξ −βϵξ ,
(2.55)
with β = 1/kBT and α = µ/kBT. The derivatives of the logarithm of the partition func-
tion return averages and variances of thermodynamic observables in this case too:
∂ln Zgc
∂α
2222
α=µ/kBT,β=1/kBT
= ⟨N⟩eq ;
(2.56a)
∂ln Zgc
∂β
2222
α=µ/kBT,β=1/kBT
= −⟨ϵ⟩eq ;
(2.56b)
and
∂2 ln Zgc
∂α2
2222
α=µ/kBT,β=1/kBT
=
*
N2+eq −
%⟨N⟩eq&2 ;
(2.57a)
−∂2 ln Zgc
∂α ∂β
2222
α=µ/kBT,β=1/kBT
= ⟨N ϵ⟩eq −⟨N⟩eq ⟨ϵ⟩eq ;
(2.57b)
∂2 ln Zgc
∂β2
2222
α=µ/kBT,β=1/kBT
=
*
ϵ2+eq −
%⟨ϵ⟩eq&2 .
(2.57c)
These relations allow us to estimate relative ﬂuctuations of thermodynamic observ-
ables. The symmetry of thermodynamic derivatives yielding the Maxwell relation (2.30)
corresponds to the symmetry of the covariance of ﬂuctuations, as in the example of
eq. (2.57).
In the canonical ensemble, the internal energy E is a ﬂuctuating quantity. Its distri-
bution can be evaluated by means of the so-called Boltzmann-Einstein principle. To
introduce it, we ﬁrst associate each value of the internal energy with the entropy of the
corresponding microcanonical ensemble:
S(E) = kB ln W(E) = kB ln
$
ξ
δ(ϵξ −E),
(2.58)

Basics
19
where δ(x) is the Dirac delta function. We substitute this result in the expression for the
probability of E in the canonical ensemble:
peq(E) =
$
ξ
peq
ξ δ(ϵξ −E) = e(F−E)/kBT $
ξ
δ(ϵξ −E)
= exp
5
−E −TS(E) −F
kBT
6
.
(2.59)
The argument of the exponential on the right-hand side of eq. (2.59) is the diﬀer-
ence between the nonequilibrium free energy Fneq with the given value of E and the
equilibrium free energy F. This reasoning can be extended to multiple observables.
For example, if we look for the joint probability distribution of E and an arbitrary
macroscopic observable A, we obtain
peq(E, A) = exp
5
−E −TS(E, A) −F
kBT
6
,
(2.60)
where
S(E, A) = kB ln
$
ξ
δ(ϵξ −E) δ(aξ −A)
(2.61)
is the entropy of a constrained microcanonical ensemble in which the values of E and
of A are both ﬁxed. In this way, the evaluation of entropy can be used to estimate
probabilities.
2.5
Stochastic dynamics
In stochastic thermodynamics, we study the dynamics of mesoscopic physical sys-
tems subject to random interactions with a heat reservoir. Because of this source of
randomness, at a given time t a system can be found in a given discrete state x with
probability px(t). If the variable x is continuous, we denote by p(x; t) the probability
density of ﬁnding the system in x at time t.
The distribution px(t) is just one way of describing the dynamics. Another way is to
study trajectories of the system:
x = (x(t)).
(2.62)
This notation means that x in boldface (the trajectory) identiﬁes the whole function x(t)
over a given time interval. In the following, we ofen use this notation to distinguish the
whole function x from its instantaneous value x(t). Trajectories of a stochastic system
are characterized by some degree of randomness. We refer to the dynamics of a stochas-
tic system, described either in terms of time-dependent probability distributions or in
terms of trajectories, as a stochastic process.
Many stochastic processes of physical interest possess a useful simplifying prop-
erty called the Markov property. A Markov process is a stochastic process that has
a ﬁnite memory, i.e., one in which knowledge of the recent past fully determines the
statistics of the system in the present. Given an increasing sequence of time instants
(t0, t1, . . . , tn, t), we denote by px;t|xn;tn,xn−1;tn−1,...,x1;t1,x0;t0 the conditional probability
that the system is in a discrete state x at time t, given that it was in state xn at time

20
Chapter 2
tn, in state xn−1 at time tn−1, ..., and in state x0 at time t0. For any increasing sequence
of time instants, a Markov process satisﬁes the condition
px;t|xn;tn,xn−1;tn−1,...,x1;t1,x0;t0 = px;t|xn;tn.
(2.63)
This means that, in a Markov process, given the value of x at a given time tn, the evo-
lution of the system at a later time is independent of events that occurred at earlier
times. The same deﬁnition of a Markov process holds if x is continuous. The condi-
tional probability density px;t|xn;tn of a Markov process satisﬁes a simple relation. We
pick an intermediate time t′ such that t0 < t′ < t. By the law of total probabilities (A.35)
and by the Markov property (2.63), we obtain
px;t|x0;t0 =
$
x′
px;t|x′;t′ px′;t′|x0;t0.
(2.64)
Equation (2.64) is called the Chapman-Kolmogorov equation. Therefore, the knowl-
edge of px;t|x′;t′ and of the distribution px(t0) at an initial time t0 allows one to evaluate
the distribution px(t) at arbitrary times t > t0. The conditional probability px;t|x′;t′ is also
called the propagator or Green function of the process. Conservation of probability
requires
$
x
px;t|x′;t′ = 1,
∀x′ and ∀t′ ≤t.
(2.65)
Applying the Chapman-Kolmogorov equation (2.64) to a time interval of inﬁnitesi-
mal duration dt, we obtain
px(t + dt) =
$
x′
px;t+dt|x′;t px′(t),
(2.66)
where px;t+dt|x′;t can be written in the form
px;t+dt|x′;t = δK
xx′ + dt Lxx′(t),
(2.67)
where δK
xx′ is the Kronecker delta and Lxx′(t) is a matrix that satisﬁes
Lxx′(t) ≥0,
if x ̸= x′;
Lxx(t) = −
$
x′ (̸=x)
Lx′x,
∀x.
(2.68)
The matrix Lxx′ is called the generator of the process. Thus px(t) satisﬁes an evolution
equation of the form
dpx(t)
dt
=
$
x′
Lxx′(t) px′(t),
(2.69)
which has the solution
px(t) =
$
x′
Gxx′(t, t′) px′(t′),
(2.70)

Basics
21
where the Green function is obtained by formally integrating eq. (2.69) with the initial
condition Gxx′(t′, t′) = δK
xx′:
Gxx′(t, t′) = px;t|x′;t′ =
!
T e
7 t
t′ dt′′ L(t′′)#
xx′ .
(2.71)
Here (expression)xx′ denotes the matrix element of expression, and T denotes the time-
ordered product:
!
T e
7 t
t′ dt′′ L(t′′)#
xx′ = δK
xx′ +
) t
t′ dt0 Lxx′(t0)
+
) t
t0
dt1
) t
t′ dt0
$
x0
Lxx0(t1)Lx0x′(t0) + · · · .
(2.72)
In the case where the generator does not depend on time, the Green function depends
only on the time diﬀerence (t −t′).
Markov processes with continuous state space are also deﬁned by the condition
(2.63). In this case, we denote the propagator by p(x; t|x′; t′), and the Chapman-
Kolmogorov equation takes the form
p(x; t|x0; t0) =
)
dx′ p(x; t|x′; t′) p(x′; t′|x0; t0).
(2.73)
The evolution equation now reads
∂
∂tp = L p,
(2.74)
where the generator L is a linear operator that in general includes derivatives with
respect to x. In the next three sections, we discuss separately, and in more detail, Markov
processes with discrete and continuous state space.
2.6
Master equations
Master equations describe the evolution of Markov processes in continuous time
with discrete states. A master equation is deﬁned by the jump rates kxx′ from discrete
state x′ to x. The jump rate is proportional to the conditional probability that a jump
x′ −→x takes place in an inﬁnitesimal time interval (t, t + dt), given that the system
is in state x′ at time t. Speciﬁcally, the jump rates (or simply rates) are related to the
propagator by
px;t+dt|x′;t = kxx′ dt,
x ̸= x′.
(2.75)
The rates can in principle depend on time. Because of the normalization condition,
eq. (2.65), the probability of remaining in a given state x in an inﬁnitesimal time interval
must be equal to 1 −dt 1
x′ kx′x = 1 −dt kout
x , where we deﬁne the escape rate from
state x:
kout
x
=
$
x′
kx′x.
(2.76)

22
Chapter 2
Figure 2.1. Jump network of a system
with three states.
k21
1
3
2
k32
k31
k23
k13
k12
Given the rates, we construct the evolution equation for the probability px(t) by eval-
uating the net probability ﬂow reaching the state x. A state x receives an inﬂow of
probability from other states at rate 1
x′ (̸=x) kxx′px′(t), and returns an outﬂow at rate
1
x′ (̸=x) kx′xpx(t). The net probability ﬂow is given by the inﬂow minus the outﬂow,
leading to the master equation
d
dtpx(t) =
$
x′ (̸=x)
8
kxx′ px′(t) −kx′x px(t)
9
.
(2.77)
We now assume that the rates kxx′ are independent of time, and look at the behav-
ior of the probability distribution px(t) for t →∞. A stationary distribution pst
x is a
probability distribution that satisﬁes
$
x′ (̸=x)
8
kxx′ pst
x′ −kx′x pst
x
9
= 0,
∀x,
(2.78)
and that is therefore a solution of the master equation (2.77) constant in time.
It is useful to represent a master equation via a jump network, where the nodes
represent the states x and the arrows x′ −→x′ represent possible jumps, i.e., jumps with
nonvanishing rates. We draw two opposite arrows between a pair of states if jumps in
both directions are possible. An example of a jump network with three states is shown
in ﬁg. 2.1, where each arrow x′ −→x is associated with a nonzero rate kxx′.
We say that a jump network is connected if any states x can be reached from any
other state x′ by means of a sequence of jumps with nonvanishing rates. In the follow-
ing, we always assume that this property holds, since disconnected master equations
represent multiple noninteracting physical systems that can be studied independently.
Under such assumptions, and provided that the number of states is ﬁnite, the Perron-
Frobenius theorem asserts that the leading eigenvalue, i.e., the eigenvalue with the
largest real part, is purely real and nondegenerate. Moreover, its associated eigenvec-
tor can be chosen to have strictly positive entries. In the case of master equations with
a ﬁnite number of states, the leading eigenvalue must be zero, otherwise the equation
would not preserve normalization. The normalized eigenvector can therefore be inter-
preted as the stationary probability distribution. If the number of states is inﬁnite, the
stationary distribution may not exist: this is the case, for example, of a particle diﬀusing
on an inﬁnite line, when the rates of jumps to the lef or to the right are independent

Basics
23
of its position. If the number of states is ﬁnite, the real parts of all eigenvalues except
the leading one are negative, and therefore the stationary distribution is approached
exponentially fast in time:
lim
t→∞px(t) = pst
x ,
∀x.
(2.79)
The Perron-Frobenius theorem is not limited to generators of Markov processes. In par-
ticular, it does not require the generator to preserve normalization, i.e., that its columns
sum to one. An elementary proof of these properties that does not explicitly rely on the
Perron-Frobenius theorem is reported in appendix A.5.
The master equation can be seen as a continuity equation for the probability. This
interpretation becomes more transparent by introducing the probability current
Jxx′(t) = kxx′px′(t) −kx′xpx(t),
x ̸= x′,
(2.80)
which quantiﬁes the net probability ﬂow from state x′ to state x at time t. In terms of
the probability currents, the master equation can be rewritten in the compact form
d
dtpx(t) =
$
x′ (̸=x)
Jxx′(t).
(2.81)
Equation (2.81) states that, at any given time, the rate change of the probability of being
in a state x is given by the total net ﬂow to state x from all other states x′. If the probability
distribution p is the stationary one, we have
$
x′ (̸=x)
Jxx′ = 0,
∀x.
(2.82)
If for any allowed jump x −→x′ (i.e., such that kx′x > 0) the reverse jump is also allowed
(kxx′ > 0), the system exhibits microscopic reversibility. Most of the systems studied
in stochastic thermodynamics possess this property. In this case, we ofen represent the
jump network by a graph in which each possible jump between two states is represented
by an undirected edge between the corresponding nodes. We discuss in section 8.5 how
to handle microscopically irreversible systems.
If the stationary distribution satisﬁes, beyond eq. (2.78), the stronger condition
kxx′pst
x′ = kx′xpst
x ,
∀x ̸= x′,
(2.83)
then in the stationary state the probability current Jxx′ vanishes for each pair (x, x′) of
diﬀerent states. The condition in eq. (2.83) is known as the detailed balance condition.
If it is satisﬁed, the stationary distribution is called the equilibrium distribution and
we denote it by peq. A master equation admits an equilibrium distribution if, for any
sequence (x0, x1, . . . , xn) of states all diﬀerent from one another, we have
kx0x1kx1x2 · · · kxnx0 = kx0xnkxnxn−1 · · · kx1x0.
(2.84)
This condition requires in particular that microscopic reversibility is satisﬁed. The con-
dition of eq. (2.84) might seem obscure at ﬁrst, but it becomes clearer in the context of a
speciﬁc jump network as in ﬁg. 2.1. Because of the conservation of probability, the sum

24
Chapter 2
of currents arriving at each node must vanish in the stationary state; see eq. (2.82). This
implies that nonvanishing stationary currents can only ﬂow in loops. This requires in
particular that the jump network contains a sequence of distinct nodes, each of them
connected to the previous one by an edge, and where an edge connects the last one
to the ﬁrst. This sequence deﬁnes a cycle in the network. A nonvanishing current in
a cycle can only be sustained if the rates “pushing” the currents clockwise and coun-
terclockwise do not balance. The balance conditions for the rates along each cycle of
the network are indeed given by eq. (2.84). This also means that, if there are no cycles
(e.g., if the network is linear or treelike), then the stationary solution always satisﬁes
detailed balance conditions, provided that microscopic reversibility holds. When the
condition (2.84) is not satisﬁed for some cycles, the probability currents along these
cycles do not vanish in the stationary state. In this case, the stationary distribution is
also called a nonequilibrium steady state.
In thermodynamic systems, the condition of detailed balance is ofen associated with
thermodynamic equilibrium, and the stationary distribution peq
x appearing in eq. (2.83)
is the Boltzmann distribution, eq. (2.42). We further discuss this point in section 3.1.
Then, assuming that kx′x > 0, eq. (2.83) implies that
kxx′
kx′x
= peq
x
peq
x′
= e−(ϵx−ϵx′)/kBT.
(2.85)
Although the master equation (2.77) is linear, solving it explicitly can be diﬃcult
when the number of states is large. To tackle it numerically, it is convenient to sim-
ulate an ensemble of random trajectories rather than integrating the master equation
itself. Trajectories of a master equation can be very eﬃciently simulated by means of the
Gillespie algorithm, which is brieﬂy described in appendix A.6.
2.7
Trajectories of master equations
During its evolution in a time interval [t0, tf], a system described by a master equa-
tion visits a sequence x0, x1, . . . , xf of states (ﬁg. 2.2). We call tk the random time at
which the system jumps from state xk−1 to state xk ̸= xk−1. The system is in state xk
during a time interval tk ≤t < tk+1. Thus the trajectory x in the given time interval is
made of a sequence of dwells, where the system remains in the same state, separated
by jumps, where the system changes state, as shown in ﬁg. 2.2. The whole trajectory x
is then encoded in the sequence
x = ((x0, t0), (x1, t1), . . . , (xf, tn), tf) .
(2.86)
We wish to evaluate the probability density Px of the trajectory x. To this aim, we dis-
cretize the time interval into N intervals of short duration "t = T /N , where T =
tf −t0 is the duration of the whole time interval. We then approximate the trajectory by
the sequence xdsc = (x0, x1, . . . , xN ) of states at the time tℓ, where tℓ= t0 + ℓ"t. For
each small interval (tℓ, tℓ+ "t), the conditional probability that x(tℓ+ "t) = x, given
that x(tℓ) = x′, is given by px;t+"t|x′;t. The probability of the discrete trajectory is then
Pxdsc|x0 =
N
,
ℓ=1
pxℓ;tℓ−1+"t|xℓ−1;tℓ−1.
(2.87)

Basics
25
x
t
x0
x1
x2
x3
x4
t0
t1
t2
t3
t4
jump
}
}
dwell
Figure 2.2. Example of a trajectory of a master equation.
From the master equation, we approximate the conditional probability by
px;t+"t|x′;t ≈δK
xx′ + "t Lxx′(t),
(2.88)
where Lxx′(t) is the generator. This expression yields conditional probabilities that are
properly normalized. Therefore, the probability of the trajectory x is approximately
equal to
Px|x0 ≈Pxdsc|x0 ≈
N
,
ℓ=1
!
δK
xℓxℓ−1 + "t Lxℓxℓ−1(tℓ−1)
#
.
(2.89)
On the one hand, we can explicitly evaluate the products over each dwell:
,
ℓ∈dwell
pxℓ;tℓ−1+dt|xℓ;tℓ−1 =
,
ℓ
%
1 −dtℓkout
xℓ
&
≈e−1
ℓkout
xℓ(t) dtℓ≈e−
7
dt kout
x(t)(t).
(2.90)
On the other hand, the probability that the system undergoes a jump from x′ to x in the
short time interval [tℓ, tℓ+ dt] is given by kxx′ dt px′(tℓ) to ﬁrst order in dt. Therefore,
the factors contributing to the probability of a trajectory x due to the sequence of dwells
and jumps are
Px = e−
7 tf
tn dt′ kout
xn (t′)kxnxn−1(tn) e−
7 tn−1
tn
dt′ kout
xn−1(t′) · · ·
× e−
7 t1
t2 dt′ kout
x1 (t′)kx1x0(t1) e−
7 t0
t1 dt′ kout
x0 (t′)px0(t0).
(2.91)
This expression includes the probability of the initial state px0(t0). The choice of writing
the factors on the right-hand side of eq. (2.91) in temporal order from right to lef might
seem awkward for a reader used to writing in the Latin alphabet from lef to right.
However, it becomes quite natural when thinking of the probability density as a product

26
Chapter 2
of matrix elements, one for each inﬁnitesimal time step, acting on the initial probability
px0(t0).
We deﬁne the integral over trajectories in the following way:
)
Dx · · · =
∞
$
n=0
$
x0,x1,...,xn
) t2
t0
dt1
) t3
t2
dt2 · · ·
) tf
tn−1
dtn · · · .
(2.92)
With this deﬁnition, the probability density Px satisﬁes the normalization condition
)
Dx Px = 1.
(2.93)
Indeed, comparing eqs. (2.91) and (2.92) with eqs. (2.71) and (2.72), we obtain
)
Dx Px =
$
xfx0
'
T e
7 tf
t0 dt L(t)
(
xfx0
px0(t0)
=
$
xfx0
pxf;tf|x0;t0 px0(t0) = 1.
(2.94)
2.8
Fokker-Planck equation (*)
The stochastic dynamics of systems with continuous state space and continuous
trajectories is described by the Fokker-Planck equation and by stochastic diﬀerential
equations. These tools were introduced in physics to investigate Brownian motion.
Einstein described Brownian motion as the phenomenon by which “bodies of micro-
scopically visible size suspended in a liquid perform [random] movements of such
magnitude that they can be easily observed in a microscope.” We follow his line of
reasoning to derive the Fokker-Planck equation.
We consider a particle that moves along a one-dimensional continuous coordinate
x. We call p(x; t) the probability density of the position x of a particle at time t. We ﬁrst
assume that the particle is immersed in a uniform ﬂuid and is not subject to external
applied forces. Due to random interactions with the ﬂuid particles, during a short time
interval of duration "t, the particle experiences a random displacement "x. If "t is
very small, the displacement "x is largely in the direction of the initial velocity of the
particle due to inertia. However, interactions with the particles of the ﬂuid soon wipe
out this dependence. Therefore, if "t is large enough but still small, we expect this
displacement to be independent in nonoverlapping time intervals. We call ψ("x) the
probability distribution of "x over these time intervals. In the absence of externally
applied forces, ψ("x) must be an even function of "x due to symmetry. We express
p(x; t + "t) in terms of p(x; t) and the displacement distribution
p(x; t + "t) =
)
d"x ψ("x) p(x −"x; t).
(2.95)
Since "t is small, "x is also small. We therefore expand p(x −"x; t) in a Taylor series
to second order:

Basics
27
p(x; t + "t) ≈
)
d"x ψ("x)
5
p(x; t) −"x ∂
∂xp(x; t) + 1
2"x2 ∂2
∂x2 p(x; t)
6
.
(2.96)
We then perform the integration over "x. Since ψ("x) is an even function, the term
proportional to "x vanishes upon integration. We thus obtain
p(x; t + "t) −p(x; t) ≈1
2
*
"x2+ ∂2
∂x2 p(x; t).
(2.97)
We now divide eq. (2.97) by "t and take the limit "t →0. In taking this limit, we make
the crucial assumption that
lim
"t→0
*
"x2+
2"t = D,
(2.98)
where D is a ﬁnite quantity called the diﬀusion constant. If this assumption holds, we
obtain the diﬀusion equation:
∂
∂tp(x; t) = D ∂2
∂x2 p(x; t).
(2.99)
Starting from a localized initial condition p(x; t0) = δ(x −x0), the solution of the
diﬀusion equation is a Gaussian distribution,
p(x; t) =
1
√
4π DT
exp
'
−(x −x0)2
4 DT
(
,
(2.100)
where T = t −t0.
In a more general case, for instance when the particle is subject to forces, the dis-
tribution of the displacements "x might depend on x, t, and might not necessarily be
even. We express it as
p("x; "t, x, t) = p(x + "x, t + "t|x, t).
(2.101)
We assume that the following limits exist and deﬁne the drif and diﬀusion coeﬃcients,
respectively, by
v(x, t) = lim
"t→0
⟨"x⟩x,t
"t
;
(2.102a)
D(x, t) = lim
"t→0
*
"x2+
x,t
2 "t .
(2.102b)
The averages ⟨. . .⟩x are taken over the distribution of displacements. Then the dynam-
ics is described by the Fokker-Planck equation (also called the Kolmogorov forward
equation):
∂
∂tp(x; t) = −∂
∂x
8
v(x, t) p(x; t)
9
+ ∂2
∂x2
8
D(x, t) p(x; t)
9
.
(2.103)

28
Chapter 2
Equation (2.103) is derived in appendix A.7. The ﬁrst term in eq. (2.103) is the drif and
is associated with the local mean velocity of particles. The second term is the diﬀusion,
which represents the “random,” unbiased component of the motion.
The Fokker-Planck equation can also be written as a continuity equation,
∂
∂tp(x; t) = −∂
∂xJ(x; t),
(2.104)
where the probability current is deﬁned by
J(x, t) = v(x, t) p(x; t) −∂
∂x
8
D(x, t) p(x; t)
9
.
(2.105)
The Fokker-Planck equation is a second-order partial diﬀerential equation. To solve it,
we need to specify the initial condition, i.e., the distribution p(x; t0), and the bound-
ary conditions. Ofen the Fokker-Planck equation is studied in the inﬁnite interval x ∈
(−∞, ∞), for which the boundary conditions are simply that the probability vanishes
as |x| →∞.
The solution p(x; t|x0; t0) of the Fokker-Planck equation with initial condition δ(x −
x0) at t = t0 is the propagator, which expresses the conditional probability density of
ﬁnding the particle close to x at time t > t0, given that it was at x0 at time t0. In some
cases, one is interested in the dependence of this probability density on the earlier state
x0 and the earlier time t0. This dependence is governed by the Kolmogorov backward
equation:
−∂
∂t0
p(x; t|x0; t0) = v(x0, t0) ∂
∂x0
p + D(x0, t0) ∂2
∂x2
0
p.
(2.106)
We derive this equation in appendix A.7.
We now consider cases where the coeﬃcients v(x, t) and D(x, t) of the Fokker-Planck
equation do not depend on time. The stationarity condition reads
∂
∂xJst(x) = 0,
(2.107)
where the stationary current is
Jst(x) = v(x) pst(x) −∂
∂x
8
D(x) pst(x)
9
.
(2.108)
When considering an inﬁnite interval, the stationary solution does not necessarily exist.
A prominent example is the diﬀusion equation (2.99), whose solution (2.100) does not
tend to a limiting form as T →∞.
In some cases, the Fokker-Planck equation also admits a stationary solution with a
vanishing stationary current:
Jst(x) = 0,
∀x.
(2.109)
Equation (2.109) is the detailed balance condition for Fokker-Planck equations. In gen-
eral, detailed balance is a rather restrictive condition. However, there are physically
relevant scenarios where this property holds, such as many one-dimensional systems

Basics
29
and most systems at thermodynamic equilibrium, as discussed at the end of section 2.6.
In the one-dimensional case, when detailed balance holds, the stationary solution is
given by
pst(x) ∝
1
D(x) exp
') x
x0
dx′ v(x′)
D(x′)
(
,
(2.110)
where x0 is arbitrary and the proportionality constant is determined by the normaliza-
tion condition
7 ∞
−∞dx pst(x) = 1.
2.9
Langevin equation (*)
Trajectories of a Brownian particle with drif coeﬃcient v(x, t) and diﬀusion coeﬃ-
cient D(x, t) are solutions of the Langevin equation
dx
dt = v(x, t) + σ(x, t) ξ(t),
(2.111)
where σ(x, t) is a function related to D(x, t) and ξ(t) is a random quantity. We impose
that this random quantity is unbiased, ⟨ξ(t)⟩= 0, ∀t. We also assume that displace-
ments in nonoverlapping time intervals are uncorrelated. This amounts to requiring
*
ξ(t) ξ(t′)
+
= 0 for t and t′ suﬃciently far apart. Assuming that this holds whenever
t ̸= t′, we obtain
*
ξ(t)ξ(t′)
+
∝δ(t −t′). We set the proportionality constant equal to 1
by suitably deﬁning σ(x, t). A variable ξ(t) satisfying these properties is called white
noise. In the mathematical literature, Langevin equations are an example of stochastic
diﬀerential equations.
Equation (2.111) is ill deﬁned as it stands, since the variance of the random quantity
ξ(t) is a delta function in time. The mathematical tools to deal with stochastic diﬀer-
ential equations were developed well afer the work of Langevin and are the subject of
the theory of stochastic calculus. Stochastic calculus is nowadays a rather developed
ﬁeld of mathematics. In this section, we concentrate on the most important and useful
results without going too deep into the mathematical details.
We formally evaluate the time integral of ξ(t):
W(t) =
) t
t0
dt′ ξ(t′) =
) t
t0
dW.
(2.112)
The random process W(t) is called the Wiener process. It has vanishing average
⟨W(t)⟩=
:) t
t0
dt′ ξ(t′)
;
=
) t
t0
dt′ *
ξ(t′)
+
= 0.
(2.113)
Since ξ(t) is unbiased on average, so is its time integral W(t). The second moment of
W(t) is given by
*
W2(t)
+
=
:) t
t0
dt′
) t
t0
dt′′ ξ(t′)ξ(t′′)
;
=
) t
t0
dt′
) t
t0
dt′′ *
ξ(t′)ξ(t′′)
+
=
) t
t0
dt′
) t
t0
dt′′ δ(t′ −t′′) = T ,
(2.114)

30
Chapter 2
where T = t −t0. In general, it can be shown that the distribution of W(t) is Gaussian:
p(W(t) = w) =
1
√
2π T
e−w2/2 T .
(2.115)
Mathematicians prefer to formally deﬁne W(t) as a process whose increments over a
time interval of duration T are Gaussian random variables with zero mean and variance
T . They allow physicists to use ξ(t) as an ill-deﬁned “derivative” of W(t).
We now consider a Langevin equation without drif:
dx
dt = σ ξ(t),
(2.116)
where we assume that the coeﬃcient σ is constant. Integrating from t = t0 to a generic
time t, we obtain
x(t) = x0 + σ W(t).
(2.117)
Thus the distribution of x(t) is a Gaussian centered in x0 and with variance σ 2 *
W2(t)
+
=
σ 2T . By comparing with the diﬀusion equation, eq. (2.99) and its solution, we conclude
that this Langevin equation describes the trajectories of a diﬀusion equation with a
diﬀusion coeﬃcient
D = σ 2/2.
(2.118)
By going through the derivation of the Fokker-Planck equation in section 2.8, one
sees that the solution of the Langevin equation (2.111) with constant σ describes a pro-
cess satisfying the Fokker-Planck equation (2.103) with the same drif v(x, t) and with
diﬀusion coeﬃcient D = σ 2/2.
Processes where σ depends on x are ofen called Langevin equations with multi-
plicative noise in the physics literature. This term is somewhat misleading as it appears
to be limited to the case in which σ ∝x. In the presence of multiplicative noise, the
interpretation of eq. (2.111) is mathematically subtle. Depending on its interpretation,
it may or may not represent the behavior of the solutions of eq. (2.103). This is due to the
fact that, for short time intervals dt, the typical increments of W are much larger than
dt, and thus the second term of the Langevin equation dominates over the ﬁrst one.
Formally, solving a Langevin equation requires the evaluation of stochasticintegrals
of the form
) tf
t0
dt ξ(t) f (x(t), t) =
) tf
t0
dW(t) f (x(t), t),
(2.119)
where f (x, t) is a given function. The ambiguity in the interpretation of the Langevin
equation stems from the ill-deﬁned nature of stochastic integrals. There are two major
conventions to resolve this ambiguity and therefore to assign a precise interpretation to
the corresponding Langevin equation:
Ito convention. The Ito convention is deﬁned by the prescription
II = lim
dt→0
N
$
k=0
[W(tk + dt) −W(tk)] f (x(tk), tk),
(2.120)

Basics
31
where ti = t0 + i dt and the sum runs over the N = (tf −t0)/dt intervals of dura-
tion dt in which we divide the interval [t0, tf]. In the Ito convention, the function
f (x(t), t) is evaluated at the beginning of each inﬁnitesimal time interval [tk, tk + dt].
We denote the Ito convention by a dot product symbol:
II =
) tf
t0
dW · f (x(t′), t′).
(2.121)
Stratonovich convention. The Stratonovich convention is deﬁned by
IS = lim
dt→0
N
$
k=0
[W(tk + dt) −W(tk)] f
'x(tk + dt) + x(tk)
2
, tk + dt
2
(
= lim
dt→0
N
$
k=0
[W(tk + dt) −W(tk)] 1
2
8
f (x(tk + dt), tk + dt) + f (x(tk), tk)
9
.
(2.122)
In the Stratonovich convention, f (x, t) is evaluated at the midpoint of each inﬁnites-
imal interval [tk, tk + dt]. We can equivalently evaluate the function f (x, t) as the
average of its values at the boundaries of the interval: the diﬀerence between these
two prescriptions vanishes as dt →0. We denote the Stratonovich convention by a
circle product symbol:
IS =
) tf
t0
dW ◦f (x(t′), t′).
(2.123)
In conventional (nonstochastic) integrals, the choices (2.120) and (2.122) yield the
same result as dt →0. This is not necessarily the case for stochastic integrals. Therefore,
a Langevin equation is not fully deﬁned unless one declares whether stochastic integrals
are interpreted according to the discretization of eq. (2.120) or (2.122).
The Langevin equation (2.111) is equivalent to the Fokker-Planck equation (2.103)
under the Ito convention. As shown in appendix A.8, the Fokker-Planck equation
corresponding to the Stratonovich convention looks slightly diﬀerent:
∂
∂tp(x; t) = −∂
∂x
%
v(x, t) p(x; t)
&
+ 1
2
∂
∂x
5
σ(x, t) ∂
∂x
%
σ(x, t) p(x; t)
&6
.
(2.124)
In this interpretation, the current is deﬁned by
J(x, t) = w(x, t) p(x; t) −D(x, t) ∂
∂x p(x; t),
(2.125)
where the diﬀusion coeﬃcient is given by D(x, t) = σ 2(x, t)/2 as in the Ito convention,
and
w(x, t) = v(x, t) −1
2σ(x, t) ∂
∂xσ(x, t) = v(x, t) −1
2
∂
∂xD(x, t).
(2.126)
When σ (or D) does not depend on x, eq. (2.124) reduces to eq. (2.103), conﬁrming the
equivalence of the two interpretations in this special case.

32
Chapter 2
There are rules for transforming a Langevin equation interpreted in the Ito con-
vention to an equivalent one interpreted in the Stratonovich convention and back. As
shown in appendix A.8, one obtains the rule that
dx
dt = v(x, t) + 1
2 σ(x, t) ∂
∂xσ(x, t) + σ(x, t) ξ
(Ito)
is equivalent to
dx
dt = v(x, t) + σ(x, t) ξ
(Stratonovich).
(2.127)
The extra term necessary to change convention is ofen called the noise-induced drif.
Which convention is the most appropriate to describe a given natural phenomenon?
The short answer is “it depends.” One can show that, considering a noise source with
a ﬁnite correlation time and then taking the limit of vanishing correlation time, the
resulting Langevin equation is of the Stratonovich type. Therefore, Stratonovich is the
correct interpretation for many systems aﬀected by noise characterized by a negligible
but ﬁnite correlation time. On the other hand, the evaluation of Stratonovich integrals
requires knowledge of the “future,” i.e., of the value of functions afer the initial instant
of each time step; see eq. (2.122). This aspect is unrealistic when the noise is generated
by the physical process itself. In general, when modeling a system with multiplicative
noise, it is safer to derive rigorously the Langevin equation and therefore to make sure
that the interpretation is correct.
Traditionally, most physicists tend to prefer to work with the Stratonovich conven-
tion, whereas mathematicians tend to prefer the Ito convention. It is useful to be aware
of the pros and cons of this choice. The Stratonovich convention has the advantage of
respecting the chain rule, i.e., d[f (x)]/dt = f ′(x) dx/dt, even if x follows a Langevin
equation. In the case of Ito, assuming that x(t) is the solution of eq. (2.111), the
derivative df /dt of f (x(t)) is instead given by
df
dt = v(x, t) f ′(x) + 1
2σ 2(x, t) f ′′(x) + σ(x, t) f ′(x) ξ.
(2.128)
This relation is known as the Ito formula. Therefore, the Ito approach introduces a
complication that is not present in the Stratonovich one. It has however the advantage
that expectations of stochastic integrals, such as
:)
dW · f (x)
;
,
always vanish in the Ito convention. This is in general not true for the Stratonovich
convention, where such integrals must be evaluated on a case-by-case basis.
2.10
Information
It is ofen useful to quantify the “uncertainty” associated with a certain probability
distribution over the states of a system S. A measure of uncertainty must satisfy three
reasonable properties: it must vanish when the system is known to be in one state, it
must be maximal when the distribution is uniform over all possible states, and, if the

Basics
33
system is made up of two independent systems, it must be the sum of the two uncer-
tainties. Claude Shannon showed that the only function of the probabilities that satisﬁes
these three requirements (up to a multiplicative constant) is the Shannon entropy
H(S) = −
$
x
px ln px,
(2.129)
where the sum runs over all the states of system S. The larger H(S), the larger the
uncertainty about S, up to a maximum H(S) = ln N when the probability is uniformly
distributed over N states. With a slight abuse of notation, we interchangeably use H(S)
or H(p) to denote the Shannon entropy of a system S having distribution p = (px)
over its states. In the latter case, we use the notation p = (px) to denote by the sym-
bol p the entire vector px. In the simple case of a binary variable (x ∈{0, 1}) with equal
probabilities p0 = p1 = 1/2, one has
H(S) = ln 2.
(2.130)
This quantity is called a bit of information.
If the system S is at thermal equilibrium, its thermodynamic entropy S is propor-
tional to the Shannon entropy of its distribution over the microstates
S = kB H(S) = −kB
$
ξ
peq
ξ ln peq
ξ ,
(2.131)
where kB is the Boltzmann constant. Indeed, evaluating H(S) with peq given by (2.45)
leads to
H(S) = −
$
ξ
peq
ξ
F −ϵξ
kBT
= 1
kBT
%⟨ϵ⟩eq −F
&
= S
kB
,
(2.132)
since F = ⟨ϵ⟩eq −TS. Equation (2.131) is known as the Gibbs relation.
The dissimilarity between two probability distributions p = (px) and q = (qx) over
the states of the same system is measured by the Kullback-Leibler divergence (also
called the relative entropy),
DKL(p∥q) =
$
x
px ln px
qx
.
(2.133)
The Kullback-Leibler divergence has the following properties:
• DKL(p∥q) ≥0;
• DKL(p∥q) = 0 only if px = qx, ∀x.
To prove these results, we consider that −ln x is a convex function of x and there-
fore satisﬁes the Jensen inequality ⟨−ln x⟩≥−ln ⟨x⟩; see appendix A.1. We therefore
obtain
DKL(p∥q) = −
$
x
px ln qx
px
≥−ln
$
x
px
qx
px
= −ln
$
x
qx = −ln 1 = 0.
(2.134)

34
Chapter 2
In eq. (2.134), equality holds only if qx = px for all x, since −ln x is a strictly convex
function. One has in general DKL(p∥q) ̸= DKL(q∥p). For instance, if qx > 0, ∀x, while
px = 0 for some x, DKL(p∥q) is ﬁnite, but DKL(q∥p) diverges.
We now consider two systems S1 and S2 whose states are respectively denoted
by x and y. The information shared by the two systems is measured by the mutual
information
I(S1 : S2) =
$
x,y
px,y ln px,y
pxpy
,
(2.135)
where px,y is the joint probability distribution of the two systems and px, py are their
marginal distributions; see appendix A.3. The mutual information can be seen as
the Kullback-Leibler divergence between the joint distribution px,y and the product of
the marginal distributions px and py. Therefore, it is nonnegative and vanishes only
if the two variables x and y are independent. The mutual information is symmetric:
I(S1 : S2) = I(S2 : S1). It can also be expressed in terms of the conditional probability
distribution px|y of the state of S1, given that of S2, by
I(S1 : S2) =
$
x,y
px,y ln px|y −
$
x
px ln px.
(2.136)
The second term on the right-hand side is the Shannon entropy H(S1) of S1. The ﬁrst
term is minus the conditional entropy of S1, given S2:
H(S1|S2) = −
$
x,y
px,y ln px|y.
(2.137)
When the two systems are statistically independent, i.e., px,y = pxpy, we have
H(S1|S2) = H(S1), and the mutual information vanishes. We moreover have
I(S1 : S2) = H(S1) −H(S1|S2) = H(S2) −H(S2|S1).
(2.138)
The Shannon entropy H(S1, S2) of the joint distribution of the states of S1 and S2 is
called the joint entropy of the two variables. It satisﬁes the relation
H(S1, S2) = H(S1) + H(S2|S1),
(2.139)
which is known as the chain rule. By exploiting (2.138), we also have
H(S1, S2) = H(S1) + H(S2) −I(S1 : S2).
(2.140)
Equation (2.140) clariﬁes that the mutual information quantiﬁes the reduction of the
uncertainty of the pair (S1, S2) due to their mutual dependence. A similar relation holds
for the Kullback-Leibler divergence:
DKL(p(S1, S2)∥q(S1, S2)) = DKL(p(S1)∥q(S1)) + DKL(p(S2|S1)∥q(S2∥S1)),
(2.141)
where
DKL(p(S2|S1)∥q(S2∥S1)) =
$
x,y
px,y ln px|y
qx|y
.
(2.142)

Basics
35
This result can be veriﬁed by a direct calculation. An immediate consequence of
eq. (2.141) is that the Kullback-Leibler divergence between two systems cannot increase
if we average out some variables.
Given three systems S1, S2, and S3, whose states are respectively denoted by x, y,
and z, the conditional mutual information between S1 and S2, given S3, is deﬁned by
I(S1 : S2|S3) =
$
x,y,z
pxyz ln
pxy|z
px|zpy|z
,
(2.143)
where px|z and py|z are conditional marginal distributions, i.e.,
py|z =
$
x
pxy|z;
px|z =
$
y
px,y|z.
(2.144)
The conditional mutual information I(S1 : S2|S3) is nonnegative and vanishes only if
the joint conditional probability distribution of x and y, given z, factorizes into the prod-
uct of the conditional marginal distributions. This happens, for instance, if S1 depends
on S2 only via S3. The mutual information also satisﬁes a chain rule, which reads
I(S1, S2 : S3) = I(S1 : S3) + I(S2 : S3|S1),
(2.145)
where I(S1, S2 : S3) is the mutual information between S1 ∪S2 and S3. Derivation of
eq. (2.145) is lef as exercise 2.7.
2.11
Further reading
The aim of this chapter is limited to giving a bird’s-eye perspective on theories that
lie at the foundation of stochastic thermodynamics. Several books explain much more
extensively the main concepts presented in each of the sections of this chapter, and
sometimes choosing among the many classic references might be a matter of personal
taste. Callen [28] and Pippard [130] are established textbooks in thermodynamics.
Feynman’s lectures in physics [54] provide an original introduction to thermodynamics
and statistical mechanics, including ideas that, in hindsight, were seminal for stochas-
tic thermodynamics. De Groot and Mazur [37] is a good reference on “nonstochastic”
nonequilibrium thermodynamics. Landau et al. [95], Chandler [29], and Peliti [125]
are classic references on statistical mechanics.
Equation (2.52) is a basic example of a ﬂuctuation-dissipation relation. These rela-
tions are of paramount importance in nonequilibrium statistical physics, as discussed
throughout this book. Marini Bettolo Marconi et al. [110] provide a comprehensive
review on ﬂuctuation-dissipation relations.
The basic concepts of stochastic processes were introduced into physics by the
pioneering work of Einstein [44] on Brownian motion (English translation in [46]).
Nowadays the theory of stochastic processes is rather well developed, even if it is still
playing a relatively marginal role in many physics curricula. There are many excel-
lent books on stochastic processes that present the theory at diﬀerent mathematical
levels and with slightly diﬀerent angles. Berg [15] is a basic introduction that focuses
on the physical concepts rather than on the mathematics. Gardiner [59], van Kam-
pen [171], and Risken [139] are references of a more mathematical nature. Øksendal

36
Chapter 2
[120] is an excellent, though even more advanced book. Other books focus on speciﬁc
aspects of the theory of stochastic processes. One important example is ﬁrst-passage
time problems, discussed in Redner [138].
The seminal paper by Shannon [154] already contains the main ideas in information
theory. Khinchin [87] provides a more systematic introduction to Shannon’s theory.
Cover and Thomas [32] and MacKay [105] present information theory in a more
modern and extended way.
2.12
Exercises
2.1
Consider a master equation with three states, x ∈{0, 1, 2}, and with constant
rates kxx′ (x ̸= x′), none of which vanishes. Write down the explicit form of
the master equation. Evaluate the steady-state probability distribution pst
x ,
x ∈{0, 1, 2} and the corresponding probability current Jst = kx′xpst
x −kxx′pst
x′
with x′ = x + 1 mod 3. Derive the conditions on the rates k such that detailed
balance is satisﬁed, i.e., such that Jst vanishes.
2.2
Consider a master equation with four states, x ∈{0, 1, 2, 3}, and with rates kxx′
(∀x ̸= x′), none of which vanishes. Show that if kxx′ = kx′x, then the unique
stationary distribution is p0 = p1 = p2 = p3 = 1/4. Show with an example that
this is not necessarily the case if some of the rates vanish.
2.3
A collection of N white balls and N black balls, with N ≥3, are randomly dis-
tributed in two urns, so that each contains N balls. At each step t, one ball
is extracted from each urn; the two balls are swapped and put back in the
urns. Denote by xt the number of white balls in the ﬁrst urn. Show that xt is
a Markov process and express its jump rates kxx′ = p(xt+1 = x|xt = x′). Discuss
whether the process satisﬁes detailed balance. Evaluate the stationary distribu-
tion pst
x and the decay rate of the correlation function ⟨xtx0⟩−⟨x0⟩2, where x0
is drawn from the stationary distribution.
2.4
Consider an inﬁnite sequence of independent, identically distributed real-
valued random variables y = (y0, y1, . . .). Another sequence x = (x0, x1,2 , . . .)
is recursively deﬁned by
x0 = y0;
xn = yn + a xn−1,
where 0 < a < 1.
a. Show that, if the distribution of yℓis Gaussian, the distribution of xℓ
approaches for ℓ→∞a stationary Gaussian distribution and evaluate
its parameters.
b. Show that, if yℓis not Gaussian distributed, the stationary distribution of
xℓ, if it exists, is not Gaussian.
2.5
A Brownian particle is conﬁned in a one-dimensional potential. Its posi-
tion x(t) satisﬁes the following Langevin equation in the Stratonovich
representation:

Basics
37
dx
dt = −0kx + σ ξ(t),
where σ > 0 and ξ(t) is Gaussian random white noise, satisfying ⟨ξ(t)⟩= 0
and
*
ξ(t) ξ(t′)
+
= δ(t −t′) ∀t, t′. Write the formal solution of the equation
for t ≥0 as a function of the initial condition x(0) = x0 and of the realization
ξ(t′) (0 ≤t′ ≤t) of the noise. Evaluate ⟨x(t)⟩and
*
(x(t) −⟨x(t)⟩)2+
for t →∞.
Assuming that the potential is harmonic, U(x) = 1
2kx2, ﬁnd the relation that
0 and σ must satisfy for the particle to reach the equilibrium distribution
peq(x) ∝exp(−U(x)/kBT) for t →∞. Write down the Fokker-Planck equa-
tion associated with the Langevin equation and show that the equilibrium
distribution is a solution.
2.6
Prove eq. (2.110) for a system satisfying a one-dimensional Fokker-Planck
equation (2.103), assuming that the detailed balance condition eq. (2.109) is
satisﬁed.
2.7
Prove the chain rule for the mutual information, eq. (2.145).

CHAPTER 3
Stochastic Thermodynamics
The fundamental concepts of stochastic thermodynamics are introduced in this chapter.
We focus on an out-of-equilibrium mesoscopic physical system described by a master
equation and discuss how stochastic thermodynamic observables can be deﬁned at the
level of individual trajectories.
3.1
The system
We consider a mesoscopic physical system that can be found in discrete mesostates,
identiﬁed by a variable x. Mesostates can represent, for example, the number of
molecules participating in a chemical reaction or diﬀerent conformations of a protein.
Physically, a mesostate corresponds to a collection of microscopic conﬁgurations, from
which it is obtained by a suitable coarse-graining procedure. We discuss in more detail
the concept of coarse graining in section 3.12. For the time being, we assume that this
procedure has been successfully carried out, and that the dynamics at the mesoscopic
level has been properly determined. Since stochastic thermodynamics focuses on the
mesoscopic dynamics, unless some ambiguity is possible, we refer to mesostates simply
as states.
Our mesoscopic system interacts with a heat reservoir. Such interactions are uncon-
trolled, making the dynamics of the system intrinsically stochastic. This means that we
expect to observe a diﬀerent trajectory every time we repeat an experiment, even if we
carefully prepare the system in the same state at the start of each realization. We there-
fore introduce the probability distribution px(t) of ﬁnding the system in state x at time
t. This probability distribution evolves according to a master equation of the form given
in eq. (2.77):
d
dtpx(t) =
!
x′ (̸=x)
"
kxx′px′(t) −kx′xpx(t)
#
.
(3.1)
Physical details of the system and the nature of its interactions with the reservoir are all
encoded into the jump rates, which can in principle be time dependent: kxx′ = kxx′(t).
The ﬁrst step to establish a connection with thermodynamics is to determine the nature
of this encoding.
We begin with the simple case where the system is in contact with a single heat reser-
voir. A crucial assumption in stochastic thermodynamics is that this reservoir is very
large and relaxes quickly enough to be considered at thermodynamic equilibrium at

Stochastic Thermodynamics
39
all times. In the absence of external forces, the jump rates satisfy the detailed balance
condition (2.85):
kxx′
kx′x
= exp
$ϵx′ −ϵx
kBT
%
,
(3.2)
where ϵx is the energy of the system in state x. The condition (3.2) ensures that the
canonical equilibrium distribution peq
x = e(F−ϵx)/kBT is the unique stationary distribu-
tion of the process and therefore that, independent of the initial condition px(t0), the
system eventually relaxes to it. It also implies that the net probability current between
any pair of states vanishes at stationarity. These two conditions are the hallmarks of a
system at equilibrium with a heat reservoir.
It is ofen easier to estimate energies and the temperature T rather than the jump
rates directly. In such cases, we can use eq. (3.2) to express rates in terms of known
quantities. However, eq. (3.2) contains the two unknowns kxx′ and kx′x and is therefore
underdetermined. This means that there is some freedom in expressing the two jump
rates. One choice that we ofen make is to write them in a symmetric form:
kxx′ = ωxx′ e−(ϵx−ϵx′)/2kBT,
kx′x = ωxx′ e−(ϵx′−ϵx)/2kBT,
(3.3)
where ωxx′ = ωx′x is the intrinsic rate of jumps between states x and x′ in the absence
of an energy diﬀerence. The intrinsic rate vanishes if the two states are not connected
by jumps. Another possibility is
kxx′ = ωxx′ e−ϵx/kBT,
kx′x = ωxx′ e−ϵx′/kBT.
(3.4)
Alternatively, it might be the case that only one jump rate depends on the energies:
kxx′ = ωxx′ e−(ϵx−ϵx′)/kBT,
kx′x = ωxx′.
(3.5)
These possibilities are not exhaustive, and the choice is ofen dictated by physical con-
siderations. For example, if we know that the rate kx′x cannot depend on the values of
the energy, then eq. (3.5) is the appropriate choice. Intrinsic rates may incorporate the
eﬀect of activation barriers, as discussed in section 3.12.
We can perturb the system away from equilibrium in two diﬀerent, but not mutually
exclusive, ways:
Manipulation. A manipulation is an external, time-dependent control of the system.
In a manipulation, the energies of states depend on an external control parameter
ϵx = ϵx(λ), which is made to change with time: λ = λ(t). When we need to stress this
dependence, we use the short notation ϵx(t) instead of ϵx(λ(t)). Experiments carried
out with optical tweezers provide paradigmatic examples of manipulated systems. In
such experiments, a laser creates an energy potential that traps a mesoscopic physi-
cal system, be it a colloidal particle or a macromolecule. The external manipulation
modulates the stiﬀness and/or the position of the optical trap.
Driving. A driving is a coupling of the system to an external agent that exchanges with
it a certain amount of energy when the system performs speciﬁc jumps. In this case,
we denote by δxx′ the energy provided by the external agent during a jump from x′
to x. The energy thus provided breaks detailed balance and is immediately released

40
Chapter 3
to the reservoir. For example, in the case of biological enzymes fueled by chemical
energy, the driving represents the energetic contribution due to ATP hydrolysis.
Our ﬁrst step is to understand how the detailed balance condition (2.84) is modi-
ﬁed in systems brought out of equilibrium by means of manipulations and/or drivings.
Because of the conservation of energy, during a jump from state x′ to state x, the heat
reservoir instantaneously receives an amount of energy equal to
qxx′ = ϵx′(λ) −ϵx(λ) + δxx′,
(3.6)
which is the sum of the energy ϵx′(λ) −ϵx(λ) lost by the system and of the energy δxx′
instantaneously provided by the external driving.
In a mesoscopic system, jumps occur due to sudden interactions with the heat reser-
voir at equilibrium at temperature T. On this fast timescale, the manipulated parameter
can be considered to be constant. The eﬀect of a driving can be directly included in the
energy budget of the jump (see eq. (3.6)) and therefore just modiﬁes the amount of heat
instantaneously released to the reservoir. We conclude that, on the timescale of a sin-
gle jump, the heat reservoir cannot distinguish between an equilibrium system and a
nonequilibrium system that provides it with the same amount of heat. This argument
implies that, even out of equilibrium, the ratio between the forward and reverse jump
rates between pairs of states x and x′ must be equal to exp(−qxx′/kBT), exactly as in the
equilibrium case:
kxx′
kx′x
= exp
$qxx′
kBT
%
= exp
$ϵx′(λ) −ϵx(λ) + δxx′
kBT
%
.
(3.7)
Equation (3.7) is the generalized detailed balance condition. It implies in particular
that the jump x −→x′ is allowed if and only if the reverse jump x′ −→x is also allowed,
i.e., that the system exhibits microscopic reversibility; see section 2.6. Physically, this
means that it is always possible to observe the reverse of any observed jump at a ﬁnite
temperature, although it can be very unlikely. We discuss how this hypothesis can be
relaxed in section 8.5.
Equation (3.7) can be used to express jump rates in terms of energies, temperatures,
and driving. Also this problem is underdetermined, and similar considerations to those
made in the context of eq. (3.2) apply here. It is ofen the case that the driving acts only
on one jump direction. In this case, we write the rates in the form
kxx′ = ωxx′ e−(ϵx−ϵx′)/(2kBT)+δxx′/kBT,
kx′x = ωxx′ e−(ϵx′−ϵx)/2kBT.
(3.8)
A model of a mesoscopic system whose jump rates satisfy eq. (3.7) is said to be
thermodynamically consistent.
In general, the energy of a nonequilibrium system exhibits a slow modulation due to
the time-dependent manipulation, interrupted by sudden changes due to jumps caused
by drivings and interactions with the heat reservoir, as shown in ﬁg. 3.1.
3.2
Work and heat in stochastic thermodynamics
In stochastic thermodynamics, work and heat are deﬁned at the level of individual
trajectories and are therefore stochastic quantities.

Stochastic Thermodynamics
41
x
t
t0
t1
t2
3
2
1
0
Figure 3.1. Trajectory of a manipulated system. Thin lines represent energy levels of dif-
ferent mesostates, modulated in time as an effect of the manipulation. Bold lines mark
the states occupied by the system; arrows represent jumps. The system is initialized in
state 2. Its energy changes as time goes from t = t0 to t = t1. At t = t1 the system jumps
to state 0, releasing a quantity of heat q02(t1) = ϵ2(t1) −ϵ0(t1) to the reservoir. The energy
of state 0 changes between t = t1 and t = t2. Then a jump occurs at t = t2 from 0 to 3,
exchanging with the reservoir a quantity of heat given by q30(t2) = ϵ0(t2) −ϵ3(t2). The fact
that q30(t2) < 0 in this case means that heat is absorbed from the reservoir. In general,
the energy of the system can change either because the energy of the occupied state
changes (work by the manipulating device) or because of jumps to a state of different
energy (due to heat exchanged with the reservoir or work by the driving or both).
We consider a trajectory x of our mesoscopic system, starting from time t0 with the
system in state x0 and ending at time tf with the system in state xf. At the times tk, the
system jumps from state xk−1 to state xk, with k = 1, . . . , n and xn = xf; see section 2.7.
Along the trajectory, energy is exchanged among the system, the external forces, and
the reservoir. The stochastic work w is the energy provided by the external forces to the
system. The stochastic heat q is the energy released by the system to the reservoir. In
this book, we use lowercase letters, like w, q, and ϵ, for stochastic, trajectory-dependent
thermodynamic observables and uppercase ones for their averaged counterparts, like
the standard thermodynamic work W, heat Q, and energy E.
We have seen how a system can be perturbed out of equilibrium by a time-dependent
manipulation or by external drivings. Both of these factors contribute in general to the
stochastic work. Their combined eﬀect can be expressed by
w(x) =
n
!
k=0
& tk+1
tk
dt dλ
dt
dϵxk
dλ
'
()
*
manipulated work
+
n
!
k=1
δxkxk−1
'
()
*
driven work
.
(3.9)

42
Chapter 3
The ﬁrst term on the right-hand side of eq. (3.9) is the work made by the manipu-
lation. Since (dλ/dt) dϵxk/dλ = dϵxk/dt, this term represents the total energy change
between consecutive jumps. As the reservoir does not exchange energy outside jumps,
this energy change necessarily originates from work by the manipulation. The second
term on the right-hand side of eq. (3.9) is the total work performed by the driving along
each jump. Because of microscopic reversibility, the driven work in a jump x −→x′ is
equal to δx′x and that in the opposite jump is δxx′ = −δx′x, independent of how the rates
kxx′ and kx′x have been deﬁned.
We now turn our attention to the stochastic heat. During a jump from state x′ to
state x at time t, the reservoir receives an amount of heat qxx′ given by eq. (3.6), with
λ = λ(t). As we discussed, heat is exchanged with the reservoir only during jumps—the
external manipulation is too slow to contribute to the energy budget on the timescale
of a single jump. Therefore, the total heat exchanged with the heat reservoir along the
trajectory x is
q(x) =
n
!
k=1
qxkxk−1(tk) =
n
!
k=1
"
−ϵxk(tk) + ϵxk−1(tk) + δxkxk−1
#
.
(3.10)
From eqs. (3.9) and (3.10), it follows that
w(x) −q(x) = ϵxf(tf) −ϵx0(t0).
(3.11)
We call eq. (3.11) the ﬁrst law of stochastic thermodynamics, since it formally resem-
bles the ﬁrst law of thermodynamics, eq. (2.2). The reason for using the cautionary word
formally is explained in the next section.
3.3
Mesoscopic and calorimetric heat (*)
To understand the physical interpretation of mesoscopic thermodynamic observ-
ables, it is useful to scrutinize in more detail each term in eq. (3.11) and compare them
with those appearing in the ﬁrst law of thermodynamics, eq. (2.2).
We start by reﬂecting on the actual meaning of the energy of a mesostate ϵx. For
an object such as a rigid colloid without any relevant hidden degrees of freedom,
this energy can be interpreted without ambiguity. A more subtle case is that of a
macromolecule, where each mesostate represents a collection of microscopic states ξ,
each characterized by its energy ϵξ. To understand this scenario, we assume that the
timescales of the fast microscopic dynamics and the slow mesoscopic dynamics are
well separated. If the manipulation is slow enough, and the driving connects diﬀer-
ent mesostates, then jumps between states in the same mesostate satisfy the detailed
balance condition. Therefore, the occupation probabilities of the microstates within a
given mesostate are proportional to their Boltzmann factors e−ϵξ/kBT, as in equilibrium.
On the other hand, the relative occupation probabilities of diﬀerent mesostates can in
general be diﬀerent from those in equilibrium.
We evaluate the equilibrium probability peq
x of a mesostate x under these assump-
tions. From the law of total probabilities, we obtain
peq
x =
!
ξ∈x
peq
ξ ∝
!
ξ∈x
e−ϵξ/kBT,
(3.12)

Stochastic Thermodynamics
43
where the sum runs over all microstates ξ contained in the mesostate x. The occupation
probability of the mesostate x can be recast in the form of a Boltzmann factor e−ϵx/kBT
by deﬁning ϵx via
ϵx = −kBT ln

!
ξ∈x
e−ϵξ/kBT

.
(3.13)
Equation (3.13) reveals that, if the mesostate x has an internal structure, ϵx represents
its free energy rather than its energy. In principle, mesostates with diﬀerent values of ϵx
might contain microstates with the same average energies but diﬀerent entropies. As a
consequence, eq. (3.11) does not really correspond to the ﬁrst law of thermodynamics:
in eq. (2.2), the energies are proper energies, not free energies.
To solve this conundrum, we inspect more closely the other ﬂuctuating thermody-
namic quantities in eq. (3.11). The stochastic work in eq. (3.9) is the sum of a driven and
a manipulated contribution. The driven work is equal to the total energy provided by
the external agent and is therefore unambiguous. The deﬁnition of manipulated work
requires more care. In a manipulated system, we have
w(x) =
n
!
k=0
& tk+1
tk
dt dλ
dt
∂ϵxk
∂λ
=
n
!
k=0
& tk+1
tk
dt dλ
dt
/
ξ∈x(∂ϵξk/∂λ) e−ϵξk/kBT
/
ξ∈x e−ϵξ/kBT
=
n
!
k=0
& tk+1
tk
dt dλ
dt
0∂ϵξk
∂λ
1eq
x
,
(3.14)
where we denote by ⟨. . .⟩eq
x the equilibrium average over the microscopic states included
in the mesoscopic state x. This means that, under our assumptions, the deﬁnition of
work in stochastic thermodynamics is consistent with the microscopic one.
The conclusion is that, to save the energy balance, we have to reconsider the phys-
ical interpretation of the stochastic heat, eq. (3.10). In particular, it is necessary to
distinguish between two deﬁnitions of heat:
Mesoscopic heat. The mesoscopic heat is deﬁned by eq. (3.10) and is associated with
changes in the free energies of the mesoscopic states. This is the natural deﬁnition of
heat in stochastic thermodynamics. It however neglects the heat exchanges necessary
to alter the entropy of the mesostates.
Calorimetric heat. The calorimetric heat is deﬁned as the heat exchanged with the
reservoir that would be measured by an inﬁnitely sensitive calorimeter. Such a
calorimeter would appreciate the amount of heat required to rearrange the distribu-
tion of microscopic states inside each mesostate. Following this deﬁnition, we exp-
ress the calorimetric heat qcal by subtracting from the mesoscopic heat the entropic
contribution
qcal(x) = q(x) −T
n
!
k=1
2
Sxk(tk) −Sxk−1(tk)
3
,
(3.15)
where Sx = −kB
/
ξ∈x pξ ln pξ is the entropy of the internal states of a mesostate.

44
Chapter 3
Summarizing, in stochastic thermodynamics “energy” actually means “free energy”
if we take into account the internal structure of each mesostate. However, the deﬁni-
tion of mesoscopic heat in stochastic thermodynamics also neglects the heat released
in the reservoir (or absorbed by the system) due to the change of entropy of these inter-
nal degrees of freedom. These two contributions compensate each other in the energy
budget, and this is the reason why eq. (3.11) formally looks like the ﬁrst law of thermo-
dynamics. In other words, eq. (3.11) is a coarse-grained ﬁrst law of thermodynamics
that overlooks the part of the heat exchange that does not aﬀect the probability distri-
bution of mesostates. This shows once more that the assumption of separation of scales
between the microscopic and the mesoscopic dynamics is crucial in stochastic ther-
modynamics. It is thanks to this assumption that microscopic energy transactions are
always thermodynamically reversible, so that we can practically forget about them.
3.4
ATP hydrolysis by myosin
Many proteins in cells act as molecular motors, meaning that they consume chem-
ical energy to perform work. This work may result in transport of cargos to diﬀerent
parts of the cell or in the assembly of molecular structures such as ﬁlaments. Myosins
are a broad class of such proteins. They consume energy in the form of ATP to generate
forces on organic ﬁlaments made of the actin protein. This mechanism is the basis for
the contraction of muscle cells. Myosins consume ATP both when attached to actin ﬁl-
aments or detached from them. We focus on the latter case, where the reaction kinetics
is substantially slower.
Afer ATP is bound to myosin, it is hydrolyzed, i.e., converted into ADP plus a phos-
phate group P. In physiological conditions, this reaction provides to the motor protein
about 25.5 kBT of free energy. Afer this reaction, the phosphate group and ADP, in that
order, are released by the protein. At this point, the myosin is free to bind to another
ATP molecule.
We describe the cycle of a single myosin protein in the cell, while detached from an
actin ﬁlament, using the tools developed in this chapter. We represent the protein cycle
via the jump network in ﬁg. 3.2a. We denote the four states where myosin is unbound,
ATP-bound, ADP+P-bound, and ADP-bound by ∅, ATP, ADP+P, and ADP, respec-
tively. We consider as “external driving” the ATP hydrolysis and assign the correspond-
ing work to the jump ATP −→ADP + P. The myosin cycle is rather well characterized
biochemically, so that all the jump rates have been experimentally estimated.
The stochastic heat q is given by eq. (3.10), with qxx′ deﬁned in eq. (3.6) and
the energies ϵx stated in the caption to ﬁg. 3.2. We model hydrolysis of ATP by the
nonequilibrium driving
δADP+P,ATP = −δATP,ADP+P = 'µ = 25.5 kBT,
(3.16)
where 'µ is the chemical potential imbalance between ATP and the products of
hydrolysis. The other reactions are not driven. The stochastic work w is expressed by
eq. (3.9).
The stochastic work w and heat q are shown in ﬁg. 3.2b as a function of time
for a sample trajectory. The diﬀerence between the stochastic work and heat is the
internal energy change; see eq. (3.11). The motor spends most of its time performing the
hydrolysis reaction, due to the slow release of the phosphate group. During this reaction,

0
10
20
30
40
t (s)
0
50
100
150
200
w, q (kBT)
w
q
ADP+P
ADP
ATP
Ø
(a)
(b)
Figure 3.2. (a) Jump network for the myosin model (from Howard [80, ch. 14]). Parame-
ters are based on measurements of myosin S1 in rabbit skeletal muscle. The energy of
unbound myosin is taken as a reference, ϵ∅= 0. The other energies are ϵATP ≈−19 kBT,
ϵADP+P ≈4 kBT, ϵADP ≈−2 kBT with 'µ ≈25.5 kBT. Thicker arrows represent jumps where
work (positive or negative) is performed by external driving. Jump rates: kATP,∅= 2 ·
104 s−1, k∅,ATP = 10−4 s−1, kADP+P,ATP = 100 s−1, kATP,ADP+P = 10 s−1, kADP,ADP+P = 0.1 s−1,
kADP+P,ADP = 2 · 10−4 s−1, k∅,ADP = 2 s−1, kADP,∅= 15 s−1. (b) Stochastic work (w) and heat
(q) as a function of time t in a simulation of the process with the above parameters. The
system spends most of the time vacillating between the ATP and ADP+P states, receiving
or releasing energy equal to 'µ, leading to large ﬂuctuations in w, while the ﬂuctuations
in q are much smaller. Lines are at intervals of 25.5 kBT, corresponding to the total energy
released to the reservoir in one cycle.

46
Chapter 3
the driving exchanges an amount of work 'µ = 25.5 kBT, whereas the exchanged heat
is qATP,ADP+P = ϵADP+P −ϵATP −'µ ≈−2 kBT. Since, for this motor, the hydrolysis
reaction occurs rather close to equilibrium, ﬂuctuations of the stochastic heat during
hydrolysis are much less pronounced than those of the stochastic work.
3.5
General reservoirs
So far, we have considered a nonequilibrium mesoscopic system in contact with a
single heat reservoir. In this section, we discuss more general reservoirs, focusing on
how the generalized detailed balance condition (3.7) is modiﬁed.
We start by considering a single reservoir that, besides providing and absorbing heat,
can also exchange particles with the system. This generalization is particularly useful for
applying stochastic thermodynamics to systems of chemical reactions, where a particle-
exchanging reservoir is called a chemostat. We extensively discuss chemical reactions
in section 3.10. For a system coupled to a reservoir exchanging particles and heat, the
generalized detailed balance condition becomes
kxx′
kx′x
= exp
4
ϵx′(λ) −ϵx(λ) + /
i µi(λ)'ni
xx′ + δxx′
kBT
5
,
(3.17)
where µi(λ) is the chemical potential of species i and 'ni
xx′ is the number of molecules
of species i exchanged with the reservoir during a jump from state x′ to state x. The
quantity ϵx′(λ) −ϵx(λ) + /
i µi(λ)'ni
xx′ appearing on the right-hand side of eq. (3.17)
can be interpreted as the diﬀerence in the Gibbs free energy between states x′ and x.
Another useful generalization is to cases where the system is simultaneously in con-
tact with multiple reservoirs, labeled by an index r = 1, . . . , R. In this case, two generic
states x′ and x can be connected by multiple jumps,
kxx′ =
R
!
r=1
k(r)
xx′,
(3.18)
each caused by an interaction with a diﬀerent reservoir. Equation (3.17) applies to each
reservoir individually:
k(r)
xx′
k(r)
x′x
= exp
6
1
kBT(r)
4
ϵx′(λ) −ϵx(λ) + δxx′ +
!
i
µi,(r)(λ)'ni
xx′
57
,
(3.19)
where T(r) and µi,(r) are, respectively, the temperature and the chemical potential of
species i for reservoir r.
In some cases, the external driving in the generalized detailed balance relation (3.7)
is implicitly related to particle reservoirs. To show that relationship, we consider a sys-
tem S in contact with two particle reservoirs R1 and R2, both at temperature T but
characterized by diﬀerent values, µ1 and µ2, of the chemical potential of particles that
they exchange with the system. Because of this diﬀerence, the composite system, i.e., the
system plus the two reservoirs, is out of equilibrium. We focus on a jump x′ −→x that
is always accompanied by the transfer of one particle from R1 to R2. The net energy
change of the composite system in this jump is given by

Stochastic Thermodynamics
47
'ϵtot
xx′ = ϵx −ϵx′ −µ1 + µ2.
(3.20)
The jump rates must satisfy the generalized detailed balance condition at the level of
the composite system:
kxx′
kx′x
= exp
$
−'ϵtot
xx′
kBT
%
= exp
$ϵx′ −ϵx + µ1 −µ2
kBT
%
.
(3.21)
The generalized detailed balance relation expresses the thermodynamic consistency of
the process. This expression can be cast in the form of eq. (3.7) by associating with the
particle exchange an eﬀective driving,
δxx′ = 'µ = µ1 −µ2.
(3.22)
This reasoning illustrates that the driving δxx′ can be interpreted as the eﬀect of an
external force facilitating the jump or, equivalently, as the chemical potential imbalance
associated with particle transfer between reservoirs. For this reason, in the following we
use interchangeably δxx′ or 'µ to denote a chemical driving originating from a chemical
potential imbalance.
Equations (3.7), (3.17), and (3.19) also apply if we manipulate the temperature, T =
T(λ). To formalize this case, one can imagine many heat reservoirs in equilibrium at
diﬀerent temperatures, and a manipulation protocol that continuously “disconnects”
the system from a reservoir at temperature T(λ(t)) and connects it to a diﬀerent one at
a slightly diﬀerent temperature T(λ(t + dt)). Also this procedure requires a separation
between the timescales at which T is manipulated and those of the individual jumps.
This hypothesis ensures that, on the timescales of individual jumps, the system is always
coupled to one equilibrium heat reservoir at a well-deﬁned temperature.
3.6
Stochastic entropy
The uncertainty associated with the distribution px(t) over the mesostates is quan-
tiﬁed by the Shannon entropy
H [S(t)] = −
!
x
px(t) ln px(t).
(3.23)
In keeping with equilibrium thermodynamics, we assign to the system a nonequilib-
rium entropy
Ssys(t) = kBH[S(t)].
(3.24)
This entropy pertains to an ensemble of systems undergoing the same process, while
each individual system follows a diﬀerent trajectory, due to diﬀerences in the initial
condition and in the interactions with the heat reservoir. To characterize individual
systems, we deﬁne the stochastic entropy
ssys
x (t) = −kB ln px(t).
(3.25)
For an individual trajectory x = (x(t)), the value of the stochastic entropy at time t
is sx(t)(t) = −kB ln px(t)(t). Although the stochastic entropy is deﬁned for individual

48
Chapter 3
trajectories, computing it requires knowledge of the probabilities px(t) that characterize
the whole ensemble of trajectories. The average and stochastic entropies are related by
Ssys(t) =
8
ssys(t)
9
t ,
(3.26)
where the average is deﬁned by ⟨· · ·⟩t = /
x · · · px(t). The entropy change of the system
between the initial and ﬁnal time is
'ssys = ssys
xf (tf) −ssys
x0 (t0).
(3.27)
We are now in a position to evaluate the total entropy change of the system plus the heat
reservoir along a given trajectory x:
stot(x) = 'ssys + sres(x),
(3.28)
where sres(x) is the trajectory-dependent change in entropy of the reservoir due to the
heat released by the system. Equation (3.28) is the stochastic counterpart of eq. (2.31).
Since the reservoir is always at equilibrium, its entropy change is
sres(x) = q(x)
T ,
(3.29)
where the stochastic heat q(x) is given by eq. (3.10).
3.7
Stochastic entropy and entropy production in a manipulated
two-level system
Lasers provide a versatile and powerful way to manipulate mesoscopic physical and
biological systems. We consider a system consisting of a single defect center in natural
IIa-type diamond simultaneously excited by a red laser of wavelength 680 nm and a
green laser of wavelength 514 nm. The red laser can bring the system to a high-energy
state from which it decays, emitting ﬂuorescence. The green laser also excites the sys-
tem to a state from which it decays nonradiatively. The state usually reached by this
decay is slightly diﬀerent from that reached afer absorbing red photons. However, with
a smaller rate the state excited by green light can decay in the ground state reached afer
absorption of red light and vice versa.
The jump network for this system is represented in ﬁg. 3.3a. The system can be
found in four states, which form two sets, corresponding respectively to the lef (0)
and right (1) part of the ﬁgure. The jump rates between the two sets are on the order of
a few inverse milliseconds, whereas those within each of them are on the order of a few
inverse nanoseconds. Since jumps within each set are hard to resolve experimentally,
we describe the process as a single eﬀective two-level system with two states, (0) and
(1). If the system is in (0) it appears bright, whereas in (1) it appears dark. The jump
rates between these two states can be manipulated by varying the power of the applied
lasers.
For a two-level system, the detailed balance condition for the steady-state probability
distribution always holds:
k↑pst
0 = k↓pst
1 .
(3.30)

Stochastic Thermodynamics
49
60
70
k10(t)
0
1
x
0.5
1.0
s/kB
0
200
400
600
800
t
0.0
0.5
stot/kB
0.575
0.600
0.625
p1 (t)
ki
0
1
+
+
green
red
kh
(a)
(b)
Figure 3.3. (a) Energy levels of the diamond-defect system. The system is described by
four states, forming two sets. Transitions within each set are too fast to be resolved. The
much smaller jump rates k↓and k↑can be manipulated by changing the intensity of
the applied laser radiation. (Adapted from Schuler et al. [147], with permission; see also
Tietz et al. [166].) (b) Simulated trajectories. Top to bottom: Escape rate k↑(t) in kHz, as
a function of time (gray) and probability of occupation p1(1) of the dark state (black);
a trajectory of the system; stochastic entropy s = sx(t)(t) for the given trajectory; and
the corresponding total produced entropy stot(t). Parameters: a−1
0
= 26 ms, b−1
0
= 31 ms,
γ = 0.16, tm = 50 ms. Time is measured in ms.
The jump rates at a given intensity of laser radiation are expressed as
k↑(t) = a0[1 + λ(t)],
k↓(t) = b0,
(3.31)
where λ(t) = γ sin(2πt/tm) is the experimental control parameter.
It is important to clarify that jumps in this system are caused by quantum eﬀects
that do not necessarily require interactions with a heat reservoir. Nevertheless, we can
formally study the system using stochastic thermodynamics. We consider a trajectory
x = ((x0, t0), (x1, t1), . . . , (xn, tn), tf),
such that
x = xk,
for tk ≤t ≤tk+1,
(3.32)

50
Chapter 3
where the last jump takes place at tn and we set tn+1 = tf. The total entropy produced
by the system in the trajectory x is given by
stot(x) = 'ssys + sres(x) = ssys
xf (tf) −ssys
x0 (t0) + kB
n
!
k=1
ln kxkxk−1(λ(tk))
kxk−1xk(λ(tk)).
(3.33)
In the second equality, we have used the generalized detailed balance condition (3.7).
In this case, we expressed the entropy production in terms of the rates and the prob-
abilities only: since jumps in this system are not caused by interactions with a heat
reservoir, we cannot invoke eq. (3.7) to interpret rates in terms of energies and tem-
perature. This also means that the stochastic work w and heat q do not have a direct
physical interpretation. On the other hand, entropy production is still a useful measure
of the irreversibility of the dynamics (ﬁg. 3.3b). The system entropy remains bounded,
whereas the total produced entropy appears to be negative at short times for the given
trajectory and then tends to increase, as shown in the bottom plot.
3.8
Average entropy production rate
We now discuss the average rate at which entropy is produced. It is convenient to
separate the contribution due to jumps from the contribution during dwells. During
each jump from state x′ to state x at a time t, the reservoir absorbs an amount of heat
qxx′ given by eq. (3.6). This corresponds to a change of reservoir entropy equal to
sres = qxx′
T = kB ln kxx′
kx′x
.
(3.34)
During the same jump, the system entropy changes by
'ssys = kB ln px′
px
.
(3.35)
Therefore, the total entropy change during a jump is
stot = kB ln kxx′px′
kx′xpx
.
(3.36)
We now consider the entropy change between jumps. Because of the separation of
timescales, there is no heat exchange with the reservoir between jumps, and therefore
the reservoir entropy does not change. When the system is in state x, its entropy changes
at a rate
dssys
dt = −kB
dλ
dt
∂
∂λ ln px = kB
px
dλ
dt
∂px
∂λ .
(3.37)
Because of conservation of probability, this change vanishes on average:
0dssys
dt
1
= kB
!
x
px
dssys
x
dt = kB
dλ
dt
!
x
∂px
∂λ = 0.
(3.38)

Stochastic Thermodynamics
51
This means that, on average, the entropy of both the system and the reservoir can only
change during jumps. On average, the net jump rate from state x′ to state x is given by the
probability current Jxx′(t); see eq. (2.80). Therefore, the net average entropy production
rate is
˙Stot(t) = kB
2
!
xx′
Jxx′(t) ln kxx′(t)px′(t)
kx′x(t)px(t) ,
(3.39)
where the factor 1/2 compensates for counting the current between each pair of states
twice. Equation (3.39) is a useful result, ofen referred to as the Schnakenberg formula.
In this expression, we denote the derivative by a dot to stress that the total entropy pro-
duction is not a state function, as discussed in section 2.2. We reserve the notation
d/dt for derivatives of state functions. Since the sign of ln[kxx′(t)px′(t)/kx′x(t)px(t)]
is the same as the sign of Jxx′(t) = kxx′(t)px′(t) −kx′x(t)px(t), each term in the sum
in eq. (3.39) is nonnegative. This implies that the average entropy production rate is
nonnegative as well, and that it vanishes if and only if the current between each pair
of states vanishes. This latter case corresponds to detailed balance and therefore to
thermodynamic equilibrium.
It follows from our discussion that the average entropy production rate can be split
into the production rate of the reservoir entropy and that of the system entropy, ˙Stot(t) =
˙Sres(t) + dSsys/dt. We express these two contributions by
˙Sres(t) = kB
2
!
xx′
Jxx′(t) ln kxx′(t)
kx′x(t);
(3.40)
dSsys
dt
= kB
2
!
xx′
Jxx′(t) ln px′(t)
px(t) .
(3.41)
In the particular case of a system in a steady state, the internal entropy is constant on
average, and one has dSsys/dt = 0 and ˙Stot = ˙Sres.
3.9
Network theory of nonequilibrium steady states (*)
In this section, we analyze nonequilibrium steady states of master equations based on
an analogy with the Kirchhoﬀtheory of electric circuits. We consider a master equation
that satisﬁes microscopic reversibility. We say that two nodes x and x′ are connected by
an edge if the jump x −→x′ and its reverse have nonvanishing rates; see section 2.6. We
represent the jump network associated with the master equation as shown in ﬁg. 2.1,
where edges are represented as segments.
In the steady state, the probability current Jxx′ = kxx′pst
x′ −kx′xpst
x satisﬁes
!
x′
Jxx′ = 0,
(3.42)
for each node x. Equation (3.42) is analogous to Kirchhoﬀ’s law for currents, with Jxx′
playing the role of the electric current.
We deﬁne a cycle C in the network as a sequence of distinct states such that each
is connected by an edge to the previous one and to the next, and the last to the ﬁrst.
Equation (3.42) implies that Jxx′ = 0 if the edge between x and x′ does not belong to any

52
Chapter 3
(a)
(b)
1
2
3
1
(c)
2
3
Figure 3.4. Example of construction of a fundamental set of cycles from the jump network
of a four-state system in which all jumps are allowed. The panels show (a) the original
network, (b) the spanning tree, where the dashed lines are the chords that have been
removed, (c) the resulting set of fundamental cycles.
cycle in the network. If the jump network is made up of a single cycle, it follows from
eq. (3.42) that the current is constant, i.e., independent of the node. The key idea of the
Kirchhoﬀtheory is to decompose an arbitrary network into a set of cycles. To this aim,
we need to introduce a few concepts from graph theory.
Our starting point is a connected jump network; see section 2.6. In principle, two
nodes could be connected by more than one edge due to coupling with diﬀerent reser-
voirs; see section 3.5. We neglect this complication here. From the original network,
we construct its core network by removing all edges that do not belong to any cycle.
Currents can run only in the core network in the steady state. We now decompose
the core network into fundamental cycles. We construct a treelike network by sequen-
tially removing an arbitrary edge from an arbitrary cycle until there are no cycles lef
(ﬁg. 3.4). In this way, we obtain a spanning tree of the core network. The spanning
tree is connected by construction, it includes all nodes of the core network, and it does
not contain any cycles. If the core network has N states, the spanning tree has N −1
edges. Since the edge to be removed at each step is arbitrary, the spanning tree is not
unique.
The edges removed to construct the spanning tree are called chords and are labeled
by an index α ∈{1, . . . , ν}. By adding one chord α to the spanning tree, we obtain
a network with exactly one cycle. We call this cycle Cα. The set of cycles (Cα) with
α = 1, . . . , ν is called the set of fundamental cycles; see ﬁg. 3.4. They are called funda-
mental since they are independent, their union reproduces the core network, and any
linear function deﬁned on the cycles in the original network can be represented by a
linear combination of functions deﬁned on the cycles in the set (Cα). A proof of this
nontrivial fact is sketched in appendix A.9.
Thanks to this result, we can express the probability current ﬂowing through any
edge in the steady state as a sum of the currents ﬂowing in the fundamental cycles. To
this aim, we assign an arbitrary orientation to each edge xx′, either x →x′ or x′ →x:

Stochastic Thermodynamics
53
Jxx′ =
ν
!
α=1
sxx′(α) Jα,
(3.43)
where the sum runs over the fundamental cycles. Here Jα is the current of the cycle,
which can be identiﬁed with the current running through the chord unique to that cycle
aligned with its orientation; and sxx′(α) = 1 if the edge xx′ has the same orientation of
Cα, sxx′(α) = −1 if it has the opposite orientation, and it vanishes if it does not belong
to Cα.
Similar to the current, the average entropy production rate is also a linear function
of the cycles in the jump network. Indeed, eq. (3.39) shows that the average entropy
production rate is a linear function of the currents and therefore does not receive con-
tributions from jumps that are not part of a cycle. Therefore, the Kirchhoﬀtheory tells
us that we can linearly decompose the average entropy production rates into contribu-
tions from the cycles in the fundamental set. The contribution of each cycle is equal to
its associated average entropy production rate according to eq. (3.39). Following this
reasoning, we introduce, for each oriented cycle α, its aﬃnity:
Aα = kBT ln


n
:
j=1
kxj+1xj
kxjxj+1

=
n
!
j=1
δxj+1xj,
(3.44)
where we set xn+1 = x1. In the second equality, we have used the generalized detailed
balance condition (3.7). We thus obtain the decomposition
˙Stot = 1
T
!
α
Aα Jα.
(3.45)
Therefore, the entropy production rate in arbitrary networks can be decomposed into a
sum of the products of currents times aﬃnities, where each product pertains to a cycle
in the fundamental set.
3.10
Stochastic chemical reactions
Stochastic chemical reactions have gained importance in recent years thanks to the
advancement of cell biology. Such advancements have revealed that many proteins are
present in concentrations as little as a few units per cell, so that representing their den-
sity as a continuous quantity is not appropriate. At such low concentrations, protein
numbers are intrinsically stochastic quantities that can be described quite naturally with
the tools of stochastic thermodynamics.
In stochastic chemical reactions, the state of a system is represented by a vector
nA, nB, nC, . . . , whose entries are the number of molecules of each chemical species
A, B, C, ..., present at a given time. By species, we mean either individual molecules or
bound states of more molecules. For example, in a dimerization reaction A + A ⇋AA,
the state of the system is identiﬁed by the two-dimensional vector (nA, nAA), where nA is
the number of monomers and nAA is the number of dimers. In a well-stirred container,
the law of mass action stipulates that the rate of each reaction is proportional to the
concentration of each reactant, raised to the power of the corresponding stoichiometric

54
Chapter 3
coeﬃcient. We assume that this is the case. The reaction rates are then simple functions
of the number of particles.
It is convenient to classify the possible reactions as follows:
One-body reactions. In one-body reactions, the reactant is a single molecule. A decay
reaction A →∅is an example of a one-body reaction. Since each molecule partici-
pates individually in a simple reaction, the total reaction rate is given by an individual
rate times the number of molecules present at time t. In the case of the decay reaction,
one has knA−1,nA = k nA, where k is the individual rate.
Binary reactions. In binary reactions, two molecules react together. For example, the
formation of a bound state A + B →AB is a binary reaction, where AB is the bound
state of a molecule A with a molecule B. On the contrary, the breaking of a bound
state, such as AB →A + B, is a one-body reaction. The total rate of binary reactions
is proportional to the number of molecules of either species participating in it and
is inversely proportional to the available volume. In the case of the bound state for-
mation, we have k(nA−1,nB−1,nAB+1),(nA,nB,nAB) = k nA nB, where k is a rate constant.
There is an exception when the two molecules entering the reaction belong to the
same species A, like in the dimerization reaction A + A →AA. In this case, the rate
is equal to k nA(nA −1). This rate duly vanishes when there is a single A molecule
available.
We can similarly deﬁne higher-order reactions with three or more reactants,
although in practice they are less common. The probability pnA,nB,nC,...(t) of the num-
bers of species evolves according to a master equation, whose rates can be determined
using the above approach. The link with thermodynamics is obtained by expressing the
jump rates in terms of the energy of states via the generalized detailed balance condition,
eq. (3.7) or (3.17).
As an illustration, we consider an isomerization reaction, in which a chemical A is
transformed into a chemical B:
A
k+
⇌
k−B.
(3.46)
We denote by [A] = ⟨nA⟩/V and [B] = ⟨nB⟩/V the concentrations of chemicals A and
B, respectively, where V is the volume of the system. We also introduce the individual
rates k± of the reactions A ⇌B and write the master equation for pnA,nB(t):
dpnA,nB
dt
= k+(nA + 1)pnA+1,nB−1(t) + k−(nB + 1)pnA−1,nB+1(t)
−
2
k+nA + k−nB
3
pnA,nB(t).
(3.47)
If the system is not in contact with a particle reservoir, the total number of particles
N = nA + nB is ﬁxed. We therefore express eq. (3.47) in terms of a single variable by
substituting nB = N −nA. In this representation, the jump rates kn′
AnA read
kn′
AnA = k+nA δn′
A,nA−1 + k−(N −nA) δn′
A,nA+1.
(3.48)

Stochastic Thermodynamics
55
Multiplying eq. (3.47) by nA and summing over nA, we obtain an equation for the
average ⟨nA⟩= /
nA nA pnA:
d
dt ⟨nA⟩= k+ ⟨nA(nA −1)⟩+ k−⟨(N −nA)(nA + 1)⟩
−k+ 8
n2
A
9
−k−⟨(N −nA)nA⟩
= −k+ ⟨nA⟩+ k−⟨N −nA⟩.
(3.49)
Dividing by the volume V of the container, we obtain the rate equation in terms of the
concentrations of A and B:
d[A]
dt
= −k+[A] + k−[B],
(3.50)
and therefore, at equilibrium,
[B]
[A] = k+
k−.
(3.51)
If the energy diﬀerence between a B molecule and an A molecule is equal to 'ϵ, we
must have, at temperature T,
[B]
[A] = e−'ϵ/kBT.
(3.52)
Therefore, the reaction (3.46) is compatible with thermodynamic equilibrium if
k+
k−= e−'ϵ/kBT.
(3.53)
Equation (3.53) is known in chemical kinetics as the de Donder relation, providing a
connection between the forward and backward reaction steps of a chemical reaction
and the aﬃnity, i.e., the change in free energy associated with the reaction.
From (3.48), provided nA, (N −nA) ≫1, we obtain
knA+1,nA
knA,nA+1
=
k+nA
k−(N −nA −1) ≈e−'ϵnA/kBT,
(3.54)
where 'ϵnA = ϵnA+1 −ϵnA, in which
ϵnA = nAkBT ln nA + (N −nA) [ϵ + kBT ln(N −nA)] ,
(3.55)
is the free energy of a state with nA A particles and (N −nA) B particles, taking into
account the entropy of mixing. Equation (3.54) connects the “macroscopic” rates with
the “microscopic” ones appearing in (3.53).
3.11
Linear response theory (*)
We consider a mesoscopic system that is brought out of equilibrium by a weak
time-dependent manipulation. As a consequence of this manipulation, average values
of observables might deviate from their equilibrium values and in principle depend

56
Chapter 3
on time. It is ofen useful to evaluate these deviations at ﬁrst order in the intensity of
the manipulation, as measured by the control parameter λ. This approach is known as
linear response theory. Although we introduce it in the context of stochastic thermo-
dynamics, linear response theory can be applied to a broader range of thermodynamic
systems close to equilibrium.
We assume that the energy of the state x can be manipulated in r diﬀerent ways,
and we denote by λ = (λα), α = 1, . . . , r the corresponding control parameters. Such
parameters act linearly and independently on the energies, so that
ϵx(λ) = ϵ(0)
x
−
r
!
α=1
λαXα,x,
(3.56)
where the observables Xα,x, α = 1, . . . , r are given functions of x. At ﬁxed values of
the control parameters, the rates kxx′ satisfy the detailed balance condition (2.85). We
denote by ⟨. . .⟩0 the equilibrium average in the unperturbed case λ = 0. At equilibrium,
the dynamics is invariant under time translations. We wish to evaluate the average val-
ues
8
Xβ(t)
9
of the observables Xβ,x at time t as a function of the manipulation protocol
λ = (λ(t)):
8
Xβ(t)
9
λ =
!
x
Xβ,xpx(t; λ),
(3.57)
where px(t; λ) is the probability distribution of the states in the presence of the manipu-
lation λ. We deﬁne the observables so that ⟨Xα⟩0 = 0 for all α. We then expand ⟨Xα(t)⟩
as a functional power series,
8
Xβ(t)
9
λ =
& ∞
−∞
dt′ !
α
Kβα(t, t′)λα(t′) + higher-order terms,
(3.58)
where we introduce the linear response function Kβα(t, t′).
We now express the linear response function in terms of equilibrium averages only.
The function Kβα(t, t′) must vanish whenever t′ > t, since the value of
8
Xβ(t)
9
λ cannot
depend on future values of λα(t′). Moreover, the eﬀects of the manipulation must be
invariant under time translation. This implies
Kβα(t, t′) = Kβα(t −t′),
∀α, β.
(3.59)
We consider a manipulation λ(t) = λ(0) θ(−t) eεt, where ε > 0 is arbitrarily small
and θ(t) is the Heaviside step function. Such a manipulation grows gradually from 0
for t →−∞to a small constant value λ(0) and is then switched oﬀat t = 0. Since ε is
small, at t = 0 the probability distribution of the system is the equilibrium probability
distribution peq(λ) in the presence of a constant λ(0):
px(0; λ) = peq
x (λ) = e(F(λ)−ϵ(0)
x +/
α λ(0)
α Xα,x)/kBT
≈peq(0)
4
1 + 1
kBT
!
α
λ(0)
α Xα,x
5
,
(3.60)

Stochastic Thermodynamics
57
where we expand to linear order in λ(0) and use the fact that
∂F(λ)
∂λα
= ⟨Xα⟩0 = 0,
∀α.
(3.61)
The average
8
Xβ(t)
9
λ for t > 0 is equal to the average of Aβ over a probability distri-
bution p(t) that satisﬁes the unperturbed master equation (2.77), but with the initial
condition peq(λ). Given the initial condition px′(t = 0; λ), the solution of this equation
is given by px(t) = /
x′ Gxx′(t)px′(0; λ), where the matrix Gxx′(t) is the Green function
introduced in eq. (2.71). We then have, to ﬁrst order in λ,
px(t) ≈peq
x (0) + 1
kBT
!
x′
Gxx′(t)
!
α
λ(0)
α Xαpeq
x′ (0)
(3.62)
and therefore, taking into account that
8
Xβ
9
0 = 0,
8
Xβ(t)
9
λ ≈1
kBT
!
xx′
Xβ,xGxx′(t)
!
α
λ(0)
α Xαpeq
x′ (0)
= 1
kBT
!
α
8
Xβ(t)Xα(0)
9
0 λ(0)
α .
(3.63)
Comparing with (3.58) and taking into account the expression of our protocol λ, we
conclude that
& 0
−∞
dt′ Kβα(t −t′) = 1
kBT
8
Xβ(t)Xα(0)
9
0 = 1
kBT Cβα(t),
(3.64)
where Cβα(t) =
8
Xβ(t) Xα(0)
9
0 is the equilibrium time-dependent correlation function.
We have, on the other hand,
& 0
−∞
dt′ Kβα(t −t′) =
& +∞
t
dt′ Kβα(t′).
(3.65)
Taking the derivative with respect to t, and taking into account that K(t) vanishes for
t < 0, we obtain the expression of the linear response function:
Kβα(t) = −θ(t)
kBT
d
dt
8
Xβ(t)Xα(0)
9
0 = −θ(t)
kBT
d
dtCβα(t).
(3.66)
This result extends the ﬂuctuation-dissipation relation from static to time-dependent
quantities.
Fluctuation-dissipation relations connect equilibrium ﬂuctuations of observables,
measured by the correlation function on the right-hand side of eq. (3.66), with the
response to a small external perturbation, given by the coeﬃcient Kβα on the lef-hand
side. These relations played a fundamental role in the development on nonequilibrium
statistical physics. We return to them in chapter 4 in the broader context of ﬂuctuation
relations.

58
Chapter 3
3.12
More on coarse graining (*)
Throughout this chapter, we have emphasized that stochastic thermodynamics deals
with a coarse-grained, mesoscopic description of a physical system. The separation be-
tween the slow timescales of the mesoscopic dynamics and the fast timescales of the
heat reservoir (and of the microscopic degrees of freedom of the system) is crucial
to achieve a simple closed description, where we can essentially forget about the fast
microscopic degrees of freedom. In practice, there are diﬀerent techniques to eliminate
the fast dynamics and obtain an eﬀective mesoscopic description. These techniques
can be classiﬁed into two broad categories. Coarse-graining procedures group states
together in such a way that the internal dynamics among states in a group is fast,
whereas dynamics among diﬀerent groups is slower. Decimation procedures eliminate
states characterized by fast dynamics. With a slight abuse of language, we ofen refer
to both categories as coarse graining. Both categories include several methods, whose
eﬀectiveness depends on the problem at hand.
In many practical situations, the choice of a coarse-graining scale is not unique.
There can be diﬀerent mesoscopic scales, corresponding to diﬀerent levels of coarse
graining. If these levels are well separated, one should be able, in principle, to formulate
stochastic thermodynamics at each mesoscopic level, and these descriptions should be
consistent among them. For example, we study how rates are transformed by changing
coarse-graining levels. We consider an equilibrium physical system with two states, 1
and 2, separated by a high-energy state f (where f stands for “fast”). The master equation
reads
d
dtp1 = k1fpf −kf1p1;
d
dtpf = kf1p1 + kf2p2 −(k1f + k2f)pf;
d
dtp2 = k2fpf −kf2p2.
(3.67)
The rates are expressed as in eq. (3.3). We now perform an adiabatic elimination of
the fast state f. The adiabatic elimination is one of the most common decimation
procedures and is schematized in ﬁg. 3.5 for the case at hand. Since the dynamics
of state f is fast, it always stays very close to a steady state on the timescales of the
slow states. We therefore eliminate this state by setting dpf/dt = 0. This implies pf =
(kf1p1 + kf2p2)/(k1f + k2f). Substituting into the remaining two equations yields
d
dtp1 = keﬀ
12p2 −keﬀ
21p1,
d
dtp2 = keﬀ
21p1 −keﬀ
12p2,
(3.68)
where
keﬀ
21 =
k2fkf1
k1f + k2f
= ω1fω2f e(ϵ1−ϵ2)/(2kBT)e−ϵf/(2kBT)
ω1f e−ϵ1/(2kBT) + ω2f e−ϵ2/(2kBT) ;

Stochastic Thermodynamics
59
Energy
kf2
f
1
2
keff
k1f
kf1
k2f
21
keff
12
Figure 3.5. Adiabatic elimination of an intermediate high-energy state. Continuous
arrows denote the original rates; dashed arrows denote coarse-grained rates. See
eq. (3.69).
keﬀ
12 =
k1fkf2
k1f + k2f
= ω1fω2f e(ϵ2−ϵ1)/(2kBT)e−ϵf/(2kBT)
ω1f e−ϵ1/(2kBT) + ω2f e−ϵ2/(2kBT) .
(3.69)
The eﬀective rates keﬀ
21 and keﬀ
12 in eq. (3.69) always satisfy detailed balance. This
means that the system remains compatible with equilibrium also afer the coarse-
graining procedure. However, the precise expressions of the rates are signiﬁcantly more
complicated than the original ones. These expressions considerably simplify when k1f
and k2f are equal, i.e., when
ω1f = ω e(ϵ1−ϵf)/(2kBT);
ω2f = ω e(ϵ2−ϵf)/(2kBT).
(3.70)
Here ω is a rate constant. In this case, the eﬀective rates become
keﬀ
21 = ω
2 e(ϵ1−ϵf)/kBT;
keﬀ
12 = ω
2 e(ϵ2−ϵf)/kBT.
(3.71)
Such an exponential dependence of the rates on the “activation barriers” ϵf −ϵ1 and
ϵf −ϵ2 is known in physical chemistry as the Arrhenius law. This dependence holds
qualitatively also for other choices of ω1f and ω2f, as long as k1f and k2f do not diﬀer
too much.
We have seen that the mesoscopic energies usually treated in stochastic thermo-
dynamics are, strictly speaking, free energies. Such free energies are automatically

60
Chapter 3
consistent across coarse-graining levels. Suppose, e.g., that a mesostate x contains
diﬀerent microstates y. We thus obtain
ϵx = −kBT ln

!
y∈x
e−ϵy/kBT

;
ϵy = −kBT ln

!
ξ∈y
e−ϵξ/kBT

.
(3.72)
One then also has
ϵx = −kBT ln

!
y∈x
!
ξ∈y
e−ϵξ/kBT

= −kBT ln

!
y∈x
e−ϵy/kBT

.
(3.73)
This property is general and does not require particular assumptions about how the
states y are assigned to the states x.
We now turn our attention to work. For simplicity, we consider a purely manipulated
system, without external driving. We follow the same line of eq. (3.14) and compare the
deﬁnitions of work w(x) and w(y) at the two coarse-graining levels x and y.
w(y) =
n
!
k=0
& tk+1
tk
dt dλ
dt
∂ϵyk
∂λ ;
(3.74)
w(x) =
n′
!
k=0
& tk+1
tk
dt dλ
dt
∂ϵxk
∂λ =
n′
!
k=0
& tk+1
tk
dt dλ
dt
/
y∈x(∂ϵy/∂λ) e−ϵy/kBT
/
y∈x e−ϵy/kBT
=
n′
!
k=0
& tk+1
tk
dt dλ
dt
0∂ϵy
∂λ
1
x,eq
;
(3.75)
where ⟨. . .⟩x,eq denotes an equilibrium average over the states y included in the coarse-
grained state x. The two deﬁnitions of work are therefore equivalent when the states
y within a state x can be considered at equilibrium among themselves, i.e., when the
dynamics among the states within x is much faster than that among the mesostates x.
We now discuss the behavior of entropy production at diﬀerent coarse-graining lev-
els. We should distinguish between two cases. In the ﬁrst case, the mesostates y within
a state x can be considered always at equilibrium as we assumed before. In this case, we
can follow the same logic of section 3.3 and conclude that, since heat exchanges between
such mesostates and the heat reservoir are reversible, they do not contribute to entropy
production. The conclusion in this case therefore is that entropy production does not
change at diﬀerent coarse-graining levels.
The situation is diﬀerent when considering cases where the internal dynamics of the
mesostates y inside a coarser mesostate x is fast but out of equilibrium. In these cases,
entropy production tends to become smaller at coarser levels of description. One main
reason is that increasing the coarse-graining level can “destroy” loops in the jump net-
work that contribute to the entropy production. For example, if the three states 1, 2, 3
represented in ﬁg. 3.6 are collapsed in the mesostate A, the entropy production associ-
ated with the current circulating in the loop does not appear anymore in the description
of the system.

Stochastic Thermodynamics
61
A
1
3
2
k32
k31
k23
k13
k12
k21
Figure 3.6. The three states 1, 2, 3 are collapsed into the state A upon coarse graining.
As a consequence, the entropy production associated with the current circulating in the
1, 2, 3 loop disappears.
In some cases, due to coarse graining, there might be multiple microscopic pathways
among pairs of states. This means that the eﬀective rate kxx′ represents the sum of rates
k(r)
xx′ associated with physically distinct possible jumps indexed by r, with kxx′ = /
r k(r)
xx′.
In this case, the correct expression of the average entropy production rate is
˙Stot = kB
2
!
xx′r
J(r)
xx′ ln k(r)
xx′pst
x′
k(r)
x′xpstx
,
(3.76)
where J(r) is deﬁned by
J(r)
xx′ = k(r)
xx′pst
x′ −k(r)
x′xpst
x ,
∀x ̸= x′, ∀r.
(3.77)
We also deﬁne the eﬀective current
Jxx′ =
!
r
J(r)
xx′,
∀x ̸= x′.
(3.78)
The eﬀective entropy production ˙Scg is the entropy production rate associated with the
eﬀective rates
˙Stot,eﬀ= kB
2
!
xx′
Jxx′ ln kxx′pst
x′
kx′xpstx
.
(3.79)

62
Chapter 3
The eﬀective average entropy production rate provides a lower bound to the actual
average entropy production rate
0 ≤˙Stot,eﬀ≤˙S.
(3.80)
One has indeed
˙Stot = kB
2
!
xx′r
;
k(r)
xx′pst
x′ −k(r)
x′xpst
x
<
ln k(r)
xx′pst
x′
k(r)
x′xpstx
= kB
!
xx′r
k(r)
xx′pst
x′ ln k(r)
xx′pst
x′
k(r)
x′xpstx
≥kB
!
xx′
kxx′pst
x′ ln kxx′pst
x′
kx′xpstx
= ˙Stot,eﬀ,
(3.81)
where we apply the logsum inequality (A.18).
3.13
Continuous systems (*)
Stochastic thermodynamics has developed in parallel for physical processes with dis-
crete state space, described by master equations, and continuous state space, described
by Langevin equations. The main results in stochastic thermodynamics, such as the
ﬂuctuation theorems discussed in the next chapter, can be equivalently derived in either
case, although the formalism is quite diﬀerent. In this section, we brieﬂy describe the
fundamental ideas of stochastic thermodynamics based on Langevin equations.
We consider a one-dimensional physical system with negligible inertia, described by
the Langevin equation
dx
dt = µP F(x, t) +
√
2D ξ(t) = µP
=
−∂
∂xϵ(x, λ) + f (x, t)
>
+
√
2D ξ(t),
(3.82)
where we split the total force F(x, t) into a term −∂ϵ(x, λ)/∂x originating from a
conservative energy ﬁeld ϵ(x, λ) and a nonconservative term f (x, t) representing the
nonequilibrium driving. We assume that the diﬀusion coeﬃcient D is constant, which
implies that the equation can be interpreted with either the Ito or the Stratonovich
convention with identical results. Then the Fokker-Planck equation corresponding to
eq. (3.82) reads
∂p(x; t)
∂t
= ∂
∂x
=
µP
$ ∂
∂xϵ(x, λ) −f (x, t)
%
p(x; t) + D ∂
∂xp(x; t)
>
.
(3.83)
This corresponds to the probability current J = µP F p −D ∂p/∂x (cf. eq. (2.105)). We
assume that the mobility µP and the diﬀusion coeﬃcient D are connected by the
Einstein relation,
D = kBT µP.
(3.84)
The Einstein relation is the condition for the Langevin equation (3.82) to be thermo-
dynamically consistent. Indeed, if this condition is satisﬁed, the driving is absent, and
λ is constant, the equation satisﬁes detailed balance and the probability current van-
ishes at stationarity. In this case, the Fokker-Planck equation (3.83) associated with the
Langevin equation (3.82) admits as a solution the equilibrium distribution

Stochastic Thermodynamics
63
peq(x) = e(F(λ)−ϵ(x,λ))/kBT,
(3.85)
where F(λ) = −kBT ln
?
dx e−ϵ(x,λ)/kBT is the free energy. If the nonconservative driving
f is present and the boundary conditions are suitable, the equation admits a nonequi-
librium stationary solution in which the work performed by the driving is released as
heat to the reservoir.
The energy change associated with the Langevin equation is
dϵ = ∂ϵ(x, λ)
∂x
◦dx + ∂ϵ(x, λ)
∂λ
dλ
dt dt.
(3.86)
The ◦symbol reminds us that the product is interpreted in the Stratonovich sense. If
we decided to adopt the Ito convention, eq. (3.86) would have contained an extra term;
see section 2.9.
Similar to (3.9), the inﬁnitesimal work is
dw = ∂ϵ(x, λ)
∂λ
dλ
dt dt + f (x, t) ◦dx,
(3.87)
where the products are interpreted in the Stratonovich sense for the same reason as
in eq. (3.86). Combining eqs. (3.86) and (3.87), we ﬁnd a simple expression for the
inﬁnitesimal heat exchange with the reservoir:
dq = dw −dϵ =
=
−∂ϵ(x, λ)
∂x
+ f (x, t)
>
◦dx = F(x, t) ◦dx,
(3.88)
where we recall the expression of F(x, t) given by eq. (3.82).
We now look at the total entropy production rate. Like in the case of discrete states,
the stochastic entropy ssys(x, t) is deﬁned by
ssys(x, t) = −kB ln p(x; t),
(3.89)
where p(x; t) is the probability distribution of the ensemble at time t. Using the rules
of Stratonovich calculus, the rate of increase of the system entropy along the trajectory
x is
d
dtssys(x(t), t) = −kB
d
dt ln p(x(t), t)
= −kB
=
1
p(x; t)
∂
∂xp(x; t) ◦dx
dt +
1
p(x; t)
∂
∂tp(x; t)
>
= kB
= J(x, t)
D p(x; t) ◦dx
dt −F(x, t)
kBT
◦dx
dt −
1
p(x; t)
∂
∂tp(x; t)
>
.
(3.90)
In the third line, we used the Einstein relation and the deﬁnition (2.105) of the current
for the Fokker-Planck equation. Since sres = q/T, we obtain
˙stot = dssys
dt + ˙sres = kB
= J(x, t)
D p(x; t) ◦dx
dt −
1
p(x; t)
∂p(x(t), t)
∂t
>
.
(3.91)

64
Chapter 3
We now use this expression to evaluate the average entropy production rate. The average
of the last term on the right-hand side vanishes:
0
1
p(x; t)
∂
∂tp(x; t)
1
=
&
dx ∂
∂tp(x; t) = ∂
∂t
&
dx p(x; t) = 0.
(3.92)
To evaluate the average of the ﬁrst term on the right-hand side of eq. (3.91), it is easier
to apply the Ito convention, which has the advantage that the average of the noise term
vanishes. We therefore switch from the Stratonovich to the Ito convention using the
rule presented in eq. (2.127), obtaining
8
dstot9
= kB
0 J(x, t)
D p(x; t) ◦dx
1
= kB
@
J(x, t)µPF(x, t)
D p(x; t)
dt +
A
2
D
J(x, t)
p(x; t) ◦dW
B
= kB
@
J(x, t)µPF(x, t)
D p(x; t)
dt +
A
2
D
J(x, t)
p(x; t) · dW
+
1
p(x; t)
∂
∂xJ(x, t) dt −J(x, t)
p2(x, t)
∂
∂xp(x; t) dt
1
.
(3.93)
Here dW is the increment of the Wiener process, deﬁned in eq. (2.112). The average of
the second term vanishes in the Ito convention, as we anticipated. The average of the
third term also vanishes since
8
(∂J(x, t)/∂x)/p(x; t)
9
=
?
dx ∂J(x, t)/∂x, which can be
transformed into a boundary term. We are therefore lef with
8˙stot9
= kB
0J(x, t)µPF(x, t)
D p(x; t)
−J(x, t)
p2(x, t)
∂p(x; t)
∂x
1
= kB
0 J2(x, t)
D p2(x, t)
1
= kB
&
dx J2(x, t)
D p(x; t),
(3.94)
where we again take advantage of eq. (2.105). This formula generalizes the expres-
sion for the average entropy production rate for master equations (3.39), to continuous
systems.
3.14
Further reading
The ideas developed in this chapter constitute the founding core of stochastic
thermodynamics. We discuss here a few references complementing our presentation,
although there are many other seminal contributions that we do not review for reasons
of space.
Sekimoto [151, 152] and Crooks [33] deﬁne stochastic work and heat for physi-
cal systems described by master equations. In our exposition, we loosely follow the
last reference. The book by Sekimoto [153] is a classic reference that, among other

Stochastic Thermodynamics
65
things, highlights the conceptual diﬀerence between mesoscopic and calorimetric heat
(ch. 6). Qian [134], Seifert [148], and other classic works discuss the deﬁnition and
interpretation of stochastic entropy production.
The example of the myosin molecular motor is inspired by the book by Howard
[80]. Stochastic chemical reactions have been both a fruitful playground for the devel-
opment of stochastic thermodynamics and extremely relevant for applications; see
Schnakenberg [146] and Rao and Esposito [135] for a more modern treatment.
The Schnakenberg formula (3.39) expresses the average entropy production rate.
Schnakenberg’s work develops ideas introduced by Bergmann and Lebowitz [16] in
the context of the nonequilibrium statistical mechanics of Hamiltonian systems inter-
acting with thermal reservoirs—a work that, in retrospect, anticipates several ideas of
stochastic thermodynamics.
Bo and Celani [18] review in a comprehensive way coarse-graining and decimation
techniques for stochastic processes, including potential pitfalls. See also Pigolotti and
Vulpiani [129] for a discussion of adiabatic elimination in master equations. Puglisi
et al. [133] proposes the idea that disappearence of loops under coarse graining leads
to a reduced entropy production rate. Kawaguchi and Nakayama [85] point out that,
when variables, even and odd, coexist under time reversal, the entropy production may
increase upon coarse graining. Rao and Esposito [136] derive a general procedure to
identify the conservative and the minimal set of nonconservative contributions to the
entropy production.
Esposito [48] discusses more generally stochastic thermodynamics under coarse
graining. Seifert [148] obtains the expression for the entropy production rate for con-
tinuous systems. The book by Sekimoto [153] and the review by Seifert [149] provide
an extensive introduction to stochastic thermodynamics focused on Langevin equa-
tions. Expressions of observables for continuous systems can be also obtained from
their discrete counterparts by taking a continuum limit; see, e.g., Gingrich et al. [70].
3.15
Exercises
3.1
Consider a system with three states, x = 0, 1, 2. The jump rates kx′x are all
equal to 1, except the jumps 0 ↔1, which are driven:
k10 = eδ/2kBT;
k01 = e−δ/2kBT.
Simulate the process by the Gillespie algorithm for diﬀerent values of δ and
show that the total entropy produced up to time t can become negative, at least
for small δ and short times.
3.2
Consider a system with two states x = 0 and x = 1 with energies ϵ0 = 0 and
ϵ1 = ϵ(t), where ϵ(t) = ϵft/T and ϵf is a constant. The system is at equilib-
rium at time t0 = 0 and is manipulated in the time interval [t0, tf] with tf = T .
Simulate the stochastic dynamics of the two-state system for a given value of
ϵ and diﬀerent values of the duration T , implementing a discrete-step simu-
lation. From the simulations, compute the average total entropy production
as a function of T . Estimate analytically the total entropy production in the
limiting cases of large and small T and verify that the result agrees with the
simulations.

66
Chapter 3
3.3
A reversible dimerization reaction A + A ⇌AA is characterized by a dimer-
ization rate k+ = 1 and a dissociation rate of dimers k−= 1. Simulate
the stochastic chemical reaction from an initial state with nA = 1000 free
monomers and no dimers, for a long enough time until equilibrium is reached.
Estimate analytically the average total entropy production and compare the
estimate with simulation results.
3.4
A three-state system is manipulated in a periodic way, λ(t + T ) = λ(t). Its
jump rates are given by
kxx′ = ωxx′ eϵx′(λ)/kBT,
x ∈{0, 1, 2}.
Show that, with this choice of rates, the probability current averaged over a
period JT =
? T
0 dt Jxx′(t)/T always vanishes.
3.5
A particle is dragged by a force f = 2 in a periodic potential ϵ(x) = sin(2πx),
where parameters are in dimensionless units µ = kBT = D = 1. Simulate the
Langevin equation corresponding to this physical system. Use simulations to
show that the average total entropy production at steady state is linear in the
duration of the time interval T .

CHAPTER 4
Fluctuation Relations
Fluctuation relations are remarkable constraints on distributions of ﬂuctuating quan-
tities like stochastic heat, work, and entropy. They hold in rather general settings and
ﬁnd their origin in the assumptions of microscopic reversibility and thermodynamic
consistency. Mathematically, ﬂuctuation relations are based on the asymmetry between
the probability of an observed trajectory and that of its time-reversed counterpart. This
asymmetry is a hallmark of nonequilibrium systems and, in stochastic thermodynam-
ics, is directly related to entropy production. In this chapter, we discuss how ﬂuctuation
theorems descend from this asymmetry and their main consequences for stochastic
thermodynamics.
4.1
Irreversibility and entropy production
Nonequilibrium processes produce entropy because of their irreversible nature. The
connection between irreversibility and entropy production can be made very explicit
in stochastic thermodynamics. Our ﬁrst step in this direction is to assign a precise
meaning to the concept of irreversibility.
We consider a mesoscopic system satisfying generalized detailed balance, eq. (3.7).
We imagine performing an experiment in which we prepare the system in an initial
statistical state and then manipulate it during a time interval [t0, tf]. We assign to the
control parameter λ the time-dependent value λ(t). We call this procedure the forward
protocol and the corresponding trajectories forward trajectories. With a slight abuse
of language, we ofen use the expression forward protocol for the function λ = (λ(t))
as well.
We now imagine preparing the system, e.g., in the ﬁnal state of the forward proto-
col, and performing the experiment with a backward protocol, i.e., by reversing the
experimental procedure in time. Mathematically, this means that the control param-
eter is varied from λ(tf) to λ(t0), tracing back the values it assumed in the forward
protocol. We call a stochastic trajectory generated by this procedure a backward trajec-
tory. How likely is it to observe backward trajectories coinciding with typical forward
trajectories, but in the reverse temporal order? If the probabilities of the most proba-
ble trajectories with the forward protocol are larger than those of their time-reversed
images with the backward protocol, we can conclude that the underlying dynamics is
irreversible.

68
Chapter 4
We express the probability density Px(λ) of a forward trajectory x with the forward
protocol λ by
Px(λ) = Px|x0(λ) px0(t0),
(4.1)
where Px|x0(λ) is the conditional probability of the trajectory x, given its initial state
x0 at time t0:
Px|x0(λ) = e−
! tf
tn kout
xf (t) dt kxfxn−1(tm) e−
! tn
tn−1 kout
n−1(t) dt · · ·
× e−
! t3
t2 kout
x2 (t) dt kx2x1(t2) e−
! t2
t1 kout
x1 (t) dt kx1x0(t1) e−
! t1
t0 kout
x0 (t) dt;
(4.2)
see section 2.7. We now associate with each trajectory x a backward trajectory !x. The
backward trajectory traces all the states visited by x in reverse order, dwelling in each
state the same time as the forward trajectory. It is obtained from the original trajectory
by an operation of time reversal:
"t = tf −(t −t0),
t0 ≤t ≤tf.
(4.3)
We assume here for simplicity that the operation of time reversal leaves the states x
unaﬀected. We discuss systems in which this is not the case in sections 4.10 and 4.14.
We now express the backward trajectory using time reversal:
"x(t) = x("t).
(4.4)
The initial state and time, respectively, of the backward trajectory are the ﬁnal state and
time of the forward one.
We also introduce a backward dynamics. The jump rates of the backward dynamics
are the same as the forward one, but with the backward protocol
"λ(t) = λ("t),
(4.5)
where"t is deﬁned in eq. (4.3). The probability density of the backward trajectory"x with
the backward protocol"λ is
P"x("λ) = P"x|xf("λ) pxf(tf),
(4.6)
where P"x|xf("λ) is the conditional probability of the backward trajectory given its initial
state, which is the ﬁnal state xf of the forward trajectory. This conditional probability is
expressed by
P"x|xf("λ) = e−
! t1
t0 kout
x0 (t) dt kx0x1(t1) e−
! t2
t1 kout
x1 (t) dt · · ·
× e−
! tn
tn−1 kout
xn−1(t) dt kxn−2xn−1(tn−1) e−
! tn
tn−1 kout
xn−1(t) dt
× kxn−1xf(tn) e−
! tf
tn kout
xf (t) dt,
(4.7)
where we exploit the relation
kxx′("λ("t)) = kxx′(λ(t)) = kxx′(t).
(4.8)

Fluctuation Relations
69
We now evaluate the ratio between conditional probabilities of forward and back-
ward trajectories. The expression considerably simpliﬁes since the exponential factors
associated with the dwells cancel out:
Px|x0(λ)
P!x|xf("λ)
=
n
#
i=1
kxixi−1
kxi−1xi
.
(4.9)
We further assume that our system is coupled to a heat reservoir at temperature T,
so that its jump rates satisfy the generalized detailed balance condition, eq. (3.7).
Substituting this condition into eq. (4.9), we obtain
Px|x0(λ)
P!x|xf("λ)
= exp
$
1
kBT
n−1
%
k=1
&
ϵxk−1 −ϵxk + δxkxk−1
'
(
= eq(x)/kBT,
(4.10)
where the second equality follows from the deﬁnition of stochastic heat, eq. (3.10).
Equation (4.10) expresses the imbalance between conditional probabilities of forward
and backward trajectories in terms of the heat released to the reservoir. We now express
the ratio of unconditioned probabilities of trajectories by including the probabilities
px0(t0) and pxf(tf) of the initial and ﬁnal states, respectively:
Px(λ)
P!x("λ)
= px0(t0)Px|x0(λ)
pxf(tf)P!x|xf("λ)
= exp
$
ssys
xf (tf) −ssys
x0 (t0)
kB
+ q(x)
kBT
(
= estot(x)/kB.
(4.11)
And, solving for the total entropy production stot(x),
stot(x) = kB ln
)Px(λ)
P!x("λ)
*
.
(4.12)
Equation (4.12) is central in stochastic thermodynamics. It provides the announced
connection between the entropy production and irreversibility, quantiﬁed as the asym-
metry between the probabilities of forward and backward trajectories. The conse-
quences of this relation are the focus of this chapter.
At equilibrium, where the system is not manipulated and the jump rates satisfy the
detailed balance relation (2.85), one has
Px = P!x,
∀x.
(4.13)
Equation (4.13) implies that the entropy production stot(x) vanishes for all trajectories
x at equilibrium.
4.2
Integral ﬂuctuation relation
Irreversibility and entropy production are related by eq. (4.12) at the level of indi-
vidual trajectories. We now consider an ensemble of trajectories starting from an initial
distribution of states p0(x0). Because of microscopic reversibility, the same set of states
is accessible to both dynamics, hence there is a one-to-one correspondence between

70
Chapter 4
trajectories of the forward and backward dynamics. We introduce averages over the
forward and backward ensembles of trajectories:
⟨. . .⟩F =
+
Dx Px(λ) . . . ,
⟨. . .⟩B =
+
D"x P!x("λ) . . . ,
(4.14)
where we use
! D!x =
! Dx, a property that can be veriﬁed by changing the signs of
the inﬁnitesimal time increments in eq. (2.92). Using eq. (4.12), we directly obtain
,
e−stot(x)/kB
-
F =
+
Dx P!x("λ) = 1.
(4.15)
Equation (4.15) is the integral ﬂuctuation relation, a relation that has many impor-
tant consequences. In particular, since the exponential is a convex function, the Jensen
inequality entails ln
.
e−x/
≥ln e−⟨x⟩= −⟨x⟩; see appendix A.1. Therefore, eq. (4.15)
implies
.
stot(x)
/
F ≥0,
(4.16)
which is the second law of stochastic thermodynamics. Like the traditional second
law of thermodynamics, eq. (4.16) reduces to an equality for equilibrium processes. In
this case, the equality is not only valid on average but also trajectory-wise: because of
detailed balance, the total entropy production vanishes for any equilibrium trajectory;
see section 4.1.
On the other hand, out of equilibrium, each trajectory is characterized by its own
entropy production, and the second law is only valid on average. Since e−stot(x)/kB <
1 for stot(x) > 0, positive values of the entropy production must be compensated by
negative values for eq. (4.15) to hold. This means that, out of equilibrium, there is always
a nonvanishing probability of observing trajectories characterized by a negative total
entropy production. This fact is one of the most important physical consequences of
the integral ﬂuctuation relation.
There are situations in which the probability distribution of stot is Gaussian. For
example, this is the case in the linear response regime, i.e., in the regime close to
thermodynamic equilibrium where linear response theory as described in section 3.11
applies. We prove this fact in section 6.2. For Gaussian distributions, the integral ﬂuc-
tuation relation (4.15) implies a relation between the mean and the variance of the
distribution of stot:
2kB⟨stot⟩= σ 2
stot.
(4.17)
This equation is another example of a ﬂuctuation-dissipation relation. Its derivation is
lef as exercise 4.1.
4.3
Dragged particle on a ring
We now consider a particle on a ring of discrete states, i = 1, . . . , N, with periodic
boundary conditions. All states have the same energy. An external agent drags the par-
ticle in the counterclockwise direction with a constant driving δ. The jump rates are
given by
k+ = kx+1,x = ω eδ/kBT;
k−= kx−1,x = ω,
(4.18)

Fluctuation Relations
71
k− = ω
k+ = ω eδ/kBT
0
25
50
75
100
t
0
50
Δx
(a)
(b)
Figure 4.1. (a) Jump network of the dragged particle on a ring. The driven jumps, x −→
x + 1, are shown with bold arrows. (b) Examples of trajectories for ω = 1 and δ = 0.2 kBT.
The y-axis represents the total displacement &x since the initial time. A random trajectory
is highlighted.
where +, −stand for counterclockwise and clockwise, respectively. The jump network
is shown in ﬁg. 4.1a. We want to verify that the integral ﬂuctuation relation holds.
We consider a time interval [t0, tf]. During this time interval, the particle performs a
number n+ of counterclockwise jumps and a number n−of clockwise jumps. Since all
states are identical, clockwise and counterclockwise jumps occur at constant rates. This
implies that n+ and n−are Poisson distributed:
pn+ = 1
n+!
0
ω eδ/kBTT
1n+
exp
2
−ω eδ/kBTT
3
,
pn−= 1
n−! [ω T ]n−exp (−ω T ) ,
(4.19)
where T = tf −t0. Examples of trajectories are shown in ﬁg. 4.1b.
The external agent performs work equal to δ for every counterclockwise jump. The
same amount of work is returned to the external agent at every clockwise jump. The
total work is therefore

72
Chapter 4
−2.5
0.0
2.5
5.0
7.5
stot, y = e−stot
0.00
0.05
0.10
p(stot), p(y)
stot
e−stot
Figure 4.2. Probability distribution of stot and y = exp−stot for the dragged particle over
a duration T = 5 s, with ω = 1 s−1 and δ = 0.2 kBT. For these parameters, the average
entropy production is ωT δ [exp(δ/kBT) −1]/T ≈0.224 kB. Entropy production is plotted
in units of kB.
w = (n+ −n−) δ.
(4.20)
Since the internal energy is constant, all the work is released into the heat reservoir. This
implies that
stot = w
T = δ
T (n+ −n−)
(4.21)
and therefore
p(stot) =
∞
%
n+,n−=0
pn+pn−δK
T stot/δ,(n+−n−) .
(4.22)
For our parameter choice, the distribution of stot is close to a Gaussian, as shown in
ﬁg. 4.2. The distribution of e−stot/kB is instead markedly skewed and exhibits a number
of peaks at large values, corresponding to the events in which stot is large and negative.
It is possible to analytically compute the sums in eq. (4.22). However, it is enough
for our purposes to substitute eq. (4.22) directly in the integral ﬂuctuation relation,
obtaining
,
e−stot/kB
-
=
%
stot
e−stot/kBp(stot) =
∞
%
n+,n−=0
pn+pn−e−δ (n+−n−)/kBT
=


∞
%
n+=0
pn+e−δ n+/kBT




∞
%
n−=0
pn−eδ n−/kBT


= exp
0
ω T
2
1 −eδ/kBT31
exp
0
ω T
2
eδ/kBT −1
31
= 1.
(4.23)

Fluctuation Relations
73
This calculation illustrates how the integral ﬂuctuation relation results from a delicate
balance between the contribution of more likely jumps that produce entropy and less
likely jumps characterized by a negative entropy production.
4.4
Back to linear response theory (*)
The ﬂuctuation-dissipation relation (4.17) descends from the integral ﬂuctuation
relation (4.15) close to equilibrium. However, it is historically more appropriate to say
that ﬂuctuation relations are the generalization of ﬂuctuation-dissipation relations far
from equilibrium, since the latter were discovered earlier. In this section, we return to
the linear response theory developed in section 3.11 and connect it with time-reversal
symmetry.
We consider the ﬂuctuation-dissipation relation (3.66) and assume that the observ-
ables X, as well as the dynamics, are invariant under time reversal. At equilibrium, the
probability of a trajectory x is equal to the probability of its backward trajectory"x. This
probability is also invariant under time translations. As a consequence, the correlation
functions introduced in section 3.11 are symmetric:
Cαβ(t) =
+
Dx Px Xα,x(t) Xβ,x(0) =
+
Dx Px Xα,x(0) Xβ,x(−t)
=
+
Dx P"x Xα,"x(0) Xβ,"x(t) = Cβα(t),
(4.24)
where we exploit time-translation invariance in the second equality, time-reversal
invariance in the third, and ﬁnally the fact that Dx = D"x. Comparing with eq. (3.64),
we obtain
+ t0
−∞
dt′ Kβα(t −t′) =
+ t0
−∞
dt′ Kαβ(t −t′).
(4.25)
Taking the derivative with respect to t, we obtain the symmetry of the response
functions:
Kαβ(t) = Kβα(t),
∀t.
(4.26)
This relation can be seen as an extension of the Maxwell relations (2.30), which express
the same symmetry for the derivatives of thermodynamic potentials.
As we are considering small perturbations, correlation functions must satisfy a linear
system of equations:
d
dtCαβ(t) = −
%
γ
Mαγ Cγβ(t),
t > 0,
(4.27)
where (Mαβ) is a positive-deﬁnite matrix since the equilibrium state must be sta-
ble. Therefore, correlations decay exponentially with time. Taking the derivative of
eq. (4.24) with respect to t in the limit t →0, we obtain
Lαβ =
%
γ
Mαγ Cγβ(0) =
%
γ
Mβγ Cγ α(0) = Lβα.
(4.28)

74
Chapter 4
Thus the matrix Lαβ is also symmetric. The relations (4.28) embodying this symme-
try are known as the Onsager reciprocity relations. To interpret them physically, we
introduce thermodynamic forces Yα that describe deviations from equilibrium:
Yα = ∂S
∂Xα
,
(4.29)
where S(X) = S(X1, X2, . . .) is the system entropy expressed in terms of the instan-
taneous values of the observables Xα. We assume that the macroscopic laws for the
time rates of change of the Xα are linear in the thermodynamic forces Yα, at least for
moderate deviations from equilibrium:
dXα
dt = 1
kB
%
β
LαβYβ,
(4.30)
where the Boltzmann constant is introduced for convenience. We now show that the
matrix (Lαβ) in eq. (4.30) is the same matrix deﬁned in eq. (4.28). Evaluating the
correlation Cαγ (t) for short times, we obtain
dCαγ
dt
8888
t=0
=
%
β
Lαβ
.
Xγ Yβ
/eq .
(4.31)
By the Boltzmann-Einstein principle (see eq. (2.60)), the equilibrium probability dis-
tribution of the observables X = (Xα) is proportional to exp(S(X)/kB). We therefore
obtain
.
Xγ Yβ
/eq = N
+ #
α
dXα Xγ
∂S
∂Xβ
eS(X)/kB = N kB
+ #
α
dXα Xγ
∂
∂Xβ
eS(X)/kB,
(4.32)
where N is a normalization constant. Integrating by parts, we obtain
.
Xγ Yβ
/eq = −kB δK
γβ.
(4.33)
A comparison with eq. (4.27) conﬁrms that the matrix Lαβ introduced in eq. (4.30) is
equal to that appearing in eq. (4.28). The coeﬃcient Lαβ appearing in eq. (4.30) relates
the time derivative of the observable Xα with the force Yβ conjugate to the observable
Xβ. A similar relation connects the time derivative of Xβ with the force Yα conju-
gate to Xα via the coeﬃcient Lβα. The Onsager reciprocal relations impose that these
coeﬃcients are equal.
The Onsager reciprocity relations generalize to nonequilibrium steady states. In the
steady state, the average entropy production rate ˙S is expressed by
˙S = 1
T
%
α
AαJα,
(4.34)
where the Aα are the aﬃnities and the Jα the corresponding currents; see section 3.9.
Since both the As and the Js vanish at equilibrium, we have close to equilibrium

Fluctuation Relations
75
1
0
(0)
(1)
(2)
k0
(2)
k0
(1)
k1
(2)
k1
(1)
k1
k0
Figure 4.3. Jump network of the two-state, two-
cycle model. Node 0 represents the inactive
state, 1 the active state. Edge (0) represents
spontaneous jumps due to thermal ﬂuctua-
tions. Edge (1) corresponds to substrate pro-
cessing and edge (2) to hydrolysis of a high-
energy molecule. Jumps along edges (1) and (2)
involve interaction with particle reservoirs.
Jα ≈
%
β
LαβAβ.
(4.35)
In this case, the matrix L = (Lαβ) is called the matrix of kinetic coeﬃcients. The
Onsager reciprocity relations impose that the matrix L is symmetric as well, allowing
us to relate kinetic coeﬃcients appearing in diﬀerent physical processes.
As an example, we consider an enzyme that transforms a substrate R into a prod-
uct P. The jump network for this system is represented in ﬁg. 4.3. The substrate is
transformed into the product when jumping from the activated state 1 to the ground
state 0 along pathway (1). The same transformation is assisted by hydrolysis of a
high-energy molecule along pathway (2). Pathway (0) represents spontaneous acti-
vation/deactivation of the enzyme by interaction with the heat reservoir, without
processing any molecule.
The jump (0) is not driven, while (1) and (2) entail a driving. Following the approach
described in section 3.9, we choose edge (0) as the spanning tree and denote by Cα,
α = (1, 2) the fundamental cycles obtained by joining edge (0) with edge (α). All
cycles are considered positive in the counterclockwise direction. The master equation
reads
dp0
dt =
2
k1 + k(1)
1 + k(2)
1
3
p1 −
2
k0 + k(1)
0 + k(2)
0
3
p0;
dp1
dt =
2
k0 + k(1)
0 + k(2)
0
3
p0 −
2
k1 + k(1)
1 + k(2)
1
3
p1.
(4.36)
We express the jump rates by
k1 = ω0 eϵ/2kBT;
k0 = ω0 e−ϵ/2kBT;
k(1)
1 = ω1 e(ϵ+δ1)/2kBT;
k(1)
0 = ω1 e−(ϵ+δ1)/2kBT;
(4.37)
k(2)
1 = ω2 e(ϵ+δ2)/2kBT;
k(2)
0 = ω2 e−(ϵ+δ2)/2kBT.

76
Chapter 4
Here ϵ is the energy diﬀerence between states 1 and 0, and δ1,2 are the drivings. The
aﬃnities are
A(1) = kBT ln k0k(1)
1
k1k(1)
0
= δ1;
A(2) = kBT ln k1k(2)
0
k0k(2)
1
= −δ2.
(4.38)
The steady-state probability distribution is given by
pst
0 = 1
N
2
k1 + k(1)
1 + k(2)
1
3
;
pst
1 = 1
N
2
k0 + k(1)
0 + k(2)
0
3
;
(4.39)
where
N = k0 + k(1)
0 + k(2)
0 + k1 + k(1)
1 + k(2)
1 .
(4.40)
The average currents in the two fundamental cycles are given by
J(1) = k(1)
1 pst
1 −k(0)
0 pst
0 = 1
N
)
2ω0ω1 sinh
9 δ1
2kBT
:
+ 2ω1ω2 sinh
9δ1 −δ2
2kBT
:*
;
J(2) = k(2)
0 pst
0 −k(2)
1 pst
1 = 1
N
)
2ω0ω2 sinh
9 δ2
2kBT
:
−2ω1ω2 sinh
9δ1 −δ2
2kBT
:*
.
(4.41)
Setting δ1,2 ≪kBT, we obtain N = 2 (ω0 + ω1 + ω2) cosh (ϵ/2kBT) and the following
expression of the matrix Lαβ:
L11 = ω1(ω0 + ω2)
N kBT
;
L22 = ω2(ω0 + ω1)
N kBT
;
L12 = −ω1ω2
N kBT = L21.
(4.42)
The coeﬃcients L12 and L21 are equal, as predicted by the Onsager reciprocity relations.
4.5
Detailed ﬂuctuation relation
The detailed ﬂuctuation relation is a stronger version of the integral ﬂuctuation rela-
tion. It however requires the further assumption that the entropy production stot(x) is
odd under the mapping x −→"x:

Fluctuation Relations
77
stot("x) = −stot(x).
(4.43)
This property is called involution. Equation (4.12) seems to suggest that the entropy
production is always an involution. There is however a subtle point. The entropy
production of the backward trajectory is
stot(!x) = kB ln

P!x("λ)
P!!x(""λ)

.
(4.44)
The time-reversal operation is an involution, therefore it is always true that ""λ = λ.
However, the involution property also requires that P""x(λ) = Px(λ), i.e., that the
backward-of-the-backward trajectory probability is equal to the forward trajectory
probability. This requires that, taking the ﬁnal distribution Pxf(tf) as the initial con-
dition and solving the diﬀerential equation with the backward protocol, we recover the
initial distribution Px0(t0) afer a duration equal to tf −t0. This is not necessarily the
case, since the distribution px at the end of the backward manipulation depends not only
on the instantaneous value of the parameter λ(t0) but on the whole backward protocol
"λ. Examples in which the entropy production is and is not an involution are shown in
ﬁg. 4.4 for a two-state system.
Assuming that the entropy production is an involution, given an arbitrary function
f (s), we obtain
,
f (stot(x)) e−stot(x)/kB
-
F =
.
f (stot(x))
/
B =
.
f (−stot(!x))
/
B .
(4.45)
We now choose the function f (stot(x)) = δ(stot(x) −s) that selects all trajectories x
characterized by a given value s of stot. Substituting and rearranging terms, we obtain
the detailed ﬂuctuation relation
p(stot; λ)
p(−stot;"λ)
= estot/kB.
(4.46)
Nonequilibrium steady states are an important case where the involution property
always holds. The reason is that, in this case, the distribution px does not depend on
time and the dynamics for the backward and forward trajectories are identical. For
nonequilibrium steady states, the detailed ﬂuctuation relation becomes
p(stot)
p(−stot) = estot/kB.
(4.47)
This expression helps clarify why the detailed ﬂuctuation relation is a more powerful
result than the integral ﬂuctuation relation. The integral ﬂuctuation relation provides
a single global constraint on the distribution of the entropy production. However,
the detailed ﬂuctuation relation provides, for any value of stot, a relation between the
probabilities of observing entropy productions +stot and −stot. Thanks to the detailed
ﬂuctuation relation, in a steady-state system it is suﬃcient to know only p(stot) for
positive (or negative) values of stot to reconstruct the entire distribution.

78
Chapter 4
0
1
2
3
4
5
t
0.00
0.25
0.50
0.75
1.00
p
0
1
2
3
4
5
t
0.00
0.25
0.50
0.75
1.00
p
(a)
(b)
Figure 4.4. Involution property in a two-state system. The instantaneous probability p(t)
of the 0 state is plotted against t. (a) For a generic initial condition p(t0), performing
the forward manipulation (solid line) and immediately following it with the backward
manipulation (dashed line), the initial probability is not recovered. Involution does not
hold. (b) With a carefully chosen initial condition, the involution property holds. In the
model, the energy difference ϵ1 −ϵ0 between the two states is manipulated according
to a linear protocol: ϵ1 −ϵ0 = λ(t) = λ0 + (λf −λ0)(t/T ). The jump rates are given by k10 =
ω e−(ϵ1−ϵ0)/2kBT , and analogously for k01. We set λ0 = −kBT, λ1 = 2kBT, T = 5, and ω = 1.
4.6
The Jarzynski and Crooks relations
The Jarzynski and Crooks relations are fundamental results in stochastic thermo-
dynamics. They can be seen as special cases of the integral and detailed ﬂuctuation
theorems when the initial and ﬁnal states are equilibrium states. Speciﬁcally, we con-
sider a system initially at thermodynamic equilibrium, bring it out of equilibrium by
means of manipulations and/or drivings, and then let it relax to equilibrium again. The

Fluctuation Relations
79
ﬁnal equilibrium state does not need to be identical to the initial one since the initial
and ﬁnal values of the control parameter may be diﬀerent. In this setting, the involu-
tion property always holds: once the reverse dynamics has brought back the energies to
their initial values and the nonequilibrium drivings have been switched oﬀ, the initial
equilibrium state is necessarily restored. Therefore, both the integral and the detailed
ﬂuctuation relations hold. Further, one has
px(t0) = e(F(t0)−ϵx(t0))/kBT,
px(tf) = e(F(tf)−ϵx(tf))/kBT,
(4.48)
where F(t) is the equilibrium free energy corresponding to the value λ(t) of the control
parameter:
F(t) = −kBT ln
%
x
e−ϵx(λ(t))/kBT.
(4.49)
Therefore, the entropy change of the system is
&ssys = kB ln
)px0(t0)
Pxf(tf)
*
= 1
T
;
ϵxf(tf) −ϵx0(t0) −&F
<
,
(4.50)
where &F = F(tf) −F(t0). We then express the total entropy production as
stot = q
T + &ssys = w −&F
T
= wdiss
T ,
(4.51)
where we use the stochastic ﬁrst law, eq. (3.11), and deﬁne the dissipated work wdiss as
the diﬀerence between the performed work and the free-energy change. The dissipated
work represents the total amount of work that is released to the reservoir as heat. Sub-
stituting expression (4.51) into the integral ﬂuctuation relation, and considering that
the free-energy diﬀerence does not ﬂuctuate, we obtain the Jarzynski equality:
,
e−w/kBT-
F = e−&F/kBT.
(4.52)
The corresponding detailed ﬂuctuation relation is the Crooks relation:
p(w; λ)
p(−w;"λ)
= e(w−&F)/kBT.
(4.53)
For both the Jarzynski and Crooks relations, the assumption that the ﬁnal state is at
equilibrium can be relaxed. We consider a process that starts at equilibrium at time t0
but ends at tf in a nonequilibrium state. We associate with it an auxiliary process of a
longer time duration. The two processes are identical in the time interval [t0, tf]. The
auxiliary process runs for longer times t > tf with all drivings set to zero, δxx′(t > tf) = 0,
a ﬁxed manipulation parameter λ(t > tf) = λ(tf), and therefore constant energies ϵx(t >
tf) = ϵx(tf). The auxiliary process ends at a time t′
f ≫tf, when equilibrium is reached.
By construction, the auxiliary process starts and ends at equilibrium, so that its work
distribution satisﬁes both the Jarzynski and Crooks relations. Moreover, in the time

80
Chapter 4
interval [tf, t′
f], no work is performed, so that the distribution of work is the same in the
original and auxiliary processes. Therefore, the work distribution of the original process
satisﬁes both the Jarzynski and Crooks relations.
The Jarzynski and Crooks relations are of paramount importance for experimental
applications, as we discuss in chapter 7 in more detail.
4.7
Instantaneous quench
A simple example that helps to acquire familiarity with the Jarzynski and Crooks
relations is a system undergoing an instantaneous quench. A quench is a manipula-
tion protocol where the energies of the states are suddenly changed at a given time, and
otherwise remain constant. Speciﬁcally, we consider a system at equilibrium at the ini-
tial time t0. The energies ϵx(t0) are constant up to the quench time tq > t0. The quench
instantly alters the energies to the values ϵx(tq). The system is then allowed to relax
without further manipulation up to a time tf, when we assume it has reached equilib-
rium. Since the manipulation is instantaneous, the work provided to the system is equal
to the energy diﬀerence before and afer the quench,
w = ϵx(tq) −ϵx(t0),
(4.54)
where x is the state of the system immediately before the quench. As the system is
initially at equilibrium, the average work is
W =
%
x
[ϵx(tq) −ϵx(t0)] e(F(t0)−ϵx(t0))/kBT.
(4.55)
During the quench, the heat reservoir does not play any role: heat is dissipated only
during the free relaxation following the quench. The average total entropy production
is given by
Stot = W −&F =
%
x
[ϵx(tq) −ϵx(t0)] e(F(t0)−ϵx(t0))/kBT −&F,
(4.56)
taking into account that ϵx(tq) = ϵx(tf). The average entropy production satisﬁes Stot ≥
0 for any choice of the initial and ﬁnal energies, although that might be not obvious
from eq. (4.56). In fact, it is easier to verify the Jarzynski equality directly:
,
e−w/kBT-
F =
%
x
e−(ϵx(tf)−ϵx(t0))/kBTe(F(t0)−ϵx(t0))/kBT
= eF(t0)/kBT %
x
e−ϵx(tf)/kBT = e−&F/kBT,
(4.57)
where &F = F(tf) −F(t0) and we exploit eq. (4.49). Positivity of the average entropy
production follows from the Jensen inequality (A.11):
0 = ln
,
e−(w−&F)/kBT-
≥−⟨w −&F⟩
kBT
.
(4.58)

Fluctuation Relations
81
The Crooks relation is easy to prove if, for each given value of w, there is never more
than one state x, such as ϵx(tf) −ϵx(t0) = w. In this case, we ﬁnd
p(w; λ)
p(−w; λ) = e(F(t0)−ϵx(t0))/kBT
e(F(tf)−ϵx(tf))/kBT = e(w−&F)/kBT.
(4.59)
One can prove the Crooks relation also in the “degenerate” case, where there are multiple
states characterized by the same energy diﬀerence w between initial and ﬁnal states.
4.8
Fluctuation relations in practice
To apply ﬂuctuation relations to real systems, we need to estimate the distribution
of entropy production by replicating an experiment a certain number of times. It is
useful to know the number N of experimental replicates necessary for this purpose. To
be more speciﬁc, we consider a manipulation experiment with control parameter λ(t)
between two equilibrium states with λ(t0) = λ0 and λ(tf) = λf. The experiment aims
at estimating the free-energy diﬀerence &F = F(λf) −F(λ0) by means of the Jarzynski
equality (4.52). Solving the Jarzynski relation for &F, we obtain
&F = −kBT ln
,
e−w/kBT-
F = −kBT ln
+
dw p(w; λ) e−w/kBT.
(4.60)
We wish to get a sense of the values of w that contribute the most to the integral in
eq. (4.60). From the Crooks relation (4.53), we obtain
p(w; λ) e(&F−w)/kBT = p(−w;"λ),
(4.61)
where p(w;"λ) is the distribution of w in the backward protocol "λ. The lef-hand side
of eq. (4.61) is proportional to the argument of the integral in eq. (4.60). Therefore,
the leading contribution to the integral comes from the most probable value of the
work in the backward protocol, which we denote by −w∗. Its probability in the forward
protocol is
p(−w∗;!λ) e−(&F−w∗)/kBT = p(−w∗;!λ) e−w∗diss/kBT,
(4.62)
where w∗diss = −w∗+ &F is the most probable value of the dissipated work in the back-
ward protocol; see eq. (4.51). We expect p(w;"λ) to be of order 1 at its maximum −w∗.
We conclude that the probability r∗of obtaining w∗in the forward protocol is on the
order of e−w∗diss/kBT.
If a single event has the small probability r of taking place in an experiment,
the number of times it takes place in N trials is approximately Poisson distributed
with a parameter θ = r N , whose standard deviation is equal to
√
θ, as discussed in
appendix A.4. The relative standard error in N trials is therefore σ = 1/
√
θ = 1/
√
r N .
If we wish to estimate r with relative standard error σ by the Jarzynski equality, the
number of trials must be on the order of N = 1/(r∗σ 2). In conclusion, to reliably esti-
mate the free-energy diﬀerence &F, we must perform a number of experiments on the
order of
N ≈ew∗diss/kBT
σ 2
.
(4.63)

82
Chapter 4
The exponential dependence on w∗diss means that the required number of experi-
ments quickly becomes prohibitive as the protocol drives the system farther away from
equilibrium.
A similar reasoning applies to the practical use of other ﬂuctuation relations.
4.9
Adiabatic and nonadiabatic entropy production and
the Hatano-Sasa relation
Throughout this book, we have discussed two ways to bring a mesoscopic system out
of equilibrium: either by an external manipulation that introduces a time dependence in
the energy of the diﬀerent states or by drivings that dissipate energy every time a jump
occurs. Either mechanism positively contributes to the total average entropy production
Stot; see section 3.8. In this section, we discuss a decomposition of the entropy pro-
duction into two contributions, one originating from time dependence and one from
drivings.
Given a trajectory x, we deﬁne the adiabatic entropy production by
sa(x) = kB
n
%
k=1
ln
kxkxk−1(tk)pst
xk−1(tk)
kxk−1xk(tk)pstxk(tk) ,
(4.64)
and the nonadiabatic entropy production by
sna(x) = kB ln px0(t0)
pxf(tf) + kB
n
%
k=1
ln
pst
xk(tk)
pstxk−1(tk).
(4.65)
In both deﬁnitions, pst
xk(t) is the instantaneous stationary distribution, i.e., the one
that the system would reach if the control parameter were “frozen” at the value λ(t). By
summing eqs. (4.64) and (4.65), we ﬁnd that the total entropy production is the sum of
the adiabatic and nonadiabatic contributions:
stot = sa + sna.
(4.66)
To justify the names adiabatic and nonadiabatic, we ﬁrst consider a case in which the
jump rates are constant in time and the system is in a nonequilibrium steady state pst. In
such a case, sna = 0, and therefore sa = stot. This means that sa is the entropy produced
to maintain a nonequilibrium steady state in the absence of any manipulation. In the
opposite case, where the system is manipulated but no drivings are present, one has
sa = 0 since pst is, at every time, an equilibrium distribution satisfying detailed balance.
Consequently, we have stot = sna.
The heat associated with sa, qhk = Tsa, is called the housekeeping heat, where the
“house” is a metaphor for the nonequilibrium steady state. The remainder heat, qex =
q −qhk, is called the excess heat. The average nonadiabatic entropy production is
Sna(t) = ⟨sna(t)⟩= &Ssys(t) + Qex(t)
T
,
(4.67)

Fluctuation Relations
83
where &Ssys(t) is the change in the average system entropy and
Qex(t) =
.
qex/
= kBT
+ t
t0
dt
%
x
)dpx(t)
dt
ln pst
x (t)
*
(4.68)
is the average excess heat ﬂowing into the reservoir, beyond the housekeeping heat.
We now consider a manipulation that brings a system from an initial steady state
pst
x0(t0) to a ﬁnal one pst
xf(tf). The associated nonadiabatic entropy production is
expressed by
sna = −kB
n
%
k=0
ln
pst
xj(tk+1)
pstxk(tj) =
+ tf
t0
dt dλ(t)
dt
∂sst
x(t)(λ)
∂λ
88888
λ=λ(t)
,
(4.69)
where we introduce the function sst
x (t) = −kB ln[pst
x (t)]. In the absence of drivings, sst
is given by sst
x = [ϵx(t) −F]/T; see eq. (2.45).
If the ﬁnal state is not a steady state, eq. (4.69) still holds. To show that, we follow the
same logic we used to prove the Jarzynski equality with a nonequilibrium ﬁnal state; see
section 4.6. We consider an auxiliary process that is identical to the original process up
to the end of the manipulation, and then runs for a suﬃciently long time afer tf without
any further manipulation, i.e., where ϵx(t) = ϵx(tf) for all x and t > tf. The nonadiabatic
entropy production for this auxiliary process is equal to that of the original process,
since the partial derivative inside the integral in eq. (4.69) vanishes for t > tf.
Although sna vanishes when the system is in a time-independent steady state, it does
not vanish for systems brought from an initial to a ﬁnal steady state by an arbitrarily
slow protocol. Indeed, from eq. (4.69), one has
sna slow manipulation
−−−−−−−−−−→
.
sst(tf)
/
−
.
sst(t0)
/
.
(4.70)
Both the adiabatic and the nonadiabatic entropy production separately satisfy ﬂuc-
tuation relations. To show that this is true, it is useful to introduce the conjugate jump
rates
k+
xx′(t) = kx′x(t)pst
x (t)
pst
x′(t).
(4.71)
The conjugate jump rates deﬁne a conjugate master equation whose solution is p+
x (t).
A master equation and its conjugate share the same stationary distribution, pst+
x (t) =
pst
x (t), since
%
x′
k+
xx′(t)pst
x′(t) =
%
x′
kx′x(t)pst
x (t) =
%
x′
kxx′(t)pst
x′(t) =
%
x′
k+
x′x(t)pst
x (t).
(4.72)
The conjugate dynamics permits us to express both the adiabatic and the nonadiabatic
entropy production as ratios of trajectory probabilities. Following similar steps as in
section 4.1, we ﬁnd
sa(x) = kB ln Px(λ)
P+
x (λ);
(4.73)

84
Chapter 4
sna(x) = kB ln Px(λ)
P+
"x ("λ)
.
(4.74)
From these expressions, integral ﬂuctuation relations for both sa and sna directly follow:
,
e−sa/kB
-
F = 1;
(4.75)
,
e−sna/kB
-
F = 1.
(4.76)
These relations imply that both the adiabatic and nonadiabatic contributions to the total
average entropy production must be nonnegative. As we discussed before, for a system
initially prepared in a steady state, eq. (4.76) can be written as
=
exp
)
−1
kB
+ tf
t0
dt dλ(t)
dt
∂λsst
x(t)(λ(t))
*>
F
= 1.
(4.77)
Equation (4.77) is the Hatano-Sasa relation. This relation is the starting point for
generalizations of ﬂuctuation-dissipation relations to nonequilibrium steady states.
4.10
Systems with odd-parity variables
We have assumed so far that the mesoscopic degrees of freedom identiﬁed by the
variable x are lef invariant under time reversal. Examples of such mesostates are the
position of a particle or the bound-unbound state of an enzyme. Some degrees of
freedom of interest in physics behave diﬀerently under time reversal. For example,
velocities, linear momenta, and magnetic momenta change sign under time reversal. In
the case of magnetic momenta, this sign change is justiﬁed by the Ampère principle,
i.e., the fundamental idea in electromagnetism stating that magnetic ﬁelds originate
from electric currents. Since electric currents change sign under time reversal, so do
their associated magnetic ﬁelds.
We call degrees of freedom such as position even under time reversal and degrees
of freedom such as momenta odd under time reversal. In general, we may consider
systems characterized by both even and odd degrees of freedom. We denote by ˜x the
state obtained by time-reversing a degree of freedom x. With this notation, a degree of
freedom that is even under time reversal satisﬁes ˜x = x, whereas a degree of freedom
that is odd under time reversal satisﬁes ˜x = −x. In general, one can encounter both types
of degrees of freedom in the same system. For example, a system could have mesostates
x identiﬁed by two discrete variables: a variable y being even under time reversal and
a variable z being odd. This means that if x = (y, z), then ˜x = (y, −z). It is important
to understand how to express the entropy production in these cases and to verify that
ﬂuctuation relations hold.
Systems with degrees of freedom of diﬀerent parity under time reversal give us a
chance to discuss a subtle aspect of the detailed balance condition
kxx′pst
x′ = kx′xpst
x .
(4.78)
Equation (4.78) ensures that all probability currents vanish in the stationary state
(see, e.g., section 2.6). The lef- and right-hand sides of eq. (4.78) can be respectively

Fluctuation Relations
85
interpreted as the rates by which jumps from x′ to x or from x to x′ take place. These rates
are equal if detailed balance holds. If the states x and x′ are even under time reversal,
the two jumps are time-reversed images of each other. Equation (4.78) then embod-
ies a fundamental condition for thermodynamic equilibrium: the lack of any statistical
asymmetry under time reversal.
The situation is diﬀerent if some degrees of freedom are not even under time reversal.
In this case, the balance condition for jump rates under time reversal becomes
kxx′pst
x′ = k˜x′˜xpst
˜x .
(4.79)
In these situations, we refer to eq. (4.78) as the mathematical detailed balance condition
and to eq. (4.79) as the physical detailed balance condition. If states are even under time
reversal, these two conditions are identical. They are also identical under the milder
symmetry condition
kxx′ = k˜x˜x′,
(4.80)
for all pairs x and x′, since this condition also ensures that pst
x = pst
˜x for all x. In systems
with degrees of freedom of diﬀerent symmetry under time reversal, the mathematical
and physical detailed balance conditions are not equivalent. It follows from our discus-
sion that thermodynamic equilibrium requires the physical detailed balance condition
to be satisﬁed, whereas the mathematical detailed balance condition might not hold.
This means that even in an equilibrium state, nonvanishing probability currents may
exist. Such probability currents are called dissipationless.
We now consider the irreversibility of trajectories kB ln Px(λ)/P!x("λ) for such a sys-
tem. In this case, the expression of the backward trajectory must take into account the
behavior of states under time reversal. This means that Eq. (4.4) must be generalized to
"x(t) = ˜x("t).
(4.81)
When evaluating the ratio of the probability of a trajectory and that of its time-
reversed image, the contributions from dwells do not necessarily cancel out in the
presence of odd-parity variables. Indeed, from the explicit expressions of the trajectory
probabilities, we obtain
kB ln Px(λ)
P!x("λ)
= &ssys + kB
n
%
j=1
ln
kxjxj−1
k˜xj−1˜xj
−kB
n+1
%
j=1
+ tj
tj−1
dt (kout
xj−1 −kout
˜xj−1),
(4.82)
where the last term represents the contribution of the dwells.
If the symmetry condition expressed in eq. (4.80) is satisﬁed, then the irreversibility
of trajectories can be interpreted as the total entropy production stot. Indeed, under
these assumptions the second term on the right-hand side of eq. (4.82) is equal to sres,
whereas the third term vanishes.
In this case, entropy production satisﬁes an integral ﬂuctuation theorem,
,
e−stot/kB
-
= 1.
(4.83)
A corresponding detailed ﬂuctuation theorem holds under additional assumptions, as
discussed in sections 4.5 and 4.6.

86
Chapter 4
4.11
Trajectory probability for Langevin equations (*)
In the following sections, we derive ﬂuctuation relations for systems described by
Langevin equations. Our ﬁrst step is to express the probability density P(x) of a
trajectory x generated by a Langevin equation,
dx
dt = µPF(x, t) +
√
2D ξ(t);
(4.84)
see also section 3.13. We consider as usual a time interval [t0, tf] and denote by x0 and
xf the initial and ﬁnal states. We approximate the trajectory by discretizing the interval
in N intervals as in section 2.7:
P(x|x0) ≈
N
#
ℓ=1
p(xℓ; tℓ−1 + &t|xℓ−1; tℓ−1),
(4.85)
where xN = xf. At variance with eq. (2.87), here the conditional probabilities are den-
sities, i.e., p(xℓ; tℓ−1 + &t|xℓ−1; tℓ−1) dx is the conditional probability that x at time
tℓ−1 + &t falls between xℓand xℓ+ dx, given that it is at xℓ−1 at time tℓ−1.
To evaluate p(xℓ, tℓ|xℓ−1, tℓ−1), we suppose that the time interval &t is so short that
we can approximate the increment &xℓ= xℓ−xℓ−1 by a term proportional to &t and a
random contribution due to the noise. The latter term is proportional to the increment
&Wℓof the Wiener process during the time interval [tℓ−1, tℓ]. We therefore set
&xℓ≈µPF(xℓ−1, tℓ−1) &t +
√
2D &Wℓ.
(4.86)
Since &Wℓis a Gaussian random variable with vanishing average and variance equal
to &t, we obtain
p(xℓ, tℓ|xℓ−1, tℓ−1) ≈
1
√
4π D &t
exp
)
−(xℓ−xℓ−1 −µPF(xℓ−1, tℓ−1) &t)2
4 D &t
*
.
(4.87)
Substituting this result into (4.85) leads to
P(x|x0) ≈
N
#
ℓ=1
?
1
√
4π D &t
exp
)
−(xℓ−xℓ−1 −µPF(xℓ−1, tℓ−1) &t)2
4 D &t
*@
.
(4.88)
Formally, in the limit &t →0, the expression of the probability density becomes
P(x; λ) = exp [−S(x, λ)] p(x0, t0),
(4.89)
where the action S(x; λ) is deﬁned by
S(x; λ) =
+ tf
t0
dt 1
4D
)dx(t)
dt
−µP F(x(t), λ(t))
*2
.
(4.90)
The expression of the action, eq. (4.90), implicitly contains stochastic quantities whose
integral requires an interpretation, i.e., an explicit discretization rule. In our case, the

Fluctuation Relations
87
discretization in eq. (4.88) implies that we evaluate F(x, t) at the initial point of each
interval. This means that the stochastic integrals appearing in the action must be
interpreted according to the Ito calculus.
We formally deﬁne the trajectory measure by
Dx = lim
&t→0
N
#
ℓ=1
dxℓ−1
√
4π D &t
· dxf.
(4.91)
This expression allows us to explicitly express averages over trajectories.
4.12
Fluctuation relation for the Langevin equation (*)
In this section, we derive ﬂuctuation relations for Langevin equations. Our ﬁrst step
is to verify that the relation (4.12) linking entropy production and the probability of
forward and backward trajectories also holds for Langevin equations.
We consider a trajectory x generated by the Langevin equation (4.84). The probabil-
ity density of x is given by eq. (4.89). We introduce the backward trajectory "x and the
backward protocol"λ as in section 4.1. We now discretize the backward dynamics. The
initial time of the ℓ-th interval of the backward trajectory, tℓ, corresponds to the ﬁnal
time of the same interval for the forward trajectory. Thus, following the same logic of
section 4.11, we obtain
&xℓ≈−µPF(xℓ, tℓ) &t +
√
2D &Wℓ,
(4.92)
where &Wℓis the increment of the Wiener process over a time interval of duration &t.
Then the probability of the backward trajectory is given by
P("x;"λ) = exp
;
−S("x,"λ)
<
p(xf, tf),
(4.93)
where the action of the backward trajectory is
S("x;"λ) =
+ tf
t0
dt 1
4D
)d"x(t)
dt
−µP F("x(t),"λ(t))
*2
=
+ tf
t0
dt 1
4D
)
−dx
dt
8888
t="t
−µP F(x("t), λ("t))
*2
=
+ tf
t0
dt 1
4D
)dx(t)
dt
+ µP F(x(t), λ(t))
*2
.
(4.94)
Here the discretization must take into account eq. (4.92), i.e., F(x, t) is evaluated at the
end of each time interval. Since this discretization is the opposite of the Ito discretiza-
tion, we call it an anti-Ito convention. The measures of the backward and forward
trajectories are equal, i.e., D"x = Dx; see eq. (4.91). We now evaluate the ratio between
the probability of the forward and of the backward trajectories:

88
Chapter 4
P(x; λ)
P(!x;"λ)
=p(x0, t0)
p(xf, tf) exp
;
−S(x, λ) + S("x,"λ)
<
=
= exp
)&ssys
kB
−S(x, λ) + S("x,"λ)
*
.
(4.95)
The diﬀerence between the actions of a forward trajectory and its backward counter-
part is
S(x; λ) −S("x;"λ) =
+ tf
t0
dt 1
4D
A)dx(t)
dt
−µP F(x(t), λ(t))
*2
−
)dx(t)
dt
+ µP F(x(t), λ(t))
*2B
= −1
kBT
+ tf
t0
dt dx(t)
dt
◦F(x(t), λ(t)),
(4.96)
where we use the Einstein relation (3.84). The integral appearing in eq. (4.96) is inter-
preted in the Stratonovich sense. The intuitive reason is that it is obtained as the average
of one integral interpreted with the Ito convention and one interpreted with the anti-Ito
convention. This result is more carefully derived in appendix A.10. Using the deﬁnition
of heat for a Langevin equation, eq. (3.88), we obtain
−dt dx(t)
dt
◦F(x(t), λ(t)) = −dx ◦F(x(t), λ(t)) = −dq.
(4.97)
We therefore have
S(x; λ) −S("x;"λ) = −1
kBT
+ tf
t0
dq = −sres
kB
,
(4.98)
where sres is the entropy change of the reservoir. Substituting this result into eq. (4.95),
we obtain the irreversibility relation
P(x; λ)
P("x;"λ)
= estot(x;λ)/kB.
(4.99)
All ﬂuctuation relations we derived from master equations can be derived for Langevin
equations from the irreversibility relation (4.99) following the same steps. In this case
too, when the initial distribution is the equilibrium one, we have for any trajectory
T stot(x) = w(x) −&F,
(4.100)
where &F = F(λf) −F(λ0). Using this relation, we can directly obtain the Jarzynski and
Crooks equalities for Langevin equations.

Fluctuation Relations
89
4.13
Brownian particle in a time-dependent harmonic potential (*)
As an illustration, we evaluate the work distribution for a particle undergoing Brow-
nian motion in a manipulated harmonic potential. The position of the particle evolves
according to a Langevin equation (3.82), where the driving is absent and the potential is
U(x, λ) = 1
2λ x2.
(4.101)
We assume that the Einstein relation (3.84) holds. Since the Langevin equation with this
potential is linear in x, its solution at time t, with a given initial condition, is a linear
functional of the Wiener process, which is Gaussian. Therefore, if the initial distribu-
tion of x is Gaussian, it will remain Gaussian at all later times; see also appendix A.4.
Moreover, if ⟨x⟩vanishes at the initial time, it will vanish by symmetry at any later time.
We look therefore for a time-dependent distribution of the form
p(x; t, λ) =
1
√2πγ (t) exp
9
−x2
2γ (t)
:
.
(4.102)
The distribution satisﬁes the Fokker-Planck equation
∂p
∂t = µP
∂
∂x
)
λ(t)x p + kBT ∂p
∂x
*
.
(4.103)
We obtain a simpler equation by introducing the generating function:
φ(q, t) =
+
dx eqx p(x, t).
(4.104)
Properties of generating functions are discussed in appendix A.4. Given the generating
function φ(q, t) of the variable x, the average ⟨x⟩t and variance σ 2(t) =
.
x2/
t −⟨x⟩2
t of x
are respectively given by
⟨x⟩t = ∂φ(q, t)
∂q
8888
q=0
;
σ 2(t) = ∂2 ln φ(q, t)
∂q2
8888
q=0
.
(4.105)
Multiplying both sizes of eq. (4.103) by eqx and integrating, we obtain an evolution
equation for the generating function:
∂φ
∂t = µP
)
−λ(t) q∂φ
∂q + kBTq2 φ
*
.
(4.106)
If p(x; t) is given by (4.102), then φ(q, t) is given by
φ(q, t) = eγ (t) q2/2.
(4.107)
Substituting in (4.106), we obtain an equation for γ (t):
dγ
dt = 2µP [−λ(t) γ (t) + kBT] .
(4.108)

90
Chapter 4
This is a linear equation that can be analytically solved. We do not however need its
solution. To obtain the ﬂuctuation relation, we consider the work w accumulated up to
time t:
w(t) =
+ t
t0
dt′ dλ(t′)
dt′
∂U
∂λ
8888
λ=λ(t′),x=x(t′)
.
(4.109)
The joint probability distribution p(x, w; t, λ) of x and w satisﬁes the evolution equation
∂
∂tp(x, w; t, λ) = µP
∂
∂x
)
λ(t)x p + kBT ∂p
∂x
*
−˙λ(t) ∂U
∂λ
8888
λ=λ(t),x=x(t)
∂p
∂w
= µP
∂
∂x
)
λ(t)x p + kBT ∂p
∂x
*
−1
2
dλ(t)
dt
x2 ∂p
∂w.
(4.110)
The corresponding generating function is
φ(x,w)(q1, q2, t) =
+
dx dw eq1x+q2w p(x, w; t, λ)
(4.111)
and satisﬁes the equation
∂φ(x,w)
∂t
= µP
$
−λ(t) q1
∂φ(x,w)
∂q1
+ kBTq2
1 φ(x,w)
(
+ 1
2
dλ(t)
dt
q2
∂2φ(x,w)
∂q2
1
.
(4.112)
This equation also admits a Gaussian solution of the form
φ(x,w)(q1, q2, t) = eα(q2,t)+γ (q2,t)q2
1/2,
(4.113)
where α and γ evolve according to
∂α
∂t = q2
2
dλ(t)
dt
γ (q2, t);
(4.114a)
∂γ
∂t = 2µP
;
−λ(t) γ (q2, t) + kBT
<
+ q2
dλ(t)
dt
γ 2(q2, t).
(4.114b)
Equation (4.114b) is a Riccati equation. It can be analytically solved in some simple
cases, but is easy to solve numerically.
The quantity α(q2, t) is the cumulant generating function of the accumulated work
w (see eq. (A.52)):
α(q2, t) = ln
,
eq2 w(t)-
.
(4.115)
The Jarzynski equality (4.52) implies that
α
9
−1
kBT
:
= ln
,
e−w(t)/kBT-
= −F(λ(t)) −F(λ(t0))
kBT
.
(4.116)

Fluctuation Relations
91
−1
0
1
2
q2
−1
0
1
2
3
α(q2, T )
T = 1
T = 2
T = 4
T = 8
−1
0
−0.02
0.00
0.02
Figure 4.5. Cumulant generating function α(q2, T ) of the work performed on the system
for the linear protocol (4.120) starting from equilibrium, plotted as a function of q2 (in
units of (kBT)−1). We set λ0 = 1, λ1 = 5 (in units of kBT), and different values of T (in units
of µ−1
P ). The cumulant generating function diverges at positive ﬁnite values of q2, which
depends on T . The curves cross at q2 = 0 by normalization, and at q2 = −1/kBT due to
the Jarzynski equality. This is highlighted in the inset, where α(q2, T ) −q2 &F is plotted
against q2. See Speck [158].
Indeed, one can verify that if q2 = −1/kBT, eqs. (4.114a and b) admit the solution
γ (t) = kBT
λ(t),
t0 ≤t ≤tf,
(4.117)
with
α(t) = −1
2 ln λ(t)
λ(t0) = −&F(t)
kBT .
(4.118)
Here &F = F(λ(t)) −F(λ(t0)), where the free energy is
F(λ) = −kBT ln
+
dx e−λx2/2kBT = −kBT
2 ln 2πkBT
λ
.
(4.119)
Numerical solution of eqs. (4.114a and b) yields the cumulant generating function
α(q2, tf) of the work performed on the system during the manipulation. Figure 4.5
shows the cumulant generating function of the work for a linear protocol,
λ(t) = λ0 + (λf −λ0) t
T ,
0 ≤t ≤T ,
(4.120)
with λ0 = 1 and λf = 5 (in units of kBT), and for diﬀerent values of T (in units of µ−1
P ).
The curves are visibly nonparabolic, which means that the distribution of w is not Gaus-
sian. All curves cross at q2 = −1 (in units of (kBT)−1) in agreement with the Jarzynski

92
Chapter 4
equality. They also exhibit a divergence for positive values of q2, which is the signature
of the exponential decay of p(w, tf) for large values of w.
4.14
Brownian motion with inertia (*)
If the inertia of a Brownian particle is not negligible, the stochastic equations describ-
ing its motion take a slightly diﬀerent form. A particle of mass m in one dimension
subject to a potential U(r, λ) and to random noise evolves according to a stochastic
version of the Newton equation:
md2r
dt2 = −∂rU(r, λ) −µP
dr
dt +
√
2D ξ(t),
(4.121)
where r is the particle position and µP dr/dt represents the eﬀects of friction. We
recast this equation in terms of the conjugate variables (pr, r), where pr = m dr/dt is
the momentum:
dr
dt = pr
m;
dpr
dt = −∂rU(r, λ) −µP
m pr +
√
2D ξ(t).
(4.122)
By going through the steps leading to the Fokker-Planck equation, we obtain the
evolution equation satisﬁed by the probability density p(pr, r; t):
∂p(pr, r; t)
∂t
= ∂
∂r
0
−pr
m p(pr, r; t)
1
+ ∂
∂pr
)9∂U
∂r + µP
m pr
:
p(pr, r; t) + D∂p(pr, r; t)
∂pr
*
.
(4.123)
This equation is known as the Kramers equation. Provided that the Einstein rela-
tion (3.84) holds, the Kramers equation has the equilibrium solution
peq(p, r) = exp
)F(λ) −H(pr, r; λ)
kBT
*
,
(4.124)
where
H(pr, r; λ) = p2
r
2m + U(r, λ)
(4.125)
is the Hamiltonian and
F(λ) = −kBT ln
+
dpr dr e−H(pr,r,λ)/kBT
(4.126)
is the free energy.
The trajectory probability of the Kramers equation can be derived following the same
reasoning as in section 4.11. In this case too, the trajectory probability can be expressed

Fluctuation Relations
93
in the form of eq. (4.89). For the Kramers equation, the action reads
S(pr, r; λ) =
+ tf
t0
dt 1
4D
)dpr(t)
dt
+ ∂
∂rU(x(t), λ(t)) + µP
m pr(t)
*2
.
(4.127)
We now compare the probability of a trajectory x = (pr, r) of the Kramers equation
to that of its time-reversed image "x. In this case, we have to take into account that the
momenta change sign under time reversal. This is therefore another example in which
the state"x(t) in the time-reversed trajectory is diﬀerent from x("t):
"x = ("pr(t),"r(t)) = (−pr("t), r("t));
(4.128)
see also section 4.10. Taking into account this transformation, the action of the back-
ward trajectory is expressed by
S("
pr,"r;"λ) =
+ tf
t0
dt 1
4D
)dpr(t)
dt
+ ∂rU(x(t), λ(t)) −µP
m pr(t)
*2
.
(4.129)
The ratio between the probability density P(x, λ) and that of its time reverse P("x,"λ)
can be evaluated as in section 4.12, leading to the expression
P(x|x0; λ)
P("x|xf;"λ)
= exp
)
−1
kBT
&S(x; λ) −S("x;"λ)
'*
,
(4.130)
where
S(x; λ) −S("x;"λ) = 1
kBT
+ tf
t0
dt pr(t)
m
9dpr(t)
dt
+ ∂rU(r(t), λ(t))
:
.
(4.131)
In this case, we have
dt pr(t)
m
9dpr(t)
dt
+ ∂rU(r(t), λ(t))
:
= d
9 p2
r
2m
:
+ dU −dλ ∂λU
= dH −dw = −dq,
(4.132)
from which the irreversibility relation (4.12) follows.
Since the states of a system described by the Kramers equation are not even under
time reversal, it is possible to have dissipationless probability currents in the equilibrium
state; see section 4.10. As a simple example, consider a charged Brownian particle in two
dimensions subject to a magnetic ﬁeld ⃗B directed normally to the plane. The Langevin
equation for this system reads
d⃗v
dt = −µP ⃗v + q
m ⃗v × ⃗B +
√
2D ⃗ξ,
(4.133)

94
Chapter 4
where ⃗v = (v1, v2) is the velocity of the particle, m its mass, and q its charge. The
corresponding Kramers equation reads
∂p(⃗v; t)
∂t
= ∂J1
∂v1
+ ∂J2
∂v2
(4.134)
= ∂
∂v1
)2
µPv1 + q
mB v2
3
p + D ∂p
∂v1
*
+ ∂
∂v2
)2
µPv2 −q
mB v1
3
p + D ∂p
∂v2
*
.
The equilibrium distribution is the Maxwell-Boltzmann one, peq(⃗v) ∝e−v2/2mkBT. Sub-
stituting in the above equation, and taking into account the Einstein relation (3.84), we
obtain
J1 = −qB
m v2 peq(⃗v);
J2 = qB
m v1 peq(⃗v).
(4.135)
One can check that the right-hand side of eq. (4.134) indeed vanishes, although the
current ⃗J does not vanish, as anticipated. In this case, eq. (4.13), which states that the
probability densities of a trajectory and its reverse are equal, does not hold. However,
according to the Ampère principle, the Langevin equation satisﬁed by the back-
ward velocity"⃗v in the backward dynamics is given by eq. (4.133), since the sign of ⃗B
must be changed. We have therefore, for any trajectory v = (⃗v(t)),
˙stot(v) = kB ln Pv(⃗B)
P"v(−⃗B)
= 0.
(4.136)
4.15
Hamiltonian systems (*)
For Hamiltonian systems, ﬂuctuation relations like the Jarzynski equality and the
Crooks relation take a very simple form. We identify the state ξ of a Hamiltonian system
by n pairs of momentum pr and coordinate r variables:
ξ = ((pr1, r1), . . . , (prn, rn)) = (pr, r).
(4.137)
The Hamiltonian H(ξ; λ) depends on an external parameter λ. The system is manip-
ulated during the time interval t0 ≤t ≤tf by changing the parameter λ according to
a protocol λ = (λ(t)), such that λ(t0) = λ0 and λ(tf) = λf. During this time interval,
the system is thermally isolated. Therefore, its state changes according to the canonical
equations of motion:
dpri
dt = −∂H
∂ri
,
dri
dt = ∂H
∂pri
,
(4.138)
for i = 1, . . . , n. Prior to the instant t0, the value of λ is constant and the system is in
equilibrium with a reservoir at temperature T. The initial distribution of ξ is therefore

Fluctuation Relations
95
equal to the equilibrium distribution
peq(ξ; λ0) = e(F(λ0)−H(ξ;λ0))/kBT,
(4.139)
where
F(λ) = −kBT ln
+
dξ e−H(ξ;λ)/kBT
(4.140)
is the free energy corresponding to a given value of λ.
Since the equations of motion (4.138) are deterministic, the trajectories ξ = (ξ(t)) in
the time interval t0 ≤t ≤tf are uniquely identiﬁed by the initial condition ξ0 = (ξ(t0)).
We have, on the other hand,
d
dtH(ξ(t); λ(t)) =
n
%
i=1
)dpri
dt
∂H
∂pri
+ dri
dt
∂H
∂ri
*
+ ∂H
∂t
=
n
%
i=1
)
−∂H
∂ri
∂H
∂pri
+ ∂H
∂pri
∂H
∂ri
*
+ ∂H
∂t = dλ
dt
∂H
∂λ .
(4.141)
We obtain therefore, for t0 ≤t ≤tf,
H(ξ(t); λ(t)) = H(ξ0; λ0) +
+ t
t0
dt′ dλ(t′)
dt′
∂
∂λH(ξ(t′); λ(t′)).
(4.142)
Identifying the value of the Hamiltonian with the system energy, the integral appear-
ing on the right-hand side is none other than the manipulated work w(ξ; λ) deﬁned
in eq. (3.9). Since ξ(t), once the protocol λ is given, depends only on ξ0, w can be
considered as a function w(t, ξ0) of the instant t and the initial state ξ0.
We now evaluate
.
e−w(t,ξ0)/kBT/
, where the average is taken over the distribution
(4.139) of the initial condition ξ0. We obtain
,
e−w(t,ξ0)/kBT-
=
+
dξ0 e−w(t,ξ0)/kBT peq(ξ0)
=
+
dξ0 e−(H(ξ(t,ξ0);λ(t))−H(ξ0;λ0))/kBT
× e(F(λ0)−H(ξ0;λ0))/kBT
=
+
dξ0 e(−H(ξ(t,ξ0);λ(t))+F(λ0))/kBT.
(4.143)
We change the variable of integration from the initial state ξ0 to the evolved state ξ(t, ξ0).
According to the Liouville theorem, the volume of the region dξ(t, ξ0) evolved at time t
from a region dξ0 at time t = t0 is equal to the volume of the original region. Therefore,
the determinant of the Jacobian associated with this change of variable is equal to one,
and we obtain
,
e−w(t,ξ0)/kBT-
=
+
dξ e(−H(ξ;λ(t))+F(λ0))/kBT = e(F(λ0)−F(λ(t)))/kBT,
(4.144)

96
Chapter 4
where we use the deﬁnition (4.140) of the free energy. Setting t = tf, we obtain the
Jarzynski equality (4.52). This implies that the average dissipated work
Wdiss = ⟨w(ξ; λ)⟩−&F
(4.145)
is nonnegative.
In this derivation, we neither considered the reverse process nor made an explicit
connection with entropy production. In fact, the dynamics in the time interval from t0
to tf satisﬁes the Liouville theorem and therefore the system entropy does not change.
We now consider a case in which, at the end of the manipulation, the system is again
put in contact with the reservoir. The heat q(ξ; λ) released to this reservoir is equal to
q(ξ; λ) = H(ξf; λf) −⟨H(ξ; λf)⟩eq
= H(ξ0; λ0) + w(tf, ξ0; λ) −(F(λf) + TS(λf))
= (w(tf, ξ0; λ) −&F) + T (s(ξ0) −S(λf)) ,
(4.146)
where &F = F(λf) −F(λ0), ⟨H(ξ; λf)⟩eq is evaluated with the equilibrium distribution
associated with λf, and Sf is the corresponding equilibrium entropy. We have indeed
⟨H(ξ; λf)⟩eq = F(λf) + T Sf.
(4.147)
Thus the total entropy produced along the trajectory ξ is given by
stot(ξ; λ) = q(ξ; λ)
T
+ Sf −s(ξ0) = w(tf, ξ0) −&F
T
.
(4.148)
As we discussed, this entropy is entirely produced at the end of the manipulation
protocol.
We now consider the reverse process. We deﬁne the backward protocol "λ as being
made up of a long initial time interval in which the system is allowed to equilibrate
with the reservoir, with the value λf of the parameter, followed by a manipulation time
interval for t0 ≤t ≤tf and followed again by a long time interval in contact with the
reservoir, with the value λ0 of the parameter. The value"λ(t) of the parameter λ in the
interval t0 ≤t ≤tf is given by
"λ(t) = λ("t),
(4.149)
where"t = tf + t −t0. We focus on the dynamics during the interval t0 ≤t ≤tf. Given
the trajectory ξ, the backward trajectory"ξ is deﬁned by"ξ(t) = ˜ξ("t), where ˜ξ is the time-
reversed image of the phase-space point ξ. If ξ = (pr, r), we have
˜ξ = (−pr, r) = ((−pr1, r1), . . . , (−prn, rn)).
(4.150)
We now compare the probabilities P(ξ; λ) and P("ξ;"λ) of the forward and backward
trajectories in the forward and backward protocols, respectively. As we stressed before,
the probability of a trajectory ξ is equal to the probability of its initial condition ξ0. It
follows that
P(ξ; λ)
P("ξ;"λ)
= peq(ξ0; λ0)
peq(˜ξf; λf)
.
(4.151)

Fluctuation Relations
97
Assuming that the Hamiltonian H(ξ; λ) is time-reversal invariant, i.e, that H(˜ξ; λ) =
H(ξ; λ), ∀λ, we obtain
P(ξ; λ)
P("ξ;"λ)
= e(F(λ0)−F(λf)−(H(ξ0;λ0)−H(ξf;λf)))/kBT
= e−(w(ξ;λ)−&F)/kBT = e−stot(ξ;λ)/kB.
(4.152)
Since the initial and ﬁnal states are equilibrium states, we have
w("ξ;"λ) = −w(ξ; λ).
(4.153)
Thus, summing over all trajectories ξ with a given value w of the work, we obtain the
Crooks relation (4.53) in the form
p(w; λ)
p(−w;"λ)
= e−(w−&F)/kBT.
(4.154)
The Jarzynski equality follows by integrating over w.
We use this result to relate the average dissipated work deﬁned in eq. (4.145) and the
Kullback-Leibler divergence between the phase-space distributions in the forward and
in the reverse process. To this aim, we express both the forward and the reverse process
in terms of the forward time, so that corresponding points in the time axis have the
same value of λ (ﬁg. 4.6). Using the Liouville theorem, eq. (4.151) assumes the form
p(ξf, tf; λ)
p(˜ξf, tf;"λ)
= e(w(ξ;λ)−&F)/kBT.
(4.155)
Taking the logarithm, we obtain
w(ξ; λ) = &F + kBT ln p(ξf, tf; λ)
p(˜ξf, tf;"λ)
.
(4.156)
Upon averaging, we express the average work W = ⟨w(ξ; λ)⟩performed on the sys-
tem as
W = &F + kBT
+
dξf p(ξf; λ) ln p(ξf, tf; λ)
p(˜ξf, tf;"λ)
= &F + kBT DKL
2
p(ξf, tf; λ)∥p(˜ξf, tf;"λ)
3
.
(4.157)
For any value of t satisfying t0 ≤t ≤tf and for any point ξ in phase space, we have
p(ξ, t; λ)
p(˜ξ, t;"λ)
= p(ξf, tf; λ)
p(˜ξf, tf;"λ)
,
t0 ≤t ≤tf,
(4.158)
because"ξ is the unique trajectory going through ˜ξ at time t under the backward protocol
"λ if the trajectory ξ goes through ξ at time t by the protocol λ. This implies that we can

98
Chapter 4
˜ξ0
t
t0
tf
ξ
ξf
˜ξf
˜ξ
ξ0
Figure 4.6. Scheme of the correspondence between the forward trajectory ξ under the
forward protocol λ and its time-reversed image "ξ under the backward protocol "λ. The
trajectory ξ starts from x0 at time t0, goes through ξ at time t, and ends at ξf at time tf.
The backward trajectory is parameterized in terms of "t rather than t. It starts at ˜ξf at tf,
goes through ˜ξ at time t, and ends at ˜ξ0 at time t0. See Kawai et al. [86].
evaluate the Kullback-Leibler divergence at any instant in time in the interval [t0, tf],
obtaining the same result. This property is peculiar to Hamiltonian systems.
We now consider a mesoscopic system coupled to a thermal reservoir and assume
that the system plus the reservoir are thermally isolated and evolve according to Hamil-
tonian dynamics. In these settings, the stochastic dynamics of the mesoscopic system
originates from coarse graining, i.e., from integrating out the degrees of freedom of
the thermal reservoir. It is interesting to study how eq. (4.157) is aﬀected by such a
coarse-graining operation. Speciﬁcally, we partition the phase space of a Hamiltonian
system into regions 0x and we assign each such region 0x to a mesostate x. We then
use eq. (4.155) to evaluate the average of e−w(ξ;λ)/kBT over each of these regions:
,
e−w(ξ;λ)/kBT-
x =
1
px(t; λ)
+
0x
dξ p(ξ, t; λ) e−w(ξ;λ)/kBT,
(4.159)
where px(t; λ) is the probability that, at time t, the microstate ξ(t) of the system belongs
to the region 0x:
px(t; λ) =
+
0x
dξ p(ξ, t; λ).
(4.160)
We then have, by eq. (4.155),
,
e−w(ξ;λ)/kBT-
x = px(t;"λ)
px(t; λ) e−&F/kBT.
(4.161)

Fluctuation Relations
99
By the Jensen inequality, this relation implies
⟨w(ξ; λ)⟩x ≥&F + kBT ln px(t; λ)
px(t;"λ)
.
(4.162)
Applying the same reasoning to w("ξ;"λ), we obtain
,
w("ξ;"λ)
-
x ≥−&F −kBT ln px(t; λ)
px(t;"λ)
.
(4.163)
Taking the averages, we obtain the following inequalities for the average work WF and
WB respectively performed in the forward and reverse processes, for t0 ≤t ≤tf:
WF ≥&F + kBT DKL(px(t; λ)∥px(t;"λ));
(4.164)
WB ≥−&F + kBT DKL(px(t;"λ)∥px(t; λ)).
(4.165)
For stochastic systems, the Kullback-Leibler divergence in general depends on t. These
results can also be directly obtained from the equality (4.157) by observing that the
Kullback-Leibler divergence cannot increase upon coarse graining; see section 2.10.
We illustrate these results by evaluating the dissipated work and the probability
distributions for the overdamped harmonic oscillator discussed in section 4.13. The
distribution p(x, t; λ) satisﬁes the Fokker-Planck equation
∂p
∂t = µP
∂
∂x
)
λ(t)x p + kBT ∂p
∂x
*
,
(4.166)
where µP is the friction coeﬃcient. In our case, if the initial distribution is Gaussian, it
remains Gaussian at all later times. We have found in section 4.13 that the mean of the
Gaussian vanishes at all times if it does so initially, and that its variance γ (t) satisﬁes
the equation
dγ
dt = 2µP [−λ(t) γ (t) + kBT] .
(4.167)
The free energy diﬀerence &F is given by
&F = kBT
2 ln λf
λ0
,
(4.168)
which is obtained by direct integration.
If p(x, γ ) is a Gaussian distribution with vanishing mean and variance equal to γ ,
we have
DKL(p(x, γ )∥p(x, "γ )) = 1
2
9γ
"γ −1 + ln "γ
γ
:
.
(4.169)
The average accumulated work up to time t satisﬁes the equation
dW(t)
dt
= 1
2
dλ(t)
dt
.
x2/
t = 1
2
dλ(t)
dt
γ (t),
(4.170)

100
Chapter 4
10−3
10−2
10−1
100
101
102
T
0.00
0.05
0.10
0.15
0.20
Wdiss
quenched limit
exact
bound
coarse grained
Figure 4.7. Dissipated work W diss = ⟨w⟩−&F as a function of the duration T = tf −t0
of the manipulation for the overdamped harmonic oscillator linearly manipulated from
λ0 = 3 to λf = 1. Units are such that µP = 1 and kBT = 1. The quenched limit is given by
eq. (4.171). We also show the bound obtained from eq. (4.164) by evaluating p(x, t; λ) and
p(x, t;"λ) for t = T /2. The weaker bound is obtained by convoluting the distribution with
a Gaussian of width σ 2 = 1/12, which is equal to the variance of a uniform distribution
over an interval of length &x = 1. See Kawai et al. [86].
where γ (t) is the solution of eq. (4.167). We can therefore solve the system of equa-
tions (4.167, 4.170) and obtain the dissipated work Wdiss and the variances γ (t), "γ (t),
respectively associated with the forward and backward protocols. In this way, we obtain
Wdiss as a function of the manipulation duration T , as shown in ﬁg. 4.7. For T →0+,
the dissipated work tends to the quenched limit, given by
Wquench =
+
dx (H(x; λf) −H(x; λ0)) peq(x; λ0) = 1
2 (λf −λ0)
.
x2/eq
λ0
= kBT
2
9 λf
λ0
−1
:
.
(4.171)
For all values of T , the dissipated work is larger than the bound obtained from
eq. (4.164) by evaluating p(x, t; λ) and p(x, t;"λ) for t = T /2, and also larger than a
weaker bound obtained by coarse-graining the distributions p(x, t; λ) and p(x, t;"λ)
with a procedure that approximates averaging over an interval of length &x = 1;
see ﬁg. 4.7.
4.16
Further reading
There exists a vast literature on ﬂuctuation relations. Indeed, diﬀerent forms of these
relations hold when the observables of interest, the dynamics obeyed by the system, or
the underlying hypotheses are diﬀerent. Evans, Cohen, and Morriss [51] proposed an

Fluctuation Relations
101
early ﬂuctuation relation for the shear stress in a nonequilibrium system in contact with
a thermostat. Gallavotti and Cohen [56, 57] derived a detailed ﬂuctuation relation for
the entropy production rate in deterministic chaotic systems. Their work has been so
inﬂuential that the symmetry implied by the detailed ﬂuctuation relation (see eq. (4.46))
is ofen referred to as the Gallavotti-Cohen symmetry. Onsager [121, 122] derived the
reciprocity relations.
Jarzynski [81] and Crooks [33, 34] developed ﬂuctuation relations for systems
manipulated from an equilibrium state to another equilibrium state. Their work paved
the way for the use of nonequilibrium measurements to estimate equilibrium free-
energy diﬀerences and therefore had an enormous impact. Their success led to the
rediscovery of works by Bochkov and Kuzovlev [19, 20, 21, 22] that pioneered simi-
lar ﬂuctuation relations, although with a diﬀerent deﬁnition of work, as discussed by
Jarzynski [82].
In parallel, Kurchan [92] showed that, for long times and in the steady state, the
entropy production of a general system of Langevin equation satisﬁes the Gallavotti-
Cohen symmetry. Lebowitz and Spohn [98] extended this result to a general Markovian
dynamics. Seifert [148] clariﬁed that, for Langevin dynamics, the integral ﬂuctuation
relation also holds for ﬁnite times and time-dependent drivings. Oono and Pani-
coni [123] introduced the concept of housekeeping heat in non-equilibrium steady
states.
We have seen that ﬂuctuation relations emerge rather naturally when relating
entropy production to the ratio of probabilities of forward and backward trajectories.
Although this idea was implicitly present in some of the early derivations, Maes [106]
points out this aspect more explicitly. This very powerful concept extends to many other
ﬂuctuation relations, as reviewed by Harris and Schütz [73] and Gawedzki [61]. The dis-
cussion in section 4.9 follows the lines of Esposito and Van den Broeck [50], and the
relation (4.77) is derived in Hatano and Sasa [75]. Decomposition of the entropy pro-
duction for systems with odd-parity variables is discussed in Spinney and Ford [159]
and Lee et al. [100]. Verley and Lacoste [173, 174] review its application to ﬂuctuation-
dissipation relations out of equilibrium. Cuetara et al. [36] derive a quite general version
of the ﬂuctuation relation. Rao and Esposito [137] provide a uniﬁed perspective on
many ﬂuctuation theorems derived in the literature. A pedagogical introduction to
ensemble and trajectory thermodynamics and to ﬂuctuation relations is due to Van den
Broeck and Esposito [170].
The example of the Brownian particle in a time-dependent harmonic potential is
discussed by Speck [158]. The relation between dissipated work and the divergence of
phase-space distributions is pointed out by Kawai et al. [86].
4.17
Exercises
4.1
Assuming that the distribution of stot is Gaussian, prove eq. (4.17).
4.2
Consider the dragged particle introduced in section 4.3. Show that the prob-
ability distribution of the total entropy stot produced in a time interval (t0, tf)
satisﬁes the detailed ﬂuctuation theorem.
4.3
A particle with mobility µP is immersed in a ﬂuid at temperature T, and it is
subject to a constant force f along the x-axis for a time interval of duration T .
Show that the Jarzynski equality implies that the Einstein relation between the
mobility and the diﬀusion coeﬃcient D is satisﬁed.

102
Chapter 4
4.4
Consider a gas made of a single molecule contained in a cylinder with adia-
batic walls with a movable piston. The molecule is initially at equilibrium at
temperature T in a volume V0. The piston is then moved with constant speed
v until the volume of the gas is V. Show explicitly the validity of the Jarzynski
equality in the case V > V0 and very large speed v. Assume that V −V0 ≪V0.
4.5
Imagine that you are shown a movie of a mesoscopic system undergoing
manipulation while in contact with a reservoir at temperature T. The movie
can be either the record of the forward (F) process, in which the system is
manipulated out of an initial equilibrium state, or the record of the backward
(B) process, projected in reverse order. Show that, to assess the probability that
the movie shows the F process, it is suﬃcient to evaluate the dissipated work
w −&F, where the work w is computed from the trajectory exhibited in the
movie. Evaluate the probability pF|w as a function of w.
4.6
By exploiting eq. (A.20), show that the average nonadiabatic entropy produc-
tion rate is nonnegative at all times.
4.7
Consider a system obeying a master equation satisfying the generalized
detailed balance condition (3.7). By exploiting eq. (A.20), show that the mini-
mal rate of entropy production needed to keep the system in a nonequilibrium
steady state pst
x is given by
˙Smin = −kBT d
dtDKL(p(t)∥peq)
8888
p=pst ,
where the derivative is evaluated with the master equation that is obtained
by setting all the drivings δxx′ to zero, and where peq
x is the corresponding
equilibrium distribution.
4.8
The position of a Brownian particle evolves according to the Langevin equa-
tion (3.82) with the potential (4.101). Evaluate the probability density pF(w)
of the work when the potential strength λ is suddenly changed from λ0 to λf,
assuming that the particle is initially in thermal equilibrium. Evaluate also
the corresponding distribution pR(w) for the reverse process, assuming that
the particle is initially at equilibrium with the strength λf. Verify the detailed
ﬂuctuation relation
pF(w)
pB(−w) = e(&F−w)/kBT,
where &F = F(λf) −F(λ0). Show that the distributions exhibit exponential
tails.
4.9
Consider eq. (4.110) in the slow manipulation regime described by equa-
tion (4.120), with T ≫1−1. Obtain the equation satisﬁed by γ1(p, t) and σ 2
w(t)
and verify the relation (4.118).

Fluctuation Relations
103
4.10
Consider a weakly interacting, dilute gas contained in a cylinder with a
piston, initially at equilibrium at temperature T. The system undergoes an adi-
abatic quasi-static transformation in which its volume is changed from V0 to
Vf. Assuming that the gas is able to equilibrate with itself during the transfor-
mation, verify the Jarzynski equality for this system. Optionally, evaluate the
probability distribution of the work performed during the transformation and
show that it satisﬁes the Jarzynski equality.

CHAPTER 5
Thermodynamics of Information
Maxwell, then Boltzmann and Gibbs, already hinted at a connection between thermo-
dynamics and information. They emphasized the statistical nature of the second law
long before the birth of information theory. Despite this long history, thermodynamics
of information still puzzles physicists. Stochastic thermodynamics places information
in the context of concrete physical models, dramatically easing the study of its role in
thermodynamics.
5.1
A brief history
In his Theory of Heat (1871), Maxwell illustrated the statistical nature of the second
principle by a very famous argument:
We now suppose that such a vessel is divided into two portions, A and B, by a
division in which there is a small hole, and that a being, who can see the individual
molecules, opens and closes this hole, so as to allow only the swifer molecules to
pass from A to B, and only the slower molecules to pass from B to A. He will thus,
without expenditure of work, raise the temperature of B and lower that of A, in
contradiction to the second law of thermodynamics.
Thus a “demon” able to determine the energy of a single molecule could use this infor-
mation to reduce the entropy of the vessel, driving it away from equilibrium. It would
then in principle be possible to extract work from this disequilibrium.
Szilard proposed an intriguing conceptual experiment that made the connection be-
tween the second law and information even sharper (ﬁg. 5.1). He considered a closed
cylindrical container of volume V, in contact with a heat reservoir at temperature T,
which contains an ideal gas made of a single molecule. The molecule is initially free
to wander in the whole cylinder. An agent divides the cylinder into two equal cham-
bers of volumes V/2 by inserting a piston in its middle. The agent then observes if the
molecule is in the lef or right chamber. If the particle is in the lef chamber, the agent
slowly moves the piston to the right, until it reaches the end of the cylinder. During this
process, the molecule keeps bouncing on the piston, yielding work given by the expres-
sion for an isothermal expansion, −W = kBT ln 2. If the particle is in the right chamber,
the agent moves the piston to the lef until it reaches the end of the cylinder, extract-
ing the same amount of work. Afer the expansion, the piston is removed, the cylinder
returns to the initial state, and the cycle is repeated.

Thermodynamics of Information
105
(h)
(b)
(c)
(d)
(a)
(e)
(f)
(g)
Figure 5.1. The Szilard thought experiment. A cylindrical container containing a single
molecule (a) is divided in two parts by a movable wall. An agent identiﬁes whether the
particle is on the left or right of the wall. If it is on the left (b) the agent slowly moves
the wall to the right (c) until it reaches the end of the container (d). In like manner, if the
particle is on the right (e), the wall is slowly moved to the left (f, g). This procedure allows
the agent to extract work equal to kBT ln 2 from the heat reservoir. At the end (h), the
position of the particle is unknown and the system is back in its initial state.
This procedure can be generalized to a case where the piston divides the cylinder
into two unequal chambers. In this case, the agent extracts from the reservoir an average
work per cycle given by
−W = kBT H(p).
(5.1)
Here H(p) = −(VL/V) ln(VL/V) −(1 −VL/V) ln(1 −VL/V) is the Shannon entropy
of the particle distribution in the two chambers, where VL is the volume of the lef
chamber. This expression already suggests a correspondence between the information
about the location of the particle and the maximum possible work extraction. This idea
was generalized by Bennett and popularized by Feynman. They considered machines
extracting work from a reservoir by exploiting very long sequences of microscopic
containers, each containing a single molecule in a known lef or right location (ﬁg. 5.2).

106
Chapter 5
1
1
1
1 1
1
1 1 1 1 1 1 1 1 1 1 1
0 0
0 0 0
exhaust
fuel
kg
Figure 5.2. The Bennett-Feynman information-fueled engine. A tape (fuel) containing a
large number of Szilard cylinders, each with the molecule in state 1 (right), is fed into the
machine. Once inside, each cylinder undergoes the Szilard manipulation, and an average
amount of work −W = kBT ln 2 is extracted. At the end of the manipulation, the location
of the molecule in the cylinder is randomized (exhaust). See the discussion in Feynman
[53, pp. 146–147].
How can we reconcile this result with the second law of thermodynamics? The Kelvin
statement of the second law of thermodynamics forbids cyclic work extraction from a
single heat reservoir, as pointed out in section 2.1. Yet the Szilard engine appears to
accomplish exactly this feat. The solution to this dilemma followed a rather wandering
path. Szilard himself suggested that the demon could be exorcised if the measurement of
the particle’s position required dissipation. Brillouin made the argument more explicit
by considering detailed measurement protocols. However, Bennett argued that a dissi-
pationless measurement could be performed provided the measuring apparatus was in
a “standard state” before the measurement.
The discussion can be made more concrete by replacing the demon with a mechani-
cal device taking actions depending on the measurement outcome. Importantly, this
device should necessarily store the measurement outcome in a physical memory, at
least for a short time. In this framework, Landauer pointed out the necessity of spend-
ing work to cyclically erase this memory. In the context of the thermodynamics of
computation, Bennett generalized it in the following way:
Any logically irreversible manipulation of information, such as the erasure of a
bit or the merging of two computation paths, must be accompanied by a corre-
sponding entropy increase in noninformation bearing degrees of freedom of the
information-processing apparatus or its environment.
This statement is referred to as the Landauer principle. Quantitatively, the Landauer
principle requires the expenditure of at least kBT ln 2 of work for erasing 1 bit, a quantity
known as the Landauer bound.
5.2
Back to nonequilibrium free energy
To analyze the Szilard engine with the tools of stochastic thermodynamics, we ﬁrst
need to extend the concept of nonequilibrium free energy introduced in section 2.3. Our
starting point is the Gibbs relation (2.132), which links the thermodynamic entropy and

Thermodynamics of Information
107
information entropy of an ensemble. In classical statistical mechanics, this link is valid
only for macroscopic systems at equilibrium. We do not set this limitation in stochas-
tic thermodynamics, where the system entropy is deﬁned by eq. (3.25) for mesoscopic
systems that are not necessarily at equilibrium. The price to pay for this generality is
to accept an ensemble perspective: the system entropy in stochastic thermodynamics is
deﬁned at the level of a single system, but only as a member of an ensemble prepared
according to a certain probability distribution.
In the ensemble perspective, the probability distribution peq of a system in ther-
mal equilibrium satisﬁes a variational principle. For instance, if ⟨ϵ⟩p = !
x pxϵx is ﬁxed,
then H(peq) ≥H(p), ∀p, where peq is the canonical distribution. Similarly, the Shannon
entropy of a grand canonical distribution cannot be smaller than that of any distribution
with the same values of average energy and average number of particles.
We derive a more general result by considering a system in contact with a reservoir
at temperature T. We assume that the system is initially in a state described by a prob-
ability distribution p over the states, with Shannon entropy H(p). We generalize the
nonequilibrium free energy to this case by setting
Fneq = ⟨ϵ⟩−kBT H(p).
(5.2)
Also this broader deﬁnition reduces to the conventional free energy at equilibrium. For
all probability distributions p, one has
Fneq(p) ≥Fneq(peq) = F.
(5.3)
To prove it, we note that
"Fneq = Fneq(p) −Fneq(peq)
=
"
x
#$
pxϵx −peq
x ϵx
%
+ kBT
$
px ln px −peq
x ln peq
x
%&
=
"
x
px
$
ϵx + kBT ln px −F
%
= kBT
"
x
px ln px
peq
x
= kBTDKL(p∥peq) ≥0,
(5.4)
where DKL(p∥peq) is the Kullback-Leibler divergence introduced in eq. (2.133). This
result generalizes the analogous one obtained in section 2.3 (cf. eq. (2.35)), which
applies to equilibrium states for which the thermodynamic entropy S is deﬁned.
5.3
Information in stochastic thermodynamics
A common ingredient in the Maxwell demon paradox, the Szilard engine, and
Landauer’s idea is the manipulation of thermodynamic systems at the level of single
molecules. Stochastic thermodynamics provides a natural framework to analyze these
systems in a concrete way, besides the general ideas discussed in section 5.1. In particu-
lar, it proves useful to also consider the measuring device as a concrete physical system.
For example, we revisit the Szilard engine by considering a system (sys) as being
made up of an object (obj) and a measuring device (dev). The object represents the
part of the system that is being measured: in the case of the Szilard engine, the object
is the particle in the cylinder. We describe the object with a binary mesoscopic variable

108
Chapter 5
x ∈{L, R}, depending on whether the particle is in the lef or right chamber, respectively.
We similarly describe the state of the measuring device by a binary mesoscopic vari-
able y ∈{L, R}. Afer performing an error-free measurement, the state of the measuring
device matches the state of the particle.
We assume that initially the location of the particle and the state of the measuring
device are independent and each uniformly distributed over the two states. The entropy
of the system is therefore
Ssys = kB ln 4 = 2kB ln 2.
(5.5)
Afer an error-free measurement, the system can only be found in the states (x, y) =
(L, L) or (R, R), with equal probabilities. This means that the total entropy is reduced
to kB ln 2 by the measurement. This can be achieved either by providing work, equal at
least to −T "Ssys = kBT ln 2, or by increasing the entropy of another system, for exam-
ple, a memory attached to the measuring device. When the expansion is completed and
the piston is replaced in the middle of the cylinder, the states of the particle and the
measuring device are again uncorrelated, and the system can be found in any of its four
states.
We now consider a more general case where the object can be found in mesostates
x, characterized by energies ϵx, initially at equilibrium at temperature T. To perform a
measurement, the object is connected to a measuring device whose states are described
by the variable y. We assume for simplicity that all these states have equal energy ϵy = 0
and that the device is initially at equilibrium. The interdependence between x and y is
quantiﬁed by the mutual information
I(obj : dev) =
"
x,y
px,y ln px,y
pxpy
.
(5.6)
At a time t0 before the measurement, the equilibrium distribution of the system factor-
izes, peq
x (t0) = peq
x p0
y, where p0
y is the initial reference state of the measuring device. This
implies that the mutual information vanishes. The measurement alters px,y by introduc-
ing dependences between x and y. We assume that the measurement does not perturb
the state x of the object, so that the marginal distribution px = !
y px,y (see section A.3)
remains unaltered. The change of system entropy therefore reads
"Ssys = S(tm) −S(t0)
= −kB
"
x,y
#
px,y(tm) ln px,y(tm) −px,y(t0) ln px,y(t0)
&
,
(5.7)
where tm is a time immediately afer the measurement. We write the ﬁnal distribution
as px,y(tm) = py|x(tm)px(tm), obtaining
"Ssys = −kB
"
x,y
'
px,y(tm) ln py,x(tm)
px(tm) −px,y(t0) ln py(t0)
(
,
(5.8)
taking into account that the distribution of x is unaltered by the measurement and
that px,y(t0) factorizes. Adding and subtracting Sdev(tm) = −kB
!
y py(tm) ln py(tm),

Thermodynamics of Information
109
we obtain
"Ssys = −kBI(obj : dev) −"Sdev.
(5.9)
Since the system interacts only with the heat reservoir, "Ssys < 0 implies that an amount
of heat at least equal to Q = T "Sres = −T "Ssys must have been released to the heat
reservoir in order to comply with the second law. It is instructive to consider two
limiting cases:
• The measurement does not alter the marginal distribution of the device, so that
"Sdev = 0. In this case, eq. (5.9) predicts that an amount of work at least equal to
kBT I(obj : dev) has to be dissipated into the reservoir during the measurement.
• The measurement is adiabatic, "Ssys = 0. Equation (5.9) then implies that
kBI(obj : dev) = −"Sdev. This means that the mutual information acquired
by the measurements has been “dumped” into the memory of the measuring
device, which necessarily increases its entropy.
In light of this discussion, the operation of the Szilard engine can be restated as
follows:
1. Initially, a partition is placed in the middle of the cylinder, but no measurement
has yet been done. The system entropy is equal to 2 kB ln 2.
2. An error-free measurement is performed, so that y = x ∈{L, R}. The system
entropy is now equal to kB ln 2. Therefore, either an amount of work equal to
at least kBT ln 2 has been performed on the system and passed as heat to the
reservoir, or the entropy of the measuring device has increased by kB ln 2, or a
combination of the two has occurred.
3. By performing a free expansion, an amount of work up to kBT ln 2 is gleaned
from the reservoir.
4. The partition is placed again in the middle of the cylinder, and the correlation
between x and y is now broken.
If the measurement in point (2) is dissipative, a nonnegative amount of work, on aver-
age, is performed on the system, in agreement with Kelvin’s formulation of the second
law. Otherwise, work has been extracted but the operation of the engine is not cyclic, as
the entropy of the device has been increased. To complete the cycle, we have to restore
the initial state of the device and include the cost of that operation. This cost can be esti-
mated by the change in nonequilibrium free energy Fneq,dev(tm) −Fneq,dev(t0), which
is equal to T "Sdev since the states of the device are isoenergetic. In our case, the mini-
mum work that has to be performed is W ≥kBT ln 2, in agreement with the Landauer
bound.
5.4
The Sagawa-Ueda relation
The link between information and stochastic thermodynamics can also be stud-
ied with ﬂuctuation relations. We consider a mesoscopic object that is manipulated
according to an experimental protocol. As in section 5.3, we suppose that an instanta-
neous measurement is performed at time tm, and we denote its outcome by y. Feedback
control is a modiﬁcation of the manipulation protocol according to the outcome of the
measurement. Using the Szilard engine as an example, feedback control represents the
decision of placing the piston on either the right or lef of the wall. Because of feedback

110
Chapter 5
control, the control parameter specifying the manipulation is a function not only of
time, but also of the measurement outcome, λ = (λ(t, y)).
As in the previous section, we express the joint distribution of the state of the object
and the measuring device at a time tm immediately afer the measurement by
px,y(tm) = py|x(tm)px(tm).
(5.10)
The mutual information quantiﬁes the average amount of information gained with
the measurement. In parallel with the entropy, we deﬁne the stochastic mutual
information
ix:y = ln
px,y(tm)
px(tm)py(tm) = ln py|x(tm)
py(tm) ,
(5.11)
so that I = ⟨i⟩. The joint probability of a trajectory x of the object and a measurement
outcome y is
Py,x(λ) = py|x(λ)Px(λ).
(5.12)
These deﬁnitions allow us to generalize the integral ﬂuctuation relation in the presence
of feedback control:
)
e−stot/kB−i*
F =
+
Dx dy py|x(tm)Px(λ)P,x(,λ)
Px(λ)
py(tm)
py|x(tm)
=
+
Dx dy P,x(,λ) py(tm) = 1.
(5.13)
Here we make use of py|x(tm) = py|x(tm): since the measurement is instantaneous, its
outcome depends only on the state of the object at time m. Equation (5.13) is the
Sagawa-Ueda relation. As in the Jarzynski equality (eq. (4.52)), if the protocol starts
and ends at equilibrium, we have stot = w −"F. There is however a subtle diﬀerence:
in this case, "F is a stochastic quantity, since the ﬁnal free energy depends in principle
on the outcome of the measurement. Equation (5.13) then implies
W −⟨"F⟩≥−kBT I.
(5.14)
Equation (5.14) quantiﬁes the apparent violations of the second law due to feedback
control. In a single, instantaneous measurement, the average total entropy production
can be negative, up to a minimum given by −kB times the mutual information between
the object and the measuring device immediately afer the measurement.
5.5
The Mandal-Jarzynski machine
The Mandal-Jarzynski machine is an explicit, analytically solvable model of a meso-
scopic physical system that is capable of trading information for work. Its dynamics
shows at play many of the concepts discussed so far.
The Mandal-Jarzynski machine is characterized by three mesostates A, B, and C, all
of equal energy (ﬁg. 5.3a). The machine interacts with a tape whose states (bits) can be 0
or 1. Bits 0 and 1 also have the same energies. At time intervals equal to τ, the tape shifs
to the right, so that the machine interacts with a new bit. We denote by r the fraction
of 1 bits in the incoming tape and by d = 1 −2r the excess of bits 0. The machine is

Thermodynamics of Information
111
1
kg
B
C
A
0 1 1 0
0 1
0
1
0 1 0 1 0 0 0
1
−0.5
0.0
0.5
d
0.00
0.25
0.50
0.75
ζ
engine
eraser
dud
(a)
(b)
Figure 5.3. (a) Sketch of the Mandal-Jarzynski machine. (b) Phase diagram. Regime
boundaries indicate (solid line) vanishing rotation speed and (dotted line) vanishing
Shannon entropy change of the tape (the machine swaps 0s and 1s at equal average
rates). The time interval τ is set to 0.8. See Mandal and Jarzynski [108].
also connected to a mass m. Depending on the operating regime, it can either lif it
(performing work) or lower it (extracting work).
Jumps between states A ←→B and B ←→C occur at rates kAB = kBA = kBC =
kCB = 1, regardless of the state of the tape and the mass. In contrast, jumps between
states A and C are coupled to both the tape and the mass:
• A jump A −→C can occur only if the bit read by the machine is 1. During such
a jump, the bit is “ﬂipped” to 0. Similarly, a jump C −→A can occur only if the
bit is 0 and is ﬂipped it to 1 when the jump occurs.
• When the machine jumps from C to A, the mass is lifed by a height "h.
Conversely, when A −→C, the mass is lowered by "h.
The jump rates between states A and C satisfy the generalized detailed balance
relation
kAC
kCA
= e−mg "h/kBT,
(5.15)
as the work by the “external agent” (the mass in this case) along the jump A →C is
equal to mg "h; see eq. (3.7). A choice compatible with eq. (5.15) is kAC = 1 −ζ and
kCA = 1 + ζ, with ζ = tanh(mg "h/2kBT). The system is at equilibrium if the fraction
r of 1s in the tape is equal to peq
1 = e−mg "h/kBT/(1 + e−mg "h/kBT) = (1 −ζ)/2.
The steady state of the model can be evaluated analytically. It turns out that the
machine can operate in three distinct regimes, depending on the choice of parameters
(ﬁg. 5.3b):
• In the ﬁrst regime, the machine is eﬀectively an information engine, as it
extracts work from the heat reservoir, at the cost of dumping entropy into
the bit sequence. The machine rotates clockwise on average, i.e., A −→B −→
C −→A. This occurs when d ≥ζ, i.e., when the entropy of the bit sequence
is suﬃciently low and the mass suﬃciently light. A machine operating in this
regime is a concrete example of a Maxwell demon.

112
Chapter 5
• In the second regime, the machine acts as an eraser, consuming mechanical
work to reduce the Shannon entropy of the tape. The rotation is counterclock-
wise, i.e., the mass is lowered on average, and the Shannon entropy of the tape is
reduced. In the particular case of full erasure, i.e., when the output tape is made
up of all 0s or 1s, the machine spends at least W ≥kBTH(p), where H(p) =
−p0 ln p0 −p1 ln p1 is the Shannon entropy of the incoming sequence of bits.
This operating regime is therefore consistent with the Landauer principle.
• In the last regime (dud), the machine both dissipates work and increases
entropy, without therefore performing any useful operation. The boundary bet-
ween the eraser and the dud regime is given by the condition H(p) = H(peq),
as for the engine-eraser boundary, but with p0 < 1
2, i.e., d < 0.
The Mandal-Jarzynski machine provides us with an opportunity to clarify one
important aspect of the Landauer principle: the work spent to reduce the entropy of
a memory may not be irreversibly dissipated into the heat reservoir. This work (or at
least a part of it) can be retrieved by another machine working as an information engine.
From this perspective, the Maxwell demon and the Landauer principle are two sides of
the same coin: information can be converted into work and back. In Landauer’s words,
“Information is physical.”
5.6
Copying information
Living systems rely on their capacity to replicate information at the molecular level
with high accuracy and speed. Important examples of information copying in biology
are DNA replication and DNA-to-RNA transcription. At variance with erasure, infor-
mation copying is not necessarily irreversible. For example, we consider a system with
two states x = 0, 1, initially prepared in the state x = 0. It is possible to copy the state y
of another binary system into x without losing information. For example, we can apply
the reversible transformation
(x, y) −→(x′, y),
(5.16)
where
x′ = x XOR y =
-
y,
if x = 0;
1 −y,
if x = 1.
(5.17)
Thus, provided that x is initially in a reference state (0 in this case), copying can be
performed without dissipation, i.e., there is no equivalent of the Landauer bound for
copying. However, information can be copied without dissipation only in the limit of
vanishing speed, whereas copying at ﬁnite speed involves a thermodynamic cost. Fur-
ther, copying at ﬁnite temperature necessarily implies errors, and correcting these errors
can signiﬁcantly increase dissipation. Understanding the tradeoﬀs between error rate,
speed, and dissipation in copying is crucial to characterize the performance of biolog-
ical copying machines. Besides biology, these trade-oﬀs are also becoming relevant for
artiﬁcial computing, as microprocessors become smaller and faster.
To be more concrete, we consider a mesoscopic machine that sequentially replicates
a long, preexisting polymer, made up of two diﬀerent kinds of monomers (ﬁg. 5.4a).
At each time, the monomer at the tip of the copied polymer can be removed, or a
new monomer can be added. We denote by k+
r , k−
r the rates of incorporation/removal
of right monomers and by k+
w, k−
w the corresponding rates for wrong monomers. We
assume for simplicity that the rates do not depend on the speciﬁc pairing of monomers

Thermodynamics of Information
113
copy
w
r
r
r
template
r
0
w
rr
ww
...
...
...
...
...
rw
...
wr...
...
(a)
(b)
Figure 5.4. (a) Scheme of a molecular machine (gray oval) that copies a long existing
polymer, called the template. Due to thermal ﬂuctuations, the machine sometimes incor-
porates w monomers that do not match the template. (b) Sketch of the corresponding
jump network. The process is iteratively repeated, so that the whole jump network is an
inﬁnite tree.
but only on whether the match is correct. The jump network for the complete sys-
tem (the machine plus the copied polymer) is an inﬁnite tree, sketched in ﬁg. 5.4b.
Each state in this tree is a string rwwr . . . , identifying the sequence of right and wrong
monomers that have been incorporated in the copy. The generalized detailed balance
condition (3.7) reads
k+
r /k−
r = e(−"ϵr+δ)/kBT;
k+
w/k−
w = e(−"ϵw+δ)/kBT.
(5.18)
Here "ϵr and "ϵw are the energies of a right and wrong monomer incorporation,
respectively. The parameter δ is an external chemical driving that promotes monomer
incorporation. We assume the chemical driving to be equal for right and wrong
monomers. Increasing δ drives the system away from equilibrium. We remark that
this system can be driven away from equilibrium although its jump network, depicted
in ﬁg. 5.4b, does not contain any loop. This fact does not contradict the results in
section 2.6, since the number of states here is inﬁnite.
We write the four jump rates as
k+
r = ωr eδ/kBT;
k−
r = ωr e"ϵr/kBT;
k+
w = ωw eδ/kBT;
k−
w = ωw e"ϵw/kBT.
(5.19)
We choose this expression of the rates on the physical assumption that the chem-
ical driving aﬀects the incorporation rates, whereas speciﬁc binding energies aﬀect
monomer stability in the copy and therefore their removal rates. In general, right and
wrong monomers can be discriminated either due to a diﬀerence in their binding ener-
gies "ϵi, i ∈{r, w} (energetic discrimination), or due to a diﬀerence in the intrinsic rates
ωi (kinetic discrimination), or both.

114
Chapter 5
The master equation for this system reads
d
dt p...r = k+
r p... + k−
r p...rr + k−
wp...rw −(k+
r + k+
w + k−
r )p...r,
d
dt p...w = k+
wp... + k−
r p...wr + k−
wp...ww −(k+
r + k+
w + k−
w)p...w,
(5.20)
where . . . r is a copy with an r monomer at the tip, and similarly for . . . w. To solve the
master equation, we assume that the probability of producing a given string rwrr . . .
with Nr right and Nw wrong monomers in the steady state is prwrr... ∝(1 −η)NrηNw,
where η is the error probability to be determined a posteriori. Substituting this guess
into the master equation, we ﬁnd that it is a solution, provided that η satisﬁes the
condition
η
1 −η =
k+
w −ηk−
w
k+r −(1 −η)k−r
.
(5.21)
The corresponding elongation speed is
v = k+
r −(1 −η)k−
r + k+
w −η k−
w.
(5.22)
We discuss two interesting limiting cases:
Equilibrium limit. In the equilibrium limit, the elongation speed v is vanishingly
small. We solve the equation for η in this limit and evaluate the corresponding rates
using eq. (5.21). We ﬁnd that the error rate tends to ηeq = e−"ϵw/kBT/(e−"ϵr/kBT +
e−"ϵw/kBT), as expected from detailed balance. The corresponding driving δ is
smaller than the average work needed for the incorporation of a right monomer:
δstall = ϵR + kBT ln(1 −ηeq). The second term in the expression of the stall driving
is due to the compositional disorder of the copy: in the absence of driving, entropy
increase would naturally lead to a nonequilibrium elongation of the chain.
Fully irreversible limit. In the limit of strong driving, δ ≫1, which implies a large
velocity, the error eventually tends to η = k+
w/(k+
r + k+
w) = ωw/(ωr + ωw). Physi-
cally, this ratio is related to the diﬀerence in the activation barrier between the
reactions leading to incorporations of right and wrong monomers; see the discussion
in section 3.12.
As the driving δ increases, the copying speed also increases, while the value of the
error moves from the equilibrium to the irreversible limit. Since the error in the fully
irreversible limit can be either larger or smaller than that in the equilibrium limit,
depending on the other parameters, the trade-oﬀbetween speed and error can be either
positive or negative. This fact is illustrated in ﬁg. 5.5.
Out of equilibrium, the elongation of the copy polymer is a dissipative process that
produces entropy. The average entropy production rate can be expressed as
T˙Stot = kBT
'
Jr ln
.k+
r
k−r
(1 −η)
/
+ Jw ln
.k+
w
k−w
η
/(
= v (1 −η)(δ −ϵr + kBT ln(1 −η)) + v η (δ −ϵw + kBT ln η)
= v
#
"W −"F −kBT DKL(η∥ηeq)
&
≥0,
(5.23)

Thermodynamics of Information
115
0.02
0.10
0.50
η
10−3
10−1
101
103
v
energetic
kinetic
Figure 5.5. Kinetic and energetic discrimination. The two curves show polymerization
speed v versus error η as the driving δ increases from 0 to 10 kBT for different choices of
the other parameters. In both curves, higher speed corresponds to larger values of δ, but
the effect of increasing the driving on the error is opposite for the two kinds of discrimi-
nation. Parameters: (energetic) ωr = ωw = 1, ϵr = 1 kBT, ϵw = 5 kBT; (kinetic) ϵr = ϵw = 1 kBT,
ωr = 50, ωw = 1. Both axes are logarithmic.
where v = Jr + Jw is the average net rate at which monomers are incorporated into the
copy, "W = δ is the work per incorporated monomer, and "F = kBT ln(e−"ϵr/kBT +
e−"ϵw/kBT) is the equilibrium free energy change afer incorporating each monomer.
A derivation of eq. (5.23) using the Schnakenberg formula (3.39) is lef as exercise 5.2.
Equation (5.23) also holds for more general models where incorporation of monomers
does not occur in a single jump, but is a more complex process characterized by several
intermediate states, potentially correcting errors.
To interpret eq. (5.23), we consider the limiting case in which right and wrong
monomers are isoenergetic, so that ηeq = 1/2. We further assume that it is possible to
transform a right monomer into a wrong one and vice versa. For example, the diﬀerent
monomers can be distinguished by a molecular tag (such as methylation) that can be
reversibly added and removed to the monomers by another enzyme. In this case, the
joint system of the template plus the copy is conceptually equivalent to the tape of the
Mandal-Jarzynski machine discussed in section 5.5. In particular, a precise match of
the template and the copy can be fed to a Mandal-Jarzynski machine operating as an
information engine. Such a machine would extract mechanical work by increasing the
error in the copy. This thought experiment shows that the last term in eq. (5.23) rep-
resents free energy reversibly incorporated into the copy as information, which can in
principle be transformed again into mechanical work.
5.7
Information cost in sensing
Living organisms need to constantly keep track of the state of relevant variables
in their environment. They perform this task by means of electrical, chemical, and
mechanical signaling pathways, called sensory systems. Important properties of sensory

116
Chapter 5
systems are a fast response to environmental changes, complemented by a slower
adaptation, i.e., a long-term storage of the average state of the environment into a mem-
ory. Systems possessing these properties are aptly called sensory adaptation systems.
Stochastic thermodynamics allows us to investigate the fundamental minimum energy
cost for the functioning of a sensory adaptation system.
We focus on a minimal model of a sensory adaptation system. This system monitors
a binary variable, the signal e ∈{0, 1}, representing a relevant property of the environ-
ment. The state x of the sensory adaptation system is speciﬁed by two internal binary
variables: the activity a ∈{0, 1} and the memory m ∈{0, 1}. At constant signal, the
state m ∈{0, 1} must be closely correlated with e, while a is lef free to adapt to sud-
den changes in the environment. This means that the dynamics of m must be much
slower than that of a.
For simplicity, we consider a sensory adaptation system that is not driven by chemical
energy. This means that, at constant signal, its dynamics satisﬁes the detailed balance
condition (2.83), and the system eventually settles down to an equilibrium state.
We write the energy function ϵ = ϵx,e = ϵa,m,e of the sensory adaptation system based
on physical considerations. The lowest-energy states must be those where the memory
matches the signal, m = e, ensuring stability of the memory. The energies of these states
are independent of a, since the activity should not play any role if the signal matches
the memory. Instead, when m ̸= e, states in which the activity matches the environment
(a = e) should be energetically more stable than those with a ̸= e. These requirements
lead to the expression
ϵa,m,e = |e −m| ("m + |a −e| "a) .
(5.24)
The parameters "m > 0 and "a > 0 are penalties due to memory and activity mistrack-
ing, respectively. We express them by
"a,m = −kBT ln δa,m ,
(5.25)
where δa,m ≪1 are tolerances for activity (a) and memory (m) tracking. We assume
that individual jumps change the state of either a or m, but not both simultaneously:
k(1−a,m),(a,m) = ωa eϵa,m,e/kBT;
k(a,1−m),(a,m) = ωm eϵa,m,e/kBT.
(5.26)
Since the activity is fast compared to the memory, we take ωa ≫ωm. The probability
distribution px(t) follows a master equation with the rates (5.26). The environment-
dependent equilibrium state is given by
peq
x|e ∝e−ϵa,m,e/kBT.
(5.27)
To illustrate the dynamics, we consider an environment that has been in state e = 0
for some time and suddenly switches to e = 1 at time t = 0. The initial distribution is
peq
x|e=0. In a time on the order of ω−1
a , the activity variable tends to the new environmen-
tal state. At longer times, of order ω−1
m , m starts aligning with the new environmental
state while a slowly resets toward a state where 0 and 1 are equiprobable. The dynamics
is shown in ﬁg. 5.6.

Thermodynamics of Information
117
0
100
200
300
t (s)
0.00
0.25
0.50
0.75
1.00
(a)
(b)
δa
δm
δad
memory
activity
signal
10−2
100
102
t (s)
0.00
0.25
0.50
0.75
1.00
8a9, 8m9
8a9, 8m9
memory
activity
δa
δm
δad
Figure 5.6. Average activity ⟨a⟩and average memory ⟨m⟩as a function of time t for a
signal switching from e = 0 to e = 1 at t = 0. (a) Linear time axis. (b) Logarithmic time
axis. Parameters: δm = 0.35, δa = 0.01, ωa = 1/50 s−1, ωm = 1/250 s−1, kBT = 1. See Sartori
et al. [142].
The information carried by the sensory adaptation system about the environment is
quantiﬁed by the mutual information
I(sys : env) =
"
x,e
px|epe ln px|e
px
,
(5.28)
where px = !
e px|epe. We assume that the environment is unbiased, so that pe = 1/2. By
using the chain rule for the mutual information (2.145) and the fact that the distribution
of the system (sys) is the joint distribution of the activity (act) and the memory (mem),
we obtain
I(sys : env) = I(mem : env) + I(act : env|mem),
(5.29)

118
Chapter 5
where
I(act : env|mem) =
"
a,m,e
pa,m|epe ln pa|m,e
pa|m
(5.30)
is the conditional mutual information between the activity and the environment, given
the memory. This quantity is positive but quite small in the steady state. The reason
is that most of the information on the environment is carried by the memory, I(sys :
env) ≈I(mem : env) ≈1 bit.
We now study a case in which the environmental signal is initially either 0 or 1 with
equal probability. At time t, the signal can switch with probability 1/2. The information
borne by the sensory adaptation system can be split into information about the initial
environment env(t0), which must be erased, and information about the ﬁnal envi-
ronment env(tf), which must be acquired. Given the instantaneous state px|e(t0),e(tf)(t)
conditioned to the initial and ﬁnal environments, we deﬁne the acquired information
"Imeas(t) on the ﬁnal environment and the erased information "Ieras(t) by
"Imeas(t) = I(sys(t) : env(tf)) −I(sys(t0) : env(tf));
"Ieras(t) = I(sys(t0) : env(t0)) −I(sys(t) : env(t0)|env(tf)).
(5.31)
Here I(sys(t) : env(tf)) is the mutual information between the state x of the sen-
sory adaptation system at time t and the ﬁnal environment. Similarly, I(sys(t) :
env(t0)|env(tf)) is the conditional mutual information between the system at time t and
the initial environment, given the ﬁnal environment. They are respectively deﬁned by
I(sys(t) : env(tf)) =
"
x,ei,ef
px|ei,ef (t)pei,ef ln px|ei,efpei,ef(t)
px(t)pef
,
I(sys(t) : env(t0)|env(tf)) =
"
x,ei,ef
px|ei,ef (t)pei,ef ln px|ei,ef(t)
px|ef(t) ,
(5.32)
where px(t) = !
ei,ef px|e(t0),e(tf)(t) pe(t0),e(tf) and pe(tf) = !
e(t0) pe(t0),e(tf). Analogous
deﬁnitions hold for I(sys : env(t0)) and pe(t0). One can verify that I(sys(t0) : env(tf)) =
limt→∞I(sys(t) : env(t0)|env(tf)) = 0. These quantities can be further split into con-
tributions from the activity and the memory via the chain rule; see section 2.10. The
behavior of "Imeas and "Ieras as a function of time are shown in ﬁg. 5.7, along with
their decomposition into information carried by m and a, respectively. In particular, the
activity carries signiﬁcant information about the measurement at intermediate times,
whereas it carries quite small erasure information.
Upon switching from ei to ef, the environment performs work on the sensory adap-
tation system. The average work is given by W = !
ei,ef
0
ϵx,ef
1
peq
x,ei pei,ef ≥0. This work
is in part dissipated in the reservoir during relaxation to the new equilibrium state
peq
x,ef , thereby producing entropy. The average total entropy produced up to time t given
(ei, ef) is expressed by
Stot
ei,ef (t) = "Ssys
ei,ef (t) + Sres
ei,ef (t),
(5.33)
where
"Ssys
ei,ef (t) = kB
#
H(px|ei,ef (t)) −H(px|ei,ef(0))
&
,
(5.34)

Thermodynamics of Information
119
10−3
10−1
101
t
10−3
10−1
101
t
0.0
0.2
0.4
0.6
0.0
0.2
0.4
0.6
ΔImeas
1 bit
ΔImeas
ΔImmeas
ΔIameas
(b)
(a)
I0 − ΔIeras
1 bit
I(0) – ΔIeras
Im
(0) – ΔImeras
Ia
(0) – ΔIaeras
Figure 5.7. (a) Information acquired about the new state of the environment as a func-
tion of time. The information is split into information carried by the memory m and
information carried by the activity a, given env(tf) and m. (b) Information lost about the
old state of the environment as a function of time. The difference I(0) −"Ieras(t), where
I(0) = I(sys(t0) : env(t0)), is split into information carried by the memory m and information
carried by the activity a, given env(t0) and m. In both plots, t denotes the time elapsed
since the switch; the scale is logarithmic. Parameters: δm = 0.01, δa = 0.01, ωa = 1/50 s−1,
ωm = 1/250 s−1, kBT = 1. See Sartori et al. [142].
in which H(px) is the Shannon entropy of the distribution px, and
Sres
ei,ef(t) = 1
T Qres
ei,ef (t) = 1
T
.0
ϵx,ef
1
peq
x|ei −
0
ϵx,ef
1
px|ei,ef (t)
/
.
(5.35)
Here Qres
ei,ef (t) is the average heat released to the reservoir up to time t, equal to the diﬀer-
ence between the initial average energy of the sensory adaptation system (immediately

120
Chapter 5
afer the switch) and its current average. By the second law of stochastic thermodynam-
ics, Stot ≥0 for any ﬁnite time interval. Therefore, Stot(t) is a monotonically nondecreas-
ing function of t. Since this is true for any choice of ei and ef, it is also true on average.
We split the total entropy production into two nonnegative terms, one pertaining
to the measuring process and the other to the erasure. Averaging out H(px|ei,ef (t)), we
obtain the conditional entropy
H(sys(t)|env(t0), env(tf)) = H(sys(t)|env(tf)) −I(sys(t) : env(t0)|env(tf))
= H(sys(t)) −I(sys(t) : env(tf)) −I(sys(t) : env(t0)|env(tf)),
(5.36)
where we apply the chain rule twice. Averaging (5.33) and substituting this relation, we
obtain
"Stot(t) = kB"H(sys(t)) + 1
T Qres(t) −kBI(sys(t) : env(tf))
2
34
5
"Smeas(t)
−kBI(sys(t) : env(t0)|env(tf))
2
34
5
"Seras(t)
.
(5.37)
The quantity "Smeas(t) cannot decrease in time:
d"Smeas
dt
= −kB
"
x,ef
pef
dpx|ef(t)
dt
ln px|ef(t)
peq
x|ef
= −kB
"
ef
pef
d
dtDKL(px|ef(t)∥peq
x|ef) ≥0.
(5.38)
The last equality holds because the Kullback-Leibler divergence between the instanta-
neous and the stationary distribution decreases monotonically with time; see eq. (A.20).
The nonnegativity of d"Seras/dt is proved in a similar way. Integrating with respect to t,
we ﬁnd that both "Smeas and "Seras are nonnegative.
We thus obtain, taking into account that limt→∞Q = W −" ⟨ϵ⟩, and recalling the
deﬁnition of the nonequilibrium free energy Fneq = ⟨ϵ⟩p −kBTH(p) in section 2.3,
W −⟨"F⟩≥kBT
#
I(sys(+∞) : env(tf)) −I(sys(0) : env(tf))
&
= kBT "Imeas;
(5.39a)
T "Seras = kBT
$
I(sys(0) : env(t0)|env(tf)) −I(sys(+∞) : env(t0)|env(tf))
%
= kBT "Ieras ≥0.
(5.39b)
The ﬁrst relation corresponds to the Sagawa-Ueda relation (5.14), and shows that, in
the present system, measurement is energetically costly and that the work is provided
by the switch in the signal. The second relation shows that memory erasure takes place
without energy costs but is necessarily dissipative. The entropy production as a function
of time is shown in ﬁg. 5.8.
Most biologically relevant sensory adaptation systems are driven in a nonequili-
brium steady state by dissipation of chemical energy and therefore do not satisfy

Thermodynamics of Information
121
10−3
10−1
101
t
0
1
2
3
S/kB
ΔStot
ΔSmeas
ΔSeras
Figure 5.8. Total entropy production of the sensory adaptation process in the model and
its decomposition in measurement "Smeas and erasure "Seras contributions, expressed
as a function of the time elapsed since the switch. Parameters: δm = 0.01, δa = 0.01,
ωa = 1/50 s−1, ωm = 1/250 s−1, kBT = 1. Timescale is logarithmic. See Sartori et al. [142].
detailed balance. In spite of this fundamental diﬀerence, inequalities closely related to
(5.39) also hold for such systems. They are based on the separate ﬂuctuation relations
for adiabatic and nonadiabatic entropy production discussed in section 4.9. Indeed,
in a nonequilibrium steady state, the entropy production is entirely captured by the
adiabatic contribution deﬁned in (4.64). A change in the signal is accompanied by nona-
diabatic entropy production (see eq. (4.67)), which is also associated with excess heat
released to the reservoir. In our case, the average excess heat is given by
Qex(t) = kBT
"
ei,ef
pei,ef
+ t
t0
dt
"
x
dpx|ei,ef(t)
dt
ln pst
x|ef.
(5.40)
As a consequence of the ﬂuctuation relation (4.74), averaged over ei, ef, one has
Sna(t) = kB "H(sys(t)|env(t0), env(tf)) + Qex(t)
T
≥0.
(5.41)
The nonadiabatic entropy production Sna(t) can be further split, as above, in the
contributions of measure and erasure, yielding
kB "H(sys(t)) + Qex(t)
T
≥kB "Imeas(t) ≥0;
Sna(t) ≥kB "Ieras(t) ≥0.
(5.42)
Here "Imeas(t) and "Ieras(t) are deﬁned as in (5.31). In this case, the system usually
receives most of the energy necessary for the process by the inner working of the cell,
rather than from the signal, as in the equilibrium case.

122
Chapter 5
5.8
Information reservoirs
We have discussed two ways of handling information in stochastic thermodynamics:
via a measurement-and-feedback scheme, as in the Szilard thought experiment, and
via interaction with a tape, as done by the Mandal-Jarzynski machine. In this section,
we introduce a uniﬁed framework to describe these two setups, where the measuring
device and the tape are seen as particular cases of a general information reservoir. This
framework also permits us to compare the total entropy production in the two cases.
We further compare the entropy production by the information reservoir with that of
a comparable heat reservoir.
We consider a system with two states, d (down) and u (up), with ϵd = 0, ϵu = ϵ > 0, in
contact with a heat reservoir at temperature T. The jump rates induced by interactions
with this reservoir satisfy the detailed balance relation
k↑
k↓= e−ϵ/kBT,
(5.43)
where k↑= kud and k↓= kdu. In the absence of other interactions, the equilibrium
distribution is
peq
d =
1
1 + e−ϵ/kBT ;
peq
u =
e−ϵ/kBT
1 + e−ϵ/kBT .
(5.44)
Besides the heat reservoir, the system is also in touch with an information reservoir.
Interactions with the information reservoir take place at random times with rate γ and
can swap the two states. If the system is in state u at the time of swapping, the system
releases an amount of work ϵ, e.g., by lifing a weight attached to it. Otherwise, if the
system is in state d, the weight is lowered, granting the system an amount of work ϵ.
Afer the interaction, we swap the labels of the states, so that the lowest-energy state
always has the label d. The information-mediated jump rates are
¯k↑= γ r;
¯k↓= γ (1 −r).
(5.45)
Here r is a parameter between 0 and 1. We also take into account interactions with the
reservoir that do not swap the states. The corresponding rates are
¯kd = γ (1 −r);
¯ku = γ r.
(5.46)
The evolution of the system coupled to both reservoirs is described by a master
equation:
dpu
dt =
6
k↑+ ¯k↑7
pd −
6
k↓+ ¯k↓7
pu;
dpu
dt =
6
k↓+ ¯k↓7
pu −
6
k↑+ ¯k↑7
pd.
(5.47)
The system eventually reaches a steady state, characterized by a probability distribution,
pst
u = k↑+ ¯k↑
k + γ ;
pst
d = k↓+ ¯k↓
k + γ ,
(5.48)

Thermodynamics of Information
123
where k = k↑+ k↓and we use the relation γ = ¯k↑+ ¯k↓. Physically, the information
reservoir can be interpreted in diﬀerent ways:
Measurement-and-feedback (MF). In this interpretation, the information reservoir is
a device that measures the state of the system at rate γ , obtaining a result y ∈{0, 1},
where 1 corresponds to u and 0 to d. The parameter r represents the error probability
of the measurement. This means that pu|1 = pd|0 = 1 −r and pu|0 = pd|1 = r. In this
interpretation, we assume 0 < r < 1/2. If the outcome of the measurement is y = 1,
the states of the system are swapped. Therefore, if the system is in u, it jumps to d with
probability (1 −r), while if it is in d, it jumps to u with probability r. We thus recover
the information-mediated rates (5.45, 5.46). The probability pdev
1
that the measure-
ment yields 1, which is also the probability the system is in state u immediately afer
an interaction, is given by
pdev
1
= (1 −r) pst
u + r pst
d = pst
u + r −2 rpst
u.
(5.49)
The average work performed on the system per unit time is
˙W = ϵ γ
#
r pst
d −(1 −r) pst
u
&
= −γ ϵ
$
pst
u −r
%
.
(5.50)
Since the system is in a steady state, ˙W is equal to the average heat released to the
heat reservoir per unit time, ˙W = T ˙Sres. The total entropy production is the sum
of Sres plus the change in the joint entropy of the system and the measuring device.
The mutual information between the system and the device for a single interaction
is given by
I = H(dev) −H(dev|sys) = H(dev) −H(r),
(5.51)
where H(dev) is the Shannon entropy of the device and H(r) is the Shannon entropy
associated with the error rate r. The Sagawa-Ueda relation (5.14) then implies
˙W + γ kBT I ≥0,
(5.52)
with I given by eq. (5.51).
TAPE. The information reservoir is interpreted as a tape containing an inﬁnite
sequence of bits. With rate γ , the tape shifs by 1 bit and is connected to the sys-
tem. If the incoming bit on the tape is 1 (0), the state of the system is labeled u (d).
If the system changes state by interacting with the heat reservoir, the bit on the tape
is also switched, so that only the jumps (0, d) ←→(1, u) are allowed. The switching
rates are again given by eq. (5.45). In this interpretation, the probabilities that incom-
ing and outgoing bits are equal to 1 are given by r and pst
u, respectively. Therefore, the
entropy of the outgoing tape changes at a rate γ kB
#
H(pst) −H(r)
&
. We then have
T ˙Stot
TAPE = ˙W + γ kBT
#
H(pst) −H(r)
&
≥0,
(5.53)
where ˙W is given by eq. (5.50). Using the relation
ϵ = kBT
#
ln
$
1 −peq
u
%
−ln peq
u
&
,
(5.54)

124
Chapter 5
we obtain
T ˙Stot
TAPE = γ kBT
#
DKL(r∥peq) −DKL(pst∥peq)
&
≥0.
(5.55)
Since
pst
u −peq
u =
γ
k + γ
$
r −peq
u
%
,
(5.56)
the diﬀerence of the Kullback-Leibler divergences is nonnegative. On the other hand,
since H(dev) ≥H(pst), the bound in eq. (5.53) is tighter than the Sagawa-Ueda
inequality (5.52). In particular, the diﬀerence H(pst) −H(r) can be negative, while
the mutual information I is always nonnegative. When H(pst) −H(r) is negative, the
system works as an eraser, spending work to reduce the tape entropy.
Generalized detailed balance (GDB). A third alternative is to treat the information
reservoir in the same way as a heat reservoir and compute the average entropy pro-
duction rate using the Schnakenberg formula (3.39). In this case, the average entropy
production rate is given by
˙Stot
GDB = kB
6
k↓pst
u −k↑pst
d
7
ln k↓
k↑+ kB
6
¯k↓pst
u −¯k↑pst
d
7
ln
¯k↓
¯k↑,
(5.57)
where we separate the contributions coming from interactions with the two diﬀerent
reservoirs. This expression can be rearranged in the form
T ˙Stot
GDB = ˙W + γ kBT
$
pst
u −r
%
ln 1 −r
r
≥0.
(5.58)
This expression of the entropy production rate diverges for r →0, in contrast with
the previous cases.
Summarizing, the same dynamics yields three diﬀerent expressions of the entropy
production rate, depending on how we interpret the information reservoir. The reason
is that some thermodynamic costs related to information handling are not taken into
account in the MF and TAPE cases: in MF, the costs associated with the acquisition and
erasure of the information in the measuring device and, in TAPE, the cost of producing
the initial state of the tape. In the latter case, it is instructive to consider a regime in
which pst
u > r, so that ˙W < 0, and the system lifs the weight on average. Equation (5.53)
sets the minimal work needed to restore the tape to its previous condition:
˙W ≥kBT γ
$
H(pst) −H(r)
%
.
(5.59)
In the regime γ ≪k, we have pst ≈peq. Therefore, to reset the fraction of 1 on the tape to
r in this regime, we need an amount of work ϵ = kBT ln[(1 −r)/r]. The corresponding
minimal power applied to the system is given by
˙W = kBT γ
$
pst
u −r
%
ln 1 −r
r
≥kBT γ
#
H(pst) −H(r)
&
.
(5.60)
If we ﬁrst extract work by increasing the tape entropy according to eq. (5.53), and
then spend some work to reset the tape, the total entropy production is bounded by
(5.58). Therefore, the divergence of the entropy production for r →0 represents the
thermodynamic cost of producing an error-free tape.

Thermodynamics of Information
125
5.9
Fluctuation relations with information reservoirs (*)
We have seen that diﬀerent interpretations of an information reservoir lead to dif-
ferent expressions of the average entropy production, that satisfy diﬀerent inequalities.
In turn, these inequalities descend from diﬀerent ﬂuctuation relations, which we derive
in this section.
Our ﬁrst step is to ﬁnd how to account for interactions with the information reservoir
that do not lead to a jump (cf. eq. (5.46)). To this aim, we formally consider two copies
of our two-state system, A and B. We swap copies every time an information-mediated
interaction occurs, even if the state x of the system does not change. The jump network
therefore has four states xα, where x ∈{d, u} represents the physical state of the system
and α ∈{A, B} denotes the copy. The jump rates k↑,↓connect states of the same copy
and ¯k↑,↓, ¯kd,u connect diﬀerent copies; see eqs. (5.43, 5.45, 5.46). Since the dynamics is
symmetric between the two copies, we have pst
xα = pst
x /2, ∀x, α.
We compare the probability density of a trajectory x with that of its reverse ,x. The
backward trajectory satisﬁes a master equation with the same jump rates k within each
copy, but diﬀerent ones,k between the copies. In particular, we choose the reverse rates
,k to satisfy
,k↑+,kd =,k↓+,ku = γ .
(5.61)
With this choice, the escape rates of forward and backward trajectories are equal. The
ratio of the probability densities of forward and backward trajectories is
Px(k, ¯k)
P,x(,k,,k)
= px0(t0)
pxn(tf) esres(x)/kB = estot(x)/kB,
(5.62)
where
sres(x) = kB
2
"
x̸=x′
Jx,x′(x) ln kxx′
kx′x
+ kB
"
x,x′
Rxx′(x) ln
¯kxx′
,kx′x
(5.63)
is the entropy change in the reservoirs associated with the trajectory x. Here Jxx′(x) is
the net integrated current between x′ and x,
Jxx′(x) =
n
"
ℓ=0
"
α
6
δK
xα,xn+1αn+1δK
x′α,xnαn −δK
x′α,xn+1αn+1δK
xα,xnαn
7
,
(5.64)
and Rxx′(x) is the total number of switches between the two copies connecting the state
x′ with the state x:
Rxx′(x) =
n
"
ℓ=0
6
δK
xA,xn+1αn+1δK
x′B,xnαn + δK
xB,xn+1αn+1δK
x′A,xnαn
7
.
(5.65)
The term in Rxx′ has this form because the switch between A and B has the same
weight as the switch between B and A. From eq. (5.62), we obtain the integral ﬂuctuation
relation
)
e−stot/kB
*
= 1,
(5.66)

126
Chapter 5
which implies
Stot =
0
stot1
≥0.
(5.67)
In the steady state, since the entropy of the system does not change, this leads to
˙Stot = lim
T →∞
⟨sres⟩
T
= kB
2
"
x̸=x′
Jx,x′ ln kxx′
kx′x
+ kB
"
x,x′
Rxx′ ln
¯kxx′
,kx′x
≥0,
(5.68)
where T is the duration of the time interval and
Jxx′ = lim
T →∞
⟨Jxx′⟩
T
= kxx′ pst
x′ −kx′x pst
x ;
Rxx′ = lim
T →∞
⟨Rxx′⟩
T
= ¯kxx′ pst
x′.
(5.69)
The diﬀerent expressions of the reservoir entropy change in the diﬀerent schemes
are obtained by suitably choosing the reverse rates,k:
• In the measurement-and-feedback interpretation, we choose the jump rates
according to the outcome of measurements along the forward trajectory:
,kud =,kdu = γ pdev
1 ;
,kdd =,kuu = γ (1 −pdev
1 ).
(5.70)
We then obtain
˙Stot
MF = kB
2
"
x̸=x′
Jx,x′ ln kxx′
kx′x
+ kB γ [H(dev) −H(r)] ≥0.
(5.71)
The last term is proportional to the mutual information between the system
and the measuring device and is therefore nonnegative.
• In the tape interpretation, we determine the rates,k characterizing the backward
trajectory by swapping the fraction of 1 in the incoming and outgoing tape with
respect to the forward trajectory:
,kuu =,kud = γ pst
u;
,kdu =,kdd = γ pst
d .
(5.72)
This choice leads to
˙Stot
TAPE = kB
2
"
x̸=x′
Jx,x′ ln kxx′
kx′x
+ kB γ
#
H(pst) −H(r)
&
≥0.
(5.73)
The term associated with information handling is a product of the rate by which
the tape is processed and the diﬀerence between the entropy of outgoing and
incoming bits. This diﬀerence can be either positive or negative, and, since it
is not antisymmetric, it does not satisfy the conservation laws of probability
currents.

Thermodynamics of Information
127
• In the generalized detailed balance interpretation, we choose ,kxx′ = ¯kxx′. The
“jumps” with x′ = x do not contribute and we obtain
˙Stot
GDB = kB
2
"
x̸=x′
Jx,x′ ln kxx′
kx′x
+ kB J′ ln 1 −r
r
≥0,
(5.74)
where
J′ = ¯k↓pst
u −¯k↑pst
d = γ (pst
u −r)
(5.75)
is the net current between u and d due to interactions with the information
reservoir. In this interpretation, we recover the familiar expression (5.58) of
the entropy production.
The diﬀerent entropy production rates satisfy the relations
˙Stot
GDB −˙Stot
TAPE = kB γ DKL(pst∥r) ≥0;
˙Stot
MF −˙Stot
TAPE = kB γ
#
H(dev) −H(pst)
&
≥0.
(5.76)
The tightest bound on ˙W is provided by ˙Stot
TAPE. There is no general inequality between
˙Stot
GDB and ˙Stot
MF.
This formalism can be generalized to arbitrary jump networks. If only some states
interact with information reservoirs, the entropy production rates take slightly diﬀerent
forms. For example, if only states d and u undergo information-mediated jumps, we
obtain
˙Stot
TAPE = kB
2
"
x̸=x′
Jx,x′ ln kxx′
kx′x
+ kB γ ¯p
#
H(¯pu) −H(r)
&
≥0,
˙Stot
MF = kB
2
"
x̸=x′
Jx,x′ ln kxx′
kx′x
+ kB γ ¯p
#
H(dev) −H(¯pu)
&
≥0,
(5.77)
where ¯p = pst
d + pst
u and ¯pu = pst
u/¯p. Further, the second equality in eq. (5.75) is replaced
by
J′ = γ ¯p
$¯pu −r
%
.
(5.78)
5.10
Further reading
The formulation of the demon paradox, in Maxwell’s words, can be found in [111,
p. 338]. The original paper by Szilard [162] is translated in [163]. Leﬀand Rex [101]
collect and discuss a number of historically important papers, including Szilard’s paper.
Brillouin [25] contributed to the solution of Maxwell’s paradox; see also Bennett [13,
sec. 5]. Landauer established his principle in [96] and further elaborated on it in [97];
see also Bennett [14]. Sagawa and Ueda [140] originally derived the theory presented
in section 5.4.
The Mandal-Jarzynski machine was introduced in [108]. Bennett [12] introduced
the model of information copying discussed in this chapter, and noted that information
can be copied without dissipation [13, 14]. Sartori and Pigolotti [143] made a distinc-
tion between kinetic and energetic discrimination in copying. Bennett [12], Andrieux

128
Chapter 5
and Gaspard [4], and Sartori and Pigolotti [144] further discussed the dissipation cost
of copying. Sartori et al. [142] proposed the model of sensory adaptation. Barato and
Seifert [7, 8] developed the theory of stochastic thermodynamics with information
reservoirs. The theory was extended by Shiraishi et al. [155]. A parallel development
is due to Horowitz and Esposito [77].
Parrondo et al. [124] review general aspects of information thermodynamics. A
recent review, which also addresses aspects of computation theory, is due to Wolpert
[176].
5.11
Exercises
5.1
Show that the work W performed on a system in contact with a reservoir at
temperature T, initially in an arbitrary distribution px, satisﬁes the inequality
−W ≤Fneq(p) −F,
where Fneq(p) is the nonequilibrium free energy given by eq. (5.2) and F is the
corresponding equilibrium free energy. Also show that
Fneq(p) −F = DKL(p∥peq),
where peq
x is the equilibrium probability distribution.
5.2
Compute the average entropy production rate of a template-assisted polymer-
ization process, eq. (5.23), using the Schnakenberg formula, eq. (3.39).
5.3
Consider a Markovian version of the Mandal-Jarzynski machine described in
section 5.5. The system can be in one of three states x ∈{0, 1, 2}. The energies
of these states are, respectively, ϵ0 = 0, ϵ1 = −ϵ/2, ϵ2 = +ϵ/2, with ϵ > 0. The
jump rates between 0 and the other two states satisfy detailed balance, i.e.,
k01
k10
= k20
k02
= e−ϵ/2kBT.
The intrinsic frequency of these jumps is equal to 1. The system is in contact
with a tape, which controls the jumps between 1 and 2. The jump 2 −→1 can
only take place if the bit on the tape is 0, and if it takes place, the bit is set to 1.
In the same way, the reverse jump can only take place if the bit on the tape is 1,
and if it takes place, the bit is set to 0. These jumps are connected to an exter-
nal weight, so that, if the state jumps from 2 to 1, an amount of work equal
to ϵ is provided to the environment, and if the reverse jump takes place, the
same amount of work is released to the system. The interactions with the tape
take place at random times with frequency γ , and afer each interaction a new
case of the tape is advanced. The fraction of 1s in the incoming tape is r. Thus
the system is described by a master equation with suitable rates, as discussed
in section 5.8. Evaluate the phase diagram of the system in the regime γ ≪1.
Give the expressions of the entropy production rate in the three interpretations
discussed in section 5.9. Generalize to larger values of γ .

Thermodynamics of Information
129
5.4
Consider a system with three states: x ∈{0, 1, 2}, with ϵ1 = ϵ2 = ϵ = 0, ϵ0 =
ϵ > 0. Jumps between 0 and 1 take place in contact with a heat reservoir at
temperature Th, and those between 0 and 2 with a reservoir at temperature
Tc < Th. Jumps between 1 and 2 are assisted by a tape: If the system is in 1
and the bit on the tape is 0, the system switches to 2 and the bit on the tape
is replaced by 1. If the system is in 2 and the bit on the tape is 1, the system
switches to 1 and the bit is replaced by 0. Interactions between the system and
the tape take place at rate γ . The fraction of 1s on the tape is r. Assume that γ
is much smaller than the jump rates between 0 and 1, 2.
Evaluate the entropy production rate and identify the working regimes.
Show that the system can operate as a refrigerator, moving energy from the
lower- to the higher-temperature reservoir while increasing the entropy of the
tape. Identify other possible regimes. Generalize to larger values of γ .
5.5
Consider a two-state system with two edges between the states, labeled by I
and II. Both edges are associated with information-mediated jumps, driven
by interaction with tapes. The fraction of ones in the two incoming tapes are
rI ≤1
2 and rII ≤1
2. The jump rates from 0 to 1 are γIrI for edge I and γIIrII for
edge II. The reverse jump rates are γI(1 −rI) and γII(1 −rII).
Evaluate the entropy production rate. Assuming rI < rII ≤1
2, information is
written on tape I and erased from tape II. Express the eﬃciency of the process
and evaluate it in the regimes γII ≫γI and γII ≪γI, respectively.
5.6
A 1-bit memory is represented by a system with three states: x ∈{−1, 0, +1},
where ϵ±1 = 0 and ϵ0 ≫kBT, and only the jumps 0 ⇋±1 are allowed, all with
equal attempt frequency. The state 0 therefore acts as a barrier between the
±1 states. The dynamics satisﬁes detailed balance. One can erase the con-
tents of the memory by manipulating the energies according to the following
protocol:
1. The energy barrier ϵ0 is continuously lowered to 0.
2. Then the energies ϵ0 and ϵ+1 are tilted by setting ϵ0(t) = −ϵ(t)/2,
ϵ+1(t) = −ϵ(t), where ϵ(t) grows from 0 to a positive value ϵf. This
biases the occupation toward the state +1.
3. The energy barrier ϵ0 is continuously reset to its initial value.
4. Finally, the energy ϵ+1 is continuously reset to its initial value.
The outcome of the process is that, independent of the initial state, the ﬁnal
state of the system is equal to +1 with high probability.
By taking advantage of the relation (4.164), show that, for such a system, the
Landauer bound holds; namely, that the average work W performed on the
system satisﬁes W ≥kBT ln 2.
Give an interpretation of the inverse process and show that it is related to
the Szilard engine.
Evaluate W numerically for diﬀerent values of the duration T of the manip-
ulation and check that the Landauer bound is approached as T →∞. Also
show numerically that the average work W in the reverse process, with the
initial condition px(t0) = δK
x,+1, satisﬁes the inequality W ≥−kBT ln 2, and
interpret this result.

CHAPTER 6
Large Deviations: Theory and Practice
The law of large numbers governs the behavior of empirical averages of random quanti-
ties when the number of realizations is large. It predicts that values of an empirical mean
far from the corresponding theoretical average are extremely unlikely. Large deviation
theory describes how the probability of these improbable events exponentially declines
with the number of realizations. It has a tremendous impact on statistical physics in
general and stochastic thermodynamics in particular. In this chapter, we introduce the
main concepts and results of large deviation theory, focusing on those that are more
useful for stochastic thermodynamics.
6.1
Large deviations in a nutshell
We consider a city in which it rains with probability r on any given day. Rain events
on diﬀerent days are uncorrelated. In a period of T ≫1 day, what is the distribution
of the number τ of rainy days? Alternatively, what is the distribution of the fraction
f = τ/T of rainy days?
With a slight abuse of language, we call observables such as τ extensive, since their
average scales linearly with the observation time T . This deﬁnition is analogous to
extensive quantities in classical thermodynamics, whose value is proportional to the
system size. Similarly, we call variables such as f intensive, since their average does not
depend on T .
To compute the distributions of f (or equivalently of τ), we introduce the variables
x(t), which assume the value 1 if it rains on day t and 0 otherwise. The variable τ =
!T
t=1 x(t) is a sum of independent dichotomous variables and therefore follows the
binomial distribution
pτ(T ) =
"T
τ
#
rτ(1 −r)T −τ.
(6.1)
We wish to describe the behavior of f for large values of T . Since f is a normalized
sum of independent, identically distributed random variables with mean r and vari-
ance r(1 −r), we can invoke the central limit theorem and obtain that its distribution
is approximately Gaussian:
p( f ; T ) ≈
$
T
2π r(1 −r) exp
%
−T ( f −r)2
2r(1 −r)
&
.
(6.2)

Large Deviations: Theory and Practice
131
−2
−1
0
1
2
(f − 8 f 9) T 1/2
0.00
0.25
0.50
0.75
p(f; T )T 1/2
10
30
100
Gaussian
0
r
0.5
1
f
0.0
0.5
1.0
1.5
(b)
(a)
T −1 lnp( f ; T )
10
30
100
I(f )
parabola
Figure 6.1. Binomial distribution, eq. (6.1), for r = 0.25 and different values of T , plotted as
a function of f = τ/T . (a) Rescaling with the average and the variance: y = (f −
'
f
(
) T 1/2.
Already at moderate values of T , the distribution of y is very close to a Gaussian dis-
tribution, in agreement with the central limit theorem. (b) Logarithmic rescaling: I(f ) =
−T −1 ln p(f ; T ). The logarithm of the distribution of f does not approach a parabola, but
rather the rate function I(f ) = f ln(f /r) + (1 −f ) ln[(1 −f )/(1 −r)].
It is instructive to quantitatively compare eq. (6.1) and eq. (6.2) in a concrete case. We
take a time interval of one year, T = 365, and a probability of rain, r = 0.25, compat-
ible with a city like Kansas City where it rains about 91 days per year on average. We
ﬁrst evaluate the probability that it rains for 100 days during a year, slightly more than
the average. The binomial distribution assigns a probability p ≈0.0270 to this event,
compared to p ≈0.0267 for the Gaussian. Thus the Gaussian approximation is rather
good in this case. The approximation of p( f ; T ) by a Gaussian for the case of a bino-
mial distribution is shown in ﬁg. 6.1a. However, the agreement is signiﬁcantly worse
if we consider years where the probability signiﬁcantly departs from the average. For

132
Chapter 6
example, the binomial distribution assigns a probability p ≈9.94 · 10−24 to the event
that it rains for almost half a year in Kansas City, τ = 180. The corresponding prob-
ability according to the Gaussian distribution is p ≈4.9 · 10−27, about three orders of
magnitude smaller.
This example shows that the Gaussian approximation implied by the central limit
theorem can be rather inaccurate on the tails of a distribution, at least in a relative sense.
We wish to circumvent this problem and characterize the distribution of f for large
T , including arbitrarily extreme events. This asymptotic behavior is described by the
function
lim
T →∞
1
T ln p( f ; T ) = −I( f ),
(6.3)
where
I( f ) = f ln f
r + (1 −f ) ln 1 −f
1 −r .
(6.4)
We compactly express this asymptotic behavior by the notation
p( f ; T ) ≍e−T I( f ).
(6.5)
When a relation of the form (6.5) holds for a probability distribution p( f ), we say that
p( f ) satisﬁes a large deviation principle. The function I( f ) is called the rate function
(or also the Cramér function) of the variable f . The rate function I( f ) for the binomial
distribution is shown in ﬁg. 6.1b. The rate function is always nonnegative, vanishes for
f =
'
f
(
, and in most cases is approximated by a parabola when f is close to its average,
in agreement with the central limit theorem. However, the rate function might signiﬁ-
cantly deviate from a parabola when the absolute diﬀerence
)) f −
'
f
()) is large, e.g., on the
order of
'
f
(
itself, as shown in ﬁg. 6.1b for the case of the binomial distribution. These
values of f are called large deviations, to contrast them with the small deviations on the
order of T −1/2 that are ruled by the central limit theorem. Large deviation theory is the
branch of probability theory that studies asymptotic forms of probability distributions
described by eq. (6.5) when a parameter like T becomes large.
It might be useful to further stress the diﬀerence between the central limit theorem
and large deviation theory. In our example, the probability of values of f that are sub-
stantially diﬀerent from the mean decreases exponentially with T . The central limit
theorem essentially ignores these values, as their probability is very small anyway. This
is the reason why the Gaussian approximation to the distribution of f improves as T
grows, regardless of the details of the original distribution (see also the discussion at the
end of appendix A.4). Instead, taking the logarithm of the distribution, as in eq. (6.3),
acts as a magnifying glass on the probability of rare events far from the mean, and
therefore reveals the problem-speciﬁc shape of the tails of p( f ). For this reason, large
deviation theory is sometimes referred to in a pictorial way as “the central limit theo-
rem in logarithmic scale.” The Gaussian behavior is recovered if we perform a Taylor
expansion of the rate function to second order around its minimum:
I( f ) ≈( f −
'
f
(
)2
2˜σ 2
f
,
(6.6)

Large Deviations: Theory and Practice
133
−2
0
2
4
6
q
−1
0
1
2
3
4
ψ(f )(q)
slope r
Figure 6.2. Scaled cumulant generating function ψ(f )(q) associated with a binomially dis-
tributed variable f with r = 0.25; see (6.1). The rate function I(f ) is shown in ﬁg. 6.1b.
The function ψ(f )(q) is obtained from I(f ) by means of the inverse Gärtner-Ellis theo-
rem; see eq. (6.10). The slope of ψ(f )(q) at q = 0 is equal to
'
f
(
, i.e., in our case, to r.
The scaled cumulant generating function is convex and lies between the two asymptotes
y = limf →0 I(f ) = ln r (for q →−∞) and y = limf →1 I(f ) + q = ln(1 −r) + q (for q →+∞).
where ˜σ 2
f is the scaled variance of f , deﬁned by
˜σ 2
f = lim
T →∞T σ 2
f .
(6.7)
The approximation in eq. (6.6) is valid in the range of small deviations governed by the
central limit theorem.
Fluctuations of intensive and extensive quantities can also be studied via the cumu-
lant generating function %( f )(q; T ) = ln
'
eT q f (
= ln ⟨eq τ⟩, discussed in appendix A.4.
For large T , the cumulant generating function grows linearly with T . We extract its
asymptotic behavior by introducing the scaled cumulant generating function
ψ( f )(q) = lim
T →∞
1
T ln
*
eq T f +
= lim
T →∞
1
T %( f )(q; T ).
(6.8)
As the name suggests, the scaled cumulant generating function “rescales” cumulants
with the appropriate power of T , so that they approach a ﬁnite limit as T →∞. The
ﬁrst scaled cumulant ∂qψ( f )(q; T )|q=0 is equal to
'
f
(
, and the second scaled cumulant
∂2
qψ( f )(q; T )|q=0 is equal to the scaled variance ˜σ 2
f introduced in eq. (6.7). As an exam-
ple, we show in ﬁg. 6.2 the scaled cumulant generating function corresponding to the
binomial distribution.
The scaled cumulant generating function contains precious information about large
deviations. Indeed, the Gärtner-Ellis theorem directly links the scaled cumulant gen-
erating function with the rate function of the same random variable. According to this

134
Chapter 6
theorem, if the rate function of f is convex, it can be obtained as the Legendre-Fenchel
transform of ψ( f )(q):
I( f ) = sup
q
,
q f −ψ( f )(q)
-
.
(6.9)
The Legendre-Fenchel transform diﬀers from the Legendre transform by the appear-
ance of the supremum rather than the maximum in its deﬁnition. This generalization
permits us to treat nonconvex or nondiﬀerentiable functions and functions achiev-
ing their supremum for q →∞, as discussed in appendix A.2. The Legendre-Fenchel
transform of a function is convex, and therefore if the rate function I( f ) satisﬁes
eq. (6.9), it is also convex. This is the case of the binomial distribution. For convex
functions, the Legendre-Fenchel transformation is an involution. This means that the
scaled cumulant generating function is also the Legendre-Fenchel transform of the rate
function:
ψ( f )(q) = sup
f
.
q f −I( f )
/
.
(6.10)
It turns out that it is easier to heuristically prove eq. (6.10):
ψ( f )(q) = lim
T →∞
1
T ln
0 ∞
−∞
df P( f ; T ) eT q f
= lim
T →∞
1
T ln
0 ∞
−∞
df e−T [I( f )−q f ] = sup
f
.
q f −I( f )
/
,
(6.11)
where the last equality follows from evaluating the integral using the method
of steepest descent. The Gärtner-Ellis theorem (6.9) then descends from the
fact that the Legendre-Fenchel transformation is an involution on convex func-
tions.
6.2
Currents, trafﬁc, and other observables
The basic observables in stochastic thermodynamics are the stochastic work w(x),
the stochastic heat q(x), and the stochastic entropy production stot(x), introduced in
chapter 3. These quantities are the stochastic counterparts of the conventional macro-
scopic thermodynamic observables; see section 2.1. Practical applications of stochastic
thermodynamics ofen involve a broader range of stochastic observables, such as the
net distance traveled by a molecular motor or the number of ATP molecules consumed
in a chemical reaction.
Large deviation theory is useful in characterizing these observables when measured
in the steady state over a long, but ﬁnite, stretch of time T . As in the previous section, we
call extensive observables those whose average grows proportionally to T . For example,
the observables w, q, and stot are extensive. By dividing an extensive observable by the
duration T , we deﬁne its intensive counterpart, whose average does not depend on T .
We consider, as usual, a mesoscopic system described by a master equation. A
ﬁrst class of observables are the static observables. Extensive static observables are
functionals of the trajectory that are expressed by
A(x) =
1
y
αyτy,
(6.12)

Large Deviations: Theory and Practice
135
where the αs are given coeﬃcients and τy is the empirical dwell time in state y, deﬁned
as the total amount of time spent in state y along the trajectory:
τy(x) =
0 tf
t0
dt δK
y,x(t).
(6.13)
A second class of observables are the dynamic observables. Dynamic observables are
functionals of the trajectory associated with the empirical number of jumps between
pairs of states. A generic extensive dynamic observable is expressed by
J (x) =
1
x̸=x′
nxx′(x) dxx′.
(6.14)
Here the empirical jump numbers nxx′(x) are deﬁned by
nxx′(x) =
n
1
k=1
δK
xxk δK
x′xk−1,
(6.15)
where the xℓs are the sequence of states visited by the trajectory. The matrix dxx′ of dis-
tances fully speciﬁes the functional. Dynamic observables deﬁned by an antisymmetric
distance matrix dxx′ are called integrated empirical currents. Integrated empiri-
cal currents are odd under time reversal (x −→2x). Relevant examples of empirical
currents are
• The entropy change of the heat reservoir sres(x), corresponding to the choice
dxx′ = kB ln(kxx′/kx′x).
• The total entropy production stot, corresponding to dxx′ = kB ln[(kxx′ px′)/
(kx′x px)].
The intensive counterparts of empirical dwell times are the empirical frequencies
fy = τy
T = 1
T
0 tf
t0
dt δK
y,x(t),
(6.16)
whereas the intensive version of integrated empirical currents are the empirical
currents
j = J (x)
T
= 1
T
1
x̸=x′
nxx′(x) dxx′.
(6.17)
We use the symbol jxx′ to denote the particular empirical current between the pair of
states x and x′:
jxx′ = Jxx′(x)
T
= nxx′ −nx′x
T
.
(6.18)
We sometimes consider dynamic observables whose distance matrix dxx′ is symmetric,
and that are therefore even under time reversal. An important example is the traﬃc
between a given pair of states x and x′:
txx′(x) = nxx′(x) + nx′x(x)
T
.
(6.19)

136
Chapter 6
In the steady state, intensive observables associated with static and dynamic observ-
ables of master equations satisfy large deviation principles. The intuitive reason is
that we can then partition a long interval T into smaller time intervals and consider
the contribution to each observable from each of these intervals. Since the dynamics
is Markovian, in the steady state these contributions are weakly correlated random
variables. This means that their sum scales asymptotically with T , like the sum of
independent random variables discussed in section 6.1.
Close to equilibrium, i.e., in the linear response regime, the large deviation functions
of arbitrary currents are approximately parabolic, corresponding to Gaussian distribu-
tions. To prove it, we consider a system in the steady state driven out of equilibrium
by a small driving δ. In the absence of the driving, the system is at equilibrium and
ψ(j)(q) = ψ(j)(−q) because of invariance under time reversal. The driving δ breaks this
symmetry. Thus, for small δ, the scaled cumulant generating function has the form
ψ(q) = ψ+(q) + δ ψ−(q),
(6.20)
where ψ+(q) is an even function and ψ−(q) is an odd function. We assume that both
of these functions are smooth around q = 0, and we expand them in powers of q:
ψ+(q) = ψ2 q2 + ψ4 q4 + . . . ,
ψ−(q) = ψ1 q + ψ3 q3 + . . . ,
(6.21)
where the ψns are given coeﬃcients. We now express the rate function of j by the
Gärtner-Ellis theorem:
I(j) = sup
q
,
q j −ψ(j)(q)
-
= q∗f −ψ(j)(q∗),
(6.22)
where q∗is the solution of the equation ψ′(q∗) = j. Thus the average of j is of order δ.
For ﬂuctuating currents on the order of this average, one has
q∗= j −ψ1 δ
2 ψ2
,
(6.23)
which is also of order δ. Substituting this value into eq. (6.22) and keeping the lowest
order in δ and j, we obtain
I(j) = (j −ψ1 δ)2
4 ψ2
,
(6.24)
of order δ2, neglecting terms of order δ4 and higher. This argument can be generalized
to cases where the system is brought out of equilibrium by several drivings, all assumed
to be small.
Static and dynamic observables can be also introduced for continuous systems
described by Langevin equations. In particular, the continuous version of empirical
integrated currents are linear functionals of the increments dx of the process. From
this perspective, the stochastic heat deﬁned in eq. (3.88) is an empirical integrated cur-
rent. The total entropy production deﬁned in eq. (3.91) is also an empirical integrated
current, provided that the system is in the steady state. The fact that these quantities

Large Deviations: Theory and Practice
137
are deﬁned as Stratonovich products ensures that they are odd under time reversal. In
any case, in this chapter we deal only with systems with discrete states for the sake of
simplicity.
6.3
Large deviations and ﬂuctuation relations
We now apply large deviation theory to the total entropy production stot produced
during a time interval of duration T in a nonequilibrium steady state. We treat stot as an
integrated empirical current of the form of eq. (6.14). We associate with stot an intensive
current, called the empirical entropy production rate:
jtot
s = stot
T .
(6.25)
Switching from the extensive variable stot to the intensive variable jtot
s , the steady-state
integral ﬂuctuation relation (eq. (4.47)) becomes
p(jtot
s ; T )
p(−jtot
s ; T ) = eT jtot
s /kB.
(6.26)
The distribution p(jtot
s ; T ) satisﬁes a large deviation principle:
p(jtot
s ; T ) ≍e−T I(jtot
s ),
(6.27)
where the rate function I(jtot
s ) depends on the speciﬁc system. By expressing p(jtot
s ; T )
in terms of the rate function, eq. (6.26) entails the asymptotic detailed ﬂuctuation
relation
I(jtot
s ) −I(−jtot
s ) = −jtot
s
kB
.
(6.28)
If the distribution of jtot
s
is Gaussian, the rate function is a parabola, and eq. (6.28) yields
2kB
'
jtot
s
(
= ˜σ 2
jtot
s ,
(6.29)
where ˜σ 2
jtot
s = limT →∞T σ 2
jtot
s . Equation (6.29) is another example of a ﬂuctuation-
dissipation relation and can be seen as the intensive counterpart of eq. (3.66). If the
rate function is not quadratic, i.e., if the distribution is not Gaussian, eq. (6.29) does not
hold and eq. (6.28) does not impose any constraint between the mean and the scaled
variance of the empirical entropy production rate.
The asymptotic detailed ﬂuctuation relation, eq. (6.28), can be written in an even
more compact form in terms of the scaled cumulant generating function. To do so, we
apply the inverse form of the Gärtner-Ellis theorem, eq. (6.10):
ψ(js)(q) = sup
js
.
jsq −I(js)
/
= sup
js
%
js
"
q + 1
kB
#
−I(−js)
&
= ψ(js)
"
−q −1
kB
#
.
(6.30)

138
Chapter 6
The relation ψ(q) = ψ(−q −1/kB), valid for intensive variables obeying an asymptotic
detailed ﬂuctuation relation, is ofen called the Gallavotti-Cohen symmetry.
6.4
Fluctuation theorem for currents (*)
In this section, we extend the network theory developed in section 3.9 to empirical
currents. Our starting point is the the irreversibility relation (4.11), which we write in
the form
Px e−stot(x)/kB = P2x,
(6.31)
where Px is the probability of a trajectory x in the steady state,2x is the backward trajec-
tory, and stot(x) = sres(x) + *ssys(x) is the total entropy produced along the trajectory.
We decompose a trajectory x of duration T into loops. A loop is an event in which the
system returns to a previously visited state, having visited a sequence of two or more
distinct states in between. Upon completion of a loop ℓ, the entropy of the reservoir
changes by
sres(ℓ) =
1
α
cα(ℓ) Aα
T ,
(6.32)
where the sum runs over all the fundamental cycles and the Aαs are the aﬃnities asso-
ciated with these cycles; see section 3.9. The coeﬃcient cα(ℓ) is equal to +1 if the loop
goes through the chord of cycle α with the same orientation, is equal to −1 if it goes
through the chord of cycle α with the opposite orientation, and vanishes if the loop
does not go through the deﬁning chord of cycle α. Therefore, the entropy change in the
reservoir associated with a trajectory x can be expressed by
sres(x) =
1
ℓ
sres(ℓ) + srem,
(6.33)
where the sum runs over all loops contained in x and the “remainder entropy” srem
takes into account incomplete loops. Substituting eq. (6.32) into eq. (6.33), we obtain
sres(x) =
1
α
Aα
T nα(x) + srem(x),
(6.34)
where nα(x) is the net number of loops in the trajectory x, including the chord α, count-
ing +1 for the same orientation and −1 for the opposite orientation. Consequently, the
total entropy produced is equal to
stot(x) =
1
α
Aα
T nα(x) + srem(x) + *ssys.
(6.35)
We now evaluate the scaled cumulant generating function of the cycle currents:
ψ(j)(q) = lim
T →∞
1
T ln
3
exp
41
α
qαnα(x)
56
,
(6.36)

Large Deviations: Theory and Practice
139
where j = (jα) and q = (qα). We thus have
ψ(j)
"
q −A
kBT
#
= lim
T →∞
1
T ln
0
Dx Px e
!
α qαnα(x)−stot(x)/kB
= lim
T →∞
1
T ln
0
D2x P2x e
!
α qαnα(x)
= lim
T →∞
1
T ln
0
D2x P2x e−!
α qαnα(2x) = ψ(j)(−q),
(6.37)
where A = (Aα). In the ﬁrst line of eq. (6.37), we neglect contributions from srem(x)
and *ssys, since they are both bounded functions of T and therefore do not contribute
to the scaled cumulant generating function. We also use eq. (6.31) in going from the
ﬁrst to the second line. Thus ψ(j)(q) exhibits the Gallavotti-Cohen symmetry under
the transformation
7
q −A/kBT
8
←→−q.
We now show that the Onsager reciprocity relations (4.28) follow from this symme-
try. The average cycle current Jα is expressed by
Jα(A) =
'
jα
(
= ∂ψ(j)
∂qα
)))))
q=0
,
(6.38)
where ψ(j)(q) is evaluated with the given value of A. For small activities, we expand
the current as in eq. (4.35), Jα(A) = !
β LαβAβ + o(A), thus introducing the matrix
L = (Lαβ) of kinetic coeﬃcients. We have therefore
Lαβ =
∂2ψ(j)
∂qα ∂Aβ
)))))
q=0,A=0
.
(6.39)
Taking advantage of the Gallavotti-Cohen symmetry, we obtain
∂2ψ(j)
∂qα ∂Aβ
)))))
q,A
= 1
kBT
∂2ψ(j)
∂qα ∂qβ
)))))
−q−A/kBT,A
−
∂2ψ(j)
∂qα ∂Aβ
)))))
−q−A/kBT,A
.
(6.40)
Setting q = A = 0, we obtain the Onsager reciprocity relations:
Lαβ =
1
2kBT
∂2ψ(j)
∂qα ∂qβ
)))))
q=0,A=0
= Lβα.
(6.41)
Further relations can be obtained by considering higher-order terms in the expansion
of J in powers of A. In this sense, one may interpret the Gallavotti-Cohen symmetry as
the generalization of the Onsager reciprocity relations beyond linear response.

140
Chapter 6
6.5
Tilting
We have seen that the scaled cumulant generating function of an observable such
as an empirical current contains precious information about large deviations. Unfortu-
nately, it is ofen diﬃcult to compute the scaled cumulant generating function directly.
A mathematical technique that substantially simpliﬁes this task is tilting. To introduce
tilting, we ﬁrst deﬁne the generating function of a current j conditioned to a ﬁnal state x:
φ(j)
x (q; t) =
*
eqT j))) x(t) = x
+
=
0
Dx Px δK
x,x(t) eqT j(x).
(6.42)
The standard generating function is retrieved by summing over the ﬁnal state:
φ(j)(q; t) = !
x φ(j)
x (q; t). We explicitly write the trajectory probability Px in eq. (6.42):
φ(j)
x (q; t) =
0
Dx δK
x,xn eq !n
k=1 dxkxk−1 kxxn−1e−kout
xn (t−tn−1) · · ·
· · · × e−kout
x1 (t2−t1)kx1x0e−kout
x0 (t1−t0) px0(t0)
=
0
Dx e−kout
x (t−tn−1) 9
kxxn−1eqdxxn−1
:
· · ·
· · · ×
9
kx1x0eqdx1x0
:
e−kout
x0 (t1−t0) px0(t0),
(6.43)
where we use the deﬁnition (6.14) of an integrated empirical current as a sum of dis-
tances associated with each observed jump. Equation (6.43) expresses the conditioned
generating function of an empirical current in terms of a “modiﬁed” trajectory proba-
bility, where each jump rate kxx′ is multiplied by a factor eqdxx′. As a consequence, the
conditioned generating function evolves according to a tilted master equation:
d
dtφ(j)
x (q; t) =
1
x′ (̸=x)
kxx′ eq dxx′φ(j)
x′ (q; t) −kout
x φ(j)
x (q; t).
(6.44)
The outﬂow terms in the master equation (6.44) are the same as in the original master
equation, since in eq. (6.43) the factors corresponding to the dwell times are unaltered.
Equations (6.43) and (6.44) embody the basic idea of tilting. The term tilting comes
from the observation that increasing q creates an imbalance in the rates of eq. (6.44)
similar to the eﬀect of tilting an external potential. We write eq. (6.44) in a more compact
form:
d
dtφ(j)
x (q; t) =
1
x′
Lxx′(q) φ(j)
x′ (q; t),
(6.45)
where the tilted generator is given by
Lxx′(q) =
;
kxx′ eqdxx′,
if x ̸= x′;
−kout
x ,
if x = x′.
(6.46)
In general, the tilted generator does not satisfy !
x Lxx′(q) = 0, and therefore the tilted
master equation (6.44) does not preserve normalization. This reﬂects the fact that the

Large Deviations: Theory and Practice
141
conditioned generating function φ(j)
x (q; t) does not need to be normalized. The formal
solution of eq. (6.45) reads
φ(j)
x (q; t) =
1
x′
.
exp
7
(t −t0) L(q)
8/
xx′ px′(t0).
(6.47)
For long times, the behavior of φx(q, tf) is dominated by the largest eigenvalue λmax(q)
of the tilted generator:
φ(j)
x (q; t) ≍e(t−t0) λmax(q).
(6.48)
We now switch to the scaled cumulant generating function ψ(j)(q) introduced in
eq. (6.8). Combining eqs. (6.48) and (6.8), we obtain
ψ(j)(q) = lim
T →∞
1
T ln
1
x
φ(j)
x (q; T ) = λmax(q).
(6.49)
Therefore, to ﬁnd ψ(j)(q), we only need to compute the largest eigenvalue λmax(q) of the
tilted generator. The Perron-Frobenius theorem ensures that this eigenvalue is always
real and nondegenerate; see appendix A.5.
In practice, the largest eigenvalue λmax(q) can be obtained by diagonalizing the tilted
generator as a function of q, at least when the number of states is small. However, this
task can become computationally unfeasible for a large number of states. If we are only
interested in the lowest-order scaled cumulants of the current, an explicit diagonal-
ization of the tilted generator can be avoided in the following way. The characteristic
equation associated with the tilted generator is
det
7
L(q) −λI
8
=
N
1
r=0
ar(q)λr = 0,
(6.50)
where I is the identity matrix. The maximum eigenvalue satisﬁes λmax(0) = 0 since,
for q = 0, the tilted generator reduces to the generator of the original master equation,
for which the maximum eigenvalue vanishes due to the normalization condition. We
therefore need to compute the derivatives with respect to q of the particular solution
of eq. (6.50) satisfying this property, and evaluate them in q = 0. We can conveniently
evaluate these derivatives by applying the implicit function theorem to the characteristic
polynomial
g(λ, q) =
N
1
r=0
ar(q)λr = 0.
(6.51)
For example, the ﬁrst two scaled cumulants can be obtained from the expressions
d
dq g(λ(q), q) = ∂g
∂λ
∂λ
∂q + ∂g
∂q = 0;
d2
dq2 g(λ(q), q) = ∂2g
∂λ2
"∂λ
∂q
#2
+ ∂g
∂λ
∂2λ
∂q2 + 2 ∂2g
∂λ∂q
∂λ
∂q + ∂2g
∂q2 = 0.
(6.52)

142
Chapter 6
Both derivatives are equal to zero since the function g(λ(q), q) vanishes for all values
of q. Solving the ﬁrst equation for ∂λ/∂q and the second for ∂2λ/∂q2, and evaluating
them for λ = q = 0, we obtain
'
j
(
= ∂λ
∂q
))))
λ=q=0
= −1
a1
∂a0
∂q
))))
q=0
,
˜σ 2
j = ∂2λ
∂q2
))))
λ=q=0
= −1
a1
4
∂2a0
∂q2
))))
q=0
+ 2
'
j
( ∂a1
∂q
))))
q=0
+ 2
'
j
(2 a2
5
,
(6.53)
where we evaluate derivatives using eq. (6.51). This trick allows us to evaluate cumulants
without having to compute the maximum eigenvalue.
An alternative strategy is to evaluate λmax(q) numerically by means of eq. (6.49). We
deﬁne the matrix ¯Lxx′ = δK
xx′ + *t Lxx′, with *t > 0 and small enough so that the matrix
¯L has nonnegative entries. Its largest eigenvalue ¯λmax(q) is equal to 1 + *t λmax(q). By
repeatedly applying ¯L to an arbitrary initial vector φ(0) = (φ(0)
x ) with positive entries,
we obtain, for large n,
¯Lnφ(0) ∼
7¯λmax(q)
8n φmax,
(6.54)
where φmax is the right eigenvector of ¯L corresponding to ¯λmax(q). Therefore,
¯λmax(q) = lim
n→∞
<1
x
9
¯Ln+1φ(0):
x
= 1
x′
9
¯Lnφ(0):
x′
>
.
(6.55)
We can then evaluate the maximum eigenvalue of the tilted generator by the expres-
sion λmax(q) = (¯λmax(q) −1)/*t. For large matrices, eﬃcient numerical methods are
available, like the Arnoldi-Lanczos method.
We apply the tilting method to speciﬁc problems in the next two sections.
6.6
Michaelis-Menten reaction scheme
In the stochastic Michaelis-Menten reaction scheme, a reactant A is transformed
into a product B with the aid of a catalytic enzyme E. In chemical kinetics, complex for-
mation is usually considered a reversible reaction, whereas product formation is ofen
taken as irreversible. Here we consider a more general case in which both processes are
reversible, i.e., the enzyme can reversibly form a complex E∗with either A or B. This
choice makes the model thermodynamically consistent. The full reaction scheme is
A + E
k+
1⇌
k−
1
E∗k+
2⇌
k−
2
B + E,
where E∗is the bound enzyme. We consider a scenario in which there is only one
enzyme molecule and the average concentrations of A and B molecules are maintained
constant by chemostats. The balance of the reaction is determined by the ratio

Large Deviations: Theory and Practice
143
k+
1 k+
2
k−
1 k−
2
= e(−ϵ+µA−µB)/kBT = e−*G/kBT,
(6.56)
where ϵ is the energy diﬀerence between the reactant and the product, µA and µB
are the chemical potentials of A and B, respectively, and *G = −ϵ + µA −µB is the
diﬀerence in the Gibbs free energy between one molecule of B and one molecule of
A. This free-energy diﬀerence eﬀectively drives the reaction: equilibrium is attained
when *G = 0. We parameterize the reaction rates by the intrinsic rates ω1, ω2 and the
activation barrier ϵ∗for the reaction A + E →E∗. Generalized detailed balance dictates
k+
1
k−
1
= e(−ϵ∗+µA)/kBT;
k+
2
k−
2
= e(−ϵ+ϵ∗−µB)/kBT.
(6.57)
We choose rates satisfying these conditions:
k+
1 = ω1 e(2µA−ϵ∗)/2kBT;
k−
1 = ω1 eϵ∗/2kBT;
k+
2 = ω2 e−(ϵ−ϵ∗)/2kBT;
k−
2 = ω2 e(2µB+ϵ−ϵ∗)/2kBT.
(6.58)
We also assume that the second reaction is much slower than the ﬁrst, ω2 ≪ω1. We
describe the evolution of the catalysis by the number n of B molecules synthesized since
an arbitrary initial time. Since the reaction is reversible, n can become negative, i.e., at
a given time there can be fewer B molecules than at the initial time. We denote the
enzyme state by 0 if it is free and by 1 if it is bound. The master equation reads
dp0n
dt = k−
1 p1n + k+
2 p1,n−1 −
7
k+
1 + k−
2
8
p0n;
dp1n
dt = k+
1 p0n + k−
2 p0,n+1 −
7
k−
1 + k+
2
8
p1n.
(6.59)
We call p = !
n p1n the probability that the enzyme is bound at a given time. From the
master equation, this probability evolves according to
dp
dt =
7
k+
1 + k−
2
8 7
1 −p
8
−
7
k−
1 + k+
2
8
p,
(6.60)
whose steady-state solution is
pst =
"
1 + k−
1 + k+
2
k+
1 + k−
2
#−1
.
(6.61)
Using the generalized detailed balance conditions (6.56) and our assumption that
ω2 ≪ω1, we approximate the steady-state probability by
pst =
e(µA−ϵ∗)/kBT
1 + e(µA−ϵ∗)/kBT .
(6.62)

144
Chapter 6
Given the binding energy ϵ∗and the chemical potential µA of the ligand, the average
production rate of B in the steady state is given by
⟨˙nB⟩= k+
2 pst −k−
2 .
(6.63)
We now analyze the large deviations of the catalysis rate in the steady state by adapt-
ing the tilted dynamics introduced in section 6.5. We introduce a two-component
generating function
φα(q, t) =
+∞
1
n=−∞
eq(n+α/2)pα,n(t),
(6.64)
where α ∈{0, 1}, and we conventionally assign a half-integer value of n to the states
where the enzyme is bound. From eq. (6.59), we obtain
d
dt
"
φ0
φ1
#
= L(z)
"
φ0
φ1
#
,
(6.65)
where z = eq/2 and the tilted generator is given by
L(z) =
4
−
7
k+
1 + k−
2
8
,
z−1k−
1 + zk+
2
zk+
1 + z−1k−
2 ,
−(k−
1 + k+
2 )
5
.
(6.66)
Importantly, z only appears in the oﬀ-diagonal elements, and determines the eigenval-
ues of L(z) only via their product:
0(z) = z2k+
1 k+
2 + k−
1 k+
1 + k−
2 k+
2 + z−2k−
1 k−
2 .
(6.67)
The eigenvalues of L(z′) are the same as those of L(z) if z′ is such that it exchanges the
values of the ﬁrst and last term:
z′2k+
1 k+
2 = z−2k−
1 k−
2 ,
(6.68)
z2k+
1 k+
2 = z′−2k−
1 k−
2 ,
(6.69)
from which we obtain
z′2 = k−
1 k−
2
k+
1 k+
2 z2 .
(6.70)
Taking into account eq. (6.56) and substituting z = eq/2, we ﬁnd that the eigenvalues are
invariant under the transformation
q −→q′ = *G
kBT −q.
(6.71)
At equilibrium, where *G = 0, this transformation reduces to q −→−q.
We denote by λmax(q) the leading eigenvalue of L. The generating function of the
number of processed molecules n is a linear combination of φ0 and φ1 and therefore

Large Deviations: Theory and Practice
145
scales exponentially with T λmax(q):
φ(n)(q; t) =
1
n
eqn[p0,n(t) + p1,n(t)] = φ0(q) + e−q/2φ1(q) ≍eT λmax(q).
(6.72)
The number of products n grows linearly with T on average. We associate with it an
intensive observable ˙n = n/T , which we interpret as the empirical production rate. On
the one hand, the scaled cumulant generating function of ˙n is equal to
ψ(˙n)(q) = lim
T →∞
1
T ln φ(˙n)(q; t) = λmax(q).
(6.73)
On the other hand, we have seen that
λmax(q) = λmax
"*G
kBT −q
#
.
(6.74)
Equation (6.74) embodies the Gallavotti-Cohen symmetry for the intensive variable ˙n;
see also eq. (6.30).
The explicit expression of the maximum eigenvalue is
λmax(q) = −1
2
,
k+
1 + k−
1 + k+
2 + k−
2
(6.75)
−
?7
k+
1 + k−
1 + k+
2 + k−
2
82 + 4
7
1 −e−q8 7
k+
1 k+
2 eq −k−
1 k−
2
8&
.
This expression behaves asymptotically as
λmax(q) ≈



?
k+
1 k+
2 eq/2,
for q →+∞;
?
k−
1 k−
2 e−q/2,
for q →−∞.
(6.76)
We use this result to evaluate the average production rate ⟨˙n⟩via the relation
⟨˙n⟩= dλmax
dq
))))
q=0
.
(6.77)
An explicit evaluation of the derivative leads to the expression
⟨˙n⟩=
k+
1 k+
2 −k−
1 k−
2
k+
1 + k−
1 + k+
2 + k−
2
.
(6.78)
The average production rate ⟨˙n⟩vanishes at equilibrium, when eq. (6.56) is satisﬁed. In a
similar way, one can obtain the scaled variance of ˙n and scaled cumulants of high order.
Since the derivative dλmax/dq can take any real value for large enough
))q
)), the empirical
production rate ˙n is also unbounded. The Legendre-Fenchel transform of λmax(q) is the
rate function of ˙n:
p(˙n; T ) ≍e−T I(˙n),
(6.79)

146
Chapter 6
where
I(˙n) = sup
q
.˙n q −λmax(q)
/
.
(6.80)
We obtain, for large values of |˙n|,
I(±˙n) ≈2 |˙n|

ln
2 |˙n|
?
k±
1 k±
2
−1

.
(6.81)
By this technique, one can also evaluate the rate function of the entropy production rate
jtot
s
and verify the asymptotic detailed ﬂuctuation relation (6.28).
6.7
Fluctuation relations in a model of kinesin (*)
Molecular motors are important proteins that perform work inside cells by consum-
ing chemical energy; see section 3.4. They are a paradigmatic example of biomolecules
that can be studied with the tools of stochastic thermodynamics.
In this section, we study a model of kinesin, which is a molecular motor that walks
on a microtubule—a hollow tubular structure that forms the cytoskeleton. The role
of kinesin is to transport cargo along microtubules from the center of the cell to its
periphery. The motion of kinesin proceeds in discrete, reversible steps. In the model,
we subdivide each step along the microtubule into two states: a low-energy state x = 0,
to which we conventionally assign an energy ϵ0 = 0, and a high-energy state x = 1,
with energy ϵ1 = ϵ > 0. We jointly represent the state of the motor and its position on
the microtubule by an integer variable r. An increment of r by one corresponds to a
half step of the motor, so that the motor is in state 0 at even-numbered coordinate r
and in state 1 at odd-numbered coordinate r. We call d the physical distance on the
microtubule corresponding to a half step.
There are four possible jumps connecting states 0 to states 1, each with its corre-
sponding reverse jump, as shown in ﬁg. 6.3a:
A: From a low-energy state, the motor makes a half step to the lef, with rate k←
0 ,
without consuming ATP. In the reverse jump, it moves a half step to the right
from a high-energy state with rate k→
1 .
B: From a low-energy state, the motor consumes one molecule of ATP and moves
a half step to the lef, with rate k↖
0 . In the reverse jump, it produces one molecule
of ATP from a high-energy state and moves a half step to the right, with rate k↘
1 .
C: From a low-energy state, the motor consumes one molecule of ATP and moves
a half step to the right, with rate k↗
0 . In the reverse jump, the motor produces
one molecule of ATP from a high-energy state and moves a half step to the lef,
with rate k↙
1 .
D: From a low-energy state, the motor moves a half step to the right, with rate
k→
0 , without consuming ATP. In the reverse jump, it moves a half step to the
lef from a high-energy state, with rate k←
1 .
Summarizing, jumps A and D represent spontaneous diﬀusion of the motor along
the microtubule without the aid of ATP, whereas B and C are the corresponding jump
rates with the use of ATP. In particular, jumps B and C are assisted by the same ATP

Large Deviations: Theory and Practice
147
0
0
1
(a)
(b)
n
0
1
2
r
1
1
1
0
A
C
D
B
1
1
0
A
B
C
D
k1
k1
k0
k0
k0
k0
k1
k1
C0
C1
C2
Figure 6.3. Kinesin model. (a) The four possible pathways connecting a state 0 to a
state 1, represented in the (r, n) plane, where r denotes the position of the motor on
the microtubule and n is the net number of ATP molecules consumed since the initial
time. Equivalent jumps in different locations of the (r, n) plane are represented by dashed
arrows. See Lacoste et al. [94]. (b) The jump network of the model. The spanning tree,
which coincides with the A edge, is marked in bold. The cycle labels are placed close to
the corresponding chords.
reservoir. We call *µ the ATP-to-ADP chemical potential imbalance; see section 3.5.
The motor is subject to a force f , considered positive in the sense of positive rs. The jump
rates kα
x (x ∈{0, 1}, α ∈{←, ↖, ↗, →, ↘, ↙}) satisfy the generalized detailed balance
conditions
k←
0
k→
1
= e(−ϵ−fd)/kBT;
k↖
0
k↘
1
= e(−ϵ−fd+*µ)/kBT;
(6.82a)

148
Chapter 6
k↗
0
k↙
1
= e(−ϵ+fd+*µ)/kBT;
k→
0
k←
1
= e(−ϵ+fd)/kBT.
(6.82b)
In terms of these rates, the steady-state probability distribution is
pst
0 =
!
α kα
1
!
α,x kαx
;
pst
1 =
!
α kα
0
!
α,x kαx
.
(6.83)
We identify the fundamental cycles in the jump network following the method of
section 3.9; see ﬁg. 6.3b. We choose the edge A as the spanning tree. The corresponding
fundamental cycles are outlined below.
C0: Formed by A and B. If run counterclockwise, it corresponds to moving a half
step to the lef with the consumption of one ATP molecule, and then a half step
to the right without consuming ATP.
C1: Formed by A and C. Run counterclockwise, it corresponds to moving a half
step to the right with the consumption of one ATP molecule, and then a half
step again to the right without use of ATP.
C2: Formed by A and D. Run counterclockwise, it corresponds to a full step to the
right without use of ATP.
We associate the aﬃnities A0,1,2 with these three cycles. Taking into account (6.82), we
obtain
A0 = kBT ln k↖
0 k→
1
k←
0 k↘
1
= *µ;
A1 = kBT ln k↗
0 k→
1
k←
0 k↙
1
= −2fd + *µ;
A2 = kBT ln k→
0 k→
1
k←
0 k←
1
= −2fd.
(6.84)
Although there are three fundamental cycles, two currents are particularly inter-
esting: the displacement velocity and the degradation rate of ATP. We evaluate the
steady-state currents J(r) = d ⟨r⟩/dt and J(n) = d ⟨n⟩/dt, where n is the number of ATP
molecules consumed since the initial time. We express the steady-state currents in terms
of the cycle currents Jα, α ∈{0, 1, 2}:
J(r) = J1 + J2;
J(n) = J0 + J1.
(6.85)
We are now in a position to draw a phase diagram by identifying the lines in which the
steady-state currents change sign (ﬁg. 6.4). The most relevant working regimes are the
following:

Large Deviations: Theory and Practice
149
−10
−5
0
5
fd
−10
0
10
20
Δµ
A
B
D
C
J(r) = 0
J(n) = 0
Figure 6.4. Phase diagram of the molecular motor in the (fd, *µ) plane, obtained by ana-
lytically evaluating the currents J(r,n) in the steady state. The axes (dotted) and the lines
J(r) = 0 (solid) and J(n) = 0 (dashed) partition the plane into eight regions. The most rele-
vant ones are A, where J(r) > 0 and J(n) < 0, with f < 0 and *µ > 0, and the system works
as a motor, producing work via ATP hydrolysis; B, where it synthesizes ATP exploit-
ing mechanical work; the narrow C region, where it exploits ADP in excess to perform
mechanical work; and D, where the system produces ADP from molecular work. In the
unshaded areas, the system acts as a dud. See Lacoste et al. [94].
A: In this regime, the system consumes ATP to produce work, therefore operating
as a proper molecular motor. This regime is characterized by f < 0, *µ > 0,
J(n) > 0, and J(r) > 0, i.e., the motor proceeds against the applied force.
B: In this regime, the motor exploits the applied force and uses up the mechanical
work to produce ATP molecules, J(r) < 0 and J(n) > 0.
C: Here the motor exploits ADP in excess to perform mechanical work against
a positive force. This regime occupies a narrow region of the phase diagram,
bounded by the f = 0 and J(n) = 0 lines.
D: In this regime, the motor produces ADP in excess from molecular work.
In the remaining four areas, unshaded in the ﬁgure, one has both f J(r) < 0 and
*µ J(n) < 0, and therefore the motor does not produce anything useful and can be
considered a dud.
In the steady state, the average entropy production rate is given by
T ˙S = A0 J0 + A1 J1 + A2 J2 = −2fd J(r) + *µ J(n).
(6.86)
We characterize the ﬂuctuations of the currents j(r), j(n) via the cumulant generating
function
ψ(r,n)(qr, qn) = lim
tf→∞
1
T ln
I
exp
%0 tf
t0
dt
9
qrj(r)(t) + qnj(n)
t
:&J
.
(6.87)

150
Chapter 6
−10
−5
0
5
10
15
qr
−20
−10
0
10
qn
(−fd, −µ/2)
Figure 6.5. Contour plot of the cumulant generating function ψ(jr,jn)(qr, qn), exhibiting
the Gallavotti-Cohen symmetry under the transformation (6.90). The invariant point of
the transformation is shown. The zero-level contour is highlighted. We have set fd = −3,
*µ = 13, and kBT = 1.
We have seen in section 6.5 that ψ(r,n)(qr, qn) is equal to the maximum eigenvalue of
the generator of the tilted dynamics. In our case, the generator is the matrix
L(qr, qn) =
"
L00,
L01
L10,
L11
#
,
(6.88)
where
L00 = −(k←
0 + k↖
0 + k↗
0 + k→
0 );
L01 = k→
1 eqx + k↘
1 e−qn+qx + k↙
1 e−qn−qx + k←
1 e−qx;
L10 = k←
0 e−qx + k↖
0 eqn−qx + k↗
0 eqn+qx + k→
0 eqx;
L11 = −(k→
1 + k↘
1 + k↙
1 + k←
1 ).
(6.89)
One can verify that, due to the generalized detailed balance conditions (6.82), the
determinant of L, and therefore its leading eigenvalue, remains unchanged under the
transformation (qr, qn) −→(q′
r, q′
n), where
q′
r = −2fd
kBT −qr;
q′
n = −*µ
kBT −qn.
(6.90)
This transformation represents the Gallavotti-Cohen symmetry for this system, as
shown in ﬁg. 6.5.

Large Deviations: Theory and Practice
151
6.8
Cloning (*)
In principle, observables of a master equation can be studied by stochastic simula-
tions, for example, using the Gillespie method reviewed in appendix A.6 and sampling
observables along the simulation. However, this approach is not practical if we are inter-
ested in large deviations: probabilities of large ﬂuctuations become exponentially small
over time, therefore simulations of any reasonable length are unlikely to sample them.
The tilting method introduced in section 6.5 provides an alternative to computing
scaled cumulant generating functions and hence rate functions. However, extracting
leading eigenvalues of very large tilted matrices can also be computationally prohibitive.
An ideal way out would be to perform some kind of stochastic simulation of the tilted
process. Unfortunately, the tilted dynamics introduced in eq. (6.44) does not conserve
the normalization of φx(q; t). Therefore, it cannot be associated with a master equation
nor with any other stochastic process that conserves probability.
A solution to this problem is cloning. Cloning algorithms simulate in parallel a pop-
ulation of N systems, which we call clones. Each clone evolves according to stochastic
dynamics. During the dynamics, clones can be stochastically “pruned” or “copied,” in a
way to account for changes in statistical weights. To understand how cloning works, we
provide the following deﬁnitions:
• The tilted jump rate kxx′(q) = kxx′ eqdxx′;
• The tilted escape rate kout
x (q) = !
x′ (̸=x)kx′x(q);
• The tilted dwell-time distribution ρx(t; q) = kout
x (q) e−kout
x (q) t;
• The weights Yx(t; q) = e(kout
x (q)−kout
x )t.
Substituting these deﬁnitions into eq. (6.43), we rewrite the generating function of a
current conditioned to a ﬁnal state x as
φ(j)
x (q, t) =
0
Dx δK
x,xn ρxn(t −tn; q) Yx(t −tn; q) kxnxn−1(q)
kout
xn−1(q)
× ρxn−1(tn −tn−1; q) Yxn−1(tn −tn−1; q) · · · kx2x1(q)
kout
x1 (q)
(6.91)
× ρx1(t2 −t1; q)Yx1(t2 −t1; q)kx1x0(q)
kout
x0 (q) ρx0(t1; q)Yx0(t1) px0(t0).
The initial distribution px0(t0) is usually chosen as the steady-state distribution,
although this choice becomes irrelevant in the long time limit in which we are
interested.
We numerically sample eq. (6.91) by introducing and evolving a population of N
clones, where N is suﬃciently large. At any given time t, each clone α is characterized
by its state xα and the time τ α of its next jump. At the initial time t0, the state xα of
each clone α is independently drawn from the initial probability distribution px(t0). We
then draw, for each clone, the waiting time *tα to its next jump from the probability
distribution ρxα(*t; q), and we set the time τ α of the next jump to t0 + *tα. We then
iterate the following procedure:
1. Identify the clone α∗with the smallest value of τ α.
2. Advance the time t to τ α∗.

152
Chapter 6
3. Update the state xα∗of the clone α∗to x, where x is drawn from the probability
distribution px|xα∗= kxxα∗(q)/kout
xα∗(q).
4. Set the time τ α∗of the next jump of clone α∗to t + *t, where *t is drawn
from the probability distribution ρx(*t; q).
5. Evaluate the weight Yx(*t) = exp
.7
kout
x (q) −kout
x
8
*t
/
.
6. Copy the clone into approximately Yx(*t) other clones. More precisely:
i. Evaluate y = ⌊Yx(*t) + ε⌋, where ε is a uniformly distributed random
number between 0 and 1 and ⌊z⌋is the largest integer not exceeding z.
ii. If y = 0, remove clone α∗from the population. Otherwise, if y > 1, add
y −1 copies of clone α∗to the population. If y = 1, go to step 8.
7. Resize the population to N. More precisely: If y = 0, pick up a random clone
and add a copy of it to the population. Otherwise, if y > 1, pick up at random
(without replacement) N clones among the N + y −1 available to form the new
population.
8. Store the rescaling factor X = N/(N + y −1).
As the name suggests, the rescaling factor X is related to the fraction of clones
other than α∗that are modiﬁed at each step in order to maintain the clone popula-
tion size equal to N. In other words, if we were simply eliminating clones (when y < 1)
and adding new clones (when y ≥1) without replacing random clones, the population
size would grow by a factor of X−1 at each jump. Therefore, to the leading order, the
generating function grows with the inverse product of the rescaling factors
φ(j)
x (q, t) ≍(X1X2 · · · Xn)−1 ,
(6.92)
where the Xk are the factors X associated with each jump. It follows that the scaled
cumulant generating function can be expressed as
ψ(q) = −lim
t→∞
1
T ln (X1X2 · · · Xn) .
(6.93)
Scaled cumulant generating functions of static observables can also be esti-
mated using cloning. We consider the generating function for an observable A(x) =
K t
t0 dt′ ax(t′), whose intensive version is a = A/T . As for dynamic observables, the strat-
egy is to express the scaled cumulant generating function as an average over trajectory
probabilities:
φ(a)
x (q; t) =
0
Dx Px δK
x,xneqA(x)
=
0
Dx e−(kout
x −ax)(t−tn−1)kxxn−1 · · ·
· · · × kx1x0e−(kout
x0 −ax0)(t1−t0) px0(t0).
(6.94)
In this case, the tilted and the original jump rates are equal, whereas dwells of duration
*t in state x yield contributions eqax *t to the generating function. Accordingly, we
deﬁne the weights by

Large Deviations: Theory and Practice
153
Yx(*t) = eqax *t.
(6.95)
By ﬁxing q in the cloning procedure, we condition the system to exhibit exceptional
values of a given observable, e.g., a current. In some cases, we are interested in averages
of other observables in this exceptional ensemble. We might be tempted to evaluate
them by averaging over the clone population that we obtain as time goes on. However,
since the dynamics does not preserve normalization, the distribution of clones at a given
time cannot be interpreted as the desired conditioned stationary distribution.
To obtain averages of observables at intermediate times t, we must therefore use a
diﬀerent method. We describe it for the example of static observables. The cloning algo-
rithm is implemented as previously explained, but when the ﬁrst jump time tk afer t is
reached, the value axα of the observable is attached to each clone α. This value is copied
whenever the clone or its descendant is copied. Then we evaluate averages of axα over
the surviving clones at the end of the process. This may yield a rather noisy result, since
the surviving clones may have only a few ancestors at time t. It is therefore preferable to
evaluate integrated quantities, like
*K tf
t0 dt ax(t)
+
/T , which are less noisy. These observ-
ables can be similarly obtained by attaching the accumulated value of the integral to
each copy of a clone.
The scaled cumulant generating function ψ(a)(q) of a given observable a can be
evaluated with the basic cloning algorithm. There is however a computationally more
eﬃcient procedure, called thermodynamic integration, based on the algorithm we just
described. To introduce thermodynamic integration, we ﬁrst deﬁne the tilted average
⟨a⟩q = dψ(a)(q)
dq
≍
'
a e−qT a(
'
e−qT a( .
(6.96)
Numerically, the tilted average is estimated by the mean of a = A/T over the popula-
tion of clones with a suitably large value of T . From the tilted average, we can estimate
ψ(q) by
ψ(q) =
0 q
0
dq′ ⟨a⟩q′ .
(6.97)
The advantage of this procedure is that the integration smooths out the noise.
This method has been applied to study the large deviations in the asymmetric sim-
ple exclusion process with periodic boundary conditions. In this process, N particles
are placed on a one-dimensional lattice of L sites, with N < L and no more than one
particle per site. Particles can jump to the next site to the right with rate kR and to the
lef with rate kL. Jumps can only take place if the target site is empty. Each jump con-
tributes +1 to the current if it is to the right and −1 if it is to the lef. The evaluation
of the large deviation function of the current by the tilting method rapidly becomes
unfeasible as L grows. In fact, tilting requires the evaluation of the leading eigenvalue
of a matrix of size N × N , where N = L!/((L −N)!N!) is the number of states. This
number grows exponentially with L at constant N/L. Therefore, the cloning method is
more advantageous for large values of L. In practice, by running calculations limited
to a few hours on a desktop computer, one can reach L ≈20 using tilting and L ≈400
using cloning (ﬁg. 6.6). Comparing the results for diﬀerent values of L, we ﬁnd small
but signiﬁcant diﬀerences due to the size dependence of the rate function.

154
Chapter 6
−4
−2
0
2
4
q
0
10
20
ψ (q)/L
L = 20 (tilting)
L = 100
L = 400
Figure 6.6. Scaled cumulant generating function ψ(q)/L for the current in an asymmetric
simple exclusion process with periodic boundary conditions. The jump rates are kR = 1.2
and kL = 0.6. Dashed line: Result of an evaluation by the tilting method for a system with
L = 20 cases and N = 10 particles. Open circles: Result of a cloning simulation for L = 100
and N = 50. Filled circles: Result of a cloning simulation for L = 400 and N = 200. The
function is symmetric around q∗= ln(kL = kR)/2 ≈−0.35.
6.9
Levels of large deviations (*)
Stochastic processes can be characterized by quantities other than the static and
dynamic observables introduced in section 6.2. A function of the instantaneous state
of the system, such as the system energy ϵx(t) in stochastic thermodynamics, is one
such example. More generally, one may consider observables that are functionals of
long chunks of trajectories. To treat this broader set of observables, it is useful to intro-
duce a hierarchy of levels of large deviations. Higher levels in this hierarchy correspond
to a more detailed statistical description of trajectories:
• Level 1 includes the large deviation principles for functions of the instanta-
neous state of the system; for example, the energy ϵx.
• Level 2 describes the static observables introduced in section 6.2. The central
observable of level 2 large deviations is the empirical vector f = ( fx), where fx
is the empirical frequency deﬁned by eq. (6.16).
• Level 3 encompasses the large deviation principles associated with observables
deﬁned on sequences of arbitrary length of the form x = (xt, xt+1, . . . , xt+k),
made of successive states occupied by the system.
The reason for introducing a hierarchy of ﬁner and ﬁner large deviations lies in a
fundamental result of large deviation theory, called the contraction principle. The con-
traction principle allows us to express the rate function I(y) of a variable y, which is a
continuous function of another variable, y = f (x). Since this principle involves changing

Large Deviations: Theory and Practice
155
the independent variable of the rate function, we denote in this section the rate function,
e.g., of the variable x by I(x)(x) to avoid misunderstandings. Now, if x satisﬁes a large
deviation principle and the rate function I(x)(x) is known, the contraction principle
states that the rate function for y is given by
I( y)(y) =
inf
x:f (x)=y I(x)(x).
(6.98)
The gist of this relation is that the asymptotic probability of a given value of y is
dominated by the least improbable event x such that f (x) = y. Importantly, the contrac-
tion principle permits us to express lower-level rate functions in terms of higher-level
ones.
For Markov processes, it is convenient to deﬁne an intermediate level between levels
2 and 3—level 2.5. A level 2.5 large deviation principle describes the joint asymptotic
distribution of the empirical vector f = ( fx) and the empirical jump frequencies ν =
(νxx′). The empirical jump frequencies are the intensive counterparts of the empirical
number of jumps introduced in eq. (6.15):
νxx′(x) = nxx′(x)
T
.
(6.99)
Level 2.5 large deviations are of paramount relevance for Markov processes. The
main reason is that, for master equations, this is the only level for which a relatively
simple analytical expression for the rate functions is known. Moreover, rate functions
for empirical currents can be obtained from the level 2.5 large deviation by means of
the contraction principle. In particular, this procedure leads to expression for the rate
function of important observables, such as the empirical entropy production rate.
We now derive the expression for the level 2.5 rate function. We consider a system
described by a master equation with time-independent rates evolving at a steady state
in a time interval [t0, tf] of duration T = tf −t0. Given a trajectory x, we evaluate the
empirical vector fx and the empirical jump frequencies νxx′. We make the additional
assumption of empirical stationarity:
1
x
νxx′ =
1
x
νx′x.
(6.100)
Equation (6.100) states that the number of times that each state is reached is equal to
the number of times that it is lef. Any long trajectory of a master equation satisﬁes
eq. (6.100) apart from a boundary term, stemming from the fact that the initial and
ﬁnal states can be diﬀerent. This means that eq. (6.100) is a rather mild constraint for
largeT . As T grows, fx and νxx′ converge to pst
x and to kxx′pst
x′, respectively, for all x, x′. To
obtain their probability densities, we introduce an auxiliary, ﬁctitious process for which
typical values of the empirical vector and number of jumps are equal to the observed
ones. The jump rates of the auxiliary process are the empirical jump rates κxx′, deﬁned
by the relation
νxx′ = κxx′fx′.
(6.101)

156
Chapter 6
The escape rates in the auxiliary process are κout
x
= !
x′ κx′x. The probability Px of a
trajectory x in the original process is given by eq. (2.91). In the auxiliary process, the
probability of the same trajectory is
P∗
x dtn · · · dt1 = e−κout
xn (t−tn)κxnxn−1 dtn e−κout
xn−1(tn−tn−1) · · ·
· · · × κx1x0 dt1 e−κout
x0 (t1−t0)px0(t0).
(6.102)
Our goal is to compute the joint probability distribution p( f , ν; t). It is easier to ﬁrst
evaluate the probability densities p( f , κ; t) and p∗( f , κ; t) in the original and auxiliary
processes, respectively, obtained by changing variables using eq. (6.99) and by summing
Px and P∗
x over all trajectories satisfying the condition (6.101). Since the auxiliary pro-
cess is constructed to have f and ν as typical values for the corresponding observables,
p∗( f , κ; t) does not decrease exponentially with t for large t. Moreover, for all trajec-
tories satisfying the condition (6.101), we can express the ratio of the two probability
densities Px and P∗
x in terms of f and κ only:
Px
P∗x
=
4 n
L
i=1
kxixi−1
κxixi−1
5 4 n
L
i=0
e−(kout
xi −κout
xi )(ti+1−ti)
5
= exp
<
−T
1
xx′
"
κxx′ ln κxx′
kxx′ −κxx′ + kxx′
#
fx′
>
,
(6.103)
where in the ﬁrst line tn+1 = tf. As a consequence, we obtain the large deviation
principle
p( f , κ; t) = p∗( f , κ; t)
IPx
P∗x
))))conditions (6.100), (6.101)
J
≍Px
P∗x
≍e−T I( f ,κ)( f ,κ),
(6.104)
where the rate function is given by
I( f ,κ)( f , κ) =
1
xx′
%
κxx′ ln κxx′
kxx′ −κxx′ + kxx′
&
fx′.
(6.105)
This expression is the central result of this section. It can be used, for example, to for-
mally express the rate function for the empirical vector f . Since the variables fx and κxx′
satisfy a large deviation principle, f satisﬁes a large deviation principle by itself:
P( f ; T ) ≍e−T I( f )( f ).
(6.106)
To obtain it, we apply the contraction principle:
I( f )( f ) = inf
κ I( f ,κ)( f , κ),
(6.107)

Large Deviations: Theory and Practice
157
where the inﬁmum is taken among all κxx′s satisfying κxx′ ≥0 and !
x′ κxx′fx′ =
!
x′ κx′xfx for all x, x′. Thus the rate function for the empirical vector f is the solution
of a minimization problem, although its explicit expression can be hard to obtain.
We similarly express the rate function I( f ,j)( f , j) by minimizing I( f ,κ)( f , κ) with
respect to κ, with the constraints κxx′fx′ −κx′xfx = jxx′. We impose the constraints via
the Lagrange multipliers λxx′ = −λx′x, and we minimize with respect to κ the quantity
%(κ, k, λ) =
1
xx′
%
I( f , κ) + 1
4λxx′ 7
κxx′fx′ −κx′xfx
8&
,
(6.108)
where the factor 1
4 is introduced for convenience. We obtain, with some algebra,
I( f ,j)( f , j) = I( f ,κ)( f , κ∗),
(6.109)
with κ∗
xx′ = kxx′ eλxx′/2. The Lagrange multipliers are equal to
λxx′ = 2 ln
%
1
2kxx′fx′
"
jxx′ +
?
j2
xx′ + α2
xx′
#&
,
(6.110)
in which we deﬁne
αxx′ =
M
kxx′kx′xfx′fx =
M
κxx′κx′xfx′fx = αx′x.
(6.111)
We then obtain
I( f ,j)( f , j) = 1
4
1
xx′
λxx′jxx′ −1
2
1
xx′
.
t∗
xx′( f ) −txx′( f )
/
,
(6.112)
where the ts are traﬃc observables given by
txx′( f ) = kxx′fx′ + kx′xfx;
t∗
xx′( f ) = κ∗
xx′fx′ + κ∗
x′xfx;
(6.113)
see also eq. (6.19). Also this result requires a stationarity condition, in this case for the
currents:
1
x′
jxx′ = 0,
∀x.
(6.114)
If the stationarity condition does not hold, one has I( f ,j)( f , j) = +∞.
We ﬁnally obtain the rate function I(j) of a current j by applying the contraction
principle:
I(j)(j) = inf
f I( f ,j)( f , j).
(6.115)
By choosing the steady-state distribution pst for f , we obtain the bound
I(j)(j) ≤I( f ,j)(pst, j).
(6.116)

158
Chapter 6
This approach has been applied to derive general inequalities connecting the aver-
age value and the variance of steady-state currents with the entropy production rate,
discussed in section 8.2.
6.10
Further reading
Theoretical physicists informally developed large deviation theory long before math-
ematicians established a uniﬁed theory, in particular following the work of Donsker
and Varadhan. Indeed, some fundamental results by Boltzmann [24], and the theory of
ﬂuctuations established by Einstein [45], can be considered as results in large deviation
theory. Touchette [168] reviews the large-deviation approach to statistical mechanics.
Ellis [47], Den Hollander [43], and Dembo and Zeitouni [42] are useful textbooks.
Touchette [168, app. C-2] and Chetrite and Touchette [30] discuss the tilting method.
The Arnoldi-Lanczos method is described, e.g., by Meyer [112, p. 651]. Koza [91] orig-
inally proposed the idea of using the implicit function theorem to compute scaled
cumulants. Giardinà et al. [62] introduced cloning. The method is thoroughly discussed
by Lecomte and Tailleur [99], including thermodynamic integration. Tizo´n-Escamilla
et al. [167] discuss extension of the tilting method to Langevin processes.
The discussion in section 6.4 follows Andrieux and Gaspard [2, 3], and section 6.7 is
inspired by Lacoste et al. [94]. For the deﬁnition of level 3 large deviation, see Ellis [47,
§I.6]. Section 6.9 follows the derivation by Maes and Netocˇny´ [107]. Bertini et al. [17]
show how one can apply level 2.5 large deviation theory to obtain the Gallavotti-Cohen
symmetries for the rate functions of the empirical currents.
6.11
Exercises
6.1
Use the expression of the rate function for the binomial distribution (6.4) and
the inverse Gärtner-Ellis theorem to compute the scaled cumulant generating
function of the binomial distribution.
6.2
Consider a system for which the total entropy production is distributed
according to a Gaussian and satisﬁes the integral ﬂuctuation theorem. Com-
pute explicitly the scaled cumulant generating function and verify that it
satisﬁes the Gallavotti-Cohen symmetry.
6.3
Show that in a system described by a master equation, jumps between states
that do not belong to any cycle do not contribute to the entropy production in
the steady state.
6.4
A particle is dragged on a discrete ring with N = 3 states; see section 4.3. Con-
sider a current equal to the number of jumps in the direction of the driving
minus the number of jumps in the opposite direction. Compute the ﬁrst two
scaled cumulants of such a current as a function of the driving f using tilt-
ing. Check the form of the Gallavotti-Cohen symmetry for the cumulant
generating function.
6.5
Consider the Mandal-Jarzynski machine described in section 5.5, but assume
that the tape advances by one case at random time points, as in exercise 5.3.

Large Deviations: Theory and Practice
159
Thus the system is described by a master equation with suitable rates, as
discussed in section 5.8. Evaluate numerically the scaled cumulant gen-
erating function of the current between state 2 and state 1 by a cloning
algorithm.
6.6
Compute the large deviation behavior of the total entropy production in the
Michaelis-Menten reaction scheme introduced in section 6.6. Verify that the
total entropy production satisﬁes the Gallavotti-Cohen symmetry.

CHAPTER 7
Experimental Applications
In this chapter, we discuss experiments that have tested predictions of stochastic
thermodynamics or exploited them to measure quantities of physical and biological
interests in mesoscopic systems. Perhaps the most celebrated experimental outcome
of stochastic thermodynamics is the possibility of estimating equilibrium free-energy
diﬀerences of biomolecules by means of nonequilibrium measurements and ﬂuctua-
tion theorems. Given the importance of this achievement, we explain in detail the idea
underlying these experiments and diﬀerent practical ways of estimating the free energy.
A comprehensive review of the experimental aspects of stochastic thermodynamics falls
beyond the scope of this book (and of our expertise). For this reason, this chapter is rel-
atively synthetic and focuses on a limited set of experiments that we consider to be good
representatives of the state of the art in stochastic thermodynamics.
7.1
The hairpin as a paradigm
A far-reaching consequence of stochastic thermodynamics is that equilibrium prop-
erties of mesoscopic systems can be measured by means of nonequilibrium experi-
ments. This idea paved the way for novel methods to evaluate, for example, free-energy
diﬀerences between diﬀerent conformations of biological macromolecules.
A basic scheme of these experiments is sketched in ﬁg. 7.1. A macromolecule, such
as a stretch of DNA, RNA, or a protein, is anchored at one tip to a rigid, unmovable
surface. A microscopic bead, made up of dielectric material, is connected to the other
tip. The position of this bead, or the force applied to it, is controlled by means of an
optical laser trap, also called optical tweezers.
In a classic “pulling” experiment, the initial position of the bead is relatively close to
the surface. Under these conditions, polymers such as RNA tend to adopt a conforma-
tion called a hairpin, as sketched in ﬁg. 7.1. This conformation is stabilized by hydrogen
bonds between diﬀerent nucleotides in the RNA chain. The bead is then pulled far-
ther from the ﬁxed surface, so that the hairpin is untied and the macromolecule
conformation becomes elongated.
Ideally, in the limit of an inﬁnitely slow pulling experiment, the thermodynamic
transformation becomes reversible, and thus the work W made by the optical tweezers
approaches the free-energy diﬀerence !F between the ﬁnal and the initial conﬁgura-
tions. This free-energy diﬀerence should be split into the free-energy change of the
device and that of the system, i.e., the folding energy of the hairpin. Usually, it is

Experimental Applications
161
Figure 7.1. Sketch of a macromolecule pulling experiment. Narrow lines denote mono-
mers connected by hydrogen bonds.
relatively easy to estimate the former contribution by independent means. This implies
that experimental measurements of W can be used to infer the folding free energy of
the hairpin.
The problem with this program is that adiabatic measurements on such mesoscopic
systems are ofen not feasible. Free-energy diﬀerences of conformational changes of
macromolecules are typically in the range of a few to a few hundred kBT at physio-
logical temperature, making their dynamics highly stochastic. The conclusion is that
the folding/unfolding process is ofen not easy to manipulate in a quasi-static way.
The counterintuitive fact that the Jarzynski equality (4.52) and the Crooks relation
(4.53) relate equilibrium free energies with work distribution far from equilibrium
have proved to be crucial to overcome these limitations of quasi-static measurement
protocols.
7.2
A simpler model
Formulating a reasonably realistic model of the dynamics of a hairpin pulled by
optical tweezers requires a number of concepts from polymer physics. Modeling the
manipulation device is also not straightforward, as devices controlling the applied force
or the position of the bead require slightly diﬀerent descriptions. To avoid these digres-
sions, we base our discussion on an idealized model. The model has a discrete number
of states x = 1, . . . , n, that represent the number of bonds formed by a hairpin. For x = n
the hairpin is completely formed, whereas for x = 0 it is unfolded. In the absence of a
manipulation, the energy of the hairpin is simply proportional to the number of bonds,
ϵx = −ϵx,
(7.1)
where the parameter ϵ represents the absolute value of the energy of each bond. We
assume that the manipulation protocol λ “tilts” the energy landscape, so that the energy
in the presence of manipulation reads
ϵx = (λ −ϵ)x.
(7.2)
A positive λ represents a state in which the manipulation is pulling the bead,
therefore making the unfolded state x = 0 more favored. We consider a manipulation

162
Chapter 7
between an initial value of the manipulation parameter λ = λ0 and a ﬁnal value λ = λf.
The free energy as a function of λ reads
F(λ) = −kBT ln Z(λ) = −kBT ln
! n
"
x=0
exp
#(ϵ −λ)x
kBT
$%
= −kBT ln
!
1 −e(ϵ−λ)(n+1)/kBT
1 −e(ϵ−λ)/kBT
%
.
(7.3)
Examples of trajectories of the hairpin model are shown in ﬁg. 7.2a for a linear
manipulation protocol. Parameter values are comparable with those of RNA hairpins
commonly used in experiments. It is useful to compare “forward” trajectories with
“backward” trajectories, i.e., with trajectories obtained by the backward manipulation
protocol. This comparison shows that the folding/unfolding of the hairpin is character-
ized by hysteresis. In this context, hysteresis means that typical forward trajectories are
markedly diﬀerent than typical backward trajectories. Hysteresis is commonly observed
in nonequilibrium experiments, as shown in ﬁg. 7.2b.
7.3
Equilibrium free energies from nonequilibrium manipulations
In practice, the Jarzynski equality (4.52) is diﬃcult to apply to systems very far from
equilibrium due to the diﬃculty in sampling large deviations; see section 4.8. On the
other hand, detailed ﬂuctuation relations, such as the Crooks relation (4.53), provide
more stringent predictions on the distribution of work in nonequilibrium protocols. It
is important to establish the best way of exploiting these predictions and, consequently,
how far we can push a system out of equilibrium if we want to reliably measure free-
energy diﬀerences.
We consider an experiment in which a hairpin is brought from an initial folded state
to a ﬁnal elongated state by a protocol λ. The free-energy diﬀerence between the ﬁnal
and the initial equilibrium states is !F. In the experiment, we estimate the probability
distribution of work pF(w) = p(w; λ), for example, by repeating the experiment many
times and evaluating the work performed by the manipulation device in each realiza-
tion. This may be achieved, e.g., by monitoring the applied force and the displacement
of the tweezers as a function of time. We also assume to be able to perform the experi-
ment backward, i.e., from the ﬁnal state to the initial state via the backward protocol&λ,
and to estimate the distribution pB(w) = p(w;&λ) of the associated work.
We consider ﬁve methods to estimate the free-energy diﬀerence.
Average work. The simplest way to estimate the free energy is to assume that the
transformation occurs close to equilibrium and therefore
!F ≈W = ⟨w⟩F,emp ,
(7.4)
where we deﬁne the empirical average over N independent realizations of the
experiment with the same forward protocol λ:
⟨w⟩F,emp = 1
N
N
"
k=1
w(xk).
(7.5)

0
5
10
15
20
n − x
0.0
2.5
5.0
7.5
10.0
(a)
(b)
λ
forward
backward
20
19
18
17
16
150
200
250
distance (nm)
stretching
releasing
force (pN)
Figure 7.2. (a) Trajectories of the hairpin model. The force λ (in units of kBT) is plotted
against the number of open residues n −x. Parameters: n = 20, ϵ = 3 kBT. The manipula-
tion protocol is linear, λ(t) = αt kBT, bringing the system from the state λ0 = 0 at initial time
t0 = 0 to λf = 20 kBT at ﬁnal time tf = 20/α. In this case, manipulation speed is α = 1. Con-
tinuous lines are forward trajectories, dashed lines are backward trajectories. Forward
trajectories are initialized at x(t = 0) = n = 20, whereas backward trajectories are initialized
at x(t = tf) = 0. (b) Experimental force-extension curves of an RNA hairpin experiment.
Darker trajectories correspond to the forward (extension) protocol, while lighter ones
correspond to the backward (refolding) one. (Adapted from Mossa et al. [113]. c⃝SISSA
Medialab Srl and IOP Publishing. Reproduced by permission of IOP Publishing. All rights
reserved.)

164
Chapter 7
Here xk is the trajectory in the kth experimental realization. We expect this method
to provide good results for slow transformations but poor approximations farther
from equilibrium.
Jarzynski equality (JE). The free-energy diﬀerence can be directly estimated from the
Jarzynski equality. In particular, the Jarzynski equality implies
!F ≈−kBT ln
'
e−w/kBT(
F,emp .
(7.6)
An advantage of this method is that it does not require performing experiments with
the backward protocol, but only many replicates of the forward protocol. However,
as we discussed in section 4.8, when the average dissipated work is large, i.e., when
the protocol drives the system too far from equilibrium, the empirical average of
e−w/kBT can be very diﬀerent from the theoretical one.
Crooks (crossing of forward/backward work distributions). This method requires
us to evaluate both the work distribution pF(w) with the forward protocol and the
corresponding pB(w) with the backward protocol, and therefore to perform both for-
ward and backward experiments. A direct consequence of the Crooks relation (4.53)
is that the distributions pF(w) and pB(−w) cross at the value w = !F. This obser-
vation provides a simple graphical method to estimate the free energy (ﬁg. 7.3b).
However, this method necessitates enough realizations to resolve both distributions
in the region where they intersect. Because of hysteresis, if the experiment is per-
formed very far from equilibrium, the overlap between the two distributions occurs
far on the tails, so that also in this case the required number of realizations may
become prohibitively large.
Crooks (linear ﬁt). A drawback of the estimate based on the crossing of the work dis-
tributions is that it exploits only the realizations of the experiments for which w ≈!F
in the forward protocol and w ≈−!F in the backward protocol. To make use of the
rest of the information gathered in the experiment, we rewrite the Crooks relation
(4.53) in the form
ln pF(w) −ln pB(−w) = w −!F
kBT
.
(7.7)
This means that the function f (w) = ln pF(w) −ln pB(−w), as estimated from exper-
iments, should look like a straight line with slope (kBT)−1, which crosses the line
y = 0 for w = !F. In practice, this relation is satisﬁed only in a limited range of val-
ues of w due to statistical limitations. The robustness of the result depends therefore
on the quality of the ﬁt. In any case, this method extends the previous one and, since
it uses more of the data, is expected to be more robust.
Bennett-Crooks acceptance ratio (BC). The logic of the linear ﬁt method can be gen-
eralized by introducing an arbitrary function of the work f (w, z) that depends on an
additional parameter z. We now consider a function
g(z) = ln
)
f (−w, z)
*
B −ln
'
f (w, z) e−w/kBT(
F .
(7.8)
Using the Crooks relation to compute the averages in eq. (7.8) leads to the result
g(z) = !F/kBT, independent of the choice of the function f (w, z). This freedom

40
50
60
70
80
w
0.00
0.05
0.10
0.15
(a)
(b)
(c)
(d)
p(w)
JE
forward
backward
56
58
60
62
64
w
0.000
0.004
0.008
p(w)
estimate
forward
backward
50
55
60
65
70
w
−100
−50
0
50
100
f (w)
estimate
f (w)
linear fit
50
55
60
65
70
z
50
55
60
65
70
g(z)
estimate
g(z)
z
8w9
Figure 7.3. Methods for evaluat-
ing a free-energy difference !F.
(a) The estimated probability dis-
tribution of the work w for the
forward protocol and the corre-
sponding distribution of −w for the
backward protocol. Work is plot-
ted in units of kBT. The mean
⟨w⟩and the Jarzynski estimator
JE are shown. (b) Close-up of the
distributions
pF(w)
and
pB(−w)
near their crossing. (c) Linear ﬁt
to the function f (w) = ln pF(w) −
ln pB(−w) −w/kBT. The estimate
corresponds to the intercept of this
line with the horizontal line at 0.
(d) The Bennett-Crooks estimator
g(z), deﬁned in eq. (7.8), with f (x, z)
given in eq. (7.9), is plotted as
a function of the parameter z.
The best estimate is obtained at
the crossing of g(z) with z. The
plots are based on 1000 repli-
cates each of the forward and back-
ward protocols on the model intro-
duced in section 7.2, with α = 0.04.
The actual free-energy difference
is !F = 60 kBT. A comparison of
results obtained by the different
methods is shown in ﬁg. 7.4.

166
Chapter 7
10−2
10−1
100
101
α
60
80
100
120
140
ΔF/kBT
JE
crossing
linear fit
BC
8w9
Figure 7.4. Estimates of the free-energy difference !F with different methods for the
hairpin model as a function of the protocol speed α, which controls the distance from
equilibrium. In all cases, the estimate is based on 1000 replicates of the forward protocol.
In addition, methods based on the Crooks relation use 1000 replicates of the backward
protocol. For large α, the linear ﬁt method cannot be applied because the empirical
distributions pF(w) and pB(−w) do not sufﬁciently overlap.
permits us to pick a function f (w, z) and a range of z that minimizes the expected
error on the estimate of !F. Bennett showed that the best estimate is obtained by
choosing
f (w) =
1
e−w/kBT + e−z/kBT ,
(7.9)
where z is chosen such that
g(z) = z.
(7.10)
A derivation of this result is sketched in appendix A.11. We therefore obtain
!F ≈kBT

ln
-
ez/kBT
1 + e(w+z)/kBT
.
B,emp
−ln
/
1
1 + e(w−z)/kBT
0
F,emp

,
(7.11)
with z ≈!F. If the numbers of forward (NF) and backward (NB) samples are not
equal, the best choice of z becomes !F −kBT ln(NF/NB), and eq. (7.10) must be
changed accordingly.
A numerical comparison of these ﬁve methods of estimating a free-energy diﬀerence
is shown in ﬁg. 7.4.

Experimental Applications
167
7.4
Maxwell demons
In chapter 5, we discussed apparent violations of the second law of thermodynam-
ics that occur when manipulating a mesoscopic system using information about its
state. In stochastic thermodynamics, information-based manipulation can be studied
within concrete models, making the correspondence between free energy and informa-
tion more explicit and resolving apparently paradoxical scenarios. Placing information
manipulation in the context of concrete models has the additional merit of laying the
groundwork for experimental tests. In particular, a crucial test of thermodynamics of
information is to extract work from a thermal reservoir via feedback control.
We discuss an experiment in which a mesoscopic dimeric particle is pinned on a
surface but is allowed to rotate freely on the surface plane. The particle is subject to
an electric ﬁeld, which applies a constant torque f in the negative angle direction, in
addition to a potential ϵ(φ, λ), where λ is the manipulation parameter. Moreover, the
particle undergoes rotational diﬀusion due to the interactions with a heat reservoir. The
potential is periodic, ϵ(φ + π) = ϵ(φ). The manipulation parameter can assume two
discrete values, λ ∈{0, 1}, which change the phase of the periodic potential, ϵ(φ, λ) =
ϵ(φ + λπ/2).
The periodic potential is manipulated according to the result of measurements. Ini-
tially, the control parameter is set to λ. At a given time, the position of the particle is
measured. If it is found in the shaded region shown in ﬁg. 7.5a, afer a delay τ the param-
eter λ is switched to 1 −λ, otherwise it is lef unaltered. The shaded region is chosen so
that the particle, afer switching, is likely to be found in a well at a higher energy than
that at the beginning of the interval. The whole procedure is periodically repeated at
intervals of time equal to 44 ms.
For small values of τ, the device operates as a Maxwell demon, i.e., it uses the
information provided by the measurement to extract heat from the heat reservoir and
perform work, on average, against the external torque f ; see ﬁg. 7.5b. The apparent
violation of the second law of thermodynamics agrees with the Sagawa-Ueda theory
presented in section 5.4, even though in this case the system is periodically manip-
ulated, whereas in section 5.4 we considered a manipulation in a ﬁnite time interval
where the system starts and ends at thermodynamic equilibrium. In fact, in the present
case, the relaxation time of the system is small enough so that the system can relax to
thermodynamic equilibrium in each manipulation, at least for small values of τ.
7.5
Landauer principle
According to the Landauer principle, erasing information in a microscopic or meso-
scopic device requires an amount of work of at least kBT ln 2 per bit; see sections 5.1
and 5.5. The Landauer principle is crucial to reconcile the workings of the Maxwell
demon and the Szilard engine with the second law of thermodynamics, a point made
by Penrose and, independently, by Bennett. In recent years, it has been possible to test
this principle, thanks to novel methods to closely monitor the position of Brownian
particles in precisely controllable potentials.
To test the Landauer principle, one needs a Brownian particle in a time-dependent
bistable potential. Experimentally, the potential can be generated by a highly focused
laser beam that is rapidly moved between two locations. A diﬀerent approach uses feed-
back loops to apply a force that depends on the particle position. In the latter approach,
the spatial dependence of the force mimics a virtual potential U(x, t) chosen by the

168
Chapter 7
0
−π/2
π/2
π
φ
−1
0
1
2
(a)
(b)
(φ,λ)
∍
A
B
Bʹ
λ = 0
λ = 1
0
10
20
30
40
τ (ms)
−0.10
−0.05
0.00
0.05
(ΔF − 8w9)/kBT
Figure 7.5. Maxwell demon experiment. (a) Scheme of the feedback manipulation pro-
tocol. The parameter λ is set to 0. If, upon measurement, the particle is found in the
unshaded areas, as in A, the parameter remains unchanged. If it is found in the shaded
areas, as near point B, the parameter switches to 1 and the particle is located near the
local minimum in B′, which is at a higher level than A. In this way, the manipulation allows
the particle to “climb the staircase.” (b) Experimental results. The net work per measure-
ment cycle (!F −⟨w⟩)/kBT is plotted against the time interval τ from the measurement
to the control. The ﬁrst two points correspond to the “Maxwell demon” regime. (Data
from Toyabe et al. [169].)
experimenter. The two wells of the potential are thought of as the two states of 1 bit
of memory. In order to act as a memory for a certain time, the potential barrier be-
tween the two minima should be so large that the probability that the particle switches
location during this time, due to thermal ﬂuctuations, is negligible. The particle is ini-
tially in one minimum (say, −1) or the other (say, +1), with a certain probability px,
x ∈{−1, 1}. The maximum Shannon entropy of ln 2 (1 bit) is reached when px = 1/2.
To reset the memory, one manipulates the system so that, at the end of the manipula-
tion, the particle is found in a reference minimum, say, x = +1, with probability close to
1, regardless of the initial state. A possible manipulation scheme is presented in ﬁg. 7.6.

Experimental Applications
169
−1
0
1
U(x)
(a)
(b)
−2
0
2
x
−1
0
1
U(x)
(d)
−2
0
2
x
(c)
Figure 7.6. Scheme of the potential manipulation in a full erasure (p = 1) protocol. (a) Initial
potential U(x) (arbitrary units). (b) The central barrier is lowered. (c) A symmetry-breaking
force is applied. (d) The central barrier is raised. At the ﬁnal step, symmetry is restored
and the initial form of the potential is recovered.
Starting from the initial bistable potential shown in (a), the central barrier is ﬁrst low-
ered (b), leading to a potential with a single minimum. Then a force directed toward
positive x is applied (c), displacing the minimum to the right. At this point the cen-
tral barrier is raised again (d), and ﬁnally the symmetry-breaking force is removed (not
shown) to recover the initial bistable potential. With this protocol, the probability p that
the particle is found in the minimum at 1 at the end of the manipulation is very close
to 1. We compare this case with a no-erasure protocol in which the symmetry-breaking
force is not applied. This protocol randomly reshuﬄes the memory, so that the prob-
ability p of ﬁnding the particle at the end of the manipulation in the minimum at 1 is
close to 1/2. In this situation, the change in the system entropy vanishes and so does
the minimum required dissipated work.
We now discuss more closely a speciﬁc experimental setup, where the manipulation
is carried out via a feedback trap. The trap acquires an image of the particle diﬀusing
in an aqueous solution and evaluates its position. Then voltages are applied across two
sets of electrodes, creating electrical forces that move the particle. The forces mimic
those that would originate by the desired potential U(x, t) at the given time and at the
measured position of the particle. The feedback loop is updated on a timescale that is
much faster than the timescale of the potential dynamics, set by the local relaxation
within the wells.
With a manipulation potential such as the one shown in ﬁg. 7.6, we expect the
Landauer bound kBT ln 2 ≈0.69 kBT to be reached as the manipulation time τ goes to

170
Chapter 7
p = 1–2
−5
0
5
10
15
w
0.0
0.1
0.2
0.3
(a)
(b)
p (w)
τ = 0.5
τ = 1
τ = 2.5
0.0
0.5
1.0
1.5
2.0
1/τ
0
1
2
3
Landauer bound
p = 1
8w9 /kBT
Figure 7.7. (a) Histogram of the work w measured in a full erasure protocol, for different
values of the protocol duration τ (measured in units of τ0). The curves are Gaussian ﬁts.
(b) Average work ⟨w⟩/kBT plotted against the inverse manipulation time 1/τ (measured
in units of τ0). The Landauer bound kBT ln 2 is also shown. (Adapted from Jun et al. [84],
with permission.)
inﬁnity. Therefore, the average work ⟨w⟩τ obtained in a manipulation of duration τ is
ﬁt to a law of the form
⟨w⟩τ ≈⟨w⟩∞+ K
τ .
(7.12)
The results of the experiment are shown in ﬁg. 7.7. The ﬁt (lines) is compatible with the
Landauer bound for p = 1 (erasure) and with 0 for p = 1/2 (no erasure). One obtains
⟨w⟩∞= 0.71 kBT and K = 1.39 τ0 for p = 1, and ⟨w⟩∞= 0.05 kBT and K = 1.48 τ0 for
p = 1/2, where τ0 ≈15 s is a timescale corresponding to the time needed by the Brow-
nian particle to freely diﬀuse a distance equal to the distance between the two minima
and thus forget the initial state of the memory.

Experimental Applications
171
7.6
Further reading
Early experiments measuring equilibrium free energies via nonequilibrium pro-
tocols used the Jarzynski equality and were therefore necessarily performed close to
equilibrium. In particular, Liphardt et al. [104, 103] measured in this way the folding
free energy of RNA molecules that can be folded/unfolded in a quasi-static way. Collin
et al. [31] showed that using the Crooks relations and the variants described in this
chapter allows one to obtain reliable measurements in experiments much farther away
from equilibrium. This observation greatly extended the range of macromolecules that
can be studied using these techniques. Crooks [35] proposed to use in this context the
Bennett-Crooks estimator [11].
Toyabe et al. [169] performed the Maxwell demon experiment. The Landauer princi-
ple was discussed by Penrose [126, ch. VI, §3] and Bennett [10]. Jun et al. [84] performed
the experiment reported in section 7.5. Other similar experiments have been performed
on colloidal particles (see, e.g., Be´rut et al. [27]) and on technologically relevant systems,
such as nanomagnetic memory bits (Hong et al. [76]). Koski et al. [89, 90] have carried
out closely related experiments in single-electron boxes.

CHAPTER 8
Developments
The core theory of stochastic thermodynamics is nowadays rather well established. In
recent years, there have been rapid developments in several directions, with a growing
body of surprisingly general results. In this chapter, we discuss some of these develop-
ments. Progress in this ﬁeld is growing by the day, and therefore we make no attempt at
being exhaustive.
8.1
Stochastic efﬁciency
An original motivation for the development of thermodynamics has been to under-
stand the eﬃciency of heat engines; see section 2.2. The concept of eﬃciency also plays
an important role for the mesoscopic systems that are the subject of stochastic thermo-
dynamics. In particular, the thermal Carnot bound also limits the maximum average
work that can be extracted from a mesoscopic heat engine. The reason is that this bound
is a direct consequence of the fundamental laws of thermodynamics, and we have seen
that these laws hold for average observables in stochastic thermodynamics.
Throughout this book, we have analyzed mesoscopic engines that perform diﬀerent
kinds of energy conversion. Prominent examples are molecular motors that convert
chemical energy into work. Information can also fuel a mesoscopic engine, as dis-
cussed in section 5.5. To include all these cases in a comprehensive framework, eﬃciency
is deﬁned as the ratio between input and output entropy change ηS = −Sin/Sout, as
discussed in section 2.2. The eﬃciency is limited by the Carnot bound ηS ≤ηC = 1.
Since entropy is a ﬂuctuating quantity in stochastic thermodynamics, it is natural to
introduce the stochastic eﬃciency
η = −sin
sout .
(8.1)
The stochastic eﬃciency exhibits surprising universal properties. To study them, we
consider the joint probability distribution p(sin, sout) of the input and output entropy
production, with stot = sin + sout. The two entropy productions sin and sout satisfy a
detailed ﬂuctuation relation
p(sin, sout)
p(−sin, −sout) = e(sin+sout)/kB.
(8.2)

Developments
173
Equation (8.2) derives from the fact that both sin and sout are odd under time reversal:
p(sin, sout) =
!
Dx δ(sin −sin(x)) δ(sout −sout(x)) P(x)
=
!
D"x δ(sin −sin(x)) δ(sout −sout(x)) estot(x) P("x)
= estot/kB
!
D"x δ(sin + sin("x)) δ(sout + sout("x)) P("x)
= estot/kB p(−sin, −sout).
(8.3)
This implies that, in the long time limit, the joint rate function of the empirical entropy
production rates jin
s = sin/T and jout
s
= sout/T satisﬁes
I( jin
s , jout
s ) −I(−jin
s , −jout
s ) = jin
s + jout
s
kB
.
(8.4)
By the contraction principle, eq. (6.98), the rate function of the eﬃciency can be
expressed as the minimum of I( jin
s , jout
s ) compatible with a given value of η:
I(η) =
min
jin
s ,jout
s
|−jin
s /jout
s
=η
I( jin
s , jout
s ) = min
jin
s
I( jin
s , −jin
s /η).
(8.5)
We analyze the qualitative behavior of the rate function I(η) using a contour plot
of the rate function I( jin
s , jout
s ) (ﬁg. 8.1). For a given value of η, I(η) can be graphically
computed by looking for the minimum in the contour plot along the straight line jout
s
=
−jin
s /η (see dotted and dashed lines in the ﬁgure). The rate function of the entropy
production rates vanishes at the average values, I( Jin
s , Jout
s
) = 0. It follows that the rate
function of the stochastic eﬃciency also vanishes at the macroscopic eﬃciency ηS =
−Jin
s /Jout
s
.
I(ηS) = min
jin
s
I
#
jin
s , jout
s
= −jin
s /ηS
$
= 0,
(8.6)
since the corresponding line intercepts the minimum (dotted line and black dot in
ﬁg. 8.1a).
The function I(η) attains its maximum at the Carnot eﬃciency ηC = 1; see ﬁg. 8.1b.
This means that the Carnot eﬃciency is, in general, the least likely eﬃciency, at least in
the inﬁnite time limit governed by large deviation theory. This fact is not a peculiarity of
the particular rate function I( jin
s , jout
s ) shown in the ﬁgure but holds in general. Indeed,
eq. (8.4) for jin
s + jout
s
= 0 implies I( jin
s , jout
s ) = I(−jin
s , −jout
s ). It follows that the function
I( jin
s , −jin
s /ηC) is a convex even function of jin
s . Its minimum is therefore achieved for
jin
s = 0:
I(ηC) = I( jin
s , jout
s )|jin
s =jout
s
=0.
(8.7)
On the other hand, from eq. (8.5) we have
I(η) = min
jin
s
I( jin
s , −jin
s /η) ≤I( jin
s , −jin
s /ηC)|jin
s =0 = I(ηC),
(8.8)

174
Chapter 8
−20
(jsin, jsout)
0
20
40
jsin
jsout
−10
0
10
−2
0
2
η
0
1
2
3
(a)
(b)
I (η)
ηC
ηS
Figure 8.1. (a) Contour plot of the rate function I(jin
s , jout
s
). In this example, the rate
function is a quadratic form, corresponding to a case where jin
s and jout
s
are two corre-
lated Gaussian random variables with scaled variances ˜σ 2
in = 50, ˜σ 2
out = 10, and correlation
˜cin,out = −20. The same qualitative picture holds for a general convex rate function. The
dotted line marks the macroscopic efﬁciency −jin
s /jout
s
= −Jin
s /Jout
s
= ηS. The dashed line
marks the maximal efﬁciency −jin
s /jout
s
= ηC = 1. (b) The corresponding rate function for
the efﬁciency, obtained from eqs. (8.6) and (8.10). See, e.g., Verley et al. [172].
i.e., I(η) reaches its maximum for η = ηC. For |η| ≫1, the rate function I(η) tends to a
ﬁnite limit, corresponding to the minimum of I( jin
s , jout
s ) for jin
s = 0. It is important to
stress in this context that large deviation theory only describes the leading behavior for
large t. The distribution of η for ﬁnite time might signiﬁcantly diﬀer due to the role of
subleading terms.
To explicitly compute the rate function of the stochastic eﬃciency in concrete exam-
ples, we exploit the inverse Gärtner-Ellis theorem to work with the scaled cumulant

Developments
175
generating function rather than with the rate functions:
ψ( jin
s ,jout
s
)(qin, qout) = lim
T →∞
1
T ln
%
eqinsin+qoutsout&
.
(8.9)
Combining eqs. (6.9) and (8.6), we express the rate function as
I(η) = inf
jin
s
sup
qin,qout
'
qinjin
s −qout(ηjin
s ) −ψ( jin
s ,jout
s
)(qin, qout)
(
= inf
jin
s
sup
q
)
qjin
s −f (q)
*
= −sup
jin
s
[q′jin
s −sup
q
)
qjin
s −f (q)
*
]
for
q′ = 0
= −f (0) = −inf
qout ψ( jin
s ,jout
s
)(qoutη, qout),
(8.10)
where in the second equality we substitute q = q −qoutη and deﬁne the convex function
f (q) = infqout ψ( jin
s ,jout
s
)(q + qoutη, qout). In the third equality, we introduce a ﬁctitious
variable q′ (to be then set to 0) and change sign to cast the expression into the Legendre
transform of f (q). The last equality is a consequence of the involution property of the
Legendre transformation.
We apply eq. (8.10) to an example in which the empirical entropy production rates
jin
s and jout
s
are correlated Gaussian random variables. In this case, the scaled cumulant
generating function is a quadratic form,
ψ( jin
s ,jout
s
)(qin, qout) = 1
2
#
˜σ 2
inq2
in + ˜σ 2
outq2
out + 2˜cin,out qinqout
$
+ jin
s qin + jout
s qout,
(8.11)
where ˜σ 2
in, ˜σ 2
out are the scaled variances of sin and sout, respectively, and we deﬁne
the scaled covariance ˜cin,out = limT →∞(
+
sin(T )sout(T )
,
−
+
sin(T )
, +
sout(T )
,
)/T . Eval-
uating eq. (8.11) for qin = η qout and minimizing with respect to qout yields qout =
( jin
s η + jout
s )/(˜σinη2 + 2˜cin,out η + ˜σout). Substituting again into eq. (8.10) yields
I(η) = 1
2
( jin
s η + jout
s )2
˜σ 2
inη2 + 2˜cin,outη + ˜σ 2
out
.
(8.12)
We use eq. (8.4) to further simplify the expression. The Gallavotti-Cohen sym-
metry associated with this detailed ﬂuctuation relation reads ψ( jin
s ,jout
s
)(qin, qout) =
ψ( jin
s ,jout
s
)(−1/kB −qin, −1/kB −qout). By imposing this condition for the Gaussian
case of eq. (8.11), we express the average empirical entropy production rates in terms
of the scaled variances and covariances, 2jin
s = ˜σ 2
in + ˜cin,out and 2jout
s
= ˜σ 2
out + ˜cin,out. In
this way, the rate function of the stochastic eﬃciency can be expressed in terms of the
scaled variances and covariances alone:
I(η) = 1
8
)
η ˜σ 2
in + (1 + η) ˜cin,out + ˜σ 2
out
*2
˜σ 2
inη2 + 2˜cin,outη + ˜σ 2
out
.
(8.13)

176
Chapter 8
8.2
Uncertainty relations
Uncertainty relations are universal inequalities relating the average value of an arbi-
trary current, its variance, and the average entropy production rate. In particular, most
uncertainty relations set lower bounds on the coeﬃcient of variation ˜σj/
--+
j
,-- of an
empirical current j, bounds that are expressed in terms of the entropy production rate.
The coeﬃcient of variation measures the amplitude of ﬂuctuations relative to the mean.
In a nutshell, uncertainty relations state that achieving very accurate currents, with a
very small coeﬃcient of variation, requires in general a minimal cost in terms of entropy
production. In fact, a number of several interconnected results have been obtained, all
broadly termed uncertainty relations. They diﬀer in their underlying hypotheses and
provide tighter or looser bounds in diﬀerent situations.
The original thermodynamic uncertainty relation represents a remarkable achieve-
ment in stochastic thermodynamics. Its nontrivial proof exploits the properties of the
level 2.5 large deviations introduced in section 6.9. For pedagogical reasons, we start
our discussion from a more recent thermodynamic uncertainty relation, which holds
in a nonequilibrium steady state and has the advantage of being relatively easy to prove.
Later in this section, we present a more general version of the original uncertainty rela-
tion involving several currents, and we sketch its proof in appendix A.13. We conclude
with some weaker inequalities that are useful for experimental applications.
We consider a system obeying a master equation as in eq. (2.77) in the steady state pst
x .
We focus on the joint probability distribution p(stot, J ) of the total entropy production
stot and a given integrated empirical current J being odd under time reversal. Both
these quantities are evaluated over a time interval of duration T . The joint probability
distribution satisﬁes a detailed ﬂuctuation relation:
p(stot, J ) = estot/kB p(−stot, −J ).
(8.14)
The proof of eq. (8.14) goes along the same lines of eq. (8.3):
p(stot, J ) =
!
Dx δ(stot −stot(x)) δ(J −J (x)) P(x)
=
!
Dx δ(stot −stot(x)) δ(J −J (x)) estot(x) P("x)
= estot/kB
!
D"x δ(stot + stot("x)) δ(J + J ("x)) P("x)
= estot/kB p(−stot, −J ).
(8.15)
We introduce a probability density normalized over the positive values of the total
entropy production:
p+(stot, J ) =
.
1 + e−stot/kB
/
p(stot, J ).
(8.16)
One has indeed, by eq. (8.14),
! ∞
0
dstot
! +∞
−∞
dJ p+(stot, J ) =
! ∞
−∞
dstot
! +∞
−∞
dJ p(stot, J ) = 1.
(8.17)

Developments
177
We then express the average of our extensive current as
⟨J ⟩=
! +∞
−∞
dstot
! +∞
−∞
dJ J p(stot, J )
=
! ∞
0
dstot
! +∞
−∞
dJ J p(stot, J )
.
1 −e−stot/kB
/
=
! ∞
0
dstot
! +∞
−∞
dJ J p+(stot, J ) 1 −e−stot/kB
1 + e−stot/kB
=
0
J tanh
1 stot
2kB
23+
,
(8.18)
where we deﬁne
⟨· · ·⟩+ =
! ∞
0
dstot
! +∞
−∞
dJ · · · p+(stot, J ).
(8.19)
The average entropy production can be similarly related to the average over positive
values only:
+
stot,
=
0
stot tanh
1 stot
2kB
23+
.
(8.20)
By applying the Cauchy-Schwarz inequality (see appendix A.12) to eq. (8.18), we obtain
⟨J ⟩2 =
40
J tanh
1 stot
2kB
23+52
≤
+J 2,+
0
tanh2
1 stot
2kB
23+
.
(8.21)
For any nonnegative variable x, one has
+
tanh2 x
,
≤tanh ⟨x⟩.
(8.22)
Indeed, if x ≥0, one has tanh2 x ≤tanh x, and moreover ⟨tanh x⟩≤tanh ⟨x⟩by the
Jensen inequality, since tanh x is concave for nonnegative x. We obtain therefore the
following thermodynamic uncertainty relation
σ 2
J
⟨J ⟩2 ≥
2
eStot/kB −1,
(8.23)
where σ 2
J =
+J 2,
−⟨J ⟩2 and we take into account that
+J 2,
=
+J 2,+.
The average of J is proportional to the duration T of the time interval: ⟨J ⟩= T Jst,
where Jst is the steady-state average of the associated intensive current. The same holds
for the total entropy production:
+
stot,
= T ˙Stot. Also the variance of J is extensive,
σ 2
J = ˜σ 2
j T , where ˜σ 2
j is the scaled variance of j. Substituting in (8.23) and taking the
small T limit, we obtain

178
Chapter 8
˜σ 2
j
( Jst)2 ≥2 kB
˙Stot ,
T ≪kB/˙Stot,
(8.24)
where we expand eStot/kB ≈1 + T ˙Stot/kB for small T . Equation (8.24) implies that the
coeﬃcient of variation of the current can be reduced only at the expense of an increased
entropy production rate, as we had anticipated. This bound holds in fact for any value
of T , as we discuss later.
The thermodynamic uncertainty relation can be generalized to multiple currents
Jα(x). To this aim, we deﬁne J (x) as a linear combination of the Jα’s:
J (x) =
6
α
λαJα(x),
(8.25)
where the coeﬃcients λα are arbitrary. We then write eq. (8.23) in the form
6
αβ
λαλβ
1
Cαβ −1
K ⟨Jα⟩+Jβ
,2
≥0,
(8.26)
where we introduce the correlation matrix
Cαβ =
+JαJβ
,
−⟨Jα⟩+Jβ
,
(8.27)
and the shorthand notation
K = 1
2
.
e⟨stot⟩/kB −1
/
.
(8.28)
If we now choose the coeﬃcients λ by
λα =
6
γ
C−1
αγ
+Jγ
,
,
(8.29)
where C−1 is the matrix inverse of C, we obtain
6
αβ
⟨Jα⟩C−1
αβ
+Jβ
,
−1
K

6
αβ
⟨Jα⟩C−1
αβ
+Jβ
,


2
≥0,
(8.30)
which implies the inequality
6
αβ
⟨Jα⟩C−1
αβ
+Jβ
,
≤K.
(8.31)

Developments
179
Switching to the currents Jst
α = limT →0+ ⟨Jα⟩/T and to the corresponding scaled
variances and covariances ˜σ 2 = (˜σ 2
αβ) = limT →0+ Cαβ/T , we obtain the multidimen-
sional uncertainty relation
6
αβ
Jst
α
#
˜σ 2$−1
αβ Jst
β ≤
˙Stot
2kB
.
(8.32)
We now discuss an important extension of uncertainty relations beyond the second
scaled cumulant. The rate function I( j) for large deviations of any current j satisﬁes the
bound
I( j) ≤
6
x′<x
#
jxx′ −Jst
xx′
$2
4kB ( Jst
xx′)2
˙Stot
xx′,
(8.33)
in which Jst
xx′ = kxx′pst
x′ −kx′xpst
x is the average current along the xx′ edge in the steady
state and ˙Stot
xx′ is the contribution of the xx′ edge to the average entropy production rate,
given by
˙Stot
xx′ = 2kB Jst
xx′ sinh−1 Jst
xx′
αxx′ = Jst
xx′
Axx′
T ,
(8.34)
where αxx′ = 2
;
kxx′kx′xpstx pst
x′. Equation (8.33) is proved in appendix A.13.
Near equilibrium, ﬂuctuations of the empirical entropy production rate jtot
s are Gaus-
sian (see section 6.2) and satisfy eq. (6.29). In keeping with eq. (8.34), we deﬁne the
empirical current jtot
s,xx′ = jxx′Axx′/T, representing the contribution of the xx′ edge to the
empirical entropy production rate. With this deﬁnition, we have <
x′<x jtot
s,xx′ = jtot
s
and
˙Stot
xx′ = ⟨jtot
s,xx′⟩. We also denote by ILR( jtot
s ) the rate function of jtot
s
in the linear response
regime. We obtain
ILR( jtot
s ) =
6
x′<x
( jtot
s,xx′ −˙Stot
xx′)2
4kB ˙Stot
xx′
=
6
x′<x
( jxx′ −Jst
xx′)2
4kB Jst
xx′
Axx′
T
=
6
x′<x
( jxx′ −Jst
xx′)2
4kB ( Jst
xx′)2 Jst
xx′
Axx′
T ,
(8.35)
which is equal to the right-hand side of eq. (8.33). This result provides additional phys-
ical insight into eq. (8.33). Since I( j) ≤ILR( j), eq. (8.33) eﬀectively means that large
ﬂuctuations of an arbitrary empirical current in the steady state are always more likely
than predicted by linear response theory.
From eq. (8.33), we derive a weaker but handier inequality, which holds for any
current j:
I( j) ≤IWLR( j) = ( j −Jst)2
4kB ( Jst)2 ˙Stot.
(8.36)
This bound depends only on the average current Jst
d and the average entropy production
rate ˙Stot. As a corollary, the bound of eq. (8.24) holds for any value of T , as anticipated.

180
Chapter 8
Choosing in particular the coeﬃcients dxx′ = Axx′/T, we obtain a weak linear response
bound for the entropy production rate jtot
s
itself:
I( jtot
s ) ≤IWLR( jtot
s ) = ( jtot
s −˙Stot)2
4kB ˙Stot
.
(8.37)
The right-hand side of eq. (8.37) is the parabolic rate function of the entropy pro-
duction rate predicted by linear response theory; see section 4.2. The thermodynamic
uncertainty relation implies that linear response theory provides a lower bound for
ﬂuctuations of the entropy production rate.
8.3
Applications of uncertainty relations
In this section, we apply thermodynamic uncertainty relations to two models of
molecular motors.
We ﬁrst use eq. (8.23) to bound the eﬃciency of a continuous molecular motor. The
molecular motor moves with an average speed v = ⟨˙r⟩, where r is its position along a
microtubule. The motor carries a load that exerts on the motor a force f . The average
entropy production rate is given by
T ˙Stot = ˙Wchem −f v,
(8.38)
where Wchem is the average rate of consumption of the chemical free energy. We express
Wchem in terms of the average ATP consumption rate Jn = ⟨˙n⟩and the ATP chemical
potential imbalance )µ by
˙Wchem = )µ ⟨˙n⟩.
(8.39)
The macroscopic eﬃciency of the motor is
ηS =
fv
˙Wchem =
fv
fv + T ˙Stot .
(8.40)
By substituting (8.24), we obtain
ηS ≤
1
1 + 2v kBT/(˜σ 2
j f ).
(8.41)
The bound provided by eq. (8.41) is particularly useful since all quantities appearing in
the right-hand side are in principle accessible to experiments.
Our second example is in the context of the kinesin model introduced in section 6.7.
This model is characterized by three independent currents. We focus on two of them:
the displacement ⟨˙r⟩and the rate of ATP consumption ⟨˙n⟩. Applying the relation (8.32),
we obtain the bounds

Developments
181
−6
−5
−4
−3
−2
f
0
20
40
Y, ˙S
˙Stot/kB
Yrr
Ynn
Yrn
Figure 8.2. Multidimensional uncertainty relation for a model of a molecular motor. The
model is deﬁned in section 6.7. The entropy production rate ˙Stot, in units of kB, is plot-
ted against the applied load f = Fd/kBT for a chemical potential imbalance )µ = 13 kBT.
The time unit is arbitrary. The quantities Yrr, Ynn, and Yrn deﬁned in eq. (8.42) are all
bounded by ˙Stot/kB by the multidimensional uncertainty relation (8.32). The bound is
tightest for Yrn.
Yrr = 2 ⟨˙r⟩2
˜σ 2rr
≤
˙S
kB
;
Ynn = 2 ⟨˙n⟩2
˜σ 2nn
≤
˙S
kB
,
Yrn = 2(⟨˙r⟩, ⟨˙n⟩) ·
#
˜σ 2$−1 ·
1
⟨˙r⟩
⟨˙n⟩
2
≤
˙S
kB
,
(8.42)
where ˙S is the average entropy production rate. The bound on Yrn is the most signiﬁcant,
since this quantity is the largest in our example, as shown in ﬁg. 8.2.
8.4
First-passage times
Large deviation theory describes the steady-state distribution of an integrated cur-
rent J for long time intervals T ; see chapter 6. Here we address a complementary
problem of characterizing the distribution of the ﬁrst-passage time Tfp( Jthr) of a cur-
rent. As the name says, the ﬁrst-passage time is the time at which the integrated current
ﬁrst crosses a given positive or negative threshold Jthr. In the steady state and for large
|Jthr|, an uncertainty relation also holds for the ﬁrst passage time:
σ 2
tfp
+
tfp
, ≥2kB
˙Stot ,
(8.43)

182
Chapter 8
where we deﬁne the intensive counterpart of the ﬁrst-passage time, tfp = Tfp/|Jthr|. To
prove eq. (8.43), we exploit the large deviation principle obeyed by currents:
p(J ; T ) ≍e−T I(J /T ),
(8.44)
where I(x) is the rate function. The average of the ﬁrst-passage time Tfp is approximately
proportional to |Jthr| for large |Jthr|. Therefore, Tfp also satisﬁes a large deviation prin-
ciple. The behavior of the ﬁrst-passage time for a positive (+) or negative (−) threshold
Jthr can in principle be diﬀerent. We denote with I+(tfp) and I−(tfp) the rate functions
corresponding to these two cases:
p(Tfp; Jthr) ≍
=
e−Jthr I+(Tfp/Jthr),
if Jthr > 0;
eJthr I−(−Tfp/Jthr),
if Jthr < 0.
(8.45)
We use the short notation I±(tfp) for either I+(tfp) or I−(tfp), depending on the sign of
Jthr. The rate functions for the ﬁrst-passage times are related to the rate function for the
current:
I(t)
± (tfp) = tfp I(±1/tfp).
(8.46)
We ﬁrst prove eq. (8.46) in the case Jthr > 0. We express the probability density of Tfp in
terms of the probability density of the trajectories:
p(Tfp = tfp Jthr) ≈
!
Dx δ(Tfp −tfp Jthr) P(x).
(8.47)
Equation (8.47) is approximate since we did not impose that the threshold is passed
for the ﬁrst time. However, for large Jthr, the times of all crossings are quite likely to
be relatively close to each other, so that eq. (8.47) provides the correct leading order
in Jthr. The trajectories that contribute to the integral in eq. (8.47) are those for which
the current is equal to Jthr. Thus the integral boils down to the probability p( Jthr; Tfp)
of having J = Jthr at time Tfp. Using the large deviation form of this probability, we
obtain
p(Tfp = tfp Jthr) ≍e−Tfp I( Jthr/Tfp) = e−Jthr tfp I(1/tfp),
(8.48)
from which (8.46) follows. The case Jthr < 0 can be treated in the same way.
We now extend the relation (8.46) between the rate functions of the current and the
ﬁrst-passage time to the scaled cumulant generating functions, deﬁned by
ψ( j)(q) = lim
T →∞
1
T ln
+
eq J,
;
ψ
(tfp)
±
(q) =
lim
|Jthr|→∞
1
|Jthr| ln
+
eq tfp,
,
(8.49)
where ± corresponds to the sign of Jthr. We now split ψ(q) in one branch (+) with posi-
tive slope and one (−) with negative slope. Remarkably, the scaled cumulant generating
functions are related by
ψ
(tfp)
±
(q) = −
1
ψ( j)
± (−q)
.
(8.50)

Developments
183
To prove this relation, we express the generating functions from the corresponding rate
function by means of the inverse Gärtner-Ellis theorem. Setting Jthr > 0 for deﬁniteness,
we obtain
ψ( j)(q) = q j∗−I( j∗),
j∗:
I′( j∗) = q;
(8.51a)
ψ
(tfp)
+
(q) = q t∗
fp −I+(t∗
fp),
t∗:
I′
+(t∗
fp) = q.
(8.51b)
We evaluate ψ( j)(−ψ
(tfp)
+
(q)), taking into account that t∗
fp corresponds to 1/j∗, obtain-
ing
ψ
.
−ψ
(tfp)
+
(q)
/
= −
.
q t∗
fp −I+(t∗
fp)
/
j∗−I( j∗)
= −q + 1
t∗
fp
I+(t∗
fp) −I
4
1
t∗
fp
5
= −q,
(8.52)
where we use eq. (8.46). This proves (8.50). The relations between these functions are
shown in ﬁg. 8.3. Evaluating
+
j
,
,
+
tfp
,
and the respective scaled variances by taking the
derivatives of the scaled cumulant generating functions around q = 0 results in
--+
j
,-- = 1
+
tfp
,;
˜σ 2
j =
--+
j
,-- ˜σ 2
tfp =
˜σ 2
tfp
+
tfp
,.
(8.53)
Substituting these expressions in the uncertainty relation (8.24), we obtain the uncer-
tainty relation (8.43) for the ﬁrst-passage time.
Some currents, such as the entropy production rate jtot
s , exhibit the Gallavotti-Cohen
symmetry; see section 6.4. In particular, the Gallavotti-Cohen symmetry for jtot
s
is
expressed by eq. (6.30) for the scaled cumulant generating function. The correspond-
ing symmetry for the scaled cumulant generating functions of the ﬁrst-passage time is
expressed by
ψ
(tfp)
+
(q) = ψ
(tfp)
−
(q) −1
kB
.
(8.54)
Applying once more the Gärtner-Ellis theorem, we ﬁnd that the rate functions for
positive and negative thresholds diﬀer by a constant:
I+(tfp) = I−(tfp) −1
kB
.
(8.55)
This relation implies that, up to the leading order, the probability of reaching a given
positive value stot of the total entropy produced in a given timeT exceeds the probability
of reaching the opposite value −stot by a factor exp(stot/kB).
Taking into account the weak linear response bound for the rate function I( j)
expressed by eq. (8.36), we obtain the inequality
I+(tfp) ≤IWLR(tfp) = (t −⟨t⟩)2
4kBt
˙Stot,
(8.56)

Figure 8.3. Large deviation func-
tions for the current j
and the
ﬁrst-passage
time
tfp
and
the
corresponding
generating
func-
tions. (a) The rate function I(j) for
the current j. It vanishes for the
average
+
j
,
. (b) The corresponding
rate functions for the ﬁrst-passage
time: I+(tfp) for positive threshold
currents and I−(tfp) for negative
threshold currents. They are related
to
I(j)
by
I±(tfp) = ±tfpI(±1/tfp).
The
smallest
values
correspond
to
tfp = 1/
+
j
,
.
The
two
curves
differ by a constant vertical offset.
(c) The scaled cumulant generating
function
ψ(q)
for
the
current.
The slope ψ′(0) at q = 0 yields
the average current
+
j
,
. (d) The
corresponding
scaled
cumulant
generating functions ψ
(tfp)
±
(q) for
the ﬁrst-passage time. They are
related to ψ(q) by the expression
ψ
(tfp)
±
(q) = −ψ−1
± (−q),
where
±
corresponds to the two branches
of the inverse of ψ(q). The slope
of
ψ
(tfp)
+
(q)
at
q = 0
yields
the
average ﬁrst-passage time 1/
+
j
,
.
See Gingrich and Horowitz [68].
(a)
(b)
(c)
(d)
ψʹ+(0) = 1/8 j9
−4
−2
0
q
0
2
ψ (tfp)
±
(q)
0
2
4
j
0.0
0.5
1.0
1.5
I(j)
8 j9
−2
−1
0
1
q
ψʹ(0) = 8 j9
0
2
4
(q)
ψ
ψ+
ψ−
ψ+
ψ−
0
1
2
3
4
tfp
0
2
4
I±(tfp)
1/8 j9
I+
I−

Developments
185
which shows how the ﬁrst-passage time ﬂuctuations are bounded by a function of
the entropy production rate, i.e., of the dissipation. The probability distribution cor-
responding to the right-hand side is an inverse Gaussian:
pWLR(tfp) =
>
Jthr ˙Stot
4kBπt3 exp
?
−Jthr(tfp −
+
tfp
,
)2 ˙Stot
4kBtfp
@
.
(8.57)
Interestingly, this is the same distribution that we would obtain by simply treating the
process as a one-dimensional diﬀusion process with constant drif
+
j
,
= 1/
+
tfp
,
and
diﬀusion coeﬃcient Dj = kB
+
j
,2 /˙Stot.
8.5
Fully irreversible processes
The irreversibility relation (4.12) connects the total entropy stot(x) produced in a tra-
jectory x to the ratio of the probability density of the trajectory x in the forward protocol
λ to that of the backward trajectory"x with the backward protocol"λ. A crucial underly-
ing hypothesis is that the manipulation is slow enough that the reservoir remains always
at equilibrium. Microscopic reversibility is a consequence of this hypothesis: whenever
a jump x −→x′ is allowed (its rate is nonvanishing), the reverse transition x′ −→x is
also allowed.
In some situations, this hypothesis is not satisﬁed because the manipulation proto-
col is too fast or the work involved too large. As an example, we consider a particle
that diﬀuses in a ﬁnite one-dimensional system. Its discrete coordinate x is in the range
1 ≤x ≤L0, where L0 > 1 is the coordinate of a removable wall. At equilibrium, the prob-
ability distribution is uniform on the allowed states, and the system entropy is given by
S0 = kB ln L0. At a time tc between t0 and tf, the wall at L0 is suddenly removed and
the particle is allowed to wander over a range 1 ≤x ≤Lf, with Lf > L0. Since no work is
performed by removing the wall, we have
%
e−w/kBT&
= 1.
(8.58)
The equilibrium entropy of the ﬁnal state is given by Sf = kB ln Lf > S0, while the
internal energy has remained constant, and therefore the free energy changes by
)F = −T )S = −kBT ln Lf
L0
< 0.
(8.59)
The Jarzynski equality
+
e()F−w)/kBT,
= 1 is therefore violated. To interpret this result,
we must have a closer look at the consequences of breaking microscopic reversibility.
We say that a trajectory x is allowed if its probability density Px does not vanish.
When microscopic reversibility (cf. section 2.6) does not hold, there exist allowed back-
ward trajectories"x under the backward protocol"λ whose reverse x are not allowed, i.e.,
Px(λ) = 0. In our example, this is the case for all the trajectories"x in which the particle
is found at time"tc at a site x in the interval L0 < x ≤Lf. We call reversible those trajec-
tories "x that are allowed under the reverse protocol "λ and whose reverse x is allowed
under the forward protocol λ. With these deﬁnitions, we generalize the irreversibility
relation (4.12) to

186
Chapter 8
Px(λ) e−stot(x)/kB =
=
P"x("λ),
if "x is reversible;
0,
otherwise.
(8.60)
We deﬁne prev as the total probability of reversible trajectories with the backward
protocol. Integrating eq. (8.60), we obtain the modiﬁed Jarzynski equality
%
e−stot(x)&
F =
!
Dx Px(λ) e−stot(x)/kB = prev.
(8.61)
In our speciﬁc example, the modiﬁed Jarzynski equality yields the correct result,
!
Dx Px(λ) e−stot(x)/kB = e−)S/kB = L0
Lf
,
(8.62)
since in this case prev = L0/Lf.
A similar reasoning applies to steady states. For example, we consider a system with
L states arranged on a ring. Jumps x −→(x + 1) and (x + 1) −→x are all allowed for
1 ≤x < L. The jump L →1 is also allowed, but the jump rate 1 −→L vanishes. In this
case, we say that the jump 1 −→L is fully or absolutely irreversible. We assume that all
the nonvanishing jump rates are equal. Then all the jumps x ←→(x + 1) with 1 ≤x < L
do not produce entropy. Entropy is produced only in the L −→1 transition, which has
no reverse. Therefore, if the trajectory x is reversible, i.e., if its reverse"x is allowed, the
relation
Px
P"x
= estot(x)/kB
(8.63)
is satisﬁed. Integrating over all reversible trajectories taking place from t = t0 to t = tf,
we obtain
! t=tf
t=t0
Dx Px e−stot(x)/kB = prev(tf),
(8.64)
where also in this case prev(tf) is deﬁned as the probability that an allowed trajectory x is
reversible. The rate of decrease of prev is given by the total rate at which fully irreversible
jumps take place in the steady state. In our model, this rate is equal to
1
prev(t)
dprev
dt
= −k1L pst
L .
(8.65)
Systems that possess absorbing states provide a common example of fully irre-
versible processes. In these cases, we characterize the dynamics by the survival prob-
ability psurv(t), i.e., the probability of not having been absorbed at time t. We consider
a system characterized by absorbing states during a time interval from t0 to tf. If a tra-
jectory x ends up in an absorbing state before tf, its reverse trajectory has a vanishing
probability. This also holds in reverse. As a consequence, we have
!
Dx Px e−stot(x)/kB = psurv(tf),
(8.66)
where the integral extends only over the reversible trajectories that run from t = t0 to
t = tf.

Developments
187
8.6
Optimal protocols
Many experiments in stochastic thermodynamics involve manipulation of a meso-
scopic system. We consider a manipulation that is speciﬁed by several control param-
eters λ(t) = (λα(t)), with α ∈{1, . . . , r}. The experiment is carried out from an initial
equilibrium state, characterized by values λα(t0) of the manipulation parameters to a
ﬁnal state characterized by other values λα(tf). In principle, there are inﬁnite ways of
performing this manipulation, speciﬁed by the functions λα(t) at ﬁxed initial and ﬁnal
values. Among these inﬁnite possibilities, it is ofen desirable to choose the optimal
manipulation protocol, deﬁned as the protocol that minimizes the average dissipated
work
Wdiss = W −F(λf) + F(λ0) = W −)F.
(8.67)
If T is very large and the manipulation is performed very slowly, the amount of work
can be made equal to the free-energy diﬀerence )F and therefore Wdiss = 0. For ﬁnite
T , the average dissipated work is positive, and determining the optimal protocol is not
always easy. This problem allows for an elegant solution if the manipulation is still rela-
tively slow and smooth, so that the system is never too far from equilibrium. The average
instantaneous power spent on the system at time t is
˙W = dF
dt + ˙Wdiss(t).
(8.68)
The last term in eq. (8.68) represents the average dissipation rate. It turns out that it can
be expressed in the form
˙Wdiss(t) =
6
αβ
gαβ(λ(t)) dλα
dt
dλβ
dt ,
(8.69)
in which g = (gαβ(λ)) is a generalized friction coeﬃcient. The generalized friction
coeﬃcient is a symmetric and positive semideﬁnite matrix, which depends smoothly
on λ, except possibly at macroscopic phase transitions. Its speciﬁc form depends on the
system at hand. The matrix g can be expressed in terms of observables Xα,x, deﬁned by
Xα,x = ∂ϵx(λ)
∂λα
,
(8.70)
where ϵx(λ) is the energy of state x. We have in fact
gαβ(λ) = 1
kBT
! ∞
0
dt Cαβ(t; λ),
(8.71)
in which we introduce the equilibrium correlation function
Cαβ(t; λ) =
+#
Xα,x(t) −
+
Xα,x
,eq$ #
Xβ,x(0) −
+
Xβ,x
,eq$,eq ,
(8.72)
where the averages are evaluated at ﬁxed λ.
Before deriving eq. (8.69), we interpret it in the language of diﬀerential geometry
with the aim of ﬁnding the optimal protocol. The symmetric and positive semideﬁnite

188
Chapter 8
matrix gαβ(λ) deﬁnes a metric in the space spanned by the manipulation variables λ. If
the λαs change by dλα, the corresponding traveled distance in this space is
ds =
>6
αβ
gαβ dλα dλβ.
(8.73)
We express the average dissipated work ˙Wdiss in terms of the speed ds/dt in the
manipulation space:
˙Wdiss =
6
αβ
gαβ
dλα
dt
dλβ
dt =
1ds
dt
22
.
(8.74)
This is the same expression of the kinetic energy of a free particle of mass equal to 2
moving on a space with metric gαβ. We deﬁne the total dissipation length of a trajec-
tory λ:
L(λ) =
! tf
t0
dt
A
B
B
C
6
αβ
gαβ(λ(t)) dλα
dt
dλβ
dt .
(8.75)
One can verify that this expression is invariant under reparameterizations λ(t) −→
λ′(τ), where λ′(τ(t)) = λ(t), with τ(t) a monotonically increasing function for t ∈
[t0, tf]. We assign to the same path [λ] all trajectories λ that can be mapped one onto the
other by reparameterization. The dissipation length is the same for all these trajectories,
hence it can be considered as a function of the path L = L([λ]). Given a path [λ], the
average dissipated work Wdiss on any trajectory of duration T = tf −t0 associated with
it satisﬁes the bound
Wdiss T ≥L2.
(8.76)
This bound follows from the Cauchy-Schwarz inequality: we write L in the form
L =
! tf
t0
dt 1 ·

6
αβ
gαβ(λ(t)) dλα
dt
dλβ
dt


1/2
.
(8.77)
We then have
L2 ≤
! tf
t0
dt 12 ×
! tf
t0
dt
6
αβ
gαβ(λ(t)) dλα
dt
dλβ
dt = T · Wdiss.
(8.78)
One can verify that the bound is saturated if the protocol satisﬁes the condition
6
αβ
gαβ(λ(t)) dλα
dt
dλβ
dt = const.
(8.79)
This corresponds to imposing that the average dissipated power is constant during the
manipulation.

Developments
189
We summarize the above results by a prescription for the optimal manipulation
protocol λ∗, given the generalized friction coeﬃcient gαβ(λ):
1. Identify the geodesic path [λ∗], i.e., the path of minimal dissipation length L
connecting the two endpoints λ0 and λf.
2. Find the trajectory λ that runs along the path [λ∗] and satisﬁes the condition
(8.79).
We can associate with a trajectory λ = (λ(t)) other trajectories λT of arbitrary dura-
tion T that follow the same path [λ], by linearly reparameterizing the time t. The
average dissipated work Wdiss in these trajectories decreases like T −1 as T becomes
large.
We now sketch the derivation of (8.69). From (8.68), we obtain
˙Wdiss =
6
α
dλα
dt
.
⟨Xα(t; λ(t))⟩λ −⟨Xα(λ(t))⟩eq
λ(t)
/
,
(8.80)
where ⟨· · ·⟩eq
λ is the equilibrium average with the given value of λ and we make explicit
the dependence of Xα on λ. We now exploit the linear response theory developed in
section 3.11. We obtain, to ﬁrst order in the perturbation and for a given protocol λ
such that limt→−∞λ(t) = λ(0),
⟨Xα(t; λ(t))⟩λ −⟨Xα(λ(t))⟩eq
λ(t) =
6
β
! t
−∞
dt′ Kαβ(t −t′; λ(0))
.
λβ(t′) −λ(0)/
,
(8.81)
where
Kαβ(t; λ) = −θ(t)
kBT
d
dtCαβ(t; λ),
(8.82)
and Cαβ(t; λ) is the correlation function deﬁned in (8.72). We substitute this expression
into eq. (8.81) and integrate by parts. The boundary terms vanish, one trivially and the
other assuming that the manipulation starts from equilibrium. We thus obtain
˙Wdiss(t) = 1
kBT
6
αβ
dλα
dt
! t
−∞
dt′ Cαβ(t −t′; λ(t)) dλβ(t′)
dt′
.
(8.83)
Changing the variable to τ = t −t′, eq. (8.83) takes the form
˙Wdiss(t) = 1
kBT
6
αβ
dλα
dt
! ∞
0
dτ Cαβ(τ; λ(t)) dλβ(t′)
dt′
----
t′=t−τ
.
(8.84)
We now expand in τ, obtaining
dλβ(t′)
dt′
----
t′=t−τ
= dλβ
dt −τ d2λβ
dt2 + o (τ) .
(8.85)

190
Chapter 8
Assuming that the manipulation is slow enough so that the change in dλ/dt in a time
on the order of the correlation time can be neglected, we keep only the ﬁrst term and
obtain
˙Wdiss(t) =
6
αβ
dλα
dt gαβ(λ(t)) dλβ
dt ,
(8.86)
where gαβ(λ) is given by (8.71), as anticipated.
An interesting, exactly solvable example is the case of a Brownian particle in a one-
dimensional harmonic potential of strength κ whose minimum is placed at ℓ. We
describe the dynamics by a Langevin equation with mobility µP:
dx
dt = −µPκ (x −ℓ) + ξ(t),
(8.87)
where ⟨ξ(t)⟩= 0,
+
ξ(t) ξ(t′)
,
= 2µP kBT δ(t −t′) by the Einstein relation. The manipu-
lation parameters are ℓand κ, and the associated observables are
∂ϵ(x)
∂ℓ
= −κ (x −ℓ);
∂ϵ(x)
∂κ
= 1
2 (x −ℓ)2 .
(8.88)
Since the equation of motion is linear, the correlation function Cαβ(t; λ), with λ =
(ℓ, κ), can be analytically obtained:
C(t; ℓ, κ) =
1
κ kBT e−µPκ|t|,
0
0,
(kBT/κ)2e−2µPκ|t|/2
2
,
(8.89)
and therefore the generalized friction coeﬃcient is given by
g(ℓ, κ) =
11/µP,
0
0,
kBT/4µPκ3
2
.
(8.90)
The matrix gαβ is diagonal, and its entries are independent of each other. Thus the
optimization problem boils down to two separate ones, for ℓand κ, respectively. The
solution for ℓis dℓ/dt = const. For κ, we obtain
˙κ2
κ3 = const.
(8.91)
or, equivalently,
dκ−1/2
dt
= const.,
(8.92)
which can be used to impose the boundary conditions.
The theory developed in this section was exploited to experimentally design energet-
ically eﬃcient nonequilibrium processes in the folding and unfolding of a DNA hairpin.
The generalized friction coeﬃcient g(λ) was estimated by measuring the equilibrium
autocorrelation function of the applied force at diﬀerent values of the control parameter
λ, which, in the case of the DNA hairpin, corresponds to a ﬁxed value of the separation
of the optical traps to which the DNA molecule is tethered. The distribution of the force

Developments
191
0.1
0.3
1.0
2.0
T  (s)
1
3
10
Wdiss/kBT
Naive
Designed
Figure 8.4. Average dissipated work with a naive and a designed protocol. The average
dissipated work W diss (in units of kBT) is plotted against the duration of the protocol T . In
the naive protocol, the separation of the optical traps is increased linearly. In the designed
protocol, the speed is inversely proportional to the square root of the generalized friction
coefﬁcient, eq. (8.79). Both axes are logarithmic. (Data from Tafoya et al. [164].)
is unimodal at small and large separations but is bimodal at intermediate values, show-
ing how the molecule vacillates from a partially folded to a partially unfolded state.
From knowledge of g(λ), the optimal protocol is evaluated by imposing the condition
(8.79). In this way, one obtains a substantially smaller average dissipation, as shown in
ﬁg. 8.4.
8.7
Martingales
Martingales are a powerful concept in the theory of stochastic processes. We con-
sider a stochastic process x(t), where the variable x can be either discrete or continuous.
We estimate ⟨x(t)⟩based on past observations x(t1), x(t2), x(t3), ..., with t > t1 > t2 >
t3 · · · . A martingale is a process in which this conditioned average is equal to the last
observed value,
⟨x(t)|x(t1), x(t2), x(t3), . . .⟩= x(t1),
(8.93)
regardless of the number of past observations, their times, or their outcomes. In a nut-
shell, a martingale is a stochastic process with no average drif. As is the case in much
of probability theory, the concept of a martingale ﬁnds its origin in gambling: if x(t)
represents a gambler’s fortune at a certain time t, x(t) is a martingale if the game is fair,
i.e., if the gambler should expect neither to lose nor to win money on average.
To understand the usefulness of martingales, we introduce the concept of a stop-
ping time tstop. A stopping time is a random time determined by some conditions on
the trajectory. First-passage times are an example of stopping times, determined by the
condition of reaching a given state. Stopping times are however more general: a stopping
time could be, for example, the Nth time at which a given state has been visited, or the

192
Chapter 8
ﬁrst time that a state has been visited afer having visited another state. The only restric-
tion is that a stopping time cannot depend on the future, i.e., on events or conditions
determined afer tstop.
A major result of the theory of martingales is Doob’s optional stopping theorem,
which states that, under certain assumptions, the average of a martingale at a stopping
time is equal to its initial value:
⟨x⟩tstop = x(t0).
(8.94)
There are several versions of Doob’s theorem in the literature, based on slightly diﬀerent
assumptions. A common version requires the stopping time to satisfy at least one of the
following three properties:
1. The stopping time is bounded, tstop ≤c, where c < ∞is a constant.
2. The average stopping time is ﬁnite,
+
tstop
,
< ∞, and the increments of the
process are bounded, |x(t + )t) −x(t)| ≤c with c < ∞.
3. The process itself is bounded, |x(t)| ≤c for t ≤tstop and c < ∞.
An example of a stopping time that does not satisfy any of these conditions is the
ﬁrst-passage time for a one-dimensional unbiased random walk. Indeed, an unbiased
one-dimensional random walk is a martingale, but its ﬁrst-passage time does not satisfy
eq. (8.94): the average of x at the ﬁrst-passage time is equal to position x of the absorbing
state, which is in general diﬀerent from the initial condition x(t0).
The meaning (and importance) of Doob’s theorem is best understood by returning
to our example of gambling. Strategic players have long tried to proﬁt from fair games
by devising strategies to leave the gambling table when certain conditions are met, for
example, when their fortune surpasses a given value. Doob’s theorem conﬁrms the intu-
ition that these strategies never lead to an average proﬁt. However, a gambler willing to
play for an inﬁnite time and having access to inﬁnite economic resources can break all
three conditions of Doob’s theorem and therefore proﬁt, on average, from a fair game.
The link between martingale theory and stochastic thermodynamics comes from the
fact that, in any steady-state mesoscopic system, the quantity e−stot/kB is a martingale.
We now verify that this is the case. Since we consider Markov processes, conditioning
to a succession of past events is equivalent to conditioning to the last event only:
%
e−stot(t)/kB
---e−stot(t1)/kB, e−stot(t2), · · ·
&
=
%
e−stot(t)/kB
---e−stot(t1)/kB
&
.
(8.95)
We now use the expression of entropy production in terms of trajectory probabilities,
eq. (4.12). Given a trajectory x deﬁned between t0 and t, we have
estot(x)/kB = Px
P"x
= px0Px|x0
pxtP"x|xt
.
(8.96)
We call x1 the part of the trajectory in the time interval [t0, t1) and x2 the part of the
trajectory in the time interval [t1, t], including t1. This means that the sum over the
state of the system at time t1 is included in Dx2 but not in Dx1. We also decompose the
entropy production stot(t) into two contributions, stot(t) = s1 + s2(x2), where s1 and s2
are the entropies produced in the time intervals [t0, t1) and [t1, t], respectively. Since we
condition on the value of s1, we do not explicitly write its dependence on x1. These two

Developments
193
contributions have the same form of eq. (8.96) thanks to the fact that the system is in a
steady state. We now write the conditional average in eq.(8.95) explicitly:
%
e−stot(t)/kB
---e−stot(t1)/kB
&
=
D Dx1
D Dx2 Px e−stot(t)/kB δ(stot(t1) −s1)
D Dx1
D Dx2 Px δ(stot(t1) −s1)
.
(8.97)
The delta function selects the trajectories characterized by the given entropy production
s1 in the ﬁrst time interval. Since the function to be averaged is constant, summing
over x1 leaves us with the probability of a state xt1 conditioned to having produced an
entropy s1 in the ﬁrst interval:
%
e−stot(t)/kB
---e−stot(t1)/kB
&
= e−stot(t1)/kB
D Dx2 Px2|xt1e−s2(x2)/kBpxt1|s1
D Dx2 Px2
,
(8.98)
where
pxt1|s1 =
D Dx1 Px1 δ(stot(t1) −s1) δK
x(t1),xt1
D Dx1 Px1δ(stot(t1) −s1)
.
(8.99)
The denominator on the right-hand side of eq. (8.98) is equal to 1 because of the
normalization. Using the deﬁnition of entropy production, eq. (8.96), we obtain
%
e−stot(t)/kB
---e−stot(t1)/kB
&
= e−stot(t1)/kB
!
Dx2 pxtP"x2|xt
pxt1|s1
pxt1
= e−stot(t1)/kB 6
xt1
pxt1|s1 = e−stot(t1)/kB,
(8.100)
as anticipated.
We now explore the physical consequences of the fact that, in the steady state,
e−stot/kB is a martingale. First of all, at the initial time t0, stot vanishes, and therefore
e−stot(t0)/kB = 1. This implies that, for any stopping time tstop satisfying at least one of
the conditions above, one has
%
e−stot/kB
&
tstop
= 1.
(8.101)
Equation (8.101) is the integral ﬂuctuation relation at stopping times. For a ﬁxed tstop,
eq. (8.101) reduces to the steady-state integral ﬂuctuation theorem, eq. (4.15).
An interesting nontrivial example is the stopping time tstop deﬁned as the ﬁrst time
for which e−stot/kB ≥c with c > 1. If in a given trajectory e−stot/kB never reaches c, then
tstop = ∞. Before the stopping time, one has
0 <
%
e−stot/kB
&
tstop
≤c,
(8.102)
and therefore the stopping time satisﬁes condition 3 of Doob’s theorem. We call pc the
probability that e−stot/kB ≥c at a ﬁnite time. Since for long times e−stot/kB →0, we obtain
from eq. (8.101)

194
Chapter 8
−10.0
−7.5
−5.0
−2.5
0.0
stot
10−6
10−4
10−2
100
p(inf stot)
infimum law
δ = 0.25
δ = 1
Figure 8.5. Inﬁmum law. Points are obtained from 104 simulations of a dragged particle
on a ring; see section 4.3. The parameter δ represents the amount of external work per
step in the positive direction in units kBT. The probability density p
#
inf stot$
is plotted
against stot, measured in units of kB. The line is the inﬁmum law given by eq. (8.105). The
vertical axis is logarithmic.
pc
%
e−stot/kB
&
c = 1,
(8.103)
where
%
e−stot/kB
&
c is the average value of e−stot/kB at the time of passing the threshold c,
conditioned on passing it. If the trajectories of stot are continuous, then
%
e−stot/kB
&
c = c,
and we obtain pc = 1/c. Changing variables, pc represents the probability that stot
attains values smaller than or equal to ¯s = −kB ln c at a ﬁnite time. This means that,
for continuous processes,
p
#
stot ≤¯s for some ﬁnite t
$
= e¯s/kB.
(8.104)
Equation (8.104) can be seen as the cumulative distribution of the inﬁmum of stot
along an inﬁnite trajectory. We obtain the probability density of the inﬁmum by taking
the derivative with respect to ¯s:
p
#
inf stot = ¯s
$
= 1
kB
e¯s/kB.
(8.105)
Equation (8.105) is the inﬁmum law (ﬁg. 8.5). It states that, for any steady-state contin-
uous process, the probability of observing a “negative record” ¯s of entropy production
is exponentially distributed with average kB. For discontinuous trajectories, such as in
discrete processes, one has in general
%
e−stot/kB
&
c ≤c, since in principle discontinuous
trajectories can jump below the threshold without hitting it exactly. Therefore, in the

Developments
195
discontinuous case, the distribution (8.104) is an upper bound:
p
#
stot ≤¯s for some ﬁnite t
$
≤e¯s/kB.
(8.106)
The importance of the inﬁmum law is that it provides a very simple bound on the
probability of observing negative values of the entropy production. Mathematically, it
is also a very good example of the usefulness of martingales and Doob’s theorem: using
them allows us to prove some simple and surprising general results in very few steps.
Following a similar logic, we can prove that several statistical properties of stot related
to more complex ﬁrst-passage times are universal, and compute them explicitly.
8.8
Random time
Entropy production in continuous systems can be studied by a technique of stochas-
tic processes called a random time transformation. To introduce this idea, we start
with an instructive exercise in stochastic calculus. In section 3.13, we derived stochas-
tic thermodynamics observables following the rules of the Stratonovich convention. We
now derive the same observables in the Ito convention, which we use throughout this
section. The energy change is expressed by
d
dtϵ(x(t), t) = ∂
∂tϵ(x, t) + ∂
∂xϵ(x, t) · dx
dt + D ∂2
∂x2 ϵ(x, t),
(8.107)
where the last term comes from applying the Ito formula (2.128). Similarly, the work
change is expressed by
d
dtw(x(t), t) = ∂
∂tϵ(x, t) + f (x, t) · dx
dt + D ∂
∂xf (x, t).
(8.108)
We obtain the heat change by applying the ﬁrst law of stochastic thermodynamics:
d
dtq(x(t), t) = d
dtw(x, t) −d
dtϵ(x, t) = F(x, t) · dx
dt + D ∂
∂xF(x, t),
(8.109)
where F(x, t) = −(∂xϵ + f ) is deﬁned in eq. (3.82). Equations (8.107), (8.108), and
(8.109) are equivalent to the expressions (3.86), (3.87), and (3.88), respectively, in the
Stratonovich convention. We now proceed to compute the entropy production rate. The
rate of system entropy change is given by
d
dtssys = −kB
E
1
p(x; t)
∂
∂tp(x; t) +
1
p(x; t)
∂
∂xp(x; t) · dx
dt
−
D
p2(x; t)
F ∂
∂xp(x; t)
G2
+
D
p(x; t)
∂2
∂x2 p(x; t)
H

196
Chapter 8
= kB
E
−
2
p(x; t)
∂
∂tp(x; t) −F(x, t)
kBT
· dx
dt + J(x, t)
Dp(x; t) · dx
dt
+
D
p2(x; t)
F ∂
∂xp(x; t)
G2
−
1
p(x; t)
∂
∂x[µPF(x, t)p(x; t)]
H
,
(8.110)
where in the last equality we use J(x, t) = µPF(x, t)p(x; t) −D ∂xp(x; t) and the Fokker-
Planck equation. We obtain the total entropy production rate by applying the Ito
formula once more:
d
dtstot = d
dtsenv(x(t), t) + d
dtssys(x(t), t)
= kB
E
−
2
p(x; t)
∂
∂tp(x; t) + µP
∂
∂xF(x, t) + J(x, t)
Dp(x; t) · dx
dt
+
D
p2(x; t)
F ∂
∂x
p(x; t)
G2
−
1
p(x; t)
∂
∂x[µPF(x, t)p(x; t)]
H
= kB
E
−
2
p(x; t)
∂
∂tp(x; t) + J(x, t)
Dp(x; t) · dx
dt
+
D
p2(x; t)
F ∂
∂xp(x; t)
G2
−µPF(x, t)
p(x; t)
∂
∂x
p(x; t)
H
(8.111)
= kB
F
−
2
p(x; t)
∂
∂tp(x; t) + J(x, t)
Dp(x; t) · dx
dt −J(x, t)
p2(x; t)
∂
∂xp(x; t)
G
= kB
?
−
2
p(x; t)
∂
∂tp(x; t) + J(x, t)2
Dp2(x; t) +
√
2J(x, t)
√
Dp(x; t)
ξ(t)
@
.
It is convenient to deﬁne
vs(x, t) = J2(x, t)
Dp2(x; t).
(8.112)
In terms of vs, the entropy production rate is expressed by
dstot
dt = kB
F
−2 ∂
∂t ln p(x; t) + vs(x, t) +
I
2vs(x, t)ξ(t)
G
.
(8.113)
Equation (8.113) is most useful in the steady state, where vs(x) can be interpreted as the
expected rate of entropy production in state x:
dstot
dt = kBvs(x) + kB
I
2vs(x) ξ(t).
(8.114)
The drif term of the Langevin equation (8.114) is equal to the diﬀusion term. This
property is related to the fact that e−stot/kB is a martingale. In the steady state, we have
in fact

Developments
197
d
dte−stot/kB = −e−stot/kBI
2vs(x) ξ(t).
(8.115)
Equation (8.115) is a Langevin equation (in the Ito interpretation) without drif: the
drif term cancels out with the Ito term in the chain rule, precisely because the drif and
diﬀusion terms in eq. (8.114) are equal. Since the average of the noise term in the Ito
equation always vanishes, the future average of e−stot/kB is equal to the initial value, i.e.,
e−stot/kB is a martingale.
A convenient way to analyze eq. (8.114) is to introduce the random time trnd, such
that
dtrnd = vs(x(t)) dt.
(8.116)
As the name suggests, the transformation between the “real” time t and the random time
trnd is stochastic, i.e., it depends on the trajectory via the quantity vs(x(t)). The random
time transformation contracts or dilates time depending on whether the local entropy
production rate is respectively large or small. In terms of the random time, eq. (8.114)
becomes
d
dtrnd
stot = kB + kB
√
2 ξ′(trnd),
(8.117)
where ξ′(trnd) is white noise. Equation (8.117) shows that the dynamics of entropy
production is system-independent when measured in terms of the random time. This
implies that ﬁrst-passage probabilities of entropy production are universal, since these
probabilities do not depend on the “speed” of the clock. For example, the inﬁmum law
introduced in eq. (8.105) can be derived by studying the probability of a trajectory of
eq. (8.117) to cross a given negative threshold. Other universal properties of continuous
systems can be similarly derived by considering diﬀerent ﬁrst-passage problems.
8.9
Population genetics
There exists a deep analogy between population genetics and thermodynamics. R. A.
Fisher [55], one of the fathers of population genetics, already pointed out this analogy in
the 1930s. In the context of the fundamental theorem of natural selection, according to
which the rate of increase in reproductive value (ﬁtness) of an organism is proportional
to its variance due to genetic factors, he states:
It will be noticed that the fundamental theorem proved above bears some remark-
able resemblances to the second law of thermodynamics. Both are properties
of population, or aggregates, true irrespective of the nature of the units which
compose them; both are statistical laws; each requires the constant increase of a
measurable quantity, in the one case the entropy of a physical system and in the
other the ﬁtness, measured by m, of a biological population. (p. 36)
This analogy extends to stochastic thermodynamics, and several works have exploited
this idea to obtain new results in population genetics. We focus here on one approach,
which allows us to obtain information on selection pressures in populations from
genealogical data.
The reproduction rate of an individual in a population depends on many features that
we call traits. Some of these traits are inheritable. In population genetics, it is important

198
Chapter 8
to identify traits and understand how they aﬀect reproduction rates. This goal can be
achieved by relating two distinct probability distributions of traits.
We consider a population initially made up of Ntot(t0) ≫1 asexually reproducing
individuals. Each individual carries a trait speciﬁed by a variable x. Individuals repro-
duce at a constant rate rx, depending on the trait and possibly on the environment. In
a reproduction event, the “mother” cell divides into two “daughters.” We momentarily
consider the simplest scenario in which the two daughters carry the same value of the
trait as their mother. At a given ﬁnal time tf, the population consists of Ntot(tf) indi-
viduals. We characterize each individual i by its trait xi and by its lineage, i.e., by the
collection of identities of its ancestors, from its mother up to its ancestor in the initial
population at t0. In particular, the lineage permits us to determine the number ρi of
cell divisions between the initial ancestor and the individual at time tf. If the model
includes birth events only, the population grows exponentially with time. However, the
size of most natural populations is limited by factors such as resource availability. A
simple modeling choice in this case is to maintain the population size N constant: at
every cell division, one other individual is removed. For example, in the Moran model
of population genetics, the individual to be removed is chosen at random.
In these cases, the N individuals constituting the population at time tf are the descen-
dants of a smaller number N(t0) of individuals in the initial population. In the following,
we focus on the individuals present at time tf and all their ancestors as speciﬁed by their
lineages. The number of individuals belonging to this set of lineages decreases mono-
tonically from N(tf) to N(t0) as we go back in time. We assume that N is always large
enough, so that we can neglect the eﬀects of sampling ﬂuctuations.
We momentarily focus on a single clone, i.e., on the family of descendants of a single
individual in the initial population. Lineages within a clone can be sampled in two ways.
One possibility is retrospective sampling. In retrospective sampling, we trace back the
ancestors of the ﬁnal population. Speciﬁcally, we randomly pick up one individual i
in the ﬁnal population with probability pret
i
= 1/N(tf), where N(tf) is the size of the
clone, and sample its lineage and its phenotypic trait xi. An alternative is chronological
sampling. In chronological sampling, we start from the ancestor and randomly pick
up one of the two daughters at each division with equal probabilities. In this case, the
lineage of an individual i that underwent ρi divisions since the initial time is sampled
with probability pchr
i
= 2−ρi. The probability pchr
i
depends only on the number ρi of
divisions of the lineage of individual i. In contrast, the probability pret
i
also depends
on the reproductive performance of the other lineages, via the total number Ntot(tf) of
individuals present at time tf. The discrepancy between the two sampling probabilities
reﬂects the variability in the number of divisions—i.e., in reproductive success—among
the diﬀerent lineages. Our aim is to exploit this discrepancy to evaluate the eﬀect of the
trait on the division rate.
We now generalize this idea to a heterogeneous population made up of individuals
with diverse traits and possibly belonging to diﬀerent clones. We assume to know the
lineage, phenotypic trait xi, and number of divisions ρi of each individual i in the ﬁnal
population. We then evaluate the joint retrospective distribution
pret
ρ,x = nρ,x
N(tf),
(8.118)
where nρ,x is the number of individuals at time tf with a lineage with ρ divisions and
phenotypic trait x. We also deﬁne the joint chronological distribution

Developments
199
pchr
ρ,x = 2−ρ
N(t0)nρ,x.
(8.119)
The population growth rate is deﬁned by
3 = 1
T ln N(tf)
N(t0),
(8.120)
where T = tf −t0. We then have the relation
pret
ρ,x = eT (˜hρ−3) pchr
ρ,x,
(8.121)
where
˜hρ = 1
T ρ ln 2.
(8.122)
Equation (8.121) bears a formal similarity to ﬂuctuation relations, with the two distribu-
tions pret
ρ,x and pchr
ρ,x respectively playing the roles of the forward and backward trajectory
probabilities. The quantity T (˜hx −3) is therefore analogous to a total entropy pro-
duction. As with ﬂuctuation theorems, it is possible to derive variants of eq. (8.121) by
choosing diﬀerent forward and backward distributions.
We follow this approach to estimate ﬁtness. The ﬁtness of a trait x measures the
reproductive success of the individuals carrying it. It is formally deﬁned as the expected
number of oﬀspring of an individual with the given trait. In practice, ﬁtness is rather
diﬃcult to evaluate. By comparing retrospective and chronological sampling, we can at
least obtain a related quantity. We introduce the marginals
pret
x =
6
ρ
pret
ρ,x;
pchr
x
=
6
ρ
pchr
ρ,x.
(8.123)
We deﬁne the ﬁtness landscape hx as a measure of the dependence of the eﬀective
division rate on a trait x:
hx = 1
T ln N(tf) pret
x
N(t0) pchr
x
= 3 + 1
T ln pret
x
pchr
x
.
(8.124)
Inverting this relation, we obtain
pret
x = eT (hx−3) pchr
x .
(8.125)
The ﬁtness landscape speciﬁes the dependence of the division rate on the trait x. If
genealogical data on a population is available, the ﬁtness landscape hx can be obtained
by sampling both pret
x and pchr
x . In the Moran model, if some individuals in the initial
population do not have descendants at tf, the ﬁtness landscape diﬀers from the repro-
duction rate by an additive constant, dependent on the probability of such events. This
phenomenon can be understood using the formalism of section 8.5: lineages having no
descendant are analogous to irreversible trajectories in stochastic thermodynamics.

200
Chapter 8
0.0
0.5
1.0
rx
0.5
1.0
hx
Figure 8.6. Estimated ﬁtness landscape hx plotted against division rate rx for a population
of N = 10, 000 individuals evolving according to a Moran model for time T = 5, where the
unit of time is the doubling time of the fastest clones. The trait x can take values from
0 to 5, with division rate rx = e−x/2. The dotted line is a ﬁt to h = r + const. The average
number of divisions per lineage in this run is 5.64.
Substituting the relation
pchr
ρ|x =
pchr
ρ,x
pchr
x
(8.126)
in eq. (8.124) and expressing pret
ρ,x by
pret
ρ,x = N(t0)
N(tf) 2ρ pchr
ρ,x,
(8.127)
we obtain the following alternative expression of the ﬁtness landscape:
hx = 1
T ln
6
ρ
2ρpchr
ρ|x.
(8.128)
The expression (8.128) provides a more convenient way to estimate the ﬁtness land-
scape from lineage distributions. Given lineage data from a large enough population,
this procedure can be carried out by looking at a relatively small number of generations
(ﬁg. 8.6).
We now generalize our theory to population dynamics characterized by phenotypic
switching. Phenotypic switching is a process that changes the trait x of an individual,
and can originate from diﬀerent biological mechanisms. For example, a strong evolu-
tionary pressure can lead to rapid adaptation of a population, with a consequential shif
of individual traits within a few generations. More recently, it has been observed that

Developments
201
even genetically identical populations ofen diversify individual phenotypes. In partic-
ular, individuals belonging to these populations may stochastically switch their trait x
in the course of their lifetimes.
We model the latter case assuming that individuals switch from phenotype x′ to x
with constant rate kxx′. Phenotypic switching and duplication occur independently.
Switching can be costly for individuals. We denote by edxx′ the survival probability
of an individual switching its phenotype, where dxx′ ≤0. We deﬁne the phenotypic
trajectory of a lineage as
x = ((x0, t0), (x1, t1), . . . , (xn, tn), tf).
(8.129)
The expected number of descendants of an individual with phenotypic trajectory x is
Nx = erxn(tf−tn)
n−1
J
ℓ=0
.
erxℓ(tℓ+1−tℓ)+dxℓ+1xℓ
/
= exp

6
x
rxτx(x) +
6
x̸=x′
dxx′nxx′(x)

,
(8.130)
where τx(x) are the empirical dwell times and nxx′(x) the empirical jump numbers
associated with the phenotypic trajectory x, respectively deﬁned by eqs. (6.13) and
(6.99). The probability of a phenotypic trajectory is also given by the expression (2.91)
of the trajectory probability Px of a master equation with jump rates kxx′. We therefore
identify Nx as the probability ratio of the phenotypic trajectory x in the retrospective
sampling to that in the chronological sampling. The expected total population size at
time tf is thus given by
Ntot(tf) =
!
Dx Nx Px Ntot(t0).
(8.131)
The population growth rate (8.120) is therefore
3 = lim
T →∞
1
T ln ⟨Nx⟩
= lim
T →∞
1
T ln
O
exp

6
x
rxτx(x) +
6
x̸=x′
dxx′nxx′(x)


P
,
(8.132)
where the average is taken with respect to the probability density Px of the pheno-
typic trajectories. Equation (8.132) shows that the population growth rate is the scaled
cumulant generating function of the dwell-time and jump-number distribution. By the
Gärtner-Ellis theorem, we express 3 as the Legendre-Fenchel transform of the rate
function I( f , κ) of the empirical jump rates κ and the empirical vector f :
3 = ψ( f ,κ)(r, d) = sup
f ,κ

6
x
rxfx +
6
x̸=x′
dxx′κxx′fx′ −I(κ, f )

.
(8.133)

202
Chapter 8
The rate function I( f , κ) is given by eq. (6.105), and the supremum is taken over all
f , κ satisfying the empirical stationarity condition; see section 6.9. We compute the
supremum ( f ∗, κ∗) using tilting. The generator of the tilted dynamics reads
Lxx′ =
#
rx −kout
x
$
δK
xx′ + edxx′ kxx′,
(8.134)
where kout
x
= <
x′ kx′x. We obtain
κ∗
xx′ = ux
ux′
#
Lxx′ −3 δK
xx′
$
,
f ∗
x = vx,
(8.135)
where u = (ux) and v = (vx) are respectively the lef and right eigenvectors of L = (Lxx′)
belonging to its maximum eigenvalue 3. This procedure bears an analogy with the
cloning algorithm described in section 6.8 to evaluate the scaled cumulant generating
function of a current.
The rates κ∗deﬁne the retrospective process associated with our population
dynamics. The retrospective process is obtained by picking up a random individual in
the present population and tracing its phenotypic trajectory backward to a very remote
time when it becomes a stationary process. Its stationary distribution f ∗is called the
ancestral distribution. Its trajectories x are the phenotypic histories, with an associ-
ated trajectory probability density P∗
x. The variational principle (8.133) permits us to
obtain the change of the population growth rate 3 under a change of the division rate
r, the switch cost d, or the switch rate k. Taking the derivative of the evolution operator
L with respect to these quantities and taking into account the properties of κ∗, f ∗, we
obtain
δ3 =
6
x
f ∗
x δrx +
6
x̸=x′
κ∗
xx′f ∗
x′ δdxx′ +
6
x̸=x′
1κ∗
xx′f ∗
x′
kxx′
−f ∗
x′
2
δkxx′.
(8.136)
In this way, the analogy with stochastic thermodynamics leads to ﬂuctuation relations
valid for populations evolving in time-varying environments.
8.10
Further reading
Our discussion of stochastic eﬃciency is mainly based on Verley et al. [172, 175].
Discussions of the ﬁnite time behavior of stochastic eﬃciency can be found in Gingrich
et al. [71] and Polettini et al. [131].
The thermodynamic uncertainty relations were ﬁrst proposed by Barato and Seifert
[9]. Gingrich et al. [69] rigorously proved the original thermodynamic uncertainty
relation using large deviation theory. The ﬁrst part of section 8.2 on uncertainty rela-
tions follows Hasegawa and Van Vu [74]. Pietzonka et al. [127] apply them to study
the eﬃciency of molecular motors. Horowitz and Gingrich [78] point out that the
ﬁnite time uncertainty relation follows from large deviation theory relations applied
to large ensembles. Dechant and Sasa [39] (see also [40, 38]) generalize the uncertainty
relations to multidimensional currents and establish their connection with the Cramér-
Rao inequality. Seifert [150] and Horowitz and Gingrich [79] review general aspects of
uncertainty relations.
The statistics of ﬁrst-passage times was ﬁrst considered by Saito and Dhar [141]
and Garrahan [60]. There are several further theoretical studies, and experiments are

Developments
203
reported by Singh et al. [156]. We follow in particular Gingrich and Horowitz [68].
Murashita et al. [114] discuss fully irreversible processes. This approach leads to an
interesting way of discussing the Gibbs paradox [Murashita and Ueda, 115]. The dis-
cussion of the optimal protocol in section 8.6 follows Sivak and Crooks [157], and
the experiment mentioned in the section is due to Tafoya et al. [164]. An alternative
approach is due to Schmiedl and Seifert [145] and is developed by Aurell et al. [6, 5],
among others. Our discussion on the application of martingales in stochastic thermo-
dynamics is based on Neri et al. [117, 118]. The random time transformation for the
entropy production is introduced in the work by Pigolotti et al. [128].
Leibler and Kussell [102] compare retrospective and chronological sampling in pop-
ulation dynamics. Mustonen and Lässig [116] propose a ﬂuctuation relation involving
ﬁtness in evolving populations. Kobayashi and Sughiyama [88] and Sughiyama et al.
[161] establish and develop the analogy with stochastic thermodynamics, obtaining
several ﬂuctuation relations. García-García et al. [58] further discuss these relations
and their applications. Our exposition follows Nozoe et al. [119].
8.11
Exercises
8.1
A particle is dragged on a ring with N states as in section 4.3. Evaluate its
entropy production rate in the steady state and verify that, for any value of the
driving δ, the current satisﬁes the uncertainty bounds in section 8.2.
8.2
Evaluate the rate function I( j) for the model of enzyme-mediated reaction
introduced in section 4.4, by applying the tilted dynamics and the Gärtner-
Ellis theorem. Compare with the weak linear response bound given in
eq. (8.36).
8.3
A Brownian particle is subject to a constant force f in one dimension. Verify
analytically and numerically that the empirical one-dimensional current satu-
rates the uncertainty bound (8.24). Provide a heuristic explanation of why this
is the case.
8.4
Following the logic of section 8.7, prove that e−sa/kB is a martingale, where sa is
the adiabatic entropy production introduced in section 4.9.
8.5
Use the random time form (8.117) of the entropy production rate to prove the
inﬁmum law (8.105). (Hint: Use the backward Kolmogorov equation (2.106).)

CHAPTER 9
Perspectives
Stochastic thermodynamics is nowadays an established branch of nonequilibrium
statistical physics, and there is a growing interest in extending its application to a
broader range of systems. Prominent examples come from the ﬁeld of active matter,
which seeks to describe, for example, scenarios in which the chemical reservoir is
itself a nonequilibrium system fueled by chemical energy. Other theoretical challenges
arise when applying stochastic thermodynamics to the quantum world. Information-
processing biological systems constitute another interesting venue, also thanks to the
steady improvement of quantitative techniques in experimental biophysics. Before dis-
cussing these future directions, we touch upon more fundamental aspects that are
related to how stochastic thermodynamics ﬁts into the grand problem of understanding
nonequilibrium physical systems.
In short, stochastic thermodynamics aims at relating a mesoscopic physical system,
described in terms of a stochastic process, with the macroscopic laws of thermody-
namics. This goal is sketched in ﬁg. 1.1, at the very beginning of this book. We have
seen throughout this book that this goal is achieved in a relatively simple and ele-
gant way. Compare, for example, the compact expressions of ﬂuctuation theorems with
the intricacies of deriving irreversibility from kinetic theory. A main reason for this
simpliﬁcation is that the mesoscopic dynamics which constitutes the starting point of
stochastic thermodynamics, is already irreversible, so that the fundamental problem of
irreversibility is not solved but rather swept under the rug; see section 1.2. It is proba-
bly fair to conclude that stochastic thermodynamics aims at a simpler goal than kinetic
theory and succeeds in providing simpler answers.
A more concerning and subtle problem is the following. Let us imagine being able to
derive the macroscopic thermodynamic behavior of a nonequilibrium physical system
from its microscopic dynamics. In parallel, we also describe the system via a coarse-
grained stochastic dynamics, and therefore also obtain the macroscopic behavior using
the tools of stochastic thermodynamics. Can we expect the two macroscopic descrip-
tions to be identical? In other words, are the two paths from the microscopic to the
macroscopic world in ﬁg. 1.1 in general equivalent?
Unfortunately, theoretical arguments suggest that this equivalence does not hold in
general [72]. The discrepancy between the two descriptions originates in the deﬁnition
of entropy in statistical mechanics. One deﬁnition is the so-called Boltzmann entropy.
One associates with a microscopic state ξ of a large system the empirical distribution
p(⃗r, ⃗pr) of the positions and momenta of all particles. The set of microstates compatible

Perspectives
205
with the same p(⃗r, ⃗pr) identiﬁes a macrostate M(ξ). We denote by "(M(ξ)) the region
of the phase space spanned by these microstates and by |"(M(ξ))| its volume. The
Boltzmann entropy is proportional to the logarithm of the phase-space volume of this
region:
S(B) = kB ln |"(M(ξ))| .
(9.1)
The Boltzmann entropy is a ﬂuctuating quantity, since it depends on the microstate ξ.
Alternatively, we can describe a macrostate by an ensemble p(ξ), as is customarily done
in equilibrium statistical mechanics. The entropy associated with this ensemble is called
the Gibbs entropy:
S(G) = −kB
!
dξ p(ξ) ln p(ξ).
(9.2)
At equilibrium, these two deﬁnitions are equivalent, in the sense that the average of
S(B) is equal to S(G) (at least for gases) and its ﬂuctuations are small. Out of equilib-
rium, this is not necessarily the case. A classic example is a gas prepared in an atypical
state, for example, compressed into a corner of a container having adiabatic walls, and
then allowed to relax to equilibrium. For such a system, the Boltzmann entropy deﬁned
in eq. (9.1) increases as expected during relaxation. On the contrary, due to the Liou-
ville theorem, the Gibbs entropy deﬁned in eq. (9.2) always remains constant since the
system is isolated. This observation, combined with the fact that eq. (9.1) is deﬁned for
a single macroscopic system whereas eq. (9.2) requires the deﬁnition of an ensemble,
leads us to conclude that the Boltzmann entropy is the proper choice to characterize
irreversibility in isolated thermodynamic systems.
We should remark that this conclusion is not universally accepted. Defenders of
eq. (9.2) claim that both eqs. (9.1) and (9.2) require a coarse graining of phase space,
since it is impossible to measure positions and momenta with inﬁnite precision. In
the presence of coarse graining, the Gibbs entropy becomes a random quantity that
increases with time, on average. However, following this line of thought, one ﬁnds that
the increase with time of the Gibbs entropy depends on the level of coarse graining, at
variance with that of the Boltzmann entropy [52]. It is our contention that the relaxation
to equilibrium of a large isolated system is objective, i.e., independent of the precision
of any conceivable microscopic measurement.
On the other hand, stochastic thermodynamics is ﬁrmly based on ensembles and
consequently on the ensemble deﬁnition of entropy; see section 3.6. Stochastic thermo-
dynamics works because of the presence of a large heat reservoir always at equilibrium,
which makes the system dynamics irreversible. In this case, the ensemble perspective is
justiﬁed by the fact that the system is small and therefore its dynamics is not determin-
istic like the dynamics of macroscopic systems. In short, macroscopic thermodynamics
and stochastic thermodynamics are consistent theories if taken individually. However, it
is not obvious whether one can invoke a “correspondence principle” and recover macro-
scopic nonequilibrium thermodynamics by taking a limit in which a mesoscopic system
becomes large.
Another subtle issue with the program of stochastic thermodynamics concerns
the separation between the mesoscopic system and the heat reservoir surrounding it.
Besides the separation of timescales, an underlying assumption is that the interaction
energy between the system and the reservoir should be negligible compared with the
system energy. If this assumption does not hold, the use of projection techniques, such

206
Chapter 9
as those mentioned in section 4.15, requires more care. Stochastic thermodynamics has
been generalized to these situations [83], although the interpretation of thermodynamic
quantities has generated some controversy [165, 160].
Besides these fundamental aspects, stochastic thermodynamics has the potential to
be applied to a broader range of systems than those studied so far. For example, “tra-
ditional” stochastic thermodynamics assumes the presence of equilibrium reservoirs
in contact with the nonequilibrium system under study. However, many interesting
physical and biological systems are embedded in ﬂuids that are steadily kept out of equi-
librium by the consumption of energy. For example, the cytosol, i.e., the liquid found
inside biological cells, contains several chemical species undergoing chemical reactions.
These reactions are kept out of equilibrium by other chemical reservoirs. Fluid (or solid)
nonequilibrium media collectively fall under the denomination of active matter [109].
The phenomenology of mesoscopic nonequilibrium systems in contact with active
reservoirs is rather rich. For example, work can be extracted from a single active heat
reservoir without necessarily violating the second law of thermodynamics. There have
been interesting attempts to extend stochastic thermodynamics to include active reser-
voirs. Such attempts are still at relatively early stages at the time of writing this book.
Quantum systems represent another important ﬁeld of application. The govern-
ing equations of quantum mechanical systems coupled to a heat reservoir, formulated
either in terms of the Schrödinger equation or in terms of a density matrix, display
symmetries similar to those of classical systems. In particular, the unitary nature of
quantum dynamics, which preserves normalization of the wave function, is mathe-
matically similar to the conservation of probability in classical stochastic dynamics.
Further, interaction with a heat reservoir breaks the time-reversal symmetry in a qual-
itatively similar way in classical and quantum systems. Fundamental results in classical
stochastic thermodynamics, such as ﬂuctuation theorems, are based on these symme-
tries and therefore have been extended to the quantum realm during the early stages
of stochastic thermodynamics [93]. On the other hand, quantum stochastic thermody-
namics presents subtleties that are absent in the classical case. One of them concerns
the nature of interactions with the heat reservoir. There are several diﬀerent techniques
to introduce these interactions, usually based on describing the degrees of freedom of
the heat reservoir explicitly and then averaging them out to obtain an eﬀective equation
for the system alone. These diﬀerent techniques are not equivalent, and each of them
presents advantages and disadvantages. Another issue concerns with the deﬁnition of
“work” in quantum mechanics. Operationally, measuring work requires measuring the
energy of the system at two diﬀerent times. However, in quantum mechanics, mea-
surements can fundamentally alter the state of the system, and it has therefore been
questioned whether work deﬁned in this way is a legitimate observable. Nowadays
quantum stochastic thermodynamics is a rather developed ﬁeld, as reviewed in [49, 41].
Finally, stochastic thermodynamics provides a natural framework to study the per-
formance of molecular machines operating out of equilibrium, such as molecular
motors or information-processing enzymes, and indeed there exists a rich literature
pursuing this direction. The application of stochastic thermodynamics in this con-
text has been mostly carried on by the analysis of extremely simpliﬁed models, which
helped to clarify the conceptual issues involved. At the same time, much progress has
been made in quantitative experimental techniques in biophysics. This progress calls for
the development and analysis of more realistic models that could be used to interpret
experimental results and predict new, unexpected features of biological systems.

Appendixes
In these appendixes, we collect some introductory material and technical calculations
whose exposition would have made heavy reading in the main chapters.
A.1
Convex functions and the Jensen inequality
Many useful inequalities are a consequence of a general relation called the Jensen
inequality, which holds for convex functions. There is sometimes confusion on the def-
initions of concave and convex. The most used convention in mathematics is to deﬁne
a ∪-shaped function as convex and a ∩-shaped function as concave. A way to mem-
orize the deﬁnition is to think that a ∩-shape looks like a cave, hence it is concave.
More formally, a real-valued function f (x) is convex over an interval (a, b) if, for any
x0, x1 ∈(a, b) and 0 ≤α ≤1, one has
f
!
(1 −α)x0 + αx1
"
≤(1 −α)f (x0) + αf (x1).
(A.1)
See the scheme in ﬁg. A.1. A function f is concave if (−f ) is convex. If the inequality is
strict for any x0 ̸= x1 and 0 < α < 1, f is said to be strictly convex.
If a function f (x) has a second derivative that is nonnegative (positive) in (a, b), then
f is convex (strictly convex). Indeed, given x0 and x, by the Taylor expansion and by the
mean value theorem, we know that there is a point u between x0 and x such that
f (x) = f (x0) + f ′(x0) (x −x0) + 1
2f ′′(u) (x −x0)2,
(A.2)
where the last term is nonnegative. Let us now consider xα = (1 −α)x0 + αx1. We
obtain
f (x0) ≥f (xα) + f ′(xα) (x0 −xα) = f (xα) −f ′(xα) α (x1 −x0)
(A.3)
and
f (x1) ≥f (xα) + f ′(xα) (x1 −xα) = f (xα) + f ′(xα) (1 −α) (x1 −x0).
(A.4)
Multiplying (A.3) by (1 −α) and (A.4) by α and summing, we obtain (A.1). The strict
inequality is derived along the same lines when f ′′(x) > 0, ∀x ∈(x0, x1).

208
Appendixes
x0
xα
x1
x
f (x0)
f (xα)
fα
f (x1)
f (x)
Figure A.1. Illustration of convexity. Given the point xα = αx1 + (1 −α)x0, with 0 ≤α ≤1,
we have f (xα) ≤fα = (1 −α)f (x0) + αf (x1), ∀α.
We also have the converse result: if the convex function f (x) is twice derivable in the
interval [x0, x1], then f ′′(x) ≥0 in the interval. Indeed, we have by deﬁnition, for any x
for which f ′′(x) exists,
f ′′(x) = lim
h→0
f (x + h) + f (x −h) −2f (x)
h2
.
(A.5)
On the other hand, by convexity, we have
1
2
!
f (x + h) + f (x −h)
"
≥f (x).
(A.6)
Thus the quantity on the right-hand side of the relation is nonnegative for all h ̸= 0. In
the limit, we obtain f ′′(x) ≥0. The strict inequality does not necessarily hold, even if
f (x) is strictly convex. An example is the function f (x) = x4.
We now take a convex function f (x), which is twice diﬀerentiable in (a, b), and a
point x0 in the interior of the interval (a, b). Then f (x) ≥f (x0) + f ′(x0)(x −x0) for x ∈
(a, b). In other words, the graph of the convex function f (x) lies above the tangent to it
in x0. The inequality is strict if f (x) is strictly convex. Indeed, by the Taylor expansion
and the mean value theorem, we have, for some u ∈(x0, x),
f (x) = f (x0) + f ′(x0)(x −x0) + 1
2f ′′(u)(x −x0)2,
(A.7)
where the last term is nonnegative. Thus we have proved the weak inequality. To prove
the strict inequality, we assume that f (x) is strictly convex and that f (x) = f (x0) +
f ′(x0)(x −x0) for some x ̸= x0. Convexity implies that, for any u ∈(x0, x),

Appendixes
209
f (u) ≤f (x)u −x0
x −x0
+ f (x0) x −u
x −x0
= f ′(x0)(u −x0) + f (x0).
(A.8)
On the other hand, the result in eq. (A.7) implies
f (u) ≥f ′(x0)(u −x0) + f (x0)
(A.9)
and therefore
f (u) = f (x)u −x0
x −x0
+ f (x0) x −u
x −x0
,
(A.10)
which violates the strict convexity.
The Jensen inequality states that if f is a convex function and x is a random variable,
then
#
f
$
≥f (⟨x⟩),
(A.11)
where ⟨x⟩is the average of x. If f is strictly convex, the equality in (A.11) implies that x
is a constant.
To prove this result, we deﬁne g(x) = f (⟨x⟩) + f ′(⟨x⟩)(x −⟨x⟩). Since f (x) is convex,
we have f (x) ≥g(x), ∀x, with equality for x = ⟨x⟩. Moreover, if f (x) is strictly convex,
we have f (x) > g(x), ∀x ̸= ⟨x⟩. Since g(x) is linear,
#
g(x)
$
= g(⟨x⟩). Thus we have
#
f
$
≥
#
g
$
= g(⟨x⟩) = f (⟨x⟩).
(A.12)
The inequality is strict if f (x) is strictly convex, unless x assumes only one value.
The Jensen inequality implies some useful corollaries. We ofen use it in cases in
which f (x) is an exponential function:
#
e−x$
≥e−⟨x⟩,
(A.13)
for any real-valued random variable x. Taking the logarithm, this relation implies
⟨x⟩≥−ln
#
e−x$
.
(A.14)
We now consider two vectors (px) and (qx) with nonnegative entries. The function
f (x) = x ln x (for x > 0) is convex. We deﬁne
S =
%
x
px ln px
qx
(A.15)
and the probability distribution
ux = qx
q ,
(A.16)
where q = &
x′ qx′. We then have
S = q
%
x
ux
'px
qx
(
ln px
qx
.
(A.17)

210
Appendixes
By the Jensen inequality, we obtain
S ≥qf
)%
x
ux
px
qx
*
=
)%
x
px
*
ln
&
x′ px′
&
x′ qx′ = p ln p
q,
(A.18)
where p = &
x px. This relation is known as the logsum inequality. One of its imme-
diate consequences holds when both px and qx are probability distributions, satisfying
&
x px = 1 and &
x qx = 1. We then have
DKL(p∥q) =
%
x
px ln px
qx
≥0.
(A.19)
The quantity on the lef-hand side is known as the Kullback-Leibler divergence of the
probability distributions px and qx. It is a measure of how the distribution px is diﬀerent
from qx.
We also mention a useful property of the Kullback-Leibler divergence. Consider a
time-dependent solution px(t) of a master equation with a unique stationary solution
pst
x , positive for all x. Then the Kullback-Leibler divergence DKL(p(t)∥pst) decreases
monotonically:
d
dtDKL(p(t)∥pst) ≤0.
(A.20)
This is a consequence of a more general result,
d
dt"(p) = d
dt
%
x
pst
x f
'px(t)
pstx
(
≤0,
(A.21)
where f (x) is an arbitrary convex function. We have indeed
d
dt"(p) =
%
xx′
+
kxx′px′ −kx′xpx
,
f ′
' px
pstx
(
=
%
xx′
kxx′pst
x′
+
ux′f ′(ux) −ux′f ′(ux′)
,
,
(A.22)
where we introduce the shorthand ux = px/pst
x . We now have, for any arbitrary vector
w = (wx),
%
xx′
kxx′pst
x (wx −wx′) = 0.
(A.23)
Choosing wx = f (ux) −uxf ′(ux) and summing this relation to (A.22), we obtain
d
dt"(p) =
%
xx′
kxx′pst
x′
+
(ux′ −ux)f ′(ux) + f (ux) −f (ux′)
,
.
(A.24)
The quantity in brackets is nonpositive by (A.9), and the result (A.21) follows. Choosing
f (x) = x ln x, we obtain the result for the Kullback-Leibler divergence.

Appendixes
211
A.2
Legendre transformation
In this appendix, we review the Legendre transformation and its properties. We con-
sider a function f (x). For simplicity, we assume that it is twice diﬀerentiable and that its
second derivative is positive. It is therefore possible to solve for x in the relation
df (x)
dx
= q.
(A.25)
We would like to use the derivative q instead of x as an independent variable. If we solve
for x in eq. (A.25) and substitute it in f (x), we indeed obtain a function of q. However,
we would obtain the same function if, instead of starting from f (x), we started from
a function f1(x) = f (x + C), where C is an arbitrary constant. Therefore, this proce-
dure discards important information on f . For example, if f depends on other variables
beyond x, C becomes an arbitrary function of the other variables. This ambiguity is
removed by the Legendre transformation, which allows us to deﬁne a function g(q)
that is equivalent to f (x), in the sense that its knowledge allows us to recover precisely
the original f (x).
With our hypotheses, the function f (x) is convex. We can represent it by a curve in
the (x, f ) plane. The same curve is also identiﬁed as the envelope of its tangents. Given
a tangent of slope q in the point x, its intercept with the y-axis is given by
φ(q) = f (x) −q x.
(A.26)
Knowledge of φ(q) allows us to recover f (x). Thus φ(q) is a good candidate for our
task. It is more convenient to use g(q) = −φ(q), which can be obtained by a variational
principle. Indeed, since f (x) is convex, its graph lies always above any tangent to it. As
a consequence, if x0 is such that f ′(x0) = q, we have
f (x) ≥f (x0) + q (x −x0),
∀x.
(A.27)
Thus g(q) satisﬁes
g(q) = q x0 −f (x0) ≥q x −f (x),
∀x.
(A.28)
Therefore, g(q) is given by
g(q) = max
x
!
q x −f (x)
"
,
(A.29)
and the abscissa x(q) of the maximum satisﬁes eq. (A.25). Equation (A.29) deﬁnes the
Legendre transform g(q) of f (x). Figure A.2 shows a simple geometric construction
representing eq. (A.29). We distinguish between the “Legendre transformation,” which
is the transformation applied to a function f (x), and the “Legendre transform,” which
is the outcome of the transformation, i.e., the function g(q).
Under our hypotheses, we have
dg(q)
dq
= x(q).
(A.30)

212
Appendixes
0
x(q)
x
0
f (x(q))
q x(q)
y
f (x)
g(q)
slope q
Figure A.2. Legendre transform of the function f (x). To obtain the Legendre transform
g(q), draw a line through the origin with slope q, and take the point x(q) at which the
directed vertical distance from the graph of f to this line is maximized. Then g(q) is given
by the maximal value of this distance. If the tangent to the graph in (x(q), f (x(q))) exists,
it has slope q.
Moreover, the second derivative of g with respect to q is positive:
d2g
dq2 = dx
dq =
'dq
dx
(−1
=
1
f ′′(x(q)) > 0.
(A.31)
We can thus apply the same transformation to g(q). By eq. (A.29), this procedure
yields f (x) again. Therefore, under our assumptions, the Legendre transformation is
an involution.
The variational principle can be generalized to functions f (x) that are nonconvex or
not everywhere diﬀerentiable, by taking the supremum instead of the maximum:
g(q) = sup
x
!
q x −f (x)
"
.
(A.32)
This equation deﬁnes a transformation more general than the Legendre one, called
the Legendre-Fenchel transformation. When f (x) is convex and twice diﬀerentiable,
we recover the Legendre transformation. However, the Legendre-Fenchel transform is
deﬁned in more general situations. In particular, if the function f (x) is not convex, some
tangents have more than one contact point with the graph. In these cases, eq. (A.25)
has more than one solution, and, by eq. (A.30), there is a whole range of tangents to the
g(q) graphs for the corresponding values of q. Thus g(q) exhibits angular points. When
this happens, the Legendre-Fenchel transformation is no longer an involution: apply-
ing it twice, we recover the convex envelope of the graph of f (x) rather than the graph
itself.

Appendixes
213
A.3
Probabilities and probability distributions
In this appendix, we review basic properties of probability and probability distribu-
tions. Given a random variable x assuming discrete values, its probability distribution
px represents the probability of observing the outcome x. For continuous variables, we
denote with p(x) the probability density, such that p(x) dx is the probability that the
random variable x assumes a value between x and x + dx.
This deﬁnition extends to multiple random variables. Given two discrete variables
x and y, we deﬁne their joint probability distribution px,y as the probability that the
ﬁrst one assumes the value x and the second one assumes a value y. Given the joint
probability distribution px,y, the marginal probability distribution, or marginal, of
the ﬁrst variable is deﬁned by
px =
%
y
px,y ,
(A.33)
where the sum runs over all possible values of y. The conditional probability of x and
y (or the probability of x, given y) is given by the Bayes formula
px|y = px,y
py
.
(A.34)
An important consequence of eqs. (A.33) and (A.34) is the law of total probability:
px =
%
y
px|ypy.
(A.35)
The law of total probability allows us to “decompose” the probability of an event into a
weighted sum of conditioned probabilities.
Here are some common examples of discrete distributions:
The binomial distribution. We consider N independent, identically distributed
events with two possible outcomes: success, with probability r, and failure, with
probability 1 −r. The distribution of the total number of successes is the binomial
distribution:
px =
'N
x
(
rx(1 −r)N−x,
x ∈{0, 1, . . . , N},
(A.36)
where
'N
x
(
=
N!
(N −x)! x!
(A.37)
is the binomial coeﬃcient.
The Poisson distribution. The Poisson distribution is the limit of the binomial distri-
bution for N →∞, where θ = Nr is kept constant. It is given by
px = θx
x! e−θ,
x ∈{0, 1, 2, . . .}.
(A.38)
We now consider the probability densities of continuous variables. The joint prob-
ability density p(x, y) of two continuous random variables x and y is such that

214
Appendixes
p(x, y) dx dy is the probability that the value of the ﬁrst variable falls in the range be-
tween x and x + dx, and at the same time the value of the second variable falls between
y and y + dy. The conditional probability density p(x|y) is given by the Bayes formula
p(x|y) = p(x, y)
p(y) ,
(A.39)
where p(y) is the marginal probability density:
p(y) =
-
dx p(x, y).
(A.40)
Here are some common examples of continuous probability distributions:
The uniform distribution. Given an interval [a, b] of the x-axis, the uniform distribu-
tion expression reads
p(x) =
.
1/(b −a),
if a < x < b;
0,
otherwise.
(A.41)
The Gaussian distribution. The Gaussian distribution is deﬁned on the whole real
axis by
p(x) =
1
√
2πσ 2 exp
/
−(x −x0)2
2σ 2
0
.
(A.42)
The exponential distribution. The exponential distribution is deﬁned by
p(x) =
.
x−1
0 e−x/x0,
if x > 0;
0,
otherwise.
(A.43)
The delta distribution. The delta distribution describes continuous random variables
that are bound to assume only one value x0: p(x) = δ(x −x0). It can be formally
obtained as the limit of the Gaussian distribution for σ →0. The delta function sat-
isﬁes
1 b
a dx δ(x −x0) = 1 if a < x0 < b and 0 otherwise. Moreover, the delta function
possesses the following properties:
•
1 ∞
−∞dx δ(x −x0) f (x) = f (x0), where f (x) is an arbitrary function;
• δ(−x) = δ(x);
• δ(ax) = |a|−1 δ(x).
A.4
Generating functions and
cumulant generating functions
The generating function of a random variable with probability density p(x) is
deﬁned by
φ(q) =
#
eqx$
=
- ∞
−∞
dx eqxp(x).
(A.44)
For discrete probability distributions px, eq. (A.44) still holds with the integral replaced
by a sum. Mathematically, the generating function can be seen as the Laplace transform

Appendixes
215
of the probability distribution. The integral in eq. (A.44) converges when −∞≤q < a,
where the value of a depends on the behavior of the distribution as x →+∞. To obtain
the probability distribution from its generating function, one can invert the Laplace
transform by the Bromwich integral
p(x) =
- γ +i∞
γ −i∞
dq
2πi e−qxφ(q).
(A.45)
In eq. (A.45), integration is performed on a path parallel to the imaginary axis. The
location γ of the path has to be negative enough that all the singularities of the inte-
grand lie on the right of the integration path. The generating function of a Gaussian
distribution has the Gaussian form, i.e., it is the exponential of a quadratic form in q:
-
dx
√
2π σ 2 eqx exp
/
−(x −x0)2
2σ 2
0
= exp
'
qx0 + q2
2 σ 2
(
.
(A.46)
The generating function gets its name from the property that its derivatives “generate”
moments of the distribution:
' d
dq
(n
φ(q)
2222
q=0
=
#
xn eqx$22
q=0 =
#
xn$
,
n ∈{1, 2, . . . }.
(A.47)
Generating functions are also useful to compute sums of random variables. Let us con-
sider two independent random variables x and y with probability densities p1(x) and
p2(y), respectively. The probability density of their sum z = x + y is given by
p(z) =
- ∞
−∞
dx
- ∞
−∞
dy p1(x) p2(y) δ(z −x −y) =
- ∞
−∞
dx p1(x) p2(z −x).
(A.48)
Denoting by φ(x)(q), φ(y)(q), and φ(z)(q) the generating functions of the variables x, y,
and z, respectively, one has
φ(z)(q) =
- ∞
−∞
dz eqz p(z) =
- ∞
−∞
dx p1(x) eqx
- ∞
−∞
dz eq(z−x) p2(z −x)
= φ(x)(q) φ(y)(q),
(A.49)
where in the second equality we use eq. (A.48). Therefore, the generating function of
the sum is the product of the generating functions. This result extends to sums of more
than two random variables. For example, consider the empirical mean
fN = 1
N
N
%
k=1
xk,
(A.50)
where the xk are independent, identically distributed random variables with distribu-
tion p(x). An important corollary of eq. (A.49) is that the generating function of the
empirical mean is given by

216
Appendixes
Table A.1. The ﬁrst four cumulants
Order
Moment
Cumulant
1
⟨x⟩
⟨⟨x⟩⟩= ⟨x⟩
2
#
x2$
##
x2$$
=
#
x2$
−⟨x⟩2
3
#
x3$
##
x3$$
=
#
x3$
−3
#
x2$ ⟨x⟩+ 2 ⟨x⟩3
4
#
x4$
##
x4$$
=
#
x4$
−4
#
x3$ ⟨x⟩−3
#
x2$2 + 12
#
x2$ ⟨x⟩2 −6 ⟨x⟩4
φ( fN)(q) =
3
φ(x) 4 q
N
56N
.
(A.51)
Linear combinations of Gaussian random variables are also Gaussian, since the product
of their Gaussian generating functions is a Gaussian.
The cumulant generating function is the logarithm of the generating function:
"(q) = ln
#
eqx$
= ln φ(q).
(A.52)
The cumulants ⟨⟨xn⟩⟩are useful combinations of the moments of a distribution. They
are related to the cumulant generating function by
##
xn$$
=
' d
dq
(n
"(q)
2222
q=0
.
(A.53)
The ﬁrst cumulant is equal to the ﬁrst moment, i.e., the average. The second cumulant is
the variance,
##
x2$$
=
#
x2$
−⟨x⟩2 = σ 2
x . Roughly speaking, the expressions of each higher-
order cumulant contain the moment of the same order minus its “best approximation”
in terms of lower-order moments. A list of the expressions of the ﬁrst four cumulants
in terms of moments is presented in table A.1.
In table A.2, we report expressions of the generating functions and cumulant gen-
erating functions for the common distributions we introduced in appendix A.3. For
a Gaussian distribution, the generating function has the same functional form as the
distribution itself, and thus the cumulant generating function is a second-order polyno-
mial. This latter fact, combined with the deﬁnition of the cumulants, eq. (A.53), implies
that all cumulants of order three and higher vanish for a Gaussian distribution. This is a
very peculiar property: Marcinkiewicz’s theorem states that the cumulant generating
function of a probability distribution, if it is a polynomial, cannot be of degree greater
than two. This means that nearly all distributions have an inﬁnite number of nonvanish-
ing cumulants—the only exceptions being the Gaussian, with the ﬁrst two nonvanishing
cumulants, and the singular delta distribution, with only one nonvanishing cumulant.
This result might seem a mathematical curiosity, but it lies at the core of the central
limit theorem. Let us return to eq. (A.51) and evaluate the cumulant generating
function of the empirical mean
"( fN)(q) = N"(x) 4 q
N
5
.
(A.54)

Appendixes
217
Table A.2. Generating functions and cumulant generating functions for
common distributions
Distribution
p(x)
φ(q)
"(q)
Exponential
x−1
0 e−x/x0
1/(1 −qx0)
−ln
!
1 −qx0
"
Gaussian
e−(x−x0)2/(2σ 2)/
√
2πσ 2
eqx0+σ 2q2/2
qx0 + σ 2q2/2
Delta
δ(x −x0)
eqx0
qx0
Binomial
!N
x
"
rx(1 −r)N−x
!
1 −r(1 −eq)
"N
N ln
!
1 −r(1 −eq)
"
Poisson
(θx/x!) e−µ
exp
!
θ (eq −1)
"
θ
!
eq −1
"
By taking derivatives with respect to q, we can use this expression to relate the cumulants
of x to those of fN:
##
f n
N
$$
=
1
Nn−1
##
xn$$
.
(A.55)
According to eq. (A.55), the average of an empirical mean is equal to that of the origi-
nal variables, its variance is N times smaller, and its higher moments are suppressed by
higher powers of 1/N compared to those of the original variable. This means that, as N
increases, the distribution of the empirical mean is better approximated by a distribu-
tion characterized by only the ﬁrst two nonvanishing cumulants, which is a Gaussian
as we have seen.
The average ⟨x⟩and the variance σ 2 =
##
x2$$
of a Poisson distribution are both equal
to the parameter θ. This result can be obtained by expanding the cumulant generating
function "(q).
A.5
Ergodic properties of Markov processes
In this appendix, we discuss the ergodic properties of master equations with a ﬁnite
number of states N, i.e., the statistical behavior of their solutions in the long run. We
prove in particular that, if the jump rates are time-independent and correspond to a
connected jump network, the master equation has a unique stationary distribution pst =
(pst
x ), which is reached as t →∞independent of the initial distribution. The proof is
inspired by Meyer [112, ch. 8].
As usual, we call kx′x the jump rates from x to x′ ̸= x. We also deﬁne for convenience
kxx = −kout
x , where kout
x
= &
x′ kx′x is the escape rate from state x. With this convention,
the generator is L = (kxx′). The master equation reads
dpx
dt =
%
x′
kxx′px′ =
!
L p
"
x .
(A.56)
Given )t > 0, the propagator px;t+)t|x′;t is given by
Pxx′()t) = px;t+)t|x′;t = (exp ()t L))xx′.
(A.57)

218
Appendixes
Since the jump network is connected, there is a path with nonvanishing jump proba-
bilities that connect any state x′ with any diﬀerent state x. This implies that, for )t > 0,
all the entries in the matrix Pxx′()t) are positive. We choose one such value of )t and
denote by P = (Pxx′) the corresponding value of the propagator. The matrix P has all
positive entries and satisﬁes the normalization condition
%
x′
Px′x = 1,
∀x.
(A.58)
The matrix P deﬁnes a Markov chain, i.e., a Markov process in discrete time. If this
Markov chain has a stationary distribution pst, then pst is an eigenvector of P with
eigenvalue λ = 1. Since L commutes with P, pst is also an eigenvector of L with eigen-
value (ln λ)/)t = 0 and is therefore a stationary distribution for the Markov process in
continuous time. Thus we only need to obtain the result for the Markov chain.
The matrix P has an eigenvalue equal to 1 since, by eq. (A.58), the vector I such
that Ix = 1, ∀x is a lef eigenvector belonging to this eigenvalue. We denote by u the
corresponding right eigenvector. Since P is real, u can be chosen to be real. We now show
that we can also choose it to have all positive entries. Let us deﬁne δ = minxx′ Pxx′ >
0 and the norm ∥u∥= maxx |ux|. Given any vector v, we denote by (v)+ its positive
part and by −(v)−its negative part. We then deﬁne α = min{
77(u)+77 ,
77(u)−77}. Then
!
P(u)+"
x ≥δα, ∀x and
!
P(u)−"
x ≥δα, ∀x. Therefore,
∥Pu∥=
77P(u)+ −P(u)−77 ≤
77P(u)+ −δαI
77 +
77P(u)−−δαI
77
≤
77(u)+77 +
77(u)−77 −2δα = ∥u∥−2δα.
(A.59)
Since Pu = u and δ > 0, this implies that α = 0, i.e., that u can be chosen to be either all
positive or all negative. We therefore set it to be all positive. The stationary distribution
is therefore equal to pst
x = ux/ &
x′ ux′.
We now prove that the stationary distribution is unique. We suppose that this is
not the case and that there are at least two stationary distributions, p and p′. Then
w = p −p′ is also an eigenvector of P belonging to the eigenvalue 1. On the one hand,
we should have wx ≥0, ∀x by the argument above, and on the other, we should have
&
x wx = &
x px −&
x p′
x = 0. Thus w = 0, i.e., the two distributions p and p′ must be
equal. Therefore, the eigenvalue 1 of P is nondegenerate. We now consider an arbitrary
distribution p and the stationary one pst. Since Pxx′ ≥δ, ∀x, x′, we have
77Pp
77 > δ
77p
77
for every positive p. We then have
77pst −Pp
77 =
77P(pst −p)
77 =
77P(pst −p)+ −P(pst −p)−77
≤
77P(pst −p)+ −δ I
77(pst −p)+7777
+
77P(pst −p)−−δ I
77(pst −p)−7777
≤(1 −δ)
77pst −p
77 .
(A.60)
This implies that the other eigenvalues of P satisfy the inequality
|λ| ≤1 −δ < 1.
(A.61)

Appendixes
219
Thus the iterates Pkp converge exponentially to pst for any initial probability distribu-
tion p. Equation (A.61) also implies that the nonvanishing eigenvalues λ of L satisfy the
inequality Reλ < −ε < 0 for some ε > 0. Therefore, the exponential convergence also
holds for the Markov process in continuous time.
We extend these results to positive generators that do not conserve the normaliza-
tion by exploiting Brouwer’s ﬁxed point theorem [26]. We deﬁne the set , of normalized
vectors with nonnegative entries: u ∈, iﬀux ≥0, ∀x and &
x ux = 1. Then , is a com-
pact and convex subset of the N-dimensional Euclidean space. Given the matrix P with
positive entries, we deﬁne the continuous mapping p 0→T(p) by
T(p) =
%
x′
Pxx′px′
8 %
xx′
Pxx′px′.
(A.62)
According to Brouwer’s theorem, a continuous mapping from a compact and convex
set of a Euclidean space to itself has a ﬁxed point, i.e., there is a vector p∗such that
T(p∗) = p∗. Let ρ = &
x(Pp∗)x. Then p∗is an eigenvector of P with nonnegative (actu-
ally positive) entries belonging to the positive eigenvalue ρ. The other properties are
obtained by adapting the reasoning leading to eqs. (A.59) and (A.60).
A.6
Gillespie algorithm
When the exact solution of a master equation is not available, one may wish to
numerically simulate the corresponding stochastic process. An exact method to gener-
ate trajectories associated with a master equation was introduced by Doob in the 1940s
and later developed and popularized by Daniel T. Gillespie in the 1970s [64, 65]. It
is therefore known as the Gillespie algorithm. The Gillespie algorithm is nowadays
widely used and has been generalized in several ways [67].
We consider a master equation
dpx
dt =
%
x′ (̸=x)
kxx′px′ −kout
x px,
(A.63)
where as usual
kout
x
=
%
x′ (̸=x)
kx′x.
(A.64)
We focus on the case in which the rates kxx′ are constant in time. Given the rates and the
initial distribution px0(t0), we generate a trajectory x of the system in the time interval
[t0, tf] in the following way:
1. Choose the initial state x0 at random according to the probability distribution
px0(t0). Set the state x of the system to x = x0 and the time t to t = t0. Set x =
((x0, t0)).
2. Draw the waiting time )t to the next jump from an exponential distribution
with average 1/kout
x . In practice, extract u with uniform probability between 0
and 1, and set )t = −ln u/kout
x . Add )t to the time variable t.
3. Draw the new state x′ of the system among the states diﬀerent from x, with
probability given by kx′x/kout
x . Set the new state of the system to x′.

220
Appendixes
4. Append (x, t) to x. Repeat from step 2 until the time t + )t of the next jump,
obtained in step 2, exceeds the wished ﬁnal time tf.
This procedure is known as the direct method. This algorithm is exact, in the sense
that it produces trajectories with the correct statistical weight in continuous time with-
out a time discretization. However, it suﬀers from the drawback that, if the number of
possible transitions from a given state x is large, the escape rate kout
x
can also be large,
and therefore the expected value of )t will be in general small, leading to a very slow
evolution. Gillespie [64] also introduced an alternative method, called the ﬁrst-reaction
method. It is also exact, but it is less eﬃcient than the direct method, because it requires
to update, in step 2, the waiting times )tx′ for all possible jumps x −→x′ and then to
keep the smallest one and discard all the others. A generalization of this idea by Gibson
and Bruck [63], known as the next-reaction method, exploits a clever way of storing
waiting times to facilitate identifying the next-occurring transition and the updating
of the waiting-time data. Due to the additional computational overhead, this method
becomes advantageous only for systems with a large number of possible transitions,
like reaction networks with many species and many reactions. For these systems, a very
eﬃcient (but approximate) method, the tau-leaping method, has been introduced by
Gillespie [66]. The C++ implementation of the tau-leaping and next-reaction meth-
ods is discussed in Press et al. [132, § 17.7.1–2]. The next-reaction method has been
generalized to tackle processes with time-dependent jump rates [1].
A.7
Derivation of the Fokker-Planck equation
The Fokker-Planck equation governs the evolution of the probability density p(x; t)
of the position x of a Brownian particle in a general case, where the particle is subject
to applied forces and/or the embedding ﬂuid is not uniform. At variance with the diﬀu-
sion equation, in this case the distribution of the displacement )x experienced by the
particle during a time interval of duration )t can depend on x and is not necessarily
even. We consider the temporal evolution of the average of an arbitrary function f (x):
#
f
$
t =
-
dx f (x) p(x; t).
(A.65)
On the one hand, we have
d
#
f
$
t
dt
=
-
dx f (x) ∂
∂tp(x; t).
(A.66)
On the other hand, the Chapman-Kolmogorov equation (2.64) implies
#
f
$
t+)t =
-
dx′
-
dx f (x′) p(x′; t + )t|x; t) p(x; t)
=
-
d)x
-
dx f (x + )x) p(x + )x; t + dt|x; t) p(x, t)
≈
-
d)x
-
dx
/
f (x) + )x ∂
∂xf (x) + )x2
2
∂2
∂x2 f (x)
0
× p(x + )x; t + dt|x; t) p(x; t)

Appendixes
221
=
-
dx
/
f (x) + ⟨)x⟩x
∂
∂xf (x) + 1
2
#
)x2$
x
∂2
∂x2 f (x)
0
p(x; t′),
(A.67)
where we deﬁne
⟨. . .⟩x =
-
d)x . . . p(x + )x; t + )t|x; t).
(A.68)
We now introduce the drif v and the diﬀusion coeﬃcient D, respectively, by
v(x, t) = lim
)t→0
⟨)x⟩x,t
)t
;
(A.69)
D(x, t) = lim
)t→0
#
)x2$
x,t
2 )t .
(A.70)
The averages are taken with the condition that the position of the particle is equal to x
at time t. We integrate by parts the last expression in (A.67), obtaining
lim
)t→0
#
f
$
t+)t −
#
f
$
t
)t
=
-
dx f (x)
9
−∂
∂x
+
v(x, t) p(x; t)
,
+ ∂2
∂x2
+
D(x, t)p(x; t)
,:
.
(A.71)
Since f (x) is arbitrary, by comparison with (A.66), we see that the term in braces must
be equal to ∂p(x; t)/∂t. We obtain therefore the Fokker-Planck equation for p(x; t):
∂
∂tp(x; t) = −∂
∂x
+
v(x, t)p(x; t)
,
+ ∂2
∂x2
+
D(x, t)p(x; t)
,
.
(A.72)
To obtain the Kolmogorov backward equation, we also start from the Chapman-
Kolmogorov equation (2.64):
p(x; t|x0, t0 −)t0) =
-
dx′ p(x; t|x′, t0) p(x′; t0|x0, t0 −)t0)
=
-
d)x0 p(x; t|x0 + )x0, t0) p(x0 + )x0; t0|x0, t0 −)t0)
≈
-
d)x0
/
p(x; t|x0, t0) + )x0
∂
∂x0
p + 1
2)x2
0
∂2
∂x2
0
p
0
× p(x0 + )x0; t0|x0, t0 −)t0)
(A.73)
= p(x; t|x0, t0) + ⟨)x0⟩x0,t0−)t0
∂
∂x0
p + 1
2
#
)x2
0
$
x0,t0−)t0
∂2
∂x2
0
p
= p(x; t|x0, t0) + v(x0, t0 −)t0) )t0
∂
∂x0
p + D(x0, t0 −)t0) )t0
∂2
∂x2
0
p.
In the limit )t0 →0, we recover eq. (2.106).

222
Appendixes
A.8
Ito formula and Stratonovich-Ito mapping
In this appendix, we sketch the derivation of eq. (2.127), which maps a Langevin
equation interpreted in the Ito convention to the corresponding one in the Stratonovich
convention, and backward, as well as the corresponding Fokker-Planck equation. We
also sketch the proof of the Ito formula, eq. (2.128). Since the main diﬃculty lies in
handling the x-dependence of the noise coeﬃcient, for the sake of simplicity, we limit
ourselves to Langevin equations without drif.
We ﬁrst show that the rule for change of variables in the Stratonovich interpretation
is the same as in ordinary calculus. We consider a continuous variable x(t) that satisﬁes
the Langevin equation
dx
dt = σ(x) ξ(t),
(A.74)
in the Stratonovich interpretation. The solution of eq. (A.74) is given by
x(t) = x(t0) +
- t
t0
dW(t′) ◦σ(x(t′)),
(A.75)
which in discretized form reads
xi+1 = xi + σ
'xi+1 + xi
2
(
(Wi+1 −Wi),
(A.76)
where xi = x(ti), Wi = W(ti), etc. We wish to evaluate the Langevin equation satisﬁed by
f (x(t)), where f (x) is a given function. To do this, we expand f (x) around the midpoint
in each time interval. We now have
f (x + a) = f (x −a) + 2a f ′(x) + 1
3a3 f ′′′(x) + · · · ,
(A.77)
where the third and subsequent terms in the expansion are higher than second order in
a and therefore negligible. We thus have
f (xi+1) = f (xi) + f ′
'xi+1 + xi
2
(
(xi+1 −xi)
= f (xi) + f ′
'xi+1 + xi
2
(
σ
'xi+1 + xi
2
(
(Wi+1 −Wi).
(A.78)
Therefore, f (x(t)) satisﬁes the Langevin equation in the Stratonovich sense,
df
dt = f ′ (x) σ(x) ξ,
(A.79)
which corresponds to the ordinary calculus rule. In the general case with nonvanishing
drif and time-dependent coeﬃcients, the equation reads
df
dt = f ′ (x) [v(x, t) + σ(x, t) ξ] .
(A.80)

Appendixes
223
We now turn to the Ito formula, eq. (2.128). We assume that x(t) satisﬁes eq. (A.74) in
the Ito interpretation, and consider the same f (x). We then have
df (x(t + dt)) = f (x + dt) −f (x(t)) = f ′(x(t)) dx + 1
2f ′′(x(t)) dx2 + · · ·
≈f ′(x(t)) σ(x(t)) dW + 1
2f ′′(x(t)) σ 2(x(t)) dW2.
(A.81)
Now dW2 = dt, up to higher-order terms. We obtain therefore the Ito formula
df = f ′(x) dx + 1
2f ′′(x) σ 2(x) dt.
(A.82)
Also this result can be extended to the general case with drif and time-dependent
coeﬃcients.
We now assume that x(t) is a solution of the Langevin equation eq. (A.74) in the
Stratonovich interpretation. To obtain the Langevin equation obeyed by x(t) in the
Ito interpretation, we expand σ(x), evaluated at midpoint, around its initial point,
obtaining
xi+1 = xi + σ
'xi+1 + xi
2
(
(Wi+1 −Wi)
= xi + σ(xi) (Wi+1 −Wi) + 1
2σ ′(xi) (xi+1 −xi) (Wi+1 −Wi)
≈xi + σ(xi) (Wi+1 −Wi) + 1
2σ ′(x) σ(xi) (Wi+1 −Wi)2.
(A.83)
Using again dW2 = dt, we obtain the Langevin equation
dx
dt = σ(x) 1
2σ ′(x) + σ(x) ξ.
(A.84)
Considering the general Langevin equation with drif, we obtain the mapping given in
eq. (2.127).
We use this result to obtain the Fokker-Planck equation associated with the Langevin
equation (A.74) in the Stratonovich interpretation. To this aim, we ﬁrst transform the
Langevin equation into the Ito convention, obtaining eq. (A.74). We then write its
associated Fokker-Planck equation:
∂
∂tp(x; t) = ∂
∂x
/
−σ(x) 1
2σ ′(x) p + 1
2
∂
∂x
!
σ 2(x) p
"0
= 1
2
∂
∂x
/
σ(x) ∂
∂x
!
σ(x) p
"0
.
(A.85)
In the general case, where a drif v(x, t) is also present, we obtain eq. (2.124), which is
known as the Stratonovich form of the Fokker-Planck equation.

224
Appendixes
e2
e1
e4
e7
e10
e5
e9
e8
e6
e3
e2
e1
e4
e7
e10
e5
e9
e8
e6
e3
(a)
(b)
Figure A.3. Construction of the cycle space. (a) The cycle shown in bold, if oriented
counterclockwise, is represented by the vector v = −e1 + e2 + e3 −e4 −e9 −e10. (b) Given
the spanning tree shown in bold, the cycle deﬁned by the chord e10 corresponds to
the vector v = e10 + e9 + e4 + e6. The cut corresponding to e4 is given by w = e4 + e5 + e8
−e10. One has v · w = 0.
A.9
Basis of the cycle space
In this appendix, we sketch the proof that the set of fundamental cycles constitutes a
complete basis for the space of cycles associated with a jump network. Our proof loosely
follows Bolloba´s [23, ch. 3]. We consider a connected jump network with N nodes and
K edges, where each edge belongs to at least one cycle. This corresponds to the core
network of a general connected jump network. We associate with it a set of fundamental
cycles, using the construction described in section 3.9.
We now show that the set of fundamental cycles is a complete basis for the space
of cycles. Since the spanning tree has N −1 edges, the number ν of cycles is equal to
K −N + 1.
The proof is based on a geometrical construction. We deﬁne the K-dimensional lin-
ear space Cedg, where K is the number of edges, by giving an (arbitrary) orientation
to each edge and associating it with a basis vector ek. A generic vector x in this space
is a linear combination x = &
k xkek of the basis vectors, with real coeﬃcients xk. We
introduce in this space the scalar product x · y = &
k xkyk.
We then introduce the space Ccyc associated with the directed cycles in the jump
network. It is obtained by associating with each cycle Cα a vector cα in Cedg, whose
entries are +1 if a given edge is part of the cycle with the same orientation, −1 if the
edge is part of the cycle with opposite orientation, and 0 if the edge is not part of the
cycle. An example of this construction is shown in ﬁg. A.3a. This representation allows
us to show that the cycles in the fundamental set are linearly independent. If this were
not the case, one could ﬁnd a linear combination of them such that &ν
α=1 λαcα = 0.
But this is impossible since each cycle contains a unique chord not shared by the other
cycles. Since the space spanned by the Cα contains at least (K −N + 1) independent
vectors, the dimension of the cycle space satisﬁes dim Ccyc ≥ν = K −N + 1.

Appendixes
225
We now deﬁne the space Ccut. A cut is a partition of the nodes of the network in
two disjoint and nonempty sets A and B, such that their union is the set of all nodes. In
particular, each edge of the spanning tree deﬁnes, if removed, two disjoint sets of nodes
and therefore a cut. We associate with each cut a cut vector in the edge space, whose
entries are equal to 1 if the corresponding edge links a state in A to a state in B, −1 if it
links a state in B to a state in A, and 0 otherwise; see ﬁg. A.3b.
A useful result of graph theory states that, for a connected graph,
Cedg = Ccyc ⊕Ccut,
(A.86)
where A ⊕B is the directsum of the linear spaces A and B, whose only common element
is the null vector. A generic element of A ⊕B is a linear combination of an element of
A and an element of B. From eq. (A.86), one obtains
dim Ccyc = N −K + 1,
dim Ccut = N −1.
(A.87)
To prove these results, we start from the observation that any cycle is orthogonal to any
cut vector. Indeed, the scalar product between a cycle and a cut vector is the number
of jumps in the cycle going from the set of states A to the set B minus the number of
jumps in the cycle going from the set B to the set A. Since the cycle must return to the
original state, this diﬀerence must vanish. This implies that Ccyc and Ccut are orthogonal
spaces.
Given this fact, as well as the facts that Ccyc ≥ν = K −N + 1 and dim Cedg = K, to
prove eqs. (A.86) and (A.87), it is suﬃcient to show that dim Ccut ≥N −1. This can be
proved by another explicit construction. We consider the N −1 cuts associated with
each of the N −1 edges of the spanning tree, as previously discussed. The cut vectors
associated with these N −1 cuts are linearly independent because of the same argument
used for the cycle space: each of these N −1 vectors has a nonzero component associ-
ated with the removed edge that is equal to zero for all other vectors. This completes
the proof.
A.10
Actions and trajectory probabilities for
Langevin equations
In this appendix, we derive in more detail the expression (4.96) of the diﬀerence
of the action between the forward and backward trajectories of a Langevin equation.
In particular, we better justify the use of the Stratonovich convention in the integral
deﬁning the action.
We rewrite the action S(x, λ) in eq. (4.90) with an explicit discretization,
S(x, λ) = 1
4D
- tf
t0
dt
'dx
dt −µPF(x, t)
(2
=
= lim
)t→0
1
4D )t
N
%
ℓ=1
(xℓ−xℓ−1 −µPF(xℓ−1, tℓ−1) )t)2 ,
(A.88)

226
Appendixes
and we rewrite the action of the backward trajectory in a similar way:
S(;x;;λ) =
- tf
t0
dt 1
4D
'dx(t)
dt
+ µP F(x(t), λ(t))
(2
=
= lim
)t→0
1
4D )t
N
%
ℓ=1
(xℓ−xℓ−1 + µPF(xℓ, tℓ) )t)2 .
(A.89)
In writing these expressions, we take into account that the forward and backward
actions must be discretized in diﬀerent ways: the former using the initial point of each
time interval of duration )t and the latter using its end point, which corresponds to
its initial point in reverse time. In deriving the ﬂuctuation relations, as in eq. (4.96), we
evaluate the diﬀerence between S(x, λ) and S(;x,;λ). We then have
S(x, λ) −S(;x,;λ)
= lim
)t→0
1
4D )t
n
%
ℓ=1
+
(xℓ−xℓ−1 −µPF(xℓ−1, tℓ−1) )t)2
−(xℓ−xℓ−1 + µPF(xℓ, tℓ) )t)2,
= lim
)t→0
1
4D
n
%
ℓ=1
[−2(xℓ−xℓ−1) × µP (F(xℓ−1, tℓ−1 + F(xℓ, tℓ))
+
!F2(xℓ−1, tℓ−1) −F2(xℓ, tℓ)
"
)t
6
,
(A.90)
where the terms
!F2(xℓ−1, tℓ−1) −F2(xℓ, tℓ)
"
)t sum up to a boundary contribu-
tion proportional to )t, which can be neglected in the )t →0 limit. The factor
(F(xℓ−1, tℓ−1 + F(xℓ, tℓ)) can be approximated by the midpoint expression 2F((tℓ+
tℓ−1)/2, (xℓ+ xℓ−1)/2) up to higher-order terms. Taking into account the Einstein
relation (3.84), we obtain
S(x, λ) −S(;x,;λ) = −1
kBT
- tf
t0
dx ◦F(x, t),
(A.91)
where ◦reminds us that the integral has to be considered in the Stratonovich interpre-
tation.
A.11
The Bennett-Crooks estimator for the
free-energy difference
In this appendix, we sketch the derivation of the Bennett-Crooks optimal estimator
of the free-energy diﬀerence, eq. (7.9), following Bennett [11] and Crooks [35]. We write
the detailed ﬂuctuation relation for the work w in the following way:
pF(w) e−w/kBT = pB(−w) e−)F/kBT.
(A.92)

Appendixes
227
Given a function f (w), it is convenient to deﬁne the averages:
φF =
<
f (w)e−w/kBT=
F =
-
dw pF(w) f (w)e−w/kBT,
φB =
#
f (−w)
$
B =
-
dw pB(w) f (−w).
(A.93)
The detailed ﬂuctuation theorem permits us to express the free-energy diﬀerence in
terms of these averages as
)F = −kBT (ln φB −ln φF) .
(A.94)
Importantly, this expression is valid for any choice of the function f (w). Our aim is to
choose this function in such a way as to minimize the expected error on the free energy
when the averages in eq. (A.93) are estimated empirically. In particular, we assume a
large number of samples NF for the forward and NB for the backward protocols, such
that the distributions of the data to be averaged are approximately Gaussian. Then the
uncertainties on the empirical means of φF,B are respectively given by the standard
errors
δφ2
F = σ 2
F
NF
,
δφ2
B = σ 2
B
NB
,
(A.95)
where we deﬁne the variances
σ 2
F =
-
dw pF(w) e−2w/kBT f 2(w) −φ2
F;
σ 2
B =
-
dw pB(w) f 2(−w) −φ2
B.
(A.96)
By propagating these uncertainties, we ﬁnd that the expected squared error δ()F)2 in
the estimate of )F is
δ()F)2
(kBT)2 =
σ 2
F
NFφ2
F
+
σ 2
B
NBφ2
B
.
(A.97)
We want to minimize the expected squared error with respect to the function f (w)
for a given expectation of )F. We ﬁrst express it as
δ()F)2
(kBT)2 =
1
φFφB
/
e)F/kBT σ 2
F
NF
+ e−)F/kBT σ 2
B
NB
0
+ const.,
(A.98)
where the constant does not depend on f (w). Now
e)F/kBT σ 2
F
NF
+ e−)F/kBT σ 2
B
NB
=
-
dw pB(−w) f 2(w)
>
e−w/kBT
NF
+ e−)F/kBT
NB
?
.
(A.99)

228
Appendixes
Minimizing with respect to f (w), we obtain
f (w) =
const.
(e−w/kBT/NF) + (e−)F/kBT/NB).
(A.100)
Setting the constant to 1 and substituting in the deﬁnitions of φF, φB, we obtain
φF =
-
dw pF(w) f (w) = NF
@
1
1 + e(w−z)/kBT
A
,
φB =
-
dw pB(w) f (−w) = NB
@
1
1 + e(w+z)/kBT
A
,
(A.101)
where
z = )F + kBT ln NB
NF
.
(A.102)
Thus we have
)F = −kBT [ln φB −ln φF]
(A.103)
= −kBT
/
ln
@
1
1 + e(w+z)/kBT
A
−ln
@
1
1 + e(w−z)/kBT
A0
−kBT ln NB
NF
.
We then obtain the self-consistency equation
z = −kBT
/
ln
@
1
1 + e(w+z)/kBT
A
−ln
@
1
1 + e(w−z)/kBT
A0
,
(A.104)
from whose solution we evaluate
)F = z −kBT ln NB
NF
.
(A.105)
A.12
Cauchy-Schwarz inequality
The Cauchy-Schwarz inequality states that, given two vectors u and v for which a
real scalar product (u · v) is deﬁned, we have
(u · v)2 ≤(u · v)(v · v).
(A.106)
The deﬁning properties of a scalar product are
Commutativity: (u · v) = (v · u).
Linearity: (au · v) = a(u · v), a ∈R.
Additivity: ((u + v) · w) = (u · w) + (v · w).
Positivity: (u · u) ≥0. If (u · u) = 0, then u = 0.

Appendixes
229
Given u and v, we deﬁne w(a) for a ∈R by
w(a) = au + v.
(A.107)
We then have
(w(a) · w(a)) = a2(u · u) + 2a(u · v) + (v · v) ≥0,
∀a ∈R.
(A.108)
This is a quadratic form in a that can have at most one zero. Hence its discriminant )
must be nonpositive. We therefore have
) = 4
+
(u · v)2 −(u · u)(v · v)
,
≤0,
(A.109)
which is the Cauchy-Schwarz inequality. Note that the inequality is saturated when v =
λ u, where λ is an arbitrary real scalar. The inequality readily generalizes to integrable
functions, when the scalar product is deﬁned by
( f , g) =
-
dx f (x) g(x).
(A.110)
A.13
Bound for the current rate function
In this appendix, we sketch the derivation of the bound (8.33) for the current rate
function, following Gingrich et al. [69].
As derived in eq. (6.116), the rate function I(j) for the current j = (jxx′) is bounded by
I(pst, j) = 1
4
%
xx′
λxx′jxx′ −1
2
%
xx′
!
t∗
xx′ −txx′"
,
(A.111)
where pst is the steady-state probability distribution, and
λxx′ = 2 ln
/
1
2kxx′pst
x′
'
jxx′ +
B
j2
xx′ + α2
xx′
(0
= −λx′x,
(A.112)
with αxx′ =
C
kxx′kx′xfx′fx. The traﬃc variables t (cf. eq. (6.19)) are deﬁned by
txx′ = kxx′pst
x′ + kx′xpst
x ;
t∗
xx′ = κ∗
xx′pst
x′ + κ∗
x′xpst
x .
(A.113)
The steady-state current is given by Jst
xx′ = kxx′pst
x′ −kx′xpst
x . The traﬃc can also be
expressed as functions of j and Jst by
txx′ =
B
(Jst
xx′)2 + α2
xx′;
t∗
xx′ =
B
j2
xx′ + α2
xx′.
(A.114)

230
Appendixes
In the ﬁrst term on the right-hand side of eq. (A.111), we regroup the terms for each
edge xx′ and obtain
S = 1
4
%
xx′
jxx′λxx′ = 1
4
%
x′<x
jxx′ (λxx′ −λx′x)
= 1
2
%
x′<x
jxx′

ln
jxx′ +
B
j2
xx′ + α2
xx′
jxx′ +
B
−j2
xx′ + α2
xx′
+ ln kx′xfx
kxx′fx′

.
(A.115)
We now have
kxx′pst
x′ = Jst
xx′ + txx′ = Jst
xx′ +
B
(Jst
xx′)2 + αxx′,
(A.116)
and we therefore obtain
S = 1
2
%
x′<x
jxx′

ln
jxx′ +
B
j2
xx′ + α2
xx′
−jxx′ +
B
j2
xx′ + α2
xx′
−ln
Jst
xx′ +
B
(Jst
xx′)2 + αxx′
−Jst
xx′ +
B
(Jst
xx′)2 + αxx′


=
%
x<x′
jxx′
'
arc sinh jxx′
αxx′ −arc sinh Jst
xx′
αxx′
(
,
(A.117)
where we use the relation
arc sinh x = ln
4
x +
C
x2 + 1
5
.
(A.118)
We therefore obtain
I(pst, j) =
%
x<x′
3
!
jxx′, Jst
xx′, α
"
,
(A.119)
where
3(jxx′, Jst
xx′, α) = jxx′
'
arc sinh jxx′
α −arc sinh Jst
xx′
α
(
+
B
Jst2
xx′ + α2 −
B
j2
xx′ + α2.
(A.120)
We also introduce the quantity
)(jxx′, Jst
xx′, α) = 3(jxx′, Jst
xx′, α) −(jxx′ −Jst
xx′)2
2Jst2
xx′
'
Jst
xx′ arc sinh Jst
xx′
α
(
≤0.
(A.121)
To obtain this inequality, we observe that ) is even in jxx′, so that we only need to con-
sider positive values of jxx′. The derivative of ) with respect to jxx′ is
∂)
∂jxx′ = arc sinh jxx′
α −jxx′
Jst
xx′
arc sinh Jst
xx′
α .
(A.122)
The second term is a line that crosses the arc sinh (jxx′/α) curve at jxx′ = 0 and at
jxx′ = Jst
xx′. Now, sinh x is convex for x ≥0, therefore arc sinh x is concave in the same

Appendixes
231
region. Thus the derivative of ) is positive for 0 < jxx′ < Jst
xx′, vanishes for jxx′ = Jst
xx′ by
inspection, and therefore, by concavity, is negative for jxx′ > Jst
xx′. Thus ), which van-
ishes at jxx′ = Jst
xx′, decreases as
22jxx′ −Jst
xx′
22 increases and is therefore nonpositive for
jxx′ ≥0. By symmetry, the same is true for jxx′ < 0.
The average entropy production rate in the steady state is given by
˙Stot = kB
2
%
xx′
Jst
xx′ ln kxx′pst
x′
kx′xpstx
.
(A.123)
By means of eq. (A.116), we cast it in the form
˙Stot =
%
x′<x
˙Stot
xx′ =
%
x′<x
2kB Jst
xx′ arc sinh Jst
xx′
αxx′ =
%
x′<x
Jst
xx′
Axx′
T ,
(A.124)
where
Axx′ = 2kBT arc sinh Jst
xx′
αxx′ .
(A.125)
We therefore obtain the bound
I(j) ≤
%
x′<x
1
4kB (Jst
xx′)2
!
jxx′ −Jst
xx′
"2 ˙Stot
xx′ .
(A.126)
We obtain eq. (8.36) from this result by the contraction principle. We deﬁne the scalar
product in the space of currents by ( f , g) = &
x′<x fxx′gxx′. Using the scalar product, the
current jd associated with a distance matrix d is expressed by jd = (d, j) (cf. eq. (6.17)).
The empirical currents j must satisfy the conservation of probability. We impose this
condition via the constraints (hy, j) = 0, ∀y, where hy,xx′ = δK
yx −δK
yx′. By the contraction
principle, we obtain.
I(jd) = inf
j I(j|(d, j) = jd, (hy, j) = 0, ∀y)
≤ILR(j|(d, j) = jd, (hy, j) = 0, ∀y).
(A.127)
We deﬁne j∗by
j∗= jd
Jst
d
Jst.
(A.128)
This current satisﬁes the conditions (d, j) = jd, (hy, j) = 0. Substituting it in ILR(j), we
ﬁnally obtain the bound
I(jd) ≤ILR(j∗) = (jd −Jst
d )
4(Jst
d )2
˙Stot = IWLR(jd).
(A.129)


Bibliography
[1] Anderson, D. F. (2007). A modiﬁed next reaction method for simulating chemical systems with
time dependent propensities and delays. Journal of Chemical Physics, 127(21):214107.
[2] Andrieux, D., and Gaspard, P. (2004). Fluctuation theorem and Onsager reciprocity relations.
Journal of Chemical Physics, 121:6167.
[3] Andrieux, D., and Gaspard, P. (2006). Erratum: “Fluctuation theorem and Onsager reciprocity
relations” [J. Chem. Phys. 121:6167 (2004)]. Journal of Chemical Physics, 125:219902.
[4] Andrieux, D., and Gaspard, P. (2008). Nonequilibrium generation of information in copoly-
merization processes. Proceedings of the National Academy of Sciences, 105(28):9516–9521.
[5] Aurell, E., Gawedzki, K., Mejía-Monasterio, C., Mohayaee, R., and Muratore-Ginanneschi, P.
(2012). Reﬁned second law of thermodynamics for fast random processes. Journal of Statistical
Physics, 147(3):487–505.
[6] Aurell, E., Mejía-Monasterio, C., and Muratore-Ginanneschi, P. (2011). Optimal protocols and
optimal transport in stochastic thermodynamics. Physical Review Letters, 106(25):250601.
[7] Barato, A., and Seifert, U. (2014a). Unifying three perspectives on information processing in
stochastic thermodynamics. Physical Review Letters, 112(9):090601.
[8] Barato, A. C., and Seifert, U. (2014b). Stochastic thermodynamics with information reservoirs.
Physical Review E, 90(4):042150.
[9] Barato, A. C., and Seifert, U. (2015). Thermodynamic uncertainty relation for biomolecular
processes. Physical Review Letters, 114(15):158101.
[10] Bennett, C. H. (1973). Logical reversibility of computation. IBM Journal of Research and
Development, 17:525–532.
[11] Bennett, C. H. (1976). Eﬃcient estimation of free energy diﬀerences from Monte Carlo data.
Journal of Computational Physics, 22(2):245–268.
[12] Bennett, C. H. (1979). Dissipation-error tradeoﬀin proofreading. Biosystems, 11:85–91.
[13] Bennett, C. H. (1982). The thermodynamics of computation—a review. International Journal
of Theoretical Physics, 21:905–940.
[14] Bennett, C. H. (2003). Notes on Landauer’s principle, reversible computation and Maxwell’s
demon. Studies in History and Philosophy of Modern Physics, 34:501–510.
[15] Berg, H. C. (1993). Random Walks in Biology. Princeton University Press, Princeton, NJ.
[16] Bergmann, P. G., and Lebowitz, J. L. (1955). New approach to nonequilibrium processes.
Physical Review, 99(2):578.
[17] Bertini, L., Faggionato, A., and Gabrielli, D. (2015). Flows, currents, and cycles for Markov
chains: Large deviation asymptotics. Stochastic Processes and Their Applications, 125(7):2786–
2819.
[18] Bo, S., and Celani, A. (2017). Multiple-scale stochastic processes: Decimation, averaging and
beyond. Physics Reports, 670:1–59.
[19] Bochkov, G. N., and Kuzovlev, Y. E. (1977). General theory of thermal ﬂuctuations in nonlinear
systems. Soviet Physics JETP, 45:125–129.
[20] Bochkov, G. N., and Kuzovlev, Y. E. (1979). Fluctuation-dissipation relations for nonequilib-
rium processes in open systems. Soviet Physics JETP, 49:543–551.

234
Bibliography
[21] Bochkov, G. N., and Kuzovlev, Y. E. (1981a). Nonlinear ﬂuctuation-dissipation relations and
stochastic models in nonequilibrium thermodynamics: I. Generalized ﬂuctuation-dissipation
theorem. Physica A: Statistical Mechanics and Its Applications, 106(3):443–479.
[22] Bochkov, G. N., and Kuzovlev, Y. E. (1981b). Nonlinear ﬂuctuation-dissipation relations
and stochastic models in nonequilibrium thermodynamics: II. Kinetic potential and varia-
tional principles for nonlinear irreversible processes. Physica A: Statistical Mechanics and Its
Applications, 106(3):480–520.
[23] Bolloba´s, B. (2013). Modern Graph Theory. Volume 184. Springer Science & Business Media,
New York.
[24] Boltzmann, L. (1877). Uber die Beziehung zwischen dem zweiten Hauptsatze der mechanis-
chen Wärmetheorie und der Wahrscheinlichkeitsrechnung respecktive den Sätzen über das
Wärmegleichgewicht. Wiener Berichte, 2:373–435.
[25] Brillouin, L. (1949). Life, thermodynamics and cybernetics. American Scientist, 37:554–568.
[26] Brouwer, L. E. J. (1912). Über Abbildung von Mannigfaltigkeiten. Mathematische Annalen,
7:97–115.
[27] Bérut, A., Arakelyan, A., Petrosyan, A., Ciliberto, S., Dillenschneider, R., and Lutz, E. (2012).
Experimental veriﬁcation of Landauer’s principle linking information and thermodynamics.
Nature, 483:187–190.
[28] Callen, H. B. (1985). Thermodynamics and an Introduction to Thermostatistics. Wiley,
New York.
[29] Chandler, D. (1987). Introduction to Modern Statistical Mechanics. Oxford University Press,
New York.
[30] Chetrite, R., and Touchette, H. (2015). Nonequilibrium Markov processes conditioned on large
deviations. Annales Henri Poincare´, 16(9):2005–2057.
[31] Collin, D., Ritort, F., Jarzynski, C., Smith, S. B., Tinoco Jr., I., and Bustamante, C. (2005). Veri-
ﬁcation of the Crooks ﬂuctuation theorem and recovery of RNA folding free energies. Nature,
437(7056):231.
[32] Cover, T. M., and Thomas, J. A. (2006). Elements of Information Theory. 2nd edition. Wiley,
Hoboken, NJ.
[33] Crooks, G. E. (1998). Nonequilibrium measurements of free energy diﬀerences for microscop-
ically reversible Markovian systems. Journal of Statistical Physics, 90:1481–1487.
[34] Crooks, G. E. (1999). The entropy production ﬂuctuation theorem and the nonequilibrium
work relation for free energy diﬀerences. Physical Review E, 60:2721–2728.
[35] Crooks, G. E. (2000). Path-ensemble averages in systems driven far from equilibrium. Physical
Review E, 61:2361–2366.
[36] Cuetara, G. B., Esposito, M., and Imparato, A. (2014). Exact ﬂuctuation theorem without
ensemble quantities. Physical Review E, 89(5):052119.
[37] De Groot, S. R., and Mazur, P. (1984). Non-equilibrium Thermodynamics. Dover, New York.
(Reprinted by Courier (2013).)
[38] Dechant, A. (2018). Multidimensional thermodynamic uncertainty relations. Journal of Physics
A: Mathematical and Theoretical, 52(3):035001.
[39] Dechant, A., and Sasa, S. (2018). Current ﬂuctuations and transport eﬃciency for general
Langevin systems. Journal of Statistical Mechanics: Theory and Experiment, 2018(6):063209.
[40] Dechant, A., and Sasa, S. (2020). Fluctuation-response inequality out of equilibrium. Proceed-
ings of the National Academy of Sciences, 117(12):6430–6436.
[41] Deﬀner, S., and Campbell, S. (2019). Quantum Thermodynamics: An Introduction to the
Thermodynamics of Quantum Information. Morgan & Claypool Publishers, San Rafael, CA.
[42] Dembo, A., and Zeitouni, O. (2010). Large Deviations Techniques and Applications. Volume 38
of Stochastic Modelling and Applied Probability. Springer, Berlin.
[43] Den Hollander, F. (2008). Large Deviations. Volume 14 of Fields Institute Monographs. Ameri-
can Mathematical Society, Providence, RI.
[44] Einstein, A. (1905). Über die von der molekularkinetischen Theorie der Wärme geforderte
Bewegung von in ruhenden Flüssigkeiten suspendierten Teilchen. Ann. Physik, 17(8):549–560.

Bibliography
235
[45] Einstein, A. (1910). Theorie der Opaleszenz von homogenen Flüssigkeiten und Flüssigkeits-
gemischen in der Nähe des kritischen Zustandes. Ann. Physik, 33:1275–1298.
[46] Einstein, A. (1956). Investigations on the Theory of the Brownian Movement. Edited by R. Fürth.
Dover, New York.
[47] Ellis, R. S. (1985). Entropy, Large Deviations and Statistical Mechanics. Springer, Berlin.
[48] Esposito, M. (2012). Stochastic thermodynamics under coarse graining. Physical Review E,
85:041125.
[49] Esposito, M., Harbola, U., and Mukamel, S. (2009). Nonequilibrium ﬂuctuations, ﬂuctua-
tion theorems, and counting statistics in quantum systems. Reviews of Modern Physics, 81(4):
1665.
[50] Esposito, M., and Van den Broeck, C. (2010). Three detailed ﬂuctuation theorems. Physical
Review Letters, 104:090601.
[51] Evans, D. J., Cohen, E. G. D., and Morriss, G. P. (1993). Probability of second law violations in
shearing steady states. Physical Review Letters, 71:2401–2404.
[52] Falcioni, M., Palatella, L., Pigolotti, S., Rondoni, L., and Vulpiani, A. (2007). Initial growth of
Boltzmann entropy and chaos in a large assembly of weakly interacting systems. Physica A:
Statistical Mechanics and Its Applications, 385(1):170–184.
[53] Feynman, R. P. (1996). Feynman Lectures on Computation. Edited by A. J. G. Hey, and R. W.
Allen. Addison-Wesley, Reading, MA.
[54] Feynman, R. P., Leighton, R. B., and Sands, M. (2011). The Feynman Lectures on Physics:
The New Millennium Edition. Volume 1, Mainly Mechanics, Radiation, and Heat. Basic Books,
New York.
[55] Fisher, R. A. (1930). The Genetical Theory of Natural Selection. Clarendon Press, New York.
(Reprinted by Dover (1958).)
[56] Gallavotti, G., and Cohen, E. G. D. (1995a). Dynamical ensembles in nonequilibrium statistical
mechanics. Physical Review Letters, 74:2694–2697.
[57] Gallavotti, G., and Cohen, E. G. D. (1995b). Dynamical ensembles in stationary states. Journal
of Statistical Physics, 80:931–970.
[58] García-García, R., Genthon, A., and Lacoste, D. (2019). Linking lineage and population
observables in biological branching processes. Physical Review E, 99(4):042413.
[59] Gardiner, C. (2009). Stochastic Methods. Volume 4 of Springer Series in Synergetics. 4th edition.
Springer, Berlin.
[60] Garrahan, J. P. (2017). Simple bounds on ﬂuctuations and uncertainty relations for ﬁrst-passage
times of counting observables. Physical Review E, 95(3):032134.
[61] Gawedzki, K. (2013). Fluctuation relations in stochastic thermodynamics. arXiv, 1308.1518.
[62] Giardinà, C., Kurchan, J., and Peliti, L. (2006). Direct evaluation of large-deviation functions.
Physical Review Letters, 96:120603.
[63] Gibson, M. A., and Bruck, J. (2000). Exact stochastic simulation of chemical systems with many
species and many channels. Journal of Physical Chemistry, 105:1876–1879.
[64] Gillespie, D. T. (1976). A general method for numerically simulating the stochastic time
evolution of coupled chemical reactions. Journal of Computational Physics, 22(4):403–434.
[65] Gillespie, D. T. (1977). Exact stochastic simulation of coupled chemical reactions. Journal of
Physical Chemistry, 81(25):2340–2361.
[66] Gillespie, D. T. (2001). Approximate accelerated stochastic simulation of chemically reacting
systems. Journal of Chemical Physics, 115:1716–1733.
[67] Gillespie, D. T. (2007). Stochastic simulation of chemical kinetics. Annual Reviews of Physical
Chemistry, 58:35–55.
[68] Gingrich, T. R., and Horowitz, J. M. (2017). Fundamental bounds on ﬁrst passage time
ﬂuctuations for currents. Physical Review Letters, 119(17):170601.
[69] Gingrich, T. R., Horowitz, J. M., Perunov, N., and England, J. L. (2016). Dissipation bounds all
steady-state current ﬂuctuations. Physical Review Letters, 116(12):120601.
[70] Gingrich, T. R., Rotskoﬀ, G. M., and Horowitz, J. M. (2017). Inferring dissipation from current
ﬂuctuations. Journal of Physics A: Mathematical and Theoretical, 50:184004.

236
Bibliography
[71] Gingrich, T. R., Rotskoﬀ, G. M., Vaikuntanathan, S., and Geissler, P. L. (2014). Eﬃciency and
large deviations in time-asymmetric stochastic heat engines. New Journal of Physics, 16(10):
102003.
[72] Goldstein, S., Huse, D. A., Lebowitz, J. L., and Sartori, P. (2017). On the nonequilibrium entropy
of large and small systems. In Giacomin, G., Olla, S., Saada, E., Spohn, H., and Stoltz, G., editors,
Stochastic Dynamics Out of Equilibrium. Volume 282 of Springer Proceedings in Mathematics
and Statistics, pages 581–596, Springer, New York.
[73] Harris, R. J., and Schütz, G. M. (2007). Fluctuation theorems for stochastic dynamics. Journal
of Statistical Mechanics: Theory and Experiment, 2007(07):P07020.
[74] Hasegawa, Y., and Van Vu, T. (2019). Fluctuation theorem uncertainty relation. Physical Review
Letters, 123(11):110602.
[75] Hatano, T., and Sasa, S. (2001). Steady state thermodynamics of Langevin systems. Physical
Review Letters, 86:3463–3466.
[76] Hong, J., Lambson, B., Dhuey, S., and Bokor, J. (2016). Experimental test of Landauer’s principle
in single-bit operations on nanomagnetic memory bits. Science Advances, 2(3):e1501492.
[77] Horowitz, J. M., and Esposito, M. (2014). Thermodynamics with continuous information ﬂow.
Physical Review X, 4(3):031015.
[78] Horowitz, J. M., and Gingrich, T. R. (2017). Proof of the ﬁnite-time thermodynamic uncertainty
relation for steady-state currents. Physical Review E, 96(2):020103.
[79] Horowitz, J. M., and Gingrich, T. R. (2019). Thermodynamic uncertainty relations constrain
non-equilibrium ﬂuctuations. Nature Physics, 16(1):15–20.
[80] Howard, J. (2001). Mechanics of Motor Proteins and the Cytoskeleton. Sinauer Associates,
Sunderland, MA.
[81] Jarzynski, C. (1997). Nonequilibrium equality for free energy diﬀerences. Physical Review
Letters, 78(14):2690.
[82] Jarzynski, C. (2007). Comparison of far-from-equilibrium work relations. Comptes Rendus
Physique, 8:495–506.
[83] Jarzynski, C. (2017). Stochastic and macroscopic thermodynamics of strongly coupled systems.
Physical Review X, 7(1):011008.
[84] Jun, Y., Gavrilov, M., and Bechhoefer, J. (2014). High-precision test of Landauer’s principle in
a feedback trap. Physical Review Letters, 113(19):190601.
[85] Kawaguchi, K., and Nakayama, Y. (2013). Fluctuation theorem for hidden entropy production.
Physical Review E, 88(2):022147.
[86] Kawai, R., Parrondo, J., and Van den Broeck, C. (2007). Dissipation: The phase-space perspec-
tive. Physical Review Letters, 98:080602.
[87] Khinchin, A. I. (1957). Mathematical Foundations of Information Theory. Translated by R. A.
Silverman and M. D. Friedman. Dover, New York.
[88] Kobayashi, T. J., and Sughiyama, Y. (2015). Fluctuation relations of ﬁtness and information in
population dynamics. Physical Review Letters, 115(23):238102.
[89] Koski, J. V., Maisi, V. F., Pekola, J. P., and Averin, D. V. (2014). Experimental realization
of a Szilard engine with a single electron. Proceedings of the National Academy of Sciences,
111(38):13786–13789.
[90] Koski, J. V., Maisi, V. F., Sagawa, T., and Pekola, J. P. (2014). Experimental observation of the role
of mutual information in the nonequilibrium dynamics of a Maxwell demon. Physical Review
Letters, 113(3):030601.
[91] Koza, Z. (1999). General technique of calculating the drif velocity and diﬀusion coeﬃ-
cient in arbitrary periodic systems. Journal of Physics A: Mathematical and General, 32(44):
7637.
[92] Kurchan, J. (1998). Fluctuation theorem for stochastic dynamics. Journal of Physics A: Mathe-
matical and General, 31(16):3719.
[93] Kurchan, J. (2000). A quantum ﬂuctuation theorem. arXiv, preprint cond-mat/0007360.
[94] Lacoste, D., Lau, A. W., and Mallick, K. (2008). Fluctuation theorem and large deviation
function for a solvable model of a molecular motor. Physical Review E, 78:011915.

Bibliography
237
[95] Landau, L. D., Lifshitz, E. M., and Pitaevskii, L. P. (1980). Statistical Physics, Part I. Volume 5 of
Course of Theoretical Physics. Pergamon Press, Oxford, UK.
[96] Landauer, R. (1961). Irreversibility and heat generation in the computing process. IBM Journal
of Research and Development, 3:183–191.
[97] Landauer, R. (1991). Information is physical. Physics Today, 44(5):23–29.
[98] Lebowitz, J. L., and Spohn, H. (1999). A Gallavotti-Cohen-type symmetry in the large deviation
functional for stochastic dynamics. Journal of Statistical Physics, 95(1):333–365.
[99] Lecomte, V., and Tailleur, J. (2007). A numerical approach to large deviations in continuous
time. Journal of Statistical Mechanics: Theory and Experiment, 2007(03):P03004.
[100] Lee, H. K., Kwon, C., and Park, H. (2013). Fluctuation theorems and entropy production with
odd-parity variables. Physical Review Letters, 110(5):050602.
[101] Leﬀ, H., and Rex, A. F., editors (2003). Maxwell’s Demon 2: Entropy, Classical and Quantum
Information, Computing. IOP Publishing, Bristol, UK.
[102] Leibler, S., and Kussell, E. (2010). Individual histories and selection in heterogeneous popula-
tions. Proceedings of the National Academy of Sciences, 107(29):13183–13188.
[103] Liphardt, J., Dumont, S., Smith, S. B., Tinoco, I., and Bustamante, C. (2002). Equilibrium infor-
mation from nonequilibrium measurements in an experimental test of Jarzynski’s equality.
Science, 296(5574):1832–1835.
[104] Liphardt, J., Onoa, B., Smith, S. B., Tinoco, I., and Bustamante, C. (2001). Reversible unfolding
of single RNA molecules by mechanical force. Science, 292(5517):733–737.
[105] MacKay, D. J. C. (2003). Information Theory, Inference and Learning Algorithms. Cambridge
University Press, Cambridge, UK.
[106] Maes, C. (1999). The ﬂuctuation theorem as a Gibbs property. Journal of Statistical Physics,
95(1–2):367–392.
[107] Maes, C., and Netocˇny´, K. (2008). Canonical structure of dynamical ﬂuctuations in mesoscopic
nonequilibrium steady states. EPL (Europhysics Letters), 82(3):30003.
[108] Mandal, D., and Jarzynski, C. (2012). Work and information processing in a solvable model of
Maxwell’s demon. Proceedings of the National Academy of Sciences, 109(29):11641–11645.
[109] Marchetti, M. C., Joanny, J.-F., Ramaswamy, S., Liverpool, T. B., Prost, J., Rao, M., and Simha,
R. A. (2013). Hydrodynamics of sof active matter. Reviews of Modern Physics, 85(3):1143.
[110] Marini Bettolo Marconi, U., Puglisi, A., Rondoni, L., and Vulpiani, A. (2008). Fluctuation-
dissipation: Response theory in statistical physics. Physics Reports, 461(4-6):111–195.
[111] Maxwell, J. C. (1871). Theory of Heat. Longmans, Green and Co., London.
[112] Meyer, C. D. (2001). Matrix Analysis and Applied Linear Algebra. SIAM, Society for Industrial
and Applied Mathematics, Philadelphia, PA.
[113] Mossa, A., Manosas, M., Forns, N., Huguet, J. M., and Ritort, F. (2009). Dynamic force spec-
troscopy of DNA hairpins: I. Force kinetics and free energy landscapes. Journal of Statistical
Mechanics: Theory and Experiment, 2009(02):P02060.
[114] Murashita, Y., Funo, K., and Ueda, M. (2014). Nonequilibrium equalities in absolutely irre-
versible processes. Physical Review E, 90(4):042110.
[115] Murashita, Y., and Ueda, M. (2017). Gibbs paradox revisited from the ﬂuctuation theorem with
absolute irreversibility. Physical Review Letters, 118(6):060601.
[116] Mustonen, V., and Lässig, M. (2010). Fitness ﬂux and ubiquity of adaptive evolution. Proceed-
ings of the National Academy of Sciences, 107(9):4248–4253.
[117] Neri, I., Rolda´n, É., and Jülicher, F. (2017). Statistics of inﬁma and stopping times of entropy
production and applications to active molecular processes. Physical Review X, 7(1):011019.
[118] Neri, I., Rolda´n, É., Pigolotti, S., and Jülicher, F. (2019). Integral ﬂuctuation relations for
entropy production at stopping times. Journal of Statistical Mechanics: Theory and Experiment,
2019(10):104006.
[119] Nozoe, T., Kussell, E., and Wakamoto, Y. (2017). Inferring ﬁtness landscapes and selection on
phenotypic states from single-cell genealogical data. PLoS Genetics, 13(3):e1006653.
[120] Øksendal, B. (2003). Stochastic Diﬀerential Equations. Springer, Berlin.
[121] Onsager, L. (1931a). Reciprocal relations in irreversible processes. I. Physical Review, 37(4):405.

238
Bibliography
[122] Onsager, L. (1931b). Reciprocal relations in irreversible processes. II. Physical Review,
38(12):2265.
[123] Oono, Y., and Paniconi, M. (1998). Steady state thermodynamics. Progress of Theoretical Physics
Supplement, 130:29–44.
[124] Parrondo, J. M., Horowitz, J. M., and Sagawa, T. (2015). Thermodynamics of information.
Nature Physics, 11(2):131.
[125] Peliti, L. (2011). Statistical Mechanics in a Nutshell. Princeton University Press, Princeton, NJ.
[126] Penrose, O. (1970). Foundations of Statistical Mechanics: A Deductive Treatment. Dover,
New York.
[127] Pietzonka, P., Barato, A. C., and Seifert, U. (2016). Universal bound on the eﬃciency of
molecular motors. Journal of Statistical Mechanics: Theory and Experiment, 2016(12):124004.
[128] Pigolotti, S., Neri, I., Rolda´n, E´., and Jülicher, F. (2017). Generic properties of stochastic entropy
production. Physical Review Letters, 119(14):140604.
[129] Pigolotti, S., and Vulpiani, A. (2008). Coarse graining of master equations with fast and slow
states. Journal of Chemical Physics, 128(15):154114.
[130] Pippard, A. B. (1957). Elements of Classical Thermodynamics. Cambridge University Press,
Cambridge, UK.
[131] Polettini, M., Verley, G., and Esposito, M. (2015). Eﬃciency statistics at all times: Carnot limit
at ﬁnite power. Physical Review Letters, 114(5):050601.
[132] Press, W. H., Teukolsky, S. A., Vetterling, W. T., and Flannery, B. P. (2007). Numerical Recipes:
The Art of Scientiﬁc Computing. 3rd edition. Cambridge University Press, New York.
[133] Puglisi, A., Pigolotti, S., Rondoni, L., and Vulpiani, A. (2010). Entropy production and
coarse graining in Markov processes. Journal of Statistical Mechanics: Theory and Experiment,
2010(05):P05015.
[134] Qian, H. (2002). Mesoscopic nonequilibrium thermodynamics of single macromolecules and
dynamic entropy-energy compensation. Physical Review E, 65:01602.
[135] Rao, R., and Esposito, M. (2016). Nonequilibrium thermodynamics of chemical reaction
networks: Wisdom from stochastic thermodynamics. Physical Review X, 6(4):041064.
[136] Rao, R., and Esposito, M. (2018a). Conservation laws shape dissipation. New Journal of Physics,
20:023007.
[137] Rao, R., and Esposito, M. (2018b). Detailed ﬂuctuation theorems: A unifying perspective.
Entropy, 20:635.
[138] Redner, S. (2001). A Guide to First-Passage Processes. Cambridge University Press, Cambridge,
UK.
[139] Risken, H. (1996). The Fokker-Planck Equation. Springer Series in Synergetics. 2nd edition.
Springer, Berlin.
[140] Sagawa, T., and Ueda, M. (2010). Generalized Jarzynski equality under nonequilibrium feed-
back control. Physical Review Letters, 104:090602.
[141] Saito, K., and Dhar, A. (2016). Waiting for rare entropic ﬂuctuations. EPL (Europhysics Letters),
114(5):50004.
[142] Sartori, P., Granger, L., Lee, C. F., and Horowitz, J. M. (2014). Thermodynamic costs of
information processing in sensory adaptation. PLoS Computational Biology, 10(12):e1003974.
[143] Sartori, P., and Pigolotti, S. (2013). Kinetic versus energetic discrimination in biological
copying. Physical Review Letters, 110:188101.
[144] Sartori, P., and Pigolotti, S. (2015). Thermodynamics of error correction. Physical Review X,
5(4):041039.
[145] Schmiedl, T., and Seifert, U. (2007). Optimal ﬁnite-time processes in stochastic thermodynam-
ics. Physical Review Letters, 98(10):108301.
[146] Schnakenberg, J. (1976). Network theory of microscopic and macroscopic behavior of master
equation systems. Reviews of Modern Physics, 48:571–585.
[147] Schuler, S., Speck, T., Tietz, C., Wrachtrup, J., and Seifert, U. (2005). Experimental test of the
ﬂuctuation theorem for a driven two-level system with time-dependent rates. Physical Review
Letters, 94(18):180602.

Bibliography
239
[148] Seifert, U. (2005). Entropy production along a stochastic trajectory and an integral ﬂuctuation
theorem. Physical Review Letters, 95:040602.
[149] Seifert, U. (2012). Stochastic thermodynamics, ﬂuctuation theorems, and molecular machines.
Reports on Progress in Physics, 75:126001.
[150] Seifert, U. (2018). Stochastic thermodynamics: From principles to the cost of precision. Physica
A: Statistical Mechanics and Its Applications, 504:176–191.
[151] Sekimoto, K. (1997). Kinetic characterization of heat bath and the energetics of thermal ratchet
models. Journal of the Physical Society of Japan, 66:1234–1237.
[152] Sekimoto, K. (1998). Langevin equation and thermodynamics. Progress of Theoretical Physics
Supplement, 130:17–27.
[153] Sekimoto, K. (2010). Stochastic Energetics. Number 799 in Lecture Notes in Physics. Springer,
Heidelberg, Germany.
[154] Shannon, C. E. (1948). A mathematical theory of communication. Bell System Technical Journal,
27:379–423, 623–656.
[155] Shiraishi, N., Matsumoto, T., and Sagawa, T. (2016). Measurement-feedback formalism meets
information reservoirs. New Journal of Physics, 18(1):013044.
[156] Singh, S., Menczel, P., Golubev, D. S., Khaymovich, I. M., Peltonen, J. T., Flindt, C., Saito, K.,
Rolda´n, E´., and Pekola, J. P. (2019). Universal ﬁrst-passage-time distribution of non-Gaussian
currents. Physical Review Letters, 122(23):230602.
[157] Sivak, D. A., and Crooks, G. E. (2012). Thermodynamic metrics and optimal paths. Physical
Review Letters, 108(19):190602.
[158] Speck, T. (2011). Work distribution for the driven harmonic oscillator with time-dependent
strength: Exact solution and slow driving. Journal of Physics A: Mathematical and Theoretical,
44(30):305001.
[159] Spinney, R. E., and Ford, I. J. (2012). Nonequilibrium thermodynamics of stochastic systems
with odd and even variables. Physical Review Letters, 108(17):170603.
[160] Strasberg, P., and Esposito, M. (2020). Measurability of nonequilibrium thermodynamics in
terms of the Hamiltonian of mean force. Physical Review E, 101(5):050101.
[161] Sughiyama, Y., Kobayashi, T. J., Tsumura, K., and Aihara, K. (2015). Pathwise thermodynamic
structure in population dynamics. Physical Review E, 91(3):032120.
[162] Szilard, L. (1929). Über die Entropieverminderung in einem thermodynamischen System bei
Eingreﬀen intelligenter Wesen. Zeitschrif für Physik, 53:840–856.
[163] Szilard, L. (2006). On the decrease of entropy in a thermodynamic system by the intervention
of intelligent beings. Behavioral Science, 9:301–310.
[164] Tafoya, S., Large, S. J., Liu, S., Bustamante, C., and Sivak, D. A. (2019). Using a system’s equilib-
rium behavior to reduce its energy dissipation in nonequilibrium processes. Proceedings of the
National Academy of Sciences, 116(13):5920–5924.
[165] Talkner, P., and Hänggi, P. (2016). Open system trajectories specify ﬂuctuating work but not
heat. Physical Review E, 94(2):022143.
[166] Tietz, C., Schuler, S., Speck, T., Seifert, U., and Wrachtrup, J. (2006). Measurement of stochastic
entropy production. Physical Review Letters, 97(5):050602.
[167] Tizo´n-Escamilla, N., Lecomte, V., and Bertin, E. (2019). Eﬀective driven dynamics for one-
dimensional conditioned Langevin processes in the weak-noise limit. Journal of Statistical
Mechanics: Theory and Experiment, 2019(1):013201.
[168] Touchette, H. (2009). The large deviation approach to statistical mechanics. Physics Reports,
478(1–3):1–69.
[169] Toyabe, S., Sagawa, T., Ueda, M., Muneyuki, E., and Sano, M. (2010). Experimental demonstra-
tion of information-to-energy conversion and validation of the generalized Jarzynski equality.
Nature Physics, 6:988–992.
[170] Van den Broeck, C., and Esposito, M. (2015). Ensemble and trajectory thermodynamics: A brief
introduction. Physica A: Statistical Mechanics and Its Applications, 418:6–16.
[171] van Kampen, N. G. (2007). Stochastic Processes in Physics and Chemistry. 3rd edition. North
Holland, Amsterdam.

240
Bibliography
[172] Verley, G., Esposito, M., Willaert, T., and Van den Broeck, C. (2014). The unlikely Carnot
eﬃciency. Nature Communications, 5:4721.
[173] Verley, G., and Lacoste, D. (2012a). Fluctuation theorems and inequalities generalizing the
second law of thermodynamics out of equilibrium. Physical Review E, 86(5):051127.
[174] Verley, G., and Lacoste, D. (2012b). Fluctuations and response from a Hatano and Sasa
approach. Physica Scripta, 86:058505.
[175] Verley, G., Willaert, T., Van den Broeck, C., and Esposito, M. (2014). Universal theory of
eﬃciency ﬂuctuations. Physical Review E, 90(5):052145.
[176] Wolpert, D. H. (2019). The stochastic thermodynamics of computation. Journal of Physics A:
Mathematical and Theoretical, 52(19):193001.

Author Index
Aihara, K. 203. Ref. [161]
Anderson, D. F. 220. Ref. [1]
Andrieux, D. 128, 158. Refs. [2,3,4]
Arakelyan, A. 171 Ref. [27]
Aurell, E. 203. Refs. [5,6]
Averin, D. V. 171. Ref. [89]
Barato, A. C. 128, 202. Refs. [7,8,9,127]
Bechhoefer, J. 171, Ref. [84]
Bennett, C. H. 105, 106, 107, 127, 166, 167, 171, 226.
Refs. [10,11,12,13,14]
Berg, H. C. 35. Ref. [15]
Bergmann, P. G. 65. Ref. [16]
Bertin, E. 158. Ref. [167]
Bertini, L. 158. Ref. [17]
Bérut, A. 171. Ref. [27]
Bo, S. 65. Ref. [18]
Bochkov, G. N. 101. Refs. [19,20,21,22]
Bokor, J. 171. Ref. [76]
Bollobás, B. 224. Ref. [23]
Boltzmann, L. 1, 158. Ref. [24]
Brillouin, L. 127. Ref. [25]
Brouwer, L. E. J. 219. Ref. [26]
Bruck, J. 220. Ref. [63]
Bustamante, C. 171, 191, 203. Refs. [31,103,104,164]
Callen, H. B. 35. Ref. [28]
Campbell, S. 206. Ref. [41]
Celani, A. 65. Ref. [18]
Chandler, D. 35. Ref. [29]
Chetrite, R. 158. Ref. [30]
Ciliberto, S. 171. Ref. [27]
Cohen, E. G. D. 100, 101, 139. Refs. [51,56,57]
Collin, D. 171. Ref. [31]
Cover, T. M. 36. Ref. [32]
Crooks, G. E. 65, 100, 164, 171, 203, 226.
Refs. [33,34,35,157]
Cuetara, G. B. 101. Ref. [36]
Dechant, A. 202. Refs. [38,39,40]
De Groot, S. R. 35. Ref. [37]
Deﬀner, S. 206. Ref. [41]
Dembo, A. 158. Ref. [42]
Den Hollander, F. 158. Ref. [43]
Dhar, A. 202. Ref. [141]
Dhuey, S. 171. Ref. [76]
Dillenschneider, R. 171. Ref. [27]
Donsker, M. D. 158
Dumont, S. 171. Ref. [103]
Einstein, A. 2, 3, 26, 35, 158. Refs. [44,45,46]
Ellis, R. S. 158. Ref. [47]
England, J. L. 202, 229. Ref. [69]
Esposito, M. 65, 101, 128, 174, 202, 206.
Refs. [36,48,49,50,77,131,135,136,137,160,170,
172,175]
Evans, D. J. 100. Ref. [51]
Faggionato, A. 158. Ref. [17]
Falcioni, M. 205. Ref. [52]
Feynman, R. P. 35, 105, 106. Refs. [53,54]
Fisher, R. A. 197. Ref. [55]
Flannery, B. P. 220. Ref. [132]
Flindt, C. 203. Ref. [156]
Ford, I. J. 101. Ref. [159]
Forns, N. 163. Ref. [113]
Funo, K. 203. Ref. [114]
Gabrielli, D. 158. Ref. [17]
Gallavotti, G. 101, 145. Refs. [56,57]
García-García, R. 203. Ref. [58]
Gardiner, C. 35. Ref. [59]
Garrahan, J. P. 202. Ref. [60]
Gaspard, P. 128, 158. Refs. [2,3,4]
Gavrilov, M. 171. Ref. [84]
Gawedzki, K. 101, 203. Refs. [5,61]
Geissler, P. L. 202. Ref. [71]
Genthon, A. 203. Ref. [58]
Giardinà, C. 158. Ref. [62]
Gibson, M. A. 220. Ref. [63]
Gillespie, D. T. 219, 220. Refs. [64,65,66,67]
Gingrich, T. R. 65, 202, 203, 229.
Refs. [68,69,70,71,78,79]
Goldstein, S. 204. Ref. [72]

242
Author Index
Golubev, D. S. 204. Ref. [156]
Granger, L. 117, 119, 121, 128. Ref. [142]
Harbola, U. 206. Ref. [49]
Harris, R. J. 101. Ref. [73]
Hasegawa, Y. 202. Ref. [74]
Hatano, T. 82,101 Ref. [75]
Hong, J. 171. Ref. [76]
Horowitz, J. M. 65, 117, 119, 121, 128, 202, 203, 229.
Refs. [68,69,70,77,78,79,124,142]
Howard, J. 45, 65. Ref. [80]
Huguet, J. M. 163. Ref. [113]
Huse, D. A. 204. Ref. [72]
Imparato, A. 101. Ref. [36]
Jarzynski, C. xii, 101, 111, 127, 171.
Refs. [31,81,82,83,108]
Joanny, J.-F. 206. Ref. [109]
Jülicher, F. 203. Refs. [117,118,128]
Jun, Y. 170, 171. Ref. [84]
Kawaguchi, K. 65. Ref. [85]
Kawai, R. 98, 100, 101. Ref. [86]
Khaymovich, I. M. 203. Ref. [156]
Khinchin, A. I. 36. Ref. [87]
Kobayashi, T. J. 203. Refs. [88,161]
Koski, J. V. 171. Refs. [89,90]
Koza, Z. 158. Ref. [91]
Kurchan, J. 101, 158, 206. Refs. [62,92,93]
Kussell, E. 203. Refs. [102,119]
Kuzovlev, Y. E. 101. Refs. [19,20,21,22]
Kwon, C. 101. Ref. [100]
Lacoste, D. 101, 147, 149, 158, 203.
Refs. [58,94,173,174]
Lambson, B. 171. Ref. [76]
Landau, L. D. 35. Ref. [95]
Landauer, R. 4, 106, 109, 112, 127. Refs. [96,97]
Large, S. J. 191, 203. Ref. [164]
Lässig, M. 203. Ref. [116]
Lau, A. W. 147, 149, 158. Ref. [94]
Lebowitz, J. L. 65, 101, 204. Refs. [16,72,98]
Lecomte, V. 158. Ref. [99]
Lee, C. F. 117, 119, 121, 128. Refs. [142]
Lee, H. K. 101. Ref. [100]
Leibler, S. 203. Ref. [102]
Leighton, R. B. 35. Ref. [54]
Lifshitz, E. M. 35. Ref. [95]
Liphardt, J. 171. Refs. [103,104]
Liu, S. 191, 203. Ref. [164]
Liverpool, T. B. 206. Ref. [109]
Lutz, E. 171. Ref. [27]
MacKay, D. J. C. 36. Ref. [105]
Maes, C. 101, 158. Refs. [106,107]
Maisi, V. F. 171. Ref. [89]
Mallick, K. 147, 149, 158. Ref. [94]
Mandal, D. 111, 127. Ref. [108]
Manosas, M. 163. Ref. [113]
Marchetti, M. C. 206. Ref. [109]
Marini Bettolo Marconi, U. 35. Ref. [110]
Matsumoto, T. 128. Ref. [155]
Mazur, P. 35. Ref. [37]
Mejía-Monasterio, C. 203. Refs. [5,6]
Menczel, P. 203. Ref. [156]
Meyer, C. D. 158, 217. Ref. [112]
Mohayaee, R. 203. Ref. [5]
Morriss, G. P. 100. Ref. [51]
Mossa, A. 163. Ref. [113]
Mukamel, S. 206. Ref. [49]
Muneyuki, E. 168, 171. Ref. [169]
Murashita, Y. 203. Refs. [114,115]
Muratore-Ginanneschi, P. 203. Refs. [5,6]
Mustonen, V. 20.3 Ref. [116]
Nakayama, Y. 65. Ref. [85]
Neri, I. 203. Refs. [117,118]
Netocˇný, K. 158. Ref. [107]
Nozoe, T. 203. Ref. [119]
Øksendal, B. 35. Ref. [130]
Onoa, B. 171. Ref. [104]
Onsager, L. 101. Refs. [121,122]
Oono, Y. 101. Ref. [123]
Palatella, L. 205. Ref. [52]
Paniconi, M. 101. Ref. [103]
Park, H. 101. Ref. [100]
Parrondo, J. 98, 100, 101 128. Refs. [86,124]
Peliti, L. 35, 158. Refs. [62,125]
Peltonen, J. T. 203. Ref. [156]
Penrose, O. 167, 171. Ref. [126]
Perunov, N. 202, 229. Ref. [69]
Petrosyan, A. 171. Ref. [27]
Pietzonka, P. 202. Ref. [127]
Pigolotti, S. 65, 127, 128, 203, 205.
Refs. [52,118,128,129,133,143,144]
Pippard, A. B. 35. Ref. [130]
Pitaevskii, L. P. 35. Ref. [95]
Polettini, M. 202. Ref. [131]
Press, W. H. 220. Ref. [132]
Prost, J. 206. Ref. [109]
Puglisi, A. 35, 65. Refs. [110,133]
Qian, H. 65. Ref. [134]
Ramaswamy, S. 206. Ref. [109]
Rao, M. 206. Ref. [109]
Rao, R. 65, 101. Refs. [135,136,137]
Redner, S. 35. Ref. [138]
Risken, H. 35. Ref. [139]
Ritort, F. 163, 171. Refs. [31,113]
Roldán, É. 203. Refs. [117,118,156]
Rondoni, L. 35, 67, 205. Refs. [52,110,133]
Rotskoﬀ, G. M. 65, 202. Refs. [70,71]

Author Index
243
Sagawa, T. 127, 168, 171. Refs. [90,124,140,155,169]
Saito, K. 202, 203. Refs. [141,156]
Sands, M. 35. Ref. [54]
Sano, M. 168, 171. Ref. [169]
Sartori, P. 117, 119, 121, 127, 128, 204.
Refs. [72,142,143,144]
Sasa, S. 101, 202. Refs. [39,40,75]
Schmiedl, T. 203. Ref. [145]
Schnakenberg, J. 65. Ref. [146]
Schuler, S. 49. Ref. [147]
Schütz, G. M. 101. Ref. [73]
Seifert, U. 49, 65, 101, 128, 202, 203.
Refs. [7,8,9,127,145,147,148,149,150,166]
Sekimoto, K. 2, 64, 65. Refs. [151,152,153]
Shannon, C. E. 35. Ref. [154]
Shiraishi, N. 128. Ref. [155]
Simha, R. A. 206. Ref. [109]
Singh, S. 203. Ref. [156]
Sivak, D. A. 203. Ref. [157]
Smith, S. B. 171. Ref. [31]
Speck, T. 49, 91, 101. Refs. [147,158,166]
Spinney, R. E. 101. Ref. [159]
Spohn, H. 101. Ref. [98]
Sughiyama, Y. 203. Refs. [88,161]
Szilard, L. 104, 106, 127. Refs. [162,162]
Tafoya, S. 191, 203. Ref. [164]
Tailleur, J. 158. Ref. [99]
Teukolsky, S. A. 220. Ref. [132]
Thomas, J. A. 35. Ref. [32]
Tietz, C. 49. Refs. [147,166]
Tinoco, I. 171. Refs. [31,103,104]
Tizón-Escamilla, N. 158. Ref. [167]
Touchette, H. 158. Refs. [30,168]
Toyabe, S. 168, 171. Ref. [169]
Tsumura, K. 203. Ref. [161]
Ueda, M. 110, 127, 168, 171, 203.
Refs. [114,115,140,169]
Vaikuntanathan, S. 202. Ref. [71]
Van den Broeck, C. 98, 100, 101, 174, 202.
Refs. [50,86,170,172,175]
van Kampen, N. G. 35. Ref. [171]
Van Vu, T. 202. Ref. [74]
Varadhan, S. S. R. 158
Verley, G. 101, 174, 202. Refs. [131,172,173,174,175]
Vetterling, W. T. 220. Ref. [132]
Vulpiani, A. 35, 65, 205. Refs. [52,110,129,133]
Wakamoto, Y. 203. Ref. [119]
Willaert, T. 174, 202. Refs. [172,175]
Wolpert, D. H. 128. Ref. [176]
Wrachtrup, J. 49. Ref. [147]
Zeitouni, O. 158. Ref. [42]


Index
absorbing state, 186
acceptance ratio, 164
action, 86, 87, 225
active matter, 206
activity, 116
adiabatic elimination, 58, 59
aﬃnity, 53, 55, 76, 138, 148
Ampère principle, 84
ancestral distribution, 202
anti-Ito convention, 87, 88
Arrhenius law, 59
asymmetric simple exclusion process, 153
ATP, 134, 146–149
ATP hydrolysis, 40, 44, 149
auxiliary process, 156
backward protocol, 68, 77, 87, 162, 165, 166,
185, 227
Bayes formula, 213, 214
Bennett-Crooks estimator, 226
binomial distribution, 130, 131, 213
bit, 33, 106, 110, 112, 123
Boltzmann distribution, 24, 42, 94
Boltzmann-Einstein principle, 18, 74
boundary condition, 28
Bromwich integral, 215
Brownian motion, 2, 26, 89, 92, 167, 190, 220
Cauchy-Schwarz inequality, 177, 188, 228
central limit theorem, 130–132, 216
chain rule, 34; mutual information, 35, 117
Chapman-Kolmogorov equation, 20, 220, 221
chemical potential, 14, 16, 46
chemical reaction, 53; binary, 54; one-body, 54
chemostat, 46
chord, 52, 147, 224
clone, 151, 153; genetics, 198
cloning, 151, 202
coarse graining, 2, 38, 58–61
coeﬃcient of variation, 176
contraction principle, 154, 173, 231
convexity, 33, 134, 207, 208, 210
core network, 52, 224
correlation function, 57, 189, 190
Crame´r function, see rate function 132
Crooks relation, 79, 81, 88, 97, 161, 164
cumulant, 216; scaled, 141
current, 151, 157, 176, 179, 181; empirical, 135
cut, 225
cycle, 24, 52; fundamental, 52, 75, 138, 139, 148, 224
decimation, 58
de Donder relation, 55
detailed balance, 23, 28, 39, 40, 42, 48, 51, 56, 59, 69,
82, 116; generalized, 40, 46, 47, 50, 53, 54, 69, 111,
113, 127, 143, 147, 150
detailed balance relation, 122
device, 107
diﬀusion, 28; rotational, 167
diﬀusion coeﬃcient, 27, 31, 221
diﬀusion equation, 27
discrimination (kinetic and energetic), 115
dissipation length, 188
distance, 135
DNA hairpin, 190
Doob stopping theorem, 192
dragged particle, 71
drif, 27, 28, 221
driving, 39, 41, 42, 44, 47, 70, 75, 82, 113, 114
dud, 112, 149
dwell, 24, 50
dwell time; empirical, 135
edge, 23, 51, 75
eﬀective rate, 59
eﬃciency, 12, 172, 180; Carnot, 12, 172, 174;
stochastic, 172, 173, 175; thermal, 12; thermal
Carnot, 12, 172
Einstein relation, 62, 89, 92, 226
empirical mean, 215, 227
empirical stationarity, 155
empirical vector, 154
ensemble, 47, 107, 205; canonical, 16, 39; grand
canonical, 18; microcanonical, 15, 19

246
Index
entropy; Boltzmann, 205; conditional, 34, 120; Gibbs,
205; joint, 34; nonequilibrium, 47; relative, 33;
Shannon, 33, 34, 47, 105, 107, 123, 168; stochastic,
47, 49, 67; thermodynamic, 8, 106
entropy production, 69, 73, 77, 80, 82, 110, 124, 134,
135, 137, 138, 172, 176, 177, 185; adiabatic, 82, 84,
121; inﬁmum, 194; negative, 70; nonadiabatic, 82,
84, 121
entropy production rate, 51, 53, 60, 61, 64, 114,
137, 149, 173, 179, 183, 195, 231; empirical, 137,
175
equilibrium distribution, 23, 79, 82
eraser, 112, 124, 170
error probability, 114
escape rate; tilted, 151
extensivity, 9
feedback, 122, 123, 126
feedback control, 109, 110, 167, 168
ﬁrst law; stochastic, 42, 79; thermodynamic, 42–44
ﬁrst-passage time, 181, 182
ﬁtness, 197, 199; landscape, 199
ﬁxed-point theorem, 219
ﬂuctuation-dissipation relation, 17, 57, 73, 137
ﬂuctuation relation, 1, 4, 67, 71, 83, 87, 88, 109, 121,
125, 199; detailed, 76, 77, 79, 175, 226; asymptotic,
137, 146; integral, 70, 72, 79, 84, 110, 125, 137;
stopping time, 193
Fokker-Planck equation, 26, 27, 30, 31, 62, 89, 221,
223; detailed balance condition, 28; stationary
solution, 28
free energy, 4, 16, 19, 43, 44, 55, 59, 95, 160–162, 164,
166, 226; Gibbs, 14; nonequilibrium, 14, 19, 106,
107, 109, 120
frequency; empirical, 135
fundamental postulate, 15
Gallavotti-Cohen symmetry, 138, 139, 145, 150, 175,
183
Gärtner-Ellis theorem, 133, 137, 174, 201
generalized friction coeﬃcient, 187, 189, 190
generating function, 89, 151, 214–216; conditioned,
140; cumulant, 90, 91, 133, 149, 216 ; scaled, 138;
scaled cumulant, 133, 141, 152, 154, 175, 182–184,
201
generator, 20, 25
Gibbs free energy, 143
Gibbs relation, 33, 106
Gillespie algorithm, 24, 219
Green function, 21
Hamiltonian, 92
Hatano-Sasa relation, 84
heat; calorimetric, 43; excess, 82; housekeeping, 82;
mesoscopic, 43; stochastic, 41, 42, 44, 48, 63, 67, 69,
134
heat engine, 11
heat reservoir, 42, 48, 50, 106
hydrolysis, 75
hysteresis, 162
ideal gas, 10, 16; equation of state, 10; internal energy,
10
implicit function theorem, 141
inﬁmum law, 194
inﬂow, 22
information copying, 112
information engine, 111, 115
information theory, 4, 104
involution, 76, 77, 79, 175
irreversibility, 3, 67; absolute, 186; full, 186; logical,
106
irreversibility relation, 88, 93
isomerization, 54
Ito convention, 30–32, 63, 64, 87, 88, 195, 222, 223
Ito formula, 32, 196, 223
Jarzynski equality, 79–81, 83, 88, 90, 96, 161, 162, 164,
185; modiﬁed, 186
Jensen inequality, 33, 70, 177, 207, 209, 210
jump, 24, 51
jump frequency; empirical, 155
jump network, 22, 45, 51, 71, 75, 147, 217, 224
jump rate, 21, 38, 39, 51; conjugate, 83; empirical, 155;
intrinsic, 39; tilted, 151
kinesin, 146, 147, 180
kinetic coeﬃcients, 75, 139
kinetic theory, 3
Kirchhoﬀ’s law, 51
Kolmogorov equation; backward, 28, 221; forward, 27
Kramers equation, 92
Kullback-Leibler divergence, 33, 97, 107, 120, 124, 210
Landauer bound, 4, 106, 109, 169, 170
Landauer limit, see Landauer bound 106
Landauer principle, 106, 107, 112, 167
Langevin equation, 29, 30, 62, 86, 87, 89, 93, 190, 222,
223, 225
large deviations, 3, 4, 132; catalysis rate, 144; levels,
154
large deviation principle, 132, 137, 156, 182; level 2.5,
155
Legendre transform, 13, 175; variational principle, 14
Legendre-Fenchel transform, 134, 201
lineage, 198
linear response, 56, 57, 70, 189
Liouville theorem, 96
logsum inequality, 62, 210
loop, 138
Loschmidt paradox, 3
magnetic ﬁeld, 93
Mandal-Jarzynski model, 110, 111, 115, 122
manipulation, 39, 41, 42, 60, 67, 80, 82, 91, 109, 167,
168, 170, 188, 190

Index
247
marginal, 108, 213, 214
marginal distribution, 34
Markov chain, 218
Markov process, 19, 155
martingale, 191–193, 196
mass action law, 53
master equation, 21, 22, 24, 38, 51, 54, 143, 155, 176,
217, 219; conjugate, 83; tilted, 140
Maxwell demon, 4, 104, 107, 111, 112, 167, 168
Maxwell relations, 13, 18
measurement, 106, 108–110, 167
memory, 116
mesoscopic system, 1, 3, 38
mesostate, 38, 42, 43, 60
metric, 188
Michaelis-Menten scheme, 142
microstate, 15, 33, 43
mobility, 62, 190
molecular motor, 44, 146, 149, 172, 180, 181
Moran model, 198
multiplicative noise, 30
mutual information, 34, 110, 117, 118, 123, 126;
conditional, 35, 118; stochastic, 110
myosin, 44
Newton equation, 92
noise-induced drif, 32
nonequilibrium steady state, 24, 51, 74, 77, 82,
121, 122, 137, 138, 148, 149, 176, 193, 196, 229
object, 107
observable, 15, 17; dynamic, 135; extensive, 9, 130,
134; intensive, 130, 134; static, 134, 152
Onsager reciprocity relations, 74, 139
optical tweezers, 1, 39, 160
optimal protocol, 187
outﬂow, 22
partition function, 16; grand canonical, 18
path, 188; geodesic, 189
Perron-Frobenius theorem, 141
phase-space distribution, 97
phenotype switch, 200, 201
Poisson distribution, 81, 213, 217
population genetics, 197
probability; survival, 186
probability current, 23, 28, 51, 62
probability density, 213; joint, 213
probability distribution, 15, 213; conditional, 213;
joint, 213; marginal, 213
propagator, 28
protocol; backward, 67; forward, 67
quench, 80
random time, 195, 197
rate function, 131, 132, 137, 145, 157, 173–175, 179,
182, 184, 229
reservoir, 2, 18, 63; chemical, 46; heat, 1, 38, 69, 123;
information, 122, 123, 127
response function, 73
retrospective process, 202
reversibility, 3; microscopic, 23, 40, 67, 185
Riccati equation, 90
RNA hairpin, 160–163
Sagawa-Ueda relation, 110, 120, 123, 167
sampling; chronological, 198, 199, 201; retrospective,
198, 199, 201
scalar product, 224, 228, 231
Schnakenberg formula, 51, 115
second law, 8, 104; Clausius statement, 10; Kelvin-
Planck statement, 11, 106; stochastic, 70, 120;
thermodynamic, 10, 167
sensory adaptation system, 116, 120
Shannon entropy, 111, 112
spanning tree, 52, 75, 147, 148
standard deviation, 81
stationary distribution, 22, 218; instantaneous, 82
statistical state, 15, 67
stochastic calculus, 29
stochastic diﬀerential equation, 29
stochastic dynamics, 3, 19
stochastic integral, 30
stochastic process, 4, 19
stopping time, 191, 193
Stratonovich convention, 31, 32, 63, 88, 222, 223,
225
Szilard engine, 106, 107, 109, 167
tape, 110, 112, 115, 123, 126
thermal isolation, 7
thermodynamic consistency, 40, 47, 62, 67, 142
thermodynamic equilibrium, 24
thermodynamic integration, 153
thermodynamic limit, 16
tilted average, 153
tilted dynamics, 140, 144, 151; generator, 140, 141,
144, 150, 202
time reversal, 67, 68, 73, 93, 97, 138, 176; even, 84;
odd, 84
timescale separation, 2, 44
trade-oﬀ, 112
traﬃc, 135, 157, 229
trait, 197
trajectory, 4, 19, 24, 38, 41, 42, 47–49, 70, 71, 138, 156,
162, 163, 182, 185, 189, 192, 219, 225; backward, 67,
68, 73, 77, 87, 93, 126; forward, 67; phenotypic, 201;
probability, 3, 86; reversible, 185, 186
two-level system, 48
uncertainty relation, 176, 177, 181; multidimensional,
179, 181
variance, 89, 176, 216; scaled, 133, 137, 175,
177, 183

248
Index
weak linear response bound, 180,
183
weight, 151
white noise, 29
Wiener process, 29, 30, 86
work; chemical, 180; dissipated, 79, 96, 97, 188, 191;
driven, 42, 43; manipulated, 42, 43; stochastic, 41,
43, 44, 63, 67, 71, 80, 91, 95, 134
zeroth law, 7

