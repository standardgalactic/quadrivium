
Concurrency Theory

Howard Bowman and Rodolfo Gomez
Concurrency 
Theory
Calculi and Automata for Modelling Untimed and Timed
Concurrent Systems
With 126 Figures

Howard Bowman
Rodolfo Gomez
Computing Laboratory
University of Kent at Canterbury
Canterbury
Kent
UK
British Library Cataloguing in Publication Data
A catalogue record for this book is available from the British Library
Library of Congress Control Number: 2005931433
ISBN-10: 1-85233-895-4
ISBN-13: 978-1-85233-895-4
Printed on acid-free paper
© Springer-Verlag London Limited 2006
Apart from any fair dealing for the purposes of research or private study, or criticism or review,
as permitted under the Copyright, Designs and Patents Act 1988, this publication may only be
reproduced, stored or transmitted, in any form or by any means, with the prior permission in writ-
ing of the publishers, or in the case of reprographic reproduction in accordance with the terms of
licences issued by the Copyright Licensing Agency. Enquiries concerning reproduction outside
those terms should be sent to the publishers.
The use of registered names, trademarks, etc. in this publication does not imply, even in the
absence of a specific statement, that such names are exempt from the relevant laws and regulations
and therefore free for general use.
The publisher makes no representation, express or implied, with regard to the accuracy of the
information contained in this book and cannot accept any legal responsibility or liability for any
errors or omissions that may be made.
Printed in the United States of America
(MVY)
9 8 7 6 5 4 3 2 1
Springer Science+Business Media
springer.com

To our friends and families.

Preface
In the world we live in concurrency is the norm. For example, the human body
is a massively concurrent system, comprising a huge number of cells, all simul-
taneously evolving and independently engaging in their individual biological
processing. In addition, in the biological world, truly sequential systems rarely
arise. However, they are more common when manmade artefacts are consid-
ered. In particular, computer systems are often developed from a sequential
perspective. Why is this? The simple reason is that it is easier for us to think
about sequential, rather than concurrent, systems. Thus, we use sequentiality
as a device to simplify the design process.
However, the need for increasingly powerful, ﬂexible and usable computer
systems mitigates against simplifying sequentiality assumptions. A good ex-
ample of this is the all-powerful position held by the Internet, which is highly
concurrent at many diﬀerent levels of decomposition. Thus, the modern com-
puter scientist (and indeed the modern scientist in general) is forced to think
about concurrent systems and the subtle and intricate behaviour that emerges
from the interaction of simultaneously evolving components.
Over a period of 25 years, or so, the ﬁeld of concurrency theory has been
involved in the development of a set of mathematical techniques that can
help system developers to think about and build concurrent systems. These
theories are the subject matter of this book.
Our motivation in writing this book was twofold. (1) We wished to synthe-
sise into a single coherent story, a body of research that is scattered across a set
of journal and conference publications. (2) We have also sought to highlight
newer research (mainly undertaken by the authors) on concurrency theory
models of real-time systems. The ﬁrst of these aspects yields the text book
style of the ﬁrst three parts of the book, whereas the second has motivated
the approach of the fourth part, which has more of the ﬂavour of a research
monograph.
There are other books on concurrency theory, but these have tended to
have a diﬀerent focus from this book. Most relevant in this respect are classic
works by Milner on the Calculus of Communicating Systems (CCS) [148],

VIII
Preface
Hoare on ﬁrst generation Communicating Sequential Processes (CSP) [96],
Roscoe on the mature CSP theory [171] and Schneider on Timed CSP [176].
However, all of these have a tighter focus than this book, being directed at
speciﬁc theories. Although one point of major focus in this book is the process
calculus LOTOS (which, by the way, has not previously been presented in
book format), our approach is broader in scope than these earlier texts. For
example, we consider both untimed and timed approaches (in the same book),
we highlight the process calculus approach along with communicating ﬁnite
and inﬁnite state automata and we present a spectrum of diﬀerent semantic
theories, including traces, transition systems, refusals and true concurrency
models. The latter of these semantic models being particularly noteworthy,
because the bundle event structure true concurrency theory we consider is not
as well known as it should be.
Another diﬀerence with previous concurrency theory texts is that this
book is less focused on proof systems. There are a number of reasons for this.
First, proof systems are not as well behaved in LOTOS as they are in CCS
and CSP; e.g. testing equivalence is not a congruence in LOTOS. Second,
we would argue that the issue of ﬁnding complete proof systems has actually
turned out to be less important than once seemed to be the case. This is be-
cause of the development of powerful state-space exploration methods, such
as model-checking and equivalence-checking, which are not proof system de-
pendent. As a reﬂection of this trend, we also consider ﬁnite and inﬁnite state
communicating automata approaches, which have recently taken a prominent
place in concurrency theory, because of their amenability to formal veriﬁca-
tion. These techniques were not considered in the previous process calculus
texts.
Due to the breadth of scope that we have sought in this book, by necessity,
certain topics have had to be treated in less depth than would be optimum.
As just discussed, one of these is the topic of proof systems. In addition, when,
in a denotational style, we interpret recursive deﬁnitions semantically, we do
not present the full details of the ﬁxed point theories that we use. However,
at all such points in the text, we give pointers to the required deﬁnitions and
include references to complete presentations of the necessary theory.
In terms of target readership, this book is partially a textbook and partially
a research monograph. It is particularly suitable for masters and doctoral level
programmes with an emphasis on parallel processing, distributed systems,
networks, formal methods and/or concurrency in general. We assume a basic
knowledge of set theory, logic and discrete mathematics, as found in a textbook
such as [86]. However, we do include a list of notation to help the reader.
The material presented here has partially grown out of a set of course
notes used in an MSc-level course on formal methods taught in the Computing
Laboratory at the University of Kent. Consequently, we would like to thank
the students who have taken this course over a number of years. The feedback
from these students has helped these notes to be reﬁned, which has, in turn,
beneﬁted this book.

Preface
IX
We would also like to thank a number of our academic colleagues with
whom we have discussed concurrency theory and who have contributed to
the development of our understanding of this ﬁeld. We would particularly like
to mention Juan Carlos Augusto, Gordon Blair, Lynne Blair, Eerke Boiten,
Tommaso Bolognesi, Jeremy Bryans, Amanda Chetwynd, John Derrick, Gior-
gio Faconti, Holger Hermanns, Joost-Pieter Katoen, Rom Langerak, Diego
Latella, Su Li, Peter Linington, Mieke Massink, Tim Regan, Steve Schnei-
der, Marteen Steen, Ben Strulo, Simon Thompson, Stavros Tripakis and Frits
Vaandrager.
In addition, we would like to acknowledge the contribution of the follow-
ing funding bodies who have provided ﬁnancial support for our concurrency
theory research over the last ten years: the UK Engineering and Physical
Sciences Research Council, British Telecom, the European Union, under the
Marie Curie and ERCIM programmes, Universities UK, through the Overseas
Research Fund, and the Computing Laboratory at the University of Kent.
Finally, we would like to thank Catherine Drury and the Springer publish-
ing team for their eﬃciency and patience with us.
Canterbury, Kent, UK,
Howard Bowman
June 2005
Rodolfo Gomez

X
Preface
Notation
The following is an account of some symbols commonly found in this book.
Numbers
N
: the natural numbers
Z
: the integer numbers
R
: the real numbers
R+ : the positive real numbers
R+0 : the positive real numbers, including zero
Sets and Functions
|S|
: cardinality of (i.e. number of elements in) S
P(S) : powerset of S (i.e. the set of all possible sets containing elements of S)
⊆(⊂) : set inclusion (proper set inclusion)
∪() : set union (generalised union)
∩() : set intersection (generalised intersection)
\
: set diﬀerence
×
: Cartesian product: S1 × S2 × · · · × Sn = {(s1, s2, . . . , sn) | si ∈Si}
−1
: inverse relation: b R−1 a iﬀa R b
⌈
: domain restriction: given f : D →R, then f⌈S is s.t. f⌈S : D ∩S →R and
f(x) = f⌈S(x) for all x ∈D ∩S
where S, S1, S2, · · · , Sn are sets, R is a binary relation and f is a function.
Logic
∧() : conjunction (generalised conjunction)
∨() : disjunction (generalised disjunction)
¬
: negation
=⇒
: implication
⇐⇒
: double implication
∀
: universal quantiﬁcation
∃
: existential quantiﬁcation
|=
: satisﬁability relation
General Abbreviations and Acronyms
≜
: “deﬁned as”
iﬀ
: “if and only if”

Preface
XI
s.t.
: “such that”
w.r.t.
: “with respect to”
LTS
: “Labelled Transition System”
BES
: “Bundle Event Structure”
TBES
: “Timed Bundle Event Structure”
TTS
: “Timed Transition System”
CA
: “(ﬁnite state) Communicating Automata”
ISCA
: “Inﬁnite State Communicating Automata”
TA
: “Timed Automata”
DTA
: “Discrete Timed Automata”
RSL
: “Ready Simulation Logic”
HML
: “Hennessy-Milner Logic”
LOTOS : “Language of Temporal Ordering Speciﬁcation”
CCS
: “Calculus of Communicating Systems”
CSP
: “Communicating Sequential Processes”
pomset : “partially ordered multiset”
lposet
: “labelled partially ordered set”
Process Calculi (Chapters 2,3,4,5,6,9 and 10)
Sets
In LOTOS
Defs
: the set of LOTOS deﬁnitions
DefList : the set of lists of LOTOS deﬁnitions
tDeﬂist : the set of tLOTOS deﬁnition lists
PIdent
: the set of process identiﬁers
Beh
: the set of LOTOS behaviours
tBeh
: the set of tLOTOS behaviours
Der(B) : the set of behaviours that can be derived from B
Act
: the set of actions
L
: the set of actions occurring in a given speciﬁcation
A(B)
: the set of actions which arise in B
Gate
: the set of gates
SN
: the set of semantic notations
SM
: the set of semantic mappings
DEV
: the set of development relations
T
: the set of traces
A∗
: the set of traces from actions in A
Tr(S)
: the set of traces that can be derived from S
LT S
: the set of labelled transition systems
T T S
: the set of timed transition systems
RefB(σ) : the set of refusals of B after σ

XII
Preface
S(B)
: the set of (RSL) observations that B can exhibit
Ξ
: the set of time intervals
where B is a behaviour, σ is a trace and S is an LTS.
In Bundle Event Structures
BES
: the set of bundle event structures
TBES
: the set of timed bundle event structures
UE
: the universe of events
$ρ
: the set of events underlying ρ
cﬂ(ρ)
: the set of events that are disabled by some event in ρ
sat(ρ) : the set of events that have a causal predecessor in ρ
for all incoming bundles
en(ρ)
: the set of events enabled after ρ
PS(ε) : the set of proving sequences of ε
CF(ε)
: the set of conﬁgurations of ε
L(X)
: the multiset of labels of events in X
Tr st(ε) : the set of step traces of ε
LP(ε) : the set of lposets of ε
PoS(ε) : the set of pomsets of ε
where ρ is a proving sequence, ε is a BES and X is a set of events.
Relations (Functional and Nonfunctional)
In Traces and Labelled Transition Systems
J K
: a semantic map
J Ktr : the trace semantic map
J Klts : the LTS semantic map
JKtts : the TTS semantic map
≤tr
: trace preorder
≍
: equivalence
≍tr
: trace equivalence
≺
: simulation
≍≺
: simulation equivalence
≺R
: ready simulation
∼R
: ready simulation equivalence
∼
: strong bisimulation
∼t
: timed strong bisimulation
≈
: weak bisimulation (or observational) equivalence
≈c
: weak bisimulation congruence
≈t
: timed weak bisimulation
≈t
r
: timed rooted weak bisimulation

Preface
XIII
In Bundle Event Structures
J Kbe
: the BES semantic mapping
JKtbe
: the TBES semantic mapping
ψ
: a mapping from BES to LT S
∼sq
: sequential strong bisimulation
∼st
: step strong bisimulation
⪯
: the causality partial order induced by bundles
⪯C
: the causality partial order ⪯restricted to C
⊗C
: the independence relation between events w.r.t. C
≍st
: step trace equivalence
≍P oS : pomset equivalence
≍P S
: proving sequence isomorphism
≃
: the isomorphism between lposets
where C is a conﬁguration.
In Testing Theory
te (tes)
: testing equivalence (stable testing equivalence)
conf (conf s): conformance (stable conformance)
red (reds)
: reduction (stable reduction)
ext (exts)
: extension (stable extension)
Transitions
In Labelled Transition Systems
B
a
−→B′ : B evolves to B′ after a
B
σ
=⇒B′ : B evolves to B′ after σ (σ ̸= i)
B
σ
=⇒⇒⇒B′: B evolves to B′ after σ (σ = i is allowed)
B
σ
=⇒⇒B′ : B evolves to B′ after σ (σ = i is allowed but B ̸= B′)
B
a↬B′
: B evolves to B′ after a (considers undeﬁnedness)
where B, B′ are LOTOS behaviours, a is an action and σ is a trace.
In Bundle Event Structures
•a
−→
: denotes a sequential transition generated from a BES
▶A
−−→
: denotes a step transition generated from a BES

XIV
Preface
In Timed Transition Systems
B
t; B′
: B evolves to B′ after t
B
a
−→B′
: B evolves to B′ after a
s
a
−→s′ (s
t; s′) : a TTS action (time) transition
B
v
−→→B′
: B evolves to B′ after v
B
σ
=⇒⇒⇒tB′
: B evolves to B′ after σ
where B, B′ are tLOTOS behaviours, s, s′ are states, t is a delay, a is an
action, v is either an action or a delay, and σ is either a trace, an internal
action, or a delay.
Other symbols and acronyms
In LOTOS
pbLOTOS
: primitive basic LOTOS, a subset of bLOTOS
bLOTOS
: basic LOTOS, the complete language without data types
fLOTOS
: full LOTOS, the complete language with data types
i
: the internal action
δ
: the successful termination action
|||
: independent parallel composition
||
: fully synchronised parallel composition
|[ G ]|
: parallel composition with synchronisation set G
[]
: choice
;
: action preﬁx
>>
: enabling
[>
: disabling
ϵ
: the empty trace
Ω
: a LOTOS process with completely unpredictable behaviour
|=RSL
: satisﬁability under RSL
|=HML
: satisﬁability under HML
[t, t′]
: time interval (also [t, ∞), [t] and (t))
⊕
: time interval addition
⊖
: time interval subtraction
initI (a, B)
: the set of intervals where B can initially perform a
initI↓(A, B) : the smallest instant where B can initially perform an action in A
initI↓↑(A, B) : the smallest of the set of all maximum time points where B
can initially perform an action in A
where B is a tLOTOS behaviour, a is an action and A is a set of actions.

Preface
XV
In Bundle Event Structures
E
: the set of events of a given BES
#
: the set of conﬂicts of a given BES
→
: the set of bundles of a given BES
l
: the labelling function of a given BES
ε[C]
: the remainder of ε after C
C
: the lposet corresponding to C
[C]≃
: the pomset corresponding to the lposet C
A
: the event-timing function
R
: the bundle-timing function
init(Ψ) : the set of initial events of Ψ
exit(Ψ) : the set of successful termination events of Ψ
res(Ψ) : the events of Ψ whose timing is restricted
rin(Ψ) : the set of initial and time restricted events of Ψ
X
I→e : a timed bundle
Z(σ, e) : the set of instants where (enabled event) e could happen, after σ
where ε is a BES, C is a conﬁguration, Ψ is a TBES, X is a set of events, I
is a time interval, e is an event and σ is a timed proving sequence.
Automata (Chapters 8, 11, 12 and 13)
Sets
In Communicating Automata, Timed Automata and Timed Automata with
Deadlines
Act
: the set of action labels
CAct
: the set of labels for completed actions
HAct
: the set of labels for half actions
CommsAut : the set of product automata (CA)
TA
: the set of timed automata
L
: the set of locations in a given automaton
TL
: the set of transition labels of a given automaton
T
: the transition relation of a given automaton
C
: the set of clocks
CC
: the set of clock constraints
C
: the set of clocks of a given automaton
CC C
: the set of clock constraints restricted to clocks in C
Clocks(φ)
: the set of clocks occurring in the constraint φ
V
: the space of clock valuations
VC
: the space of valuations restricted to clocks in C
Runs(A)
: the set of runs of A
ZRuns(A) : the set of zeno runs of A

XVI
Preface
Loops(A)
: the set of loops in A
Loc(lp)
: the set of locations of lp
Clocks(lp)
: the set of clocks occurring in any invariant of lp
Trans(lp)
: the set of transitions of lp
Guards(lp) : the set of guards of lp
Resets(lp)
: the set of clocks reset in lp
Act(lp)
: the set of transition labels in lp
HL(|A)
: the set of pairs of matching half loops in |A
CL(|A)
: the set of completed loops in |A
Esc(lp)
: the set of escape transitions of lp
where A is an automaton, |A is a network of automata and lp is a loop.
In Inﬁnite State Communicating Automata, Discrete Timed Automata and
Fair Transition Systems
A
: the set of actions of a given automaton
COMP(A) : the set of completed actions in A
IN (A)
: the set of input actions in A
OUT(A)
: the set of output actions in A
V
: the set of variables in a given automaton or fair transition system
V ′(e)
: the set of variables modiﬁed by eﬀect e
VL
: the set of local variables of a given automaton
VS
: the set of shared variables of a given automata network
Θ
: the initialisation formula
ΘL
: the initialisation formula for variables in VL
ΘS
: the initialisation formula for variables in VS
Transitions
In Communicating Automata, Timed Automata and Timed Automata with
Deadlines
l
a
−→l′
: a CA transition
s
a
−→s′
: an LTS transition
l
a,g,r
−−−−→l′
: a TA transition
l
a,g,d,r
−−−−−→l′ : a TAD transition
s
γ
−→→s′
: a TTS transition from s to s′
where l, l′ are automata locations, s, s′ are states, γ is either an action or a
delay, a is an action label, g is a guard, r is a reset set and d is a deadline.

Preface
XVII
Relations
∆1 : the mapping from product automata (CA) to pbLOTOS speciﬁcations
∆2 : a mapping from product automata (CA) to CCS CAct speciﬁcations
Other Symbols and Acronyms
CCS CAct
: a CCS variant with completed actions
|A
: a network of automata
⟨u1, . . . , un⟩: a location vector
u[l →j]
: substitution of locations (the jth component in u, by location l)
\CAct
: the CCS CAct restriction operator
ΠCAct
: the CCS CAct parallel composition operator
EV
: an expression on variables in V
JvKs (JEV Ks) : the value of variable v (expression EV ) in state s
l0
: the initial location of a given automaton
I(l)
: the invariant of l, where l is a location of a given TA
[l, v]
: a state with location l and valuation v
(l, Z)
: a symbolic state with location l and zone Z
r(Z)
: reset of zone Z w.r.t. reset set r
Z↑
: forward projection of zone Z
norm(Z)
: normalisation of zone Z

Contents
Part I Introduction
1
Background on Concurrency Theory . . . . . . . . . . . . . . . . . . . . . . .
3
1.1
Concurrency Is Everywhere . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.2
Characteristics of Concurrent Systems . . . . . . . . . . . . . . . . . . . . .
4
1.3
Classes of Concurrent Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.3.1
Basic Event Ordering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.3.2
Timing Axis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
1.3.3
Probabilistic Choice Axis . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
1.3.4
Mobility Axis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
1.4
Mathematical Theories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
1.5
Overview of Book . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
Part II Concurrency Theory – Untimed Models
2
Process Calculi: LOTOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
2.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
2.2
Example Speciﬁcations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
2.2.1
A Communication Protocol . . . . . . . . . . . . . . . . . . . . . . . . . 20
2.2.2
The Dining Philosophers . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
2.3
Primitive Basic LOTOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
2.3.1
Abstract Actions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
2.3.2
Action Preﬁx . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
2.3.3
Choice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
2.3.4
Nondeterminism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
2.3.5
Process Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
2.3.6
Concurrency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
2.3.7
Sequential Composition and Exit . . . . . . . . . . . . . . . . . . . . 47
2.3.8
Syntax of pbLOTOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
2.4
Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52

XX
Contents
3
Basic Interleaved Semantic Models . . . . . . . . . . . . . . . . . . . . . . . . 55
3.1
A General Perspective on Semantics . . . . . . . . . . . . . . . . . . . . . . . 55
3.1.1
Why Semantics? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
3.1.2
Formal Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
3.1.3
Modelling Recursion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
3.1.4
What Makes a Good Semantics? . . . . . . . . . . . . . . . . . . . . 63
3.2
Trace Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
3.2.1
The Basic Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
3.2.2
Formal Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
3.2.3
Development Relations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
3.2.4
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
3.3
Labelled Transition Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
3.3.1
The Basic Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
3.3.2
Formal Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
3.3.3
Development Relations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
3.4
Veriﬁcation Tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
3.4.1
Overview of CADP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
3.4.2
Bisimulation Checking in CADP . . . . . . . . . . . . . . . . . . . . 103
4
True Concurrency Models: Event Structures . . . . . . . . . . . . . . . 105
4.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
4.2
The Basic Approach – Event Structures . . . . . . . . . . . . . . . . . . . . 107
4.3
Event Structures and pbLOTOS. . . . . . . . . . . . . . . . . . . . . . . . . . . 112
4.4
An Event Structures Semantics for pbLOTOS . . . . . . . . . . . . . . . 115
4.5
Relating Event Structures to Labelled Transition Systems . . . . 123
4.6
Development Relations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
4.7
Alternative Event Structure Models . . . . . . . . . . . . . . . . . . . . . . . . 134
4.8
Summary and Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
5
Testing Theory and the Linear Time – Branching Time
Spectrum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
5.1
Trace-refusals Semantics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
5.1.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
5.1.2
The Basic Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
5.1.3
Deriving Trace-refusal Pairs . . . . . . . . . . . . . . . . . . . . . . . . 145
5.1.4
Internal Behaviour . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
5.1.5
Development Relations: Equivalences . . . . . . . . . . . . . . . . 152
5.1.6
Nonequivalence Development Relations. . . . . . . . . . . . . . . 154
5.1.7
Explorations of Congruence . . . . . . . . . . . . . . . . . . . . . . . . . 158
5.1.8
Summary and Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
5.2
Testing Justiﬁcation for Trace-refusals Semantics . . . . . . . . . . . . 160
5.3
Testing Theory in General and the Linear Time – Branching
Time Spectrum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
5.3.1
Sequence-based Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
5.3.2
Tree-based Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163

Contents
XXI
5.4
Applications of Trace-refusals Relations in Distributed Systems166
5.4.1
Relating OO Concepts to LOTOS . . . . . . . . . . . . . . . . . . . 166
5.4.2
Behavioural Subtyping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
5.4.3
Viewpoints and Consistency . . . . . . . . . . . . . . . . . . . . . . . . 177
Part III Concurrency Theory – Further Untimed Notations
6
Beyond pbLOTOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
6.1
Basic LOTOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
6.1.1
Disabling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
6.1.2
Generalised Choice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188
6.1.3
Generalised Parallelism . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
6.1.4
Verbose Speciﬁcation Syntax . . . . . . . . . . . . . . . . . . . . . . . . 190
6.1.5
Verbose Process Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
6.1.6
Syntax of bLOTOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
6.2
Full LOTOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192
6.2.1
Guarded Choice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
6.2.2
Speciﬁcation Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
6.2.3
Process Deﬁnition and Invocation . . . . . . . . . . . . . . . . . . . 194
6.2.4
Value Passing Actions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194
6.2.5
Local Deﬁnitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
6.2.6
Selection Predicates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202
6.2.7
Generalised Choice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
6.2.8
Parameterised Enabling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204
6.2.9
Syntax of fLOTOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
6.2.10 Comments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
6.3
Examples. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
6.3.1
Communication Protocol . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
6.3.2
Dining Philosophers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
6.4
Extended LOTOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213
7
Comparison of LOTOS with CCS and CSP . . . . . . . . . . . . . . . . 215
7.1
CCS and LOTOS. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
7.1.1
Parallel Composition and Complementation of Actions . 217
7.1.2
Restriction and Hiding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
7.1.3
Internal Behaviour . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221
7.1.4
Minor Diﬀerences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221
7.2
CSP and LOTOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222
7.2.1
Alphabets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222
7.2.2
Internal Actions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224
7.2.3
Choice . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
7.2.4
Parallelism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227
7.2.5
Hiding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227

XXII
Contents
7.2.6
Comparison of LOTOS Trace-refusals with CSP
Failures-divergences. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228
8
Communicating Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233
8.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233
8.2
Networks of Communicating Automata . . . . . . . . . . . . . . . . . . . . . 234
8.2.1
Component Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234
8.2.2
Parallel Composition. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 236
8.2.3
Example Speciﬁcations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
8.2.4
Semantics and Development Relations . . . . . . . . . . . . . . . 240
8.2.5
Veriﬁcation of Networks of Communicating Automata. . 241
8.2.6
Relationship to Process Calculi. . . . . . . . . . . . . . . . . . . . . . 246
8.3
Inﬁnite State Communicating Automata . . . . . . . . . . . . . . . . . . . 250
8.3.1
Networks of Inﬁnite State Communicating Automata . . 251
8.3.2
Semantics of ISCAs as Labelled Transition Systems . . . . 254
Part IV Concurrency Theory – Timed Models
9
Timed Process Calculi, a LOTOS Perspective. . . . . . . . . . . . . . 261
9.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
9.2
Timed LOTOS – The Issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
9.2.1
Timed Action Enabling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
9.2.2
Urgency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267
9.2.3
Persistency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270
9.2.4
Nondeterminism . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271
9.2.5
Synchronisation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
9.2.6
Timing Domains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
9.2.7
Time Measurement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
9.2.8
Timing of Nonadjacent Actions . . . . . . . . . . . . . . . . . . . . . 274
9.2.9
Timed Interaction Policies . . . . . . . . . . . . . . . . . . . . . . . . . . 275
9.2.10 Forms of Internal Urgency . . . . . . . . . . . . . . . . . . . . . . . . . . 276
9.2.11 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278
9.3
Timed LOTOS Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278
9.3.1
The Language . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278
9.3.2
Example Speciﬁcations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281
9.4
Timing Anomalies in tLOTOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
9.5
E-LOTOS, the Timing Extensions . . . . . . . . . . . . . . . . . . . . . . . . . 285
10
Semantic Models for tLOTOS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287
10.1 Branching Time Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287
10.1.1 Timed Transition Systems . . . . . . . . . . . . . . . . . . . . . . . . . . 287
10.1.2 Operational Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289
10.1.3 Branching Time Development Relations . . . . . . . . . . . . . . 299
10.2 True Concurrency Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304

Contents
XXIII
10.2.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304
10.2.2 Timed Bundle Event Structures . . . . . . . . . . . . . . . . . . . . . 305
10.2.3 Causal Semantics for tLOTOS . . . . . . . . . . . . . . . . . . . . . . 308
10.2.4 Anomalous Behaviour . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 318
10.2.5 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 320
11
Timed Communicating Automata . . . . . . . . . . . . . . . . . . . . . . . . . 321
11.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321
11.2 Timed Automata – Formal Deﬁnitions . . . . . . . . . . . . . . . . . . . . . 323
11.2.1 Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324
11.2.2 Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325
11.3 Real-time Model-checking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332
11.3.1 Forward Reachability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 333
11.3.2 Example: Reachability Analysis on the Multimedia
Stream . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341
11.3.3 Issues in Real-time Model-checking . . . . . . . . . . . . . . . . . . 342
12
Timelocks in Timed Automata. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347
12.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347
12.2 A Classiﬁcation of Deadlocks in Timed Automata . . . . . . . . . . . 349
12.2.1 Discussion: Justifying the Classiﬁcation of Deadlocks. . . 350
12.2.2 Discussion: Timelocks in Process Calculi . . . . . . . . . . . . . 351
12.3 Time-actionlocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352
12.3.1 Timed Automata with Deadlines . . . . . . . . . . . . . . . . . . . . 353
12.3.2 Example: A TAD Speciﬁcation for the Multimedia
Stream . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 358
12.4 Zeno-timelocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 359
12.4.1 Example: Zeno-timelocks in the Multimedia Stream. . . . 359
12.4.2 Nonzenoness: Syntactic Conditions . . . . . . . . . . . . . . . . . . 361
12.4.3 Nonzenoness: A Suﬃcient-and-Necessary Condition . . . . 368
12.5 Timelock Detection in Real-time Model-checkers . . . . . . . . . . . . 374
12.5.1 Uppaal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 374
12.5.2 Kronos . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 376
13
Discrete Timed Automata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 377
13.1 Inﬁnite vs. Finite States . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 377
13.2 Preliminaries. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 380
13.2.1 Fair Transition Systems and Invariance Proofs . . . . . . . . 381
13.2.2 The Weak Monadic Second-order Theory of 1
Successor (WS1S) and MONA . . . . . . . . . . . . . . . . . . . . . . 383
13.3 Discrete Timed Automata – Formal deﬁnitions . . . . . . . . . . . . . . 384
13.3.1 Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 384
13.3.2 Example: A DTA Speciﬁcation for the Multimedia
Stream . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 386
13.3.3 Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 387

XXIV
Contents
13.4 Verifying Safety Properties over DTAs . . . . . . . . . . . . . . . . . . . . . 389
13.5 Discussion: Comparing DTAs and TIOAs with Urgency . . . . . . 394
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397
Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 409
14.1 Enabling as a Derived Operator . . . . . . . . . . . . . . . . . . . . . . . . . . . 409
14.2 Strong Bisimulation Is a Congruence . . . . . . . . . . . . . . . . . . . . . . . 409
14.3 Weak Bisimulation Congruence. . . . . . . . . . . . . . . . . . . . . . . . . . . . 414
14.4 Timed Enabling as a Derived Operator . . . . . . . . . . . . . . . . . . . . . 419
14.5 Hiding is Not Substitutive for Timed Bisimulations . . . . . . . . . . 420
14.6 Substitutivity of Timed Strong Bisimulation . . . . . . . . . . . . . . . . 420
14.7 Substitutivity of Timed Rooted Weak Bisimulation . . . . . . . . . . 422
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 429

Part I
Introduction

1
Background on Concurrency Theory
1.1 Concurrency Is Everywhere
There are two main axes to mathematical research,
1. Reﬁning and building upon existing mathematical theories, e.g. trying to
prove or disprove the remaining conjectures in well explored branches of
mathematics (Andrew Wiles’s proof of Fermat’s Last Theorem is such an
eﬀort [179]), and
2. Developing mathematical theories for new areas of interest.
The mathematical theory of concurrency is an example of the latter. Although
concurrent systems are ubiquitous in our world, no mathematical theory of
concurrent systems existed until the pioneering work of Carl Petri in the
1960s [161,169] and the ﬁeld did not really come to maturity until the 1980s.
Thus, in terms of the history of mathematics, the area of concurrency can
ﬁrmly be considered to be new.
With what then is the area concerned? For want of a better deﬁnition, we
give the following.
Concurrency theory concerns itself with the development of mathe-
matical accounts of the behaviour of systems containing a number of
components, each of which evolves simultaneously with the others,
subject to (typically frequent) interaction amongst the components.
The ubiquity of concurrent systems should be clear. In fact, although concur-
rency theory was inspired by the needs of designers and developers of com-
puter systems, where critical advances (such as the construction of reliable
communication networks) were aided by its deﬁnition, concurrency is every-
where in our world: all entities, whether they be plants, animals, machines,
or whatever, execute in parallel with one another.
To take a familiar example, a car engine is a concurrent machine: spark
plugs spark in parallel, pistons ﬁre in parallel, wheels turn in parallel and

4
1 Background on Concurrency Theory
engine components run simultaneously. Also, driving a car is a concurrent
process: we seamlessly adjust our steering, change gear and maintain a con-
versation in a coordinated stream of parallel activity.
Furthermore, the concurrent nature of the world we inhabit is reﬂected
by the multimodal nature of our sensory and eﬀector systems: tactile, visual,
acoustic and olfactory (smell) sensations are simultaneously relayed to and
processed by the brain. Indeed, in the brain, all levels of cognitive activity have
a concurrent element. For example, at the lower levels of cognitive processing,
neurons evolve concurrently, and so do the neural circuits that are built from
them.
In fact, our world can be seen to be fundamentally concurrent and we
would argue that it is best to view concurrency as the norm, rather than
the exception. As a reﬂection of this, we would further argue that sequential
systems are best viewed as a special case of concurrent systems and this is
what we do in this book. It is just the history of the development of computer
science, where it was initially easier to work with sequential paradigms, that
led to the historical over-emphasis on sequential systems.
1.2 Characteristics of Concurrent Systems
Three particularly important characteristics of concurrent systems are:
1. Interaction – components interact with one another;
2. Nontransformational – the ongoing behaviour is critical; and
3. Unbounded Execution – placing an upper bound on the execution time
of the system is typically inappropriate.
The conjunction of these characteristics yields a class of systems that is closely
related to what Manna and Pnueli call reactive systems [136]. However, we
do not explicity use this term here.
We consider each of the above three characteristics in turn.
1. Interaction
It is possible that components evolve both in parallel and completely inde-
pendently of one another; that is, they do not interact. However, this sce-
nario is not very interesting as it implies that components are completely
isolated from one another: in order to generate sophisticated behaviour,
components must communicate. Indeed the richness of concurrent systems
can be seen to arise from interaction.
Many diﬀerent interaction mechanisms have been considered, e.g. asyn-
chronous communication [56], synchronous communication [148] and by
shared memory [136]. In this book, we use a particular variety of syn-
chronous (message passing) communication. One reason for choosing this
model of interaction is that it can be shown to be primitive in the sense

1.2 Characteristics of Concurrent Systems
5
that other forms of interaction can be built out of it (see, for example, the
spectrum of buﬀer implementations deﬁned in CSP [171]).
Furthermore, we wish to allow the possibility that control is distributed.
That is that, unless explicitly required, components are autonomous and
there is no centralised controller or repository at which the global state of
the system is recorded. Approaches that employ a shared memory, through
which components interact, typically contradict this characteristic and
concurrently evolving components do have access to a global view of the
state of the entire system.
2. Nontransformational
The early years of computer science research were focused on what we
can broadly call transformational systems. These are systems that can
be viewed as input to output transformers: input is presented to the sys-
tem, the system executes according to this input and then the system
terminates and outputs its results.
However, concurrent systems are not transformational because compo-
nents evolve in parallel with their environment (whereas in transforma-
tional systems, there is a sequential relationship between system and envi-
ronment) [136]. Thus, the key concern with nontransformational systems
is not deﬁning functions, which characterise input to output behaviour,
rather it is describing the “ongoing” behaviour of systems and what series
of interactions they can perform.
In fact, some prominent researchers, e.g. Peter Wegner [197], have sug-
gested that the class of concurrent systems is in computability terms more
expressive than the class of transformational systems. In other words there
exist concurrent computations that cannot be expressed by Turing ma-
chines!
3. Unbounded Execution
It is typically inappropriate to place an upper bound on the execution of
concurrent systems. Consider, for example, the Internet. This is a highly
concurrent system, however, predicting and enforcing a life span for it is
not appropriate. This is particularly true of many noncomputing concur-
rent systems such as biological and physics systems, the world itself being
one example.
As a reﬂection of these three points, an execution of a concurrent system can
be viewed as a (possibly inﬁnite1) sequence of events.2
For example, the ongoing behaviour of a person driving a car would contain
fragments such as:
..brake, depress_clutch, change_gear,
1In fact, there are diﬀerent ways to handle this potential for inﬁnite execution,
which sometimes do not imply an inﬁnite sequence, but this becomes clearer in the
body of this book.
2Here we use the term event in a nonspeciﬁc way. Later in the book it comes to
have a particular meaning.

6
1 Background on Concurrency Theory
release_clutch, accelerate..
where each of the events in this sequence would yield an interaction between
the driver and components of the car, e.g. the brake pedal.
However, you should notice that, when concurrent systems are considered,
viewing the behaviour in terms of such sequences can be problematic because
the execution of events may overlap. For example, when we drive, there may
be an overlap between the ﬁrst two events in this sequence, i.e. braking and
depressing the clutch. However, if we view events as atomic markers then
this problem does not arise. This is a central point that justiﬁes interleaved
interpretations of concurrency and we return to it in Section 2.3.6 of this book.
In addition, although for almost all this book issues of the physical distri-
bution of components are not explicitly considered (although, we discuss the
related topic of mobility very shortly, in Section 1.3.4), there is an implicit
assumption that, with the approaches we consider, components are physically
distributed. It is worth noting that distribution is closely related to the issue of
nontransformational systems. Speciﬁcally, tightly coupled concurrent systems
can often exhibit transformational behaviour, but the more loosely coupled
the components of a system, the more unlikely it is that a transformational
behaviour will emerge from the concurrent interaction of components.
1.3 Classes of Concurrent Systems
From within concurrency theory a number of diﬀerent classes of system are
considered. Typically, these focus on particular aspects of concurrency and
abstract from other aspects. We can distinguish among these classes on a
number of axes. For example, we can distinguish between the following three
axes:
1. Timing
2. Probabilistic choice
3. Mobility
First we consider the primitive class of concurrent systems that these axes
generalise. Then we discuss each of the three axes in turn.
1.3.1 Basic Event Ordering
One abstract view of concurrent systems is to model them purely in terms of
the order in which events occur. This was, for example, the approach implicitly
taken above when we wrote out the sequence of events involved in changing
gear. However, this sequence of events says nothing about the relative timing
of diﬀerent events. For example, it does not indicate how soon after depressing
the clutch we should start to change gear.

1.3 Classes of Concurrent Systems
7
Thus, all this class of system allows us to state is that events must fol-
low one another, but it makes no distinction between whether events follow
immediately or a million years after one another. As a reﬂection of this char-
acteristic, it is often said that basic event ordering allows the qualititative,
rather than the quantitative, properties of systems to be described, where
quantitative refers to timing.
We suggest that basic event ordering is the minimal level of expressiveness
required in order to specify interesting aspects of concurrent systems. It is the
focus of Parts II and III of this book.
Each of the axes that we consider in the following sections gives a path to
increasing the level of expressiveness of basic event ordering. They each gener-
alise the basic event ordering approach according to a particular characteristic
of concurrent systems.
1.3.2 Timing Axis
In order that we can deﬁne quantitative aspects of concurrent systems we
need to add ways of expressing relative timing between events. This is what
the timing axis considers.
The standard way of doing this is to add constructs that enable deter-
ministic timing to be expressed (the term deterministic is used to distinguish
this approach from the stochastic timing approach, which we discuss shortly).
There are a number of subtle issues surrounding this addition of timing prop-
erties and hence many diﬀerent approaches exist. However, all broadly provide
a means to associate timing intervals with the enabling of events; i.e. upper
and lower time bounds are placed on the interval of time in which an event
can occur.
Broadly speaking, approaches employing deterministic timing generalise
those employing basic event ordering. Ignoring some subtle issues that arise
with particular formalisms, if all events are given a timing interval of zero to
inﬁnity, then deterministically timed systems behave as if no distinction were
made between the times at which events can occur.
Part IV of this book considers how deterministic timing can be added to
techniques for describing basic event ordering.
A further class of timed system comes from allowing stochastic timing.
According to this approach, the interval of time in which an event can oc-
cur is sampled from a probability distribution function. A number of such
approaches exist, e.g. [18,93,94], most of which only allow sampling from ex-
ponential distributions. The reason for this restriction to exponential distribu-
tions is that it yields a much more tractable class of speciﬁcations. However,
if generalised distributions (which, for example, allow timings to be sampled
deterministically) are used, then stochastic models would be able to generalise
deterministically timed approaches.

8
1 Background on Concurrency Theory
1.3.3 Probabilistic Choice Axis
Another axis is generalising the choice implicit in basic event ordering to
allow probabilistic branching. When describing concurrent systems, choice
points have to be speciﬁed. For example, in our gear changing example, after
braking, we might have a choice between depressing the clutch (in order to
change gear) and accelerating away in the same gear. Informally, this could
be depicted by the branching shown in Figure 1.1.
brake
depress_clutch
accelerate
A
B
Fig. 1.1. A Choice Point
With basic event ordering, choices between diﬀerent events are either of-
fered to the environment for resolution or are resolved internally (and non-
deterministically). For example, if we view the car as the system being de-
scribed and the driver as the environment, the above choice between depress-
ing the clutch and accelerating is an external choice, which the environment
would make. However, we might wish to include the possibility that, due to
a gear box failure, the gear cannot be changed and this would be modelled
by an internal choice between the car oﬀering the change gear event and an
event lock gear box.
Models can also be devised in which probabilities are associated with
branches. Thus, in the above example, the probability of oﬀering change gear
may be 0.999 and that of lock gear box 0.001.
In fact, probabilistic approaches and stochastic approaches (as considered
in the last section) have a close relationship because sampling timings from
probability distribution functions generates a race condition on branching.
This race condition expresses the likelihood that one or other branch is likely
to happen ﬁrst, i.e. yields a form of probabilistic choice.
The main target of probabilistic branching is to give a more reﬁned non-
deterministic choice. Thus, rather than just stating that either branch could

1.4 Mathematical Theories
9
be taken internally, such approaches allow likelihoods to be associated with
these internal choices. This is important when considering failure scenarios
such as the gearbox locking example just highlighted. However, due to space
limitations, we are not able to discuss this topic further in this book.
1.3.4 Mobility Axis
In their primitive form, approaches which just describe the basic event order-
ing of systems assume a static conﬁguration of components. Thus, for exam-
ple, it is not possible to change communication paths between components (if
component A does not communicate with component B at the start of the
execution of the system, it never will), and it is not possible for components
to physically change locations.
Such mobility and dynamic reconﬁguration, though, arises frequently in
practice. For example, mobile phones and mobile computers or systems where
autonomous agents move are typical examples of such systems.
There are now a number of ways to generalise basic event ordering models
by adding mobility features, one of the most important being Milner’s π-
calculus [149]. In this book however, we do not consider such generalisations
and restrict ourselves to considering timing generalisations.
1.4 Mathematical Theories
The previous sections of this introduction have clariﬁed what we mean by
concurrency theory. However, this leaves the question of what we mean by a
mathematical theory of concurrency.
In a broad sense, our mathematical theory of concurrency has the same
ingredients as the familiar mainstream mathematical theories, such as, for
example, the theory of (counting) numbers (which is the heart of the math-
ematical discipline of number theory). We illustrate this by comparing the
ingredients of the theory of numbers with those of concurrency theory.
1. Values
These are the primitive elements in mathematical theories. They are the
basic objects that the theory is about.
The values in the theory of numbers are the integers,
. . . , –3, –2, –1, 0, 1, 2, 3, . . .
In contrast, values in concurrency theory denote the behaviour of concur-
rent systems. The event sequence that we illustrated earlier is related to
such (concurrency theory) values. However, it is not wholely accurate to
view a single trace as a value, because to characterise the behaviour of
a system requires a number of traces. This is because systems will have
choice points and thus, many traces could possibly result from a single sys-
tem. In fact, a large part of this book is concerned with the issue of what

10
1 Background on Concurrency Theory
constitute suitable values for concurrent systems and we show many dif-
ferent varieties of value: trace sets, trace-refusals sets, labelled transition
systems, event structures etc.
By way of illustration, we present an example of a labelled transition
system in Figure 1.2. Thus, nodes represent states that the system can
be in, arcs represent that an event can occur and the labelling of arcs
indicates which event occurs.
a
b
c
d
e
c
Fig. 1.2. A Labelled Transition System
One point to note is that the values in mathematical theories of computa-
tion (of which concurrency theory is a branch) are behaviours of systems:
they code the possible executions of systems. This computational aspect
of underlying mathematical objects is in contrast to standard mathemat-
ical theories, where values are static in nature. As a reﬂection of this, we
use the term behavioural values to denote the values found in concurrency
theory.
In one sense, standard mathematics typically provides a ﬁxed static view
of the world, whereas theories of computation are fundamentally dynamic,
expressing how entities can evolve. Mathematical theories of computation
must reﬂect this dynamic/behavioural aspect.
2. Variables
In the theory of numbers we use variables to symbolically denote values,
e.g. X, Y or Z. In concurrency theory we do the same. Thus, we might
denote the system that behaves as the labelled transition system in Figure
1.2 by P. In fact, we use variables to denote many diﬀerent entities, e.g.
action names (this becomes clear in the body of this book).
3. Operators
Arithmetic operators, e.g. + and ×, are used in the theory of numbers to
express how numbers can be transformed into other numbers. In concur-
rency theory we also have operators, e.g. ||| and []. The former of these

1.4 Mathematical Theories
11
denotes a particular form of parallel composition and the second a choice
between two alternatives.
4. Expressions
Arithmetical expressions can be deﬁned in the theory of numbers, e.g.
(X + 73) × 3
These are built as “allowable” combinations of variables, values and op-
erators. The same is true in concurrency theory. For example, we might
write the following expression,
(P [] Q) ||| R
which states that two components, P [] Q and R, are “run” independently
in parallel with each other, where P [] Q oﬀers a choice between behaving
as P and behaving as Q (the actual characteristics of this choice are
clariﬁed later).
Notice that, due to the nature of our values, it is not possible to “quote”
them inline in our expressions (although there are graphical notations
which do something like this, e.g. Statecharts [87]). However, eﬀectively,
we can view the variables here, P, Q and R, as standing for particular
labelled transition systems, i.e. behavioural values. In fact, once we have
more operators, we will be able to code up labelled transition systems
directly as expressions.
5. Evaluating Expressions
If we give values to all free variables in an expression we can then evaluate
it to get a (result) value. For example, if X is given the value 4, then (X +
73)×3 can be evaluated to yield 231 and the same applies to expressions in
concurrency theory. So, for example, we will be able to take an expression
such as,
(P [] Q) ||| R
and assign a labelled transition system value to it. This can be done be-
cause the deﬁnitions of the operators [] and ||| state how a (result) labelled
transition system can be built from two (argument) labelled transition sys-
tems. To be more precise, we deﬁne semantic mappings that deﬁne how
(behavioural) values can be derived from (behaviour) expressions. This
becomes clear during the next part of this book.
6. Relations
In the same way that we can deﬁne relations between values in the theory
of numbers, e.g. < or >, and hence deﬁne relations between expressions,
e.g. X +4 < X +9, we can do the same in concurrency theory. In particu-
lar, we deﬁne preorders and equivalences which characterise relationships
between concurrency theory values. For example, we deﬁne a relation ≤tr
(called trace preorder), which gives one interpretation of when a particular
system (value) is “less than or equal to” a second system (value).
7. Equality
Probably the most important relation is equality. For example, in the
theory of numbers, (X + 73) × 3 = ((X + 72) × 3) + 3. The fact that these

12
1 Background on Concurrency Theory
two expressions are equal is justiﬁed by the fact that whatever value you
plug in for X, the two expressions evaluate to the same value.
In a similar way to equality in the theory of numbers, the theory of con-
currency deﬁnes notions of equality, but this time it is between systems.
In fact, there turn out to be many diﬀerent possible notions of when two
systems are indistinguishable and this is a signiﬁcant element of the story
of this book.
As we just stated, in the theory of numbers, evaluating to the same value
is the sole justiﬁcation for viewing two expressions as equal. However, in
concurrency theory, equality between expressions is often more generous
than the equality induced by evaluating to the same behavioural value.
This means that there will be some expressions that we view as equal
(in fact, equivalent) which are not semantically mapped to the same be-
havioural value.3 One of the most important examples of such a relation-
ship is strong bisimulation equivalence. This is denoted ∼and if P ∼Q
then, broadly speaking, we can view P as strongly equivalent to Q. Once
again, this is an issue that we return to later in this book.
8. Proof Rules
One of the most powerful techniques in mathematics is to identify proof
systems. These are sets of rules about the particular mathematical the-
ory under investigation, which allow equality (or other relations) to be
demonstrated between expressions without recourse to evaluating the ex-
pressions. Thus, we can investigate the relationship between expressions at
a more “abstract”, syntactic, level. For example, in the theory of numbers
we might have a rule such as the following,
X × (1 + Y ) = X + (X × Y )
which states a general property about the relationship between multipli-
cation and addition.
We can, once again, do the same in our theory of concurrency. For example,
the following rule will turn out to hold,
a; P ||| b; Q ∼a; (P ||| b; Q) [] b; (a; P ||| Q)
which the reader should not feel must be understood at this stage. It
broadly shows how parallelism can be turned into sequence and choice
and is justiﬁed by interleaving interpretations of concurrency. Such rules
can be used to analyse systems; e.g. they can be used to determine that
two descriptions of a system are behaviourally the same.
In fact, in this book, we are not strongly focused on proof rules. This is not
because such rules cannot be devised in the domain of concurrency theory.
Indeed a number of other texts give comprehensive presentations of proof
rules for analysing concurrent systems, e.g. [148,171]. Rather, we focus on
analysis methods that the power of modern computers have made feasible.
That is, automatic veriﬁcation techniques, such as equivalence-checking
3However, a particular relationship between their behavioural values must exist.

1.5 Overview of Book
13
and model-checking. These are algorithms that undertake systematic ex-
ploration of the behaviour of a system description (i.e. its state-space).
For example, equivalence checkers can determine when two descriptions
of a system are equivalent by systematically traversing the labelled tran-
sitions arising from these descriptions, comparing what events the two
descriptions can perform at each state.
The capacity to undertake such automatic veriﬁcation arises naturally
from the mathematical theory we develop4 and is a major strength of
modern concurrency theory. It is for this reason that automatic veriﬁcation
plays an important role in our presentation.
1.5 Overview of Book
The book comprises four parts. The ﬁrst of these just contains this introduc-
tion. Then Part II presents a basic body of concurrency theory, focused on
untimed models of concurrent systems. Speciﬁcally, Chapter 2 introduces a
basic LOTOS calculus, denoted pbLOTOS. Then, in Chapters 3, 4 and 5, we
consider a spectrum of diﬀerent semantic models for this calculus. Following
this, Part III considers a set of more advanced untimed modelling notations.
Included are discussions of richer LOTOS calculi, which, in particular, have
the capacity to deﬁne a spectrum of data types, in Chapter 6; a compar-
ison with the calculi CCS and CSP in Chapter 7; and a consideration of
communicating automata approaches in Chapter 8. Finally, Part IV of the
book considers how the theory presented in previous parts of the book can be
enhanced in order to model timed concurrent systems. Chapters 9 and 10 con-
sider timed enhancements of the pbLOTOS theory developed in Part II, and
the remaining three chapters (11, 12 and 13) consider timed versions of the
communicating automata discussed in Chapter 8 and associated theoretical
issues.
4Although, we consider inﬁnite state frameworks (see the last section of Chapter
8 and the whole of Chapter 13) where automatic veriﬁcation can only be applied to
ﬁnite abstractions of full models.

Part II
Concurrency Theory – Untimed Models

17
This part contains core concurrency theory material. We present the process
calculus pbLOTOS from ﬁrst principles in Chapter 2, illustrating the approach
with a number of running examples. Then, in Chapters 3, 4 and 5, we consider
how this calculus can be interpreted semantically. In particular, we motivate
the use of semantic models in concurrency theory in Chapter 3. Then, in
the same chapter, we consider two simple semantic theories: (linear time)
trace semantics and (branching time) labelled transition system semantics.
Contrasting semantic theories are considered in Chapters 4, where we discuss
true concurrency semantics, and 5, where we focus on testing theories.

2
Process Calculi: LOTOS
2.1 Introduction
A number of notations have been developed within concurrency theory for
speciﬁcation of concurrent systems, e.g. process calculi [96, 148],1 temporal
logics [136], Petri Nets [169] and extended ﬁnite state machines [105]. We will
particularly focus on process calculi, as realised in the speciﬁcation language
LOTOS [101].
LOTOS (Language Of Temporal Ordering Speciﬁcation) was deﬁned dur-
ing the 1980’s by a standardisation committee chaired by Ed Brinksma of
the University of Twente. The most signiﬁcant inﬂuence on the design of the
language was a number of previously deﬁned process calculi, including CCS,
CSP, CIRCAL [144] and ACP [15]. From amongst this list, the two most di-
rect inﬂuences were CCS [148] and CSP [96]. In fact, the language is largely
a composite of these two previous process calculi.
The language has two main parts: a behavioural part (sometimes also
referred to as the process algebraic part) and a data part. The role of the
behavioural part is to specify the order in which actions can occur; for exam-
ple, you may specify that component B of a system receives messages from
component A and then either passes the messages on to a further component,
C, or loses the message. The data part on the other hand deﬁnes the data
types that can be used in the behavioural part. For example, a queue data
type might be deﬁned. This queue type may then be used as an input queue
by component B. Thus, when an action occurs at component B to indicate a
message has arrived, the message will be added to the queue. The data part
1We prefer the term process calculus to process algebra, because in fact, the
approach we present is not that advanced in algebraic terms. In particular, we do
not consider algebraic proof systems. Although, the reader should be aware that
the term, process algebra, is often used in the literature to describe very similar
approaches to the one we highlight.

20
2 Process Calculi: LOTOS
of LOTOS uses an abstract data typing language called ACT-ONE; see [24]
for an introduction to this notation.
A process of restandardisation has been undertaken. One particular area
of redeﬁnition is the data part, which in its original form was seen to be
very cumbersome and a hindrance to the uptake of the language. The ACT-
ONE notation has been replaced with a functional notation. We discuss these
revisions in Chapter 6.
It is quite easy though to view the behavioural and data parts as distinct.
In fact, here we are almost exclusively interested in the behavioural part. We
use the term full LOTOS (which we shorten to fLOTOS) to refer to the full
language with data types and the term basic LOTOS (which we shorten to
bLOTOS) to refer to the language without data types (i.e. just the behavioural
part). We also subdivide basic LOTOS, because the full behavioural language
contains a lot of syntax that is somewhat cumbersome to carry around when
looking at the theoretical properties of the language. Thus, our main point of
focus is a subset of bLOTOS that we call primitive basic LOTOS (which we
shorten to pbLOTOS).
The next section (Section 2.2) introduces two speciﬁcation examples that
we use to illustrate formal description in LOTOS. Then Section 2.3 introduces
pbLOTOS; and, ﬁnally, Section 2.4 presents example speciﬁcations written in
pbLOTOS.
2.2 Example Speciﬁcations
A simple communication protocol and the Dining Philosophers problem are
used as running examples. Both of these are standard examples of concurrent
behaviour and readers who are familiar with them can safely skip this section.
2.2.1 A Communication Protocol
The communication protocol comprises three main components: a sender pro-
cess, a receiver process and a medium (or channel). These components are
depicted in Figure 2.1. The speciﬁcation task here is to ﬁrstly model the be-
haviour of the medium (e.g. its ability to lose messages) and then to give sender
and receiver process speciﬁcations that support reliable communication. The
speciﬁcation will use timeouts, sequence numbering and acknowledgement in
order to do this.
The sender process obtains messages to send (also called packets or frames)
from outside the protocol system (in terms of a layered protocol model, mes-
sages to send would be obtained from a previous layer in the protocol stack).
The computation steps of the sender are: request a message from outside the
system, successfully send the message (perhaps with some retransmission)

2.2 Example Speciﬁcations
21
sender
process
receiver
process
send
receive
receiveAck
sendAck
medium
process
start
get
put
Fig. 2.1. Components in the Communication Protocol
and then request a new message. Thus, the protocol is a stop and wait pro-
tocol [187]; it waits for the current message to be successfully sent before it
requests a new message to send.
Transmission using the protocol is initiated by a request to start from
outside the protocol. The sender then obtains a message to send and sends it.
Getting a message to send is identiﬁed by an event get being performed by the
sender process with the environment and sending is identiﬁed by an event send
occurring between the sending process and the medium. The medium then
relays the message to the receiver. Successful transmissions cause an event
receive to occur at the receiver process. However, the medium may lose the
message, in which case no such event is able to occur. In addition, the receiver
sends acknowledgements through the medium (so the medium is a duplex
channel). Sending and receiving these acknowledgements are identiﬁed by the
events sendAck and receiveAck, respectively. Successfully received messages
are passed out of the system on the receiver side using the event put.
We consider two variants of this basic scenario. The ﬁrst assumes a reliable
acknowledgement medium. The second assumes that acknowledgements can
be lost. We discuss these in turn.
•
Reliable Acknowledgement. In this class of protocol, messages sent
from the sender to the receiver may be lost, but acknowledgements will
always be relayed successfully. This assumption simpliﬁes the protocol con-
siderably and avoids the necessity for sequence numbers. The sender pro-
cess will still have to set a timer when it sends a message. If the timer
expires, the message is assumed lost in transit and is resent.
•
Unreliable Acknowledgement. The second variant assumes that ac-
knowledgements may be lost. The troublesome scenario for such a protocol
is that an acknowledgement is lost, the sender times out and retransmits
the original message, which is successfully transmitted to the receiver. The
receiver will have no way of knowing that this is a retransmission and will
blindly pass it to higher layers, resulting in delivery of a duplicate message.
Stop and wait protocols, which can lose acknowledgements, typically use

22
2 Process Calculi: LOTOS
alternating bit sequence numbering in order to obtain reliable communica-
tion. A sequence number of zero or one is associated with every message.
This means that retransmissions can be distinguished from transmission
of new messages when an acknowledgement is lost, because the sequence
number of a retransmission will have the same sequence number as the
previously received message.
2.2.2 The Dining Philosophers
The Dining Philosophers scenario has been used for many years as an illustra-
tion of the problems associated with scheduling shared resources in concurrent
systems. The version of the problem that we seek to specify is given by the
following scenario.2
Four philosophers (Aristotle, Buddha, Confucius and Descartes) are
sitting around a table, which has a large plate of rice in the middle.
Philosophers alternately think and eat. To be able to eat they must
ﬁrst pick up two chopsticks, one in their left hand and one in their
right. They can pick up the chopsticks in any order, either right hand
ﬁrst or left hand ﬁrst. Because there are only four chopsticks, not all
of them can eat at the same time.
The table is depicted in Figure 2.2. A formal description of this problem will
describe all the possible behaviours in which the four philosophers can engage.
2.3 Primitive Basic LOTOS
The Nature of LOTOS Speciﬁcation. A major objective of formal descrip-
tion is not to over-specify and to allow implementation freedom by being non-
prescriptive about aspects of realisation. Such avoidance of over-speciﬁcation
is at the heart of the process calculus approach. In particular, it is important
that the correct interpretation is imposed on LOTOS descriptions. Specif-
ically, they should be viewed as expressing the “externally visible possible
behaviour” of a system. Speciﬁcations should be viewed as black boxes; they
describe the order of possible external interaction, but do not prescribe how
that interaction order is internally realised. Any physical system that realises
the external behaviour is a satisfactory implementation.
The concept of the environment that a speciﬁcation evolves in is central in
obtaining this interpretation. The term environment refers to the behaviour
that the external observer of a system wishes to perform. Note that this exter-
nal observer could be either human or mechanical. Conceptually, a LOTOS
2This scenario is based upon a Dining Philosophers speciﬁcation associated with
the SEDOS tool set.

2.3 Primitive Basic LOTOS
23
     * *
  * * * *
* * * * * *
stick4
right
left
Aristotle
right
left
Buddha
right
left
Confucius
right
left
Descartes
stick1
stick3
stick2
Fig. 2.2. The Dining Philosophers
speciﬁcation only deﬁnes “possibilities” for evolution of a system and it is
through interaction with a particular environment that these possibilities are
resolved and realised. For example, if an environment cannot oﬀer an action
that a speciﬁcation must perform, a deadlock will ensue.
As an illustration, we might view a LOTOS speciﬁcation, called S, in the
form depicted in Figure 2.3; i.e. as a black box with two interaction points
between the speciﬁcation and the environment, g and h. Such interaction
points are called gates (the term port is also sometimes used). The set of all
gates of a speciﬁcation deﬁnes the interface to the speciﬁcation. It is only
through gates in this interface that an external observer can interact with the
speciﬁed system.
Gates reference “locations” at which interactions can take place. At such
gates, actions are performed. We say more shortly about this concept, but
they can be thought of as interaction activities, e.g. passing a value, sending a
message or pressing a button. In fact, the latter of these yields a nice pictorial
representation of interaction between environment and speciﬁcation. LOTOS
descriptions deﬁne the order in which actions can be oﬀered at gates; e.g. it
might be that an action at gate g can only be oﬀered once an action at gate
h has been performed. Thus, typically, actions are only oﬀered intermittently

24
2 Process Calculi: LOTOS
S
g
h
Fig. 2.3. Black Box Interpretation of a LOTOS Speciﬁcation
at gates. We can view the oﬀering of an action to the environment as the
popping up of a button. For example, Figure 2.4 depicts the situation when
an action is oﬀered at gate g, but not at gate h. The environment can decide
to push the button or to leave it unpushed. We could also have situations such
as that depicted in Figure 2.5, where both buttons are up and the external
observer has a choice of actions to perform.
S
h
g
Fig. 2.4. Action Oﬀering as Buttons Popping Up
S
g
h
Fig. 2.5. Choice of Action Oﬀers
We use this button-pushing analogy a number of times in our presentation
of LOTOS.

2.3 Primitive Basic LOTOS
25
Behaviour Expressions. As indicated already, we introduce pbLOTOS by
working through the main constructs of the language. As also indicated al-
ready, we are interested in deriving behavioural speciﬁcations. As a reﬂection
of this, the main unit of pbLOTOS speciﬁcation is a behaviour. The operators
that we introduce characterise the possible behaviour expressions that can be
written in pbLOTOS. The set of all possible pbLOTOS behaviour expressions
is denoted Beh; the variables B, B′, B′′, B1, B2, . . . range over the set Beh;
i.e. when we refer to such a variable it is implicitly assumed to be in Beh; e.g.
B ∈Beh.
There is one behaviour expression that we can highlight immediately; it is
the null behaviour expression,
stop
which is a distinguished behaviour that performs no actions. In fact, it is
synonymous with deadlock. stop is typically used to terminate a nonnull be-
haviour; i.e. it indicates that a point has been reached at which no more
behaviour can be performed.
Behaviour Trees. We use a general notation, which we call behaviour trees,
in order to depict the allowable evolutions of a behaviour expression. One of
the semantics that we consider in the next chapter, labelled transition sys-
tems, has similarities to behaviour trees and can be seen as a formalisation of
some aspects of behaviour trees.3 Examples of behaviour trees are presented
in Figure 2.6. The exact meaning of this graphical notation is made clear as
we introduce the LOTOS constructs. Such a representation of behaviour is
helpful for simple speciﬁcations, but becomes unmanageable when speciﬁca-
tions become complex, e.g. if a large amount of recursive behaviour is included
in a speciﬁcation.
a
a
b
B
a
a
b
a
B
Fig. 2.6. Example Behaviour Trees
3In fact, labelled transition systems are more general than behaviour trees, be-
cause their underlying connectivity can be a graph; i.e. can contain cycles.

26
2 Process Calculi: LOTOS
2.3.1 Abstract Actions
The ﬁrst major principle is to assume the existence of a universe of observable
actions (these are also called external actions). For example, in specifying a
communication protocol we might assume the following observable actions
exist.
•
send, which references the instant that a message is transmitted from a
sender process to a communication medium;
•
receive, which references the instant that a message is passed from the
communication medium to a receiver process;
•
timeout, which references the instant that a sender process times out wait-
ing for an acknowledgement;
•
And similarly, sendAck, receiveAck, get, put etc;
and, in specifying the Dining Philosophers problem, we might assume the
following observable actions:
•
pick, which references the instant that a chopstick is picked up oﬀthe
table; and
•
put, which references the instant that a chopstick is put back onto the
table.
The set of all such actions is denoted Act; i.e. this is the set of all possible
actions that can be written; this set will clearly be inﬁnite. Act is sometimes
called the alphabet of actions. The variables u, v, x, y, z and their super- and
subscripts, e.g. x′, x′′, x1, x2, . . . , range over Act.4 However, although Act is
inﬁnite, the set of actions used in a particular pbLOTOS speciﬁcation is ﬁnite;
i.e. a ﬁnite subset of Act. Assuming that a particular pbLOTOS speciﬁcation
is being considered, the set of all actions in the speciﬁcation is denoted L; i.e.
the labels arising in the speciﬁcation.
In pbLOTOS, actions and gates are synonymous. This is because no data
is passed as part of an action, so, the name of the gate at which an action is
performed completely deﬁnes the action performed at that gate. As a reﬂection
of this, for pbLOTOS, the terms gate and action can be used interchangeably.
It is important to note that actions are atomic; they are atomic units
of observation and cannot be divided in time. A consequence of this is that
no two actions can occur at the same time and, thus, the occurrence of two
actions cannot overlap. For example, a send and a sendAck or a pick and
a put cannot happen at the same time. The atomicity of actions clearly has
important consequences for the modelling of concurrency; we discuss these
consequences in Section 2.3.6.
The restriction to atomic actions does not limit expressiveness, because
nonatomic activities can be speciﬁed in terms of the actions that delimit the
4Not only is this convention employed in this chapter, it is followed throughout
the book, unless otherwise stated.

2.3 Primitive Basic LOTOS
27
activity; i.e. rather than deﬁning an action that has duration, we can specify
the atomic instant at which the activity starts and the atomic instant at
which it stops. For example, rather than specifying that a philosopher eats,
we specify that at some instant he starts eating (which could be marked with
an action pick) and at some instant he stops eating (which could be marked
with an action put).
Actions are a fundamental abstraction device. Systems are described in
terms of such abstract entities rather than physical realisations; e.g. a com-
munication protocol is described in terms of abstract actions rather than the
physical mechanisms that realise the tasks of sending, receiving, timing-out
etc.
A special distinguished action, i, is also used; it denotes an internal action;
i.e. an action that is hidden from the external observer. The occurrence of
an internal action is not externally visible. Thus conceptually, no button is
raised when it is oﬀered or pushed when it is performed. It is important
to note though that although an i action is not externally visible, it may
“indirectly” aﬀect behaviour that is externally visible. Typically, an i action
will represent an internal decision, resolution of which prescribes a particular
visible behaviour.
The internal action has a number of roles. Firstly, it enables information
hiding; actions that are observable at one level of speciﬁcation can be trans-
formed into hidden actions at another level. Thus, behaviour that should not
be visible can be hidden. Such hiding supports a form of abstraction, because
the complexity of a part of the system is abstracted away from, by hiding it,
when specifying another part. In addition, internal actions play a central role
in creating nondeterminism; see Section 2.3.4.
Internal actions also prove to be important when (behavioural) equiv-
alences are deﬁned. In particular, two speciﬁcations with diﬀerent internal
behaviour may achieve the same “observable” behaviour and could, thus, be
considered equivalent.
Observable actions can be transformed into i using a hiding operator,
which takes the form:
hide x1, . . . , xn in B
and states that wherever any of the actions x1, . . . , xn arise during the evalu-
ation of the behaviour B they will be replaced by i. Thus, the gates x1, . . . , xn
are removed from the interface of behaviour B. For example, if we assume B′
models the behaviour of a sending process and contains an action timeout,
we might wish to hide the timeout from all observers outside the sender; i.e.
hide timeout in B′
This hiding reﬂects the reality of networked communication, where, for exam-
ple, the receiver process would be unable to observe a timer expiring in the
sender. We use a, b, c, d, e and their super- and subscripts, e.g. a′, a′′, a1, a2,
. . . , to range over Act ∪{i}.

28
2 Process Calculi: LOTOS
Actions are the basic unit of LOTOS speciﬁcation and, typically, when
performing a formal description using LOTOS, a set of actions in the prob-
lem domain would be located. Having identiﬁed the constituent actions of
the speciﬁcation we would like to order them in someway, i.e. to deﬁne the
“temporal order” in which actions can occur (after all this is what basic event
ordering models are about). The pbLOTOS operators allow us to do this.
Thus, we postulate a universe of actions and then order them according to a
set of primitive operators. Standard operators are: sequence, choice, process
instantiation and concurrency.
2.3.2 Action Preﬁx
Basic sequencing of actions is deﬁned in LOTOS using action preﬁx, which
has the general form
a ; B
where a is an action from Act ∪{i} and B is a behaviour. Thus, a ; B is a
behaviour that will perform action a and then behave as B. We can depict the
eﬀect of this construct using the behaviour tree shown in Figure 2.7. Thus,
action oﬀers are attached to line segments in behaviour trees and unspeciﬁed
behaviour, such as B, is depicted using a triangle.
In terms of pushing buttons, we can also view a ; B as a black box with a
gate a (and gates for all the external actions in B). The button a is initially
the only button raised; if the environment pushes a then the black box behaves
as B (e.g. new buttons will be raised).
B
a
Fig. 2.7. A General Behaviour Tree Depicting Action Preﬁx
As an example, we may wish to specify that our medium process will
perform a send action with the sender process and then perform a receive
action with the receiver process (this behaviour is depicted in Figure 2.8):
send ; receive ; stop
Notice the use of the distinguished behaviour stop to terminate the action
oﬀering of the sender. This behaviour states that the action receive cannot
happen before the action send and, following the action receive, no more

2.3 Primitive Basic LOTOS
29
send
receive
pick
put
Fig. 2.8. Behaviour Trees of Action Preﬁx
actions will be oﬀered. By way of clariﬁcation, this behaviour can be derived
from the general form for action preﬁx by repeated application. In fact, as a
reﬂection of this, the behaviour is actually a shorthand for the following fully
bracketed behaviour
send ; ( receive ; ( stop ) )
where the repeated application is made explicit.
Alternatively, we might want to specify the following behaviour (depicted
in Figure 2.8) for a dining philosopher
pick ; put ; stop
indicating that a philosopher cannot put his chopstick down until he has
picked it up.
2.3.3 Choice
Choice is denoted
B1 [] B2
and states that either behaviour B1 or behaviour B2 will be performed. The
choice of which behaviour to perform is determined by the initially oﬀered
action of the two behaviours. Typically, all such actions will be oﬀered to the
environment, which will choose which to perform; this decision will resolve
the choice.
The necessity to oﬀer such choices largely arises because of the move to
systems that contain concurrency. A behaviour oﬀering a choice of a number
of observable actions to perform is really oﬀering a menu of possible inter-
actions from which concurrently executing objects can select. The behaviour
is deﬁning the set of actions to which it is willing to react. Such choices are
not typically associated with sequential systems which are, in comparison to
parallel systems, closed. The interaction choices between components are pre-
determined in sequential systems.
As an example of choice, we may wish to specify the sender behaviour
depicted to the left in Figure 2.9:

30
2 Process Calculi: LOTOS
B
B
send
receiveAck
timeout
send
pick_stick1
pick_stick2
1
2
Fig. 2.9. Examples of Choice in Behaviour Trees
send ; ( receiveAck ; stop [] timeout ; send ; stop )
This states that after a send the sender will either receive an acknowledge-
ment or time out and retransmit, by performing another send. Each of the
alternatives is completed by stopping.
We can also picture choice in terms of buttons popping up. For example,
this behaviour yields a black box with gates send, receiveAck and timeout
and it is initially in the state depicted in Figure 2.10(i). If the environment per-
forms a send then the box progresses to the state depicted in Figure 2.10(ii).
So, there is now a choice for the environment: does it press receiveAck or
timeout? (In fact, in more advanced versions of this behaviour we hide timeout
and do not make this choice externally visible, but for illustrative purposes
we leave it visible here.) If the environment presses receiveAck no more ac-
tions will be oﬀered; i.e. all buttons will be depressed. However, if timeout
is pressed, the send button pops up and we progress to the (external) state
depicted in Figure 2.10(i).
This is only a snapshot of the full behaviour of the sender and is far from
complete. For example, after timing out we would actually like to specify that
the behaviour recurses back to the start in order to resend. We have to wait
until we have a few more constructs before we can express such behaviour.
In a similar way, we could specify the behaviour depicted on the right in
Figure 2.9 as
pick stick1 ; B1 [] pick stick2 ; B2
i.e. a philosopher can either pick up stick 1 or stick 2.
2.3.4 Nondeterminism
Nondeterminism goes hand in hand with concurrency. Because, in concurrent
systems, components can evolve independently of one another, choices made

2.3 Primitive Basic LOTOS
31
S
send
receiveAck timeout
(i)
S
send
timeout
(ii)
receiveAck
Fig. 2.10. Examples of Choice in Black Boxes
inside one component can create nondeterminism for the component’s envi-
ronment (i.e. all components that evolve in parallel with it). This is because
components cannot “look inside” other components to see why they make a
particular choice, thus, to the environment, hidden choices seem nondetermin-
istic.
Another way of viewing this is that components are autonomous and thus,
they make decisions for themselves, which are not “explained” to their envi-
ronment. This does not mean that overall behaviour is nondeterministic; the
emergent behaviour could be deterministic. Speciﬁcally, it will be determin-
istic if the environment can handle all the nondeterministic possibilities, i.e.
if nothing is unexpected. Although many hidden choices are taking place in a
car engine, (while faults do not occur) its emergent behaviour is predictable,
once it has been explained to the driver by reading the car manual or passing
a driving test.
Nondeterminism is deﬁned in LOTOS as a special case of choice. Speciﬁc
forms of choice yield a nondeterministic resolution of the alternatives. The
main forms are:
(i) i ; B1 [] i ; B2
(ii) i ; B1 [] x ; B2
(iii) x ; B1 [] i ; B2
(iv) x ; B1 [] x ; B2

32
2 Process Calculi: LOTOS
where x denotes an observable action and (ii) and (iii) are mirror images
of each other; so, there are really three basic forms. Notice that these ﬁrst
three classes of nondeterminism could be created by hiding some actions in
an otherwise deterministic behaviour. In addition, parallel composition can
create nondeterminism, as we discuss in Section 2.3.6. The three basic forms
are depicted in Figure 2.11.
B1
B2
i
i
B1
B2
i
B1
B2
x
x
x
(i)
(ii)
(iv)
Fig. 2.11. General Forms of Nondeterminism in Behaviour Trees
The nondeterminism arises because selection between the two initial ac-
tions of the choice is beyond the control of the environment. For example, in
(iv), when the external observer performs an x he or she has no control over
whether the speciﬁcation evolves to B1 or to B2. As a reﬂection of this, a
nondeterministic choice is also referred to as an internal choice.
Each of these three forms yields a diﬀerent variant of nondeterministic
behaviour. Firstly, notice that forms (i) and (iv) are symmetric, while (ii) is
nonsymmetric, in the sense that the left branch starts with an internal action,
while the right branch starts with an observable action. We now consider each
in turn.
•
In (i), the initial evolution of the behaviour is completely hidden from the
external observer; in terms of button-pushing, no buttons are raised. Thus,
a wholely internal choice will be made to either evolve to behaviour B1 or
to evolve to behaviour B2.
•
In (ii), the initial evolution could also be completely hidden from the ex-
ternal observer; i.e. the left branch could be taken immediately and no
buttons will be raised. However, if the external observer is quick enough
to interact with the behaviour she could perform action x and evolve to
B2. However, if the external observer is either not quick enough or unable
to perform an x, the behaviour will eventually evolve to B1. Conceptually,
the button x is raised, to see whether the environment can push it, and
then, at some point, retracted (i.e. depressed). Critically though, because
we are not yet in the business of quantitative time speciﬁcation, the time

2.3 Primitive Basic LOTOS
33
point at which x is retracted is not stated. Eﬀectively, the speciﬁcation
says that, if the environment has not performed the x by some unspeciﬁed
time point, it will be retracted.
•
In (iv), the point of initial evolution of the behaviour is always externally
visible; i.e. an x action will be oﬀered and the corresponding button will
be raised. However, the choice of evolving to B1 or to B2 after performing
x is made internally and hence nondeterministically.
It is important to note the diﬀerence between a deterministic choice (some-
times referred to as an external choice) and a nondeterministic choice. For ex-
ample, you should convince yourself that the following two behaviours, which
are depicted in Figure 2.12, are diﬀerent.
x
x
1
2
x
x
x
1
x
2
x
Fig. 2.12. A Deterministic and a Nondeterministic Choice
x ; ( x1 ; stop [] x2 ; stop ) and x ; x1 ; stop [] x ; x2 ; stop
Speciﬁcally, after performing an x action, the ﬁrst behaviour will oﬀer an
external choice between performing an x1 or an x2, whereas, after performing
an x action, the second behaviour will oﬀer one of x1 or x2 to the environment,
but, crucially, not the choice between both. In terms of button-pushing, we
can depict the two behaviours as the two alternative sequences of black box
states depicted in Figure 2.13, where the arrows indicate evolution of the
system and, in particular, the two arrows in the nondeterministic black box
indicate a choice of internal evolution.
Nondeterminism plays a number of roles in process calculi. In general it
acts as an abstraction device. For example, nondeterminism is often intro-
duced when, at a certain level of system development, we wish to abstract
away from a particularly complex mechanism. A good example of this is in
modelling loss in a communication medium. For example, the medium in our
running example might be speciﬁed as follows,
send ; ( i ; B1 [] receive ; B2 )

34
2 Process Calculi: LOTOS
x
x1
x2
x
x 1
x2
x
x1
x2
x
x 1
x2
x
x 1
x 2
Fig. 2.13. Deterministic and Nondeterministic Choice in Black Boxes
which will perform a send action with the sender process (i.e. a message is
sent to the medium) and then it will either nondeterministically decide to lose
the message, represented by the i action, or pass the message on, represented
by oﬀering the receive action, with which the receiver process may interact.
What we are really doing here is abstracting away from the speciﬁc mech-
anism by which loss occurs in a communication medium. We are stating that
some internal mechanism could occur and result in the message being lost, but,
at the particular level of abstraction we are considering, we are not interested
in how this happens. Notice that a complete speciﬁcation of the mechanics
of loss would probably require the physical laws of noise and attenuation on
communication lines to be expressed.
There is also a sense in which nondeterminism is used in speciﬁcation to
allow implementation freedom. A nondeterministic choice between evolving
to B1 or to B2 can be viewed as stating that implementations that behave
as either B1 or B2 are satisfactory. Such a speciﬁcation is stating that the
speciﬁer does not mind whether the system behaves as B1 or as B2. Such
nondeterminism may then be reﬁned out during development. This is the
motivation behind reﬁnement relations, such as reduction; see Section 5.1.6.2.
2.3.5 Process Deﬁnition
Basic Form. The basic unit of modularity is the process. The syntax for
process deﬁnition is:
P [x1, . . . , xn] := B
where P ∈PIdent, the set of process identiﬁers. This states that the process
identiﬁer P is bound to the behaviour B. The list x1, . . . , xn indicates the

2.3 Primitive Basic LOTOS
35
actions that are observable in B. [x1, . . . , xn] can be thought of as denoting
the interface of B, i.e. the actions that can be interacted with; it deﬁnes the
buttons that must be made available in a black box implementation of the
process P.
Instantiation of the behaviour B is performed through reference to P in
a behaviour expression (we also talk about invocation of processes; the terms
instantiation and invocation are interchangeable). In the process of instanti-
ating P, we can alter the action names. For example, the deﬁnition
P [x, y, z] := B
(a)
could be invoked by referencing
P [u, x, w]
(b)
which has the eﬀect of instantiating behaviour B in such a way that, whenever
it is speciﬁed to oﬀer an x it oﬀers a u, whenever it is speciﬁed to oﬀer a y it
oﬀers an x and whenever it is speciﬁed to oﬀer a z it oﬀers a w. The terms
formal and actual gates, are often used to refer to these action lists. Thus, in
the above example, x, y and z are formal gates of the process P, whereas u,
x and w are actual gates of the process instantiation.
In terms of black boxes, the deﬁnition of P, expression (a), can be depicted
as in Figure 2.14, whereas instantiation of P, expression (b), can be depicted
as in Figure 2.15.
x
z
y
B
Fig. 2.14. Process Deﬁnition Black Box
Notice also that, in P [x, y, z] := B, the behaviour B can reference P and
thus create recursion. As an example, consider the behaviour
P [z, w] := z ; w ; P [w, z]
which, on invocation as
P [x, y]
yields the inﬁnite behaviour depicted in Figure 2.16. Inﬁnite behaviour is cre-
ated by recursive process invocation. Notice also, recursive behaviour cannot

36
2 Process Calculi: LOTOS
u
x
w
B
Fig. 2.15. Process Instantiation Black Box
be ﬁnitely represented in a tree. Thus, to denote such executions, we need
to use what could be called behaviour graphs as a generalisation of the trees
used to this point.
x
y
y
x
Fig. 2.16. An Inﬁnite Behaviour
Sometimes when we use process deﬁnition and instantiation we drop the
action list. So, we write
P := B
as a shorthand for
P [x1, . . . , xn] := B
We only use this shorthand when the action list plays no role; i.e. action names
are not renamed on process instantiation. Thus, a process deﬁnition such as
P := x ; y ; stop
cannot be invoked as

2.3 Primitive Basic LOTOS
37
P [z, w]
Example. As an example of process deﬁnition and instantiation, the medium
in the communication protocol example could be speciﬁed as a process called
Medium and deﬁned as follows.
Medium[send, receive] :=
send ; ( i ; Medium [send, receive] [] receive ; Medium [send, receive] )
This is actually a one-slot medium; i.e. it deals with one message at a time.
A one-slot medium is suitable for a stop and wait protocol because only one
message is in transit between the sender and receiver at any time. The process
named Medium performs a send action with the sender. Then the medium
will either nondeterministically lose the message or oﬀer the action receive
with which the receiver may interact. After either of these alternatives, the
behaviour recurses by invoking Medium again, thus preparing the process for
the next send action from the sender.
We can also specify a possible behaviour for the sender process as follows.
Sender [get, send, receiveAck] :=
get ; send ; Sending [get, send, receiveAck]
Sending [get, send, receiveAck] :=
hide timeout in ( receiveAck ; Sender [get, send, receiveAck]
[]
timeout ; send ; Sending [get, send, receiveAck] )
The top-level process here is Sender, which invokes the process Sending. We
use the convention that process identiﬁers are written with a capital ﬁrst let-
ter, whereas action names are written with a small ﬁrst letter. The process
Sender obtains a message to deliver by performing the action get (remem-
ber this interaction takes place between the Sender and its environment); it
transmits the message by performing send and then it invokes Sending.
The role of Sending is to ensure successful transmission of the mes-
sage sent. In order to do this, Sending waits for an acknowledgement (the
receiveAck) action; if it does not arrive in time a timeout occurs and the
message is resent, modelled by oﬀering the action send again. Notice that, if
a receiveAck is successfully received then the recursive call takes us back to
Sender, indicating that the message has been successfully transmitted, and we
are ready to send another message. In contrast, after timing out and resend-
ing, we recurse back to the start of Sending and try for an acknowledgement
to the resend.
Although they are the same actions, the two references to send are con-
ceptually diﬀerent: the send in Sender is an initial transmission, whereas the
send in Sending is a retransmission of an old message. This distinction is
justiﬁed because an initial transmission send is preceded by the action get.

38
2 Process Calculi: LOTOS
You can think of the eﬀect of the action get as being to ﬁll the send buﬀer
with a new message.
In this example, you should notice the approach of invoking a subprocess,
which enables a repetition to be set up by recursing on the name of the
subprocess. The deﬁnition and invocation of the process Sending is just such
an example. In terms of state machines, Sending can be viewed as a state
back to which the machine iterates. In fact, all constituent behaviours of a
pbLOTOS speciﬁcation can be viewed as states. For example, the behaviour
expression:
get ; send ; Sending [. . .]
can be viewed as a state from which a transition labelled get can be performed
and the system evolves into state,
send ; Sending [. . .]
which is a state from which a transition labelled send can be performed and
the system evolves into state,
Sending [. . .]
To complete the set of processes in the communication protocol example, the
receiver process and acknowledgement mediums can be speciﬁed as follows:
Receiver [put, receive, sendAck] :=
receive ; put ; sendAck ; Receiver [put, receive, sendAck]
AckMedium [sendAck, receiveAck] :=
sendAck ; receiveAck ; AckMedium [sendAck, receiveAck]
As indicated earlier, we have assumed a reliable acknowledgement medium.
Thus, the receiver simply receives messages and sends acknowledgements and
the acknowledgement medium passes these messages on (and does not lose
any of them).
Divergence. An important technical issue arising through recursion is the
possibility of inﬁnite internal behaviour, which is called divergence. The fol-
lowing behaviours give diﬀerent examples of the phenomenon.
1. P := i ; P
2. P := x ; stop [] i ; P
3. P := x ; stop [] y ; hide y in P
4. hide x in ( y ; B [] z ; P )
where
P := x ; x ; P

2.3 Primitive Basic LOTOS
39
i
i
i
(1)
i
i
i
(2)
i
i
i
(3)
i
i
i
i
(4)
B’
B’
x
x
x
x
y
x
x
x
y
x
y
z
y
z
where
B’=hide x in B
Fig. 2.17. Divergent Behaviour

40
2 Process Calculi: LOTOS
The behaviour of these expressions is depicted in Figure 2.17; both inﬁnite
expansions and cyclic depictions are presented.
Thus, (1) is a straightforward form of divergence; (2) oﬀers the possibility,
at every state, of not diverging by performing an x, but nonetheless it could
diverge if the environment is never willing to perform an x; (3) shows how
hiding can create divergence; and (4) shows how hiding can create divergence
deep inside a subprocess.
The correct interpretation of divergence is a hotly debated issue, with one
school of thought viewing divergence as degenerate in the extreme [96]. For
example, extreme cases of divergence, where the recursive call is not even
“guarded” by an internal action, are certainly problematic, viz:
P := P
We discuss these issues in some depth in Sections 5.1.4 and 7.2.6.
Relabelling. In order to correctly model the eﬀect of process instantiation,
another operator is required called relabelling. This has the form,
B [y1/x1, . . . , yn/xn]
and has the eﬀect of relabelling the xis with the yis in the behaviour B (i.e.
buttons are renamed). Notice that xi ∈Act for all 1 ≤i ≤n, so internal
actions cannot be relabelled; this also applies to the special (pseudo internal)
action δ, which we introduce in Section 2.3.7. In the standard LOTOS lan-
guage, the relabelling operator is not available to the speciﬁer, rather it is used
in deﬁning the semantics of the language. This is because the basic form, i.e.
renaming through binding actual gate names to formal gate names is viewed
to be more usable from the speciﬁer’s point of view. However, the basic form
is really just syntactic sugar for direct application of the relabelling operator.
In particular, an invocation,
P [y1, . . . , yn]
of a process deﬁnition,
P [x1, . . . , xn] := B
can always be rewritten using our simpliﬁed form of process instantiation and
relabelling, i.e.,
P [y1/x1, . . . , yn/xn]
with a process deﬁnition,
P := B
This approach of completely dividing the mechanisms for process invocation
and the mechanisms for relabelling leads to more elegant semantic deﬁnitions
and is thus, generally used in our chapters on semantics. However, the basic
form is kept for presentation of examples.

2.3 Primitive Basic LOTOS
41
2.3.6 Concurrency
2.3.6.1 Independent Parallelism
We begin with a special case of concurrency; this is given by the operator |||,
and has the general form,
B1 ||| B2,
which states that the two behaviours B1 and B2 evolve independently in
parallel. Independent in this context means that there is no shared behaviour,
which would arise if B1 and B2 performed some actions together.
We might, for example, use this construct to specify that the behaviour of
two philosophers that do not share chopsticks are independent:
pick stick1 ; pick stick2 ; put stick1 ; put stick2 ; stop |||
pick stick3 ; pick stick4 ; put stick4 ; put stick3 ; stop
Of course, if they share a chopstick there would be some overlapping be-
haviour; we come to this situation shortly.
How though should we view such independent behaviour? In fact, the
choice of interpretation to put on parallelism is one of the main issues in
our discussion of semantics. However, here we focus on what is the standard
interpretation: interleaving.
Interleaved interpretations of concurrency are justiﬁed by our assumption
that all actions are atomic. Speciﬁcally, as discussed earlier, a direct conse-
quence of actions being assumed to be atomic is that no two actions can
occur simultaneously. Thus, in terms of action occurrences, there is no true
simultaneity and any execution path through the speciﬁcation will be a linear
sequence of actions. As an illustration, consider the following simple example,
x ; stop ||| y ; stop
This behaviour speciﬁes that the action x will be oﬀered independently in
parallel with the action y. Now, assuming atomicity of actions, we know that
the occurrences of x and y cannot overlap, which implies that one must occur
before the other. So, we obtain the following relationship,
x ; stop ||| y ; stop ≡x ; y ; stop [] y ; x ; stop
where ≡means “are equivalent” (we make precise such notions of equivalence
later in this book). This states that x occurring in parallel with y is the same
as either the occurrence of x being followed by the occurrence of y or the
occurrence of y being followed by the occurrence of x. Thus, interleaving al-
lows parallelism to be expressed in terms of sequence and choice and although
behaviours may be “truly in parallel”, no two actions occur “truly” simulta-
neously. This interpretation allows us to depict independent concurrency very
easily; a depiction of x ; stop ||| y ; stop is given in Figure 2.18.
Figure 2.19 shows the following larger example of interleaved parallelism.

42
2 Process Calculi: LOTOS
x
y
y
x
Fig. 2.18. Interleaved Parallelism
( x ; y ; stop ) ||| ( y ; z ; stop )
y
x
y
y
z
x
y
y
z
x
y
z
z
z
y
y
z
y
Fig. 2.19. Interleaved Parallelism 2
We have once again mapped concurrency to sequence and choice, but this time
the possible alternatives are far greater. This is characteristic of interleaving:
the number of states in the interleaved representation increases very rapidly
as the complexity of the parallel behaviour increases. Also, notice that the y
actions on both sides of the parallel behaviour occur independently. These two
actions would have to be explicitly identiﬁed for synchronisation if they were
to occur together. In addition, notice that some subbranches of the complete
behaviour are repeated. Such repetitions could be pruned out.
Nondeterministic choices can also be created through parallel composition.
For example, if the environment performs the action x, then the behaviour,
( x ; stop ) ||| ( x ; y ; stop )
will internally decide whether to oﬀer just an x and then a y or an external
choice between y and x, with the former evolving to oﬀering an x and the

2.3 Primitive Basic LOTOS
43
latter evolving to oﬀering a y. This behaviour is depicted in Figure 2.20. You
should also notice that a similar instance of nondeterminism is embedded into
the behaviour depicted in Figure 2.19; the nondeterminism is on the action
y. Forms of nondeterminism based on internal actions can also be created
through parallel composition.
x
x
x
y
x
y
x
y
Fig. 2.20. Interleaving Creating Nondeterminism
2.3.6.2 General Form
As already stated, independent parallelism is one speciﬁc class of concurrent
behaviour. Concurrency, in its most general form, is denoted
B1 |[x1, . . . , xn]| B2
with the operator parameterised on the observable actions that must be syn-
chronised, the x1, . . . , xn. This behaviour states that B1 and B2 evolve inde-
pendently in parallel subject to the synchronisation of actions x1, . . . , xn; i.e.
an action xi (1 ≤i ≤n) appearing in either B1 or B2 can only be executed
if it synchronises with an xi in the other behaviour. Also notice that internal
actions cannot synchronise; this is because they are not externally visible and,
thus, cannot be interacted with.
As examples, consider the following behaviours.
(i)
( x ; y ; stop ) |[y]| ( y ; z ; stop )
(ii)
( x ; y ; stop ) |[x]| ( x ; z ; stop )
(iii)
( x ; stop ) |[y]| ( z ; stop )
(iv)
( x ; y ; stop ) |[y]| ( z ; stop )
(v)
( x ; y ; w ; stop ) |[x, y]| ( x ; z ; stop )
(vi)
( x ; y ; stop ) |[y]| ( i ; z ; stop )

44
2 Process Calculi: LOTOS
Their behaviour trees are depicted in Figure 2.21. For each of the behaviours,
independent parallelism is constrained by synchronisation of the actions in
the gate set.
•
(i) Synchronisation on y results in a totally sequential behaviour. In par-
ticular, notice that the y on the right-hand side of the behaviour cannot
occur without the left-hand side oﬀering a y with which to synchronise.
Thus, the x must be performed ﬁrst.
•
(ii) Synchronisation on x still allows y and z to be arbitrarily interleaved
once x has occurred.
•
(iii) The interleaving of the two behaviours is unconstrained because y
does not appear in either behaviour.
•
(iv) The interleaving of x and z is unconstrained, but because the y action
is identiﬁed for synchronisation and does not appear on both sides of the
parallel operator, it does not occur. The behaviour on the left-hand side
is, in fact, unable to proceed once the x action has been performed; i.e. it
is locally deadlocked.
•
(v) Firstly, the x action is synchronised on, then the z action can occur,
but, once again, the y action is deadlocked. The inability to perform a y
blocks the w action from being oﬀered as well.
•
(vi) The interleaving of x and i is unconstrained by the synchronisation
on y and the z action can follow the occurrence of i. However, the y action
is blocked from being oﬀered.
Generalised parallelism, |[. . .]|, has two special cases, one of them we have seen
already:
B1 ||| B2,
which is equivalent to writing, B1 |[ ]| B2, i.e. general parallel composition
with an empty synchronisation set; and,
B1 || B2
which is equivalent to generalised parallelism with a synchronisation set con-
taining all the actions of B1 and B2 or alternatively containing all the actions
in L. Thus, ||| gives the composition of independent concurrent threads and
|| gives fully synchronised parallelism.
As illustrations of fully synchronised parallelism, consider the following
behaviours (behaviour trees for which are presented in Figure 2.22).
(i)
( x ; y ; stop ) || ( x ; y ; z ; stop )
(ii)
( x ; y ; z ; stop ) || ( z ; y ; z ; stop )
(iii)
( x ; stop [] y ; stop [] z ; w ; stop) || ( x ; stop [] i ; y ; stop )
Thus, (i) can successfully synchronise on x and then y, but then is unable to
progress, as the z action is only oﬀered on one side of the parallel composition.

2.3 Primitive Basic LOTOS
45
(i)
(iii)
(iv)
(v)
(ii)
i
i
(vi)
x
y
z
x
y
z
z
y
x
z
z
x
x
z
z
x
x
z
x
x
z
z
z
x
Fig. 2.21. Generalised Parallelism
(ii)
(iii)
i
x
y
x
y
(i)
Fig. 2.22. Fully Synchronised Parallelism
In contrast, (ii) can perform no actions and thus induces the indicated trivial
behaviour tree, because it cannot even synchronise on an initial action. (iii)
illustrates how choice and internal actions behave through fully synchronised
parallelism. In particular, notice how one of the branches of the left-hand
choice is blocked because z is not oﬀered as an initial action of the right-hand
choice. In addition, the internal action is not subject to synchronisation, so
appears in the resultant behaviour.

46
2 Process Calculi: LOTOS
As a reﬂection of the relationship between generalised parallelism and
the two operators ||| and ||, only |[. . .]| is included in pbLOTOS; ||| and ||
are viewed as derived operators; i.e. ||| = |[ ]| and || = |[x1, . . . , xn]| where
{x1, . . . , xn} = L.
2.3.6.3 Example
As a more concrete illustration of parallel composition, in the communication
protocol example we might compose the two mediums together to form a
duplex medium as follows,
DupMedium [send, receive, sendAck, receiveAck] :=
Medium [send, receive] ||| AckMedium [sendAck, receiveAck]
This states that the behaviour of the two mediums is independent, which is
as expected, because the two directions of communication do not aﬀect each
other. We can now deﬁne the top-level behaviour of the protocol as follows:
( ( Sender [get, send, receiveAck] ||| Receiver [put, receive, sendAck] )
|[send, receive, sendAck, receiveAck]|
DupMedium [send, receive, sendAck, receiveAck] )
So, the Sender and Receiver processes evolve independently, but commu-
nicate by synchronising on the commmon gates send, receive, sendAck and
receiveAck through the duplex medium.
2.3.6.4 Why Synchronous Communication?
As indicated already, in LOTOS concurrent threads of control interact by
synchronous communication. Synchronous message passing is chosen because
it can be viewed as the primitive mechanism from which other communication
paradigms, e.g. asynchronous communication or remote procedure call, can be
deﬁned.
The particular class of synchronous communication employed in LOTOS
is multiway synchronisation. Thus, any number of behaviour expressions can
be involved in a synchronous communication. For example, in the following
behaviour,
P [x, y] |[x]| Q [x] |[x]| R [x, z]
all three of the processes, P, Q and R, have to synchronise in order to perform
the action x.
The LOTOS multiway synchronisation plays an important role in the
constraint-oriented style of speciﬁcation [171, 195]. The term constraint-
oriented is used to refer to an incremental system development style in which
system speciﬁcations are reﬁned by imposing behavioural constraints on the

2.3 Primitive Basic LOTOS
47
system. This is done by composing the system in parallel with a piece of be-
haviour, which reﬂects this constraint. It is suggested that such an approach
oﬀers a powerful incremental development methodology [195].
You should also be aware of the important role that hiding plays in rela-
tion to multiway synchronisation. Speciﬁcally, hiding is used to “close oﬀ” an
interaction and prevent further synchronisation on a particular action. This
implies a very speciﬁc order to the application of operators in constraint-
oriented styles of speciﬁcation. In particular, an interaction cannot be hidden
until the behaviour has been fully constrained through parallel composition.
2.3.7 Sequential Composition and Exit
Action preﬁx deﬁnes sequencing for actions, however, we would also like to
deﬁne sequential composition of complete behaviours. This is supported by
the sequential composition operator (also called enabling),
B1 >> B2
which will evolve as B1 then; if B1 terminates successfully, it will behave as
B2. The concept of successful termination is pivotal here. We do not wish
B1 >> B2 to evolve to B2 unless B1 completes its evolution. In particular,
if B1 is in a deadlock state we would wish B1 >> B2 to evolve to the same
deadlock state. Thus, we introduce a special distinguished behaviour,
exit
to denote successful termination. For example, consider the following be-
haviour expressions.
(i) ( x ; y ; exit ) >> ( z ; stop )
(ii) ( x ; y ; stop ) >> ( z ; stop )
(iii) ( x ; stop [] y ; exit ) >> ( x ; stop )
(iv) ( x ; exit ||| y ; exit ) >> ( z ; stop )
(v) ( x ; stop ||| y ; exit ) >> ( z ; stop )
(vi) ( x ; exit |[x]| y ; exit ) >> ( z ; stop )
(vii) x ; y ; exit
Behaviour trees for expressions (i) to (vi) are depicted in Figure 2.23 and
expression (vii) is shown in Figure 2.24. We consider each of the examples in
turn.
•
(i) The left-hand behaviour is performed ﬁrst (x followed by y), then an
internal action is performed (reﬂecting the successful termination at exit)
and this is followed by the right-hand behaviour (performing the z action).

48
2 Process Calculi: LOTOS
•
(ii) Only the left-hand behaviour is performed here. This is because the
left-hand behaviour does not successfully terminate, i.e. there is no exit,
so, the right-hand behaviour is not enabled.
•
(iii) Only one branch of the choice successfully terminates and thus, only
this branch is postﬁxed with the right-hand behaviour.
•
(iv) It is important to note that, in the behaviour on the left side of
>> both sides of the parallel composition successfully terminate. Thus, in
whatever state the left-hand behaviour terminates, it will be followed by
the right-hand behaviour.
•
(v) In contrast to (iv), because only one side of the parallel composition
concludes with an exit, the behaviour on the left of >> cannot successfully
terminate and, thus, the right-hand behaviour cannot follow. This is an
important aspect of sequential composition. Both branches of a parallel
composition must successfully terminate in order for the whole of a parallel
composition to successfully terminate. With some thought you will be able
to convince yourself that this correctly reﬂects the behaviour of concurrent
threads of execution.
•
(vi) Because it is in deadlock after performing action y, the left-hand side
of this behaviour is not able to successfully terminate.
•
(vii) The behaviour successfully terminates by performing a δ action (see
Figure 2.24). However, there is no behaviour to enable, thus, the δ action is
left dangling. δ is a special action used to signal successful termination and,
thus, enable a sequential composition. It is really a semantic device, which
enables sequential composition to work. We postpone a full discussion of
its behaviour until we consider actual semantic approaches. However, you
should note that δ cannot be explicitly used by a speciﬁer, thus, δ ̸∈Act;
it is a distinguished event, which has some similarities to i.
As a more concrete example of the use of successful termination, consider the
Dining Philosophers example. We might want to specify that a philosopher
can only perform the behaviour of putting his chopsticks down once he has
performed the behaviour of picking his chopsticks up:
( pick stick1 ; exit ||| pick stick2 ; exit )
>> ( put stick1 ; stop ||| put stick2 ; stop )
Notice that this expresses that the chopsticks can be picked up and put down
in any order, modelled by actions on stick 1 and stick 2 being placed indepen-
dently in parallel. But, it is only after both chopsticks have been picked up
that a successful termination can occur and we can evolve to putting down
the chopsticks. This behaviour is depicted in Figure 2.25.
As suggested by this example, the main role of the sequential composition
operator is in enabling speciﬁers to subdivide their speciﬁcations into phases.
Here we have decomposed into a picking-up phase and a putting-down phase
and there will be a synchronisation (the successful termination) before moving
between phases. We could specify this example using just action preﬁx and

2.3 Primitive Basic LOTOS
49
i
(i)
(ii)
i
(iii)
(iv)
i
i
x
y
z
x
y
x
y
x
x
y
y
x
z
z
(v)
(vi)
x
y
y
x
y
Fig. 2.23. Sequential Composition and Exit
y
x
δ
(vii)
Fig. 2.24. Further Sequential Composition and Exit Illustration

50
2 Process Calculi: LOTOS
i
i
pick_stick1
pick_stick2
pick_stick2
pick_stick1
put_stick1
put_stick2
put_stick2
put_stick1
put_stick1
put_stick2
put_stick2
put_stick1
Fig. 2.25. Sequential Composition in the Dining Philosophers
choice (and possibly concurrency), but the speciﬁcation would be far more
complex and diﬃcult to understand without the high-level description pro-
vided by >>. For example, the following is a speciﬁcation of this behaviour
that avoids the use of >>,
( pick stick1 ; pick stick2 ; i ; ( put stick1 ; stop ||| put stick2 ; stop ) )
[] ( pick stick2 ; pick stick1 ; i ; ( put stick1 ; stop ||| put stick2 ; stop ) )
and more complex speciﬁcations can be given.
2.3.8 Syntax of pbLOTOS
This section brings together the constructs that we have introduced to give
an abstract syntax for pbLOTOS. The syntax deﬁnes an arbitrary pbLOTOS
speciﬁcation S ∈pbLOTOS as follows.
S ::= B | B where D
D ::= ( P [x1, . . . , xn] := B ) | ( P [x1, . . . , xn] := B ) D
B ::= stop | exit | a ; B | B1 [] B2 | B1 |[x1, . . . , xn]| B2 |
B1 >> B2 | hide x1, . . . , xn in B | B [y1/x1, . . . , yn/xn] |
P [x1, . . . , xn]
a ∈Act ∪{i}, xi, yi ∈Act, D ∈DefList (the set of pbLOTOS deﬁnition lists),
P ∈PIdent (the set of process identiﬁers) and B ∈Beh. The set of pbLOTOS

2.3 Primitive Basic LOTOS
51
deﬁnitions is denoted Defs. Also note that the body of a deﬁnition (denoted
B above) could contain a reference to the process identiﬁer (P), thus setting
up a recursive behaviour.
So, the top-level structure of a pbLOTOS speciﬁcation (the ﬁrst clause) is
either a behaviour or a behaviour and an associated list of process deﬁnitions.
Deﬁnitions have the expected form. There can be many such deﬁnitions. Be-
haviours are the main syntactic construct; they can be constructed using any
of the operators and constructs that we have introduced.
In many circumstances we simplify the expression of action sets and map-
pings in parallel composition, hiding and relabelling operators, as follows,
B1 |[G]| B2 ≜B1 |[x1, . . . , xn]| B2
where, G = { x1, . . . , xn }
hide G in B ≜hide x1, . . . , xn in B
where, G = { x1, . . . , xn }
B [H] ≜B [y1/x1, . . . , yn/xn]
where, H : Act ∪{i, δ} −→Act ∪{i, δ}
and
H(a) ≜if a = xi (1 ≤i ≤n) then yi else a
We typically simplify presentation, by assuming the following operator prece-
dences,
action preﬁx > choice > parallel composition > enabling > hiding >
relabelling
where A > B states that A binds more tightly than B. So, for example, the
expression:
hide y in y ; x ; stop [] z ; exit ||| x ; exit >> z ; stop
would be fully parenthesised as:
hide y in ( ( ( (y ; (x ; stop)) [] (z ; exit) ) ||| (x ; exit) ) >> (z ; stop) )
It should also be pointed out that the diﬀerent operators of pbLOTOS can
be subdivided according to their character. For example, we can view the
operators, stop, action preﬁx, choice and process instantiation as “low-level”
(more primitive) operators, whereas the operators, such as parallel compo-
sition, enabling, hiding and relabelling, can be viewed as more “high-level”
operators. This is in the sense that the high-level operators facilitate high-
level speciﬁcation structuring. Such high-level structuring may, for example,
reﬂect real-world identiﬁable components. Identiﬁcation of such components
in speciﬁcations using just low-level operators is often less straightforward.
In fact, a behaviour expressed using high-level operators can typically be
mapped to an equivalent behaviour expressed purely in terms of the low-level

52
2 Process Calculi: LOTOS
operators. A very important example of such a mapping is the expansion law
for a calculus [101, 148], which relates parallel composition to action preﬁx
and choice. In eﬀect, the expansion law realises the interleaved interpretation
of parallelism. As a reﬂection of this, parallel composition cannot so naturally
be viewed as a high-level operator when true concurrency semantics are being
considered, which they are in Chapter 4.
The term monolithic speciﬁcation is often associated with a speciﬁcation
expressed purely in terms of the low-level operators. Thus, there is a clear
distinction between speciﬁcations expressed in a constraint-oriented style, as
highlighted in Section 2.3.6.4, and those expressed in a monolithic style.
2.4 Example
The following is a speciﬁcation in pbLOTOS of the behaviour of the commu-
nication protocol with reliable acknowledgement. The top-level behaviour of
the protocol is speciﬁed as a process called Protocol.
Protocol [start, get, put] :=
start ;
hide send, receive, sendAck, receiveAck in
( ( Sender [get, send, receiveAck] ||| Receiver [put, receive, sendAck] )
|[send, receive, sendAck, receiveAck]|
DupMedium [send, receive, sendAck, receiveAck] )
So, the action start initiates the behaviour of the protocol. This causes the
processes Sender, Receiver and DupMedium to be invoked according to the
required parallel composition. Notice, all the actions send, receive, sendAck
and receiveAck are hidden from outside the protocol. Such hiding reﬂects the
fact that the actions involved in implementing the protocol are hidden from
users of the protocol. The behaviour of the sender could be speciﬁed as follows
(this is the behaviour we discussed earlier).
Sender [get, send, receiveAck] :=
get ; send ; Sending [get, send, receiveAck]
Sending [get, send, receiveAck] :=
hide timeout in ( receiveAck ; Sender [get, send, receiveAck]
[] timeout ; send ; Sending [get, send, receiveAck] )
The behaviour of the receiver could be speciﬁed as follows.
Receiver [put, receive, sendAck] :=
receive ; put ; sendAck ; Receiver [put, receive, sendAck]

2.4 Example
53
The top-level behaviour of the medium could be speciﬁed as
DupMedium [send, receive, sendAck, receiveAck] :=
Medium [send, receive] ||| AckMedium [sendAck, receiveAck]
which in turn uses the following sending medium,
Medium[send, receive] :=
send ;
( i ; Medium [send, receive]
[] receive ; Medium [send, receive] )
and the following acknowledgement medium,
AckMedium [sendAck, receiveAck] :=
sendAck ; receiveAck ; AckMedium [sendAck, receiveAck]
Sender
timeout
Receiver
Medium
AckMedium
DupMedium
receiveAck
send
receive
sendAck
Protocol
get
put
start
Fig. 2.26. Box Diagram of the Communication Protocol
We can explicitly depict the structure of the protocol speciﬁcation using a box
diagram, such as in Figure 2.26. This diagram shows the process structure
of the speciﬁcation; you should notice that the structure closely resembles
our original depiction of the protocol in Figure 2.1. The process Sending is

54
2 Process Calculi: LOTOS
not included in this diagram as it sets up a mutual recursion with Sender,
which is diﬃcult to depict. Such diagrams as these are only really useful for
representing static process structure, the dynamics of process instantiation
quickly become unrepresentable.
The interface of each process is directly represented. For example, the
process protocol has three external gates, start, get and put, which are distin-
guished from internal gates by being linked to the exterior of the Protocol box.
In addition, the fact that subprocesses interact on external gates is indicated
by a line segment, e.g. the attachment of get to Sender. In contrast, start
is not interacted with by any subprocess. All actions in the speciﬁcation are
depicted (apart from the i action in Medium). Notice also that the diagram
shows that timeout is completely internal to the process Sender and that the
gates receiveAck, send, receive and sendAck are hidden from the interface
of the process Protocol.
Finally, the top-level behaviour of the protocol speciﬁcation will invoke
the process Protocol and thus initiate its evolution, e.g.
Protocol [sstart, ssend, rreceive]
where the external gates of the protocol have been renamed, start to sstart,
get to ssend and put to rreceive.

3
Basic Interleaved Semantic Models
This chapter considers two of the main semantic models that can be associated
with LOTOS. We begin by discussing the motivation for giving semantics
to speciﬁcation notations and then we discuss the relevant semantics: trace
semantics (in Section 3.2) and labelled transition systems (in Section 3.3). Note
also that two further semantics are introduced, event structures, in Chapter
4, and trace-refusals, in Chapter 5.
In addition, as an illustration of the value of semantic models, Section 3.4
considers how tools to analyse the behaviour of speciﬁcations (i.e. veriﬁcation
tools) can be developed from these semantic models.
3.1 A General Perspective on Semantics
3.1.1 Why Semantics?
The constructs of speciﬁcation and programming languages are chosen to ease
the task of system speciﬁcation. They are “natural” at the level of the system
developer’s view of computer systems. This is reﬂected in the “high-level”
speciﬁcation constructs oﬀered by LOTOS, e.g. parallel composition, sequen-
tial composition etc. In contrast, semantic models are not intended to be
natural vehicles for speciﬁcation; rather they express the “meaning” of speci-
ﬁcations. This is similar to the way in which execution of a program expresses
the meaning of a program; it is what the program does; e.g. the meaning of
a hello world program is to output the words “hello world” and then termi-
nate. In this sense, semantics are the machine code of formal speciﬁcation;
they express what a speciﬁcation does. This interpretation is reﬂected in the
terminology that is often associated with semantics; a semantics is sometimes
referred to as a model or even an implementation of a speciﬁcation.
It is mportant to note though that, semantics deﬁne mathematical models
of the meaning of speciﬁcations and, thus, the meaning of speciﬁcations can be

56
3 Basic Interleaved Semantic Models
analysed. As an initial example, we might deﬁne the meaning of the LOTOS
behaviour,
x ; y ; stop [] z ; w ; stop
as the following set,
{ ϵ , x , z , xy , zw }
which deﬁnes the possible “linear” sequences of actions, or executions, that
the behaviour can perform. The symbol ϵ denotes an empty sequence / trace.
Notice, the set reﬂects all possible positions in the evaluation of the behaviour,
even before any evaluation has occurred, i.e. after ϵ. Thus, it represents all
possible complete or partial executions of a system. This reﬂects the char-
acteristics of nontransformational (reactive) systems, as discussed in Section
1.2.
Perhaps the most signiﬁcant value of semantics is that they enable the
meaning of diﬀerent speciﬁcations to be compared and allow us to answer
questions such as: are two speciﬁcations the same or alternatively are they
developments / reﬁnements of each other? For example, we might want to
view the following pairs of LOTOS behaviours as equal, because “intuitively”
we can see that they have the same meaning.
( x ; y ; stop ) [] ( z ; w ; stop )
and
( z ; w ; stop ) [] ( x ; y ; stop )
( x ; x ; stop )
and
( x ; x ; stop ) [] ( x ; x ; stop )
( x ; y ; stop ) || ( y ; x ; stop )
and
stop
( x ; stop [] y ; stop ) || x ; stop
and
x ; stop
Such relating of speciﬁcations is not possible without semantics, because
purely syntactic comparison will distinguish the pairs. In contrast, if we were
to compare the trace sets of the pairs, they would be equal. Thus, a trace
semantics would equate the two speciﬁcations in each pair, as we require.
It is also worth pointing out that the ﬂip side of knowing what syntactic
structures are equivalent is locating what structures are to be diﬀerentiated.
For example, an obvious approach to obtaining equality in a syntactic setting
is to directly identify syntactic laws that characterise how behaviours relate,
in the spirit of the proof rules we discussed in Section 1.4. An obvious such
law is distributivity of ; through []. However, this does not in general hold.
That is,
x ; ( B [] B′ )
and
x ; B [] x ; B′
should be distinguished because they have diﬀerent observable behaviour.
Other behaviours that we may or may not want to equate are:

3.1 A General Perspective on Semantics
57
x ; stop ||| y ; stop
and
( x ; y ; stop ) [] ( y ; x ; stop )
( x ; y ; stop ) [] ( x ; z ; stop )
and
( i ; x ; y ; stop ) [] ( i ; x ; z ; stop )
A principle, which all our semantics adhere to, and which is illustrated in
the above trace semantics examples, is to abstract away from syntactic com-
parison and rather express the meaning of syntactic expressions in terms of
how they “can behave.” We model expressions in terms of what actions they
can or cannot perform and in what order these actions can be performed.
Thus, in analogy with state machines, where behaviour expressions are seen
as states and actions oﬀers as transitions from states to states, we are inter-
ested in relating the “labelled transitions”, rather than the states (which are
the syntactic structures). It is in fact possible to regain syntactic relation-
ships between expressions by axiomatizing particular semantic relationships,
i.e. identifying proof rules. But, this would only be done alongside identiﬁ-
cation of a “behavioural” semantic relationship, which would be used as a
yardstick for assessing the correctness of the syntactic rules.
We should also point out that equality is not the only relationship that we
are interested in verifying. For example, we might want to show that a partic-
ular speciﬁcation is a reﬁnement of a second speciﬁcation. As a reﬂection of
this, a semantic model for a speciﬁcation language will typically have a num-
ber of correctness relations associated with the semantics. These characterise
certain intuitive relationships between speciﬁcations. For example, notions of
equivalence based on the observable behaviour are deﬁned. These characterise
when two processes cannot be distinguished by some external observer. There
are also equivalences based on the testing of processes; see [89] and Chapter
5.
3.1.2 Formal Deﬁnition
More formally, we can think of a semantic notation as just a set of descriptions,
each description being a particular model in the semantics. We denote the
set of all semantic notations as SN and for a particular semantic notation
sn ∈SN, a semantic map, typically denoted J K, maps speciﬁcations in a
formal technique, say ft, into the semantic notation. Thus, the semantic map
is typed as follows,
J K : ft −→sn
So, a semantic map is just a function from elements of ft to elements of sn;
it deﬁnes how formal speciﬁcations can be mapped to semantic descriptions.
For example, in Section 3.2 we deﬁne a semantics,
J Ktr
which, if applied to the behaviour

58
3 Basic Interleaved Semantic Models
P := ( x ; y ; stop ) [] ( z ; w ; stop )
will map it to the trace set that we highlighted earlier; i.e.
J P Ktr = { ϵ , x , z , xy , zw }
As stated already, a semantics will typically incorporate an associated set
of development relations. Thus, we can think of a semantics for a formal
technique ft, which we denote S, as having the following general form,
S ∈SN×SM×P(DEV)
where SN is the set of all semantic notations, SM is the set of all semantic maps
and DEV is the set of all development relations (we use the term development
relation to embrace all possible correctness relations, e.g. equivalences and
reﬁnement relations, and to emphasise their role in the process of system
development). Thus,
Str = ( P(T ) , J Ktr , {≤tr, ≍tr} )
is a typical semantics. T is the trace-setting notation that we have been re-
ferring to and ≤tr and ≍tr are development relations, which we discuss in
Section 3.2.3.
As yet, we have not put any constraints on the properties that the cho-
sen development relations should have. However, diﬀerent classes of devel-
opment will typically have diﬀerent properties. In particular, DEV contains
reﬁnement relations, equivalences and relations that can broadly be classed
as implementation relations [122], such as the LOTOS conformance relation
conf; see Section 5.1.6.1. These diﬀerent classes of development are best distin-
guished by their basic properties. Reﬁnement is reﬂexive and transitive (i.e. a
preorder); equivalences are reﬂexive, symmetric and transitive; and implemen-
tation relations only need to be reﬂexive. The distinction between reﬁnement
and implementation relations is particularly signiﬁcant; transitivity is a cru-
cial property in enabling incremental development of speciﬁcations towards
realisations and implementation relations are typically lacking in this respect.
We must also consider what interpretation of equivalence (which we denote
≍) we should adopt. The interpretation that we choose is
X ≍dv X′ iﬀ∀Y, Y dv X ⇐⇒Y dv X′
where dv is a development relation; i.e. dv ∈DEV and ≍dv∈DEV . Thus, two
equivalent descriptions have identical development sets; i.e. every description
that is a development of one will be a development of the other. This demon-
strates that during system development we really can choose any one of a set
of equivalent speciﬁcations without aﬀecting the possibilities of future devel-
opment.
≍dv can easily be shown to be an equivalence and, in addition, no proper-
ties are required of dv for ≍dv to be an equivalence. In particular, even if dv
is not reﬂexive or transitive, ≍dv will be an equivalence.

3.1 A General Perspective on Semantics
59
Another standard interpretation of equivalence between speciﬁcations is
that they are developments of each other. With transitivity of dv, this inter-
pretation gives us that two speciﬁcations in any cycle by the relation dv are
equivalent.
However, if dv is in fact a preorder, we can obtain that ≍dv = dv ∩dv−1.
Thus, we use these two interpretations interchangeably if development is a
preorder. We summarise these results in the following proposition.
Proposition 1
(i) ≍dv is an equivalence.
(ii) If dv is a preorder then ≍dv = dv ∩dv−1.
(iii) If dv is a preorder and ≍dv is taken as identity then dv is a partial order.
Proof
The only part of this proposition that is not completely trivial is (ii), so we
include this proof. Firstly, assume X ≍dv X′, but because, by reﬂexivity,
X dv X, this gives us X dv X′ and similarly, X′ dv X. Secondly, assume
X dv ∩dv−1 X′ and take Y , such that Y dv X, but using our assumption
and transitivity of dv we get Y dv X′ and similarly, we can show that Y dv X′
implies Y dv X.
⃝
Congruence. A property that would be particularly nice for development
relations to satisfy is congruence. This has a very basic relationship to incre-
mental development. We apply the term congruence to equivalence relations
and precongruence to preorders. Let us consider congruence ﬁrst. This is best
explained in terms of behaviours with holes. For example, the following be-
haviour,
( x ; y ; stop ) [] [·]
contains a hole, indicated by [·]. An arbitrary behaviour can be inserted into
this hole; for example,
z ; stop
(*)
could be inserted to obtain,
( x ; y ; stop ) [] ( z ; stop )
(+)
Behaviours with holes are called contexts and denoted C[·]. For example, if,
C[·] = ( x ; y ; stop ) [] [·]
then C[·] is the context into which the behaviour (*) can be placed, i.e.
C[z ; stop], to obtain behaviour (+).

60
3 Basic Interleaved Semantic Models
Deﬁnition 1
Congruence states that given B and B′ such that B ≍B′ (where ≍is an
equivalence), then, for any context C,
C[B] ≍C[B′]
Thus, equivalence is preserved when placed in any context. This property is
actually a constraint on the operators of a language. To preserve it, we need
to know that for any operator, + say (here we consider only binary operators,
but this can be generalised to any arity), and any behaviour B, if B′ ≍B′′
then
B + B′ ≍B + B′′
Thus, B+[·] plays the role of the context. If this property holds, we say that ≍
is a congruence over the operators of the particular language being considered.
Although in some places in this book we use the term more liberally,
mathematically speaking, an equivalence does not have the right to be viewed
as an identity relation unless it can be shown to be a congruence. The deﬁning
property of equality is that like can be substituted for like without changing
the meaning of an expression. Congruence is the property that ensures this is
indeed the case.
We can similarly deﬁne a precongruence, by replacing the relation ≍with
a preorder, say ⊑.
Deﬁnition 2
A preorder ⊑is a precongruence if, for any context C[·], if B ⊑B′ then
C[B] ⊑C[B′].
One reason why congruence is such an important property is that it enables
incremental system development. For example, if we wish to develop a com-
ponent of a complete system, then congruence implies that, if we can derive
a relationship between the component and its replacement, then we will ob-
tain the same relationship between the entire system and the system with the
component replaced.
Two particular ways in which congruence is important are in (i) reusing
known relationships and (ii) enabling strategies of stepwise reﬁnement to im-
plementation. Speciﬁcally, (i), if a property, such as equivalence or reﬁnement,
can be determined between two speciﬁcations B and B′, by perhaps some com-
plex proof, we can infer a property between larger speciﬁcations, if the two
speciﬁcations are placed in a particular context. This suggests that, if known
results are stored, signiﬁcant reuse can be obtained.
Congruence enables us to, (ii), employ a stepwise reﬁnement strategy in
which we assume some initial speciﬁcation is identiﬁed, S say. Then we can
construct implementations as follows. First, decide on a construction C to use
and write a subspeciﬁcation, S′, such that C[S′] is equivalent to S. Now, if
we can identify an implementation of S′, I say, we know how C[I] is related

3.1 A General Perspective on Semantics
61
to S. In addition, if at any stage it is not feasible to implement the identiﬁed
component, the reﬁnement process can be applied recursively.
Axiomatisation. One consequence of deﬁning behavioural semantics, such
as those being considered here, is that syntactic rules (i.e. proof rules, as
discussed in Section 1.4) between behaviours can be derived that reﬂect these
semantics. The identiﬁcation of such a set of rules is called an axiomatisation
of a language. For example, a rule that we might want to hold of a particular
behavioural equivalence ≍is
a ; i ; B ≍a ; B
i.e. a hidden action, which is guarded by another action, can be removed. This
rule could be justiﬁed because the observable behaviour of the two syntactic
expressions would be the same. Two properties associated with axiomatisation
are soundness and completeness.
The former of these is an absolute requirement, whereas the latter is de-
sirable, but sometimes not achievable. Intuitively, soundness requires that all
the laws in an axiomatisation are valid and completeness ensures that every
true statement, in a particular domain, can be veriﬁed using the laws. Ax-
iomatisation is extremely important and amongst other things plays a central
role in proof-based veriﬁcation.
The following three books [96], [171] and [148] have made extensive investi-
gations of axiomatisation of behavioural semantics in process calculi settings.
In particular, the rule we quoted above is an example of one of Milner’s tau
laws (i is written τ in CCS). We do not cover the topic of proof rules as ex-
tensively. One reason for this is because so much attention has been given to
such approaches in the CCS and CSP settings. However, in addition, axioma-
tisation of LOTOS is in fact diﬃcult (as indicated by the diﬃculty in ﬁnding
congruence relations for LOTOS; see, for example, Section 5.1.7). Further-
more, as discussed in Section 1.4, our emphasis in this book is on automatic
veriﬁcation rather than proof.
3.1.3 Modelling Recursion
One of the most diﬃcult aspects of deﬁning semantics is modelling recursive
behaviour. One reason for this is that some pbLOTOS speciﬁcations are inher-
ently inﬁnite state and, thus, all semantic models must be capable of handling
inﬁnite structures. This implies that inﬁnite trees, inﬁnite graphs and inﬁnite
sets of traces must be considered.
In our handling of recursion we only consider directly recursive deﬁnitions,
such as P := x ; y ; P, rather than mutually recursive deﬁnitions, such as
P := x ; y ; Q and Q := z ; P. However, the approaches that we present could
easily be extrapolated to sets of mutually recursive deﬁnitions.
Modelling recursion typically implies that ﬁxed point theory must be used.
This concerns ﬁnding solutions of equations of the form:

62
3 Basic Interleaved Semantic Models
E = F(E)
i.e. given some function F, ﬁnd an object E such that application of the
function to the object leaves the object unchanged. In our setting, the solution
E here is a semantic model. The point is that we can think of a recursive
deﬁnition as having the form,
P := F(P)
where F is the body of the behaviour of the deﬁnition. For example, F would
correspond to the context x ; y ; [·] in the process deﬁnition P := x ; y ; P. A
solution for P will be a semantic structure that is a ﬁxed point of F.
In certain circumstances we have to impose constraints on the recursive
deﬁnitions that we can interpret in this way. For example, consider a deﬁnition
such as,
P := P
In terms of our abstract syntax, this is syntactically well formed, but as a
recursive deﬁnition there is something odd going on: this deﬁnition has more
than one solution. In fact, any arbitrary model can be seen as a solution of
the equation. The problem is that the equation is under-deﬁned and does
not identify a solution precisely enough. There are a number of approaches
to handling this problem; one is to ban such deﬁnitions and only characterise
the meaning of more well-behaved recursive deﬁnitions; alternatively, a unique
solution to the deﬁnition can be selected from the set of possible solutions in
some uniform way. For example, in [96] both approaches are considered. First
in deﬁning a trace semantic meaning for CSP, Hoare imposes a guardedness
condition on processes, whereas, in deﬁning a full failures semantics, the most
nondeterministic process is selected as the solution.
The concept of guardedness is quite straightforward.
Deﬁnition 3 (Guarded)
A process invocation P is guarded in B if each reference to P is within some
behaviour expression a ; B′, where a ∈Act ∪{i}.
Notice that the guard here can be either an internal or external action. This
will not always be suﬃcient. In circumstances where we only want to model
external behaviour, e.g. we might have a syntactic rule such as,
B ≡i ; B
our guardedness constraint will have to be stronger than Deﬁnition 3. In such
circumstances deﬁnitions such as
P := i ; P
and
P := i ; P [] B
would have to be ruled out. Stronger notions of guardedness can be deﬁned
to do this, although hiding can make this problematic. Such deﬁnitions are
beyond the scope of this book.

3.2 Trace Semantics
63
3.1.4 What Makes a Good Semantics?
We look at a number of diﬀerent semantic models for LOTOS. Before we do
this, it is worth considering what constitutes a “good” semantics, and what
criteria we can apply to the choice of semantics. The following issues can be
highlighted.
•
A semantics should enable properties of a speciﬁcation to be veriﬁed, e.g.
that the speciﬁcation cannot do a particular “bad thing,” such as deadlock.
•
The semantics should be unambiguous; i.e. it should not be possible to
relate a speciﬁcation to two diﬀerent meanings.
•
The semantics must be intuitively meaningful. Perhaps the most impor-
tant criterion for the choice of semantics is that it correctly reﬂects the
“meaning” that is trying to be extracted from a speciﬁcation. Thus, the
semantics should relate speciﬁcations that are “intuitively” the same.
•
A semantics must distinguish speciﬁcations that are diﬀerent. This is just
as important as the previous point. If a semantic map relates two “intu-
itively” diﬀerent speciﬁcations to the same semantic model we would not
be able to diﬀerentiate between the speciﬁcations in our semantic world.
This would, for example, mean that any property that held about one
of the speciﬁcations would hold for the other. Thus, we must be careful
to ensure that our semantics are fully expressive, in the sense that they
distinguish between enough speciﬁcations.
An obvious question that arises from these points is: what is an appropriate
intuitive meaning? There are actually a number of diﬀerent such intuitions.
Most of our semantics though seek to describe only the observable behaviour
of systems (this applies less to the true concurrency model). Thus, we seek
to locate semantics that model the observable behaviour of systems and that
abstract from the internals of how this behaviour is obtained.
3.2 Trace Semantics
3.2.1 The Basic Approach
This is the ﬁrst semantic model that was considered for process calculi [95]
and it remains the simplest approach that is in use. The idea is to model
the semantics of speciﬁcations as the set of all possible linear sequences (or
traces) of actions that the speciﬁcation can perform. The “all possible” here
is important. In particular, you should notice that we are not solely interested
in complete traces, i.e. sequences of actions that cannot be extended. Rather,
we are interested in all possible intermediate and complete traces.
As a reﬂection of the fact that trace semantics consider linear traces, such
approaches are frequently referred to as linear time models. As suggested
earlier, we denote the trace semantic map as

64
3 Basic Interleaved Semantic Models
J Ktr : pbLOTOS −→P(T )
i.e. it maps primitive basic LOTOS speciﬁcations to trace sets. The following
pbLOTOS behaviours,
P0 := x ; y ; stop
P1 := ( x ; y ; stop ) [] ( z ; w ; stop )
P2 := ( z ; w ; stop ) [] ( x ; y ; stop )
P3 := x ; x ; stop
P4 := ( x ; x ; stop ) [] ( x ; x ; stop )
P5 := stop
are mapped to the following trace sets,
J P0 Ktr = { ϵ , x , xy }
J P1 Ktr = { ϵ , x , z , xy , zw }
J P2 Ktr = { ϵ , x , z , xy , zw }
J P3 Ktr = { ϵ , x , xx }
J P4 Ktr = { ϵ , x , xx }
J P5 Ktr = { ϵ }
Notice that we have now equated two of the pairs of speciﬁcations that we
highlighted as intuitively equal; i.e. J P1 Ktr = J P2 Ktr and J P3 Ktr = J P4 Ktr.
The properties of sets play an important role in making these semantic de-
scriptions equal; i.e. sets are unordered and duplicates are removed.
Also notice that the behaviour stop is mapped to the trace set which
includes just one trace: ϵ, the empty trace. It is a rule of trace semantics
that the trace set of any behaviour will contain the empty trace, because all
behaviours can perform an empty trace.
Process invocation and action relabelling can also be easily modelled using
trace semantics. Consider the following recursive process deﬁnition,
P [z, w] := z ; w ; P [w, z]
Notice how the action names are ﬂipped on recursive invocation. So, invo-
cation of this behaviour with the action z relabelled to x and the action w
relabelled to y will have the following inﬁnite trace model,
JP [x, y]Ktr = { ϵ , x , xy , xyy , xyyx , xyyxx , xyyxxy , xyyxxyy , . . . }
Inﬁnite models typically arise when recursive behaviour is considered. We
consider how to handle such behaviour shortly.
As already indicated, we are interested in modelling just the observable
behaviour of pbLOTOS speciﬁcations. As a reﬂection of this, internal actions
do not ﬁnd their way into trace sets. For example, the behaviours

3.2 Trace Semantics
65
P0 := i ; y ; stop
P1 := ( x ; i ; stop ) [] ( z ; w ; stop )
P2 := i ; i ; stop
P3 := hide z in ( x ; z ; y ; stop )
are mapped to the trace sets:
J P0 Ktr = { ϵ , y }
J P1 Ktr = { ϵ , x , z , zw }
J P2 Ktr = { ϵ }
J P3 Ktr = { ϵ , x , xy }
Notice that this gives us equality between behaviours such as
i ; i ; stop ,
i ; stop
and
stop
and also, between behaviour such as
x ; y ; stop
and
hide z in ( x ; z ; y ; stop ).
Because of the suppression of internal actions, the point of sequential compo-
sition is not directly reﬂected in trace semantics. Remember that successful
termination in pbLOTOS has the form:
B1 >> B2
where the behaviour B1 enables the behaviour B2 when all concurrent threads
in B1 have performed an exit and an internal action is generated when control
is handed from B1 to B2. For example, the behaviour,
P := ( x ; y ; exit [] z ; exit ) >> ( w ; stop )
will map to the following trace set,
J P Ktr = { ϵ , x , z , xy , zw , xyw }
However, successful termination actions, denoted δ, can arise in trace sets.
Such actions will only appear when an exit is left “dangling” in a behaviour,
i.e. is not matched by a sequential composition. Thus, the behaviour
Q := ( x ; y ; exit ) [] ( z ; exit )
will map to the following trace set,
J Q Ktr = { ϵ , x , z , xy , zδ , xyδ }
Trace semantics typically model concurrency using interleaving (an exception
is found in [139]). This view of concurrency ﬁts naturally with the linear trace
approach. For example, the behaviours

66
3 Basic Interleaved Semantic Models
P0 := x ; stop ||| y ; stop
P1 := ( x ; stop ) ||| ( y ; z ; stop )
P2 := ( x ; z ; stop ) |[z]| ( y ; z ; stop )
P3 := ( x ; y ; z ; stop ) || ( x ; y ; stop )
are mapped to the following trace sets,
J P0 Ktr = { ϵ , x , y , xy , yx }
J P1 Ktr = { ϵ , x , y , xy , yx , yz , xyz , yxz , yzx }
J P2 Ktr = { ϵ , x , y , xy , yx , xyz , yxz }
J P3 Ktr = { ϵ , x , xy }
3.2.2 Formal Semantics
This section gives a formal interpretation of trace semantics, which reﬂects
the intuition that we have presented in the examples of the previous section.
3.2.2.1 Preliminaries: Traces
First we need to formalise what we mean by a trace and a set of traces. The
set of all traces is denoted T ; it contains the special distinguished trace ϵ
(which denotes an empty trace) and all sequences,
x0x1x2x3 . . . xn, where xi ∈Act ∪{δ}
of observable actions or successful terminations.1 Notice that these traces are
ﬁnite; i.e. each trace represents a ﬁnite sequence of behaviour. However, the set
of all traces of a computation is likely to be inﬁnite. Thus, we model behaviour
as a (potentially) inﬁnite set of ﬁnite computations. We use σ, σ′, σ′′, σ1, σ2, . . .
to range over T and we deﬁne a number of basic operations on traces.
•
Concatenation. Two traces σ and σ′ can be concatenated by performing
the operation, σ.σ′. Formally, we can deﬁne concatenation as:
(σ1 = ϵ =⇒σ1.σ2 = σ2) ∧
(σ2 = ϵ =⇒σ1.σ2 = σ1) ∧
(σ1 = x1x2 . . . xn ∧σ2 = y1y2 . . . yn)
=⇒σ1.σ2 = x1x2 . . . xny1y2 . . . yn
As a slight abuse of notation, we write x to mean both a single action and
the singleton trace; the correct interpretation is clear from the context.
1In fact, our semantics will ensure that successful termination actions only arise
as the last element of a trace, however, for ease of presentation, we use a more liberal
deﬁnition here.

3.2 Trace Semantics
67
•
Star. Given a set A ⊆Act, we denote the set of all traces that can be
formed using actions from the set A as A∗. Formally,
A∗≜{ϵ} ∪{ x0x1 . . . xn | xi ∈A }
Using this notation we can note that T = (Act ∪{δ})∗.
A wealth of additional operators on traces is deﬁned in [96].
3.2.2.2 A Denotational Trace Semantics for pbLOTOS
The following rules deﬁne a, so called, denotational semantics for pbLOTOS.
This will realise the semantic map J Ktr and, thus, deﬁne a function from
pbLOTOS speciﬁcations to trace sets. The function is expressed by deﬁn-
ing the meaning of all the syntactic elements of the language. This is done
by traversing the abstract syntax of pbLOTOS. The mathematically correct
phrase is that the mapping is deﬁned by induction over the syntax of the lan-
guage. So, the rules work construct by construct through the language. The
rules we give are based on those presented in [120] with some inﬂuence from
similar rules presented for CSP in [96].
What we are interested in is the meaning of an arbitrary pbLOTOS spec-
iﬁcation, i.e. to evaluate J S Ktr, where S ∈pbLOTOS and J Ktr has the form:
J Ktr : pbLOTOS −→P(T )
The function J Ktr is deﬁned according to the syntactic alternatives a top-
level pbLOTOS speciﬁcation can be constructed from, i.e. according to the
ﬁrst clause in the pbLOTOS abstract syntax. Thus, we have the following
rules, which handle the two alternative forms that a top-level speciﬁcation
can take.
J B Ktr ≜BJ B K(∅)
J B where D Ktr ≜BJ B K(DJ D K)
BJ K is the semantic function that maps behaviour expressions to trace sets.
The function BJ K has two parameters: the behaviour expression to evaluate
(here B) and a set of process deﬁnitions (the second parameter is written as
a subscript of the application, e.g. J K(d)). This set of deﬁnitions is used in
the evaluation of the behaviour B, thus enabling processes deﬁned in D to be
instantiated in B. In analogy with programming language semantics d is an
environment.
The rules state that if the speciﬁcation just contains a behaviour expres-
sion, with no process deﬁnitions, then the trace model of the speciﬁcation
is given by applying BJ B K(∅) (with the deﬁnition parameter empty). Alter-
natively, if the speciﬁcation is a behaviour followed by a where clause, then
the trace model of the speciﬁcation is given by applying BJ B K(DJ D K), i.e.
evaluating behaviour B according to the declarations in D.

68
3 Basic Interleaved Semantic Models
Now we step down one level in the pbLOTOS abstract syntax to deﬁne the
meaning of lists of deﬁnitions. All we do here is to place the list of deﬁnitions
into a set, which can be accessed at a deeper level in the semantics. Thus, we
deﬁne the function
DJ K : DefList −→P(Defs)
which is deﬁned as
DJ (P := B) K ≜{ P := B }
DJ (P := B) D K ≜{ P := B } ∪DJ D K
We can now step down another level in the syntax to deﬁne the trace mean-
ing of behaviour expressions. This is the major part of the semantics and it
involves deﬁning the meaning of the function,
BJ K(d) : Beh × P(Defs) −→P(T )
which evaluates behaviour expressions. Notice that the two parameters to the
function are made explicit in the typing.
In a similar way to earlier, BJ K is deﬁned by working through the possible
syntactic forms that a behaviour expression can take. Thus, we deﬁne the
meaning of all possible formats that a behaviour expression can take.
Stop. The semantics of this behaviour are trivial; it simply yields the set
containing the empty trace. This indicates that the behaviour stop cannot
perform any nontrivial traces.
BJ stop K(d) ≜{ϵ}
Exit. The semantics of exit are only marginally more complex:
BJ exit K(d) ≜{ϵ, δ}
exit is a behaviour which can perform one of two traces: the empty trace
or a singleton trace just containing an action δ. The δ action is the special
distinguished action which denotes successful termination. The action is used
as a signal to indicate successful termination. This becomes clear when we
consider the semantics of enabling, >>, which use the δ action to initiate the
transfer of control to the enabled behaviour.
Action Preﬁx. There are two clauses for action preﬁx; the ﬁrst deals with
observable actions and the second deals with internal actions. The ﬁrst is as
follows,
BJ x ; B K(d) ≜{ϵ} ∪{ x.σ | σ ∈BJ B K(d) }

3.2 Trace Semantics
69
The trace set for action preﬁx is deﬁned by taking the traces that can be
derived from B (thus, BJ K is a recursive deﬁnition) and prepending the
action x on the front of all of them. The empty trace must also be added,
because, although BJ B K(d) will contain an empty trace, it will be lost when
x is prepended.
The second clause is as follows.
BJ i ; B K(d) ≜BJ B K(d)
Because i is not observable in trace semantics, the occurrence of such an action
is simply ignored.
Choice. Choice yields a straightforward trace semantics; it simply corre-
sponds to taking the union of the trace sets derived from the two alternative
behaviours.
BJ B1 [] B2 K(d) ≜BJ B1 K(d) ∪BJ B2 K(d)
Notice that any traces that can be performed by both B1 and B2 will be
represented by a single trace in BJ B1 [] B2 K(d) and that choice points are not
explicitly reﬂected in the semantics.
Enabling. The semantic rule for sequential composition centres on the han-
dling of the δ action.
BJ B1 >> B2 K(d) ≜
{ ϵ } ∪{ σ.x | σ.x ∈BJ B1 K(d) ∧x ̸= δ } ∪
{ σ.σ′ | σ.δ ∈BJ B1 K(d) ∧σ′ ∈BJ B2 K(d) }
Firstly, any trace from B1 that does not successfully terminate, i.e. does not
have δ as the last element, is included directly in the semantics of B1 >> B2.
These traces reﬂect the noncomplete evaluations of B1, in other words, all
the traces that B1 performs before it terminates. Secondly, all traces from B1
that ﬁnish with δ are concatenated with all traces from B2. It is important
to note that the δ action does not appear in the concatenated trace (unless it
appears in B2). In terms of the informal deﬁnition of pbLOTOS, the δ should
be transformed into an internal action. However, because internal actions are
not depicted in trace semantics, this replacement is not visible.
Parallel Composition. The semantics of parallel composition are somewhat
more complex. We need to compose the traces of B1 and B2 in such a way
that the resultant traces reﬂect the parallel composition of the two behaviours.
The basic rule is
BJ B1 |[x1, . . . , xn]| B2 K(d) ≜
{ σ | ∃σ1 ∈BJ B1 K(d), ∃σ2 ∈BJ B2 K(d) s.t. σ ∈σ1|{x1, . . . , xn, δ}|σ2 }

70
3 Basic Interleaved Semantic Models
which returns the set of all traces that are in σ1|{x1, . . . , xn, δ}|σ2 for all possi-
ble traces σ1 in BJ B1 K(d) and σ2 in BJ B2 K(d). Thus, we determine the traces
of B1 and the traces of B2; then we apply |{x1, . . . , xn, δ}| to each possible
pair of traces from the two. For each of these pairs, |{x1, . . . , xn, δ}| derives
the set of possible interleavings of the two traces subject to synchronisation
on actions from {x1, . . . , xn, δ}. Notice, in particular, that δ is included in
this synchronisation set. This is because a parallel composition only success-
fully terminates when both its constituent threads have terminated (see the
discussion in Section 2.3.7).
So, the central aspect of this deﬁnition is the mapping |{x1, . . . , xn, δ}|; it
is a function with the following type,
|A| : T × T
−→P(T )
where A ⊆Act ∪{δ}
The operator is written inﬁx, as σ1|A|σ2, and, broadly, it denotes the set of
possible interleavings of σ1 and σ2 that identify actions in A. The operator is
deﬁned as follows, where x, x′ ∈A, x ̸= x′ and y, y′ ̸∈A,
σ1|A|σ2 ≜
if (σ1 = x.σ′
1 ∧σ2 = ϵ) ∨(σ1 = ϵ ∧σ2 = x′.σ′
2) ∨
(σ1 = σ2 = ϵ) ∨(σ1 = x.σ′
1 ∧σ2 = x′.σ′
2)
then {ϵ}
otherwise { y.σ | σ ∈σ′
1|A|σ2 ∧σ1 = y.σ′
1 } ∪
{ y′.σ | σ ∈σ1|A|σ′
2 ∧σ2 = y′.σ′
2 } ∪
{ x.σ | σ ∈σ′
1|A|σ′
2 ∧σ1 = x.σ′
1 ∧σ2 = x.σ′
2 }
This deﬁnition mirrors, in some respects, the operational semantics deﬁnition
of parallel composition that we present in Section 3.3.2.2. The operator is best
illustrated through an example. Consider the behaviour
( y ; x ; z ; stop ) |[x]| ( x ; w ; stop )
Evaluation of the two component behaviours yields the following two trace
sets,
{ ϵ , y , yx , yxz }
and
{ ϵ , x , xw }
where the ﬁrst is the trace set for the left-hand behaviour and the second is
the trace set for the right-hand behaviour. Our deﬁnition of
BJ B1 |[x1, . . . , xn]| B2 K(d)
would apply |{x}| to all possible pairings of traces from the two sets (in fact,
it would apply |{x, δ}|, but because there is no exit in the original behaviour,
δ can be safely ignored). The results of these applications are:

3.2 Trace Semantics
71
ϵ|{x}|ϵ = {ϵ}
y|{x}|ϵ = {y}
yx|{x}|ϵ = {y}
yxz|{x}|ϵ = {y}
ϵ|{x}|x = {ϵ}
y|{x}|x = {y}
yx|{x}|x = {yx}
yxz|{x}|x =
{yxz}
ϵ|{x}|xw = {ϵ}
y|{x}|xw = {y}
yx|{x}|xw =
yxz|{x}|xw =
{yxw}
{yxzw, yxwz}
The deﬁnition of BJ B1 |[x1, . . . , xn]| B2 K(d) accumulates traces from the sets,
to yield
BJ y ; x ; z ; stop |[x]| x ; w ; stop K(d) =
{ ϵ , y , yx , yxz , yxw , yxzw , yxwz }
as required.
Hiding. We need an auxiliary operator in deﬁning the semantics of hiding.
The operator is denoted / and it has the type:
/ : T
× (Act ∪{δ} −→T ) −→T
The operator is written inﬁx and has two arguments: a trace and a function
from actions to traces, which is total on Act ∪{δ}. The operator returns a
new trace. Given that λ ∈Act ∪{δ} −→T , then σ/λ is deﬁned as
ϵ/λ ≜ϵ ∧
(x.σ′)/λ ≜λ(x).(σ′/λ)
Thus, the application,
σ/λ′
where
λ′(x) ≜if x = xi (1 ≤i ≤n) then σi else x
has the eﬀect of searching along the trace σ and replacing every occurrence
of an action xi with the trace σi.
The trace semantics for hiding derives all the traces from B and then
removes all occurrences of the (to be hidden) actions x1, . . . , xn from the
generated traces, by replacing xi with ϵ.
BJ hide x1, . . . , xn in B K(d) ≜{ σ/λhide | σ ∈BJ B K(d) } where,
λhide(x) ≜if x = xi (1 ≤i ≤n) then ϵ else x
Relabelling. The semantics of relabelling follow very much the same lines as
the semantics for hiding. However, rather than replacing actions with a null
trace, we replace them with the required relabelling.
BJ B[y1/x1, . . . , yn/xn] K(d) ≜{ σ/λrel | σ ∈BJ B K(d) } where,
λrel(x) ≜if x = xi (1 ≤i ≤n) then yi else x
Process Instantiation. The semantics of process instantiation are compli-

72
3 Basic Interleaved Semantic Models
cated by the need to interpret recursion. In fact, we only give a partial def-
inition of such behaviour, as the full semantics are relatively complex. In
particular, we do not consider mutual recursion, i.e. indirect recursion result-
ing from a series of process instantiations (although, generalisation to such
deﬁnitions can easily be given) and our presentation is informal. A full formal
treatment is beyond the scope of this book.
Nonrecursive process deﬁnitions can be handled very easily; i.e.
BJ P K(d) ≜BJ B K(d)
where P := B is a deﬁnition in d and P is not referenced in B
Notice that it is here, in deﬁning the meaning of process instantiation, that
we use the deﬁnitions contained in d. This rule states that the meaning of a
process instantiation is the meaning of the corresponding process body.
In contrast, the semantics of recursion (in fact, only direct recursion) is
deﬁned by
BJ P K(d) ≜
n∈N BJ f n
B(stop) K(d)
where P := fB(P) is a deﬁnition in d
Firstly, we have written the process deﬁnition in an unusual manner; viz,
P := fB(P)
fB denotes a function, which takes a process instantiation and evaluates it in
place in the body of B. In fact, fB can be thought of as a context corresponding
to the behaviour B, with holes where P is referenced. Filling these holes
corresponds to instantiating a behaviour in place for P.
We can think of a recursion as generating a series of models, which are
increasingly large; each successive model corresponds to a further unfolding of
the recursive call. This series of models is inﬁnite; i.e. we will keep on making
recursive calls and increasing the size of the resulting model. We refer to such
a series of models as a chain.
The semantic model for this behaviour will have to be an inﬁnite set; it
will be an inﬁnite set which contains all the models from all the recursive
calls, i.e. every model in the chain. The expression:

n∈N BJ f n
B(stop) K(d)
(*)
turns out to yield the least upper bound of this chain, i.e. a model which is
larger than all elements in the chain, but does not contain more than is found
in elements of the chain. It is the union of all models in the chain.
The notation f n
B is deﬁned as follows.
f 0
B(B′) ≜B′
f 1
B(B′) ≜fB(B′)
f 2
B(B′) ≜fB(fB(B′))

3.2 Trace Semantics
73
. . .
. . .
f n
B(B′) ≜fB(fB . . . (fB(B′)) . . .)
where there are n fBs on the right-hand side
This construction generates the inﬁnite chain to which we have been referring.
The chain requires a “bottom” behaviour to start from; it can be shown that
stop is the required bottom or null behaviour. Thus, in our above deﬁnition,
the chain is given by:
f 0
B(stop) , f 1
B(stop) , f 2
B(stop) , . . .
In order to prove that our deﬁnition yields the least upper bound of such a
chain we would have to consider ﬁxed point theory. This is beyond the scope
of this book; the interested reader is referred to [199].
In addition, it can be shown that, as long as the behaviour fB is guarded,
this deﬁnition of recursion is the only solution [96,120]. In fact, we would need
a strong guardedness property, because internal behaviour is not reﬂected in
trace semantics. For example, the deﬁnition:
P := ( x ; stop ) [] ( i ; P )
will have an inﬁnite number of solutions. In fact, for any B′,
x ; stop [] B′
is a solution as
( x ; stop ) [] ( i ; ( x ; stop [] B′ ) ) = x ; stop [] B′
in trace semantics.
3.2.3 Development Relations
As previously indicated, a semantics typically has three constituents: a nota-
tion in which to express semantic models, a semantic map and a set of devel-
opment relations. We have presented the ﬁrst two of these, the trace notation
T and the semantic map J Ktr. In this section we consider the third: devel-
opment relations for trace semantics. We consider the two classic relations:
trace preorder and trace equivalence. These relations deﬁne how pbLOTOS
speciﬁcations can be related using trace semantics.
3.2.3.1 Trace Preorder
Trace preorder is the basic reﬁnement relation of trace semantics; it is denoted
≤tr, and deﬁned as follows.
S ≤tr S′ if and only if J S Ktr ⊆J S′ Ktr

74
3 Basic Interleaved Semantic Models
So, S is a trace reﬁnement of S′ if and only if the traces of S are a subset of
or equal to the traces of S′. Firstly, it is easy to show that this relation is a
preorder.
Proposition 2
≤tr is (i) reﬂexive and (ii) transitive.
Proof
(i) This is trivial, because the traces of a speciﬁcation are equal to the traces
of the same speciﬁcation. (ii) This follows from transitivity of subset inclusion;
i.e. if J S Ktr ⊆J S′ Ktr and J S′ Ktr ⊆J S′′ Ktr then J S Ktr ⊆J S′′ Ktr.
⃝
The fact that the trace preorder is not symmetric is also easy to verify. Con-
sider for example the two behaviours:
Q := stop
and
P := x ; stop
we have,
J Q Ktr = { ϵ }
and
J P Ktr = {ϵ , x }
which implies that J Q Ktr ⊆J P Ktr but J P Ktr ̸⊆J Q Ktr. So, Q ≤tr P,
but, P ̸≤tr Q. As illustration of the trace preorder, consider the LOTOS
behaviours:
P1 := y ; stop
P2 := x ; stop
P3 := ( x ; stop ) [] ( y ; stop )
P4 := hide y, z in ( ( y ; x ; z ; stop ) [] ( z ; x ; stop ) )
P5 := ( x ; y ; stop ) |[y]| ( z ; stop )
P6 := ( x ; y ; stop ) ||| ( z ; stop )
The following is a subset of the trace reﬁnement relations amongst these
behaviours.
P1 ̸≤tr P2
and
P2 ̸≤tr P1
P1 ≤tr P3
and
P2 ≤tr P3
P4 ≤tr P3
and
P5 ̸≤tr P3
and
P3 ̸≤tr P5
P2 ≤tr P6
and
P4 ≤tr P6
and
P5 ≤tr P6
You should also notice that the behaviour stop is more reﬁned (by trace
preorder) than any other pbLOTOS speciﬁcation. This is because its trace
set only contains the empty trace, which is included in the trace set of all
speciﬁcations. Thus, we can reﬁne any pbLOTOS speciﬁcation to stop. This

3.2 Trace Semantics
75
is clearly not very satisfactory, as it means that during development, we can
just throw all the content of a speciﬁcation away.
The theoretical justiﬁcation for the trace preorder is that it preserves so-
called safety properties. These are properties which state that “something bad
does not happen.” For example, we might want to ensure that a particular
unwanted action, perhaps one called crash, never happens. Reﬁnement by
trace preorder cannot introduce actions. Thus, if our abstract speciﬁcation
satisﬁes a particular safety property, we know that all reﬁnements of the
speciﬁcation will satisfy the property. But, this does not prevent us from
reﬁning out all the wanted behaviour.
3.2.3.2 Trace Equivalence
As stated by Proposition 1 earlier, a preorder development relation will nat-
urally induce an equivalence between speciﬁcations. In trace semantics, the
trace equivalence, denoted ≍≤tr (or ≍tr for presentational simplicity), is in-
duced; it is deﬁned as follows.
S ≍≤tr S′ if and only if S ≤tr S′ and S′ ≤tr S
≍≤tr is reﬂexive, symmetric and transitive, so, it is an equivalence; it plays
the role of identity in the trace theory of pbLOTOS. From the deﬁnition of
the trace preorder, it can easily be seen that
S ≍≤tr S′ ⇐⇒J S Ktr = J S′ Ktr
Thus, any two speciﬁcations with equal traces are trace equivalent. This is
actually the identity that we have been using informally already; see, for
example, the discussion in Section 3.2.1.
3.2.4 Discussion
So, we have deﬁned a simple linear time semantics for pbLOTOS, Str. In its
entirety, the semantics comprises:
Str ≜( P(T ) , J Ktr , {≤tr, ≍tr} )
Thus, it contains P(T ) (a notation of semantic models), a semantic map J Ktr
and two development relations, ≤tr and ≍tr. The semantics is relatively crude;
in particular, we can make two observations.
Firstly, although preserving safety is a useful property of development,
there are many diﬀerent classes of property that we would like to preserve
during reﬁnement and safety is only one of these. For example, we would like
to preserve liveness properties, i.e. statements that “something good must
eventually happen.” The trace preorder cannot guarantee such properties, as
the required “good thing” may simply be reﬁned out during application of
≤tr.

76
3 Basic Interleaved Semantic Models
Secondly, the trace semantics equate too many speciﬁcations. They do
not enable branching points to be distinguished; in particular, they do not
enable deterministic and nondeterministic choice to be distinguished. This is
highly unsatisfactory as, from our discussions already, we have noted that
deterministic and nondeterministic choices yield a very diﬀerent observable
behaviour. We discuss this issue in more depth in Section 3.3.1.
However, in a completely deterministic setting, trace semantics are quite
satisfactory and fully characterise the behaviour of pbLOTOS. This is wit-
nessed by the fact that in [96] a reduced process calculus, which is determin-
istic, is completely characterised by a trace semantics.
As presented in [96], the trace equality relation can be axiomatised for
this deterministic language. We conjecture that similar trace-based axiomati-
sations could be developed for pbLOTOS.
We do not consider congruence issues with either trace preorder or trace
equivalence. This is for two reasons. Firstly, for the reasons just discussed,
neither are particularly useful development relations and secondly, in order to
prove congruence in recursive contexts we would have to work from a complete
ﬁxed point theory. In the absence of such a theory, we wait for the, more useful,
bisimulation relations before considering congruence issues.
3.3 Labelled Transition Systems
A more distinguishing semantics than trace semantics can be given using
labelled transition systems. This is in fact the standard semantics for LOTOS
and the one presented in the LOTOS standard [101]. It is also the most
commonly used semantics throughout the process calculi domain.
3.3.1 The Basic Approach
We have already seen a notation that is similar to labelled transition systems
(LTS), viz the behaviour trees presented in Chapter 2 (although in the gen-
eral case we deal with graphs, rather than trees). For example, the two trees
depicted in Figure 3.1 could be viewed as labelled transition systems. In such
systems, the arcs of the tree are called transitions and the actions associated
with arcs give the labelling. LTS model systems solely in terms of sequence
and choice. In particular, a branching point indicates a choice and sequence
is denoted by transitions following one another.
What though resides at the nodes of a labelled transition system? Nodes
represent states; these are locations in the computation that are nonatomic
and can consume time (remember actions and, thus, transitions are atomic).
Such states are equated with the behaviour expression reached at that point
in evaluation. Thus, the two labelled transition systems depicted in Figure 3.1
can more fully be depicted as in Figure 3.2.

3.3 Labelled Transition Systems
77
x
x
1
2
x
x
x
1
x
2
x
Fig. 3.1. Labelled Transition Systems (Deterministic and Nondeterministic)
x
x
x
1
x
2
x
1
2
x;(x  ;stop [] x  ;stop)
1
2
x  ;stop [] x  ;stop
1
x
2
x
stop
stop
1
2
1
x  ;stop
x  ;stop
2
stop
stop
x; x  ;stop [] x; x  ;stop
Fig. 3.2. Labelled Transition System with States Explicitly Represented
The term branching time model is often associated with approaches such
as labelled transition systems, where choice is explicitly represented; this is
in contrast to linear time models. As a reﬂection of this, labelled transition
systems can be seen to be more discriminating than trace semantics. For
example, the two behaviours,
x ; ( x1 ; stop [] x2 ; stop )
and ( x ; x1 ; stop ) [] ( x ; x2 ; stop )
cannot be distinguished in trace semantics; the two behaviours will both have
the trace semantic model,
{ ϵ , x , xx1 , xx2 }
However, they can be distinguished with labelled transition systems, as made
apparent in Figure 3.2. This example is a particularly good one, because from
our earlier discussion, it should be clear that we would like to diﬀerentiate
these two behaviours. This is because the ﬁrst expresses a deterministic choice,
whereas the second expresses a nondeterministic choice. If you are not happy
that these two should be distinguished, look again at Section 2.3.4 and, in
particular, consider the illustration of these two behaviours in terms of black

78
3 Basic Interleaved Semantic Models
boxes oﬀering interactions at buttons. Thus, branching time models, such as
LTS, can distinguish diﬀerent forms of choice, whereas trace semantics cannot.
3.3.2 Formal Semantics
3.3.2.1 Preliminaries: Labelled Transition Systems
We begin by giving a formal deﬁnition of a labelled transition system. The
set of all labelled transition systems is denoted LT S and ∀Sys ∈LT S, Sys is
a four tuple (S, A, T, s0), where
•
S is a nonempty set of states; these are the behaviour expressions derived
from evaluation of the speciﬁcation;
•
A is a set of actions; A contains all the actions that the speciﬁcation can
perform, including i and δ, thus, A ⊆Act ∪{i, δ};
•
T is a set of transition relations; one relation, Ta, is included for each
a ∈A; and
•
s0 ∈S is the starting state for Sys.
A transition relation Ta is a set of triples of the form (s, a, s′); i.e.
Ta ⊆S × {a} × S
where (s, a, s′) states that a transition from state s to state s′ exists, which is
labelled with action a. Transitions are usually denoted
s
a
−→s′
The labelled transition system contains suﬃcient information to construct
transition system diagrams such as those that we have seen already:
•
S deﬁnes the nodes of the diagrams;
•
A deﬁnes the allowable labels for arcs in the diagrams;
•
T deﬁnes the arcs in the diagrams; and
•
s0 deﬁnes the start point of the diagram.
A ﬁnal point to notice is that internal actions do get represented in labelled
transition systems. This is in contrast to the situation with trace semantics,
where all internal actions are ignored. This may seem surprising, as it seems to
indicate that labelled transition systems depict more than just the externally
visible behaviour of the system. This view is to some extent true. However,
in general, the occurrence of internal actions is needed in order that diﬀerent
varieties of choice (in particular, forms of nondeterminism) can be distin-
guished. Section 3.3.3 shows how development relations can be used to equate
the labelled transition systems that cannot realistically be distinguished by
the external observer. Thus, the approach in labelled transition systems is to
give a distinguishing and expressive underlying semantic notation and then
to equate, using equivalence relations, models in the notation that should be
viewed as the same.

3.3 Labelled Transition Systems
79
3.3.2.2 An Operational Semantics for LOTOS
The following rules deﬁne a, so-called, operational semantics for pbLOTOS.
This will realise the semantic map J Klts,
J Klts : pbLOTOS −→LT S
i.e. deﬁne a function from pbLOTOS speciﬁcations to labelled transition sys-
tems. As was the case with the denotational approach, these semantics will
traverse the abstract syntax of pbLOTOS. However, the rules for the seman-
tics are expressed very diﬀerently from those in the denotational setting (for
a comprehensive discussion of diﬀerent forms of semantics see [199]). Specif-
ically, they are expressed as a series of inference rules. A set of inference
rules deﬁnes a derivation system, which characterises how behaviours can be
mapped to transition systems.
Inference rules have the form:
R : P1 . . . Pn
Q
C
where P1, . . . , Pn, Q are assertions. The R here is merely a label for the rule,
the assertions P1, . . . , Pn are called the premises of R and the assertion Q is
called the conclusion or consequence of R. C is optional; it is used to express
conditions on the variables used in the inference rule (e.g. a variable v might be
stated to be in a set V ). The informal meaning of the rule is that if P1, . . . , Pn
hold then the assertion Q will hold. If the list of premises is empty, i.e.
R : Q
then the inference rule deﬁnes an axiom of the derivation system; the conse-
quence Q will always hold, as it does not depend upon any premises.
Now we come to the operational semantics for pbLOTOS. The derivation
system that we deﬁne characterises how to derive transition relations from a
pbLOTOS behaviour. The top-level structure of a pbLOTOS speciﬁcation is
either B or B where D, with D a list of process deﬁnitions. In the former
case, we can interpret the behaviour directly; in the latter case, we have to
interpret the behaviour B subject to the bindings set up in D. In our seman-
tics, the process deﬁnitions of D are assumed to be available throughout the
derivation system, enabling us to reference them in our inference rules. We
could add a mechanism to transmit these deﬁnitions through the inference
rules. However, in order not to complicate our mathematical constructions,
we have not included this. The basic derivation system follows.
Stop. The behaviour stop has no inference rule. This is because, as it cannot
perform any actions, it cannot be derived further.
Exit. The behaviour exit has the following inference rule,

80
3 Basic Interleaved Semantic Models
(EX) :
exit
δ
−→stop
This rule deﬁnes an axiom stating that a behaviour exit can always perform
a δ (remember δ is a hidden action used to signal successful termination, as
discussed in Section 3.2.2.2) and evolve to stop. So, the sole purpose of exit
is to signal successful termination and then evolve no further.
Action Preﬁx. Sequencing by action preﬁx also yields an axiom of the deriva-
tion system,
(AP) : a ; B
a
−→B (a ∈Act ∪{i})
i.e. a behaviour a ; B can always perform action a and evolve to behaviour B.
Notice, a may be an external or internal action, reﬂecting that i actions are
represented in LTS.
Choice. The behaviour of choice is expressed using two rules, which are sym-
metric. They are not axioms, because they are both dependent upon a single
premise.
(CH.i) :
B1
a
−→B′
1
B1 [] B2
a
−→B′
1
(a ∈Act ∪{i, δ})
(CH.ii) :
B2
a
−→B′
2
B1 [] B2
a
−→B′
2
(a ∈Act ∪{i, δ})
The rules state that, if either of the alternatives can perform a transition a
and evolve into a state B′, then the whole behaviour can perform a and evolve
into B′. This correctly models the eﬀect of choice, which is to select between
the two possible alternatives. Notice also that δ actions are included; thus,
successful termination of one alternative can resolve the choice.
As these are our ﬁrst nonaxiomatic inference rules it is worth at this point
clarifying the manner in which transitions are derived using such rules. So,
consider for example, the behaviour,
P := ( x ; y ; stop ) [] ( x ; stop )
We are seeking to apply one of the two rules (CH.i) or (CH.ii) in order to
determine what transitions this behaviour is able to perform. However, both
rules require properties to hold of one of the two constituent behaviours. Thus,
determining the behaviour of P induces evaluation of the behaviour of,
x ; y ; stop
and
x ; stop
We can apply our action preﬁx rule (AP) to determine what transitions can
be derived from these behaviours; i.e.,
x ; y ; stop
x
−−→y ; stop
and
x ; stop
x
−−→stop
The former of these enables us to apply (CH.i) and determine that

3.3 Labelled Transition Systems
81
P
x
−−→y ; stop
whereas the latter enables us to apply (CH.ii) and determine that
P
x
−−→stop
Thus, P oﬀers a choice of transitions (as we would expect). From this discus-
sion it should be straightforward to see that the complete transition system
for this behaviour is as depicted in Figure 3.3. Thus, the approach is, at each
stage, to apply exhaustively as many rules as possible. We can in fact put a
derivation of behaviour together into an inference tree in a similar way to that
found in logical deduction; see, for example [148].
x;y;stop [] x;stop
x
x
y
stop
stop
y;stop
Fig. 3.3. Derivation of Labelled Transition Systems from Inference Rules
Parallel Composition. The parallel composition operator has three rules.
The ﬁrst two are symmetric.
(PA.i) :
B1
a
−→B′
1
B1|[x1, . . . , xn]|B2
a
−→B′
1|[x1, . . . , xn]|B2
(a ̸∈{x1, . . . , xn, δ})
(PA.ii) :
B2
a
−→B′
2
B1|[x1, . . . , xn]|B2
a
−→B1|[x1, . . . , xn]|B′
2
(a ̸∈{x1, . . . , xn, δ})
These state how parallel composition can evolve for actions not in the syn-
chronisation set x1, . . . , xn or equal to δ. The rules state that, if one of the
constituent behaviours, say B1, can perform an action that is not in the syn-
chronisation set and evolve into B′
1, then the whole behaviour can perform
the action and evolve into B′
1|[x1, . . . , xn]|B2. It is important to note that,
in contrast to the situation with choice, an evolution of the whole behaviour
does not exclude one of the constituent behaviours. This reﬂects the nature
of parallel behaviour: B1 and B2 continue evolving in parallel.
Also notice that a δ action cannot be performed from these two rules. This
reﬂects the fact that successful termination must be synchronised on by all
parallel threads.

82
3 Basic Interleaved Semantic Models
The ﬁnal rule for parallel composition deﬁnes synchronisation behaviour,
(PA.iii) :
B1
a
−→B′
1
B2
a
−→B′
2
B1|[x1, . . . , xn]|B2
a
−→B′
1|[x1, . . . , xn]|B′
2
(a ∈{x1, . . . , xn, δ})
It states that an action in the synchronisation set can only be performed if
both constituent behaviours can perform the action and, as a consequence,
both sides of the parallel composition will evolve. The rule implies that, if one
of the behaviours is ready to perform an action in the synchronisation set (or
δ), if there are no alternative actions, it must wait for its “partner” behaviour
to oﬀer the same action. Notice also that δ actions can only be performed if
both threads can perform the action.
We have only presented inference rules for the general form of parallel
composition. The two derived operators, ||| and ||, can be given very simple
direct operational semantics. These are left as an exercise (note: you should
be careful of how you handle δ).
Enabling. There are two rules for enabling.
(EN.i) :
B1
a
−→B′
1
B1 >> B2
a
−→B′
1 >> B2
(a ̸= δ)
(EN.ii) :
B1
δ
−→B′
1
B1 >> B2
i
−→B2
(EN.i) states that B1 can evolve by performing an action a as long as the
action is not a successful termination. (EN.ii) states that B1 performing a
successful termination will cause B1 >> B2 to perform an internal action and
then evolve to B2. Thus, as stated in Section 2.3.7, successful termination
is represented by the occurrence of an i action. So, the δ action is used to
signal the point of successful termination, but, that point is represented by
an i action.
Hiding. There are two rules for hiding,
(HD.i) :
B
x
−−→B′
hide x1, . . . , xn in B
i
−→hide x1, . . . , xn in B′ (x ∈{x1, . . . , xn})
(HD.ii) :
B
a
−→B′
hide x1, . . . , xn in B
a
−→hide x1, . . . , xn in B′ (a ̸∈{x1, . . . , xn})
(HD.i) states that, if an action in the hiding set can be performed, it will be
replaced by an internal action. (HD.ii) states that any action not in the hiding
set can be performed as normal.
Relabelling. This again has two forms.
(RL.i) :
B
xj
−−→B′
B[y1/x1, . . . , yn/xn]
yj
−−→B′[y1/x1, . . . , yn/xn]
(1 ≤j ≤n)

3.3 Labelled Transition Systems
83
(RL.ii) :
B
a
−→B′
B[y1/x1, . . . , yn/xn]
a
−→B′[y1/x1, . . . , yn/xn] (a ̸∈{x1, . . . , xn})
These rules are similar to the hiding rules.
Process Instantiation. There is just one rule for process instantiation; it
assumes that the relevant process deﬁnition can be accessed.
(PI) : B
a
−→B′
P
a
−→B′
(P := B is in deﬁnition list D ∧a ∈Act ∪{δ, i})
Thus, the transitions of a process instantiation are those of the body of the
process B.
One important issue to note is that recursive behaviour is treated in a
very direct manner. In particular, a ﬁxed point characterisation is not given,
as is typically presented for a denotational semantics; rather recursion falls
out of the inference rules of process instantiation. Thus, inﬁnite behaviour of a
pbLOTOS speciﬁcation is mimicked directly in the derivation rules it induces.
Deriving a Labelled Transition System. From the inference rules deﬁned
above we can quite easily derive a labelled transition system. Firstly, we de-
termine the set of states of the transition system; we denote this as Der(S).
Assuming S has the form
B where D
(if S is just a behaviour expression, B, this can be viewed as an expression of
the above form, but with an empty deﬁnition list) we deﬁne
•
B ∈Der(S)
•
B′ ∈Der(S) ∧∃a ∈Act ∪{i, δ} s.t. B′
a
−→B′′ =⇒B′′ ∈Der(S)
where
a
−→is the smallest relation closed under the inference rules just pre-
sented. Thus, all possible derivations from B, according to transitions induced
by the above inference rules, are included. We also need to deﬁne a function
that maps behaviour expressions to their constituent actions. This is denoted
A and is deﬁned by induction over the structure of pbLOTOS behaviours, as
shown in Figure 3.4.
Notice that this will actually give an upper bound on the actions that a
behaviour can perform, as some actions may be prevented from happening
by parallel composition. Now we are in a position to derive a labelled transi-
tion system for an arbitrary pbLOTOS speciﬁcation S. Once again assuming,
without lose of generality, that S has the form B where D then J S Klts is
deﬁned as
J S Klts ≜( Der(B) , A(B) , T , B )
where

84
3 Basic Interleaved Semantic Models
A(stop) ≜∅
A(exit) ≜{δ}
A(a ; B) ≜A(B) ∪{a}
A(B1 [] B2) ≜A(B1) ∪A(B2)
A(B1 |[x1, . . . , xn]| B2) ≜A(B1) ∪A(B2)
A(B1 >> B2) ≜A(B1) ∪A(B2)
A(hide x1, . . . , xn in B) ≜A(B) \ {x1, . . . , xn}
A(B[y1/x1, . . . , yn/xn]) ≜{ H(a) | a ∈A(B) } where,
H(a) ≜if a = xi (1 ≤i ≤n) then yi else a
A(P) ≜A(B)
assuming P := B is in D
Fig. 3.4. Function for Extracting Labels from a Behaviour
T ≜{
a
−→⊆Der(B) × Der(B) | a ∈A(B) }
where
a
−→
≜{ (B1, B2) | B1
a
−→B2 ∧B1, B2 ∈Der(B) }
This completes our derivation of labelled transition systems from pbLOTOS
speciﬁcations.
3.3.2.3 Deriving Trace Semantics from Labelled Transition
Systems
We have already suggested that labelled transition systems are a more dis-
tinguishing semantics than trace semantics; i.e. they identify fewer pbLOTOS
speciﬁcations. This relationship is reﬂected by the fact that we can derive trace
semantics from labelled transition systems. We deﬁne a mapping from labelled
transition systems to trace sets. The mapping is standard and, in fact, many
researchers prefer to derive trace semantics for LOTOS indirectly via labelled
transition systems, rather than deﬁning a direct denotational semantics, such
as the one we presented in Section 3.2.2.2.
We denote the mapping,
Tr : LT S −→P(T )
which is deﬁned, for a particular LTS, say (S, A, T, s0), using a relation,
=⇒⊆S × A∗× S
which is usually written
σ
=⇒, where σ is a trace in A∗. Typical applications
of the relation might be:

3.3 Labelled Transition Systems
85
s
σ
=⇒s′
where s, s′ ∈S or,
B
σ
=⇒B′
where B, B′ ∈Beh
Remember, states and behaviour expressions are identiﬁed in labelled transi-
tion systems. So, the relation can be deﬁned interchangeably over either. The
relation s
σ
=⇒s′ should be read: from state s, the trace σ can be performed
to reach state s′. Performing a trace σ means performing the sequence of ob-
servable actions included in the trace. The relation =⇒is derived from the
relation −→; it corresponds to zero or more occurrences of the relation −→,
with internal actions possibly interleaved. To be more formal, we ﬁrst deﬁne
the meaning of applying
σ
=⇒with the empty trace.
s
ϵ
=⇒s′ iﬀs = s′ ∨
( ∃s0, . . . , sn ∈S . s
i
−→s0 ∧s0
i
−→s1 ∧. . . ∧sn
i
−→s′ )
So, s
ϵ
=⇒s and s
ϵ
=⇒s′ if s′ can be reached from s by a sequence of internal
actions. The former of these reﬂects the fact that an empty trace can always
be performed and leave the LTS in the same state, whereas the latter re-
ﬂects the fact that internal behaviour is not represented in trace semantics.
In mathematical terms, the relation
ϵ
=⇒is the reﬂexive and transitive closure
of
i
−→.
We are now able to deﬁne
σ
=⇒for any nonempty trace σ.
s
x.σ
===⇒s′ iﬀ∃s1, s2 . s
ϵ
=⇒s1 ∧s1
x
−−→s2 ∧s2
σ
=⇒s′
This deﬁnition is (tail) recursive; it deﬁnes the relation by stating how the
head of the trace, the x, should be handled and then considers recursively the
tail of the trace, the σ. The relation states that s
σ
=⇒s′ if and only if s′ can
be reached from s by performing the zero or more actions of the trace σ, with
internal actions possibly interleaved.
We can now deﬁne the function Tr; it is very simply expressed as
Tr( (S, A, T, s0) ) ≜{ σ | ∃s ∈S s.t. s0
σ
=⇒s }
So, this deﬁnes the set of all possible traces that can be derived from the
labelled transition system, (S, A, T, s0).
3.3.3 Development Relations
3.3.3.1 Basic Equivalence Relations
In some circumstances, labelled transition systems can be seen to be too
discriminating. For example, consider the following two pbLOTOS behaviours
(these were highlighted in [148]),
P1 := x ; y ; stop and P2 := ( x ; ( y ; stop [] y ; stop ) ) [] ( x ; y ; stop )

86
3 Basic Interleaved Semantic Models
which have the labelled transition systems depicted in Figure 3.5. Although
these transition systems are diﬀerent, in fact, they should not be distinguished,
as their observable behaviour will be the same. This is because, although
there are a number of diﬀerent alternative paths that can be taken through
P2, whereas there is only one possible path through P1, all these alternative
paths generate the same external behaviour.
x
y
x
y
y
x
y
Fig. 3.5. Two Labelled Transition System: P1 on the Left and P2 on the Right
What is required then is to deﬁne an identity relation that equates be-
haviours that we want to consider as identical, such as P1 and P2. So, the ap-
proach with LTS is to deﬁne a semantics that diﬀerentiates many pbLOTOS
speciﬁcations and then to identify processes again by equating LTS models.
There are two relations that are typically used to identify LTS. These are
strong and weak bisimulation;2 they are the main development relations de-
ﬁned over labelled transition systems. The latter of these is also often called
observational equivalence. The distinction between the two equivalences re-
ﬂects two diﬀerent views of the observability of systems. We discuss the two
in turn. We follow relatively closely the treatment to be found in [148], which
is the classic text on the topic.
Strong Bisimulation. As reﬂected in its name, this relation characterises a
strong interpretation of observation and, thus, induces a strong equivalence.
The following deﬁnes a strong bisimulation relation.
Deﬁnition 4
(Strong Bisimulation Relations)
A binary relation R ⊆Beh × Beh is a strong bisimulation if (B1, B2) ∈R
implies ∀a ∈Act ∪{i, δ},
1. ∀B′
1 ∈Beh, B1
a
−→B′
1 =⇒∃B′
2 ∈Beh . B2
a
−→B′
2 ∧(B′
1, B′
2) ∈R ∧
2. ∀B′
2 ∈Beh, B2
a
−→B′
2 =⇒∃B′
1 ∈Beh . B1
a
−→B′
1 ∧(B′
1, B′
2) ∈R.
2Although, we will also consider a derivation of this latter relation, called weak
bisimulation congruence, which is technically more well behaved.

3.3 Labelled Transition Systems
87
Informally, the deﬁnition states that B1 R B2 (which we have written above
as (B1, B2) ∈R) implies that any transition that B1 can perform, B2 can
perform as well and they will evolve into bisimilar states and the converse;
i.e. any transition that B2 can perform, B1 can perform and they will evolve
into bisimilar states. Bisimulation requires the states in the two speciﬁcations
to be related in such a way that the transition property holds at all states.
However, it is important to note that this relation is not driven in any way
by the syntactic relationship between states. For example, the two behaviour
expressions:
( x ; y ; stop ) || ( x ; z ; stop )
and
x ; stop
could quite reasonably be identiﬁed by a strong bisimulation relation R, even
though they are syntactically very diﬀerent. This aspect illustrates how bisim-
ulation relations abstract away from syntactic equality. Notice that the deﬁ-
nition matches internal actions and successful terminations. Thus, in order to
characterise externally observable behaviour, the strong bisimulation relation
delves into the internals of speciﬁcations. We have more to say about this
shortly.
The concept is best illustrated by example. Consider the following be-
haviours.
P1 := ( x ; y ; stop ) [] ( z ; stop )
P2 := ( z ; stop ) [] ( x ; y ; stop )
P3 := ( x ; y ; stop )
P4 := ( x ; ( y ; stop [] y ; stop ) ) [] ( x ; y ; stop )
P5 := ( x ; y ; stop ) [] ( x ; ( y ; stop [] y ; stop [] y ; stop ) )
We can identify strong bisimulation relations between a number of these be-
haviours. For example, if we denote behaviours in the evaluation of these
expressions as
P 2
1 , P 3
1 , P 1
2 , P 3
2 , P 2
3 , P 3
4 , P 4
4 , P 3
5 , P 4
5
= stop
P 1
1 , P 2
2 , P 1
3 , P 2
4 , P 1
5
= y ; stop
P 1
4
= y ; stop [] y ; stop
P 2
5
= y ; stop [] y ; stop [] y ; stop
then we can demonstrate the following strong bisimulation, denoted R′, be-
tween P1 and P2.
R′ = { (P1, P2), (P 1
1 , P 2
2 ), (P 3
1 , P 1
2 ), (P 2
1 , P 3
2 ) }
This relation is depicted in Figure 3.6(i); P1 is on the left and P2 is on the
right and the arcs between the two derivation trees highlight the states that
are identiﬁed by R′. You should convince yourself that the relationship be-
tween states highlighted does yield a strong bisimulation relation. In fact, the

88
3 Basic Interleaved Semantic Models
bisimulation between these two behaviours is very straightforward and all the
states that are related are syntactically equal (i.e. denote the same behaviour
expression) apart from the root states. This, however, is not always the case,
as we show shortly.
P1
P 1
1
P 1
3
P 1
2
x
y
z
P
P 1
P
P
y
z
2
2
2
2
2
3
x
(i)
P
P
1
P2
x
y
3
3
3
P1
P1
1
P1
3
P1
2
x
y
z
(ii)
P
P
1
P
2
x
y
3
3
3
P
P
1
P
P
x
y
(iii)
4
x
4
2
4
3
4
P
y
4
4
Fig. 3.6. Examples of Strong Bisimulation Relations
It is also easy to locate two behaviours that cannot be related by a strong
bisimulation. For example, Figure 3.6(ii) depicts an attempt to relate the
states in the two behaviours P3 and P1. All states can be related apart from
the root states. We can show this by considering Condition (2) of Deﬁnition 4.
Speciﬁcally, P1
z
−→P 3
1 , but P3 can perform no transition with this labelling;
i.e. P3
z
−−→
/ . In this example, strong bisimilarity is prevented by an initial
action oﬀer, but diﬀerences in action oﬀers farther down the derivation tree
will similarly prevent strong bisimulation. Because of the recursive nature of
the deﬁnition, states that cannot be related inside derivation trees will prevent
the root states from being related by bisimulation.
We can also show that the two behaviours that we identiﬁed earlier as
candidates for being equated are related by strong bisimulation. Figure 3.6(iii)
highlights a strong bisimulation between P3 and P4. Notice that we have

3.3 Labelled Transition Systems
89
compressed the two branches of P4 following state P 1
4 into a single branch.
This is because the two branches are actually identical. Further notice that,
apart from initial states, the relation equates single states in P3 to multiple
states in P4. This reﬂects the increased branching of P4.
Deﬁnition 4 does not yet give us an equivalence though. In particular, many
relations, including the null relation, will satisfy Deﬁnition 4. For example, we
can show that there is more than one strong bisimulation relation between the
behaviours P4 and P5; Figure 3.7 highlights two strong bisimulations for P4
and P5.
P
P
1
P
P
x
y
4
x
4
2
4
3
4
P
y
4
4
P
P
1
P
P
x
y
x
2
3
P
y
4
5
5
5
5
5
P
P
1
P
P
x
y
4
x
4
2
4
3
4
P
y
4
4
P
P
1
P
P
x
y
x
2
3
P
y
4
5
5
5
5
5
Fig. 3.7. Two Strong Bisimulation Relations
In general, there can be many strong bisimulation relations between pairs
of speciﬁcations. These arise when there is a choice of states to which to relate.
However, what we are actually interested in, is that a strong bisimulation
exists. If it does exist, we should equate the two speciﬁcations. Thus, we take
as our equivalence relation, the largest relation that satisﬁes Deﬁnition 4. This

90
3 Basic Interleaved Semantic Models
amounts to taking the union of all possible strong bisimulation relations and
states that two speciﬁcations are equivalent if at least one strong bisimulation
relation can be found between the two speciﬁcations.
Deﬁnition 5
(Strongly Bisimilar)
Two behaviours B and B′ are strongly bisimilar (also called strongly equiva-
lent), denoted B ∼B′, if there exists a strong bisimulation relation R such
that B R B′, or equivalently,
∼≜{ R | R is a strong bisimulation relation }
The following relationships between our example behaviours can be identiﬁed.
P1 ∼P2 ,
P3 ∼P4 ,
P4 ∼P5 ,
P3 ∼P5
P1 ̸∼P3, P2 ̸∼P3 , P1 ̸∼P4, P2 ̸∼P4 , P1 ̸∼P5 and
P2 ̸∼P5
Deﬁnition 5 induces a relation with a number of useful properties; see, for
example, [148]. In particular, the relation can easily be shown to be an equiv-
alence and, in addition, the relation is a congruence for the pbLOTOS oper-
ators. A proof of this fact is presented in Theorem 14.1 of Section 14.2 in the
appendix.
Theorem 3.1.
∼is a congruence over the pbLOTOS operators.
Weak Bisimulation. As indicated already, ∼induces a strong notion of
identity. In particular, it matches internal behaviour in the two speciﬁcations.
For example, none of the following three behaviours,
x ; y ; stop
,
i ; x ; y ; stop
and
x ; i ; y ; stop
are strongly bisimilar. However, in reality, there is no way that these three be-
haviours can be distinguished by an external observer. In particular, the only
way in which internal behaviour could alter a linear sequence of actions in re-
spect of an observer is that an action might be slowed. However, such slowing
is not observable in the untimed world. Implicitly, the length of time the envi-
ronment may have to wait before performing an action is not distinguishable
in the semantic models of this part.
In response to this observation, we introduce the notion of a weak bisimu-
lation between behaviours. This uses a slight enhancement of the relation
σ
=⇒,
which was introduced in Section 3.3.2.3. This is denoted
σ
=⇒⇒⇒and formally,
B1
σ
=⇒⇒⇒B2 iﬀ
( B1
σ
=⇒B2 ) ∨( B1
ϵ
=⇒B2 ∧σ = i )

3.3 Labelled Transition Systems
91
Thus, σ ∈(Act ∪{δ})∗or σ = i.3 Deﬁnition of this equivalence follows the
same lines as that of strong bisimulation. Thus, we begin by deﬁning what it
means for a relation to be a weak bisimulation relation.
Deﬁnition 6
(Weak Bisimulation Relations)
A binary relation S ⊆Beh × Beh is a weak bisimulation if (B1, B2) ∈S
implies, ∀a ∈Act ∪{i, δ},
1. ∀B′
1 ∈Beh, B1
a
−→B′
1 =⇒∃B′
2 ∈Beh . B2
a
=⇒⇒⇒B′
2 ∧(B′
1, B′
2) ∈S ∧
2. ∀B′
2 ∈Beh, B2
a
−→B′
2 =⇒∃B′
1 ∈Beh . B1
a
=⇒⇒⇒B′
1 ∧(B′
1, B′
2) ∈S.
Informally, the deﬁnition states that B1 S B2 implies that any transition
that B1 can perform B2 can perform as well, with internal actions “skipped
over” and they evolve into weakly bisimilar states and the converse. So, the
deﬁnition is identical to that given for a strong bisimulation relation apart
from the fact that the double arrow,
a
=⇒⇒⇒, is used in the target behaviour.
Remember the deﬁnition of
σ
=⇒that we gave in Section 3.3.2.3; i.e. it denotes
the occurrence of the sequence of actions in σ with internal actions possibly
interleaved. Here we are only considering singleton traces, i.e. traces of one
element. So, the deﬁnition states that, if we are trying to ﬁnd a transition
which matches
x
−−→say, we can use a transition that has internal actions
before and after x, i.e. one that satisﬁes
x
=⇒⇒⇒and hence
x
=⇒.
This concept is also best illustrated by example. Consider the following
behaviours,
P1 := x ; y ; stop
P2 := i ; x ; y ; stop
P3 := x ; i ; y ; stop
There are weak bisimulation relations between all these three behaviours.
Consider, for example, P1 and P2. The weak bisimulation relation between
these two behaviours is:
S′ = { (P1, P2), (P1, P 1
2 ), (P 1
1 , P 2
2 ), (P 2
1 , P 3
2 ) }
which is depicted in Figure 3.8(i). You should be able to convince yourself
that,
(P 2
1 , P 3
2 ), (P 1
1 , P 2
2 ), (P1, P 1
2 )
are weakly bisimilar. So, the interesting issue is relating P1 and P2, assuming
the pairs of behaviour just highlighted are related by weak bisimulation. First,
we consider how to relate P1 to P2 from left to right. We have,
P1
x
−−→P 1
1 is matched by P2
x
=⇒⇒⇒P 2
2 and (P 1
1 , P 2
2 ) ∈S′
3The abuse of notation here, whereby σ is used to denote both a trace and an
internal action, does not cause any diﬃculties.

92
3 Basic Interleaved Semantic Models
P
P
1
P
2
x
y
1
1
1
P
P
1
P
2
i
x
P
y
2
2
2
2
3
(i)
P
P
1
P
2
i
x
P
y
2
2
2
2
3
P
P
1
P
2
P
y
3
3
3
3
3
i
x
(ii)
P
P
1
P
2
x
y
1
1
1
P
P
1
P
2
P
y
3
3
3
3
3
i
x
(iii)
Fig. 3.8. Weak Bisimulation Relations
and second, we consider how to relate P1 to P2 from right to left. We have,
P2
i
−→P 1
2 is matched by P1
i
=⇒⇒⇒P1 and (P1, P 1
2 ) ∈S′
(This is why we need to move from =⇒to =⇒⇒⇒, because
i=⇒is not
deﬁned, as i is not an observable trace.)
which gives us that (P1, P2) ∈S′ as required. Figures 3.8(ii) and 3.8(iii)
highlight the, slightly more complex, weak bisimulation relations between P2
and P3 and P1 and P3.
It would though be wrong to suggest that internal behaviour cannot pre-
vent two behaviours from having a weak bisimulation relation between them;
the deﬁnition is more subtle than that. For example, consider whether a weak
bisimulation can be found which relates P1 and P4, where
P4 := ( x ; y ; stop ) [] ( i ; stop )
An attempt to identify states to locate a weak bisimulation relation, S′′ say,
between P1 and P4 is shown in Figure 3.9. You should be able to convince
yourself that the following pairs of states are weak bisimilar,

3.3 Labelled Transition Systems
93
(P 1
1 , P 1
4 ), (P 2
1 , P 3
4 ), (P 2
1 , P 2
4 ),
but what about P1 and P4? Where this fails is in trying to relate P1 and P4
from right to left. In particular, from P4 we have
P4
i
−→P 2
4
So, we require a state in P1 that will be related to P 2
4 after
i
=⇒⇒⇒is performed.
The only candidate for such a state is P1 itself as P1
i
=⇒⇒⇒P1, but, P1 and P 2
4
are not weak bisimilar, because P 2
4 cannot oﬀer an x. So, P1 and P4 cannot
be related by weak bisimulation.
We can give similar arguments to show that none of the following be-
haviours can be related by a weak bisimulation.
x ; stop [] y ; stop,
( x ; stop ) [] ( i ; y ; stop ) and
( i ; x ; stop ) [] ( i ; y ; stop )
So, weak bisimulation relations do distinguish nondeterminism due to internal
behaviour from deterministic behaviour and also diﬀerent varieties of nonde-
terminism due to internal behaviour. This relatively closely reﬂects the capa-
bilities of the external environment to observe a pbLOTOS behaviour, as we
have discussed previously. However, it should be pointed out, that some re-
searchers believe that even weak bisimulation induces an unrealistically strong
equivalence; they advocate a relation called testing equivalence, which we con-
sider in Chapter 5.
P
P
1
P
2
x
y
1
1
1
P
i
x
P
1
P
4
4
P
y
4
2
3
4
Fig. 3.9. A Failed Weak Bisimulation Relation

94
3 Basic Interleaved Semantic Models
As was the case for strong bisimulation, there can be many bisimulation
relations between pairs of speciﬁcations. So, once again, we take as our equiv-
alence relation, the largest relation that satisﬁes Deﬁnition 6.
Deﬁnition 7
(Weakly Bisimilar)
Two behaviours B and B′ are weakly bisimilar (also called observationally
equivalent), denoted B ≈B′ if there exists a weak bisimulation relation S
such that B S B′, or equivalently,
≈≜{ S | S is a weak bisimulation relation }
Deﬁnition 7 induces a relation with a number of useful properties; see [148]. In
particular, the relation can easily be shown to be an equivalence. In addition,
it can be shown that strong bisimulation implies weak bisimulation, but not
the converse; i.e.
∼⊂≈
Weak Bisimulation Congruence. However, ≈is only substitutive for a
subset of the pbLOTOS operators. The context that prevents ≈from being a
congruence is choice. As an illustration, consider the two behaviours:
x ; stop
and
i ; x ; stop
These are weakly bisimilar, because the internal action at the start of the
second expression does not aﬀect the observable behaviour. However, the two
behaviours,
x ; stop [] y ; stop
and
( i ; x ; stop ) [] ( y ; stop )
are not weakly bisimilar. The internal action in the second expression now
aﬀects the external behaviour, because an asymmetric nondeterministic choice
is created. This is an unfortunate result; however, a number of alternative
relations have been devised in order to obtain a congruent equivalence with
the ﬂavour of weak bisimulation.
Typically, these constrain the initial moves of the relation. For instance,
they may require that, if the initial states of one of the behaviours can perform
an internal action, then the other must be able to do at least one internal
action and change state, thus, preventing behaviours of the form
i ; x ; B
and
x ; B
from being related. Typical examples of such relations include Milner’s obser-
vational congruence [148] and rooted bisimulations [120].
We follow Milner [148] and deﬁne a relation, which we call weak bisim-
ulation congruence. It uses a new double arrow transition relation, which is
deﬁned as follows.
B1
σ
=⇒⇒B2 iﬀ
( B1
σ
=⇒B2 ) ∨( σ = i ∧B1
ϵ
=⇒B′
1 ∧B′
1
i
−→B2 )

3.3 Labelled Transition Systems
95
where σ ∈(Act∪{δ})∗or σ = i. Thus, =⇒⇒strengthens =⇒⇒⇒in one crucial
case; that is,
∀B , B
i
=⇒⇒⇒B, but, B
i
=⇒⇒
̸
B
Thus, =⇒⇒⇒allows i moves that stay in the same state, whereas =⇒⇒rules
out this possibility; it can only perform an i move if there is a concrete i
transition (by −−→). It is straightforward to show that
=⇒⊂=⇒⇒⊂=⇒⇒⇒
Thus, =⇒does not allow i moves (i.e. moves of the form B1
i=⇒B2), however,
=⇒⇒does allow such moves, but only when an i transition (i.e.
i
−→) can be
made and, ﬁnally, =⇒⇒⇒also allows “null” i moves between the same state.
Now, we can deﬁne weak bisimulation congruence as follows.
Deﬁnition 8
(Weak Bisimulation Congruence)
Two pbLOTOS behaviours, B1 and B2, are weak bisimulation congruent, writ-
ten B1 ≈c B2, if ∀a ∈Act ∪{i, δ},
1. ∀B′
1 ∈Beh, B1
a
−→B′
1 =⇒∃B′
2 ∈Beh . B2
a
=⇒⇒B′
2 ∧B′
1 ≈B′
2 ∧
2. ∀B′
2 ∈Beh, B2
a
−→B′
2 =⇒∃B′
1 ∈Beh . B1
a
=⇒⇒B′
1 ∧B′
1 ≈B′
2.
It is important to note that when compared with weak bisimulation, this
deﬁnition only imposes the stronger (=⇒⇒) constraint on initial moves. In par-
ticular, once initial transitions have been successfully matched, the deﬁnition
reverts to checking weak bisimulation (hence the use of ≈rather than ≈c).
Through this stronger constraint on initial moves, weak bisimulation congru-
ence prevents a behaviour with an initial i transition from being matched
with a behaviour that oﬀers no such transition. For example, the following
two behaviours,
x ; stop
and
i ; x ; stop
are not related by ≈c. However, the following,
y ; x ; stop
and
y ; i ; x ; stop
are weak bisimulation congruent.
Our choice of the name weak bisimulation congruence is justiﬁed by The-
orem 14.2 of Section 14.3 in the Appendix.
Discussion. The area of bisimulation semantics is extremely rich and the
presentation in this book has only been able to reﬂect a small part of this
area of study. We oﬀer the following pointers to other important topics.
•
In [148], Milner investigates axiomatic laws for bisimulation equivalences
and gives sound and complete axiomatisations for ﬁnite processes.

96
3 Basic Interleaved Semantic Models
•
In [148], Milner deﬁnes notions of strong and weak bisimulation up to ∼
(respectively, ≈). These relations simplify the process of locating bisimu-
lation relations.
•
Weak bisimulation can be presented in terms of just the double arrow
relation; remember we have presented it in terms of −→and =⇒⇒⇒. In
fact, presentation using only the double arrow predominates in the LOTOS
community. However, the presentations induce the same relation, although,
the deﬁnition we have favoured can be easier to handle, because it does
not require as many states to be matched.
It is also worth pointing out that bisimulation relations do not distinguish
divergent behaviour. This is in contrast to CSP failure semantics. We discuss
this issue in some depth in Chapter 7.
In summary, it should be apparent that identifying speciﬁcations based on
bisimulation equivalences is far more discriminating than using trace equal-
ity. In particular, as noted earlier, trace-based semantics can only ensure
safety properties are preserved. However, bisimulation semantics ensure both
safety and liveness properties are preserved. For example, the following two
behaviours would be identiﬁed by trace equality,
( i ; x ; stop ) [] ( i ; stop )
and
x ; stop
but, they clearly would not be identiﬁed by any of the bisimulation equiva-
lences, because the second behaviour cannot evolve into a deadlock state after
performing the i action by any of the transition relations, −→, =⇒, =⇒⇒⇒or
=⇒⇒.
3.3.3.2 Reﬁnement Relations and Induced Equivalences
The relations that we have considered in the previous section have all been
equivalences. However, in some circumstances, we would like to use reﬁnement
relations. Such relations can also be deﬁned for labelled transition systems.
Although, there has been less work on deﬁning nonequivalence relations in the
bisimulation setting (this is in contrast to the situation with trace semantics
and trace-refusals semantics), thus, our presentation is not as in depth as was
the case in the previous section. References for the relations that we consider
in this section include [73,118,148].
The ﬁrst relation we consider is called simulation and it was actually one
of the ﬁrst correctness relations that was explored with regard to process
calculi. The relation is something like half of bisimulation; i.e. bisimulation
in just one direction. It could be formulated in a weak manner, analogously
to how weak bisimulation is deﬁned, however, here we restrict ourselves to a
strong formulation. It is deﬁned as follows.
Deﬁnition 9
(Simulation Relations)
A binary relation S ⊆Beh × Beh is a simulation relation if B1 S B2 implies

3.3 Labelled Transition Systems
97
∀a ∈Act ∪{i, δ},
∀B′
1 ∈Beh, B1
a
−→B′
1 =⇒∃B′
2 ∈Beh s.t. B2
a
−→B′
2 ∧B′
1 S B′
2.
Deﬁnition 10
(Similar)
Behaviour B′ simulates behaviour B, denoted B′ ≺B if there exists a simu-
lation relation S such that B S B′, or equivalently,
≺≜{ S−1 | S is a simulation relation }
Notice that, in deﬁning ≺, we have ﬂipped the order of relations S. This is to
bring the relation into line with the direction LOTOS reﬁnement relations are
typically written. Thus, in Deﬁnition 9, B2 is the more concrete speciﬁcation
(i.e. closer to an implementation) and B1 is the abstract speciﬁcation.
It can be veriﬁed that ≺does indeed satisfy the requirements of a reﬁne-
ment relation; i.e. it is a preorder. In fact, the relation is a precongruence.
Proposition 3
(i) ≺is a preorder.
(ii) ≺is a precongruence.
Proof
The proof of (i) is straightforward. (ii) could be veriﬁed using an adaptation of
the line of reasoning given in Section 14.2 to justify that strong bisimulation
is a congruence. In fact, the required proof is a simpliﬁcation of the line of
reasoning given there in which only one direction of deduction is used.
⃝
To illustrate the relation, consider the following behaviours.
P1 := x ; y ; stop
P2 := ( x ; y ; stop ) [] ( z ; stop )
P3 := ( x ; y ; z ; stop )
P4 := ( x ; y ; stop ) [] ( x ; stop )
P5 := x ; stop
The following relationships hold:
•
(P2 ≺P1). This example shows that a new branch in a choice can be added.
In this respect, simulation is related to the extension relation, which we
consider in Section 5.1. The reason that new branches can be added is that
the relation is only checked in one direction; i.e. from P1 to P2, so, any
extra behaviour of P2 is not considered.
•
(P3 ≺P1). This example demonstrates that extra behaviour can be added
to the end of a complete trace. This is because, after performing x and y,
P1 evolves to stop and stop
a
−−→
/
for any a. Thus, state z ; stop vacuously
simulates state stop. This is another illustration of the fact that simulation
allows traces to be extended.

98
3 Basic Interleaved Semantic Models
•
(P4 ≺P1). This shows that deadlocks can be added by simulation. That is,
an environment can always perform a y after an x when interacting with
P1, but it may deadlock after performing x with P4. Simulation behaves
in this way because there only has to be one match for the transitions of
P1 in P4. Thus, the x ; stop branch of P4 is not involved in the derived
simulation relation.
•
(P5 ̸≺P1). These are not related because, after performing x, P5 cannot
perform a y.
It should be clear from these examples that simulation is not a well-behaved
reﬁnement relation. It does not preserve safety properties (i.e. traces can be
extended) and it does not preserve liveness properties (i.e. deadlocks can be
added).4 The relation is largely included here for completeness and as a his-
torical artefact.
An obvious notion of equivalence that can be obtained from simulation is
the following.
Deﬁnition 11
(Simulation Equivalent)
B and B′ are simulation equivalent iﬀB ≺B′ and B′ ≺B; i.e. simula-
tion equivalence is the relation: ≺∩≺−1, which, in terms of the notation
introduced earlier, would be written as ≍≺.
This turns out to be an inappropriate deﬁnition of equivalence in the same
way that ≺was an inappropriate notion of reﬁnement. For example, P4 ≍≺P1
because we have already justiﬁed that P4 ≺P1 and a simulation in the other
direction would relate the rightmost P4 behaviour stop to y ; stop in P1. Notice
that the simulation relations used to justify P4 ≺P1 and to justify P1 ≺P4
are diﬀerent. This example demonstrates that simulation equivalence does not
always preserve liveness properties.
It can be shown that, if the same relation is used in both directions, strong
bisimulation is obtained.
Proposition 4
R ⊆Beh × Beh is a strong bisimulation if and only if R and R−1 are simu-
lations.
Proof
See [160].
⃝
An alternative reﬁnement relation to simulation is ready simulation [192],
which coincides with, what has been called, 2/3-bisimulation [118].
Deﬁnition 12
(Ready simulation)
R ⊆Beh × Beh is a ready simulation if B1 R B2 implies ∀a ∈Act ∪{i, δ},
4Chapter 5 elaborates on the relationship between liveness and deadlocks.

3.3 Labelled Transition Systems
99
1. ∀B′
1 ∈Beh, B1
a
−→B′
1 =⇒∃B′
2 ∈Beh . B2
a
−→B′
2 ∧B′
1 R B′
2,
2. B2
a
−→
=⇒B1
a
−→.
Deﬁnition 13
(Ready similar)
≺R ≜{ R−1 | R is a ready simulation }
In terms of the examples presented earlier,
P2 ̸≺R P1,
P3 ̸≺R P1
These indicate that, as a result of adding Condition 2 in Deﬁnition 12, traces
cannot be extended with ready simulation. However we can still add deadlocks;
e.g. P4 ≺R P1.
Ready simulation induces an equivalence.
Deﬁnition 14
(Ready Simulation Equivalence)
B and B′ are ready simulation equivalence iﬀthere exist ready simulations R
and R′ such that B R B′ and B′ R′ B. This equivalence is denoted ∼R.
To illustrate the diﬀerence between ∼R and the other two “strong” equiva-
lences that we have discussed (strong bisimulation and simulation), consider
the following processes (where the ﬁrst two were also considered as P4 and P1
earlier in this section).
R1 := ( x ; y ; stop ) [] ( x ; stop )
R2 := x ; y ; stop
R3 := ( x ; y ; stop ) [] ( x ; z ; stop )
R4 := x ; ( y ; stop [] z ; stop )
R5 := x ; ( y ; z ; stop [] y ; w ; stop )
R6 := x ; ( y ; z ; stop [] y ; w ; stop ) [] x ; y ; z ; stop
Corresponding transition systems are depicted in Figure 3.10. It can be shown
that the following relationships hold between these processes.
R1 ≍≺R2,
R1 ̸∼R R2
and
R1 ̸∼R2
R3 ̸≍≺R4,
R3 ̸∼R R4
and
R3 ̸∼R4
R5 ≍≺R6,
R5 ∼R R6
and
R5 ̸∼R6
Most of these relationships are straightforward. Thus, we only discuss a subset
of the relationships in more depth.
R1 ̸∼R R2 is because R2 ̸≺R R1 (whereas R1 ≺R R2; in fact, this is the
same as P4 ≺R P1 discussed earlier in this section). The reason that R2 ̸≺R R1
is that R1
2 ̸≺R R2
1 (see Figure 3.10), because the second condition of Deﬁnition
12 requires R2
1
y
−→.
Now, in order to justify R3 ̸≍≺R4, we can see that R3 ̸≺R4. This is
because for R3 ≺R4 to hold, we would need to relate R1
4 to one of R2
3 or

100
3 Basic Interleaved Semantic Models
x
y
x
2
3
1
1
R
R
1
1
R
1
R
y
R
R
R
2
2
1
2
2
x
x
y
x
2
3
R
R
1
R
R
3
3
3
3
R3
z
4
R
R
1
x
R
R
4
4
2
4
4
3
y
z
R
R
1
x
R
R
2
3
y
R
R
5
5
5
5
5
4
5
5
y
z
w
R
1
R
R
2
3
y
R
R
4
5
y
z
w
R 6
6
6
6
6
6
x
x
R
R
R6
6
6
7
6
8
y
z
Fig. 3.10. Ready Simulation Illustrations

3.4 Veriﬁcation Tools
101
R1
3. That is, either R2
3 ≺R1
4 or R1
3 ≺R1
4, but neither of these hold, because
R1
4
y
−→and R1
4
z
−→.
Finally, the fact that R5 ̸∼R6 follows, because to show bisimulation from
right to left requires that R6
6 be related to R1
5. However, this is not the case,
because, after performing a y, R1
5 reaches a state (R3
5) where it can perform a
w; this sequence of actions is not available to R6
6. In fact, this is an example of a
situation in which strong bisimulation could be argued to be too distinguishing
with respect to the branching structure of the transition system, in that it
is not clear that an external observer could distinguish between R5 and R6.
Indeed, it is examples of this variety that motivate our exploration of testing
theories and trace-refusals semantics in Chapter 5.
The following proposition summarises the relationship between ≍≺, ∼R
and ∼.
Proposition 5
Strong bisimulation is strictly stronger than ready simulation equivalence,
which is strictly stronger than simulation equivalence. That is, more formally,
∼⊂∼R ⊂≍≺.
Proof
See [118].
⃝
3.4 Veriﬁcation Tools
A number of mature and powerful veriﬁcation tools have been developed for
process calculi. Typically, the centre point of these tools is decision procedures
that check development relations of the kind introduced in this chapter. Ac-
cordingly, these tools are often based upon semantic theories such as those just
presented. The most prominent approach is to use branching time theories,
such as the labelled transition systems we introduced in Section 3.3, and, thus,
to compare pairs of process calculus speciﬁcations by checking their underlying
transition systems according to one of the spectrum of bisimulation equiva-
lences. This approach is typically employed, because trace semantic models
are considered not to be discriminating enough (for the reasons introduced
in this chapter), whereas true concurrency and refusals-based models (which
we discuss in the next two chapters) are often argued to be more complex to
check.
As a representative example of such a veriﬁcation tool, we brieﬂy consider
the salient features of the CADP tool suite [81]. The acronym now stands for
Construction and Analysis of Distributed Processes, although it was formerly
known as the CAESAR / ALDEBARAN Development Package.
We begin, in Section 3.4.1, by giving a brief overview of the tool suite and
then, in Section 3.4.2, we focus more directly on bisimulation checking in this
environment, which is one of the key strengths of CADP.

102
3 Basic Interleaved Semantic Models
3.4.1 Overview of CADP
The CADP tools have been developed as a veriﬁcation suite for analysing
LOTOS speciﬁcations. However, for some time, the tools have additionally
supported other input notations, including ﬁnite state machines and commu-
nicating automata. In particular, the latter of these is realised by the EXP
notation, in which labelled transition systems are combined using LOTOS-
style parallel composition and hiding operators. This yields a notation for
describing networks of communicating automata, similar to the formalism we
introduce in Chapter 8, although the synchronisation primitives are slightly
diﬀerent.
Furthermore, the recent development of the OPEN / CAESAR environ-
ment provides an open and extensible means to interface with the CADP tools.
For example, this has been applied to interface languages such as µCRL, SDL
and UML / RT.
The CADP suite is a state of the art formal development framework; it in-
cludes compilers that translate LOTOS to C code (the CAESAR tools), which
can be used for simulation, veriﬁcation and generation of test purposes. For
example, the simulators provide a number of facilities to step through speciﬁ-
cations. In addition, a spectrum of veriﬁcation algorithms is supported, such
as deadlock detection, reachability analysis, model-checking and assessment
of bisimulation equivalences. These facilities are supported by representations
for compact encoding of the behaviour of speciﬁcations. In particular, BCG
(Binary Coded Graphs) provide a compact labelled transition system descrip-
tion format together with eﬃcient and useful tools and libraries.
One of the strengths of CADP is its use of on-the-ﬂy analysis of state-
spaces. On-the-ﬂy techniques have been developed to limit the state-space
explosion problem. The key idea is to avoid building the transition system of
the entire system, unless absolutely necessary. The transition system of the
top-level behaviour of the system is often called the product transition system
and, with interleaving semantics, it is likely to be prohibitively large. This is
because the size of the top-level transition system can grow as a product of
the size of its parallel components. Thus, rather than building the product at
the start of veriﬁcation, on-the-ﬂy techniques derive transitions as and when
they are required during exploration (i.e. on-the-ﬂy) and this derivation is
driven by the veriﬁcation question at hand.
In addition to bisimulation-checking, which we discuss in the next sec-
tion, model-checking is a key veriﬁcation mechanism that CADP supports. In
particular, the EVALUATOR 3.0 tool provides a state of the art on-the-ﬂy
model-checker for regular alternation free µ-calculus formulae [138]. This logic
provides a “machine code” for temporal logic model-checking; i.e. a low-level
notation, to which higher-level, more user-friendly notations can be mapped.
For example, CADP provides a mapping by which computation tree logic (see
Section 8.2.5) can be mapped to the µ-calculus. The tool also generates a diag-
nostic portion of the LTS under evaluation, which serves as a counter-example

3.4 Veriﬁcation Tools
103
when a model-check fails. For the interested reader, more detailed explana-
tions of model-checking can be found elsewhere in this book, particularly in
Section 8.2.5.
The tool suite also beneﬁts from the EUCALYPTUS graphical user in-
terface, which integrates with the CADP tools, providing user-friendly inter-
action with the system. For more details on all the aspects of CADP dis-
cussed in this section, the interested reader is referred to the following CADP
overview [81].
3.4.2 Bisimulation Checking in CADP
Perhaps the most valuable veriﬁcation technique available in CADP is the
checking of bisimulation and simulation-based equivalences over labelled tran-
sition systems. The key transformation provided is the minimisation of a la-
belled transition system modulo such an equivalence. Critically, for bisimu-
lation and simulation equivalences, a canonical (smallest) transition system
always exists. That is, there is a unique minimal transition system modulo
such an equivalence. The CADP minimisation techniques generate such canon-
ical transition systems for a spectrum of equivalences, which includes strong
and weak bisimulation, branching bisimulation and safety equivalence [81].
CADP oﬀers three diﬀerent algorithms to minimise transition systems: an
approach based on the Paige–Tarjan algorithm for computing the relational
coarsest partition [159], an on-the-ﬂy technique developed by Fernandez and
Mournier [75,76] and a recently developed approach that works on symbolic
representations of labelled transition systems using Binary Decision Diagrams
(BDDs) [54]. These algorithms also provide counterexample-based diagnostic
support when an equivalence check fails. We discuss the Paige–Tarjan-based
relational coarsest partition approach further now, and the interested reader
is referred to the literature for explanation of the other two algorithms.
The states of a labelled transition system can be partitioned according to
an equivalence relation, such that all elements of each partition are equivalent.
The Paige–Tarjan-based algorithm extracts the coarsest such partition; i.e. in
which the partitions are maximal. It does this by applying an iterative algo-
rithm that repeatedly reﬁnes a given partition to a coarser one. The algorithm
is initiated with a single partition containing all states in the labelled tran-
sition system and, due to the existence of a canonical transition system for
the equivalences under investigation, is known to terminate with the coarsest
partition. Because all states in a given partition are equivalent, they can be
treated as a single state in the minimal transition system.
This algorithm can also be used to check that two transition systems are
equivalent by including all states of the two transition systems in the starting
partition. If the transition systems are equivalent, their start states will appear
together in the same partition when the algorithm terminates.
A simple, but elegant, illustration of CADP bisimulation checking is the
alternating bit protocol veriﬁcation, which is undertaken in demo 2 of the

104
3 Basic Interleaved Semantic Models
standard release of the tool suite. A LOTOS speciﬁcation of the alternating
bit protocol is provided, which is similar to the communication protocol run-
ning example that we have used to illustrate pbLOTOS.5 The correctness of
this speciﬁcation is veriﬁed in a number of steps. Firstly, a (BCG-format) la-
belled transition system is generated, which is surprisingly large and unwieldy
for such a relatively small speciﬁcation. Secondly, reduction by strong bisimu-
lation is applied, which dramatically reduces the LTS, despite which, the LTS
is still too large for meaningful evaluation.
The resulting labelled transition system is then further reduced by apply-
ing minimisation according to weak bisimulation (called observational equiv-
alence in CADP). This generates a further dramatic reduction of the size of
the transition system. In fact, this reduction could be argued to be the main
step in the veriﬁcation scenario. In particular, in the speciﬁcation, all com-
munications that are not visible to the environment are hidden. Thus, the
only observable actions are get and put (or CADP analogues thereof). Criti-
cally, minimisation due to weak bisimulation removes all internal actions that
do not aﬀect externally visible behaviour. Because the protocol is correctly
speciﬁed and thus, ensures reliable communication (i.e. all messages eventu-
ally get delivered), all internal behaviour can be removed without changing
what is externally observed. Thus, external behaviour of the original LOTOS
speciﬁcation, the strong bisimulation reduced transition system and the weak
bisimulation reduced transition system are all the same; they implement a
one-place buﬀer; i.e. each get is eventually followed by a put.
As a reﬂection of this observable behaviour, the ﬁnal step in the veriﬁca-
tion scenario is to compare the weak bisimulation reduced transition system
with a one-place buﬀer speciﬁcation. The fact that the reduced communica-
tion protocol and requirements speciﬁcation transition systems are bisimilar
formally justiﬁes the correctness of the protocol speciﬁcation.
Due to the similarity of the CADP alternating bit protocol and the commu-
nication protocol running example that we have used to illustrate pbLOTOS,
this CADP veriﬁcation serves as an illustration of how our communication
protocol could be formally veriﬁed.
5The reader comparing the CADP communication protocol with ours should
though beware of a number of diﬀerences between the two. Firstly, actions PUT
and GET in the CADP speciﬁcation actually play the opposite role to put and
get in our protocol speciﬁcation. Thus, in the CADP example, PUT plays the role
of putting into the protocol (at the sender end), whereas in our speciﬁcation, put
plays the role of putting into the layer above the protocol (at the receiver end).
Secondly, the CADP speciﬁcation also includes the possibility that the mediums
can knowingly lose a message; i.e. with an indication that the message has been
lost, and, in this situation, the mediums notify the sender and receiver of this loss,
which resend accordingly. Finally, there are two further diﬀerences, which, actually,
make the CADP example more similar to the full LOTOS communication protocol
version we consider in 6.3.1. First, the CADP version assumes that messages can be
lost in both directions and, second, it also includes explicit data passing.

4
True Concurrency Models: Event Structures
4.1 Introduction
So far we have considered two semantic notations for pbLOTOS, trace seman-
tics and LTS semantics. We have argued that these give increasingly discrimi-
nating models for pbLOTOS descriptions. Speciﬁcally, trace semantics cannot
distinguish certain (behaviourally distinct) varieties of choice, whereas LTS
semantics can. However, we can go one step further and notice that, although
LTS do distinguish diﬀerent forms of choice, they are unable to distinguish
concurrency from certain forms of choice and sequence. For example, the fol-
lowing two behaviours would be equated under both trace semantics and LTS
semantics,
x ; stop ||| y ; stop (1)
and
( x ; y ; stop ) [] ( y ; x ; stop )
(2)
There is no way of diﬀerentiating between these two behaviours using these
semantics. This identiﬁcation of concurrency and choice / sequence is typical
of models that employ an interleaved interpretation of parallelism.
A body of researchers has argued that this is not a realistic assumption
and has considered, so-called, true concurrency notations, where concurrency
is fully distinguished from behaviour that uses just choice and sequence. There
are a number of reasons for advocating a true concurrency approach.
•
Interleaving semantics abstract away from the decomposition of systems
into components and, thus, they abstract from aspects of “physical” dis-
tribution. However, such abstraction may or may not reﬂect the intention
of the speciﬁcation being semantically modelled. Interleaving semantics
model a global view of “observable behaviour.” This is reﬂected in the
fact that independence of components is not distinguished from forms of
choice and sequence (as highlighted above). For example, in the behaviours
above, x and y in (1) could be quite independent actions (e.g. x could
happen in Japan and y could happen in the U.K.), whereas in (2) the two
actions are causally related; e.g. one causes the other in each branch of

106
4 True Concurrency Models: Event Structures
the choice, and they could, conceptually, be viewed as being oﬀered in the
same logical component (probably in the same interface).
This discussion reﬂects the classic distinction between the extensionalist
and intensionalist view of formal speciﬁcation. The former argues that sys-
tems can be modelled purely in terms of the externally visible behaviour,
whereas the latter argues that the internal decomposition of systems must
be reﬂected in modelling, see [147].
•
The previous point suggests that full independence and autonomy of com-
ponents can only be expressed with true concurrency semantics. Further-
more, this enables parts of systems to be isolated and studied; i.e. a local
view can be taken, as opposed to the typically global view enforced by
interleaving.
•
A strong argument is that the diﬀerent approaches are applicable at dif-
ferent levels of abstraction. Thus, interleaving is most applicable at early
stages of system development, where global systemwide requirements are
being identiﬁed, whereas true concurrency is more applicable when com-
ponents need to be identiﬁed and made visible, in preparation for imple-
mentation. It could be said that interleaving implies a black box approach,
whereas true concurrency implies a white box approach.
•
True concurrency models are less susceptible to “state-space explosion”
than interleaved models. This is because the number of states in a truly
concurrent (independent) parallel composition is a sum of the number
of states in its components, rather than a product, as is the case with
interleaving. State explosion is currently the major hindrance to the de-
velopment of veriﬁcation tools.
•
An area of reﬁnement that we do not have a chance to cover in these
notes is action reﬁnement; i.e. reﬁning by replacing a single action by
some composite behaviour, however, we simply note that there are strong
arguments in favour of true concurrency models when action reﬁnement is
being considered [191].
In response to these observations, we consider a true concurrency approach
called event structures. The next section (Section 4.2) introduces event struc-
tures and the particular form of this model that we use: bundle event struc-
tures. In Section 4.3 we illustrate, by example, how the behaviour of pbLO-
TOS speciﬁcations can be modelled using bundle event structures. Section
4.4 presents a denotational semantics for mapping pbLOTOS speciﬁcations
to bundle event structures. Section 4.5 shows how labelled transition systems
can be generated from event structures. Then Section 4.6 describes some of the
development relations that can be associated with event structure semantics
and Section 4.7 gives a brief review of the diﬀerent event structures models.
Finally, Section 4.8 presents a concluding discussion.

4.2 The Basic Approach – Event Structures
107
4.2 The Basic Approach – Event Structures
The event structures model dates back to work by Winskel and co-workers
[155], which sought to reconcile Scott domain theory and Petri Nets. In fact,
event structures have a very close link with Petri Nets and have been success-
fully used to give domain-theoretic interpretations of a number of classes of
Petri Net. However, our presentation does not focus on this aspect of event
structures; rather we consider how they can be used to give a semantics to
process calculi.
Three basic concepts are at the heart of event structures:
Events,
Conﬂict and Causality
We consider each of these in turn.
1. Events. It is important to note that the notion of event is not the same as
that of action. The latter of these models a particular kind of interaction,
e.g. picking up a fork. Thus, there can be many instances of an action in
a speciﬁcation. For example, the behaviour
pick ; put ; pick ; stop
enables the action pick to be performed twice. In contrast, an event de-
notes a unique instance of an interaction. In the above example, the two
instances of action pick would be diﬀerentiated and modelled as distinct
events. This reﬂects the fact that they are diﬀerent occurrences and may,
for example, be diﬀerentiated in time; e.g. in the above behaviour the
ﬁrst occurrence of pick represents one instance at which the fork is picked
up, which perhaps occurs at 5 PM, and the second represents a diﬀerent
instance, which perhaps occurs at 6 PM. The capacity to distinguish dif-
ferent instances of an action reﬂects the intensionalist’s view alluded to
above. Intensionalist approaches imply that the internal decomposition
of a system is reﬂected in semantic models. Events reﬂect this by distin-
guishing the diﬀerent internal occurrences of the same external action.
2. Conﬂict. This identiﬁes events that cannot occur together in the same
evaluation of the event structure. Such events are said to be in conﬂict.
So, for example, two events which identify actions that are on either side
of a choice would be in conﬂict with each other.
3. Causality. This is a relationship between events, which characterises how
events enable (or cause) other events. For example, we might specify that
event e causes event e′, which states that e′ cannot happen until e has. In
addition, more than one event can cause a particular event. For example,
event e might only be able to occur once both events e′ and e′′ have
occurred. Causality is deﬁned on events rather than on actions, because
diﬀerent action occurrences may have diﬀerent causes.
The literature contains a spectrum of event structure models, e.g. Prime Event
Structures [155], Stable Event Structures [198] and Flow Event Structures [31].

108
4 True Concurrency Models: Event Structures
The particular event structure model that we consider was developed by Rom
Langerak [114] and is called Bundle Event Structures (BES). The work of
Joost-Pieter Katoen has also served as valuable source material [107]. Bundle
event structures extend classic event structures in order to model the LOTOS
multiway synchronisation. We deﬁne the model as follows.
The set of all bundle event structures is denoted BES and ε ∈BES has
the form ε = (E, #, →, l), where
1. E is a set of unique events;
2. # ⊆E × E is the conﬂict relation;
3. →⊆P(E) × E is the bundle relation; and
4. l : E →Act ∪{i, δ} is the labelling function;
subject to the constraint that:
(1) # is irreﬂexive and symmetric, and,
(2) ∀X ⊆E, ∀e ∈E , ( X →e =⇒( ∀e′, e′′ ∈X , e′ ̸= e′′ =⇒e′#e′′ ) ).
The ﬁrst two of these, events and conﬂict, are much as described above and
are relatively standard. Notice that conﬂict is expressed as a binary relation
between events. In addition, we assume a universe of events, denoted UE,
which is such that ∀e, e′ ∈UE, (e, ∗), (∗, e), (e, e′) ∈UE. This structure of
events is used in the representation of parallel composition, as clariﬁed later
in this section.
The other two constituents of this structure require some explanation.
1. Bundle Relation. This set expresses the causality relation. However, this
is not a binary causality relation, as it often is in event structure models;
rather a many-to-one relation is used. This relation is called the bundle
relation, denoted →. A typical member of →is a pair, which has the form
(X, e)
where X is a set of events and e is an event; i.e. X ⊆E and e ∈E. The
meaning of this pair is that the event e cannot happen until one of the
events in X has occurred. In addition, only one of the events in X can
take place and this is realised in bundle event structures by imposing the
constraint that all the events in X must be in conﬂict, which is the second
constraint (see above) associated with bundle event structures.
Notice that, if the set X here is a singleton, we obtain the standard binary
causality relation. In fact, in most cases, X will be a singleton. However,
there are circumstances, arising from modelling multiway synchronisation,
where X will contain more than one element. In addition, it is also possible
for X to be empty; this has a special meaning which we discuss shortly.
As a shorthand, we often write
X →e
in place of

4.2 The Basic Approach – Event Structures
109
(X, e) ∈→
The set →is called either the bundle set or bundle relation; in X →e, X
is called the bundle enabling set or simply the enabling set and e is called
the enabled event.
2. Labelling. As bundle event structures are used to model pbLOTOS spec-
iﬁcations, a labelling function is also included. This associates an action
name with every event in the bundle event structure; it states that a par-
ticular event indicates the occurrence of a particular action. However, the
same action can be associated with more than one event and in addition,
there will be circumstances in which actions are not mapped to by any
event; thus, the function is neither one-to-one nor onto.
For a BES ε = (E, #, →, l), we use the notation, Eε = E, #ε = #, →ε = →
and lε = l. Bundle Event Structures (BES) have a very natural pictorial
representation; Figure 4.1 shows a number of simple BES. We discuss each of
the structures in turn.
1. This structure models the fragment of Dining Philosophers behaviour
highlighted earlier. Events are depicted as black dots and bundles are
represented as arrows between events. Labelling is shown separately.
2. This is a BES with one event labelled x. Note that event labelling for all
BES in this ﬁgure, apart from the Dining Philosophers BES, is shown at
the bottom right of the diagram.
3. In this structure, the event e′′ is caused by e, but, neither is related in
any way to the event e′. This BES depicts independent parallelism. In
particular, e must occur before e′′, however, e′ can occur at any point
relative to e and e′′; i.e. before e, at the same time as e, between e and
e′′, at the same time as e′′ or after e′′. Thus, concurrency is reﬂected by
events that are not related by either of the relations # or →.
4. Conﬂict is represented by a dotted line between events. This event struc-
ture can either perform the event e or the event e′. If the former of these
is selected then the event e′′ will be enabled. In addition, the event not
selected will be permanently prevented from occurring; i.e. will be dis-
abled. Thus, no evaluation / run of this event structure will contain both
the events e′ and e. In addition, if e′ is in an evaluation, then e′′ cannot
occur either, as its occurrence is guarded by e. This is called the con-
ﬂict inheritance property and some event structure models include the
resultant inherited conﬂicts explicitly, e.g. between e′ and e′′. Prime event
structures, which we discuss in Section 4.7, is such an approach.
5. This depicts our ﬁrst example of a bundle with a nonsingleton enabling
set. This BES contains a single bundle, which has the form {e, f} →e′′.
The line segment just above the two arrow heads indicates that a single
bundle is being depicted. Notice that the events of the bundle enabling
set are in conﬂict, as required by constraint (2) on BES. The behaviour
of this structure is to enable e′′ only after one of e or f has been selected.

110
4 True Concurrency Models: Event Structures
f
f’
f"
l(f)=pick
l(f’)=put
l(f")=pick
e
e
e"
e’
(1)
(2)
(3)
e
e"
e’
(4)
......
e
e"
......
(5)
e
e"
e’
......
(6)
e
e"
e’
(7)
f
l(e)=x
l(e’)=y
l(e")=z
l(f)=x
Fig. 4.1. Simple Bundle Event Structures
6. The behaviour of this BES is the same as (4) except the event e′′ is
prevented from happening, because a bundle with a null enabling set,
∅→e′′, causes e′′. Thus, a bundle with an empty enabling set blocks the
event to which it points.
7. It is important to note that this structure deﬁnes quite a diﬀerent be-
haviour to that depicted in (5). It states that e′′ can only occur once both
e and e′ have occurred and the two occur independently in parallel with
each other. This structure and the structure in (6) are examples of BES
in which an event is enabled by multiple bundles.
In future, where it does not lead to confusion, we depict BES with action
labels as event names or by associating action labels as subscripts of events.

4.2 The Basic Approach – Event Structures
111
An obvious concept that we consider is that of an evaluation or run of
a BES. This yields the concept of a proving sequence for a BES, which is a
linear run of the events of a BES. This turns out to be a very expressive model,
because event names are referenced in proving sequence semantics as opposed
to actions (which is the case with interleaving trace models). We need some
preliminaries before we deﬁne this concept.
Let ET denote the set of all ﬁnite event traces (sequences); i.e.
ET ≜{ e0e1 . . . en | n ∈N ∧ei ∈UE } ∪{ ϵ }
where ϵ is the empty event trace. σ ranges over ET and we denote the preﬁx of
σ up to the i −1st element by σi; i.e. if σ = e0e1 . . . en then σi = e0e1 . . . ei−1
for 0 ≤i ≤n and for i = 0, σi = ϵ. Notice, the symbols σ and ϵ have
already been used in action traces. However, no confusion will result from
this overloading.
We also deﬁne the set of events underlying an event trace by:
$e0e1 . . . en ≜{ e0, e1, . . . , en }
and
$ϵ ≜∅
Now we can deﬁne a proving sequence as follows.
Deﬁnition 15
Given a BES ε = (E, #, →, l), then σ ∈ET is a proving sequence for ε iﬀ
σ = ϵ or σ = e0e1 . . . en and ∀i (0 ≤i ≤n),
ei ∈E ∧ei ∈sat(σi) \ (cﬂ(σi) ∪$σi)
where
cﬂ(σ) ≜{ e ∈E | ∃ej ∈$σ s.t. ej#e }
and
sat(σ) ≜{ e ∈E | ∀X ⊆E, X →e =⇒X ∩$σ ̸= ∅}
This deﬁnition is due to Katoen [107] and is deﬁned in terms of cﬂ(σ), which
generates the set of all events that are in conﬂict with an event in σ and
sat(σ), which generates the set of all events that are completely enabled by
events in σ. sat(σ) ensures that an event in each of the enabling sets of each
bundle has already occurred.
Deﬁnition 16
The set of all proving sequences of a BES ε = (E, #, →, l) is deﬁned as
PS(ε) ≜{ σ | σ is a proving sequence for ε }
By way of illustration of this concept, the sets of proving sequences associated
with each of the BES depicted in Figure 4.1 are as follows.
•
BES (1) - { ϵ , f , ff′ , ff ′f ′′ }
•
BES (2) - { ϵ , e }

112
4 True Concurrency Models: Event Structures
•
BES (3) - { ϵ , e , e′ , ee′ , e′e , ee′′ , ee′e′′ , e′ee′′ , ee′′e′ }
•
BES (4) - { ϵ , e , e′ , ee′′ }
•
BES (5) - { ϵ , e , f , ee′′ , fe′′ }
•
BES (6) - { ϵ , e , e′ }
•
BES (7) - { ϵ , e , e′ , ee′ , e′e , ee′e′′ , e′ee′′ }
We can also deﬁne the notion of a conﬁguration, which is the set of events
that have occurred at a particular point in the evaluation of a BES.
Deﬁnition 17
C ⊆E is a conﬁguration of a BES ε = (E, #, →, l) iﬀ∃σ ∈PS(ε) . C = $σ.
The set of all conﬁgurations of a BES is denoted CF(ε).
For example, BES (7) in Figure 4.1 has the following conﬁgurations,
{ ∅, {e} , {e′} , {e, e′} , {e, e′, e′′} }
Both the concepts of a proving sequence and a conﬁguration are used when
we deﬁne event structure-based development relations for pbLOTOS.
4.3 Event Structures and pbLOTOS
This section illustrates informally how event structures relate to pbLOTOS
speciﬁcations. It considers a number of typical pbLOTOS behaviours and
shows how they would be modelled in a BES. We begin by considering the
examples that motivated our investigation of true concurrency models:
(1) x ; ( y ; stop ||| z ; stop )
and
(2) x ; ( y ; z ; stop [] z ; y ; stop )
These behaviours would be bisimulation equivalent under LTS and trace
equivalent under trace semantics. The corresponding bundle event structures
are depicted in Figure 4.2. The left-hand BES models behaviour (1) and the
right-hand BES models behaviour (2). The labelling in these two bundle event
structures is as follows.
l(e) = x ,
l(e′) = y ,
l(e′′) = z
and
l(e1) = x ,
l(e2) = y ,
l(e3) = z ,
l(e4) = z ,
l(e5) = y
Thus, in general, action preﬁx in pbLOTOS gets modelled using causality,
choice is modelled using conﬂict and concurrency is modelled by independence
of events; e.g. the events e′ and e′′ can evolve concurrently because they are
not related by conﬂict or causality. So, bundle event structures clearly give us
a more discriminating semantics in terms of distinguishing concurrency.
In fact, most of the interesting BES models arise through parallel compo-
sition and synchronisation between parallel components. As an illustration,
the BES for the following behaviour,

4.3 Event Structures and pbLOTOS
113
e
e’
e"
e
......
1
e2
e3
e4
e5
Fig. 4.2. Two Bundle Event Structures
( y ; x ; z ; stop ) |[x]| ( x ; w ; stop )
is depicted in Figure 4.3(1) (labelling is indicated by subscripting). Thus, a
single event labelled x is created from the synchronisation over |[x]|.
In order to show why the causality relation is not a binary relation, ﬁrst
consider the following behaviour,
( x ; y ; stop ||| x ; stop ) ||| ( x ; z ; stop )
which has the BES model shown in Figure 4.3(2). Notice how the three oc-
currences of the (nonsynchronised) action x are modelled as separate events,
in contrast to the previous example where x is synchronised. Two instances
of the same actions occurring in parallel is called autoconcurrency. Now, if we
replace the second parallel composition by a synchronised parallel context, as
follows,
( x ; y ; stop ||| x ; stop ) |[x]| ( x ; z ; stop )
then the BES shown in Figure 4.3(3) results. The event gx results from syn-
chronisation on x between events ex and e′′
x and g′
x results from synchronisa-
tion on x between events e′
x and e′′
x. It is important to note though that, the
conﬂict between gx and g′
x arises because only one of the independent events
ex and e′
x can synchronise with e′′
x at a time. Thus, a bundle of the form
{ gx, g′
x } →f ′
z results. As a point of comparison, consider the labelled transi-
tion system that would be generated from this behaviour; this is depicted in
Figure 4.4.
As a further example of the use of bundle enabling sets, Figure 4.3(4)
depicts the BES model of the behaviour:
( y ; x ; stop [] z ; x ; stop ) |[x]| ( x ; w ; stop )
Our next example illustrates how null enabling sets can be created in order
to model deadlock situations. The BES depicted in Figure 4.3(5) models the
behaviour:
( y ; stop ) |[x]| ( x ; z ; w ; stop )

114
4 True Concurrency Models: Event Structures
e
e’
f
e
(1)
......
f
f
......
f
f’
f
(4)
f
f
f
(5)
e
f
e’
(2)
f
e
e
e
(6)
......
e
e
e
(7)
g
g’
f’
f’
......
(3)
y
x
z
w
x
x
y
z
e"x
x
x
y
z
y
z
w
y
z
x
x
w
x
y
z
z
x
y
Fig. 4.3. Bundle Event Structures
x
x
y
z
z
y
z
Fig. 4.4. Labelled Transition System Example

4.4 An Event Structures Semantics for pbLOTOS
115
Notice that no event labelled x appears because the action is deadlocked. In
addition, all events that would be caused by such an event are either directly
or indirectly caused by a bundle with a null enabling set. Thus, they are also
deadlocked.
Another example of a deadlock behaviour is
( x ; y ; stop ) |[x, y]| ( y ; z ; x ; stop )
the model for which is depicted in Figure 4.3(6). This cycle of causality pre-
vents any of the three generated events from occurring.
Our ﬁnal example shows another way in which an event can be prevented
from occurring. The model for the following behaviour is depicted in Figure
4.3(7),
( x ; stop [] y ; z ; stop ) |[x, z]| ( x ; z ; stop )
Event ez can never occur, as its two enabling bundles cannot both be satisﬁed;
it is caused by two conﬂicting events.
4.4 An Event Structures Semantics for pbLOTOS
This section presents a denotational semantics for pbLOTOS in bundle event
structures. We deﬁne a mapping,
J Kbe : pbLOTOS −→BES
This mapping is based upon the semantics given by Langerak in [114]. The
top-level machinery of the semantics is much the same as that presented for
our other denotational semantics, the trace semantics. We deﬁne:
J B Kbe ≜B′J B K(∅)
J B where D Kbe ≜B′J B K(DJ D K)
where D is as deﬁned in Section 3.2.2.2; i.e.
DJ (P := B) K ≜{ P := B }
DJ (P := B) D K ≜{ P := B } ∪DJ D K
Once again, the main part of the semantics is the interpretation of behaviour
expressions. But, before we consider this, we need some preliminary deﬁni-
tions.
•
We use two auxiliary functions which, assuming ε = (E, #, →, l), are de-
ﬁned as follows.

116
4 True Concurrency Models: Event Structures
init(ε) ≜{ e ∈E | ̸∃X ⊆E s.t. X →e }
exit(ε) ≜{ e ∈E | l(e) = δ }
So, init yields the set of initial (or immediately enabled) events of a BES,
whereas exit yields the set of successful termination events; i.e. those la-
belled with δ.
Given that
B′J B1 K(d) = ε1 = (E1, #1, →1, l1) and
B′J B2 K(d) = ε2 = (E2, #2, →2, l2)
and assuming that E1 ∩E2 = ∅(which, if necessary, can be obtained through
systematic renaming of events), then the mapping of pbLOTOS to BES is as
follows.
Stop. The behaviour stop induces the null BES:
B′J stop K(d) ≜(∅, ∅, ∅, ∅)
Exit. The semantics of successful termination are also relatively straightfor-
ward:
B′J exit K(d) ≜({e}, ∅, ∅, {(e, δ)})
for an arbitrary e ∈UE
Thus, a single event is generated, which is labelled by δ.
Action Preﬁx. This construct cannot introduce conﬂicts, but events, bundles
and labelling are all changed.
B′J a ; B1 K(d) ≜(E, #1, →, l)
where,
E = E1 ∪{e}
for some e ∈UE \ E1
→= →1 ∪( {{e}} × init(ε1) )
l = l1 ∪{ (e, a) }
A new event is added and labelled a. In addition, bundles from the new event
to all initial events in B1 are included. Thus, the new event is grafted onto
the front of the BES generated from B1. We can illustrate this with a simple
example. Consider the behaviour:
x ; ( y ; z ; stop [] z ; stop )
Two of the stages in the generation of the BES for this behaviour are depicted
in Figure 4.5. Notice in particular that the events labelled ey and ez are the
initial events of the behaviour:

4.4 An Event Structures Semantics for pbLOTOS
117
STAGE 1
......
f
e
e
e
e
;
......
f
e
e
STAGE 2
x
y
z
z
x
y
z
z
Fig. 4.5. Depiction of Action Preﬁx Semantics
( y ; z ; stop ) [] ( z ; stop )
You should also notice that there is only one action preﬁx rule, so, internal
and external actions are treated identically. Thus, internal actions can appear
in BES in the same way that they appear in LTS.
Another point about this deﬁnition is that, not only is the selection of
e from UE unique in terms of the behaviour a ; B1, it is also assumed to
be unique in terms of the entire pbLOTOS speciﬁcation. Each instance of a
pbLOTOS action will have a unique event denotation. To actually deﬁne this
precisely over the binary pbLOTOS operators would require a more sophis-
ticated mechanism than we have presented here. However, such mechanisms
are relatively standard, would only complicate the presentation and have thus
not been included.
Choice. This construct aﬀects all elements of the bundle event structure.
B′J B1 [] B2 K(d) ≜(E, #, →, l)
where
E = E1 ∪E2
# = #1 ∪#2 ∪( init( ε1 ) × init( ε2 ) )
→= →1 ∪→2
l = l1 ∪l2
The events, bundles and labels of B′J B1 [] B2 K(d) are obtained by unioning the
events, bundles and labels arising from the two constituent behaviours. This
reﬂects the natural relationship between choice, logical or and set-theoretic
union.
As might be expected, the deﬁnition for conﬂict is slightly more involved.
Speciﬁcally, conﬂicts from either B′J B1 K(d) or B′J B2 K(d) are preserved and
conﬂicts are added between initial events of B′J B1 K(d) and B′J B2 K(d). Thus,
events at the choice point are put into conﬂict with one another.

118
4 True Concurrency Models: Event Structures
Parallel Composition. The deﬁnition of parallel composition is somewhat
more involved than the deﬁnitions we have seen so far. We use the following
notation.
•
Given B′J B1 K(d) = (E1, #1, →1, l1) and B′J B2 K(d) = (E2, #2, →2, l2)
then, for a parallel composition B1 |[G]| B2,
Es
i ≜{ e ∈Ei | li(e) ∈G ∪{δ} }
for i = 1, 2
and
Ef
i ≜Ei \ Es
i
for i = 1, 2
which distinguishes between events that synchronise on parallel execution
and those that are free (i.e. do not synchronise). Notice that successful
termination events synchronise over parallel composition, as required by
the standard LOTOS semantics.
Parallel composition can now be deﬁned as
B′JB1 |[G]| B2 K(d) ≜(E, #, →, l)
where
E = ( Ef
1 × {∗} ) ∪( {∗} × Ef
2 ) ∪
{ (e1, e2) ∈Es
1 × Es
2 | l1(e1) = l2(e2) }
(e1, e2) # (e′
1, e′
2) iﬀ( e1 #1 e′
1 ) ∨( e2 #2 e′
2 ) ∨
( e1 = e′
1 ̸= ∗∧e2 ̸= e′
2 ) ∨
( e2 = e′
2 ̸= ∗∧e1 ̸= e′
1 )
X →(e1, e2) iﬀ∃X1 ⊆E1 . ( X1 →1 e1 ∧X ={ (ei, ej)∈E | ei ∈X1 } ) ∨
∃X2 ⊆E2 . ( X2 →2 e2 ∧X ={ (ei, ej)∈E | ej ∈X2 } )
l(e1, e2) = if e1 = ∗then l2(e2) else l1(e1)
We explain the deﬁnitions for events, conﬂict, bundles and labelling in turn.
•
Events. All free events are paired with ∗, whereas all synchronising events;
i.e. those labelled by an action in the gate set G or labelled δ, are paired
with events with which they synchronise. This construction ensures that
events generated from a parallel composition are unique and justiﬁes the
earlier deﬁnition concerning the structure of events in UE.
•
Conﬂict. Component conﬂict creates conﬂict between paired events. In
addition, diﬀerent events with a component unequal to ∗in common are
made conﬂicting. This situation arises, for example, if an action oﬀered
independently in parallel on two sides of a parallel composition is synchro-
nised with the same action in a third thread of parallel execution. See the
examples in Section 4.3 for an illustration of this situation.
•
Bundles. This states that a bundle is introduced between paired events if,
when we project on the ith component (i = 1,2) of events in the bundle,
we obtain a bundle in BJ Bi K(d).

4.4 An Event Structures Semantics for pbLOTOS
119
•
Labelling. Event pairs constructed from free events are labelled with the
label of their only proper component; for example, an event pair (e, ∗)
would inherit the label of e. Event pairs constructed from synchronising
events must, by the deﬁnition of event pairing, have the same labelling
and will thus, inherit it.
We present ﬁve illustrations of the semantics, through presentation in Figure
4.6 of the stages in evaluation of the following behaviours (uniqueness of events
is obtained by superscripting action names; this informality does not cause
ambiguity here).
1. ( x ; y ; stop ) ||| ( y ; z ; stop )
2. ( x ; y ; w ; stop ) |[y]| ( y ; z ; stop )
3. ( x ; y ; stop [] x ; z ; stop ) |[x]| ( x ; w ; stop )
4. ( x ; y ; stop ||| x ; stop ) |[x]| ( x ; w ; stop )
5. ( x ; y ; stop ||| x ; stop ) |[x]| ( x ; x ; stop )
The bundle event structures for the ﬁrst two behaviours are relatively straight-
forward. So, we only provide explanation of the last three. Behaviour (3)
illustrates how component conﬂict is inherited by the parallel composition,
as stated in the ﬁrst two disjuncts of the clause deﬁning # above. Thus,
(x, x′′)#(x′, x′′), because x#x′. In addition, notice that the component bun-
dle from x′′ to w yields a bundle from { (x, x′′), (x′, x′′) } to (∗, w) in the
parallel composition; i.e. one (and only one) of the events (x, x′′), (x′, x′′) can
cause (∗, w); the clause deﬁning →above ensures that the bundle enabling
set has this form.
Now consider behaviour (4) above, parallel composition of which is de-
picted in Figure 4.6(4). The generation of conﬂict between events (x, x′′) and
(x′, x′′) in the parallel composition arises from the last two disjuncts of the
clause deﬁning # above. That is, x′′ can only synchronise with one of x and
x′ and, in so doing, prevents the other from becoming possible. Thus, this
is a situation in which the requirement to synchronise on an action and the
availability of only one instance of the action in one parallel component, turns
independent parallelism in the other component into choice / conﬂict in the
parallel composition. This phenomenon can also be seen in the labelled tran-
sition that would be generated from this behaviour (see Figure 4.4), which
arises when interleaving semantics are applied.
Finally, consider behaviour (5) above, parallel composition of which is
depicted in Figure 4.6(5). This example is similar to behaviour (4), except
here, the inclusion of a further instance of action x, which yields the event
denoted x∧in Figure 4.6(5), generates an extra level of conﬂict and causality.
In addition, for comparison purposes, Figure 4.7 shows the labelled transition
system that would arise from behaviour (5), if the interleaving semantics of
Section 3.3 were applied.

120
4 True Concurrency Models: Event Structures
STAGE 1
STAGE 2
|||
(1)
STAGE 1
STAGE 2
(2)
(5)
x
y
y’
z
x
y
w |[y]| y’
z
(x,*)
(*,y’)
(y,*)
(*,z)
(x,*)
(y,y’)
(w,*)
(*,z)
......
STAGE 1
x
x’
x"
y
z
w
|[x]|
......
STAGE 2
(3)
(x,x")
(x’,x")
(y,*)
(*,w)
(z,*)
STAGE 1
x
x’
x"
|[x]|
y
x^
STAGE 2
............
............
............
............
(x,x")
(x’,x")
(y,*)
(x,x^)
(x’,x^)
STAGE 1
x
x’
x"
|[x]|
y
w
......
STAGE 2
(4)
(x,x")
(x’,x")
(y,*)
(*,w)
Fig. 4.6. Parallel Composition Semantics

4.4 An Event Structures Semantics for pbLOTOS
121
x
x
y
x
x
y
x
y
Fig. 4.7. Labelled Transition System of Behaviour (5)
The approach presented here will generate some impossible events; i.e.
that cannot happen, e.g. events enabled by null bundles. It is shown in [114]
that a mapping can be applied to remove all such events from a generated
BES. An alternative approach would be to generate only events that are not
impossible. This, for example, is the approach taken in [131] when modelling
parallel composition in CSP. However, this approach leads to a more involved
deﬁnition of the semantics of parallel composition.
Hiding and Relabelling. These deﬁnitions are straightforward.
B′J hide G in B1 K(d) ≜(E1, #1, →1, l)
where
l(e) = if l1(e) ∈G then i else l1(e)
B′J B1[y1/x1, . . . , yn/xn] K(d) ≜(E1, #1, →1, l)
where
l(e) = if ∃i (1 ≤i ≤n) . l1(e) = xi then yi else l1(e)
Sequential Composition/Enabling. The semantics for this construct are
deﬁned as follows.

122
4 True Concurrency Models: Event Structures
B′J B1 >> B2 K(d) ≜(E, #, →, l)
where
E = E1 ∪E2
# = #1 ∪#2 ∪{ (e, e′) | e, e′ ∈exit(ε1) ∧e ̸= e′ }
→= →1 ∪→2 ∪( {exit(ε1)} × init(ε2) )
l = ( l1 ∪l2 \ ( exit(ε1) × {δ} ) ) ∪( exit(ε1) × {i} )
This deﬁnition can be explained in the following points.
•
Events in either of the constituent BES are events of the combined BES.
•
Conﬂicts in either of the constituent BES are preserved in the combined
BES, but in addition, distinct exit events are placed mutually in conﬂict.
This reﬂects the fact that in B1, only one successful termination event
needs to be performed for the whole behaviour to successfully terminate.
•
Bundles in either of the constituent BES are preserved and in addition,
initial events in B2 become caused by a bundle from all the exit events
of B1. Notice that the deﬁnition of # above ensures that all events in
exit(ε1) are in conﬂict and thus, exit(ε1) is a valid bundle enabling set.
So, we attach the BES generated from B2 to the BES generated from B1
by connecting “ﬁnal” events of B1 (i.e. exit events) to “starting” events of
B2 (i.e. initial events).
•
Labelling in either of the constituent BES is preserved in the combined
BES, but in addition, the labelling of exit events with δ is replaced by i.
Thus, successful termination is referenced by an internal action occurring
at the point of sequential composition, as is normal.
We give one illustration of these semantics. The behaviour that we consider
is
( x ; ( y ; exit ||| z ; exit ) ) >> ( w ; stop )
the semantics of which are depicted in Figure 4.8.
x
y
z
STAGE 2
i
w
x
δ
y
z
STAGE 1
>>
w
Fig. 4.8. Depiction of Sequential Composition Semantics
Process Instantiation and Recursion. The bundle event structure se-
mantics for process instantiation and recursion are relatively complex. This

4.5 Relating Event Structures to Labelled Transition Systems
123
complexity centres on the deﬁnition of a bundle event structure ﬁxed point for
recursive processes. As a consequence, we are not able to present this theory
here, but the interested reader is referred to [114]. However, general points
that should be noted are ﬁrstly, strong guardedness is not an issue in deﬁn-
ing this ﬁxed point, because internal actions are included in BES. Secondly,
the semantic rules for all the pbLOTOS constructs are compositional; this
property is crucial if a ﬁxed point theory is to be presented.
We simply quote the deﬁnition of process instantiation:
BJ P K(d) ≜
i F i
B(⊥)
where (P := B) ∈d, 
i is the least upper bound operator for chains of BES,
FB is a function, which re-expresses pbLOTOS behaviours as BES behaviours
and ⊥is a “bottom” BES in a complete partial ordering between BES.1
4.5 Relating Event Structures to Labelled Transition
Systems
In a similar way to which LTS were related to trace models, we can relate
bundle event structures to labelled transition systems. This is realised by
deﬁning a transition relation over bundle event structures.
Firstly, let us remember the constituents of a labelled transition system. A
LTS is a four-tuple (S, A, T, s0), where S is a set of states, A is a set of actions,
T is a set of transition relations and s0 is a start state. So, we must derive
all of these four constituents from a bundle event structure. This immediately
prompts the question: what is our notion of state for BES? Basically, each
state in our transition system will be a BES, with the starting state being the
BES that we are modelling and other states being the BES that result from
evolving the initial BES.
Central to this approach is the remainder function, which takes a BES and
a conﬁguration and derives the remainder of the BES after performing all the
events in the conﬁguration. This remainder will itself be a BES.
Deﬁnition 18
Let ε = (E, #, →, l); then the remainder of ε after the conﬁguration C, denoted
ε[C], is as follows, where ε[C] ≜(E′, #′, →′, l′),
E′ = E \ C
#′ = # ∩(E′ × E′)
→′ = ( →\ { (X, e) ∈→| X ∩C ̸= ∅} ) ∪{ (∅, e) | ∃e′ ∈C . e#e′ }
l′ = l⌈E′
1We elaborate on the BES and timed BES ﬁxed point constructions in section
10.2.3.6.

124
4 True Concurrency Models: Event Structures
We explain the changes made to events, conﬂict, bundles and labelling in turn.
•
Events. Only events that are not in the conﬁguration are included in the
remainder.
•
Conﬂict. Only conﬂicts that are between events in the remainder are
preserved.
•
Bundles. All bundles are preserved apart from those that are enabled by
an event in the conﬁguration, which are removed. In addition, an empty
bundle is included to all events that are in conﬂict with an event in the
conﬁguration; such events will be disabled by the execution of the conﬁg-
uration.
•
Labelling. The labelling function is restricted to a domain, which is the
events of the remainder.
It can be checked that ε[C] is indeed a BES [114].
As an illustration of the function, Figure 4.9 presents the possible remain-
ders of the bundle event structure derived from the behaviour:
P := ( x ; y ; stop ||| x ; stop ) |[x]| ( x ; x ; stop )
The depicted event structures are identiﬁed as follows:
(1) is B′J P K(d) = ε = ε[∅]
(2) is ε[{e}]
(3) is ε[{e, e′′}]
(4) is ε[{e, f ′}]
(5) is ε[{e, e′′, f ′}]
(6) is ε[{e′}]
(7) is ε[{e′, f}]
(8) is ε[{e′, f, f′}]
So, in deriving transition systems, BES model states; BES can perform some
conﬁguration C and evolve to a new state ε[C]. In the transition systems that
we give, the conﬁgurations considered are singleton sets. We deﬁne the basic
transition relation as follows.
Deﬁnition 19
Given that ε = (E, #, →, l), for all a ∈Act ∪{i, δ} we deﬁne
ε ⋆a
−→ε[{e}] iﬀ{e} ∈CF(ε) ∧lε(e) = a.
Using this transition relation, we can introduce a mapping from BES to LTS,
which we denote ψ : BES −→LT S, and deﬁne as follows.

4.5 Relating Event Structures to Labelled Transition Systems
125
......
............
............
............
(1)
......
e
e’
e"
f
f’
............
............
(2)
f’
e’
e"
f
f’
e’
f
(3)
............
............
e’
e"
f
(4)
e’
f
(5)
e
e"
f’
(7)
e
e"
(8)
............
............
e
e"
f
f’
(6)
Labelling:
l(e)  =  l(e’) =
l(e’’) = l(f) = x
l(f’) = y
Fig. 4.9. Illustration of Remainder Function
ψ(ε) = (S, A, T, s0)
where
S = { ε[C] | C ∈CF(ε) }
A = image(l)
where
image(f) = { r2 | (r1, r2) ∈f }
T = { •a
−→⊆BES × BES | a ∈A }
where,
•a
−→= { (ε1, ε2) | ∃ε1, ε2 ∈S . ε1 ⋆a
−→ε2 }
s0 = ε
Transition systems can also be derived from BES by making states conﬁgu-
rations of events that have occurred up to a certain point, e.g. [191,193].

126
4 True Concurrency Models: Event Structures
4.6 Development Relations
In the same way that we deﬁned development relations for trace semantics and
labelled transition systems we can deﬁne such relations for bundle event struc-
tures. Unfortunately, we do not have suﬃcient space to consider reﬁnement
relations for BES, so, we concentrate on equivalences.
The spectrum of equivalences for BES is very large; this reﬂects the ex-
pressiveness of the model. We give a selection of relations, which spans this
spectrum. See [191] for a more complete presentation.
Isomorphism of BES. A very strong identity between bundle event struc-
tures is given by isomorphism.
Deﬁnition 20
Let ε and ε′ be BES; then an event structure isomorphism between ε and ε′
is a bijection,
φ : Eε −→Eε′
such that
1. ∀e, e′ ∈Eε , e#εe′ ⇐⇒φ(e)#ε′φ(e′);
2. ∀X ⊆Eε, ∀e ∈Eε , X →ε e ⇐⇒{ φ(e′) | e′ ∈X } →ε′ φ(e) and
3. ∀e ∈Eε , lε(e) = lε′(φ(e))
According to this deﬁnition, BES are identiﬁed if an event renaming function
can be identiﬁed, which preserves the structure of BES. This is in the sense
that the mapping is a bijection, so the set of events is preserved; and it pre-
serves conﬂict, bundles and labelling. Thus, BES are identiﬁed if they have
the same structure; in particular, there is no consideration of the behaviour
of the BES. Consequently, two event structures with the same behaviour may
be distinguished.
For example, consider the four BES depicted in Figure 4.10. BES (1) and
(2) are clearly not isomorphic, because it is not even possible to deﬁne a bi-
jective mapping between the events of the two BES. However, the behaviour
of the two BES is the same: neither can evolve. Thus, they have identical
proving sequences and conﬁgurations, viz {ϵ} and {∅}, respectively. In addi-
tion, (3) and (4) in Figure 4.10 would not be identiﬁed by isomorphism, as,
although there is an obvious bijective mapping between events, which satisﬁes
the labelling and conﬂict conditions, the bijection will not satisfy the bundles
condition, as {fx} →fz, but {ex} ̸→ez. However, their behaviour is clearly
equivalent.
So, we seek weaker equivalences than isomorphism that identify bundle
event structures according to their behaviour. We begin with a weak inter-
pretation and then work in the direction of, generally, stronger equivalences;
none of which though will be stronger than isomorphism.

4.6 Development Relations
127
e
e
e
(1)
f
(2)
(3)
f
f
f
(4)
e
e
e
x
z
y
z
x
y
z
x
y
z
Fig. 4.10. Nonisomorphic Event Structures
Sequential Bisimulations. Using the mapping between BES and LTS de-
ﬁned in Section 4.5, we can deﬁne BES equivalences, which correspond to the
bisimulations considered earlier for labelled transition systems.
We could deﬁne equivalences, which are weak in the sense of weak bisim-
ulation; i.e. only identify according to the observable behaviour, however, in
accordance with the intensionalist true concurrency view, we do not do this
and internal actions are treated as any other action. See [131] for the deﬁni-
tion of an equivalence that abstracts from internal actions. Thus, the relation
that we consider corresponds to strong bisimulation.
Deﬁnition 21
(Sequential Strong Bisimulation Relation)
A binary relation R ⊆BES × BES is a sequential strong bisimulation if
(ε1, ε2) ∈R implies ∀a ∈Act ∪{i, δ},
1. ∀ε′
1 ∈BES, ε1 • a
−→ε′
1 =⇒∃ε′
2 ∈BES . ε2 • a
−→ε′
2 ∧(ε′
1, ε′
2) ∈R ∧
2. ∀ε′
2 ∈BES, ε2 • a
−→ε′
2 =⇒∃ε′
1 ∈BES . ε1 • a
−→ε′
1 ∧(ε′
1, ε′
2) ∈R
Deﬁnition 22
(Sequential Strong Bisimilar)
∼sq ≜{ R | R is a sequential strong bisimulation }

128
4 True Concurrency Models: Event Structures
......
e
e
e
(1)
f ......
f
f’
f
(2)
......
e
e
f
f
e
e
(3)
f ......
(4)
f
e
e
(5) The empty BES
f’
x
y
z
y
z
x
x
y
z
y
z
x
y
x
y
x
y
f’y
f’x
y
f’x
(1.x)
(2.x)
(2.x’)
(3.y)
(3.x)
(4.x)
(4.y)
Fig. 4.11. Event Structures Illustrating Equivalence Relations
As illustrations of this deﬁnition, consider the bundle event structures depicted
in Figure 4.11, where impossible events, i.e. with a null incoming bundle, are
simply not depicted. The BES are identiﬁed as follows.
(1) depicts ε1;
(1.x) depicts ε1.x;
(2) depicts ε2;
(2.x) depicts ε2.x;
(2.x′) depicts ε2.x′;
(3) depicts ε3;
(3.y) depicts ε3.y;
(3.x) depicts ε3.x;
(4) depicts ε4;
(4.x) depicts ε4.x;
(4.y) depicts ε4.y;
and
(5) depicts ε3.0 = ε4.0.
As would be expected, sequential bisimulation over BES distinguishes branch-
ing points; thus, ε1 ̸∼sq ε2. This is because, for example, ε2 • x
−−→ε2.x, for which
the only matching transition in ε1 is ε1 • x
−−→ε1.x. However, ε1.x ̸∼sq ε2.x as
ε1.x • z
−→, but ε2.x • z
−→
̸
.
The transition relation •−−→oﬀers an interleaved interpretation of BES;
thus, as its name suggests, sequential bisimulations do not distinguish inde-

4.6 Development Relations
129
pendent parallelism from choice and sequence. For example, ε3 ∼sq ε4, because
the relation,
R = { (ε3, ε4), (ε3.y, ε4.y), (ε3.x, ε4.x), (ε3.0, ε4.0) }
is a sequential strong bisimulation.
In a true concurrency setting, where we are seeking to distinguish concur-
rency from interleaving, sequential bisimulation is an unsuitable equivalence.
The remaining relations all distinguish concurrency from interleaving.
Step Equivalences. Step semantics oﬀer a simple means to distinguish con-
currency from interleaving. Before we deﬁne the induced equivalence relations,
we need some preliminary concepts.
First, we deﬁne a partial order causality relation over bundle event struc-
tures, which has a similar character to the classic causality relation of prime
event structures (see the discussion in Section 4.7).
Deﬁnition 23
(Causality)
Given a BES ε, we deﬁne a causality partial order, denoted ⪯, as follows,
e ≺e′ iﬀ∃X ⊆Eε s.t. e ∈X ∧X →ε e′ and
⪯is the reﬂexive and transitive closure of ≺
The restriction of ⪯to a particular conﬁguration C of ε is denoted ⪯C.
So, ⪯is the causality partial order induced by the bundle relation.
A standard relation in event structures theory is that of independence.
This states when events are not related by causality or conﬂict, are thus,
independent of one another, and can evolve independently in parallel.
Deﬁnition 24
(Independence in a Conﬁguration)
Given a conﬁguration C ∈CF(ε), then events e and e′ in C are independent,
denoted e ⊗C e′ if and only if ¬(e ⪯C ∪⪰C e′).
Notice that the fact that e and e′ are in the same conﬁguration implies that
they are not related by #.
In order to deﬁne a step semantics-based equality, we use the notion of
a step transition relation, ▶A
−−→⊆BES × BES, where A is a multiset over
Act ∪{i, δ}. A multiset is a function A : Act∪{i, δ} →N where A(a) denotes
the number of occurrences of the action a in the multiset. Remember, multiple
instances of an action may occur in parallel with one another; this is called
autoconcurrency. The required transition relation is deﬁned as follows.
Deﬁnition 25
We use the auxiliary function L(X) : Act ∪{i, δ} →N, which for ε ∈BES
and X ⊆Eε, denotes the multiset of labels of events from X, and is deﬁned
as L(X)(a) ≜|{e ∈X | lε(e) = a}|.
Now, for a given BES ε, we can deﬁne the transition relation:

130
4 True Concurrency Models: Event Structures
∀A s.t. A : Act ∪{i, δ} →N,
ε ▶A
−−→ε[C] iﬀC ∈CF(ε) ∧∀e, e′ ∈C, e⊗C e′ ∧L(C) = A
ε ▶A
−−→ε′ states that the BES ε can concurrently perform the multiset of
actions A and evolve to ε′.
This construction enables us to deﬁne, ﬁrst, the notion of a step trace and
then, a step bisimulation; a multiset is called a step.
Deﬁnition 26
A multiset sequence, A1 . . . An, is a step trace of ε ∈BES iﬀ∃ε0, . . . , εn ∈BES
such that ε = ε0 ∧εi−1 ▶Ai
−−→εi for 1 ≤i ≤n. If we let
Trst(ε) = { ρ | ρ is a step trace of ε }
then, this induces an equivalence:
S ≍st S′ iﬀTrst(J S Kbe) = Trst(J S′ Kbe)
Deﬁnition 27
(Step Strong Bisimulation Relation)
∀ε1, ε2 ∈BES, R ⊆BES × BES is a step strong bisimulation if (ε1, ε2) ∈R
implies ∀A s.t. A : Act ∪{i, δ} →N,
1. ∀ε′
1 ∈BES, ε1 ▶A
−−→ε′
1 =⇒∃ε′
2 ∈BES . ε2 ▶A
−−→ε′
2 ∧(ε′
1, ε′
2) ∈R ∧
2. ∀ε′
2 ∈BES, ε2 ▶A
−−→ε′
2 =⇒∃ε′
1 ∈BES . ε1 ▶A
−−→ε′
1 ∧(ε′
1, ε′
2) ∈R
Deﬁnition 28
(Step Strong Bisimilar)
∼st ≜{ R | R is a step strong bisimulation }.
In a general sense, step trace equivalence is related to step bisimulation in a
similar way to which strong trace equivalence (in which, internal actions are
not collapsed) would be related to strong bisimulation in LTS. Thus, we do not
discuss step trace equivalence further; it is largely included for completeness.
Step bisimulation is more discriminating than sequential bisimulation.
With regard to the examples presented in Figure 4.11, ε1 ̸∼st ε2 and ε3 ̸∼st ε4.
The ﬁrst of these arises because ∼st ⊆∼sq, which can be veriﬁed quite easily,
whereas the second arises because
ε3 ▶{(x,1),(y,1)}
−−−−−−−−−→
but,
ε4 ▶{(x,1),(y,1)}
−−−−−−−−−−→
̸
where we have denoted the multiset by its underlying set of pairs. Thus, step
bisimulation semantics are more discriminating than sequential bisimulation
semantics; i.e. ∼st ⊂∼sq.
Pomset Equivalence. Partially ordered multisets, or pomsets, are a well-
known truly concurrent semantic model. In deriving pomsets and their in-
duced equivalence, we take the approach employed in [114], which is to deﬁne
an even more expressive semantics, labelled partially ordered sets, or lposets,

4.6 Development Relations
131
and then derive pomsets from this model. This is also similar to the approach
taken in [131].
Lposet semantics for BES were presented in [114] and are based on ideas
investigated in [170]. The approach is to model events as well as actions (all
previous approaches have only modelled actions) and, in addition, to include
causality relations. Thus, an lposet is a conﬁguration of a BES with labelling
and causalities between events included. We have the following deﬁnition.
Deﬁnition 29
(Lposets)
Take ε ∈BES; then if C ∈CF(ε), there is a labelled partially ordered set (or
lposet) corresponding to C, denoted C, deﬁned as C = (C, ⪯C, lε⌈C).
LP(ε) denotes the set of all lposets of a BES ε.
Lposets are denoted lp and the elements of lp can be accessed using Elp, ⪯lp
and llp.
So, an lposet is a triple containing a set of events, a partially ordered
causality relation and a labelling. In fact, an lposet can be viewed as a (la-
belled) conﬂict-free prime event structure (see discussion of event structure
models in Section 4.7). Each lposet corresponds to a single system run and in-
cludes the causalities that have contributed to the run. Because ⪯is a partial
ordering, independence of events will be reﬂected in the lposet.
From lposets we deﬁne pomsets using the notion of an lposet isomorphism.
Deﬁnition 30
lp is isomorphic to lp′, denoted ≃, iﬀthere exists a bijection φ : Elp →Elp′
such that
1. e ⪯e′ ⇐⇒φ(e) ⪯φ(e′)
2. l(e) = l(φ(e))
The isomorphism class of an lposet is a pomset over Act. The pomset cor-
responding to an lposet C is denoted by [C]≃. PoS(ε) denotes the set of all
pomsets of ε; i.e.
PoS(ε) ≜{ [C]≃| C ∈CF(Eε ) }
Now we can deﬁne pomset equivalence.
Deﬁnition 31
(Pomset Equivalent)
Two event structures, ε and ε′, are pomset equivalent, denoted ε ≍P oS ε′, if
and only if PoS(ε) = PoS(ε′).
Pomsets are trace-based semantics, so they do not distinguish forms of choice.
For example, ε1 ≍P oS ε2 (see Figure 4.11), because they both have the maxi-
mal pomsets {[x →y], [x →z]} (each pomset is denoted inside square brack-
ets; for example, [x →y] denotes the isomorphism class of pomsets with two
events labelled x and y, respectively, and a causality between the events).
Notice, the maximal lposets of ε1 are {[ex →ey], [ex →ez]} and the maximal

132
4 True Concurrency Models: Event Structures
lposets of ε2 are {[fx →fy], [f ′
x →fz]}; so, they are not lposet equivalent.
This is reﬂected in our consideration of equality of proving sequences. How-
ever, [ex →ey] and [fx →fy] are in the same isomorphism class and similarly,
[ex →ez] and [f ′
x →fz] are isomorphic.2 Thus, we have a pair of BES, (ε1, ε2),
such that ε1 ≍P oS ε2, but ε1 ̸∼st ε2. Thus, ≍P oS ̸⊆∼st.
Furthermore, we can show that ∼st does not imply ≍P oS, by considering
the two behaviours:
P := ( x ; stop ) ||| ( y ; stop )
Q := ( x ; stop ||| y ; stop ) [] ( x ; y ; stop ) [] ( y ; x ; stop )
The underlying bundle event structures for these two behaviours are step
equivalent, however, they are not pomset equivalent. The resulting bundle
event structures are depicted as (1), respectively, (2) in Figure 4.12. Note,
this example reveals a limitation of step equivalence. This diﬃculty arises
because, in addition to maximal steps (i.e. multisets that reﬂect as many
independent events as possible at a particular state), it is also possible to take
submaximal steps. For example, if we let εP denote the BES arising from P
and assume εx ; stop and εy ; stop similarly, then, although εP ▶{(x,1),(y,1)}
−−−−−−−−−→, it
is also the case, for example, that εP ▶{(y,1)}
−−−−−→εx ; stop and εx ; stop ▶{(x,1)}
−−−−−→.
Critically, in P, this possibility to perform such submaximal steps, eﬀectively,
covers the interleaving of x and y, found as an alternative to the independent
parallel behaviour, in Q. It is for this reason that P and Q are indistinguishable
according to step semantics.
In Figure 4.12, (3) and (4) give another such example; they are step bisim-
ulation equivalent, but not pomset equivalent (this example is due to Van
Glabbeek [191]).3 So, ∼st and ≍P oS are incomparable; that is, neither implies
the other.
Proving Sequence Equivalence. Now we come to what is our most discrim-
inating event structure development relation: equality of proving sequences,
denoted ≍P S. Firstly, we have the following important result.
Proposition 6
PS(ε) = PS(ε′) ⇐⇒LP(ε) = LP(ε′) ⇐⇒CF(ε) = CF(ε′).
Proof
See [114].
⃝
So, equality of proving sequences is equivalent to equality of lposets and
to equality of conﬁgurations. Thus, without loss of generality we can use
2The key point is that a diﬀerent bijection, φ in deﬁnition 30, is used in each
pomset, which is quite legitimate.
3Although, it is not clear what process calculus speciﬁcation would generate the
event structure in Figure 4.12(4).

4.6 Development Relations
133
(1)
(3)
......
......
......
......
(4)
......
......
......
......
(2)
............
x
y
x
x’
y"
y’
y
x"
x
z
y
x
y’
y
z’
z
Fig. 4.12. More Event Structures Illustrating Equivalence Relations
these three equalities interchangeably. Here we focus on equality of proving
sequences.
≍P S is a discriminating equality, not only does it discriminate concurrency
and interleaving, it also distinguishes choice points. The discriminating power
over choice is obtained because events are referenced rather than actions. Such
event references imply an inherently more intensionalist equality than those
we have considered so far.
Implicitly ≍P S is deﬁned modulo an isomorphism, but it is a diﬀerent
isomorphism to that used to generate pomsets.
Deﬁnition 32
(Proving Sequence Isomorphic)
Given E = {e | ∃σ ∈PS(ε) . e ∈$σ} and E′ = {e | ∃σ ∈PS(ε′) . e ∈$σ},
where $σ returns the set of elements in a sequence, then ε and ε′ are proving
sequence isomorphic, denoted ≍P S, if and only if there exists a bijection,
φ : E →E′,
such that,
lε(e) = lε′(φ(e))
and
e1 . . . en ∈PS(ε) ⇐⇒φ(e1) . . . φ(en) ∈PS(ε′).
Notice how this isomorphism behaves diﬀerently to that used to derive pom-
sets. In pomsets, the isomorphism is between the events in a single lposet.
However, here our isomorphism is between the events of the entire set
of proving sequences. For example, if we consider ε1 and ε2 again, which
are pomset equivalent, as indicated earlier, the maximum lposets of ε1 are
[ex →ey] and [ex →ez] and the maximum lposets for ε2 are [fx →fy] and
[f ′
x →fz]. Now, individually, [ex →ey] and [fx →fy] are isomorphic; i.e.
φ = {(ex, fx), (ey, fy)} will work, and in addition, [ex →ez] and [f ′
x →fz] are
isomorphic, but only by a diﬀerent isomorphism, viz φ′ = {(ex, f ′
x), (ez, fz)}.
However, there does not exist a single bijection between the two sets of lposets

134
4 True Concurrency Models: Event Structures
{[ex →ey], [ex →ez]} and {[fx →fy], [f ′
x →fz]} as the latter contains two
events labelled x, whereas the former contains only one such event. Similarly,
the induced sets of maximal proving sequences, {exey, exez} from ε1, and
{fxfy, f ′
xfz} from ε2, are not isomorphic.
So, in terms of the examples presented in Figure 4.11, ε1 ̸≍P S ε2 and
ε3 ̸≍P S ε4. In addition, the two pairs of BES highlighted in Figure 4.12 are
distinguished by ≍P S. But, the more signiﬁcant observation is that proving
sequence equality often diﬀerentiates BES with identical external behaviour.
For example, the two BES depicted in Figure 4.13 are distinguished by proving
sequence equality. A justiﬁcation for such a strong notion of equality is that,
although behaviourally the two BES are the same, in terms of implementation
they are not the same, in the sense that (2) is a more resilient solution, because
it has some built-in redundancy.
f ...... f
e
(1)
(2)
x
x
x’
Fig. 4.13. BES with the Same Behaviour
4.7 Alternative Event Structure Models
We discuss three event structure models, which are to be found in the litera-
ture: prime event structures, stable event structures and ﬂow event structures.
We relate each of these to the BES model we have just presented.
Prime Event Structures. These were the original event structures model,
as deﬁned in [155]. They are called “prime” event structures because, when
the model is related to domain theory, it yields a Prime Algebraic Coherent
Partial Order [155]. Ignoring labelling, which could easily be added, prime
event structures have the following basic form.
A prime event structure is a triple: ε = (E, #, ≤), where
•
E is a set of events;
•
# ⊆E × E is a conﬂict relation (irreﬂexive and symmetric); and
•
≤⊆E × E is a causality relation (a partial order).
The structure is subject to the following two conditions.
1. Finite Causes – { e′ | e′ ≤e } is ﬁnite

4.7 Alternative Event Structure Models
135
2. Conﬂict Inheritance – e#e′ ∧e′ ≤e′′ ⇒e#e′′
There are two basic aspects of prime event structures that diﬀer from BES:
the deﬁnition of causality and the conﬂict inheritance property.
•
Causality. This is a binary partial order relation between events. It is
denoted e ≤e′, which, if equality of events is factored out, induces a
relation <, which states that “e must happen before e′ can happen” or,
alternatively, “e′ depends upon the previous occurrence of the event e.”
This is a naturally transitive interpretation and, thus, ≤is a partial order.
•
Conﬂict Inheritance. The conﬂict relation has the same form as in BES; i.e.
it is a binary relation between events. However, an additional constraint is
imposed. This is the conﬂict inheritance property, which states that, if an
event is in conﬂict with a second event, all causal successors of the event
must be in conﬂict with the second event.
Prime event structures are a very simple true concurrency model with nice
mathematical properties, but they are not well suited to modelling a process
calculus like pbLOTOS. As acknowledged by [198], they oﬀer a limited inter-
pretation of parallel composition. This is because the model does not allow
events to have multiple possible enablings. Consider the behaviour:
( x ; y ; stop [] x ; stop ) |[x]| ( x ; z ; stop ) (∗)
which generates the BES depicted in Figure 4.14(1), where the event gz could
be enabled by either gx or g′
x. The obvious representation in an event structure
with binary causality is depicted in Figure 4.14(2). However, this structure
contradicts the conﬂict inheritance property, which would require that gz be
in conﬂict with both gx and g′
x.
......
g
g
g
......
g
g
g
(1)
(2)
g’
......
g
g
g
(3)
z
y
x
z
y
g’x
x
y
z
g’x
x
x
g’z
Fig. 4.14. Event Structures with Multiple Enablings
Prime event structures have the nice property that each event is enabled by
a unique set of events, which immediately prevents choices of enabling from
being modelled. However, it should be pointed out that copying of events can
be used to model the behaviour we are seeking in prime event structures. For
example, we could duplicate the event gz to obtain the structure depicted
in Figure 4.14(3). This is the solution employed in [131] for modelling CSP

136
4 True Concurrency Models: Event Structures
parallel composition. This solution has been argued against even by Winskel
[198], because a conceptually “single” piece of computation, the event gz, has
been subdivided.
Stable Event Structures. These are an enhancement of prime event struc-
tures, which overcomes the problem highlighted in the previous section. The
main diﬀerence to prime event structures is that the binary causality relation
is replaced by a, nonbinary, enabling relation:
⊢⊆Con × E
where Con is the set of all ﬁnite conﬂict-free subsets of E; i.e.
Con ≜{ X ⊆E | ∀e, e′ ∈X, ¬(e#e′) }
So, for example, for X ∈Con and e ∈E we could have X ⊢e, which states
that, if all the events in X have occurred, then e can occur. In accordance
with this interpretation, we impose the following constraint,
X ⊢e ∧X ⊆Y ∧Y ∈Con =⇒Y ⊢e
i.e. e is enabled by any conﬂict-free set, which contains more than the mini-
mum number of events required to enable e. An enabling relation is depicted
in a similar way to a bundle; e.g. {e, e′} ⊢e′′ would be depicted as in Figure
4.15. However, it should be apparent that the enabling relation has quite a
diﬀerent meaning to the bundle relation in BES.
e’
e"
e
Fig. 4.15. An Enabling Relation
A stable event structure has the following structure.
A stable event structure is a triple: ε = (E, #, ⊢) where
•
E is a set of events;
•
# ⊆E × E is a conﬂict relation (irreﬂexive and symmetric); and
•
⊢⊆P(E) × E is the enabling relation.
Stable event structures can model behaviours such as (*), which was high-
lighted in the subsection on prime event structures. This is because they do

4.7 Alternative Event Structure Models
137
e’
e"
e
Fig. 4.16. Concurrent Enablings
not include the conﬂict inheritance property. In fact, the stable event structure
for (*) would be the structure depicted in Figure 4.14(2).
However, without more constraints, structures of the form depicted in
Figure 4.16 can be deﬁned. This structure has two enabling relations {e} ⊢e′′
and {e′} ⊢e′′. Conceptually, this is a slightly odd structure as both the sets
{e} and {e′} enable e′′, but their union, {e, e′}, does not, even though {e, e′}
is conﬂict-free. Another way of looking at this structure is that the enabling
of e′′ is not unique; i.e. in a conﬁguration {e, e′, e′′} we do not know whether
e′′ is immediately caused by {e} or {e′}. In response to this observation,
[198] imposes the, so-called, stability condition on the basic event structure
construction, hence the name stable event structures. This condition states
the following,
X ⊢e ∧Y ⊢e ∧X ∪Y ∪{e} ∈Con =⇒X ∩Y ⊢e
which would not be satisﬁed by the structure depicted in Figure 4.16, because
{e} ∩{e′} = ∅̸ ⊢e′′. A unique minimal enabling set can always be found,
which is obtained by taking the intersection of enabling sets, as suggested by
the above property.
Winskel [198] deﬁnes a stable event structure semantics for parallel compo-
sition and a semantics for pbLOTOS based on stable event structures could be
deﬁned. However, we have chosen to use bundle event structures, as their link
with LOTOS has been more extensively explored than is the case with stable
event structures. In addition, [114] argues against stable event structures on
a number of technical grounds.
Flow Event Structures. These oﬀer an alternative approach to resolving
the problems prime event structures have in modelling parallel composition.
The main workers are Boudol and Castellani, and a good reference to the
work is [31].
The basic idea of ﬂow event structures is to drop the conﬂict inheritance
property of prime event structures, but maintain a binary causality relation,
although this will have a diﬀerent character.
A ﬂow event structure is a triple: ε = (E, #, ≺) where
•
E is a set of events;

138
4 True Concurrency Models: Event Structures
•
# ⊆E × E is a conﬂict relation (symmetric, but not necessarily
irreﬂexive); and
•
≺⊆E × E is an irreﬂexive binary ﬂow relation.
It is important to note that the ﬂow relation has a diﬀerent interpretation to
the causality relation of prime event structures. Speciﬁcally, e ≺e′ means “if
e occurs e′ cannot have already occurred.” This does not induce a transitive
relation; for example, consider the ﬂow event structure depicted in Figure
4.17, which could have been generated from the pbLOTOS behaviour:
( y ; x ; stop ||| x ; stop ) |[x]| ( x ; z ; stop )
g’
......
g
g
g
y
x
x
z
Fig. 4.17. A Flow Event Structure
Although, gy ≺gx and gx ≺gz it is clear that gy ̸≺gz. In particular, a
legitimate evaluation of this event structure could perform g′
x ﬁrst, then gz
and ﬁnally gy. Thus, gz has occurred before gy. ≺is a local, nontransitive
relation, which expresses immediate enabling.
Another important aspect of ﬂow event structures is the concept of self-
conﬂicting events; i.e. events e such that e#e. These are used to model events
that cannot occur and, thus, to create deadlock situations (in a related way
to the use of empty bundles in BES). Flow event structure semantics could
also be given for LOTOS. However, [114] argues against this on a number of
grounds, most signiﬁcantly, because self-conﬂicting events cannot be removed
from ﬂow event structures; i.e. a transformation cannot be found which re-
moves such events, but yields an equivalent event structure in terms of possi-
ble conﬁgurations. This is in contrast to the situation with BES, where empty
bundles can be transformed out.
4.8 Summary and Discussion
Bundle event structures are a more discriminating semantics than the inter-
leaving semantics that we have considered in Chapter 3. In particular, they

4.8 Summary and Discussion
139
allow us to distinguish between concurrent behaviour and forms of choice and
sequence which model interleaving. Conceptual justiﬁcations for event struc-
ture approaches emphasise the importance of the intensionalist view of mod-
elling concurrent systems. The added expressiveness of bundle event struc-
tures is reﬂected in the increased complexity of the semantic mapping from
pbLOTOS.
A spectrum of development relations can be identiﬁed for bundle event
structures. Each of these, to a diﬀerent degree, abstracts away from the ex-
pressiveness of the basic bundle event structures. In particular, interleaving
equivalences and relations can be regained. In addition, more discriminating
relations, which distinguish concurrency from interleaving can be highlighted.
Even relations which diﬀerentiate according to the internal construction of
speciﬁcations can be deﬁned.

5
Testing Theory and the Linear Time –
Branching Time Spectrum
There is a whole spectrum of alternative approaches to the three semantic
models we considered in Chapters 3 and 4. This chapter discusses a number
of these alternatives, within the context of a powerful conceptual framework
for investigating the meaning of concurrent systems: testing theory. Central
to this approach is the principle that has dominated our treatment of con-
currency theory; that is, that two systems / processes are considered to be
equivalent if they cannot be distinguished by an external observer or, in other
words, by an agent testing the system. This statement leaves open a number
of issues; perhaps most signiﬁcantly, what capacity does the observer have to
test / interrogate the system? Note that, in Chapter 2, we informally (and im-
plicitly) took a position on this question, when we explained the behaviour of
pbLOTOS operators and speciﬁcations in terms of performing button-pressing
actions on a black box representation of systems.
We only have room to describe one of these models in depth; this is the
trace-refusals model, which we discuss in Section 5.1. This approach arises
out of a very natural interpretation of the capacity of an observer to test
a process, which we discuss in Section 5.2. Then, in Section 5.3, we review
the spectrum of testing theoretic interpretations of diﬀerent equivalences and
preorders. Finally, in Section 5.4, we show how the testing theory discussed
in this chapter can be applied in the context of object-oriented distributed
systems.
It is also important to note that this chapter focuses exclusively on inter-
leaving semantics. This is because testing theories have been far more exten-
sively explored in this context than in the true concurrency domain.
5.1 Trace-refusals Semantics
5.1.1 Introduction
LOTOS trace-refusals semantics were derived from the failure semantics de-
ﬁned for CSP [96]. However, in LOTOS, the model is formulated in a subtly

142
5 Testing Theory and the Linear Time – Branching Time Spectrum
diﬀerent way to the CSP deﬁnition. We discuss this formulation here and give
a comparison with the CSP approach in Section 7.2.6.
Trace-refusals semantics are a hybrid approach, which extends trace se-
mantics. Remember, trace semantics cannot distinguish certain forms of
branching; in particular, they identify some behaviours that have quite diﬀer-
ent deadlock properties (i.e. one could deadlock where the other could not).
Thus, a second concept is added, which characterises the possible deadlocks of
a behaviour at a certain point in its evaluation. This is the notion of a refusal;
it records what a behaviour can refuse to do; i.e. a set of actions, which, if
oﬀered by the environment, would result in a deadlock.
The equality induced by trace-refusals is weaker than the bisimulation
equalities; it responds to the observation that weak bisimulation unrealistically
distinguishes certain behaviours. For example, the behaviours:
P := ( x ; x ; y ; stop ) [] ( x ; x ; z ; stop )
and
Q := x ; ( x ; y ; stop [] x ; z ; stop ),
x
x
x
x
x
x
y
z
y
z
*
**
P
Q
x
Fig. 5.1. Labelled Transition Systems with Two Levels of Nondeterminism
LTS for which are depicted in Figure 5.1, are not weak bisimilar. This is
because P can perform an x and evolve into the state marked *. In addition,
after x, Q must evolve into the state marked **, but these two states are not
weak bisimilar, as * cannot perform an x and get into a state where it can
perform a z. A similar example was discussed in Section 3.3.3.2: processes R5
and R6 in the discussion of ready simulation.
The problem is that bisimulation is too discriminating with regard to
branching. Both P and Q contain a nondeterministic choice; in P it is imme-
diate, whereas in Q it is after one x. However, the point at which this internal
choice is made will not be observable, because both can perform two xs and
then reach a state where they can either only perform a y or only perform a z.
Thus, there is strong intuitive justiﬁcation for equating these two behaviours.

5.1 Trace-refusals Semantics
143
Trace-refusals semantics will not distinguish these two behaviours. In fact,
we show a number of behaviours that trace-refusals identiﬁes, but ≈does not.
5.1.2 The Basic Approach
The central concept in trace-refusals semantics is that of a refusal. A set
of actions X is a refusal at a particular state if none of the actions can be
performed at that state; i.e. they are all refused. Thus, if you consider the
behaviour:
P1 := x ; y ; stop,
which has alphabet of actions {x, y}, at its initial state, it can refuse the sets
∅and {y} (each of these sets is called a refusal), but it cannot refuse x. After
performing an x, the behaviour can refuse ∅and {x}. Finally, after performing
xy, the behaviour will have four possible refusals: ∅, {x}, {y} and {x, y}.
We typically talk about a refusal after a certain trace. Thus, P1 will refuse
{x, y} after the trace xy. Notice that the empty set is a refusal of all states,
because any state can refuse to perform all actions in the empty set.
An intuitive justiﬁcation for the trace-refusals formulation is in terms of
testing. Assume that we are a tester who is observing how a particular spec-
iﬁcation behaves. We have the capacity to record the actions that are per-
formed; this is the trace part of trace-refusals. In addition, we can observe
when a deadlock has occurred. A ﬁnite observation of a speciﬁcation either
yields a trace or a trace followed by deadlock. In the latter case, a trace may
be recorded along with a set of actions, which indicates the set of actions
oﬀered by the environment at the point where deadlock ensued; it is a refusal
of the speciﬁcation after the recorded trace. We elaborate on this intuition in
Section 5.2.
A complete trace-refusals characterisation of a speciﬁcation B is a pair,
which records the set of traces B can perform and the set of all possible
refusals of B after any trace. We denote the set of all refusals of a behaviour
B after a trace σ by
RefB(σ)
and this will be a subset of P(Act ∪{δ}). Notice that, because it cannot be
synchronised on, the internal action cannot be included in a refusal set. So,
the observer cannot test a system with regard to i. This also reﬂects the fact
that we are once again only interested in observable behaviour.
Thus, a refusals model for a speciﬁcation S is a pair:
(J S Ktr,RefS) ∈P(T ) × ( T →P( P(Act ∪{δ}) ) )
with ﬁrst element a set of traces and second element a function from traces to
sets of refusals. In CSP, this is written diﬀerently; each refusals set is associated
with a speciﬁc trace, to generate a failure. Thus, the basic model is a set of

144
5 Testing Theory and the Linear Time – Branching Time Spectrum
pairs, where the elements of each pair are a trace and a refusal. However,
the two are isomorphic formulations and one can trivially be regained from
the other. For example, the following function will map a LOTOS-style trace-
refusals characterisation to a CSP-style set of failures, where T is a set of
traces and Ref is a function from traces to sets of refusal sets.
toF( (T, Ref ) ) ≜

σ∈T
{ (σ, X) | X ∈Ref (σ) }
We present a series of examples to illustrate the LOTOS trace-refusals con-
cept.
5.1.2.1 Example 1
P1 := stop
J P1 Ktr = {ϵ},
RefP1(ϵ) = P(L)
The deadlock behaviour will perform nothing and refuse everything.
5.1.2.2 Example 2
P2 := x ; y ; stop
assuming L = {x, y}
J P2 Ktr = {ϵ, x, xy},
RefP2(ϵ) = {∅, {y}}
RefP2(x) = {∅, {x}}
RefP2(xy) = {∅, {x}, {y}, {x, y}} = P(L)
As suggested by this example, refusal sets are subset closed, because, if a set of
actions is refused, clearly, all subsets of the set of actions will also be refused.
5.1.2.3 Example 3
P3 := x ; ( y ; stop [] z ; stop )
assuming L = {x, y, z}
J P3 Ktr = {ϵ, x, xy, xz},
RefP3(ϵ) = P(L \ {x})
RefP3(x) = {∅, {x}}
RefP3(xy) = RefP3(xz) = P(L)
At a choice point, e.g. after the trace x, every action, apart from the actions
oﬀered in the choice, are refused.

5.1 Trace-refusals Semantics
145
5.1.2.4 Example 4
P4 := ( x ; y ; stop ) [] ( x ; z ; stop )
assuming L = {x, y, z}
J P4 Ktr = {ϵ, x, xy, xz},
RefP4(ϵ) = P(L \ {x})
RefP4(x) = {∅, {x}, {y}, {z}, {x, y}, {x, z}}
RefP4(xy) = RefP4(xz) = P(L)
This illustrates that choice points are distinguished, because the refusals of P3
and P4 are diﬀerent (notice their trace sets are the same). The two behaviours
are diﬀerentiated by the refusals after the trace x. P3 only refuses x, whereas
P4 refuses all subsets of {x, y} and {x, z}. This is because the refusals of P4
after the trace x are a composite of the refusals at the two states that can be
reached after the trace x. So, after a particular trace, a behaviour might be
able to get into a number of diﬀerent states and a refusal at each of these states
is a refusal of the behaviour after the trace. This is an important point, which
generates much of the subtlety of refusals. Such situations are characteristic
of nondeterministic behaviour. However, the set {y, z} is not a refusal of P4
after x, because if the environment oﬀers both y and z, one of them will be
able to be performed and thus, a deadlock will not result. In addition, note
that actions can be both performed and refused after a particular trace; e.g.
y can be oﬀered after x, but it can also be refused. We postpone considering
examples of how internal behaviour is represented until we have presented the
trace-refusals concept formally.
5.1.3 Deriving Trace-refusal Pairs
There are basically two approaches to deriving trace-refusals pairs from pbLO-
TOS speciﬁcations. The ﬁrst is via labelled transition systems and the second
is through a direct semantics. We consider these in turn.
5.1.3.1 Deriving Trace-refusals from Labelled Transition Systems
The standard semantics for LOTOS are labelled transition systems; this is
the semantic model presented in the deﬁning standard [104]. Thus, a natural
approach is to derive trace-refusals semantics indirectly via labelled transition
systems. Thus, LOTOS speciﬁcations are ﬁrst mapped to labelled transition
systems and then a trace-refusals characterisation is derived from the labelled
transition system. In fact, this is the standard approach for deriving trace-
refusals for LOTOS.
The heart of the labelled transition system to trace-refusals mapping is
the double arrow transition relation deﬁned in Section 3.3.2.3, which was used
there to generate trace sets from labelled transition systems. Our approach
here is a natural extension of the mapping of Section 3.3.2.3.

146
5 Testing Theory and the Linear Time – Branching Time Spectrum
An important mapping used in constructing trace-refusals is after, which
is deﬁned as,
B after σ ≜{ B′ | B
σ
=⇒B′ }
which denotes the set of all states reachable from B, after performing the
trace σ. Using this mapping, we can deﬁne the refusals of a behaviour after a
particular trace:
RefB(σ) ≜{ X | ∃B′ ∈B after σ s.t. ∀x ∈X, B′
x
≠⇒}
This denotes the set of all sets, X say, such that a state can be reached after
σ, at which all actions in X are refused. It is important to notice that this is
a set of sets; i.e. all possible refusals after performing the trace σ. Also notice
that, as indicated earlier, the refusals after a particular trace are a composite
of the refusals at each state reachable after that trace.
5.1.3.2 Direct Denotational Semantics
The failures semantics for CSP are deﬁned using a direct denotational se-
mantics [171]. Thus, the eﬀect of each operator on the traces and refusals is
deﬁned directly. Leduc [120] attempts to give a similar direct semantics for
LOTOS, however, it is important to note that the modelling of divergence
in his semantics is very diﬀerent from that employed in the CSP semantics
(as discussed in the next section). In particular, he seeks to give a noncatas-
trophic interpretation of divergence, which is in accordance with the standard
LOTOS interpretation of the concept. However, this turns out to be prob-
lematic and Leduc shows that the LOTOS hiding operator cannot be fully
modelled in this setting. The problem is that it is very hard to see how to give
hiding a compositional semantics. Due to this complexity we do not present a
direct denotational semantics here; the interested reader is referred to Leduc’s
thesis [120].
5.1.4 Internal Behaviour
The handling of internal behaviour in trace-refusals semantics leads to much
of the subtlety and power of the approach. This section presents examples of
how pbLOTOS behaviours with internal actions map to trace-refusals models.
These follow on from the examples presented in Section 5.1.2.
The pbLOTOS behaviours:
P1 := i ; i ; x ; y ; stop
P2 := x ; i ; y ; stop
P3 := x ; stop [] y ; stop
P4 := ( i ; x ; stop ) [] ( i ; y ; stop )
P5 := ( i ; x ; stop ) [] ( y ; stop )

5.1 Trace-refusals Semantics
147
with L = {x, y}, have the following trace-refusals characterisations.
J P1 Ktr = { ϵ , x , xy }
RefP1(ϵ) = { ∅, {y} }
RefP1(x) = { ∅, {x} }
RefP1(xy) = P(L)
J P2 Ktr = { ϵ , x , xy }
RefP2(ϵ) = { ∅, {y} }
RefP2(x) = { ∅, {x} }
RefP2(xy) = P(L)
J P3 Ktr = { ϵ , x , y }
RefP3(ϵ) = { ∅}
RefP3(x) = RefP3(y) = P(L)
J P4 Ktr = { ϵ , x , y }
RefP4(ϵ) = { ∅, {x} , {y} }
RefP4(x) = RefP4(y) = P(L)
J P5 Ktr = { ϵ , x , y }
RefP5(ϵ) = { ∅, {y} }
RefP5(x) = RefP5(y) = P(L)
We discuss each of these in turn.
1. The trace-refusals characterisation of P1 is the same as the trace-refusals
characterisation for x ; y ; stop; this is because the internal actions do not
create any nondeterminism. Also, because refusals are deﬁned in terms of
the =⇒transition relation, the internal actions guarding x will be skipped
over and all states reachable after the empty trace; i.e. i ; i ; x ; y ; stop,
i ; x ; y ; stop and x ; y ; stop, will have the same refusals; i.e. ∅and {y}.
2. The point to note here is that the trace-refusals of P2 are identical to
those of P1, because once again, the internal action does not aﬀect the
observable behaviour.
3. P3 is included as a point of comparison with the refusals of P4 and P5.
Notice in particular that, after the empty trace, P3 does not refuse any
actions. This is because both actions in the alphabet of the behaviour are
oﬀered.
4. In contrast, P4 oﬀers a symmetric nondeterministic choice created through
internal behaviour. Thus, we would expect that P4 would have a diﬀerent
refusal characterisation after the empty trace to P3. In explaining the
refusal sets derived, you should ﬁrst notice that P4 after ϵ contains three

148
5 Testing Theory and the Linear Time – Branching Time Spectrum
states: the initial state, which we reference as P4, x ; stop and y ; stop.
This is because P4
ϵ
=⇒can map to any of these states. Thus, a refusal
at any one of these states will be a refusal of P4 after ϵ. In the initial
state, only the empty set can be refused, because P4
x
=⇒and P4
y
=⇒. So,
the initial state does not contribute any “proper” refusals. However, in
state x ; stop, both the empty set and {y} are refusals and, similarly, in
state y ; stop both the empty set and {x} are refusals. Thus, these are
all members of RefP4(ϵ). What this refusal characterisation is modelling is
the fact that, after the empty trace, P4 could be in a state where it refuses
{x} and it could be in a state where it refuses {y}. However, it cannot be
in a state where it refuses {x, y}.
5. Our ﬁnal example is that of an asymmetric nondeterministic choice. Once
again the interesting refusals are those after the empty trace. Notice that
P5 after ϵ will contain two states: P5 and x ; stop. As was the case for P4,
P5 has no proper refusals, but y can be refused at state x ; stop.
In understanding refusal characterisations of nondeterministic behaviour you
should remember that we are working in an untimed setting. Thus, it is as-
sumed, that, if an environment / tester is oﬀering a particular action, this oﬀer
will wait for any ﬁnite period necessary for the behaviour being observed to
complete any internal evolution. Thus, in P5, the action x cannot be refused
after the empty trace, because any tester will wait an arbitrarily long period
for P5 to evolve to state x ; stop.
In a similar vein, consider the following processes with cyclic behaviour,
transition systems for which are shown in Figure 5.2.
(1)
z
y
i
x
z
y
(3)
x
z
i
y
(2)
Q1
Q2
Q3
x
Fig. 5.2. Processes with Cyclic Behaviour
1. Q1 := x ; Q
and
Q := y ; Q [] z ; stop

5.1 Trace-refusals Semantics
149
2. Q2 := x ; Q′
and
Q′ := y ; i ; Q′ [] z ; stop
3. Q3 := x ; Q′′
and
Q′′ := i ; y ; Q′′ [] z ; stop
Assuming L = {x, y, z} and that Y is the set of all (nonempty) sequences
containing a ﬁnite repetition of y; i.e. y, yy, yyy, . . . , we have the following
trace-refusals characterisations.
J Q1 Ktr = J Q2 Ktr = J Q3 Ktr =
{ ϵ , x } ∪{ xσ | σ ∈Y } ∪{ xσz | σ ∈Y }
RefQ1(ϵ) = RefQ2(ϵ) = RefQ3(ϵ) = { ∅, {y} , {z} , {y, z} }
RefQ1(x) = RefQ2(x) = { ∅, {x} }
RefQ3(x) = { ∅, {x} , {z} , {x, z} }
∀σ ∈Y, RefQ1(xσ) = RefQ2(xσ) = { ∅, {x} }
∀σ ∈Y, RefQ3(xσ) = { ∅, {x} , {z} , {x, z} }
∀σ ∈Y, RefQ1(xσz) = RefQ2(xσz) = RefQ3(xσz) = P(L)
Thus, Q1 and Q2 are indistinguishable in trace-refusals semantics. This is
because the internal action in Q2 does not create nondeterminism, thus, it
is important to note that after performing xσ (for σ ∈Y ), Q2 is either in
state Q′ or i ; Q′ and neither of these states can refuse z. However, the state
y ; Q′′, reachable by Q3 after performing xσ (for σ ∈Y ), and actually also
after performing x, refuses z. Consequently, an observer that, for example,
wishes to perform the trace xyyyzδ, will always manage to reach δ (here used
as a signal of successful completion of an observation) with Q1 or Q2, whereas,
with Q3, it may deadlock attempting to perform the z and thus, not reach
the δ.
Much of the diﬀerence between alternative refusal-based semantic models
is associated with the interpretation of inﬁnite internal behaviour. This, for
example, is a major diﬀerence between the CSP failures model and LOTOS
trace-refusals, which we discuss in some depth in Section 7.2.6. However, as
a precursor to that discussion, here we consider the nature of the LOTOS
trace-refusals interpretation of cyclic internal behaviour.
The ﬁrst point to note is that, unlike many other approaches (see [192]
and especially CSP [171]), there is no extra semantic item, such as a set of di-
vergences, added to the basic trace-refusals pair. Thus, divergence; i.e. inﬁnite
internal behaviour, is semantically handled by the trace-refusals structure.
This is best understood by example. Consider the following behaviours,
transition systems for which are shown in Figure 5.3.
1. R1 := x ; stop
2. R2 := x ; R
and
R := i ; R
3. R3 := x ; R′
and
R′ := i ; i ; R′
4. R4 := x ; i ; R
and
R := i ; R

150
5 Testing Theory and the Linear Time – Branching Time Spectrum
5. R5 := x ; y ; stop
6. R6 := x ; R′′
and
R′′ := ( y ; stop ) [] ( i ; R′′ )
7. R7 := x ; R′′′
and
R′′′ := ( i ; y ; stop ) [] ( i ; R′′′ )
x
x
i
i
x
i
x
i
i
x
y
x
y
i
x
i
y
i
(1)
(2)
(3)
(4)
(5)
(6)
(7)
R 1
R
R
R
R
R 2
R 3
4
5
6
7
Fig. 5.3. Processes with Inﬁnite Internal Behaviour

5.1 Trace-refusals Semantics
151
Now, assuming that L = {x}, we have the following trace-refusals characteri-
sations for the ﬁrst four processes.
J R1 Ktr = J R2 Ktr = J R3 Ktr = J R4 Ktr = { ϵ , x }
RefR1(ϵ) = RefR2(ϵ) = RefR3(ϵ) = RefR4(ϵ) = { ∅}
RefR1(x) = RefR2(x) = RefR3(x) = RefR4(x) = P(L)
So, these four behaviours are indistinguishable by LOTOS trace-refusals.
Thus, with regard to the notion of observability inherent in these semantics,
the internal behaviour included fails to render R2, R3 or R4 distinguishable
from R1. The intuition for this is that, although a process may be inﬁnitely
evolving internally, this is not externally visible and is, thus, indistinguishable
from a process that has deadlocked.
Now, assuming that L = {x, y}, we have the following trace-refusals char-
acterisations for the ﬁnal three processes above.
J R5 Ktr = J R6 Ktr = J R7 Ktr = { ϵ , x , xy }
RefR5(ϵ) = RefR6(ϵ) = RefR7(ϵ) = { ∅, {y} }
RefR5(x) = RefR6(x) = RefR7(x) = { ∅, {x} }
RefR5(xy) = RefR6(xy) = RefR7(xy) = P(L)
So, again, including divergent loops is not detectable in these processes ac-
cording to LOTOS trace-refusals. For example, the reason that R5 and R7
are indistinguishable is that, although, after performing trace x, R7 may be
in a state where y is not immediately oﬀered, it will eventually (i.e. in a ﬁnite
period of time) evolve into a state where y is oﬀered. This intuition of eventu-
ally evolving into a state in which an action is oﬀered, is encapsulated in the
=⇒transition relation, as used in the deﬁnition of Ref ; see Section 5.1.3.1.
Thus, according to the intuition of untimed semantics, whereby, eﬀectively,
the observer is always willing to wait as long as necessary, an observer wishing
to perform a y after an x will be as satisﬁed with R7 as with R5. In other
words, they are indistinguishable and consequently, they both yield the same
trace-refusals characterisation.
A theoretical key to the handling of divergence in LOTOS trace-refusals is
a fairness assumption, which states that, if there is a path out of a tau cycle,1
as is the case in R6 and R7, then that path cannot be inﬁnitely often ignored.
In other words, if an action is repeatedly enabled, a process cannot inﬁnitely
often refuse to take that path. This is commonly called Kooman’s Fair Ab-
straction property [8] and it is an issue we return to when we compare the
LOTOS and the CSP handling of divergence, the latter of which is typically
described as a catastrophic interpretation of divergence.
1Internal actions are denoted τ in CCS; consequently, the term tau cycle has
been inherited from this earlier process calculus and is used in preference to the
term i cycle.

152
5 Testing Theory and the Linear Time – Branching Time Spectrum
5.1.5 Development Relations: Equivalences
We can identify a number of development relations, which are deﬁned in terms
of trace-refusals semantics. We begin by considering equivalence.
The basic equivalence induced by trace-refusals semantics is testing equiv-
alence.
Deﬁnition 33
(Testing Equivalence)
Behaviours B and B′ are testing equivalent, denoted B te B′, if and only if,
•
J B Ktr = J B′ Ktr
and
•
∀σ ∈J B Ktr, RefB(σ) = RefB′(σ)
Proposition 7
te is an equivalence relation.
Proof
The result is clear from the properties of set equality.
⃝
So, speciﬁcations are testing equivalent if they have the same trace-refusals
characterisation; in other words, if they have the same trace and deadlock
properties.
A particularly interesting aspect of testing equivalence is how it relates
to weak bisimulation equivalence. First, let us consider the example that we
identiﬁed at the start of this section.
P := x ; x ; y ; stop [] x ; x ; z ; stop
and
Q := x ; ( x ; y ; stop [] x ; z ; stop )
It is clear that P and Q are trace equivalent, but, in addition, after any trace,
they have the same refusals. The crucial point is the refusals after the trace x:
in both cases, everything apart from x is refused. Trace-refusals identify these
behaviours because these semantics are not as distinguishing with regard to
branching as bisimulations. In this respect, trace-refusals seem a more realistic
semantic interpretation.
The following are all examples of speciﬁcations that are testing equivalent,
but not weak bisimilar; (1) is taken from [104] and (2) is taken from [120].
(1) P1 := x ; ( x ; x ; stop [] x ; stop )
and
Q1 := ( x ; x ; x ; stop ) [] ( x ; x ; stop )
(2) P2 := x ; y ; stop [] x ; z ; stop ,
Q2 := i ; x ; y ; stop [] i ; x ; z ; stop
and
R2 := x ; ( i ; y ; stop [] i ; z ; stop )
(3) P3 := i ; x ; stop [] y ; stop and
Q3 := i ; x ; stop [] i ; ( x ; stop [] y ; stop )

5.1 Trace-refusals Semantics
153
These examples demonstrate that te ̸⊆≈. However, it is a well-known result
that ≈⊆te [52]. Thus, we have the following important relationship between
bisimulation equivalences and testing equivalences.
Theorem 5.1.
≈⊂te
However, unfortunately, testing equivalence is not a congruence. As was the
case with weak bisimulation, choice is an oﬀending context. For example,
x ; stop
and
i ; x ; stop
are testing equivalent, but it is not the case that the following are testing
equivalent.
x ; stop [] y ; stop
and
i ; x ; stop [] y ; stop
In addition, Leduc has shown [120] that hiding contexts that create divergence
are not always substitutive. For example, consider P and Q, depicted in ﬁgure
5.4 and deﬁned as follows,
P := x ; P1 [] x ; P2
where
P1 := w ; P1 [] y ; stop
and
P2 := w ; P2 [] z ; stop
Q := x ; Q1 [] x ; Q2
where
Q1 := w ; Q2 [] y ; stop
and
Q2 := w ; Q1 [] z ; stop
P and Q are testing equivalent. In particular, after either the trace x or
xσ (where σ is a ﬁnite repetition of w), the refusals of both P and Q are
{ ∅, {x} , {y} , {z} , {x, y} , {x, z} }, noticing especially that although y
and z can be refused individually, they cannot be refused together, because
both of the states in P after x and P after xσ (and Q after x and Q after xσ)
can perform one or the other of these actions.
However, P ′ and Q′, deﬁned as follows, and depicted in Figure 5.4, are not
testing equivalent.
P ′ := hide w in P
and
Q′ := hide w in Q
It is important to note that after the trace x, P ′ can refuse y and it can refuse
z (although, it cannot refuse the two together), but Q′ can refuse neither
action.
As we discuss in Section 7.2.6, it turns out that a catastrophic interpreta-
tion of divergence (as found in CSP) does not suﬀer substitutivity diﬃculties
in hiding contexts such as these. Thus, in this sense, enforcement of Kooman’s
fair abstraction property [8] leads to a theoretically less clean handling of
divergent behaviour. Although, there may, nonetheless, be good conceptual
reasons for sticking with the property and indeed we believe there are such
reasons.

154
5 Testing Theory and the Linear Time – Branching Time Spectrum
P
P’
i
i
Q
Q’
i
i
x
x
x
x
x
x
x
x
w
w
y
z
y
z
w
w
y
z
y
z
Fig. 5.4. Testing Equivalence Is Not a Congruence in the Hiding Context
5.1.6 Nonequivalence Development Relations
A number of development relations based on trace-refusals semantics that are
not equivalences have been deﬁned. We consider three of these, here: conf, red
and ext. These were deﬁned by Brinksma and co-workers [50], [52] and [53].
We consider each of these relations in turn.
5.1.6.1 Conformance
This relation was devised as a formal instantiation of the conformance testing
process. It is deﬁned as follows.
Deﬁnition 34
(Conformance)
∀B, B′ ∈pbLOTOS, B conf B′ iﬀ∀σ ∈J B′ Ktr , RefB(σ) ⊆RefB′(σ).

5.1 Trace-refusals Semantics
155
Thus, B conforms to B′ if and only if, for the traces of B′, B cannot refuse
more than B′; i.e. it cannot deadlock in an environment that B′ cannot. Thus,
deadlock properties are not worsened for any trace in B′.
Brinksma argues that conf corresponds to a restricted notion of testing,
which is practically feasible to realise. In accordance with this view, conf has
been used as the basis of much work on test case generation from LOTOS
speciﬁcations [50].
Unfortunately, the properties of the relation are not very pleasing. In par-
ticular, conf is not transitive. As an illustration, consider the speciﬁcations:
P1 := x ; stop [] i ; y ; stop
,
P2 := i ; y ; stop
and
P3 := x ; z ; stop [] i ; y ; stop
We claim that P1 conf P2 and P2 conf P3, but ¬(P1 conf P3). We can justify
these as follows.
•
P1 conf P2 follows because the traces of P2 are { ϵ , y } and the refusals
after both are equal: after ϵ they both refuse all actions apart from y and
after y they both refuse all actions.
•
To show that P2 conf P3 holds, consider the traces of P3: { ϵ , y , x , xz }.
The interesting traces are those that are not in Tr(P2); i.e. x and xz. How-
ever, refusals are deﬁned in such a way that after a trace that a behaviour
cannot perform, the empty set is refused; i.e. RefP2(x) = RefP2(xz) = ∅.
Thus, the refusals of P2 after x and xz are trivially a subset of the refusals
of P3 after the same traces.
•
However, ¬(P1 conf P3) because P1 can refuse z after the trace x, but P3
cannot refuse z after the same trace.
Another aspect of the conf relation is that it does not induce an equivalence in
the manner that preorder reﬁnement relations do. In particular, the relation
confSy (standing for conf symmetric) deﬁned as
confSy = conf ∩conf −1
is not an equivalence. In particular, P1, P2 and P3 above serve as a coun-
terexample to confSy being transitive. This is because P1 confSy P2 and
P2 confSy P3, but ¬(P1 confSy P3).
However, an equivalence relation can be deﬁned, if we use our original,
more general, formulation of ≍dv; i.e.
B1 ≍conf B2
iﬀ
{ B′
1 | B′
1 conf B1 } = { B′
2 | B′
2 conf B2 }
This was justiﬁed in the general case in Section 3.1.2.
It should be clear from this discussion that conf is a poorly behaved rela-
tion. However, it should also be pointed out that its role is somewhat diﬀerent
from that of the other development relations. In fact, it has been argued that
conformance testing is not an inherently transitive process, because it concerns

156
5 Testing Theory and the Linear Time – Branching Time Spectrum
the one-step mapping from a speciﬁcation to a real physical implementation.
Thus, incremental development is not an issue. The term implementation re-
lation is often associated with development relations such as conf, which are
concerned with relating speciﬁcations directly to real implementations [120].
5.1.6.2 Reduction
Probably the most important of the LOTOS trace-refusals development rela-
tions is reduction, red. This is an almost direct import from CSP, where the
corresponding relation is simply called reﬁnement; we discuss how this relates
to reduction in Section 7.2.6.
Reduction is deﬁned as follows.
Deﬁnition 35
(Reduction)
∀B, B′ ∈pbLOTOS, B red B′ iﬀ,
•
J B Ktr ⊆J B′ Ktr ∧∀σ ∈J B′ Ktr , RefB(σ) ⊆RefB′(σ),
•
or, alternatively, B ≤tr B′ ∧B conf B′.
Reduction requires that, in addition to deadlocks not being added, traces are
not added. Thus, a concrete behaviour is a reduction of an abstract behaviour
as long as the concrete behaviour does not perform traces that the abstract
behaviour cannot and after any trace of the abstract behaviour, the concrete
behaviour cannot deadlock in an environment where the abstract behaviour
cannot deadlock.
Reduction can also be thought of in terms of reducing nondeterminism; a
reduction cannot add nondeterminism to that deﬁned in the abstract speciﬁ-
cation. This is in accordance with the view that nondeterminism is a device
applicable to abstract stages in speciﬁcation and the observation that it is gen-
erally viewed as bad if implementations contain nondeterminism (although,
see [185]).
We can give the following examples of reduction. Consider the behaviours:
•
P1 := x ; stop
•
P2 := x ; stop [] x ; y ; stop
•
P3 := i ; x ; stop [] y ; stop
•
P4 := x ; stop [] y ; stop
•
P5 := i ; x ; stop [] i ; y ; stop
•
P6 := y ; stop
The following relationships can be determined,
P1 red P2
P1 red P3
P4 red P3
P4 red P5
P3 red P5
¬(P1 red P4) ¬(P6 red P3) ¬(P3 red P4) ¬(P5 red P3) ¬(P5 red P4)

5.1 Trace-refusals Semantics
157
In addition, the following result is clear.
Proposition 8
red is a preorder (in fact, it is a partial order with identity te).
Proof
Reﬂexivity: clear from properties of subsetting. Antisymmetry: P1 red P2 and
P2 red P1 if and only if P1 te P2. Transitivity: assuming P1 red P2 and
P2 red P3, then, clearly, J P1 Ktr ⊆J P3 Ktr by transitivity of subsetting. But,
in addition, ∀σ ∈J P3 Ktr if σ ∈J P1 Ktr then σ ∈J P2 Ktr (because, P1 red P2)
and so, RefP1(σ) ⊆RefP2(σ) ⊆RefP3(σ), as required; otherwise, σ ̸∈J P1 Ktr
and then, RefP1(σ) = ∅and, thus, trivially, RefP1(σ) ⊆RefP3(σ), as required.
The result follows.
⃝
However, unfortunately, reduction is not a precongruence. Choice and hiding
are the oﬀending contexts once again. This said, reduction is the most impor-
tant, well behaved and widely accepted of the nonequivalence development
relations introduced in this section.
Subject to the handling of divergence, reduction can be shown to corre-
spond, not only to the CSP reﬁnement relation, but also Must Testing [89].
5.1.6.3 Extension
Implicit in the deﬁnition of reduction is the condition that traces cannot be
added during reﬁnement. Adding traces can be viewed as adding behaviour;
i.e. extending the possible computations that a speciﬁcation can perform.
There are development situations in which such addition of functionality is
required. For example, a subclass in an OO-type system may add operations
to the interface of a superclass. Operations can be interpreted as actions in
process calculi and, thus, the relationship of the subclass to the superclass is
one of adding traces [33]. We return to these issues in Section 5.4.
The extension relation is a direct realisation of this idea of extending be-
haviour.
Deﬁnition 36
(Extension)
∀B, B′ ∈pbLOTOS, B ext B′ iﬀ,
•
J B Ktr ⊇J B′ Ktr ∧∀σ ∈J B′ Ktr , RefB(σ) ⊆RefB′(σ),
•
or alternatively, B ≥tr B′ ∧B conf B′.
Thus, a concrete behaviour is an extension of an abstract one if and only if the
concrete behaviour does not contain fewer traces than the abstract behaviour,
and, for the traces of the abstract behaviour, the concrete behaviour does not
add deadlocks. Thus, behaviour can be extended, but subject to the normal
refusals property being preserved, as reﬂected in the conf relation.
As an illustration of the relation, consider the following behaviours.

158
5 Testing Theory and the Linear Time – Branching Time Spectrum
•
P1 := x ; y ; stop
•
P2 := x ; y ; stop [] z ; stop
•
P3 := x ; y ; stop [] x ; stop
•
P4 := x ; y ; stop [] i ; z ; stop
The following properties hold,
P2 ext P1
,
¬(P3 ext P1)
,
¬(P4 ext P1)
,
P2 ext P4
The ﬁrst of these relationships shows that extension typically allows the addi-
tion of branches. An alternative behaviour, z ; stop, has been added in P2 and
placed at a choice point. Thus, P2 could behave as P1 or it could behave as
the added behaviour. It is important to note though that this extension does
not add nondeterminism; in particular, x cannot be refused after the empty
trace. This is in contrast to P3 and P4, which although they do not reduce
the traces of P1, they do add nondeterminism. Speciﬁcally, after performing
x, y can be refused by P3, but it could not be refused after x by P1 and P4
can refuse x after the empty trace.
So, extension allows behaviour to be added, as long as nondeterminism
is not added, as this would invalidate the refusals constraint. Unfortunately,
extension is also not a precongruence. The oﬀending contexts are choice and
hiding once again. Although, ext is a preorder.
Proposition 9
ext is a preorder (in fact, it is a partial order with identity te).
Proof
Reﬂexivity: clear from properties of subsetting. Antisymmetry: P1 ext P2
and P2 ext P1 if and only if P1 te P2. Transitivity: assuming P1 ext P2 and
P2 ext P3, then, clearly, J P1 Ktr ⊇J P3 Ktr by transitivity of subsetting. But,
in addition, ∀σ ∈J P3 Ktr, σ ∈J P1 Ktr (because J P1 Ktr ⊇J P3 Ktr, as just
veriﬁed) and so, RefP1(σ) ⊆RefP2(σ) ⊆RefP3(σ), as required. The result
follows.
⃝
5.1.7 Explorations of Congruence
An approach similar to that used to obtain observational congruence from
weak bisimulation can be applied to the trace-refusals relations. This is done
by restricting the initial behaviour of related speciﬁcations. As an example,
we consider stable testing equivalence.
Deﬁnition 37
B tes B′ iﬀB te B′ ∧stable(B) ⇐⇒stable(B′), where stable(B) iﬀB
i
−−→
/
.

5.1 Trace-refusals Semantics
159
So, tes is a stronger equivalence than testing equivalence; it adds the condition
that, either both speciﬁcations must be stable, or both speciﬁcations must be
unstable. Behaviours are stable if and only if they do not oﬀer any initial i
transitions.
A consequence of this is that the following two behaviours are not viewed
as equivalent under tes,
x ; stop
and
i ; x ; stop
Deﬁnitions similar to tes can be given for red and ext. The induced relations
are called reds and exts.
However, as Leduc demonstrated [120], and we discussed in Section 5.1.5,
hiding contexts that create divergence can also fail to be substitutive. Thus,
tes is also not a congruence. The interested reader is referred to [120] for
further discussion of this point.
5.1.8 Summary and Discussion
Trace-refusals semantics oﬀer a model of semantic behaviour that intuitively
sits between trace semantics and bisimulation semantics. In particular, the
induced equivalence, testing equivalence, is weaker than weak bisimulation
and has been argued to be a more realistic instantiation of observational
identity.
The trace-refusals development relations are more discriminating than
their trace counterparts. This is because they preserve liveness properties
as well as safety properties. Remember trace semantics only preserve safety
properties.
However, the LOTOS development relations induced from trace-refusals,
although similar in spirit to the CSP failures relations, are in fact diﬀerent.
A major reason for this is that trace-refusals employ a (CCS-like) noncatas-
trophic interpretation of divergent behaviour. We elaborate on this issue in
Chapter 7.
Tool support for LOTOS-style trace-refusals semantics is not, to the au-
thors’ knowledge, currently available. One reason for this is that bisimulation
equivalences have dominated veriﬁcation strategies for LOTOS speciﬁcations,
as indicated by the power and maturity of the CADP tool set; see Section
3.4. However, CSP does boast a powerful refusals-based tool environment:
the FDR (Failures Divergences Reﬁnement) suite [171]. Although, as should
now be clear, diﬀerences between CSP and LOTOS, in particular, in respect
of handling divergence, mean that LOTOS speciﬁcations cannot be mapped
to this framework without a good deal of care.

160
5 Testing Theory and the Linear Time – Branching Time Spectrum
5.2 Testing Justiﬁcation for Trace-refusals Semantics
Testing theory is extremely rich. In fact, it is possible to place the spectrum of
process calculi correctness relations into a hierachy of strength;2 i.e. in terms
of their level of discrimination, and this is what we consider in the next section
(5.3). The relative strengths of particular correctness relations are tied to the
intrusive capabilities of the tester to observe the speciﬁcation.
In this section, we consider a notion of testing in which the tester has the
power of a standard process calculus process, here a pbLOTOS process. In
this respect we follow the work of Brinksma and Scollo [52], who were, in turn,
inspired by the pioneering work of De Nicola and Hennessy [153].
The following results justify this intuitive interpretation of this form of
testing.
Theorem 5.2.
For all pbLOTOS processes P1 and P2, the following are equivalent.
1. P1 red P2,
and,
2. ∀P ∈pbLOTOS, G ⊆Act, σ ∈T ,
(P1 |[G]| P
σ
=⇒≈stop implies P2 |[G]| P
σ
=⇒≈stop).
Proof
Brinksma and Scollo [52] provide a proof of this result with the assumption
that J P1 Ktr ⊆J P2 Ktr. Thus, all we need to consider is the situation in which
J P1 Ktr ̸⊆J P2 Ktr. So, take σ ∈J P1 Ktr\J P2 Ktr. Now, P1 red P2 must be false,
by deﬁnition. However, in addition, condition (2) fails, because, if we take G
to be all the labels of P1 and P to be the process that performs the sequence
of actions encapsulated by σ and then stops, then P1 |[G]| P
σ
=⇒≈stop, but
P2 |[G]| P
σ
=⇒≈stop fails to hold, because P2 |[G]| P
σ
=⇒
̸
. Thus, conditions
(1) and (2) will always both be false when J P1 Ktr ̸⊆J P2 Ktr and therefore,
the two conditions are also equivalent in this situation. The result follows.
⃝
Corollary 5.3.
For all pbLOTOS processes P1 and P2, the following are equivalent.
1. P1 te P2,
and,
2. ∀P ∈pbLOTOS, G ⊆Act, σ ∈T ,
(P1 |[G]| P
σ
=⇒≈stop ⇐⇒P2 |[G]| P
σ
=⇒≈stop).
Proof
Follows from Theorem 5.2 and the fact that te = red ∩red−1.
⃝
2Although, to date, the emphasis has been placed on interleaving theories.

5.3 Testing Theory in General and the Linear Time – Branching Time Spectrum
161
In these results, we use the following concepts that have been previously in-
troduced, |[G]| is the LOTOS parallel composition operator, ≈is weak bisim-
ulation equivalence, stop is the deadlock process and σ is a trace of observable
actions. In addition, relation composition is denoted by juxtaposition.3 Theo-
rem 5.2 states that P1 reduces P2 if and only if, for all possible tester processes
(denoted P), if P1 can perform a trace σ and then deadlock, then, under the
control of the same tester, P2 could also have performed σ and then dead-
locked. Thus, even more informally, when observed / interacted with, P1 does
not add any new deadlocks to those that could already arise from P2.
Furthermore, in a similar vein, Corollary 5.3 states that P1 and P2 are
testing equivalent if and only if, for any tester process and trace, one will
perform the trace and deadlock if and only if the other will do the same.
Thus, when observed / interacted with, P1 and P2 have the same deadlocks.
The importance of these results is that they link semantic models to the
capacity of pbLOTOS processes to observe other pbLOTOS processes. For
example, Corollary 5.3 ensures that, if two processes are testing equivalent,
then no process (when run as an observer) can tell them apart. Thus, red and
te characterise the testing power of the behavioural speciﬁcation notation
itself! Because of this natural intuitive characterisation, testing equivalence
has a claim to being the most appealing of the LOTOS equivalence relations,
as does reduction in respect of nonequivalence development relations.
The following (more restrictive) result characterises extension in a similar
manner.
Proposition 10
For all processes P1 and P2 such that J P1 Ktr ⊇J P2 Ktr and assuming that
L(Q) denotes the labels of process Q, the following are equivalent.
1. P1 ext P2,
and,
2. ∀P ∈pbLOTOS, G ⊇L(P2), σ ∈J P2 Ktr,
P1 |[G]| P
σ
=⇒≈stop implies P2 |[G]| P
σ
=⇒≈stop.
Proof
See [52].
⃝
Thus, extension only ensures that deadlocks are not added when restricting
to traces of the abstract speciﬁcation.
5.3 Testing Theory in General and the Linear Time –
Branching Time Spectrum
As should be becoming clear, testing theory is a rich and extensively investi-
gated branch of concurrency theory [2,153,192]. Testing theory systematically
3That is, S |[G]| P
σ
=⇒≈stop means ∃Q . S |[G]| P
σ
=⇒Q ∧Q ≈stop.

162
5 Testing Theory and the Linear Time – Branching Time Spectrum
considers how the behaviour of processes can be observed by their environ-
ment / observer. Such observations naturally yield preorders and equivalences
between processes. Two processes P and Q might be related by such a pre-
order if all the observations that can be made of P can also be made of Q;
similarly, the processes might be related by equivalence if they generate the
same observations.
5.3.1 Sequence-based Testing
Testing relations can be characterised by comparing the set of observations
that can be made of a process. The observations that characterise reduction
and testing equivalence are trace-refusals. This is easiest to see if the trace-
refusals of a process are expressed (isomorphically) as a set of failure pairs,
the mapping, toF, introduced in Section 5.1.2, performs this transformation.
Thus, a failure (σ, X) of a process indicates an observation in which a sequence
of actions (corresponding to the trace) was observed, followed by the process
deadlocking in response to an environment that attempts to perform the set
of actions X. Using toF, it is not hard to show the following.
P1 red P2 if and only if every failure of P1 is also a failure of P2
P1 te P2 if and only if the failures of P1 are equal to those of P2
In fact, trace-refusals are just one class of observation and we can explore
testing in a more general context by viewing processes as closed systems with
some form of interface to the outside world. Then, the process is observed
through this interface. By varying the nature of the interface, one can concep-
tually vary the “blackness” of the box. Thus, some classes of interface oﬀer a
very limited capacity to interact with the process, whereas others allow highly
invasive interaction.
In this way, diﬀerent notions of testing can be obtained, each supporting a
diﬀerent level of invasiveness and more important, each can be characterised
by a diﬀerent style of observation, yielding diﬀerent preorders and equiva-
lences. For example, in trace preorder and trace equivalence the observations
are traces, the observations in failure traces are traces with failures informa-
tion throughout, and the observations in readiness preorder and equivalence
consider the actions that may be accepted rather than those that may be re-
fused. Furthermore, this spectrum of testing preorders and equivalences can
be placed in a hierarchy of strength; see [192].
We use the term sequence-based testing to embrace all forms of testing that
yield linear sequences of observations, which, in all but the pure traces case,
are entwined or terminated with some refusal or ready information. Thus,
this form of testing corresponds to the linear time portion of the linear time
– branching time spectrum.

5.3 Testing Theory in General and the Linear Time – Branching Time Spectrum
163
5.3.2 Tree-based Testing
An alternative way to relate processes is to match transitions in the inductive
style of (bi)simulation relations; see Section 3.3.3. This yields a further spec-
trum of preorders and equivalences, e.g. simulation, ready simulation, weak
and strong bisimulation, and the strength of these relations can be compared
to the sequence based testing relations, yielding an enlarged hierarchy of re-
lations; see [192] again.
Here, in fact, we concentrate on equivalences. This is because preorders
have not been extensively studied in the (bi)simulation setting, which is par-
tially because the natural preorders that arise are not always that well be-
haved, especially in respect of preservation of deadlock properties. In fact, this
aspect of (bi)simulation relations was alluded to in Section 3.3.3.2.
Testing categorizations of these simulation relations can also be given.
However, because these relations are more discriminating with regard to the
branching structure of labelled transition systems, sequence-based testing is
not suﬃcient; rather observations have to be constructed as trees. This can be
viewed as giving the environment the capability that, at any time during the
run of a process, an arbitrary (but ﬁnite) number of copies of the process, in its
current state, can be taken and all observed independently. This copying yields
the branches in the observation tree. We call such testing tree-based testing,
which comprises the branching time portion of the linear time – branching
time spectrum.
Ready Simulation Testing. As an example of tree-based testing, we con-
sider ready simulation testing. The resulting observations of the behaviour of
processes are constructed using a simple modal logic, which codes up obser-
vation trees.
Deﬁnition 38 The logic, denoted RSL, is called Ready Simulation Logic and
an arbitrary formula φ is characterised by the following syntax,
φ := True | φ ∧φ | aφ | X
where a ∈Act ∪{i, δ} and X ⊆Act ∪{i, δ}.
Note that the ready simulation framework we consider here is strong and
thus, internal actions are treated identically to observable actions. However,
this framework could easily be adapted to yield a weak interpretation (in the
same manner that weak bisimulation adapts strong bisimulation in respect of
the handling of internal evolutions).
The elements of the logic are straightforward. In particular, we can assert
the statement True, which any process satisﬁes and conjunction is also in-
herited from propositional logic. However, we can also make statements that
are speciﬁc to transition systems. That is, aφ holds over a process that can
perform an a and reach a state where φ holds and a process satisﬁes X if all
the actions in X are immediately oﬀered. The element X is often termed a

164
5 Testing Theory and the Linear Time – Branching Time Spectrum
ready set (or an acceptance set), because it characterises the set of actions
that a process is ready to perform / accept.
As an example of ready simulation, the following are some of the observa-
tions that can be performed by both the behaviours P and Q,
P := x ; x ; y ; stop [] x ; x ; z ; stop
and
Q := x ; ( x ; y ; stop [] x ; z ; stop )
which were ﬁrst highlighted in Section 5.1.1 (see also Figure 5.1) as archety-
pal processes that are distinguished by bisimulation relations and not distin-
guished by trace-refusals semantics,
xxyTrue
xx{y}
x{x}
xxTrue ∧xTrue
xx{y} ∧xTrue
The generalisation of sequence-based testing arises because, not only can we
express traces, the action sequences, and ready / acceptance properties,4 the
set of actions X, we can also express branching, using ∧.
The capability of a process to yield an observation is expressed using log-
ical satisfaction, |=RSL ⊆pbLOTOS × RSL. Thus, R |=RSL φ means intu-
itively that, when tested, the transition system J R Klts (see Section 3.3.2.2)
can exhibit the observable behaviour expressed by φ. Satisfaction is deﬁned
inductively over the structure of formulae, as follows,
R |=RSL True
R |=RSL φ ∧ψ
iﬀ
R |=RSL φ and R |=RSL ψ
R |=RSL aφ
iﬀ
∃R′ s.t. (R
a
−→R′ and R′ |=RSL φ)
R |=RSL X
iﬀ
out(R) = X
where out(R) = { a | ∃R′ . R
a
−→R′ }. Using |=RSL, we deﬁne the mapping
S : pbLOTOS →P(RSL), which yields the set of formulae that a particular
process satisﬁes; i.e. S(R) = { φ | R |=RSL φ }. In other words, S(R) is the set
of all observations that R can exhibit.
Now, because ready simulation employs tree-based testing, it should be
able to distinguish P and Q (highlighted above and in Section 5.1.1) and
indeed it does. For example,
Q |=RSL φ,
but
P ̸|=RSL φ,
where φ = x(xyTrue ∧xzTrue)
In fact, it can be shown (see [192]) that this testing characterisation yields the
same equivalence as that highlighted inductively in Deﬁnition 14 of Chapter
3; i.e.,
P1 ∼R P2
iﬀ
S(P1) = S(P2)
That is, P1 ∼R P2 (i.e. P1 and P2 are ready simulation equivalent) if and only
if, the observations of P1 and P2 are the same.
4Note, tree-based testing formulations that use refusals, rather than ready sets
can also be given; see [192].

5.3 Testing Theory in General and the Linear Time – Branching Time Spectrum
165
Bisimulation. The move from sequence-based testing to tree-based testing
corresponded to an increased capacity of the tester to observe the system.
That is, additionally, the observer could, at any time during the investigation
of the system, take a ﬁnite, but arbitrarily large, number of copies of the
process under test (in its current state) and observe them all separately. This
capacity is aﬀorded by the inclusion of conjunction in the modal observation
language RSL.
However, bisimulations are even more discriminating than ready simula-
tions; see Proposition 5 of Section 3.3.3.2. What then is the further testing
capacity that comes with a move to this setting?
Well, it turns out that what is required is the additional capacity to per-
form what has been called global testing. The key aspect that global testing
gives is the capability to selectively explore all branches of a nondeterministic
choice. This amounts to a signiﬁcant increase in the invasiveness of the testing
process, because, in this setting, the observer really can look inside the black
box and view the taking of internal decisions. The unrealistic nature of such
testing is illustrated by the fact that, when describing this form of testing,
Milner drew an analogy with the famously unpredictable issue of forecasting
the weather, according to which he argued that global testing assumes the
capability to control the weather [145]!
In terms of modal (observation) logics, global testing adds to RSL the
capacity to take negations, which yields Hennessy-Milner logic (HML) [90].
For example, the following two processes,
T := x ; x ; y ; stop [] x ; ( x ; y ; stop [] x ; z ; stop )
and
U := x ; ( x ; y ; stop [] x ; z ; stop ),
x
x
x
y
x
x
y
z
x
T
U
x
x
y
z
Fig. 5.5. Ready Simulation Equivalent, but Not Bisimulation Equivalent Processes

166
5 Testing Theory and the Linear Time – Branching Time Spectrum
which are depicted in Figure 5.5, are distinguished by HML, but not by RSL.5
A formula / observation that distinguishes the two is as follows.
T |=HML ψ,
but
U ̸|=HML ψ,
where
ψ = x(xyTrue ∧¬(xzTrue))
The fact that HML distinguishes more processes than RSL is, of course, con-
sistent with Proposition 5 of Section 3.3.3.2.
5.4 Applications of Trace-refusals Relations in
Distributed Systems
Testing theory in general and the trace-refusals development relations in par-
ticular have been used to investigate the theoretical properties of modern
distributed systems. Providing formal frameworks for such domains has been
a major objective of recent formal methods research. This section gives a brief
pointer to some of the work in this area. Bowman and Derrick [41] and Bow-
man [33] give reviews of this ﬁeld that are broader in scope than we present
here.
We consider three topics in the general area of LOTOS testing theory
applied to modern Object-Oriented (OO) distributed systems: (1) a basic
relating of OO concepts to LOTOS; (2) the behavioural subtyping problem;
and (3) viewpoint models of distributed systems and consistency-checking.
These are discussed in the next three sections. One reason for including this
material is to illustrate application of the theory highlighted in this chapter.
5.4.1 Relating OO Concepts to LOTOS
It is worth clarifying how LOTOS speciﬁcations relate to OO concepts. This
section highlights some basic relationships.
Class. A class describes the common behaviour of a set of objects. As noted by
a number of authors (e.g. [70,173,180]), in LOTOS, the natural counterpart
to a class is a process deﬁnition. This describes the common behaviour of
instantiations of the process deﬁnition.
Object. In OO programming, objects are instantiations of a class. Thus, a sim-
ple interpretation of class instantiation in LOTOS is as process instantiation.
However, more sophisticated interpretations of object instantiation can
also be given. For example, [61, 173] interpret instantiation as the LOTOS
implementation relation conf. Thus, any process that conforms to the speciﬁ-
cation of a class is seen as an instantiation of the class. Although, as discussed
5Note, the pattern of nondeterminism in T and U that leads to this result is
eﬀectively the same as that to be found in R5 and R6, which we considered in
Section 3.3.3.2 to distinguish ∼and ∼R.

5.4 Applications of Trace-refusals Relations in Distributed Systems
167
in Section 5.1.6.1, conf has a number of undesirable properties as a develop-
ment relation, in principle, such an interpretation of instantiation is richer and
more ﬂexible than simple process instantiation. In particular, when working
in a behavioural setting, it seems sensible to interpret instantiation in be-
havioural terms, rather than as a purely syntactic operation. Although we do
not consider this issue of instantiation further here, implicitly, instantiations
in our setting are related to their class deﬁnition much more strongly than by
conf, perhaps by testing equivalence.
Operations. The basic units of interaction between objects are operations,
also called method invocations, member function calls or feature calls. In
process calculi, the basic units of interaction between processes are actions.
The aﬃnity between these two concepts is witnessed by the number of workers
in this area who have related the two, e.g. [61,70,156,173,180]
However, it should be pointed out that this similarity may not be exact,
because process calculi actions are atomic, whereas, in many OO models, op-
erations have duration. The assumption of atomicity is highly signiﬁcant in
the process calculi setting, because it justiﬁes the modelling of concurrency as
interleaving, as discussed in Section 2.3.6.1. Nonatomic interpretations of ac-
tions lead to more complex semantic theories. A simplifying assumption that
Nierstrasz makes [156] is only to model method requests. Such an assump-
tion eﬀectively justiﬁes an atomic interpretation of actions when modelling
operations. In accordance with this majority of workers, we also enforce a
simplifying atomic interpretation of actions / operations.
Finally, the parameters of operations may be modelled using LOTOS’s
data passing attributes, “!” and “?”, which are introduced in Section 6.2.4.
Interface. An object-oriented class deﬁnition will usually contain a statement
of the interface to objects of that class: usually a list of calls that may be made
on the objects. The LOTOS equivalent is the set of all nonhidden actions in
the process deﬁnition.
The above are only the most basic correspondences; there are many more that
can be made. For example, Rudkin [173] describes how inheritance and self
might be introduced into LOTOS and Najm et al [151] consider how object
mobility may be obtained. The interested reader is also referred to part IV
of [106], which relates OO modelling concepts to LOTOS constructs in the
open distributed processing setting [41].
5.4.2 Behavioural Subtyping
The concept of subtyping is familiar from object-oriented programming lan-
guages [80]; it is deﬁned as substitutability: type A is a subtype of type B if
and only if objects of type A may be used in any situation where an object of
type B was expected, without the object’s environment being able to tell the
diﬀerence. Thus, an object of any particular type can masquerade as, or stand

168
5 Testing Theory and the Linear Time – Branching Time Spectrum
in for, an object of any of its supertypes. Subtyping is naturally a reﬂexive
and transitive relation; i.e. a preorder.
However, in client–server distributed systems, the state of the art in service
matching is signature-based subtyping; see Chapter 11 of [41]. Unfortunately,
such matching is not rich enough to ensure the safety of object interactions in
a heterogeneous distributed processing environment. For example, two object
types may have methods with the same name but quite diﬀerent meaning. To
take a rather frivolous example, consider the analogy of an artist and a cowboy.
Both are able to perform an operation “draw”, but the results in each case
will be rather diﬀerent! Thus, it is possible that, although signatures match,
compatibility, in terms of the behaviour of services, is not obtained. What is
actually required is a more powerful interpretation of service matching based
on (stronger) behavioural notions of subtyping. Here we investigate possible
deﬁnitions of such behavioural subtyping in LOTOS.
Relating OO terms to process calculus terms, the following is a semiformal
deﬁnition of behavioural subtyping.
S1 is a behavioural subtype of S2 if and only if, any client (tester),
using S1 according to any interface (synchronisation set), can only
perform a sequence of interactions (a trace) and then refuse to per-
form further interactions (deadlock), if, when using S2 (with the same
interface), the client could observe the same sequence of interactions
followed by a deadlock. 6
Assuming more explicitly that S1 and S2 are LOTOS processes, we can make
this deﬁnition more precise as follows.
S1 is a behavioural subtype of S2 iﬀ, for all, processes P, ﬁnite sets
of observable actions G, and traces σ, S1 |[G]| P
σ
=⇒≈stop implies
S2 |[G]| P
σ
=⇒≈stop.
In terms of OO, P reﬂects possible client speciﬁcations / program and G
reﬂects the possible interfaces between S1 and the client; i.e. the actions by
which they can communicate.
Thus, it is clear that behavioural subtyping is just a reformulation, in a
new context, of the classic testing theory interpretation of when a more con-
crete process (the subtype) is observationally indistinguishable from a more
abstract process (the supertype). Consequently, the results we justiﬁed in Sec-
tion 5.2, can be used to inform our discussion of behavioural subtyping. The
choice of this interpretation of testing from within the linear time – branching
time spectrum arises because, in the setting being considered here, clients are
LOTOS processes. Thus, the capacity of a client to observe a server object is
that of a LOTOS tester process.
6Because we test against all possible clients (and not just those that have a
subset of the operations of S2) we get a strong notion of subtyping. This strength
is necessary, e.g. when there is concurrent interaction between objects.

5.4 Applications of Trace-refusals Relations in Distributed Systems
169
This leaves the question of which exactly of the LOTOS development re-
lations does indeed correspond to behavioural subtyping. From amongst the
LOTOS development relations, a direct application of reduction does not in
fact yield a suﬃcient deﬁnition of behavioural subtyping. This is because, be-
havioural subtyping in the OO context allows extension of functionality; e.g.
a subtype can oﬀer more operations than its supertype.
In the process calculi setting, extending functionality implies addition of
traces. However, reduction enforces a trace subsetting property and thus, does
not allow functionality to be extended. In response to this observation, a num-
ber of previous workers [61, 156, 173] have based their interpretation of sub-
typing upon extension. However, we argue against using this relation; rather
we show how to reinterpret LOTOS speciﬁcations in order that reduction is
the appropriate relation.
5.4.2.1 Relating LOTOS Relations and Subtyping
In this section, we attempt to locate an interpretation of behavioural subtyp-
ing from amongst the existing LOTOS development relations. Firstly, because
subtyping is reﬂexive and transitive, but not symmetric (a symmetric relation
would suggest substitutability in both directions, which is too strong), we
only consider the preorder relations. This choice rules out the equivalences:
weak bisimulation (≈), strong bisimulation (∼), simulation equivalence (≍≺),
ready simulation equivalence (∼R) and testing equivalence (te) and the im-
plementation relation, conf, which is not transitive.
Trace Subsetting and Supersetting. We ﬁrst consider trace preorder. This
is inappropriate, because it does not allow the subtype to have any more traces
than the supertype, which contradicts the extension of functionality involved
in subtyping.
An alternative to ≤tr is trace extension: P1 ≤tre P2 iﬀTr(P1) ⊇Tr(P2).
This does allow new operations to be added and, in fact, is the interpretation
of subtyping used in [163]. In Puntigam’s work, trace extension serves as a
valid check for type safety, where, in this context, type safety ensures that the
subtype can understand all operations that the supertype can. However, the
relation is not a suitable instantiation of the stronger notion of behavioural
subtyping, because it allows deadlocks to be added. For example, if X and Y
are deﬁned as
X := x ; stop [] y ; stop
Y := x ; stop [] y ; stop [] i ; stop
then Y ≤tre X. However, Y is not a behavioural subtype of X. When placed
in synchronisation with the process / client x ; stop, X will perform action x,
but Y may perform x, or may perform an internal action and then deadlock.
If Y deadlocks in a situation where X would not, Y is distinguishable from
X and is therefore not a behavioural subtype of X. Indeed, of course, the

170
5 Testing Theory and the Linear Time – Branching Time Spectrum
same criticism can be levelled at all solely trace-based correctness relations,
including trace preorder.
Reduction. As discussed earlier in this chapter, reduction adds consideration
of liveness properties to trace preorder; see Section 5.1.6.2. Indeed, Theorem
5.2 in Section 5.2 ensures the deadlock property we are seeking. However, as
discussed earlier, reduction fails to allow extension of functionality. So, as it
stands, it is not a suitable instantiation of subtyping.
Extension. Because extension is sensitive to deadlock properties and sup-
ports extension of functionality (see Section 5.1.6.3) it appears, at ﬁrst sight,
to be an ideal candidate for the subtyping relation. This is witnessed by the
large number of workers who have used it as the basis for deﬁnitions of sub-
typing [61,156,173].
Consider two LOTOS processes, X and Y :
X := x ; stop [] y ; stop
Y := x ; stop [] y ; stop [] z ; stop
We see that Y ext X. Y can perform every trace that X does (and more),
and, after any trace that X can perform, X refuses at least everything that
Y refuses. Conceptually, Y deﬁnes a class that adds an operation to class X,
viz. the action z. Thus, extension enables interface enlargement.
Unfortunately, extension does not satisfy our requirements for behavioural
subtyping, because it does not guarantee the deadlock property we require.
For example, the tester z ; stop, with synchronisation set {z}, serves as a
counterexample, because,
Y |[z]| z ; stop
z
=⇒≈stop
but
X |[z]| z ; stop
z
≠⇒
By Proposition 10 in Section 5.2, extension only ensures the deadlock property
we require when restricting to traces of the supertype. However, we require
that it hold for all traces.
Another way of looking at this problem is that our deﬁnition of behavioural
subtyping is based on the principle that a subtype must be usable in any situa-
tion where the supertype could be used, and not be seen to behave diﬀerently.
If we have a process that may be an X or a Y , we can detect which it is by
trying to perform the action z on the process. If the z is accepted, we have
Y , but if z is refused, we must have X. Because it is possible to tell that we
have a Y , Y is not a subtype of X.
Interestingly, this problem with extension is one that Nierstrasz has ob-
served [156]. His illustrative example is that of a one-place buﬀer supertype
and a deleting buﬀer subtype. We can express his example in pbLOTOS as
follows,
Buf1 := put ; get ; Buf1 and DelBuf := put ; ( get ; DelBuf [] del ; stop )

5.4 Applications of Trace-refusals Relations in Distributed Systems
171
Thus, DelBuf behaves as Buf1 does, but it adds the possibility to delete the
element in the buﬀer and then evolve to deadlock.7 The tester / client that
distinguishes the two is analogous to the LOTOS process:
T := Prod ||| Cons ||| del ; stop
where,
Prod := put ; Prod
Cons := get ; Cons
del
T
put
get
put
get
del
DelBuf |[put,get,del]| T
Buf1 |[put,get,del]| T
put
get
put
get
Fig. 5.6. LOTOS Buﬀers, with Grey Arrows Denoting Start States
which yields the composite behaviour shown in Figure 5.6. Now, DelBuf is
clearly an extension of Buf1, however, Nierstrasz observes that, with the in-
terface {put, get, del} and the tester T, Buf1 cannot reach a deadlock state,
whereas DelBuf can. Speciﬁcally,
DelBuf |[put, get, del]| T
put del
=====⇒≈stop
but
Buf1 |[put, get, del]| T
put del
====≠⇒
In fact, the problem here is exactly the same as that which we highlighted with
behaviours X and Y above. Nierstrasz develops a number of concepts such
as request substitutability and a notion of restriction in order to contain this
problem. In contrast, our approach is to reject extension as an interpretation
of behavioural subtyping.
5.4.2.2 Functionality Extension and Undeﬁned
Undeﬁned Operations in Object–oriented Methods. In order to in-
form this problem let us consider how functionality extension and particularly
adding operations works in OO speciﬁcation and programming methods.
7Note that, because we have not yet introduced data passing behaviours, no
actual data is associated with these data structures. However, these could be added
in a full LOTOS version of these behaviours.

172
5 Testing Theory and the Linear Time – Branching Time Spectrum
•
OO Speciﬁcation Techniques. A number of OO speciﬁcation notions exist,
for example, OO versions of Z, such as Object-Z [41,172] and ZEST [60],
OO versions of VDM, such as VDM++ [115] and Liskov and Wing’s no-
tation [41, 130]. Subtyping is not handled in a uniform way throughout
these techniques, so, let us focus on the Liskov and Wing approach, which
has considered the topic in some depth. In [130] and Chapter 12 of [41],
a number of conditions are highlighted, which must all hold in order to
ensure subtyping between a pair of speciﬁcations. However, the part of
the deﬁnition that concerns us here is the pre- and postcondition relation-
ship between operations. The deﬁnition requires that, for every operation
in the supertype, there must exist a corresponding operation in the sub-
type (although, the subtype may contain extra operations) such that, for
corresponding operations, the following holds.
1. The precondition of the supertype operation implies the precondition
of the subtype operation, and
2. The postcondition of the subtype operation implies the postcondition
of the supertype operation.
Thus, through subtyping, preconditions can be weakened and postcondi-
tions can be strengthened. In informal terms, weakening of preconditions
enables operations to be applied (i.e. terminate) in more states, whereas
strengthening of postconditions reduces nondeterminism. This really does
give us what we seek: addition of traces and reduction of refusals when
we take subtypes. In spirit, subtyping behaves as does reﬁnement in state-
based speciﬁcation notations such as Z [69].
It is important to note though that this interpretation of subtyping only
works because applying an operation outside its precondition has a very
diﬀerent meaning from the analogous occurrence in process calculi. In pro-
cess calculi, the analogue of applying an operation outside its precondition
is the environment trying to perform an action when it is not currently
oﬀered, which has the result deadlock. In contrast, in state-based speci-
ﬁcation notations, such as Z or Liskov and Wing’s notation, applying an
operation outside its precondition is undeﬁned; i.e. is completely unpre-
dictable. In an “operational sense,” anything could occur and the choice
between these alternatives is nondeterministic.
•
OO Programming Methods. In strongly typed object-oriented systems, it is
not possible to call an operation that is not oﬀered by an object. However,
other OO systems produce error messages when a program calls an un-
deﬁned operation, or result in undeﬁned behaviour (such as the program
crashing or giving incorrect results), e.g. Smalltalk [83].
So, both these OO settings give justiﬁcation for the argument that attempting
to apply an operation that is not currently oﬀered should result in undeﬁned
behaviour and not deadlock.
Undeﬁnedness and LOTOS. What, then, would be the consequence of
adapting LOTOS speciﬁcations to behave in an undeﬁned fashion if an ac-

5.4 Applications of Trace-refusals Relations in Distributed Systems
173
tion that is not currently oﬀered is performed? Unpredictable behaviour can
be modelled in LOTOS using nondeterminism. In fact, we can highlight the
following process,
Ω:= ( choice x in Act ∪{δ} [] i ; x ; Ω) [] ( i ; stop )
where choice x in { x1 , . . . , xn } [] B = B[x1/x] [] . . . [] B[xn/x] and B[y/z]
denotes B with all occurrences of z replaced by y.8 Ωoﬀers a completely
nondeterministic behaviour; at every point in its evolution it could oﬀer any
action and refuse any set of actions. Because (1) Tr(Ω) = (Act ∪{δ})∗and
(2) ∀σ ∈(Act ∪{δ})∗, RefΩ(σ) = P(Act ∪{δ}), we know that Ωis at the top
of the reduction preorder: every behaviour is a reduction of it.9
It turns out that we are able to use reduction as the subtyping relation if
the LOTOS deﬁnitions of our objects’ behaviours are modiﬁed using Ω. We
show how the modiﬁcation is done with two examples.
Example 1. A one-place buﬀer, Buf1, was deﬁned earlier. A two-place buﬀer
may be deﬁned as follows.
Buf2 := put ; Buf2a
Buf2a := get ; Buf2 [] put ; get ; Buf2a
The labelled transition systems corresponding to Buf1 and Buf2 are given on
the left side in Figure 5.7. For these deﬁnitions, L = {put, get}.
We would like the two-place buﬀer to be a subtype of the one-place buﬀer.
Notice that, for the same reasons that we highlighted in our earlier example,
as they stand, the two-place buﬀer is not a subtype of the one-place buﬀer. To
achieve this, we modify the two processes as shown in the right-hand labelled
transition systems of Figure 5.7.
We have added transitions such that every node has at least one transi-
tion leading away from it for every possible action in L. Following any of the
transitions we have added, the process evolves to Ω(this is in fact a rela-
tively standard technique in process calculi, which is used to enable parts of
speciﬁcations to be extended when reﬁning; see, for example, [119]).
Using the fact that any behaviour reduces Ω, these two processes are now
related in the way we wish. With the addition of undeﬁned behaviour, Buf2 is
both a reduction and a subtype of Buf1. To justify this, ﬁrstly observe that the
traces of T(Buf2) and T(Buf1) (we deﬁne the mapping T, that adds undeﬁned
behaviour shortly) are the same; i.e. L∗. This is because our transformation
has ensured that, at any state, each process “may” perform any action in
L. Secondly, observe that, for any trace in L∗, the refusals of T(Buf2) are
a subset of those of T(Buf1). Informally, T(Buf1) and T(Buf2) have identical
refusals apart from those for traces of the form ρ put put σ, where, σ ∈L∗
8Actually, Ωenables δ to arise directly in action preﬁx (i.e. i ; δ ; Ω), which is
not strictly allowed in LOTOS, but this abuse of notation does not cause problems.
Also, this choice notation is discussed in some depth in Section 6.1.
9Although, Ωdoes not uniquely characterise the top of the reduction preorder.
See [38] for a fuller discussion of this issue.

174
5 Testing Theory and the Linear Time – Branching Time Spectrum
put
get
get
put
put
put
get
get
get
put
put
get
Buf1
put
put
get
get
Buf2
Fig. 5.7. Buf1 and Buf2 Without and with Undeﬁned Added and Start States
Marked with Gray Arrows
and ρ ∈{ϵ} ∪{ ρ0 . . . ρn | n ∈N ∧∀i(0 ≤i ≤n) . ρi = put get }. For such
traces, T(Buf1) will have evolved to undeﬁned, and will thus refuse everything,
whereas T(Buf2) may still be performing deﬁned behaviour, in which case it
will refuse nothing. In addition, T(Buf1) is not a reduction / subtype of T(Buf2)
because, for example, T(Buf1) can perform the trace put put and then refuse
anything, whereas, after the same trace, T(Buf2) cannot refuse anything.
Example 2. Interestingly, using the label set {put, get, del}, when transformed,
DelBuf will be a subtype of Buf1. This is because, in either of its deﬁned states,
the transformed Buf1 can perform a del and evolve to Ω. This contrasts with

5.4 Applications of Trace-refusals Relations in Distributed Systems
175
the approach taken in [156], where Nierstrasz attempts to develop conditions
that show that, in their untransformed form, DelBuf is not a subtype of Buf1.
5.4.2.3 Adding Undeﬁnedness to LOTOS Speciﬁcations
Transforming Speciﬁcations. Having introduced the concept of undeﬁned
behaviour we have to consider how to add this behaviour to LOTOS speciﬁ-
cations in an automated way. Our approach is to take the labelled transition
system of a LOTOS process and derive a new transition relation, which we
denote,
a↬.
This new relation will add states and transitions that reﬂect the required
undeﬁned behaviour. Where L is the label set of the speciﬁcation, we generate
the relation that satisﬁes the inference rules:
R1 : P
a
−→P ′,
a ∈L ∪{δ, i}
P
a↬P ′
R2 : x ∈(L ∪{δ}) \ initials(P)
P
x↬Ω
R3 : x ∈L ∪{δ}
Ω
i↬x ; Ω
R4 :
−
x ; Ω
x↬Ω
R5 :
−
Ω
i↬stop
where initials(P) = { x ∈L ∪{δ} | ∃P ′ . P
x
=⇒P ′ }. R1 ensures that the
new relation contains the relation −−→. R2 adds the possibility to evolve to
Ωwhen applying an action that is not currently oﬀered. Rules R3, R4 and
R5 code up the behaviour of the undeﬁned process Ω.
Nondeterminism. These inference rules deﬁne a simple means to add un-
deﬁnedness to a labelled transition system. For deterministic processes, the
consequences of applying these rules are very straightforward. For example,
the rules will map the two labelled transition systems to the left in Figure
5.7 to the two labelled transition systems to the right. However, application
of the rules is more subtle in the presence of nondeterminism. Consider the
following examples of the three archetypal forms of LOTOS nondeterminism,
with L = {x, y, z},
X := x ; y ; stop [] x ; z ; stop
Y
:= i ; x ; stop [] i ; y ; stop
Z := i ; x ; stop [] y ; z ; stop
Labelled transition systems resulting from adding undeﬁnedness for each of
these processes are shown as (1), (2) and (3) of Figure 5.8. This transformation
has the virtue of being extremely simple, however, it does not generate the

176
5 Testing Theory and the Linear Time – Branching Time Spectrum
(1)
i
(3)
i
i
(2)
i
(4)
x
x
y
z
x,y,z
x,z
y,z
x,y
x,y,z
x
y
z
x,y,z
y,z
x,z
x,y,z
x
y
z
z
x,y,z
y,z
x,y
x,y,z
x
y
z
x,y,z
y,z
x,y
x,y,z
X
Y
Z
Z’
Fig. 5.8. Transformed Behaviours
minimum (in terms of least number of transitions) labelled transition system.
For example, in (3), the transition labelled z, emanating from the start state,
is in fact redundant and (3) and (4) of Figure 5.8 are testing equivalent.
A consequence of applying this transformation is that (modulo the addi-
tion of undeﬁned behaviour) more processes are reductions than they would
normally be. For example, once transformed, all of the following behaviours
would be reductions of Z.
x ; stop [] y ; z ; stop [] z ; stop
x ; stop [] z ; stop
x ; stop [] y ; x ; stop
The last of these is perhaps the most surprising as the deﬁned behaviour
of the resulting speciﬁcation requires an x action to be performed after the
trace y, whereas Z requires a z action to be performed after the same trace.
However, according to our intuition of subtyping in OO, this is correct, as the
transformed Z can refuse the y action at the root that leads to z, but cannot
refuse the y action reached via i, which leads to Ω. Thus, this situation is only
odd if the processes are interpreted without undeﬁnedness.

5.4 Applications of Trace-refusals Relations in Distributed Systems
177
Further Examples. It is important to note though that, although trans-
forming LOTOS speciﬁcations in this way yields a more generous relationship
between processes, which was after all our original intention, the resulting
notion of subtying still remains sensitive to incompatible behaviour.
Consider two examples from [156]: a variable and a nondeterministic stack,
although both these deﬁnitions are rather abstract and underspeciﬁed, be-
cause we do not have data types in pbLOTOS.
Var := put ; Var2
Var2 := put ; Var2 [] get ; Var2
NDstack := put ; NDstack2
NDstack2 := put ; NDstack2 [] get ; NDstack2 [] get ; NDstack
Now, it can be checked that T(Var) red T(NDstack) and T(NDstack) red
T(Buf1), but ¬(T(NDstack) red T(Var)) and ¬(T(Buf1) red T(NDstack)). The
latter two of these are because
Ref T(NDstack)(put get get) = P(L) ̸⊆{∅} = Ref T(Var)(put get get)
Ref T(Buf1)(put put) = P(L) ̸⊆{∅} = Ref T(NDstack)(put put)
Bowman et al [38] who consider the issue discussed here in more depth, also
explore how this transformation works in the presence of data.
As these examples demonstrate, transformed behaviours have a very pre-
cise trace / refusal character. Transformed speciﬁcations can perform any trace
in (L∪{δ})∗and after all traces either refuse nothing or refuse everything. One
consequence of this is that, for transformed speciﬁcations, red = ext = conf.
Finally, it is worth noting that the issue of how to handle undeﬁnedness
is also one of the main hurdles that has to be tackled when behavioural spec-
iﬁcations, such as those arising from LOTOS, and state-based speciﬁcations,
such as those arising from Z, are related. For a detailed discussion of this issue,
see [40].
5.4.3 Viewpoints and Consistency
Viewpoints are becoming a dominant structuring concept in a number of areas
of computer science, e.g. requirements engineering [79], OO design methodolo-
gies [27], formal system development [203], in the Uniﬁed Modelling Language
(see Chapter 7 of [41]) and in software engineering in general [182]. The idea is
that, rather than having a single thread of system development, in the style of
the classic waterfall approach, multiple partial speciﬁcations (i.e. viewpoints)
of a system are considered during system development. Each particular spec-
iﬁcation represents a diﬀerent perspective on the system under development
and, in fact, may well be written by a diﬀerent speciﬁer and be in a diﬀerent
notation.
A distributed systems context in which viewpoints are particularly sig-
niﬁcant is Open Distributed Processing (ODP), which is a joint ITU / ISO

178
5 Testing Theory and the Linear Time – Branching Time Spectrum
standardisation framework for constructing distributed systems in a multi-
vendor environment. The interested reader is referred to published introduc-
tions, e.g. [129] and Chapters 1 and 2 of [41], and the standards documents
themselves [106]. It is beyond the scope of this chapter to give a complete in-
troduction to ODP, however, we summarise the basic ODP viewpoints model
to frame our presentation.
ODP uses ﬁve predeﬁned viewpoints – the enterprise viewpoint, the in-
formation viewpoint, the computational viewpoint, the engineering viewpoint
and the technology viewpoint. They have the following respective roles.
•
The Enterprise Viewpoint supports capture of global “business” require-
ments;
•
The Information Viewpoint enables the generic information structures and
ﬂows of the system to be deﬁned;
•
The Computational Viewpoint is an object-oriented design model targeted
at the applications programmer;
•
The Engineering Viewpoint enables the engineering structures supporting
the computational and information viewpoints to be deﬁned;
•
The Technology Viewpoint identiﬁes how and where existing technologies
can be used in the target system.
ODP is not prescriptive about which language each viewpoint should be spec-
iﬁed with; rather the standard deﬁnes the basic structures and concepts that
would be used in each viewpoint. It is assumed that, through a process of
instantiation, the basic concepts of each viewpoint will be related to the con-
structs of particular speciﬁcation languages.
One of the consequences of adopting a multiple viewpoints approach to
development is that descriptions of the same, or related, entities can appear
in diﬀerent viewpoints and must co-exist. Consistency of speciﬁcations across
viewpoints thus becomes a central issue. The problem is complicated by the
fact that we can expect viewpoint speciﬁcations to be written in diﬀerent
languages, viz. languages particularly suited for the viewpoint at hand, e.g. Z
for the information viewpoint and LOTOS for the computational viewpoint.
Thus, providing techniques to check viewpoint consistency is a major re-
search topic surrounding ODP viewpoints modelling. A number of workers
have responded to this challenge [17,42,74].
5.4.3.1 Consistency Deﬁnition
An initial challenge of work on viewpoints was to locate a deﬁnition of con-
sistency that was general enough to be used in the ODP context. Bowman et
al [37] proposed such a deﬁnition.
The intuition is that we can view n speciﬁcations X1, X2, . . . , Xn as con-
sistent if there exists a physical implementation which is a realisation of all
the speciﬁcations; i.e. X1, X2 through to Xn can be implemented in a single

5.4 Applications of Trace-refusals Relations in Distributed Systems
179
imp
imp
imp
S1
S2
S3
Implementation
Plane
imp
imp
imp
S4
S5
S6
(a)
(b)
Fig. 5.9. Common Implementation Models
system. This interpretation has similarities to satisfaction in a logical setting.
A conjunction of propositions φ1 ∧φ2 ∧. . . ∧φn is satisﬁable if there exists
a single model that individually satisﬁes all the propositions.
Figures 5.9(a) and 5.9(b) illustrate this; in both depictions speciﬁcations
are related to their set of possible realisations by a relation implements (de-
noted imp). Thus, the Venn diagrams in the implementation plane depict the
set of possible realisations of each speciﬁcation. It should be clear that the
three speciﬁcations in Figure 5.9(a) are consistent, because their set of possi-
ble implementations intersect. In contrast, the three speciﬁcations in Figure
5.9(b) are not consistent, although the pairs S4 and S5 and S5 and S6 are
mutually consistent.
However, rather than talk explicitly about implementation, as this inter-
pretation does, it is necessary to work purely in the formal setting and deﬁne
consistency solely in terms of speciﬁcations and relations between speciﬁca-
tions. Thus, we deﬁne consistency in terms of a common (formal) speciﬁcation,
X, and a list of development relations, dv1, dv2, . . . , dvn. n speciﬁcations are
consistent, denoted C(dv1, Xn) . . . (dvn, Xn) if there exists a speciﬁcation that
is a development of X1 according to dv1, X2 according to dv2, through to Xn
according to dvn; i.e.
C(dv1, Xn) . . . (dvn, Xn) iﬀ∃X s.t. X dv1 X1 ∧. . . ∧X dvn Xn.
Notice that we allow the descriptions to be related to their common develop-
ment in diﬀerent ways; i.e. if dvi ̸= dvj. This is inherent in the nature of ODP
viewpoints modelling, where, for example, one viewpoint could be related to
the common implementation by conformance, another by direct implemen-
tation and a third by functionality extension. In addition, there is nothing
preventing the speciﬁcations from being in diﬀerent languages.
One central issue that we do not have space to discuss here is that of ob-
taining global consistency from a series of binary consistency checks. It turns
out that the choice of common implementation between viewpoint speciﬁca-
tions is crucial to obtaining such incremental consistency checking [48].

180
5 Testing Theory and the Linear Time – Branching Time Spectrum
This deﬁnition of consistency is very general, being parameterised, ﬁrstly,
on the choice of speciﬁcation language and secondly, on the notion of devel-
opment used. In the following we consider consistency in the LOTOS setting.
5.4.3.2 Consistency in LOTOS
What makes consistency checking between viewpoint speciﬁcations in LOTOS
a particularly challenging task is the existence and use of multiple development
relations. Consistency checking using combinations of these development re-
lations has been investigated [48,184], which characterises consistency checks
that result when diﬀerent LOTOS development relations are used.
As a very simple illustration, consider the consistency check,
C(ext, P)(red, Q)
where ext is the extension relation, introduced in Section 5.1.6.3, and red is
the reduction relation, introduced in Section 5.1.6.2. We can give the following
examples of consistent and inconsistent pairs of “buﬀer” speciﬁcations.
¬C(ext, Inbuf )(red, blockbuf )
and
C(ext, 1buf )(red, blockbuf )
where
Inbuf := put ; Inbuf
1buf := put ; get ; 1buf
blockbuf := put ; get ; blockbuf [] put ; stop
We can justify the former of these, because any extension, call it R, of In-
buf must be able to perform the trace put put (for example), but R cannot
be a reduction of blockbuf , because put put ̸∈J blockbuf Ktr. In addition, the
latter holds because 1buf extends itself (ext is reﬂexive) and it reduces block-
buf. This is, of course, a rather trivial illustration of consistency checking; a
larger example is considered in [22, 48]. Furthermore, [48] gives a complete
characterisation of consistency checking using LOTOS development relations.
5.4.3.3 Discussion
Our discussion here of consistency checking has been presented as a taster
of the topic. In particular, it is beyond the scope of this book to go into
what is a very complex topic in full depth. However, the interested reader is
referred to the literature for more details. In particular, [23] considers how
consistency can be checked between pairs of Z speciﬁcations; [48] presents
a theoretical framework for viewpoints and consistency checking; the same
paper instantiates this framework in the LOTOS context; and, ﬁnally, [70]
shows how LOTOS speciﬁcations can be translated into Z speciﬁcations and
then consistency checking can be performed in Z.

Part III
Concurrency Theory – Further Untimed
Notations

183
This part builds from Part II by considering a set of more advanced untimed
modelling notations, which enhance the capabilities of the methods developed
in Part II. Speciﬁcally, Chapter 6 discusses enhanced LOTOS calculi, which
are syntactically richer and interface with data typing notations. Then in
Chapter 7, a comparison with the calculi CCS and CSP is made. Finally, a
consideration of communicating automata approaches is presented in Chapter
8.

6
Beyond pbLOTOS
Chapter 2 deﬁned a relatively restricted subset of LOTOS. The main reason
for isolating this subset is that it is a suitable size to consider formally and
the chapters of the previous part that discuss semantics restrict themselves
to this subset. However, the complete language contains a number of other
constructs and a somewhat more verbose syntax. This chapter presents bLO-
TOS (i.e. LOTOS without data types), which is discussed in Section 6.1, and
fLOTOS (i.e. the full language, with data types), which is discussed in Sec-
tion 6.2. Included are the full syntactic forms for a number of the constructs
that we have already discussed and some completely new constructs. We give
operational semantics rules for each new construct, which map to labelled
transition systems. However, these semantics are presented as a taster, rather
than as an exhaustive semantic deﬁnition, which would require us to be more
detailed in respect of our treatment of data than we are able to be within this
book. We also illustrate the fLOTOS constructs with examples in Section 6.3.
fLOTOS is eﬀectively the language (minus the data typing notation) that
was standardised in 1987 in [104]. However, there has been a further stan-
dardisation activity focused on enhancing LOTOS by adding features and
responding to perceived problems in the original language. Unfortunately, it
is beyond the scope of this book to give a full presentation of the resulting
E-LOTOS notation, however, we give a short review of the main extensions
and highlight pointers to literature on the topic in Section 6.4.
6.1 Basic LOTOS
We begin by looking at bLOTOS. We work construct by construct through
the new operators and then we deﬁne an abstract syntax for bLOTOS.
6.1.1 Disabling
Disabling has the general form:

186
6 Beyond pbLOTOS
B1 [> B2
which states that behaviour B2 can disable behaviour B1. We call B1 the
normal behaviour and B2 the exception behaviour. At any point during the
evolution of B1, the ﬁrst action of B2 can be performed, causing B1 to be
stopped and B1 [> B2 to behave as B2. In fact, even before B1 has performed
an action, B2 can disable it. Once B1 has successfully terminated, it can no
longer be disabled.
For example, consider the following behaviours.
(i) x ; y ; exit [> w ; z ; stop
(ii) P [> w ; z ; stop
where, P := x ; y ; P
(iii) x ; y ; stop [> w ; z ; stop
(iv) x ; y ; exit [> i ; z ; stop
(v) ( x ; y ; exit [> w ; z ; stop ) >> v ; stop
Behaviour trees for these expressions are depicted in Figure 6.1. The following
points can be made on each example behaviour.
(i) The exception behaviour, w ; z ; stop, is oﬀered as an alternative to per-
forming any action in the normal behaviour. Thus, at any point, the nor-
mal behaviour can be disabled, that is, until a successful termination
action is performed.
(ii) Because the normal behaviour has an inﬁnite character, there is no suc-
cessful termination to disable the exception behaviour.
(ii) This behaviour cannot successfully terminate, thus, the exception be-
haviour cannot be disabled and must happen after the normal behaviour
has completed.
(iv) An asymmetric nondeterministic choice is generated between performing
the normal behaviour observably or internally evolving to the exception
behaviour.
(v) This behaviour illustrates the interplay of disabling and successful termi-
nation. Speciﬁcally, successful termination of the normal behaviour en-
ables the new behaviour v ; stop.
The disable operator is not a standard process calculus operator (although,
its origins date back to [96]); rather it is targeted at the speciﬁc application
domain of LOTOS: description of communication protocols. In this context, it
is used to express the disrupting eﬀect of error and exception behaviour, e.g. a
connection being unexpectedly disconnected. We have not included disabling
in pbLOTOS because it has some unpleasant semantic consequences. For ex-
ample, disabling cannot be expressed easily using the bundle event structure
true concurrency semantics that were considered in Chapter 4.
Three simple operational semantics rules can be given for the behaviour
of the disabling operator.

6.1 Basic LOTOS
187
(ii)
(i)
δ
δ
(iii)
i
i
(iv)
i
z
(v)
x
w
z
y
w
z
z
w
w
z
x
w
z
y
z
z
w
w
x
w
z
y
z
z
y
x
z
z
w
z
w
w
y
x
v
i
Fig. 6.1. Disabling Examples

188
6 Beyond pbLOTOS
(DIS.i) :
B1
a
−→B′
1
B1 [> B2
a
−→B′
1 [> B2
(a ̸= δ)
(DIS.ii) :
B1
δ
−→B′
1
B1 [> B2
δ
−→B′
1
(DIS.iii) :
B2
a
−→B′
2
B1 [> B2
a
−→B′
2
(a ∈Act ∪{i, δ})
Thus, rule (DIS.i) ensures that any nonterminating action that B1 can per-
form, can be performed by B1 [> B2 and the capacity to disable remains. Rule
(DIS.ii) states that a successful termination on the part of B1, will success-
fully terminate the disabling. Finally, rule (DIS.iii) indicates how a transition
of B2 can disable the evolution of B1.
6.1.2 Generalised Choice
Generalised choice has the form,
choice ge1, . . . , gen [] B
where gei is a gate expression of the form:
x in [x1, . . . , xm]
which states that the variable x ranges over the set [x1, . . . , xm]; i.e. can be
instantiated with any of the actions x1, . . . , xm. Generalised choice allows us
to express behaviour such as
choice x in [v, z, w], y in [u, w] [] B′
which is equivalent to the following
B′[v/x, u/y] [] B′[z/x, u/y] [] B′[w/x, u/y] []
B′[v/x, w/y] [] B′[z/x, w/y] [] B′[w/x, w/y]
So, the choice of a series of instances of B′ is generated, where each instance
reﬂects a particular instantiation of x and y.
As suggested by this example, generalised choice enables us to express a
large class of behaviours signiﬁcantly more succinctly than they would be
expressed with basic (binary) choice. In addition, we can express inﬁnite
choices using generalised choice (such behaviour cannot be expressed using
basic choice). This particularly becomes clear when we discuss the integration
of data with generalised choice in the next section. However, a speciﬁc case
of inﬁnite choice is given by the following behaviour,
choice x in Act [] B
where B usually refers to x

6.1 Basic LOTOS
189
which deﬁnes an inﬁnite choice of behaviour B instantiated with actions from
the (inﬁnite) set of all possible LOTOS actions.
A simple operational semantics rule can be given for the behaviour of
generalised choice.
B[xi/x]
a
−→B′
choice x in [x1, . . . , xn] [] B
a
−→B′
(1 ≤i ≤n)
This rule assumes just a single action binder, x in [x1, . . . , xn], however, it
can easily be generalised to multiple action binders.
6.1.3 Generalised Parallelism
Generalised parallelism has the form,
par ge1, . . . , gen |[x1, . . . , xm]| B
For example, the behaviour:
par x in [v, z, w], y in [u, w] |[w]| B′
is equivalent to:
B′[v/x, u/y] |[w]| B′[z/x, u/y] |[w]| B′[w/x, u/y] |[w]|
B′[v/x, w/y] |[w]| B′[z/x, w/y] |[w]| B′[w/x, w/y]
It should be noted that the parallel composition operator, |[w]| above, cannot
be aﬀected by the instantiation of action names. This construct plays a similar
role to generalised choice, but in the context of parallel behaviour.
Rather than giving inference rules speciﬁc to this operator, as we did for
generalised choice, we simply provide a mapping from generalised parallelism
to a sequence of normal binary parallel compositions. This is possible because
the number of parallel threads that can be generated with this operator is
always ﬁnite (in contrast, generalised choice can yield inﬁnite choices).
par x in [y1, . . . , yn] |[x1, . . . , xm]| B ≜
B[y1/x] |[x1, . . . , xm]| . . . |[x1, . . . , xm]| B[yn/x]
Again our rule is speciﬁc to a single action binder, but it could also easily
be generalised to multiple action binders. Another reason why this mapping
is well-formed is because in pbLOTOS, parallel composition is associative
when synchronisation sets are repeated. That is, an expression of the form,
B1 |[x1, . . . , xm]| . . . |[x1, . . . , xm]| Bn deﬁnes a unique behaviour, because any
bracketing that decomposes the expression into a sequence of binary compo-
sitions would be equivalent up to strong bisimulation.

190
6 Beyond pbLOTOS
6.1.4 Verbose Speciﬁcation Syntax
The top-level syntax for a bLOTOS speciﬁcation has the following form,
speciﬁcation I [x1, . . . , xn] : F
behaviour
. . .
. . .
endspec
where I is an identiﬁer that names the speciﬁcation, x1, . . . , xn are the ob-
servable actions of the entire speciﬁcation and F denotes the functionality
of the speciﬁcation. These extensions to the top-level speciﬁcation syntax of
pbLOTOS are largely syntactic sugar. The body of the speciﬁcation appears
between the keywords behaviour and endspec. This behaviour will have the
form:
B
where
D1
. . .
. . .
Dn
where B is an arbitrary behaviour and Di is a process deﬁnition. Although
the list of declarations could be empty.
The functionality parameter, F, states that the speciﬁcation either has the
functionality exit or noexit. A speciﬁcation that can successfully terminate
has the functionality exit, whereas a speciﬁcation that is unable to successfully
terminate has the functionality noexit. Rules for determining the functionality
of speciﬁcations are given in [24].
6.1.5 Verbose Process Syntax
In a similar way, a verbose process syntax is used in bLOTOS,
process P [x1, . . . , xn] : F :=
. . .
. . .
endproc
where P is the process identiﬁer; x1, . . . , xn are the observable actions of the
process; F denotes the functionality of the process; i.e. exit or noexit in the
same way as for complete speciﬁcations; and the body of the process is between
the symbol := and endproc. This behaviour will typically have the form:

6.1 Basic LOTOS
191
B
where
D1
. . .
. . .
Dn
where B is an arbitrary behaviour and Di is a process deﬁnition. In fact, the
similarity between the syntax of process deﬁnitions and the top-level structure
of speciﬁcations is not surprising, because a speciﬁcation, as a whole, can be
seen to be a process. A speciﬁcation is a special kind of process, but only by
virtue of its name.
6.1.6 Syntax of bLOTOS
This section brings together the constructs that we have introduced to give
an abstract syntax for bLOTOS. The syntax deﬁnes an arbitrary speciﬁcation
S ∈bLOTOS as follows.
S ::= speciﬁcation I [x×] : F
behaviour U endspec
U ::= B | B where D+
D ::= process P [x×] : F :=
U endproc
B ::= stop | exit | a ; B | B1 [] B2 | B1 |[x×]| B2 |
B1 >> B2 | B1 [> B2 | choice ge+ [] B | par ge+ |[x×]| B |
hide x+ in B | B[(x/y)+] | P[x×]
F ::= exit | noexit
ge ::= y in [x+]
where
•
We have used BNF notation in which X+ denotes a ﬁnite number, bigger
than zero, of repetitions of X and Y × denotes a ﬁnite number, including
zero, of repetitions of Y , which are separated by commas, if there is more
than one;
•
S is the domain of speciﬁcations, U is the domain of top-level behaviours,
D is the domain of deﬁnitions, B is the domain of behaviour expressions,
F is the domain of functionality parameters and ge are action binders;
•
The domain D has changed from pbLOTOS; here we are using it to range
over single deﬁnitions; and
•
a ∈Act ∪{i}, x, y ∈Act, I, P ∈PIdent.1
1Note, we do not distinguish the domain of speciﬁcation names from that of
process names.

192
6 Beyond pbLOTOS
6.2 Full LOTOS
As indicated earlier, full LOTOS integrates the constructs introduced above
with a data typing notation, ACT-ONE. A complete presentation of this no-
tation is inappropriate for a number of reasons.
•
Our main interest in this book is the behavioural part of LOTOS.
•
The ACT-ONE data language has proved a troublesome part of full LO-
TOS. There are a number of reasons for this, which we do not have room
to consider here; see, for example, [150] for a discussion of this issue. How-
ever, a central issue is that ACT-ONE is not in practice easy to use. In
particular, even trivial speciﬁcations, such as that of the natural numbers,
prove complex to express in ACT-ONE.
•
LOTOS restandardisation has designed a new data language to replace
ACT-ONE; see Section 6.4. Thus, in the LOTOS context, ACT-ONE is
largely obsolete.
However, we now give a ﬂavour of the interface between data and behaviour
provided by full LOTOS. In order to do this, we assume a basic set of data
types that are not tied to any particular data language; i.e. natural numbers,
Booleans and enumerated types. We show how these can be interfaced with
LOTOS. So, we assume the following primitive set of data domains.
•
A set nat of natural numbers, with 0, 1, 2, 3, . . . ∈nat and operations +
and relations =, >, <, etc. deﬁned on nat; we also have an operator comp,
which takes the complement of 0 and 1; i.e. comp(0) = 1 and comp(1) = 0;
•
A set int of integers, with . . . , −3, −2, −1, 0, 1, 2, 3, . . . ∈int and operations
+, −and relations =, >, <, etc. deﬁned on int;
•
A set bool of Booleans, with two elements, true and false, and operations
not, and, or etc. deﬁned on bool; and
•
Four enumerated types that are used in the Dining Philosophers example:
name ::= Aristotle | Buddha | Confucius | Descartes
side ::= left | right
action ::= eat | think
chopstick ::= stick1 | stick2 | stick3 | stick4
These are presented in a standard way using BNF. These deﬁnitions state
that the type name can have four constant values, Aristotle, Buddha,
Confucius and Descartes, and similarly for side, action and chopstick.
As was the case with bLOTOS, for each of the new constructs we introduce,
we provide operational semantics rules to illustrate how these constructs are
interpreted in a labelled transition systems semantics. However, as stated
earlier, these semantics are presented as a taster, rather than as an exhaustive
semantic deﬁnition.
We present the fLOTOS extensions to bLOTOS construct by construct.

6.2 Full LOTOS
193
6.2.1 Guarded Choice
Conditional selection based on the value of variables can be deﬁned. There are
three basic ways to deﬁne data conditionals in fLOTOS: guarded commands,
selection predicates and generalised choice. We consider the ﬁrst of these here.
The other two are considered when we have described value passing actions.
Guarded choice is derived from Dijkstra’s guarded commands notation; it
has the following general form,
[be] −> B
[]
[be′] −> B′
where be and be′ are Boolean expressions. The meaning of this construct is: if
the guard be holds, behave as B, otherwise, if the guard be′ holds, behave as
B′. Notice that if the guards overlap, nondeterminism can be created.
In fact, any arbitrary piece of behaviour can be preﬁxed with a guard.
Thus, the choice here is not even required and the basic syntactic enhancement
that arises with guards is the capacity to “preﬁx” any arbitrary behaviour with
a guard. Thus,
[be] −> B
Semantically, this construct is interpreted via the following inference rule,
B
a
−→B′
beval(be)
([be] −> B)
a
−→B′
where a ∈Act ∪{i, δ}2 and beval evaluates the Boolean expression be in the
obvious way. Notice that the LOTOS semantics ensure that be only contains
ground terms. Thus, beval does not require a state or environment in order
to evaluate a Boolean expression.
6.2.2 Speciﬁcation Notation
The top-level syntax for an fLOTOS speciﬁcation has the following form,
speciﬁcation I [x1, . . . , xn](n1 : T1, . . . , nm : Tm) : F
TD
behaviour
B
where
TD
D×
endspec
2Although, with fLOTOS actions are more complex, because they carry data
attributes. This is an issue we elaborate on shortly.

194
6 Beyond pbLOTOS
where TD is a list of type deﬁnitions and D+ is a list of process deﬁnitions. The
TDs in the above speciﬁcation indicate places where ACT-ONE deﬁnitions can
legally be placed in LOTOS speciﬁcations. The type deﬁnitions that follow
the speciﬁcation header would be global, over the entire speciﬁcation, whereas
the type deﬁnitions following the where keyword only range over the list of
process deﬁnitions.
In addition, the list (n1 : T1, . . . , nm : Tm) parameterises the speciﬁcation
on a group of data variables with associated types, which can be instantiated
on execution of the speciﬁcation. So, these are data values that are input to
the speciﬁcation.
6.2.3 Process Deﬁnition and Invocation
The fLOTOS syntax for process deﬁnition is:
process P [x1, . . . , xn](n1 : T1, . . . , nm : Tm) : F :=
B
where
TD
D×
endproc
Thus, process deﬁnition takes a very similar form to the top-level speciﬁcation
syntax. In particular, processes are parameterised on certain variables and
local data type and process deﬁnitions can be included following the keyword
where; although, these are all optional.
This parameterisation means that process invocation takes on a somewhat
more complicated form than it did for pbLOTOS and bLOTOS. Given the
above process deﬁnition, process invocation takes the following general form,
P[y1, . . . , yn](E1, . . . , Em)
where Ei is a value expression of type Ti. The eﬀect of this invocation is
to textually substitute the expressions Ei in place into the process body for
their corresponding formal parameter; i.e. ni. This class of parameter passing
is similar to call by name as used in standard programming languages.
6.2.4 Value Passing Actions
In fLOTOS, actions can exchange data. As a reﬂection of this, we distinguish
between gates and actions and we assume variables g, g′, g′′, g1, g2, . . . ranging
over the set Gate. Actions now have the general form:
g d1 . . . dn

6.2 Full LOTOS
195
i.e. action instances comprise a gate and a list of value and variable decla-
rations, denoted di (these are sometimes called experiment oﬀers and what
we call value and variable declarations are called value experiments and vari-
able experiments). For example, in the communication protocol example, we
might want to specify that, when a send is performed, a natural number is
passed with the send. This number could, for example, be used to associate a
sequence number with messages. The following are typical data valued action
instances occuring in this setting,
send!5 ,
send!(10 + 2) ,
send!n ,
send!(10 + n) ,
send?m : nat
In these action instances, send is the gate name and !5, !(10+2), !n, !(10+n)
and ?m : nat are data passing declarations. In particular, !5, !(10+2), !n and
!(10+n) are value declarations, whereas ?m : nat is a variable declaration. The
eﬀect of a value declaration is to pass a data value (here a natural number).
So, the eﬀect of send!20 is to oﬀer an interaction at the gate named send and
associate the value 20 with that interaction, whereas send!n oﬀers interaction
on the same gate, but, this time, the value of the variable n is associated with
the interaction. In contrast, the eﬀect of a variable declaration is to oﬀer a
variable to which a binding can be made. So, the eﬀect of send?m : nat is to
oﬀer an interaction at the gate named send and associate a binding to variable
m with that interaction. In eﬀect, the declaration ?m : nat states that m can
take any value from the natural numbers.
Notice that one implication of value passing is that speciﬁcations will now
typically have an inﬁnite set of possible actions. Thus, the set L can now be
inﬁnite. For example, for the behaviour,
P := send?m : nat ; stop
L = { send 0, send 1, send 2, . . . }, where send v denotes interaction at gate
send with an associated data value v.
In fact, this style of action denotation plays a central role in the fLOTOS
semantics. Speciﬁcally, labels in transition systems will now have the form,
g v1 v2 . . . vn
where the vis are data values. Thus, eﬀectively, data is “ﬂattened out” when
the semantics are applied. For example, the transition system arising from
process P above is shown in Figure 6.2.
One beneﬁcial consequence of this ﬂattening of data is that the standard
development relations introduced in Part II can be applied in this context,
subject to the problems that may arise with inﬁnite branching.3 Eﬀectively,
these relations just treat the complex ﬂattened labels that arise from fLOTOS
in the same way as the pure action names that arise from pbLOTOS. Thus,
3Of course, we are here talking from a theoretical perspective, because it is clear
that such inﬁnite branching is a major diﬃculty for the development of veriﬁcation
tools for data passing calculi.

196
6 Beyond pbLOTOS
.....
send_0
send_1
Fig. 6.2. Flattening of Data
reassuringly, all theory developed in the pbLOTOS setting is still applicable
in the fLOTOS setting.
In our general form of action, the dis can have one of the following forms,
!E or ?n : T
where E is a value expression and T is a type name. The n here is described
as a binding occurrence of the variable, whereas instances of variables in E
would, in this context, be described as free.
As a consequence, action preﬁx has the general form:
g d1 . . . dm ; B
The variables declared in di can be used in B. In fact, the scope for these
declarations is exactly the extent of B. We assume that, for any i (1 ≤i ≤m),
if di is a binding occurrence of n, then n does not appear in any dj (j ̸= i)
or occur as a binder in B. Note, systematic renaming can always be used to
resolve any such name clashes.
In the behaviour of the medium, we might want to express that, once
a send has been performed, with a certain sequence number, a receive is
performed with the same sequence number. This models the successful trans-
mission by the medium of a message from sender to receiver. We can express
this as
send ?m : nat ; receive !m ; B
which states that the variable m will be bound to a value in nat when an
interaction at send occurs and then the value of m will be associated with
interaction on the receive gate. We could also specify that, after a receiveAck
action is performed in the sender process, a send action is performed with an
incremented sequence number. This could be speciﬁed as follows,
receiveAck ?m : nat ; send !(comp(m)) ; B
where comp is the complement operator introduced earlier, as appropriate for
alternating bit sequence numbering.
In addition, a single gate can have a number of value or variable declara-
tions associated with it. For example, the action,

6.2 Full LOTOS
197
receive !seqno ?d : data ?c : checksum
oﬀers interaction on gate receive with a speciﬁed sequence number, an arbi-
trary data unit and error checksum.
The semantic interpretation of this construct is as follows.
−
g d1 . . . dn ; B
g v1 ... vn
−−−−−−−−→B(rewrite(J))
where m ≤n ∧∀i(1 ≤i ≤n), j(1 ≤j ≤m),
•
vi ≜eval(E) if di = !E;
•
vi ∈T
if di = ?r′ : T;
•
J ≜{ (uj, rj) | di = ?rj : T ∧uj = vi };
•
rewrite({ (s1, t1), . . . , (sk, tk) }) ≜[s1/t1, . . . , sk/tk];
where vi and uj are data values, types are treated as sets, which is appro-
priate in this setting, there are m variable declarations in the list d1 . . . dn, i
ranges over all data passing declarations, j ranges over variable declarations,
[u1/r1, . . . , um/rm] ≜[u1/r1] . . . [um/rm] 4 and eval evaluates data expres-
sions in the obvious manner. Note, that, as was the case with Boolean expres-
sions, by the time eval is applied in the semantics, all data expressions will
only contain ground terms.
6.2.4.1 Value Passing and Synchronisation
As indicated earlier, communication between parallel threads of control is per-
formed through actions synchronising on parallel composition. What happens
then when data passing actions synchronise? Well, in general, some form of
value binding occurs. However, there are a number of possibilities for such
synchronisation. The following are the basic forms of data passing synchroni-
sation.5
(i) g!E ; B |[g]| g!F ; B′
(ii) g!E ; B |[g]| g?n : T ; B′
(iii) g?m : T ; B |[g]| g?n : T ′ ; B′
We explain these in turn, when the pbLOTOS parallel composition rules (de-
ﬁned in Section 2.3.6) are applied with the (ﬂattened) actions that arise from
our value passing calculus.
4Notice that, because we assume there is no possibility of a name clash, these
renamings could actually be performed in any order.
5We assume that static checks, such as those considered in [104], have already
been applied in order to ensure type correctness.

198
6 Beyond pbLOTOS
1. If eval(E) = eval(F) then the action g eval(E) will be performed. How-
ever, if eval(E) ̸= eval(F) then interaction on gate g cannot take place
and deadlock will result. This form of synchronisation is called value syn-
chronisation.
2. Assuming the type of E is T, the action g eval(E) will be performed and,
as a by-product, on the right-hand side of the behaviour, the variable n
will be bound to eval(E). This form of synchronisation is called value
passing.
3. Assuming T = T ′, this behaviour will oﬀer an interaction on gate g with
all values from T associated. This form of synchronisation is called value
generation. It is important to note that synchronisation on gate g in this
way will not prescribe a particular value from T. In eﬀect, a (potentially
inﬁnite) choice is made available to the environment between performing
g with each of the data values of T. In particular, because multiway syn-
chronisation is allowed on gate g, a further behaviour that constrains the
value to be associated with the interaction (e.g. a gate g!E) could be com-
posed in parallel and, thus, resolve the choice. As an illustration of this
form of value synchronisation, Figure 6.3 depicts the choice of possible
immediate evolutions of a typical behaviour of this form.
g?m:nat;B |[g]| g?n:nat;B’
g_1
g_0
.....
B[0/m] |[g]| B’[0/n]
B[1/m] |[g]| B’[1/n]
Fig. 6.3. Value Generation Example
6.2.4.2 Value Passing and Internal Behaviour
Hidden behaviour is also aﬀected by value passing. Firstly, it is syntactically
illegal to associate a data attribute with an internal action, e.g. the behaviour:
i !5 ; stop
is not syntactically well formed. This is because an internal action is not able
to interact with the environment and thus, passing values to and from the
environment is not meaningful. However, data passing can be associated with
internal actions through hiding. This reﬂects that an observable interaction

6.2 Full LOTOS
199
with data can be hidden. Thus, the interaction and its data experiments still
occur, but are made internal and hidden from the environment. For example,
all the following behaviours are syntactically well formed,
(i) hide g in g!5 ; stop
(ii) hide g in (g!5 ; B |[g]| g?n : nat ; B′)
(iii) hide g in (g?m : nat ; B |[g]| g?n : nat ; B′)
and we depict them in Figure 6.4. Although, (i) is rather a silly speciﬁcation,
because no other party can view the value 5.
However, in all these behaviours, the data value associated with each in-
ternal action is not visible to the external observer; they can be thought of as
being transmitted inside some internal communication channel. You should
also notice that behaviour (iii) amounts to an inﬁnite nondeterministic choice;
the nondeterminism arises because the choice is over a hidden gate. Thus, an
internal action will be performed and the same arbitrary value will be bound
to both m in B and n in B′.
(i)
i
.....
(iii)
i
i
(ii)
i
hide g in ( B |[g]| B’[5/n] )
hide g in ( g?m:nat;B |[g]| g?n:nat;B’ )
hide g in
( B[0/m] |[g]| B’[0/n] )
hide g in
( B[1/m] |[g]| B’[1/n] )
Fig. 6.4. Value Generation Examples and Internal Behaviour

200
6 Beyond pbLOTOS
6.2.4.3 Illustration of Value Passing
Examples of the use of value passing synchronisation can be found in the
communication protocol example. As an illustration, consider ﬁrst the receiver
process:
process Receiver [put, receive, sendAck](m : nat) : noexit :=
hide timeout in
( timeout ; sendAck!comp(m) ;
Receiver[put, receive, sendAck](m)
[]
receive?n : nat ;
( [m = n] −> put ; sendAck!n ;
Receiver[put, receive, sendAck](comp(m))
[]
[m ̸= n] −> sendAck!n ;
Receiver[put, receive, sendAck](m) ) )
endproc
Note that the protocol example we discuss in this chapter is slightly more
complex than the version considered in Chapter 2. In particular, here we add
the diﬃculty that the acknowledgement medium may lose messages. As a
result, the receiver is never sure that its acknowledgements get through to the
sender.
Notice that sequence numbers are transmitted in the speciﬁcation; thus,
for example, when the receiver performs the action receive, the variable n is
bound to the sequence number of the received message. Then, depending upon
the value of n, either the message is relayed to higher layers, by performing a
put, or it is dropped. In both cases, an acknowledgement is sent and then the
process recurses.
The reason for the conditional is that the message may be a retransmission
of a previously received message, which has had its acknowledgement lost.
In this case, the expected sequence number, m, and the received sequence
number, n, will not be equal, the message will not be relayed to higher layers
and acknowledgement of the previously received message will be resent on the
sendAck gate.
In addition, in this speciﬁcation, the Receiver is initially waiting to receive
a message from the medium. However, if the message does not arrive “in time”,
it can timeout, in which case it sends an acknowledgement for the previous
message. This is because it assumes that its previous acknowledgement must
have been lost in transit.
In the more complex protocol example considered here, on receipt of an
acknowledgement (on gate sendAck), the acknowledgement medium can ei-
ther relay the acknowledgement (ensuring that the same sequence number is
used) or it can lose the acknowledgement in transit. This behaviour is realised
in the following speciﬁcation.

6.2 Full LOTOS
201
process AckMedium [sendAck, receiveAck] : noexit :=
sendAck?n : nat ;
( receiveAck!n ; AckMedium[sendAck, receiveAck]
[]
i ; AckMedium[sendAck, receiveAck] )
endproc
As a fragment of the communication protocol, we can consider the following
parallel composition.
Receiver[put, receive, sendAck](0)
|[sendAck]|
AckMedium[sendAck, receiveAck]
It is important to note that synchronisation on the gate sendAck now has the
eﬀect of binding the value of n or comp(m) (depending upon the instance of
sendAck) in the process Receiver to the variable n in AckMedium. Thus,
the sequence number of the message being acknowledged is passed through
the medium.
It is also worth noting that there is a good deal of redundancy in LOTOS
concerning how conditional data passing behaviours can be expressed. For
example, the following fragment of behaviour from the Receiver process,
receive?n : nat ;
( [m = n] −> put ; sendAck!n ;
Receiver[put, receive, sendAck](comp(m))
[]
[m ̸= n] −> sendAck!n ;
Receiver[put, receive, sendAck](m) )
could also be expressed as follows,
receive!m ; put ; sendAck!m ;
Receiver[put, receive, sendAck](comp(m))
[]
receive!(comp(m)) ; sendAck!(comp(m)) ;
Receiver[put, receive, sendAck](m)
where branching according to the sequence number received is pushed into
the action instances. In fact, although these two fragments are equivalent
in the context of the communication protocol example, which only uses two
numbers, 0 and 1, they are not equivalent in every context. This is because,
the second fragment will deadlock with an environment that attempts to per-
form a receive with a value greater than 1, however, the original version will
not deadlock on that receive, although it is likely to deadlock immediately
afterwards.

202
6 Beyond pbLOTOS
6.2.5 Local Deﬁnitions
We can associate value expressions with free variables using the let construct,
which has the following general form,
let m1 : T1 = E1, . . . , mn : Tn = En in B
where, for i ̸= j, mi ̸= mj and, in general, B references m1, . . . , mn
This states that the behaviour B is performed with the variables mi of type
Ti replaced by the value expressions Ei.
Now, assuming that the construct is well typed and that there are no
binding occurrences of the mis in B (note, if necessary, systematic renaming
of bound variables could be applied to ensure this holds), then the following
inference rule can be applied for this construct.
B[E1/m1, . . . , En/mn]
a
−→B′
(let m1 : T1 = E1, . . . , mn : Tn = En in B)
a
−→B′
where B[E1/m1, . . . , En/mn] ≜B[E1/m1] . . . [En/mn] and a ∈Act ∪{i, δ}.
6.2.6 Selection Predicates
We introduce two more forms of conditional in this and the next sections. The
ﬁrst of these is the selection predicate. This gives the ﬁnal enhancement to
action preﬁx, which in fLOTOS has the general form:
g d1 . . . dn[be] ; B
This allows the values of variables in the declaration list, d1 . . . dn, to be
constrained by the Boolean expression be. For example, the Boolean expression
may specify that a variable declared in di to be of type nat, can only take
values between 4 and 10.
The semantic interpretation of this construct generalises that of action
preﬁx. As previously, we assume that, for any i (1 ≤i ≤n), if di is a binding
occurrence of n, then n does not appear in any dj (j ̸= i) or occur as a binder
in B.
beval(be[u1/r1, . . . , um/rm])
g d1 . . . dn [be] ; B
g v1 ... vn
−−−−−−−−→B(rewrite(J))
where m ≤n ∧∀i(1 ≤i ≤n), j(1 ≤j ≤m),
•
vi ≜eval(E) if di = !E;
•
vi ∈T
if di = ?r′ : T;
•
J ≜{ (uj, rj) | di = ?rj : T ∧uj = vi };
•
rewrite({ (s1, t1), . . . , (sk, tk) }) ≜[s1/t1, . . . , sk/tk];

6.2 Full LOTOS
203
where vi and uj are data values, there are m variable declarations in the list
d1 . . . dn, i ranges over all data passing declarations and j ranges over variable
declarations.
As an illustration of this construct, in the communication protocol exam-
ple, we may wish to enforce an exception behaviour on receipt of an out of
range sequence number. For example, we may re-express our receiving frag-
ment of behaviour as follows.
receive?n : nat [n ≤1] ;
( [m = n] −> put ; sendAck!n ;
Receiver[put, receive, sendAck](comp(m))
[]
[m ̸= n] −> sendAck!n ;
Receiver[put, receive, sendAck](m) )
[>
receive?n : nat [n > 1] ; Bexcept
6.2.7 Generalised Choice
We can further generalise choice, enabling it to be deﬁned over a number of
variable declarations. Thus, it can take the following form,
choice m1 : T1, . . . , mn : Tn [] B
where for i ̸= j, mi ̸= mj, B will typically refer to m1, . . . , mn and there
are no binding occurrences of mi in B. Thus, mi : Ti is a declaration, which
speciﬁes that the variable mi ranges over the type Ti. This allows us to express
inﬁnite choices, such as the following,
choice n : nat [] B
where typically B references n
which states that B will be performed with n instantiated by one of 0, 1, . . ..
The following inference rule interprets this operator.
B[v1/m1, . . . , vn/mn]
a
−→B′
(choice m1 : T1, . . . , mn : Tn [] B)
a
−→B′ (v1 ∈T1, . . . , vn ∈Tn)
It should also be noted that the generalised choice,
choice n : T [] a!n ; B
is equivalent to the action preﬁx a?n : T ; B.
As an example of the relationship between ! and ?, we could re-express the
fragment of receiver behaviour highlighted at the end of the previous Section
(6.2.6) as follows.

204
6 Beyond pbLOTOS
choice n : nat []
( [n = m] −> receive!n ; put ; sendAck!n ;
Receiver[put, receive, sendAck](comp(m))
[]
[n ̸= m ∧n ≤1] −> receive!n ; sendAck!n ;
Receiver[put, receive, sendAck](m)
[]
[n > 1] −> receive!n ; Bexcept )
Notice that, because we do not use disabling here, the exception behaviour
can only occur at the initial choice point, where the behaviour is waiting to
perform an action on gate receive. In contrast, the use of disabling in the
fragment highlighted at the end of the previous section (6.2.6), allows the
exception behaviour to be initiated at any point during the execution of the
normal behaviour.
In conclusion then, generalised choice can either be parameterised on sets
of actions (see Section 6.1.2) or data types.
6.2.8 Parameterised Enabling
Sequential composition, also called enabling,
B1 >> B2
may also be parameterised. This has the eﬀect of binding data values from
B1 to variables contained in B2 on successful termination. However, in order
for this to happen we need some extra syntax to enable us to match up the
values generated from B1 with the variables contained in B2. There are three
aspects to this syntax; ﬁrstly, a parameterised exit notation,
exit(e1, . . . , en)
which deﬁnes the list of values that are generated from a behaviour on success-
ful termination; secondly, the functionality parameter referenced in process
and speciﬁcation headers (the F in the abstract syntax of Section 6.2.9) is
enhanced in order to deﬁne the typing associated with successful termination
of that process; i.e.
exit(T1, . . . , Tn)
Thirdly, a special construct, accept, is introduced in order that the enabled
behaviour can accept the values passed through sequential composition. This
gives us the following general form for sequential composition,
B1 >> accept m1 : T1, . . . , mn : Tn in B2

6.2 Full LOTOS
205
which states that, on successful termination of B1, the variables m1, . . . , mn,
of the speciﬁed types, will be bound in B2 to the exit values of behaviour B1.
We again assume that there are no binding occurrences of the mis in B2 and
that for i ̸= j, mi ̸= mj.
Determining the functionality of a behaviour is not completely straight-
forward. In particular, in order for the functionality of a process to be identi-
ﬁed, all exits in the process must have compatible functionality. For example,
exit(true) and exit(5), as used in, say,
a ; exit(true) ||| b ; exit(5)
are clearly not compatible. However, in order to give some ﬂexibility in deﬁn-
ing exit parameters, the construct any is introduced. This can be used to
state that any value from a type is an acceptable exit parameter. For ex-
ample, exit(5, any bool) and exit(any nat, true) would match with function-
ality (nat,bool) and would terminate with the values (5, true). In contrast,
exit(5, any bool) and exit(4, true) would not match.
There is a set of rules that enable the functionality of a behaviour to be
deﬁned. These rules express how the functionality of the constituent operators
of a process are determined. For more details, the interested reader is referred
to [24,101].
The following inference rules interpret these operators. Firstly, we interpret
parameterised successful termination.
−
exit(e1, . . . , en)
δ v1... vn
−−−−−−−→stop
where ∀i(1 ≤i ≤n),
vi = eval(E)
if
ei = E
vi ∈T
if
ei = any T
Using the function name, which returns the underlying gate name of a data
passing action, we have two rules for the accept operator. We begin with a
rule that allows behaviour B1 to evolve.
B1
a
−→B′
1
B1 >> accept m1 : T1, . . . , mn : Tn in B2
a
−→
B′
1 >> accept m1 : T1, . . . , mn : Tn in B2
(name(a) ̸= δ)
Thus, B1 can perform any action, as long as it is not a successful termination.
The ﬁnal rule characterises the point of successful termination.
B1
δ v1... vn
−−−−−−−→B′
1
B1 >> accept m1 : T1, . . . , mn : Tn in B2
i
−→
B2[v1/m1, . . . , vn/mn]

206
6 Beyond pbLOTOS
So, a successful termination action passes control to B2, subject to the bind-
ings arising from the accept construction.
Parameterised enabling is illustrated in the Dining Philosophers example
shortly.
6.2.9 Syntax of fLOTOS
This section brings together the constructs that we have introduced to give
an abstract syntax for fLOTOS. The syntax deﬁnes an arbitrary speciﬁcation
S ∈fLOTOS as follows.
S ::= speciﬁcation I [g×]((n : T)×) : F TD behaviour U endspec
U ::= B | B where TD D+
D ::= process P [g×]((n : T)×) : F :=
U endproc
B ::= stop | exit(e×) | i ; B | g d#[be] ; B | B1 [] B2 | [be] −> B |
B1 |[g×]| B2 | B1 >> accept (n : T)× in B2 | hide g+ in B |
B[(g/h)+] | P[g×](E×) | B1 [> B2 | choice df [] B |
par (g in [h+])+ |[g×]| B | let (n : T = E)+ in B
F ::= noexit | exit(T ×)
df ::= (g in [h+])+ | (n : T)+
d ::= !E | ?n : T
e ::= any T
| E
where Z# is the same as Z×, except the repetitions are not separated by
commas, g, h ∈Gate, I, P ∈PIdent,6 n is a data variable, T is a data type, E
is a data expression, be is a Boolean expression, TD is a data type declaration
(the syntax of which is left unspeciﬁed), F are functionality parameters, e are
exit parameters and d are data passing declarations.
We also assume the following deﬁned special cases of operators.
exit
≜
exit( )
g d1 . . . dn ; B
≜
g d1 . . . dn [true] ; B
B1 >> B2
≜
B1 >> accept in B2
6.2.10 Comments
Comments can appear anywhere in fLOTOS speciﬁcations and are enclosed
in starred brackets as follows,
(∗. . . ∗)
6Again, we do not distinguish the domain of speciﬁcation names from that of
process names.

6.3 Examples
207
6.3 Examples
As an illustration of fLOTOS, we present complete speciﬁcations of the two
running examples that we have been using: the communication protocol and
the Dining Philosophers.7 Together, these speciﬁcations illustrate the major
features of fLOTOS.
6.3.1 Communication Protocol
The top-level behaviour of the communication protocol is as follows:
speciﬁcation protocol [start, get, put] : noexit
(* Type Deﬁnitions *)
behaviour
start;
( hide send, receive, sendAck, receiveAck in
( ( Sender[get, send, receiveAck](0)
||| Receiver[put, receive, sendAck](0) )
|[send, receive, sendAck, receiveAck]|
DupMedium[send, receive, sendAck, receiveAck] ) )
where
(* Deﬁnition of Sender *)
(* Deﬁnition of Receiver *)
(* Deﬁnition of DupMedium *)
endspec
The protocol has three external actions, start, get and put. The ﬁrst of these
starts the communication system. The get action is used to request transmis-
sion of a message from outside the protocol, e.g. from the previous layer in a
protocol stack. Notice that the sender and receiver processes are instantiated
with the value of the starting sequence number as their actual parameters.
The behaviour of the sender could be speciﬁed as follows.
process Sender [get, send, receiveAck](n : nat) : noexit :=
get; send!n; Sending[get, send, receiveAck](n)
endproc
7The Dining Philosophers speciﬁcation is taken from the SEDOS tool set, which
is, in turn, based upon a similar speciﬁcation to be found in [96].

208
6 Beyond pbLOTOS
process Sending [get, send, receiveAck](m : nat) : noexit :=
hide timeout in
( timeout; send!m; Sending[get, send, receiveAck](m)
[]
receiveAck?n : nat;
( [m = n] −> Sender[get, send, receiveAck](comp(m))
[]
[m ̸= n] −> send!m;
Sending[get, send, receiveAck](m) ) )
endproc
One point to observe is that, although we model sequence numbers directly,
using natural numbers, we still do not model the data elements of a message.
These could easily be added, yielding action instances of the form send !d !n
and receive ?d : data ?n : nat, where data is a new data type. However,
because this communication layer is blind to the contents of these data items
and just relays them through as encapsulated packets, message data has no
eﬀect on the behaviour of the protocol and is thus abstracted away at this
level.
The sender behaviour here has a similar structure to that encoded in the
nondata passing version of the protocol considered in Section 2.4. However,
now receiveAcks are not always assumed to be acknowledgements of the ex-
pected message, as they were in the pbLOTOS example. Rather, now, an
incorrect acknowledgement is assumed to indicate that the receiver has resent
an acknowledgement to the previous message. This could arise if the receiver
times out waiting for a message. In response to this situation, the sender will
resend the current message (assuming its previous transmission of the same
message was lost in the medium).
As discussed in Section 6.2.4.1, the behaviour of the receiver could be
speciﬁed as follows.
process Receiver [put, receive, sendAck](m : nat) : noexit :=
hide timeout in
( timeout; sendAck!comp(m);
Receiver[put, receive, sendAck](m)
[]
receive?n : nat;
( [m = n] −> put; sendAck!n;
Receiver[put, receive, sendAck](comp(m))
[]
[m ̸= n] −> sendAck!n;
Receiver[put, receive, sendAck](m) ) )
endproc

6.3 Examples
209
The top-level behaviour of the medium (which is now a duplex communication
channel) could be speciﬁed as
process DupMedium [send, receive, sendAck, receiveAck] : noexit :=
Medium[send, receive] ||| Medium[sendAck, receiveAck]
endproc
which in turn uses the following medium.
process Medium [in, out] : noexit :=
in?n : nat;
( i; Medium[in, out]
[]
out!n; Medium[in, out] )
endproc
Notice that both directions of transmission can be modelled using the same
behaviour, with some simple renaming. This is because both mediums pass
on and lose messages in the same way.
This represents a typical LOTOS speciﬁcation of a communication pro-
tocol, however, the speciﬁcation is not wholely satisfactory, because timeouts
in communication protocols make such speciﬁcations time dependent. Hence,
to give a completely representative speciﬁcation of this protocol, we would
like to associate a time value with the action timeout and, hence, make the
oﬀering of this action dependent upon the time at which other actions can
occur. This is not possible in LOTOS, because the language only considers
“qualitative timing”; see Section 1.3. We discuss extensions to LOTOS that
support quantitative timing in Part IV.
As was the case for our nondata passing protocol example, the speciﬁcation
presented here is very similar to that investigated in demo 2 of the standard
release of the CADP tools [81]; see our earlier discussion in Section 3.4.2.
Once again, the veriﬁcation presented in the CADP demo can be viewed as
an illustration of how a protocol speciﬁcation such as ours could be formally
veriﬁed against a requirements description.8
8The reader comparing the CADP communication protocol with ours should
though beware of a number of diﬀerences between the two. Firstly, the CADP ver-
sion does include a data component to message transmissions, however, we have ab-
stracted from this detail; see the discussion earlier in this section. Secondly, rather
than using guarded commands, the CADP speciﬁcation uses data passing condi-
tionals in the style of the fragment at the end of Section 6.2.4.3. Thirdly, actions
PUT and GET in the CADP speciﬁcation actually play the opposite role to put
and get in our protocol speciﬁcation. Thus, in the CADP example, PUT plays the
role of putting into the protocol (at the sender end), whereas in our speciﬁcation,
put plays the role of putting into the layer above the protocol (at the receiver end).
Finally, the CADP speciﬁcation also includes the possibility that the mediums can

210
6 Beyond pbLOTOS
6.3.2 Dining Philosophers
Assuming the deﬁnition of the constant data types, name, side, action and
chopstick, introduced at the beginning of Section 6.2, the top-level behaviour
of the Dining Philosophers can be speciﬁed as follows.
speciﬁcation philo [pick, put] : noexit
(* Type Deﬁnitions *)
behaviour
ThinkTank [pick, put] || ChopSticks [pick, put]
where
(* Deﬁnition of ThinkTank *)
(* Deﬁnition of ChopSticks *)
endspec
Thus, the speciﬁcation is composed of the collection of philosophers, which
reside in process ThinkTank, and the collection of chopsticks, which reside in
process ChopSticks. These two components are run together fully synchronised
in parallel. As a result, the actions of the speciﬁcation, which are all either
on gates pick or put, can only be performed jointly by the ThinkTank and
the ChopSticks components. In other words, an eating implement can only be
moved (to a mouth or back to the table) by a philosopher.
ThinkTank is deﬁned as follows.
process ThinkTank [pick, put] : noexit :=
phil [pick, put] (Aristotle, stick1, stick4)
|||
phil [pick, put] (Buddha, stick2, stick1)
|||
phil [pick, put] (Confucius, stick3, stick2)
|||
phil [pick, put] (Descartes, stick4, stick3)
endproc
This process simply runs the four philosophers independently in parallel, with
the appropriate instantiation of data values. The use of independent paral-
lelism here reﬂects the fact that the philosophers do not communicate amongst
themselves; our philosophers have simple needs: they are only motivated to
knowingly lose a message; i.e. with an indication that the message has been lost,
and, in this situation, the mediums notify the sender and receiver of this loss, which
resend accordingly.

6.3 Examples
211
sustain themselves by eating and by (self-) reﬂecting on their theories. How-
ever, they have no desire to subject their ideas to the competing views of their
co-thinkers.
All philosophers have the same basic behaviour, which is coded in process
phil.
process phil [pick, put] (n:name, l,r:chopstick): noexit :=
( pick !n !l !left; exit(n, eat)
|||
pick !n !r !right; exit(n, eat) )
>> accept n1:name, ac: action in
( put !n !l !left; exit(n, think)
|||
put !n !r !right; exit(n, think) )
>> accept n1:name, ac:action in
phil [pick, put] (n,l,r)
endproc
Thus, philosophers repeatedly perform a sequence of phases. The ﬁrst of these
involves picking up (in either order) the two pieces of cutlery required to eat.
Once these have been acquired, the philosopher enters an eating state.9 Then,
once the philosopher is satiated, he decides to put his two sticks down (again in
either order) so that he can liberate his mind from the demands of controlling
his eating implements and can satisfy his other needs: to think. This sequence
of phases repeats ad inﬁnitum.
The chopsticks also exist independently in parallel with each other.
process ChopSticks [pick, put] : noexit :=
stick [pick, put] (stick1)
|||
stick [pick, put] (stick2)
|||
stick [pick, put] (stick3)
|||
stick [pick, put] (stick4)
endproc
process stick [pick, put] (chs:chopstick): noexit :=
pick ?n:name !chs ?s:side;
9Note, the data values passed through the sequential composition, here bound
to n1 and ac, are actually superﬂuous, because they are not used in the enabled
behaviour. Thus, they are included here as a, somewhat artiﬁcial, demonstration of
the successful termination syntax.

212
6 Beyond pbLOTOS
put ?n:name !chs ?s:side; stick [pick, put] (chs)
endproc
endspec
So, each chopstick simply makes itself available to be picked up and then put
down.
This speciﬁcation correctly models the behaviour of the Dining Philoso-
phers scenario, however, it contains a deadlock. For example, because there are
only four chopsticks shared amongst four philosophers and each philosopher
requires two sticks to eat, the following trace will yield a deadlock,
pick Confucius stick3 left pick Aristotle stick1 left
pick Descartes stick4 left pick Buddha stick2 left
The result of this sequence (and there are a number of others) is that all
philosophers hold a single stick (actually, all in the same hand) and there are
no more sticks left on the table. However, two sticks are required in order to
eat and, thus, every philosopher is blocked in his eﬀort to satisfy his appetite
and the system is deadlocked. The upshot of which is that all the philosophers
will eventually starve to death!
There are many known solutions to the Dining Philosophers problem. How-
ever, we only have room to focus on one of these approaches. This adds a con-
straining process that limits the capacity of philosophers to pick up sticks.10
behaviour
ThinkTank [pick, put]
||
ChopSticks [pick, put]
||
StickConstraint [pick, put] (0, 0)
This added constraint keeps track of the total number of chopsticks that are
in left, respectively, right-hands, which it does by maintaining a global count
of the number of left (nl), respectively, right (nr), stick allocations.
process StickConstraint [pick, put] (nl, nr: int) : noexit :=
pick ?n:name ?chs:chopstick !left [nl < 3];
StickConstraint [pick, put] (nl + 1, nr)
[]
pick ?n:name ?chs:chopstick !right [nr < 3];
StickConstraint [pick, put] (nl, nr + 1)
10Note, this is a nice example of the value of multiway synchronisation, which
enables constraining behaviours to be run in parallel, synchronising on existing in-
teractions in the constrained system. Thus, it enables the constraint-oriented spec-
iﬁcation style [196].

6.4 Extended LOTOS
213
[]
put ?n:name ?chs:chopstick !left;
StickConstraint [pick, put] (nl −1, nr)
[]
put ?n:name ?chs:chopstick !right;
StickConstraint [pick, put] (nl, nr −1)
endproc
This constraint prevents the occurrence of deadlock: a chopstick may only
be picked up as right or left chopstick, if there are less than three chopsticks
picked up as left, respectively, right chopstick. Thus, the transition system
arising from this constrained Dining Philosophers will be the same as that for
the original (nonconstrained) Dining Philosophers, except that, branches that
lead to four chopsticks being placed in four left (respectively, right) hands will
not arise. Thus, traces of the form of the deadlock causing trace we highlighted
earlier will not arise.
6.4 Extended LOTOS
The E-LOTOS restandardisation activity was completed in 2001 [103]. It is
beyond the scope of this format to present an exhaustive discussion of the
notation, the interested reader is referred to an overview of the language
presented as Chapter 5 of [41]. Thus, we merely give a very brief summary of
the extensions.
The list of features added is extensive; it includes the following,
•
A modules facility,
•
A new (ML-based) data language,
•
Real-time features (which are discussed in more depth in Part IV),
•
A re-evaluation of sequential composition,
•
Entwining of the process and data parts,
•
Imperative features (such as assignment and loops),
•
A more general parallel composition operator,
•
A suspend / resume operator (a generalisation of the disabling operator),
•
Exception handling, and
•
Subtyping and typed gates.
Thus, although backward compatibility with LOTOS has been maintained, in
many respects, E-LOTOS is a completely new language. Each of the new fea-
tures is individually elegant and well justiﬁed. However, because the resulting
complete language is now rather large, it is not clear how the features will sit
together. In particular, the basic semantic deﬁnitions are now rather complex.

214
6 Beyond pbLOTOS
This can be argued to be unavoidable for an “industrially usable” lan-
guage. However, it certainly contrasts with standard LOTOS, which has a sim-
ple semantic interpretation. Consequently, theoretical investigations of stan-
dard LOTOS are feasible, e.g. axiomatisation [28]. Such investigations will be
harder with E-LOTOS.
In fact, in some respects, E-LOTOS is running against the tide of con-
currency theory research, which has been moving in the direction of pared
down tractable notations; i.e. that are amenable to formal veriﬁcation. In
contrast, E-LOTOS adds functionality at the expense of ease of veriﬁcation
and tractability.
This said, the added features certainly enhance the speciﬁcation power of
the language. For example, it is clear that ACT-ONE (the “original” LOTOS
data language) was a major hindrance to the industrial uptake of LOTOS [150]
and the new data language resolves many of the concerns raised by users.
Furthermore, the real-time features are very powerful and enable application
of the language to a whole new class of systems.

7
Comparison of LOTOS with CCS and CSP
There are now many process calculi, all in some way inspired by the pioneering
work of Milner, Hoare and, a little later, Roscoe. Prominent within this family
of basic calculi are, CCS, CSP, CIRCAL [144], ACP [15], LOTOS and SCCS
[146].1 A small portion of the history of the development of these calculi is
depicted in Figure 7.1. As this diagram indicates, LOTOS can largely be
seen as a syntactic and semantic composite of CSP and CCS. In fact, one
of the most interesting aspects of LOTOS is how it seeks to reconcile the
two diﬀerent approaches. This chapter makes a broad comparison between
LOTOS and each of these other two techniques. Although, we make no claims
to be exhaustive in this comparison. Rather, our focus is on a small set of key
diﬀerences between the approaches.
This material has been prepared with reference to the CCS notation de-
ﬁned in [148] and the CSP notation deﬁned in [96] and in [171]. Although,
in the latter case, there are actually a number of diﬀerences between Hoare’s
1985 presentation of CSP and Roscoe’s updating of the approach in 1997. As
a result, our comparison between LOTOS and CSP is somewhat longer and
more caveat laden than our CCS comparison. In addition, the unpublished
notes associated with the tutorial [77] have proved valuable source material.
In terms of motivation, the three techniques have some diﬀerences.
•
In CCS, Milner sought to identify a minimal calculus from which all use-
ful behaviour and operators can be deﬁned. Thus, the base language is
deliberately small.
•
CSP is, in some respects, an investigation into the spectrum of possi-
ble “useful” operators for expressing concurrent behaviour. Thus, [96]
and [171] contain a large number of operators, which they characterise
mathematically.
1Note again that we are not considering here an important branch of process
calculi focused on mobility of processes and communication channels, e.g. [149].

216
7 Comparison of LOTOS with CCS and CSP
[Hoare78]
Initial CSP
[Hoare85]
CSP
[INMOS84]
OCCAM
[ISO87]
LOTOS
[Milne&Milner79]
Early Process Calculi
[Milner80]
CCS
[Milner83]
SCCS
[Bergstra&
Klop85]
ACP
[Milne85]
CIRCAL
....
[ISO2001]
E−LOTOS
[Roscoe97]
CSP
[Milner89]
Refined CCS
theory
Fig. 7.1. Portion of the History of Process Calculi
•
LOTOS has sought to standardise a “canonical” set of operators, where
they are canonical both in terms of usability and in terms of primitiveness.
In this respect, LOTOS could be argued to sit between CCS and CSP.
Before we compare the approaches, it is important not to overlook that, de-
spite the impression that our comparisons may give, the three calculi are, in
a broader sense, very similar. This is because all the notations are built upon
the basic idea of atomic actions, their combining operators and interleaving
(branching-time) semantics. This is the starting point for all the calculi.
We relate CCS and CSP to LOTOS separately.

7.1 CCS and LOTOS
217
7.1 CCS and LOTOS
We begin with Table 7.1, which summarises how LOTOS and CCS relate
construct by construct. Bold in the table indicates syntactic constructs that
are very closely related, whereas constructs not in bold are only approximately
related. However, the comparison here is not exhaustive in respect of LOTOS
operators, which are, as a reﬂection of the diﬀerent intents of the notations,
a lot more numerous than in CCS. We particularly concentrate on diﬀerences
between the notations as they are most revealing with regard to the character
of the LOTOS approach.
As indicated in this table, a number of the CCS and LOTOS constructs
are analogous, e.g. ports and gates, agents and behaviours and action preﬁx.
However, some of the operators have subtly diﬀerent and some signiﬁcantly
diﬀerent behaviour. We consider these diﬀerences in the following sections.
7.1.1 Parallel Composition and Complementation of Actions
It is here that the greatest diﬀerences exist between LOTOS and CCS. With
regard to parallel composition, LOTOS is much more akin to CSP. CCS em-
ploys a biparty synchronous communication paradigm, whereas LOTOS uses
multiway synchronisation.
In CCS, each observable action, x say, has a complement, x, with which
it can synchronise. Such annotation of actions deﬁnes the communication
patterns within a speciﬁcation. The concept is best illustrated by example.
Consider the CCS behaviour:
X
def
= (x.A | x.A′ | x.A′′)
which yields the derivation tree depicted in Figure 7.2. Thus, any of the ac-
tions that are initially oﬀered by the three constituent behaviours, x.A, x.A′
and x.A′′, are oﬀered individually by the composite behaviour (and suitable
evolution of the complete behaviour takes place). In addition, the action x
could synchronise with either of the two complement actions and evolve ac-
cordingly. Thus, the derivation allows x to interact with either of the x actions,
but, it is important to note that the two x actions cannot interact together.
In addition, notice the use of internal (or perfect) actions to identify a
synchronisation / communication in CCS, the τ actions in Figure 7.2. The
implication of this is that an interaction between two parties is closed to
any third party. This also motivates the preference for restriction rather than
hiding, which we discuss shortly.
Thus, in CCS, we obtain a biparty form of synchronisation, which con-
trasts with the multiway synchronisation oﬀered by LOTOS. For example, in
LOTOS, we could give an example which, at least superﬁcially, looks related
to the above, viz,
Q := x; B |[x]| x; B′ |[x]| x; B′′

218
7 Comparison of LOTOS with CCS and CSP
Construct
CCS
LOTOS
Computation Units
Agents (A1, A2,. . . )
Behaviours (B1, B2,. . . )
Interaction Points
Ports (p1, p2,. . . )
Gates (g1, g2,. . . )
Units of Observation
Observable Actions
Observable Actions
(x1, x2,. . . ) (x1, x2,. . . )
(x1, x2,. . . )
Internal Actions
τ
i
Action Preﬁx
a.A
a; B
Inaction
0
stop
Binary Choice
A + A′
B [] B′
Parallel Composition
A | A′
B |[G]| B′
(+ action complementation)
Hiding
A\G (restriction)
hide G in B (hiding)
Process Deﬁnition
X
def
= A
P := B
Recursion
ﬁx (X = A)
P := B
(P referenced in B)
Relabelling
A[f] or A[x′
1/x1, . . . , x′
n/xn]
B[x′
1/x1, . . . , x′
n/xn]
Generalised Choice

j∈I Aj
choice x in G [] B
Successful Termination
Not in basic calculus
exit
Enabling
Not in basic calculus
B1 >> B2
Generalised Parallelism
Πj∈I Aj
par x in G |[H]| B
Value Passing Actions
x(r),
x(E)
x ?r : T,
x !E
Table 7.1. Relating CCS and LOTOS Constructs

7.1 CCS and LOTOS
219
x.A | x.A’ | A’’
x.A | A’ | x.A’’
τ
τ
A | x.A’ | A’’
x
A | x.A’ | x.A’’
x.A | x.A’ | x.A’’
x
x
A | A’ | x.A’’
Fig. 7.2. Derivation of CCS Parallel Composition
x;B |[x]| x;B’ |[x]| x;B"
x
B |[x]| B’ |[x]| B"
Fig. 7.3. Derivation of LOTOS Parallel Composition
which can only perform a single transition, as depicted in Figure 7.3. This as-
pect of LOTOS is often vaunted as a motivation for preferring the language; in
particular, it enables the constraint-oriented style of speciﬁcation, discussions
of which can be found in [171,196].
Returning to the CCS communication mechanism, you can also view ac-
tions such as x as input actions, and complemented actions, x, as output
actions. This becomes evident when the data passing calculus is considered
and the values of expressions are associated with x, e.g. x(r +5), and variable
bindings are associated with x, e.g. x(n). Thus, complementation has a rela-
tion to ! and ? in LOTOS. Although, through their interplay with multiway
synchronisation, LOTOS ! and ? are more general, e.g. value generation can
be created; see Section 6.2.4.1.
Another aspect of relating LOTOS concurrency to CCS concurrency is to
ﬁnd equivalents of the extreme forms of LOTOS parallel composition, ||| and
||. The ﬁrst of these is, in eﬀect, duplicated by CCS parallel composition; i.e.
A1 | A2

220
7 Comparison of LOTOS with CCS and CSP
when L(A1) ∩L(A2) = ∅; i.e. when the two sides of the parallel composition
do not have any complementary actions. However, the generation of τ actions
by CCS synchronisation prevents an equivalent of || from existing.
7.1.2 Restriction and Hiding
The CCS equivalent of hiding is called restriction, however, this operator
does not generate internal actions; rather it removes actions (and the labelled
transition system subgraph rooted at that transition) altogether. For example,
the transitions that can be performed by X\{x}, where X was deﬁned in the
previous section, are depicted in Figure 7.4. Thus, all actions, or complements
of actions, in the restriction set are literally blocked from occurring. The
related hiding of x in the LOTOS behaviour Q would yield the transition
depicted in Figure 7.5.
X\{x}
τ
τ
(A | x.A’ | A’’)\{x}
(A | A’ | x.A’’)\{x}
Fig. 7.4. Derivation of CCS Parallel Composition with Restriction
hide x in Q
i
hide x in (B |[x]| B’ |[x]| B")
Fig. 7.5. Derivation of LOTOS Parallel Composition with Hiding
This diﬀerence in interpretation arises because restriction is typically used
in CCS to limit evolution of a behaviour to just synchronisation transitions;
i.e. the τ transitions. Thus, a typical speciﬁcation strategy is to deﬁne syn-
chronisation between an action and its complement and then restrict the spec-
iﬁcation in terms of that action.

7.1 CCS and LOTOS
221
7.1.3 Internal Behaviour
Modulo the diﬀerences discussed in the last two sections; i.e. the direct genera-
tion of internal actions as markers of synchronisation and the use of restriction
rather than hiding, CCS and LOTOS treat internal actions in similar ways.
In particular, the LOTOS handling of internal behaviour in choice contexts is
directly inherited from CCS; i.e. in respect of the creation of symmetric and
asymmetric internal choices.
In addition, LOTOS’s “fair” (rather than catastrophic) treatment of diver-
gence (see Section 5.1.4) is also largely inherited from CCS. This issue really
comes down to how divergence is handled in bisimulation relations, which are
the key means of semantic interpretation in CCS. By not adding an explicit
divergence term or condition and simply relying on the capacity of the double
arrow (=⇒) relation to pass through tau cycles, weak bisimulation (in partic-
ular) satisﬁes Kooman’s Fair Abstraction property [8]; see our discussion in
Section 5.1.4.
In addition, CCS obtains a “weak” congruence relation. This is typically
called observational congruence [145]. It is a little stronger than weak bisim-
ulation, because it constrains the initial internal moves of the two behaviours
in order to prevent the classic nonsubstitutive choice context, viz, that, using
CCS syntax,
τ.x.0
and
x.0
are weak bisimilar
but
τ.x.0 + y.0
and
x.0 + y.0 are not.
Thus, CCS observational congruence uses the same trick we used in our bisim-
ulation congruence introduced in Section 3.3.3.1.
Finally, it is also interesting that use of the restriction operator in CCS,
rather than hiding, may make the quest for congruences more straightforward.
For example, nonsubstitutive cases, such as were highlighted in Figure 5.4 with
regard to LOTOS testing equivalence, do not carry over to the restriction
operator.
7.1.4 Minor Diﬀerences
There are a number of further minor (and mainly syntactic) diﬀerences be-
tween CCS and LOTOS, some of which we document here.
•
Relabelling. The only point to make here is that CCS relabelling can
be arbitrarily placed between other operators in a behaviour expression,
whereas, in LOTOS, relabelling syntactically arises through action param-
eter binding on process invocation. In addition, the LOTOS equivalent of
CCS relabelling (i.e. B[x1/y1, . . . , xn/yn]) is syntactically hidden from the
speciﬁer.

222
7 Comparison of LOTOS with CCS and CSP
•
Generalised Choice. This takes a somewhat diﬀerent form in the two no-
tations. The CCS summation operator is indexed over some indexing set.
So, for example,

j∈{1,2,3} Aj = A1 + A2 + A3
If the indexing set is inﬁnite, an inﬁnite choice is generated. In contrast, the
LOTOS generalised choice operator is parameterised on gates or variable
names. Two typical examples are:
choice x in [y, z, w] [] x ; P
choice n : [1 . . . 10] [] z !n ; Q
•
Exit and Enabling. Neither successful termination nor sequential compo-
sition is included as primitive in CCS. However, Milner shows how similar
forms can be derived from the basic CCS calculus (see [148] Chapter 9)
by running the enabling and enabled behaviours together in parallel, sub-
ject to synchronisation on a distinguished action that signals termination
of the enabling behaviour and plays the role of the LOTOS action δ. We
reuse this approach in Section 14.1. In a value passing calculus, data val-
ues could be passed with this distinguished action, thus yielding a derived
analogue of fLOTOS’s parameterised exit and accept constructs.
•
Recursion. CCS deﬁnes recursion using a ﬁxed point notation and explicit
self-reference interchangeably. This is because the ﬁxed point notation:
ﬁx (X = A)
is more easy to deal with in certain formal situations.
7.2 CSP and LOTOS
In general, in terms of parallel composition, LOTOS and CSP are similar, and
CCS is diﬀerent, whereas in terms of choice, LOTOS and CCS are similar,
and CSP is diﬀerent. In addition, it should be noted that, in a number of
respects, time has brought CSP and LOTOS closer together. In particular,
the presentation of CSP in [171] is more similar to LOTOS than the version
of the language discussed in [96]. For example, the parallel composition stories
are a good deal closer in [171].
We present a list of LOTOS and CSP comparisons in Tables 7.2 and 7.3.
In the following sections, we consider in more depth key constructs that are
diﬀerent.
7.2.1 Alphabets
An initial point that is worth making is the important role that alphabets
play in CSP. All processes have an explicitly associated alphabet of actions
and the operators of the language are each deﬁned to have speciﬁc eﬀects on
alphabets. The notation αP denotes the alphabet of process P. As an example,
the following rule is associated with the parallel composition operator ||.

7.2 CSP and LOTOS
223
Construct
CSP
LOTOS
Computation Units
Processes (P1, P2,. . . )
Behaviours (B1, B2,. . . )
Interaction Points
Channels (c1, c2,. . . )
Gates (g1, g2,. . . )
Units of Observation
Events (x1, x2,. . . )
Observable Actions
(x1, x2,. . . )
Internal Actions
Not directly referencible
i
Action Preﬁx
x →P
a ; B
Inaction
stop
stop
Deterministic Choice
x1 →P1 | x2 →P2
x1 ; B1 [] x2 ; B2
x1 ̸= x2
x1 ̸= x2 ̸= i
Generalised
?x : A →P(x)
choice x in G [] x ; B
Deterministic Choice
(A a set of actions)
External Choice
P1 [] P2
B1 [] B2
Nondeterministic
P1 ⊓P2
i ; B1 [] i ; B2
Choice
Generalised Non-
⊓S
choice x in G [] i ; B
deterministic Choice
(S a set of processes)
choice r : T [] i ; B
Independent Parallel
P1 ||| P2
B1 ||| B2
Alphabetised Parallel
P1 αP1||αP2 P2
B1 |[G]| B2
(although, see caption)
(G = L(B1) ∩L(B2))
Fully Synchronised
P1 Σ||Σ P2
B1 || B2
(Σ the set of all actions)
Table 7.2. Relating CSP and LOTOS Constructs (continued in Table 7.3). Note
though that, in fact, the alphabetised parallel considered here is the one used in [96],
Roscoe generalises the operator by allowing it to be parameterised on sets of actions
other than the intrinsic alphabet of the constituent processes [171].

224
7 Comparison of LOTOS with CCS and CSP
Construct
CSP
LOTOS
Generalised Parallel
P1 ||
A
P2
B1 |[G]| B2
Hiding
P\A (concealment)
hide G in B (hiding)
Process Deﬁnition
X = P
P := B
Recursion
µX.F(X) or X = P
P := B
(X referenced in P)
(P referenced in B)
Relabelling
f(P) f a one-to-one func-
B[x′
1/x1, . . . , x′
n/xn]
tion (although, see caption)
Successful Termination
skip and √
exit and δ
Enabling
P1 ; P2
B1 >> B2
Disabling
P1 ∧P2
B1 [> B2
Value Passing Actions
x !E , x ?r : T
x !E , x ?r : T
Table 7.3. Relating CSP and LOTOS Constructs continued. Note, the restriction
here that relabelling is a one-to-one function is actually dropped in [171]
α(P||Q) = αP ∪αQ
In fact, the reason for explicitly recording alphabets is to enable the alpha-
betised parallel composition operator to be deﬁned2, because it is expressed
explicitly in terms of the alphabets of its constituent processes. We return to
this point shortly.
7.2.2 Internal Actions
Internal actions are used for many roles, for example, in CCS τ is used to
denote a synchronisation; in LOTOS and CCS it is used to create nonde-
terminism and it is also used to denote some internal behaviour, perhaps
resulting, in LOTOS, from hiding. In CSP, an internal action cannot be di-
rectly referenced by the speciﬁer. Although, it can be created through hiding
2In fact, this was more of an issue for Hoare’s 1985 presentation of the language
[96], which was particularly strongly focused on the alphabetised parallel operator. In
contrast, Roscoe’s 1997 presentation [171] reﬂects the expressive power of generalised
parallel, which corresponds to LOTOS’s generalised parallel; see Section 7.2.4.

7.2 CSP and LOTOS
225
(called concealment in CSP). A consequence of this is that nondeterminism
and concealment must be handled diﬀerently in CSP compared to LOTOS
and we discuss both of these in future sections.
7.2.3 Choice
As already suggested, some major diﬀerences between CSP and LOTOS reside
in the deﬁnition of choice. CSP contains a spectrum of choice operators, each
of which captures a diﬀerent class of choice. One motivation for this is to locate
the particular characteristics and laws applicable to each of these classes. In
contrast, LOTOS (and CCS as well) uses a single general notion of choice,
specialisations of which reﬂect diﬀerent forms of CSP choice. We consider each
of the CSP choice operators in turn.
7.2.3.1 Deterministic Choice (also Called Guarded Alternative)
This is the most basic form of choice oﬀered in CSP and its binary form is
denoted
x1 →P1 | x2 →P2
which is only deﬁned if x1 ̸= x2. Thus, this operator can only express deter-
ministic choices. Remember, internal actions cannot be explicitly referenced,
so asymmetric nondeterminism cannot be directly deﬁned with this operator
(although, it can be created in combination with concealment).
Using deterministic choice in [96], Hoare is able to deﬁne a completely
deterministic subcalculus of CSP which he fully characterises using trace se-
mantics. Clearly, a LOTOS equivalent of this operator is given by
x1; B1 [] x2; B2
where nondeterminism is not allowed; i.e. x1 ̸= x2 and neither x1 or x2 are
internal actions.
CSP allows a generalisation of the binary deterministic choice, denoted
?x : A →P(x)
where A is a set of action names; e.g.,
?x : {y, z, w} →P(x) = y →P(y) | z →P(z) | w →P(w)
Notice that, because A is a set, once again, a nondeterministic choice cannot
be deﬁned. An obvious equivalent of this behaviour is given by:
choice x in A [] x ; B

226
7 Comparison of LOTOS with CCS and CSP
7.2.3.2 External Choice
The CSP operator [] strictly generalises deterministic choice. In particular, it
adds the possibility that certain forms of nondeterminism can arise, because
in
P1 [] P2
the processes P1 and P2 can have any arbitrary form. Thus, a behaviour such
as
(a →Q1) [] (a →Q2)
is legal. However, because internal actions cannot be explicitly referenced,
we cannot directly create internal action induced nondeterminism with this
operator. Although, using CSP concealment / hiding, some varieties of such
nondeterminism can be created, which we discuss in Section 7.2.5. In summary
then, although [] in CSP is certainly the closest to the LOTOS [] operator, due
to diﬀerences in the languages, it is not quite an analogue of LOTOS choice.
7.2.3.3 Nondeterministic Choice
CSP also includes a pure form of symmetric nondeterministic choice, denoted
⊓, where
P1 ⊓P2
will internally decide to either behave as P1 or as P2. It is not hard to see
that the LOTOS equivalent of this behaviour is:
i ; B1 [] i ; B2
In addition, a generalised nondeterministic choice is oﬀered in CSP, which is
denoted
⊓S
where S is a set of processes. In fact, LOTOS generalised choice cannot be
parameterised over sets of processes, so, neither of the following is quite an
analogue of this operator.
choice x in G [] i ; B
or
choice r : T [] i ; B
However, of course, if S is ﬁnite, ⊓S can be expressed as a number of binary
nondeterministic choices.
So, we have considered how CSP models the symmetric forms of non-
determinism that were introduced for LOTOS. This only leaves asymmetric
nondeterminism:
i ; B1 [] x ; B2

7.2 CSP and LOTOS
227
The CSP analogue is modelled using a combination of [] and ⊓; i.e,
P1 [] (x →P2 ⊓stop)
which will initially oﬀer an external choice between P1 and x →P2, but,
at some point, may nondeterministically decide to evolve to P1 (actually,
P1 [] stop, which is equivalent).
7.2.4 Parallelism
The basic principles of CSP and LOTOS parallel composition are very similar.
Although, the earlier presentations of CSP parallel composition, particularly
[96], used alphabetised parallelism. However, by the time of [171], an operator
equivalent to LOTOS generalised parallel composition was employed as the
primitive form.
Indeed, it is clear that alphabetised parallel can be generated from gener-
alised parallel. Speciﬁcally, the alphabetised parallel introduced in [171],
P1 A1||A2 P2
states that P1 and P2 evolve independently in parallel, subject to synchroni-
sation on any events in A1 ∩A2. The equivalent of this operator is a LOTOS
composition:
B1 |[G]| B2
where G is exactly the set of actions in both A1 and A2. In the special case
where A1 = A2 = Σ (Σ is the CSP analogue of Act), the CSP parallel com-
position is equivalent to the LOTOS fully synchronised parallel composition:
B1 || B2
In addition, CSP contains an explicit independent parallelism operator |||,
which is clearly equivalent to the LOTOS parallel composition:
B1 ||| B2
7.2.5 Hiding
CSP concealment, denoted
P\G
conceptually has a similar eﬀect to
hide G in B
In particular, nondeterminism can be created through concealment. For ex-
ample,

228
7 Comparison of LOTOS with CCS and CSP
(a →P1 | b →P2)\{a, b}
is equivalent to
P1 ⊓P2
and is, thus, analogous to the LOTOS behaviour,
i; B1 [] i; B2
This also means that asymmetric nondeterminism can be created using con-
cealment. In particular,
(a →P1 | b →P2)\{a}
is analogous to the LOTOS behaviour
i; B1 [] b; B2
(*)
However, a subtle, but important distinction is that a concealed action cannot
resolve a choice. So,
(a →P1)\{a} | (b →P2)
is not equivalent to (*) above. This behaviour is, in fact, analogous to the
LOTOS behaviour:
B1 [] b; B2
This diﬀerent interpretation of how internal behaviour aﬀects choice turns out
to be crucial as it is one reason why CSP is a congruence for refusal-based
reﬁnement and equivalence, but LOTOS is not; see [120] and our discussion
in Section 7.2.6.2.
7.2.6 Comparison of LOTOS Trace-refusals with CSP
Failures-divergences
Of the refusal-based semantics, the CSP failures model [96, 171] is the most
well known and has the longest history. As indicated earlier, LOTOS refusal
semantics are based upon CSP failures. However, the approaches are diﬀerent
in important respects.
7.2.6.1 Divergence
A fundamental diﬀerence between LOTOS trace-refusals and CSP failures is
the handling of divergence. In fact, it is in this area that many of the semantic
models associated with process calculi can be diﬀerentiated [192].
CSP is extreme in its handling of divergence; it employs a, so called, catas-
trophic interpretation, reﬂecting a strong view of the undesirability of diver-
gence; to quote [96]:

7.2 CSP and LOTOS
229
“. . . divergence is never the intended result of the attempted deﬁnition
of a process.”
This interpretation of divergence is a reﬂection of Hoare’s concern for imple-
mentability and, clearly, implementation of divergent behaviour is an issue.
However, this view of inﬁnite internal behaviour is not universally accepted,
as exempliﬁed by Kooman’s Fair Abstraction property [8] (see Section 5.1.4)
which the LOTOS handling of divergence reﬂects.
The CSP view of divergence is reﬂected in the important role the process
CHAOS plays. CHAOS is a process that can perform any trace, can refuse
anything after any trace and can diverge after any trace. It is the top element
of the failures–divergences preorder; i.e. every other process is a reﬁnement of
CHAOS, in the sense that, every other process is more deterministic than it. In
fact, CHAOS can be viewed as the most nondeterministic and unpredictable
process and, in CSP terms, the “worst” process.
Another important aspect of the catastrophic handling of divergence is
that, if a divergence could occur during a computation, the complete com-
putation is viewed to be divergent. That is, even if a computation can pass
through a divergent state; i.e. one that oﬀers the chance of diverging, but
could also reach a nondivergent state, the computation is viewed to be di-
vergent (and, hence, chaotic); some of the examples we considered in Section
5.1.4, e.g. (6) and (7) in Figure 5.3, have this character. Put another way, any
suﬃx of a divergent trace is itself divergent. This again reﬂects the view that
any computation containing the possibility of divergence is unintended.
Divergence is handled quite diﬀerently in CCS, and LOTOS inherits this
interpretation: a noncatastrophic approach is employed. For example, in terms
of weak bisimulation, a deﬁnition such as
R := i; R [] x; stop
is equivalent to the behaviour:
T := x; stop
even though the R could possibly diverge. Also, see the examples previously
highlighted in Section 5.1.4. As previously suggested, this is often called a
“fair” interpretation of divergence, in the sense that R cannot refuse the ob-
servable action x inﬁnitely many times in favour of i. Thus, there must exist
a ﬁnite time in the future at which x is oﬀered, hence, Kooman’s Fair Ab-
straction property [8].
The LOTOS trace-refusals semantics reﬂect this fair (noncatastrophic)
interpretation. Divergence is not distinguished in trace-refusals semantics. For
example, in the above behaviours,
J R Ktr = J T Ktr = { ϵ , x }
and
RefR(ϵ) = RefT (ϵ) = P(L −{x})

230
7 Comparison of LOTOS with CCS and CSP
In particular, notice that R does not refuse x after ϵ; this is a direct con-
sequence of employing the Fair Abstraction property. Furthermore, R ≈T,
because,
{ (R, T) , (stop, stop) }
is a suitable weak bisimulation relation.
A consequence of this handling of divergence is that weak bisimularity does
not imply CSP failures–divergences equivalence. However, weak bisimularity
does imply testing equivalence in the LOTOS setting.
As an illustration of the diﬀerence between LOTOS and CSP in respect of
handling divergence, consider the weak bisimulation reduction of the CADP
LOTOS alternating bit protocol discussed in Section 3.4.2. The resulting tran-
sition system generated is very small and also does not contain any “tau”
loops; i.e. cycles in the transition system that only involve internal actions.
However, the nonreduced transition system of the example did contain tau
loops, which could arise, for example, because the system could enter the fol-
lowing pattern of inﬁnite behaviour, the sender sends a message, it is lost in
the medium, the sender times out and resends, the resend is again lost etc.
Because only put and get actions are observable, all such cyclic behaviour is
divergent.
The reason that such tau loops can be removed under weak bisimulation is
due to the noncatastrophic interpretation of divergence. That is, the fairness
assumption implies that a process cannot inﬁnitely often select a transition of
the loop at the expense of a transition that escapes the divergence; i.e. in our
example, a transition that escapes the continuous sequence of retransmission
and loss.
This diﬀerence between the LOTOS and CSP approaches is reﬂected in
the way that the alternating bit protocol has to be speciﬁed in CSP; see
Section 5.3 of [171]. Speciﬁcally, Roscoe has to go to great lengths to prevent
the sort of sequences of loss, timeout and retransmission, highlighted above,
from generating divergence. This adds to the complexity of the speciﬁcation.
In contrast, the Fair Abstraction approach is to allow such tau loops to arise
unconstrained at the speciﬁcation level, but to impose a fairness assumption
at the level of the transition system that ensures they will be exited in ﬁnite
time.
7.2.6.2 Development Relations and Congruence
The complete CSP semantic model identiﬁes the failures of a process (i.e.
traces and refusals) and its divergences (i.e. the traces from which it could
diverge). Then the CSP reﬁnement relation is subsetting of each of the con-
stituents of this semantic model. Thus, a reﬁnement must not have any failures
or divergences that the abstract speciﬁcation does not. This leads to a relation
that, modulo the handling of divergence, is very close in spirit to the LOTOS

7.2 CSP and LOTOS
231
reduction relation and reﬁnement corresponds to reduction of nondetermin-
ism.
However, an important aspect of CSP reﬁnement is that it is a pre-
congruence over the CSP operators and the induced equivalence (failures
equivalence) is a congruence. Two issues contribute to this; the ﬁrst is re-
lated to the handling of divergence and how such divergence can be created
through concealment and the second is due to the capacity of internal actions
to resolve choice in CSP. As an illustration of the former of these; i.e. that a
catastrophic interpretation of divergence helps the quest for congruence, con-
sider the example processes at the end of Section 5.1.5 depicted in Figure 5.4;
i.e.
P := x ; P1 [] x ; P2
where
P1 := w ; P1 [] y ; stop
and
P2 := w ; P2 [] z ; stop
Q := x ; Q1 [] x ; Q2
where
Q1 := w ; Q2 [] y ; stop
and
Q2 := w ; Q1 [] z ; stop
which demonstrate that te is not a congruence in hiding contexts. Speciﬁcally,
P and Q are testing equivalent. However, P ′ and Q′, deﬁned as follows, and
also depicted in Figure 5.4, are not testing equivalent.
P ′ := hide w in P
and
Q′ := hide w in Q
However, not only are the CSP analogues of P and Q failures equivalent (in a
similar way to which P and Q are testing equivalent), but, the CSP analogues
of P ′ and Q′ are also failures equivalent. This is because, according to a
CSP interpretation, they both perform an x and then become equivalent to
CHAOS, because, even only the possibility to diverge, collapses to catastrophe;
i.e. the capacity to perform any trace and refuse anything at any point. For a
further discussion of this issue see [120].
Finally, with regard to the capacity of internal actions to resolve choice
in CSP, we can see that the fact that internal actions generated from process
arguments do not resolve [] helps the quest for congruence. Speciﬁcally, let us
return to our classic illustration of why choice is not a congruence for “weak”
LOTOS equivalences; i.e.,
R1 := x ; stop
and
R2 := i ; x ; stop
are testing and weak bisimulation equivalent, but
R1 [] y ; stop
and
R2 [] y ; stop
are not. However, the CSP analogues would be
R1 = x →stop
and
R2 = (z →x →stop)\{z}
and
Q1 = R1 [] (y →stop)
and
Q2 = R2 [] (y →stop)

232
7 Comparison of LOTOS with CCS and CSP
both pairs of which are failures–divergences equivalent, because the initial τ
generated by R2 cannot resolve the choice in Q2 and, thus, does not generate
asymmetric nondeterminism. This is, for example, apparent in the operational
semantics of CSP choice on page 162 of [171].

8
Communicating Automata
8.1 Introduction
This chapter focuses on a class of concurrency theory notations that can
be seen as an alternative to process calculi. These notations are a rather
natural adaptation of classic automata theory (see e.g. [5]), which are broadly
classiﬁed as Communicating Automata (CAs). The basic idea is to model the
components in a concurrent system using automata and interaction between
components is modelled using message passing communication. Although not
universally the case, interaction in these techniques is typically modelled using
synchronous message passing, similar to that employed in process calculi.
Indeed, we introduce a communicating automata notation based upon CCS-
style binary synchronisation.
Communicating automata are the most prominent modelling technique
when exhaustive veriﬁcation of concurrent systems is applied, which is wit-
nessed by model-checking, one of the most successful applications of formal
methods in practice. Given a system represented as a network of communi-
cating automata, and a correctness requirement expressed in some temporal
logic (e.g. Linear time Temporal Logic (LTL) [162] or Computation Tree Logic
(CTL) [57]), the model-checking algorithm will explore the network’s state-
space in order to determine whether the property is satisﬁed (in other words,
whether the state-space represents a model for the formula). Depending on
the formula, the model-checking algorithm might also return a justiﬁcation
for the answer, typically in the form of a system execution (a sequence of
states). Usually, temporal logic formulae will denote safety or liveness proper-
ties (important among these are reachability formulae); informally speaking,
these properties denote the reachability (or unreachability) of certain states
of interest (or executions characterised by certain ordering of relevant states).
Despite being ubiquitous in the modelling of concurrent systems, com-
municating automata can only describe systems for which a ﬁnite state-space
abstraction can be found (a limitation inherited by model-checking). Neverthe-
less, many systems of interest naturally present inﬁnite state behaviour (e.g.

234
8 Communicating Automata
those systems where the modelling of data in inﬁnite domains is important).
This motivates the presentation of inﬁnite state communicating automata (IS-
CAs), a basic framework in which inﬁnite state systems can be modelled. In
this respect, we also comment on a typical deductive veriﬁcation approach for
this kind of systems, which is representative of those commonly found in the
literature and practice.
Finally, a further reason for introducing communicating automata is that
they play a particularly important role in the timed concurrency theory set-
ting, where timed automata, and their associated model-checking algorithms,
are one of the most commonly used methods for specifying and verifying time
critical systems. Chapters 11, 12 and 13 focus on such timed extensions of
communicating automata.
The rest of the chapter is organised around ﬁnite and inﬁnite state com-
municating automata. Section 8.2 describes networks of (ﬁnite state) com-
municating automata; this includes formal deﬁnitions of components in Sec-
tion 8.2.1, parallel composition in Section 8.2.2, and a comparison with process
calculi in Section 8.2.6. Semantics and development relations are discussed in
Section 8.2.4, and veriﬁcation of networks of CAs is addressed in Section 8.2.5
(in particular, temporal logic and model-checking are discussed). The pre-
sentation of inﬁnite state communicating automata in Section 8.3 follows a
similar layout.
8.2 Networks of Communicating Automata
We begin by describing a basic automata model in which components are
ﬁnite-state automata and there is one level of such components. This approach
is called networks of communicating automata.
8.2.1 Component Automata
The ﬁnite-state automata components have much in common with the la-
belled transition systems discussed as a semantic model of process calculi
in Section 3.3. Speciﬁcally, automata components have the following general
form,
(L, TL, T, l0)
where
•
L is a ﬁnite set of locations; the automaton can only be in one location at
a time;
•
TL is a ﬁnite set of transition labels;
•
T ⊆L × TL × L is the transition relation, where (l, a, l′) ∈T states that a
transition from location l to location l′ exists, which is labelled with a. Note

8.2 Networks of Communicating Automata
235
that more than one transition may contain the same label.1 Transitions
are typically denoted
l
a
−→l′
•
And l0 ∈L is the initial location of the automaton.
As an illustration of component automata, Figure 8.1 depicts a Medium and a
Sender automaton for the communication protocol introduced in Section 2.2.1.
In this depiction, initial locations are denoted with a double circle and tran-
sition labels are action names. In particular, there is a distinction between
communication actions (here called half actions) and internal actions (here
called completed actions). The former are indicated by the annotations ! and
?. We discuss this distinction further shortly.
Medium
send?
receive!
Sender
get?
receiveAck?
send!
send!
timeout
lose
Fig. 8.1. Example Communicating Automata
These automata follow the same pattern as the pbLOTOS speciﬁcation of
the same components introduced in Section 2.4. Thus, the Medium waits for
a send action (from the Sender), then it either loses the transmission or it
1Alternatively, T could have been deﬁned as a set of sets Ta, where every set
Ta contains all transitions labelled with a ∈TL, which is the approach we took in
Section 3.3.2.1.

236
8 Communicating Automata
passes it on by performing a receive action (with the Receiver). In both cases,
the automaton evolves back to the initial location.
The Sender automaton gets a message to send from its environment; it
then passes the message to the Medium by performing the send action. The au-
tomaton then waits for an acknowledgement, which it either receives (through
the action receiveAck) or it times out and resends the message.
8.2.2 Parallel Composition
8.2.2.1 Basic Notation
Notice in Figure 8.1 that we are using binary synchronisation in our networks
of CAs. Thus, we are taking inspiration from CCS and assuming that each
interaction involves only two automata. Consequently, we distinguish between
instances of half actions, indicated by the symbols ! and ?, and completed
actions, denoted without input/output annotations.
In this notation, ! marks an output synchronisation and ? an input syn-
chronisation.2 Although, it is important to realise that we are using these
symbols here in a diﬀerent way from their use in full LOTOS (and indeed
CSP). Thus, in our network of CAs notation, ! and ? are not denoting data
passing communication attributes, as they do in full LOTOS and CSP. In-
deed, the variety of networks that we consider in this book do not support
data passing communication.
Many of the diﬀerent parallel composition strategies considered in the
process calculus setting could be applied between component automata. One
reason for focusing on binary synchronisation is that it is used in the timed
automata notation, which we are working up to introducing (and which we
present in Chapter 11).
Perhaps the most signiﬁcant diﬀerence between parallel composition in the
networks of CAs and process calculus setting is that the former is typically
deﬁned over a vector of component automata, rather than as a binary op-
erator. Thus, the main semantic mapping applied to networks of CAs is the
generation of a single automaton from a vector of interacting component au-
tomata. This single automaton characterises the global behaviour that results
from running the component automata in parallel. The automaton that arises
from this parallel composition is called the product automaton, because its
locations are generated from the Cartesian product of the component loca-
tions.
In fact, the focus on a vector of components is another reason why binary
synchronisation is often employed in communicating automata. For example,
LOTOS-style multiway synchronisation is more naturally applied as a com-
positional binary operator, rather than over a vector of components.
2These are distinguished with overlining in CCS.

8.2 Networks of Communicating Automata
237
8.2.2.2 Formal Deﬁnition
In order to deﬁne parallel composition over the vector of automata, we need
some notation. CAct is a set of completed (or internal) actions. HAct =
{ x?, x! | x ∈CAct } is a set of half (or uncompleted) actions. These give
a simple CCS-style [148] point-to-point communication similar, for example,
to the synchronisation primitives found in Uppaal [16]. Thus, two actions, x?
and x! can synchronise and generate a completed action x. Act = HAct ∪CAct
is the set of all actions.
Network of Communicating Automata. Networks are intended to model
closed systems, that is, systems where synchronisation is deﬁned solely in
terms of their components. Thus, the term closed here refers to the fact that
the interaction between the system and the environment is not modelled, or
equivalently, where the environment is modelled as another component (i.e.
every possible interaction is known at design-time). This is an important dis-
tinction between automata and process calculi; processes may specify inter-
actions with the environment, without necessarily modelling the environment
itself (in this sense, process calculi model open systems).
Formally, a network of CAs is modelled by a vector of automata denoted
|A = |⟨A1, . . . , An⟩, where, for 1 ≤i ≤n, Ai = (Li, TLi, Ti, li,0) is a commu-
nicating automaton and TLi ⊆Act.
Note, we write s ≤k ̸= r ≤t in place of s ≤k ≤t ∧s ≤r ≤t ∧k ̸= r;
and denote (l, a, l′) ∈Ti as l
a
−→i l′. In addition, we let u, u′ etc. range over
the set of location vectors L1 × · · · × Ln, which are written, ⟨u1, . . . , un⟩. We
use a substitution notation as follows,
⟨u1, . . . , uj, . . . , un⟩[l →j] = ⟨u1, . . . , uj−1, l, uj+1, . . . , un⟩
and we write
u[l1 →i1] . . . [lm →im]
as
u[l1 →i1, . . . , lm →im]
Product Automaton. The product automaton, which characterises the be-
haviour of |A, is given by
Π = (L, TL, T, l0)
where
•
L = { l0 } ∪{ u′ | ∃u ∈L, a . u
a
−→u′ };
•
l0 = ⟨l1,0, . . . , ln,0⟩;
•
TL =
n
i=1
TLi; and

238
8 Communicating Automata
•
T is as deﬁned by the following two inference rules (1 ≤i ̸= j ≤n),
(R1) ui
x?
−−→i l uj
x!
−−→j l′
u
x
−−→u[l →i, l′ →j]
(R2) ui
x
−−→i l x ∈CAct
u
x
−−→u[l →i]
Thus, the locations of the product automaton are vectors of component lo-
cations, which are reachable from the initial location of the product. The
recursive nature of the deﬁnition of L and its use of the product transition
relation (
a
−→) ensures that only reachable locations are included.
In addition, the two inference rules determine the transitions between
product locations. The ﬁrst rule (R1) governs when the product can perform
a synchronised transition, which two of the component automata interact in
performing. Thus, if the product reaches a location in which two components
oﬀer matching half actions (x? and x! in the inference rule), then the prod-
uct can perform the corresponding completed action (x above).3 As a result,
the product moves to a new vector of locations in which the locations of the
synchronising components have both moved accordingly.
The second rule (R2) deﬁnes independent parallel execution in the prod-
uct. Thus, completed actions in components are performed independently of
any other transition and the corresponding component automaton moves on
accordingly in the product.
It should be apparent that these rules follow a similar pattern to the LO-
TOS parallel composition operational semantics discussed in Section 3.3.2.2.
Speciﬁcally, the synchronisation rule (R1) plays the role of (PA.iii) in the LO-
TOS semantics and the independent parallel execution rule (R2) plays the
role of rules (PA.i) and (PA.ii) in the LOTOS semantics.
As an illustration of this product construction, consider the example in
Figure 8.2. Fragments of each of the two components of the communication
protocol shown in Figure 8.1 are highlighted to the left of the Figure. These
fragments have been extracted from the Figure 8.1 components by removing
all half actions that synchronise with components other than the sender and
medium.
The resulting product automaton (denoted |⟨Sender ′, Medium′⟩) is shown
to the right of Figure 8.2. Because it characterises the global behaviour of
the network, the product only contains completed actions. Furthermore, the
product reﬂects the expected emergent behaviour of the network. Thus, the
rather degenerate behaviour of the product is for a message to be sent, followed
by an interleaving of the message being lost at the medium and the sender
timing out. This sequence is repeated ad inﬁnitum.
3Note that, as is in fact also the case with CCS demarcation of half actions using
overlining, because nothing is actually transmitted over the communication channel,
the directionality of communication here is rather artiﬁcial. Despite this, we describe
half actions annotated ! as output and ? as input.

8.2 Networks of Communicating Automata
239
send!
send!
timeout
Sender’
1
2
3
send?
lose
Medium’
a
b
send
timeout
send
timeout
lose
lose
<2,b>
<2,a>
<3,b>
<3,a>
<1,a>
|<Sender’,Medium’>
Fig. 8.2. Product Automaton Example
8.2.3 Example Speciﬁcations
As an illustration of networks of CAs, we present the full (nondata passing
version of the) communication protocol example, as presented for LOTOS in
Section 2.4. This full speciﬁcation is shown in Figure 8.3. We must observe
that the network is not complete: an Environment automaton (not shown in
the Figure), which provides the get! and put? actions, is also assumed to be a
component of the network.
The components, over and above those presented in Figure 8.1, are a reli-
able acknowledgement medium (AckMedium), which relays acknowledgements
from the receiver back to the sender, and a receiver, which receives messages
(action receive?), passes them to the environment (action put!) and then sends
an acknowledgement (action sendAck!).

240
8 Communicating Automata
Medium
send?
receive!
Sender
get?
receiveAck?
send!
send!
AckMedium
sendAck?
receiveAck!
receive?
put!
sendAck!
Receiver
timeout
lose
Fig. 8.3. Communication Protocol Example as a Network of CAs
8.2.4 Semantics and Development Relations
Labelled transition systems are the standard semantics for networks of CAs.
This is consistent with the dominant role that transition systems semantics
also play in process calculi. Indeed, due to the close relationship between au-
tomata and transition systems, the product automata generation rules, which
we highlighted in Section 8.2.2.2, eﬀectively play the role of a semantic map
for networks of CAs. Furthermore, the labelled transition systems generated in
this way play a central role in veriﬁcation methods. For example, bisimulation
equivalences can be applied directly over product automata.
However, it should also be noted that, although not typically explored, it
is easy to map to semantic models other than labelled transition systems. For
example, trace semantics and trace-refusals semantics can both be straight-
forwardly generated from networks of CAs, via the product automata; the
mappings considered in Sections 3.3.2.3 and 5.1.2 could be used for this pur-
pose. In addition, true concurrency semantics could be generated in two steps.
Firstly, the network of CAs to process calculi mapping, considered in Sec-
tion 8.2.6, could be applied and then, secondly, a process calculus to event
structures mapping could be applied.
Finally, and to complete the overview of CA semantics, we must mention
that a general liveness hypothesis is implicitly assumed in CA models: at

8.2 Networks of Communicating Automata
241
any given state, some enabled action will always eventually be taken. More
formally, a path in the labelled transition system represents a valid (complete)
system execution only if either (a) it is inﬁnite or (b) it is ﬁnite and there is
no enabled transition in its last state (i.e. a deadlock state).
This liveness hypothesis represents a typical communicating automata in-
terpretation for system executions (also called computations; see e.g. [136]).
Although we do not discuss this topic any further, in principle, CA models
could also be augmented with fairness conditions. For example, a common
way [136] to add fairness conditions to labelled transition systems, is to mark
certain transitions as “just” or “compassionate”. Inﬁnite paths in the labelled
transition system will not be considered valid executions if just transitions
are continuously enabled without being eventually taken, or if compassion-
ate transitions are enabled inﬁnitely often, but taken only a ﬁnite number of
times (an overview of fair transition systems [136] is given in Section 13.2.1).
The model-checker SMV4 is a good example of how fairness is dealt with in
practice; in SMV, the user may specify fairness assumptions as part of the
model.
8.2.5 Veriﬁcation of Networks of Communicating Automata
Eﬃcient veriﬁcation of networks of CAs (in their practical incarnations) can
be achieved through model-checking: correctness requirements are expressed
as formulae in some temporal logic, and, typically, an algorithm is run on the
product automaton, which checks whether the property is satisﬁed. Depending
on the formula, model-checkers might also return a justiﬁcation for their an-
swers, typically in the form of a sequence of states validating (or invalidating)
the veriﬁed property.
This informal description of model-checking corresponds to the most
widespread veriﬁcation technique for ﬁnite-state systems. In practice, most
model-checkers choose either CTL (Computation Tree Logic) [57,58] or LTL
(Linear Time Temporal Logic) [128, 136, 162] as property speciﬁcation lan-
guages (or some variants of these temporal logics).
This section discusses, brieﬂy, the main features of CTL and the basics of
CTL-based model-checking. We refer the reader interested in LTL and LTL-
based model-checking to [128] and [97].5 Vardi [194] compares CTL and LTL
on a number of technical grounds, including the expressiveness of the logics
as property speciﬁcation languages, and the eﬃciency of the related model-
checking algorithms.
8.2.5.1 Computation Tree Logic (CTL)
Informally, CTL formulae can be seen as statements about system executions.
4http://www-2.cs.cmu.edu/∼modelcheck/smv.html
5See also the SPIN site at http://spinroot.com/spin/whatispin.html

242
8 Communicating Automata
•
States of interest can be characterised by atomic propositions and logical
connectives. For example, and with respect to the network of CAs shown in
Figure 8.2, the formula SL1 ∨SL3 ⇒MLa denotes a set of states in which
Medium′ is in location a (prop. MLa) whenever Sender′ is either in location
1 or 3 (props. SL1 and SL3). Clearly, more interesting characterisations
can be obtained in richer automata models, e.g. those which include shared
variables.
•
The sequencing of states in a particular execution can be seen as a temporal
ordering of events, and thus can be characterised by temporal operators.
For example, the CTL formula Gφ denotes an execution in which every
state satisﬁes the formula φ.
•
Properties of interest might range over all or just some of the system
executions; hence, CTL includes operators which quantify over the set of
possible executions. For example, the CTL formula Aφ denotes a system
in which φ is satisﬁed on all possible executions.
In consequence, many interesting properties can be naturally expressed in
CTL. For example, a possible correctness requirement for the system of Fig-
ure 8.2 may state that Sender′ is always allowed to send packets. This is the
same as saying that whenever a send! action is enabled in Sender′, a send?
action is also enabled in Medium′. This can be expressed in CTL as
AG(SL1 ∨SL3 ⇒MLa)
Notice that SL1 ∨SL3 ⇒MLa characterises exactly the set of states where
action send? in Medium′ is enabled, provided any of the two send! actions in
Sender′ is also enabled.
Syntax. A CTL formula φstate is typically given in the following syntax
(where p is an atomic proposition),
φstate ::= p | ¬φstate | φstate ∧φstate | {A, E}φpath
φpath ::= φstate | {F, G}φstate
We also assume the usual logical connectives (∨, ⇒, etc.) and tautologies.
Other important operators, not considered here, include X (next) and U until
(see e.g. [58] for a complete presentation). Notice that “temporal operators”,
F and G, can only occur under the immediate scope of a “path quantiﬁer”, A
or E. Simple examples of CTL formulae include EFp and AG(p ⇒EFq), where
p and q are atomic propositions.
Semantics. CTL is a logic interpreted on Kripke structures, essentially, ﬁnite-
state automata of the form (S, T, P, M, s0), where
•
S is a ﬁnite set of states (and s0 ∈S the initial state);
•
T ⊆S × S is a transition relation, which is total on S; i.e. for every s ∈S
there exists s′ ∈S s.t. (s, s′) ∈T;

8.2 Networks of Communicating Automata
243
•
P is a ﬁnite set of atomic propositions; and
•
M : S →P(P) is a mapping which relates every state in the automaton
with a valuation for propositions in P. Equivalently, M can be seen as
relating every state with a subset of P, which includes only those atomic
propositions which are considered true in that state.
A Kripke structure can be unfolded into an inﬁnite tree (called a computation
tree) where every state in the structure corresponds to at least one node in
the tree (with the initial state being the root), and every path in the tree
corresponds to the inﬁnite traversal of consecutive transitions. Because the
transition relation is total, every state in the Kripke structure has at least one
outgoing transition, which guarantees the existence of inﬁnite paths in the
computation tree. This unfolding is illustrated in Figure 8.4, where the initial
state is distinguished with a double circle.
It is not diﬃcult to see that a mapping between networks of CAs and
Kripke structures (and correspondingly, computation trees) can be readily
obtained. Eﬀectively, a product automaton, Π = (L, TL, TΠ, l0), can be in-
terpreted as a Kripke structure K = (S, TK, P, M, s0), where
•
S = L (and s0 = l0);
•
TK = { (l, l′) | l
a
−→Πl′ } ∪{ (l, l) | ∄a ∈TL, l′ ∈L . l
a
−→Πl′ }
This states that labels in the product transitions are disregarded; and that
locations in the product with no outgoing transitions result in reﬂexive
states in the Kripke structure (this ensures that TK is total on S).
•
P and M can be arbitrarily deﬁned; they usually depend on the application
domain (i.e. the interpretation of states and transitions of the network of
CAs) and the properties to be veriﬁed.
{a,b}
{a}
{b}
{b}
{b}
{a,b}
{b}
{b}
{a}
{a}
Kripke structure
Computation tree
{a,b}
* * *
* * *
* * *
Fig. 8.4. A Kripke Structure and Its Related Computation Tree (Fragment)
The satisﬁability of a CTL formula is deﬁned with respect to a given state
s in a computation tree. Path quantiﬁers A and E refer to all paths, or some

244
8 Communicating Automata
path starting at s, respectively. Temporal operators G and F refer to all states,
or some state in a given path, respectively. Finally, propositional formulae are
interpreted over the valuation which deﬁnes a particular state. For example,
the formula EFp will be satisﬁed in a state s where there exists at least one
path starting from s (E), which contains at least one state (F) where p holds.
Similarly, the more interesting AG(p ⇒EFq) is satisﬁable at s if in every state
s′, which satisﬁes p, of every possible path starting at s, there exists at least
one path starting at s′ along which some state satisﬁes q.
By way of example, Figure 8.5 illustrates the satisﬁability of EFφ, AGφ, EGφ
and AFφ, over computation trees. In these, we assume that the uppermost node
is the root, that black nodes denote states satisfying the CTL formula φ and
that dashed lines denote repetition in the tree structure.
(i)
(ii)
(iii)
(iv)
Fig. 8.5. Fragments of Computation Trees, (i) EFφ, (ii) AGφ, (iii) EGφ, (iv) AFφ
Notice that a temporal interpretation can be given to CTL formulae, if we
consider that a sequence of states represents the evolution of a system in time.
According to this view, then, the formula EFp can be said to be satisﬁable in s
if there exists a possible execution of the system in which, eventually, a state
where p holds can be reached.
Table 8.1 gives formal semantics for CTL operators. We assume a Kripke
structure K = (S, T, P, M, s0), and C the computation tree arising from K;
s ∈S denotes a node in C; σ ≜σ0σ1σ2 . . . , an inﬁnite path in C (not
necessarily starting at the root) where σi ∈S, i ≥0 and σ0 ∈S is the initial
state of the path. We use p ∈s, where p ∈P, to denote that p is true in s with
respect to M. CTL formulae are state formulae, φstate, and are interpreted
over a pair (K, s). Correspondingly, path formulae φpath are interpreted over
a pair (K, σ). We use |= to denote both the satisﬁability relations for state
and path formulae.
Correctness Properties as CTL Formulae. CTL formulae can be classi-
ﬁed according to the kind of correctness properties they can express. Typically
(see e.g. [14]), the literature distinguishes among the following.

8.2 Networks of Communicating Automata
245
(K, s)
|= p
iﬀp ∈s
(K, s)
|= ¬φstate
iﬀ(K, s) ̸|= φstate
(K, s)
|= φstate ∧φ′
state
iﬀ(K, s) |= φstate and (K, s) |= φ′
state
(K, s)
|= Eφpath
iﬀexists σ s.t. σ0 = s and (K, σ) |= φpath
(K, s)
|= Aφpath
iﬀfor all σ s.t. σ0 = s, (K, σ) |= φpath
(K, σ) |= φstate
iﬀ(K, σ0) |= φstate
(K, σ) |= Fφstate
iﬀexists σi, i ≥0, s.t. (K, σi) |= φstate
(K, σ) |= Gφstate
iﬀfor all σi, i ≥0, (K, σi) |= φstate
Table 8.1. Semantics of CTL Formulae
•
Reachability properties are usually expressed as a CTL formula of the form
EFφ. This formula states that a certain event of interest (characterised by
φ) may eventually occur, i.e. is reachable.
•
Safety properties are typically of the form AG¬φ. This formula states that
an error-state (characterised by φ) is never reached.
•
Liveness properties (other than reachability) express, in general, that some
event will always eventually occur. It is common to ﬁnd liveness expressed
by CTL formulae such as AGEFφ or AG(φ ⇒EFψ), where φ and ψ usually
denote propositional formulae.
A reachability property of interest in the system shown in Figure 8.2, may
state that a timeout is possible. This can be expressed as EFSL3; we recall
that SL3 is a proposition denoting that Sender′ is currently in location 3. We
have already seen an example of a safety property, AG (SL1 ∨SL3 ⇒MLa),
which states that Sender′ is always allowed to send messages to Medium′.
Equivalently, the property states that Sender′ is never prevented from sending
the messages; i.e.,
AG¬((SL1 ∨SL3) ∧¬MLa)
Safety properties can be expressed as reachability properties, because CTL
operators A and E, and F and G, are duals.6 Following the previous example,
the safety property in question can be expressed in terms of reachability,
¬EF((SL1 ∨SL3) ∧¬MLa)
which denotes that a state where a send! action is enabled, and a send? action
is not, cannot be reached. As for examples of liveness properties, consider the
following.
•
The property which states that Sender′ will always eventually attempt to
send messages, can be expressed as AGEF(SL1 ∨SL3); i.e. a state is always
eventually reached in which some send! action in Sender′ is enabled.
6Aφ and ¬E¬φ are logically equivalent, and so are Gφ and ¬F¬φ.

246
8 Communicating Automata
•
The property which states that every time after a timeout occurs a packet
is eventually sent (at least to Medium′, can be expressed as AG(SL3 ⇒
AFSL2).
8.2.5.2 Model-checking CTL
Although, in practice, much more eﬃcient algorithms have been implemented
(e.g. [140]), CTL model-checking can be conceptually described in terms of a
labelling procedure which works on Kripke structures [58].
Given a system represented as a Kripke structure K = (S, T, P, M, s0),
and a correctness property expressed as a CTL formula φ, we can state the
model-checking problem as a search for those states in S which satisfy φ. If
s0 ∈S represents the system’s initial state, then the system satisﬁes φ if φ
is satisﬁed at s0. This search can be performed in many ways. Consider, for
example, a procedure which labels each state s ∈S with the set of subformulae
of φ (which are themselves state formulae) that are satisﬁed in s. Let label(s)
be such a set. Then, the set of states which satisfy φ is given by
{ s ∈S | φ ∈label(s) }
The labelling procedure can be thought of as working in stages. Initially, and
for every s ∈S, label(s) is just the set of propositions which are true in s;
then states are labelled according to subformulae in φ until eventually φ is
processed. As the satisﬁability of a CTL formula φ can be deﬁned in terms of
the satisﬁability of its subformulae (see table 8.1), the labelling of states with
respect to φ can be deﬁned in terms of a labelling with respect to subformulae
of φ.
To illustrate this procedure, Figure 8.6 sketches a possible implementation
for the labelling of EFφ on the states of K, where φ is a CTL formula. The
function labelEF(φ, s, Visited) will label all states in S with respect to EFφ,
assuming that,
•
K is strongly connected;
•
Successors(s) = { s′ | (s, s′) ∈T };
•
φ has been “marked” already; i.e. for every state s ∈S, φ ∈label(s) if and
only if φ has been found to be satisﬁable in s; and
•
initially, Visited = ∅and s = s0.
8.2.6 Relationship to Process Calculi
8.2.6.1 Encoding Networks of CAs into Process Calculi
Networks of CAs can be viewed as a specialisation of process calculi and they
can be encoded into the sort of notation we discussed in Chapters 2 and 7.

8.2 Networks of Communicating Automata
247
Function labelEF(φ, s, Visited)
begin
Visited ←Visited ∪{ s };
if φ ∈label(s) then
label(s) ←label(s) ∪{ EFφ };
else
for all s′ ∈Successors(s), s′ /∈Visited do
labelEF(φ, s′, Visited);
end for
if ∃s′ ∈Successors(s) . EFφ ∈label(s′) then
label(s) ←label(s) ∪{ EFφ };
end if
end if
return;
end.
Fig. 8.6. Model-checking CTL: The Labelling of EFφ Formulae.
However, in general, process calculi are too expressive to be encoded into
networks of CAs.
As an initial illustration, we consider a mapping,
∆1 : CommsAut −→pbLOTOS,
from product automata to pbLOTOS speciﬁcations, which is deﬁned as fol-
lows.
1. Given an automaton A = (L,TL, T, l0), we assume n is the cardinality of
L and we introduce n process identiﬁers indexed by locations in L, each
denoted Pl for l ∈L.
2. For all l, l′ ∈L, deﬁne,
Pl := []{ x; Pl′ | l
x
−−→l′ }
where
[]{ E1 , . . . , Er } = E1 [] . . . [] Er
3. Now, Pl0 is the top-level pbLOTOS behaviour corresponding to the initial
location of the product automaton.
However, the ∆1 mapping requires transitions to be labelled with completed
actions. In particular, the disparity in communication mechanisms (binary
communication vs. multiway synchronisation), prevents us from being able to
give a compositional transformation of networks of CAs into LOTOS. How-
ever, we can give such a compositional mapping if the target of the translation
is a CCS-style calculus; remember, CCS employs a binary synchronisation
mechanism very similar to that employed in our networks of CAs. In fact,
the CCS dialect we map to is slightly nonstandard, in the sense that com-
pleted actions (as characterised by the set CAct) play the role of internal,

248
8 Communicating Automata
τ, actions (as classically used in CCS). We denote the completed actions xτ
(where x ∈CAct) in this CCS variant, which we call CCS CAct.
Thus, we consider a compositional mapping,
∆2 : CommsAut −→CCS CAct,
which is deﬁned as follows.
1. Given a vector |⟨A1 , . . . , Am ⟩of component automata, where Ai =
(Li,TLi, Ti, l0,i) for 1 ≤i ≤m and ni is the cardinality of Li. For each
i (1 ≤i ≤m) we assume ni process identiﬁers indexed by locations in Li,
each denoted Xi,l for l ∈Li.
2. For all i (1 ≤i ≤m), l, l′ ∈Li, let,
Xi,l
def
= Σ { α(a). Xi,l′ | l
a
−→i l′ }
where
Σ { E1 , . . . , Er } =
Σ
j (1≤j≤r) Ej
and, for x ∈CAct,
α(x?) = x
α(x!) = x
α(x) = xτ
3. Xi,l0,i gives the top-level behaviour of the CCS CAct agent corresponding
to the ith component automaton.
4. Finally, the following deﬁnes a process variable, X, which is the top-level
CCS CAct agent corresponding to running the network of CAs in parallel.
X
def
= ( ΠCAct
i (1≤i≤m) Xi,l0,i )\CAct (
m
i=1
TLi)
where ΠCAct enforces the usual CCS generalised parallel composition,
with the one alteration being that synchronisation generates the corre-
sponding completed action, rather than τ, and A\CAct G enforces the
usual CCS restriction, with one alteration being that only half actions are
restricted (and, it is important to note, completed actions are not).
Thus, X runs the agents generated from each component automaton in
parallel. In addition, CCS CAct parallel composition ensures that matching
half actions synchronise and restriction removes branches from leftover
instances of half actions.
Although we do not provide a formal proof to justify the statement, it should
be clear that, through ∆2, networks of CAs can be compositionally encoded
into process calculi.
8.2.6.2 Comparing Communicating Automata Networks and
Process Calculi
Although communicating automata networks are an elegant (and simple)
model of concurrent systems, they are expressively limited when compared

8.2 Networks of Communicating Automata
249
with process calculi. In particular, they only oﬀer one level of parallel com-
ponents. Consequently, it is typically more diﬃcult to describe large systems
in networks of CAs than in process calculi. In particular, with process cal-
culi, a decompositional strategy of system speciﬁcation can be employed, in
which complex systems can be incrementally described. That is, the system
developer can focus on specifying a part of the entire system, then she can
hide all internal behaviour and wrap that part of the system up as a process,
which can be composed with other parts of the system at the next level of de-
compositional structure. In addition, processes (and thus, arbitrarily complex
behaviour) can be nested to any arbitrary depth.
This is a serious limitation of networks of CAs. However, these expres-
siveness limitations are often accepted, because veriﬁcation of such restricted
notations is more straightforward than for arbitrary process calculi. For ex-
ample, this is one of the reasons for the widespread use of networks of CAs in
the timed model-checking domain; see Section 11.3.
In addition, it is worth noting that, although not considered here, data
typing primitives could be added to networks of CAs, to yield a more pow-
erful speciﬁcation notation. In particular, data passing could be associated
with networks of CAs in a similar manner to that employed in fLOTOS. In
fact, Section 11.2 discusses timed automata, which have an expressive data
notation in their most mature practical incarnation: the Uppaal speciﬁcation
language [16]. Although, because Uppaal employs shared data variables, it
does not include data passing in the basic communication primitives.
State-based and Action-based Formalisms. We can also compare com-
municating automata and process calculi from the perspective of state-based
and action-based formalisms. Process calculi are usually considered to be
action-based formalisms in the sense that actions play the most important
role in the representation of both the system behaviour and the correctness
requirements of interest. For example, we have seen that LOTOS speciﬁca-
tions are interpreted over sequences of actions (i.e. semantics are usually given
in terms of LTSs, traces, etc.), but states are regarded as subordinated to ac-
tions, in the sense that they simply denote a stage in the behaviour of the
system, which lies between the execution of two consecutive actions. From an-
other point of view, states can also be considered as black boxes which carry
no visible structure or relevant information about the system behaviour, and
so one can argue that states are “indistinguishable”, where one can only ob-
serve (and given the whole execution context) the sequences of actions which
led to them, and those which may possibly follow from them.
Action-based formalisms have also encouraged a veriﬁcation method where
correctness is stated operationally, and one is usually interested in determining
whether the behaviour of two systems is equivalent according to some devel-
opment relation (where the second system describes the “correct” behaviours
the ﬁrst system can perform). For example, the CADP tool is able to check,
given two LOTOS speciﬁcations, whether a bisimulation exists between them.

250
8 Communicating Automata
This is in contrast to state-based formalisms, such as communicating au-
tomata. Here (and even more so in CA models augmented with shared vari-
ables), the behaviour of a system is interpreted in terms of sequences of states
which carry the relevant information, e.g. the current location in the automa-
ton and a valuation for its variables. Thus, states have a certain structure
and are distinguishable, deﬁning precisely those points in system execution
where the system can be observed. Actions, on the other hand, are viewed
mostly as the means by which diﬀerent states in execution can be reached.
Consequently, veriﬁcation is concerned with states and sequencing of interest-
ing states in a given execution; these elements are the building blocks in the
speciﬁcation of correctness properties as temporal logic formulae (e.g. in CTL
and LTL).
To conclude, let us mention that choosing either an action-based or a state-
based model depends on the system at hand, and the type of properties we
are interested in verifying. Also, and in particular for complex systems, it is
usually the case that both viewpoints are necessary, and so they complement
each other. For example, it may be the case that the system in question is
more naturally modelled in terms of networks of CAs, but some correctness
requirements are better expressed in terms of actions rather than states. In
addition, we must point out that veriﬁcation methods are not, per se, exclusive
to one type of formalism or another. For example, determining the existence
of a bisimulation between two CAs is a common practice to verify correctness;
on the other hand, LOTOS speciﬁcations can be model-checked in CADP with
respect to properties written in the µ-Calculus logic [112].
8.3 Inﬁnite State Communicating Automata
Communicating automata (in their many incarnations) stand, probably, as
the most widely used formal methods for the speciﬁcation of concurrent sys-
tems. Despite their limitations in expressiveness (and to a great extent, thanks
to these limitations), communicating automata allow for eﬃcient, exhaustive
veriﬁcation of systems. As we have seen, an automatic veriﬁcation technique,
such as model-checking, is made possible because the state-space is ﬁnite.
Nevertheless, many systems of interest cannot be model-checked, because
no ﬁnite state-space abstraction can be obtained for them. This inﬁnite state
behaviour is common in systems where data play a central role (and so the
speciﬁcation language must deal with inﬁnite domains of some sort). For ex-
ample, this is commonly found in the veriﬁcation of software or parameterised
communication protocols, to name just two.
Many frameworks have been proposed to deal with inﬁnite state systems,
and the literature on the topic is very rich (e.g. see the prominent work of
Manna and Pnueli on transition systems and LTL [136,137], and Lynch et al.
on I/O automata [132, 133]). The main disadvantage of inﬁnite state frame-
works has been, traditionally, the expertise required in the veriﬁcation process.

8.3 Inﬁnite State Communicating Automata
251
The expressiveness of these notations is such that veriﬁcation must be per-
formed in the form of deductive proofs, where theorem provers provide the
(semi automatic) tool support.
This section presents an abstract notation, named Inﬁnite State Commu-
nicating Automata (ISCAs), which embodies many of the principles found in
this area. In addition, the reason for introducing this notation here is similar
to that which we oﬀered for communicating automata: ISCAs are a good start-
ing point to understand discrete timed automata (Chapter 13), a notation for
(inﬁnite state) timed systems.
We hope this gives the reader a good idea about how inﬁnite state sys-
tems can be speciﬁed, without burdening them too much with technical details
(which are, in most cases, particular to each notation). Having said that, by
all means the reader is encouraged to consult the bibliography and compare
between diﬀerent frameworks (e.g. Manna and Pnueli’s fair transition sys-
tems [136], and Lynch and Tuttle’s I/O automata [132]), and their related
veriﬁcation techniques.
8.3.1 Networks of Inﬁnite State Communicating Automata
In this model, systems are described by a network where the components
are inﬁnite state communicating automata. As for communicating automata,
there is only one level of such components, and networks of ISCAs repre-
sent closed systems (synchronisation is speciﬁed only among the network’s
components).
8.3.1.1 Component Automata
Let the sets CAct, HAct and Act be deﬁned as in Section 8.2.2.2. An inﬁnite
state communicating automaton is a tuple A = (V, Θ, TL, A), where
•
V is a ﬁnite set of variables;
•
Θ is a formula in ﬁrst-order language (FOL), which denotes the initial
valuation for variables in V ;
•
TL ⊆Act is a set of action labels; and
•
A is a ﬁnite set of actions with labels in TL .
Actions in A are triples7, (a, p, e), where a ∈TL is the action’s label, p (the
action’s precondition) is a FOL-formula on variables in V , and e (the action’s
eﬀect) is a FOL-formula on variables in V and their primed versions. The
precondition denotes a set of possible valuations which enable the action; in
other words it represents a set of states where the action may be performed.
7Notice, in contrast with the meaning assigned in process calculi, that here ac-
tions have a structure (a label, a precondition and an eﬀect). This is a direct conse-
quence of the notation being state-based: actions explicitly denote how the state of
a system evolves during execution.

252
8 Communicating Automata
The eﬀect denotes the valuation which results after the action has been taken
(denoted by valuations of primed variables). Although more general forms can
be given, we adopt a simple deterministic behaviour for actions; i.e. actions,
when performed, will always result in single next state (e.g. as in [136]). Let e
be an eﬀect formula, and V ′(e) ⊆V be the set of variables modiﬁed by e (i.e.
those whose valuations change as the result of performing the corresponding
action). Then, e has the form,
e ≜

v∈V ′(e)
v′ = EV
where EV is an expression on variables in V . Notice that any variable not in
V ′(e) is assumed unchanged when the corresponding action is performed. In
other words, the above expression for e is a shorthand for
e ≜

v∈V ′(e)
v′ = EV ∧

y∈V \V ′(e)
y′ = y
Binary synchronisation between automata (as in ﬁnite state communicating
automata) will be achieved by partitioning A into sets of completed (or inter-
nal), input and output actions; that is,
A = COMP(A) ∪IN (A) ∪OUT(A)
Completed, input and output actions will be labelled with a ∈CAct,
x?, x! ∈HAct, respectively. Collectively, input and output actions can be
thought of as the half actions of the model (with a similar role as that in
Communicating Automata). Note, also, that more than one action in the
same partition (completed, input or output actions) may share labels. This
allows the representation of actions which have diﬀerent eﬀects depending on
the state where they are enabled. In the following deﬁnitions, we may refer
to actions simply by their labels. For example, we use x? ∈A to denote any
input action (x?, p, e) ∈IN (A).
Figure 8.7 illustrates a network of component automata (ISCAs) corre-
sponding to (a fragment of) the communication protocol example of Fig-
ure 8.2.
8.3.1.2 Parallel Composition
Here we follow the synchronisation model of communicating automata (Sec-
tion 8.2.2.2). For any given network, parallel composition results in a product
automaton that represents the semantics of the network. By construction
(and well-formedness of the network), this product automaton contains just
completed actions. These concepts (both networks of ISCAs and product au-
tomaton) are formalised by the following deﬁnitions.

8.3 Inﬁnite State Communicating Automata
253
Network: |⟨Sender′,Medium′⟩
ISCA: Sender′
V : SenderState ∈{1, 2, 3}
Θ : SenderState = 1
TL = {send!, timeout}
A : send!
prec: SenderState = 1
eﬀ:
SenderState′ = 2
timeout
prec: SenderState = 2
eﬀ:
SenderState′ = 3
send!
prec: SenderState = 3
eﬀ:
SenderState′ = 2
ISCA: Medium′
V : MediumState ∈{a, b}
Θ : MediumState = a
TL = {send?, lose}
A : send?
prec: MediumState = a
eﬀ:
MediumState′ = b
lose
prec: MediumState = b
eﬀ:
MediumState′ = a
Fig. 8.7. Example Inﬁnite State Communicating Automata
Network of Inﬁnite State Communicating Automata. A network of
ISCAs is a vector of components |A = ⟨A1, . . . , An⟩, where, for 1 ≤i ≤n,
Ai = (Vi, Θi, TLi, Ai) is an ISCA. A network is well-formed if both variables
and completed actions are local to components; that is,
∀i, j (1 ≤i ̸= j ≤n) , Vi ∩Vj = ∅
∀i, j (1 ≤i ̸= j ≤n) , COMP(Ai) ∩Aj = ∅
Product Automaton. Let |A = ⟨A1, ... , An⟩be a network of ISCAs, where
Ai = (Vi, Θi, TLi, Ai), for 1 ≤i ≤n. The product automaton, which results
from the parallel composition of the network’s components, is given by
Π = (V, Θ, TL, A)
where
•
V =
n
i=1
Vi;

254
8 Communicating Automata
•
Θ =
n
i=1
Θi;
•
TL = (CAct ∩
n
i=1
TLi) ∪{ x | ∃x? ∈TLi , x! ∈TLj . 1 ≤i ̸= j ≤n }; and
•
COMP(A) =
n
i=1
COMP(Ai) ∪
{ (x, p, e) | ∃i, j (1 ≤i ̸= j ≤n) .
(x?, pi, ei) ∈IN (Ai) ∧(x!, pj, ej) ∈OUT(Aj) ∧
(p ≜pi ∧pj) ∧
(e ≜ei ∧ej) }
•
IN (A) = OUT(A) = ∅
Notice that all actions in the product automaton are completed, where syn-
chronisation has been resolved by producing one completed action from every
two matching input/output actions in the components. By way of example,
Figure 8.8 shows the product automaton corresponding to the network of
Figure 8.7. In particular, observe that the automaton includes two completed
actions send, each one representing a possible synchronisation between one of
the send!s in Sender and the send? action in Medium (see Figure 8.7 again),
but just one timeout and one lose.
This is worth comparing with the product automaton in the CA setting
(Figure 8.2), where the interleaving between these two completed actions is
explicit. Unlike in communicating automata, the interleaving of completed
actions in the ISCA setting does not cause an explosion in the size of the re-
sulting product automaton. This is so because preconditions implicitly model
a set of states; for example, the precondition of the timeout action denotes
that this action is only enabled in those states where SenderState = 2, but it
does not specify what the value of MediumState is. Consequently, timeout is
enabled both in states,
s1 = (SenderState = 2, MediumState = a) and
s2 = (SenderState = 2, MediumState = b)
On the other hand, and in order to represent the same information with
ﬁnite state communicating automata, the product automaton in Figure 8.2
must produce two timeout transitions, one for every possible location vector
denoting that Sender′ is in location 2 (that is, vectors ⟨2, a⟩and ⟨2, b⟩).
8.3.2 Semantics of ISCAs as Labelled Transition Systems
The semantics of a network of ISCAs is evident from the product automaton;
nevertheless the distinction between syntax and semantics will acquire more
importance in timed automata notations (both for ﬁnite- and inﬁnite-state
systems). It is interesting, then, to present a formalisation for the semantics
of networks of ISCAs, in terms of labelled transitions systems.

8.3 Inﬁnite State Communicating Automata
255
ISCA: Π
V : SenderState ∈{1, 2, 3}, MediumState ∈{a, b}
Θ : SenderState = 1 ∧MediumState = a
TL = {send, timeout, lose}
A : send
prec: SenderState = 1 ∧MediumState = a
eﬀ:
SenderState′ = 2 ∧MediumState′ = b
send
prec: SenderState = 3 ∧MediumState = a
eﬀ:
SenderState′ = 2 ∧MediumState′ = b
timeout
prec: SenderState = 2
eﬀ:
SenderState′ = 3
lose
prec: MediumState = b
eﬀ:
MediumState′ = a
Fig. 8.8. Communication Protocol - Product Automaton (ISCA).
Let A = (V, Θ, TL, A) be an ISCA where all actions are completed (i.e.
A = COMP(A)). The semantics of A are given by the LTS (S, TL, T, s0),
where
•
S is the state-space deﬁned by all possible valuations for variables in V .
We use JvKs (resp. JEV Ks) to denote the value of the variable v ∈V in
s ∈S (resp. the result of evaluating the expression EV in s).
•
s0 ∈S s.t. s0 |= Θ, is the starting state (for convenience, we assume there
is a unique starting state).
•
T ⊆S × TL × S is the transition relation, where transitions (s, a, s′) ∈T
are denoted s
a
−→s′. The transition relation is deﬁned by the following
rule,
(a, p, e) ∈A s |= p (s, s′) |= e
s
a
−→s′
where s |= φ denotes that s ∈S satisﬁes the formula φ (under FOL
semantics). Similarly, (s, s′) |= e denotes that s′ is the state which results
from s by applying the eﬀect formula e, and where every variable not
modiﬁed by e remains unchanged. Formally, (s, s′) |= e if, for every v ∈V ,
s′ satisﬁes the following.
JvKs′ =
	
JEV Ks if v ∈V ′(e)
JvKs
otherwise
The set of reachable states in any possible execution of A is, then,
Sreach = { s0 } ∪{ s′ | ∃a ∈TL, s ∈Sreach . s
a
−→s′ }

Part IV
Concurrency Theory – Timed Models

259
This part considers the important issue of real-time extensions to concurrency
theory.8 The need for such models was discussed in Section 1.3.
If you consider the historical development of the ﬁeld of timed concurrency
theory, it is clear that, broadly speaking, there were two phases. Initially, from
the mid-1980s to the early 1990s, there was considerable investigation of how
time could be added to the ﬁrst generation of (untimed) process calculi. As
a result, timed extensions of all the major process calculi were explored, e.g.
timed extensions of CCS [167,201], CSP [64,177] and LOTOS [26,59,125,164]
and important new timed calculi were proposed [154]. Due to the algebraic
focus of process calculi there were accompanying explorations of proof systems
for such languages, e.g. [176].
This initial thrust of timed concurrency theory research had great theoreti-
cal value. However, as is also, to some extent, the case in the untimed setting,
the expressive power of the resulting calculi made the search for tractable
veriﬁcation algorithms very diﬃcult. Thus, in the second phase of timed con-
currency theory research, focus was placed on more restricted (communicat-
ing automata-based) notations, for which tractable (region-based) veriﬁca-
tion methods could be developed [7, 13, 16, 91, 189, 202]. Thus, for example,
the resulting timed automata notations typically do not support hierarchical
decomposition of process structure; they oﬀer a ﬂat model of parallel compo-
nents.
The format of this part reﬂects this historical progression of the ﬁeld.
Thus, we begin, in Chapters 9 and 10, by discussing timed extensions of the
process calculus LOTOS. The ﬁrst of these chapters considers mainly syntactic
issues of how time should be added to such a calculus, whereas the second
explores formal semantic interpretations of the resulting timed LOTOS. Both
branching time and true concurrency interpretations are presented. We then
move to considering real-time communicating automata notations in Chapters
11, 12 and 13. Chapter 11 considers a basic timed communicating automata
model and associated region-based model-checking. Chapter 12 considers the
thorny issue of how timelocks should be handled in timed communicating
automata. Then, ﬁnally, Chapter 13 considers a new notation for inﬁnite-state
models of timed communicating automata.
8Notice, the term temporal is often used confusingly in this domain. For exam-
ple, the use of the term in the context Language of Temporal Order Speciﬁcation
(LOTOS) does not imply real-time, but rather, what we called basic event ordering
in Section 1.3.

9
Timed Process Calculi, a LOTOS Perspective
9.1 Introduction
The need to incorporate quantitative time into formal speciﬁcation languages
has been widely recognised. This is essential in order that applications that
are time dependent can be correctly modelled at early stages in system de-
velopment. Typical classes of such applications are communication protocols,
real-time control systems and real-time distributed systems (e.g. multime-
dia applications). A spectrum of classic examples are used to test the ex-
pressiveness of speciﬁcation techniques; typical examples are, the Alternating
Bit Protocol [167], Train Gate examples [175], the Tick Tock Protocol [127],
Dying Dining Philosophers [183] and Lip Synchronisation [21]. A number of
time dependent computation structures arise repeatedly in these examples,
e.g. standard timeouts [167], symmetric timeouts [26], watchdog timers [154],
continuous media (streams) [21] and quality of service constraints [21]. Timed
formal description notations must support speciﬁcation of all these computa-
tion structures. Parts II and III have justiﬁed that process calculi [148] provide
an appropriate means to specify the functional aspects of concurrent and dis-
tributed systems (i.e. what we called basic event ordering in Section 1.3) and
convincing arguments for the approach have been given elsewhere [147].
The ﬁrst generation of process calculi did not support speciﬁcation of real-
time constraints. Consequently, there has been much interest in extending
process calculi in this direction, e.g. [64, 154, 167, 177, 201]. In particular, a
plethora of timed extensions to LOTOS have been proposed, e.g. [25, 26, 59,
123, 125, 143, 164, 166, 168] and the experience of these proposals has been
fed into the standardisation of the enhanced LOTOS language E-LOTOS;
see Section 6.4. The revised language, amongst a number of other extensions,
adds support for the expression of quantitative time; see Section 9.5.
This chapter presents a timed extension to LOTOS that uses a number of
the proposed enhancements, with particular emphasis being placed on the
following approaches, [26, 99, 102, 125, 143]. Thus, the chapter surveys the

262
9 Timed Process Calculi, a LOTOS Perspective
main design decisions involved in extending LOTOS with real-time and then
presents a particular approach.
The main requirements for time-extended LOTOS are reviewed and al-
ternative design choices are contrasted with reference to a number of the
main proposals. One important point to note is that adding quantitative time
has an impact on the nature of formal description in process calculi. Specif-
ically, standard process calculus speciﬁcation gives an abstract expression of
“possible” behaviour, whereas real-time speciﬁcation, by its nature, is more
prescriptive; it grounds action possibilities in real-time and deﬁnes when ac-
tions will happen, rather than the possibility that they may occur [36]. This is
exacerbated by the enforcement of urgency properties in timed process calculi
(an observation also made by [78,165] and further discussed in Section 9.2.2).
Thus, we view timed calculi as a more low-level formalism than classic process
calculi, less an abstract speciﬁcation notation and more a design notation.
Section 9.2 contains the review of requirements and issues surrounding
timed extension to LOTOS. Section 9.3 presents the timed LOTOS notation
that we are proposing. Then Section 9.4 discusses some anomalous behaviours
that can arise in timed LOTOS. Finally, Section 9.5 brieﬂy reviews the timed
extensions in E-LOTOS.
9.2 Timed LOTOS – The Issues
The now extensive ﬁeld of timed process calculi has revealed a number of
design choices involved in extending LOTOS with real-time. These choices
are discussed in the following sections, each of which is devoted to a partic-
ular feature of extending LOTOS with real-time. The following features are
discussed.
•
Timed action enabling;
•
Urgency;
•
Persistency;
•
Nondeterminism;
•
Synchronisation;
•
Timing domains;
•
Time measurement;
•
Timing of nonadjacent actions;
•
Timed interaction policies; and
•
Forms of internal urgency.
9.2.1 Timed Action Enabling
In a most basic sense, the enabling of LOTOS actions (i.e. when they are
oﬀered to the environment for interaction) needs to be tied to the passage of
time. This section considers the diﬀerent classes of timed action enabling that

9.2 Timed LOTOS – The Issues
263
can be employed and highlights notational extensions to standard LOTOS
that can be used to support these classes. First we consider two basic choices.
•
Instantaneous (Atomic) Actions vs. Durational Actions
As previously indicated, the atomic actions principle is central to standard
process calculus theory; see Section 2.3.6.1. However, the move to real-time
has prompted a minority of workers to consider noninstantaneous actions,
e.g. [4]. By their very nature, approaches with action duration are truly
concurrent; it would be unrealistic to prevent the interval of execution of
any action from overlapping with any other action. However, largely in
order to remain in line with the majority of timed process calculi workers,
and, to our knowledge, all timed LOTOS workers, we remain faithful to
the concept of atomic (and temporally instantaneous) actions.
•
Relative vs. Global (Absolute) Time
The distinction here is between approaches in which timing constraints are
expressed relative to the execution of a causally preceding action (relative
timing) and approaches in which all actions are timed relative to an abso-
lute global clock (global timing). The former of these two approaches has
dominated the time extended LOTOS work and can be seen to be most
appropriate, because speciﬁcation of ordering is expressed relatively; thus
it is natural to interpret timing constraints in the same manner.
In accordance with these choices, the remainder of this chapter considers
timed speciﬁcation based on relative timings of atomic instantaneous actions.
Expression of such real-time behaviour is generally facilitated by notational
extensions to action preﬁx. Thus, some variety of timed action preﬁx is intro-
duced, which has the general form,
a T ; B
i.e. an action followed by a time constraint, denoted T, and a behaviour B.
T expresses a time constraint that deﬁnes when a is oﬀered relative to the
execution of a predecessor action or the start of execution (when there is no
predecessor). Once a has been executed, a T; B behaves as B. The diﬀerent
notational conventions for T and the diﬀerent interpretations of these conven-
tions reﬂect the class of timed action enabling being employed. The diﬀerent
classes of enabling are as follows.
•
Simple Enabling
This is the simplest approach. It allows the instant an action becomes
enabled to be constrained by real-time, but, note, it does not allow any
constraint to be placed on how long this enabling lasts. Thus, no upper
bound can be imposed on enabling and the timing constraint associated
with action preﬁx simply states the time that an action starts being oﬀered
relative to a predecessor action. So, a behaviour such as
a [0] ; b [5] ; stop

264
9 Timed Process Calculi, a LOTOS Perspective
states that the action a is enabled immediately, whereas action b is enabled
5 time units after action a is taken (note: the T discussed previously has
been instantiated with the syntax [t]1). This approach only very loosely
prescribes when actions are taken. For example, from 5 time units after
the execution of a, b can be taken at any time, e.g. 6 time units after a, 12
time units after a or 10000007 time units after a. Thus, this approach oﬀers
a minimal timing capability and it is easy to think of real-time examples
that require a richer timing model. The advantage of this class is that
it imposes minimal alterations to the classic process calculus model. In
particular, once enabled, an action behaves as a standard process calculus
action. An important consequence of this is that parallel composition rules
(both interleaved and synchronised) are only minimally changed. Simple
enabling is adopted as the main class of timing in [51].
•
Initiation and Termination of Enabling
In this class, both lower and upper time bounds can be imposed on en-
abling. Thus, the region of time in which an action is oﬀered is bounded
by an initiating and a terminating time constraint. The class is typically
modelled using timing intervals. For example, a behaviour such as
a [0, 2] ; b [5, 12] ; stop
states that a is enabled immediately and will be oﬀered for 2 time units; b
will be enabled 5 time units after a is taken and will be oﬀered for 7 time
units. Clearly, an issue is what happens if the environment does not allow
the action to be taken in the region in which it is enabled. This issue is
discussed when we consider the possibilities for parallel composition and
synchronisation in Section 9.2.5.
•
Punctual Enabling
The ﬁnal class is punctual enabling, i.e. instantaneous initiation and then
retraction of enabling. The action preﬁx of [143] uses this class of timing.
So, a behaviour such as
a [0] ; b [5] ; stop
states that a is instantaneously oﬀered and that 5 time units after a is
taken, b is oﬀered instantaneously. Punctual enablings are used as abstrac-
tions of real-world systems. An important class of applications that use
punctual enabling is those employing periodic behaviour, e.g, isochronous
transmissions, which are central to multimedia applications based on con-
tinuous media, and clocks. For example, the following behaviour,
Clock := tick [100] ; Clock
will oﬀer a tick every 100 time units. Once again, an issue to consider is
what happens if the environment is not willing to engage in the action
when it is instantaneously oﬀered. This issue is discussed in Section 9.2.5.
1This syntax should not be confused with a selection predicate, as discussed in
Section 6.2.6.

9.2 Timed LOTOS – The Issues
265
It should be clear that a fully expressive timed LOTOS should support all
these classes of enabling. Thus, the central issue to consider is which class
should be adopted as primitive. Clearly, only a class for which all the other
classes can be derived would be suitable. The diﬀerent classes can be related
as follows.
•
Simple Enabling as Primitive
This choice is not appropriate as neither intervals of enabling nor punctual
enabling can be derived.
•
Initiation and Termination of Enabling as Primitive
If we allow intervals to have upper bounds of inﬁnity then simple enabling
can be directly deﬁned using this class; e.g. the simple enabling behaviour
a [0] ; b [5] ; stop is equivalent to a [0, ∞) ; b [5, ∞) ; stop using intervals. In
addition, punctual enabling can be deﬁned by giving the interval the same
lower and upper bound; e.g. the behaviour a [0] ; b [5] ; stop with punctual
enabling is equivalent to a [0, 0] ; b [5, 5] ; stop using intervals.
•
Punctual Enabling as Primitive
It is more diﬃcult to see how the other classes of enabling can be deﬁned
from punctual enabling, but they can. The timed LOTOSs built using
punctual enabling typically use generalised choice in order to derive richer
real-time scenarios, e.g. [143]. See Section 6.2.7 for an introduction to
generalised choice. A typical example of the use of generalised choice to
deﬁne timing intervals from punctual timing behaviour is
choice t : nat [] ( [5 ≤t ≤12] −> b [t] ; B )
which states that b is enabled after 5 time units and is then oﬀered for
the next 7 time units, when the oﬀer is retracted. Thus, the behaviour is
equivalent to the interval behaviour b [5, 12] ; B. In addition, placing an
inﬁnite upper bound on generalised choice facilitates deﬁnition of simple
enabling; e.g. the punctual timing behaviour,
choice t : nat [] ( [5 ≤t] −> b [t] ; B )
is equivalent to the simple enabling b [5] ; B.
There are actually more notational alternatives than we have revealed in the
discussion so far; some of these are considered in more depth later, e.g. in
Sections 9.2.8 and 9.2.9, but we consider two alternatives now.
•
Delays
An alternative to adding time through action preﬁx is to include a delay
operator, such as ∆t or Wait t; see [99, 123]. The behaviour ∆t B will
idle for t time units and then behave as B. On its own, a delay operator
does not yield a rich enough timing notation. However, in addition to other
timed extensions, a fully expressive timed calculus can be devised. A good
example of such an approach is the proposal [125], which supports two
primary timing constructs, the “dream team” as Leduc refers to them, a
delay operator ∆t and the, so-called, “life reducer”. The latter of these is

266
9 Timed Process Calculi, a LOTOS Perspective
an action preﬁx notation that bounds the length of enabling of an action;
i.e. a [t] ; B will oﬀer a for a time period t, i.e. until the life reducer expires.
With these two operators, lower bounds on enabling can be deﬁned using
the delay operator and upper bounds can be imposed using the life reducer,
e.g. ∆5 b [10] ; B corresponds to b [5, 15] ; B in interval notation.
Leduc’s motivation for including an explicit delay operator is to enable
delays to be imposed that do not resolve choice on expiry of the delay. For
example, the following behaviour ∆5 B [] ∆7 B′ imposes 5 time unit
(respectively 7 time unit) delays on B (resp. B′), but, it is important to
note that the choice between B and B′ cannot be resolved solely by the
expiry of either of the delays. This is in contrast to the solution that would
have to be employed in a model without delays: i [5, 5] ; B [] i [7, 7] ; B′,
where the delay is overloaded on a hidden action. (Assuming maximal
progress, which we discuss shortly) this solution will perform an i and
behave as B after 5 time units have been reached. Thus, the choice is
resolved by the i action with the smallest timing.
In actual fact, we would like to have a delay interval available, e.g.
∆[t1, t2] B, which will wait for a time period nondeterministically chosen
from the interval t1 to t2. This can be obtained using a single valued delay
and oﬀering an internal action during an interval, but this again has the
problem of resolving choice. Typically, models do not support such a delay
interval.
The reason for this is that it is diﬃcult to deﬁne semantically. Speciﬁcally, a
semantics would have to distinguish between the following two behaviours,
∆[0, 2] x [0, 2] ; B and x [0, 4] ; B
because the ﬁrst selects a delay (nondeterministically) from the interval
[0, 2], waits that period of time and then (and only then) starts to oﬀer x,
which it oﬀers for 2 time units. In contrast, the second behaviour oﬀers x
for 4 time units.
These are behaviourally very diﬀerent processes; in particular, a tester
process that wishes to perform x after 1 time unit, i.e. x [1] ; exit, can
never deadlock with the second process, but it can with the ﬁrst. How-
ever, because we will have no semantic way of distinguishing deterministic
and nondeterministic timing we will not be able to distinguish the two se-
mantically. As a reﬂection of this, we do not include interval delays in our
model. Thus, in this respect, we have the same limitation as E-LOTOS.
•
“High-level” Operators
Another approach is to incorporate “high-level” timing operators, such as
timeouts and watchdog timers, directly in the language. One of Leduc’s
proposals emphasizes such operators. For example, [123] introduces an
operator of the form ⌊P⌋t,x(Q), which enables a timeout of value t to
be imposed on all instances of action x in P; if a timeout expires, Q is
activated (the operator is a generalisation of the timeout operator of TCSP
[175], which is usually also introduced as primitive). Leduc’s operators are

9.2 Timed LOTOS – The Issues
267
related to the timed interaction operators of Bolognesi, which is discussed
in Section 9.2.9.
In particular, one of Leduc’s motivations in introducing these operators
was to support speciﬁcation of time constraints over interactions and
thereby to support structured speciﬁcation styles, such as the constraint-
oriented style [24]. However, the introduction of operators such as timeouts
and watchdogs as primitive leads to semantic complexity and is somehow
not in keeping with the standard LOTOS operators, which provide a lower
level of behavioural speciﬁcation. Thus, our approach does not consider
such high-level operators as primitive, but rather derives realisations of
timeouts and watchdog timers in terms of more low-level primitive con-
structs. This is the approach taken in the majority of timed LOTOSs;
in particular, later Leduc proposals have largely rejected the high-level
operators.
In summary then, we have highlighted a number of diﬀerent classes of timed
enabling and a number of diﬀerent notational conventions that can realise
these classes. The debate between these notations concerns which is the most
expressive and which will support all other classes of timed enabling. It is clear
from our discussion that punctual timing and intervals could both be employed
as primitive. However, the derivation from intervals is more straightforward
and does not rely on an additional LOTOS construct, the generalised choice
operator. Thus, we employ time intervals as our primitive timing notation. In
addition, as justiﬁed above, we incorporate a delay operator similar to that
in E-LOTOS.
9.2.2 Urgency
The previous section has highlighted a number of classes of timed action en-
abling. However, even a model that supports all these classes is only expressive
enough to model a subset of real-time systems. The classic process calculus
model expresses possibilities; it enables speciﬁcation of what a system may
do. The interpretation of choice in process calculi directly reﬂects this char-
acteristic. Speciﬁcally, there is no point at which one of the two branches of a
choice, such as a ; stop [] b ; stop, is forced to happen; it really is the case that
the behaviour may do a or it may do b and at no point (until the environment
dictates) must it perform one in preference to the other. In addition, although
internal actions are not waiting for environmental inﬂuence, in untimed cal-
culi, they also express a may (rather than a must) execution policy. Thus,
there is no point at which an internal action can be forced to happen. All we
know is that it will eventually (at some ﬁnite point in time) happen.
The domain of real-time speciﬁcation requires a revision of this interpre-
tation. For many important classes of time-dependent systems, it is necessary
to express that a particular behaviour must happen. As discussed at the end
of Section 6.3.1, the classic example of this is a protocol containing a timeout;
e.g. in our running communication protocol example, the sender behaviour,

268
9 Timed Process Calculi, a LOTOS Perspective
Sender [get, send, receiveAck] :=
get ; send ; Sending [get, send, receiveAck]
Sending [get, send, receiveAck] :=
receiveAck ; Sender [get, send, receiveAck]
[] i [t, t] ; send ; Sending [get, send, receiveAck]
will perform an action send and then wait for an acknowledgement (the ac-
tion receiveAck). If the acknowledgement arrives before a timer has expired,
modelled here as the internal action i, which occurs punctually t time units
after the send, then the behaviour recurses and makes its next transmission.
If the behaviour times out waiting for receiveAck it will resend the message.
Superﬁcially, this seems a suitable solution, however, unless we can force the
action i to occur urgently we cannot guarantee that the speciﬁcation behaves
correctly. Thus, we must actively rule out evolutions of the behaviour in which
a receiveAck is oﬀered at times greater than or equal to t time units after
the send and force the i action to occur at time t. This requires some form
of urgency to be imposed on timed actions, i.e. to deﬁne that an action must
occur by some point in time.
Urgency is now a well-accepted and extensively documented requirement
[123,154,167] and many diﬀerent solutions exist. Three main approaches have
been identiﬁed. These are diﬀerentiated by where urgency is placed in the
model.
•
Urgent Actions
In this approach, all actions (both those that are observable and those
that are unobservable) are interpreted as urgent. This approach can lead
to some counterintuitive scenarios. Speciﬁcally, a main premise of process
calculi is that the environment should dictate when observable actions are
selected. With urgent actions, it is possible that observable actions will
become urgent, but will be prevented from executing by an environment
that is not oﬀering the action. A consequence of this interpretation is that
timelocks, i.e. situations in which time is not able to pass, may occur,
because the speciﬁcation may not allow time to pass because it wants to
perform an action urgently, but the environment is not able to perform
the action. Timed calculi have been considered that assume urgent actions,
but allow nonurgency to be enforced explicitly, e.g. ATP [154], and this
approach was reﬂected in an early timed LOTOS proposal by Leduc [121],
which has not been taken further. In addition, some of the early Spanish
proposals adopted urgent actions (e.g. [164]). However, urgent actions are
now largely rejected in timed process calculi.
•
Explicit Urgency Operator
In this approach, a speciﬁc operator is incorporated into the language
that enables actions to be made into urgent actions. So, for example, an
operator urge may be introduced, which, in the following behaviour,

9.2 Timed LOTOS – The Issues
269
urge y in ( x [2, 10] ; y [4, 6] ; stop )
will make the y urgent, i.e. force it to be oﬀered urgently 4 time units after
the execution of x. This approach clearly constrains the environment more
selectively than the urgent actions approach, however, timelocks can still
occur. Bolognesi [25,26], the main advocate of explicit urgency operators,
argues that timelocks reﬂect a speciﬁcation error and should be accepted
in timed calculi. Brinksma et al [51] provide another notable approach that
employs an explicit urgency construct, although, urgency in this model is
deﬁned over action instances rather than over interactions as advocated in
Bolognesi’s proposals.
•
Urgent Internal Actions
All of the following terms have been used in the literature in order to de-
scribe variants of this class of urgency: Maximal Progress, asap (as soon as
possible) and Minimal Delay. The approach restricts urgency to internal
actions. Thus, unless an extra paradigm is incorporated into the language,
all observable actions are interpreted as nonurgent, whereas internal ac-
tions are interpreted urgently. The intuition behind this is that all external
actions are subject to the control of the environment, which should not
be constrained by the imposition of urgency on oﬀered behaviour, whereas
internal actions are not so constrained. Thus, an internal action can always
execute and it can always execute urgently (and without the possibility
of timelocks arising). This is now the most common approach; see, for ex-
ample, [99, 102, 125, 127, 143, 168]. However, it is worth pointing out that
there are limitations to this approach. In particular, a speciﬁer may want
to constrain an action to be urgent, but still leave it available for synchro-
nisation. With maximal progress, when an action is selected as urgent, the
speciﬁer is forced to hide the action and thus constraints can no longer be
added to the action. This imposes a strict order of steps on the develop-
ment process; all parallel constraints must be added ﬁrst before urgency
of interactions, and hence hiding, is considered.
It should be clear from the discussion above that incorporating urgency in
LOTOS enables more “prescriptive” speciﬁcations than one classically oﬀered
by standard LOTOS. Urgency constraints prescribe that particular actions
must happen in preference to other oﬀered actions. In fact, some authors
have viewed all forms of urgency as encouraging overspeciﬁcation. Although
we acknowledge this argument, we feel that the pragmatic case for forms of
urgency (i.e. that certain classes of timed speciﬁcation are only possible with
it) is powerful. In accordance with what is now the majority of researchers,
we prefer urgent internal actions over the other approaches.
However, there is still a choice to be made over the type of internal urgency
that we recommend and we return to this issue in Sections 9.2.4 and 9.2.10.

270
9 Timed Process Calculi, a LOTOS Perspective
9.2.3 Persistency
Action persistency is the property that the passage of time cannot cause an
oﬀered action to be retracted. In transition notation, action persistency can
be deﬁned as
∀B, B′, t, a ∈Act ∪{i, δ} , ( B
t; B′ ∧B
a
−→=⇒B′
a
−→)
where B and B′ are behaviour expressions, t is a time delay and
t; is a time
passing transition. The property states that, if a behaviour B can perform an
action a, after idling, it will still be able to perform the action a.
Persistency enforces the standard untimed process calculus retraction of
an enabled action, i.e. by action occurrence. The timed LOTOS community
is split over the value of this property. Proposals which support persistency
include [25,26,123], and proposals which do not support the property include
[99, 102, 143]; in addition, [125] contains two proposals; the ﬁrst does not
support the property and the second does.
The strongest advocate of the principle is certainly Bolognesi [26], who
argues for what he calls a strong timing policy (although, he does also recog-
nise the need for a weak timing policy). He obtains this strong timing policy
by enforcing a hard or strict upper bound on intervals of action enabling.
Thus, time cannot pass beyond this upper bound without the action being
executed or being disabled by the execution of an alternative action; e.g. if the
action a is strongly timed, in the absence of an alternative action oﬀer, the
time constraint a [2, 10] means that a becomes enabled two time units after
the previous action and must have been taken within eight time units of this
enabling. Thus, a must timing constraint is enforced, in a similar way as for
urgency.
As was the case with imposing urgency on external actions, Bolognesi’s
strong timing policy has some counterintuitive consequences, such as the pos-
sibility of timelocks. In addition, speciﬁcation of a choice between two actions
with nonoverlapping intervals, e.g.
( x [5, 10] ; B ) [] ( y [15, 20] ; B′ )
(*)
will only oﬀer the environment the possibility of interacting with the ﬁrst en-
abled action, i.e. the action x. This is because the upper bound on enabling
of x is strict and, thus, either the x is taken within its time constraint or a
timelock ensues; the y can never be oﬀered. This seems a surprising interpre-
tation of the interplay of choice and intervals of action enabling and suggests
that the consequences of enforcing action persistency can be severe. A solution
which would work in Bolognesi’s model is
( x [5, 10] ; B ) [] ( i [10, 10] ; y [5, 10] ; B′ )
where an internal action is introduced, execution of which will give an action
persistent alternative to the execution of x at its upper bound. However, this

9.2 Timed LOTOS – The Issues
271
solution becomes cumbersome if a choice contains many alternatives with
nonoverlapping timing intervals.
So, in accordance with a number of the other timed LOTOS workers, we
believe this is a situation in which timed LOTOS should diverge from the
standard untimed language and, in situations such as the above example,
we would like time to pre-empt action oﬀers. Thus, the interpretation of the
behaviour (*) that we would advocate is that after 10 time units have passed
the oﬀer of action x is retracted; 5 time units pass and then action y is oﬀered.
We advocate, in Bolognesi’s terminology, a weak timing policy. A consequence
of this is that we must decide what happens when an upper bound on an action
expires without the environment having been able to interact with the oﬀered
action. We adopt what is now a relatively standard approach: to interpret
a behaviour x I; B as stop if the upper bound of the interval I expires; i.e.
the oﬀer of action x is retracted and no further action oﬀers can be made.
Importantly, this evolution to stop avoids timelocks as stop allows time to
pass.
9.2.4 Nondeterminism
This section considers the implications of real-time on nondeterminism. In
general, we seek to preserve the standard untimed behaviour of nondetermin-
ism. This is reﬂected in the requirement of the following property, which is
called time determinism,
∀B, B′, B′′, t , ( B
t; B′ ∧B
t; B′′ =⇒B′ = B′′ )
where equality here is syntactic equality. This states that the progression
of time cannot create nondeterminism, i.e. cannot force B to evolve to two
distinct behaviours. This is a reasonable property to require of a timed LOTOS
and one that our extension will uphold.
In addition, the argument is often made that urgency of internal actions
must be carefully deﬁned. For some real-time behaviours, we would like to
impose an interval of enabling on internal actions, i.e. to interpret a behaviour,
i [t, t′] ; B
as i is performed in the interval t to t′. The choice of instant that the inter-
nal action occurs is made nondeterministically. This is in keeping with the
fact that internal actions are beyond the control of the environment. The im-
plication of supporting this nondeterministic internal action is that i actions
become urgent when they reach their upper time bounds. With strict maximal
progress, they become urgent as soon as they are enabled.
The strict upper bound could though be circumvented through reference
to an inﬁnite upper bound,
i [t, ∞) ; B

272
9 Timed Process Calculi, a LOTOS Perspective
Furthermore, maximal progress can be regained through a behaviour such as:
i [t, t] ; B
ET-LOTOS [102] has adopted this approach of only enforcing urgency on
the upper bound of time intervals for explicitly referenced internal actions (it
employs maximal progress on hidden actions, as we discuss in Section 9.2.10).
However, it should also be noted that the eﬀect of a nondeterministic timed
i action could be obtained through the combination of a delay operator and
strict maximal progress on internal actions. For example, ∆[t, t′] i ; B, where
i occurs as soon as possible, in the classic sense of maximal progress. However,
as discussed in Section 9.2.1 we do not include such an interval delay in our
calculus. So this is not a solution we can employ.
9.2.5 Synchronisation
The basic diﬃculty surrounding synchronisation is that the timing intervals
of synchronising actions may conﬂict (i.e. not overlap). We discuss this issue
for each category.
•
Simple Enabling
For this class of enabling, synchronisation causes no problem. Conﬂicting
timings cannot be speciﬁed as actions are enabled permanently from a
particular point. For example, in the behaviour:
( x [5] ; stop ) |[x]| ( x [3000] ; stop )
the interaction on x would be oﬀered after 3000 time units (the maximum
of 5 and 3000).
•
Punctual Enabling
Timing conﬂicts arise if the instants of enabling of two synchronised actions
are not identical. Thus,
( x [5] ; stop ) |[x]| ( x [6] ; stop )
will be in conﬂict on the interaction x.
•
Initiation and Termination of Enabling
As for punctual enabling, conﬂicting synchronisations can be easily illus-
trated; e.g.
( x [5, 10] ; stop ) |[x]| ( x [11, 15] ; stop )
However, the timing constraints do not have to be identical to enable
synchronisation, as was the case for punctual enabling. Consider,
( x [5, 10] ; stop ) |[x]| ( x [8, 15] ; stop )
here the intersection of the two intervals, i.e. [8, 10], deﬁnes a constraint
on the interaction x, which can satisfy the original intervals of enabling of
the left- and right-hand instances of action x.

9.2 Timed LOTOS – The Issues
273
Similar alternatives are available for handling synchronisation conﬂicts with
both punctual enabling and initiation and termination of enabling. The two
standard alternatives are to enforce a timelock when synchronisations con-
ﬂict or to enforce a deadlock (which would allow time to pass). The choice
surrounding these two alternatives is clearly tied to the choices surrounding
urgency and persistency already discussed. In keeping with our conclusions
on these issues, we advocate that conﬂicting synchronisations deadlock rather
than timelock.
9.2.6 Timing Domains
There are three realistic options for the choice of time domain: discrete, dense
(but countable) and continuous, i.e. isomorphic to the natural numbers, the
nonnegative rationals or the nonnegative reals. Many early approaches used
discrete time domains [167] because they were simple and on the grounds
that computers are discrete digital artefacts and so computer speciﬁcations
should reﬂect this. However, the limitation of the discrete approach is that a
minimal time unit must be assumed and no subdivision of this grain size can
be made. This brings problems, because it may be diﬃcult to determine what
a suitable indivisible grain is for a speciﬁcation. Employing reﬁnement during
system development accentuates the problem, because evolving a speciﬁcation
may reveal that the grain size chosen is too coarse.
This said, in certain contexts, the simplicity of discrete time models, es-
pecially in respect of how easily they can be analysed, outweighs these limi-
tations. As a reﬂection of this, we consider a discrete time model in Chapter
13.
However, it is important to note that dense and continuous time domains
do not suﬀer these problems concerning the granularity of timing. So, the
problem could be resolved with either. However, continuous time domains
have been argued for in order to support speciﬁcation of systems combining
analogue and digital elements. Thus, because it will not generate any techni-
cal problems for our approach, we employ the nonnegative reals as our time
domain. Notice that discrete time (and time isomorphic to the rationals) can
be recovered as a special case.
9.2.7 Time Measurement
The ability to reference the time instant at which an action occurs is important
in certain classes of real-time speciﬁcation. This facility enables constraints on
action oﬀers to be made subject to the time instant at which a previous action
is taken. More generally, it enables time measurements to be undertaken.
A number of the timed LOTOS proposals incorporate facilities to reference
the instant at which an action is executed. Miguel et al [143], for example,
were the ﬁrst to deﬁne timing domains as standard ACT-ONE data types and
then timing variables were deﬁned as any normal data variable. This enables

274
9 Timed Process Calculi, a LOTOS Perspective
the generalised choice operator to be used to reference the instant an action
is taken; e.g.
send ; ( choice t : nat [] receive [t] ; B )
will record the time between send and receive (the propagation delay of a
protocol) in the variable t. Time measurement facilities are also available
in [152], but perhaps the most important proposal in this area is that by [125];
a variant of which has been adopted in the E-LOTOS standard [99,102]. The
notation is based upon that used by Wang Yi [201] in his time-extended CCS;
it enables an @t attribute to be associated with timed action preﬁx. The
construction a@t ; B states that the value of variable t is the relative time
instant at which a occurred; i.e. t records the duration that the action a is
oﬀered before it is taken. The lifetime of the binding to t is the whole of B. A
typical example that uses the @ attribute is the speciﬁcation of a global time
clock:
Clock(time : nat) :=
current time ?cur : nat @t [cur = time + t] ; Clock(cur)
This discrete time (because it uses the naturals as a time domain) behaviour
oﬀers the current time of a global clock as a data attribute of the action
current time and then recurses with the new global time as argument.
9.2.8 Timing of Nonadjacent Actions
The majority of timed extensions to process calculi incorporate a notion
of timed action preﬁx, similar to those discussed in Section 9.2.1. These
paradigms express time constraints relative to the occurrence of a causally
preceding action. However, some real-time problems require time constraints
to be deﬁned between actions, which are not direct predecessor and succes-
sor of one another. For example, we might want to specify that action z will
occur between 10 and 15 time units after action x in the following behaviour
x ; y ; z ; stop. This constraint, of course, assumes that y happens between 0
and 15 time units after x. We can specify such a behaviour using parallel
composition; e.g.
( x ; y ; z ; stop ) |[x, z]| ( x ; z [10, 15] ; stop )
This solution ﬁts nicely into a constraint-oriented style of speciﬁcation, where
constraints on system behaviour are added through parallel composition.
However, this approach does not work so well when the nonadjacent tim-
ing spans a choice or parallel composition. For example, specifying that z is
time-constrained by x in the behaviour,
x ; (y ; z ; stop [] w ; z ; stop)

9.2 Timed LOTOS – The Issues
275
in such a way that the reference to z on the left of the choice has a diﬀerent
time constraint to the reference to z on the right of the choice, is diﬃcult to
envisage.
In addition, there is no way to directly express nonadjacent timing in
calculi that only support a restricted notion of timed action preﬁx. For some
workers this is a signiﬁcant limitation of the standard approach [152]. Time
measurement attributes such as the @t discussed in the last section aid direct
expression of this class of property. For example, the above behaviour could
be expressed as
x ; y@t ; z [10 −t, 15 −t] ; stop
but, if many intermediate actions exist between the nonadjacent actions, this
can be cumbersome. For example, the behaviour,
x ; y@t1 ; z@t2 ; w@t3 ; u@t4 ;
v [10 −(t1 + t2 + t3 + t4), 15 −(t1 + t2 + t3 + t4)] ; stop
expresses that v will be enabled between 10 and 15 time units after x, with
intermediate actions, y, z, w and u.
Nakata et al [152] directly address the issue of timing on nonadjacent ac-
tions with a proposal that rejects relative timing and where timing constraints
in ﬁrst-order predicate logic are associated with action oﬀers. For example,
the previous example would be expressed as
x [c = t] ; y ; z ; w ; u ; v [10 + c ≤t ≤15 + c] ; stop
where t is a distinguished variable that denotes the current global time. t is
used twice in this example, ﬁrst to express the time at which x occurs and
second to express the time at which v occurs. The use of t is akin to the use
of clock variables in explicit clock temporal logics such as RTTL [157]. This
approach certainly enables a rich set of nonadjacent timing constraints to be
deﬁned, but it also brings not insigniﬁcant added complexity, mainly centred
on checking satisﬁability of ﬁrst-order predicate logic. Although, it should be
noted, [152] argues that the logic is amenable to formal veriﬁcation.
9.2.9 Timed Interaction Policies
Bolognesi and co-workers have consistently argued for a timed interaction pol-
icy, rather than the more common timed action policy. This preference has
been reﬂected in a series of timed LOTOS proposals leading up to the exten-
sion presented in [26]. The choice is between the local application of timing
constraints, as exempliﬁed by approaches based on timed action preﬁx, and
the more global application of timing constraints to interactions. The timed
interaction policy enables a timer to be started at the precise moment that
two parties begin interaction over a parallel composition. Bolognesi argues
that speciﬁcation of such behaviour is important and not possible with timed

276
9 Timed Process Calculi, a LOTOS Perspective
action policies. He draws analogies with the mature timing model oﬀered by
Merlin and Farber Petri nets [141].
As an illustration of the timed interaction approach, the following be-
haviour,
time y (5, 8) in ( x ; y ; stop |[y]| y ; z ; stop )
will oﬀer y between 5 and 8 time units after the synchronisation of y across |[y]|
becomes possible. Thus, the timing constraint is imposed on the interaction
y, rather than on the instances of action y, as would be the case with a
timed action policy. Quantitative time in such a timed interaction policy is
introduced into the language in a similar way to hiding in standard LOTOS.
In fact, Bolognesi imposes both timing constraints and urgency constraints
on interactions in preference to on actions; see the urge operator of Section
9.2.2
The, so-called, high-level timing operators of one of Leduc’s early timed
LOTOS proposals [123], which were discussed in Section 9.2.1, have many sim-
ilarities to Bolognesi’s timed interaction notation. However, in later proposals,
Leduc has largely rejected these operators, stating that experience they have
gained from extensive case studies suggests timed interaction operators are
not in fact necessary.
9.2.10 Forms of Internal Urgency
As previously suggested, there are a number of diﬀerent ways in which internal
actions can be made urgent. We highlight the two main approaches.
1. Maximal Progress
With pure maximal progress, as soon as an internal action becomes possi-
ble it must be taken. Thus, for example, (assuming that x does not appear
in B), the following behaviours,
i [2, 10] ; B
,
i [2, 4] ; B
and
hide x in ( x [2, ∞) ; B )
are “behaviourally equivalent”2 to each other and to the behaviour,
i [2] ; B
Internal actions occurs as soon as possible.
2. Urgent on Upper Bounds
With this approach, internal actions only become urgent when they reach
the upper bound of their enabling. Thus, (again assuming that x does not
appear in B) the behaviours,
i [2, 10] ; B
,
i [2, 4] ; B
and
hide x in ( x [2, ∞) ; B )
are no longer “behaviourally equivalent”, because the ﬁrst becomes urgent
after 10 time units, the second after 4 and the third will never become
urgent.
2For the moment we use this term informally. However, we formalise it in Chapter
10.

9.2 Timed LOTOS – The Issues
277
There are arguments in favour of both approaches, for example, as previously
suggested, the latter allows nondeterministic timing of internal actions, e.g.
the i action in,
i [2, 10] ; B
will happen at any time from 2 to 10, with the choice being made nonde-
terministically and this cannot be expressed with pure maximal progress.
Furthermore, since we do not include an interval delay we cannot mimic this
eﬀect using it.
In contrast, maximal progress allows an important form of urgency on in-
teractions to be deﬁned. This can be seen from a scenario devised by Bolognesi,
called the symmetric timeout. The timeout is built from two similar processes,
each of which independently performs an unpredictably long activity (com-
pletion of which is signalled by w below). Then it wishes to synchronise on
a given action (the x below) with its partner process as soon as possible (i.e.
as soon as both are ready). However, the process sets a timer on how long it
waits to synchronise and if synchronisation does not happen quickly enough
it times out and retracts its oﬀer of the synchronisation.
The general process is deﬁned as follows:
P [w, timeout, x] :=
w ;
( x ; P [w, timeout, x]
[] timeout [t] ; stop )
and two copies of this process are run in parallel, subject to synchronisation
on x (note: we could give each process a diﬀerent timeout value, but we avoid
this for simplicity of presentation).
Q :=
hide timeout1, timeout2 in
( P [w1, timeout1, x] |[x]| P [w2, timeout2, x] )
Now importantly, the eﬀect we seek is that, as soon as the two processes can
synchronise on x, they do so. Thus, urgency is enforced at the point of the
synchronisation being fulﬁlled and to do this we need to impose urgency on
the interaction x, rather than each of the instances of x. We can do this with
maximal progress using hiding, i.e.
hide x in Q
However, it is not clear how to obtain the same eﬀect when urgency is enforced
on the upper bounds of internal actions. This observation has lead some work-
ers to include both scenarios [102]. Thus, explicitly referenced internal actions,
e.g. i [0, 5] ; B are made urgent on their upper time bound (here 5), while hid-
ing yields maximal progress. Thus, using ≡to denote our informal notion of
behavioural equivalence (and assuming no references to x in B),

278
9 Timed Process Calculi, a LOTOS Perspective
hide x in ( x [0, 5] ; B ) ≡hide x in ( x [0] ; B ) ̸≡i [0, 5] ; B
which is an unpleasant compromise that advocates of this approach would
accept.
Our approach is to handle internal actions consistently (whether explicit or
hidden) and employ urgency on the upper time bound of all internal actions.
We acknowledge that this reduces the expressiveness of our approach in terms
of examples such as the symmetric timeout above.
9.2.11 Discussion
Combinations of the highlighted options have been incorporated into diﬀerent
proposals. However, no approach has incorporated all the options. In fact, such
an all-embracing language is almost certain to be unsatisfactorily complex.
With the desire not to over-complicate in mind we have made the following
choices for our timed LOTOS.
•
Timed Action Enabling – initiation and termination of enabling using in-
tervals and a punctual delay operator;
•
Urgency – urgency is imposed on internal actions;
•
Persistency – nonpersistent;
•
Nondeterminism – timing intervals associated with internal actions;
•
Synchronisation – behaviours evolve to deadlock if the intervals of syn-
chronising actions do not overlap;
•
Timing Domains – isomorphic to the nonnegative reals;
•
Time Measurement – not included;
•
Timing of Nonadjacent Actions – no new operator included;
•
Timed Interaction Policies – not included; and
•
Forms of Internal Urgency – on upper bounds.
The absence of time measurement is a limitation, however, we do not see any
technical reason why it could not be included in our model, with a certain
amount of added complexity. In addition, we have not included a speciﬁc
notation to obtain timing of nonadjacent actions, however, incorporation of
time measurement would resolve this deﬁciency (although the @t construct
and intervals are not a wholely natural combination). One reason for not
including these facilities is that our semantic model will not support data.
9.3 Timed LOTOS Notation
9.3.1 The Language
The timed LOTOS that we introduce is denoted tLOTOS; it reﬂects a “core”
subset of LOTOS operators, which excludes data and some high-level con-

9.3 Timed LOTOS Notation
279
structs, e.g. disabling, generalised choice and generalised parallelism.3 Han-
dling disabling would require richer semantic models than we consider (e.g.
extended bundle event structures; see [114]) and we avoid the added com-
plexity of considering these here. However, what we present can easily be
extended to these models. tLOTOS is ostensibly a timed version of pbLO-
TOS; see Chapter 2. In accordance with what we have argued so far, we add
intervals as our basic timing syntax. More formally, Ξ is the set of all possible
timing intervals and I ∈Ξ has the form:
[t, t′]
or
[t, ∞)
where t,t′ ∈R+0 and R+0 is the positive reals with zero (and R+ will denote
the positive reals without zero). So, these are (continuous) intervals on the
nonnegative real numbers, either closed or half-open with an upper bound
of inﬁnity4. If t > t′ in [t, t′] then an empty interval results, denoted ∅. We
use the notation ↑I to yield the upper bound of I and ↓I to yield the lower
bound. For half open intervals, ↑[t, ∞) = ∞. In addition, by convention, we
assume that ↑∅= 0 and ↓∅= ∞.
We deﬁne addition on intervals as follows,
I ⊕J = { t1 + t2 | t1 ∈I ∧t2 ∈J }
where, because t + ∞= ∞, inﬁnite bounds are preserved.
We deﬁne subtraction on intervals in a similar way,
I ⊖J = { (t1 −t2) ∈R+0 | t1 ∈I ∧t2 ∈J }
which avoids negative values being generated by enforcing that (t1−t2) ∈R+0.
Clearly, we can obtain constant addition and subtraction as a specialisation
of these operators. Thus, we write,
I ⊖d for I ⊖[d, d] and I ⊕d for I ⊕[d, d]
Observe also that I ⊖d does not necessarily have the same cardinality as I.
In particular, I ⊖d = ∅if d > ↑I.
The set of all tLOTOS descriptions is deﬁned as follows. Thus, all S ∈
tLOTOS satisfy the following rules.
S ::= B | B where D
D ::= (P := B) | (P := B) D
B ::= stop | exit I | wait [t] B | a I ; B | B1 [] B2 | B1 |[G]| B2 |
B1 >> B2 | hide G in B | B [y1/x1, . . . , yn/xn] | P
3Strictly speaking, we should call this language tpbLOTOS, but we use the more
concise tLOTOS for presentational convenience.
4Note, we do not allow half-open intervals in any other circumstances, since they
can generate timelocks. For example, enforcing urgency at the upper bound of an
interval, which has no proper upper bound, would prevent time passing.

280
9 Timed Process Calculi, a LOTOS Perspective
where a ∈Act ∪{i}, xi, yi ∈Act, t ∈R+0, I ∈Ξ, D ∈tDeﬂist (the set of
tLOTOS deﬁnition lists), G ⊆Act, P ∈PIdent and B ∈tBeh (the set of all
tLOTOS behaviour expressions).
Thus, we have a deadlock behaviour, stop; timed successful termination,
exit I; a delay operator, wait [t]B; timed action preﬁx, a I ; B; binary choice,
B1 [] B2; parallel composition, B1 |[G]| B2; sequential composition, B1 >>
B2; hiding, hide x1, . . . , xn in B; relabelling, B[y1/x1, . . . , yn/xn]; and process
instantiation, P.
In order to simplify presentation, we often write relabelling as B[H] where
H is a relabelling function. It is assumed to be total on Act∪{i, δ} and can be
obtained from a relabelling vector, y1/x1, . . . , yn/xn, by deﬁning H(xi) = yi
for all 1 ≤i ≤n and H(a) = a for all a ∈( Act \ {x1, . . . , xn} ) ∪{i, δ}. Also,
for ease of presentation, in some examples we associate gate lists with process
deﬁnitions and instantiations even though this is not in the base language.
The construct wait [t] B is our delay; it will idle for t time units and
then behave as B. Timed action preﬁx, a I ; B, will oﬀer a (which ranges over
internal and observable actions) in the interval of enabling deﬁned by I and,
if a is taken, it will behave as B. Thus,
•
x [t, t′] ; B will oﬀer x between t and t′ inclusive;
•
x [t, ∞) ; B deﬁnes simple enabling of x; and
•
x [t, t] ; B deﬁnes punctual enabling of x.
We can create nondeterministic intervals of internal behaviour such as
i [10, 20] ; B
More usable operators can be derived from the basic tLOTOS constructs. We
assume the following derivations.
•
a (t) ; B ≜a [t, ∞) ; B;
•
x ; B ≜x (0) ; B for x ∈Act;
•
a [t] ; B ≜a [t, t] ; B;
•
i ; B ≜i [0] ; B;
•
exit (t) ≜exit [t, ∞);
•
exit ≜exit [0, ∞);
•
exit [t] ≜exit [t, t]; and
•
B t B′ ≜B [] ( wait [t] i ; B′ ).
Notice that nontime-constrained action preﬁx is interpreted diﬀerently depen-
dent upon whether the action is internal or external; i.e. x ; B ≜x [0, ∞) ; B
while i ; B ≜i [0, 0] ; B. This reﬂects the standard interpretational distinction
between external and internal behaviour arising from urgency. Notice also
that the last of these derived operators is a timeout, which will behave as B

9.3 Timed LOTOS Notation
281
if the ﬁrst action of B is performed before t time units expire; if t time units
do pass before this action is performed, the behaviour evolves to B′. Central
to the deﬁnition of this operator is the interpretation of internal actions as
urgent, which ensures that the timeout really does expire after t time units
and the exception behaviour is performed.
9.3.2 Example Speciﬁcations
This section discusses speciﬁcation of two typical real-time constructs, a time-
out and a multimedia stream.
Simple Timeout. From the communication protocol example, the following
behaviour,
Sender [get, send, receiveAck] :=
get ; send [0] ; Sending [get, send, receiveAck]
Sending [get, send, receiveAck] :=
receiveAck ; Sender [get, send, receiveAck]
t send [0] ; Sending [get, send, receiveAck]
deﬁnes a simple Sender process, which sends a message immediately and then
goes into state Sending. In this state it will either receive an acknowledgement
and restart the transmission process or it will timeout after t time units, resend
and try again for an acknowledgement.
Multimedia Stream. Distributed multimedia computing is an important
area of real-time systems and the application of timed formal techniques to this
area is being widely considered [21]. Distributed multimedia systems contain
continuous ﬂows of data with strict associated timing constraints, e.g. ﬂows of
audio or video. A multimedia stream is an abstraction of such ﬂows of data.
We consider a very simple example of such a stream, comprising a data source
and a data sink communicating asynchronously over a channel; see Figure 9.1.
The channel is assumed to be inﬁnite and may lose messages. Time units are
milliseconds.
The top-level behaviour of the stream could be speciﬁed as
start;
hide sourceOut, sinkIn in
( ( ( sourceOut [0] ; Source ) ||| Sink )
|[sourceOut, sinkIn]|
Channel )
This composes the Source, Sink and Channel processes into a form equivalent
to that depicted in Figure 9.1. The gates sourceOut and sinkIn are hidden
from the external observer. The start action is oﬀered until it is taken and

282
9 Timed Process Calculi, a LOTOS Perspective
Source
Process
Sink
Process
play
Channel
sourceOut
sinkIn
Fig. 9.1. A Multimedia Stream
the sourceOut action is oﬀered immediately following start (as long as the
Channel is willing).
The Source process has a very simple behaviour,
Source := sourceOut [50] ; Source
sourceOut actions are repeatedly oﬀered at 50 ms intervals. Notice that no
error recovery is incorporated, i.e. acknowledgement or timeout schemes. This
is typical of multimedia data, where temporal integrity is most important and
retransmission is of limited value, since it would typically invalidate temporal
integrity. The behaviour of the Channel can be speciﬁed as follows,
Channel :=
sourceOut ;
( ( i [80, 90] ; sinkIn [0] ; stop
[] i [0, 90] ; stop )
||| Channel )
So, the Channel will always oﬀer a sourceOut and then either a sinkIn will
be oﬀered or the Channel will internally decide to lose the message, indicated
by an internal action. In addition, the channel imposes a latency delay of
between 80 and 90 ms on each transmission. The action sinkIn will be oﬀered
at a time instant nondeterministically chosen from the interval [80, 90]. The
independent parallel recursive call ensures that the channel is nonblocking.
The data sink could be speciﬁed as
Sink :=
( sinkIn ; ( play [5] ; stop ||| Waiting ) )

9.4 Timing Anomalies in tLOTOS
283
90 ( i ; error ; stop )
Waiting :=
( sinkIn ; ( play [5] ; stop ||| Waiting ) )
50 ( i ; error ; stop )
which either receives a sinkIn and plays the frame or returns an error. The
process takes 5 ms to process frames, i.e. the time between frames arriving
and being played. If either the ﬁrst frame does not arrive within 90 ms of the
action start occurring or a future frame does not arrive within 50 ms of a
previous frame, the Sink will go into error.
9.4 Timing Anomalies in tLOTOS
The fact that observable actions cannot be forced to be urgent, prevents a
major source of timelocks, i.e. those that arise through mismatched synchro-
nisations, where one partner in a synchronisation wishes to force the action
to occur at a particular point, but the other partner does not oﬀer the action
at that instant. However, other forms of timelocks can occur. These are ana-
logues of what we call zeno-timelocks in Chapter 12, where we discuss these
issues in some depth in the timed automata setting. They all occur through
the interplay of recursion and the passage of time and they correspond to
situations in which an inﬁnite number of transitions can be performed in a
ﬁnite (even zero) amount of time.
Firstly, instantaneous tau loops can stop time. For example,
P := i ; P
(remember, i ; B ≜i [0, 0] ; B)
will perform an inﬁnite number of i transitions without passing time. Note,
the urgency of internal transitions is critical in generating this behaviour. In
particular, although
R := x (0) ; R
has a trace whereby an inﬁnite number of xs are performed at time zero (i.e.
a zeno run), at all points during that trace, there is a future point at which it
can allow time to pass arbitrarily. Indeed, this arbitrary idling will, at some
point, become the only possibility for the process unless the environment is
also willing to undertake an inﬁnite number of x actions at time zero. Thus,
through its choice of action oﬀers, the environment can “force” R out of its
zeno run. Consequently, R never actually locks time; it is not an example of
a timelock.
Secondly, unguarded recursion can generate timelocks. For example,
Q := Q

284
9 Timed Process Calculi, a LOTOS Perspective
will block time. This is because the labelled transition system semantics for
tLOTOS take the smallest relation satisfying the operational semantics infer-
ence rules (which are given in Section 10.1.2). Consequently, Q yields the null
transition system, which can neither pass time nor perform any actions; i.e. it
is timelocked (actually, time-action locked in the terminology of Chapter 12).
Indeed, any tLOTOS process containing an unguarded recursion will block
time. For example,
unguarded := ( x [2, 6] ; stop ) ||| unguarded
cannot pass time.
Finally, if we imagine our language has data typing capabilities, we can
deﬁne pure zeno processes. First, the following is a process with zeno runs.
zeno := zzeno(1)
zzeno(k : nat) := x ; wait [2−k] zzeno(k+1)
This process can perform an x, delay for 0.5 time units, then perform another
x, wait 0.25 time units, and so on, ad inﬁnitum. Thus, if x is repeatedly
selected instantaneously, the process gets inﬁnitely close to an absolute time
of 1, but it never actually gets there. However, because it uses observable
actions, it will not generate a timelock; that is, repeatedly, during a zeno run
it will reach points from which it could pass time, i.e. when x is enabled.
Notice, the following process also does not create a zeno timelock, even
though it does have zeno runs.
zeno′ := zzeno′(1)
zzeno′(k : nat) := x [0] ; wait [2−k] zzeno′(k+1)
In this case, idling will make x unavailable, but, nonetheless, any point in a
zeno run is followed by a point at which the process can idle arbitrarily.
However, the following behaviour does timelock.
zeno urgent := zzeno urgent(1)
zzeno urgent(k : nat) := i ; wait [2−k] zzeno urgent(k+1)
It never reaches a state where it can idle to an absolute time not less than 1.
Once again, the urgency of internal actions is critical in obtaining this eﬀect.
A key characteristic of timelocks is that they prevent a completely inde-
pendent process from evolving [34,35]. Accordingly, zeno and zeno′ have paths
in which time passes arbitrarily and thus, they will not block a completely
independent process. However, zeno urgent will. For example,
zeno urgent ||| ( i [2] ; success ; stop )
can never perform the action success. However,

9.5 E-LOTOS, the Timing Extensions
285
zeno ||| ( i [2] ; success ; stop )
and
zeno′ ||| ( i [2] ; success ; stop )
can both reach success. We do not view behaviours with zeno runs as, au-
tomatically, degenerate, however, behaviours with only zeno runs, i.e. zeno
timelocks, are clearly very dangerous.
Whereas timing anomalies, such as those highlighted here, are not a pleas-
ing part of tLOTOS, our position is that such zeno timelocks should not be
prevented by construction (this is in contrast with our position with respect
to nonzeno timelocks, which, as discussed throughout this chapter, we believe
should be ruled out by construction). Indeed, it has been observed in [65]
that such behaviour can have an important role in a constraint-oriented spec-
iﬁcation style [195]. We thus prefer the application of analytical methods,
which can detect such degenerate behaviour. We highlight such an analysis
technique, which detects zeno timelocks in timed automata speciﬁcations in
Chapter 12. It should be possible to devise similar techniques that can be
applied in the tLOTOS setting.
9.5 E-LOTOS, the Timing Extensions
E-LOTOS was brieﬂy discussed in Section 6.4. In addition to the extensions
discussed there, the language also has a number of extensions that allow the
speciﬁcation of real-time behaviour; these include the following.
•
E-LOTOS has the capacity to deﬁne timing domains in the data language.
This yields a type time, with appropriate operations deﬁned on it. Typi-
cally, the data domain chosen will be a renaming of either the non negative
naturals or the nonnegative rationals.
•
A wait operator, similar to tLOTOS’ wait operator, is included. Thus,
behaviours such as
x ; wait(5) ; y
and, more interestingly,
x ; ( ?t := any time [t <= 10] ) ; wait(t) ; y
can be speciﬁed. The former just enforces a 5 time unit delay between x and
y (note, in E-LOTOS ; denotes sequential composition, rather than action
preﬁx and action instances implicitly generate successful terminations).
The latter enforces a delay between x and y that is a randomly chosen
value less than 10 (note, in E-LOTOS ?t denotes a binding occurrence of
variable t).
•
A powerful time capture enhancement of action preﬁx (as discussed earlier
in this chapter) is included. Thus, in
x @?t ; wait(20 −t) ; y

286
9 Timed Process Calculi, a LOTOS Perspective
t captures the time elapsed between when x started being oﬀered and when
it is taken. Assuming that x occurs within 20 time units of being enabled,
the above behaviour ensures that y becomes enabled 20 time units after x
initially became enabled.
When combined with the selection predicate, the time capture operator
can also be used to recover punctual and interval enabling; e.g.
x @?t [t = 5] ; y
and
x @?t [2 <= t <= 5] ; y
The left-hand behaviour requires x to happen at time 5, or not at all and
the right-hand behaviour oﬀers x between times 2 and 5.
•
The maximal progress principle is employed. Thus, internal actions gener-
ated through hiding must occur as soon as possible and observable actions
cannot be urgent.
E-LOTOS certainly oﬀers a powerful set of timing operators. In particular,
the time measurement capacities of the @t attribute give E-LOTOS advan-
tages over tLOTOS. However, we have selected the pure intervals approach
of tLOTOS because of its simplicity and because semantic treatments of it in
both the interleaved and true concurrency setting have been given, which is
not the case for time capture.

10
Semantic Models for tLOTOS
We need to consider semantic models for timed process calculi for just the
same reason that we had to consider semantics for untimed process calculi. In
particular, in order to know deﬁnitively when we can view two speciﬁcations
of timed systems as behaviourally equivalent, we need to relate their semantic
models. Syntactic equivalence is again much too ﬁne a means of comparison.
As was the case in the untimed setting, many diﬀerent semantic inter-
pretations have been devised, each of which induces a particular notion of
equivalence. In fact, timed versions of all the semantic models we considered
in Part II can be presented. However, due to the limits of this presentational
format, we restrict ourselves to timed versions of labelled transition systems
and of bundle event structures. The interested reader can, for example, con-
sider the timed CSP theory [176] for details of timed extensions of trace-based
and trace-refusals based theories.
The material presented in this chapter follows closely work performed by
Joost-Pieter Katoen and co-workers [51,108,109]; Bowman [32,39] and, par-
ticularly closely, Bowman and Katoen [47]. The chapter is divided into two
sections. The ﬁrst (Section 10.1) considers labelled transition system semantics
for tLOTOS and the second (Section 10.2) considers bundle event structure
semantics for the calculus.
10.1 Branching Time Semantics
10.1.1 Timed Transition Systems
In order to give a branching time semantics for tLOTOS we need an enhance-
ment of labelled transition systems that not only allows us to describe the
order in which actions occur, but also allows us to express relative timing
between actions. The semantic structure that we use is what has been called
a time action transition system [26], although, when there is no chance of
confusion, we use the simpler term “timed transition system”. Bolognesi [26]

288
10 Semantic Models for tLOTOS
gives a justiﬁcation for why this approach is preferable to the other common
approach, which he calls timed-action transition systems.
The set of all time action transition systems is denoted T T S and we
require that ∀Sys ∈T T S, Sys is a four tuple (S,TL, T, s0) where
•
S is a nonempty set of states.
•
TL ⊆A ∪R+ is a set of transition labels. Notice that real numbers as well
as actions (from the set A) can label transitions (for tLOTOS A will be
set to Act ∪{i, δ}).
•
T is a set of transition relations. One relation, Tv, is included for each
v ∈TL.
•
s0 ∈S is the starting state of Sys.
In the normal way, a transition relation Tv is a set of triples of the form
(s, v, s′),1 i.e.
Tv ⊆S × {v} × S
where (s, v, s′) states that a transition from state s to state s′ exists, which
is labelled by v. Thus, transitions in time action transition systems not only
denote when actions occur, but, by placing values (in the reals) on transitions,
they also denote time passing. For example, Figure 10.1 shows a very simple
time action transition system. The system will idle for 1.5 time units, then it
will perform a nondeterministic choice on x, as a result of which it will either
idle 0.9 time units and oﬀer a y or it will idle 2.8 time units and then oﬀer
a z. Thus, time and action transitions are scattered throughout the resulting
graph, indicating that the oﬀering of atomic actions can be interleaved with
the passage of time.
1.5
0.9
2.8
x
x
y
z
Fig. 10.1. A Time Action Transition System
As a notational convention, we distinguish between transitions labelled with
actions, which we denote
1Although, rather than explicitly subdividing T into subrelations by label, we
could analogously have given a ﬂat deﬁnition of the transition relation, as we did in
Section 8.2.1. Indeed, our use of a nested transition relation in the process calculus
setting, and a ﬂat relation with automata, is largely historical.

10.1 Branching Time Semantics
289
s
a
−→s′
and those labelled with time steps, which we denote
s
d; s′
where d ∈R+.
In contrast to the illustration we gave in Figure 10.1, the time action
transition systems derived from a nontrivial speciﬁcation will almost certainly
contain inﬁnite branching. In particular, for a speciﬁcation such as
P := x [0, 1] ; B
the following will hold
∀d ∈R+ . P
d;
and because our time domain is the reals, the number of possibilities for d
will not only be inﬁnite, but it will also be uncountable!
10.1.2 Operational Semantics
We present an operational semantics that maps tLOTOS speciﬁcations to
time action transition systems. The inference rules presented in this section
realise the semantic map J Ktts,
J Ktts : tLOTOS −→T T S
The inference rules we give are based upon the (event-based) operational
semantics given in [47], which were, in turn, based on those given in Katoen’s
PhD thesis [107]. Although, our rules are adapted to the calculus tLOTOS,
they work on action labels, rather than event labels and they resolve some
subtle diﬃculties with the earlier semantics, which we discuss in the next few
paragraphs.
We need some preliminary deﬁnitions before we give our inference rules.
Let initI (a, B) be the set of time intervals at which B is allowed to initially
perform a (this function is based upon the mapping denoted al in [47], which
was originally deﬁned in [107]2). The interpretation of initI (a, B) being equal
to ∅or {∅, . . . , ∅} is that B cannot initially perform a.
For tLOTOS expression B and a ∈Act ∪{i, δ}, function initI (a, B) is
deﬁned as the smallest set satisfying the rules in Figure 10.2. The rules deﬁne
a relatively straightforward induction on the structure of tLOTOS speciﬁca-
tions. Note in particular, that the wait operator merely delays the initial times
2Although it is important to note that we take the set of initial intervals, rather
than collapsing these intervals together to obtain the set of initial time points. It
turns out that a correct interpretation of urgency generated by hiding and enabling
requires this richer representation, as discussed further in the next few paragraphs.

290
10 Semantic Models for tLOTOS
initI (a, stop) ≜∅
initI (a, exit I) ≜
 ∅
if a ̸= δ
{I} if a = δ
initI (a, b I ; B) ≜
 ∅
if a ̸= b
{I} if a = b
initI (a, B [] B′) ≜initI (a, B) ∪initI (a, B′)
initI (a, wait [t] B) ≜{ t ⊕I | I ∈initI (a, B) }
initI (a, B >> B′) ≜
⎧
⎨
⎩
∅
if a = δ
initI (a, B)
if a ̸∈{ i, δ }
initI (a, B) ∪initI (δ, B) if a = i
initI (a, B |[G]| B′) ≜
 initI (a, B) ∪initI (a, B′)
if a̸∈G∪{δ}
{ I∩I′ | I ∈initI (a, B) ∧I′ ∈initI (a, B′) } if a∈G∪{δ}
initI (a, B[H]) ≜{ I ∈initI (b, B) | a = H(b) }
initI (a, hide G in B) ≜
⎧
⎨
⎩
∅
if a ∈G
initI (a, B)
if a ̸∈G ∧a ̸= i
{ I ∈initI (b, B) | b ∈G ∪{i} } if a = i
initI (a, P) ≜initI (a, B) for P := B
Fig. 10.2. Deﬁnition of initI
to perform an action of the behaviour it preﬁxes. In addition, the lower clause
for |[G]| deﬁnes the initial intervals for synchronised actions. Thus, such an
action can only be performed at a time point that is initial for both compo-
nent behaviours. Finally, consider the third clause of the rule for hiding. It
states that any initial instant of an action, which will be or, indeed, has been,
hidden, becomes an initial instant of the internal action.
One important point to note about this deﬁnition is that initI (a, B) re-
turns a set, each element of which is an interval. In particular, initI (a, B)
cannot yield an item that is a discontinuous subset of the real number line.
Thus, for each I ∈initI (a, B), the upper bound of enabling is straightfor-
wardly characterised, which is important with respect to enforcing urgency
on i actions generated by hiding and sequential composition, see the discus-
sion of hiding later in this section.
As an example of the application of initI (a, B), the following two processes,
R1 := x [5] ; stop [] x [2, 4] ; stop
R2 := x ; stop [] x [2, 4] ; stop
would be interpreted as follows.
initI (x, R1) = { [5, 5] , [2, 4] }
initI (x, R2) = { [0, ∞) , [2, 4] }.

10.1 Branching Time Semantics
291
We have introduced initI in order to derive two other functions, which play
an important role in deﬁning the operational semantics of hiding (and, in-
deed, sequential composition). The ﬁrst identiﬁes the smallest initial instant
at which a particular action can be performed. That is, for A ⊆Act ∪{i, δ}
let
initI↓(A, B) ≜Min( 
a∈A initI (a, B))
We write initI ↓(a, B) for initI ↓({ a }, B) and we assume Min (∅) = ∞. We
also use the smallest of the set of all maximum time points at which an action
in a set of actions can initially be performed. Thus, for A ⊆Act ∪{i, δ},
initI↓↑(A, B) ≜Min( { ↑I | I ∈
a∈A initI (a, B) ∧I ̸= ∅} )
As illustration of these deﬁnitions, the two processes R1 and R2 introduced
earlier would be interpreted as follows.
initI↓(x, R1) = 2
initI↓(x, R2) = 0
initI↓↑(x, R1) = initI↓↑(x, R2) = 4
The relations −→and ; are the smallest relations that satisfy the inference
rules deﬁned below.
Stop / Inaction. This behaviour cannot perform any action, but permits
any amount of time to pass.
(tST)
stop
d; stop
This is consistent with the intuition that we have of what, in the untimed
setting, would have been called a deadlock. Such locks fail to oﬀer further
actions, but, it is important to note that they still allow time to pass. Thus,
they cannot stop time; i.e. generate timelocks; see Sections 9.4 and 10.2.4.
Successful Termination / Exit. The I in exit I governs the time points
at which the successful termination, marked δ, can occur. Thus, exit I can
perform a δ action if suﬃcient time has elapsed, i.e. if 0 ∈I. If time advances
by d time units, it evolves into exit (I ⊖d).
(tEX.i) exit I
δ−→stop (0 ∈I)
(tEX.ii)
exit I
d; exit (I ⊖d)
Rule (tEX.ii) implies that δ actions are not interpreted urgently. This is be-
cause nothing prevents the rule from being applied in a situation in which
d > ↑I. In which circumstance, exit I will become strongly equivalent to stop.
For example, exit [2, 10]
12
; exit ∅.

292
10 Semantic Models for tLOTOS
Observable Action Preﬁx. Because it is only internal actions that are
treated urgently, we consider external and internal action preﬁx separately.
As was the case for successful termination, x I ; B can perform x if 0 ∈I; i.e.
it is enabled at the current time point (see rule (tAP.i)). It allows any amount
of time to pass, with the possibility that x is no longer oﬀered. This will arise
if d >↑I, which ensures that 0 ̸∈(I ⊖d) = ∅, i.e. if time has passed beyond
the enabling of x.
(tAP.i) x I ; B
x
−→B (0 ∈I)
(tAP.ii)
x I ; B
d; x (I ⊖d) ; B
Internal Action Preﬁx. The diﬀerence between internal and external action
preﬁx is that internal actions are urgent. This is reﬂected in rule (tIAP.ii),
which allows delays up to ↑I, but not beyond. The only possibility to evolve
after a maximal delay is to perform i (whereas for the observable case the
possibility of further delay also exists; see rule (tAP.ii)). Thus, rule (tIAP.ii)
ensures that internal actions become urgent on the upper bound of their time
interval, which was the approach that we motivated in Section 9.2.10.
(tIAP.i)
i I ; B
i
−→B
(0 ∈I)
(tIAP.ii)
i I ; B
d; i (I ⊖d) ; B
(d ≤↑I)
Delay. Behaviour wait [t] B waits for t time units and then evolves into B. It
either waits for more than t time units in one step (rule (tD.iii)) or by delaying
precisely t time units, thus reaching wait [0] B (using rule (tD.ii)). When the
delay has been satisﬁed, the wait construct can perform action transitions
(rule (tD.i)).
(tD.i)
B
a
−→B′
wait [0] B
a
−→B′
(tD.ii)
wait [t] B
d; wait [t −d] B
(d ≤t)
(tD.iii)
B
d; B′
wait [t] B
d+t
; B′
Choice. The action rules for [] are as per the untimed case; see Section 3.3.2.2.
With regard to passing time, if B1 and B2 permit time to pass, then so will

10.1 Branching Time Semantics
293
their choice B1 [] B2. Note that, the passage of time cannot resolve choice.
However, time passing can cause action oﬀers to be retracted. Thus, in combi-
nation with the action preﬁx rules, we obtain a nonpersistent semantics. For
example, if
R := (x [2] ; B1) [] (y [4] ; B2)
then
R
3; B
where B is “strongly equivalent” to y [1] ; B2; i.e., because x has missed its
interval (/point) of enabling, the option to perform this branch disappears.
(tCH.i)
B1
a
−→B′
1
B1 [] B2
a
−→B′
1
B2 [] B1
a
−→B′
1
(tCH.ii)
B1
d; B′
1
B2
d; B′
2
B1 [] B2
d; B′
1 [] B′
2
Notice, for presentational simplicity we combine the two symmetric action
rules into a single rule (tCH.i). We use the same format in rule (tPA.i) for
parallel composition.
Parallel Composition. As was the case for choice, B1 |[G]| B2 allows time to
pass by some amount, if both components permit that evolution of time. Thus,
parallel components synchronise on the passage of time (rule (tPA.iii)). In
addition, parallel components may perform actions not in the synchronisation
set G ∪{δ} independently (rule (tPA.i)), whereas, if both B1 and B2 can
participate in a synchronisation action, x ∈G∪{δ}, then so can their parallel
composition (rule (tPA.ii)).
(tPA.i)
B1
a
−→B′
1
B1 |[G]| B2
a
−→B′
1 |[G]| B2
B2 |[G]| B1
a
−→B2 |[G]| B′
1
(a ̸∈G ∪{δ})
(tPA.ii)
B1
x
−−→B′
1
B2
x
−−→B′
2
B1 |[G]| B2
x
−→B′
1 |[G]| B′
2
(x ∈G ∪{δ})
(tPA.iii)
B1
d; B′
1
B2
d; B′
2
B1 |[G]| B2
d; B′
1 |[G]| B′
2
Relabelling. If B can perform action a and evolve into B′, then B[H] can
perform H(a) and evolve into B′[H] (tRL.i), whereas the passage of time is
unaﬀected by relabelling (tPA.ii).
(tRL.i)
B
a
−→B′
B[H]
H(a)
−−−−→B′[H]
(tRL.ii)
B
d; B′
B[H]
d; B′[H]

294
10 Semantic Models for tLOTOS
Hiding. This operator is strongly aﬀected by the choices made concerning
urgency, because, eﬀectively, it turns nonurgent (observable) actions into ur-
gent (hidden) ones. However, the action rules are inherited unchanged from
the untimed case. That is, any actions that B can perform, can also be per-
formed by hide G in B, subject to actions in the hiding set being turned into
internal actions (rules (tHD.i) and (tHD.ii)). Because hidden actions become
urgent on their upper bound (see Section 9.2.10) time cannot pass beyond this
bound. This is reﬂected in rule (tHD.iii), which allows hide G in B to pass
time by d time units only if there is no hidden action that must be performed
earlier.
(tHD.i)
B
x
−−→B′
hide G in B
i
−→hide G in B′ (x ∈G)
(tHD.ii)
B
a
−→B′
hide G in B
a
−→hide G in B′ (a ̸∈G)
(tHD.iii)
B
d; B′
hide G in B
d; hide G in B′ (d ≤initI↓↑(G, B))
As an example of how (tHD.iii) “prunes” the passage of time in order to
enforce urgency, consider the following behaviour,
P := ( x [5, 10] ; D ) [] ( y [12, 15] ; D′ )
Now, not only can P (initially) pass time by 10 time units, it can also pass time
by 15 and, indeed, it will have a transition P
d; for any d ∈R+. This is the
nonpersistent interpretation we have alluded to a number of times. However,
hide x in P
can only pass time up to 10 time units, at which point, it must perform the
internal action that has arisen from hiding x. As a result, hide x in P can
never perform a y.
Notice that internal actions inherited from B do not have to be explicitly
treated in (tHD.iii), because their urgency will be taken into account in the
delay that B allows, i.e. the premise of rule (tHD.iii). For example, if,
Q := ( i [5, 10] ; B ) [] ( y [12, 15] ; B′ )
then
hide y in Q
will only be able to initially pass time by 10 time units, which was also the
case for Q.

10.1 Branching Time Semantics
295
It is also important to note that the appropriate smallest interval upper
bound, which governs (tHD.iii) and, thus, the enforcement of urgency has to
be carefully considered. For example, consider R1 and R2, which we introduced
earlier in this section. That is
R1 := x [5] ; stop [] x [2, 4] ; stop
R2 := x ; stop [] x [2, 4] ; stop
In addition, consider
S1 := hide x in R1
S2 := hide x in R2
Now, (tHD.iii) ensures that,
∀d > 4, S1 ̸
d; ∧S2 ̸
d;,
because,
initI↓↑(x, R1) = initI↓↑(x, R2) = 4
This interpretation is justiﬁed because we wish urgency created through ex-
plicit reference to i actions and through hiding to behave consistently. For
example, for,
T1 := i [5] ; stop [] i [2, 4] ; stop
T2 := i ; stop [] i [2, 4] ; stop
we would expect T1 and S1 to be behaviourally indistinguishable and similarly
T2 and S2. However, this is only the case if S1 and S2 cannot pass time beyond
4 time units, which our use of initI↓↑in (tHD.iii) ensures. Note, in fact,
S1 ∼t S2 ∼t T1 ∼t T2 ∼t ( i [2, 4] ; stop ),
where ∼t denotes timed strong bisimulation equivalence, which we will in-
troduce shortly (see Section 10.1.3). It is also important to note that this
interpretation of urgency in hiding contexts is consistent with the interpreta-
tion arising from timed bundle event structures, see Section 10.2.
You should also notice that, as discussed in Section 9.2.10, this handling
of hidden actions is diﬀerent to the approach taken in ET-LOTOS [126] and
in E-LOTOS [102]. In both of these, strict maximal progress is enforced on
hidden actions. Thus, time can only pass up to the lower bound of the ﬁrst
enabled hidden action.
However, our semantics could be adjusted to bring them into line with
these other approaches, yielding a pure maximal progress handling of hiding.
We could do this by replacing (tHD.iii) with the following rule,

296
10 Semantic Models for tLOTOS
B
d; B′
hide G in B
d; hide G in B′ (d ≤initI↓(G, B))
Enabling. Action transitions of B1 >> B2 are the same as those of the
untimed case: if B1 can evolve to B′
1, by performing a (a ̸= δ), then B1 >> B2
can do the same, and evolve into B′
1 >> B2. In addition, if B1 successfully
terminates, control passes to B2. If B1 can pass time by d time units then, as
long as d does not pass beyond the upper bound of enabling of δ, B1 >> B2
can also pass d time units. Thus, we allow the passage of time as long as the
internal action resulting from the implicit hiding of the successful termination
of B1 (when control is passed to B2) must not occur earlier. Notice that we
maintain our policy that internal actions should become urgent on the upper
bound of their enabling. Again this contrasts with the approach of ET-LOTOS
and E-LOTOS.
(tEN.i)
B1
a
−→B′
1
B1 >> B2
a
−→B′
1 >> B2
(a ̸= δ)
(tEN.ii)
B1
δ
−→B′
1
B1 >> B2
i
−→B2
(tEN.iii)
B1
d; B′
1
B1 >> B2
d; B′
1 >> B2
(d ≤initI↓↑(δ, B1))
Process Instantiation. The rules for process instantiation are a straightfor-
ward extrapolation from the untimed rules.
(PI.i) B
a
−→B′
P
a
−→B′ (P := B)
(PI.ii) B
d; B′
P
d; B′ (P := B)
It is straightforward to derive a timed transition system from a tLOTOS
behaviour using these inference rules. In particular, exactly the same steps as
were used at the end of Section 3.3.2.2 to derive a labelled transition system
from a pbLOTOS behaviour, could be applied in this context.
Properties of Operational Semantics. There are a number of properties
satisﬁed by the timed transition systems that these inference rules generate.
These are relatively standard “well behavedness” properties.
The ﬁrst of these is time continuity (also often called time additivity,
e.g. [126]); it states that a behaviour can pass time by a certain amount if and
only if it can pass time by any intermediate amount and reach a state from
which it can pass time the remaining amount.

10.1 Branching Time Semantics
297
Proposition 11
(Time Continuity)
∀B1, B2, ∀d1, d2 ∈R+ , ( ( ∃B . B1
d1
; B ∧B
d2
; B2 ) ⇔B1
d1+d2
;
B2 )
Proof
We proceed by induction on the structure of B1.
Base Case. The axioms of the inference system (i.e. the rules without hypothe-
ses) give the base cases, that is, the rules for Inaction, Successful Termination,
Observable Action Preﬁx and Internal Action Preﬁx. These all hold straight-
forwardly. However, by way of illustration, we give the proof for internal action
preﬁx.
So, take B1, B2, D ∈tBeh, d1, d2 ∈R+ and assume that B1 = i I ; D; we
can argue as follows.
( B1
d1
; B ∧B
d2
; B2 )
⇔
{ by rule (tIAP.ii) }
( B = i (I ⊖d1) ; D ) ∧( B2 = i ((I ⊖d1) ⊖d2) ; D ) ∧
( d1 ≤↑I ) ∧( d2 ≤↑(I ⊖d1) )
⇔
{ mathematics }
( B2 = i (I ⊖(d1+d2)) ; D ) ∧( (d1+d2) ≤↑I )
⇔
{ by rule (tIAP.ii) }
B1
d1+d2
;
B2
Inductive Case. Now we consider the nonaxiomatic rules of the inference sys-
tem, i.e. Delay, Choice, Parallel Composition, Relabelling, Hiding, Enabling
and Process Instantiation. Very similar inductive arguments can be applied in
all these cases. By way of illustration, we consider the argument for parallel
composition.
So, take B1, B2, D1, D2, D′
1, D′
2, D′′
1, D′′
2 ∈tBeh, d1, d2 ∈R+ and assume
that B1 = D1 |[G]| D2; we can argue as follows.
( B1
d1
; B ∧B
d2
; B2 )
⇔
{ by rule (tPA.iii) }
( B = D′
1 |[G]| D′
2 ) ∧( B2 = D′′
1 |[G]| D′′
2 ) ∧
( D1
d1
; D′
1 ) ∧( D2
d1
; D′
2 ) ∧( D′
1
d2
; D′′
1 ) ∧( D′
2
d2
; D′′
2 )
⇔
{ inductive hypothesis }
( B2 = D′′
1 |[G]| D′′
2 ) ∧( D1
d1+d2
;
D′′
1 ) ∧( D2
d1+d2
;
D′′
2 )
⇔
{ by rule (tPA.iii) }
B1
d1+d2
;
B2
The result follows.
⃝

298
10 Semantic Models for tLOTOS
In addition, as discussed in Section 9.2.4, the following property demonstrates
that the time-passing transitions generated from our semantics cannot create
nondeterminism; i.e. it is not possible to evolve to two diﬀerent states with
identically timed transitions.
Proposition 12
(Time Determinism)
∀B1, B2, B, ∀d ∈R+ , (B
d; B1 ∧B
d; B2 ⇒B1 = B2).
Proof
We proceed by induction on the structure of B.
Base Case. The axioms of the inference system give the base cases, that is,
the rules for Inaction, Successful Termination, Observable Action Preﬁx and
Internal Action Preﬁx. These all hold straightforwardly. However, by way of
illustration, we give the proof for internal action preﬁx.
So, take B1, B2, B ∈tBeh and d ∈R+; we can argue as follows.
i I ; B
d; B1 ∧i I ; B
d; B2
⇒
{ by rule (tIAP.ii) }
B1 = i (I ⊖d) ; B ∧B2 = i (I ⊖d) ; B ∧d ≤↑I
⇒
{ syntactic equality }
B1 = B2
Inductive Case. Now, we consider the nonaxiomatic rules of the inference sys-
tem, i.e. Delay, Choice, Parallel Composition, Relabelling, Hiding, Enabling
and Process Instantiation. Very similar inductive arguments can be applied in
all these cases. By way of illustration, we consider the argument for parallel
composition.
So, take B1, B2, B′
1, B′
2, B′′
1 , B′′
2 , D1, D2 ∈tBeh and d ∈R+; we can argue
as follows.
B1 |[G]| B2
d; D1 ∧B1 |[G]| B2
d; D2
⇒
{ by rule (tPA.iii), we know the form of D1 and D2 }
( B1 |[G]| B2
d; D1 ) ∧( B1 |[G]| B2
d; D2 ) ∧
( D1 = B′
1 |[G]| B′
2 ) ∧( D2 = B′′
1 |[G]| B′′
2 )
⇒
{ by rule (tPA.iii) }
( B1
d; B′
1 ) ∧( B2
d; B′
2 ) ∧( B1
d; B′′
1 ) ∧( B2
d; B′′
2 ) ∧
( D1 = B′
1 |[G]| B′
2 ) ∧( D2 = B′′
1 |[G]| B′′
2 )
⇒
{ by inductive hypothesis }
( B′
1 = B′′
1 ) ∧( B′
2 = B′′
2 ) ∧
( D1 = B′
1 |[G]| B′
2 ) ∧( D2 = B′′
1 |[G]| B′′
2 )
⇒
{ syntactic equality }
D1 = D2

10.1 Branching Time Semantics
299
The result follows.
⃝
Finally, as discussed in Section 9.2.3, tLOTOS is not action persistent.
Proposition 13
(Not Action Persistent)
The following does not hold.
∀B, B′, d ∈R+, ∀a ∈Act ∪{i} , ( B
d; B′ ∧B
a
−→
=⇒B′
a
−→)
Proof
By example, for B = x [0, 5] ; stop, it is clear that B
6; B′, where our inference
rules ensure that B′ = x ∅; stop and ¬(B′
x
−−→), whereas B
x
−−→.
⃝
10.1.3 Branching Time Development Relations
The need to deﬁne equivalence and, more generally, preorder relations be-
tween speciﬁcations, still applies in the timed setting. In particular, syntactic
correspondence of speciﬁcations is again much too strong. In fact, the prob-
lem is accentuated by the addition of timing constraints and there are many
speciﬁcations that are behaviourally equivalent (informally denoted ≡here)
even though the syntax of their timing diﬀers. For example, for
P1 := wait [0] stop
and
P2 := wait [2] stop
and
P3 := stop
we have
P1 ≡P2 ≡P3
Thus, it is necessary to deﬁne timed counterparts to the equivalences that
we introduced in Section 3.3.3. We do not though consider (nonequivalence)
preorders in this timed setting. This is because little work on such reﬁnement
relations has been undertaken in the timed LOTOS domain. Although, failure-
based reﬁnement for timed CSP has been explored; see [176].
Returning to the issue of equivalences, many such relations have in fact
been explored in the timed process calculus domain, e.g. timed traces [176],
timed failures [176], etc. However, here we restrict ourselves to consideration
of bisimulation equivalences.
In fact, it turns out that the strong and weak bisimulation deﬁnitions that
we already have can be almost directly reused in the timed setting. This is
because, in timed transition systems, both time passing and action oﬀering
are expressed in terms of transitions. Consequently, if we wish to ensure that
the timing behaviour from two states is equivalent, we can match up time
passing transitions in a similar way to how we matched up action transitions
in the untimed setting, Section 3.3.3.1.

300
10 Semantic Models for tLOTOS
Deﬁnition 39
(Timed Strong Bisimulation Relations)
A binary relation R ⊆tBeh×tBeh is a timed strong bisimulation if whenever
(B1, B2) ∈R the following holds ∀v ∈Act ∪{i, δ} ∪R+,
1. ∀B′
1 ∈tBeh, B1
v
−→→B′
1 =⇒∃B′
2 ∈tBeh . B2
v
−→→B′
2 ∧(B′
1, B′
2) ∈R ∧
2. ∀B′
2 ∈tBeh, B2
v
−→→B′
2 =⇒∃B′
1 ∈tBeh . B1
v
−→→B′
1 ∧(B′
1, B′
2) ∈R.
The only diﬀerence to the (untimed) deﬁnition of strong bisimulation (Deﬁni-
tion 4 in Section 3.3.3.1) is that we need to ensure that both time and action
transitions are matched; we do this by using a relation −→→, which is deﬁned
as follows,
−→→≜; ∪−→
and by quantifying v over time values as well as actions.
Furthermore, in the standard way, we take as our equivalence, the largest
relation that satisﬁes Deﬁnition 39.
Deﬁnition 40
(Timed Strongly Bisimilar)
Two behaviours B and B′ are timed strongly bisimilar, denoted B ∼t B′, if
there exists a timed strong bisimulation relation R, such that B R B′, or,
equivalently,
∼t ≜{ R | R is a timed strong bisimulation relation }
It is clear that ∼t is indeed an equivalence relation.
As an illustration of this relation, with regard to the examples at the be-
ginning of this section, P1 ∼t P2 ∼t P3. In particular, to justify P1 ∼t P3,
observe that { (wait [0] stop , stop ) , ( stop , stop ) } is a timed strong bisimu-
lation, because wait [0] stop can pass any length of time and evolve to stop. In
addition, to see that P2 ∼t P3, you should note that the following is a timed
strong bisimulation { (wait [d] stop , stop ) | 0 ≤d ≤2 } ∪{ ( stop , stop ) } and
P1 ∼t P2 can be shown in a similar way or using transitivity and symmetry
of ∼t.
In the same way as was discussed in depth in Section 3.3.3, ∼t induces
a strong notion of identity, which equivalently matches internal as well as
external behaviour in the two speciﬁcations. The same issues concerning the
need for a weak matching of i actions apply in the timed setting and thus, we
consider timed weak bisimulation.
However, before we can give our deﬁnition, we need to adapt the relation,
σ
=⇒⇒⇒, which we introduced in Section 3.3.3, to accommodate the passage of
time (related deﬁnitions can be found in Leonard [124]). Thus, assuming that
d, d1, . . . , dn ∈R+ and σ ∈T we deﬁne =⇒⇒⇒t as follows.
B1
d
=⇒⇒⇒t B2 iﬀB1(
ϵ
=⇒)
d1
; (
ϵ
=⇒)
d2
; . . .
dn
; (
ϵ
=⇒)B2 ∧d = Σ
1≤j≤n dj
B1
σ
=⇒⇒⇒t B2 iﬀB1
σ
=⇒⇒⇒B2

10.1 Branching Time Semantics
301
Thus, not only can
σ
=⇒⇒⇒t run over internal actions, so can
d
=⇒⇒⇒t. However,
in the latter case, we also have to ensure that the accumulated delays sum
appropriately.
We deﬁne timed weak bisimulation in the obvious way.
Deﬁnition 41
(Timed Weak Bisimulation Relations)
A binary relation S ⊆tBeh × tBeh is a timed weak bisimulation if whenever
(B1, B2) ∈S it follows that ∀v ∈Act ∪{i, δ} ∪R+,
1. ∀B′
1 ∈tBeh, B1
v
−→→B′
1 =⇒∃B′
2 ∈tBeh . B2
v
=⇒⇒⇒t B′
2 ∧(B′
1, B′
2)∈S ∧
2. ∀B′
2 ∈tBeh, B2
v
−→→B′
2 =⇒∃B′
1 ∈tBeh . B1
v
=⇒⇒⇒t B′
1 ∧(B′
1, B′
2)∈S.
As was the case for timed strong bisimulation, there can be many timed weak
bisimulation relations between pairs of speciﬁcations. So, once again, we take
as our equivalence relation, the largest relation which satisﬁes Deﬁnition 41.
Deﬁnition 42
(Timed Weakly Bisimilar)
Two behaviours B and B′ are timed weakly bisimilar, denoted B ≈t B′ if there
exists a timed weak bisimulation relation S such that B S B′, or, equivalently,
≈t ≜{ S | S is a timed weak bisimulation relation }
As an example of this relation at work, consider the following two processes.
Q1 := i [2] ; i [0, 2] ; x ; stop
and
Q2 := i [2, 4] ; x ; stop
Depictions of timed transition systems of these processes are shown in Figure
10.3.3 In particular, the reader should note that the two states marked * in
the left-hand transition system are both timed weakly bisimilar to the state
marked + in the right-hand transition system.
As a justiﬁcation of the use of the term strong and weak, it is clear that
∼t ⊂≈t
In particular, any timed strong bisimulation relation also satisﬁes the deﬁni-
tion of timed weak bisimulation and, for example,
i ; stop ≈t stop,
but
i ; stop ̸∼t stop
We also consider a generalisation of weak bisimulation congruence, which we
discussed in Deﬁnition 8 of Section 3.3.3.1. This new equivalence is called
timed rooted weak bisimulation. The reason that we do not use the term
congruence here is discussed in Section 14.7 in the appendix.
3Although, due to the continuous nature of the time domain, it is often diﬃcult to
represent timed behaviours perfectly accurately. Thus, ﬁgures such as these should
be taken as approximate (schematic) depictions.

302
10 Semantic Models for tLOTOS
2
i
2
i
Q
1
2
i
x
2
Q
2
action transitions
time passing transitions
*
*
+
time
actions
actions
time
x
. . .
. . .
. . .
. . .
. . .
. . .
Fig. 10.3. Depiction of Timed Transition Systems for Weakly Bisimilar Processes
Deﬁnition 43
(Timed Rooted Weak Bisimulation)
A binary relation S ⊆tBeh × tBeh is a timed rooted weak bisimulation if
(B1, B2) ∈S implies ∀a ∈Act ∪{i, δ}, d ∈R+,
1. ∀B′
1 ∈tBeh,
a) B1
d
−→→B′
1 =⇒∃B′
2 ∈tBeh . B2
d; B′
2 ∧(B′
1, B′
2) ∈S ∧
b) B1
a
−→→B′
1 =⇒∃B′
2 ∈tBeh . B2
a
=⇒⇒B′
2 ∧B′
1 ≈t B′
2 and
2. ∀B′
2 ∈tBeh,
a) B2
d
−→→B′
2 =⇒∃B′
1 ∈tBeh . B1
d; B′
1 ∧(B′
1, B′
2) ∈S ∧
b) B2
a
−→→B′
2 =⇒∃B′
1 ∈tBeh . B1
a
=⇒⇒B′
1 ∧B′
1 ≈t B′
2.
In addition, in standard fashion, we deﬁne timed rooted weak bisimulation as
follows.
Deﬁnition 44
(Timed Rooted Weak Bisimilar)
Two behaviours B and B′ are timed rooted weak bisimilar, denoted B ≈t
r B′,
if there exists a timed rooted weak bisimulation relation S such that B S B′,
or equivalently,
≈t
r ≜{ S | S is a timed rooted weak bisimulation relation }
As an explanation of this deﬁnition we have the following points.

10.1 Branching Time Semantics
303
1. By analogy with the untimed case, we match B1
a
−→→B′
1 with B2
a
=⇒⇒B′
2
and then require B′
1 ≈t B′
2. This ensures that initial i transitions are not
mapped to
ϵ
=⇒, as justiﬁed late in Section 3.3.3.1 (the discussion of weak
bisimulation congruence).
2. We match B1
d
−→→B′
1 with B2
d; B′
2 and require (B′
1, B′
2) ∈S, rather
than matching to B2
d
=⇒⇒⇒t B′
2 and requiring B′
1 ≈t B′
2, since skipping
over initial i transitions, when passing time, would prevent substitutiv-
ity in choice contexts. As an illustration of this, if it were the case that
B1
d
−→→B′
1 was matched with B2
d
=⇒⇒⇒t B′
2 and B′
1 ≈t B′
2 then, for exam-
ple, with the following deﬁnitions,
Q1 := wait [2] x ; stop
Q2 := wait [2] i ; x ; stop
C[.] ≜[.] [] y ; stop
Q1 and Q2 would be equivalent, but C[Q1] and C[Q2] would not be equiv-
alent. To illustrate this, we can see that
C[Q1]
3; Q ∼t ( ( x ; stop ) [] ( y ; stop ) )
but,
∀R ∈tBeh, ( C[Q2]
3
=⇒⇒⇒t R =⇒( R ∼t x ; stop ∧Q ̸∼t R ) )
In response to this issue, we strongly match all initial time transitions
and also require (B′
1, B′
2) ∈S (i.e., timed rooted weak bisimilar), rather
than B′
1 ≈t B′
2, because we want to ensure that an initial i action, even
when preceded by a delay, is matched by “proper” i (rather than
ϵ
=⇒)
derivations. That is, we strongly match time passing transitions, until the
ﬁrst discrete / action transition is reached, after which we enforce the
more liberal ≈t relationship.
We have the following simple relationship between the weak bisimulation re-
lations we are considering
Proposition 14
≈t
r ⊂≈t
Proof
This follows because,
∀d ∈R+,
d; ⊂
d
=⇒⇒⇒t
and,
∀a ∈Act ∪{i, δ},
a
=⇒⇒⊂
a
=⇒⇒⇒t,
which is as required.
⃝

304
10 Semantic Models for tLOTOS
10.2 True Concurrency Semantics
10.2.1 Introduction
The work presented here is based upon previous work on true concurrency
semantics for timed LOTOS, e.g. [32,39,51,108,109]. The thread of research
represented by these publications took much of its impetus from Katoen’s
PhD thesis [107], although similar ideas were independently developed by
Bowman et al [32,39]. We begin by reiterating the motivation for giving true
concurrency semantics to process calculi; see Chapter 4 for a more detailed
justiﬁcation.
Interleaved semantics reﬂect the extensionalist [147] view that formal spec-
iﬁcation should just describe the “observable behaviour” of systems. This in-
herently means that some aspects of causality are abstracted away from. For
example, the following two behaviours would be identiﬁed,
x ; y ; stop [] y ; x ; stop
and
x ; stop ||| y ; stop
even though the ﬁrst contains two causalities, an instance of action x causing
an instance of action y and an instance of action y causing an instance of
action x, and the second contains no causalities. Abstracting, in this way,
from the internal relationships between components ﬁts well into early phases
of system development, such as the speciﬁcation stage. Such phases typically
involve the description of the global observable behaviour of systems and this
is exactly what interleaved approaches model.
However, at later stages of system development, explicit links to implemen-
tations have to be made. At these stages, semantic models must be capable
of modelling the decomposition of systems into components, which each have
their own local state. In other words, they must accurately reﬂect the dis-
tribution aspects of the system under development. True concurrency models
reﬂect such nonglobal interpretation; they are often categorised as intension-
alist, because they model the internal decomposition of systems. A further
beneﬁt of true concurrency models is that, when exhaustive state exploration
is being undertaken, such models limit the state-space explosion problem: par-
allel composition generates the sum of the component’s states as opposed to
the product, which is the case with interleaving semantics.
The motivation for true concurrency models carries over to the real-time
setting. In fact, it has been argued that the incorporation of real-time prop-
erties ﬁts naturally with both the move to true concurrency models and with
the focus on lower levels of system development [36,78,107]. In order to realise
the beneﬁts of the true concurrency approach in the timed LOTOS setting,
we present a true concurrency semantics for tLOTOS.
We build our timed true concurrency model from the bundle event struc-
tures semantics that we introduced in Section 4. The approach is inspired by
the (several) real-time enhancements to bundle event structures to be found
in the literature [32,39,51,108,109], Katoen’s thesis being a particular source
of inspiration [107].

10.2 True Concurrency Semantics
305
10.2.2 Timed Bundle Event Structures
There are two aspects to adding time to bundle event structures. Firstly, to
deﬁne delays between causally related events, time is associated with bundles,
and, secondly, in order to enable timing of events that have no incoming
bundles (i.e., the initial events of a timed bundle event structure), time is also
associated with events.4
Deﬁnition 45
(Timed Bundle Event Structure)
A timed bundle event structure has the form ⟨ε, A, R⟩, where
•
ε is a bundle event structure (E, #, →, l)
•
A : E −→Ξ, is an event-timing function
•
R : →−→Ξ, is a bundle-timing function, and
for ease of presentation, we sometimes write, ⟨E, #, →, l, A, R⟩, as a short-
hand for ⟨ε, A, R⟩and ε = (E, #, →, l).
We denote the set of Timed Bundle Event Structures as TBES. Note, event
timing speciﬁes a time relative to the start of the TBES, which is assumed
to be time zero. In contrast, bundle-timings specify time relative to a causal
predecessor.
A bundle X →e where R((X, e)) = I is denoted X
I→e. When dia-
grammatically represented, bundle and event timings are depicted near to
the corresponding bundle and event, respectively. In addition, intervals of the
form [0, ∞) are usually omitted and intervals [t, ∞) are abbreviated to t.
An example timed bundle event structure is shown in ﬁgure 10.4(2). This
is a timed extension of the bundle event structure in Figure 10.4(1). More
precisely, we have the following event timings, A(ei) = [2, 8], A(ey) = [5, 10]
and A(ew) = [4, ∞) and the following bundle timings, R(({ ei, ey }, ez)) =
[10, ∞) and R(({ ew }, ev)) = [2, ∞) 5.
What though do these timings intuitively mean? Well, an event can only
happen when all its bundle and event timing constraints are satisﬁed; e.g.
A(ez) = I constrains ez to happen at a time tz ∈I from the beginning of the
execution of the system, which is assumed to be time 0. Suppose, in addition,
that there is a single bundle entering ez, which is such that
{ ex }
I′
→ez
Assuming that ex happens at time tx, this bundle further constrains the oc-
currence of ez to any tz such that tz ∈tx ⊕I′. Thus, I′ speciﬁes the relative
delay between ex and ez. Now, putting these two timing constraints together,
we get that tz ∈(tx ⊕I′) ∩I, which characterises the timing of ez. Further
4An alternative to event delays is to explicitly model the start of the system by
a “ﬁctitious” event; see [32].
5For presentational ease, where it does not cause confusion, we represent events
by their labelling, while noting that this is, of course, informal.

306
10 Semantic Models for tLOTOS
i
y
10
z
i
y
z
(2)
[5,10]
(1)
4
v
w
[2,8]
v
w
2
Fig. 10.4. Example Timed Bundle Event Structure
note that, if the intersection of a number of interval timing constraints is
empty, then that event can never happen.
The notion of timed proving sequence (called a timed event sequence in
[47]) formalises this intuition; it is a (timed) generalisation of the notion of a
proving sequence; see Deﬁnition 15 in Section 4.2. However, before deﬁning
this concept we introduce some notation.
Firstly, let (e, t) denote that e happened at (absolute) time t. For sequences
of timed events σ = (e1, t1) . . . (en, tn), let [σ] denote the (untimed) proving
sequence of σ; i.e. [σ] ≜e1 . . . en.
Now, the following concepts were deﬁned in Deﬁnition 15 in Section 4.2.
For an (untimed) proving sequence ρ, cﬂ(ρ) is the set of events that are
disabled by some event in ρ and sat(ρ) is the set of events that have a causal
predecessor in ρ for all incoming bundles. That is, for events in sat(ρ), all
bundles (i.e. causal constraints) are “satisﬁed”.
We use en(ρ), which is deﬁned in terms of cﬂand sat. It characterises
the set of events enabled after ρ and is deﬁned as follows en(ρ) ≜sat(ρ) \
(cﬂ(ρ) ∪$ρ).
Now, assuming that σ is a timed proving sequence, Z(σ, e) (which has its
roots in Katoen’s PhD thesis [107]) is used to denote the set of time instants
at which e ∈en([σ]) could happen, given that each event ej in σ occurred at
time tj. Thus, event e can occur if,
1. the event delay, A(e), is satisﬁed, and

10.2 True Concurrency Semantics
307
2. the bundle delays from all immediate causal predecessors are satisﬁed.
Formally, with regard to a timed bundle event structure, ⟨ε, A, R⟩, Z is deﬁned
as follows.
Z(σ, e) ≜ ({ A(e) } ∪H)
where,
H ≜{ tj ⊕I | ∃X ⊆E . ( X
I→e ∧X ∩$[σ] = { ej } ) }
where A(e) represents the ﬁrst constraint above and H represents the second.
Notice that H is a set of intervals, one per incoming bundle. Consistent with
our intuition, Z(σ, e) is obtained by intersecting the interval constraint A(e)
with the interval constraints arising from H.
A timed proving sequence is now deﬁned as follows, where we have the
convention that Max (∅) = ∞and, also, recall that the preﬁx of σ up to the
j −1st element is denoted σj.
Deﬁnition 46
(Timed Proving Sequence)
σ = (e1, t1) . . . (en, tn) is a timed proving sequence of Ψ = ⟨ε, A, R⟩if and
only if, for all k (0 < k ≤n), ek ∈E, tk ∈R+0, and,
1. e1 . . . en is a proving sequence of ε, by Deﬁnition 15 in Section 4.2,
2. ∀j . ( k < j =⇒tk ≤tj ),
3. tk ∈Z(σk, ek), and
4. ∀e ∈en([σk]) , ( l(e) = i =⇒tk ≤Max(Z(σk, e)) ).
The ﬁrst condition ensures consistency with the untimed model; i.e. if all
timings are deleted from σ, a proving sequence of ε is obtained. The second
condition requires time consistency, i.e. that time does not decrease through
the sequence,6 and the third requires that events happen at one of their pos-
sible timings. The ﬁrst three conditions do not recognise the possibility that
urgent events may prevent other events from occurring at certain times. The
last condition enforces such urgency. It states that trace σk may be extended
by (ek, tk) if and only if there is no urgent (i.e., internal) event enabled after
σk that must occur earlier than ek.
By way of illustration, the (nonempty) timed proving sequences of the
timed bundle event structure in Figure 10.5 are (ei, t), where 2 ≤t ≤6,
(ex, t), where 5 ≤t ≤6 and (ex, t) (ey, t′), where 5 ≤t ≤6 and t ≤t′. Notice
that, for example, (ex, 7) is not a timed proving sequence, because the event
labelled i will be forced at time 6, thus disabling ex.
6Although, consistently with all our timed models, time can stay the same be-
tween adjacent points in the sequence, reﬂecting that multiple events / actions can
occur at the same time instant.

308
10 Semantic Models for tLOTOS
y
i
[2,6]
x
5
Fig. 10.5. Example Timed Bundle Event Structure for Consideration of Urgency
in Timed Proving Sequences
10.2.3 Causal Semantics for tLOTOS
In this section we present a noninterleaving semantics for tLOTOS using timed
bundle event structures. We deﬁne a mapping,
J Ktbe : tLOTOS −→TBES
This mapping is based upon the semantics given in [47] and [46]. Many of these
deﬁnitions ﬁrst appeared in Katoen’s thesis [107]. The top-level machinery
of the semantics is the same as that presented for (untimed) bundle event
structures. Thus, we deﬁne:
J B Ktbe ≜B′′J B K(∅)
J B where D Ktbe ≜B′′J B K(DJ D K)
where D is as deﬁned in Section 3.2.2.2; i.e.
DJ (P := B) K ≜{P := B}
DJ (P := B) D K ≜{P := B} ∪DJ D K
Throughout these semantics, for an arbitrary TBES, Ψ = ⟨E, #, →, l, A, R⟩,
we use init(Ψ), which denotes the set of initial events of Ψ; exit(Ψ), which
denotes the set of successful termination events; and res(Ψ), which denotes
the events whose timing is restricted. The deﬁnitions of init and exit in Section
4.4 are lifted to timed bundle event structures in the obvious way, whereas
res(Ψ) ≜{ e ∈E | A(e) ̸= R+0 }, i.e. the set of events that do not have a
completely unrestricted timing. Furthermore, we abbreviate init(Ψ) ∪res(Ψ)
by rin(Ψ). As previously, UE denote the universe of events.

10.2 True Concurrency Semantics
309
The main part of the semantics is the interpretation of behaviour expres-
sions. Thus, in the rest of this section we assume that B′′J B1 K(d) = Ψ1 =
⟨ε1, A1, R1⟩with ε1 = (E1, #1, →1, l1) and B′′J B2 K(d) has a corresponding
format. Furthermore, for B1 and B2 we assume that E1 ∩E2 = ∅; in case of
name clashes, renaming can be used to obtain this property.
10.2.3.1 Inaction, Successful Termination and Action Preﬁx
These are deﬁned as follows.
B′′J stop K(d) ≜⟨∅, ∅, ∅, ∅, ∅, ∅⟩
B′′J exit I K(d) ≜⟨{ e }, ∅, ∅, { (e, δ) }, { (e, I) }, ∅⟩
where e ∈UE
B′′J a I ; B1 K(d) ≜⟨E, #1, →, l, A, R⟩
where
E = E1 ∪{ e }
for, e ∈UE \ E1
→= →1 ∪({ { e } } × rin(Ψ1))
l = l1 ∪{ (e, a) }
A = { (e, I) } ∪(E1 × { R+0 })
R = R1 ∪{ (({ e }, e′), A1(e′)) | e′ ∈rin(Ψ1) }
Thus, stop yields the empty timed bundled event structure and exit I is
mapped to a single event, labelled δ with timing I.
With regard to a I ; B1, a bundle is added from a new event e (labelled
a) to events in Ψ1 that are, either, initial (e will now causally precede these
events) or time-restricted. For all such initial and time-restricted events, e′ say,
the delay is now relative to e, so a time delay A1(e′) is associated with each
bundle { e } →e′ and A(e′) becomes R+0; i.e. e′ becomes time-unrestricted.
In addition, I becomes the timing of e.
It is suﬃcient in the untimed case to introduce only bundles from e to the
initial events of Ψ1; c.f. Section 4.2. However, in the timed case, new bundles
to time-restricted events of Ψ1 are used to make delays relative to e. Notice
that the above construction applies to both observable and internal events.
As an example, Figure 10.6(b) provides the semantics of x [5, 6] ; P, where
the semantics of P is given as Figure 10.6(a). The following behaviour would
yield an event structure consistent with ﬁgure 10.6(a).
P := ( ( y (2) ; z (8) ; ( w (2) ; stop ||| exit (18) ) )
|[w]| w [8, 25] ; stop )
||| i [12, 14] ; v ; stop

310
10 Semantic Models for tLOTOS
(a)
y
2
8
z
2
[8,25]
18
i
[12,14]
v
(b)
2
z
8
y
2
[5,6]
[12,14]
i
v
18
x
[8,25]
w
δ
w
δ
Fig. 10.6. Semantics of Action Preﬁx
10.2.3.2 Delay, Hiding and Relabelling
The semantics for these constructs are as follows.
B′′J wait [d] B1 K(d) ≜⟨E1, #1, →1, l1, ((+d) ◦A1), R1⟩
B′′J hide G in B1 K(d) ≜⟨E1, #1, →1, l, A1, R1⟩
where ,
( l1(e) ∈G =⇒l(e) = i ) ∧
( l1(e) ̸∈G =⇒l(e) = l1(e) )
B′′J B1[H] K(d) ≜⟨E1, #1, →1, (H ◦l1), A1, R1⟩

10.2 True Concurrency Semantics
311
Semantically, wait [d] B1 is identical to B′′J B1 K(d), but with event delays in-
cremented by d (◦denotes function composition; i.e. f ◦g (x) = f(g(x))).
Bundle delays express relative delays between events, and, thus, are unaf-
fected. B′′J hide G in B1 K(d) simply takes B′′J B1 K(d) and turns events with
labels in G into internal events. B′′J B1[H] K(d) is identical to B′′J B1 K(d), but
with events relabelled according to H.
As an example of these denotational semantics, consider the timed bundle
event structure depicted in ﬁgure 10.7(a). After the hiding of actions y and v
the event structure of Figure 10.7(b) results.
[5,6]
[12,14]
2
[8,25]
2
z
8
y
i
v
18
[5,6]
[12,14]
[8,25]
(a)
z
8
i
2
i
i
18
x
x
w
δ
δ
w
(b)
2
Fig. 10.7. Example of Semantics for Hiding

312
10 Semantic Models for tLOTOS
10.2.3.3 Choice
The semantics of choice are straightforward.
B′′J B1 [] B2 K(d) ≜⟨E1 ∪E2, #, →1 ∪→2, l1 ∪l2, A1 ∪A2, R1 ∪R2⟩
# = #1 ∪#2 ∪(init(Ψ1) × init(Ψ2))
B′′J B1 [] B2 K(d) takes the componentwise union of B′′J B1 K(d) and B′′J B2 K(d)
subject to the addition of conﬂicts between initial events of B′′J B1 K(d) and
B′′J B2 K(d). This ensures that, in the resulting structure, only one of B1 or B2
can happen. Timing is unaﬀected by this construct.
10.2.3.4 Enabling
The semantics of enabling are as follows.
B′′J B1 >> B2 K(d) ≜⟨E1 ∪E2, #, →, l, A, R⟩
# = #1 ∪#2 ∪(exit(Ψ1) × exit(Ψ1)) \ Id
→= →1 ∪→2 ∪({ exit(Ψ1) } × rin(Ψ2))
l = ((l1 ∪l2) \ (exit(Ψ1) × { δ })) ∪(exit(Ψ1) × { i })
A = A1 ∪(E2 × { R+0 })
R = R1 ∪R2 ∪{ ((exit(Ψ1), e), A2(e)) | e ∈rin(Ψ2) }
Thus, the event set of B′′J B1 >> B2 K(d) is the union of those for B′′J B1 K(d)
and for B′′J B2 K(d). Component conﬂicts are inherited, with the addition of
conﬂicts between nonidentical successful termination events of B′′J B1 K(d) (the
identity relation (Id) is subtracted in order to avoid generating self-conﬂicts).
These mutual conﬂicts between successful termination events ensure that
newly introduced bundles really are bundles, i.e. have mutually in conﬂict
enabling sets. These new bundles are introduced from the successful termina-
tion events of B′′J B1 K(d) to the initial and time-restricted events of B′′J B2 K(d).
Bundles to the initial events of B′′J B2 K(d) reﬂect that B2 can only start if
B′′J B1 K(d) has successfully terminated. In a similar way as with action preﬁx,
new bundles to time-restricted events of B′′J B2 K(d) are required to enforce
that event delays become relative to the termination of B′′J B1 K(d). Finally,
in standard fashion, successful termination events of B′′J B1 K(d) are relabelled
as internal events.
Figure 10.8 illustrates these semantics. The diagram depicts stages in se-
mantic interpretation of the behaviour,
P >> Q
where
P := ( y ; exit (5) ) [] ( x ; exit (2) ),
and
Q := ( z ; w (10) ; stop ) |[w]| ( w [5, 7] ; stop )

10.2 True Concurrency Semantics
313
The exact reason why B′′J Q K(d) generates the enabled structure, shown to the
left of the equals in Figure 10.8 becomes clear when we discuss the semantics
of parallel composition. However, for the moment, the main point to note is
how the enabling event structure is appended on the front of the enabled event
structure. Notice also that ez is an initial event of B′′J Q K(d), whereas ew is a
time-restricted event of B′′J Q K(d).
2
z
10
[5,7]
w
y
x
δ
δ
=
5
[5,7]
10
y
z
w
x
5
2
i
i
>>
Fig. 10.8. Example of Semantics for Enabling
10.2.3.5 Parallel Composition
The ﬁrst four clauses of the deﬁnition of parallel composition (shown in Fig-
ure 10.9) are inherited unchanged from the untimed setting; see Section 4.4.
However, we brieﬂy re-iterate their explanation for completeness.
Firstly, the events of B′′J B1 |[G]| B2 K(d) comprise events arising through
the pairing of (i) the symbol ∗with events of B′′J B1 K(d) or B′′J B2 K(d) that
do not need to synchronise (Ef
1 and Ef
2 , respectively), and (ii) events labelled
with actions in G ∪{δ} with identically labelled events in the other process
(as determined by Es
1 and Es
2). Thus, parallel composition events are non-
synchronising component events paired with ∗and synchronising events of
B′′J B1 K(d) and B′′J B2 K(d) paired with each other. Es
k and Ef
k (for k ∈{1, 2})
were deﬁned in Section 4.4.
Events are put in conﬂict if (i) any of their components are in conﬂict or
(ii) distinct events have a common proper component (i.e. other than ∗). The
latter case arises if a number of events in one process synchronise with the
same event in the other process.
With regard to causality, bundles in the parallel composition are such that,
if a projection on B1 (or B2) of all events in the bundle is taken, a bundle in
B′′J B1 K(d) (or B′′J B2 K(d)), respectively, results. Labelling is straightforward.
The new clauses are the last two, which were originally highlighted by Ka-
toen [107]. Firstly, the event timing function is the intersection of component
event timings, with * events yielding null timing constraints. Secondly, bundle
timings are deﬁned to be the intersection of the time sets associated with the
bundles obtained by projecting on the events of B1 (or B2), subject to the

314
10 Semantic Models for tLOTOS
requirement that this projection yields a bundle in B′′J B1 K(d) (or B′′J B2 K(d)),
respectively.
B′′ B1 |[G]| B2 (d) ≜⟨E, #, →, l, A, R⟩
where,
E = (Ef
1 × { ∗}) ∪({ ∗} × Ef
2 ) ∪
{ (e1, e2) ∈Es
1 × Es
2 | l1(e1) = l2(e2) }
(e1, e2) # (e′
1, e′
2) ⇔(e1 #1 e′
1) ∨(e2 #2 e′
2) ∨
(e1 = e′
1 ̸= ∗∧e2 ̸= e′
2) ∨
(e2 = e′
2 ̸= ∗∧e1 ̸= e′
1)
X →(e1, e2) ⇔(∃X1 . (X1 →1 e1 ∧X = { (e, e′) ∈E | e ∈X1 })) ∨
(∃X2 . (X2 →2 e2 ∧X = { (e, e′) ∈E | e′ ∈X2 }))
l((e1, e2)) = if e1 = ∗then l2(e2) else l1(e1)
A((e1, e2)) = A1(e1) ∩A2(e2)
where,
A1(∗) = A2(∗) = R+0.
R((X, (e1, e2))) = if X = ∅then R+0
otherwise,

X1∈S1
R1(X1, e1) ∩

X2∈S2
R2(X2, e2)
where,
S1 = { X1 ⊆E1 | X1 →1 e1 ∧
X = { (e, e′) ∈E | e ∈X1 } }
S2 = { X2 ⊆E2 | X2 →2 e2 ∧
X = { (e, e′) ∈E | e′ ∈X2 } }
Fig. 10.9. TBES Semantics for Parallel Composition
Our ﬁrst illustration of parallel composition (see Figure 10.10) highlights
how events are constructed when there is no synchronisation. Note, in contrast
to earlier event structure depictions in this chapter, event labels are explicitly
represented. This is required to avoid ambiguity, because here, multiple events
have the same label. Events are denoted e, f, g etc. and their primed versions.
The following tLOTOS behaviour could yield the event structures shown in
Figure 10.10.
P ||| Q
where
P := x ; z [2, 10] ; stop
and
Q := ( y ; z (5) ; stop ) [] ( w ; stop )

10.2 True Concurrency Semantics
315
Because no causal or conﬂict relationships cross component event structures,
the parallel composition yields two disconnected and, thus, independently
evolving, event structures.
x
[2,10]
z
|||
5
z
=
e
[2,10]
z
y
5
x
(e,*)
(f,*)
(*,e’)
(*,f’)
z
w
P
P ||| Q
Q
(*,e’’)
f’
y
e’
e’’
f
w
Fig. 10.10. Example Without Synchronisation, Illustrating Semantics for Parallel
Composition
Next, we consider an example containing synchronisation. This yields pair-
ing of component events and intersection of component event timings; see
Figure 10.11. This structure could arise from the following behaviour,
P |[z]| ( Q |[z]| R )
where
P and Q are as deﬁned above and
R := z [2, 5] ; stop
The ﬁnal example (see Figure 10.12) could arise from the following tLOTOS
behaviour,
S |[x]| T
where
S := ( x [2, 8] ; i (10) ; stop ) [] ( x [3, 10] ; stop )
and
T := ( x [2, 7] ; z (9) ; stop ) [] ( w [2, 12] ; stop )
The example shows how bundles can result from synchronisation. In par-
ticular, because two in conﬂict events (e and f) both labelled x in the left
component event structure are synchronised with a single event (e′) labelled
x in the right-hand component, a single bundle is generated of the form,
{ (e, e′), (f, e′) } →(∗, g′).
In addition, this example demonstrates how event timings are intersected dur-
ing parallel composition. For example, A(S |[x]| T )( (f, e′) ) = AS(f) ∩AT (e′).

316
10 Semantic Models for tLOTOS
[2,10]
z
5
z
(e,*)
[2,10]
5
x
z [2,5]
=
e
[2,5]
f
|[z]|
(*,e’’)
P|[z]| (Q |[z]| R)
x
P
f’
(*,e’)
y
Q |[z]| R
e’
y
e’’
w
w
( f , f’ )
Fig. 10.11. Example with Synchronisation, Illustrating Semantics for Parallel Com-
position
=
e
f
g
i
x
i
z
[2,8]
10
x
[3,10]
9
[2,7]
x
z
10
e’
(e,e’)x
x
w
9
(f,e’)
S |[x]| T
[2,7]
[3,7]
S
[2,12]
g’
(*,f’)
(g,*)
(*,g’)
|[x]|
T
[2,12]
f’
w
Fig. 10.12. Further Example with Synchronisation, Illustrating Semantics for Par-
allel Composition
10.2.3.6 Process Instantiation
The rule for process instantiation can be succinctly stated.
B′′J P K(d) ≜
j Fj
B(⊥)
where

10.2 True Concurrency Semantics
317
(P := B) ∈d
and
Fj
B(⊥) ≜FB(FB(. . . FB(⊥) . . .))
with j repetitions of FB on the right-hand side.
However, this belies a good deal of theoretical complexity, which is required in
order to support this statement. This complexity is focused on the derivation
of a suitable ﬁxed point theory to handle recursive process deﬁnitions. As was
the case for the other denotational semantics we have considered, the trace
semantics of Chapter 3 and the (untimed) bundle event structure semantics
of Chapter 4, it is beyond the scope of this book to present the necessary ﬁxed
point theory in full detail. However, the required semantic constructions are
very closely related to those presented in [107], have similarities to those given
in [32] and are presented in detail in [46]. To give an informal perspective on
this theory, the mathematical constructions in [46] ensure that the above deﬁ-
nition characterises the (unique) least timed bundle event structure, according
to a complete partial order, denoted ⪯, that satisﬁes Ψ = FB(Ψ).
B′′J P K(d) for P := B is deﬁned using standard ﬁxed point theory. A
complete partial order ⪯is deﬁned (see [46]) on timed bundle event structures
with the empty event structure (i.e. B′′J stop K(d)) as the least element, denoted
⊥. Then, for each deﬁnition P := B, a function FB is deﬁned that substitutes
a timed bundle event structure for each occurrence of P in B, interpreting
all operators in B as operators on timed bundle event structures. (Due to the
compositionality of our semantics this approach is feasible.)
FB is shown to be continuous with respect to ⪯, which means that
B′′J P K(d) can be deﬁned as the least upper bound of the chain (under ⪯)
⊥, FB(⊥), FB(FB(⊥)), . . .. Such a chain reﬂects the unfolding of a recursive
process deﬁnition, with the nth unfolding of the process deﬁnition being larger,
in the sense of ⪯, than the n−1 previous unfoldings. Furthermore, [46] gives
a deﬁnition of , such that 
i Ψi is the least upper bound of such a chain;
i.e. it is the smallest TBES that is larger according to ⪯than all TBESs in
the chain.
We illustrate this mathematical construction with a simple example of a
recursive process:
Q := x [2, 4] ; ( hide x in ( z [3, 6] ; stop ||| Q ) )
Our semantics would yield the series of timed bundle event structure approx-
imations to B′′J Q K(d) shown in Figure 10.13.
As a further example, consider the channel from the multimedia stream
speciﬁcation of Section 9.3.2:
Channel := sourceOut ; ( ( i [80, 90] ; sinkIn [0] ; stop
[] i [0, 90] ; stop )
||| Channel )

318
10 Semantic Models for tLOTOS
-
HHHH
j

*
HHHH
j

*
-
-

*
HHHH
jt
t
t
[2, 4]
[3, 6]
[3, 6]
[2, 4]
ETC
[2, 4]
x
z
x
[3, 6]
z
i
x
z
i
z
i
z
[2, 4]
z
[2, 4]
[3, 6]
[3, 6]
[3, 6]
t
t
t
t
t
t
t
t
t
[2, 4]
Fig. 10.13. Example Fixed Point Approximations
Figure 10.14 presents the true concurrency model resulting from this be-
haviour. The triangle informally denotes further recursive unfolding of the
event structure. We have not included the interleaved interpretation, because
the parallel interleaving of time and action transitions makes it too com-
plicated to draw. In fact, even without showing time transitions, the labelled
transition system is highly complex. This example illustrates one of the major
beneﬁts of the true concurrency approach: avoidance of state-space explosion.
10.2.4 Anomalous Behaviour
As noted in [47], some situations of degenerate behaviour that arise when
tLOTOS is given an operational semantics (see Section 9.4) do not arise in
the true concurrency setting. In particular, the direct link between unguarded
recursion and timelocks is lost when event structure semantics are considered.
In addition, zeno processes can be given a natural interpretation in a rather
straightforward way. We discuss these issues in this section.
Consider, for example the unguarded recursion introduced in Section 9.4.
unguarded := ( x [2, 6] ; stop ) ||| unguarded
The interleaving semantics of tLOTOS generates a timelock for this behaviour.
In contrast, the timed bundle event structure semantics for an instantiation
of unguarded,

10.2 True Concurrency Semantics
319
[0,0]
Channel
sourceOut
[0,0]
sinkIn
i
i
sourceOut
i
sinkIn
[80,90]
[0,90]
[80,90]
[0,90]
i
Fig. 10.14. True Concurrency Model of Multimedia Stream Channel
t
t
t
t
............
x
x
x
x
[2, 6]
[2, 6]
[2, 6]
[2, 6]
does not timelock. This event structure allows (amongst others) a trace of
inﬁnite length consisting of events all labelled with x that occur in the interval
[2, 6]. For unguarded ||| ( i (t) ; success ; stop ) and arbitrary t (t ̸= ∞), the
occurrence of success is not prevented: an event labelled i followed by an
event labelled success can happen after any ﬁnite sequence of xs.
Notice the diﬀerence with the process,
unguarded′ := hide x in unguarded
which leads to the timed bundle event structure,
t
t
t
t
............
i
i
i
i
[2, 6]
[2, 6]
[2, 6]
[2, 6]
Now, unguarded′ ||| ( i (t) ; success ; stop ) only permits success to happen if
t ≤6. For t > 6 there exist an inﬁnite number of urgent events that should
occur before the right-hand side i.
Unguarded recursion is the only one of the anomalous behaviours consid-
ered in Section 9.4 that behave fundamentally diﬀerently in the true concur-
rency setting. However, timed bundle event structures yield compact repre-
sentations for instant recursion and zeno behaviour. For example, an instant
recursion, such as
R := x (0) ; R
which we discussed in Section 9.4, will give rise to the timed bundle event
structure:

320
10 Semantic Models for tLOTOS
-
-
-
-
[0, 0]
[0, 0]
[0, 0]
............
[0, 0]
x
x
x
t
t
t
t
x
This structure can perform inﬁnitely many events labelled x without passing
time, however, again, nothing forces the nontime-passing run, thus, this is not
a timelock.
A zeno process, such as
zeno := zzeno(1)
zzeno(k : nat) := x ; wait [2−k] zzeno(k+1)
which was introduced in Section 9.4, yields the timed noninterleaving seman-
tics,
-
-
-
-
2−2
2−3
e1
e2
............
e4
x
2−1
x
e3
x
t
t
t
t
x
The inﬁnite sequence (e1, t1)(e2, t2) . . . is a timed proving sequence of this
timed bundle event structure if tj+1 ≥tj + 2−j for all j ≥1. In particular, for
t1 = 0 and tj+1 = tj + 2−j we obtain a proving sequence in which inﬁnitely
many events happen before time 1. However, zeno does not stop time.
10.2.5 Discussion
One of the current limitations of the ﬁeld of timed extensions of event struc-
tures is that development relations have not, to date, been explored. However,
it is likely that relations of the style of those considered in Section 4.6 could be
applied in this context. This then remains a topic awaiting further research.
In fact, within the format of this book, we have only been able to explore a
subset of the full timed bundle event structure theory. In a somewhat broader
context than that considered here, in [107], Katoen gives a comprehensive
account of the TBES theory. In addition, within the context of tLOTOS-
like calculi, [47] and [46] go beyond the theory presented here by also giving
(event-based) operational semantics for a tLOTOS-like calculus and showing
that these semantics characterise the same set of timed proving sequences
(called timed event traces in that work) as the timed bundle event structure
semantics.

11
Timed Communicating Automata
11.1 Introduction
Timed automata are one of the most successful techniques for modelling and
verifying real-time systems. This is particularly evident from the success of
region graph-based model-checking techniques, implemented in tools such as
Uppaal [16]1, Kronos [66] and HyTech [92]. Diﬀerent timed automata models
and extensions are described in the literature and adopted by tools. For exam-
ple, Uppaal’s model supports shared variables (where types include bounded
integers and arrays of clocks and integers) and diﬀerent forms of synchronisa-
tion, including binary and (nonblocking) broadcast synchronisation (through
broadcast channels.2) In addition, clocks in Uppaal’s timed automata can be
reset to any positive integer value. Urgent behaviour can be expressed through
invariants, urgent channels (resulting in urgent binary synchronisation), and
urgent and committed locations. Kronos, on the other hand, does not have
such a rich automata language, but supports multiway synchronisation. Yet,
other timed automata models represent progress conditions with deadlines or
urgency types [30,35].
Here we describe a simple model that nevertheless suﬃces to explain the
concepts underlying timed automata frameworks. This model basically corre-
sponds to that of Safety Timed Automata [91], but communication between
automata follows a CCS-style [148] binary synchronisation. In this sense, the
model can be seen as a timed extension of ﬁnite state communicating au-
tomata (Chapter 8). Furthermore, the reader will ﬁnd that many results and
discussions oﬀered in this chapter particularly apply to Uppaal, and in many
cases are also based on Uppaal developments in recent years.
A timed automaton is a ﬁnite automaton (i.e. a set of locations and tran-
sitions) extended with clocks, which allows for the representation of quan-
titative timed behaviour. For example, timed automata can describe that a
1http://www.uppaal.com.
2Uppaal’s channels play a similar role to half actions in process calculi.

322
11 Timed Communicating Automata
system cannot remain for more than ﬁve time units in a given state, or that
two actions cannot be executed more than three time units apart. Clocks are
variables in R+0 which increment synchronously, thus representing the passage
of time. Time can only pass in locations; transitions are considered instan-
taneous. Transitions are annotated with guards, these are clock constraints
which determine when the transition is enabled. Transitions may also include
a reset set, which corresponds to a set of clocks whose values are set to zero
when the transition is performed.
Timed automata are a natural extension of communicating automata
(chapter 8) to model real-time systems. Complex systems can be represented
as a network of timed automata executing in parallel. Concurrency is mod-
elled by interleaving, and communication is synchronous, where synchroni-
sation between components is modelled through half actions. The semantics
of the network correspond to those of the product automaton (which results
from parallel composition). At any given time, either (a) a completed action
is performed, in some component automaton; or (b) two synchronising half
actions are performed simultaneously, yielding a completed action; or (c) some
time passes without any transition being performed.
Notice that, unlike in (untimed) communicating automata, it is not guar-
anteed that enabled transitions in timed automata are eventually executed. In
many applications, though, it is necessary to model actions that must be ex-
ecuted in some time interval (provided they are enabled). In order to express
this kind of situation, locations in a timed automaton can be annotated with
clock constraints called invariants, with the following (informal) semantics:
at any location, time progress is allowed only as long as the resulting clock
valuations satisfy the corresponding invariant. In a network, time progress
must satisfy the invariant of the current location in every component (i.e. the
conjunction of all current invariants). Thus, when time cannot pass any longer
in a given location (invariants usually express upper bounds), enabled tran-
sitions will be considered urgent and performed (if possible) without delay.
This modelling of urgency gives rise to the occurrence of timelocks in timed
automata speciﬁcations. For example, if some invariant prevents time from
passing any further, and no transition is enabled at that point (possibly by a
mismatched synchronisation), control will remain in that location indeﬁnitely,
and (semantically) time stops. Worryingly, a timelock originating in one com-
ponent will propagate globally, bringing any possible execution to a halt. This
issue is discussed in detail later, in Chapter 12.
This chapter is organised as follows. The timed automata model is formally
deﬁned in Section 11.2. This includes syntax, semantics and some explanatory
examples. Then, Section 11.3 elaborates on automatic veriﬁcation of timed
automata (real-time model-checking); symbolic states, forward reachability,
and techniques adopted by Uppaal and Kronos are discussed. Throughout the
chapter, the multimedia stream protocol (Section 9.3.2) is used as a running
example.

11.2 Timed Automata – Formal Deﬁnitions
323
11.2 Timed Automata – Formal Deﬁnitions
This section formally deﬁnes the syntax and semantics of timed automata.
The model presented here has some diﬀerences with others frequently found
in the literature. For example, the CCS-like synchronisation adopted in our
model closely resembles that of Uppaal, but is diﬀerent from the multiway
synchronisation adopted by Kronos. Nevertheless, the reader will ﬁnd that
our timed automata model represents all the main elements of the theory,
and that other models can be easily studied by taking this as a starting point.
Before we concern ourselves with formal deﬁnitions, let us ﬁrst present an
introductory example. Figure 11.1 shows a network composed of two timed
automata, and its corresponding product automaton. Initial locations are dis-
tinguished with a double circle; the initial value for clocks is assumed to be
0. Transition a! 3 has a guard 3 < x ≤5, meaning that it is enabled in the
time interval (3, 5]. As we have discussed in the timed process calculus set-
ting, this does not imply that a! must be performed at some point in that
interval; in fact, an execution where the automaton remains permanently in
location 1 is possible. Synchronisation between a! and a? results in transition
a in the product automaton, with guards conjoined. Location 2 is assigned
the invariant x ≤6, meaning that time is allowed to pass in that location only
as long as the value of x is less than 6. If the value of x reaches 6 while in
location 2, transition b becomes urgent and must be performed without delay.
Notice that (immediate) interleaving with other actions is still possible: for
example, even if b is urgent, transition c can be performed before b, although
time would not be able to pass until b is performed. This can be seen in the
product automaton, if the lowest branch ⟨2, 5⟩c ⟨2, 6⟩b ⟨3, 6⟩is executed
when the value of x reaches 6 in ⟨2, 5⟩(at any location vector, the invariant
results from conjoining the invariants of the component locations). Finally,
note that x is reset in b, and so its value is zero when location 3 is entered.
1
2
3
x:=0
b
4
5
6
c
a!
a?
3<x<=5 x<=6
y<=10
4<y<6
a
b
c
c
b
3<x<=5,
4<y<6
x:=0
x:=0
x<=6,
y<=10
x<=6
y<=10
<3,5>
<2,6>
||    =>
<3,6>
<1,4>
<2,5>
Fig. 11.1. A Simple Network of Timed Automata, and Its Product Automaton
3In this, and following chapters, we depart from our process calculus notation and
use a, b, etc. to denote action labels (either for completed actions or half actions),
and x, y, etc. to denote clocks.

324
11 Timed Communicating Automata
11.2.1 Syntax
Basic Sets and Notation. TA denotes the set of all timed automata. The
sets CAct (completed actions), HAct (half actions), and Act (all actions) are
deﬁned as for communicating automata (Section 8.2.2.2). C is the set of clocks,
all of which take values in R+0. CC is a set of clock constraints, whose syntax
is given by
φ ::= false | true | x ∼c | x −y ∼c | φ ∧φ
where c ∈N, x, y ∈C, φ ∈CC and ∼∈{<, >, =, ≤, ≥}. Clocks(φ) is the set
of clocks occurring in φ ∈CC. Let C ⊆C denote the set of clocks of a given
timed automaton. CCC is the set of constraints over clocks in C. Similarly,
V : C →R+0 is the space of possible clock valuations, and VC : C →R+0
the space of valuations restricted to clocks in C.
Given φ a clock constraint and v a valuation, we use v |= φ to denote
that v satisﬁes φ (or, equivalently, that v is in the solution set of φ). If r is a
reset set, and d ∈R+0 a delay, we deﬁne v + d to be the valuation such that
(v + d)(c) = v(c) + d, for all c ∈C. Also, we use r(v) to denote the valuation
that results from v by resetting to zero all clocks in r, i.e. r(v) = v′, where
v′(c) = 0 whenever c ∈r and v′(c) = v(c) otherwise.
Timed Automata. A timed automaton A ∈TA is a tuple (L, TL, T, l0, C, I),
where
•
L is a ﬁnite set of locations;
•
C ⊆C is a ﬁnite set of clocks;
•
TL ⊆Act is a ﬁnite set of transition labels;
•
T ⊆L × TL × CC C × P(C) × L is a transition relation, where transitions
(l, a, g, r, l′) ∈T are usually denoted,
l
a,g,r
−−−−→l′
where a ∈TL is the action, g ∈CC C is the guard and r ∈P(C) is the
reset set;
•
l0 ∈L is the initial location; and
•
I : L →CC C is a mapping which associates invariants with locations.
11.2.1.1 Example: A TA Speciﬁcation for the Multimedia Stream
Let us revisit the example of the multimedia stream, introduced in Sec-
tion 9.3.2 (see Figure 9.1). The Source process generates a continuous sequence
of packets which are relayed by the Channel to a Sink process which displays
the packets. Three basic interprocess communication actions support the ﬂow
of data (see Figure 9.3.2 again), sourceOut, sinkIn and play, which respectively
transfer packets from the Source to the Channel, from the Channel to the Sink
and display them at the Sink. Here we assume that the Channel is reliable;

11.2 Timed Automata – Formal Deﬁnitions
325
the Source transmits a packet every 50 ms; packets arrive at the Sink between
80 ms and 90 ms after their transmission (the latency of the Channel) and
that whenever the Sink receives a packet, it needs 5 ms to process it, after
which it is ready to receive the next packet.
Figure 11.24 shows a possible timed automata speciﬁcation, where the
Channel is represented by two one-place buﬀers, Place1 and Place2. Notice,
in contrast to the tLOTOS speciﬁcation in Section 9.3.2, that in timed au-
tomata we cannot (directly) specify a channel with an unbounded number of
places. Nevertheless, it can be shown5 that two one-place buﬀers represent
a safe implementation of an inﬁnite-capacity channel, in the sense that syn-
chronisation between Source and either Place1 or Place2 is always possible (in
other words, a packet can always be put into the Channel).
Every component in the network includes a local clock: t1, t2, t3 and t4.
The initial location in the Source, State0, is annotated with the invariant
t1 = 0 to ensure that the ﬁrst packet (sourceOut!) is sent immediately. The
guard t1 = 50 and reset t1 := 0 enable sourceOut! in location State1, once
every 50 ms. The invariant at State1, t1 ≤50, makes the sourceOut! urgent
as soon as it is enabled. Notice that, because sourceOut! is a half action, it
will only be performed if sourceOut? is enabled in either Place1 or Place2
(otherwise a timelock would occur). Now consider the model for a buﬀer, say
Place1. At location State1, transition sourceOut? is oﬀered to synchronise with
a sourceOut! from the Source. Should this happen (notice that the Source
may nondeterministically synchronise with Place2 instead), the clock t4 is
reset and the automaton moves to location State2. The value of t4 represents
the time elapsed since the last packet was transmitted. The invariant t4 ≤
90, together with the guard t4 ≥80 enabling transition sinkIn!, eﬀectively
represent the Channel’s latency: packets arrive at the Sink between 80 and 90
ms after they have been sent. The Sink synchronises with the Channel (i.e.
with Place1/Place2) by oﬀering a sinkIn? action. The action play is performed
5 ms after a packet has arrived, representing the speed at which the Sink can
process and play packets.
11.2.2 Semantics
The semantics of a timed automaton, say A = (L, TL, T, l0, C, I), can be inter-
preted in terms of a timed transition system (S, Lab, TS, s0), which describes
all possible executions of A. S denotes a set of states6 of the form s = [l, v],
where l is a location in A and v a possible valuation for its clocks. s0 = [l0, v0]
is the starting state, where l0 is the initial location in A, and v0 is the initial
valuation, which sets all clocks to 0. Lab = TL ∪R+ is a set of transition
4This is based on a model presented in [43].
5A report on the veriﬁcation of this and other correctness properties using Uppaal
can be found in [43].
6Also referred to as concrete states.

326
11 Timed Communicating Automata
State1
State2
t4<=90
State1
t1<=50
State1
State2
t3<=90
State1
State2
t2<=5
play
t2=5
Place1
Place2
Sink
State0
t1=0
Source
sourceOut !
t1=50
sourceOut !
t1:=0
sourceOut ?
t4:=0
sourceOut ?
t3:=0
sinkIn ?
t2:=0
sinkIn !
t4>=80
sinkIn !
t3>=80
Fig. 11.2. Timed Automata Speciﬁcation of the Multimedia Stream
labels. The transition relation TS ⊆S × Lab × S represents the set of all pos-
sible executions of A (also called runs). For any (reachable) state, a transition
denotes one possible step the current execution can take. Thus, transitions
can be of one of two types: action transitions, e.g. (s, a, s′), where a ∈Act, or
time transitions, e.g. (s, d, s′), where d ∈R+ and the passage of d time units
is denoted. Transitions are denoted7
s
γ
−→→s′
where γ ∈Lab. We use s
γ
−→→to denote ∃s′. s
γ
−→→s′. Usually, we refer to
action transitions simply as actions.
Semantic transitions (time and action transitions, e.g. s
a
−→→s′) are not to
be confused with the syntactic transitions (or edges, e.g. l
a,g,r
−−−−→l′) in a timed
automaton graph. Indeed, transitions and locations in a timed automaton are
ﬁnite. On the other hand, the TTS describing the semantics of the automaton
will be, in most cases, inﬁnite. This is due to clocks taking valuations in a
dense space, R+ (a similar point was made in Section 10.1.1). In general,
whenever the automaton is allowed to remain in a given location l for d ∈R+
time units, the TTS contains inﬁnitely many time transitions
[l, v]
d′
−→→[l, v + d′],
d′ ∈R+, 0 ≤d′ ≤d. Figure 11.3 below illustrates these concepts.
The timed automaton depicted in Figure 11.3(i) can remain in location 1
for 5 time units. Transition a can be performed at any time in [2, 5], and is
urgent when v(x) = 5. Once in location 2, any amount of time can pass be-
fore transition b is executed. Moreover, and unlike in untimed communicating
7In the presentation of TTS in Section 10.1.1 we have used −→and ; to denote,
respectively, action and time transitions. Also, Section 10.1.3 introduced −→→to
denote the union of these two types of transitions. Here we use −→→for the same
purpose, but we do not use −→and ; separately, to avoid confusion with syntactic
transitions (edges) in timed automata (denoted −→).

11.2 Timed Automata – Formal Deﬁnitions
327
1
2
a
x>=2
x<=5
2
3
(i)
(ii)
b
x:=0
a
3
actions
time
b
action transitions
time passing transitions
. . .
. . .
. . .
Fig. 11.3. A Timed Automata (i) and (Part of) Its TTS (ii)
automata (chapter 8) here there is no guarantee that b is ever executed: the
timed automaton may remain in location 2 permanently. This results in an
inﬁnite TTS, part of which is sketched in Figure 11.3(ii). For example, the
following runs are two particular instances of the timed automaton’s execu-
tion.
ρ1 = [1, 0]
2
−→→[1, 2]
a
−→→[2, 0] 3.3
−→→[2, 3.3]
b
−→→[3, 3.3] · · ·
ρ2 = [1, 0] 3.5
−→→[1, 3.5]
a
−→→[2, 0]
7
−→→[2, 7] · · ·
where, for every state [l, v], l denotes a location in the automaton and v the
current value of x in that state. The ﬁrst run, ρ1, denotes a partial execution
where the automaton remains in location 1 for 2 time units, takes transition
a, then remains for 3.3 time units in location 2 and takes transition b. Another
possible partial execution is represented by ρ2: the automaton takes a when
v(x) = 3.5 and then remains in location 2 for 7 time units without performing
any action.
Some other aspects of timed automata semantics are worth observing.
For example, the action transition [2, 3.3]
b
−→→[3, 3.3] in ρ1 conﬁrms the in-
stantaneous nature of transitions in a timed automaton: notice that x is not
incremented (which is consistent with all the models considered in this book).
Similarly, [1, 2]
a
−→→[2, 0] illustrates the reset of x in transition a. The time
transition [1, 0]
2
−→→[1, 2] in the same run shows that time only elapses in lo-
cations. And, as we have mentioned before, time is allowed to progress only
as long as it does not invalidate the current invariant. For example, a run like
ρ3 below is not possible because the invariant x ≤5 in location 1 would be

328
11 Timed Communicating Automata
invalidated by time-progress (equivalently, a must be performed before more
than 5 time units have elapsed in location 1):
ρ3 = [1, 0]
6
−→→[1, 6]
a
−→→[2, 6]
11.2.2.1 Runs
A run starting from state s ∈S, is a ﬁnite or inﬁnite sequence ρ deﬁned as
follows,
ρ ≜s1
γ1
−→→s2
γ2
−→→s3
γ3
−→→. . .
where s1 = s, si ∈S, and γi ∈Act ∪R+, for all i ≥1. We use s
γ
−→→s′ ∈ρ
to denote that s
γ
−→→s′ is a (action or time) transition in the sequence ρ. We
deﬁne delay(ρ) as the sum of all delays in the run ρ:
delay(ρ) ≜Σ {γ | γ ∈R+ ∧s
γ
−→→s′ ∈ρ }
We deﬁne Runs(A) to be the set of all runs of a timed automaton A. A diver-
gent run is a run ρ s.t. delay(ρ) = ∞, i.e. an inﬁnite run where time diverges.
Nondivergent runs are called convergent runs. A zeno run is a convergent,
inﬁnite run with inﬁnitely many actions. ZRuns(A) ⊆Runs(A) is the set of
all zeno runs of A.
As we have mentioned, runs represent possible system executions. How-
ever, ﬁnite runs are considered valid executions only if they end in a state
where no transition (either action or time passing) is enabled. Notice that
here we drop the liveness hypothesis of ﬁnite state communicating automata
(see our discussion in Section 8.2.4), where action transitions, if enabled, will
eventually be performed. Timed automata, on the contrary, can remain at any
location for as long as the invariant in that location allows. In this model, the
intended (urgent) execution of actions must be indicated explicitly through
invariants. Moreover, one must be precise in quantifying the intended exe-
cution time (through guards and invariants): there is no way to enforce the
execution of actions at some (unspeciﬁed) point in the future.
11.2.2.2 Parallel Composition
The behaviour of a network can be deﬁned in terms of the parallel composition
of the component automata. Composition results in a single automaton, called
the product automaton, whose semantics correspond to that of the network.
The parallel composition of timed automata is just an extension of the same
operation deﬁned for (untimed) communicating automata (Section 8.2.2.2).
In addition, here we note that component guards and reset sets are conjoined

11.2 Timed Automata – Formal Deﬁnitions
329
as a result of synchronisation, and that component invariants are conjoined in
location vectors. Formally, the product automaton can be deﬁned as follows.
Let |A = |⟨A1, ... , An⟩be a network of TAs, where
Ai = (Li, TLi, Ti, li,0, Ci, Ii)
for 1 ≤i ≤n. Let u, u′ be location vectors. The product automaton, which
represents the behaviour of the network |A, is deﬁned as
Π = (L, TL, T, l0, C, I)
where
•
L = { l0 } ∪{ u′ | ∃u ∈L, a, g, r . u
a,g,r
−−−−→u′ };
•
TL =
n
i=1
TLi;
•
T is as deﬁned by the following rules (1 ≤i ̸= j ≤n)8,
(P1)
ui
a?,gi,ri
−−−−−−→i l uj
a!,gj,rj
−−−−−→j l′
u
a,gi ∧gj,ri∪rj
−−−−−−−−−−→u[l →i, l′ →j]
(P2) ui
a,g,r
−−−−→i l a ∈CAct
u
a,g,r
−−−−→u[l →i]
•
l0 = ⟨l1,0, . . . , ln,0⟩;
•
C =
n
i=1
Ci; and
•
I(⟨u1, ..., un⟩) =
n
i=1
Ii(ui).
Example: Product Automaton for the Multimedia Stream. Fig-
ure 11.4 shows part of the product automaton which corresponds to the multi-
media stream speciﬁcation (Figure 11.2). We have omitted unreachable loca-
tions; these result from transitions that will never be enabled.9 For example,
location ⟨0, 1, 1, 1⟩corresponds to Source.State0, Place1.State1, Place2.State1
and Sink.State1. Transition sourceOut, from ⟨0, 1, 1, 1⟩to ⟨1, 2, 1, 1⟩, results
from synchronisation between sourceOut! in Source.State0 and sourceOut? in
Place1.State1 (a similar transition exists from ⟨0, 1, 1, 1⟩to ⟨1, 1, 2, 1⟩, which
corresponds to initial synchronisation between Source and Place2). The in-
variant t1 ≤50∧t4 ≤90 in location ⟨1, 2, 1, 1⟩corresponds to the conjunction
of invariants in Source.State1, Place1.State2, Place2.State1 and Sink.State1.
8As for communicating automata in Chapter 8, we use a?, a! ∈HAct to denote
half actions.
9Notice that these locations and transitions are still part of the product automa-
ton. Reachability can only be determined by semantic analysis.

330
11 Timed Communicating Automata
t1<=50
t4<=90
t1<=50,
t3<=90
t1<=50,
t2<=5,
t4<=90
t1<=50,
t2<=5,
t3<=90
t2=5
play
t2=5
play
t1<=50
t4<=90
t1<=50,
t3<=90
t1<=50,
t3<=90,
t4<=90
t1<=0
<0,1,1,1>
<1,1,2,1>
<1,2,1,1>
<1,2,2,1>
<1,2,1,2>
<1,2,1,1>
<1,1,2,1>
<1,1,2,2>
sourceOut
t3:=0
sourceOut
t4:=0
t1=50
sourceOut
t1:=0
t3:=0
t1=50
sourceOut
t1:=0
t4:=0
t1=50
sourceOut
t1:=0
t4:=0
t1=50
sourceOut
t1:=0
t3:=0
t4>=80
sinkIn
t2:=0
t3>=80
sinkIn
t2:=0
Fig. 11.4. Product Automaton (TA) For The Multimedia Stream
11.2.2.3 A TTS Semantics for Timed Automata
Here we present a formalisation of semantics in terms of TTSs. We assume
that an automaton with half actions cannot be executed in isolation (this
corresponds, for example, to the semantics of Uppaal models), and as such it
does not have a semantics related to it. Therefore, the semantics oﬀered in
this section correspond to automata where all actions are completed. Note (as
for communicating automata in Chapter 8) that this does not prevent us from
oﬀering a semantics for a network of TAs: the behaviour of a network corre-
sponds to the TTS semantics for its product automaton (Section 11.2.2.2).
Let A = (L, TL, T, l0, C, I) ∈TA be a timed automaton where all actions
are completed (i.e. TL ⊆CAct). The semantics of A is given by the TTS
(S, Lab, TS, s0), where
•
S ⊆L × VC is the set of reachable states; i.e.
S = { s0 } ∪{ s′ | ∃s ∈S, γ ∈Lab . s
γ
−→→s′ }
•
s0 = [l0, v0] is the starting state, where v0 (the initial clock valuation) is
s.t. ∀c ∈C , v0(c) = 0;
•
Lab = TL ∪R+ is the set of transition labels;
•
TS ⊆S × Lab × S is the transition relation, deﬁned by the following
inference rules,

11.2 Timed Automata – Formal Deﬁnitions
331
(R1) l
a,g,r
−−−−→l′ v |= g r(v) |= I(l′)
[l, v]
a
−→→[l′, r(v)]
(R2) ∀d′ ≤d , (v + d′) |= I(l)
[l, v]
d
−→→[l, v + d]
The ﬁrst transition rule, (R1), gives an interpretation to invariants in which
locations cannot be entered if the invariant is false. This strong-invariant in-
terpretation is the most commonly adopted both in the literature and tools
(e.g. Uppaal). In contrast, a weak-invariant interpretation, in which the in-
variant in the target location is not required to hold for a transition to be
performed, is given by the following rules,
(W1) l
a,g,r
−−−−→l′ v |= g
[l, v]
a
−→→[l′, r(v)]
(W2) ∀d′ ≤d , (v + d′) |= I(l)
[l, v]
d
−→→[l, v + d]
The diﬀerence between these two interpretations can be observed in rules
(R1) and (W1), which govern when a transition can be performed; rules (R2)
and (W2), which determine when time is allowed to elapse, are the same in
both interpretations. For example, if the semantics of the automaton shown in
Figure 11.5 is considered with respect to the strong-invariant interpretation,
then a would only be performed in the interval [0, 5]. After that, the invariant
in location 2 is not valid and so that location cannot be entered. On the other
hand, with a weak-invariant interpretation, a can be performed at any time.
If a is performed after 5 time units have passed, then b must be performed
immediately afterwards. Consider, for example, the following run.
ρ = [1, 0]
6
−→→[1, 6]
a
−→→[2, 6]
b
−→→[3, 6] · · ·
1
2
a
x<=5
3
b
Fig. 11.5. Strong and Weak Invariants
Such a run waits for 6 time units in location 1 and then performs a. This
is not possible with a strong-invariant interpretation, because performing a
when v(x) = 6 would invalidate the invariant in the target location (x ≤5 in
location 2). On the other hand this run is possible with weak invariants, and
b is performed urgently after a.
11.2.2.4 Discussion: Urgency in Timed Automata and tLOTOS
The form of urgency expressed by invariants can be compared to that ob-
tained through explicit urgency operators in process calculi, discussed in Sec-
tion 9.2.2. With invariants, urgency can be enforced on both completed and

332
11 Timed Communicating Automata
half actions (which corresponds to urgency in internal and observable actions
in process calculi). Consequently, this form of urgency is stronger than the one
adopted by tLOTOS, which is enforced only on internal actions. Therefore,
the use of invariants in timed automata may cause timelocks due to synchro-
nisation mismatches, whereas this cannot occur in tLOTOS, as observable
actions are never urgent.
11.3 Real-time Model-checking
In general, real-time model-checking refers to a collection of formal auto-
matic veriﬁcation methods in which a system, modelled as a network of
timed automata, is checked against a property expressed in some temporal
logic. Predominantly, properties will be expressed in some subset of TCTL
(Timed Computation Tree Logic) [6], a real-time extension of CTL [57] (Sec-
tion 8.2.5.1). Because the state space of a network is inﬁnite, these methods
rely on the computation of abstractions, which map an inﬁnite number of
states in the network’s TTS (which we call concrete states) to a ﬁnite number
of symbolic states. In general, a symbolic state consists of a location vector
and a number of clock constraints, which represent a space of clock valuations:
every single valuation in this set, together with the location vector, deﬁne one
reachable concrete state.
Indeed, we can say that progress in the area of automatic veriﬁcation of
timed systems, and in particular of timed automata, has a milestone in the
seminal work of Alur and Dill [7]: a region graph partitions the inﬁnite state-
space into a ﬁnite number of equivalence classes: for any guard g, all valuations
in a region satisfy g, or none does. The fundamental drawback of the region
graph is its size: the number of regions grows exponentially with the number
of clocks and the maximum constants (per clock) used in clock constraints.
In practice, real-time model-checkers use a coarser abstraction, the forward
reachability graph, which can be much smaller (in number of symbolic states)
than the corresponding region graph.
The key observation here is that, in order to determine whether a certain
state is reachable, the ﬁne discrimination of valuations introduced by regions
is not necessary. Instead, the forward reachability graph divides the inﬁnite
state-space into zones. Like regions, zones are conjunctions of clock constraints
and can be seen as symbolic states in the execution of a timed automaton.
Zones characterise all valuations that are reachable on a given automaton’s
location, from the time that location is entered and as long as the location’s
invariant allows. However, unlike regions, it is not required that all valuations
in a zone satisfy the same guards. Therefore, more valuations can be consid-
ered part of the same zone, and so the (inﬁnite) state-space is divided into a
smaller number of symbolic states.
Also, model-checkers cope with complex systems thanks to on-the-ﬂy ver-
iﬁcation: properties can be checked while the reachability graph is being gen-

11.3 Real-time Model-checking
333
erated. Therefore, and depending on the property at hand, it may not be
necessary to construct the whole graph to determine whether the system sat-
isﬁes a property. Moreover, and because the veriﬁcation algorithms work over
the reachability graph, the construction of the product automaton is not nec-
essary to model-check a network of TAs.
11.3.1 Forward Reachability
Model-checkers can verify a number of diﬀerent TCTL formulae, including
reachability, safety and liveness properties (including bounded-response10). In
general, TCTL extends CTL by allowing the speciﬁcation of time intervals.
For example, a TCTL formula EF≤nφ is satisﬁable in given state s, if there
exists a run ρ (i.e. a path in the computation tree) starting from s where a
state s′ is reachable, such that φ is satisﬁable in s′ and the accumulated delay
in ρ, up to s′, is in the interval [0, n], n ∈R+0. Although some model-checkers
(notably, Kronos) are able to deal with general TCTL formulae, this section
is concerned just with reachability formulae of the form EFφ, where φ is given
in the BNF,
φ ::= g | l | φ ∧φ | ¬ φ
where g is a clock constraint in CC and l is a location in a given timed automa-
ton. Notice that, even when delays are not explicitly speciﬁed in the TCTL
formula, they can be naturally modelled as part of the clock constraint g. In
practice, TCTL formulae without explicit delays have proved to be expres-
sive enough for real-time veriﬁcation. For example, Uppaal veriﬁes a subset
of TCTL without explicit delays, and where modalities cannot be nested: for-
mulae include EFφ, AGφ, EGφ and AFφ; but φ cannot contain path (A/E) or
temporal (F/G) operators.
Furthermore, reachability analysis remains the core of the veriﬁcation en-
gine, in all real-time model-checkers. One reason for this is that reachability
analysis is versatile. For example, we have seen already that safety properties
can be expressed in terms of reachability properties: AGφ is satisﬁable if EF¬φ
is not. Also, a number of methods are known that augment the timed au-
tomata speciﬁcation (e.g. with test automata [4], or extra clocks and Boolean
variables) and allow the veriﬁcation of bounded-response properties to be ex-
pressed in terms of basic safety properties [16]. The other reason why reach-
ability analysis is crucial to model-checking is that the veriﬁcation of more
complex formulae, such as general liveness properties (e.g. AGEFφ), can be re-
alised by nested reachability checks (see, e.g. [189]). Mostly, then, development
in both model-checking theory and tools has focused on eﬃcient reachability
algorithms (and on the data structures used by these algorithms).
10In TCTL, bounded-response properties usually take the form AG(φ ⇒AF≤nψ),
for some n ∈N denoting the maximum delay between a φ-state and a ψ-state.

334
11 Timed Communicating Automata
We now describe forward reachability in detail. Our discussions are based
on a single timed automaton, but deﬁnitions readily accommodate networks
of automata (if we apply these deﬁnitions to the product automaton). Given
a timed automaton A and a state formula φ (a formula given in the BNF
mentioned above), an algorithm will determine whether there exists a symbolic
state in the forward reachability graph for A, which satisﬁes φ. In what follows,
we assume A = (L, TL, T, l0, C, I).
11.3.1.1 Symbolic States and Operations on Zones
This section presents the main theoretical elements underlying symbolic
model-checking of timed automata. Because this area is still under active
research, we decided to keep our discussions at a conceptual level, without
delving too deep into current implementations (such as Uppaal or Kronos).
These and other issues are further discussed in Section 11.3.3, where pointers
to relevant literature are also oﬀered.
Symbolic States. A symbolic state is a pair (l, Z), where l ∈L is a location
in A and Z ∈CC C (called a zone) is a clock constraint. Symbolic states are
ﬁnite abstractions of inﬁnite sets of (concrete) states. In this sense, a sym-
bolic state (l, Z) encodes the set { [l, v] | v |= Z }; that is, the set of all concrete
states with location l and valuation v satisfying the constraints in Z. We use
s ∈(l, Z) to denote s = [l, v], and v |= Z.
Symbolic states constitute the nodes of the reachability graph. We show
that, given a symbolic state in the reachability graph, the derivation of its
direct successors is a crucial operation in the reachability algorithm. This,
in turn, consists of a number of operations on zones. Figure 11.6 below illus-
trates some of these basic operations, where zones (over {x, y}) are represented
through their solution sets.
y
x
1
1
(i)
(ii)
(iii)
(iv)
Fig. 11.6. (i) Z and Z′, (ii) Z ∧Z′, (iii) r(Z′), r = {x}, (iv) Z↑
Conjunction. Let Z and Z′ be two zones; conjunction is deﬁned in the usual
way and corresponds to the set of valuations satisfying both Z and Z′.

11.3 Real-time Model-checking
335
Z ∧Z′ ≜Z ∩Z′
Figure 11.6(i) shows the zones,
Z = x ≥1 ∧x ≤4 ∧y ≥1 ∧y ≤2 ∧x −y ≥0
Z′ = x ≥2 ∧x ≤4 ∧y ≥1 ∧y ≤4
Conjunction (Figure 11.6(ii)) gives the expected,
Z ∧Z′ = x ≥2 ∧x ≤4 ∧y ≥1 ∧y ≤2
Reset. Let Z be a zone and r a reset set. The reset of Z with respect to r,
denoted r(Z), corresponds to the set of valuations in Z where the value of
every clock in r is set to zero.
r(Z) ≜{ r(v) | v |= Z }
For example, the reset of Z′ with respect to r = {x} (Figure 11.6(iii)) yields,
r(Z′) = x = 0 ∧y ≥1 ∧y ≤4
Forward projection. Given a zone Z, its forward projection, Z↑, is deﬁned
as follows,
Z↑≜{v + d | v |= Z ∧d ∈R+0}
The forward projection of Z is the set of valuations that can be reached
from any valuation in Z by letting some time pass. This operation preserves
the lower bounds imposed by Z, but allows time to diverge, maintaining the
uniform clock speed.11 Figure 11.6(iv) depicts the forward projection of Z,
which yields
Z↑= y ≥1 ∧x −y ≥0 ∧x −y ≤3
Normalisation. Let cmax ∈N be the greatest constant occurring in any
guard or invariant in A. Let Z be a zone, and m ∈N, m > cmax. We de-
ﬁne norm(Z) as the zone which can be obtained from Z by removing all
constraints x ∼m, x −y ∼m (∼∈{<, ≤}), and replacing all constraints
x ∼m, x −y ∼m (∼∈{>, =}) with x > cmax and x −y > cmax, respectively.
Normalisation (not shown in Figure 11.6) guarantees a ﬁnite number of zones
in the forward reachability graph, and therefore is necessary to ensure that the
11As we have mentioned before, timed automata synchronise on the passage of
time, and thus, clocks advance at the same speed. Eﬀectively, the time model of TA
assumes an implicit global clock.

336
11 Timed Communicating Automata
reachability algorithm terminates. We now explain the necessity for normali-
sation through a small example.12 Consider the timed automaton depicted by
Figure 11.7,
x<=10
1
2
a
b
y>=20
x=10
x:=0
Fig. 11.7. Clock Drift
The clock y is allowed to “drift” unbounded in location 1, generating an
inﬁnite number of symbolic states (1, Zi), where
Z0 = x ≤10 ∧x = y
Z1 = x ≤10 ∧y ≤20 ∧y −x = 10
Z2 = x ≤10 ∧y ≤30 ∧y −x = 20
Z3 = x ≤10 ∧y ≤40 ∧y −x = 30
Z4 = x ≤10 ∧y ≤50 ∧y −x = 40
...
The state (1, Z0) denotes that, initially, the automaton can remain in location
1 for 10 time units. State (1, Z1) is reachable from (1, Z0): Z1 represents
the set of valuations that can be reached in location 1 after transition a is
performed (and letting time pass as much as the invariant allows). The clock
x is constrained to x ≤10 by the invariant in location 1; however, after a is
performed, the value of y and the diﬀerence between y and x increase: this is
so because a resets x and y is not constrained by the invariant. Consequently,
an inﬁnite number of zones Z0, Z1, . . . are reachable, and so the reachability
algorithm may not terminate (this would be the case, for example, when the
property to check cannot be veriﬁed until the whole of the state-space has
been explored).
Notice that v2(y) ∈[20, 30], v3(y) ∈[30, 40] and v4(y) ∈[40, 50], where
v2 |= Z2, v3 |= Z3 and v4 |= Z4. Transition b, therefore, does not distinguish
among these diﬀerent valuations: all that matters is that b is enabled because
v(y) ≥20. Therefore, removing the constraint y ≤30 from Z2 produces a
“normalised” zone, norm(Z2), which is, in the sense just mentioned, equivalent
to Z2. Similarly, removing y ≤40 and replacing y −x = 30 with y −x > 20
in Z3 results in the equivalent zone norm(Z3) (which is also equivalent to
Z4, Z5, . . .). We have, then:
12This is inspired by an example in [13].

11.3 Real-time Model-checking
337
norm(Z2) = x ≤10 ∧y −x = 20
norm(Z3) = x ≤10 ∧y > 20 ∧y −x > 20
Normalisation, then, is an operation on zones that produces an equivalent zone
with respect to timed automata tests (i.e. guards and invariants). For explana-
tory purposes, our deﬁnition of normalisation is just a simpliﬁed description
of the procedures currently implemented in Uppaal or Kronos. Section 11.3.3
oﬀers some pointers to some literature on this topic.
11.3.1.2 The Forward Reachability Graph
Consider, once again, the timed automaton shown in Figure 11.7. The corre-
sponding TTS contains, for example, a time transition
[1, x = y = 0]
10
−→→[1, x = y = 10]
that will trigger the immediate execution of action a. In general, the TTS
contains inﬁnitely many time transitions of the form:
[1, x = y = 0]
d
−→→[1, x = y = d]
where d ≤10, d ∈R+, which denote that time can initially elapse by 10 time
units in location 1. Similarly, there exist inﬁnitely many action transitions of
the form:
[1, x = 0 + d ∧y = 20 + d]
b
−→→[2, x = 0 + d ∧y = 20 + d]
for any d ≤10, d ∈R+0. These action transitions denote that b can be
performed at any time during the interval [20,30].
We could argue that the distinction between these inﬁnitely many transi-
tions (that is, the diﬀerent ways in which time can pass up to a certain point)
is not relevant to the execution of the timed automaton. What is important,
though, is whether time has elapsed by a certain relevant quantity: this is
determined by guards, invariants and resets in the automaton.
The forward reachability graph, then, provides an abstraction for the elaps-
ing of time in the form of clock constraints (zones). Every node in the graph is
represented by a symbolic state (l, Z), where l is a location in the automaton
A and Z is a zone. The starting node is (l0, Z0), where l0 is the initial location
of A and Z0 is the zone describing the maximum time-progress allowed in
l0 (notice that this depends on the invariant in l0). Given a node (l, Z), the
forward reachability graph contains a direct successor (l′, Z′) for every transi-
tion t = l
a,g,r
−−−−→l′ in A. The zone Z′ represents the maximum time-progress
allowed in the target location l′, after t has been performed. Z′ is calculated
from the current zone Z, the transition’s guard g and reset set r, and the
target location’s invariant I(l′). In what follows, we give formal deﬁnitions for
symbolic successors and the forward reachability graph, and illustrate these

338
11 Timed Communicating Automata
concepts with a small example.
Symbolic Successors. Let t = l
a,g,r
−−−−→l′ be a transition in A and (l, Z) be
a symbolic state, where l ∈L is a location in A and Z ∈CC C is a zone. Let
Zt be a zone deﬁned as follows,
Zt ≜r(Z ∧g) ∧I(l′)
The symbolic state (l′, Zt) represents the set of all concrete states that can be
reached from any concrete state in (l, Z), by performing transition t. Hence,
the following holds,
∀s′ ∈(l′, Zt) , ∃s ∈(l, Z) . s
a
−→→s′
It is not diﬃcult to see that, if a concrete state s′ = [l′, v′] ∈(l′, Zt) is
reachable from some state s ∈(l, Z), by taking transition t, then so is any
state s′′ = [l′, v′ + d], d ∈R+0, v′ + d |= I(l′) (just by allowing time to elapse
in the target location l′). Then, the set of immediate successors of any node
(l, Z) is given by,
Successors(l, Z) = { (l′, norm(Z↑
t ∧I(l′))) | t = l
a,g,r
−−−−→l′ }
Forward Reachability Graph. Let
Z0 ≜I(l0) ∧

x,y∈C
x = y
be the initial zone. The forward reachability graph, G = (N, E), where N is
a ﬁnite set of nodes and E is a ﬁnite set of edges, can be deﬁned inductively
as follows,
N = { (l0, Z0) } ∪

(l,Z)∈N
Successors(l, Z)
E = { (l, Z) −→(l′, Z′) | (l, Z) ∈N ∧(l′, Z′) ∈Successors(l, Z) }
Notice that normalisation guarantees ﬁniteness of N. The graph can be in-
terpreted as a ﬁnite abstraction of the concrete, operational (TTS) semantics
given in Section 11.2.2. Eﬀectively, a node (l, Z) ∈N represents the set of
time transitions,
{ [l, v]
d
−→→[l, v + d] | d ∈R+ ∧v |= Z ∧v + d |= Z }
and an edge (l, Z) −→(l′, Z′) ∈E represents the set of action transitions,
{ [l, v]
a
−→→[l′, v′] | a ∈Act ∧v |= Z ∧v′ |= Z′ }

11.3 Real-time Model-checking
339
An Example. Consider the automaton of Figure 11.7. The starting node in
the reachability graph is the symbolic state (1, Z0), where
Z0 = x ≤10 ∧x = y
This state denotes that initially (location 1) time can pass up to 10 time units
and that clocks x and y have the same value. One of the direct successors of
the starting node is given by (1, Z1), where
Z1 = x ≤10 ∧y ≤20 ∧y −x = 10
This new symbolic state represents all the concrete states that are reachable
from (l, Z0) by performing transition a, and then letting some time pass in
the target location.
11.3.1.3 A Forward Reachability Algorithm
The reachability algorithm is shown in Figure 11.8. This is sketched as a
Boolean function reachable(A, φ) (where A ∈TA and φ is a state formula)
which can be thought of as exploring the forward reachability graph, generat-
ing its nodes on demand. The algorithm starts with the starting node of the
graph, and then generates, at every step, the set of successors for the node
under consideration. This is repeated until a node is found which satisﬁes the
reachability formula (line 7), or until the whole graph has been explored and
no node has been found to satisfy φ (line 19).
Termination is guaranteed by the normalisation of zones performed during
the generation of successors, and by keeping a set Visited of visited nodes. The
set Waiting contains the nodes to be explored. Notice (line 10) that successors
are generated only for unvisited nodes. Indeed, given two symbolic states (l, Z)
and (l, Zv) s.t. Z ⊆Zv, all states which are reachable from (l, Z) are also
reachable from (l, Zv). Thus, there is no need to explore (l, Z) if (l, Zv) has
been visited already.
We note that this algorithm just sketches those currently implemented in
tools such as Uppaal and Kronos, where many optimisations have been realised
both in terms of data structures and the algorithm itself (see Section 11.3.3).
To conclude this section, then, let us brieﬂy comment on some ways to improve
the algorithm of Figure 11.8.
•
The algorithm could be modiﬁed to avoid keeping visited states in the
Waiting list. Notice that successors are generated and stored in Waiting
regardless of whether they have been previously visited (line 14), thus
potentially wasting memory (until they are eventually checked in line 5).13
13Indeed, Uppaal implements a uniﬁed Waiting-Visited list, minimising the stor-
age of symbolic states during exploration (see, e.g. [62]).

340
11 Timed Communicating Automata
Function reachable(A, φ)
1
begin
2
Visited ←∅;
3
Waiting ←{(l0, Z0)};
4
while Waiting ̸= ∅do
5
Choose (l, Z) ∈Waiting;
6
Waiting ←Waiting \{(l, Z)};
7
if (l, Z) |= φ then return TRUE;
8
end if
9
if ∄(l, Zv) ∈Visited. Z ⊆Zv then
10
Waiting ←Waiting ∪Successors(l, Z);
11
Visited ←Visited ∪{(l, Z)};
12
end if
13
end while
14
return FALSE;
15
end.
Fig. 11.8. A Simple Forward Reachability Algorithm
•
One can observe that the construction of the product automaton is not
necessary for the reachability analysis of a network. Every location in
a symbolic state would correspond to a location vector in the product,
and synchronisation will be solved on demand when successor states are
generated.
•
It is not diﬃcult to modify this algorithm so as to generate the set of traces
that witness the satisﬁability of φ. These traces correspond to paths in the
reachability graph, from the initial symbolic state to the state which was
found to satisfy φ (for example, a simple implementation would consider
storing the current path in a stack for later retrieval). Indeed, trace gen-
eration is a standard and necessary feature of model-checkers, as usually
this is the main source for debugging. This is particularly important in
the veriﬁcation of safety properties: if a safety property is not satisﬁed,
then “observing” the system execution which leads to the error state is
much more useful than just knowing that such an error state is reachable.
Uppaal, for example, provides the means to generate and visualise both
the shortest trace (in terms of number of symbolic states) and the fastest
trace (in terms of accumulated delay).
11.3.1.4 Diﬀerence Bound Matrices (DBMs): A Data Structure to
Represent Zones
Diﬀerence Bound Matrices (DBMs) [71] are eﬃcient data structures to rep-
resent conjunctions of clock constraints (and hence, zones). Consequently,

11.3 Real-time Model-checking
341
symbolic operations such as forward projection, conjunction, reset and nor-
malisation will have their counterparts implemented over DBMs [13,189]. Here
we give just a brief introduction to the representation of zones using DBMs.
Let Z be a zone over the set of clocks CZ = { x1, x2, . . . , xn }. Let x0 be
a special clock denoting the constant 0; i.e. v(x0) = 0 for any valuation v.
Then, Z can be rewritten using just clock-diﬀerence constraints of the form
xi −xj ∼k, where xi, xj ∈CZ ∪{x0}, ∼∈{<, ≤} and k ∈Z.
Given, then, a zone Z written as a conjunction of clock-diﬀerence con-
straints over CZ ∪{x0}, a DBM representing Z will be a matrix M of dimen-
sion (n + 1) × (n + 1), where the Mij element of the matrix stores the bound
for the diﬀerence xi −xj in Z. Formally,
1. Mij is set to (k, ∼), for every constraint xi −xj ∼k occurring in Z;
2. Mij is set to ∞, for every clock diﬀerence xi −xj, i ̸= 0, i ̸= j, which is
not constrained in Z;
3. Mii is set to (0, ≤), denoting that the diﬀerence between a clock and itself
is zero; and
4. M0i is set to (0, ≤), for every clock diﬀerence x0 −xi which is not con-
strained in Z. This denotes that every clock is positive.
For example, the zone
Z deﬁned as x1 ≥5 ∧x1 ≤10 ∧x3 > 20 ∧x1 −x2 = 3
can be rewritten as
Z′ = x0 −x1 ≤−5
∧
x1 −x0 ≤10
∧
x0 −x3 < −20 ∧
x1 −x2 ≤3
∧
x2 −x1 ≤−3
and its corresponding DBM is
⎛
⎜
⎜
⎝
(0, ≤) (−5, ≤) (0, ≤) (−20, <)
(10, ≤) (0, ≤) (3, ≤)
∞
∞
(−3, ≤) (0, ≤)
∞
∞
∞
∞
(0, ≤)
⎞
⎟
⎟
⎠
11.3.2 Example: Reachability Analysis on the Multimedia Stream
Section 11.2.1.1 described a timed automata speciﬁcation (Figure 11.2) for the
multimedia stream, where the Channel was modelled as a pair of automata
Place1 and Place2, each one representing an independent one-place buﬀer syn-
chronising with the Source (which puts packets in the buﬀer via a sourceOut!
action) and the Sink (which receives packets via a sinkIn? action).

342
11 Timed Communicating Automata
One important correctness requirement for this speciﬁcation is that at
least one buﬀer must be empty every time a packet is to be sent, or, equiv-
alently, that there does not exist a reachable state in which the Source is
attempting to send a packet and both Place1 and Place2 are currently trans-
mitting a packet. Notice in Figure 11.2 that this set of reachable states is
characterised by both Place1 and Place2 being in State2, and by v(t1) = 0
or v(t1) = 50 (i.e. those times at which sourceOut! is enabled). Therefore, we
can verify the correctness requirement by testing that reachable(Π, φ) does not
hold, where Π denotes the product automaton corresponding to the network
|A = |⟨Source, Place1, Place2, Sink⟩, and φ stands for the following state
formula (where A.l denotes that l is a location of A),
φ = ((Source.State0 ∧t1 = 0) ∨t1 = 50) ∧Place1.State2 ∧Place2.State2
Figure 11.9 shows a fragment of the forward reachability graph, where we
have annotated the edges with the components involved in their generation.
The Figure depicts a 5-state path in the graph; every symbolic state being
composed of a vector location and a zone. For example, S0 corresponds to
the initial symbolic state, in which the location vector ⟨0, 1, 1, 1⟩corresponds
to Source.State0, Place1.State1, Place2.State1 and Sink.State1; and the initial
zone represents that all clocks are initially set to zero. Moreover, because of the
constraint t1 ≤0, time is not allowed to pass. The outgoing edge corresponds
to the initial, urgent sourceOut between the Source and Place1, and connects
S0 with one of its successors, S1. Notice that, although it is not shown in the
Figure, a similar edge does exist which corresponds to a sourceOut between
Source and Place2, because at this point the Source may synchronise with
either buﬀer. The zone in S1 conﬁrms the intuition that, after performing the
ﬁrst sourceOut action, control can remain in Source.State1 and Place1.State2
as long as v(t1) ≤50 and v(t4) ≤90. Following a similar reasoning, S4
represents all those states which can be reached after the ﬁrst packet has
been played and before the second packet arrives at the Sink, provided the
ﬁrst packet was initially put in Place1.
11.3.3 Issues in Real-time Model-checking
Canonical zones. In general, a given set of valuations can be described by
an inﬁnite number of zones. However, every zone can be converted to a closed
form (also called a canonical form) such that no constraint can be strength-
ened without reducing the solution set. Working with zones in closed form
has the advantage of fast inclusion checking (which, as we have seen, occurs
at every step of the reachability algorithm), and thus, operations on zones are
implemented on DBMs in such a way that they yield closed zones, or resulting
zones are “closed” as a ﬁnal step [13].
Unfortunately, the algorithm used to obtain zones in closed form usually
produces zones with redundant constraints. The work of Larsen et al. [116,117]

11.3 Real-time Model-checking
343
play
(Sink)
S0
S1
S2
S3
S4
<0,1,1,1>
t1=t2=t3=t4,
t1<=0
<1,2,2,1>
t1=t3,
t2=t4,
t1<=50,
t3<=90,
t4<=90,
t4−t1=50
<1,2,1,1>
t1=t2=t3=t4,
t1<=50,
t4<=90
sourceOut
(Source || Place1)
sourceOut
(Source || Place2)
sinkIn
(Place1 || Sink)
<1,1,2,2>
t1=t3,
t1<=50,
t2<=5,
t3<=90,
t4−t1=50,
t4−t2>=80
<1,1,2,1>
t1=t3,
t1<=50,
t2>=5,
t3<=90,
t4−t1=50,
t4−t2>=80
Fig. 11.9. Reachability Graph (Fragment) for the Multimedia Stream
provides a step further towards minimal representation of zones. The authors
describe a minimisation algorithm for DBMs, which reduces the space re-
quirements for zones, obtaining a closed representation that is minimal in the
number of constraints. This also results in faster zone-related operations, e.g.
checking for zone-inclusion, and thus might improve the time requirements
of reachability analysis in general. The authors present, as well, a technique
which proposes to store, as visited, just a particular subset of all symbolic
states generated by the reachability algorithm. It is shown that this particu-
lar subset is suﬃcient to guarantee termination of reachability checking, while
reducing the space requirements as fewer states need to be kept as visited.
These states are identiﬁed based on static information: certain key locations
are detected that are entry points for loops in the timed automaton graph.
Bengtsson [12] and David et al. [63] describe techniques for eﬃcient storage
of symbolic states in Uppaal.
Normalisation. Normalisation can be eﬃciently implemented if zone con-
straints are reduced with respect to individual upper bounds (i.e. the greatest
upper bound per clock), instead of one single upper bound for all clocks. This
is currently done in Uppaal and Kronos (see [13] for a description of the tech-
nique). More eﬃcient abstractions have been recently found [11], which take
into account both upper and lower bounds for clocks.
Over- and under-approximation. These two abstractions are used to re-
duce the state-space during veriﬁcation, at the expense of potentially incon-
clusive answers. With over-approximation [9, 67], the union of zones, which
could be related to the same location is replaced by its convex hull. Because
the set of clock valuations satisfying a convex hull can be a proper superset

344
11 Timed Communicating Automata
of those satisfying the corresponding union of zones, it cannot be concluded
that a given state is reachable. This abstraction can, though, guarantee that
a given state is unreachable. Over-approximation has been implemented both
in Kronos and Uppaal.
With under-approximation [12,98,186,200], a hash signature is computed
for every symbolic state, and only this signature is kept as a record of vis-
ited states. With a small probability, a number of symbolic states might have
the same hash signature, and so a new symbolic state found during reach-
ability will be assumed to be visited if some other state with the same sig-
nature has already been visited. This may yield situations in which some
parts of the state-space remain unexplored when the reachability analysis
is ﬁnished (i.e. those symbolic states which could only be reachable from a
state that was wrongly assumed to be visited). Consequently, the results of
under-approximation are inconclusive if a state is “found” to be unreachable.
Under-approximation is available in Uppaal.
Clock reduction. Daws and Yovine [68] describe a static algorithm which
identiﬁes those clocks which are irrelevant during reachability analysis. Infor-
mally, a clock is said to be active from the point where it is reset up to the
point where it is tested (i.e. in a guard or invariant), without being reset on the
way. For every location in the timed automaton, then, a set of active clocks can
be computed (the technique is compositional, and thus generalises to location
vectors for networks of automata). Later, during reachability analysis, zones
are generated so as to include just those constraints which refer exclusively to
the active clocks related to the corresponding location. This may result, not
only in smaller zones, but also in fewer symbolic states (e.g. diﬀerent sym-
bolic states related through the same location might become indistinguishable
when inactive clock constraints are removed from the corresponding zones).
Clock reduction has been implemented both in Kronos and Uppaal.
Symmetry reduction. Hendricks et al. [88] describe an extension to Uppaal
with symmetry reduction, aiming to limit the state-explosion problem. The
user is expected to provide a number of scalarsets [100] representing the (full)
symmetries of the system. This (and other static information) is used to de-
rive an abstraction that partitions the set of symbolic states (as generated by
the forward reachability graph) into a number of equivalence classes: all states
in a class are regarded as symmetric upon a notion of state swap. Moreover,
the authors show how, for any given symbolic state, a unique representative
of the state’s equivalence class can be eﬃciently computed. In this way, the
forward reachability graph can be generated just among representative states.
Experiments described in [88] conﬁrm that, for systems which present a high
degree of symmetry, the gain in space-performance can even approach a fac-
torial magnitude. Symmetry reduction is expected to be a standard feature
of forthcoming Uppaal releases.

11.3 Real-time Model-checking
345
Beyond reachability checking. Aceto et al. [3] present a temporal logic
L∀S which characterises the set of properties whose veriﬁcation can be re-
duced to reachability checking. Given a property in L∀S, a test automaton
can be derived which contains a distinguished “rejecting” state. The property
is considered satisﬁed if this reject state is not reachable when the system is
composed with the test automaton. In this way, for example, some properties
can be veriﬁed in Uppaal even when they cannot be directly expressed in its
speciﬁcation language (which is a subset of TCTL).
In contrast with the branching-time properties (TCTL) usually considered,
Tripakis [189] presents algorithms to model-check linear-time properties, ex-
pressed as Timed B¨uchi Automata (TBA), and ETCTL∗
∃properties, a logic
which is strictly more expressive than both TCTL and TBA. Also, Tripakis
shows how existing untimed model-checking techniques and tools (e.g. the
CADP toolset [81]) could also be used to verify timed systems. This involves
the generation of a quotient graph, an untimed automaton, which is (time-
abstracting) bisimilar to the original system. This reduction from a timed to
an untimed system can also be used to check whether two timed automata
are behaviourally equivalent, by checking that their quotients are bisimilar
with respect to an untimed bisimulation. Most of these techniques have been
included in Kronos.

12
Timelocks in Timed Automata
12.1 Introduction
Informally speaking, a system can “timelock” if a state can be reached where
time cannot diverge in any possible run.1 Timelocks can arise for a number
of reasons, and diﬀerent classes of timelock need to be handled in diﬀerent
ways. In particular, we can distinguish between time-actionlocks, which are
states where neither time nor action transitions can be performed, and zeno-
timelocks: states where time is unable to pass beyond a certain point, but
actions continue to be performed. In other words, a zeno-timelock can be seen
as a situation where an inﬁnite number of actions are performed in a ﬁnite
period of time.
It is important to realise that timelocks are quite diﬀerent from action-
locks, which are the analogue of deadlocks in untimed speciﬁcations. Criti-
cally, actionlocks allow time to pass; even when the automaton is unable to
perform any further “useful” computation, it does not prevent other compo-
nent automata from passing time. Timelocks, on the other hand, propagate
to the rest of the network; this is a consequence of timed automata implicitly
synchronising on the passage of time.2
In most cases (if not all), real-time model-checking is meaningful only for
speciﬁcations that are free from timelocks. For example, consider the network
shown in Figure 12.1. Notice that the automaton A1 contains a timelock when
v(x) = 1 (this could have been a consequence, for example, of the designer
forgetting to reset x in transition a). Consider the veriﬁcation of the (TCTL)
safety property AG ¬A2.E, which expresses the unreachability of a certain
error-state in the network (represented by location E in A2). Now, this error-
state can only be reached after 2 time units have passed; i.e. after transition
1Notice that this is consistent with the intuition of timelocks in timed process
calculi (Section 9.2.2).
2The same applies to tLOTOS, because parallel processes synchronise on the
passage of time (Section 10.1.2).

348
12 Timelocks in Timed Automata
b is performed. However, this will never happen, because the timelock in A1
does not allow time to progress beyond 1 time unit. Then, the safety property
will be found satisﬁable (because no error-state can ever be reached), giving
false conﬁdence in the model’s correctness (and so we are left with validation
problems). Undetected, this error-state might still be present at some later
implementation stage; after all, a system that “stops time” is not physically
realisable.
1
||     =>
x<=1
2
E
A1:
A2:
x<=1
x=1
a
x=1  a
x=1  a
<1,E>
<1,2>
x<=1
y>2   b
y>2   b
Fig. 12.1. Timelocks and Safety Properties
In this chapter we present a classiﬁcation of deadlocks in timed automata,
and discuss solutions for every class. In particular, we describe timed automata
with deadlines [29] which are, by construction, free from time-actionlocks (also
known as time reactiveness). In addition, the chapter includes an analytical
method to ensure absence of zeno-timelocks (also called nonzenoness), which
builds upon the notion of strong nonzenoness [190]. This method extends
earlier results and broadens the class of timed automata speciﬁcations that
can be guaranteed to be nonzeno. Also, the more general concept of inherently
safe automata is introduced. This embodies a number of properties that can
be checked at the level of the automaton’s syntax (in particular, loops) and
guarantee that a zeno-timelock does not occur.
Detecting zeno-timelocks at a syntactic level is usually eﬃcient, and in
many cases compositional (i.e. depending on the check, nonzeno components
guarantee that the network itself is also nonzeno). Also, syntactic properties
are usually general enough to analyse most speciﬁcations, as zeno-timelocks
seldom occur. However, these properties are suﬃcient-only, in the sense that
they can only guarantee nonzenoness: if the properties are not fulﬁlled, then
a zeno-timelock may or may not occur, but neither case can be proved.
For some systems, where a complete conﬁdence in the nonzenoness status
must be established, suﬃcient-only methods are not enough. This motivates
a discussion of suﬃcient-and-necessary conditions for nonzenoness. In par-
ticular, a condition is presented that can be reduced to simple reachability
analysis. The method works at the level of the product automaton, using
ﬁrst suﬃcient-only conditions to identify those loops that do not produce
zeno-timelocks. A certain kind of reachability formula will then be derived,

12.2 A Classiﬁcation of Deadlocks in Timed Automata
349
syntactically, from the remaining loops. The satisﬁability of these formulae is
both suﬃcient and necessary to decide whether a zeno-timelock occurs in the
automaton.
This chapter is organised as follows. Section 12.2 presents a classiﬁcation
of the diﬀerent kinds of deadlocks that may occur in timed automata. Later,
Section 12.3 elaborates on time-actionlocks, and discusses a solution based
on timed automata with deadlines (Section 12.3.1). Section 12.4 describes
zeno-timelocks in detail, and presents both suﬃcient-only and suﬃcient-and-
necessary conditions for nonzenoness. Finally, Section 12.5 gives an overview
on the detection of timelocks in Uppaal and Kronos. Let us note that, when-
ever not deﬁned otherwise, this chapter follows the timed automata notation
and deﬁnitions given in Chapter 11.
12.2 A Classiﬁcation of Deadlocks in Timed Automata
In a broad sense, deadlocks are states where the system is unable to progress
further. In untimed systems, deadlocks are states where the system is unable to
perform any action. However, in timed automata, transitions correspond either
to time-progress or the execution of actions. Consequently, in this setting, the
ways of violating the requirements of progress can vary.
Generally speaking, an actionlock is a state where, for however long time
is allowed to pass, no action transition can be performed. Formally, given
A = (L, TL, T, l0, C, I) ∈TA with TTS (S, Lab, TS, s0), a state s ∈S is an
actionlock if
∀d ∈R+0 , s + d ∈S =⇒∄a ∈Act . s + d
a
−→→
where, if s = [l, v], then s + d = [l, v + d]. On the other hand, a timelock
is a state s ∈S where time is not able to progress beyond a certain limit.
Equivalently, s is a timelock if every run starting from s, ρ(s), converges:
∀ρ(s) ∈Runs(A) , delay(ρ) ̸= ∞
A timed automaton A is actionlock-free (timelock-free) if none of its reachable
states is an actionlock (timelock). Actionlocks and timelocks can be further
classiﬁed as pure-actionlocks, time-actionlocks or zeno-timelocks (also called
pure timelocks), which are explained next.
Pure-actionlock. A pure-actionlock is a state where the system cannot per-
form any action transitions, but time is allowed to progress. Figure 12.2(i)3
shows an example of a timed automaton with a pure actionlock: no action is
enabled once the automaton reaches location 2, however, time is not prevented
from passing. Formally, a state s is a pure-actionlock if
3Omitted guards and invariants are assumed to be true.

350
12 Timelocks in Timed Automata
∀d ∈R+0 , s + d ∈S ∧∄a ∈Act . s + d
a
−→→
Time-actionlock. Time-actionlocks are states where neither action nor time
transitions can be performed. For example, Figure 12.2(ii) shows a time-
actionlock produced by a mismatched synchronisation between two automata.
Transition a! in the upper automaton is urgent when v(x) = 5, but it cannot
synchronise with a? in the lower automaton, because this transition is not
enabled at that time. Consequently, the system enters a time-actionlock state
at v(x) = 5. Formally, s ∈S is a time-actionlock if,
∄a ∈Act, d ∈R+ . s
a
−→→∨s
d
−→→
Zeno-timelock. In such a state, systems can still perform transitions (which
can be either action or time transitions), but time cannot pass beyond a
certain point. This represents a situation where the system performs an inﬁnite
number of actions in a ﬁnite period of time. For example, any reachable state
in the automaton shown in Figure 12.2(iii) is a zeno-timelock, because time
can only pass up to 5 time units and transition a is always enabled. Hence,
a becomes urgent at v(x) = 5 and will be performed inﬁnitely often, without
time-passing at all. Formally, s ∈S is a zeno-timelock if there exists at least
one inﬁnite run starting from s, and all such runs are zeno; i.e.
∃ρ(s) ∈ZRuns(A) ∧∀ρ(s) ∈Runs(A), ρ(s) ∈ZRuns(A)
a!
x>5 a?
x<=5
a
a
b
c
1
2
1
2
3
4
1
x<=10
x<=5
(i)
(ii)
(iii)
Fig. 12.2. (i) Pure-actionlock (ii) Time-actionlock (iii) Zeno-timelock
12.2.1 Discussion: Justifying the Classiﬁcation of Deadlocks
One reason for presenting this classiﬁcation is that we believe that diﬀer-
ent types of deadlocks bring diﬀerent types of problems and, hence, should
be treated diﬀerently. Firstly, although pure actionlocks may be undesirable
within the context of a particular speciﬁcation, they are not of themselves

12.2 A Classiﬁcation of Deadlocks in Timed Automata
351
counterintuitive situations. It is wholely reasonable that a component or a
system might reach a state from which it cannot perform any actions, as long
as such an actionlock does not stop time. Thus, although analytical tools that
detect pure-actionlocks certainly have value, we do not believe there is any
fundamental reason why actionlocks should be prevented (by construction) at
the level of the speciﬁcation notation.
In contrast, we are strongly of the opinion that time-actionlocks are coun-
terintuitive. In particular, and as previously discussed, a local “error” in one
component has a global eﬀect on the entire system, even if other components
have no actions in common with the timelocked component. Because of these
particularly counterintuitive aspects, we believe that time-actionlocks should
be prevented by construction; i.e. the timed automata model should be rein-
terpreted in such a way that time-actionlocks just cannot arise.
Finally, to come to zeno-timelocks: our position here is that analytical
methods should be provided to check on a speciﬁcation-by-speciﬁcation basis
whether zeno-timelocks occur. Our reasons for advocating this approach are
largely pragmatic, because it is not clear how the timed automata model could
be changed in order to constructively prevent such situations. In particular,
any mechanism that ensured at the level of the semantics that a minimum
time (say ϵ) was passed on every cycle, would impose rigid constraints on the
speciﬁer’s ability to describe systems abstractly. Sections 12.4.2 and 12.4.3
consider just such an analytical method for detecting zeno-timelocks.
12.2.2 Discussion: Timelocks in Process Calculi
It is interesting to mention that in the early work on timed concurrency theory,
which largely focused on timed process calculi (see Chapter 9), the problem
of timelocks was noted and partially resolved. As a result most timed process
calculi only allow urgency to be applied to internal actions, and so timelocks
due to synchronisation mismatches cannot happen. Indeed, they often enforce
the so-called as soon as possible (asap) principle [168] that we have mentioned
in Section 9.2.2; in such an interpretation, internal actions are considered
implicitly urgent and will be performed as soon as they are enabled.
In timed process calculi with asap, a hiding operator can be used to make
synchronisation urgent without causing a time-actionlock (see Sections 9.2.10
and 9.4). The hiding operator turns observable into internal actions, which
are, as we just mentioned, urgent as soon as they are enabled. Because ob-
servable actions correspond to successful synchronisation between half actions,
synchronisation is only made urgent if it is possible. This rules out most
time-actionlocks in timed process calculi with asap (as we have discussed in
Section 9.4, unguarded recursion can though also generate time-actionlocks).
Unlike timed process calculi, timed automata do not incorporate a hiding
operator, and so it is not possible to selectively take an observable action that
results from synchronising half actions and turn it into an (urgent) completed
action. Instead, urgency can only be speciﬁed individually for half actions,

352
12 Timelocks in Timed Automata
regardless of whether synchronisation is possible.
12.3 Time-actionlocks
As previously discussed, perhaps the most counterintuitive aspect of the time-
lock story is the manner in which timelocks can arise from mismatched syn-
chronisations (e.g. Figure 12.2(ii)). If we consider how this problem arises, we
can see that it is caused by the particular interpretation of urgent interaction
employed in timed automata.
It is undoubtedly true that facilities to express urgency are required; oth-
erwise certain important forms of timing behaviour could not be expressed
(e.g. timeouts; see Section 9.2.2). However, it is our perspective that although
urgency is needed, currently it is given an excessively strong formulation. We
illustrate this issue with a modiﬁed speciﬁcation for the multimedia stream
example.
Consider the model shown in Figure 12.3, where now packets can be sent
to the Sink by two diﬀerent sources, Source1 and Source2. The behaviour
of the new added Source2 is similar to that of Source1, although (a) it can
send the ﬁrst packet at any time (notice that there is no invariant attached
to Source2.State0) and (b) following packets are sent faster than in Source1
(1 packet every 25 ms). This, however, will produce a time-actionlock in the
network.
Consider the following scenario. Source1 sends its ﬁrst packet to Place1,
at time t = 0. Later, say at t = 10, Source2 sends its ﬁrst packet to Place2. By
the time that Source2 attempts to send the second packet (t = 35), neither
Place1 nor Place2 can oﬀer a matching sourceOut?, as the transmission of
the previous packets is not yet ﬁnished (the transmission delay is at least 80
ms). At this point, a time-actionlock occurs: because sourceOut! in Source2 is
urgent at t = 35, time is prevented from passing and no action is enabled.
The time-actionlock occurs because Source2 makes the sourceOut! action
urgent even when it is not enabled, as both Place1 and Place2 are currently
transmitting packets and synchronisation cannot be achieved. Moreover, the
time-actionlock propagates to all other components because time is prevented
from passing. We would argue, then, that it should only be possible to make
an action urgent if it is enabled, i.e.
must requires may or, in other terms, you can only force what is pos-
sible.
Such an interpretation of urgency arises in Timed Automata with Deadlines
(TADs) [29,30], which are discussed in the next section. In particular, certain
time constraints (so-called deadlines) are attached to actions denoting those
time intervals where the action is considered urgent. Because every deadline
implies the action’s guard, only enabled actions can be urgently performed,

12.3 Time-actionlocks
353
State1
State2
t4<=90
State1
t1<=50
t1=50
sourceout !
t1:=0
State1
State2
t3<=90
State1
State2
t2<=5
play
t2=5
Place1
Place2
Sink
State0
State1
t5<=25
Source1
Source2
State0
t1=0
sourceOut !
sourceOut !
t5:=0
t5=25
sourceOut !
t5:=0
sourceOut ?
t3:=0
sourceOut ?
t4:=0
sinkIn ?
t2:=0
sinkIn !
t4>=80
sinkIn !
t3>=80
Fig. 12.3. A Multimedia Stream with Two Sources and a Time-actionlock
and therefore time-actionlocks are ruled out by construction (although zeno-
timelocks, on the other hand, can still occur). Timed automata with deadlines,
then, guarantee time reactiveness (i.e. the absence of time-actionlocks) by
construction.
12.3.1 Timed Automata with Deadlines
Informally speaking, timed automata with deadlines [29, 30, 34, 35] can be
described as timed automata where the time progress condition is expressed
by deadlines, instead of invariants. Importantly, TADs are time reactive; i.e.
time-actionlocks cannot occur. Diﬀerent variants of TADs have been proposed,
which diﬀer in the treatment of parallel composition (although all of them
preserve time reactiveness), e.g. standard TADs, sparse TADs and TADs with
minimal priority escape transitions [34]. Our presentation of TADs in this
section follows the model of Sparse-TADs, developed by Bowman in [34,35].
Deadlines are clock constraints attached to transitions (in contrast with
invariants, which are attached to locations), which determine when the transi-
tion is considered urgent. However, in TADs, time cannot be prevented from
passing by an “urgent” transition not being enabled. This is an important
diﬀerence between invariants and deadlines: unlike in TAs, urgency in TADs
does not cause time-actionlocks. Let us illustrate this issue with the following
example.

354
12 Timelocks in Timed Automata
Figure 12.4(i) shows a network of two TADs4, and the corresponding prod-
uct automaton to the right. Assuming all clocks are initially set to zero, tran-
sition b! is enabled in the time interval [1, ∞), and is urgent in [2, ∞): the
deadline (x ≥2) expresses that, during [2, ∞), synchronisation must happen
as soon as possible. In the second automaton, b? is enabled during [3, ∞), and
is urgent in [4, ∞). But then, what happens when v(x) = v(y) = 2? Clearly, at
this point in execution, transition b! is enabled and enters its urgency period,
but b? is not yet enabled, and so synchronisation cannot occur! Deadlines on
half actions enforce urgency only if synchronisation can be achieved. Equiva-
lently, synchronisation is urgent as soon as: (a) one of the parties is urgent, and
(b) both parties can synchronise (i.e. when both half actions are enabled).5
As a result, b! “waits” for b? to become enabled, and so synchronisation is im-
mediately performed when v(x) = v(y) = 3. It is important to note that time
passes until synchronisation is possible, and so synchronisation mismatches
cannot cause time-actionlocks. This behaviour is evident from the structure
of the product automaton: the guard on b results from conjoining the compo-
nent guards, and the deadline assigned to b is deﬁned as the disjunction of the
component deadlines, conjoined with the component guards. In this way, the
deadline on b implies its guard. Furthermore, by construction, every deadline
in a TAD speciﬁcation implies the corresponding guard: this is true for half
actions, completed actions in components and completed actions which re-
sult from synchronisation. It is not diﬃcult to see, then, that time-actionlocks
cannot occur in TAD speciﬁcations.
The TA speciﬁcation in (ii), on the other hand, shows that invariants en-
force a stronger form of urgency than deadlines. Notice that the network of
TAs shown in (ii) “intends” to mimic the network of TADs in (i); for example,
the invariant x ≤2 (in location 1), makes b! urgent at v(x) = v(y) = 2. How-
ever, unlike the network of TADs, the network of TAs enters a time-actionlock
at v(x) = v(y) = 2: synchronisation cannot yet occur, but the invariant in
location 1, x ≤2, prevents time from passing any further. Even though, in this
example, half actions are not urgent until they are enabled (e.g. b! becomes
enabled at v(x) = 1, and is not urgent until v(x) = 2), invariants will enforce
this “local” urgency regardless of whether synchronisation is possible. This
can be seen in the product automaton: the invariant in ⟨1, 3⟩prevents time
from passing beyond v(x) = v(y) = 2, even though b is not yet enabled.
12.3.1.1 Formal Deﬁnitions: Timed Automata with Deadlines
Here we just highlight the basic elements of the theory, and refer the reader
to [29, 30, 34, 35] for a more comprehensive presentation. Unless stated oth-
4In our TAD ﬁgures, deadlines are shown in brackets; “,” denotes conjunction;
and “|” denotes disjunction.
5Notice that tLOTOS adopts a similar approach: internal actions (in particular,
those which result from synchronisation) are urgent on their upper bounds (Sec-
tion 9.2.10).

12.3 Time-actionlocks
355
1
2
3
4
(TAD)
||     =>
<1,3>
<2,4>
1
2
3
4
||     =>
<1,3>
<2,4>
(i)
(ii)
(TA)
x>=1 b!
y<=4
x>=1
b!
(x>=2)
y>=3
b?
(y>=4)
x>=1, y>=3
b
((x>=2 | y>=4),
  x>=1,y>=3)
x<=2
y>=3 b?
x>=1, y>=3
b
x<=2,
y<=4
Fig. 12.4. Parallel Composition in TADs and TAs
erwise, the notation used here respects the sets and conventions deﬁned for
timed automata in Section 11.2.
Syntax. A timed automaton with deadlines (or simply, TAD) is a tuple of the
form A = (L, TL, T, l0, C), where L is a ﬁnite set of locations (l0 ∈L is the
initial location); TL ∈Act is a set of labels; T is a transition relation and C
is a set of clocks. Transitions in T are denoted l
a,g,d,r
−−−−−→l′, where l, l′ ∈L are
automata locations; a ∈TL is the action labelling the transition; g ∈CC C
is a guard; d ∈CC C is a deadline; and r ∈P(C) is a reset set. In addition,
deadlines and guards satisfy the following conditions.
1. Deadlines imply guards,
(C1) l
a,g,d,r
−−−−−→l′ =⇒(d ⇒g)
2. If both a deadline and its corresponding guard denote the same solution
set, then this set must denote a left-closed time interval,
(C2) l
a,g,d,r
−−−−−→l′ =⇒((d = g) ⇒∃v . (v |= g) ∧∀v′ , (v′ |= g) ⇒v′ ≥v)
Let us illustrate the necessity for condition (C2) with the following example.
Assume a transition with guard g = x > 1 and deadline d = x > 1, where
x ∈C. Notice that both g and d denote the same solution set, which corre-
sponds to the left-open interval v(x) ∈(1, ∞). This transition will be urgent
as soon as it is enabled, but the constraint imposed by the d does not allow

356
12 Timelocks in Timed Automata
time to progress beyond v(x) = 1 (to see why, check the semantic rule S2
below). It should not be diﬃcult to see, then, that TADs that do not fulﬁll
(C2) are not guaranteed to be time reactive, even if deadlines imply guards
(C1).
Semantics. Let A = (L, TL, T, l0, C, I) be a TAD where all actions are
completed (i.e. TL ⊆CAct). The semantics of A are given by the TTS
(S, Lab, TS, s0), where
•
S ⊆L × VC is the set of reachable states; i.e.
S = { s0 } ∪{ s′ | ∃s ∈S, γ ∈Lab . s
γ
−→→s′ }
•
s0 = [l0, v0] is the starting state;
•
Lab = TL ∪R+ is the set of transition labels;
•
TS ⊆S × Lab × S is the transition relation, deﬁned by the following
inference rules,
(S1) l
a,g,d,r
−−−−−→l′ v |= g
[l, v]
a
−→→[l′, r(v)]
(S2) ∀l′ , l
a,g,d,r
−−−−−→l′ ⇒∀t′ < t ∈R+ , v + t′ ̸|= d
[l, v]
t
−→→[l, v + t]
At the beginning of this section, we elaborated on the relation between dead-
lines and invariants; let us carry on with this comparison a bit further. Ur-
gency, as expressed by deadlines in TADs, has more in common with a weak
interpretation of invariants in TAs (Section 11.2.2), than it does with the
strong interpretation. For example, the TAD shown in Figure 12.5(i) can per-
form transition a at any time (false-deadlines model non urgent actions), but
it will take b immediately after that. This behaviour corresponds to the timed
automaton with weak invariants in (ii). Notice that, if the same automaton
would be given a strong invariant interpretation, no transition (not even a)
can ever be performed, as locations with false-invariants cannot be entered.
On the other hand, the timed automaton with strong invariants shown in (iii)
achieves the same behaviour as the TAD in (i), at the expense of adding a
clock x, which is reset in a, and attaching the invariant x = 0 to location 2.
In any case, as we have discussed before (and illustrated by Figure 12.4), the
semantics of networks of TADs cannot always be expressed by networks of
TAs.
Parallel Composition (Sparse TADs). Let |A = ⟨A1, ... , An⟩be a net-
work of TADs, where

12.3 Time-actionlocks
357
1
2
3
a
b
(false)
1
2
3
a
b
false
(true)
true
true
1
2
3
a
b
true
true
x:=0
x=0
(i) TAD
(ii) TA−weak invariants
(iii) TA−strong invariants
Fig. 12.5. Deadlines, Weak Invariants and Strong Invariants
Ai = (Li, TLi, Ti, li,0, Ci)
for 1 ≤i ≤n. Let u, u′, etc. denote location vectors. Once again, here we
follow the substitution notation introduced in Section 8.2.2.2. The product
automaton is deﬁned as
Π = (L, TL, T, l0, C)
where
•
L = { l0 } ∪{ u′ | ∃u ∈L, a, g, d, r . u
a,g,d,r
−−−−−→u′ };
•
TL =
n
i=1
TLi;
•
T is as deﬁned by the following rules (1 ≤i ̸= j ≤n),
(TAD1) ui
a?,gi,di,ri
−−−−−−−→i l uj
a!,gj,dj,rj
−−−−−−−→j l′
u
a,g′,d′,ri∪rj
−−−−−−−−−→u[l →i, l′ →j]
(TAD2) ui
a,g,d,r
−−−−−→i l a ∈CAct
u
a,g,d,r
−−−−−→u[l →i]
where g′ ≜gi ∧gj and d′ ≜gi ∧gj ∧(di ∨dj);
•
l0 = ⟨l1,0, . . . , ln,0⟩; and
•
C =
n
i=1
Ci
Rule (TAD1) deﬁnes synchronisation in TADs. As in TAs, guards and reset
sets of component transitions (matching half actions) are combined in the re-
sulting transition in the product automaton (completed action). Two things
must be noticed in the deﬁnition of the resulting deadline. First, the disjunc-
tion of component deadlines ensures that synchronisation is made urgent if
at least one of the involved half actions is urgent. Second, and as it is nec-
essary to ensure time-reactiveness, conjoining the component guards ensures
that deadlines in the product automaton’s transitions imply their guards. In
other words, synchronisation is urgent only if it can be performed. Finally, rule
(TAD2) gives the standard interpretation for completed actions in component
TADs.

358
12 Timelocks in Timed Automata
12.3.2 Example: A TAD Speciﬁcation for the Multimedia Stream
Figure 12.6 shows a TAD speciﬁcation for the multimedia stream, correspond-
ing to the example discussed in Section 12.3. Transitions have been annotated
with the necessary deadlines (shown in brackets): for example, sourceOut?
in Source1.State1 is made urgent as soon as it is enabled (with a deadline
t1 = 50). Let us revisit the scenario which caused a time-actionlock in the TA
speciﬁcation (see again Figure 12.3). Source1 sends at t = 0; Source2 sends
at t = 10 and attempts to send the second packet at t = 35. At this point,
Source2 blocks because synchronisation with sourceOut? in either Place1 or
Place2 is not possible. However, unlike in the TA speciﬁcation, time is not
prevented from passing and all the other components can evolve normally.
This is so because deadlines attached to half actions are only enforced if syn-
chronisation can be achieved (rule TAD1).
State1
State1
State1
Place1
Place2
Sink
State0
State0
State1
State2
State2
State2
State1
Source1
Source2
sourceOut !
(t1=0)
sourceOut ?
t4:=0
sourceOut ?
t3:=0
sinkIn ?
t2:=0
sourceOut !
t5:=0
t1=50
sourceout !
(t1=50) t1:=0
play
t2=5
(t2=5)
t5=25
sourceOut !
(t5=25)
 t5:=0
sinkIn !
t3>=80
(t3=90)
sinkIn !
t4>=80
(t4=90)
Fig. 12.6. A TAD Speciﬁcation for the Multimedia Stream (with Two Sources)

12.4 Zeno-timelocks
359
12.4 Zeno-timelocks
This section elaborates on a number of methods to detect nonzenoness
[44, 190]. Before discussing these approaches in detail, let us introduce some
basic concepts and notation which appear throughout the section.
Preliminaries. Let A ∈TA. A simple loop is a cycle in the timed automaton
graph; i.e. a sequence of locations and transitions of the form,
l0
a1,g1,r1
−−−−−→l1
a2,g2,r2
−−−−−→. . .
an,gn,rn
−−−−−−→ln
where l0 = ln such that li ̸= lj for all 0 ≤i ̸= j < n. A nonsimple loop is,
correspondingly, a sequence of locations and transitions that starts and ends
in the same location, and also contains other repeating locations.
Unless otherwise stated, when we talk about loops we are referring to
simple loops. Usually, we refer to loops (both simple and nonsimple) through
their component transitions. For example, Figure 12.7 shows two simple loops,
⟨ab⟩6 and ⟨cd⟩, and one nonsimple loop, ⟨acdb⟩. The entry point (a location
through which the loop is reachable) in these loops is location 1, where x is
previously set to 0.
x:=0
1
x<=1
x<=1
x<=1
3
2
a
b
c
d
Fig. 12.7. Simple and Non Simple Loops
Let Loops(A) be the set of all loops in A, and lp a given loop in A. Loc(lp)
is the set of all locations of lp; Clocks(lp) is the set of all clocks occurring in any
invariant of lp; Trans(lp), Guards(lp) and Resets(lp) are, respectively, the sets
of all transitions of lp, all guards of lp, and all clocks that are reset in lp; and
Act(lp) is the set of all actions labelling transitions in lp. A half loop is a loop
that contains at least one transition labelled with a half action. A completed
loop is a loop which is not a half loop, i.e. a loop where all transitions are
labelled with completed actions.
12.4.1 Example: Zeno-timelocks in the Multimedia Stream
Figure 12.8 shows a multimedia stream similar to the one described in Sec-
tion 12.3 (Figure 12.3), but where a new component Source3 has been added.
6The notation for loops must not be confused with that we have used for location
vectors, e.g. ⟨1, 3⟩.

360
12 Timelocks in Timed Automata
This automaton models an unreliable source, which will attempt to send pack-
ets at a speed of 1 packet per 100 ms but, occasionally, a failure may occur,
which forces the source to enter an Oﬄine state. Source3 will remain in Of-
ﬂine for an unspeciﬁed period of time, and then it will restart the sequence
again.
Consider, once more, the scenario which in Figure 12.3 caused a time-
actionlock: Source1 sends at t = 0 to Place1; Source2 sends at t = 10 to Place2
and attempts to send again at t = 35, but is blocked because synchronisation
with sourceOut? in either Place1 or Place2 is not possible. At this point,
v(t5) = 25, and so the invariant t5 ≤25 in Source2.State1 prevents time from
passing any further. However, and unlike in the speciﬁcation of Figure 12.3,
a time-actionlock does not occur because transition failure at Source3.State0
is enabled. Moreover, notice that all inﬁnite runs starting at Source3.State0
converge, because the loop ⟨failure, reset⟩can be visited inﬁnitely often while
time is blocked by Source2. A zeno-timelock occurs, then, at a state s = [l, v]
where l is a location vector denoting Source1.State1, Source2.State1, Source3.
State0, Place1.State2, Place2.State2 and Sink.State1, and v is s.t. v(t) = 25
for t ∈{t3, t5} and v(t) = 35 for t ∈{t1, t2, t4, t6}.
State1
State2
t4<=90
State1
t1<=50
State1
State2
t3<=90
State1
State2
t2<=5
play
t2=5
Place1
Place2
Sink
State0
State1
t5<=25
State0
Source3
failure
Offline
reset
t6:=0
State0
t1=0
sourceOut !
t1=50
sourceOut !
t1:=0
sourceOut ?
t4:=0
t5=25
sourceOut !
t5:=0
sourceOut ?
t3:=0
t6=100
sourceOut !
t6:=0
sinkIn ?
t2:=0
sourceOut !
t5:=0
sinkIn !
t3>=80
sinkIn !
t4>=80
Source1
Source2
Fig. 12.8. A Multimedia Stream with Three Sources and a Zeno-timelock

12.4 Zeno-timelocks
361
12.4.2 Nonzenoness: Syntactic Conditions
Tripakis [190] showed that the absence of zeno-timelocks (nonzenoness) in a
timed automaton can be determined from the syntactic structure of its loops.
By deﬁnition, a zeno-timelock occurs when some state can be reached in the
automaton where actions are performed inﬁnitely often, in a ﬁnite period of
time. Now, actions can only be performed inﬁnitely often if they are part of
some loop. Thus, in order to ensure that no zeno-timelock can ever occur, it
is suﬃcient to check that any loop allows time to diverge, if visited inﬁnitely
often.
Following this argument, the Strong NonZenoness (SNZ) property is a con-
dition on the guards and resets of a loop, which, if satisﬁed, guarantees that in
every iteration of the loop time passes at least by d time units (d ∈N, d > 0).
Hence, every run that visits a SNZ-loop inﬁnitely often is guaranteed to be
divergent (notice that, by deﬁnition, such an inﬁnite run contains inﬁnitely
many actions). Clearly, if all loops in a given automaton are SNZ, then all in-
ﬁnite runs with inﬁnitely many actions are divergent, and so no zeno-timelock
can occur in the automaton. Moreover, strong nonzenoness is a compositional
property: if every automaton in a network is SNZ (i.e. all its loops are SNZ),
then so is the network itself (and it is thus free from zeno-timelocks). Some
necessary deﬁnitions, and the strong nonzenoness property itself, are presented
below.
Bounded from Below. Given a clock constraint φ ∈CC C, a clock x ∈C
is said to be bounded from below in φ, if φ contains a term x ∼c, or a term
x −y ∼c, where y ∈C, c ∈N, c > 0 and ∼∈{=, >, ≥}.
Bounded from Above. Given a clock constraint φ ∈CC C, a clock x ∈C
is said to be bounded from above in φ, if either:
1. φ contains a term x ∼c, where c ∈N, c > 0 and ∼∈{=, <, ≤};
2. φ contains a term x −y ∼c, where y ∈C, c ∈N, c > 0, ∼∈{=, <, ≤}
and y is bounded from above in φ; or
3. φ contains a term y −x ∼c, where y ∈C, c ∈N, c > 0, ∼∈{=, >, ≥}
and y is bounded from above in φ.
Strong Nonzenoness (SNZ). A loop lp in A ∈TA is called Strongly
NonZeno (or an SNZ-loop) if there exists a clock which is both reset in the
loop, and bounded from below in some guard in the loop. If every loop in A
is SNZ, then A is said to be SNZ.
Figure 12.9 shows an example of a strongly nonzeno loop: the clock x is
bounded from below in a (with guard: x > 1), and is reset in b. It is not
diﬃcult to see that at least 1 time unit must pass between any two consecutive
iterations of the loop. This means that runs which visit the loop inﬁnitely often
accumulate at least a 1 time unit delay in every iteration, and so they diverge.

362
12 Timelocks in Timed Automata
x:=0
1
2
x<=2
x<=2
a  x>1
b  x:=0
Fig. 12.9. A Strongly Nonzeno Loop
Lemma 12.1 (which was proved in [190]) formalises the relationship between
SNZ-loops and nonzenoness, and the compositionality of SNZ. This lemma
suggests a static veriﬁcation method in which a network can be guaranteed
to be nonzeno if every loop is found to be SNZ.
Lemma 12.1. If A ∈TA is strongly nonzeno then A does not contain
zeno-timelocks. Moreover, if A1, . . . , An ∈TA are strongly nonzeno then
|A = |⟨A1, . . . , An⟩is also strongly nonzeno.
It so happens that Lemma 12.1 can be weakened, in the sense that not every
loop in a network must necessarily be SNZ to guarantee that the network itself
is nonzeno. Indeed, every loop in the product automaton results either from
a completed loop in the component automata, or from the synchronisation of
two matching half loops. If every completed loop in the network is SNZ, then
every loop in the product resulting from these is also SNZ: by construction,
guards and resets in completed loops are preserved in the product (see Sec-
tion 11.2.2). Similarly, if at least one of two matching half loops in the network
is SNZ, then every loop in the product resulting from these is also SNZ. Once
again, by construction, if a clock x is bounded from below and reset in a half
loop, then x will also be bounded from below and reset in every loop in the
product that is derived from this half loop. For example, Figure 12.10 shows
the composition between a SNZ loop and a non-SNZ loop, which results in
two SNZ loops in the product automaton. Both loops, ⟨abc⟩and ⟨acb⟩are
SNZ because x is bounded from below in a and reset in b.
We conclude that synchronisation between a SNZ loop and any other loop
(even a non-SNZ loop) must be considered safe. This is in contrast with
Lemma 12.1; in particular, the conditions imposed by this lemma cannot
guarantee that the network of Figure 12.10 is nonzeno. The following method
(and the corresponding Lemma 12.2 below, which is proved in [44]) reﬁnes
the compositional results of Lemma 12.1, so a more comprehensive class of
nonzeno systems can be analysed positively. Nonzenoness can be veriﬁed, then,
as follows.
1. Pair all complementary half loops in the network, i.e. those loops which
may synchronise on some transition;

12.4 Zeno-timelocks
363
1
2
x>1
x:=0
a?
b
a!
c
3
4
b
x:=0
b
x:=0
y<=1
y<=1
c
a
x>1
y<=1
c
y<=1
y<=1
y<=1
SNZ
Non−SNZ
SNZ
x:=0
y:=0
x:=0,
y:=0
<1,3>
<1,4>
<2,3>
<2,4>
||       =>
Fig. 12.10. Composition Preserves Strong Nonzenoness
2. If at least one loop in every resulting pair is SNZ, and every completed
loop in the network is SNZ7, then the network itself is nonzeno.
Lemma 12.2. Let |A = |⟨A1, . . . , An⟩be a network of TAs. Let HL(|A) be
the set of matching half loops, and CL(|A) the set of completed loops in the
network, where
HL(|A) = { (lp, lp′) | ∃i, j (1 ≤i ̸= j ≤n) . lp ∈Loops(Ai) ∧lp′ ∈Loops(Aj)
∧∃a? ∈Act(lp). a! ∈Act(lp′) }
CL(|A) = { lp | ∃i (1 ≤i ≤n) . lp ∈Loops(Ai) ∧∀a ∈Act(lp) , a ∈CAct }
If at least one loop in every pair in HL(|A) is strongly nonzeno and every loop
in CL(|A) is strongly nonzeno, then the product automaton obtained from |A
is strongly nonzeno. Equivalently, |A is nonzeno.
In general, there exist a number of ways in which a loop can be syntactically
guaranteed not to produce a zeno-timelock. We discuss, in what follows, a
number of nonzenoness conditions that work very much in the same way as
strong nonzenoness: if fulﬁlled, they guarantee that in every iteration of the
loop time passes at least by d time units (d ∈N, d > 0) and so, time will
necessarily diverge if the loop is visited inﬁnitely often.
Because these conditions are deﬁned in terms of invariants and not tran-
sitions, they characterise some kinds of safe loops that are not SNZ, and
thus they can be used to complement the analysis of a broader class of TA
speciﬁcations. Before presenting these syntactic conditions, let us deﬁne the
7Non-SNZ completed loops in components are inherited by the product. There-
fore, if this is the case, the network cannot be considered nonzeno.

364
12 Timelocks in Timed Automata
general concept of inherently safe loops, and the related (and straightforward)
Lemma 12.3.
Inherently Safe Loops. We say that a loop is inherently safe if it can be
guaranteed, by syntactic means, not to contain a zeno-timelock.
Lemma 12.3. If every loop in A ∈TA is inherently safe, then A is nonzeno.
A number of nonzenoness conditions (including strong nonzenoness) are pre-
sented below in Lemma 12.4 (proofs can be found in [44]) to characterise loops
that are inherently safe (the deﬁnition of smallest upper bound, which comes
before, is necessary to formulate one of the syntactic conditions enumerated
in the lemma). It is important to realise that this list of syntactic conditions
is, by no means, comprehensive: other interactions between guards, resets and
invariants can possibly be found to guarantee nonzenoness.
Smallest Upper Bound. Let lp be a loop in A ∈TA, and x ∈Clocks(lp)
where at least one invariant in the loop contains a term of the form x ∼c,
where c ∈N, c > 0 and ∼∈{=, <, ≤}. We deﬁne cmin(x, lp) ∈N to be the
smallest upper bound for x occurring in any invariant in lp, i.e. cmin(x, lp) ≤c′,
for any term x ∼c′ occurring in any invariant of the loop (c ∈N, c > 0 and
∼∈{=, <, ≤}).
Lemma 12.4. Let lp be a loop in A ∈TA, where lp satisﬁes at least one of
the following conditions.
1. lp is strongly nonzeno.
2. There exists at least one invariant in lp where no clock is bounded from
above.
3. There exists a clock x ∈Resets(lp) s.t. x is bounded from below in some
invariant in lp.
4. There exists at least one invariant in lp of the form
n
i=1
xi ≤ci,
where, for all 1 ≤i ≤n, either (a) ci > cmin(xi, lp), or (b) xi ∈Resets(lp)
and ci > 0.
Then, lp is inherently safe.
Figure 12.11 helps to understand the last three conditions enumerated in
Lemma 12.4. Figure 12.11(i) shows a loop which satisﬁes condition (2): notice
that location 2 has a true-invariant, and so it does not impose upper bounds
on any clock occurring in the loop. This guarantees the existence of divergent
runs in the loop (which just idle in location 2).
The loop shown in (ii) satisﬁes condition (3): x is reset in transition b and
bounded from below in location 2 (1 < x ≤2). Then, a delay of at least 1
time unit is guaranteed between consecutive iterations of the loop.

12.4 Zeno-timelocks
365
Figures 12.11(iii) to (vi) illustrate condition (4), which involves the small-
est upper bound of the loop. Notice in (iii), that location 1 always allows
time to pass by 1 time unit, because x is reset in b and it is the only clock
occurring in that location. Correspondingly, the loop satisﬁes condition (4)
in the lemma. On the other hand, we cannot guarantee that the loop shown
in (iv) allows time to pass in every iteration: the clock y is not reset in the
loop, it occurs in every invariant and all invariants impose the same smallest
upper bound on y (cmin(y, lp) = 1) (thus, condition (4) is not satisﬁed). In
particular, notice that the state s = [1, v] is a zeno-timelock, where v(y) = 1
and v(x) = v(z) = 0.
The loop in Figure 12.11(v) is also guaranteed to be inherently safe: all
conjuncts in the invariant of location 2 refer to constants that are greater
than the smallest upper bound for every clock. Notice that the diﬀerence
between the upper bounds in locations 1 and 2 conﬁrms that time is allowed
to pass by at least 1 time unit in location 2 (if so, we will end up with a
time-actionlock, but no zeno-timelock can be contained in this loop). Finally,
the loop in (vi) shows a slightly diﬀerent arrangement of upper bounds, but
cannot be guaranteed to be inherently safe. Notice that there does not exist an
invariant where every clock is either greater than its smallest upper bound,
or reset in the loop. In fact, the loop contains a zeno-timelock s = [1, v],
v(x) = v(y) = 1.
b
a
x<=1
1
a
2
x:=0,
y:=0,
z:=0
b
1
a
2
x:=0 y<=1
x<=1,
y<=1
y<=1,
z<=1
x:=0
x<=1,
y<=1
x<=2,
y<=2
x:=0,
y:=0
b
1
2
x:=0,
y:=0
x<=1,
y<=2
x<=2,
y<=1
a
x:=0
1
2
b
a
x<1
b
a
x:=0,
y:=0
x:=0 y<=1
x:=0
1
2
x<=2
a
b
x:=0
1<x<=2
(i)
(ii)
(iii)
(vi)
1
22
b
z:=0
(v)
(iv)
Fig. 12.11. Syntactic Conditions

366
12 Timelocks in Timed Automata
Syntactic Conditions Are Suﬃcient-only. The syntactic conditions enu-
merated in Lemma 12.4 are suﬃcient-only in the following sense: if they are
satisﬁed by every loop in a given A ∈TA, then every such loop is inherently
safe and so Lemma 12.3 guarantees that A is nonzeno. However, nothing about
A can be said if some of its loops are not inherently safe. This is to say, some
nonzeno automata do exist where some (or all) of its loops do not satisfy any
of the conditions enumerated in Lemma 12.4.
For example, the loop ⟨a⟩in Figure 12.12 does not satisfy any of the
four conditions stated in Lemma 12.4, and therefore it cannot be considered
inherently safe. Nonetheless, the automaton is nonzeno! The key point here is
that, even when zeno runs do exist in the automaton (e.g. the run starting in
location 1, which remains there, performing an inﬁnite number of a-transitions
in 1 time unit), there is no state in the system that prevents the existence
of divergent runs. Notice that b is always enabled in location 1, and time is
always allowed to diverge in location 2. This is strongly related to the notion
of escape transitions, which is exploited in Section 12.4.3 to deﬁne a suﬃcient-
and-necessary condition for nonzenoness.
1
2
b
a
x<=1
c
Fig. 12.12. Lemma 12.4 Is Suﬃcient-only
On the Compositionality of Syntactic Conditions. It is interesting to
consider some results regarding the compositionality of the conditions stated
by Lemma 12.4. As we have discussed previously, strong nonzenoness is com-
positional.
Condition (2) is not compositional because new upper bounds can occur
as the result of conjoining invariants during the construction of the product
automaton. For example, both component loops in Figure 12.13(i) satisfy
condition (2), because there exists at least one location in every loop with
a true-invariant (i.e. there exists at least one invariant where no clock is
bounded from above). Consequently, both component loops are inherently
safe. However, composition results in a product automaton with a single loop,
which does not satisfy any of the conditions in Lemma 12.4. In fact, a zeno-
timelock occurs at s = [l, v], where l = ⟨1, 3⟩and v(x) = v(y) = 1.
For the same reason, condition (4) is not compositional either. Once again,
the component loops in Figure 12.13(ii) can be considered inherently safe, as
they satisfy condition (4) in Lemma 12.4. Notice that, in every component

12.4 Zeno-timelocks
367
loop, there exists at least one invariant where all the clocks are bounded from
above by a constant bigger than the corresponding smallest upper bound.
However, composition yields a loop which contains the zeno-timelock s = [l, v],
where l = ⟨1, 3⟩and v(x) = v(y) = 1.
1
2
x<=1
a!
b!
y<=1
a?
b?
3
4
1
2
x<=1
a!
b!
y<=1
a?
b?
3
4
x<=2
y<=2
(i)
(ii)
a
b
x<=1
y<=1
a
b
x<=1,
y<=2
y<=1,
x<=2
||       =>
||       =>
<1,3>
<2,4>
<1,3>
<2,4>
Fig. 12.13. Noncompositional Syntactic Conditions
On the other hand, condition (3) is compositional, although it is not com-
monly found in practice.8 Nevertheless, it remains an interesting alternative
given the fact that, at least in principle, invariants with lower bounds might
occur when modelling real-time constraints (e.g. 1 < x ≤2).
To conclude, we can say that, in general, checking that all components in
a network are inherently safe does not guarantee that the product automaton
is nonzeno. Nevertheless, Lemmas 12.4 and 12.3 are important as they can
be applied to the product automaton itself: if every loop in the product is
inherently safe according to Lemma 12.4, then by Lemma 12.3 the product is
nonzeno.
8For instance, Uppaal does not allow lower bounds in invariant expressions.

368
12 Timelocks in Timed Automata
12.4.3 Nonzenoness: A Suﬃcient-and-Necessary Condition
The syntactic conditions presented in the previous section provide suﬃcient-
only conditions for nonzenoness. One may argue that in most systems the
presence of zeno-timelocks during modelling stages is rare, and for that reason,
a suﬃcient-only check is generally enough to ensure that a system is nonzeno.
However, there is always the possibility of systems that fail to satisfy the
static properties, in which case, nonzenoness cannot be formally proved (or
disproved). Here we show that reachability analysis, based on syntactic infor-
mation obtained from a timed automaton’s structure, can be used to provide
a suﬃcient-and-necessary condition to guarantee nonzenoness.
This suﬃcient-and-necessary condition, however, does not come for free.
Among some other minor syntactic restrictions, this nonzenoness condition
can only be obtained from a single timed automaton where all actions are
completed. This means that we do not have a compositional method to guar-
antee nonzenoness for an arbitrary network of automata: the analysis has to
be performed on the product automaton. Depending on the model at hand,
the resulting product automaton might be too big, even though many location
vectors are actually unreachable. Notice that reachability will be governed by
clock valuations in possible executions, i.e. “semantic” information that is
not available when the product is built. Nevertheless, the construction of the
product automaton is a purely syntactic operation, and so we could expect
the method to scale up reasonably well.
Loops and Local Zeno-timelocks. Intuition suggests that a zeno-timelock
can only occur if a loop is visited inﬁnitely often, and time is not allowed to
pass in any iteration. Although not trivial to prove, this observation can be
strengthened: a zeno-timelock occurs if and only if execution reaches a state
in a loop lp (i.e. a state s = [l, v], l ∈Loc(lp)) where all subsequent inﬁnite
runs are convergent and visit just transitions in lp. We say that this state is
a zeno-timelock local to lp, and the nonzenoness condition we elaborate on in
this section is concerned only with the detection of local zeno-timelocks.
For example, consider the loop ⟨cd⟩in Figure 12.14. This loop can be
reached either through transitions a or b. The reader will notice that this
loop is not inherently safe according to Lemma 12.4: nonzenoness cannot be
determined by any of the proposed syntactic conditions. However, reachability
analysis can help to determine whether a zeno-timelock is produced by this
loop.
For a zeno-timelock to occur in ⟨cd⟩, a state s = [l, v] must be reached
where l ∈{1, 2} and v is a valuation (which we call maximal) which
1. Enables all invariants in the loop,
2. Enables all transitions in the loop,
3. Assigns 0 to all clocks that are reset in the loop, and
4. Satisﬁes at least one upper bound occurring in every invariant in the loop.

12.4 Zeno-timelocks
369
1
2
y=2
x:=0
x=1
y:=0
x<=1,
y<=2
x<=1,
y<=2
w>3
z:=0
a
b
c
d
3
y=2
e
f
Fig. 12.14. Zeno-timelocks: Loops, Maximal Valuations and Escape Transitions
Clearly, if conditions (1) to (3) are fulﬁlled, then there exists at least one
inﬁnite run starting from s, which visits the loop inﬁnitely often. Condition (4)
guarantees that v makes all transitions in the loop urgent, and, therefore, no
further execution will change the value of any clock. Consequently, all inﬁnite
runs that visit just transitions in the loop are guaranteed to be convergent.9
If we observe Figure 12.14 again, it is not diﬃcult to convince ourselves
that a state s = [1, v] could be reached in ⟨cd⟩through a, where v is s.t.
v(x) = v(z) = 0, v(y) = 2 and v(w) > 3 (we can assume the values of z and w
are such that this valuation is possible). This valuation satisﬁes all conditions
(1) to (4). However, notice that in this case, v also enables an inﬁnite run
starting from s that visits a location outside the loop, and diverges: this run
starts at s, takes c, then e and visits the loop ⟨f ⟩inﬁnitely often (passing, say, 1
time unit between consecutive f -steps). Thus, s is not a zeno-timelock, because
not every inﬁnite run starting from s converges. This proves that conditions
(1) to (4) are necessary for a zeno-timelock to occur, but not suﬃcient. We
also need to ensure that the maximal valuation does not enable any transition
leading to a location outside the loop (which we call an escape transition).
Escape transitions witness the existence of runs that visit some transi-
tion outside the loop, providing a counterexample for the occurrence of a
zeno-timelock, which is local to that loop. See Figure 12.14 again. A zeno-
timelock s′ = [1, v′] may occur in ⟨cd⟩, where v′(y) = v′(z) = 0, v′(x) = 1 and
v′(w) > 3. With this valuation (which can be reached through transition b),
transition e is not enabled and therefore all inﬁnite runs starting from s′ visit
just transitions in the loop, and are convergent.
Using Reachability to Guarantee Nonzenoness. It turns out, then, that
a suﬃcient-and-necessary condition for the occurrence of zeno-timelocks in a
given loop can be expressed as a reachability problem. A loop lp contains a
zeno-timelock if and only if a state in lp can be reached where the valuation
is maximal, and it does not enable any transition leading to a location outside
lp. Moreover, we show that such a state can be characterised by a formula con-
9Moreover, because clocks cannot change their values, such a run is unique.

370
12 Timelocks in Timed Automata
structed out of information derived from the syntactic structure of the loop,
provided this structure respects certain restrictions. Now, let us be formal.
Let A ∈TA be a timed automaton where all actions are completed, and
all invariants respect the following syntax (I is an invariant, x is a clock and
c ∈N),
I ::= true | x ≤c | I ∧I
Let lp be a loop in A which is not inherently safe.10 We deﬁne a state formula
φ ≜A.l ∧α(lp) ∧β(lp), where l ∈Loc(lp), s.t.
A state s satisfying φ is reachable in A, if and only if A contains a
zeno-timelock, which is local to lp.
The formula α(lp) characterises the set of maximal valuations of lp, and β(lp)
represents the set of all valuations that simultaneously disable all escape tran-
sitions from lp. Next, we show that these formulae can be deﬁned in terms of
the syntactic structure (guards, invariants and resets) of lp.
α(lp) ≜

l∈Loc(lp)
I(l)
∧

g∈Guards(lp)
g
∧

y∈Resets(lp)
y = 0
∧

conj ∈SUBs(lp)
conj
where (for Loc(lp) = { l1, . . . , ln })
SUBs(lp) ≜{ x1 = c1 ∧. . . ∧xn = cn | xi ≤ci ∈LocSUBs(li, lp), 1 ≤i ≤n }
LocSUBs(l, lp) ≜{ x ≤c | x ≤c occurs in I(l) and c = cmin(x, lp) }
Here, every element of SUBs(lp) is a conjunct representing that at least one
clock in every invariant has reached its smallest upper bound (every element of
LocSUBs(l, lp) is a term of I(l) that refers to a smallest upper bound). Note,
because lp is assumed not to be inherently safe, every invariant in the loop
contains at least one term of the form x ≤cmin(x, lp) (otherwise, condition
4 in Lemma 12.4 would be satisﬁed, and so lp would be inherently safe).
Therefore, the set LocSUBs(l, lp) cannot be empty, and so the conjuncts in
SUBs(lp) are always well-formed.
As we mentioned before, α(lp) denotes the set of all maximal valuations
of a given loop lp. A maximal valuation v of lp must satisfy all invariants and
10We can check this by applying, for example, Lemma 12.4. We know that inher-
ently safe loops do not produce zeno-timelocks.

12.4 Zeno-timelocks
371
guards in lp, and assign 0 to all clocks that are reset in lp. This ensures that,
if a state s = [l, v], l ∈Loc(lp) is reached, then there exists a run ρ starting
from s, which visits lp inﬁnitely often, without changing its clock valuation
(i.e. v). These conditions are expressed in α(lp) by

l∈Loc(lp)
I(l),

g∈Guards(lp)
g,
and

y∈Resets(lp)
y = 0
A maximal valuation must also satisfy at least one smallest upper bound in
every invariant of lp11, which ensures that v not only enables every transition
in lp, but also makes them urgent (when v is reached, every invariant in the
loop has reached an upper bound). This is characterised by

conj ∈SUBs(lp)
conj
Thus, ρ represents an inﬁnite run starting from s, which visits lp inﬁnitely
often (and visits just locations in lp) and does not allow time to progress be-
yond v (i.e. it is a zeno run). An intricate example is shown in Figure 12.15,
which results in the following expression,
α(lp) =
(x ≤1 ∧y ≤2) ∧(z ≤2 ∧y ≤3) ∧
(y ≤2 ∧w ≤1) ∧(t ≤0)
∧(z > 1 ∧y = 2)
∧(t = 0 ∧w = 0)
∧( (x = 1 ∧z = 2 ∧y = 2 ∧t = 0) ∨
(x = 1 ∧z = 2 ∧w = 1 ∧t = 0) ∨
(y = 2 ∧z = 2 ∧y = 2 ∧t = 0) ∨
(y = 2 ∧z = 2 ∧w = 1 ∧t = 0) )
Now, for a state s = [l, v] to be a zeno-timelock local to lp, we need to ensure,
in addition to the conditions expressed by α(lp), that v does not enable any
escape transition from lp. This would guarantee that the run ρ, described
above, is the only inﬁnite run starting from s which visits lp inﬁnitely often
(and, as we saw, convergence of ρ is guaranteed by α(lp)). With this in mind,
we deﬁne a function β(lp) that characterises the set of all valuations that
simultaneously disable all escape transitions from lp. Let us ﬁrst deﬁne an
11Note, if v is a maximal valuation of lp, and x is a clock occurring in any invariant
in lp, then v(x) ≤cmin(x, lp). Otherwise, v would invalidate all invariants in lp that
contain the term x ≤cmin(x, lp) (we know that, because lp is not inherently safe,
there must exist at least one such invariant), which contradicts its maximality.

372
12 Timelocks in Timed Automata
b
1
a
2
x<=1,
y<=2
z>1
w:=0
c
d
4
3
z<=2,
y<=3
y<=2,
w<=1
t<=0
y=2
t:=0
Fig. 12.15. A Complex Loop: Calculating α(lp)
auxiliary function, IsEnabled(g, r, l′) (where x is a clock, g is a guard, r is a
reset set and l′ is a location):
IsEnabled(g, r, l′) ≜g ∧

conj ∈Target(l′,r)
conj
Target(l′, r) ≜{ x ≤c | x ≤c occurs in I(l′) and x /∈r }
The function IsEnabled(g, r, l′) checks whether a given outgoing transition t,
with guard g, reset set r and target location l′, is enabled by the current
valuation. It is not diﬃcult to realise that t (the escape transition) is enabled
by the current valuation, v say, if v satisﬁes (a) the transition’s guard g, (b)
the invariant in the source location and (c) the invariant in the target location,
after the reset (i.e. r(v) must satisfy I(l′)). However, notice the following.
1. The invariant of the source location is not considered in IsEnabled(g, r, l′).
Note that β(lp), and therefore, IsEnabled(g, r, l′), is meant to be checked
in conjunction with α(lp), which represents the maximal valuations in the
loop. Then, by deﬁnition of maximal valuation, the invariant in the source
location (which is a location in the loop) is satisﬁed whenever α(lp) is.
2. Conjuncts in the invariant of the target location, which refer to clocks that
are reset in t, are not considered in IsEnabled(g, r, l′) (note the deﬁnition
of Target(l′, r)). Let us show you why this is the case. Suppose that x ≤c
is one of such conjuncts in the target invariant12, i.e. x is reset in t (x ∈r).
When t is performed, the value of x is set to zero, and so x ≤c is trivially
satisﬁed. Therefore, for any v that holds before t is performed, r(v) satisﬁes
the target invariant (I(l′)) if and only if v satisﬁes all conjuncts in I(l′)
that do not refer to clocks in r (i.e. all conjuncts in Target(l′, r)).
Let Esc(lp) = { l1
a1,g1,r1
−−−−−→l′
1, . . . , ln
an,gn,rn
−−−−−−→l′
n } be the set of escape transi-
tions of lp, i.e. transitions where li ∈Loc(lp) and l′
i /∈Loc(lp), for all 1 ≤i ≤n.
We can now deﬁne β(lp):
β(lp) ≜
n
i=1
¬ IsEnabled(gi, ri, l′
i)
12Remember, as in Uppaal, that we disallow invariants with lower bounds.

12.4 Zeno-timelocks
373
For example, Esc(lp), α(lp) and β(lp), are calculated below for the loop ⟨cd⟩
in Figure 12.14 (redundant terms have been removed):
Esc(⟨cd⟩) = {2
e, y=2, {}
−−−−−−−→3}
α(⟨cd⟩) = (x ≤1 ∧y ≤2) ∧
(w > 3) ∧
(z = 0) ∧
(x = 1 ∨y = 2)
β(⟨cd⟩) = ¬ (y = 2)
Taking φ = A.1 ∧α(⟨cd⟩) ∧β(⟨cd⟩), the reachability algorithm reachable(A, φ)
(Figure 11.8) would conﬁrm that there exists a state that satisﬁes φ, and
therefore that the loop ⟨cd⟩contains a local zeno-timelock.
The following theorem (proved in [44]) formalises a suﬃcient-and-necessary
condition for nonzenoness in a timed automaton.
Theorem 12.5. Let A ∈TA. A contains a zeno-timelock if and only if there
exists a loop in A, lp, such that reachable(A, φ) holds, where φ is deﬁned as
follows, φ ≜A.l ∧α(lp) ∧β(lp), l ∈Loc(lp).
Zeno-timelocks
and
Nonsimple
Loops. Clearly, the application of
Theorem 12.5 requires the detection of all loops in the automaton in question
(most likely, this will be the product automaton for a given network). One
would expect that simple loops are enough to accomplish the task. Unfortu-
nately, some zeno-timelocks can only be considered local to nonsimple loops.
Consider again Figure 12.7: the state s = [1, v], v(x) = 1, is a zeno-timelock
local to the nonsimple loop ⟨acdb⟩. However, s is neither local to the simple
loop ⟨ab⟩(v enables the escape transition c) nor is it local to ⟨cd⟩(v enables
the escape transition b).
In practice, however, detection of all nonsimple loops in the automaton
may not be required. Nonzenoness detection might proceed in a number of
steps, where each step ideally reduces the number of possible loops worth
considering. Arguably, this avoids the detection of nonsimple loops as much
as possible, making the overall process much more practical.13 We conclude
this section, then, with a method to analyse nonzenoness in a given network
(a more detailed algorithm is oﬀered in [44]),
1. Initially, suﬃcient-only conditions can be applied to the components of the
network, possibly identifying a small number of unsafe loops (completed
loops, or pairs of half loops, as discussed in Section 12.4.2). Let L0 be that
set of unsafe loops.
13We note that this method is presented here only for the sake of completeness;
better strategies can be found and are deﬁnitely worth exploring.

374
12 Timelocks in Timed Automata
2. Then, when the product automaton (Π) is constructed, the completed
loops that result just from loops in L0 can be identiﬁed. Let L1 be this
new set of loops in the product, all of which are not inherently safe. Notice
that, so far, we are just dealing with simple loops.
3. Now, we could reduce L1 by removing those loops that do not reach
maximal valuations (this, as we have seen, is a necessary condition for
the occurrence of zeno-timelocks). These loops lp ∈L1 are such that
reachable(Π, φα) does not hold, where φα is deﬁned by the following re-
lationship φα ≜A.l ∧α(lp), l ∈Loc(lp).14 Then, let L2 ⊆L1 be the set
of simple loops that do reach maximal valuations.
4. We can remove, from L2, those loops that can be guaranteed to contain
a local zeno-timelock, i.e. those loops lp ∈L2 for which reachable(Π, φ)
holds, where φ is deﬁned as φ
≜
A.l ∧α(lp) ∧β(lp), l ∈Loc(lp). It
is important to mention that, most likely, the analysis will be concluded
here: once a zeno-timelock is found, the model will be corrected before
nonzenoness is checked again. In the worst case, though, let us assume
that we want to continue the analysis with the rest of the loops, say
L3 ⊆L2.
5. L3 is such that every loop is a simple loop that reaches maximal valuations,
and every such maximal valuation enables one or more escape transitions.
As a ﬁnal step, then, we consider from Π only those nonsimple loops
that could be obtained by combining (where possible) simple loops in
L3. For every such nonsimple loop, the suﬃcient-and-necessary condition
(φ ≜A.l ∧α(lp) ∧β(lp)) is tested again.
12.5 Timelock Detection in Real-time Model-checkers
12.5.1 Uppaal
Currently, Uppaal only supports a limited form of timelock detection. The
formula A[]not deadlock15 can be veriﬁed, which guarantees absence of ac-
tionlocks. This clearly implies time reactiveness. However, if the speciﬁcation
does not verify A[]not deadlock, no facilities are available to detect whether
the cause is just a pure actionlock, or a time-actionlock.
Nonzenoness can be detected in Uppaal by adding a new component to the
network, usually referred to as a test automaton. This automaton looks like
the one shown in Figure 12.16(i), where t is a local clock and a is a completed
action. In networks augmented with such a test automaton, nonzenoness can
14Notice that we do not need to check, at this stage, for escape transitions. Thus,
formula β(lp) is not included in this check.
15This corresponds to a TCTL formula AG¬ (Deadlock), where Deadlock is a state
formula that holds whenever no action transition is enabled in the current state.

12.5 Timelock Detection in Real-time Model-checkers
375
be guaranteed if the Uppaal formula (t==0)-->(t==1)16 is satisﬁable. This
corresponds to the TCTL formula AG((t = 0) ⇒AF(t = 1)), which is satisﬁable
only if for every state s = [l, v] in which v(t) = 0, a state s = [l′, v′] in which
v(t) = 1 is reachable in every possible run starting from s (l and l′ denote
arbitrary location vectors). In other words, this guarantees that the network
is always able to elapse 1 time unit.
1
a
t=1
t:=0
t<=1
(i)
1
a
t=1
t:=0
t<=1
2
b
true
||
(ii)
Fig. 12.16. Test Automaton (i) and a Nonzeno System (ii)
The combined use of a test automaton and a leads-to formula provides
an ingenious solution to guarantee nonzenoness, and is good evidence of the
versatility of Uppaal in respect of veriﬁcation of nontrivial properties. How-
ever, this approach has a few drawbacks. One problem is that veriﬁcation of
a leads-to formula is computationally demanding; algorithms would typically
include some sort of nested reachability veriﬁcation. The other problem is
that the approach is suﬃcient-only: there exist some networks that do not
satisfy (t==0)-->(t==1), yet they are nonzeno. The system shown in Fig-
ure 12.16(ii) illustrates such a case. Notice that the system does not contain
zeno-timelocks, although it contains zeno runs. For example, transition b can
be performed inﬁnitely at v(t) = 0, generating a zeno run that is a counterex-
ample to (t==0)-->(t==1). To convince ourselves that this is so, we only
need to observe that this zeno run is a run starting from a (t = 0)-state in
which no (t = 1)-state is reachable.
It turns out that, considering again a network augmented with a test au-
tomaton such as the one shown in Figure 12.16, a suﬃcient-and-necessary con-
dition for nonzenoness is given by the TCTL formula AG((t = 0) ⇒EF(t = 1)).
Indeed, a system is timelock-free if there exists at least one run starting at
every (t = 0)-state, where a (t = 1)-state is reachable. Notice that this
formula provides a “weaker” condition than the Uppaal leads-to formula
(t==0)-->(t==1), in the sense that just one divergent run is enough to prove
nonzenoness. Unfortunately, such a formula cannot be written in Uppaal.
Despite these drawbacks, Uppaal remains probably the most usable and
eﬃcient real-time model-checker available. This has motivated recent research,
which aims to complement the timelock-detection facilities in Uppaal [44,45].
In particular, this research is concerned with the integration of the syn-
tactic and suﬃcient-and-necessary nonzenoness conditions presented in Sec-
tions 12.4.2 and 12.4.3.
16A leads-to formula [16].

376
12 Timelocks in Timed Automata
12.5.2 Kronos
Kronos handles an expressive TCTL subset, which allows for the veriﬁcation
of the TCTL formula AGEF=1true. This formula characterises models where,
from every reachable state, at least 1 time unit is always allowed to pass.
Unlike Uppaal’s leads-to formula, this one represents itself as a suﬃcient-and-
necessary nonzenoness condition [49]. However, this formula is also diﬃcult
to verify, and Kronos’ engine is not as eﬃcient as Uppaal’s. This means that
for some speciﬁcations, checking nonzenoness in Kronos would be the most
expensive requirement to check and the need to check it could prevent a
complete veriﬁcation.

13
Discrete Timed Automata
13.1 Inﬁnite vs. Finite States
The attractiveness of timed automata as a formal method is the possibil-
ity it raises of eﬃcient and automatic veriﬁcation (real-time model-checking).
However, automatic veriﬁcation comes at a price: systems must exhibit a be-
haviour where “discrete changes” are ﬁnite, e.g. systems that can be modelled
using ﬁnitely many automata locations and variables in ﬁnite domains (e.g.
Uppaal [16]).
Unfortunately, many interesting systems that present inﬁnite behaviour
cannot be represented using timed automata. For example, reasoning about
this sort of behaviour comes about naturally when dealing with parameterised
communication protocols. Formal notations for timed inﬁnite-state systems
(see, e.g. [1,113,134,135,142,178]) have been developed for a number of years
to respond to this issue, providing speciﬁcation and veriﬁcation solutions in
those domains where automatic techniques, such as model-checking, cannot be
applied. The evolution in formal frameworks for timed, inﬁnite state systems is
witnessed by several pieces of work, e.g. [82,84,85,110]. The main disadvantage
of inﬁnite-state frameworks is the lack of fully automatic veriﬁcation support.
Typically, properties will have to be veriﬁed deductively, where proofs are
developed by hand or aided by theorem provers. Therefore, a considerable
degree of user interaction and expertise is usually needed. But on the other
hand, deductive proofs strongly encourage a deep understanding of how the
system works.
Here we discuss Discrete Timed Automata (DTAs) [84,85] as a represen-
tative notation for inﬁnite-state, real-time systems. This notation is a natural
timed extension of inﬁnite state communicating automata, presented in Sec-
tion 8.3, and it embodies many of the principles that are present in other
formalisms, e.g. timed I/O automata with urgency [82]. The main elements of
this theory are enumerated below, and formally introduced in Section 13.3.
1. A DTA is composed of a set of variables and a number of actions.

378
13 Discrete Timed Automata
2. Variables deﬁne the state-space of an automaton (every state correspond-
ing to one possible valuation) and can be local to an automaton, or de-
clared externally and shared with other components in a network of DTAs.
DTAs have been developed so MONA [111], a satisﬁability checker for the
Weak Monadic Second-order Theory of 1 Successor (WS1S), can be used
to support the deductive veriﬁcation of safety properties. One consequence
of this is that variables in DTAs are typed, and types must be supported
by MONA, which oﬀers natural numbers, Boolean values, enumerations
and ﬁnite sets of natural numbers. Other relatively complex data types,
such as ﬁnite arrays on ﬁnite domains, can also be derived from the basic
types [181].
3. Actions are deﬁned in terms of a label, a precondition, a deadline and an
eﬀect. Preconditions, deadlines and eﬀects are deﬁned as MONA (WS1S)
formulae over the automaton’s variables. A precondition deﬁnes the set of
states where the action is enabled; correspondingly, the eﬀect deﬁnes the
states reachable when the action is performed. As in timed automata with
deadlines (Section 12.3.1), a deadline deﬁnes the states where the action
must be performed. Equivalently, time is not allowed to progress in any
state where some action’s deadline holds. Also, deadlines are required to
imply preconditions, hence DTAs are time reactive by construction (i.e.
time-actionlocks cannot occur).
4. Time is discrete, represented by a designated shared variable T ∈N (called
the time variable), and a special action, tick, that increments the value of
T (by 1 time unit). T can be read by any action, but updated only by the
tick action. Time constraints (occurring in preconditions and deadlines)
will refer to T, and be expressible in WS1S. This, and the fact that T
represents a natural number, allows DTA speciﬁcations to be expressed
in MONA.
5. Systems are modelled as networks of synchronising DTAs. A set of shared
variables, which includes the time variable T, is related to the network.
Among other well-formedness conditions, one automaton in the network
(and just one) is required to include the tick action. In general, shared
variables can be read and updated by any component, with the following
exceptions: (a) T is only updated by one component (the one that includes
the tick action) and (b) shared variables cannot be simultaneously updated
by two synchronising half actions.
6. Concurrency is modelled by interleaving; at any point in execution a given
action is nondeterministically chosen from the set of actions enabled at
that point. Communication is achieved through binary CCS-like synchro-
nisation; actions are classiﬁed as completed, input or output actions, and
communication takes place when two matching actions (input/output ac-
tions with the same label in two diﬀerent components in a network) are
executed at the same time. There is no value-passing in communication,
but this can be achieved with shared variables with one restriction: either

13.1 Inﬁnite vs. Finite States
379
the input or output matching action can modify a shared variable, but
not both (to prevent simultaneous, inconsistent updates).
As in timed automata with deadlines, parallel composition preserves time
reactiveness: synchronisation will only be considered urgent if both match-
ing actions are enabled (i.e. if synchronisation is possible).
7. Veriﬁcation of properties in DTAs is deductive: proofs can be developed
by hand or supported by theorem provers. Here we focus, in particular,
on the veriﬁcation of safety properties (i.e. those stating that error-states
are never reachable) by the well-known method of invariance proofs [137].
We show that crucial to these proofs is the satisﬁability checking of cer-
tain MONA formulae, which characterise the successful execution of DTA
actions.
Example: A DTA Speciﬁcation of an Alarm Clock. Figure 13.1 shows
a DTA speciﬁcation of a simple alarm clock. VL denotes the automaton’s local
variables, ΘL denotes the initialisation formula for variables in VL, TL is a
set of action labels, and A the automaton’s actions; true-preconditions, false-
deadlines and eﬀects which do not change the current valuation are omitted.
The network of DTAs is composed of two automata, Clock and Alarm. VS
denotes the set of shared variables related to the network (note, in this example
only T is shared) and ΘS denotes the initialisation formula (which sets T
initially to zero).
The Clock component models a 24-hour clock, where the alarm is set to
5:30. Local variables s, m and h denote, respectively, the seconds, minutes
and hours elapsed so far (assuming the granularity of tick is to the second).
Actions minute and hour calculate the current minute and hour; hour and
reset keep the values of m and h between 0 and 60, and 0 and 24, respectively.
To keep the speciﬁcation simple, s is allowed to drift unbounded. All these
actions are internal to the automaton; on the other hand sound alarm! is
an output action, which synchronises with the input action sound alarm? in
Alarm. Once synchronisation happens, the alarm will ring for 15 seconds and
stop. The following general points are worth observing,
•
All actions, save for tick and sound alarm?, are made urgent as soon as
they are enabled: the set of states denoted by deadlines and preconditions
are the same.
•
Local variables such as s and d, which are referred to as time capture vari-
ables, are kept implicitly synchronised with the global time, by resetting
them to the current value of T.
•
The value of a variable, say v, after an action has been performed, is
denoted by its primed version, v′.

380
13 Discrete Timed Automata
Network: |⟨Clock, Alarm⟩
VS : {T ∈N}
ΘS : T = 0
DTA: Clock
VL : s, m, h ∈N
ΘL : s = 0 ∧m = 0 ∧h = 0
TL : {tick, minute, reset, hour, sound alarm!}
A : tick
eﬀ:
T ′ = T + 1
minute
prec:
T = s + 60 ∧m < 60
deadline: T = s + 60 ∧m < 60
eﬀ:
m′ = m + 1 ∧s′ = T
hour
prec:
m = 60 ∧h < 24
deadline: m = 60 ∧h < 24
eﬀ:
h′ = h + 1 ∧m′ = 0
reset
prec:
h = 24
deadline: h = 24
eﬀ:
h′ = 0
sound alarm!
prec:
h = 5 ∧m = 30
deadline: h = 5 ∧m = 30
DTA: Alarm
VL : d ∈N, on ∈B
ΘL : d = 0 ∧on = false
TL : {sound alarm?, stop}
A : sound alarm?
eﬀ:
on′ = true ∧d′ = T
stop
prec:
on ∧T = d + 15
deadline: on ∧T = d + 15
eﬀ:
on′ = false ∧d′ = 0
Fig. 13.1. A Simple Alarm Clock
13.2 Preliminaries
This section gives the necessary information on fair transition systems, invari-
ance proofs, the logic WS1S and MONA.

13.2 Preliminaries
381
13.2.1 Fair Transition Systems and Invariance Proofs
Fair Transition Systems (FTSs) are a well-known computational model for
(untimed) inﬁnite-state systems [136]. Here we include a brief description of
FTS, as this model can elegantly express the semantics of DTAs1.
An FTS, F = (V, Θ, T ), includes a ﬁnite set of typed variables V (types
are not part of the theory, but assumed, instead, to be application-dependent),
an initial condition Θ and a ﬁnite set of transitions T . V determines the state-
space of the system, each state corresponding to a possible valuation. Θ and
transitions in T are expressed as assertions in a ﬁrst-order language (predicate
logic). Θ is an assertion, which deﬁnes a set of possible starting states (i.e.
initial valuations for V ).
A transition τ ∈T is represented by an assertion ρτ on variables in V
and their primed versions, where V ′ denotes the set of primed variables with
respect to V . If V ′(τ) denotes the set of variables in V that are modiﬁed by
τ, then ρτ (here referred to as a transition formula) is usually written as
ρτ ≜pV ∧

v∈V ′(τ)
v′ = EV
where pV is an assertion which imposes a certain valuation for some variables
in V , representing the set of states where τ is enabled; and

v∈V ′(τ)
v′ = EV
where EV is an expression on V , indicates a new valuation for some variables
in V after τ has been performed (i.e. it deﬁnes the next state). Notice that
terms of the form v′ = EV determine a unique next state. For example, the
assertion ρτ : x > 0 ∧x′ = x+1, characterises a transition τ, which can only
be performed in those states where x > 0, and whose eﬀect is to increment
the value of x by 1. T is also assumed to include the idling transition,
ρidle ≜

v∈V
v′ = v
which does not change the current state. All other transitions in T are referred
to as nonidle.
A computation is an inﬁnite sequence of states s0, s1, s2, . . . such that (a)
s0 satisﬁes Θ, (b) for each i ≥0 there is some enabled transition τ ∈T that
is performed at si and results in si+1, and (c) the sequence contains either
inﬁnitely many nonidle steps (i.e. the result of performing a nonidle transition)
or a terminal state (i.e. a state where the only enabled transition is the idling
transition). Every state in a computation is referred to as a reachable state.
Concurrency is modelled by interleaving: at any given point in a computa-
tion, a transition is executed, being nondeterministically chosen from the set of
1Although, in this work, we are not concerned with fairness in DTAs.

382
13 Discrete Timed Automata
enabled transitions at that point. Fairness conditions are enforced to prevent
computations that do not correspond to executions of real-life systems. This
is achieved by marking transitions in an FTS as just or compassionate. A just
transition cannot be continuously enabled (i.e. enabled in every state of some
computation’s suﬃx), but performed only ﬁnitely many times. A compassion-
ate transition cannot be enabled inﬁnitely often, but performed only ﬁnitely
many times. Compassionate transitions respond to stronger fairness condi-
tions than just transitions. Notice that a transition can be enabled inﬁnitely
often without being continuously enabled; hence, marking this transition as
“just” will not guarantee its eventual execution.
A safety property is an assertion about the system that holds in all reach-
able states (see Section 8.2.5.1). Formally, a safety property can be speciﬁed
as an LTL (Linear Temporal Logic) [137] formula 2φ, where φ is, in general,
an LTL past formula. If 2φ holds then φ holds in every reachable state. In
this chapter, φ just refers to a state assertion (i.e. a formula without LTL
temporal operators), which is usually called an invariant2. Invariants can be
formally veriﬁed over FTS using the rule presented below.
P1
ϕ →φ
P2
Θ →ϕ
P3
∀τ ∈T , ρτ ∧ϕ →ϕ′
2φ
This deductive rule guarantees the invariance of φ, provided the existence of
a (usually stronger) invariant ϕ such that (P1) ϕ implies φ, (P2) ϕ holds in
every starting state and (P3) ϕ is “preserved” by all transitions in T (i.e. if
ϕ holds whenever τ is enabled, then it also holds after τ is performed). The
formula ϕ′ can be obtained by replacing, in ϕ, all variables v by their primed
version v′, where v′ occurs in ρτ.
It is not diﬃcult to see that, if all premises hold, then φ is satisﬁable
in every reachable state. Manna et al. [137] also proved that, if 2φ is valid,
then an assertion ϕ exists which satisﬁes the rule premises. Unfortunately,
methods to obtain such an assertion ϕ (called an inductive invariant) are not
complete. It turns out that, for any assertion ϕ, premises may be found to be
unsatisﬁable for some valuations, even in those cases when ϕ is, indeed, an
invariant. The following discussion explains this issue in more detail.
Without loss of generality, let us assume that ϕ = φ is a good guess to
start our deductive proof. Suppose that a valuation is found that invalidates
either premise P2 or P3, and which, therefore, does not allow us to conclude
the validity of 2φ. Now, if this valuation denotes a reachable state, then φ is
guaranteed not to be an invariant, as there exists a reachable state in which
it does not hold. On the other hand, if the valuation in question denotes an
unreachable state, then φ may or may not be an invariant, but neither case can
be conﬁrmed yet. In addition, the problem becomes more diﬃcult to tackle as
2Not to be confused with invariants in timed automata.

13.2 Preliminaries
383
to determine whether a valuation denotes a reachable or unreachable state is,
in general, far from straightforward. Notice, as well, that this issue is inherent
to the nature of transition formulae: they represent a set of states where the
transition is enabled, but not every state in this set is necessarily reachable.
One way to approach this problem is to assume ϕ = φ initially, and then
to strengthen it (on demand) with auxiliary invariants, which rule out un-
reachable states. It is hoped that this process results in a formula ϕ for which
the deductive rule provides a deﬁnite answer; ϕ will typically have the form:
ϕ ≜φ ∧
n

i=1
αi
where αi, for all 1 ≤i ≤n, is an auxiliary invariant describing some known
relationship between the system variables. Note that ingenuity is needed here
to propose convenient auxiliary invariants, and to prove that these assertions
are, themselves, invariants. In consequence, it is often the case that the ver-
iﬁcation of a safety property requires several applications of the deductive
rule.
Nevertheless, the case is far from hopeless, as many heuristics have been
proposed in the literature to guide the invariant strengthening process (see,
e.g. [19,20]). It is also worth mentioning that other deductive rules have been
devised to prove the invariance of more general LTL past formulae [137],
which can also be applied to verify more complex safety properties in DTA
speciﬁcations.
13.2.2 The Weak Monadic Second-order Theory of 1 Successor
(WS1S) and MONA
This section gives the necessary background on WS1S and MONA (further
details can be investigated in [111]). WS1S [55, 72, 188] is a decidable logic
interpreted over ﬁnite sets of natural numbers, with the following (minimal)
syntax:
φ ::= p = q + 1 | p ∈X | ¬φ | φ ∨φ | ∃p . φ | ∃X . φ
where φ denote a WS1S formula, p, q two ﬁrst-order variables and X a second-
order variable. WS1S is interpreted over N; ﬁrst-order variables range over
natural numbers, second-order variables range over ﬁnite sets of natural num-
bers and operators =,+, ∈, ¬, ∨and ∃have the classic interpretation. Other
operators can be derived from these, e.g. ⇒, ≤, and ⊆, in the usual way.
MONA [111] implements a decision procedure for WS1S based on a trans-
lation from WS1S formulae to DFA (Deterministic Finite Automata) [55,72].
The syntax of MONA is that of WS1S augmented with syntactic sugar, that is,
no expressive power is added. A MONA speciﬁcation consists of a declaration
section and a formula section.

384
13 Discrete Timed Automata
Boolean, ﬁrst-order and second-order variables can be declared (these are
declared by var0, var1 and var2, respectively). Other relatively complex data
types, such as ﬁnite arrays on ﬁnite domains, can also be represented in MONA
[181]. Predicates can also be declared, which instantiate a given formula with
actual parameters.
Formulae are built using the usual logic connectives, such as ∼(negation),
& (conjunction), | (disjunction) and => (implication). Expressions on ﬁrst-
order variables include relational operators (e.g. t1>=t2), addition of constant
values (t+n) and quantiﬁcation (ex1 t:ϕ, all1 t:ϕ). Expressions on second-
order variables include min T, max T (minimum and maximum element in a
set), t in T (membership), T1 sub T2 (set inclusion), quantiﬁcation (ex2
T:ϕ, all2 T:ϕ) and other typical set operations such as intersection, diﬀer-
ence and union.
MONA translates a WS1S formula to a minimum DFA that represents the
set of satisfying interpretations. Models of the formula are then expressed by
paths from the starting state to an accepting state (MONA returns only the
shortest model). Similarly, counterexamples are represented by paths leading
to rejecting states. For example, MONA returns X={0,1,2} and Y={1,2,3}
as a model for the following formula (X={} and Y={} are respectively returned
as a counterexample),
var2 X,Y;
X={0,1,2} & all1 k:k in X => k+1 in Y;
Despite the nonelementary complexity of the decision problem, MONA has
been applied in many nontrivial problems, such as controller synthesis [174],
protocol veriﬁcation [181] and theorem proving [158], [10] (more applications
can be found in [111]). MONA’s successful applications can be explained by
optimisations performed during the translation process as well as by the fact
that the decision procedure is nonelementary in the worst case, which may
not arise so frequently in practice.
13.3 Discrete Timed Automata – Formal deﬁnitions
13.3.1 Syntax
Discrete Timed Automata. DTAs always stand as components of a given
network. A single DTA can be deﬁned as a tuple,
A = (VL, ΘL, TL, A, VS, ΘS)
where
•
VL is a ﬁnite set of local, MONA-typed variables (these include Boolean
values, natural numbers and ﬁnite sets of natural numbers);

13.3 Discrete Timed Automata – Formal deﬁnitions
385
•
ΘL is a MONA formula representing the initial valuation for variables in
VL;
•
TL ⊆Act is a ﬁnite set of action labels;
•
A is a ﬁnite set of actions; and
•
VS, which includes the time variable T, is a set of shared variables with
initial valuations given by ΘS. Both VS and ΘS are declared (globally) in
the network where A sits. In what follows, we use V = VL ∪VS to denote
the set of variables accessible by the automaton.
Actions in A are tuples (a, p, d, e), where a ∈TL is the action’s label, p, d
are MONA formulae on V , respectively denoting the action’s precondition
and deadline; and e is a MONA formula on variables in V and their primed
versions, which denotes the action’s eﬀect. As in inﬁnite state communicating
automata (Section 8.3.1.1), eﬀect formulae are of the form
e ≜

v∈V ′(e)
v′ = EV
where V ′(e) ⊆V is the set of variables modiﬁed by e, and EV is a MONA
expression on V . As in timed automata with deadlines (Section 12.3.1), time
reactiveness in DTAs is guaranteed by restricting deadlines to imply precon-
ditions3,
∀(a, p, d, e) ∈A , d ⇒p
The set of actions A is further partitioned into sets of completed, input and
output actions; that is,
A = COMP(A) ∪IN (A) ∪OUT(A)
Internal, input and output actions are labelled with a ∈CAct, x? ∈HAct
and x! ∈HAct, respectively. Note that many actions in the same partition
(completed, input or output) may share the same label; in this way we nat-
urally model actions that have diﬀerent eﬀects depending on the state. The
time action is a completed action,
(tick, true, false, T ′ = T + 1) ∈COMP(A)
Notice that the time action is always enabled (the precondition is true), and
never urgent (the deadline is false).
Network of DTAs. A network of DTAs, |A = (|⟨A1, . . . , An⟩, VS, ΘS), is a
tuple, where Ai = (V i
L, Θi
L, TLi, Ai, VS, ΘS), for 1 ≤i ≤n, and the following
well-formedness conditions4 apply.
3Left-closed intervals are naturally obtained in DTAs due to discrete time.
4Notice that the ﬁrst two conditions are inherited from those imposed on net-
works of ISCAs (see Section 8.3.1).

386
13 Discrete Timed Automata
1. The time variable, T ∈N, is included in VS, and initialised (T = 0) by
ΘS.
2. Local variables are disjoint among the components,
∀i, j (1 ≤i ̸= j ≤n) , V i
L ∩V j
L = ∅
3. The set of completed actions in any component is disjoint from the set of
actions (completed, output and input actions) in any other component in
the network,
∀i, j (1 ≤i ̸= j ≤n) , COMP(Ai) ∩Aj = ∅
4. One (and only one) automaton in the network must include the time
action tick, and T can only be updated by tick. Formally,
∃i (1 ≤i ≤n) . tick ∈TLi ∧∀j (1 ≤i ̸= j ≤n) , tick /∈TLj
∀i (1 ≤i ≤n), ( (a, p, d, e) ∈Ai =⇒(T ∈V ′(e) ⇐⇒a = tick) )
5. The set of shared variables modiﬁed by input actions is disjoint from the
set of shared variables modiﬁed by matching output actions. Let V ′
S(e) =
VS ∩V ′(e) be the set of shared variables modiﬁed by a given eﬀect formula
e. Then,
∀i, j (1 ≤i ̸= j ≤n) ,
∀(x?, pi, di, ei) ∈IN (Ai), (x!, pj, dj, ej) ∈OUT(Aj) ,
V ′
S(ei) ∩V ′
S(ej) = ∅
13.3.2 Example: A DTA Speciﬁcation for the Multimedia Stream
Figure 13.2 shows a DTA speciﬁcation for the multimedia stream example of
Section 11.2.1.1, and is worth comparing with the TA speciﬁcation given in
Figure 11.2. The network of DTAs is composed of the following automata:
Source, Place1, Place2 and Sink, representing the components of the stream,
and Clock, representing the passage of time (it declares both the time variable
T and the time action tick).
The Source declares a variable SourceState ∈{0, 1} to represent the cur-
rent control state of the automaton, and a time capture variable t1 to keep
track of the time elapsed between two consecutive transmissions. Control
states will denote that the automaton is ready to transmit the ﬁrst packet
(when SourceState = 0), or that it is ready to transmit the next packet in
the sequence (when SourceState = 1). Transmissions are represented by two
sourceOut!s: one for the ﬁrst packet, and the other one for any subsequent
packet. Deadlines ensure that the ﬁrst packet is transmitted urgently when

13.3 Discrete Timed Automata – Formal deﬁnitions
387
T = 0, and that every subsequent packet is transmitted 50 ms after the pre-
vious one. This is achieved by setting the value of t1 to the current time
immediately after a packet is sent (t1′ = T), and sending the next packet only
when the diﬀerence between t1 and the current time is 50 ms (as expressed
by the deadline T = t1 + 50).
Similarly, it is not diﬃcult to analyse the behaviour of the other compo-
nents in the network. For example, the action sinkIn! in Place1 is enabled
as soon as at least 80 ms have passed since a packet was received (i.e. since
sourceOut? was performed), and must be performed before 90 ms have passed
since then (notice that the deadline in sinkIn! does not allow time to pass
beyond T = t4 + 90).
13.3.3 Semantics
Let A = (VL, ΘL, TL, A, VS, ΘS) be a DTA where all actions are completed
(i.e. A = COMP(A)). Notation is as deﬁned for inﬁnite state communicating
automata (Section 8.3); the main diﬀerence being that |= here denotes satis-
ﬁability with respect to WS1S semantics. The semantics of A are given by an
LTS (S, TL, TS, s0), where
•
S denotes the set of all type-consistent valuations for variables in VL ∪VS;
•
s0 ∈S is the starting state, which satisﬁes s0 |= ΘL ∧ΘS;
•
TS ⊆S×TL×S is the transition relation, where transitions (s1, a, s2) ∈TS
are denoted, as usual, s1
a
−→s2. TS is deﬁned by the following inference
rules,
(D1) a ̸= tick s1 |= p (s1, s2) |= e
s1
a
−→s2
(D2) a = tick s1 |= p (s1, s2) |= e ∄(a1, p1, d1, e1) ∈A . s1 |= d1
s1
tick
−−−→s2
where (a, p, d, e) ∈A. Notice that rule (D2) only allows time to pass in
states where no deadline is enabled (i.e. where no action is urgent). Time-
actionlocks cannot occur because deadlines imply preconditions, and so,
only enabled actions can be considered urgent (hence, s1 |= d1 ⇒s1 |= p1
is implicit in the rule’s premises). The set of reachable states is, then,
Sreach = {s0} ∪{s2 | ∃a ∈TL, s1 ∈Sreach. s1
a
−→s2}
Parallel Composition. Parallel composition for DTAs is inspired by sparse
TADs (Section 12.3.1), and also preserves time reactiveness (i.e. timelocks
cannot occur in DTA speciﬁcations). For any given network DTAs, the result-
ing product automaton is a single DTA whose semantics (according to the
LTS deﬁned in the previous section) correspond to that of the network. By

388
13 Discrete Timed Automata
Network: |⟨Clock,Source,Place1,Place2,Sink⟩
VS : {T ∈N}
ΘS : T = 0
DTA: Clock
VL : ∅
ΘL : true
TL : {tick}
A : tick
eﬀ:
T ′ = T + 1
DTA: Source
VL : SourceState ∈{0, 1}, t1 ∈N
ΘL : SourceState = 0 ∧t1 = 0
TL : {sourceOut!}
A : sourceOut!
prec:
SourceState = 0 ∧T = 0
deadline: SourceState = 0 ∧T = 0
eﬀ:
SourceState′ = 1
sourceOut!
prec:
SourceState = 1 ∧T = t1 + 50
deadline: SourceState = 1 ∧T = t1 + 50
eﬀ:
t1′ = T
DTA: Place1
VL : Place1State ∈{1, 2}, t4 ∈N
ΘL : Place1State = 1 ∧t4 = 0
TL : {sourceOut?, sinkIn!}
A : sourceOut?
prec:
Place1State = 1
eﬀ:
Place1State′ = 2 ∧t4′ = T
sinkIn!
prec:
Place1State = 2 ∧T > t4 + 80
deadline: Place1State = 2 ∧T ≥t4 + 90
eﬀ:
Place1State′ = 1
DTA: Sink
VL : SinkState ∈{1, 2}, t2 ∈N
ΘL : SinkState = 1 ∧t2 = 0
TL : {sinkIn?, play}
A : sinkIn?
prec:
SinkState = 1
eﬀ:
SinkState′ = 2 ∧t2′ = T
play
prec:
SinkState = 2 ∧T = t2 + 5
deadline: SinkState = 2 ∧T = t2 + 5
eﬀ:
SinkState′ = 1
Fig. 13.2. Multimedia Stream as a Network of DTAs. Only one place is shown; the
other is similar.

13.4 Verifying Safety Properties over DTAs
389
construction (and well-formedness of the network), this product automaton
contains just completed actions, and declares both the time variable and the
time action.
Let |A = (|⟨A1, ... , An⟩, VS, ΘS) be a network of DTAs, where
Ai ≜(V i
L, Θi
L, TLi, Ai, VS, ΘS)
for 1 ≤i ≤n. The resulting product automaton is a DTA,
Π ≜(VL, ΘL, TL, A, VS, ΘS)
where
•
VL ≜
n
i=1
V i
L
•
ΘL ≜
n
i=1
Θi
L
•
TL ≜
n
i=1
TLi
•
COMP(A) ≜
n
i=1
COMP(Ai) ∪
{(x, p, d, e) | ∃i, j (1 ≤i ̸= j ≤n) .
(x?, pi, di, ei) ∈IN (Ai) ∧
(x!, pj, dj, ej) ∈OUT(Aj) ∧
(p = pi ∧pj) ∧
(d = pi ∧pj ∧(di ∨dj)) ∧
(e = ei ∧ej) }
•
IN (A) ≜OUT(A) ≜∅
Notice that all actions in the product automaton are completed, where syn-
chronisation has been resolved by producing one completed action from every
two matching input/output actions in the components. By way of example,
Figure 13.3 below shows the product automaton corresponding to the network
of DTAs of Figure 13.2. In particular, observe that the product includes four
completed actions sourceOut, each one representing a possible synchronisation
between a sourceOut! in Source and a sourceOut? in either Place1 or Place2
(see Figure 13.2 again).
13.4 Verifying Safety Properties over DTAs
Invariance proofs can be applied on networks of DTAs to verify safety prop-
erties, by mapping5 the network’s product automaton to an equivalent FTS
5The soundness of this mapping is proved in [85].

390
13 Discrete Timed Automata
Network: |⟨Π⟩
VS : {T ∈N}
ΘS : T = 0
DTA: Π
VL : t1, t2, t3, t4 ∈N
SourceState ∈{0, 1},
Place1State, Place2State, SinkState ∈{1, 2}
ΘL : t1 = 0 ∧t2 = 0 ∧t3 = 0 ∧t4 = 0 ∧
SourceState = 0 ∧
Place1State = 1 ∧Place2State = 1 ∧SinkState = 1
TL = {sourceOut, sinkIn, play}
A : tick
eﬀ:
T ′ = T + 1
sourceOut
prec:
SourceState = 0 ∧T = 0 ∧Place1State = 1
deadline: SourceState = 0 ∧T = 0 ∧Place1State = 1
eﬀ:
SourceState′ = 1 ∧t4′ = T ∧Place1State′ = 2
sourceOut
prec:
SourceState = 0 ∧T = 0 ∧Place2State = 1
deadline: SourceState = 0 ∧T = 0 ∧Place2State = 1
eﬀ:
SourceState′ = 1 ∧t3′ = T ∧Place2State′ = 2
sourceOut
prec:
SourceState = 1 ∧T = t1 + 50 ∧Place1State = 1
deadline: SourceState = 1 ∧T = t1 + 50 ∧Place1State = 1
eﬀ:
t1′ = T ∧t4′ = T ∧Place1State′ = 2
sourceOut
prec:
SourceState = 1 ∧T = t1 + 50 ∧Place2State = 1
deadline: SourceState = 1 ∧T = t1 + 50 ∧Place2State = 1
eﬀ:
t1′ = T ∧t3′ = T ∧Place2State′ = 2
sinkIn
prec:
Place1State = 2 ∧T > t4 + 80 ∧SinkState = 1
deadline: Place1State = 2 ∧T ≥t4 + 90 ∧SinkState = 1
eﬀ:
Place1State′ = 1 ∧t2′ = T ∧SinkState′ = 2
sinkIn
prec:
Place2State = 2 ∧T > t3 + 80 ∧SinkState = 1
deadline: Place2State = 2 ∧T ≥t3 + 90 ∧SinkState = 1
eﬀ:
Place2State′ = 1 ∧t2′ = T ∧SinkState′ = 2
play
prec:
SinkState = 2 ∧T = t2 + 5
deadline: SinkState = 2 ∧T = t2 + 5
eﬀ:
SinkState′ = 1
Fig. 13.3. DTA Product Automaton for the Multimedia Stream

13.4 Verifying Safety Properties over DTAs
391
(Section 13.2.1). In particular, deadlines in the product automaton can be ex-
pressed as (semantically equivalent) preconditions for the tick action; because
the product automaton does not contain half actions, time progress conditions
can be independently obtained from every deadline.
Let |A = (|⟨A1, . . . , An⟩, VS, ΘS) be a network of DTAs, and
Π ≜(VL, ΘL, TL, A, VS, ΘS)
the corresponding product automaton. Let ρtick be deﬁned as follows,
ρtick ≜(T ′ = T + 1) ∧

(a,p,d,e)∈A
¬ d
Then, Π is semantically equivalent to the FTS FΠ = (V, Θ, T ), where
V
≜VL ∪VS
Θ ≜ΘL ∧ΘS
T ≜{ ρtick } ∪{ ρτ ≜p ∧e | τ = (a, p, d, e) ∈A, a ̸= tick }
Consider again the multimedia stream example, and the product automaton
Π depicted by Figure 13.3. Figure 13.4 shows the equivalent FTS FΠ (super-
scripts have been used to distinguish the transition formulae that correspond
to actions with the same label).
Given FΠ, then, invariance proofs can be used to conﬁrm that synchroni-
sation between Source and either Place1 or Place2 is always possible, i.e. that
packets can be put in the Channel whenever the Source is ready to send them.
This safety property6 can be expressed by the LTL formula 2φ, where
φ ≜¬((T = 0 ∨T = t1 + 50) ∧Place1State = 2 ∧Place2State = 2)
As discussed in Section 13.2.1, the veriﬁcation of 2φ is achieved by applying
the deductive rule,
P1
ϕ →φ
P2
Θ →ϕ
P3
∀τ ∈T , ρτ ∧ϕ →ϕ′
2φ
In particular, Figure 13.5 oﬀers a list of assertions, which can be used as
auxiliary invariants in the veriﬁcation of 2φ. The predicate mult50(n) can be
expressed in WS1S and holds whenever n is a multiple of 50.
6Section 11.3.2 discusses the veriﬁcation of an equivalent (branching-time) reach-
ability property, for a TA speciﬁcation of the multimedia stream.

392
13 Discrete Timed Automata
V : {T, t1, t2, t3, t4 ∈N
SourceState ∈{0, 1}, Place1State, Place2State, SinkState ∈{1, 2}
}
Θ : T = 0 ∧t1 = 0 ∧t2 = 0 ∧t3 = 0 ∧t4 = 0 ∧
SourceState = 0 ∧Place1State = 1 ∧Place2State = 1 ∧SinkState = 1
T : { ρtick :
¬(SourceState = 0 ∧T = 0 ∧Place1State = 1) ∧
¬(SourceState = 0 ∧T = 0 ∧Place2State = 1) ∧
¬(SourceState = 1 ∧T = t1 + 50 ∧Place1State = 1) ∧
¬(SourceState = 1 ∧T = t1 + 50 ∧Place2State = 1) ∧
¬(Place1State = 2 ∧T ≥t4 + 90 ∧SinkState = 1) ∧
¬(Place2State = 2 ∧T ≥t3 + 90 ∧SinkState = 1) ∧
¬(SinkState = 2 ∧T = t2 + 5) ∧
T ′ = T + 1
ρ1
sourceOut : SourceState = 0 ∧T = 0 ∧Place1State = 1 ∧
SourceState′ = 1 ∧t4′ = T ∧Place1State′ = 2
ρ2
sourceOut : SourceState = 0 ∧T = 0 ∧Place2State = 1 ∧
SourceState′ = 1 ∧t3′ = T ∧Place2State′ = 2
ρ3
sourceOut : SourceState = 1 ∧T = t1 + 50 ∧Place1State = 1 ∧
t1′ = T ∧t4′ = T ∧Place1State′ = 2
ρ4
sourceOut : SourceState = 1 ∧T = t1 + 50 ∧Place2State = 1 ∧
t1′ = T ∧t3′ = T ∧Place2State′ = 2
ρ1
sinkIn :
Place1State = 2 ∧T > t4 + 80 ∧SinkState = 1 ∧
Place1State′ = 1 ∧t2′ = T ∧SinkState′ = 2
ρ2
sinkIn :
Place2State = 2 ∧T > t3 + 80 ∧SinkState = 1 ∧
Place2State′ = 1 ∧t2′ = T ∧SinkState′ = 2
ρplay :
SinkState = 2 ∧T = t2 + 5 ∧
SinkState′ = 1 }
Fig. 13.4. FTS FΠ for the Multimedia Stream
Notice that all formulae occurring in the deductive rule, that is ϕ, ϕ′, φ, Θ,
the transition formulae ρτ, and the premises themselves would be instantiated
with WS1S formulae and, as such, they are expressible in MONA. Therefore,
MONA can be used to check whether a particular premise is valid. In the
case where the premise is not valid, MONA will return a given valuation (i.e.
a state) as a counterexample, and user interaction will be needed to assess
whether such a valuation is reachable in the system. As we have mentioned in
Section 13.2.1, if we are in the presence of a reachable state then 2φ can be
immediately guaranteed not to hold. If, on the other hand, the MONA coun-

13.4 Verifying Safety Properties over DTAs
393
(1) Place1State = 2 ∧Place2State = 2 ⇒(t3 ≥t4 + 50 ∨t4 ≥t3 + 50)
(2) t1 ≥t3 ∧t1 ≥t4
(3) SourceState = 0 ⇒T = 0 ∧Place1State = 1 ∧Place2State = 1
(4) (T > t4 + 90 ⇒Place1State = 1) ∧(T > t3 + 90 ⇒Place2State = 1)
(5) T ≥t1 ∧T ≥t2 ∧T ≥t3 ∧T ≥t4
(6) mult50(t1) ∧mult50(t3) ∧mult50(t4)
(7) t2 = T ∧T > 0 ⇒((Place1State = 1 ∧T ≤t4 + 90 ∧T > t4 + 80)∨
(Place2State = 1 ∧T ≤t3 + 90 ∧T > t3 + 80))
(8) SinkState = 2 ⇒T ≤t2 + 5
(9) T ≤t1 + 50
Fig. 13.5. Example Auxiliary Invariants
terexample denotes an unreachable state, then veriﬁcation might proceed by
strengthening ϕ with other auxiliary invariants, and checking all rule premises
again. Figure 13.6 shows, as an example, the MONA speciﬁcation that checks
whether the invariant φ is preserved by the time action, i.e. to check the
validity of the WS1S formula (part of rule premise P3),
ρtick ∧φ ⇒φ′
% Variables
var1 T,T’,t1,t3,t4,t2,
SourceState where SourceState in {0,1},
Place1State where Place1State in {1,2},
Place2State where Place2State in {1,2},
SinkState where SinkState in {1,2};
% ρtick
∧φ ⇒φ′ as a MONA formula
% for φ ≜¬((T = 0 ∨T = t1 + 50) ∧Place1State = 2 ∧Place1State = 2)
∼(SourceState=0 & T=0 & Place1State=1) &
∼(SourceState=0 & T=0 & Place2State=1) &
∼(SourceState=1 & T=t1+50 & Place1State=2) &
∼(SourceState=1 & T=t1+50 & Place1State=1) &
∼(Place1State=2 & T>=t4+90 & SinkState=1) &
∼(Place2State=2 & T>=t3+90 & SinkState=1) &
∼(SinkState=2 & T=t2+5) &
T’ = T+1 &
(∼((T=0 | T=t1+50) & Place1State=2 & Place2State=2))
=>
(∼((T’=0 | T’=t1+50) & Place1State=2 & Place2State=2));
Fig. 13.6. MONA Speciﬁcation to Verify ρtick ∧φ ⇒φ′

394
13 Discrete Timed Automata
Other quality of service properties can also be veriﬁed for the multimedia
stream, such as throughput (i.e. the number of packets delivered to the Sink
in a given period of time), and latency (i.e. the end-to-end delay between the
time a packet is sent by the Source, and the time it is played by the Sink).
As shown in [85], a few modiﬁcations to the original DTA speciﬁcation allow
these properties to be expressed as invariants, and be veriﬁed by MONA.
13.5 Discussion: Comparing DTAs and TIOAs with
Urgency
A detailed comparison between DTAs and other similar notations (e.g. clock
transition systems [135]) escapes the format of this book (the reader is re-
ferred, instead, to [85]). Nevertheless, this section highlights some diﬀerences
and common points between DTAs and timed I/O automata with urgency
(TIOAUs, for short) [82].
Both notations, DTAs and TIOAUs, are inﬂuenced (among other frame-
works) by timed I/O automata [110] and TAD (Section 12.3.1). As a result
of this, a number of similarities can be observed. In both notations, DTA and
TIOAU, automata are composed of variables, which deﬁne the state-space,
and actions, which model instantaneous state changes (i.e. discrete events).
Actions are characterised by a label, a precondition, an eﬀect and a deadline.
The set of actions is partitioned into internal (or completed) and external
(input or output) actions. Automata can be composed to describe complex
systems, and interaction among components is realised via message passing
(matching external actions). Also, DTA and TIOAU speciﬁcations are time-
reactive (although, zeno-timelocks can occur in both models). But here the
similarities end, and the models diﬀer in a number of ways.
Synchronisation and Parallel Composition. DTAs adopt CCS-like bi-
nary synchronisation, and only allows one level of parallel components. Eﬀec-
tively, a network of DTAs results in a product automaton where synchronisa-
tion is resolved, and all actions are completed. Thus, the product automaton
cannot participate in further synchronisations, and so parallel composition
cannot be applied incrementally. Notice that this is consistent with the com-
municating automata models described in this book: ﬁnite- and inﬁnite-state
communicating automata (chapter 8), and timed automata (chapter 11).
On the other hand, TIOAUs are closer to process calculi such as CSP or
LOTOS. TIOAUs adopt multiway synchronisation, and parallel composition
can be incrementally applied to build larger systems (as discussed in Sec-
tion 2.3.6.4, this suits a constraint-oriented style of speciﬁcation). In TIOAU,
parallel composition can be thought of as yielding a new automaton, where
synchronisation between matching output and input actions results in a new
output action (and not a completed action, as in DTAs). Also, and unlike
DTAs, TIOAUs are input enabled; i.e. input actions are enabled in any state.

13.5 Discussion: Comparing DTAs and TIOAs with Urgency
395
This is consistent with the intention of TIOAUs to model open systems, in
which input actions are assumed to be under the control of the environment
(hence, it can be argued that input actions should not be constrained by the
system). These diﬀerent approaches to speciﬁcation have been discussed in
Section 8.2.6.2, in the context of communicating automata and process cal-
culi. In general, the same conclusions apply here, and thus we can argue that
the expressiveness of TIOAUs facilitates the speciﬁcation of complex systems,
whereas the veriﬁcation of DTA speciﬁcations is easier to automatise.
Time. Discrete time in DTAs is represented by a time-passage action, whereas
in TIOAUs continuous time is represented by trajectories (which describes
how variables, i.e. the state, change over time). It is argued [110], that trajec-
tories are more convenient than time-passage actions, as they lead to simpler
mathematical proofs. On the other hand, a time-passage action, such as the
tick action in DTAs, seems to be a more natural choice if invariance proofs
are to be applied (because both discrete events and the passage of time are
represented by the same kind of actions, mapping DTAs to FTSs is straight-
forward).
Expressiveness of the Speciﬁcation Language. Representing complex
speciﬁcations with TIOAUs can be considerably easier than doing so with
DTAs. For example, TIOAUs support continuous time domains, parame-
terised actions, more general data types and a powerful assertion language
(for writing preconditions and eﬀects). On the other hand, the expressiveness
of DTAs is limited to allow MONA to be used as a veriﬁcation tool, whereas
proofs for TIOAUs speciﬁcations are usually developed by hand.

References
1. M. Abadi and L. Lamport. An old-fashioned recipe for real time. ACM Trans-
actions on Programming Languages and Systems, 16(5):1543–1571, September
1994.
2. S. Abramsky. Observation equivalence as a testing equivalence. Theoretical
Computer Science, 53:225–241, 1987.
3. L. Aceto, P. Bouyer, A. Burgue˜no, and K. Larsen. The power of reachability
testing for timed automata. Theoretical Computer Science, 1-3(300):411–475,
2003.
4. L. Aceto and D. Murphy. On the ill-timed but well-caused. In CONCUR’93:
Concurrency Theory, Lecture Notes in Computer Science, N0. 715. Springer-
Verlag, 1993.
5. A. Aho and J. Ullman. Foundations of Computer Science. Computer Science
Press, 1992.
6. R. Alur, C. Courcoubetis, and D. Dill.
Model-checking in dense real-time.
Information and Computation, 104(1):2–34, May 1993.
7. R. Alur and D. Dill.
A theory of timed automata.
Theoretical Computer
Science, 126:183–235, 1994.
8. J.C.M. Baeten, J.A. Bergstra, and J.W. Klop. On the consistency of Koomen’s
fair abstraction rule. Theoretical Computer Science, 51:129–176, 1987.
9. F. Balarin. Approximate reachability analysis of timed automata. In IEEE
Real-Time Systems Symposium, pages 52–61, 1996.
10. D. Basin and S. Friedrich. Combining WS1S and HOL. In D.M. Gabbay and
M. de Rijke, editors, Frontiers of Combining Systems 2, volume 7 of Studies in
Logic and Computation, pages 39–56. Research Studies Press/Wiley, Baldock,
Herts, UK, February 2000.
11. G. Behrmann, P. Bouyer, K.G. Larsen, and R. Pelanek.
Lower and upper
bounds in zone based abstractions of timed automata.
In Proceedings of
TACAS’04, LNCS 2988, pages 312–326. Springer, 2004.
12. J. Bengtsson. Eﬃcient symbolic state exploration of timed systems: Theory
and implementation. Technical Report 2001-009, Department of Information
Technology, Uppsala University, 2001.
13. J. Bengtsson and W. Yi. Timed automata: Semantics, algorithms and tools.
In W. Reisig and G. Rozenberg, editors, Lecture Notes on Concurrency and
Petri Nets, LNCS 3098. Springer, 2004.

398
References
14. B. Berard, M. Bidoit, A. Finkel, F. Laroussinie, A. Petit, L. Petrucci, and
P. Schnoebelen. Systems and Software Veriﬁcation. Springer, 2001.
15. J.A. Bergstra and J.W. Klop. Algebra for communicating processes with ab-
straction. Journal of Theoretical Computer Science, 37:77–121, 1985.
16. G. Berhmann, A. David, and K. Larsen. A tutorial on uppaal. In M. Bernardo
and F. Corradini, editors, Formal Methods for the Design of Real-Time Sys-
tems. International School on Formal Methods for the design of Computer,
Communication and Software Systems, SFM-RT 2004. Revised Lectures, LNCS
3185, pages 200–236. Springer, 2004.
17. C. Bernardeschi, J. Dustzadeh, A. Fantechi, E. Najm, A. Nimour, and F. Olsen.
Transformations and consistent semantics for ODP viewpoints. In H. Bowman
and J. Derrick, editors, FMOODS’97, 2nd IFIP Conference on Formal Methods
for Open Object Based Distributed Systems. Chapman & Hall, July 1997.
18. M. Bernardo and R. Gorrieri.
A tutorial on empa: A theory of concurrent
processes with nondeterminism, priorities, probabilities and time. Theoretical
Computer Science, 202:1–54, 1998.
19. N.S. Bjørner. Integrating Decision Procedures for Temporal Veriﬁcation. PhD
thesis, Computer Science Department, Stanford University, November 1998.
20. N.S. Bjørner, A. Browne, and Z. Manna.
Automatic generation of invari-
ants and intermediate assertions. Theoretical Computer Science, 173(1):49–87,
February 1997.
21. G. S. Blair, L. Blair, H. Bowman, and A. Chetwynd. Formal Speciﬁcation of
Distributed Multimedia Systems. UCL Press, 1998.
22. E. Boiten, H. Bowman, J. Derrick, and M. Steen. Viewpoint consistency in Z
and LOTOS: A case study. In J. Fitzgerald, C.B. Jones, and P. Lucas, edi-
tors, FME’97: Industrial Applications and Strengthened Foundations of Formal
Methods, LNCS 1313, pages 644–664. Springer-Verlag, September 1997.
23. E. Boiten, J. Derrick, H. Bowman, and M. Steen.
Consistency and reﬁne-
ment for partial speciﬁcation in Z. In M.-C. Gaudel and J. Woodcock, editors,
FME’96: Industrial Beneﬁt of Formal Methods, Third International Sympo-
sium of Formal Methods Europe, LNCS 1051, pages 287–306. Springer-Verlag,
March 1996.
24. T. Bolognesi and E. Brinksma. Introduction to the ISO speciﬁcation language
LOTOS. Computer Networks and ISDN Systems, 14(1):25–29, 1988.
25. T. Bolognesi and F. Lucidi. LOTOS-like process algebras with urgent or timed
interactions. In FORTE’91. North-Holland, 1991.
26. T. Bolognesi, F. Lucidi, and S. Trigila. Converging towards a timed LOTOS
standard. Computer Standards & Interfaces, 16:87–118, 1994.
27. G. Booch. Object-oriented Analysis and Design. Benjamin/Cummings, 1994.
28. M. Boreale, P. Inverardi, and M. Nesi. Complete sets of axioms for ﬁnite basic
LOTOS behavioural equivalences. Information Processing Letters, 43:155–160,
1992.
29. S. Bornot and J. Sifakis. On the composition of hybrid systems. In Hybrid
Systems: Computation and Control, LNCS 1386, pages 49–63. Springer, 1998.
30. S. Bornot, J. Sifakis, and S. Tripakis. Modeling urgency in timed systems. In
Compositionality: The Signiﬁcant Diﬀerence, International Symposium, COM-
POS’97, Bad Malente, Germany, September 8-12, 1997. Revised Lectures,
LNCS 1536, pages 103–129. Springer, 1998.

References
399
31. G. Boudol and I. Castellani. Flow models of distributed computations: Three
equivalent semantics for CCS.
Information and Computation, 114:247–314,
1994.
32. H. Bowman. A true concurrency approach to time extended LOTOS (revised
version). Technical Report 17-96, Computing Laboratory, University of Kent
at Canterbury, 1996.
33. H. Bowman. A LOTOS based tutorial on formal methods for object-oriented
distributed systems. New Generation Computing, 16:343–372, 1998.
34. H. Bowman.
Modelling timeouts without timelocks.
In ARTS’99, Formal
Methods for Real-Time and Probabilistic Systems, 5th International AMAST
Workshop, LNCS 1601, pages 335–353. Springer-Verlag, 1999.
35. H. Bowman. Time and action lock freedom properties for timed automata. In
M. Kim, B. Chin, S. Kang, and D. Lee, editors, FORTE 2001, Formal Tech-
niques for Networked and Distributed Systems, pages 119–134, Cheju Island,
Korea, 2001. Kluwer Academic.
36. H. Bowman, L. Blair, G.S. Blair, and A. Chetwynd. Time versus abstraction in
formal description. In R.L. Tenney, P.D. Amer, and M.U. Uyar, editors, Formal
Description Techniques VI, FORTE’93, pages 467–482, Boston, October 1993.
North-Holland.
37. H. Bowman, E.A. Boiten, J. Derrick, and M. Steen. Viewpoint consistency in
ODP, a general interpretation. In E. Najm and J. Stefani, editors, First IFIP
International Workshop on Formal Methods for Open Object-based Distributed
Systems, pages 189–204, Paris, March 1996. Chapman & Hall.
38. H. Bowman, C. Briscoe-Smith, J. Derrick, and B. Strulo.
On behavioural
subtyping in LOTOS. In H. Bowman and J. Derrick, editors, FMOODS’97,
Second IFIP International Conference on Formal Methods for Open Object-
based Distributed Systems. Chapman & Hall, 1997.
39. H. Bowman and J. Derrick. Extending LOTOS with time; a true concurrency
perspective. In M. Bertran and T. Rus, editors, Proceedings 4th Amast Work-
shop on Real-Time Systems, Concurrent and Distributed Software, LNCS 1231.
Springer-Verlag, 1997.
40. H. Bowman and J. Derrick. A junction between state based and behavioural
speciﬁcation. In Formal Methods for Open Object-based Distributed Systems,
pages 213–239. Kluwer, February 1999.
41. H. Bowman and J. Derrick, editors. Formal Methods for Distributed Processing,
A Survey of Object-Oriented Techniques. Cambridge University Press, 2001.
42. H. Bowman, J. Derrick, P. Linington, and M. Steen.
Cross viewpoint con-
sistency in open distributed processing. IEE Software Engineering Journal,
11(1):44–57, January 1996.
43. H. Bowman, G. Faconti, and M. Massink.
Speciﬁcation and veriﬁcation of
media constraints using uppaal. In 5th Eurographics Workshop on the Design,
Speciﬁcation and Veriﬁcation of Interactive Systems, DSV-IS 98, Eurographics
Series. Springer-Verlag, August 1998.
44. H. Bowman and R. Gomez. How to stop time stopping. Submitted for publi-
cation, 2005.
45. H. Bowman, R. Gomez, and L. Su. A tool for the syntactic detection of zeno-
timelocks in timed automata. In Proceedings of the 6th AMAST Workshop on
Real-Time Systems, Stirling, July 2004.
46. H. Bowman and J. Katoen. A true concurrency semantics for ET-LOTOS.
Technical Report 12/97, Univeristy of Erlangen, 1997.

400
References
47. H. Bowman and J. Katoen. A true concurrency semantics for ET-LOTOS.
In CSD’98 International Conference on Application of Concurrency to System
Design. IEEE Computer Society, 1998.
48. H. Bowman, M.W.A. Steen, E.A. Boiten, and J. Derrick. A formal framework
for viewpoint consistency. Formal Methods in System Design, 21:111–166, 2002.
49. M. Bozga, C. Daws, O. Maler, A. Olivero, S. Tripakis, and S. Yovine. Kronos:
A model-checking tool for real-time systems. In Proceedings of the 10th Inter-
national Conference on Computer Aided Veriﬁcation, pages 546–550. Springer-
Verlag, 1998.
50. E. Brinksma. A theory for the derivation of tests. In S. Aggarwal and K. Sab-
nani, editors, Protocol Speciﬁcation, Testing and Veriﬁcation, VIII, pages 63–
74, Atlantic City, USA, June 1988. North-Holland.
51. E. Brinksma, J. Katoen, R. Langerak, and D. Latella. Performance analysis
and true concurrency semantics. In Theories and Experiences for Real-time
System Development (ARTS’93), pages 309–337. World Scientiﬁc, 1994.
52. E. Brinksma and G. Scollo.
Formal notions of implementation and confor-
mance in LOTOS. Technical Report INF-86-13, Dept of Informatics, Twente
University of Technology, 1986.
53. E. Brinksma, G. Scollo, and C. Steenbergen. Process speciﬁcation, their im-
plementation and their tests. In B. Sarikaya and G. V. Bochmann, editors,
Protocol Speciﬁcation, Testing and Veriﬁcation, VI, pages 349–360, Montreal,
Canada, June 1986. North-Holland.
54. R.E. Bryant.
Graph-based algorithms for Boolean function manipulation.
IEEE Transactions on Computers, C-35(8), 1986.
55. J.R. B¨uchi.
On a decision method in restricted second-order arithmetic.
Zeitschrift f¨ur Mathemathische Logik and Grundlagen der Mathematik, 6:66–
92, 1960.
56. CCITT Z.100. Speciﬁcation and Description Language SDL, 1988.
57. E. Clarke and E. Emerson. Design and synthesis of synchronization skeletons
using branching-time temporal logic. In D. Kozen, editor, Logic of Programs,
Workshop, Yorktown Heights, New York, May 1981, LNCS 131, pages 52–71.
Springer-Verlag, 1982.
58. E.M. Clarke, O. Grumberg, and D.A. Peleg. Model Checking. The MIT Press,
1999.
59. J. Courtiat and R.C. de Oliveria. RT-LOTOS and its application to multi-
media protocol speciﬁcation and validation. In International Conference on
Multimedia Networking, pages 30–47. IEEE Computing Press, 1995.
60. E. Cusack and G. H. B. Rafsanjani. ZEST. In S. Stepney, R. Barden, and
D. Cooper, editors, Object Orientation in Z, Workshops in Computing, pages
113–126. Springer-Verlag, 1992.
61. E. Cusack, S. Rudkin, and C. Smith.
An object oriented interpretation of
LOTOS. In Proceedings 2nd International Conference on Formal Description
Techniques (FORTE’89). North-Holland, December 1989.
62. A. David, G. Behrmann, K. Larsen, and W. Yi. A tool architecture for the next
generation of uppaal. In UNU/IIST 10th Anniversary Colloquium. Formal
Methods at the Cross Roads: From Panacea to Foundational Support, LNCS
2757. Springer, 2003.
63. A. David, G. Behrmann, K. Larsen, and W. Yi.
Uniﬁcation & sharing in
timed automata veriﬁcation. In SPIN Workshop 03, volume 2648 of LNCS,
pages 225–229, 2003.

References
401
64. J. Davies. Speciﬁcation and Proof in Real-time CSP. Cambridge University
Press, 1993. Distinguished Dissertations in Computer Science.
65. J. Davies, J.W. Bryans, and S.A. Schneider. Real-time LOTOS and timed ob-
servations. In D. Hogrefe and S. Leue, editors, Formal Description Techniques
VIII. Chapman & Hall, 1995.
66. C. Daws, A. Olivero, S. Tripakis, and S. Yovine. The tool KRONOS. In Hybrid
Systems III, Veriﬁcation and Control, LNCS 1066. Springer-Verlag, 1996.
67. C. Daws and S. Tripakis. Model checking of real-time reachability properties
using abstractions. In TACAS, pages 313–329, 1998.
68. C. Daws and S. Yovine.
Reducing the number of clock variables of timed
automata.
In RTSS ’96: Proceedings of the 17th IEEE Real-Time Systems
Symposium (RTSS ’96), page 73. IEEE Computer Society, 1996.
69. J. Derrick and E. Boiten.
Reﬁnement in Z and Object-Z: Foundations and
Advanced Applications. Springer, FACIT Series, 2001.
70. J. Derrick, E.A. Boiten, H. Bowman, and M. Steen. Supporting ODP - trans-
lating LOTOS to Z. In First IFIP International workshop on Formal Methods
for Open Object-based Distributed Systems, Paris, March 1996. Chapman &
Hall.
71. D. Dill.
Timing assumptions and veriﬁcation of ﬁnite-state concurrent sys-
tems. In Proceedings of the International Workshop on Automatic Veriﬁcation
Methods for Finite State Systems, pages 197–212. Springer-Verlag, 1990.
72. C.C. Elgot. Decision problems of ﬁnite automata design and related arith-
metics. Trans. Amer. Math. Soc., 98:21–51, 1961.
73. A. Fantechi, S. Gnesi, and G. Ristori. Compositional logic semantics and LO-
TOS. In L. Logrippo, R. L. Probert, and H. Ural, editors, Protocol Speciﬁcation,
Testing and Veriﬁcation, X, Ottawa, Canada, June 1990. North-Holland.
74. K. Farooqui and L. Logrippo.
Viewpoint transformations.
In J. de Meer,
B. Mahr, and O. Spaniol, editors, 2nd International IFIP TC6 Conference on
Open Distributed Processing, pages 352–362, Berlin, Germany, September 1993.
75. J. Fernandez.
An implementation of an eﬃcient algorithm for bisimulation
equivalence. Science of Computer Programming, 13(2–3):219–236, 1990.
76. J. Fernandez and L. Mournier. On-the-ﬂy veriﬁcation of behavioural rquiva-
lences and preorder. In 3rd Workshop on Computer-Aided Veriﬁcation, 1991.
77. C.J. Fidge. A comparative introduction to CSP, CCS and LOTOS. In FORTE
92 Tutorial, Lannion, France, 1992.
78. C.J. Fidge.
A constraint-oriented real-time process calculus.
In M. Diaz
and R. Groz, editors, FORTE 92, Formal Description Techniques V, Lannion,
France, 1993. North-Holland.
79. A.C.W. Finkelstein, D. Gabbay, A. Hunter, J. Kramer, and B. Nuseibeh. In-
consistency handling in multiperspective speciﬁcations. IEEE Transactions on
Software Engineering, 20(8):569–578, August 1994.
80. K. Fisher and J.C. Mitchell. Notes on typed object-oriented programming. In
Proceedings of Theoretical Aspects of Computer Software (TACS ’94), Sendai,
Japan, LNCS 789, pages 844–886. Springer, 1994.
81. H. Garavel, F. Lang, and R. Mateescu.
An overview of CADP 2001.
Technical Report RT-254, INRIA, France, December 2001.
Also see
http://www.inrialpes.fr/vasy/cadp/.
82. B. Gebremichael and F. Vaandrager. Specifying Urgency in Timed I/O Au-
tomata. Technical Report NIII-R0459, Radboud University Nijmegen, Nether-
lands, December 2004.

402
References
83. A. Goldberg and D. Robson. Smalltalk-80: The Language and its Implemen-
tation. Addison-Wesley, 1983.
84. R. Gomez and H. Bowman. Discrete timed automata and MONA: Description,
speciﬁcation and veriﬁcation of a multimedia stream. In H. Konig, M. Heiner,
and A. Wolisz, editors, Formal Techniques for Networked and Distributed Sys-
tems - FORTE 2003. Proceedings of the 23rd IFIP WG 6.1 International Con-
ference, Berlin, Germany, September/October 2003, LNCS 2767, pages 177–
192. Springer, 2003.
85. R. Gomez and H. Bowman. Discrete timed automata, invariance proofs and
mona: An alternative approach to the speciﬁcation and veriﬁcation of real-time
systems. Submitted for publication, 2004.
86. D. Gries and F.B. Schneider. A Logical Approach to Discrete Math. Springer-
Verlag, 1993.
87. D. Harel. Statecharts: A visual formalism for complex systems.
Science of
Computer Programming, 8:231–274, 1987.
88. M. Hendriks, G. Behrmann, K. Larsen, P. Niebert, and F. Vaandrager. Adding
symmetry reduction to uppaal. In K. Larsen and P. Niebert, editors, Proceed-
ings of FORMATS 2003, LNCS 2791, pages 46–59. Springer-Verlag, 2004.
89. M. Hennessy. Algebraic Theory of Processes. MIT Press, 1988.
90. M. Hennessy and R. Milner. Algebraic laws for non-determinism and concur-
rency. Journal of the ACM, 32(1):137–161, 1985.
91. T. Henzinger, X. Nicollin, J. Sifakis, and S. Yovine. Symbolic model checking
for real-time systems. Information and Computation, 111(2):193–244, 1994.
92. T.A. Henzinger and Pei-Hsin.
HyTech: The Cornell HYbrid TECHnology
tool. In Proceedings of TACAS, Workshop on Tools and Algorithms for the
Construction and Analysis of Systems, 1995.
93. H. Hermanns. Interactive Markov Chains. PhD thesis, University of Erlangen,
1998.
94. J. Hillston. A Compositional Approach to Performance Modelling. Cambridge
University Press, 1996. Distinguished Dissertations in Computer Science.
95. C.A.R. Hoare. Communicating sequential processes. Communications of the
ACM, 21(8):666–677, 1978.
96. C.A.R. Hoare. Communicating Sequential Processes. Prentice-Hall, 1985.
97. G. Holzmann. The SPIN MODEL CHECKER: Primer and Reference Manual.
Addison-Wesley, 2003.
98. G.J. Holzmann. Design and Validation of Computer Protocols. Prentice-Hall,
1991.
99. International Standards Organization. Belgium-Spanish Proposal for a Time
Extended LOTOS, December 1994.
100. C. Ip and D. Dill. Better veriﬁcation through symmetry. Formal Methods in
System Design, 9(1-2):41–75, 1996.
101. ISO. Information processing systems – Open Systems Interconnection – LO-
TOS – A formal description technique based on the temporal ordering of ob-
servational behaviour, 1989. IS 8807.
102. ISO.
Time Extended LOTOS. International Standards Organization, 1997.
Available at ftp://ftp.dit.upm.es/pub/lotos/elotos/.
103. ISO. Information Technology - E-LOTOS, ISO/IEC 15437:2001, International
Standard. ISO, 2001.
104. ISO 8807. LOTOS: A Formal Description Technique based on the Temporal
Ordering of Observational Behaviour, July 1987.

References
403
105. ISO 9074. Estelle, a Formal Description Technique based on an extended state
transition model, June 1987.
106. ITU Recommendation X.901-904 — ISO/IEC 10746 1-4.
Open Distributed
Processing - Reference Model - Parts 1-4, July 1995.
107. J. Katoen. Quantitative and Qualititative Extensions of Event Structures. PhD
thesis, University of Twente, The Netherlands, 1996.
108. J. Katoen, D.Latella, R. Langerak, E. Brinksma, and T. Bolognesi. A consistent
causality-based view on a timed process algebra including urgent interactions.
Journal of Formal Methods in System Design, 12(2):189–216, 1998.
109. J. Katoen, D. Latella, R. Langerak, and E. Brinksma. On specifying real-time
systems in a causality-based setting. In B. Jonsson and J. Parrow, editors, For-
mal Techniques in Real-Time and Fault-Tolerant Systems, LNCS 1135, pages
385–405. Springer-Verlag, 1996.
110. D. Kaynar, N. Lynch, R. Segala, and F. Vaandrager.
Timed I/O au-
tomata: a mathematical framework for modelling and analyzing real-time sys-
tems. In Proceedings 24th IEEE International Real-Time Systems Symposium
(RTSS03), pages 166–177. IEEE Computer Society, 2003.
111. N. Klarlund and A. M¨oller. MONA Version 1.4 User Manual. BRICS, Uni-
versity of Aarhus, Denmark, January 2001.
112. D. Kozen. Results on the propositional mu-calculus. Theoretical Computer
Science, 27:333–354, 1983.
113. L. Lamport. Hybrid systems in TLA+. In Hybrid Systems, LNCS 736, pages
77–102. Springer-Verlag, 1993.
114. R. Langerak. Transformations and Semantics for LOTOS. PhD thesis, Uni-
versity of Twente, The Netherlands, 1992.
115. K. Lano.
Speciﬁcation of distributed systems in VDM++.
In FORTE’95.
Chapman & Hall, 1995.
116. K. Larsen, F. Larsson, P. Pettersson, and W. Yi. Eﬃcient veriﬁcation of real-
time systems: Compact data structures and state-space reduction.
In Pro-
ceedings of the 18th IEEE Real-Time Systems Symposium, pages 14–24. IEEE
Computer Society Press, December 1997.
117. K. Larsen, F. Larsson, P. Pettersson, and W. Yi.
Compact data structure
and state-space reduction for model checking real time systems. Real-Time
Systems, 25(2):255–275, September 2003.
118. K. Larsen and A. Skou.
Bisimulation through probabilistic testing.
In 6th
ACM Symposium on Principles of Programming Languages, 1989.
119. K.G. Larsen, B. Steﬀen, and C. Weise. A constraint oriented proof methodology
based on modal transition systems. Technical Report RS-94-47, University of
Aarhus, 1994.
120. G. Leduc. On the Role of Implementation Relations in the Design of Distributed
Systems using LOTOS. PhD thesis, University of Li`ege, Li`ege, Belgium, June
1991.
121. G. Leduc. An upward compatible timed extension to LOTOS. In FORTE’91.
North-Holland, 1991.
122. G. Leduc. A framework based on implementation relations for implementing
LOTOS speciﬁcations. Computer Networks and ISDN Systems, 25:23–41, 1992.
123. G. Leduc and L. Leonard. A timed LOTOS supporting a dense time domain
and including new timed operators. In FORTE’92, Lannion, France, October
1992. North-Holland.

404
References
124. L. Leonard. An Extended LOTOS for the Design of Time-Sensitive Systems.
PhD thesis, University of Liege, Belgium, 1997.
125. L. Leonard and G. Leduc.
An enhanced version of timed LOTOS and its
application to a case study.
In P. Amir R. Tenney and U. Uyar, editors,
FORTE’93, pages 483–498, Boston, October 1993. North-Holland.
126. L. Leonard and G. Leduc. An introduction to ET-LOTOS for the description
of time-sensitive systems. Computer Networks and ISDN Systems, 29:271–292,
1996.
127. L. Leonard, G. Leduc, and A. Danthine.
The tick-tock case study for the
assessment of timed fdts. In The OSI95 Transport Service with Multimedia
Support, pages 338–352. Springer-Verlag, 1994.
128. O. Lichtenstein and A. Pnueli. Propositional temporal logics: Decidability and
completeness. Logic Journal of the IGPL, 8(1), 2000.
129. P. F. Linington. RM-ODP: The architecture. In K. Raymond and L. Arm-
strong, editors, IFIP TC6 International Conference on Open Distributed Pro-
cessing, pages 15–33, Brisbane, Australia, February 1995. Chapman and Hall.
130. B. Liskov and J. M. Wing. A new deﬁnition of the subtype relation. In O. M.
Nierstrasz, editor, ECOOP ’93 - Object-Oriented Programming, LNCS 707,
pages 118–141. Springer-Verlag, 1993.
131. R. Loogen and U. Goltz. Modelling nondeterministic concurrent processes with
event structures. Fundamenta Informaticae XIV, pages 39–74, 1991.
132. N. Lynch and M. Tuttle. An introduction to input/output automata. CWI
Quarterly, 2(3):219–246, September 1989.
133. N. Lynch and F. Vaandrager. Forward and backward simulations: I. untimed
systems. Information and Computation, 121(2):214–233, 1995.
134. N. Lynch and F. Vaandrager.
Forward and backward simulations—Part ii:
Timing-based systems. Information and Computation, 128(1):1–25, July 1996.
135. Z. Manna, Y. Kesten, and A. Pnueli. Verifying clocked transition systems. In
Hybrid Systems III, LNCS 1066, pages 13–40. Springer-Verlag, 1996.
136. Z. Manna and A. Pnueli.
The Temporal Logic of Reactive and Concurrent
Systems: Speciﬁcation. Springer-Verlag, 1992.
137. Z. Manna and A. Pnueli. Temporal Veriﬁcation of Reactive Systems: Safety.
Springer-Verlag, 1995.
138. R. Mateescu and M. Sighireanu. Eﬃcient on-the-ﬂy model-checking for regu-
lar alternation-free mu-calculus. In I. Schieferdecker S. Gnesi and A. Rennoch,
editors, FMICS’2000, 5th International Workshop on Formal Methods for In-
dustrial Critical Systems, GMD Report 91, pages 65–89, 2000.
139. A. Mazurkiewicz. Basic notions of trace theory. In Linear Time, Branching
Time and Partial Order in Logics and Models of Concurrency, LNCS 354.
Springer-Verlag, 1988.
140. K. McMillan.
Symbolic model checking: an approach to the state explosion
problem. PhD thesis, Carnegie Mellon University, Pittsburgh, PA, 1992.
141. P. Merlin and D.J. Farber. Recoverability of communication protocols - Impli-
cations of a theoretical study. IEEE Transactions on Communications, COM-
24:1036–1043, September 1976.
142. M. Merritt, F. Modugno, and M. Tuttle. Time-constrained automata. In CON-
CUR: 2nd International Conference on Concurrency Theory. LNCS, Springer-
Verlag, 1991.

References
405
143. C. Miguel, A. Fernandez, and L. Vidaller. Extending LOTOS towards per-
formance evaluation. In M. Diaz and R. Groz, editors, Formal Description
Techniques, V, Lannion, France, October 1992. North-Holland.
144. G.J. Milne. CIRCAL and the representation of communication concurrency
and time.
ACM Transactions on Programming Languages and Systems,
7(2):270–298, 1985.
145. R. Milner. A Calculus of Communicating Systems. LNCS 92. Springer-Verlag,
1980.
146. R. Milner. Calculi for synchrony and asynchrony. Journal of Theoretical Com-
puter Science, 25:267–310, 1985.
147. R. Milner. Process constructors and interpretations. In Information Processing
86. Elsevier Publishers, 1986.
148. R. Milner. Communication and Concurrency. Prentice-Hall, 1989.
149. R. Milner, J. Parrow, and D. Walker. A calculus of mobile processes. Infor-
mation and Computation, 100:1–77, 1992.
150. H.B. Munster. Comments on the LOTOS standard. Technical Report DITC
52/91, National Physical Laboratory, Teddington, Middlesex, UK, September
1991.
151. E. Najm, J. Stefani, and A. Fevrier. Introducing Mobility in LOTOS. ISO/IEC
JTC1/SC21/WG1 approved AFNOR contribution, July 1994.
152. A. Nakata, T. Higashino, and K. Taniguchi. Lotos enhancement to specify time
constraint among non-adjacentactions using 1st-order logic.
In FORTE’93.
North-Holland, 1993.
153. R. De Nicola and M. Hennessy. Testing equivalences for processes. Journal of
Theoretical Computer Science, 34:83–133, 1984.
154. X. Nicollin and J. Sifakis. An overview and synthesis on timed process algebra.
In Real-time Theory in Practice, LNCS 600, pages 549–572. Springer-Verlag,
June 1991.
155. M. Nielsen, G. Plotkin, and G. Winskel.
Petri nets, event structures and
domains, part 1. Theoretical Computer Science, 13, 1981.
156. O. Nierstrasz. Regular types for active objects. In Object-oriented Software
Composition, pages 99–120. Prentice-Hall, 1995.
157. J.S. Ostroﬀ. Temporal Logic for Real-Time Systems. Research Studies Press,
1989.
158. S. Owre and H. Rueß. Integrating WS1S with PVS. In E.A. Emerson and A.P.
Sistla, editors, Computer-Aided Veriﬁcation, CAV ’2000, LNCS 1855, pages
548–551. Springer-Verlag, 2000.
159. R. Paige and R. Tarjan. Three partition reﬁnement algorithms. SIAM Journal
of Computing, 16(6), 1987.
160. D. Park. Concurrency and automata on inﬁnite sequences. In Proceedings of
5th GI Conference, LNCS 104, pages 167–183. Springer-Verlag, 1981.
161. C.A. Petri. Fundamentals of a theory of asynchronous information ﬂow. In
Information Processing 1962, Proceedings of the IFIP Congress 62, pages 386–
390, Munich, Germany, 1962. North Holland Publishing Company.
162. A. Pnueli. The temporal logic of programs. In Proceedings of the 18th IEEE
Symposium Foundations of Computer Science (FOCS 1977), pages 46–57,
1977.
163. F. Puntigam.
Types for active objects based on trace semantics.
In First
IFIP Workshop on Formal Methods for Open Object-Based Distributed Sys-
tems, Paris, March 1996. Chapman & Hall.

406
References
164. J. Quemada and A. Fernandez. Introduction of quantitative relative time into
lotos. In Protocol Speciﬁcation, Testing and Veriﬁcation, VII, pages 105–121.
North-Holland, 1987.
165. J. Quemada, D. Frutos, and A. Azcorra. Tic: A timed calculus. Technical
Report 28040, University of Madrid, Madrid, Spain, July 1991.
166. J. Quemada, C. Miguel, D. de Frutos, and L. Llana.
Proposal for Timed
LOTOS. ISO/IEC JTC1/SC21/WG1, 1994.
167. T. Regan.
Process Algebra for Timed Systems.
PhD thesis, University of
Sussex, Sussex, UK, 1991.
168. T. Regan. Multimedia in temporal LOTOS: A lip synchronisation algorithm.
In PSTV XIII, 13th Protocol Spec., Testing & Veriﬁcation. North-Holland,
1993.
169. W. Reisig. Petri Nets, An Introduction. Springer-Verlag, 1982.
170. A. Rensink. Posets for conﬁgurations! In CONCUR’92, LNCS 30. Springer-
Verlag, 1992.
171. A.W. Roscoe. The Theory and Practice of Concurrency. Prentice-Hall, 1997.
172. G.A. Rose.
Object-Z.
In S. Stepney, R. Barden, and D. Cooper, editors,
Object Orientation in Z, Workshops in Computing, pages 59–78. Springer-
Verlag, 1992.
173. S. Rudkin. Inheritance in LOTOS. In K.R. Parker and G.A. Rose, editors,
Formal Description Techniques, IV, Sydney, Australia, November 1991. North-
Holland.
174. A. Sandholm and M.I. Schwartzbach. Distributed safety controllers for web
services. In E. Astesiano, editor, Fundamental Approaches to Software Engi-
neering (FASE’98), LNCS 1382, pages 270–284. Springer-Verlag, 1998.
175. S. Schneider. Timewise reﬁnement for communicating processes. Science of
Computer Programming, 28:43–90, 1997.
176. S. Schneider. Concurrent and Real-time Systems, the CSP Approach. Wiley,
2000.
177. S. Schneider, J. Davies, D.M. Jackson, G.M. Reed, J.N. Reed, and A.W.
Roscoe. Timed CSP: Theory and practice. In Real-Time: Theory in Prac-
tice, LNCS 600, pages 640–675. Springer-Verlag, 1991.
178. R. Segala, R. Gawlick, J. Sogaard-Andersen, and N. Lynch. Liveness in timed
and untimed systems. Information and Computation, 141(2):119–171, 1998.
179. S. Singh. Fermat’s Last Theorem. Walker, 1997.
180. G. Smith. Extending W for Object-Z. In J. Bowen and M. Hinchey, editors,
9th International Conference of Z Users, LNCS 967, pages 276–295. Springer-
Verlag, 1995.
181. M.A. Smith and N. Klarlund. Veriﬁcation of a sliding window protocol using
IOA and MONA. In T. Bolognesi and D. Latella, editors, Formal Methods for
Distributed System Development, pages 19–34. Kluwer Academic, 2000.
182. I. Sommerville. Software Engineering. Addison-Wesley, 1989.
183. J.A. Stankovic and K. Ramamiritham.
Tutorial - Hard Real-time Systems.
IEEE Computer Society Press, 1988.
184. M. Steen, H. Bowman, and J. Derrick. Composition of LOTOS speciﬁcations.
In P. Dembinski and M. Sredniawa, editors, Protocol Speciﬁcation, Testing and
Veriﬁcation, Warsaw, Poland, 1995. Chapman & Hall.
185. M. Steen, H. Bowman, J. Derrick, and E.A. Boiten. Disjunction of LOTOS
speciﬁcations. In Formal Description Techniques and Protocol Speciﬁcation,
Testing and Veriﬁcation, 1997, pages 177–192. Kluwer, 1997.

References
407
186. U. Stern and D.L. Dill. Improved probabilistic veriﬁcation by hash compaction.
In Proceedings of the Advanced Research Working Conference on Correct Hard-
ware Design and Veriﬁcation Methods, pages 206–24, 1995.
187. A. Tanenbaum. Computer Networks. Prentice-Hall, 1989.
188. W. Thomas. Automata on inﬁnite objects. In Handbook of Theoretical Com-
puter Science, volume B, pages 133–191. MIT Press, Elsevier, 1990.
189. S. Tripakis. The analysis of timed systems in practice. PhD thesis, Universite
Joseph Fourier, Grenoble, France, December 1998.
190. S. Tripakis. Verifying progress in timed systems. In ARTS’99, Formal Methods
for Real-Time and Probabilistic Systems, 5th International AMAST Workshop,
LNCS 1601. Springer-Verlag, 1999.
191. R.J. van Glabbeek. The reﬁnement theorem for ST-bisimulation semantics. In
Programming Concepts and Methods. Elsevier Science Publishers, 1990.
192. R.J. van Glabbeek. The linear time - branching time spectrum (I and II). In
Concur’90 and Concur’93, LNCS 458 and LNCS 715. Springer-Verlag, 1990
and 1993.
193. R.J. van Glabbeek and G.D. Plotkin. Conﬁguration structures. In 10th An-
nual Symposium on Logic in Computer Science. IEEE Computer Society Press,
1995.
194. M.Y. Vardi. Branching vs linear time: Final showdown. In T. Margaria and
W. Yi, editors, TACAS’2001, Tools and Algorithms for the Construction and
Analysis of Systems, held as part of ETAPS’01, LNCS 2031. Springer-Verlag,
2001. invited talk.
195. C. A. Vissers, G. Scollo, M. van Sinderen, and E. Brinksma. On the use of
speciﬁcation styles in the design of distributed systems. Theoretical Computer
Science, 89(1):179–206, October 1991.
196. C.A. Vissers, G. Scollo, and M. van Sinderen. Architecture and speciﬁcation
styles in formal descriptions of distributed systems. In Protocol Speciﬁcation,
Testing and Veriﬁcation, VIII, pages 189–204. North-Holland, 1988.
197. P. Wegner. Why interaction is more powerful than algorithms. Communica-
tions of the ACM, 40(5):80–91, 1997.
198. G. Winskel. An introduction to event structures. In Linear Time, Branching
Time and Partial Order in Logics and Models of Concurrency, LNCS 354,
pages 364–397. Springer-Verlag, 1988.
199. G. Winskel. The Formal Semantics of Programming Languages, an Introduc-
tion. MIT Press, 1993.
200. P. Wolper and D. Leroy.
Reliable hashing without collision detection.
In
CAV’93, pages 59–70, 1993.
201. Wang Yi. Ccs + time = an interleaving model for real-time systems. In Au-
tomata, Languages and Programming 18, LNCS 510, pages 217–228. Springer-
Verlag, 1991.
202. S. Yovine. Kronos: A veriﬁcation tool for real-time systems. Springer Interna-
tional Journal of Software Tools for Technology Transfer, 1997.
203. P. Zave and M. Jackson. Conjunction as composition. ACM Transactions on
Software Engineering and Methodology, 2(4):379–411, October 1993.

14
Appendix
14.1 Enabling as a Derived Operator
The following sections (14.2 and 14.3) present congruence proofs for bisimula-
tion equivalences over the pbLOTOS operators. To avoid one case in each of
these proofs, we use the fact that enabling can be encoded using hiding and
parallel composition.1
The mapping works as follows. Take d as a distinguished action and then
assume a mapping, denoted tr>>, which takes a behaviour, and rewrites all
occurrences of exit with d ; stop and ensures that all parallel threads synchro-
nise on d. Then it should be straightforward to see that
B1 >> B2 ∼hide d in ( tr>>(B1) |[d]| d ; B2 )
14.2 Strong Bisimulation Is a Congruence
This section includes a proof of the fact that strong bisimulation equivalence
(see Deﬁnition 5 in Section 3.3.3.1) is a congruence over the pbLOTOS oper-
ators.
Theorem 14.1.
If we assume that B1 ∼B2, then C[B1] ∼C[B2], if C[.] is any allowable
pbLOTOS context, i.e. could be generated from any of the operators of the
calculus.
Proof
Assume B1 ∼B2 and that R is a corresponding strong bisimulation containing
(B1, B2). We step through the pbLOTOS operators, showing that substitution
into the corresponding context preserves ∼.
1In fact, a similar observation was made by Milner, see Section 8.2 of [148].

410
14 Appendix
Action Preﬁx
Let P1 := a ; B1 and P2 := a ; B2 (where a ∈Act ∪{i}). Further assume that
S = {(P1, P2)} ∪R. We claim that S is a strong bisimulation relation. To
show this, take (Q1, Q2) ∈S and assume that Q1
b
−→Q′
1. We have two cases
to consider.
Case 1 (Q1 = P1 and Q2 = P2).
But, then, Q′
1 = B1, a = b and Q2
a
−→B2. The result follows because
(B1, B2) ∈R ⊆S.
Case 2 (Q1 ̸= P1 or Q2 ̸= P2).
But, then, (Q1, Q2) ∈R and the result follows.
Symmetric arguments can be given from Q2 to Q1.
Choice
This case is simpler than that for parallel composition and is omitted.
Parallel Composition
Let P1 := B |[G]| B1 and P2 := B |[G]| B2 (where G ⊆Act). Further assume
that S = {(D |[G]| D1, D |[G]| D2) | D, D1, D2 ∈Beh ∧(D1, D2) ∈R }. We
claim that S is a strong bisimulation relation. To show this, take (Q1, Q2) ∈S,
assume that Q1
a
−→Q′
1, Q1 = D |[G]| D1 and Q2 = D |[G]| D2. We have two
cases to consider.
Case 1 (a ̸∈G ∪{δ}).
This yields two subcases.
Case 1.a (D
a
−→D′).
But then, Q′
1 = D′ |[G]| D1, Q2
a
−→Q′
2 and Q′
2 = D′ |[G]| D2. The result
follows because (D′ |[G]| D1, D′ |[G]| D2) ∈S.
Case 1.b (D1
a
−→D′
1).
But then, Q′
1 = D |[G]| D′
1 and (because (D1, D2) ∈R), D2
a
−→D′
2 and
(D′
1, D′
2) ∈R. It follows then that Q2
a
−→Q′
2 and Q′
2 = D |[G]| D′
2. The
result follows because (D |[G]| D′
1, D |[G]| D′
2) ∈S.
Case 2 (a ∈G ∪{δ}).
But then, D
a
−→D′ and D1
a
−→D′
1 and Q′
1 = D′ |[G]| D′
1. However, because
(D1, D2) ∈R, D2
a
−→D′
2 and (D′
1, D′
2) ∈R. It follows then that Q2
a
−→Q′
2 and
Q′
2 = D′ |[G]| D′
2. The result follows because, (D′ |[G]| D′
1, D′ |[G]| D′
2) ∈S.
Symmetric arguments can be given from Q2 to Q1.

14.2 Strong Bisimulation Is a Congruence
411
Enabling
The encoding, presented in Section 14.1, of >> using hiding and parallel
composition means that this case does not have to be separately considered.
Hiding
Let P1 := hide G in B1 and P2 := hide G in B2 (where G ⊆Act). Fur-
ther assume that S = {(hide G in D1, hide G in D2) | D1, D2 ∈Beh
∧
(D1, D2) ∈R }. We claim that S is a strong bisimulation relation. To show
this, take (Q1, Q2) ∈S, assume that Q1
a
−→Q′
1, Q1 = hide G in D1 and
Q2 = hide G in D2. We have two cases to consider.
Case 1 (a ̸= i).
But then, a ̸∈G and D1
a
−→D′
1. However, because (D1, D2) ∈R we know
that D2
a
−→D′
2 and (D′
1, D′
2) ∈R. Hence, Q2 = hide G in D2
a
−→Q′
2 =
hide G in D′
2 and because (Q′
1, Q′
2) = (hide G in D′
1, hide G in D′
2) ∈S,
the result follows.
Case 2 (a = i).
This yields two subcases.
Case 2.a (D1
i
−→D′
1).
This case proceeds as per Case 1 above and is omitted.
Case 2.a (D1
x
−−→D′
1 ∧x ∈G).
But then because (D1, D2) ∈R we know that D2
x
−−→D′
2 and (D′
1, D′
2) ∈R.
Hence, Q2 = hide G in D2
i
−→Q′
2 = hide G in D′
2 and because (Q′
1, Q′
2) =
(hide G in D′
1, hide G in D′
2) ∈S, the result follows.
Symmetric arguments can be given from Q2 to Q1.
Relabelling
Follows similar lines to hiding and is omitted.
Process Instantiation
The proof here is somewhat more involved, because we need to handle recur-
sive deﬁnitions. We closely follow Milner’s proof for CCS [148].
Assume deﬁnitions of the form P := E, where E only references the process
variable X. We only deal with the case of single recursion. However, the
argument can easily be generalised to multiple recursive equations.
We write recursive equations as P := E[P/X].2 Expressions of the form
E[B/X] can be deﬁned by induction on the structure of E in the obvious way.
2The overloading of the [c/d] notation, which is already used for action rela-
belling, will not cause any confusion.

412
14 Appendix
In addition, we actually work with a generalisation of strong bisimulation
to behaviour expressions containing references to process variables. Again,
only dealing with the single recursion case, assuming that E and F only
reference the process variable X, we deﬁne
E ∼∗F iﬀ∀B ∈Beh , E[B/X] ∼F[B/X]
Now, the result we require is that, assuming that E and F only reference the
process variable X,
( E ∼∗F ∧P := E[P/X] ∧Q := F[Q/X] ) =⇒P ∼∗Q
Now, on the assumption that E and F only reference the process variable X,
and E ∼∗F ∧P := E[P/X] ∧Q := F[Q/X], we show that,
S = { (C[P/X], C[Q/X]) | C only references X }
is a strong bisimulation, which is as required because the case C = X gives
us that P ∼∗Q.
In fact, we show that
C[P/X]
a
−→B′ =⇒∃D′, D′′ . C[Q/X]
a
−→D′′ ∼∗D′ ∧(B′, D′) ∈S.
In all cases, there will exist symmetric arguments to justify the correspond-
ing result from C[Q/X] back to C[P/X]. We prove this result by transition
induction (see Section 2.10 of [148]) on the depth of the inference by which
the transition C[P/X]
a
−→B′ is generated. So, assume that C[P/X]
a
−→B′;
we have the following cases.
Case 1 (C = X).
But then, C[P/X] = P and thus, P
a
−→B′. It follows then that E[P/X]
a
−→B′
by a shorter inference, and thus, E[Q/X]
a
−→D′′ ∼∗D′
∧(B′, D′) ∈S.
However, because E ∼∗F, we know that F[Q/X]
a
−→D′′′ ∼∗D′ and, because
Q := F[Q/X], we have C[Q/X] = Q
a
−→D′′′ ∼∗D′ and (B′, D′) ∈S, as
required.
Case 2 (C = a ; C′).
But then, C[P/X] = a ; C′[P/X] and B′ = C′[P/X]. Also, we know that
C[Q/X] = a ; C′[Q/X]
a
−→C′[Q/X] and clearly (C′[P/X], C′[Q/X]) ∈S, as
required.
Case 3 (C = C1 [] C2).
Proceeds by a similar, but simpler, line of argument to the parallel composition
case and is, thus, omitted.
Case 4 (C = C1 |[G]| C2).
But then, C[P/X] = (C1 |[G]| C2)[P/X] = C1[P/X] |[G]| C2[P/X]. We have
two subcases.

14.2 Strong Bisimulation Is a Congruence
413
Case 4.a (a ̸∈G ∪{δ}).
Without loss of generality, assume C1[P/X]
a
−→B′
1 and B′ = B′
1 |[G]| C2[P/X],
which is by a shorter inference, thus, C1[Q/X]
a
−→D′′
1 ∼∗D′
1 ∧(B′
1, D′
1) ∈S.
But, then we know that, C[Q/X] = C1[Q/X] |[G]| C2[Q/X]
a
−→D′′ ∼∗D′,
where D′′ = (D′′
1 |[G]| C2[Q/X]) and D′ = (D′
1 |[G]| C2[Q/X]). But, we also
know that (B′
1, D′
1) ∈S, therefore, ∃H . B′
1 = H[P/X] ∧D′
1 = H[Q/X]. It
follows then that
(B′, D′) = ( B′
1 |[G]| C2[P/X] , D′
1 |[G]| C2[Q/X] )
= ( H[P/X] |[G]| C2[P/X] , H[Q/X] |[G]| C2[Q/X] )
= ( (H |[G]| C2)[P/X] , (H |[G]| C2)[Q/X] ) ∈S
which is as required.
Case 4.b (a ∈G ∪{δ}).
Follows similar lines to Case 4.a and omitted.
Case 5 (C = C1 >> C2).
This does not have to be separately dealt with, because of the encoding of
enabling into hiding and parallel composition discussed in Section 14.1.
Case 6 (C = hide G in C′).
But then, C[P/X] = (hide G in C′)[P/X] = hide G in C′[P/X]. We have two
subcases.
Case 6.a (a ̸= i).
But then, C′[P/X]
a
−→D1 (where B′ = hide G in D1), which is by a
shorter inference, therefore, C′[Q/X]
a
−→D2 ∼∗D3 ∧(D1, D3) ∈S. Thus,
C[Q/X] = (hide G in C′)[Q/X] = hide G in C′[Q/X]
a
−→D′′ ∼∗D′, where
D′′ = hide G in D2 and D′ = hide G in D3. But, we also know that
(D1, D3) ∈S, therefore, ∃H . D1 = H[P/X] ∧D3 = H[Q/X]. It follows
then that
(B′, D′) = ( (hide G in D1) , (hide G in D3) )
= ( (hide G in H[P/X]) , (hide G in H[Q/X]) )
= ( (hide G in H)[P/X] , (hide G in H)[Q/X] ) ∈S
which is as required.
Case 6.b (a = i).
This case is similar to Case 6.a, and is omitted.
Case 7 (C = C′[H]).
Similar to Case 6, and omitted.
Case 8 (C = R, where X does not occur).
Holds automatically, because C[P/X] = C[Q/X].
⃝

414
14 Appendix
14.3 Weak Bisimulation Congruence
This section includes a proof that justiﬁes our use of the term weak bisimu-
lation congruence; see Deﬁnition 8 in Section 3.3.3.1.
Theorem 14.2.
If we assume that B1 ≈c B2, then C[B1] ≈c C[B2], if C[.] is any allowable
pbLOTOS context, i.e. could be generated from any of the operators of the
calculus.
Proof
Assume B1 ≈c B2 and that R is a corresponding weak bisimulation congruence
containing (B1, B2). We step through the pbLOTOS operators, showing that
substitution into the corresponding context preserves ≈c.
Action Preﬁx
Let P1 := a ; B1 and P2 := a ; B2 (where a ∈Act ∪{i}). Further assume
that S = {(P1, P2)}. We claim that S is a weak bisimulation congruence. To
show this, take (Q1, Q2) ∈S and assume that Q1
b
−→Q′
1. Now, we know that
Q1 = P1 and Q2 = P2. But, then, Q′
1 = B1, a = b and Q2
a
=⇒⇒Q′
2 = B2
(note, whether a = b = i, or not,
a
=⇒⇒will have the same eﬀect). The result
follows because, as ≈c⊂≈, we now that B1 ≈B2.
Symmetric arguments can be given from Q2 to Q1.
Choice
Let P1 := B [] B1 and P2 := B [] B2. Further assume that S = {(P1, P2) }.
We claim that S is a weak bisimulation congruence. To show that this is the
case, take (P1, P2) ∈S and assume that P1
b
−→P ′
1. We have two cases to
consider.
Case 1 (B
b
−→B′).
But then, P ′
1 = B′ and P2
b
−→B′ and P2
b
=⇒⇒B′. The result follows because
(B′, B′) ∈Id ⊂≈.
Case 2 (B1
b
−→B′
1).
But then, P ′
1 = B′
1 and, because B1 ≈c B2, we know that B2
b
=⇒⇒B′
2 and
(B′
1, B′
2) ∈≈. Therefore, we know that P2
b
=⇒⇒B′
2.3 The result follows because
(B′
1, B′
2) ∈≈.
Symmetric arguments can be given from P2 to P1.
3It is this deduction, from B2
b
=⇒⇒B′
2 to P2
b
=⇒⇒B′
2, that is dependent upon the
use of =⇒⇒, because, with this relation, we know that choice is resolved when B2
performs b. If we had used =⇒⇒⇒with b = i, this would not have been certain.

14.3 Weak Bisimulation Congruence
415
Parallel Composition
Let P1 := B |[G]| B1 and P2 := B |[G]| B2 (where G ⊆Act). Further
assume S = {(P1, P2)} and R = { (D |[G]| D1, D |[G]| D2) | D, D1, D2 ∈
Beh ∧(D1, D2) ∈≈}. We claim that S is a weak bisimulation congruence,
with R the associated weak bisimulation. We verify these two statements in
turn.
Case 1 (to show that S is a weak bisimulation congruence).
Take (P1, P2) ∈S and assume that P1
a
−→P ′
1. We have two cases to consider.
Case 1.a (a ̸∈G ∪{δ}).
This yields two subcases.
Case 1.a.i (B
a
−→B′).
But then, P ′
1 = B′ |[G]| B1, P2
a
−→P ′
2 and P ′
2 = B′ |[G]| B2. Therefore,
P2
a
=⇒⇒P ′
2 and because ≈c ⊂≈and B1 ≈c B2, we have that (P ′
1, P ′
2) =
(B′ |[G]| B1, B′ |[G]| B2) ∈R, as required.
Case 1.a.ii (B1
a
−→B′
1).
But then, P ′
1 = B |[G]| B′
1 and (because B1 ≈c B2), B2
a
=⇒⇒B′
2 and
(B′
1, B′
2) ∈≈. It follows then that P2
a
=⇒⇒P ′
2 and P ′
2 = B |[G]| B′
2. The result
follows because (B |[G]| B′
1, B |[G]| B′
2) ∈R.
Case 1.b (a ∈G ∪{δ}).
But then, B
a
−→B′, B1
a
−→B′
1 and P ′
1 = B′ |[G]| B′
1. However, because
(B1, B2) ∈≈c, B2
a
=⇒⇒B′
2 and (B′
1, B′
2) ∈≈. It follows then that P2
a
=⇒⇒P ′
2
and P ′
2 = B′ |[G]| B′
2 and because (P ′
1, P ′
2) = (B′ |[G]| B′
1, B′ |[G]| B′
2) ∈R,
the result follows.
Symmetric arguments can be given from P2 to P1.
Case 2 (to show that R is a weak bisimulation equivalence).
To show this, take (Q1, Q2) ∈R and assume that Q1
a
−→Q′
1. Let Q1 =
D |[G]| D1 and Q2 = D |[G]| D2. We have two cases to consider.
Case 2.a (a ∈G ∪{δ}).
But then, D
a
−→D′ and D1
a
−→D′
1 and Q′
1 = D′ |[G]| D′
1. However, be-
cause (D1, D2) ∈≈, D2
a
=⇒⇒⇒D′
2 and (D′
1, D′
2) ∈≈. It follows then that
Q2
a
=⇒⇒⇒Q′
2
4 and Q′
2 = D′ |[G]| D′
2. The result follows because D′
1 ≈D′
2
and, thus, (Q′
1, Q′
2) = (D′ |[G]| D′
1, D′ |[G]| D′
2) ∈R.
Case 2.b (a ̸∈G ∪{δ}).
The two subcases here are both easier than Case 2.a above; both follow the
Case 2.a strategy and are both omitted.
Symmetric arguments can be given from Q2 to Q1.
4Note, any i actions that D2 performs before or after the a in
a
=⇒⇒⇒would be
inherited as (nonsynchronising) internal actions of D |[G]| D2, allowing
a
=⇒⇒⇒also
at this level.

416
14 Appendix
Enabling
The encoding, presented in Section 14.1, of >> using hiding and parallel
composition means that this case does not have to be separately considered.
Hiding
Let P1 := hide G in B1 and P2 := hide G in B2 (where G ⊆Act). Further
assume S = {(hide G in D1, hide G in D2) | D1, D2 ∈Beh ∧(D1, D2) ∈≈c }
and R = {(hide G in C1, hide G in C2) | C1, C2 ∈Beh ∧(C1, C2) ∈≈}. We
claim that S is a weak bisimulation congruence and R is a weak bisimulation
equivalence. We show these two results in turn.
Case 1 (to show that S is a weak bisimulation congruence).
Take (Q1, Q2) ∈S; assume that Q1
a
−→Q′
1, Q1 = hide G in D1, Q2 =
hide G in D2 and D1 ≈c D2. We have two cases to consider.
Case 1.a (a ̸= i).
But then, a ̸∈G and D1
a
−→D′
1. However, because (D1, D2) ∈≈c we know
that D2
a
=⇒⇒D′
2 and (D′
1, D′
2) ∈≈. Hence, Q2 = hide G in D2
a
=⇒⇒Q′
2
5,
Q′
2 = hide G in D′
2 and because (Q′
1, Q′
2) = (hide G in D′
1, hide G in D′
2) ∈R,
the result follows.
Case 1.b (a = i).
This yields two subcases.
Case 1.b.i (D1
i
−→D′
1).
Follows Case 1.a, and thus, omitted.
Case 1.b.ii (D1
x
−−→D′
1 ∧x ∈G).
But then because (D1, D2) ∈≈c we know that D2
x
=⇒⇒D′
2 and (D′
1, D′
2) ∈≈.
Hence, Q2 = hide G in D2
i
=⇒⇒Q′
2 = hide G in D′
2
6 and because (Q′
1, Q′
2) =
(hide G in D′
1, hide G in D′
2) ∈R, the result follows.
Symmetric arguments can be given from Q2 to Q1.
Case 2 (to show that R is a weak bisimulation equivalence).
Take (Q1, Q2) ∈R, assume that Q1
a
−→Q′
1, Q1 = hide G in D1 and Q2 =
hide G in D2 and D1 ≈D2. We have two cases to consider.
Case 2.a (a ̸= i).
But then, a ̸∈G and D1
a
−→D′
1. However, because (D1, D2) ∈≈we know
5Note, any i actions that D2 performs before or after the a in
a
=⇒⇒⇒would be
inherited by hide G in D2, allowing
a
=⇒⇒⇒also at this level.
6Note, D2
x
=⇒⇒D′
2 ensures that ∃D, D′ (possibly equal to D2, D′
2, respec-
tively) such that D is reachable from D2 by
ϵ
=⇒and D
x
−−→D′ and D′
ϵ
=⇒D′
2.
Now, applications of (HD.ii) ensure that hide G in D2
ϵ
=⇒hide G in D and
hide G in D′
ϵ
=⇒hide G in D′
2 and (HD.i) ensures that hide G in D
i
−→hide G in D′.

14.3 Weak Bisimulation Congruence
417
that D2
a
=⇒⇒⇒D′
2 and (D′
1, D′
2) ∈≈. Hence, Q2 = hide G in D2
a
=⇒⇒⇒Q′
2 =
hide G in D′
2 and because (Q′
1, Q′
2) = (hide G in D′
1, hide G in D′
2) ∈R, the
result follows.
Case 2.b (a = i).
This yields two subcases.
Case 2.b.i (D1
i
−→D′
1).
But then, D2
i
=⇒⇒⇒D′
2 and (D′
1, D′
2) ∈≈. Hence, Q2 = hide G in D2
i
=⇒⇒⇒Q′
2
7,
Q′
2 = hide G in D′
2 and because (Q′
1, Q′
2) = (hide G in D′
1, hide G in D′
2) ∈R,
the result follows.
Case 2.b.ii (D1
x
−−→D′
1 ∧x ∈G).
But then because (D1, D2) ∈≈we know that D2
x
=⇒⇒⇒D′
2 and (D′
1, D′
2) ∈≈.
Hence, Q2 = hide G in D2
x
=⇒⇒⇒Q′
2 = hide G in D′
2 and moreover because
(Q′
1, Q′
2) = (hide G in D′
1, hide G in D′
2) ∈R, the result follows.
Symmetric arguments can be given from Q2 to Q1.
Relabelling
Follows similar lines to hiding and is omitted.
Process Instantiation
Again, we closely follow Milner’s proof for CCS [148]. We generalise weak
bisimulation congruence to behaviour expressions containing references to pro-
cess variables. Again, only dealing with the single recursion case, assuming
that E and F only reference the process variable X, we deﬁne
E ≈∗
c F iﬀ∀B ∈Beh , E[B/X] ≈c F[B/X]
Now, the result we require is that, assuming that E and F only reference the
process variable X,
( E ≈∗
c F ∧P := E[P/X] ∧Q := F[Q/X] ) =⇒P ≈∗
c Q
Now, on the assumption that E and F only reference the process variable X,
and E ≈∗
c F ∧P := E[P/X] ∧Q := F[Q/X], we show that
S = { (C[P/X], C[Q/X]) | C only references X }
is a weak bisimulation congruence. This is as required because the case C = X
gives us that P ≈∗
c Q.
7The only slight diﬀerence between the argument here and the argument with
i
=⇒⇒in the corresponding case, (1.b.i), is that Q2 = Q′
2 and D2 = D′
2 are possible
here, but this does not cause any problems for the reasoning.

418
14 Appendix
In fact, we show that
C[P/X]
a
−→B′ =⇒∃D′, D′′ . C[Q/X]
a
=⇒⇒D′′ ≈∗
c D′ ∧(B′, D′) ∈S.
In all cases, there will exist symmetric arguments to justify the corresponding
result from C[Q/X] back to C[P/X]. We prove this theorem by transition
induction (see Section 2.10 of [148]) on the depth of the inference by which
the transition C[P/X]
a
−→B′ is generated. So, assume that, C[P/X]
a
−→B′;
we have the following cases.
Case 1 (C = X).
But then, C[P/X] = P and thus, P
a
−→B′. It follows then that E[P/X]
a
−→B′
by a shorter inference, and thus, E[Q/X]
a
=⇒⇒D′′ ≈∗
c D′ ∧(B′, D′) ∈S.
However, because E ≈∗
c F, we know that F[Q/X]
a
=⇒⇒D′′′ ≈∗
c D′ 8 and,
because Q := F[Q/X], we have C[Q/X] = Q
a
=⇒⇒D′′′ ≈∗
c D′ and further
(B′, D′) ∈S, as required.
Case 2 (C = a ; C′).
But then, C[P/X] = a ; C′[P/X] and B′ = C′[P/X]. Also, we know that
C[Q/X] = a ; C′[Q/X]
a
−→C′[Q/X]. Therefore, C[Q/X]
a
=⇒⇒C′[Q/X] Fur-
thermore, it is clear that (C′[P/X], C′[Q/X]) ∈S, as required.
Case 3 (C = C1 [] C2).
But then, C[P/X] = (C1 [] C2)[P/X] = C1[P/X] [] C2[P/X]. Without loss
of generality, assume C1[P/X]
a
−→B′, which is by a shorter inference, thus,
C1[Q/X]
a
=⇒⇒D′′ ≈∗
c D′
∧
(B′, D′) ∈S. However, then we know that
C[Q/X] = (C1 [] C2)[Q/X]
a
=⇒⇒D′′ ≈∗
c D′, where (B′, D′) ∈S and the result
follows.
Case 4 (C = C1 |[G]| C2).
But then, C[P/X] = (C1 |[G]| C2)[P/X] = C1[P/X] |[G]| C2[P/X]. We have
two cases to consider.
Case 4.a (a ̸∈G ∪{δ}).
Without loss of generality, assume C1[P/X]
a
−→B′
1 and B′ = B′
1 |[G]| C2[P/X],
which is by a shorter inference, thus, C1[Q/X]
a
=⇒⇒D′′
1 ≈∗
c D′
1 ∧(B′
1, D′
1) ∈S.
However, then we know that C[Q/X] = C1[Q/X] |[G]| C2[Q/X]
a
=⇒⇒D′′ ≈∗
c
D′, where D′′ = (D′′
1 |[G]| C2[Q/X]) and D′ = (D′
1 |[G]| C2[Q/X]). But, we
also know that, (B′
1, D′
1) ∈S, therefore, ∃H . B′
1 = H[P/X] ∧D′
1 = H[Q/X].
It follows then that
8Notice, the deduction here is more complex than the corresponding deduc-
tion for strong bisimulation. Speciﬁcally, there must be a derivation that witnesses
E[Q/X]
a
=⇒⇒, possibly involving i transitions. Now, because E ≈∗
c F, we can walk
along this path turning it into a (possibly longer, i.e. containing more i transitions)
path to witness F[Q/X]
a
=⇒⇒.

14.4 Timed Enabling as a Derived Operator
419
(B′, D′) = ( B′
1 |[G]| C2[P/X] , D′
1 |[G]| C2[Q/X] )
= ( H[P/X] |[G]| C2[P/X] , H[Q/X] |[G]| C2[Q/X] )
= ( (H |[G]| C2)[P/X] , (H |[G]| C2)[Q/X] ) ∈S
which is as required.
Case 4.b (a ∈G ∪{δ}).
Follows similar lines to Case 4.a and omitted.
Case 5 (C = C1 >> C2).
This does not have to be separately dealt with, because of the encoding of
enabling into hiding and parallel composition discussed in Section 14.1.
Case 6 (C = hide G in C′).
But then, C[P/X] = (hide G in C′)[P/X] = hide G in C′[P/X]. We have two
subcases.
Case 6.a (a ̸= i).
But then, C′[P/X]
a
−→D1 (where B′ = hide G in D1), which is by a
shorter inference, therefore, C′[Q/X]
a
=⇒⇒D2 ≈∗
c D3
∧
(D1, D3) ∈S.
Thus, C[Q/X] = (hide G in C′)[Q/X] = hide G in C′[Q/X]
a
=⇒⇒D′′ ≈∗
c D′,
where D′′ = hide G in D2 and D′ = hide G in D3. But, we also know that
(D1, D3) ∈S, therefore, ∃H . D1 = H[P/X] ∧D3 = H[Q/X]. It follows
then that
(B′, D′) = ( hide G in D1 , hide G in D3 )
= ( hide G in H[P/X] , hide G in H[Q/X] )
= ( (hide G in H)[P/X] , (hide G in H)[Q/X] ) ∈S
which is as required.
Case 6.b (a = i).
This case is similar to Case 6.a, and is omitted.
Case 7 (C = C′[H]).
Similar to Case 6, and omitted.
Case 8 (C = R, where X does not occur).
Holds automatically, because C[P/X] = C[Q/X].
⃝
14.4 Timed Enabling as a Derived Operator
The following sections (14.5, 14.6 and 14.7) investigate substitutivity of tLO-
TOS operators with respect to timed bisimulation equivalences. As was the

420
14 Appendix
case in the untimed setting (see Section 14.1), to show that enabling does
not fundamentally complicate the question of substitutivity, we show that,
in the tLOTOS context, enabling can be encoded using hiding and parallel
composition.
The mapping works as follows. Take d as a distinguished action and then
assume a mapping, denoted tr>>
t
, which takes a behaviour, and rewrites all
occurrences of exit I with d I ; stop and ensures that all parallel threads syn-
chronise on d. Then the following holds.
B1 >> B2 ∼t hide d in ( tr>>
t
(B1) |[d]| d ; B2 )
14.5 Hiding is Not Substitutive for Timed Bisimulations
In fact, because of our handling of urgency of internal actions, hiding fails to
be substitutive for all the timed bisimulation equivalences that we consider.
The following serves as a counter-example for all these equivalences. So, for
an arbitrary t in R+0 assume the following deﬁnitions.
observable1 := ( x [0, t] ; stop [] x ; stop )
observable2 := x ; stop
hidden1 := hide x in observable1
hidden2 := hide x in observable2
Now, observable1 and observable2 are equivalent by any of our timed bisimu-
lation relations: they both allow time to pass arbitrarily and immediately, or
after any such time passing transition, both can perform an x and evolve to
deadlock. However, hidden1 and hidden2 are behaviourally very diﬀerent and
fail to be equivalent according to any one of our timed bisimulation equiva-
lences. In fact, hidden1 is equivalent to i [0, t] ; stop, because i becomes urgent
at time t and, thus, hidden1 cannot pass time beyond t time units. However,
hidden2 can pass time arbitrarily.
14.6 Substitutivity of Timed Strong Bisimulation
Leonard [124] provides a timed strong bisimulation congruence for a calculus
(ET-LOTOS) that has similarities to tLOTOS. In order to reuse some of
these results, we provide the following mapping from tLOTOS to Leonard’s
ET-LOTOS, which is typed as
toETLOT : tLOTOS −→ET-LOTOS
and is deﬁned as follows.

14.6 Substitutivity of Timed Strong Bisimulation
421
toETLOT(B) ≜B , if B ∈{ stop , B1 [] B2 , B1 |[G]| B2
B1 >> B2 , hide G in B′ , P }
toETLOT(exit I) ≜∆↓I exit [↑I −↓I]
toETLOT(x I ; B) ≜x@t [t ∈I] ; toETLOT(B)
for t a fresh time variable
toETLOT(i I ; B) ≜∆↓I i [↑I −↓I] ; toETLOT(B)
toETLOT(wait [t] B) ≜∆t toETLOT(B)
The requirement that t be a fresh variable in the third clause of this deﬁni-
tion is needed to ensure that t does not appear in toETLOT(B). Relabelling
would be translated via ET-LOTOS process deﬁnition and instantiation in
the obvious way and tLOTOS process deﬁnition can also be translated in the
obvious way.
From a consideration of the ET-LOTOS semantics (Section 3.4 of [124]) it
is not hard to see that the meaning of the following tLOTOS operators is pre-
served by this mapping: stop, exit, (internal and external) action preﬁx, delay,
choice, parallel composition, relabelling and process instantiation. However,
because tLOTOS and ET-LOTOS (which enforces maximal progress when
an observable or successful termination action is hidden) handle hiding and
enabling diﬀerently, we cannot reuse Leonard’s proof in these two cases. As a
result, we have the following theorem.
Theorem 14.3.
For B1, B2 ∈tBeh, if we assume that B1 ∼t B2, then C[B1] ∼t C[B2], where
C[.] is a tLOTOS context using any operator apart from hiding and enabling.
Proof
This result follows from Leonard’s congruence proofs in Section 3.6.2 of [124]
using the toETLOT mapping.
⃝
However, the tLOTOS hiding and enabling operators are not substitutive.
Hiding. The example in Section 14.5 demonstrates hiding’s lack of substi-
tutivity. In particular, observable1 ∼t observable2, which can be justiﬁed as
follows. First, if we let,
Rd := ( x [0, t −d] ; stop ) [] ( x ; stop )
and
T ≜{ (Rd, observable2) | d ∈R+0 } ∪{ (stop, stop) }
noting that
(observable1,observable2) = (R0,observable2) ∈T

422
14 Appendix
we can show that T is a timed strong bisimulation. We argue as follows.
take d ∈R+0 and for v ∈{x} ∪R+ let Rd
v
−→→R
There are two cases to consider depending upon the type of v.
Case 1 (v = d′ ∈R+)
Now, because
observable2 = x[0, ∞) ; stop = x([0, ∞) ⊖d′) ; stop
and thus,
observable2
d′
; x([0, ∞) ⊖d′) ; stop =observable2
we know that R = R(d−d′) and therefore (R,observable2) ∈T, as required.
Case 2 (v = x and R = stop)
But then, observable2
x
−−→stop and (stop, stop) ∈T, as required.
The other direction of the deﬁnition of ∼t follows similarly.
This conﬁrms that observable1 and observable2 are timed strong bisimilar.
However, hidden1 ̸∼t hidden2, because
hidden2
t+k
−→→for k ∈R+, but hidden1
̸
t+k
−→→.
Enabling. In addition, enabling is not substitutive with respect to timed
strong bisimulation. In fact, due to the encoding of enabling using hiding and
parallel composition given in Section 14.4, this lack of substitutivity can be
tracked back to the previously discussed problem with hiding. However, for
completeness, we oﬀer a counter-example expressed directly using enabling.
Thus, take t ∈R+0 and assume the following deﬁnitions.
Exit1 := exit [0, t] [] exit
Exit2 := exit
Enab1 := Exit1 >> stop
Enab2 := Exit2 >> stop
But then it is straightforward to show that Exit1 ∼t Exit2. However, Enab1 ̸∼t
Enab2, because, ∀d ∈R+, Enab2
t+d
−→→, but Enab1
̸
t+d
−→→.
14.7 Substitutivity of Timed Rooted Weak Bisimulation
This section includes a proof that justiﬁes that, apart from hiding and en-
abling, all tLOTOS operators are substitutive with respect to timed rooted
weak bisimulation, as introduced in Deﬁnition 44 of Section 10.1.3. First
though, we justify that hiding and enabling are not substitutive in this con-
text. In fact, we can reuse the examples used for timed strong bisimulation.

14.7 Substitutivity of Timed Rooted Weak Bisimulation
423
That is, with respect to hiding, considering the deﬁnitions ﬁrst highlighted
in Section 14.5, it is not hard to see that observable1 ≈t
r observable2, but
hidden1 ̸≈t
r hidden2. In addition, with respect to enabling, consider the deﬁni-
tions highlighted in the discussion of enabling in Section 14.6. The following
relations obtain, Exit1 ≈t
r Exit2 and Enab1 ̸≈t
r Enab2.
Now we move to our main result.
Theorem 14.4.
If we assume that B1 ≈t
r B2, then C[B1] ≈t
r C[B2], where C[.] is any tLOTOS
context that does not contain hiding or enabling.
Proof
Assume B1 ≈t
r B2. We step through the tLOTOS operators, showing that
substitution into the corresponding context preserves ≈t
r.
Observable Action Preﬁx
Assume that S = { (x I ; D1 , x I ; D2) | D1 ≈t D2 ∧x ∈Act }, noting that
(x I ; B1, x I ; B2) ∈S, because ≈t
r⊂≈t. We will show that S is a timed rooted
weak bisimulation.
First, let P1 := x I ; D1 and P2 := x I ; D2 and D1 ≈t D2. Second, let
P1
v
−→→P ′
1. There are two cases to consider.
Case 1 (v = d ∈R+).
But then, P ′
1 = x (I ⊖d) ; D1 and P2
d; x (I ⊖d) ; D2 = P ′
2. In addition,
(P ′
1, P ′
2) ∈S, as required.
Case 2 (v = x).
But then, P ′
1 = D1 and 0 ∈I. From which it is clear that P2
x
−−→D2, which
implies that P2
x
=⇒⇒D2 and because D1 ≈t D2, the result follows.
Symmetric arguments can be given from P2 to P1.
Internal Action Preﬁx
Assume S = { (i I ; D1, i I ; D2) | D1 ≈t D2 }, noting that, because ≈t
r⊂≈t, it
is also the case that (i I ; B1, i I ; B2) ∈S. We will show that S is a timed
rooted weak bisimulation.
Firs, let P1 := i I ; D1 and P2 := i I ; D2 and D1 ≈t D2. Second, let
P1
v
−→→P ′
1. There are two cases to consider.
Case 1 (v = d ∈R+).
But then, P ′
1 = i (I ⊖d) ; D1 and d ≤↑I. From which it is straightforward to
see that P2
d; i (I ⊖d) ; D2 = P ′
2. In addition, (P ′
1, P ′
2) ∈S, as required.
Case 2 (v = i).
But then, P ′
1 = D1 and 0 ∈I. From which it is clear that P2
i
−→D2, which
implies that P2
i
=⇒⇒D2, and, because D1 ≈t D2, the result follows.
Symmetric arguments can be given from P2 to P1.

424
14 Appendix
Wait
Assume that S = { ( wait [t] D1 , wait [t] D2 ) | D1 ≈t
r D2 } ∪≈t
r, noting that
(wait [t] B1, wait [t] B2) ∈S. We will show that S is a timed rooted weak
bisimulation.
First, let P1 := wait [t] D1 and P2 := wait [t] D2 and D1 ≈t
r D2. Second,
let P1
v
−→→P ′
1. There are three cases to consider.
Case 1 (v = a ∈Act ∪{i, δ}).
But then, D1
a
−→D′
1 and t = 0. From which it is clear that P ′
1 = D′
1,
D2
a
=⇒⇒D′
2 and D′
1 ≈t D′
2. But then, P2 = wait [0] D2
a
=⇒⇒D′
2 (note, any
i transitions that enables D2
a
=⇒⇒will be inherited by P2
a
=⇒⇒). The result
follows because D′
1 ≈t D′
2.
Case 2 (v = d ∈R+ ∧d ≤t).
But then, P2
d; wait [t−d] ; D2 = P ′
2, P ′
1 = wait [t−d] ; D1 and (P ′
1, P ′
2) ∈S,
as required.
Case 3 (v = (d + t) ∈R+).
But then, D1
d; D′
1 and P ′
1 = D′
1. Furthermore, because D1 ≈t
r D2, we know
that D2
d; D′
2 and D′
1 ≈t
r D′
2. But then, P2
d+t
; P ′
2 and P ′
2 = D′
2. The result
follows, because (P ′
1, P ′
2) ∈S.
Symmetric arguments can be given from P2 to P1.
Choice
Assume that S = { (D [] D1, D [] D2) | D1 ≈t
r D2 }, noting that, by deﬁnition,
∀B, (B [] B1, B [] B2) ∈S. We will show that S is a timed rooted weak
bisimulation.
First, let P1 := D [] D1 and P2 := D [] D2 and D1 ≈t
r D2 (symmetric
arguments can be given if it is the ﬁrst argument that varies). Second, let
P1
v
−→→P ′
1. There are two cases to consider.
Case 1 (v = a ∈Act ∪{i, δ}).
Proceeds as per the untimed case (Theorem 14.2).
Case 2 (v = d ∈R+).
But then, D
d; D′, D1
d; D′
1 and P ′
1 = D′ [] D′
1. In addition, because
D1 ≈t
r D2, we know that D2
d; D′
2 and D′
1 ≈t
r D′
2. It follows then that
P2
d; P ′
2 and P ′
2 = D′ [] D′
2. The result follows because (P ′
1, P ′
2) ∈S.
Symmetric arguments can be given from P2 to P1.

14.7 Substitutivity of Timed Rooted Weak Bisimulation
425
Parallel Composition
Assume that S = { (D |[G]| D1 , D |[G]| D2) | D1 ≈t
r D2 }, noting that, by
deﬁnition, ∀B, (B |[G]| B1, B |[G]| B2) ∈S. We will show that S is a timed
rooted weak bisimulation.
First, let P1 := D |[G]| D1 and P2 := D |[G]| D2 and D1 ≈t
r D2 (symmet-
ric arguments can be given if it is the ﬁrst parameter that varies). Second, let
P1
v
−→→P ′
1. There are two cases to consider.
Case 1 (v = a ∈Act ∪{i, δ}).
Proceeds as per the untimed case (Theorem 14.2).
Case 2 (v = d ∈R+).
But then, D
d; D′, D1
d; D′
1 and P ′
1 = D′ |[G]| D′
1. In addition, as D1 ≈t
r D2
we know that D2
d; D′
2 and D′
1 ≈t
r D′
2. It follows then that P2
d; P ′
2 and
P ′
2 = D′ |[G]| D′
2. The result follows because (P ′
1, P ′
2) ∈S.
Symmetric arguments can be given from P2 to P1.
Relabelling
Straightforward.
Process Instantiation
Again, we closely follow Milner’s proof for CCS [148]. We generalise timed
rooted weak bisimulation to behaviour expressions containing references to
process variables. Again, we only deal with the single recursion case. Assuming
that E and F only reference the process variable X, we deﬁne,
E ≈t∗
r F iﬀ∀B ∈tBeh , E[B/X] ≈t
r F[B/X]
Now, the result we require is that, assuming that E and F only reference the
process variable X and do not contain hiding or enabling,
( E ≈t∗
r F ∧P := E[P/X] ∧Q := F[Q/X] ) =⇒P ≈t∗
r Q
Now, on the assumption that E and F only reference the process variable
X, do not contain hiding or enabling, and E ≈t∗
r
F, P := E[P/X] and
Q := F[Q/X], we will show that
S = { (C[P/X], C[Q/X]) | C only references X
and does not use hiding or enabling }
is a timed rooted weak bisimulation. This is as required because the case
C = X gives us that P ≈t∗
r Q.
In fact, we will show that

426
14 Appendix
C[P/X]
d
−→→B′ =⇒∃D′, D′′ . C[Q/X]
d; D′′ ≈t∗
r D′ ∧(B′, D′) ∈S
and
C[P/X]
a
−→→B′ =⇒∃D′, D′′ . C[Q/X]
a
=⇒⇒D′′ ≈t D′ ∧(B′, D′) ∈S.
In all cases there will exist symmetric arguments to justify the corresponding
result from C[Q/X] back to C[P/X]. We prove this theorem by transition
induction (see Section 2.10 of [148]) on the depth of the inference by which
the transition C[P/X]
v
−→→B′ (v ∈R+ ∪Act∪{δ, i}) is generated. So, assume
that C[P/X]
v
−→→B′, we have the following cases.
Case 1 (C = X).
But then, C[P/X] = P and thus, P
v
−→→B′. It follows then that E[P/X]
v
−→→B′
by a shorter inference, from which we have two cases.
Case 1a (v = d ∈R+).
∃D′, D′′ . E[Q/X]
d; D′′ ≈t∗
r D′ ∧(B′, D′) ∈S. However, because E ≈t∗
r F,
we know that F[Q/X]
d; D′′′ ≈t∗
r D′. Therefore, because Q := F[Q/X], we
have C[Q/X] = Q
d; D′′′ ≈t∗
r D′ and (B′, D′) ∈S, as required.
Case 1b (v = a ∈Act ∪{δ, i}).
∃D′, D′′ . E[Q/X]
a
=⇒⇒D′′ ≈t D′ ∧(B′, D′) ∈S. However, because E ≈t∗
r F,
we know that F[Q/X]
a
=⇒⇒D′′′ ≈t D′ (this step follows as per the untimed
case (Theorem 14.2)). Therefore, because Q := F[Q/X], we have C[Q/X] =
Q
a
=⇒⇒D′′′ ≈t D′ and (B′, D′) ∈S, as required.
Case 2 (C = a I ; C′).
But then, C[P/X] = a I ; C′[P/X]. From which there are four cases to con-
sider.
Case 2a (a = x ∈Act ∧v = d ∈R+).
But then, B′ = x (I ⊖d) ; C′[P/X]. Also, C[Q/X] = x I ; C′[Q/X]
d; D′ =
x (I ⊖d) ; C′[Q/X]. Furthermore, it is clear that
(B′, D′) = ( x (I ⊖d) ; C′[P/X] , x (I ⊖d) ; C′[Q/X] )
= ( (x (I ⊖d) ; C′)[P/X] , (x (I ⊖d) ; C′)[Q/X] ) ∈S
as required.
Case 2b (a = v = x ∈Act).
But then, B′ = C′[P/X] and 0 ∈I. Also,
C[Q/X] = x I ; C′[Q/X]
x
−−→D′ = C′[Q/X].
Furthermore, it is clear that C[Q/X]
x
=⇒⇒D′ = C′[Q/X] and the result follows
because (B′, D′) = (C′[P/X], C′[Q/X]) ∈S.

14.7 Substitutivity of Timed Rooted Weak Bisimulation
427
Case 2c (a = i ∧v = d ∈R+).
But then, B′ = i (I ⊖d) ; C′[P/X] and d ≤↑I. From which we know that
C[Q/X] = i I ; C′[Q/X]
d; D′ = i (I ⊖d) ; C′[Q/X]. Furthermore, it is clear
that
(B′, D′) = ( i (I ⊖d) ; C′[P/X] , i (I ⊖d) ; C′[Q/X] )
= ( (i (I ⊖d) ; C′)[P/X] , (i (I ⊖d) ; C′)[Q/X] ) ∈S,
as required.
Case 2d (a = v = i).
Proceeds as per Case 2b.
Case 3 (C = wait [t] C′).
But then, C[P/X] = wait [t] C′[P/X], from which there are three cases to
consider.
Case 3a (v = d ∈R+ ∧d ≤t).
But then, B′ = wait [t −d] C′[P/X]. In addition, it follows immediately that
C[Q/X] = wait [t] C′[Q/X]
d; D′ = wait [t −d] C′[Q/X]. Furthermore, it is
clear that
(B′, D′) = ( wait [t −d] C′[P/X] , wait [t −d] C′[Q/X] )
= ( (wait [t −d] C′)[P/X] , (wait [t −d] C′)[Q/X] ) ∈S,
as required.
Case 3b (v = (t + d) ∈R+).
But then, C′[P/X]
d; B′′ and B′ = B′′, which is by a shorter inference.
Therefore, we know that ∃D′, D′′ . C′[Q/X]
d; D′′ ≈t∗
r D′ ∧B′SD′. But
then, (wait [t] C′)[Q/X] = wait [t] C′[Q/X]
t+d
; D′′ ≈t∗
r
D′
∧B′SD′, as
required.
Case 3c (v = a ∈Act ∪{δ, i}).
But then, t = 0 and C′[P/X]
a
−→B′′ and B′ = B′′, which is by a shorter in-
ference. Therefore, we know that ∃D′, D′′ . C′[Q/X]
a
=⇒⇒D′′ ≈t D′ ∧B′SD′.
But then, (wait [0] C′)[Q/X] = wait [0] C′[Q/X]
a
=⇒⇒D′′ ≈t D′ ∧B′SD′, as
required.
Case 4 (C = C1 [] C2).
But then, C[P/X] = (C1 [] C2)[P/X] = C1[P/X] [] C2[P/X]. We have two
cases to consider.
Case 4.a (v = d ∈R+).
Thus, C1[P/X]
d; C′
1, C2[P/X]
d; C′
2 and B′ = C′
1 [] C′
2. However, these two
time transitions are by a shorter inference, thus, we know that

428
14 Appendix
∃D′
1, D′′
1, D′
2, D′′
2 .
C1[Q/X]
d; D′′
1 ≈t∗
r D′
1 ∧(C′
1, D′
1) ∈S ∧
C2[Q/X]
d; D′′
2 ≈t∗
r D′
2 ∧(C′
2, D′
2) ∈S.
But then,
C[Q/X] = C1[Q/X] [] C2[Q/X]
d; D′′ ≈t∗
r D′.
where D′′ = (D′′
1 [] D′′
2) and D′ = (D′
1 [] D′
2). But, we also know that, for
j ∈{1, 2}, (C′
j, D′
j) ∈S, therefore, ∃Hj . C′
j = Hj[P/X] ∧D′
j = Hj[Q/X].
It follows then that
(B′, D′) = ( C′
1 [] C′
2 , D′
1 [] D′
2 )
= ( H1[P/X] [] H2[P/X] , H1[Q/X] [] H2[Q/X] )
= ( (H1 [] H2)[P/X] , (H1 [] H2)[Q/X] ) ∈S
which is as required.
Case 4.b (v = a ∈Act ∪{δ, i}).
Without loss of generality, assume C1[P/X]
a
−→C′
1 and B′ = C′
1, which is by
a shorter inference, thus, ∃D′, D′′ . C1[Q/X]
a
=⇒⇒D′′ ≈t∗
r
D′ ∧(B′, D′) =
(C′
1, D′) ∈S. However, then we know that
C[Q/X] = (C1 [] C2)[Q/X] = C1[Q/X] [] C2[Q/X]
a
=⇒⇒D′′ ≈t∗
r D′
where (B′, D′) ∈S and the result follows.
Case 5 (C = C1 |[G]| C2).
Arguments used for timed transitions are similar to those given in Case 4a
and for discrete / action transitions are as per the untimed case (Theorem
14.2).
Case 6 (C = C′[H]).
Straightforward.
⃝

Index
δ (LOTOS successful termination), 40
i (LOTOS internal action), 27
ACT-ONE, 20
action, 19, 23
completed action
in Communicating Automata, 235,
236, 238
in Discrete Timed Automata, 378,
385
in Inﬁnite State Communicating
Automata, 252
in Timed Automata, 322, 330
in Timed Automata with Deadlines,
357
durational action, 263
eﬀect, 252, 385
half action
in Communicating Automata, 235,
236, 238
in Inﬁnite State communicating
automata, 252
in Timed Automata, 322
in Timed Automata with Deadlines,
357
hidden action, 27
in Discrete Timed Automata, 378,
384–385
in Inﬁnite State Communicating
Automata, 251
in LOTOS, 26–28
input action
in Discrete Timed Automata, 378,
385
in Inﬁnite State Communicating
Automata, 252, 254
instantaneous action, 263
internal action, 27, 43
and urgency, see urgent internal
actions
observable action, 26, 43
output action
in Discrete Timed Automata, 378,
385
in Inﬁnite State Communicating
Automata, 252, 254
precondition, 251, 385
time action, 378
and deadlines, 391
timed enabling, 262–267
initiation and termination of
enabling, 264
punctual enabling, 264
simple enabling, 263
timing operators, 266
value passing actions, 194–201
and internal behaviour, 198
and synchronisation, 197
action preﬁx
in LOTOS, 28
BES semantics, 116
LTS semantics, 80
trace semantics, 68
in tLOTOS
TBES semantics, 309
TTS semantics, 292
actionlock, 347, 349

430
Index
pure-actionlock, 349
behaviour (LOTOS), 25
BES, see Bundle Event Structures
bisimulation, 345
in Communicating Automata, 240
step strong bisimulation, 130
strong bisimulation, 12, 86
timed strong bisimulation, 300
timed weak bisimulation, 301
weak bisimulation, 90
bLOTOS, 20, 185–191
syntax, 191
branching time, 77
Bundle Event Structures, 108–134
and Labelled Transition Systems,
123–125
isomorphism of BES, 126
bundle relation (BES), 108
CA, see Communicating Automata
CADP, 102, 345
CCS, 19, 236
choice, 31, 41
deterministic choice, 33
external choice, 8, 33
generalised choice, 188, 203
guarded choice, 193
LTS semantics, 193
in LOTOS, 29
BES semantics, 117
LTS semantics, 80
trace semantics, 69
in tLOTOS
TBES semantics, 312
TTS semantics, 292
internal choice, 8
nondeterministic choice, 32, 42
clock, 321, 324
active clock reduction, 344
bounded from above, 361
bounded from below, 361
clock constraint, 322, 324
clock valuation, 324
maximal valuation, 368–374
smallest upper bound, 364
Communicating Automata, 234–250
and process calculi, 246–250
Communication Protocol (example), 20,
52, 207, 239, 252
computation, 381
concurrency, 30, 41
concurrency theory, 3, 19, 233
concurrent systems, 4–9, 19
in Discrete Timed Automata, 378
in Fair Transition Systems, 381
in LOTOS, 41–47
in Timed Automata, 322
true concurrency, 105, 304
conﬂict relation (BES), 108
conformance, 154
congruence, 59
CSP, 19
CTL (Computation Tree Logic),
241–246
DBM (Diﬀerence Bound Matrix),
340–341
deadline
and guards, 355–356
and invariants, 353–354, 356
and preconditions, 385
in Discrete Timed Automata, 378,
385, 387
in Timed Automata with Deadlines,
353, 355
deadlock, 25, 347, 349
delay
and timed action enabling, 265
in tLOTOS
TBES semantics, 310
TTS semantics, 292
development relations, 58
Dining Philosophers (example), 22, 210
disabling (LOTOS), 185
Discrete Timed Automata, 377–395
divergence, 38, 146, 149
DTA, see Discrete Timed Automata
E-LOTOS (Extended LOTOS),
213–214, 285
enabled event (BES), 109
enabling, 47
in LOTOS
BES semantics, 121
LTS semantics, 82
trace semantics, 69

Index
431
in tLOTOS
TBES semantics, 312
TTS semantics, 296
parameterised enabling, 204
enabling set (BES), 109
environment, 5, 22
equivalence, 11, 58
observational equivalence, 104
pomset equivalence, 130–132
proving sequence equivalence,
132–134
testing equivalence, 152
trace equivalence, 75
Event Structures, 10, 105–139
event trace (BES), 111
extension, 157
Fair Transition Systems, 381–383
and veriﬁcation of DTAs, 389
fairness
in Communicating Automata, 241
in Fair Transition Systems, 382
fLOTOS, 20, 192–213
syntax, 206
Flow Event Structures, 137
forward reachability, see reachability
analysis
forward reachability graph, 332,
337–339
FTS, see Fair Transition Systems
gate, 23
actual, 35
formal, 35
guard
in Timed Automata, 322, 324
in Timed Automata with Deadline,
355
hiding
in LOTOS, 27
and divergence, 40
and synchronisation, 47
BES semantics, 121
LTS semantics, 82
trace semantics, 71
in tLOTOS
TBES semantics, 310
TTS semantics, 294
HML (Hennessy–Milner Logic), 165
HyTech, 321
implementation relations, 58
inaction
in LOTOS
BES semantics, 116
LTS semantics, 79
trace semantics, 68
in tLOTOS
TBES semantics, 309
TTS semantics, 291
Inﬁnite State Communicating Au-
tomata, 250–256
interface (LOTOS), 23
interleaving
in LOTOS, 41
in Timed Automata, 322
invariance, 382
invariance proofs, 389, 391
invariant
auxiliary invariant, 383, 391
in Fair Transition Systems, 382
in Timed Automata, 322, 324, 331
inductive invariant, 382
strong-invariant interpretation, 331
weak-invariant interpretation, 331
ISCA, see Inﬁnite State Communicating
Automata
Kripke Structures, 242
Kronos, 321, 339, 376
Labelled Transition Systems, 78
linear time, 77
liveness
hypothesis
in Communicating Automata, 240
in Timed Automata, 328
property
in Communicating Automata, 245
in Timed Automata, 333
local deﬁnitions (LOTOS), 202
location
in Communicating Automata, 234
in Timed Automata, 324
in Timed Automata with Deadlines,
355
loop

432
Index
and zeno-timelocks, 361–376
completed loop, 359
half loop, 359
inherently safe loop, 348, 363–367
non-simple loop
and zeno-timelocks, 373–374
nonsimple loop, 359
simple loop, 359
LOTOS, 19–54, 238
and behavioural subtyping, 167–177
extension and subtyping, 170
reduction and subtyping, 170
trace preorder and subtyping, 169
undeﬁnedness, 171–177
and CCS, 217–222
internal behaviour, 221
observational congruence, 221
parallel composition, 217
retriction and hiding, 220
and CSP, 222–232
alphabets, 222
choice, 225–227
development relations and congru-
ence, 230
divergence, 228
hiding and concealment, 227
internal actions, 224
parallel composition, 227
and object-oriented concepts, 166–167
and viewpoint consistency, 177–180
sequential strong bisimulation, 127
speciﬁcation, 190
LTL (Linear Temporal Logic), 382
LTS
seeLabelled Transition Systems, 78
model-checking
CTL mode checking, 246
real-time model-checking, 332–345,
347
trace generation, 340
MONA, 378, 383–384, 392
Multimedia Stream (example), 281,
324, 341, 358, 359, 386
network
of Communicating Automata, 237
of Discrete Timed Automata, 385–386
of Inﬁnite State Communicating
Automata, 253
of Timed Automata, 322, 330, 333
nondeterminism
and maximal progress, 271
and time, 271–272
in LOTOS, 30–34, 43
and internal actions, 27
nonzenoness, see zeno-timelock
observer, 22, 23, 27, 32, 141, 165
on-the-ﬂy (veriﬁcation), 332
over-approximation, 343
parallel composition
and timing of nonadjacent actions,
274
in Communicating Automata,
236–239
in Discrete Timed Automata, 387–389
in Inﬁnite State Communicating
Automata, 252–254
in LOTOS, 41–47
BES semantics, 118
generalised parallelism, 189
LTS semantics, 81
trace semantics, 69
in Timed Automata, 322, 328–329
in Timed Automata with Deadlines,
356
in tLOTOS
TBES semantics, 313
TTS semantics, 293
pbLOTOS, 20
syntax, 50
persistency, 270–271
and strong timing policy, 270
and weak timing policy, 271
in tLOTOS, 299
preorder, 11, 58
trace preorder, 73
Prime Event Structures, 134
process calculi, 19
process instantiation
in LOTOS, 34–40
BES semantics, 122
LTS semantics, 83
trace semantics, 71
in tLOTOS

Index
433
TBES semantics, 316
TTS semantics, 296
product automaton
in Communicating Automata, 237
in Discrete Timed Automata, 387,
391
in Inﬁnite State Communicating
Automata, 253
in Timed Automata, 322, 330, 333,
340
in Timed Automata with Deadlines,
357
proving sequence, 111
reachability
algorithm, 334, 339–340
analysis, 333
graph, see forward reachability graph
property
in Communicating Automata, 245
in Timed Automata, 333
recursion
in LOTOS, 35
reduction, 156
reﬁnement, see preorder
region graph, 332
relabelling, 40
in LOTOS
BES semantics, 121
LTS semantics, 82
trace semantics, 71
in tLOTOS
TBES semantics, 310
TTS semantics, 293
reset set
in Timed Automata, 322, 324
in Timed Automata with Deadlines,
355
RSL (Ready Simulation Logic), 163
run
convergent, 328, 349, 368
divergent, 328, 364
in Timed Automata, 326, 328
zeno, 328, 350
safety, 379
in Communicating Automata, 245
in Discrete Timed Automata, 389–394
in Fair Transition Systems, 382
in Timed Automata, 333
selection predicates (LOTOS), 202
semantics, 55
and recursion, 61
BES semantics, 115–134
in Communicating Automata, 240
in Communicating Automata,
240–241
in Discrete Timed Automata, 387–389
in Inﬁnite State Communicating
Automata, 254–256
in Timed Automata, 322, 325–332
in Timed Automata with Deadlines,
356
in tLOTOS, 287–320
LTS semantics, 10
in Communicating Automata, 240
in Discrete Timed Automata, 387
in LOTOS, 76–101
operational semantics, see LTS
semantics
semantic map, 57
semantic notation, 57
TBES semantics for tLOTOS,
308–318
trace semantics, 10, 63–76
in Communicating Automata, 240
trace-refusals semantics, 10, 141–161
and bisimulations, 142
and internal behaviour, 146–151
and testing, 160–161
failures, 143
from Labelled Transition Systems,
145
in Communicating Automata, 240
refusals, 143
traces from Labelled Transition
Systems, 84
TTS semantics
in Timed Automata, 330
in Timed Automata with Deadlines,
356
TTS semantics for tLOTOS, 289–299
sequential composition, see enabling
simulation, 96
ready simulation, 98
ready simulation testing, 163
SNZ, see strong nonzenoness
solution set, 334

434
Index
Stable Event Structures, 136
state
concrete state, 332
in Communicating Automata,
233–234, 241–246
in Discrete Timed Automata, 378
in Fair Transition Systems, 381
in Inﬁnite State Communicating
Automata, 250, 254–256
and eﬀects, 252
and preconditions, 251, 254
in LOTOS, 38
in Timed Automata, 325, 330, 332
in Timed Automata with Deadlines,
356
state-based and action-based
formalisms, 249–250
successors, 334, 338
symbolic state, 332, 334
strong nonzenoness, 348, 361–363
and completed loops, 362–363
and half loops, 362–363
symmetry reduction, 344
synchronisation, 4–5, 43
and initiation and termination of
enabling, 272
and punctual enabling, 272
and simple enabling, 272
and strong nonzenoness, 362–363
and time, 272–273
and time-actionlocks, 352–353
bi-party synchronisation, see binary
synchronisation
binary synchronisation, 321
in Communicating Automata, 236,
252
in Discrete Timed Automata, 378,
389
in Inﬁnite State Communicating
Automata, 252, 254
in LOTOS, 46–47
in Timed Automata, 322
in Timed Automata with Deadlines,
353–354, 357
multi-party synchronisation, see
multiway synchronisation
multiway synchronisation, 46
TAD, see Timed Automata with
Deadlines
TBES, see Timed Bundle Event
Structures
TCTL (Timed Computation Tree
Logic), 332
temporal logic, 19
in Communicating Automata,
241–246
in Timed Automata, 332
termination
in LOTOS, 47
BES semantics, 116
LTS semantics, 79
trace semantics, 68
in tLOTOS
TBES semantics, 309
TTS semantics, 291
test automata, 345
testing theory, 141, 161–166
and bisimulations, 165
sequence-based testing, 162
tree-based testing, 163–166
time
global time, 263
and timing of nonadjacent actions,
275
quantitative time, 261, 262, 276
relative time, 263
time continuity in tLOTOS, 297
time determinism in tLOTOS, 298
time measurement, 273
timed interaction policies, 275
timing domains, 273
timing of nonadjacent actions, 274
time measurement
and timing of nonadjacent actions,
275
time reactiveness, 348, 385
time-actionlock, 347, 350, 352–358
in Discrete Timed Automata, 387
Timed Automata, 321–345
Timed Automata with Deadlines, 348,
353–358, 385
Timed Bundle Event Structures,
305–307
Timed Communicating Automata, see
Timed Automata
Timed Process Calculi, 261–278

Index
435
timed proving sequence, 307
Timed Transition Systems, 287
timelock
and real-time model-checking,
374–376
and TCTL, 374–376
and test automata, 374–375
in Timed Automata, 322, 347–376
in timed process calculi, 351
in tLOTOS
and Timed Bundle Event Struc-
tures, 318–320
and Timed Transition Systems,
283–285
tLOTOS, 278–285
syntax, 279
transition
action transition, 326
and timelocks, 349–352
compassionate transition, 382
escape transition, 366, 369
idling transition, 381
in Communicating Automata, 234
in Timed Automata, 324
in Timed Automata with Deadlines,
355
just transition, 382
nonidle transition, 381
time transition, 326
transition formula, 381, 391
TTS, see Timed Transition Systems
under-approximation, 343
Uppaal, 321, 339, 374
urgency
and time-actionlocks, 352–353
ASAP (As Soon As Possible), 269
in Discrete Timed Automata, 379,
387
in Timed Automata, 322
in Timed Automata with Deadlines,
353–354, 357
in timed process calculi, 267–269
in untimed process calculi, 267
Maximal Progress, 269, 276
and interactions, 277
and internal actions, 277
Minimal Delay, 269
on upper bounds, 276
and internal actions, 277
urgency operator, 268
urgent actions, 268
urgent internal actions, 269, 276–278
variable
in Discrete Timed Automata, 255,
378, 384–385
in Fair Transition Systems, 381
in Inﬁnite State Communicating
Automata, 251
primed variable, 381
time variable, 378
WS1S (Weak Monadic Second Order
Theory of 1 Successor), 383–384
WS1S (Weak Monadic Second-order
Theory of 1 Successor), 378
zeno-timelock, 347, 350, 359–376
and completed actions, 368
and networks of TAs, 368
and reachability analysis, 348,
369–374
local zeno-timelock, 368–369
suﬃcient-and-necessary conditions,
348, 368–374
suﬃcient-only conditions, 348
syntactic conditions, 361–367
and compositionality, 366–367
zone, 334
canonical, 342
conjunction, 334
forward projection, 335
minimal representation, 343
normalisation, 335, 338, 343
reset, 335

