
Generalized Barycentric Coordinates 
in Computer Graphics 
and Computational Mechanics


Generalized Barycentric Coordinates 
in Computer Graphics 
and Computational Mechanics
edited by
Kai Hormann 
N. Sukumar

CRC Press
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
© 2018 by Taylor & Francis Group, LLC
CRC Press is an imprint of Taylor & Francis Group, an Informa business
No claim to original U.S. Government works
Printed on acid-free paper
Version Date: 20170918
International Standard Book Number-13:  978-1-4987-6359-2 (Hardback)
This book contains information obtained from authentic and highly regarded sources. Reasonable efforts have been made to publish 
reliable data and information, but the author and publisher cannot assume responsibility for the validity of all materials or the 
consequences of their use. The authors and publishers have attempted to trace the copyright holders of all material reproduced in 
this publication and apologize to copyright holders if permission to publish in this form has not been obtained. If any copyright 
material has not been acknowledged please write and let us know so we may rectify in any future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, transmitted, or utilized in any 
form by any electronic, mechanical, or other means, now known or hereafter invented, including photocopying, microfilming, and 
recording, or in any information storage or retrieval system, without written permission from the publishers.
For permission to photocopy or use material electronically from this work, please access www.copyright.com (http://www.
copyright.com/) or contact the Copyright Clearance Center, Inc. (CCC), 222 Rosewood Drive, Danvers, MA 01923, 978-750-8400. 
CCC is a not-for-profit organization that provides licenses and registration for a variety of users. For organizations that have been 
granted a photocopy license by the CCC, a separate system of payment has been arranged.
Trademark Notice: Product or corporate names may be trademarks or registered trademarks, and are used only for identifica-
tion and explanation without intent to infringe.
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the CRC Press Web site at
http://www.crcpress.com
Library of Congress Cataloging-in-Publication Data
Names: Hormann, Kai, editor. | Sukumar, N., editor.
Title: Generalized barycentric coordinates in computer graphics and computational mechanics / edited by
   Kai Hormann and N. Sukumar.
Description: Boca Raton : Taylor & Francis, CRC Press, 2017.
Identifiers: LCCN 2016056577 | ISBN 9781498763592 (hardback : alk. paper).
Subjects: LCSH: Barycentric coordinates. | Mechanics. | Computer graphics--Mathematics. | Center of mass.
Classification: LCC QA556 .G284 2017 | DDC 516/.16--dc23
LC record available at https://lccn.loc.gov/2016056577

Contents
Preface
xv
Contributors
xix
Section I
Theoretical Foundations
1
Chapter
1 ■Barycentric Coordinates and Their Properties
3
Dmitry Anisimov
1.1
INTRODUCTION
4
1.1.1
Barycentric coordinates for simplices
5
1.1.2
Generalized barycentric coordinates
5
1.2
2D COORDINATES
6
1.2.1
Wachspress coordinates
7
1.2.2
Discrete harmonic coordinates
8
1.2.3
Mean value coordinates
8
1.2.4
Complete family of coordinates
9
1.2.5
Metric coordinates
9
1.2.6
Poisson coordinates
10
1.2.7
Gordon–Wixom coordinates
10
1.2.8
Harmonic coordinates
11
1.2.9
Maximum entropy coordinates
11
1.2.10 Local coordinates
12
1.2.11 Aﬃne coordinates
12
1.2.12 Sibson coordinates
12
1.2.13 Laplace coordinates
13
1.2.14 Hermite coordinates
13
1.2.15 Complex coordinates
14
v

vi
■Contents
1.2.16 Comparison
14
1.3
3D COORDINATES
20
1.3.1
Wachspress coordinates
20
1.3.2
Discrete harmonic coordinates
21
1.3.3
Mean value coordinates
21
1.3.4
Complete family of coordinates
22
1.3.5
Other coordinates
22
Chapter
2 ■Shape Quality for Generalized Barycentric
Interpolation
23
Andrew Gillette and Alexander Rand
2.1
INTRODUCTION
24
2.2
DECONSTRUCTING THE A PRIORI ERROR ESTIMATE
26
2.3
SHAPE QUALITY METRICS FOR SIMPLICES
29
2.4
SHAPE QUALITY METRICS FOR POLYGONS
AND POLYHEDRA
31
2.5
INTERPOLATION ERROR ESTIMATES ON POLYGONS
34
2.5.1
Triangulation coordinates
34
2.5.2
Harmonic coordinates
35
2.5.3
Wachspress coordinates
37
2.5.4
Mean value coordinates
39
2.6
INTERPOLATION ERROR ESTIMATES ON POLYHEDRA AND
POLYTOPES
39
2.6.1
Harmonic coordinates in 3D and higher
40
2.6.2
Wachspress coordinates in 3D and higher
40
2.7
EXTENSIONS AND FUTURE DIRECTIONS
41
Chapter
3 ■Transﬁnite Barycentric Coordinates
43
Alexander G. Belyaev and Pierre-Alain Fayolle
3.1
INTRODUCTION
44
3.2
WEIGHTED MEAN VALUE INTERPOLATION
45
3.2.1
General construction
45
3.2.2
Transﬁnite three-point coordinates
47
3.2.3
Transﬁnite Laplace coordinates
48

Contents
■vii
3.2.4
Transﬁnite Wachspress coordinates
49
3.2.5
Transﬁnite Laplace and Wachspress coordinates
coincide for a disk
51
3.3
GORDON–WIXOM INTERPOLATION
51
3.3.1
Lagrange-type Gordon–Wixom interpolation
51
3.3.2
Hermite-type Gordon–Wixom interpolation
54
3.3.3
Modiﬁed Hermite-type Gordon–Wixom interpolation
55
3.3.4
Modiﬁed Gordon–Wixom for polyharmonic
interpolation
56
3.4
GENERALIZED MEAN VALUE POTENTIALS AND DISTANCE
FUNCTION APPROXIMATIONS
57
3.4.1
Generalized mean value potentials for smooth domains
57
3.4.2
Generalized potentials for polygons
61
Chapter
4 ■Barycentric Mappings
63
Teseo Schneider
4.1
INTRODUCTION
64
4.1.1
Convex polygons
64
4.1.2
Arbitrary polygons
65
4.2
BIJECTIVE BARYCENTRIC MAPPING
66
4.2.1
Perturbed target polygons
66
4.3
BIJECTIVE COMPOSITE BARYCENTRIC MAPPING
68
4.3.1
Limit of composite barycentric mappings
70
4.4
EXTENSIONS
71
4.4.1
Closed planar curves
71
4.4.2
Polyhedra
73
4.5
PRACTICAL CONSIDERATIONS
75
4.5.1
Choosing the coordinates
75
4.5.2
Choosing the vertex paths
75
Chapter
5 ■A Primer on Laplacians
77
Max Wardetzky
5.1
INTRODUCTION
77
5.1.1
Basic properties
78

viii
■Contents
5.2
LAPLACIANS ON RIEMANNIAN MANIFOLDS
79
5.2.1
Exterior calculus
79
5.2.2
Hodge decomposition
81
5.2.3
The spectrum
82
5.3
DISCRETE LAPLACIANS
83
5.3.1
Laplacians on graphs
83
5.3.2
The spectrum
84
5.3.3
Laplacians on simplicial manifolds
86
5.3.4
Strongly and weakly deﬁned Laplacians
87
5.3.5
Hodge decomposition
88
5.3.6
The cotan Laplacian and beyond
88
5.3.7
Discrete versus smooth Laplacians
90
Section II Applications in Computer Graphics
95
Chapter
6 ■Mesh Parameterization
97
Bruno L´evy
6.1
INTRODUCTION
97
6.2
APPLICATIONS OF MESH PARAMETERIZATION
98
6.3
NOTIONS OF TOPOLOGY
100
6.4
TUTTE’S BARYCENTRIC MAPPING THEOREM
102
6.5
SOLVING THE LINEAR SYSTEMS
106
6.6
CHOOSING THE WEIGHTS
108
Chapter
7 ■Planar Shape Deformation
109
Ofir Weber
7.1
INTRODUCTION
110
7.2
COMPLEX BARYCENTRIC COORDINATES
111
7.2.1
Holomorphic functions
113
7.2.2
General construction of complex barycentric
coordinates
118
7.2.3
Magic coordinates
121
7.3
VARIATIONAL BARYCENTRIC COORDINATES
123
7.3.1
Point-based barycentric maps
123

Contents
■ix
7.3.2
Point-to-point barycentric coordinates
124
7.4
CONFORMAL MAPS
127
7.4.1
Log derivative construction
127
7.4.2
Shape interpolation
130
7.4.3
Variational conformal maps
131
7.5
IMPLEMENTATION DETAILS
132
7.5.1
Visualizing planar maps
132
Chapter
8 ■Multi-Sided Patches via Barycentric Coordinates
135
Scott Schaefer
8.1
INTRODUCTION
136
8.1.1
Bézier form of curves
136
8.1.2
Evaluation
137
8.1.3
Degree elevation
137
8.2
MULTISIDED BÉZIER PATCHES IN HIGHER DIMENSIONS
138
8.2.1
Indexing for S-patches
139
8.2.2
Evaluation
141
8.2.3
Degree elevation
142
8.3
APPLICATIONS
143
8.3.1
Surface patches
143
8.3.2
Spatial deformation
144
Chapter
9 ■Generalized Triangulations
147
Pooran Memari
9.1
INTRODUCTION
147
9.2
GENERALIZED PRIMAL-DUAL TRIANGULATIONS
148
9.2.1
Some classical examples
149
9.2.2
Primal-dual triangulations (PDT)
150
9.3
A CHARACTERIZATION THEOREM
151
9.3.1
Combinatorially regular triangulations (CRT)
151
9.3.2
Equivalence between PDT and CRT
152
9.3.3
Parametrization of primal-dual triangulations
152
9.4
DISCRETE REPRESENTATION USING GENERALIZED
TRIANGULATIONS
153

x
■Contents
9.4.1
Discrete exterior calculus framework
153
9.4.2
Applications in mesh optimization
154
Chapter 10 ■Self-Supporting Surfaces
157
Etienne Vouga
10.1 INTRODUCTION AND HISTORICAL OVERVIEW
158
10.1.1 What is a masonry structure?
158
10.1.2 Heyman’s safe theorem
159
10.1.3 Gaudí and hanging nets
160
10.1.4 Maxwell’s reciprocal diagrams
161
10.2 SMOOTH THEORY
162
10.2.1 Equilibrium equations
163
10.2.2 Airy stress potential
164
10.2.3 Relative curvatures
164
10.2.4 Curvature interpretation of equilibrium
165
10.3 DISCRETE THEORY
166
10.3.1 Thrust network analysis
166
10.3.2 Thrust networks as block networks
167
10.3.3 Discrete Airy stress potential
167
10.3.4 FEM discretization of Airy stress
169
10.3.5 Discrete curvature interpretation of equilibrium
169
10.4 OPTIMIZING FOR STABILITY
170
10.4.1 Alternating optimization
170
10.4.2 Dual formulation as vertex weights
172
10.4.3 Perfect Laplacian optimization
172
10.4.4 Relative-curvature-based smoothing
173
10.4.5 Steel-glass structures and PQ faces
174
10.4.6 Block layouts from stable surfaces
175
10.5 CONCLUSION AND OPEN PROBLEMS
175
10.5.1 Sensitivity analysis of masonry structures
176
10.5.2 Progressive stable structures
176

Contents
■xi
Section III Applications in Computational Mechanics
177
Chapter 11 ■Applications of Polyhedral Finite Elements in Solid
Mechanics
179
Joseph E. Bishop
11.1 INTRODUCTION
180
11.2 GOVERNING EQUATIONS OF SOLID MECHANICS
183
11.3 POLYHEDRAL FINITE ELEMENT FORMULATION
184
11.3.1 Weak form of governing equations
185
11.3.2 Shape functions
185
11.3.3 Element integration
186
11.4 RAPID ENGINEERING ANALYSIS
187
11.5 FRAGMENTATION MODELING
191
11.5.1 Fracture methodology
192
11.5.2 Random Voronoi meshes
193
11.5.3 Fragmentation
194
11.6 SUMMARY AND OUTLOOK
195
Chapter 12 ■Extremely Large Deformation with Polygonal and
Polyhedral Elements
197
Glaucio H. Paulino, Heng Chi, Cameron Talischi, and Oscar Lopez-Pamies
12.1 INTRODUCTION
198
12.2 FINITE ELASTICITY FORMULATIONS
200
12.2.1 Displacement-based formulation
201
12.2.2 A general two-ﬁeld mixed variational formulation
201
12.3 POLYGONAL AND POLYHEDRAL APPROXIMATIONS
203
12.3.1 Displacement space on polygons in 2D
203
12.3.2 Displacement space on polyhedra in 3D
204
12.3.3 Pressure space on polygons in 2D
204
12.4 QUADRATURE RULES AND ACCURACY REQUIREMENTS
205
12.5 GRADIENT CORRECTION SCHEME AND ITS PROPERTIES
208
12.5.1 Gradient correction for scalar problems
208
12.5.2 Gradient correction for vectorial problems
212
12.6 CONFORMING GALERKIN APPROXIMATIONS
213

xii
■Contents
12.7 NUMERICAL EXAMPLES
214
12.7.1 Displacement-based polygonal and polyhedral elements 214
12.7.2 Two-ﬁeld mixed polygonal elements
217
12.8 APPLICATION TO THE STUDY OF FILLED ELASTOMERS
221
12.8.1 Results for ﬁlled neo-Hookean elastomers
222
12.8.2 Results for a ﬁlled silicone elastomer
223
Chapter 13 ■Maximum-Entropy Meshfree Coordinates in
Computational Mechanics
229
Marino Arroyo
13.1 INTRODUCTION
230
13.2 SELECTING BARYCENTRIC COORDINATES THROUGH
ENTROPY MAXIMIZATION
231
13.3 INTRODUCING LOCALITY: LOCAL MAXIMUM-ENTROPY
APPROXIMANTS
234
13.4 FURTHER EXTENSIONS
238
13.5 APPLICATIONS
240
13.5.1 High-order partial diﬀerential equations
240
13.5.2 Manifold approximation
241
13.6 OUTLOOK
243
Chapter 14 ■BEM-Based FEM
245
Steffen Wei er
14.1 INTRODUCTION
246
14.2 HIGH-ORDER BEM-BASED FEM IN 2D
247
14.2.1 Construction of basis functions
248
14.2.2 Finite element method
249
14.2.3 Introduction to boundary element methods
250
14.2.4 Numerical examples
252
14.3 ADAPTIVE BEM-BASED FEM IN 2D
253
14.3.1 Adaptive FEM strategy
254
14.3.2 Residual-based error estimate for polygonal meshes
255
14.3.3 Numerical examples
256
14.4 DEVELOPMENTS AND OUTLOOK
258
ß

Contents
■xiii
14.4.1 Hierarchical construction for 3D problems
259
14.4.2 Convection-adapted basis functions in 3D
261
Chapter 15 ■Virtual Element Methods for Elliptic Problems
on Polygonal Meshes
263
Andrea Cangiani, Oliver J. Sutton Vitaliy Gyrya, and Gianmarco Manzini
15.1 INTRODUCTION
264
15.2 VIRTUAL ELEMENT SPACES AND GBC
265
15.2.1 Generalities
265
15.2.2 Lowest order discrete space
265
15.2.3 Generalization to arbitrary order discrete spaces
266
15.2.4 The natural basis
267
15.2.5 A convenient basis
269
15.2.6 A link between the bases
271
15.2.7 Extension to three dimensions
273
15.3 VIRTUAL ELEMENT METHOD FOR ELLIPTIC PDES
273
15.3.1 Model problem
273
15.3.2 Overview of the conforming VEM
274
15.4 CONNECTION WITH OTHER METHODS
276
15.4.1 Polygonal and polyhedral ﬁnite element method
276
15.4.2 Nodal MFD method
276
15.4.3 BEM-based FEM
278
Bibliography
281
Index
309
,


Preface
Interpolating given discrete data with continuous functions in one or more variables
is a fundamental problem in diverse ﬁelds of sciences and engineering. Barycentric
coordinates, which were introduced by Möbius [282] in 1827, still provide perhaps
the most convenient way to linearly interpolate data prescribed at the vertices of a
d-dimensional simplex. Barycentric interpolation is widely used in computer graph-
ics, whereas such interpolating (basis) functions are also adopted as trial and test
approximations in ﬁnite element and boundary element methods. Starting with
the seminal work published by Wachspress [407] in 1975,∗the ideas of barycen-
tric coordinates and barycentric interpolation have been extended in recent years
to arbitrary polygons in the plane and general polytopes in higher dimensions,
which in turn has led to novel solutions in applications like mesh parametrization,
image warping, mesh deformation, and ﬁnite element and boundary element meth-
ods. This book summarizes the latest developments and applications of generalized
barycentric coordinates in computer graphics and computational mechanics.
The advent of mean value coordinates [144] in 2003 was a turning point in the
sustained interest and further development of generalized barycentric coordinates.
This construction generated renewed attention to Wachspress coordinates, and led
to many new pathways in geometry (polygonal mesh) processing and polygonal
ﬁnite element computations. Realizing this trend, we co-organized (together with
Gautam Dasgupta and Eitan Grinspun) a workshop in 2012 that was supported
by the U.S. National Science Foundation, on Barycentric Coordinates in Geometry
Processing and Finite/Boundary Element Methods, which was held at Columbia
University in New York. There was broad participation at the workshop from both
communities to foster synergy between the two ﬁelds. This book is envisioned as the
second step in the partnership of researchers from computer graphics and computa-
tional mechanics. We are hopeful that the contents of this book will be beneﬁcial to
both the uninitiated undergraduate or graduate student as well as the experienced
researcher who is well-versed in generalized barycentric coordinates.
This book is divided into three sections: Section I (Chapters 1–5) is on the the-
oretical foundations of generalized barycentric coordinates; and Sections II (Chap-
ters 6–10) and III (Chapters 11–15) are on its applications in computer graphics
and computational mechanics, respectively. There exist many distinct construc-
tions for generalized barycentric coordinates; an overview with comparisons and
contrasts of known generalized barycentric coordinates is presented in Chapter 1.
∗A revised and extended version of this book [406] was published in 2016.
xv

xvi
■Preface
The mathematical theory of simplicial ﬁnite elements is well-established; however,
for polygons in 2D and polyhedra in 3D, the relationship between the shape of the
polytope and the interpolation properties on them are not yet fully understood.
Theoretical interpolation estimates for these coordinates, with supportive numeri-
cal experiments, are presented in Chapter 2. Besides interpolation within polygonal
domains, realizing continuous linearly precise interpolants over smooth domains—
with so-called transﬁnite barycentric coordinates (Chapter 3)—is also of broad in-
terest. In many computer graphics applications, bijective mappings between simple
polytopes are needed, and one route to achieve this is through composite bijective
mappings, which are discussed in Chapter 4. The smooth and discrete Laplacian on
manifolds has a rich history in mathematical theory and numerical computations.
The preservation of the properties of the continuous operator on discrete grids is
desirable, which forms the foundation for many numerical discretizations that are
based on discrete exterior calculus and mimetic schemes. A primer on the Laplacian
is provided in Chapter 5.
Applications of generalized barycentric coordinates in computer graphics and
geometry processing are covered in Section II. One of the fundamental concepts
in computer graphics for enhancing the visual quality of a rendered triangle mesh
is texture mapping. This requires us to ﬁrst compute a suitable mesh parameter-
ization of the 3D mesh over a 2D domain, which can be done eﬃciently using
generalized barycentric coordinates (Chapter 6). Complex barycentric coordinates
naturally arise from the identiﬁcation of R2 with the complex plane C and provide
a convenient framework for deforming planar shapes and images intuitively by en-
closing the region of interest with a polygonal cage and moving the cage vertices
(Chapter 7). An alternative approach to shape deformation is given by S-patches
(Chapter 8), which generalize the idea of parametric Bézier surfaces from triangular
and quadrilateral to arbitrary polygonal domains and can be extended to arbitrary
dimensions. Generalized barycentric coordinates further play a key role in the repre-
sentation of primal-dual triangulations, with applications in mesh optimization and
ﬁnite element methods (Chapter 9), and in the computational design and analysis
of self-supporting masonry structures (Chapter 10).
New and emerging polyhedral formulations and their applications to second-
and fourth-order elliptic partial diﬀerential equations (PDEs) are emphasized in
Section III. In solid mechanics, use of polyhedral ﬁnite element formulations is ap-
pealing for pervasive fracture and fragmentation simulations (Chapter 11) and to re-
alize extremely large deformations in numerical simulations (Chapter 12). For such
applications, simulations on polyhedral meshes can outperform existing tetrahedral
ﬁnite element simulation capabilities. For scattered sets of points in Rd, there exist
meshfree generalized barycentric coordinates known as maximum-entropy coordi-
nates. The essentials on their construction with applications in solid mechanics and
biomechanical simulations are presented in Chapter 13. In recent years, new com-
putational methods on polygonal and polyhedral meshes have been developed that
do not require the explicit computation of the basis functions in the interior of the
polytope: among these, a boundary element method that uses PDE-aware (Treﬀtz-
based) basis functions (Chapter 14) and the virtual element method (Chapter 15),

Preface
■xvii
which provides a variational foundation for mimetic ﬁnite-diﬀerence schemes, are
prominent.
A few words on the notation adopted in this book. To ensure uniformity and to
facilitate understanding, we use common notation for the most frequently used con-
cepts related to generalized barycentric coordinates that appear in computer graph-
ics and computational mechanics. Throughout the book, Ωis a general bounded
domain in Rd, with ∂Ωits boundary and ¯Ωits closure. When Ωis speciﬁcally a
bounded polytope in Rd, we use P for the open set, and the vertices of P are
v1, . . . , vn. A generic point in ¯P is denoted by x, and the i-th generalized barycen-
tric coordinate is φi : ¯P →R. In general, we follow the convention of using bold-
face for vector quantities, to distinguish them from scalar quantities; for example,
x = (x1, . . . , xd) ∈Rd.
Our thanks go to Rick Adams at CRC Press for initiating this book project
and to Jessica Vega and Marcus Fontaine at CRC Press for their assistance during
various stages of the publishing process. Most importantly, we are very grateful to
all contributors, for their time and eﬀort in preparing the chapters with diligence
and in a timely manner. Their contributions have shaped this book.
Kai Hormann
Lugano, Switzerland
N. Sukumar
Davis, CA, USA


Contributors
Dmitry Anisimov
Università della Svizzera italiana
Lugano, Switzerland
Marino Arroyo
Universitat Politècnica de Catalunya
Barcelona, Spain
Alexander G. Belyaev
Heriot-Watt University
Edinburgh, UK
Joseph E. Bishop
Sandia National Laboratories
Albuquerque, USA
Andrea Cangiani
University of Leicester
Leicester, UK
Heng Chi
Georgia Institute of Technology
Atlanta, USA
Pierre-Alain Fayolle
University of Aizu
Aizuwakamatsu, Japan
Vitaliy Gyrya
Los Alamos National Laboratory
Los Alamos, USA
Andrew Gillette
University of Arizona
Tucson, USA
Bruno Lévy
Inria Nancy Grand Est
Villers-lès-Nancy, France
Oscar Lopez-Pamies
University of Illinois
Urbana-Champaign, USA
Gianmarco Manzini
Los Alamos National Laboratory
Los Alamos, USA
Pooran Memari
LIX, CNRS, École Polytechnique,
Université Paris Saclay
Palaiseau, France
Glaucio H. Paulino
Georgia Institute of Technology
Atlanta, USA
Alexander Rand
CD-adapco
Austin, USA
Scott Schaefer
Texas A&M University
College Station, USA
Teseo Schneider
Università della Svizzera italiana
Lugano, Switzerland
Oliver J. Sutton
University of Leicester
Leicester, UK
Cameron Talischi
McKinsey & Company
Chicago, USA
Etienne Vouga
University of Texas
Austin, USA
xix

xx
■Contributors
Max Wardetzky
Georg-August-University
Göttingen, Germany
Oﬁr Weber
Bar-Ilan University
Ramat Gan, Israel
Steﬀen Weißer
Saarland University
Saarbrücken, Germany

I
Theoretical Foundations
1


C H A P T E R 1
Barycentric Coordinates
and Their Properties
Dmitry Anisimov
Università della Svizzera italiana, Lugano, Switzerland
CONTENTS
1.1
Introduction ......................................................
4
1.1.1
Barycentric coordinates for simplices ....................
5
1.1.2
Generalized barycentric coordinates .....................
5
1.2
2D coordinates ...................................................
6
1.2.1
Wachspress coordinates ..................................
7
1.2.2
Discrete harmonic coordinates ...........................
8
1.2.3
Mean value coordinates ..................................
8
1.2.4
Complete family of coordinates ..........................
9
1.2.5
Metric coordinates .......................................
9
1.2.6
Poisson coordinates ......................................
10
1.2.7
Gordon–Wixom coordinates .............................
10
1.2.8
Harmonic coordinates ....................................
11
1.2.9
Maximum entropy coordinates ...........................
11
1.2.10 Local coordinates ........................................
12
1.2.11 Aﬃne coordinates ........................................
12
1.2.12 Sibson coordinates .......................................
12
1.2.13 Laplace coordinates ......................................
13
1.2.14 Hermite coordinates ......................................
13
1.2.15 Complex coordinates .....................................
14
1.2.16 Comparison ..............................................
14
1.3
3D coordinates ...................................................
20
1.3.1
Wachspress coordinates ..................................
20
1.3.2
Discrete harmonic coordinates ...........................
21
1.3.3
Mean value coordinates ..................................
21
1.3.4
Complete family of coordinates ..........................
22
1.3.5
Other coordinates ........................................
22
3

4
■Generalized Barycentric Coordinates in Graphics and Mechanics
B
arycentric coordinates are commonly used in computer graphics and
computational mechanics to represent a point inside a simplex as an aﬃne
combination of the simplex’s vertices. We show how they can be generalized to
arbitrary polytopes and present the most known constructions of these generalized
barycentric coordinates in 2D and 3D.
1.1
INTRODUCTION
It was known since the days of the Peripatetic School and usually attributed to
Archimedes (c. 287 BC–c. 212 BC) [116] that a lever [v1, v2] with two weights w1
and w2 attached to its ends is balanced when a fulcrum is placed at the point
x ∈[v1, v2] such that
w1l1 = w2l2,
(1.1)
where l1 = x −v1 and l2 = v2 −x (see Figure 1.1). Equation (1.1) is called the law
of the lever and the point of balance x is called the center of mass of this lever or
its barycenter (from Ancient Greek βάρος = “weight” and κέντρον = “center”). The
weights w1 and w2 are often called homogeneous, because multiplying them with a
common non-zero scalar α does not change the equation. Rearranging terms, (1.1)
can be written in the form
w1(v1 −x) + w2(v2 −x) = 0
(1.2)
and further as
w1v1 + w2v2 = Wx,
W = w1 + w2.
Choosing the scalar α =
1
W , we can deﬁne the normalized weights φ1 = αw1 and
φ2 = αw2 and write the barycenter x as an aﬃne combination of the ends of the
lever with these weights,
φ1 + φ2 = 1,
(1.3)
φ1v1 + φ2v2 = x.
(1.4)
The normalized weights φ1 and φ2 are called the barycentric coordinates of the
point x with respect to the segment [v1, v2].
While the problem above is about ﬁnding the barycenter x for the given weights,
it is also interesting to study the opposite problem. Given the end points v1 and v2
Figure 1.1 Law of the lever.

Barycentric Coordinates and Their Properties
■5
of an arbitrary segment and some point x along this segment, how do we ﬁnd the
barycentric coordinates φ1 and φ2 of x with respect to this segment? It turns out
that they are uniquely determined by (1.3) and (1.4) as ratios of lengths,
φ1 = l2
l ,
φ2 = l1
l ,
where l = l1 + l2 = v2 −v1 is the length of the segment.
1.1.1
Barycentric coordinates for simplices
In 1827, the German mathematician August Ferdinand Möbius (1790–1868) [282]
considered the problem of ﬁnding barycentric coordinates with respect to an arbi-
trary d-simplex in d ∈N dimensions. For example, a 1-simplex is a line segment in
1D, a 2-simplex is a triangle in 2D, and a 3-simplex is a tetrahedron in 3D.
Given a non-degenerate d-simplex △with d + 1 vertices v1, . . . , vd+1 ∈Rd, we
search for d+1 functions φ = [φ1, . . . , φd+1]: △→Rd+1, which satisfy the partition
of unity property
d+1
X
i=1
φi(x) = 1
∀x ∈△
(1.5)
and the linear reproduction property
d+1
X
i=1
φi(x)vi = x
∀x ∈△.
(1.6)
The functions φ1, . . . , φd+1 are called barycentric coordinates with respect to △.
Analogously to the one-dimensional case in the previous section, it turns out
that these barycentric coordinates are uniquely determined by (1.5) and (1.6), and
Möbius shows that they are ratios of volumes,
φi(x) = Vi(x)
V
,
i = 1, . . . , d + 1,
(1.7)
where Vi(x) = Vol[v1, . . . , vi−1, x, vi+1, . . . , vd+1] are the volumes of the corre-
sponding d-simplices and V = V1(x) + · · · + Vd+1(x) = Vol[v1, . . . , vd+1] is the
volume of △and does not depend on x.
1.1.2
Generalized barycentric coordinates
To the best of our knowledge, Kalman [221] was the ﬁrst to propose a generalization
of barycentric coordinates to convex polyhedra, and in recent years there has been
a growing interest in the problem of ﬁnding barycentric coordinates with respect to
arbitrary polytopes. Throughout this book, we consider a non-degenerate polytope
P with n ≥d + 1 vertices v1, . . . , vn ∈Rd, which is viewed as an open set. We
denote the boundary of this polytope by ∂P and its closure by ¯P.

6
■Generalized Barycentric Coordinates in Graphics and Mechanics
Deﬁnition 1.1. Given the polytope P, the n functions φ = [φ1, . . . , φn]: ¯P →Rn
are called generalized barycentric coordinates if they satisfy the partition of unity
property
n
X
i=1
φi(x) = 1
∀x ∈¯P
(1.8)
and the linear reproduction property
n
X
i=1
φi(x)vi = x
∀x ∈¯P.
(1.9)
For n = d+1, the only functions that satisfy the properties in Deﬁnition 1.1 are
the φi in (1.7). For n > d + 1, however, the φi are no longer uniquely determined,
which is the reason for the existence of the diﬀerent constructions of generalized
barycentric coordinates that we review in the remainder of this chapter.
In addition to the deﬁning properties (1.8) and (1.9), it is often desirable for
the functions φi to have a few extra properties,
•
Non-negativity: φi(x) ≥0 for any x ∈¯P;
(1.10a)
•
Lagrange property: φi(vj) = δij, where δij is the Kronecker delta;
(1.10b)
•
Linearity on the boundary: φi is linear on each facet of P;
(1.10c)
•
Smoothness: φi ∈C∞.
(1.10d)
We remark that all these properties are satisﬁed in the case n = d+1 for the linear
functions φi in (1.7).
In general, there are two types of generalized barycentric coordinates. On the one
hand, there are coordinates with a closed form. Analogously to (1.2), the closed-form
deﬁnition is often based on certain weight functions w = [w1, . . . , wn]: P →Rn,
which satisfy
n
X
i=1
wi(x)(vi −x) = 0
∀x ∈P.
(1.11)
These weight functions are also called homogeneous coordinates, because normaliz-
ing them gives the generalized barycentric coordinates
φi(x) = wi(x)
W(x),
W(x) =
n
X
j=1
wj(x),
i = 1, . . . , n.
(1.12)
On the other hand, there are computational coordinates that can only be obtained
numerically, for example, by solving an optimization problem.
1.2
2D COORDINATES
We ﬁrst focus on the 2D case and consider a simple polygon P. Without loss of
generality, we assume the vertices vi of this polygon to be given in a counter-
clockwise direction and we treat the vertex indices cyclically, that is, vi+kn = vi

Barycentric Coordinates and Their Properties
■7
for i ∈{1, . . . , n} and k ∈Z. Note that all the coordinates in this section, except
for Hermite and complex, are generalized barycentric coordinates in the sense of
Deﬁnition 1.1.
The earliest generalizations of barycentric coordinates in 2D were closed-form
constructions and restricted to convex polygons. In this setting, the key objective is
ﬁnding smooth and positive weights wi, which satisfy (1.11). It is then known [149]
that the normalized weights φi in (1.12) are well-deﬁned generalized barycentric
coordinates with respect to P and satisfy all properties in (1.10). However, most
of these constructions lead to negative weights wi at certain points inside non-
convex polygons. Even worse, the denominator W may vanish, so that the φi are
not necessarily well-deﬁned for all x ∈P. So far, no closed-form construction of
positive weights for arbitrary non-convex polygons is known, and even if it exists,
the resulting coordinates would not be more than C0 at concave corners [10]. We
discuss diﬀerent closed-form coordinates in Sections 1.2.1–1.2.7.
It was later realized that φi can also be obtained numerically as the solution of
an optimization problem subject to the constraints given by the required properties
of the coordinates. This optimization problem can either be global or local, and we
present diﬀerent kinds of such computational coordinates in Sections 1.2.8–1.2.10.
If the points vi are not given as vertices of a polygon, but rather as scattered
points, Deﬁnition 1.1 and properties (1.10b) and (1.10d) still make sense. In this
setting, we can deﬁne generalized barycentric coordinates φi with respect to the
set Π = {v1, . . . , vn} ∈R2 of n ≥3 scattered points, and we review three diﬀerent
constructions in Sections 1.2.11–1.2.13.
We also give a short overview of coordinates that generalize Deﬁnition 1.1 in
some other way. In particular, we brieﬂy discuss Hermite and complex coordinates
in Sections 1.2.14 and 1.2.15.
1.2.1
Wachspress coordinates
Wachspress [407] was one of the ﬁrst who suggested a generalization of barycentric
coordinates to a polygon with n > 3 vertices. Later, Meyer et al. [275] propose
a simple local formulation of these Wachspress coordinates, which is given by the
normalization (1.12) of the weight functions
wi = cot γi−1 + cot βi
r2
i
,
i = 1, . . . , n,
where γi−1 and βi are the angles shown in Figure 1.2 and ri = ∥vi −x∥. These
coordinates are rational functions with numerator and denominator of degrees at
most n −2 and n −3, respectively, which are the minimal possible degrees [412].
For strictly convex polygons, it is clear that all wi(x) > 0 for any x ∈P, so
that Wachspress coordinates are well-deﬁned and satisfy all properties in (1.10).
They are also aﬃne invariant. For non-convex polygons, the coordinates are not
well-deﬁned at some points in the polygon’s interior, because the denominator W
vanishes, but they can be generalized to weakly convex polygons [264].

8
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 1.2 Notation used for signed angles, distances, and signed areas in a
polygon P.
1.2.2
Discrete harmonic coordinates
Discrete harmonic coordinates [136, 309] arise from the standard piecewise linear
ﬁnite element approximation to the Laplace equation and are given by the weight
functions
wi = cot βi−1 + cot γi,
i = 1, . . . , n,
where βi−1 and γi are the angles shown in Figure 1.2. Interestingly, it turns out
that for all polygons, whose vertices lie on a common circle, these coordinates are
identical to Wachspress coordinates and therefore possess the same properties [149].
For other strictly convex polygons, they are still well-deﬁned and satisfy all proper-
ties in (1.10), except for non-negativity. For non-convex polygons, the denominator
W of these coordinates vanishes at some points in the polygon’s interior, so that
they are not well-deﬁned.
1.2.3
Mean value coordinates
The derivation of discrete harmonic coordinates suggests that diﬀerent properties of
harmonic functions can be exploited to derive other generalized barycentric coordi-
nates. Floater [144] considers the circumferential mean value property of a harmonic
function u: P →R, which states that for any disc B = B(x, r) ⊂P of radius r > 0,
centered at x, with boundary ∂B,
u(x) =
1
2πr
ˆ
y∈∂B
u(y)dy.
(1.13)
He then shows that applying (1.13) to a piecewise linear function leads to mean
value coordinates. These coordinates are given by the weight functions
wi = tan(αi−1/2) + tan(αi/2)
ri
,
i = 1, . . . , n,
where αi−1 and αi are the angles shown in Figure 1.2 and ri = ∥vi −x∥.
Hormann and Floater [200] show that mean value coordinates are well-deﬁned
even for sets of nested simple polygons and everywhere in the plane. They are
positive inside the kernel of a star-shaped polygon and satisfy properties (1.10b)

Barycentric Coordinates and Their Properties
■9
and (1.10c). Moreover, mean value coordinates are positive inside any quadrilateral,
similarity invariant, and smooth, except at the vertices of P, where they are only C0.
To derive positive mean value coordinates for non-convex polygons, Lipman
et al. [251] use the transﬁnite description of mean value coordinates [217] and
restrict the integration to the part of ∂P that is visible from x. These coordinates
can be eﬃciently evaluated by exploiting the GPU, but they are only C0 along
certain lines inside the polygon.
1.2.4
Complete family of coordinates
Floater et al. [149] show that for arbitrary real functions ci : P →R, the weights
wi = ci−1Ai −ciBi + ci+1Ai−1
Ai−1Ai
,
i = 1, . . . , n,
(1.14)
with the signed areas Ai and Bi shown in Figure 1.2, satisfy property (1.11). There-
fore, the task of ﬁnding generalized barycentric coordinates simpliﬁes to ﬁnding
functions ci such that the weights in (1.14) are positive, or, if not, at least sum up to
a non-vanishing denominator W, without our having to worry about properties (1.8)
and (1.9), which are satisﬁed by construction, and the resulting coordinates are as
smooth as the functions ci. Moreover, any set of generalized barycentric coordinates
can be expressed in terms of the weights in (1.14) with the proper choice of ci.
An interesting special case of this complete family of coordinates is given by
ci = ∥vi −x∥p for any p ∈R. In this case, the choices p = 0, p = 1, and p = 2
give Wachspress, mean value, and discrete harmonic coordinates, respectively. Sur-
prisingly, the only coordinates for this choice of ci, which are non-negative for any
convex polygon, are Wachspress and mean value coordinates [149]. For any p, the
coordinates are similarity invariant, and a simple geometric interpretation can be
found in [232, Appendix A].
An alternative geometric construction for general weight functions wi, which
satisfy (1.8) and (1.9) and are non-negative by construction, is based on power
diagrams [78]. However, the resulting power coordinates are not necessarily smooth.
1.2.5
Metric coordinates
Malsch et al. [265, 375] construct the so-called metric coordinates, which are given
by the weight functions
wi =
Ai−2
Ci−1qi−2qi−1
−
Bi
Ciqi−1qi
+
Ai+1
Ci+1qiqi+1
,
i = 1, . . . , n,
where Ai, Bi, and Ci are the areas shown in Figure 1.2, and
qi = ri + ri+1 −ei
with ri = ∥vi −x∥and ei = ∥vi+1 −vi∥. The functions qi are non-negative ev-
erywhere in the plane, which guarantees a non-vanishing denominator W for all

10
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 1.3 Notation used for the Gordon–Wixom interpolant.
simple polygons [200]. Metric coordinates are not necessarily positive inside convex
polygons, satisfy properties (1.10b) and (1.10c), and they are smooth, except at the
vertices of P, where they are only C1. These coordinates are not well-deﬁned for
polygons with three consecutive collinear vertices.
1.2.6
Poisson coordinates
Taking inspiration from the derivation of mean value coordinates, Li et al. [247] de-
rive Poisson coordinates from the Poisson integral formula for a harmonic function
u: P →R, which states that for any disc B = B(r) ⊂P of radius r > 0, centered
at the origin, with boundary ∂B and any point x ∈B,
u(x) =
1
2πr
ˆ
y∈∂B
r2 −∥x∥2
∥x −y∥2 u(y)dy.
(1.15)
Poisson coordinates extend mean value coordinates, because the circumferential
mean value theorem (1.13) is a special case of (1.15) when x is at the center of B.
They are well-deﬁned for any simple polygon P and possess the same properties as
mean value coordinates. Moreover, following a speciﬁc construction, Poisson coordi-
nates are proved to be pseudo-harmonic, that is, they reproduce harmonic functions
on n-dimensional balls (see [94] for more details on pseudo-harmonic coordinates).
The closed-form expressions of the Poisson weights wi are rather lengthy and can
be found in [247, Section 4.1].
1.2.7
Gordon–Wixom coordinates
Consider a line L through x ∈P along some direction at a given angle θ with
respect to a ﬁxed axis, which intersects ∂P at the points y1, . . . , ym (see Figure 1.3).
Summing over all m intersections, Belyaev et al. [37, 38] extend Gordon–Wixom
coordinates [171] from convex to arbitrary simple polygons and show that they can
be obtained as basis functions from the transﬁnite interpolant (see Chapter 3 for
more details)
f(x) = 1
2π
ˆ 2π
0
 m
X
i=1
εif(yi)
ρi
 m
X
i=1
εi
ρi

dθ,
(1.16)

Barycentric Coordinates and Their Properties
■11
where f(yi) are data sampled from a piecewise-linear function f given along the
polygon’s boundary, ρi = ∥x −yi∥, and εi ∈{−1, 0, 1} with εi = −1 if the ray
from x to yi approaches yi from the outside of P, εi = 0 if it is tangent to ∂P
at yi, or εi = 1 if it approaches yi from the inside of P. These coordinates satisfy
properties (1.10b) and (1.10c), but they can be negative inside non-convex polygons.
Manson et al. [266] extend (1.16) and present positive Gordon–Wixom coordinates
inside any simple polygon, which are as smooth as the boundary. The analytic
expressions of these coordinates are rather lengthy, and we refer the reader to [266,
Section 3.2].
1.2.8
Harmonic coordinates
As observed in [149], one way of acquiring generalized barycentric coordinates with
respect to any simple polygon is by solving the Laplace equation
∆φ = 0
(1.17)
subject to suitable Dirichlet boundary conditions. These boundary conditions are
given by a set of piecewise linear functions g = [g1, . . . , gn]: ∂P →Rn such that
every gi has the Lagrange property (1.10b). These so-called harmonic coordinates
satisfy all properties in (1.10).
The classical way [215] to approximate these coordinates is by discretizing (1.17)
over the space of piecewise linear functions with respect to a triangulation of ¯P.
Alternatively, harmonic coordinates can also be approximated using the boundary
element method [342], the complex variable boundary method [417], and the method
of fundamental solutions [269].
1.2.9
Maximum entropy coordinates
Arroyo and Ortiz [15] and Sukumar [372] show independently that generalized
barycentric coordinates can be obtained as the solution of a constrained optimiza-
tion problem based on the principle of maximum entropy [211]. These maximum
entropy coordinates are non-negative, but the Lagrange property (1.10b) holds only
for strictly convex polygons. It was later realized in [380] that, using prior distri-
butions [212, 230, 357], the constrained optimization can be modiﬁed to be
max
φ(x)∈Rn
+
−
n
X
i=1
φi(x) ln φi(x)
ωi(x)
subject to (1.8) and (1.9), where ωi : P →R+ is a prior estimate for φi, which can
be viewed as a weight function (see Chapter 13 for further details).
Hormann and Sukumar [202] show how to construct ωi such that maximum
entropy coordinates satisfy all properties in (1.10), except smoothness, for any
simple polygon. Regarding smoothness, these coordinates are proven to be C0-
continuous [379] for any set of Ck prior functions with k ≥0 and assumed to be as
smooth as the priors. Unlike harmonic coordinates, maximum entropy coordinates

12
■Generalized Barycentric Coordinates in Graphics and Mechanics
do not require solving a global optimization problem, but can rather be evaluated
locally at any point x ∈P using Newton’s method that converges quadratically.
1.2.10
Local coordinates
Zhang et al. [433] propose to minimize the sum of total variations of the coordinate
functions φi,
min
φ
n
X
i=1
ˆ
P
∥∇φi∥,
subject to the constraints given by (1.8), (1.9), (1.10a), (1.10b), and (1.10c), where
the total variation of φi is the L1-norm of ∥∇φi∥in P. The solution of this convex
minimization problem gives the so-called local coordinates, which are at least C0.
The name stems from the fact that the numerically computed function values are
very close to zero in a large part of P. The exact support of these coordinates,
however, is not known.
1.2.11
Afﬁne coordinates
Among all generalized barycentric coordinates with respect to a scattered set of
points Π, Waldron [408] suggests considering those with minimal L2-norm, which
are uniquely deﬁned as the aﬃne functions
φi(x) = (x −c) · ((V V ∗)−1(vi −c))T + 1
n,
i = 1, . . . , n,
where c = 1
n
Pn
i=1 vi is the barycenter of Π, V = (v1 −c, . . . , vn −c) is a 2 × n
matrix, and V ∗is the adjoint of V . These coordinates are non-negative inside a
convex region that contains c, and they are equal to 1
n at c. They are smooth and
well-deﬁned everywhere in the plane, but, in general, the Lagrange property (1.10b)
holds only in the case n = 3 (see Section 1.1.1).
1.2.12
Sibson coordinates
Let V be the Voronoi diagram [404] of the set Π and Ci be the Voronoi cell in V
that contains vi. Further let Vx be the Voronoi diagram of Π ∪{x} and Cx be the
Voronoi cell in Vx that contains x (see Figure 1.4). Intersecting the cells Ci with
Cx, we can deﬁne the weight functions
wi = Area[Ci ∩Cx],
i = 1, . . . , n.
(1.18)
These areas were originally proposed by Sibson [360, 361] with the emphasis on
natural neighbor interpolation, where the natural neighbors of some x are all points
from Π for which wi(x) ̸= 0.
Normalizing the weights in (1.18) as in (1.12) deﬁnes the Sibson coordinates.
These coordinates are well-deﬁned over the convex hull of Π, have local support,

Barycentric Coordinates and Their Properties
■13
Figure 1.4 Voronoi diagram of a set of scattered points (left) and notation used for
the construction of Sibson and Laplace coordinates (right).
and satisfy the Lagrange property (1.10b). They are C1, except at vi, where they
are only C0. A simple computational algorithm for Sibson coordinates can be found
in [371] and further details in [376].
1.2.13
Laplace coordinates
The concept of natural neighbors (see Section 1.2.12) is also used for the deﬁnition of
so-called Laplace coordinates [34, 103, 370], which are given by the weight functions
wi =
(
si
ri ,
if i ∈Ix,
0,
otherwise,
i = 1, . . . , n,
where si is the length of the edge of Cx that is contained in Ci, ri = ∥vi −x∥,
and Ix ⊂{1, . . . , n} is the subset of indices of the natural neighbors of x (see
Figure 1.4).
These coordinates have the same properties as Sibson coordinates, but they are
only C0 along the boundary of their support. Interestingly, for polygons, whose ver-
tices lie on a circle, Sibson, Laplace, Wachspress, and discrete harmonic coordinates
are all identical [375]. A simple computational algorithm for Laplace coordinates
can be found in [371] and further details in [377].
1.2.14
Hermite coordinates
To interpolate not only boundary data, but also derivative information along the
boundary, we can complement the functions φi with a second set of n functions ψi
and substitute the Lagrange property (1.10b) with the Hermite property
φi(vj) = δij,
ψi(x) = 0
∀x ∈∂P,
∂φi
∂ν (x) = 0
∀x ∈∂P,
∂ψi
∂ν (x) = δij
∀x ∈[vj, vj+1],
(1.19)

14
■Generalized Barycentric Coordinates in Graphics and Mechanics
where ν is the unit vector normal to the boundary ∂P. In this setting, the key
properties of generalized barycentric coordinates in Deﬁnition 1.1 take on the form
n
X
i=1
φi(x) +
n
X
i=1
ψi(x) = 1
∀x ∈¯P,
(1.20)
n
X
i=1
φi(x)vi +
n
X
i=1
ψi(x)νi = x
∀x ∈¯P,
(1.21)
where νi is the unit normal of the edge [vi, vi+1]. Note that (1.20) is essentially the
same as (1.8), because ψi(x) = 0.
To the best of our knowledge, Lipman et al. [252] were the ﬁrst to derive coor-
dinates φi and ψi that satisfy (1.20) and (1.21) from Green’s third identity. These
Green coordinates have a closed form, but do not satisfy (1.19). By ﬁtting a bi-
variate polynomial in a weighted least squares sense to values and derivatives given
along the polygon’s boundary, Manson and Schaefer [267] construct moving least
squares coordinates, which are deﬁned for arbitrary, even disconnected polygons
and have a closed form. Another closed-form solution for Hermite coordinates with
property (1.19) for arbitrary simple polygons is presented by Li et al. [248], who
derive cubic mean value coordinates from the mean value property of biharmonic
functions. Weber et al. [418] extend harmonic coordinates to biharmonic coordi-
nates, which satisfy (1.19), but do not posses a closed form.
1.2.15
Complex coordinates
If we interpret P as a subset of C and view its vertices vi = (xi, yi) as complex
numbers zi = xi +i yi, then we can reformulate generalized barycentric coordinates
as complex functions [415, 416]. These complex coordinates are very useful in the
context of planar shape deformation (see Chapter 7 for more details). The complex
setting also reveals that Green coordinates (see Section 1.2.14) can alternatively be
derived from Cauchy’s integral formula [415].
1.2.16
Comparison
To compare the generalized barycentric coordinates from this section, except for
Hermite and complex, we summarize some of their properties in Table 1.1 and show
contour plots of some coordinate functions for a convex as well as a concave polygon
in Figures 1.5–1.8.
In particular, Table 1.1 lists the domain for which the coordinates are
well-deﬁned and whether or not they have a closed-form deﬁnition, are non-
negative (1.10a), and satisfy the Lagrange property (1.10b). In addition, the table
shows how smooth the coordinates are over the interior of the respective domain.
The partition of unity (1.8) and linear reproduction (1.9) properties are not in-
cluded in the table, because all the coordinates comply with them. Moreover, we
do not include the extra property (1.10c) since it is satisﬁed by all the coordinates
deﬁned for polygons and does not apply to coordinates for scattered points.

Barycentric Coordinates and Their Properties
■15
Coordinates
(Section)
Valid
domain
Closed
form
Non-
negativity
Lagrange
property
Smooth-
ness
WP (1.2.1)



C∞
DH (1.2.2)


C∞
CF
(1.2.4)


C∞
MV (1.2.3)


C∞
PM (1.2.3)



C0
MT (1.2.5)


C∞
PS
(1.2.6)


C∞
GW (1.2.7)


C0
PG (1.2.7)



C0
HM (1.2.8)


C∞
ME (1.2.9)


Ck
LC
(1.2.10)


C0
AF
(1.2.11)

C∞
SB
(1.2.12)



C1
LP
(1.2.13)



C0
Table 1.1 Properties of 2D generalized barycentric coordinates.
For a better comparison we group all coordinates by the ﬁrst two properties. The
ﬁrst group includes Wachspress (WP), discrete harmonic (DH), and the complete
family (CF) of coordinates. These coordinates are well-deﬁned for convex polygons
only and have a closed form. The second group consists of mean value (MV), pos-
itive mean value (PM), metric (MT), Poisson (PS), Gordon–Wixom (GW), and
positive Gordon–Wixom (PG) coordinates that are well-deﬁned for arbitrary sim-
ple polygons and have a closed form.
In the third group we list harmonic (HM),
maximum entropy (ME), and local (LC) coordinates that are also well-deﬁned for
arbitrary simple polygons, but can be obtained only numerically. The last group

16
■Generalized Barycentric Coordinates in Graphics and Mechanics
WP
DH
CF
MV
PM
MT
PS
GW
PG
HM
ME
LC
AF
SB
LP
Figure 1.5 2D generalized barycentric coordinates for a convex polygon with respect
to the marked vertex.

Barycentric Coordinates and Their Properties
■17
WP
DH
CF
MV
PM
MT
PS
GW
PG
HM
ME
LC
AF
SB
LP
Figure 1.6 2D generalized barycentric coordinates for a convex polygon with respect
to the marked vertex.

18
■Generalized Barycentric Coordinates in Graphics and Mechanics
MV
PM
MT
PS
GW
PG
HM
ME
LC
Figure 1.7 2D generalized barycentric coordinates for a concave polygon with re-
spect to the marked vertex.

Barycentric Coordinates and Their Properties
■19
MV
PM
MT
PS
GW
PG
HM
ME
LC
Figure 1.8 2D generalized barycentric coordinates for a concave polygon with re-
spect to the marked vertex.

20
■Generalized Barycentric Coordinates in Graphics and Mechanics
includes aﬃne (AF), Sibson (SB), and Laplace (LP) coordinates that are deﬁned
with respect to sets of scattered points.
Figures 1.5 and 1.6 provide a visual comparison of all coordinates by showing
contour plots of two diﬀerent basis functions for a convex polygon. A similar com-
parison of all coordinates that are well-deﬁned for a concave polygon is given in
Figures 1.7 and 1.8. In all plots the thick curves represent contours for the func-
tion values 0.0, 0.1, . . . , 1.0 and allow for a comparison of the general shapes of the
coordinate functions. In addition, the decay towards zero can be deduced from the
thin curves, which represent contours for the values 0.01, 0.02, . . . , 0.09. The same
contour spacing is used for negative function values, and the corresponding regions
are shaded in light gray. Likewise, regions with function values greater than one are
shaded in dark gray. As a representative of the complete family (CF) of coordinates,
we choose the function
ci = 2ri
sin αi−1 + sin αi
sin αi−1 + sin αi + sin(αi−1 + αi),
which was proposed in [149, Section 5]. For aﬃne, Sibson, and Laplace coordinates
we treat the vertices of the polygon as a set of scattered points and restrict the plot
to the convex hull. The plots show that mean value, Poisson, and Gordon–Wixom
coordinates can become negative inside non-convex polygons. The same is true for
metric coordinates, also for convex polygons, and for aﬃne coordinates, which do
not even necessarily satisfy the Lagrange property.
1.3
3D COORDINATES
We now focus on the 3D case and consider a polyhedron P with n vertices v1, . . . , vn
and m faces f1, . . . , fm. We present explicit formulations for some generalized
barycentric coordinates in this setting, which are direct extensions of the corre-
sponding 2D constructions. Since the properties of these coordinates carry over
from 2D to 3D, we do not mention them explicitly.
1.3.1
Wachspress coordinates
Wachspress coordinates can be generalized to convex polyhedra in which all ver-
tices have exactly three incident faces [407, 411, 413], and to arbitrary convex
polyhedra using the concept of polar duals [218]. The polar dual of a bounded con-
vex polyhedron that contains the origin is itself a convex polyhedron of the form
Pd = {y ∈R3 | y · z ≤1 ∀z ∈P}. Since each vertex vi of P has a dual polygonal
pyramid △i in Pd (see Figure 1.9 for a 2D example), translating P such that x is
at the origin and letting
wi = Vol[△i],
i = 1, . . . , n
leads to 3D Wachspress coordinates after the normalization in (1.12). Note that the
constructions in [411, 413] also extend to higher dimensions.

Barycentric Coordinates and Their Properties
■21
△i
vi
P
x
Pd
△i
Figure 1.9 Polar dual Pd of a hexagon P centered at x, where the triangle △i is
dual to the vertex vi.
1.3.2
Discrete harmonic coordinates
It was ﬁrst mentioned in [276] that 3D discrete harmonic coordinates exist, but no
exact formula was given. Later, Ju et al. [216] show that for convex polyhedra with
triangular faces these coordinates are given by the weight functions
wi =
X
j∈Ni
hj cot βj,
i = 1, . . . , n,
where Ni ⊂{1, . . . , n} is the subset of the indices of the vertices in the one-ring
neighborhood of vi, βj is the dihedral angle between the faces [vi, vj, vj+] and
[x, vj, vj+], and hj = ∥vj −vj+∥(see Figure 1.10).
Interestingly, unlike their 2D counterparts (see Section 1.2.2), discrete harmonic
and Wachspress coordinates are not identical for polyhedra, whose vertices lie on
a common sphere. However, Ju et al. [216, Section 3.2.2] introduce Voronoi coordi-
nates, which are identical to Wachspress coordinates on such polyhedra.
1.3.3
Mean value coordinates
Floater et al. [150] and Ju et al. [217] independently generalize mean value coordi-
nates to arbitrary polyhedra with triangular faces. Consider a face fk = [vk
1, vk
2, vk
3]
of P. By projecting fk onto the unit sphere centered at x we obtain a triangular
Figure 1.10 Notation used for signed angles, distances, and signed volumes in a
polyhedron with triangular faces.

22
■Generalized Barycentric Coordinates in Graphics and Mechanics
wedge Tk. The weight functions for 3D mean value coordinates with respect to the
vertices vk
j of the face fk are then deﬁned as
wk
j = ek
j −ek
j−1 cos αk
j+1 −ek
j+1 cos αk
j−1
rk
j sin αk
j+1 sin αk
j−1
,
j = 1, . . . , 3,
k = 1, . . . , m,
with the angles αk
j and the spherical edge lengths ek
j as shown in Figure 1.10
and rk
j =
vk
j −x
. Details regarding the generalization of this construction to
polyhedra with arbitrary faces can be found in [145].
1.3.4
Complete family of coordinates
Ju et al. [216] show that for convex polyhedra with triangular faces, Wachspress,
discrete harmonic, and mean value coordinates can all be uniﬁed in a simple frame-
work, which closely resembles the one in Section 1.2.4. This complete family of 3D
coordinates is given by the weight functions
wi =
X
j∈Ni
cj,j+
Aj
+
X
j∈Ni
ci,jBj
AjAj−,
i = 1, . . . , n,
where ci,j : P →R are arbitrary real functions, Aj and Bj are the signed volumes
shown in Figure 1.10, and Ni ⊂{1, . . . , n} is the subset of indices of the vertices in
the one-ring neighborhood of vi. The name stems from the fact that this framework
includes all possible coordinates for polyhedra with triangular faces. For example,
given the signed angle αi,j formed by vi −x and vj −x, the choices
ci,j = 2 −
 ∥vi −x∥
∥vj −x∥+ ∥vj −x∥
∥vi −x∥

· cos αi,j,
ci,j = ∥(vi −x) × (vj −x)∥2,
ci,j = ∥(vi −x) × (vj −x)∥· αi,j
lead to Wachspress, discrete harmonic, and mean value coordinates, respectively.
Alternatively, all non-negative coordinates for convex polyhedra can be rep-
resented as 3D power coordinates [78], and both approaches can be extended to
convex polytopes in higher dimensions.
1.3.5
Other coordinates
The extensions of positive mean value [251], harmonic [215], maximum entropy [202]
and local [433] coordinates to 3D are straightforward and mentioned in the re-
spective papers. Extensions of Sibson and Laplace coordinates to arbitrary higher
dimensions are discussed in [55] and to higher continuity in [194]. The other 2D
coordinates in Section 1.2 can probably be extended to 3D, too, but to the best of
our knowledge, this has not been done so far. Apart from Wachspress coordinates,
the only other coordinates that have been explicitly extended to arbitrary higher
dimension are aﬃne coordinates [408].

C H A P T E R 2
Shape Quality for
Generalized Barycentric
Interpolation
Andrew Gillette*
University of Arizona, Tucson, USA
Alexander Rand
CD-adapco, Austin, USA
CONTENTS
2.1
Introduction ......................................................
24
2.2
Deconstructing the a priori error estimate ......................
26
2.3
Shape quality metrics for simplices ..............................
29
2.4
Shape quality metrics for polygons and polyhedra ..............
31
2.5
Interpolation error estimates on polygons .......................
34
2.5.1
Triangulation coordinates ................................
34
2.5.2
Harmonic coordinates ....................................
35
2.5.3
Wachspress coordinates ..................................
37
2.5.4
Mean value coordinates ..................................
39
2.6
Interpolation error estimates on polyhedra and polytopes ......
39
2.6.1
Harmonic coordinates in 3D and higher .................
40
2.6.2
Wachspress coordinates in 3D and higher ...............
40
2.7
Extensions and future directions ................................
41
A
T A TIME WHEN generalized barycentric coordinates are gaining popu-
larity in an ever-growing set of application contexts, there is a need for a
clear understanding of the relationship between the interpolation properties of var-
ious coordinate types and the geometries on which they are deﬁned. Consider, for
*Supported in part by the U.S. National Science Foundation under grant DMS-1522289.
23

24
■Generalized Barycentric Coordinates in Graphics and Mechanics
1
ϵ
1
1
ϵ
1
1
ϵ
1
(a)
(b)
(c)
Figure 2.1 Three families of polygons with degenerate geometry as ϵ →0 are shown:
(a) an interior angle approaching 180◦; (b) an edge approaching length 0; (c) a
vertex approaching the interior of a non-adjacent edge.
instance, an academic or industrial code employing generalized barycentric coor-
dinates that fails to give a numerical output when applied to some polygonal or
polyhedral mesh. Could the premature termination of the simulation be averted by
changing the coordinates that are used? Or by improving the “quality” of the mesh
elements in some way? Or neither?
2.1
INTRODUCTION
In this work, we present both practical computational evidence and theoretical
mathematical analyses for a variety of circumstances in which generalized barycen-
tric interpolation will predictably succeed. Our primary proxy for the success of
interpolation is a sharp upper bound on ∥∇φi∥∞, the maximum gradient of a gen-
eralized barycentric coordinate function, in terms of the relative positioning of the
vertices {v1, . . . , vn} of the polygon or polyhedron P on which φi is deﬁned. In
computer graphics applications, control of gradients is essential to avoid visual ar-
tifacts. In computational mechanics applications, the gradient of the solution to
a partial diﬀerential equation is often a quantity of interest in itself; in Poisson’s
equation, for instance, the gradient of the solution contributes to the energy norm
(i.e., the H1-norm) that is used to measure error. Further, we seek the broadest
possible class of polygons or polyhedra over which our gradient estimates hold, as
this puts the least restrictive requirements on the domain geometry.
To get a sense of the subtleties that can arise in this kind of analysis, consider
three ways in which polygonal geometry can become “degenerate,” as shown in
Figure 2.1: collinearity of consecutive vertices, short edge length relative to diam-
eter, and close proximity between a vertex and a non-adjacent edge. We carry out
a numerical experiment to test ﬁve kinds of generalized barycentric coordinates
on these representative “low-quality geometric domains.” Boundary values for the
generalized barycentric coordinates are derived from a simple quadratic function,

Shape Quality for Generalized Barycentric Interpolation
■25
ϵ
HM
WP
MV
DH
LS-1
LS-2
LS-3
ME-T
ME-U
0.1600
1.3e0
2.6e-1
6.0e-2
2.3e-1
1.8e-1
2.2e-2
5.4e-2
7.9e-2
5.1e-1
0.0400
1.3e0
1.3e0
1.1e-1
1.5e0
3.6e-1
5.4e-2
1.2e-1
1.6e-1
2.2e0
0.0100
1.3e0
3.1e0
1.3e-1
3.9e0
4.4e-1
6.5e-2
1.4e-1
1.9e-1
5.1e0
0.0025
1.3e0
6.4e0
1.3e-1
8.3e0
4.5e-1
6.7e-2
1.4e-1
2.0e-1
9.3e0
0.0000
1.3e0
—
1.3e-1
—
4.5e-1
6.8e-2
1.5e-1
2.0e-1
⋆
Table 2.1 Comparison among the harmonic (HM), Wachspress (WP), mean value
(MV), discrete harmonic (DH), moving least squares (LS-∗), and maximum en-
tropy (ME-∗) coordinates over the family of domains depicted in Figure 2.1a. The
harmonic coordinates were approximated using a ﬁne triangular mesh to provide
a benchmark value; the H1-seminorm of the interpolant is reported. For the other
coordinates, the reported value is the H1-seminorm of the diﬀerence between the
interpolant and the harmonic interpolant.
u(x, y) = 0.77223(x −0.331)2 + 1.1123(y + 0.177344)2, with some arbitrary coef-
ﬁcients selected to avoid degeneracy or symmetry during interpolation. First, we
compute an approximation to the harmonic coordinates using a ﬁne triangular
mesh (see Section 1.2.8). Since harmonic coordinates provide an interpolant with
minimal H1-seminorm by Dirichlet’s principle, this establishes a good benchmark
interpolant.
We then compute interpolants using the following coordinates: Wachspress,
mean value, discrete harmonic, moving least squares with linear, quadratic, and cu-
bic weights, and maximum entropy with a “triangle inequality” prior (constructed
from edge weight functions that vanish along each edge of the polygon and are
strictly positive elsewhere) and the uniform prior. All of these coordinates are de-
ﬁned in Section 1.2, except for the moving least squares coordinates, which are
described in the discussion below.
Table 2.1 shows the result of our experiment for the family of domains shown in
Figure 2.1a. Here, the limiting case, when ϵ = 0, looks like a square with a hanging
node, but we formally treat it as a pentagon with two adjacent collinear sides.
The H1-seminorm of the approximation to the harmonic interpolant is reported in
the ﬁrst column, demonstrating that this value does not grow as ϵ →0. For other
coordinates, the H1-seminorm of the diﬀerence between the interpolant and the
harmonic interpolant is reported. Here, the well-known advantage of mean value
coordinates over Wachspress coordinates is evident: the Wachspress gradients grow
with large interior angles whereas mean value coordinates do not. Discrete harmonic
coordinates exhibit a similar behavior as they, like Wachspress coordinates, are not
well-deﬁned when the domain is not strictly convex.
Maximum entropy coordinates [202] are deﬁned both as ϵ →0 and when ϵ = 0;
however, the choice of prior aﬀects their behavior in the limit. In the case of the
uniform prior (ME-U), the value at the peak vertex jumps from 1 to 1/3 when the
geometry changes from a pentagon to a square, breaking the Lagrange property.

26
■Generalized Barycentric Coordinates in Graphics and Mechanics
Note that if the ME-U coordinates are used throughout an entire mesh, the resulting
interpolant will be conforming, that is globally C0. However, the value of the ME-U
interpolant along adjacent collinear edges may not be the same as the interpolant
produced by other kinds of generalized barycentric coordinates. We ﬂag this special
case with ⋆in Table 2.1. On the other hand, when using the “triangle inequality”
prior (ME-T), the Lagrange property is satisﬁed when ϵ = 0 and the success of the
interpolant as ϵ →0 is conﬁrmed by the data.
Moving least squares coordinates [267] are deﬁned in terms of a minimization
problem, weighted by the distance from a point to the boundary. The weight func-
tion W(x, t) = ∥p′(t)∥/∥p(t) −x∥α ensures that the coordinates have the boundary
values encoded by p on each edge; the larger the exponent α, the more weight is
given to smoothness of the coordinates near the boundary relative to smoothness
on the interior of the domain. As reported in the LS-α columns of Table 2.1, for
α = 1, 2, 3, the moving least squares interpolant exhibits small error compared to
the harmonic interpolant as the geometry degenerates to a square, with α = 2
producing the smallest error. From this perspective, the quadratic weight seems to
do the best mimicking harmonic coordinates by balancing smooth enforcement of
boundary requirements with interior smoothness; the other weight choices overly
prefer one of these objectives to the detriment of the interpolation error. Note that
moving least squares coordinates may take on negative values, which can present
challenges in graphics applications. In regards to the error analysis presented here,
however, non-negativity of the interpolant is not required.
The results of our experiments for the domains shown in Figures 2.1b and 2.1c
are provided in Tables 2.2 (page 34) and 2.4 (page 37), respectively. All the results
are discussed more thoroughly in Section 2.5.
2.2
DECONSTRUCTING THE A PRIORI ERROR ESTIMATE
The typical a priori error analysis of a ﬁnite element method begins with a charac-
terization of the partial diﬀerential equation to be solved as an equation between a
coercive, continuous bilinear form on V ×V and a bounded linear operator L on V ,
where V is the function space from which u is sought [70, 369]. We ﬁx the common
setting of V = H1
0(Ω), the space of H1 functions on domain Ω, with zero boundary
conditions on ∂Ω. Cea’s lemma then asserts the existence of a constant CC such
that
∥u −uh∥H1(Ω) ≤CC min
vh∈Vh ∥u −vh∥H1(Ω).
(2.1)
Here, u ∈V is the unknown continuous solution to the problem, uh is the approxi-
mation to u computed by the ﬁnite element method, and Vh is a ﬁnite-dimensional
subspace of V from which uh is sought. Hence, (2.1) establishes that the error be-
tween uh and u is within a constant multiple of the best possible error when looking
for a solution in Vh.
The next step in the analysis is to bound the error in the particular case of
vh := Iu, where I : V →Vh is an interpolation operator. A subtle but crucial point
is that I takes as input the entire unknown function u to produce Iu and thus

Shape Quality for Generalized Barycentric Interpolation
■27
can employ quantities such as u(vi) in its deﬁnition. The ﬁnite element solution
uh, on the other hand, is the output of a solution operator whose only inputs
are the bilinear form, the linear operator Vh, and the boundary conditions. For
linear interpolation derived directly from barycentric or generalized barycentric
coordinates, the interpolation error estimate has the form
∥u −Iu∥H1(Ω) ≤CIE h |u|H2(Ω),
(2.2)
where h is the maximum diameter of an element in a mesh of Ω. The constant CIE
in (2.2) depends both on the interpolation method (i.e., the deﬁnition of Iu) and
on the shape of the elements used in the mesh. This dependence is quite subtle and
often misunderstood.
Analysis leading to estimate (2.2) can be simpliﬁed via two observations. First,
the error can be decomposed into individual mesh elements rather than the entire
solution domain. Second, assuming that the interpolation method is aﬃne invariant,
all estimates can be rescaled to diameter 1 elements. Thus, it is suﬃcient to establish
∥u −Iu∥H1(P ) ≤CIE |u|H2(P ),
(2.3)
for any polytope P of diameter 1 that is similar to an element in the mesh of Ω.
For interpolation via a set of generalized barycentric coordinates φ, the inter-
polation operator I : H2(P) →span{φ} is deﬁned by
Iu :=
n
X
i=1
u(vi)φi.
(2.4)
In order to prove (2.3), we may only assume that u ∈H2(P); however, the formula
for Iu in (2.4) requires point values for u at vertices of P. We can appeal to the
Sobolev embedding theorem [4, 70, 240] to ensure that u is in fact a continuous
function and hence that u(vi) is well-deﬁned. We state a special case of the theorem
that is also called Morrey’s inequality, which we have tailored to the relevant setting.
Theorem 2.1 (Sobolev embedding/Morrey’s inequality). Let k > d/2. For any
polygonal or polyhedral domain P, there exists a constant CSE depending only on k
and d such that for any u ∈Hk(P),
∥u∥L∞(P ) ≤CSE ∥u∥Hk(P ).
Moreover, there is a continuous function in the L∞(P) equivalence class of u.
The constant CSE depends, in general, on the geometry of P and it is possible
to ﬁnd a sequence of polytopes {Pi}∞
i=1 for which the associated sequence of con-
stants grows without bound. In these cases, the sequence of boundaries {∂Pi}∞
i=1
is typically approaching some kind of cusp, fractal, or other kind of “degenerate”
geometry. Accordingly, we require that P belong to some class of polytopes whose
geometry is controlled via shape quality metrics and then seek a uniform bound on
CSE for this class.

28
■Generalized Barycentric Coordinates in Graphics and Mechanics
We will also make use of the Bramble–Hilbert lemma [69], which estimates how
well a function u can be approximated by polynomials in relevant Sobolev norms. It
can be established uniformly over convex domains [117, 402] and can be extended
to non-convex domains that are “star-shaped with respect to a ball” [70]. We state
the convex version here.
Theorem 2.2 (Bramble–Hilbert). There exists a constant CBH depending only
upon d such that for any convex polytope P ⊂Rd of diameter 1 and any u ∈H2(P),
there exists an aﬃne function pu such that,
∥u −pu∥H1(P ) ≤CBH |u|H2(P ).
(2.5)
We now state ﬁve additional estimates that are either helpful or essential in
proving (2.3). All of these are stated in terms of the spatial dimension d for unit
diameter domains.
Uniform Sobolev Embedding:
n
X
i=1
|u(vi)| ≤CUSE ∥u∥H2(P ).
(2.6)
Bounded Gradients in L∞:
|∇φi|L∞(P ) ≤C∇φ.
(2.7)
Bounded Gradients in H1:
∥φi∥H1(P ) ≤CH1 .
(2.8)
Bounded Interpolation:
∥Iu∥H1(P ) ≤CBI ∥u∥H2(P ).
(2.9)
Interpolation Error:
∥u −Iu∥H1(P ) ≤CIE |u|H2(P ).
(2.10)
Each estimate is of interest when the associated constant C can be bounded above
uniformly over some class p of polygons or polyhedra. In such cases, we say the
estimate “holds over p” and we have the following implications.
Proposition 2.3. Let p be a class of polygons or polyhedra with unit diameter.
(i) If (2.7) holds over p, then (2.8) holds over p.
(ii) If (2.6) and (2.8) hold over p, then (2.9) holds over p.
(iii) If (2.9) holds over p, then (2.10) holds over p.
Proof. For (i), we have that
∥φi∥2
H1(P ) =
ˆ
P
|φi|2 + |∇φi|2 ≤
 1 + |∇φi|2
L∞(P )

|P| ≤(1 + C2
∇φ)|P|,
where |P| denotes the measure of P. Since |P| must be contained inside a d-ball of
unit radius, there is a constant C such that |P| ≤C and the estimate follows.
For (ii), Theorem 2.1 ensures that any u ∈H2(P) can be treated as a continuous
function on P, since d = 2 or 3. Thus, u(vi) is well-deﬁned and we have that
∥Iu∥H1(P ) ≤
n
X
i=1
|u(vi)| · ∥φi∥H1(P ) ≤CH1CUSE ∥u∥H2(P ).

Shape Quality for Generalized Barycentric Interpolation
■29
For (iii), ﬁrst note that any choice of generalized barycentric coordinates φ
ensures that
Ip =
n
X
i=1
p(vi)φi = p
(2.11)
for any linear polynomial p: P →R. Now, given u, let pu be the ﬁrst-order poly-
nomial satisfying (2.5). Then,
∥u −Iu∥2
H1(P ) ≤∥u −pu∥2
H1(P ) + ∥pu −Iu∥2
H1(P )
by triangle inequality,
= ∥u −pu∥2
H1(P ) + ∥I(u −pu)∥2
H1(P )
by (2.11),
≤∥u −pu∥2
H1(P ) + C2
BI ∥u −pu∥2
H2(P )
by (2.9),
≤(1 + C2
BI)∥u −pu∥2
H1(P ) + C2
BI |u −pu|2
H2(P )
≤
 C2
BH(1 + C2
BI) + C2
BI

|u|2
H2(P )
by (2.5).
The last step also uses the fact that the H2 semi-norm of the ﬁrst order polynomial
pu is zero.
Fix any h > 0. The estimate on ∥u −Iu∥H1(P ) just derived can be strengthened
to an estimate on ∥u −Iu∥H1(Ω), where Ωis a mesh made of elements from p scaled
by at most h. The resulting estimate is
∥u −uh∥H1(Ω)
|
{z
}
ﬁnite element error
≤
CC
|{z}
from
(2.1)
∥u −Iu∥H1(Ω)
|
{z
}
interpolation error
≤CC CIE h |u|H2(Ω)
|
{z
}
2nd order
oscillation
,
(2.12)
where
CIE :=
 C2
BH(1 + C2
BI) + C2
BI
1/2,
with CBH from (2.5) and CBI from (2.9). As seen from the proof of Proposition 2.3,
CBI may depend in turn on the constants CH1 from (2.8) and CUSE from (2.6) and
CH1 may depend on the constant C∇φ from (2.7).
Equation (2.12) is the standard optimal convergence estimate for linear order,
scalar-valued ﬁnite element methods. We can now see that the choice of generalized
barycentric coordinates φ and class of polytopes p is relevant at two key places in
the analysis: the uniform Sobolev embedding estimate (2.6) and, more crucially, the
gradient bound (2.7). We next investigate shape quality metrics that can ensure
these two essential estimates on simplicial and polytopal meshes.
2.3
SHAPE QUALITY METRICS FOR SIMPLICES
The simplest case for our analysis is the class of triangles of diameter 1. Consider
the following two types of subclasses:
tmina — All angles are bounded away from zero: αi > α∗> 0.
tmaxa — All angles are bounded away from 180◦: αi < α∗< 180◦.

30
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 2.2 Left: Representative triangles satisfying one of three common quality
metrics are shown: modest aspect ratio, one small angle, and one large angle. Right:
Polygons are more challenging to classify in this manner as the presence of large or
small angles neither implies nor excludes a good aspect ratio.
The terms minimum angle condition and maximum angle condition, which are com-
mon in the ﬁnite element literature, refer to classes of type tmina or tmaxa, respec-
tively. In each case, estimate (2.7) can be established.
Lemma 2.4. The inequality in (2.7) holds uniformly on tmina.
The proof of Lemma 2.4 is straightforward, since the minimum angle bound im-
plies a minimum altitude, which in turn implies a maximum gradient on barycentric
coordinates as required for (2.7).
Theorem 2.5. The inequality in (2.10) holds uniformly on tmaxa.
The proof of Theorem 2.5 is more involved since large angle triangles admit small
altitudes and thus potentially large gradients locally. Instead, the proof involves
mapping large angle triangles to those with bounded aspect ratio and following
the error estimates through this mapping. Interpolation error estimates over these
kinds of triangle classes originated independently in work by Babuška and Aziz [22]
and Jamet [209].
Another way to describe the triangle quality is illustrated in Figure 2.2. The
three triangles shown on the left have a modest aspect ratio, a single small angle,
and a single large angle, respectively. Recall that the aspect ratio of a triangle is the
ratio of its longest edge to the radius of its smallest inscribed circle. A bound on
the aspect ratio is equivalent to a bound on the smallest angle in the triangle, hence
any class of triangles with bounded aspect ratio is some class of the form of tmina.
Further, arbitrarily large angles only occur in conjunction with very small angles,
hence, as a subclass of diameter 1 triangles, any class of type tmina is contained in
a class of type tmaxa. The converse is false: each class of type tmaxa includes some
triangles with arbitrarily small angles, which is not contained in any class of type
tmina.
Simple examples demonstrate unbounded interpolation error on classes of tri-
angles admitting arbitrarily large interior angles [22]. More precisely, it has been
shown that the rate at which the interpolation error grows is proportional to the

Shape Quality for Generalized Barycentric Interpolation
■31
circumradius of the triangle [225, 317]. Thus, while a bound on the circumradius
implies a bound on the maximum angle and vice versa, the former has a more direct
connection to the interpolation error.
While a class of type tmaxa is suﬃcient for the interpolation analysis outlined
in Section 2.2, it is not strictly necessary for the convergence of ﬁnite element
methods, as demonstrated in [185]. However, the examples of convergent ﬁnite
element methods on meshes with arbitrarily large angles employ shape function
spaces that contain subspaces corresponding to shape-regular meshes. Thus, some
form of shape regularity still appears to underlie successful ﬁnite element methods.
These ideas have been generalized to tetrahedra and higher-dimensional sim-
plices [7, 209, 231, 318]. On tetrahedra, the most widely known and used shape
quality metric is aspect ratio, which on polyhedra is the ratio of the diameter of
the element to the radius of the smallest inscribed sphere. Error analysis based on
aspect ratio is straightforward to carry out, but is overly restrictive on the geometry,
in the same way that a bound on the aspect ratio on triangles excludes permissible
single-small-angle triangles. While a bound on the circumradius is closely tied to
the interpolation error on triangles, the same is not true on tetrahedra due to the
possibility of slivers. Slivers are very ﬂat tetrahedra with evenly spaced vertices
near a common circle such that the circumradius is modest. A metric called copla-
narity [318] balances a weakened aspect ratio bound with an exclusion of sliver
tetrahedra; it measures how far the edges of a tetrahedron lie to a common plane,
thereby allowing narrow elements without allowing slivers.
2.4
SHAPE QUALITY METRICS FOR POLYGONS AND POLYHEDRA
For the class of diameter 1 triangles, we have just discussed how many common
shape quality metrics are eﬀectively equivalent. For the class of diameter 1 polygons,
however, these equivalences do not hold and the relations among metrics are more
subtle. For example, a polygon can have high aspect ratio without any small interior
angles or can have a modest aspect ratio with interior angles near 180◦. Some
illustrative examples are shown in Figure 2.2.
To analyze the polygonal setting, let P denote a generic polygon of diameter 1
with edges {ei}n
i=1, vertices {vi}n
i=1, interior angles {αi}n
i=1, and maximum radius
of an inscribed circle r(P). We consider the following subclasses of polygons.∗
pcvx — P is convex.
par — The aspect ratio is bounded: diam(P)
r(P)
≤γ∗.
pnv — The number of vertices is bounded: n < n∗.
pedge — The ratio of diameter to the shortest edge is bounded: diam(P)
|ei|
< e∗.
∗We have included diam(P) in some of the deﬁnitions even though we have ﬁxed it to be 1 for
the subsequent analysis; this is intended to highlight the scaling eﬀect of the diameter.

32
■Generalized Barycentric Coordinates in Graphics and Mechanics
pmina — All interior angles are bounded away from zero: αi > α∗> 0.
pmaxa — All interior angles are bounded away from 180◦: αi < α∗< 180◦.
The deﬁnitions of pcvx, par, pnv, and pedge also deﬁne subclasses of diameter 1
polyhedra and of higher-dimensional polytopes. The deﬁnitions of pmina and pmaxa
are speciﬁc to polygons as stated, but can be generalized to higher dimensions by
considering dihedral angles between faces with codimension 1. On polygons, we
have previously shown some containments between these classes, as indicated in
the following lemma; a proof is given in [164, Proposition 4].
Lemma 2.6. For the class of diameter 1 polygons:
(i) pcvx ∩par ⊂pmina.
(ii) pcvx ∩pedge ⊂pnv.
(iii) pcvx ∩pmaxa ⊂pnv.
We have also shown that for P, a convex polygon of diameter 1, an aspect ratio
and edge bound imply that a ball of some uniform radius r∗centered at any x ∈P
will intersect ∂P in one of three ways: at two adjacent edges, at a single edge, or
not at all. This non-degeneracy result is helpful for our subsequent analysis and can
be stated more precisely as follows; a proof is given in [164, Proposition 9].
Lemma 2.7. For the class of diameter 1 polygons, there exists r∗> 0 such that
for all P ∈pcvx ∩par ∩pedge and for any x ∈P, B(x, r∗) does not intersect two
non-adjacent edges of P.
Beyond direct relationships between these geometric criteria, uniformity of the
Sobolev embedding constant is an essential ingredient of our analysis involving
some (relatively mild) geometric restrictions. This component is unique to polygonal
analysis, since simplices can be mapped aﬃnely to a single reference element.
Lemma 2.8. Set d = 2. The uniform Sobolev embedding estimate (2.6) holds on
pcvx ∩par.
We omit a full proof of Lemma 2.8 and instead provide a sketch of the key
ideas; the interested reader can ﬁnd relevant technical details in the proof of [164,
Proposition 10]. In the mathematical analysis literature, the constant in the Sobolev
embedding theorem is typically derived from the “cone condition” [3]. This condi-
tion requires the existence of a cone such that for any point x ∈P, the cone can
be rotated and translated so that it lies entirely inside P with its apex at x. We
can prove Lemma 2.8 by ﬁnding a single cone, depending only on the aspect ratio
bound, such that the cone condition holds for any domain in pcvx ∩par. In the
polygonal case, a minimum interior angle bound is required so that the speciﬁc
cone can be placed near the vertices, and Lemma 2.6 (i) provides this guarantee.

Shape Quality for Generalized Barycentric Interpolation
■33
Various polytopal element methods have recently appeared in the literature on
numerical methods for partial diﬀerential equations that can accommodate polygo-
nal and polyhedral meshes without the use of generalized barycentric coordinates.
These include mimetic methods, virtual elements (see Chapter 15), weak Galerkin
methods, gradient schemes, and many more that are beyond the scope of discus-
sion in this chapter. All these approaches still require assumptions on shape quality
of the mesh elements in order to carry out their desired error analyses. The typi-
cal assumption is that each mesh element is “star-shaped with respect to a ball,”
that is, there exists a d-ball BP ⊂P of radius r(BP ) such that the convex hull of
{x} ∪B is a subset of P [70]. Then, on a sequence of meshes, it is assumed that
diam(P)/r(BP ) is bounded above uniformly. Since r(BP ) ≤r(P), this assumption
is stronger than a bound on the aspect ratio as in par. Since many of those methods
are, in eﬀect, using harmonic coordinates for their error analysis, it seems likely
that their assumptions could be weakened accordingly.
Shape regularity conditions for polygonal and polyhedral meshes have also
been considered recently by Mu, Wang, and Wang in the context of discontinuous
Galerkin methods [288]. They provide four shape regularity conditions, denoted
A1–A4, which bear many similarities to the metrics presented here. Condition A1
ensures that mesh elements have a good quality decomposition into simplices, which
is related to our ﬁndings for harmonic coordinates; this is discussed further in Sec-
tion 2.5 and [163]. Condition A2 requires the existence of one “large” edge per
element, but this is later recast as condition A2′′, which is exactly the same as
a bound on the aspect ratio. Condition A3 allows a more general interpretation
of how two polygons or polyhedra may meet in a mesh and A4 ensures that the
ratio of diameters of adjacent mesh elements is bounded above; that is, the mesh
is “graded” reasonably well.
In work by Floater et al. [147], the shape quality of a convex polytope P is
characterized by a single parameter h∗, deﬁned as the minimum distance between
a vertex of P and any hyperplane containing a non-incident face. More formally,
h∗(P) := min
f∈F
min
v∈V \Vf hf(v),
where F, V are the sets of faces and vertices of P, respectively, Vf ⊂V is the set
of vertices belonging to face f, and hf(v) is the distance from vertex v to the d −1
dimensional hyperplane containing f. Consider the associated class of polytopes:
pvf — The value of h∗is bounded away from zero: h∗(P) ≥h∗> 0.
In the case of polygons, ﬁxing a counterclockwise ordering of the vertices and f :=
[vi−1, vi], we have hf(vi+1) = ∥vi+1 −vi∥sin αi, where αi := ∠(vi−1, vi, vi+1).
Thus, a lower bound on h∗ensures a balance between short edges in P and the
angles adjacent to them. A precise result is the following.
Lemma 2.9. On polygons, (pcvx ∩pedge ∩pmina ∩pmaxa) ⊂pvf.
A proof of Lemma 2.9 can be found within the proof of [147, Corollary 2.4].

34
■Generalized Barycentric Coordinates in Graphics and Mechanics
ϵ
HM*
WP
MV
DH
LS-1
LS-2
LS-3
ME-T
ME-U
0.1600
7.5e-1
1.1e-1
4.0e-2
2.3e-1
2.2e-1
3.4e-2
6.5e-2
2.5e-1
7.3e-1
0.0400
8.5e-1
3.9e-2
1.2e-2
8.3e-2
9.0e-2
1.3e-2
2.9e-2
9.6e-2
4.6e-1
0.0100
8.9e-1
1.2e-2
3.2e-3
1.6e-1
2.9e-2
4.3e-3
1.0e-2
3.0e-2
2.5e-1
0.0025
9.1e-1
3.3e-3
6.7e-4
3.7e-3
7.9e-3
1.2e-3
3.2e-3
8.9e-3
9.9e-2
Table 2.2 Comparison of some generalized barycentric coordinates over the family of
domains depicted in Figure 2.1b. Coordinates and data are the same as in Table 2.1;
that is, the H1-seminorm of the interpolant is reported for harmonic coordinates
and the H1-seminorm diﬀerence from the harmonic interpolant is reported for other
coordinates. The data shows that generalized barycentric coordinates can have
controlled interpolation error in the presence of a small edge.
2.5
INTERPOLATION ERROR ESTIMATES ON POLYGONS
Let φ be a speciﬁc kind of barycentric coordinates; for example, Wachspress coordi-
nates. What is a suﬃcient but not overly restrictive subclass of diameter 1 polygons
for which one of the estimates (2.7)–(2.9) is guaranteed to hold for φ? In light of
the analysis in Section 2.2, an answer to this question, coupled with a uniform
Sobolev embedding estimate (2.6), implies a standard a priori error estimate of the
form (2.12). We have answered this question for a variety of generalized barycentric
coordinates, as we now discuss.
We ﬁrst consider some simple examples demonstrating the robustness or failure
of generalized barycentric interpolation over families of polygons admitting degen-
erate geometries. In Section 2.1, we discussed the family from Figure 2.1a, which
included arbitrarily large angles. Now consider Figure 2.1b, which depicts a family
of quadrilaterals containing arbitrarily small edge lengths, approaching a triangular
geometry. Interpolation errors computed in Table 2.2 demonstrate that this degen-
eracy does not pose any practical problems. The data shows that while pedge is
useful for analysis, it is not strictly necessary for controlled interpolation.
Moreover, the interpolation error can withstand the presence of many short
edges, even over a class of polygons that is not of type pnv. Table 2.3 contains inter-
polation errors over regular polygons with increasingly large numbers of vertices;
this family of polygons is of type pcvx, par, and pmina, but not of type pedge, pmaxa,
or pnv. For every kind of coordinates tested, the interpolation error is practically
bounded, although some errors could be growing very slowly. Another challenge
also arises: large vertex counts make the computation of the coordinates increas-
ingly expensive.
2.5.1
Triangulation coordinates
The simplest generalized barycentric coordinates to construct on a polygon P are
the triangulation coordinates, which require the triangulation of P followed by piece-

Shape Quality for Generalized Barycentric Interpolation
■35
n
HM*
WP
MV
DH
LS-1
LS-2
LS-3
ME-T
ME-U
4
1.5e0
0.0e0
4.5e-2
0.0e0
1.1e-1
8.3e-3
1.2e-2
0.0e0
0.0e0
8
1.9e0
5.0e-2
1.0e-2
5.0e-2
1.3e-1
9.9e-3
2.3e-2
7.5e-2
1.3e-1
16
1.9e0
7.9e-2
4.2e-2
7.9e-2
1.7e-1
5.5e-3
4.0e-2
8.2e-2
1.7e-1
32
2.0e0
8.8e-2
4.3e-2
8.8e-2
1.7e-1
2.3e-3
4.3e-2
6.8e-2
1.8e-1
64
2.0e0
9.1e-2
4.3e-2
9.1e-2
1.7e-1
9.7e-4
4.3e-2
5.2e-2
1.8e-1
128
2.0e0
9.2e-2
4.3e-2
9.2e-2
1.8e-1
5.8e-4
4.4e-2
3.9e-2
1.8e-1
256
2.0e0
9.2e-2
4.3e-2
9.2e-2
1.8e-1
5.0e-4
4.4e-2
2.9e-2
1.8e-1
Table 2.3 Comparison of some generalized barycentric coordinates over regular,
ﬁxed diameter polygons with n vertices. Coordinates and data are the same as
in Tables 2.1 and 2.2.
wise linear barycentric interpolation over each triangle. Of course, the choice of
triangulation matters signiﬁcantly to the quality of interpolation. For example, the
polygon in Figure 2.1a has three possible triangulations: one in which the center
top vertex is connected to all four vertices and two where the top three vertices
form an obtuse triangle. The ﬁrst of these options provides bounded interpolation
error independent of ϵ while the latter two yield large errors as ϵ shrinks.
As discussed in Section 2.3, the interpolation error can be large for triangles
with large angles or, equivalently, triangles with large circumradii. Given a set of
points (in our case, the vertices of P), the Delaunay triangulation is deﬁned as
the set of triangles with empty circumballs. The Delaunay triangulation provides a
valid triangulation for any convex polygon and tends to avoid triangles with large
circumradii as that would require the existence of a large empty ball passing through
three of the vertices of P. More precisely, the Delaunay triangulation has a number
of optimality properties: it maximizes the minimum angle [233, 359], minimizes the
Lp error for the function ∥x∥2 [92, 112, 327], and minimizes the H1-seminorm of
the interpolant [312, 326].
If P is non-convex, the constrained Delaunay triangulation [97] can be used
to construct triangulation coordinates. This modiﬁed deﬁnition ensures that the
edges of P exist in the triangulation while still avoiding large circumradii whenever
possible. In applications that only require a piecewise linear interpolant, such as
low-order ﬁnite element methods, triangulation coordinates using the (constrained)
Delaunay triangulation perform quite well compared to more elaborate generalized
barycentric coordinate types. To understand why this is the case, we turn next to
the smoothest possible interpolant: harmonic coordinates.
2.5.2
Harmonic coordinates
Since harmonic coordinates are the solution to a simple elliptic partial diﬀeren-
tial equation, the standard, simplicial ﬁnite element theory provides a connection
between triangulation coordinates (i.e., the discrete solution) and harmonic coor-
dinates (i.e., the continuous solution). Speciﬁcally, the theory guarantees that the

36
■Generalized Barycentric Coordinates in Graphics and Mechanics
H1-seminorm of the triangulation coordinates must be larger, up to a constant
factor depending on the diameter of the polygon, than that of the harmonic coor-
dinates. Thus, ﬁnding a class of polygons for which the triangulation coordinates
have bounded interpolation error estimates is suﬃcient to ensure bounded error in
the harmonic coordinates. Starting with triangulation coordinates provides a dis-
tinct advantage: since interpolation error is very well understood for triangles of all
types, there is no need to restrict our attention to a class of type pedge or pnv.
This line of analysis can be broadened to allow any triangulation of the poly-
gon, including any number of interior vertices, as long as the boundary of the
triangulation exactly matches the edges of the polygon; that is, no vertices of the
triangulation lie on edges of the polygon. The result is a straightforward approach
to analyzing harmonic coordinates on a class of type par: triangulate using a single
additional vertex placed at the center of the largest inscribed circle. A proof is given
in [164, Lemma 4].
Lemma 2.10. The inequality in (2.9) holds uniformly for the harmonic coordinates
on pcvx ∩par.
Attempting to relax the bounded aspect ratio restriction yields an even stronger
connection between triangulation and harmonic coordinates. Speciﬁcally, we show
in [163] that whenever the Delaunay triangulation of a convex polygon contains
a large circumradius triangle (which implies a poor interpolant via triangulation
coordinates), the harmonic coordinates are also large (in H1-norm). Selection of the
Delaunay triangulation is essential for this analysis. For example, the polygon in
Figure 2.1a can be triangulated in essentially two ways: one with an obtuse triangle
formed by the top three vertices and another in which the top vertex is connected
to all the other vertices. The former produces unbounded interpolation error as the
angle approaches 180◦, similar to Wachspress coordinates in Table 2.1, while the
latter, which is the Delaunay triangulation, has controlled interpolation error.
We study harmonic interpolation on non-convex polygons ﬁrst via numerical
experiment on a simple example depicted in Figure 2.1c. The interpolation error for
this case, with ϵ shrinking, is given in Table 2.4. However, this numerical experiment
is somewhat inconclusive: the H1 error is slightly increasing as ϵ is reduced but it
is not clear if the trend is approaching a ﬁxed value or growing unbounded.
The analysis given in [163] resolves this ambiguity. Whenever a family of poly-
gons contains this kind of conﬁguration where a polygon vertex can be arbitrarily
close to the interior of a non-adjacent edge, the interpolation error under harmonic
coordinates cannot be bounded. Hence, theoretically, the error must be unbounded
as ϵ →0 for all coordinates in Table 2.4. The details of this analysis are delicate
and involve estimates at the critical case of k = d/2 in the Sobolev embedding
theorem. Thus, it is not surprising that the divergence occurs very slowly.
The takeaway message is the following: poor quality triangles in the constrained
Delaunay triangulation of a polygon will cause interpolation error estimates to fail.
However, such situations pose few practical limitations as the error grows very
slowly, at least for harmonic coordinates.

Shape Quality for Generalized Barycentric Interpolation
■37
ϵ
HM*
MV
LS-1
LS-2
LS-3
ME-T
0.1600
2.4e0
8.2e-1
2.3e-0
4.2e-1
8.9e-1
1.4e-0
0.0400
2.2e0
7.4e-1
2.3e-0
3.0e-1
8.7e-1
1.4e-0
0.0100
2.4e0
7.6e-1
2.4e-0
2.6e-1
8.6e-1
1.6e-0
0.0025
2.6e0
8.2e-1
2.6e-0
2.4e-1
1.1e0
1.7e-0
Table 2.4 A comparison of some generalized barycentric coordinates over the family
of non-convex domains depicted in Figure 2.1c. Coordinates and data are the same
as in Tables 2.1 and 2.2, although only coordinates that are well-deﬁned on non-
convex polygons are included.
2.5.3
Wachspress coordinates
When analyzing explicitly deﬁned coordinates (beginning with Wachspress), we
follow an approach that hinges on deriving a uniform upper bound on the gradi-
ent of the coordinates. Selecting a class of polygons inside pcvx ∩par, the uniform
Sobolev embedding estimate holds by Lemma 2.8. Then, Proposition 2.3 ensures
that the desired interpolation error estimate holds. Thus the missing component of
the analysis is addressed in the following result. A proof is given in [164, Lemma
6].
Lemma 2.11. The inequality in (2.7) holds uniformly for the Wachspress coordi-
nates on pcvx ∩par ∩pedge ∩pmaxa.
Rather than provide the complete proof, we brieﬂy sketch why the geometric
conditions are suﬃcient for ensuring the gradient bound. Without loss of generality,
we consider a general diameter 1 polygon where the Wachspress coordinates are
constructed from weights of the form
wi = A(vi−1, vi, vi+1)
Y
j̸=i,i+1
A(vj−1, vj, x).
(2.13)
The relevant triangles [vi−1, vi, vi+1] and [vi−1, vi, x] for this construction are de-
picted in the top row of Figure 2.3.
In the class pcvx ∩par ∩pedge ∩pmaxa, weights can be bounded from above,
since Lemma 2.6 ensures an upper bound on the number of terms in the expression
and every triangle is a subset of the diameter 1 polygon. Further, gradients of the
weights can be written as
∇wi = A(vi−1, vi, vi+1)
X
k̸=i,i+1
∇A(vk−1, vk, x)
Y
j̸=i,i+1,k
A(vj−1, vj, x).
These summands can be bounded from above via a similar argument, namely, that
the norm of the gradient of a triangle area with respect to one of its vertices is
half the length of the opposite edge, which is certainly bounded in a diameter 1
polygon.

38
■Generalized Barycentric Coordinates in Graphics and Mechanics
vi
x
vi−1
vi+1
vi
vi−1
vi+1
vi
x
vi−1
vi+1
γi−1
γi
Figure 2.3 Notation and context for the interpolation error analysis of Wachspress
(top two ﬁgures) and mean value (bottom two ﬁgures) coordinates.
The Wachspress coordinates are constructed by normalizing the weights from
(2.13). Hence, to ensure the desired bound, we also must show that the sum of
the weights is bounded from below. First, we observe that the maximum interior
angle and edge length restrictions ensure that A(vj−1, vj, x) can be small for at
most 2 consecutive vertices, since x is very close to at most one vertex of the
polygon. So, for any x, there is one weight involving only non-small areas of the
form A(vj−1, vj, x) and the remaining term A(vi−1, vi, vi+1) also cannot be small,
again thanks to the geometric restrictions. The full proof is given in [164], but the
discussion above outlines the key points at which the geometric restrictions come
into play.
A slightly diﬀerent take on this result is given in [147, Theorem 2.3, d = 2], as
restated here.
Lemma 2.12. The inequality in (2.7) holds uniformly for the Wachspress coordi-
nates on pcvx ∩pvf.
Note that by Lemma 2.6 (i), a class of the form pcvx ∩par ∩pedge ∩pmaxa can be
recast as a class of the form pcvx ∩pedge ∩pmina ∩pmaxa, which by Lemma 2.9 can be
recast as a class of the form pcvx ∩pvf. Thus, Lemma 2.12 implies Lemma 2.11, al-
though it seems likely that the reverse implication is true as well. The generalization
of Lemma 2.12 to dimensions d ≥3 is discussed in Section 2.6.

Shape Quality for Generalized Barycentric Interpolation
■39
2.5.4
Mean value coordinates
The analysis of mean value coordinates follows the same lines as that of Wachspress
coordinates: we bound the L∞norm of the gradients of the individual coordinates
as in (2.7), which is suﬃcient to imply the interpolation error estimate. The key
diﬀerences are a new expression for the weights used to construct the coordinates
and the fact that it is no longer necessary to exclude interior angles close to 180◦.
A proof of the following result is given in [319, Theorem 1].
Lemma 2.13. The inequality in (2.7) holds uniformly for the mean value coordi-
nates on pcvx ∩par ∩pedge.
Mean value coordinates are constructed from weights of the form,
wi(x) =
tan

γi(x)
2

+ tan

γi−1(x)
2

∥vi −x∥
,
where the angles γi(x) are depicted in the bottom left image of Figure 2.3. The
subsequent analysis in [319] hinges on the observation that these weights get large
if either x is very close to a vertex of the polygon or if x is near one of the edges
of the polygon. In the latter case, one of the angles γi is near 180◦, causing the
associated tangent term to be large. The analysis is divided into a number of cases,
depending on which of these terms is nearly degenerate. The bottom right image in
Figure 2.3 shows a polygon subdivided into diﬀerent regions where these diﬀerent
cases apply. Lemma 2.7 helps to simplify this classiﬁcation by ensuring that a
vertex can only be near a limited number of polygon edges and vertices. Since the
coordinates involve normalization of the weight functions, large weight functions
do not prevent bounds on the coordinates and their gradients. In order to bound
the gradient in each case, these large terms are shown to be oﬀset by larger terms
in the denominator. The analysis requires the convexity of the polygon to ensure
all possible cases are covered; the non-convex case has not yet been considered.
2.6
INTERPOLATION ERROR ESTIMATES ON POLYHEDRA AND
POLYTOPES
Moving from polygons to polyhedra and general polytopes, the challenge of quanti-
fying shape quality becomes signiﬁcantly more complex. Metrics involving polygo-
nal interior angles (i.e., pmina and pmaxa) are essential in two-dimensional analysis,
but do not have natural extensions to higher dimensions; dihedral angles are perhaps
the closest analogue. Moreover, there are fewer deﬁnitions of generalized barycen-
tric coordinates in higher dimensions, due in part to the fact that the restriction of
such coordinates to a possibly non-simplicial boundary facet should produce a lower
dimensional generalized barycentric coordinate in some pre-determined fashion. For
simplicity, some constructions (e.g., mean value coordinates) restrict their deﬁni-
tions to polytopes with simplicial boundary faces, although others (e.g., harmonic

40
■Generalized Barycentric Coordinates in Graphics and Mechanics
and maximum entropy coordinates) are deﬁned without restriction. The interpola-
tion error has been analyzed under some strong geometric restrictions for harmonic
and Wachspress coordinates, as discussed below.
2.6.1
Harmonic coordinates in 3D and higher
Based on the very general theory of elliptic partial diﬀerential equations, much
of the analysis of harmonic coordinates applies to arbitrary dimensions. Only two
key diﬀerences impact the ﬁnal conclusions and statement of our results from the
polygonal setting: the circumradius is no longer a good measure of simplex quality
and the Sobolev embedding theorem allows more kinds of discontinuous functions
in higher dimensions. We discuss each in turn.
Tetrahedra known as “slivers,” deﬁned by four vertices lying near a common
circle, provide a simple example of the challenges of interpolation error analysis in
three dimensions and higher. Slivers have a modest circumradius relative to their
diameter but have a poor aspect ratio and exhibit large errors in linear interpolation.
Accordingly, the 3D analogue of the constrained Delaunay triangulation, which
minimizes large circumaradii, cannot be expected to control interpolation on par
with harmonic coordinates.
Broadly speaking, the Sobolev embedding theorem describes which Sobolev
spaces admit discontinuous functions and which contain only continuous ones. Two
critical parameters in this regard are the spatial dimension, d, and the exponent used
in integration, p. Discontinuous functions are admitted in the associated Sobolev
space W 1,p(Ω) when d > p, and, as d increases with p ﬁxed, more functions are
included in the space.
What do these facts imply about harmonic coordinates? While harmonic coor-
dinates can still be estimated by comparison to triangulation coordinates via a valid
tetrahedralization of the domain, there is not a clear procedure for identifying the
“best” tetrahedralization. Further, while it is true in d = 2 that the presence of a
vertex near a non-incident edge of the polygon causes poor interpolation, analogous
conﬁgurations in 3D still allow good interpolation errors. The shape quality metric
of bounded aspect ratio can and is used to control the interpolation error, despite
the fact that this is an overly restrictive geometric assumption. A sharp metric for
harmonic coordinates in 3D is still unknown.
2.6.2
Wachspress coordinates in 3D and higher
One of the few types of generalized barycentric coordinates on polyhedra that is
both relatively simple to implement and amenable to error analysis is the general-
ization of Wachspress coordinates by Warren et al. [411, 413]. Floater et al. [147]
provide MATLABTM code for the computation of these coordinates on generic convex
polyhedra and derive an interpolation error bound over a subclass of simple, convex
polyhedra.
A d-dimensional polytope is called simple if every vertex is incident to exactly
d faces of dimension d −1. In particular, every polygon is simple, every simplex

Shape Quality for Generalized Barycentric Interpolation
■41
is simple, and polyhedra generated from a Voronoi diagram are simple if the seed
points are in general position. We introduce the associated class of polytopes:
psimp
— P is simple.
The following result is a generalization of Lemma 2.12 to d dimensions. Recall
the deﬁnition of pvf from the end of Section 2.4; the following result is from [147,
Theorem 2.3].
Lemma 2.14. Fix d ≥2. Then the inequality in (2.7) holds uniformly for the
Wachspress coordinates on pcvx ∩pvf ∩psimp.
A sketch of the proof is as follows. First, the quantity ∥∇φi(x)∥is bounded
by terms that are O(hf(x)−1); recall that hf(x) is the distance from point x to
face f. These estimates are summed over all the vertices of P and regrouped. Since
the function hf(x) is aﬃne in x, it can be written as a linear combination of
{φi(x)}, allowing further simpliﬁcation of the estimate. Since P ∈pvf, we have
hf(x) ≥h∗(P) > 0 and since P ∈psimp, we can factor out 2d to produce the result.
As highlighted by the above proof and other results in [147], the sum of gra-
dients of Wachspress coordinates scales roughly like h−1
∗. Thus, if h∗is small, we
would expect the Wachspress coordinates to have poor interpolation properties. Any
polyhedron with a large dihedral angle has a small value of h∗, meaning any mesh-
ing scheme designed to allow Wachspress interpolation on the output mesh should
aim to avoid large dihedral angles. Further analysis along these lines remains an
important direction for future work.
2.7
EXTENSIONS AND FUTURE DIRECTIONS
The results from this chapter focus on interpolation error estimates for generalized
barycentric coordinates in the context of linear ﬁnite element methods on polygo-
nal and polyhedral meshes for scalar-valued elliptic partial diﬀerential equations.
In [320], we have shown how to construct basis functions for quadratic order ﬁnite
elements on polygons by taking linear combinations of pairwise products of gener-
alized barycentric coordinates. The gradients of such functions have terms of the
form φi∇φj and thus our estimates on ∥∇φj∥remain a crucial ingredient in error
estimates for such higher order methods.
In [165], we have shown how to construct basis functions for linear order, vector-
valued, H(curl)- and H(div)-conforming elements on polygons and polyhedra. Our
construction uses generalized barycentric functions and their gradients in forms
like φi∇φj −φj∇φi, mimicking the approach of Whitney functions for barycentric
coordinates on simplices. Again, the bounds on ∥∇φj∥explained in this chapter are
necessary in the error analysis of such methods.
At the beginning of this chapter we raised the question of whether a change in
mesh or an alternative selection of generalized barycentric coordinate type could
ﬁx a simulation code that would otherwise crash. The answer is certainly yes, both
approaches can improve numerical methods for interpolation. In particular, the
Wachspress, discrete harmonic, and maximum entropy coordinates with the uniform

42
■Generalized Barycentric Coordinates in Graphics and Mechanics
prior were shown to provide poor interpolation on polygons with large angles and
are not deﬁned on non-convex polygons. Changing the coordinate type or remeshing
to avoid large angles and non-convex polygons avoids this failure.
On the other hand, our numerical experiments also demonstrate the surprising
robustness of many coordinate types against extremely degenerate polygonal ge-
ometry. For instance, the element family of a quadrilateral collapsing to a triangle
(Figure 2.1b) does not belong to the class pedge nor the class pvf, excluding the
Wachspress and mean value coordinates from the gradient estimates guaranteed by
Lemma 2.11, Lemma 2.12, and Lemma 2.13. Nevertheless, the interpolation error
remains small for all the coordinates that we tested on this family. Additional analy-
sis and experiments will help sharpen existing gradient estimates and shape quality
metrics in ways that increase their relevance to practical application settings.

C H A P T E R 3
Transfinite Barycentric
Coordinates
Alexander G. Belyaev
Heriot-Watt University, Edinburgh, UK
Pierre-Alain Fayolle
University of Aizu, Aizuwakamatsu, Japan
CONTENTS
3.1
Introduction ......................................................
44
3.2
Weighted mean value interpolation ..............................
45
3.2.1
General construction .....................................
45
3.2.2
Transﬁnite three-point coordinates ......................
47
3.2.3
Transﬁnite Laplace coordinates ..........................
48
3.2.4
Transﬁnite Wachspress coordinates ......................
49
3.2.5
Transﬁnite Laplace and Wachspress coordinates coincide
for a disk .................................................
51
3.3
Gordon–Wixom interpolation ....................................
51
3.3.1
Lagrange-type Gordon–Wixom interpolation ............
51
3.3.2
Hermite-type Gordon–Wixom interpolation .............
54
3.3.3
Modiﬁed Hermite-type Gordon–Wixom interpolation ...
55
3.3.4
Modiﬁed Gordon–Wixom for polyharmonic interpolation
56
3.4
Generalized mean value potentials and distance function
approximations ..................................................
57
3.4.1
Generalized mean value potentials for smooth domains .
57
3.4.2
Generalized potentials for polygons ......................
61
43

44
■Generalized Barycentric Coordinates in Graphics and Mechanics
I
N THIS CHAPTER we study properties of transﬁnite barycentric interpola-
tion schemes, which can be considered as continuous counterparts of generalized
barycentric coordinates and are currently a subject of intensive research due to
their fascinating mathematical properties and numerous applications in computa-
tional mechanics [170, 344], computer graphics [247, 248], and geometric modeling
[93, 145, 227, 413] (see also references therein).
We start from a general construction of transﬁnite barycentric coordinates,
which is obtained as a simple and natural generalization of Floater’s mean value
coordinates [144, 217], and investigate the properties of the continuous analogues
of three-point coordinates [149]. We discuss the Gordon–Wixom interpolation ap-
proach [171] and consider its generalizations and modiﬁcations [37, 38]. Finally we
introduce generalized mean value potentials and demonstrate how they can be used
for distance function approximation purposes [40].
3.1
INTRODUCTION
While traditional generalized barycentric coordinates interpolate function values
given at the vertices of a polygon or polyhedron, transﬁnite barycentric interpo-
lation is based on smooth domains. Transﬁnite barycentric interpolation schemes
establish bridges between barycentric coordinates and methods used to interpolate
continuous data [38, 77, 93, 133, 151, 153, 171]. In addition, studying continuous
versions of generalized barycentric coordinates helps us to achieve a better under-
standing of their discrete counterparts [37, 93, 248, 346, 413].
Similar to the discrete case (see Section 1.1.2), let us consider a convex domain
Ωin Rd and a smooth function φ(x, y), x ∈Ωand y ∈∂Ω, satisfying the two
properties
Partition of unity:
ˆ
∂Ω
φ(x, y) dsy = 1,
(3.1)
Linear precision:
ˆ
∂Ω
y φ(x, y) dsy = x,
(3.2)
which are the continuous analogues of Conditions (1.8) and (1.9) in Deﬁnition 1.1.
Now the transﬁnite interpolant of some function u(y) deﬁned on ∂Ωinto Ωis given
by
u(x) =
ˆ
∂Ω
u(y)φ(x, y) dsy.
(3.3)
In mathematical terminology, φ(x, y) is the kernel of the integral operator deﬁned
by the right-hand side of (3.3).
Our main task is to establish links between various barycentric coordinates
and the general transﬁnite interpolation construction described by (3.3) with some
kernel φ(x, y) satisfying (3.1) and (3.2).
In this chapter, we assume that the domain Ωis convex and bounded. In prac-
tice, of course, we would like to work with non-convex domains as well. An eﬃcient

Transﬁnite Barycentric Coordinates
■45
and simple way to extend barycentric interpolation schemes to simply connected
non-convex domains is proposed in [200]. An even simpler approach to deal with
non-convex domains is suggested in [251]. We brieﬂy discuss both approaches at
the end of Section 3.2.
3.2
WEIGHTED MEAN VALUE INTERPOLATION
3.2.1
General construction
Let us start from the transﬁnite mean value interpolation scheme proposed in [217].
Let Ωbe a bounded convex domain and x be a point inside Ω. Consider the unit
sphere Sx centered at x and assume that Sx is parameterized by its outer unit
normal eθ. Let y be a point on ∂Ωand ρ = ∥x −y∥. Denote by z the intersection
point between the ray [x, y) and Sx (see Figure 3.1, left). If we assume that we
know the values of the function u on ∂Ωand at x, then we can estimate u(z) using
linear interpolation,
u(z) ≈(ρ −1)u(x) + u(y)
ρ
.
Now, applying S-averaging (circular averaging in the 2D case and spherical aver-
aging in the 3D case) to the left and right sides of the above equation yields
ˆ
Sx
u(z) dθ = |Sx|u(x) −u(x)
ˆ
Sx
dθ
∥x −y∥+
ˆ
Sx
u(y) dθ
∥x −y∥,
where dθ is the area element of the unit sphere Sx at z ∈Sx (to distinguish the 2D
case we denote the angular element of the unit circle by dθ), and |Sx| is the unit
sphere area. Assuming that u is harmonic, we arrive at the transﬁnite mean value
interpolation scheme
u(x) =
ˆ
Sx
u(y) dθ
∥x −y∥
 ˆ
Sx
dθ
∥x −y∥.
(3.4)
It is interesting that instead of mimicking the mean value property of harmonic
functions we can derive (3.4) from the simple observation that the spherical (circular
Figure 3.1 Left: notation used to deﬁne weighted mean value interpolation. Right:
if Ωis non-convex, then the rays emitted from x ∈Ωmay intersect ∂Ωin multiple
points.

46
■Generalized Barycentric Coordinates in Graphics and Mechanics
in the 2D case) mean of all the directional derivatives of a given smooth function is
equal to zero. Now, approximating the directional derivative of u in the direction of
the ray [x, y) by (u(y)−u(x))/∥x −y∥and averaging with respect to all directions
yields
ˆ
Sx
u(y) −u(x)
∥x −y∥
dθ = 0,
which is equivalent to (3.4).
The interpolation scheme (3.4) allows for a natural generalization
u(x) =
ˆ
Sx
u(y)ω(x, eθ)
∥x −y∥
dθ
 ˆ
Sx
ω(x, eθ)
∥x −y∥dθ,
(3.5)
where ω(x, eθ) is a weighting function that may depend on the interpolated lo-
cation x and the direction eθ. It is easy to see that (3.5) is just another form of
(3.3) and we can also consider (3.5) as a transﬁnite version of the basic Shepard
interpolation [354].
Let us check when (3.5) satisﬁes the linear precision property (3.2). Setting
u(x) ≡x yields u(y) ≡y = x + ρ eθ. Substituting the latter into (3.5) gives
0 =
ˆ
Sx
eθ ω(x, eθ) dθ
∀x ∈Ω,
(3.6)
which is necessary and suﬃcient for linear precision. One can see that (3.6) is
satisﬁed, if the weighting function is centrally symmetric and coincides at each pair
of antipodal points,
ω(x, eθ) = ω(x, −eθ).
Consider now the case of planar interpolation with d = 2 and eθ = (cos θ, sin θ),
u(x) =
ˆ 2π
0
u(y)ω(x, θ)
∥x −y∥
dθ
 ˆ 2π
0
ω(x, θ)
∥x −y∥dθ.
(3.7)
Then, (3.6) becomes
ˆ 2π
0
ω(x, θ) cos θ dθ = 0 =
ˆ 2π
0
ω(x, θ) sin θ dθ
∀x ∈Ω.
(3.8)
If ω(x, θ) satisﬁes (3.8), then by using the Fourier series expansion
ω(x, θ) =
X
cn(x)einθ,
i =
√
−1,
it is easy to show that there exists p(x, θ) such that
p′′
θθ(x, θ) + p(x, θ) = ω(x, θ).
(3.9)
Here and below we often use prime-notations for the ﬁrst- and second-order deriva-
tives with respect to θ:
(·)′
θ
stands for
d
dθ(·)
and
(·)′′
θθ
stands for
d2
dθ2 (·).

Transﬁnite Barycentric Coordinates
■47
The orthogonality condition (3.8) can be veriﬁed by simple integration by parts,
ˆ 2π
0
ω(x, θ)eiθdθ =
ˆ 2π
0
 ∂2
∂θ2 p + p

eiθdθ =
ˆ 2π
0
p(x, θ)
 ∂2
∂θ2 eiθ + eiθ

dθ = 0.
Representation (3.9) has an interesting geometric interpretation. Given a curve
Σ and a point x, the geometry of Σ is determined by its support function p(x, θ),
the signed distance from x to the tangents of Σ. The support function satisﬁes the
second-order diﬀerential equation
p′′
θθ + p = R(θ) ≡1/k(θ),
where k(θ) is the curvature of Σ and R(θ) is the radius of curvature of Σ. See, for
example, [345] for details.
Now we can interpret (3.9) as follows. Each x ∈Ωdeﬁnes a closed curve Σx with
radius of curvature R = ω(x, θ). The orthogonality condition (3.8) then corresponds
to
ˆ 2π
0
nR dθ ≡
ˆ
Σx
n dl = 0,
where n = (cos θ, sin θ) is the outer unit normal of Σx and l denotes the arc-length
parametrization of Σx. For example, Σx is a unit circle for the 2D transﬁnite mean
value coordinates and it is a unit sphere in R3 for the three-dimensional transﬁnite
mean value coordinates.
If Ωis not convex, then a ray emitted from x ∈Ωmay intersect ∂Ωin multiple
points (see Figure 3.1, right). One way to cope with this situation is proposed in
[200] and consists of using alternating signs for intersection points. For instance,
the example shown in the right image of Figure 3.1 leads to
u(y1)
∥x −y1∥−
u(y2)
∥x −y2∥+
u(y3)
∥x −y3∥
instead of u(y)/∥x −y∥in (3.5). However, in practice it is often better to fol-
low a simpler approach suggested in [251] and consider only the ﬁrst intersections:
u(y1)/∥x −y1∥instead of u(y)/∥x −y∥in (3.5). For example, we use such a sim-
pliﬁcation in our numerical experiments with the so-called Gordon–Wixom coordi-
nates and their extensions (see Section 3.3 and Figure 3.4).
3.2.2
Transﬁnite three-point coordinates
A general construction for discrete three-point coordinates (see Section 1.2.4) was
introduced in [149]. Let A(x, y, z) denote the signed area of the triangle formed by
points x, y, and z, Given a convex polygon with vertices v1, v2, . . . , vn and some
point x inside the polygon, consider the signed triangle areas Ai(x) = A(x, vi, vi+1)
and Bi(x) = A(x, vi−1, vi+1). Then, according to [149], the three-point coordinates
are given by the weights
wi = F(ri+1)Ai−1 −F(ri)Bi + F(ri−1)Ai
Ai−1Ai
,
(3.10)

48
■Generalized Barycentric Coordinates in Graphics and Mechanics
where ri = ∥x −vi∥and F(r) is an arbitrary function. Following [149], one can
also rewrite (3.10) as
wi = 2
ri
f(ri+1) −f(ri) cos θi
sin θi
+ f(ri−1) −f(ri) cos θi−1
sin θi−1

,
(3.11)
where f(r) = F(r)/r and θi is the angle between the rays [x, vi) and [x, vi+1).
Assuming that f(r) is suﬃciently smooth, the number of vertices of the polygon
tends to inﬁnity, and all θi uniformly tend to zero, θi ≈dθ →0, we then have
f(ri+1) −f(ri) cos θi
sin θi
≈

f(ρ(θ))′
θ + f(ri)θi
2

ρ=ri+1
,
f(ri−1) −f(ri) cos θi−1
sin θi−1
≈

−f(ρ(θ))′
θ + f(ri)θi−1
2

ρ=ri
,
hence (3.11) is approximately equal to
2
ρ
 f(ρ(θ))′′
θθ + f(ρ(θ))

ρ=ri
dθ.
This implies that the continuous or transﬁnite version of the three-point coordinates
is described by (3.7) with
ω(x, θ) = f(ρ(θ))′′
θθ + f(ρ(θ)).
(3.12)
3.2.3
Transﬁnite Laplace coordinates
Following [37, 94], let us deﬁne transﬁnite Laplace coordinates as the continuous
version of discrete harmonic coordinates [309] (see Section 1.2.2), which are used
widely in computational mechanics [375]. As discrete harmonic coordinates corre-
spond to (3.10) with F(r) = r2, their continuous version is given by (3.7) with the
weight (3.12), where f(r) = r. In other words,
ω(x, θ) = ρ(θ)′′
θθ + ρ(θ).
(3.13)
It turns out that (3.13) can also be derived by mimicking the Dirichlet energy
minimization property of harmonic functions [37, 346]. Given u(y), deﬁned for
each y ∈∂Ω, let us choose x ∈Ωand assume that u(x) is known. Consider a ruled
surface patch generated by straight segments connecting the inner point (x, u(x))
with the boundary points (y, u(y)). Now the value u(x) is deﬁned such that the
Dirichlet energy of the constructed ruled surface attains its minimal value.
Let (r, θ) be the polar coordinates centered at x. Then ∂Ωis described by
r = ρ(θ). The ruled surface associated with x is given by
Ux(z) = (ρ −r)u(x) + ru(y)
ρ
,

Transﬁnite Barycentric Coordinates
■49
where r = ∥x −z∥and y ∈∂Ωdenotes the intersection point between ∂Ωand the
ray from x through z. We then arrive at the minimization problem
min ←
ˆ
Ω
|∇Ux|2dz
=
ˆ 2π
0
dθ
ˆ ρ
0
r dr
 u(x) −u(y)
ρ
2
+
 u(y) −u(x)
1
ρ
′
θ
+ 1
ρu′
θ(y)
2!
= 1
2
ˆ 2π
0
dθ
 

u(x) −u(y)
2 +

u′
θ(y) +
 u(y) −u(x)
ρ′
θ
ρ
2!
,
where the last integral is a quadratic function with respect to u(x). Thus the optimal
value of u(x) is given by
u(x) =
ˆ 2π
0

u(y) −u′
θ(y)[ρ′
θ/ρ] + u(y)[ρ′
θ/ρ]2
dθ
 ˆ 2π
0

1 + [ρ′
θ/ρ]2
dθ. (3.14)
Integration by parts yields
−
ˆ 2π
0
u′
θ(y)[ρ′
θ/ρ] dθ =
ˆ 2π
0
u(y)[ρ′
θ/ρ]′
θ dθ =
ˆ 2π
0
u(y)

ρ′′
θθ/ρ −(ρ′
θ/ρ)2
dθ,
ˆ 2π
0
[ρ′
θ/ρ]2dθ =
ˆ 2π
0
 ρ′′
θθ/ρ −[ρ′
θ/ρ]′
θ

dθ =
ˆ 2π
0
(ρ′′
θθ/ρ) dθ,
and thus (3.14) is equal to
ˆ 2π
0
u(y)ρ′′
θθ + ρ
ρ
dθ
 ˆ 2π
0
ρ′′
θθ + ρ
ρ
dθ.
(3.15)
One can now see that (3.15) corresponds to (3.7) with (3.13).
3.2.4
Transﬁnite Wachspress coordinates
As demonstrated in [149], Wachspress coordinates (see Section 1.2.1) can be de-
scribed by (3.10) with F(r) ≡1. This yields (3.7) with
ω(x, θ) = (1/ρ)′′
θθ + 1/ρ
(3.16)
and corresponds to a curve Σx whose radius of curvature is given by (3.16). The
domain enclosed by Σx is the polar dual (polar reciprocal) of Ωwith respect to
x ∈Ω[179] (see also [307] for modern proofs of properties of the polar duals).
Interesting relationships between Wachspress coordinates and polar duals are es-
tablished in [218, 346]. Below, for the 2D case, we link together (3.16), polar duals,
and a curvature formula derived in [413].
Let ∂Ωbe described by the radius vector r whose tail is situated at x ∈Ω.
Denote by t and n the unit tangent and normal vectors forming the Frenet frame

50
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 3.2 The Frenet frame (t, n) for ∂Ωis one of our main tools for studying
geometric quantities of ∂Ωwith respect to x ∈Ω.
for ∂Ω, as shown in Figure 3.2. Let s be the arc-length parameterization of ∂Ω. We
then have
t′ = kn,
n′ = −kt,
r = gt + hn
with
g = r · t
and
h = r · n,
where the derivatives are taken with respect to the arc-length s and k denotes the
curvature of ∂Ω.
It is easy to show [307] that the polar reciprocal curve Σx is given by the radius
vector n/h. Then a tangent vector for Σx can be obtained by
n
h
′
= n′h −nh′
h2
= −kth + nkg
h2
= gn −ht
p
g2 + h2
kρ
h2 ,
(3.17)
where the simple observations that
h′ = (r·n)′ = r′·n+r·n′ = r·n′ = −k r·t = −kg
and
p
g2 + h2 = |r| = ρ
are used. Normalizing the tangent vector given by the right-hand side of (3.17) gives
dl/ds = kρ/h2,
where l is the arc-length of Σx. The unit normal for Σx is given by nΣ = r/ρ.
Now we can ﬁnd the curvature kΣ of Σx by diﬀerentiating its unit normal nΣ with
respect to l,
d
dlnΣ = −kΣtΣ
with
nΣ = r
ρ = gt + hn
p
g2 + h2
and
tΣ = −n⊥
Σ = ht −gn
p
g2 + h2 ,
where ⊥denotes the π/2 rotation in a clockwise direction. Further,
d
dl = ds
dl
d
ds,
d
ds
r
ρ

= r′ρ −rρ′
ρ2
= tρ −rg/ρ
ρ2
= h2t −ghn
ρ3
= h
ρ2
ht −gn
p
g2 + h2 ,
d
dlnΣ = ds
dl
d
ds
r
ρ

= h2
kρ
d
ds
r
ρ

= h3
kρ3 tΣ = −kΣtΣ.
Thus the curvature kΣ of Σx is given by
kΣ = −h3
kρ3 = −[n(y) · (y −x)]3
k(y)∥x −y∥3

Transﬁnite Barycentric Coordinates
■51
Figure 3.3 Notation used to demonstrate that transﬁnite Laplace and Wachspress
coordinates coincide if Ωis a disk.
and therefore
−dθ
kΣ
= kρ3
h3 dθ = kρ
h2 ds,
ˆ
∂Ω
r k ds
h2 =
ˆ
∂Ω
ρeθ
k ds
h2 = −
ˆ 2π
0
dθ
kΣ
= 0,
which is in agreement with [413].
3.2.5
Transﬁnite Laplace and Wachspress coordinates coincide for a disk
As shown in [149], discrete harmonic and Wachspress coordinates are the same for
a circumscribable polygon. The continuous or transﬁnite version of this remarkable
result is established in [93]. Below we give a diﬀerent and elementary proof that
transﬁnite Laplace and Wachspress coordinates coincide if Ωis a disk.
Using the notations of Figure 3.3 we have
cos θ = ρ2 + r2 −R2
2ρr
= Aρ −B 1
ρ
for some values of A and B, which do not depend on θ. Thus,
0 = (cos θ)′′ + cos θ = A

ρ′′
θθ + ρ

−B

(1/ρ)′′
θθ + 1/ρ

.
It remains to note that the kernels ρ′′
θθ + ρ and (1/ρ)′′
θθ + 1/ρ correspond to the
transﬁnite Laplace and Wachspress coordinates, respectively.
3.3
GORDON–WIXOM INTERPOLATION
3.3.1
Lagrange-type Gordon–Wixom interpolation
Harmonic coordinates and harmonic mappings deliver extremely useful tools for
high quality interpolation and shape deformation [95, 101, 241] (see also references
therein). However, harmonic mappings and coordinates do not allow for closed-form
solutions in general and sophisticated numerical schemes are required for comput-
ing accurate approximations. One possible way to overcome this diﬃculty con-
sists of using mappings and coordinates, which can be calculated eﬀortlessly and
mimic some properties of harmonic mappings and coordinates. In particular, the
so-called pseudo-harmonic barycentric coordinates [94, 247] can be considered as

52
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 3.4 The main idea behind Gordon–Wixom interpolation consists of combin-
ing linear interpolation for each chord passing through x with circular averaging
with respect to all directions eθ.
potentially good substitutes for harmonic coordinates [215]. Below we consider a
pseudo-harmonic transﬁnite barycentric interpolation scheme introduced initially
by Gordon and Wixom [171] and then studied and extended by a number of re-
searchers [37, 38, 145, 146, 266].
Following [171], let us call a transﬁnite barycentric interpolation scheme pseudo-
harmonic if it reproduces harmonic functions in a ball (a disk in the 2D case). It
turns out that transﬁnite mean value (3.4), Laplace (3.13), and Wachspress coordi-
nates (3.16) are not pseudo-harmonic [37]. In contrast, the Gordon–Wixom inter-
polation scheme [171] and some of its generalizations and modiﬁcations [37, 38] are
pseudo-harmonic.
The basic idea behind the approach of Gordon and Wixom is simple and elegant.
Given a point x inside a bounded convex domain Ω⊂R2, consider a straight line
passing through x, forming an angle θ with some ﬁxed direction, and intersecting ∂Ω
in two points y1 and y2 (see Figure 3.4). We then use linear interpolation between
u(y1) and u(y2) to obtain an estimate u(x, θ) associated with the direction θ,
u(y1)
ρ1
+ u(y2)
ρ2
 1
ρ1
+ 1
ρ2

.
Circular averaging of u(x, θ) with respect to θ then yields the Gordon–Wixom
interpolation of some function u from ∂Ωto x ∈Ω,
u(x) = 1
2π
ˆ 2π
0
u(y1)
ρ1
+ u(y2)
ρ2
 1
ρ1
+ 1
ρ2

dθ.
(3.18)
To demonstrate that the Gordon–Wixom interpolation scheme is pseudo-
harmonic, we rewrite (3.18) as
u(x) = 1
π
ˆ 2π
0
ρ2
ρ1 + ρ2
u(y1) dθ
(3.19)
and assume that Ωis a disk of radius R. We now recall that, according to the
intersecting chords theorem,
ρ1ρ2 ≡c(x),
where c(x) depends only on x. In the notation of Figure 3.5 we further have
h1 = ρ1 sin ϕ,
h2 = ρ2 sin ϕ,
ρ1 + ρ2 = 2R sin ϕ,

Transﬁnite Barycentric Coordinates
■53
Figure 3.5 Geometric notation used to demonstrate that the Gordon–Wixom inter-
polation scheme (3.18) and its modiﬁcation (3.22) reproduce harmonic functions if
Ωis a disk.
h1h2
sin2 ϕ = c(x),
ρ2
ρ1 + ρ2
=
h2
2R sin2 ϕ = c(x)
2R
1
h1
.
Thus, (3.19) reduces to
u(x) =
ˆ 2π
0
u(y) dθ
h(x, y)
 ˆ 2π
0
dθ
h(x, y),
(3.20)
where h(x, y) denotes the distance from x ∈Ωto the straight line tangent to ∂Ω
at y ∈∂Ω. It is easy to see that the length element dsy of ∂Ωat y ∈∂Ωis given
by
dsy = ρ2dθ/h
with
ρ = ∥x −y∥
and
h = h(x, y).
Thus, (3.20) can be rewritten as
u(x) =
ˆ
∂Ω
u(y) dsy
∥x −y∥2
 ˆ
∂Ω
dsy
∥x −y∥2 ,
which is equivalent to the classical Poisson integral formula for recovering the values
of a harmonic function inside a disk from its boundary values.
Another connection between the Gordon–Wixom approach and harmonic inter-
polation can be derived from the following observation. If ρ1 and ρ2 are small, then
we can write
∂2u
∂e2
θ
(x) ≈
2
ρ1ρ2
u(y1)
ρ1
+ u(y2)
ρ2
 1
ρ1
+ 1
ρ2

−u(x)

.
(3.21)
Note that
1
π
ˆ 2π
0
∂2
∂e2
θ
dθ = 1
π
ˆ 2π
0

cos θ ∂
∂x1
+ sin θ ∂
∂x2
2
dθ = ∆,
which together with (3.21) implies
∆u ≈2
π
ˆ 2π
0
u(y1)
ρ1
+ u(y2)
ρ2
 1
ρ1
+ 1
ρ2

−u(x)
 dθ
ρ1ρ2
.

54
■Generalized Barycentric Coordinates in Graphics and Mechanics
Mimicking harmonic interpolation thus leads to the modiﬁcation of the Gordon–
Wixom scheme (3.18)
u(x) =
ˆ 2π
0
u(y1)
ρ1
+ u(y2)
ρ2
 1
ρ1
+ 1
ρ2
 dθ
ρ1ρ2
 ˆ 2π
0
dθ
ρ1ρ2
,
(3.22)
which was obtained in [38]. In some sense, (3.22) resembles the transﬁnite mean
value interpolation scheme (3.4).
The modiﬁed Gordon–Wixom interpolation scheme (3.22) is also pseudo-
harmonic. Indeed, if Ωis a circle, then ρ1ρ2 in (3.22) does not depend on the
integration variable θ and (3.22) reduces to (3.18), which is pseudo-harmonic. The
modiﬁed Gordon–Wixom scheme also has linear precision.
Both (3.18) and (3.22) can be considered as particular cases of weighted mean
value transﬁnite interpolation (3.7). Indeed, both can be rewritten as
u(x) =
ˆ 2π
0
u(y1)
ρ1
+ u(y2)
ρ2
 1
ρ1
+ 1
ρ2

˜ω(x, θ) dθ
 ˆ 2π
0
˜ω(x, θ) dθ, (3.23)
where the weighting functions ˜ω(x, θ) in (3.23) and ω(x, θ) in (3.7) are related by
˜ω(x, θ) = (1/ρ1 + 1/ρ2)ω(x, θ).
Setting ˜ω(x, θ) = (1/ρ1 + 1/ρ2) in (3.23) corresponds to the transﬁnite mean value
interpolation scheme (3.4), choosing ˜ω(x, θ) = 1 yields the Gordon–Wixom scheme
(3.18), and ˜ω(x, θ) = 1/(ρ1ρ2) gives the modiﬁed Gordon–Wixom scheme (3.22).
In practice (3.22) demonstrates a higher quality of interpolation compared with
(3.18). In our numerical experiments (3.18) and (3.22) are evaluated using the
composite trapezoidal rule (typically 100 equispaced directions are used). For non-
convex domains, the ray [x, y) deﬁned by the unit vector eθ can intersect the
boundary at more than one point. For the two opposite directions eθ and −eθ we
consider the intersections y1 and y2 that are closest to x, respectively. Figure 3.6
compares the approximations obtained with the Gordon–Wixom scheme (3.18) and
its modiﬁcation (3.22) for a harmonic function x3−3xy2 in a geometrically complex
domain. The absolute errors between the given function and its interpolations is
used to illustrate the advantages of (3.22) over (3.18).
3.3.2
Hermite-type Gordon–Wixom interpolation
Gordon and Wixom extended their scheme in [171] to handle Hermite-type inter-
polation. Replacing linear interpolation with cubic interpolation of (u(y1), u′(y1))
and (u(y2), u′(y2)) gives
u(x, θ) = (3ρ1 + ρ2)ρ2
2
(ρ1 + ρ2)3 u(y1) + (ρ1 + 3ρ2)ρ2
1
(ρ1 + ρ2)3 u(y2)
−
ρ1ρ2
2
(ρ1 + ρ2)2
∂u
∂eθ
(y1) +
ρ2
1ρ2
(ρ1 + ρ2)2
∂u
∂eθ
(y2).
(3.24)

Transﬁnite Barycentric Coordinates
■55
Figure 3.6 The original (top left) and modiﬁed (top right) Gordon–Wixom interpo-
lation schemes (3.18) and (3.22) are used to interpolate a polynomial in a geomet-
rically complex domain. The modiﬁed scheme yields a lower approximation error
(bottom right) than the original scheme (bottom left).
Averaging (3.24) with respect to θ leads to the Hermite-type Gordon–Wixom in-
terpolation scheme
u(x) = 1
2π
ˆ 2π
0
u(x, θ) dθ.
(3.25)
The transﬁnite interpolation scheme (3.25) has cubic precision and reproduces bi-
harmonic functions if Ωis a disk. The biharmonic property was conjectured in [171]
and rigorously proved in [145].
3.3.3
Modiﬁed Hermite-type Gordon–Wixom interpolation
If ρ1 and ρ2 are small, then an approximation of the 4th-order directional derivative
of u(x) in the direction of eθ is given by
∂4u
∂e4
θ
(x) ≈
24
ρ2
1ρ2
2

u(x) −(3ρ1 + ρ2)ρ2
2
(ρ1 + ρ2)3 u(y1) −(ρ1 + 3ρ2)ρ2
1
(ρ1 + ρ2)3 u(y2)
+
ρ1ρ2
2
(ρ1 + ρ2)2
∂u
∂eθ
(y1) −
ρ2
1ρ2
(ρ1 + ρ2)2
∂u
∂eθ
(y2)

.
(3.26)

56
■Generalized Barycentric Coordinates in Graphics and Mechanics
Combining (3.26) with
4
3π
ˆ 2π
0
∂4u
∂e4
θ

dθ = ∆2u
(3.27)
and mimicking biharmonic interpolation then leads to a modiﬁed version of the
cubic Gordon–Wixom interpolation scheme,
u(x) =
ˆ 2π
0
(3ρ1 + ρ2)ρ2
2
(ρ1 + ρ2)3 u(y1) + (ρ1 + 3ρ2)ρ2
1
(ρ1 + ρ2)3 u(y2)
−
ρ1ρ2
2
(ρ1 + ρ2)2
∂u
∂eθ
(y1) +
ρ2
1ρ2
(ρ1 + ρ2)2
∂u
∂eθ
(y2)
 dθ
ρ2
1ρ2
2
 ˆ 2π
0
dθ
ρ2
1ρ2
2
.
(3.28)
Similar to the cubic Gordon–Wixom interpolation scheme, (3.28) has cubic precision
and reproduces biharmonic functions on a disk.
3.3.4
Modiﬁed Gordon–Wixom for polyharmonic interpolation
Earlier we noted that
1
π
ˆ 2π
0
∂2
∂e2
θ
dθ = 1
π
ˆ 2π
0

cos θ ∂
∂x1
+ sin θ ∂
∂x2
2
dθ = ∆.
Together with (3.27), this suggests that similar formulas can be obtained for the
poly-Laplacian. Indeed, direct computations yield
8
5π
ˆ 2π
0
∂6u
∂e6
θ
dθ = ∆3u
and more generally
cn
ˆ 2π
0
∂2nu
∂e2n
θ
dθ = ∆nu,
where
cn = 1
 ˆ 2π
0
(cos θ)2n dθ.
(3.29)
For example, c1 = 1/π, c2 = 4/(3π), and c3 = 8/(5π).
In order to get a modiﬁed Gordon–Wixom scheme for polyharmonic inter-
polation, we then need to compute an approximation of ∂2nu/∂e2n
θ
in terms of
u(x), u(y1), u(y2), . . . , ∂n−1u(y1)/∂en−1
θ
, ∂n−1u(y2)/∂en−1
θ
.
If ρ1 and ρ2 are small, then an approximation of the (2n)-th order directional
derivative of u(x) in the direction of eθ can be obtained using the Taylor series
u(x + ρ1eθ) = u(x) + ρ1
∂u
∂eθ
(x) + · · · + ρ2n
1
(2n)!
∂2nu
∂e2n
θ
(x),
u(x −ρ2eθ) = u(x) −ρ2
∂u
∂eθ
(x) + · · · + (−ρ2)2n
(2n)!
∂2nu
∂e2n
θ
(x),
...

Transﬁnite Barycentric Coordinates
■57
∂n−1u
∂en−1
θ
(x + ρ1eθ) = ∂n−1u
∂en−1
θ
(x) + ρ1u(n)(x) + · · · + ρ2n
1
(2n)!
∂2nu
∂e2n
θ
(x),
∂n−1u
∂en−1
θ
(x −ρ2eθ) = ∂n−1u
∂en−1
θ
(x) −ρ2u(n)(x) + · · · + (−ρ2)2n
(2n)!
∂2nu
∂e2n
θ
(x).
Eliminating terms in ∂u(x)/∂eθ, . . . , ∂2n−1u(x)/∂e2n−1
θ
we arrive at
∂2nu
∂e2n
θ
(x) = (2n)!
ρn
1ρn
2

u(x) −α1u(y1) −α2u(y2) −· · ·
−α2n−1
∂n−1u
∂en−1
θ
(y1) −α2n
∂n−1u
∂en−1
θ
(y2)

,
where α1, . . . , α2n are some weights. Combining with (3.29) and mimicking poly-
harmonic interpolation gives a high-order generalization of the modiﬁed Gordon–
Wixom interpolation scheme.
3.4
GENERALIZED MEAN VALUE POTENTIALS AND DISTANCE
FUNCTION APPROXIMATIONS
In this section we study properties of generalized mean value potentials, which
are generalizations of the normalization function for the transﬁnite mean value
coordinates; that is, the denominator in (3.4). We show that these generalized mean
value potentials deliver accurate approximations of the distance function dist(x, ∂Ω)
near ∂Ωand can be seen as smooth distance functions. Eﬃcient computation of
smooth distance functions is important for a number of applications, including
pattern recognition [435], computational mechanics [157], medical imaging [338],
and computational ﬂuid dynamics [332, 399].
3.4.1
Generalized mean value potentials for smooth domains
Floater et al. [77, 133] observed some remarkable properties of the mean value
normalization function
Φ(x) =
ˆ
Sx
dθ
∥x −y∥,
which is the denominator in (3.4). In particular, for Ψ(x) = 1/Φ(x), they show
that
Ψ(y) = 0
and
∂Ψ(y)
∂ny
=
1
Vd−1
∀y ∈∂Ω,
(3.30)
where ny is the outer unit normal for the boundary of Ω⊂Rd at y ∈∂Ωand
Vd−1 is the volume of the unit ball in Rd−1 (V1 = 2 and V2 = π). In view of (3.30),
the function Vd−1Ψ(x) delivers an accurate approximation of the distance function
dist(x, ∂Ω) near ∂Ω.

58
■Generalized Barycentric Coordinates in Graphics and Mechanics
This property can be used for Hermite interpolation purposes as in [77, 133].
More generally, the distance function property also plays an important role in com-
puter graphics, visualization, and modeling. For example, it is used as a parameter
for material modeling in [51], for the animation of shapes in [106], and in level-set
methods [297]. See also [214] and the references therein for further applications in
computer graphics and visualization.
It seems natural to consider the Lp generalizations of Φ(x) and Ψ(x). Following
[39, 40], let us consider
Φp(x) =
ˆ
Sx
dθ
∥x −y∥p
and
Ψp(x) = 1/Φp(x)
(3.31)
with p > 0. Below, for the sake of simplicity, we deal with the two-dimensional
version of (3.31). A similar study of the generalized mean value potential Φp(x) in
the 3D case can be found in [39].
In the 2D case, Φp(x) can be written as
Φp(x) =
ˆ 2π
0
dθ
ρ(θ)p ,
where, as before, θ is the angle between the vector y −x and a ﬁxed direction
and ρ(θ) = ∥x −y∥. The generalized mean value potential Φp(x) satisﬁes some
interesting properties, including [40, Proposition 3]
∆Φp(x) = p(p + 2)Φp+2(x).
(3.32)
It is clear that Φp(x) > 0 and Φp(x) →∞as x approaches ∂Ω. Further, (3.32)
implies that Φp(x) has no local maxima inside Ω, because otherwise ∆Φp > 0
at a local maximum and (3.32) cannot be satisﬁed. Hence, Ψp(x) is positive inside
Ω, vanishes on ∂Ω, and has no local minima inside Ω. Below we study the asymp-
totic properties of Φp(x) near ∂Ω(or, equivalently, the asymptotic properties of
Ψp(x) near ∂Ω) and show that, after a proper constant rescaling, Ψp(x) delivers
an accurate approximation of dist(x, ∂Ω) near ∂Ω.
Let x be near ∂Ωand denote by h = dist(x, ∂Ω) the distance from x to ∂Ω. We
keep following [39] and now show that in the planar case (d = 2) for p > 1 we have
Φp(x) =
ˆ 2π
0
dθ
ρ(θ)p = cp
hp + k cp−2
2hp−1 + O

1
hp−2

(3.33)
with
cp =
ˆ π/2
−π/2
cosp θ dθ,
where k is the curvature of ∂Ωat y ∈∂Ω. The case p = 1, which corresponds to
the mean value normalization function, yields
Φ1(x) ∼2
h + k
2 ln 1
h + O(1)
as
h →0,
(3.34)
which is an extension of one of the main results in [133].

Transﬁnite Barycentric Coordinates
■59
Figure 3.7 To analyze the asymptotic behavior of Φp(x) when x approaches ∂Ω
(h →0) we locally approximate ∂Ωby osculating parabolas.
Let us demonstrate (3.33) and (3.34). Given a point x ∈Ω, situated at the
distance h ≪1 from ∂Ω, let us introduce Euclidean and polar coordinates, as
shown in Figure 3.7, where the origin of coordinates is located at the closest point
to x on ∂Ωand the y-axis coincides with the direction of the orientation normal.
Let us start with the case of positive curvature k of ∂Ωat the origin of coordi-
nates. Locally, ∂Ωis approximated by the osculating parabola
y = x2/(2R),
where R = 1/k is the curvature radius, as seen in Figure 3.7 (left). In polar coor-
dinates
x = ρ sin θ,
y = h −ρ cos θ
the parabola becomes
ρ2 sin2 θ + 2Rρ cos θ −2Rh = 0.
Solving this quadratic equation for ρ > 0 yields
ρ = −R cos θ +
√
D
sin2 θ
,
D = R2 cos2 θ + 2Rh sin2 θ
and we can write
1
ρ =
1
2Rh

R cos θ
r
1 + 2h
R tan2 θ + R cos θ

= cos θ
h
+ 1
2R
sin2 θ
cos θ + O(h).
Therefore,
Φp(x) ∼
ˆ π/2
−π/2
dθ
ρ(θ)p = cp
hp + 1
R
˜cp
hp−1 + O

1
hp−2

,
where
cp =
ˆ π/2
−π/2
cosp θ dθ
and
˜cp = p
2
ˆ π/2
−π/2
cosp−2 θ sin2 θ dθ.
(3.35)
Simple calculations show that ˜cp = cp−2/2.
Above we assumed that p > 1. If p = 1 (the case of mean value coordinates),
then we have
Φ1(x) =
ˆ π/2
−π/2
dθ
ρ(θ) = 2
h + 1
2R
ˆ π/2
−π/2
sin2 θ
cos θ dθ + O(h)

60
■Generalized Barycentric Coordinates in Graphics and Mechanics
and the integral diverges at ±π/2. So we have to consider
Φ1(x) ∼
1
2Rh
ˆ π/2
−π/2
p
R2 cos2 θ + 2Rh sin2 θ + R cos θ

dθ
(3.36)
as h →0. Note that
ˆ π/2
−π/2
p
R2 cos2 θ + 2Rh sin2 θ dθ = 2R
ˆ π/2
0
r
1 −

1 −2h
R

sin2 θ dθ
= 2R E

1 −2h
R

,
where
E(t) =
ˆ π/2
0
p
1 −t sin2 θ dθ
is the complete elliptic integral of the second kind. It can be shown that
E(1 −ε) = 1 −1
4ε ln ε + · · ·
as
ε →0.
Thus,
Φ1(x) ∼2
h + 1
2R ln 1
h + O(1)
as
h →0,
which completes our proof of (3.34) in the case of positive curvature.
Now let us consider the negative curvature case, shown in Figure 3.7 (right).
We have
x = ρ sin θ,
y = h −ρ cos θ,
y = −x2/(2R),
ρ2 sin2 θ−2Rρ cos θ+2Rh = 0,
ρ =

R cos θ−
p
R2 cos2 θ −2Rh sin2 θ

sin2 θ,
1
ρ =
1
2Rh
p
R2 cos2 θ −2Rh sin2 θ + R cos θ

= cos θ
h
−1
2R
sin2 θ
cos θ + O(h).
Thus we arrive at
1
ρp = cosp θ
hp
−p
2R
cosp−2 θ sin2 θ
hp−1
+ O

1
hp−2

.
(3.37)
Now let us study the asymptotic behavior of
ˆ α(h)
−α(h)
dθ
ρ(θ)p ,
where the integration limits α(h) and −α(h) correspond to the two rays originating
from x and the tangent to the osculating parabola y = −x2/(2R), as shown in

Transﬁnite Barycentric Coordinates
■61
Figure 3.7 (right). Note that α(h) = π/2 + O(h) and cos θ = O(h) for |θ| between
α(h) and π/2, as h →0. Thus, in view of (3.37), we have
Φp(x) ∼
ˆ α
−α
dθ
ρ(θ)p
= 1
hp
ˆ α
−α
cosp θ dθ −
p
2Rhp−1
ˆ α
−α
cosp−2 θ sin2 θ dθ + O

1
hp−2

= 1
hp
ˆ π/2
−π/2
cosp θ dθ −
p
2Rhp−1
ˆ π/2
−π/2
cosp−2 θ sin2 θ dθ + O

1
hp−2

= cp
hp −1
R
˜cp
hp−1 + O

1
hp−2

with the same cp and ˜cp as in (3.35) (the case of positive curvature). This completes
our proof of (3.33).
Similarly, for p = 1, instead of (3.36) we have
Φ1(x) =
1
2Rh
ˆ α(h)
−α(h)
p
R2 cos2 θ −2Rh sin2 θ + R cos θ

dθ + O(1)
=
1
2Rh
ˆ π/2
−π/2
p
R2 cos2 θ −2Rh sin2 θ + R cos θ

dθ + O(1)
as
h →0.
Further,
ˆ π/2
−π/2
p
R2 cos2 θ −2Rh sin2 θ dθ = 2R E

1 + 2h
R

,
Φ1(x) ∼2
h −1
2R ln 1
h + O(1)
as
h →0,
which completes the proof of (3.34) for the negative curvature case.
3.4.2
Generalized potentials for polygons
When the domain boundary ∂Ωis approximated by a polygon in 2D, then the
potential Φp(x) at a point x is obtained by computing the contribution of each
edge of the polygon and summing these contributions.
In the 2D case, given a point x, an edge [vi, vi+1], and the angle α between
the vectors vi −x and vi+1 −x, we need to express the distance ρ(θ) between x
and the point y ∈[vi, vi+1], where θ is the angle between vi −x and y −x. Let
ri = ∥x −vi∥and ri+1 = ∥x −vi+1∥(see Figure 3.8). The area of the triangle
[x, vi, vi+1] is equal to the sum of the triangles [x, vi, y] and [x, y, vi+1],
riri+1 sin α = riρ(θ) sin θ + ri+1ρ(θ) sin(α −θ),
giving
ρ(θ) =
riri+1 sin α
ri sin θ + ri+1 sin(α −θ).

62
■Generalized Barycentric Coordinates in Graphics and Mechanics
x
vi
vi+1
y
ρ(θ)
α −θ
θ
ri
ri+1
Figure 3.8 Notation used to deﬁne the generalized mean value potential induced by
the edge [vi, vi+1].
The potential Φp(x) for the edge [vi, vi+1] is then given by
Φp(x) =
ˆ α
0
dθ
ρ(θ)p =
1
(riri+1 sin α)p
ˆ α
0
(ri sin θ + ri+1 sin(α −θ))pdθ.
For a given value of p the integral can be computed symbolically. In particular,
when p is odd, it can be expressed as a polynomial of degree p of the variable
t = tan(α/2). The ﬁrst expressions for p = 1, 3 are given by
Φ1(x) =
 1
ri
+
1
ri+1

t,
Φ3(x) = 1
3
 1
r3
i
+
1
r3
i+1

t + 1
6
 1
ri
+
1
ri+1
3
t(1 + t2).
The expression for Φ1(x) corresponds to the expression for the mean value weight
in [144, 200]. For even p, the resulting expressions are no longer simple anymore,
except for the case p = 0, which corresponds to the angle α. The interested reader
can ﬁnd further details in [40].
In the 3D case we need to compute the contribution of the potential induced by
a triangle [vi, vj, vk] at x. The case p = 0 corresponds to the solid angle at which
the triangle [vi, vj, vk] is seen from x. The case p = 1 corresponds to the mean
value weight for which an expression is given in [217]. For other values of p, a closed
form expression for the potential Φp(x) induced by one triangle can be obtained as
a particular case of the expressions for singular potential integrals derived in [85].

C H A P T E R 4
Barycentric Mappings∗
Teseo Schneider
Università della Svizzera italiana, Lugano, Switzerland
CONTENTS
4.1
Introduction ......................................................
64
4.1.1
Convex polygons .........................................
64
4.1.2
Arbitrary polygons .......................................
65
4.2
Bijective barycentric mapping ...................................
66
4.2.1
Perturbed target polygons ...............................
66
4.3
Bijective composite barycentric mapping ........................
68
4.3.1
Limit of composite barycentric mappings ...............
70
4.4
Extensions .......................................................
71
4.4.1
Closed planar curves .....................................
71
4.4.2
Polyhedra ................................................
73
4.5
Practical considerations ..........................................
75
4.5.1
Choosing the coordinates ................................
75
4.5.2
Choosing the vertex paths ...............................
75
B
arycentric mappings allow us to naturally warp a source polygon to a cor-
responding target polygon, or, more generally, to create mappings between
closed curves or polyhedra. Unfortunately, bijectivity of such barycentric mappings
can only be guaranteed for the special case of warping between convex polygons.
In fact, for any barycentric coordinates, it is always possible to construct a pair
of polygons such that the barycentric mapping is not bijective. However, if the
two polygons are suﬃciently close, the mapping is close to the identity and hence
bijective. This fact suggests “splitting” it into several intermediate mappings and
creating a composite barycentric mapping, which is guaranteed to be bijective be-
tween arbitrary polygons, polyhedra, or closed planar curves.
∗This work was supported by the SNSF under project number 200020_156178.
63

64
■Generalized Barycentric Coordinates in Graphics and Mechanics
source
Wachspress
mean value
discrete
harmonic
Figure 4.1 Example of a barycentric mapping based on diﬀerent barycentric coor-
dinates. For the discrete harmonic mapping we only show the image of the interior
of ¯Ω0.
4.1
INTRODUCTION
A barycentric mapping between a source polygon ¯Ω0 ⊂R2 with n ≥3 source vertices
v0
i , i = 1, . . . , n, ordered anticlockwise, and a target polygon ¯Ω1 ⊂R2 with the same
number of target vertices v1
i , is a mapping
f : ¯Ω0 →¯Ω1,
f(x) =
n
X
i=1
φi(x)v1
i ,
(4.1)
where the functions φi : ¯Ω0 →R, i = 1, . . . , n are barycentric coordinates with
respect to ¯Ω0 (see Chapter 1). Since f depends on the particular choice of coor-
dinates, we denote the mapping f with the name of the coordinate generating it.
For instance, a Wachspress mapping is a barycentric mapping based on Wachspress
coordinates.
Because of the Lagrange property (1.10b), it is clear that f(v0
i ) = v1
i . Moreover,
if a point x = (1 −µ)v0
i + µv0
i+1 lies on the edge [v0
i , v0
i+1], the only non-zero
coordinates are φi(x) = 1 −µ and φi+1(x) = µ, because the coordinates are linear
along the edges of the polygon (1.10c). Hence the mapping is f(x) = (1 −µ)v1
i +
µv1
i+1, which means that it is linear along the edges, too. Finally, the mapping f
is always surjective, because the coordinates φi are continuous, which implies that
f is continuous on ¯Ω0, and edges are mapped to edges.
Figure 4.1 shows an example of a barycentric mapping for diﬀerent coordinates.
We see that the mapping is linear along the edges, regardless of the choice of
coordinates, and that it is not bijective; that is, the grid folds over in concave
regions.
4.1.1
Convex polygons
Barycentric mappings between convex polygons are guaranteed to be bijective only
for the special case of Wachspress mappings [152]. Figure 4.2 shows an extreme
example of a barycentric mapping between two convex polygons. In the close-up we

Barycentric Mappings
■65
source
Wachspress
mean value
Figure 4.2 Example of a convex source and a convex target polygon with 5 vertices,
taken from [152], for which the mean value mapping (right) is not bijective, whereas
the Wachspress (middle) is.
see that the mean value mapping is not bijective, whereas the Wachspress mapping
is.
4.1.2
Arbitrary polygons
For any choice of barycentric coordinates, it is possible to construct a source and a
target polygon such that the barycentric mapping is not bijective [208]. In order to
construct such a counterexample, let us consider the barycentric mapping between
a square and a deformed square, as shown in Figure 4.3.
Because we only move v0
3, we know that v1
i −v0
i = 0 for i = 1, 2, 4, and we can
rewrite the mapping f, evaluated at the origin, as
f(0) =
4
X
i=1
φi(0)(v1
i −v0
i +v0
i ) =
4
X
i=1
φi(0)(v1
i −v0
i ) = φ3(0)(v1
3−v0
3) = φ3(0)(v1
3+v0
1),
where we exploit the fact that v0
3 = −v0
1 in the last step.
We ﬁrst assume that φ3(0) > 0.5 and show that there exists a choice of v1
3
such that f(0) = v1
1, which contradicts the bijectivity of the mapping. To this end,
(−1, 0) = v0
1
v0
2 = (0, −1)
v0
3 = (1, 0)
v0
4 = (0, 1)
x = (0, 0)
v1
1
v1
2
v1
3
v1
4
f(x)
Figure 4.3 Source and target polygon for the construction of a non-bijective barycen-
tric mapping.

66
■Generalized Barycentric Coordinates in Graphics and Mechanics
1
0.5
0
1.5
<0
>1.5
¯Ω0
¯Ω1
¯Ω1
¯Ω1
Figure 4.4 Color-coded plots of Jf for the mean value mapping f : ¯Ω0 →¯Ω1 for
diﬀerent target polygons, which remains positive when the perturbation is small,
but becomes negative for large deformations. See color insert.
observe that
x = φ3(0) −1
φ3(0)
> −1
by the assumption and choose v1
3 = (x, 0) = −xv0
1. With this choice,
f(0) = φ3(0)(1 −x)v0
1 = v1
1.
Assuming next that φ3(0) < 0.5, we conclude with similar considerations that
f(0) = v1
3, again contradicting the bijectivity of f.
Finally, consider the case when φ3(0) = 0.5. Rotating the source polygon by
90 degrees, keeping in mind that f is invariant under rotations, and repeating the
same reasoning as in the previous two cases, we conclude that φi(0) = 0.5 for all i,
which contradicts the partition of unity property.
4.2
BIJECTIVE BARYCENTRIC MAPPING
Let us denote the partial derivatives of the barycentric mapping f = (f1, f2) in (4.1)
at x = (x1, x2) ∈¯Ω0 by ∂kf(x) = ∂f/∂xk, k = 1, 2, and the gradients of its two
components fi by ∇fi = (∂1fi, ∂2fi).
Since we consider only source and target polygons without self-intersections and
assume that the barycentric coordinates φi are at least continuously diﬀerentiable,
a suﬃcient condition for the injectivity of f is that its Jacobian determinant
Jf =

∂1f1
∂2f1
∂1f2
∂2f2

is strictly positive in ¯Ω0 [272]. As it follows from (4.1) that a barycentric mapping
between identical source and target polygons is the identity with Jf(x) = 1 for all
x ∈¯Ω0, it is reasonable to expect that a small perturbation of the target vertices
keeps Jf positive and the mapping bijective, as shown in Figure 4.4.
4.2.1
Perturbed target polygons
Consider ﬁrst a target polygon with a single perturbed vertex, as shown in Fig-
ure 4.5. Formally, the target vertices are v1
i = v0
i + u for some i and v1
j = v0
j

Barycentric Mappings
■67
v0
i
ui
v1
i
v0
i
ui
v1
i
Figure 4.5 Perturbation of one vertex (left) and all vertices (right) of the target
polygon.
for j ̸= i. Substituting these target vertices v1
i in (4.1) and recalling the linear
reproduction property (1.9), we obtain
f(x) = x + φi(x)u
for any x ∈¯Ω0, and further,
Jf(x) =

1 + ∂1φi(x)u1
∂2φi(x)u1
∂1φi(x)u2
1 + ∂2φi(x)u2
 = 1 + ∇φi(x) · u.
Therefore,
Jf(x) ≥1 −|∇φi(x) · u| ≥1 −∥u∥∥∇φi(x)∥,
which is strictly positive for ∥u∥< 1/Mi with
Mi = sup
x∈¯Ω0 ∥∇φi(x)∥.
This result nicely extends to a perturbation of all vertices, where we consider a
target polygon with vertices v1
i = v0
i + ui for i = 1, . . . , n (Figure 4.5). Using the
linear reproduction property again, we reformulate the mapping as
f(x) = x +
n
X
i=1
φi(x)ui
for any x ∈¯Ω0, hence
Jf(x) =

1 + P
i ∂1φi(x)ui,1
P
i ∂2φi(x)ui,1
P
i ∂1φi(x)ui,2
1 + P
i ∂2φi(x)ui,2

= 1 +
X
i ∇φi(x) · ui +
X
i
X
j ∂1φi(x)∂2φj(x)(ui × uj),
where ui = (ui,1, ui,2) and the sums range from 1 to n. Therefore,
Jf(x) ≥1 −Md −M 2d2

68
■Generalized Barycentric Coordinates in Graphics and Mechanics
¯Ω0
v0
i
vtk
i
v1
i
ψi
¯Ωtk
¯Ω1
Figure 4.6 Construction of the intermediate polygon ¯Ωtk using the paths ψi.
with M = M1 + · · · + Mn and d = max1≤i≤n ∥ui∥. Overall, this implies that the
mapping f is injective if
d <
√
5 −1
2M
.
4.3
BIJECTIVE COMPOSITE BARYCENTRIC MAPPING
Section 4.2.1 suggests that if source and target polygon are suﬃciently close, the
mapping is close to the identity and hence bijective. Therefore, by “splitting” the
barycentric mapping from source to target polygon into a ﬁnite number of interme-
diate steps, where each step perturbs the vertices only slightly, it should be possible
to obtain a bijective composite mapping.
To this end, suppose that ψi : [0, 1] →R2, i = 1, . . . , n are a set of continuous
vertex paths between each source vertex v0
i = ψi(0) and its corresponding target
vertex v1
i = ψi(1), as shown in Figure 4.6. Let τ = (t0, t1, . . . , tm) with t0 = 0,
tm = 1, let tk < tk+1 for k = 0, . . . , m −1 be a partition of [0, 1] and let fk be the
barycentric mapping from ¯Ωtk to ¯Ωtk+1, based on the barycentric coordinates φtk
i .
f0 =
n
X
i=1
φ0
i v0.5
i
f0.5 =
n
X
i=1
φ0.5
i
v1
i
fτ = f0.5 ◦f0
¯Ω0
¯Ω0.5
¯Ω1
Figure 4.7 Construction of a composite barycentric mapping for τ = [0, 0.5, 1].

Barycentric Mappings
■69
1 step
4 steps
20 steps
Figure 4.8 Examples of uniform composite mean value mappings for diﬀerent num-
bers of uniform steps.
The mapping
fτ = fm−1 ◦fm−2 ◦· · · ◦f0
is called a composite barycentric mapping from ¯Ω0 to ¯Ω1 [350]. An example of a
composite barycentric mapping between a square and a concave quadrilateral is
shown in Figure 4.7.
Denoting the maximum displacement distance between ¯Ωtk and ¯Ωtk+1 by
dk = max
1≤i≤n
vtk
i −vtk+1
i
,
it follows from the previous results that fτ is bijective if
dτ = max
0≤k<m dk <
√
5 −1
2nM ∗,
where
M ∗= max
1≤i≤n sup
t∈[0,1]
sup
x∈¯Ωt
∇φt
i(x)
.
Figure 4.9 Example of a composite mean value mapping with 1000 uniform steps.
The resolution of the grid is increased by a factor of 4 in the close-up.

70
■Generalized Barycentric Coordinates in Graphics and Mechanics
For the special case of mean value mappings, this bound can provably be satisﬁed
for mappings between any convex polygons (see Chapter 2). Figure 4.8 shows that
with enough intermediate steps the mapping f becomes bijective.
In particular, there exists some m ∈N such that the uniform partition τm with
tk = k/m gives a bijective composite barycentric mapping fτm. Figure 4.9 shows
an example of a composite mean value mapping for two nested squares, where the
interior square is rotated by 90 degrees in the target conﬁguration using the uniform
partition τ1000.
4.3.1
Limit of composite barycentric mappings
The idea of uniform composite barycentric mappings leads to the interesting ques-
tion of the behavior in the limit. To this end, we consider the inﬁnite composite
barycentric mapping f∞= limm→∞fτm and its backward mapping g∞: ¯Ω1 →¯Ω0.
Figure 4.10 shows the result of mapping a star with a uniform composite mapping
fτm composed with its backward mapping gτm : ¯Ω1 →¯Ω0 with the same number of
steps. Computing the maximum distance ∥x −gτm(fτm(x))∥for one million ran-
dom points x ∈¯Ω0 indicates that this distance converges to zero and so gτm = f −1
τm
as m →∞. Consequently, the inverse of an inﬁnite barycentric mapping is likely
to be an inﬁnite barycentric mapping itself, which is not the case for standard
barycentric mappings.
This observation can be proven by considering the diﬀerence between two suc-
cessive steps and taking its limit [145]. For any point x0 ∈¯Ω0 we evaluate the ﬁrst
step f0 of the composite mapping f,
xt1 = f0(x0) =
n
X
i=1
φt0
i (x0)ψi(t1).
Because of the linear reproduction property,
x0 =
n
X
i=1
φt0
i (x0)ψi(t0),
target
100 steps
200 steps
400 steps
Figure 4.10 Composing the mapping fτm and the backward mapping gτm converges
to the identity as the number of uniform steps m increases.

Barycentric Mappings
■71
hence
xt1 −x0 =
n
X
i=1
φt0
i (x0)(ψi(t1) −ψi(t0)).
Dividing by t1 −t0 and taking the limit for t1 →t0, yields
x′(t) =
n
X
i=1
φi(x(t), t)ψ′
i(t),
which is a ﬁrst-order diﬀerential equation in x(t) of the form
x′(t) = F(t, x(t)).
with initial condition x(0) = x0.
If the barycentric coordinates φi are Lipschitz-continuous, then F is Lipschitz-
continuous, too, which is a suﬃcient condition for the existence of a local unique
solution, according to the Picard–Lindelöf Theorem [250, 308]. The solution of the
diﬀerential equation is also a global solution, since x(t) stays inside all intermediate
polygons. This is the case because the mapping is bijective and edges are mapped
to edges.
In order to show that g−1 = f, we consider, for any point x1 = x(1) ∈¯Ω1,
y′(t) =
n
X
i=1
φi(x(1 −t), 1 −t) ¯ψ′
i(t),
¯ψi(t) = ψi(1 −t),
with y(0) = x(1) as the mapping of x1 from ¯Ω1 to ¯Ω0. Because ¯ψ′
i(t) = −ψ′
i(1−t),
we conclude that y(t) = x(1 −t). Therefore, y(1) = x0 and g has an inverse
generated by the previous equation with g−1 = f.
4.4
EXTENSIONS
The suﬃcient condition for guaranteeing bijectivity of a composite barycentric
mapping between polygons can be naturally extended to mappings between closed
curves and polyhedra.
4.4.1
Closed planar curves
We deﬁne the barycentric mapping between a closed planar source curve γ0(s) and
a closed planar target curve γ1(s) with s ∈[0, 1], as
f(x) =
ˆ 1
0
φ(s, x)γ1(s)ds,
where φ(s, x) are the transﬁnite barycentric coordinates with respect to γ0 (see
Chapter 3). Analogously to the polygonal case, we now consider a perturbed target

72
■Generalized Barycentric Coordinates in Graphics and Mechanics
source
t = 0.2
t = 0.4
t = 0.6
t = 0.8
target
Figure 4.11 Example of a composite mean value mapping between two closed planar
curves. The grid shows how the interior of the source curve is morphed to the interior
of the target curve.
curve γ1(s) = γ0(s) + u(s) and assume that the maximum displacement distance
satisﬁes
d = sup
s∈[0,1]
∥u(s)∥<
√
5 −1
2M
,
where
M = sup
s∈[0,1]
sup
x∈γ0 ∥∇φ(s, x)∥.
We exploit the linear reproduction property to rewrite
f(x) = x +
ˆ 1
0
φ(s, x)u(s)ds
and compute
Jf(x) =

1 +
´
∂1φ(s, x)u1(s)ds
´
∂2φ(s, x)u1(s)ds
´
∂1φ(s, x)u2(s)ds
1 +
´
∂2φ(s, x)u2(s)ds

= 1 +
ˆ
∇φ(s, x) · u(s)ds +
¨
∂1φ(s, x)∂2φ(r, x)(u(s) × u(r))ds dr,
where the integrals range from zero to one. Therefore,
Jf(x) ≥1 −Md −M 2d2,
which is strictly positive for Md < (
√
5 −1)/2. Hence the mapping is injective as
long as d <
√
5−1
2M . It is interesting to note that this bound is the same as in the
polygonal case.
Now suppose that ψ is a continuous closed curve interpolation function between
the source curve γ0 = ψ(0) and the target curve γ1 = ψ(1). Again we let τ =
(t0, t1, . . . , tm) with t0 = 0, tm = 1, and tk < tk+1 for k = 0, . . . , m −1 be a
partition of [0, 1], and let fk be the barycentric mapping from γtk to γtk+1, based
on the barycentric coordinates φtk. The mapping
fτ = fm−1 ◦fm−2 ◦· · · ◦f0,

Barycentric Mappings
■73
source
t = 0.2
t = 0.4
t = 0.6
t = 0.8
target
Figure 4.12 Example of a composite mean value mapping between two polyhedra.
The color shows how the interior of the source polyhedron is morphed to the interior
of the target polyhedron. See color insert.
is called a composite barycentric mapping from γ0 to γ1. An example of a composite
barycentric mapping between two closed curves is shown in Figure 4.11.
Denoting the maximum displacement distance between γtk and γtk+1 by
dk = sup
s∈[0,1]
γtk(s) −γtk+1(s)
,
it follows from the previous result that fτ is bijective if
dτ = max
0≤k<m dk <
√
5 −1
2nM ∗,
where
M ∗= sup
s∈[0,1]
sup
t∈[0,1]
sup
x∈γt
∇φt(s, x)
.
4.4.2
Polyhedra
A barycentric mapping between two polyhedra with the same number of vertices n
and the same topology is deﬁned as a function
f : ¯Ω0 →¯Ω1,
f(x) =
n
X
i=1
φi(x)v1
i ,
where v1
i are the vertices of the target polyhedron and φi(x) are 3D barycentric
coordinates (see Section 1.3). An example of such a mapping is illustrated in Fig-
ure 4.12.
As in the polygonal case we ﬁrst perturb only one vertex and consider a target
polyhedron with vertices v1
i = v0
i + u for some i and v1
j = v0
j for j ̸= i. Then,
Jf(x) =

1 + ∂1φi(x)u1
∂2φi(x)u1
∂3φi(x)u1
∂1φi(x)u2
1 + ∂2φi(x)u2
∂3φi(x)u2
∂1φi(x)u3
∂2φi(x)u3
1 + ∂3φi(x)u3

= 1 + ∇φi(x) · u
and
|Jf(x)| ≥1 −|φi(x) · u| ≥1 −∥φi(x)∥∥u∥,

74
■Generalized Barycentric Coordinates in Graphics and Mechanics
which is positive for ∥u∥< 1/Mi with
Mi = sup
x∈Ω
∥∇bi(x)∥.
Again, we perturb all vertices of the polyhedron and consider a target polyhe-
dron with vertices v1
i = v0
i + ui for i = 1, . . . , n, to get
Jf(x) =

1 + P
i ∂1φi(x)ui,1
P
i ∂2φi(x)ui,1
P
i ∂3φi(x)ui,1
P
i ∂1φi(x)ui,2
1 + P
i ∂2φi(x)ui,2
P
i ∂3φi(x)ui,2
P
i ∂1φi(x)ui,3
P
i ∂2φi(x)ui,3
1 + P
i ∂3φi(x)ui,3

= 1 +
X
i ∇φi(x) · u +
X
i
X
j
X
k ∂1φi(x) ∂2φj(x) ∂3φk(x) |(ui uj uk)|
+
X
i
X
j

∂1φi(x) ∂2φj(x) D3 + ∂1φi(x) ∂3φj(x) D2 + ∂2φi(x) ∂3φj(x) D1

,
where the sums range from 1 to n and Dk is the k-th component of ui × uj.
Therefore,
Jf(x) ≥1 −Md −3M 2d2 −M 3d3,
where
d = max
1≤i≤n ∥ui∥
and
M = M1 + · · · + Mn,
which is positive if Md <
√
2 −1, implying that f is injective for d <
√
2−1
M
.
Now, suppose that ψi : [0, 1] →R3, i = 1, . . . , n are a set of continuous vertex
paths between each source vertex v0
i = ψi(0) and its corresponding target vertex
v1
i = ψi(1). We deﬁne the composite barycentric mapping from ¯Ω0 to ¯Ω1 as
fτ = fm−1 ◦fm−2 ◦· · · ◦f0,
where fk : ¯Ωtk →¯Ωtk+1 are barycentric mappings based on the partition τ =
(t0, t1, . . . , tm) of the interval [0, 1].
Denoting the maximum displacement distance between ¯Ωtk and ¯Ωtk+1 by
dk = max
1≤i≤n
vtk
i −vtk+1
i
,
it follows that fτ is bijective if
dτ = max
0≤k<m dk <
√
2 −1
2nM ∗,
where
M ∗= max
1≤i≤n sup
t∈[0,1]
sup
x∈¯Ωt
∇φt
i(x)
.
The composite barycentric mapping fτ can also be extended to closed smooth
surfaces, and by following a similar reasoning we can conclude that the mapping
fτ is bijective if dτ < (
√
2 −1)/(2nM ∗).

Barycentric Mappings
■75
source
mean value
harmonic
maximum entropy
Figure 4.13 Composite barycentric map for diﬀerent types of barycentric coordi-
nates for 100 uniform steps.
4.5
PRACTICAL CONSIDERATIONS
Composite barycentric mappings depend on two main choices: the underlying
barycentric coordinates φ and the vertex paths ψ. In this section we illustrate
the inﬂuence of these choices on the composite mapping.
4.5.1
Choosing the coordinates
In general, the vertex paths ψi produce an arbitrary intermediate shape, which may
be concave or weakly convex. For this reason we need barycentric coordinates that
are well-deﬁned for arbitrary simple polygons. We suggest using mean value (see
Section 1.2.3), harmonic (see Section 1.2.8), or maximum entropy coordinates (see
Section 1.2.9). Figure 4.13 shows an example of a composite barycentric mapping
for these three diﬀerent coordinates.
4.5.2
Choosing the vertex paths
To create intermediate shapes, the natural vertex path that works in any dimen-
sion and for any shape is to linearly interpolate the shapes from source to target.
However, this interpolation is not invariant with respect to similarity transforma-
tions, while the mapping is. Moreover, linear interpolation of the vertices is more
likely to produce self-intersecting polygons in the case of rotations, which invali-
dates the mapping, since barycentric coordinates are well-deﬁned only for non-self-
intersecting polygons. For these reasons, linear interpolation is not well-suited for
creating the intermediate shapes for the composite barycentric mappings.
Instead, the intermediate polygons can be computed by linearly interpolating
the turning angle and the edge lengths [352], which generates more natural results
than linearly interpolating the vertices, because edges and angles are invariant with
respect to similarity transformations. Figure 4.14 shows how the composite barycen-
tric mapping changes when this method is used instead of linearly interpolating the

76
■Generalized Barycentric Coordinates in Graphics and Mechanics
linear
[352]
Figure 4.14 Example of a composite barycentric map for diﬀerent vertex paths for
100 uniform steps.
vertices. A similar approach can be employed for closed planar curves where the
curvature is interpolated between source and target curve [343]. An alternative ap-
proach consists of creating a multi-resolution representation of the two input curves
(or polygons) and to interpolate between these multi-resolution representations to
create the intermediate shape [168].
By combining both ideas in 3D we interpolate edges and dihedral angles and,
to derive a globally coherent solution, we follow a hierarchical shape-matching ap-
proach [428]. An alternative and simpler approach involves decomposing the global
interpolation into local aﬃne transformations and splitting them into a rotational
and a scale/shear part [381, 382]. While the scale/shear part can then be inter-
polated linearly, the rotational part should be treated in log-space. However, the
problem is that this method cannot properly handle large global rotations.
Unfortunately, none of these methods guarantees that the intermediate shapes
are intersection-free. To overcome this limitation in two dimensions, initial results
deal with pairs of polygons that have corresponding parallel edges [180]. A more
general method embeds the two polygons inside a convex region, generates a pair
of compatible triangulations, and interpolates the stochastic matrices whose eigen-
vectors encode the geometry [173]. An alternative idea is to create the intermediate
polygons by “unfolding” the source polygon and “refolding” it back to the target
polygon [206].

C H A P T E R 5
A Primer on Laplacians
Max Wardetzky
Georg-August-University Göttingen, Germany
CONTENTS
5.1
Introduction ......................................................
77
5.1.1
Basic properties ..........................................
78
5.2
Laplacians on Riemannian manifolds ............................
79
5.2.1
Exterior calculus .........................................
79
5.2.2
Hodge decomposition ....................................
81
5.2.3
The spectrum ............................................
82
5.3
Discrete Laplacians ..............................................
83
5.3.1
Laplacians on graphs .....................................
83
5.3.2
The spectrum ............................................
84
5.3.3
Laplacians on simplicial manifolds .......................
86
5.3.4
Strongly and weakly deﬁned Laplacians .................
87
5.3.5
Hodge decomposition ....................................
88
5.3.6
The cotan Laplacian and beyond ........................
88
5.3.7
Discrete versus smooth Laplacians .......................
90
I
n this chapter we review some important properties of Laplacians, smooth and
discrete. We place special emphasis on a uniﬁed framework for treating smooth
Laplacians on Riemannian manifolds alongside discrete Laplacians on graphs and
simplicial manifolds. We cast this framework into the language of linear algebra,
with the intent to make this topic as accessible as possible. We combine perspec-
tives from smooth geometry, discrete geometry, spectral analysis, machine learning,
numerical analysis, and geometry processing within this uniﬁed framework. The
connection to generalized barycentric coordinates is established through harmonic
functions that interpolate given boundary conditions.
5.1
INTRODUCTION
The Laplacian is perhaps the prototypical diﬀerential operator for various physical
phenomena. It describes, for example, heat diﬀusion, wave propagation, steady
77

78
■Generalized Barycentric Coordinates in Graphics and Mechanics
state ﬂuid ﬂow, and it is key to the Schrödinger equation in quantum mechanics.
In Euclidean space, the Laplacian of a smooth function u: Rn →R is given as the
sum of second partial derivatives along the coordinate axes,
∆u = −
∂2u
∂x2
1
+ ∂2u
∂x2
2
+ · · · + ∂2u
∂x2n

,
where we adopt the geometric perspective of using a minus sign.
5.1.1
Basic properties
The Laplacian has many intriguing properties. For the remainder of this exposition,
consider an open and bounded domain Ω⊂Rn and the L2 inner product
(f, g) =
ˆ
Ω
fg
on the linear space of square-integrable functions on Ω. Let u, v: Ω→R be two
(suﬃciently smooth) functions that vanish on the boundary of Ω. Then the Lapla-
cian ∆is a symmetric (or, to be precise, a formally self-adjoint) linear operator
with respect to this inner product, since integration by parts yields
(Sym)
(u, ∆v) =
ˆ
Ω
∇u · ∇v = (∆u, v).
Here ∇denotes the standard gradient operator and ∇u · ∇v denotes the standard
inner product between vectors in Rn. The choice of using a minus sign in the
deﬁnition of the Laplacian makes this operator positive semideﬁnite, since
(Psd)
(u, ∆u) =
ˆ
Ω
∇u · ∇u ≥0.
If one considers only functions that vanish on the boundary of Ω, (Psd) implies
that the only functions that lie in the kernel of the Laplacian (∆u = 0) are those
functions that vanish on the entire domain. Moreover, properties (Sym) and (Psd)
imply that the Laplacian can be diagonalized and its eigenvalues are nonnegative,
∆u = λu
⇒
λ ≥0.
Another prominent property of smooth Laplacians is the maximum principle. Let
u: Ω→R be harmonic; that is, ∆u = 0. The maximum principle asserts that
(Max)
u is harmonic
⇒
u has no strict local maximum in Ω,
where we no longer assume that u vanishes on the boundary of Ω. Likewise, no
harmonic function can have a local minimum in Ω.
The maximum principle can be derived from another important property of
harmonic functions, the mean value property. Consider a point x ∈Ωand a closed

A Primer on Laplacians
■79
ball B(x, r) of radius r centered at x that is entirely contained in Ω. Every harmonic
function has the property that the value u(x) can be recovered from the average of
the values of u in the ball B(x, r):
u(x) =
1
vol(B(x, r))
ˆ
B(x,r)
u(y)dy.
A simple argument by contradiction shows that the mean value property implies
property (Max).
The properties mentioned so far play an important role in applications; specif-
ically, in the context of barycentric coordinates, they give rise to mean value co-
ordinates (see Section 1.2.3) and harmonic coordinates (see Section 1.2.8). Below
we discuss additional properties of Laplacians. For further reading we refer to the
books [43, 140, 333] and the lecture notes [83, 109].
5.2
LAPLACIANS ON RIEMANNIAN MANIFOLDS
The standard Laplacian in Rn can be expressed as
∆u = −div ∇u,
where div is the usual divergence operator acting on vector ﬁelds in Rn. Written
in integral form, the negative divergence operator is the (formal) adjoint of the
gradient: If X is a vector ﬁeld and u: Ω→R is a function that vanishes on the
boundary of Ω, then
ˆ
Ω
∇u · X =
ˆ
Ω
u (−divX).
This perspective can be generalized to Riemannian manifolds, which incorporate
the notion of curvature. The Laplacian plays an important role in the study of these
curved spaces.
5.2.1
Exterior calculus
Although gradient and divergence can readily be deﬁned on Riemannian manifolds,
it is more convenient to work with the diﬀerential (or exterior derivative) d instead
of the gradient and with the codiﬀerential d∗instead of divergence.
The diﬀerential d is similar to (but not the same as) the gradient. Indeed, given
a function u: Ω→R, one has
du(X) = ∇u · X
for every vector ﬁeld X. In particular, the diﬀerential does not require the notion of
a metric, whereas the gradient does. The codiﬀerential d∗is deﬁned as the formal
adjoint to d, in the same way as divergence is the adjoint of the gradient. In contrast
to the divergence operator, which acts on vector ﬁelds, the codiﬀerential d∗acts on
1-forms. A 1-form is a covector at every point of Ω; that is, if X is a vector ﬁeld on

80
■Generalized Barycentric Coordinates in Graphics and Mechanics
Ωand α is a 1-form, then α(X) is a real-valued function on Ω. In order to deﬁne
the codiﬀerential d∗, consider a 1-form α and a function u: Ω→R that vanishes
on the boundary of Ω. Then
ˆ
Ω
du · α =
ˆ
Ω
u d∗α,
where the dot product is the inner product between covectors induced from the
inner product between vectors. Notice that diﬀerent from the diﬀerential d, the
codiﬀerential does require the notion of a metric. The Laplacian of a function u can
be expressed as
∆u = d∗du,
which is equivalent to the representation ∆u = −div∇u given above.
In order to carry over this framework to manifolds, let M be a smooth orientable
manifold with smooth Riemannian metric g. Suppose for simplicity that M is com-
pact and has an empty boundary. The Riemannian metric induces a pointwise inner
product between tangent vectors on M, which, analogously to the above discussion,
induces an inner product between 1-forms. More generally, one works with k-forms
for k ≥0. A 0-form, by convention, is a real-valued function on M. A 1-form can
be thought of as an oriented 1-volume in the sense that applying a 1-form to a
vector ﬁeld returns a real value at every point. Likewise, a k-form for k > 1 can be
thought of as an oriented k-volume in the sense of returning a real number at every
point when applied to an ordered k-tuple (parallelepiped) of tangent vectors. As a
consequence, k-forms can be integrated over (sub)manifolds of dimension k. In the
sequel we let Λk denote the linear space of k-forms on M.
Analogous to the L2 inner product between function in Rn, let
(α, β)k =
ˆ
M
g(α, β)volg
denote the L2 inner product between k-forms α and β on M, where, by slight
abuse of notation, we let g(α, β) denote the (pointwise) inner product induced by
the Riemannian metric.
The diﬀerential d: Λk →Λk+1 maps k-forms to (k+1)-forms for 0 ≤k ≤dimM,
where one sets dα = 0 for any k-form with k = dimM. One can deﬁne the diﬀerential
acting on k-forms by postulating Stokes’s theorem,
ˆ
U
dα =
ˆ
∂U
α,
for every k-form α and every (suﬃciently smooth) submanifold U ⊂M of dimension
(k + 1) with boundary ∂U. If one asserts this equality as the deﬁning property of
the diﬀerential d, then it immediately follows that d ◦d = 0 since the boundary of
a boundary of a manifold is empty (∂(∂U) = ∅).
The codiﬀerential d∗, taking (k+1)-forms back to k-forms, is the (formal) adjoint
of d with respect to the L2 inner products on k- and (k + 1)-forms. It is deﬁned by
requiring that
(dα, β)k+1 = (α, d∗β)k

A Primer on Laplacians
■81
for all k-forms α and all (k + 1)-forms β. Finally, the Laplace–Beltrami operator
∆: Λk →Λk acting on k-forms is deﬁned as
∆α = dd∗α + d∗dα.
Notice that this expression reduces to ∆u = d∗du for 0-forms (functions) on M. It
follows almost immediately from the deﬁnition of the Laplacian that a k-form α is
harmonic (∆α = 0) if and only if α is closed (dα = 0) and co-closed (d∗α = 0).
From a structural perspective it is important to note that properties (Sym),
(Psd), and (Max) mentioned earlier remain true (among various other properties)
in the setting of Riemannian manifolds. For further details on exterior calculus and
the Laplace–Beltrami operator, we refer to [333].
5.2.2
Hodge decomposition
Every suﬃciently smooth k-form α on M admits a unique decomposition
α = dµ + d∗ν + h,
known as the Hodge decomposition (or Hodge–Helmholtz decomposition), where µ
is a (k−1)-form, ν is a (k+1)-form, and h is a harmonic k-form. This decomposition
is unique and orthogonal with respect to the L2 inner product on k-forms,
0 = (dµ, d∗ν)k = (h, dµ)k = (h, d∗ν)k,
which immediately follows from the fact that d ◦d = 0 and the fact that harmonic
forms satisfy dh = d∗h = 0. The Hodge decomposition can be thought of as a
(formal) application of the well-known fact from linear algebra that the orthogonal
complement of the kernel of a linear operator is equal to the range of its adjoint
(transpose) operator.
By duality between vector ﬁelds and 1-forms, the Hodge decomposition for 1-
forms carries over to a corresponding decomposition for vector ﬁelds into curl-free
and divergence-free components, which has applications for ﬂuid mechanics [13] and
Maxwell’s equations for electromagnetism [155].
Geometrically, the Hodge decomposition establishes relations between the
Laplacian and global properties of manifolds. Indeed, the linear space of harmonic
k-forms is ﬁnite-dimensional for compact manifolds and isomorphic to Hk(M; R),
the k-th cohomology of M. As an application of this fact, consider a compact ori-
entable surface without boundary. Then the dimension of the space of harmonic
1-forms is equal to twice the genus of the surface; that is, this dimension is zero
for the 2-sphere, two for the two-dimensional torus, four for a genus-two surface
(pretzel) and so on. Hence the Laplacian provides global information about the
topology of the underlying space.
For a thorough treatment of Hodge decompositions, including the case of man-
ifolds with boundary, we refer to [351].

82
■Generalized Barycentric Coordinates in Graphics and Mechanics
5.2.3
The spectrum
One cannot speak about the Laplacian without discussing its spectrum. On a com-
pact orientable manifold without a boundary, it follows from the inequality
(∆u, u)0 = (du, du)1 ≥0
that the spectrum is nonnegative and that the only functions in the kernel of the
Laplacian are constant functions. Thus zero is a trivial eigenvalue of the Laplacian
with a one-dimensional space of eigenfunctions. The next (non-trivial) eigenvalue
λ1 > 0 is much more interesting. By the min-max principle, this eigenvalue satisﬁes
λ1 =
min
(u,1)0=0
(du, du)1
(u, u)0
,
where one takes the minimum over all functions that are L2-orthogonal to the
constants. Higher eigenvalues can be obtained by successively applying the min-max
principle to the orthogonal complements of the eigenspaces of lower eigenvalues.
The ﬁrst non-trivial eigenvalue already tells a great deal about the geometry of
the underlying Riemannian manifold. As an example, consider Cheeger’s isoperi-
metric constant
λC = inf
N

voln−1(N)
min(voln(M1), voln(M2))

,
where N runs over all compact codimension-1 submanifolds that partition M into
two disjoint open sets M1 and M2 with N = ∂M1 = ∂M2. Intuitively, the optimal
N for which λC is attained partitions M into two sets that have maximal volume
and minimal perimeter. As an example, suppose that M has the shape of the surface
of a smooth dumbbell. Then N is a curve going around the axis of the dumbbell at
the location where the dumbbell is thinnest.
A relation of Cheeger’s constant to the ﬁrst non-trivial eigenvalue of the Lapla-
cian is provided by the Cheeger inequalities
λ2
C
4 ≤λ1 ≤c(KλC + λ2
C),
where the constant c only depends on dimension and K ≥0 provides a lower bound
on the Ricci curvature of M in the sense that Ric(M, g) ≥−K2(n−1); see [79, 89].
Recall that for surfaces, Ricci curvature and Gauß curvature coincide. The ﬁrst
non-trivial eigenvalue of the Laplacian is thus related to the metric problem of
minimal cuts—thus providing a relation between an analytical quantity (the ﬁrst
eigenvalue) and a purely geometric quantity (the Cheeger constant). Intuitively, if
λ1 is small, then M must have a small bottleneck; vice-versa, if λ1 is large, then M
is somewhat thick.
Equipped with the full set of eigenfunctions {ϕi} of the Laplace–Beltrami op-
erator, one can perform Fourier analysis on manifolds by decomposing any square-
integrable function u into its modes,
u =
X
i
(u, ϕi)0ϕi,

A Primer on Laplacians
■83
provided that one chooses the eigenfunctions such that (ϕi, ϕi) = δij. (Notice that
(ϕi, ϕj)0 = 0 is automatic for eigenfunctions belonging to diﬀerent eigenvalues.)
The Fourier perspective is of great relevance in signal and geometry processing.
Maintaining a spectral eye on geometry, it is natural to ask the inverse question:
How much geometric information can be reconstructed from information about the
Laplacian? If the entire Laplacian is known on a smooth manifold, then one can
reconstruct the metric, for example, by using the expression of ∆in local coordi-
nates. If, however, “only” the spectrum is known, then less can be said in general.
For example, Kac’s famous question Can one hear the shape of a drum? [220], that
is, whether the entire geometry can be inferred from the spectrum alone, has a
negative answer: There exist isospectral but non-isometric manifolds [169, 383].
5.3
DISCRETE LAPLACIANS
Discrete Laplacians can be deﬁned on simplicial manifolds or, more generally, on
graphs. We treat the case of graphs ﬁrst and discuss simplicial manifolds further
below.
5.3.1
Laplacians on graphs
Consider an undirected graph Γ = (V, E) with vertex set V and edge set E. For
simplicity, we only consider ﬁnite graphs here. Suppose that every edge e ∈E
between vertices i ∈V and j ∈V carries a real-valued weight ωe = ωij = ωji ∈R.
We discuss below how weights can be chosen; suppose for now that such a choice
has been made. A discrete Laplacian acting on a function u: V →R is deﬁned as
(Lu)i =
X
j∼i
ωij(ui −uj),
(5.1)
where the sum ranges over all vertices j that are connected by an edge with vertex
i.∗This allows for representing the linear operator L as a matrix by
Lij =





−ωij,
if there is an edge between i and j,
P
k∼i ωik,
if i = j,
0,
otherwise.
The matrix L is called the discrete Laplace matrix. This deﬁnition may seem to
come a bit out of the blue. In order to see how it relates to smooth Laplacians,
consider again the smooth case and the quantity
ED[u] = 1
2
ˆ
Ω
∥∇u∥2,
∗Some authors include a division by vertex weights in the deﬁnition of Laplacians on graphs.
Such a division arises naturally when considering strongly deﬁned Laplacians, instead of weakly
deﬁned Laplacians. We cover this distinction below.

84
■Generalized Barycentric Coordinates in Graphics and Mechanics
which is known as the Dirichlet energy of u. In the discrete setup, one may discretize
the gradient ∇u along an edge e = (i, j) as the ﬁnite diﬀerence (ui−uj). Accordingly,
one deﬁnes discrete Dirichlet energy as
ED[u] = 1
2
X
e∈E
ωij(ui −uj)2,
where the sum ranges over all edges. One then has
(discrete) ED[u] = 1
2uT Lu
vs.
(smooth) ED[u] = 1
2(u, ∆u)0,
which justiﬁes calling L a Laplace matrix. Due to this representation (and using the
language of partial diﬀerential equations [140]) we call discrete Laplacians of the
form (5.1) weakly deﬁned instead of strongly deﬁned. We return to this distinction
below.
Weakly deﬁned discrete Laplacians of the form (5.1) are always symmetric—
they satisfy (Sym) due to the assumption that ωij = ωji. However, whether or not
a discrete Laplacian satisﬁes (at least some of) the other properties of the smooth
setting heavily depends on the choice of weights.
The simplest choice of weights is to set ωij = 1 whenever there is an edge
between vertices i and j. This results in the so-called graph Laplacian. The diagonal
entries of the graph Laplacian are equal to the degree of the respective vertex, that
is, the number of edges adjacent to that vertex. The graph Laplacian is just a special
case of what we call a Laplacian on graphs here.
Positive edge weights are a natural choice if weights resemble transition prob-
abilities of a random walker. Discrete Laplacians with positive weights are always
positive semideﬁnite (Psd) and, just like in the smooth setting, they only have the
constant functions in their kernel provided that the graph is connected. As a word
of caution we remark that positivity of weights is not necessary to guarantee (Psd).
Below we discuss Laplacians that allow for (some) negative edge weights but still
satisfy (Psd).
Laplacians with positive edge weights always satisfy the mean value property
since every harmonic function u (a function for which Lu = 0) satisﬁes
ui =
X
j∼i
lijuj
with
lij = ωij
Lii
> 0.
Therefore, discrete Laplacians with positive weights also satisfy the maximum prin-
ciple (Max) since P
j∼i lij = 1 and thus ui is a convex combination of its neighbors
uj for discrete harmonic functions. This convex combination property establishes
a connection between Laplacians and barycentric coordinates via the partition of
unity property (1.8).
5.3.2
The spectrum
As in the smooth case, one cannot discuss discrete Laplacians without mentioning
their spectrum and their eigenfunctions, which provide a ﬁngerprint of the structure
of the underlying graph.

A Primer on Laplacians
■85
As an example, consider again Cheeger’s isoperimetric constant. In order to
deﬁne this constant in the discrete setting, consider a partitioning of Γ into two
disjoint subgraphs Γ1 and ¯Γ1 such that the vertex set V of Γ is the disjoint union of
the vertex sets V1 of Γ1 and ¯V1 of ¯Γ1. Here a subgraph of Γ denotes a graph whose
vertex set is a subset of the vertex set of Γ such that two vertices in the subgraph
are connected by an edge if and only if they are connected by an edge in Γ. For
positive edge weights, the discrete Cheeger constant (sometimes called conductance
of a weighted graph) is deﬁned as
λC = min

vol(Γ1, ¯Γ1)
min(vol(Γ1), vol(¯Γ1))

,
where
vol(Γ1, ¯Γ1) =
X
i∈V1,j /∈V1
ωij
and
vol(Γ1) =
X
i∈V1
ωii,
and similarly for vol(¯Γ1). Here, ωii := Lii. Notice that for the case of the graph
Laplacian, vol(Γ1, ¯Γ1) equals the number of edges with one vertex in Γ1 and another
vertex in its complement.†
Similar to the smooth case, one then obtains the Cheeger inequalities
λ2
C
2 ≤˜λ1 ≤2λC,
where ˜λ1 is the ﬁrst nontrivial eigenvalue of the rescaled Laplace matrix
˜L = SLS,
where S is a diagonal matrix with Sii = 1/√ωii. This rescaling is necessary since
λC is invariant under a uniform rescaling of edge weights (and so is ˜L), whereas L
scales linearly with the edge weights. A proof of the discrete Cheeger inequalities
for the case of the graph Laplacians (ωij = 1) can be found in [104]; the proof for
arbitrary positive edge weights is nearly identical.
The Cheeger constant—and alongside, the corresponding partitioning of Γ into
the two disjoint subgraphs Γ1 and ¯Γ1—has applications in graph clustering, since
the edges connecting Γ1 and ¯Γ1 tend to “cut” the graph along its bottleneck [222].
Any discrete Laplacian (having positive edge weights or not) that satisﬁes (Sym)
and (Psd) can be used for Fourier analysis on graphs. Indeed, let {ϕi} be the
eigenfunctions of L, chosen such that ϕT
i ϕj = δij. Then one has
u =
X
i
(uT ϕi)ϕi,
just like in the smooth setting. This decomposition of discrete functions on graphs
†Some authors use a diﬀerent version of the respective volumes in the deﬁnition of the Cheeger
constant, resulting in diﬀerent versions of the Cheeger inequalities; see [384].

86
■Generalized Barycentric Coordinates in Graphics and Mechanics
into their Fourier modes has a plethora of applications in geometry processing;
see [242] and references therein.
As in the smooth setting, it is natural to ask the inverse question of how much
geometric information can be inferred from information about the Laplacian. Recall
that in the the smooth case, knowing the full Laplacian allows for recovering the
Riemannian metric. Similarly, in the discrete case it can be shown that for simpli-
cial surfaces the knowledge of the cotan weights for discrete Laplacians (covered
below) allows for reconstructing edge lengths (i.e., the discrete metric) of the un-
derlying mesh up to a global scale factor [432]. If, however, only the spectrum of
the Laplacian is known, then there exist isospectral but non-isomorphic graphs [76].
In fact, for the case of the cotan Laplacian (see below), the exact same isospectral
domains considered in [169] that were originally proposed for showing that “One
cannot hear the shape of a drum” for smooth Laplacians work in the discrete setup.
A curious fact concerning the connection between discrete Laplacians and the
underlying geometry is Rippa’s theorem [326]: The Delaunay triangulation of a ﬁxed
point set in Rn minimizes the Dirichlet energy of any piecewise linear function over
this point set. In [96], this result is taken a step further, where the authors show
that the spectrum of the cotan Laplacian obtains its minimum on a Delaunay
triangulation in the sense that the i-th eigenvalue of the cotan Laplacian of any
triangulation of a ﬁxed point set in the plane is bounded below by the i-th eigenvalue
resulting from the cotan Laplacian associated with the Delaunay triangulation of
the given point set.
5.3.3
Laplacians on simplicial manifolds
Recall that in the smooth case, Laplacians acting on k-forms take the form
∆= dd∗+ d∗d.
In order to mimic this construction in the discrete setting, one requires a bit more
structure than just an arbitrary graph. To this end, consider a simplicial manifold,
such as a triangulated surface. We keep referring to this manifold as M. As in the
smooth case, for simplicity, suppose that M is orientable and has no boundary.
Simplicial manifolds allow for a natural deﬁnition of discrete k-forms as duals
of k-cells. Indeed, every 0-form is a function deﬁned on vertices, a 1-form α is dual
to edges, that is, α(e) is a real number for any oriented 1-cell (oriented edge), a
2-form is dual to oriented 2-cells, and so forth. In the sequel, let the linear space of
discrete k-forms (better known as simplicial cochains) be denoted by Ck.
As in the smooth case, the discrete diﬀerential δ (better known as the cobound-
ary operator) maps discrete k-forms to discrete (k+1)-forms, δ: Ck →Ck+1. Again
as in the smooth case, the discrete diﬀerential can be deﬁned by postulating Stokes’s
formula: Let α be a discrete k-form. Then one requires that
δα(σ) = α(∂σ)
for all (k + 1)-cells σ, where ∂denotes the simplicial boundary operator. The sim-
plicial boundary operator, when applied to a vertex returns zero (since vertices do

A Primer on Laplacians
■87
not have a boundary). When applied to an oriented edge, the boundary operator
returns the diﬀerence between the edge’s vertices. Likewise, ∂applied to an oriented
2-cell σ returns the sum of oriented edges of σ (with the orientation induced by
that of σ). Since the boundary of a boundary is empty (∂◦∂= 0) one has δ ◦δ = 0,
just like in the smooth case. Notice that the deﬁnition of δ does not require the
notion of inner products.
In order to deﬁne the discrete codiﬀerential δ∗one additionally requires an
inner product (·, ·)k on the linear space of k-forms for each k. Below we discuss
the construction of such inner products. Given a ﬁxed choice of inner products on
discrete k-forms, the codiﬀerential is deﬁned by requiring that
(δα, β)k+1 = (α, δ∗β)k
for all k-forms α and all (k+1)-forms β, and the discrete strongly deﬁned Laplacian
acting on k-forms takes the form
L = δδ∗+ δ∗δ.
(5.2)
This perspective is that of discrete exterior calculus (DEC) [109, 118], where—by
slight abuse of notation—inner products are referred to as “discrete Hodge stars.”
Strongly deﬁned Laplacians are self-adjoint with respect to the inner products
(·, ·)k on discrete k-forms, since
(Lα, β)k = (δα, δβ)k+1 + (δ∗α, δ∗β)k−1 = (α, Lβ)k.
Moreover, strongly deﬁned Laplacians are always positive semideﬁnite (Psd), since
(Lα, α)k = (δα, δα)k+1 + (δ∗α, δ∗α)k−1 ≥0.
In particular, a discrete k-form is harmonic (Lα = 0) if and only if δα = δ∗α = 0,
just like in the smooth setting.
5.3.4
Strongly and weakly deﬁned Laplacians
Every strongly deﬁned Laplacian acting on 0-forms has a weakly deﬁned cousin L
acting on discrete functions u. The weak version is obtained by requiring that at
every vertex i the resulting function Lu is equal to
(Lu)i = (Lu, 1i)0 = (δ∗δu, 1i)0 = (δu, δ1i)1,
where 1i is the indicator function of vertex i. In particular, let M0 and M1 be
the symmetric positive deﬁnite matrices that encode the inner products between
0-forms and 1-forms, respectively,
(u, v)0 = uT M0v
and
(α, β)1 = αT M1β.
Then the weakly and strongly deﬁned Laplacians satisfy, respectively,
L = δT M1δ
and
L = M−1
0 L.

88
■Generalized Barycentric Coordinates in Graphics and Mechanics
As an example, consider diagonal inner products on 0-forms and 1-forms,
(u, v)0 =
X
i∈V
miuivi
and
(α, β)1 =
X
e∈E
ωeα(e)β(e),
with positive vertex weights mi > 0 and positive edge weights ωe > 0. The resulting
strongly deﬁned Laplacian acting on 0-forms (functions) takes the form
(Lu)i = 1
mi
X
j∼i
ωij(ui −uj)
and its associated weakly deﬁned cousin is the Laplacian on graphs deﬁned in (5.1).
5.3.5
Hodge decomposition
Given a choice of inner products for k-forms on simplicial manifolds, one always
obtains a discrete Hodge decomposition. Indeed, for every discrete k-form α one
has
α = δµ + δ∗ν + h,
where µ is a (k −1)-form, ν is a (k + 1)-form and h is a harmonic k-form (Lh = 0).
As in the smooth case, not only is this decomposition unique, it is also orthogonal
with respect to the inner products on k-forms,
0 = (δµ, δ∗ν)k = (h, δµ)k = (h, δ∗ν)k,
which immediately follows from δ ◦δ = 0 and the fact that harmonic forms satisfy
δh = δ∗h = 0.
Akin to the smooth case, the Hodge decomposition establishes relations to global
properties of simplicial manifolds, since the linear space of harmonic k-forms is iso-
morphic to the k-th simplicial cohomology of the simplicial manifold M. Again, as
an application of this fact, consider a compact simplicial surface without a bound-
ary. Then the dimension of the space of harmonic 1-forms is equal to twice the genus
of the surface—independent of the concrete choice of inner products on k-forms.
5.3.6
The cotan Laplacian and beyond
We conclude the discussion of Laplacians on simplicial manifolds by providing an
important example of inner products. In [426], Whitney constructs a map from
simplicial k-forms (k-cochains) to piecewise linear diﬀerential k-forms. In a nut-
shell, the idea is to linearly interpolate simplicial k-forms across full-dimensional
cells. As the simplest example, consider linear interpolation of 0-forms (functions)
on vertices. This kind of interpolation can be extended to arbitrary k-forms. The
resulting map
W : Ck →L2Λk

A Primer on Laplacians
■89
takes simplicial k-forms to square-integrable k-forms on the simplicial manifold,
where we assume each simplex carries the standard Euclidean structure. The Whit-
ney map is the right inverse of the so-called de Rham map,
α(σ) =
ˆ
σ
W(α)
for all discrete k-forms α and all k-cells σ. For details we refer to [426]. The Whitney
map W is a chain map—it commutes with the diﬀerential (d W = Wδ) and thus
factors to cohomology.
Dodziuk and Patodi [124] use the Whitney map in order to deﬁne an inner
product on discrete k-forms (k-cochains) by
(α, β)k =
ˆ
M
g(Wα, Wβ)volg,
where (in our case) g denotes a piecewise Euclidean metric on the simplicial mani-
fold. From the perspective of the Finite Element Method (FEM), Whitney’s con-
struction is a special case of constructing stable ﬁnite elements; see [12].
For triangle meshes the resulting strongly deﬁned Laplacian acting on 0-forms
(functions) is given by
L = M−1
0 L,
where M0 is the mass matrix given by
(M0)ij =







Aij
12 ,
if i ∼j,
Ai
6 ,
if i = j,
0,
otherwise.
Here Aij denotes the combined area of the two triangles incident to edge (i, j) and
Ai is the combined area of all triangles incident to vertex i. The corresponding
weakly deﬁned Laplacian L is the stiﬀness matrix with entries
Lij =







−1
2(cot αij + cot βij),
if i ∼j,
−P
j∼i Lij,
if i = j,
0,
otherwise,
where αij and βij are the two angles opposite to edge (i, j). The matrix L is often
referred to as the cotan Laplacian.
The cotan Laplacian has been rediscovered many times in diﬀerent con-
texts [130, 134, 309]; the earliest explicit mention seems to go back to Mac-
Neal [262], but perhaps it was already known at the time of Courant. The cotan
Laplacian has been enjoying a wide range of applications in geometry processing
(see [109, 242, 341] and references therein), including barycentric coordinates (see
in particular Section 1.2.2 in this book), mesh parameterization, mesh compression,

90
■Generalized Barycentric Coordinates in Graphics and Mechanics
fairing, denoising, spectral ﬁngerprints, shape clustering, shape matching, physical
simulation of thin structures, and geodesic distance computation.
The construction of discrete Laplacians based on inner products can be extended
from simplicial surfaces to meshes with (not necessarily planar) polygonal faces;
see [8] for such an extension that is similar to the approach considered in [73, 74]
for planar polygons. The cotan Laplacian has furthermore been extended to semi-
discrete surfaces [84] as well as to subdivision surfaces [114].
5.3.7
Discrete versus smooth Laplacians
Structural properties of discrete Laplacians play an important role for computa-
tions; for example, when solving the Poisson problem
Lu = f
for a given right-hand side f and an unknown function u with Dirichlet boundary
conditions. For solving this problem, one often prefers to work with the weak for-
mulation of the problem (Lu = M0f) instead of the strong one (Lu = f) since the
weakly deﬁned cousins of strongly deﬁned Laplacians satisfy properties (Sym) and
(Psd), which allows for eﬃcient linear solvers for this problem.
We now turn to the question of which properties are desirable for discrete Lapla-
cians on top of (Sym) and (Psd) and if it is furthermore possible to recover all
properties of smooth Laplacians in the discrete case. We follow [410], on which this
section is largely based.
Smooth Laplacians are diﬀerential operators that act locally. Locality can be
represented in the discrete case by working with (weakly deﬁned) discrete Lapla-
cians based on edge weights:
(Loc)
vertices i and j do not share an edge
⇒
ωij = 0.
This property reﬂects locality of action by ensuring that if vertices i and j are not
connected by an edge, then changing the function value uj at a vertex j does not
alter the value (Lu)i at vertex i. Property (Loc) results in sparse matrices, which
can be treated eﬃciently in computations.
Keeping an eye on the relation between discrete Laplacians and barycentric co-
ordinates, it is desirable (or even mandatory) to require linear reproduction; see
requirement (1.9) in Chapter 1. In the smooth setting, linear reproduction cor-
responds to the fact that linear functions on Rn are in the kernel of the standard
Laplacian on Euclidean domains. For discrete Laplacians on a graph Γ, linear repro-
duction means that (Lu)i = 0 at each interior vertex whenever Γ is embedded into
the plane with straight edges and u is a linear function on the plane, point-sampled
at the vertices of Γ,
(Lin) Γ ⊂R2 embedded and u: R2 →R linear ⇒(Lu)i = 0 at interior vertices.
In applications this property is desirable for denoising of surface meshes [120] (where
one expects to remove normal noise only but not to introduce tangential vertex

A Primer on Laplacians
■91
drift), mesh parameterization [148] (where one expects planar regions to remain
invariant under parameterization), and plate bending energies [341] (which must
vanish for ﬂat conﬁgurations).
Furthermore, it is often natural and desirable to require positive edge weights:
(Pos)
vertices i and j share an edge
⇒
ωij > 0.
This requirement implies (Psd) and is a suﬃcient (but by no means necessary)
condition for a discrete maximum principle (Max). In diﬀusion problems corre-
sponding to ut = −∆u, (Pos) ensures that ﬂow travels from regions of higher
potential to regions of lower potential. Additionally, as discussed above, positive
edge weights establish a connection to barycentric coordinates.
The combination (Loc)+(Sym)+(Pos) is related to Tutte’s embedding theorem
for planar graphs [172, 400]: Positive weights associated to edges yield a straight-line
embedding of an abstract planar graph for a ﬁxed convex boundary polygon. Tutte’s
embedding is unique for a given set of positive edge weights, and it satisﬁes (Lin)
by construction since each interior vertex (and therefore its x- and y-coordinate) is
a convex combination of its adjacent vertices with respect to the given edge weights.
It is natural to ask which of the properties (Loc), (Sym), (Pos), and (Lin) are
satisﬁed by the discrete Laplacians considered so far.
As the simplest example, consider again the graph Laplacian (ωij = 1). This
Laplacian clearly satisﬁes (Loc)+(Sym)+(Pos), but in general fails to satisfy
(Lin). Next, consider the cotan Laplacian. The edge weights of the cotan Laplacian
turn out to be a special case of weights arising from orthogonal duals. To deﬁne
those, consider a graph embedded into the plane with straight edges that do not
cross. An orthogonal dual is a realization of the dual graph in the plane, with
straight edges orthogonal to primal edges (viewed as vectors in the plane). Edge
weights can then be constructed as the ratio between the signed lengths of dual
edges and the unsigned lengths of primal edges,
ωe = |⋆e|
|e| .
Here, |e| denotes the usual Euclidean length, whereas |⋆e| denotes the signed Eu-
clidean length of the dual edge. The sign is obtained as follows. The dual edge ⋆e
connects two dual vertices ⋆f1 and ⋆f2, corresponding to the primal faces f1 and
f2, respectively. The sign of |⋆e| is positive if along the direction of the ray from
⋆f1 to ⋆f2, the primal face f1 lies before f2. The sign is negative otherwise.
For the cotan Laplacian, the dual graph is obtained by connecting circumcen-
ters of (primal) triangles by straight edges; see Figure 5.1 (left). More generally,
discrete Laplacians derived from orthogonal duals on arbitrary (including non-
planar) triangular surfaces were considered in [166]. These Laplacians always satisfy
(Loc)+(Sym)+(Lin) for the case of planar primal graphs, but fail to satisfy (Pos)
in general. Indeed, for the cotan Laplacian one has (cot αij +cot βij) > 0 if and only
if (αij + βij) < π. This is the case for all edges (i, j) if and only if the triangulation
is Delaunay. One may restore (Pos) by successive edge ﬂips (thereby changing the

92
■Generalized Barycentric Coordinates in Graphics and Mechanics
i
Figure 5.1 Left: Primal graph (solid lines) and orthogonal circumcentric dual graph
(dashed lines) deﬁning the cotan Laplacian. Middle: Mean value weights correspond
to dual edges tangent to the unit circle around a primal vertex. Right: The projec-
tion of the Schönhardt polytope does not allow for a discrete Laplacian satisfying
(Sym)+(Loc)+(Lin)+(Pos).
combinatorics) until one arrives at a Delaunay triangulation [57]. Unfortunately,
the number of required edge ﬂips to obtain a Delaunay triangulation from an arbi-
trary given triangulation cannot be bounded a priori. Therefore, this approach fails
to satisfy locality in general.
More generally, so-called weighted Delaunay triangulations turn out to be the
only triangulations that possess positive orthogonal duals and thus admit discrete
Laplacians that satisfy (Loc)+(Sym)+(Lin)+(Pos). Like Rippa’s theorem (see
above) this fact provides an instance of the intricate connection between properties
of discrete diﬀerential operators (the Laplacian) and purely geometric properties
(weighted Delaunay triangulations).
Finally, if one drops the requirement of symmetric edge weights, then one enters
the realm of barycentric coordinates. In this case one may still obtain an orthogonal
dual face per primal vertex, but these dual faces no longer ﬁt into a consistent dual
graph; see Figure 5.1 (middle). Hence, for the case of dual edges with positive
lengths, one obtains edge weights satisfying (Loc)+(Lin)+(Pos) but not (Sym).
Floater et al. [149] explored a subspace of this case: a one-parameter family of linear
precision barycentric coordinates, including mean value and Wachspress coordinates
(see Section 1.2.4). Langer et al. [232] showed that each member of this family
corresponds to a speciﬁc choice of orthogonal dual face per primal vertex.
The fact that no discrete Laplace operator satisﬁes all of the desired properties
simultaneously is not a coincidence. It can be shown that general simplicial meshes
do not allow for discrete Laplacians that satisfy (Loc)+(Sym)+(Lin)+(Pos);
see [410] for more on this topic and Figure 5.1 (right) for a simple example. This
limitation provides a taxonomy on existing literature and explains the plethora of
existing discrete Laplacians: Since not all desired properties can be fulﬁlled simul-
taneously, it depends on the application at hand to design discrete Laplacians that
are tailored towards the speciﬁc needs of a concrete problem.

A Primer on Laplacians
■93
Another important desideratum is convergence: In the limit of reﬁnement of
simplicial manifolds that approximate a smooth manifold, one seeks to approxi-
mate the smooth Laplacian by a sequence of discrete ones. For applications this is
important in terms of obtaining discrete operators that are as mesh independent
as possible—re-meshing a given shape should not result in a drastically diﬀerent
Laplacian.
A closely related concept to convergence is consistency. A sequence of discrete
Laplacians (∆n)n∈N is called consistent if ∆nu →∆u for all appropriately chosen
functions u. For example, it can be shown that Laplacians on point clouds, such as
those considered in [35] are consistent; see [122].
Convergence is more diﬃcult to show than consistency since it additionally re-
quires that the solutions un to the Poisson problems ∆nun = f converge (in an
appropriate norm) to the solution u of ∆u = f. Discussing convergence in detail is
beyond the scope of this short survey. Roughly speaking, Laplacians on simplicial
manifolds converge to their smooth counterparts (in an appropriate operator norm)
if the inner products on discrete k-forms used for deﬁning simplicial Laplacians con-
verge to the inner products on smooth k-forms. In this case, one obtains convergence
of solutions to the Poisson problem, convergence of the components of the Hodge de-
composition, convergence of eigenvalues and eigenfunctions [124, 134, 191, 409, 427],
and (using diﬀerent techniques) convergence of Cheeger cuts [398].


II
Applications in Computer Graphics
95


C H A P T E R 6
Mesh Parameterization
Bruno Lévy
Inria Nancy Grand Est, Villers-lès-Nancy, France
CONTENTS
6.1
Introduction ......................................................
97
6.2
Applications of mesh parameterization ..........................
98
6.3
Notions of topology ..............................................
100
6.4
Tutte’s barycentric mapping theorem ...........................
102
6.5
Solving the linear systems .......................................
106
6.6
Choosing the weights ............................................
108
T
HIS CHAPTER introduces mesh parameterization, an application of gen-
eralized barycentric coordinates. By “unfolding” a surface onto a 2D space,
mesh parameterization has many possible applications, such as texture mapping. In
this chapter we present some basic notions of topology that characterize the class
of surfaces that admit a parameterization. Then we focus on the speciﬁc case of
a topological disk with its boundary mapped to a convex polygon. In this setting,
Tutte’s barycentric mapping theorem not only gives suﬃcient conditions, but also
a practical algorithm to compute a parameterization. We outline the main argu-
ment of the simple and elegant proof of Tutte’s theorem by Gortler, Gotsman, and
Thurston [172]. It is remarkable that their proof solely uses basic topological no-
tions together with a counting argument. Finally, we mention the importance of the
weights in the quality of the result, and demonstrate how mean value coordinates
can be used to reduce the distortions.
6.1
INTRODUCTION
Before diving into the formal deﬁnition, we ﬁrst give an intuitive explanation of
what a mesh parameterization is. Intuitively, given a triangulated mesh (see Fig-
ure 6.1, left), a parameterization “unfolds” the mesh in 2D (see Figure 6.1, right).
Such an “unfolding” is an interesting representation that can be considered as a
“map” of the 3D object, and that can be exploited by several applications.
97

98
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 6.1 Left: a 3D mesh. (Model courtesy of Stanford University.) Right: a 2D
parameterization of the 3D mesh and a zoom into the region of the head.
More formally, if we denote by pi = (xi, yi, zi) the 3D position of the mesh vertex
vi, i = 1, . . . , nv, where nv denotes the number of vertices, then a parameterization
of the mesh is a set of two additional coordinates ui = (ui, vi) associated with each
mesh vertex.
In addition, these coordinates need to be such that there is no intersection
between the triangles in 2D. This chapter presents a method to generate such (ui, vi)
coordinates. Before entering the heart of the matter, to motivate the subject, we
present several applications of mesh parameterization. We suppose for now that the
(ui, vi) coordinates are already given; how to compute them will be explained later.
6.2
APPLICATIONS OF MESH PARAMETERIZATION
Texture mapping, that is, “wrapping” images around 3D objects, is one of the main
applications of mesh parameterization (see Figure 6.2). Texture mapping uses a
one-to-one correspondence between the 3D mesh and a 2D domain (referred to as
parametric space). It is possible to deﬁne such a correspondence by linearly inter-
polating the (ui, vi) coordinates associated with each vertex of the triangulation.
Suppose you want to know the 3D point that corresponds to a given point u = (u, v)
in parameter space. If the point u corresponds to one of the vertices ui = (ui, vi),
then it is mapped to pi = (xi, yi, vi). If the point u is arbitrary, then it is mapped
as follows:
1. Determine the triangle with 2D vertices ui = (ui, vi), uj = (uj, vj), uk =
(uk, vk) that contains the point u = (u, v);
2. determine the barycentric coordinates (see Section 1.1.1) φ1(u), φ2(u), φ3(u)
of the point u with respect to the triangle [ui, uj, uk];
3. then u is mapped to φ1(u)pi + φ2(u)pj + φ3(u)pk.
Conversely, for an arbitrary 3D point p = (x, y, z) on the mesh, contained in the
triangle t = [pi, pj, pk], one can retrieve its barycentric coordinates φ1(p), φ2(p),
φ3(p) with respect to t by working in the supporting plane of t, and map it to the

Mesh Parameterization
■99
Figure 6.2 A mesh parameterization can be used to “wrap” a 3D object with an im-
age. The used image is a regular grid (left) and a “fur” texture (right). (Model cour-
tesy of Stanford University and fur texture courtesy of www.myfreetextures.com,
used under the Creative Commons license.)
point u = φ1(p)ui +φ2(p)uj +φ3(p)uk. One can check that this procedure deﬁnes
the inverse of the (u, v) →(x, y, z) mapping deﬁned above.
Equipped with this extended, linearly-interpolated mapping, we now have a
one-to-one correspondence between all the 3D points of the surface and all the
2D points of the parametric domain. This correspondence can be used for many
diﬀerent applications. For instance, texture mapping consists of drawing an image
in parametric space, and transporting it onto the surface through the linearly-
interpolated mapping. An example is shown in Figure 6.2. This technique is widely
used both in the movie industry and in interactive 3D graphics (visualization, video
games). In this latter context, graphics processing units (GPUs) have very eﬃcient
optimized silicon for evaluating barycentric coordinates and linearly interpolating
(u, v) coordinates. Texture mapping can also be used to associate a high-resolution
attribute to a coarse mesh, as shown in Figure 6.3. By encoding the ﬁne-scale
Figure 6.3 Application of mesh parameterization: normal mapping. A coarse mesh
(left, compare with Figure 6.1) is textured-mapped with an image that encodes the
ﬁne geometric details of the initial high-resolution mesh (right).

100
■Generalized Barycentric Coordinates in Graphics and Mechanics
geometric details in an image (here the normal vectors), it is possible to “replace
triangles with pixels,” and substantially lower rendering cost and time.
6.3
NOTIONS OF TOPOLOGY
Clearly, not all surfaces admit a parameterization. For instance, a sphere cannot
be mapped to the plane without cutting it or poking a hole (see Figure 6.4, left).
Therefore, it is a necessary condition that the surface has a boundary. However,
it is not a suﬃcient condition. Consider the surface in Figure 6.4 (right): due to
the handle, it is impossible to unfold it to 2D without intersections. Therefore,
it is necessary to be able to determine whether a given mesh has a handle or
not. The number of handles of a surface is referred to as its genus. A sphere (see
Figure 6.5 A, B), has genus 0, a torus (see Figure 6.5 C), has genus 1, a double torus
(see Figure 6.5 E), has genus 2.
The genus (denoted by g in what follows) is a global property of surfaces that is
at ﬁrst sight non-trivial to determine. Fortunately, for a closed connected surface,
it can be deduced from the Euler–Poincaré characteristic χ, another quantity that
is very easy to compute, given by χ = nv −ne + nf, where nv denotes the number
of vertices, ne the number of edges, and nf the number of facets. Both the Euler–
Poincaré characteristic and the genus are topological invariants that depend neither
on the shape of the surface nor on the way it is decomposed into polygons. For
instance, consider the sphere in Figure 6.5 (A), decomposed into 8 vertices, 12
edges, and 6 facets in a cube-like manner. Its Euler–Poincaré characteristic is χ =
8 −12 + 6 = 2. Considering now the tetrahedron-like decomposition of the sphere
in Figure 6.5 (B), one gets χ = 4 −6 + 4 = 2 again. Whatever the considered
decomposition of the sphere, one always gets χ = 2. Let us take a look now at the
torus (see Figure 6.5 C), decomposed as shown in Figure 6.5 (D). It has 16 vertices,
32 edges, and 16 faces, thus χ = 16 −32 + 16 = 0.
Now we would like to know the Euler–Poincaré characteristic of a double torus
(see Figure 6.5 E), that is, a surface of genus g = 2. One possibility would be to
“mesh” the double torus and count the number of elements. Another more inter-
esting method is to analyze how the Euler–Poincaré characteristic χ changes when
one creates a handle, as shown in Figure 6.6. The operation creates a change ∆nv
of the number of vertices and changes ∆ne, ∆nf of the number of edges and faces,
respectively. In turn, χ becomes χ + ∆χ, where ∆χ = ∆nv −∆ne + ∆nf. In the
Figure 6.4 Some surfaces cannot be unfolded to the plane without cutting.

Mesh Parameterization
■101
Figure 6.5 Determining the genus (number of handles) using the Euler–Poincaré
characteristic.
ﬁrst step (A), two faces are deleted, therefore nf is decreased twice (∆nf = −2), as
well as χ = nv −ne + nf. In the second step (B), the two boundary components
created by deleting the two faces are merged. This merges the vertices and the
edges on the boundary components, therefore both nv and ne are decreased by the
same number (there are the same number of vertices and edges on both boundary
components; that is, four in the present example). The changes of nv and ne can-
cel out when taken into account in ∆χ, therefore the second step does not change
χ. To summarize, this operation decreases χ by two. Note that this is completely
independent from the number of vertices in the two facets that are removed; they
just need to match. As a consequence, starting from a sphere that has genus zero
and Euler–Poincaré characteristic χ = 2 (see Figure 6.5), each time one creates a
handle, g is increased by one (by the deﬁnition of g) and χ is decreased by two. To
summarize, for a connected surface without any boundary, we have
χ = nv −ne + nf = 2 −2g.
For example, for the double torus (see Figure 6.5 E), we have g = 2, thus χ =
2 −2g = −4.
Let us now turn to surfaces with multiple connected components and boundaries.
It is easy to see what the formula becomes: since for a topological sphere, χ = 2,
each connected component adds two to the Euler–Poincaré characteristic. Consider
now the “topological surgery” operation that creates a boundary by deleting a facet.
It decreases nf, thus it also decreases χ. To summarize, for a surface with multiple
connected components and multiple boundary components, we have
χ = nv −ne + nf = 2ncc −2g −nbc,
where ncc denotes the number of connected components and nbc the number of
boundary components.
In what follows, we consider topological disks, that is, surfaces with genus zero,
a single connected component, and a single boundary component. They are char-
acterized by
g = 0,
ncc = 1,
nbc = 1.
Using the previous identity, for a topological disk, it is easy to check that χ = 1.
To test whether a given surface mesh is a topological disk, we ﬁrst test the value of
χ = nv −ne +nf. Then we need to determine whether the surface is connected. One

102
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 6.6 Increasing the genus by “topological surgery.” A: delete two facets
(∆nf = −2); B: glue the two holes (∆nv = −4; ∆ne = −4); C: the result
(∆χ = ∆nv −∆ne + ∆nf = −2).
can use a recursive traversal algorithm from an arbitrary facet and test whether it
visits all the facets. Finally, to determine the number of boundary components, one
can iterate along the edges on the boundary component incident to an arbitrary
boundary edge and test whether there exists another boundary edge that was not
visited.
6.4
TUTTE’S BARYCENTRIC MAPPING THEOREM
We now focus on Tutte’s barycentric mapping theorem [400], which not only charac-
terizes a family of mesh parameterizations, but can also be used as a computational
algorithm to create a parameterization [143]. In simple form, this theorem may be
stated as follows.
Theorem 6.1. Consider a 3-connected mesh that is a topological disk and with
vertices in 2D. If the boundary vertices are positioned on a (not necessarily strictly)
convex polygon, and if each interior vertex is a convex combination of its neighbors,
then there is no intersection between the edges and each face is strictly convex.
A mesh is 3-connected if it remains connected after removing any two vertices
and their incident edges. This condition is required to avoid some degeneracies
(collapsed triangles) that occur, for instance, if a long interior edge connects two
vertices on the boundary.
More formally, each interior vertex is a linear combination of its neighbors, if
X
j∈Ni
wijuj = ui,
i = 1, . . . , (nv −nbv),
X
j∈Ni
wijvj = vi,
i = 1, . . . , (nv −nbv),
ui = bu
i ,
i = (nv −nbv + 1), . . . , nv,
vi = bv
i ,
i = (nv −nbv + 1), . . . , nv,
(6.1)

Mesh Parameterization
■103
Figure 6.7 Convex face (A) and non-convex faces (B, C); wheel vertex (D) and
non-wheel vertices (E,F).
where Ni denotes the neighbors of vertex i (that is, all vertices connected to i by
an edge), nbv is the number of boundary vertices, and where vertices are ordered in
such a way that interior vertices appear ﬁrst. The given coeﬃcients wij associated
with the half-edges (i, j) are positive and such that P
j wij = 1. The coeﬃcients wij
are not required to be symmetric (in general, wij ̸= wji). In other words, Condition
(6.1) means that each vertex is inside the convex hull of its neighbors (hence the
term convex combination).
From the given positions of the boundary vertices (ui, vi), i = 1, . . . , nv −nbv
and the weights wij, one can construct a parameterization by solving the two linear
systems in (6.1), as suggested in [143] and explained in the next section. Before
explaining how, the rest of this section deals with the proof of Tutte’s theorem.
The original proof by Tutte [400] requires a substantial background from graph
theory. Later, another proof was proposed by Gortler et al. [172]. This latter proof
is much simpler and only requires elementary concepts. In order to better grasp an
intuition of the structure of the proof, we adopt here a top-down approach (starting
from the conclusion) and skip the details for keeping only the main arguments.
The main argument of the proof, exposed later, is that if (6.1) is satisﬁed, then
each face is strictly convex and each interior vertex is a wheel. Then it is quite
easy to deduce that no two faces can have an intersection. A wheel vertex v is such
that the oriented angles between each pair of consecutive oriented edges emanating
from v are all positive and sum to 2π. Examples of non-wheel vertices are shown
in Figure 6.7 (E) (one of the angles is negative) and Figure 6.7 (F) (the vertex is a
double-wheel, with an angle sum of 4π instead of 2π). Any line in generic position
(thick gray) intersects a convex polygon in zero or two edges (A). Any line that
passes through the center of a wheel intersects two wedges (D). For non-convex
faces (non-wheel vertices, respectively), there exist lines with a larger number of
intersections.
We now show that if (6.1) is satisﬁed, then all polygons are convex and all
vertices are wheels, by studying the relation between a straight line with a direc-
tion vector (α, β) and the polygons’ and vertices’ neighborhoods, and showing that
conﬁgurations such as B, C, E, F cannot be encountered.

104
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 6.8 Left and center: the maximum number of intersections between a polygon
and a line is bounded by the number of sign changes. Right: global structure of sign
changes in the vertices and facets of a mesh with (u, v) coordinates that satisfy the
conditions of Tutte’s theorem.
Consider the conﬁgurations depicted in Figure 6.8, with a line of direction vector
(α, β). Note that the ﬁgure is rotated to make the oriented line direction (α, β)
horizontal. We classify each oriented edge (i, j) as ascending (+) or descending
(−), depending on the sign of the dot product (uj −ui) · n, where n = (−β, α)
denotes the normal vector of the line.
The edges intersected by a line appear in (+, −) pairs, therefore their number
is bounded by the number of sign changes (the vertices that correspond to sign
changes are highlighted in gray in the ﬁgure). A convex polygon has exactly two
sign changes for any (α, β) in generic position (not collinear to an edge), whereas a
non-convex polygon admits (α, β) directions with a larger number of sign changes.
The same reasoning can be applied to the vertices’ neighborhoods.
We now consider a topological disk and transform it into a topological sphere
by adding a face that closes its boundary. The main argument of the proof shows
that if the (ui, vi) coordinates satisfy the conditions of Tutte’s theorem (boundary
vertices on a convex polygon and interior vertices satisfying (6.1)), then for any line
direction (α, β), the structure of the sign changes in the overall mesh is as depicted
in Figure 6.8 (right): all the interior vertices and facets have two sign changes, two
boundary vertices have no sign change (topmost and bottommost), and all the other
nbv −2 vertices have two sign changes. In the ﬁgure, we took a convention that is
diﬀerent from [172]: the arrows correspond to the oriented edges emanating from
each vertex and to the oriented edges that form the boundary of the facets. Sign
changes are highlighted in gray. Note that there is an inﬁnite outer facet (the one
that was added to turn the topological disk into a topological sphere), thus some
sign-changes wedges are on the exterior of the boundary.
To prove that the structure induced by the solution of (6.1) matches this conﬁg-
uration, Gortler et al. [172] make the observation that the set of values n·(uj −ui)
attached to the oriented half-edges of the mesh can be considered as a discrete

Mesh Parameterization
■105
vector ﬁeld (or 1-form) and that it obeys a discrete equivalent of the Poincaré–
Hopf theorem [181], which relates the topology of a vector ﬁeld (here represented
by the sign changes) to the topology of the underlying surface (here a topological
sphere). In a nutshell, this theorem states that the number of singularities of the vec-
tor ﬁeld is equal to the Euler–Poincaré characteristic of the surface. In the present
case, we have a sphere with χ = 2 and two singularities (topmost and bottommost
vertices). Several discrete versions of this theorem were proposed [323, 324]. The
discrete Poincaré–Hopf theorem in [172] can be stated as follows.
Theorem 6.2. For any set of non-vanishing scalar values zij attached to the half-
edges of an oriented mesh with genus g and no boundary and such that zji = −zij,
we have
nv
X
i=1
ind(vi) +
nf
X
j=1
ind(fj) = χ = 2 −2g.
The integer quantities ind(v) = (2 −sc(v))/2 and ind(f) = (2 −sc(f))/2 are
called the index of vertex v and the index of facet f in z. The integer quantities sc(v)
and sc(f) denote the number of sign changes of z when traversing the half-edges
emanating from v and the half-edges turning around f, respectively. The index can
take the following values:
• ind = 1: zij has the same sign for all half-edges of the vertex/face. A vertex
with index one is called a source (+) or a sink (−). A face with index one is
called a vortex;
• ind = 0: a vertex or facet with zero index is said to be non-singular;
• ind < 0: a vertex or facet with negative index is called a saddle.
Proof. The last statement follows, because
nv
X
i=1
ind(vi) +
nf
X
j=1
ind(fj) = 1
2
nv
X
i=1
(2 −sc(vi)) + 1
2
nf
X
j=1
(2 −sc(fj))
= nv + nf −1
2
 nv
X
i=1
sc(vi) +
nf
X
j=1
sc(fj)
!
= nv + nf −ne.
The last step of the derivation above uses the observation that each half-edge intro-
duces exactly one sign change in a vertex and one sign change in a facet: consider
the half-edge h1 in Figure 6.9 and its opposite half-edge h2 (with opposite sign).
There are two cases: either h1 and h2 have the same sign, then the wedge h2, h3 is
a sign change in vertex v, or h1 and h2 have opposite signs, then the corner h1, h2
is a sign change in facet f.
Equipped with this discrete Poincaré–Hopf theorem, we can examine the struc-
ture of sign changes induced by a set of values n·(uj−ui) attached to the half-edges

106
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 6.9 There is exactly one sign change in a vertex and one sign change in a
facet per half-edge.
(i, j) of a mesh, where the ui = (ui, vi) are given by the solution of Tutte’s equa-
tions in (6.1). Note that the faces cannot be vortices (that is, with index one), since
this would mean that one would not end up at its original position when turning
around a facet.
Since the ui’s satisfy Tutte’s equation, it is easy to verify that the values zij
associated with the half-edges emanating from an interior vertex vi satisfy the
condition
X
j∈Ni
wijzij = 0.
Since all the wij coeﬃcients are positive and zij is non-vanishing, the sign of zij
needs to change, thus vi can be neither a source nor a sink. To summarize,
ind(vi) ≤0,
i = 1, . . . , nv −nbv,
ind(fj) ≤0,
j = 1, . . . , nf.
Now, remembering that the maximum possible value for an index is one, the only
possibility we have for reaching the overall value of two dictated by the Poincaré–
Hopf theorem (for χ = 2),
nv
X
i=1
ind(vi) +
nf
X
j=1
ind(fj) = 2,
is to have index zero for all facets and all interior vertices, index one for two bound-
ary vertices, and index zero for all the remaining boundary vertices.
Note that throughout the proof we assume that all the considered geometrical
objects are in generic position. The initial article includes perturbation lemmas
that handle the cases where an edge is collinear with the direction (α, β) of the
intersected line. The original article also includes results for multiple possibly non-
convex boundaries and higher-genus objects that we do not describe here. In the
frame of this chapter, we restrict ourselves to the case of a single topological disk
with a convex boundary. For more general cases, the reader is referred to the original
article [172] and to [61, 66, 201].
6.5
SOLVING THE LINEAR SYSTEMS
Given a topological disk, the 2D positions of its boundary vertices, and the weights
wij, a parameterization can be obtained by solving (6.1). We explain here sev-

Mesh Parameterization
■107
eral methods for solving such linear systems. Tutte’s equation in its original form
corresponds to the linear systems
ui =
X
j∈Ni
wijuj
i = 1, . . . , nv −nbv,
vi =
X
j∈Ni
wijvj
i = 1, . . . , nv −nbv.
Note that the right-hand side contains a mixture of unknowns (the uj’s and vj’s
associated to interior vertices) and ﬁxed values (the uj’s and vj’s associated to
boundary vertices). To re-organize the equation in a form that gathers the ﬁxed
values on the right-hand side, one can extend the deﬁnition of wij with the following
conventions: wii = −1 and wij = 0 if j /∈Ni. We then have
nv−nbv
X
j=1
wijuj = −
nv
X
j=nbv+1
wijuj
i = 1, . . . , nv −nbv,
nv−nbv
X
j=1
wijvj = −
nv
X
j=nbv+1
wijvj
i = 1, . . . , nv −nbv.
In matrix form, the two linear systems can be written as
WXu = Y u,
WXv = Y v,
where W is an (nv −nbv) × (nv −nbv) matrix, and Xu,Y u,Xv,Y v are (nv −nbv)-
dimensional vectors.
We now outline several methods to solve such linear systems. Considering a
system in the form WX = Y , with n = nv −nbv, Gauss–Seidel relaxation is
a method that is very simple to implement. Intuitively, it can be understood by
considering the equation in the form of the linear system
w1,1x1 + w1,2x2 +
· · ·
+ w1,nwn = y1,
...
wi,1x1 + wi,2x2 + · · · + wi,ixi + · · · + wi,nwn = yi,
...
wn,1x1 + wn,2x2 +
· · ·
+ wn,nwn = yn.
The algorithm iterates over and over through the n equations. For each equation i, it
“pretends” that all the variables xj for j ̸= i are known and updates xi accordingly
as
xi ←
1
wii
 
yi −
nv−nbv
X
j=1
wijxj
!
.

108
■Generalized Barycentric Coordinates in Graphics and Mechanics
Replacing the right-hand side component yi with the expression −Pnv
j=nbv+1 wijxj
and wii with −1, we get the update
xi ←−
 
−
nv
X
j=nbv+1
wijxj −
nv−nbv
X
j=1
wijxj
!
or simply
xi ←
X
j∈Ni
wijxj.
To summarize, applying Gauss–Seidel relaxation to Tutte’s equation simply means
iteratively moving each interior vertex to the weighted barycenter of its neighbors.
This method is very simple to implement, and gives results in a reasonable time for
small meshes (with a few thousand elements). If larger meshes need to be processed,
then one can consider using more eﬃcient iterative methods such as the bi-conjugate
gradient method, as suggested in [143]. If memory consumption is not an issue,
sparse direct solvers such as SuperLU [246] can be an even more eﬃcient alternative.
See also the chapter on numerical aspects in [66].
6.6
CHOOSING THE WEIGHTS
Depending on the application, it is often desired to create a parameterization that
minimizes deformations between the 2D parametric space and the 3D surface. Using
uniform weights wij = 1/|Ni|, where |Ni| denotes the number of neighbors of vertex
vi, the obtained parameterization is valid, but can be highly distorted. Figure 6.10
(left) displays the deformations by painting a regular grid in the 2D parametric
space and transforming it onto the 3D surface.
One can use instead as weights wij the mean value coordinates [144, 200], which
take into account the geometry of the input surface and are positive as required by
Tutte’s theorem (see Section 1.2.3). Note that to satisfy the requirements of Tutte’s
theorem, they need to be normalized as in (1.12). The resulting parameterization
is displayed in Figure 6.10 (right).
Figure 6.10 Uniform weights (left) and mean value coordinates (right).

C H A P T E R 7
Planar Shape
Deformation
Oﬁr Weber
Bar-Ilan University, Ramat Gan, Israel
CONTENTS
7.1
Introduction ......................................................
110
7.2
Complex barycentric coordinates ................................
111
7.2.1
Holomorphic functions ...................................
113
7.2.2
General construction of complex barycentric coordinates
118
7.2.3
Magic coordinates ........................................
121
7.3
Variational barycentric coordinates ..............................
123
7.3.1
Point-based barycentric maps ............................
123
7.3.2
Point-to-point barycentric coordinates ...................
124
7.4
Conformal maps .................................................
127
7.4.1
Log derivative construction ..............................
127
7.4.2
Shape interpolation ......................................
130
7.4.3
Variational conformal maps ..............................
131
7.5
Implementation details ..........................................
132
7.5.1
Visualizing planar maps .................................
132
B
arycentric coordinates are extremely useful for deforming shapes. They
lead to smooth deformations that are simple and highly eﬃcient to compute. In
this chapter, we focus on the special case of planar shape deformation, where the
barycentric map can be interpreted as a complex-valued function. We generalize
barycentric coordinates from real to complex-valued functions and introduce the
notion of complex barycentric coordinates. Complex coordinates can lead to planar
barycentric maps with unique shape preserving properties. We provide a general
construction for complex barycentric coordinates (Section 7.2.2) and show how to
design custom-made complex coordinates (Section 7.2.3). We derive holomorphic
coordinates (Section 7.2.1), relying on the rich theory of complex analysis, and
explore their intimate relation to conformal maps (Section 7.4).
109

110
■Generalized Barycentric Coordinates in Graphics and Mechanics
7.1
INTRODUCTION
Interactive shape deformation is a fundamental problem in computer graphics and
geometry processing. It is essential for designing and modeling variations of shapes
and for generating believable animation sequences. In this chapter, we focus on the
special case of planar shape deformation, for which the domain Ωto be deformed
is an open and connected subset of the plane. For simplicity, we assume that the
domain is bounded by a simple polygon P. The codomain is again a subset of
the plane, where in some scenarios (as in Chapter 4), the user explicitly dictates
its shape (e.g., to be a polygon as well), while in other scenarios, more freedom
is allowed, and the shape freely evolves. More formally, our goal is to compute a
map (a vector function) f(x): Ω→R2 that maps points in the domain to points
in the codomain, such that f satisﬁes some boundary constraints while having
certain desirable properties. Some properties, such as smoothness of f, are easier
to attain, whereas other properties, such as local injectivity, are more challenging to
guarantee. The complete list of desired properties will be revealed as the discussion
of this chapter evolves. However, we brieﬂy mention and motivate below the most
important properties and requirements.
The domain Ωis equipped with a colored texture and we are interested in visual-
izing the map f by rendering a high quality image of the codomain. The algorithms
that we consider for computing the underlying map f are indiﬀerent to the choice of
such texture. These algorithms are solely based on geometric considerations; how-
ever, for the result to be valuable from the graphics application standpoint, some
requirements have to be added. A high quality result should preserve the ﬁne details
of the underlying texture. Hence, smoothness of the map is often required. Luckily,
this is relatively easy to obtain when working with barycentric coordinates as it is
implied by the smoothness of the coordinates themselves. In addition to smooth-
ness, we often desire that the amount of metric distortion induced by the map is
as low as possible. We consider both the conformal and the isometric distortion,
where conformal distortion refers to the amount by which angles between arbitrary
intersecting curves are altered under the action of the map, and isometric distortion
refers to the amount of change in the length of arbitrary curves. A map is said to
be conformal if it has zero conformal distortion everywhere. The Jacobian matrix
Jf of a conformal map is a similarity transformation, allowing only rotations with
isotropic scale, but it can have arbitrarily high isometric distortion. Ideally, a map
should be isometric, with a Jacobian that is restricted to be a rotation (without
scale). Unfortunately, unlike the space of conformal maps, the space of isometries
in R2 is fairly restricted and contains only rigid motions (a global rotation and
translation) and reﬂections. Hence, we can only hope for maps that are close to
isometry, having a low amount of isometric and conformal distortion.
In order to control the end result, a user interface is provided, where some
boundary conditions for the map f can be prescribed. For example, the user can
prescribe the shape of the entire target boundary. Since the target boundary is a
curve with an inﬁnite number of degrees of freedom, a common choice in practice
is to assume that the image of the map is bounded by a polygon. The user only

Planar Shape Deformation
■111
determines the vertex positions, and the map is implicitly assumed to be linear
along the polygon edges. Notwithstanding, ﬁxing the entire boundary can be overly
restrictive. It requires more than a bare minimum input from the user and can lead
to less visually pleasing deformations, where the underlying map f has excessive
metric distortion. One way to alleviate this is to use less restricting constraints and
to allow the algorithm to deduce the missing degrees of freedom automatically by
solving a variational problem (Section 7.3). For example, the user can prescribe the
behavior of the map f on a sparse set of interior points rather than on the entire
boundary (Section 7.3.2).
Another requirement is that the underlying algorithms need to be relatively
eﬃcient to compute. This allows the users to explore the space of valuable defor-
mations interactively and to reach their envisioned artistic design by trial and error.
Interactivity and simplicity of the user interface also allow novice users to use the
application. As we will see, many of the involved computations can be done in a
preprocessing step, leaving a marginal amount of computation to be done in run-
time during interaction with the system. Moreover, the deformation can often be
computed in parallel, utilizing the graphics hardware, where the computation time
is of the same order of magnitude as the rendering time itself (Section 7.5).
Working with the special case of maps from R2 to R2 allows us to use an
alternative representation by identifying R2 with the complex plane C. Points
x = (x, y) ∈R2 are identiﬁed with complex numbers z ∈C by z = x + iy. The
map f becomes a complex-valued function of a single complex variable f : Ω→C.
Utilizing complex notation often leads to simpliﬁed expressions and allows us to
rely on powerful mathematical results from the rich theory of complex analysis.
This is particularly apparent when the underlying complex functions are holomor-
phic (complex analytic) and/or harmonic, which are of particular value in shape
deformation due to their smoothness and other mathematical properties.
7.2
COMPLEX BARYCENTRIC COORDINATES
Let z1, . . . , zn ∈C be the vertices of a simple polygon P (not necessarily convex) in
counter-clockwise orientation (see Figure 7.1). We sometimes refer to P as the cage,
as it encapsulates the part of the plane that we would like to deform. The interior
of P is treated as an open domain denoted by Ω. A set of complex-valued functions
φi : Ω→C, i = 1, . . . , n are called complex barycentric coordinates [415] if they
satisfy the complex analogue of the Properties (1.8) and (1.9) in Deﬁnition 1.1,
n
X
i=1
φi(z) = 1,
(7.1)
n
X
i=1
φi(z)zi = z
(7.2)
for all points z ∈Ω.

112
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 7.1 Notation used for complex barycentric maps. Left: the source polygon
P. Note that Bi(z) = zi −z are functions of z, while the edge vectors ei = zi+1 −zi
are independent of z. Right: the target polygon ˆP as well as the image of a complex
holomorphic barycentric map f : Ω→C. Note that f(z) does not interpolate the
target polygon.
A complex barycentric map is a planar map expressed as a complex-valued func-
tion f : Ω→C with
f(z) =
n
X
i=1
φi(z)fi,
where fi ∈C are some complex coeﬃcients. Similarly to the real case, Property (7.1)
is called the constant precision property (or sometimes denoted as the partition of
unity property). It requires that the real parts of the coordinates sum to 1, and
in addition, that their imaginary parts sum to 0. Algebraically, it implies that if g
is a complex constant function over Ω, and fi = g(zi), then f(z) = g(z). In other
words, f reproduces complex constant functions from their vertex values. Geomet-
rically, (7.1) means that the barycentric map is invariant to translations applied
to the cage vertices. Property (7.2) is called the linear precision property. Alge-
braically, it implies that f reproduces complex linear functions over Ωfrom their
vertex values. In particular, it reproduces the (linear) identity function g(z) = z,
and hence it is sometimes referred to as the identity reproduction property. To-
gether, Properties (7.1) and (7.2) imply that f reproduces complex aﬃne functions,
that is, functions ψ: C →C of the form ψ(z) = αz + β, where α, β ∈C are com-
plex constants. However, it is important to note that unlike real barycentric maps,
complex barycentric maps do not, in general, reproduce planar aﬃne maps, that is,
maps g: R2 →R2 of the form g(x) = Ax + b, where A is a 2 × 2 real matrix and
x, b ∈R2 are real vectors (see Figure 7.2). While this may be initially perceived as
a limitation, for the particular application of planar shape deformation, it is mostly
an advantage. The matrix A encodes rotation, isotropic scale, and shear, whereas
in the complex case, the multiplication αz is equivalent to a multiplication of x
by a similarity matrix
  αx −αy
αy
αx

, where α = αx + iαy. In other words, complex
barycentric maps reproduce similarity transformations (translation, rotation, and
isotropic scale) but do not reproduce, in general, anisotropic scale and shears, which
lead to distortion of angles.

Planar Shape Deformation
■113
(c) Cauchy
(a) source
(d) MAGIC
(b) mean value
Figure 7.2 Comparison of real and complex barycentric coordinates. The cage
of a pants shape in (a) is transformed in (b–d) by the aﬃne transformation
g: (x, y) →(2x, y). In (b) the mean value barycentric map reproduces g. In (c)
and (d), the Cauchy and magic complex barycentric coordinates produce maps
that do not reproduce g. The map in (c) is conformal. See color insert.
In addition to constant and linear precision, smoothness is also required, that is,
φi ∈Ck(Ω),
i = 1, . . . , n,
where k is at least 1 (continuously diﬀerentiable), but typically we work with C∞
(inﬁnitely diﬀerentiable) functions.
Note that unlike their real counterpart, complex barycentric coordinates do
not have a sign, hence the positivity property is omitted. The Lagrange property
(interpolation of the boundary data) is possible to attain but we will see that it can
interfere with other (later to be deﬁned) properties such as holomorphicity, hence
it is not considered a mandatory property.
The ﬁrst question that comes to mind is how can we come up with a set of
functions φi that satisfy (7.1) and (7.2)? A thorough answer to this question is
provided in Section 7.2.2. However, we start by deriving a special type of com-
plex barycentric coordinates, which are denoted as Cauchy coordinates. Unlike all
real barycentric coordinates, these coordinates have the special property of being
holomorphic functions.
7.2.1
Holomorphic functions
Holomorphic functions (also known as complex analytic functions) have remarkable
mathematical properties and they are the central objects of study in the mathemat-
ical ﬁeld of complex analysis. We provide below a short introduction to holomorphic
functions and some of their fascinating properties, and refer the reader to [5] for
an in-depth review. A holomorphic function f : Ω→C is a complex-valued func-
tion that is complex diﬀerentiable in a neighborhood of every point z ∈Ω. Complex
diﬀerentiability is a strong condition implying that f is inﬁnitely diﬀerentiable. Fur-
thermore, holomorphic functions are integrable (on a simply connected domain) an
inﬁnite number of times, and these derivatives and anti-derivatives are all holomor-
phic as well. Holomorphic functions form a linear space, hence sums of holomorphic
functions and multiplications of a holomorphic function with a complex scalar are

114
■Generalized Barycentric Coordinates in Graphics and Mechanics
holomorphic. In addition, products and compositions of holomorphic functions are
also holomorphic, and the quotient of two holomorphic functions is holomorphic as
long as the denominator does not vanish.
If a complex function f(x+iy) = u(x, y)+iv(x, y) is holomorphic, then the real
and imaginary parts, u and v, have ﬁrst partial derivatives with respect to x and y
that satisfy the Cauchy–Riemann equations
∂u
∂x = ∂v
∂y ,
∂u
∂y = −∂v
∂x.
The converse is also true under very mild assumptions; that is, if the partial deriva-
tives of f are continuous and satisfy the Cauchy–Riemann equations, then f is
holomorphic. Treating f as a planar map, we can express the Jacobian of f as
Jf =
 ∂u
∂x
∂u
∂y
∂v
∂x
∂v
∂y
!
=
 ∂u
∂x
−∂v
∂x
∂v
∂x
∂u
∂x
!
=
a
−b
b
a

,
where the second equality is due to the Cauchy–Riemann equations. The ﬁrst com-
plex derivative of a holomorphic function with respect to z is often denoted by f ′
and satisﬁes f ′ = a + ib. As can be seen above, the Jacobian matrix of a holo-
morphic function (when treated as a planar map) has the structure of a similarity
matrix. Its determinant is given by det(Jf) = a2 + b2 and is always nonnegative;
hence, holomorphic maps cannot reverse orientation. If a holomorphic map f has
nonvanishing derivative f ′(z) ̸= 0 (which is equivalent to det(Jf) > 0) for every
z ∈Ω, then the map f is called a conformal map. For conformal maps, the Jacobian
above can be expressed as
Jf = r
cos θ
−sin θ
sin θ
cos θ

,
(7.3)
where r = |f ′| =
√
a2 + b2 =
p
det(Jf) is the modulus (length) of the complex
derivative and θ = Arg f ′ is its complex argument, that is, the angle between
the complex number viewed as a vector and the positive real axis. Equation (7.3)
provides a geometric interpretation for conformal maps as those maps that locally
scale (isotropically), rotate, and translate. As such, conformal maps preserve angles
between intersecting curves in the sense that if the angle between the tangents of two
intersecting curves at a point z0 ∈Ωis α, then the angle between the images of these
curves at f(z0) is also α. Conformality also means that small (inﬁnitesimal) circles
are mapped to small circles (rather than ellipses). Conformal maps, in general,
are not isometric as they distort the length of curves. The parameter r in (7.3)
characterizes the amount of change that the conformal map induces on the original
metric. The quantity r2 is called the pullback metric, and the quantity ln r is called
the conformal scale factor. The isometric distortion τ(z) of a conformal map at
a point z ∈Ωmeasures the amount of shrinkage and expansion in a symmetric
manner. Popular deﬁnitions are: |ln r|, max(r, 1
r), or r + 1
r.
A real-valued function u(x, y) is harmonic if it satisﬁes the Laplace equation
∆u = ∂2u
∂x2 + ∂2u
∂y2 = 0.

Planar Shape Deformation
■115
A complex-valued function f(x + iy) = u(x, y) + iv(x, y) is harmonic if both u
and v are harmonic. It is easy to verify (by diﬀerentiation and using the Cauchy–
Riemann equations) that if f is holomorphic then both u and v are harmonic.
Hence, a holomorphic map is also a harmonic map. The converse is not true in
general, with many harmonic planar maps not being holomorphic.
Transﬁnite complex barycentric coordinates
The derivation of holomorphic complex barycentric coordinates can be obtained
through the generalization of the concept of complex barycentric coordinates to the
transﬁnite case. The polygonal region is substituted with an arbitrary domain Ω
bounded by a simple contour ∂Ωwith arbitrary shape. Real transﬁnite barycentric
coordinates are discussed in detail in Chapter 3. Here we focus on the complex
counterpart.
To this end, we use the notion of a kernel function φ: ∂Ω× Ω→C. Loosely
speaking, the continuous contour can be viewed as a polygon with an inﬁnite number
of vertices, and the complex kernel φ(w, z) is viewed as an analogue for the i-th
coordinate where w, a boundary point, substitutes the i-th vertex. Analogously
to (7.1) and (7.2) in the discrete polygonal case, we say that φ(w, z) is a complex
barycentric kernel, if the properties
ˆ
∂Ω
φ(w, z) dw = 1,
(7.4)
ˆ
∂Ω
φ(w, z)w dw = z
(7.5)
hold for every point z ∈Ω. Then, a transﬁnite complex barycentric map is a
complex-valued function f : Ω→C of the form
f(z) =
ˆ
∂Ω
φ(w, z)f(w) dw,
(7.6)
where the diﬀerential dw in the contour integrals in (7.4), (7.5), and (7.6) is complex.
Somewhat surprisingly, there is a fairly simple choice for a kernel φ(w, z) that
satisﬁes (7.4) and (7.5), which is called the Cauchy kernel [36]
φC(w, z) =
1
2πi
1
w −z .
To see why this is true, let us recall Cauchy’s integral formula, which is one of the
most fundamental statements in complex analysis. The statement asserts that the
value of a holomorphic function h: Ω→C at a point z ∈Ω, is fully determined
by its values on the boundary of the domain, and can be expressed explicitly by
evaluating the contour integral,
h(z) =
1
2πi
ˆ
∂Ω
h(w)
w −z dw.
(7.7)

116
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 7.3 The Cauchy transform. The domain on the left is mapped holomorphi-
cally to the domain on the right using the Cauchy transform (7.8). However, note
that g(w) ̸= f(w).
Applying Cauchy’s integral formula to the holomorphic functions h(z) = 1 and
h(z) = z results in (7.4) and (7.5), respectively. The underlying assumption for
Cauchy’s formula to hold is that the function h in (7.7) is holomorphic. At this
point, an interesting question arises. What if we substitute h(w) on the right-hand
side of (7.7) with an arbitrary complex-valued function f : Ω→C that is not
holomorphic? In other words, let us ﬁnd out what we can say about the function
g: Ω→C with
g(z) =
1
2πi
ˆ
∂Ω
f(w)
w −z dw.
(7.8)
Apparently, under very mild assumptions on the smoothness of f in the vicinity
of the boundary, the function g is holomorphic on Ω, hence (7.8) can be seen as a
projection operator that acts on an arbitrary function f and returns a holomorphic
function g. This operator is sometimes referred to as the Cauchy transform [36].
It is important to note that if f in (7.8) is not holomorphic, then the holomorphic
function g will not, in general, interpolate f on the boundary, that is, g(w) ̸= f(w),
w ∈∂Ω(see Figure 7.3). In other words, one cannot expect to prescribe the values
of a function f on ∂Ω, and obtain through (7.8) a holomorphic function f in Ω
having these boundary values. To conclude, if the boundary values of f are such
that there exists a holomorphic function that realizes them, then (7.8) precisely
reproduces them. Otherwise, if a holomorphic function with such boundary values
does not exist, (7.8) obviously does not reproduce it, but still results in a holomor-
phic function. It is important to note that a limitation of holomorphic functions
is that a holomorphic function with arbitrary prescribed boundary values does not
exist.
Derivation of Cauchy coordinates
The next step toward derivation of complex barycentric coordinates is to discretize
the Cauchy transform (7.8) by assuming that f is a function that belongs to a
ﬁnite-dimensional function space. In the language of boundary element methods
(BEM), such f is called a trial function. While many choices are possible, a simple
choice is to assume that f is a complex piecewise aﬃne continuous function, that

Planar Shape Deformation
■117
is, f is a (diﬀerent) similarity transformation on each polygon edge. The space of
piecewise aﬃne continuous functions on the boundary of P can be parameterized
by a set of complex coeﬃcients fi, i = 1, . . . , n. Geometrically, one can think of fi
as the vertices of a target polygon ˆP that is in one-to-one correspondence with the
source polygon P. Each edge of the source polygon (zi, zi+1) is then mapped to a
corresponding edge (fi, fi+1) in the target polygon by the similarity transformation
(see Figure 7.1)
Si(z) = Bi+1(z)fi −Bi(z)fi+1
ei
,
(7.9)
where Bi(z) = zi −z, and ei = zi+1 −zi. The contour integral in (7.8) is then split
into a sum of integrals over the polygon edges,
g(z) =
1
2πi
n
X
i=1
zi+1
ˆ
zi
Si(w)
w −z dw,
(7.10)
where the integral over each edge has a simple closed-form expression,
zi+1
ˆ
zi
Si(w)
w −z dw = Si(z) Log
Bi+1(z)
Bi(z)

+ ˆei,
(7.11)
where ˆei = fi+1 −fi, and Log is the principal branch of the complex logarithm.
When summing over all edges, the term ˆei in (7.11) vanishes since the target polygon
is closed. Plugging the expression Si(z) Log
  Bi+1(z)
Bi(z)

into (7.10) and rearranging the
terms yields the discrete Cauchy transform of f,
g(z) =
n
X
i=1
Ci(z)fi,
(7.12)
where the functions Ci(z) are called the Cauchy barycentric coordinates and have
the closed-form expression
Ci(z) =
1
2πi
Bi+1(z)
ei
Log
Bi+1(z)
Bi(z)

−Bi−1(z)
ei−1
Log
 Bi(z)
Bi−1(z)

.
(7.13)
A similar derivation with other types of trial functions f in (7.8) can be obtained.
For example, a higher-order polynomial per edge can be used, as well as discontinu-
ous piecewise smooth functions. Such choices typically provide better approximation
power and lead to more accurate results [414, 417] but are excluded here to keep
the discussion simple.
Cauchy coordinates are shown in [415, Theorem 3] to be equivalent to Lipman’s
Green coordinates [252]. Green coordinates are a generalization of real barycentric
coordinates where the barycentric map is expressed as a sum of two terms, the ﬁrst
blends the target vertex positions, and the second blends the normals to the tar-
get edges. The derivation of Green coordinates is done through the application of

118
■Generalized Barycentric Coordinates in Graphics and Mechanics
Green’s third integral identity to harmonic functions, which is equivalent in 2D to
Cauchy’s integral formula [5]. The (real-valued) expressions for Green coordinates
are more complicated, compared to (7.13), and working with complex numbers is
a great advantage; however, in contrast to Cauchy coordinates, Green coordinates
have a natural generalization to 3D where they lead to volumetric harmonic maps
[42, 252].
7.2.2
General construction of complex barycentric coordinates
In the previous section we derived Cauchy complex barycentric coordinates. Our
construction was based on Cauchy’s kernel, which reproduces holomorphic functions
in the transﬁnite case. Holomorphic functions are extremely valuable in the context
of planar shape deformation due to their relation to conformal maps. However,
holomorphic maps form a rather small subspace out of the wider space of complex-
valued maps. In particular, they do not allow for the Lagrange (interpolation)
property to hold. Non-holomorphic complex barycentric coordinates clearly exist,
since any real barycentric coordinates are also complex barycentric coordinates. As
we will see next, there exist complex barycentric coordinates that are neither real
nor holomorphic, and in contrast to Cauchy’s coordinates, some of them possess
the Lagrange property.
It is convenient to think about complex barycentric coordinates as a special type
of complex basis functions that are associated with the cage’s vertices. However,
unlike arbitrary basis functions, the additional requirements (7.1) and (7.2) make
it challenging to design such coordinates. To overcome this problem, we follow the
same approach as in Section 1.1.2.
Deﬁnition 7.1. A set of complex-valued functions wi : Ω→C, i = 1, . . . , n that
satisfy
n
X
i=1
wi(z)(zi −z) = 0
(7.14)
at every point z ∈Ωare called complex homogeneous coordinates.
Normalizing these weight functions then gives complex barycentric coordinates.
Proposition 7.2. Let wi(z) be complex homogeneous coordinates, such that their
sum at every point z ∈Ωis nonvanishing. Then the normalized functions
φi(z) =
wi(z)
nP
j=1
wj(z)
(7.15)
are complex barycentric coordinates.
Proof. The partition of unity property (7.1) follows immediately from the normal-
ization in (7.15). The linear precision property (7.2) is due to
n
X
i=1
φi(z)zi =
n
X
i=1
wi(z)zi
nP
j=1
wj(z)
=
1
nP
j=1
wj(z)
n
X
i=1
wi(z)zi =
1
nP
j=1
wj(z)
n
X
i=1
wi(z)z = z,

Planar Shape Deformation
■119
where the third inequality follows from (7.14).
Proposition 7.2 is useful because ﬁnding complex homogeneous coordinates is
simpler than ﬁnding complex barycentric coordinates. Rather than vertex-based
weight functions, let us consider weight functions γi that are associated conceptually
with the i-th edges.
Proposition 7.3. Let γi : Ω→C, i = 1, . . . , n be arbitrary weight functions, then
the functions
wi(z) = γi(z)Bi+1(z)
ei
−γi−1(z)Bi−1(z)
ei−1
(7.16)
are complex homogeneous coordinates.
Proof. The proof follows directly by plugging (7.16) into (7.14),
n
X
i=1
wi(z)(zi −z) =
n
X
i=1
wi(z)Bi(z) =
n
X
i=1
γi(z)Bi+1(z)Bi(z)
ei
−γi−1(z)Bi−1(z)Bi(z)
ei−1
=
n
X
i=1
γi(z)Bi+1(z)Bi(z)
ei
−
n
X
i=1
γi−1(z)Bi−1(z)Bi(z)
ei−1
=
n
X
i=1
γi(z)Bi+1(z)Bi(z)
ei
−
n
X
i=1
γi(z)Bi(z)Bi+1(z)
ei
= 0,
where in the third row, we shifted the summation index on the right-hand side by
one.
Proposition 7.4. The sum of the weight functions γi at every point in the domain
is identical to the sum of the homogeneous coordinates wi in (7.16).
Proof.
n
X
i=1
wi(z) =
n
X
i=1
γi(z)Bi+1(z)
ei
−γi−1(z)Bi−1(z)
ei−1
=
n
X
i=1
γi(z)Bi+1(z)
ei
−
n
X
i=1
γi−1(z)Bi−1(z)
ei−1
=
n
X
i=1
γi(z)Bi+1(z)
ei
−
n
X
i=1
γi(z)Bi(z)
ei
=
n
X
i=1
γi(z)Bi+1(z) −Bi(z)
ei
=
n
X
i=1
γi(z)zi+1 −z −(zi −z)
ei
=
n
X
i=1
γi(z)zi+1 −zi
ei
=
n
X
i=1
γi(z).

120
■Generalized Barycentric Coordinates in Graphics and Mechanics
As an immediate corollary of Proposition 7.4, we have that if the γi have nonva-
nishing sum, then the homogeneous coordinates wi of (7.16) also have nonvanishing
sum.
We have basically shown that for any set of arbitrary complex weight functions
γi with nonvanishing sum, there is a corresponding set of complex barycentric coor-
dinates. Constructing barycentric coordinates from the weight functions is straight-
forward. Simply plug the γi weight functions into (7.16) to obtain the homogeneous
coordinates wi (Proposition 7.3) and normalize (Proposition 7.2) by either Pn
i=1 wi
or Pn
i=1 γi to obtain complex barycentric coordinates φi. Hence, we simpliﬁed the
task of constructing complex barycentric coordinates to the task of ﬁnding arbi-
trary weight functions with nonvanishing sum. Moreover, the above construction
covers the entire space of complex barycentric coordinates in the sense that for any
complex barycentric coordinates φi there exist (not necessarily unique) weights γi
that result in φi if the above construction is applied. The proof is done by choosing
γ1 arbitrarily and recursively computing all other γi using (7.16) [415].
We now provide an alternative interpretation for the weight functions γi. Any set
of complex-valued weight functions γi with a nonvanishing sum everywhere inside
the domain corresponds to the complex barycentric map [416]
f(z) =
n
X
i=1
Si(z)˜γi(z),
(7.17)
where Si are the unique similarity transformations that map the edges of the
source cage to the edges of the target cage (recall (7.9) for their expression) and
˜γi = γi
Pn
j=1 γj are the normalized weights. The converse is also true. That is,
any complex barycentric map can be expressed as a (normalized) blending of edge-
to-edge similarity transformations. In particular, it is easy to verify that the choice
of γi = Log
  Bi+1
Bi

leads to Cauchy’s coordinates. This alternative viewpoint is
somewhat more intuitive geometrically than (7.16). It emphasizes that the weight
functions can be associated with the edges and is useful for deriving custom-made
barycentric coordinates (Section 7.2.3). Moreover, it allows us to extend the concept
of barycentric maps in two possible ways. First, we can use (7.17) for an arbitrary
collection of segments that do not necessarily form a closed polygon, allowing us
to deﬁne “partial” cages or to augment a given cage with additional interior seg-
ments for extra user control. The second possible extension is to substitute the
similarity transformations Si in (7.17) with more general edge-to-edge aﬃne trans-
formations Ai,
f(z) =
n
X
i=1
Ai(z)˜γi(z).
Note that such planar maps cannot in general be expressed as real or complex
barycentric maps. However, their evaluation is straightforward and as computa-
tionally eﬃcient as the evaluation of barycentric maps, since the weights ˜γi can be
computed and stored in a preprocessing step.

Planar Shape Deformation
■121
(b)
Cauchy
(a)
source
(c)
Figure 7.4 Blending edge-to-edge aﬃne maps. A source cage of a pants shape in (a)
is deformed identically in (b) and (c) to create an eﬀect of legs stretching. In (b) the
edge-to-edge aﬃne maps are chosen to be similarities. The map from (a) to (b) is the
holomorphic Cauchy barycentric map. In (c) the edge-to-edge aﬃne maps stretch
only in the direction of the edges but not in the orthogonal direction, resulting
in a non-holomorphic map with a more natural look that better approximates the
target cage. See color insert.
Planar aﬃne maps A(z) = az + bz + c have three complex degrees of freedom
a, b, c ∈C. Two are nailed down by the requirement to map the source edge end-
points to the target ones, Ai(zi) = fi and Ai(zi+1) = fi+1. The third degree of
freedom controls the behavior of the map in the direction orthogonal to the edge.
Let ei = zi+1−zi and ˆei = fi+1−fi, then the (unnormalized) normals to the source
and target edges are ni = iei and ˆni = iˆei. We require that Ai transforms the vector
ni to the vector ρiˆni, where ρi ∈C, and it turns out that the edge-to-edge aﬃne
maps can be expressed as
Ai(z) = fi −(ρi + 1)ˆeiBi(z)
2ei
+ (ρi −1)ˆeiBi(z)
2ei
.
If ρi = 1, then the anti-holomorphic term on the right-hand side above vanishes
and Ai(z) = Si(z). An alternative choice is to use ρi = |ei|/|ˆei|, which maps the
source normal to a vector that is orthogonal to the target edge while maintaining
its length. This encourages the map to allow stretch only in the direction tangential
to the boundary. Figure 7.4 shows a comparison between two types of maps having
γi = Log
  Bi+1
Bi

. The ﬁrst map uses ρi = 1, and is hence identical to Cauchy’s
coordinates, while the second map uses ρi = |ei|/|ˆei|.
7.2.3
Magic coordinates
In the previous section we showed how to construct complex barycentric coordi-
nates based on arbitrary weight functions γi. Since the similarity transformations
Si are holomorphic functions, it is clear that if γi are holomorphic, then the com-
plex barycentric map (7.17) is also holomorphic. Obviously, there exist complex

122
■Generalized Barycentric Coordinates in Graphics and Mechanics
barycentric coordinates that are not holomorphic, as real barycentric coordinates
are a special case of complex barycentric coordinates, where the imaginary part
is 0. For example, the well-known Wachspress, mean value, and discrete harmonic
coordinates can be derived using the weights
γi(z) =
ei
Im(BiBi+1)
|Bi+1|p
Bi+1
−|Bi|p
Bi

,
(7.18)
with p = 0, p = 1, and p = 2, respectively. It is easy to verify that for p = 2 the γi
in (7.18) are real-valued functions and complex-valued functions otherwise. In fact,
it turns out [416, Theorem 3] that the discrete harmonic coordinates are the only
real-valued barycentric coordinates with a real-valued γi function.
Holomorphicity is a strong condition that conﬂicts with the need to interpolate
the boundary data. While all holomorphic barycentric maps are non-interpolating,
almost all real barycentric maps are interpolating. It is interesting then to explore
new types of complex barycentric coordinates that are interpolating, yet not purely
real. These are obviously not holomorphic.
Suﬃcient conditions for interpolation of complex barycentric coordinates are
discussed in [416]. Loosely speaking, each weight function γi should approach inﬁn-
ity on its corresponding edge (including its endpoints) while being ﬁnite elsewhere.
This ensures that the limit of the normalized weight ˜γi is 1 when approaching a
point on the open (i.e., excluding the endpoints) i-th edge from within the do-
main, while all other weights ˜γj, j ̸= i approach zero. Hence, the barycentric map
f = Pn
i=1 Si˜γi maps the open i-th edge as Si. For the exact suﬃcient conditions,
as well as the conditions to interpolate the vertices, see [416, Section 3.1].
Let us demonstrate how to design “custom-made” coordinates with desirable
properties, in particular the Lagrange property. To interpolate the vertices, we
include in the weight function γi the term 1/|Bi(z)Bi+1(z)|, which grows to inﬁnity
at the i-th edge endpoints and decays as the distance to the edge increases. This
term is ﬁnite on the edge itself, hence we include the term 1/(π −θi(z)), where
θi(z) = Im(Log(Bi+1(z)/Bi(z))) is the signed angle of the triangle [z, zi, zi+1] at
z (see Figure 7.1). The angle θi(z) ∈(−π, π] approaches π as z approaches the
open edge (zi, zi+1) from within the cage, causing the weight function to explode,
providing interpolation. Finally, we add a third term that weighs the contribution
of each edge according to its length |ei|. Combining the three terms results in
the weight functions of the Made-to-order Angle Guided Interpolating Coordinates
(MAGIC)
γi(z) =

ei
Bi(z)Bi+1(z)

1
π −θi(z).
Since these weight functions are strictly positive everywhere, it is clear that their
sum is non-vanishing, hence they correspond to barycentric coordinates. Moreover,
γi are C∞except at the edges where they have a jump discontinuity, hence the
magic coordinates are smooth inside the cage but do not extend smoothly to the
exterior of the cage. Figure 7.5 provides a comparison between magic and (real)
harmonic coordinates [215].

Planar Shape Deformation
■123
(a) source
(c) MAGIC
(b) harmonic
Figure 7.5 Comparison of magic and harmonic coordinates. The upper part of the
cage in (a) is bent to the right. (b) The result of harmonic coordinates. Note the
spilling of the image outside the cage in the vicinity of the corner where the map is
not bijective (see the zoom-in images). (c) The result with the magic coordinates.
See color insert.
7.3
VARIATIONAL BARYCENTRIC COORDINATES
So far we have constructed complex barycentric coordinates with a closed-form ex-
pression. Such coordinates are eﬃcient to compute, simple to implement, and have
high numerical accuracy. We now introduce other types of coordinates that possess
additional properties that are highly desirable in the context of planar shape defor-
mation. These coordinates, unfortunately, do not possess a closed-form expression
and are approximated numerically. While their derivation is more involved, the
additional computational eﬀort can be performed in a preprocessing step. Once
the computation of the coordinates is completed, in runtime, the evaluation of the
barycentric map is as eﬃcient as any other barycentric map. This new type of coor-
dinate obeys some variational principles and is considered optimal with respect to
such principles. Such coordinates are obtained through the solution of a numerical
optimization problem.
7.3.1
Point-based barycentric maps
A limitation of holomorphic maps is that they cannot, in general, satisfy positional
boundary conditions at every boundary point, therefore holomorphic barycentric
maps do not possess the Lagrange property. Nonetheless, we can always ﬁnd a
holomorphic map with some desirable values at a ﬁnite set of points. Prescribing
the exact behavior of the map at such points allows the users to better control
the deformation and fulﬁll their design goals. Let rj ∈Ω, j = 1, . . . , p be a set of
user-deﬁned points inside the domain. We would like to ﬁnd a holomorphic function
g: Ω→C that maps rj to prescribed target positions qj. In order to guarantee that
the map is holomorphic, we use the discrete Cauchy transform g(z) = Pn
i=1 Ci(z)fi
in (7.12), where for any choice of the coeﬃcients fi, the map g is holomorphic by

124
■Generalized Barycentric Coordinates in Graphics and Mechanics
construction. Our goal then is to design an optimization problem in which fi are the
unknowns. Intuitively, rather than relocating the target cage vertices fi manually,
we design a procedure that relocates fi automatically such that the corresponding
holomorphic map g satisﬁes the desirable requirements.
Adding a positional constraint to our optimization boils down to satisfying
g(rj) =
n
X
i=1
Ci(rj)fi = qj.
Since rj is constant, so is Ci(rj). Thus, the above equality constraint is aﬃne in the
variables fi and easy to enforce. Setting p = n, such constraints correspond to a
nonsingular linear system of equations with a unique solution. One possible choice is
to use rj = zj, that is, to design holomorphic complex barycentric coordinates that
interpolate the vertices of the cage. The edges themselves will not be interpolated,
though.
Trying to add more than n constraints leads to an overdetermined system that
has no solution. A possible remedy is to obtain a least-squares solution that min-
imizes an energy that measures the Euclidean distances between the image of the
points rj and their desired target positions qj,
min
f1,...,fn
p
X
j=1
|qj −g(rj)|2 =
min
f1,...,fn
p
X
j=1
qj −
n
X
i=1
Ci(rj)fi

2
.
(7.19)
In [415], the points rj are taken to be dense uniform samples on the source cage,
and qj are the corresponding samples on the target cage. The solution to the least-
squares problem (7.19) is obtained by solving a linear system, leading to a new
type of barycentric coordinates that are called the Szegő coordinates. Since the
energy is not zero, in general, the Szegő barycentric map does not interpolate the
target cage. However, it provides better approximation compared to the Cauchy
barycentric map, which has a higher energy (7.19).
7.3.2
Point-to-point barycentric coordinates
Till now, the user interacted with the deformation system by manipulating the ver-
tices of the cage. In many cases, the user is not interested in prescribing the exact
shape of the boundary of the deformed shape. Especially for shapes with a com-
plicated boundary that consists of hundreds of vertices, manipulating each vertex
separately is time-consuming. Instead, it makes more sense to prescribe the position
of a small set of p < n points (also called P2P handles) that are not necessarily part
of the boundary, while allowing the boundary to deform freely. In this scenario, the
corresponding linear system is underdetermined and has an inﬁnite number of so-
lutions. This provides an opportunity to pick a particular solution with additional
desirable geometric properties. A simple, yet powerful choice is to regularize the
solution, allowing the barycentric map to be as smooth as possible. This can be
achieved by minimizing some aggregated diﬀerential quantity. More speciﬁcally, we

Planar Shape Deformation
■125
wish to solve the optimization problem
min
f1,...,fn
1
2
ˆ
∂Ω
|g′′(w)|2ds,
s.t.
g(rj) = qj,
j = 1, . . . , p,
(7.20)
where fi ∈C are the variables, g(z) is the discrete Cauchy transform, and
g′′(z) = Pn
i=1 C′′
i (z)fi is its second complex derivative. The choice of g′′ rather
than g′ in (7.20) is due to the fact that the second complex derivative of a sim-
ilarity transformation S(z) = αz + β is zero everywhere. Therefore, if the user
transforms the P2P handles using a similarity S(z), the solution to the optimiza-
tion is fi = S(zi) with the corresponding map g(z) = S(z) having zero energy. In
particular, the map g reproduces the identity map if the P2P handles are ﬁxed,
that is, if g(rj) = rj, j = 1, . . . , p, then g(z) = z.
Luckily, the derivatives of Cauchy coordinates possess simple closed-form ex-
pressions [414, Appendix C–E]. In particular the second derivative is given by
C′′
i (z) =
1
2πi

1
Bi−1(z)Bi(z) −
1
Bi(z)Bi+1(z)

.
(7.21)
The boundary integral in (7.20), however, is approximated numerically. The sim-
plest way to approximate the integral is to substitute it with a summation over a
dense set of k ≫n boundary samples, where the sampling should be as uniform as
possible. This allows us to assume that the diﬀerential ds is approximately constant.
While Cauchy coordinates have well-deﬁned limits at the vertices [414, Appendix
B], the second derivative in (7.21) is singular at the vertices. There are two possible
ways to avoid these singularities. One is to exclude the cage vertices from the set of
samples (note that (7.21) is well-deﬁned on the open edges). A second choice is to
oﬀset the source cage in the outward normal direction by a very small amount, and
to use the outward oﬀset cage as our new cage. The original cage (which is strictly
inside the oﬀset cage) is then sampled. This choice also makes the evaluation of the
Cauchy coordinates themselves simpler.
With the integral being approximated as a sum, we can express (7.20) in matrix
form
min
f
1
2∥Ef∥2,
s.t.
Af = q,
(7.22)
where f ∈Cn×1 is the complex column vector with fi as entries, E ∈Ck×n is
the matrix of second complex derivatives of the Cauchy coordinates evaluated at
the samples, A ∈Cp×n is the matrix of Cauchy coordinates evaluated at the P2P
handles, and q ∈Cp×1 is the vector with the user-speciﬁed target P2P positions.
Equation (7.22) is a linearly constrained least-squares problem. Its solution can
be obtained using the method of Lagrange multipliers. Let λ ∈Cp×1 be additional
variables (the Lagrange multipliers), then the solution to (7.22) can be obtained by

126
■Generalized Barycentric Coordinates in Graphics and Mechanics
solving the linear system

M
AH
A
0
 f
λ

=
0
q

,
(7.23)
where | · |H stands for the conjugate transpose matrix, and the matrix M ∈Cn×n
is given by EHE. Let B ∈Cn+p×n+p be the block matrix on the left-hand side
of (7.23). Let the block matrix B−1 =
  · T
· ·

be the inverse of B, with T ∈Cn×p,
then the solution to (7.22) is given by f = T q. The matrix T represents a linear
transformation that maps the user-prescribed target positions of the P2P handles
qj to the (unknown) target cage vertices fi. Computing T boils down to evaluating
B and inverting it. Evaluating B is embarrassingly parallel and can be computed
eﬃciently using modern GPUs. Since B is typically small, the time for inverting it is
often short and the typical runtime for computing T for a complicated shape is less
than a second. More importantly, this computation is done once in preprocessing.
In a typical deformation application, the barycentric coordinates are also eval-
uated in a preprocessing step on a set of m points inside Ωon which we want to
evaluate the barycentric map. Let C ∈Cm×n be a matrix of Cauchy coordinates
evaluated at these points, then during interaction with the system, the only com-
putation that is done is that of the vector d ∈Cm×1 of deformed points, which is
given by the matrix-vector multiplication d = Cf. Since f = T q, we have d = P q,
where P = CT is in Cm×p. The matrix P can be computed in preprocessing as
well, hence during interaction we only need to compute the multiplication P q,
which is more eﬃcient than Cf since the number of P2P handles p is typically
much smaller than the number of vertices in the cage n.
Finally, the columns of P can be interpreted as a special type of complex
barycentric coordinates, where the vertices of the cage in the barycentric map are
substituted with the P2P handles. We call them the P2P-Cauchy coordinates. Call-
ing them barycentric coordinates is justiﬁed by the fact that they have constant
precision (7.1) and linear precision (7.2). Figure 7.6 shows two examples of image
deformation made with the P2P-Cauchy coordinates. An alternative derivation of
P2P coordinates can be done by substituting the equality constraints of (7.20) with
soft constraints [415]. This results in a smoother deformation at the expense of only
approximating the P2P handles.
It is important to note that the quality of variational coordinates like the Szegő
and P2P-Cauchy coordinates can be dramatically improved at the expense of longer
preprocessing times. Whereas the discrete Cauchy transform always produces holo-
morphic functions, in contrast to the smooth Cauchy transform (7.8), the discrete
transform only spans a ﬁnite-dimensional subspace of holomorphic functions. As
the number of cage vertices increases, the subspace becomes richer. A simple way
to enrich this subspace is to insert “virtual” vertices along the cage edges without
altering the geometry of the cage. Typically, the cage is up-sampled as uniformly
as possible such that the total number of vertices is at least 200. A non-uniform
sampling strategy is also possible, and the actual number of vertices depends on
the complexity of the shape and the intended eﬀect.

Planar Shape Deformation
■127
source
deformed
source
deformed
Figure 7.6 Deformation with P2P-Cauchy coordinates. The P2P handles are de-
picted by cyan disks. See color insert.
7.4
CONFORMAL MAPS
A common mistake is to identify holomorphic functions with planar conformal
maps. While a planar conformal map can be expressed as a holomorphic function,
the converse is not always true. A holomorphic function f : Ω→C is conformal only
if its ﬁrst complex derivative f ′ is nonvanishing everywhere in the domain. If f is
holomorphic and f ′(z0) = 0 for a point z0 ∈Ω, then angles between intersecting
curves at z0 are not preserved. Furthermore, the isometric distortion induced by
the map is inﬁnite at the singular point z0, and high in its vicinity. The turning
number of the image of the boundary curve increases, and the map is not locally
injective at z0. For planar shape deformation, we are mostly interested in locally
injective maps with low distortion and artifacts like these should be avoided.
7.4.1
Log derivative construction
As we saw in the previous sections, generating holomorphic maps is quite simple,
but unfortunately, conformal maps do not form a linear subspace and are harder
to control. If f is Cauchy’s barycentric map represented as f(z) = Pn
i=1 Ci(z)fi,
the additional condition |f ′(z0)| > 0 that guarantees that f is conformal at z0
is a non-convex constraint. Non-convex constraints pose a great challenge for nu-
merical optimization and cannot be enforced eﬃciently in general. We can address
this diﬃculty by parameterizing the space of conformal maps, by using alternative
variables. On a simply connected domain Ω∈C, there is a one-to-one correspon-
dence between the space of conformal maps and the space of holomorphic maps
[241, 417]. If f is conformal, it is also holomorphic. The derivative of a holomorphic
map is holomorphic, hence f ′ is holomorphic and nonvanishing. The complex log-
arithm of a nonvanishing holomorphic function is holomorphic, meaning that if f
is conformal, then l(z) = log(f ′(z)) is holomorphic. With this observation in hand,
we represent our conformal map based on the holomorphic function l. No special

128
■Generalized Barycentric Coordinates in Graphics and Mechanics
non-convex constraints on l are needed. We proceed by designing a holomorphic
function l according to some criteria, and for each such l, a unique corresponding
conformal map is reconstructed. The reconstruction process is the key to success
and is described as follows. First, we compute the function el(z), which is holomor-
phic since the complex exponent is, and composition of holomorphic functions is
holomorphic. Such a holomorphic function is nonvanishing by construction since
el(z) = e|l(z)| ̸= 0. We interpret el(z) as the (nonvanishing) derivative of our (un-
known) conformal map, and compute its antiderivative to ﬁnally recover the map
f. This is possible since on a simply connected domain, holomorphic functions are
integrable and their antiderivative is also holomorphic.
With these observations in hand, the problem of computing a conformal map
becomes that of computing a meaningful holomorphic function l followed by a
reconstruction step. Recalling the discussion on the derivative of holomorphic func-
tions in Section 7.2.1, and the deﬁnition of the complex logarithm, we have that the
function l encodes the amount of local scale and rotation in its real and imaginary
parts, respectively,
l(z) = log(f ′(z)) = ln(|f ′(z)|) + i arg f ′(z).
We discretize the function l as
l(z) =
n
X
i=1
Di(z)li,
(7.24)
with the basis functions
Di(z) =
1
2πiγCauchy
i
(z) =
1
2πi Log
Bi+1(z)
Bi(z)

.
Other choices for discretization are possible, including higher order approximations
[417], but this simple choice suﬃces for the sake of discussion. The coeﬃcients li in
(7.24) can be interpreted as the piecewise constant values of log(f ′(z)) on the edges
of the cage and our goal is to estimate them from the data provided by the user,
that is, the shape of the target cage. Our simple choice is to aim at designing a
conformal map f that acts as a (diﬀerent) similarity transformation on each edge.
Given the unique similarity Si from (7.9) that maps the source edge to the target
edge, the derivative is given by S′
i(z) = ˆei/ei and we use li = log(ˆei/ei).
When computing li in practice, care should be taken when evaluating the com-
plex logarithm, which is a multi-valued function. Standard C++/MATLAB soft-
ware implementations only produce the single-valued principal branch, and using it
independently on each edge may lead to wrong assignment for the imaginary part
that encodes the rotation of the edge in radians. Instead, we suggest the following
strategy to recover the correct angles. The rotation of the ﬁrst edge is computed
as l1 = Log(ˆe1/e1), where Log is the standard principal branch implementation
with imaginary values in the range (−π, π]. To compute the subsequent li, we ﬁrst
compute the diﬀerence of corner vertex angles between the source and target cages,
di = Log
 ˆei
ˆei−1

−Log
 ei
ei−1

,

Planar Shape Deformation
■129
source
Cauchy
conformal
Figure 7.7 A comparison between holomorphic and conformal maps. Left: source do-
mains. Middle: deformation with Cauchy’s coordinates. Note the vanishing deriva-
tive which is emphasized in the zoom-in images. Right: conformal maps obtained
from the same target cage. See color insert.
and then accumulate these values to obtain the correct rotation of the edges,
li = li−1 + di,
i = 2, . . . , n.
We assume that the turning number of the target cage is 1, or equivalently that
Pn
i=1 di = 0. This makes sense since a necessary condition for local injectivity of
any map (in particular, conformal) is that the image of the boundary curve under
the map forms a self-overlapping curve (which implies that the turning number is
one) [419].
Plugging li into (7.24) provides a closed-form expression for the logarithm of
the derivative l(z) of our conformal map f(z) at any point z ∈Ω. Furthermore, the
derivative is given by the single-valued function el(z), which also has a closed form.
Yet in order to obtain the actual map f, we need the antiderivative
´
el(z), which
cannot be expressed in a straightforward manner. This antiderivative is holomor-
phic (hence precisely integrable) but it does not belong, in general, to the ﬁnite-
dimensional space spanned by the discrete Cauchy transform. To alleviate this,
we can either project
´
el(z) to the Cauchy’s ﬁnite-dimensional space [417] (which
boils down to solving a small dense linear system), or approximate the integral
numerically [101, 241]. Both alternatives are very eﬃcient to compute.
The reconstruction of the conformal map from its derivative is only unique up
to a complex constant that corresponds to a global translation. The simplest way
to nail down this degree of freedom is to allow the user to pick an anchor point
z0 ∈Ω, and set f(z0) = Pn
i=1 φi(z0)fi, where φi are barycentric coordinates (we
used Cauchy’s coordinates in Figure 7.7), and fi are the target cage vertices. Since

130
■Generalized Barycentric Coordinates in Graphics and Mechanics
source t=0
deformed t=1
t=0.5
Figure 7.8 Interpolation of a conformal map. The domain on the left is mapped
conformally to the domain on the right. Blending the logarithm of the derivative
linearly with t=0.5 leads to the conformal map in the middle. See color insert.
the reconstructed conformal map does not interpolate the target cage, a slightly
more sophisticated alternative is to solve for the translation (and possibly even for
a similarity) that will minimize the distance between the target cage and the image
of the boundary. Figure 7.7 provides a comparison of deformations between holo-
morphic maps obtained with the cage-based Cauchy’s coordinates and the simple
cage-based conformal method that we described. Both methods are highly eﬃcient
to compute as they do not require solving a numerical optimization problem at
runtime.
7.4.2
Shape interpolation
Planar shape interpolation is a classical problem in computer graphics. It is impor-
tant for creating animation sequences and for exploring shape spaces. A naive and
widely used interpolation approach is to linearly blend the input maps. If f 1(z) and
f 2(z) are conformal, then f t(z) = (1−t)f 1(z)+tf 2(z), for t ∈[0, 1] is holomorphic
but is not, in general, conformal. However, generating conformal maps based on
the logarithm of the derivative (see Section 7.4.1) also leads to a natural way for
interpolating two or more conformal maps.
The idea is to linearly blend the log derivatives rather than the maps themselves,
and then to reconstruct the map (which is conformal by construction). For brevity,
let us consider the most common case where we want to blend a given conformal
map f with the identity map. Since the logarithm of the derivative of the identity
map is 0 we have lt(z) = t l(z), where l(z) is the log derivative of f(z). Blending
l linearly leads to natural visually pleasing results, since rotations (the imaginary
part of l) are blended linearly. Figure 7.8 shows such a result where we computed
l using the simple technique described in Section 7.4.1. Then we reconstructed the
conformal map as before and repeated the reconstruction process with 0.5 l(z) as
input.

Planar Shape Deformation
■131
7.4.3
Variational conformal maps
The simple strategy of constructing a conformal map from l can be extended by
using a variational approach, designing a numerical optimization in which the real
and imaginary parts of li in (7.24) are variables. We can add, for example, equality
constraints on the real and/or imaginary parts of l(rj) at some user-deﬁned points
rj at which the user can precisely control the amount of scale and/or rotation
induced by the map. Such constraints are linear in the variables and can be easily
enforced. In fact, in the continuous case, it is possible to prescribe the scale or the
rotation (but not both) on the entire boundary (of a simply connected domain). In
[417], the rotation is fully prescribed on the boundary and a linear system is solved
to recover l. Furthermore, the method of [241] can be used to enforce additional
inequality constraints that bound the isometric distortion (recall Section 7.2.1),
τ(w) =
ln |f ′(w)|
.
The goal is to bound the distortion at a point yj by some positive user-deﬁned
constant Γ. This constraint can be expressed as
τ(yj) ≤Γ
⇔
−Γ ≤ln |f ′(yj)| ≤Γ
⇔
−Γ ≤Re (log(f ′(yj))) ≤Γ
⇔
−Γ ≤Re (l(yj)) ≤Γ,
where it is easy to see that the last row corresponds to two inequalities that are
linear in our variables. Such inequalities are convex and can be enforced eﬃciently
in practice using convex programming [67]. Furthermore, since Re (l(z)) is the real
part of a holomorphic function, it is harmonic, therefore its minimum and maximum
are attained on the boundary. Hence, bounding the isometric distortion of a con-
formal map on the boundary implies a global bound throughout the entire domain,
which guarantees that the conformal map in hand is of high quality. Bounding the
distortion on the boundary is still challenging since there are still an inﬁnite number
of boundary points. However, due to the smoothness of the basis functions, this can
be accomplished by forcing a bound on a ﬁnite dense set of boundary samples yj
[95].
The approach presented in this section for computing conformal maps is simple
to implement and fairly eﬃcient. Nevertheless, it does not allow for prescription of
positional constraints (P2P handles) since the positions are highly nonlinear expres-
sions in the li variables. A sophisticated approach based on non-convex program-
ming was introduced in [95]. This method is order of magnitudes slower compared
to the ones presented here, but it produces remarkable results and can still run at
interactive rates.

132
■Generalized Barycentric Coordinates in Graphics and Mechanics
7.5
IMPLEMENTATION DETAILS
In this section we provide some directions for the eﬃcient implementation of a
planar deformation system and point out some practical aspects that should be
considered.
7.5.1
Visualizing planar maps
Accurate and eﬃcient visualization of barycentric maps is an important part of our
shape deformation system. To this end, we should make an eﬀort to perform as
much as possible computations in preprocessing for the sake of faster computations
during interaction. In addition, it is advised to utilize parallelism and in particular
to shift computations to the graphics processer when possible.
The simplest and most eﬃcient way to visualize the map is to use the GPU’s
ability to eﬃciently texture map triangle meshes. The user provides the polygonal
cage that deﬁnes the source domain and a dense triangulation (a mesh) of the
domain is computed (once) in preprocessing. We have found the code of [355] useful,
though other high quality and eﬃcient triangulation algorithms exist. At runtime,
the map is evaluated on the vertices of this mesh and the GPU renders the deformed
mesh with the original vertex positions as (u, v) texture coordinates. Since the
GPU’s rasterizer assumes that the map is piecewise linear on the triangles, it is
preferable to use a high density mesh in order to obtain smooth results.
The next step is to compute the barycentric coordinates and store them in a
large dense matrix. Some care should be taken with certain types of coordinates
such as Cauchy’s, since their expression (7.13) is singular on the boundary. The
limits when approaching an edge or a vertex from within the cage exist [414],
but special classiﬁcation of the vertices according to their position is required. This
complicates the implementation and is less suitable for implementation on the GPU,
where regularity is crucial. A simple “trick” to avoid this problem is to oﬀset the
cage in the outward normal direction and to use the oﬀset cage for the derivation
of the coordinates. The amount of oﬀsetting should be small enough to avoid visual
artifacts and large enough to avoid numerical errors when evaluating the vertices
that lie on the boundary. We used a default value of 0.0001, where the cages we
used have a diameter of 10 units.
Evaluating basis functions is an embarrassingly parallel process. For each in-
ternal mesh vertex vj and each cage vertex zi the coordinate function Ci(vj) can
be computed independently. Moreover, the regular memory access pattern is suited
perfectly for a GPU implementation. Algorithm 1 shows our MATLAB code for
computing a matrix of Cauchy’s coordinates. The running time on a machine with
Nvidia’s Quadro K6000 processor for a mesh with 125, 000 vertices of the pants
shape of Figure 7.2 is 17 milliseconds.
The most critical computation is the evaluation of the barycentric map, since
this is done during interaction. Here again, there is room for exploiting parallelism,
since the evaluation of f(vj) = Pn
i=1 Ci(vj)fi is independent for each internal
vertex vj. This computation can be expressed as a matrix-vector multiplication,

Planar Shape Deformation
■133
Algorithm 1 Parallel MATLAB code for computing Cauchy’s coordinates. z is a
complex vector of internal mesh vertices, and z_i is a complex vector of oﬀset cage
vertices. The output is the coordinates matrix C. This code runs in parallel on the
CPU. Moreover, if a CUDA-enabled GPU is available, and z is of type gpuArray,
the computation is automatically performed on the GPU.
e_i = z_i([2:end 1], :) - z_i;
e_i_m = e_i([end 1:end-1], :);
B_i = bsxfun(@minus, z_i.’, z.’);
B_i_p = B_i(:, [2:end 1]);
B_i_m = B_i(:, [end 1:end-1]);
C = (1/(2*pi*1i))*(B_i_p.*bsxfun(@rdivide, log(B_i_p./B_i), e_i.’)
- B_i_m.*bsxfun(@rdivide, log(B_i./B_i_m), e_i_m.’));
for which many eﬃcient parallel implementations are widely available. If the GPU
is being used, it is preferable to compute and store the coordinates matrix on the
GPU (during the preprocess) without transferring it to the CPU, and to perform
the matrix-vector multiplication directly on the GPU. The Matlab code for doing
it is as simple as d=C*f, where C is the matrix computed in Algorithm 1, f is the
target cage vertices, and d is the deformed vertex positions. For maximum eﬃciency,
it is possible to instruct the GPU to perform the rendering of the mesh directly
according to d, which resides on the GPU memory, avoiding redundant data transfer
between the GPU and the CPU.


1
0.5
0
1.5
<0
>1.5
¯Ω0
¯Ω1
¯Ω1
¯Ω1
Figure 4.4 Color-coded plots of Jf for the mean value mapping f : ¯Ω0 →¯Ω1 for
diﬀerent target polygons, which remains positive when the perturbation is small,
but becomes negative for large deformations.
source
t = 0.2
t = 0.4
t = 0.6
t = 0.8
target
Figure 4.12 Example of a composite mean value mapping between two polyhedra.
The color shows how the interior of the source polyhedron is morphed to the interior
of the target polyhedron.
(c) Cauchy
(a) source
(d) MAGIC
(b) mean value
Figure 7.2 Comparison of real and complex barycentric coordinates. The cage
of a pants shape in (a) is transformed in (b–d) by the aﬃne transformation
g: (x, y) →(2x, y). In (b) the mean value barycentric map reproduces g. In (c)
and (d), the Cauchy and magic complex barycentric coordinates produce maps
that do not reproduce g. The map in (c) is conformal.

(b)
Cauchy
(a)
source
(c)
Figure 7.4 Blending edge-to-edge aﬃne maps. A source cage of a pants shape in (a)
is deformed identically in (b) and (c) to create an eﬀect of legs stretching. In (b) the
edge-to-edge aﬃne maps are chosen to be similarities. The map from (a) to (b) is the
holomorphic Cauchy barycentric map. In (c) the edge-to-edge aﬃne maps stretch
only in the direction of the edges but not in the orthogonal direction, resulting
in a non-holomorphic map with a more natural look that better approximates the
target cage.
(a) source
(c) MAGIC
(b) harmonic
Figure 7.5 Comparison of magic and harmonic coordinates. The upper part of the
cage in (a) is bent to the right. (b) The result of harmonic coordinates. Note the
spilling of the image outside the cage in the vicinity of the corner where the map is
not bijective (see the zoom-in images). (c) The result with the magic coordinates.

source
deformed
source
deformed
Figure 7.6 Deformation with P2P-Cauchy coordinates. The P2P handles are de-
picted by cyan disks.
source
Cauchy
conformal
Figure 7.7 A comparison between holomorphic and conformal maps. Left: source do-
mains. Middle: deformation with Cauchy’s coordinates. Note the vanishing deriva-
tive which is emphasized in the zoom-in images. Right: conformal maps obtained
from the same target cage.

source t=0
deformed t=1
t=0.5
Figure 7.8 Interpolation of a conformal map. The domain on the left is mapped
conformally to the domain on the right. Blending the logarithm of the derivative
linearly with t=0.5 leads to the conformal map in the middle.
(
)
3
2
5
4 ,
2
2
)
1(
)
1(
v
u
−
−
2)
1(
)
1(
2
v
u
u
−
−
2
2
)
1(
v
u
−
2
2v
u
2
2)
1(
v
u
−
2
)
1(
2
uv
u
−
v
v
u
)
1(
)
1(
2
2
−
−
v
v
u
)
1(
2
2
−
v
v
u
u
)
1(
)
1(
4
−
−
p
(
)
3
2
5
4 ,
225
1
225
8
225
16
225
4
225
32
225
64
225
4
225
32
225
64
Figure 8.10 Image deformation using S-patches. The left image shows the image
and a point to evaluate the deformation at which each control point lists its basis
functions using a quadratic S-patch with Wachspress coordinates. The middle image
shows the weights associated with the evaluation point after evaluating the basis
functions. Moving the control points induces a deformation on the image shown on
the right.

Figure 8.11 An example of surface deformation using linear S-patches. The initial
surface of a horse is surrounded by a low resolution approximation called a cage
(left). The right two images show diﬀerent deformations where the head and torso
are kept the same size but the neck and legs are compressed or stretched.
Figure 9.3 In a high-quality optimized Delaunay mesh of Bimba con Nastrino, we
show the set of tetrahedra for which the distance between weighted circumcenter
and barycenter is greater than a threshold, before (left) and after (right) the HOT
optimization [289]. The primal triangulations are the same, and this signiﬁcant
optimization is done only on the dual, using the weights.

Figure 10.1 Left: A freeform masonry structure, composed of rigid, unreinforced
blocks. (Image courtesy of Mathias Höbinger, used by permission.) Middle: The
thrust network that certiﬁes that this masonry structure is stable under its own
weight. Each edge radius is proportional to the magnitude of compressive force
carried by the edge. Right: An arch in 2D, with the self-load, and the thrust line
certifying its stability, both illustrated.
(a)
(b)
1.0
0.0
0.5
Figure 11.3 (a) Stress ﬁeld (von Mises) resulting from a ﬁnite element analysis of
the I-beam shown in Figure 11.1 with applied torsional tractions, (b) cross-section
view. (Reproduced with permission from [48].)

(a)
(b)
50 × 103
25 × 103
0
Figure 11.6 Large deformation example, a hyperelastic beam subjected to a torsion
loading. One end is ﬁxed while a full 360◦rotation is applied to the opposite end.
(a) original polyhedral mesh (Voronoi tessellation with maximal Poisson seeding),
(b) deformed shape and von Mises stress ﬁeld.
(a)
(b)
Figure 11.8 Example of polyhedral meshing using barycentric subdivision (see Fig-
ure 11.7(a)): (a) Barycentric dual of the tetrahedral mesh shown in Figure 11.1(c);
(b) Each polyhedral cell is represented as a diﬀerent color.

Figure 12.1 An illustration of the limited capability of standard tetrahedral ele-
ments to undergo large deformation. Experimentally, a synthetic rubber ﬁlled with
20% volume fraction of randomly distributed silica particles can be stretched more
than four times its original length (λ = 4) without internal damage under uniaxial
tension [315]. By contrast, a ﬁnite element model, based on standard 10-node hy-
brid elements with linear pressure, is only able to deform to a macroscopic stretch
of λ = 1.5 [174].
Figure 12.2 (a) Contour plot of a mean value basis φ(1)
i
over a concave polygon.
(b) Contour plot of quadratic basis φ(2)
i
over a concave polygon associated with a
vertex. (c) Contour plot of quadratic basis φ(2)
i
over a concave polygon associated
with a mid-side node.

Figure 12.11 (a) The unit cell considered in the problem. (b) The quadratic tri-
angular mesh comprised of 58,814 CPE6MH elements and 118,141 nodes in total,
with 71,179 nodes in the matrix phase. (c) The linear polygonal mesh comprised of
39,738 elements and 76,020 nodes in total, with 66,095 nodes in the matrix phase.
(d) The quadratic polygonal mesh comprised of 20,205 elements and 95,233 nodes
in total, with 67,325 nodes in the matrix phase. This ﬁgure is adapted from [100].

Figure 12.12 For loading condition (i), displaying pure shear with average deforma-
tion gradient ⟨F ⟩= λe1 ⊗e1 + λ−1e2 ⊗e2, λ ≥1, the ﬁgure illustrates the ﬁnal
deformed conﬁguration reached by (a) M2 −M1 elements, (b) M2 −P1 elements,
(c) M1−P0 elements, and (d) CPE6HM elements (solved in ABAQUS). This ﬁgure
is adapted from [100].

Figure 12.14 For loading condition (ii), displaying ⟨F ⟩= I + γe1 ⊗e2, γ ≥0,
the ﬁgure illustrates the ﬁnal deformed conﬁgurations reached by (a) M2 −M1
elements, (b) M2−PD
1 elements, (c) M1−PD
0 elements, and (d) CPE6HM elements
(solved in ABAQUS). Both matrix and interphase are considered to be typical
silicone rubber.

Figure 13.1 Set of vertices V in two dimensions, along with the convex hull P.
0
0.5
1
1.5
2
2.5
3
0
0.2
0.4
0.6
0.8
1
 = [0.6  1.2  1.8  2.4  3  3.6  4.2  4.8  5.4  6]
(a)
(b)
(c)
Figure 13.3 Local maximum-entropy (LME) basis functions. (a) Selected basis func-
tions for a one-dimensional vertex set, with varying non-dimensional aspect ratio
parameter γi = βih2, see main text. (b) Basis functions for an interior node in
a two-dimensional set of vertices and diﬀerent aspect ratio parameters, and (c)
representative basis functions of boundary nodes.

(a)
Maximum-entropy second 
order basis function
Moving-least-squares 
second order basis function
(b)
LME function
Cell-maxent function
(c)
Figure 13.4 Extensions of maximum-entropy approximations. (a) Representative
second-order maximum entropy basis function, compared to a moving-least-squares
function, which is wiggly and negative at some points. (b) Comparison of a standard
LME basis function and a cell-based maximum entropy basis function supported on
a triangulation, which results in a structured adjacency relation and more eﬃcient
calculations to approximate PDEs for a comparable accuracy. (c) Combination of
LME approximants with a boundary representation based on B-splines.

(a)
(b)
Figure 13.5 Application of the LME approximants to high-order PDEs. (a) In phase-
ﬁeld models of biomembranes, the unknown ﬁeld deﬁning the shape of a moving
interface is governed by a fourth-order PDE. Therefore, a Galerkin method requires
smooth basis functions (with square integrable second derivatives). The phase ﬁeld
develops sharp gradients, calling for an adaptive solution and an approximation
scheme devoid of Gibbs phenomenon. All these conditions are met by LME approx-
imations. (b) shows two snapshots in a dynamical simulation tracking the shape
of a deforming vesicle made out of a ﬂuid membrane with curvature elasticity, to-
gether with the hydrodynamics of the surrounding ﬂuid. The resolution of the set
of vertices follows the sharp variations of the phase-ﬁeld.

Nonlinear dimensionality 
reduction of each partition
2D embedding of partition (*), where 
smooth parametrization using LME 
approximants is deﬁned.
(a)
(b)
Partitioned point-set surface
(*)
(c)
Figure 13.6 Approximation of manifolds using an atlas of smooth LME parametriza-
tions. (a) Methodology to deﬁne local parametrizations mapping partitions of a
surface deﬁned by a set of points. (b) Application of this method to solve the high-
order PDE for a nonlinear Kirchhoﬀ–Love shell. (c) Application of the method to
describe the molecular conformations of alanine dipeptide, a small molecule. An
ensemble of conformations of this molecule samples an underlying conﬁgurational
manifold homeomorphic to a torus. With the method presented in (a), this manifold
is partitioned into four pieces, each of which is parametrized with LME approxi-
mants. This method allows us to deﬁne smooth collective variables for this system,
required to enhance sampling in molecular dynamics simulations.

Figure 15.1 Vertex (left), edge (middle), and interior (right) polygonal basis func-
tions for k = 2 on a square element.

C H A P T E R 8
Multi-Sided Patches via
Barycentric Coordinates
Scott Schaefer
Texas A&M University, College Station, USA
CONTENTS
8.1
Introduction ......................................................
136
8.1.1
Bézier form of curves ....................................
136
8.1.2
Evaluation ................................................
137
8.1.3
Degree elevation ..........................................
137
8.2
Multisided Bézier patches in higher dimensions .................
138
8.2.1
Indexing for S-patches ...................................
139
8.2.2
Evaluation ................................................
141
8.2.3
Degree elevation ..........................................
142
8.3
Applications ......................................................
143
8.3.1
Surface patches ...........................................
143
8.3.2
Spatial deformation ......................................
144
C
HAPTER 1 introduced several constructions of barycentric coordinates as
well as their properties. In this chapter, we explore the deep connection
between barycentric coordinates and higher order parametric representations of
curves, surfaces, and volumes in arbitrary dimension. In the case of curves, these
curves are known as Bézier curves, which are used in applications from font rep-
resentations to controlling animations. The extension to convex surface patches,
called S-patches [257], is more recent. As originally proposed, S-patches were para-
metric, multi-sided surface patches restricted to convex domains. However, these
restrictions were more of a function of the limited set of generalized barycentric
coordinates, namely Wachspress coordinates, available at that time. Today we have
generalized barycentric coordinate functions that do not require convexity and ex-
tend to arbitrary dimension. Hence, we will investigate S-patches within their full
generality, aﬀorded by modern barycentric coordinates with generalized domains
and in arbitrary dimension.
135

136
■Generalized Barycentric Coordinates in Graphics and Mechanics
8.1
INTRODUCTION
8.1.1
Bézier form of curves
To begin, we consider one of the simplest instantiations of barycentric coordinates.
Consider the domain deﬁned by the interval [0, 1]. This interval yields barycentric
coordinate functions
φ0(x) = (1 −x),
φ1(x) = x,
(8.1)
which reproduce constant and linear functions,
φ0(x) + φ1(x) = 1,
0 · φ0(x) + 1 · φ1(x) = x.
If we examine the terms of the binomial expansion of (φ0(x) + φ1(x))m, we obtain
functions of the form
Bm
j (x) =
m
j

(1 −x)m−jxj,
(8.2)
where m is the degree of the functions Bm
j (x). These functions are special functions
called Bernstein basis functions. Associating these functions with control points fj
yields a Bézier curve
F(x) =
m
X
j=0
Bm
j (x)fj.
Note that F(x) trivially reproduces constant functions due to the fact that φ0 and
φ1 form a partition of unity. For example, if fj = c, then
c =
m
X
j=0
Bm
j (x)c = c ((1 −x) + x)m.
In addition, F(x) can also reproduce all polynomial functions up to degree m. This
last property follows directly from the linear reproduction property of barycentric
coordinates. In particular, to reproduce a function xk where k ≤m, there exists
coeﬃcients fj such that
F(x) = (φ0(x) + φ1(x))m−k(0 · φ0(x) + 1 · φ1(x))k = 1m−kxk = xk,
where the coeﬃcients fj are given by collecting the coeﬃcients of Bm
j (x) in the
polynomial expansion above. For example, to reproduce the function x, the coeﬃ-
cients are given by fj = j/m. Such properties also follow directly from the theory
of blossoming and polar forms [316], which is beyond the scope of this chapter.
In addition, the barycentric coordinate functions φi also impart a number of
useful geometric properties on the resulting Bézier curves. For example, Bézier
curves interpolate their end points due to the Lagrange property of barycentric
coordinates. Bézier curves also fall within the convex hull of their control points over
the interval [0, 1] since 0 ≤φi(x) ≤1 for all x ∈[0, 1]. The curves are also aﬃnely

Multi-Sided Patches via Barycentric Coordinates
■137
Figure 8.1 An example cubic Bézier curve (left) and the curve degree elevated to a
quartic (right).
0p
1p
1
0
p
b
p
a
+
a
b
Figure 8.2 An example pyramid diagram. The values at the base are multiplied by
the constants on the arrows and summed to produce the result at the apex of the
pyramid.
invariant; that is, transforming each control point by an aﬃne transformation T
transforms the Bézier curve by T. Figure 8.1 shows an example of a Bézier curve
where the fj are points in R2.
8.1.2
Evaluation
While we can evaluate Bézier curves by evaluating the polynomial expressions in
the Bernstein basis functions, a more elegant solution exists via de Casteljau’s
algorithm. To do so, we introduce a graphical notation for a linear combination of
two control points. Figure 8.2 shows a simple pyramid diagram. The arrows denote
taking the product of the value at the base of the arrow with the scalar value listed
along the arrow. The result of this product is then added to the sum at the end of
the arrow. Hence, this ﬁgure denotes taking f0, f1 and multiplying these values by
a, b, respectively, to form the result af0 + bf1. Using this notation, de Casteljau’s
algorithm can be written in a very elegant fashion as a pyramid diagram shown in
Figure 8.3 [167]. Note that each level of the pyramid produces lower order Bézier
functions with the value of the curve appearing at the apex of the pyramid.
8.1.3
Degree elevation
Degree elevation for Bézier curves is simply ﬁnding a Bézier curve of degree m+1 to
represent a Bézier curve of degree m. One beneﬁt of performing degree elevation is
that the process introduces an additional control point that can be used to control
the shape of the curve. Furthermore, the addition of this new control point does

138
■Generalized Barycentric Coordinates in Graphics and Mechanics
0f
1f
2f
3f
1
0
)
1(
xf
f
x
+
−
2
1
)
1(
xf
f
x
+
−
3
2
)
1(
xf
f
x
+
−
2
2
1
0
2
)
1(
2
)
1(
f
x
f
x
x
f
x
+
−
+
−
3
2
2
1
2
)
1(
2
)
1(
f
x
f
x
x
f
x
+
−
+
−
3
3
2
2
1
2
0
3
)
1(
3
)
1(
3
)
1(
f
x
f
x
x
f
x
x
f
x
+
−
+
−
+
−
x
−
1
x
x
x
−
1
x
x
−
1
x
x
−
1
x
x
−
1
x
x
−
1
Figure 8.3 The de Casteljau algorithm for cubic Bézier curves.
not change the shape of the curve. Such degree elevation is always possible since
every Bézier curve of degree m is also a Bézier curve of degree m + 1.
To derive degree elevation, it is useful to notice a connection between the Bern-
stein basis functions of diﬀerent degrees. Using (8.2), we can show that
Bm+1
j
(x) =
m + 1
m + 1 −j φ0(x)Bm
j (x) = m + 1
j
φ1(x)Bm
j−1(x).
Therefore, we can elevate the degree of a Bézier curve by simply multiplying a
degree m Bézier curve by (φ0(x) + φ1(x)), so that
F(x) =
 m
X
j=0
Bm
j (x)fj
!
(φ0(x) + φ1(x))
=
m+1
X
j=0
Bm+1
j
(x)

j
m + 1fj−1 + m + 1 −j
m + 1
fj

.
Figure 8.1 (right) shows an example of elevating the degree of a Bézier curve.
8.2
MULTISIDED BÉZIER PATCHES IN HIGHER DIMENSIONS
Section 8.1.1 provides some hint as to how we might extend the univariate curve
construction to domains such as polygons or even polytopes in higher dimensions
through the use of generalized barycentric coordinates. In particular, we use the
extension of (8.1) to more generalized domains. Given a polygon P with vertices

Multi-Sided Patches via Barycentric Coordinates
■139
vi ∈Rd, the generalized barycentric coordinate functions φi satisfy
n
X
i=1
φi(x) = 1,
n
X
i=1
φi(x)vi = x
(8.3)
for all points x ∈Rd (although x may be restricted to P for some barycentric
coordinate constructions).
To build S-patches, we examine the functions that arise from the multinomial
expansion of the barycentric basis functions
 n
X
i=1
φi(x)
!m
=
X
|ℓ|=m
m
ℓ

n
Y
i=1
φi(x)ℓi
where the index ℓ= (ℓ1, . . . , ℓn) is a vector of n non-negative integers, |ℓ| is the sum
of the entries of ℓ, and
 m
ℓ

is the multinomial coeﬃcient
 m
ℓ

=
m!
ℓ1!ℓ2!···ℓn!. Setting
Bm
ℓ(x) to be the corresponding term in this expansion yields
Bm
ℓ(x) =
m
ℓ

n
Y
i=1
φi(x)ℓi.
(8.4)
These basis functions are the generalization of the Bézier basis functions from
Section 8.1.1. In fact, if we use the barycentric basis functions from (8.1), we obtain
the exact same curves albeit with a diﬀerent indexing scheme. If we associate values
fℓwith each of these basis functions, we obtain a multi-sided Bézier function
f(x) =
X
|ℓ|=m
Bm
ℓ(x)fℓ,
which is also known as an S-patch. Like univariate Bézier curves, S-patches can
reproduce all polynomials up to total degree m, which follows directly from (8.3).
For example, to reproduce x, the control points are given by
fℓ=
n
X
i=1
ℓi
mvi.
(8.5)
Unlike univariate curves, the barycentric coordinate functions in (8.3) are not neces-
sarily polynomials. Nevertheless, we will refer to the S-patch basis functions Bm
ℓ(x)
as a function of degree m indicating the total degree of the individual barycentric
coordinate functions φi.
8.2.1
Indexing for S-patches
For curves, indexing control points is trivial as each basis function is simply given
an index j = 0, . . . , m based on an ordering of the Bernstein basis functions. How-
ever, this simple indexing scheme does not extend to higher dimensions. As already

140
■Generalized Barycentric Coordinates in Graphics and Mechanics
)
20000
(
)
02000
(
)
00200
(
)
00002
(
)
00020
(
)
10001
(
)
11000
(
)
01100
(
)
00110
(
)
00011
(
)
10100
(
)
10010
(
)
01001
(
)
00101
(
)
01010
(
Figure 8.4 Indexing of a quadratic pentagonal S-patch using the speciﬁed connec-
tivity rule.
alluded to in (8.4), S-patches use a multi-index to refer to control points. Each con-
trol point fℓis associated with an index vector of length n non-negative integers
whose sum is the degree m of the patch. Given a polygon P, we typically draw
the control points in canonical position such that fℓare placed so that F(x) = x.
Luckily, this combination is solely a function of P, independent of what barycentric
basis we choose, and is given by (8.5).
In addition, there is a simple rule for drawing connectivity of a simple 2D S-
patch. We connect two control points fℓand fh if there exists an index 1 ≤j ≤n
such that
ℓi = hi,
i ̸= j, j + 1
|ℓj −hj| = 1
|ℓj+1 −hj+1| = 1
where the arithmetic on j is performed modulo n. Figure 8.4 shows an example
of this indexing for a quadratic pentagonal S-patch. While drawing this connec-
tivity makes sense for 2D domains, S-patches extend beyond 2D to polytopes in
higher dimensions. There, the cyclic ordering of the indices used in 2D to identify
connectivity does not generalize to higher dimensions. While we can generalize the
connectivity rules to higher dimensions, the information imparted by the connec-
tivity in higher dimensions becomes more diﬃcult to discern. This connectivity is
not essential to evaluation algorithms or other properties of S-patches in higher
dimensions, so we simply omit it.
Note that something curious happens to the S-patch control points for certain
polygons. Figure 8.5 shows an example of two quadratic, quadrilateral patches. One
example has 10 control points while the other appears to have 9 control points. The
issue is that two of the control points corresponding to the (1010) and (0101) in-
dex overlap according to (8.5) in the left example and not the right example. To
reproduce polynomial functions, these control points must have the same value,
which leads to a loss of degrees of freedom. However, in the more general case of

Multi-Sided Patches via Barycentric Coordinates
■141
)
2000
(
)
1100
(
)
0200
(
)
0101
(
)
1010
(
)
0110
(
)
0020
(
)
0011
(
)
0002
(
)
1001
(
)
2000
)
(
0200
(
)
0020
(
)
0002
(
)
1100
(
)
0110
(
)
0011
(
)
1001
(
)
1010
(
)
0101
(
Figure 8.5 An example of ambiguous indexing for S-patches. The left shows an
example where two control points overlap in the parametric domain. The right
shows the same indexing for a diﬀerent base polygon where the overlapping control
points separate.
modeling shapes with S-patches, these two control points may have diﬀerent values
despite being drawn in the same location. It is useful to note that, in the situation
on the left of the ﬁgure, if we require the overlapping control points to have the
same function value, which eﬀectively reduces the number of control points to 9,
the S-patch is identical to a tensor-product Bézier patch when using Wachspress co-
ordinates as the barycentric coordinate functions. Therefore, tensor product Bézier
patches as well as triangular Bézier patches (S-patches with a simplicial domain)
are all special cases of S-patches [257]. Indeed, the basis functions for Wachspress
coordinates are identical for the (1010) and (0101) control points in this example.
However, the basis functions for two overlapping control points do not have to be
identical and, in fact, rarely are in the general case.
8.2.2
Evaluation
Similar to Bézier curves, one possible method for evaluating an S-patch is sim-
ply to multiply the control points by the corresponding basis functions from (8.4)
evaluated at the point in question. However, there also exists a de Casteljau-like al-
gorithm that utilizes the hierarchical relationship between the control points. Given
an evaluation point x, we compute the value of the barycentric basis functions φi(x)
at the evaluation point using the polytope P. Now, we proceed in a recursive fash-
ion. Let fj be the control points at level k −1 where |j| = k −1 and let fℓwith
|ℓ| = m be the initial control points. Then, we compute the fj for all |j| = k −1
fj =
n
X
i=1
φi(x)fj+In
i

142
■Generalized Barycentric Coordinates in Graphics and Mechanics
)
(
0 x
φ
)
(
1 x
φ
)
(
2 x
φ
)
(
3 x
φ
)
(
4 x
φ
)
10000
(f
)
20000
(f
)
11000
(f
)
10100
(f
)
10010
(f
)
10001
(f
)
(
0 x
φ
)
(
1 x
φ
)
(
2 x
φ
)
(
3 x
φ
)
(
4 x
φ
)
00000
(f
)
10000
(f
)
01000
(f
)
00100
(f
)
00010
(f
)
00001
(f
Figure 8.6 The de Casteljau algorithm applied to a quadratic, pentagonal S-patch.
The left image depicts the calculation for one point of the ﬁrst level of the algorithm.
The right image shows the computation of the ﬁnal evaluation point.
where In
i is the ith row of the n × n identity matrix. The value of the S-patch is
then given by f0. Figure 8.6 depicts this hierarchical evaluation algorithm.
8.2.3
Degree elevation
Even though Loop and DeRose [257] mention degree elevation for S-patches, the
authors provide no explicit formula. However, degree elevation is not diﬃcult to
derive. Let fℓbe the values of the control points for an S-patch function of degree
|ℓ| = m and ˆfj be control points of the same S-patch function of degree |j| = m+1.
Then,
 X
|ℓ|=m
Bm
ℓ(x)fℓ
! n
X
i=1
φi(x)
!
=
X
|j|=m+1
Bm+1
j
(x) ˆfj.
(8.6)
Note that the basis functions of various degrees are related to each other via
Bm+1
j
(x) = Bm
j−In
i (x)m + 1
ji
φi(x)
(8.7)
for ji > 0. Expanding the left-hand side of (8.6) and using (8.7) yields the formula
for the m + 1 degree control points ˆfj,
ˆfj =
X
ji>0
ji
m + 1fj−In
i .

Multi-Sided Patches via Barycentric Coordinates
■143
Figure 8.7 An example of an S-patch with a convex domain. From left to right: the
base polygon P shaded gray, the control point structure for the quadratic S-patch,
and an example S-patch in 3D.
8.3
APPLICATIONS
While the original deﬁnition of S-patches [257] used convex, multi-sided polygon do-
mains, this restriction was more a function of the barycentric coordinates available
at that time [407] than any limitation of the construction. Many diﬀerent types
of barycentric coordinates have been developed since then (see Chapter 1). The
majority of these constructions are not limited to a particular dimension for the
domain and do not require convex domains. While any of these constructions can
be used to create S-patches, we utilize mean value coordinates [144, 150, 200, 217]
here in these examples.
8.3.1
Surface patches
Perhaps the most commonly used application of S-patches is to ﬁll multi-sided holes
in surfaces. Figure 8.7 shows an example of such a multi-sided patch using a convex
domain. Due to the interpolatory properties of barycentric coordinates, the curves
along the boundary of the domain are solely a function of the control points along
that boundary and form a Bézier curve. In this case, the six-sided patch is bounded
by six quadratic Bézier curves.
Given that the original deﬁnition of S-patches [257] used Wachspress coordi-
nates [407], the S-patch domain was required to be convex. Convexity is no longer
a requirement with many barycentric coordinate constructions, though the mis-
conception of this requirement for S-patches persists. Figure 8.8 (right) shows an
example of a quadratic S-patch with a concave domain. Figure 8.8 (middle) shows
a 2D image of the control point structure of this patch. Unlike convex domains, the
control points of S-patches with concave domains may lie outside of the original
polytope.
S-patches can be formed with domains that are even more general than these
convex or concave examples. In fact, S-patches can support domains of nearly ar-
bitrary shape that may even contain one or more holes. The restrictions on the
domain follow directly from the barycentric coordinates used to construct the S-

144
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 8.8 An example of an S-patch with a concave domain. From left to right: the
base polygon P shaded gray, the control point structure for the quadratic S-patch,
and an example S-patch in 3D. Note that, unlike the example in Figure 8.7, the
control points do not all lie within the domain P.
Figure 8.9 An example of an S-patch whose domain contains a hole. From left to
right: the base polygon P shaded gray, the control point structure for the quadratic
S-patch, and an example S-patch in 3D.
patch. For barycentric coordinate constructions like mean value coordinates, the
domain may even contain holes like the example in Figure 8.9.
8.3.2
Spatial deformation
S-patches can be used for applications other than ﬁlling multi-sided holes on surfaces
as well. Though rarely thought of in this way, S-patches can be used for image and
surface deformation as well. In fact, free-form deformations [353] (FFDs) as well
as cage-based deformations [215, 217] are all special cases of deformation using
S-patches.
To perform such spatial deformation, we use S-patches to construct a map
F : Rd →Rd where d = 2 for images and d = 3 for surfaces and volumes. F is
then given by
F (x) =
X
|ℓ|=m
Bm
ℓ(x)pℓ.
Hence, we control the deformation by manipulating the control points pℓ∈Rd.
The key to creating a map that is useful for deformation is to construct such a
function that can produce the identity transformation; that is, F (x) = x for some

Multi-Sided Patches via Barycentric Coordinates
■145
(
)
3
2
5
4 ,
2
2
)
1(
)
1(
v
u
−
−
2)
1(
)
1(
2
v
u
u
−
−
2
2
)
1(
v
u
−
2
2v
u
2
2)
1(
v
u
−
2
)
1(
2
uv
u
−
v
v
u
)
1(
)
1(
2
2
−
−
v
v
u
)
1(
2
2
−
v
v
u
u
)
1(
)
1(
4
−
−
p
(
)
3
2
5
4 ,
225
1
225
8
225
16
225
4
225
32
225
64
225
4
225
32
225
64
Figure 8.10 Image deformation using S-patches. The left image shows the image
and a point to evaluate the deformation at which each control point lists its basis
functions using a quadratic S-patch with Wachspress coordinates. The middle image
shows the weights associated with the evaluation point after evaluating the basis
functions. Moving the control points induces a deformation on the image shown on
the right. See color insert.
conﬁguration of control points. Luckily, (8.5) already provides the location of the
control points to reproduce this function. We refer to this conﬁguration of control
points as the bind pose.
Now, given a shape, for each point x in the shape, we compute x as a weighted
combination of the control points pℓwhere the weights are simply given by the
values of the basis functions Bm
ℓ(x). Notice that the weights Bm
ℓ(x) are constant
for each point x and can be precomputed, which yields a fast deformation function.
When pℓsatisfy (8.5), F(x) is the identity map. However, as the user manipulates
the control points away from the bind pose, the map produces a smooth deformation
of the underlying shape.
Deforming a shape such as an image is simple with this function. Given an im-
age such as the one shown in Figure 8.10, we surround the image with some base
polygon P. In this example, we use a rectangle and compute the deformation using
a quadratic S-patch. Then, we sample the deformation using a regular grid over the
image. For each grid point, we compute the weights of the deformation function.
As the user manipulates the control points, we simply apply the weights to the de-
formed control point positions to produce a deformed grid. Bilinearly interpolating
the deformation within each grid cell generates the ﬁnal deformation. Notice that
the grid in this case may be as ﬁne as the pixels in the input image, although such
ﬁne resolution is not typically necessary to create a smooth-looking deformation.
Figure 8.10 shows the result of such a deformation. In this case, the deformation is
equivalent to using a tensor-product Bézier patch when using Wachspress coordi-
nates, which is called a free-form deformation [353] (a special case of an S-patch).
Surface deformation follows a similar route. In this case, we are typically given
a triangulated surface that we wish to deform with vertices xj. Figure 8.11 (left)

146
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 8.11 An example of surface deformation using linear S-patches. The initial
surface of a horse is surrounded by a low resolution approximation called a cage
(left). The right two images show diﬀerent deformations where the head and torso
are kept the same size but the neck and legs are compressed or stretched. See color
insert.
shows an example of a 3D model of a horse containing 48, 485 such vertices. First,
we construct a polytope to surround the horse typically with fewer vertices vℓthan
the actual horse. In this example, the cage, shown on the left of the ﬁgure, contains
only 51 control points. Next, we compute each xj as a weighted combination of the
vℓ. As the user manipulates the control points, we apply the constant weights for
each vertex to the deformed control point locations to create the location of the
deformed vertex of the surface as shown on the middle and right of Figure 8.11.
Unlike the original deﬁnition of free-form deformations that relies on tensor-
product Bézier functions of various degrees with cube domains, cage-based defor-
mations can conform to the shape of the object. And while cage-based deformations
are not typically thought of this way, these deformations are obviously S-patch
deformations of degree 1. This insight means that we can construct volumetric
cage-based deformations of higher degree as well. Unfortunately, the number of
control points for these deformations grows quite rapidly. For example, the cage in
Figure 8.11 has 51 control points as a linear S-patch. A quadratic S-patch would
contain 1, 326 control points. Moreover, the majority of those control points exist
in the interior of the cage, which would make it diﬃcult for a user to manipulate
those points. Hence, higher degree cage-based deformations are not practical from
a user-interface perspective. One alternative would be to use selective degree eleva-
tion [364] to avoid inserting more control points than desired as the degree of the
patch is elevated. However, such a method is beyond the scope of this chapter, and
we refer the interested reader to the corresponding reference.

C H A P T E R 9
Generalized
Triangulations
Pooran Memari
LIX, CNRS, École Polytechnique, Université Paris Saclay, Palaiseau, France
CONTENTS
9.1
Introduction ......................................................
147
9.2
Generalized primal-dual triangulations ..........................
148
9.2.1
Some classical examples ..................................
149
9.2.2
Primal-dual triangulations (PDT) .......................
150
9.3
A characterization theorem ......................................
151
9.3.1
Combinatorially regular triangulations (CRT) ..........
151
9.3.2
Equivalence between PDT and CRT ....................
152
9.3.3
Parametrization of primal-dual triangulations ...........
152
9.4
Discrete representation using generalized triangulations ........
153
9.4.1
Discrete exterior calculus framework ....................
153
9.4.2
Applications in mesh optimization .......................
154
T
he main concept of barycentric coordinates is intimately linked to the du-
ality between primal and dual complexes. This chapter presents a general
framework in Rd to deﬁne a family of compatible dual complexes for a given tri-
angulation. We derive a combinatorial characterization theorem for triangulations
that admit a compatible, possibly non-orthogonal dual complex. We show how the
mesh optimization methods in geometric modeling can beneﬁt from the parameter-
ization of the space of generalized triangulations.
9.1
INTRODUCTION
A triangle mesh is a partition of a bounded domain with simplices (triangles in
2D, tetrahedra in 3D) so that any two of these simplices are either disjoint or
sharing a face. The resulting triangulation (also called tetrahedralizations in 3D)
provides a discretization of space through both its primal (simplicial) elements and
147

148
■Generalized Barycentric Coordinates in Graphics and Mechanics
its dual (cell) elements. Both types of element are crucial to a variety of numerical
techniques. A growing trend in numerical simulation is the simultaneous use of
primal and dual meshes: Petrov–Galerkin ﬁnite element/ﬁnite volume methods [24,
271, 298] and methods based on exterior calculus [65, 119, 176] use the ability
to store quantities on both primal and dual elements to enforce (co)homological
relationships, which for instance appear in Hodge theory. The choice of the dual,
deﬁned by the location of the dual vertices, is however not speciﬁed a priori. The
barycentric dual, for which barycenters are used instead of circumcenters, is used
for certain ﬁnite volume computations, but it fails to satisfy both the orthogonality
and the convexity conditions on general triangulations. A very common dual to a
triangulation in Rd is the cell complex that uses the circumcenters of each d-simplex
as dual vertices. It corresponds to the Voronoi diagram in the case of Delaunay
triangulations [137, 313]. The circumcentric Delaunay–Voronoi duality has been
extensively used in diverse ﬁelds. Building on a number of results in algebraic
and computational geometry, a more general primal-dual pair of complexes can be
deﬁned [274], as we brieﬂy describe in the ﬁrst sections of this chapter. A barycentric
representation of primal-dual triangulations is then presented as a parameterization
of this space of generalized triangulations.
Classical methods, such as centroidal Voronoi tessellations [127], lead to “good”
simply connected domain dual elements, while optimal Delaunay triangulations [9]
optimize the shape of primal elements. Nowadays, recent numerical methods on
meshes can beneﬁt from optimizations over both primal and dual complexes. At the
end of this chapter, we present a unifying approach to mesh quality [289], which
is based on the placement of primal and orthogonal dual elements with respect to
each other, for instance, to make orthogonal barycentric duals.
9.2
GENERALIZED PRIMAL-DUAL TRIANGULATIONS
We start by recalling important notions on this topic. More detailed deﬁnitions can
be found in [289] and [274].
Complex and triangulation
A cell complex in Rd is a set K of convex polyhedra (called cells) satisfying two
conditions:
1. Every face of a cell in K is also a cell in K.
2. If C and C′ are cells in K, their intersection is either empty or a common
face of both.
A simplicial complex is a cell complex whose cells are all simplices.
For a set X of points {xi}i=1,...,|X| in Rd, a triangulation of X is a simplicial
complex K for which each vertex of K is in X, and the union of all the cells of K is
the convex hull of X. Note that the triangulations we consider usually come from a
point set and hence partition a simply connected domain in Rd (corresponding to
the convex hull of the point set).

Generalized Triangulations
■149
Also, in the deﬁnition of a triangulation of X, we do not require all the points
of X to be used as vertices; a point xi ∈X is called hidden if it is not used in the
triangulation.
Dual cell complexes
Two cell complexes K and K′ in Rd are said to be dual to one another if there
exists a duality map ∗from K to K′ that associates any cell σ in K of dimension
i (0 ≤i ≤d) to a cell ∗σ in K′ of dimension d −i for all 0 ≤i, j ≤d, σi ⊂σj ↔
∗σi ⊃∗σj.
9.2.1
Some classical examples
Power diagrams and weighted Delaunay triangulations
For a given point p ∈Rd and a scalar ω ∈R, the power distance from any point
x ∈Rd to the so-called weighted point (p, ω) is deﬁned by an additive modiﬁcation
of the Euclidean metric as ∥x −p∥2 −ω (also called the Laguerre distance).
In terms of the power distance, the bisector separating any pair of weighted
points (p, ωp) and (q, ωq) is a hyper-plane with points x satisfying ∥x −p∥2 −ωp =
∥x −q∥2 −ωq. Therefore, the diﬀerence of weights acts as a shift of the bisector
towards the smaller weight. This leads to the deﬁnition of a generalized Voronoi
diagram called power diagram. Let (X, ω) = {(xi, ωi)}i∈I be a weighted point set
in Rd. To each xi we associate its weighted Voronoi region
V (xi, ωi) = {x ∈Rd : ∥x −xi∥2 −ωi ≤∥x −xj∥2 −ωj∀j}.
Note that drastic diﬀerences between weights may induce empty power cells
and thereby isolate sites with no neighbors. We denote sites associated with zero
volume cells as hidden sites [20]. Also, when the weights are all equal, the power
diagram coincides with the Euclidean Voronoi diagram of X. While many other gen-
eralizations of Voronoi diagrams exist, they do not form straight-edge and convex
polytopes and are thus not relevant here.
The dual of the power diagram of (X, ω) is the weighted Delaunay triangulation
of (X, ω). This triangulation contains a k-simplex with vertices xi0, xi1, . . . , xik in
X, if and only if V (xi0, ωi0) ∩V (xi1, ωi1) ∩· · · ∩V (xik, ωik) ̸= ∅, ∀k ≥0.
Regular triangulations
Note that for a simply connected domain (that is, the convex hull of X ⊂Rd), the
weighted Delaunay triangulation coincides with the so-called regular triangulation
that is deﬁned as the projection of the lower hull of the lifted point set F(X), for
some lifting F of X to Rd+1. As it is shown in [113], this equivalence is no longer
true for domains with non-trivial topology.

150
■Generalized Barycentric Coordinates in Graphics and Mechanics
Weighted circumenters
For any simplex σ of the weighted Delaunay triangulation, let c(σ) denote the
weighted circumcenter of σ, that is, the unique intersection of (the mutually or-
thogonal aﬃne spaces supporting) the primal simplex σk and its weighted dual
∗σk. The positions of weighted circumcenters can be computed explicitly from the
positions of vertices and the weights of the corresponding simplex [289, Equation 7].
Of particular importance are the weighted circumcenters of the d-simplices for
a mesh T in Rd: these form the vertices of its dual complex D. Any point in the
aﬃne space supporting a d-simplex σ can be the weighted circumcenter of σ for a
choice of weights on the corresponding vertices. As we will see, this can be seen as
a parameterization of the space of dual complexes.
Computation
Algorithms to construct power diagrams make use of the same strategies as in the
case of Voronoi diagrams, where the Euclidean distances are replaced by power
distances. Therefore, the worst time complexity to generate a power diagram with
n weighted points is O(n log n) in R2 and O(n
d
2 ) in Rd. Eﬃcient implementations
of these algorithms, such as in the CGAL library [86], have reported that the
complexity bound is typically reached in cases with coplanar sites, while the general
case performs close to linear in the number of sites.
9.2.2
Primal-dual triangulations (PDT)
Compatible dual complexes of triangulations
We now show that the notion of mesh duality can be extended, so that the dual com-
plex is deﬁned geometrically and independently from the triangulation—while the
combinatorial compatibility between the triangulation and its dual is maintained.
Deﬁnition 9.1 (Simple cell complex). A cell complex K in Rd is called simple if
every vertex of K is incident to d+1 edges. K is called labeled if every d-dimensional
cell of K is assigned a unique label; in this case, we write K = {C1, . . . , Cn}, where
n is the number of d-dimensional cells of K, and Ci is the i-th d-dimensional cell.
Deﬁnition 9.2 (Compatible dual complex). Let T be a triangulation of a set
X = {x1, . . . , xn} of points in Rd and let K = {Ci1, . . . , Cin} be a labeled simple
cell complex, that is, there is a one-to-one correspondence between xp and Cip. We
then call K a compatible dual complex of T if, for every pair of points xp and xq
that are connected in T, the cells Cip and Ciq share a face.
This compatibility between K and T is purely combinatorial, that is, it simply
states that the connectivity between points induced by K coincides with the one
induced by T. Notice that the cell Cip associated to the point xp does not necessarily
contain xp in its interior. Moreover, the edge [xp, xq] and its dual Cip ∩Ciq are
not necessarily orthogonal to each other, unlike most conventional geometric dual
structures. Consequently, we can generalize the notion of mesh duality.

Generalized Triangulations
■151
Figure 9.1 A regular triangulation (left), once deformed (right), becomes a combi-
natorially regular triangulation that is not regular itself. (Image taken from [237].)
Deﬁnition 9.3 (Primal-dual triangulation (PDT)). A pair (T, K) is said to form
a d-dimensional primal-dual triangulation if T is a triangulation in Rd and K is
a compatible dual complex of T. If every edge [xp, xq] and its dual Cip ∩Ciq are
orthogonal to each other, then the pair (T, K) is said to form an orthogonal primal-
dual triangulation.
9.3
A CHARACTERIZATION THEOREM
Let us consider a set of points X in Rd. For any set of weights ω, the power diagram
of (X, ω) and the corresponding dual regular triangulation form a PDT of the
convex hull of X. In other words, any regular triangulation admits a compatible dual
complex and can be part of a PDT. Moreover, in [274] we showed that for simply
connected domains, any triangulation that admits a compatible dual complex is
indeed regular up to a perturbation. For a more formal statement we need the
following deﬁnitions.
9.3.1
Combinatorially regular triangulations (CRT)
Deﬁnition 9.4 (Combinatorial equivalence). Two triangulations T and T ′ are
combinatorially equivalent if there exists a labeling that associates to each point
xi in T a point x′
i in T ′ so that the connectivity between the xi’s induced by T
matches the connectivity between the x′
i’s induced by T ′.
Deﬁnition 9.5 (Combinatorially regular triangulations (CRT)). A triangulation
T of a d-dimensional point set X is called a combinatorially regular triangulation
if there exists a d-dimensional point set X′ admitting a regular triangulation T ′,
such that T and T ′ are combinatorially equivalent.
These CRT triangulations have been introduced in [237] under the name of
weakly regular triangulations, since a displacement of their vertices suﬃces to make
them regular. Figure 9.1 shows an example of a combinatorially regular triangula-
tion that is not regular itself.

152
■Generalized Barycentric Coordinates in Graphics and Mechanics
Existence of PDTs in 2D.
The 2D case is rather simple, due to the following result, which is mainly based on
a classical theorem of Steinitz [368] and also mentioned in [237, 274].
Proposition 9.6. Any 2-dimensional triangulation is combinatorially regular.
Therefore, every 2D triangulation T can be part of a PDT pair (T, K). However,
in higher dimensions (d ≥3), the situation is rather diﬀerent [274].
Proposition 9.7. For d ≥3, there exist d-dimensional triangulations that do not
admit any compatible dual complex.
This is equivalent to the fact that there exist triangulations that are not com-
binatorially regular. The simplest non-combinatorially regular examples are the
Brucker sphere and the Barnette sphere [141].
9.3.2
Equivalence between PDT and CRT
As shown in [274], combinatorially regular triangulations are the only triangulations
that admit compatible dual complexes. The proof revolves around a theorem due to
Aurenhammer:
Every simple cell complex in Rd, d ≥3, is dual to a regular triangulation.
This theorem was proved in [18] through an iterative construction, which is valid in
any dimension d ≥3. In [274], we used this theorem to prove the following theorem,
which surprisingly implies that in higher dimensions there are triangulations that
do not admit a dual complex.
Theorem 9.8 (PDT characterization). A d-dimensional triangulation T admits a
compatible (not necessarily orthogonal) dual complex if and only if T is combinato-
rially regular.
9.3.3
Parametrization of primal-dual triangulations
We established that for simply connected domains, the space of primal-dual trian-
gulations covers all dual complexes in d ≥3. It also covers all 2D triangulations,
but only combinatorially regular triangulations in d ≥3. The proof of Theorem 9.8
leads naturally to a parameterization of all triangulations that admit a compatible
dual complex [274].
Deﬁnition 9.9. A parameterized primal-dual triangulation is a primal-dual tri-
angulation parameterized by a set of triplets (xi, ωi, vi), where xi is the position
in Rd of the i-th node, ωi is a real number called the weight of xi, and vi is a
d-dimensional vector called the displacement vector of xi. The triangulation asso-
ciated with the triplets (xi, ωi, vi) is deﬁned such that its dual complex K is the
power diagram of weighted points (pi, ωi), where pi = xi + vi.

Generalized Triangulations
■153
The dual complex K can be seen as the generalized Voronoi diagram of the
xi’s for the distance d(x, xi) = ∥x −xi −vi∥2 −ωi. If the vectors vi are all zero,
then the parameterized primal-dual triangulation T is regular, thus perpendicular
to its dual K, and the pair (T, K) forms an orthogonal primal-dual triangulation.
This proves that weighted Delaunay triangulations are suﬃcient to parameterize
the set of all orthogonal primal-dual triangulations of a simply connected domain
(see also [166]). The displacement vectors extend the type of triangulations and
duals we can parameterize.
Characterizing the classes of equivalent triplets parameterizing the same PDT
and completed with constraints for the parameters in order to avoid redundancy
between equivalent triplets, the following theorem was proved in [274].
Theorem 9.10 (PDT parameterization). There is a bijection between all primal-
dual triangulations in Rd and sets of triplets (xi, ωi, vi), 1 ≤i ≤n, where
xi, vi ∈Rd, ωi ∈R with P
i ωi = 0, P
i vi = 0, and P
i ∥xi + vi∥2 = P
i ∥xi∥2.
Using this parameterization, the particular case of Delaunay and Voronoi PDT
of a set of points {xi}i=1,...,n is naturally parameterized by the triplets (xi, 0, 0).
We now employ this parameterization to derive a novel discretization of cal-
culus that veriﬁes structural geometric properties, such as the linear accuracy for
the gradient and Laplacian operators that are useful in geometry processing and
graphics applications (see also [115]).
9.4
DISCRETE REPRESENTATION USING GENERALIZED
TRIANGULATIONS
9.4.1
Discrete exterior calculus framework
The theory of discrete exterior calculus (see Section 5.2.1) provides one possible
discretization of diﬀerential geometry, which has proven to be highly successful in
improving and analyzing ﬁnite element methods.
The geometric principles on which these methods of computations are built
are very intuitive. In this framework, discrete diﬀerential forms are considered as
continuous forms integrated over each discrete element (simplices and cells). Once
discrete forms and vector ﬁelds are deﬁned, a calculus can be developed by deﬁning
discrete operators.
For example, the classical operations of gradient, divergence, and curl, as well
as the theorems of Green, Gauss, and Stokes can all be expressed concisely in terms
of two diﬀerential forms: the discrete exterior derivative (d) and the Hodge star (⋆).
More details on the discrete exterior calculus framework can be found in a variety
of sources [118, 192], as well as in a recent Siggraph course [109].
Here, we are particularly interested in the discrete Hodge star ⋆, which takes
geometry into account by encoding how integrated measures over primal elements
are transferred to their associated dual elements. More concretely, the discrete
diagonal Hodge star for discrete p-forms is deﬁned as a diagonal matrix with entries

154
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 9.2 Notations for the cotangent formula.
per primal element σ of dimension p given as ⋆σ = |∗σ|/|σ|, where |σ| indicates the
signed measure of σ.
In the classical case of two-dimensional meshes and their circumcentric duals,
this quantity is the ratio between the dual and the primal edge length. As ex-
plained in Section 5.3.6, this quantity coincides with the well-known cotangent
formula [262]:
 cot(αikj) + cot(αjli)

/2 (see Figure 9.2).
In the general case of two-dimensional orthogonal primal-dual meshes, we make
use of the closed-form expressions for primal and dual volumes to deﬁne a weighted
version of the discrete Hodge star operator, leading to
1
2
 
cot αikj + cot αjli + (ωi −ωk)
cot αkji
∥xi −xj∥2 + (ωj −ωk)
cot αjik
∥xi −xj∥2
+ (ωi −ωl)
cot αijl
∥xi −xj∥2 + (ωj −ωl)
cot αlij
∥xi −xj∥2
!
.
Observe that the dual structure for constant weights corresponds to the circum-
centric dual, and therefore the Hodge star for one-forms reduces to the cotangent
formula in this case of constant weights.
This way, most of the discrete exterior calculus methods in graphics (including
the literature on Laplacian, Laplace–Beltrami, and discrete conformal parameteri-
zations) can be directly adapted by including the contribution due to the weights.
9.4.2
Applications in mesh optimization
In the last sections we derived a natural parameterization of all primal-dual struc-
tures of simply connected domains in Rd. This parameterization can in particular
improve mesh optimization algorithms as it provides a convenient way to explore
a large space of primal-dual structures. We already provided a ﬁrst step in this di-
rection by designing pairs of primal-dual structures that optimize accuracy bounds
on diﬀerential operators using our parameterization [289], thus extending varia-
tional approaches designed to improve either primal (optimal Delaunay triangu-
lations [397]) or dual (centroidal Voronoi tessellations) structures. In that work,

Generalized Triangulations
■155
Hodge-optimized triangulations (HOT) were introduced, as a family of well-shaped
primal-dual pairs of complexes designed for fast and accurate computations in com-
puter graphics. Other existing work most commonly employs barycentric or circum-
centric duals. While barycentric duals guarantee that the dual of each simplex lies
within the simplex, circumcentric duals are often preferred due to the induced
orthogonality between primal and dual complexes. This new approach instead pro-
motes the use of weighted duals (power diagrams) and allows for much greater
ﬂexibility in the location of dual vertices while keeping primal-dual orthogonality.
This provides an invaluable extension to the usual choices of duals by only adding
one additional scalar per primal vertex. Furthermore, in that work, we introduce
a family of functionals on pairs of complexes that we derive from bounds on the
errors induced by diagonal Hodge stars, commonly used in discrete computations.
The minimizers of these functionals, called HOT meshes, are shown to be gener-
alizations of centroidal Voronoi tessellations and optimal Delaunay triangulations,
and to provide increased accuracy and ﬂexibility for a variety of computational
purposes [289].
Following this framework, minor changes can be accommodated seamlessly in
existing mesh optimization codes in order to allow for much greater ﬂexibility.
Weights can be, for instance, optimized (with ﬁxed connectivity or not) to locally
“displace” dual vertices onto an immersed boundary [26] through a least-squares
ﬁt. Vertices can be optimized as well, for instance, in applications requiring local
or global remeshing to maintain good numerical analysis.
To some extent, this approach can even help to deal with situations where the
primal triangulation is given and cannot safely be altered. For instance, moving
vertices and/or changing the connectivity of a triangle mesh in R3 is potentially
harmful, as it aﬀects the surface shape. Still, the ability to optimize weights to
drive the selection of the dual mesh is very useful. We can easily optimize primal-
dual triangulations (meshes) by minimizing a functional (energy) with respect to
the weights. The connectivity is kept intact, regardless of the weights—only the
position and shape of the compatible dual is optimized.
As is shown in [289], even an optimized Delaunay triangulation with excep-
tionally high-quality tetrahedra can be made signiﬁcantly better centered (with
dual vertices closer to the inside of their associated primal simplex), using a simple
weight optimization by this method (see Figure 9.3).

156
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 9.3 In a high-quality optimized Delaunay mesh of Bimba con Nastrino, we
show the set of tetrahedra for which the distance between weighted circumcenter
and barycenter is greater than a threshold, before (left) and after (right) the HOT
optimization [289]. The primal triangulations are the same, and this signiﬁcant
optimization is done only on the dual, using the weights. See color insert.

C H A P T E R 10
Self-Supporting Surfaces
Etienne Vouga
University of Texas, Austin, USA
CONTENTS
10.1
Introduction and historical overview ............................
158
10.1.1 What is a masonry structure? ...........................
158
10.1.2 Heyman’s safe theorem ..................................
159
10.1.3 Gaudí and hanging nets .................................
160
10.1.4 Maxwell’s reciprocal diagrams ...........................
161
10.2
Smooth theory ...................................................
162
10.2.1 Equilibrium equations ...................................
163
10.2.2 Airy stress potential .....................................
164
10.2.3 Relative curvatures .......................................
164
10.2.4 Curvature interpretation of equilibrium .................
165
10.3
Discrete theory ...................................................
166
10.3.1 Thrust network analysis .................................
166
10.3.2 Thrust networks as block networks ......................
167
10.3.3 Discrete Airy stress potential ............................
167
10.3.4 FEM discretization of Airy stress ........................
169
10.3.5 Discrete curvature interpretation of equilibrium .........
169
10.4
Optimizing for stability ..........................................
170
10.4.1 Alternating optimization .................................
170
10.4.2 Dual formulation as vertex weights ......................
172
10.4.3 Perfect Laplacian optimization ..........................
172
10.4.4 Relative-curvature-based smoothing .....................
173
10.4.5 Steel-glass structures and PQ faces ......................
174
10.4.6 Block layouts from stable surfaces .......................
175
10.5
Conclusion and open problems ..................................
175
10.5.1 Sensitivity analysis of masonry structures ...............
176
10.5.2 Progressive stable structures .............................
176
157

158
■Generalized Barycentric Coordinates in Graphics and Mechanics
T
he study of masonry structures has fascinated architects, geometers, and
engineers since antiquity. Artifacts like the Pantheon in Rome and Gothic
cathedrals, which have stood for centuries without the beneﬁt of modern mechan-
ical engineering and materials science research, stand testament to the power and
elegance of masonry construction techniques. This chapter sketches how the me-
chanics of masonry structures, and smooth and discrete geometry, are inseparably
entwined, beginning with a historical overview of how stable structures were de-
signed, covering some fundamental theory, and then surveying recent works in com-
puter graphics on computational design and analysis of masonry structures. Weight
functions deﬁning generalized barycentric coordinates appear as a key component
of this analysis, where they represent the force ﬂowing through the structure.
10.1
INTRODUCTION AND HISTORICAL OVERVIEW
To study whether an arch or dome stands or falls is to study geometry. This is the
key insight underlying equilibrium analysis or limit analysis, whose principles have
been exploited for centuries by architects seeking to understand the mechanics of
masonry structures.
10.1.1
What is a masonry structure?
Masonry structures are man-made structures composed of unreinforced concrete,
brick, or stone, such as cathedrals, domes, and vaults. In particular, we consider
freeform masonry structures, which though assembled of volumetric blocks, have
a thin dimension (so that they resemble a surface). Figure 10.1 (left) shows an
example of freeform masonry.
Figure 10.1 Left: A freeform masonry structure, composed of rigid, unreinforced
blocks. (Image courtesy of Mathias Höbinger, used by permission.) Middle: The
thrust network that certiﬁes that this masonry structure is stable under its own
weight. Each edge radius is proportional to the magnitude of compressive force
carried by the edge. Right: An arch in 2D, with the self-load, and the thrust line
certifying its stability, both illustrated. See color insert.

Self-Supporting Surfaces
■159
Following Heyman [189], we make the following assumptions about the masonry
structures we consider:
1. The material has eﬀectively inﬁnite compressive strength (reasonable since the
yield stress of stone far exceeds the working stress in practical structures).
2. In contrast, the structure has no tensile strength: mortar may be present at
block interfaces, but this mortar is weak and cracks readily due to settling
and weathering, so that it cannot be assumed to have any structural strength.
3. Failure of the structure by sliding is impossible (prevented either by the ori-
entation of the block interfaces, or the presence of suﬃcient friction). Failure
can occur only due to hinging apart of the structure.
The assumptions about compressive and tensile strength are critical ingredients
in the geometric analysis of masonry, since they remove concerns about material
failure: when a network of blocks crumbles, it is not due to buckling or crumpling
of the blocks, but rather, due to geometric failure of the arrangements of the blocks
alone. We thus need make no further assumptions about the composition, density,
size, or other physical characteristics of the blocks.
10.1.2
Heyman’s safe theorem
Heyman, building on the ideas of Kooharian [226], applied limit theorems from the
theory of plasticity to formulate the safe theorem of 2D masonry structures∗for
masonry structures:
If a line of thrust can be found which is in equilibrium with the
external loads and lies wholly within the masonry, then the structure is
safe.
A thrust line is a geometric representation of the forces ﬂowing through the masonry
structure. More speciﬁcally, consider a network of rigid blocks (see Figure 10.1,
right). To each block i we associate an external load Fi ∈R2; typically this load is
the block’s self-weight and so is parallel to the direction of gravity. We also classify
blocks as anchored boundary blocks if they are planted into the ground, and thus
can support arbitrary loads from arbitrary directions, and free boundary blocks or
interior blocks if they must be supported.
A thrust line is a graph G dual to the block network (so that to each block i
corresponds a vertex vi of G), and an associated set of weights wij > 0 on the edges
of G (with wij = wji), so that the weighted sum of all edge vectors coming in to
an interior or free boundary vertex vi exactly balances the external load:
Fi =
X
j∼i
wij(vi −vj),
(10.1)
where the sum is over all vertices j incident to i.
∗Note that this “theorem” only holds for structures obeying the material assumptions of Sec-
tion 10.1.1: the restriction on sliding is particularly subtle, as discussed by Bagi [23].

160
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 10.2 Hanging nets and weights used by Gaudí to design the form of the
Sagrada Família church in Barcelona. (Image courtesy of Flickr user ralmonline
alm and reproduced under the CC-BY-2.0 license; colors have been converted to
grayscale and white-balanced.)
Intuitively, the thrust line can be interpreted as a network of inﬁnitesimal beams
connected by pin joints at the vertices of G, with the weighted length of the edges
wij∥vj −vi∥the magnitude of the compression force within each beam. The safe
theorem guarantees that if such a beam network exists that is in equilibrium under
the external loads acting on a masonry structure, and the beam network is con-
tained entirely within the volume of the structure, then the structure itself is stable.
This ability of the safe theorem to reduce the problem of determining stability by
one dimension has made thrust line analysis tremendously valuable as a practical
technique for analyzing masonry arches, vaults, and domes [190, 203].
10.1.3
Gaudí and hanging nets
Although analyses of domes and vaults have been performed by considering thrust
lines in 2D cross-sections, the safe theorem also applies to three-dimensional block
structures, with (10.1) unchanged, with vertices of G (now a thrust network) and
load vectors elements of R3.
The thrust network can again be viewed as a network of beams connected by
pin joints, and under equilibrium when subject to the external load. This analogy
has been exploited by architects and engineers like Frei Otto, Heinz Isler, and
Antoni Gaudí, who used hanging chain and membrane models to ﬁnd architectural
forms [228]. Gaudí’s masterpiece, the Sagrada Família, for instance, was designed
using hanging nets and weights (see Figure 10.2). Notice that the thrust network
equilibrium equations (10.1), when negated, describe the equilibrium of networks of
string under tension; the shape of the hanging net, when turned upside down, thus
yields a masonry structure that is stable by the safe theorem. This observation dates
back at least as far as Hooke (who published in his famous anagram the observation
that “as it hangs in a continuous ﬂexible form, so it will stand contiguously rigid
when inverted,” and who used hanging nets and weights to design the dome of St
Paul’s Cathedral [210]).

Self-Supporting Surfaces
■161
Figure 10.3 Left: A thrust network, inspired by the shape of the top of the Lilium
tower, and its top view. Middle: The top view admits a reciprocal diagram, certify-
ing horizontal equilibrium. Right: The discrete Airy stress surface S corresponding
to this reciprocal diagram.
While existence of a thrust network within a masonry structure is suﬃcient to
guarantee the structure’s stability, the thrust line does not necessarily encode the
true forces ﬂowing through the structure: many possible thrust networks can exist
within a masonry volume, and any one of these certiﬁes the structure’s stability.
Consider for instance a four-legged stool: the stool stands with any one of its legs
removed, and the true force ﬂowing through the four legs cannot be determined by
examining the geometry of the stool alone. In practice such static indeterminacy is
commonplace.
10.1.4
Maxwell’s reciprocal diagrams
Given a graph G and vertex loads Fi, when do there exist edge weights that place
the thrust network in equilibrium? To address this question, we begin by making
the additional assumption about the structure that the external loads are purely
vertical, that is, parallel to the ˆz axis (this is reasonable, since the self-weight of the
structure usually dominates most other external loads such as those due to wind,
etc.). We can thus write Fi = Fi ˆz for scalar loads Fi. It will also be useful to project
the vertices vi of G into the xy-plane, to yield a top view ¯G with vertices ¯vi, to
which we associate heights zi (see Figure 10.3). The equilibrium equations (10.1)
then split into the pair
0 =
X
j∼i
wij(¯vj −¯vi)
(10.2)
−Fi =
X
j∼i
wij(zj −zi)
(10.3)
of horizontal and vertical equilibrium equations for each interior or free boundary
vertex i. Notice that only the vertical equations involve the loads or heights of the
vertices of G; existence of weights that satisfy the horizontal equations is purely

162
■Generalized Barycentric Coordinates in Graphics and Mechanics
a property of the geometry of the top view. Notice that (10.2) are precisely those
deﬁning homogeneous weights of generalized barycentric coordinates (1.11) satisfy-
ing linear precision [149] for ¯vi with respect to the polygon P that is composed of
¯vi’s one-ring. The extra symmetry condition wij = wji on weights in overlapping
one-rings reﬂects the fact that forces exerted by both ends of a beam must be equal
and opposite (Newton’s third law). Vertical equilibrium then requires that barycen-
tric interpolation of the one-ring’s vertical heights diﬀer from zi by an amount Fi/W
depending on the load at vertex i.
A polygonal complex ¯G∗in the plane is called a reciprocal (dual) diagram of the
top view ¯G if it is a dual complex of ¯G, and every edge of ¯G∗is orthogonal to its
dual edge on ¯G (see Figure 10.3).† Reciprocal diagrams and their relationship to
static equilibrium have been studied extensively, starting with James Maxwell [270],
who observed the following fact.
Theorem 10.1. Given a top view ¯G, edge weights wij exist satisfying horizontal
equilibrium (10.2) if ¯G possesses a reciprocal diagram, and only if every simply
connected subcomplex of ¯G possesses a reciprocal diagram.
Indeed, observe that if weights exist satisfying (10.2), the edges surrounding a
vertex ¯vi can be scaled by wij and rotated by ninety degrees to form a dual face
(sometimes called the force polygon) on the reciprocal diagram, and similarly, given
a dual face, edge weights can be computed by taking edge length ratios.
For simplicity of exposition, in what follows we assume that a global reciprocal
diagram can always be constructed from edge weights; the fact that the recipro-
cal diagram can only be pieced together locally when ¯G has higher genus is not
important in practice.
Finally, notice that the compression-only constraint wij ≥0 has a natural ge-
ometric analogue on the reciprocal diagram: none of the dual edges in ¯G∗may be
inverted.
10.2
SMOOTH THEORY
Before we continue analyzing the stability of thrust networks, we take a detour
to study the properties of the continuum limit of a surface-like masonry structure
made of inﬁnitesimally small blocks, so that the geometry of the masonry structure
can be represented as a smooth surface M embedded in R3. In this setting, external
load magnitude (we again assume loads are only vertical) is represented by a scalar
density function F : M →R on the surface, and static equilibrium of M under these
loads can be characterized using the classical theory of elasticity [178]. To simplify
the analysis we will assume that M has no overhangs, that is, it is a graph over the
plane, though such overhangs do occur in some practical masonry structures (such
as the oculus in the dome of the Pantheon).
†Some authors deﬁne the reciprocal dual so that the dual edges are parallel to the primal edges;
this notion of reciprocality diﬀers from ¯G∗only by an unimportant ninety-degree rotation.

Self-Supporting Surfaces
■163
F ˆz
Ω
drσg−1 ˆn
Figure 10.4 Balance of forces on a small patch.
10.2.1
Equilibrium equations
Consider a point x on M, and Ωa small neighborhood of x. As above, we project
Ωonto the xy-plane to yield a top view ¯Ω⊂R2, and parameterize Ωby a height
function z : ¯Ω→R. The embedding of the patch Ωis then given by r(x, y) =
(x, y, z(x, y)) and the induced metric on ¯Ωis g = I + dz ⊗dz.
Internal forces acting through the boundary of Ωare characterized by the stress
tensor σ: ¯Ω→GL(2, R); for a tangent vector v at a point on the top view, σv
measures the internal force that would result from making a small cut in Ωin the
tangent direction perpendicular to drv. Balance of forces on Ωmeans that the
internal forces integrated along ∂Ωmust exactly cancel the total external load on
Ω(see Figure 10.4),
ˆ
¯Ω
F ˆz d ¯A =
ˆ
∂¯Ω
drσg−1 ˆn ds,
where d ¯A = √det g dx dy is the area element on Ω, ˆn is the outward-pointing unit
normal (with respect to the metric g) on the boundary ∂¯Ω, and ds is the diﬀerential
on ∂Ω. Applying Stokes’s theorem and contracting Ωto a point yields the pointwise
equilibrium condition
F ˆz
p
det g = ∇·
 p
det g

g−1σ∇r

,
where the divergence operator ∇· is understood to act on matrices by producing a
vector whose entries are the divergences of the columns of the matrix. Equilibrium
conditions also exist on the free boundaries: the traction on these boundaries must
be zero, that is, σg−1 ˆn = 0, where ˆn is the boundary normal on ∂¯
M.
Since the stress tensor is self-adjoint with respect to g, S =
 √det g

g−1σ is
a symmetric matrix; the fact that M supports only compressive, and not tensile,
internal forces becomes the constraint that S is positive semideﬁnite. Therefore M
is in static equilibrium if there exists a section of matrices S ⪰0 over ¯Ωwith
F ˆz
p
det g = ∇· [S∇r]
(10.4)
at every point on the interior of ¯Ω.

164
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 10.5 A function z(x, y) and its polar dual. Tangent planes map to points.
10.2.2
Airy stress potential
We can again decompose the equilibrium equation (10.4) into horizontal and vertical
components,
0 = ∇· S
F
p
det g = ∇· [S∇z].
The ﬁrst set of equations, together with symmetry of S, are precisely the local
integrability conditions required for existence of a scalar function, the Airy stress
potential s, with
S =

syy
−sxy
−sxy
sxx

= JT [Hs]J,
where Hs is the Hessian of s and J is the ninety-degree rotation matrix.
In direct analogy to the discussion above on reciprocal diagrams, if ¯
M is simply
connected, s exists globally, and we have the following theorem.
Theorem 10.2. The surface M with simply connected top view ¯
M is in compressive
static equilibrium if there exists a convex function s: ¯
M →R with
F
p
det g = ∇· JT [Hs]J∇z
at every point on the interior of ¯
M, and
[Hs]J ˆn = 0
on the free boundary, where ˆn is the normal to ∂¯
M.
10.2.3
Relative curvatures
The standard Gauss map ξ maps every point on a surface z(x, y) to the corre-
sponding point on the unit sphere with matching tangent plane. This idea can be
generalized: given a second, convex surface s(x, y), we deﬁne the relative Gauss

Self-Supporting Surfaces
■165
map ξs : R2 →R2 as the function mapping every point on z to the point‡ on s with
identical tangent plane,
[∇z](x, y) = [∇s](ξs(x, y)).
From this relative Gauss map we can deﬁne a relative shape operator dξs(x, y) =
[Hz(x, y)][Hs(ξs(x, y))]−1, and mean and Gaussian curvatures of z relative to s by
1
2 tr(dξs) and det(dξs).
The isotropic polar dual z∗of a surface z(x, y) is formed by mapping
[x, y, z(x, y)] 7→[zx(x, y), zy(x, y), −z + xzx(x, y) + yzy(x, y)];
(10.5)
notice that (a) this mapping is an involution when z is strictly convex; (b) it maps
planes to points; and (c) it maps points with parallel tangent plane to points that
are vertically oﬀset, that is, are coincident when projected onto the xy-plane [310].
See Figure 10.5 for an example of a surface and its dual. The Gauss map, expressed
on the dual surfaces z∗and s∗, is thus simply the identity: it maps points on z∗to
points on s∗with identical (x, y) coordinates. Dual relative curvatures thus have
the particularly simple formulas
Ks∗
z∗= det(Hz)
det(Hs),
Hs∗
z∗= 1
2 tr
 [Hs]−1[Hz]

.
Of special note is the Maxwell hyperboloid h(x, y) =
1
2(x2 + y2), whose dual is
simply a reﬂection about the xy-plane, and for which Kh
z∗= det(Hz); curvatures
relative to h arise naturally in isotropic geometry, where the hyperboloid plays the
role of the canonical unit sphere [310].
10.2.4
Curvature interpretation of equilibrium
As suggested by the above notation, the Airy stress function s(x, y) of a surface
in equilibrium can be interpreted as a height ﬁeld deﬁning a convex surface. This
yields a geometric characterization of equilibrium in terms of the dual relative
curvatures of the surface z and its Airy stress potential s; to see this, note that
JT [Hs]J = det(Hs)[Hs]−1; therefore
Hs∗
z∗=
1
2 det(Hs) tr
 JT [Hs]J[Hz]

=
1
2 det(Hs)∇· JT [Hs]J∇z
and the surface M is in equilibrium if and only if there exists a convex surface
s(x, y), deﬁned on the same top view ¯
M as z, with
2Kh
s∗Hs∗
z∗= F
p
det g
(10.6)
at every interior point of ¯
M, and [Hs]J ˆn = 0 on the free boundary [405].
‡We ignore issues of existence and uniqueness of such a point.

166
■Generalized Barycentric Coordinates in Graphics and Mechanics
The importance of this relation is that it measures equilibrium purely in terms
of the geometry of two height ﬁelds z and s; we will see that this relationship can be
directly ported to the discrete setting, where these two surfaces become piecewise-
aﬃne meshes. And the discretization reconnects with the reciprocal diagrams of
Maxwell and Gaudí.
10.3
DISCRETE THEORY
We now turn to the vertical discrete equilibrium equation (10.3). This equation
takes the very familiar form of a discrete Laplace–Beltrami operator; we can rewrite
it as
−Fi/Ai = 1
Ai
X
j∼i
wij(zj −zi) = (Lwz)i,
(10.7)
where Ai is the dual Voronoi area§ of ¯vi (the area of the region in the plane
nearer to ¯vi than to any other vertex of ¯G) and Lw denotes the discrete Laplace–
Beltrami operator with wij taking the place of the usual cotangent weights (see
Section 1.2.2). Horizontal equilibrium with Lwv = 0 corresponds to the linear
precision property (see Section 1.1.2); together with the compression-only constraint
wij ≥0, horizontal equilibrium guarantees that this so-called stress Laplacian Lw
is a perfect discrete Laplace–Beltrami operator, in the sense of satisfying the four
properties discussed in Section 5.3.7, as originally investigated by Wardetzky et
al. [410]. We thus have yet another characterization of equilibrium: a thrust network
is in equilibrium under loads Fi if and only if there exists a perfect Laplace–Beltrami
operator Lw on ¯G, such that the heights satisfy the Poisson equation (10.7) (with
Neumann boundary conditions at the free boundaries, and Dirichlet at the anchored
boundaries). The right-hand side Fi/Ai can be interpreted as a load density (with
respect to area on the top view) that will be applied to the masonry structure.
10.3.1
Thrust network analysis
Philippe Block, in his seminal work on Thrust Network Analysis [52, 54], exploited
the above observations to formulate an algorithm for designing equilibrium thrust
networks. The form-ﬁnding proceeds in four steps:
1. First, a top view ¯G is constructed in the silhouette of the desired form.
2. Next, a reciprocal diagram is found for ¯G. For regular quadrilateral grids, this
can be done in a marching fashion. As discussed below, a reciprocal diagram
is rarely unique, and later work [53, 273] explored the large space of possible
diagrams to increase design ﬂexibility.
3. Edge weights wij are extracted from the reciprocal diagram.
§Some authors prefer to deﬁne the discrete Laplace–Beltrami operator in terms of barycentric
dual areas, or a Galerkin mass matrix; these alternatives are also suitable.

Self-Supporting Surfaces
■167
4. Given external loads, the Poisson equation (10.7) is solved to determine the
heights z of the network vertices.
The user can explore the space of possible forms by interactively changing the top
view, reciprocal diagram, and/or applied external loads.
10.3.2
Thrust networks as block networks
The safe theorem certiﬁes that if a block network contains a thrust network in
equilibrium within its volume, then the block network is itself stable. This relation-
ship can be reversed: once a thrust network in equilibrium has been constructed,
a masonry structure can be designed enclosing the thrust network, which is stable
by the safe theorem. There are two subtleties with this approach in practice: ﬁrst,
the loads on the structure must be the same as those that were imposed on the
thrust network (although scaling all of the loads by a constant factor is allowed,
since the equilibrium equations (10.1) are scale-invariant, a fact exploited since an-
cient times to analyze full-sized masonry structures using scale models). Second,
masonry blocks have only ﬁnite coeﬃcients of friction and resistance to sliding, so
the orientation of the block interfaces cannot be entirely neglected.
Nevertheless, every thrust network G in equilibrium corresponds to some set of
blocks in frictionless equilibrium [356]. First, compute an intrinsic Voronoi diagram
on G (so that the cell corresponding to vertex vi is piecewise-aﬃne and contains
pieces of all faces adjacent to vi). Each cell can be “fattened” by normal extrusion
to give a network of blocks that completely enclose the thrust network, with block
interfaces perpendicular to the dual edges of the thrust network. Each block can
now be modiﬁed (by adding or removing material, while keeping it in contact with
all of its neighbors) so that its total mass equals the load Fi imposed on the thrust
network, and so that its centroid is at vi.
The thrust network and external loads can then be interpreted as a network
of contact and external forces, respectively, acting on each block’s centroid; equi-
librium of the thrust network guarantees balance of forces and moments for each
block, and thus that the block network is stable [425].
10.3.3
Discrete Airy stress potential
In the smooth setting, we were able to characterize equilibrium in terms of a scalar
Airy stress potential over the top view; so far, in the discrete setting, we have
edge weights, or equivalently reciprocal diagrams, or equivalently perfect Laplace–
Beltrami operators. We now discretize the Airy stress potential [405], and show how
it ties to the other characterizations described above.
Given a top view ¯G, we call a polygonal 2-complex S in R3 a discrete Airy stress
surface with respect to ¯G if:
• the top view ¯S of S (formed by projecting all vertices of S into the plane) is
identical to ¯G;
• the faces of S are planar;

168
■Generalized Barycentric Coordinates in Graphics and Mechanics
fa
S∗
vi
¯vi
¯S∗
a
Figure 10.6 Relationship between S∗and reciprocal diagrams of ¯G.
• when interpreted as a function over ¯G, S is convex.
See Figure 10.3 (right) for an example of such an S. A discrete Airy stress surface,
like the thrust network itself, can be encoded by an assignment of heights si ∈R to
the vertices of ¯G; however, not all such assignments encode valid discrete Airy stress
surfaces, since the resulting points (¯vi, si) ∈R3 cannot always be interpolated by
planar faces.
Applying isotropic polar duality (10.5) to S yields a dual point for every face of
S; denote by ¯S∗the top view of this dual discrete Airy stress surface. ¯S∗and ¯S are
dual as polygonal complexes in the plane. Moreover, they are reciprocal duals:¶ let
¯S∗
a and ¯S∗
b be two adjacent vertices of ¯S∗, and fa(x, y), fb(x, y) be the aﬃne height
functions describing the corresponding faces on S. Then ¯S∗
a = ∇fa, and the dual
edge connecting ¯S∗
a and ¯S∗
b is parallel to ∇fa −∇fb. Since
∇fa · (¯vi −¯vj) = ∇fb · (¯vi −¯vj) = si −sj,
where the primal edge ij is the common edge to faces a and b, the corresponding
edges of ¯S and ¯S∗are orthogonal (see Figure 10.6).
Therefore a reciprocal diagram can be constructed from any discrete Airy stress
surface. The converse is also true: given a reciprocal diagram, assign arbitrary
values of s to the vertices of an arbitrary face a. Then the gradient of all of the
neighboring faces can be computed by adding to the gradient of S on face a the
vector corresponding to the dual edge on the reciprocal diagram joining the dual
vertices of the two faces. All of S can be constructed by gluing together faces in
this way. Local integrability of S follows directly from closure of the force polygon
on the reciprocal diagram,
X
i
(∇fi+1 −∇fi) =
X
i
(¯v∗
i+1 −¯v∗
i ) = 0,
¶Note that there are two distinct notions of duality at work here: polar duality of S and S∗,
and reciprocal duality of their top views.

Self-Supporting Surfaces
■169
where the sums index over the faces circulating around a vertex of ¯G.
The discrete Airy stress surface is not unique, since the choice of the gradient
of the ﬁrst face of S was chosen arbitrarily. Diﬀerent stress surfaces of the same
diagram will diﬀer by addition of a linear function to S. The above constructions
also require ¯G to be simply connected; otherwise S can only be assembled locally.
10.3.4
FEM discretization of Airy stress
By the above construction, lengths on the reciprocal diagram correspond to the
magnitude of the jump in the gradient of S when moving between neighboring
faces. This relationship has also been observed by Fraternali [156], who derived it
in the context of ﬁnite element analysis of cracking in masonry vaults. Starting from
the smooth setting, both the thrust surface z(x, y) and the Airy stress potential
s(x, y) can be discretized using piecewise linear shape functions over the top view
¯G. Doing so, and discretizing horizontal equilibrium using Galerkin ﬁnite elements,
yields the orthogonal relationship between gradient jumps of S and edges of ¯G.
10.3.5
Discrete curvature interpretation of equilibrium
Relative curvature of a polyhedral surface at a vertex with respect to a second poly-
hedral surface has been studied by Bobenko et al. [56] and formulated in terms of
mixed areas of vertex neighborhoods. This concept can be extended to dual isotropic
relative curvature [311] to yield formulas for the dual relative mean curvature at a
vertex vi of a discrete surface G,
HS∗
G∗(vi) = Ai(G∗, S∗)
Ai(S∗, S∗) ,
Ai(G∗, S∗) = 1
4
X
j

det
 ¯v∗
j , ¯S∗
j

+ det
  ¯S∗
j , ¯v∗
j

,
where the sum in the mixed area term Ai is over the faces in the one-ring of vi. It
can be shown [405] that the mixed area in the numerator is
2Ai(G∗, S∗) =
X
j∼i
wij(zj −zi),
where the weights wij are those corresponding to the reciprocal diagram constructed
from S. Moreover, the dual Gaussian curvature relative to the Maxwell paraboloid
is
Kh
S∗(vi) = Ai(S∗, S∗)
Ai
,
where Ai (with no arguments) is, as before, the Voronoi area of ¯vi in the top view.
Putting together all of the pieces and combining them with (10.3), we have, in
direct analogy to (10.6), the following theorem.

170
■Generalized Barycentric Coordinates in Graphics and Mechanics
Theorem 10.3. A thrust network G with simply connected top view ¯G is in equi-
librium if and only if there exists a discrete Airy stress surface S over ¯G with
−Fi/Ai = 2Kh
S∗(vi)HS∗
G∗(vi)
(10.8)
at interior vertices vi, with faces of S abutting consecutive pieces of free boundary
coplanar.
Here, Fi/Ai, like F√det g in (10.6), should be interpreted as a load density over
the top view rather than the thrust surface itself.
10.4
OPTIMIZING FOR STABILITY
We now have the theoretical pieces necessary to formulate some algorithms for
solving inverse problems related to stable masonry. In its simplest form, the inverse
problem asks: given a thrust network M, is it in equilibrium? If not, what changes
must be made to M so that it is now in equilibrium? Once such a network is found,
a masonry structure can be built that is adapted to the shape of the thrust network,
as described in Section 10.3.2.
The ﬁrst question can be answered by looking for non-negative edge weights
wij that satisfy equilibrium (10.1). If such weights do not exist, some modiﬁcation
must be made, either to the combinatorics of M, or to its geometric shape, in order
for it to become stable.
10.4.1
Alternating optimization
If a thrust network is not stable, one can still look for weights that satisfy equi-
librium as much as possible, in the sense of minimizing the residual force at each
node of the thrust network,
arg min
wij≥0
X
i
Fi −
X
j∼i
wij(vi −vj)

2
,
(10.9)
where the sum is taken over all interior and free boundary vertices of M. This opti-
mization amounts to solving a least squares problem with nonnegativity constraints
on the variables, for which there exist specialized solvers [234].
One could now ﬁx the weights wij and solve for displacements of the vertices of
the thrust network that minimize the force residual; since this is a square system
of linear equations, it usually has a solution. While the resulting thrust network
M ′ would be in equilibrium, there is no guarantee that M ′ is at all similar in
shape to M, and in practice it is not, particularly if the initial network M was
far from equilibrium. Vouga et al. [405] proposed an alternating minimization that
repeatedly solves for the wij, while allowing the thrust network to slowly relax away
from M:

Self-Supporting Surfaces
■171
Figure 10.7 Left: The initial, unstable thrust network M and its top view. Middle:
Several iterations of alternating optimizations bring the network to equilibrium.
Right: The Airy stress surface S certifying stability. Since M is not simply con-
nected, S exists only locally; it was cut to reduce its genus for visualization.
1. Begin iteration k = 0 with a guess Mk = M for the stable thrust network.
2. Estimate the loads Fi on the vertices of Mk.
3. Fix Mk and solve for weights wij that minimize the force residuals; see (10.9).
4. Fix wij and improve the positions of the vertices Mk to yield a new thrust
network Mk+1 closer to equilibrium.
5. Repeat from Step 1 until convergence.
Recomputing the loads at every iteration is required since the load typically
depends on the surface areas of the faces of Mk, which change in every iteration.
In Step 4, the new thrust network Mk+1 can be computed from Mk by solving a
least squares problem with one objective term penalizing the force residual, and a
second penalizing displacements of the vertices of Mk+1 away from their positions
in Mk; Vouga et al. suggest penalizing motion in the direction normal to Mk more
severely than tangential sliding, since only the former aﬀects the aesthetics of the
ﬁnal masonry structure.
The above algorithm, though simple and eﬀective in practice (see Figure 10.7),
has several limitations. First, it is not guaranteed to terminate: although both
Steps 3 and 4 are guaranteed to strictly decrease the force residual, Step 2 can
increase it. In practice, termination is not an issue when reasonable boundary con-
ditions and loads are imposed. Second, the optimization modiﬁes M by displacing
its vertices, but does not consider improving equilibrium by remeshing M or per-
forming other combinatorial edits. Third, the algorithm does not consider changing
the boundary conditions (for instance, adding a supported pillar at the interior of
an unstable region of the network) even though such operations are quite natural to
human architects. Finally, the constrained optimization in Step 3 can be a perfor-
mance bottleneck and a source of numerical instability: many solutions might exist
to (10.9), some of which could have edge weights with extremely large or extremely
small magnitudes.

172
■Generalized Barycentric Coordinates in Graphics and Mechanics
10.4.2
Dual formulation as vertex weights
Instead of examining equilibrium through the lens of edge weights, one may instead
attack the problem from the perspective of the discrete Airy stress surface S. Here
we can make an important observation: when a thrust network top view ¯
M is simply
connected and has purely triangular faces, then all discrete convex functions S on
¯
M are valid discrete Airy stress surfaces on ¯
M, since S automatically has planar
faces. To each such S must be associated a reciprocal diagram, which in this case
is the power diagram [19] (see Section 9.2.1) with vertex weight ri at ¯vi given by
ri = 1
2∥vi∥2 −1
2si.
Some sets of edge weights do not correspond to valid reciprocal diagrams, and hence
Airy stress surfaces (if they do not satisfy (10.2)) and many sets of edge weights can
give the same Airy stress surface. On the other hand, the vertex weights si form
a reduced basis for the valid Airy stress surfaces, an observation that de Goes et
al. [113] and Liu et al. [255] leveraged into eﬃcient algorithms for ﬁnding equilibrium
thrust networks M ′ approximating a designed network M.
Given ¯
M, the algorithm seeks Si and heights zi satisfying the vertical equilib-
rium condition (10.3) while keeping the zi as close as possible to their designed
values; de Goes et al. [113] propose to penalize displacements of zi more for vertices
initially closer to equilibrium. The compression-only constraint, that S is convex,
becomes a set of linear inequality constraints encoding that every edge of S is a
convex edge. The algorithm can be easily modiﬁed to handle the more general case
where ¯
M has holes, and S exists only locally. It can also be augmented to allow
sliding of the top view vertices, using edge ﬂips to keep
¯
M a regular triangula-
tion [255].
10.4.3
Perfect Laplacian optimization
Recall that equilibrium of M is equivalent to the existence of a perfect Lapla-
cian (10.2) on the top view ¯
M for which vertical heights of the network vertices
satisfy a Poisson equation (10.3). Herholz et al. [187] studied perfect Laplacians
on polygonal meshes and developed a diﬀerent approach to ﬁnding an equilibrium
thrust network M ′ given a guess M. The key insight is that a current guess for the
weights wij, together with the speciﬁed supported boundary vertex positions and
the external loads, uniquely determine heights zi of a thrust network M ′ in equi-
librium, with ¯
M = ¯
M ′, via (10.3). Comparing edge lengths of M ′ to M suggests
that the edge weights should be updated as
wk+1
ij
= wk
ij
vk
i −vk
j

∥vi −vj∥,
where wk
ij and vk
i are the edge weights and vertex positions at the k-th iteration of
the algorithm. This process is repeated until convergence of M ′.

Self-Supporting Surfaces
■173
Figure 10.8 Left: Direct optimization of the thrust network can cause “spikes” to
appear where the stresses change rapidly over the surface. Optimizing for constant
dual-isotropic mean curvature yields a better-behaved thrust network. (Data for
this image courtesy of Yang Liu and Hao Pan.) Right: Laying out blocks on a
thrust surface by staggered grouping of quadrilateral faces, as a ﬁnal step of the
design process. (Image courtesy of Daniele Panozzo, used by permission.)
Remarkably, this optimization works well even in cases where the top view ¯
M
has challenging geometry, such as sliver triangles or non-convex polygonal faces,
which is far from admitting a perfect Laplacian. Moreover, the update rules for M
and wij do not require the constrained optimization of the alternating algorithm in
Section 10.4.1, instead needing only the solution of sparse linear systems. On the
other hand, the forms M ′ to which this approach converges can diﬀer substantially
from the initial design M.
10.4.4
Relative-curvature-based smoothing
One drawback of the optimization methods presented so far is that they do not
guarantee the quality of the ﬁnal, equilibrium thrust network M ′; indeed, a common
problem is the presence of “spikes” in the equilibrium network, caused by edge
weights that vary wildly over the star of a vertex (or equivalently, stresses that
do not change smoothly over a small neighborhood). See Figure 10.8, left. Liu et
al. [255] developed a method for addressing this problem by insisting that M has
constant dual-isotropic relative mean curvature relative to its Airy stress surface S:
HS∗
M ∗= H for a constant H (taken to be the median value of HS∗
M ∗in the input
network). If this assumption were to hold, equilibrium, as understood in terms of
curvatures in (10.8), would reduce to
−Fi = 2AiKh
S∗H = 2Ai(S∗, S∗)H,
where the dual cell areas Ai(S∗, S∗) depend on the stress surface heights si. Liu
et al. solve for these using Newton’s method, taking care that S remains convex
(this is done by computing the convex hull and projecting any violating vertices

174
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 10.9 Left: Initial thrust network and Airy stress surface. Middle: Eigenvectors
of [Hs]−1[Hz] trace out curve networks conjugate to both surfaces. Right: Simulta-
neous remeshing of both thrust network and stress surface as planar quadrilateral
meshes. (Images courtesy of Mathias Höbinger, used by permission.)
down to the convex hull in between Newton iterations). This curvature-smoothing
operation dramatically improves the fairness of the thrust network.
10.4.5
Steel-glass structures and PQ faces
A popular alternative to masonry for realizing freeform structures are steel-glass
constructions, made out of glass panels supported inside a steel skeleton. Under the
assumption that the glass panels are not structural and carry no load, equilibrium
of steel-glass structures is identical to equilibrium of thrust networks, with the
exception that the steel beams can carry only bounded compressive load, and do
support some tension.
Steel-glass structures introduce new aesthetic considerations, however. Quadri-
lateral glass panels are preferred to triangular ones, as the nodes where beams meet
in the former case have lower valence and are thus easier to manufacture, and the
structure requires fewer steel beams, making the structure more permeable to light.
Planar glass panels are much preferred to curved panels, as it is much easier to cut
planar panels from a large glass sheet, than it is to hot-bend custom panel shapes.
We are thus left with a geometry problem: given a thrust network M in equi-
librium, can it be approximated by a thrust network N with planar quadrilateral
faces? Let S be the Airy stress surface certifying M’s stability. One could simply
remesh M, and then resample S to yield Ψ with ¯Ψ = ¯N. While Ψ would still be
convex, there is no guarantee that the faces of Ψ are planar, and thus Ψ is no
longer necessarily a valid stress surface. One thus needs to simultaneously remesh
both M and S so that both remeshed surfaces have an identical top view, and
planar quadrilateral faces (see Figure 10.9).
The edges of any planar quadrilateral mesh approximating M follow conjugate
curve networks [347] on M. More speciﬁcally, if M approximates a smooth surface

Self-Supporting Surfaces
■175
z : ¯
M →R, M can be remeshed as a planar quadrilateral mesh by ﬁrst ﬁnding two
families of curves a(s, t), b(s, t) in the plane with ˙aT [Hz]˙b = 0. Since the same must
hold for S approximating s, we need families of curves satisfying
˙aT [Hz]˙b = ˙aT [Hs]˙b = 0,
which we can ﬁnd by taking a and b to be streamlines following the eigenvectors
of [Hs]−1[Hz]. A new top view can be traced along these lines, and then lifted
to planar quadrilateral remeshings N and Ψ of M and S, using the procedure of
Schiftner [347]. Since remeshing does not alter the surface’s coarse geometry, Ψ is
close to being convex and to satisfying the curvature equilibrium equation (10.8); N
and Ψ can be further polished using Newton’s method to exactly satisfy equilibrium
and face planarity.
The unexpected consequence of the above is the following theorem [405].
Theorem 10.4. If a surface z(x, y) can be approximated by a thrust network M
in compressive equilibrium, it can also be approximated by a thrust network N in
compressive equilibrium and with planar quadrilateral faces.
However, there is no guarantee about the quality of the faces, which can vary
dramatically in scale across the surface.
10.4.6
Block layouts from stable surfaces
Once a thrust network in equilibrium has been found, a masonry structure can
be constructed around it that is guaranteed to be stable by the safe theorem, as
discussed in Section 10.3.2. However, a practical issue remains: blocks arranged
directly by dualizing the thrust network tend to lie in long “chains” or “strips”
that easily come apart under weathering or horizontal load. Panozzo et al. [301]
developed a post-processing algorithm that remeshes the thrust network into blocks
that are rectangular and staggered, much as is seen in a regular brick wall. The
algorithm ﬁrst remeshes the surface into a quadrilateral mesh. If the quad mesh
has no singularities, one can ﬁnd a staggered block pattern by simply deleting
every other “vertical” edge. Generally speaking, a nontrivial freeform surface has
complex geometry with several singularities present after remeshing, so edges are
instead removed by solving a 2-coloring problem, which guarantees that blocks are
staggered and are composed of at most two quads (see Figure 10.8, right).
10.5
CONCLUSION AND OPEN PROBLEMS
Although computational analysis and form-ﬁnding of stable freeform masonry struc-
tures is by now a thoroughly studied topic, there remain several open questions that
have not been addressed by any previous work. Answering them will require sig-
niﬁcantly expanding our understanding of the mathematics of stable masonry, and
its connections to discrete and smooth geometry.

176
■Generalized Barycentric Coordinates in Graphics and Mechanics
10.5.1
Sensitivity analysis of masonry structures
In the above we assumed that the loads are known (either prescribed, or speciﬁed
as a function of the surface area of the masonry structure). We know multiple
characterizations of when the structure is stable under these known loads. However,
will the structure remain standing if the loads change (as can easily happen during,
for instance, a snowstorm, wind storm, or earthquake)? Can bounds be proven
guaranteeing that the structure remains standing, if the loads do not change by
more than some tolerance? How must the structure be modiﬁed to improve its
resilience to additional loads?
The main challenge to addressing changes in load is that there is no simple
relationship between the loads and the internal forces (or the wij), thanks to static
indeterminacy. Instead, if the structure can bear additional load, it usually can do
so in inﬁnitely many ways. A more complete understanding of the space of possible
stresses that can bear a given load, and how that space changes as the loads change,
remains elusive.
10.5.2
Progressive stable structures
The analysis presented in this chapter only applies to complete masonry structures.
Of course, these must still be built one brick at a time, and the stability of the ﬁnal
structure does not in any way speak to the stability of the structure in a partial
state (consider that an arch is unstable up until the keystone is placed). When can
a masonry structure be built progressively, so that at every point the structure is
stable? Can a design be modiﬁed to eliminate, or at least mitigate, the need for
scaﬀolding or formwork? Some work in a similar vein [121] has looked at supporting
blocks from above using chains attached to ﬁxed vertical anchors, and where to place
the anchors to minimize the number of chains that must be added or removed.

III
Applications in Computational Mechanics
177


C H A P T E R 11
Applications of Polyhedral
Finite Elements in Solid
Mechanics∗
Joseph E. Bishop
Sandia National Laboratories, Albuquerque, USA
CONTENTS
11.1
Introduction ......................................................
180
11.2
Governing equations of solid mechanics .........................
183
11.3
Polyhedral ﬁnite element formulation ...........................
184
11.3.1 Weak form of governing equations .......................
185
11.3.2 Shape functions ..........................................
185
11.3.3 Element integration ......................................
186
11.4
Rapid engineering analysis .......................................
187
11.5
Fragmentation modeling .........................................
191
11.5.1 Fracture methodology ....................................
192
11.5.2 Random Voronoi meshes .................................
193
11.5.3 Fragmentation ...........................................
194
11.6
Summary and outlook ...........................................
195
T
he finite element method has revolutionized structural analysis since its in-
ception over 50 years ago, by enabling the computer analysis of geometrically
complex structures. The main requirement of the ﬁnite element method is that an
appropriate partition, or mesh, of the structure be created ﬁrst. The elements of
the partition typically have standard shapes, such as the hexahedron, pentahedron,
∗Research support of Sandia National Laboratories is gratefully acknowledged. Sandia National
Laboratories is a multimission laboratory managed and operated by National Technology and
Engineering Solutions of Sandia, LLC., a wholly owned subsidiary of Honeywell International,
Inc., for the U.S. Department of Energy’s National Nuclear Security Administration under contract
DE-NA-0003525.
179

180
■Generalized Barycentric Coordinates in Graphics and Mechanics
(a)
(b)
(c)
Figure 11.1 Example structure (a) with ﬁnite element meshes composed of standard
element shapes: (b) hexahedral mesh, (c) tetrahedral mesh.
and tetrahedron. While this small library of standard element shapes is suﬃcient
for many applications, there is a growing need for more general polyhedral shapes,
ones that can have an arbitrary number of vertices, edges, and faces, and ones that
can be non-convex. In this chapter, we discuss current and possible future appli-
cations of polyhedral ﬁnite elements in solid mechanics. These applications include
rapid engineering analysis through novel meshing and discretization techniques,
and fracture and fragmentation modeling. Several ﬁnite element formulations of
general polyhedra have been developed. In this chapter we use a polyhedral formu-
lation based on the use of harmonic shape functions. Harmonic shape functions are
one example of several possible generalized barycentric coordinates, as discussed in
Chapter 1.
11.1
INTRODUCTION
The analysis of stress and strain in a mechanical part or structure is critically
important to the overall engineering design and development process. The ﬁnite
element method has revolutionized analysis in solid mechanics by enabling the
computer analysis of geometrically complex, nonlinear structures subjected to gen-
eral loading conditions. Additionally, the ﬁnite element method can incorporate
general material constitutive models, interface models, and constraints, making it
an extremely versatile engineering analysis tool [41]. The main requirement of the
ﬁnite element method is that an appropriate partition, or mesh, of the domain be
created ﬁrst, as shown in Figure 11.1. This partition of the domain typically con-
sists of standard ﬁnite element shapes, such as the hexahedron and tetrahedron, as
shown in Figures 11.2(a) and 11.2(b), respectively. Once the ﬁnite element mesh
is created, analysis of the response of the structure to applied loads can be ob-
tained using standard computational techniques, starting with the weak form of
the governing ﬁeld equations of solid mechanics [41]. Figure 11.3 shows the stress
ﬁeld (von Mises) resulting from the application of torsional tractions to the I-beam
shown in Figure 11.1. This type of structural analysis is now an indispensable tool
in engineering practice.

Applications of Polyhedral Finite Elements in Solid Mechanics
■181
(a)
1
2
3
4
6
5
7
8
(c)
(b)
1
2
3
4
Figure 11.2 Finite element shapes: (a) hexahedron, (b) tetrahedron, (c) general
polyhedron (possibly non-convex with warped faces).
(a)
(b)
1.0
0.0
0.5
Figure 11.3 (a) Stress ﬁeld (von Mises) resulting from a ﬁnite element analysis of
the I-beam shown in Figure 11.1 with applied torsional tractions, (b) cross-section
view. (Reproduced with permission from [48].) See color insert.
While the small library of element shapes consisting of hexahedra, pentahedra,
and tetrahedra is suﬃcient for many applications, there is a growing need to have
access to ﬁnite element formulations for general polyhedral shapes, ones that can
have an arbitrary number of vertices, edges, and faces (see Figure 11.2(c)). For ad-
ditional ﬂexibility, it is also desirable to have formulations that can handle warped
polygonal faces and allow for non-convex shapes. (Note that the conventional for-
mulation of the hexahedral ﬁnite element, using trilinear shape functions mapped
from a parent element, allows for warped faces.) While several ﬁnite element for-
mulations of general polyhedra now exist (see, for example, [27, 47, 322]), in this
chapter a formulation based on harmonic shape functions is used. Harmonic shape
functions are one example of several possible generalized barycentric coordinates,
as discussed throughout this book. A diﬀerent formulation for polyhedra, one that
is based on the virtual element method, is given in Chapter 15.
A driving application for general polyhedral ﬁnite elements in solid mechanics is
rapid engineering analysis. Despite several decades of research on mesh generation,
the meshing process for geometrically complex shapes, though much advanced, is
still time consuming and labor intensive. While automated tetrahedral meshing

182
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 11.4 Conventional meshing techniques on a portion of an automotive cylin-
der head. The cylinder head contains a multitude of machine features such as holes,
ﬁllets, blends, and chamfers: (a) hybrid hexahedral/pentahedral mesh, (b) tetrahe-
dral mesh. (Adapted from [45].)
technology seemingly circumvents the manual meshing process, there are still nu-
merous heuristics involved with geometry defeaturing and cleanup, a priori mesh
adaptation for minimization of solution error, and dimensional representations (e.g.,
beam versus shell versus continuum elements). The challenges in meshing realistic
domains is shown in Figure 11.4. The automotive cylinder head has several geomet-
ric scales and numerous machine features such as holes, ﬁllets, blends, and chamfers.
Two examples of conventional meshing techniques are shown. Several possible uses
of polyhedral ﬁnite elements to speed up the meshing process will be discussed in
Section 11.4.
Another application of polyhedral ﬁnite elements is modeling pervasive fracture
and fragmentation processes using dynamically changing mesh connectivity with-
out remeshing [46, 49]. In this approach, fracture surfaces are allowed to nucleate
and propagate only along inter-element faces. This is demonstrated in Figure 11.15
in which a quasi-brittle column impacts a rigid surface at an oblique angle. This
technique for modeling fracture typically results in a type of mesh-dependency.
The use of random polyhedral meshes can alleviate this mesh-dependency and re-
store a notion of convergence with mesh reﬁnement. Details of this application and
simulation are given in Section 11.5.
Additional advantages of polyhedral ﬁnite elements have been explored in mod-
eling ﬂuid dynamics using ﬁnite-volume techniques [207] and for topology opti-
mization [390]. These applications will not be discussed here. The application of
polyhedral ﬁnite elements for extremely large deformations in solid mechanics is
discussed in Chapter 12.

Applications of Polyhedral Finite Elements in Solid Mechanics
■183
This chapter is organized as follows. The governing equations of solid mechan-
ics are reviewed in Section 11.2. Section 11.3 provides an overview of a ﬁnite ele-
ment formulation based on harmonic shape functions. Several approaches of rapid
meshing/analysis are discussed in Section 11.4. The use of polyhedral elements in
modeling fracture and fragmentation is discussed in Section 11.5. A summary of
this chapter and an outlook are provided in Section 11.6.
11.2
GOVERNING EQUATIONS OF SOLID MECHANICS
In this section, the governing equations of solid mechanics are brieﬂy reviewed.
Consider the motion of a body B with interior domain Ωand boundary Γ subjected
to a body force b and applied surface tractions t. A Lagrangian description of the
motion of B is used. The initial conﬁguration of the body is denoted by Ω0 with
boundary Γ0. In the initial conﬁguration, the position vector of a material point is
denoted by X. In the deformed conﬁguration, the position of a material point is
denoted by x. The displacement vector u is given by u = x −X. The (material)
derivative of the current position x with respect to the original position X is given
by ∂x/∂X. This vector derivative is called the deformation gradient, denoted by
F , and in terms of the displacement is given by
F = ∂u
∂X + I,
where I is the identity tensor. From the deformation gradient, one can deﬁne
measures of strain, for example, engineering strain, logarithmic strain, Lagrangian
strain, and Eulerian strain [63]. The Lagrangian strain tensor E is deﬁned as
E := 1
2(C −I),
where
C := F T F
is the right Cauchy–Green tensor.
In order to describe the kinetics of the material, one needs to derive measures
of stress and the constitutive relations between stress and strain. In the context of
hyperelasticity, one posits a potential energy function W of the strain tensor,
W = W(E).
Certain restrictions are placed on W to obtain a constitutive model that is in-
dependent of the observer (objectivity) and to obtain a stable material. The ﬁrst
Piola–Kirchhoﬀstress tensor P is deﬁned to be work conjugate to the derivative of
W with respect to the deformation gradient F ,
P = ∂W
∂F
(11.1)
so that
dW = P : dF .

184
■Generalized Barycentric Coordinates in Graphics and Mechanics
An idealized material model useful for demonstrating large deformation behavior
of a ﬁnite element formulation is the isotropic neo-Hookean model. For this material
model the potential energy is of the form [63]
W(F ) = µ
2 (C : I) −µ log J + λ
2 (log J)2,
(11.2)
where µ and λ are material constants, and J2 = det C. Substituting (11.2) into
(11.1) results in the following constitutive relationship between the ﬁrst Piola–
Kirchhoﬀstress P and the deformation gradient F ,
P =

µ(F F T −I) + λ(log J)I

F −T .
(11.3)
This material model is used in the simulation results shown in Figure 11.6. In
the small deformation limit, (11.3) becomes the standard linear elasticity equation
with µ and λ the shear modulus and the Lamé parameter, respectively. Hyperelastic
formulations also exist for large-deformation plasticity [139], where now the stress
tensor is a function of the entire history of deformation.
Finally, the governing equilibrium equations (conservation of linear momentum)
are required. In Section 11.3, generalized barycentric coordinates are used to form
the ﬁnite element shape functions directly in the initial conﬁguration of the domain.
Additionally, the weak form of the equilibrium equations will be integrated in the
reference conﬁguration. Therefore, a total-Lagrangian formulation of the governing
equations is appropriate (as opposed to updated-Lagrangian). The conservation of
linear momentum is then given by [41]
∂P
∂X : I + ρ0b = ρ0 ¨u
(11.4)
with displacement boundary conditions
u = ¯u
on
Γu
(11.5)
and traction boundary conditions
P · N = t0
on
Γt,
(11.6)
where ρ0 is the initial density, b is the body force vector per unit mass, ¨u is the
acceleration vector, N is the outward unit normal on Γ0, t0 is the traction vector
per unit initial area, and Γu ∪Γt = Γ0 and Γu ∩Γt = ∅.
11.3
POLYHEDRAL FINITE ELEMENT FORMULATION
The formulation of general polyhedral ﬁnite elements, ones with an arbitrary num-
ber of vertices and faces, both convex and non-convex, is an active area of research.
A ﬁnite element formulation for polyhedra with planar faces, applicable to non-
linear solid mechanics, has been achieved by Rashid and Selimotic [322]. Shape
functions were constructed by using a polynomial basis optimized for smoothness,

Applications of Polyhedral Finite Elements in Solid Mechanics
■185
while satisfying other constraints necessary for mesh convergence. The shape func-
tions, however, are only weakly compatible at element faces. More recently, Rashid
and Sadri [321] have proposed a polygonal ﬁnite element formulation for use in
solid mechanics in which the discrete values of both the shape functions and their
derivatives at the quadrature points are determined based only on the satisfaction
of linear consistency, integration consistency, and a combined smoothness and com-
patibility measure. The recent virtual element method (VEM) [27, 161] provides
a type of mean-gradient formulation for polyhedra with necessary stabilization for
convergence with mesh reﬁnement [81]. This method is discussed in Chapter 15. Re-
cently, the author has developed a displacement-based ﬁnite element formulation
for general polyhedra based on the use of harmonic shape functions for applica-
tions in nonlinear solid mechanics [47]. This latter formulation is brieﬂy reviewed
here. Other types of generalized barycentric coordinates, such as those described in
Chapter 1, could possibly be used as well.
11.3.1
Weak form of governing equations
The weak form of (11.4) through (11.6) is given by the following variational prob-
lem [41]: ﬁnd u ∈H1(Ω0), where H1(Ω0) := [H1(Ω0)]d, with u = ¯u on Γu such
that
ˆ
Γt
to · δu dΓ0 +
ˆ
Ω0
ρ0b · δu dΩ0 −
ˆ
Ω0
P : (∂(δu)/∂X) dΩ0 −
ˆ
Ω0
ρ0 ¨u · δu dΩ0 = 0
(11.7)
for all test functions δu ∈H1
0(Ω0). Here, H1(Ω0) is the Sobolev function space
of degree one containing functions that possess square-integrable weak derivatives,
and the Sobolev space H1
0(Ω0) = {u ∈H1(Ω0) : u = 0 on Γu}. Any u ∈H1(Ω0)
is referred to as a trial function. The Bubnov–Galerkin procedure for obtaining an
approximate solution to (11.7) uses a ﬁnite dimensional approximation to H1(Ω0),
denoted by V h, with V h ⊂H1(Ω0) and V h
0
= {uh ∈V h : uh = 0 on Γu}.
Let {ψI, I = 1, . . . , N} be a basis for V h so that any uh ∈V h may be writ-
ten as uh(X) = PN
I=1 uIψI(X). A ﬁnite element approximation entails choosing
basis functions with local support deﬁned by a mesh. Let Ωe represent the do-
main of a ﬁnite element with vertex (nodal) coordinates {vi , i = 1, . . . , n}. The
basis functions ψI(X) are decomposed into element shape functions denoted as
{φi(X) , i = 1, . . . , n}, where n is the number of vertices in the polyhedral element.
11.3.2
Shape functions
For a ﬁnite element formulation of polyhedra, several types of barycentric coor-
dinates can be adopted for the element shape functions including harmonic [215],
maximum entropy [202, 375], and reproducing kernel [46]. These barycentric coor-
dinates are described in Chapter 1 along with several other types. Harmonic shape
functions are used here. The shape functions φi(X) are deﬁned in the reference
(original) conﬁguration, so there is no mapping to a parent coordinate system as
is done with standard elements. Integration points within the element, used to in-

186
■Generalized Barycentric Coordinates in Graphics and Mechanics
(a)
(b)
(c)
(d)
0.0
0.5
1.0
Figure 11.5 (a) Example polyhedron with element shape functions (b–d) based
on harmonic coordinates. Shape functions for three vertices are shown. (Adapted
from [47].)
tegrate the contribution to the volume integral in (11.7), are also deﬁned in the
reference conﬁguration.
Harmonic functions satisfy the Laplace equation (1.17). For use in deﬁning shape
functions of a polyhedral ﬁnite element, solutions of (1.17) with appropriate bound-
ary conditions possess the necessary properties of partition of unity (1.8) and linear
reproduction (1.9). These properties result in an isoparametric displacement-based
ﬁnite element formulation with an optimal rate of convergence, assuming that the
weak form given by (11.7) is integrated in a consistent manner [47]. The shape func-
tions also possess the Kronecker-delta property at the nodes. This property greatly
simpliﬁes the enforcement of displacement boundary conditions in the ﬁnite element
solution.
The appropriate boundary conditions for the solution of (1.17) on a polyhe-
dral ﬁnite element are developed hierarchically. Equation (1.17) is ﬁrst applied to
each edge, with appropriate end-point boundary conditions (zero or one). Equa-
tion (1.17) is then solved for each face, with the previous edge solutions applied
as boundary conditions. Equation (1.17) is then solved in the interior of the poly-
hedron, with the previous face solutions applied as boundary conditions. Example
shape functions are shown in Figure 11.5. In [47], solutions to (1.17) were approx-
imated using the ﬁnite element method on a sub-tetrahedral mesh of the element.
The construction of this sub-tetrahedral mesh was facilitated by assuming that the
element shape was star-convex with respect to the vertex-averaged centroid. These
approximate solutions still provide the necessary properties of ﬁnite element shape
functions described previously.
11.3.3
Element integration
The integration points of the polyhedral ﬁnite element are deﬁned based on the
approach of Rashid and Selimotic [322]. In this approach, integration points are
placed in so-called tributary volumes associated with each polyhedral vertex. Thus,
the number of integration points is equal to the number of vertices. In practice,
this integration method is suﬃcient to prevent any zero-energy modes of defor-
mation. However, this integration scheme has only linear precision (can integrate
linear functions exactly). Since the harmonic shape functions are non-polynomial in

Applications of Polyhedral Finite Elements in Solid Mechanics
■187
(a)
(b)
50 × 103
25 × 103
0
Figure 11.6 Large deformation example, a hyperelastic beam subjected to a torsion
loading. One end is ﬁxed while a full 360◦rotation is applied to the opposite end.
(a) original polyhedral mesh (Voronoi tessellation with maximal Poisson seeding),
(b) deformed shape and von Mises stress ﬁeld. See color insert.
nature, signiﬁcant error is introduced with this low-order integration scheme. Fur-
thermore, this error results in a failure to pass the patch test (a test for polynomial
completeness in the element formulation). To circumvent this diﬃculty, the deriva-
tives of the harmonic shape functions are modiﬁed slightly to satisfy the discrete
divergence theorem while maintaining other necessary consistency properties [47].
This derivative correction has been further elucidated in [393].
A large deformation example using this polyhedral ﬁnite element formulation
is shown in Figure 11.6. A beam of dimensions 100 × 100 × 500 is ﬁxed at one
end while the opposite end is subjected to a full 360◦rotation. The hyperelastic
material model deﬁned in (11.3) is used with λ = 57.7 × 103 and µ = 38.4 × 103.
A Voronoi tessellation with random seeding, described in Section 11.5, is used to
mesh the beam with polyhedral elements.
11.4
RAPID ENGINEERING ANALYSIS
As noted in Section 11.1, for engineered mechanical structures the process of mesh-
ing realistic domains can be extremely challenging. This is also true for geologi-
cal [154, 219], biological [68, 365, 434], and micromechanical structures [238, 249,
363]. Several recent discretization paradigms are focused on reducing the meshing
task in solid mechanics. These include (1) meshfree methods [91, 245], (2) isoge-
ometric methods [108], and (3) ﬁctitious-domain methods (also called embedded
domain and immersed boundary methods) [45, 132, 348, 349].
Additionally, there are a number of possible ways of using polyhedral ﬁnite el-
ements to signiﬁcantly decrease the burden of meshing. One approach to direct
polyhedral mesh generation is to use Voronoi constructions [295]. While straight-
forward on simple convex domains using ghosting techniques [60], the generation of
Voronoi meshes on geometrically complex structures is challenging. A more practi-

188
■Generalized Barycentric Coordinates in Graphics and Mechanics
(a)
(b)
(c)
Figure 11.7 Example of polygonal element construction using the barycentric sub-
division of a triangular mesh: (a) triangle element with barycentric subdivision
using edge midpoints and the element centroid, (b) barycentric subdivision of a
patch of triangle elements, (c) aggregation of sub-quadrilaterals into a polygonal
element.
cal approach is to use barycentric subdivision of tetrahedral elements into hexahe-
dra. In this approach, each tetrahedral element is subdivided into four hexahedral
elements using edge midpoints and the element centroid. Figure 11.7(a) shows a
two-dimensional example. This approach of all hexahedral meshing typically re-
sults in highly distorted hexahedral elements that may be unsuitable for use as
individual elements within a ﬁnite element analysis. However, a polyhedral element
can be created by aggregating the set of hexahedral elements attached to the origi-
nal nodes of the tetrahedral mesh. This process is demonstrated in Figures 11.7(b,c)
in two dimensions for an interior vertex. A three-dimensional example is shown in
Figure 11.8. Furthermore, the sub-hexahedra that form the polyhedron provide a
convenient structure for element integration and shape function construction.
Another approach to polyhedral meshing is to ﬁrst create a highly reﬁned tetra-
hedral mesh that captures all of the geometric detail, but is too reﬁned to be compu-
tationally practical. The tetrahedra can then be adaptively aggregated into larger
polyhedral elements producing a mesh that is computationally feasible yet still
captures the geometric detail. Standard domain-decomposition techniques could
be used to form the aggregates. This approach has been studied in the context of
discontinuous Galerkin ﬁnite elements [25]. However, aggregates of a large number
of tetrahedral elements will result in a polyhedral element with a large number
of vertices. The number of vertices could be reduced by creating a “virtual mesh”
with reduced geometrical representation. Discretization techniques based on primi-
tive triangle meshes but using maximum-entropy coordinates deﬁned on larger cell
aggregates have recently been investigated [281].
In an approach similar to ﬁctitious-domain methods, cut-cell methods embed
the geometrically complex domain within a structured hexahedral mesh of a bound-
ing box. The desired mesh of the geometrically complex domain is then obtained by

Applications of Polyhedral Finite Elements in Solid Mechanics
■189
(a)
(b)
Figure 11.8 Example of polyhedral meshing using barycentric subdivision (see Fig-
ure 11.7(a)): (a) Barycentric dual of the tetrahedral mesh shown in Figure 11.1(c);
(b) Each polyhedral cell is represented as a diﬀerent color. See color insert.
“simply” cutting hexahedral elements that intersect the domain boundary to form
polyhedra. Hexahedra are then left on the interior and exterior. The exterior hexa-
hedra and polyhedra are discarded. This technique has been used in computational
ﬂuid dynamics with ﬁnite-volume discretizations [162, 207, 430]. It has also been
investigated for use in solid mechanics by Rashid and Selimotic [322], and more
recently by Sohn and coworkers [224, 365, 366], with promising results. Song and
coworkers [256, 387] have developed a similar approach using the “scaled boundary”
ﬁnite-element formulation of the resulting cut-cell polyhedra. In practice the “cut-
ting” of a hexahedron by an arbitrary surface is nontrivial, particularly since the
cutting operation needs to produce a continuous surface and preserve the topology
of the original domain.
One approach to simplifying the computational-geometry problem is to use the
classical marching cubes algorithm [261, 291]. This algorithm is commonly used to
construct isosurfaces of ﬁeld quantities. In this approach, each vertex of the hexahe-
dron is identiﬁed as either interior or exterior to the given domain. For a hexahedron,
there are 28 = 256 possible cases, which can be reduced to 15 base conﬁgurations
by rotation and symmetry operations. These 15 base conﬁgurations are shown in
Figure 11.9. With this categorization of vertices, the edges of the hexahedron that
intersect the surface of the domain are then known. The actual intersection points
within an edge can be determined by linear interpolation if a scalar ﬁeld is assigned
to each vertex, such as a signed distance function. A polyhedral element can then

190
■Generalized Barycentric Coordinates in Graphics and Mechanics
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
Figure 11.9 The 15 base conﬁgurations of the marching cubes triangulation table.
The other cases can be found by rotation or symmetry. (Adapted from [291].)
(a)
(b)
Trimmed 
hexahedral 
elements
CAD surface
Figure 11.10 Trimmed hexahedral elements using the cut-cell process: (a) cutting
process, before and after, (b) trimmed hexahedral element with nodes at the ver-
tices. (Adapted from [224].)
be constructed from this triangulated surface within each hexahedron as shown in
Figure 11.10. In practice, the created polyhedra may be non-convex. Also, toler-
ancing issues due to small edges are a primary concern, and topology issues may
require disambiguation techniques [283, 401]. These techniques are extensible to
adaptively reﬁned (quadtree in 2D or octree in 3D) overlay meshes [358, 424].

Applications of Polyhedral Finite Elements in Solid Mechanics
■191
(a)
(b)
(c)
Figure 11.11 Examples of fracture processes in a continuum in which unrestricted
fracture growth could lead to modeling diﬃculties: (a) two fractures propagate from
the surface and touch at an arbitrarily small angle, (b) fractures initiate and branch
arbitrarily, (c) three fractures propagate from the surface and intersect, creating an
arbitrarily small fragment.
11.5
FRAGMENTATION MODELING
The modeling of failure and fracture of a solid body is one of the major challenges in
theoretical and computational solid mechanics. The extent of fracturing in a solid
body is termed pervasive when a number of cracks nucleate, propagate, branch, and
coalesce. The highly nonlinear, multiscale problem of pervasive fracture is challeng-
ing to simulate. The simulation of pervasive fracture is further complicated by the
extensive self-contact that can accompany the generation of new crack surfaces,
especially during fragmentation.
Several computational fracture methods strive to model unrestricted fracture
growth in a continuum using an explicit representation of the fracture surfaces,
e.g., explicit meshing [290], extended ﬁnite element method [374], and embedded
discontinuities [213]. However, the goal of unrestricted fracture growth quickly be-
comes computationally infeasible when considering pervasive fracture processes in
which multiple fractures nucleate, branch, and intersect. Figure 11.11 gives three
examples of unrestricted fracture processes in a continuum. Figure 11.11(a) shows
two fractures initiating from a surface and approaching each other at an arbitrar-
ily small angle. Figure 11.11(b) shows one fracture initiating from a surface with
arbitrary branching, self-intersection, and initiation away from the surface. Fig-
ure 11.11(c) shows three fractures initiating from a surface, then intersecting and
forming an arbitrarily small fragment. In order to enable robust simulations of per-
vasive fracture processes, the allowable fracture paths must be restricted to some
degree. This may be thought of as regularizing the pervasive fracture problem. One
approach to this regularization is to a priori discretize the space of all possible
fracture paths with constraints on minimum fragment size, bifurcation locations,
etc.

192
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 11.12 Dynamic mesh connectivity to represent a new fracture surface along
the face network of a polygonal mesh.
11.5.1
Fracture methodology
One approach for regularizing the pervasive fracture problem is to only allow frac-
ture surfaces to form at the inter-element faces of a ﬁnite element mesh as shown in
Figure 11.12. At the inception of material softening leading to fracture, the connec-
tivity of the mesh is modiﬁed to reﬂect a new surface, and a cohesive traction with
a softening behavior is dynamically inserted. The cohesive traction is of the ex-
trinsic form, as opposed to an intrinsic traction-separation relation that is a priori
seeded throughout the face network of the ﬁnite element mesh [303]. The restriction
of only allowing new surfaces to form at inter-element faces provides a necessary
regularization of the resulting domain and surface topologies to obtain a robust
simulation. This approach to modeling pervasive fracture processes has been used
by several researchers [46, 239, 299, 300, 339, 340]. Instead of inserting new fracture
surfaces at the start of material softening, one could also use gradient damage or
phase ﬁeld computational methodologies [64, 277, 278, 331] to model the physics
of material softening and then change mesh connectivity when the load-carrying
capacity of the material has decreased below a certain threshold.
This technique for modeling fracture typically results in a type of mesh-
dependency in the crack paths. The use of a random mesh with no preferred orien-
tation restores, in a weak sense, simulation objectivity within this class of fracture
methods. A certain type of random mesh advocated by the author is the random
close-packed (RCP) Voronoi mesh [46]. This type of mesh is described in more
detail in the following subsection. The RCP Voronoi mesh provides a random face
network for representing fracture surfaces. The polyhedral cells of the RCP Voronoi
mesh are formulated as ﬁnite elements. The broader question of what type of mesh
is optimal for this fracture methodology is an area of active research [302, 304, 325].
Within this computational approach for modeling pervasive fracture, there are a
number of possibilities for controlling fracture initiation and growth. For example,
at one extreme new fracture surfaces can be restricted to nucleate only at an existing
fracture tip. At the other extreme new fracture surfaces can be allowed to nucleate
at any element face. For quasi-static applications, the approach of only allowing
new fractures to form from existing fracture surfaces seems more realistic. However,
this restriction may be overly restrictive by not allowing new fracture surfaces to
form in front of or near an existing fracture. Allowing fractures surfaces to form in
front of or near an existing fracture would help ameliorate the artiﬁcial toughness
induced by constraining crack growth to predeﬁned surfaces. In eﬀect, a damage
band is formed around the crack front, in analogy to subscale damage mechanisms

Applications of Polyhedral Finite Elements in Solid Mechanics
■193
(b)
(a)
(c)
Figure 11.13 Example showing the generation of a Voronoi tessellation, or mesh,
starting with a random close-packed arrangement of points. (a) Points are randomly
assigned inside the domain with a constraint on minimum distance (red circles). (b)
A Voronoi cell corresponding to the construction deﬁned by (11.8) and a subset of
points. (c) A three-dimensional example. The domain boundaries are reproduced by
reﬂecting interior points about the domain boundary. (Reproduced with permission
from [48].)
in the material. In the simulations presented here, fracture initiation and growth
are allowed at any facet at any time during the simulation.
11.5.2
Random Voronoi meshes
Voronoi tessellations, or tilings, have a rich history in mathematics and science and
have a number of interesting properties [295]. Given a ﬁnite set of points xi (sites),
the Voronoi tessellation is deﬁned as the collection of regions, or cells, Vi where
Vi =
\
i̸=j
{x ∈Ω| d(xi, x) < d(xj, x)}.
(11.8)
Here, Ωrepresents the given domain, and the function d(x, y) is the Euclidean
metric (distance) between the two points x and y. Each spatial point belonging to
the Voronoi cell Vi is closer to site i than all other sites j ̸= i. Each Voronoi cell is the
intersection of a collection of half-spaces, and therefore forms a convex polyhedron.
An example of a two-dimensional Voronoi cell is shown in Figure 11.13(b). An
example of a three-dimensional Voronoi tessellation is shown in Figure 11.13(c).
While the Voronoi tessellation can be formed from any ﬁnite set of points, a spe-
cial structure arises from the close packing of equi-sized hard spheres [431]. A classic
experiment of dropping hard spheres into a relatively large container produces a
structure known as random close packed (RCP). The face-centered cubic (FCC)
structure possesses an optimal packing factor of 0.740, whereas the RCP struc-
ture exhibits a maximum packing factor of 0.637. An example of a two-dimensional
random close-packing is shown in Figure 11.13(a). The statistical geometry as-
pects of RCP structures and their associated Voronoi diagrams have been studied

194
■Generalized Barycentric Coordinates in Graphics and Mechanics
by Finney [142]. For the RCP structure, the average aspect ratio of each Voronoi
cell is approximately one. Each junction or node of the RCP Voronoi structure is
randomly oriented with only a short range correlation to neighboring nodes. The
three-dimensional Voronoi tessellation shown in Figures 11.6(a) and 11.13(c) result
from an RCP point distribution.
A common method for generating the RCP points is based on a variant of a
Poisson process and is known as random sequential adsorption, or maximal Poisson
sampling (MPS). In this approach, points are randomly and sequentially placed
in a domain with a constraint on minimum distance between points [60]. The con-
straint on distance between points is enforced by merely discarding those new points
that violate the constraint. The seeding process stops when the maximum packing
threshold is reached within tolerance. This approach to generating the RCP seeding
can be ineﬃcient, and does not have a quantiﬁable stopping time. Recently, a very
eﬃcient MPS method has been proposed with a ﬁnite stopping time [135].
In practice, the Voronoi tessellation can contain numerous relatively small edges
that are inappropriate for ﬁnite element analysis, in particular for explicit-dynamics
time integration. The Voronoi mesh can be regularized for ﬁnite element compu-
tation by simply deleting those edges whose size is below a relative tolerance. In
three dimensions, this edge-collapse operation will produce non-planar faces, and
may give tangled polyhedra if the regularization is too aggressive.
11.5.3
Fragmentation
To illustrate the fracture methodology, two fragmentation examples are presented:
(1) a rigid sphere impacting a quasi-brittle beam, and (2) a three-dimensional quasi-
brittle beam impacting a rigid surface at an oblique angle. These examples illustrate
the dynamically evolving fracture network as well as the self-contact capability
required for this class of problems. The Mohr–Coulomb fracture initiation model,
the cohesive traction-separation model, and material properties used in [46] are
also used in these examples. The cohesive model is representative of a quasi-brittle
material with a relatively large crack-tip cohesive-zone size. For a fracture-initiation
criterion, the stress ﬁeld is ﬁrst interpolated to each facet using a volume-weighted
average of the stress in the two attached elements. The traction vector on the facet
is then used to assess the fracture criterion.
Figure 11.14 shows the simulation of a rigid sphere impacting a quasi-brittle
beam. The sphere has a diameter of 100 mm, a velocity of 100 m/s, and has the den-
sity of steel (7800 kg/m3). The beam has dimensions 100 mm ×100 mm ×1000 mm.
The RCP Voronoi mesh is similar to the one shown in Figure 11.6(a). The simu-
lation shows fragmentation under the impact location along with bending-induced
fractures away from the impact location.
Figure 11.15 shows the simulation of a quasi-brittle beam of dimensions
100 mm × 100 mm × 500 mm impacting a rigid surface at an angle of 45 degrees
with a striking velocity of 70.7 m/s normal to the rigid plane. The RCP Voronoi
mesh shown in Figure 11.6(a) was used in the simulation. The deformed state is
shown at three instances in time. The initial fractures initiate from the beam sur-

Applications of Polyhedral Finite Elements in Solid Mechanics
■195
Figure 11.14 Pervasive-fracture simulation of a rigid sphere impacting a quasi-brittle
beam. The Voronoi mesh used here is similar to the one shown in Figure 11.6(a).
t = 1.0 ms
(a)
(b)
(c)
t = 0.4 ms
t = 0.2 ms
Figure 11.15 Pervasive-fracture simulation of a quasi-brittle beam impacting a rigid
surface at an oblique angle. The fracture growth at various times is shown: (a)
t = 0.2 ms, (a) t = 0.4 ms, (a) t = 1.0 ms. The Voronoi mesh shown in Figure 11.6(a)
was used in the simulation.
face near the mid-section and then grow and coalesce into numerous fragments.
This simulation shows the need for an eﬃcient and robust fracture algorithm.
11.6
SUMMARY AND OUTLOOK
In this chapter, we discussed several applications of polyhedral ﬁnite elements in
solid mechanics. These included rapid meshing of geometrically complex structures
and pervasive-fracture modeling using random close-packed Voronoi meshes. Each
of these applications requires a ﬁnite element formulation that can handle non-
convex polyhedra and polyhedra with warped faces. A displacement-based ﬁnite
element formulation based on the use of harmonic shape functions, a type of gen-
eralized barycentric coordinate, was reviewed for use in these applications.
With continuing research into polyhedral meshing tools and ﬁnite element for-
mulations, the use of polyhedral ﬁnite elements is expected to become commonplace

196
■Generalized Barycentric Coordinates in Graphics and Mechanics
in industrial structural analysis. The development of novel discretization techniques
for exploiting the versatility of polyhedral elements, e.g., cut-cell methods, will en-
able a rapid design-to-analysis paradigm that has heretofore been unobtainable.
A primary challenge in the presented approach for modeling pervasive fracture
is the deﬁnition and veriﬁcation of convergence with mesh reﬁnement. One possible
approach for achieving convergence with mesh reﬁnement is to adopt a probabilis-
tic or distributional view of convergence. This is consistent with the use of a ran-
dom mesh, a random heterogeneous material, and the fact that pervasive fracture
phenomena are inherently sensitive to initial conditions. Each pervasive-fracture
simulation provides one realization, and the results of several simulations provide
a sampling for approximating the true distribution of engineering quantities-of-
interest such as fracture paths or fragment volumes. The concept of convergence in
distribution has been used by the author to measure convergence in neck spacing
of thin ductile rings with random material properties [50].

C H A P T E R 12
Extremely Large
Deformation with
Polygonal and Polyhedral
Elements∗
Glaucio H. Paulino, Heng Chi
Georgia Institute of Technology, Atlanta, USA
Cameron Talischi
McKinsey & Company, Chicago, USA
Oscar Lopez-Pamies
University of Illinois at Urbana-Champaign, USA
CONTENTS
12.1
Introduction ......................................................
198
12.2
Finite Elasticity Formulations ...................................
200
12.2.1 Displacement-based formulation .........................
201
12.2.2 A general two-ﬁeld mixed variational formulation .......
201
12.3
Polygonal and Polyhedral Approximations ......................
203
12.3.1 Displacement space on polygons in 2D ..................
203
12.3.2 Displacement space on polyhedra in 3D .................
204
12.3.3 Pressure space on polygons in 2D .......................
204
12.4
Quadrature Rules and Accuracy Requirements ..................
205
12.5
Gradient Correction Scheme and Its Properties .................
208
12.5.1 Gradient correction for scalar problems .................
208
12.5.2 Gradient correction for vectorial problems ..............
212
12.6
Conforming Galerkin Approximations ...........................
213
∗Research support from the U.S. National Science Foundation through grant CMMI #1624232
(formerly #1437535) is gratefully acknowledged. The information presented in this chapter is the
sole opinion of the authors and does not necessarily reﬂect the views of the sponsoring agency.
197

198
■Generalized Barycentric Coordinates in Graphics and Mechanics
12.7
Numerical Examples .............................................
214
12.7.1 Displacement-based polygonal and polyhedral elements .
214
12.7.2 Two-ﬁeld mixed polygonal elements .....................
217
12.8
Application to the study of ﬁlled elastomers ....................
221
12.8.1 Results for ﬁlled neo-Hookean elastomers ...............
222
12.8.2 Results for a ﬁlled silicone elastomer ....................
223
S
oft organic materials are of great engineering interest, but challenging to model
with standard ﬁnite elements. The challenges arise primarily because their non-
linear elastic response is characterized by non-convex stored-energy functions, they
are incompressible or nearly incompressible, and oftentimes possess complex mi-
crostructures. Recently, polygonal ﬁnite elements have been found to possess sev-
eral advantages over standard ﬁnite elements when studying the mechanics of such
materials under ﬁnite deformations. This chapter summarizes a new approach, us-
ing polygonal and polyhedral elements in nonlinear elasticity problems involving
extremely large and heterogeneous deformations. We present both displacement-
based and two-ﬁeld mixed variational principles for ﬁnite elasticity, together with
the corresponding lower- and higher-order polygonal and polyhedral ﬁnite element
approximations. We also utilize a gradient correction scheme that adds minimal
perturbations to the gradient ﬁeld at the element level in order to restore polyno-
mial consistency and recover (expected) optimal convergence rates when the weak
form integrals are evaluated using quadrature rules. With the gradient correction
scheme, optimal convergence of the numerical solutions for displacement-based and
mixed formulations with both lower- and higher-order displacement interpolants is
conﬁrmed by numerical studies of several boundary-value problems in ﬁnite elastic-
ity. For demonstration purposes, we deploy the proposed polygonal discretization
to study the nonlinear elastic response of rubber ﬁlled with random distributions
of rigid particles considering interphasial eﬀects. These physically motivated exam-
ples illustrate the potential of polygonal ﬁnite elements to simulate the nonlinear
elastic response of soft organic materials with complex microstructures under ﬁnite
deformations.
12.1
INTRODUCTION
Many organic materials are characterized by their ability to undergo large reversible
deformations in response to a variety of stimuli, including mechanical forces, electric
and magnetic ﬁelds, and temperature changes. While they have long been utilized
in numerous engineering applications, modern advances in material science have
demonstrated that soft organic materials, such as electro- and magneto-active elas-
tomers, gels, and shape-memory polymers, hold tremendous potential to enable new
technologies, and in particular, the new generation of sensors and actuators. From
a mechanical perspective, although most of these materials can be approximated
“simply” as nonlinear elastic, they more often than not contain highly heteroge-

Extremely Large Deformation with Polygonal and Polyhedral Elements
■199
neous, complex microstructures. The heterogeneity of the microstructures makes
the underlying local deformations inherently complex.
Computational microscopic studies of nonlinear elastic materials, especially
those with complex microstructures, help in gaining a quantitative understand-
ing of the complex behavior of these materials. These studies are also essential in
guiding the optimization of nonlinear elastic materials, so that they can enable
new technological applications. It has long been recognized that standard ﬁnite el-
ements, especially simplicial (triangular and tetrahedral) ﬁnite elements, are inade-
quate in simulating processes involving realistic, large deformations—an example is
shown in Figure 12.1. By contrast, recent studies have demonstrated that polygo-
nal elements possess signiﬁcant potential in the study of nonlinear elastic materials
under ﬁnite deformations. First, these elements are well-suited to model complex
microstructures (e.g., particulate microstructures and microstructures involving dif-
ferent length scales) and to seamlessly incorporate periodic boundary conditions.
Secondly, polygonal elements are found to be more tolerant to large localized defor-
mations and to produce more accurate results in bending and shear than standard
ﬁnite elements. With mixed formulations, lower-order mixed polygonal elements
are also shown to be numerically stable on Voronoi-type meshes without the need
for any additional stablization terms. Likewise, numerical stability of the polygonal
ﬁnite elements is also demonstrated in topology optimization [160, 389, 392] and in
ﬂuid mechanics [394] problems.
One major challenge in the polygonal ﬁnite method is accurate numerical inte-
gration of the weak-form integrals. The ﬁnite element space for polygonal elements
contains non-polynomial (e.g., rational) functions, and therefore, the use of exist-
ing quadrature schemes, typically designed for integration of polynomial functions,
leads to non-vanishing consistency errors [268, 388] and consequently, sub-optimal
or even non-convergent ﬁnite element solutions under mesh reﬁnement. In practice,
using a suﬃciently large number of integration points can lower the consistency
error for linear polygonal elements in two dimensions. A triangulation scheme with
three integration points per triangle is shown to be suﬃciently accurate for practical
problems and mesh sizes [99, 388]. However, for higher-order polygonal elements, the
number of integration points for such a scheme can become prohibitively large [100].
This is also the case for polyhedral elements in three dimensions [268, 393]. In practi-
cal applications, as the number of elements increases, the associated computational
cost for a polyhedral discretization can become exorbitant.
Several attempts have been made in the literature to address the issue of numer-
ical quadrature. For example, in the context of scalar diﬀusion problems, inspired
by the virtual element method (VEM) [33, 72, 161], Talischi et al. [388] have pro-
posed a polynomial projection approach to ensure the polynomial consistency of
the bilinear form, and thereby ensure the satisfaction of the patch test and optimal
convergence for both linear and quadratic polygonal elements. A similar approach
was also adopted by Manzini et al. [268] to solve Poisson problems on polyhedral
meshes. However, those approaches require the existence of a bilinear form, and
therefore, extension to general nonlinear problems is non-trivial and is still an open
question. Borrowing the idea of pseudo-derivatives in the meshfree literature [229],

200
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 12.1 An illustration of the limited capability of standard tetrahedral ele-
ments to undergo large deformation. Experimentally, a synthetic rubber ﬁlled with
20% volume fraction of randomly distributed silica particles can be stretched more
than four times its original length (λ = 4) without internal damage under uniaxial
tension [315]. By contrast, a ﬁnite element model, based on standard 10-node hy-
brid elements with linear pressure, is only able to deform to a macroscopic stretch
of λ = 1.5 [174]. See color insert.
Bishop has proposed an approach to correct the derivatives of the shape functions
to enforce the linear consistency property on general polygonal and polyhedral
meshes [46, 47]. With this correction, the linear patch test is passed and optimal
convergence is achieved. Although applicable for general nonlinear scenarios, the
extension to higher-order cases (for example, quadratic polygonal ﬁnite elements)
is not straightforward, More recently, Talischi et al. [393] proposed a general gradi-
ent correction scheme that is applicable to both linear and nonlinear problems on
arbitrary-order polygonal and polyhedral elements. By requiring a minimum order
of accuracy in the numerical quadrature, the correction scheme is shown to restore
optimal convergence for both linear and nonlinear problems [393]. In this chapter,
we apply the gradient correction scheme to polygonal and polyhedral ﬁnite elements
for ﬁnite elasticity problems and demonstrate that the gradient correction scheme
can eﬀectively and eﬃciently render optimally convergent polygonal and polyhedral
ﬁnite element methods.
12.2
FINITE ELASTICITY FORMULATIONS
This section brieﬂy recalls the equations of elastostatics applied to hyperelastic ma-
terials. Two variational formulations are presented: (i) the standard displacement-
based formulation [63, 294, 429], and (ii) a general mixed formulation involving the

Extremely Large Deformation with Polygonal and Polyhedral Elements
■201
displacement ﬁeld and a pressure-like scalar ﬁeld as trial ﬁelds. Throughout this
chapter, we adopt a Lagrangian description of the ﬁelds.
Consider a body in its stress-free, undeformed conﬁguration that occupies an
open domain Ω⊂Rd with boundary ∂Ω. On its boundary, it is subjected to a
prescribed displacement ﬁeld u0 on Γx and traction t (per unit undeformed surface)
on Γt, such that Γx ∪Γt = ∂Ωand Γx ∩Γt = ∅. The body is also assumed to be
subjected to a body-force f (per unit undeformed volume) in Ω. A stored-energy
function W is used to characterize the constitutive behavior of the body, which is
assumed to be an objective function of the deformation gradient F . In terms of W,
the ﬁrst Piola–Kirchhoﬀstress tensor P at each material point x ∈Ωis thus given
by the following relation:
P (x) = ∂W
∂F (x, F ),
which is used as the stress measure of choice in this chapter.
12.2.1
Displacement-based formulation
The well-known principle of minimum potential energy asserts that the equilibrium
displacement ﬁeld u minimizes the potential energy Π among all displacement ﬁelds
that are kinematically admissible:
Π(u) = min
v∈K Π(v),
(12.1)
with
Π(v) =
ˆ
Ω
W(x, F (v)) dx −
ˆ
Ω
f · v dx −
ˆ
Γt t · v ds.
(12.2)
In the above expression, K stands for a suﬃciently large set of displacements such
that v = u0 on Γx.
The weak form of the Euler–Lagrange equations associated with the variational
problem (12.1) reads as follows:
G(v, δv) =
ˆ
Ω
∂W
∂F (x, F (v)) : ∇(δv) dx −
ˆ
Ω
f · δv dx
−
ˆ
Γt t · δv ds = 0
∀δv ∈K0,
(12.3)
where the test displacement ﬁeld δv is the variation of v, and K0 denotes the set
of all the kinematically admissible displacement ﬁelds that vanish on Γx.
12.2.2
A general two-ﬁeld mixed variational formulation
For nonlinear elastic materials that are nearly incompressible, the variational prin-
ciple in (12.1)–(12.2) is known to perform poorly when approximated by stan-
dard ﬁnite element methods [204]. As a standard remedy, mixed variational prin-
ciples that involve not only the deformation, but also a pressure ﬁeld are uti-
lized [17, 75, 87, 90, 99, 188, 362, 385]. Based on the multiplicative splitting of

202
■Generalized Barycentric Coordinates in Graphics and Mechanics
the deformation gradient, the mixed variational formulations are categorized into
two classes, the F -formulation and the F -formulation [99]. In this section, we recall
the F -formulation; for the F -formulation, the reader is referred to [17, 99, 188] and
references therein.
The basic idea is to introduce a function c
W such that W(x, F ) = c
W(x, F , J)
when J = det F , and its partial Legendre transformation,
c
W ∗(x, F , bq) = max
J

bq(J −1) −c
W(x, F , J)
	
.
Provided that c
W is convex in the argument J, the following duality relation holds:
c
W(x, F , J) = max
bq

bq(J −1) −c
W ∗(x, F , bq)
	
.
(12.4)
Direct substitution of relation (12.4) in the principle of minimum potential en-
ergy (12.1)–(12.2) renders the following alternative mixed variational principle:
bΠ(u, bp) = min
v∈K max
bq∈Q
bΠ(v, bq),
(12.5)
with
bΠ(v, bq)
=
ˆ
Ω

−c
W ∗(x, F (v), bq) + bq[det F (v) −1]
	
dx
−
ˆ
Ω
f · v dx −
ˆ
Γt t · v ds.
(12.6)
In the above expression, Q denotes the set of square-integrable scalar functions
and the maximizing scalar ﬁeld bp is directly related to the equilibrium Cauchy
hydrostatic pressure ﬁeld p := tr σ via [99]
p = bp −
1
3 det F
∂c
W ∗
∂F (x, F , bp) : F .
The weak form of the Euler–Lagrange equations associated with the variational
principle (12.5)–(12.6) reads as
Gv(v, bq, δv) =
ˆ
Ω

−∂c
W ∗
∂F (x, F (v), bq) + bq adj
 F T (v)

: ∇(δv) dx
−
ˆ
Ω
f · δv dx −
ˆ
Γt t · δv ds = 0
∀δv ∈K0,
Gbq(v, bq, δbq) =
ˆ
Ω

det F (v) −1 −∂c
W ∗
∂bq (x, F (v), bq)

δbq dx = 0
∀δbq ∈Q,
where the test ﬁeld δbq is the variation of bq, and adj(·) stands for the adjugate
operator.

Extremely Large Deformation with Polygonal and Polyhedral Elements
■203
12.3
POLYGONAL AND POLYHEDRAL APPROXIMATIONS
This section discusses the displacement and pressure spaces for the polygonal and
polyhedral ﬁnite element approximations. In 2D, we present the constructions of
conforming ﬁnite-dimensional displacement and pressure spaces, for both linear and
quadratic polygonal ﬁnite elements. In 3D, we present the construction of linear
displacement ﬁnite element space on convex polyhedra.
12.3.1
Displacement space on polygons in 2D
Let us begin in the 2D setting and consider a general polygon P with n edges and
vertices, v1, . . . , vn, in the undeformed conﬁguration. We use generalized barycen-
tric coordinates as the basis for a linear polygonal ﬁnite element space on P, denoted
by V1(P), with degrees of freedom associated with the vertices of P.
Quite a few barycentric coordinates can be found in the literature [15, 34, 149,
193, 215, 265, 275, 372] (see Chapter 1 for details), among which the mean value
coordinates [144] are adopted in this chapter. The mean value coordinates, denoted
by φ(1)
1 , . . . , φ(1)
n , can be constructed on arbitrary polygons. Contour plots of the
mean value coordinates deﬁned on non-convex polygons are shown in Figure 12.2(a).
A second-order space on P, denoted as V2(P), can be constructed using pairwise
products of the generalized barycentric coordinates [320]. V2(P) is a 2n-dimensional
space having the degrees of freedom at each vertex of P, as well as at the mid-point
of each edge. Its interpolants φ(2)
1 , . . . , φ(2)
2n are expressed as:
φ(2)
i (x) =
n
X
j=1
n
X
l=1
ci
jlφ(1)
j (x)φ(1)
l
(x),
where φ(1)
j
are the mean value coordinates. The coeﬃcients ci
jl are computed such
Figure 12.2 (a) Contour plot of a mean value basis φ(1)
i
over a concave polygon.
(b) Contour plot of quadratic basis φ(2)
i
over a concave polygon associated with a
vertex. (c) Contour plot of quadratic basis φ(2)
i
over a concave polygon associated
with a mid-side node. See color insert.

204
■Generalized Barycentric Coordinates in Graphics and Mechanics
that any quadratic function can be interpolated exactly by φ(2)
i :
q(x) =
n
X
i=1

q(vi)φ(2)
i (x) + q(ˆvi)φ(2)
i+n(x)

∀q ∈P2(E),
and the Kronecker-delta property
φ(2)
i (vj) = φ(2)
i+n(ˆvj) = δij,
φ(2)
i (ˆvj) = φ(2)
i+n(vj) = 0
∀i, j = 1, . . . , n,
is satisﬁed, where ˆvi = (vi + vi+1)/2 denotes the mid-side nodes.
Although the construction above is derived assuming that the polygonal ele-
ments are strictly convex [320], we also ﬁnd that it is valid on concave polygons
when constructed from the mean value coordinates. Basis function plots for a ver-
tex node and a mid-side node of a concave polygon are shown in Figures 12.2(b)
and 12.2(c), respectively.
12.3.2
Displacement space on polyhedra in 3D
Let P ∈R3 be a polyhedron whose boundary consists of planar polygonal faces in
its undeformed conﬁguration with its n vertices located at v1, . . . , vn. As in the 2D
case, one can deﬁne generalized barycentric coordinates φ(1)
1 , . . . , φ(1)
n
as the basis
for a linear polyhedral ﬁnite element space on P using vertex degrees of freedom.
This chapter considers the Wachspress coordinates, as deﬁned in [413] and ana-
lyzed in [147], which are valid for simple polyhedra. This means that the collection
of faces that include v for each i = 1, . . . , n consists of exactly three faces. As before,
we denote by V1(P) = span

φ(1)
1 , . . . , φ(1)
n
	
the ﬁnite element space on P, which
by linear precision of the Wachspress coordinates includes P1(P). We remark that
the gradient correction scheme described later in this chapter is applicable to other
types of coordinates on linear and quadratic polyhedrons as well, though certain
aspects of its implementation and performance in numerical simulations require a
separate examination.
12.3.3
Pressure space on polygons in 2D
Regarding the two-ﬁeld mixed ﬁnite elements, approximation of the additional pres-
sure ﬁeld is needed. This chapter only considers mixed polygonal elements in 2D;
we leave mixed polyhedral elements as a subject for future work. For conforming
approximations of Q, either discontinuous or continuous approximations can be
adopted. For discontinuous approximations, the discrete pressure space QD
h,k−1 can
be deﬁned as:
QD
h,k−1 = {bqh ∈Q : bqh|P ∈Pk−1(P) ∀P ∈Ωh},
where k is the order of the element. As implied by the above deﬁnition, the approx-
imated pressure ﬁeld may be discontinuous across element boundaries. This type

Extremely Large Deformation with Polygonal and Polyhedral Elements
■205
4-gon
5-gon
4-gon
5-gon
 elements
elements
  elements
4-gon
5-gon
(a)
(b)
(c)
Pressure DOF
Displacement DOF
Figure 12.3 Illustration of the degrees of freedom of displacement and pressure ﬁelds
for diﬀerent mixed polygonal elements. (a) M1 −PD
0
elements, (b) M2 −PD
1
elements, and (c) M2 −M1 elements.
of mixed element is similar to the Crouzeix–Raviart (C–R) elements in ﬂuid prob-
lems [110]. For the remainder of this chapter, we adapt the acronyms from [100]
and denote this family of mixed elements as Mk −PD
k−1 elements. Therefore, the
pressure space of the M1 −PD
0
element consists of piecewise constant functions,
which are constant over each element. Similarly, the pressure space of the M2 −PD
1
element contains piecewise linear functions that vary linearly over each element.
Alternatively, a continuous approximation of the pressure space can be deﬁned
in the following manner:
QC
h,k−1 = {bqh ∈C0(Ω) : bqh|P ∈Mk−1(P) ∀P ∈Ωh}.
This class of elements resembles the Taylor-Hood (T–H) elements in ﬂuid prob-
lems [395], and they are henceforth denoted as the Mk −Mk−1 elements (k ≥2).
Here we consider both types of mixed polygonal ﬁnite elements up to quadratic
order. As an illustration, the degrees of freedom (DOFs) of the displacement ﬁeld
and pressure ﬁeld for these mixed polygonal elements are shown in Figure 12.3.
12.4
QUADRATURE RULES AND ACCURACY REQUIREMENTS
On general polygonal and polyhedral elements, generalized barycentric coordinates
are usually non-polynomial functions. As discussed in [100, 388, 393], the evalua-
tion of weak form integrals involving barycentric coordinates and their gradients
by means of available quadrature schemes leads to errors that are persistent under
mesh reﬁnement. In order to control the quadrature errors and restore polynomial

206
■Generalized Barycentric Coordinates in Graphics and Mechanics
consistency, using the gradient correction scheme by Talischi et al. [393] requires the
quadrature schemes that are adopted to respect certain minimal accuracy require-
ments, which are expressed in terms of their polynomial precision. In this section,
we state these requirements for volumetric and surface quadrature rules on a gen-
eral element P and proceed to introduce the numerical quadrature schemes that
are used.
Given a polygonal or polyhedral ﬁnite element P, we denote by
›
P the evaluation
of the volume (area) integral
´
P using quadrature. Similarly, we use
¸
∂P to denote
the numerical evaluation of surface (line) integral
´
∂P . Throughout, we shall assume
that the order k of the ﬁnite element space Vk(P) is ﬁxed.
In the gradient correction scheme by Talischi et al. [393], the volumetric quadra-
ture
›
P is assumed to be exact when the integrand is a polynomial ﬁeld of order
2k −2. This means that the quadrature can exactly integrate constant ﬁelds when
k = 1 and quadratic ﬁelds when k = 2. This requirement guarantees that the
integrals,
ˆ
P
p · ∇q dx,
ˆ
P
q∇· p dx,
are exact when p ∈[Pk−1(P)]d and q ∈Pk(P). Additionally, an implicit assump-
tion is made on the volume quadrature rule that it is suﬃciently rich to eliminate
the appearance of spurious elemental zero-energy modes that can compromise the
stability of the resulting discretization scheme. For instance, for k = 1, a one-point
rule consisting of an integration point at the centroid of E, with the volume |P|
being the weight, satisﬁes the above precision requirement, but leads to spurious
zero-energy modes.
On the other hand, the boundary quadrature
¸
∂P is required to integrate poly-
nomial ﬁelds of order 2k −1 on each edge/face of the element. Therefore, 1-point
(k = 1) and 2-point (k = 2) quadrature suﬃces for piecewise linear and cubic ﬁelds,
respectively. This requirement ensures that integrals of the form
ˆ
∂P
q(p · n)ds
are exact if p ∈[Pk−1(P)]d and q are piecewise k-th order polynomials on ∂P
with n being the unit normal vector to the boundary. For 2D elements, because
the functions in Vk(P) have k-th order polynomial variation on ∂P, the assumed
accuracy ensures exact integration:
˛
∂P
v(p · n) ds =
ˆ
∂P
v(p · n) ds,
for any v ∈Vk(P) and p ∈[Pk−1(P)]d.
We next describe the quadrature schemes that are used in the numerical stud-
ies. For the 2D case, we adopt a triangulation scheme that divides each polygonal
element into triangles by connecting the centroid to each vertex and apply the
Dunavant rules [131] in each subdivided triangle. According to the above-stated

Extremely Large Deformation with Polygonal and Polyhedral Elements
■207
(a)
(b)
(c)
Figure 12.4 Illustration of the “triangulation” scheme for general polygons in the
physical domain. (a) 1st order triangulation scheme, (b) 2nd order triangulation
scheme, and (c) 3rd order triangulation scheme.
requirements, instead of using a one-point rule, the 1st order triangulation scheme
with one integration point per subdivided triangle is used for linear elements to
avoid spurious energy modes. For quadratic elements, the 2nd order triangulation
scheme is employed, which contains three integration points per subdivided triangle.
Furthermore, the 3rd order triangulation scheme is also used to investigate the eﬀect
of increasing integration orders on the accuracy of the results in the gradient cor-
rection scheme. Illustrations of these schemes are shown in Figure 12.4(a)–12.4(c).
As a side note, the triangulation scheme requires polygonal elements to be star-
convex with respect to their centroids, which is indeed the case for all the examples
presented here. Other quadrature schemes can also be utilized in conjunction with
the gradient correction scheme, such as those speciﬁcally designed for integrating
polynomial functions over arbitrary polygonal domains [102, 285, 286], as long as
they satisfy the requirements stated in this section.
For volumetric integration in the 3D case, one possibility is to split the element
into tetrahedra and use the available quadrature schemes on these subdomains. A
more economical alternative for the linear polyhedron that satisﬁes the polynomial
precision requirement is proposed in [322] and utilized in [47, 393]. This scheme,
which is illustrated in Figure 12.5, can exactly integrate constant and linear ﬁelds.
Additional options are noted in [102], which is designed for general polyhedral
domains.
Regarding the boundary quadrature, the one-dimensional Gauss–Lobatto
quadrature rule is adopted in 2D, which uses two integration points per edge for
linear elements and three integration points per edge for quadratic elements. As for
the boundary quadrature in 3D, the integration on each face is carried out by means
of a vertex quadrature rule that requires only the evaluation of the integrand at the
vertices of the face. The face is split into quadrilateral regions associated with its
vertices by connecting the centroid to the midpoint of the edges of the faces. The

208
■Generalized Barycentric Coordinates in Graphics and Mechanics
x
x
x
x
v
v
v
v
x
x
x
P
xP
xP
xP
Figure 12.5 Illustration of the volumetric integration rule used for 3D linear poly-
hedrals. The weight associated with vertex vi is the volume of the dark gray poly-
hedron formed by pyramids associated with the faces connected to vi. The pyramid
associated with a face F j
i is formed by the centroid of the element xP , centroid of
the face xF j
i , and the midpoint of the edges of F j
i connected to vi. This ﬁgure is
taken from [393].
quadrature weights are the areas of these quadrilateral regions. It can be shown
that this scheme is exact for integration of linear ﬁelds (see Appendix of [268]).
12.5
GRADIENT CORRECTION SCHEME AND ITS PROPERTIES
In this section, the gradient correction scheme by Talischi et al. [393] is presented.
First, we review the scheme for scalar problems and then show its extension to
vectorial problems.
12.5.1
Gradient correction for scalar problems
Given an element P, the basic idea of the gradient correction scheme is to correct
the gradient of functions in the local space Vk(P) with minimal perturbations that
result in the satisfaction of a discrete divergence theorem. For scalar problems, the
corrected gradient of v ∈Vk(P), henceforth denoted by ∇P,kv, is taken to be a
vector ﬁeld over P that solves the optimization problem
min
ξ
“
P
∥ξ −∇v∥2 dx,
(12.7)
subject to
“
P
p · ξ dx = −
“
P
v∇· p dx +
˛
∂P
v(p · n) ds
∀p ∈[Pk−1(P)]d.
(12.8)
The above constrained minimization is carried out over all suﬃciently smooth vector
ﬁelds on P such that the utilized quadrature makes sense. The corrected gradient
∇P,kv = [(∇P,kv)x, (∇P,kv)y]T in 2D
∇P,kv = [(∇P,kv)x, (∇P,kv)y, (∇P,kv)z]T in 3D

Extremely Large Deformation with Polygonal and Polyhedral Elements
■209
is thus the “closest”† ﬁeld to ∇v = [(∇v)x, (∇v)y]T (or ∇v = [(∇v)x, (∇v)y, (∇v)z]T
in 3D) that satisﬁes the discrete divergence theorem against all polynomials of or-
der k.
To assist the formal deﬁnition of the gradient correction scheme for scalar prob-
lems, we consider a basis {ζ1, . . . , ζn} for [Pk−1(P)]d and replace the equality con-
straint (12.8) by the equivalent set of constraints:
“
P
ζa · ξ dx = −
“
P
v∇· ζa dx +
˛
∂P
v(ζa · n) ds,
a = 1, . . . , n
Introducing multipliers λ1, . . . , λn, one obtains the Lagrangian:
L(ξ, λ1, . . . , λn) =
“
P
∥ξ −∇v∥2 dx
+
n
X
a=1
λa
“
P
ζa · ξ dx +
“
P
v∇· ζa dx −
˛
∂P
v(ζa · n) ds

.
The optimality of ∇P,kv requires that for any variation η,
DξL(∇P,kv, λ1, . . . , λn)[η] = 2
“
P
(∇P,kv −∇v) · η dx +
n
X
a=1
λa
“
P
ζa · η dx = 0,
and therefore
“
P
 
∇P,kv −∇v +
n
X
a=1
1
2λaζa
!
· η dx = 0.
This shows that the perturbation ∇P,kv −∇v coincides with an element of
[Pk−1(P)]d at the location of the quadrature points, because the optimization prob-
lem (12.7)–(12.8) can only prescribe the values of ∇P,kv at the quadrature points.
Therefore, we can oﬃcially deﬁne the corrected gradient ∇P,kv as the ﬁeld satisfying
the following two conditions:
• ∇P,kv −∇v ∈[Pk−1(P)]d.
• For all p ∈[Pk−1(P)]d,
“
P
p · ∇P,kv dx = −
“
P
v∇· p dx +
˛
∂P
v(p · n) ds.
(12.9)
We observe from these two conditions that ∇P,k is a linear map, and so in practice
only the action of ∇P,k on the basis of Vk(P) must be computed. Here, we present
the details on a systematic procedure for computing the corrected gradient of the
basis functions for arbitrary k. We denote {φ(k)
1 , · · · , φ(k)
nV} as the basis for Vk(P),
†The distance here is with respect to the quadrature form of the L2-metric.

210
■Generalized Barycentric Coordinates in Graphics and Mechanics
where nV is the dimension of the space Vk(P). Our goal is to ﬁnd a coeﬃcient
matrix S such that
∇P,kφ(k)
i
= ∇φ(k)
i
+
nP
X
a=1
Siaζa
∀i = 1, . . . , nV.
To explicitly compute S, we further deﬁne matrices R of size nV × nP, and M of
size nP × nP with the following forms:
Ria =
˛
∂P
(ζa · n)φ(k)
i
ds −
“
P
φ(k)
i
∇· ζa dx −
“
P
ζa · ∇φ(k)
i
dx,
and
Mab =
“
∂P
ζa · ζb dx.
Replacing v and p with φk
i and ζb in (12.9) yields the linear system of equations
nP
X
a=1
SiaMab = Rib
∀i = 1, . . . , nV
and
b = 1, . . . , nP.
Therefore, the coeﬃcient matrix is obtained as S = RM −1.
In order to better understand the gradient correction scheme, let us denote by
pv the perturbation to ∇v that gives the corrected gradients, that is,
∇P,kv = ∇v + pv.
Inserting the above in (12.9), we get for any p ∈[Pk−1(P)]d,
“
P
p · pv dx =

−
“
P
v∇· p dx +
˛
∂P
v(p · n)ds

−
“
P
p · ∇v dx.
(12.10)
Several observations can be made. First, the integral on the left-hand side of the
above equation is exactly computed by the utilized quadrature (recall that we re-
quire the quadrature to be exact for polynomial functions up to order 2k −2).
Second, notice the right-hand side of the above expression represents the diﬀerence
of the two quadrature approximations (the two quadrature approximations are the
terms in the bracket and the last term, respectively) of
´
P p · ∇v dx. Therefore,
(12.10) shows that the perturbations pv capture the diﬀerence between two ap-
proximations of ∇v when integrated against polynomials of order k −1. pv is, in
fact, the “smallest” element in [Pk−1(P)]d with respect to the L2-norm that does
so according to (12.7)–(12.8). Third, the smaller the error in the satisfaction of
the discrete divergence theorem
 i.e., right-hand side of (12.10)

, the smaller the
perturbation is to the gradient. This error depends on the accuracy of quadrature
as well as the nature of the functions in the local space Vk(P). Last but not least,

Extremely Large Deformation with Polygonal and Polyhedral Elements
■211
by setting p = ∇P,kq −∇q = pq in (12.10), we have
ˆ
P
(∇P,kq −∇q)2dx = −
“
P
q∇· pq dx +
˛
∂P
q(pq · n) ds −
“
P
pq · ∇q dx
= −
ˆ
P
q∇· pq dx +
ˆ
∂P
q(pq · n) ds −
ˆ
P
pq · ∇q dx
= 0,
which implies that the corrected gradient coincides with the exact gradient when
applied to k-th order polynomials, i.e.,
∇P,kq = ∇q
∀q ∈Pk(P).
(12.11)
This property of the correction scheme plays an important role in ensuring that the
resulting discretizations are polynomially consistent and satisfy the patch test.
To aid in better understanding (12.11), we consider the case with linear space
V1(P), where an explicit expression for the corrected gradient can be readily ob-
tained. Let p ∈[P0(P)]d and v ∈V1(P). We arrive at the following expression for
the corrected gradient:
∇P,1v = ∇v + 1
|P|
˛
∂P
vn ds −
“
P
∇v dx

,
which is similar to the corrected strain operator in the meshfree literature [296]. We
can see from this expression that the perturbation is a constant ﬁeld proportional
to the error in satisfying the identity
´
P ∇v dx =
´
∂P vn ds by the volumetric
and surface quadrature schemes. This implies that if v ∈P1(P), then there is no
correction to its gradient, i.e., ∇P,1v = ∇v. Additionally, in the 2D case, recall that
the variation of v on ∂P is piecewise linear, and the boundary quadrature is exact.
In this case,
¸
∂P vn ds =
´
∂P vn ds =
´
P ∇v dx, and subsequently
∇P,1v = ∇v + 1
|P|
ˆ
P
∇v dx −
“
P
∇v dx

.
(12.12)
The perturbation is simply the diﬀerence between the volume average of ∇v and its
approximations through the quadrature. An immediate observation from (12.12) is
that
“
P
∇P,1v dx =
ˆ
P
∇v dx.
This shows that the corrected gradient ∇P,1v under the action of the quadrature
behaves like ∇v under exact integration.
Generally, it is expected from the deﬁnition of the correction that
“
P
ψ · ∇P,kv dx −
ˆ
P
ψ · ∇v dx = O(hk
P )∥∇v∥L2(P )d
for v ∈Vk(P) when ψ is a suﬃciently smooth vector ﬁeld. Here, hP is the diameter
of element P.

212
■Generalized Barycentric Coordinates in Graphics and Mechanics
12.5.2
Gradient correction for vectorial problems
The gradient correction scheme deﬁned in the preceding subsection for scalar prob-
lems can be readily extended to vectorial problems. For a vector ﬁeld v = [vx, vy]T
(or v = [vx, vy, vz]T in 3D) ∈[Vk(P)]d, the gradient correction scheme takes the
form
∇P,k ⊗v =
(∇P,kvx)T
(∇P,kvy)T

in 2D,
∇P,k ⊗v =


(∇P,kvx)T
(∇P,kvy)T
(∇P,kvz)T

in 3D.
Similar to the scalar case, the corrected gradient satisﬁes the discrete divergence
theorem,
“
P
p : ∇P,k ⊗v dx =
ˆ
∂E
(p · n) · v ds −
“
P
v · (∇· p) dx
∀p ∈[Pk−1(P)]d×d,
and, moreover, for any suﬃciently smooth second-order tensorial ﬁeld ψ, the
element-level consistency error satisﬁes
“
P
ψ : ∇P,k ⊗v dx −
ˆ
P
ψ : ∇v dx = O(hk
P )∥∇v∥L2(P )d.
In the computational implementation of 2D problems, let us assume the set of
basis functions

φ(k)
1 , . . . , φ(k)
2nV
	
of

Vk(P)
2 are of the form
φ(k)
2i−1 =

φ(k)
i
, 0
T ,
φ(k)
2i =

0, φ(k)
i
T
for i = 1, . . . , nV, and where nV is the dimension of the space Vk(P). The correction
scheme for vectorial problems in practice amounts to correcting each basis function
as follows:
∇P,k ⊗φ(k)
2i−1 =
 ∇P,kφ(k)
i
T
0

,
∇P,k ⊗φ(k)
2i =

0
 ∇P,kφ(k)
i
T

for i = 1, . . . , nV, and where ∇P,kφ(k)
i
is the computed corrected gradient of the
shape function according to the procedure outlined for the scalar problem.
Similarly, let us assume the set of basis functions for

φ(k)
1 , . . . , φ(k)
3nV
	
of the
3D space

Vk(P)
3 are of the form
φ(k)
3i−3 =

φ(k)
i
, 0, 0
T ,
φ(k)
3i−1 =

0, φ(k)
i
, 0
T ,
and
φ(k)
3i =

0, 0, φ(k)
i
T
for i = 1, . . . , nV. The gradient correction scheme for 3D vectorial problems corrects
each basis function as
∇P,k ⊗φ(k)
3i−2 =


 ∇P,kφ(k)
i
T
0
0

,
∇P,k ⊗φ(k)
3i−1 =


0
 ∇P,kφ(k)
i
T
0

,
∇P,k ⊗φ(k)
3i =


0
0
 ∇P,kφ(k)
i
T


(i = 1, . . . , nV).

Extremely Large Deformation with Polygonal and Polyhedral Elements
■213
12.6
CONFORMING GALERKIN APPROXIMATIONS
Consider Ωh to be a ﬁnite element decomposition of the domain Ωinto non-
overlapping polygons or polyhedra, where h is the average element size. The bound-
ary of the mesh, denoted as Γh, is assumed to be compatible with the applied
boundary condition. In other words, Γt
h and Γx
h are both unions of edges of the
mesh.
We deﬁne the numerical integration
›
Ωh on Ωh as the summation of the con-
tributions from numerical integrals
›
P from each element P following the stan-
dard assembly rule, namely,
›
Ωh = P
P ∈Ωh
›
P , and
¸
Γt
h as the numerical integra-
tion on Γt
h. Similarly, we deﬁne the gradient correction map on the global level,
∇h,k : Kh,k →[L2(Ωh)]
d×d, such that it coincides with the gradient correction map
∇P,k at the element level,
(∇h,kvh)|P = ∇P,k ⊗(vh|P )
∀P ∈Ωh
and
vh ∈Kh,k.
The Galerkin approximation of the displacement-based formulation then con-
sists of ﬁnding uh ∈Kh,k, such that
Gh(uh, δvh) = 0
∀δvh ∈K0
h,k,
where K0
h,k = Kh,k
T K0 and Gh(uh, δvh) is the discretization and quadrature eval-
uation of G(u, δv) in (12.3) with the exact gradient operator ∇replaced by ∇h,k,
which takes the form
Gh(uh, δvh) =
“
Ωh
∂W
∂F (x, I + ∇h,kuh) : ∇h,k(δvh) dx
−
“
Ωh
fh · δvh dx −
˛
Γt
h
th · δvh ds,
(12.13)
and terms fh and th are the approximated body force and boundary traction,
respectively.
For the two-ﬁeld mixed formulation, if we introduce the additional ﬁnite ele-
ment space QD
h,k−1(or QC
h,k−1)⊆Q, the Galerkin approximation consists of ﬁnding
(uh, bph) ∈Kh,k × QD
h,k−1(or QC
h,k−1), such that
Gv
h(uh, bph, δvh) = 0
∀δvh ∈K0
h,k,
Gbq
h(uh, bph, δbqh) = 0
∀δbqh ∈QD
h,k−1
(or QC
h,k−1),
with Gv
h(uh, bph, δvh) and Gbq
h(uh, bph, δbqh) being of the form
Gv
h(uh, bph, δvh) =
“
Ωh

−∂c
W ∗
∂F (x, I + ∇h,kuh, bph) + bph adj
 I + (∇h,kuh)T 
: ∇h,k(δvh) dx −
“
Ωh
fh · δvh dx −
˛
Γt
h
th · δvh ds,
(12.14)

214
■Generalized Barycentric Coordinates in Graphics and Mechanics
Gbq
h(uh, bph, δbqh) =
“
Ωh

det(I + ∇h,kuh) −1 −∂c
W ∗
∂bp (x, I + ∇h,kuh, bph)

δbqh dx.
(12.15)
Notice that since we replace the gradient operators ∇in both uh and δvh in
(12.13), (12.14), and (12.15) with ∇h,k, the resulting approximations yield sym-
metric linearizations. Moreover, both of the above ﬁnite element approximations
pass the ﬁrst-order patch test [100]. This means that when the exact displacement
ﬁeld is a linear ﬁeld, the above ﬁnite element approximations give the exact results.
12.7
NUMERICAL EXAMPLES
In this section, we present a series of numerical tests to assess the performance of the
displacement-based and the two-ﬁeld mixed polygonal and polyhedral ﬁnite element
methods. For 2D problems, both displacement-based and mixed polygonal elements
up to the second order are considered, whereas only ﬁrst-order displacement-based
polyhedral elements are studied for the 3D case. We demonstrate, through the
convergence studies of two boundary-value problems, that the gradient correction
scheme is capable of ensuring optimal convergence of polygonal and polyhedral ele-
ments in ﬁnite elasticity. For mixed polygonal elements, we also provide numerical
evaluations and discuss inf-sup stability for diﬀerent choices of pressure approxima-
tions.
Throughout this section, a neo-Hookean material model is considered. For a
compressible neo-Hookean material, the stored-energy function characterizing the
material behavior has the form
W(F ) = µ
2 [F : F −3] −µ(det F −1) + 3κ + µ
6
(det F −1)2,
where µ and κ denote the initial shear and bulk moduli of the material response.
In the limit of incompressibility (κ →∞), the above compressible neo-Hookean
material reduces to the standard neo-Hookean stored-energy function
W(x, F ) =
(µ
2 [F : F −3],
if det F = 1,
+∞,
otherwise.
(12.16)
The standard Newton–Raphson method is employed to solve the nonlinear system
of equations, and we assume that convergence at each loading step is met if the
norm of the residual falls below 10−8 times that of the initial residual.
12.7.1
Displacement-based polygonal and polyhedral elements
This subsection presents a convergence study of the displacement-based polygonal
and polyhedral ﬁnite elements using the gradient correction scheme. In particu-
lar, we consider a boundary-value problem as shown in Figure 12.6(a), where a
rectangular block of dimensions 1 × 1 × π is bent into a semi-circular shape. The
corresponding analytical displacement solution u is given by
ux = −1 + (1 + x) cos(z) −x,
uy = 0,
uz = (1 + x) sin(z) −z,

Extremely Large Deformation with Polygonal and Polyhedral Elements
■215
while the corresponding body force f = [fx, fy, fz]T reads as
fx = −(1 + x) cos(z)(3κ −2µ)
3
,
fy = 0,
fz = −(1 + x) sin(z)(3κ −2µ)
3
.
Throughout, we set the initial shear and bulk moduli µ and κ as 1 and 10, and
consider two error measures, the L2-norm and the H1-seminorm of the displacement
error. More speciﬁcally, the L2-norm and the H1-seminorm, respectively, are given
by
E0,u = ∥u −uh∥
and
E1,u = ∥∇u −∇uh∥,
where the L2-norm, ∥·∥, is evaluated using a ﬁfth order triangulation rule.
Since no deformation occurs in the uy direction, this problem can be simpliﬁed
into a plane strain problem as shown in Figure 12.6(b). We make use of structured
Figure 12.6 (a) An illustration of the 3D boundary-value problem. (b) Associated
simpliﬁed 2D plane strain problem of (a). (c) An example of the extruded structured
hexagonal mesh consists of 120 elements. (d) An example of the extruded CVT mesh
with 40 elements. (e) An example of the 2D structured hexagonal mesh with 28
elements. (f) An example of the 2D CVT mesh with 50 elements.

216
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 12.7 Plots of the error norms against the average mesh size h for structured
hexagonal meshes with (a) linear polygonal elements and (b) quadratic polygonal
elements.
hexagonal meshes to discretize the domain, an example of which is displayed in
Figure 12.6(e). Both linear and quadratic polygonal elements are considered, which
utilize the triangulation scheme with their required minimal order of accuracy (1st
order for linear elements and 2nd order for quadratic element). To investigate the
eﬀect of increasing the integration order on the convergence and accuracy of the
results, we also consider triangulation rules that are one order higher than the
required minimum (2nd and 3rd orders for linear and quadratic elements, respec-
tively). The results of the convergence study are summarized in Figure 12.7(a)
and 12.7(b), respectively, for linear and quadratic polygonal elements. For linear
polygonal elements, it is clear from the ﬁgure that, without the gradient correction,
the 1st triangulation itself is not suﬃcient to ensure optimal convergence. How-
ever, the 2nd order triangulation rule seems suﬃcient to ensure suﬃcient accuracy
and optimal convergence for the range of mesh sizes considered, even without the
gradient correction scheme. We should note, however, that with further reﬁnement
of the mesh, we expect the consistency error to become dominant and the conver-
gence rate to decrease. In contrast, for quadratic elements, both 2nd and 3rd order
triangulation rules are not suﬃcient to ensure the optimal convergence of the ﬁnite
element results without the gradient correction scheme.
When the gradient correction scheme is applied, the optimal convergence in the
ﬁnite element results is recovered for both linear and quadratic polygonal elements
with the triangulation schemes of minimal required orders. We also observe that
the gradient correction scheme allows the use of the minimal required order of
integration to achieve the same level of accuracy as with higher order integrations.
If the gradient correction scheme is used, the displacement errors are identical for
1st and 2nd order triangulation rules for the linear polygonal elements and for 2nd
and 3rd triangulation rules for the quadratic polygonal elements. This indicates

Extremely Large Deformation with Polygonal and Polyhedral Elements
■217
Figure 12.8 Plots of the error norms against the average mesh size h for (a) extruded
structured hexagonal meshes and (b) extruded CVT meshes.
that the gradient corrections scheme can allow for a more eﬃcient ﬁnite element
implementation without sacriﬁcing accuracy.
We also assess convergence for displacement-based polyhedral computations.
To this end, we take the original 3D problem shown in Figure 12.6(a) and con-
sider two types of polyhedral meshes, extruded structured hexagonal meshes and
extruded centroid Voronoi tessellation (CVT) meshes, as shown in Figures 12.6(c)
and 12.6(d), respectively. The convergence results for the displacement error norms
as functions of the average mesh size are depicted in Figure 12.8. Each data point
for the extruded CVT meshes is the mean of a ﬁve-mesh set. Again, the prelim-
inary study indicates that the gradient correction scheme can ensure the optimal
convergence for polyhedral elements.
12.7.2
Two-ﬁeld mixed polygonal elements
In this subsection, together with the gradient correction scheme, the performance
of mixed polygonal elements on inf-sup stability and convergence are numerically
evaluated for the 2D case. In addition to the displacement error norms considered
in the previous subsection, we deﬁne the L2-norm of the pressure error
E0,bp = ∥bph −bp∥,
which is evaluated using a ﬁfth order quadrature scheme.
Inf-sup stability of polygonal discretizations
The satisfaction of the inf-sup stability condition is crucial to guarantee the conver-
gence of mixed ﬁnite elements [58, 235, 293]. For ﬁnite elasticity problems, inf-sup
stability is formally deﬁned by the generalized inf-sup condition [235, 293], which

218
■Generalized Barycentric Coordinates in Graphics and Mechanics
states that a strictly positive and size-independent constant C0 exists such that
βh(uh) =
inf
bqh∈QD or C
h,k−1
sup
vh∈Kh,k
´
Ωbqh adj
 I + (∇uh)T 
: ∇vh dx
∥∇vh∥∥bqh∥
≥C0.
(12.17)
for any admissible displacement ﬁeld uh ∈Kh,k. Because the above generalized
inf-sup condition is deformation dependent and diﬃcult to verify, we only consider
the inf-sup condition in the linear elasticity context,
β0
h =
inf
bqh∈QD or C
h,k−1
sup
vh∈Kh,k
´
Ωbqh∇· vh dx
∥∇vh∥∥bqh∥
≥C0,
(12.18)
which essentially is a special case of (12.17) when uh = 0. This example focuses on
the inf-sup stability of polygonal discretizations in 2D (similar to Figure 12.6(b)). It
is well known that most of the lower order standard mixed ﬁnite elements in 2D are
not inf-sup stable, whereas Beirão da Veiga et al. [30] have derived a geometrical
condition to guarantee the satisfaction of (12.18), if every internal vertex node in
the mesh is connected to no more than three edges. However, the analogous con-
dition for polygonal discretizations with higher order mixed polygonal elements is
still unknown. For 3D problems, even with lower order displacement and piecewise-
constant pressure polyhedral elements, the inf-sup stability of polyhedral meshes
is still an open question and needs further investigation. Here, we adopt the so
called inf-sup test [88] to numerically evaluate the inf-sup stability of the linear
and quadratic polygonal elements on several polygonal discretizations. We remark
that while passing the inf-sup test only constitutes a necessary condition for the
satisfaction of the inf-sup condition, the inf-sup test has been shown to reliably pre-
dict the stability properties of many well-known mixed ﬁnite elements [88, 391]. We
consider a unit square domain with imposed boundary conditions as shown in Fig-
ure 12.9(a) and consider three Voronoi-type discretizations: structured hexagonal
meshes, CVT meshes, and random Voronoi meshes, examples of which are provided
in Figure 12.9(b)–(d). In general, the Voronoi-type discretizations with lower order
elements satisfy the geometrical condition of Beirão da Veiga et al. [30], except for
several limiting special cases such as the one where the Voronoi seeds are aligned
in a Cartesian grid, forming a Cartesian mesh. In the inf-sup test, we compute the
stability index β0
h as a function of the average mesh size h for all the families of dis-
cretizations considered in Figure 12.9(e)–(g). Each point for the CVT and random
Voronoi meshes represents an average from ﬁve results. The ﬁgures indicate that
all three polygonal discretizations are inf-sup stable with both discontinuous and
continuous pressure approximations, at least in the linear elasticity regime. In com-
parison, while the standard linear and quadratic mixed elements with continuous
pressure approximations (the T–H family) are unconditionally stable [58], most of
those with discontinuous pressure approximations (the C-R family), such as lower-
order mixed triangular and quadrilateral elements, are inf-sup unstable [58, 88, 204].

Extremely Large Deformation with Polygonal and Polyhedral Elements
■219
Figure 12.9 (a) Dimensions and boundary conditions adopted for the inf-sup test.
(b) An example of the structured hexagonal dominant mesh with 56 elements.
(c) An example of the randomly generated CVT mesh with 50 elements. (d) An
example of the random Voronoi mesh with 50 elements. (e) Plot of the computed
value of the stability index as a function of the average mesh size h for structured
hexagonal dominant meshes. (f) Plot of the computed value of the stability index
as a function of the average mesh size h for CVT meshes. (g) Plot of the computed
value of the stability index as a function of the average mesh size h for random
Voronoi meshes. This ﬁgure is adapted from [100].
Convergence study
Next we perform a convergence study of the two-ﬁeld mixed elements through
a 2D boundary-value problem, where an incompressible rectangular block with
dimensions 1 × 1 is bent into a semicircle, as illustrated by Figure 12.6(b). The
closed-form displacement and pressure solutions for such a problem read as
ux = −r(−0.5) + r(x) cos(y) −0.5 −x,
uy = r(x) sin(y) −y,
and
bp = 2µ(4x2 −3)x −
√
2
8x2 −4
,

220
■Generalized Barycentric Coordinates in Graphics and Mechanics
where the function r(x) is given by r(x) =
p
2x +
√
2. In order to avoid the de-
velopment of surface instabilities [44] and guarantee the uniqueness of the ﬁnite
element solutions, the displacement boundary condition is prescribed on the left
side of the block as well as the top and bottom of the block, leaving the right side
of the block traction-free. Unlike in the previous subsection, we consider a fam-
ily of CVT meshes, an example of which is shown in Figure 12.6(f), and plot the
convergence results in Figure 12.10(a)–(f) for all three types of mixed polygonal
ﬁnite elements. Each data point in the ﬁgures represents an average of the results
from ﬁve meshes. We observe that optimal convergence in both displacement ﬁeld
and pressure ﬁeld is recovered for both linear and quadratic mixed polygonal ﬁnite
elements when the gradient correction scheme is adopted, as opposed to the case
when no gradient correction scheme is used. Again, an identical level of accuracy in
both the displacement and pressure ﬁelds is achieved with minimal and higher-order
triangulation rules.
Figure 12.10 The displacement errors for the CVT meshes with (a) M1 −PD
0
el-
ements, (b) M2 −PD
1 elements, and (c) M2 −M1 elements. The pressure errors
for the CVT meshes with (d) M1 −PD
0 elements, (e) M2 −PD
1 elements, and (f)
M2 −M1 elements.

Extremely Large Deformation with Polygonal and Polyhedral Elements
■221
12.8
APPLICATION TO THE STUDY OF FILLED ELASTOMERS
Experiments have demonstrated that typical ﬁlled elastomers contain stiﬀ“inter-
phases” or layers of stiﬀ“bound rubber” around their inclusions [236]. The presence
of such interphasial regions can signiﬁcantly aﬀect the macroscopic response of the
ﬁlled elastomer when the ﬁllers are submicron in size [175, 260]. In this section,
the nonlinear elastic response of an incompressible elastomer reinforced with a ran-
dom, isotropic distribution of circular rigid particles, bounded through ﬁnite-size
interphases, is studied by means of polygonal ﬁnite elements. We aim at demon-
strating the ability of polygonal ﬁnite elements to model the complex behavior of
nonlinear elastic materials with extremely large localized deformations. Through-
out this section, we consider each particle to be inﬁnitely rigid and model them
with the variational formulation proposed by Chi et al. [98]. This variational for-
mulation treats the presence of each particle as a set of kinematic constraints on
the displacement DOFs.
We approximate the truly random and isotropic distribution of particles by
the periodic repetition of a unit cell in the e1 and e2 directions. The unit cell
contains a total of 50 monodisperse rigid particles at an area fraction of cp = 25%.
Each particle is bounded to the matrix by an interphase that is ten times stiﬀer
than the matrix and whose thickness is assumed to be 20% of the radius of the
particle, resulting in a total area fraction of ci = 11%. The mixed F -formulation
is employed in this example and polygonal meshes with both linear and quadratic
mixed elements are considered as shown in Figure 12.11(c) and (d). For comparison
purposes, a ﬁnite element mesh with the commonly used 6-node hybrid quadratic
triangular elements (termed CPE6MH) is included, as depicted in Figure 12.11(b).
In order to make a fair comparison, all the meshes are generated such that they
have a similar number of nodes in the matrix phase.
In the following study, we consider periodic boundary conditions [100, 260]
for two loading conditions: (i) pure shear with average deformation gradient
⟨F ⟩= λe1 ⊗e1 + λ−1e2 ⊗e2 and (ii) simple shear with ⟨F ⟩= I + γe1 ⊗e2
where λ ≥1 and γ ≥0 denote the applied stretch and amount of shear, respec-
tively. We remark that the periodicity in the pressure ﬁeld cannot in general be
enforced when employing mixed ﬁnite elements. At any rate, even when we use
the T–H mixed elements where the pressure ﬁeld is continuous, as shown in [100],
the enforcement of periodic pressure boundary conditions only exerts a negligible
inﬂuence on the solution. Moreover, the discontinuities of shear moduli between the
matrix, interphase, and inclusions generate a discontinuous pressure ﬁeld, which,
in general, cannot be captured by mixed elements with continuous approximations
for the pressure ﬁeld, i.e., T–H elements. However, [100] has shown that using T-
H elements (with minor levels of discontinuities (e.g., µi = 10µm) between the
matrix and interphase) can still produce suﬃciently accurate solutions, provided
that the stiﬀinclusions are treated independently using the rigid-body constraint
formulation by Chi et al. [98].

222
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 12.11 (a) The unit cell considered in the problem. (b) The quadratic tri-
angular mesh comprised of 58,814 CPE6MH elements and 118,141 nodes in total,
with 71,179 nodes in the matrix phase. (c) The linear polygonal mesh comprised of
39,738 elements and 76,020 nodes in total, with 66,095 nodes in the matrix phase.
(d) The quadratic polygonal mesh comprised of 20,205 elements and 95,233 nodes
in total, with 67,325 nodes in the matrix phase. This ﬁgure is adapted from [100].
See color insert.
12.8.1
Results for ﬁlled neo-Hookean elastomers
In this subsection, the matrix is assumed to be an incompressible neo-Hookean
material, described by the stored-energy function (12.16). The initial shear modulus
µm of the matrix is taken to be µm = 1 MPa, and that of the interphase is set as
µi = 10 µm = 10 MPa. Figure 12.12(a)–(d) plots the deformed conﬁgurations of
the unit cell obtained by M2 −M1, M2 −PD
1 , M1 −PD
0 , and CPE6MH elements,
at their respective maximum global stretches, λmax = 2.9132, 2.6456, 2.2515 and
1.4308, under loading condition (i). The fringe scales in the deformed conﬁgurations

Extremely Large Deformation with Polygonal and Polyhedral Elements
■223
correspond to the maximum principal stretch of each element (representing the level
of local deformation), with those having a value of 8 or larger plotted in red. The
maximum global and local stretches reached by each mesh are also summarized in
Table 12.1. As an additional quantitative comparison, the relevant components of
the macroscopic ﬁrst Piola–Kirchhoﬀstress ⟨P ⟩as functions of the applied global
stretch λ or shear γ are shown in Figure 12.13(a)–(b) for loading conditions (i)
and (ii). The simulated macroscopic responses are compared with the available
analytical solution in the literature for neo-Hookean elastomers, reinforced with a
random and isotropic distribution of polydisperse circular particles, which considers
the interphasial eﬀect [175, 258].
Several observations and conclusions can be made. First, the macroscopic re-
sponses obtained by all three types of meshes under both loading conditions (i) and
(ii) agree well with the analytical solutions. Second, the results from the polygonal
meshes reach signiﬁcantly larger global deformation states than the ones from the
quadratic triangular mesh. Since the eﬀective volume fraction of the ﬁlled elastomer
considered in this example is high (cp + ci = 36%), resulting in extremely hetero-
geneous and large localized deformation ﬁelds, a remeshing strategy is likely to
be ineﬀective in stretching the triangular mesh farther [284]. Third, the quadratic
polygonal meshes exhibit better performance than linear meshes, as they can reach
larger global deformation states, especially under loading condition (i). Partially,
this is because the quadratic polygonal elements have richer approximating ca-
pabilities, allowing them to better capture the curvatures in the highly stretched
regions (for example, see the region in Figure 12.12). Furthermore, while produc-
ing almost identical macroscopic responses, the quadratic polygonal mesh with the
M2 −M1 element in this example appears to reach a larger global stretch than the
one with M2 −PD
1 elements under loading condition (i) (λmax = 2.91 as compared
to λmax = 2.65).
12.8.2
Results for a ﬁlled silicone elastomer
This subsection studies the large deformation response of a ﬁlled elastomer with
both its matrix and interphase being a typical silicone rubber, characterized by the
Max. global deformation
Max. local deformation
Pure shear
Simple shear
Pure shear
Simple shear
M1 −PD
0 elements
2.9132
1.086
13.8016
6.4693
M2 −PD
1 elements
2.6456
1.091
11.1457
6.6314
M2 −M1 elements
2.2615
1.078
10.2077
6.9639
CPE6MH elements
1.4308
0.622
4.4819
3.6324
Table 12.1 Comparison of maximum global deformation and the maximum local
deformation (maximum principal stretch) in the ﬁnal deformed conﬁgurations ob-
tained by diﬀerent types of elements. Both matrix and interphase are neo-Hookean
materials.

224
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 12.12 For loading condition (i), displaying pure shear with average deforma-
tion gradient ⟨F ⟩= λe1 ⊗e1 + λ−1e2 ⊗e2, λ ≥1, the ﬁgure illustrates the ﬁnal
deformed conﬁguration reached by (a) M2 −M1 elements, (b) M2 −P1 elements,
(c) M1−P0 elements, and (d) CPE6HM elements (solved in ABAQUS). This ﬁgure
is adapted from [100]. See color insert.
following stored-energy function [259]
W(F ) =



31−α1
2α1
µ1[Iα1
1
−3α1] + 31−α2
2α2
µ2[Iα2
1
−3α2],
if det F = 1,
+∞,
otherwise,
with I1 = FijFij, µ1 = 0.032 MPa, µ2 = 0.3 MPa, α1 = 3.837, α2 = 0.559. Thus,
the initial shear modulus of the matrix is µm = µ1 + µ2 = 0.332 MPa, and that
of the interphase is µi = 3.32 MPa. Again, both loading conditions (i) and (ii) are
considered.

Extremely Large Deformation with Polygonal and Polyhedral Elements
■225
Figure 12.13 Plots of the macroscopic Piola–Kirchhoﬀstress function as the applied
stretch/shear for diﬀerent types of elements under (a) pure shear (λ ≥1) and (b)
simple shear.
Figure 12.14(a)–(d) shows the ﬁnal deformed conﬁgurations of the unit cell ob-
tained by M2 −M1, M2 −PD
1 , M1 −PD
0 , and CPE6MH elements under loading
condition (ii) at their respective maximum global deformation states. The color
scale in each conﬁguration corresponds to the maximum principal stretch of each
element, with those having a value of 4 and above plotted in red. The maximum
global and local stretches reached by each mesh are summarized in Table 12.2.
Furthermore, the macroscopic responses predicted by each type of element under
both loading conditions (i) and (ii) are plotted in Figure 12.15(a) and (b) as func-
tions of applied global stretch λ or shear γ. Similar to the preceding subsection,
we conclude that polygonal discretizations (both linear and quadratic elements)
Max. global deformation
Max. local deformation
Pure shear
Simple shear
Pure shear
Simple shear
M1 −PD
0 elements
1.911
1.482
4.256
4.545
M2 −PD
1 elements
2.064
1.548
4.543
4.562
M2 −M1 elements
1.910
1.551
4.257
4.799
CPE6MH elements
1.349
0.595
2.777
2.699
Table 12.2 Comparison of maximum global deformation and the maximum local
deformation (maximum principal stretch) in the ﬁnal deformed conﬁgurations ob-
tained by diﬀerent types of elements. Both matrix and interphase are considered to
be typical silicone rubber.

226
■Generalized Barycentric Coordinates in Graphics and Mechanics
Figure 12.14 For loading condition (ii), displaying ⟨F ⟩= I + γe1 ⊗e2, γ ≥0,
the ﬁgure illustrates the ﬁnal deformed conﬁgurations reached by (a) M2 −M1
elements, (b) M2−PD
1 elements, (c) M1−PD
0 elements, and (d) CPE6HM elements
(solved in ABAQUS). Both matrix and interphase are considered to be typical
silicone rubber. See color insert.

Extremely Large Deformation with Polygonal and Polyhedral Elements
■227
Figure 12.15 Plots of the macroscopic ﬁrst Piola–Kirchhoﬀstress as functions of the
applied stretch/shear for diﬀerent types of elements under (a) pure shear (λ ≥1)
and (b) simple shear. Both matrix and interphase are considered to be typical
silicone rubber.
are capable of reaching much larger stretches at both global and local levels than
quadratic triangle elements under loading conditions (i) and (ii). However, unlike
in the preceding subsection, the quadratic polygonal mesh with M2 −PD
1 elements
reaches a larger global stretch than the one with M2 −M1 elements in terms of
the maximum global stretch/shear reached. This diﬀerence in results indicates that
the comparison of performance of the M2 −PD
1 element and M2 −M1 element
may be problem-dependent.


C H A P T E R 13
Maximum-Entropy
Meshfree Coordinates in
Computational Mechanics
Marino Arroyo
Universitat Politècnica de Catalunya, Barcelona, Spain
CONTENTS
13.1
Introduction ......................................................
230
13.2
Selecting barycentric coordinates through entropy maximization
231
13.3
Introducing locality: local maximum-entropy approximants ....
234
13.4
Further extensions ...............................................
238
13.5
Applications ......................................................
240
13.5.1 High-order partial diﬀerential equations .................
240
13.5.2 Manifold approximation .................................
241
13.6
Outlook ..........................................................
243
C
ONVENTIONAL BARYCENTRIC COORDINATES are deﬁned rela-
tive to vertices deﬁning the boundary of a polytope. Here, we develop barycen-
tric coordinates relative to a cloud of vertices sampling not only the boundary,
but also the interior of a region in Rd, with the objective of using these barycen-
tric coordinates as basis functions to approximate partial diﬀerential equations or
parametrize surfaces. We show that entropy maximization provides a rational way
to deﬁne smooth barycentric coordinates, but for the resulting basis functions to
be localized, and hence lead to sparse matrices in computational mechanics, en-
tropy maximization needs to be biased by a suitable notion of locality. The basis
functions that result from this approach are smooth, reproduce polynomials, are
localized around their corresponding vertex, and their deﬁnition does not rely on
an underlying mesh or grid but rather on less structured neighborhood relations be-
tween vertices. Thus, they can be viewed as meshfree basis functions [159, 245, 380].
229

230
■Generalized Barycentric Coordinates in Graphics and Mechanics
The theory and practical evaluation behind these basis functions is reviewed next,
and selected applications in computational mechanics are presented.
13.1
INTRODUCTION
A standard approach to numerically representing a function u over a domain Ω⊂Rd
is to expand it in terms of a ﬁnite set of basis functions, that is
uh(x) =
n
X
i=1
φi(x)ui,
(13.1)
where φi : ¯Ω→R is the i-th basis function and ui its corresponding coeﬃcient.
Such a representation is the basis of Galerkin methods to solve partial diﬀerential
equations (PDEs), see [204]. Here, rather than choosing a priori the set of basis
functions, such as piecewise polynomials deﬁned over a mesh, we initially leave their
deﬁnition open, and then motivate and make explicit the speciﬁc choices leading to
maximum-entropy meshfree basis functions.
To show convergence of numerical solutions obtained by a Galerkin method to
the exact solution, the basis functions need to satisfy the so-called reproducibility
conditions. These conditions ensure that polynomials up to degree p are exactly
represented by the basis functions. For second-order PDEs such as the heat equation
and the most common systems arising in ﬂuid and solid mechanics, consistency
conditions up to p = 1 are required at all points x ∈Ω, namely
n
X
i=1
φi(x) = 1,
(13.2a)
n
X
i=1
φi(x)vi = x,
(13.2b)
for some vector coeﬃcients vi ∈Rd. If these conditions are met, then any aﬃne
function w(x) = a·x+b, where a is a vector in Rd and · denotes the scalar product,
can be exactly represented in Ωas w(x) = Pn
i=1 φi(x)(a · vi + b).
Interpreting the coeﬃcients vi as the coordinates of points or vertices, we can
naturally associate each basis function to a vertex, and view the set of vertices
V = {v1, v2, . . . , vn} as points sampling the domain Ω. With this interpretation,
we only need to require the basis functions to be non-negative,
φi(x) ≥0
∀x ∈Ω, i = 1, 2, . . . , n
(13.3)
and recall (13.2) to realize that the functions φi(x), i = 1, 2, . . . , n deﬁne a set
of generalized barycentric coordinates relative to V . A diﬀerence with respect to
previous chapters is that now we allow for interior vertices to the domain, and for
multiple vertices along a face of the domain.

Maximum-Entropy Meshfree Coordinates in Computational Mechanics
■231
Figure 13.1 Set of vertices V in two dimensions, along with the convex hull P. See
color insert.
Because generalized barycentric coordinates at x are coeﬃcients of a convex
combination of the vertices resulting in x, see (13.2b), it immediately follows that
such basis functions can only be deﬁned in the convex hull of V , and therefore
Ω⊂conv V . Furthermore, exploiting elementary facts of convex geometry, it is
possible to characterize the behavior of convex approximation schemes of V , that
is, barycentric coordinates deﬁned in the vertex set V , on the boundary of the
polytope P = conv V [15]. In particular, it can be shown that if F denotes a face of
P in the sense of convex geometry (in R3 0-dimensional faces are extreme points,
1-dimensional faces are edges, and 2-dimensional faces are proper faces) and vi /∈F,
then the corresponding basis function φi vanishes on F [15].
Immediate consequences of this fact are that: (1) basis functions of interior ver-
tices (see Figure 13.1) vanish on the boundary of P, (2) basis functions of extreme
points vi of P satisfy the Kronecker-delta property, φi(vj) = δij, and (3) on a given
face F (in Figure 13.1), only the basis functions of vertices lying on F are non-zero
in F. As a result of (3), if we denote by IF the set of indices of nodes lying on F,
then (13.2a,13.2b) become P
i∈IF φi(x) = 1 and P
i∈IF φi(x)vi = x for all x ∈F,
that is, the basis functions of nodes on a face maintain the full approximation prop-
erties on that face. Furthermore, (3) also implies that the basis functions on a face
can be deﬁned without reference to information in the higher-dimensional ambient
space. These properties can be referred to as a weak Kronecker-delta property, which
facilitate the imposition of boundary conditions in the numerical approximation of
PDEs.
13.2
SELECTING BARYCENTRIC COORDINATES THROUGH
ENTROPY MAXIMIZATION
On examining (13.2a) and (13.3), it is clear that for each point x ∈P, the barycen-
tric coordinates {φ1(x), φ2(x), . . . , φn(x)} can be viewed as a discrete probability
distribution for n events. Deﬁning the barycentric coordinates then becomes a prob-
lem of statistical inference. In the absence of additional information and if one tries
to avoid any bias, Laplace’s principle of insuﬃcient reason would suggest selecting

232
■Generalized Barycentric Coordinates in Graphics and Mechanics
φi(x) = 1/n for i = 1, . . . , n. Yet we do have additional information, since (13.2b)
states that the average of the vertex positions is x. How can we incorporate this
piece of information, while making a choice of the probabilities (barycentric coor-
dinates) as unbiased as possible?
One classical answer to this question in information theory is Jaynes’s principle
of maximum entropy [211]. Let us ﬁrst introduce the information entropy associated
to a ﬁnite probability distribution by considering a coin toss. In this case, there are
two events (heads or tails) that for a perfectly balanced coin have equal probabili-
ties, p1 = p2 = 1/2. Instead, we could conceive an extremely unbalanced coin with
probabilities p1 = 0.99, p2 = 0.01. A fundamental question in information theory
is how to quantify the uncertainty of a probability distribution, or in other words,
how to quantify the amount of information gained by realizing a coin toss. It is
obvious that the balanced coin leads to a much more uncertain outcome, whereas,
for the unbalanced one, we will learn very little by throwing it since we know that
the outcome will most likely be heads. It can be shown that a canonical measure
of uncertainty or information is given by the Shannon entropy function,
H(p1, p2, . . . , pn) = −
n
X
i=1
pi log pi,
(13.4)
where the function x log x is extended by continuity at zero, i.e., 0 log 0 = 0. See [223]
for a detailed motivation of this measure of information and its properties. By
evaluating Shannon entropy on the previous two probability distributions, we ﬁnd
that the ﬁrst coin is about 12 times more uncertain than the second one. In fact, it
can be shown that the function in (13.4) is strictly concave with a maximum at the
uniform distribution pi = 1/n, i = 1, 2, . . . , n. This last fact shows that maximizing
the entropy is consistent with Laplace’s principle of insuﬃcient reason.
Let us now introduce Jaynes’s principle using another simple example, that of
a dice with six faces, A1, A2, . . . , A6. Consider the random function that assigns
to a given face its numerical value, f(Ai) = i. For a perfectly balanced dice, the
average of f is P6
i=1 i/6 = 7/2. Suppose, however, that an accurate sample mean is
computed for this quantity after a large number of trials, giving a result of 4. Clearly,
this new piece of information is inconsistent with the uniform probabilities that we
expect for a perfectly balanced dice. We would like to incorporate this information
in the inference of the probabilities p1, p2, . . . , p6 associated to each face of the dice,
but clearly it is not suﬃcient to uniquely determine these probabilities. Jaynes’s
recipe is to consider the most uncertain probability distribution, that is, the one that
maximizes entropy, while being consistent with the known partial information [211].
Mathematically, this statement can be formulated as an optimization program with
constraints
max
p1,...,p6
−
6
X
i=1
pi log pi
subject to
pi ≥0,
6
X
i=1
pi = 1,
6
X
i=1
ipi = 4,

Maximum-Entropy Meshfree Coordinates in Computational Mechanics
■233
where the last constraint encodes the additional information about the system.
The solution to this constrained optimization problem is p1 = 0.103, p2 = 0.123,
p3 = 0.146, p4 = 0.174, p5 = 0.207, and p6 = 0.247, showing that the higher
expected value for f biases the probabilities towards faces with a higher numerical
value.
Going back to the problem of inferring the generalized barycentric coordinates,
it is now clear that application of Jaynes’s principle of maximum entropy leads to
an optimization program at each point x ∈P and is given by
max
φ1,...,φn
−
n
X
i=1
φi log φi
subject to
φi ≥0,
n
X
i=1
φi = 1,
n
X
i=1
φivi = x,
(13.5)
where the dependence on x only enters through the last vectorial constraint. The
solution to the program is the value of the barycentric coordinates selected by
entropy maximization at x, φi(x), i = 1, 2, . . . , n. Because the entropy function is
strictly concave, this program has a unique solution if and only if it is feasible, that
is, whenever x ∈¯P [67]. This method, reviewed in Section 1.2.9, was introduced
in [372] to generate basis functions for polygons.
Figure 13.2 shows the basis functions deﬁned by entropy maximization for a
set of vertices that not only deﬁnes a polygon, but also samples its interior and
its faces. It can be observed that in agreement with the general results for convex
approximation schemes mentioned earlier, the basis function associated to the ex-
treme vertex v1 is 1 at v1, and therefore all other basis functions are zero at this
point. Also in agreement with the general results, the basis function of the interior
vertex v3 vanishes on the boundary of P, and the basis function φ2 does not satisfy
the Kronecker-delta property because v2 is on the boundary but is not an extreme
point. Yet this set of basis functions presents a signiﬁcant disadvantage when used
to approximate functions in general, or solutions of PDEs in particular: the basis
functions are completely nonlocal. The most dramatic case is that of basis functions
of interior nodes, such as φ3, which spread through the entire domain and are as
uniform as allowed by the convex structure of the optimization program. This is
not a desirable feature to approximate functions over P because with such a basis
it is not possible to deﬁne a localized feature, say around vertex vi, and correlate
this feature with the nodal value ui in (13.1). Besides the lack of local resolution,
such a global set of basis functions leads to a dense stiﬀness matrix when used in a
Galerkin method to approximate partial diﬀerential equations [204].
This discussion suggests that in deﬁning the generalized coordinates by mere
entropy maximization, we have been “too unbiased.” We have ignored the funda-
mental requirement of locality, by which the approximation in (13.1) at a given
point x should more strongly depend on coeﬃcients ui associated to vertices close
to x. Local basis functions should concentrate their “mass” in the vicinity of their
associate vertex, where their value should be closer to 1 than, for instance, φ3 in
Figure 13.2.

234
■Generalized Barycentric Coordinates in Graphics and Mechanics
0.08
0
(a)
(d)
(b)
(c)
1
1
1
0
0
0
Figure 13.2 Basis functions selected by entropy maximization for the set of vertices
shown in (a). Selected basis functions for vertices at extreme positions of P (b),
along a face of P (c), and in the interior of P (d).
13.3
INTRODUCING LOCALITY: LOCAL MAXIMUM-ENTROPY
APPROXIMANTS
Clearly, locality and entropy maximization are conﬂicting objectives. For a given
point x, locality implies that only a few basis functions (corresponding to vertices
xi that are closer to x) have values signiﬁcantly larger than 0, while others are close
to 0. In contrast, maximizing entropy delivers φi(x) that are as uniform as possible.
Interestingly, there is another family of generalized barycentric coordinates associ-
ated to V that can be characterized through an optimization program analogous
to that in (13.5): the piecewise linear basis functions associated to the Delaunay
triangulation of V . Indeed, if the vertices in V are in general positions (there are
no d + 1 cospherical vertices in V ), then there is a unique Delaunay triangulation
with vertices V and the solution to the constrained optimization problem
min
φ1,...,φn
n
X
i=1
φi∥x −vi∥2
subject to
φi ≥0,
n
X
i=1
φi = 1,
n
X
i=1
φivi = x,
(13.6)

Maximum-Entropy Meshfree Coordinates in Computational Mechanics
■235
are the barycentric coordinates of the simplex in the d-dimensional Delaunay trian-
gulation where x belongs [314]. Thus, at each point there are at most d+1 non-zero
basis functions. See [15, 314] for a discussion about the situation in which the ver-
tices are not in general positions. Arguably, these are the most local generalized
barycentric coordinates associated to V .
Comparison of (13.5) and (13.6) suggests combining both objective functions to
deﬁne the following optimization problem
min
φ1,...,φn
β
n
X
i=1
φi∥x −vi∥2 +
n
X
i=1
φi log φi
subject to
φi ≥0,
n
X
i=1
φi = 1,
n
X
i=1
φivi = x,
(13.7)
which deﬁnes Pareto optima harmonizing the two conﬂicting objectives: information
theory optimality and locality. Depending on β, or its non-dimensional counterpart
γ = βh2 where h is the typical spacing between vertices, the basis functions will
more closely resemble nonlocal approximants such as those shown in Figure 13.2,
or highly local piecewise aﬃne barycentric coordinates supported on a Delaunay
triangulation. In fact, the locality parameter β, controlling the aspect ratio of the
basis functions, can be deﬁned locally by considering the following objective function
in (13.7)
n
X
i=1
βiφi∥x −vi∥2 +
n
X
i=1
φi log φi,
where βi is the aspect ratio parameter associated to vertex i. We call the set of basis
functions obtained through the optimization program (13.7), φi(x), i = 1, 2, . . . , n,
local maximum-entropy (LME) approximants. Figure 13.3 illustrates the LME ba-
sis functions in one and two dimensions, although the formulation can be imple-
mented in principle in any dimension. The smooth basis functions closely resemble
other meshfree basis functions, such as those generated by the moving least-squares
method [380]. The crucial diﬀerence, however, is that such alternative methods do
not produce in general generalized barycentric coordinates because the basis func-
tions can be negative. The fact that LME functions are non-negative, and thus
convex approximants with a weak Kronecker-delta property, facilitates the imposi-
tion of essential boundary conditions in the numerical solution of PDEs.
Note that while (13.6) is a linear program with a unique solution only when
vertices are in general positions, the one-parameter family of optimization programs
in (13.7) is nonlinear and strictly convex as a result of the entropy function. Thus,
since it is feasible for all x ∈¯P, it has a unique solution. Thus, the entropy functional
regularizes in some sense the linear program in (13.6). In fact, as shown in [15],
entropy regularization leads to a unique well-deﬁned set of generalized Delaunay
barycentric coordinates in the limit β →+∞.
Another important consequence of the entropy functional in (13.7) is the
smoothness of the resulting LME barycentric coordinates, as compared to those
resulting from (13.6). While the Delaunay barycentric coordinates are only C0 in P,

236
■Generalized Barycentric Coordinates in Graphics and Mechanics
0
0.5
1
1.5
2
2.5
3
0
0.2
0.4
0.6
0.8
1
 = [0.6  1.2  1.8  2.4  3  3.6  4.2  4.8  5.4  6]
(a)
(b)
(c)
Figure 13.3 Local maximum-entropy (LME) basis functions. (a) Selected basis func-
tions for a one-dimensional vertex set, with varying non-dimensional aspect ratio
parameter γi = βih2, see main text. (b) Basis functions for an interior node in
a two-dimensional set of vertices and diﬀerent aspect ratio parameters, and (c)
representative basis functions of boundary nodes. See color insert.
since they have discontinuous derivatives along the faces of the Delaunay simplices,
it can be shown using the implicit function theorem that the LME approximants
are C∞in P with respect to x (also with respect to βi).
The LME basis functions have been deﬁned implicitly so far through a con-
vex constrained optimization program with as many unknowns as vertices in V .
Through standard duality methods, however, it is possible to obtain an almost ex-
plicit form of the basis functions. For this, let us ﬁrst deﬁne the partition function
Z(x, λ) =
n
X
i=1
exp

−βi∥x −vi∥2 + λ · (x −vi)

.
(13.8)

Maximum-Entropy Meshfree Coordinates in Computational Mechanics
■237
Then, the LME basis functions can be expressed at any point x ∈P as
φi(x) =
1
Z (x, λ∗(x)) exp

−βi∥x −vi∥2 + λ∗(x) · (x −vi)

.
(13.9)
This expression is not fully explicit because to compute λ∗(x) an unconstrained
optimization must be solved: the minimization of the strictly convex function
log Z(x, λ). It can be observed that the functions can be viewed as the product of a
Gaussian function around vertex vi, a normalizing factor (Z) so that all functions
add up to one, and an exponential factor that depends on the Lagrange multiplier
λ∗enforcing the linear reproducing condition. Examination of (13.9) shows that,
strictly speaking, these basis functions have global support. However, due to the fast
decay of the Gaussian function, for all practical purposes they can be considered as
compactly supported. Furthermore, the sum in calculation of Z in (13.8) eﬀectively
involves only a handful of terms corresponding to vertices in the neighborhood of
x, which makes the evaluation of the basis functions eﬃcient.
We emphasize the dependence of λ∗on position to highlight the fact that at
each evaluation point, an unconstrained nonlinear optimization problem must be
solved. This problem, however, is only d-dimensional, has a unique solution, and
can be eﬃciently solved numerically using Newton’s method. See [15, 279, 335] for
mathematical and computational details, as well as for the explicit expressions to
compute ﬁrst and second spatial derivatives of the basis functions, and see [177] for
the calculation of the gradients of the basis functions on the boundary of P.
We end this section by presenting an alternative method to introduce locality
into the maximum-entropy framework, which in addition provides a means to de-
ﬁne strictly compactly supported basis functions. It is very easy to deﬁne a set
of non-negative smooth basis functions ψi(x) relative to V , localized around the
corresponding vertex, and satisfying only the zeroth-order reproducing condition,
Pn
i=1 ψi(x) = 1. Indeed, consider for instance a scalar, non-negative, and smooth
window function w : [0, +∞) →R, which decays when the argument is large com-
pared to 1 and satisﬁes that all odd derivatives up to k at 0 vanish (to guarantee
that the even extension of w to R is Ck). Then, for a large enough ρ the functions
ψi(x) =
w (∥x −vi∥/ρ)
Pn
j=1 w (∥x −vj∥/ρ)
are clearly non-negative, localized around their corresponding vertex vi with typi-
cal width ρ, smooth, and add up to one. Furthermore if w is compactly supported,
then the functions ψi(x) are also compactly supported. Thus, at each point, the
numbers ψ1(x), ψ2(x), . . . , ψn(x) deﬁne a discrete probability distribution, which
contains information about locality (ψi(x) is larger if x is closer to vi) but does
not satisfy the ﬁrst-order reproducing constraint (13.2b). This constraint can be re-
covered using the concept of relative entropy, also called Kullback–Leibler distance,
which measures the amount of information required to obtain a discrete probabil-
ity distribution from a prior distribution. Viewing ψi(x), i = 1, . . . , n as a prior

238
■Generalized Barycentric Coordinates in Graphics and Mechanics
distribution, the relative entropy can be written as
D(φ|ψ(x)) =
n
X
i=1
φi log
φi
ψi(x).
Minimization of this function with respect to φi, i = 1, . . . , n, subject to (13.2)
and (13.3), will produce the closest set of barycentric coordinates to the prior
from an information theoretical viewpoint, i.e., introducing the least extra infor-
mation [16, 202, 380]. A direct calculation using duality methods shows that the
resulting basis function φi can be written as the product of ψi and another fac-
tor enforcing the linear reproducing condition, and thus the prior and the relative
maximum-entropy functions have the same support. In particular, if w(r) = e−r2
and ρ = 1/√β, then these functions coincide with the LME basis functions.
13.4
FURTHER EXTENSIONS
We summarize next extensions to the meshfree and convex basis functions gen-
erated by the LME optimization program. An obvious question is whether these
approximants can be extended to higher-order, that is, if in addition to exactly re-
producing aﬃne functions due to (13.2), they can be designed to exactly reproduce
higher-order polynomials. This would lead to a higher rate of convergence when
approximating PDEs. Focusing in 1D for simplicity, a naive extension would be to
maximize the LME objective function subject to
n
X
i=1
φi = 1,
n
X
i=1
φivi = x,
n
X
i=1
φiv2
i = x2,
(13.10)
which are a set of conditions met, for instance, by quadratic ﬁnite element spaces.
However, as identiﬁed in [15], conditions in (13.10) together with the non-negativity
constraint φi ≥0 are infeasible for almost all points in P. This may seem contradic-
tory at ﬁrst sight, since there are examples of non-negative approximants that can
reproduce quadratic and higher-order functions, notably B-splines. One option is to
give up non-negativity and consider a notion of entropy for signed probability distri-
butions, which however destroys the convex structure of the approximation scheme,
does not produce generalized barycentric coordinates, and can lead to wiggly basis
functions [62, 373]. Insisting on non-negativity, the apparent contradiction referred
to above is resolved by noting that for the second-order consistency condition to
hold, the coeﬃcients that multiply the generalized barycentric coordinates do not
need to be v2
i . By designing appropriate coeﬃcients, it is possible to restore fea-
sibility, and thus deﬁne second-order maximum entropy approximants in multiple
dimensions [111, 336], see Figure 13.4(a). The construction of feasible constraints
for higher-order reproducing conditions, however, is an open question.
When applied to the numerical solution of PDEs with Galerkin methods, one
aspect complicating the implementation and diminishing the eﬃciency of LME ap-
proximations is the “uncontrolled” support of the basis functions. This is important

Maximum-Entropy Meshfree Coordinates in Computational Mechanics
■239
(a)
Maximum-entropy second 
order basis function
Moving-least-squares 
second order basis function
(b)
LME function
Cell-maxent function
(c)
Figure 13.4 Extensions of maximum-entropy approximations. (a) Representative
second-order maximum entropy basis function, compared to a moving-least-squares
function, which is wiggly and negative at some points. (b) Comparison of a standard
LME basis function and a cell-based maximum entropy basis function supported on
a triangulation, which results in a structured adjacency relation and more eﬃcient
calculations to approximate PDEs for a comparable accuracy. (c) Combination of
LME approximants with a boundary representation based on B-splines. See color
insert.
because any two basis functions with overlapping support will generate an entry in
the stiﬀness matrix resulting from the Galerkin method. Because the LME basis
functions have completely unstructured support, the underlying adjacency structure
setting the matrix structure is quite dense, but with many very small entries [305].
To alleviate this, a modiﬁcation of the LME basis functions was proposed, and called
cell-based maximum entropy approximations, in which prior functions (ψi(x) in the
previous section) were designed to be supported on the k-ring of simplices around
vi of a triangulation, see Figure 13.4(b). In this way, the adjacency structure of the
stiﬀness matrix is given directly by the topology of the triangulation and is much
sparser, leading to more eﬃcient calculations without nearly any degradation in
accuracy [281]. In this reference, the smooth and compactly supported prior func-

240
■Generalized Barycentric Coordinates in Graphics and Mechanics
tions were computed using approximate distance functions and R-functions, but
other techniques may result in better priors.
We ﬁnally report on a method that uses LME approximants to represent do-
mains with complex geometry and smooth boundaries. As described up to now,
the natural domain where the LME approximants are deﬁned is the convex hull of
P. For subsets of P, the approximants do not satisfy the weak delta-Kronecker on
the boundary. However, there is an increasing awareness of the importance of geo-
metric ﬁdelity in engineering calculations [205]. In fact, it is quite natural to blend
maximum-entropy approximations with any other convex approximation scheme,
such as most approximation methods used in computer graphics. It is suﬃcient
to consider an optimization program such as that in (13.7), in which some of the
barycentric coordinates are taken as data (the known convex scheme) and the rest
are the unknowns of the problem [334]. For instance, in Figure 13.4(c) one layer of
tensor product B-spline basis functions extruded from a B-spline boundary repre-
sentation was blended with LME functions.
13.5
APPLICATIONS
The LME approximants and their extensions have been adopted as trial and test
functions in Galerkin methods to solve various PDEs, including linear and nonlin-
ear elasticity [15, 334, 335, 336], incompressible solids [296], and ﬂuid ﬂow prob-
lems [243, 292, 306]. In these problems, which often exhibit smooth solutions, LME
approximations provide highly accurate numerical approximations with relatively
coarse sets of points, as compared to standard C0 ﬁnite elements. Furthermore, the
meshfree basis functions can accommodate very large grid distortions in Lagrangian
large deformation simulations [243, 306]. However, some applications truly beneﬁt
from the smoothness of the LME approximants for general unstructured sets of
points. We next outline two examples: the numerical approximation of high-order
PDEs and the approximation of manifolds deﬁned by scattered sets of points.
13.5.1
High-order partial differential equations
Many physical phenomena of interest in science and engineering are modeled using
higher-order PDEs. For instance, the Kirchhoﬀ–Love equations of thin shells are
fourth-order PDEs. Similarly, many problems involving evolving discontinuities can
be modeled using phase-ﬁeld models, where the discontinuity is smeared out and
tracked by a ﬁeld governed by a PDE. In many cases, such a PDE is of fourth
order, including models for crack propagation [64], crystal growth [396], or the
mechanics of ﬂuid membranes [128]. The numerical treatment of such problems
with C0 ﬁnite elements is cumbersome and involves independently interpolating
the ﬁeld and its gradient [129]. In contrast, a Galerkin approach is straightforward
if smooth basis functions are used. LMEs are not only smooth, but also easily
amenable to adaptive methods and have monotonicity properties that help them
accurately describe the sharp variations characteristic of phase-ﬁeld solutions. See
Figure 13.5 for an illustration of LME approximants applied to a phase-ﬁeld model

Maximum-Entropy Meshfree Coordinates in Computational Mechanics
■241
(a)
(b)
Figure 13.5 Application of the LME approximants to high-order PDEs. (a) In phase-
ﬁeld models of biomembranes, the unknown ﬁeld deﬁning the shape of a moving
interface is governed by a fourth-order PDE. Therefore, a Galerkin method requires
smooth basis functions (with square integrable second derivatives). The phase ﬁeld
develops sharp gradients, calling for an adaptive solution and an approximation
scheme devoid of Gibbs phenomenon. All these conditions are met by LME approx-
imations. (b) shows two snapshots in a dynamical simulation tracking the shape
of a deforming vesicle made out of a ﬂuid membrane with curvature elasticity, to-
gether with the hydrodynamics of the surrounding ﬂuid. The resolution of the set
of vertices follows the sharp variations of the phase-ﬁeld. See color insert.
of vesicle dynamics [306, 337]. LME approximants have also been applied to phase-
ﬁeld models of fracture [244], and to other high-order PDEs such as those arising in
the mechanics of thin shells [280] or in the coupled electromechanics of ﬂexoelectric
materials [1, 2].
13.5.2
Manifold approximation
Finally, LME approximations have been used to smoothly parametrize manifolds
sampled by clouds of points in an automated way and without the need for a
mesh, using an atlas of partially overlapping charts [280]. See [263] for recent work
along these lines, with a review of similar approaches in computer graphics. Fig-
ure 13.6(a) illustrates the procedure, in which the point-set on a d-dimensional

242
■Generalized Barycentric Coordinates in Graphics and Mechanics
Nonlinear dimensionality 
reduction of each partition
2D embedding of partition (*), where 
smooth parametrization using LME 
approximants is deﬁned.
(a)
(b)
Partitioned point-set surface
(*)
(c)
Figure 13.6 Approximation of manifolds using an atlas of smooth LME parametriza-
tions. (a) Methodology to deﬁne local parametrizations mapping partitions of a
surface deﬁned by a set of points. (b) Application of this method to solve the high-
order PDE for a nonlinear Kirchhoﬀ–Love shell. (c) Application of the method to
describe the molecular conformations of alanine dipeptide, a small molecule. An
ensemble of conformations of this molecule samples an underlying conﬁgurational
manifold homeomorphic to a torus. With the method presented in (a), this manifold
is partitioned into four pieces, each of which is parametrized with LME approxi-
mants. This method allows us to deﬁne smooth collective variables for this system,
required to enhance sampling in molecular dynamics simulations. See color insert.
manifold is systematically partitioned until each partition is homeomorphic to an
open set in Rd. Then, each partition is embedded in Rd using nonlinear dimen-
sionality reduction methods, and this embedding is used as a parametric domain
for a local parametrization of the partition. Parametrizations of adjacent partitions
are “glued” with partition-of-unity functions. This natural but powerful procedure
has been used to model thin shells of complex geometry, see Figure 13.6(b); to
parametrize the gait of microscopic swimming cells [14]; or to deﬁne collective vari-

Maximum-Entropy Meshfree Coordinates in Computational Mechanics
■243
ables for molecular systems based on parametrizing the so-called intrinsic manifold
underlying molecular ﬂexibility [186], see Figure 13.6(b).
13.6
OUTLOOK
In summary, the principle of maximum entropy is a conceptually appealing and
computationally practical approach to deﬁning generalized barycentric coordinates
for clouds of points. The resulting barycentric coordinates can be viewed as mesh-
free basis functions and used in computational mechanics, exploiting their smooth-
ness and the relative ease of implementing adaptive strategies. The fact that these
basis functions are barycentric coordinates makes it easier to impose boundary con-
ditions, but also provides a natural framework to couple maximum entropy basis
functions with multivariate spline techniques. We have demonstrated this by blend-
ing maximum entropy approximations to B-spline boundary representations, but
another attractive idea is using such blending to resolve the issues associated with
irregular vertices in spline patches [263]. Open issues include the systematic formu-
lation of feasible higher-order consistency conditions in multiple dimensions (see the
discussion following (13.10)), and the accurate and eﬃcient numerical quadrature
of the integrals appearing in Galerkin methods, which involve products of deriva-
tives of the non-polynomial LME basis functions. Finally, the applicability of the
LME approach in higher (greater than three) space dimensions has not yet been
exploited in applications.


C H A P T E R 14
BEM-Based FEM
Steﬀen Weißer
Saarland University, Saarbrücken, Germany
CONTENTS
14.1
Introduction ......................................................
246
14.2
High-order BEM-based FEM in 2D .............................
247
14.2.1 Construction of basis functions ..........................
248
14.2.2 Finite element method ...................................
249
14.2.3 Introduction to boundary element methods .............
250
14.2.4 Numerical examples ......................................
252
14.3
Adaptive BEM-based FEM in 2D ...............................
253
14.3.1 Adaptive FEM strategy ..................................
254
14.3.2 Residual-based error estimate for polygonal meshes .....
255
14.3.3 Numerical examples ......................................
256
14.4
Developments and outlook .......................................
258
14.4.1 Hierarchical construction for 3D problems ...............
259
14.4.2 Convection-adapted basis functions in 3D ...............
261
T
HE Boundary Element Method (BEM)-based Finite Element Method (FEM)
is an approach to approximate solutions of boundary-value problems over
polygonal and polyhedral meshes. The approximation spaces are deﬁned implicitly
over the polygonal or polyhedral elements. Harmonic coordinates are recovered
for the lowest order approximation in the special case of the diﬀusion problem.
Thus, this method can be viewed as a generalization of harmonic coordinates to
higher-order approximations. The deﬁnition and treatment of basis functions as
well as the ﬁnite element formulation are discussed in detail. Furthermore, the
BEM-based FEM is applied in the context of an adaptive FEM strategy yielding
locally reﬁned polygonal meshes. Theoretical evidence and numerical experiments
are presented that establish optimal rates of convergence for uniform and adaptive
mesh reﬁnement strategies.
245

246
■Generalized Barycentric Coordinates in Graphics and Mechanics
14.1
INTRODUCTION
In this chapter, we study a continuous-Galerkin ﬁnite element formulation on
polygonal and polyhedral meshes, which is applied to boundary-value prob-
lems. The approach was proposed in [107] and established in a sequence of pa-
pers [195, 196, 329, 330, 420, 421, 423]. First, the general situation is described
in the introduction, and afterwards the Poisson problem is considered as a simple
model problem to explain the approach.
Let Ω⊂Rd, d = 2, 3 be a bounded polygonal or polyhedral domain with
Lipschitz boundary ∂Ω= ΓD ∪ΓN, which is split into a Dirichlet and a Neumann
part that are denoted by ΓD and ΓN, respectively. We seek to ﬁnd the function
u : Ω→R that solves the following second-order convection-diﬀusion-reaction
boundary-value problem:
Lu = −div (A∇u) + b · ∇u + cu = f
in Ω,
u = gD
on ΓD,
∂u
∂n = gN
on ΓD,
where n denotes the outward unit normal vector to Ω. A ∈Rd×d, b ∈Rd, c ∈R are
some coeﬃcients, f is a source term, and gD, gN are boundary data. We assume that
the operator L is elliptic and the boundary-value problem has a unique solution.
This is guaranteed by the usual assumptions on the coeﬃcients and the data.
To obtain an approximation of the unknown solution u, the domain Ωis dis-
cretized by non-overlapping polygonal or polyhedral elements and a ﬁnite element
formulation is applied. The idea of the BEM-based FEM is to use a Treﬀtz-like
approximation space. Its basis functions are deﬁned to fulﬁl certain local boundary-
value problems related to the diﬀerential operator L on each element P. In these
local problems, the coeﬃcients of L are chosen to be constant. The global continu-
ity of the basis functions is ensured by prescribing the boundary data on ∂P. Due
to the special choice of basis functions, it is possible to restate the ﬁnite element
formulation such that only integrals over ∂P appear in the ﬁnite element matrix
and we do not have to evaluate the basis functions explicitly in the interior of P.
However, this procedure involves boundary integral operators, which are treated by
means of the BEM in the realization.
All these steps are treated more precisely in the following sections. To simplify
the presentation, we restrict ourselves to L = −∆and zero Dirichlet data on ΓD
with |ΓD| > 0. Thus, we consider the problem
−∆u = f in Ω,
u = 0 on ΓD,
∂u
∂n = gN on ΓN.
(14.1)
The well-known variational formulation reads: ﬁnd u ∈V such that
b(u, v) = (f, v)L2(Ω) + (gN, v)L2(ΓN)
∀v ∈V,
(14.2)
where
b(u, v) =
ˆ
Ω
∇u · ∇v dx
and
V = {v ∈H1(Ω) : v = 0 on ΓD}.

BEM-Based FEM
■247
For f ∈L2(Ω) and gN ∈L2(ΓN), problem (14.2) admits a unique solution according
to the Lax–Milgram Lemma, since the bilinear form b(·, ·) is bounded and coercive
on V . To obtain a discrete ﬁnite element solution we replace V in (14.2) by a ﬁnite-
dimensional conforming subspace Vh ⊂V that is spanned by some basis functions,
i.e., Vh = span{ϕ1, . . . , ϕm}. The ansatz uh = Pm
i=1 uiϕi yields the ﬁnite element
system of linear equations
Ku = f
for
u = (u1, . . . , um) ∈Rm,
(14.3)
where
K = (b(ϕj, ϕi))m
i,j=1 ∈Rm×m,
f =
 (f, ϕi)L2(Ω) + (gN, ϕi)L2(ΓN)
m
i=1 ∈Rm.
The basis functions ϕi are deﬁned over the polygonal or polyhedral mesh Th in
such a way that they have local support. Consequently, the ﬁnite element stiﬀness
matrix K is sparse, and it is symmetric as well as positive deﬁnite because of the
properties of b(·, ·). Therefore, eﬃcient numerical solvers such as those based on the
conjugate gradient method are available to solve (14.3).
In the ﬁrst part of this chapter we consider the two-dimensional case d = 2. We
already mentioned that the basis functions ϕi are deﬁned locally on each polygonal
element P with the help of the diﬀerential operator L = −∆in the BEM-based
FEM. For the ﬁrst-order approximation space, we prescribe linear data on ∂P and
use −∆ϕi = 0 in P. As a consequence, we recover harmonic coordinates that were
ﬁrst proposed in [215] for applications in computer graphics, see Section 1.2.8 as
well. These harmonic coordinates belong to the class of generalized barycentric
coordinates, which also ﬁnd applications in polygonal ﬁnite element methods, see
Chapter 11. The general construction of basis functions for high-order approxima-
tion spaces within the BEM-based FEM is discussed in Section 14.2. This approach
generalizes harmonic coordinates to higher order basis functions and shows similar-
ities to the virtual element method (VEM). The VEM was ﬁrst introduced in [27]
and is discussed in Chapter 15. In Section 14.2, we additionally discuss the treat-
ment of the locally implicit basis functions and the computation of the ﬁnite element
matrix K. This involves the application of BEM locally, for which we give a short
introduction. One of the promising application areas of polygonal meshes is in adap-
tive mesh reﬁnement, where the ﬂexibility of using diﬀerent element shapes in the
meshes can be exploited. In Section 14.3, an adaptive FEM strategy is reviewed,
one that makes use of the BEM-based FEM and a residual-based a posteriori error
estimator. Numerical experiments are presented that demonstrate the application
of polygonal meshes to solve two-dimensional boundary-value problems. Finally, in
Section 14.4, we present an outlook to further developments in 2D and 3D.
14.2
HIGH-ORDER BEM-BASED FEM IN 2D
In this section, we address the ﬁnite element formulation and give theoretical and
numerical rates of convergence for the BEM-based FEM on sequences of uniformly
reﬁned meshes. First, the domain Ω⊂R2 is decomposed into a ﬁnite number of non-
overlapping polygonal elements P such that ¯Ω= S{ ¯P : P ∈Th}. Here, Th is the

248
■Generalized Barycentric Coordinates in Graphics and Mechanics
set of all these polygonal elements, and it is called the polygonal mesh. We assume
that Th is regular, i.e., all polygonal elements P ∈Th are star-shaped with respect
to a circle such that the aspect ratio hP /ρP of their diameter hP and the radius ρP
of the circle is uniformly bounded for all elements, and that the lengths h[vi,vi+1] of
the edges of P can be uniformly bounded from below such that cT hP ≤h[vi,vi+1]
for a ﬁxed constant cT .
14.2.1
Construction of basis functions
The global approximation space Vh = span{ϕ1, . . . , ϕm} is also denoted by V k
h to
specify its approximation order k ∈N. It is constructed by prescribing its basis
functions ϕi over the single elements P ∈Th such that
V k
h = {v ∈V : v|P ∈V k
h (P) ∀P ∈Th},
and we only have to give a local basis for V k
h (P).
Let Pk(ω) be the space of polynomials of degree less than or equal to k over ω,
where ω is either an element P or an edge [vi, vi+1]. Before we address V k
h (P), we
introduce an auxiliary space over ∂P. Let
Pk
pw(∂P) = {v ∈C(∂P) : v|[vi,vi+1] ∈Pk([vi, vi+1]), i = 1, . . . , n}
be the space of piecewise functions on ∂P that are polynomials of degree smaller or
equal to k over each edge [vi, vi+1] and that are continuous at the vertices vi. Fur-
thermore, let {λi : i = 1, . . . , kn} be a basis set of Pk
pw(∂P), where λi, i = 1, . . . , n
is linear on each edge [vj, vj+1] and fulﬁls λi(vj) = δij. For i > n, λi are chosen
as polynomial bubble functions that vanish at the vertices and have local support
on one edge. For example, λi, i = n + 1, . . . , 2n is a quadratic polynomial over
[vi, vi+1], λi, i = 2n + 1, . . . , 3n is a cubic polynomial over [vi, vi+1], and so on.
Next, the space V k
h (P) is given by prescribing its basis functions. They satisfy
certain boundary-value problems on P, as mentioned in the introduction. Since
L = −∆for the model problem, we deﬁne φi, i = 1, . . . , kn as the unique solution
of
−∆φi = 0
in P
and
φi = λi
on ∂P.
(14.4)
For the lowest-order case k = 1, we recover harmonic coordinates, compare Sec-
tion 1.2.8. For k > 1, we have additional harmonic basis functions with polynomial
data on ∂P. Furthermore, we introduce element bubble functions φi,j for k > 1
with i = 0, . . . , k −2 and j = 0, . . . , i as the unique solutions of
−∆φi,j = pi,j
in P
and
φi,j = 0
on ∂P,
(14.5)
where pi,j(x) = (x−¯x)i−j(y−¯y)j and ¯x = (¯x, ¯y) is the center of mass of P. Later on,
it is convenient to reformulate the local boundary-value problems for the element
bubble functions φi,j such that they reduce to Laplace problems. Afterwards, φi,j
can be expressed in terms of the harmonic basis functions φi. This yields the form
φi,j = qi,j −
n
X
ℓ=1
αℓφℓ,
(14.6)

BEM-Based FEM
■249
where qi,j ∈Pk(P) is such that −∆qi,j = pi,j. The polynomial qi,j is always
constructible and it is not unique. The coeﬃcients αℓare chosen in accordance
with qi,j|∂P −Pn
ℓ=1 αℓλi = 0.
Since the basis functions are deﬁned as solutions of boundary-value problems,
the theory of partial diﬀerential equations provides regularity results. It is known
that the solution of (14.4) and (14.5) belongs to C2(P) ∩C( ¯P) for convex ele-
ments P. In the case of non-convex elements, the classical notion of smoothness is
lost and the diﬀerential equations have to be understood in the weak sense. Nev-
ertheless, the basis functions still belong to H1(P) ∩C( ¯P), which is suﬃcient to
ensure conformity.
Finally, the space V k
h (P) is deﬁned as the span of the functions φi and φi,j.
Since {pi,j : i = 0, . . . , k −2 and j = 0, . . . , i} is a basis set of Pk−2(P), we obtain
V k
h (P) = {v ∈H1(P) : −∆v ∈Pk−2(P) and v|∂P ∈Pk
pw(∂P)}.
(14.7)
Furthermore, we observe that Pk(P) ⊂V k
h (P). This is a consequence of the unique
solvability of the Poisson problem with Dirichlet boundary data. For p ∈Pk(P), it
is evidently p|∂P ∈Pk
pw(∂P) and −∆p ∈Pk−2(P) and thus p ∈V k
h (P).
The VEM in Chapter 15 also uses the local space deﬁned in (14.7). Therefore,
the BEM-based FEM and the VEM seek the approximation of the solution of
the boundary-value problem for the Poisson equation (14.1) in the same discrete
space. The VEM reduces all computations to carefully chosen degrees of freedom
and to local projections into polynomial spaces. The BEM-based FEM in contrast
makes use of the explicit knowledge of the basis functions and thus enables the
evaluation of the approximation inside the elements. Both methods rely on clever
reformulations to avoid volume integration. Since the BEM-based FEM applies
Treﬀtz-like basis functions, which are related to the diﬀerential equation of the
global problem, the discrete space for the BEM-based FEM and the VEM diﬀer as
soon as more general boundary-value problems are considered.
14.2.2
Finite element method
The conforming approximation space V k
h ⊂H1(Ω) can be utilized in an FE compu-
tation. The variational formulation of the model problem is already given in (14.2)
and its approximation yields the system of linear equations (14.3). The approxi-
mation properties of the Galerkin formulation have been studied in [329, 421]. The
space V k
h yields the same error estimates that are known for classical approximation
spaces over triangulations, but on much more general meshes.
Theorem 14.1. Let Th be a regular polygonal mesh, u ∈V be the solution of (14.2),
and uh ∈V k
h be the Galerkin approximation obtained by (14.3). Then,
∥u −uh∥Hℓ(Ω) ≤c hk+1−ℓ|u|Hk+1(Ω)
for u ∈Hk+1(Ω) and ℓ= 0, 1,
where the constant c only depends on the mesh regularity and for ℓ= 0 some
additional regularity of the dual problem is assumed.

250
■Generalized Barycentric Coordinates in Graphics and Mechanics
It remains to discuss the setup of (14.3) and how to compute the involved
integrals. The formation of the matrix K and the right-hand side f is done as in
FEM by agglomerating local (element-wise) stiﬀness matrices. Therefore, we write
b(ϕj, ϕi) =
X
P ∈Th
ˆ
P
∇ϕi · ∇ϕj dx.
(14.8)
The diﬃculty arises in the application of the bilinear form to the implicitly deﬁned
basis functions and to evaluate the integral (f, ϕi)L2(P ) on the right hand side. The
computation of the boundary integral (gN, ϕi)L2(ΓN) is straightforward, since the
basis functions ϕi are known explicitly along the edges. Thus, these integrals are
treated over each edge in ΓN by numerical quadrature.
To evaluate the integrals in (14.8), we distinguish three cases and apply Green’s
ﬁrst identity locally on each element P ∈Th. The details are left to the reader. If
ϕi|P and ϕj|P correspond to harmonic basis functions φi and φj, we obtain
ˆ
P
∇φi · ∇φj dx =
ˆ
∂P
∂φi
∂nP
φj dsx.
(14.9)
If ϕi|P and ϕj|P correspond to element bubble functions φi,j and φi′,j′, then we
can use (14.6) to obtain
ˆ
P
∇φi,j·∇φi′,j′ dx =
ˆ
∂P
∂qi,j
∂nP
qi′,j′ dsx−
n
X
ℓ=1
αℓ
ˆ
∂P
∂φℓ
∂nP
qi′,j′ dsx+
ˆ
P
pi,jqi′,j′dx.
And if ϕi|P corresponds to a harmonic basis function and ϕj|P to an element
bubble function, we obtain
´
P ∇ϕi · ∇ϕj dx = 0. Therefore, the system of linear
equations decouples in the FE computation. Furthermore, besides the unknown
term ∂φi/∂np all others are (piecewise) polynomials such that the ﬁrst and third
integral in the last formula can be analytically computed. The approximation of
∂φi/∂np is addressed in the next subsection.
For the computation of (f, φi)L2(Ω), we proceed as in (14.8). Then, we approx-
imate the local integrals
´
P fϕi dx by a numerical quadrature over polygonal el-
ements. This is realized by subdividing the polygon into triangles and applying
standard quadrature rules over them, cf. [378]. Alternatively, we might also apply
quadrature rules over polygons directly, see for example [102]. If ϕi|P corresponds
to a harmonic basis function φi, we make use of the representation formula
φi(x) = −1
2π
ˆ
∂P
ln |x −y| ∂φi(y)
∂nP
dsy −1
2π
ˆ
∂P
nP · (x −y)
|x −y|2
φi(y) dsy
(14.10)
for x ∈P, see below. If ϕi|P corresponds to an element bubble function, we ap-
ply (14.6). We stress again that the knowledge of ∂φi/∂np is important.
14.2.3
Introduction to boundary element methods
The representation formula (14.10) is crucial for boundary element methods, which
are utilized to approximate boundary integral formulations. To be mathemati-
cally precise, see [367], we denote by γ0 : H1(P) →H1/2(∂P) the usual trace

BEM-Based FEM
■251
operator that satisﬁes γ0v = v|∂P for continuous functions. Furthermore, let
γ1v ∈H−1/2(∂P) be the conormal derivative, also called Neumann trace, of a
function v ∈H1(Ω) with ∆v in the dual of H1(Ω). The Neumann trace γ1v is
deﬁned by Green’s identity
ˆ
P
∇v · ∇w dx =
ˆ
∂P
γ1v γ0w dsx −
ˆ
P
w∆v dx
for w ∈H1(P) and coincides with ∂v/∂nP for suﬃcient regular functions. Thus,
we write (14.10) in terms of boundary integral operators for a harmonic function v
as v = ˜V(γ1v) −W(γ0v) in P. Applying the trace operators γ0 and γ1 to the
representation formula yields the Calderon projector
 γ0v
γ1v

=

1
2I −K
V
D
1
2I + K′
  γ0v
γ1v

,
(14.11)
where I is the identity operator. The single layer, double layer, and adjoint double
layer potential as well as the hypersingular integral operator have the mapping
properties
V : H−1/2(∂P) →H1/2(∂P),
K : H1/2(∂P) →H1/2(∂P),
K′ : H−1/2(∂P) →H−1/2(∂P),
D : H1/2(∂P) →H−1/2(∂P).
For a detailed study of these operators, see [367]. The ﬁrst equation in (14.11)
gives the boundary integral equation V(γ1v) = ( 1
2I + K)(γ0v). Consequently, if
γ0v is known, the Neumann trace t = γ1v is given as the solution of the Galerkin
formulation
(Vt, τ)L2(∂P ) =
 ( 1
2I + K)γ0v, τ

L2(∂P )
∀τ ∈H−1/2(∂P).
This formulation admits a unique solution, since V is known to be invertible for
hP < 1. To obtain an approximation of t ∈H−1/2(∂P), we apply the BEM. We
discretize H1/2(∂P) by Pk
pw(∂P) and H−1/2(∂P) by Pk−1
pw,d(∂P), where
Pk−1
pw,d(∂P) = {v ∈L2(∂P) : v|[vi,vi+1] ∈Pk−1([vi, vi+1]), i = 1, . . . , n}
is the space of piecewise polynomials of order smaller or equal to k −1 that allow
discontinuities at the vertices of P. Let {τi : i = 1, . . . , kn} be a basis set of
Pk−1
pw,d(∂P) that is constructed analogously to {λi : i = 1, . . . , kn}. For polynomial
data γ0v = Pkn
i=1 viλi ∈Pk
pw(∂P), the ansatz t ≈th = Pkn
i=1 tiτi ∈Pk−1
pw,d(∂P)
yields the system of linear equations
Vt =
  1
2M + K

v,
(14.12)
with t = (t1, . . . , tkn) and v = (v1, . . . , vkn), where
V =
 (Vτj, τi)L2(∂P )
kn
i,j=1 ,
M =
 (λj, τi)L2(∂P )
kn
i,j=1 ,
K =
 (Kλj, τi)L2(∂P )
kn
i,j=1 ,
D =
 (Dλj, λi)L2(∂P )
kn
i,j=1 .

252
■Generalized Barycentric Coordinates in Graphics and Mechanics
If we apply analogously a Galerkin formulation to the second equation in (14.11)
and replace γ1v with th on the right-hand side, then we obtain the matrix
S = D +
  1
2M⊤+ K⊤
V−1  1
2M + K

.
Because of γ0φi = λi, the matrix entries are good approximations for
S ≈
 (γ1φj, γ0φi)L2(∂P )
kn
i,j=1 .
(14.13)
The entries of the matrices V, K, and D are double integrals over ∂P. The inner
integral, which corresponds to the action of the boundary integral operator on a ba-
sis function, can be evaluated in closed form. The outer integral, which corresponds
to the L2-product, is approximated by numerical quadrature.
At this point, we stress that in the previous description the boundary element
method is directly applied on the naturally given discretization of the polygonal
element P. For example, if we have a pentagon and we are interested in k = 1,
the Dirichlet trace is described exactly by ﬁve degrees of freedom on ∂P and the
Neumann trace is approximated by one constant per edge. In general, the BEM
makes use of a ﬁner discretization of ∂P, but for our purpose the coarsest and
naturally given discretization is suﬃcient.
Finally, we draw the connection to the global BEM-based FEM. If we com-
pare (14.13) with (14.8) and (14.9), we see that S serves as a good approximation
of the local stiﬀness matrices in the ﬁnite element formulation. Furthermore, the
approximation th of γ1v for v = φi obtained by (14.12) is used in the representation
formula (14.10) to evaluate the basis functions φi in the interior of the polygonal
element P. All boundary element matrices are set up once per element in a BEM-
based FEM simulation and are used for all basis functions. Since the number of
vertices per element is bounded and we do not discretize the element boundaries
further, the local BEM matrices are rather small and the inversion of V can be
done eﬃciently with a LAPACK routine.
14.2.4
Numerical examples
The theoretical results of Theorem 14.1 are illustrated on a model problem. The
BEM-based FEM is applied on a sequence of uniformly reﬁned polygonal meshes.
In each step of the reﬁnement, the boundary-value problem
−∆u = f
in Ω= (0, 1)2,
u = 0
on Γ
is solved, where f is chosen such that u(x) = sin(πx) sin(πy) is the unique solution.
The initial mesh and some reﬁnements are shown in Figure 14.1. The successively re-
ﬁned meshes are obtained by dividing each polygonal element as described in [420],
also see the next section. The Galerkin error ∥u −uh∥Hℓ(Ω) is computed for the
H1-norm (ℓ= 1) and the L2-norm (ℓ= 0). In Figure 14.2, the relative errors are
plotted with respect to the mesh size h = max{hP : P ∈Th} on a logarithmic
scale. The slopes of the curves reﬂect the theoretical rates of convergence for the
approximation orders k = 1, 2, 3.

BEM-Based FEM
■253
Tue May 31 11:44:20 2011
0
1
0
1
Mesh in Level 0
X−Axis
Y−Axis
Tue May 31 11:44:48 2011
0
1
0
1
Mesh in Level 2
X−Axis
Y−Axis
Tue May 31 11:44:58 2011
0
1
0
1
Mesh in Level 4
X−Axis
Y−Axis
Figure 14.1 Initial mesh (left), reﬁned mesh after two steps (middle), reﬁned mesh
after four steps (right).∗
10−4
10−3
10−2
10−1
100
10−1
100
∥u −uh∥H1(Ω)/∥u∥H1(Ω)
mesh size h
1
1
2
1
3
1
k = 1
k = 2
k = 3
10−6
10−5
10−4
10−3
10−2
10−1
10−1
100
∥u −uh∥L2(Ω)/∥u∥L2(Ω)
mesh size h
2
1
3
1
4
1
k = 1
k = 2
k = 3
Figure 14.2 Relative error in H1-norm (left) and L2-norm (right) with respect to
the mesh size h.†
14.3
ADAPTIVE BEM-BASED FEM IN 2D
In the uniform reﬁnement strategy, each element of the mesh is split into two
new elements to obtain the next ﬁner mesh. This splitting process is performed
as described below. To obtain the optimal rates of convergence according to The-
orem 14.1, the solution has to be smooth. This assumption is often violated in
practical applications, where singularities can arise due to discontinuous material
parameters or reentrant corners in the geometry. Consequently, the convergence
slows down for uniform reﬁnement. Therefore, the meshes have to be adapted to
the problem in order to recover optimal rates of convergence. For the adaptive
†Reprinted from Numerische Mathematik, Residual error estimate for BEM-based FEM on
polygonal meshes, Vol. 118, 2011, pages 765–788, S. Weißer, c⃝Springer-Verlag 2011, with per-
mission of Springer.
∗Reprinted from Computers & Mathematics with Applications, Vol. 67(7), S. Weißer, Arbitrary
order Treﬀtz-like basis functions on polygonal meshes and realization in BEM-based FEM, pages
1390–1406, Copyright (2014), with permission from Elsevier.

254
■Generalized Barycentric Coordinates in Graphics and Mechanics
BEM-based FEM, we proceed by adopting a common strategy, which only selects
several elements for reﬁnement in each step, see [403]. Essential ingredients are the
element-wise error indicators ηP that monitor the approximation quality over the
single elements. In the following we assume that these indicators bound the true
error in the desired norm such that
∥u −uh∥≤c ηR = c
 X
P ∈Th
η2
P
1/2
.
(14.14)
In Section 14.3.2, we present a residual-based error estimator, which bounds the
error in the energy norm.
14.3.1
Adaptive FEM strategy
The adaptive BEM-based FEM successively reﬁnes elements that contribute most
to the error. This strategy proceeds in a loop over four steps:
SOLVE The boundary-value problem (14.1) is approximated by means of the
BEM-based FEM on the current polygonal mesh using the approximation
space V k
h .
ESTIMATE An error estimator ηR as well as the element-wise error indicators ηP
(see Section 14.3.2) are computed on the discretization Th.
MARK A minimal subset Mh ⊂Th of all elements are marked according to
Dörﬂers strategy [125] such that
 X
P ∈Mh
η2
P
1/2
≥(1 −θ) ηR,
where 0 ≤θ < 1 is a user-deﬁned parameter. To obtain a minimal set Mh,
it is possible to sort the elements according to their indicators ηP and mark
those with the largest indicators. Instead of that, we implemented the marking
algorithm given in [125] to achieve linear complexity. Furthermore, we choose
θ = 0.5 in the numerical experiments.
REFINE Each marked element is reﬁned and we consequently obtain a new mesh
for the next cycle in the loop. For the reﬁnement of an element P, we bi-
sect P through its barycenter ¯x orthogonal to its characteristic direction, see
Figure 14.3, that is given by the eigenvector that corresponds to the largest
eigenvalue of the matrix
MCov =
ˆ
P
(x −¯x)(x −¯x)⊤dx,
¯x =
1
|P|
ˆ
P
x dx.
For more details, see [420]. Furthermore, we check the regularity of the mesh
and reﬁne additional elements if cT hP ≤h[vi,vi+1] for any i = 1, . . . , n is
violated with a user-deﬁned parameter cT .

BEM-Based FEM
■255
Mon May 31 12:05:17 2010
0.1
0.2
0.3
0.4
0.5
0.35
0.4
0.5
0.6
0.7
0.75
Mesh in Level 0
X−Axis
Y−Axis
Mon May 31 12:05:58 2010
0.1
0.2
0.3
0.4
0.5
0.35
0.4
0.5
0.6
0.7
0.75
Mesh in Level 0
X−Axis
Y−Axis
Mon May 31 11:44:58 2010
0.1
0.2
0.3
0.4
0.5
0.35
0.4
0.5
0.6
0.7
0.75
Mesh in Level 1
X−Axis
Y−Axis
Figure 14.3 Reﬁnement of an element: element with center ¯x (left), element with
eigenvector (middle), two new elements (right).†
The adaptive mesh reﬁnement process is kept very local. Only the marked and
degenerated elements are bisected during the reﬁnement. It is not necessary to
resolve hanging nodes and keep the mesh admissible, as for example in the red-
blue-green reﬁnement procedure for triangular meshes, see [403]. This advantage is
due to the polygonal meshes with very ﬂexible elements.
14.3.2
Residual-based error estimate for polygonal meshes
The residual-based a posteriori error estimate bounds the diﬀerence of the exact
solution and the Galerkin approximation in the energy norm associated to the
bilinear form. Among others, the estimate contains the jumps of the conormal
derivatives over the element edges. Let P ∈Th be a polygonal element with edge
[vi, vi+1] and P ′ ∈Th be the neighboring element that contains this edge. Then,
the jump is given on (vi, vi+1) by
JuhK = ∂uh|P
∂nP
+ ∂uh|P ′
∂nP ′ .
We deﬁne the so-called edge residual by
RP,i =





0
for (vi, vi+1) ⊂ΓD,
gN −∂uh
∂nP
for (vi, vi+1) ⊂ΓN,
−1
2JuhK
for (vi, vi+1) ⊂Ω.
All ingredients are now available to state the residual-based error estimate that
fulﬁls (14.14) for the energy norm ∥∇· ∥L2(Ω).
Theorem 14.2 (Reliability). Let Th be a regular mesh. Furthermore, let u ∈V
and uh ∈V k
h be the solutions of (14.2) and the Galerkin approximation obtained
†Reprinted from Numerische Mathematik, Residual error estimate for BEM-based FEM on
polygonal meshes, Vol. 118, 2011, pages 765–788, S. Weißer, c⃝Springer-Verlag 2011, with per-
mission of Springer.

256
■Generalized Barycentric Coordinates in Graphics and Mechanics
by (14.3), respectively. Then the residual-based error estimate is reliable, i.e.,
∥∇(u −uh)∥L2(Ω) ≤c ηR
with
η2
R =
X
P ∈Th
η2
P ,
where the error indicators are deﬁned by
η2
P = h2
P ∥f + ∆uh∥2
L2(P ) +
n
X
i=1
h[vi,vi+1]∥RP,i∥2
L2([vi,vi+1]).
The constant c > 0 only depends on the regularity parameters of the mesh and the
approximation order k.
The error in the energy norm decreases at least as fast as the error estimator ηR
according to the previous theorem. In order to have a good estimator, which can
be used eﬃciently to estimate the true error, it is important that the error does
not decrease faster than ηR. This behavior is shown in the next theorem, where the
error indicators ηP are bounded in terms of the error plus some data oscillations.
For the lower bound, the estimate involves the neighborhood ωP of the element P.
This patch of elements is given by ¯ωP = S{ ¯P ′ : P ′ ∈Th, ¯P ∩¯P ′ ̸= ∅}.
Theorem 14.3 (Eﬃciency). Under the assumptions of Theorem 14.2, the residual-
based error indicator is eﬃcient, i.e.,
ηP ≤c

∥∇(u −uh)∥2
L2(ωP )
+ h2
P ∥f −ef∥2
L2(ωP ) +
X
i=1,...,n:
[vi,vi+1]̸⊂ΓD
h[vi,vi+1]∥gN −egN∥2
L2([vi,vi+1])

where ef and egN are piecewise polynomial approximations of the data f and gN,
respectively. The constant c > 0 only depends on the regularity parameters of the
mesh and the approximation order k.
The terms ∥f −ef∥L2(ωP ) and ∥gN −egN∥L2([vi,vi+1]) are often called data oscil-
lations. They are usually of higher order.
14.3.3
Numerical examples
Let Ω=
 (−1, 1) × (−1, 1)

\
 [0, 1] × [0, −1]

and ΓD = ∂Ω. Using polar coordi-
nates (r, ϕ) for x = (r cos ϕ, r sin ϕ), the boundary data gD is chosen in such a way
that
u(r cos ϕ, r sin ϕ) = r2/3 sin
2ϕ
3

is the solution of the boundary-value problem
−∆u = 0
in Ω,
u = gD
on Γ.

BEM-Based FEM
■257
Tue Sep 21 14:54:10 2010
1
0
1
−
−1
0
1
Tue Sep 21 15:00:39 2010
1
0
1
−
−1
0
1
Tue Sep 21 14:55:19 2010
1
0
1
−
−1
0
1
Figure 14.4 Initial mesh (left), adaptive reﬁned mesh after ﬁve steps (middle), adap-
tive reﬁned mesh after ten steps (right).†
The inhomogeneous Dirichlet data is treated by means of a discrete extension as
usual in ﬁnite element methods. The boundary-value problem is discretized using
the ﬁrst order approximation space V 1
h on uniformly and adaptively reﬁned meshes.
Because of the reentrant corner in the geometry, the solution does not meet the reg-
ularity assumptions of Theorem 14.1. The derivatives of u have a singularity at the
origin of the coordinate system, and consequently, uniform reﬁnement yields sub-
optimal rates of convergence. However, we still expect optimal rates of convergence
for the adaptive BEM-based FEM computation.
On a sequence of uniform reﬁned meshes, the following hold:
DOFs = O(h−2),
where DOFs denotes the number of degrees of freedom. Since the mesh size h is not
strictly monotonically decreasing for adaptive reﬁnement strategies, we study the
convergence with respect to the number of degrees of freedom. Figure 14.4 shows the
initial mesh as well as the adaptive meshes after ﬁve and ten reﬁnement steps. The
adaptive algorithm detects the singularity and tunes the mesh towards the origin of
the coordinate system. The reﬁnement is kept very local since hanging nodes do not
have to be resolved by additional reﬁnements. The convergence plot in Figure 14.5
conﬁrms the predicted behavior. Whereas the convergence for uniform reﬁnement
slows down, the adaptive algorithm recovers linear convergence, which corresponds
to a slope of −1/2. Furthermore, the residual-based error estimator ηR bounds the
true error and represents the reduction of the error very well, see Figure 14.5.
In order to further stress the use and the ﬂexibility of polygonal meshes in adap-
tive computations, we analyze the ﬁrst two reﬁnement steps. For this reason, the
error distribution is visualized in Figure 14.6 for the ﬁrst three meshes. Each ele-
ment P is colored according to the value ∥∇(u−uh)∥L2(P ). The adaptive algorithm
apparently marks and reﬁnes the elements with the largest error contribution. The
introduced nodes on straight edges (hanging nodes for classical meshes) are not
†Reprinted from Numerische Mathematik, Residual error estimate for BEM-based FEM on
polygonal meshes, Vol. 118, 2011, pages 765–788, S. Weißer, c⃝Springer-Verlag 2011, with per-
mission of Springer.

258
■Generalized Barycentric Coordinates in Graphics and Mechanics
10−2
10−1
100
101
101
102
103
104
105
∥∇(u −uh)∥L2(Ω), ηR
number of degrees of freedom
2
1
2
1
adaptive ∥∇(u −uh)∥L2(Ω)
uniform ∥∇(u −uh)∥L2(Ω)
adaptive ηR
uniform ηR
Figure 14.5 Convergence for singular solution on an arc, cf. Figure 14.4, on a loga-
rithmic scale.†
1.3 · 10−2
1.0 · 10−2
7.5 · 10−3
5.0 · 10−3
2.5 · 10−3
2.3 · 10−4
Figure 14.6 Error distribution ∥∇(u −uh)∥2
L2(P ) for the ﬁrst three meshes.†
resolved. Each of these nodes corresponds to a degree of freedom in the FE com-
putation and thus, improves the approximation within the neighboring elements.
For example, the upper right triangle close to the reentrant corner in Figure 14.6
is not reﬁned. But, the error reduces due to the additional nodes on the left edge,
namely, the triangle became a pentagon in the right most mesh.
14.4
DEVELOPMENTS AND OUTLOOK
The idea of the BEM-based FEM has been applied to time-dependent prob-
lems [422] and in the discretization of H(div)-conforming approximation spaces
†Reprinted from Numerische Mathematik, Residual error estimate for BEM-based FEM on
polygonal meshes, Vol. 118, 2011, pages 765–788, S. Weißer, c⃝Springer-Verlag 2011, with per-
mission of Springer.

BEM-Based FEM
■259
over polygonal meshes [138]. The application to three-dimensional problems on
polyhedral meshes is discussed in the original work [107] and a generalization is
given in [330]. Additionally, a ﬁnite element tearing and interconnecting (FETI)
type solver has been developed to handle the large system of linear equations [198].
In this section, we present the essentials for 3D problems and provide an application
to a convection-dominated boundary-value problem.
14.4.1
Hierarchical construction for 3D problems
In several publications on the BEM-based FEM, the approach is applied to three-
dimensional problems. For simplicity we restrict ourselves to the ﬁrst order method
(k = 1) in the following. The construction of basis functions is straightforward,
as soon as it is assumed that the faces of the polyhedral elements are triangles.
In the original approach, the basis functions are deﬁned analogously to the two-
dimensional case. For each vertex vi, we have a function φi such that φi(vj) = δij,
it is linear on the triangular faces, and φi is harmonic inside the polyhedral element.
Furthermore, a three-dimensional version of the boundary element method is avail-
able. Here, the boundary integral operators only diﬀer in their kernel function and,
of course, in the integration, which is done over two-dimensional surfaces of the
polyhedra instead of one-dimensional boundaries of the polygons. In the treatment
of the resulting boundary integral equation, in order to approximate the Neumann
trace, the Sobolev spaces H1/2(∂P) and H−1/2(∂P) are discretized by continuous
and piecewise linear polynomial functions over the surface triangles and by piece-
wise constant functions, respectively. All considerations on the assembling of the
ﬁnite element matrix in 2D transfer to the 3D case.
What can be done in the case of general polyhedral elements with polygonal
faces? A simple and practical idea is to triangulate the surface ∂P of the polyhe-
dral element P ﬁrst and then apply the strategy described above. However, this
introduces additional (artiﬁcial) vertices to the polyhedral element, which lead to
additional degrees of freedom in the ﬁnite element computation. An alternative
approach has been proposed in [330] that is applicable on general polygonal faces.
In order to motivate the construction in 3D, we analyze once more the ﬁrst-
order basis functions φi for i = 1, . . . , n in 2D, or equivalently the harmonic coordi-
nates from Section 1.2.8. These functions fulﬁl φi(vj) = δij, are linear on the one-
dimensional edges, and are harmonic inside the two-dimensional polygonal element.
We observe that the second derivative of a linear function vanishes. Consequently,
if we parametrize the edges linearly and treat φi as a function of one variable along
the edge, we see that φ′′
i = 0. Therefore, the linear function φi is harmonic in
1D on the edge and can be interpreted as the solution of a Laplace problem with
boundary data that is correspondingly 0 and 1. From this viewpoint, it is clear
how to proceed for the construction in 3D. Let ∆1 and ∆2 denote the one- and
two-dimensional Laplace operators in the linear parameter spaces of an edge and
face, respectively, and let ∆3 be the usual Laplace operator in three dimensions.

260
■Generalized Barycentric Coordinates in Graphics and Mechanics
φi(vj) = δij
∆1φi = φ′′
i = 0
∆2φi = 0
∆3φi = 0
Figure 14.7 Construction of 3D basis functions for pentagonal prism P as well as
auxiliary triangulation of the surface ∂P.
Then, the basis functions are deﬁned by
φi(vj) = δij
j = 1, . . . , n,
−∆1φi = 0
on each edge,
−∆2φi = 0
on each face,
−∆3φi = 0
in P.
This procedure is visualized in Figure 14.7, where the auxiliary triangulation of
∂P can be neglected for the deﬁnition. We prescribe the values at the vertices.
Afterwards, we solve 1D Laplace problems on the edges with the given data at the
vertices as boundary-values, which is equivalent to connecting the values by a linear
function. Next, 2D Laplace problems are solved on each polygonal face with the
previously deﬁned data on the edges as boundary-values. And ﬁnally, the data on
the faces is used as Dirichlet data for 3D Laplace problems in the element. Thus, we
have a hierarchical construction for the basis functions starting from the deﬁnition
at the vertices and going over the edges to the faces and ﬁnally to the elements. In
the case of a polyhedral element P with triangular faces, the two strategies result
in the same basis functions. If we have polygonal faces, however, the hierarchical
strategy has fewer basis functions compared to the original one in general.
In the realization of the approach, we have to deal with an implicit deﬁni-
tion of basis function on faces as well as on elements. To handle these two- and
three-dimensional boundary-value problems, it has been proposed to introduce an
auxiliary triangulation of the surface of P in [330]. For this reason the vertices of
each face are connected with the center of mass of this face. The resulting triangula-
tion can be reﬁned successively such that several levels of nested triangular meshes
are obtained. We denote the triangular mesh of the surface ∂P by Th(∂P). In Fig-
ure 14.7, Th(∂P) is shown for one successive reﬁnement. Afterwards, the Sobolev
spaces H1/2(∂P) and H−1/2(∂P) are discretized as usual on the surface triangu-
lation Th(∂P), see above. The piecewise linear and continuous functions in the
discrete space over Th(∂P) from the 3D BEM can be used for a 2D ﬁnite element
method on each face to approximate the basis functions φi there. Consequently,
standard 2D FEM tools are used to handle the boundary-value problems on the

BEM-Based FEM
■261
faces and standard 3D BEM tools are applied for the problems on the element. This
approach yields optimal rates of convergence for polyhedral meshes in 3D, see [330].
14.4.2
Convection-adapted basis functions in 3D
In the following, we depart from the model Laplace equation and discuss the
convection-diﬀusion equation
Lu = −ε∆u + b · ∇u = 0
(14.15)
on a bounded polyhedral domain Ω⊂R3 with constant ε > 0, b ∈R3, b ̸= 0, and
some boundary conditions. As already mentioned in the introduction, the basis
functions φi are now constructed for the diﬀerential operator L. The lowest order
basis functions fulﬁl Lφi = 0 instead of −∆φi = 0 in each polyhedral element. While
piecewise linear functions are recovered on triangular and tetrahedral meshes for
the Laplace operator, we now build-in some non-linear features of the diﬀerential
operator L into the functions φi.
The original version of the BEM-based FEM is applied in [197] to (14.15) on a
ﬁxed tetrahedral mesh in 3D. Thus, the basis functions φi are linear on the surface
triangles of the tetrahedral elements and fulﬁl the diﬀerential equation (14.15) inside
the elements. The case ε →0 is numerically analyzed. Standard methods without
additional stabilization run into oscillations for small ε, since the equation degen-
erates to a ﬁrst-order problem. The original BEM-based FEM formulation without
explicit stabilization, however, shows less oscillations due to the built-in features.
The hierarchical construction described in the previous subsection even improves
this eﬀect. In this case the basis functions φi fulﬁl certain projected convection-
diﬀusion equations on the edges and faces of the tetrahedra, see Figure 14.7 and
replace −∆by L. The results presented in [199] are even promising when compared
to a streamline upwind/Petrov-Galerkin (SUPG) ﬁnite element method, which has
explicit stabilization to treat the convection-dominated case.


C H A P T E R 15
Virtual Element Methods
for Elliptic Problems on
Polygonal Meshes
Andrea Cangiani, Oliver J. Sutton
University of Leicester, Leicester, UK
Vitaliy Gyrya, Gianmarco Manzini
Los Alamos National Laboratory, Los Alamos, USA
CONTENTS
15.1
Introduction ......................................................
264
15.2
Virtual element spaces and GBC ................................
265
15.2.1 Generalities ..............................................
265
15.2.2 Lowest order discrete space ..............................
265
15.2.3 Generalization to arbitrary order discrete spaces ........
266
15.2.4 The natural basis ........................................
267
15.2.5 A convenient basis .......................................
269
15.2.6 A link between the bases ................................
271
15.2.7 Extension to three dimensions ...........................
273
15.3
Virtual element method for elliptic PDEs .......................
273
15.3.1 Model problem ...........................................
273
15.3.2 Overview of the conforming VEM .......................
274
15.4
Connection with other methods .................................
276
15.4.1 Polygonal and polyhedral ﬁnite element method ........
276
15.4.2 Nodal MFD method .....................................
276
15.4.3 BEM-based FEM ........................................
278
263

264
■Generalized Barycentric Coordinates in Graphics and Mechanics
T
HIS CHAPTER establishes a connection between the harmonic generalized
barycentric coordinates (GBCs) and the lowest order virtual element method,
resulting from the fact that the discrete function space is the same for both meth-
ods. This connection allows us to look at the high order virtual element spaces
as a further generalization of the harmonic GBC in both two and three spatial
dimensions. We also discuss how the virtual element methodology can be used
to compute approximate solutions to PDEs without requiring any evaluation of
functions in the local discrete spaces, which are implicitly deﬁned through local
boundary-value problems.
15.1
INTRODUCTION
The virtual element method (VEM) was originally introduced in [27] as a variational
reformulation of the arbitrary order mimetic ﬁnite diﬀerence method [31, 71]; see
also [32] and the review paper [253]. The VEM is a generalization of the ﬁnite
element method (FEM), oﬀering great ﬂexibility in utilizing meshes with (almost)
arbitrary polygonal elements, and the possibility of constructing discrete spaces
incorporating an arbitrary degree of inter-element continuity [33].
The discrete space used by the lowest order conforming virtual element method
on each polygonal mesh element is simply the space of harmonic GBC. The functions
in this space are implicitly deﬁned through local Dirichlet problems. These problems
must be solved before they can be used in the standard harmonic GBC method [215].
However, the virtual element method is formulated in such a way that these local
problems do not have to be solved. Instead, projections of the functions onto a
subspace of polynomials are computed, which do not rely on evaluating the local
functions, and these projections are employed in the method.
The virtual element method also provides generalizations of the harmonic GBC
of arbitrary order, in the sense that they contain a subspace of polynomials of
speciﬁed degree. These spaces still deﬁne the functions implicitly through local
Dirichlet problems, but by carefully choosing the set of functions taken as the ba-
sis of the space, the virtual element method can still be computed without ever
having to solve (or even approximate) the local problems. Indeed, the method only
requires the knowledge of a polynomial subspace of the local ﬁnite element space
to provide stable and accurate computational methods. This is accomplished by
separating the contributions of the polynomial subspace from that of the com-
plementary non-polynomial virtual subspace through the introduction of suitable
projection operators that can be computed using only the VEM degrees of free-
dom. The polynomial consistency terms, responsible for the convergence properties
of the method, are computed accurately. The remaining terms are only required to
ensure the stability of the method, and hence they can be roughly estimated from
the degrees of freedom.
We present here a link between a natural basis of the local discrete space, asso-
ciated with a parametrization of the data of the local Dirichlet problems, and the
virtual basis that is used in practice. This construction also addresses the commonly

Virtual Element Methods for Elliptic Problems on Polygonal Meshes
■265
asked question of how the virtual element spaces can use polynomial moments as
degrees of freedom when their formal deﬁnition does not contain any explicit refer-
ence to the moments themselves.
In the rest of the chapter we discuss the construction of the local function spaces
from the perspective of generalized barycentric coordinates (Section 15.2), give a
short overview of the nodal VEM for elliptic problems (Section 15.3), and outline
the connection with similar methods, like the nodal mimetic ﬁnite diﬀerence method
and the BEM-based FEM of Chapter 14 (Section 15.4).
15.2
VIRTUAL ELEMENT SPACES AND GBC
15.2.1
Generalities
Let Ωbe an open polygonal domain in R2, partitioned by a ﬁnite mesh Ωh consist-
ing of simple polygonal elements. By “simple,” we mean that the boundary ∂P of
each polygonal mesh element P is not self-intersecting and consists of a uniformly
bounded number of straight line segments. We further assume that the intersection
of any two distinct elements of Ωh is either empty, a collection of mesh vertices, or a
collection of mesh edges. In particular, neighboring elements are permitted to share
multiple (possibly coplanar) edges. We denote the set of all edges of the element P
by EP . We also introduce the notation Pk(P) to denote the space of physical-frame
polynomials of total degree ≤k on the element P.
15.2.2
Lowest order discrete space
The lowest order local virtual element function space on the mesh element P co-
incides with the space of harmonic generalized barycentric coordinates on P, and
consists of functions satisfying the following properties:
• they are harmonic on P,
• they are linear on each edge,
• the space P1(P) of linear polynomials on P is included as a subspace.
Speciﬁcally, this space is deﬁned such that
V 1
P :=
n
vh ∈H1(P) : ∆vh = 0 in P,
v|e ∈P1(e) for each edge e of ∂P,
vh|∂P ∈C0(∂P)
o
,
and we can deﬁne a natural Lagrangian basis for this space as the set of functions
{φi}n
i=1, such that φi(vj) = δij for each vertex vj of P. This deﬁnition ensures
that these basis functions are linearly independent, and provides us with a natural
way to identify V 1
P with the space Rn by associating a vector of n numbers with
the values of a function at the n vertices of P. These values will be referred to as

266
■Generalized Barycentric Coordinates in Graphics and Mechanics
the degrees of freedom of the space. Using this basis, any function v ∈V 1
P can be
represented as:
v(x) =
n
X
i=1
v(vi)φi(x)
∀x ∈P.
(15.1)
In particular, using (15.1) with v = 1, x, y we obtain the decompositions:
n
X
i=1
φi = 1,
n
X
i=1
xiφi = x,
n
X
i=1
yiφi = y,
(15.2)
where xi and yi are the x and y coordinates of the vertex vi respectively. The ﬁrst
identity in (15.2) is the partition of unity property of barycentric coordinates, and
together with the other identities expresses the linear completeness of V 1
P .
The global functional space is constructed from the local spaces as
V 1
h =
n
v ∈H1(Ω) ∩C0(Ω) : v|P ∈V 1
P
o
,
and as global degrees of freedom we can take the values of the functions at the
vertices of the mesh, thus ensuring the continuity property of the ambient space.
While (in this case) the virtual element and harmonic GBC discrete spaces are
identical, the crucial diﬀerence between the methods lies in how these functions are
used. In particular, the virtual element method is designed in such a way that the
local PDE problems, which deﬁne the space, never have to be solved because the
method does not require evaluating the basis functions (cf. Section 15.3).
15.2.3
Generalization to arbitrary order discrete spaces
The virtual element technology provides a generalization of the local harmonic
GBC spaces to include the space of polynomials of arbitrary degree k. Extensions
to arbitrary global regularity that is more than just C0(Ω) are also possible [33].
These extra polynomials can be used to improve the accuracy and convergence rate
of the method, just like within the standard ﬁnite element method.
The general order local discrete space V k
P is constructed on the element P for any
integer k ≥1 as solutions of local Poisson problems with a polynomial right-hand
side and continuous piecewise polynomial Dirichlet boundary data, such that
V k
P :=
n
vh ∈H1(P) : ∆vh ∈Pk−2(P),
v|e ∈Pk(e) for each edge e of P,
vh|∂P ∈C0(∂P)
o
,
(15.3)
where we adopt the convention that P−1(P) = {0}. When k = 1, this deﬁnition
simply produces the space described in the previous section. Moreover, this space
will contain the space Pk(P) of physical-frame polynomials of degree k on P. As
before, the global space is constructed from the local spaces as
V k
h =
n
v ∈H1(Ω) ∩C0(Ω) : v|P ∈V k
P
o
.
(15.4)

Virtual Element Methods for Elliptic Problems on Polygonal Meshes
■267
Figure 15.1 Vertex (left), edge (middle), and interior (right) polygonal basis func-
tions for k = 2 on a square element. See color insert.
Remark 15.1. Using a Neumann-type boundary condition in the local deﬁni-
tion (15.3) leads to a diﬀerent class of virtual element spaces, known as the non-
conforming virtual elements [21, 82]. In this setting, the formal deﬁnition in (15.4)
must be changed, since non-conforming functions can be discontinuous over Ωand,
consequently, are not in H1(Ω) ∩C0(Ω). However, we will not pursue this method
any further here.
15.2.4
The natural basis
An intuitive choice of basis for the general local space V k
P is to use the degrees
of freedom of the data that deﬁne the Dirichlet problem on each element P. This
yields the set of basis functions
ψ =
n
{ψvi}n
i=1, {ψe,α}Ne
α=1 for each e ∈EP , {ψP,α}NP
α=1
o
,
where each function is the formal solution of an independent problem associated
with a vertex, edge, or the interior of P. Figure 15.1 shows an example of these
basis functions for k = 2 on a square element. From the deﬁnition of the VE spaces,
we may note that k = 2 is the lowest order case for which edge and interior basis
functions are present. Indeed, for k = 1 we only have vertex basis functions, which
are also the same for every k > 1. Here, n still denotes the number of vertices of
P, and
Ne := dim
 Pk−2(e)

= k −1;
NP := dim
 Pk−2(P)

= k(k −1)/2.
The basis functions are deﬁned as follows:
Vertex basis functions ψvi
For every vertex vi, we deﬁne the function ψvi ∈V k
P as the unique solution of the
following Poisson problem:



−∆ψvi
= 0
in P,
ψvi(vj)
= δij
for i, j = 1, . . . , n,
ψvi|e ∈P1(e)
∀e ∈EP .
(15.5)

268
■Generalized Barycentric Coordinates in Graphics and Mechanics
Remark 15.2. We could have equivalently formulated the edge-wise boundary
conditions by assuming that ψvi|e is a harmonic function with respect to a speciﬁc
local coordinate frame on e. In this way we have the following recursive construc-
tion: starting from the vertex values, we set the boundary data as the edge-wise
harmonic lifting on each edge of ∂P and then we deﬁne ψvi as the harmonic lifting
in P of such a boundary function.
These vertex basis functions coincide with those considered in Section 15.2.2,
although for k > 1 they are included alongside the extra edge and interior polygonal
basis functions. In this sense, this natural basis can be seen as an augmentation of
the standard basis of the harmonic GBC space.
Edge basis functions ψe,α
If k > 1, for every edge e ∈EP , let {qe,α}Ne
α=1 be a basis for the polynomial space
Pk(e)/P1(e) such that each qe,α is zero at the end points of e. For every index
α = 1, . . . , Ne, the function ψe,α ∈V k
P is the solution of



−∆ψe,α = 0
in P,
ψe,α|∂P =

qe,α
on e,
0
otherwise.
(15.6)
The crucial point is that the edge polynomials qe,α together with the linear poly-
nomials deﬁning the vertex basis functions (15.5) form a basis for Pk(e), meaning
that with these two sets of basis functions we have parametrized all of the possible
choices of Dirichlet data for the local problems deﬁning the space.
Interior basis functions ψP,α
Let {qP,α}NP
α=1 be a basis for the polynomial space Pk−2(P). For every index
α = 1, . . . , NP , we deﬁne ψP,α ∈V k
P to be the solution of
 −∆ψP,α
= qP,α in P,
ψP,α|∂P
= 0
in ∂P.
(15.7)
Taken together, the functions ψP,α, ψe,α, and ψvi are linearly independent and
represent a basis for V k
P . By counting them we conclude that the size of V k
P is given
by
dim
 V k
P

= n + n(k −1) + NP .
As mentioned above, the vertex and edge basis functions fully determine the be-
havior of the functions of V k
P on ∂P, because the interior polygonal basis functions
ψP,α satisfy zero Dirichlet boundary conditions.

Virtual Element Methods for Elliptic Problems on Polygonal Meshes
■269
k=1
k=2
k=3
k=4
- values at the vertices
- moments on edges
- moments inside the element
Figure 15.2 Illustration of the degrees of freedom of V k
P for k = 1, . . . , 4.
15.2.5
A convenient basis
While the basis introduced in the previous section provides an intuitive splitting of
the discrete space, using it in practice for solving PDEs requires (approximately)
solving the associated Dirichlet problem for each basis function in order to evaluate
the bilinear form of the global problem. Instead, we now describe an alternative
basis for the virtual element spaces introduced in the previous section. With this
new basis, we can gain access to partial information about the functions in V k
P
without needing to evaluate them directly, and hence without having to solve the
local boundary-value problems. From the degrees of freedom, we will be able to
compute local polynomial projections on each mesh element. In the context of the
discretization of PDEs, these piecewise-polynomial projections can then be used to
build a discrete bilinear form in such a way that the functions of V k
P never have to
be evaluated. Hence, this basis provides us with a method of using the generalized
harmonic function spaces in such a way that we never need to even approximately
solve the local boundary value problems.
For the special case of k = 1, we still take the standard vertex basis functions
familiar from harmonic GBC. However, we still construct the discrete bilinear form
in a virtual way that avoids ever having to evaluate the basis functions inside the
element, and therefore avoids solving the local Dirichlet problems.
The basis for the general order space, on the other hand, is constructed diﬀer-
ently from the natural basis. Instead of parametrizing the data of the local Dirichlet
problems, we directly parametrize the functions in the space through their values
at the vertices of the element, their moments on each edge, and their moments
inside the element. Although not particularly intuitive, this choice of degrees of
freedom is shown to be unisolvent for the space in [27] using formal arguments. In
Section 15.2.6 we show a correspondence between this basis and the natural basis
of the previous section, which can be seen as a constructive unisolvence proof.
Speciﬁcally, the basis is chosen to be the Lagrangian basis with respect to the
degrees of freedom, and is illustrated in Figure 15.2:

270
■Generalized Barycentric Coordinates in Graphics and Mechanics
Deﬁnition 15.3. The degrees of freedom of a function v ∈V k
P , k ≥1, illustrated
in Figure 15.2, are:
• the value of v at the vertices of P;
• for k > 1,
– the moments of v up to order k −2 on each edge e ∈EP :
1
|e|
ˆ
e
vmα dS
∀mα ∈Mk−2(e);
(15.8)
– the moments of v up to order k −2 inside the element P:
1
|P|
ˆ
P
vmα dS
∀mα ∈Mk−2(P).
(15.9)
where Mk(P) and Mk(e) are the sets of scaled monomials of degree k, forming a
basis of Pk(P) and Pk(e), respectively, and deﬁned such that
Mk(P) =
[
ℓ≤k
M∗
ℓ(P),
with
M∗
ℓ(P) :=
 x −xP
hP
s
,
|s| = ℓ

,
where s = (s1, s2) is a 2-index with the usual notation |s| = s1+s2 and xs = xs1
1 xs2
2 .
The scaled monomials Mk(e) are similarly deﬁned by scaling back the previous
deﬁnition to one spatial dimension.
The basis with respect to these degrees of freedom will be denoted by
φ =
n
{φvi}n
i=1, {φe,α}k−1
α=1 for each e ∈EP , {φP,α}NP
α=1
o
,
associated with the vertex, edge, and internal degrees of freedom, respectively.
While the vertex basis functions coincide with those of the natural basis in the
lowest order case k = 1, this will not be true for k > 1 since these basis functions
may no longer be linear on each edge.
This choice of degrees of freedom is particularly useful because it allows us to
compute several diﬀerent projections of functions in V k
P onto the polynomial sub-
space Pk(P) directly from the degrees of freedom of the function, requiring knowl-
edge only of the polynomial subspace. These projectors are crucial for the method
presented in Section 15.3.
For instance, we can compute the H1(P)-orthogonal projector Π∇
k
: V k
P →
Pk(P), deﬁned for v ∈V k
P to be such that
(
(∇(v −Π∇
k v), ∇p)P = 0
∀p ∈Pk(P),
´
∂P v −Π∇
k v dS = 0
where (·, ·)P denotes the L2(P) inner product. Integrating by parts, this can be
rewritten as
(∇Π∇
k v, ∇p)P =
ˆ
∂P
vn · ∇p dS −(v, ∆p)P ,

Virtual Element Methods for Elliptic Problems on Polygonal Meshes
■271
where n denotes the unit vector normal to ∂P. The terms on the right-hand side of
the above equation can be expressed through the degrees of freedom of v. The ﬁrst
term can be computed exactly because n · ∇p is a polynomial of degree k −1 on
each edge of P, while ∆p is a polynomial of degree k −2 inside P, so the ﬁrst and
the second terms are simply a sum of, respectively, the edge and internal degrees of
freedom of v. Clearly, however, this projection would not be so straightforward to
compute using the natural basis of Section 15.2.4. Expanding Π∇
k v in the basis of
Pk(P) and varying p over the basis of Pk(P), it is clear that this provides a linear
system of equations that can be solved for the coeﬃcients of Π∇
k v.
Similarly, we can compute the L2(P)-orthogonal projection of the gradient onto
polynomials, deﬁned such that
(∇v −Π0
k−1∇v, p )P = 0
∀p ∈(Pk−1(P))2,
where (Pk−1(P))2 denotes the space of vector-valued polynomials of degree k −1.
This projection is computed in a similar way, by integrating by parts to ﬁnd that
(Π0
k−1∇v, p)P =
ˆ
∂P
vn · p dS −(v, ∇· p)P ,
and observing that the terms on the right are exactly computable as before.
15.2.6
A link between the bases
We now establish a correspondence between the natural basis ψ of Section 15.2.4
and the virtual basis φ of Section 15.2.5. To this end, we deﬁne a linear transfor-
mation that maps the ψ basis to the φ basis:
φP,α =
X
1≤γ≤NP
CP,α
P,γ ψP,γ
1 ≤α ≤NP ,
(15.10)
φe,α =
X
1≤γ≤NP
Ce,α
P,γψP,γ +
X
e′∈EP ,
1≤γ≤k−1
Ce,α
e′,γψe′,γ
∀e ∈EP , 1 ≤α ≤k −1,
(15.11)
φvi =
X
1≤γ≤NP
Cvi
P,γψP,γ +
X
e′∈EP ,
1≤γ≤k−1
Cvi
e′,γψe′,γ + ψvi
1 ≤i ≤n.
(15.12)
The system (15.10)–(15.12) may then be solved for the “C” coeﬃcients in the
three consecutive steps explained in the following paragraphs. Note the reverse
order of this construction: we ﬁrst solve for the interior basis functions φP,α, then
for the edge basis functions φe,α, and ﬁnally for the vertex basis functions φvi. This
derivation can also be seen as an alternative constructive proof of the unisolvency
of the degrees of freedom of Deﬁnition 15.3.

272
■Generalized Barycentric Coordinates in Graphics and Mechanics
Interior basis functions φP,α
These are the basis functions associated with the internal degrees of freedom
in (15.9). We determine the coeﬃcients CP,α
P,γ in (15.10) for 1 ≤α, γ ≤NP by
explicitly requiring that
ˆ
P
φP,αqP,β dV = δα,β,
1 ≤α, β ≤NP .
Edge basis functions φe,α
These are the basis functions associated with the edge degrees of freedom in (15.8).
In (15.11), we determine the coeﬃcients Ce,α
e′,γ by explicitly requiring that
ˆ
e′ φe,αqe′,β dS =
(
δα,β,
for e = e′,
0,
otherwise
∀e, e′ ∈EP ,
1 ≤α,
β ≤k −1,
and the coeﬃcients Ce,α
P,γ by explicitly requiring that
ˆ
P
φe,αqP,β dV = 0
∀e ∈EP ,
1 ≤α ≤k −1,
1 ≤β ≤NP .
Vertex basis functions φvi
These are the basis functions associated with the cell vertices according to Def-
inition 15.3. The canonical condition φvi(xj) = δij is automatically satisﬁed by
the deﬁnition given in (15.12) since ψvi(xj) = δij, while ψe,γ(xj) = 0 for every
e ∈EP and 1 ≤γ ≤k −1, and ψP,γ(xj) = 0 for every 1 ≤γ ≤NP . Hence, the
coeﬃcients “C” on the right-hand side of (15.12) must be determined so that all
internal moments and edge moments of each φvi are zero. To this end, we require
that the coeﬃcients Cvi
e′,γ of (15.12) satisfy the condition
ˆ
e
φviqe,β dS = 0
∀vi ∈∂P,
∀e ∈EP ,
1 ≤β ≤k −1,
and the coeﬃcients Cvi
P,γ satisfy the condition:
ˆ
P
φviqP,β dV = 0
∀vi ∈∂P, 1 ≤β ≤NP .
It is easy to prove that the above set of conditions is unisolvent and hence the
two bases represent the same space. However, we stress that the VEM uses the
virtual basis directly through the corresponding degrees of freedom, and none of
the local basis functions are ever computed or evaluated in practice.

Virtual Element Methods for Elliptic Problems on Polygonal Meshes
■273
15.2.7
Extension to three dimensions
We now brieﬂy consider the situation when Ωis a subset of R3. In this case, Ωh
is assumed to be a mesh consisting of very general shaped polyhedra with planar
faces and straight edges, and the virtual space (15.3) is deﬁned by taking
V k
P :=
n
vh ∈H1(P) : ∆vh ∈Pk−2(P);
v|e ∈V k
f for each face f of P;
vh|∂P ∈C0(∂P)
o
,
(15.13)
where V k
f is the two-dimensional discrete space on the face f, introduced in Sec-
tion 15.2.3 (with the convention that P−1(P) = {0}).
As for the two-dimensional case, two equivalent bases for this space can be
considered: the natural basis, deﬁned through a set of Dirichlet problems from the
space deﬁnition (15.13); a virtual basis, deﬁned through the degrees of freedom
associated with the vertex values and the moments on the edges, the faces, and
the interior of element P. However, in the 3D case the orthogonal projections of
Section 15.2.5 cannot be computed directly using these degrees of freedom, since
this would require the knowledge of the moments of order up to k −1 and k on the
element faces, which are not available from (15.13).
To get around this problem, the space must be modiﬁed in such a way that
these extra moments are available. One approach is to simply expand the space by
relaxing the conditions required in its deﬁnition such that the extra moments can
be taken as degrees of freedom. However, this results in a signiﬁcant increase in the
dimension of the space and therefore the size of the ﬁnal matrix. Instead, a process
known as VEM enhancement has been developed (see [6, 82]) to produce a space
with the same virtual degrees of freedom as V k
P , but in which these moments may
be computed. We point out that although the virtual degrees of freedom remain
unchanged, the natural basis for V k
P is no longer valid for the enhanced space.
15.3
VIRTUAL ELEMENT METHOD FOR ELLIPTIC PDES
15.3.1
Model problem
Consider the diﬀusion of the scalar variable u, which satisﬁes the following Poisson
problem (we refer to [29, 82] for a treatment of more general elliptic problems):
−div(K∇u) = f
in Ω,
(15.14)
u = g
on ∂Ω,
(15.15)
where K is the diﬀusion tensor, f is the forcing term, and g deﬁnes the (typically
non-homogeneous) Dirichlet boundary condition. We assume that:
(H1) Ωis a bounded, open, polytopal subset of Rd;

274
■Generalized Barycentric Coordinates in Graphics and Mechanics
(H2) the diﬀusion tensor K : Ω→Rd×d is a d × d bounded, measurable, and
symmetric tensor. Moreover, we assume that K is strongly elliptic, i.e., there
exist two positive constants C∗and C∗such that, for almost every x ∈Ω,
C∗||ξ||2 ≤ξ · K(x)ξ ≤C∗||ξ||2
∀ξ ∈Rd,
where ||ξ||2 = ξ · ξ is the square of the Euclidean 2-norm of ξ;
(H3) the two functions f and g belong to L2(Ω) and H
1
2 (∂Ω), respectively.
The variational form of the problem (15.14)–(15.15) reads:
ﬁnd u ∈H1
g(Ω) such that
A
 u, v

:=
ˆ
Ω
K∇u · ∇v dV =
ˆ
Ω
fv dV
∀v ∈H1
0(Ω),
(15.16)
where
H1
g(Ω) :=

u ∈H1(Ω) | u|∂Ω= g
	
.
The existence of a unique weak solution to (15.16) follows from the continuity and
coercivity of the bilinear form A
 ·, ·

under Assumptions (H1)–(H3).
15.3.2
Overview of the conforming VEM
In the conforming virtual element method we approximate the symmetric, bilinear
form A
 ·, ·

with the symmetric bilinear form Ah
 ·, ·

that can be exactly computed
without having to evaluate the functions of the virtual space. Moreover, Ah
 ·, ·

should exactly evaluate A
 ·, ·

when at least one of its entries is a polynomial of
degree k ≥1. This property is called polynomial consistency and can be stated as:
Ah
 v, p

= A
 v, p

,
which holds for any v ∈Vh and piecewise k-degree polynomial function p deﬁned on
Ωh. The polynomial consistency property determines the accuracy of the method.
Beyond this, we merely require Ah
 ·, ·

to be stable with respect to A
 ·, ·

when the
trial and test functions are non-polynomial. The right-hand side of (15.16) is also
discretized through a similar process. Finally, the Dirichlet boundary conditions of
the original problem are imposed in the virtual element formulation by deﬁning V k
h,g
as the aﬃne subspace of V k
h whose functions interpolate the boundary condition
g on ∂Ω. In a practical implementation, the boundary conditions on the virtual
functions of V k
h,g are imposed by restricting their degrees of freedom associated with
the vertices, and edges lying on ∂Ω, to coincide with vertex values and boundary
moments of g.
The virtual element approximation to (15.16) reads: ﬁnd uh ∈V k
h,g such that:
Ah
 uh, vh

=
 f, vh

h
∀vh ∈V k
h,0.
(15.17)

Virtual Element Methods for Elliptic Problems on Polygonal Meshes
■275
The well-posedness of this problem follows from the well-posedness of (15.16)
through the stability property mentioned above. The discrete bilinear form
in (15.17) is deﬁned as the sum of local contributions
Ah
 uh, vh

=
X
P ∈Ωh
AP
h
 uh, vh

,
each elemental term of which is the sum of a consistency term and a stability term,
AP
h
 uh, vh

= AP
cons(uh, vh) + AP
stab(uh, vh),
where
AP
cons(uh, vh) =
ˆ
P
K Π0
k−1∇uh · Π0
k−1∇vh dV,
AP
stab(uh, vh) = KP SP
 (I −Π∇
k )uh, (I −Π∇
k )vh

,
with Π0
k−1 and Π∇
k deﬁned as in Section 15.2.5. Here, KP is a constant approxi-
mation of K on P, as for example, its cell average or its value at the barycenter of
the cell, and SP : V k
P × V k
P →R is the bilinear form
SP (uh, vh) :=
n
X
r=1
dofr(uh)dofr(vh),
where, for wh ∈V k
P , we use dofr(wh) to denote the value of the r-th degree of
freedom of wh with respect to some arbitrary but ﬁxed ordering of the local degrees
of freedom. This bilinear form is just the Euclidean inner product on the space Rn
of vectors of degrees of freedom. The right-hand side is discretized as
(f, vh)h :=
X
P ∈Ωh
ˆ
P
fΠ0
k−2vh dV.
Remark 15.4. This approximation is sub-optimal in the L2-norm for k = 1, 2.
However, for these cases it is possible to construct alternative approximations of
the right-hand side, which makes the method optimal.
Under fairly general mesh assumptions [82], it may be shown that there exists
a constant C independent of h and P such that
C−1AP  vh, vh

≤AP
h
 vh, vh

≤CAP  vh, vh

for all vh ∈V k
P , which provides the stability of the method and ensures the existence
of a unique discrete solution. Moreover, only the ﬁrst term of AP
h
 ·, ·

will be non-
zero when either uh or vh is a polynomial, and when both are polynomials the
bilinear form will exactly evaluate AP  ·, ·

.
All terms can be evaluated using only the degrees of freedom and the ability
to evaluate and integrate polynomials. Implementation details can be found in [28,
386]. In particular, no pointwise evaluation of the virtual functions other than the
polynomial subspace is ever required. Given the virtual nature of the method, the
numerical solution is known in the form of its degrees of freedom, i.e., nodal values
and moments, from which a global continuous solution is obtained by interpolation.

276
■Generalized Barycentric Coordinates in Graphics and Mechanics
15.4
CONNECTION WITH OTHER METHODS
In recent years, there has been a growing interest in numerical methods for PDEs
on general polygonal and polynomial meshes. We refer, for example, to the mimetic
ﬁnite diﬀerence (MFD) method [32, 253], composite ﬁnite elements (CFEs) in both
their conforming [184] and discontinuous Galerkin (dG) [11] version related to
the agglomeration dG method [25], hp-dG [80], HDG [105], weak Galerkin meth-
ods [287], Hybrid high-order (HHO) methods [123], polygonal ﬁnite element method
[378], BEM-based FEM [421], extended ﬁnite element method [158], and gradient
scheme [126], to mention just a few. In this section, we discuss methods in the above
list that are related to the VEM. In particular, PFEM and BEM-based FEM are
based on similar discretizations spaces. The VEM approach can also be viewed as
a variational analogue of the MFD method.
15.4.1
Polygonal and polyhedral ﬁnite element method
Assuming that we know how to compute the basis functions at any point of P, a
ﬁnite element formulation is readily available for polygonal and polyhedral elements.
For the lowest-order case (i.e., for k = 1), such a method coincides with an instance
of the PFEM method. For a more detailed discussion, see, for instance, the review
in [268, 378]. For k > 1, the calculation of the integrals of the stiﬀness matrix and
the right-hand side would be very expensive, which would render this approach
to be non-competitive with other methods, and in particular, with the VEM. A
diﬀerent strategy based on approximating the Poisson problems that provide the
basis functions can be devised by reformulating such problems as boundary element
problems [421]. More details are discussed in Section 15.4.3.
15.4.2
Nodal MFD method
In this section, we compare the formulation of the conforming VEM to that of the
mimetic ﬁnite diﬀerence method [32, 253] for the model problem presented in Sec-
tion 15.3.1. For simplicity of exposition we assume that the diﬀusion tensor K is
piecewise constant on Ωh and denote its restriction to P by KP . The major dif-
ference between the two formulations is that the MFD method follows a discrete
approach like that of ﬁnite volumes, whereas the VEM relies on a continuous vari-
ational formulation like that of the ﬁnite element method. In fact, the conforming
VEM is a variational reformulation of the nodal MFD method proposed in [31, 71]
and the two families of schemes are equivalent up to the stability term.
To ease the notation at the price of a minor inconsistency, we will use the symbols
Ah and AP
h to denote the global and local discrete operators provided by the MFD
method. We will also continue referring to them as “bilinear forms” although these
operators are matrices that act directly on the degrees of freedom through a matrix-
vector product. Moreover, in this section uh, vh represent both continuous functions
and the associated “grid functions,” whose values are associated with geometric
objects such as vertices, edges, faces, and cells. We represent uh and vh as the

Virtual Element Methods for Elliptic Problems on Polygonal Meshes
■277
Ndofs-sized column vectors Uh and Vh, respectively, where Ndofs is the total number
of degrees of freedom.
Just like in the VEM approach, the global bilinear form Ah is assembled as the
sum of local contributions AP
h
 uh, vh

. The elemental bilinear form AP
h
 ·, ·

is now
built to explicitly satisfy the two following conditions:
• (S1) Polynomial Consistency: for any p ∈Pk(P) and any grid function uh, it
holds that
AP
h
 uh, p

= A
 uh, p

.
(15.18)
• (S2) Stability: there exist two constants α∗> α∗> 0 independent of the
mesh, such that for any uh it holds that
α∗A
 uh, uh

≤AP
h
 uh, uh

≤α∗A
 uh, uh

.
(15.19)
The conditions (S1)–(S2) are also satisﬁed in the VEM. However, these conditions
are an explicit part of the MFD construction process, whereas in the VEM they
are the consequence of the formulation of the method.
The action of the mimetic bilinear form on the degrees of freedom of uh and vh
is expressed by
AP
h
 vh, uh

= V T
h AP Uh,
where AP is a positive semideﬁnite matrix. After an integration by parts, the
polynomial consistency condition (15.18) can be restated as
U T
h AP Nα =
ˆ
P
∇uh · KP ∇mα dV
= −
ˆ
P
uh div (KP ∇mα) dV +
X
e∈EP
ˆ
e
uh ne · KP ∇mα dS
= U T
h Rα,
(15.20)
where mα is a scaled monomial of Mk(P), Nα the column vector of its degrees
of freedom, and Rα the corresponding column vector of coeﬃcients determined
by (15.20). Assembling all column vectors Nα and Rα into the column-partitioned
matrices N =
 Nα

and R =
 Rα

and noting that Uh is arbitrary, we can rewrite
the consistency conditions (15.20) in matrix form as
AP N = R.
(15.21)
On a general d-dimensional polytope, (15.21) provides an underdetermined linear
system that has a non-unique solution. A possible solution to (15.21) is:
AP
cons := R
 RT N
†RT ,
(15.22)

278
■Generalized Barycentric Coordinates in Graphics and Mechanics
where
 RT N
† denotes the pseudo-inverse of (RT N) (note that matrix RT N is
the stiﬀness matrix of the scaled monomials Mk(P) and thus is singular).
Matrix AP
cons as deﬁned by (15.22) does not satisfy the stability condition (15.19)
due to an enlarged kernel. Hence a stability term has to be added, which is given
by
AP
stab := N⊥SNT
⊥,
where S is a symmetric, positive deﬁnite matrix, and the columns of N⊥are or-
thogonal to the columns of N and such that the span of N and N⊥is RNdofs. From
the orthogonality NT
⊥N = 0 it follows that AP
stabN = 0. Thus, for any choice of S,
the combined matrix
AP = AP
cons + AP
stab
still satisﬁes the consistency condition (15.21). The stability condition is satisﬁed
by taking S to be spectrally equivalent to the non-zero part of AP
cons. A particularly
simple but rather eﬀective choice for S is the scalar matrix tr(AP
cons)|P|I, where
tr(AP
cons) is the trace of matrix AP
cons.
The choice of S can be optimized for a particular set of criteria [183]. This
optimization process is dubbed “mimetic adaptation” or “m-adaptation” and can
lead to certain improvements of the scheme such as attaining a discrete form of
maximum/minimum principles [254] or reducing the numerical dispersion for wave
problems by several orders of magnitude on structured meshes [59, 182].
15.4.3
BEM-based FEM
A direct evaluation of the basis functions of V k
P for k > 1 would require the ap-
proximation of the variational problems that deﬁne them on P. A few attempts
have been made along this direction by meshing each element and solving the Pois-
son problems through a local ﬁnite element approximation. However, such a direct
approach is prohibitive for its complexity and the related computational costs. An
interesting alternative is found in the BEM-based FEM ﬁrst introduced in [107]
and reported in Chapter 14. We also refer to [421] for the two-dimensional case
and [330] for the three-dimensional case.
In the two-dimensional case, the set of basis functions considered by the BEM-
based FEM is precisely the one in Section 15.2.4 for all polynomial degrees, cf. Chap-
ter 14. Therefore, the evaluation of the basis functions can be dealt with by re-
writing the Poisson boundary-value problems (15.5), (15.6), and (15.7) as boundary
element problems for the conormal derivative deﬁned on the elemental boundary.
This latter problem is then solved by a standard ﬁnite element method, whence
the coining of the method as BEM-based FEM. Computational costs and complex-
ity are reduced since the approximation is one-dimensional. Indeed, although the
boundary element formulation leads to full matrices, these are rather small as no
additional ﬁner discretization of the boundary is needed.
Here we summarize how the local bases (associated with each vertex, edge, or
face) of Section 15.2.4 can be approximated using the BEM approach and their
use within the BEM-based FEM. The problem for an interior basis can always be

Virtual Element Methods for Elliptic Problems on Polygonal Meshes
■279
treated by transforming it into a problem with homogeneous right-hand-side and
non-homogeneous boundary data (cf. [421]).
Therefore, we only need to consider the case of a vertex or edge basis function,
which solves a problem such as:
 −∆φ = 0
in P,
φ|∂P = g,
(15.23)
where g ∈C(∂P) is polynomial on each edge.
Let γP
0 φ and γP
1 φ = nP ·γP
0 ∇φ denote, respectively, the trace and the Neumann
trace of φ. It is well known that the solution operator for (15.23) can be seen as
a map of the trace into the Neumann trace (Dirichlet-to-Neumann or Steklov–
Poincaré operator). Formally,
γP
1 φ = SP γP
0 φ.
(15.24)
The Steklov–Poincaré operator is obtained by considering the representation for-
mula for the solution of (15.23):
φ(x) =
ˆ
∂P
U ∗(x, y)γP
1 φ(y)dsy −
ˆ
∂P
γP
1,yU ∗(x, y)γP
0 φ(y)dsy
(15.25)
for x ∈P, where U ∗(x, y) := −1
2π ln |x −y| is the fundamental solution of the
negative Laplacian in two dimensions. Taking the trace of the above yields the
following problem for γP
1 φ:
VP γP
1 φ = (1
2I + KP )γP
0 φ,
(15.26)
where VP and KP are the single-layer and double-layer potential operators and
I is the identity operator, from which (15.24) is derived; see Chapter 14 or [367]
for details. The BEM now consists of: (1) discretizing problem (15.26) with the
use of ﬁnite element methods to compute numerical approximations g
γP
1 φ, and (2)
evaluating the approximation eφ inside P by the representation formula (15.25). A
guide on fast numerical approaches to boundary integral equations is given in [328].
Now, suppose we seek the numerical solution of problem (15.16). Here we as-
sume that the diﬀusion coeﬃcient is a piecewise constant scalar, say κ. Then
the BEM-based FEM operates as follows. First, following the approach described
above, compute on each P ∈Ωh a numerical approximation to each basis function
in (15.5), (15.6), and (15.7). Second, solve the discrete problem (15.17) with
Ah
 uh, vh

=
X
P ∈Ωh
AP
h
 uh, vh

=
X
P ∈Ωh
ˆ
∂P
]
γP
1 uh γP
0 vh ds −
ˆ
P
∆uh f
vh dV
(f, vh)h =
X
P ∈Ωh
ˆ
P
ff
vh dV.
The advantage of this approach is that no element-wise sub-meshing is required,
although some form of volumetric quadrature is still needed in order to compute
the volumetric terms in the previous equations.


Bibliography
[1] A. Abdollahi, D. Millán, C. Peco, M. Arroyo, and I. Arias. Revisiting pyramid com-
pression to quantify ﬂexoelectricity: A three-dimensional simulation study. Physical
Review B, 91(10):Article 104103, 8 pages, 2015.
[2] A. Abdollahi, C. Peco, D. Millán, M. Arroyo, G. Catalan, and I. Arias. Fracture
toughening and toughness asymmetry induced by ﬂexoelectricity. Physical Review
B, 92(9):Article 094101, 6 pages, 2015.
[3] R. A. Adams and J. Fournier. Cone conditions and properties of Sobolev spaces.
Journal of Mathematical Analysis and Applications, 61(3):713–734, 1977.
[4] R. A. Adams and J. J. F. Fournier. Sobolev Spaces, volume 140 of Pure and Applied
Mathematics. Academic Press, Amsterdam, 2nd edition, 2003.
[5] L. V. Ahlfors. Complex Analysis. International Series in Pure and Applied Mathe-
matics. McGraw-Hill, New York, 3rd edition, 1979.
[6] B. Ahmad, A. Alsaedi, F. Brezzi, L. D. Marini, and A. Russo.
Equivalent pro-
jectors for virtual element methods. Computers & Mathematics with Applications,
66(3):376–391, 2013.
[7] N. Al Shenk. Uniform error estimates for certain narrow Lagrange ﬁnite elements.
Mathematics of Computation, 63(207):105–119, 1994.
[8] M. Alexa and M. Wardetzky.
Discrete Laplacians on general polygonal meshes.
ACM Transactions on Graphics, 30(4):Article 102, 10 pages, 2011.
[9] P. Alliez, D. Cohen-Steiner, M. Yvinec, and M. Desbrun. Variational tetrahedral
meshing. ACM Transactions on Graphics, 24(3):617–625, 2005.
[10] D. Anisimov, C. Deng, and K. Hormann. Subdividing barycentric coordinates. Com-
puter Aided Geometric Design, 43:172–185, 2016.
[11] P. F. Antonietti, S. Giani, and P. Houston. hp–Version composite discontinuous
Galerkin methods for elliptic problems on complicated domains. SIAM Journal on
Scientiﬁc Computing, 35(3):A1417–A1439, 2013.
[12] D. N. Arnold, R. S. Falk, and R. Winther. Finite element exterior calculus, homo-
logical techniques, and applications. Acta Numerica, 15:1–155, 2006.
[13] V. I. Arnold and B. A. Khesin. Topological Methods in Hydrodynamics, volume 125
of Applied Mathematical Sciences. Springer, New York, 1998.
[14] M. Arroyo, L. Heltai, D. Millán, and A. DeSimone. Reverse engineering the euglenoid
movement. Proceedings of the National Academy of Sciences, 109(44):17874–17879,
2012.
[15] M. Arroyo and M. Ortiz. Local maximum-entropy approximation schemes: A seam-
less bridge between ﬁnite elements and meshfree methods. International Journal for
Numerical Methods in Engineering, 65(13):2167–2202, 2006.
281

282
■Bibliography
[16] M. Arroyo and M. Ortiz.
Local maximum-entropy approximation schemes.
In
M. Griebel and M. A. Schweitzer, editors, Meshfree Methods for Partial Diﬀerential
Equations III, volume 57 of Lecture Notes in Computational Science and Engineer-
ing, pages 1–16. Springer, Berlin, 2007.
[17] S. N. Atluri and E. Reissner. On the formulation of variational theorems involving
volume constraints. Computational Mechanics, 5(5):337–344, 1989.
[18] F. Aurenhammer. A criterion for the aﬃne equivalence of cell complexes in Rd and
convex polyhedra in Rd+1. Discrete & Computational Geometry, 2(1):49–64, 1987.
[19] F. Aurenhammer. Power diagrams: properties, algorithms, and applications. SIAM
Journal on Computing, 16(1):78–96, 1987.
[20] F. Aurenhammer. Recognising polytopical cell complexes and constructing projec-
tion polyhedra. Journal of Symbolic Computation, 3(3):249–255, 1987.
[21] B. Ayuso de Dios, K. Lipnikov, and G. Manzini. The nonconforming virtual element
method. ESAIM: Mathematical Modelling and Numerical Analysis, 50(3):879–904,
2016.
[22] I. Babuška and A. K. Aziz. On the angle condition in the ﬁnite element method.
SIAM Journal on Numerical Analysis, 13(2):214–226, 1976.
[23] K. Bagi. When Heyman’s Safe Theorem of rigid block systems fails: Non-Heymanian
collapse modes of masonry structures. International Journal of Solids and Struc-
tures, 51(14):2696–2705, 2014.
[24] B. R. Baliga and S. V. Patankar. A control volume ﬁnite-element method for two-
dimensional ﬂuid ﬂow and heat transfer. Numerical Heat Transfer, 6(3):245–261,
1983.
[25] F. Bassi, L. Botti, A. Colombo, D. Di Pietro, and P. Tesini. On the ﬂexibility of
agglomeration based physical space discontinuous Galerkin discretizations. Journal
of Computational Physics, 231(1):45–65, 2012.
[26] C. Batty, S. Xenos, and B. Houston. Tetrahedral embedded boundary methods for
accurate and ﬂexible adaptive ﬂuids. Computer Graphics Forum, 29:695–704, 2010.
[27] L. Beirão da Veiga, F. Brezzi, A. Cangiani, G. Manzini, L. D. Marini, and A. Russo.
Basic principles of virtual element methods. Mathematical Models and Methods in
Applied Sciences, 23(1):199–214, 2013.
[28] L. Beirão da Veiga, F. Brezzi, L. D. Marini, and A. Russo. The hitchhiker’s guide to
the virtual element method. Mathematical Models and Methods in Applied Sciences,
24(8):1541–1573, 2014.
[29] L. Beirão da Veiga, F. Brezzi, L. D. Marini, and A. Russo. Virtual element method
for general second-order elliptic problems on polygonal meshes. Mathematical Models
and Methods in Applied Sciences, 26(4):729–750, 2016.
[30] L. Beirão da Veiga and K. Lipnikov. A mimetic discretization of the Stokes problem
with selected edge bubbles. SIAM Journal on Scientiﬁc Computing, 32(2):875–893,
2010.
[31] L. Beirão da Veiga, K. Lipnikov, and G. Manzini. Arbitrary-order nodal mimetic dis-
cretizations of elliptic problems on polygonal meshes. SIAM Journal on Numerical
Analysis, 49(5):1737–1760, 2011.

Bibliography
■283
[32] L. Beirão da Veiga, K. Lipnikov, and G. Manzini. The Mimetic Finite Diﬀerence
Method for Elliptic Problems, volume 11 of MS&A – Modeling, Simulation and Ap-
plications. Springer, Cham, 2014.
[33] L. Beirão da Veiga and G. Manzini. A virtual element method with arbitrary regu-
larity. IMA Journal of Numerical Analysis, 34(2):759–781, 2014.
[34] V. V. Belikov, V. D. Ivanov, V. K. Kontorovich, S. A. Korytnik, and A. Y. Semenov.
The non-Sibsonian interpolation: A new method of interpolation of the values of a
function on an arbitrary set of points. Computational Mathematics and Mathemat-
ical Physics, 37(1):9–15, 1997.
[35] M. Belkin, J. Sun, and Y. Wang. Constructing Laplace operator from point clouds
in Rd. In Proceedings of the 20th Annual ACM-SIAM Symposium on Discrete Algo-
rithms (SODA 2009), pages 1031–1040, 2009.
[36] S. R. Bell. The Cauchy Transform, Potential Theory and Conformal Mapping. Stud-
ies in advanced Mathematics. CRC Press, Boca Raton, 1992.
[37] A. Belyaev. On transﬁnite barycentric coordinates. In Proceedings of the 4th Euro-
graphics Symposium on Geometry Processing (SGP 2006), pages 89–99, 2006.
[38] A. Belyaev and P.-A. Fayolle. On transﬁnite Gordon-Wixom interpolation schemes
and their extensions. Computers & Graphics, 51:74–80, 2015.
[39] A. Belyaev and P.-A. Fayolle.
On variational and PDE-based distance function
approximations. Computer Graphics Forum, 34(8):104–118, 2015.
[40] A. Belyaev, P.-A. Fayolle, and A. Pasko. Signed Lp-distance ﬁelds. Computer-Aided
Design, 45(2):523–528, 2013.
[41] T. Belytschko, W. K. Liu, B. Moran, and K. I. Elkhodary. Nonlinear Finite Elements
for Continua and Structures. Wiley, Chichester, 2nd edition, 2014.
[42] M. Ben-Chen, O. Weber, and C. Gotsman. Variational harmonic maps for space
deformation. ACM Transactions on Graphics, 28(3):Article 34, 11 pages, 2009.
[43] M. Berger. A Panoramic View of Riemannian Geometry. Springer, Berlin, 2003.
[44] M. Biot. Surface instability of rubber in compression. Applied Scientiﬁc Research.
Section A, 12(2):168–182, 1963.
[45] J. E. Bishop. Rapid stress analysis of geometrically complex domains using implicit
meshing. Computational Mechanics, 30(5):460–478, 2003.
[46] J. E. Bishop. Simulating the pervasive fracture of materials and structures using
randomly close packed Voronoi tessellations. Computational Mechanics, 44(4):455–
471, 2009.
[47] J. E. Bishop. A displacement-based ﬁnite element formulation for general polyhedra
using harmonic shape functions. International Journal for Numerical Methods in
Engineering, 97(1):1–31, 2014.
[48] J. E. Bishop, J. M. Emery, R. V. Field, C. R. Weinberger, and D. J. Littlewood.
Direct numerical simulations in solid mechanics for understanding the macroscale
eﬀects of microscale material variability. Computer Methods in Applied Mechanics
and Engineering, 287:262–289, 2015.
[49] J. E. Bishop, M. J. Martinez, and P. Newell. Simulating fragmentation and ﬂuid-
induced fracture in disordered media using random ﬁnite element meshes. Interna-
tional Journal for Multiscale Computational Engineering, 14(4):349–366, 2016.

284
■Bibliography
[50] J. E. Bishop and O. E. Strack. A statistical method for verifying mesh convergence
in Monte Carlo simulations with application to fragmentation. International Journal
for Numerical Methods in Engineering, 88(3):279–306, 2011.
[51] A. Biswas, V. Shapiro, and I. Tsukanov.
Heterogeneous material modeling with
distance ﬁelds. Computer Aided Geometric Design, 21(3):215–242, 2004.
[52] P. Block. Thrust Network Analysis: Exploring Three-Dimensional Equilibrium. PhD
thesis, Massachusetts Institute of Technology, 2009.
[53] P. Block and L. Lachauer. Closest-ﬁt, compression-only solutions for free form shells.
In Proceedings of the Jointly Organized 35th Annual Symposium of IABSE and 52nd
Annual Symposium of IASS, 2011.
[54] P. Block and J. Ochsendorf. Thrust network analysis: A new methodology for three-
dimensional equilibrium.
Journal of the International Association for Shell and
Spatial Structures, 48(3):167–173, 2007.
[55] T. Bobach, M. Hering-Bertram, and G. Umlauf.
Comparison of Voronoi based
scattered data interpolation schemes. In Proceedings of Visualization, Imaging, and
Image Processing (VIIP 2006), pages 342–349, 2006.
[56] A. I. Bobenko, H. Pottmann, and J. Wallner. A curvature theory for discrete surfaces
based on mesh parallelity. Mathematische Annalen, 348(1):1–24, 2010.
[57] A. I. Bobenko and B. A. Springborn.
A discrete Laplace–Beltrami operator for
simplicial surfaces. Discrete & Computational Geometry, 38(4):740–756, 2007.
[58] D. Boﬃ, F. Brezzi, and M. Fortin. Mixed Finite Element Methods and Applications,
volume 44 of Springer Series in Computational Mathematics. Springer, Heidelberg,
2013.
[59] V. A. Bokil, N. L. Gibson, V. Gyrya, and D. A. McGregor. Dispersion reducing
methods for edge discretizations of the electric vector wave equation. Journal of
Computational Physics, 287:88–109, 2015.
[60] J. E. Bolander and S. Saito. Fracture analyses using spring networks with random
geometry. Engineering Fracture Mechanics, 61(5–6):569–591, 1998.
[61] D. Bommes, B. Lévy, N. Pietroni, E. Puppo, C. Silva, M. Tarini, and D. Zorin.
Quad-mesh generation and processing: A survey. Comput. Graph. Forum, 32(6):51–
76, 2013.
[62] A. Bompadre, L. E. Perotti, C. J. Cyron, and M. Ortiz. Convergent meshfree approx-
imation schemes of arbitrary order and smoothness. Computer Methods in Applied
Mechanics and Engineering, 221–222:83–103, 2012.
[63] J. Bonet and R. D. Wood.
Nonlinear Continuum Mechanics for Finite Element
Analysis. Cambridge University Press, Cambridge, 2nd edition, 2008.
[64] M. J. Borden, T. J. R. Hughes, C. M. Landis, and C. V. Verhoosel. A higher-order
phase-ﬁeld model for brittle fracture: Formulation and analysis within the isogeomet-
ric analysis framework. Computer Methods in Applied Mechanics and Engineering,
273:100–118, 2014.
[65] A. Bossavit. Computational Electromagnetism. Electromagnetism. Academic Press,
San Diego, 1998.
[66] M. Botsch, L. Kobbelt, M. Pauly, P. Alliez, and B. Lévy. Polygon Mesh Processing.
A K Peters, Natick, 2010.

Bibliography
■285
[67] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press,
Cambridge, 2004.
[68] S. K. Boyd and R. Muller. Smooth surface meshing for automated ﬁnite element
model generation from 3D image data. Journal of Biomechanics, 39(7):1287–1295,
2006.
[69] J. H. Bramble and S. R. Hilbert. Estimation of linear functionals on Sobolev spaces
with application to Fourier transforms and spline interpolation. SIAM Journal on
Numerical Analysis, 7(1):112–124, 1970.
[70] S. C. Brenner and L. R. Scott. The Mathematical Theory of Finite Element Methods,
volume 15 of Texts in Applied Mathematics. Springer, New York, 3rd edition, 2008.
[71] F. Brezzi, A. Buﬀa, and K. Lipnikov. Mimetic ﬁnite diﬀerences for elliptic problems.
ESAIM: Mathematical Modelling and Numerical Analysis, 43(2):277–295, 2009.
[72] F. Brezzi, R. S. Falk, and L. D. Marini. Basic principles of mixed virtual element
methods.
ESAIM: Mathematical Modelling and Numerical Analysis, 48(4):1227–
1240, 2014.
[73] F. Brezzi, K. Lipnikov, and M. Shashkov. Convergence of mimetic ﬁnite diﬀerence
methods for diﬀusion problems on polyhedral meshes. SIAM Journal on Numerical
Analysis, 43(5):1872–1896, 2005.
[74] F. Brezzi, K. Lipnikov, and V. Simoncini.
A family of mimetic ﬁnite diﬀerence
methods on polygonal and polyhedral meshes. Mathematical Models and Methods
in Applied Sciences, 15(10):1533–1551, 2005.
[75] U. Brink and E. Stein. On some mixed ﬁnite element methods for incompressible
and nearly incompressible ﬁnite elasticity. Computational Mechanics, 19(1):105–119,
1996.
[76] R. Brooks. Isospectral graphs and isospectral surfaces. Séminaire de théorie spectrale
et géométrie, 15:105–113, 1996–1997.
[77] S. Bruvoll and M. S. Floater. Transﬁnite mean value interpolation in general di-
mension. Journal of Computational and Applied Mathematics, 233(7):1631–1639,
2010.
[78] M. Budninskiy, B. Liu, Y. Tong, and M. Desbrun. Power coordinates: A geometric
construction of barycentric coordinates on convex polytopes. ACM Transactions on
Graphics, 35(6):Article 241, 11 pages, 2016.
[79] P. Buser. A note on the isoperimetric constant. Annales Scientiﬁques de l’École
Normale Supérieure, 15(2):213–230, 1982.
[80] A. Cangiani, E. H. Georgoulis, and P. Houston. hp-Version discontinuous Galerkin
methods on polygonal and polyhedral meshes. Mathematical Models and Methods
in Applied Sciences, 24(10):2009–2041, 2014.
[81] A. Cangiani, G. Manzini, A. Russo, and N. Sukumar. Hourglass stabilization and
the virtual element method. International Journal for Numerical Methods in Engi-
neering, 102(3–4):404–436, 2015.
[82] A. Cangiani, G. Manzini, and O. J. Sutton. Conforming and nonconforming virtual
element methods for elliptic problems. IMA Journal of Numerical Analysis, 2016.
DOI: https://doi.org/10.1093/imanum/drw036.

286
■Bibliography
[83] Y. Canzani.
Analysis on manifolds via the Laplacian.
Course notes, Math 253,
Harvard University, 2013. http://canzani.web.unc.edu/ﬁles/2016/08/Laplacian.pdf.
[84] W. Carl. A Laplace operator on semi-discrete surfaces. Foundations of Computa-
tional Mathematics, 16(5):1115–1150, 2015.
[85] M. J. Carley. Analytical formulae for potential integrals on triangles. Journal of
Applied Mechanics, 80(4):Article 041008, 7 pages, 2013.
[86] CGAL.
Computational
Geometry
Algorithms
Library
(release
4.9),
2016.
http://www.cgal.org.
[87] T. Y. P. Chang, A. F. Saleeb, and G. Li. Large strain analysis of rubber-like materials
based on a perturbed Lagrangian variational principle. Computational Mechanics,
8(4):221–233, 1991.
[88] D. Chapelle and K. J. Bathe. The inf-sup test. Computers & Structures, 47(4–
5):537–545, 1993.
[89] I. Chavel. Eigenvalues in Riemannian Geometry, volume 115 of Pure and Applied
Mathematics. Academic Press, Orlando, 1984.
[90] J. S. Chen, W. Han, C. T. Wu, and W. Duan.
On the perturbed Lagrangian
formulation for nearly incompressible and incompressible hyperelasticity. Computer
Methods in Applied Mechanics and Engineering, 142(3–4):335–351, 1997.
[91] J.-S. Chen, M. Hillman, and M. Rüter. An arbitrary order variationally consistent
integration for Galerkin meshfree methods.
International Journal for Numerical
Methods in Engineering, 95(5):387–418, 2013.
[92] L. Chen and J. Xu. Optimal Delaunay triangulation. Journal of Computational
Mathematics, 22(2):299–308, 2004.
[93] R. Chen and C. Gotsman. Complex transﬁnite barycentric mappings with similarity
kernels. Computer Graphics Forum, 35(5):41–53, 2016.
[94] R. Chen and C. Gotsman. On pseudo-harmonic barycentric coordinates. Computer
Aided Geometric Design, 44:15–35, 2016.
[95] R. Chen and O. Weber. Bounded distortion harmonic mappings in the plane. ACM
Transactions on Graphics, 34(4):Article 73, 12 pages, 2015.
[96] R. Chen, Y. Xu, C. Gotsman, and L. Liu. A spectral characterization of the Delaunay
triangulation. Computer Aided Geometric Design, 27(4):295–300, 2010.
[97] L. P. Chew. Constrained Delaunay triangulations. Algorithmica, 4(1):97–108, 1989.
[98] H. Chi, O. Lopez-Pamies, and G. H. Paulino. A variational formulation with rigid-
body constraints for ﬁnite elasticity: Theory, ﬁnite element implementation, and
applications. Computational Mechanics, 57(2):325–338, 2016.
[99] H. Chi, C. Talischi, O. Lopez-Pamies, and G. H. Paulino. Polygonal ﬁnite elements
for ﬁnite elasticity. International Journal for Numerical Methods in Engineering,
101(4):305–328, 2015.
[100] H. Chi, C. Talischi, O. Lopez-Pamies, and G. H. Paulino. A paradigm for higher
order polygonal elements in ﬁnite elasticity. Computer Methods in Applied Mechanics
and Engineering, 306:216–251, 2016.
[101] E. Chien, R. Chen, and O. Weber. Bounded distortion harmonic shape interpolation.
ACM Transactions on Graphics, 35(4):Article 105, 15 pages, 2016.

Bibliography
■287
[102] E. B. Chin, J. B. Lasserre, and N. Sukumar.
Numerical integration of homoge-
neous functions on convex and nonconvex polygons and polyhedra. Computational
Mechanics, 56(6):967–981, 2015.
[103] N. H. Christ, R. Friedberg, and T. D. Lee. Weights of links and plaquettes in a
random lattice. Nuclear Physics B, 210(3):337–346, 1982.
[104] F. Chung. Four proofs for the Cheeger inequality and graph partition algorithms.
In L. Ji, K. Liu, L. Yang, and S.-T. Yau, editors, Fourth International Congress of
Chinese Mathematicians, volume 48 of AMS/IP Studies in Advanced Mathematics,
pages 331–349. American Mathematical Society/International Press, Providence/-
Somerville, 2010.
[105] B. Cockburn, W. Qiu, and M. Solano. A priori error analysis for HDG methods
using extensions from subdomains to achieve boundary conformity. Mathematics of
Computation, 83(286):665–699, 2014.
[106] D. Cohen-Or, A. Solomovic, and D. Levin. Three-dimensional distance ﬁeld meta-
morphosis. ACM Transactions on Graphics, 17(2):116–141, 1998.
[107] D. Copeland, U. Langer, and D. Pusch. From the boundary element domain decom-
position methods to local Treﬀtz ﬁnite element methods on polyhedral meshes. In
M. Bercovier, M. Gander, R. Kornhuber, and O. Widlund, editors, Domain Decom-
position Methods in Science and Engineering XVIII, volume 70 of Lecture Notes in
Computational Science and Engineering, pages 315–322. Springer, Berlin, 2009.
[108] J. A. Cottrell, T. J. R. Hughes, and Y. Bazilevs. Isogeometric Analysis: Toward
Integration of CAD and FEA. Wiley, Chichester, 2009.
[109] K. Crane, F. de Goes, M. Desbrun, and P. Schröder. Digital Geometry Processing
with Discrete Exterior Calculus. Number 7 in SIGGRAPH 2013 Course Notes. ACM,
New York, 2013.
[110] M. Crouzeix and P.-A. Raviart. Conforming and nonconforming ﬁnite element meth-
ods for solving the stationary Stokes equations I. Revue française d’automatique,
informatique, recherche opérationelle. Analyse Numérique, 7(3):33–76, 1973.
[111] C. J. Cyron, M. Arroyo, and M. Ortiz. Smooth, second order, non-negative meshfree
approximants selected by maximum entropy. International Journal for Numerical
Methods in Engineering, 79(13):1605–1632, 2009.
[112] E. F. D’Azevedo and R. B. Simpson. On optimal interpolation triangle incidences.
SIAM Journal on Scientiﬁc and Statistical Computing, 10(6):1063–1075, 1989.
[113] F. de Goes, P. Alliez, H. Owhadi, and M. Desbrun. On the equilibrium of simplicial
masonry structures.
ACM Transactions on Graphics, 32(4):Article 93, 10 pages,
2013.
[114] F. de Goes, M. Desbrun, M. Meyer, and T. DeRose. Subdivision exterior calculus for
geometry processing. ACM Transactions on Graphics, 35(4):Article 133, 11 pages,
2016.
[115] F. de Goes. Geometric Discretization Through Primal-Dual Meshes. PhD thesis,
California Institute of Technology, 2014.
[116] H. de Monantheuil. Aristotelis Mechanica. Jeremias Perier, Paris, 1599. In Greek,
corrected, translated into Latin and illustrated with commentary.
[117] S. Dekel and D. Leviatan. The Bramble–Hilbert lemma for convex domains. SIAM
Journal on Mathematical Analysis, 35(5):1203–1212, 2004.

288
■Bibliography
[118] M. Desbrun, A. N. Hirani, M. Leok, and J. E. Marsden. Discrete Exterior Calculus.
arXiv:math/0508341 [math.DG], 2005. https://arxiv.org/pdf/math/0508341.pdf.
[119] M. Desbrun, E. Kanso, and Y. Tong. Discrete diﬀerential forms for computational
modeling. In A. I. Bobenko, J. M. Sullivan, P. Schröder, and G. M. Ziegler, editors,
Discrete Diﬀerential Geometry, volume 38 of Oberwolfach Seminars, pages 287–324.
Birkhäuser, Basel, 2008.
[120] M. Desbrun, M. Meyer, P. Schröder, and A. H. Barr.
Implicit fairing of irregu-
lar meshes using diﬀusion and curvature ﬂow. In Proceedings of the 26th Annual
Conference on Computer Graphics and Interactive Techniques (SIGGRAPH 1999),
pages 317–324, 1999.
[121] M. Deuss, D. Panozzo, E. Whiting, Y. Liu, P. Block, O. Sorkine-Hornung, and
M. Pauly. Assembling self-supporting structures. ACM Transactions on Graphics,
33(6):Article 214, 10 pages, 2014.
[122] T. K. Dey, P. Ranjan, and Y. Wang. Convergence, stability, and discrete approxima-
tion of Laplace spectra. In Proceedings of the 21st Annual ACM-SIAM Symposium
on Discrete Algorithms (SODA 2010), pages 650–663, 2010.
[123] D. A. Di Pietro and A. Ern. Hybrid high-order methods for variable-diﬀusion prob-
lems on general meshes. Comptes Rendus Mathematiques, 353(1):31–34, 2015.
[124] J. Dodziuk and V. K. Patodi. Riemannian structures and triangulations of mani-
folds. The Journal of the Indian Mathematical Society, 40:1–52, 1976.
[125] W. Dörﬂer. A convergent adaptive algorithm for Poisson’s equation. SIAM Journal
on Numerical Analysis, 33(3):1106–1124, 1996.
[126] J. Droniou, R. Eymard, and R. Herbin.
Gradient schemes: generic tools for the
numerical analysis of diﬀusion equations, 2015. https://hal.archives-ouvertes.fr/hal-
01150517v2/document.
[127] Q. Du, V. Faber, and M. Gunzburger. Centroidal Voronoi tessellations: applications
and algorithms. SIAM Review, 41(4):637–676, 1999.
[128] Q. Du, C. Liu, and X. Wang. A phase ﬁeld approach in the numerical study of the
elastic bending energy for vesicle membranes. Journal of Computational Physics,
198(2):450–468, 2004.
[129] Q. Du and L. Zhu. Analysis of a mixed ﬁnite element method for a phase ﬁeld
bending elasticity model of vesicle membrane deformation. Journal of Computational
Mathematics, 24(3):265–280, 2006.
[130] R. J. Duﬃn. Distributed and lumped networks. Journal of Mathematics and Me-
chanics, 8(5):793–826, 1959.
[131] D. A. Dunavant. High degree eﬃcient symmetrical Gaussian quadrature rules for the
triangle. International Journal for Numerical Methods in Engineering, 21(6):1129–
1148, 1985.
[132] A. Düster, J. Parvizian, Z. Yang, and E. Rank. The ﬁnite cell method for three-
dimensional problems of solid mechanics. Computer Methods in Applied Mechanics
and Engineering, 197(45–48):3768–3782, 2008.
[133] C. Dyken and M. S. Floater. Transﬁnite mean value interpolation. Computer Aided
Geometric Design, 26(1):117–134, 2009.

Bibliography
■289
[134] G. Dziuk.
Finite elements for the Beltrami operator on arbitrary surfaces.
In
S. Hildebrandt and R. Leis, editors, Partial Diﬀerential Equations and Calculus of
Variations, volume 1357 of Lecture Notes in Mathematics, pages 142–155. Springer,
Berlin, 1988.
[135] M. S. Ebeida, S. A. Mitchell, A. Patney, A. A. Davidson, and J. D. Owens.
A
simple algorithm for maximal Poisson-disk sampling in high dimensions. Computer
Graphics Forum, 31(2):785–794, 2012.
[136] M. Eck, T. DeRose, T. Duchamp, H. Hoppe, M. Lounsbery, and W. Stuetzle. Mul-
tiresolution analysis of arbitrary meshes. In Proceedings of the 22nd Annual Confer-
ence on Computer Graphics and Interactive Techniques (SIGGRAPH 1995), pages
173–182, 1995.
[137] H. Edelsbrunner.
Algorithms in Combinatorial Geometry, volume 10 of EATCS
Monographs on Theoretical Computer Science. Springer, Berlin, 1987.
[138] Y. Efendiev, J. Galvis, R. Lazarov, and S. Weißer.
Mixed FEM for second or-
der elliptic problems on polygonal meshes with BEM-based spaces. In I. Lirkov,
S. Margenov, and J. Waśniewski, editors, Large-Scale Scientiﬁc Computing, volume
8353 of Lecture Notes in Computer Science, pages 331–338. Springer, Heidelberg,
2014.
[139] A. L. Eterovic and K.-J. Bathe. A hyperelastic-based large strain elasto-plastic con-
stitutive formulation with combined isotropic-kinematic hardening using the loga-
rithmic stress and strain measures. International Journal for Numerical Methods in
Engineering, 30(6):1099–1114, 1990.
[140] L. C. Evans. Partial Diﬀerential Equations, volume 19 of Graduate Studies in Math-
ematics. American Mathematical Society, Providence, 1998.
[141] G. Ewald. Combinatorial Convexity and Algebraic Geometry, volume 168 of Grad-
uate Texts in Mathematics. Springer, New York, 1996.
[142] J. L. Finney. Random packings and the structure of simple liquids. I. The geometry
of random close packing.
Proceedings of the Royal Society of London. Series A,
Mathematical and Physical Sciences, 319(1539):479–493, 1970.
[143] M. S. Floater. Parametrization and smooth approximation of surface triangulations.
Computer Aided Geometric Design, 14(3):231–250, 1997.
[144] M. S. Floater. Mean value coordinates. Computer Aided Geometric Design, 20(1):19–
27, 2003.
[145] M. S. Floater. Generalized barycentric coordinates and applications. Acta Numerica,
24:161–214, 2015.
[146] M. S. Floater. On the monotonicity of generalized barycentric coordinates on convex
polygons. Computer Aided Geometric Design, 42:34–39, 2016.
[147] M. S. Floater, A. Gillette, and N. Sukumar. Gradient bounds for Wachspress coor-
dinates on polytopes. SIAM Journal on Numerical Analysis, 52(1):515–532, 2014.
[148] M. S. Floater and K. Hormann. Surface parameterization: A tutorial and survey. In
N. A. Dodgson, M. S. Floater, and M. A. Sabin, editors, Advances in Multiresolution
for Geometric Modeling, Mathematics and Visualization, pages 157–186. Springer,
Berlin, 2005.

290
■Bibliography
[149] M. S. Floater, K. Hormann, and G. Kós.
A general construction of barycentric
coordinates over convex polygons. Advances in Computational Mathematics, 24(1–
4):311–331, 2006.
[150] M. S. Floater, G. Kós, and M. Reimers. Mean value coordinates in 3D. Computer
Aided Geometric Design, 22(7):623–631, 2005.
[151] M. S. Floater and J. Kosinka. Barycentric interpolation and mappings on smooth
convex domains. In Proceedings of the 14th ACM Symposium on Solid and Physical
Modeling (SPM 2010), pages 111–116, 2010.
[152] M. S. Floater and J. Kosinka. On the injectivity of Wachspress and mean value
mappings between convex polygons.
Advances in Computational Mathematics,
32(2):163–174, 2010.
[153] M. S. Floater and C. Schulz. Pointwise radial minimization: Hermite interpolation
on arbitrary domains. Computer Graphics Forum, 27(5):1505–1512, 2008.
[154] H. Florez, R. Manzanilla-Morillo, J. Florez, and M. F. Wheeler. Spline-based reser-
voir’s geometry reconstruction and mesh generation for coupled ﬂow and mechanics
simulation. Computational Geosciences, 18(6):949–967, 2014.
[155] T. Frankel. The Geometry of Physics: An Introduction. Cambridge University Press,
Cambridge, 2nd edition, 2004.
[156] F. Fraternali. A thrust network approach to the equilibrium problem of unreinforced
masonry vaults via polyhedral stress functions. Mechanics Research Communica-
tions, 37(2):198–204, 2010.
[157] M. Freytag, V. Shapiro, and I. Tsukanov. Finite element analysis in situ. Finite
Elements in Analysis and Design, 47(9):957–972, 2011.
[158] T.-P. Fries and T. Belytschko. The extended/generalized ﬁnite element method: An
overview of the method and its applications. International Journal for Numerical
Methods in Engineering, 84(3):253–304, 2010.
[159] T.-P. Fries and H.-G. Matthies. Classiﬁcation and overview of meshfree methods.
Technical Report 2003-3, Institute of Scientiﬁc Computing, Technische Universität
Braunschweig, July 2004.
[160] A. L. Gain, G. H. Paulino, L. S. Duarte, and I. F. M. Menezes. Topology optimization
using polytopes. Computer Methods in Applied Mechanics and Engineering, 293:411–
430, 2015.
[161] A. L. Gain, C. Talischi, and G. H. Paulino. On the Virtual Element Method for three-
dimensional linear elasticity problems on arbitrary polyhedral meshes. Computer
Methods in Applied Mechanics and Engineering, 282:132–160, 2014.
[162] F. Gao, D. M. Ingram, D. M. Causon, and C. G. Mingham. The development of
a Cartesian cut cell method for incompressible viscous ﬂows. International Journal
for Numerical Methods in Fluids, 54(9):1033–1053, 2007.
[163] A. Gillette and A. Rand. Interpolation error estimates for harmonic coordinates on
polytopes. ESAIM: Mathematical Modelling and Numerical Analysis, 50(3):651–676,
2016.
[164] A. Gillette, A. Rand, and C. Bajaj.
Error estimates for generalized barycentric
coordinates. Advances in Computational Mathematics, 37(3):417–439, 2012.

Bibliography
■291
[165] A. Gillette, A. Rand, and C. Bajaj. Construction of scalar and vector ﬁnite element
families on polygonal and polyhedral meshes. Computational Methods in Applied
Mathematics, 16(4):667–683, 2016.
[166] D. Glickenstein.
Geometric triangulations and discrete Laplacians on manifolds.
arXiv:math/0508188 [math.MG], 2005. https://arxiv.org/pdf/math/0508188.pdf.
[167] R. Goldman. Pyramid Algorithms: A Dynamic Programming Approach to Curves
and Surfaces for Geometric Modeling.
The Morgan Kaufmann Series in Com-
puter Graphics and Geometric Modeling. Morgan Kaufmann Publishers, Amster-
dam, 2003.
[168] E. Goldstein and C. Gotsman. Polygon morphing using a multiresolution represen-
tation. In Proceedings of Graphics Interface (GI 1995), pages 247–254, 1995.
[169] C. Gordon, D. L. Webb, and S. Wolpert. One cannot hear the shape of a drum.
Bulletion of the American Mathematical Society, 27(1):134–138, 1992.
[170] W. J. Gordon and C. A. Hall.
Transﬁnite element methods: Blending-function
interpolation over arbitrary curved element domains.
Numerische Mathematik,
21(2):109–129, 1973.
[171] W. J. Gordon and J. A. Wixom. Pseudo-harmonic interpolation on convex domains.
SIAM Journal on Numerical Analysis, 11(5):909–933, 1974.
[172] S. J. Gortler, C. Gotsman, and D. Thurtson. Discrete one-forms on meshes and
applications to 3D mesh parameterization.
Computer Aided Geometric Design,
23(2):83–112, 2006.
[173] C. Gotsman and V. Surazhsky.
Guaranteed intersection-free polygon morphing.
Computers & Graphics, 25(1):67–75, 2001.
[174] T. Goudarzi.
Iterative and Variational Homogenization Methods for Filled Elas-
tomers. PhD thesis, University of Illinois at Urbana-Champaign, 2014.
[175] T. Goudarzi, D. W. Spring, G. H. Paulino, and O. Lopez-Pamies. Filled elastomers:
A theory of ﬁller reinforcement based on hydrodynamic and interphasial eﬀects.
Journal of the Mechanics and Physics of Solids, 80:37–67, 2015.
[176] L. J. Grady and J. R. Polimeni. Discrete Calculus: Applied Analysis on Graphs for
Computational Science. Springer, London, 2010.
[177] F. Greco and N. Sukumar. Derivatives of maximum-entropy basis functions on the
boundary: Theory and computations. International Journal for Numerical Methods
in Engineering, 94(12):1123–1149, 2013.
[178] A. E. Green and W. Zerna. Theoretical Elasticity. Clarendon Press, Oxford, 2nd
edition, 1968.
[179] B. Grünbaum. Convex Polytopes, volume 221 of Graduate Texts in Mathematics.
Springer, New York, 2nd edition, 2003.
[180] L. Guibas, J. Hershberger, and S. Suri.
Morphing simple polygons.
Discrete &
Computational Geometry, 24(1):1–34, 2000.
[181] V. Guillemin and A. Pollack. Diﬀerential Topology. Prentice-Hall, Englewood Cliﬀs,
1974.
[182] V. Gyrya and K. Lipnikov. M-adaptation method for acoustic wave equation on
square meshes. Journal of Computational Acoustics, 20(4):Article 1250022, 23 pages,
2012.

292
■Bibliography
[183] V. Gyrya, K. Lipnikov, G. Manzini, and D. Svyatskiy. M-adaptation in the mimetic
ﬁnite diﬀerence method. Mathematical Models and Methods in Applied Sciences,
24(8):1621–1663, 2014.
[184] W. Hackbusch and S. A. Sauter. Composite ﬁnite elements for the approximation
of PDEs on domains with complicated micro-structures. Numerische Mathematik,
75(4):447–472, 1997.
[185] A. Hannukainen, S. Korotov, and M. Křížek. The maximum angle condition is not
necessary for convergence of the ﬁnite element method. Numerische Mathematik,
120(1):79–88, 2012.
[186] B. Hashemian, D. Millán, and M. Arroyo. Charting molecular free-energy landscapes
with an atlas of collective variables. The Journal of Chemical Physics, 145(17):Ar-
ticle 174109, 13 pages, 2016.
[187] P. Herholz, J. E. Kyprianidis, and M. Alexa. Perfect Laplacians for polygon meshes.
Computer Graphics Forum, 34(5):211–218, 2015.
[188] L. R. Herrmann. Elasticity equations for incompressible and nearly incompressible
materials by a variational theorem. AIAA Journal, 3(10):1896–1900, 1965.
[189] J. Heyman. The stone skeleton. International Journal of Solids and Structures,
2(2):249–279, 1966.
[190] J. Heyman. The Stone Skeleton: Structural Engineering of Masonry Architecture.
Cambridge University Press, Cambridge, 1995.
[191] K. Hildebrandt, K. Polthier, and M. Wardetzky. On the convergence of metric and
geometric properties of polyhedral surfaces. Geometriae Dedicata, 123(1):89–112,
2006.
[192] A. N. Hirani. Discrete Exterior Calculus. PhD thesis, California Institute of Tech-
nology, 2003.
[193] H. Hiyoshi and K. Sugihara. Two generalizations of an interpolant based on Voronoi
diagrams. International Journal of Shape Modelling, 5(2):219–231, 1999.
[194] H. Hiyoshi and K. Sugihara. Voronoi-based interpolation with higher continuity.
In Proceedings of the 16th Annual Symposium on Computational Geometry (SCG
2000), pages 242–250, 2000.
[195] C. Hofreither. L2 error estimates for a nonstandard ﬁnite element method on poly-
hedral meshes. Journal of Numerical Mathematics, 19(1):27–39, 2011.
[196] C. Hofreither, U. Langer, and C. Pechstein. Analysis of a non-standard ﬁnite element
method based on boundary integral operators. Electronic Transactions on Numerical
Analysis, 37:413–436, 2010.
[197] C. Hofreither, U. Langer, and C. Pechstein. A non-standard ﬁnite element method
for convection-diﬀusion-reaction problems on polyhedral meshes. In M. D. Todorov
and C. I. Christov, editors, Application of Mathematics in Technical and Natural
Sciences, number 1404 in AIP Conference Proceedings, pages 397–404. American
Insitute of Physics, Melville, 2011.
[198] C. Hofreither, U. Langer, and C. Pechstein. FETI solvers for non-standard ﬁnite
element equations based on boundary integral operators. In J. Erhel, M. J. Gander,
L. Halpern, G. Pichot, T. Sassi, and O. Widlund, editors, Domain Decomposition
Methods in Science and Engineering XXI, volume 98 of Lecture Notes in Computa-
tional Science and Engineering, pages 729–737. Springer, Cham, 2014.

Bibliography
■293
[199] C. Hofreither, U. Langer, and S. Weißer. Convection-adapted BEM-based FEM.
ZAMM, 96(12):1467–1481, 2016.
[200] K. Hormann and M. S. Floater. Mean value coordinates for arbitrary planar poly-
gons. ACM Transactions on Graphics, 25(4):1424–1441, 2006.
[201] K. Hormann, B. Lévy, and A. Sheﬀer. Mesh Parameterization: Theory and Practice.
Number 2 in SIGGRAPH 2007 Course Notes. ACM, New York, 2007.
[202] K. Hormann and N. Sukumar. Maximum entropy coordinates for arbitrary poly-
topes. Computer Graphics Forum, 27(5):1513–1520, 2008.
[203] S. Huerta. Mechanics of masonry vaults: The equilibrium approach. In Proceedings of
the 3rd International Conference on Structural Analysis of Historical Constructions
(SAHC 2001), pages 47–69, 2001.
[204] T. J. R. Hughes. The Finite Element Method: Linear Static and Dynamic Finite
Element Analysis. Dover Publications, Mineola, 2000.
[205] T. J. R. Hughes, J. A. Cottrell, and Y. Bazilevs. Isogeometric analysis: CAD, ﬁnite
elements, NURBS, exact geometry and mesh reﬁnement.
Computer Methods in
Applied Mechanics and Engineering, 194(39–41):4135–4195, 2005.
[206] H. N. Iben, J. F. O’Brien, and E. D. Demaine. Refolding planar polygons. Discrete
& Computational Geometry, 41(3):444–460, 2009.
[207] D. M. Ingram, D. M. Causon, and C. G. Mingham. Developments in Cartesian cut
cell methods. Mathematics and Computers in Simulation, 61(3–6):561–572, 2003.
[208] A. Jacobson. Bijective mappings with generalized barycentric coordinates: A coun-
terexample. Journal of Graphics Tools, 17(1–2):1–4, 2013.
[209] P. Jamet. Estimations d’erreur pour des éléments ﬁnis droits presque dégénérés.
Revue française d’automatique, informatique, recherche opérationelle. Analyse
Numérique, 10(1):43–60, 1976.
[210] L. Jardine. Monuments and microscopes: Scientiﬁc thinking on a grand scale in the
early Royal Society. Notes and Records of the Royal Society of London, 55(2):289–
308, 2001.
[211] E. T. Jaynes.
Information theory and statistical mechanics.
Physical Review,
106(4):620–630, 1957.
[212] E. T. Jaynes. Information theory and statistical mechanics. In K. W. Ford, editor,
Statistical Physics, volume 3 of Brandeis University Summer Institute Lectures in
Theoretical Physics, pages 181–218. W. A. Benjamin, New York, 1963.
[213] M. Jirásek. Comparative study on ﬁnite elements with embedded discontinuities.
Computer Methods in Applied Mechanics and Engineering, 188(1–3):307–330, 2000.
[214] M. W. Jones, J. A. Bærentzen, and M. Sramek. 3D distance ﬁelds: A survey of
techniques and applications.
IEEE Transactions on Visualization and Computer
Graphics, 12(4):581–599, 2006.
[215] P. Joshi, M. Meyer, T. DeRose, B. Green, and T. Sanocki. Harmonic coordinates for
character articulation. ACM Transactions on Graphics, 26(3):Article 71, 9 pages,
2007.
[216] T. Ju, P. Liepa, and J. Warren. A general geometric construction of coordinates
in a convex simplicial polytope. Computer Aided Geometric Design, 24(3):161–178,
2007.

294
■Bibliography
[217] T. Ju, S. Schaefer, and J. Warren. Mean value coordinates for closed triangular
meshes. ACM Transactions on Graphics, 24(3):561–566, 2005.
[218] T. Ju, S. Schaefer, J. Warren, and M. Desbrun. A geometric construction of coordi-
nates for convex polyhedra using polar duals. In Proceedings of the 3rd Eurographics
Symposium on Geometry Processing (SGP 2005), pages 181–186, Vienna, Austria,
2005.
[219] M. Juntunen and M. F. Wheeler. Two-phase ﬂow in complicated geometries: Mod-
eling the Frio data using improved computational meshes.
Computational Geo-
sciences, 17(2):239–247, 2013.
[220] M. Kac. Can one hear the shape of a drum? The American Mathematical Monthly,
73(4, Part 2):1–23, 1966.
[221] J. A. Kalman. Continuity and convexity of projections and barycentric coordinates
in convex polyhedra. Paciﬁc Journal of Mathematics, 11(3):1017–1022, 1961.
[222] R. Kannan, S. Vempala, and A. Vetta. On clusterings: Good, bad and spectral.
Journal of the ACM, 51(3):497–515, 2004.
[223] A. Y. Khinchin. Mathematical Foundations of Information Theory. Dover Publica-
tions, New York, 1957.
[224] H.-G. Kim and D. Sohn. A new ﬁnite element approach for solving three-dimensional
problems using trimmed hexahedral elements. International Journal for Numerical
Methods in Engineering, 102(9):1527–1553, 2015.
[225] K. Kobayashi and T. Tsuchiya. A Babuška–Aziz type proof of the circumradius
condition.
Japan Journal of Industrial and Applied Mathematics, 31(1):193–210,
2014.
[226] A. Kooharian. Limit analysis of Voussoir (segmental) and concrete arches. Proc.
Am. Concr. Inst., 49(12):317–328, 1952.
[227] J. Kosinka and M. Bartoň. Convergence of barycentric coordinates to barycentric
kernels. Computer Aided Geometric Design, 43:200–210, 2016.
[228] T. Kotnik and M. Weinstock.
Material, form and force.
Architectural Design,
82(2):104–111, 2012.
[229] Y. Krongauz and T. Belytschko. Consistent pseudo-derivatives in meshless methods.
Computer Methods in Applied Mechanics and Engineering, 146(3–4):371–386, 1997.
[230] S. Kullback and R. A. Leibler.
On information and suﬃciency.
The Annals of
Mathematical Statistics, 22(1):79–86, 1951.
[231] M. Křížek. On the maximum angle condition for linear tetrahedral elements. SIAM
Journal on Numerical Analysis, 29(2):513–520, 1992.
[232] T. Langer, A. Belyaev, and H.-P. Seidel. Spherical barycentric coordinates. In Pro-
ceedings of the 4th Eurographics Symposium on Geometry Processing (SGP 2006),
pages 81–88, 2006.
[233] C. L. Lawson. Software for C1 surface interpolation. In J. R. Rice, editor, Mathe-
matical Software III, volume 39 of Publication of the Mathematics Research Center,
University of Wisconsin-Madison, pages 161–194. Academic Press, New York, 1977.
[234] C. L. Lawson and R. J. Hanson.
Solving Least Squares Problems, volume 15 of
Classics in Applied Mathematics. SIAM, Philadelphia, 1995.

Bibliography
■295
[235] P. Le Tallec. Existence and approximation results for nonlinear mixed problems:
Application to incompressible ﬁnite elasticity. Numerische Mathematik, 38(3):365–
382, 1982.
[236] J. L. Leblanc. Filled Polymers: Science and Industrial Applications. CRC Press,
Boca Raton, 2010.
[237] C. W. Lee. Regular triangulations of convex polytopes. In Applied Geometry and
Discrete Mathematics: The Victor Klee Festschrift, volume 4 of DIMACS Series
in Discrete Mathematics and Theoretical Computer Science, pages 443–456. Ameri-
can Mathematical Society/Association for Computing Machinery, Providence/Bal-
timore, 1991.
[238] S.-B. Lee, G. S. Rohrer, and A. D. Rollett. Three-dimensional digital approximations
of grain boundary networks in polycrystals. Modelling and Simulation in Materials
Science and Engineering, 22(2):Article 025017, 21 pages, 2014.
[239] S. E. Leon, D. W. Spring, and G. H. Paulino. Reduction in mesh bias for dynamic
fracture using adaptive splitting of polygonal ﬁnite elements. International Journal
for Numerical Methods in Engineering, 100(8):555–576, 2014.
[240] G. Leoni. A First Course in Sobolev Spaces, volume 105 of Graduate Studies in
Mathematics. American Mathematical Society, Providence, 2009.
[241] Z. Levi and O. Weber. On the convexity and feasibility of the bounded distortion
harmonic mapping problem. ACM Transactions on Graphics, 35(4):Article 106, 15
pages, 2016.
[242] B. Lévy and H. Zhang. Spectral Mesh Processing. Number 8 in SIGGRAPH 2010
Course Notes. ACM, New York, 2010.
[243] B. Li, F. Habbal, and M. Ortiz. Optimal transportation meshfree approximation
schemes for ﬂuid and plastic ﬂows. International Journal for Numerical Methods in
Engineering, 83(12):1541–1579, 2010.
[244] B. Li, C. Peco, D. Millán, I. Arias, and M. Arroyo. Phase-ﬁeld modeling and sim-
ulation of fracture in brittle materials with strongly anisotropic surface energy. In-
ternational Journal for Numerical Methods in Engineering, 102(3–4):711–727, 2015.
[245] S. Li and W. K. Liu. Meshfree and particle methods and their applications. Applied
Mechanics Reviews, 55(1):1–34, 2002.
[246] X. S. Li. An overview of SuperLU: Algorithms, implementation, and user interface.
ACM Transactions on Mathematical Software, 31(3):302–325, 2005.
[247] X.-Y. Li and S.-M. Hu. Poisson coordinates. IEEE Transactions on Visualization
and Computer Graphics, 19(2):344–352, 2013.
[248] X.-Y. Li, T. Ju, and S.-M. Hu. Cubic mean value coordinates. ACM Transactions
on Graphics, 32(4):Article 126, 10 pages, 2013.
[249] H. Lim, F. Abdeljawad, S. J. Owen, B. W. Hanks, J. W. Foulk, and C. C. Battaile. In-
corporating physically-based microstructures in materials modeling: Bridging phase
ﬁeld and crystal plasticity frameworks. Modelling and Simulation in Materials Sci-
ence and Engineering, 24(4):Article 045016, 19 pages, 2016.
[250] E. Lindelöf. Sur l’application de la méthode des approximations successives aux
équations diﬀérentielles ordinaires du premier ordre. Comptes Rendus des Séances
de l’Académie des Sciences, 118(9):454–457, 1894.

296
■Bibliography
[251] Y. Lipman, J. Kopf, D. Cohen-Or, and D. Levin.
GPU-assisted positive mean
value coordinates for mesh deformations. In Proceedings of the 5th Eurographics
Symposium on Geometry Processing (SGP 2007), pages 117–123, 2007.
[252] Y. Lipman, D. Levin, and D. Cohen-Or. Green coordinates. ACM Transactions on
Graphics, 27(3):Article 78, 10 pages, 2008.
[253] K. Lipnikov, G. Manzini, and M. Shashkov. Mimetic ﬁnite diﬀerence method. Jour-
nal of Computational Physics, 257, Part B:1163–1227, 2014.
[254] K. Lipnikov, G. Manzini, and D. Svyatskiy. Analysis of the monotonicity conditions
in the mimetic ﬁnite diﬀerence method for elliptic problems. Journal of Computa-
tional Physics, 230(7):2620–2642, 2011.
[255] Y. Liu, H. Pan, J. Snyder, W. Wang, and B. Guo.
Computing self-supporting
surfaces by regular triangulation. ACM Transactions on Graphics, 32(4):Article 92,
10 pages, 2013.
[256] Y. Liu, A. A. Saputra, J. Wang, F. Tin-Loi, and C. Song. Automatic polyhedral mesh
generation and scaled boundary ﬁnite element analysis of STL models. Computer
Methods in Applied Mechanics and Engineering, 313:106–132, 2017.
[257] C. T. Loop and T. D. DeRose. A multisided generalization of Bézier surfaces. ACM
Transactions on Graphics, 8(3):204–234, 1989.
[258] O. Lopez-Pamies. An exact result for the macroscopic response of particle-reinforced
neo-Hookean solids. Journal of Applied Mechanics, 77(2):Article 021016, 5 pages,
2010.
[259] O. Lopez-Pamies. A new I1-based hyperelastic model for rubber elastic materials.
Comptes Rendus Mécanique, 338(1):3–11, 2010.
[260] O. Lopez-Pamies, T. Goudarzi, and K. Danas. The nonlinear elastic response of
suspensions of rigid inclusions in rubber: II—a simple explicit approximation for
ﬁnite-concentration suspensions. Journal of the Mechanics and Physics of Solids,
61(1):19–37, 2013.
[261] W. Lorensen and H. Cline. Marching cubes: A high resolution 3D surface construc-
tion algorithm. ACM SIGGRAPH Computer Graphics, 21(4):163–169, 1987.
[262] R. MacNeal. The Solution of Partial Diﬀerential Equations by Means of Electrical
Networks. PhD thesis, California Institute of Technology, 1949.
[263] M. Majeed and F. Cirak. Isogeometric analysis using manifold-based smooth basis
functions. Computer Methods in Applied Mechanics and Engineering, 316(1):547–
567, 2017.
[264] E. A. Malsch and G. Dasgupta.
Interpolations for temperature distributions: A
method for all non-concave polygons. International Journal of Solids and Structures,
41(8):2165–2188, 2004.
[265] E. A. Malsch, J. J. Lin, and G. Dasgupta. Smooth two-dimensional interpolants: A
recipe for all polygons. Journal of Graphics Tools, 10(2):27–39, 2005.
[266] J. Manson, K. Li, and S. Schaefer. Positive Gordon–Wixom coordinates. Computer-
Aided Design, 43(11):1422–1426, 2011.
[267] J. Manson and S. Schaefer. Moving least squares coordinates. Computer Graphics
Forum, 29(5):1517–1524, 2010.

Bibliography
■297
[268] G. Manzini, A. Russo, and N. Sukumar. New perspectives on polygonal and polyhe-
dral ﬁnite element methods. Mathematical Models and Methods in Applied Sciences,
24(8):1665–1699, 2014.
[269] S. Martin, P. Kaufmann, M. Botsch, M. Wicke, and M. Gross. Polyhedral ﬁnite
elements using harmonic basis functions. Computer Graphics Forum, 27(5):1521–
1529, 2008.
[270] J. C. Maxwell. On reciprocal ﬁgures, frames, and diagrams of forces. Transactions
of the Royal Society of Edinburgh, 26:1–40, 1870.
[271] S. F. McCormick. Multilevel Adaptive Methods for Partial Diﬀerential Equations,
volume 6 of Frontiers in Applied Mathematics. SIAM, Philadelphia, 1989.
[272] G. H. Meisters and C. Olech. Locally one-to-one mappings and a classical theorem
on the schlicht functions. Duke Mathematical Journal, 30(1):63–80, 1963.
[273] T. V. Mele and P. Block. A novel form ﬁnding method for fabric formwork for con-
crete shells. Journal of the International Association for Shell and Spatial Structures,
52(4):217–224, 2011.
[274] P. Memari, P. Mullen, and M. Desbrun.
Parametrization of generalized primal-
dual triangulations. In W. R. Quadros, editor, Proceedings of the 20th International
Meshing Roundtable, pages 237–253. Springer, Berlin, 2012.
[275] M. Meyer, A. Barr, H. Lee, and M. Desbrun. Generalized barycentric coordinates
on irregular polygons. Journal of Graphics Tools, 7(1):13–22, 2002.
[276] M. Meyer, M. Desbrun, P. Schröder, and A. H. Barr. Discrete diﬀerential-geometry
operators for triangulated 2-manifolds.
In H.-C. Hege and K. Polthier, editors,
Visualization and Mathematics III, Mathematics and Visualization, pages 35–57.
Springer, Berlin, 2003.
[277] C. Miehe, M. Hofacker, L.-M. Schänzel, and F. Aldakheel. Phase ﬁeld modeling of
fracture in multi-physics problems. Part II. Coupled brittle-to-ductile failure criteria
and crack propagation in thermo-elastic-plastic solids. Computer Methods in Applied
Mechanics and Engineering, 294(1):486–522, 2015.
[278] C. Miehe, L.-M. Schänzel, and H. Ulmer. Phase ﬁeld modeling of fracture in multi-
physics problems. Part I. Balance of crack surface and failure criteria for brittle crack
propagation in thermo-elastic solids. Computer Methods in Applied Mechanics and
Engineering, 294(1):449–485, 2015.
[279] D. Millán, A. Rosolen, and M. Arroyo. Thin shell analysis from scattered points
with maximum-entropy approximants. International Journal for Numerical Methods
in Engineering, 85(6):723–751, 2011.
[280] D. Millán, A. Rosolen, and M. Arroyo. Nonlinear manifold learning for meshfree
ﬁnite deformation thin-shell analysis. International Journal for Numerical Methods
in Engineering, 93(7):685–713, 2013.
[281] D. Millán, N. Sukumar, and M. Arroyo. Cell-based maximum-entropy approximants.
Computer Methods in Applied Mechanics and Engineering, 284:712–731, 2015.
[282] A. F. Möbius. Der barycentrische Calcul. J. A. Barth, Leipzig, 1827.
[283] C. Montani, R. Scateni, and R. Scopigno. A modiﬁed look-up table for implicit
disambiguation of Marching Cubes. The Visual Computer, 10(6):353–355, 1994.

298
■Bibliography
[284] J. Moraleda, J. Segurado, and J. Llorca. Finite deformation of incompressible ﬁber-
reinforced elastomers: A computational micromechanics approach. Journal of the
Mechanics and Physics of Solids, 57(9):1596–1613, 2009.
[285] S. E. Mousavi and N. Sukumar. Numerical integration of polynomials and discon-
tinuous functions on irregular convex polygons and polyhedrons.
Computational
Mechanics, 47(5):535–554, 2011.
[286] S. E. Mousavi, H. Xiao, and N. Sukumar. Generalized Gaussian quadrature rules on
arbitrary polygons. International Journal for Numerical Methods in Engineering,
82(1):99–113, 2010.
[287] L. Mu, J. Wang, and X. Ye. Weak Galerkin ﬁnite element methods on polytopal
meshes. International Journal of Numerical Analysis and Modeling, 12(1):31–53,
2015.
[288] L. Mu, X. Wang, and Y. Wang. Shape regularity conditions for polygonal/polyhedral
meshes, exempliﬁed in a discontinuous Galerkin discretization.
Numer. Methods
Partial Diﬀerential Equations, 31(1):308–325, 2015.
[289] P. Mullen, P. Memari, F. de Goes, and M. Desbrun. HOT: Hodge-optimized trian-
gulations. ACM Transactions on Graphics, 30(4):Article 103, 12 pages, 2011.
[290] J. B. C. Neto, P. A. Wawrzynek, M. T. M. Carvalho, L. F. Martha, and A. R.
Ingraﬀea. An algorithm for three-dimensional mesh generation for arbitrary regions
with cracks. Engineering with Computers, 17(1):75–91, 2001.
[291] T. S. Newman and Y. Hong. A survey of the marching cubes algorithm. Computers
& Graphics, 30(5):854–879, 2006.
[292] K. Nissen, C. J. Cyron, V. Gravemeier, and W. A. Wall. Information-ﬂux method:
a meshfree maximum-entropy Petrov–Galerkin method including stabilised ﬁnite
element methods. Computer Methods in Applied Mechanics and Engineering, 241–
244:225–237, 2012.
[293] J. T. Oden. Recent developments in the theory of ﬁnite element approximations
of boundary value problems in nonlinear elasticity. Computer Methods in Applied
Mechanics and Engineering, 17–18(1):183–202, 1979.
[294] R. W. Ogden. Non-linear Elastic Deformations. Dover, Mineola, 1997.
[295] A. Okabe, B. Boots, K. Sugihara, and S. N. Chiu. Spatial Tessellations: Concepts
and Applications of Voronoi Diagrams. Wiley Series in Probability and Statistics.
Wiley, Chichester, 2nd edition, 2000.
[296] A. Ortiz, M. A. Puso, and N. Sukumar. Maximum-entropy meshfree method for
compressible and near-incompressible elasticity. Computer Methods in Applied Me-
chanics and Engineering, 199(25–28):1859–1871, 2010.
[297] S. Osher and R. Fedkiw. Level Set Methods and Dynamic Implicit Surfaces, volume
153 of Applied Mathematical Sciences. Springer, Berlin, 2003.
[298] A. Paluszny, S. K. Matthäi, and M. Hohmeyer. Hybrid ﬁnite-element ﬁnite vol-
ume discretization of complex geologic structures and a new simulation workﬂow
demonstrated on fractured rocks. Geoﬂuids, 7(2):186–208, 2007.
[299] A. Pandolﬁ, P. Krysl, and M. Ortiz. Finite element simulation of ring expansion and
fragmentation: The capturing of length and time scales through cohesive models of
fracture. International Journal of Fracture, 95(1):279–297, 1999.

Bibliography
■299
[300] A. Pandolﬁand M. Ortiz. An eﬃcient adaptive procedure for three-dimensional
fragmentation simulations. Engineering with Computers, 18(2):148–159, 2002.
[301] D. Panozzo, P. Block, and O. Sorkine-Hornung. Designing unreinforced masonry
models. ACM Transactions on Graphics, 32(4):Article 91, 12 pages, 2013.
[302] K. D. Papoulia, S. A. Vavasis, and P. Ganguly. Spatial convergence of crack nucle-
ation using a cohesive ﬁnite-element model on a pinwheel-based mesh. International
Journal for Numerical Methods in Engineering, 67(1):1–16, 2006.
[303] K. Park, G. H. Paulino, and J. R. Roesler. A uniﬁed potential-based cohesive model
of mixed-mode fracture. Journal of the Mechanics and Physics of Solids, 57(6):891–
908, 2009.
[304] G. H. Paulino, K. Park, W. Celes, and R. Espinha.
Adaptive dynamic cohesive
fracture simulation using nodal perturbation and edge-swap operators. International
Journal for Numerical Methods in Engineering, 84(11):1303–1343, 2010.
[305] C. Peco, D. Millán, A. Rosolen, and M. Arroyo. Eﬃcient implementation of Galerkin
meshfree methods for large-scale problems with an emphasis on maximum entropy
approximants. Computers & Structures, 150:52–62, 2015.
[306] C. Peco, A. Rosolen, and M. Arroyo. An adaptive meshfree method for phase-ﬁeld
models of biomembranes. Part II: A Lagrangian approach for membranes in viscous
ﬂuids. Journal of Computational Physics, 249:320–336, 2013.
[307] D. Peng, S. Osher, B. Merriman, and H.-K. Zhao. The geometry of Wulﬀcrystal
shapes and its relations with Riemann problems. In G.-Q. Chen and E. DiBenedetto,
editors, Nonlinear Partial Diﬀerential Equations, volume 238 of Contemporary
Mathematics, pages 251–303. American Mathematical Society, Providence, 1999.
[308] É. Picard. Sur l’application des méthodes d’approximations successives á l’étude
de certaines équations diﬀérentielles ordinaires. Journal de Mathématiques Pures et
Appliquées, 9:217–271, 1893.
[309] U. Pinkall and K. Polthier. Computing discrete minimal surfaces and their conju-
gates. Experimental Mathematics, 2(1):15–36, 1993.
[310] H. Pottmann, P. Grohs, and N. J. Mitra.
Laguerre minimal surfaces, isotropic
geometry and linear elasticity. Advances in Computational Mathematics, 31(4):391–
419, 2009.
[311] H. Pottmann and Y. Liu. Discrete surfaces in isotropic geometry. In R. Martin,
M. Sabin, and J. Winkler, editors, Mathematics of Surfaces XII, volume 4647 of
Lecture Notes in Computer Science, pages 341–363. Springer, Berlin, 2007.
[312] P. L. Powar. Minimal roughness property of the Delaunay triangulation: a shorter
approach. Computer Aided Geometric Design, 9(6):491–494, 1992.
[313] F. P. Preparata and M. I. Shamos. Computational Geometry: An Introduction. Texts
and Monographs in Computer Science. Springer, New York, 1985.
[314] V. Rajan. Optimality of the Delaunay triangulation in Rd. Discrete & Computational
Geometry, 12(1):189–202, 1994.
[315] J. Ramier. Comportement mécanique d’élastomèrs chargés, inﬂuence de l’adhésion
charge – polymére, inﬂuence de la morphologie. PhD thesis, L’Institut National des
Sciences Appliquées de Lyon, 2004.

300
■Bibliography
[316] L. Ramshaw. Blossoming: A connect-the-dots approach to splines. Technical Re-
port 19, Digital Equipment Corporation, Systems Research Centre, Palo Alto, June
1987.
[317] A. Rand. Delaunay Reﬁnement Algorithms for Numerical Methods. PhD thesis,
Carnegie Mellon University, 2009.
[318] A. Rand. Average interpolation under the maximum angle condition. SIAM Journal
on Numerical Analysis, 50(5):2538–2559, 2012.
[319] A. Rand, A. Gillette, and C. Bajaj. Interpolation error estimates for mean value coor-
dinates over convex polygons. Advances in Computational Mathematics, 39(2):327–
347, 2013.
[320] A. Rand, A. Gillette, and C. Bajaj.
Quadratic serendipity ﬁnite elements on
polygons using generalized barycentric coordinates. Mathematics of Computation,
83(290):2691–2716, 2014.
[321] M. M. Rashid and A. Sadri. The partitioned element method in computational solid
mechanics. Computer Methods in Applied Mechanics and Engineering, 237–240:152–
165, 2012.
[322] M. M. Rashid and M. Selimotic. A three-dimensional ﬁnite element method with
arbitrary polyhedral elements. International Journal for Numerical Methods in En-
gineering, 67(2):226–252, 2006.
[323] N. Ray, B. Vallet, L. Alonso, and B. Lévy. Geometry-aware direction ﬁeld processing.
ACM Transactions on Graphics, 29(1):Article 1, 11 pages, 2009.
[324] N. Ray, B. Vallet, W. C. Li, and B. Lévy. N-symmetry direction ﬁeld design. ACM
Transactions on Graphics, 27(2):Article 10, 13 pages, 2008.
[325] J. J. Rimoli and J. J. Rojas. Meshing strategies for the alleviation of mesh-induced
eﬀects in cohesive element models. International Journal of Fracture, 193(1):29–42,
2015.
[326] S. Rippa. Minimal roughness property of the Delaunay triangulation. Computer
Aided Geometric Design, 7(6):489–497, 1990.
[327] S. Rippa.
Long and thin triangles can be good for linear interpolation.
SIAM
Journal on Numerical Analysis, 29(1):257–270, 1992.
[328] S. Rjasanow and O. Steinbach.
The Fast Solution of Boundary Integral Equa-
tions. Mathematical and Analytical Techniques with Applications to Engineering.
Springer, New York, 2007.
[329] S. Rjasanow and S. Weißer. Higher order BEM-based FEM on polygonal meshes.
SIAM Journal on Numerical Analysis, 50(5):2357–2378, 2012.
[330] S. Rjasanow and S. Weißer. FEM with Treﬀtz trial functions on polyhedral elements.
Journal of Computational and Applied Mathematics, 263:202–217, 2014.
[331] A. Rodríguez-Ferran, T. Bennett, H. Askes, and E. Tamayo-Mas. A general frame-
work for softening regularisation based on gradient elasticity. International Journal
of Solids and Structures, 48(9):1382–1394, 2011.
[332] B. Roget and J. Sitaraman. Wall distance search algorithm using voxelized marching
spheres. Journal of Computational Physics, 241:76–94, 2013.
[333] S. Rosenberg.
The Laplacian on a Riemannian Manifold, volume 31 of London
Mathematical Society Student Texts. Cambridge University Press, Cambridge, 1997.

Bibliography
■301
[334] A. Rosolen and M. Arroyo.
Blending isogeometric analysis and local maximum
entropy meshfree approximants. Computer Methods in Applied Mechanics and En-
gineering, 264:95–107, 2013.
[335] A. Rosolen, D. Millán, and M. Arroyo. On the optimum support size in meshfree
methods: A variational adaptivity approach with maximum-entropy approximants.
International Journal for Numerical Methods in Engineering, 82(7):868–895, 2010.
[336] A. Rosolen, D. Millán, and M. Arroyo.
Second-order convex maximum entropy
approximants with applications to high-order PDE. International Journal for Nu-
merical Methods in Engineering, 94(2):150–182, 2013.
[337] A. Rosolen, C. Peco, and M. Arroyo. An adaptive meshfree method for phase-ﬁeld
models of biomembranes. Part I: Approximation with maximum-entropy approxi-
mants. Journal of Computational Physics, 249:303–319, 2013.
[338] Y. Rouchdy and L. D. Cohen. Geodesic voting methods: overview, extensions and
application to blood vessel segmentation. Computer Methods in Biomechanics and
Biomedical Engineering: Imaging & Visualization, 1(2):79–88, 2013.
[339] G. Ruiz, M. Ortiz, and A. Pandolﬁ. Three-dimensional ﬁnite-element simulation
of the dynamic Brazilian tests on concrete cylinders.
International Journal for
Numerical Methods in Engineering, 48(7):963–994, 2000.
[340] G. Ruiz, A. Pandolﬁ, and M. Ortiz. Three-dimensional cohesive modeling of dynamic
mixed-mode fracture. International Journal for Numerical Methods in Engineering,
52(1–2):97–120, 2001.
[341] M. Rumpf and M. Wardetzky. Geometry processing from an elastic perspective.
GAMM Mitteilungen, 37(2):184–216, 2014.
[342] R. M. Rustamov. Boundary element formulation of harmonic coordinates. Technical
report, Department of Mathematics, Purdue University, Nov. 2008.
[343] M. Saba, T. Schneider, K. Hormann, and R. Scateni. Curvature-based blending of
closed planar curves. Graphical Models, 76(5):263–272, 2014.
[344] M. Sabin. Transﬁnite surface interpolation. In Proceedings of the 6th IMA Confer-
ence on the Mathematics of Surfaces, pages 517–534, 1996.
[345] L. A. Santaló. Integral Geometry and Geometric Probability. Cambridge Mathemat-
ical Library. Cambridge University Press, Cambridge, 2nd edition, 2004.
[346] S. Schaefer, T. Ju, and J. Warren. A uniﬁed, integral construction for coordinates
over closed curves. Computer Aided Geometric Design, 24(8–9):481–493, 2007.
[347] A. Schiftner. Planar quad meshes from relative principal curvature lines. Master’s
thesis, Technische Universität Wien, 2007.
[348] D. Schillinger, L. Dedè, M. A. Scott, J. A. Evans, M. J. Borden, E. Rank, and
T. J. R. Hughes. An isogeometric design-through-analysis methodology based on
adaptive hierarchical reﬁnement of NURBS, immersed boundary methods, and T-
spline CAD surfaces. Computer Methods in Applied Mechanics and Engineering,
249-252:116–150, 2012.
[349] D. Schillinger and M. Ruess. The ﬁnite cell method: A review in the context of
higher-order structural analysis of CAD and image-based geometric models. Archives
of Computational Methods in Engineering, 22(3):391–455, 2015.

302
■Bibliography
[350] T. Schneider, K. Hormann, and M. S. Floater.
Bijective composite mean value
mappings. Computer Graphics Forum, 32(5):137–146, 2013.
[351] G. Schwarz. Hodge Decomposition: A Method for Solving Boundary Value Problems,
volume 1607 of Lecture Notes in Mathematics. Springer, Berlin, 1995.
[352] T. W. Sederberg, P. Gao, G. Wang, and H. Mu. 2-D shape blending: an intrinsic
solution to the vertex path problem. In Proceedings of the 20th Annual Conference
on Computer Graphics and Interactive Techniques (SIGGRAPH 1993), pages 15–18,
1993.
[353] T. W. Sederberg and S. R. Parry. Free-form deformation of solid geometric models.
ACM SIGGRAPH Computer Graphics, 20(4):151–160, 1986.
[354] D. Shepard. A two-dimensional interpolation function for irregularly-spaced data.
In Proceedings of the 23rd ACM national conference, pages 517–524, 1968.
[355] J. R. Shewchuk. Triangle: Engineering a 2D quality mesh generator and Delaunay
triangulator. In M. C. Lin and D. Manocha, editors, Applied Computational Geom-
etry. Towards Geometric Engineering, volume 1148 of Lecture Notes in Computer
Science, pages 203–222. Springer, Berlin, 1996.
[356] H. V. Shin, C. F. Porst, E. Vouga, J. Ochsendorf, and F. Durand.
Reconciling
elastic and equilibrium methods for static analysis. ACM Transactions on Graphics,
35(2):Article 13, 16 pages, 2016.
[357] J. E. Shore and R. W. Johnson.
Axiomatic derivation of the principle of maxi-
mum entropy and the principle of minimum cross-entropy. IEEE Transactions on
Information Theory, 26(1):26–37, 1980.
[358] R. Shu, C. Zhou, and M. S. Kankanhalli. Adaptive marching cubes. The Visual
Computer, 11(4):202–217, 1995.
[359] R. Sibson. Locally equiangular triangulations. The Computer Journal, 21(3):243–
245, 1978.
[360] R. Sibson. A vector identity for the Dirichlet tessellation. Mathematical Proceedings
of the Cambridge Philosophical Society, 87(1):151–155, 1980.
[361] R. Sibson.
A brief description of natural neighbor interpolation.
In V. Barnet,
editor, Interpreting Multivariate Data, Wiley Series in Probability and Mathematical
Statistics, pages 21–36. Wiley, Chichester, 1981.
[362] J. C. Simo, R. L. Taylor, and K. S. Pister. Variational and projection methods for
the volume constraint in ﬁnite deformation elasto-plasticity. Computer Methods in
Applied Mechanics and Engineering, 51(1–3):177–208, 1985.
[363] I. Simonovski and L. Cizelj. Automatic parallel generation of ﬁnite element meshes
for complex spatial structures. Computational Materials Science, 50(5):1606–1618,
2011.
[364] J. Smith and S. Schaefer. Selective degree elevation for multi-sided Bézier patches.
Computer Graphics Forum, 34(2):609–615, 2015.
[365] D. Sohn, Y.-S. Cho, and S. Im. A novel scheme to generate meshes with hexahedral
elements and poly-pyramid elements: The carving technique. Computer Methods in
Applied Mechanics and Engineering, 201–204:208–227, 2012.
[366] D. Sohn, J. Han, Y.-S. Cho, and S. Im. A ﬁnite element scheme with the aid of a
new carving technique combined with smoothed integration. Computer Methods in
Applied Mechanics and Engineering, 254:42–60, 2013.

Bibliography
■303
[367] O. Steinbach. Numerical Approximation Methods for Elliptic Boundary Value Prob-
lems: Finite and Boundary Elements. Springer, New York, 2008.
[368] E. Steinitz. Polyeder und Raumeinteilungen. In W. F. Meyer and H. Mohrmann,
editors, Encyklopädie der mathematischen Wissenschaften mit Einschluss ihrer An-
wendungen, volume III, part 1, 2nd half, chapter 12, pages 1–139. Teubner, Leipzig,
1922.
[369] G. Strang and G. J. Fix. An Analysis of the Finite Element Method. Prentice-Hall
Series in Automatic Computation. Prentice-Hall, Englewood Cliﬀs, 1973.
[370] K. Sugihara. Surface interpolation based on new local coordinates. Computer-Aided
Design, 31(1):51–58, 1999.
[371] N. Sukumar.
Voronoi cell ﬁnite diﬀerence method for the diﬀusion operator on
arbitrary unstructured grids. International Journal for Numerical Methods in En-
gineering, 57(1):1–34, 2003.
[372] N. Sukumar. Construction of polygonal interpolants: a maximum entropy approach.
International Journal for Numerical Methods in Engineering, 61(12):2159–2181,
2004.
[373] N. Sukumar. Quadratic maximum-entropy serendipity shape functions for arbitrary
planar polygons. Computer Methods in Applied Mechanics and Engineering, 263:27–
41, 2013.
[374] N. Sukumar, J. E. Dolbow, and N. Moës. Extended ﬁnite element method in com-
putational fracture mechanics: a retrospective examination. International Journal
of Fracture, 196(1):189–206, 2015.
[375] N. Sukumar and E. A. Malsch. Recent advances in the construction of polygonal
ﬁnite element interpolants.
Archives of Computational Methods in Engineering,
13(1):129–163, 2006.
[376] N. Sukumar, B. Moran, and T. Belytschko. The natural element method in solid
mechanics. International Journal for Numerical Methods in Engineering, 43(5):839–
887, 1998.
[377] N. Sukumar, B. Moran, A. Y. Semenov, and V. V. Belikov.
Natural neighbor
Galerkin methods. International Journal for Numerical Methods in Engineering,
50(1):1–27, 2001.
[378] N. Sukumar and A. Tabarraei. Conforming polygonal ﬁnite elements. International
Journal for Numerical Methods in Engineering, 61(12):2045–2066, 2004.
[379] N. Sukumar and R. J.-B. Wets. Deriving the continuity of maximum-entropy basis
functions via variational analysis. SIAM Journal on Optimization, 18(3):914–925,
2007.
[380] N. Sukumar and R. W. Wright. Overview and construction of meshfree basis func-
tions: from moving least squares to entropy approximants. International Journal
for Numerical Methods in Engineering, 70(2):181–205, 2007.
[381] R. W. Sumner and J. Popović. Deformation transfer for triangle meshes. ACM
Transactions on Graphics, 23(3):399–405, 2004.
[382] R. W. Sumner, M. Zwicker, C. Gotsman, and J. Popović. Mesh-based inverse kine-
matics. ACM Transactions on Graphics, 24(3):488–495, 2005.

304
■Bibliography
[383] T. Sunada. Riemannian coverings and isospectral manifolds. Annals of Mathematics,
121(1):169–186, 1985.
[384] T. Sunada. Discrete geometric analysis. In P. Exner, J. P. Keating, P. Kuchment,
T. Sunada, and A. Teplyaev, editors, Analysis on Graphs and Its Applications, vol-
ume 77 of Proceedings of Symposia in Pure Mathematics, pages 51–83. American
Mathematical Society, Providence, 2008.
[385] T. Sussman and K.-J. Bathe.
A ﬁnite element formulation for nonlinear incom-
pressible elastic and inelastic analysis. Computers & Structures, 26(1–2):357–409,
1987.
[386] O. J. Sutton.
The Virtual Element Method in 50 lines of MATLAB.
arXiv:
1604.06021 [math.NA], 2016. https://arxiv.org/pdf/1604.06021.pdf.
[387] H. Talebi, A. Saputra, and C. Song.
Stress analysis of 3D complex geometries
using the scaled boundary polyhedral ﬁnite elements. Computational Mechanics,
58(4):697–715, 2016.
[388] C. Talischi and G. H. Paulino.
Addressing integration error for polygonal ﬁnite
elements through polynomial projections: A patch test connection. Mathematical
Models and Methods in Applied Sciences, 24(8):1701–1727, 2014.
[389] C. Talischi, G. H. Paulino, and C. H. Le. Honeycomb Wachspress ﬁnite elements
for structural topology optimization. Structural and Multidisciplinary Optimization,
37(6):569–583, 2009.
[390] C. Talischi, G. H. Paulino, A. Pereira, and I. F. M. Menezes.
Polygonal ﬁnite
elements for topology optimization: A unifying paradigm. International Journal for
Numerical Methods in Engineering, 82(6):671–698, 2010.
[391] C. Talischi, G. H. Paulino, A. Pereira, and I. F. M. Menezes. PolyMesher: a general-
purpose mesh generator for polygonal elements written in Matlab. Structural and
Multidisciplinary Optimization, 45(3):309–328, 2012.
[392] C. Talischi, G. H. Paulino, A. Pereira, and I. F. M. Menezes. PolyTop: a Matlab
implementation of a general topology optimization framework using unstructured
polygonal ﬁnite element meshes.
Structural and Multidisciplinary Optimization,
45(3):329–357, 2012.
[393] C. Talischi, A. Pereira, I. F. M. Menezes, and G. H. Paulino. Gradient correction
for polygonal and polyhedral ﬁnite elements. International Journal for Numerical
Methods in Engineering, 102(3–4):728–747, 2015.
[394] C. Talischi, A. Pereira, G. H. Paulino, I. F. M. Menezes, and M. S. Carvalho. Polygo-
nal ﬁnite elements for incompressible ﬂuid ﬂow. International Journal for Numerical
Methods in Fluids, 74(2):134–151, 2014.
[395] C. Taylor and P. Hood. A numerical solution of the Navier–Stokes equations using
the ﬁnite element technique. Computers & Fluids, 1(1):73–100, 1973.
[396] S. Torabi and J. Lowengrub. Simulating interfacial anisotropy in thin-ﬁlm growth
using an extended Cahn–Hilliard model. Physical Review E, 85(4):Article 041603,
16 pages, 2012.
[397] J. Tournois, C. Wormser, P. Alliez, and M. Desbrun. Interleaving Delaunay reﬁne-
ment and optimization for practical isotropic tetrahedron mesh generation. ACM
Transactions on Graphics, 28(3):Article 75, 9 pages, 2009.

Bibliography
■305
[398] N. G. Trillos, D. Slepčev, J. von Brecht, T. Laurent, and X. Bresson. Consistency
of Cheeger and ratio graph cuts. Journal of Machine Learning Research, 17:Article
181, 46 pages, 2016.
[399] P. G. Tucker. Hybrid Hamilton–Jacobi–Poisson wall distance function model. Com-
puters & Fluids, 44(1):130–142, 2011.
[400] W. T. Tutte. How to draw a graph. Proceedings of the London Mathematical Society,
13(3):743–767, 1963.
[401] A. van Gelder and J. Wilhelms. Topological considerations in isosurface generation.
ACM Transactions on Graphics, 13(4):337–375, 1994.
[402] R. Verfürth.
A note on polynomial approximation in Sobolev spaces.
ESAIM:
Mathematical Modelling and Numerical Analysis, 33(4):715–719, 1999.
[403] R. Verfürth. A Posteriori Error Estimation Techniques for Finite Element Meth-
ods. Numerical Mathematics and Scientiﬁc Computation. Oxford University Press,
Oxford, 2013.
[404] G. Voronoi. Nouvelles applications des paramètres continus à la théorie de formes
quadratiques. Journal für die reine und angewandte Mathematik, 134:198–287, 1908.
[405] E. Vouga, M. Höbinger, J. Wallner, and H. Pottmann. Design of self-supporting
surfaces. ACM Transactions on Graphics, 31(4):Article 87, 11 pages, 2012.
[406] E. Wachspress. Rational Bases and Generalized Barycentrics. Springer, Cham, 2016.
[407] E. L. Wachspress. A Rational Finite Element Basis, volume 114 of Mathematics in
Science and Engineering. Academic Press, New York, 1975.
[408] S. Waldron. Aﬃne generalised barycentric coordinates. Jaen Journal on Approxi-
mation, 3(2):209–226, 2011.
[409] M. Wardetzky. Discrete Diﬀerential Operators on Polyhedral Surfaces: Convergence
and Approximation. PhD thesis, Freie Universität Berlin, 2006.
[410] M. Wardetzky, S. Mathur, F. Kälberer, and E. Grinspun. Discrete Laplace operators:
No free lunch.
In Proceedings of the 5th Eurographics Symposium on Geometry
Processing (SGP 2007), pages 33–37, 2007.
[411] J. Warren. Barycentric coordinates for convex polytopes. Advances in Computa-
tional Mathematics, 6(1):97–108, 1996.
[412] J. Warren.
On the uniqueness of barycentric coordinates.
In R. Goldman and
R. Krasauskas, editors, Topics in Algebraic Geometry and Geometric Modeling, vol-
ume 334 of Contemporary Mathematics, pages 93–100. American Mathematical So-
ciety, Providence, 2003.
[413] J. Warren, S. Schaefer, A. N. Hirani, and M. Desbrun. Barycentric coordinates for
convex sets. Advances in Computational Mathematics, 27(3):319–338, 2007.
[414] O. Weber. Hybrid Methods for Interactive Shape Manipulation. PhD thesis, Technion
– Israel Institute of Technology, 2010.
[415] O. Weber, M. Ben-Chen, and C. Gotsman. Complex barycentric coordinates with
applications to planar shape deformation. Computer Graphics Forum, 28(2):587–
597, 2009.
[416] O. Weber, M. Ben-Chen, C. Gotsman, and K. Hormann. A complex view of barycen-
tric mappings. Computer Graphics Forum, 30(5):1533–1542, 2011.

306
■Bibliography
[417] O. Weber and C. Gotsman. Controllable conformal maps for shape deformation and
interpolation. ACM Transactions on Graphics, 29(4):Article 78, 11 pages, 2010.
[418] O. Weber, R. Poranne, and C. Gotsman. Biharmonic coordinates. Computer Graph-
ics Forum, 31(8):2409–2422, 2012.
[419] O. Weber and D. Zorin.
Locally injective parametrization with arbitrary ﬁxed
boundaries. ACM Transactions on Graphics, 33(4):Article 75, 12 pages, 2014.
[420] S. Weißer. Residual error estimate for BEM-based FEM on polygonal meshes. Nu-
merische Mathematik, 118(4):765–788, 2011.
[421] S. Weißer.
Arbitrary order Treﬀtz-like basis functions on polygonal meshes and
realization in BEM-based FEM.
Computers & Mathematics with Applications,
67(7):1390–1406, 2014.
[422] S. Weißer.
BEM-based ﬁnite element method with prospects to time dependent
problems. In Proceedings of the Jointly Organized 11th World Congress on Compu-
tational Mechanics (WCCM XI), 5th European Conference on Computational Me-
chanics (ECCM V), and 6th European Conference on Computational Fluid Dynam-
ics (ECFD VI), pages 4420–4427, 2014.
[423] S. Weißer.
Residual based error estimate and quasi-interpolation on polygonal
meshes for high order BEM-based FEM. Computers & Mathematics with Appli-
cations, 73(2):187–202, 2017.
[424] R. Westermann, L. Kobbelt, and T. Ertl. Real-time exploration of regular volume
data by adaptive reconstruction of isosurfaces. The Visual Computer, 15(2):100–111,
1999.
[425] E. Whiting, J. Ochsendorf, and F. Durand. Procedural modeling of structurally-
sound masonry buildings.
ACM Transactions on Graphics, 28(5):Article 112, 9
pages, 2009.
[426] H. Whitney. Geometric Integration Theory. Number 21 in Princeton Mathematical
Series. Princeton University Press, Princeton, 1957.
[427] S. O. Wilson.
Cochain algebra on manifolds and convergence under reﬁnement.
Topology and its Applications, 154(9):1898–1920, 2007.
[428] T. Winkler, J. Drieseberg, M. Alexa, and K. Hormann. Multi-scale geometry inter-
polation. Computer Graphics Forum, 29(2):309–318, 2010.
[429] P. Wriggers. Nonlinear Finite Element Methods. Springer, Berlin, 2008.
[430] G. Yang, D. M. Causon, and D. M. Ingram. Calculation of compressible ﬂows about
complex moving geometries using a three-dimensional Cartesian cut cell method.
International Journal for Numerical Methods in Fluids, 33(8):1121–1151, 2000.
[431] R. Zallen. The Physics of Amorphous Solids, chapter 2. Wiley, New York, 1983.
[432] W. Zeng, R. Guo, F. Luo, and X. Gu.
Discrete heat kernel determines discrete
Riemannian metric. Graphical Models, 74(4):121–129, 2012.
[433] J. Zhang, B. Deng, Z. Liu, G. Patanè, S. Bouaziz, K. Hormann, and L. Liu. Lo-
cal barycentric coordinates. ACM Transactions on Graphics, 33(6):Article 188, 12
pages, 2014.
[434] Y. Zhang, C. Bajaj, and B.-S. Sohn. 3D ﬁnite element meshing from imaging data.
Computer Methods in Applied Mechanics and Engineering, 194(48–49):5083–5106,
2005.

Bibliography
■307
[435] S. W. Zucker. Distance images and the enclosure ﬁeld: applications in intermediate-
level computer and biological vision. In M. Breuß, A. Bruckstein, and P. Maragos,
editors, Innovations for Shape Analysis: Models and Algorithms, Mathematics and
Visualization, pages 301–323. Springer, New York, 2013.


Index
A
Aﬃne coordinates, 12
Airy stress potential, 164
Arbitrary polygons (mappings), 65–66
B
Barycentric coordinates and their
properties, 3–22
barycentric coordinates for simplices,
5
generalized barycentric coordinates,
5–6
2D coordinates, 6–20
3D coordinates, 20–22
Barycentric interpolation, see Shape
quality for generalized
barycentric interpolation
Barycentric mappings, see Mappings
Bézier curves, 136–137
Bijective barycentric mapping, 66–68
Bijective composite barycentric mapping,
68–71
Bind pose, 145
Boundary Element Method (BEM)-based
Finite Element Method (FEM),
245–261, 278–279
adaptive BEM-based FEM in 2D,
253–258
construction of basis functions,
248–249
convection-adapted basis functions in
3D, 261
developments and outlook, 258–261
hierarchical construction for 3D
problems, 259–261
high-order BEM-based FEM in 2D,
247–252
residual-based error estimate for
polygonal meshes, 255–256
C
Cauchy kernel, 115
Cauchy transform, 116
CFEs, see Composite ﬁnite elements
Combinatorially regular triangulations
(CRT), 151–152
Complete family of coordinates, 9, 22
Complex barycentric coordinates (planar
shape deformation), 111–122
boundary element methods, 116
Cauchy kernel, 115
Cauchy transform, 116
conformal map, 114
conformal scale factor, 114
constant precision property, 112
general construction of, 118–121
holomorphic functions, 113–118
holomorphicity, 122
identity reproduction property, 112
linear precision property, 112
magic coordinates, 121–122
pullback metric, 114
trial function, 116
Complex coordinates, 2D coordinates, 14
Composite barycentric mapping, 69, 73
Composite ﬁnite elements (CFEs), 276
Computational mechanics, see
Maximum-entropy meshfree
coordinates in computational
mechanics
Conformal maps, 114, 127–131
log derivative construction, 127–130
shape interpolation, 130
variational conformal maps, 131
Conformal scale factor, 114
Constant precision property, 112
Cotan Laplacian, 88–90
CRT, see Combinatorially regular
triangulations
D
Delaunay triangulation, 35, 86, 234
Dirichlet energy, 84
Discrete exterior calculus (DEC), 87
Discrete harmonic coordinates, 8, 21
309

310
■Index
Discrete Hodge stars, 87
Discrete Laplacians, 83–93
cotan Laplacian and beyond, 88–90
discrete Hodge stars, 87
discrete versus smooth Laplacians,
90–93
Hodge decomposition, 88
Laplacians on graphs, 83–84
Laplacians on simplicial manifolds,
86–87
spectrum, 84–86
strongly and weakly deﬁned
Laplacians, 87–88
Discrete theory (self-supporting surfaces),
166–170
discrete Airy stress potential, 167–169
discrete curvature interpretation of
equilibrium, 169–170
FEM discretization of Airy stress, 169
thrust network analysis, 166–167
thrust networks as block networks,
167
E
Elliptic problems on polygonal meshes, see
Virtual element methods
(VEMs) for elliptic problems on
polygonal meshes
Entropy maximization, see
Maximum-entropy meshfree
coordinates in computational
mechanics
Equilibrium analysis, 158
Extremely large deformation with
polygonal and polyhedral
elements, 197–227
conforming Galerkin approximations,
213–214
displacement-based formulation, 201
displacement-based polygonal and
polyhedral elements, 214–217
displacement space on polygons in
2D, 203–204
displacement space on polyhedra in
3D, 204
ﬁlled elastomers, application to the
study of, 221–227
ﬁnite elasticity formulations, 200–202
general two-ﬁeld mixed variational
formulation, 201–202
gradient correction scheme and its
properties, 208–212
numerical examples, 214–220
polygonal and polyhedral
approximations, 203–205
pressure space on polygons in 2D,
204–205
quadrature rules and accuracy
requirements, 205–208
scalar problems, gradient correction
for, 208–211
two-ﬁeld mixed polygonal elements,
217–220
vectorial problems, gradient
correction for, 212
F
Face-centered cubic (FCC) structure, 193
Finite Element Method (FEM), 89, 264,
see also Boundary Element
Method-based Finite Element
Method
Finite element tearing and interconnecting
(FETI), 259
Force polygon, 162
Free-form deformations (FFDs), 144
G
Generalized barycentric coordinates
(GBCs), 6, 264
Generalized barycentric interpolation, see
Shape quality for generalized
barycentric interpolation
Generalized triangulations, see
Triangulations (generalized)
Gordon–Wixom coordinates, 2D
coordinates, 10–11
Gordon–Wixom interpolation, 51–57
Hermite-type, 54–55
Lagrange-type, 51–54
modiﬁed Hermite-type, 55–56
for polyharmonic interpolation, 56–57
Graphics processing units (GPUs), 99
Graph Laplacian, 84
H
Hanging nets, 160–161
Harmonic coordinates, 11
interpolation error estimates on
polygons, 35–36

Index
■311
polygons, 35–36
polyhedra and polytopes, 40
2D coordinates, 11
Hermite coordinates, 2D coordinates,
13–14
Heyman’s safe theorem, 159–160
Hodge decomposition, 81, 88
Hodge-optimized triangulations (HOT),
155
Holomorphic functions, 113–118
Homogeneous coordinates, 6
HOT, see Hodge-optimized triangulations
I
Identity reproduction property, 112
Interpolation error estimates on polygons,
35–36
K
Kronecker-delta property, 231
L
Laplace coordinates, 13, 48–49
Laplacians, 77–93
basic properties, 78–79
cotan Laplacian, 88–90
Dirichlet energy, 84
discrete Hodge stars, 87
discrete Laplacians, 83–93
discrete versus smooth Laplacians,
90–93
graphs, Laplacians on, 83–84
Hodge decomposition, 88
Rham map, 89
Riemannian manifolds, Laplacians on,
79–83
simplicial manifolds, Laplacians on,
86–87
strongly and weakly deﬁned
Laplacians, 87–88
Law of the lever, 4
Linear precision property, 112
Local coordinates, 12
Local maximum-entropy (LME)
approximants, 235
M
Made-to-order Angle Guided Interpolating
Coordinates (MAGIC), 122
Mappings, 63–76
arbitrary polygons, 65–66
bijective barycentric mapping, 66–68
bijective composite barycentric
mapping, 68–71
choosing the coordinates, 75
choosing the vertex paths, 75–76
closed planar curves, 71–73
composite barycentric mappings, limit
of, 70–71
convex polygons, 64–65
extensions, 71–74
perturbed target polygons, 66–68
polyhedra, 73–74
practical considerations, 75–76
Masonry structure, 158–159
Maximal Poisson sampling (MPS), 194
Maximum entropy coordinates, 2D
coordinates, 11–12
Maximum-entropy meshfree coordinates in
computational mechanics,
229–243
applications, 240–243
further extensions, 238–240
high-order partial diﬀerential
equations, 240–241
locality (local maximum-entropy
approximants), 234–238
manifold approximation, 241–243
outlook, 243
selecting barycentric coordinates
through entropy maximization,
231–233
Mean value coordinates
interpolation error estimates on
polygons, 39
polygons, 39
2D coordinates, 8–9
3D coordinates, 21–22
Mesh parameterization, 97–108
applications, 98–100
choosing the weights, 108
convex combination, 103
genus, 100
parametric space, 98
sign changes, 105
solving the linear systems, 106–108
texture mapping, 99
topology, notions of, 100–102

312
■Index
Tutte’s barycentric mapping theorem,
102–106
Metric coordinates, 9–10
Mimetic ﬁnite diﬀerence (MFD), 276
MPS, see Maximal Poisson sampling
Multi-sided patches via barycentric
coordinates, 135–146
applications, 143–146
Bézier curves, 136–137
bind pose, 145
degree elevation, 137–138, 142
free-form deformations, 144
multisided Bézier patches in higher
dimensions, 138–142
S-patches, indexing for, 139–141
spatial deformation, 144–146
surface patches, 143–144
N
Neo-Hookean elastomers, 222–223
Nonconforming virtual elements, 267
P
Partial diﬀerential equations (PDEs), 230,
269
Patches, see Multi-sided patches via
barycentric coordinates
PDT, see Primal-dual triangulation
Planar shape deformation, 109–133
boundary element methods, 116
Cauchy transform, 116
complex barycentric coordinates,
111–122
conformal maps, 114, 127–131
constant precision property, 112
holomorphic functions, 113–118
identity reproduction property, 112
implementation details, 132–133
linear precision property, 112
magic coordinates, 121–122
pullback metric, 114
trial function, 116
variational barycentric coordinates,
123–126
visualizing planar maps, 132–133
Poisson coordinates, 2D coordinates, 10
Polygonal meshes, elliptic problems on, see
Virtual element methods for
elliptic problems on polygonal
meshes
Polygons, interpolation error estimates on,
34–39
Polyhedral ﬁnite elements in solid
mechanics, applications of,
179–196
element integration, 186–187
fracture methodology, 192–193
fragmentation modeling, 191–195
maximal Poisson sampling, 194
outlook, 195–196
polyhedral ﬁnite element formulation,
184–187
random Voronoi meshes, 193–194
rapid engineering analysis, 187–190
shape functions, 185–186
solid mechanics, governing equations
of, 183–184
trial function, 185
weak form of governing equations, 185
Polyhedra and polytopes, interpolation
error estimates on, 39–41
Power coordinates, 9
Primal-dual triangulation (PDT), 150–151
Primal-dual triangulations (generalized),
148–151
cell complex, 148
classical examples, 149–150
dual cell complexes, 149
parametrization of primal-dual
triangulations, 152–153
power diagrams and weighted
Delaunay triangulations, 149
regular triangulations, 149
simplicial complex, 148
weighted circumcenter, 150
Pseudo-harmonic barycentric coordinates,
51
Pullback metric, 114
R
Random close packed (RCP)
structure, 193
Voronoi mesh, 192
Reciprocal diagrams, 161–162
Rham map, 89
Riemannian manifolds, Laplacians on,
79–83

Index
■313
exterior calculus, 79–81
Hodge decomposition, 81
spectrum, 82–83
Rippa’s theorem, 86
S
Self-supporting surfaces, 157–176
Airy stress potential, 164
alternating optimization, 170–171
block layouts from stable surfaces, 175
continuum limit, 162
curvature interpretation of
equilibrium, 165–166
discrete Airy stress potential, 167–169
discrete curvature interpretation of
equilibrium, 169–170
discrete theory, 166–170
dual formulation as vertex weights,
172
equilibrium analysis, 158
equilibrium equations, 163
FEM discretization of Airy stress, 169
force polygon, 162
Gaudí and hanging nets, 160–161
Heyman’s safe theorem, 159–160
historical overview, 158–162
masonry structure, 158–159
Maxwell’s reciprocal diagrams,
161–162
open problems, 175–176
optimizing for stability, 170–175
perfect Laplacian optimization,
172–173
progressive stable structures, 176
relative-curvature-based smoothing,
173–174
relative curvatures, 164–165
sensitivity analysis of masonry
structures, 176
smooth theory, 162–166
steel-glass structures and PQ faces,
174–175
thrust network analysis, 166–167
thrust networks as block networks,
167
Shape quality for generalized barycentric
interpolation, 23–42
deconstructing the a priori error
estimate, 26–29
extensions and future directions,
41–42
interpolation error estimates on
polygons, 34–39
interpolation error estimates on
polyhedra and polytopes, 39–41
“low-quality geometric domains,” 24
polygons and polyhedra, shape
quality metrics for, 31–34
simplices, shape quality metrics for,
29–31
Sibson coordinates, 2D coordinates, 12–13
Silicone elastomer, 223–227
Smooth theory (self-supporting surfaces),
162–166
Airy stress potential, 164
continuum limit, 162
curvature interpretation of
equilibrium, 165–166
equilibrium equations, 163
relative curvatures, 164–165
Solid mechanics, see Polyhedral ﬁnite
elements in solid mechanics,
applications of
Steel-glass structures, 174–175
T
Texture mapping, 99
3D coordinates, 20–22
complete family of coordinates, 22
discrete harmonic coordinates, 21
mean value coordinates, 21–22
Wachspress coordinates, 20
Thrust network, 160
Transﬁnite barycentric coordinates, 43–62
generalized mean value potentials for
smooth domains, 57–61
generalized potentials for polygons,
61–62
Gordon–Wixom interpolation, 51–57
Laplace coordinates, 48–49
Laplace and Wachspress coordinates
coincide for a disk, 51
three-point coordinates, 47–48
Wachspress coordinates, 49–51
weighted mean value interpolation,
45–51
Trial function, 116, 185
Triangulation coordinates

314
■Index
interpolation error estimates on
polygons, 34–35
polygons, 34–35
Triangulations (generalized), 147–156
characterization theorem, 151–153
combinatorially regular
triangulations, 151–152
discrete exterior calculus framework,
153–154
discrete representation, 153–156
equivalence between PDT and CRT,
152
Hodge-optimized triangulations, 155
mesh optimization, 154–156
parametrization of primal-dual
triangulations, 152–153
primal-dual triangulations
(generalized), 148–151
Tutte’s barycentric mapping theorem,
102–106
2D coordinates, 6–20
aﬃne coordinates, 12
comparison, 14–20
complete family of coordinates, 9
complex coordinates, 14
discrete harmonic coordinates, 8
Gordon–Wixom coordinates, 10–11
harmonic coordinates, 11
Hermite coordinates, 13–14
Laplace coordinates, 13
local coordinates, 12
maximum entropy coordinates, 11–12
mean value coordinates, 8–9
metric coordinates, 9–10
Poisson coordinates, 10
Sibson coordinates, 12–13
Wachspress coordinates, 7
V
Variational barycentric coordinates (planar
shape deformation), 123–126
point-based barycentric maps,
123–124
point-to-point barycentric
coordinates, 124–126
Virtual element method (VEM), 185, 199,
247
Virtual element methods (VEMs) for
elliptic problems on polygonal
meshes, 263–279
BEM-based FEM, 278–279
conforming VEM, 274–275
connection with other methods,
276–279
convenient basis, 269–271
degrees of freedom of the space, 266
elliptic PDEs, 273–275
extension to three dimensions, 273
generalization to arbitrary order
discrete spaces, 266–267
grid functions, 276
link between the bases, 271–272
lowest order discrete space, 265–266
natural basis, 267–268
nodal MFD method, 276–278
nonconforming virtual elements, 267
polygonal and polyhedral ﬁnite
element method, 276
VEM enhancement, 273
virtual element spaces and GBC,
265–273
Voronoi tessellation, 193
W
Wachspress coordinates
interpolation error estimates on
polygons, 37–38
polygons, 37–38
polyhedra and polytopes, 40–41
transﬁnite, 49–51
2D coordinates, 7
3D coordinates, 20
Weighted circumcenter, 150
Weighted Delaunay triangulations, 92
Weighted mean value interpolation
(transﬁnite barycentric
coordinates), 45–51
general construction, 45–47
transﬁnite Laplace coordinates, 48–49
transﬁnite Laplace and Wachspress
coordinates coincide for a disk,
51
transﬁnite three-point coordinates,
47–48
transﬁnite Wachspress coordinates,
49–51
Weight functions, 6

