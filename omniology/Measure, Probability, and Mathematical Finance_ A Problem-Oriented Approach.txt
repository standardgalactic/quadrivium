

MEASURE, PROBABILITY, 
AND MATHEMATICAL 
FINANCE 


MEASURE, PROBABILITY, 
AND MATHEMATICAL 
FINANCE 
A Problem-Oriented Approach 
Guojun Gan 
Manulife Financial 
Toronto, ON, Canada 
Chaoqun Ma 
School of Business Administration 
Hunan University 
Changsha, Hunan, P.R. China 
HongXie 
Manulife Financial 
Toronto, ON, Canada 
WILEY 

CopyrightÂ© 2014 by John Wiley & Sons, Inc. All rights reserved. 
Published by John Wiley & Sons, Inc., Hoboken, New Jersey. 
Published simultaneously in Canada. 
No part of this publication may be reproduced, stored in a retrieval system or transmitted in any form or 
by any means, electronic, mechanical, photocopying, recording, scanning or otherwise, except as 
permitted under Section I 07 or I 08 of the 1976 United States Copyright Act, without either the prior 
written permission of the Publisher, or authorization through payment of the appropriate per-copy fee to 
the Copyright Clearance Center, Inc., 222 Rosewood Drive, Danvers, MA 01923, (978) 750-8400, fax 
(978) 750-4470, or on the web at www.copyright.com. Requests to the Publisher for permission should 
be addressed to the Permissions Department, John Wiley & Sons, Inc., Ill River Street, Hoboken, NJ 
07030, (201) 748-60 II, fax (201) 748-6008, or online at http://www.wiley.com/go/permission. 
Limit of Liability/Disclaimer of Warranty: While the publisher and author have used their best efforts in 
preparing this book, they make no representation or warranties with respect to the accuracy or 
completeness of the contents of this book and specifically disclaim any implied warranties of 
merchantability or fitness for a particular purpose. No warranty may be created or extended by sales 
representatives or written sales materials. The advice and strategies contained herein may not be suitable 
for your situation. You should consult with a professional where appropriate. Neither the publisher nor 
author shall be liable for any loss of profit or any other commercial damages, including but not limited 
to special, incidental, consequential, or other damages. 
For general information on our other products and services please contact our Customer Care 
Department within the United States at (800) 762-2974, outside the United States at (317) 572-3993 or 
fax (317) 572-4002. 
Wiley also publishes its books in a variety of electronic formats. Some content that appears in print, 
however, may not be available in electronic formats. For more information about Wiley products, visit 
our web site at www.wiley.com. 
Library of Congress Cataloging-in-Publication Data is available. 
Measure, Probability, and Mathematical Finance: A Problem-Oriented Approach 
Guojun Gan, Chaoqun Ma, and Hong Xie 
ISBN 978-1-118-83196-0 
Printed in the United States of America. 
10 9 8 7 6 5 4 3 2 I 

To my parents 
-Guojun Gan 
To my wife and my 
daughter 
-ChaoqunMa 
To my family and 
friends 
-Hong Xie 


CONTENTS 
Preface 
Financial Glossary 
PART I MEASURE THEORY 
1 
Sets and Sequences 
1.1 
1.2 
1.3 
1.4 
1.5 
Basic Concepts and Facts 
Problems 
Hints 
Solutions 
Bibliographic Notes 
2 
Measures 
2.1 
2.2 
2.3 
2.4 
Basic Concepts and Facts 
Problems 
Hints 
Solutions 
XVll 
xxii 
3 
3 
6 
8 
8 
13 
15 
15 
18 
20 
21 
vii 

viii 
CONTENTS 
2.5 
Bibliographic Notes 
28 
3 
Extension of Measures 
29 
3.1 
Basic Concepts and Facts 
29 
3.2 
Problems 
30 
3.3 
Hints 
32 
3.4 
Solutions 
32 
3.5 
Bibliographic Notes 
36 
4 
Lebesgue-Stieltjes Measures 
37 
4.1 
Basic Concepts and Facts 
37 
4.2 
Problems 
39 
4.3 
Hints 
41 
4.4 
Solutions 
41 
4.5 
Bibliographic Notes 
45 
5 
Measurable Functions 
47 
5.1 
Basic Concepts and Facts 
47 
5.2 
Problems 
48 
5.3 
Hints 
50 
5.4 
Solutions 
51 
5.5 
Bibliographic Notes 
56 
6 
Lebesgue Integration 
57 
6.1 
Basic Concepts and Facts 
57 
6.2 
Problems 
59 
6.3 
Hints 
62 
6.4 
Solutions 
64 
6.5 
Bibliographic Notes 
76 
7 
The Radon-Nikodym Theorem 
77 
7.1 
Basic Concepts and Facts 
77 
7.2 
Problems 
79 
7.3 
Hints 
80 
7.4 
Solutions 
80 
7.5 
Bibliographic Notes 
83 
8 
LP Spaces 
85 

CONTENTS 
ix 
8.1 
Basic Concepts and Facts 
85 
8.2 
Problems 
88 
8.3 
Hints 
89 
8.4 
Solutions 
90 
8.5 
Bibliographic Notes 
95 
9 
Convergence 
97 
9.1 
Basic Concepts and Facts 
97 
9.2 
Problems 
98 
9.3 
Hints 
100 
9.4 
Solutions 
102 
9.5 
Bibliographic Notes 
111 
10 
Product Measures 
113 
10.1 
Basic Concepts and Facts 
113 
10.2 
Problems 
115 
10.3 
Hints 
118 
10.4 
Solutions 
118 
10.5 
Bibliographic Notes 
123 
PART II 
PROBABILITY THEORY 
11 
Events and Random Variables 
127 
11.1 
Basic Concepts and Facts 
127 
11.2 
Problems 
130 
11.3 
Hints 
132 
11.4 
Solutions 
133 
11.5 
Bibliographic Notes 
139 
12 
Independence 
141 
12.1 
Basic Concepts and Facts 
141 
12.2 
Problems 
142 
12.3 
Hints 
145 
12.4 
Solutions 
146 
12.5 
Bibliographic Notes 
159 
13 
Expectation 
161 
13.1 
Basic Concepts and Facts 
161 

X 
CONTENTS 
13.2 
Problems 
163 
13.3 
Hints 
165 
13.4 
Solutions 
166 
13.5 
Bibliographic Notes 
172 
14 
Conditional Expectation 
173 
14.1 
Basic Concepts and Facts 
173 
14.2 
Problems 
175 
14.3 
Hints 
178 
14.4 
Solutions 
179 
14.5 
Bibliographic Notes 
187 
15 
Inequalities 
189 
15.1 
Basic Concepts and Facts 
189 
15.2 
Problems 
190 
15.3 
Hints 
191 
15.4 
Solutions 
192 
15.5 
Bibliographic Notes 
198 
16 
Law of Large Numbers 
199 
16.1 
Basic Concepts and Facts 
199 
16.2 
Problems 
200 
16.3 
Hints 
203 
16.4 
Solutions 
205 
16.5 
Bibliographic Notes 
215 
17 
Characteristic Functions 
217 
17.1 
Basic Concepts and Facts 
217 
17.2 
Problems 
218 
17.3 
Hints 
220 
17.4 
Solutions 
221 
17.5 
Bibliographic Notes 
226 
18 
Discrete Distributions 
227 
18.1 
Basic Concepts and Facts 
227 
18.2 
Problems 
228 
18.3 
Hints 
230 
18.4 
Solutions 
231 

CONTENTS 
xi 
18.5 
Bibliographic Notes 
237 
19 
Continuous Distributions 
239 
19.1 
Basic Concepts and Facts 
239 
19.2 
Problems 
241 
19.3 
Hints 
244 
19.4 
Solutions 
246 
19.5 
Bibliographic Notes 
256 
20 
Central Limit Theorems 
257 
20.1 
Basic Concepts and Facts 
257 
20.2 
Problems 
258 
20.3 
Hints 
260 
20.4 
Solutions 
261 
20.5 
Bibliographic Notes 
267 
PART Ill 
STOCHASTIC PROCESSES 
21 
Stochastic Processes 
271 
21.1 
Basic Concepts and Facts 
271 
21.2 
Problems 
275 
21.3 
Hints 
278 
21.4 
Solutions 
280 
21.5 
Bibliographic Notes 
289 
22 
Martingales 
291 
22.1 
Basic Concepts and Facts 
291 
22.2 
Problems 
292 
22.3 
Hints 
294 
22.4 
Solutions 
295 
22.5 
Bibliographic Notes 
300 
23 
Stopping Times 
301 
23.1 
Basic Concepts and Facts 
301 
23.2 
Problems 
303 
23.3 
Hints 
305 
23.4 
Solutions 
307 
23.5 
Bibliographic Notes 
319 

xii 
CONTENTS 
24 
Martingale Inequalities 
321 
24.1 
Basic Concepts and Facts 
321 
24.2 
Problems 
322 
24.3 
Hints 
323 
24.4 
Solutions 
324 
24.5 
Bibliographic Notes 
331 
25 
Martingale Convergence Theorems 
333 
25.1 
Basic Concepts and Facts 
333 
25.2 
Problems 
334 
25.3 
Hints 
336 
25.4 
Solutions 
336 
25.5 
Bibliographic Notes 
342 
26 
Random Walks 
343 
26.1 
Basic Concepts and Facts 
343 
26.2 
Problems 
344 
26.3 
Hints 
346 
26.4 
Solutions 
347 
26.5 
Bibliographic Notes 
355 
27 
Poisson Processes 
357 
27.1 
Basic Concepts and Facts 
357 
27.2 
Problems 
359 
27.3 
Hints 
361 
27.4 
Solutions 
361 
27.5 
Bibliographic Notes 
371 
28 
Brownian Motion 
373 
28.1 
Basic Concepts and Facts 
373 
28.2 
Problems 
375 
28.3 
Hints 
377 
28.4 
Solutions 
378 
28.5 
Bibliographic Notes 
387 
29 
Markov Processes 
389 
29.1 
Basic Concepts and Facts 
389 
29.2 
Problems 
391 

29.3 
Hints 
29.4 
Solutions 
29.5 
Bibliographic Notes 
30 
Levy Processes 
31 
32 
33 
34 
30.1 
Basic Concepts and Facts 
30.2 
Problems 
30.3 
Hints 
30.4 
Solutions 
30.5 
Bibliographic Notes 
PART IV STOCHASTIC CALCULUS 
The Wiener Integral 
31.1 
Basic Concepts and Facts 
31.2 
Problems 
31.3 
Hints 
31.4 
Solutions 
31.5 
Bibliographic Notes 
The Ito Integral 
32.1 
Basic Concepts and Facts 
32.2 
Problems 
32.3 
Hints 
32.4 
Solutions 
32.5 
Bibliographic Notes 
Extension of the Ito Integral 
33.1 
Basic Concepts and Facts 
33.2 
Problems 
33.3 
Hints 
33.4 
Solutions 
33.5 
Bibliographic Notes 
Martingale Stochastic Integrals 
34.1 
Basic Concepts and Facts 
34.2 
Problems 
34.3 
Hints 
CONTENTS 
xiii 
393 
394 
399 
401 
401 
404 
407 
408 
417 
421 
421 
423 
424 
425 
429 
431 
431 
433 
437 
438 
452 
453 
453 
455 
456 
457 
462 
463 
463 
468 
469 

xiv 
CONTENTS 
34.4 
Solutions 
470 
34.5 
Bibliographic Notes 
475 
35 
The Ito Formula 
477 
35.1 
Basic Concepts and Facts 
477 
35.2 
Problems 
481 
35.3 
Hints 
483 
35.4 
Solutions 
485 
35.5 
Bibliographic Notes 
494 
36 
Martingale Representation Theorem 
495 
36.1 
Basic Concepts and Facts 
495 
36.2 
Problems 
496 
36.3 
Hints 
497 
36.4 
Solutions 
498 
36.5 
Bibliographic Notes 
501 
37 
Change of Measure 
503 
37.1 
Basic Concepts and Facts 
503 
37.2 
Problems 
504 
37.3 
Hints 
508 
37.4 
Solutions 
508 
37.5 
Bibliographic Notes 
513 
38 
Stochastic Differential Equations 
515 
38.1 
Basic Concepts and Facts 
515 
38.2 
Problems 
517 
38.3 
Hints 
521 
38.4 
Solutions 
522 
38.5 
Bibliographic Notes 
530 
39 
Diffusion 
531 
39.1 
Basic Concepts and Facts 
531 
39.2 
Problems 
534 
39.3 
Hints 
536 
39.4 
Solutions 
537 
39.5 
Bibliographic Notes 
545 
40 
The Feynman-Kac Formula 
547 

CONTENTS 
XV 
40.1 
Basic Concepts and Facts 
547 
40.2 
Problems 
549 
40.3 
Hints 
551 
40.4 
Solutions 
552 
40.5 
Bibliographic Notes 
557 
PART V STOCHASTIC FINANCIAL MODELS 
41 
Discrete-Time Models 
561 
41.1 
Basic Concepts and Facts 
561 
41.2 
Problems 
565 
41.3 
Hints 
568 
41.4 
Solutions 
569 
41.5 
Bibliographic Notes 
576 
42 
Black-Scholes Option Pricing Models 
579 
42.1 
Basic Concepts and Facts 
579 
42.2 
Problems 
583 
42.3 
Hints 
585 
42.4 
Solutions 
586 
42.5 
Bibliographic Notes 
591 
43 
Path-Dependent Options 
593 
43.1 
Basic Concepts and Facts 
593 
43.2 
Problems 
598 
43.3 
Hints 
600 
43.4 
Solutions 
601 
43.5 
Bibliographic Notes 
608 
44 
American Options 
609 
44.1 
Basic Concepts and Facts 
609 
44.2 
Problems 
613 
44.3 
Hints 
616 
44.4 
Solutions 
617 
44.5 
Bibliographic Notes 
626 
45 
Short Rate Models 
629 
45.1 
Basic Concepts and Facts 
629 

xvi 
CONTENTS 
45.2 
Problems 
631 
45.3 
Hints 
635 
45.4 
Solutions 
635 
45.5 
Bibliographic Notes 
644 
46 
Instantaneous Forward Rate Models 
647 
46.1 
Basic Concepts and Facts 
647 
46.2 
Problems 
650 
46.3 
Hints 
654 
46.4 
Solutions 
654 
46.5 
Bibliographic Notes 
665 
47 
LIBOR Market Models 
667 
47.1 
Basic Concepts and Facts 
667 
47.2 
Problems 
668 
47.3 
Hints 
672 
47.4 
Solutions 
673 
47.5 
Bibliographic Notes 
685 
References 
687 
List of Symbols 
703 
Subject Index 
707 

PREFACE 
Mathematical finance, a new branch of mathematics concerned with financial mar-
kets, is experiencing rapid growth. During the last three decades, many books and 
papers in the area of mathematical finance have been published. However, under-
standing the literature requires that the reader have a good background in measure-
theoretic probability, stochastic processes, and stochastic calculus. The purpose of 
this book is to provide the reader with an introduction to the mathematical theory 
underlying the financial models being used and developed on Wall Street. To this 
end, this book covers important concepts and results in measure theory, probabil-
ity theory, stochastic processes, and stochastic calculus so that the reader will be in 
a position to understand these financial models. Problems as well as solutions are 
included to help the reader learn the concepts and results quickly. 
In this book, we adopted the definitions and theorems from various books and 
presented them in a mathematically rigorous way. We tried to cover the most of the 
basic concepts and the important theorems. We selected the problems in this book 
in such a way that the problems will help readers understand and know how to apply 
the concepts and theorems. This book includes 516 problems, most of which are not 
difficult and can be solved by applying the definitions, theorems, and the results of 
previous problems. 
This book is organized into five parts, each of which is further organized into sev-
eral chapters. Each chapter is divided into five sections. The first section presents 
xvii 

XViii 
PREFACE 
the definitions of important concepts and theorems. The second, third, and fourth 
sections present the problems, hints on how to solve the problems, and the full so-
lutions to the problems, respectively. The last section contains bibliographic notes. 
Interdependencies between all chapters are shown in Table 0.1. 
Table 0.1: Interdependencies between Chapters. 
Chapter 
I. Sets and Sequences 
2. Measures 
3. Extension of Measures 
4. Lebesgue-Stieltjes Measures 
5. Measurable Functions 
6. Lebesgue Integration 
7. The Radon-Nikodym Theorem 
8. LP Spaces 
9. Convergence 
10. Product Measures 
11. Events and Random Variables 
12. Independence 
13. Expectation 
14. Conditional Expectation 
15. Inequalities 
16. Law of Large Numbers 
17. Characteristic Functions 
18. Discrete Distributions 
19. Continuous Distributions 
20. Central Limit Theorems 
21. Stochastic Processes 
22. Martingales 
23. Stopping Times 
24. Martingale Inequalities 
25. Martingale Convergence Theorems 
26. Random Walks 
27. Poisson Processes 
28. Brownian Motion 
Related to Chapter(s) 
1;2 
2;3 
2 
1 ;2;5 
2;6 
2;6 
1;2;6;8 
2;3;5;6 
1;2;4;5 
2;3;5;11 
2;6;8;10;11;12 
1 ;2;5;6;7;8;10;11; 12;13 
8;11;14 
2;8;9;1 0; 12; 13; 15 
5;6;8;11 ;12;13; 15 
12;14;17 
6;10;12;13;17 
6;9; II 
2;5;10;11;12;19 
2;5;11;13;14;15 
2;5;9; 11; 14;21 ;22 
2;6;8; 13;14;15;23 
1 ;6;9; 11; 14; 15;22 
8;9; 13; 14; 15; 19;20;22;23;24 
11; 12; 14; 17;21 ;22 
8;9; 11; 12; 14; 15; 16; 17; 19 

29. Markov Processes 
30. Levy Processes 
31. The Wiener Integral 
32. The Ito Integral 
33. Extension of the Ito Integrals 
34. Martingale Stochastic Integrals 
35. The Ito Formula 
36. Martingale Representation Theorem 
37. Change of Measure 
38. Stochastic Differential Equations 
39. Diffusion 
40. The Feynman-Kac Formula 
41. Discrete-Time Models 
42. Black-Scholes Option Pricing Models 
43. Path-Dependent Options 
44. American Options 
45. Short Rate Models 
46. Instantaneous Forward Rate Models 
47. LIBOR Market Models 
PREFACE 
XiX 
2;6;11;14;21 
1 ;5;6;11 ;12;14;17;19;22;27;28;29 
6;9;15;19;28 
5;6;8;10;14;15;22;24;28 
9; 1 0; 14;22;23;32 
14;15;19;27;32 
6;8;9;22;24;32;34 
9; 14;25 ;28;32;33 ;35 
7; 14;32;34;35 
8;11;13;32;34;35 
6;9; 11; 14; 19;21 ;24;32;35 ;38 
6; 14;32;35;38;39 
7;12;14;22;23 
9; 14; 19;24;32;33;35;36;37 ;38;41 
10;14;19;28;37;38;42 
14; 15 ;21 ;22;23;32;35 ;36;37 ;42;43 
11;14;19;29;32;35;37;38;39;40 
1 0; 14; 19;32;34;35;37 ;38;40;45 
14;32;37;45;46 
In Part I, we present measure theory, which is indispensable to the rigorous de-
velopment of probability theory. Measure theory is also necessary for us to discuss 
recently developed theories and models in finance, such as the martingale measures, 
the change of numeraire theory, and the London interbank offered rate (LIBOR) 
market models. 
In Part II, we present probability theory in a measure-theoretic mathematical 
framework, which was introduced by A.N. Kolmogorov in 1937 in order to deal 
with David Hilbert's sixth problem. The material presented in this part was selected 
to facilitate the development of stochastic processes in Part III. 
In Part III, we present stochastic processes, which include martingales and Brow-
nian motion. In Part IV, we discuss stochastic calculus. Both stochastic processes 
and stochastic calculus are important to modem mathematical finance as they are 
used to model asset prices and develop derivative pricing models. 
In Part V, we present some classic models in mathematical finance. Many pricing 
models have been developed and published since the seminal work of Black and 
Scholes. This part covers only a small portion of many models. 
In this book, we tried to use a uniform set of symbols and notation. For example, 
we used N, R, and 0 to denote the set of natural numbers (i.e., nonnegative integers), 

XX 
PREFACE 
the set of real numbers, and the empty set, respectively. A comprehensive list of 
symbols is also provided at the end of this book. 
We have taken great pains to ensure the accuracy of the formulas and statements 
in this book. However, a few errors are inevitable in almost every book of this size. 
Please feel free to contact us if you spot errors or have any other constructive sug-
gestions. 
How to Use This Book 
This book can be used by individuals in various ways: 
(a) It can be used as a self-study book on mathematical finance. The prerequisite is 
linear algebra and calculus at the undergraduate level. This book will provide 
you with a series of concepts, facts, and problems. You should explore each 
problem and write out your solution in such a way that it can be shared with 
others. By doing this you will be able to actively develop an in-depth and com-
prehensive understanding of the concepts and principles that cannot be archived 
by passively reading or listening to comments of others. 
(b) It can be used as a reference book. This book contains the most important 
concepts and theorems from mathematical finance. The reader can find the 
definition of a concept or the statement of a theorem in the book through the 
index at the end of this book. 
(c) It can be used as a supplementary book for individuals who take advanced 
courses in mathematical finance. This book starts with measure theory and 
builds up to stochastic financial models. It provides necessary prerequisites for 
students who take advanced courses in mathematical finance without complet-
ing background courses. 
Acknowledgments 
We would like to thank all the academics and practitioners who have contributed to 
the knowledge of mathematical finance. In particular, we would like to thank the 
following academics and practitioners whose work constitutes the backbone of this 
book: Robert B. Ash, Krishna B. Athreya, Rabi Bhattacharya, Patrick Billingsley, 
Tomas Bjork, Fischer Sheffey Black, Kai Lai Chung, Erhan <;:inlar, Catherine A. 
Doleans-Dade, Darrell Duffie, Richard Durrett, Robert J. Elliott, Damir Filipovic, 
Allan Gut, John Hull, Ioannis Karatzas, Fima C. Klebaner, P. Ekkehard Kopp, Hui-
Hsiung Kuo, Soumendra N. Lahiri, Damien Lamberton, Bernard Lapeyre, Gregory 
F. Lawler, Robert C. Merton, Marek Musiela, Bernt Oksendal, Andrea Pascucci, 
Jeffrey S. Rosenthal, Sheldon M. Ross, Marek Rutkowski, Myron Scholes, Steven 
Shreve, J. Michael Steele, and Edward C. Waymire. 
We are grateful to Roman Naryshkin and several anonymous reviewers for their 
helpful comments. Guojun Gan and Hong Xie would like to thank their friends 

PREFACE 
XXi 
and colleagues at the Global Variable Annuity Hedging Department of Manulife 
Financial for the pleasant cooperation over the last 4 years. 
Guojun Gan gratefully acknowledges support from the CAIS (Canadian Academy 
of Independent Scholars) grant and thanks Simon Fraser University for giving him 
full access to its libraries. Guojun Gan wants to thank his parents and parents-in-law 
for all their love and support. He wants to thank his wife, Xiaoying, for taking care 
of their children. 
This work was supported in part by the National Science Foundation for Distin-
guished Young Scholars of China (grant 70825006), Program for Changjiang Schol-
ars and Innovative Research Team in University of Ministry of Education of China 
(grant IRT0916), the Foundation for Innovative Research Groups of the National 
Natural Science Foundation of China (grant 71221001), and the Furong Scholar Pro-
gram. 
GUOJUN GAN, CHAOQUN MA, AND HONG XIE 
Toronto, ON, Canada and Changsha, Hunan, P.R. China, February 28, 2014 

Financial Glossary 
American option An option that can be exercised at any time prior to the expiration 
date. 
Asia option An option whose payoff is dependent on the average price of the un-
derlying asset during a certain period. 
barrier option An option whose payoff is dependent on whether the path of the 
underlying asset has reached a barrier, which is a certain predetermined level. 
call option An option that gives the holder the right to buy an asset. 
derivative A financial instrument whose price depends on the price of another asset 
(called the underlying asset); also referred to as derivative security or financial 
derivative. 
down-and-in option A barrier option that comes into existence when the price of 
the underlying asset declines to the barrier. 
down-and-out option A barrier option that ceases to exist when the price of the 
underlying asset declines to the barrier. 
xxii 

FINANCIAL GLOSSARY 
XXiii 
European option An option that can be exercised only on the expiration date. Let 
K be the strike price of an option. Let Sr be the price of the underlying asset 
at maturity. The terminal payoff of a long position (the holder's position) of 
a European call is given by max(Sr - K, 0). The terminal payoff of a long 
position (the holder's position) of a European put is given by max(K- Sr, 0). 
forward contract A nonstandardized agreement between two parties to buy or sell 
an asset at a certain future time for a certain price. 
futures contract A standardized agreement between two parties to buy or sell an 
asset at a certain future time for a certain price. 
LIBOR London interbank offered rate. 
lookback option An option whose payoff is dependent on the maximum or mini-
mum price of the underlying asset in a certain period. 
option A derivative that gives the holder the right (not the obligation) to buy or 
sell an asset by a certain date for a predetermined price. The date is called the 
expiration date and the predetermined price is called the strike price or exercise 
price. An option is said to be exercised if the holder chooses to buy or sell the 
underlying asset. 
put option An option that gives the holder the right to sell an asset. 
term structure The relationship between interest rates and their maturities. 
up-and-in option A barrier option that comes into existence when the price of the 
underlying asset increases to the barrier. 
up-and-out option A barrier option that ceases to exist when the price of the under-
lying asset increases to the barrier. 
zero-coupon bond A bond that does not pay coupons. 


PART I 
MEASURE THEORY 


CHAPTER 1 
SETS AND SEQUENCES 
Sets are the most basic concepts in measure theory as well as in mathematics. In fact, 
set theory is a foundation of mathematics (Moschovakis, 2006). The algebra of sets 
develops the fundamental properties of set operations and relations. In this chapter, 
we shall introduce basic concepts about sets and some set operations such as union, 
intersection, and complementation. We will also introduce some set relations such 
as De Morgan's laws. 
1.1 
Basic Concepts and Facts 
Definition 1.1 (Set, Subset, and Empty Set). A set is a collection of objects, which 
are called elements. A set B is said to be a subset of a set A, written as B ~ A, if 
the elements of Bare also elements of A. A set A is called an empty set, denoted by 
0, if A contains no elements. 
Definition 1.2 (Countable Set). A set A is said to be countable if either A contains 
a finite number of elements or every element of A appears in an infinite sequence 
x 1, x2 , .... A set A is said to be uncountable if it is not countable. 
Measure, Probability, and Mathematical Finance. 
3 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

4 
SETS AND SEQUENCES 
Definition 1.3 (Equality of Sets). Two sets A and Bare said to be equal, written as 
A = B. if A t:: B and B t:: A. 
Definition 1.4 (Union, Intersection, and Complement of Sets). Let A and B be two 
subsets of a setS. The union of A and B is defined as 
A U B = { s E S : s E A or s E B}. 
The intersection of A and B is defined as 
A n B = { s E S : s E A and s E B}. 
The complement of A relative to S is defined as 
Ac = {s E S: s tf_ A}. 
Definition 1.5 (Difference and Symmetric Difference of Sets). Let A and B be two 
sets. The difference between A and B, denoted by A~ B or A\B, is defined as 
The symmetric difference between A and B is defined as 
A~B = (A\B) U (B\A). 
Definition 1.6 (Increasing and Decreasing Sequence of Sets). Let {An}n:::: 1 be a 
sequence of sets. We say that { An}n>l is an increasing sequence of sets with limit 
A, written as An t A, if 
(a) An l:: An+l for all n 2 1. 
(b) U~=l An = A. 
We say that {An }n>l is a decreasing sequence of sets with limit A, written as An .j._ 
A, if 
(a) An :2 An+l for all n 2 1. 
(b) n~= 1 An =A. 
Definition 1.7 (Indicator Function). Let A be a set. Then the indicator function of 
A is defined as 
IA(s) = { 1, 
0, 
if sEA; 
if s 1- A. 

BASIC CONCEPTS AND FACTS 
5 
Definition 1.8 (Upper Limit and Lower Limit of Sequences of Sets). Let { En}n21 
be a sequence of subsets of S. Then lim sup En and lim inf En are defined as 
and 
respectively. 
Definition 1.9 (Upper Limit and Lower Limit of Sequences of Real Numbers). Let 
{ Xn }n>l be a sequence of real numbers. Then lim sup Xn and lim inf Xn are defined 
as 
limsupxn = inf {sup xn} = lim {sup xn} 
m21 
n2m 
m--+oo 
n2m 
and 
liminf Xn = sup { inf Xn} = 
lim { inf Xn}, 
m21 
n2m 
m--+oo 
n2m 
respectively. 
Definition 1.10 (Convergence of Sequences). A sequence { Xn }nEN of real numbers 
is said to be convergent if and only if 
lim sup Xn = lim inf Xn. 
The sequence is said to be convergent to x, written as Xn --+ x or limn--+oo Xn = x, 
if and only if Xn is convergent and lim sup Xn = lim inf Xn = x. 
Definition 1.11 (Convergence of Sets). A sequence { An}nEN of sets is said to con-
verge to A, written as An --+ A or limn--+oo An = A, if 
for all s E S. 
Definition 1.12 (Partial Ordering, Totally Ordered Sets, and Chains). A partial or-
dering ::; on a set S is a relation that satisfies the following conditions, where a, b, 
and care arbitrary elements of S: 
(a) a ::; a (reflexivity). 
(b) If a ::; band b::; a, then a= b (antisymmetricity). 
(c) If a::; band b::; c, then a ::; c (transitivity). 

6 
SETS AND SEQUENCES 
Let S be a set with a partial ordering ::::;. A subset C of S is said to be a totally 
ordered subset of S if and only if for all a, b E C, we have either a ::::; b orb ::::; a. A 
chain in Sis a totally ordered subset of S. 
Theorem 1.1 (De Morgan's Laws). Let {An}n2:l be a sequence of sets. Then 
and 
00 
n=l 
Theorem 1.2 (Zorn's Lemma). LetS be a nonempty set with a partial ordering 
"::::; ". Assume that every nonempty chain C inS has an upper bound, that is, there 
exists an element x E S such that a ::::; x for all a E C. Then S has a maximal 
element; in other words, there exists an element m E S such that a ::::; m for all 
a E S. 
1.2 Problems 
1.1. Let I be a countable set. For each i E J, let Ai be a countable set. Show that 
the union 
is again countable. 
1.2. Let Q be the set of all rational numbers, which have the form of ajb, where a 
and b(b -j. 0) are integers. Let R be the set of all real numbers. Show that 
(a) Q is countable. 
(b) R is uncountable. 
1.3. Let {En }n2: 1 be a sequence of sets. Show that 
lim inf En ~ lim sup En. 
1.4. Let { En}n>l be a sequence of subsets of S. Show that 
(lim sup Ent = lim inf E~ 
and 
(liminf En)c = limsupE~, 
where Ac = S\A for set A. 

1.5. Let { En}n>l be a sequence of subsets of a setS. Show that 
and 
luminfEn(s) = liminfiEn(s), 
'Vs E S, 
where I is the indicator function. 
PROBLEMS 
7 
(1.1) 
(1.2) 
1.6. Let {An}n>l be a sequence of sets of real numbers defined as follows: 
A = {(-~, 1], 
n 
(-1 .!.] 
'n' 
Calculate lim inf An and lim sup An. 
if n is odd; 
if n is even. 
1.7. Let {xn}n;:::1 a sequence of real numbers. Show that Xn converges (i.e., the 
limit limn--+oo Xn exists) in [ -oo, oo] if and only if 
lim sup Xn = lim inf Xn. 
1.8. Let {xn}n;:::l and {Yn}n;:::l be two sequences of real numbers. Let c be a con-
stant in ( -oo, oo). Show that 
(a) lim sup( -xn) = -liminf XnÂ· 
(b) lim sup Xn 2: lim inf Xn. 
(c) lim inf Xn +lim inf Yn :S; lim inf(xn + Yn)Â· 
(d) limsupxn + limsupyn 2: limsup(xn + Yn). 
(e) lim sup Xn +lim inf Yn :S: lim sup(xn + Yn)Â· 
(f) liminf(c + Xn) = c + liminf XnÂ· 
(g) lim inf( c- Xn) = c- lim sup Xn. 
1.9. Let { An}n>l be a sequence of subsets of a setS. Show that limn--+oo An exists 
if and only if lim sup An = lim inf An. In addition, if A = limn--+oo An exists, then 
A = lim sup An = lim inf An. 
1.10. Let {xn}n;:::l and {Yn}n;:::l be two sequences of real numbers. Suppose that 
lim Xn 
and 
lim Yn 
n~oo 
n~oo 
exist. Show that limn--+oo(Xn + Yn) exists and 
lim (xn + Yn) = lim Xn + lim YnÂ· 
n~oo 
n~oo 
n~oo 

8 
SETS AND SEQUENCES 
1.3 Hints 
1.1. Try to construct a sequence in which every element in A appears. 
1.2. To prove part (a), show that all rational numbers can be written as a sequence. 
Part (b) can be proved by the method of contradiction, that is, by assuming that R is 
countable and can be written as a sequence (xn)n2:lÂ· Then represent every Xn as a 
decimal of finite digits and find a new number, which is not in the sequence. 
1.3. This problem can be proved by using Definition 1.8. 
1.4. This problem can be proved by using Definition 1.8 and Theorem 1.1. 
1.5. An indicator function has only two possible values: 0 and 1. Hence the first 
equality of the problem can be proved by considering two cases: 8 E lim sup En and 
8 Â¢:_ lim sup En. The second equality of the problem can be proved using the result 
of Problem 1.4. 
1.6. The lower and upper limits of the sequence can be calculated by using Defini-
tion 1.8. 
1. 7. Use the definition of limits. For example, limn-+oo Xn = oo if and only if, given 
any E > 0, there exists an integer N< such that Xn > E for all n 2:: N<. Similarly, 
limn-+oo Xn = L for some L E ( -oo, oo) if and only if, given any E > 0, there 
exists an integer N< such that L- E < Xn < L + E for all n ::::: N<. 
1.8. Use Definition 1.9 and the fact that supn>m( -xn) = - infn>m Xn to prove 
part (a). To prove part (b), try to establish 
-
sup Xi 2:: inf Xn, 
j, m 2:: 1. 
i2:j 
n2m 
To prove part (c), try to establish the following inequality 
inf Xn+infyi :Ssupinf(xr+Yr)Â· 
n2m 
i2j 
s2:1 r2:s 
Use parts (a) and (c) to prove part (d). Use parts (a) and (d) to prove part (e). Use 
part (c) to prove part (f). Use parts (a) and (f) to prove part (g). 
1.9. Use Definition 1.11 and the results of Problems 1.5 and 1. 7. 
1.10. Use the results of Problems 1. 7 and 1.8. 
1.4 Solutions 
1.1. Since I is countable, then { Ai : i E I} is countable. Note that Ai is countable 
for each i E I. There exists a sequence (Bn)n2l of countable sets such that every 

SOLUTIONS 
9 
Ai appears in the sequence. For each integer n 2': 1, as Bn is countable, there exists 
a sequence (xn,m)m~l such that every element of Bn appears in the sequence. Now 
let (Yi)i~l be a sequence given by 
Then every element in A appears in the sequence (yi)i>lÂ· Hence A is countable. 
This completes the proof. 
1.2. 
(a) For each integer n 2': 0, let 
An= {r E Q: n:::; r:::; n + 1}, 
Bn = {r E Q: -n- 1:::; r:::; -n}. 
Then 
00 
Q = U (An U Bn)Â· 
n=O 
By Problem 1.1, it is sufficient to show that An and Bn are countable for each 
integern 2': 0. NotethatAn = {r+n: r E A0 }andBn = {r-n-1: r E A0}. 
We only need to show that A0 is countable. 
Let (xn)n;::: 1 be a sequence given by 
1 1 2 1 2 3 
o, 1' 2' 3' 3' 4' 4' 4' .... 
Then every number in A0 appears in the sequence. Hence Q is countable. 
(b) Assume that R is countable. Then the subset (0, 1] ofR is also countable. Let 
the numbers in (0, 1] be written as a sequence (xn)n~lÂ· Since Xn E (0, 1], we 
can represent Xn as a decimal 
O.zn,1Zn,2 ... ' 
where Zn,j is one ofthe 10 digits. The decimal representation is not unique for 
some numbers. For example, we have 
00 
9 
o.1 = o.o999 ... = 2::: 1Qi+l. 
j=l 
In such cases, we choose the representation with 9s at the end. Now let y = 
w1 w2 Â· Â· Â· be a decimal given by 
Wj = {7, 
2, 
if Zj,j :::; 5; 
if Zj,j > 5. 

1 0 
SETS AND SEQUENCES 
Since w1 i=- 9 and Wj i=- z1,1 for all j 2 1, we have y i=- Xn for all n 2 1. But 
the sequence (xn)n;:: 1 includes all numbers in (0, 1]. Hence y = Xn 0 for some 
n 0 . This is a contradiction. Hence R is uncountable. 
This completes the proof. 
1.3. Lets E liminf En. Then by Definition 1.8, we haves En.>. Ei for some 
~_Jo 
j 0 2 1. It follows that s E Ei for all i 2 j 0 . Hence we have 
S E Emax{j,jo} c:;;; U Ei 
i::Cj 
for all j 2 1. Consequently, s E lim sup En. Therefore, lim inf En c:;;; lim sup En. 
1.4. By Definition 1.8 and Theorem 1.1, we have 
(limsupEnt 
(Q (Yo E,))' ,Y, (Yo E,)' 
U (n Ef) = liminf E~. 
">1 
i>. 
)_ 
_) 
Similarly, we can show that (lim inf Ent = lim sup E~. 
1.5. To prove ( 1.1), we consider two cases: 8 E lim sup En and 8 ~ lim sup En. If 
8 E lim sup En, then 
which implies 
8 E n U En, 
s E U En, vm 2 1. 
n::Cm 
Thus s E En for infinitely many n. Hence we have 
sup hn(s) = 1, vm:::: 1, 
n2:m, 
which gives 
If s ~ lim sup En, then s E En for only finitely many n. Thus we have 
sup h,(.s) = 0, vm 2 Mo, 
n2:m 
where A10 is a sufficient large number. Hence we have 
inf sup IEn(s) = 0. 
m::Cl n::Cm 

SOLUTIONS 
11 
Therefore (1.1) is true. From (1.1) and noting that IE(s) = 1 -lEe (s), we have 
lnminf En (s) = 1- fnmsupE:; (s) = 1 -lim sup IE:; (s) = liminf lEn (s). 
Thus (1.2) holds. 
1.6. 
To find liminf An, we first need to calculate ni:2:i Ai for all j ~ 1. To do 
that, we let Bn = A2n-l and Cn = A2n for n = 1, 2, .... Then Bn and Cn are 
decreasing, and we have 
n 
Bn = [0,1] 
n:2:k 
and 
n 
Cn = (-1,0] 
n:2:k 
for all k ~ 1. Thus ni:2:i Ai = 
{ 0} for all j > 1. Hence lim inf An 
{ 0}. 
Similarly, we have lim sup An = ( -1, 1]. 
1.7. 
We first prove the "only if' part. Suppose that limn-+= Xn exists. Let L = 
limn-+= Xn and E > 0. If L = -oo, then there exists an N< ~ 1 such that Xn < -E 
for all n ~ N<. Hence 
inf sup Xn ~ sup ~ -E. 
m:2:1n;:::m 
n;;::N, 
Letting E ---+ oo in the above equation gives limsupxn 
-oo, which implies 
lim sup Xn = lim inf Xn = -oo. Similarly, we can show that 
lim sup Xn :;:= lim inf Xn 
for -oo < L < oo and L = oo. Now we prove the "if" part. Suppose that 
lim sup Xn = lim inf Xn = L and let E > 0. If -oo < L < 00, then SUPn>m, Xn ~ 
L + E for some m1 ~ 1 and infn>m2 Xn ~ L -
E for some m2 ~ 1. Therefore, we 
have 
L-E~Xn~L+E, n~max(m1,m2). 
Since this is true for every E > 0, limn-+= Xn exists and is equal to L. Similarly, we 
can show that limn-+= Xn exists for L = -oo and L = oo. 
1.8. 
(a) By Definition 1.9, we have 
lim sup( -xn) 
inf sup ( -xn) 
m:2:1n;:::m 
inf (- inf Xn) 
m:2:1 
n;;::m 
-sup inf Xn 
m;:::ln:2:m 
-liminf XnÂ· 

12 
SETS AND SEQUENCES 
(b) For j, m;:::: 1, we have 
supx;;:::: Xr;:::: inf Xn, 
i?:j 
n?:m 
where r = max(j, m). Since this is true for all j, m;:::: 1, we have 
inf supx;;:::: inf Xn, 
m;:::: 1, 
j?:l i?:j 
n?:m 
which implies 
inf sup X; ;:::: sup inf Xn. 
j?:l i?:j 
m?:l n?:m 
(c) For fixed m, j ;:::: 1, 
inf Xn + inf Yi:::; Xr + Yn 
r;:::: max(m,j), 
n?:m 
i?:j 
we have 
inf Xn+infy;:::; 
inf 
(xr+Yr):::;supinf(xr+Yr) m,j;:::l. 
n?:m 
1?:J 
r?:max(m,j) 
s?:l r?:s 
Since this is true for every m, j ;:::: 1, we have 
sup inf Xn +sup inf Yi :::; sup inf (xr + Yr ); 
m?:l n?:m 
J?:l i?:j 
s?:l 1Â·?:s 
that is, lim inf Xn +lim inf Yn :::; lim inf(xn + Yn)Â· 
(d) From parts (a) and (c) of this proof, we have 
lim sup Xn +lim sup Yn 
-lim inf( -xn) -lim inf( -yn) 
> -lim inf( -Xn- Yn) 
limsup(xn + Yn)Â· 
(e) From parts (a) and (d) of this proof, we have 
lim sup Xn +lim inf Yn 
lim sup(xn + Yn -
Yn) +lim inf Yn 
< 
lim sup(:rn + Yn) +lim sup( -yn) +lim inf Yn 
limsup(xn + Yn)Â· 
(f) Since c = lim inf c and -c = lim inf( -c), by part (c), we have 
c + lim inf Xn = lim inf c + lim inf Xn :::; lim inf ( c + Xn), 
and 
lim inf(c + Xn) - c =lim inf(c + Xn) +lim inf( -c) :::; lim inf Xn. 
It follows that c + lim inf Xn = lim inf ( c + .Tn). 

BIBLIOGRAPHIC NOTES 
13 
(g) From parts (a) and (f) of this proof, we have 
liminf(c- Xn) = c + liminf( -xn) = c -limsupxn. 
This finishes the proof. 
1.9. First, we prove the "if" part. Suppose that lim sup An = lim inf An. Then by 
Problem 1.5, we have lim infi An ( s) = lim sup IAn ( s) for all s E S. It follows that 
lim I An ( s) exists for all s E S. Hence limn-+oo An exists. 
Next, we prove the "only if" part. Suppose that limn-+oo An exists. Then by 
definition, we have limn-+oo I An ( s) exists for all s E S. It follows that 
for all s E S. By Problem 1.5, we have hm sup An ( s) = hm inf An ( s) for all s E S. 
Therefore, lim sup An = lim inf An. By Problem 1.5, we have 
lim IAn (s) =lim sup IAn (s) = liminf IAn (s) 
n-+oo 
hmsupAn(s) = luminfAn(s), 
'is E S. 
Hence A = lim sup An = lim inf An. 
1.10. Since limn-+oo Xn and limn-+oo Yn exist, it follows from Problem 1.7 that 
and 
lim Xn = lim inf Xn = lim SUp Xn 
n-+oo 
lim Yn = lim inf Yn = lim sup Yn. 
n-+oo 
Then by parts (c) and (d) of Problem 1.8, we have 
which shows that 
lim inf(xn + Yn) 
> lim inf Xn +lim inf Yn 
limsupxn + limsupyn 
> limsup(xn + Yn), 
limsup(xn + Yn) = liminf(xn + Yn) = lim Xn + lim YnÂ· 
n-+oo 
n-+oo 
This completes the proof. 
1.5 Bibliographic Notes 
In this chapter, we introduced some concepts in set theory as well as some set opera-
tions and relations. For further information about these concepts, readers are referred 

14 
SETS AND SEQUENCES 
to Papoulis (1991), Williams (1991), Ash and Doleans-Dade (1999), Jacod and Prot-
ter (2004), and Reitano (2010). 
We also introduced some concepts related to sequences of real numbers, which are 
connected to sequences of sets via indicator functions. The properties of sequences 
of real numbers and sets are frequently used in later chapters. 
Zorn's lemma is an axiom of set theory and is equivalent to the axiom of choice. 
For a proof of the equivalence, readers are referred to Vaught (1995, p80), Dudley 
(2002, p20), and Moschovakis (2006, pll4). 

CHAPTER2 
MEASURES 
Measurable sets are to measure theory as open sets are to topology (Williams, 1991). 
Measures are set functions defined on measurable sets. These concepts are used later 
to define integration. In this chapter, we shall introduce measurable sets, measures, 
and other relevant concepts such as algebras and u-algebras. 
2.1 
Basic Concepts and Facts 
Definition 2.1 (Algebra). An algebra or field I:0 on S is a collection of subsets of S 
that satisfies the following conditions: 
(a) S E I:o. 
(b) IfF E I:o, then pc E I:0, where pc = S\F. 
(c) IfF E I:o and G E I:o, then F U G E I:o. 
Definition 2.2 (u-Algebra). A collection I: of subsets of Sis called au-algebra or 
u-field if I: is an algebra on S and is closed under countably infinite unions; that is, 
Measure, Probability, and Mathematical Finance. 
15 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

16 
MEASURES 
if Fn E E for n = 1, 2, ... , then 
00 U Fn E E. 
n=l 
Definition 2.3 (Measurable Space and Measurable Set). A measurable space is a 
pair (S, E), where Sis a set and Eisa a-algebra on S. A subset C of Sis said to be 
E-measurable if C E E. 
Definition 2.4 (Generated a-Algebra). Let C be a collection of subsets of a setS. 
The a-algebra a( C) generated by Cis the intersection of all the a-algebras containing 
C. 
Definition 2.5 (Topology, Topological Space, Open Set). A topology Tin a set S is 
a a collection of subsets of S that satisfies the following conditions: 
(a) S E T and 0 E T. 
(b) IfF, G E T, then F n G E T. 
(c) If Fi E T for all i E J, then uiEI Fi E T, where I is an index set (finite, 
countable, or uncountable). 
A topological space is a pair ( S, T) where S is a nonempty set and Tis a topology 
in S. For simplicity, we classify S as a topological space if Tis evident or does not 
need an explicit name. The elements ofT are called open sets inS. 
Definition 2.6 (Borel a-Algebra). The Borel a-algebra B(S) on a topological space 
Sis the a-algebra generated by the collection of open sets inS. The Borel a-algebra 
on the real lineR is denoted by B, and the sets in Bare called Borel sets. If E E B, 
then B(E) denotes the a-algebra {An E: A E B}. 
Definition 2.7 (Borel Measure). A Borel measure is a measure defined on a Borel 
a-algebra. 
Definition 2.8 (Finitely Additive and Countably Additive Set Function). Let S be a 
set and Eo be an algebra on S. Let J.Lo be a nonnegative set function 
J.Lo :Eo---+ [0, oo]. 
The set function J.Lo is called .finitely additive if it satisfies the following conditions: 
(a) J.Lo(0) = 0, where 0 denotes an empty set. 
(b) IfF, G E Eo and F n G = 0, then J.Lo(F U G) = J.Lo(F) + J.Lo(G). 
The set function J.Lo is called countably additive if it satisfies the following condi-
tions: 
(a) J.Lo(0) = 0. 

BASIC CONCEPTS AND FACTS 
17 
(b) If F1 , F2, ... is a disjoint sequence of elements of I:o and U:=l Fn E I:o, then 
Definition 2.9 (Measure). Let 2:0 be an algebra of subsets of a set S. A measure on 
the algebra 2:0 is a nonnegative, countably additive set function on I:o. 
Definition 2.10 (Measure Space). A measure space is a triple (S, 2:, JL) where (S, I:) 
is a measurable space and JL is a measure on (S, 2:). 
Definition 2.11 (Finite Measure and a-Finite Measure). Let (S, 2:, JL) be a measure 
space. The measure JL is considered finite if JL( S) < oo. The measure JL is deemed 
a-finite if there exists a sequence {Sn}nEN of elements of I: such that JL(Sn) < oo 
for all n E Nand U:=l Sn = S, where N is the set of natural numbers, that is, 
N = {1,2,3, ... }. 
Definition 2.12 (Probability Measure and Probability Space). Let (D.,.#", P) be a 
measure space. Then (D.,.#", P) is called a probability measure space, or simply a 
probability space, if Pis a probability measure, that is, P(D.) = 1. 
Definition 2.13 (Counting Measure). Let (S, I:) be a measurable space. The count-
ing measure JL on (S, I:) is defined as 
(A) = { lA I, 
if A is finite subset of S; 
JL 
oo, 
if A is infinite subset of S. 
Definition 2.14 (JL-Null and Almost Everywhere (a.e.)). Let (S, 2:, JL) be a measure 
space. An element F of I: is called JL-null if its measure is zero (i.e., JL(F) = 0). A 
statement about points in S is said to be true a.e. if the measure of the set of points 
for which the statement is false is zero, that is 
F = { s : the statement about s is false} E I: 
and JL( F) = 0. 
Definition 2.15 (1r-System). A 1r-system I on a setS is a collection of subsets of S 
that is closed under finite intersection: 
h, J2 E I implies h n J2 E I. 
Definition 2.16 (d-System). Ad-system Von a setS is a collection of subsets of S 
such that 
(a) S E V. 
(b) If A, BE V and As;;; B, then B\A E V. 
(c) If An E V for n E N and An t A, then A E V. 

18 
MEASURES 
Theorem 2.1 (Monotone Convergence of Measures). Let L:0 be an algebra of sub-
sets of a setS and f-L a measure on L:a. Let F1, F2, ... , E I: a. If Fn t F and F E I:o, 
then JL(Fn) t JL(F). 
Theorem 2.2 (First Borel-Cantelli Lemma). Let ( S, L:, f-L) be a measure space and 
{ En}n;=:I be a sequence of elements of I: such that 
00 
Then f-L (lim sup En) = 0. 
2.2 
Problems 
2.1. LetS be a finite set and 28 denote the collection of all subsets of S. Show that 
28 is finite and that it is a a-algebra. 
2.2. Let C be a collection of subsets C of N = { 1, 2, 3, ... } for which the following 
limit 
l. 
I { k : 1 :::; k :::; m; 
k E C} I 
liD 
m--+oo 
m 
exists, where IAI denotes the number of elements in A. Show that Cis not an algebra. 
2.3. Let A1 , A2, ... , An be arbitrary subsets of a setS, and let I:= a(A1 , A2, ... , 
An). Give an upper bound of II: I that is attainable under certain conditions, where 
II: I denotes the number of sets in I:. 
2.4. Let C = {( -oo, c] : c E R}, where R = ( -oo, oo). Show that a( C)= !3. In 
addition, C can be replaced by other classes of intervals, for example, all intervals 
( -oo, c), c E JR., all intervals [c, oo), c E JR., all intervals (c, oo), c E JR., all intervals 
[a, b), a, bE JR., all intervals (a, b], a, bE JR., or all intervals [a, b], a, bE R 
2.5. Let I: be a a-algebra of subsets of a set S, and let C E I:. Show that C = 
{An C : A E I:} is a a-algebra of subsets of C. 
2.6. Let I: be a collection of subsets of a set S. Show that I: is a a-algebra if and 
only if I: is both a 7r-system and a d-system. 
2.7 (Dynkin's Lemma). Show that if I is a 7r-system, then 
d(I) = a(I), 
where d(I) is the intersection of all d-systems that contain I. 
2.8. Let I be a 7f-system on S and I: = a(I). Let /-Ll and JL2 be measures on the 
measurable space (S, I:) such that /-LI (S) = JL2(S) < oo and /-LI (I) = JL2(I) for all 
I E I. Show that 
1J ={FE I:: /-LI(F) = /-L2(F)} 

PROBLEMS 
19 
is a d-system. 
2.9. Let (S, ~) be a measurable space. Suppose that {An}n~l is a sequence of 
~-measurable sets. Show that lim inf An E ~ and lim sup An E ~. 
2.10. LetS be a countably infinite set, and let ~o = {A ~ S: IAI < oo or INI < 
oo}. Let J.Lo be a set function on S be defined as 
(A) = {0, if A is finite; 
J.Lo 
1, 
if Ac is finite. 
(a) Show that ~0 is an algebra but not a a-algebra. 
(b) Show that J.Lo is finitely additive but not countably additive on ~0 . 
(c) Show that there exists a sequence { An}n~l of elements of ~o such that AntS 
and J.Lo(An) = 0 for all n ~ 1. 
2.11. Let ~0 be an algebra of subsets of a set S and J.L be a measure on ~0 . Let 
A, BE ~0 . Show that 
(a) J.L(A U B)= J.L(A) + J.L(B)- J.L(A n B); 
(b) J.L(A U B) :::; J.L(A) + J.L(B); 
(c) J.L(A n B) :::; J.L(A). 
2.12. Let (S, ~. J.L) be a measure space and Ai E ~fori = 1, 2, ... , n. Suppose that 
J.L is finite. Show that 
l~i~n 
l~i<j~n 
2.13. Let (S, ~. J.L) be a measure space and An E ~for n ~ 1. Suppose that J.L is 
finite. Show that 
2.14. Let J.Lo be a nonnegative, finitely additive set function on an algebra ~0 . Let 
A1, A2, ... be pairwise disjoint sets in ~o and U:::"=l An E ~o. Show that 

20 
MEASURES 
2.15. Let S be an infinite set and J-l the counting measure on (S, 25 ), where 25 
denotes the collection of all subsets of S. Show that there exists a sequence {An }n> 1 
such that An .,l. 0 and limn--+oo J-l(An) -1- 0. 
2.16. LetS be a set, and let Q and 1-l be two a-algebras on S. Let 
'I={GnH: GEQ,HE1-l}. 
Show that I is a 1r-system and a(I) = a(Q, 1-l), where a(Q, 1-l) is the a-algebra 
generated by Q U 1-l, that is, a(Q, 1-l) = a(Q U 1-l). 
2.17. Let (S, I:) be a measurable space and { An}n>l be a sequence of I:-measurable 
sets. Show that if limn--+oo An = A, then A E I:. 
2.18. Let (S, I:, J-l) be a measure space. Let G1 , G2 , ... E I: such that Gn 4- G and 
J-l(Gk) < oo for some k. Show that J-l(Gn) 4- J-l(G). 
2.19. Let (S, I:, J-l) be a measure space, and let Gn E I: (n;::: 1) such that J-l(Gn) = 
0. Show that 
J-l (u ci) = 0. 
z=l 
2.20. Let J-l be a finite measure on a measurable space (S, I:). Show that there cannot 
be uncountably many disjoint sets A E I: such that J-l(A) > 0. 
2.3 Hints 
2.1. Consider how many subsets contain zero elements, how many subsets contain 
one elements, and so forth. The sum of those numbers is the number of elements in 
25 . Use Definition 2.2 to show that 25 is a a-algebra. 
2.2. 
To show that C is not an algebra, one can try to find two sets A, B E C but 
An B tf_ C. If Cis indeed an algebra, then An B = (Ac U Bc)c E C. To make sure 
that An B tf_ C, one needs to show that the sequence 
i{k: 1:::; k:::; m; 
k E AnB}I 
rm= ~--------------------~ 
m 
has no limits; that is, lim sup r m -1- lim inf r m. 
2.3. Consider simple cases when n = 1, 2, 3, and then consider the general case. 
2.4. Use the standard technique to show that a(C) = B; that is, show that a(C) ~ B 
and B ~ a( C). 
2.5. Use Definition 2.2. 
2.6. Use Definitions 2.2, 2.16, and 2.15. 

SOLUTIONS 
21 
2.7. Use the result of Problem 2.6. 
2.8. Use Definitions 2.16 and 2.9. 
2.9. Use Definitions 1.8 and 2.3. 
2.10. 
Since S is a countably infinite set, the elements of S can be enumerated as 
a1, az, .. .. 
2.11. Use Definitions 2.8 and 2.9. 
2.12. Consider the cases when n = 1, 2, and then use the mathematical induction 
method. 
2.13. Write U~=l An as a union of n mutually disjoint sets. 
2.14. Since A1 , A2 , ... are pairwise disjoint, we have 
Use the above inequality to prove the inequality in question. 
2.15. Try to construct a sequence of sets A1 , A2 , ... such that lim sup An = 0 and 
J,L(An) =f. 0 for all n ~ 1. 
2.16. Use Definition 2.15 to show that I is a 1r-system and use the standard tech-
nique to show that a(I) = a(g, 1-l)[(i.e., a(I) 2 a(g, 1-l) and a(I) ~ a(Q, 1-l)]. 
2.17. Note that if limn~oo An = A, then lim inf An = lim sup An = A. 
2.18. Use Theorem 2.1. 
2.19. Write U:1 Gi as a union of pairwise disjoint sets and utilize the fact that 1-L is 
countably additive. 
2.20. Use the method of contradiction; that is, suppose that there are uncountably 
many disjoint sets A E E such that J,L(A) > 0. Then show that 1-L is infinity. 
2.4 Solutions 
2.1. Let n = lSI. Since Sis finite, we haven < oo. In addition, we can classify the 
subsets of Sinton+ 1 groups 90 , 9 1 , ... , 9n. where gi (0:::; i:::; n) is the group of 
subsets containing i elements. Then U~=l gi = 28 , and gin gi = 0 for all i =f. j. 
Hence we have 128 1 = L~=O l9ilÂ· But l9il = ( i ), so we have 128 1 = 2n < oo. 
By definition of 28 , we haveS E 28 . IfF E 28, then F ~ S, which leads to 
Fe= S\F ~Sand FeE 28 . If Fn E 28 for n ~ 1, then Fn ~ S for n ~ 1. Let 

22 
MEASURES 
X E u:=1 Fn. Then X E Fno for some no ?: 1. But Fno ~ S, we have XES. Thus 
U:=1 Fn ~ S, which gives U:=1 Fn E 28 . Therefore, 28 is a Â£T-algebra. 
2.2. To show that C is not an algebra, we only need to find two sets A, B E C but 
An B Â¢:.C. To do this, we divide N into the following mutually disjoint intervals Ji 
and Ij fori= 0, 1, 2, ... ,where 10 = {1, 2}, J0 = {3, 4}, and 
h=(2Â·2k,3Â·2k]nN, 
Jk=(3Â·2\2Â·2k+l]nN, Vk?:l. 
Then lhl = 2k and IJkl = 2k for all k?: 1. We define A and Bas 
00 
A= u 
(JZ u JZ) 
k=O 
and 
00 
B= U(IZUJk), 
k=O 
respectively, where IZ is the set of all even numbers in h and Ik is the set of all odd 
numbers in h for all k ?: 0, JZ and Jk are defined similarly. Then we have 
00 
AnB = U IZ. 
k=O 
Now we claim that A, BE C and An B Â¢:_C. Since 
l{k: 1:::; k:::; m; 
m 
and 
k E A}l = {~' 
m-1 
2m' 
ifm is even; 
ifm is odd, 
l{k: 1:::; k:::; m; 
k E B}l = { ~- 1 
-'--"-----m--------'--'-
2m ' 
m+1 
2m' 
ifm is even; 
if m is odd and m E h for some k; 
if m is odd and mE Jk for some k, 
we have 
lim l{k: 1:::; k:::; m; 
m---+oo 
m 
and 
l. 
l{k: 1 :::; k:::; m; 
liD 
m---+oo 
m 
k E A}l 
k E B}l 
1 
2' 
1 
-
2 
Thus A, B E C. As for An B, we have 
' Vk > 1 
l{k:1:::;k:::;m; 
kEAnB}I ={-31 , 
ifm=3Â·2k. 
m 
l 
if m = 2 Â· 2k+1, 
-
4' 

which gives 
l. 
I { k : 1 ::::; k ::::; m; 
liD SUp 
m-+oo 
m 
and 
l. . f l{k: 1::::; k::::; m; 
liDlll 
m-+oo 
m 
Thus the limit does not exist and A n B ~ C. 
k E AnB}I > ~ 
- 3' 
k E AnB}I < ~ 
-
4" 
SOLUTIONS 
23 
2.3. The upper bound of I~ I is 2N, where N = 2n - 1. The upper bound can be 
attained when B1, B2, ... , BN are all nonempty, where 
for i = 1, 2, ... , N and h, I2, ... , IN are nonempty, distinct subsets of { 1, 2, ... , 
n}. 
The sets B1, B2, ... , BN are pairwise disjoint but may contain empty sets. One 
can use the standard technique (i.e., A ~ B and B ~ A imply A = B) to show that 
~ = a(B1,B2, ... ,BN)Â· 
When B1, B2, ... , BN are all nonempty, we have~ = 2{B1 ,B2 , ..â¢ ,BN} and 1~1 = 
2N. 
Now we show that such upper bound is attainable. LetS= {0, 1, 2, ... , 2n - 1} 
and Ai = {s E S: s = f3I + /322 + Â· Â· Â· + f3n2n-I, f3k E {0, 1} fork=/= i, f3i = 0} 
fori = 1, 2, ... , n. Then Bi = {LjEif 21-l} for If =/= 0 and Bi = {0} for If = 0. 
Hence B1, B2, ... , BN are all nonempty. In this case, we have 1~1 = 2N. 
2.4. Since 
(-oo,c] = ft ( 
-oo,c+ ~), \fc E R, 
we have C ~B. Note that B is a a-algebra, we have a( C) ~B. 
Now we show that every open subset 0 of R is in a(C). Note that 0 is a finite or 
countable union of open intervals, we only need to show that 
(a, b) E a( C), 
\fa, bE R with a< b. 
But 
(a, b)= ( -oo, b) n ( -oo, ar = (Ql ( 
-oo, b- ~]) n( -oo, a]c, 
we have (a, b) E a( C). Thus we have B ~a( C). Therefore, B =a( C). 
Other implications can be proved by similar arguments. 

24 
MEASURES 
2.5. Since C E L, we have C E C. Let BE C. Then B =An C for some A E L. 
Thus we have C\B = C n Be = C n Ae E C, where the complement is taken 
relative to S. Now let Bn E C for n 2': 1. Then Bn = Ann C for some An E L. But 
U~= 1 Bn = U~= 1 (Ann C) = (U~=l An) n C, so we have U~= 1 Bn E C. Hence 
C is a cr -algebra over C. 
2.6. The necessity part is trivial. To prove the sufficiency, we assume that L is both 
a 1r-system and a d-system. From the assumption L is a d-system, we have S E L. 
IfF E L, then Fe= S\F E L, since F,S ELand F ~ S. If F,G E L, then 
FUG = (Fe nGe)e E L, since Lis a 1r-system and d-system. Let Fn E L (n EN) 
and An= U~=l Fi. Then An~ An+l and Ant U:1 Fi. By assumption, we have 
U:1 Fi E L. Thus, Lis a cr-algebra. 
2.7. 
From Problem 2.6, we know that cr(I) is a d-system. Note that as d(I) is 
the intersection of all d-systems containing I, we have d(I) ~ cr(I). To prove 
cr(I) ~ d(I), we only need to show that d(I) is a cr-algebra. From Problem 2.6, we 
only need to show that d(I) is a 1r-system. 
Let D1 ={DE d(I) : D n IE d(I), VIE I}, then D1 ~ d(I). We claim that 
D1 is a d-system on I. Since I is a 1r-system, we have I ~ D1. Let A, B E D1 and 
A~ B; then 
(B\A) n I= (B n I) n (Ae U Ie) = (B n I)\(A n I) E d(I), 
VIE I, 
since Ani, Bni E d(I) for all IE I and d(I) is ad-system. Thus B\A E D1. Let 
An E D1 and Ant A, then AnnIE d(I) and Ann It An I for all IE I. Since 
d(I) is ad-system, we have An IE d(I) (VIE I), which leads to A E D1. Thus 
D1 is ad-system on I. Note that d(I) is the intersection of all d-systems containing 
I, so we have d(I) ~ D1. Hence we have D1 = d(I). 
Let D2 = { D E d(I) : D n J E d(I), V J E d(I)}. We claim that D2 is also ad-
system on I. Since D1 = d(I), we have I~ D2. Let A, B E D2 and A~ B, then 
(B\A) n J = (B n J)\(A n J) E d(I) for all J E d(I), since B n J, An J E d(I) 
for all J E d(I) and d(I) is ad-system. Thus we have B\A E D2. Let An E D2 
and An t A, then Ann J E d(I) and Ann J t An J for all J E d(I). Since 
d(I) is ad-system, we have An J E d(I) for all J E d(I), which gives A E D2. 
Therefore, D2 is ad-system on I. Hence we have d(I) ~ D2. By definition, we 
have D2 ~ d(I). So we have D2 = d(I), which means that In J E d(I) for all 
I, J E d(I). Therefore d(I) is a 1r-system. 
2.8. We only need to show that D satisfies the conditions in Definition 2.16. Since 
p 1(S) = p2(S), we haveS E D. Let A,B E D and A ~ B; then we have 
A, BEL, p1(A) = p2(A) < oo, and pl(B) = p2(B) < oo, which lead to 
JLI(B\A) = JL1(B)- JLl(A) = JL2(B)- JL2(A) = JL2(B\A). 
Thus B\A ED. To check the last item, let Fn ED and Fn t F. Then by Theorem 
2.1, we have 
Jll (F) = lim Jll (Fn) = lim JL2(Fn) = JL2(F). 
n--too 
n--+oo 

SOLUTIONS 
25 
Hence, 1J is a d-system. 
2.9. Let Bj = ni~j Ai for j = 1, 2, .... Since :Eisa a--algebra and Ai E :E for all 
i 2: 1, we have Ai E :E for all i 2: 1 and thus Bj = ( Ui~j Ai) e E :E for all j 2: 1. 
Note that liminf An= Uj~l Bj, we have liminf An E :E. Similarly, we can show 
that lim sup An E :E. 
Now we show that lim inf An ~ lim sup An. Let s E lim inf An. Then s E 
ni~jo Ai for some jo E N; that is, s E Ai for all i 2: jo. Consequently, we have 
s E Ui~j Ai for all j 2: 1. By definition, we have s E lim sup An. Therefore, 
lim inf An ~ lim sup An. 
2.10. Since ISel = 101 = 0 < oo, we haveS E :E0 â¢ Let A E :E0 . Then A is finite 
or A e is finite. In both cases, we have A e E :E0 â¢ Now let A, B E :E0 . If both A and 
Bare finite, then AU B is finite and thus AU B E :E0 . If at least one of A and B is 
infinite, then (AU BY = Ae n Be is finite and thus AU B E :E0 . Hence :E0 is an 
algebra. 
Now we show that :E0 is not a a--algebra. Since Sis infinite, we can find an infinite 
subset B = {b1, b2, ... } of S. Let An = {b2n-d for all n 2: 1. Then An E :Eo for 
all n 2: 1. But A= U:'=1 An is infinite and N is also infinite. Therefore A tf. :E0 . 
Let A, B E :E0 and An B = 0. We claim that at most one of A and B can be infinite. 
If both A and B are infinite, then A e and Be are finite, which contradicts A e U Be = 
S. If both A and B are finite, then llo(A U B) = 0 = llo(A) + llo(B). If one of 
A and B is infinite and the other is finite, then llo(A U B) = 1 = llo(A) + llo(B). 
Hence /lo is finitely additive. 
Since Sis countably infinite, we can enumerate the elements of S as a 1 , a2 , .... 
But 2:::'=1 1-Lo( {an}) = 0 and /lo (U:'=l {an}) = llo(S) = 1. Therefore /lo is not 
countably additive. 
LetS= {a1, a2, ... } and An= {ai : i = 1, 2, ... , n} for all n 2: 1. Then AntS 
and /lo(An) = 0 for all n 2: 1. 
2.11. 
(a) Since AU B =AU (B\A) and An (B\A) = 0, we have 
11(A U B) = 11(A) + M(B\A). 
Note that since (B\A) U (An B)= Band (B\A) n (An B)= 0, we have 
11(B) = M(B\A) + 11(A n B). 
Combining the two equation gives 11(A U B) = 11(A) + 11(B) - 11(A n B). 
(b) Since 11 is nonnegative, this implication follows immediately from part (a). 
(c) Since A = (An B) u (B\A) and (An B) n (B\A) = 0, we have 11(A) = 
11(A n B)+ M(B\A) 2: 11(A n B). 

26 
MEASURES 
2.12. 
We use the mathematical induction method. When n = 1, the equality is 
trivial. Suppose that the equality holds for n = m. Then from problem 2.11 and the 
induction hypothesis, we have 
~ (Q Ai) + ~(Am+I)- ~ ( (Q Ai) n Am+I) 
L ~(Ai)- L 
~(Ai n Aj) 
l:S;i.<j<k:S;m 
+(-l)m+l~(A 1 nA2 n Â· Â· Â· nAm) 
+~(Am+l)- ~ ( (Q Ai) n Am+l). 
(2.1) 
Also from the induction hypothesis, we have 
~ ( (QAi) nAm+l) 
~ (Q(Ai n Am+I)) 
L 
~(Ai n Am+ I) 
(2.2) 
l:S;i:S;m 
l:S;i<j:S;m 
+ 
l:S;i<j<k:S;m 
(2.3) 
It follows from Equations (2.1) and (2.3) that the equality holds for n = m + 1. 
Therefore, the equality holds for all n E N. 
2.13. 
Let B 1 = A1 and Bn = An\ ( U~:/ Ai) for n ?: 2. Then U~=l Bn = 
U~=l An, Bi n Bj = 0 for all 1 :S i < j, and ~(En) :S ~(An) for all n ?: 1. 
Consequently, we have 
This completes the proof. 

SOLUTIONS 
27 
2.14. Since J-Lo is finitely additive and A1, A2, ... are disjoint, we have 
for all N 2: 1. Since J-Lo is nonnegative, we have J-Lo (U~=l An) = J-Lo ( U~=l An)+ 
J-Lo (U~=N + 1 An) 2: L~= 1 J-Lo (An) for all N 2: 1. Now the result follows by letting 
N-+ oo. 
2.15. Since Sis infinite, we can find an infinite subset B = {b1, b2, ... } of S. Let 
An = {bi : i 2: n} for all n 2: 1. Then An .j,. 0. Note that J-L(An) = oo for all n 2: 1, 
we have limn-+oo J-L(An) = 00. 
2.16. 
First, we show that I is a 1r-system. Let h E I and I 2 E I. Then, by 
definition of I, we have h = G1 n H 1 and I 2 = G2 n H2 for some G 1 , G2 E Q, 
and H 1, H 2 E H. Since Q and Hare O"-algebras, we have h n I 2 = (G1 n G2) n 
(H1 n H2) E I. Thus, I is a 1r-system. 
Next, we show that O"(I) = O"(Q, H). Since I 
<;;; O"(Q, H), we have O"(I) <;;; 
O"(Q, H). Note that Q and H are O"-algebras on S, we have S E Q and S E H. 
Consequently, Q <;;; I and H <;;; I. Hence, Q U H <;;; O"(I) and O"(Q, H) <;;; O"(I). 
Therefore, O"(I) = O"(Q, H). 
2.17. This implication A E ~follows from Problems 1.9 and 2.9. 
2.18. 
By Problem 2.17, we have G E ~-
Let Fn = G k \ Gn for all n 2: k. 
Since Gn :2 Gn+l for all n and Gn .j,. G, we have Fn <;;; Fn+l for all n 2: k and 
Fn t Gk \G. Using Theorem 2.1, we have 
Since J-L(Gk) is finite by hypothesis, we have J-L(Gn) .j,. J-L(G). 
2.19. Let F1 = G1 and Fn = Gn \(U~:1
1 Gi) for n 2: 2. Then Fn (n E N) are 
mutually disjoint and 
00 
00 
n 
n 
U Fi = U Gi, 
'In 2: 1. 
i=l 
i=l 
i=l 
i=l 
Since J-L is countably additive, we have 
Note that J-L is nonnegative and Fi <;;; Gi for all i, we have 0 :S J-L(Fi) :S J-L(Gi) = 0 
for all i, which give J-L(Fi) = 0 for all i. From the above equation, we have 

28 
MEASURES 
2.20. 
Suppose that there are uncountably many disjoint sets A E I: such that 
p,(A) > 0 and let C be the collection of such sets. Let Cn = {A E C : p,(A) > 1/n} 
for all n ;:::: 1. Then C = U:=l Cn. Since Cis uncountable, there exists at least one 
Cia for some i 0 ;::=: 1 that has uncountably many elements. It follows that Jt(S) ;::=: 
LAEC, 0 p,(A) = oo, contradicting the assumption that JL is finite. Therefore, there 
cannot be uncountably many disjoint sets A E I: such that p,(A) > 0. 
2.5 
Bibliographic Notes 
A a--algebra is a structure imposed on a collection of sets on which a measure can 
be defined. Recall that a measure on a set S is a function that assigns a real number 
to subsets of S. We can think of the measure as a notion of size or volume for the 
subsets. However, it might be not possible to assign such a size to every subset of S. 
For example, it is not possible to assign a size to a Vitali set (Herrlich, 2006, p 120). 
As a result, we consider only a smaller collection of subsets of S when defining 
measures. This smaller collection of subsets are called measurable sets. 
The notions of 1r-system and ,\-system are adopted from Williams (1991). Those 
concepts are useful for dealing with a--algebras. For more information about a--
algebras and measures, readers are referred to Billingsley (1986), Williams (1991 ), 
Ash and Doleans-Dade (1999), Vestrup (2003), and Athreya and Lahiri (2006). 
Topology space and continuous functions are presented in books on real analysis 
such as Rudin (1970). For a history of measure theory, readers are referred to Pap 
(2002). 
Theorems 2.1 and 2.2 are very useful. For proofs of these theorems, readers can 
consult Williams ( 1991, pp21 ,27). 

CHAPTER 3 
EXTENSION OF MEASURES 
As defined in the previous chapter, a measure is a set function on an algebra. To 
extend a measure from an algebra to a a-algebra, we need some tools. In this chapter, 
we will introduce concepts and theorems related to measure extension. 
3.1 
Basic Concepts and Facts 
Definition 3.1 (Outer Measure). An outer measure on a setS is a nonnegative, ex-
tended real-valued set function J..L* : 28 --+ [0, oo] that satisfies the following condi-
tions: 
(a) J..L* (0) = 0. 
(b) (Monotonicity) If A~ B ~ S, then J..L*(A)::::; J..L*(B). 
(c) (Countable subadditivity) If An ~ S for all n ~ 1, then 
Measure, Probability, and Mathematical Finance. 
29 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

30 
EXTENSION OF MEASURES 
Definition 3.2 (Complete Measure). Let J-l be a measure on a O"-algebra ~. The 
measure f-l is said to be complete if and only if all subsets of a zero measure set in ~ 
are in~. Thus, whenever A E ~with J-l(A) = 0, we have BE~ for all B ~A. 
Definition 3.3 (Completion of Measure Spaces). Let (S, ~' J-l) be a measure space. 
The completion of (S, ~' J-l) is a measure space (S, ~~"' J-l), where 
~~" = {AUB: A E ~,B ~ N E ~,J-l(N) = 0}. 
The measure J-l is extended to ~It as follows. Let E E ~w Then E = AU B, 
where A E ~and B ~ N for some N E ~with J-l(N) = 0. We define J-l(E) = 
J-l(A U B) = J-l(A). 
Theorem 3.1 (Extension of Finite Measures). If J-l is a finite measure on an algebra 
~0 , then J-l can be extended to a measure on 0"(~0 ). 
Theorem 3.2 (Uniqueness of Extension). Let S be a set, let I be a 1r-system on S, 
and let ~ = O"(I) be the O"-algebra generated by I. If /-ll and f-l2 are measures on 
(S, ~)such that /-ll (S) = /12(8) < oo and /-ll (I) = J-l2(I) for all I E I, then 
J-li(I) = /12(!) 
't:/1 E ~. 
Theorem 3.3 (Monotone Class Theorem). Let ~ 0 be an algebra of subsets of a set 
S. Let~ be a monotone class of subsets of S. (i.e., if A 1 , A2, ... E ~and An t A 
or An_)_ A, then A E ~). lf~o ~ ~.then O"(~o) ~ ~. 
Theorem 3.4 (Caratbeodory's Extension Theorem). Let J-l be a O"-finite measure on 
an algebra ~0 of subsets of a set S. Then J-l has a unique extension to a measure on 
O"(~o). 
Theorem 3.5 (Approximation Theorem). Let (S, ~' J-l) be a measure space. Let ~0 
be an algebra of subsets of S such that 0"(~0 ) = ~. Assume that J-l is O"-finite on ~o. 
If A E ~and J-l(A) < oo, then, for each E > 0, there exists a set B E ~ 0 such that 
J-l(AtlB) < E, where AtlB is the symmetric difference of A and B (see Definition 
/.5). 
3.2 
Problems 
3.1. Let ~0 be an algebra of subsets of a setS, and let J-l be a finite measure on ~ 0 
(see Definition 2.9). Let { An}n::=: 1 and { Bn}n::=: 1 be two sequences of elements of 
~ 0 such that An t A and Bn t B (A and B may not belong to ~0 ). Show that if 
A~ B, then 
(3.1) 
if A= B, then 
lim J-l(An) = lim J-l(Bn)Â· 
n-too 
n-too 
(3.2) 

PROBLEMS 
31 
3.2. Let 2::0 be an algebra of subsets of a set S, and let f1 be a finite measure on 
2::0. Let C be the collection of all limits of increasing sequence of elements of I:o. 
Thus, A E C if and only if there exists a sequence AI, A2, ... E 2::0 such that 
An t A. Let A be a set function on C defined as follows. If A E C and A t/:. 2::0 , then 
A( A) = limn--+oo fl(An), where AI, A2, ... E I:o and An t A E C. If A E C and 
A E 2::0 , then A( A) = 11(A). Show that 
(a) A is well defined. 
(b) 0 E C and A(0) = 0; S E C and A(S) < oo. 
(c) If A, BE C, then AUB, AnB E C and A(AUB) =A( A) +A( B) -A(AnB). 
(d) If A, BE CandAS: B, then A(A) ::::; A(B). 
(e) If AI, A2, ... E C and Ant A, then A E C and A(An) -+A( A). 
3.3. Let C be a collection of subsets of a set S and A be a nonnegative, real-valued 
set function on C such that C and A satisfy the four conditions (b)-(e) in Problem 3.2; 
that is, C and A satisfy: 
(a) 0 E C and A(0) = 0; S E C and A(S) < oo. 
(b) If A, BE C, then AUB, AnB E C and A(AUB) = A(A) +A(B)- .A(AnB). 
(c) If A, B E C and A S: B, then A(A) ::::; A(B). 
(d) If AI, A2, ... E C and Ant A, then A E C and A(An)-+ A( A). 
For each A s:;; S, define 
fl*(A) = inf{A(G): G E C, AS: G}. 
Show that 
(a) 11* = A on C, and 0 ::::; 11* (A) ::::; A(S) for all A S: S. 
(b) fl*(A U B)+ fl*(A n B)::::; fl*(A) + fl*(B) for all A, B S: S. 
(c) If A, B S: Sand AS: B, then fl*(A)::::; fl*(B). 
(d) If AI, A2, ... S: Sand Ant A, then fl*(An) t fl*(A). 
(e) 11* is an outer measure on S. 
(f) IfH = { H S: S : 11* (H)+ 11* (He) = fl*(S)}, then His a O"-algebra of subsets 
of Sand 11* is a finite measure on H. 
3.4. Let ( S, I:, f1) be a measure space and I: !L be the completion of I: relative to fl. 
Show that I:M is a O"-algebra. 

32 
EXTENSION OF MEASURES 
3.5. Let (S, I:, p,) be a measure space, and let I:JL be the completion of I: relative to 
J-L. Let p,1 and J-l2 be two set functions on S defined as 
Show that 
J-LI(A) 
J-L2(A) 
sup{p,(B): BE I:,B ~A}, 
A~ S, 
inf{p,(B) : B E I:, A~ B}, 
A ~ S. 
(a) If A E I:JL, then J-L1 (A) = J-L2(A) = p,(A). 
(b) If A~ Sand J-LI(A) = J-L2(A) < oo, then A E I:w 
3.3 
Hints 
3.1. Consider the sequence Am n Bn and use Theorem 2.1. 
3.2. 
The parts (a)-(d) should be straightforward according to the definition of>., 
Problem 3.1, and Problem 2.11. For part (e), we need to construct an increasing se-
quence of sets in I:0 from the increasing sequences that converge to A 1 , A2, ... , An, 
... such that the constructed increasing sequence of sets converges to A. For exam-
ple, let Bnm t An as m --+ oo for each n ~ 1. Then we let Cm = U:1 Bi,m+l-i 
form ~ 1. The sequence { Cm}m:::: 1 is an increasing sequence and converges to A. 
3.3. Part (a) follows from the definition of p,* directly. For parts (b)-(d), we need to 
use the definition of p,* in another form. For example, for each n ~ 1, there exists a 
set An E C such that A~ An and >.(An) < p,*(A) + 1/n. Part (e) can be proved 
by using the definition of outer measures and parts (a), (b), and(d). For part (f), we 
can use the concepts of 1r-system and .A-system to prove that 1i is a a-algebra. The 
method of mathematical induction can be used to prove that p,* is a measure on H. 
3.4. Follow the definition of a-algebra (see Definition 2.2). 
3.5. Part (a) can be proved by using the definition of p,1 and p,2 . For part (b), we 
need to use the E technique; that is, for any E > 0, there exists a set Bâ¬ E I: and 
Bâ¬ ~ A such that p,1 (A) < p,(Bâ¬) +E. 
3.4 Solutions 
3.1. Let m ~ 1 be fixed. Then Am n Bn t Am n B = Am as n --+ oo. By Theorem 
2.1, we have p,(Am n Bn) t p,(Am) as n --+ oo. But by Problem 2.11, we have 
p,(Am n Bn) :S: p,(Bn) for all n ~ 1. Hence we have p,(Am) = limn--+oo p,(Am n 
Bn) :S: limn--+oo p,(Bn)Â· Inequality (3.1) follows by letting m --+ oo. Equality (3.2) 
follows from inequality (3.1). 
3.2. 

SOLUTIONS 
33 
(a) This follows from Problem 3.1. 
(b) This is trivial since ~ 0 is an algebra, ~0 <;;; C, and>.= f-t on ~o-
(c) Let An, Bn E ~ 0 for n 2 1 such that An t A and Bn t B. Then we have 
An U Bn t AU B E C and Ann Bn t An B E C. By Problem 2.11, 
f-t(An u Bn) = f-t(An) + f-t(Bn) - f-t(An n Bn) for all n 2 1. Letting n-+ oo, 
we get >.(AU B) =>.(A)+ >.(B)- >.(An B). 
(d) This follows from Problem 3.1. 
(e) For each n 2 1, since An E C, there exists a sequence { Bnm}m>l in ~o 
such that Bnm t An as m -+ oo. Let Cn = U~ 1 Bin for all n 2-1. Then 
Bin <;;; Cn <;;; An and f-t(Bin) :::; f-t( Cn) :::; >.(An) for all i :::; n. Letting n-+ oo, 
we get Ai <;;; U~= 1 Cn <;;;A and >.(Ai) :::; limn-+oo f-t(Cn) :::; limn-+oo >.(An)Â· 
Letting i -+ oo, we get A = U~=l Cn (or Cn t A) and limn-+oo >.(An) 
limn-too f-t(Cn) =>.(A). 
3.3. 
(a) This follows from the definition of f-t*. 
(b) Let E > 0. By the definition of f-l*, there exists a set E E C such that A <;;; E 
and >.(E) :::; f-t*(A) +E. Similarly, there exists a set F E C and >.(F) :::; 
f-t*(B) +E. Note that AU B <;;; E U FE C and An B <;;;En FE C, we have 
f-t*(A U B):::; >.(E U F) and J.L*(A n B):::; >.(En F) by the definition of J.L*. 
Since >.(E u F)+ >.(En F) = >.(E) +>.(F), we have 
J.L*(A U B)+ J.L*(A n B):::; J.L*(A) + f-t*(B) + 2E. 
Since E > 0 is arbitrary, the result follows. 
(c) By the definition of J.L*. there exists a set Bn E C such that B <;;; Bn and 
>.(Bn) < J.L*(B) + 1/n. Since A <;;; B, we have A <;;; Bn and thus J.L*(A) :::; 
>.(Bn). Hence we have J.L*(A) < J.L*(B) + 1/n. The result follows by letting 
n-+ oo. 
(d) Since Ant A, then J.L*(An) is increasing and J.L*(An) :::; J.L*(A) :::; >.(S) < oo 
for all n 2 1. Hence the limit of J.L * (An) exists and limn-+oo J.L * (An) :::; J.L * (A). 
Thus we only need to prove J.L*(A):::; limn-+oo J.L*(An)Â· 
Let E > 0. For each n 2 1, by the definition of J.L*, there exists a set En E C 
such that An <;;; En and >.(En) :::; J.L*(An) + E/2n. Then A = U~=l An <;;; 
U~=l En. It follows that 
(3.3) 

34 
EXTENSION OF MEASURES 
We claim that 
( 
N 
) 
N 
1 
A n~l En 
:S: J1*(AN) + E ~ 
2n. 
(3.4) 
To prove inequality (3.4), we use mathematical induction. When N = 1, in-
equality (3.4) is true by the choice of E 1 . Assume that inequality (3.4) is true 
for N = m. Then by the property of >., we have 
>. CQl En) +>.(Em+!)- A ( CQl En) n Em+l) 
< 
>. CQl En) + >.(Em+d ->.(Em n Em+I) 
< J1*(Am) + E f 2~ + J1*(Am+I) + 2.:+! -J1*(Am) 
n=l 
m+l 1 
< J1*(Am+I) + E L 2n. 
n=l 
Hence inequality (3.4) is true. Letting N---+ oo in inequality (3.4) gives 
lim .x (u):::: lim J1*(AN) +E. 
N --+oo 
N --+oo 
n=l 
By inequality (3.3), we get J1*(A)::; limN--+oo J1*(AN) +E. Since E is arbitrary, 
we have J1*(A)::; limn--+oo J1*(An). This completes the proof. 
(e) It is clear that /1*(0) = 0 and J1*(A) ::; J1*(B) for A ~ B ~ S. Now let 
An ~ S for n 2:: 1. Then by parts (d) and (b) of this proof, we have 
Hence 11* is an outer measure on S. 
(f) By Problem 2.6, to show that 1i is a O"-algebra, we only need to show that 1i is 
both a 1r-system and ad-system. Let A, B E 1i. By part (b) of this proof, we 
have J1*(A n B)+ 11*((A n B)c) 2:: J1*(S) and J1*(A u B)+ J1*((A U B)c) 2:: 
11*(8). Hence, wehavef1*(AnB)+M*((AnB)c)::; J1*(A)+J1*(B)-J1*(Au 
B)+J1*(Ac)+J1*(Bc)-J1*(AcnBc) = 2J1*(S)-[J1*(AUB)+J1*(AcnBc)]::; 
11*(8). Hence 11*(A n B)+ J1*((A n Bn = 11*(8) and then An B E 1i. 
Therefore, 1i is a 1r-system. 
Now we show that 1i is ad-system. Since /1*(0) = 0, we haveS E 1i. Let 
A, B E 1i and A ~ B. Then Ac E 1i. Since 1i is a 1r-system, we have 
B n Ac E 1i. Now let An E 1i for n 2:: 1 and An t A. By part (d) of this proof, 

SOLUTIONS 
35 
we have p,*(An) t p,*(A). Since A~ J. Ae, p,*(Ae) :::; p,*(A~) = p,*(S)-
p,*(An) or p,*(An) :::; p,*(S)- p,*(Ae) for all n :::: 1. Letting n -7 oo gives 
p,*(A):::; p,*(S)-p,*(N). Butsincep,*(A)+p,*(N):::: p,*(AuAe) = p,*(S), 
we have p,*(A) + p,*(N) = p,*(S). Therefore, A E 1i. Hence 1i is ad-system. 
Finally, we show that p,* is a finite measure on 1i. Clearly, p,*(0) = 0 and 
p,* (S) < oo. To show that p,* is countably additive, let A1 , A2 , ... be disjoint 
sets in 1i. We claim that 
(3.5) 
To show this, we use mathematical induction. When N = 1, Equation (3.5) is 
trivial. Assume that Equation (3.5) holds for N = m. Then by part (b) of this 
proof, we obtain 
p,*(S)- p,* co: A~) 
> p,*(S)- p,* (ft A~) - p,*(A~+l) 
+p,* ( (01 A~) U A~+ 1 ) 
2p,*(S) _ p,* co A~) _ p,*(A~+l) 
p,* (Ql An) + p,*(Am+l) 
Therefore, equation (3.5) holds for all N :::: 1. The result follows by letting 
N -7 oo in Equation (3 .5) and part (d) of this proof. 
3.4. 
Since S E I: and p,(0) = 0, we have S = S U 0 E I:w Let E E I:w 
Then E = AU B, where A E I; and B ~ N for some N E I; with p,(N) = 0. 
Since Ne ~ Be, we have Ee = Ae n Be = (Ae nNe) u (Ae n Ben N). Note 
that since p,(Ae n Be n N) :::; p,(N) = 0, we have p,(Ae n Be n N) = 0. Thus 
Ee E I:w Now let En E I: I-' for n :::: 1. Then En =An U Bn, where An and Bn are 
defined similarly. Since U~= 1 En = U~= 1 An u Bn = (U~= 1 An) u (U~= 1 Bn) 
and JL (U~= 1 Bn) = 0 (see Problem 2.19), we have U~=l En E I:w Therefore, I:~-' 
is aCT-algebra. 
3.5. 

36 
EXTENSION OF MEASURES 
(a) Since A E I:J.L, we can express A = A1 U A2 , where A1 E I: and A2 ~ N for 
some set N E I: with J.L(N) = 0. Note that A1 E I: and A1 ~ A, we have 
J.Ll (A) 2:: J.L(Al) = J.L(A). On the other hand, we have A ~ A1 UN. We have 
J.L1 (A) :::; J.L(A1 UN) = J.L(Al) = J.L(A). Thus J.Ll(A) = J.L(A). Similarly, we 
have J.L2(A) = J.L(A). 
(b) Suppose that A ~ Sand /-Ll (A) = J.L2(A) < oo. For each n 2:: 1, by definition 
of J.L1, there exists a set Bn E I: such that Bn ~ A and /-Ll (A) < J.L(Bn) + 1/n. 
Similarly, there exists a sequence { Cn}n>l of sets in I: such that Cn ::2 A for 
all n 2:: 1 and J.L2(A) > J.L(Cn)- 1/n. Then U~ 1 Bi ~ A~ n~ 1 Ci. Now 
we let B = U~ 1 Bn and C = n~=l Cn and write A= B U (A\B). Note that 
J.L(Bn) :::; J.L (U~l. Bi), J.L(Cn) 2:: J.L(n~=l Cn), and J.L(Bn) + 1/n > /-Ll (A) = 
J.L2(A) > J.L(Cn)- 1/n for all n 2:: 1. We have J.L(C\B) = J.L(C)- J.L(B) :::; 
J.L(Cn) - J.L(Bn) < 2/n. Letting n-+ oo gives J.L(C\B) = 0. This completes 
the proof. 
3.5 
Bibliographic Notes 
Usually we define a set function on a field I:0 of subsets of a setS and then extend the 
set function to a measure on cr(I:0 ), the smallest cr-field containing I:0 . The theorems 
presented in this chapter provide a theoretical foundation for measure extension. For 
example, we can extend the set function J.L( a, b] = b - a defined on the set of all 
right-semiclosed intervals to B (Ash and Doleans-Dade, 1999, p12). 
In a general case, we consider extending a finite measure J.Lo from a field I:0 of 
subsets of a setS to the minimal cr-field I: = cr(I:0 ). To do this, we first consider 
extending the measure to the set of all limits of increasing sequences of sets in I:0 , 
as follows: 
I:1 ={A~ S: there are sets An E I:o such that Ant A}. 
We can do this by defining J.Ll on I:1 as follows: 
J.Ll(A) = lim J.Lo(An), 
n-+oo 
where A E I:1 and An E I:0 is a sequence such that An t A. 
Then we define an extended set function J.L* on S as 
J.L*(A) = inf{J.Ll(G): G E I:1, G ::2 A}. 
It can be shown that J.L* defined in the above equation is an outer measure on S 
(see Problem 3.3). Using the outer measure, we define a set 1i = 
{ H 
~ S : 
J.L*(H) + J.L*(Hc) = J.L*(S)}. It can be shown that 1i is a cr-field and J.L* is a finite 
measure on 1i. The set 1i is a superset of cr(I:0 ). In fact, if a set B E 1i, then 
we can write B = AU N for some A E cr(I:0 ) and N ~ M, where M E cr(I:0 ) 
and J.L* (M) = 0. The measure space (S, 1i, J.L*) is also called the completion of the 
measure space (S, cr(I:o), J.L*). 
Rosenthal (2006, Chapter 2) presented some examples of constructing probability 
measures using the extension theorem. 

CHAPTER4 
LEBESGUE-STIELT JES MEASURES 
The Lebesgue measure is a special measure defined on subsets of Euclidean spaces 
and is the standard way of measuring the length, area, and volume of these subsets. In 
this chapter, we define the Lebesgure measure and present some relevant theorems. 
4.1 
Basic Concepts and Facts 
Definition 4.1 (Lebesgue-Stieltjes Measure). A Lebesgue-Stieltjes measure on R = 
( -oo, oo) is a measure 11 on B such that 11(!) < oo for each bounded interval I C R. 
Definition 4.2 (Distribution Function). A distribution function on R is a map F : 
R ---+ R that satisfies the following conditions: 
(a) F is increasing; that is, a< b implies F(a) :::::; F(b). 
(b) F is right-continuous: 
lim = F(xo), 
x--+xci 
where x---+ xt means that x > x 0 and x converges to x 0 â¢ 
Measure, Probability, and Mathemntical Finance. 
37 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

38 
LEBESGUE-STIELTJES MEASURES 
Definition 4.3 (Lebesgue Measure). The Lebesgue-Stieltjes measure J-L on R defined 
by 
J-L( a, b] = b - a, 
a < b 
is called the Lebesgue measure on B (see Theorem 4.1). The completion i3 of B 
relative to the Lebesgue measure is called the class of Lebesgue measurable sets. 
Definition 4.4 (Lebesgue-Stieltjes Measure on Rd). A Lebesgue-Stieltjes measure 
on Rd is a measure f-L on B(Rd) such that J-L(I) < oo for each bounded interval 
I c R d, where d E N and B(R d) is the collections of Borel sets of R d, that is, the 
a-algebra generated by all intervals (a, b], a, bE Rd. 
Definition 4.5 (Difference Operator). Let G : Rd --+ R be a function. The differ-
ence operator ~i,b,aG(x 1 , x2, ... , xd), 1 :::; i :::; d, is defined as 
G(x1, ... , Xi-l, b, Xi+ I, ... , xd) 
-G(xl, ... ,Xi-l,a,xi+l,Â·Â·Â·Â·xd)Â· 
(4.1) 
Definition 4.6 (Distribution Function on R d). A distribution function on R d is a 
map F : R d --+ R that satisfies the following conditions: 
(a) F is increasing; that is, a :::; b (i.e., ai :::; bi fori = 1, 2, ... , d, where ai and bi 
are the ith components of a and b, respectively), implies F(a, b] ::::: 0, where 
F(a, b] = ~l,b 1 ,a 1 â¢.â¢ ~d,bd,adF(xl, x2, ... , Xd); 
(4.2) 
(b) F is right-continuous; that is, for any sequence x 1 ::::: x 2 ::::: Â· Â· Â· --+ x, we have 
F(xk) --+ F(x). 
Definition 4.7 (Lebesgue Measure on Rd). The Lebesgue-Stieltjes measure J-L on 
R d defined by 
J-L(a, b] = F(a, b], 
a:::; b 
is called the Lebesgue measure on B(Rd) if F(x) = x 1x2 Â· Â· Â· Xd for x E Rd. The 
completion B(Rd) of B(Rd) relative to the Lebesgue measure is called the class of 
Lebesgue measurable sets in Rd. 
Theorem 4.1. Let F be a distribution function on R, and let B0 (R) be the algebra 
of all finite disjoint unions of right-semiclosed intervals ofR (counting [-oo, b] as 
right-semiclosed). Let J-L: B0 (R) --+ R be a set function defined as 
J-L(a, b] = F(b)- F(a), 
a< b. 
Then J-L has a unique extension to a Lebesgue-Stieltjes measure on R. 
Theorem 4.2. Let F be a distribution function on Rd, and let B0(fid) be the alge-
bra of all finite disjoint unions of right-semiclosed intervals (a, b] of R d (counting 
[ -oo, b] as right-semiclosed), where 
(a, b] = {x E Rd: ai <Xi :::; bi, i = 1, 2, ... , d}. 

PROBLEMS 
39 
Let JL: B0(Rd) ~ R be a set function defined as 
JL(a, b] = F(a, b], 
aS:: b, 
where F(a, b] is defined in Equation (4.2). Then JL has a unique extension to a 
Lebesgue-Stieltjes measure on Rd. 
4.2 Problems 
4.1. Let JL be a Lebesgue-Stieltjes measure on R. Let F : R ~ R be a function 
defined by F(b)- F(a) = JL(a, b] forb;::: a and F(O) = cfor some constant c E R. 
Show that F is a distribution function on R. 
4.2. Find a measure JL on R such that the distribution function F defined by F(b) -
F(a) = JL(a, b] forb ;::: a is not left-continuous at some point x0 , where x ~ x0 
means x < x0 and x converges to x0 : 
lim F(x) #- F(xo), 
x--+xo 
4.3. Let F be a distribution function, and let JL be the corresponding Lebesgue-
Stieltjes measure: 
JL( a, b] = b - a, 
a < b. 
Let F(x0) denote Iimx--+x- F(x). Show that 
0 
(a) JL[a, b] = F(b)- F(a-). 
(b) JL(a, b)= F(b-)- F(a). 
(c) JL[a, b) = F(b-)- F(a-). 
(d) JL( -oo, x] = F(x) - F( -oo ). 
(e) JL(-oo,x) = F(x-)- F(-oo). 
(f) JL[x,oo) = F(oo)- F(x-). 
(g) JL(x,oo) = F(oo)- F(x). 
(h) JL(R) = F(oo)- F(-oo). 
4.4. Let F : R d ~ R be a function. Show that 
d 
b.1,b1,a1 Â· Â· Â· b.d,bd,adF(x) = L) -l)iSi, 
i=O 
where 
si = 
L 
F(x)lxj=Uj for jEA,Xj=bj for jEQd\Aâ¢ 
A~Qd,IAI=i 
(4.3) 

40 
LEBESGUE-STIELTJES MEASURES 
with Qd = {1, 2, ... , d}. For example, So= F(b1, bz, ... , bd) and 
d 
sl = L F(bi, ... 'bi-1, ai, bi+I, ... 'bd)Â· 
i=l 
4.5. Let f..t be a finite measure on B(Rd), and let F : Rd --+ R be defined as 
F(x) = f..t( -oo, x] = f..t{Y E Rd: Yi ::::; Xi, i = 1, 2, ... , d}. 
Let a, bE Rd and a::::; b. Show that 
4.6. Let F1 , F2 , ... , Fd be distribution functions on R, and define F: Rd--+ R as 
d 
F(x) =II Fi(xi)Â· 
i=l 
Show that 
(a) 
d 
F(a, b] =II (Fi(bi)- Fi(ai)), 
a::::; b, 
i=l 
where F(a, b] is as defined in Equation (4.2). 
(b) F is a distribution function on Rd. 
4.7. Let F be a continuous distribution function on R. Let f..t be the Lebesgue-
Stieltjes measure defined by f..t(a, b] = F(b)- F(a). Show that f..t(A) = 0 if A is a 
countable subset of R. 
4.8 (Cantor Ternary Set). The Cantor ternary set is constructed by removing the 
middle thirds of line segments in [0, 1] as follows. Let M 1 be the middle third of 
[0, 1], that is, M1 = (~, ~). Let M2 be the union of the middle thirds of the two 
intervals in [0, 1]\MI, i.e., Mz = (-~, ~) U a,~). Sets M3, M4, Â· Â· Â· are constructed 
similarly. The Cantor ternary set Cis defined to be [0, 1]\ U~=l Mn. 
(a) Show that C has Lebesgue measure 0. 
(b) Let x = (O.a1a2 Â· Â· Â· h = 
L:~=l an/3n be the ternary form (i.e., the base 3 
expansion) of x E [0, 1]. For example, ~ = (0.1)3 = (0.0222 Â· Â· Â· )3. Show that 
x E C if and only if an E {0, 2} for all n 2': 1. 
(c) Show that Cis uncountable. 
4.9. Let f..t be the Lebesgue measure on R. Give an example set A ~ R such that 
f..t(A) > 0 and A does not contain any open interval. 

HINTS 
41 
4.3 Hints 
4.1. Use the definition of distribution functions (see Definition 4.2) and the result of 
Problem 2.18. 
4.2. It might not be easy to find such a measure directly. But one can easily find a 
distribution function that is not left-continuous at some point. Then one can define a 
measure based on the distribution function. 
4.3. 
To prove those equalities, we need to write the intervals in terms of right-
semiclosed intervals. 
4.4. Consider simple cases when d = 1, 2 and then use the method of mathematical 
induction to deal with the general case. 
4.5. First consider simple cases when d = 1, 2 and then consider the general case. 
4.6. 
Part (a) can be proved by using the definition of F(a, b]. Part (b) can be 
proved by using the proof of part (a) and the fact that F1 , F2 , ... , Fd are distribution 
functions on R. 
4.7. Use the result of problem 4.3 and the fact that a countable set can be expressed 
as{al,a2, ... }. 
4.8. 
For part (a), we can show that C has Lebesgue measure 0 by calculating the 
Lebesgue measure of U:'=1 Mn. Part (b) can be proved by examining the construc-
tion procedure of C. For part (c), we can use the method of contradiction to prove 
that C is uncountable; that is, we assume that C is countable and try to find another 
point inC using the ternary forms (Cantor's diagonalizing method). 
4.9. Use the idea of constructing the Cantor ternary set in Problem 4.8. 
4.4 Solutions 
4.1. 
Clearly, F is increasing. To show that F is right-continuous, let Xn .j.. x0, 
that is, x1 2:: X2 2:: Â· Â· Â· > Xo and Xn -+ xa. Then we have (xo, Xn] .j.. 0. Then by 
Problem 2.18, we have F(xn)- F(x0) .j.. 0. Thus F is right-continuous and hence a 
distribution function. 
4.2. Let J.L be a set function defined on all right-semiclosed intervals as follows: 
{
0, 
if a< b < 0; 
J.L( a, b] = 
2, 
if a < 0 and 0 ::; b; 
0, 
if 0 ::; a < b. 

42 
LEBESGUE-STIELTJES MEASURES 
Then f-L can be extended to a measure on B according to Theorem 3.1. The corre-
sponding distribution function F is 
F(x) = {F(O)- 2, 
F(O), 
if X< 0; 
ifO::; X. 
Clearly, the distribution function is not left-continuous at 0. 
4.3. 
Parts (d)-(h) are obtained from the definition and items (a)-(c) by letting 
a--+ -oo orb--+ oo. In the following we prove parts (a)-( c). 
(a) By definition and Problem 2.18, we have 
JL[a,b] 
(b) By definition and Theorem 2.1, we get 
JL(a, b) = 
(c) Similarly, we have 
4.4. 
We use mathematical induction on d. When d = 1, Equation (4.3) reduces 
to .6.1,b,,a, = F(bi)- F(ai), which is true. Suppose that the equation holds when 
d = m. When d = m + 1, let 
f}.m+l,bm+l,am+l F(x1, Â· Â· Â· 'Xm+I) 
F(x1, ... , Xm, bm+l)- F(x1, ... , Xm, am+dÂ· 

SOLUTIONS 
43 
Then by the induction hypothesis, we obtain 
~1 b 
Â· Â· Â· ~ b 
E(x1 
x ) 
, 1,a1 
m, rn,arn 
'Â· â¢ Â·' m 
m 
2.)-1)j 
L 
E(x1, ... ,Xm)lxJ=aJforjEA,xJ=bjforjEQ,.\A 
j=O 
A<;;Qm,IAI=j 
m L( -1)j 
L 
F(x1, Â· Â· Â·, Xm, bm+dlx;=aj for jEA,xj=bJ for jEQ,. \A 
j=O 
A<;;Q,.,IAI=j 
m 
- L(-1)j L 
F(x1, ... ,Xm,amH)IxJ=ajforjEA,xJ=bJforjEQ,.\A 
j=O 
A<;;Qm,IAI=j 
m+1 
L ( -1)j 
L 
F(x1, Â· Â· Â·, Xm+dlxJ=aJ for jEA,xJ=bJ for jEQ,.+1 \AÂ· 
j=O 
A<;;Q,.+1,IAI=j 
Hence Equation (4.3) holds for all d ~ 1. 
4.5. By definition, we have 
and 
F(x1, ... , xd-1, bd)- F(x1, ... , Xd-1, ad) 
J.l{Y: Yi:::; Xi,i = 1,2,. 0 
0 ,d -1,yd:::; bd} 
-JL{Y: Yi:::; xi,i = 1,2, ... ,d -1,yd:::; ad} 
J.l{Y : Yi :::; Xi, i = 1, 2, ... , d- 1, ad :::; Yd :::; ad} 
~d-1,bd_ 1 ,ad_ 1 ~bdadF(x1, ... , X d) 
F(x1, ... , Xd-2, bd-1, bd)- F(x1, ... , Xd-2, bd-1, ad) 
-F(x1, ... , xd-2, ad-1, bd) + F(x1, ... , Xd-2, ad-1, ad) 
J.l{Y: Yi :::; xi, i = 1, 2, ... , d- 2, Yd-1 :::; bd-1, ad :::; Yd :::; ad} 
-JL{Y : Yi :::; Xi, i = 1, 2, ... , d- 2, Yd-1 :::; ad-1, ad :::; Yd :::; ad} 
J.l{Y: Yi:::; xi,i = 1,2, ... ,d- 2,ad-1:::; Yd-1:::; bd-1,ad:::; Yd:::; ad}Â· 
Repeating the above procedure d times gives the result. 
4.6. By definition, we have 
~d,bd,adF(x1, ... ,xd) 
F(x1, ... , Xd-1, bd) - F(x1, ... , Xd-1, ad) 
F(x1) Â· .. F(xd_I)F(bd)- F(x1) Â· Â· Â· F(xd_I)F(ad) 
F(x1) Â· Â· Â· F(xd_I)(F(bd)- F(ad)), 

44 
LEBESGUE-STIELT JES MEASURES 
and 
~d-l,bd_,,ad-1 ~d,bd,adF(xl, Â· Â· Â·, Xd) 
~bd_ 1 ad_ 1 F(xl) Â· Â· Â· F(xd_l)(F(bd)- F(ad)) 
F(xl) Â· Â· Â· F(xd-2)(F(bd-I)- F(ad_l))(F(bd)- F(ad)). 
The result follows by repeating the above procedure d times. 
Now we show that F is a distribution function on Rd. Let a ::::; b. Then by the 
first part of this proof, we have 
d 
F(a, b] = IJ (Fi(bi)- Fi(ai)) ;:::: 0. 
i=l 
Hence F is an increasing function. The right-continuity ofF follows from the right-
continuity of F 1 , F 2 , ... , Fd. This completes the proof. 
4.7. 
Since A is a countable set, we can enumerate the elements of A and write 
A= {a1 , a 2 , ... }. Since f-L is countably additive, we have f..L(A) = 2:::~= 1 f..L(an). By 
Problem 4.3 and the assumption that F is continuous, we have f..L(an) = f..L[an, an] = 
F(an)- F(a;;) = 0. Hence f..L(A) = 0. 
4.8. 
(a) Let f-L be the Lebesgue measure. Then f..L(Mn) = ~ Â· (~r- 1 for n = 1, 2, .... 
Noting that lvh, M 2 , Â· Â· Â· are pairwise disjoint, we have 
00 
00 
f..L(C) = 1- f..L( U Mn) = 1-L f..L(Mn) = 0. 
n=l 
n=l 
(b) Suppose that x E C. Then in the first step of constructing C we have x E [0, ~] 
or x E [~, 1]. If x E [0, ~],then a 1 = 0 [~can be written as (0.0222 Â· Â· Â· )3]. 
If x E [{, 1], then a1 = 2. In this second step, we have x E [0, iJ U [~, ~] U 
[~, ~] U [~, 1], which implies that a 1, a 2 E {0, 2}. Repeating the above process 
shows that an E {0, 2} for all n ;:::: 1. 
Suppose that an E {0, 2} for all n;:::: 1. Then x E [0, ~] U [~, 1] in the first step 
of constructing Cas a 1 E {0, 2}. Similarly, xis not in the removed intervals in 
all steps. Hence x E C. 
(c) Suppose that C is countable. Then we can write C = { c1 , c2 , ... } . According 
to the second item of this problem, we can write en = (O.an 1an2 Â· Â· Â· h with 
anm E {0, 2} for all n, m;:::: 1. Now we let b = (O.b1 b2 Â· Â· Â· )3, where 
bn = {0, 
~f ann= 2; 
2, 
1f ann= 0. 

BIBLIOGRAPHIC NOTES 
45 
Then b =1- Cn for all n ~ 1 since the difference of bn and ann is 2. Hence b tJ_ C. 
But bn E {0, 2} for all n ~ 1, we have b E C, which contradicts b tJ_ C. Thus 
C is uncountable. 
4.9. We use a similar approach used to construct the Cantor ternary set to construct 
A. Let a E (0, 1) be a constant. First we remove the middle a/2 from interval [0, 1]. 
That is, we remove M 1 = (a/4, 3a/4) from [0, 1]. Then we remove the middle 
a/8 of the remaining two intervals; that is, we remove M2 = (a/16, 3a/16) U 
(8 + 5a/16, 8 + 7a/16). We continue the above process to remove M 3 , M 4 , .. . . 
Finally, we let A = [0, 1]\ U~=l Mn. Note that f.L(Mn) = a/2n and M1, M2, .. . 
are disjoint, we have f.L(A) = 1- ,L~=l f.L(Mn) = 1 a> 0. 
We claim that A does not contain any open interval. In fact, suppose that (a, b) r:;;; 
A for some a < b. Then (a, b) must be in some remaining interval after Mn is 
removed for all n ~ 1. However, for sufficient large n, the length of each remaining 
interval after Mn is removed is less than b- a. Hence (a, b) must not be in any of 
those remaining intervals. Thus, A does not contain any open interval. 
4.5 
Bibliographic Notes 
In this chapter, we introduced the Lebesgue measure and the Lebesgue-Stieltjes mea-
sure, which is more general than the Lebesgue measure. To define the Lebesgue 
measure on the real line, we first define the measure on the collection of left-open 
and right-closed intervals. Then we extend this measure to the collection of Borel 
sets. For more information about Lebesgue measures, readers are referred to Ash 
and Doleans-Dade (1999). 
Theorems 4.1 and 4.2 state that we can define measures based on distribution 
functions. The proofs of these theorems can be found in Ash and Doleans-Dade 
(1999, pp24,30). 


CHAPTERS 
MEASURABLE FUNCTIONS 
In measure theory, measurable functions are defined by the property of their pre-
images. The definition of measurable functions is similar to the definition of contin-
uous functions in topology. In this chapter, we introduce measurable functions and 
relevant theorems. 
5.1 
Basic Concepts and Facts 
Definition 5.1 (E-Measurable Function). Let (S, E) be a measurable space. A func-
tion h : S --7 R is called E-measurable, or measurable relative to the a-algebra E, 
if and only if 
h- 1(A) E E, 
\fA E B, 
where B is the Borel a-algebra on R (see Definition 2.6) and h- 1(A) is defined as 
h- 1(A) = {s E S: h(s) E A}. 
The set of all E-measurable functions is denoted by mE. 
Measure, Probability, and Mathematical Finance. 
47 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

48 
MEASURABLE FUNCTIONS 
Definition 5.2 (Borel Function). Let S be a topological space (see Definition 2.5). 
A function h : S --+ R is called a Borel function if his B(S)-measurable or Borel 
measurable, where B(S) is the a-algebra generated by the collection of all open sets 
inS. 
Definition 5.3 (EI/E2-measurable Function). Let (81, El) and (82, E2) be two 
measurable spaces and h : 51 --+ 82. h is considered EI/E2-measurable if and 
only if 
h- 1(A) E E1, 
\fA E E2, 
where h- 1(A) = {s E 81: h(s) E A}. 
Definition 5.4 (Monotone Class of Functions). Let (S, E) be a measurable space and 
M be a collection of functions from S to R. The collection M is called a monotone 
class if it satisfies the following properties: 
(a) M includes the constant function 1. 
(b) Iff and g are bounded functions in Manda, bE R, then af + bg EM. 
(c) Iff is the limit of an increasing sequence {fn : n ~ 1} of positive functions in 
M (i.e., fn t f), then f E M. 
Theorem 5.1. Let (S, E) be a measurable space and mE denote the set of all E-
measurable functions from S to R. If A E R and h1 , h2 E mE, then 
h1 + h2 E mE, 
hi E mE, 
h1h2 E mE, 
>.h1 E mE. 
Theorem 5.2. Suppose that f : R --+ R is a continuous function or a piecewise-
continuous function. Then f is Borel measurable. 
5.2 Problems 
5.1. Let (81, E1) and (82, E2) be measurable spaces, and let h 
51 --+ 52 be a 
function. Show that 
(a) If Ai E E2 for all i E N, then 
5.2. Let (S, E) be a measurable space. Show that a subset A of Sis E-measurable 
if and only if IA is E-measurable; that is, A E E if and only if IA E mE. 
5.3. Let (S, E) be a measurable space, and let h : S --+ R be a function. Suppose 
that C ~ Band a(C) = B. Show that if h- 1(A) E E for every A E C, then his 
E-measurable. 

PROBLEMS 
49 
5.4. Let (S1, I;I) and (S2, I;2) be measurable spaces, and let h : S1 ~ S2 be a 
function. Suppose that C ~ I;2 and a(C) = I;2. Show that if h-1 (A) E I;1 for every 
A E C, then h is I;I/I;2-measurable. 
5.5. Let (S, I;) be a measurable space, and let h : S ~ R be a I;-measurable 
function. Let C ~ B. Show that 
where 
{h- 1(A) :A E a(C)}, 
{h- 1(A) :A E C}. 
5.6. LetS be a topological space. If h : S ~ R is continuous (i.e., h-1 (0) is open 
for any open set 0 E B), then h is a Borel function. 
5.7. Let (S, I;) be a measurable space. Show that h : S ~ R is I;-measurable if 
{h ~ c} E I;, 
Vc E R, 
where {h ~ c} = {s E S: h(s) ~ c}. 
5.8. Let (S, I;) be a measurable space. If h E mi; and f E mB, then f o h E mi;, 
where f o h : S ~ R is defined as 
(! o h)(s) = f(h(s)), 
't:/s E S. 
5.9. Let (S, I;) be a measurable space and { hn}nEN be a sequence of I;-measurable 
functions. Show that 
(a) infn~m hn is I;-measurable for all m E N. 
(b) supn~m hn is I;-measurable for all m E N. 
(c) lim inf hn is I;-measurable. 
(d) lim sup hn is I;-measurable. 
(e) {s: limn--too hn(s) exists in R} E I;, 
5.10. Let (S, I;) be a measurable space. Assume that h1 E mi; and h2 E mi;. Show 
that max(h1, h2) E mi;. 
5.11. Let (S, I;) be a measure space and f a positive I;-measurable function. For 
n E N, let O:n : [0, oo] ~ [0, oo] be defined as 
{
0, 
ifx = 0; 
O:n(X) = 
(i -1)2-n, if (i- 1)2-n <X~ i2-n, i = 1, 2, ... , n2n; 
n, 
ifn < x. 
(5.1) 

50 
MEASURABLE FUNCTIONS 
Show that 
fn t J, 
where fn = Ctn of, i.e., fn(s) = an(f(s)) for s E S. 
5.12. Let (S, I:) be a measurable space and M be a monotone class of functions 
on S. Let I be a 1r-system such that I: = a(I). Suppose that IA E M for every 
A E I, where IA is the indicator function of A. Show that M includes all positive 
I:-measurable functions and all bounded I:-measurable functions. 
5.3 Hints 
5.1. Use the definition of h- 1 (Definition 5.1) and the standard technique to prove 
that two sets are equal. In other words, we can prove A = B by establishing A ~ B 
andB ~A. 
5.2. Use the definition of I:-measurable functions (see Definition 5.1). 
5.3. A function h is I:-measurable if and only if h - 1 (A) E I; for all A E B (see 
DefinitionS.!). HencewecanshowthatA ={A E B: h- 1(A) E I:} is a a-algebra 
in order to establish A = B. 
5.4. Use the same idea used to prove Problem 5.3. 
5.5. First show that h - 1 (a( C)) is a a-algebra and then use the standard technique 
to show that h- 1(a(C)) = a(h- 1(C)); that is, show that h- 1(a(C)) ;;;? a(h- 1 (C)) 
and h- 1(a(C)) ~ a(h- 1(C)). 
5.6. Compare this problem with Problem 5.3 and note that B =a( C) (see Definition 
2.6), where C is the set of all open sets. 
5.7. Compare this problem with Problem 5.3 and note that B = a( C) (see Problem 
2.4), where C = { ( -oo, c] : c E R} is the set of all open sets. 
5.8. Use the result of Problem 5.7. 
5.9. 
Use the result of Problem 5.7 to prove parts (a) and (b). Parts (c)-(e) follow 
from parts (a) and (b). 
5.10. Use the result of Problem 5.8 and Theorem 5.1. 
5.11. Use the E technique to show that lim inf f n 2': f; that is, show that lim inf f n 2': 
f -
E for an arbitrary E > 0. 
5.12. Use Dynkin's lemma (see Problem 2.7) and the result of Problem 5.11. 

SOLUTIONS 
51 
5.4 Solutions 
5.1. 
(a) First, let x E h-1 (U:1 Ai)Â· By definition, we have 
Thus we have h(x) E U:1 Ai, which implies that h(x) E Aix for some ix E 
N. Therefore 
00 
i=1 
Since x is arbitrary, we have 
(5.2) 
Next, let x E U:1 h- 1(Ai), then x E h-1(AiJ for some ix EN. By defini-
tion, we have 
00 
i=1 
which gives x E h-1 (U:1 Ai). Since xis arbitrary, we have 
(5.3) 
Combining (5.2) and (5.3) gives 
(b) Since x E h- 1(Ac) is equivalent to h(x) E Ac, which is equivalent to h(x) rf-
A, and h(x) rf- A is equivalent to x rf- h-1(A), which is equivalent to x E 
(h- 1(AW, we have h- 1(Ac) = (h- 1(AW. 
5.2. 
First, we prove necessity. Suppose that IA E mE. Then, by definition of 
E-measurable functions, we have A= 1_.41(1) E E. 
Next, we prove sufficiency. Suppose that A E E. Let BE B. Then we have 
if 1 E B and 0 rf_ B; 
if 1 rf_ B and 0 E B; 
if 1 E B and 0 E B; 
ifl rf- Band 0 rf- B. 

52 
MEASURABLE FUNCTIONS 
Thus we have (41 (B) E ~- Hence IA is ~-measurable. 
5.3. Let A be the collection of elements A of !3 such that h - 1 (A) E ~: 
A= {A E !3: h- 1(A) E ~}. 
We claim that A is a a-algebra on R. Since h-1(R) = {s E S: h(s) E R} = S E 
~.we haveR E A. Let A E A, then h- 1(A) E ~- From Problem 5.1, we have 
h- 1(Ac) = (h- 1(A))c. Note that~ is a a-algebra on S, so we have h- 1(Ac) E ~ 
which implies Ac E A. Let Ai E A (i E N), then we have h- 1(Ai) E ~for all 
i EN. From Problem 5.1, we have 
which gives 
00 U Ai EA. 
i=1 
Therefore, A is a a-algebra on R. From the definition of A, we have A s;;; !3. Since 
!3 = a(C) and C s;;; A (by hypothesis), we have !3 s;;; A. Thus we have A = !3, 
which implies that h is ~-measurable. 
5.4. This proof is similar to that of Problem 5.3. Let A be defined as 
We show that A is a a-algebra on S2. Since h-1(82) = {x E S1 : h(x) E S2} = 
S1 E ~1, we have S2 E A. Let A E A, then h- 1(A) E ~1Â· From Problem 
5.1, we have h- 1(Ac) = (h- 1(A))c, and so h-1(N) E ~ 1 . Hence Ac E A. Let 
Ai E A (i EN); then we have h- 1(Ai) E ~ 1 for every i EN. From Problem 5.1, 
we have 
which gives 
00 
Therefore, A is a a-algebra on S2. From the definition of A, we have As;;; ~ 2 . Since 
~2 =a( C) and C s;;; A (by hypothesis), we have ~ 2 s;;; A. Thus we have A= ~ 2 , 
which implies that h is ~I/~ 2 -measurable. 
5.5. 
First, we show that h-1(a(C)) is a a-algebra on S. In fact, since a(C) is a 
a-algebra on R, we haveS = h-1(R) E h-1(a(C)). Let F E h-1(a(C)); then 
we have F = h- 1(A) for some A E a(C). From Problem 5.1, we have pc = 

SOLUTIONS 
53 
(h- 1(A))c = h- 1(N) E h- 1(a(C)). Let Fn E h- 1(a(C)) (n E N); then Fn = 
h- 1(An) for some An E a( C). Again from Problem 5.1, we have 
9
1 Fn = 9
1 h-1(An) = h-1 (91 An) E h-1(a(C)). 
Thus, h- 1(a(C)) is a a-algebra on S. Note that as h- 1(C) ~ h- 1 (a(C)), we have 
(5.4) 
Next, we show that 
(5.5) 
To do this, we define A as 
We claim that A is a a-algebra on R. In fact, sinceRE a(C) and h- 1(R) = S E 
a(h- 1(C)), we haveR EA. Let A E A, then A E a( C) and h- 1(A) E a(h- 1(C)). 
From Problem 5.1, we have h- 1(N) = (h- 1(A))c E a(h- 1 (C)). Thus, Ac EA. 
Let An E A (n EN), then An E a(C) and h- 1(An) E a(h- 1(C)). From Problem 
5.1, we have 
h- 1 (91 An) = 9
1 h- 1(An) E a(h- 1(C)), 
which implies U:=l An E A. Therefore, A is a a-algebra on R. Note that with 
C ~ A, we have a(C) ~ A. By definition of A, we have A ~ a(C). Therefore, 
A= a( C), which implies (5.5). 
Combining (5.4) and (5.5) gives the result. 
5.6. 
Let C = {0 ~ R : 0 is open}, then B = a(C). By hypothesis, we have 
h-: 1(0) E B(S), 'VO E C. From Problem 5.3, we know that his B(S)-measurable; 
that is, h is Borel (see Definition 5.2). 
5.7. 
Let C = {( -oo, c] : c E R}, then we have B = a( C) (see Problem 2.4). 
By hypothesis, h- 1(A) E L:, 'VA E C. From Problem 5.3, we know that his L:-
measurable. This completes the proof. 
5.8. To prove a function f o h E mL:, we only need to show that {! o h > c} E 
L:, 'Vc E R, where{! o h > c} = {s E S: f(h(s)) > c} (see Problem 5.7). To do 
this, let 
Ac ={a E R: f(a) > c} = f- 1((c,oo)), 
'Vc E R. 
Since f E mB, we have AcE B, 'Vc E R. Note that 
{! o h > c} = {s E S: h(s) E Ac} = h- 1(Ac), 
'Vc E R 
and h E mL:, we have {! o h > c} E L:, which implies that f o h is L:-measurable, 
that is, f o hE mL:. 

54 
MEASURABLE FUNCTIONS 
5.9. To prove a function h E m~, we only need to show that { h > c} E ~. 't/c E R, 
where {h > c} = {s E S: h(s) > c} (see Problem 5.7). 
(a) Note that 
{~g~ hn > c} = n {hn > c}, 
't/m EN, 
-
n2':m 
which implies infn'2:m hn is ~-measurable for all mE N. 
(b) From 
{ sup hn :S c} = n {hn :S c}, 
't/m EN, 
n2':m 
n2':m 
we know that supn'2:m hn is ~-measurable for all mEN. 
(c) Since 
lim inf hn = sup inf hn 
m'2:1n'2:m 
and infn'2:m hn is ~-measurable for every m E N, we have lim inf hn E m~. 
(d) Similarly, note that 
lim sup hn = inf sup hn, 
m'2:1n'2:m 
and supn'2:m hn is ~-measurable for every m E N, we have lim sup hn E m~. 
(e) Note that limn-+oo hn ( s) exists in R if and only if 
lim sup hn(s) =lim inf hn(s). 
Thus we have 
{ s: lim hn(s)existsinR} 
n-+oo 
{lim sup hn < oo} n {liminf hn > -oo} n f-1( {0} ), 
where f = lim sup hn - lim inf hn. Since lim sup hn and lim inf hn are ~Â­
measurable, we have 
{ s: lim hn(s) exists in R} E ~-
n-+oo 
5.10. 
By Theorem 5.1, we know that h1 -
h2 and h2 -
h1 are ~-measurable 
functions. Let f : R ---+ R be defined as 
f(x) = { ~ 
Then we have 
if X> 0; 
if X::::: 0. 

SOLUTIONS 
55 
By Problem 5.8, we only need to show that f is B-measurable in order to show that 
max(h1 , h 2 ) is I:-measurable. Let A E B. Then we have 
f_ 1(A) ={An (O,oo) 
ifO tf. A; 
AU ( -oo, 0] 
if 0 E A, 
which implies that f- 1 (A) E B. Hence f E mB. This completes the proof. 
5.11. 
Clearly, f n ( n ~ 1) are nonnegative simple functions and f n :::; f for all 
n~l. 
To show that f n t f, we first show that 
(5.6) 
To do this, let x E S. If f(x) = 0, then fn(x) = fn+l(x) = 0. If (i- 1)2-n < 
f(x) :::; i2-n for some 1 :::; i :::; n2n, then fn(x) = (i- 1)2-n. But (2i-
2)2-(n+l) < f(x):::; (2i)2-(n+l), we have fn+l(x) ~ (2i- 2)2-(n+l) = fn(x). 
If f(x) > n, then fn(x) = n. But fn+l(x) > n. Therefore, inequality (5.6) is true. 
Next, we show that 
lim fn =f. 
(5.7) 
n-7cxo 
Since lim sup fn :::; f, we only need to prove lim inf fn ~ f. To do this, let E > 0. 
For fixed xES, choose N, EN such that N, ~ max[f(x), log2 (1/c)]. Then 
liminf fn ~ inf fn(x) ~ fN,(x) > f(x)- TN, ~ f(x)- E. 
n?:N, 
Since this is true for every E > 0, we have lim inf f n ~ f. On combining Equation 
(5.6) and Equation (5.7), we get fn t f. 
5.12. First, we show that IA E M for every A E I:. To do that, let 
V ={A E I:: IA EM}. 
It follows from the definition of monotone classes that V is a d-system. From the 
assumption, we have I~ V. By Problem 2.7, I:= (]'(I) ~ V. Hence IA EM for 
every A E I:. Since M is a monotone class, M contains all the simple functions on 
S. 
Next, let f be a positive I:-measurable function on S. Then by Problem 5.11, 
there exists a sequence {fn: n ~ 1} of positive simple functions such that fn t f. 
Since fn EM, we have f EM. 
Finally, let f be a bounded I:-measurable function on S. Then f+ =max(!, 0) E 
M and f- = max(- f, 0) E M. Hence we have f = f+ - f- E M. 
This completes the proof. 

56 
MEASURABLE FUNCTIONS 
5.5 
Bibliographic Notes 
Most material in this chapter was taken from Williams (1991 ), where readers can find 
proofs of Theorem 5 .1. Proving Theorem 5.2 requires the following basic result of 
point-set topology: Iff is continuous, then f- 1 ( 0) is an open subset ofR whenever 
0 is an open subset ofR (Rosenthal, 2006, p31). 
In measure theory, the measurability of a function f : (81 , I:I) ---+ (82 , I:2 ) 
is defined in terms of the inverse image of f rather than the direct image of f. 
Hence, the function f is I:I/I:2-measurable does not imply than f(A) E I:2 for 
each A E I:1. In fact, basic set operations are preserved by inverse images but not in 
general by direct images (Ash and Doleans-Dade, 1999, p36). For example, we have 
f- 1(Ac) = [f- 1(AW but not f(Ac) = [f(AW in general. 

CHAPTER 6 
LEBESGUE INTEGRATION 
Lebesgue integration is the general theory of integration of a function with respect 
to a general measure. In this chapter, we present some concepts and theorems used 
to develop the Lebesgue integration theory. 
6.1 
Basic Concepts and Facts 
Definition 6.1 (Simple Function). Let (S, ~) be a measurable space and (m~)+ 
denote the set of all nonnegative ~-measurable functions. An element f of (m~)+ 
is considered simple if f can be written as a finite sum 
(6.1) 
where ak E [0, oo] and Ak E ~fork = 1, 2, ... , m. The set of all nonnegative 
simple functions is denoted by SF+. 
Measure, Probability, and Mathematical Finance. 
57 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

58 
LEBESGUE INTEGRATION 
Definition 6.2 (Integral of Nonnegative Simple Functions). Let (S, I:, J-L) be a mea-
sure space, and let 
m 
f = l::::akiAk 
k=l 
be a nonnegative simple function on S. The integral off with respect to J-L is defined 
as 
m 
J-Lo(f) = L akJ-L(Ak)Â· 
(6.2) 
k=l 
Definition 6.3 (Integral of Nonnegative Measurable Functions). Let (S, I:, J-L) be a 
measure space and (mi:)+ be the set of all nonnegative I:-measurable functions on 
S. Let f E (mi:)+, then the Lebesgue integral off with respect to J-L is defined as 
J-L(f) = sup{J-Lo(h): hE SF+, h :<::; !}. 
The integral J-L(f) is also written as fs f(x)J-L(dx) or J fdJ-L. 
Definition 6.4 (Integral of General Measurable Functions). Let (S, I:, J-L) be a mea-
sure space and f E mi:, where mi: is the set of all measurable functions on S. The 
function f is called J-L-integrable, denoted f E Â£1 (S, I:, J-L), if 
where j+ =max(!, 0) and f- =max(-f, 0). Iff is J-L-integrable, then the integral 
of f is defined as 
Definition 6.5 (Integral over Subsets). Let (S, I:, J-L) be a measure space and f E 
mi:. Let A E I:. The integral off over A is defined as 
Theorem 6.1 (Integration by Substitution). Let (81 , I:I) and (82 , I:2) be two mea-
surable spaces and T : 81 ---+ 82 be a I:I/I:2-measurable function. Let f.-Ll be a 
measure on I:1, and let J-L2 = J-L1T- 1 be a measure on I:2 defined as 
Iff: 82---+ R is I:2 /B(R)-measurable and A E I:2, then 
{ 
f(T(s))J-LI(ds) = { f(t)J-L2(dt), 
lr-'A 
}A 

PROBLEMS 
59 
in the sense that if one of the integrals exists (finite or infinite), then the other also 
exists and the two integrals are equal. 
Theorem 6.2 (Monotone Convergence Theorem). Let (S, 1:, p,) be a measure space, 
and let Un}n>l be a sequence of elements of(m1:)+ such that fn t f. Then 
Theorem 6.3 (Fatou's Lemma). Let (S, 1:, p,) be a measure space and fn E (m1:)+ 
for all n ~ 1. Then 
p,(liminf fn) :S: liminf J.L(fn)Â· 
Theorem 6.4 (Dominated Convergence Theorem). Let (S, 1:, p,) be a measure space. 
Suppose that f E m1: and fn E m1: for n ~ 1, that the sequence {fn}n>l con-
verges pointwise to f, that is, 
lim fn(s) = f(s), 
1:/s E S, 
n-+oo 
and that the sequence {fn}n21 is dominated by some nonnegative p,-integrablefunc-
tion g: 
lfn(s)l :S: g(s), 
s E S, n ~ 1. 
Then f is p,-integrable, that is, 
lim J.L(lfn - fl) = 0, 
n-+oo 
and 
lim J.LUn) = p,(f). 
n-+oo 
6.2 Problems 
6.1. Let (S, 1:, p,) be a measure space and 
m 
f = L:aiiAi 
i=l 
be a nonzero simple function on S, where ai E [0, oo] and Ai E 1:. Show that there 
exists a finite collection of mutually disjoint sets CH (HE 1i) and uH > 0 such that 
m 
m 
L:aJAi = L uHicH, 
i=l 
HE1i 
i=l 
HE1i 
6.2. Show that p,0(!) in Equation (6.2) is well defined. 
6.3. Let (S, 1:, p,) be a measure space and SF+ be the set of nonnegative simple 
functions on S. Let J.Lo be as defined in Equation (6.2). Show that 

60 
LEBESGUE INTEGRATION 
(a) If J, g E SF+ and JLU -=1- g) = 0, then J.Lo(f) = J.Lo(g). 
(b) (Linearity) Iff, g E SF+ and c ~ 0, then f + g, cf E SF+ and 
JLoU +g) = J.Lo(f) + J.Lo(g), 
J.Lo(cf) = CJ.Lo(f); 
(c) (Monotonicity) Iff, g E SF+ and f:::; g, then J.Lo(f) :::; J.Lo(g). 
(d) If f, g E SF+, then f A g E SF+ and f V g E SF+, where f A g = min(!, g) 
and f V g =max(!, g). 
6.4. Let (S, ~. JL) be a measure space. Let A E ~and {hn}n>l be a sequence of 
nonnegative simple functions such that hn t I A. Show that 
J.Lo(hn) t JL(A), 
where J.Lo is as defined in Equation (6.2). 
6.5. Let ( S, ~. Jl) be a measure space, and let f E SF+. Suppose that {! n }n> 1 is a 
sequence of elements of SF+ such that fn t f. Show that 
-
J.Lo(fn) t J.Lo(f), 
(6.3) 
where J.Lo is as defined in Equation (6.2). 
6.6. Let (S, ~. JL) be a measure space and f E (m~)+, where f is a nonnegative~Â­
measurable function on S. Suppose that {fn}n>l and {gm}m>l are two sequences 
of elements of SF+ such that 
-
-
Show that 
lim JLoUn) = lim J.Lo(gm), 
n-too 
m-+oo 
where J.Lo is as defined in Equation (6.2). 
6.7. Let (S, ~. Jl) be a measure space, and f E ( m~)+. Let {Yn}n>l be any se-
quence of elements of SF+ such that Yn t f. Show that 
-
6.8. Let (S, ~. JL) be a measure space, and let f E (m~)+ and JL(f) = 0. Show that 
JL({f > 0}) = 0. 
6.9. Let (S, ~. JL) be a measure space and let f, g E (m~)+ such that JLU -=1- g) = 0. 
Show that JL(f) = JL(g). 

PROBLEMS 
61 
6.10. Let (S, :E, p,) be a measure space and A E :E. Let f E m:E. Show that if 
p,(A) = 0, then 
ifdp,=O. 
6.11. Let (S, :E, p,) be a measure space and f E (m:E)+. Suppose that Un}n>l is a 
sequence of elements of (m:E)+ such that, except on a p,-null set A, fn t f.-Show 
that J.LUn) t p,(f). 
6.12. Let (S, :E, p,) be a measure space and J, g E (m:E)+. Let o:, ;3 > 0. Show that 
p,(o:f + ;3g) = o:p,(f) + ;3p,(g). 
6.13 (Reverse Fatou's Lemma). Let (S, :E, p,) be a measure space and {fn}n>l be a 
sequence of elements of (m:E)+ such that fn ~ g for all n ~ 1, where g E (m:E)+ 
and p,(g) < oo. Show that 
p,(limsupfn) ~ limsupp,(fn)Â· 
6.14. Let (S, :E, p,) be a measure space and h be a :E-measurable function. Show that 
(a) If his p,-integrable, then hi A is also p,-integrable for each A E :E, where fA is 
the indicator function. 
(b) If fs hdp, is finite, then JA hdp, is also finite for each A E :E. 
6.15. Let (S, :E, p,) be a measure space and h a :E-measurable function. Show that if 
his p,-integrable, then p,( {I hi = oo}) = 0, that is, his finite a.e. 
6.16 (Chebyshev's Inequality). Let (S, :E, p,) be a measure space and f be a non-
negative, extended-value, Borel measuralbe function on S. Let p E (0, oo) and 
E E (O,oo). Show that 
6.17. Let (S, :E, p,) be a measure space and J, g E L1(S, :E, p,), where L1(S, :E, p,) 
is the set of all p,-integrable functions on S. Let o:, ;3 E R. Show that o:f + ;3g E 
L 1 (S,:E,p,) and 
p,(o:f + ;3g) = o:p,(f) + ;3p,(g). 
6.18 (Scheffe's Lemma A). Let (S, :E, p,) be a measure space. Suppose that fn, f E 
L 1(S, :E, p,)+, that is, fn, f are nonnegative p,-integrable functions on S, and that 
fn -+ f a.e. Show that J.L(Ifn - fl) -+ 0 if and only if J.LUn) -+ p,(f). 
6.19 (Scheffe's Lemma B). Let (S, :E, p,) be a measure space. Suppose that fn, f E 
L 1(S,:E,p,),andthatfn-+ f(a.e.). Showthatp,(lfn-fl)-+ Oifandonlyif 
J.L(Ifnl)-+ J.L(Ifl). 

62 
LEBESGUE INTEGRATION 
6.20. Let (S, I:, J.L) be a measure space and h : R ---+ R be a Borel measurable 
function. Show that h of E L 1 (S, I:, J.L) if and only if h E L 1 (R, B, A1 ), where AJ 
is a measure on (R,B) andisdefinedasAJ(B) = J.LU E B)= J.L({s E S: f(s) E 
B} ), and that 
J.L(h of)= is h(f(s))J.L(ds) = L 
h(x)A1(dx) = A1(h). 
6.21. Let (S, I:, J.L) be a measure space and { hn}n> 1 be a sequence of elements of 
(mi:)+. Show that 
-
is (~hn) df..L =~is hndf..L. 
6.22 (Extended Monotone Convergence Theorem). Let (S, I:, J.L) be a measure space, 
and let g, h, g1 , g2 , ... be I:-measurable functions. Show that 
(a) If fs hdf..l > -oo, gn 2: h for all n 2: 1, and gn t g, then 
is gndf..l tis gdJ.L; 
(b) If fs hdJ.L < oo, gn ~ h for all n 2: 1, and gn .j,.. g, then 
6.23 (Gronwall's Lemma). Let f and g be two nonnegative Borel measurable func-
tions on [0, oo). LetT > 0 and a ;::: 0 be constants. Suppose that 
faT f(s)ds < oo 
and 
g(t) ~a+ fat g(s)f(s)ds, 
'it E [0, T]. 
Show that 
g(t) ~ aexp (fat f(s)ds), 
'it E [0, T]. 
6.3 Hints 
6.1. First find a way to construct a collection of pairwise disjoint sets from A1 , A2 , 
... , Am. The remaining proof is straightforward. 
6.2. Use the result of Problem 6.1. 

HINTS 
63 
6.3. For parts (a), (c), and (d), we need to use the result of Problem 6.1. Part (b) can 
be proved by using the definition of simple functions (see Definition 6.1). 
6.4. According to Problem 6.3, {JLo(Hn)}n>l is increasing. To show that 
lim JLo(hn) = JL(A), 
n-+oo 
we can show that 
limsupJLo(hn)::; JL(A) 
and 
liminf JLo(hn) ~ JL(A). 
The first equation here is straightforward. The second one can be established by 
showing that liminf JLo(hn) ~ (1- E)JL(A) for all E > 0. 
6.5. 
Since f n and f are nonnegative simple functions, we can write them as the 
linear combinations of indicator functions (see Problem 6.1). Then we can use the 
result of Problem 6.4 to prove this problem. 
6.6. 
Use the E technique to show that the two limits are equal; that is, we can 
show that Roo > Loo- E and Loo > Roo- E, where Roo = limm-+oo JLo(9m) and 
Loo = limn-+oo J,lo(/n). 
6.7. Use the result of Problem 5.11 to construct an increasing sequence {fn}n>l of 
nonnegative simple functions such that fn t f and JLo(f) t JL(/). Then the result 
follows from Problem 6.6. 
6.8. Consider the measure of sets An = {! > 1 j n} for n ~ 1. 
6.9. 
Construct two sequences {fn}n~l and {gn}n~l of increasing nonnegative 
simplex functions such that JLUn =/:- 9n) = 0 for all n ~ 1, fn t /,and 9n t g (see 
Problem 5.11). 
6.10. Consider the sequence f n = O:n o J+ and 9n = O:n o f-, where O:n is defined 
in Problem 5.11. Then use the monotone convergence theorem (Theorem 6.2). 
6.11. Consider functions fniS\A and f ! 8 \A and use the result of Problem 6.9 and 
Theorem 6.2. 
6.12. 
Use the result of Problem 5.11 to choose two sequences fn(n ~ 1) and 
9n ( n ~ 1) of nonnegative simple functions on S such that f n t f and 9n t g and 
use the result of Problem 6.3. 
6.13. Consider functions g- fn and g- f and use Fatou's lemma (see Theorem 
6.3). 
6.14. Consider the positive and negative parts of h and use the definition of integra-
tion of general measurable functions (see Definition 6.4). 

64 
LEBESGUE INTEGRATION 
6.15. Use the method of contradictino. 
6.16. Compare the integration of fP overS and over {s: f(s) ~ E}. 
6.17. 
Consider the positive and negative parts of the functions and the result of 
Problem 6.12. 
6.18. Consider the positive and negative parts of the function f n - f and use the 
dominated convergence theorem (see Theorem 6.4). 
6.19. 
Consider the positive and negative parts of the functions fn and f and use 
Fatou's lemma (see Theorem 6.3). 
6.20. 
Prove the problem by considering different cases of h. First show that the 
result holds when h is an indicator function. Then show that the result holds when 
h is a nonnegative simple function, a nonnegative Borel measurable function, and a 
general measurable function. 
6.21. Consider the partial sum of the sequence of functions (i.e., gn = I:~= I hi), 
and use Theorem 6.2 and the result of Problem 6.17. 
6.22. Consider the cases Is hdp, = oo and Is hdp, < oo and use Theorem 6.2. 
6.23. Let 
F(t) = 1t f(s)ds, 
G(t) = 1t f(s)g(s)ds. 
Then consider the function e-F(t)G(t). 
6.4 Solutions 
6.1. 
Let Hm = P( {1, 2, ... , m} ), where P( {1, 2, ... , m}) is the power set of 
{1, 2, ... , m }. We define 
UH = Lai, 
iEH 
where He= {1, 2, ... , m}\H. Then CH E '5:. (HE Hm) are mutually disjoint, and 
u 
HE1lrn,iEH 
Define Ht, as 
H-:;, ={HE Hm: UH > 0}. 

SOLUTIONS 
65 
Then we have 
m 
m 
LaiiAi 
Lai 
2:.:: 
IcH 
i=l 
i=l 
HEtlm,iEH 
2:.:: UHJCH 
HEtlm 
2:.:: UHJCHo 
HE1lt 
and 
m 
m 
L 
aiJL(Ai) 
Lai 
2:.:: 
JL(CH) 
i=l 
i=l 
HEtlm,iEH 
2:.:: UHJL(CH) 
HEtlm 
2:.:: UHJL(CH ). 
HE1lt 
Since IHml = 2m, we can show that H:j;, is a finite set. We let 1i = H:j;,. This 
completes the proof. 
6.2. Let f E S p+. Suppose that f has two different representations: 
m 
n 
f = LaiiAi = LbjJBJ' 
(6.4) 
i=l 
j=l 
where ai 2: 0, bj 2: 0, Ai E :E, and Bj E :E fori = 1, 2, ... , m and j = 1, 2, ... , n. 
Iff = 0, then we have aiiA, = 0 and bjiBJ = 0 for all 1 ::; i ::; m and 
1 ::; j ::; n. In this case, both representations give JLo(f) = 0. Iff =J 0, then from 
Problem 6.1 we have 
(6.5) 
where C H ( H E H:j;,) are pairwise disjoint sets, u H > 0, D J ( J E H:/;) are pairwise 
disjoint sets, and VJ > 0. 
Since 
{f > 0} = U CH = U DJ, 
HEHi;, 
JEH/; 
we have 

66 
LEBESGUE INTEGRATION 
Then, from (6.4) and (6.5) we have 
m 
L aitL(Ai) 
L 
UHfL(CH) = L:: 
L 
uHM(CH n DJ), (6.6) 
i=l 
HE1i1;. 
HE1i1;. JE1i1; 
n 
LbjtL(Bj) 
L 
VJM(DJ) = L:: 
L 
VJM(CH n DJ). 
(6.7) 
j=l 
JE1i1; 
HE1i1;. JE1i1; 
We claim that 
In fact, if CH n DJ = Â¢,then both sides of (6.8) are zero. If CH n DJ -/= Â¢,we 
have, forw E CH n DJ, 
f(w) = UH = VJ. 
Thus (6.8) is true. 
Therefore, (6.6) and (6.7) give the same fLo(!). Thus Mo is well defined. 
6.3. Let 
f 
(6.9) 
n 
g 
(6.10) 
where ai, bj E [0, oo] and Ai, Bj E :E. Then from Problem 6.1 we can write J, gas 
f = L uHicH, 
HE1i1;. 
without changing Mo(/), where CH (H E 1-Â£1;,) are mutually disjoint, uH > 0, 
D J ( J E 1-l-:j;) are mutually disjoint, and v J > 0. Let 

SOLUTIONS 
67 
then we have 
f 
L 
uHicH 
HE1-l"i;. 
L 
L 
UHlcHnDJ + L 
UHlcHnDc, 
(6.11) 
HE1-l"i;. JEH"}; 
HEH"i;. 
g 
L 
VJIDJ 
JEH"}; 
L 
L 
VJlcHnDJ + L 
VJIDJncc. 
(6.12) 
HEH"i;. JEH"}; 
JEH"}; 
(a) From (6.11) and (6.12), we have 
/LoU)- JLo(g) 
= 
L 
L 
(uH- VJ )JL(CH n DJ) 
HEH"i;. JEH"}; 
Since JLU -=1- g) = 0, we can show that (uH -VJ )JL(CHnDJ) = 0, UHJL(CH n 
DC) = 0, and VJJL(DJ n cc) = 0. In fact, if UH -=1- VJ, then CH n DJ ~ {f -=1-
g}, which gives JL(CH n DJ) :::; JLU -=1- g) = 0. If CH n nc -=1- Â¢,then 
f(s) = UH > g(s) = 0 for s E CH nne, which implies that JL(CH nne)= 0. 
Similarly, JL(DJ n cc) = 0. Therefore, JLoU) = JLo(g). 
(b) From (6.9) and (6.10), we have 
/LoU+ g) 
m 
n 
LaiJL(Ai) + LbjJL(Bj) 
i=l 
j=l 
/LoU)+ JLo(g), 
and 
(c) Let f and g be written as in (6.11) and (6.12), respectively. Since f :::; g, we 
have f(w) = UH :::; VJ = g(w) for w E CH n DJ if CH n DJ -=1- Â¢. If 

68 
LEBESGUE INTEGRATION 
CH n DC =IÂ¢, we have f(w) = UH = 0 for wE CH n De. Thus we have 
fto(f)- flo(g) 
L L (uH- vJ)fl(CH n DJ) 
HE1i1;, JEH1; 
HEH1;, 
JEH1; 
< 0. 
(d) From ( 6.11) and ( 6.12), we have 
fAg 
L L min(uH,VJ)IcHnDJ' 
HEHt JEH1; 
fVg 
L L max(uH,VJ)IcHnD" 
HEH;;, JEH1; 
+ L UHlcHnDc + L VJIDJncc, 
which imply that f A g and f V g are simple functions. 
6.4. Since hn t IA, from Problem 6.3, we have flo(hn) :S: flo(hn+I) for n :::0: 1 and 
flo(hn) ::::; flo(IA) = fl(A), which implies that limsupflo(hn) ::::; fl(A). Thus, we 
only need to show that 
liminf flo(hn) :::0: fl(A). 
(6.13) 
Let E > 0, and let An = { s E A : hn ( s) > 1 - E}. We claim that An t A. In fact, 
since hn :S: hn+l, we have An ~ An+lÂ· By definition, we have limn-+oo An ~ A. 
Lets E A. Since hn t IA, then hns (s) > 1 -
E for some n 8 E N. Hence we 
haves E AnsÂ· Thus, s E limn-+oo An. Hence Ant A. By Theorem 2.1, we have 
fl(An) t fl(A). But 
(1- E)IAn ::::: hn, 
n EN, 
thus, by Problem 6.3, (1 - E)fl(An) ::::; flo(hn)Â· Noting that hj ::::; hi for j ::::; i, by 
Problem 6.3, we have 
which gives 
(6.14) 
Letting m --+ oo in (6.14), we have 
lim inf flo(hn) :::0: (1 - E)fl(A). 
(6.15) 

SOLUTIONS 
69 
Since (6.15) is true for every E > 0, (6.13) is true. 
6.5. By hypothesis, f is a nonnegative simple function on S. Hence 
where ak 2: 0 and Ak E L: for 1 ::::; k ::::; r. 
If f = 0, then f n = 0, since, by hypothesis, f n ::::; f and f n 2: 0. By Problem 
6.2, J.Lo(fn) = J.Lo(f) = 0. Therefore (6.3) is true. 
If f > 0, then, by Problem 6.1, f can be written as 
s 
f= L:cJci, 
i=l 
where s E N, Ci > 0 for 1 ::::; i ::::; s, and Ci (1 ::::; i ::::; s) are pairwise disjoint. We 
claim that 
s 
fn = LlcJn, n 2: 1. 
(6.16) 
i=l 
To do this, let x E S. If fn(x) = 0, then Equation (6.16) is trivial. If fn(x) > 0, 
then, by hypothesis, f(x) 2: fn(x) > 0, which implies that X E Cia for some 
1 ::::; i 0 ::::; s. Accordingly, we have 
s 
fn(x) = IciJn(x) = L IcJn(x). 
i=l 
Therefore, Equation (6.16) is true. However, 
and by Problems 6.4 and 6.3, we have 
(6.17) 
Thus, by Problem 6.3 and Equation ( 6.17), we have 
This completes the proof. 
6.6. Let 

70 
LEBESGUE INTEGRATION 
where Ln = J.LoUn) for n;::: 1 and Rm = J.Lo(9m) form;::: 1. Let E > 0. Then 
for some n 0 E N. Let 
hn,rn = min(fn, 9m), 
n ;::: 1, m ;::: 1. 
By Problem 6.3, hn,m is a simple function on S. Noting that, for fixed n, 
we have 
hn,m t min(fn, f) = fn, 
E 
J.Lo(hno,mo) > Lno- 2' 
for some m 0 EN. By Problem 6.3, we have 
Roo;::: J.Lo(9m 0 );::: J.Lo(hn0 ,m0 )Â· 
On combining Equations (6.18)-(6.20), we get 
Roo> Loo- E, 
(6.18) 
(6.19) 
(6.20) 
so that Roo ;::: L 00 â¢ Similarly, L 00 ;::: R 00 â¢ Therefore, Loo = R 00 â¢ This completes 
the proof. 
6.7. By Definition 6.3, we may choose a sequence hn (n ;::: 1) of simple functions 
on S such that hn :::; f and J.Lo(hn) t J.L(f). By Problem 5.11, we may also choose a 
sequence 9n ( n ;::: 1) of simple functions on S such that 9n t f. 
Let 
fn = max(gn, h1, h2, ... , hn), 
n EN. 
Then, fn :::; fn+l :::; f for n ;::: 1 and, by Problem 6.3, fn (n ;::: 1) are nonnegative 
simple functions. Since 9n t f and f ;::: fn ;::: 9n, we get fn t f. Since fn :::; f 
and fn is simple, by definition of J.L(f), J.LoUn) :::; J.L(f). Noting that hn :::; fn and 
J.Lo(hn) t J.L(f), we have J.LoUn) t J.L(f). 
By hypothesis, Yn t f. Since fn t f and J.Lo(fn) t J.L(f), by Problem 6.6, we 
have 
J.Lo(Yn) t J.L(f). 
Note that Yn (n;::: 1) are simple functions, we have J.L(Yn) = J.Lo(Yn). Therefore 
6.8. 
We will show that J.L( {! > 0}) = 0 by contradiction. To do this, let An = 
{f > 1/n} for n;::: 1. Then Ant {f > 0}. By Theorem 2.1, J.L(An) t J.L( {! > 0} ). 
Suppose that J.L( {! > 0}) > 0. Then J.L(AN) > 0 for some N EN. By definition of 
J.L(f), we obtain 

SOLUTIONS 
71 
which contradicts the hypothesis that J.LU) = 0. Thus J.L( {f > 0}) = 0. 
6.9. Let fn = o:nof and gn = o:nog, where O:n is as defined in Equation (5.1). Then 
fn and gn are nonnegative simple functions. Since, by hypothesis, J.LU =/=- g) = 0, 
J.LUn =/=- gn) = 0 and, by Problem 6.3, J.L(/n) = J.L(gn)Â· Noting that fn t f and 
gn t g, by Theorem 6.2, we have J.L(/) = J.L(g). 
6.10. Let f n = O:n o j+ and gn = O:n o f-, where O:n is as defined in Problem 5 .11. 
Then we have fn t j+ and gn t f-. By Theorem 6.2, we have 
i fndf-L = is fniAdJ.L tis J IAdJ.L = i fdJ.L. 
But 
0 :S: i fndf-L :S: i ndJ.L = nJ.L(A) = 0, 
which gives fA fndf-L = 0. Hence we have fA j+df-L = 0. Similarly, we have 
fA f-dJ.L = 0. Therefore, fA fdJ.L = 0. This completes the proof. 
6.11. By hypothesis, J.L(A) = 0. Hence J.LU =/=- f Is\A) = 0 and J.LUn =/=- fnls\A) = 
0. Consequently, by Problem 6.9, J.L(f) = J.LU Is\A) and J.LUn) = J.LUnis\A)Â· By 
Theorem 6.2, J.LUnis\A) t J.LU Is\A)Â· Therefore, J.LUn) t J.L(/). 
6.12. By Problem 5.11, we may choose two sequences f n ( n ;:::: 1) and gn ( n ;:::: 1) 
of nonnegative simple functions on S such that fn t f and gn t g. Then we have 
o:fn + f3gn t o:f + (3g. But, by Problem 6.3, 
J.L(o:Jn + f3gn) = O:J.L(/n) + f3J.L(gn)Â· 
Therefore, by Theorem 6.2, we have 
J.L(o:f + (3g) = O:J.L(f) + f3J.L(g). 
6.13. By hypothesis, fn,g E (m~)+ andfn:::; gforn;:::: 1. Theng- fn E (m~)+. 
By Theorem 6.3, we have 
J.L(liminf(g- fn)) :S: liminf J.L(g- fn)Â· 
Noting that J.L(g) < oo, by Problem 6.12, we have 
J.L(g)- J.L(limsupfn) :S: J.L(g) -limsupJ.L(/n), 
which leads to 
J.L(lim sup fn) ;:::: lim sup J.LUn)Â· 
6.14. 
(a) Since his J.L-integrable, we have f(h+ + h-)dJ.L < oo. Noting that h+ IA :::; h+ 
and h- IA :::; h-, we have fA (h+ + h-)dJ.L = f(h+ IA + h- IA)dJ.L:::; f(h+ + 
h-)dJ.L < oo by definition. Hence hiA is J.L-integrable. 

72 
LEBESGUE INTEGRATION 
(b) Since 
the result follows. 
6.15. Suppose that JL( {I hi = oo}) > 0. Then fs lhidJL 2: OOJL( {I hi = oo}) = oo, 
which contradicts the hypothesis that h is JL-integrable. Hence h is finite a.e. 
6.16. Let A= {s: f(s) 2: E}. Then by Definition 6.5 and Problem 6.12, we have 
is JPdJL 
is (JP JA + JP fAc )dJL 
is JP JAdJL +is JP JAcdjL 
> i fPdJL 
> i EPdjL 
EPJL(A). 
The result follows by dividing EP on both sides of the above inequality. 
6.17. 
We first show that af + {Jg E L 1 (S, 1:, JL). Since, by hypothesis, f, g E 
L 1(S, I:,JL), we have 
JL(iaf + fJgl)::::: JL(Iallfl + lfJIIgl)::::: laiJL(Ifl) + lfJIJL(Igl) < oo. 
Therefore, af + {Jg is JL-integrable. 
Next, we show that 
JL(af + fJg) = aJL(f) + fJJL(g). 
(6.21) 
Let J;t = max(sgn(a)f, 0), J;; = max(- sgn(a)f, 0), gt = max(sgn(fJ)g, 0), 
and g(i =max(- sgn(fJ)g, 0), where 
{ 
1, 
if X> 0; 
sgn(x) = 
0, 
if x = 0; 
-1, ifx < 0. 
Then af = lal sgn(a)f = lalf;t - lalf;;, fJg = lfJI sgn(fJ)g = lfJigt - lfJig(i, 
and so, by Definition 6.4 and Problem 6.12, we obtain 
JL(af + fJg) 
JL(IaiJ;t- lalf; + lfJigt- lfJig(i) 
JL(IaiJ;t + lfJigt)- JL(Ialf; + lfJig(i) 
laiJL(f;t) + lfJIJL(gt) -laiJL(f;) -lfJIJL(g(i) 
laiJLU:t- J;) + lfJIJL(gt- g(i) 
JL(af) + JL(fJg). 

SOLUTIONS 
73 
Now we show that p,(af) = ap,(f). Let j+ = max(!, 0) and f- = max(- j, 0). 
If a 2': 0, then p,(af) = p,(aj+ - af-) = ap,(J+) - ap,(f-) = ap,(f). If 
a< 0, then p,(af) = p,( -af- - ( -aj+)) = -ap,(f-)- ( -a)p,(J+) = ap,(f). 
Similarly, we can show that p,(f3g) = f3p,(g). Therefore, Equation (6.21) is true. 
6.18. We first prove the "only if" part. Suppose that p,(lfn - fl) -+ 0. Note that 
which implies that 
lf.L(fn- f)l :S M(lfn- Jl). 
Therefore, p,(fn) -+ p,(f). 
Next, we prove the "if" part. Suppose that p,(fn) -+ p,(f). Since, by hypothesis, 
fn and fare nonnegative p,-integrable, Un- n- =max(-fn + j, 0) ::; f. Noting 
that f n -+ f, by Theorem 6.4, we have 
lim p,((fn- f)-)= p,(O) = 0. 
n-+oo 
Since 
we have p,((fn- J)+)-+ 0. Therefore 
lim M(lfn- Jl) = lim JL((fn- f)+)+ lim p,((fn- f)-)= 0. 
n---+ oo 
n---+ oo 
n--+ oo 
This completes the proof. 
6.19. 
We first prove the "only if" part. Suppose that p,(lfn- fl) -+ 0. Since 
lfni-IJI = lfn- f + fi-IJI :S lfn- fl + IJI-IJI = lfn- Jl and lfni-IJI = 
Ifni-If- fn + fnl 2': Ifni- (If- fnl +Ifni)= -lfn- Jl, llfni-IJII :S lfn- Jl, 
whichimpliesthatp,(llfnl-1!11)-+ 0. Therefore,p,(lfnl)-+ p,(IJI). 
Next, we prove the "if" part. Suppose that p,(lfnl) -+ p,(IJI). Then, by Fatou's 
lemma (see Theorem 6.3), we have 
and 
p,(f-) = p,(liminf J;)::; liminf p,(f,;:-). 
Therefore, by Problem 1.8, we have 
M(lfl) = p,(J+) + p,(f-) :S liminf(p,(f;t) + p,(f,;:-)) = liminf p,(lfnl) = M(IJI), 
which implies that p,(J+) = lim inf p,(f;t) and p,(f-) = lim inf p,(f;;). But, by 
Problem 1.8, we have 
limsupp,(f;t) + liminf p,(f,;:-) 
< limsup(p,(f;t) + p,(f,;:-)) 
limsupp,(lfnl) 
M(IJI) = M(IJ+I) + p,(lrD, 

74 
LEBESGUE INTEGRATION 
which implies that lim sup J-LU;t) = J-L(J+). Therefore, J-LU;t) ---+ J-L(J+). Similarly, 
we can show that J-L(f;;) ---+ J-L(f-). Thus, by Problem 6.18, we have J-L(IJ;t -
J+ I) ---+ 0 and J-L(IJ;; - f-1) ---+ 0. But 
J-L(Ifn- !I) 
J-L(IJ;t- J;;- t+ + rl) 
:::; 
J-L(IJ;t- t+l) + J-L(IJ;;- rl). 
Therefore, J-L(Ifn - fl) ---+ 0. This completes the proof. 
6.20. First, we consider the case when h = IB forB E B. In this case, we have 
J-L(h of)= { h(f(s))J-L(ds) = 
{ 
1J-L(ds) = J-LU E B), 
(6.22) 
J 
S 
}{fEB} 
and 
At(h) = l h(x)At(dx) = l1At(dx) = At(B). 
(6.23) 
Suppose that h o f E L 1 (S, L-, J-L). Then, from Equation (6.22), we have J-L(f E 
B) < oo. By the definition of At, At(B) = J-L(f E B), and so J-L(h of) = At(h). 
Therefore, At(h) < oo, and soh E L 1(R,B,At). Similarly, we can show that 
hof E L1(S,L-,J-L) ifh E L 1(R,B,At)Â· 
Next, we consider the case when h is a simple B-measurable function. By Prob-
lem 6.1, we can write h as 
n 
h= LbJBi, 
i=l 
where bi > 0 and Bi E B (i = 1, 2, ... , n) are pairwise disjoint. Then, by Problem 
6.3 and Equation (6.22), we have 
J-L(h 0 f) 
i=l 
n 
LbiJ-L(f E Bi), 
(6.24) 
i=l 
and 
At(h) =At (~ bJBi) = ~ 
biAt(IBJ = ~ 
biAt(Bi)Â· 
(6.25) 
Since, by definition of At, J-LU E Bi) = At(Bi), we have J-L(h of) = At(h). 
Therefore, h of E L 1(S, L-, J-L) if and only if hE L 1(R, .%, At). 
Next, we consider the case when his a nonnegative B-measurable function. Then, 
by Problem 5.11, there exists a sequence hn ( n ;::: 1) of simple functions such that 

SOLUTIONS 
75 
hn t h. Since hnof t hof andJL(hnof) = At(hn) forn?: 1, we have, by Theorem 
6.2, JL(hn of) t JL(h of) and At(hn) t At(h). Therefore, JL(h of) = At(h) and 
so that h of E L 1(S, E, J.L) if and only if hE Â£ 1 (R, $,At). 
Finally, we consider the case when h is a B-measurable function. Then h o f = 
h+ o f - h- o J, where h+ = max(h, 0) and h- = max( -h, 0). We have al-
ready shown that JL(h+ of) = At(h+) and JL(h- of) = At(h-). If h of E 
L 1(S, E, J.L), then h+ of and h- of are in L1(S, E, J.L). Accordingly, h+ and h-
are in Â£ 1 (R, B, A 1) and so is h. Similarly, we can show that h E Â£1 (R, B, A f) if 
hof E L 1 (S,E,J.L). 
This completes the proof. 
6.21. Let 9n = 2:::~ 1 hi. Since hn E (mE)+ for all n?: 1, we have 9n E (mE)+ 
for all n ?: 1. Since 9n t 2::::1 hi, the result follows from Theorem 6.2 and Problem 
6.17. 
6.22. 
(a) If Is hdJL = oo, then Is gndJL = oo for all n ?: 1 and Is gdJL = oo. If 
Is hdJL < oo, then his finite a.e. by Problem 6.15. Let A= {s E S: lh(s)l = 
oo }. Then J.L(A) = 0. Also we have 9n- h?: 0 on S\A and 9n- h t g- h on 
S\A. By Theorem 6.2, Is\A (gn- h)dJ.L t Is\A (g- h)dJ.L. Since JL(A) = 0, 
we have Is(9n- h)dJ.L t Is(g- h)dJ.L. Since Is hdJL is finite, the result follows 
from Problem 6.17. 
(b) From the assumption, we have Is -hdJL > -oo, -gn ?: -h for n ?: 1, and 
-gn t -g. Hence the result follows from part (a) of this proof. 
6.23. Let F ( t) and G ( t) be defined as 
F(t) =lot f(s)ds, 
G(t) =lot f(s)g(s)ds. 
Then by the assumption, we have 
:t [e-F(t)G(t)] = f(t)e-F(t)(g(t)- G(t))::; af(t)e-F(t)_ 
Integrating the first and the last terms in this equation gives 
e-F(t)Q(t) :S a ( 1 - e-F(t)) , 'it E [0, T], 
which leads to 
G(t) ::; a ( eF(t) - 1) . 
Again by the assumption, we have 
g(t) ::; a+ G(t) ::; aeF(t). 
This completes the proof. 

76 
LEBESGUE INTEGRATION 
6.5 
Bibliographic Notes 
In this chapter, we introduced Lebesgue integration. To construct the Lebesgue in-
tegral, we first deal with nonnegative simple functions, which are Borel measurable 
and take on only finitely many distinct values. Then we consider general nonnega-
tive measurable functions. Finally we define the integration for general measurable 
functions. For more information about Lebesgue integration, readers are referred 
to Williams (1991) and Ash and Doleans-Dade (1999). Lebesgue integration on the 
real line is introduced in many books on real analysis such as Wheeden and Zygmund 
(1977), Royden (1988), and Yeh (2006). 
The Lebesgue integration is more general than the Riemann integration (Royden, 
1988, Section 4.1 ). For a comparison of Lebesgue and Riemann integrals, readers 
are referred to Ash and Doleans-Dade (1999, Section 1.7). 

CHAPTER 7 
THE RADON-NIKODYM THEOREM 
The Radon-Nikodym theorem is a fundamental and important result in measure the-
ory and has important applications in modem probability theory. For example, the 
Radon-Nikodym theorem can be used to prove the existence of conditional expecta-
tions (Klenke, 2006). In this chapter, we present some concepts and results related 
to this theorem. 
7.1 
Basic Concepts and Facts 
Definition 7.1 (Signed Measure). A signed measure on a a-algebra is a set function 
J.t : I: --+ R that is countably additive: 
(a) J.t(0) = 0. 
(b) For any disjoint sets An E I:, n = 1, 2, ... , have 
Measure, Probability, and Mathematical Finance. 
77 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

78 
THE RADON-NIKODYM THEOREM 
Definition 7.2 (Absolute Continuity). Let (S, I:, 1-l) be a measure space and >. a 
signed measure on I:. The signed measure >. is said to be absolutely continuous with 
respect to f-l, denoted by>.Â« f-l, if and only if f-l(A) = 0 (A E I:) implies >.(A) = 0. 
Definition 7.3 (Equivalent Measures). Let f-l and >. be two measures defined on a 
measurable space (S, I:). The two measures are said to be equivalent, written as 
1-l "' >., if and only if 1-l Â« >. and >. Â« f-lÂ· 
Definition 7.4 (Singularity). Let /-li and f-l2 be two measures on a measurable space 
(S, I:). Let AI and >.2 be two signed measures on (S, I:). Let 1>-II and l>-21 be the 
total variations of >.I and >.2, respectively (see Theorem 7.2). The two measures /-li 
and f-l2 are said to be mutually singular, denoted by /-li l_ f-l2, if and only if there 
exists a set A E I: such that /-li (A) = 0 and f-l2(Ac) = 0. The two signed measures 
AI and >.2 are said to be mutually singular if and only if 1>-II l_ l>-2lÂ· The signed 
measure AI and the measure /-li are said to be mutually singular if and only if there 
exists a set A E I: such that /-li (A) = 0 and 1>-II (A) = 0. 
Theorem 7.1. Let (S, I:) be a measurable space and>. a countably additive extended 
real-valued set function on I:. Then the maximum and the minimum values of>. are 
attainable; that is, there exist sets C, D E I: such that 
>.(C)= sup{>.(A): A E I:}, 
and 
>.(D) = inf{>.(A) : A E I:}. 
Theorem 7.2 (Jordan-Hahn Decomposition). Let>. be a countably additive extended 
real-valued set function on a (>-algebra I:. Let >. + and >.- be set functions on I: 
defined as 
>.+(A)= sup{>.(B): BE I:, B ~A}, 
>.-(A)= -inf{>.(B): BE I:, B ~A}. 
Then >. + and >.- are measures on I: and >. = >. + - >.-. 
(7.la) 
(7.1 b) 
The measure >. + is the upper variation or positive part of>., the measure >.- is 
the lower variation or negative part of>., and the measure 1>-1 = >. + + >.- is the total 
variation of>.. 
Theorem 7.3 (Lebesgue Decomposition Theorem). Let (S, I:) be a measurable 
space and f-l a measure on I:. If>. is a (>-finite signed measure (i.e., 1>-1 is (>-finite), 
then >.has a unique decomposition as AI + >.2, where AI and >.2 are signed measures 
on I: such that AI Â« f-l and >.2 l_ f-l. 
Theorem 7.4 (Radon-Nikodym Theorem). Let (S, I:) be a measurable space and 1-l 
a (>-finite measure on I:. Suppose that >. is a signed measure on I: that is absolutely 
continuous with respect to f-lÂ· Then there exists a Borel measurable function g : S -+ 
R such that 
>.(A) = f-l(g; A)= i gdf-L, 
VA E I:. 

PROBLEMS 
79 
If h is another such function, then J-L(g -1- h) = 0. The function g is the Radon-
Nikodym derivative and is commonly denoted by 
or 
7.2 Problems 
dA 
g=-
dJ-L 
7.1. Let (S, ~) be a measurable space and A a countably additive extended real-
valued set function on~. Let D E ~such that A( An D) 2:: 0 and A(A n Dc) :::; 0 
for all A E ~. Show that A+(A) = A(A n D) and A-(A) = A(A n Dc) for all 
A E ~. where A+ and A- are as defined in Equation (7 .1 ). 
7.2. Let J-L1 be an arbitrary finite measure on B. Let J-L2 be a measure on B defined 
as follows: 
(A)= {J-L1(R), 
ifO E A; 
J-L2 
0, 
ifO rJ. A. 
Find the Jordan-Hahn decomposition of the signed measure A = /-Ll -
J-L2. 
7.3. Let (S, ~)be a measurable space and A be a signed measure on~. Suppose that 
A(A) < oo for all A E ~and that D E ~is a set on which A attains its maximum 
(see Theorem 7.1). Show that 
(a) A( An D) 2:: 0 and A( An Dc) :::; 0 for all A E ~. 
(b) A+(A) =A( An D) and A-(A) = -A(A n Dc) for all A E ~. 
7.4. Let (S, ~)be a measurable space. Let A, A1, and A2 be signed measures on~. 
Show that 
(a) IAI(A) = sup{I:~ 1 IA(Bi)l : B1, B2, ... , Bn are arbitrary disjoint measur-
able subsets of A, n = 1, 2, ... } , where I A I is the total variation of A (see 
Theorem 7.2). 
7.5. Let (S, ~) be a measurable space and J-L a measure on ~. Let A1 and A2 be 
signed measures on~. Show that 
(a) If A1 j_ J-L and A2 j_ J-L, then A1 + A2 j_ J-L. 
(b) If A1 Â« J-L, then IA1I Â« J-L. 
(c) IfiA1I Â«J-L,thenAl Â«J-L. 

80 
THE RADON-NIKODYM THEOREM 
(d) If .A1 Â« f.L and .A2 _l f.L, then .A1 _l .A2. 
(e) If .X1 Â« f.L and .X1 _l f.L, then .X1 = 0 (i.e., .X( A) = 0 for all A E I:). 
(f) If .A1 is finite, then .X1 Â« f.L if and only if lim~t(A)--to .A1 (A) = 0. 
7.6. Let P and Q be probability measures on a measurable space (0, Â§). Suppose 
that Q is absolutely continuous relative to P and let g = dQ/dP be the Radon-
Nikodym derivative. Show that P and Q are equivalent if and only if 
P{g > 0} = 1. 
7.3 Hints 
7.1. Follow the definitions of .X+ and .X-. 
7.2. Use the definition of .X+ and .X- in Equation (7 .1 ). 
7.3. 
Part (a) can be proved by using the method of contradiction. Part (b) can be 
proved by using the result of part (a) and the definition of upper and lower variations. 
7.4. Use the result of Problem 7.3 and the definition of I .XI to prove part (a). Then 
use the result of part (a) to prove part (b). 
7.5. Use the definition of singularity (Definition 7.4) and the result of Problem 7.4 
to prove part (a). Use the result of Problem 7.3 to prove part (b). Use the definition 
of I.X11 (see Theorem 7.1) to prove part (c). Use part (b) to prove part (d). Part (e) 
can be proved by using part (d). For part (f), we need to use the first Borel-Cantelli 
lemma (Theorem 2.2), the result of Problem 2.18, and the method of contradiction. 
7.6. 
Follow the definition of equivalent measures (Definition 7.3). To prove the 
necessity part, try to show that Q{g ::; 0} = 0. Use the result of Problem 6.8 to 
prove the sufficiency part. 
7.4 Solutions 
7.1. Let A E I:. Since AnD ~ A, we only need to show that .X( B) ::; .X( An D) 
for all B ~ A. Using the assumption, we have .X( B) = .X(B n D) + .X(B n De) ::; 
.X(B n D)::; .X(B n D)+ .X((A\B) n D)= .X( An D). Hence V(A) =.X( An D). 
Similarly, we can show that .X- (A) = .X(A n De). 
7.2. First let us calculate the measure .x+. By definition, we have 
.x+(A) = sup{.A(B): BE B, B ~A} 

SOLUTIONS 
81 
for all A E B. Note that 
>.(B)= {J.L1(B)- 111(R), 
ifO E B; 
/11(B), 
ifO ~B. 
we have).. +(A) = 111 (A\ {0}) for all A E B. Similarly, we have)..- (A) = 111 (R)-
111 ( { 0}) if 0 E A and ).. - (A) = 0 if 0 ~ A. 
7.3. 
(a) Suppose that >.(An D) < 0 for some A E ~- Note that >.(D) = >-.(DnA) + 
>-.(DnA c). By the assumption that).. is bounded above, we have >.(DnA c) = 
>.(D) - >-.(DnA) > >.(D). However, this contradicts the assumption that D 
is a set on which).. attains its maximum. Hence >.(An D) ~ 0 for all A E ~Â­
Similarly, we can show that >.(An De) :::; 0. 
(b) Let A E ~- To show that >.+(A) = >.(An D), we only need to show that 
>.(B) :::; >.(An D) for all B ~ A and B E ~- In fact, by the result of part 
(a), we have >.(B) = >-.(B n D) + >-.(B n De) :::; >-.(B n D) :::; >-.(B n D) + 
>-.((A\B) n D)= >.(An D). Similarly, we have >.-(A)= ->.(An De). This 
completes the proof. 
7.4. 
(a) Noting that)..=)..+ -)..-and 1>-.1 is a measure, we have 
n 
n 
L I>. +(Bi)-)..- (Bi)l :::; L >-.+(Bi) +)..- (Bi) 
i=1 
i=1 
n 
2:::1>-.I(Bi) 
i=1 
n 
1>-.I(U Bi) 
i=1 
< 
1>-.I(A). 
By Problem 7.3, there exists a set D E ~such that >.+(A) =>.(An D) ~ 0 
and >.-(A)= ->.(An De)~ 0. Hence 
1>-.I(A) 
>.+(A)+ >.-(A) 
>.(An D)- >.(An De) 
i>-.(A n D) I+ i>-.(A n De) I. 
Since 2::~= 1 1>-.(Bi)l is bounded above by 1>-.I(A) and can reach 1>-.I(A) for some 
Bi, the result follows. 

82 
THE RADON-NIKODYM THEOREM 
(b) Let A E ~be an arbitrary set. By part (a) of this problem, we have 
n 
i=l 
are arbitrary disjoint measurable subsets of A, n = 1, 2, ... } 
n 
i=l 
are arbitrary disjoint measurable subsets of A, n = 1, 2, ... } 
n 
i=l 
are arbitrary disjoint measurable subsets of A, n = 1, 2, ... } 
IAli(A) + IA2I(A). 
Since A is arbitrary, the result follows. 
This completes the proof. 
7.5. 
(a) Since A1 ..l fl and A2 ..l fl, we have fl(A) = fl(B) = 0 and IA1I(Ae) = 
IA2 1 (Be) = 0 for some A E ~ and B E ~. Noting that fl is a measure, we 
have 0 :S: fl(A U B) :S: fl(A) + fl(B) = 0, which implies that fl(A U B) = 0. 
By Problem 7.4 and noting that IA1 + A2l, IA1I, and IA21 are measures, we have 
0 :s; IAl + A21((A u Bn = IAl + A21(N n Be) :s; IAli(Ac n Be)+ IA2I(Ac n 
Be) :S: IA1I (A c)+ IA2I (Be) = 0, which implies that IA1 + A2l ((AU B)c) = 0. 
Hence A1 + A2 ..l fl. 
(b) Let fl(A) = 0. By Problem 7.3, we have Xt = A1 (An D) and X[ = A1 (An 
De) for some set D E ~. where At and A2 are the upper variation and lower 
variation of A1, respectively. Since AnD <;;;; A, we have fl( AnD) = 0. By the 
assumption that A1 Â« fl, we have A1 (An D) = 0. Hence At Â« fl. Similarly, 
we have A[ Â«fl. Hence IA1I Â«fl. 
(c) Let fl(A) = 0. Then IA1I(A) = 0. Noting that IA11 = At + A[, we have 
At(A) = 0 and A[(A) = 0. Thus A1(A) = At(A)- A[(A) = 0. Therefore, 
Al Â« fL. 
(d) By assumption, we have fl(A) = IA2I(Ac) = 0 for some A E ~. By part (b) 
of this problem and the assumption that A1 Â« fl, we have IA11 Â« fl. Thus 
IA1I(A) = 0. Hence A1 ..l A2. 
(e) By part (d) of this problem, we have A1 ..l A1, which implies that IA1I(A) = 
IA1I(Ac) = 0 for some A E 
~. Therefore, IA1I(S) = 0. It follows that 
At (S) = A[ (S) = 0. Hence A1 (B) = 0 for all B E ~. 

BIBLIOGRAPHIC NOTES 
83 
(f) First we prove the "if' part. Suppose that JL(A) = 0 and 
lim 
.A1 (B) = 0. 
!L(B)-tO 
We need to show that ,\1 (A) = 0. To do this, we let Bn = A for n = 1, 2, .... 
Then by assumption we have A1 (A) = lim!L(Bn)-+O ,\1 (Bn) = 0. Hence ,\1 Â« 
JL. 
Then we prove the "only if' part. Suppose that ,\1 Â« JL. We need to show that 
lim!L(B)-+O .A1(B) = 0. Since I.A1(B)I::; I.A1I(B) for all BEE, we only need 
to show that limn-too I.AII(An) = 0, where JL(An) -t 0 as n -too. To do this, 
we only need to show that lim sup I .Ail (An) = 0. If lim sup I .Ail (An) =f. 0, then 
there exists some E > 0 such that supi~j I.A1I(Ai) ~ 2E for all j ~ 1. Hence 
there are infinitely many An such that I.AII(An) ~E. Noting also that JL(An) -t 
0 as n -t oo, we can find a subsequence {Bn}n~l from {An}n~l such that 
JL(Bn) ::; 2-n and I.AII(Bn) ~ E. Then I::'=l JL(Bn) < oo. By Theorem 
2.2, we have JL(limsupBn) = 0. By part (b), we have I.A1I(limsupBn) = 0. 
However, I.AII(U~1 (Bi) ~ I.AII(Bj) ~ E for all j ~ 1. By Problem 2.18 
and the assumption that ,\1 is finite, we have I.AII(limsupBn) ~ E, which 
contradicts I.AII(limsupBn) = 0. Thus lim!L(B)-+0 I.AII(B) = 0. 
This completes the proof. 
7.6. First let us prove the necessity ("only if') part. Suppose that Q'"" P. Since 
0 ::; Q{g ::; 0} = J 
gdP ::; 0, 
{gS:O} 
we have Q{g ::; 0} = 0. By the assumption that Q'"" P, we have P{g ::; 0} = 0, 
which gives P{g > 0} = 1. 
Now we prove the sufficiency part. Suppose that P{g > 0} = 1. We need to 
show that P is absolutely continuous relative to Q. To do that, let A E Â§ such that 
Q(A) = 0. Note that 
Q(A) = { gdP = { 
gdP. 
jA 
JAn{g>O} 
Then by Problem 6.8, P(A n {g > 0}) = 0. Since P{g > 0} = 1, we have 
P(A n {g > 0}) = P(A) + P{g > 0}- P(A U {g > 0}) ~ P(A). 
Hence P(A) = 0. Since A is arbitrary, Pis absolutely continuous relative to Q. 
This finishes the proof. 
7.5 
Bibliographic Notes 
In this chapter, we introduced the Radon-Nikodym theorem. As a fundamental result 
in measure theory, the Radon-Nikodym theorem is presented and discussed in many 

84 
THE RADON-NIKODYM THEOREM 
textbooks such as Rudin (1970), Taylor (1973), Royden (1988), Ash and Doleans-
Dade (1999), Schilling (2005), Klenke (2006), and Capinski and Kopp (2007). The 
Jordan-Hahn decomposition (see Theorem 7.2) was used to develop the Radon-
Nikodym theorem, the proof of which is not presented in this chapter. One can 
find a proof in Ash and Doleans-Dade (1999, p65). 

CHAPTERS 
LP SPACES 
LP spaces are spaces of functions whose pth power is integrable. For functions in a 
LP space, we can define norms and metrics and study the convergence of sequences 
of functions. In this chapter, we introduce the concepts of LP spaces and some 
important inequalities for functions in the Â£P spaces. 
8.1 
Basic Concepts and Facts 
Definition 8.1 (LP Space). Let (S, E, f.L) be a measure space and p E (0, oo]. Then 
LP(S, E, f.L) is defined as 
LP(S, E, f.L) = {! : IJIP is p,-integrable} 
= {1: is IJIPdf.L < oo}, 
p E (O,oo), 
and 
L 00(S, E, f.L) = {!: f.L(Ifl > K) = 0 for some K E (0, oo)}. 
Measure, Probability, and Mathematical Finance. 
85 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

86 
LP SPACES 
Definition 8.2 (LP Norm). Let p E (0, oo] and f E LP(S, ~' JL). The norm off on 
LP(S, ~' JL) is defined as 
{Us IJIPdJL)min(p)' 
llfllp = 
sup{k: JL(Ifl > k) > 0}, 
ifO < p < oo; 
ifp = 00. 
When p = oo, the norm is called the infinite norm or the maximum norm. 
Definition 8.3 (Metric Space). LetS be a set and d: S x S---+ [0, oo] be a function. 
(S, d) is called a metric space if for all x, y, z E S, 
(a) (Symmetry) d(x, y) = d(y, x). 
(b) (Triangle inequality) d(x, y) ~ d(x, z) + d(y, z). 
(c) d(x, y) = 0 if and only if x = y. 
The function d( Â·, Â·) is called a metric on S. 
Definition 8.4 (Cauchy Sequence). Let ( S, d) be a metric space and { Xn }n> 1 be a 
sequence of elements of S. Then the sequence { Xn}n>l is called a Cauchy sequence 
in (S, d) if 
lim sup d(xn X 8 ) = 0. 
k---+oo r,s?_k 
Definition 8.5 (Completeness of Metric Spaces). A metric space (S, d) is considered 
complete if every Cauchy sequence in (S, d) converges to an element in S; that is, 
if { xn}n>l is a Cauchy sequence in (S, d), then there exists an element x in (S, d) 
such that 
lim d(xn, x) = 0. 
n---+oo 
Definition 8.6 (Equivalence Relation). Let S be a set. A relation "' is called an 
equivalence relation on S if 
(a) (Reflexive) X rv X for all X inS. 
(b) (Symmetry) X rv y implies y rv X. 
(c) (Transitive) X rv y andy rv z imply X rv z. 
Definition 8.7 (Equivalence Relation on LP Spaces). Let f, g E LP(S, ~' JL). f is 
considered equivalent to g, written as f "' g, iff = g a.e. The relation "' is an 
equivalent relation on the LP space (see Problem 8.7). 
Definition 8.8 (Metric on LP Spaces). For j, g E LP(S, ~' JL), 1 ~ p ~ oo, let 
dp(Â·, Â·)be defined as 
(8.1) 

BASIC CONCEPTS AND FACTS 
87 
where [!] and [g] denote the equivalence classes of functions containing f and g, re-
spectively. Then dp(Â·, Â·)is a metric on LP(S, E, J-L) and (LP(S, E, J-L), dp) is a metric 
space (see Problem 8.8). 
Definition 8.9 (Real Inner Product Space). A vector space Vis called a real inner 
product space if there exists a function f : V x V-+ R, denoted by f(x, y) = (x, y), 
such that 
(a) (x, y) = (y, x) for all x, y E V. 
(b) (ax+ by, z) = a(x, z) + b(y, z) for all a, bE Rand x, y, z E V. 
(c) (x, x) 2: 0 for all x E V and (x, x) = 0 if and only if x = (),the zero vector in 
v. 
The function ( Â·, Â·) is called the inner product. 
Definition 8.10 (Orthogonal Vector and Collection). Let (V, ( Â·, Â·)) be an inner prod-
uct space. Two vectors x, y E V are considered orthogonal, written as x .l y, if 
(x, y) = 0. A collection B <:;:; V is considered orthogonal if for x, y E B, x =f. y 
implies (x, y) = 0. 
Definition 8.11 (Inner product Space L 2 ). Let (S, E, J-L) be a measure space. Let the 
inner product on L 2(S, E, J-L) be defined as 
Then ( L2 ( S, E, J-L), ( Â·, Â·)) is a complete inner product space. 
Theorem 8.1 (HOlder's Inequality). Let (S, E, J-L) be a measure space. Let f E 
LP(S, E, J-L) and g E Lq(S, E, J-L), where 1 < p < oo and q = pf(p- 1). Then 
llfglll:::; ll!llpllgllq: 
is lfgldJ-L :::; (is IJIPdJ-L) i (is lglqdJ-L) ~ . 
(8.2) 
If llfgll1 =/=- 0, then the equality in (8.2) holds if and only if IJIP = clglq (a.e.) for 
some constant c E (0, oo ). 
Theorem 8.2 (Minkowski's Inequality). Let 1 < p < oo and J, g E LP(S, E, J-L). 
Then II!+ giiP :::; IIJIIP + llgiiP' specifically 
(is If+ giPdJ-L) i :::; (is IJIPdJ-L) i + (is lgiPdJ-L) i ' 
(8.3) 
and the equality in (8.3) holds if and only iff = >.g (a.e.) for some constant).. E 
(0, oo). 

88 
LP SPACES 
Theorem 8.3 (Schwarz's Inequality). Let J, g E Â£ 2(8, ~. JL). Then 
and 
Theorem 8.4 (Completeness of LP Spaces). For 1 ::::; p ::::; oo, (LP(8, ~. JL), dp) is 
complete, where dp is as defined in Equation (8.1 ). 
Theorem 8.5 (Orthogonal Projection). Let ( Â£ 2 ( 8, ~. /L), ( Â·, Â·)) be an inner product 
space and K a subspace of ( Â£ 2 ( 8, ~. /L), (-, Â·)) that is complete in that whenever 
{fn}n;::l is a Cauchy sequence inK, then there exists a function f E K such that 
llfn - Jll2 ---+ 0. 
Then, given X E Â£ 2(8, ~. JL), there exists a function Y E K such that 
IIX- Yll2 = inf{IIX- Wll2: WE K}, 
X- Y .l Z, 
VZ E K. 
(8.4) 
(8.5) 
Also, (8.4) and (8.5) are equivalent. IfY satisfies (8.4) or (8.5), then Y = Y (a.e.) 
The function Y is considered a version of the orthogonal projection of X into K. 
8.2 Problems 
8.1. Let 0 < a < 1 and fJ = 1 -a. Let x > 0 andy > 0. Show that 
xo:yf3 < ax+ fly. 
8.2. Prove HOlder's inequality in Theorem 8.1. 
8.3. Let a ~ 0, b ~ 0, and p ~ 1. Show that 
8.4. Prove Minkowski's inequality in Theorem 8.2. 
(8.6) 
8.5. Let (8, ~. JL) be a finite measure space [i.e., JL(8) < oo] and 1 ::::; p < r < oo. 
Show that Lr(8, ~. JL) <::;; Â£P(8, ~. JL). 
8.6. Let 0 < p ::::; oo. Let a, b E Rand f, g E Â£P(8, ~. JL). Then af + bg E 
Â£P(8, ~. JL). 
8.7. Let "'be a relation on Â£P(8, ~. JL) such that f "' g iff = g a.e. for J, g E 
Â£P(8, ~. JL). Show that"' is an equivalent relation. 

HINTS 
89 
8.8. For f, g E LP(S, E, J-L), 0 < p::; oo, let dp(Â·, Â·)be defined as 
where [f] and [g] denote the equivalence classes of functions containing f and g, 
respectively. Show that dp is a metric on LP(S, E, J-L). 
8.9 (Parallelogram Law). Let U, V E (L2(S, E, J-L), (Â·, Â·)).Show that 
IIU +VII~+ IIU- VII~ = 2IIUII~ + 2IIVII~-
8.10. Prove Theorem 8.4. 
8.11. Prove Theorem 8.5. 
8.3 Hints 
8.1. Consider the inequality z"' - 1 ::; a(z- 1) for a E (0, 1) and z ~ 1. 
8.2. Use the result of Problem 8.1. 
8.3. Consider the derivative of the following function 
8.4. Consider applying Holder's inequality (Theorem 8.1) to the functions Is If+ 
giP- 1 IfldJ-L and Is If+ giP- 1 1YidJ-L. 
8.5. Use HOlder's inequality (Theorem 8.1) and the definition of LP space (Defini-
tion 8.1). 
8.6. Consider the case when p E (0, oo) and the case when p = oo. 
8.7. Just follow the definition of an equivalence relation (Definition 8.6). 
8.8. Follow the definition of a metric (Definition 8.3). 
8.9. Follow the definition of the inner product in L2 space (Definition 8.9). 
8.10. 
Find a subsequence { nk}k~l such that Unk }k~ 1 converges a.e. to a limit 
function f. 
8.11. Consider a sequence {Yn}n~l inK such that 
IIX- Ynll2-+ inf{IIX- Wll2: WE K} 
and show that {Yn}n~l is a Cauchy sequence. 

90 
LP SPACES 
8.4 Solutions 
8.1. We first show, for a E (0, 1) and z ~ 1, that 
z"' - 1 :S: a(z- 1), 
(8.7) 
and the equality in (8.7) holds if and only if z = 1. To do this, consider the function 
<p(z) = a(z- 1) - z"' + 1. The derivative of this function is <p1 (z) = a(1 - z"'- 1 ). 
Since <p'(z) > 0 for z > 1, <p(z) is strictly increasing in (1, oo). Noting that <p(l) = 
0, we have <p(z) > 0 for z > 1. 
Now suppose that x ~ y (since x andy are symmetric, we can do tllis) and let 
z = xjy. Then 
which, after some algebraic manipulation, is 
x"'y13 :S: ax+ (3y, 
and the equality holds if and only if xjy = 1 or x = y. 
8.2. If f = 0 or g = 0, then both sides of (8.2) are equal to zero. If f ::/= 0 and 
g ::f. 0, then, by Problem 8.1, we have 
Therefore (8.2) follows from integrating botll sides of the above equation over S and 
the equality in (8.2) holds if and only if 
or IJIP = clglq (a.e.), where 
This completes the proof. 
8.3. Let 
Then 
Is lfiPd~-t 
c = Is lglqdf-t. 

SOLUTIONS 
91 
Note that f'(x) = p[(a + x)P-1 - (2x)P-1]. Hence 
{ 
> 0 if 0 ::::; x < a; 
f'(x) 
= 0 ifx =a; 
< 0 ifx >a, 
which implies that f(x) is maximized at x =a. Therefore 
f(b) =(a+ b)P- 2P- 1(aP + bP)::::; f(a) = 0. 
This completes the proof. 
8.4. Iff+ g = 0, then (8.3) is true. Suppose that f + g =f. 0 and let q = pf(p- 1). 
Then (p- 1)q = p and, by Theorem 8.1, we get 
1 
1 
is If+ glp-1lfldJL::::; (is IJIPdJL)" (is If+ giCp-1)qdJL) â¢ 
= (is lfiPdJL) f; (is If+ giPdJL) * , 
(8.8) 
and, similarly, 
Thus we have 
is If+ giPdJL::::; is If+ giP-1(1!1 + lgl)dJL 
1 
(8.10) 
::::; (is If+ giPdJL) q (IIJIIP + llgllp). 
Dividing (8.10) by (f8 If+ giPdJL)i gives (8.3). In addition, the equality in (8.3) 
holds if and only if the equalities in Equations (8.8)-(8.10) hold. Therefore If+ gl = 
IJI + lgl (a.e.) and, by Theorem 8.1, If+ giP = If+ gl(p-1)q = c1IJIP = c2lgiP 
(a.e.) for some constants c1, c2 E (0, oo ). Accordingly, f = >..g (a.e.) for some 
).. E (0, oo). 
8.5. 
Since p < r, rjp > 1. Let q = r/(r- p). Then 1/(r/p) + 1/q = 1. Let 
f E U(S, E, JL). Then, by Theorem 8.1, we obtain 
Noting that JL(S) < oo and f E U(S, E, JL), we have 
is lfiPdJL < 00. 

92 
LP SPACES 
Thus f E LP(S, 'E, J.L). This completes the proof. 
8.6. First, we consider p E ( 0, oo). Then 
laf + bgiP ::::; (iafl + lbgi)P 
::::; [2max(iafl, lbgi)]P 
::::; 2P(iafiP + lbgiP) 
= l2aiPIJIP + I2WigiP. 
The result follows by integrating the above equation. 
Next, we consider p = oo. By definition, there exist constants K 1 < oo and 
K2 < oo such that J.L(Ifl > Kl) = 0 and J.L(Igl > K2) = 0. Then J.L(iaf + bgl > 
k)::::; J.L(iafl+lbgl > K)::::; J.L(Ifl > Kl)+J.L(Igl > K2) = Ofor K > !aiKI+IbiK2. 
Hence af + bg E U)0 (S, 'E, J.L). 
8.7. 
Since J.L(f -1- f) = J.L(0) = 0 for f E LP(S, 'E, J.L), f "' f. Iff "' g, then 
J.LU -1- g) = 0. But J.L(g -1- f) = J.LU -1- g) = 0. Hence g rv f. Suppose that 
f "'g and g"' h for j, g, hE LP(S, 'E, J.L). Then J.L(f -1- g) = 0 and J.L(g -1- h) = 0. 
Since {f = g} n {g = h} ~ {f = h}, {f -1- h} ~ {f -1- g} U {g -1- h}, and so 
J.LU -1- h) ::::; J.LU -1- g) + J.L(g -1- h) = 0. Hence f rv h. Thus rv is an equivalent 
relation. 
8.8. 
Since functions in an equivalence class are equivalent, dp is well defined. 
Since dp([f], [g]) = llf - giiP = llg - fliP = dp([g], [!]), symmetry holds. Let 
j, g, h E LP(S, 'E, J.L). Since 
II!- glh =is If- gldJ.L::::; is (If- hi+ lg- hl)dJ.L =II!- hll1 + llg- hll1, 
and, by Theorem 8.1, 
II!- gllp ::::; II!- hllp + llg- hllp, 
P > 1, 
we have dp([f], [g]) ::::; dp([f], [h]) + dp([g], [h]). Suppose that dp([f], [g]) = 0. 
Then, by Problem 6.8, f = g a.e. and so [!] = [g]. Suppose that[!] = [g]. Then 
f = g a.e. and so dp([j], [g]) = llf - giiP = 0. Therefore, dp is a metric on 
LP(S, 'E, J.L). 
8.9. By definition of the inner product, we obtain 
IIU +VII~+ IIU- VII~ 
=(U + V, U + V) + (U - V, U - V) 
=(U, U) + 2(U, V) + (V, V) + (U, U) - 2(U, V) + (V, V) 
=2IIUII~ + 2IIVII~Â· 
8.10. 
Let {fn}n~I be a Cauchy sequence in (LP(S, 'E, J.L), dp)Â· We need to show 
that there exists a function f E (LP(S, 'E, J.L), dp) such that 
lim llfn -fliP = 0. 
n--+oo 

SOLUTIONS 
93 
First, we show that there exists a subsequence {nk}k;:::l such that Unkh2:1 con-
verges (a.e.) to a limit function f. To do this, let Ek = 2-(p+l)k and 8k = 2-k for 
k 2:: 1. Since Un}n;:::l is a Cauchy sequence, for each k 2:: 1, there exists an integer 
nk such that 
is lfr - fs I Pdp, < Ek, 
for all r, s 2:: nk. 
Let Ak = {lfnk+l - fnk I 2:: 8k} fork 2:: 1. Then 
p,(Ak) = { 1dp, 
jAk 
~ rfk,P { 
lfnk+l - fnk IPdp, 
}Ak 
~ 8/? is lfnk+l - fnk IPdp, 
< bkpfk = Tk, 
k 2:: 1, 
(8.11) 
which implies L:~=l p,(Ak) < oo. By Theorem 2.2, p,(A) = 0, where A = 
limsupAk. Then for s E Ac, there exists an integer ks such that s E Ak for all 
k 2:: k 8 , and so 
Thus {fnk (s)}k;:::1 converges in R. Let 
Then we have 
Next, we show that 
lim fnk = f 
a.e. 
k-+oo 
lim llfnk -fliP = 0. 
k-+oo 
By Theorem 6.3 and (8.11), we have 
(8.12) 
is lfnk- fiPdp, ~ liminf is lfnk- fnk+jiPdp, < Ek, 
k 2:: 1. 
(8.13) 
Thus fnk - f E LP(S, E, p,). Since fnk E LP(S, E, p,), by Problem 8.6, f E 
LP(S, E, p,). The result in (8.12) follows by letting k--+ oo in (8.13). 
Next, we show that 
lim llfn -fliP = 0. 
n-+oo 
(8.14) 
By triangle inequality (see Problem 8.8), Equations (8.11) and (8.13), we have 
1 
llfn- fliP ~ lfn - fnk liP+ llfnk -fliP < 2E~, 
n 2:: nk. 

94 
LP SPACES 
The result in (8.14) follows by letting k ---+ oo in the above inequality. This completes 
the proof. 
8.11. Let {Yn}n;::1 be a sequence inK such that 
where .6. = inf{IIX- Wll2 :WE K}. Then by Problem 8.9, we have 
Since ~(Yr + Ys) E K, IIX- ~(Yr + Ys)ll2 2 .6.. Let E > 0. Choose N, EN such 
that 
Then for r, s 2 N,, we have 
which gives II ~(Yr - Ys) ll2 < E. Thus {Yn}n;::l is a Cauchy sequence inK. Since 
K is complete, there exists a Y E K such that 
llYn - Yll2 ---+ 0. 
Since, by Theorem 8.2, IIX- Yll2 ~ IIX- Yn ll2 +llYn- Yll2, we have IIX- Yll2 = 
.6.. 
Now we show that Equations (8.4) and (8.5) are equivalent. Suppose that Y E K 
satisfies IIX- Yll2 = .6.. Then for any Z E K, we have Y + tZ E K fort E R. 
Thus IIX - Y - tZII2 2 IIX - Yll2Â· Note that IIX - Y- tZII~ = IIX -
Yll~ -
2t(X- Y, Z) + t 2 IIZII~, we have 
-2t(X- Y, Z) + t2 IIZII~ 2 0, 
t E R. 
Therefore (X - Y, Z) = 0. Suppose that Y satisfies (8.5), that is, X - Y .l Z for 
all Z E K. Then for any Z E K, we have Y - Z E K, and so (X - Y, Y - Z) = 0. 
Thus 
IIX- Zll~ = IIX- Yll~ + IIY- Zll~ 2 IIX- Yll~, vz E K, 
which gives (8.4). 
If Y, Y E K satisfy (8.5), then 
(X- Y, Z) = 0, 
(X- Y, Z) = 0, vz E K, 
and so (Y-Y, Z) = 0 for all Z E K. Since Y- Y E K, we have (Y-Y, Y- Y) = 
0, which implies Y = Y a.e. This completes the proof. 

BIBLIOGRAPHIC NOTES 
95 
8.5 Bibliographic Notes 
In this chapter, we introduced basic concepts of Â£P spaces and some inequalities such 
as the HOlder's inequality, Minkowski's inequality, and Schwarz's inequality. LP 
spaces are covered by books on functional analysis, measure theory, and probability 
theory. For example, readers can find more information on Â£P spaces in Williams 
(1991), Ash and Doleans-Dade (1999), Athreya and Lahiri (2006), and Capinski and 
Kopp (2007). 


CHAPTER 9 
CONVERGENCE 
In measure theory, there exist several different notions of convergence of measurable 
functions, for example, convergence almost everywhere, convergence in measure, 
convergence in Â£P, to just name a few. In this chapter, we present definitions of 
some common notions of convergence. 
9.1 
Basic Concepts and Facts 
Definition 9.1 (Convergence in Measure). Let J, JI, h, Â· Â· Â· be Borel measurable 
functions on a measure space (S, I;, f.L). The sequence {fn}n>l is said to converge 
to f in measure, written as f n 4 f, if and only if for every E > 0, f.L{ 8 : If n ( 8) -
f(8)1 ~ â¬}--+ 0 as n--+ oo. 
In particular, if f.L is a probability measure, then convergence in measure is also 
referred to as convergence in probability. 
Definition 9.2 (Convergence in Â£P). Let f be a Borel measurable function on a 
measure space (S, I;, f.L) and {fn}n~l a sequence of of functions in LP(S, I;, f.L). 
Measure, Probability, and Mathematical Finance. 
97 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

98 
CONVERGENCE 
The sequence Un}n>l is said to converge to fin LP, written as fn ~ 
f, if and 
-
1 
only if llfn- fliP-+ 0 as n-+ oo, where llfn- fliP= (f8 lfn- fiPdp,) 1i. 
Definition 9.3 (Uniform Convergence). Let f, fl, h, ... be Borel measurable func-
tions on a measure space (S, E, p,) and B E E. The sequence {fn}n>l is said to 
converge to f uniformly on B if and only if for every E > 0, there exists an N E N 
such that lfn(s)- f(s)i < E for all s E Band n 2:: N. 
Definition 9.4 (Almost Uniform Convergence). Let f, fl, h, ... be Borel measur-
able functions on a measure space (S, E, p,). The sequence {fn}n>l is said to con-
verge to f almost uniformly if and only if for a given E > 0, there is a set A E E 
such that p,(A) < E and fn -+ f uniformly on A c. 
Definition 9.5 (Almost Everywhere Convergence). Let f, h, h, ... be Borel mea-
surable functions on a measure space (S, E, p,). The sequence Un}n2;:l is said to 
converge to f almost everywhere, written as f n ~ 
f, if and only if there is a set 
A E E such that fn-+ f on A and p,(Ac) = p,(S\A) = 0. 
Definition 9.6 (Uniform Integrability). Let {fihEI be a collection of Borel measur-
able functions on the measure space (S, E, p,), where p, is finite and I is an index set 
(countable or uncountable). The fi are said to be uniformly integrable if and only if 
lim sup r 
lfildp, = 0. 
c-+oo iEJ }{lfil2::c} 
Theorem 9.1 (Weierstrass M-Test). Let {fn}n2;:l be a sequence of Borel measurable 
functions defined on a set A. Suppose that there exist positive constants Mn such that 
and the series L~=l Mn converges. Then the series L~=l fn converges uniformly 
on A. 
9.2 
Problems 
9.1. Letp E (0, oo). Iff, fl, h, ... E LP(S, E, p,), then fn ~ 
f implies fn .!!:.t f. 
9.2. Let (S, E, p,) be a measure space and f, fl, h, ... E mE. Suppose that fn-+ f 
almost uniformly. Show that f n -+ f in measure and almost everywhere. 
9.3. Let (S, E, p,) be a measure space and f, h, h, Â· Â· Â· E mE. Given p, finite, show 
that f n -+ f almost everywhere if and only if for every J > 0, 
J-t CQn {s: ifk(s)- f(s)i 2:: J}) -+ 0 as n-+ oo. 

PROBLEMS 
99 
9.4 (Egoroff's Theorem). Let (S, I:, J.L) be a measure space and f, h, h, ... E mi:. 
Suppose that J.L is finite and fn --+ f a.e. Show that fn --+ f almost uniformly. 
9.5. Let (S,I:,J.L) be a measure space and f,g,h,Jz, ... E mi:. Suppose that 
fn ~ f and fn ~g. Show that f = g a.e.[i.e., J.LU =1- g) = 0]. 
9.6. Let (S, I:, J.L) be a measure space and f, h, h, ... E mi:. Suppose that fn ~ 
f. Show that 
(a) There is a subsequence converging almost uniformly to f. 
(b) There is a subsequence converging to f a. e. 
9.7. Let (S, I:, J.L) be a measure space and h, fz, ... E mi:. Show that 
lim fn 
n---+oo 
exists a.e. if and only if fJ - fk --+ 0 as j, k --+ oo a.e, that is, for each E > 0, 
9.8. Let (S, I:, J.L) be a measure space and h, fz, Â· Â· Â· E mi:. Show that 
lim fn 
n---+oo 
exists a. e. if and only if for each E > 0, 
9.9. Let {fn : n ~ 1} be a sequence of measurable functions on a finite measure 
space (S, I:, J.L) such that for every n ~ 1, 
where C < oo is a constant. Show that {fn : n ~ 1} is uniformly integrable. 
9.10. Let (S, I:, J.L) be a finite measure space and h, Jz, ... uniformly integrable 
functions on (S, I:, J.L). Show that 
(a) 
Is liminf fndJ.L :S: liminf Is fndJ.L :S: lim sup Is fndJ.L :S: Is lim sup fndJ.L. 
(9.1) 

100 
CONVERGENCE 
(b) If fn ~ 
f, then f is JL-integrable and 
(9.2) 
(c) If fn ~ f, then f is JL-integrable and 
(9.3) 
9.11. Let {fn}n>l be a sequence of Borel measurable functions on the measure 
space (S, E, JL), where J-l is finite. Show that {fn}n>l are uniformly integrable if 
and only if the integrals .[8 lfnldJL are uniformly boun-ded, that is, 
for some M > 0, and uniformly continuous: 
sup { lfnldJL--+ 0 as 
JL(A)--+ 0. 
n }A 
9.12. Let (S, E, JL) be a finite measure space and 0 < p < oo. Let Un}n>l be a 
sequence of Borel measurable functions. Assume that fn ~ f and the lfniP are 
uniformly integrable. Show that 
Â£P 
fn --+ f 
as 
n --+ oo. 
9.13. Let /i, i E J, be integrable functions on a finite measure space (S, E, JL). Let 
h : [0, oo) --+ [0, oo) be a Borel measurable function such that 
Show that if 
h(t)--+ oo 
as 
t--+ oo. 
t 
sup r h(lfil)dJL < oo, 
iEJ ls 
then the fi are uniformly integrable. 
Â£P 
9.14. Let 0 < p < oo and f, h, /2, ... E LP(S, E, JL). Assume that fn --+ f and J-l 
is finite. Show that the If niP are uniformly integrable. 
9.3 
Hints 
9.1. Follow the definition of convergence LP and convergence in measure and use 
Chebyshev's inequality (see Problem 6.16). 

HINTS 
101 
9.2. 
Follow the definition of almost uniform convergence (see Definition 9.4), 
convergence in measure (see Definition 9.1), and almost everywhere convergence 
(see Definition 9.5). 
9.3. Follow the definition of convergence almost everywhere (see Definition 9.5). 
9.4. Use the result of Problem 9.3. 
9.5. Use the definition of convergence in measure (see Definition 9.1) and the fact 
that 
1 
1 
1 
{s: lf(s)-g(s)l ~ -;;;} ~ {s: lfn(s)-f(s)l ~ 2k}U{s: lfn(s)-g(s)l ~ 2k}. 
9.6. 
To prove part (a), first show that {fn}n;::l is Cauchy in measure; that is, for 
every E > 0, 
lim sup JL{IIJ- fkl 2: E} = 0. 
n---+oo j,k;::n 
Then use the result of Problem 9.5 to show that the limit of the subsequence is equal 
to f a.e. 
9.7. Use the result of Problem 9.3. 
9.8. Use the result of Problem 9.7. 
9.9. Follow the definition of uniform integrability (see Definition 9.6). 
9.10. Part (a) can be proved by Fatou's lemma (see Theorem 6.3) and the definition 
of uniformly integrability (see Definition 9.6). Try to establish 
is lim inf f n dJL :S lim inf is f n dJL + E. 
Parts (b) and (c) can be proved by part (a) and the result of Problem 9.6. 
9.11. 
The "if" part can be proved by Chebyshev's inequality (see Problem 6.16). 
The "only if" part can be proved by following the definition of uniform integrability 
(see Definition 9.6). 
9.12. First use the result of Problem 9.11 to show that the lfn- JIP are uniformly in-
tegrable. Then use the result of Problem 9.10 to show that the subsequence converges 
to fin Â£P. 
9.13. Use the definition of uniform integrability (see Definition 9.6). 
9.14. Use the results of Problems 8.3 and 9.11. First try to establish that lfn- JIP 
is uniformly integrable. 

102 
CONVERGENCE 
9.4 Solutions 
9.1. Let E > 0. Then by Problem 6.16, we have 
tt{s: lfn(s)- f(s)l ~ E}:::; ~ r lfn(s)- f(s)IPdft. 
E ls 
By assumption, we have fs lfn(s) - f(s)IPdtt -+ 0 as n -+ oo. Thus we have 
tt{s: lfn(s)- f(s)l ~ E}-+ 0 as n-+ oo. This completes the proof. 
9.2. First, we show that fn -+ fin measure. Let E > 0. By definition, we only need 
to show that tt{s: lfn(s)- f(s)l ~ E}-+ 0 as n-+ oo. To do this, we only need to 
show that for every k > 1, there exists an integer Nk such that 
1 
tt{s: lfn(s)- f(s)l ~ E} < k 
for all n ~ Nk. By assumption that fn -+ f almost uniformly, for every k > 1 
there exists a set Ak E :E such that fn -+ f uniformly on Ak and tt(Ak) < 1/k. By 
Definition 9.3, there exists an Nk such that lfn(s)- f(s)l <Eon Ak for all n ~ Nk. 
Hence the result follows since tt{s: lfn(s)- f(s)l ~ E} = tt(Ak) < 1/k for all 
n~Nk. 
Next, we show that fn -+ f almost everywhere. Let Ak (k ~ 1) be the sets 
mentioned in the first part of this proof and B = U%':1 Ak. Then fn -+ f on B. 
Noting that tt(Bc) = tt(n%':1 Ak) :::; tt(Ak) < 1/k, we have tt(Bc) = if we let 
k -+ oo. Hence f n -+ f almost everywhere. 
9.3. First, we prove the "if" part. Suppose that for every 8 > 0, 
ft CQn {s: lfk(s)- f(s)l ~ 8}) -+ 0 as n-+ oo. 
Let Am = n~=1 U%:n{s: lfk(s)- f(s)l ~ 1/m} form= 1, 2, .... Then we 
have tt(Am) = 0 for all m ~ 1. Now let A = U:=1 Am. Then 0 :::; tt(A) :::; 
2::=1 tt(Am) = 0, implying that tt(A) = 0. The result follows if we show that 
fn-+ f on A c. To do this, JetE> 0 and tEA c. Then tEA;, for all m ~ 1. Hence 
t E A~, where r E Nand r > 1/E. Therefore, t E n%:nr {s : lfk(s)- f(s)l < 
1/r < E} for some nr ~ 1, which means that lfk(t) - f(t)l < E for all k ~ nr. 
Since E and t are arbitrary, we have f n -+ f on A c. 
Now we prove the "only if' part. Suppose that fn -+ f almost everywhere. Then 
there exists a set A E :E such that tt(A) = 0 and fn -+ f on A c. Let 8 > 0. Then 
for every t E Ac, there exists an integer Nt,i5 such that lfk(t) - f(t)l < 8 for all 
k ~ Nt,i5Â· Hence t E U~ 1 n%:n{s: lfk(s)- f(s)l < 8}. Since tis arbitrary, 
we have Ac <;;; U~= 1 n~=n{s: lfk(s)- f(s)l < 8}. Noting that tt is finite, we 
tt(S) ~ tt(U~= 1 n%:n{s: l!k(s)- f(s)l < 8}) ~ tt(Ac) = tt(S)- tt(A) = 
tt(S), implying that tt(U~=1 n~=n{s: l!k(s)- f(s)l < 8}) = tt(S). Therefore, 
tt(n~= 1 U%':n{s: lfk(s)- f(s)l ~ 8}) = 0. ButU~=n{s: lfk(s)- f(s)l ~ 8} -1-

SOLUTIONS 
1 03 
n~=l U~=n{s: lfk(s)- f(s)l :2: J} as n-+ oo. The result follows from Problem 
2.18. 
9.4. Since J.L is finite and fn -+ f a.e., by Problem 9.3 we have for every J > 0, 
J.L CQn {s: lfk(s)- f(s)l :2: J}) -+ 0 
as n-+ oo. 
Let E > 0. Then for every m :2: 1, there exists an integer Nm such that J.L(Am) < 
E/2m, where 
00 
1 
Am= U {s: lfk(s)- f(s)l :2: m}. 
k=N-m 
Define A= U:=l Am. Then J.L(A) < E. 
Now we show that fn -+ f uniformly on A c. To do this, let() > 0. Choose mo 
such that ( 1 / mo) < (). Then for all m :2: N mo and s E A c, we have If m ( s) - f ( s) I < 
....!... <().Hence fn-+ f uniformly on A c. This completes the proof. 
mo 
9.5. Let E > 0. Note that 
00 
1 
{s: f(s) -::J g(s)} = U {s: lf(s)- g(s)l :2: k}. 
k=l 
Since lf(s)- g(s)l ~ lfn(S)- f(s)l + lfn(s)- g(s)l, we have 
1 
1 
1 
{s: lf(s)-g(s)l :2: k} ~ {s: lfn(s)-f(s)l :2: 2k}U{s: lfn(s)-g(s)l :2: 2k}. 
By assumption, for every k :2: 1, there exists an integer Nk such that J.L{ s : lfn(S)-
f(s)l :2: A} < zk'+, and J.L{s : lfn(S)- g(s)l :2: 21k} < zk'+l for all n :2: Nk. 
Then we have J.L{s: lf(s)- g(s)l :2: -!-}<~-Therefore, J.LU -::J g)~ L::~=l J.L{s: 
lf(s)- g(s)l :2: -!-} <E. Since E is arbitrary, we have J.LU -::J g)= 0. This completes 
the proof. 
9.6. 
(a) First we show that Un}n>l is Cauchy in measure. Let E > 0 and TJ > 0. Since 
fn _!!:_, f, we have 
{ 
â¬} 
TJ 
. 
J.L IIi -!I :2: 2 < 2' 
't!] :2: N,, 
where N"' is some integer. Then for all j, k :2: N"', we have 

104 
CONVERGENCE 
Hence {fn}n;:>l is Cauchy in measure. Then for each positive integer k, we can 
choose an integer N k such that N k+ 1 > N k and 
Let gk =iNk' k = 1, 2, .... Then 
1L { jgk ~ gk+ll :;:, 2~} < 21k, 
k :;:, 1. 
Let A = lim sup Ak. where Ak = { jgk ~ gk+ 1 j :;:. 1 /2k}. Then by Theorem 
2.2, we have IL(A) = 0. 
If 8 Â¢c A, then 8 E Ak for only finitely many k. Hence 8 Â¢c Ak fork :;:. M 8 for 
some M 8 â¢ Therefore, jgk(8) ~ gk+1(8)j < 1/2k fork:;:. M 8 â¢ Thus {gk(8)}k;:>l 
converges to a limit g(8). Since IL(A) = 0, we have gk ~g. 
Now we show that gk converges tog almost uniformly. Let o > 0 and Bn = 
U%':n Ak. Then we can choose a large integer r such that 
00 
1 
IL(Br) $ L IL(Ak) = 2r-l < 0Â· 
k=r 
By Theorem 9.1, gk converges tog uniformly. Since o is arbitrary, gk converges 
to g almost uniformly. 
By assumption, we have fn ~ f. Hence gk ~ f. By Problem 9.2, we have 
gk ~g. Thus, by Problem 9.5, we have f = g a.e. 
(b) This part follows from part (a) and Problem 9.2. 
9.7. First let us prove the "if" part. Suppose that, for each E > 0, we have 
Let TJ > 0 and o > 0. Then there exists an N,7 such that 
Let f = lim sup fnÂ· Now we consider the following set: 
00 
A= U {lfk ~ fl :;:. o}. 
k=N,1 

SOLUTIONS 
1 05 
We claim that 
To show that, let s E A. Then there exists an integer ko ~ N,., such that I lko ( s) -
f(s)l ~ 8. Note that f = lim sup fnÂ· There exists an integer jo ~ N.,., such that 
lfj0 (s)- f(s)l < 8/2. Thus, we have 
which implies that s E Uj,k~N, {IIJ - lkl ~ 8/2}. Since sis arbitrary, we have 
A~ Uj,k~N, {IIJ- fkl ~ n. Therefore, we have 
Since 8 and ry are arbitrary positive numbers, fn ~ 
f by Problem 9.3. Hence 
lim f n exists a. e. 
Next, let us prove the "only if' part. Suppose that lim f n exists a.e. Let f = 
lim sup f n. Then f n a.e f. By Problem 9 .3, we have for every 8 > 0, 
Let E > 0 and TJ > 0. Then there exists an integer N.,., such that 
Now we consider the following set 
B= U {IIJ-Iki~E}. 
j,k~N, 
We claim that B ~ U%"=N, {Ilk- fl ~ E}. To show that, lets E B. Then there exist 
two integers io, ko ~ N.,., such that IIJ0 (s)- fko(s)l ~E. Note that f(s) ~ fJ 0 (s) 
and f(s) ~ fko(s). If IJo(s) < lko(s), then lf(s)- IJo(s)l = f(s)- fj 0 (s) ~ 
fko(s)- !Jo(s) ~E. If fj 0 (s) ~ fko(s), then lf(s)- fko(s)l = f(s)- fk 0 (s) ~ 
!Jo(s)- lko(s) ~E. Hence s E U%"=N, {Ilk- fl ~ E}. Therefore 
00 
B ~ u {Ilk- fl ~ E}. 
k=N, 

106 
CONVERGENCE 
Hence JL(B) < TJÂ· Since E and TJ are arbitrary positive numbers, we have 
This completes the proof. 
9.8. First let us prove the "if" part. Suppose that for each E > 0, we have 
Let 8 > 0 and TJ > 0. Then there exists an integer N, such that 
Now we consider the following set: 
A= U {lfJ- !kl ~ 8}. 
j,k?_N~ 
We claim that 
A~ 1Q
1 {lfN~+J- fN~I ~ ~}. 
To show that, let s E A. Then I !Jo ( s) - fko ( s) I ~ Hor some )o, ko ~ N,. Hence 
which implies that at least one of the following two inequalities is true: I !Jo ( s) -
iN~ (s) I ~ 8/2 and liko (s)- !N,, (s) I ~ 8/2. Therefore s E u~l {lfN~+j- !N, I ~ 
8/2}. Hence we have 
JL(A) < TJÂ· 
Since 8 and TJ are arbitrary positive numbers, it follows from Problem 9.7 that 
lim fn 
n->oo 
exists a.e. 
The "only if" part is straightforward. Suppose that limn->oo fn exists a.e. Then 
by Problem 9.7, for each E > 0, we have 

SOLUTIONS 
1 07 
But 
j=l 
j,k?_n 
we have 
M (,~{lf;+n- fnl 2 d) -> 0 "' n-> 00. 
This completes the proof. 
9.9. Let E > 0. Let N = C /E. Then we have 
r 
lfnl 2dJL + r 
lfnl 2dJL 
}{lfni?.N} 
}{lfni<N} 
> 
{ 
lfniNdJL 
}{lfni?_N} 
c r 
lfnldJL. 
E J{lfni?.N} 
By the assumption that J8 lfnl 2dJL < C, we have 
SUp r 
lfnldJL < E, 
n ~ 1. 
n?_l }{lfni?.N} 
Since E is arbitrary, the sequence is uniformly integrable. This completes the proof. 
9.10. 
(a) Let E > 0. Since !I, h, ... are uniformly integrable, we have 
SUp r 
lfnldJL < f 
n?_l }{ifnl?.c} 
for some c > 0. Hence 
Note that fniUn?.-c} + c ~ 0. By Theorem 6.3, we have 
h 
liminf(fniun?.-c} + c)dJL::::; liminf h 
Uni{tn?.-c} + c)dJL. 
Since JL is finite and liminf fniUn?.-c} + c = liminf(fni{fn?.-c} +c) (see 
Problem 1.8), we have 
Is liminf fni{fn?.-c}dJL :S liminf Is fni{fn?.-c}dJL. 

108 
CONVERGENCE 
Note that fnl{fn?_-c} ~ fnÂ· From the above inequality, We have 
is liminf fndf.-L::; liminf is fnl{fn?_-c}df.-L. 
(9.5) 
By Problem 1.8, we have 
liminf is fnl{fn?_-c}df.-l + liminf is fnl{fn<-c}df.-l::; liminf is fndf.-L. 
(9.6) 
Combining inequality (9.4) and inequality (9.6) gives 
liminf is fnl{fn?_-c}df.-L::; liminf is fndf.-L +E. 
Combining inequality (9.5) and the above inequality gives 
is lim inf fndf.-l ::; lim inf is fndf.-l +E. 
Since E > 0 is arbitrary, the first inequality in Equation (9 .1) is true. The second 
inequality is obvious by definition of lim inf and lim sup. The third inequality 
can be proved similarly. 
(b) If fn ~ 
f, then lim inf fn =lim sup fn = f. By part (a), we have 
is fdJ-L::; liminf is fndf.-l::; lim sup is fndf.-l::; is fdJ-L, 
which implies inequality (9.2). 
(c) By Problem 9.6, there exists a subsequence fnk such that fnk ~ 
f. By part 
(b), we know that f is integrable and 
isfnkdJ-L---7 isfdJ-L 
as 
k---+ oo. 
We claim that 
is fndf.-l---+ is fdJ-L 
as 
n---+ oo. 
If Is fndf.-l does not converge to Is fdJ-L, then we have for some E > 0, 
for infinitely many n. But we can find a subsequence fmk from these fn such 
that fmk ~f. Using the above argument, we have 

SOLUTIONS 
1 09 
This contradicts the hypothesis. Hence our claim is true. 
9.11. 
First let us prove the "if' part. Assume that the integrals fs lfnldp, are 
uniformly bounded and uniformly continuous. By Problem 6.16, we have 
Hence p,{ IfnI ~ c} ---+ 0 uniformly as c ---+ oo. Since the integrals are also uniformly 
continuous, we have 
sup { 
lfnldp,---+ 0 as 
c---+ oo. 
n }Wnl?.c} 
Hence the f n are uniformly integrable. 
Now we prove the "only if' part. Suppose that the f n are uniformly integrable. 
Let E > 0. Then there exists a c > 0 such that 
Hence we have 
{ 
lfnldp, + { 
lfnldp, 
J{ifnl?.c} 
J{lfnl<c} 
< 
E + cp,(S), 
n ~ 1, 
which shows that the integrals are uniformly bounded. 
Let 8 > 0. Then we can choose d such that 
Let A E I; such that p,(A) < 8/(2d). Then we have 
{ 
lfnldp, + { 
lfnldp, 
JAn{lfnl?.d} 
JAn{lfnl<d} 
8 
< 
"2 + dp,(A) 
< 
8, 
n ~ 1. 
Since 8 is arbitrary, it follows that the integrals are uniformly continuous. This com-
pletes the proof. 
9.12. First we show that the lfn - JIP are uniformly integrable. By Problem 8.3, 
we have 

110 
CONVERGENCE 
Also lfn- JIP :::; If niP+ IJIP for 0 < p:::; 1. Note that fn 4 f. By Problem 9.6, 
there exists a subsequence Un. h::::1 converging to f a.e. Hence lfnk IP ~ 
IJIP. 
By Problem 9.10, IJIP is integrable. Note that the lfniP are uniformly integrable. 
Hence the integrals Is lfn- fiPdJ.l are uniformly bounded and uniformly continuous. 
By Problem 9.11, the lfn - JIP are uniformly integrable. 
Since fnk ~ 
f and lfnk - JIP are uniformly integrable, by Problem 9.10, we 
have 
Is lfnk - fiPdJ.l -t 0 
as 
k -t oo. 
Using the same argument, we can show that any subsequence of {fn}n?l has a 
subsequence converging to f in LP. It follows that f n ~ f. This completes the 
proof. 
9.13. Let E > 0 and M = supiEI Is h(lfil)dJ.L. By assumption, there is a positive 
number c such that 
h(t) > M 
'Vt >_ c. 
t 
-
E ' 
Then 
Since E is arbitrary, the fi are uniformly integrable by definition. This completes the 
proof. 
9.14. First we show that the lfn - JIP are uniformly integrable. Let E > 0. Since 
f n ~ 
f, there is a positive integer N, such that 
Is lfn- JIPdP < ~' 
'Vn > N,. 
Let M = maxl:S;n:S;N, lfn- JIP. Then 
sup 
{ lfn - fiPdP + sup { lfn - fiPdP 
l:S;n:S;N, j A 
n>N, j A 
< 
{ MdP + sup { lfn- fiPdP 
JA 
n>N,Js 
E 
< J.L(A)M + "2' 
A E ~. 
If J.L(A) < E(2M), then 

BIBLIOGRAPHIC NOTES 
111 
Since f is arbitrary, we have L 
lin - iiPdP -t 0 as 
M(A) -t 0. 
Hence the integrals of lin - iiP are uniformly continuous. If A= S, then 
sup { lin - iiPdP ~ M(S)M + -2f. 
n?_l Js 
Since 11 is finite, the above inequality shows that the integrals of lin - iiP are uni-
formly bounded. Hence I in - i IP are uniformly integrable by Problem 9 .11. 
Now, by Problem 8.3, we have 
It follows that liniP are uniformly bounded and uniformly continuous. Hence the 
liniP are uniformly integrable. This completes the proof. 
9.5 Bibliographic Notes 
In this chapter, we defined several types of convergence in measure theory. The 
relationships of those types of convergence are shown in Figure 9 .1. 
11 is finite 
Figure 9.1 
Relationships of several types of convergence, where a.u and a.e. mean almost 
uniform convergence and almost everywhere convergence, respectively. 
Convergence in LP is stronger than convergence in measure. Almost uniform 
convergence is stronger than both convergence in measure and almost everywhere 
convergence. Convergence in measure does not necessarily lead to almost uniform 
convergence. However, if a sequence is convergent in measure, then there is a sub-
sequence that is convergent almost uniformly to the same limit function. If the un-
derlying measure is finite, then almost everywhere convergence implies almost uni-
form convergence. More information about convergence can be found in Ash and 
Doleans-Dade (1999, Section 2.5) and Lawler (2006). 


CHAPTER 10 
PRODUCT MEASURES 
Product measures are measures defined on the product of several measurable spaces. 
Fubini's theorem gives conditions under which we can evaluate integrals with respect 
to product measures by computing iterated integrals. In this chapter, we present the 
definition of product measures and Fubini's theorem. 
1 0.1 
Basic Concepts and Facts 
Definition 10.1 (Cartesian Product). Let 8 1 and 8 2 be two sets. The Cartesian prod-
uct of 81 and 82 is a set defined as 
81 X 82 = {(x,y): X E 81 andy E 82}. 
Definition 10.2 (Measurable Rectangle). Let (8h I;I) and (82, I;2) be two measur-
able spaces. Let 8 = 81 X 82 be the Cartesian product of 81 and 82. A measurable 
rectangle in the product space 8 is a product A1 x A2 for which A1 E I;1 and 
A2 E I;2Â· 
Definition 10.3 (Product a-Algebra). Let (81, I;I) and (82, I;2) be two measurable 
spaces. The product a-algebra I; Â® I;2 (I;1 Â® I;2 is not a Cartesian product in the 
Measure. Probability. and Mathematical Finance. 
113 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

114 
PRODUCT MEASURES 
usual sense.) is defined as the a-algebra generated by all measurable rectangles in 
the product space S 1 X 82: 
Definition 10.4 (Infinite Product). Let I be an index set, countable or uncountable. 
For each t E J, let (St, I:t) be a measurable space. LetS be the product space of St, 
t E J. A rectangle inS is defined as 
x At= {(xt)tEI E S: Xt EAt, t E I}, 
tEl 
where At ~ St and At differs from St for only a finite number oft. The rectangle is 
said to be measurable if At E I:t for every t E J. 
The a-algebra on S generated by the collection of all measurable rectangles is 
called the product a-algebra and is denoted by 
The resulting measurable space is denoted by 
Definition 10.5 (Coordinate Maps). Let 81 x 82 be the Cartesian product of 81 and 
s2. Then the ith coordinate map Pi : 81 X s2 ---+ si is defined as 
Definition 10.6 (Product Measure and Product Measure Space). Let (81, I:1, 11d 
and (82, I:2, 112 ) be measure spaces and suppose that 111 and 112 are a-finite. The 
product measure 11 = 111 x 112 of 111 and 112 is defined as follows (see Problems 10.6 
and 10.7): 
11(E)= { 112({yES2:(x,y)EE})111(dx) 
ls, 
= 
{ 11l({x E 81: (x,y) E E})/12(dy). 
Js2 
The measure space (S, I:, 11) = (81 x 82, I:1 0 I:2, /ll x 112) is called the product 
measure space. 
Theorem 10.1 (Tonelli's Theorem). Let (S1,I:1,/11) and (S2,I:2,112) be a-finite 
measure spaces, and let f: sl X sl ---+ R+ be a nonnegative I:l 0 I:2-measurable 
function, where R + = [0, oo) denotes the set of all nonnegative real numbers. Let 
91 : S1 ---+ :Rand 92 : S2 ---+ :R be defined as 
92(Y) = 
{ 
f(x,y)/11(dx), 
ls, 

PROBLEMS 
115 
where R = [ -oo, oo] denotes the set of extended real numbers. 
Then 91 is L.I/B(R)-measurable and 92 is L.2/B(R)-measurable. In addition 
{ 
f(z)!L(dz) = { 91(X)/L1(dx) = { 92(Y)/L2(dy), 
(10.1) 
J~x~ 
J~ 
J~ 
where /1 = /11 x /12Â· 
Theorem 10.2 (Fubini's Theorem). Let (81,L.1,!L1) and (82,L.2,1L2) be a-finite 
measure spaces and f E Â£1 (81 x 82, L.1 Q9 L.2, /11 x /12); that is, f is /11 x /12-
integrable. Then there exist sets A1 E L.1 and A2 E L.2 such that 
(a) /11 (81 \AI) = 0 and /12(82 \A2) = 0. 
(b) Forfixedx E A1o fx(Y) = f(x,y) E L 1(82,L.2,/12). 
(c) The function 
(10.2) 
is L.1 -measurable and 
(d) Forfixedy E A2, jy(x) = f(x,y) E L1(81,L.1,/LI). 
(e) The function 
is L.2-measurable and 
1 0.2 Problems 
10.1. Let (81, L.I) and (82 , L.2) be measurable spaces, and I be the collection of all 
measurable rectangles in the product space 81 x 82: 
Show that I is a 1r-system. 
10.2. Let (81, L.I) and (82, L.2) be measurable spaces and Pi : 81 X 82-+ 8i be the 
ith coordinate map fori= 1, 2. Show that Pi is L.1 Q9 L.2/L.i-measurable. 

116 
PRODUCT MEASURES 
10.3. Let ( 81' ~I) and ( 82' ~2) be measurable spaces and Pi : 81 X 82 ---+ 8i be the 
ith coordinate map fori= 1, 2. Show that 
where ~1 0 ~2 is as defined in Definition 10.3 and a(p1 , p2) is defined as 
a(p1,p2) = a(pi 1(B): i = 1,2,B E B) 
= a({(s1,s2) E 81 x 82: Pi(sl,s2) E B}: i = 1,2,B E B). 
10.4. Let (81, ~I) and (82, ~2 ) be measurable spaces, and let ~ 1 0~2 be the product 
a-algebra. Show that 
(a) If E E ~ 1 0 ~ 2 , then for each x E 81 the set Ex = {y : (x, y) E E} is 
~ 2 -measurable and for each y E 82 the set Ey = {x: (x,y) E E} is ~ 1 -
measurable. 
(b) Iff is ~1 0 ~2-measurable, then for each fixed x E 81 the function fx(Y) = 
f(x, y) is ~ 2 -measurable and for each fixed y E 82 the function jy(x) = 
f(x,y) is ~1-measurable. 
10.5. Let (81, ~ 1 , pi) and (82, ~ 2 , p2) be measure spaces and suppose that p1 and 
P2 are finite measures. ForEE ~1 0 ~ 2 , let 9E,i : 8i---+ R (i = 1, 2) be defined as 
Show that 
9E,l(x) = P2({y E 82: (x,y) E E}), 
9E,2(Y) = PI({x E 81: (x,y) E E}). 
(a) 9E,l and 9E,2 are well defined and bounded forE E ~1 0 ~2Â· 
(b) If [i (i = 1, 2) is the collection of E in ~ 1 0~ 2 for which 9E,i is ~i-measurable, 
then [i =~I 0 ~2-
10.6. Let ( 81, ~ 1 , pi) and ( 82, ~2, P2) be measure spaces and suppose that p1 and 
p2 are finite measures. Then 9E,1(x) = p2({y E 82 : (x,y) E E}) is bounded 
and ~1-measurable and 9E,2(Y) = PI({x E 81 : (x,y) E E}) is bounded and 
~2-measurable forE E ~1 0 ~2 (see Problem 10.5). Let e1 : ~1 0 ~2 ---+ Rand 
e2 : ~ 1 0 ~2 ---+ R be defined as 
el(E) = { 9E,l(x)pl(dx) = { P2({y E 82: (x,y) E E})PI(dx), 
ls, 
ls, 
e2(E) = { 9E,2(Y)P2(dy) = { PI({x E 81: (x,y) E E})p2(dy). 
ls2 
ls2 
Show that 
(a) e1 and e2 are finite measures on (8, ~) = (81 x 82, ~I 0 ~2). 

PROBLEMS 
117 
(b) For measurable rectangles E = A1 x A2, we have 
(c) ForE E 2::1 0 I:2, we have 
10.7. Let (S1, 2::1, J.Ld and (S2, 2::2, J.L2) be measure spaces and suppose that Jli and 
112 are a-finite measures. Show that 
(a) gE,l(x) = J12({y E S2: (x,y) E E}) iswelldefinedandi:1-measurableand 
gE,2(Y) = J.LI( {x E S1 : (x, y) E E}) is well defined and I:2-measurable for 
E E I:1 0 I:2. 
fh(E)= { gE,l(x)J.LI(dx)= { J12({yES2:(x,y)EE})J.LI(dx), 
Js, 
Js, 
B2(E) = { gE,2(Y)J12(dy) = { Jli({x E S1: (x,y) E E})J.L2(dy). 
Js2 
Js2 
(c) For measurable rectangles E = A1 x A2, we have 
10.8. Let (0, ff) be a measurable space. Let (Et. G''t), t E J, be measurable spaces, 
where I is an index set. Let ( F, 9) be the product measurable space of ( Et, 0t), 
t E J: 
For each t E J, let ft be a mapping from 0 to Et. For each w E 0, define f(w) = 
Ut(w))tEI E F. Show that the mapping f: 0--+ F isÂ§ /~-measurable if and only 
if for every t E J, ft is Â§ / G"rmeasurable. 

118 
PRODUCT MEASURES 
10.3 Hints 
10.1. Use the definition of the Cartesian product (Definition 10.1) and the definition 
of n-system (Definition 2.15). 
10.2. Use the definition of measurable functions (Definition 5.3). 
10.4. For part (a), consider mapping Tx : s2 ---+ s1 X s2. For part (b), consider the 
set J;;1 (B) forB E Band use the result of part (a). 
10.5. To prove part (a), use the result of Problem 10.4. To prove part (b), use the 
results of Problems 10.1 and 2. 7. 
10.6. To prove part (a), follow the definition of measures and use Theorem 6.2 and 
the result of Problem 6.12. To prove part (b), note that 
To prove part (c), use Theorem 3.2. 
10.7. To prove part (a), use the result of Problem 10.5 and Theorem 5.1. Use the 
result of Problem 10.6 and Theorem 6.2 to prove part (b). Parts (c) and (d) can be 
proved by using the result of Problem 1 0.6. 
10.8. 
To prove the "if' part, use the definition of infinite products (Definition 
10.4) and the result of 5.4. The "only if" part can be proved by considering special 
rectangles. 
1 0.4 Solutions 
10.1. Let A1 x A2 E I and B1 x B2 E I. Since 
we have (A1 x A2) n (B1 x B2) E I. Hence I is an-system. 
10.2. We show that p1 is ~ 1 lSI ~2 /~ 1 -measurable. By the definition of p1, we have 
P11(Bl) = B1 x S2, 
B1 E ~1Â· 
By the definition of ~1 lSI ~2. we have B1 X s2 E ~1 lSI ~2 for B1 E ~1- Therefore, 
P11 (Bl) E ~1 lSI ~2 for B1 E ~1; that is, P1 is ~1 lSI ~2/~1-measurable. Similarly, 
we can show that P2 is ~1 lSI ~2/~2-measurable. 
10.3. We will prove ~1 lSI ~2 = a(p1,P2) by showing that ~1 lSI ~2 ~ a(p1,P2) 
and a(p1, P2) ~ ~1 lSI ~2Â· To show that ~1 lSI ~2 ~ a(p1, P2), we let A1 E ~1 and 

SOLUTIONS 
119 
A2 E E2. Note that A1 x A2 = (A1 x S2) n (S1 x A2) and A1 x S2 = P11(Al) E 
a(p1,P2) and S1 X A2 = P21(A2) E a(p1,p2), we have A1 x A2 E a(p1,P2). 
Therefore, E1 0 E2 ~ a(p1,P2). 
Now we show that a(p1,p2) ~ E1 0 E2. But given P11(Al) = A1 x S2 E 
E1 0 E2 and P21(A2) = S1 x A1 E E1 0 E2 for all A1 E E1 and A2 E E2, we 
have a(p1, P2) ~ E1 0 E2. This completes the proof. 
10.4. 
(a) Let X E s1 be fixed. We consider the mapping Tx : s2 -+ s1 X s2 defined by 
Tx(Y) = (x, y). If E = A1 x A2 is a measurable rectangle, then 
r-1(E) = {A2 if x E A1; 
X 
0 
if X rJ_ A1, 
and so rx- 1 (E) E E2. Noting that E1 0 E2 is generated by all measurable 
rectangles, we have, by Problem 5.4, Tx is E2/E1 0 E2-measurable. It follows 
that Ex = Tx- 1(E) E E2 forE E E1 0 E2; that is, Ex is E2-measurable. 
Similarly, we can show that for each fixed y the set Ey is E1-measurable. 
(b) Now we show that fx is E2-measurable. To do this, let B E B. Then J;1 (B) = 
{y E S2 : fx(Y) E B} = {y E S2 : f(x, y) E B}. Since f is E1 0 E2-
measurable, we have EB = {(x, y) E S1 x S2 : f(x, y) E B} = f-1(B) E 
E1 0 E2. Noting that J;1(B) = {y E S2: (x, y) E EB}, we have, by the first 
part of this proof, J;1 (B) E E2. Hence fx is E2-measurable. Similarly, we 
can show that fy is E1-measurable for fixed y. 
10.5. 
(a) Let E E E1 0 E2. By Problem 10.4, for fixed x E S1 the set {y E S2 : 
(x, y) E E} is E2-measurable. Therefore, the function gE,1 is well defined. By 
hypothesis, f..l2 is finite. Then gE,1(x)::; M2(S2) < oo and so gE, 1 is bounded. 
Similarly, gE,2 is well defined and bounded. 
(b) Now we show that Â£1 = E1 0 E2. First, we show that Â£1 is ad-system on 
s1 X S2. Sincegslxs2,1(x) = f..l2({y E s2: (x,y) E sl X S2}) = f..l2(S2) for 
x E S1, forB E B 
and so g81\s2,1 E E1. Hence gsl xS2,1 is E1-measurable, and so s1 X s2 E Â£1. 
LetE1, E2 E Â£1 andE1 ~ E2. ThengE1,1(x) andgE2,1(x) are E1-measurable. 
Since 
gE2\E1,1(x) = f..l2({y E S2: (x,y) E E2\El}) 
= f..l2({y E S2: (x,y) E E2}\{y E S2: (x,y) E E1}) 
= f..l2({y E S2: (x,y) E E2})- f..l2({y E S2: (x,y) EEl}) 
= gE2,1 (x) - gE1,1 (x), 

120 
PRODUCT MEASURES 
9E2 \E1,I(x) is I:t-measurable. Therefore, E2\Et E Ct. Let En E Ct (n 2: 1) 
and En t E. Then {y E 82 : (x,y) E En} t {y E 82 : (x,y) E E}. By 
Theorem2.1,gen,t(x) = J12({y E 82: (x,y) E En}) t 9E,t(x) = J12({y E 
82 : (x, y) E E} ). By Problem 5.9, 9E,t (x) is I:rmeasurable. Hence E E Ct. 
Therefore, Ct is ad-system on 8t x 82. 
Next, we show that Ct contains all measurable rectangles in the product space 
8t x 82. Let E =At x A2 be a measurable rectangle. Then 9E,t (x) = 112( {y E 
82 : (x, y) E At x A2}) = IA 1 (x)112(A2) and so 9E,t (x) is I:t-measurable. 
Hence E E Ct. 
By Problem 10.1, the collection I of all measurable rectangles is an-system. 
By definition, I:t Â® I:2 = a(I). Recall that Ct is ad-system. Then, by Problem 
2.7, I:t Â® I:2 = a(I) = d(I) ~ Ct. By the definition of Ct, we have Ct ~ 
I:t Â® I:2. Therefore, Ct = I:t Â® I:2. Similarly, we can show that C2 = I:t Â® I:2. 
This completes the proof. 
10.6. First, we show that Bt is a finite measure. By the definition of Bt, we have 
Bt 2: 0 and Bt(0) = fs 1 J12(0)JLt(dx) = fs 1 OJLt(dx) = 0. Let En (n 2: 1) be a 
sequence of pairwise disjoint sets in I: t Â® I:2. Let f n : 8 t ---+ R and f : 8 t ---+ R be 
defined as 
f n ( x) = J12 ( { y E 82 : ( x, y) E Q 
Ei}) , 
n E N, 
f(x) = 112 ( { y E 82 : (x, y) E Q 
Ei}) , 
n EN. 
Then f n t f and, by Theorem 6.2, we obtain 
But, by Problem 6.12, we have 
From equation ( 10.4 ), we have 
and so 

SOLUTIONS 
121 
Therefore, el is a measure on (Sl X s2, I;l 0 I;2). Since /-ll and /-l2 are finite and 
B1 (S1 x S2) = /-ll (St)f-l2(S2) < oo, we see that B1 is finite. Similarly, we can show 
that e2 is a finite measure on (Sl X S2, I;l 0 I;2)Â· 
Next, let E = A1 x A2 be a measurable rectangle. Then 
B1(E) = { /-l2({y E S2: (x,y) E A1 x A2})/-l1(dx) 
ls, 
= r IA,(X)f..l2(A2)/-ll(dx) 
ls, 
= /-l1(A1)/-l2(A2). 
Similarly, we have B2(E) = f-l1(At)f..l2(A2)Â· 
Finally, we show that B1(E) = B2(E) forE E I;l 0 I;2Â· Since B1(E) = B2(E) 
for every E E I, where I is the collection of all measurable rectangles in the product 
space sl X S2, and I;l 0 I;2 = a(I), the equality of el and e2 on I;l 0 I;2 follows 
from Theorem 3.2. 
10.7. By hypothesis, /-ll and f-l2 are a-finite. Let Cn (n ;:::: 1) and Dm (m ;:::: 1) be 
decompositions of S1 and S2 into sets of finite measure, and let /-ln,1 (C) = /-ll ( C n 
Cn) forCE S1 and /-lm,2(D) = /-l2(D n Dm) forD E 82. 
(a) Let E E I;1 0 I;2. Since 
9E,l(x) = /-l2({y E 82: (x,y) E E}) 
= /-l2 (Q1({y E 82: (x,y) E E} nDm)) 
00 
(10.5) 
= L /-l2({y E s2: (x,y) E E} n Dm) 
m=l 
00 
= L /-lm,2({y E s2: (x,y) E E}), 
m=l 
by Problem 10.5 and Theorem 5.1, 9E,l (x) is well defined and I;1-measurable. 
Similarly, 9E,2(Y) is well defined and I;2-measurable. 

122 
PRODUCT MEASURES 
(b) By Equation (10.5) and Theorem 6.2, we have 
B1(E) = { 9E,l(x)J.Ll(dx) 
ls, 
= 1 f: J.Lm,2( {y E S2: (x, y) E E} )J.Ll(dx) 
S1 m=l 
= f: 1 
J.Lm,2( {y E S2: (x, y) E E} )J.Ll(dx) 
m=l s, 
= f: f: 1 
J.Lm,2({y E S2: (x,y) E E})J.Ln,l(dx) 
m=l n=l s,nCn 
00 
00 
= 2::: 2::: Bm,n,l (E), 
m=l n=l 
where 
(10.6) 
Bm,n,l(E) = 
{ 
J.Lm,2({y E S2: (x,y) E E})J.Ln,l(dx), 
m,n 2 1. 
Js,ncn 
Similarly, we have 
00 
00 
B2(E) = 2::: 2::: Bm,n,2(E), 
(10.7) 
m=l n=l 
where 
Bm,n,2(E) = 
{ 
J.Ln,l({x E S1: (x,y) E E})J.Lm,2(dy), 
m,n 2 1. 
Js2nD, 
By Problem 10.6, Bm,n,l and Bm,n2 are measures on sl X s2. Therefore, (}1 (E) 
and (}2(E) are measures on sl X s2. 
(c) Let E = A1 x A2 be a measurable rectangle.By Problem 10.6, we have 
Hence 
00 
00 
m=l n=l 
00 
00 
= 2::: 2::: J.Ln,I(AI)J.Lm,2(A2) = J.LI(AI)J.L2(A2)Â· 
m=l n=l 
Similarly, we have B2(E) = J.LI(AI)J.L2(A2). 
(d) By Problem 10.6, we have Bm,n,l (E) = Bm,n,2(E) forE E I:1 0 I:2. There-
fore, by Equations (10.6) and (10.7), B1(E) = B2(E) forE E I:1 0 I:2. 

BIBLIOGRAPHIC NOTES 
123 
This completes the proof. 
10.8. 
First, let us prove the "if" part. Suppose that for every t E I, ft is !7 I rf:t-
measurable. Let C be the collection of all measurable rectangles on F. Let A E C. 
Then 
A= X At, 
tEl 
where At E gt and At differs from Et for only a finite number oft. Note that 
r
1(A) ={wE 0: ft(w) EAt}= n{ft EAt}, 
tEJ 
where J is the finite index set of t where At differs from Et. Hence we have 
f- 1(A) E !7. Since <;ff =a( C), by Problem 5.4, f is !7 l';ff-measurable. 
Second, let us prove the "only if" part. Suppose that f is !7 l';ff-measurable. Let 
s E I be fixed and B E gs. Let A be a measurable rectangle on F given by 
where A 1 = Et fort =/= s and At = B fort = s. By the assumption, we have 
f- 1(A) E !7. 
But f- 1(A) = J; 1(B). Thus we have J; 1(B) E !7. 
Hence fs is !7 I rf:t-measurable. This completes the proof. 
10.5 Bibliographic Notes 
In this chapter, we introduced product measures and Fubini's theorem. We presented 
the definitions using the product of two measurable spaces. In fact, these definition 
and theorems can be extended to the product of n measurable spaces. For more 
information on product measures and Fubini's theorem, readers are referred to Weir 
(1979), Billingsley (1986), Williams (1991), Vestrup (2003), and Athreya and Lahiri 
(2006). 


PART II 
PROBABILITY THEORY 


CHAPTER 11 
EVENTS AND RANDOM VARIABLES 
Samples, events, and random variables are the fundamental concepts in probability 
theory. In this chapter, we shall introduce the definitions of these concepts based on 
measure theory. 
11.1 
Basic Concepts and Facts 
Definition 11.1 (Sample Space, Sample Point, and Event). Let (0, Â§, P) 
be a 
probability space (see Definition 2.12). The set 0 is called the sample space, a point 
in 0 is called a sample point, and a subset ofÂ§ is called an event. 
Definition 11.2 (Discrete Probability Space). Let n = {WI' w2' ... } be a finite or 
countably infinite set. Let P be a set function defined as 
P{wi} =Pi, 
i = 1, 2, ... 
and 
P(A) = L Pi, 
A ~ n, 
w,EA 
Measure, Probability, and Mathematical Finance. 
127 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

128 
EVENTS AND RANDOM VARIABLES 
where p 1 , p2 , ... are nonnegative numbers whose sum is 1. Then P is a probability 
measure on 2Â°, which is the collection of all subsets of 0. The probability space 
(0, 2Â°, P) is called a discrete probability space. 
Definition 11.3 (Almost Surely). Let (0, ~' P) be a probability space. A statement 
about outcomes is said to be true almost surely (a.s.), or with probability 1, if the set 
of sample points for which the statement is true has probability 1: 
F = { w E 0 : the statement about w is true} E ~ and P( F) = 1. 
Definition 11.4 (Infinitely Often Event). Let (0, ~' P) be a probability space, and 
let {En }nEN be a sequence of events. Infinitely often event lim sup En is defined as 
limsupEn = n ( U En)Â· 
m:::O:l 
n:::O:m 
Definition 11.5 (Eventual Event). Let (0, ~' P) be a probability space and let 
{ En}nEN be a sequence of events. Eventual event lim inf En is defined as 
lim inf En = U ( n En) Â· 
m:::O:l 
n:::O:m 
Definition 11.6 (Random Variable). Let (0, ~) be a measurable space. A random 
variable X is a ~-measurable function; that is, 
X: 0--+ R, 
and x- 1(A) E ~' 'v'A E 13, where 
x- 1(A) ={wE 0: X(w) E A}. 
Definition 11.7 (E-Valued Random Variable). Let (0, ~)and (E, 0") be two mea-
surable spaces. An E-valued random variable X is a ~I 6" -measurable function; 
that is, 
X: 0--+ E, 
and x- 1(A) E ~' 'v'A E 0", where 
x- 1(A) ={wE 0: X(w) E A}. 
Definition 11.8 (Random Vectors). Let (0, ~) be a measurable space. An n-
dimensional random vector X is a ~I !3(R n )-measurable function. That is, 
and x- 1(A) E ~' 'v'A E !3(Rn), where 
x- 1(A) ={wE 0: X(w) E A}. 

BASIC CONCEPTS AND FACTS 
129 
A random vector X can be regarded as ann-tuple (X1 , X2, ... , Xn) of random 
variables defined on a common probability space. 
Definition 11.9 (a-algebra Generated by a Collection of Functions). Let (0, $")be 
a measurable space and (Y1 : 'Y E C) be a collection of functions Y1 : 0 -+ R. The 
a-algebra Y generated by the collection (Y1 : 'Y E C) of functions is defined as 
Y = a(Y1 : 'Y E C)= a ({wE 0: Y1 (w) E B}: 'Y E C, BE !3). 
In other words, Y is the smallest a-algebra on 0 such that each function Y1 is Y-
measurable. 
Definition 11.10 (Probability Law and Distribution Function). Let (0, $", P) be a 
probability space and X be a random variable on 0. The probability law of X is a 
function .Cx: !3-+ [0, 1] defined as 
.Cx = PoX-1. 
The distribution function Fx : R-+ [0, 1] of X is defined as 
Fx(c) = .Cx( -oo, c] =(Po x- 1)( -oo, c] = P(X ~c)= P{w: X(w) ~ c}. 
Definition 11.11 (Joint Law and Joint Distribution Function). Let X = (X1 , X2 , 
... , Xn) be a random vector on a probability space (0, $", P), where n is a natural 
number. Then the distribution function of X is the function Fx : Rd -+ R given by 
(see Definition 4.2) 
Fx(xl,X2, ... ,xn) = P{w: X1(w) ~ x1,X2(w) ~ X2, ... ,Xn(w) ~ Xn}. 
Definition 11.12 (Absolutely Continuous Random Variable and Density Function). 
A random variable X is said to be absolutely continuous if and only if there exists a 
nonnegative Borel function f on R such that 
F(x) = lxoo f(t)dt, 
x E R, 
where F is the distribution function of X. The function f is called the density func-
tion of X. 
A random vector X is said to be absolutely continuous if and only if there exists 
a nonnegative Borel function f on R n such that 
F(x) = [x~ [x~ Â· Â· Â·lx~ f(tl, t2, ... , tn)dt1dt2 Â· Â· Â· dtn, 
where F is the joint distribution function of X. 
Definition 11.13 (Degenerate and Nondegenerate Random Variable). A random 
variable X on a probability space (0, $", P) is said to be degenerate if its law is 
a Dirac measure be, where 
bc(A) = { 1, if c E A; 
A E !3. 
0, 
if c ~A, 

130 
EVENTS AND RANDOM VARIABLES 
A random variable is said to be nondegenerate if it is not degenerate. 
Theorem 11.1 (Fatou's Lemma). Let (S, I:, f.l) be a measure space and let { En}nEN 
be a sequence ofi:-measurable subsets of S. Then we have 
Theorem 11.2. Let (D, $") be a measurable space. Let X1, X2, ... , Xn be func-
tions from n toR. Then a function Z: n---+ R is a(X1, X2, ... , Xn)-measurable 
if and only if there exists a Borel function f : R n ---+ R such that 
Theorem 11.3. Let (D, $")be a measurable space. Let (X"' : 'Y E C) be a collection 
of functions from n to R, where C is an infinite index set. Then a function Z : n ---+ 
R is a(X'Y : 'Y E C)-measurable if and only if there exists a countable sequence 
( 'Yi : i E N) of elements of C and a Borel function f : RN ---+ R such that 
11.2 Problems 
11.1. Let (D, $", P) be a probability space, and let { Fn }nEN be a sequence of events 
such that P(Fn) = 1 for all n E N. Show that 
11.2. Prove Fatou's lemma in Theorem 11.1. 
11.3 (Reverse Fatou's Lemma). Let (D, .9>, P) be a probability space and {En}nEN 
a sequence of events. Show that 
P(limsupEn)?: limsupP(En)Â· 
11.4. Let (D, $") be a measurable space, where n = { H, T} and 
.9> = {0, {H}, {T}, {H, T} }. 
Let X : n ---+ R be defined as 
X(w) = {p, 1- p, 
ifw = H; 
ifw = T, 
where 0 < p < 1. Show that X is a random variable. 

PROBLEMS 
131 
11.5. Let (0, Â§, P) be a probability space and E E $be an event. Show that 
{0, E, 0\E, 0} = a(IE), 
where IE is the indicator function. 
11.6. Let (0, $, P) be a probability space and { En}n;:::: 1 be a sequence of events. 
Show that 
(a) If En t E, then P(En) t P(E). 
(b) If En .,l. E, then P(En) .,l. P(E). 
11.7. Let (n, $, P) be a probability space and {En}n;:::l be a sequence of events 
such that En ---+ E. Show that P(En) ---+ P(E). 
11.8. Let (0, $, P) be a probability space and {En}n;:::1 be a sequence of events. 
Show that 
11.9 (Bonferroni Inequalities). Let (n, Â§, P) be a probability space and {En}n;:::l 
be a sequence of events. Show that 
and 
P (Q E;) ,; t,P(E;)- ,,~,. P(E; nE;) + '9~''" P(E; nE; nE,). 
(11.2) 
11.10. Let (n, Â§, P) be a probability space and X be a random variable on n. Let 
rr(X) be defined as 
rr(X) ={{wE 0: X(w) ~ c}: c E R}. 
Show that rr(X) is a rr-system and 
a(X) = a(rr(X)). 
11.11. Let (0, Â§, P) be a probability space and {Xn}nEN be a sequence of random 
variables on n. Define rr(Xn : n E N) as 
rr(Xn: n EN)= {{wE 0: Xi(w) ~ ci, i EN}: ci E RU {oo}}. 
Show that rr(Xn : n E N) is a rr-system and 
a(Xn : n EN) = a(rr(Xn : n EN)). 

132 
EVENTS AND RANDOM VARIABLES 
11.12. Let (0, $, P) be a probability space and { Xn }n>l be a sequence of random 
variables on 0. Show that 
{limsupXn >a}= limsup{Xn >a}, 
a E R. 
11.13. Let Fx be a distribution function of a random variable X. Show that F has 
only countably many discontinuities, that is, the set 
D ={a E R: F(x) is not continuous at a} 
is countable. 
11.14. Let X be a random variable with continuous distribution function F. Find 
the distribution function of the random variable Y = F(X). 
11.15. Let { En}n>l be a sequence of events in a probability space (0, $, P) such 
that 
lim P(En) = 0 
n---+oo 
and 
00 L p (En+l n E~) = 0. 
n=l 
Show that 
P (lim sup En) = 0. 
11.3 Hints 
11.1. Apply the result of Problem 2.19. 
11.2. 
Establish p, (ni2:m Ei) :::; supr2:l (infn;::r p,(En)) for all m ~ 1 first and 
then apply Theorem 2.1. 
11.3. First establish P (Un;::m En) ~ infr;::l (supn>r P(En)) for all m ~ 1 and 
then use the result of Problem 2.18. 
11.4. By definition, a random variable is a measurable function. To show that X is 
$-measurable, one can use the result of Problem 5.7. 
11.5. 
Follow the definition of a-algebra generated by functions (see Definition 
11.9). 
11.6. Look at Theorem 2.1 and Problem 2.18. 
11.7. First get familiar with what En ---+ E means (see Problem 1.9) and then apply 
the result of Problem 11.6. 

SOLUTIONS 
133 
11.8. 
Write U~=l En as an infinite union of disjoint sets and use properties of 
measures. 
11.9. Use the mathematical induction method. 
11.10. Use the results of Problems 2.4 and 2.18 to show that a(X) = a( 1r(X) ). 
11.11. 
To show that a(Xn : n E N) = a(1r(Xn : n E N)), one can use the 
standard technique, that is, show that a(Xn : n E N) ~ a(1r(Xn : n E N)) and 
a(Xn: n EN)~ a(1r(Xn: n EN)). 
11.12. Use the standard technique to show that two sets are equal (see Hint 11.11). 
11.13. Use the result of Problem 2.20. 
11.14. Note that ifF is continuous, then F- 1 (y) is nonempty for any y E [0, 1]. 
Then use the definition of distribution functions (Definition 11.1 0) to calculate the 
distribution function of Y. 
11.15. First try to establish that 
lim sup En~ [lim sup (En+l n E~)] U liminf En. 
and then use the first Borel-Cantelli lemma (Theorem 2.2) and Fatou's lemma (The-
orem 11.1). 
11.4 Solutions 
11.1. Since Pis a probability measure, we have P(F~) = 1 - P(Fn) = 0 for all 
n ~ 1. From Problem 2.19, we have 
This finishes the proof. 
11.2. Since 
we have 
\fm ~ 1. 
(11.3) 

134 
EVENTS AND RANDOM VARIABLES 
From Theorem 2.1, we have 
as m-+ oo. Combining (11.3) and (11.4) gives 
This proves the theorem. 
11.3. Since 
P (u Ei) 2: P(En), 
\In 2: m, mEN, 
t?':m 
we have 
2: sup P(En) 2: inf (sup P(En)) , 
n?':m 
r?':l 
n?':r 
\/mEN. 
(11.5) 
From Problem 2.18, we have 
as m -+ oo. Combining ( 11.5) and ( 11.6), we have 
P(limsupEn) 2: limsupP(En)Â· 
11.4. 
To show that X is a random variable, we only need to show that X is Â§-
measurable. To do this, we show that {X > c} E Â§, 't/c E R (see Problem 5.7), 
where {X > c} = { w E 0 : X ( w) > c}. 
If p < ~, then p < 1 - p and 
{
{H,T}, 
{X> c} = 
{T}, 
0, 
If p = ~, then p = 1 - p and 
{X> c} = {{H, T}, 
0, 
if c < p; 
ifp:::; c < 1- p; 
if 1- p:::; c. 
if c < p; 
if 1- p:::; c. 

If p > ~, then p > 1 - p and 
{
{H,T}, 
{X> c} = 
{H}, 
0, 
Thus we have {X> c} E Â§, Vc E R. 
11.5. By definition, we have 
if c < 1- p; 
if1- p:::;: c < p; 
ifp:::;: c. 
SOLUTIONS 
135 
a(Ie) = a({w E 0: fe(w) E B}: BE B). 
But 
!
0, 
{wE 0: Ie(w) E B} = 
O\E, 
E, 
o, 
Thus we have 
if 0 tf. Band 1tf. B; 
if 0 E B and 1 tf. B; 
if 0 tf. B and 1 E B; 
if 0 E Band 1 E B, 
a(Ie) = a(0, E, 0\E, 0). 
Noting that {0, E, 0\E, 0} is the smallest a-algebra containing 0, E, 0\E, and 0, 
we have a(0, E, 0\E, 0) = {0, E, 0\E, 0}, which gives the result. 
11.6. The results follow from Theorem 2.1 and Problem 2.18 immediately. 
11.7. 
Since En -+ E, we have, by Problem 1.9, E E Â§ 
and lim sup En 
liminf En =E. Let An = Ui>n Ei and Bn = ni>n Ei for all n?: 1. Then An .j.. 
E and Bn t E. By Problem 11.6, we have P(An) .j..-P(E) and P(Bn) t P(E). But 
P(An) ?: P(En) ?: P(Bn) for all n ?: 1, we have P(En) -+ P(E). 
11.8. 
Let A1 = E1 and An = En\ U~:1
1 Ei for n ?: 2. Then A1, A2, ... are 
pairwise disjoint and U~=l An= U~=l En. Noting that Pis a probability measure 
and P(An) :::;: P(En) for n?: 1, we have 
11.9. We use the mathematical induction method. When n = 1, inequality (11.1) 
reduces to P(El) ?: P(E1 ), which is true. Suppose that inequality (11.1) is true for 

136 
EVENTS AND RANDOM VARIABLES 
n = m. Then by Problem 2.11, the induction hypothesis, and Problem 11.8, we have 
P CQ Ei) + P(Em+l)- P ( (Q Ei) n Em+l) 
m 
> LP(Ei)-
L 
P(EinEj) 
i=l 
l:s;i<j:s;m 
Therefore, inequality ( 11.1) is true for all n 2 1. 
We can prove inequality ( 11.2) by mathematical induction and inequality ( 11.1 ). 
11.10. We first show that n(X) is an-system. Let h E n(X) and J2 E n(X); then 
fr 
{ w E 0 : X ( w) :S cr}, 
J2 
{wE 0: X(w) :S c2} 
for some c1 , c2 E R. But 
which implies that n(X) is an-system. 
Note that 
a(X) ={{wE 0: X(w) E B}: BE B} = x- 1(8), 
and 
n(X) = {{wE 0: X(w) :S c}: c E R} = x- 1(n(R)), 
where n(R) = {( -oo, c]: c E R}. By Problem 2.4 and Problem 5.5, we have 
a(X) = x- 1(8) = a(X- 1 (n(R))) = a(n(X)). 
This completes the proof. 
11.11. We first show that n(Xn : n E N) is an-system. To do this, let fr,J2 E 
n(Xn : n E N); then we have 
fr 
{wE 0: Xi(w) :Sci, i EN}, 
J2 
{wE 0: Xi(w) :S di, i EN}, 
for some ci, di E R U { oo }. But 

SOLUTIONS 
137 
Thus, 1r(Xn : n E N) is a 1r-system. 
Noting that, for any i E N, we obtain 
1r(Xi) 
E 
{w: Xi(w)::::; c, X1(w)::::; oo,j E N,j =1- i} 
{w: Xi(w) :=::; c} 
E 
1r(Xn: n EN), 
'1/c E RU {oo}, 
which implies 
1r(Xi) ~ 1r(Xn : n EN). 
From Problem 11.1 0, we have 
Therefore 
00 U a(Xi) ~ a(1r(Xn: n EN)). 
i=l 
But 
a({w E 0: Xn(w) E B}: n E N,B E !3) 
a CQ1 a(Xn)) . 
Thus, from ( 11. 7) we have 
Now we show that 
To do this, let I E 1r(Xn : n E N); then 
I= {wE 0: Xi(w) :s; ci, i EN}. 
But 
00 
( 11.7) 
(11.8) 
(11.9) 
{wE 0: Xi(w) :s; ci, i EN}= n{w E 0: Xi(w) :s; ci} E a(Xn: n EN). 
i=l 
We have I E a(Xn : n E N). Since I is arbitrary, we have 
which gives (11.9). Combining (11.8) and (11.9) gives the result. 

138 
EVENTS AND RANDOM VARIABLES 
11.12. First we show that 
{limsupXn >a}~ limsup{Xn >a}. 
To do this, let wE {limsupXn >a}. Then limsupXn(w) >a. By Definition 1.9, 
we have supn>m Xn(w) > a for all m ;::: 1, which implies that w E Un>m {Xn > 
a} for all m ~ 1. Hence wE nm>l Un>m {Xn >a}. Thus {limsupXn >a} ~ 
limsup{Xn >a}. 
-
-
Similarly, we can show that {limsupXn > a} ;;;;? limsup{Xn > a}. This 
completes the proof. 
11.13. 
Suppose that X is a random variable on the probability space (0., Â§, P). 
For each a E D, define an event 
Ea = { w E 0. : X ( w) = a}. 
Then the Ea, a E D, are disjoint sets inÂ§. By the definition of D, for a E D, we 
have P(Ea) = F(a)- F(a-) > 0, where 
F(a-) = lim F(x). 
x---+a-
It follows from Problem 2.20 that D is a countable set. This completes the proof. 
11.14. Let Fy be the distribution function of Y. Then by Definition 11.10, we have 
Fv(y) = P{Y :<:; y} = P{F(X) :<:; y}, 
y E R. 
Note that F(X) E [0, 1]. We have Fy(y) = 0 for y < 0 and Fy(y) = 1 for y > 1. 
Now let us consider the case when y E [0, 1]. By the assumption that the distribution 
function F is continuous, we know that p-I (y) is nonempty. Hence we can find an 
x0 E F- 1 (y); that is, we can find an x0 such that F(x0 ) = y. Thus 
Fv(y) = P{F(X) :<:; y} = P{F(X) :<:; F(x0 )} = P{X :<:; x 0 } = F(x0 ) = y. 
Therefore, Y has a distribution function given by 
{
0, 
ify < 0; 
Fv(Y) = 
y, 
ifO :<:; y :<:; 1; 
1, 
if y > 1. 
11.15. To prove the result, we first show that 
limsupEn ~ [limsup(En+I nE~)] UliminfEn. 
(11.10) 
To do that, let w E lim sup En. Then there are infinitely many events containing w. 
That is, w E En, for n1 < n2 < .... 

BIBLIOGRAPHIC NOTES 
139 
Now if there exists an integer ko such that nk = nko + k - ko all k 2: ko, then 
w E lim inf En; that is, if w is contained in all Ei for i 2: nko, then w E lim inf En. 
In this case, we have 
wE [lim sup (En+l n E~)] U liminf En. 
Now suppose that no such k0 exists. Then for any i E N, we can find an integer 
k > i such that w E Ek+l n Ek. It follows that w E lim sup (En+l n E~). In this 
case, we still have 
wE [lim sup (En+l n E~)] U liminf En. 
Therefore, Equation (11.10) holds. By the first Borel-Cantelli lemma (Theorem 2.2) 
and the assumption, we have 
P[limsup (En+l n E~)] = 0. 
By Fatou's lemma (Theorem 11.1) and the assumption, we have 
P(liminf En)~ liminf P(En) = 0. 
Hence by Equation ( 11.1 0), we get 
P(lim sup En) ~ P[lim sup (En+l n E~)] + P(lim inf En) = 0. 
This completes the proof. 
11.5 Bibliographic Notes 
In this chapter, we introduced some basic concepts in probability theory based on 
measure theory. In fact, measure theory is necessary for us to study probability 
theory in a rigorous manner. Rosenthal (2006, Chapter 1) discussed why measure 
theory is indispensable to a mathematical rigorous theory of probability. Shafer and 
Vovk (2001) discussed the historical development of probability theory. 
Theorems 11.2 and 11.3 are two interesting results that characterize the a-algebras 
generated by random variables. For proofs of these two theorems, readers are re-
ferred to ~inlar (2011, pp76-78). 
For textbooks on measure-theoretic probability, readers are referred to Loeve 
(1978), Williams (1991), Billingsley (1995), Kallenberg (1997), Chung (2000), Pol-
lard (2001), Jacod and Protter (2004), Roussas (2005), Athreya and Lahiri (2006), 
Rao and Swift (2006), Koralov and Sinai (2007), Bhattacharya and Waymire (2007), 
Durrett (2010), and ~inlar (2011). For probability theory without measure theory, 
readers may consult Hsu (1996), Roussas (1997), Stirzaker (2003), Dekking et al. 
(2005), Lefebvre (2006), Bartoszynski and Niewiadomska-Bugaj (2007), and Gut 
(2009). Most probability concepts and results are also introduced in statistics books, 
such as Roussas (1997) and Shao (2003). 
For problem books on probability, readers are referred to Mosteller ( 1987), Capin-
ski and Zastawniak (2000), Mills (2001), Grimmett and Stirzaker (2001), and Chau-
mont and Yor (2003). 


CHAPTER 12 
INDEPENDENCE 
Independence is an important concept in probability theory. Intuitively, two events 
are independent if the occurrence of one event does not make the other happen more 
or less. In this chapter, we will introduce the concept of independence of events and 
random variables. 
12.1 
Basic Concepts and Facts 
Definition 12.1 (Independent a-Algebras). Let (0, Â§, P) be a probability space. 
Sub-a-algebras g1, g2 , ... , gn ofÂ§ are considered independent if and only if 
for all sets Gi E gi (1 :=:; i :=:; n ). 
Let gi, i E I (an arbitrary index set) be an arbitrary family of sub-a-algebras of 
$". The gi are deemed independent if and only if gi1 , gi2 , â¢â¢â¢ , gin are independent 
for each finite set { i 1 , i2 , ... , in} of distinct indices in I. 
Measure, Probability, and Mathematical Finance. 
141 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

142 
INDEPENDENCE 
Definition 12.2 (Independent Random Variable). Let (0, Â§, P) be a probability 
space and Xi, i E I be a collection of random variables on 0, where I is an index 
set. The random variables Xi are deemed independent if and only if the sub-a-
algebras a(Xi), i E I are independent, where a(Xi) is the a-algebra generated by 
Xi fori E I (see Definition 11.9). 
Definition 12.3 (Independent Random Variable and a-Algebra). A random variable 
X is said to be independent of a a-algebraÂ§ if and only if a( X) is independent of 
Â§. 
Definition 12.4 (Independent Events). Let (0, Â§, P) be a probability space and 
Ei E Â§ ( i E I) be a collection of events, where I is an index set. The events Ei are 
considered independent if and only if the a-algebras 
are independent. 
Definition 12.5 (Tail a-Algebra). Let {Xn}nEN be a sequence of random variables. 
The tail a-algebra T of the sequence is defined as 
00 
T= n 
~n. 
n=l 
where 
12.2 Problems 
12.1. Let X be a random variable on some probability space (0, Â§, P). Let Â§ 0 = 
{0, 0} be the trivial a-algebra. Show that X is independent of Â§ 0 , that is, a(X) is 
independent of Â§o. 
12.2. Let (0, Â§, P) be a probability space. Let g1, g2 , ... be sub-a-algebras ofÂ§. 
Then g1, g2 , ... are independent if and only if 
P (IJ a,,) ~}] P(G,,) 
for any 1 S i1 < i2 < Â· Â· Â· < ir and all subsets Gi1 E gi1 (1 S j S r). 
12.3. Let (0, Â§, P) be a probability space and g and 1l be sub-a-algebras ofÂ§. 
Let I and ..J be 1r-systems (see Definition 2.15) such that 
g = a(I), 
1l = a(..J). 

PROBLEMS 
143 
Then Q and 1-l are independent if and only if I and .:1 are independent in that 
P(I n J) = P(I)P(J), 
VIE I, VJ E .:f. 
12.4. Let (n, Â§, P) be a probability space and Qi (1 :::; i :::; n) sub-a-algebras of 
Â§. Let Ii ( 1 :::; i :::; n) be 1r -systems such that 
Qi = a(Ii), 
i = 1, 2, ... , n. 
Then Ql, Q2, ... , 9n are independent if and only if I1, I2, ... , In are independent in 
that 
for all sets Ii E Ii. 
12.5. Let Xt, X2, ... , Xn be random variables on (n, Â§, P). Show that X 1, X2, 
... , Xn are independent if and only if 
n 
P{X1 E B1,X2 E B2, ... ,Xn E Bn} =II P{Xi E Bi} 
i=l 
for all sets Bt, B2, ... , Bn E !3(R). 
12.6. Let Xt, X2, ... , Xn be discrete random variables on a probability space (n, 
$", P); that is, Xi assumes either a finite number of values or an infinite sequence 
of values. Show that X 1 , X 2 , ... , Xn are independent if and only if 
n 
P{X1 = x1,X2 = x2, ... ,Xn = xn} =II P{Xi =xi} 
i=l 
for all Xi E {Xi(w) :wE f2}, i = 1, 2, ... , n. 
12.7. Let X 1, X2, ... , Xn be random variables on a probability space (n, Â§, P). 
Let fi : R -+ R be a Borel measurable function fori = 1, 2, ... , n. Show that if 
Xt, X2, ... , Xn are independent, then ft(Xt), h(X2), ... , fn(Xn) are also inde-
pendent. 
12.8. Let X1, X2, ... , Xn be random variables on (n, Â§, P). Let Fi be the distri-
bution function of Xi fori = 1, 2, ... , n, and let F be the distribution function of 
X= (X1, X2, ... , Xn)Â· Show that X1, X2, ... , Xn are independent if and only if 
n 
F(x1, x2, ... , Xn) =II F(xi) 
i=l 

144 
INDEPENDENCE 
12.9 (Second Borel-Cantelli Lemma). Let (0, Â§, P) be a probability space and 
{ En}n>l be a sequence of independent events on 0. If 
00 
LP(En) = 00, 
n=l 
then 
P(lim sup En) = 1. 
12.10 (Kolmogorov's 0-1 Law). Let (0, Â§, P) be a probability space and { Xn}n>l 
be a sequence of independent random variables on 0. LetT be the tail a-algebra for 
Xn (n EN). Then Tis ?-trivial in that 
(a) IfF E T, then P(F) = 0 or P(F) = 1. 
(b) If Y is aT-measurable random variable, then P(Y = c) = 1 for some constant 
c E [-oo, oo]. 
12.11. Let (0, Â§, P) be a probability space. Let A and B be two events. Show that 
A and Bare independent if P(A n B) = P(A)P(B). 
12.12. Let (0, Â§, P) be a probability space. Let A and B be two independent 
events. Show that A and Be are independent, Ac and Be are independent, and Ac 
and Be are independent. 
12.13. Give an example showing that a set of events E 1 , E 2 , ... , En are pairwise 
independent but are not independent. 
12.14. Let (0, Â§, P) be a probability space andii (i = 1, 2, 3) be three 1r-systems 
on 0 such that 
Ii<:;;;Â§andOEii, 
i=1,2,3. 
Show that if 
P(h n h n !3) = P(h)P(I2)P(h), 
\II; E I;, i = 1, 2, 3, 
(12.1) 
then a( h), a(J2), and a( h) are independent. 
12.15. Lets> 1 and ~(s) = L~=l n-s. Let (0, Â§, P) be a probability space, and 
let X andY be two independent N-valued random variables on (0, Â§, P) with 
n-s 
P(X = n) = P(Y = n) = ~(s), 
1::/n EN. 
Show that 
(a) The events Ep (pEP) are independent, where Ep ={wEn: pI X(w)} and 
Pis the set of all prime numbers inN. Here a I b means b is divisible by a. 

HINTS 
145 
(c) P({w En: m 2 f X(w), Vm > 1}) = 1/.;(2s), where a f b means b is not 
divisible by a. 
(d) P(H = n) = n-2s j.;(2s), where His the highest common factor of X andY. 
12.16. Let (n, $", P) be a probability space and Xn (n E N) be a sequence of 
independent random variables that are exponentially distributed with rate 1: 
P(Xn > x) =e-x, 
x 2:0. 
Show that 
P (lim sup l~nn 2: 1) = 1. 
12.17. Let (n, Â§, P) be a probability space and Xn (n E N) be random variables 
on n. Let 7 be the tail a-algebra of Xn (n E N). Show that F1, F2 , and F3 are 
/-measurable, where 
F1 
(lim Xn exists) = {wEn: lim Xn(w) exists}, 
n-+oo 
n-+oo 
F2 
(n~~~ t Xk exists) , 
k=l 
F3 
(lim ~ t Xk exists) . 
n-+oo n k=l 
12.3 Hints 
12.1. Follow the definition of independence (Definition 12.1). 
12.2. Use the definition of independent a-algebras (Definition 12.1) and note that 
n is an element of all sub-a-algebras of$". 
12.3. 
The "only if" part is straightforward. To prove the "if" part, one needs to 
use the unique extension theorem (Theorem 3.2). To do so, one can define two set 
functions J-L1(H) = P(I n H) and J-L2(H) = P(I)P(H) on 1i for fixed IE I and 
show that /-ll = /-l2 on .J. 
12.4. Apply the same argument used to prove Problem 12.3. 
12.5. Follow the definition of independent random variables (Definition 12.2) and 
use the results of Problems 12.4 and 11.10. 
12.6. Use the result of Problem 12.5 
12.7. Use the result of Problem 12.5 

146 
INDEPENDENCE 
12.8. Use the results of Problems 12.5, 11.10, and 12.4 and note that 
12.9. Show that P(nn:;:.:m E~) = 0 and apply the result of Problem 2.19. 
12.10. 
For part (a), one needs to show that 7 and 7 are independent. To do 
this, one can show that rr(X1 , X 2 , Â· Â· Â· , Xn) and 7 are independent. Then show that 
rr(Xn : n E N) and 7 are independent. Part (b) is just a corollary of part (a). 
12.11. Apply the result of Problem 12.3. 
12.12. Apply the result of Problem 12.11. 
12.13. Find an example such that P(Ei n E1) = P(Ei)P(E1) for all i =!= j and 
P(E1 n E2 n Â· Â· Â· n En) =/= P(E1)P(E2) Â· Â· Â· P(En). 
12.14. Apply the result of Problem 12.4 or apply the result of Problem 12.3 to prove 
directly. 
12.15. For part (a), one can show that Ep (p E P) are independent by establishing 
P ( n;=l Ep,j) = IJ;=l P(Ep,j) for all 1 :=:; i1 < i2 < Â· Â· Â· < ir, where Pij are 
prime numbers. Parts (b)-(d) can be derived from part (a). 
12.16. Apply the results of Problems 11.12 and 12.9. 
12.17. For the first equation, use the fact that lim Xn(w) exists if and only if 
limsupXn(w) = liminf Xn(w). 
Other equations can be proved similarly. 
12.4 Solutions 
12.1. By Definition 12.1, we only need to show that for every A E rr(X) and every 
BEffo, 
P(A n B) = P(A) Â· P(B). 
(12.2) 
Since Â§ 0 contains only two elements, we only need to verify that Equation (12.2) 
holds for B = 0 and B = n. 
If B = 0, then P(A n 0) = 0 = P(A) Â· P(0). If B = n, then P(A n D) = 
P(A) = P(A) Â· P(D). This completes the proof. 
12.2. The "if" part is straightforward. Suppose that 

SOLUTIONS 
147 
for any 1 :<:: i1 < i2 < Â· Â· Â· < ir and all subsets Gi1 E Yi1 (1 :<:: j :<:: r). Then by 
choosing r =nand ij = j for j = 1, 2, ... , n, we have 
Hence these sub-o--algebras are independent, by Definition 12.1. 
Now let us prove the "only if" part. Suppose that 91, 92, ... are independent. 
Then we have 
for any n :2: 1 and all subsets Gi E Yi (1 :<:: i :<:: n). 
Let 1 :<:: i1 < i2 < Â· Â· Â· < ir and Gi1 E Yi1 (1 :<:: j < r). Then we define 
H1, H2, ... , Hir as follows: 
if k = ij for some j. 
By assumption and the fact that P(O) = 1, we have 
Hence the "only if" part is valid. This completes the proof. 
12.3. First, suppose that g and H are independent; then by definition, we have 
P(G n H)= P(G)P(H), 
'VG E Q, 'VH E H. 
By hypothesis, we have I <;;; g and J <;;; H. Thus 
P(I n J) = P(I)P(J), 
'VIE I, 'VJ E J. 
Next, suppose that I and J are independent. For fixed I E I, we define two 
functions J..ll : H -+ [0, 1] and J.L2 : H -+ [0, 1] as 
J..l1 (H) = P(I n H), 
J..l2(H) = P(I)P(H). 
We claim that J..ll and J.L2 are measures on (0, H). In fact, noting that Pis a proba-
bility measure on (0, H), we have 
J.L1 (0) = P(0 n H) = P(0) = 0, 
J..l2(0) = P(0)P(H) = 0, 

148 
INDEPENDENCE 
and 
DO 
n=I 
P(I)P (QI Hn) 
DO 
P(J) LP(Hn) 
n=I 
DO 
where Hn (n E N) are mutually disjoint elements of 1i. Therefore, f..LI and J.L2 are 
measures on (0, 1i). Since J.L1 and J.L2 are finite and agree on J, by Theorem 3.2 
they agree on rr(J) = 1i. Hence 
f..LI(H) = J.L2(H), 
VIE I, 't/H E 1i. 
For fixed H E 1i, we define two functions vi : g -t [0, 1] and v2 : g -t [0, 1] as 
vi(G) = P(G n H), 
v2(G) = P(H)P(G). 
Similarly, we can show that v1 and v2 are measures on (0, Q) and agree on I. By 
Theorem 3.2, they agree on a(I) = Q. Thus, g and 1i are independent. 
12.4. 
The argument used to prove this problem is similar to that in the proof of 
Problem 12.3. The "only if' part is obvious. We only prove the "if" part here. 
To do that, we fix Ii E Ii ( i = 2, 3, ... , n) and define two functions f..LI : gi -t 
[0, 1] and VI : gi -t [0, 1] as 
n 
vi(GI) 
= 
P(GI) IJ P(Ii)Â· 
i=2 
In the same way as in Problem 12.3, we can verify that f..LI and VI are measures on 
(0, QI). By hypothesis, f..LI and VI agree on II. By Theorem 3.2, they agree on 
gi = a(II). 

SOLUTIONS 
149 
Then we fix h E ~h and Ii E Ii ( i = 3, 4, ... , n) and define two functions 
JLz : Qz-+ [0, 1] and liz : Qz-+ [0, 1] as 
n 
P(h)P(Gz) II P(Ii)Â· 
i=3 
We can verify that J.Lz and liz are measures on (0, Qz) and agree on Iz. By Theorem 
3.2, they therefore agree on Qz = a(I2). 
Repeating this process, we can show that 
for Ii E giÂ· Since the Ii are arbitrary, by definition 9n (n E N) are independent. 
This completes the proof. 
12.5. First let us prove the "if" part. Let n(Xi) ={{Xi :::; c}: c E R} = {{wE 
n : Xi(w) :S c} : c E R} fori = 1, 2, ... , n. Then n(Xi) is an-system and, by 
Problem 11.10, a(Xi) = a(n(Xi)). 
Let Ii E n(Xi)Â· Then Ii ={Xi :::; ci} for some ci E R. Then by assumption we 
have 
By Problem 12.4, we know that X 1 , Xz, ... , Xn are independent. 
The "only if" part is obvious. Suppose that X1, Xz, ... , Xn are independent. Let 
Bi E B. Then {Xi E Bi} E a(Xi)Â· By assumption we have 
n 
P{X1 E B1, Xz E Bz, ... , Xn E Bn} =II P{Xi E Bi}. 
i=l 
This completes the proof. 
12.6. The "only if" follows from Problem 12.5 directly. We only need to prove the 
"if" part. Suppose that 
n 
P{X1 = X1J Xz = Xz, ... , Xn = Xn} =II P{Xi =xi} 
i=l 

150 
INDEPENDENCE 
for all Xi E {Xi(w) :wE 0}, i = 1, 2, ... , n. Let E 1, E2, ... , En be arbitrary sets 
in B(R), and let Vi= {Xi(w): wE 0} fori= 1, 2, ... , n. Then we have 
P{X1 E E1,X2 E E2, ... ,Xn E En} 
L 
P{Xl = X1,X2 E E2, ... ,Xn E En} 
x,EB,nV, 
L 
L 
P{Xl=Xl,Â·Â·Â·,Xn=Xn} 
x1EB1nV1 
XnEBnnVn 
n 
L 
L II P{Xi =xi} 
n-1 
II P{Xi = x;} 
n II P{Xi E E;}. 
i=l 
By Problem 12.5, X 1 , X 2 , ... , Xn are independent. This completes the proof. 
12.7. By Problem 12.5, we only need to show that 
n 
P{!J (XI) E E1, h(X2) E E2, Â· Â· Â·, fn(Xn) E En}= II P{fk(Xk) E Ek} 
k=l 
for all E 1 , E2, ... , En E B. Note that 
{wE 0: fk(Xk(w)) E Ek} 
{wE 0: Xk(w) E fJ: 1(Ek)} = {Xk E fJ: 1(Ek)} 
fork = 1, 2, ... , n. Since X 1 , X 2 , ... , Xn are independent random variables, we 
have 
n 
P{Xl E f11(El), ... , Xn E J;; 1(En)} = II P{Xk E fJ: 1(Ek)}, 
k=l 
which leads to the results. This completes the proof. 
12.8. 
The "only if" part follows from Problem 12.5. Let us prove the "if" part. 
Suppose that 
n 
i=l 
for all x1, x2, ... , Xn E R. Then 
n 
P{X1 ::=:; X1,X2 ::=:; X2, ... ,Xn ::=:; Xn} =II P{Xi ::=:;xi}. 
i=l 

SOLUTIONS 
151 
for all X1, X2, ... , Xn E R. 
Now let 7r(Xi) = {{Xi ::::; c} : c E R} = {{w E f2 : Xi(w) ::::; c} : c E R} 
fori = 1, 2, ... , n. Then 7r(Xi) is a 7!"-system and, by Problem 11.10, a(Xi) = 
a(7r(Xi)). Then by assumption we have 
for all Ji E 7r(Xi), i = 1, 2, ... , n. By Problem 12.4, we know that X1, X2, ... , Xn 
are independent. This completes the proof. 
12.9. By Definition 11.4, we have 
where 
(limsupEn)c = U Gm, 
m2:1 
Since En (n E N) are independent and 1 - x ::::; e-x, Vx ;::: 0, we have 
Noting that I:~=l P(En) = oo, we have P(Gm) = 0 (mEN). Since the union of 
P-null sets are P-null (see Problem 2.19), we have 
P(limsupEn) = 1- P((limsupEnn = 1- P ( U Gm) = 1. 
m2:1 
This completes the proof. 
12.10. Let 
Xn 
a(X1,X2, ... ,Xn), 
Tn 
a(Xn+l, Xn+l, .. . ), 
and 
lCn 
{{w: Xi(w)::::; Ci, 1::::; i::::; n}: Ci E RU {oo}}, 
Jn 
{{w: Xi(w)::::; Ci, n + 1::::; i}: Ci E RU {oo}}. 
From Problem 11.11, we know that lCn and Jn are 7r -systems that generate Xn and 
T;., respectively. Let K E lCn and JET;.; then K = {w: Xi(w)::::; ci, 1::::; i::::; n} 

152 
INDEPENDENCE 
and J = {w: Xi(w) :::; ci, n + 1 :::; i} for some ci E RU { oo} (i EN). Noting that 
Xn ( n E N) are independent random variables, we have 
P(Kn J) 
P( {w: Xi(w):::; ci, 1:::; i:::; n} n {w: Xi(w):::; ci, n + 1:::; i}) 
P ( (n{w: Xi(w):::; ci}) n (. n {w: Xi(w):::; ci)) 
â¢=1 
â¢=n+1 
P (n{w: Xi(w):::; ci}) P (. n {w: Xi(w):::; ci) 
â¢=1 
â¢=n+1 
P(K)P(J), 
which implies that Kn and .:ln are independent. By Problem 12.3, we know that Xn 
and In are independent. Since T s;; /n, it follows that Xn and Tare independent. 
Let Xoo = rr(Xn : n E N) and Koo = U~= 1 Xn. We claim that Koo is a n-
system and rr(Koo) = X00 â¢ In fact, let A, B E K 00 , then A E Xr and B E X 8 for 
some r, s E N. Assuming r :::; sand noting that Xr s;; X8 , we have A, B E X 8 , 
which implies An B E K00 â¢ Thus, Koo is an-system. Noting that Xn s;; X00 for all 
n E N, we have K 00 s;; X00 which implies rr(Koo) s;; X00 â¢ Also, by definition, we 
have 
X00 
rr(Xn : n EN) 
rr({w: Xn(w) E B}: n E N,B E B) 
0" CQ1 rr(Xn)) , 
we have Xoo s;; rr(K00 ), since U~= 1 rr(Xn) s;; K00 â¢ Thus Xoo = rr(K00 ); that is, 
Koo generates X00 â¢ 
Since Xn and Tare independent for all n E N, it follows that Koo and Tare 
independent. By Problem 12.3, Xoo and Tare independent. 
Since T = n~= 1 In s;; X00 , Tis independent ofT Therefore, for F E T, we 
have 
P(F) = P(F n F)= P(F)P(F) = P(F) 2 , 
which gives P(F) = 0 or P(F) = 1. 
If Y is a T-measurable random variable, then 
P(Y:::; y) = Oor1, 
'Vy E R. 
Let c E R U { -oo, oo} be such that 
c = sup{y : P(Y :::; y) = 0}. 

SOLUTIONS 
153 
If c = -oo, then P(Y = -oo) = 1. If c = oo, then P(Y = oo) = 1. If 
- oo < c < oo, then, by Problems 2.19 and 11.1, we have 
P(Y <c) 
P(Y :S c) 
which gives 
This completes the proof. 
p CQl { y :::; c- ~}) = 0, 
p (!51 { 
y:::; c + ~}) = 1, 
P(Y =c)= 1. 
12.11. By definition, events A and Bare independent if the a-algebras Â£1 = {0, A, 
Ae, D} and Â£2 = {0,B,Be,n} are independent. However, Â£1 = a({A}) and 
Â£2 =a( { B} ). Thus the result follows from Problem 12.3. 
12.12. By Problem 12.11, to show that A and Be are independent we only need to 
prove P(A n Be) = P(A)P(Be). But P(A n Be) = P(A)- P(A n B)= P(A)-
P(A)P(B) = P(A)P(Be). Thus A and Be are independent. Other implications 
can be proved similarly. 
12.13. Let D = {1, 2, 3, 4}, ff = 211 , and P(i) = 0.25 fori= 1, 2, 3, 4. Let E 1 = 
{1, 2}, E2 = {2, 3}, and E3 = {1, 3}. Then P(Ei n Ej) = 0.25 = P(Ei)P(Ej) 
fori -1- j. But P(E1 n E2 n E3) = P(0) = 0 -1- P(EI)P(E2)P(E3). 
12.14. By hypothesis D E Ii (i = 1, 2, 3) and Ii (i = 1, 2, 3) are 1r-systems on D, 
and from (12.1) we have 
P(h n h n D) = P(h)P(I2)P(D), 
VIi E Ii, i = 1, 2. 
Since P(D) = 1, the above equation gives 
P(h n I2) = P(h)P(I2), 
VIi E Ii, i = 1, 2. 
By Problem 12.3, a( h) and a(I2 ) are independent. 
Now we define Cas 
(12.3) 
We can verify that C is a 1r-system on D. In fact, let I, J E C, then I = h n h 
and J = J1 n h for some h, J1 E I1 and h, J2 E I 2, respectively. But, In J = 
(h n h) n (J1 n J2) = (h n JI) n (I2 n J2). Noting that I1 and I2 are 1r-systems, 
we have I1 n J1 E I1 and h n J2 E I2, which lead to In J E C. Thus, Cis a 
1r-system. 
We claim that a(C) and a(I3 ) are independent. In fact, let I E a(C) and h E I 3 , 
then I = h n I2 for some h E I 1 and I2 E I 2 and 
P(I n I3) = P(h n I2 n h) = P(h)P(I2)P(h). 
(12.4) 

154 
INDEPENDENCE 
Since a(II) and a(I2 ) are independent, we have P(I) = P(h ni2 ) = P(h)P(I2). 
Thus from (12.4) we have 
P(I n h) = P(I)P(I3). 
Since I and ! 3 are arbitrary, by Problem 12.3, a( C) and a( h) are independent. 
Since 0 E Ii (i = 1, 2), from (12.3) we have Ii ~ C (i = 1, 2). Thus, a(Ii) ~ 
a( C) (i = 1, 2). Now let Ai E a(Ii) (i = 1, 2, 3), then A1 , A2 E a( C). Since a( C) 
and a(I3) are independent, we have P(A1 n A2 n A3) = P(A1 n A2)P(A3). Since 
a(h) and a(/2 ) are independent, we have P(A1 n A2 ) = P(AI)P(A2). Therefore 
P(A1 n A2 n A3) = P(A1 n A2)P(A3) = P(AI)P(A2)P(A3), 
which implies that a( h), a(I2), and a( h) are independent. 
12.15. 
(a) By definition of independent events, to show that Ep (p E P) are independent 
we need to show that 
Ep = {0, Ep, 0\Ep, 0}, 
p E P 
are independent. Note that Ep (p E P) are n-systems and Ep = a( { Ep} ), by 
Problem 12.4 we only need to show {Ep} (pEP) are independent. 
To do this, let P = {Pl, P2, ... } such that P1 < P2 < P3 < Â· Â· Â· , and let r E N 
and ij EN (j = 1, 2, ... , r) such that 1 :<::; i1 < i2 < Â· Â· Â· < ir; then n;=l Ep,j 
is the set of samples w for which X ( w) are divisible by fl;=l Pij: 
{ wEn: ITPij I X(w)} 
J=l 
{ wEn: X(w) = n ITPij' n EN}. 
J=l 
Thus, 
(12.5) 
Note that, for any pEP, we have 
Ep = {w: pI X(w)} = {w: X(w) = np, n EN}, 
which gives 
(12.6) 

SOLUTIONS 
155 
In particular, we have 
T 
r 
IT P(Ep;i) = ITP~s. 
(12.7) 
j=l 
j=l 
Combining (12.5) and (12.7) gives 
Therefore, Ep (p E P) are independent. 
(b) On one hand, we have P(X = 1) = 1/c;-(s). On the other hand, X = 1 if and 
only if p f X, \fp E P; that is, 
{w: X(w) = 1} = {w: p f X(w), \fp E P} = n 
E~. 
pEP 
Since Ep (pEP) are independent, we have 
P(X = 1) = P({w: X(w) = 1}) = p ( n E~) =IT (1- p- 8 ). 
pEP 
pEP 
Therefore, 
(12.8) 
(c) Noting that m 2 f X \fm > 1 if and only p2 f X \fp E P, we have 
{wE 0: m 2 f X(w), \fm > 1} 
{wEO:p2 fX(w), \/pEP} 
n 
a~, 
pEP 
where 
Gp ={wEn: p2 I X(w)} ={wEn: X(w) = np2 \:In EN}. 
Using the same argument as in the first part of this proof, we can show that 
Gp (pEP) are independent and 
P(Gp) = p-2s. 
Then 
P({w E 0: m 2 f X(w), Vm > 1}) 
p (n a~) 
pEP 
IT (1- p-2s). 
(12.9) 
pEP 

156 
INDEPENDENCE 
Since (12.8) holds for any s > 1, we have 
1 
IJ( 
-2s) 
-(-)= 
1-p 
. 
<;" 2s 
pEP 
Combining (12.9) and (12.10) gives 
P({w E 0: m 2 f X(w), \/m > 1}) = ~(~s)" 
(12.10) 
(d) Note that gcd(X, Y) = n if and only if there exist k, l E N such that X = kn, 
Y = ln, and gcd(k, l) = 1, where gcd(X, Y) denote the highest common 
factor of X andY. For n E N, we define events Fn as 
Fn = {H = n} = {w: X(w) = kn, Y(w) = ln, (k, l) E I}, 
where I = { (k, l) : k, l E N, gcd(k, l) = 1 }. Since X andY are independent, 
we then have 
P(Fn) = L P(X = kn, Y = ln) = L P(X = kn)P(Y = ln) 
(k,l)El 
( kn) -s (ln) -s 
L-Â·-
(k,l)El 
<;"(s) 
<;"(s) 
-2s '"""' k-s z-s 
n 
6 -Â·-
(k,l)EI ~(s) <;"(s) 
n- 2s P(FI). 
(k,l)El 
(12.11) 
Noting that Fn (n EN) are mutually disjoint and U~=l Fn = n, we have 
which results in 
1 
P(F1) = 2.::= 
_28 
n=ln 
Thus, from (12.11) we get 
n-2s 
P(Fn) = -( -). 
<;" 2s 
12.16. We define events En ( n E N) as 
1 
<;"(2s)Â· 
{ 
X(w) 
} 
En = { Xn ~ log n} = 
w E n : -- ~ 1 
. 
logn 

Then 
Note that 
and 
{limsup l~nn 2:: 1} = limsupEnÂ· 
1 
P(En) = P(Xn 2:: logn) = -, 
n 
00 
00 1 
LP(En) = L- = 00. 
n=l 
n=l n 
SOLUTIONS 
157 
By the second Borel-Cantelli theorem (see Problem 12.9), we have 
P(limsupEn) = 1, 
which gives 
P (lim sup l~nn 2:: 1) = 1. 
12.17. Let In= a(Xn+1,Xn+2 , Â· Â· Â·) (n EN). By Definition 11.9, we have 
/n = a({w E !1: Xm(w) E B}, m 2:: n+ 1,B E B). 
To prove that F 1, F2, and F3 are T-measurable, we only need to show that F 1 , F2, 
and F3 are In-measurable for all n EN. 
Noting that limn--+oo an exists if and only if lim sup an = lim inf an, we have 
F1 
{wE !1: limsupXn(w) = liminf Xn(w)} = h11(0), 
F2 
{wE !1: limsup txk(w) = liminfXk(w)} = h21 (0), 
k=l 
{ 
1 
n 
1 
n 
} 
F3 
wE !1: lim sup; LXk(w) = liminf; LXk(w) = h3 1 (0), 
k=l 
k=l 
where 
hl(Xn) 
limsupXn -liminf Xn, 
h2 (~xk) 
n 
n 
limsup LXk -liminfLXk, 
k=l 
k=l 
h3 (~~xk) 
1 n 
1 n 
lim sup-I: xk -liminf-I: xk. 
n 
n 
k=l 
k=l 
For fixed N E N, to show that F1 is TN-measurable, we only need to show that 
limsupXn and liminf Xn are TN-measurable. By Problem 5.7, we only need to 
show that 
{limsupXn:::; c} E TN, 
{liminf Xn:::; c} E TN 

158 
INDEPENDENCE 
for all c E R. Note that 
j?_l i?_j 
j?_N +1 i?_j 
and 
{Xi> c} E TN, 
Vi 2:: N + 1, 
We have {lim sup Xn :::; c} E TN. Similarly, we can show that {lim inf Xn :::; c} E 
TN. Hence, F1 is TN-measurable. 
Regarding F2 , we have 
{ limsup txk:::; c} 
k=l 
WJ, {t,x. ~ c} 
;!)+,Y, {t,x, ~ c} 
{ 
i 
N 
} 
j?_(L ~ k];+l xk :::; c-t; xk . 
Since { L~=N+l xk:::; c- L~=l xk} are Twmeasurable, we have 
{ limsup txk:::; c} E TN. 
k=l 
Similarly, we can show that 
{ liminftxk:::; c} E TN. 
k=l 
Thus, F2 is TN-measurable. 
Similarly, for F3 we have 
{ lim sup~ txk:::; c} 
k=l 
,QY, H t,x, ~c} 
j?_Q+l~ { ~ ~xk:::; c} 
{ 
i 
N 
} 
j?_Q+l i~ k];+l xk :::; ic-t; xk . 
Since { L~=N+l xk :::; ic- L~=l xk} are TN-measurable, we have 
{ limsup~ txk:::; c} E TN. 
k=l 

BIBLIOGRAPHIC NOTES 
159 
Similarly, we can show that 
{ liminf ~ t Xk s; c} E TN. 
k=l 
Thus, F3 is TN-measurable. 
12.5 Bibliographic Notes 
In this chapter, we introduced the concept of independence in probability theory. 
Mathematically, definition of the independence of random variables and events is 
based on the independence of a-algebras. For more information on independence, 
readers are referred to Williams (1991), Ash and Doleans-Dade (1999), and <;inlar 
(2011). 


CHAPTER13 
EXPECTATION 
In probability theory, the expectation of a random variable is the integral of the ran-
dom variable with respect to its probability measure. For example, the expectation 
of a discrete random variable is the weighted average of all possible values that the 
random variable can take on. In this chapter, we shall introduce the definition of 
expectation and relevant concepts. 
13.1 
Basic Concepts and Facts 
Definition 13.1 (Expectation). Let (0, $, P) be a probability space and X E Â£ 1 (0, 
$, P), where Â£ 1(0, $, P) denotes the set of all P-integrable functions on 0 (see 
Definition 6.4). The expectation E(X) of X is defined as 
E(X) = k X(w)P(dw) = k XdP. 
Measure, Probability, and Mathematical Finance. 
161 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

162 
EXPECTATION 
Definition 13.2 (Expectation over Subsets). Let (0, Â§, P) be a probability space, 
FEÂ§, and X be a random variable on 0. Then E(X; F) is defined as 
where 
E(X;F) = t X(w)P(dw) = t XdP = E(Xlp), 
]p(w) = {1, if wE F; 
0, 
ifwt}_F. 
Definition 13.3 (Integration with Respect to Distribution Functions). Let F be a dis-
tribution function on R n and let JL be the corresponding Lebesgue-Stieltjes measure. 
Let g be a Borel function from R n to R. Then the integration of g with respect to 
the distribution function F is defined as 
{ g(x)dF(x) = 
{ 
gdJL. 
}Rn 
}Rn 
Definition 13.4 (Covariance and Variance). Let (0, Â§, P) be a probability space 
and X, Y E Â£ 2(0, Â§, P). Then, by the monotonicity of norms (see Problem 8.5), 
X, Y E Â£ 1(0, Â§, P). Let X =X- JLx andY= Y- JLy, where JLx = E(X) 
and JLY = E(Y). Then X, Y E Â£ 2 (0, Â§, P) and so XY E Â£ 1(0, Â§, P). The 
covariance of X and Y is defined as 
Cov(X, Y) = E(XY) = E[(X- JLx)(Y- JLY)]. 
The variance of X is defined as 
Var(X) = Cov(X, X). 
Definition 13.5 (Moment, Central Moment and Absolute Moment). Let X be a ran-
dom variable on the probability space (0, Â§, P). Let k > 0. Then the kth moment 
of X is defined as 
The kth absolute moment of X is defined as 
If E(X) is finite, then the kth central moment of X is defined as 
and the kth absolute central moment of X is defined as 
E(IX- E(xW). 

PROBLEMS 
163 
The first moment of X is also called the mean of X. The second absolute central 
moment of X is also called the variance of X. 
Definition 13.6 (Correlation). Let X, Y E L2(fl, .Â§, P). Then the correlation of X 
and Y is defined as 
Corr(X Y) = 
Cov(X, Y) 
' 
Jvar(X)Var(Y) 
where Jlx = E(X) and JlY = E(Y). 
E[(X- J.Lx)(Y- J.Ly)] 
IIXII2 Â·IIYII2 
Theorem 13.1. Let X be a random variable on the probability space (fl, .Â§, P), 
and let g a Borel function from R toR. Let Y =go X. Then 
E(Y) = L 
gdPx = L 
g(x)dF(x), 
where F is the distribution function of X. 
If X has a density function f, we have 
E(Y) = L 
g(x)f(x)dx. 
Theorem 13.2. Let (fl, .Â§, P) be a probability space, and let X andY be inde-
pendent random variables on n such that X,Y E L 1(fl,.Â§,P). Then XY E 
L 1(fl,.Â§,P)and 
E(XY) = E(X)E(Y). 
13.2 Problems 
13.1. Let n = (2, oo) and.Â§ = B(fl). Let X be a random variable on (fl, .Â§) with 
the following distribution function: 
if X E (oo, 2]; 
if X E (2, 3); 
if X E [3, oo). 
Compute E(X2 ). 
13.2. Let (fl, .Â§, P) be a probability space and X E (m.Â§)+ such that E(X) < oo. 
Show that P(X < oo) = 1. 
13.3. Let (fl, .Â§, P) be a probability space, and let {Zn}n>l be a sequence of ele-
ments of ( m.Â§) +. Show that 
-

164 
EXPECTATION 
13.4. Let Xi (i = 1, 2, ... , n) be random variables on a probability space (rl, ~' P) 
with finite expectations. Show that 
13.5. Let (rl, ~, P) be a probability space and { Zn }n:;::l be a sequence of elements 
of ( m~) + such that 
00 
LE(Zn) < 00. 
n=l 
Show that :L:=l Zn < oo a.s. and Zn -+ 0 a.s. 
13.6. Let Xi E L 2 (rl, ~' P) fori= 1, 2, ... , n. Show that 
13.7. Let X, Y be independent elements of L 2 (rl, ~' P). Show that 
Cov(X, Y) = 0 
and 
Var(X + Y) = Var(X) + Var(Y). 
13.8. Let X, Y be elements of L 2(rl, ~' P). Show that X andY are independent if 
and only if 
E[g(X)h(Y)] = E[g(X)] Â· E[h(Y)] 
for all g, h : R-+ R such that the expectations exist. 
13.9. Let (rl, ~' P) be a probability space. Suppose that X is a random variable on 
(rl, ~' P) that assumes only nonnegative integer values. Show that 
00 
E(X) = L P{X > k}. 
k=O 
13.10. Let (rl, ~' P) be a probability space. Suppose that X is a nonnegative ran-
dom variable on (rl, ~' P). Show that 
E(X) = loo P{X > A}dA. 
13.11. Let (rl, ~' P) be a probability space. Let X andY be random variables on 
(rl, ~' P). Suppose that Y is nonnegative. Show that 

HINTS 
165 
13.12. Let X be a nonnegative random variable on some probability space ( !1, .?/, 
P). Let f be a function on [0, oo) such that f has a nonnegative continuous first 
derivative (i.e., f' ~ 0). Show that 
E[f(X)] = f(O) + 1= f'(>..)P{X ~ >..}d>... 
13.13. Let X be a nonnegative random variable on the probability space (!1, .?/, P). 
Suppose that E(X) < oo. Show that 
lim nP{X > n} = 0. 
n-+oo 
13.14. Let X 1 , X 2 , ... be a sequence of identically distributed random variables on 
a probability space (!1, .?/, P). Suppose that 
Show that 
13.3 Hints 
13.1. Use Theorem 13.1. 
P {lim sup IXnl ::::; 1} = 1. 
lnn 
13.2. Consider the sequence of sets An = {X < n} for n = 1, 2, ... and use the 
results of Problem 15.2 and Theorem 2.1. 
13.3. Consider the partial sums Sn = Z1 + Z2 + Â· Â· Â· + Zn for n ~ 1 and apply 
Theorem 6.2. 
13.4. Use the definition of integration (see Definition 6.4) and the result of Problem 
13.3. 
13.5. The first conclusion is implied from Problems 13.2 and 13.3. For the second 
conclusion, one can use the inequality 0::::; Zn ::::; S- Sn_ 1, where Sn = Z1 + Z2 + 
Â· Â· Â· + Zn and S = 2:~= 1 Zn. 
13.6. Follow the definition of variances and covariances (Definition 13.4). 
13.7. Apply Theorem 13.2 and the result of Problem 13.6. 
13.8. The "if" part can be proved by using the result of Problem 12.5 and special 
cases of g and h. The "only if" part can be proved by using the result of Problem 
12.5 and Theorem 13.2. 

166 
EXPECTATION 
13.9. 
Follow the definition of expectation (Definition 1301) and use the result of 
Problem 6021 to show that 
00 
E[X] = LkP{X = k}o 
k=l 
13.10. Apply Tonelli's theorem (Theorem lOol)o 
13.11. 
Apply Tonelli's theorem (Theorem 1001)0 The proof is similar to Problem 
130100 
13.12. Use Tonelli's theorem (Theorem 10o1)o 
13.13. Note that 
E(X) = ( 
XdP+ ( 
XdP 
}{X>n} 
}{X<:n} 
and use Theorem 6020 
13.14. Use the results of Problems 11.12 and 1309 and Theorem 2020 
13.4 Solutions 
13.1. The distribution function F has the following density function: 
if X E (oo, 2]; 
ifx E (2,3); 
iLc E [3,oo)o 
Then, by Theorem 13 01, we have 
1
0 
13 2 
38 
E(X2 ) = 
x 2.f(x)dx = 
-x2dx = - 0  
R 
2 3 
9 
13.2. Let An = {X < n} for n = 1, 2, 0 0 .. Then Ant {X < oo }0 By hypothesis, 
X is nonnegative and E(X) < ooo Then, by Problem 1502, we obtain 
which implies 
nP(X ::>: n) :::; E(X) < oo, 
1 
P(An) = 1- P(X ::>: n) ::>: 1- -E(X)o 
n 
Therefore, P(An) -t 1. Recalling that An t {X < oo }, we have, by Theorem 201, 
P(An) t P({X < oo})o HenceP({X < oo}) = 1. 

SOLUTIONS 
167 
13.3. 
By hypothesis, Zn ( n 2: 1) are nonnegative random variables on D. Then 
Sn = Z1 + Z2 + Â· Â· Â· + Zn (n 2: 1) are also nonnegative random variables on D. By 
Problem 6.12, we have 
(13.1) 
Noting that Sn E (rnÂ§)+ and Sn t I;%: 1 Zko by Theorem 6.2, we have 
(13.2) 
Combining Equations (13.1) and (13.2), we get 
This completes the proof. 
13.4. Let xt and xi- be the positive and negative parts of Xi, respectively. Then 
Xi = Xt -xi-. By the assumption that Xi has finite expectation and by Definition 
6.4, we have E(Xt) < oo, E(xi-) < oo, and 
By Problem 13.3, we have 
E (~xt) = ~E(Xt) 
( 13.3) 
and 
E (~xi-) = ~ 
E(xi-). 
(13.4) 
Subtracting Equation (13.4) from Equation (13.3) gives 
This completes the proof. 
13.5. We first show that 2:::~= 1 Zn < oo a.s. Since, by hypothesis, I:~=l E(Zn) 
< oo, we have, by Problem 13.3, E (2:::~= 1 Zn) < oo. Therefore, by Problem 13.2, 
2:::~= 1 Zn < oo a.s. 
Next, we show that Zn --t 0 a.s. Let Sn = Z1 +Z2+Â· Â· Â·+Zn and S = 2:::~= 1 Zn. 
Then Sn t S. Recall that S < oo a.s., we haveS- Sn + 0 a.s. Since 0 ~ Zn ~ 
S- Sn- 1 for every n 2: 2, we have Zn --t 0 a.s. This completes the proof. 

168 
EXPECTATION 
13.6. 
Since, by hypothesis, X; E L2 (0, :#, P) for i = 1, 2, ... , n, we have 
X 1 + X 2 + Â· Â· Â· + Xn E L2 (0, :#, P) and X;, X 1 , X;Xj E L 1(0, :#, P). Then 
g [(~(X, -tâ¢d)'] 
g [~(X,- M;)' + 2 ~'~'(X, -p,)(XJ -Iâ¢J)l 
n 
n 
n 
2:: E[(X;- fL;) 2] + 2 2:: 2:: E[(X;- fL;)(Xj- /Lj)] 
i=l 
i=l j=i+l 
n 
n 
n 
2:: Var(X;) + 2 2:: 2:: Cov(X;, XJ), 
i=l 
i=l j=i+l 
where fL; = E(X;) fori= 1, 2, ... , n. 
13.7. 
Since X and Y are independent, we have, by Theorem 13.2, E(XY) 
E(X)E(Y). Then 
Cov(X, Y) = E[(X- E(X))(Y- E(Y))] = E(XY)- E(X)E(Y) = 0, 
and so, by Problem 13.6, we have 
Var(X + Y) = Var(X) + Var(Y) + 2Cov(X, Y) = Var(X) + Var(Y). 
13.8. Let us first prove the "if" part of this problem. To do that, we assume that 
E[g(X)h(Y)] = E[g(X)] Â· E[h(Y)] 
for all g, h : R-+ R such that the expectations exist. Let B 1 , B2 E B(R) and define 
h.h: R-+ Ras 
h(X) = eÂ· 
if X E B1; 
0, 
if X tf. B 1, 
and 
h(Y) = eÂ· 
ifY E B2; 
0, 
ifY tf. B2, 
Then by assumption, we have E[h(X)h(Y)] = E[!J(X)] Â· E[h(Y)]. But note 
that 
E[fi(X)_h(Y)] = E[IB,xB 2 (X, Y)] = P(X1 E B1, Y E B2) 
and 
E[fi(X)] = E[IB, (X)]= P(X E BI), 
E[_h(Y)] = E[IB2 (Y)] = P(Y E B2), 

SOLUTIONS 
169 
we have P(X E B1 , Y E B2 ) = P(X E Bl) Â· P(Y E B2 ). By Problem 12.5, we 
know that X and Y are independent. 
Now we prove the "only if" part. Suppose that X and Y are independent. We 
claim that g(X) and h(Y) are also independent for any functions g and h. To prove 
this claim, let B1, B 2 E B(R). Then we have g- 1 (Bl), h- 1 (B2) E B(R). Hence, 
by Problem 12.5, we have 
P(X E g- 1(Bl), Y E h- 1(B2 )) 
P(X E g- 1(Bl)) Â· P(Y E h- 1(B2 )) 
P(g(X) E Bl) Â· P(h(Y) E B2). 
Hence g(X) and h(Y) are independent. The result follows from Theorem 13.2. 
This completes the proof. 
13.9. By Definition 13.1 and Problem 6.21, we have 
E[X] = l XdP 
l ~ 
kJ{X=k}dP 
f k { I{X=k}dP 
k=1 Jn 
00 
LkP{X = k}. 
k=1 
Note that P{X = k} = P{X > k- 1}- P{X > k}. We have 
00 
00 
Lk(P{X > k -1}- P{X > k}) 
k=1 
00 
00 
LkP{X > k -1}- LkP{X > k} 
k=1 
k=1 
00 
00 
L(k + 1)P{X > k}- L kP{X > k} 
k=O 
k=1 
00 
LP{X > k}. 
k=O 
This completes the proof. 
13.10. Note that for each w E D, we have 
{X(w) 
roo 
X(w) = Jo 
d).= Jo 
I[o,X(w))(>.)d>.. 

170 
EXPECTATION 
Then, by Theorem 10.1, we have 
E(X) 
L XdP 
This completes the proof. 
k loo I[o,x)(.A)d.AdP 
1
00 k 
I[o,x)(>.)dPd>. 
1
00 L I{X>>-}dPd>. 
loo P{X > .A}d.A. 
13.11. Note that for each w E D, we have 
{Y(w) 
roo 
Y(w) = Jo 
d).= Jo 
I[o,Y(w))(>.)d>.. 
Then by Theorem 10.1, we have 
E(XY) 
This completes the proof. 
foxYdP 
k 
X 1
00 I[o,Y)(>.)d>.dP 
1
00 k 
XI[o,Y)(>.)dPd>. 
1
00 LX I{Y>>-}dPd>. 
loo E [XI{Y>>-}] d.A. 
13.12. By the definition of expectations, we have 
E[f(X)] = L f(X)dP = 1
00 f(x)P(dx) = 1
00 (t(O) +lax f'(>.)d>.) P(dx). 
Then by Theorem 10.1, we have 
E[f(X)] 
f(O) + loo j'(>.) 1
00 P(dx)d>. 
f(O) + loo j'(>.)P{X 2: .A}d.A. 

SOLUTIONS 
171 
This completes the proof. 
13.13. For arbitrary integer n, we have 
E(X) = 1 
XdP + 1 
XdP. 
{X>n} 
{X:5n} 
Since X is nonnegative, the above equation leads to 
E(X) ~ nP{X > n} + 1 
XdP. 
{X:5n} 
Note that X I{x::;n} t X as n--+ oo. By Theorem 6.2, we have 
lim 1 
XdP = E(X). 
n-+oo {X:5n} 
The result follows by the assumption that E(X) is finite. This completes the proof. 
13.14. To prove this problem, we only need to show that 
P {lim sup ~~~~ > 1} = 0. 
By Problem 11.12, we have 
{limsup ~~~~ > 1} =lim sup { ~~~~ > 1}. 
Hence we only need to show that 
P (lim sup { 
11~~~ > 1}) = 0. 
Note the assumption that X 1 , X 2 , ... are identically distributed and that 
E [exp(IX11)] < oo. 
By Problem 13.9, we have 
00 
LP{IXkl > lnk} 
k=l 
k=l 
00 
LP{eiX1I > k} 
k=l 
E [eiX1I] _ p { eiX1I > 0} 
< 
00. 
By Theorem 2.2, Equation (13.5) holds. This completes the proof. 
(13.5) 

172 
EXPECTATION 
13.5 Bibliographic Notes 
In this chapter, we introduced the concept of expectation, variance, covariance, and 
moments. We defined expectations on the basis of integration with respect to prob-
ability measures. In some books such as Bartoszynski and Niewiadomska-Bugaj 
(2007), expectations are defined in terms of densities. For more information on 
expectations, readers are referred to Williams ( 1991, Chapters 6 and 7), Ash and 
Doleans-Dade (1999), and (,":inlar (2011). 

CHAPTER14 
CONDITIONAL EXPECTATION 
In probability theory, the conditional expectation is the expected value of a random 
variable given some information represented by a a-algebra. The conditional ex-
pectation defined on the basis of a a-algebra is again a random variable satisfying 
certain properties. In this chapter, we present the definition of conditional expecta-
tions based on this approach. 
14.1 
Basic Concepts and Facts 
Definition 14.1 (Conditional Expectation of a Random Variable Given a a-Algebra). 
Let (n, Â§, P) be a probability space, and X a random variable with E(IXI) < oo. 
Let Q be a sub-a-algebra ofÂ§. Then a version of the conditional expectation of X 
given Q is defined to be a random variable Y (see Theorem 14.1) such that 
(a) Y is 9-measurable. 
(b) E(IYI) < 00. 
Measure, Probability, and Mathematical Finance. 
173 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

17 4 
CONDITIONAL EXPECTATION 
(c) For every G E Q, we have 
fc YdP = fc XdP. 
The version of the conditional expectation of X given Q is written as Y = E(XIQ) 
a.s. 
Definition 14.2 (Conditional Expectation of a Random Variable Given a Random 
Variable). Let X andY be random variables on some probability space (0, Â§, P) 
with E(IXI) < oo. The conditional expectation ofY given X, written as E[YIX], is 
defined as E[Yiu(X)]. Similarly, E(XIZ1 , Z2 , ... ) stands for E(XIu(Z1 , Z2 , ... )). 
Definition 14.3 (Conditional Expectation of a Random Variable Given an Event). 
Let Y be a random variable on some probability space (0, Â§, P). Let H E /#. 
Then the conditional expectation of Y given H, written as E[YIH], is defined as 
E[Yiu(IH )], where IH is the indicator function of H. 
Definition 14.4 (Conditional Probability of an Event Given au-Algebra). Let (0, 
Â§, P) be a probability space and Q a sub-u-algebra of /F Let B E .'#. Then 
a version of the conditional probability of B given Q is defined to be a function 
Y : (0, Q) --+ (R, B) (see Theorem 14.2) such that 
P( A n B) = l Y dP, 
A E Q. 
The version of the conditional probability of B given Q is written as P(BIQ). 
Note that E[IsiQ] is a version of the conditional probability of B given Q. We 
also write 
P(BIQ) = E[Isl9]. 
Definition 14.5 (Conditional Probability of an Event Given a Random Variable). Let 
(0, Â§, P) be a probability space and Q be a sub-u-algebra ofÂ§. Let BE.'#, and let 
X be a random variable on the probability space. Then a version of the conditional 
probability of B given X is defined as 
P(BIX) = P(Biu(X)) = E[Islu(X)]. 
Then P(BIX) is a u(X)-memasurable function. By Theorem 11.2, there exists a 
Borel function f such that P(BIX) = f(X). The conditional probability P(BIX = 
x) is defined as 
P(BIX = x) = f(x). 
Definition 14.6 (Conditional Probability of an Event Given an Event). Let G and H 
be two events. The conditional probability of H given G is defined to be any number 
P(HIG) in [0, 1] satisfying 
P(G n H)= P(G) Â· P(HIG). 

PROBLEMS 
175 
This number is unique if P( G) > 0. 
Theorem 14.1. Let (n, $, P) be a probability space, and X a random variable 
with E(IXI) < oo. Let Q be a sub-a-algebra of$. Then there exists a random 
variable Y such that 
(a) Y is Q-measurable. 
(b) E(IYI) < oo. 
(c) For every G E Q, we have 
i YdP= i XdP. 
Moreover, ifY is another random variable satisfying (a)-( c), then Y = Y a.s. 
Theorem 14.2. Let (n, $, P) be a probability space and Q a sub-a-algebra of$. 
Let B E $. Then there exists a function Y : (n, Q) ---+ (R, B) such that 
P(AnB) = i YdP, 
A E Q. 
In addition, ifY is another such function, then Y = Y a.s. 
14.2 Problems 
14.1. Let (n, $, P) be a probability space and Q a sub-a-field of$. Let X E 
L1(n, $, P). Use the Radon-Nikodym theorem to show thatthereis aQ-measurable 
random variable Y such that E (I Y I) < oo and 
i X dP = i Y dP, 
VA E Q. 
14.2. Let (n, $, P) be a probability space, and let X be a random variable with 
E(IXI) < oo. Let Q be a sub-a-algebra of$. Suppose that Y is random variable 
with the following properties: 
(a) Y is Q-measurable. 
(b) E(IYI) < oo. 
(c) For every G E I, where I is a 1r-system that contains nand generates Q, we 
have 
i YdP= i XdP. 

176 
CONDITIONAL EXPECTATION 
Show that Y = E(XIQ) a.s. 
14.3. Let (0, Â§, P) be a probability space and X be a random variable on 0 with 
E(IXI) < oo. Let g be a sub-a-algebra ofÂ§. Show that if Y is a version of 
E(XIQ), then E(Y) = E(X). 
14.4. Let (0, Â§, P) be a probability space and X be a random variable on 0 with 
E(IXI) < oo. Let g be a sub-a-algebra ofÂ§. Show that if X is Q-measurable, then 
E(XIQ) =X a.s. 
14.5 (Linearity). Let (0, Â§, P) be a probability space, and let X 1 and X2 be random 
variables on 0 with E(IX1I) < oo and E(IX2I) < oo. Let g be a sub-a-algebra of 
Â§. Show that for a1, a2 E R, E(a1X1 + a2X2IQ) = a1E(XIIQ) + a2E(X2IQ) 
a.s. 
14.6 (Positivity). Let (0, Â§, P) be a probability space and X be a random variable 
on 0 with E(IXI) < oo. Let g be a sub-a-algebra ofÂ§. Show that if X 2': 0, then 
E(XIQ) 2': o a.s. 
14.7 (Conditional Monotone Convergence). Let (0, Â§, P) be a probability space, 
and let X be a random variable on 0 with E(IXI) < oo. Let g be a sub-a-algebra 
ofÂ§. Show that ifO :S Xn t X, then E(Xnl9) t E(XIQ) a.s. 
14.8 (Conditional Fatou's Lemma). Let (0, Â§, P) be a probability space and let 
{Xn}n>l be a sequence of nonnegative random variables on 0 with E(IXnl) < oo. 
Let g be a sub-a-algebra ofÂ§. Show that E(lim inf Xn 19) ::::; lim inf E(Xn IQ) a.s. 
14.9 (Conditional Dominated Convergence). Let (0, Â§, P) be a probability space. 
Let {Xn}n;:::1 be a sequence of random variables on 0 such that IXnl ::::; V for 
n 2': 1, where Vis a random variable with E(V) < oo, and Xn ---t X a.s. Let g be 
a sub-a-algebra ofÂ§. Show that E(Xnl9) ---t E(XIQ) a.s. 
14.10 (Tower Property). Let (0, Â§, P) be a probability space and X be a random 
variable on 0 with E(IXI) < oo. Let g be a sub-a-algebra ofÂ§ and 1i be a sub-a-
algebra of g. Show that 
E(XIQIH) = E(XIH), 
where E(XIQIH) = E[E(XIQ)IH]. 
14.11. Let X be a random variable on some probability space (0, Â§, P). Show that 
E[E[X]] = E[X] 
a.s. 
14.12. Let (0, Â§, P) be a probability space and X be a random variable on 0 with 
E(IXI) < oo. Let g be a sub-a-algebra ofÂ§. Show that if Z is Q-measurable and 
bounded, then E(ZXIQ) = ZE(XIQ) a.s. 
14.13. Let X : (0, ~) ---t (E, C:) and Y : (0, Â£') ---t (F, Â§) be two random 
variables. Let <I> be a nonnegative Borel function on (E x F, C: 0 Â§). Let rp : 
( E, C:) ---t ( [0, oo), .6[0, oo)) be defined by 
rp(x) = E[<I>(x, Y)], 
x E E. 

PROBLEMS 
177 
Suppose that Y is independent of<;1'. Show that 
E[<I>(X, Y)l<;1'] = cp(X) 
a.s. 
14.14. Let (0, Â§, P) be a probability space. Let p > 1 and 1/p+ 1/ q = 1. Suppose 
that X E LP(O, Â§, P) and Z E Lq(O, Q, P), where Q is a sub-CJ-algebra ofÂ§. 
Show that E(ZXIQ) = ZE(XIQ) a.s. 
14.15. Let (0, Â§, P) be a probability space. Let Q be a sub-CJ-algebra ofÂ§. Let X 
and Z be random variables such that X E (mff)+, Z E (mQ)+, E(X) < oo, and 
E(ZX) < oo. Show that E(ZXIQ) = ZE(XIQ) a.s. 
14.16. Let (0, Â§, P) be a probability space and X be a random variable on 0 with 
E(IXI) < oo. Let Q and 1-l be sub-CJ-algebras ofÂ§. Show that 
(a) If 1-l is independent of CJ(CJ(X), Q), then 
E(XICJ(Q, H))= E(XIQ) 
a.s. 
(b) If X is independent of 1-l, then E(XIH) = E(X). 
14.17. Let (0, Â§, P) be a probability space and Q a sub-CJ-algebra ofÂ§. Let B E 
Â§.Show that 
P(BIQ) = E(IBIQ), 
a.s. 
14.18. Let X be a random variable on a probability space (0, Â§, P) with E[IXI] < 
oo. LetHEÂ§. Show that 
(a) 
E[XIH] = E[XIH] Â· E[IH] = E[XIH]P(H), 
where IH is the indicator function of H. 
(b) 
E[X] = E[XIHJP(H) + E[XIHc]P(Hc), 
where He = 0\H. 
14.19. Let X be a real random variable on a probability space ( 0, Â§, P). Let <;1' be a 
sub-CJ-algebra ofÂ§. Suppose that X is discrete and takes values in { x 1 , x 2 , ... , Xn}. 
Show that 
n 
E[XI<;1'] = LxkP(X = Xki<;1'). 
k=l 
14.20 (Bayes' Formula). Let (0, Â§, P) be a probability space. Let Q be a proba-
bility measure on (0, Â§) such that Q Â« P. Let <;1' be a sub-CJ-algebra ofÂ§ and 
X E L 1(0, Â§, Q). Let L = dQ/dP be the Radon-Nikodym derivative. Show that 
(a) Q{Ep[LI<;1'] > 0} = 1. 
(b) 

178 
CONDITIONAL EXPECTATION 
14.3 Hints 
14.1. Consider the following set function 
.A(A) = l XdP, 
A E Q 
and apply the Radon-Nikodym theorem (Theorem 7.4). 
14.2. 
By Definition 14.1, one only needs to show that E(Y; G) = E(X; G) for 
G E Q. This can be achieved by showing that {G E Q: E(Y; G)= E(X; G)}= Q. 
The result of Problem 2.7 is helpful here. 
14.3. This problem can be proved by using the definition of conditional expectations 
(Definition 14.1) and the fact that rl E Q. 
14.4. Use the definition of conditional expectations (Definition 14.1) to show that 
X is a version of E(XIQ). 
14.5. 
Show that a1Y1 + a2Y2 is a version of E(a1X1 + a2X2IQ), where Y1 
E(X1IQ) and Y2 = E(X2IQ). 
14.6. To show that E(XIQ) 2: 0 a.s., one only needs to prove that P(E(XIQ) < 
0) = 0. To do that, one can use the definition of conditional expectations and Theo-
rem 2.1. 
14.7. 
Using Theorem 6.2, one can show that lim sup Yn is a version of E(XIQ), 
where Yn = E(Xnl9). 
14.8. Consider Ym = infn~m Xn form 2: 1 and use the result of Problem 14.7. 
14.9. 
Apply the conditional Fatou's lemma (see Problem 14.8) to the sequences 
V + Xn and V- Xn. The result of Problem 1.8 is also helpful here. 
14.10. 
Use the definition of conditional expectations to show that E(XIH) is a 
version of E(YIH). 
14.11. Use the Tower property (see Problem 14.10) and the result of Problem 12.1. 
14.12. 
Use the definition of conditional expectations and the standard technique 
(i.e., from simple functions to general functions) to show that ZE(XIQ) is a version 
of E(ZXIQ). 
14.13. 
Use the definition of conditional expectation (Definition 14.1), Tonelli's 
theorem (Theorem 10.1), and change of variables, specifically, 
{ cp(X)dP = 
{ 
cp(x)Px(dx), 
}A 
lx(A) 

SOLUTIONS 
179 
where X(A) = {X(w) :wE A} and Px is the probability law of X. 
14.14. Use the same hint as Hint 14.12. 
14.15. Use the same hint as Hint 14.12. 
14.16. Show that Y = E(XIQ) is also a version of E(XIa(Q, 1-l)). This can be 
achieved by using the results of Problem 14.2, Problem 2.16, and Theorem 13.2. 
14.17. 
Use the definition of conditional expectations (Definition 14.1) and the 
definition of conditional probabilities (Definition 14.4). 
14.18. Follow the definition of the expectation of a random variable given an event 
(Definition 14.3) to and the tower property (see Problem 14.10) prove part (a). Use 
part (a) to prove part (b). 
14.19. Use the definition of conditional expectations (Definition 14.1) and condi-
tional probabilities (Definition 14.4). 
14.20. 
Follow the definition of conditional expectations (Definition 14.1) and 
Radon-Nikodym derivative (Theorem 7.4) to prove part (a). Use the definition of 
conditional expectations and the result of Problem 14.12 to prove part (b). 
14.4 Solutions 
14.1. Let A : g --+ R be defined as 
A(A) = i XdP, 
A E g. 
We claim that A is a signed measure on (0, Q). By the definition of the integral over 
subsets (Definition 6.5), we have 
Let An, n = 1, 2, ... , be disjoint sets in g. Then 
Hence A is a signed measure on (0, Q). 
Now if P(A) = 0 and A E g, then by Problem 6.10, we have A(A) = 0. Hence 
A is absolutely continuous with respect to P. By the Radon-Nikodym theorem, there 
is a g-measurable random variable Y such that 
i XdP = i Y dP, 
\lA E g. 

180 
CONDITIONAL EXPECTATION 
Note that X E L 1(0,ff:,P). WehaveE(IXI) < oo. But 
-E(IXI):::; E(X) = E(Y):::; E(IXI), 
which implies that E(IYI) < oo. This completes the proof. 
14.2. We only need to show that E(Y; G) = E(X; G) for G E Q. To do this, let 
C = {G E g : E(Y; G) = E(X; G)}. We claim that Cis ad-system on 0. By 
hypothesis, we have E(Y; 0) = E(X; 0). Hence 0 E C. Suppose that A, B E C 
with A ~ B. Then E(Y; B\A) = E(Y IB\A) = E(Y IB - Y IA) = E(Y; B) -
E(Y; A) = E(X; B)- E(X; A) = E(X; B\A). Hence B\A E C. Suppose that 
An E C and An t A. Then X IAn t X IA andY IAn t Y IA and so, by Theorem 6.2, 
E(X; An) = E(XIAn) t E(Xh) = E(X; A) and E(Y; An) t E(Y; A). Since 
E(Y; An) = E(X; An), we have E(X; A) = E(Y; A). Thus A E C. Therefore C 
is a d-system. 
Noting that I~ C ~ Q, we have d(I) ~ C and so, by Problem 2.7, a(I) ~ C. 
But with a(I) = Q, we have C = Q. This completes the proof. 
14.3. Let Y be a version of E(XIQ). Then, by definition of conditional expecta-
tions, we have E(Y; G) = E(X; G) for all G E Q. Since g is a sub-a-algebra of 
Y:, we have 0 E Q. Thus E(Y; 0) = E(X; 0), which is E(Y) = E(X). 
14.4. By hypothesis, we know that X is (}-measurable and E(IXI) < oo. Also, we 
have 
fc XdP= fc XdP, 
CEQ. 
Thus X is a version of E(XIQ). Hence X= E(XIQ), a.s. 
14.5. Let Y1 = E(X1IQ) and Yz = E(Xzl9). We only need to show that a1Y1 + 
azYz is a version of E(a1X 1 + azXzl9). Since Y1 and Y2 are (}-measurable, we 
have a1Y1 + azYz E mQ. Since E(IY1I) < oo and E(IYzl) < oo, we have 
Moreover, for G E g, we have 
a1E(Y1; G)+ azE(Yz; G) 
a1E(X1; G)+ azE(X2; G) 
E(a1X1 + a2X2; G). 
14.6. 
Let Y = E(XIQ). Since P(Y ?': 0) = 1 - P(Y < 0), we only need to 
show that P(Y < 0) = 0. To do this, let An = {Y < -1/n} for n ?': 1. Then 
Ant {Y < 0}. Since X ?': 0, we have 
1 
0:::; E(X; An) = E(Y; An) :::; --P(An) :::; 0, 
n ?': 1, 
n 

SOLUTIONS 
181 
which implies P(An) = 0 for n 2: 1. Thus by Theorem 2.1, P(A) = 0, that is, 
P(Y < 0) = 0. 
14.7. Let Yn = E(XniQ). Then by Problems 14.6 and 14.5, we have Yn 2: 0 a.s. 
and Yn+l - Yn = E(Xn+l - Xnl9) 2: 0 a.s. for n 2: 1. Let Y = lim sup Yn. 
Then Y is Q-measurable and Yn t Y a.s. Since E(Yn; G) = E(Xn; G) for G E g 
and n 2: 1, it follows from Theorem 6.2 that E(Y; G) = E(X; G) for G E Q. In 
particular, E(Y; fl) = E(X; fl), which is E(Y) = E(X). Thus E(Y) < oo. Hence 
Y is a version of E(XIQ). Therefore E(XniQ) t E(XIQ) a.s. 
14.8. Let Ym = infn~m Xn form 2: 1. Then Ym t lim inf Xn as m -+ oo. Since 
Ym :-=:; Xn for n 2: m, by Problem 14.6, we have 
which gives 
E(Yml9) :S: inf E(XniQ) :S: sup inf E(XniQ) = liminf E(Xnl9). 
n~m 
m~ln~m 
Since Ym t liminfXn, by Problem 14.7, we have E(Yml9) t E(liminfXniQ). 
Therefore 
E(liminf XniQ) :S: liminf E(Xnl9). 
14.9. Since IXn I :S: V for n 2: 1, we have V + Xn 2: 0 and V - Xn 2: 0. Then by 
Problem 14.8, we have 
E(liminf(V + Xn)IQ) :-=:; liminf E(V + Xnl9), 
a.s. 
(14.1) 
and 
E(liminf(V- Xn)IQ) :-=:; liminf E(V- XniQ), 
a.s. 
(14.2) 
Since Xn -+ X, we have liminf(V + Xn) = V +X and liminf(V- Xn) = 
V- X. In addition, by Problem 1.8, we have liminf E(V + XniQ) = E(VIQ) + 
liminf E(Xnl9) and liminf E(V- XniQ) = E(VIQ) -limsupE(Xnl9). Thus 
it follows from (14.1) and (14.2) that 
limsupE(Xnl9) :S: E(XIQ) :S: liminf E(Xnl9), 
a.s., 
which implies E(XniQ) -+ E(XIQ), a.s. 
14.10. 
Let Y = E(XIQ) and Z = E(Xi1l). We only need to show that Z is a 
version of E(Yi1l). By definition, Z is 1l-measurable. Let Z+ = E(IXIIH). Then 
by Problem 14.6, we have IZI = IE(XIH)I :-=::: E(IXII1l) = z+ and 
E(IZI) :-=:; E(Z+) = E(Z+; fl) = E(IXI; fl) = E(IXI) < oo, 
because fl E 1l. In addition, we have 
faxdP= iYdP, CEQ, 

182 
CONDITIONAL EXPECTATION 
and 
i X dP = i ZdP, 
H E H. 
Since His a sub-a-algebra of Q, we have 
i YdP = i ZdP, 
HE H. 
Therefore Z is a version of E(YIH). 
14.11. Let Â§o = {0, 0} be the trivial a-field. Then by Problems 12.1 and 14.10, 
we have 
E[E[X]] = E[E[XIÂ§o]lÂ§o] = E[XIÂ§o] = E[X]. 
This finishes the proof. 
14.12. Let Y be a version of E(XIQ). We show that ZY is a version of E(ZXIQ). 
Since Z is Q-measurable and bounded, we have ZY E mQ (see Theorem 5.1) and 
E(IZYI) :::; (sup Z(w)) E(IYI) < oo. 
wErl 
Therefore, to show ZY = E(ZXIQ), we only need to show that 
E(ZY; G)= E(ZX; G), 
G E Q. 
(14.3) 
If we can show that ( 14.3) holds for X 
~ 0, then E ( ZY; G) 
E ( ZY1; G) -
E(ZY2 ; G) = E(zx+; G)- E(zx-; G) = E(ZX; G) forGE Q, where Y1 = 
E(X+ 19) and Y2 = E(X-IQ). Therefore, we can assume that X ~ 0. By Problem 
14.6, Y ~ 0, a.s. 
First, we consider the case when Z is an indicator function. Since Z is Q-
measurable, we have Z = IA for some A E Q (A = z- 1(1) E Q). Then 
E(ZY;G) = E(YIA;G) = E(Y;A n G)= E(X;A n G)= E(XIA;G) = 
E(X Z; G) for G E Q. Hence (14.3) is true. 
Next, we consider the case when Z is a simple function. Then Z has finitely many 
values. Let ai ~ 0, i = 1, 2, ... , n be all the distinct values of Z. Then 
i=l 
where Ai = z- 1 (ai) E Q. ForGE Q, we have 
E(ZY;G) = [ 
Y~aiiA,dP 
= tai 1 
YIArdP 
i=l 
G 
= tai 1 
XIArdP 
i=l 
G 
= E(ZX;G). 

SOLUTIONS 
183 
Next, we consider the case when Z is a nonnegative function. Then there exists a 
sequence { Zn }n>l of Q-measurable simple functions such that Zn t Z (see Problem 
5.11). We have already shown that E(ZnY; G) = E(ZnX; G) for G E Q. Noting 
that Y ~ 0, a.s., and X ~ o, we have ZnY t ZY, a.s., and ZnX t ZX, a.s. By 
Theorem 6.2, E(ZY; G)= E(ZX; G) forGE Q. 
Finally, we consider the case when Z is a general function. Let Z = z+ - z-. 
Then E(ZY; G) = E(Z+Y; G)- E(z-y; G) = E(z+ X; G)- E(z- X; G) = 
E(ZX; G) forGE Q. This completes the proof. 
14.13. 
By Theorem 10.1, <p(x) is a $"-measurable function. In consequence, we 
know that <p(X) is r,1 /$"-measurable. Since <I> is nonnegative, <p(X) is also nonneg-
ative. Hence E[<p(X)] is defined. Thus, for every A E r,1, we only need to show 
that 
L 
<p(X)dP = L 
<I>(X, Y)dP. 
Then by Theorem 10.1 and Problem 14.11, we have 
L 
<p(X)dP = f 
<p(x)Px(dx) 
lx(A) 
f 
( f <I>(x, Y)dP) Px(dx) 
lx(A) ln 
f 
f <I>(x,y)Py(dy)Px(dx) 
lx(A) jF 
{ 
{ 
<I>(x, y)Px(dx)Py(dy) 
jFjX(A) 
t (i <I>(X, y)dP) Py(dy) 
t E[IA<I>(X, y)]Py(dy) 
E[E[IA<I>(X, Y)]] 
E[IA<I>(X, Y)]. 
Equation (14.4) follows immediately from 
E[IA<I>(X, Y)] = L 
<I>(X, Y)dP. 
This completes the proof. 
(14.4) 

184 
CONDITIONAL EXPECTATION 
14.14. Since p > 1, X E LP(O, Â§, P), and Z E Lq(O, (), P) <;;; Lq(O, Â§, P), by 
Theorem 8.1, we have 
E(IZXI) =In IZXIdP 
~ (In IXIPdP) ~ (In IZiqdP) i 
<(X). 
Thus E(ZXI()) exists. By Problem 8.5, we have X E L 1(0,Â§,P), which gives 
E(IXI) < oo. Hence E(XIQ) exists. 
Let Y = E(XIQ). We show that ZY is a version of E(ZXI()). By definition, 
Y is ()-measurable. Hence ZY is ()-measurable. By Problem 15.8, we know that 
Y E LP(O, Â§, P) and so, by Theorem 8.1, we have 
E(IZYI) = jiZYidP 
n 
<(X). 
Using the same argument in Problem 14.12, we have E(ZY; G) = E(ZX; G) for 
G E ().Hence ZY is a version of E(ZXI()). 
14.15. 
Since X E (mÂ§)+ and E(X) < oo, we know that E(XIQ) exists and, 
by Problem 14.6, Y = E(XI()) ~ 0 a.s. Since Z E (m())+, we know that ZY E 
m(). Using a similar argument in Problem 14.12, we can show that E(ZX; G) = 
E(ZY; G) for G E Q. Note that 0 E g and E(ZX) < oo, we have E(IZYI) = 
E(ZY) = E(ZY; 0) = E(ZX; 0) = E(ZX) < oo. Hence ZY = E(ZXIQ). 
14.16. Let Y be a version of E(XIQ). Then Y is ()-measurable, E(IYI) < oo, and 
E(Y ! 0 ) = E(XI0 ), 
'VG E (). 
(14.5) 
Note that g <;;;a((), 1-l), we have Y is a((), H)-measurable. By Problems 14.2 and 
2.16, we only need to show that 
E(Y IciH) = E(XIciH ), 
'VG E (), HE 1i. 
In fact, by Theorem 13.2, Equation (14.5), and the assumption that 1i is independent 
of a( a( X),()), for all G E (), HE 1-l, we have 
E(YiclH) = E(Yic)E(IH) = E(XIc)E(IH) = E(XIciH)Â· 
This completes the proof. 

SOLUTIONS 
185 
14.17. We only need to show that E(I8 1Q) is a version of the conditional probability 
P(BIQ). By Definition 14.1, E(IBIQ) is Q-measurable and 
i IBdP = i E(IBIQ)dP, 
A E Q. 
Integrating out the left term of the above equation gives 
P(A n B)= i E(IBIQ)dP, 
A E Q. 
Hence E(I8 1Q) is a version of the conditional probability P(BIQ). This completes 
the proof. 
14.18. 
(a) By Problems 14.10 and 14.12, we have 
Hence we only need to show that 
(14.6) 
Since E[XIH] = f(IH) for some Borel function f (see Theorem 11.2), we 
know that E[XIH] is constant on the event H. Therefore, we have 
Hence Equation (14.6) holds. 
(b) By part (a) of this problem, we have 
This completes the proof. 
L 
IHE[XIH]dP 
i E[XIH]dP 
E[XIH]LdP 
E[XIH]E(IH) 
E[XIH]P(H). 
14.19. We only need to show that I:~=l xkP(X = xkl<:1) is a version of E[XI<:1]. 
Since P(X = xkl<:1) is <:1-measurable, I:~=l xkP(X = xkl<:1) is <:1-measurable. In 
addition, we have 

186 
CONDITIONAL EXPECTATION 
Now let G E '#. Then by Definition 14.4 we have 
n 
.l.:xkP({X = xk} nG) 
k=l 
~ 
~X=xk}nG XdP 
fc XdP. 
Hence ~~=l xkP(X = xkl~1) is a version of E[XI'#]. This completes the proof. 
14.20. 
(a) Since Er[LI'#] is '#-measurable, we have {Ep[LI'#] > 0} E ~1. Hence, by 
Definition 14.1, we have 
Q{Ep[LI'#] = 0} 
r 
dQ 
J{Ep[L['#]=O} 
{ 
LdP 
j{Ep[L['#J=O} 
{ 
Ep[LI'#]dP 
./ {Ep [L['#J=O} 
0, 
which gives Q{Ep[LI'#] > 0} = 1. 
(b) Since Ep[LI'#] and Eq [XI'#] are '#-measurable, it follows from Problem 14.12 
that 
Hence for every G E 'Â§, we have 
fc Ep(LEq[XI'#JI'#)dP 
fc LEq[XI'#]dP 
fc Eq[XI'#]dQ 
fc XdQ 
fc XLdP. 

BIBLIOGRAPHIC NOTES 
187 
It follows from Definition 14.1 that 
This completes the proof. 
14.5 Bibliographic Notes 
In this chapter, we introduced conditional expectations. Many properties of condi-
tional expectations are presented as problems. Those properties are very important 
at a later stage when we study martingales. For more information about conditional 
expectations, readers are referred to Williams ( 1991 ), Ash and Do leans-Dade ( 1999), 
Rosenthal (2006), Kuo (2006), and <;inlar (2011). Wise and Hall (1993) and Stoy-
anov (1997) present several counterexamples related to conditional expectations. 
In particular, <;inlar (2011) presents a detailed introduction to conditional expecta-
tions and conditional probabilities. As <;inlar (20 11, p 14 7) pointed out, for example, 
the proper interpretation of P(XIY = y) when P{Y = y} = 0 is f(y), where 
!(Â·)is defined as f(Y) = P(XIY). When P{Y = y} > 0, P(XIY = y) can be 
interpreted as P(XI{Y = y}) or f(y) as the two quantities are identical. 


CHAPTER 15 
INEQUALITIES 
We introduced several important inequalities in Chapter 8 when we presented the Â£P 
spaces. In this chapter, we shall introduce Jensen's inequality for convex functions. 
Jensen's inequality can be used to prove many other inequalities. 
15.1 
Basic Concepts and Facts 
Definition 15.1 (Convex Functions). Let G be an open subinterval ofR. A function 
c.p : G --+ R is considered convex on G if its graph lies below any of its chords; that 
is, for any x, y E G and 0:::; p:::; 1, we have 
c.p(px + qy) :::; pc.p(x) + qc.p(y), 
where q = 1 - p. 
Theorem 15.1 (Mean Value Theorem). Let f(x) be a continuous function on the 
closed interval [a, b]. Suppose that f(x) is differentiable on the open interval (a, b). 
Then there exists a point c E (a, b) such that 
!'(c)= f(b~ =~(a). 
Measure, Probability, and Mathematical Finance. 
189 
By Guojun Gan, Chaoqun Ma, and Hong Xie Copyright@ 2014 John Wiley & Sons, Inc. 

190 
INEQUALITIES 
Theorem 15.2 (Jensen's Inequality). Let (0, Â§, P) be a probability space and r.p : 
G---+ R be a convex function on G, where G is an open subinterval ofR. Suppose 
that X is a random variable on n such that E(IXI) < oo, P(X E G) = 1, and 
E(lr.p(X)I) < oo. Then 
E(r.p(X)) 2:: r.p(E(X)). 
15.2 Problems 
15.1 (Chebyshev's Inequality). Let X E L2(n, Â§, P) and c > 0. Then 
P(IX- J.tl > c) ::; Var~X)' 
c 
where J.t = E(X). 
15.2 (Markov's Inequality). Let (0, Â§, P) be a probability space and Z E mÂ§. 
Suppose that g : R---+ [0, oo] is B-measurable and nondecreasing. Show that 
Eg(Z) 2:: E(g(Z); Z 2:: c) 2:: g(c)P(Z 2:: c), 
c E R. 
15.3. Let r.p : G ---+ R be a convex function on an open subinterval G of R. Show 
that 
(a) .D.u,v ::; .D.u,w ::; .D.v,w for u, v, w E G and u < v < w, where 
.D. 
_ r.p(a)- r.p(b) 
a,b-
a- b 
' 
a, b E G, a =1- b. 
(b) r.p is continuous. 
15.4. Let r.p : G ---+ R be a convex function on an open subinterval G of R. Suppose 
that the second derivative r.p" ( x) 2:: 0 for all x E G. Show that r.p is a convex function 
on G. 
15.5 (Line of Support Theorem). Let r.p : G ---+ R be a convex function on an open 
subinterval G of R. Show that there exists a sequence { (an, bn)}n>l of points in 
R 2 such that 
-
r.p(x) = sup(anx + bn), 
x E G. 
n2:1 
15.6. Let n 2:: 1 and a 1 , a2 , ... , an E R. Show that 
15.7 (Conditional Jensen's Inequality). Let (0, Â§, P) be a probability space and X 
be a random variable on n with E(IXI) < oo. Let g be a sub-a-algebra ofÂ§. Show 
that if r.p : R ---+ R is convex, then 
r.p(E(XIQ))::; E(r.p(X)I9), 
a.s. 

HINTS 
191 
15.8. Let (0, ~. P) be a probability space and X be a random variable on n with 
E(IXI) < oo. Let g be a sub-a-algebra of~- Let p ~ 1. Show that 
where 
15.9 (Kolmogorov's Inequality). Let X 1 , X 2 , ... , Xn be independent random vari-
ables on the probability space (0, ~. P) with IE(Xi)l < oo, i = 1, 2, ... , n. Let 
sj = xl + x2 + ... + Xj. j = 1, 2, ... 'n. For any E > 0, show that 
(15.1) 
15.10. Let Y be a nonnegative random variable on a probability space (0, ~, P). 
Show that 
00 
00 
L P{Y ~ n}::; E(Y)::; 1 + L P{Y ~ n}. 
(15.2) 
n=l 
n=l 
15.11 (Levy's Inequality). Let xl, x2, ... 'XN be independent random variables 
that are distributed symmetrically about zero. Let 
For y > 0, show that 
15.3 Hints 
j 
sj = Lxi, J = 1,2, ... ,N. 
i=l 
15.1. This problem is a special case of Problem 15.1. 
15.2. Use the fact that g(Z) ~ g(Z)fz?.c ~ g(c)lz?_c and properties of integration. 
15.3. Follow the definition of convex functions (Definition 15.1) to prove part (a). 
Apply part (a) to prove part (b). 
15.4. 
Note that the first derivative 'P'(x) is a nondecreasing function and use the 
mean value theorem (Theorem 15.1). 
15.5. Use the result ofProb1em 15.3 and the fact that rational numbers are countable 
and dense. 

192 
INEQUALITIES 
15.6. 
Construct a discrete random variable with values in { a 1 , a 2 , ... , an} and 
apply Jensen's inequality (Theorem 15.2). 
15.7. Use the result of Problem 15.5. 
15.8. Show that IIÂ· [[pis convex, and then use the result of Problem 15.7. 
15.9. First break the set A= {max1:s:j:S:n [Sj- E(Sj)l ~ t:} into a disjoint union 
of n sets in the following way: 
k = 1,2, ... ,n. 
Then consider the variance of Sn and use properties of integration and independence. 
15.10. Break the range of Y into the following sequence of intervals: [0, 1), [1, 2), 
... , and then use properties of integration. 
15.11. Note that 
{,~NS; '-: Y} ~ {SN '-: y} U (~>; n{SN < y}), 
where Aj = {81 < y, 82 < y, ... , Sj-1 < y, Sj ~ y} for j = 1, 2, ... , N. 
15.4 Solutions 
15.1. By definition, we have 
Var(X) 
E[(X- JL) 2] 
k 
[X(w)- JL[ 2 P(dw) 
> 1 
c2dP = c2 P([X- p,[ > c), 
IX-ILI>c 
from which the result follows. 
15.2. By hypothesis, g is nonnegative and nondecreasing. Hence 
Then we have 
g(Z) ~ g(Z)fz?.c ~ g(c)lz?_cÂ· 
Eg(Z) > E(g(Z)Iz?.c) 
> E(g(c)Iz?.c) 
l?.c g(c)dP 
g(c)P(Z ~c), 

SOLUTIONS 
193 
This completes the proof. 
15.3. Let p = ( v - u) I ( w - u) and q = 1 - p = ( w - v) I ( w - u). Then, 0 < p < 1 
and so, by the definition of convex functions, we obtain 
cp(pw + qu) ~ pcp(w) + qcp(u). 
Noting that pw + qu = v, we have 
(w- u)cp(v) ~ (v- u)cp(w) + (w- v)cp(u), 
(15.3) 
which is equivalent to 
(w- u)(cp(u)- cp(v)) 2:: (u- v)(cp(w)- cp(u)). 
Dividing both sides of the above equation by (w- u)(u- v), we get D.u,v ~ D.u,wÂ· 
Note that Equation (15.3) is also equivalent to 
(u- w)(cp(v)- cp(w)) 2:: (v- w)(cp(u)- cp(w)). 
Dividing both sides of this equation by ( u- w) ( v - w ), we get D.u,w ~ D.v,wÂ· 
Now we show that cp is continuous. Let x0 E G. To show that cp is continuous at 
x 0 , we only need to find a 8 for every E > 0 such that lcp(x)- cp(xo)l < E whenever 
lx-xo I < 8. To do this, let Y1, Y2 E G such that Y1 < xo < Y2 (Since G is open, such 
Yl,Y2 exist.). Then we have D.Yl,xo ~ D-xo,x ~ D-x0 ,y2 forx E (yl,xo) U (xo,Y2)Â· 
Consequently, we have 
ID-x,x 0 I ~ L, 
X E (Yl. xo) U (xo, Y2), 
where L = max(lb.y1,x0 I, ID-x0 ,y2 1). Let 8 =ElL. Then 
lcp(x)- cp(xo)l ~ Llx- xol < E, 
x E (xo- 8, xo + 8). 
Therefore, cp(x) is continuous at x0 . Since this is true for every x0 E G, cp(x) is 
continuous on G. 
15.4. 
Let x, y E G such that x < y. Let p E (0, 1). Let z = px + qy, where 
q = 1- p. Then by Theorem 15.1, we have 
cp'(6 ) = cp(z)- cp(x) = cp(z)- cp(x) 
z-x 
q(y-x) 
and 
cp'(6 ) = cp(y)- cp(z) = cp(y)- cp(z), 
y- z 
p(y- x) 
where for some 6 E (x, z) and 6 E (z, y). But by Theorem 15.1, we have 
cp"(c) = cp'(6)- cp'(6) 2:: 0, 
6-6 

194 
INEQUALITIES 
which gives cp' ( 6) :<:; cp' ( 6). Thus we have 
cp(z)- cp(x) 
cp(y)- cp(z) 
..:.......:....-;-___.:_~< 
' 
q(y - X) 
-
p(y - X) 
which leads to 
cp(z) :<:; pcp(x) + qcp(y). 
Therefore, 'P is convex on G. This completes the proof. 
15.5. For q E G, let {Yn}n:;::I be a sequence of points in G such that Yn t q. Then 
by Problem 15.3, we have dn :S dn+l :S d+ for n 2:: 1, where dn = ('P(Yn) -
cp(q))/(Yn- q) and d+ = (cp(q+)- cp(q))/(q+- q) for some q+ E G and q+ > q. 
Thus limn-too dn exists and is bounded. Let 
~-(q) =lim cp(y)- cp(q), 
yfq 
y - q 
q E G. 
Let x E G. Then by Problem 15.3, we have 
cp(x)- cp(q) 2:: ~-(q)(x- q) 
or 
cp(x) 2:: ~-(q)(x- q) + cp(q) 
for all q E G. Thus 
cp(x) = sup[~-(q)(x- q) + cp(q)], 
x E G. 
qEG 
Now we show that 
cp(x) = L [~-(q)(x- q) + cp(q)], 
x E G, 
(15.4) 
qEGnQ 
where Q is the set of all rational numbers. To do this, we fix x E G. Since G is open, 
we can choose an E > 0 such that (x- E, x +E) ~ G. Let { qn}n:;::q be a sequence of 
rational numbers in (x- E, x +E) such that qn --+ x. Then it follows from Problem 
15.3 that 
~-(x- E):<:; ~-(qn) :<:;~-(X+ E), 
n 2:: 1. 
Thus 1~-(qn)l :S L = max(l~-(x- E)l, 1~-(x + E)l) for n 2:: 1 and so 
1~-(qn)(x- Qn) + cp(qn)- cp(x)l :S Llx- Qnl + lcp(qn)- cp(x)l. 
(15.5) 
By Problem 15.3, 'Pis continuous on G. Therefore, it follows from Equation (15.5) 
that ~-(qn)(x- qn) + cp(qn) --+ cp(x). Therefore (15.4) is true. Since G n Q 
is countable, we can label all the points in G n Q as a sequence {xn}n>l and let 
an= ~-(xn) and bn = cp(qn)- ~-(Qn)Qn forn 2:: 1. Then 
cp(x) = sup(anx + bn), 
x E G. 
n2:1 

15.6. Let X be a random variable such that 
Then we have 
1 
P{X=ai}=-, i=1,2, ... ,n. 
n 
n 
E[X] = Lai. 
i=l n 
SOLUTIONS 
195 
Let <p(x) = x2â¢ Since <p(x) is a convex function, it follows from Theorem 15.2 that 
<p(E[X]):::; E[<p(x)], 
which is 
The resulting inequality follows by multiplying n 2 in both sides of the above equa-
tion. This completes the proof. 
15.7. Since <pis convex, by Problem 15.5, we have 
<p(X) = sup(anX + bn), 
n::::1 
where {(an, bn)}n::::l is a sequence in R 2 . Since E(l<p(X)I) < oo, E(<p(X)IQ) 
exists. Let Y be a version of E(<p(X)IQ) and Z be a version of E(XIQ). Since for 
each fixed n, <p(X) 2: anX +bn, by Problems 14.6 and 14.5, we have Y 2: anZ +bn, 
a.s. For each n 2: 1, let An be defined as 
Then P(An) = 1 for n 2: 1 and so, by Problem 11.1, we obtain 
P(A) = P ( n An) = 1, 
n::::1 
where A = nn>l An. Since Y(w) 2: anZ(w) + bn for all n 2: 1 and w E A, we 
have Y 2: anZ +- bn simultaneously for all n 2: 1, a.s., and so 
which is 
Y 2: sup(anZ + bn) = <p(Z), 
a.s., 
n::::1 
E(<p(X)IQ) 2: <p(E(XIQ), 
a.s. 
This completes the proof. 

196 
INEQUALITIES 
15.8. We show that II Â· liP is a convex function for p ~ 1. Let 0 ::::; a = 1 - b ::::; 1. 
Then by Theorem 8.2, we have 
1 
llaY + bZIIP = (L laY+ bZIPdP)" 
::::: (L laYIPdP) ~ + (L lbZIPdP) ~ 
=allY liP+ biiZIIpÂ· 
Thus II Â· liP is convex. The result follows from Problem 15.7. 
15.9. Let A= {maxl:S:i:S:n lSi- E(Sj)l ~ E} and 
k = 1,2, ... ,n. 
Then A1 , A2, ... , An are mutually disjoint and A = U~=l Ak. By definition, we 
have 
E [(Sn- E(Sn))2] 
k 
(Sn- E(Sn)) 2dP ~ i (Sn- E(Sn)) 2dP 
~ ik (Sn- E(Sn)) 2dP. 
(15.6) 
Now let Yk = Sn- Sk. k = 1, 2, ... , n. Then Sk and Yk are independent. Hence 
{ [(Sk- E(Sk)) + (Yk- E(Yk))]dP 
jAk 
{ (Sk- E(Sk)) 2dP + { (Yk- E(Yk)) 2dP 
jAk 
jAk 
+2 k 
hk(Sk- E(Sk))(Yk- E(Yk))dP 
{ (Sk- E(Sk)) 2dP + { (Yk- E(Yk)) 2dP 
}Ak 
jAk 
> 
{ (Sk- E(Sk)) 2dP 
jAk 
> 
E2P(Ak), 
k=1,2, ... ,n. 
Combining Equations (15.6) and (15.7) gives 
n 
Var(Sn) ~ L E2 P(Ak) = E2 P(A). 
k=l 
(15.7) 

SOLUTIONS 
197 
This completes the proof. 
15.10. Let An = Y ~ n, n = 0, 1, .... By the assumption that Y is nonnegative, 
we have 
E(Y) 
kYdP 
~l~Y<n+l YdP 
00 
> 
L nP{ n ~ Y < n + 1} 
n=O 
00 
L n(P(An)- P(An+l)) 
n=O 
00 
00 
L nP(An)- L(n -1)P(An) 
n=l 
n=2 
00 
LP(An)Â· 
n=l 
Similarly, we have 
E(Y) 
kYdP 
~ 
l~y <n+l Y dP 
00 
< L(n+ 1)P{n ~ Y < n+ 1} 
n=O 
00 
L(n + 1)(P(An)- P(An+I)) 
n=O 
00 
00 
L(n + 1)P(An)- L nP(An) 
n=O 
n=l 
00 
< 1+ LP(An)Â· 
n=l 
This completes the proof. 
15.11. LetAi = {S1 < y,S2 < y, ... ,Si-l < y,Si ~ y}forj = 1,2, ... ,N. 
Then we have 
{ max sj ~ y} = {SN ~ y} u (Nu-l Aj n {SN < y}) ' 
l<j<N 
-
-
j=l 

198 
INEQUALITIES 
which gives 
p { max sj ~ y} 
l<;j<;N 
N-l 
P{SN~Y}+ LP(AJn{SN<y}). 
j=l 
Note that Aj n {SN < y} c;:: Aj n {SN- SJ < 0} and that Aj and {SN- Sj < 0} 
are independent. We have 
p { max sj ~ y} 
1 <;j <;N 
N-l 
P{SN ~ y} + L 
P(Aj)P ( {SN < y}) 
j=l 
N-l 
< 
P{SN ~y}+ LP(Aj)P({SN-Sj <0}). 
j=l 
By the assumption that X 1 , X 2 , ... , XN are symmetrically distributed about zero, 
we have P{SN- Sj > 0} = P{SN- Sj > 0}. Hence we have 
P { max Sj ~ y} 
l<;j<;N 
â¢ 
This completes the proof. 
N-l 
P{SN ~ y} + L 
P(Aj)P({SN- sj > o}) 
j=l 
N-l 
P{SN ~ y} + L 
P (Aj n {SN- sj > o}) 
j=l 
N-l 
< 
P{SN~Y}+ LP(Ajn{SN>Y}) 
j=l 
< 
P{SN ~ y} + P{SN > y} 
2P{SN ~ y}- P{SN = y}. 
15.5 Bibliographic Notes 
In this chapter, we introduced Jensen's inequality. Jensen's inequality is very power-
ful in that it allows us to prove many other inequalities. A proof of Jensen's inequality 
can be found in Williams (1991). For more information about probability inequal-
ities, readers are referred to Jacod and Protter (2004), Rosenthal (2006), Ross and 
Pekoz (2007), Gut (2007), and Lin and Bai (201 0). In particular, the book by Lin 
and Bai (20 I 0) is devoted to probability inequalities. 

CHAPTER 16 
LAW OF LARGE NUMBERS 
The law of large numbers is a theorem in probability theory that describes the average 
of a large number of random variables. The law states that the average of a large 
number of random variables converges to the expected value in some sense under 
certain conditions. In this chapter, we introduce some laws of large numbers. 
16.1 
Basic Concepts and Facts 
Definition 16.1 (Almost Surely Convergence). Let X, X 1 , X 2 , ... be random vari-
ables on a probability space (0, ~, P). The sequence { Xn}n>l is said to converge 
to X almost surely if and only if it converges to X almost everywhere; that is, there 
is a set A E ~such that Xn --+X on A and P(Ac) = P(O\A) = 0. 
Definition 16.2 (Convergence in Probability). Let X 1,X2 , ... , be a sequence of 
random variables on (0, ~. P). The sequence Xi is said to be convergent to a 
random variable X on (0, ~. P) if for every E > 0, we have 
lim P (JXn - XJ ~ E) = 0. 
n--+oo 
Measure, Probability, and Mathematical Finance. 
199 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

200 
LAW OF LARGE NUMBERS 
Definition 16.3 (Identically Distributed Random Variables and liD). A sequence of 
random variables { Xn }n> 1 is are said to be identically distributed if they have the 
same distribution. These random variables are called liD random variables if they 
are independent and identically distributed. 
Theorem 16.1 (Weak Law of Large Numbers). Let X 1, X2, ... , be a sequence 
of independent random variables on (0, .9?", P). Suppose that IE(Xi)l < oo and 
Var(Xi) < M for all i = 1, 2, ... , where M < oo. Let Sn = X 1 + X 2 + Â· Â· Â· + Xn. 
Then [Sn - E(Sn)Jin converges to 0 in probability; that is,for every E > 0, we have 
Theorem 16.2 (Kolmogorov Strong Law of Large Numbers). Let X 1, X 2, ... , be a 
sequence of independent random variables on (0, .9?", P), each with .finite mean and 
variance. Let {bn}n>l be a sequence of positive real numbers such that bn too. If 
~ 
Var(Xn) 
~ b2 
< oo, 
n=l 
n 
then 
lim Sn - E(Sn) = O 
n--+oo 
bn 
a.s., 
where Sn = "L7=l Xj, n = 1, 2, .... 
Theorem 16.3 (Strong Law of Large Numbers, liD Case). Let {Xn}n;::1 be a se-
quence of liD random variables on the probability space (0, .9?", P) with .finite ex-
pectation m. Let Sn = "L7=l Xj, n = 1, 2, .... Then 
16.2 Problems 
16.1. Prove Theorem 16.1. 
l. 
Sn 
1m- =m a.s. 
n--+oo n 
16.2. Let (0, .9?", P) be a probability space. Suppose that Xn (n ~ 1) are indepen-
dent random variables on 0 such that E(Xk) = 0 and E(Xt) :::::: K for all k ~ 1, 
where K E [0, oo) is a constant. Show that 
where Sn = X1 + X2 + Â· Â· Â· + Xn. 
16.3. Let A = ( aij )i;::l,j2:l be an infinite matrix of real numbers with the following 
properties: 

(a) For fixed j, we have 
lim anj = 0; 
n--+oo 
(b) For some c ~ 0, we have 
00 
L 
ianj I ~ c, 
'tin ~ 1. 
j=l 
Let Xnn~l be a sequence of bounded real numbers and define 
Show that 
00 
Yn = L.:anjXj, 
n = 1,2, .... 
j=l 
(a) If limn--+oo Xn = 0, then limn--+oo Yn = 0. 
PROBLEMS 
201 
(b) If limn--+oo .L:~ 1 anj = 1 and limn--+oo Xn = x for some x E R, then 
lim Yn =X. 
n--+oo 
16.4 (Toeplitz Lemma). Let { an}n~l be a sequence of nonnegative real numbers. 
Let bn be the partial sum defined as 
n 
bn=Laj, n=1,2, .... 
j=l 
Suppose that bn > 0 for all n ~ 1 and bn -+ oo as n -+ oo. Let {xn}n~l be a 
sequence of real numbers such that limn--+oo Xn = x. Show that 
1 
n 
lim b LajXj = x. 
n--+oo 
n j=l 
16.5 (Kronecker Lemma). Let {bn}n~l be a sequence of positive real numbers such 
that bn too, and let {xn}n~l be a sequence of real numbers such that .L:~=l Xn = 
x, where lxl < oo. Show that 
1 
n 
lim b LbjXj = 0. 
n--+oo 
n j=l 
16.6 (Mean Square Summability Criterion). Let {Xn}n~l be a sequence of inde-
pendent random variables on the probability space (0, $, P) with IE(Xn)l < oo, 
n = 1, 2, .... Show that if 
00 L Var(Xn) < oo, 
n=l 

202 
LAW OF LARGE NUMBERS 
then L~=l (Xn- E(Xn)) exists a.s. 
16.7. Prove the Kolmogorov strong law of large numbers (Theorem 16.2). 
16.8. Let {Xn}n>l be a sequence of liD random variables on the probability space 
(rl, Â§, P). Assume that 
1 n 
lim - ~ 
xj = m 
a.s., 
n--+oo n L 
j=l 
where lml < oo. Show that E(X1) is finite and E(XI) = m a.s. 
16.9. Let { Xn }n:::: 1 be a sequence of independent random variables. Suppose that 
for every n::::: 1, we have P(Xn = 1) = Pn and P(Xn = 0) = 1- PnÂ· Show that 
(a) Xn ~ 0 if and only if limn--+oo Pn = 0. 
(b) Xn ~ 
0 if and only if L~=l Pn < oo. 
16.10. Let { Xn : n ::::: 1} be a sequence of independent and identically distributed 
random variables such that E[lln X 1IJ < oo. 
(a) Find the a.s. limiting geometric mean 
lim (rr xi)~ 
n--+oo 
i=l 
(b) Suppose that X 1 is uniformly distributed on ( 0, 1). Calculate the numerical 
value of the a.s. limiting geometric mean. 
16.11 (Kolmogorov's Three-Series Criterion: Sufficiency Part). Let {Xn}n>l be a 
sequence of independent random variables. Suppose that there exists a number a > 0 
such that 
(a) L~=l P{IXnl >a} converges. 
(b) L~=l E[X,,J{IXnl~a}] converges. 
(c) L~=l Var(Xni{IXnl~a}) converges. 
Show that L~=l Xn converges with probability 1. 
16.12. Let {Yn}n2:l be a sequence of independent random variables. Suppose that 
for all n ::::: 1, we have E[Yn] = 0 and IYnl :S c a.s. for some c < oo. Show that if 
I:~= I Yn is convergent a.s., then 
00 

HINTS 
203 
Furthermore, for all >. > 0, the following inequality holds, where Sn = Y1 + Y2 + 
Â·Â·Â·+Yn: 
16.13. Let {Yn}n>1 be a sequence of independent random variables. Suppose that 
for all n ?: 1, IYn I:::; c a.s. for some c < oo. Show that if 2.::~= 1 Yn is convergent 
a.s., then 2.::~= 1 E[Yn] converges. 
16.14 (Kolmogorov's Three-Series Criterion: Necessary Part). Let {Xn}n>1 be a 
sequence of independent random variables. Suppose that 2.::~= 1 Xn converges with 
probability 1. Let a > 0. Show that 
(a) 2.::~= 1 P{IXnl >a} converges. 
(b) 2.::~= 1 E[Xni{IXnl:s;a}] converges. 
(c) 2.::~= 1 Var(Xni{IXnl:s;a}) converges. 
16.15. Let { Xn}n> 1 be a sequence of independent and identically distributed ran-
dom variables defined as 
1 
P{X1 = 1} = P{X1 = -1} = 2Â· 
Let { an}n2:1 be a sequence of real numbers. Show that 2.::~= 1 anXn converges a.s. 
if and only if 
00 
:La~< oo. 
n=1 
16.3 Hints 
16.1. 
Use Chebyshev's inequality (see Problem 15.1) and the result of Problem 
13.7. 
16.2. First try to establish that 
and then use the result of Problem 13.5. 
16.3. Part (a) can be proved using the standard technique; that is, for every E > 0, 
we need to find an integer N< such that 
IYnl < E, 
Vn > N<. 
We can derive part (b) from part (a). 

204 
LAW OF LARGE NUMBERS 
16.4. Use the result of Problem 16.3. 
16.5. Use the Toeplitz lemma (see Problem 16.4). 
16.6. 
Use the result of Problem 9.8 and Kolmogorov's inequality (see Problem 
15.9). 
16.7. Use the results of Problems 16.6 and 16.5. 
16.8. Use the second Borel-Cantelli lemma (see Problem 12.9), the result of Prob-
lem 15.10, and the strong law oflarge numbers for the liD case (see Theorem 16.3). 
16.9. Part (a) can be proved using the definition of convergence in probability (Def-
inition 16.2). Part (b) can be proved using the first Borel-Cantelli lemma (Theorem 
2.2) and the second Borel-Cantelli lemma (see Problem 12.9). 
16.10. Consider the random variables Yn = ln Xn, n 2 1, and apply Theorem 16.3. 
16.11. Use the results of Problems 9.8 and 16.6 to show that both the sequences 
00 L Xnl{IXnl:s;a} 
n=l 
and 
00 L XnJ{IXnl>a} 
n=l 
converge a.s. 
16.12. For a fixed .X, introduce a random variable T = inf { n 2 1 : I Sn I > ,\} and 
note that { T = j} is independent of YJ+ 1 , YJ+2 , .... 
16.13. 
Let (0, ~. P) be the probability space on which {Yn}n>l are defined. 
Consider the random variable Zn on (n X n, ~ 0 ~. p X P) 
Zn(wl,w2) = Yn(wl)- Yn(w2), 
and use Fubini's theorem (Theorem 10.2) to establish 
E [z;] = 2Var(Yn)Â· 
Then use the result of Problems 16.12 and 16.6. 
16.14. The convergence of the first series can be proved by the method of contradic-
tion with Problem 9.8 and the second Borel-Cantelli lemma (see Problem 12.9). The 
convergence of the second series can be proved by Problem 16.13. The convergence 
of the third series can be proved by Problem 16.12. 
16.15. The "if" part is implied by Problem 16.6. The "only if" part can be proved 
by the result of Problem 16.14. 

SOLUTIONS 
205 
16.4 Solutions 
16.1. Let E > 0. Then by Chebyshev's inequality (see Problem 15.1), Problem 13.7, 
and the assumption, we have 
M 
< 
E2nÂ· 
Hence 
This completes the proof. 
16.2. 
By the assumption that E [Xt] ~ K < oo and Problem 8.5, we get 
E [X~] < oo and E [XZJ < oo. Also from the assumption that Xn (n ~ 1) are in-
dependentandE(Xn) = O(n ~ 1), we have E[XiXjXkXz] = 0, E[XiXjX~] = 0, 
and E[XiXJ] = 0 for all distinct i, j, k, l. Therefore, we have 
E[S~J = E[(X1+X2+Â·Â·Â·+Xn)4] 
E [txt + 6 2: x; x;]. 
t=l 
â¢<J 
By Schwarz's inequality (Theorem 8.3), we have 
Combining the above two equations, we have 
E [s~J ~ nK + 3n(n -1)K ~ 3n2 K, 
which implies that 
By Problem 13.3 and the above inequality, we have 
[ 
00 
( s ) 4] 
00 3K 
E ~ :: 
~ ~ ~ 
< oo. 

206 
LAW OF LARGE NUMBERS 
By Problem 13.5, ( 5;) 4 ---+ 0 a.s. Hence we have 8nn ---+ 0 a.s. This completes the 
proof. 
16.3. 
(a) Let E > 0. By assumption that limn-Hxl Xn = 0, there exists an integer N 0,, 
such that 
E 
lx1l < 2c' 
Vj >No,,. 
Then by the property of A, we have 
00 
IYnl 
I>njXj 
j=1 
No,â¬ 
oo 
< L lan,jlÂ·lxjl + L 
ian,jlÂ·lxjl 
j=1 
j=No,,+1 
No,, 
< L lan,jlÂ·lxjl + ~Â­
j=1 
( 16.1) 
By the assumption that anj ---+ 0 as n ---+ oo for fixed j, there exists an integer 
Nj,< such that 
E 
lanjl < No,,(1 + lxjl)' 
\:In> Nj,<Â· 
Combining the above inequality into Equation (16.1) gives 
Since E > 0 is arbitrary, we have Yn ---+ 0 as n ---+ oo. 
(b) We write Yn as 
00 
Yn- X= L anj(Xj- x) + 
j=1 
(f= anj- 1) x, 
]=1 
n = 1,2, .... 
By the first item, we have 2::~ 1 anj(Xj - x) ---+ 0 as n---+ oo. By the assump-
tion that limn-+oo 2::~ 1 anj = 1, we have Yn - x ---+ 0 as n ---+ oo. Hence 
limn-too Yn =X. 
This completes the proof. 
16.4. Let C = ( Cij k:: 1 ,j:::: 1 be an infinite matrix defined by 
{ 
Uj 
b, 
Cij = 
O 
if j ~ i; 
if j > i. 

SOLUTIONS 
207 
By the assumption that bn -7 oo as n -7 oo, we have Cnj -7 0 as n -7 oo for fixed 
j. In addition, we have 
Therefore, by Problem 16.3, we have 
which is 
This completes the proof. 
16.5. Let Sn be defined as 
00 
lim L CnjXj = x, 
n--+oo j=1 
1 
n 
lim -
""""' a Â· x Â· = x. 
n--+oo bn L....t 
J 
J 
j=1 
n 
Sn+1 = LXj, 
n 2:: 1. 
j=1 
Taking b0 = 0 and s 1 = 0, we have 
(16.2) 
Let an = bn- bn-1 for n 2:: 1. Then an 2:: 0 and 2:.7=1 aj = bn. By Problem 16.4, 
we have 
lim ~ (~(b _
1 - b )s) =- lim ~ (~a s) = -x. 
n--+oo bn 
L....t 
J 
J 
J 
n--+oo bn 
L....t 
J J 
j=1 
j=1 
Note that sn+ 1 -7 x as n -7 oo. From Equation (16.2) we have 
This completes the proof. 
1 
n 
lim -
""""'b x = 0. 
n--+oo b 
L....t J 
J 
n j=1 

208 
LAW OF LARGE NUMBERS 
16.6. Let Sn = 2::;= 1 (XJ- E(XJ)), n = 1, 2, .... Then by Problem 9.8, to show 
that limn-too Sn exists a.s., we only need to show that for every E > 0, 
(16.3) 
By Problem 15.9, we have 
< 
1 . 
2 hmsup Var(Sn+m- Sn) 
E 
m--+oo 
< 
1 
m 
2 limsup z:=var(Xn+J)Â· 
E 
m--+oo j=1 
Note that 2::~= 1 Var(Xn) < oo, we have 
m 
limsup z:=var(Xn+J)-+ 0 
as 
n-+ oo. 
m-+oo j=1 
Combining the above two equations leads to Equation (16.3). This completes the 
proof. 
16.7. By assumption, we have 
~ (Xn - E(Xn)) = ~ 
Var(Xn) 
~ 
Var 
bn 
~ b2 
< oo. 
~1 
~1 
n 
Then by Problem 16.6, we know that 
exists a.s. Note that 
By Problem 16.5, we have 
lim Sn - E(Sn) = O 
n--+oo 
bn 
a.s. 

This completes the proof. 
16.8. Let Sn = 2::7=1 Xj, n = 1, 2, .... Note that 
Sn 
Sn-1 
Sn-1 
-----
n 
n-1 
n(n-1)' 
Since Sn/n--+ mas n--+ oo a.s. and lml < oo, we have 
which means that 
lim Xn = 0 a.s. 
n-+ n 
n?_l. 
P { liminf :n =lim sup :n = 0} = 1. 
Hence 
SOLUTIONS 
209 
P(limsup{IXnl ?_ n}) = P {lim sup l:nl ?_ 1} = 0. 
By the second Borel-Cantelli lemma (see Problem 12.9), we must have 
00 
LP(IXnl ?_ n) < oo. 
n=1 
By Problem 15.10, E(IX1 1) is finite a.s. By Theorem 16.3, we have E(IX11) = m 
a.s. This completes the proof. 
16.9. 
(a) By definition, Xn ~ 0 means that for every E > 0, we have 
lim P{IXnl ?_ E} = 0. 
n-+oo 
Note that P{IXnl ?_ E} = P{Xn = 1} = PnÂ· Hence Xn ~ 0 is equivalent to 
lim Pn = 0. 
n-+oo 
(b) First let us prove the "if" part. Suppose that 2::~= 1 Pn < oo. Then by the first 
Borel-Cantelli lemma (Theorem 2.2), we have 
P {limsupXn = 1} = P {limsup{Xn = 1}} = 0. 
Hence P {lim sup Xn = 0} = 1 as lim sup Xn can be either 0 or 1. Noting 
that limsupXn ?_ liminf Xn ?_ 0, we have 
P{limsupXn = liminfXn = 0} = 1, 

210 
LAW OF LARGE NUMBERS 
which implies that Xn ~ 
0. 
Next, let us prove the "only if' part. Suppose that Xn ~ 
0. Then we have 
P {limsupXn = liminf Xn = 0} = 1, 
which implies that P{lim sup Xn = 1} = 0. By the second Borel-Cantelli 
lemma (see Problem 12.9), we have 
00 LPn < 00. 
n=1 
This completes the proof. 
16.10. 
(a) Let Yn = ln Xn for n 2:: 1. Then by the assumption, we have E[IY1 1] < oo. 
Hence by Theorem 16.3, we have 
lim y1 + y2 + ... + Yn = E[Y1], 
n-+oo 
n 
a.s. 
But 
Hence we have 
(b) If X 1 is a uniformly distributed random variable on (0, 1), we have 
E[lnX1] = 1
1 lnxdx = x lnxl~ -1
1 1dx = -1. 
Hence the numerical value is eP -1. 
This completes the solution. 
16.11. By the assumption and Problem 16.6, we know that the sequence 
00 L XnJ{IXni:'Oa} 
n=1 
converges with probability one. Now let 
n 
Sn = L XiJ{IXil>a}â¢ 
n 2:: 1. 
i=1 

SOLUTIONS 
211 
Let E > 0. Then for each n 2:: 1, we have 
00 
U{ISn+j- Bnl > E} 
j=l 
In fact, let 
00 
C 
U{IXn+jl >a}. 
j=l 
Then we must have w E { IXn+k I > a} for some k 2:: 1. This gives 
00 
wE U{IXn+jl >a}. 
j=l 
(16.4) 
Hence Equation (16.4) holds. By the assumption that L~=l P{IXnl > a} con-
verges, we have 
lim P{IXn+jl >a}= 0. 
n-+oo 
Hence by Equation (16.4), we have 
It follows from Problem 9.8 that limn-+oo Sn exists a.s. Note that 
00 
00 
00 
L Xn = L Xnf{IXnl~a} + L Xnf{IXnl>a}Â· 
n=l 
n=l 
n=l 
The result holds. This completes the proof. 
16.12. Let >. > 0. Let T be defined as T = inf { n 2:: 1 : I Sn I > >.}. Since 

212 
LAW OF LARGE NUMBERS 
{ T = j} is independent of lj+l, lj+2 , .... Then for N ~ 1, we have 
N 
E[SF,I{r:'ON}] = 
L E[SF,J{r=j}] 
Hence we have 
j=l 
N 
LE [(SJ + 2Sj(SN- Sj) + (SN- Sjf)J{r=j})] 
j=l 
N 
N 
L 
E [SJI{r=j}] + LE[2Sjl{r=j}]E[SN- Sj] 
j=l 
j=l 
N 
+ LE [(SN- Sj)2] E [I{r=j}] 
j=l 
N 
N 
< LE[(Sj-r+lj)2I{r=j}] + LE[SF,r]P{T=j} 
j=l 
j=l 
N 
N 
< LE [(.X+ c) 2I{r=j}] + E [SF,] LP{T = j} 
j=l 
[(.X+ c) 2 + E [SF_r]J P{T S N} 
< (A+ c) 2 + E [SF_r] P{T S N}. 
j=l 
E [SF_r] 
E [SF_rl{r:'ON}] + E [SF_rl{r>N}] 
< 
(-X+c) 2 +E[SF_r]P{TSN}+-X2P{T>N}, 
which gives 
By the assumption that Sn converges a.s., we have 
P {sup ISnl < oo} = 1, 
n?l 
which gives 
lim P {sup ISnl < .x} = 1. 
.>..--+oo 
n?l 
Hence for sufficiently large A, we have P { supn> 1 I Sn I < A} > 0. Therefore 
~ [ 2] _ . 
[ 2] < 
(A+ c? 
6E Yj 
-
hm E SN - P{ 
IS I A}< oo. 
. 
N--+oo 
SUPn>l 
n S 
J=l 
-

SOLUTIONS 
213 
This completes the proof. 
16.13. Let (0, Â§, P) be the probability space on which {Yn}n;-:::1 are defined. Let 
Zn be random variables on (0 X 0, Â§ 0 Â§, p X P) that are defined as 
Zn(w1,w2) = Yn(wl)- Yn(w2), 
(w1,w2) E 0 x 0. 
Then we have E[Zn] = 0 and by Theorem 10.2, we obtain 
E [z~] 
{ 
Z~d(P x P) 
loxo 
l (in [Y;(w1)- 2Yn(wl)Yn(w2) + Y;(w2)] P(dwl)) P(dw2) 
l (E [Y;) - 2E[YnJYn(w2) + Y;(w2)) P(dw2) 
E [Y;] - 2E[Yn]E[Yn] + E [Y;] 
2Var(Yn)Â· 
Note that IZnl :::=; 2c for all n ?: 1 and 2::~= 1 Zn converges a.s. By Problem 16.12, 
we have 
00 
Hence we have 
00 L Var(Yn) < 00. 
n=1 
It follows from Problem 16.6 that 2::~= 1 (Yn- E[Yn]) converges a.s. By the assump-
tion that 2::~= 1 Yn converges a.s., 2::~= 1 E[Yn] converges a.s. This completes the 
proof. 
16.14. 
(a) Assume that 2::~= 1 P{IXnl >a} does not converge. Then we have 
00 L P{IXnl >a}= oo. 
n=1 
Then by the second Borel-Cantelli lemma (see Problem 12.9), we have 
P(limsup{IXnl >a})= 1. 
However, with 

214 
LAW OF LARGE NUMBERS 
we have 
By Problem 9.8, L~=l Xn does not converge. This contradicts the assumption. 
Hence L~=l P{!Xn! >a} converges. 
(b) Let 
n 
i=l 
Then, for E > 0, we have 
00 
00 
j=l 
j=l 
which gives 
By part (a) of this proof, we have 
It follows from Problem 9.8 that Sn converges a.s. Therefore the sequence 
00 
00 
00 
n=l 
n=l 
n=l 
converges a.s. Then by Problem 16.13, L~=l E[Xni{IXni:'Oa}] converges. 
(c) Let 
Yn = Xnl{!Xni:'Oa} - E[X,J{IXni:'Oa}], 
n ~ 1. 
By part (b) of this proof, we know that L~=l Yn converges a.s. Also note that 
E[Yn] = 0 
and 
!Ynl :S: IXnl{IXni:'Oa}l + E[IXnl{IXni:'Oa}IJ :S: 2a. 
It follows from Problem 16.12 that 
00 
00 
n=l 
n=l 

BIBLIOGRAPHIC NOTES 
215 
This completes the proof. 
16.15. Let us prove the sufficiency first. Suppose that 
00 
La~< oo. 
n=1 
Then we have 
00 
CXl 
n=1 
n=1 
It follows from Problem 16.6 that 2.:~= 1 anXn converges a.s. 
Now let us prove the necessity. Suppose that 2.:~= 1 anXn converges a.s. Let 
a > 0. Then by Problem 16.14, we know that 2.:~= 1 P{lanXnl > a} converges. 
But lanXnl = lanlÂ· Hence there exists an integer N > 0 such that I ani ::::; a for all 
n ~ N. Therefore, we have 
00 
00 
La~= L 
Var(anXni{IanXni:Sa})Â· 
n=N 
n=N 
Also by Problem 16.14, we have 
00 
L 
Var(anXni{IanXni:Sa}) < 00, 
n=1 
which leads to 
00 
La~< oo. 
n=N 
This completes the proof. 
16.5 Bibliographic Notes 
In this chapter, we presented some results on law of large numbers. The weak law 
of large numbers is about a sequence of random variables converging in probability, 
while the strong law of large numbers is about a sequence of random variables con-
verging almost surely. A proof of Theorem 16.3 based on Chebyshev's inequality 
can be found in Bhattacharya and Waymire (2007, p51). 
For more information about the law of large numbers, readers can consult text-
books such as Billingsley ( 1999), Chung (2000), and Bhattacharya and Waymire 
(2007). 


CHAPTER17 
CHARACTERISTIC FUNCTIONS 
Characteristic functions provide an important tool to study the distributional proper-
ties of random variables and sums of independent random variables. In particular, 
characteristic functions can be used to characterize the probability distribution of a 
random variable and to identify the limit distribution of a sequence of random vari-
ables. In this chapter, we present characteristic functions and relevant results. 
17.1 
Basic Concepts and Facts 
Definition 17.1 (Moment Generating Function). Let X be a random variable. Then 
the moment generating function of X is defined as 
Mx(t) = E (etx), 
t E R. 
(17.1) 
The moment generating function of a random vector X= (X1 , X2 , ... , Xn)T is 
defined as 
(17.2) 
Measure, Probability, and Mathematical Finance. 
217 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

218 
CHARACTERISTIC FUNCTIONS 
Definition 17.2 (Cumulant Generating Function). Let X be a random variable. Then 
the cumulant generating function of X is defined as 
Cx(h) = ln(Mx(h)), 
(17.3) 
where M x (h) is the moment generating function of X. 
Definition 17.3 (Characteristic Function of Random Variables). Let X be a random 
variable. Then the characteristic function of X is defined as 
cf>x(t) = E (eitX) = E[cos(tX)] + iE[sin(tX)], 
t E R, 
(17.4) 
where i = J=I is the imaginary number. 
The characteristic function of a random vector X = (XI' x2, 0 
0 
0 'Xn)T is de-
fined as 
(17.5) 
Definition 17.4 (Characteristic Function of Probability Measures). Let J.L be a prob-
ability measure on (R, B). Then the characteristic function of J.L is defined as 
fj,(t) = L 
eitxJ.L(dx), 
t E R. 
(17.6) 
Definition 17.5 (Characteristic Function of Distribution Functions). Let F be a cu-
mulative distribution function on (R, B). Then the characteristic function ofF is 
defined as flp(t), where J.LF is the Lebesgue-Stieltjes measure corresponding to F. 
Theorem 17.1 (Fourier Uniqueness Theorem). Let X andY be two random vari-
ables. Thencf>x(t) = cpy(t)forallt E Rifandonlyif.Cx = Ly, that is, ifand 
only if X and Y have the same distribution. 
Theorem 17.2 (Kac's Theorem). Let X 1, X 2, ... , Xn be Rd-valued random vari-
ables. Then X 1, X 2Â· ... , X n are independent if and only if for all u 1, u2, ... , Un E 
Rd, we have 
n 
=IT cf>xj(uj)Â· 
j=l 
17.2 Problems 
17.1. Let X andY be independent random variables. Show that 
Mx+y(t) = Mx(t)My(t), 
t E R, 

PROBLEMS 
219 
where Mx+Y(t), Mx(t), and My(t) are themomentgeneratingfunctions of X +Y, 
X, andY, respectively. 
17.2. Let X andY be independent random variables. Show that 
Â¢x+Y(t) = Â¢x(t)Â¢y(t), 
t E R, 
where Â¢ x + y ( t), Â¢ x ( t), and if;y ( t) are the characteristic functions of X+ Y, X, and 
Y, respectively. 
17.3. Let {Ft}a<t<b be a collection of random variables on the probability space 
(0, Â§, P) with finite expectations. Suppose thatforeachw E 0 and each t E (a, b), 
the derivative 
F;(w) = :tFt(w) 
exists. Show that 
(a) For every t E (a, b), Ff is a random variable. 
(b) For every t, t +hE (a, b), we have 
I Ft+\- Ft I ::; Y. 
(c) If there exists a random variable Yon (0, Â§, P) with a finite expectation such 
that for all t E (a, b), we have 
IF:I ::; Y, 
then for all t E (a, b), the function f ( t) = E ( Ft) is differentiable and has a 
finite derivative. 
17.4. Let X be a random variable with Mx(t) < oo fort E ( -t0 , t 0), for some 
to > 0. Show that 
(a) E(IXnl) < oo for all n ~ 0. 
(b) For any t E ( -t0 , t0 ), we have 
(c) For any j ~ 0, the jth derivative at t = 0 is 
17 .5. Let X be a random variable. Suppose that M x ( t) < oo for all t E ( r - t0 , r + 
to), where to > 0, r E R, and Mx(t) is the moment generating function of X. 
Show that 

220 
CHARACTERISTIC FUNCTIONS 
(a) E [IXnerX IJ < oo for all n ~ 0; 
(b) For any j ~ 0, we have 
17.6. Let X be a nondegenerate random variable. Suppose that Mx(t) < oo for all 
t E R, where Mx(t) is the moment generating function of X. Show that 
(a) Mx(t) is a convex function on R. 
(b) C x ( t) is a convex function, where C x ( t) is the cumulant generating function. 
17.7. Let { Xn}n>l be a sequence of independent and identically distributed random 
variables with common mean m and with Mx1 (t) < oo fortE (-a, b), where a> 0 
and b > 0. Show that for any E > 0, we have 
(a) 
Mx (t) 
inf 
1 
< 1. 
D<t<b exp(t(m +E)) 
(b) 
where 
. f 
Mx1 (t) 
p= m 
D<t<b exp(t(m +E)) 
17.8. Let X be a random variable on a probability space (0, $, P). Let lc/>x(t)l be 
the norm given by 
1 
lc/>x(t)l = [(E[costX]) 2 + (E[sintX]) 2] 2 . 
Show that lc/>x(to)l = 1 for some t0 -1- 0 if and only if there exist a E Rand h -1- 0 
such that 
P{X E {a+ jh: j E Z}} = 1. 
17.3 Hints 
17 .1. Use the result of Problem 12.7 and Theorem 13 .2. 
17.2. 
Follow the definition of characteristic functions (Definition 17.3) and use 
trigonometric identities to expand Â¢ x + y ( t) as 
E[cos(tX + tY)] + iE[sin(tX + tY)] 
E[cos(tX) cos(tY)- sin(tX) sin(tY)] 
+iE[sin(tX) cos(tY) + cos(tX) sin(tY)]. 

SOLUTIONS 
221 
Then use the result of Problem 12.7 and Theorem 13.2. 
17.3. To prove part (a), follow the definition of random variables (Definition 11.6) 
and use the result of Problem 5.9. To prove part (b), use the mean value theorem 
(Theorem 15.1). Use part (b) and the dominated convergence theorem (Theorem 
6.4) to prove part (c). 
17.4. Part part (a) can be proved by using the inequality lxl < elxl. To prove part 
(b), consider the following sequence 
n 
tkXk 
Sn=L~Â· n2:0. 
k=O 
Then use the dominated convergence theorem (Theorem 6.4) to show that 
E ( lim Sn) = lim E (Sn) . 
n--+ oo 
n--+ oo 
Part (c) is implied from part (b). 
17.5. Consider the random variable X under the probability measure P defined as 
-
erx 
P(dx) = Mx(r) P(dx), 
and use the result of Problem 17 .4. 
17.6. Use the results of Problems 17.5 and 15.4 to prove part (a). Use Schwarz's 
inequality (Theorem 8.3) to prove part (b). 
17.7. Part (a) can be proved by considering the function 
f(t) = E [et(X-m-â¢)] 
and its derivative at 0. Part (b) can be proved by consider the integration of X 1 + 
X2 + Â· Â· Â· + Xn over the set {(X1 + X2 + Â· Â· Â· + Xn)/n 2: m + c:}. 
17.8. To prove the "only if' part, consider the characteristic function of X- a0 jt0 , 
where ao is a real number such that Â¢ x ( t0 ) = e iao â¢ 
17.4 Solutions 
17.1. 
Lett E R. By Theorem 5.2, the functions f(x) = etx and g(y) = ety 
are Borel measurable. Then by Problem 12.7 and the assumption that X andY are 
independent, etx and etY are independent. By Theorem 13.2, we have 
Mx+Y(t) 
E [et(X+Y)] 
E [etXetY)] 
E [etx] E [etY)] 
Mx(t)My(t). 

222 
CHARACTERISTIC FUNCTIONS 
This completes the proof. 
17.2. By Definition 17.3 and the trigonometric identities, we have 
E[cos(tX + tY)] + iE[sin(tX + tY)] 
E[cos(tX) cos(tY)- sin(tX) sin(tY)] 
+iE[sin(tX) cos(tY) + cos(tX) sin(tY)]. 
By the assumption that X andY are independent, Problem 12.7, and Theorem 13.2, 
the above equation can be written as 
Â¢x+Y(t) = 
E[cos(tX)]E[cos(tY)]- E[sin(tX)]E[sin(tY)] 
+iE[sin(tX)]E[cos(tY)] + iE[cos(tX)]E[sin(tY)] 
(E[cos(tX)] + iE[sin(tX)])(E[cos(tY)] + iE[sin(tY)]) 
Â¢x (t)Â¢Y (t). 
This completes the proof. 
17.3. 
(a) Lett E (a, b) and tn = t + 1/n for n = 1, 2, .... By the assumption, we have 
lim n(F1 
-
Ft) = F{. 
n--+OCJ 
n 
It follows from Problem 5.9 that Ff is also ,~-measurable. Hence Ff is a ran-
dom variable. 
(b) Lett, t +hE (a, b). Then by Theorem 15.1, we have 
Ft+h- Ft = F' 
h 
c 
for some c between t and t + h. Thus 
(c) Lett E (a, b). Let {t,}n>l be an arbitrary sequence of real numbers in (a, b) 
such that tn ---+ t as n---+ oo. Then by part (b), for every n ;::: 1, we have 
It follows from Theorem 6.4 that 
J: = lim E [Ftn- Ft] = E [lim Ft"- Ft] = E[F[l. 
n-+oc 
tn - t 
n-+= tn - t 

SOLUTIONS 
223 
Since IE[F:J I :<:; E[IFÂ£ IJ :<:; E[Y] < oo, it follows that fÂ£ is finite. 
This completes the proof. 
17.4. 
(a) If n = 0, the result holds obviously. Let n > 0 and t E ( -t0 , t0). Since 
lxl < elxl for all x E R, we have 
which gives 
Then we have 
(b) Lett E ( -t0 , to). Define 
Then we have 
Note that 
Is I<~ ltXIk < eltXI. 
n 
-
L...t 
k! 
k=O 
and Bn ~ etx. By Theorem 6.4, we have 
lim E(Sn) = E [ lim Bn] , 
n-+oo 
n-too 
which gives 
(c) By the second item, Mx(t) is a polynomial oft. Hence the result is obtained 
by taking derivatives of Mx(t). 
This completes the proof. 

224 
CHARACTERISTIC FUNCTIONS 
17.5. Let P be a probability measure defined as 
-
erx 
P(dx) = Mx(r) P(dx), 
where Pis the underlying probability for X. Let Mx(t) be the moment generating 
function of X under the probability measure P. Then we have 
(a) By the assumption that Mx(t) < oo in the neighborhood of r, we know that 
Mx(t) < oo in the neighborhood of r. By Problem 17.4, we have 
where E p is the expectation under the measure P. But 
which gives 
E[IXnerXIJ < oo, 
n?: 0. 
(b) By Problem 17 .4, for j ?: 0, we have 
MJfl(t) = Ep[XJ]. 
Hence 
which leads to 
This completes the proof. 
17.6. 
(a) By Problem 17.5, we have 
Mfl(t) = E[X2etx] > 0, 
t E R. 
It follows from Problem 15.4 that Mx(t) is a convex function on R. 
(b) By Problem 17.5, we have 
cfl(t) 
= 
Mfl(t)Mx(t)- (Mj}l(t))2 
M}(t) 
E[X2etX]E[etX]- (E[Xetx])z 
Mk(t) 

SOLUTIONS 
225 
By Theorem 8.3, we have 
Hence we have df)(t) ~ 0. By Problem 15.4, Cx(t) is a convex function on 
R. 
This completes the proof. 
17.7. 
Let f ( t) be defined as 
f(t) = E [et(X-m-â¬)], 
t E (-a,b). 
Then we have f(O) = 1 and, by Problem 17.4, we have 
j'(O) = E(X- m-E)= -E < 0. 
Hence f is decreasing around 0. Therefore we must have f(t) < 1 for all 
positive t that are sufficiently close to 0. 
(a) Lett E (O,b) andSn = X1 +X2+Â· Â· Â·+Xn. NotethattheXn are independent 
and identically distributed. By Problem 17.1, we have 
E [et8n] = Mx1+X2 + .. Â·+Xn(t) = Mx1(tt 
But 
Hence we have 
Since tis an arbitrary number in (0, b), we have 

226 
CHARACTERISTIC FUNCTIONS 
This completes the proof. 
17.8. Let us first prove the "if" part. Suppose that there exist a E Rand hi=- 0 such 
that 
P{X E {a+ jh: j E Z}} = 1. 
Let P{X = a+ jh} = Pj for j E Z. Noting that cos(x- y) = cosxcosy + 
sin x sin y, we have 
(l::>j cos(t(a + jh))) 
2 + (LPj sin(t(a + jh))) 
2 
JEZ 
JEZ 
= LPJ + LPiPj cos(th(j- i)). 
jEZ 
i-1-J 
Letting to= 21rjh gives I<Px(to)l = 1. 
Now let us prove the "only if" part. Suppose that there exists t0 =i=- 0 such that 
11> x (to) I = 1. Then there exists a0 E R such that 
1>x(to) = eiao. 
Let a= a0 jt0 . Then the characteristic function of X- a is e-ia1>x(t). Hence we 
have E[exp(it0(X- a)] = 1. Equating the real parts gives 
E[cos(t0(X- a))]= 1. 
Since I cos Bl :::; 1 and cos e = 1 if and only if e = 27rj for some j E Z, the above 
equation implies that 
P{to(X- a) E {27rj: j E Z}} = 1. 
The result holds with h = 21r jt0 . This completes the proof. 
17.5 Bibliographic Notes 
Most material in this chapter was taken from Rosenthal (2006, Chapters 9 and 11 ). 
For more information about characteristic function, readers are referred to Lukacs 
( 1970), Billingsley ( 1995), Chung (2000), Athreya and Lahiri (2006), Klenke (2006), 
Rao and Swift (2006), Koralov and Sinai (2007), and Bhattacharya and Waymire 
(2007). In particular, Athreya and Lahiri (2006) discussed the criteria for a function 
to be a characteristic function. 
A proof of Theorem 17.1 can be found in Rosenthal (2006, Corollary 11.1. 7). 
Theorem 17.2 was adopted from Applebaum (2009, Theorem 1.1.16). For a proof of 
Theorem 17.2, readers are referred to Pascucci (2011, Corollary A.91). 

CHAPTER18 
DISCRETE DISTRIBUTIONS 
Discrete distributions are used to describe random variables that can only take count-
ably many different values. In this chapter, we present several discrete probability 
distributions and their properties. 
18.1 
Basic Concepts and Facts 
Definition 18.1 (Bernoulli Distribution). Let 0 = { 0, 1} and p E (0, 1). A random 
variable X on (0, 2Â°) is said to have a Bernoulli distribution with parameter p, 
written as X"' Be(p), if and only if 
P{X = k} = pk(1- P?-k, 
k = 0, 1. 
Definition 18.2 (Binomial Distribution). Let n = {0, 1, 2, ... , n }, where n is a 
positive integer, and p E (0, 1). A random variable X on (0, 2Â°) is said to have a 
binomial distribution with parameters (n,p), written as X"' B(n,p), if and only if 
Measure, Probability, and Mathematical Finance. 
227 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

228 
DISCRETE DISTRIBUTIONS 
where q = 1 - p and 
n! 
n(n-1)Â·Â·Â·(n-k+1) 
k!(n-k)! 
k(k-1)Â·Â·Â·1 
When n = 1, the binomial distribution is the same as the Bernoulli distribution. 
Definition 18.3 (Poisson Distribution). Let 0 = {0, 1, 2, ... } and() > 0. A random 
variable X on (0, 211 ) is said to have a Poisson distribution with parameter(), written 
as X ,...., P( e), if and only if 
e-&ek 
P{X=k}=~, k=0,1,2, ... . 
Definition 18.4 (Geometric Distribution). Let 0 = {0, 1, 2, ... } and p E (0, 1). A 
random variable X on (0, 211 ) is said to have a geometric distribution with parame-
ters p, written as X,....., G(p), if and only if 
P{X = k} = (1-p)pk, 
k = 0,1,2, .... 
Definition 18.5 (Negative Binomial Distribution). Let 0 = {0, 1, 2, ... }, r > 0, 
and p E (0, 1 ). A random variable X on (0, 211 ) is said to have a negative binomial 
distribution with parameters (r,p), written as X,...., NB(r,p), if and only if 
When r = 1, the negative binomial distribution is the same as the geometric 
distribution. 
Definition 18.6 (Hypergeometric Distribution). Let N, m, and n be integers such 
thatN ~ 1, 0 :S m :S N, and 1 :S n :S N. LetO = {k E Z: max(O,n+m-N)::; 
k::; min(m, n)}. A random variable X on (0, 211 ) is said to have a hypergeometric 
distribution with parameters (N, m, n), written as X,...., HG(N, m, n), if and only if 
P{X = k} = 
18.2 Problems 
18.1. Let 0 = {0, 1, 2, ... , n }, where n is a positive integer. Let X be a binomial 
random variable with parameters (n,p) on (0, 211 ). Show that 

PROBLEMS 
229 
and 
Mx(t) = (I- P + petr, 
where Â¢x(t) and Mx(t) are the characteristic function and the moment generating 
function of X, respectively. 
18.2. Letnbeapositiveintegerandpt,p2,Â·Â·Â·,Pn E (0,1). LetXl,X2, ... ,Xn 
be n independent random variables such that 
Xk "'Be(pk), 
k = 1, 2, ... , n. 
Let M be a random variable defined as 
Show that 
M"' Be(>-.), 
where 
n 
).. = 1- IT (1 - Pk)Â· 
k=l 
18.3. Let X be a binomial random variable with parameters ( n, p). Show that 
E(X) = np 
and 
Var(X) = np(1 - p). 
18.4. Let n1 and n2 be positive integers and p E (0, 1). Let X1 and X2 be inde-
pendent random variables having binomial distributions with parameters ( n1, p) and 
( n2, p), respectively. Find 
(a) The distribution of X1 + X2. 
(b) The conditional probability distribution of X1 given X 1 + X2 = k, where k is 
an integer in [0, n1 + n2]. 
18.5. Let X "' B(n,p); that is, X is binomially distributed with parameter (n,p). 
Show that for any integer mE [1, n], we have 
'""" 
pk(1 _ p)n-k = 
Xm-1(1 _ x)n-mdx. 
n (n) 
n! 
1P 
{;;:, 
k 
(m- 1)!(n- m)! 
0 
18.6. Let).. > 0 be a real number. For each integer n > >-., let Xn "' B (n, >-.jn). 
Show that for any fixed integer m, we have 
lim P{Xn = m} = e-.\)..m1â¢ 
n-+oo 
m. 

230 
DISCRETE DISTRIBUTIONS 
18.7. Let X be a Poisson random variable with parameter(), that is, X "' P(()). 
Show that 
Â¢x(t) = exp [e (eit- 1)], 
and 
Mx(t) = exp [e (et- 1)], 
where Â¢ x ( t) and M x ( t) are the characteristic function and the moment generating 
function of X, respectively. 
18.8. Let X be a Poisson random variable with parameter(), that is, X "' P(()). 
Show that 
E(X) = () 
and 
Var(X) =e. 
18.9. Let >'1 > 0 and .A2 > 0 be real numbers. Let X 1 and X 2 be independent ran-
dom variables having Poisson distributions with parameters .A1 and .A2 , respectively. 
Find 
(a) The distribution of X1 + X2. 
(b) The conditional probability distribution of X1 given X1 + X2 = k, where k 2: 0 
is an integer. 
18.10. Let n be a positive integer and P1, P2, ... , Pn E (0, 1). Let X1, X2, ... , Xn 
be n independent random variables such that 
Xk "'G(pk), 
k = 1, 2, ... , n, 
where G(pk) denotes the geometric distribution with parameter PkÂ· Let Y be a ran-
dom variable defined as 
Show that Y"' G(p), where 
n 
18.3 Hints 
18.1. Note that the characteristic function is defined as E [ eitX], and use the bino-
mial expansion 

SOLUTIONS 
231 
18.2. Follow the definition of Bernoulli distribution (Definition 18.1) and use the 
result of Problem 12.5. 
18.3. Use the moment generating function and the result of Problem 17 .4. 
18.4. To prove part (a), use the results of Problems 18.1 and 17 .2, and the Fourier 
uniqueness theorem (Theorem 17.1). To prove part (b), use the result of part (a) and 
follow the definition of conditional probabilities (Definition 14.6). 
18.5. Use integration by parts and the method of mathematical induction. 
18.6. Consider ln P{ Xn = m} and use l'Hopital's rules. 
18.7. Use the Taylor series for the exponential function ex: 
00 
k 
X 
"""'X 
e = ~kfÂ· 
k=O 
18.8. Use the moment generating function of X and the result of Problem 17.4. 
18.9. To prove part (a), use the results of Problems 18.7 and 17.2, and the Fourier 
uniqueness theorem (Theorem 17.1). To prove part (b), use the result of part (a) and 
follow the definition of conditional probabilities (Definition 14.6). 
18.10. Note that 
P{Y = m} = P{Y > m- 1} - P{Y > m }, 
and use the definition of geometric distribution (Definition 18.4) and the result of 
Problem 12.5. 
18.4 Solutions 
18.1. By definition, we have 
n L eitk P{X = k} 
k=O t eitk (n) pkqn-k 
k=O 
k 
t (n) (peit) k qn-k 
k=O 
k 
(peit + q)n. 

232 
DISCRETE DISTRIBUTIONS 
Since q = 1 - p, the result follows from the above equation. Similarly, we can show 
that 
18.2. Since X1, X2, ... , Xn are independent, by Problem 12.5 we have 
P{M = 0} 
P{X1 = O,X2 = 0, ... ,Xn = 0} 
n II P{Xk = 0} 
k=l 
n II (1- Pk) 
k=l 
1- >.. 
Since X 1, X2, ... , Xn are all Bernoulli random variables, we know that M = 0 or 
1. Hence 
P{M = 1} = 1- P{M = 0} = >.. 
Therefore, M,....., Be(>.). This completes the proof. 
18.3. By Problem 17.4, we have 
E(X) = MJfl (0) 
and 
Var(X) = E [X2] - (E[X])2 = Mfl(o)- (E[X]f. 
By Problem 18.1, we have Mx(t) = (1- p + pet)n. Hence 
MJfl(t) = npet (1- p + petr-1 
and 
Therefore, we have 
E(x) = np 
and 
Var(X) = np(1- p). 
This completes the proof. 
18.4. 
(a) Since X 1 and X 2 are independent, it follows from Problems 18.1 and 17.2 that 
( ) 
( 
it) n, +n2 
r/JX+Y t = 1-p+pe 
. 

SOLUTIONS 
233 
By the Fourier uniqueness theorem (Theorem 17.1), we know that X1 + X2 "' 
B(n1 + n 2,p), that is, X 1 + X 2 has a binomial distribution with parameter 
(n1 + n2,p). 
(b) By Definition 14.6, we have 
P({X1 = x} n {X1 + X2 = k}) 
P{X1+X2=k} 
P({X1 = x} n {X2 = k- x}) 
P{X1+X2=k} 
P{X1 = x}P{X2 = k- x} 
P{X1+X2=k} 
By part (a) and the assumption, we have 
and 
P{Xl = x} = ( :1) px(l- p)n,-x, 
P{X2=k-x}= ( n2 )Pk-x(l-p)n2-k+x, 
k-x 
P{Xl + X2 = k} = ( nl: n2) pk(l- p)n,+n2-k. 
Hence we have 
which is a hypergeometric distribution with parameter ( n 1 + n2 , n 1 , k ). 
This completes the solution. 
18.5. We use the method of mathematical induction on m. When m = 1, we have 

234 
DISCRETE DISTRIBUTIONS 
and 
n! r (1- x)n- 1dx = -(1- xtlb = 1- (1- p)n. 
(n-1)!}0 
Hence the result holds for m = 1. 
Suppose that the result holds form = m 0 for some integer m0 E [1, n]: 
~ (n) pk(1- p)n-k = 
n! 
{P Xmo-1(1- x)n-modx. 
L....t 
k 
(mo- 1)!(n- mo)! }0 
k=mo 
(18.1) 
We consider the case when m = m0 + 1. In this case, the integration by parts gives 
(18.2) 
Combining Equations (18.1) and (18.2) gives 
which shows that the result also holds from m = m 0 + 1. Therefore, the result holds 
for all integers in [1, n]. This completes the proof. 
18.6. Since Xn "'B(n, )..jn), we have 
which gives 
( )..m) 
( 
)..) 
m-1 
( 
') 
lnP{Xn = m} = ln 
m! 
+ (n- m) In 1- ~ + t; ln 1- ~ . 
Since 
lim ~
1 ln (1 - .L) = 0 
n--+oo L....t 
n 
j=O 

SOLUTIONS 
235 
and by l'Hopital's rules, 
lim (n- m) ln (1- ~) 
n--+oo 
n 
ln(1- ~) 
lim 
1 
x 
x--+oo 
(x-m) 
' 1' 
(x- m)2 
-A 1m 
x--+oo x2 -
AX 
-A, 
we get 
lim lnP{Xn = m} = ln (Ami) -A. 
n--+oo 
m. 
Hence 
Am 
lim P{Xn = m} = e->--1â¢ 
n--+oo 
m. 
This completes the proof. 
18.7. By definition, we have 
k=O 
Sirnilary, we can show that 
Mx(t) = exp [0 (et- 1)], 
This completes the proof. 
18.8. 
To calculate the mean and variance of X, we use the moment generating 
function of the Poisson distribution from Problem 18.7: 
Mx(t) = exp [0 (et- 1)]. 
The first derivative and the second derivative of the moment generating function are 
and 

236 
DISCRETE DISTRIBUTIONS 
respectively. Hence we have 
and 
Var(X) = E [X2] - (E[X])2 = Mfl(O)- (E[X])2 =e. 
This completes the proof. 
18.9. 
(a) Since X 1 and X 2 are independent, it follows from Problems 18.7 and 17.2 that 
By the Fourier uniqueness theorem (Theorem 17.1), we know that X 1 + X2"' 
P(>q + >.2), that is, X 1 + X 2 has a Poisson distribution with parameter .-\1 + .-\2. 
(b) By Definition 14.6, we have 
P({X1 = x} n {X1 + X2 = k}) 
P{X1 +X2 = k} 
P({X1 =x}n{X2 =k-x}) 
P{X1+X2=k} 
P{X1 = x}P{X2 = k- x} 
P{X1+X2=k} 
By part (a) and the assumption, we have 
and 
Hence we have 
Ak-x 
P{x - k 
} -
-.A2 
2 
2 -
- x - e 
.,.-( k-'_"--x,.-,)! , 
P{X1 = xiX1 + X2 = k} 
-.A1 ~ -.A2 ;_~-x 
e 
x! e 
(k-x)! 
-.A1 -.A2 (.A1 +.A2)k 
e 
k! 
which is a binomial distribution with parameter (k, .XI/(>.1 + .-\2)). 

BIBLIOGRAPHIC NOTES 
237 
This completes the solution. 
18.10. Letm 2: Obe an integer. SinceX1, X2, ... , Xn are independent, by Problem 
12.5 we have 
P{Y > m} 
Hence we have 
P{X1 > m,X2 > m, ... ,Xn > m} 
n II P{Xk > m} 
k=l 
n II PZ'+l 
k=l 
pm+l. 
P{Y = m} = P{Y > m -1}- P{Y > m} = pm- pm+l = (1- p)pm, 
which shows that Y is geometrically distributed with parameter p. This completes 
the proof. 
18.5 Bibliographic Notes 
In this chapter, we presented several discrete distributions. These discrete distribu-
tions are probably discussed in many books. Johnson et al. (2005) discussed many 
advanced results of discrete distributions regarding their history, properties, estima-
tion, applications, and recent developments. Kinney (2009) introduced many ex-
amples of statistical distributions including discrete distributions. Balakrishnan and 
Nevzorov (2003) is a textbook on statistical distributions, which also discussed these 
discrete distributions. For more information about discrete distributions, readers are 
referred to Feller (1968), Wimmer and Altmann (1999), and Evans et al. (2000). 


CHAPTER 19 
CONTINUOUS DISTRIBUTIONS 
Unlike the discrete distributions described in the previous chapter, continuous distri-
butions are used to describe random variables that can take any number of values. In 
this chapter, we present some common continuous distributions and their properties. 
19.1 
Basic Concepts and Facts 
Definition 19.1 (Univariate Normal Distribution). A random variable X on (R, B) 
is said to be normally distributed with mean f..L and standard deviation 0', written as 
X""' N(J.L, 0'2), if and only if its probability density function is given by 
1 
( (x- J.L) 2 ) 
cp(f..L, 0', x) = O'y'27[ exp -
20'2 
, 
x E R. 
(19.1) 
A normal random variable is called a standard normal random variable if it has 
mean 0 and standard deviation 1. The probability density function of a standard 
normal random variable is denoted by cp(x). 
Measure. Probability. and Mathematical Finance. 
239 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

240 
CONTINUOUS DISTRIBUTIONS 
The cumulative density function of a normal random variable with mean J.L and 
standard deviation a is given by 
Jx 
1 Jx 
( (t- J.L?) 
<l>(J.L, a, x) = 
'P(J.L, a, t)dt = 
;cc 
exp -
2 
dt. 
-oo 
ay 271" 
-oo 
2a 
(19.2) 
The cumulative density function of a standard normal random variable is denoted 
by <I>(x) or N(x ). 
Definition 19.2 (Lognormal Distribution). Let J.L E Rand a > 0. A random variable 
X on ((O,oo),B(O,oo)) is said to have a lognormal distribution with parameters 
(J.L, a 2 ), written as X "' LN(J.L, a 2 ), if and only if X has the following probability 
density function 
f() 
1 
[ (lnx-J.L)2] 
x= 
exp 
, 
xav'21T 
2a2 
X> 0. 
(19.3) 
Definition 19.3 (Student's t-Distribution). Let v > 0. A random variable X on 
(R, B) is said to have a Student's t-distribution, written as X "' ST(v), if and only 
if X has the following probability density function: 
-
r ( v!l) 
x2 - v!l 
f (X) - Jil7ff ( ~) ( 1 + --;-) 
, x E R, 
(19.4) 
where r (.) is the gamma function defined as 
(19.5) 
Definition 19.4 (Cauchy Distribution). Let a, h E R. A random variable X on 
(R, B) is said to have a Cauchy distribution, written as X "'C(a, h), if and only if 
X has the following probability density function: 
h 
f(x) = (h2 + (x- a)2) 71"' 
X ER. 
(19.6) 
Definition 19.5 (Pareto Distribution). Let a > 0 and h > 0. A random variable X 
on ([h, oo), B[h, oo)) is said to have a Pareto distribution, written as X"' Pa(a, h), 
if and only if X has the following probability density function: 
aha 
f(x) = a+l, 
X~ h. 
X 
(19.7) 
Definition 19.6 (Beta Distribution). Let p > 0 and q > 0. A random variable 
X on ((0, 1), B(O, 1)) is said to have a standard beta distribution, written as X "' 
Beta(p, q), if and only if X has the following probability density function 
1 
f(x) = -( -)xP-1(1- x)q-1, 
x E (0, 1), 
B p,q 
(19.8) 

PROBLEMS 
241 
where B ( Â·, Â·) is the beta function defined as 
(19.9) 
Definition 19.7 (Gamma Distribution). Let a > 0 and() > 0. A random variable 
X on ( [0, oo), B[O, oo)) is said to have a gamma distribution with parameters a and 
(),written as X rv r(o:, ()),if and only if X has the following probability density 
function, where r(Â·, Â·)is the gamma function defined in Equation (19.5): 
f( ) 
1 
a-1 _!!: 
X = r(o:)()aX 
e 9' 
X E [0, oo). 
(19.10) 
The parameters a and () are known as the shape and scale parameters, respectively. 
If() = 1, then the distribution is called the standard gamma distribution. 
Definition 19.8 (Exponential Distribution). Let >. > 0. A random variable X 
on ( (0, oo ), B(O, oo)) is said to have an exponential distribution, written as X 
Exp(>.), if and only if X has the following probability density function 
f(x) = >.e->..x, 
x E (O,oo). 
(19.11) 
Definition 19.9 (Multivariate Normal Distribution). A random vector X= (X1 , X2 , 
... , Xn) T on (R n, B(Rn)) is said to have a multivariate normal distribution if its 
probability density function is given by 
(19.12) 
where f.L = (f.L1 , f.L2 , ... , f.Ln) T is the mean of X and 2: is the covariance matrix of X 
given by 
L:ij = Cov(Xi, Xj), i,j = 1, 2, ... , n. 
Theorem 19.1. Let X rv C(a, h). Then the characteristic function of X is given by 
c/>x(t) = eita-hltl. 
19.2 Problems 
19.1. Let X be a normal random variable with mean f.L and standard deviation a. 
Show that 
and 

242 
CONTINUOUS DISTRIBUTIONS 
where M x ( t) and Â¢ x ( t) are the moment generating function and the characteristic 
function of X, respectively. 
19.2. Let X= (XI, X2, ... , Xn)T on (Rn, B(Rn)) be a multivariate normal ran-
dom vector with a probability density function given by 
where J.t = (J.LI, J.L2, ... , J.Ln)T is the mean vector and~ is the covariance matrix. 
Show that the characteristic function of X is 
Â¢x(t) =exp (itTJ.t_ ~tT~t). 
19.3. Let X and Y be two independent normal random variables with means f..LI and 
J.L2, and variances O"f and O"~. Show that aX+ bY is normally distributed with mean 
aJ.LI + bJ.L2 and variance a 20"f + b2 0"~. 
19.4. Let (X, Y) be bivariate normally distributed. Show that the linear combination 
of X and Y is a normal random variable, that is, aX + bY is normally distributed 
fora,b E R. 
19.5. Let X= (XI, X2, ... , Xn)T be a random vector on (Rn, B(Rn)). Then X 
has a multivariate normal distribution if and only if, for every a = (a I, a 2 , ... , an) T, 
the random variable 
is a normal random variable. 
n 
aTX = 2:aiXi 
i=I 
19.6. Let (XI, X2, ... , Xn)T be multivariate normally distributed. Show that XI, 
X 2 , ... , Xn are independent if and only if 
E(XiXj) = E(Xi)E(Xj), 
for all i-=/- j. 
19.7. Let X rv N(O, 1). Show that 
E (IXI2n+I) = 2nn!f!. 
19.8. Let N (d) be defined as 
Show that 
(a) N(oo) = 1: 
(19.13) 
(19.14) 

PROBLEMS 
243 
(b) FordE ( -oo, oo), N(d) + N( -d)= 1. 
19.9. Let a, b, j3, 1' E R and T > 0. Let N ( Â·) as be defined in Problem 19.8. Show 
that 
(a) 
(b) 
(c) 
19.10. Let a, b, c, and d be constants such that a =/=- 0 and b < 0. Show that 
1
00 eay N(by + c)dy 
-~ead N(bd +c)+~ exp ( a
2 ;b~abc) N (bd + c- ~), 
where N(Â·) is as defined in Problem 19.8. 
19.11. Let Xi "' C(ai, hi) fori = 1, 2. Suppose that X 1 and X 2 are independent. 
Show that 
X1 + X2 "'C(a1 + a2, h1 + h2). 
19.12. Let X"' C(a, h) andY= 1/ X. Show that 
y "' C ( a2 : h2' a2 ~ h2) Â· 
19.13. LetXi "'Pa(ai,h) fori= 1,2, ... ,nandsupposethatX1,X2 , ... ,Xn 
are independent. Let Y = min{X1 , X 2 , ... , Xn}Â· Show that 

244 
CONTINUOUS DISTRIBUTIONS 
19.14. Let B(Â·, Â·)and f(Â·) be the beta function and the gamma function, respectively. 
Show that 
(a) For any x E R, 
r(x) = (x- 1)f(x- 1). 
(b) If n is a positive integer, then 
f(n) = (n- 1)!. 
(c) For any p > 0 and q > 0, 
B( 
) = f(p)f(q) 
p,q 
f(p+q)" 
19.15. Let m and n be integers such that m :::; n. Let p E (0, 1). Let X "" 
Beta(m, n - m + 1) and Y "" B(n,p); that is, X has a beta distribution with 
parameters ( m, n- m + 1) and Y has a binomial distribution with parameters ( n, p). 
Show that 
P{X < p} = P{Y 2:: m}. 
19.16. Let X ""N(O, 1), that is, X is a standard normal random variable. Find the 
distribution of X 2 . 
19.17 (Feller's Tail Probability Estimates). Let Z ""N(O, 1) and x > 1. Show that 
(a) 
(b) 
(c) 
lim 
P{IZI 2:: x} 
= 1. 
x->oo 1 {2 
( 
x2 ) 
-xy :;rexp -2 
19.3 Hints 
19.1. Use the fact that P(O.) = 1, that is, the integration of the probability density 
function is 1. 
19.2. Note that 

HINTS 
245 
19.3. 
Use the characteristic function theorem (Theorem 17.1 ), the characteristic 
function ofnorma1 random variables (see Problem 19.1), and Theorem 13.2. 
19.4. Use the characteristic function theorem (Theorem 17.1) and the characteristic 
function of normal random variables (see Problem 19.1). 
19.5. The "if" part can be proved by the results of Problems 19.1 and 19.2, and the 
Fourier uniqueness theorem (Theorem 17 .1). The "only if" part can be proved by the 
result of Problem 19.1 and the Fourier uniqueness theorem. 
19.6. The "only if" part follows from Theorem 13.2. The "if' part can be proved 
by using the result of Problem 12.8. 
19.7. Note that 
and use the method of induction. 
19.8. To prove part (a), use Tonelli's theorem (Theorem 10.1) and consider 
N(oo) 2 = ~ laoo e_x22 dx laoo e-~dy = ~ laoo (fooo e_x21Â°2 dy) dx. 
Then for fixed x, let y = sx and dy = xds. Use part (a) to prove part (b). 
19.9. Use change of variables and the definition of N ( Â·) to prove part (a). Then use 
part (a) and the monotone convergence theorem (Theorem 6.2) to prove parts (b) and 
(c). 
19.10. Use integration by parts and l'Hopital's rule. 
19.11. Use the characteristic function of the Cauchy distribution (see Theorem 19.1) 
and Theorem 17 .1. 
19.12. Note that 
Fy(y) = P(Y :S y) = P (~ :S y) 
and use the probability density function of the Cauchy distribution. 
19.13. Note that 
P(Y :S y) = 1- P(Y > y) = 1- P(X1 > y, X2 > y, ... , Xn > y) 
and use the result of Problem 12.5. 
19.14. Part (a) can be proved by integration by parts. Part (b) can be derived from 
part (a). Part (c) can be proved by using multivariate integration and changes of 
variables (i.e., Jacobian). 

246 
CONTINUOUS DISTRIBUTIONS 
19.15. Note that 
P{X < p} = 
xm- 1(1- x)n-mdx 
1 
1p 
B(m,n-m+1) 0 
and apply integration by parts. 
19.16. Try to compute the probability density function by taking the derivative of 
the distribution function of X 2 
0 
19.17. The first inequality can be proved by observing that 
The second inequality can be proved by observing that 
19.4 Solutions 
19.1. By definition, we have 
Mx(t) 
E [etX] 
~ joo exp(tx) Â· exp (- (x- ~)
2 ) d.r 
ay2K -= 
2a 
~ 1= exp (tx- (x- ~)
2 ) dx 
av 2K -= 
2a 
Similarly, we can show that 
This completes the proof. 

SOLUTIONS 
247 
19.2. Let C = (2n)-~ lEI-!. By definition, we have 
Â¢x(t) 
E [eitTx] 
C L 
exp (itT x- ~(x- J.L)TE-1(x- J.L)) dP 
C L 
exp ( -~(x- J.L + iEtfE-1(x- J.L + iEt) +itT J.L- ~eEt) dP 
exp (itT J.L- ~tTEt) . 
This completes the proof. 
19.3. By Problem 19.1, we have 
Â¢x(t) = exp (itL1t- ~a~t2) 
and 
cpy(t) = exp (itL2t- ~a~t2) . 
Hence by Theorem 13.2, we have 
E [exp(it(aX +bY))] 
E [eitaX] E [eitaYJ 
exp [i(a/Ll + btLz)t- ~ (a2a~ + b2aD t2] . 
The conclusion follows from Theorem 17 .1. This completes the proof. 
19.4. Suppose that (X, Y) has the following joint probability distribution function: 
f(x,y) 
1 
Then we have 
E ( eit(aX+bY)) 
I: I: f(x,y)eit(ax+by)dxdy 
exp ( (a/Ll + btLz)it- ~(a2d + b2a~- 2pabalaz)t2 ) . 

248 
CONTINUOUS DISTRIBUTIONS 
By Theorem 17.1, the random variable aX + bY is normally distributed with mean 
ap,1 + btt2 and variance (a2cr? + b2 cr~- 2pabcr1cr2 ). 
19.5. Let us prove the sufficiency first. Suppose that for every a = ( a 1 , a2 , ... , an) T, 
the random variable 
n 
arX= l.:aiXi 
i=l 
is a normal random variable. Then tTX is a normal random variable. Hence by 
Problem 19.1, we have 
Â¢x(t) 
E [eitTX] 
exp (ip,(tTX)- ~cr2 (tTX)) , 
where p,(tTX) and cr2 (tTX) are the mean and variance oftTX, respectively. Sup-
pose that E[X] = J-L and Cov(X) = I:. Then we have 
JL(ex) = tr J-L 
and 
Therefore, we get 
c/Jx(t) = exp (ie f-L- ~tTL;t). 
It follows from Theorem 17.1 and Problem 19.2 that X has a multivariate normal 
distribution. 
Now let us prove the necessity. Suppose that X has a multivariate normal distri-
bution whose density function is given by 
Let a= (a1. a2, ... , an)T be a vector. Let Y = arX. Then 
cpy(t) 
E [eitY] 
E [eitaTX] 
(21r)-~ IL:I-~ l exp (itarx- ~(X- J-LfL:- 1(X- J-L)) dP 
exp (itar f-L- ~earL:a) . 
By Problem 19.1 and Theorem 17.1, Y is normally distributed with mean aT J-L and 
variance aTL:a. 

SOLUTIONS 
249 
This completes the proof. 
19.6. The "only if" part follows from Theorem 13.2. We only need to prove the "if" 
part. AssumethatE(XiXj) = E(Xi)E(Xj) foralli =1- j. ThenCov(Xi,Xj) = 
E(XiXj)- E(Xi)E(Xj) = 0. Hence (X1,X2, ... ,Xn)T has the following joint 
distribution function 
1 
( 
1 ~ (xi- f..Li) 2 ) 
f(x) = (2 )'-'- rr .. exp -2 ~ 
2 
' 
7r 
2 
i=l a, 
i=l 
ai 
where f..Li and ai are the mean and standard deviation of Xi. Then we have 
n II P(Xi:::; Xi)Â· 
i=l 
By Problem 12.8, X1, X2, ... , Xn are independent. This finishes the proof. 
19.7. Note that 
Now we show that Equation ( 19.13) is true by the method of induction. When n = 0, 
integrating by parts gives 
1
00 
1 
x2 1
00 
1 
x2 
I! 
E(IXI) = 2 
x--e- 2 dx = 
--e->dx2 = 
-. 
0 
J21f 
0 
J21f 
7r 
Hence Equation (19.13) holds for n = 0. Now suppose that Equation (19.13) holds 
for n = k; it follows from the integration by parts and Equation (19.15) that 
(19.15) 

250 
CONTINUOUS DISTRIBUTIONS 
Then for n = k + 1, we have 
E (1XI2(k+l)+l) 
{2 {'X) 
x2 
-y;: Jo 
x2k+2de-2 
{2 {')() 
x2 
y;: Jo 
(2k + 2)x2k+le-2dx 
2(k + 1)E (IXI2k+l) 
2k+1(k + 1)!~. 
Hence Equation (19.13) holds for n = k + 1. This completes the proof. 
19.8. 
(a) Since 
2 100 
x2 
N(oo) = 
tn= 
e-Tdx, 
y27r 
0 
by Theorem 10.1, we have 
Now for fixed x, we let y = sx. Then we have 
2 roo ( roo 
2 l+s2 
) 
;: Jo 
Jo 
e-x -2-xds dx 
2 roo ( roo 
2 l+s2 
) 
;: Jo 
Jo 
e-x -2-xdx ds 
-
--ds 
2100 
1 
7r o 
1 + s2 
2 
~ 
1 
- r 
2 (B)dtan(B) 
1r } 0 
1 +tan 
1. 
Since N(oo) > 0, we have N(oo) = 1. 
(b) By changes of variables and the first item, we have 
N(d)+N(-d) 
- 1-Jd e_x22dx+-1-f-de_x22dx 
..ffrr - 00 
..ffrr -00 
_1_ Jd e- x22 dx + _1_1d e-.V: d( -y) 
..ffrr - 00 
..ffrr 00 
1 Jd 
x2 
1 100 
x2 
--
e-Tdx + --
e-Tdx 
..ffrr - 00 
..ffrr d 
1. 

This completes the proof. 
19.9. 
(a) Let 
x-rT 
y= /T . 
Writing the integral with respect to the variable y gives 
vk lb exp (jj +/X- 2~x2) dx 
exp (/J + h 2T) J 
b-:}{ 
( 
1 2) 
exp --y 
dy 
V2Jr 
a~-yT 
2 
v'T 
SOLUTIONS 
251 
Since N(d) = 1- N( -d) (see Problem 19.8) for any dE R, we have 
(b) Let {an : n = 1, 2, ... } be an arbitrary sequence of real numbers such that 
an .,(_ -oo as n --+ oo. By the monotone convergence theorem (Theorem 6.2) 
and part (a), we have 
(c) Let { bn : n = 1, 2, ... } be an arbitrary sequence of real numbers such that 
bn t oo as n --+ oo. By the monotone convergence theorem (Theorem 6.2) and 

252 
CONTINUOUS DISTRIBUTIONS 
part (a), we have 
This completes the proof. 
19.10. Using integration by parts, we get 
1
00 eay N(by + c)dy 
eay 
I 
00 
b 1
00 
( 
1 
) 
-N(by +c) 
-
rn= 
eay exp --(by+ c) 2 
dy.(l9.16) 
a 
d 
av 27f 
d 
2 
By Problem 19.9 and the assumption that b < 0, we have 
~ roo eay exp (-~(by+ c) 2 ) dy 
ay27r Jd 
2 
1 
((a- bc) 2 
1 2) 
( 
[ 
a- be]) 
--exp 
- -c 
N 
-b -d+ --
a 
2b2 
2 
b2 
1 
(a2 - 2abc) 
( 
a) 
--exp 
N bd+c--
a 
2b2 
b Â· 
(19.17) 
By l'Hopital's rule, we have 
lim eay N(by +c) = 
y---too 
_b_ exp ( -l(by + c) 2 ) 
lim v'27T-" 
2 
y---too 
-ae-ay 
-
~ lim exp (ay- ~(by+ cf) 
ay 27r y---too 
2 
0. 
(19.18) 
The result follows immediately by combining Equations (19.18), (19.17), and 
(19.16). This completes the proof. 

SOLUTIONS 
253 
19.11. By the assumption that X 1 and X2 are independent and Theorem 19.1, we 
have 
The result follows from Theorem 17 .1. 
19.12. By definition, the distribution function of Y is 
Note that for y < 0, we have 
which gives 
P (~ < x < o) = fa 
h 
, 
y-
J1. (h2 + (x- a)2)n 
y 
jy(y) 
dFy(y) 
dy 
h 
1 
( h2 + (i- a) 2) 1f â¢ y2 
(y- a2~h2r + (a2~h2)
2
. 
ify < 0; 
ify > 0. 
When y > 0, the probability density function of Y is the same as above. Hence Y 
follows a Cauchy distribution with parameters ( a2 ~h2 , a2 ~h2 ). This completes the 
proof. 
19.13. By the assumption that X 1 , X 2 , ... , Xn are independent and Problem 12.5, 
we have 
Fy(y) 
P(Y ~ y) = 1- P(Y > y) 
1- P(X1 > y,X2 > y, ... ,Xn > y) 
n 
1 -II P(Xi > y) 
i=l 
1 - ITn 1oo aiha; dx 
x<>â¢+l 
i=l y 
ha 
1--
y<>' 

254 
CONTINUOUS DISTRIBUTIONS 
where a = o:1 + o:2 + Â· Â· Â· + O:n. Taking the derivative of the above equation gives 
aha 
fy(y) = ya+1 Â· 
Hence Y is Pareto distributed with parameters o:1 + a + 2 + Â· Â· Â· + O:n and h. This 
completes the proof. 
19.14. 
(a) By integration by parts, we have 
f(x) = 100 tx-1e-tdt 
-100 e-1de-t 
100 (x- 1)tx-2e-tdt 
(x- 1)f(x- 1). 
(b) Applying the result of part (a) gives 
f(n) = (n- 1)!f(1). 
Since 
f(1) = 100 e-tdt = -e-tlgo = 1, 
we get f(n) = (n- 1)!. 
(c) By the definition of r function, we have 
f(p)f(q) = 1
00 rP- 1e-rdr 1
00 sq-1e- 8 ds 
1oo 1oo rp-1 sq-1e-r-sdrds. 
Let r = xt and s = t(1 - x ), where x E [0, 1] and t E [0, oo ). Then we have 
I 
ar 
drds = ax 
as 
ax 
Hence we get 
f(p)f(q) 
ar I 
I t 
x I 
g; dxdt = 
dxdt = tdxdt. 
at 
-t 1- x 
1
001
00 (xt)P-1(t(1- x))q-1e-ttdxdt 
1
001
00 tP+l-1e-txP-1(1- x)q-1dxdt 
f(p + q)B(p, q). 

SOLUTIONS 
255 
This completes the proof. 
19.15. Note that f(l + 1) = l! for all integers l :2: 0. Then by integration by parts, 
we have 
P{X < p} 
1 
rp xm-1(1- x)n-mdx 
B(m,n-m+1) }0 
n! 
r ~(1- x)n-mdxm 
(m- 1)!(n- m)! }0 m 
(~) pm(1- p)n-m- (~)lap xm(n- m)(1- x)n-m-ldx 
t (~) pm(l- p)n-m 
J=m 
J 
P{Y :2: m}. 
This completes the proof. 
19.16. Let Y = X 2 . Then for y :2: 0, we have 
Fy(y) 
P{Y::; y} 
P{X2 ::; y} 
P{ -Vfj::; X::; Vfj} 
[VY 
1 
x2 
2 Jo 
v'27fe-2 dx. 
Taking the derivative of Fy (y) with respective to y gives 
1 
1 
y 
Jy(y) = y-2 --e-2. 
v'27f 
Note that f( ~) = ft. The distribution of X 2 is a gamma distribution with parame-
ters~ and 2: 
This completes the solution. 
19.17. 
(a) By definition, we have 
P{IZI :2: x} 

256 
CONTINUOUS DISTRIBUTIONS 
(b) Noting that for s > 1 
we have 
P{IZI 2:: x} 
> 
(c) By parts (a) and (b) of this proof, we have 
~ - ;a < _P-={=-1 Z_l:_2::_x"-} _ < 1 
~ 
-
~ ~ 
exp (- x;) -
. 
Letting x -+ oo gives the result. 
This finishes the proof. 
19.5 Bibliographic Notes 
In this chapter, we presented several continuous probability distributions that can be 
used in finance. In general, probability distributions of asset returns should have the 
following properties (Watsham and Parramore, 1997): 
(a) Stationarity- that is, the parameters of the distribution are unchanging through 
time; 
(b) Stability - that is, linear combinations of the distributions have the same type of 
distribution. 
(c) Finite variance. 
Johnson et al. (1994), Johnson et al. (1995), Evans et al. (2000), and Forbes et al. 
(2011) presented a comprehensive discussion of continuous univariate distributions. 
Haas and Pigorsch (2011) studied several fat-tailed distributions. Balakrishnan and 
Nevzorov (2003) is a textbook on statistical distributions that includes several contin-
uous probability distributions. Some common continuous distributions are discussed 
in Borokov (1999), Meucci (2005), Krishnan (2006), and DasGupta (2010). 

CHAPTER 20 
CENTRAL LIMIT THEOREMS 
The central limit theorem is a very important result in probability theory. It states 
that the mean of a sufficiently large number of independent random variables will 
be approximately normally distributed under certain conditions. The central limit 
theorem has several versions. In this chapter, we present some central limit theorems. 
20.1 
Basic Concepts and Facts 
Definition 20.1 (Degenerate Distribution). A distribution function is said to be de-
generate if it is equal to ~xo for some x0 , where ~xo is defined as 
~xo(x) = {0, 
~fx < xo; 
1, 
lfX~Xo. 
(20.1) 
Definition 20.2 (Weak Convergence). A sequence {Fn}n>l of distribution func-
tions is said to converge weakly to a distribution function F, written as Fn =} For 
Fn(x) =} F(x), if 
lim Fn(x) = F(x), 
for all x E C(F), 
n-+oo 
Measure, Probability, and Mathematical Finance. 
257 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

258 
CENTRAL LIMIT THEOREMS 
where C(F) = {x E R: F is continuous at x }. 
Definition 20.3 (Convergence in Distribution). Let { Xn}n>l be a sequence of ran-
dom variables. The sequence is said to converge in distribution (or in law) to a 
random variable X 0 , written as Xn ~ X 0 , if Fn => Fa, where Fn is the distribution 
function of Xn for n ?: 0. 
Theorem 20.1 (Lindeberg's Central Limit Theorem). For each n, let Xn,lâ¢ Xn, 2, 
... , Xn,kn be kn independent random variables satisfying the following conditions: 
(a) E(Xn,j) = Oforallj = 1,2, ... ,kn. 
(b) 
where an,j = J 
E[X~,j]. 
(c) (Linde berg condition) For any E > 0, we have 
kn 
}~~LE 
(x~,jJ{IXn,jl><}) = o. 
j=l 
Then 2::~~ 1 Xn,j converges in distribution to the standard normal random variable, 
that is, 
kn 
LXn,j ~ N(O, 1). 
j=l 
20.2 Problems 
20.1. Let {Xn}n>l be a sequence of random variables on some probability space 
(n, $, P). Let X 0 be a random variable on (n, Â§, P). Show that if Xn ~ X 0 , 
then Xn ~ X 0 ; that is, if the Xn converges to X 0 in probability, then Xn converges 
to X 0 in distribution. 
20.2. Let a> 0 and {an}n2:l a sequence of positive real numbers. Let {bn}n2:l be 
a sequence of real numbers and b a real number. Let F be a distribution function and 
{ Fn }n> 1 a sequence of distribution function. 
(a) Suppose that Fn => F, an -+ a, and bn -+ b. Show that 
where Gn(x) = Fn(anx + bn) and G(x) = F(ax +b). 

PROBLEMS 
259 
(b) Suppose that Fn =} F and an ---+ oo. Show that 
where Gn(x) = Fn(anx) and ~o is as defined in Definition 20.1. 
(c) Suppose that Fn =} F and {bn}n>l is unbounded. Let Gn(x) = Fn(X + bn)Â· 
Show that Gn cannot converge weakly. 
(d) Let Gn(x) = Fn(anx + bn)Â· Suppose that Fn =} F, Gn =} G, and F and G 
are nondegenerate. Show that 
0 < inf an ::::; sup an < oo 
n~l 
n~l 
and 
(e) Suppose that F ( x) = F (ax + b) for all x E (-oo, oo) and F is nondegenerate. 
Show that a = 1 and b = 0. 
20.3. Let { an}n>l and { un}n>l be two sequences of positive real numbers, that 
-
-
is, an > 0 and Un > 0 for all n ~ 1. Let { F n} n> 1 be a sequence of distribution 
functions such that Fn(anx + bn) =} G(x) and Fn(unx + vn) =} F(x), where F 
and G are nondegenerate distribution functions. Then there exist a and b, a > 0, 
such that 
and 
l. 
an 
1m- =a, 
n--+oo Un 
l. 
bn- Vn 
b 
lm 
= 
' 
n--+oo 
Un 
F(ax +b)= G(x). 
20.4 (The Classical Central Limit Theorem). Let { Xn}n~l be a sequence of in-
dependent and identically distributed random variables with E(XI) = f.L and cr = 
y!Var(Xl) < oo. Show that 
~xj -M d 
L.J --r,;; ---+ N(O, 1). 
cryn 
j=l 
20.5 (Lyapounov's Central Limit Theorem). For each n, let Xn,lâ¢ Xn,2, ... , Xn,kn 
be kn independent random variables satisfying the following conditions: 
(a) 
kn 
LE(Xn,j) = f-LÂ· 
j=l 

260 
CENTRAL LIMIT THEOREMS 
(b) 
kn L Var(Xn,j) = a 2 > 0. 
j=l 
(c) (Lyapounov condition) For some 8 > 0, 
Show that 2::7:1 Xn,j converges in distribution to the normal distribution with pa-
rameters (J.L, a 2), that is, 
kn 
LXn,j ~ N(J.L,a2 ). 
j=l 
20.6. Let { Xn : n 2: 1} be a sequence of independent random variables distributed 
as 
P{Xn = 1} = P{Xn = -1} = Pn, 
P{Xn = 0} = 1- 2pn, 
n 2: 1, 
where Pn E [0, ~]and 
00 
Find a suitable choice of scaling constants en such that the rescaled sum 
1 
n 
-L:xi 
Cn i=l 
converges in distribution to the normal distribution with mean 0 and variance 1 as 
n---+ oo. 
20.3 Hints 
20.1. 
Use the definition of convergence in probability (Definition 9.1) and the 
definition of convergence in distribution (Definition 20.3). 
20.2. To prove part (a), follow the definition of weak convergence (Definition 20.2) 
and note that a distribution function has only countably many discontinuities (see 
Problem 11.13). To prove part (b), consider the cases x > 0 and x < 0 and follow 
Definition 20.2. To prove part (c), use the method of contradiction. To prove part 
(d), use the method of contradiction and parts (a), (b), and (c). Use part (d) to prove 
part (e). 
20.3. Apply the results of Problem 20.2. 

SOLUTIONS 
261 
20.4. 
Use Lindeberg's central limit theorem (Theorem 20.1) and the dominated 
convergence theorem (Theorem 6.4). 
20.5. Let 
Y. . _ Xn,j - E(Xn,j) 
n,J -
a 
and apply Lindeberg's central limit theorem (Theorem 20.1). 
20.6. Find en to satisfy the conditions in Lindeberg's central limit theorem (Theo-
rem 20.1). 
20.4 Solutions 
20.1. 
Let Fn be the distribution function of Xn for n ~ 0. Let x E C(Fa), 
where C (Fa) is the set of points at which Fa is continuous. Let o > 0. Then by the 
continuity of Fa at x, there exists an t > 0 such that 
and 
0 
IFa(x + t)- Fa(x)[ < 2 
0 
[Fa(x- t)- Fa(x)[ < 2. 
By the assumption that Xn ~ X, there exists an integer N such that 
0 
P{[Xn- X[~ t} < 2, foralln ~ N. 
For n ~ N, since 
P{Xn :S x} 
(20.2) 
(20.3) 
P({Xn :S x} n {[Xn- X[< t}) + P({Xn :S x} n {[Xn- X[~ t}), 
and 
we have 
P({Xn :S x} n {[Xn- X[< t}) :S P{X :S X+ t}, 
0 
P({Xn :S x} n {[Xn- X[~ t}) :S P{[Xn- X[~ t} < 2' 
0 
P{Xn :S x} :S 2 + P{X <X+ t}. 
Similarly, we have 
P{X:Sx-t} 
P({X :S X- t} n {[Xn- X[< t}) + 
P({X :S x- t} n {[Xn- X[~ t}), 
(20.4) 

262 
CENTRAL LIMIT THEOREMS 
which leads to 
6 
P{X :S: X- E} :S: 2 + P{Xn :S: x}. 
(20.5) 
Combining Equations (20.2) - (20.5) gives 
Fo(x)- 6 :S: Fn(x) :S: Fo(x) +b. 
Since 6 is arbitrary, Fn ( x) ---+ F0 ( x). Hence the conclusion is true. This completes 
the proof. 
20.2. 
(a) Let x be a continuity point of G(:r) and let E > 0. Then F(y) is continuous at 
a:r: +b. By Problem 11.13, F has only countably many discontinuities. Then 
we can choose two continuity points u and v of F such that u < ax + b < v 
and F(v)- F(u) <E. By the assumption that Fn =? F, an---+ a, and bn---+ b, 
there exists an integer N, such that for n ::>: Nc, we have 
and 
IFn(u)- F(u)l < E, 
IFn(v)- F(v)l < E, 
Therefore 
IGn(x)- G(:r:)l 
< IFn(anX + bn)- F(ax + b)l 
< 
IFn(anX + bn)- Fn(Â·u)l + IFn(u)- F(u)l + IF(u)- F(ax +b) I 
< Fn(v)- Fn(u) + IFn(u)- F(u)l + F(v)- F(u) 
< 
5E. 
Since E is arbitrary, we have Gn(x)---+ G(x) as n---+ oo. 
(b) Let E > 0. Let x > 0. Then ~ 0 ( x) = 1. Let u be a continuity point ofF such 
that F(u) > 1- E/2. By the assumption that Fn =? F, there exists an integer 
N 1 such that 
Since an ---+ oo and x > 0, there exists an integer N2 such that anx > u for all 
n ::>: N2. Hence for every n ::>: max(N1 , N 2 ), we have 
1- Fn(anx) < 1- Fn(u) 
< 1- F(u) + IFn(u)- F(u)l 
< 
E. 

SOLUTIONS 
263 
Since E is arbitrary, we have Fn(anx) --+ 1. Similarly, we can show that 
Fn(anx)--+ 0 when x < 0. Therefore, we have Gn =?boo. 
(c) Assume that Gn =? G for some distribution function G. Since {bn}n>l is 
unbounded, we suppose that {bn}n>l is unbounded above. Let u be a continuity 
point of G such that G(u) < ~- By the hypothesis that Gn =? G, there exists 
an integer N1 such that for all n > N1, we have 
1 
IGn(u)- G(u)l = IFn(u + bn)- G(u)l < 4' 
which implies that 
1 
G(u) > Fn(u + bn)- 4 
(20.6) 
Note the assumption that Fn =? F. Let v be a continuity point ofF such that 
F( v) > ~. Then there exists an integer N2 such that for all n > N2 , we have 
1 
IFn(v)- F(v)l < 4Â· 
(20.7) 
By the hypothesis that {bn}n~l is unbounded above, there exists an integer 
N3 > max(N1 , N2 ) such that u + bN3 > v. Hence from Equations (20.6) and 
(20.7), we have 
1 
1 
1 
G(u) > Fn(v)- 4 ~ F(v)- IFn(v)- F(v)l- 4 > 4Â· 
But G(u) < ~- This is a contradiction. Similarly, we can show that Gn cannot 
converge weakly when {bn}n>l is unbounded below. 
(d) Suppose that the sequence {an}n>l is not bounded above. Then there exists a 
subsequence { akn }n~l of { an}n~l such that akn --+ oo. By part (b), we have 
(20.8) 
Since G is nondegenerate and 
Fkn [akn (x+ !::)] =Fkn(aknx+bkn)--+G(x), 
it follows from part (c) that {bkn/akn}n~l is bounded. Hence there exists a 
subsequence {bin/ain}n~l of {bkn/akn}n~l such that 
for some constant c. Then by part (a) and Equation (20.8), we have 
Fkn [ akn (X+!::)] --+ b.o(x +c). 

264 
CENTRALUMITTHEOREMS 
This contradicts the assumption that G is nondegenerate. Thus { an}n;,-1 is 
bounded above. 
Since Gn '* G and Gn(a:;:1x- a:;:1bn) = Fn(x)--+ F(x), the same argument 
shows that { a:;: 1 }n;,- 1 is bounded above. Hence we have 
0 < inf an ""::: sup an < oo. 
n:2-1 
n:2-1 
Now suppose that {bn}n> 1 is unbounded. Then {bn/an}n>1 is unbounded. 
-
-
Thereexistsasubsequence{bj,,/aj,}n;o-1 suchthatb]n/aj,--+ Â±ooanda]n--+ 
a for some a > 0. Then by part (a), we have 
Since G is nondegenerate, we have 
it follows from part (c) that {bj,)a]n}n;,- 1 is bounded. This is a contradiction. 
Hence {bn}n>1 is bounded. 
(e) Since F(x) = F(ax +b) for all x, we have the following for every n?: 1: 
F(x) 
F(ax +b) 
F(a(a.T +b)+ b) 
F(anx + (1 +a+Â·Â·Â·+ an)b). 
It follows from Item (d) that {an }n;,- 1 is bounded away from 0 and oo. Hence 
a= 1. Then also by part (d), { nb }n;,- 1 is bounded. Hence b = 0. 
This completes the proof. 
20.3. Let Hn(x) = Fn(UnX + vn) for n?: 1. Then we have Hn(x) '* F(x) and 
(20.9) 
It follows from part (d) of Problem 20.2 that 
and 
I bn- Vn I 
sup 
< oo. 
n:2-1 
Un 

Then there exists a subsequence {kn}n;;:.l of {1, 2, ... } such that 
for some a > 0 and b. By part (a) of Problem 20.2, we have 
Hkn (akn X+ bk,- Vkn) =} F(ax +b). 
Ukn 
Ukn 
From Equations (20.9) and (20.10), we get F(ax +b)= G(x). 
SOLUTIONS 
265 
(20.10) 
Suppose that there exists another subsequence {jn }n;;:. 1 of { 1, 2, ... } such that 
aÂ· 
__:!_>:>:_ --+a' 
UÂ· 
Jn 
for some a' > 0 and b'. Then we have 
F(a'x + b') = G(x) = F(ax +b). 
It follows from part (e) of Problem 20.2 that a' = a and b' = b. Therefore, we have 
This completes the proof. 
20.4. For each n, let Yn,l, Yn,2, ... , Yn,n be defined as 
XJ -J-L 
Yn,j = ---;:;;:;, 
j = 1, 2, ... , n. 
uyn 
Then it is obvious that E (Yn,j) = 0 for all j = 1, 2, ... , n and 
Now we show that the Yn,j satisfies the Lindeberg condition. Since X 1, X 2 , ... are 
identically distributed, we have 
n L E (Y;,jJ{IYn,jl><}) 
j=l 
Note that 

266 
CENTRAL LIMIT THEOREMS 
and 
By Theorem 6.4, the Y,,,j satisfies the Lindeberg condition. Hence the conclusion 
follows from Theorem 20.1. This completes the proof. 
20.5. Let 
Y, . _ Xn.j- E(Xn,J) 
n.J -
(J 
. 
Then the Yn,j satisfies the first two conditions given in Theorem 20.1. Let E > 0. 
Since 
we have 
kn 
kn 1 
LE (IYn,Jf 2J{IYnil>c}) ~ L foE (fY,,,Jf 2+0) Â· 
j=l 
j=l 
Hence by the Liyapounov condition, we have 
k, 
}~~ L E (IYn,j I2J{IYn Jl><}) = 0. 
j=l 
It follows from Theorem 20.1 that 2::~~ 1 Y,,,j converges in distribution to N(O, 1). 
Therefore 2::~~ 1 Xn,j converges in distribution to N(J.L, cr2 ). This completes the 
proof. 
20.6. Let en be defined as 
Let Xn.J be defined as 
xj 
XÂ·=-
n.J 
Cn 
n~l. 
n~1,j~l. 
Then we have E[Xn,j] = 0 for all j = 1, 2, ... , n. Let cr;,i = E[x;,j]. Then we 
have 
n 
n 
2 
'""' 
2 
'""' Pi 
1 
L 
crn,j = L 2 = Â· 
J=l 
j=l 
n 
Let E > 0. Then for n > 1/ E, we have 
IXJI 
1 
fXn,jl = -- ~- < f, 
j = 1,2, ... ,n, 
Cn 
Cn 

which gives 
Hence 
n L E[X~,jJ{IXn,jl>e}] = 0. 
j=l 
n 
BIBLIOGRAPHIC NOTES 
267 
lim "E[X~ 1.f{IX Â·I>â¢}] = 0. 
n---?oo~ 
' 
n,J 
j=l 
Therefore, it follows from Theorem 20.1 that 
n 
LXn,j ~ N(O, 1). 
j=l 
This completes the solution. 
20.5 Bibliographic Notes 
In this chapter, we introduced the concepts of weak convergence and convergence 
in distribution, which are classic topics in probability theory and discussed in many 
texts such as Billingsley (1995). Unlike other notions of convergence, convergence 
in distribution does not require the random variables to be defined on a common 
probability space. 
Lindeberg's central limit theorem is a very general central limit theorem, which 
can be used to prove other central limit theorems. Lindeberg's central limit theorem 
can be proved in several ways. For example, Bhattacharya and Waymire (2007) 
presented a proof without relying on the characteristic function. Athreya and Lahiri 
(2006) presented a proof using the characteristic function. 


PART Ill 
STOCHASTIC PROCESSES 


CHAPTER 21 
STOCHASTIC PROCESSES 
A stochastic process is a collection of random variables. Stochastic processes play 
an important role in mathematical finance as they are used to model the stock prices. 
In this chapter, we shall present some general concepts and results about stochastic 
processes. 
21.1 
Basic Concepts and Facts 
Definition 21.1 (Stochastic Process). Let I be a set and (E, c&") a measurable space. 
A stochastic process indexed by I is a family of measurable functions Xt. t E I, 
from a probability space (0, ff:, P) into (E, c&"). The measurable space (E, c&") is 
referred to as the state space. 
For each w E 0, the mapping t-+ Xt(w) is called a trajectory or a sample path 
of X. 
Definition 21.2 (Probability Law of Stochastic Process). Let {Xt : t E I} be 
a stochastic process on some probability space (0, g;, P) with some state space 
(E, c&"). Let X = (Xt)tEJ be the corresponding random variable from (0, ff:) into 
Measure, Probability, and Mathematical Finance. 
271 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

272 
STOCHASTIC PROCESSES 
the product space (F, ~) = (E1 , tff1 ), where 
E 1 =X E 
tEl 
and 
The probability law or distribution of the stochastic process { Xt : t E I} is defined 
asP o x- 1, namely, the probability law of the random variable X. 
Definition 21.3 (Continuous and Right-Continuous Stochastic Process). A stochas-
tic process { Xt : t E I} is said to be continuous if almost all sample paths of the Xt 
are continuous. A stochastic process { Xt : t E I} is said to be right-continuous if 
almost all sample paths of the Xt are right-continuous. 
Definition 21.4 (CadHtg Process). A stochastic process { Xt : t E I} is called a 
cadlag process if almost all its sample paths are right-continuous with left-hand lim-
its. 
Definition 21.5 (Independent Increments). A stochastic process {Xt : t E I} is said 
to have independent increments if Xt- Xs is independent of a(Xu : u :S s) for all 
s :S t. 
Definition 21.6 (Stationary Increments). A stochastic process { Xt : t E I} is said 
to have stationary increments if for any s, t, u, v E I, s < t, u < v, t - s = v - u; 
then the distribution Xt - Xs is the same as that of Xv - Xu. 
Definition 21.7 (Finite-Dimensional Distribution). Let { Xt : t E I} be a stochas-
tic process with values on (E, Iff). Then the finite-dimensional distributions of a 
stochastic process { Xt : t E I} are probability measures defined as 
/-Lt 1 ,t2 , ... ,tk(H) = P{(Xt,,Xt 2 , â¢â¢â¢ ,Xtk) E H}, 
HE Iff\ 
where ( h, t 2 , ... , tk) is k-tuple of distinct elements of I. 
Definition 21.8 (Consistency Conditions). Let I be a set and (E, Iff) a measurable 
space. For each n and each n-tuple (t1 , t 2 , ... , tn) of distinct elements of I, let 
f.Lt 1 h, ... ,t,. be a probability measure on (En, gn). Then the collection 
{t-Lt 1h, ... ,tn : n 2: 1, t1, t2, ... , tn are distinct elements of I} 
of probability measures is said to be consistent if it satisfies the following two con-
sistency conditions: 
(a) For all t 1 , t 2 , ... , tk E I, each permutation 1r of {1, 2, ... , k}, and all H 1 , H 2 , 
... , Hk E Iff, we have 

BASIC CONCEPTS AND FACTS 
273 
Definition 21.9 (Version). Let I be a set and (E, <f:) a measurable space. Let {Xt : 
t E I} and {yt : t E I} be two stochastic processes with the same state space (E, 6"), 
defined on the probability spaces (!1, g;, P) and (!1', ,g';', P'), respectively. Then the 
two stochastic processes are called versions of each other if for all t 1 , t 2 , ... , tk E I 
and H1, H2, ... , Hk E 6", we have 
Two stochastic processes are also said to be equivalent if they are versions of each 
other. 
Definition 21.10 (Modification). Let I be a set and (E, 6") a measurable space. Let 
{ Xt : t E I} and {yt : t E I} be two stochastic processes with the same state 
space (E, 6"), defined on the same probability space (!1, ,g';, P). The two stochastic 
processes are said to be modifications of each other if for any t E I, 
P{Xt = yt} = 1. 
Definition 21.11 (Indistinguishable Process). Let I be a set and ( E, 6") a measurable 
space. Let { Xt : t E I} and {Yt : t E I} be two stochastic processes with the 
same state space (E, 6"), defined on the same probability space (!1, ,g';, P). The two 
stochastic processes are said to be indistinguishable if almost all their sample paths 
agree: 
P{Xt = yt : t E I}= 1. 
Definition 21.12 (Dominance). Let {Xt : t E I} and {Yt : t E I} be two stochastic 
processes defined on the same probability space (!1, ,g';, P), where I is an index set. 
The process { Xt : t E I} is said to dominate {yt : t E I} if 
P{Xt ~ yt : t E I}= 1. 
Definition 21.13 (Independent Stochastic Processes). Let {xpl : t E I}, {Xi2l : 
t E I}, ... , {Xin) : t E I} ben stochastic processes defined on the same probability 
space. Then stochastic processes are said to be independent if the a-algebras ,g'; x<'l, 
m-x<2) 
m-x<n) 
. 
.:r 
, ... , .:r 
are mdependent, where 
g;x<kJ = a(Xik) : t E I), 
1 ::; k ::; n. 
Definition 21.14 (Processes with Same Finite-Dimensional Distribution). Let I be 
an index set. Let { Xt : t E I} and {yt : t E I} be two stochastic processes defined 
on probability spaces (!11, ,g';1 , PI) and (!12 , ,g';2 , P2), respectively, and having the 
same state space ( E, 6"). Then X and Y are said to have the same finite-dimensional 

274 
STOCHASTIC PROCESSES 
distribution if, for any integer n ~ 1, t 1 , t 2 , ... , tn E I, and A E !! 0 Â· Â· Â· 0 !!, we 
have 
Pl((Xtp Xt 2 , â¢â¢â¢ , XtJ E A)= P2((rt1 , rt2 , â¢â¢â¢ , ytJ E A). 
Definition 21.15 (Measurable Process). A stochastic process {Xt : t ~ 0}, de-
fined on a probability space (fl, ~. P) and having a state space (E, !!), is said to be 
measurable if, for every A E !!, we have 
{(t,w): Xt(w) E A} E B[O, oo) 0 ~. 
Definition 21.16 (Gaussian Process). A stochastic process {Xt : t ~ 0} with the 
state space (R d, B(R d)) is called a Gaussian process if its finite-dimensional distri-
butions are (multidimensional) normal distributions (see Definition 19.9). 
Definition 21.17 (Random Time). A random variable T on a measurable space 
(fl, ~)with values in [0, oo] is called a random time. 
Definition 21.18 (Filtration). Let I be a set and (fl, ~) a measurable space. A 
filtration on (fl, ~) is a family { ~t : t E I} of sub-a-algebras of~ such that 
~s ~~t 
for all s ::; t. 
If the set I is a discrete set (e.g., I = { 1, 2, ... } ), the filtration is called a discrete 
filtration. Ifthe set I is a continuous set (e.g., I = { t E R : t ~ 0} ), then the 
filtration is called a continuous filtration. 
Definition 21.19 (Right Limit and Left Limit of Filtration). Let { ~t : a ::; t ::; b} 
be a continuous filtration. Lett E [a, b]. Then the right limit of the filtration at tis 
defined as 
n=l 
where ~t = ~b for t > b. 
The left limit of the filtration at t is defined as 
00 
~t- = n ~t-~Â· 
n=l 
where ~t = ~a fort < a. 
Definition 21.20 (Right-Continuous and Left-Continuous Filtration). A continuous 
filtration { ~t : a ::; t ::; b} is said to be a right-continuous filtration if 
~t = ~t+ for all t E [a, b]. 
A continuous filtration { ~t : a ::; t ::; b} is said to be a left-continuous filtration if 
~t = ~t-
for all t E [a, b]. 

PROBLEMS 
275 
Definition 21.21 (Natural Filtration). Let X = (Xt : t E I) be a stochastic process. 
The natural filtration { g;tx : t E I} of X is defined as 
ff:{ = o-(Xs : s ::::;; t), 
t E I. 
The natural filtration of X is also referred to as the filtration generated by X. 
Definition 21.22 (Adapted Process). Let X = (Xt : t E I) be a stochastic process 
and { ff:t : t E I} a filtration, where I is an index set. The stochastic process is 
considered adapted to the filtration if Xt is ff:rmeasurable for all t E I. 
Definition 21.23 (Progressively Measurable Process). Let I= [0, oo) or I= [0, t 0] 
for some t0 < oo. A stochastic process { Xt : t E I} with values in a measurable 
space (E, c&") is said to be progressively measurable with respect to a filtration { ff:t : 
t E I} if for each t E I, the map (s,w) -+ X 8 (w) from [0, t] x 0 toE is B[O, t] x 
ff:t/ c&" -measurable (i.e., measurable with respect to a--fields B[O, t] x ff:t and c&"). 
Definition 21.24 (Stochastic Continuity). A stochastic process {Xt : t 2: 0} is said 
to be stochastically continuous if for all 8 > 0 and for all t ;::: 0, we have 
lim P{IXt+h- Xtl > 8} = 0. 
h-tO 
Theorem 21.1 (Kolmogorov's Existence Theorem). Let I be a set. For each n and 
each n-tuple (t1 ,t2, ... , tn) of distinct elements of I, let f.Ll! .f2, ... ,tn be a probability 
measure on (Rn, B(Rt). If the collection 
{f..Ll!.f2, ... ,tn : n 2: 1, t1, t2, ... , tn are distinct elements ofT} 
satisfies the two consistency conditions given in Definition 21.8, then on some prob-
ability space (0, ff:, P) there exists a stochastic process {Xt : t E I} having the 
collection of probability measures as its finite-dimensional distributions. 
Theorem 21.2 (Kolmogorov's Continuity Criterion). Let { Xt : 0 ::::;; t ::::;; T} be 
a stochastic process with the state space (Rd, B(Rd)). Suppose that there exist 
constants a:, {3, and K such that 
for all s, t E [0, T]. Then there exists a continuous modification of { Xt : 0 ::::;; t ::::;; T}. 
21.2 Problems 
21.1. Let {Xt : t E I} be a stochastic process with values on (E, c&"). Let f..Lt 1 .f2, ... ,tnâ¢ 
n 2: 1, t1. t2, ... , tn distinct elements of I, be the finite-dimensional distributions of 
{ Xt : t E I}. Show that the collection of finite-dimensional distributions satisfies 
the two consistency conditions given in Definition 21.8. 

276 
STOCHASTIC PROCESSES 
21.2. Let { Xt : t E I} and {yt : t E I} be two stochastic processes defined on 
the same probability space. Show that if the two processes are modifications of each 
other, then they are versions of each other. 
21.3. Let n = [O,oo) and~= B[O,oo)). Let P be a probability measure on 
(D,~) suchthatP{x} = Oforallx E [O,oo). Let{Xt: t 2:: O}beastochastic 
process on the probability space (D, ~' P) defined as 
( ) 
{ 1, ift=w; 
Xt w = 
0, 
otherwise. 
Let {yt : t 2:: 0} be a stochastic process on the probability space (D, ~' P) defined 
as 
yt(w) = 0, 
for all (t,w) E [O,oo) x [O,oo). 
Show that 
(a) The process {Xt : t 2:: 0} is a modification ofthe {yt : t 2:: 0}. 
(b) The two processes {Xt : t 2:: 0} and {yt : t 2:: 0} have the same finite-
dimensional distributions. 
21.4. Let X = { Xt : t 2:: 0} and Y = {yt : t 2:: 0} be two stochastic processes. 
Suppose that X and Y are modifications of each other and that almost all sample 
paths of X and Y are right-continuous. Show that X and Y are indistinguishable. 
21.5. Let X = {Xt : t 2:: 0} andY = {yt : t 2:: 0} be two stochastic processes 
defined on the same probability space (D, ~' P). Suppose that almost all sample 
paths of X andY are right-continuous and that for every t 2:: 0, 
P{Xt 2:: yt} = 1. 
Show that X dominates Y: 
P{Xt 2:: yt : t 2:: 0} = 1. 
21.6. Let X = {Xt : t 2:: 0} be a stochastic process on some measurable space 
(D, ~). Assume that every sample path of X is right-continuous on [0, oo) with 
finite left-hand limits on (0, oo ). Let A be the event defined as 
A= {wED: Xt(w) is continuous on [0, t0 )}, 
where t0 is some positive real number. Show that 
where ~t~ is as defined in Definition 21.21 

PROBLEMS 
277 
21.7. Let I = [0, oo) or I = [0, t 0] for some t0 < oo. Let { Xt : t E I} be 
a stochastic process with values in a measurable space (E, <&"),where Eisa metric 
space and g is its Borel a-field. Suppose that X is adapted to a filtration { fft : t E I} 
and that every sample path of X is right-continuous. Show that X is progressively 
measurable with respect to the filtration. 
21.8. Let (0, $) be a measurable space, and let I be an index set, countable or 
uncountable. For each t E I, let Xt be a random variable from (0, $)into some 
measurable space (Et, Ct). Let X = (Xt)tEl be the random variable from (0, $) 
into the product space 
(F,~) = ( x Et,Q9c&'t). 
tEl 
tEl 
For each t E I, let 'Dt be a 7!"-system that generates Ct. Let ~0 be the collection of all 
rectangles G in F having the form 
G = 
X At, 
tEl 
where At E 'Dt and At differs from Et for only a finite number oft. Let C be given 
by 
C ={{X E B}: BE ~o}. 
Show that 
(a) The set C is a 7!"-system. 
(b) ~ = a(~o). 
(c) a(C) = a(X). 
21.9. Let (0, $) be a measurable space, and let I be an index set, countable or 
uncountable. For each t E I, let Xt be a random variable from (0, $)into some 
measurable space (Et, Ct). Let X = (Xt)tEl be the random variable from (0, $) 
into the product space 
(F,~) = (X Et.@Ct). 
tEl 
tEl 
Show that 
a(X) = a(Xt : t E I), 
where 
a(X) = {{wE 0: X(w) E B}: BE~} 
and 
a(Xt : t E I)= a{{w E 0: Xt(w) E B}: BE <&"t, t E I}. 
21.10. Let {Xt : t ~ 0} be a real-valued stochastic process on some probability 
space (0, $, P), and let { fft : t ~ 0} be its natural filtration: 
fft = a(Xs : 0 ~ s ~ t), 
t ~ 0. 

278 
STOCHASTIC PROCESSES 
Let Y be a random variable defined on the same probability space (0, Â§, P). Show 
that Y is independent of fft (see Definition 12.3) if and only if for any integer m, 
any 0 :S: s1 < s2 < ... < Sm :S: t, and any c1, c2, ... , Cm, c E R, 
P{ Xs, ::::: cl' Xs2 ::::: c2, ... 'Xs, ::::: Cm, y ::::: c} 
P{Xs, :S: c1,X82 :S: c2, ... ,X8 , 
:S: Cm}P{Y :S: c}. 
21.11. Let (0, Â§) be a measurable space and let I be an index set, countable or 
uncountable. For each t E J, let Xt be a random variable from (0, Â§) into some 
measurable space (Et, t&t). Let X = (Xt)tEI be the random variable from (0, Â§) 
into the product space 
(F,~) = ( x Et,Q9gt). 
tEI 
tEI 
For each t E J, let Dt be a 1r-system that generates gtÂ· Let M be a monotone class 
(see Definition 5.4) of mappings from 0 to [-oo, oo]. Suppose that M includes 
every mapping v : 0 -+ [0, 1] having the form 
v = II h, (Xt), 
tEI 
where At E Dt and At differs from Et for only a finite number oft. Show that M 
includes every positive CJ( X)-measurable function. 
21.12. Let { Xt : t E I} be a stochastic process on some probability space (0, Â§, P) 
with state space (R, B). Let M be a monotone class of mappings from 0 to [-oo, 
oo ]. Suppose that M includes every function V of the form 
n 
v =II fi(Xt;), 
i=l 
where n 2: 1, t1, ... , tn E J, and fi, ... , fn are bounded continuous functions from 
R toR. Show that M contains all positive CJ(Xt : t E I)-measurable functions. 
21.13. Let { Xt : t 2: 0} be a stochastically continuous process. Show that for every 
u E R, the map 
t-+c/Jx,(u) 
is continuous, where Â¢; x, ( Â·) is the characteristic function of Xt. 
21.3 Hints 
21.1. Follow the definition of the consistency conditions. 
21.2. Try to establish that 

HINTS 
279 
and 
21.3. 
part (a) can be proved by verifying the definition directly. Part (b) can be 
proved by part (a) and the result of Problem 21.2. 
21.4. Use the density of rational numbers to show that 
{Xt = yt: t ~ 0} = 
rE[O,oo)nQ 
where Q is the set of all rational numbers. Then use the result of Problem 11.1. 
21.5. The proof is similar to that of Problem 21.4. 
21.6. Try to prove that 
where 
Here Q is the set of all rational numbers. 
21.7. For a fixed t E J, construct a sequence {Xin) : s E [0, t]}n>1 of stochastic 
processes as 
where k = 1, 2, ... , 2n. Noting that forB E Iff, we have 
{(s,w) E [0, t] X 0: Xin) E B} 
2
n ([(k -l)t kt) 
) 
1J
1 
2n 
, 2n 
X {w: Xkt/2n (w) E B} 
U({t} x {w: Xt(w) E B}). 
21.8. Use the definition of measurable rectangles (Definition 10.4) to prove part (a). 
To prove part (b), consider the collection ~1 of all measurable rectangles in F and 
show that ~1 s:;; 0"(~0 ). Part (c) can be proved by using the result of Problem 5.5 and 
part (b). 
21.9. Use the result of Problem 21.8 to get 
O"(X) = O"{{w E 0: X(w) E B}: BE ~o}, 

280 
STOCHASTIC PROCESSES 
where ~0 is the collection of measurable rectangles generating~- Then show that 
a{{w En: X(w) E B}: BE ~o} ~ a(Xt: t E I) 
and 
a(Xt: t E I)~ a{{w En: X(w) E B}: BE ~o}. 
21.10. Use the results of Problem 21.8, 21.9, 12.3, and 2.4. 
21.11. Use the results of Problems 5.12 and 21.8. 
21.12. Use the results of Problems 2.4, 21.11, and 21.9. Let A= ( -oo, c] and show 
that I A is the limit of an increasing sequence of bounded continuous functions. 
21.13. Use the definition of stochastic continuity (Definition 21.24) and the E - 8 
technique; that is, to show that for any E > 0, there exists a 8 > 0 such that for any 
h E ( -8, 8), we have 
21.4 Solutions 
21.1. Lett1,t2, ... ,tk,tk+l E IandH1,H2 , ... ,Hk E C:. Let1rbeapermutation 
of {1, 2, ... , k }. Since 
and 
{(Xt,..(l)'Xt,..(2)l"""lXt,..(k)) E H7r(l) X H7r(2) X ... X H7r(k)} 
are the same event, we have 
Now since 
and 
are the same event, we have 
Hence the collection of finite-dimensional distributions satisfies the two consistency 
conditions. This completes the proof. 

SOLUTIONS 
281 
21.2. Let (E, 6") be the state space of the two stochastic processes. Let k 2:: 1 and 
h, t2, ... , tk be distinct elements of I. Let H1, H2, ... , Hk E 6". Let A and B be 
given by 
k 
A= n{Xt; E Hi} 
i=l 
and 
k 
B = n{yt; E Hi}Â· 
i=l 
Now we claim that 
k 
An Be~ U{Xt; =1- ytJ. 
(21.1) 
i=l 
To show this, let w E An Be. Then w E A and w tf. B; that is, Xt;(w) E Hi 
for all i = 1, 2, ... , k, and ytj (w) tJ. Hj for some 1 :::; j :::; k. Hence we have 
Xtj (w) =1- ytj (w ), that is, w E { Xtj =1- ytj }. This gives 
k 
wE U{Xt; =1- ytJ. 
i=l 
Since w is arbitrary, Equation (21.1) is true. From Equation (21.1), we have 
By the assumption that the two processes are modifications of each other, we get 
P(A) - P(B) :::; 0. Similarly we can show that P(B) - P(A) :::; 0. Hence we 
have P(A) = P(B). Therefore, the two processes are versions of each other. This 
finishes the proof. 
21.3. 
(a) Lett 2:: 0. Then we have 
{Xt = yt} = {Xt = 0} = [O,t) U (t,oo). 
By the assumption that P{ x} = 0 for all x 2:: 0, we have 
~{Xt = yt} = 1- P{t} = 1. 
Hence the two processes are modifications of each other. 
(b) By part (a) and Problem 21.2, the two processes {Xt : t 2:: 0} and {yt : t 2:: 0} 
are versions of each other. By the definition of versions, the two processes have 
the same finite-dimensional distributions. 

282 
STOCHASTIC PROCESSES 
This completes the proof. 
21.4. Let Q be the set of all rational numbers. We first show that 
{Xt = yt : t?: 0} = 
(21.2) 
rE[O,oo)nQ 
In fact, it is clear that 
{Xt = yt : t?: 0} ~ 
rE[O,oo)nQ 
To show that Equation (21.2) holds, we only need to verify that 
n {Xr = Yr} ~ {Xt = yt: t?: 0}. 
(21.3) 
rE[O,oo)nQ 
To do that, let w E nrE[O,oo)nQ{Xr = Yr }, then Xr(w) = Yr(w) for all r E 
[0, oo) n Q. Let t ?: 0. Then there exists a sequence of rational numbers r 1 , r 2 , ... 
such that rn ?: t and rn -+ t as n-+ oo. By the assumption that X andY are right-
continuous, we have Xrn ( w) -+ Xt ( w) and Yrn ( w) -+ yt ( w) as n -+ oo. Noting 
that Xrn (w) = Yrn (w) for all n?: 1, we have Xt(w) = yt(w). Since tis arbitrary, 
we have Xt(w) = yt(w) for all t?: 0. Hence Equation (21.3) is true. 
By the assumption that X andY are modifications of each other, for all n ?: 1, 
we have 
P{Xrn = Yrn} = 1. 
Therefore, by Problem 11.1 and Equation (21.2), we have 
P{Xt = yt: t?: 0} = P ( n {Xr = Yr}) = 1, 
rE[O,oo)nQ 
which shows that X and Y are indistinguishable. This completes the proof. 
21.5. Let Q be the set of all rational numbers. We claim that 
{Xt?: yt: t?: 0} = 
(21.4) 
rE[O,oo)nQ 
In fact, it is clear that 
{Xt?: yt: t?: 0} ~ 
rE[O,oo)nQ 
To show that Equation (21.4) holds, we only need to show that 
n {Xr?:Yr}~{Xt?:Yt:t?:O}. 
(21.5) 
rE[O,oo)nQ 

SOLUTIONS 
283 
To do that, let w E nrE[O,oo)nQ{Xr ~ Yr }, then Xr(w) ~ Yr(w) for all r E 
[0, oo) n Q. Lett ~ 0. Then there exists a sequence of rational numbers r 1, r2, ... 
such that rn ~ t and rn -t t as n -too. By the assumption that X andY are right-
continuous, we have Xrn(w) -t Xt(w) and Yrn(w) -t yt(w) as n -t oo. Since 
Xrn (w) ~ Yrn (w) for all n ~ 1, we have Xt(w) ~ Yt(w). Since tis arbitrary, we 
have Xt(w) ~ yt(w) for all t ~ 0. Hence Equation (21.5) is true. 
By assumption, we have P{Xrn = Yrn} = 1 for all n ~ 1. It follows from 
Problem 11.1 and Equation (21.4) that 
P{Xt ~ yt : t ~ 0} = P ( n {Xr ~ Yr }) = 1, 
rE[O,oo)nQ 
which shows that X dominates Y. This completes the proof. 
21.6. Let A1 , A2, ... be events defined as 
where Q is the set of all rational numbers. Since An is an intersection and union of 
countably many .Â§"t~ -measurable sets, An is .Â§"t~ -measurable. 
We claim that 
(21.6) 
To do that, let w E A c. Then Xt(w) is not continuous on [0, t 0 ). Hence there exists 
some s0 E (0, t 0 ) such thatXt(w) is not continuous at s0 â¢ In other words, there exists 
an E > 0 such that for each m ~ 1, there exists some Sm with Ism- sol < 1/m and 
IXs,.Jw)- X 80 (w)l > 3E. By the assumption that X is right-continuous, we can 
find two positive numbers 81 and 82 such that 
and 
IXs(w)- Xs0 (w)l < E 
for allis- sol< 82. 
Hence we can find two rational numbers rm,l and rm,2 such that 
and 
lrm,2- sol< min (82, 3~), 
IXrm,l (w) - Xs= (w) I < E, 

284 
STOCHASTIC PROCESSES 
From the above inequalities we get 
and 
Therefore, we have 
where N is some integer greater than ~. Since w is arbitrary, we get 
00 
(21.7) 
It is clear that 
00 
(21.8) 
n=l 
Combining Equations (21.7) and (21.8) gives Equation (21.6). Hence A is Â§/[,-
measurable. This completes the proof. 
21.7. Lett E I. For n :;::: 1, let { X}nl : s E [0, t]} be a stochastic process defined 
as 
(n) 
(k-1)t 
kt 
() 
X 8 
(w)=Xkt/ 2n(w)for 
2n 
:S:s< 2n, 
Xtn =Xt, 
where k = 1, 2, ... , 2n. Let BE If!. Then we have 
{(s,w) E [O,t] x 0: Xin) E B} 
lJ ([(k~n 1)t,~!) x{w:Xkt/2"(w)EB}) 
k=l 
U({t} x {w: Xt(w) E B}) 
E 
B[O, t]0 Â§t. 
By the assumption that X is right-continuous, we have 
lim {(s,w) E [O,t] x 0: Xin) E B} = {(s,w) E [O,t] x 0: Xs E B}. 
n-+oo 
Hence we have 
{(s,w) E [O,t] x 0: Xs E B} E B[O,t]0Â§t. 
Therefore, X is progressively measurable with respect to the filtration. 
21.8. 

SOLUTIONS 
285 
(a) Let C1 E C and C2 E C. Then there exist B1 and B2 in \1'o such that Ci = {X E 
Bi}, i = 1, 2. Since B1 and B2 are rectangles, by Definition 10.4, B1 n B2 is 
also a rectangle. Note that Vt. t E J, are n-systems. We have B1 n B2 E \1'o. 
Thus 
Therefore, Cis an-system. 
(b) Let \1'1 be the collection of all measurable rectangles in F. Then by Definition 
10.4, \1' = a(\1'1). Hence we only need to show that 
(21.9) 
By the assumption that tfft = a(Vt). t E J, we have \1'0 <;;:: \1'1, which implies 
that a(%) <;;:: a(\1'1). To show that Equation (21.9) holds, we need to show that 
a(\1'1 ) <;;:: a(\1'0 ). To do this, it is sufficient to show that 
Let G E \1'1 . Then 
G = X At, 
tEl 
(21.10) 
where At E gt and At differs from Et for only a finite number of t. Let 
S = { t E I : At -=/:- Et}. For each s E S, let 
where Bt = Et fort -=1- sand B 8 = A 8 â¢ Then we have 
But Gs E a(\1'o). It follows that Equation (21.10) holds. 
(c) By part (b) of this proof, \1' = a(\1'0 ). It follows from Problem 5.5 that a(X) = 
a(C). 
This finishes the proof. 
21.9. Let \1'o be the collection of all measurable rectangles in F. Then by Definition 
10.4, we have \1' = a(\1'0 ). By Problem 5.5, we have 
a(X) =a {{wE 0: X(w) E B} :BE \1'o}. 
Hence we only need to show that 
a {{wE 0: X(w) E B} :BE \1'o} = a(Xt : t E J). 
(21.11) 

286 
STOCHASTIC PROCESSES 
To do that, let us first show that 
a{{w E 0: X(w) E B}: BE ~o} ~ a(Xt: t E I). 
(21.12) 
Let A E {{wE 0: X(w) E B}: BE ~0 }. Then there exists a set B E ~0 such 
that A= {X E B}. Since% is the collection of all measurable rectangles on F, we 
have 
B = X Bt, 
Bt E rf!t, 
tEl 
where Bt differs from Et for only a finite number oft. Then we have 
A= n{Xt E Bt} E {Xt E Bt} E a(Xt: t E I). 
tEl 
Since A is arbitrary, it follows that Equation (21.12) holds. 
Next we show that 
a(Xt: t E J) ~a {{wE 0: X(w) E B}: BE ~o}. 
(21.13) 
LetA E {{wE 0: Xt(w) E B}: BE rf!t,t E J}. Thenthereexistsas E Janda 
set Bs E 6"8 such that A= {Xs E B 8 }. Let C be a rectangle on F given by 
where Ct = Et fort-/=- sand Cs = B 8 â¢ Then we have 
A= {Xs E Bs} = n{Xt E Bt} ={X E C} E {{X E B}: BE ~o}, 
tEl 
which shows that Equation (21.13) holds. 
Combining Equations (21.12) and (21.13) gives Equation (21.11). This completes 
the proof. 
21.10. Lett ;::: 0 be fixed. By Problem 21.9, we have 
S:t = a(Xs : 0 ::; s ::; t) = a(Z), 
where Z = (Xs)o<s<t is a random variable from (0, $)to the product space 
( 
x 
R, Â® B(R)) . 
o::;s::;t 
o::;s::;t 
By Problem 2.4, we have 
B(R) = a('D), 
where'D= {(-oo,x] : x E R}. Let ~0 be the collection of all rectangles Gin 
Xo::;s::;t R having the form 

SOLUTIONS 
287 
where As E D and As differs from R for only a finite number of s. Let C1 and C2 
be given by 
C1 = { {Z E B}: BE ~o}, 
C2 = { {Y E B}: BED}. 
Then by Problem 21.8, we find that C1 and C2 are 1r-systems and that CT(Cl) = CT(Z) 
and CT(C2) = CT(Y). 
By Problem 12.3, CT(Y) and $tare independent if and only if 
P(I n J) = P(I)P(J) 
for all IE C1 and J E C2. This completes the proof. 
21.11. Let ~0 be the collection of all rectangles G in F having the form 
where At E Dt and At differs from Et for only a finite number oft. Let C be given 
by 
C ={{X E B}: BE ~o}. 
Then by Problem 21.8, we know that Cis a 1r-system and CT(X) = CT(C). Hence by 
Problem 5.12, it is sufficient to show that for every A E C, we have 
(21.14) 
To show this, we let A E C. Then there exists a set B E ~0 such that A = {X E B}. 
Since B is a rectangle, we have 
B = 
X Bt, 
tEl 
where Bt E Dt and Bt differs from Et for only a finite number oft. Then we have 
IA = IB(X) =II IB,(Xt)â¢ 
tEl 
By the assumption, Equation (21.14) holds. This completes the proof. 
21.12. Let D = {( -oo, c] : c E R}. Then Dis a 1r-system and by Problem 2.4, 
B = CT(D). By Problem 21.9, we have CT(Xt : t E I) = CT(X). By Problem 21.11, it 
is sufficient to show that M includes every mapping V : 0-+ [0, 1] having the form 
where At E D and At differs from R for only a finite number oft. 

288 
STOCHASTIC PROCESSES 
To do this, letS = { s E I : As cf R }. For each s E S, let As = ( -oo, cs] for 
some Cs < oo. Let !s,n : R--+ [0, 1] be defined as 
{
1, 
f.s,n(x) = 
n(cs- x), 
0, 
x E ( -oo, C8
-
1/n]; 
X E (cs- 1/n, C8 ); 
x E [c8 , oo), 
n~l. 
Then !s,nâ¢ n > 1, are bounded continuous functions and fs.n t IA., as n --+ oo. 
Hence 
sES 
sES 
The result follows from the assumption. This completes the proof. 
21.13. 
Let u E R be fixed. We show that the map is continuous at an arbitrary 
point t. To do that, let E > 0. Since y --+ eiuy is continuous at the origin, we can find 
51 > 0 such that 
for all y E (-51 , ol). Also by the assumption that { Xt : t ~ 0} is stochastically 
continuous, we can find 52 > 0 such that 
for all h E ( -02, 02). 
Then for all h E (-52 , 52 ), we have 
I<Px,+,(u)- Â¢x,(u)l 
IL eiuXt+h(w) _ eiuX1(w) P(dw)l 
< L 
Jeiu[X,+h(w)-X,(w)]- 11 P(dw) 
I: leiuy -11 Fx,+h-x,(dy) 
f a, leiuy -11 Fx,+h-x,(dy) + 1 
leiuy -11 Fx,+,-x,(dy) 
-8, 
y(i!(-8,,8,) 
< .:.+21 
Fx,+h-x,(dy) 
2 
y(t(-8,,<\,) 
< 
f. 
Since E is arbitrary, the map is continuous. This completes the proof. 

BIBLIOGRAPHIC NOTES 
289 
21.5 Bibliographic Notes 
In this chapter, we introduced stochastic processes. The general definition of stochas-
tic process is adopted from Kallenberg (1997) and Revuz and Yor (1999). Karatzas 
and Shreve (1988) studied stochastic processes with (R d, B(R d)) as the state space. 
For a proof of Kolmogorov's existence theorem, readers are referred to Billingsley 
(1995). For a proof of Kolmogorov's continuity theorem, readers are referred to 
Stroock and Varadhan (1979). 
Brzezniak and Zastawniak (1999) is a textbook that introduces stochastic pro-
cesses base on a measure theoretic framework. Other books that introduce stochas-
tic processes on a measure theoretic framework include c;inlar (1974), Liptser and 
Shiryayev (1977), Kannan (1979), Doob (1990), Billingsley (1995), Koralov and 
Sinai (2007), and c;inlar (2011). For introduction to stochastic processes without 
measure theory, readers are referred to Karlin and Taylor (1975), Karlin and Taylor 
(1981), Resnick (1992), Ross (1995), Stirzaker (2005), and Ross (2010). 
There are also several problem books on stochastic processes. For example, 
Brzezniak and Zastawniak (1999) is a problem book that is suitable for final year 
undergraduate students. Takacs (1960), Baldi et al. (2002), and Gusak et al. (2010) 
are also problem books on stochastic processes. 


CHAPTER 22 
MARTINGALES 
A martingale is a special stochastic process whose increments over an interval in 
future have zero expectation given information of the past history of the process. 
Martingales play a central role in the theory of stochastic processes and stochastic 
calculus. In this chapter, we present the definition of martingales. 
22.1 
Basic Concepts and Facts 
Definition 22.1 (Martingale). Let I be a set. A stochastic process X = (Xt : t E I) 
is called a martingale relative to a filtration ( { fft : t E I}, P) if the process satisfies 
the following three conditions: 
(a) X is adapted to the filtration. 
(b) E(IXtl) < oo for all t E I. 
(c) E[Xtlffs] = X 8 a.s. for all s:::; t. 
Definition 22.2 (Supermartingale). Let I be a set. A stochastic process X = (Xt : 
t E I) is called a supermartingale relative to a filtration ( { fft : t E I}, P) if the 
process satisfies the following three conditions: 
Measure. Probability, and Mathematical Finance. 
291 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

292 
MARTINGALES 
(a) X is adapted to the filtration; 
(b) E(IXt I) < oo for all t E J; 
(c) E[Xtl$s]::::; X 8 a.s. for all s::::; t. 
Definition 22.3 (Submartingale). Let I be a set. A stochastic process X = (Xt : t E 
I) is called a submartingale relative to a filtration ( { $t : t E J}, P) if the process 
satisfies the following three conditions: 
(a) X is adapted to the filtration. 
(b) E(IXtl) < oo for all t E J. 
(c) E[Xtl$s] 2:: Xs a.s. for all s::::; t. 
22.2 Problems 
22.1. Let X = (Xn : n 2:: 0) be a martingale with respect to a filtration ( { $n : n 2:: 
0}, P). Let m < n. Show that 
22.2. Let X 1 , X 2 , ... be a sequence of independent random variable on a measure 
space (0, $, P) with E(IXnl) < oo and E(Xn) = 0 for all n 2:: 1. Let So = 0, 
$o = {0,0}, 
and 
$n = a(X1, X2, Â· Â· Â· , Xn), 
n 2:: 1. 
Show that S = ( Sn : n 2:: 1) is a martingale with respect to { $ n : n 2:: 0}. 
22.3. Let { Xn }n>o be a sequence of integrable random variables on the probability 
space (0, $, P) and {$n : n 2:: 0} a filtration of$. Assume that {Xn}n>O is 
adapted to { $ n : n 2:: 0}. Show that 
(a) { Xn}n>o is a martingale if and only if 
(b) { Xn}n>O is a submartingale if and only if 

PROBLEMS 
293 
22.4. Let (Xn : n ~ 0) and (Yn : n ~ 0) be submartingales with respect to the 
filtration {Â§n: n ~ 0}. Show that (max(Xn, Yn) : n ~ 0) is also a submartingale 
withrespectto {Â§n: n ~ 0}. 
22.5. Let {Yn}n>l be a sequence of independent random variables with E(Yn) = 
an -:/- 0. Let 
X -IIn Yj 
n-
, 
n~1 
j=l aj 
and 
Â§n = O"(Y1, Y2, ... , Yn), 
n ~ 1. 
Show that {Xn}n>l is a martingale with respect to the filtration {Â§n: n ~ 1}. 
22.6 (Doob-Levy Martingale). Let Y be a random variable on the probability space 
(0, Â§, P) with E(IYI) < oo. Let { Â§n}n>o be an increasing sequence of sub-O"-
fields ofÂ§. Let Xn = E(YIÂ§n), n = 0, 1, .... Show that { Xn}n>o is a martingale 
with respect to the filtration { Â§ n : n ~ 0}. 
22.7. Let {Xn}n>l be a submartingale with respect to the filtration {Â§n: n ~ 1}. 
Let g be a convex and increasing function from R to R. Assume that g(Xn) is 
integrable for all n ~ 1. Show that {g(Xn)Hn>l is a submartingale with respect to 
the filtration { Â§n : n ~ 1 }. 
22.8. Let {Xn}n2':l be a martingale with respect to the filtration {Â§n : n ~ 1}. 
Let g be a convex function from R toR. Assume that g(Xn) is integrable for all 
n ~ 1. Show that {g(Xn) }n2':l is a submartingale with respect to the filtration 
{Â§n: n ~ 1}. 
22.9 (Optional Skipping Theorem). Let {Xn}n>l be a submartingale with respect 
to the filtration {Â§n : n ~ 1}. Let Mk (k ~ 1) be Borel measurable functions of 
xl, x2, ... defined as 
where B1, B2 , ... are arbitrary sets in B(Rk). Let Yn (n ~ 1) be defined as 
Show that 
n-1 
Yn = xl + L Mj(Xj+l- Xj)Â· 
j=l 
(a) {Yn}n2':1 is a submartingale with respect to the filtration { Â§n : n ~ 1 }. 
(b) E(Yn) :::; E(Xn) for all n ~ 1. 

294 
MARTINGALES 
(c) If {Xn}n>1 is a martingale with respect to the filtration {Â§n : n ~ 1}, then 
{Yn}n>1 is also a martingale with respect to the filtration { Â§n : n ~ 1} and 
E(Yn) = E(Xn) for all n ~ 1. 
22.10. Let { Xn}n>o be a submartingale with respect to the filtration { Â§n : n ~ 0}. 
Let {An }n>o be a sequence of random variable defined as 
Show that Mn = Xn - An is a martingale. 
ifn = 0; 
if n ~ 1. 
22.11 (Doob Decomposition). Let {Xn}n2:0 be a submartingale with respect to the 
filtration {Â§n: n ~ 0}. Show that Xn can be written as 
where {Mn}n>o is a martingale, An is Â§n-1-measurable for all n ~ 0, An ~ An-1 
for all n ~ 1, and Ao = 0. 
22.12. Let { Xt : 0 ::; t ::; T} be a supermartingale. Show that { Xt : 0 ::; t ::; T} is 
a martingale if and only if 
E[Xr] = E[Xo]. 
22.3 Hints 
22.1. Use the tower property of the conditional expectations (see Problem 14.10). 
22.2. Follow the definition of martingales (see Definition 22.1) and use Theorem 
11.2andtheresultsofProblem 13.3, 14.4, 14.5,and 14.16. 
22.3. Use the definition of martingales (Definition 22.1) and the definition of con-
ditional expectations (Definition 14.1). 
22.4. Use the results of Problems 14.6 and 5.10. 
22.5. Use the definition of martingales (Definition 22.1) and Theorem 13.2. 
22.6. Use the tower property of the conditional expectations (see Problem 14.10) 
and the result of Problem 15.7. 
22.7. Use the conditional Jensen's inequality (see Problem 15.7). 
22.8. Use the conditional Jensen's inequality (see Problem 15.7). 
22.9. Part (a) can be proved by using the definition of submartingales (Definition 
22.3). Part (b) can be proved by using the tower property of conditional expectations 

SOLUTIONS 
295 
(see Problem 14.10) and using the relation Yn+l-Xn+1 = Yn-Xn+(1-Mn)(Xn-
Xn+1) recursively. Part (c) can be proved similarly. 
22.10. Follow the definition of discrete martingales (Definition 22.1). 
22.11. Use the result ofProb1em 22.10. 
22.12. To prove the sufficiency ("only if") part, use the definition of martingales and 
the tower property of conditional expectations (see Problem 14.10). Use the method 
of contradiction to prove the necessity part. 
22.4 Solutions 
22.1. 
Note that {$n : n ~ 0} is a filtration, which is an increasing family of 
a-fields. By Problem 14.10, we have 
(22.1) 
Since X is a martingale, we have E[Xnl.%n-1] = Xn-1Â· Substituting Xn-1 into 
Equation (22.1) gives 
E[Xnl.%m] = E[Xn-1l.%m]Â· 
Repeating the above process gives E[Xnl.%m] = E[Xml.%m]. By Problem 14.4, we 
have E[Xnl.%m] = Xm. This completes the proof. 
22.2. To show that S is a martingale, we only need to verify that S satisfies the three 
conditions. First, by Theorem 11.2 we know that Sn is a .%n-measurable function 
for each n ~ 0. Hence Sn is adapted to the filtration. Then, by Problem 13.3 and the 
assumption, we have 
E(ISnl) 
E (ltxil) 
< E (tiXil) 
n 
i=1 
< 
00 
for all n ~ 0. Finally, by Problem 14.5 and the assumption, we have 
Noting that Sn-1 is .%n-1-measurable, by Problem 14.4 we have E(Sn-1l$n_1) = 
Sn-1Â· Also noting that Xn and $n_1 are independent, by Problem 14.16 we have 

296 
MARTINGALES 
E(Xnlffn-d = E(Xn) = 0. Hence E(Snlffn-d = Sn-1Â· This completes the 
proof. 
22.3. 
(a) By the assumption that {Xn}n>o is integrable, we have E(IXnl) < oo for 
n?: 0. Note that {Xn}n:;:.o is adapted to the filtration. We only need to verify 
that E(Xn+llffn) = Xn is equivalent to 
But this equation is implied by Definition 14.1 and the assumption. This com-
pletes the proof. 
(b) The proof is similar to that of part (a). 
22.4. 
By Problem 5.10, we have max(Xn, Yn), which is adapted to the filtration 
{ ffn : n ?: 0}. In addition, 
Hence we only need to verify that 
(22.2) 
By the assumption that (Xn : n ?: 0) and (Yn : n ?: 0) are submartingales and 
Problem 14.6, we have 
and 
E[max(Xn, Yn)lffn-1] ?: E[Ynlffn-d?: Yn-1Â· 
The above two inequalities imply that Inequality (22.2) is true. This completes the 
proof. 
22.5. By definition of Xn, Xn is ffn-measurable. By Theorem 13.2, we have 
E(IXnl) = E ( IT; ) =IT E (I; I)Â· 
]=1 
J 
.)=1 
.1 
Since E(Yn), n = 1, 2, ... exist, we have E(IXnl) < oo. By Theorem 13.2, we have 

SOLUTIONS 
297 
Hence { Xn}n~ 1 is a martingale with respect to the filtration { Â§n : n ~ 1 }. 
22.6. By definition, Xn = E(YIÂ§n) is Â§n-measurable. In addition, by Problems 
15.7 and 14.10, we have 
By Problem 14.10, we have 
E[E(YIÂ§n)lÂ§n-1] 
E(YIÂ§n-1) 
Xn-1, 
n ~ 1. 
Hence {Xn}n>o is a martingale. This completes the proof. 
22.7. We only need to verify the last condition of submartingales: 
But by Problem 15.7 and the assumption that g is convex, we have 
By the assumption that {Xn}n~ 1 is a submartingale, we have 
E(Xn+llÂ§n) ~ Xn, 
n ~ 1. 
(22.3) 
Note that g is also an increasing function. The inequality (22.3) is true. This com-
pletes the proof. 
22.8. We only need to verify the last condition of submartingales, i.e, 
But by Problem 15.7 and the assumption that g is convex, we have 
By the assumption that {Xn}n>1 is a martingale, we have 
E(Xn+1lÂ§n) = Xn, 
n ~ 1. 
Hence the inequality (22.4) is true. This completes the proof. 
22.9. 
(22.4) 
(a) It is obvious that Yn is Â§n-measurable and E(IYnl) < oo for all n ~ 1. Noting 
that Mn is a Borel measurable function of X 1, X 2 , ... , Xn and that {Xn}n~ 1 
is a submartingale, we have 
E(Yn + Mn(Xn+l- Xn)lÂ§n) 
Yn + MnE(Xn+l- XnlÂ§n) 
> Yn. 

298 
MARTINGALES 
Hence {Yn}n2:l is also a submartingale with respect to the filtration { Â§n : n 2: 
1 }. 
(b) By definition, we have 
Subtracting Xn+l from both sides of the above equation gives 
which is equivalent to 
Taking expectation of both sides of the above equation gives 
By Problem 14.10, we have 
E[(1- Mn)(Xn- Xn+I)J 
E(E[(1- Mn)(Xn- Xn+I)IÂ§n]) 
E((1- Mn)(Xn- E[Xn+1lÂ§n]). 
Noting that { Xn}n> 1 is a submartingale, we have 
Hence 
(1- Mn)(Xn- E(Xn+llÂ§n) :::; 0. 
Combining inequalities (22.5), (22.6), and (22.7) gives 
E(Yn+l- Xn+1) :::; E(Yn- Xn), 
n 2: 1. 
Note that E(Y1 -XI) = 0. We have E(Yn- Xn) :::; 0 for all n 2: 1. 
(c) The proof is similar to those of parts (a) and (b). 
(22.6) 
(22.7) 
22.10. For each n 2: 1, An is Fn_1-measurable. Hence Xn- An is jOn-measurable. 
Thus, Mn is adapted to the Â§nÂ· Since Xn is a submartingale, we have 
n 
< E(IXnl) + L {E(E(IXillÂ§i_I)) + E(IXi-11)} 
i=1 
n 
E(IXnl) + L {E(IXil) + E(IXi-11)} 
i=1 
< 
00. 

Now for n 2::: 1, we have 
E(Mnlffn-1) 
E(Xnlffn-d - E(Anlffn-d 
E(Xnlffn-d- An 
n 
n 
SOLUTIONS 
299 
E(Xnlffn-d- LE(Xilffi_I) + LXi-1 
i=1 
i=1 
Therefore, Mn is a martingale. 
22.11. Let Ao = 0 and 
n 
i=1 
Then for each n 2::: 1, An is ffn_1-measurable. Since the Xn is a submartingale, we 
have 
An= E[Xnlffn-1]- Xn-d + An-1 2::: An-1, 
n 2::: 1. 
Now let Mn = Xn - An. By Problem 22.10, the Mn is a martingale. This 
completes the proof. 
22.12. 
First, let us prove the sufficiency. Suppose that { Xt : 0 :::; t :::; T} is a 
martingale. Then by Definition 22.1 we have 
E[Xrlffo] = Xo. 
By Problem 14.10, we get 
E[Xr] = E(E[Xrlffo]) = E[Xo]. 
Now let us prove the necessity. Suppose that E[Xr] = E[X0]. Since {Xt : 0:::; 
t :::; T} be a supermartingale, we have 
E[Xtlffs] :S: Xs 
a.s. 
for all s :::; t. Hence we have 
E[Xr] :::; E[Xt] :::; E[Xs] :::; E[Xo] 
for all 0 :::; s :::; t :::; T. By the assumption, we get E[Xs] = E[Xt] for all s :::; t. Let 
An= {Xs- E[Xtlffs] > 1/n} for n 2::: 1. Then for s < t, we have 
1 
0 = E[Xs]- E[Xt] = E(Xs- E[Xtlffs]) 2::: -P(An), 
n 
which implies P(An) = 0. By Theorem 2.2, we have P(lim sup An) = 0. But 
{Xs- E[Xtlffs] > 0} ~ limsupAn. 
Hence we have P{Xs- E[Xtlffs] > 0} = 0; that is, X 8
- E[Xtlffs] = 0 a.s. 
Therefore, { Xt : 0 :::; t :::; T} is a martingale. This completes the proof. 

300 
MARTINGALES 
22.5 Bibliographic Notes 
In this chapter, we defined the martingale. Since the martingale is the most basic 
concept in stochastic processes and stochastic calculus, it has been studied in many 
books such as Karlin and Taylor (1975), Williams (1991), Resnick (1999), Shorack 
(2000), Chung (2000), Klebaner (2005), Gut (2007), and Pascucci (2011). Baldi 
et al. (2002) is a problem book with martingales. For some interesting applications 
of martingales, readers are referred to Ross ( 1995). 

CHAPTER 23 
STOPPING TIMES 
Stopping times are important tools that allow us to analyze stochastic processes by 
viewing them at random times. In this chapter, we present a definition and relevant 
results of stopping times. 
23.1 
Basic Concepts and Facts 
Definition 23.1 (Discrete Stopping Time). Let (0, $, P) be a probability space and 
{ $n, n = 0, 1, 2, ... } an increasing sequence of sub-a-fields of$. A stopping time 
for { $n : n 2: 0} is a function 
T: n-+ {o, 1, ... , oo} 
such that {T ::; n} E $ n for each n 2: 0. 
A stopping time for a sequence of random variables, { Xn}n>o, is a stopping time 
relative to the a-fields $n = a(Xo, X1, ... , Xn)Â· 
In the above definition, the index starts from 0. The definition can be modified in 
the obvious way ifthe index starts from 1. 
Measure, Probability, and Mathematical Finance. 
301 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

302 
STOPPING TIMES 
Definition 23.2 (Continuous Stopping Time). Let (0, $, P) be a probability space 
and { $t : a :<:::; t :<:::; b} be a filtration. A stopping time with respect to the filtration is 
a function 
7 : 0 --+ [a, b] 
such that {7 :<:::; t} E $t for all t E [a,b]. 
Definition 23.3 (Events Prior to T). Let { $n, n = 0, 1, 2, ... } be an increasing 
sequence of sub-a-fields of$. LetT be a stopping time for {$n : n 2: 0}. An 
event A E $ is said to be prior to T if and only if 
The collection of all sets prior toT is denoted by $r: 
$r ={A E $: An {T :<:::; n} E $n, n = 0, 1, ... }. 
For a continuous stopping time 7 with respect to a filtration { $t : a :<:::; t :<:::; b }, the 
quantity $r is defined as 
$r ={A E $:An {7 :<:::; t} E $t forallt E [a,b]}. 
Definition 23.4 (Hitting Time and Exit Time). Let {Xt : t 2: 0} be a stochastic 
process adapted to some filtration { $t : t 2: 0}. Let A be a measurable subset of R. 
The hitting time of A is defined as 
{ inf{t 2: 0: Xt E A}, 
if {t 2: 0: Xt E A} =j;0; 
TA= 
oo, 
if otherwise. 
The exit time from the set A is defined as 
7A = TR\A = { inf{t 2: 0: Xt 1- A}, 
if {t 2: 0: Xt 1- A} =j;0; 
oo, 
if otherwise. 
Theorem 23.1 (Optimal Stopping Theorem). Let I = [0, oo) or I = N. Let { Xt : 
t E I} be a right-continuous supermartingale on a probability space (0, $, P) with 
respect to a filtration { $t : t E I}. Suppose that 7 1 and 7 2 are bounded stopping 
times such that 7 1 :<:::; 7 2. Then 
where 
In addition, if the Xt is a right-continuous martingale, then 

PROBLEMS 
303 
If the Xt is a right-continuous submartingale, then 
E[XT21Â§Tll ~ XT!' 
Theorem 23.2 (Optimal Sampling Theorem). Let I = [0, oo) or I = N. Let { Xt : 
t E I} be a right-continuous martingale on a probability space (D, Â§, P) with 
respect to a filtration { fft : t E I}. If T is a stopping time (not necessarily finite), 
then {XTJ\t: t E I} is a martingale with respect to the filtration {Â§TJ\t: t E I}. 
23.2 Problems 
23.1. Let { ffn : n ~ 0} be an increasing sequence of a-fields. Let S and T be 
stopping times for { Â§ n : n ~ 0}. Show that S V T and S 1\ T are also stopping 
times for {ffn: n ~ 0}, where 
S V T = max(S, T), 
S 1\ T = min(S, T). 
23.2 (Hitting Time). Let { Xn}n>O be a sequence of random variables on the proba-
bility space (D, Â§, P) and BE B. LetT: n-+ {0, 1, ... , oo} be defined as 
{
min{n: Xn(w) E B} ifXn(w) E Bforsomen; 
T(w) = 
oo 
if Xn(w) is never in B. 
Show that T is a stopping time for { Â§ n : n ~ 0}, where 
ffn=a(Xo,Xl, ... ,Xn), 
n=0,1, .... 
23.3. Let (D, <~, P) be a probability space. Let { Â§ n, n = 0, 1, 2, ... } be an increas-
ing sequence of sub-a-fields ofÂ§. LetT be a stopping time for {ffn : n ~ 0}. 
Show that ffr is a sub-a-field ofÂ§. 
23.4. LetS and T be stopping times for { ffn, n = 0, 1, 2, ... }. Show that if S :::; T, 
then ffs ~ Â§y, where ffs and ffr are the collections of all sets prior to SandT, 
respectively. 
23.5. Let (D, Â§, P) be a probability space. Let { ffn, n = 0, 1, 2, ... } be an increas-
ing sequence of sub-a-fields ofÂ§. LetT be a stopping time for { Â§n : n ~ 0}. Let 
{Xn}n;::o be a sequence of random variables adapted to {ffn : n = 0, 1, ... }. Let 
Xr : n-+ R be defined as 
Xr(w) = Xn(w) 
ifT(w) = n,w ED. 
Show that Xr is ffr-measurable and is a random variable. 
23.6. Let { Xn : n = 1, 2, ... , m} be a submartingale with respect to the filtration 
{ffn: n = 1, 2, ... , m}. LetT be a stopping time for the ffnÂ· Show that 
E(IXrl) S 2E(X!)- E(Xl). 

304 
STOPPING TIMES 
23.7. Let {Xn : n = 1, 2, ... , m} be a martingale with respect to the filtration 
{-~n : n = 1, 2, ... , m }. Let {Tn}n>l be a nondecreasing sequence of finite 
stopping times for {Â§n : n = 1, 2, ... , m }. Then, T1 <::: T2 <::: ... <::: m. Show that 
(a) { Â§T; : i 2: 1} is a filtration. 
(b) {X T, : i 2: 1} is a martingale. 
(c) {X T, : i 2: 1} is a submartingale with respect to the filtration { Â§T; : i 2: 1} if 
{ Xn : n = 1, 2, ... , m} is a submartingale. 
23.8. Let T1 and T2 be stopping times for a filtration { Â§t : t 2: 0}. Suppose that 
T1 <::: T2. Show that Â§T, <;;;: Â§T2Â· 
23.9. Let T1 and T2 be stopping times with respect to a filtration { Â§t : t 2: 0}. Show 
that 
(b) The events { T1 < T2}. { T1 <::: T2}, { T1 > T2}, { T1 2: T2}, and { T1 = T2} belong 
tO '~Tj/\T2 â¢ 
23.10. Let { -~t : a <::: t <::: b} be a right-continuous filtration. Show that a random 
variable T : n --+ [a, b] is a stopping time with respect to { Â§t : a <::: t <::: b} if and 
only if 
{T < t} E Â§t for all t E [a,b]. 
23.11. Let I = [0, oo) or I = [0, t 0] for some t0 < oo. Let { Xt : t E I} be a 
stochastic process with values in a measurable space (E, f:). Suppose that { Xt : 
t E I} is progressively measurable (see Definition 21.23) with respect to a filtration 
{Â§t : t E 1}. LetT be a stopping time for the filtration. Show that XT is Â§T .. 
measurable, that is, { XT E B} n { T <::: t} E Â§t for each B E g and t E I. 
23.12. Let ( 12, .'#, P) be a probability space and { Â§t : t 2: 0} be a filtration. Let T 
be a bounded stopping time with respect to the filtration. Let n be a positive integer. 
Let T(n) : n --+ [0, 00) be defined as 
if T(w) E [ 2~, to, k2-1;ho), k = 0, 1, ... , 217 ~ 1; 
ifT(w) =to, 
where t0 is the bound ofT, that is, T <::: t0. Show that T(n) is a stopping time with 
respect to the filtration. 
23.13. Let { Xt : t 2: 0} be a right-continuous stochastic process and adapted to a 
right-continuous filtration {Â§t: t 2: 0}. Show that 
(a) If A is an open set, then TA is a stopping time. 
(b) If Dis a closed set, then TD is a stopping time. 

HINTS 
305 
Here TD and TA are the exit time and the hitting time defined in Definition 23.4, 
respectively. 
23.14. Let {Xt : t ;::: 0} be a right-continuous stochastic process and adapted to 
some filtration { fft : t ;::: 0}. Let A be a closed subset of R. Show that the hitting 
time T A is a stopping time. 
23.15. Let I = [0, oo) or I = N. Let { Xt : t E I} be a right-continuous martingale 
on a probability space (n, Â§, P) with respect to a filtration {fft : t E I}. LetT be 
a stopping time such that 
(a) P{T<oo}=l. 
(b) X 7 At(t E I) is uniformly integrable. 
Show that 
E[XT] = E[Xo]. 
23.16. Let { Â§n : n ;::: 0} be a filtration and Z an integrable random variable. 
Let Xn = E[Ziffn] for all n ;::: 0. LetT be a stopping time with respect to the 
filtration. Suppose that Z is ff00-measurable, where Â§
00 = !J (U::o ffn). Show 
that { X 7 , Z} is a martingale with respect to the filtration { Â§
7 , Â§ oo}: 
23.17. Let { Xn : n ;::: 0} be a martingale adapted to a filtration { Â§n : n ;::: 0}. Let 
T be a bounded stopping time with respect to the filtration, that is, P{ T :::; M} = 1 
for some constant M. Show that {X 7 , X M} is a martingale. 
23.18. Let {Xn : n;::: 0} be a submartingale adapted to a filtration {Â§n : n;::: 0}. 
LetT be a bounded stopping time with respect to the filtration, that is, P{ T :::; M} = 
1 for some constant M. Show that { Xn XM} is a submartingale, i.e., 
23.19. Let {Xt 
t > 0} be a right-continuous martingale with X 0 
A,B > 0 and 
T = inf{t: Xt =A or Xt = -B}. 
Suppose that P{ T < oo} = 1. Show that E[X7 ] = 0 and 
23.3 Hints 
B 
P{XT =A}= -A-. 
+B 
23.1. Use the definition of stopping times (Definition 23.1). 
0. Let 

306 
STOPPING TIMES 
23.2. Note that 
n 
{T :S n} = U{Xk E B}, 
k=O 
and then use the definition of stopping times (Definition 23.1). 
23.3. Use the definition of a-field (Definition 2.2). 
23.4. Follow the definition of events prior toT (Definition 23.3) and use the standard 
technique, that is, show that A E ~s implies A E ~TÂ· 
23.5. Follow the definition of measurable functions (Definition 5.1) and the defini-
tion of random variables (Definition 11.6). 
23.6. Note that 
E(IXrl) 
kiXrldP 
fJ _ 
IXildP 
i=l {T-z} 
2 ~ 
/T=i} Xt dP - ~ 
/T=i} XidP 
and that {X;t}n=l,2, ... is a submartingle (see Problem 22.7). Then use the result of 
Problem 22.3. 
23.7. Part (a) is implied by Problem 23.4. Parts (b) and (c) can be proved by using 
the result of Problem 22.3 and the technique used to prove Problem 23.6. 
23.8. For every A E ~71 , consider the decomposition 
23.9. To prove part (a), use the result of Problem 23.8 and Definition 23.3. To prove 
part (b), consider the decompositions 
and 
23.10. Use the definition of right-continuous filtrations (Definition 21.20) and note 
that 

SOLUTIONS 
307 
and 
23.11. For a fixed t E I, note that X 7 is the composition of the map from { T :S: t} 
to [0, t] x { T:::; t} and the map from [0, t] x { T:::; t} to E. 
23.12. Try to construct { T(n) :::; t} by a union of events of the form { T :S: t'} and 
then follow the definition of stopping times. 
23.13. Use the result of Problem 23.10 to prove part (a). Part (b) is equivalent to 
part (a). 
23.14. Consider the sequence of sets 
An= { x E R: inf{IY- xl: yEA}< ~}, n 2: 1, 
and try to establish 
{TA :S: t} = {Xt E A} U ( n U {Xq E An}) . 
n=l qEQn[O,t) 
23.15. Use the result of Problem 9.10 to show that E[Xr/\t] ---+ E[Xr] as t ---+ oo. 
Then use the optimal sampling theorem (Theorem 23.2). 
23.16. Follow the definition of conditional expectations (Definition 14.1) and note 
that for A E ffn we have 
A= u An{T=n}. 
nE{O,l, ... ,oo} 
23.17. Use the result of Problem 23.16. 
23.18. Use the definition of conditional expectations (Definition 14.1) and consider 
23.19. Use the optimal stopping theorem (Theorem 23.1) and the result of Problem 
14.18. 
23.4 Solutions 
23.1. By definition, we only need to show that { S V T :::; n} and { S 1\ T :::; n} are 
elements of ffn for n 2: 0. But 
{ S V T :::; n} = { S :::; n} n {T:::; n} 

308 
STOPPING TIMES 
and 
{S 1\ T :S: n} = {S :S: n} U {T :S: n}. 
By the assumption that SandT are stopping times, we have {S V T:::; n} E Â§n 
and { S 1\ T :::; n} E Â§ n. This completes the proof. 
23.2. By definition of stopping times, we only need to show that {T :::; n} E Â§n, 
n 2": 0. Note that 
n 
{T :S: n} = U {Xk E B}, 
n 2": 0. 
k=O 
We have {T :::; n} E Â§nÂ· Hence Tis a stopping time. 
23.3. By the definition of stopping times, we have 0 n {T:::; n} = {T :::; n} E Â§n. 
n = 0, 1, .... Hence 0 E Â§r. 
Now let A E Â§r. Then An {T:::; n} E Â§n, n = 0, 1, .... Note that 
and Â§n is a Â£T-field. We have Ac n {T:::; n} E Â§n, n = 0, 1, .... Hence AcE Â§r. 
Finally, let Ai E Â§r, i = 0, 1, .... Then Ai n {T :S: n} E Â§n, n = 0, 1, .... 
Note that 
(Q Ai) n {T:::; n} = Q[Ai n {T:::; n}]. 
We have U:o Ai E Â§r. Therefore, Â§Tis a O"-field. 
23.4. Let A E Â§ s. Then 
An {S :S: n} E Â§n, 
\:In 2": 0. 
By the assumption that S :::; T, we have 
Hence 
An{T:S:n} 
n 
{T:S:n}<;;;; U{S=k}. 
k=O 
A n (Qo { 
S = k}) n {T :::; n} 
CQ0[A n {S = k}]) n {T:::; n}. 
Since Sis a stopping time for {Â§n: n 2": 0}, we have An {S = k} E Â§k <;;;; Â§n, 
k = 0, 1, ... , n. Therefore, the above equation implies that An {T :S: n} E Â§nÂ· 
Hence A E Â§r. Since A is arbitrary, we have Â§s <;;;; Â§r. This completes the proof. 

SOLUTIONS 
309 
23.5. Let BE B. Note that Xy; 1(B) ={wE 0: Xr(w) E B} = {Xr E B}. To 
show that Xr is Â§r-measurable, we only need show that {Xr E B} E Â§r. Note 
that 
n 
{Xr E B} n {T:::; n} = U [{Xk E B} n {T = k}] 
k=O 
and {Xn}n>o is adapted to {Â§n, n = 0, 1, 2, ... }. We have 
{Xr E B} n {T:::; n} E Â§nÂ· 
Hence {Xr E B} E Â§r. Since B is arbitrary, Xr is Â§r-measurable. 
Since Â§T <;;; Â§, Xr is also Â§-measurable, that is, Xr is a random variable on 
(0, Â§, P). This completes the proof. 
23.6. Since 
E(IXrl) 
it suffices to show that 
and 
fn1XrldP 
~ 
IT=i} IX;IdP 
2:t { . XtdP-:t { . X;dP, 
i=l J{T=2} 
i=l J{T=2} 
:t 1 _ 
XtdP:::; E(X;;-,) 
i=l {T-2} 
:t { . X;dP :2 E(Xl). 
i=l j{T=2} 
(23.1) 
(23.2) 
First, let us show that inequality (23.1) is true. By Problem 22.7, {X;{}n=l,2, ... ,m is 
a submartingale with respect to the Â§nÂ· Since {T = 1} E Â§ 1, by Problem 22.3, we 
have 
{ 
X{dP:::; { 
XidP. 
J{T=l} 
J{T=l} 
Hence we have 
:t { . XtdP = :t { XtdP+ { 
X{dP 
i=l j{T=2} 
i=2 J{T=i} 
J{T=l} 
m 
< L r 
xtdP+ r 
XidP 
i=2 j{T=i} 
j{T=l} 
:t { XtdP + { 
XidP. 
i=3 J {T=i} 
j {T~2} 

310 
STOPPING TIMES 
Repeating the above process leads to 
m L { 
X{dP::::; { 
X~dP. 
i=1 j{T=i} 
j{TS,m} 
But {T ::::; m} = 0. It follows that inequality (23.1) is true. 
Next, let us prove inequality (23.2). Since {Xn}n=1,2, ... ,m is a submartingale and 
{T = m} = {T ~ m} = {T::::; m- 1}c E Â§m_ 1, by Problem 22.3, we have 
{ 
XmdP ~ { 
Xm-1dP. 
}{T=m} 
J{T=m} 
Hence 
m-1 
L { 
XidP+ { 
XmdP 
i=1 j{T=i} 
j{T=m} 
m-1 
L { . XidP + { 
Xm-1dP 
i=1 J{T=<} 
J{T=m} 
> 
m-2 
L { . XidP + { 
Xm-1dP. 
i=1 J{T=<} 
J{T?_m-1} 
Repeating the above process leads to 
f { 
XidP ~ { 
X 1dP. 
i=1 J{T=i} 
J{T?_1} 
But {T ~ 1} = 0. It follows that inequality (23.2) is true. This completes the proof. 
23.7. 
(a) By Problems 23.4 and 23.3, and the assumption that {Tn : n ~ 1} is increasing, 
{ .9"r, : i ~ 1} is a filtration. 
(b) Let Yi = Xr,, i = 1, 2, .... Since 
theY; are integrable. By Problem 22.3, to show that {Yi : i ~ 1} is a martingale 
with respect to {Ti : i ~ 1 }, we only need to show that 
i Yi+1dP = i Y;dP, 
\lA E .9"r" i ~ 1. 
(23.3) 
Let i ~ 1 and A E .9"r,. Since Ti is finite, we have 
m 
A= U[An{Ti=k}]. 
k=1 

SOLUTIONS 
311 
Then, to show that Equation (23.3) holds, it is sufficient to show that 
(23.4) 
where Dk =An {Ti = k}. 
Since Ti+1 is finite and Ti+l ?: Ti, we have 
(23.5) 
Since {Ti+l = m} = {Ti+1 ?: m} = {Ti+l :::; m- 1}c E Â§m_1, we have 
Dk n {Ti+1 = m} E Â§m_1. By the assumption that {Xn}n>1 is a martingale 
and Problem 22.3, We have 
Hence, Equation (23.5) becomes 
r Yi+IdP 
}Dk 
m-1 
~ 
lkn{Ti+l=j} XJdP + lkn{Ti+l=m} Xm_ 1dP 
Since {Ti+1 ?: m- 1} = {Ti+1 :::; m- 2}c E Y:m-2, we have Dk n {Ti+1 ?: 
m - 1} E Â§ m-2 . Again by Problem 22.3, we have 
{ 
Xm-1dP = 
{ 
Xm-2dP. 
J Dkn{Ti+l::C:m-1} 
J Dkn{Ti+l::C:m-1} 
Hence, Equation (23.6) becomes 
r Yi+1dP 
}Dk 
m-2 
L j 
XjdP + j 
Xm-2dP 
j=k Dkn{Ti+,=j} 
Dkn{T,+ 1 ::C:m-1} 
m-3 
L r 
XjdP + r 
Xrn-2dP. (23.7) 
j=k j D,n{Ti+l =j} 
j Dkn{Ti+ 1 ::C:m-2} 

312 
STOPPING TIMES 
Repeating the above process, we get 
Since Dk c;;- {Ti+l ;::: k }, we have Dk n {Ti+l ;::: k} = Dk. Hence the above 
equation becomes 
which shows that Equation (23.4) is true. Hence {X T, : i ;::: 1} is a martingale 
with respect to the Â§Ti. 
(c) The proof is similar to that of part (b). 
23.8. Let A E :!771 and t ;::: 0. Then we have 
A n { T2 :::; t} = [A n { T2 :::; t} n { T1 :::; t}] u [A n { T2 :::; t} n { T1 > t} ]. 
By the assumption that T1 :::; T2 , we have { T2 :::; t} n { T1 > t} = 0. Hence 
A n { T2 :::; t} = A n { T2 :::; t} n { T1 :::; t}. 
Since A n { T1 :::; t} E Â§
1 and { T2 :::; t} E Â§ 1 , by the above equation we get 
Since tis arbitrary, we have A E .'#T2. Hence Â§ 71 c;;- :!772 . This completes the proof. 
23.9. 
(a) By Problem 23.8, we have .'#71 M2 c;;- .'#7 , n .'#72 . Hence we only need to prove 
(23.8) 
To do that, let A E .'#7, n Â§72 and t ;::: 0. Then we have A n { T] :::; t} E fft 
and A n { T2 :::; t} E .'#1 for all t ;::: 0. Note that 
Hence we have A n { T1 1\ T2 :::; t} E Â§ 1. Since t is arbitrary, we have A E 
ff7,M2 â¢ Since A is arbitrary, Equation (23.8) holds. 
(b) Let t ;::: 0. Since 
and {T1 1\ t :::; T2 1\ t}, {T1 :::; t}, and {T2 :::; t} are events in Â§ 1, we have 
{ T1 :::; T2 } E :#72 â¢ Similarly, we have { T1 < T2 } E :#72 â¢ Since .'l'T2 is CJ-
algebra, we have { T1 = T2 } E .'#72 , { T1 > T2 } E ,'#72 , and { T1 ;::: T2 } E ff72 â¢ 

SOLUTIONS 
313 
If we interchange the roles of 7 1 and 7 2, we see that these events also belong to 
$ r 1 â¢ Hence by the first item, these events belong to $ r 1 Ar2 . 
This completes the proof. 
23.10. First let us prove the "if" part. Suppose that 
{7 < t} E Â§t for all t E [a,b]. 
Then we have 
{ 7 < t + ~} E Â§t+ ~ for all n ?: 1. 
By the assumption that the Â§t is right-continuous, we have 
00 
g-t = n 
g-t+~Â· 
n=l 
Therefore, we have 
Since t is arbitrary, 7 is the stopping time by definition. 
Now let us prove the "only if" part. Suppose that 7 is the stopping time with 
respect to the filtration. Then we have { 7 :::.; t} E Â§t for all t E [a, b ]. Note that 
and 
{ 7:::.; t- ~} E Â§t-~ ~ Â§t. 
We have { 7 < t} E Â§t. This completes the proof. 
23.11. Lett E I be fixed. Let f2t = {7:::.; t} and .#t ={An f2t :A E Â§t}. Let 
f : f2t -+ [0, t] X f2t be defined as 
f(w) = (7(w),w). 
Let g : [0, t] X nt -+ E be defined as 
g(s,w) = X 8 (w). 
Then Xr =go f, that is, Xr is the composition of maps f and g. By the assumption 
that X is progressively measurable, g on [0, t] x n is B[O, t] x Â§t/8'-measurable. 
Hence the restriction of g on [0, t] x f2t is measurable with respect to the a-fields 
{An ([0, t] x f2t): A E B[O, t] x Â§t} and 8'. 

314 
STOPPING TIMES 
Hence we only need to show that f is a measurable map. To do that, let C E 
{An ([0, t] x flt): A E B[O, t] x .~t}. Then 
r
1(C) ={wE flt: f(w) E C} ={wE flt: T(w) ~ t} E fft. 
Hence f is a measurable map. This completes the proof. 
23.12. Let t E [ 0, oo). Let Kt be the largest integer in { 0, 1, ... , 2" - 1} such that 
K~;; 1 t0 ~ t. Then we have 
K, { 
k 
1 
} 
{T(n)~t}=U T~ ;, to. 
k=O 
Since T is a stopping time with respect to { fft : t 2::: 0}, we have 
k=0,1, ... ,Kt. 
It follows that { T(n) ~ t} E fft. Hence T(n) is a stopping time. This completes the 
proof. 
23.13. 
By Problem 23.1 0, it is sufficient to show that 
To do that, we show that 
{TA < t} = U {Xq E A}, 
qEQn(o.t) 
where Q is the set of rational numbers. Let 
wE U {Xq E A}. 
qEQn(O,t) 
(23.9) 
Thenw E {Xq E A}forsomerationalnumberin(O,t). HenceTA(w) ~ q < t, 
which implies that wE {TA < t}. Therefore, we have 
U {Xq E A}~ {TA < t}. 
(23.1 0) 
qEQn(O,t) 
Now let wE {TA < t}. Then we have XrA(w) (w) EA. Since A is an open set, 
there exists an E > 0 such that 

SOLUTIONS 
315 
Since Xt is right-continuous, there exists a o E (0, t- TA(w)) such that for 
every r E (TA(w), TA(w) + o), 
IXr(w)- XrA(w)(w)l <E. 
Let q be a rational number in (TA(w), TA(w) + o). Then we have 
Hence wE {Xq E A}. Since w is arbitray, we have 
{TA < t} s;;; U {Xq E A}. 
qEQn(O,t) 
(23.11) 
Equation (23.9) follows from Equations (23.10) and (23.11). Since {TA < t} 
is a countable union of elements in fft. we have {TA < t} E fft. 
(a) This follows from part (a) because Tv = TR\DÂ· 
This completes the proof. 
23.14. For every n ~ 1, let 
An= { x E R: inf{IY- xl: yEA}< ~}. 
Then An is an open set for all n ~ 1. We claim that 
{TA:::; t} = {Xt E A} U ( n U {Xq E An}) . 
n=l qEQn[O,t) 
(23.12) 
To show this, let wE {TA :::; t}. IfTA(w) = t, then we have wE {Xt E A}. Hence 
we have 
{TA:::; t} s;;; {Xt E A} U ( n U {Xq E An}) . 
n=l qEQn[o,t) 
(23.13) 
Suppose that TA(w)) < t. Note that for every n ~ 1, there exists an En > 0 such 
that 
(XrA(w)(w)- En, XrA(w)(w) +En) s;;; An. 
Since the Xt is right-continuous, there exists a On E (0, t- TA(w)) such that for 
every r E (TA(w), TA(w) +On). we have 

316 
STOPPING TIMES 
Let qn be a rational number in (TA(w), TA(w) + 8n)Â· Then we have Xqn (w) E An, 
which implies wE {Xqn E An}Â· Hence for every n;::: 1, we have 
wE U {Xq E An}Â· 
qEQn[O,t) 
Thus Equation (23.13) still holds in this case. 
Now let 
wE{XtEA}U (n U {XqEAn}). 
n=l qEQn[o,t) 
If wE {Xt E A}, then TA(w) ::; t, which implies wE {TA ::; t}. Suppose that 
w E ( n U { Xq E An}) . 
n=l qEQn[o,t) 
Then for every n ;::: 1, we have w E {Xqn E An} for some rational number qn 
in [0, t). Let Tn = infr::::n qn and let r = limn---+oo TnÂ· Then we haver ::; t and 
Xr(w) E A. Hence we have TA(w) ::; r ::; t, which implies that w E {TA ::; t}. 
Therefore, we have 
{Xt E A} U (n U {Xq E An}) ~ {TA::; t}. 
n=l qEQn[O,t) 
(23.14) 
It follows from Equations (23.13) and (23.14) that Equation (23.12) holds. Since the 
right-hand side of Equation (23.12) is a countable union of 9"rmeasurable sets, we 
have {TA ::; t} E 9"t. This completes the proof. 
23.15. 
By the assumption that P( T < oo) = 1, we know that T 1\ t = T for 
sufficiently large t outside a P-null set. Hence Xrl\t = Xr a.s. as t ---+ oo. Now, by 
the assumption that Xrl\t is uniformly integrable and Problem 9.10, we have 
lim E[Xr/\t] = E[Xr]Â· 
t---+oo 
By Theorem 23.2, we have 
E[Xrl\t] = E(E[Xrl\tl9"o]) = E(XrAo) = E[Xo]. 
Hence E[Xrl\t] = E[X0]. This completes the proof. 

SOLUTIONS 
317 
23.16. By Problem 23.5, X 7 is $
7 -measurable. Let N = {0, 1, ... , oo }. Then by 
Definition 14.1 and the definition of Xn, we have 
E[IXT ll 
In IXT ldP 
"f_hr=n} IXrldP 
"f_hr=n} IXnldP 
< "f_hr=n} E[IZII$n]dP 
"f. hr=n} E[IZI]dP 
= 
E[IZI]. 
Since Z is integrable, X 7 is also integrable. 
Now let A E $r- Since 
we have 
iXrdP 
A= U An{T=n}, 
nEN 
LN_ Ln{r=n} XrdP 
nE 
"f. Ln{r=n} XndP 
"f_Ln{r=n} E[ZI$n]dP 
"f_Ln{r=n} ZdP 
izdP. 
It follows from Definition 14.1 that X 7 = E[ZI$7 ]. This completes the proof. 
23.17. 
Let Yn = E[XMI$n] for all n ~ 0. By Problem 23.16, {Yn XM} is a 
martingale. By the assumption that { Xn : n ~ 0} is a martingale, we have Yn = Xn 
for 0 :-:; n :-:; M. Since T :-:; M a.s., {X7 , XM} is a martingale. This completes the 
proof. 
23.18. Let 

318 
STOPPING TIMES 
Then A = U%"=1 Ak. where 
By Definition 14.1 and the assumption that {Xn : n 2: 0} is a submartingale, we 
have 
which implies that P(Ak) = 0. Since Ak t A ask -t oo, it follows from Problem 
11.6 that P(A) = 0. Hence 
This completes the proof. 
23.19. Let 
71 = inf{t: Xt =A}, 
72 = inf{t: Xt = -B}. 
Then 7 = 71 A72 and {XT =A}= {71 < 72}. By Theorem 23.1, we have 
E[XT] = E(E[XTig-o]) = E[Xo] = 0. 
But by Problem 14.18, we have 
E[XTI71 < 72]P{71 < 72} + E[XTI71 < 72]P{71 > 72} 
AP{XT =A}- B(l- P{XT =A}). 
Combining the above two equations gives 
This completes the proof. 
B 
P{XT =A}=--. 
A+B 

BIBLIOGRAPHIC NOTES 
319 
23.5 Bibliographic Notes 
In this chapter, we introduced the concept of stopping times and relevant results. The 
proofs of Theorems 23.1 and 23.2 can be found in Bhattacharya and Waymire (2007) 
and Pascucci (2011). Jeanblanc et al. (2009) studied hitting times for Brownian 
motions. For more properties of stopping times, readers are referred to Williams 
(1991) and Gut (2007). 


CHAPTER 24 
MARTINGALE INEQUALITIES 
Martingale inequalities are important in the study of stochastic differential equa-
tions. For example, martingale inequalities are used to establish bounds of solutions 
to stochastic differential equations. In this chapter, we present several important 
martingale inequalities. 
24.1 
Basic Concepts and Facts 
Theorem 24.1 (Doob's Submartingale Inequality). Let {yt 
a ::; t < b} be a 
right-continuous submartingale. Then for any E > 0, we have 
where yb+ = max(Yb, 0). In particular, if the yt is a right-continuous martingale, 
then for any E > 0, we have 
(24.2) 
Measure, Probability, and Mathematical Finance. 
321 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

322 
MARTINGALE INEQUALITIES 
24.2 Problems 
24.1. Let {Xi : i = 0, 1, 0 
0 
0 
, n} be a submartingale adapted to a filtration { ~i : i = 
0, 1, 0 
0 
0, n }o Show that for every>. > 0, we have 
P{Mn > >.}::; ~ 1 
XndP::; ~E[X;t] ::; ~E[IXnl], 
{Mn>>.} 
where Mn =max{ Xi: i = 0, 1, 0 
0 
0, n}o 
24.2 (Doob's Maximal Inequality). Let {Xi : i = 1, 2, 0 
0 
0, n} be a martingale or 
nonnegative submartingale adapted to the filtration { ~i : i = 1, 2, 0 
0 
0, n }o Suppose 
that E [IXniP] < oo for some p 2: 1. For all>.> 0, show that 
P{Mn 2: >.}::; ,1 1 
IXniPdP::; ,1 E [IXniPJ, 
/\p 
{Mn2:A} 
/\p 
where 
Mn = max{IX1I, IX2I, o o o, IXnl}o 
24.3. Let {Xi : i = 1, 2, 0 
0 
0, n} be a martingale adapted to the filtration { ~i : i = 
1, 2, 0 
0 
0, n}o Suppose that E [X~] < ooo Show that 
E [M~] ::; 4E [X~], 
where 
Mn = max{IX1I, IX2I, o o o, IXnl}o 
24.4. Let { Xt : 0 ::; t ::; b} be a nonnegative right-continuous submartingale 
adapted to the filtration { ~t : 0 ::; t ::; b} 0 Suppose that E [Xb'J < oo for some 
p 2: 1. For all >. > 0, show that 
P{Mb > >.}::; ,1 1 
Xb'dP::; ,1 E [Xb'], 
/\P 
{Mb>>.} 
/\P 
where 
Mb = sup{Xt: 0::; t::; b}o 
24.5. Let { Xt : 0 ::; t ::; b} be a nonnegative right-continuous submartingale 
adapted to the filtration { ~t : 0 ::; t ::; b} 0 Suppose that E [ Xb'J < oo for some 
p 2: 1. Show that 
where 
Mb = sup{Xt: 0::; t::; b}o 
24.6. Let { Xt : 0 ::; t ::; b} be a right-continuous martingale or a nonnegative right-
continuous submartingale adapted to the filtration { ~t : 0 ::; t ::; b} 0 For every 
o: > 1, show that 

HINTS 
323 
24.7. Let {X 1, X 2, ... , X m} be a submartingale on some probability space ( 0, Â§, 
P), and let>. 2: 0. Let A be a set defined as 
Show that 
>.P(A) ::; i XmdP ::; E(X~). 
24.8. Let {Xn: n 2: 1} be a submartingale on the probability space (0, Â§, P) and 
>. 2: 0. Show that 
>.P {supXn > >-}::; supE(X;{). 
n2:1 
n2:1 
24.9. Let { Xn : n 2: 1} be a supermartingale on the probability space (0, Â§, P) 
and >. 2: 0. Show that 
>.P {sup Xn > >-} ::; E(XI) +sup E(X;;). 
n2:1 
n2:1 
24.10 (Ward's Theorem). Let {Yn : n 2: 1} be a sequence of independent and 
identically distributed random variables on the probability space (0, Â§, P), with 
finite mean m. Let Xn = 2::7=1 Yi, n = 1, 2, ... and T be a stopping time for 
{Xn: n 2: 1}. Show that 
(a) If Yn 2: 0, n = 1, 2, ... , then E(Xr) = mE(T); 
(b) If E(T) < oo, then E(IXrl) < oo and E(Xr) = mE(T). 
24.11. Let { Xt : 0 ::; t ::; b} be a right-continuous supermartingale adapted to the 
filtration { Â§t : 0 ::; t ::; b}. Let >. > 0. Show that 
p { su 
X > >-} < E[Xo] + E[Xb] 
p 
t-
-
\ 
' 
O.,;t~b 
A 
where Xb =max{ -Xb, 0}. 
24.3 Hints 
24.1. Consider T = min{k: Xk >>.},and use the result of Problem 23.18. 
24.2. To prove this inequality, one can construct a partition of the event { Mn 2: >.}. 
Forexample,letA1 = {IX1I2': >.},A2 = {IX1I < >.,IX2I2': >.},andsoforth. 
24.3. UsetheresultsofProblems 13.10, 13.1l,and24.2. 

324 
MARTINGALE INEQUALITIES 
24.4. Consider the discrete submartingales 
{xi : 
i = o, 2: , ~~, ... , b} 
as n-+ oo and use Doob's maximal inequality (see Problem 24.2). 
24.5. The proof is similar to that of Problem 24.3, applying the results of Problems 
13.10, 13.11, and 24.4. 
24.6. The proof is similar to that of Problem 24.5, but using the results of Problems 
13.12 and 13.11, and Holder's inequality (Theorem 8.1). 
24.7. Consider the stopping time T defined as 
T = {inf{k: SUpl:'Oi:'Ok Xi~ A}, 
if {k: SUpl:Si:Sk Xi~ A} -:f. 0; 
m, 
if otherwise, 
and apply the optimal stopping theorem (Theorem 23.1). 
24.8. Use the results of Problem 24.7 and Theorem 2.1. 
24.9. First use Theorem 23.1 to prove that for every integer m ~ 1, we have 
>.P { max Xk > >-} :<::; E(XI) + E(X;;,). 
l:Sk:Sm 
Then apply Theorem 2.1. 
24.10. To prove part (a), consider the stopping timeT 1\ nand apply Theorems 23.1 
and 6.2. Use part (a) to prove part (b). 
24.11. Consider the stopping time 
7 = {inf{t: SUPo::;s::;tXs ~A}, if {t: SUPo::;s::;tXs ~A} -:f. 0; 
b, 
otherwise, 
and use the optimal stopping theorem (Theorem 23.1). 
24.4 Solutions 
24.1. Let 
T = {min{k: Xk >A}, if {k: Xk >A} -:f. 0; 
n, 
otherwise. 

SOLUTIONS 
325 
Then T is a bounded stopping time. It follows from Problem 23.18 that X,. < 
E[Xnl$r] a.s. Since {Mn >.A}= {Xr >.A}, we have 
.AP{Mn >.A} 
.AP{Xr >.A} 
< 
{ 
XrdP 
j{X.,.>>.} 
< 
{ 
E[Xnl$r]dP 
j{X.,.>>.} 
n L { 
E[Xn l$r ]dP 
k=O J{X.,.>>.}n{r=k} 
n 
L 
{ 
XndP 
k=O J{X.,.>>.}n{r=k} 
{ 
XndP. 
j{X.,.>>.} 
In addition, we have 
{ 
XndP:::; { 
x;;dP:::; E[X;;]:::; E[IXnl]. 
j{X.,.>>.} 
j{X.,.>>.} 
This completes the proof. 
24.2. Let At = {IXtl ~ .A} and Ak = {IXtl < .A, ... , IXk-tl < .A, IXkl ~ .A} 
fork= 2, 3, ... , n. Then Ak E $k fork= 1, 2, ... , nand {At, A2, ... , An} is a 
partition of {Mn ~.A}. Hence we have 
n 
P{Mn ~.A}= LP(Ak)Â· 
(24.3) 
k=t 
Note that 
P(Ak) = { 1dP :::; { 
~~~~PdP, 
k = 1, 2, ... , n. 
(24.4) 
}Ak 
}Ak 
Note that lxiP is a convex function for p ~ 1. By Problem 15.7 and the assumption 
that {X k : k = 1, 2, ... , k} is a martingale or nonnegative submartingale, we have 
(24.5) 
By the definition of conditional expectation (Definition 14.1), we have 

326 
MARTINGALE INEQUALITIES 
Combining Equations (24.3), (24.4), (24.5), and (24.6) proves the inequality. This 
completes the proof. 
24.3. By Problem 13.10, we have 
E [M~] = 1
00 P{M~ > s}ds = 21
00 >.P{Mn > >.}d>.. 
Then by Doob's maximal inequality (see Problem 24.2) and Problem 13.11, we get 
E [M~] < 
2 roo r 
IXnldPd).. 
Jo lu-vr, ;:>.\} 
21oo E [IXnii{Atn::>.x}] d>. 
2E[IXniMn]Â· 
Now by Schwarz's inequality (Theorem 8.3), we get 
Combining the above equations gives 
This completes the proof. 
24.4. For each n _::::: 1, let 
Mn =max {xi : 
i = 0, .!_b, 2_b .... , b} . 
2n 
2n , 
Let ).. > 0. We claim that { Mn > ).. } t { Mb > ).. } as n -+ oo. In fact, since 
{Mn > >.} c:;; {Mn+l >>.},we have 
lim {Mn > >.} = U {Mn > >.} c:;; {Mb > >.}. 
n------+CXJ 
n--+oo 
To prove the claim, we only need to show that 
n--+cx:;. 
To do that, let wE {Mb >>.}.Then there exists as E [0, b] such that X,,(w) > >.. 
Since X is right-continuous, there exist K and N such that 
which gives that 
wE {MN > >.} c:;; u {Mn > >.}. 
n--+oo 

SOLUTIONS 
327 
Since w is arbitrary, the claim is valid. 
Now note that for each n, {Xi : i = 0, 2~ b, 2:_ b, ... , b} is a nonnegative sub-
martingale. By Problem 24.2, we have 
P{Mn > >.}:::; ,1 { 
XbdP:::; ,1 E[Xb], n:::: 1. 
/\p }{Mn>>.} 
/\p 
The result follows by letting n ---+ oo. This completes the proof. 
24.5. By Problem 13.10, we have 
By Problem 24.4 and Problem 13.11, we have 
E [M~) < 2 r= { 
XbdPd>. 
lo 
J{Mb?_>.} 
21= E [Xbl{Mb?_>.}) d>. 
2E[XbMb]Â· 
Now by Schwarz's inequality (Theorem 8.3), we get 
Combining the above equations gives 
This completes the proof. 
24.6. Let Mb = SUPo::;t::;b IXtlÂ· By Problem 13.12, we have 
E[Mb'] 
E[(M~-l)a~l] 
r= _a_>.a~lP{M~-l:::: >.}d>.. 
} 0 
a -1 
Since IXtl is a nonnegative submartingale, it follows from Problem 24.4 that for 
>. > 0, we have 
p { M~- 1 :::: >.} 
p { Mb :::: >. a~l } 
< r a~l r 
IXbldP. 
j { Mt:-1 ?_>.} 

328 
MARTINGALE INEQUALITIES 
By Problem 13.11 and Theorem 8.1, we have 
E[Mb'] < 
< 
< 
which gives 
1 
a 
1 
E [Mb'P' :::; a -1 E [IXblap;. 
The result follows immediately by taking powers of a on both sides of the above 
inequality. This completes the proof. 
24.7. Let T be defined as 
T = {inf{k: SUPl::;i:<:::kXi 2': .X}, 
if {k: SUPl::;i:<:::kXi 2': .X}=/:- 0; 
m, 
if otherwise. 
Then Tis a stopping time with respect to the underlying filtration { Â§'i : 1 :::; i :::; m}. 
By Theorem 23.1, we have 
Since T = m on the event A c, we have 
which gives 
>.P(A):::; i XmdP:::; i X;t;dP:::; E[X;t;]. 
This completes the proof. 
24.8. By Problem 24.7, for every m 2': 1, we have 
>.P { max Xk 2': .x} :::; E[X;t;]:::; supE[X;t]. 
l::;k::;m 
n:::O::l 
Since 
{ max Xk 2': .x} t {supXn 2': .x} 
as m---+ oo, 
l::;k::;m 
n:::O::l 
it follows from Theorem 2.1 that 
P { max Xk 2': .x} t P {supXn 2': .x} 
as m---+ oo. 
l:=;k:::;m 
n:::O::l 

SOLUTIONS 
329 
Hence we have 
>.P {sup Xn > >.} $_ >.P {sup Xn 2:: )..} $_ sup E(X;;). 
n2':1 
n2':1 
n2':1 
This finishes the proof. 
24.9. Let m be a positive integer. We claim that 
>.P { max Xk > >.} $_ E(XI) + E(X;;,). 
l:<:;k:<:;m 
To prove this claim, let T be defined as 
T = {inf{k: SUPl:<:;i:<:;k Xi 2:: A}, 
if {k: SUPl:<:;i:<:;k Xi 2:: A}=/:- 0; 
m, 
if otherwise. 
(24.7) 
Then T is a stopping time with respect to the underlying filtration { g;i : 1 $_ i $_ m}. 
By Theorem 23.1, we have 
Let A= {max1<k<m Xk 2:: >.}.Then T = m on the event Ac. Hence we have 
which gives 
E[X1] 2:: >.P(A)- { X;;,dP 2:: >.P { max Xk > >.}- E[X;;,]. 
}Ac 
l:<=;k:<=;m 
Hence Equation (24.7) holds. Thus we have 
>.P { max Xk > >.} $_ E(XI) + E(X;;,) $_ E(XI) +sup E[X,:;-]. 
l:<:;k:<:;m 
n2':1 
The result follows immediately from Theorem 2.1 by letting m --+ oo. This com-
pletes the proof. 
24.10. 
(a) Let Zn = Xn- nm. Then {Zn : n 2:: 1} is a martingale. By Problem 23.1, 
TAn is a stopping time and is bounded. Then by Theorem 23.1, we have 
which gives 
E[XTAn] = mE[T An]. 

330 
MARTINGALE INEQUALITIES 
Since Yj ~ 0 for all j ~ 1 and Tis finite, we have Xr/\n t Xr and T 1\ n t T 
as n ---+ oo. Hence it follows from Theorem 6.2 that 
E[Xr] = mE[T]. 
(b) Let 
n 
n 
x(l) = "y+ 
X(2) = "y-
n ~ 1. 
n 
~J' 
n 
~J' 
j=l 
j=l 
Let Z~l) = X~l) - nm1 and Z~2 ) = X~2 ) - nm2, where m1 = E[Y1+] and 
m2 = E[Y1-]. Then by part (a) ofthis problem, we have 
E[X~1 )] = m1E[T] and E[XflJ = m1E[T]. 
By the assumption that E[T] < oo, we have 
E[IXrl] = E[X~1 l] + E[x,fl] < oo 
and 
This completes the proof. 
24.11. Let T be defined as 
T = {inf{ t : SUPo::;s::;t X 8 ~ A}, 
if { t : SUPo::;s::;t Xs ~ A} -=/=- 0; 
b, 
otherwise, 
Then T is a stopping time with respect to the filtration { Â§t : 0 :::; t :::; b}. Since 
{ Xt : 0 :::; t :::; b} is a right-continuous supermartingale, by Theorem 23.1 we have 
where 
E[Xo] > E[E[XT lÂ§o]J 
E[XT] 
r xTdP + r xTdP, 
}A 
}Ac 
A = { sup Xt ~ A} . 
o::;t::;b 
(24.8) 
Note that XT ~ A on event A and that T = bon event Ac. Hence from Equation 
(24.8), we have 
E[Xo] > 1 
AdP+ 1 XbdP 
A 
Ac 
> AP(A) -1 Xi;dP 
Ac 
> AP(A) - E[Xi;], 

BIBLIOGRAPHIC NOTES 
331 
which gives 
P(A) ::; E[Xo] : E[XbJ. 
This completes the proof. 
24.5 Bibliographic Notes 
In this chapter, we introduced some inequalities for martingales. Doob's submartin-
gale inequality has two versions: a discrete version (see Problem 24.2) and a con-
tinuous version (see Theorem 24.1). The continuous version can be proved by the 
discrete version. For such a proof, readers are referred to Bhattacharya and Waymire 
(2007, p41). More information about martingale inequalities can be found in Brzez-
niak and Zastawniak (1999), Chung (2000), Chung and Lu (2006), and Gut (2007). 


CHAPTER 25 
MARTINGALE CONVERGENCE 
THEOREMS 
Martingale convergence theorems state that under certain conditions, a martingale, 
submartingale, or supermartingale converges to a limiting random variable. In this 
chapter, we shall present several martingale convergence theorems. 
25.1 
Basic Concepts and Facts 
Definition 25.1 (Crossing of Real Numbers). Let { Xn : n ~ 0} be a sequence of real 
numbers. Let a < b be real numbers. The sequence { T n (a, b) : n ~ 0} of crossings 
with respect to the sequence { Xn : n ~ 0} is defined by 
To(a, b)= 0, 
(25.la) 
and for every n ~ 1, we have 
( b) _ {minA2n-1, 
72n-l a, 
-
oo, 
( 
b) _ {minA2n, 
T2n a, 
-
oo, 
if A2n-l -1- 0; 
otherwise, 
if A2n -1- 0; 
otherwise, 
(25.lb) 
(25.lc) 
Measure, Probability, and Mathematical Finance. 
333 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

334 
MARTINGALE CONVERGENCE THEOREMS 
where A2n-I = {k 2: T2n-2: Xk:::; a} and A2n = {k 2: T2n-I : Xk 2: b}. 
Definition 25.2 (Crossing of Random Variables). Let {Xn : n 2: 0} be a sequence of 
real random variables. Let a < b be real numbers. The sequence { T n (a, b) : n 2: 0} 
of crossings with respect to the sequence {Xn : n 2: 0} is defined as follows. For 
every w E 0, { T n (a, b) ( w) : n 2: 0} is the sequence of crossings with respect to the 
sequence {Xn(w) : n 2: 0}. 
Definition 25.3 (Â§00 ). Let {Â§n: n 2: 0} be a filtration. Then Â§
00 is the a-algebra 
generated by U~=O Â§n: 
Theorem 25.1 (Submartingale Convergence Theorem). Let {Xn}n;::::I be a sub-
martingale with respect to the filtration {Â§n: n 2: 1}. If 
supE(X;t) < oo, 
n 
then there exists an integrable random variable Xoo such that 
X 
a.s. X 
n ----+ 
ooÂ· 
25.2 Problems 
25.1. Let { Xn : n 2: 0} be a sequence of real numbers. Show that { Xn : n 2: 0} 
converges if and only if 
v(a,b) = max{k: T2k(a,b) < oo} < oo 
for all a, bE Q, a< b, where Tn(a, b) is as defined in Definition 25.1. 
25.2. Let { Xn : n 2: 0} be a sequence of real random variables. Show that { Xn : 
n 2: 0} converges almost surely if and only if 
v(a,b) = max{k: T2k(a,b) < oo} < oo, 
a.s. 
for all a, b E Q, a < b. 
25.3 (Upcrossing Theorem). Let {XI, X 2, ... , Xn} be a martingale with respect to 
the filtration {Â§I, Â§2, ... , Â§n}Â· Let a, b E R such that a < b. Let Uab be the 
number ofupcrossings by XI, x2, ... 'Xn, defined as follows. 
Let TI = TI (w) be the first integer in {1, 2, ... , n} such that Xr, :::; a. Let T2 be 
the first integer greater than TI such that Xr2 2: b. Let T3 be the first integer greater 
than T2 such that Xr2 
:::; a, and so on. If no such integer exists for Tk, then Tk = oo: 
l
min{i: i E Ak} 
T, ~ :in{i' i E B,) 
if k is odd and IAkl > 0; 
if k is even and IAkl > 0; 
if Ak is empty, 
k = 1,2, ... , 

PROBLEMS 
335 
where Ak = {i: Tk-l < i::::; nand Xi::::; a}, Bk = {i: Tk-l < i::::; nand Xi 2:: 
b}, and To= 0. Then define 
Uab = {~ 
N-l 
-2-
if N is even; 
if N is odd, 
where N is the number of finite Tk. Show that 
25.4. Let Y be an integrable random variable on some probability space (r2, Â§, 
P). Let Â§i, i E J, be arbitrary sub-u-fields ofÂ§. Show that the random variables 
xi = E(YIÂ§i), i E J, are uniformly integrable: 
lim sup r 
IXildP = 0. 
c--+oo iEI } {IX, I ?_c} 
25.5. Let Y be an integrable random variable on some probability space (r2, Â§, P). 
Let { Â§n}n>l be an increasing sequence of sub-u-fields ofÂ§. Let Xn = E(YIÂ§n), 
n = 1, 2, .... Show that 
and 
L' 
Xn -----+ E(YIÂ§oo), 
where Â§ 00 is as defined in Definition 25.3. 
25.6. Let {X n : n = 1, 2, ... , oo} be a nonnegative submartingale with respect to 
the filtration { Â§ n : n = 1, 2, ... , oo}, where X 00 is a last element. Show that the 
Xn are uniformly integrable. 
25.7. Let {Xn : n 2:: 0} be a martingale adapted to a filtration {Â§n : n;::: 0}. Let 
Â§00 = u~=O Â§nÂ· Show that the following are equivalent: 
(a) {Xn : n 2:: 0} is uniformly integrable. 
(b) Xn converges in L 1 . 
(c) Xn ~ 
X 00 as n---+ oo and {Xn : n = 0, 1, ... , oo} is a martingale adapted 
to { Â§n : n = 0, 1, ... , oo }, where Xoo is some integrable random variable. 
(d) There exists an integrable random variable Y such that Xn = E[YIÂ§n] for all 
n 2:: 0. 
25.8. Let {X n : n 2:: 0} be a submartingale adapted to a filtration { Â§ n : n ;::: 0}. 
Let Â§oo = U~=O Â§nÂ· Show that the following are equivalent: 
(a) {Xn: n 2:: 0} is uniformly integrable. 

336 
MARTINGALE CONVERGENCE THEOREMS 
(b) Xn converges in L 1 . 
(c) Xn ~X= 
as n--+ oo and {Xn : n = 0, 1, ... ,oo} is a submartingale 
adapted to {Â§n : n = 0, 1, ... , oo }, where X= is some integrable random 
variable. 
25.3 Hints 
25.1. Use the definition of convergences (Definition 1.1 0). 
25.2. Use the result of Problems 25 .I and ll.l. 
25.3. Use the optional skipping theorem (see Problem 22.9) and the result of Prob-
lem 22.7. First consider the case when a = 0 and Xk ~ 0. Then consider the case 
(Xk- a)+. 
25.4. 
Use Chebyshev's inequality (see Problem 6.16) and the tower property of 
conditional expectations (see Problem 14.1 0). 
25.5. Use the results of Problems 22.6 and 25.4, and the submartingale convergence 
theorem (Theorem 25.1 ). 
25.6. Use the result of Problem 9.11. 
25.7. To prove (a) ===? (b), use Theorem 25.1 and the results of Problems 9.11, 
9.4, 9.2, and 9.12. To prove (b) ===? (c), use the result of Problem 9.14. To prove 
(c) ===? (d), consider Y = X=. To prove (d) ===? (a), use the result of Problem 
25.4. 
25.8. Theproofof(a) ===?(b)===? (c)isthesameasthatofProblem25.7. The 
proof of (c) ===? (a) is similar to that of Problem 25.4. 
25.4 Solutions 
25.1. Let use first prove the necessity ("only if") part. Suppose that 
v(a,b) = max{k: T2k(a,b) < oc} < oo 
for all a, b E Q, a < b. We claim that 
liminfxn = limsupxnÂ· 
(25.2) 
If lim inf Xn -1- lim sup Xn, there exist rational numbers a and b such that 
liminfxn <a< b < limsupxrz, 

SOLUTIONS 
337 
which implies that v( a, b) = oo. This contradicts our hypothesis. Hence Equation 
(25.2) must hold. By Definition 1.10, { Xn : n :::: 0} converges. 
Now let us prove the sufficiency. Suppose that {xn: n:::: 0} converges. Then by 
Definition 1.10, Equation (25.2) holds. We claim that 
v(a, b)= max{k: T2k(a, b)< oo} < oo 
(25.3) 
for all a, bE Q, a< b. If v(a, b) = oo for some a, bE Q, a< b, then we must have 
infinitely many x's below a and infinitely many x's above b. Hence we have 
lim inf Xn :':: a < b :':: lim sup Xn, 
which implies that { Xn : n :::: 0} does not converge. This contradicts our hypothesis. 
Hence Equation (25.3) must hold. This completes the proof. 
25.2. For a given w E 0, it follows from Problem 25 .I that {X n ( w) : n :::: 0} if and 
only if 
v(a, b)(w) = max{k: T2k(a, b)(w) < oo} < oo 
for all a, b E Q, a < b. Hence we have 
{wE 0: {Xn(w): n:::: 0} converges}= n {v(a,b)<oo}. 
a,bEQ,a<b 
If P{w E 0: {Xn(w) : n:::: 0} = 1, then we have 
p ( n {v(a,b) < oo}) = 1, 
a,bEQ,a<b 
which implies that P{v(a, b) < oo} = 1 for all a, bE Q, a< b. 
If P { v( a, b) < oo} = 1 for all a, b E Q, a < b, then it follows from Problem 
11.1 that 
p( n {v(a,b)<oo})=1, 
a,bEQ,a<b 
which gives 
P{w E 0: {Xn(w): n:::: 0} = 1. 
This completes the proof. 
25.3. First, assume that a= 0 and Xk :::: 0 fork :::: 1. Then the resulting inequality 
becomes 
Let Mk be defined as 
{
0 ifT2j-2::; k < T2j-l forsomej:::: 1; 
Mk= 
1 if T21 _ 1 ::; k < T21 for some j :::: 1, 
(25.4) 
k = 1, 2, ... , n- 1. 

338 
MARTINGALE CONVERGENCE THEOREMS 
Then let Yn be defined as 
k-1 
Yk = X1 + LMj(XJ+l- Xj), 
k = 1,2, ... ,n. 
j=l 
By Problem 22.9, we have 
But 
(25.5) 
if N is even; 
if N is odd. 
Noting that X 1 2': 0, we have Yn 2': bU0b, which gives 
(25.6) 
Combining inequalities (25.5) and (25.6) gives (25.4). 
Now we consider the general case. By Problem 22.7, (Xk -a)+ is a submartin-
gale. Since Xk upcrossing (a, b) is equivalent to (Xk- a)+ upcrossing (0, b- a), 
applying the above result proves the problem. This completes the proof. 
25.4. 
Let E > 0. Note that IYII{IYI<n} t IYI as n -t oo. By the monotone 
convergence theorem (Theorem 6.2), we have 
r IYII{IYI<n}dP = r 
IYidP t r IYidP as 
n -t 00. 
Jn 
.J{IYI<n} 
./n 
Therefore there exists an integer N such that 
r 
IYidP = r IYidP- r 
IYidP < ~. 
j{jYj?:_N} 
Jn 
j{jYj<N} 
2 
By the conditional Jensen's inequality (see Problem 15.7), we have 
Hence we have 
r 
E(IYIIY';)dP 
.J{jX;j?:_c} 
r 
IYidP 
}{]Xi]?:_c} 
r 
IYidP + r 
IYidP 
J{jX,j?:_c}n{jYj?:_N} 
J{jX;j?:_c}n{jYj<N} 
E 
:2 + N P{IX;I;:::: c}. 
< 

SOLUTIONS 
339 
By Problem 6.16, we have 
P{IXil ~ c}:::; E(IXil) :::; E[E(IYII~i)] = E(IYI) 
c 
c 
c 
If we choose c > 2N E(IYI) / E, we have 
sup { 
IXildP < E. 
iEI j{IX;I"?.c} 
Since E is arbitrary, the conclusion follows. This completes the proof. 
25.5. 
By Problem 22.6, {Xn} is a martingale. By Problem 25.4, the Xn are 
uniformly integrable. By the assumption that Y is integrable and Problem 14.10, we 
have 
Hence, by Theorem 25.1, there exists an integrable random variable Xco such that 
X 
a.e. X 
n -----+ 
coÂ· 
Note that the probability measure Pis finite. By Egoroff's theorem (see Problem 
9.4), Xn converges to Xco almost uniformly. By Problem 9.2, Xn .!!:..t Xco. By 
Ll 
Problem 9.12, Xn-+ Xco. 
Now we show that Xco is a version of E(YI~co)Â· Since Xco is integrable, we 
have E(IXcol) < oo. Since Xn is ~co-measurable, Xco is also ~co-measurable. 
Let A E ~coÂ· Then 
IL YdP-i XcodPI 
IL E(YI~n)dP-i XcodPI 
< i IXn- XcoldP. 
Ll 
Since Xn -+ X co, we have 
By definition of conditional expectation, we have Xco = E(YI~co) a.e. This com-
pletes the proof. 
25.6. By the definition of conditional expectation and the hypothesis, we have 

340 
MARTINGALE CONVERGENCE THEOREMS 
By Chebyshev's inequality (see Problem 6.16), we have 
P{Xn?:: c}:::; E(Xn) :::; E(Xoo). 
c 
c 
Hence P {X n ?:: c} -+ 0 as c -+ oo. Therefore, the integral of X n is uniformly 
bounded and uniformly continuous. By Problem 9.11, the Xn are uniformly inte-
grable. 
25.7. First, let us prove (a) ===?- (b). Suppose that {Xn : n?:: 0} is uniformly inte-
grable. Then it follows from Problem 9.11 that the E[IXnl] are uniformly bounded, 
specifically, 
supE[IXnl]:::; M 
n 
for some constant M < oo. Hence we have 
sup E[X;t] < oo. 
n 
By Theorem 25.1, there exists an integrable random variable X 00 such that X n ~ 
L' 
X 00 as n-+ oo. Then it follows from Problems 9.4, 9.2, and 9.12 that Xn---+ Xoo 
as n-+ oo. 
L' 
Next, let us prove (b) 
===?-
(c). Suppose that Xn ---+ Xoo as n -+ oo. Then 
it follows from Problem 9.14 that {Xn : n ?:: 0} is uniformly integrable. Then 
from the previous proof, there exists an integrable random variable X 00 such that 
Xn ~ 
Xoo as n -+ oo. Let m ?:: 0 and A E ,~m- Since {Xn : n ?:: 0} is a 
martingale, we have for very n ?:: m, 
By the hypothesis, we have 
{ XmdP = lim { XndP = { XoodP. 
j A 
n-+oo j A 
J 
A 
Since A is arbitrary, we get 
Hence { Xn : n = 0, 1, ... , oo} is a martingale. 
Next, let us prove (c) ===?- (d). In fact, this follows immediately if we let Y = 
Xoo. 
Finally, let us prove (d) ===?- (a). In fact, this follows immediately from Problem 
25.4. This completes the proof. 
25.8. First, let us prove (a) ===?- (b). Suppose that {Xn : n?:: 0} is uniformly inte-
grable. Then it follows from Problem 9.11 that the E[IXn I] are uniformly bounded, 
specifically, 
supE[IXnl]:::; M 
n 

SOLUTIONS 
341 
for some constant M < oo. Hence we have 
sup E[X;t] < oo. 
n 
By Theorem 25.1, there exists an integrable random variable X oo such that X n ~ 
L' 
X 00 as n---+ oo. Then it follows from Problems 9.4, 9.2, and 9.12 that Xn -----+ X 00 
as n---+ oo. 
L' 
Next, let us prove (b) 
===? (c). Suppose that Xn -----+ Xoo as n ---+ oo. Then 
it follows from Problem 9.14 that {Xn : n 2': 0} is uniformly integrable. Then 
from the previous proof, there exists an integrable random variable Xoo such that 
Xn ~ 
X 00 as n ---+ oo. Let m 2': 0 and A E Â§mÂ· Since {Xn : n 2': 0} is a 
submartingale, we have for very n 2': m (see Problem 22.3), 
i XmdP ::; i XndP. 
By the hypothesis that Xn converges in L 1, we have 
{ XmdP ::; lim { XndP = { X 00dP. 
}A 
n-+oo}A 
}A 
Since A is arbitrary, we get 
E[XoolÂ§m] 2': Xm. 
Hence { Xn : n = 0, 1, ... , oo} is a submartingale. 
Finally, let us prove (c) ===? (a). To do that, let E > 0. Since IXooii{IXool<n} t 
IXoo I as n---+ oo, it follows from the monotone convergence theorem (Theorem 6.2) 
that 
r IXooii{IXool<n}dP = r 
IXooldP t r IXooldP as 
n---+ 00. 
Jo 
J{IXool<n} 
Jo 
Therefore there exists an integer N such that 
r 
IXooldP = r IXooldP- r 
IXooldP < ~. 
j{IXocci?.N} 
Jo 
j{IXooi<N} 
2 
By the hypothesis and the conditional Jensen's inequality (see Problem 15.7), we 
have IXil ::; IE(XoolÂ§i)l ::; E(IXoollÂ§i). Hence we have 
r 
1xi1dP 
j{IXil?.c} 
< 
{ 
E(IXoollÂ§i)dP 
j{IXil?.c} 
r 
IXooldP 
j{IXil?.c} 
r 
IXoo ldP + r 
IXoo ldP 
}{IXi l?.c}n{IXoo I?.N} 
}{IXi l?.c}n{IXoo I<N} 
E 
"2 + NP{IXil 2': c}. 
< 

342 
MARTINGALE CONVERGENCE THEOREMS 
By Problem 6.16, we have 
c 
If we choose c > 2NE(IXooi)/E, we have 
sup r 
IX; ldP < E. 
iEJ j{IX,I?_c} 
Since E is arbitrary, {Xn: n ~ 0} is uniformly integrable. This completes the proof. 
25.5 Bibliographic Notes 
In this chapter, we presented several convergence theorems for submartingales. The 
proof of Theorem 25.1 can be found in Ash and Doleans-Dade (1999) and Gut 
(2007). Lawler (2006) presented many examples of applying the martingale con-
vergence theorems. Hall and Heyde ( 1980) is a book devoted to martingale limit 
theory. 

CHAPTER26 
RANDOM WALKS 
A random walk is a simple discrete stochastic process formed by successive sum-
mation of independent and identically distributed random variables. Random walks 
are one of the most widely studied topics in probability theory and have important 
applications in finance. In this chapter, we present random walks and relevant results. 
26.1 
Basic Concepts and Facts 
Definition 26.1 (Random Walk). A random walk { Sn : n ~ 0} starting at x is a 
stochastic process defined as 
n 
Sn = X + L zi' 
So = x, 
i=l 
where X E Rand zi 's are independent and identically distributed random variables. 
Definition 26.2 (Simple Random Walk). Let { Sn : n ~ 0} be a random walk as 
defined in Definition 26.1. It is called a simple random walk if for every n ~ 1, 
P{Zn = 1} = p, 
P{Zn = -1} = q = 1- p, 
Measure, Probability, and Mathematical Finance. 
343 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

344 
RANDOM WALKS 
where p E (0, 1). 
26.2 Problems 
26.1. Let { Sn : n :::: 0} be a random walk as defined in Definition 26.1. Let J-L = 
E[Z1] and a= JE[(Z1 -
J-L) 2]. Suppose that IJ-LI < oo and a< oo. Show that 
(a) {Sn- J_Ln: n:::: 0} is a martingale. 
(b) {(Sn- J-Ln) 2 -
a 2n: n:::: 0} is a martingale. 
(c) For any u E R, { exp( uSn - n ln E[euz1 ]) : n :::: 0} is a martingale. 
(d) If P(Z1 = 1) = p and P(Z1 = -1) = 1- p for some p E (0, 1), then 
is a martingale. 
26.2 (Scaled Random Walk). Let { Zn}n~l be a sequence of independent and iden-
tically distributed symmetric Bernoulli random variables such that 
1 
P(Zn = 1) = P(Zn = -1) = 2' n:::: 1. 
Let Mo = 0 and Mn = Z 1 + Z2 + Â· Â· Â· + Zn for n :::: 1. For every n :::: 1, let 
nt - [nt] 
[nt] + 1 - nt 
Wn(t) = 
Vn 
M[nt]+l + 
Vn 
M[nt]' t:::: 0, 
where [x] denotes the largest integer that is less than or equal to x. Show that for 
every t :::: 0, the distribution of Wn(t) converges weakly to the normal distribution 
with mean zero and variance t. 
26.3. Let {Zn}n~l be a sequence of independent and identically distributed sym-
metric Bernoulli random variables such that 
1 
P(Zn = 1) = P(Zn = -1) = 2' n:::: 1. 
Let S0 = x and 
s~ =X+ zl + z2 + ... + Zn, 
n :::: 1, 
where xis an integer. Let N 1 and N2 be integers such that N 1 ::;; x ::;; N2 . LetT be 
defined as 
where 
TNl = inf{n:::: 0: s~ = NI}, 
TN2 = inf{n:::: 0: s~ = N2}Â· 

Show that 
(a) {S~ : n ~ 0} is a martingale. 
(b) TN1 and TN2 are a.s. finite stopping times. 
(c) Tis a stopping time and P{ T < oo} = 1. 
(d) s~l\n(n ~ 1) is uniformly integrable. 
(e) 
PROBLEMS 
345 
26.4. Let {S~ : n ~ 0} be a simple random walk starting at x (see Definition 26.2), 
where xis an integer. Let N1 and N2 be two integers such that N1 :::; x :::; N2. Let 
T'fvl = inf{n ~ 0: s~ = N!}, 
T'fv2 = inf{n ~ 0: s~ = N2}Â· 
For every integer x, let <p(x) be defined as 
<p(x) = P{T'fv2 < T'fvJ. 
Show that 
(a) For every integer x in [N1 + 1, N2 - 1], 
(b) If p =1- q, then 
(c) If p = q, then 
<p(x) = p<p(x + 1) + q<p(x- 1); 
x-N1 
<p(x) = N 
N . 
2-
1 
26.5. Let { Zn}n>l be a sequence of identically and independently distributed ran-
dom variables such that 
P(Zn = 1) = p, 
P(Zn = -1) = 1- p, 
n ~ 1, 
where p E (0, ~ ). Let 50 = 0 and 
Sn = Z1 + Z2 + Â· Â· Â· + Zn, 
n ~ 1. 
Show that 
(a) For y ~ 0, we have 
P {supSn > y}:::; (-p )Y 
n~O 
1- p 

346 
RANDOM WALKS 
(b) 
E 
supSn 
~ --. 
( 
) 
1-p 
n;:,o 
1- 2p 
26.6. Let zl' z2' ... 'z N be independent and identically distributed symmetric ran-
dom variables such that 
1 
P(Z1 = 1) = P(Zi = -1) = 2, 1 ~ j ~ N. 
Let SJ = Z 1 + Z2 + Â· Â· Â· + Zi for j = 1, 2, ... , N. Let m be a positive integer. Show 
that 
P { max SJ ::> m} = 2P{SN ::> m}- P{SN = m}. 
l"5cj"5cN 
26.7. Let { Zn}n>l be a sequence of independent and identically distributed sym-
metric Bernoulli random variables such that 
P(Zn = 1) = P(Z., = -1) = ~' 
n ::> 1. 
Let lVlo = 0 and 1V1n = Z1 + Z2 + Â· Â· Â· + Zn for n :2> 1. For every n :2> 1, let 
_ 
( 
(J 
) 1([nt]+M[nt[) ( 
(J 
) 1([nt]-M[ntJ) 
Sn(t)-
1 + y7i 
1- y7i 
t :;,. 0, 
where [x] denotes the largest integer that is less than or equal to .T. Show that for 
every t ::> 0, the distribution of Sn ( t) converges weakly to the distribution of 
where B(t) is a normal random variable with mean zero and variance t. 
26.3 
Hints 
26.1. Consider the filtration given by 
ffo = {0,0}, 
ffn = a(Zk: k = 1,2, ... ,n), 
n :2> 1 
and follow the definition of martingales (Definition 22.1). 
26.2. Apply the classical central limit theorem (see Problem 20.4) and use the result 
of Problem 20.2. 
26.3. 
Part (a) can be proved by the definition of martingales. To prove part (b), 
we follow the definition of stopping times. To prove that the stopping times are a.s. 
finite, we can establish the following inequality, where n 0 = N 2 -
N 1 : 
( 
1 ) k 
1--
2no 
' 

SOLUTIONS 
347 
Part (c) is implied by part (b) (see Problem 23.1). To prove (d), we follow the defini-
tion of uniform integrability (Definition 9 .6) and part (c). Part (e) can be proved by 
the result of Problem 23.15. 
26.4. To prove part (a), consider different values of Z 1 and use the result of Problem 
14.18. To prove parts (b) and (c), consider cp(Nl) and cp(N2) and use part (a). 
26.5. 
Apply Doob's maximal inequality to {(q/p) 8 n 
: n ~ 0} to prove part (a). 
Use the result of Problem 13.10 to prove part (b). 
26.6. Note that 
{ max Sj ~ m} = {SN ~ m} U (D
1 Aj n {SN < m}), 
1<j<N 
--
j=1 
where Aj = {81 < m, 8 2 < m, ... , Sj-1 < m, Sj = m} for j = 1, 2, ... , N. 
26.7. 
Consider lnSn(t) and use the classical central limit theorem (see Problem 
20.4) and the result of Problem 20.2. 
26.4 Solutions 
26.1. Let Â§'o = {0, !l} and Â§'n = a(Zk : k = 1, 2, ... , n) for n ~ 1. 
(a) By Schwarz's inequality (Theorem 8.3), we have 
E[ISn - J.tnl] ~ lxl + niJ.LI + nE[IZ1 - J.LI] ~ lxl + na < oo. 
Hence Sn- nJ.L is integrable. By Problem 14.4, we have 
Bn-1 + E[Zn - J.LIÂ§'n-1] 
= Bn-1 + E[Zn -
J.L] 
= 
Bn-1Â· 
Hence { Sn - J.Ln : n ~ 0} is a martingale. 
(b) By Problem 15.6, we have 
E [J(Sn- J.Ln) 2 - a 2nJ] ~ na2 +n2E [(Z1 - J.L) 2] = (n+n 2)a2 < oo, 
which shows that (Sn- J.Ln) 2 - a 2n is integrable. In addition, by Problem 14.4 
we have 
E[(Sn- J.Ln) 2 - a 2nlÂ§'n-1] 
(Sn-1- (n- 1)J.L)2 - na2 + E[2(Zn- J.L)(Sn-1- (n- 1)J.L) 
+(Zn- J.L?IÂ§'n-1] 
(Sn-1 - (n- l)J.L)2 - na2 + 2(Sn-l - (n- l)J.L)E[(Zn - J.L)] 
+E[(Zn- J.L) 2] 
(Sn-1- (n- l)J.L) 2 - (n- l)a2 . 

348 
RANDOM WALKS 
Hence { (Sn- ;m) 2 -
(J 2n: n;::: 0} is a martingale. 
(c) If E[euz,] = oo, then exp(uSn- nlnE[euz,]) = 0. It is a martingale. We 
assume that E[euz,] < oo. Since 
exp( uSn - n ln E[euz,]) = (E[euz, ])-n exp( uSn) 
and Zn 's are independent, by Theorem 13.2 we have, 
E[exp(uSn- nlnE[euz'])] 
n 
i=l 
Also we have 
(E[euz,]) -n E[exp( uSn) lÂ»'n-1] 
( E[euZ,]) -neuSn-1 E[exp( uZn)] 
(E[euz, ])-n+leus,_,. 
Hence { exp( uSn - n ln E[euZ']) : n ;::: 0} is a martingale. 
(d) Let u be such that eu = (1- p)jp in part (c). Then we have 
E[e"z1 ] = eup + e-u(1- p) = 1 
and 
exp(uSn- nlnE[euz,]) = C; P) Sn 
By part (c), we obtain that 
is a martingale. 
This completes the proof. 
26.2. If t = 0, the conclusion is trivial. Lett > 0 be fixed. Let Fn be the distribution 
function of A1[nt]/ J[nij: 
{ M[nt] 
} 
Fn(x) = P 
J[nij ~X . 
Since the Zn are independent and identically distributed and Var(Zn) = 1, it follows 
from Problem 20.4 that 
Fn(x) =? <I>(O, 1,x), 

SOLUTIONS 
349 
where <P(O, 1, x) is as defined in Equation (19.1). Now let 
Vn 
an= JrntJ' 
nt- [nt] 
bn = -
JrntJ Z[nt]+1 
for all n such that [nt] 2 1. Then we have an --+ 1/ Vt and bn --+ 0 as n --+ oo. It 
follows from part (a) of Problem 20.2 that 
Fn(anX + bn) =?- <P ( 0, 1, ~) = <P(O, t, x). 
The result follows immediately by noting that 
This completes the proof. 
26.3. Let ffn = a(Z1, Z2, ... , Zn), n 2 1. 
(a) By the assumption that Z 1 , Z2, ... are independent, we have 
E[S~+ 1 Iffn] = S~ + E[Zn+1lffn] = S~ + E[Zn+l] = S~, 
n 2 0. 
Hence { S~ : n 2 0} is a martingale. 
(b) To show that TN, is a stopping time, we only need to show that 
{TN1 :S:n}Effn, n21. 
Note that 
n 
{TN1 :S: n} = u{sg oJ N1, ... ,Sfc-1 oJ N1,Sk = N1}. 
k=O 
But {Sg -1 N1, ... , S'k_ 1 oJ N1, S'k = NI} E ffn for all k :S: n. Hence we 
have { TN1 :S: n} E ffn. Thus TN1 is a martingale. 
Now we show that P{ TN1 < oo} = 1. Let no= N 2 - N 1. Then 
1 
P{TN, ::::; no}::::: P{Z1 = -1, z2 = -1, ... 'Zno = -1} = 2no' 
which gives 
Fork 2 1, we have 
P{TN1 > kno} 
P{TN1 > (k -l)no,TN1 > kno} 
E[J{ TN 1 >(k-1)no}J{ TN 1 >kno} J 
E[J{ TN 1 >(k-1)no}E(J{ TN 1 >kno} lff(k-1)no )]. 

350 
RANDOM WALKS 
But by Definition 14.4, we have 
E(J{ TN1 >kno} lÂ§(k-l)n,J 
1- E(J{TN1 S:kno}lÂ§(k-l)no) 
< 
1 - E[J{ TN1 >(k-l)no}J{ TN1 <;kno} lÂ§(k-l)no] 
1- P({TN, > (k -1)no} n {TN,<::: kno}lÂ§(k-l)n,J 
< 1- P({Z(k-l)no+l = -1, Â· Â· Â· 'Zkno = -1}lÂ§(k-l)n0 ) 
1- P( {Z(k-l)no+l = -1, Â· Â· Â·, Zkno = -1}) 
1 
1--. 
2no 
Hence by induction, we get 
( 
1 ) k 
1--
2no 
Letting k -+ oo, we get P{ TN, = oo} = 0. 
Similarly, we can show that TN2 is also an a.s. finite stopping time. 
(c) By Problem 23.1, Tis a stopping time. Since 
we have 1 :::, P{T < oo} :::, P{TN, < oo} = 1 by part (b). Hence Tis a.s. 
finite. 
(d) By the definition ofT, we have s~l\n E [Nl, N2]. Hence if c > max{INll, 
IN21}, we have 
which shows that s~l\n is uniformly integrable. 
(e) By parts (a)- (d) and Problem 23.15, we have 
Solving the above equation gives 
This completes the proof. 
26.4. 

SOLUTIONS 
351 
(a) LetH = {Z1 = 1}. Then we have He= {Z1 = -1}. ItfollowsfromProblem 
14.18 that 
<p(x) 
E [I{rRr2 <7 N1 }] 
E [I{ 7 N2 <7 N1 }1H] P(H) + E [I{ 7N2 <7 N1 }1Hc] P(Hc) 
pE [I{rN2 <rN1 }1H] + qE [I{rN2 <rN1 }1Hc]. 
(26.1) 
LetS~+l = 1+xandS~+l = 1+x+Z2+Â·Â· Â·+Zn+l forn ~ 1. Thens~+l 
and s~+ 1 have the same distribution. Hence, on the event H, we have 
and 
T'fvl 
inf{n ~ 0: s~ = Nl} 
inf{n ~ 1: X+ 1 + z2 + ... + Zn = Nl} 
inf{n > 1 : Â§x+l = N } 
-
n-1 
1 
inf{n ~ 0: .Â§~+1 = Nl} 
inf{n ~ 0: s~+l = N1} 
7 x+1 
N1 
Similarly, on the event He, we have 
(26.2) 
(26.3) 
(26.4) 
The result follows by combining Equations (26.1), (26.2), (26.3), and (26.4). 
(b) From part (a), we have 
<p(x + 1)- <p(x) = g_[<p(x)- <p(x- 1)], 
x E [N1 + 1, N2 -1], 
p 
which implies 
<p(x + 1)- <p(x) = (~) x-N
1 [<p(N1 + 1)- <p(N1)], 
x E [N1 + 1, N2 -1], 
By the assumption thatp =f=. q, for every x E [N1 + 1, N2 - 1], we have 
<p(x + 1)- <p(N1 + 1) 
X 
2:: [<p(i + 1)- <p(i)J 

352 
RANDOM WALKS 
Since T%: = 0 and T%; = 0, we have cp(N1 ) = P{T%; < 0} = 0 and 
cp(N2 ) = P{O < T%:} = 1. Letting x = N 2 -
1 in Equation (26.5) gives 
Hence we have 
1- qjp 
cp(NI + 1) = 1 _ (qjp)N2-N,. 
Combining Equations (26.5) and (26.6) gives 
or 
1 _ (qjp)x-N, 
cp(x) = 1 _ (qjp)N2 -N,, 
x E [N1 + 2, N 2]. 
Note that cp(N1 ) = 0 and Equation (26.6). We have 
(26.6) 
(c) The proof is similar to that of part (c). When p = q, Equation (26.5) becomes 
Since cp(NI) = 0 and cp(N2 ) = 1, letting x = N 2 -
1 in the above equation 
gives 
1 
cp(N1 + 1) = N 
N 
2-
1 
Then combining the above equations gives 
This completes the proof. 
26.5. Let q = q - p. 
( 
) Sn 
(a) Let Xn = 
~ 
, n 2: 0. Let ffn = a(Z1, Z2, ... , Zn)Â· Then 

SOLUTIONS 
353 
Hence {Xn : n :::0: 0} is a martingale. Let N > 1. By Doob's maximal 
inequality (see Problem 24.2), we have 
P { sup Sn > y} = 
O~n~N 
< 
The result follows by letting N --+ oo. 
(b) Note that p E (0, ~). We have pjq < 1. By part (a) and Problem 13.10, we 
have 
E [ sup sn] 
O~n~N 
This completes the proof. 
r= P { sup Sn > y} dy 
Jo 
O~n~N 
= lk+l (p)k 
< L: 
-
dy 
k=O 
k 
q 
q 
q-p 
26.6. Let AJ = {S1 < m, S2 < m, ... , SJ- 1 < m, SJ = m} for j = 1, 2, ... , N. 
Then we have 
N-1 
P{SN:::O:m}+ LP(AJn{SN<m}). 
j=1 
Note that AJ n {SN < m} = AJ n {SN < SJ} and that AJ and {SN < SJ} are 
independent. We have 
P{ max Sj :::0: m} 
1~j~N 
N-1 
P{SN :::0: m} + L 
P(Aj)P ({SN < Sj}). 
j=1 

354 
RANDOM WALKS 
By the assumption that X 1, X 2 , ... , XN are symmetrically distributed about zero, 
we have P{SN > Sj} = P{SN > Sj}Â· Hence we have 
P{ max Sj;::: m} 
15oj5oN 
This completes the proof. 
N-1 
P{SN;::: m} + L P(Aj)P({SN > Sj}) 
j=1 
N-1 
P{SN;::: m} + L P(Ai n {SN > Sj}) 
j=1 
N-1 
P{SN;::: m} + L P(Aj n {SN > m}) 
j=1 
P{SN;::: y} + P{SN > m} 
2P{SN;::: y} ~ P{SN = m}. 
26.7. The case when t = 0 is trivial. Suppose that t > 0. Then we have 
lnSn(t) 
= 
[nt]ln (1 ~ a 2 ) + M[nt]ln ( 1 + 0') 
2 
n 
2 
1~-
vn 
where 
bn = [nt]ln (1 ~ a 2 ) . 
2 
n 
Applying !'Hospital's rule to an and bn gives 
an -+a-It, 
1 2 
b -+~-a t 
n 
2 
. 
Let Fn be the distribution function of M[nt]/ Jlntj, i.e., 
It follows from Problem 20.4 that Fn =? N(O, 1) or 
Fn(x) =} <1>(0, 1,x), 
(26.7) 
where <I> is as defined in Equation (19.2). By part (a) of Problem 20.2, we have 
.T 
bn 
( 
X 
1 
~) 
( 
1 2 
2 
) 
Fn(- ~-)=?<I> 0,1, 
~ + -avt =<I> 
~-a t,a t,x . 
an 
an 
ayt 
2 
2 

BIBLIOGRAPHIC NOTES 
355 
Since 
X 
bn 
{ M[nt] 
X 
bn } 
Fn(---)=P --::=:;---
=P{lnSn(t)::=:;x} 
an 
an 
vrntJ 
an 
an 
and the distribution oflnS(t) is .P (-~a2 t,a 2 t,x), the result follows. This com-
pletes the proof. 
26.5 Bibliographic Notes 
In this chapter, we presented random walks. As one of the most studied topics 
in probability theory, random walks have been discussed in many books, for ex-
ample, Bailey (1964), Feller (1968), Loeve (1977), Kannan (1979), Shiryaev and 
Boas (1995), Grinstead and Snell (1997), Kallenberg (1997), Paul and Baschnagel 
(1999), Steele (2003), James (2003), Klebaner (2005), Stroock (2005), Lin (2006), 
Buchanan (2006), Bhattacharya and Waymire (2009), and Durrett (2010). There 
are several books devoted to random walks, including Spitzer (2001), Rudnick and 
Gaspari (2004), and Lawler and Limic (2010). 


CHAPTER27 
POISSON PROCESSES 
A Poisson process is a continuous-time stochastic process that counts the number of 
events in a given time interval. In mathematical finance, Poisson processes are used 
to build jump processes for modeling asset prices. In this chapter, we present the 
mathematical definition of the Poisson process and relevant results. 
27.1 
Basic Concepts and Facts 
Definition 27.1 (Poisson Process). Let A > 0. A stochastic process { Nt : t ~ 0} is 
said to be Poisson process with parameter A if it satisfies the following conditions: 
(a) P{No = 0} = P{w: No(w) = 0} = 1. 
(b) For any 0 :-:; s < t, the random variable Nt - N 8 is a Poisson random variable 
with parameter A(t- s): 
P{Nt- Ns = k} = e->.(t-s) (A(t ~ s))k, 
k = 0, 1, 2, .... 
(c) The Nt has independent increments, that is, for any 0 :-:; t 1 < t2 < ... < tn. 
the random variables Nt1 , Nt 2 -
Nt1 , â¢â¢â¢ , Ntn - Ntn-l are independent. 
Measure, Probability, and Mathematical Finance. 
357 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

358 
POISSON PROCESSES 
(d) Almost all sample paths of { N 1 
left-hand limits. 
> 0} are right-continuous functions with 
Definition 27.2 (Poisson Process with Respect to Filtrations). Let {Â§1 : t :-=:: 0} be 
a filtration, and let,\ > 0. A stochastic process { N 1 : t :-=:: 0} is said to be Poisson 
process with respect to the filtration { JY1 : t :-=:: 0} and with parameter ,\ if it satisfies 
the following conditions: 
(a) P{N0 = 0} = P{w: N 0 (w) = 0} = 0. 
(b) For any 0 :::; s < t, the random variance Nt - Ns is a Poisson random variable 
with parameter >.(t- s): 
P{N - N = k} = e-.\(t-s) (>.(t- s))k 
t 
s 
. 
. 
k! 
k = 0, 1, 2, .... 
(c) For any .s :::; t, the random variable Nt - Ns is independent of the o--field Y
8 â¢ 
(d) Almost all sample paths of { Nt : t :-=:: 0} are right continuous functions with 
left-hand limits. 
Definition 27.3 (Compensated Poisson Process). Let {Nt : t :-=:: 0} be a Poisson 
process with parameter,\ > 0. Then the corresponding compensated Poisson process 
Nt is defined by 
Definition 27.4 (Compound Poisson Process). A compound Poisson process { Q t 
t :-=:: 0} has the form 
N, 
Qt = LYi, 
t :-::: o, 
i=l 
where { Nt : t :-=:: 0} is a Poisson process with some parameter ,\ > 0 defined on 
a probability space (r2, /Y, P), {Yn : n = 0,1, ... } is a sequence of independent 
and identically distributed random variables defined on the same probability space 
(r2, /F, P), and the sequence {Y;, : n = 0, 1, ... } is independent of the Poisson 
process {N1 : t :-=:: 0}. 
Definition 27.5 (Counting Process). Let {Tn : n :-=:: 1} be an increasing sequence of 
positive random variables. Let T0 = 0 a.s. Then the counting process { Nt : t :-=:: 0} 
associated to the sequence {Tn : n :-=:: 0} is defined as 
Nt = L IrnÂ·~Â·Jâ¢ 
t :-=:: 0. 
n:;>l 
Theorem 27.1. Let {Tn : n :-=:: 0} be an increasing sequence qf positive random 
variables with P{T0 = 0} = 1 and P{Tn ---7 oo} = 1. Let {Nt : t :-=:: 0} be a 
counting process associated with the Tn. If { Nt : t :-=:: 0} has stationary independent 
increments, then { Nt : t :-=:: 0} is a Poisson process. 

PROBLEMS 
359 
27.2 Problems 
27.1. Let { Nt : t ;:::: 0} be a Poisson process ~ith parameter A > 0. Show that the 
corresponding compensated Poisson process Nt is a martingale. 
27.2. Let {Nt : t ;:::: 0} be a Poisson process with parameter A, where A > 0. The 
sample paths of the Poisson process are step functions with jumps. Let TI be the 
time of the first jump. For n ;:::: 2, let Tn be the elapsed time between the ( n - 1 )th 
the jump and the nth jump. Show that {Tn : n ;:::: 1} is a sequence of independent 
random variables having the same exponential distribution with parameter A: 
{
1-e->-.t, ift;::::O; 
P{Tn::; t} = 
0, 
if t < 0. 
27.3. Let { Tn}n>I be a sequence of independent and identically distributed expo-
nential random variables with parameter A. Let {Tn}n>I be the sequence of partial 
sums of the Tn: 
n 
Tn = L Ti, 
n ;:::: 1. 
i=I 
Let { Nt : t ;:::: 0} be a stochastic process defined as 
Nt = L ft'2Tn Â· 
n'2I 
Show that { Nt : t ;:::: 0} is a Poisson process with parameter A. 
27.4. Let { NP) : t ;:::: 0} and { NF) : t ;:::: 0} be two independent Poisson processes 
with parameters AI and A2 , respectively. Show that { NP) + NF) : t ;:::: 0} is a 
Poisson process with parameter AI + A2 . 
27 .5. Let { Nt : t ;:::: 0} be the compensated Poisson process corresponding to a 
Poisson process with parameter A > 0. Let 0 < s < t. Show that the moment 
generating function of Nt - Ns is 
E [exp(x(Nt- Hs))J = exp [A(t- s)(ex- x- 1)]. 
In particular, the first four moments are given by 
E [Nt- Hs] 
E [(.Nt- Hs) 2] 
E [(.Nt- Ns) 3 ] 
E [(.Nt- Ns) 4 ] 
0, 
A(t-s), 
A(t-s), 
A(t- s) + 3A2(t- s) 2 . 

360 
POISSON PROCESSES 
27.6. Let {Nt : t ::> 0} be the compensated Poisson process corresponding to a 
Poisson process with parameter .\ > 0. Let 0 ::;: a < b < oo. Show that 
as 
i=l 
where ~n = {t0 , t 1 , ... , tn} is a partition of [a, b] and 
27.7. Let { Nt : t ::> 0} be the compensated Poisson process corresponding to a 
Poisson process with parameter .\ > 0. Show that 
- 2 
Mt = Nt - .\t 
is a martingale. 
27.8 (Geometric Poisson Process). Let {N1 : t ::> 0} be a Poisson process with 
parameter.\> 0. Let {Xt: t ::> 0} be defined as 
Xt = exp (Nt ln(l +a)- .\at)= (1 + a)N'e->-.ut, 
t > 0, 
where a> -1 and X 0 > 0 are constants. Show that {Xt: t ::> 0} is a martingale. 
27.9. Let { Qt : t ::> 0} be a compound Poisson process as defined in Definition 27.4. 
Let {Â§1 : t ::> 0} be the natural filtration of {Qt : t ::> 0}. Show that 
(a) For every integer m ::> 0, every t ::> 0, and every h ::> 0, the random variables 
and 
have the same distribution: 
Nt+h-Nt 
L 
Yrt+m 
n=l 
Nt+h-Nt 
L 
Yn+Nt 
n=l 
(b) For every t ::> 0 and every h ::> 0, Qt+h - Qt has the same distribution as Qh. 
(c) For every t ::> 0 and every h ::> 0, Qt+h - Qt is independent of Â§ 1. 
27.10. Let { Qt : t ::> 0} be a compound Poisson process as defined in Definition 
27.4. Suppose that E(YI) = (3. Show that 
(a) For every t ::> 0, E[Qt] = ;3.\t. 
(b) The process { Qt - (3.\t : t ::> 0} is a martingale. 

HINTS 
361 
27.3 Hints 
27.1. Use the definition of compensated Poisson process (Definition 27.3). 
27.2. Note that the event {T1 > t} coincides with the event {Nt = 0} and use the 
tower property of conditional expectations (see Problem 14.10). 
27.3. Verify the four conditions in Definition 27.1. One can use direct computation 
to verify the first two conditions. The third condition can be verified by using the 
result of Problem 12.6. The fourth condition can be proved by using the result of 
Problem 11.1. 
27 .4. Verify the four conditions of Poisson processes (Definition 27.1 ). 
27.5. Follow the definition of compensated Poisson processes. 
27 .6. Consider the random variables X 1 , X 2, ... , Xn given by 
-
-
2 
-
-
Xi= (Nti- Nti_J - (Nti- Nti-1)- >.(ti- ti-dÂ· 
27.7. 
Follow the definition of martingales (Definition 22.1) and note that Nt 
Nt- >.t. 
27 .8. Use the definition of Poisson processes (Definition 27 .2) and the definition of 
martingales (Definition 22.1 ). The results of Problems 14.12 and 14.16 can be used 
to verify E[Xtlffs] = Xs. 
27.9. To prove parts (a) and (b), note that 
Use part (a) and the result of Problem 21.10 to prove part (c). 
27.10. To prove part (a), follow the definition of compound Poisson process (Defi-
nition 27.4) and use the result of Problem 14.18. To prove (b), note that Qt- Q 8 has 
the same distribution as Qt-s and use part (a). 
27.4 Solutions 
27.1. By definition, N(t) is fft-measurable. In addition, we have 
E(INti) = E(INt- >.ti) ~ E(Nt) + >.t = 2>.t < oo. 

362 
POISSON PROCESSES 
Let s :-:::; t. Then we have 
E(Nt - .Atlffs) 
E(Nt- Ns + Nslffs)- t.A 
E(Nt - Ns) + Ns -.At 
N 8
-
AS. 
Hence the Nt is a martingale. This completes the proof. 
27.2. Since {T1 > t} = {Nt = 0}, we have 
P{T1 > t} = P{Nt = 0} = e->.t, 
t ~ 0. 
Since {T1 = s} E ffs and Nt+s - N 8 is independent of ff8 , we have 
P{Nt+s- Ns = OIT1 = s} 
P{Nt+s- Ns = 0} 
e->.t, 
which shows that T2 is independent of T1. By Definition 14.5, we have 
Hence by Problem 14.1 0, we have 
P{T2 > t} 
E[P{T2 > t!Tl}] 
E [e-At] 
->.t 
e 
. 
Similarly, we can show that Tn is independent of T1 , T2 , ... , Tn-l and 
This completes the proof. 
27 .3. To show that { Nt : t ~ 0} is a Poisson process, we only need to verify that 
{ Nt : t ~ 0} satisfies the four conditions in Definition 27 .I. First, let us show that 
P{No = 0} = 1. Note that 
{w: N0 (w) = 0} = {w: Tn(w) > 0, n = 1,2, ... } = {w: T 1(w) > 0}, 
which gives P{No = 0} = P{ T1 > 0} = 1. 
Now let us verify the second condition. Let 0 :-:::; s < t. Then we have 
n:2:1 
n:2:1 
n:2:1 

SOLUTIONS 
363 
Noting that the Tn is an non-decreasing sequence, we have 
00 
{Nt- N 8 = k} = U{Ti::; S < Ti+lâ¢ Ti+k::; t < Ti+k+l}, 
k 2: 0, 
i=O 
where T0 = 0. Since the sets {Ti ::; s < Ti+lâ¢ Ti+k ::; t < Ti+k+d are mutually 
disjoint, we have 
00 
P{Nt-Ns = k} = LP{Ti::; S < Ti+l,Ti+k::; t < Ti+k+l}, 
k 2:0. (27.1) 
i=O 
But 
Combining Equations (27.1) and (27.2) gives 
00 
i 
k 
k 
P{N - N = k} = "'~(t- s)k d+ke->-.t = >. (t- s) e->-.(t-s) 
k 
t 
S 
~ 
ilk! 
A 
k! 
' 
:::: 0. 
i=O 
Hence Nt- N 8 is Poisson distributed with parameter >.(t- s). 
To verify the third condition, we use the result of Problem 12.6. Let 0 ::; t 1 < 
t2 < Â· Â· Â· < tn. Then Nh, Nt2 -
Nt1 , â¢â¢â¢ , Ntn - Ntn-l are Poisson distributed. Let 

364 
POISSON PROCESSES 
k1, k2, ... , kn ?:: 0 and j1 = k1, j2 = k1 + k2, ... , Jn = k1 + Â· Â· Â· + kn. Then we 
have 
P{Nt, = k1, Nt 2 ~ Nt, = k2, ... , Ntn ~ Ntn-l = kn} 
P{TJ, ::; t1 < Th+I, ... , TJn::; tn < TJn+I}. 
Using the same approach in Equation (27.2), we can get 
where to = 0. Since Nt 1 , Nt 2 ~ Nt,, ... , Ntn ~ Ntn-l are Poisson distributed, we 
have 
n IT P{Nt, ~ Nt,_, = ki} 
i=l 
Therefore, we have 
n 
P{Nt 1 = k1, Nt 2 ~Nt 1 = k2, â¢ â¢., Ntn ~Ntn-l = kn} =IT P{Nti ~Nt,_ 1 = ki}. 
i=l 
It follows from Problem 12.6 that Nt,, Nt 2 ~ Nt,, .. . , Ntn ~ Ntn-l are independent. 
Finally, let us verify the fourth condition. By the definition of Nt, for almost every 
wE fl, the sample path t--+ Nt(w) is constant at each interval (Tn_ 1(w), Tn(w)), 
n = 1, 2, .... Hence 
{ wE fl: limNs(w) = Nt(w) and limNs(w) exists, 'Vt?:: o} 
s_j_t 
stt 
n 
{wE fl: 
lim Ns(w) = Nrn(w)(w) and 
lim N 8 (w) exists}. 
n=l 
s-1-Tn(w) 
stTn(w) 
But 
{wE fl: Tn-I(w) < Tn(w) < Tn+I(w)} 
C 
{wE fl: 
lim Ns(w) = Nrn(w)(w) and 
lim Ns(w) exists} 
s-1-Tn(w) 
stTn(w) 
and 
P{w E fl: Tn-l(w) < Tn(w) < Tn+l(w)} = P{Tn > O,Tn+l > 0} = 1. 

SOLUTIONS 
365 
By Problem 11.1, we have 
P {wE !:2: limNs(w) = Nt(w) and limNs(w) exists, 'v't?: o} = 1. 
8{-t 
stt 
Therefore, almost all sample paths of {Nt : t ?: 0} are right-continuous with left-
hand limits. This completes the proof. 
27.4. To show that {NP) + NF) : t ?: 0} is a Poisson process, we only need to 
verify that it satisfies the four conditions given in Definition 27.1. Since {NP) : t?: 
0} and { Nt(2) : t ?: 0} are independent Poisson processes, we have 
P { N61l = 0, N62l = 0} 
P { N61l = 0} P { N62l = 0} 
1. 
Hence the process satisfies the first condition. 
Now let 0 :::; s < t and k ?: 0. Then we have 
P {N<1l + N(2) - N(l) - N(2) = k} 
t 
t 
8 
8 
k 
""'P {N(I) - N(l) = i N(2J - N(2) = k- i} 
L......t 
t 
8 
' 
t 
8 
i=O 
k L p { NP) - NP) = i} p { N?) -
N~ 2 ) = k - i} 
i=O 
k >.i (t 
)i 
)..k-i(t 
)k-i 
""' 
1 
-
8 
-)q(t-8) 
2 
-
8 
-.A2(t-8) 
L......t 
., 
e 
. 
(k- ')1 
e 
z. 
z 0 
i=O 
(>.1 + A.2)k(t- s)k -(.A1+.A2)(t-8) 
k! 
e 
' 
which shows that the process satisfies the second condition. 
The third condition and the fourth condition are implied from the properties of 
Poisson processes and the assumption that {NP) : t?: 0} and {NF) : t ?: 0} are 
independent. This completes the proof. 

366 
POISSON PROCESSES 
27.5. Since Nt- N8 = Nt- N8
- >-.(t- s), we have 
E [exp(x(Nt- Ns- >-.(t- s)))] 
00 
L.::exp[x(k- >-.(t- s))]P{Nt- Ns = k} 
k=O 
oo 
(>-.(t- s))k 
L exp[x(k- >-.(t- s))]e-.A(t-s) 
k! 
k=O 
oo 
(ex >-.(t 
s))k 
L exp[(>-.(t- s))( -x- 1)] 
k~ 
k=O 
exp [>-.(t- s)(ex- x- 1)]. 
The moments follow from Problem 17.4. This completes the proof. 
27.6. Let 
Then 
n 
n 
L(Nt, - Nt,_, )2 - (>-.(b- a)+ Nb- Na) = L xi. 
i=l 
i=l 
To show that 
n 
2 
L(Nt,- Nt,_,) 2 ~ 
>-.(b- a)+ Nb- Na 
as 
ll~nll--+ 0, 
i=l 
we only need to prove 
(27.3) 
Note that 
Fori< j, since Xi and Xj are independent, we have E[XiXj] = E[Xi]E[Xj] = 0. 
By Problem 27.5, we have E [X?] = 2)..2(ti- ti_1) 2. Therefore, we have 
which implies that Equation (27.3) is true. This completes the proof. 

SOLUTIONS 
367 
27.7. Since Poisson processes are square integrable, Mt is integrable. Also the Mt 
is adapted to the filtration Â§t. We are left to verify that E(MtlÂ§s) = M 8 for all 
0 ~ s < t. 
Let 0 ~ s < t. Then we have 
E(MtlÂ§s) 
E[(Nt - Ns + Ns) 2 - >.tlÂ§s] 
E[(Nt- Ns) 2 lÂ§s] + 2E[(Nt- Ns)NslÂ§s] + E[N;- >.tiÂ§s] 
E[(Nt - N8 ) 2] + N: - >.t 
N2 - >.s 
8 
Hence the Mt is a martingale. This completes the proof. 
27.8. 
Suppose that {Nt : t ~ 0} is adapted to a filtration {Â§t : t ~ 0}. Then 
{Xt : t ~ 0} is also adapted to this filtration. Now we show that 
E(IXtl) < oo, 
Vt ~ o. 
(27.4) 
In fact, ift = 0, then E(IX0 1) = 0 < oo. 1ft> 0, it follows from Definition 27.2 
that 
00 
(>.t)k 
"'(1 + a)ke->.ate->.t __ 
~ 
k! 
k=O 
->.(l+a)t ~ 
[(1 + a)>.t]k 
e 
~ 
k! 
k=O 
e->.(l+a)t . e>-(l+a)t 
1, 
which shows that Equation (27.4) holds. 
It remains to check that 
(27.5) 
To do that, let 0 ~ s < t be fixed. By the definition of Poisson processes (Definition 
27 .2), we know that Nt- N 8 is independent of Â§
8 and N 8 is Â§
8 -measurable. Hence 
it follows from Problems 14.12 and 14.16 that 
E [(1 + a)N<e->.atlÂ§s] 
e->.at(1 + a)Ns E [(1 + a)Nt-Ns lÂ§s] 
e->.at(1 + a)Nâ¢ f:(l + a)ke->.(t-s) [>.(t ~ s)]k 
k=O 
k. 

368 
POISSON PROCESSES 
Therefore, Equation (27 .5) also holds. This completes the proof. 
27.9. 
(a) Let m :2: 0, t :2: 0, and h :2: 0 be fixed. Since 
U ({Nt+h- Nt = j} n {Nt = i} n {t Yn+i S c}) 
t,J2:0 
n=l 
and the sets { Nt+h - Nt = j} n { Nt = i} { L~=l Yn+i S c} are disjoint for 
different pairs ( i, j), we have 
{
Nt+h-Nt 
} 
P 
~ Yn+Nt S C 
_L P ({Nt+h- Nt =j} n {Nt = i} n {tYn+i S c}). 
t,J20 
n=l 
By the assumption that { Nt : t :2: 0} and {Y1 , Y2 , ... } are independent, we 
have 
Note that Yn+i and Yn+m have the same distribution. We get 

SOLUTIONS 
369 
(b) Lett ~ 0 and h ~ 0 be fixed. By the proof of the first item, we have 
Since Nt+h- Nt has the same distribution as Nh and Nt+h- Ntis independent 
of Nt. the above equation gives 
,~/{N<+h -N, ~j)P{N, ~ i)P{tYn,; c} 
,~/{Nh ~ j)P{N, ~ i)P {t 
Yn,; c} 
P{t,Yn ~ c}. 
Hence Qt+h- Qt has the same distribution as Qh. 
(c) Lett ~ 0 and h ~ 0 be fixed. By Problem 21.10, we only need to show 
that for any integer m ~ 0, any 0 ~ s 1 < s2 < Â· Â· Â· < Sm ~ t, and any 
c1, c2, ... , em, c E R, we have 
P{Qs, ~ cl, ... 'QSm ~ Cm, Qt+h- Qt ~ c} 
P{Qs, ~ CI, ... 'QSm ~ Cm}. P{Qt+h- Qt ~ c}. 
(27.6) 

370 
POISSON PROCESSES 
In fact, we have 
P{Qs,:::; cl,Â· .. ,Qs,.:::; Cm,Qt+h- Qt:::; c} 
L 
P( { Ns, = kl' ... 'Ns,. = km, Nt = i} n 
{Nt+h- Nt = j} n 
{ t, Zn :::; C1, ... , ~ 
Zn :::; Cm, t Zn+i :::; C}) 
L 
P({Ns, = k1, Â· .. ,N8 ,. = km,Nt = i}) Â· 
k1 ,k2, ... ,krn ,i,j~O 
Since Zn+i has the same distribution as Zn, we get 
P{Qs, :::; c1, ... , Qs,. :::; Cm, Qt+h- Qt:::; c} 
L 
P({N81 = k1, ... ,N8 ,. = km,Nt = i}) Â· 
k1 ,k2 , ... ,krn ,i,j~O 
Equation (27 .6) follows from the above equation and the first item. 
This completes the proof. 
27.10. 

BIBLIOGRAPHIC NOTES 
371 
(a) By Problem 14.18 and the assumption that {Nt : t ~ 0} and {Yn 
n = 
0, 1, ... } are independent, we have 
E[Qt] 
= 
E [t, }i l 
~E [t,}il Nt = kl P{Nt = k} 
~E [t,}i l 
P{Nt = k} 
f k(3 (A:t e->.t 
k=O 
(3At. 
(b) Let{$t: t ~ O}bethefiltrationgeneratedby{Qt: t ~ 0}. LetO ~ s < t. 
Then Qt- Q 8 is independent of F8 (see Problem 27.9). In addition, Qt- Q 8 
has the same distribution as Qt-s because Nt - N 8 has the same distribution as 
Nt-sÂ· Hence 
E[Qt- Qsl$s] + Qs- (3At 
E[Qt-s] + Q 8 - (3At 
(3A(t- s) + Qs- (3At 
Qs- (3As, 
which shows that { Qt - (3At : t ~ 0} is a martingale. 
This completes the proof. 
27.5 Bibliographic Notes 
In this chapter, we introduced Poisson processes. The definition of Poisson process 
is similar to that of Brownian motion. This definition was adopted from Kuo (2006). 
In some books, the Poisson process is defined as a counting process [see Cont and 
Tankov (2003, Section 2.5) and Protter (2003, Section 1.3)]. Theorem 27.1 says 
that if a counting process has stationary independent increments, then it is a Poisson 
process. For a proof of this theorem, readers are referred to Cont and Tankov (2003, 
Lemma 2.1). For more information about Poisson process, readers are referred to 
Ross (1995) and Chung and Aitsahlia (2007). 


CHAPTER 28 
BROWNIAN MOTION 
Brownian motion is a fundamentally important stochastic process in that it is a cen-
tral notion throughout the theoretical development of stochastic processes. In this 
chapter, we present the definition and some properties of Brownian motion. 
28.1 
Basic Concepts and Facts 
Definition 28.1 (Standard Brownian Motion). Let (0, $, P) be a probability space. 
A stochastic process { Bt : t 2:: 0} on ( 0, $, P) is called a standard Brownian 
motion if it satisfies the following conditions: 
(a) P{Bo = 0} = P{w: Bo(w) = 0} = 1. 
(b) For any 0 s; s < t, the increment Bt - Bs is a random variable normally 
distributed with mean 0 and variance t - s, that is, for any a < b, we have 
1 
1b ( x2 
) 
P{ a :S Bt - Bs :S b} = 
exp 
( 
) 
dx. 
J27l'(t-s) 
a 
2 t-s 
Measure, Probability, and Mathematical Finance. 
373 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

374 
BROWNIAN MOTION 
(c) Bt has independent increments, that is, for any 0 ::::; h < t 2 < ... < tn, the 
random variables Bt1 , Bt2 - Bh, .. . , Bt" - Btn-l are independent. 
(d) Almost all sample paths of Bt are continuous functions: 
P{w: B(t,w) = Bt(w) is continuous}= 1. 
Definition 28.2 (Brownian Motion with Respect to Filtrations). Let { ~t : t 2': 0} be 
a filtration. A stochastic process { Bt : t 2': 0} is said to be a Brownian motion with 
respect to the filtration { ~t : t 2': 0} if it satisfies the following conditions: 
(a) P{Bo = 0} = P{w: Bo(w) = 0} = 1. 
(b) For any 0 ::::; s < t, the increment Bt - B 8 is a random variable normally 
distributed with mean 0 and variance t - s, that is, for any a < b, we have 
1 
1b ( -x2 
) 
P{a::::; Bt- B 8
::::; b} = 
exp 
( 
) 
dx. 
yf27r(t-s) 
a 
2 t-s 
(c) For any s ::::; t, the random variable Bt - B 8 is independent of the a-field ~8 â¢ 
(d) Almost all sample paths of Bt are continuous functions: 
P{w: B(t,w) = Bt(w) is continuous}= 1. 
Definition 28.3 (m-Dimensional Brownian Motion). Let m be a positive integer 
and J.L a probability measure on (R m, B(R m)). Let Bt be a continuous process with 
values in Rm, defined on a probability space (n, ~. P), and adapted to a filtration 
{ ~t : t 2': 0}. This process is called an m-dimensional Brownian motion with initial 
distribution J.L if 
(a) P{Bo E A}= J.L(A) for all A E B(Rm). 
(b) For 0 ::::; s < t, the increment Bt - Bs is independent of ~s and is normally 
distributed with mean zero and covariance matrix (t- s)Im, where Im is the 
m x m identity matrix. 
Theorem 28.1 (Law of the Iterated Logarithm). Let { Bt : t 2': 0} be a Brownian 
motion. Then 
{ . 
Bt 
} 
P hmsup 
= 1 = 1 
yf2t log log t 
and 
P {liminf 
Bt 
= -1} = 1. 
yf2t log log t 
Theorem 28.2 (Strong Markov Property). Let { Bt : t 2': 0} be a Brownian motion. 
Let T be a stopping time with respective to the filtration generated by the Brownian 
motion. Then the process 

PROBLEMS 
375 
is a standard Brownian motion independent of~:, where 
~: = n a(Bs : 0 ~ 8 ~ t). 
t>T 
28.2 Problems 
28.1. Let { Bth>o be a Brownian motion and { ~t : t ~ 0} be a filtration defined as 
~t = a{Bs: 8 ~ t}, 
t ~ 0. 
Show that { Bt }t;:::o is a martingale with respect to { ~t : t ~ 0}. 
28.2. Let { Bt h>o be a Brownian motion. Show that 
(a) For any t > 0, Bt is normally distributed with mean 0 and variance t. 
(b) For any 8, t ~ 0, E[BsBt] = min(8, t). 
28.3 (Translation Invariance ). Let { Bt }t;:::o be a Brownian motion. Show that for any 
fixed to ~ 0, the stochastic process Bt = Bt+to - Bt0 is also a Brownian motion. 
28.4 (Scaling Invariance). Let { Bt}t;:::o be a Brownian motion. Show that for any 
>. > 0, the stochastic process 
is also a Brownian motion. 
28.5 (Time-Inversion Invariance ). Let { Bt h;:::o be a Brownian motion. Let W0 = 0 
and 
Wt = tB1, 
t > 0. 
t 
Show that {Wt}t;:::o is a Brownian motion. In particular, show that 
lim Wt = 0, 
a.s. 
t.j.O 
28.6. Let { Bt h>o be a Brownian motion. Show that 
28.7. Let {Bt}t;:::o be a Brownian motion. Let 8, t E Rand 8 ~ t. Show that the 
random variable 
aBs + bBt 
is normally distributed with mean 0 and variance (a2 + 2ab)8 + b2t. 
28.8. Let { Bt}t;:::o be a Brownian motion, and let 0 < 8 < t ~ u < v. Show that 

376 
BROWNIAN MOTION 
(a) The random variables i Bt - i Bs and aBu + bBv are independent for any 
a,bE R. 
(b) The random variables aBs + bBt and ~Bv -
~Bu are independent for any 
a, b E R satisfying the condition as + bt = 0. 
28.9. Let { Bt }t;::o be a Brownian motion. Let { Lt : t ;:::: 0} be a stochastic process 
defined as 
Lt = ~ (Bl- t), t 2:: 0. 
Show that the Lt is a martingale with respect to the filtration g;t = a{ B 8 
: s ::; t }. 
28.10. Let {Wt : t ;:::: 0} be a stochastic process adapted to the filtration { g;t : t ;:::: 
0}. Suppose that for any s ::; t, the random variable Wt - W 8 is independent of the 
a-field g;sÂ· Show that the process Wt has independent increments. 
28.11. Let { Bt : t ;:::: 0} be a Brownian motion. Let y > 0. For any t > 0, show that 
P {max B 8 2': y} ::; 2P{Bt 2': y}. 
O:Ss::;t 
28.12. Let {Bt : t;:::: 0} be a Brownian motion. Show that 
and 
P {limsupBt = oo} = 1, 
t--+oo 
P {lim inf Bt = -oo} = 1. 
t--+oo 
28.13 (Reflection Principle). Let {Bt : t ;::=: 0} be a Brownian motion and T be a 
stopping time with respect to the filtration generated by the Brownian motion. Let 
{ Bt : t ;:::: 0} be a process defined by 
ift < T; 
ift 2': T. 
Show that { Bt : t ;:::: 0} is a standard Brownian motion. 
28.14 (Reflection Equality). Let { Bt : t ;:::: 0} be a Brownian motion and a E R. 
Let T a be a stopping time defined by 
T = min { t : Bt = a}. 
Suppose that a > 0. For every (3 ::; a, show that 
P{Ta::; t,Bt::; /3} = P{Bt 2': 2a- (3}. 

HINTS 
377 
28.15. Let { Bt : t :=:::: 0} be a Brownian motion and a > 0. Let T be a stopping time 
defined by 
T = min { t : Bt = a}. 
Let { Mt : t :=:::: 0} be defined as 
Show that 
(a) P{Mt >a}= 2P{Bt >a}. 
(b) The probability density function of T is given by 
where 
28.16. Let { Bt : t :=:::: 0} be a Brownian motion. Let { Mt : t :=:::: 0} be defined as 
Mt = max B., 
t :=:::: 0. 
o::;8::;t 
Show that for every t > 0, the joint density function of ( Mt, Bt) is 
2(2x- y) 
( (2x- y) 2 ) 
!M,B,(x,y)= 
tv'27rf; 
exp -
2t 
' 
y S:: X, X> 0 
and is zero for other values of x andy. 
28.17. Let Bt = (B?), Bi2), ... , Bim)) be an m-dimensional Brownian motion. 
. 
B(l) 
(1) B(2) 
B(2) 
B(m) 
B(m) 
Show that for 0 :::; s < t, the mcrements t - B8 , t -
8 , ... , t 
-
8 
are independent. 
28.3 Hints 
28.1. Use the fact that for any s :::; t, Bt - B8 is independent of Â§ 8. 
28.2. 
Part (a) is implied by the definition of Brownian motions (Definition 28.1). 
Part (b) can be proved by the independence property of the increments. 
28.3. Use the definition of Brownian motions (Definition 28.1). 
28.4. Use the definition of Brownian motions (Definition 28.1). 

378 
BROWNIAN MOTION 
28.5. 
Use the definition of Brownian motions (Definition 28.1). The result of 
Problem 19.3 can be used to prove the second condition. Use the results of Problems 
19.5 and 19.6 to prove the third condition. To prove the fourth condition, consider 
1 
Nn 1 
Nn 
1 
Wt = -B = -- "'(B - B-_1) + -(B - BN) 
n 
Sn 
N L.-t 
2 
'l.. 
Sn 
n 
' 
Sn 
Sn 
n i=l 
Sn 
where sn = 1/tn and Nn is the largest integer such that Nn ~ Sn, and use the strong 
law of large numbers (Theorem 16.2) and the result of Problem 19.17. 
28.6. Use the moment generating function of the normal distribution (see Problem 
19.1) and the result of Problem 17 .4. 
28.7. Use the result of Problem 19.3 and the properties of Brownian motion. 
28.8. Use the results of Problems 28.7 and 19.6. 
28.9. Use the results of Problems 14.4 and 14.12. 
28.10. Follow the definition of independence (Definitions 12.1 and 12.2). 
28.11. Use Levy's inequality (see Problem 15.11). 
28.12. Apply the law of the iterated logarithm (Theorem 28.1 ). 
28.13. Apply the strong Markov property (Theorem 28.2). 
28.14. Apply the reflection principle (see Problem 28.13). 
28.15. To prove part (a), consider the Brownian motion reflected at T and use the 
reflection principle (see Problem 28.13). Part (b) can be proved by part (a). 
28.16. Use the result of Problem 28.14. 
28.17. Use the definition of multidimensional Brownian motions (Definition 28.3) 
and the result of Problem 19 .6. 
28.4 Solutions 
28.1. Lets~ t. Then Bt- Bs is independent of g;sÂ· Hence we have 
Note that E(Bf) = t < oo. By Problem 8.5, we have E(IBtl) < oo. Hence the Bt 
is a martingale with respect to the g;tÂ· This completes the proof. 
28.2. 

SOLUTIONS 
379 
(a) By Definition 28.1, Bt - B 0 is normally distributed with mean 0 and variance 
t. But B 0 is equal to 0 a.s. Hence Bt is normally distributed with mean 0 and 
variance t. 
(b) Without loss of generality, we assume that 0 ~ s < t. Then by definition, 
B s - Bo and Bt - B s are independent. Hence we have 
This completes the proof. 
28.3. To show that { Bt}t>o is a Brownian motion, we only need to verify that it 
satisfies the four conditions in Definition 28.1. Since Bo = Bt0 -
Bt0 = 0, the Bt 
satisfies the first condition. Let 0 ~ s < t. Then 
which implies that Bt - Bs is normally distributed with mean 0 and variance t + 
t 0 - (s + t0 ) = t- s. Hence the Bt satisfies the second condition. 
Now let 0 ~ t1 < t2 < ... < tn. Then we have 0 ~ h +to < t2 +to < 
Â·: Â· < t"':.. +to. The increments Bh = Bh+toâ¢ Bt2
- Bh = Bt.:;+to- Bt 1+toâ¢ ... , 
Btn - Btn-l = Btn+to - Btn- 1+to are independent. Hence Bt satisfies the third 
condition. Since almost all sample paths of the Bt are continuous, so are the sample 
paths of the (B)t = Bt+to- BtoÂ· Hence the Bt satisfies the fourth condition. 
28.4. 
It is obvious that the Bt satisfies the first, third, and fourth conditions in 
Definition 28.1. Let 0 ~ s < t. Then 
-
-
B>..t- B>..s 
Bt- Bs = 
-..(5.. 
Note that B>..t- B>..s is normally distributed with mean 0 and variance .>..(t- s). We 
know that Bt - Bs is normally distributed with mean 0 and variance t- s. Hence 
the Bt satisfies the second condition. Therefore the Bt is a Brownian motion. 
28.5. 
To show that {Wt}t?:O is a Brownian motion, we only need to verify that 
Wt satisfies the four conditions in Definition 28.1. By the definition of W 0 , the first 
condition is satisfied. Let 0 < s < t. Then 
Wt- Ws = tB1- sB1 = (t- s)B1- s (B1- B1). 
t 
8 
t 
8 
t 
Note that B 1 and B 1 - B 1 are independent normal random variables. By Problem 
19.3, we kn~w that Wt - Ws is normally distributed with mean 0 and variance 
(t-s) -+s ---
=t-s. 
21 
2(1 1) 
t 
s 
t 
Similarly, Wt - Wo = tB 1 is also normally distributed with mean 0 and variance t. 
t 
Hence Wt satisfies the second condition. 

380 
BROWNIAN MOTION 
Let 0 < t1 < t2 < ... < tn. Let (a1, az, ... , an)T be a vector. Then we have 
n 
al wl + L ai(Wt,- Wt,_,) 
i=2 
n-1 
'"'(ai- ai+l)tiB.l. + antnB_l 
L.....t 
t1 
t7! 
i=l 
which shows the the linear combination of Wt 1 , Wt 2 - Wt,, ... , Wt, - Wt,_ 1 is a 
normal random variable. It follows from Problem 19.5 that the vector (Wt 1 , Wt 2 -
Wt,, ... , Wt"- Wt,_ 1 ) Tis a multivariate normal random variable. Now by Problem 
28.2, for i > 1, we have 
E[Wt.(Wt,- Wt,_,)] = t1tiE [n_l_B.l.] - t1ti-1E [n_l_B_,_J = 0, 
tl 
t,i 
tl 
t1-1 
and for i > j > 1, we have 
E[(Wti- Wt,_,)(Wtj- Wt 1 _ 1 )] 
titJE [n.l.. B_1_] - ti-ltJE [n_,_B_l_] - titJ-lE [B.l.B_,_J 
t1 
tj 
t1-1 
tj 
ti 
tj-1 
+ti-ltJ-lE [n_l_B_,_J 
tl-1 
tj-1 
tj- tj- tj-1 + tj-1 
0. 
Therefore, by Problem 19.6, the increments are independent. Hence the third condi-
tion is satisfied. 
To show that the Wt satisfies the fourth condition. We only need to show that 
lim Wt = 0, 
a.s. 
t_j_O 
To do that, let tn + 0 and sn = 1/tn. Let Nn be the largest integer less than or equal 
to Sn. Then we have 
1 
N 
1 
Nn 
1 
Wt =-B =_____!.!:_-'"'(B-B_I)+-(B -BN)Â· 
'n 
Sn 
N 
L.....t 
2 
2 
Sn 
n 
Sn 
8n 
n i=l 
Sn 
But by Theorem 16.2, we have 
1 
Nn 
lim -
'"'(Bi- Bi-d= 0, 
a.s. 
n--+oo Nn L 
i=l 

Let 6 > 0. By Problem 19.17, for sufficiently large n, we have 
Hence 
By Problem 9.3, we have 
< 
2 ~ 
_1_ exp (- s~J2) 
L 
Skb 
2 
k=n 
00 
1 
< 2 L 82J2 
k=n 
k 
2 ( 1 1
00 1 
) 
< 
lj2 
s~ + sn x2 dx 
;2 (-;- + 2_) . 
u 
Sn 
Sn 
Therefore, limtn-l-0 Wtn = 0. This completes the proof. 
SOLUTIONS 
381 
28.6. 
Lets < t. Then by definition, X = Bt - Bs is normally distributed with 
mean 0 and variance t - s. By Problem 17 .4, we have 
By Problem 19.1, we have 
Mx(t) = e~a2t2. 
The fourth derivative of Mx(t) is 
which gives 
This completes the proof. 
28.7. The case when s = tis trivial. Suppose that s < t. Then by the definition 
of Brownian motion, the random variables Bs and Bt - Bs are independent normal 

382 
BROWNIAN MOTION 
random variables. Hence by Problem 19.3, aB8 + bBt = (a+ b)Bs + b(Bt- Bs) 
is normally distributed. In addition, the mean of aB8 + bBt is 0 and the variance is 
(a+ b) 2s + b2(t- s) = (a2 + 2ab)s + b2t. This completes the proof. 
28.8. 
(a) By Problem 28.7, the random variables tBt- ~Bs and aBu + bBv are normal 
random variables. By Problem 28.7, t Bt- ~ B 8 and aBu +bBv are independent 
if and only if 
E [ (~Bt- ~Bs) (aBu + bBv)] = E [~Bt- ~Bs] E[aBu + bBv]Â· 
(28.1) 
But E [tBt- ~Bs] = 0 and E[aBu + bBv] = 0. By Problem 28.2, we have 
E [ (~Bt- ~Bs) (aBu + bBv)] 
a 
a 
b 
b 
tE[BtBu]- -_;E[BsBu] + tE[BtBv]- ~E[BsBv] 
a-a+b-b 
0. 
Hence Equation (28.1) holds for all a, b E R. Therefore, tBt -
~Bs and 
aBu + bBv are independent. 
(b) Similar to part (a), aB8 + bBt and ~Bv- ~Bu are independent if and only if 
(28.2) 
Expanding the left-hand side of Equation (28.2) gives 
a 
b 
a 
b 
-s + -t- -s- -t = 0, 
v 
v 
u 
u 
which is equivalent to 
(as+ bt) ( ~- ~) = 0. 
Note that u < v. The above equation gives as+ bt = 0. 
This completes the proof. 

SOLUTIONS 
383 
28.9. Lets :::; t. Since Bt - Bs and Bu are independent for all u :::; s, it follows 
that Bt- Bs and $
8 are independent. By Problems 14.4 and 14.12, we have 
28.10. Let 0 :::; t1 < t2 < Â· Â· Â· < tn. Let Gi E o-(Wt; -
Wt;_ 1 ) fori = 1, 2, ... , n, 
where Wt 0 = 0. By Definitions 12.2 and 12.1, we only need to show that 
(28.3) 
By the assumption that Wtn - Wtn_ 1 is independent of $tn_ 1 and the fact that 
G1 n G2 n Â· Â· Â· n Gn-1 E $tn-I' we have 
Repeating the above calculation gives Equation (28.3). This completes the proof. 
28.11. 
Let N be an integer. Let t3 = -fvt for 1 S j :::; N. Let X 1 = Btt and 
Xj = Bti+1 - Bt; for j = 2, 3, ... , N. Then xl, x2, ... , XN are independent and 
symmetrically distributed normal random variables. Let 
j 
s3 = L xi, J = 1, 2, ... , N. 
i=l 
Then by Levy's inequality (see Problem 15.11), we have 
Now we show that 
lim P { max 83 :2: y} = P { max Bs :2: y} . 
(28.4) 
N -too 
1-:::,_j-:::,_N 
o-::;_s-::;_t 

384 
BROWNIAN MOTION 
To do that, let A = { w : Bt ( w) is continuous}. Then P( A) = 1. Since 
lim { max Sj :::0: y} n 
A = { max Bs :::0: y} n 
A, 
N--+oo 
l<::,j<::,N 
O<::,s<::,t 
we have 
P ( lim { max Sj ;::: y} n A) = P ({ max Bs ;::: y} n A) . 
N--+oo 
l<::,J<::,N 
O<::,s<::,t 
Since P(A) = 1, Equation (28.4) is true. This completes the proof. 
28.12. Let En be events defined as 
Since 
En= {limsupBt > n}, 
n = 1, 2, .... 
t--+oo 
{ limsup 
Bt 
= 1} C En 
Hoo yf2log log t 
-
for all n = 1, 2, ... , by Theorem 28.1, we have 
P(En) = 1, 
n :::0: 1. 
But by Problem 11.1, we have 
Similarly, we can show that 
P {liminf Bt = -oo} = 1. 
t--+oo 
This completes the proof. 
28.13. By Theorem 28.2, the two processes 
are standard Brownian motions independent of Â§:. Hence the concatenations 
( { Bt : 0 :::; t :::; T}, { B 7 + ( Bt+r - B 7 ) : t :::0: 0}) 
and 
( { Bt : 0 :::; t :::; T}, { Br - ( Bt+r - Br) : t :::0: 0}) 
have the same distribution. But note that the first concatenation is just { Bt : t :::0: 0} 
and the second one is just { Bt : t :::0: 0}. Hence { Bt : t :::0: 0} is a standard Brownian 
motion. This completes the proof. 

SOLUTIONS 
385 
28.14. Let { Bt : t ~ 0} be a process defined by 
Bt = {Bt, 
ift < Ta; 
2BTa - Bt ift ~ Ta. 
Then it follows from Problem 28.13 that { Bt : t ~ 0} _is a standard Brownian 
motion. Hence for every t ~ Ta, we have 2BT"' - Bt = Bt and Bt have the same 
distribution, which gives 
Since BT, = a, the above equation becomes 
By the assumption that f3 ~ a, we have 2a - f3 ~ a. Hence Bt ~ 2a - f3 implies 
that t ~ T a. Therefore, we get 
P{Ta ~ t,Bt ~ /3} = P{2a- (3 ~ Bt}. 
This completes the proof. 
28.15. 
(a) Let { Bt : t ~ 0} be the Brownian motion reflected at T (see Problem 28.13). 
Then we have 
Note that 
{ Mt > a} = { Bt > a} U { Mt > a, Bt ~ a}. 
We have 
{ Mt > a} = { Bt > a} U { Bt ~ a}, 
which gives 
P{Mt >a}= P{Bt >a}+ P{Bt ~a}= 2P{Bt >a}. 
(b) Note that 
{ T > x} = { max Bt < a} . 
O:St:Sx 
By part (a), we have 
P{T > x} = P {max Bt <a}= 1- 2P{Bx >a}. 
O:St:Sx 
Therefore, the cumulative density function is given by 
1
00 
1 
( 82) 
F(x) = P{T ~ x} = 2P{Bx >a}= 2 
r.c= exp --
ds. 
a 
v 21rx 
2x 

386 
BROWNIAN MOTION 
Taking the derivative of F(x) gives 
This completes the proof. 
28.16. Lett > 0, x > 0 andy ::; x. Then 
Let Tx = min{s ~ 0: B 8 = x}. Then {Mt ~ x} = {Tx :=; t}, which gives 
P{Mt ~ x,Bt::; y} = P{Tx::; t,Bt::; y}. 
(28.6) 
From Problem 28.14, we have 
P { T x :=; t, Bt :=; y} = P { Bt ~ 2x - y}. 
(28.7) 
Hence combining Equations (28.5), (28.6), and (28.7) gives 
1
00 1y 
1
00 
1 
( 
82 ) 
!M,,B,(r,s)dsdr = 
~exp --
ds. 
x 
-oo 
2x-y y 27rt 
2t 
Differentiating with respect to x in the above equation gives 
1
Y 
2 
( 
(2x-y)2) 
-
!M,,B,(x,s)ds=-
~exp -
. 
-oo 
y 27rt 
2t 
Differentiating with respect to y in the above equation gives 
2(2x-y) 
( 
(2x-y)2) 
-!M,,B,(x,y)=-
t-/21ft exp -
2t 
. 
This completes the proof. 
28.17. Let Xi = Bii) - B}il fori = 1, 2, ... , m. Then by Definition 28.3, we have 
where /jij is the Kronecker delta. Hence we have 
The independence of X1, X2, ... , Xm follows immediately from Problem 19.6. This 
completes the proof. 

BIBLIOGRAPHIC NOTES 
387 
28.5 Bibliographic Notes 
In this chapter, we presented Brownian motion and related problems. A Brownian 
motion is defined as a stochastic process satisfying certain properties. In fact, such 
stochastic processes exist and can be constructed mathematically in several ways. 
For example, Kuo (2006, Chapter 3) introduced three approaches of constructing 
Brownian motion: Wiener's method, Kolmogorov's method, and Levy's interpo-
lation method. The history of Brownian motion is discussed in Bhattacharya and 
Waymire (2007, Chapter XIII). 
Theorem 28.1 is a very interesting result of Brownian motions. Readers can find 
a proof of this theorem in Bhattacharya and Waymire (2007, p144). For a proof of 
Theorem 28.2, readers are referred to Hunt (1956). 
The definition of m-dimensional Brownian motion (see Definition 28.3) was adopted 
from Karatzas and Shreve (1991, Section 2.5). This definition implies that the incre-
ments of the components are independent (see Problem 28.17). For more informa-
tion about Brownian motion, readers are referred to Borodin and Salminen (2002), 
Shreve (2004), Wiersema (2008), and Morters and Peres (2010). 


CHAPTER 29 
MARKOV PROCESSES 
A Markov process is a stochastic process that has the Markov property. In other 
words, a stochastic process is called a Markov process if at every time t, the condi-
tional probability law of the process given the past depends only on the present state. 
Intuitively, a Markov process is a process that does not have memory. In this chapter, 
we present the mathematical definition of Markov processes and relevant results. 
29.1 
Basic Concepts and Facts 
Definition 29.1 (Conditional Independence). Let (0, Â§, P) be a probability space. 
LetÂ£, Â§ 1, ... , Â§n be sub-a-algebras ofÂ§. Then Â§ 1, ... , Â§n are said to be 
conditionally independent given Â£ if 
n 
E[V1 v2 ... Vni.Ye] =II E[VilÂ£], 
i=1 
where Vi is an arbitrary positive random variable in mÂ§i, i 
mÂ§i is the set of all Â§i-measurable functions. 
1, 2, ... , n. Here 
Measure, Probability, and Mathematical Finance. 
389 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

390 
MARKOVPROCESSES 
Definition 29.2 (Markov Process). Let I be an index set. Let (D, Â§, P) be a 
probability space and { Â§t : t E I} be a filtration over the probability space. 
Let { Xt : t E I} be a stochastic process adapted to the filtration. The process 
{ Xt : t E I} is called a Markov process relative to the filtration if for every t E I, 
the past Â§t and the future !:f!x, = a(Xu : u 2:: t, u E I) are conditionally indepen-
dent given the present state Xt. 
Definition 29.3 (Transition Kernel). Let (E, !&") and (F, Â§) be two measurable 
spaces. A transition kernel from (E, !&") to (F, Â§) is a mapping K : (E, Â§) --+ 
[0, oo] with the following properties: 
(a) For every set B E Â§,the mapping x--+ K(x, B) is !&"-measurable. 
(b) For every x E E, the mapping B--+ K(x, B) is a measure on (F, Â§). 
A transition kernel from ( E, !&") to ( E, !&") is called a transition kernel on ( E, !&"). 
Definition 29.4 (Markov Kernel). Let (E, !&") be a measurable space. A Markov 
kernel on (E, !&") is a transition kernel K on (E, !&") such that for every x E E, we 
have 
K(x,E) = 1. 
Definition 29.5 (Identity Kernel). Let (E, !&") be a measurable space. An identity 
kernel on (E, !&")is a transition kernel I on (E, !&") such that for every x E E, 
I(x, A)= IA(x), 
A E 0", 
where I A ( Â·) is the indicator function. 
Definition 29.6 (Product of Kernels). Let K be a transition kernel from (E, !&")into 
( F, Â§), and let L be a transition kernel from ( F, Â§) into ( G, !:f). Then their product 
is a transition kernel K L from ( E, !&") into ( G, !:f) defined as 
KL(x,B) = l K(x,dy)L(y,B), 
x E E, BE 1:Â§. 
Definition 29.7 (Markovian Transition Function). Let ( E, !&") be a measurable space. 
Let { Pt,u : 0 ::::; t ::::; u} be a family of Markov kernels on (E, !&") indexed by pairs of 
times t and u. It is called a Markovian transition function on ( E, !&") if it satisfies the 
Chapman-Kolmogorov equation 
(29.1) 
Definition 29.8 (Markov Process with a Transition Function). Let { Xt : t E I} be 
a Markov process with some state space (E,i&"). Let {Pt,u: t,u E I,t::::; u} be 
a transition function on (E, !&"). The Markov process is said to admit the transition 
function if for every positive g -measurable function, we have 

PROBLEMS 
391 
where Pt,u! is the product of Pt,u and f (see Theorem 29.1). 
Definition 29.9 (Time-Homogeneous Markov Process). Let { Xt : t E I} be a 
Markov process that admits { Pt,u : 0 :::; t :::; u} as a transition function. The Markov 
process is said to be time-homogeneous if for every time t and time u > t, the 
dependence of Pt,u on the pair (t, u) is through u- t only, that is, 
Pt,u =Pu-t 
for some Markov kernel Pu-tÂ· 
Definition 29.10 (Markov Chain). A stochastic process { Xt : t E I} is said to be a 
Markov chain if the process is a time-homogeneous Markov process and I = N. 
Theorem 29.1 (Measure, Kernel, and Function). Let K be a transition kernel from 
( E, 0") into ( F, $). Let f be a positive Â§-measurable function and J.L a measure on 
(E,6"). Then 
(a) The function K f defined as 
Kf(x) = l K(x,dy)f(y), 
x E E, 
is a positive 6" -measurable function. 
(b) The function J.LK defined as 
J.LK(B) = lJ.L(dx)K(x,B), BEÂ§, 
is a measure on (F, $). 
(c) 
(J.LK)f = J.L(Kf) = lJ.L(dx) l K(x,dy)f(y). 
29.2 Problems 
29.1. Let (0, Â§, P) be a probability space. LetÂ£, Â§ 1 , and Â§ 2 be sub-a--algebras 
ofÂ§. Show that the following are equivalent: 
(a) $1 and Â§ 2 are conditionally independent givenÂ£. 
(b) For every positive random variable V2 E m$2, we have 
where .Ye V $1 is the a--algebra generated by .Ye U Â§ 1 . 

392 
MARKOVPROCESSES 
(c) For every positive random variable V2 E mÂ§2 , we have 
29.2. Let { Xt : t E I} be a stochastic process with some state space ( E, lff) and 
adapted to a filtration { Â§t : t E I}. Let~!, = a(Xu : u ~ t, u E I). Show that the 
following are equivalent: 
(a) The process {Xt : t E I} is a Markov process with respect to the filtration 
{Â§t: t E I}. 
(b) For every t E I, u > t (u E I), and positive function f E mlff, we have 
(29.2) 
(c) For every t E I and positive random variable V E m~!,, we have 
(29.3) 
(d) For every t E I and every V of the form 
n 
V = II fi(XuJ, 
i=l 
where n ~ 1, t :s; u 1 :s; u2 :s; Â· Â· Â· :s; Un, and h, ... , fn are bounded continuous 
functions in mlff, the following equation holds: 
(29.4) 
(e) For every t E I and positive random variable V E m~!,, we have 
(29.5) 
that is, E[VIÂ§t] is a(Xt)-measurable. 
29.3. Let K be a transition kernel from (E, lff) into (F, Â§),and let L be a transition 
kernel from ( F, Â§) into ( G, ~). Show that 
(a) For every x E E and BEÂ§, we have 
K(x, B)= KIB(x), 
where I B ( Â·) is the indicator function. 
(b) For every positive ~-measurable function J, we have 
(KL)f = K(Lj), 
where K L is the product of K and L. 

HINTS 
393 
29.4. Let {Xt : t E I} be a Markov process with some state space (E, rff) that 
admits { Pt,u : t, u E I, t ~ u} as a transition function. Let x E E. Show that 
Pt,u(x,A) = P{Xu E AIXt = x}, 
A E rff. 
29.5. Let {Xt : t 2: 0} be a Markov process with state space (E, rff) and transition 
function {Pt,u : 0 ~ t ~ u}. Let {yt : t 2: 0} be a stochastic process defined as 
yt = (t,Xt), 
t E [O,oo). 
Show that 
(a) The process {yt : t 2: 0} is a Markov process with state space (F, $") 
([O,oo) x E,B[O,oo) Â®rff). 
(b) The process {yt : t 2: 0} is time-homogeneous. 
(c) The transition function for {yt : t 2: 0} is given by 
Qtf(y) = L 
Ps,s+t(X, dz)f(s + t, z), 
y = (s, x) E F, 
where f is an arbitrary positive Â§-measurable function. 
29.6. Let { Pt,u : 0 ~ t ~ u} be the transition function of a Markov process { Xt : 
t 2: 0}, which is adapted to some filtration { Â§t : t 2: 0}. Show that the transition 
function is Markovian: 
29.7. Let { Bt : t 2: 0} be a Brownian motion adapted to some filtration { Â§t : t 2: 
0}. Show that 
(a) The Brownian motion { Bt : t 2: 0} is a Markov process relative to the filtration. 
(b) The transition function for the Brownian motion is given by 
1 
1 
( (y- x)2) 
Pt,u(x, A) = 
exp - 2( 
) 
dy, 
A yl21r(u-t) 
u-t 
0 ~ t < u. 
29.3 Hints 
29.1. 
Use the results of Problems 14.2, 14.15, and 2.16 to show that part (a) is 
equivalent to part (b). Then show that parts (b) and (c) are equivalent. 
29.2. 
Use the definition of Markov processes (Definition 29.2) and the results of 
Problems 21.12 and 29.1. First show that part (a) is equivalent to part (c) and that 
part (d) is equivalent to part (e). Then show that part (c) ===} part (b) ===} part (d). 
Finally, show that part (e) ===} part (c). 

394 
MARKOVPROCESSES 
29.3. Part (a) can be proved by using the definition of kernel and function compo-
sition (see Theorem 29.1). To prove part (b), use the third result of Theorem 29.1 to 
show that (KL)f(x) = K(Lf)(x) for x E E. 
29.4. Use the definition of Markov processes with a transition function (Definition 
29.8) to establish 
P(Xu E AIXt) = Pt,u(Xt, A). 
Then note that how P(Xu E AIXt = x) is interpreted (see Section 14.5). 
29.5. 
Part (a) follows from the definition of Markov processes directly. To prove 
part (b), one can show that 
To prove part (c), one can use the following equation 
29.6. Use the definition of Markov processes with a transition function (Definitionn 
29.8), the result of part (b) of Problem 29.2, and the tower property of conditional 
expectations (see Problem 14.10). 
29.7. Use the results of Problems 29.2 and 14.13 to prove part (a). Use Definition 
29.8, part (a) of this problem, and the result of Problem 14.13 to prove part (b). 
29.4 Solutions 
29.1. 
We first show that part (a) is equivalent to part (b). Note that part (a) is 
equivalent to 
(29.6) 
where vl and v2 are arbitrary positive random variables in mÂ§'l and mÂ§'2. respec-
tively. By Problem 14.15, Equation (29.6) is equivalent to 
(29.7) 
By the definition of conditional expectation (Definition 14.1), Equation (29.7) is 
equivalent to 
By the monotone convergence theorem (Theorem 6.2), we can show that Equation 
(29.8) is equivalent to 

SOLUTIONS 
395 
But by Problem 14.2, Equation (29.9) is equivalent to 
which is part (b). 
Now we show that part (b) is equivalent to part (c). It is clear that part (b) implies 
part (c). Conversely, assume that part (c) holds. Then by the definition of conditional 
expectation, we have 
(29.10) 
which implies that 
i E[V2IÂ£' V $"1]dP = i V2dP, 
\fA E Â£'. 
(29.11) 
Note that E[V2IÂ£' V $"1] EmÂ£'. We have 
Hence part (b) is true. This completes the proof. 
29.2. Let V be a positive random variable that is measurable with respect to ~~. 
Then by Problem 29.1, part (a) is equivalent to 
E[VIÂ§t v a(Xt)] = E[VIa(Xt)]. 
Since { Xt : t E J} is adapted to { Â§t : t E J}, we have a(Xt) ~ Â§t. Hence part (a) 
is equivalent to 
E[VIÂ§t] = E[VIa(Xt)] = E[VIXt]. 
Therefore, part (a) is equivalent to part (c). It follows from Problem 21.12 that part 
(d) is equivalent to part (e). 
It is obvious that part (c) implies part (b). Now we show that part (b) ===> part 
(d). To do that, we use the induction method. Fork= 1, we have 
E[!l(XuJIÂ§t] 
E[fi(XuJIÂ§t]- E[f!(Xul)lÂ§t] 
E[fi(Xu1 )1Xt]- E[f1(Xu1)1Xt] 
E[f1(XuJIXt] E ma(Xt)Â· 
Hence part (d) holds. Suppose that part (d) holds fork. Then for n = k + 1, 
E(E[Vk+llÂ§uk]lÂ§t) 
E(VkE[fk+l (Xuk+l) lÂ§uk]lÂ§t) 
E(Vkg(Xuk) lÂ§t) 
E 
ma(Xt)Â· 

396 
MARKOV PROCESSES 
Here E[fk+I (Xuk+ 1 )lÂ§uk] E u(Xuk). By Theorem 11.2, E[fk+l (Xuk+ 1)lÂ§uJ is 
a function of X uk. Hence part (d) holds for k + 1. 
It follows from Problem 29.1 that part (e) implies part (c). This completes the 
proof. 
29.3. 
(a) By Theorem 29.1, we have 
KIB(x) = l K(x,dy)IB(Y) = l K(x,dy). 
(29.12) 
Note that by the definition of transition kernels (Definition 29.3), K(x, Â·)is a 
measure for every x. Hence from Equation (29.12), we have 
KIB(x) = K(x, B). 
(b) Let x E E be fixed. Let ILx(B) = K(x, B) forB E Â§. Then by Theorem 
29.1, we have 
P,xL(C) = liLx(dy)L(y, C) = l K(x, dy)L(y, C), 
C E r.1. 
(29.13) 
Again by Theorem 29.1 and Equation (29.13), we have 
(KL)f(x) 
[ KL(x, dz)f(z) 
[ J(z) l K(x, dy)L(y, dz) 
[ f(z)p,xL(dz) 
(p,xL)J 
ILx(LJ) 
lP,x(dy) [ L(y, dz)f(z) 
K(LJ)(x). 
Since xis arbitrary, it follows that (K L )! = K(LJ). 
This completes the proof. 
29.4. Let x E E and A E g be fixed. Letting f(Â·) = IA(Â·) in Definition 29.8 gives 
E[IA(Xu)IXt] = (Pt,uiA)(Xt) = l Pt,u(Xt, dy)IA(y). 
(29.14) 
Note that P(Xu E AIXt) = E[IA(Xu)IXt] and Pt,u(Xt, Â·)is a measure. From 
Equation (29.14), we have 
(29.15) 

SOLUTIONS 
397 
Hence Pt,u(Xt, A) is the conditional probability of {Xu E A} given a(Xt). There-
fore, we have 
Pt,u(x, A)= P(Xu E AIXt = x). 
This completes the proof. 
29.5. 
(a) Let{~ : t ~ 0} be the filtration to which the process {Xt : t ~ 0} is adapted. 
By Problem 29.2, to prove that {yt : t ~ 0} is a Markov process, we only need 
to show that 
E[f(Yu)l~] = E[f(Yu)IYt], 
0:::; t:::; u, 
(29.16) 
where f is a positive $-measurable function. But since f(t, Â·)is a nonnegative 
g -measurable function, we have 
E[f(Yu)l~] = E[f(u,Xu)l~] = E[f(u,Xu)IXt]Â· 
(29.17) 
Now by the definition of conditional expectation (Definition 14.1), for any C E 
a(Xt). we have 
{ 
E[f(Yu)IYt]dP 
J{u}xC 
{ 
f(Yu)dP 
J{u}xC 
lf(u,Xu)dP 
l E[f(u,Xu)IXt]dP. 
(29.18) 
Since Equation (29.18) holds for any C E a(Xt). we have E[f(Yu)IYt] 
E[f(Yu)IXt] a.s. Hence Equation (29.16) holds. 
(b) To show that {yt : t ~ 0} is time-homogeneous, we only need to show that 
But 
and 
E[f(Ys2+t)IYs 2 = (s, x)] = E[f(Ys+t)IXs = x], 
it follows that Equation (29.19) holds. 
(c) Since {yt : t ~ 0} is time-homogeneous, for y = (s, x), we have 
Qtf(y) 
E[f(Yr+t)IYr = y] 
E[f(Ys+t)IXs = x] 
E[f(s + t, Xs+t)IXs = x] 
Ps,s+tf(s + t, x) 
h 
Ps,s+t(x,dz)f(s+t,z). 
(29.19) 

398 
MARKOVPROCESSES 
This finishes the proof. 
29.6. Let f be a positive Borel function. Let 0 :::; s < t :::; u. Then by Problems 
29.2 and 14.10, and Definition 29.8, we have 
But by Theorem 29.1, we have 
E[f(Xu)[Xs] 
E[J(Xu)[Â§s] 
E(E[f(Xu)[Â§t][Â§s) 
E(Pt,uf(Xt)[Â§s) 
Ps,t(Pt,uf)(Xs) 
Hence Ps,u = Ps,tPt,uÂ· This finishes the proof. 
29.7. Let 0 :::; t < u be fixed. 
(a) By Problem 29.2, we only need to prove that 
(29.20) 
To do this, let cp(x) = E[f(Bu- Bt + x)]. Since Bu- Bt is independent of 
Â§t and Bt is $t-measurable, it follows from Problem 14.13 that 
(29.21) 
Similarly, since Bu- Bt is independent of a(Bt) and Bt is a(Bt)-measurable, 
it follows from Problem 14.13 that 
(29.22) 
Hence Equation (29.20) follows by combining Equations (29.21) and (29.22). 
(b) By Theorem 29.1, we have 
By Definition 29.8 and the first item, we have 
where 
E[iA(Bu)[Xt] 
E[IA(Bu- Bt + Bt)[Xt] 
cp(Bt), 
cp(x) = E[IA(Bu- Bt + x))] = P{Bu- Bt + x E A}. 

BIBLIOGRAPHIC NOTES 
399 
Note that Bu- Bt +X rv N(x, u- t), that is, Bu- Bt +X is a normal random 
variable with mean x and variance u - t. Then we have 
-
{ 
1 
( (y-x)2)d 
<p(x)- }A y'21r(u-t) exp -2(u-t) 
y. 
Combining the above equations gives 
1 
1 
( (y- x)2) 
Pt,u(x, A)= 
exp -
( 
) 
dy. 
A y'21r(u-t) 
2 u-t 
This completes the proof. 
29.5 Bibliographic Notes 
In this chapter, we defined Markov processes and relevant concepts. The defini-
tion of Markov processes (see Definition 29.2) is adopted from <;inlar (2011). For 
more information about Markov processes, readers are referred to Friedman (1975), 
Ethier and Kurtz (1986), Kannan and Lakshmikantham (2001), Klebaner (2005), 
Stroock (2005), and <;inlar (2011). For information about Markov chains, readers 
are referred to Hoe1 et al. (1972), Ross (1995), Kao (1997), Tijms (2003), Stirzaker 
(2005), Lawler (2006), Beichelt (2006), and Bhattacharya and Waymire (2009). 


CHAPTER 30 
LEVY PROCESSES 
Levy processes are stochastic processes that have independent and stationary incre-
ments. The basic theory of Levy processes was established in the 1930s. Recently, 
Levy processes have been used as asset price models in mathematical finance. In this 
chapter, we present Levy processes and their main properties. 
30.1 
Basic Concepts and Facts 
Definition 30.1 (Levy Process). Let (0, Â§, P) be a probability space and { Â§t 
t ~ 0} a filtration on the probability space. A stochastic process X= {Xt : t ~ 0} 
is called a Levy process in R d with respect to { Â§t : t ~ 0} if it is adapted to the 
filtration and 
(a) For almost every w, the path t--+ Xt(w) is right-continuous with left limit and 
Xa(w) = 0. 
(b) For every t and h in [0, oo ), the increment Xt+h- Xt is independent of Â§t and 
has the same distribution as X h. 
Measure, Probability, and Mathematical Finance. 
401 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

402 
LEVY PROCESSES 
A process {yt : t 2: 0} is considered a Levy process, without mentioning a filtration, 
if it is a Levy process with respect to the filtration generated by itself. 
Definition 30.2 (Jump). Let { Xt : t 2: 0} be a Levy process. For every w E n and 
every t E [0, oo), let 
Xt_(w) = limXx(w), 
Xt+(w) = limX8 (w) = Xt(w). 
xtt 
s{.t 
Here Xt- (w) = 0 fort = 0. If Xt_(w) =1- Xt(w), we say that the path Xt(w) jumps 
from its left limit Xt_(w) to its right-hand value Xt(w). The size of the jump is 
given by 
~Xt(w) = Xt(w)- Xt_(w). 
The jump magnitude is I~Xt(w)l. The discontinuity set for the path Xt(w) is de-
noted by 
Dw = {t > 0: ~Xt(w) =/:- 0}. 
Definition 30.3 (Pure-Jump Process). A Levy process is called a pure-jump process 
if for every t 2: 0, Xt is equal to the sum of the sizes of its jumps during [0, t]. That 
is, for almost every w, we have 
Xt(w) = L 
~X8 (w), t E [0, oo), 
sEDwn[O,t) 
where the sum on the right-hand side converges absolutely: 
Vt(w) = 
L 
I~Xs(w)l < oo. 
sEDwn[O,t) 
Here vt (w) denotes the total variation of the path Xt(w) over [0, t]. 
Definition 30.4 (Jump-Diffusion Process). A stochastic process {Xt 
t > 0} is 
called a jump-diffusion process if it has the following form 
N, 
Xt = at+ aBt + L Zn, 
n=l 
where a E R, a 2: 0, { Bt : t 2: 0} is a standard Brownian motion, { Nt : t 2: 0} 
is a Poisson process, and { Zn : n = 1, 2, ... } is a sequence of independent and 
identically distributed random variables that is independent of { Nt : t 2: 0}. The 
Poisson process {Nt: t 2: 0}, the sequence {Zn: n = 1, 2, ... }, and the Brownian 
motion { Bt : t 2: 0} are assumed to be independent. 
Definition 30.5 (Infinitely Divisibility). A probability distribution F on (R, B) is 
said to be infinitely divisible if for any integer n 2: 2, there exists n independent 
and identically random variables Y1, Y2, ... , Yn such that Y1 + Y2 + Â· Â· Â· + Yn has 
distribution F. 

BASIC CONCEPTS AND FACTS 
403 
A random variable X is said to be infinitely divisible if and only if for each n ~ 1, 
X has the same distribution as the sum of n independent and identically distributed 
random variables. 
Definition 30.6 (Random Measure). Let (!1, ~. P) be a probability space and (E, 
6") a measurable space. A random measure on ( E, 6") is a transition kernel from 
(n, ~)into (E, 6"); that is, a mapping M : n X 6"-+ [0, oo] if 
(a) For every A E 6", M(A) : w-+ M(w, A) is a random variable. 
(b) For every wEn, Mw :A-+ M(w, A) is a measure on (E, 6"). 
Definition 30.7 (Levy Measure). A Levy measure v is a Borel measure defined on 
R\{0} = {x E R: x =/= 0} such that 
{ 
(y2 A 1)v(dy) < oo. 
jR\{0} 
A Levy measure v can be extended to the whole real line R by assigning 
v({O})=O. 
Definition 30.8 (Poisson Random Measure). Let (E, 6") be a measurable space. Let 
v be a measure on (E, 6"). A random measure N on (E, 6") is called a Poisson 
random measure with mean v if it satisfies the following conditions: 
(a) For every A E 6", the random variable N(A) has a Poisson distribution with 
mean v(A). 
(b) For every integer n ~ 2, if A 1 , A2 , ... , An E 6" are disjoint, then the random 
variables N(A1), N(A2), ... , N(An) are independent. 
Theorem 30.1 (Uvy-Khintchine Formula). A probability distribution F of a real-
valued random variable is infinitely divisible if and only if there exists a triplet 
(a, u, v ), where a E R, u ~ 0, and v is a Levy measure, such that for all() E R, 
L 
eiOxJ.tp(dx) 
L 
eiOxdF(x) 
exp (ia()- ~u2()-L 
(1- eiex + iOxi(- 1,l)(x)) v(dx)) , 
where J.tF is the Lebesgue-Stieltjes measure corresponding to F and J(-1,1)(Â·) is an 
indicator function. 
Theorem 30.2 (Levy Processes and Infinitely Divisible Distributions). If {Xt : t ~ 
0} is a Levy process, then for every t, Xt has an infinitely divisible distribution. 

404 
LEVY PROCESSES 
Conversely, ifF is an infinitely divisible distribution, then there exists a Levy process 
{ Xt : t 2: 0} such that the distribution of X 1 is F. 
Theorem 30.3 (Characteristic Function of a Levy Process). Let {Xt : t ;:::: 0} be a 
Rd-valued Levy process. Then for each t 2: 0, the characteristic function of Xt is 
given by 
Â¢x,(u)=etry(u), 
't:/uERd, 
where ry( u) is a continuous function, which is said to be the characteristic exponent 
of the process. 
Theorem 30.4 (Existence of Poisson Random Measure). For any given u-finite mea-
sure space (S, ~ â¢ .X), there exists a Poisson random measure M on some probability 
space (O.,Â§,P) such that .X(A) = E(M(A))forall A E ~-
Theorem 30.5 (Levy-Ito Decomposition). Let {Xt : t ;:::: 0} beaR-valued Levy 
process. Then 
Xt = bt + uBt + 1 xNt(dx) + 1 xNt(dx), 
JxJ<l 
Jxj:;::l 
where 
b = E [xl -1 
xN1(dx)], 
Jxj:;::l 
u 2: 0, { Bt : t 2: 0} is a standard Brownian motion, Nt is a Poisson random 
measure on (R\{0}, B(R\{0} )) defined as 
Nt(A)(w) = I{O:::; s:::; t: Xs(w)- Xs_(w) E A}l, 
t 2: 0, A E B(R\{0} ), 
and 
Here I Â· I denotes the number of elements in a set. 
30.2 Problems 
30.1. Let {Xt : t ;:::: 0} be a Levy process. For every t ;:::: 0, show that Xt is an 
infinitely divisible random variable. 
30.2. Let F be a Poisson distribution with parameter .X > 0. Show that F is infinitely 
divisible. 
30.3. Let N be a Poisson random variable with parameter .X > 0 and {li : i = 
1, 2, ... } a sequence of independent and identically distributed random variables 
having distribution F. Suppose that N is independent of {li : i = 1, 2, ... } and 

PROBLEMS 
405 
that J-lF( {0}) = 0, where J-lF is the Lebesgue-Stieltjes measure corresponding to F. 
Let X be a compound Poisson random variable defined as 
N 
X= LYiÂ· 
i=1 
Show that X has an infinitely divisible distribution with the Levy-Khintchine triplet 
(a, a, v) given by 
a=,\ [
1
1 XJ-lF(dx), 
a= 0, 
v = Af-lFÂ· 
30.4. Let X be a normal random variable with a distribution F given by 
dF(x) = 
~ 
exp (- (x -;)2 ) dx, 
sv2n 
2s 
where s > 0 and 'Y E R are constants. Show that F is an infinitely divisible distri-
bution with the Levy-Khintchine triplet (a, a, v) given by 
a= "f, 
a= s, 
v = 0. 
30.5. Let {yt : t ~ 0} be a compound Poisson process defined as 
N, 
yt = L Zn, 
t ~ 0, 
n=1 
where {Nt : t ~ 0} is a Poisson process and {Zn : n = 1, 2, ... } is a sequence 
of independent and identically distributed random variables that is independent of 
{Nt: t ~ 0}. Show that {yt: t ~ 0} is a Levy process. 
30.6. Let {Xt : t ~ 0} and {yt : t ~ 0} be two independent Levy processes. Show 
that {Xt + yt : t ~ 0} is also a Levy process. 
30.7. Let {Xt : t ~ 0} be a Levy process with characteristic exponent ry(Â·). For any 
() E R, show that 
{exp (i()Xt- try(())): t ~ 0} 
is a martingale. 
30.8 (Markov Property). Let {Xt : t ~ 0} be a Levy process adapted to some 
filtration {$t: t ~ 0}. Show that {Xt: t ~ 0} is a Markov process with respect to 
the filtration. 
30.9. Let {Xt : t ~ 0} be a jump-diffusion process as defined in Definition 30.4. 
For every t ~ 0 and A E B(R), define 
N, 
Mt(A) = L IA(Zn), 
n=O 

406 
LEVY PROCESSES 
where I A ( Â·) is an indicator function. Let v be a set function defined as 
v(A) = E[MI(A)], 
A E B(R). 
Suppose that N 1 has a Poisson distribution with parameter>. and Z1 has a distribution 
function F. Show that 
(a) The process { Xt : t 2': 0} is a Levy process. 
(b) For every t 2': 0, Mt is a random measure. 
(c) For every t 2': 0, Mt is a Poisson random measure with mean tv. 
(d) The set function vis a finite measure on (R, B(R)) and 
v(A) = AJ-tp(A), 
A E B(R), 
where /-tF is the Lebesgue-Stieltjes measure corresponding to F. 
(e) The characteristic exponent of {X t : t 2': 0} is given by 
ry(u) = iau- ~a2u + r (eiux- 1) v(dx). 
2 
jR 
30.10. Let { Xt : t 2': 0} be a jump-diffusion process as defined in Definition 30.4. 
For every t 2': 0, let Mt be a Poisson random measure (see Problem 30.9) defined as 
N, 
Mt(A) = L JA(Zn), 
A E B(R). 
n=O 
Let v be a measure (see Problem 30.9) defined as 
v(A) = E[M1 (A)], 
A E B(R). 
Let {yt : t 2': 0} be a process defined by 
Â¥t = L 
xMt(dx) = L 
xMt(dx)-L 
xtv(dx), 
where Mt = Mt- tv. Show that 
(a) For every t > 0, we have 
N, 
L ~Xs = L Zn, 
a.s., 
O<s::Ot 
n=l 
where ~Xs = Xs- Xs-Â· 

HINTS 
407 
(b) For every t > 0, we have 
N, 
{ 
L Zn = }F xMt(dx), 
n=l 
R 
a.s. 
(c) If IJR xv(dx)i < oo, then {yt: t ~ 0} is a martingale and E[yt] = 0: 
E [L xMt(dx)] = t L 
xv(dx). 
(d) If IJR x2v(dx)l < oo, then 
Var(yt) = t L 
x2v(dx). 
30.3 Hints 
30.1. Follow the definition of Levy processes (Definition 30.1) and the definition of 
infinitely divisible random variables (Definition 30.5). 
30.2. Apply the Levy-Khintchine formula (Theorem 30.1). 
30.3. Apply the Levy-Khintchine formula (Theorem 30.1). 
30.4. Use the result of Problem 19.1 and apply the Levy-Khintchine formula (The-
orem 30.1). 
30.5. Follow the definition of Levy processes (Definition 30.1) and the definition of 
Poisson processes (Definition 27.1). 
30.6. Follow the definition of Levy processes (Definition 30.1). 
30.7. Follow the definition of characteristic exponent (see Theorem 30.3) and the 
definition of martingales (Definition 22.1 ). 
30.8. Use the result of Problem 14.13 to show that for all positive Borel function f, 
E[j(Xt)lÂ§s] = E[f(Xt)IXs], 
0 s; s < t. 
Then apply the result of Problem 29.2. 
30.9. To prove part (a), use the results of Problems 30.6 and 27.9, and the defini-
tions of Brownian motion (Definition 28.1). To prove part (b), follow the definition 
of random measures (Definition 30.6). To prove part (c), follow the definition of 
Poisson random measures (Definition 30.8) and use Kac's theorem (Theorem 17.2). 
To prove part (d), first show that v(A) = Af.tF(A). To prove part (e), use the results 
of Problems 30.3 and 30.4. 
30.10. To prove part (a), note that almost all paths of { N 8 
: 0 s; s s; t} have finite 
number of jumps. To prove part (b), use the result of Problem 5.11 and the monotone 
convergence theorem (Theorem 6.2). Use the result of part (b) to prove part (c). Use 
the results of parts (b) and (c) to prove part (d). 

408 
LEVY PROCESSES 
30.4 Solutions 
30.1. Let n ;::: 2 be an integer. For each t. we can express Xt as 
n 
Xt = L~(k)' 
Ac=l 
where 
(k) 
~ =XM -X(k-Â·'l'Â· 
n 
n 
By the definition of Levy processes (Definition 30. I), ~(1), ~( 2 ), ... , ~(n) are in-
dependent and identically distributed random variables. Hence Xt is an infinitely 
divisible random variable. This completes the proof. 
30.2. Let /1F be the Lebesgue-Stieltjes measure corresponding to F. Then we have 
and 
r eitx /1F(dx) = f eitke->. ,\~ = exp ( -,\ + ,\eit). 
JR 
k=O 
k. 
Let a = a = 0 and v = .\51 , where 51 is the Dirac measure supported on { 1}: 
5l(A) = { 1, 
0, 
Then we have 
ifl E A; 
if1 ~A, 
\fA E B(R). 
It follows from Theorem 30. I that F is infinitely divisible. This completes the proof. 
30.3. Let G be the distribution of X. Then we have 
L 
eiexJlc(dx) 

SOLUTIONS 
409 
Comparing the above equation with the Levy-Khintchine formula gives 
a= A j_
1
1 XJLp(dx), 
a= 0, 
v = AJLFÂ· 
Hence it follows from Theorem 30.1 that G is infinitely divisible. This completes the 
proof. 
30.4. By Problem 19.1, we have 
L 
eilixJLp(dx) = E [eiliX] = exp (i')'O- ~s2 82). 
Comparing the above equation with the Levy-Khintchine formula gives 
a=')', a=s, 
v=O. 
By Theorem 30.1, F is infinitely divisible. This finishes the proof. 
30.5. 
By Definition 27.1, {Nt : t ~ 0} is right-continuous with left limit and 
P { N 0 = 0} = 1. Hence { yt : t ~ 0} is right -continuous with left limit and 
P{Yo = 0} = P{No = 0} = 1. 
Let h ~ 0. Then 
Nt+h 
Yt+h- yt = L 
ZnÂ· 
n=Nt+l 
30.6. Let Zt = Xt + yt for all t ~ 0. To show that { Zt : t ~ 0} is a Levy process, 
we only need to verify that it satisfies the two conditions in Definition 30.1. 
Since {Xt : t ~ 0} and {yt : t ~ 0} are Levy processes, we have P( {Xo = 
0} n {Yo= 0}) = 1 (see Problem 11.1). Hence Z0 = X 0 +Yo= 0 a.s. In addition, 
by Problem 1.1 0, for every s ~ 0, we have 
limZt = limXt +lim yt = X 8 + Y8 , 
t.j.s 
t.j.8 
t.j.8 
and for every s > 0, we have 
limZt = limXt +lim yt = X8- + Y8 _. 
~8 
~8 
~8 
Hence { Zt : t ~ 0} satisfies the first condition. 
Let Â§t = a(Z8 
: 0 ~ s ~ t) and Y4 = a(X8 , Y8 
: s ~ t) for all t ~ 0. Then we 
have 
Â§t <;;; .Ytt, 
t ~ 0. 
Since {Xt : t ~ 0} and {yt : t ~ 0} are independent Levy processes, Zt- Z 8 = 
(Xt- X 8 ) + (yt - Y8 ) is independent of .Yes and thus Zt- Z 8 is independent of 
Â§8. In addition, Zt - Z 8 has the same distribution as Xt-8 + yt_8 = Zt- 8 â¢ Hence 
{ Zt : t ~ 0} satisfies the first condition. 

410 
LEVY PROCESSES 
This completes the proof. 
30.7. 
Let {Â§t : t ~ 0} be the filtration generated by {Xt : t ~ 0}. Then the 
process { exp ( iBXt - try( B)) : t ~ 0} is adapted to the filtration. In addition, we 
have 
E[l exp (iBXt- try( B)) I]= 1 < oo. 
For 0 :::; s < t, we have 
E[exp (iBXt- try( B)) lÂ§s] 
E[exp (iB(Xt- Xs)) exp(iBXs- try(B))IÂ§s] 
E[exp (iB(Xt- Xs))] exp(iBXs- try( B))) 
exp (iBX8
-
try( B)) ei(t-s)'1(1!) 
exp (iBXs- sry(B)). 
This completes the proof. 
30.8. Let 0 :::; s < t be fixed. Let f be a positive Borel function. Let Y = Xt- X 8 â¢ 
Since { Xt : t ~ 0} is a Levy process, Y is independent of Â§s. Then by Problem 
14.13, we have 
where g(x) = E[f(Y + x)]. Since Y is also independent of a(Xs), by Problem 
14.13 we have 
Hence 
It follows from Problem 29.2 that {Xt : t ~ 0} is a Markov process. This completes 
the proof. 
30.9. 
(a) By Definition 28.1, the Brownian motion {aBt : t ~ 0} is a Levy process. 
By Problem 30.6, we only need to show that the compound Poisson process 
{'2:=~~ 1 Zn : t ~ 0} is a Levy process. To do that, let 
N, 
yt = L Zn, 
t ~ 0. 
n=l 
Then P{Yo = 0} = P{No = 0} = 1. By Problem 27.9, Yi+h - yt is 
independent of a(Ys : 0 :::; s :::; t) and Yi+h - yt has the same distribution as 
Yh. Hence {yt : t ~ 0} is a Levy process. 

SOLUTIONS 
411 
(b) Suppose that { Nt : t ;::: 0} and { Z 1 , Z2 , ... } are defined on a probability space 
(O,ff,P). 
Let A E B(R) and t ;::: 0 be fixed. We show that Mt(A) is a random variable. 
To do that, letHE B(R). Then 
{Mt(A) E H} = U _ [u ({Nt = i} n {t IA(Zn) = k})] E .'7, 
kEHnN 
22':0 
n=O 
where N = {0, 1, 2, ... }. Since His arbitrary, Mt(A) is Â»>-measurable. Hence 
Mt (A) is a random variable. 
Now let w E 0 and t ;::: 0 be fixed. We show that Mt,w is a measure on 
(R, B(R) ). In fact, by the definition of Mt. we have Mt,w(0) = 0 and Mt,w(A) 
;::: 0 for all A E B(R). Let G 1 , G2 , ... E B(R) be a sequence of mutually 
disjoint sets. Then 
N, L Iu~=' Gn (Zi) 
i=l 
i=l n=l 
00 
which shows that Mt,w is countably additive. Therefore, Mt,w is a measure. 
(c) By part (b), Mt is a random measure. To show that Mt is a Poisson random 
measure with mean v, we first show that for every A E B(R), Mt(A) has 
a Poisson distribution with mean v(A). Let k ;=:: 0 be an integer. Then by 
Problem 14.18, we have 
P{Mt(A) = k} = P {~ IA(Zn) = k} 
~ 
P{Nt = i}P {~ IA(Zn) = k} 
~e-,\t(~~)i (~) P{Z1 E A}kP{Z1 tf_ A}i-k 
-,\tP{Z,EA} (>.tP{ZI E A} )k 
e 
k! 
which shows that Mt(A) has a Poisson distribution with mean >.tP{Z1 E A}. 
Hence we have 

412 
LEVY PROCESSES 
Now let n 2': 2, and let A1 , ... , An E B(R) be disjoint. To show that Mt(AI), 
Mt(A2 ), .. . , Mt(An) are independent, we use Kac's theorem (Theorem 17.2) 
to show that 
In fact, by Problems 14.18 and 12.7 we have 
Since Z1 , Z2 , ... have the same distribution and A1 , A2 , ... , An are disjoint, 
the above equation gives 
E [exp (i ~ 
OkMt(Ak))] 
exp (AtE [exp (i ~ 
OkiAk (Zl)) ]-At) 
exp (At L 
exp (i~OkiAk(x)) fLF(dx)- At) 
exp (At [~(l+ei 1h)tLF(Ak)]). 
(30.2) 

SOLUTIONS 
413 
Since Z 1 , Z2 , â¢.. are independent, by Problem 14.18 and Theorem 17.2 we have 
n II E [exp (iOkMt(Ak))] 
k=l 
n II exp (.\tE [exp (i(hlAk (ZI))]- .\t) 
k=l 
n II exp (.Xt[1 + ei!Jk]J.LF(Ak)). 
(30.3) 
k=l 
Hence Equation (30.1) follows from Equations (30.2) and (30.3). Thus, Mt is a 
Poisson random measure. 
(d) By Problem 14.18, we have 
v(A) 
E [t, lA(Zn)] 
fo P{Nt = m}E [~IA(Zn)l 
oo 
_xm 
L e->.-1 mJ.LF(A) 
m=O 
m. 
AJ.LF(A). 
Since f.Â£F is a finite measure, vis also a finite measure. 
(e) By the assumption that {Nt : t ~ 0}, {Zn : n = 1, 2, ... }, and {Bt : t ~ 0} 
are independent, we have 
By Problems 30.3 and 30.4, we have 

414 
LEVY PROCESSES 
and 
E [ eiu L:;:'~, Zn] 
exp (iut [
1
1 xv(dx)- t L 
[1- eiux + iuxJ(- 1,l)(x)] v(dx)) 
exp ( -t L 
[1- eiux] v(dx)). 
Combining the above three equations gives 
This completes the proof. 
30.10. 
(a) Let n0 be the set such that for any w E n0 , the path {N8 (w) : 0 :::; s :::; t} 
is right-continuous with left limit and the path {as + a B s ( w) : 0 :::; s :::; t} 
is continuous. Then we have P(no) = 1. Let w E no. Since Nt(w) < oo, 
the path { N 8 ( w) : 0 :::; s :::; t} has at most a finite number of jumps. Let 
s 1 , s2 , ... , sm be the jump points of the path. Then we have 
n=1 
(b) For every n 2:: 1, let An,o = {0}, 
An,i = {X E R: (i- 1)Tn <X:::; iTn}' 
i = 1, 2, ... 'n2n, 
and An,n2n+1 = { x E R: x > n }. For every n 2:: 1, let 
{
0, 
ifx=O; 
an(x)= 
(i-1)2-n, ifxEAn,i,i=1,2, ... ,n2n; 
n, 
ifn<x. 
Then by Problem 5.11, we have for any x E R, an(x+) t x+ as n -+ oo, 
where x+ = max(x, 0). By Theorem 6.2, we have 
and 

SOLUTIONS 
415 
where x- = max( -x, 0). But 
n2n+l . 
1 
L Z; Mt(An,i) 
i=l 
n2n+l . 
1 N, 
L 
Z ;n LJAn,i(Zj), 
i=l 
j=l 
which gives 
Hence we have 
Similarly, we have 
Therefore, we have 
{ 
N, 
JF xMt(dx) = L z1. 
R 
j=l 
(c) By part (b), we only need to show that 
(30.4) 

416 
LEVY PROCESSES 
But by Problem 27.10, we have 
(30.5) 
By Problem 30.9, we have 
t l xv(dx) = t l xE[Nl]/LF(dx) = tE[N1]E[Z1], 
(30.6) 
where F is the distribution function of Z1 and /LF is the Lebesgue-Stieltjes mea-
sure with respect to F. Hence Equation (30.4) follows from Equations (30.5) 
and (30.6). It follows from Problem 27.10 that {Yt : t 2: 0} is a martingale. 
(d) By parts (c) and (b), we have 
Var(Yt) 
E [Y,'] ~ E [ (t,z; -I L 
xv(dx)) '] 
E [ (t,z}]- (t L 
xv(dx))' 
But 
I/{N, ~ m)E [ (~z, )'] 
f e->.t (>-.t)lm [mE[ZrJ + m(m- l)E[Z1]E[Z1l] 
m. 
m=l 
>-.tE[Z~] + (>-.tE[Z1])2 
t l x 2 AI-Â£F(dx) + (t l XA/LF(dx)) 
2 
t l x2v(dx) + (t l xv(dx)) 
2 
where ).. = E[N1], F is the distribution function of Z1 and /LF is the corre-
sponding Lebesgue-Stieltjes measure of F. The result follows by combining 
the above two equations. 
This finishes the proof. 

BIBLIOGRAPHIC NOTES 
417 
30.5 Bibliographic Notes 
The Levy process introduced in this chapter forms a rich class of stochastic pro-
cesses. For example, the Poisson process and Brownian motion are special cases 
of the Levy process. Our definition of the Levy process is adopted from <;inlar 
(2011). For an alternative definition, readers are referred to Protter (2003) and Ca-
passo and Bak:stein (2005). For stochastic calculus with Levy processes, readers are 
referred to Applebaum (2009) and Pascucci (2011). For more information about 
Levy processes, readers are referred to Bertoin (1996), Sato (1999), Applebaum 
(2004), Kyprianou (2006), Pascucci (2011), and Stroock (2011). 
Levy processes with jumps have been used to model stock prices for the pur-
pose of risk management and derivative pricing. For more information about finan-
cial modeling with Levy processes, readers are referred to Cont and Tankov (2003), 
Schoutens (2003), and Schoutens and Cariboni (2009). 
The Levy-Khintchine formula (see Theorem 30.1) describes the structure of the 
characteristic exponent of an infinitely divisible distribution. A proof of this theorem 
can be found in Lukacs (1970) and Sato (1999). Theorem 30.2 states the relationship 
between Levy processes and infinitely divisible distributions. For a proof of the con-
verse part, readers are referred to Sato (1999, Corollary 11.6). A proof of Theorem 
30.3 can be found in Applebaum (2009, Theorem 1.3.3). 
Theorem 30.4 says that Poisson random measures exist. A proof of this theorem 
can be found in Sato (1999, Proposition 19.4). For more information about Poisson 
random measures, readers are referred to <;inlar (2011, Chapter VI). 
The Levy-Ito decomposition (see Theorem 30.5) is an important result, which 
describes the path properties of Levy processes. For a proof of this theorem, readers 
are referred to Applebaum (2009, Section 2.4). 


PART IV 
STOCHASTIC CALCULUS 


CHAPTER 31 
THE WIENER INTEGRAL 
The Wiener integral is a simple stochastic integral where the integrand is a determin-
istic function. In this chapter, we present a definition and some results of the Wiener 
integral. 
31.1 
Basic Concepts and Facts 
Definition 31.1 (Function Space L 2 [a, b]). The function space 
denotes the space of all real-valued square Lebesgue integrable functions on [a, b], 
where J-L is the Lebesgue measure. 
Definition 31.2 (Function Space Â£ 2(0, ~. P)). The function space 
denotes the space of all square integrable real-valued random variables with inner 
product (X, Y) = E(XY). 
Measure, Probability, and Mathematical Finance. 
421 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

422 
THE WIENER INTEGRAL 
Definition 31.3 (Wiener Integral of Step Functions). Let f be a step function in 
L2 [a, b] given by 
n 
f(x) = 2..: aJ[t,_,,t,J(x), 
x E [a, b], 
i=l 
where a = t0 < t1 < Â· Â· Â· < tn = b. The Wiener integral off is defined as 
n 
I (f) = 2..: ai(Bt, - Bt,_, ), 
i=l 
where { Bt}t>o is the standard Brownian motion. 
(31.1) 
Definition 31.4 (Wiener Integral of General Functions). Let f E L2[a, b], and let 
{fn}n>l be a sequence of step functions such that 
f 
L 2 [a,b] J 
n -----=----:.t 
. 
Then the sequence {I(fn)}n>l is Cauchy in L 2(rl,Â§,P) and thus converges in 
L 2 (rl, Â§, P). The Wiener int~gral off is defined as 
I (f) = lim I (in) 
in L 2 (rl, Â§, P). 
n---+oo 
(31.2) 
The Wiener integral I(f) is also denoted by I: f(t)dBt or I: f(t)dBt(w). 
Definition 31.5 (Riemann-Stieltjes Integral). Let f and g be bounded functions on a 
finite closed interval [a, b]. The function f is said to be Riemann-Stieltjes integrable 
with respect to g if the following limit exists: 
where D.n = { t0 , h, ... , tn} is a partition of [a, b], that is, a = to < h < Â· Â· Â· < 
tn = b, D.n = maxl<i<n(ti- ti_l), and TiE [ti-1 1 ti]Â· 
Theorem 31.1. For each f E L2 [a, b], the Wiener integral I: f(t)dBt is a random 
variable normally distributed with mean 0 and variance 11!11 2 = I: f(t) 2dt. 
Theorem 31.2. Let f be a continuous function in L2 [a, b]. Then for almost all 
wE rl, we have 
(lb f(t)dBt) (w) = (RS) lb f(t)dBt(w), 
where the right-hand side is the Riemann-Stieltjes integral and the left-hand side is 
the Wiener integral. 

PROBLEMS 
423 
31.2 
Problems 
31.1. Let f be a step function in L2[a, b] given by 
n 
f(x) = L::>ii[ti_ 1 ,ti)(x), 
x E [a, b], 
i=l 
where a = t0 < t 1 < Â· Â· Â· < tn = b. Let I(!) be the Wiener integral defined in 
Equation (31.1). Show that 
31.2. Show that the Wiener integral I (f) in Equation (31.1) is well defined a.s. In 
other words, if f has two representations 
n 
m 
i=l 
j=l 
where a = to < t1 < Â· Â· Â· < tn = b and a = so < s1 < Â· Â· Â· < sm = b, then 
n 
m 
i=l 
j=l 
31.3. Let f and g be step functions in L2[a, b]. Let a, (3 E R. Show that 
I(af + (3g) = ai(f) + (3I(g), 
where I ( Â·) is the Wiener integral defined in Equation (31.1 ). 
31.4. Show that the Wiener integral in Equation (31.2) is well-defined a.s. In other 
words, if {fn}n~l and {gn}n~l are two sequences of step functions such that 
then we have 
lim I(fn) = lim I(gn), 
a.s. 
n--+oo 
n--+oo 
31.5. Let j, g E L2 [a, b]. Show that 
(a) 
E[I(f)I(g)] = 1b j(t)g(t)dt. 
(b) Iff and g are orthogonal (i.e., J: f(t)g(t)dt = 0), then the normal random 
variables I (f) and I (g) are independent. 

424 
THE WIENER INTEGRAL 
31.6. Let { Bt h>o be a Brownian motion and 
X= 1
1 Btdt. 
Find the distribution of X. 
31.7. Let { Bt}t>o be a Brownian motion and let f E L 2 [a, b]. Show that the stochas-
tic process 
Mt = 1t f(s)dBs, 
t E [a, b], 
is a martingale with respect to the filtration $t =a{ Bs : s :S t}. 
31.8 (Integration by Parts). Let { Bt}t>o be a Brownian motion and let f E L 2 [a, b]. 
Show that 
31.3 Hints 
31.1. Use the properties of Brownian motion. 
31.2. 
Consider the partition produced by points to, h, ... , tn and so, s1, ... , Sm 
and use the results of Problems 31.1 and 6.8. 
31.3. Suppose that f and g are given by 
n 
f(x) = L aJ[ti-l,t,)(x), 
x E [a, b) 
i=l 
and 
m 
g(x) = L bJ[sj-l,sj)(x), 
x E [a, b), 
i=l 
where a = t0 < h < Â· Â· Â· < tn = band a= so < s1 < Â· Â· Â· < sm. Then consider 
the partition produced by points t0 , h, ... , tn, s0 , s 1 , ... , Sm and use the result of 
Problem 31.2. 
31.4. Use the results of Problems 31.1 and 31.3. 
31.5. Part (a) can be proved by considering the expectation E[(J(f) + J(g)) 2] and 
the linearity of I (see Problem 31.3). Part (b) is implied from part (a) and Problem 
19.6. 
31.6. Use the integration by parts and Theorem 31.2. 
31.7. 
Use the idea of how the Wiener integral is defined and the fact that the Bt 
is a martingale with respect to the $t (see Problem 28.1); that is, first consider step 
functions and then general functions. 
31.8. Apply Theorem 31.2. 

SOLUTIONS 
425 
31.4 Solutions 
31.1. By Definition 31.3, we have 
Since the Bt is a Brownian motion, E[(Bt, - Bt,_,)(Bt; - Bt;_,)] = 0 if i =f. j, 
and E[(Bt, - Bt,_,)(Bt; - Bt;_,)] = ti- ti-l if i = j. Therefore we have 
E [I(f)2] = t a~(ti- ti_I) = 1b f(t)2dt. 
i=l 
a 
This completes the proof. 
31.2. 
Let a = ro < r 1 < Â· Â· Â· < r1 = b be distinct points of t0, t 1 , ... , tn and 
so, s1, ... , Sm. Then we have 
n 
m 
l 
U[ti-I.ti) = U[sj-I.Sj) = Uh-I.rk) = [a,b). 
i=l 
j=l 
k=l 
Let Ck be the value off on [rk-1. rk), k = 1, 2, ... , l. Then ck = ai = bj if 
h-1, rk) s;:; [ti-l, ti) n [sj-1, Sj ). 
Now let 
and 
n 
h(f) = L>i(Bt,- Bt,_ 1 ) 
i=l 
m 
f2(f) = L bj(Bs,- B8 ,_ 1 ). 
j=l 
Then, by Problem 31.1, we have 
E [(h(f)- !2(!))2] 
E [(h(f))2 + (!2(!))2 - 2h(f)I2(!)] 
21b f(x) 2dx- 2 t f aibjE[(Bt, - Bt,_,)(Bs; - Bs;_,)] 
a 
i=lj=l 
b 
l 
21 f(x) 2dx-2 L c~(rk- rk-1) 
a 
k=l 
0. 
By Problem 6.8, we have lh(f)- I2(f)l = 0 a.s. Hence we have ! 1(!) = !2(!) 
a.s. This completes the proof. 

426 
THE WIENER INTEGRAL 
31.3. Let f and g be given by 
n 
f(x) = LaJ[t,_,,t,)(x), 
:r; E [a, b) 
i=1 
and 
m 
g(x) = L bii[sJ-l ,sJ) (x), 
x E [a, b), 
i=1 
where a = to < t1 < Â· Â· Â· < tn = band a = so < s1 < Â· Â· Â· < Sm. Then we have 
rt 
rn 
cd(f) + {3I(g) = L aai(Bt, - Bt,_ 1 ) + L {3bj (BsJ - B,J_ 1 ). 
(31.3) 
i=1 
j=l 
Let 0 =To < r1 < Â· Â· Â· < Tt = b be the distinct points of to, t 1 , ... , tn. so, s 1 , 
... , Bm. Then we have 
l 
af + {3g = L ckih_,,r,)â¢ 
k=1 
where Ck = aai + ,Bbj if [rk-1, rk) c:; [ai-l, a;) n [sj_1, sj)Â· Hence we have 
l 
I(af + {3g) = L ck(Br, - Br,_ 1 ). 
k=l 
Note that 
n 
m 
l 
U[t;-1.ti) = U[sj-1,sj) = Uh-1,rk) =[a, b). 
i=1 
j=1 
k=l 
It follows that 
n 
rn 
l 
(31.4) 
Laai(Bt,- Bt,_ 1 ) + Lf3bj(BsJ- B 8 j_ 1 ) = Lck(Br,- Br,_ 1 ). 
i=1 
j=l 
k=l 
By Equations (31.3) and (31.4), we have I(af+bg) = ai(f)+bi(g). This completes 
the proof. 
31.4. By Problems 31.3 and 31.1, we have 
E [(I(fn)- J(gm)) 2] = E [(I(fn- 9m)) 2] = 1b (fn(x)- 9m(x)) 2dx. 
But 
1b(fn(x)- 9m(x)) 2dx 
1b[(fn(:r;)- f(x))- (gm(x)- f(t))) 2dx 
< 21
6 (fn(x)- f(x)) 2dx + 21
6 (gm(x)- f(t))) 2dx. 

By the assumption that 
we have 
E [(I(fn)- J(gm))2] --+ 0 
as 
n, m--+ oo. 
It follows that 
lim I(fn) = lim I(gn), 
a.s. 
n~oo 
n--+oo 
This completes the proof. 
31.5. 
(a) By Problems 31.3 and 31.1, we have 
E[(I(f) + J(g))2] 
E[(I(f + g)?J 
1b (f(t) + g(t)) 2dt 
SOLUTIONS 
427 
1b f(t) 2dt + 21b f(t)g(t)dt + 1b g(t) 2dt. 
(31.5) 
But 
E[(I(f) + J(g))2] 
E[J(f) 2] + 2E[I(f)I(g)] + E[J(g) 2] 
1b f(t) 2dt + 2E[I(f)I(g)] + 1b g(t) 2dt. 
(31.6) 
The result follows by combining Equations (31.5) and (31.6). 
(b) The independence follows from part (a) and Problem 19.6. 
31.6. Integrating by parts, we get 
X(w) = 1
1 Bt(w)dt = Bt(w)(t- 1)1~ -1
1 (t -1)dBt(w) = 1
1 (1- t)dBt(w). 
By Theorem 31.2, we have 
X = 1
1 (1- t)dBt. 
By Theorem 31.1, X is normally distributed with mean 0 and variance 
1
1 
1 
(1- t) 2dt = -. 
0 
3 

428 
THE WIENER INTEGRAL 
31.7. By the definition of the Â§t, Mt is adapted to the Â§tÂ· Note that 
E[IMtl 2] = 1t f(r) 2dr < oo 
andE(IMtl)::::: (E[IMtl 2])!. WehaveE(IMtl) < oo. 
It is left to show that 
But 
Mt = Ms + 1t J(r)dBr 
and Ms is Â§
8 -measurable, we only need to show that 
(31.7) 
To to that, we first consider the case when f is a step function. Suppose that f is 
given by 
n 
f(r) = I:aJ[t;_ 1,ti)(r), 
r E [a, b), 
i=l 
where s = to < t 1 < Â· Â· Â· < tn = t. Note that the Bt is a martingale. We have 
E(Bti - Bti-l lÂ§s) = 0 since ti 2': s for all i = 0, 1, ... , n. Then 
n 
i=l 
0. 
Hence Equation (31.7) holds for step functions. 
Now consider f E L 2 [a, b]. Let {fn}n>l be a sequence of step functions con-
verging to fin L 2 [a, b]. Let the Xn be random variables defined as 
Then E(XnlÂ§s) = 0. By the conditional Jensen's inequality (see Problem 15.7) 
with cp( x) = x2 , we have 

BIBLIOGRAPHIC NOTES 
429 
which gives 
E [ ( E [ xn -1t J(r)dBrl g;sJr] 
< ( xn -1t J(r)dBrr 
< 1t Un(r)- f(r)) 2 dBrÂ· 
Hence 
E(XnlÂ§s) .J:4 E (1t f(r)dBrlÂ§s) as n --too. 
By Problems 9.1 and 9.6, there is a subsequence { Xn; }i~ 1 such that 
Therefore Equation (31.7) holds for general functions in L2 [a, b]. This completes the 
proof. 
31.8. By Theorem 31.2 and integration by parts from calculus, we have 
This completes the proof. 
31.5 Bibliographic Notes 
(RS) 1b f(t)dBt(w) 
f(b)Bb(w) -1b Bt(w)df(t). 
The Wiener integral is a simple type of stochastic integral, which integrates a deter-
ministic function with respect to a standard Brownian motion. Most material in this 
chapter is taken from Kuo (2006), where readers can find proofs of Theorems 31.1 
and 31.2. 


CHAPTER 32 
THE ITO INTEGRAL 
The Ito integral defines an integral of a stochastic process with respect to a standard 
Brownian motion. The Ito integral is more general than the Wiener integral intro-
duced in the previous chapter. In this chapter, we shall introduce the concept of Ito 
integrals. 
32.1 
Basic Concepts and Facts 
Definition 32.1 (Stochastic Process Space L~d([a, b] x 0)). Let { fft : a :::; t :::; b} 
be a filtration under consideration. The space L~d([a, b] X n) is defined to be the 
space of all stochastic processes f(t,w), t E [a, bj, wE 0, satisfying the following 
conditions: 
(a) f(t) is adapted to the fft. 
(b) I: E(lf(t)l 2)dt < 00. 
Definition 32.2 (Ito Integral of Step Stochastic Processes). Let { fft : a :::; t :::; b} 
be a filtration. Let { Bt : a :::; t :::; b} be a Brownian motion satisfying the following 
conditions: 
Measure, Probability, and Mathematical Finance. 
431 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

432 
THE IT6 INTEGRAL 
(a) For each t, Bt is $rmeasurable. 
(b) For any 8 ~ t, the random variable Bt - B 8 is independent of $
8 â¢ 
Let f be a step stochastic process in L~d([a, b] x 0) given by 
n 
f(t,w) = L~i-l(w)I[t,_,,t,)(t), 
i=l 
where a= to < h < ... < tn =band ~i-1 is Â§t,_,-measurable with E((f_ 1 ) < 
oo fori = 1, 2, ... , n. Then the stochastic integral off is defined as 
n 
I(!)= L~i-l(Bt, -Bt,_,). 
(32.1) 
i=l 
Definition 32.3 (Ito Integral of General Stochastic Processes). Let { Â§t : a ~ t ~ b} 
be a filtration. Let { Bt : a ~ t ~ b} be a Brownian motion satisfying the following 
conditions: 
(a) For each t, Bt is $rmeasurable. 
(b) For any 8 ~ t, the random variable Bt - B 8 is independent of $
8 â¢ 
Let f be a stochastic process in L~d([a, b] x 0). Then there exists a sequence {fn : 
n ~ 1} of step stochastic processes such that 
lim {bE (lf(t)- fn(t)l 2 ) dt = 0. 
n-too }a 
The stochastic integral of f is defined as 
I(!)= lim I(fn), 
in 
L2 (0), 
n-+oo 
where I(! n) is the stochastic integral of the step stochastic process f n. The stochas-
tic integral I (f) is said to be the Ito integral off and is written as J: f(t)dBt. 
Theorem 32.1. Let f E L~d([a, b] x 0). Then the Ito integral 
I(!) = 1b f(t)dBt 
is a random variable with mean E[I(f)] = 0 and variance 
Theorem 32.2 (Martingale Property). Let f E L~d([a, b] x 0). Then the stochastic 
process 

PROBLEMS 
433 
is a martingale with respect to the filtration { fft : a ::::; t ::::; b}. 
Theorem 32.3 (Continuity Property). Let j E L~d([a, b] x n). Then the stochastic 
process 
Xt = 1t f(u)dBu, 
a::::; t::::; b, 
is continuous; that is, almost all of its sample paths are continuous functions on 
[a, b]. 
Theorem 32.4. Let f E L~d([a, b] x n). Suppose that E[f(t)f(s)] is a continuous 
function of(t, s) E [a, b] x [a, b]. Then 
1
b f(t)dBt = 
lim t f(ti_I)(Bt, - Bti-t ), 
in 
L2(f1), 
a 
ll~nll-->cxo i=1 
where 6.n ={to, h, ... , tn} are partitions of[a, b] and 
32.2 
Problems 
32.1. Let f be a step stochastic process in L~d([a, b] X n) given by 
n 
f(t,w) = L~i-1(w)I[ti_ 1 ,t,)(t), 
i=1 
where a= to < t1 < Â· Â· Â· < tn =band ~ti-t is ffti_,-measurable with E(~f- 1 ) < 
oo fori = 1, 2, ... , n. Show that 
E[I(f)] = 0 
and 
E (IIUW) = 1b E (1!1 2 ) dt, 
where I (f) is the stochastic integral defined in Equation (32.1). 
32.2. Show that the stochastic integral I (f) defined in Equation (32.1) is well de-
fined. In other words, if f has two representations given by 
n 
m 
i=1 
j=1 
where a= to < t1 < Â· Â· Â· < tn = b, a= so < s1 < Â· Â· Â· < Sm = b, ~i-1 is ffti_ 1 -
measurable fori = 1, 2, ... , n, and T}j-1 is ffsj_ 1 -measurable for j = 1, 2, ... , m, 
then 
n 
m 
i=1 
j=1 

434 
THE IT6 INTEGRAL 
32.3. Let f and g be two step stochastic processes in L~d([a, b] x 0). Show that 
I(af + f3g) =a! (f)+ /3I(g), 
a, /3 E R, 
where I(Â·) is as defined in Equation (32.1). 
32.4. Let f(t) be a step stochastic process in L~d([a, b] x 0). Let C > 0, and let 
f c ( t) be a stochastic process defined as 
Show that 
{
f(t,w) 
if J: lf(u,wWdu:::; C; 
fc(t,w) = 
0 
otherwise. 
32.5. Let f(t) be a step stochastic process in L~d([a, b] x 0). Show that for any 
E > 0 and C > 0, we have 
32.6. Let f be a function in L~d([a, b] x 0) such that E[f(t)f(s)] is a continuous 
function of (t, s) E [a, b] x [a, b]. Show that there exists a sequence Un}n>l of step 
stochastic processes in L~d([a, b] x 0) such that 
-
lim lb E (lf(t)- fn(t)l 2 ) dt = 0. 
n--+oo 
a 
32.7. Let f be a bounded function in L~d([a, b] x 0). Then f(t) is adapted to some 
filtration {9"t : a :::; t :::; b}. Let {gn}n>l be a sequence of stochastic processes 
defined by 
r(t-a) 
9n(t,w)= Jo 
e-rf(t-~,w)dT. 
Show that 
(a) For each n 2': 1, 9n(t) is adapted to the filtration { 9"t : a :::; t :::; b }. 
(b) For each n 2': 1, 
(c) For each n 2': 1, E[gn(t)gn(s)] is a continuous function of (t, s) E [a, b] x [a, b]. 

PROBLEMS 
435 
(d) 
lim 1b E (lf(t)- 9n(t)i 2 ) dt = 0. 
n--+oo 
a 
32.8. Let { Â§t : 0 :::; t :::; b} be a filtration and { Bt : 0 :::; t :::; b} be a Brownian 
motion adapted to the filtration. Let f ( t) be a continuous stochastic process adapted 
to the filtration. Let 
Mt = (E [sup if(sw])~, t E [O,b]. 
O:'Os:'Ot 
Suppose that Mb < oo. Show that 
(a) For every t E [0, b], we have 
E [sup I r f(u)dul
2
] 
:::; t1t M;ds. 
O:'Os:'Ot Jo 
(b) For every t E [0, b], we have 
E [sup I r f(u)dBul
2
] :::; 4 rot M;ds. 
O:'Os:'Ot Jo 
Jn 
32.9. Let f and g be two stochastic processes in L;d([a, b] x r2). Show that 
E [1b j(t)dBt 1b g(t)dBtl = 1b E[f(t)g(t)]dt. 
32.10. Let { Bt}t>O be a Brownian motion and [a, b] C R. Let ~n = { tn,o, 
tn,l, ... , tn,n} be a sequence of partitions of [a, b]. Show that 
i=l 
where ll~nll = maxl:'Oi:'On(tn,i- tn,i-dÂ· 
32.11. Let { Bt}t;:>o be a Brownian motion and [a, b] c R. Let ~n = { tn,o, 
tn,l, ... , tn,n} be a sequence of partitions of [a, b]. Show that 
n 
2 
1 
L 
L (!1) 
( 
2 
2 
) 
Bt .(Bt . - Bt 
Â·~,) ~- Bb- Ba + b- a 
n,t 
n,t 
n,t 
2 
i=l 
as 
ll~nll-+ 0, 
and 
n 
2 
1 
""' 
( 
L (!1) 
( 
2 
2 
) 
~ 
Btn,i~l Btn,i -
Btn,i~l) ~ 
2 Bb - Ba - (b- a) 
i=l 
as 
ll~nll-+ 0, 

436 
THE IT6 INTEGRAL 
where IID.nll = maxlS:iS:n(tn,i- tn,i-dÂ· 
32.12. Let { Bt}t2o be a Brownian motion and [a, b] c R. Show that 
1
b BtdBt = ~ [B~- B~- (b- a)]. 
a 
2 
32.13. Let { Bt}t>o be a Brownian motion and [a, b] C R. Show that 
1b 
BzdBt = ~ [ B~ - B~] -1b Btdt. 
a 
3 
a 
32.14. Let { Bt}t>o be a Brownian motion. Define 
Xt = lot B;dBu, 
t ?: 0. 
Show that the Xt is a martingale. 
32.15 (Exponential Inequality). Let f E L~d([O, b] x 0) such that 
fob f(s) 2ds :S K 
a.s. 
for some constant K. Let 
Show that 
(a) For every a E R, the process 
is a martingale. 
(b) For every >. > 0, 
P { sup IXtl?: >-} :S 2exp (- >.K
2 ). 
OS:tS:b 
2 
32.16. Let { Bt : 0 :.::;: t :.::;: b} be a Brownian motion adapted to some filtration 
{Â§t : 0 :S t :S b }. Let f(t) be a process adapted to { Â§t : 0 :S t :S b }. Suppose that 
lf(t)i :S k 
a.s., 
1::/t E [0, b], 
where k is some constant. For every t E [0, b], show that 

HINTS 
437 
32.3 Hints 
32.1. Use the tower property of conditional expectations (see Problem 14.10) and 
note that fori < j, ~i-l~j-l (Bt; - Bt;_J is ff:tj_ 1 -measurable. 
32.2. Consider the partition produced by t0 , t 1 , ... , tn, s0 , s 1 , ... , sm and use the 
result of Problem 32.1. 
32.3. Suppose that f and g are given by 
n 
f(t,w) = L~i-I(w)I[t;_ 1 ,t;)(t) 
i=l 
and 
m 
g(t,w) = L1'1J-I(w)I[sj_ 1,sj)(t), 
i=l 
where a = to < t1 < Â· Â· Â· < tn = b, a = so < s1 < Â· Â· Â· < Sm, ~i-1 is ff:t;_ 1 -
measurable fori = 1, 2, ... , n, and 'T}j-l is ff:sj-l -measurable. Then consider the 
partition produced by the points to, t1, ... , tn, so, s1, ... , Sm. 
32.4. Note that the result is equivalent to 
32.5. Consider the stochastic process fc defined in Problem 32.4 and note that 
{l1b f(t)dBtl > E} 
c 
{ l1b fc(t)dBtl > E} U { 1b f(t)dBt =J 1b fc(t)dBt}. 
32.6. Let ~n = {to, t 1 , ... , tn} be a partition of [a, b ]. Consider the step stochastic 
processes fn (t, w) = f(ti-1, w) if t E (ti-l, ti]Â· 
32.7. Part (a) can be proved by the result of Problem 5.9. Part (b) follows from the 
fact that f is bounded. To prove (c), try to establish that E[gn(t)gn(s)] is continuous 
if 
lim E [(gn(s)- 9n(so))2] = 0, 
s E [a, b]. 
s----tso 
Part (d) can be proved by the dominated convergence theorem (Theorem 6.4). 
32.8. Use Holder's inequality (Theorem 8.1) to prove part (a). Use Theorem 32.2 
and the result of Problem 24.5 to prove part (b). 

438 
THE ITO INTEGRAL 
32.9. Consider the expectation of [J(f) + I(g)F and use Theorem 32.1. 
32.10. Note that the (Btn,, - Btn,i-I )2 are independent and that 
E(Bt . - Bt 
)2 = t 
- t Â· 1 
n,t 
n.z-1 
n,t 
T/, 11,-
â¢ 
32.11. Use the result of Problem 32.10. 
32.12. Follow the definition of the Ito integral and use the results of Problems 32.11 
and 32.6. 
32.13. Construct a sequence of step stochastic processes 
and calculate the limit of I(fn)Â· 
32.14. Use the result of Problem 32.13. 
32.15. To prove part (a), try to show that 
Use part (a) and the result of Problem 24.11 to prove part (b). 
32.16. Use the result of Problem 32.15 and Holder's inequality (Theorem 8.1 ). 
32.4 Solutions 
32.1. First, we show that E[J(f)] = 0. By definition, we have 
n 
I(!)= L~i-l(Bti- Bt,_,). 
By Problem 14.10, we have 
Hence E[J(f)] = 0. 
Second, let us prove 
i=l 
E{E[~i-1 (Bt,- Bt,_,)lÂ§t,_,]} 
E{~i-IE[Bt,- Bt,-1lÂ·g;ti-1]} 
E{~i-IE[Bti - Bti-1]} 
0. 
(32.2) 

SOLUTIONS 
439 
By definition we have 
n 
IIUW = L ~;_1 (Bt; - Bti-1 )2 + 2 L ~i-1~j-1 (Bti - Bti_,)(Btj - Btj-1 ). 
i=1 
i<j 
Note that ~i- 1 is Â§i_1-measurable. We have 
E{E[~l-1(Bti- Bti_,)2 lÂ§ti_,]} 
E{~l-1E[(Bti- Bti-1) 2 lÂ§ti-1]} 
E{~L 1 E[(Bti- Bt,_ 1 ) 2]} 
(t;- ti_l)E (~L1). 
Since ~i-l~j- 1 (Bti - Bti_,) is Â§t1_ 1 -measurable fori < j, we have 
Hence we have 
E[~i-1~J-1 (Bti - Bti_ 1 )(Bt1 - Bt1_ 1 )] 
E{E[~i-1~J-1(Bti- Bti_ 1 )(Bt1 - Bt1_1)1Â§t1 _,]} 
E{~i-1~J-1(Bti- Bti_,)E[(Bt1 - Bt1_,)lÂ§t1_ 1]} 
E{ ~i-1~J-1 (Bti - Bti_ 1 )E[(Bt1 - Bt1_ 1)]} 
0. 
n 
E (IIUW) = L(ti- t;_l)E (~L1). 
i=1 
On the other hand, we have 
1b E (1!1 2 ) dt 
(32.3) 
1b E (t~}_ 1 l[ti_ 1 ,ti)(t) + 2 L:~i-1~J-1l[ti_ 1 ,t;J(t)I[t1 _ 1 ,t1 )(t)) dt 
a 
t=1 
t<J 
t E (~l-1) 1b l[ti_1,t;J(t)dt 
i=1 
a 
n 
L(ti- ti_l)E (~l-1). 
(32.4) 
i=1 
Equation (32.2) follows from Equation (32.3) and Equation (32.4). This completes 
the proof. 
32.2. 
Let a = r0 < r 1 < Â· Â· Â· < rz = b be the distinct points from points 
to,t1, ... , tn,so,s1, ... ,sm. Then tiE {ro,r1, ... ,rz} fori= O,l, ... ,n and 
s j E { r0, r 1 , ... , rz} for j = 0, 1, ... , m. Let 

440 
THE ITO INTEGRAL 
fork= 1, 2, ... , l. Then we have 
n 
m 
0 = 
L~i-1I[ti-1,ti)(t)- L"7J-1I[Sj-1,Si)(t) 
i=1 
l 
L ek-1Ih-1,rk)" 
k=1 
j=1 
By the definition of the stochastic integral of step functions, we have 
l 
But 
where 
J(O) = L ek-1 (Brk - Brk-1 ). 
k=1 
l 
Lek-1(Brk- Brk_J = h(f)- I2(!), 
k=1 
n 
m 
h(f) = L~i-1(Bt, -Bti_J, 
J2(f) = LT/j-1(Bs1 -Bs1_ 1). 
i=1 
j=1 
Therefore, by Problem 32.1, we have 
which gives h (!) = J2 (f) a.s. This completes the proof. 
32.3. Let f and g be given by 
n 
f(t,w) = L~i-1(w)I[t,_ 1 ,ti)(t) 
i=1 
and 
m 
i=1 
where a = to < t1 < Â· Â· Â· < tn = b, a = so < s1 < Â· Â· Â· < Sm, ~i-1 is .97ti_ 1 -
measurable fori = 1, 2, ... , n, and T/j- 1 is .9781 _ 1 -measurable. Then by definition, 
we have 
n 
m 
I (f) = L 
~i-1 (Bti - Bti_J, 
I(g) = L 
T/j-1 (Bs1 - Bs1_ 1 ). 
i=1 
j=1 
Let a = r0 < r 1 < Â· Â· Â· < rz = b be the distinct points from points t0 , t 1, ... , 
tn, so, s1, ... , Sm, and let 

fork= 1, 2, ... , l. Then we have 
which gives 
But 
l 
af + f3g = L ek-l(w)Ih-!,Tk)(t), 
k=l 
l 
I(af + f3g) = L ek-l(Brk- Brk_,). 
k=l 
n 
m 
SOLUTIONS 
441 
ai(f) + f3I(g) 
L~i-l(Bt,- Bt,_,) + L 'Tlj-l(Bs1 - Bs1_ 1 ) 
i=l 
l 
LBk-l(Brk- Brk_,). 
k=l 
j=l 
Therefore we have I(af + f3g) = ai(f) + f3I(g). This completes the proof. 
32.4. To prove this problem, we only need to show that 
To do that, let 
w E { lb lf(tWdt ~ c} . 
Then we have I: lf(u,w)l 2du ~ I: lf(u,w)l2du ~ C for all t E [a,b]. Hence 
we have fc(t,w) = f(t,w) for all t E [a,b]. It follows that I: f(t,w)dBt = 
I: fc(t,w)dBt. Therefore 
w E { lb f(t)dBt = lb fc(t)dBt}. 
Since w is arbitrary, the result holds. This completes the proof. 
32.5. Let f c ( t) be a stochastic process defined as 
{
f(t,w) 
if I: lf(u,w)l2du ~ C; 
fc(t,w)= 
0 
otherwise. 

442 
THE ITO INTEGRAL 
Then we have 
{l1b f(t)dBtl > E} 
c 
{ l1b fc(t)dBtl > E} u { 1b j(t)dBt cj 1b fc(t)dBt}, 
which gives 
P{l1b j(t)dBtl > E} 
< P { l1b fc(t)dBt I > E} + P { 1b f(t)dBt cj 1b fc(t)dBt}. 
By Problem 32.4, we have 
Also by Chebyshev inequality (see Problem 6.16), we have 
p{l1b fc(t)dBtl > E} 
< ,1, E [ll fc(t)dB"'l " ,; l E(lfc(t)l')dt" ~. 
The result follows by combining the above inequalities. 
32.6. 
Let ~n = {to, t1 , ... , tn} be a partition of [a, b]. Let fn(t, w) be a step 
stochastic process defined by 
fn(t.w) = .f(t;-J,w), t E (t;-1,t;]. 
Since .f is an adapted stochastic process to some filtration { fft : a ::; t ::; b}, it 
follows that .fn is also adapted to the filtration. By the assumption that E[.f(t)f(s)] 
is a continuous function on [a, b] x [a, b], we have 
lim E (l.f(t)- fn(t)l 2 ) = 0. 
n--+= 
Note that 
E (lf(t)- .fn(tW) :S: 2E (lf(tW + lfn(t)l 2 ) :S: 4 sup E (l.f(sW) Â· 
a:'Os:'Ob 

SOLUTIONS 
443 
By Theorem 6.4, we have 
lim rb E (lf(t)- fn(t)l 2 ) dt = rb lim E (lf(t)- fn(tW) dt = 0. 
n-+oo} a 
} a n--+oo 
This completes the proof. 
32.7. By changing of variable, we can write 9n as 
9n(t, w) = 1t ne-n(t-x) f (x, w) dx. 
(a) Let ~m ={to, t1, ... , tm} be a sequence of partitions of [a, t] such that ll~mll 
---+ 0 as m---+ oo, where ll~mll = maxl<k<m(tk- tk-dÂ· Define 
m 
Xm(w) = L ne-n(t-tk-d f (tk-l,w)' 
wEn. 
k=l 
Then Xm are random variables and are $rmeasurable. By the assumption 
that f E L~d([a, b] x 0), f(t,w) is an integrable function oft for each w. 
Hence Xm ---+ 9n(t, Â·)as m---+ oo. By Problem 5.9, 9n(t, Â·)is $t-measurable. 
Therefore, 9n is adapted to the Â§t. 
(b) Since f is bounded, we have 
where M = SUP(x,w)E[a,b]xn lf(x,w)l. Hence we have 
(c) Let (to, so) E [a, b] x [a, b]. We need to show that 
lim 
E[gn(t)gn(s)] = E[gn(to)gn(so)]. 
(t,s)--+(to,so) 
By Jensen's inequality with Â¢(x) = x 2 (see Theorem 15.2) and the inequality 
(x + y) 2 :::;: 2(x2 + y2), we have 
(E[gn(t)gn(s)]- E[gn(to)gn(so)]) 2 
< E [ (gn (t)gn( S) - 9n (to)gn (so) )2] 
E [{gn(t)(gn(s)- 9n(so))- 9n(so)(gn(t)- 9n(to))}2] 
< 2E [gn(t) 2(gn(s)- 9n(so)) 2] + 2E [gn(so) 2(gn(t)- 9n(to)) 2] 
< 2M2(E [(gn(s)- 9n(so))2] + E [(gn(t)- 9n(to)) 2] ), 
(32.5) 

444 
THE IT6 INTEGRAL 
where M = SUP(x,w)E[a,b]xn l9n(x,w)l. By inequality (32.5), we only need to 
show that 
lim E [(gn(s)- 9n(so)) 2] = 0, 
s E [a, b]. 
(32.6) 
s--+so 
Note that 
9n(s)- 9n(so) 
1
8 
1~ 
ne-n(s-x) f(s)dx + [e-ns- e-nsol 
nenx f(x)dx. 
so 
a 
We have 9n(s) --+ 9n(so) ass--+ sa. Inequality (32.6) follows from the domi-
nated convergence theorem 6.4. Therefore E[gn(t)gn(s)] is a continuous func-
tion of (t, s). 
(d) Suppose that f(t) = 0 fort< a. Then we have 
32.8. 
f(t)- 9n(t) = 1
00 e-r [f(t)- f (t- ;) J dT. 
By Schwarz's inequality (Theorem 8.3), we have 
lf(t)- 9n(tW 
11
00 e-;e-; [f(t)- f (t- ;) J dTI
2 
< 1
00 
e-T [!(t) -f(t-;)r dT 
Hence we have 
lb E [IJ(t)- 9n(t)l 2] dt 
< lb E [1
00 e-r [f(t)- j (t- ;) r 
dT] dt 
1
00 e-rE (lb [f(t)- j (t- ;) r 
dt) dT. 
By the assumption that f is bounded, we have 
lb [!(t)- f (t- ;) r 
dt--+ 0 
a.s. as n--+ 00. 
It follows that 
lim lb E [lf(t)- 9n(tWJ dt = 0. 
n--+oo 
a 

SOLUTIONS 
445 
(a) By Theorem 8.1, for every s E [0, b], we have 
118 f(u)dul2 < (18 lf(u)ldu) 2 
< s 1slf(uWdu 
< t 1t lf(uWdu 
< t 1t sup lf(rWdu. 
0 o::;r::;u 
Since the above inequality holds for all s E [0, b], we have 
sup I r f(u)dul 2 :::; t t sup lf(rWdu. 
o::;s::;t lo 
lo o::;r::;u 
Hence the result follows by taking expectation in both sides of the above in-
equality and Tonelli's theorem (Theorem 10.1). 
(b) For every s E [0, b], let 
Xs = 1s f(u)dBu. 
Then by Theorem 32.2, {Xs : 0 :::; s :::; b} is a martingale adapted to the 
filtration {Â§s : 0 :::; s :::; b}. By Problem 22.8, {IXsl : 0 :::; s :::; b} is a 
submartingale. Hence it follows from Problem 24.5 that 
By Theorem 32.1, we have 
We get the result by combining Equations (32.7) and (32.8). 
This finishes the proof. 
32.9. On one hand, by Theorem 32.1, we have 
E [II(!)+ I(gW] 
E [II(!+ gW] 
1b E [lf(t) + g(t)l2] dt 
1b E [lf(tW] dt + 21b E [f(t)g(t)] dt + 1b E [lg(tW] dt. 

446 
THE ITO INTEGRAL 
On the other hand, we have 
E [II(!)+ I(gWJ 
E [II(f)l 2 + 2J(f)J(g) + IJ(g)l 2] 
1b E [lf(t)l 2 ] dt + 2E[J(f)J(g)] + 1b E [lg(t)l 2] dt. 
Combining the above equations gives 
E[J(f)J(g)] = .lb E [j(t)g(t)] dt. 
This completes the proof. 
32.10. By the definition of L 2 convergence, we need to show that 
lim 
E [(~. 
n (Bt 
- Bt ._ 1 ) 2 - (b- a)) 
2
] = 0. 
ll2.nll--+0 
~ nâ¢ 
n,> 
To do that, we let Xn,i = (Btn i 
-
Btn.i-l j2 - (tn,i - tn,i-d fori = 1, 2, ... , n 
and n ~ 1. Then Xn,l, Xn,2, ... , Xn,n are independent and 
E(X~,;) 
Hence we have 
E [((Btni- Btni-1) 2 - (tn,i- tn,i-1)) 2] 
E [(Bt",- Btn.i-1 )2] - 2E [(Btn.i - Btn i-Y(tn,i- tn,i-d] 
+E [(tn,i- tn.i-1) 2] 
2 
2(tn,i- tn,i-d Â· 
R [ (t(B,,, -ll,, ,_.)'- (b- a))'] 
E [ (txn,)'] 
n 
L 
E(X~,i) + 2 L E(Xn,iXn,j) 
i=l 
i<j 
n L 2( tn,i - tn,i-1) 2 
i=l 
n 
:S: 
2.6.n L(tn,i- tn,i-d 
i=l 
2.6.n(b- a). 

Therefore the result is true. This completes the proof. 
32.11. Let Rn and Ln be defined as 
Then we have 
and 
n 
Rn = L Btn,i (Btn,i - Btn,i-l ), 
n ~ 1, 
i=l 
n 
Ln = LBtn,i-l(Btn,i- Btn,i-1), 
n ~ 1. 
i=l 
n 
Rn- Ln = L(Btn,i- Btn,i-l? 
i=l 
i=l 
From the above two equations we can solve Rn and Ln as 
The results follow from Problem 32.10. This completes the proof. 
SOLUTIONS 
447 
32.12. By Problem 28.2, E[BtBs] = min(s, t), which is a continuous function. Let 
.6.n = { tn,o, tn,l, . .. , tn,n} be a sequence of partitions of [a, b] such that ll.6.n II -+ 0 
as n-+ oo. Let {fn}n::=-: 1 be a sequence of step stochastic processes defined by 
n 
fn(t,w) = LBtn,i-J[tn,i-l,tn,i)(t). 
i=l 
By Problem 32.6, we have 
1
b BtdBt = lim I(fn), 
m 
L 2(!1). 
a 
n---?oo 
But by definition, we have 
n 
I(fn) = ""'Bt _,(Bt . - Bt _,). 
~ n,z 
n,1. 
n,?.. 
i=l 
Thus it follows from Problem 32.11 that 
1b BtdBt = ~ [B~- B~- (b- a)]. 

448 
THE IT6 INTEGRAL 
This completes the proof. 
32.13. 
Note that E[BfB;] = ts + 2min(s, t) 2 , which is a continuous function 
of (t, s). Let ~n = {tn,o, tn, 1 , ... , tn,n} be a sequence of partitions of [a, b] such 
that ll~nll -t 0 as n -too. Let {fn}n>l be a sequence of step stochastic processes 
defined by 
n 
fn(t,w) = LBL,,_J[tn,i-l,tn,i)(t). 
i=l 
By Problem 32.6, we have 
By definition, we have 
n 
J(fn) 
L 
BL,i-1 (Btn,i - Btn,i-1) 
which implies that 
i=l 
1 ( 
3 
3) 
1 Ln 
3 
-
Bb - B 
- -
(Bt 
- Bt . ) 
3 
a 
3 
n,, 
n,,-1 
i=l 
n 
- L 
Btn,i-1 (Btn,i - Btn,i-1 )2 Â· 
i=l 
n 
15 L(tn,i - tn,i-1) 3 
i=l 
< 
(32.9) 
(32.10) 
i=l 
LetXi = (Bt . -Bt _1 ) 2 -(tni-tni-l)fori = 1,2, ... ,n. SinceE[(Bt-
Bs)2] = It- sl, E(Xi) ;Â·a fori = 1,' 2, ... : n. By the tower property of conditional 
expectations, for i < j, we have 
E{E [Btn,i-1XiBtn,j-1XJifftn,j-J]} 
E{Btn,,_1XiBtn,j- 1E [Xjlfftn,j-l]} 
E{Btn,i-1XiBtn,j- 1E [Xj]} 
0, 

SOLUTIONS 
449 
since Btn,i- 1 , Xi, and Btn,j- 1 are Â§tn,j- 1 -measurable, and X 1 is independent of 
:Ftn,j-1" 
Since Btn,i- 1 and Xi are independent, we have 
Therefore 
E[(~Bt -1(Bt .-Bt _ 1 ) 2 -~Bt .(tni-tni-1))
2
] 
L......t 
n,~ 
n,1. 
n,1. 
L...,; 
n,t 
, 
, 
i=l 
i=l 
n 
i=l 
< 2biln(b- a), 
which implies that 
as 
n--+ oo. 
(32.11) 
The result follows from Equations (32.9), (32.10), and (32.11). This completes the 
proof. 
32.14. Let s :::; t. Then by Problem 32.13, we have 
Note that 
E [(Bt- Bs)3 + 3(Bt- Bs)2 Bs + 3(Bt- Bs)B; + B:i.f7s] 
3(t- s)Bs + B:. 
Combining the above two equations gives 
which shows that Xt is a martingale. This completes the proof. 
32.15. 

450 
THE ITO INTEGRAL 
(a) Since .f E L~d([O, b] x rl), it follows from Theorem 32.2 that {Xt : 0:::; t:::; b} 
is a martingale. Now for a > 0, 0 :::; s :::; t, we have 
E [exp ( aXt- ~
2 .[ .f(u) 2du) I .%8 ] 
exp ( aX8
-
~
2 1
8 .f(u) 2du) 
xE [ exp ( a(Xt- Xs)- ~
2 1t .f(u) 2du) I Â§
8 ] 
Ys Â· E [ exp ( a(Xt- Xs)- ~
2 1t .f(u) 2du) I Â§s] . 
Notethatexp ( a(Xt- Xs)- c;_2 .J: .f(u) 2du) isindependentof.g;;s andXt-
Xs ~ N(O, a 2), where 
Hence we have 
Combining the above two equations shows that {Yt : 0 :::; t :::; b} is a martin-
gale. 
(b) Let {lt : 0:::; t:::; b} be the process given in the first item of this problem. Then 
we have 
{ sup Xt :.::0: A} ~ { sup lt :.::0: exp (a>- - a
2 K) } . 
O<::t<::b 
O<::t<::b 
2 
(32.12) 
Note that Y0 = 1 and yb- = 0. By Problem 24.11, we have 
P { sup lt :.::0: exp (a>- - a2 K) } :::; exp (-aA + 0'2 K) . 
O<::t<::b 
2 
2 
(32.13) 
If we let a= f?, then Equations (32.12) and (32.13) give 
P { sup Xt :.::0: >-}:::; exp (-~). 
O<::t<::b 
2K 

SOLUTIONS 
451 
Similarly, we have 
P { sup ( -Xt) ~A} :::; exp (- AK
2 ) . 
O-:;t5,b 
2 
Hence the result follows from the above two inequalities. 
This completes the proof. 
32.16. By Problem 32.15, the process 
is a martingale. Hence we have 
By Theorem 8.1, we have 
E [exp (lot f(s)dBs)] 
E [exp (lot f(s)dB 8 -lot f 2(s)ds) Â· exp (lot f 2(s)ds)] 
< ( E [exp (2lot f(s)dB 8
- 2lot f 2(s)ds)]) ~ 
Â· ( E [exp (2lot f 2(s)ds)]) ~ 
( E [exp ( 2lot f 2(s)ds)]) ~ 
which gives 
Similarly, we can show that 
This completes the proof. 

452 
THE ITO INTEGRAL 
32.5 
Bibliographic Notes 
The stochastic integral was first introduced by K. Ito in his 1944 paper (Ito, 1944 ). 
In this chapter, we defined the stochastic integral for stochastic processes f ( t) that 
are adapted to a filtration { Â§t : a :::; t :::; b} and satisfy the condition 
The stochastic integral 
1" f(t)dBt 
is defined in such a way that the stochastic process 
is a martingale. 
The proofs of Theorems 32.2 and 32.3 can be found in Kuo (2006, Chapter 4). 
The two theorems can be proved by first considering step stochastic processes and 
then general stochastic processes. 
There are several texts on stochastic calculus. Karatzas and Shreve ( 1991) intro-
duces stochastic calculus for Brownian motions. Baxter and Rennie (1996) gives an 
intuitive introduction to stochastic calculus. Durrett (1996) gives a concise introduc-
tion to stochastic calculus. Mikosch (1999) is a short book on stochastic calculus 
at an elementary level. Steele (2003) introduces stochastic calculus with a focus on 
finance applications. Klebaner (2005) introduced stochastic calculate with some ap-
plications in finance. Sondermann (2007) is a short course on stochastic calculus for 
finance. Roberts (2009) and Kopp (2011) are short books on Ito calculus. 
Malliavin and Thalmaier (2006) is a book on Malliavin calculus (i.e., stochastic 
calculus of variations), which provides mechanics to calculate derivatives of random 
variables. 

CHAPTER 33 
EXTENSION OF THE ITO INTEGRAL 
In this chapter, we define the Ito integral for stochastic processes in a larger space. 
33.1 
Basic Concepts and Facts 
Definition 33.1 (Stochastic Process Space L:ad(fl, L2 [a, b])). Let { fft : a :::; t :::; b} 
be a filtration under consideration. The space L:ad(fl, L2[a, b]) is defined to be the 
space of all stochastic processes f(t,w), t E [a, b], wE fl, satisfying the following 
conditions: 
(a) f(t) is adapted to the fft. 
(b) J: lf(t)i2dt < oo a.s. 
Definition 33.2 (Extension of the Ito Integral). Let { fft : a :::; t :::; b} be a filtration. 
Let { Bt : a :::; t :::; b} be a Brownian motion satisfying the following conditions: 
(a) For each t, Bt is fft-measurable. 
(b) For any s :::; t, the random variable Bt - Bs is independent of Â§
8 â¢ 
Measure, Probability, and Mathematical Finance. 
453 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

454 
EXTENSION OF THE ITO INTEGRAL 
Let f E Lad(O, L 2 [a, b]). Then there exists a sequence Un(t)}n>l of step stochastic 
processes in L~d([a, b] x 0) such that 
-
1b lfn(t)- f(t)i 2dt ~ 0 
as 
n--+ oo. 
The Ito integral of f is defined as 
l b j(t)dBt = lim I (in) 
in probability, 
a 
n--+oo 
where I ( Â·) is as defined in Equation (32.1 ). 
Definition 33.3 (Local Martingale). Let { Xt : a ::; t ::; b} be a stochastic process 
adapted to the filtration { fft : a ::; t ::; b}. The stochastic process Xt is said to be 
a local martingale with respect to the fft if there exists a nondecreasing sequence 
{ T n : n ;::: 1} of stopping times of { fft : a ::; t ::; b} such that 
(a) Tn --+ b a.s. as n--+ oo. 
(b) For each n;::: 1, XtATn is a martingale with respect to the filtration {fft :a::; 
t::; b}. 
The stopping times { T n : n ;::: 1} are said to reduce {X t : a ::; t ::; b}. Local 
submartingales and local boundedness are defined in the same way. 
Theorem 33.1. Let f be a continuous stochastic process adapted to the filtration 
{ fft : a ::; t ::; b }. Then 
(a) f E Lad(O, L 2 [a, b]); 
(b) 
l
b 
n 
j(t)dBt = 
lim Lf(ti- 1)(Bt,- Bt,_,), 
inprobability, 
a 
IID.nii--+Oi=l 
where ~n = {to,tl, ... ,tn} is a partition ofthefinite interval [a,b] and 
ll~nll = maxl<i<n(ti- ti-dÂ· 
Theorem 33.2. Let f E Lad(O,L2 [a,b]). Let {Xt: a::; t::; b} be a stochastic 
process defined as 
Xt = 1t f(u)dBu, 
t E [a, b]. 
Then { Xt : a ::; t ::; b} is a local martingale with respect to the underlying filtration 
{fft: a::; t::; b}. 
Theorem 33.3 (Continuous Realization). Let f E Lad(O, L2[a, b]). Then the pro-
cess 
Xt = lt f(u)dBu, 
t E [a, b] 
has a continuous realization; that is, there exists a continuous stochastic process 
{Yi : a ::; t ::; b} such that for each t E [a, b], Yi = Xt a.s. 

PROBLEMS 
455 
33.2 
Problems 
33.1. Let L~d([a, b] x 0) be the space of stochastic processes defined in Definition 
32.1. Let Lad(O, L2 [a, b]) be the space of stochastic processes defined in Definition 
33.1. Show that 
33.2. Let f E Lad(O, L2[a, b]). Show that there exists a sequence Un}n>l of 
functions in L~d([a, b] x 0) such that 
-
(a) 
(b) 
where ~ 
denotes convergence almost surely. 
1b lfn(t)- J(tWdt ~ 
0, 
where ~ 
denotes convergence in probability. 
33.3. Let f E Lad(O, L2[a, b]). For each fixed n 2': 1, let Tn be defined as 
where 
{
inf An(w) 
if An(w) =J 0; 
Tn(w) = 
b 
if An(w) = 0, 
An(w) = { t E [a, b]: 1t lf(u, w)l 2du > n}. 
Show that the Tn is a stopping time. 
(33.1) 
33.4. LetT be a stopping time with respect to a filtration { Â§t : t ;::: 0}. Let { Xt : t 2': 
0} be a process adapted to { Â§t : t 2': 0}. Show that { Xti\r : t ;::: 0} is a martingale 
with respect to the filtration { ,~ti\r : t 2': 0} if and only if it is a martingale with 
respect to the filtration { Â§t : t ;::: 0}. 
33.5. Let f E Lad(O, L2 [a, b]). Let { Xt : a <::: t <::: b} be a stochastic process 
defined as 
Xt = 1t f(u)dBu, 
t E [a, b]. 
Let Tn be as defined in Equation (33.1). Show that for each n, the stochastic process 
Xti\rn is a martingale, where t 1\ Tn = min(t, Tn)Â· 
33.6. Let f and g stochastic processes in L~d([a, b] x n). Let A be an event defined 
as 
A= {wE 0: j(t,w) = g(t,w) for all t E [a,b]}. 

456 
EXTENSION OF THE ITO INTEGRAL 
Show that 
almost surely on A: 
P {wE A: .lb f(t,w)dBt(w) i= 1b g(t,w)dBt(w)} = 0. 
33.7. Let f E Lad(D, L2 [a, b]). For every t E [a, b], let Mt be defined as 
Mt = 1t j(8)dBs. 
Suppose that supa<::t<::b Mt is square-integrable. Show that f E L~d([a, b] x D). 
33.3 
Hints 
33.1. Use the Fibini theorem (Theorem 10.2). 
33.2. Part (a) can be proved by considering the sequence 
{
f(t,w) 
if J~ lf(u,wji2du::; n; 
fn(t, w) = 
O 
otherwise. 
Part (b) is implied by part (a). 
33.3. Use the result of Problem 23.10 and note that 
33.4. The "if" part can be proved by noting that !#'sAT ~ .'#"8 â¢ To prove the "only 
if" part, use the definition of conditional expectations (Definition 14.1) and consider 
C = (Cn {T::; .s}) U (Cn {T > .s}) 
to prove, for every C E !78 , that 
1 
XsATdP = 1 
XtATdP. 
c 
c 
33.5. Consider the stochastic process 
{
f(t,w) 
fn(t, w) = 
0 
otherwise, 

SOLUTIONS 
457 
and use the martingale property of the Ito integral (Theorem 32.2). 
33.6. 
Consider the random variable X = J:[J(u) - g(u)]dBu, where T is a 
stopping time defined as 
{
inf{t: f(t,w) -1- g(t,w)}, 
if {t: f(t,w) -1- g(t,w)} -1- 0; 
T(w) = 
b, 
if {t: f(t,w) -1- g(t,w)} = 0. 
33.7. Use the results of Problems 33.3 and 33.5 to show that 
where Tn is as given in Problem 33.3. 
33.4 Solutions 
33.1. Suppose that f E L~d([a, b] x 0). By Theorem 10.2, we have 
Let An be sets defined as 
An= { w: 1b lf(t,wWdt < n}, 
n 2 1. 
Then 
We claim that 
In fact, if this is not the case, then there exists an E > 0 such that 
which implies that P(A~) > E for all n 2 1. Then 
(33.2) 
(33.3) 

458 
EXTENSION OF THE ITO INTEGRAL 
for all n ~ 1. This contradicts Inequality (33.2). Hence Equation (33.3) is true. 
Therefore f E Lad(O, L 2 [a, b]). This completes the proof. 
33.2. 
(a) Let {fn}n~l be a sequence of functions defined as 
_ {f(t,w) 
if I: lf(u,wWdu :S:: n; 
fn(t,w)-
, 
0 
otherwise. 
By the assumption that f E Cad(O, L 2 [a, b]), we have 
1b lf(t)l 2dt < oo, 
a.s. 
Then we have 
n~l. 
lb 
1Tn 
lb 
a lfn(t)l 2dt = 
a IJ(tWdt :S:: 
a IJ(t)l 2dt < 00, 
a.s., 
where Tn = sup{t: I: lf(u)l 2du :<:; n}. Hence we have 
which implies that fn E L~d([a, b] x 0). 
Now we show that 
To do that, let 
A= { w: 1b lf(t,w)l 2 < oo}. 
Then P(A) = 1 by assumption. Note that 
Let w E A. Then 
WE { W: 1b lf(t,wW :S:: Nw} 
for some Nw ~ 1. Hence for any n ~ Nw, we have fn(t, w) = f(t, w) for all 
t E [a, b]. Therefore 
1b lfn(t)- f(t)l 2dt = 1b Odt = 0 for all 
n ~ Nw, 

SOLUTIONS 
459 
which implies that 
Since P(A) = 1, the almost surely convergence is true. 
(b) By Problem 9.3, J: lfn(t) - f(t)i 2dt converges to 0 almost uniformly. By 
Problem 9.2, the sequence also converges in probability. 
This completes the proof. 
33.3. Since { Tn < a} = 0, we have { Tn < a} E Â§aÂ· Now lett E (a, b]. We claim 
that 
(33.4) 
where Q denotes the set of all rational numbers. Let w E { T n < t}. Since 
we have 
WE { Tn ~ t- ~} 
for some m ~ 1. Hence we have 
Thus there exists a rational number r E ( t -
~, t) such that 
which implies that 
Hence we have 
On the other hand, it is obvious that 

460 
EXTENSION OF THE ITO INTEGRAL 
Therefore Equation (33.4) is true. 
Since Equation (33.4) holds, we have { Tn < t} E fft. Hence by Problem 23.10, 
the r n is a stopping time. 
33.4. Let us first prove the "if" part. Suppose that { XtM : t 2: 0} is a martingale 
with respect to the filtration { fft : t 2: 0}. Then for all 0 :::; s < t, we have 
E[XtMiffs] = Xst\TÂ· 
Since ffst\T <::;; ffs (see Problem 23.4) and Xst\T is ffsM-measurable (see Problem 
23.11), it follows from Problems 14.10 and 14.4 that 
Hence {XtM: t 2: 0} is a martingale with respect to the filtration {fftt\T: t 2: 0}. 
Now let us prove the "only if" part. Suppose that {Xtr\T : t 2: 0} is a martingale 
with respect to the filtration { fftM : t 2: 0}. Let 0 :::; s < t. Then, for all A E ffsM 
(see Problem 22.3), we have 
i XsMdP = i Xtt\TdP. 
Let C E Â§
8 â¢ Then 
C= (Cn{r:::; s})u(Cn{r > s}). 
Since C n { r > s} n { r :::; r} = C n { s < r :::; r} E ffr for all r 2: 0, it follows 
from Definition 23.3 that c n { T > s} E ffst\Tâ¢ Hence we have 
1 
Xst\TdP = 1 
Xtt\TdP. 
Cn{ r>s} 
en{ r>s} 
Also we have 
Combining Equations (33.5) and (33.6) gives 
i Xst\TdP = i XuvrdP. 
Therefore, we have 
This completes the proof. 
33.5. Let n be fixed and let f n be a stochastic process defined as 
{
f(t,w) 
fn(t,w) = 
O 
otherwise. 
(33.5) 
(33.6) 

SOLUTIONS 
461 
Then we have 
1
t/\Tn 
1t 
Xt/\Tn = a 
f(u)dBu = a fn(u)dBu, 
t E [a, b]. 
Note that I: lfn(tWdt::; n a.s. We have I: E(lfn(t)l 2 )dt::; n, which implies that 
fn E L~d([a, b] x 0). By Theorem 32.2, XtATn is the martingale. This completes 
the proof. 
33.6. LetT : n -+ [a, b] be a random variable defined as 
{
inf{t: f(t,w) =1- g(t,w)}, if {t: f(t,w) =1- g(t,w)} =1- 0; 
T(w) = 
b, 
if {t: f(t,w) =1- g(t,w)} = 0. 
Then T is the stopping time. Let X ( T) be a random variable defined as 
X(T) = 1T (f(u)- g(u))dBu = 1b I[a,Tj(u)(f(u)- g(u))dBu. 
Since I[a,Tj(u)(f(u)- g(u)) E L~d([a,b] x 0), the X(T) is defined. Then, by 
Theorem 32.1, we have 
But 
1b I[a,Tj(u)if(u)- g(u)l 2du = 1T lf(u)- g(u)l 2du = 0, 
a.s. 
Therefore we have E(IX(TW) = 0, which implies that X(T) = 0 a.s., that is, 
P(X(T) = 0) = 1. Now let wE A. Then T(w) = b by the definition of A. Hence 
we have X(T(w)) = I:(f(u)- g(u))du. Hence we have 
{wE A: 1b f(t,w)dBt(w) =1-jb g(t,w)dBt(w)} <;;; {X(T) =/:- 0}, 
which implies that 
P {wE A: 1b f(t,w)dBt(w) =1-jb g(t,w)dBt(w)} = 0. 
This completes the proof. 
33.7. Let { Tn : n ;:::: 1} be the sequence of stopping times defined in Problem 33.3. 
For each n;:::: 1, let fn(t) = f(t)I{tSJn}Â· Then we have 
1
t/\Tn 
1b 
Mt/\Tn = a 
f(s)dBs = a fn(s)dB 8 â¢ 

462 
EXTENSION OF THE ITO INTEGRAL 
Since 
< 
n, 
we have fn E L~d([a, b] x 0). Then it follows from Theorem 32.1 that 
By the assumption that supa:c;t:c;b 1\It is square-integrable, we have 
E [Mt2ATJ :::; E [ sup llft2] = L < oo, 
a:c;t:c;b 
(33.7) 
(33.8) 
where L is some positive constant. From Equations (33.7) and (33.8), for every 
n ?: 1, we have 
E [1bAT, f(s) 2ds] :::; L. 
Since T n ---t b as n ---t oo, letting n ---t oo in the above equation gives 
Hence j E L~d([a, b] x r2). This completes the proof. 
33.5 
Bibliographic Notes 
In this chapter, we introduced the Ito integral for stochastic processes f ( t) satisfying 
the condition 
1b lf(t)l 2dt < oo, 
a.s. 
The resulting Ito integral is a random variable, which in general is not integrable. 
The associated stochastic process 
Xt = 1t f(u)dBu, 
t E [a, b], 
may not be a martingale but is a local martingale. For more information about the 
extension of Ito integrals, readers are referred to Karatzas and Shreve ( 1988), Lam-
berton and Lapeyre (1996), Steele (2003), and Kuo (2006, Chapter 5). For proper-
ties of local martingales, readers are referred to Durrett ( 1996), Meyer (2000), Steele 
(2003), and Medvegyev (2007). 

CHAPTER34 
MARTINGALE STOCHASTIC 
INTEGRALS 
In the previous two chapters, we introduced stochastic integrals with respect to stan-
dard Brownian motions. In this chapter, we expand the definition of stochastic inte-
gral such that the integrators are right-continuous and square-integrable martingales. 
34.1 
Basic Concepts and Facts 
Definition 34.1 (Stochastic Process Space IL([a, b] x 0)). Let { $t : a :::; t :::; b} be 
a right-continuous filtration. The stochastic process space IL([a, b] X n) is the space 
of all stochastic processes X ( t, w) satisfying the following conditions: 
(a) X ( t) is adapted to the filtration { $t : a :::; t :::; b}. 
(b) Almost all sample paths of Xt are left-continuous. 
Definition 34.2 (Predictable Stochastic Process). Let P be the smallest a-field of 
subsets of [a, b] X n with respect to which all stochastic processes in IL([a, b] X n) 
are measurable. A stochastic process { Xt : a :::; t :::; b} is said to be predictable if 
the function 
(t,w) ~ Xt(w), 
(t,w) E [a,b] X 0, 
Measure, Probability, and Mathematical Finance. 
463 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

464 
MARTINGALE STOCHASTIC INTEGRALS 
is P-measurable. 
Definition 34.3 (Increasing Process). A stochastic process { Xt : a ::; t ::; b} on a 
probability space (0, Â§, P) is said to be increasing if there exists a set 0 0 ~ 0 with 
P(00 ) = 1 such that for every w E 0 0 , 
(a) Xo(w) = 0. 
(b) The function t --+ Xt ( w) is a nondecreasing, right -continuous function, 
and E(Xt) < oo holds for every t E [a, b]. 
Definition 34.4 (Natural Process). An increasing process {At : a ::; t ::; b} is 
considered natural if for every bounded, right-continuous martingale { Mt : a ::; t ::; 
b} with left-hand limits, we have 
E ( { 
M 8 dA 8 ) == E ( { 
Ms_dAs) , 
J(o,t] 
J(o,t] 
where M 8 _ is the left-hand limit of Mt at s. 
Definition 34.5 (Square-Integrable Stochastic Process). A stochastic process { Xt : 
a ::; t ::; b} is said to be square-integrable if and only if for each t E [a, b], we have 
E(X;) < oo. 
Definition 34.6 (p-th Variation Process). Let X = { Xt : a ::; t ::; b} be a stochastic 
process. Let p > 0. Then the p-th variation process of X is defined as 
n 
[X]~P) = 
lim L IXtk -
Xtk~,IP, 
(in probability) 
IIAII--+D k=l 
where Ll = { t0 , t 1 , ... , tn} is a partition of the interval [a, t] and 
In particular, if p = 1, the process is referred to as the total variation process. If 
p = 2, the process is called the quadratic variation process and is written as [X]t. 
Definition 34.7 (Stochastic Process Sapce L;red([a, b] (M) x 0)). The space 
denotes the space of all predictable stochastic process f : [a, b] x 0 --+ R satisfying 
the following condition: 

BASIC CONCEPTS AND FACTS 
465 
Definition 34.8 (Martingale Stochastic Integral for Step Stochastic Processes in Stochas-
tic Process Space L~red([a, b] (M) x 0)). Let { Mt : a ~ t ~ b} be a right-continuous, 
square-integrable martingale with left-hand limits. Let f be a step stochastic process 
in L~red([a, b](M) X 0) given by 
n 
f(t,w) = L~i-l(w)I(t;_ 1 ,t;J(t), 
i=l 
where ~i-1 is Â§t;_ 1 -measurable fori = 1, 2, ... , n. Then the stochastic integral of 
f with respect to the martingale Mt is defined as 
n 
I(!)= L~i-l(Mt;- Mt,_J. 
(34.1) 
i=l 
Definition 34.9 (Martingale Stochastic Integral for General Stochastic Processes in 
Stochastic Process Space L~red([a, b](M) x 0)). Let {Mt :a~ t ~ b} be a right-
continuous, square-integrable martingale with left-hand limits. Let f be a stochastic 
process in L~red([a, b](M) x 0). Then there exists a sequence {fn}n~l of step 
stochastic processes in L~red([a, b](M) x 0) such that 
Then the stochastic integral of f with respect to the martingale Mt. denoted by 
J: f(t)dMt, is defined as 
1
b f(t)dMt = lim I(fn), 
in 
L2(0), 
a 
n--+oo 
(34.2) 
where I ( Â·) is as defined in Equation (34.1 ). 
Definition 34.10 (Stochastic Process Sapce .Cpred(O, L 2[a, b] (M))). The space 
denotes the space of all predictable stochastic process f : [a, b] x 0 --+ R satisfying 
the following condition: 
Definition 34.11 (Martingale Stochastic Integral for Stochastic Processes in the Pro-
cess Space .Cpred(O, L 2 [a, b] (M) )). Let { Mt : a ~ t ~ b} be a right-continuous, 
square-integrable martingale with left-hand limits. Let f be a stochastic process in 

466 
MARTINGALE STOCHASTIC INTEGRALS 
the space Lpred(O, L2 [a, b]\M)). Then there exists a sequence Un}n;:>l of stochastic 
processes in L~red([a, b](M) x 0) such that 
lim {b lf(t) ~ fn(tWd(M/t = o, 
a.s. 
n--+OCJ} a 
Then the stochastic integral of f with respect to the martingale Aft, denoted by 
I: f(t)dMt. is defined as 
{ f(t)dMt = lim 
fn(t)dMt, 
b 
1b 
} a 
n--+CXJ 
a 
in probability. 
(34.3) 
Theorem 34.1 (Doob-Meyer Decomposition for Ml). Let { Mt : a ::= t ::= b} be a 
right-continuous, square-integrable martingale with left-hand limits. Then the pro-
cess Ml can be uniquely (up to indistinguishability) decomposed as 
M? = Lt +At, 
a 2= t 2= b, 
where the Lt is a right-continuous martingale with left-hands limits and the At is a 
natural process. 
Process At is called the compensator of Ml and is denoted by (M/t. 
Theorem 34.2. Let { Mt : a ::= t ::= b} be a continuous and square integrable 
martingale. Then 
[M]t = (M/t, 
a 2= t 2= b, 
where [iVI]t is the quadratic variation process (see Definition 34.6) and (lvf/t is the 
compensator of Ail. 
Theorem 34.3. Let { Mt : a ::= t ::= b} be a right-continuous, square-integrable mar-
tingale with left-hand limits. Let f be a stochastic process in L~red([a, b](M) x 0). 
Then the stochastic integral I: f(t)dMt defined in Equation (34.2) is well defined. 
In addition,forany a, (3 E Rand f,g E L~red([a, b](M) X 0), we have 
rb 
rb 
rb 
}a. (af(t) + f3g(t))dMt =a }a. f(t)dMt + f3 }a g(t)dMt. 
Theorem 34.4. Let f E L~red([a, b] (M) x 0). Let {Xt : a 2= t 2= b} be a stochastic 
process defined as 
Then 
(a) The Xt is a martingale. 
(b) 

BASIC CONCEPTS AND FACTS 
467 
(c) The Xt is right-continuous with left-hand limits, that is, almost all of its sample 
paths are right-continuous functions with left-hand limits on [a, b]; 
(d) The compensator of Xf is given by 
Theorem 34.5. Let f E .Cpred(O., L2 [a, b] (M) ). Let { Xt : a ~ t ~ b} be a stochas-
tic process defined as 
Then 
(a) The Xt is a local martingale. 
(b) The Xt has a right-continuous realization with left-hand limits. 
(c) If the Mt is continuous, then the Xt has a continuous realization. 
Theorem 34.6. Let { Mt : a ~ t ~ b} be a continuous and square-integrable 
martingale. Let f be a continuous stochastic process in .Cpred(O., L2 [a, b] (M) ). Then 
1
b 
n 
f(t)dMt = 
lim Lf(ti_I)(Mti -Mti_ 1 ), 
inprobability, 
a 
ll~n 11-+0 i=l 
where ~n = {to, h, ... , tn} is a partition of the interval [a, b] and 
Theorem 34.7. Let { Mt : a ~ t ~ b} be a continuous and square-integrable 
martingale. Let f be a bounded, continuous, and adapted stochastic process. Then 
in probability, 
where ~n = {to, h, ... , tn} is a partition of the interval [a, b] and 
The left-hand side is the Riemann-Stieltjes integral J: f(t, w)d(M)t(w) defined for 
each win some 0.0 with P(0.0 ) = 1. 

468 
MARTINGALE STOCHASTIC INTEGRALS 
34.2 
Problems 
34.1. Let { fft : a :S; t :S; b} be a right-continuous filtration. Let a :S; s < t :S; band 
A E :75 â¢ Let { ~'" a :S; u :S; b} be a stochastic process defined as 
~(u,w) = IA(w)I(s.tJ(u), 
u E [a, b], wE D. 
Show that ~u E JL([a, b] x D). 
34.2. Let { fft : a :S; t :S; b} be a right-continuous filtration, which is complete (i.e., 
all u-fields fft are complete). Assume that for each t E [a, b], the a-field fft is 
complete. Let C be a collection of sets defined as 
C = {(s,t] x A: a :S; s < t :S; b, A E ffs} U {{a} x B: BE :70 }. 
Show that 
P = a(C), 
where P is as defined in Definition 34.2, namely, it is the smallest u-field of sub-
sets of [a, b] x D with respect to which all stochastic processes in JL([a, b] x D) are 
measurable. 
34.3. Let { Mt : a :S; t :S; b} be a square-integrable martingale. Show that { Ml : 
a :S; t :S; b} is a submartingale. 
34.4. Let { Bt : t ;::: 0} be a standard Brownian motion. Find the Doob-Meyer 
decomposition of Bf. 
34.5. Let { Bt : t ;::: 0} be a standard Brownian motion, and let Mt = Bf - t. Then 
the Mt is a martingale. Find the Doob-Meyer decomposition of Ml. 
34.6. Let { Bt : a :S; t :S; b} be a standard Brownian motion and { Nt : a :S; t :S; b} 
be a compensated Poisson process with parameter A. Let Nit = Bt + Nt. Assume 
that the Bt and the Nt are independent. Calculate (M)t and [M]t. 
34.7. Let { l\!It : a :S; t :S; b} be a right-continuous, square-integrable martingale 
with left-hand limits. For any a :S; s < t :S; b, show that 
34.8. Let { Mt : t ;::: 0} be a continuous and square-integrable martingale. Show that 
34.9. Let f be a step stochastic process and .Mt a martingale given in Definition 
34.8. Show that 

HINTS 
469 
where I (f) is as defined in Equation (34.1 ). 
34.10. Let ,\ E R and { Bt : 0 ::; t} be a standard Brownian motion. Let 
Mt = exp ( .ABt - ~
2 t) , t :::: 0. 
Show that 
(a) The Mt is a martingale. 
(b) The compensator of Mf is given by 
34.3 Hints 
34.1. Follow the definition oflL([a, b] x !J) (Definition 34.1). 
34.2. Use the standard technique, that is, show that P <:;;; a( C) and a( C) <:;;; P. To 
prove a( C) <:;;; P, one can choose special functions from JL([a, b] x !:1). To prove 
P <:;;; a( C), one can show that a process X E JL([a, b] x !J) is a( C)-measurable by 
constructing a sequence of processes 
Xn(t,w) = {X(a,w), 
X(rk, w), 
where rk = 2kn (b- a)+ a, k = 0, 1, ... , 2n. 
if t =a; 
if rk < t::; rk+l' 
34.3. Use the conditional Jensen's inequality (see Problem 15.7). 
34.4. Note that the B; - t is a martingale. 
34.5. 
Let 0 ::; s < t. Suppose that the Doob-Meyer decomposition is Mf 
Lt +At. Then consider E(Mn~s = Ls + E(Atlffs)Â· 
-
-
34.6. 
Use the independence of the Bt and the Nt to establish that the BtNt is a 
martingale. Then use the results of Problems 32.11, 27.6, and 27.7. 
34.7. Use the Doob-Meyer decomposition of Mf. 
34.8. Use Theorems 34.6 and 34.2. 
34.9. Follow the definition of J(f) (Definition 34.8) and use the tower property of 
conditional expectations (see Problem 14.10) and the result of Problem 34.7. 
34.10. Part (a) can be proved by the result of Problem 19.1. To prove part (b), let 
Mf = Lt + At and consider the conditional expectation E ( Mfl ffs). 

470 
MARTINGALE STOCHASTIC INTEGRALS 
34.4 Solutions 
34.1. By the definition of ~u. we have 
Hence for u < s, we have 
if u :S: s; 
if s < u ::::: t; 
ift < u .. 
{ 0 
ifO E BÂ·, 
~;;l(B) = 
0,' 
ifO ~B. BE B, 
which implies that ~" E /~, for u < s. Similarly, we can show that ~u E ffu for 
u E (s, t] and for u E (t, b]. Hence ~u is adapted to the filtration {.9't :a :S: t :S: b }. 
It is left to show that ~u is left-continuous. Let w E 0 be fixed. Then 
( 71 w) = {J(s,tj(u). 
ifw E A; 
~ ' 
0, 
if w ~ A. ' 
Â·u E [a, b], 
which shows that the sample path ~(Â·,w) is left-continuous. Since w is arbitrary, (u 
is a left-continuous process. Therefore, (u E IL([a, b] x 0). This completes the proof. 
34.2. First let us show that a( C) c-;; P. Let a :S: s < t :S: band A E .9'8 â¢ Consider 
the random variable ( ( n, w) defined as 
((n,w) = IA(w)I(s,tj(u), 
11 E [a,b], wEn. 
By Problem 34.1, we have (, E IL([a, b] x 0). Then by the definition of P, ~u is 
P-measurable. But 
(;; 1(1) = (s, t] x A, 
we have (s, t] x A E P. Similarly, we can show that {a} x B E P for all B E ffa.. 
Since Pis the a-field, we have a( C) c-;; P. 
Now we show that P c-;; a( C). To do this, let X E IL([a, b] x 0). Then X is 
adapted to { fft : a :S: t :S: b} and almost all sample paths of X are left-continuous. 
We show that X is a(C)-measurable. Let D E B. Let {Xn}n>l be a sequence of 
processes defined as 
( 
) 
{ X(a, w), 
Xn t.w = 
Â· 
X(rk,w), 
if t =a; 
ifrk < t :S: rk+lÂ· 
where Tk = 2kn (b- a)+ a, k = 0, 1, ... , 2n. Then we have 
{(t,w) E [a,b] x n: Xn(t,w) ED} 
{{a} x {wEn: X(a,w) ED}} U 
u {(rk, rk+l] x {wE 0: X(rk, w) ED}}. 
k=O 

SOLUTIONS 
471 
Note that X is adapted to the filtration fft. We have 
{(t,w) E [a,b] x [2: Xn(t,w) ED} E C. 
Hence Xn is o-(C)-measurable. Since Xn converges to X a.s. and the filtration is 
complete, X is also CT(C)-measurable. Therefore, we have P <;;: CT(C) because Pis 
the smallest CT-field to which processes in JL([a, b] x n) are measurable. 
This completes the proof. 
34.3. Since { Mt : a :s; t :s; b} is a martingale, the M'f is an adapted process. By the 
assumption that the Mt is square-integrable, we have E(IMtl 2 ) < oo. Now by the 
conditional Jensen's inequality (see Problem 15.7), for a :s; s < t :s; b, we have 
E (M[Iffs) ~ [E(Mtlffs)] 2 = M?. 
Therefore, the M'f is a submartingale. 
34.4. Let 0 :s; s < t. Then 
E (Bllffs) 
= 
E ((Bt- Bs + Bs) 2lffs) 
= B; + t- s, 
which implies that Bj; -tis a martingale. Note that 
Bl = (Bl - t) + t. 
The Doob-Meyer decomposition is Lt = Bj; - t and (B)t = t. 
34.5. Let 0 :s; s < t. Then 
and 
E (B{Iffs) = B! + 6(t- s)B; + 3(t- s) 2 . 
Suppose that the Doob-Meyer decomposition of M'f is Lt +At. Then we have 
which gives 
E (B{Iffs) - 2tE (Bllffs) + t 2 
B! + (4t- 6s)B; + 3s2 - 4ts + t2 
Ls + E(Atlffs) 
M?- As+ E(Atlffs), 
E(At- Aslffs) = 4(t- s)B; + 2(t- s) 2 . 
Note that E (B'flffs) = B;- s + t. We have 
lt E(B;Iffs)du 
lt(B;+u-s)du 
2 
1 
2 
(t- s)B8 + 2(t- s) . 

472 
MARTINGALE STOCHASTIC INTEGRALS 
Hence we have 
and 
Lt = (Bl - t) 2 -fat B~du. 
34.6. Let 0 ::=:; s < t. Then we have 
E(Btlltlff:.) 
= 
E[(Bt- B.+ B.)(Nt- N. +IV.) Iff:.] 
= BsNs, 
which implies that BtNt is a martingale. By Problem 27.7, Nl- >.tis a martingale. 
Therefore, the following process 
2 
2 
-
-2 
Mt - (1 + >.)t = (Bt - t) + 2BtNt + (Nt - >.t) 
is a martingale. Hence we have the following Doob-Meyer decomposition for Ml; 
Mt2 = (M'f - (1 + >.)t) + (1 + >.)t, 
which gives (M)t = (1 + >.)t. 
Now let us calculate [ M]t. Let .6-n = { t0 , t 1 , ... , tn} be a partition of the interval 
[0, t]. Then we have 
n 
:~::)Mt; - Mt;_, )2 
i=l 
n 
i=l 
n 
n 
L(Bt;- Bt;_,)2 + L2(Bt;- Bt;_,)(Nt;- Nt;_,) 
i=l 
i=l 
n 
+ L(Nt;- Nt;_,) 2 . 
i=l 
Hence by Problems 32.11 and 27 .6, we have 
[M]t = (1 + >.)t + Nt. 
34.7. By Theorem 34.1, Ml can be uniquely decomposed as 
M'f = Lt + (M)t, 
a::::; t::::; b, 
where the Lt is a martingale. Then we have 
E [M'f- 2MtMs + M;lff:s] 
E[Lt + (M)tlff:.]- M; 
E[Lt + (M)tlff:s]- Ls- (M)s 
E[(M)t- (M).Iff:.]. 

SOLUTIONS 
473 
This completes the proof. 
34.8. Let Rn and Ln be defined as 
n 
Rn = LMt;(Mt;- Mt;_J, 
i=1 
and 
n 
Ln = LMt;_ 1 (Mt;- Mt;_J, 
i=1 
respectively, where .6.n = {t0 , h, ... , tn} is a partition of the interval [0, t]. Then 
we have 
n 
Rn + Ln = L(Mt; + Mt;_J(Mt;- Mt;_J = M'f- M5 
i=1 
and 
n 
Rn- Ln = L(Mt;- Mt;_ 1 ) 2â¢ 
i=1 
Solving the above equations gives 
The result follows by letting ll.6.nll ---+ 0 and Theorem 34.2. This completes the 
proof. 
34.9. By the definition of I(f) in Equation (34.1), we have 
IIUW 
n 
L 
~;_1 (Mt; - Mt;_J 2 + 2 L 
~i-1~j-1 (Mt; - Mt;_J(Mtj - Mtj_J. 
i=1 
i<j 
By Problems 14.10 and 34.7, we have 
E [E {~t_1(Mt;- Mti-1) 2 lÂ§ti-1}] 
E [~I-1E { (Mt;- Mti-1) 2 iÂ§ti-1}] 
E [~I-1E{((M)t;- (M)t;_JIÂ§ti-1}] 
E [~I- 1 ((M)t;- (M)t;_J]. 
Again by Problem 14.10, we have for i < j, 
E [~i-1~j-1(Mt;- Mt;_J(Mti- Mti_ 1 )] 
E [E { ~i-1~j-1(Mt;- Mt;_J(Mtj- Mtj_JI$tj_1}] 
E [~i-1~j-1(Mt;- Mt;_ 1 )E { Mti- Mtj_1iÂ§tj_1}) 
0. 

474 
MARTINGALE STOCHASTIC INTEGRALS 
Therefore, we have 
E [IIUW] 
This completes the proof. 
34.10. 
n l::E [~f_l(Mti- Mti_,)2] 
i=l 
n l::E [e_l((M)t,- (M)ti_J] 
i=l 
E [t~f_ 1 ((M)t,- (M)ti_Jl 
E [1b lf(tWd(M)tlÂ· 
(a) It is obvious that the Mt is an adapted process and is integrable. Since Bt- Bs 
is normally distributed with mean 0 and variance t - s, by Problem 19.1 we 
have 
exp ( AB8
-
~
2 t) E [ e>.(B,-Bs) I ~s] 
exp ( >.B8
-
~
2 t) exp (~>. 2 (t- s)) 
exp ( >.Bs - ~
2 s) 
Ms. 
Hence the Mt is a martingale. 
(b) Let Mt2 = Lt + At. where Lt is a martingale. Then we have 
and 
E (e2>.B,->.2tl~s) 
e2>.B.->.2tE (e2>.(B,-B,)I~s) 
e2>.Bs ->.2 t e2>.2 (t-s) 
e2>.B.+>. 2t-2>.2 s 

BIBLIOGRAPHIC NOTES 
475 
Combining the above two equations gives 
E(At ~ AslÂ§s) = e2>-Bs+>-2t-2.\2s ~ e2>-Bs-A2S. 
On the other hand, we have 
E (it .A2e2>-Bu->-2udu! Â§s) 
lt .A2e2>-Bs->-2u E [ e2.\(Bu -Bs) lÂ§s] du 
~t .\2e2>-Bs+>-2(u-2s)du 
e2>-Bs+>- 2 (t-2s) ~ e2.\B 8 -.\2s. 
Comparing Equations (34.4) and (34.6) gives 
At= .A21t exp (2.ABs ~ .A2s) ds. 
This completes proof. 
34.5 
Bibliographic Notes 
(34.4) 
(34.5) 
(34.6) 
For more information on stochastic integration, readers are referred to Karatzas and 
Shreve (1988), Chung and Williams (1990), Durrett (1996), Oksendal (1998), Meyer 
(2000), and Protter (2003). Meyer (2000) introduced stochastic integration with 
many applications in finance. Durrett ( 1996) introduced stochastic integration with 
respect to local martingales. Bichteler (2002) presented stochastic integration with 
jumps. 
Theorem 34.1 is a special case of the Doob-Meyer decomposition theorem where 
the square of a martingale is considered. For a general Doob-Meyer decomposition 
and its proof, readers are referred to Karatzas and Shreve (1991, Theorem 4.10). 
Theorem 34.2 states that if a square integrable martingale Mt is continuous, then 
the compensator of Ml is just the quadratic variation process of Mt. For a proof of 
Theorem 34.2, readers are referred to Karatzas and Shreve (1991, Theorem 5.8). 


CHAPTER35 
THE ITO FORMULA 
The Ito formula in stochastic calculus is similar to the chain rule in Leibniz-Newton 
calculus. In this chapter, we introduce the simple Ito formula and its variations. 
35.1 
Basic Concepts and Facts 
Definition 35.1 (C2-Function). A function f on [a, b] is called a C2-function if and 
only iff is twice differentiable and the second derivative f" is continuous on [a, b]. 
Definition 35.2 (Stochastic Process Space .Cad(O, L1 [a, b])). Let { $t : a :::; t :::; b} 
be a filtration under consideration. The space .Cad(O, L1 [a, b]) is defined to be the 
space of all stochastic processes f(t,w), t E [a, b], wE 0, satisfying the following 
conditions: 
(a) f(t) is adapted to the $t. 
(b) J: lf(t)ldt < oo a.s. 
Measure, Probability, and Mathematical Finance. 
477 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

478 
THE IT6 FORMULA 
Definition 35.3 (Ito Process). A stochastic process { Xt : a ::; t ::; b} is called an Ito 
process if it has the form 
Xt = Xa + lt f(s)dB 8 + lt g(s)ds, 
a::; t::; b, 
(35.1) 
where Xa is ffa-measurable, f E .Cad(n, L2 [a, b]), and g E .Cad(n, L1[a, b]). 
For convenience, Equation (35.1) is also written in the following stochastic dif-
ferential form 
dXt = f(t)dBt + g(t)dt. 
(35.2) 
Definition 35.4 (Continuous Part of Quadratic Variation Processes). Let {Mt: a::; 
t ::; b} be a right-continuous, square-integrable martingale with left-hand limits. 
Then the continuous part of [ M] t is defined as 
[M]~ = [M]t - [M]a - L ~[M] 8 , 
a ::; t ::; b, 
a<s~t 
where ~[M]s is the jump of [M]s at s: 
~[M]s = [M]s- [M]s-Â· 
Definition 35.5 (Cross-Variation Process). Let X andY be right-continuous and 
square-integrable martingales. Then the cross-variation process (X, Y)t is defined 
by 
1 
(X, Y)t = 4" ((X + Y)t - (X - Y)t) , 
0 ::; t < oo. 
Theorem 35.1. Let f E C 2[a, b], that is, let f be a C 2-function on [a, b]. Then 
where the Bt is a standard Brownian motion. 
Theorem 35.2 (Ito's Formula). Let f(t, x) be a continuous function with continuous 
"ld .
. 
!!.1. !!.1. 
dlf:_j_ 'T'h 
partza 
erzvatzves at, ox, an ox2. ', en 
f(t, Bt)- f(a, Ba) 
1t a J 
jt (a J 
1 a2 J 
) 
a ax (s, Bs)dBs + a 
at (s, Bs) + 2, ax2 (s, Bs) ds. 
Theorem 35.3 (General Form of Ito's Formula). Let { Xt : a ::; t ::; b} be an Ito 
process given by 
Xt = Xa + lt f(s)dBs + lt g(s)ds, 
a::; t::; b, 

BASIC CONCEPTS AND FACTS 
479 
where Xa is $a-measurable, f E Lad(!1,L2[a,b]), and g E Lad(!1,L1[a,b]). Let 
()(t, x) be a continuous function with continuous partial derivatives~~' g!, and~-
(If~ is undefined at finitely many points, the formula still holds if I g:~ I is bounded 
and g! is defined for every x E Rand is continuous (Shreve, 2004, p205)). Then 
()(t, Xt) is also an Ito process and 
The general form of Ito's formula can be written in the following stochastic dif-
ferential form 
where (dXt) 2 = f(t) 2dt, which is derived symbolically using the Ito table given in 
Table 35.1. 
Table 35.1 
Ito table. 
X 
dBt 
dt 
dBt 
dt 
0 
dt 
0 
0 
Theorem 35.4 (Multidimensional Ito's Formula). Let BP), Bi2), . .. , Bim) be min-
dependent standard Brownian motions. Let xP)' xi2)' ... 'xin) ben Ito processes 
given by 
where X~i) is $a-measurable, fij E .Cad(n, L 2[a, b]), andgi E .Cad(n, L 1[a, b])for 
all1 :S: i :S: n and 1 :S: j :S: m. Let()( t, X1, X2, .â¢. , Xn) be a continuous function on 
[a, b] x Rn with continuous partial derivatives ~~, ::; , and a:.~xk for 1 ::; i, k ::; n. 

480 
THE IT6 FORMULA 
Then()( t, xpl, x?l, .. . , X~n)) has the following stochastic differential 
d()( 
(1) 
(2) 
(n)) 
t, xt , xt , ... , xt 
a() ( 
(1) 
(2) 
(n)) 
~ 
a() ( 
(1) 
(2) 
(n)) 
(i) 
at t,Xt ,Xt , ... ,Xt 
dt+ ~axÂ· t,Xt ,Xt , ... ,Xt 
dXt 
i=1 
z 
n 
n 
a2() 
+ ~ "-"-
(t x(ll x<2l 
x<nJ)dX(iJdx<kJ 
2 ~ 
~ 
ax .[)x 
' 
t ' 
t ' ... ' 
t 
t 
t ' 
i=1 k=1 
z 
k 
where dXt(i)dX~k) is computed using the Ito table given in Table 35.2. 
Table 35.2 
Multidimensional Ito table. In the table, 8;k is Kronecker delta, i.e., 8;k = 1 for 
i = k and 8;k = 0 fori =I k. 
x 
dB~k) 
dt 
dB~il 
8;kdt 
0 
dt 
0 
0 
Theorem 35.5 (Ito's Formula for Martingales). Let F be a C 2-function and Mt a 
right-continuous, square-integrable martingale with left-hand limits. Then 
F(Mt) - F(Ma) 
1 t F'(Ms_)dMs + ~ 1t F"(Ms)d[M]~ 
a 
2 
a 
+ L [F(Ms)- F(Ms-)- F'(Ms-)~Ms], 
a<s"'St 
where M 8 _ is the left-hand limit of M 8 , [M]; is the continuous part of [M]s (see 
Definition 35.4), and ~Ms = Ms - Ms-Â· 
Theorem 35.6 (Ito's Formula for Continuous and Square-Integrable Martingales). 
Let F( t, x) be a continuous function with continuous partial derivatives c;};, ~~, 
and ~. Let Mt be a continuous and square-integrable martingale. Then 
F(t, Mt)- F(a, Ma) 
1 t aF 
1t aF 
11t a2 F 
--;::}(s, M 8 )ds + 
~(s, M 8 )dM8 +-
!)2(s, Ms)d(M) 8 â¢ 
a ut 
a uX 
2 a uX 
Theorem 35.7 (Multidimensional Ito Formula for Continuous and Square-Integrable 
Martingales). Let MP), M?), ... , Mt(n) be n continuous and square-integrable 
martingales. Let F( t, x 1 , x2, .. . , xn) be a continuous function with continuous par-
tial derivatives c;};, g;,, and a~,?f'xk for alll :::; i, k :::; n. Then 

PROBLEMS 
481 
where ( Â·, Â·) is the cross variation process. 
Theorem 35.8 (Uniqueness of Cross-Variation Process). Let X andY be two right-
continuous and square-integrable martingales. Then the cross variation process 
(X, Y)t is (up to indistinguishability) the only process of the form A= A(l) -
A(2) 
with A(l) and A(2) adapted and natural, such that XY- A is a martingale. 
35.2 Problems 
35.1. Let g(x) be a continuous function on R. Let Xn be defined as 
n 
Xn = L 
[g(Bt,_ 1 + Ai(Bt,- Bt,_,))- g(Bt,_,)] (Bt,- Bt,_ 1 ) 2 , 
n::::: 1, 
i=l 
where ~n = {t0 , h, ... , tn} is a partition of the interval [a, t] and Ai E (0, 1) for 
i = 1, 2, ... , n. Show that there exists a subsequence of {Xn}n>l converging to 0 
a.s. as ll~nll--+ 0, where ll~nll = maxl::;i::;n(ti- ti-l)Â· 
35.2. Let g ( x) be a continuous function on R. Let X n be defined as 
n 
Xn = Lg(Bt,_ 1 ) [(Bt,- Bt,_,)2 - (ti- ti-l)], n::::: 1, 
i=l 
where ~n ={to, h, ... , tn} is a partition of the interval [a, t]. Show that 
p 
Xn ---+ 0 
as 
ll~n II --+ 0. 
35.3. Let { Bt : t ::::: 0} be a standard Brownian motion. Show that 
tBl = 2 {t sB8 dBs + t B;ds + ~t2 . 
lo 
lo 
2 
35.4. Let { Mt : 0 ::::; t} be a process defined by 
Mt = exp (cBt- ~c2t), t::::: 0, 
where c is a constant and the Bt is a standard Brownian motion. Show that 
(a) The Mt is martingale. 
(b) The compensator of Mf is 

482 
THE IT6 FORMULA 
35.5 (Langevin Equation). Let a E R and (3 > 0. Let { Xt : 0 ::::; t} be a process 
satisfying the following equation 
where x0 E R. Show that 
35.6 (Ito's Product Formula). Let Xt and yt be two Ito processes given by 
dXt = f(t)dBt + ~(t)dt 
and 
dyt = g(t)dBt + TJ(t)dt, 
respectively. Show that 
XtYt- XaYa 
1t [f(s)Ys + g(s)Xs] dB8 + 1t [~(s)Ys + TJ(s)Xs + f(s)g(s)] ds. 
35.7. Let X, Y, and Z be right-continuous and square-integrable martingales. Let 
a and (3 be real numbers. Show that 
(a) (X, Y)t = (Y, X)t. 
(b) (aX+ (3Y, Z)t = a(X, Z)t + (3(Y, Z)t. 
(c) (aX)t = a 2(X)t. 
(d) (X)t = (X, X)t. 
(e) I(X, Y)tl 2 ::::; (X)t(Y)t. 
35.8. Let B~ 1 ) and B?) be two independent standard Brownian motions. Calculate 
(B(1l + B(2l)t, (B(l)- B(2l)t, and (B(l), B(2l)tÂ· 
35.9. Let Xt and yt be two stochastic processes defined by 
and 

HINTS 
483 
respectively, where f, g E L~d([a, b] x 0). Show that 
(X, Y)t = 1t f(s)g(s)ds. 
35.10. Let {BP) : a ::::; t ::::; b} and {B~ 2 ) 
: a ::::; t ::::; b} be two independent 
Brownian motions. Let Xt and yt be two stochastic processes defined by 
and 
yt = 1t g( s )dBi2)' 
respectively, where f, g E L~d([a, b] x n). Show that 
(X, Y)t = 0. 
11 
(1) 
(2) 
(m) 
. 
35. 
â¢ Let c, a1, a2, ... , an be constants. Let Bt , Bt , ... , Bt 
be m mdepen-
dent standard Brownian motions. Let 
Xt = exp (ct + f ajB~j)) . 
J=l 
Show that 
35.12. Let n be a positive integer. Let f be a stochastic process such that fn E 
L~d([a, b] x n). Show that for every t E [a, b], we have 
where Cn is a constant depending only on n. 
35.3 
Hints 
35.1. Consider the sequence { ~n}n>l defined by 
~n = 
max 
lg(Bt ~ 1 + .A(Bt - Bt ~ 1 ))- g(Bt ~ 1 )1, 
n ~ 1 
l:O:i:O:n,0<.\<1 
' 
' 
' 
' 
and first prove that ~n --+ 0 a.s. as II ~n II --+ 0 by using the continuity of g and Bt. 

484 
THE ITO FORMULA 
35.2. Let L > 0 be a large number. Consider the sequence Sn,L given by 
n 
Sn,L = L g(Bt,_ 1 ) [(Bt; - Bt;_y- (t;- t;_J)] IA,_u, 
i=l 
where Ai-l,Â£ = { IBtj I :S: L for all j :S: i - 1} fori = 1, 2, ... , n. First show that 
Sn.L converges to 0 in L 2 (rl) and in probability. 
35.3. Use Ito's formula with f(t, x) = tx2 . 
35.4. Part (a) can be proved by using Ito's formula with 
f(t,x) = exp (ex- ~c2t) 
and Theorem 32.2. Part (b) can be proved similarly. 
35.5. Use the general form oflto's formula with B(t, x) = ef3tx. 
35.6. Apply the multidimensional Ito formula (Theorem 35.4). 
35.7. Part (a) can be proved by the definition of cross-variation processes (Definition 
35.5) and the fact that (X - Y) 2 = (Y - X?. Part (b) can be proved by using 
Theorem 35.8. Part (c) is implied by the definition. Part (d) can be derived from 
parts (b) and (c). Part (e), one can first establish that 
and then use the method of contradiction. 
35.8. First calculate (B(J), B(2))t by using the fact that B(l) B(2)- (B(l), B( 2)) 1 is 
a martingale. Other two compensators can be derived by using the results of Problem 
35.7. 
35.9. 
Use the definition of (X, Y)t (Definition 35.5), the result of Problem 34.8, 
and Theorem 35.3. 
35.10. The proof is similar to that of Problem 35.9, namely, using the definition of 
(X, Y)t (Definition 35.5), the result of Problem 34.8, and Theorem 35.4. 
35.11. Consider 
m 
yt = LajBij) 
j=l 
and B(t, x) = cxp(ct + x). Then apply the multidimensional Ito formula (Theorem 
35.4). 
35.12. First consider the case when f is bounded. Use Ito's lemma (Theorem 35.3), 
the result of Problem 32.16, and Holder's inequality (Theorem 8.1) to prove this case. 
Then consider the general case by constructing a sequence of bounded processes. 

SOLUTIONS 
485 
35.4 Solutions 
35.1. Let ~n be defined as 
~n = 1 s;is;~~>-< 1 ig(Bti- 1 + >..(Bti- Bti_J)- g(Bti_Ji, 
n ~ 1. 
By the definition of the Brownian motion, almost all sample paths of the Bt are 
continuous. Suppose that Bt ( w) is continuous for all w E A for some A <;;; n with 
P(A) = 1. Then for each wE A, we know that ~n(w) converges to 0 as ll.6.nll ---+ 0 
by the continuity of g(x) and Bt(w). 
By Problem 32.10, 2.::7=1 (Bti- Bti_1 )2 converges tot-a in L2 (!1). By Problems 
9.1 and 9.6, there exists a subsequence of 2.::7=1 (Bti - Bti_1? converging tot- a 
a.s. Since 
n 
i=l 
there exists a subsequence of Xn converging to 0 a.s. This completes the proof. 
35.2. Let L > 0. Let Ai-l,L be events defined as 
Ai-l,L = {IBtjl::; Lforallj::; i -1}, 
i = 1,2, ... ,n. 
Let Sn,L be a sequence defined as 
n 
Sn,L = Lg(Bti_1) [(Bti- Bti_1)2 - (ti- ti-l)] IAi-1,L' 
n ~ 1. 
i=l 
Let Yi = [(Bti- Bti-1) 2 - (ti- ti-l)] and zi,L = g(Bti-1)YiiAi-1,L fori = 
1, 2, ... , n. Let $t = cr(Bs : s ::; t). Then fori < j, we have 
Hence we have 
E[E(Zi,LZJ,LI$tj-1 )] 
E[g(Bti-1 )Yig(Btj-1 )IAi-1,L IAj-1,LE(Yj l$tj-1 )] 
0. 
n 
L 
E [zl,L] + 2 L 
E(Zi,Lz1,L) 
i=l 
i<j 
n 
< 2 max lg(xW L(ti- ti_I) 2 
lxls;L 
i=l 
< 
2 max lg(x)l 2 ll.6.nll(t- a), 
lxls;L 

486 
THE ITO FORMULA 
which implies that Sn,L Â£
2 (!:1) 0 as llb.nll---+ 0, By Problem 9,1, Sn,L converges to 
0 in probability, 
Now let E > 0. Then 
(35.3) 
Since 
we have by Doob submartingale inequality (see Theorem 24,1), 
{ 
} 
1 
1~t 
P{Sn cJ Sn,d <::: P 
max IBsl > L 
<::: -LE(IBtl) = -L -. 
a~s~t 
K 
2/2t 
Let 5 > 0. Let L!i = sy -:rrÂ· Then 
Since Sn,Ls converges to 0 in probability, there exist an Nc,J such that 
for all n:;:. N<,l5Â· Thus for n:;:. Nc15, we have by Equation (35.3), 
Since E and 5 are arbitrary, Sn converges to 0 in probability. This completes the 
proof. 
35.3. Let f(t,x) = tx 2 â¢ Then we have~{ = :r:2 , ~~ = 2tx, and~:{ = 2t. By 
Theorem 35.2, we have 
35.4. 
(a) Let f(t, x) = exp (ex- ~e2 t). Then we have 
of 
c2 
( 
1 2 ) 
-
= -- exp ex - - e t 
at 
2 
2 
' 

SOLUTIONS 
487 
and 
a2 j 
2 ( 
1 2) 
ax2 = c exp ex - 2c t . 
By Theorem 35.2, we get 
Mt -1 =lot cexp (cBs- ~c2 s) dB 8 â¢ 
Since cexp (cBs -
~c2 s) E L~d([O, t] x 0), Mt is a martingale by Theorem 
32.2. 
(b) Since M'f = e 2 cB,~c2 t, we consider the function f(t,x) = e 2cx~c 2 t. In this 
case, we have 
aj 
2 
( 
2 ) 
at = -c exp 2cx - c t ' 
aj 
ax = 2cexp (2cx- c2t)' 
and 
a2j 
ax2 = 4c2 exp (2cx- c2t). 
By Theorem 35.2, we have 
M'f- 1 = 2c lot exp (2cBs- c2s) dBs + c2 lot exp (2cBs- c2s) ds. 
By Theorem 32.2, 1 + 2c J~ exp (2cBs - c2 s) dB 8 is a martingale. Note that 
c2 lot exp ( 2cB s - c2 s) ds 
is an increasing process. The compensator of M'f is given by 
(M)t = c2 lot exp (2cBs- c2s) ds. 
35.5. Note that the Xt is an Ito process given by 
Xt = Xo +lot adBs +lot ( -f3Xs)ds. 
Let ()(t x) = ef3tx Then we have ae = (3ef3tx ae = ef3t and 88x2e2 = 0. By 
' 
Â· 
at 
, ax 
, 
Theorem 35.3, we have 
e13t Xt - Xo 
= 
lot ae138dBs +lot [f3ef3s Xs + ( -f3Xs)e138 + o] ds 
a 1t ef3 8 dB 8) 
0 

488 
THE ITO FORMULA 
which gives 
Xt = xoe-f3t +a 1t e-f3(t-s)dB8 â¢ 
This completes the proof. 
35.6. Let (}(t, x, y) = xy. Then we have ~~ = 0, g! = y, g~ = x, S = 0, and 
a2e 
Bx2 = 0. By Theorem 35.4, we have 
1 
1 
ytdXt + XtdYf + "2dXtdYf + 2dytdXt 
ytdXt + XtdYt + dXtdYf 
ytj(t)dBt + yt~(t)dt + Xtg(t)dBt + XtTJ(t)dt + f(t)g(t)dt 
[Ytf(t) + Xtg(t)]dBt + [yt~(t) + XtTJ(t) + j(t)g(t)]dt. 
The result follows from the above equation. This completes the proof. 
35.7. 
(a) Note that (X - Y) 2 = (Y - X) 2 . By the uniqueness of the Doob-Meyer 
decomposition, we have (X - Y)t = (Y - X)t. Hence we have 
(X, Y)t 
1 4 ((X + Y)t - (X - Y)t) 
1 4 ( (Y + X)t- (Y- X)t) 
(Y, X)tÂ· 
(b) By Theorem 35.8, (aX+ fJY, Z)t is the only process of the form A= A(l)-
A (2) with A (1) and A (2) adapted and natural, such that (aX + fJY)Z - A is a 
martingale. However, a(X, Z)t + fJ(Y, Z)t is a process of the same form such 
that 
(aX+ {JY)Z- a(X, Z)t- fJ(Y, Z)t 
is a martingale. Therefore, we have 
(aX+ {JY, Z)t = a(X, Z)t + fJ(Y, Z)t. 
(c) By definition, we have 
X'f = Mt + (X)t, 
where A1t is a martingale. Multiplying a 2 to both sides of the above equation 
gives 
(aXtf = a 2 Mt + a 2 (X)t. 
Since a 2 (X)t is an adapted and natural process and a 2 Mt is a martingale, we 
have (aX)t = a 2 (X)tÂ· 

SOLUTIONS 
489 
(d) By parts(b) and (c), we have 
1 
(X, X)t = 4(2X)t = (X)tÂ· 
(e) By part (b), we have 
(X + Y, X+ Y)t = (X)t + (Y)t + 2(X, Y)t 
and 
(X- Y, X- Y)t = (X)t + (Y)t - 2(X, Y)tÂ· 
Since 
(X+ Y, X+ Y)t = (X + Y)t ~ 0 
and 
(X - Y, X - Y)t = (X - Y)t ~ 0, 
we have 
2I(X, Y)tl :S (X)t + (Y)tÂ· 
Therefore, we have 
Replacing X by aX in the above equation and dividing a 2 in both sides, we 
get 
41 (X, Y)t 12 :S ( a(X)t - ~ (Y)t r 
+ 4(X)t (Y)tÂ· 
(35.4) 
Suppose that there exist a w0 such that 
I(X, Y)t(woW > (X)t(wo) Â· (Y)t(wo). 
B 
"f 
1 
(Y),(wo) Â· Eq 
Â· 
(35 4) 
ut 1 we eta= 
(X),(wo) m 
uahon 
. , we get 
I(X, Y)t(woW :S (X)t(wo) Â· (Y)t(wo), 
which contradicts Equation (35.5). Hence we have 
4I(X, Y)tl 2 :S 4(X)t(Y)t, 
which gives I(X, Y)tl 2 :S (X)t(Y)tÂ· 
This completes the proof. 
35.8. Let us first calculate (B(l), B(2))t. To do that, let us consider 
(35.5) 

490 
THE ITO FORMULA 
for s :::; t, where the ~t is a filtration under which Bil) and B?l are martingales. 
By using the properties of conditional expectations and the assumption that Bil) and 
Bl2l are independent, we have 
E ( Bi1l Bi2l l~s) 
E ( (Bil)- BFl)(Bi2l- Bi2l)J~s) + E ( BFl(Bi2l- B~2l)J~s) 
+E ( Bil) B~2 l l~s) 
E ((Bill - BFl)(B?l - Bi2l)) + B~ll E ( (Bi2l - Bi2l)J~s) 
+B(llB(2l 
s 
s 
B~ll B~2l. 
Hence the BPl Bi2l is a martingale. Therefore, we have 
(B(1l, B(2l)t = 0. 
Now by Problem 35.7, we have 
(B(1l + B(2l)t = (B(ll)t + (B(2l)t + 2(B(1l, B(2l)t = 2t 
and 
(B(1l - B(2l)t = (B(1l)t + (B(2l)t - 2(B(1l, B(2l)t = 2t. 
35.9. 
Since f, g E L~d([a, b] x D), it follows from Theorems 32.1 and 32.2 that 
Xt + yt = J:(f(s) + g(s))dB8 and Xt- yt = J:(f(s)- g(s))dB8 are continuous, 
square-integrable martingales. By Problem 34.8 and Theorem 35.3, we have 
(X+ Y)t 
(Xt + Yf)2 - (Xa + Ya) 2 - 21t (Xs + Ys)(f(s) + g(s))dBs 
1t (f(s) + g(s)fds. 
Similarly, we have 
(X- Y)t 
(Xt- Yf) 2 - (Xa- Ya) 2 - 21t (Xs- Ys)(f(s)- g(s))dBs 
1t (f(s)- g(s)fds. 
Then by Definition 35.5, we have 
1 
1t 
(X, Y)t =-((X+ Y)t- (X- Y)t) = 
f(s)g(s)ds. 
4 
a 

SOLUTIONS 
491 
This completes the proof. 
35.10. Since f, g E L~d([a, b] x f2), it follows from Theorems 32.1 and 32.2 that 
Xt and yt are continuous, square-integrable martingales. Since 
Xt + yt is also a continuous, square-integrable martingale. Similarly, Xt - yt is also 
a continuous, square-integrable martingale. By Problem 34.8 and Theorem 35.4, we 
have 
(X+ Y)t 
(Xt + Yt) 2 - (Xa + Ya) 2 - 21t (Xs + Ys)(f(s)dBFl + g(s)dB~2l) 
1t [!2(s) + g2(s)]ds. 
Similarly, we have 
(X- Y)t 
(Xt- Yf) 2 - (Xa- Ya) 2 - 21t (Xs- Ys)(f(s)dB~ 1)- g(s)dB~2)) 
1t [f2(s) + g2(s)]ds. 
Then by Definition 35.5, we have 
1 
(X, Y)t = 4((X + Y)t- (X- Y)t) = 0. 
This completes the proof. 
35.11. Let 
m 
Yt = LaiBij) 
j=l 
and B(t, x) = exp(ct + x). Then we have Xt = B(t, Yt) and 
m 
dyt = L dBij) 0 
j=l 

492 
THE ITO FORMULA 
By Theorem 35.4, we have 
This completes the proof. 
35.12. First let us assume that If I ::; k for some constant k. Let 
yt = 1t f(s)dBs, 
t E [a, b]. 
Then by Problem 32.16, exp(Â±yt) is finite. Hence all moments of Yt are finite. 
Therefore, we have 
which shows that Y 82n-l f(s) E L;d([a, b] x D). By Theorems 35.3 and 32.1, we 
have 
2nE [1t Y52n-l f(s)dBs] + n(2n- 1)E [1t Y52n- 2 j 2 (.s)ds] 
n(2n - 1 )E [1t Y82n-2 j 2 ( s )d.s] . 
(35.6) 
By Theorem 8.1, we have 
E [Y';2n] 
< n(2n- 1) 1t (E [Ys2n]) n;:' Â· (E [f2n(s)]) ~ ds 
n-1 
1 
:S: 
n(2n -1) (lt E [Y}n] ds) ---n Â· (1t E [f2n(s)] cis)" 
(35.7) 
Since Y';2n is a submartingale (see Problem 22.8), we get 

SOLUTIONS 
493 
Thus Equation (35.7) becomes 
1 
E [YrJ :::; n(2n- 1) ((t- a)E [Yr]) n;;:l Â· (1t E [f2n(s)] ds)"' 
Taking powers of n on both sides of the above inequality gives the result with Cn = 
[n(2n- l)]n. 
Now we prove the general case. Let fm(s) = min{m,max{-m,f(s)}} for 
m ~ 1. By the assumption that r E L~d([a, b] x 0), we have f E L~d([a, b] X 0) 
(see Problem 8.5). Since 
lfm(s)- f(s)l:::; lfm(s)l + lf(s)l:::; 21/(s)i, 
it follows from Theorem 6.4 that 
J~oo E [(fat fm(s)ds -lot f(s)ds) 
2
] 
lim E [ t Um(s)- f(s))2 ds] 
m-+oo 
Jo 
E [ rt lim Um(s)- f(s)) 2 ds] = 0. 
Jo n-+oo 
Hence 
1t fm(s)ds ~lot f(s)ds. 
Then by Problem 9.1 and Problem 9 .6, there exists a subsequence f m1 , f m2 , â¢â¢â¢ such 
that 
lot fm;(s)ds ~lot f(s)ds. 
Hence it follows from Fatou's lemma (Theorem 6.3) that 
Cn(t- a)n- 1 1t E [f2n(s)] ds 
> 
liminf ( Cn(t- a)n- 1 1t E [f!~(s)] ds) 
> liminfE [11t fm;(s)dB81
2nl 
> 
E [liminf 11t /m;(s)dB81
2nl 
E [11t f(s)dBsl2nlÂ· 
This completes the proof. 

494 
THE IT6 FORMULA 
35.5 
Bibliographic Notes 
In this chapter, we introduced the simple Ito formula, the multidimensional Ito for-
mula, and the Ito formula for martingales. For more information about Ito formula, 
readers are referred to Oksendal ( 1998) and Kuo (2006). Theorem 35.8 can be proved 
by using the same argument used to prove the uniqueness of the Doob-Meyer decom-
position (Karatzas and Shreve, 1991, p31 ). 
For some moment inequalities for Ito integrals, readers may read the papers by 
Zakai (1967) and Novikov (1973). 

CHAPTER 36 
MARTINGALE REPRESENTATION 
THEOREM 
The Ito integral defined in Chapter 32 is a martingale with respect to the underlying 
filtration. The martingale representation theorem states that the converse is also true. 
In this chapter, we introduce the martingale representation theorem. 
36.1 
Basic Concepts and Facts 
Theorem 36.1 (Martingale Representation Theorem). Let { g;tB : a ~ t ~ b} 
be the filtration generated by the Brownian motion {Bt : a ~ t ~ b}, that is, 
Â§l = a(Bs: s ~ t). Let {Mt: a~ t ~ b} be a square integrable martingale with 
respect to the filtration. Then Mt has a continuous version Mt given by 
where() E L~d([a, b] x D). 
Measure, Probability, and Mathematical Finance. 
495 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

496 
MARTINGALE REPRESENTATION THEOREM 
36.2 
Problems 
36.1. Let { Bt : t ;::: 0} be a Brownian motion with respect to a filtration { Y"t : t ;::: 
0}. Let 0 ::; a < band X be a finite Y"a-measurable random variable. Show that 
there exists a stopping time T with a ::; T < b such that 
(a) 
1
T 
1 
X= 
--dB1â¢ 
(l b- t 
(b) For any A > 0 and (3 E R, we have 
P{h(T);::: >-}::; ji + P{IXI ;::: 1!31}, 
where 
1
T 
1 
h(T) = 
( _ 
)2 ds. 
a 
b 
8 
36.2 (Representation by Informative Increments). Let { Bt : 0 ::; t ::; T} be a Brow-
nian motion and .'#r = a(Bt : t ::; T). Let X be a -~r-measurable random variable. 
Suppose that { an}n:;o- 1 and {bn}n:;o- 1 are two summable sequences of decreasing real 
numbers. Show that there exists an increasing sequence {tn}n> 1 of real numbers 
such that tn t T and a sequence { 6.n}n:;o. 1 of random variables such that 
(a) 6.n is -~tn -measurable for all n ;::: 1. 
(b) 
P {x = f 6.n} = 1. 
n=1 
(c) P { l6.n I ;:=: an} ::; bn for all n ;:=: 1. 
36.3 (Dudley's Representation Theorem). Let { Bt : 0 ::; t ::; T} be a Brownian 
motion and .'#r = a(Bt : t ::; T). Let X be a Y"r-measurable random variable. 
Show that there exists aÂ¢ E .Cad(O, L2 [0, T]) (see Definition 33.1) such that 
!
Â·T 
X= 
Â¢(s,w)dBs 
. 0 
a.s . 
36.4. Let { Bt : 0 ::; t ::; T} be a Brownian motion and { Y"t : 0 ::; t ::; T} the 
corresponding natural filtration. Let X and Y be two bounded random variables 
with the following representations: 
j
Â·T 
Y =Yo+ 0 1/J(t,w)dBt, 

HINTS 
497 
whereÂ¢ and 7/J are elements of L~d([O, T] x r:l) (see Definition 32.1). Suppose that 
faT Â¢(s,w)7/J(s,w)ds = 0. 
Show that 
where { Xt : 0 :::; t :::; T} and {yt : 0 :::; t :::; T} are bounded martingales defined as 
36.3 
Hints 
36.1. To prove part (a), consider the process defined as 
Y,-{0, 
ifO:::;t:::;a; 
t -
ft 
1 dB 
if a <_ t < b, 
a b-u 
u, 
and the T defined as T = min { t 2 a : yt = X}. To prove part (b), consider 
v f3 = min { t : yt = f3, t 2 a} 
and then try to establish 
and 
h(vf3) = min{t: Bt = f3, t 2 0}. 
36.2. 
Consider the random variable Y = <I>(X) and its conditional expectations 
Yn = E(YI9n), where <I>(-) is the standard normal cumulative distribution function 
and 
9n = CJ ( Bt : t :::; T - ~) , 
n 2 1. 
Then consider Xn = <I>- 1 (Yn) and use the result of Problem 25.5. 
36.3. Use the results of Problems 36.1 and 36.2. 
36.4. Use Theorem 32.1 and the results of Problems 14.16 and 35.6. 

498 
MARTINGALE REPRESENTATION THEOREM 
36.4 Solutions 
36.1. 
(a) Let {yt : 0 <::: t < b} be a process defined by 
{ 0, 
ifO<:::t<:::a; 
Y't= 
t 
fa b2udBu, 
if a<::: t < b, 
Then we have E[Y:,yt] = min{h(s), h(t)}, where 
{ 0, 
h( t) = 
t 
1 
1 
1 
-~du~---
fa (b-u) 2 
~ b-t 
b-a' 
if 0 <::: t <::: a; 
if a<::: t < b, 
Hence the process {yt : 0 <::: t < b} is equivalent to the time-changed Brownian 
motion { Bh(t) : 0 <::: t < b }. Now letT be defined as 
T = min { t ?: a : yt = X}. 
Then T is a stopping time and, by Problem 28.12, P { T < b} = 1. 
(b) Note that 
We have 
P{h(T)?: .>.} 
= P{h(T)?: .>., lXI < I;JI} + P{h(T)?: .>., lXI ?: 1/31} 
<::: 
P{h(T)?: A, lXI < I!JI} + P{IXI ?: I!JI}. 
Hence it is sufficient to show that 
(36.1) 
To do that, let 
Vf3 = min{t: Y1 = !), t?: a}. 
Then 
{T?: t, lXI < I!JI} ~ {v/3?: t} U {v-~1?: t}, 
t?: 0. 
Since h(-) is monotone, we have 
{h(T)?: >-.lXI < I!JI} <::: 2P{h(vp)?: .>.}. 
(36.2) 
But noting that {yt : 0 <::: t < b} and { Bh(t) : 0 <::: t < b} are equivalent, we 
have 
h(ve) 
min{h(t) : yt = 8, t?: 0} 
min{h(t) : Bh(t) = !), t?: 0} 
min{t: B 1 = ;1}. 

SOLUTIONS 
499 
By Problem 28.15 and the fact that <p(x) :::; ~.we have 
(36.3) 
Hence combining Equations (36.2) and (36.3) leads to the inequality given in 
Equation (36.1). 
This completes the proof. 
36.2. 
Let Y = <I>(X), where <I>(Â·) is the standard normal cumulative distribution 
function. Let Yn = E(YI9n), where 
9n = a ( Bt : t :S: T - ~) , 
n ~ 1. 
Since IYI :::; 1, by Problem 25.5, we have 
Since <I>(X) is strictly monotone, we can define Xn = <I>- 1 (Yn). Then we have 
X 
a.s. X 
n---+ 
. 
Note that { an}n;::1 and {bn}n;::1 are summable sequences, we can choose a sequence 
{ kn}n>1 of integers such that 
P {IX _X I > an+1 } < bn+l 
kn -
2 
-
2 ' 
n ~ 1. 
Now we let ~ 1 = Xk 1 and 
Then for tn = T- f, we have ~n E mff:t , that is, ~n is ff:t -measurable. Hence 
{ ~n }n;:: satisfies then first property. The sec~nd property follo;s from the fact that 
N L ~n = xkN' 
N ~ 1, 
n=1 
and that xkN ~X. 
Note that 
Hence the third property is satisfied. This completes the proof. 

500 
MARTINGALE REPRESENTATION THEOREM 
36.3. Let {an}n:;::1 and {bn}n:;::1 be two decreasing sequences that satisfy 
and 
00 I: nan< oo 
n=1 
00 
Lbn < 00. 
n=1 
Then by Problem 36.2, we know that there exists an increasing sequence { tn }n> 1 of 
real numbers such that tn t T and a sequence { ~n}n:;:: 1 of random variables such 
that 
(a) ~n is Â§tn -measurable for all n 2:: 1. 
(b) P{X = 2.::~= 1 ~n} = 1 a.s. 
(c) P{l~nl 2': an} ~ bn for all n 2': 1. 
Now by Problem 36.1, we can find, for each n 2:: 1, a stopping time Tn E [tn, tn+I) 
such that 
where 
1
Tn 
1 
1T 
~n = 
dEs= 
cf>n(s,w)dB8 , 
tn tn+1- S 
0 
cf>n(s,w) = {tn+~-s 
0, 
if S E [tn, Tn); 
if otherwise. 
LetÂ¢( s, w) be defined as 
00 
Â¢(s,w) = LÂ¢n(s,w). 
n=1 
We claim thatÂ¢ E Lad(O, Â£ 2 [0, T]). Since Â¢ 1 , Â¢ 2 , ... have mutually disjoint sup-
ports, we have 
T 
oo 
T 
1 Â¢2(s,w)ds = L 1 Â¢;(s,w)ds. 
0 
n=1 0 
Thus by Problem 36.1, we have 
By Problem 9.8, we know that 

BIBLIOGRAPHIC NOTES 
501 
exists a.s. Hence 4> E .Cad(n, Â£ 2 [0, T]). 
Finally, we have 
N 
N 
rtN+l 
~.::>~n = Lcf>n(s,w) = Jn 
cf>(s,w)ds, 
n=l 
n=l 
0 
N;:::l. 
By Theorem 33.3, we know that 
t ---+ lotÂ¢( s, w )ds 
is continuous a.s. Hence letting N ---+ oo in Equation (36.4) gives 
00 
00 
L~n = Lcf>n(s,w)ds. 
n=l 
n=l 
This completes the proof. 
36.4. By Theorem 32.1 and Problem 14.16, we have 
Xt = Xo +lot cf>(s,w)dB8 , 
(36.4) 
which can be written as dXt = cf>(t,w)dBt. Similarly, we have dyt = 'lj;(t,w)dBt. 
Then by Problem 35.6, we have 
This completes the proof. 
36.5 Bibliographic Notes 
In this chapter, we presented the martingale representation theorem. In mathematical 
finance, this theorem is used to establish the existence of a hedging strategy. For 
a proof of the martingale representation theorem, readers are referred to Oksendal 
(1998, p53), Steele (2003, Chapter 12), and Kuo (2006, p182). 


CHAPTER 37 
CHANGE OF MEASURE 
The notion of change of measure has important applications in mathematical finance. 
In this chapter, we present some relevant concepts and theorems such as the Girsanov 
theorems. 
37.1 
Basic Concepts and Facts 
Definition 37.1 (Exponential Process). LethE .Cad(f!, Â£ 2 [0, T]). The exponential 
process given by h is defined to be 
Â£h,t = exp [1t h(s)dB8
-
~ 1t h(s) 2ds], 
0 :S t :S T, 
where the Bt is a standard Brownian motion. 
Theorem 37.1 (Novikov's Theorem). Let { Xt : 0 :S t :S T} be a martingale, where 
T :S oo. Let { Mt : 0 :S t :S T} be defined as 
Mt = exp ( Xt- ~(X)t), 
Measure, Probability, and Mathematical Finance. 
503 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

504 
CHANGE OF MEASURE 
where (X)t is the compensator of Xf (see Theorem 34.2). Suppose that 
E [exp (~(X)t)] < oo, 
Vt E [0, T]. 
Then { Mt : 0 :S t :S T} is a continuous martingale. 
Theorem 37.2 (Levy Characterization of Brownian Motion). Let X = { Xt = 
(x?l, 
0 
0 
., xid)) : t 2:: 0} be a continuous stochastic process on the probability 
space (0, Jot", Q) with the state space (R d, B(R d)), adapted to a filtration { ~ 
t 2:: 0}. Suppose that for every 1 :S k :S d, the process 
is a continuous martingale with respect to { ~ : t 2:: 0} under Q, and the cross-
variations are given by 
where r5kj is the Kronecker delta. Then X is a d-dimensional Brownian motion with 
respect to { ~ 
: t 2:: 0} under Q. 
37.2 Problems 
37.1. Let f-l and v be two probability measures on a measurable space (0, ff) such 
that 
dv = f 
df-l 
for some f E Â£1(0, ff, J-L). Let X be a random variable on (0, ff) such that 
Ev[IXI] = L 
IX(w)lf(w)dJ-L(w) < oo. 
Suppose that Jot" is a sub-a-algebra of ff. Show that 
37.2 (Exponential Martingale). Let Bt = (Bi 1), Bi2 ), â¢â¢â¢ , Bim)) be an m-dim-
ensional Brownian motion. Let T :S oo be a constant. Let { Mt : 0 :S t :S T} be 
defined as 
( 
m 
t 
lm 
t 
) 
Mt = exp 
- ~ 1 
fJ(s,w)dBYl- 2 ~ 1 
fj(s,w)ds 
. 

PROBLEMS 
505 
where f1, h, ... , fm are elements of L~d([O, T] x 0) and satisfy Novikov's condi-
tion: 
Show that { Mt : 0 ~ t ~ T} is a martingale. 
37.3. Let {Mt : 0 ~ t ~ T} be a martingale under a filtered probability space 
(0, ~. {~t : 0 ~ t ~ T}, Q), where T ~ oo is a constant. Let P be a probability 
measure on (0, ~T) defined as 
dQ=MrdP. 
Show that fortE [0, T], 
37.4 (The Girsanov Theorem 1). Let 
Bt = (B~1)' B~2)' ... 'B~m)) 
be an m-dimensional Brownian motion on a filtered probability space (0, ~, { ~t : 
. 
( 
(1) 
(2) 
(m)) 
0 ~ t ~ T}, P), where T ~ oo 1s a constant. Let Yt = 1';; , 1';; 
, ... , 1';; 
be 
an m-dimensional Ito process given by 
where !1, h, ... , fm satisfy Novikov's condition: 
Let { Mt : 0 ~ t ~ T} be defined as 
( 
m 
t 
1 m 
t 
) 
Mt = exp 
- "'f 1 
fJ(s,w)dB~j)- 2 "'f 1 
f](s,w)ds 
. 
Let Q be a probability measure on (0, ~T) defined as 
dQ = MrdP. 
Show that {Yt : 0 ~ t ~ T} is an m-dimensional Brownian motion with respect to 
the probability measure Q. 
37.5 (The Girsanov Theorem II). Let 
_ ( 
(1) 
(2) 
(m)) 
Bt -
Bt , Bt , ... , Bt 

506 
CHANGE OF MEASURE 
be an m-dimensional Brownian motion on a filtered probability space (11, Â§, {,~1 : 
. 
(1) 
(2) 
(n) 
0 ::; t ::; T}, P), where T ::; oo IS a constant. Let yt = (~ , ~ , ... , ~ ) be 
an n-dimensional Ito process given by 
m 
d~(il = f)j(t,w)dt+ z=ejkdB~kl, o::; t::; T. 
k=l 
Suppose that there exist processes u 1 , u2, ... , Um and VI, v2 , ... , Vn such that 
81ml [uil [f)Il [v1l 
82m 
U2 
f12 
V2 
O~m 
u~, 
;n 
v~ 
Assume that Â·ui, Â·u2 , ... , Um satisfy Novikov's condition: 
Let { M 1 : 0 ::; t ::; T} be defined as 
( 
m 
t 
1m 
t 
) 
M 1 = exp 
- ~ 1 
Uj(s,w)dBij)- '2 ~ 1 
u](s,w)ds 
Let Q be a probability measure on (11, Y:r) defined as 
dQ = MrdP. 
Let { B1 : 0 ::; t ::; T} be defined as 
Show that 
(a) { B1 : 0 ::; t ::; T} is an m-dimensional Brownian motion with respect to the 
probability measure Q. 
(b) {yt : 0 ::; t ::; T} has the following representation: 
m 
(.i) -
"""' 
A (k) 
d~ - Vj(t, w)dt + ~ 
ejk(t, w)dBt ' j=l,2 ... ,n. 
k=l 

PROBLEMS 
507 
37.6. Let Bt = 
{(B~ 1 l,B~ 2 )) : 0 ::; t ::; T} be a two-dimensional Brownian 
motion on a filtered probability space ( D, ff, { fft : 0 ::; t ::; T}, P). Let Bt = 
{ ( B~l), B~ 2 )) : 0 ::; t ::; T} be defined as 
iJ?l = -3t + Bi1l, 
Bi2 ) = t + Bi2 ). 
Let yt = (~(1), ~( 2 )) be defined as 
dYYl - dB(1l + 3dB(2l 
dY:t(2l = dt- dBt(l) - 2dBt(2l. 
t 
-
t 
t 
' 
Find a probability measure Q on (D, ffr) such that 
(a) Q '"" P (see Definition 7.3); 
(b) {yt : 0 ::; t ::; T} can be represented as 
d~(lJ = diJ?l + 3diJ?l, 
d~c 2 l = -dBi1l - 2dBi2l. 
(c) { Bt : 0 ::; t ::; T} is a Brownian motion under Q. 
37.7 (Risk-Neutral Measure Q). Let { Bt : 0 ::; t ::; T} be a Brownian motion on 
a filtered probability space (D,ff,{fft : 0 < t < T},P), where T < oo. Let 
{Wt : t :::0: 0} be a process given by 
W -B 
(f.l-r)t 
t-
t + 
' 
(]' 
where r, fl, and (]' ((]' -1- 0) are finite constants. Show that there exists a probability 
measure Q equivalent toP such that {Wt : 0 ::; t ::; T} is a Brownian motion under 
Q. 
37.8. Let { ( B~ 1 ), B~ 2 ), ... , B~n)) : 0 ::; t ::; T} be an n-dimensional Brownian 
motion on some filtered probability space (D, ff, {fft : 0 ::; t ::; T}, P). Let 
{(J'ij(t): 0::; t::; T}beanadaptedprocessforeveryi = 1,2, ... ,dandj = 
{(w(l) W(2) 
w<n)) 
T} 
. 
l 
1, 2, ... , n. Let 
t 
, 
t 
, ... , 
t 
: 0 ::; t ::; 
be an n-d1mensiona 
stochastic process defined as 
where 
n 
(J'i(t)= 
l.:(J'lj(t), 
i=1,2, ... ,d. 
j=l 
Suppose that (J'i(t) > 0 for all i = 1, 2, ... , d and t E [0, T]. Show that for every 
i = 1, 2, ... , d, {Wt(i) : 0 ::; t ::; T} is a Brownian motion under the probability 
measure P. 

508 
CHANGE OF MEASURE 
37.3 Hints 
37 .1. Use the definition of conditional expectations (Definition 14.1) and the result 
of Problem 14.12. 
37 .2. Consider 
and use Theorem 34.4, Problem 34.4, and Theorem 37.1. 
37.3. Use the tower property of conditional expectations (see Problem 14.10). 
37.4. 
Use Levy characterization of Brownian motion (see Theorem 37.2). To do 
( 
(1) 
(2) 
(m)) . 
that, use the result of Problem 37.2 to show that yt = ~ , ~ , ... , ~ 
1s a 
martingale with respect to Q and use Theorem 35.8 to calculate (Y(i), y(j))t. 
37.5. Part (a) follows from Problem 37.4. To prove part (b), consider d~(j). 
37.6. Apply the result of Problem 37.5. 
37.7. Use the Girsanov theorem I (see Problem 37.4). 
37.8. Apply the Levy characterization theorem (Theorem 37.2) and use the results 
of Problems 35.7, 35.9, and 35.10. 
37.4 Solutions 
37.1. By Definition 14.1, we have 
i Ev[XjÂ£]dv = i Xdv, 
\lA E Â£. 
Since dv = fdf-L, this equation gives 
(37.1) 
By the assumption that Ev[IXI] < oo and EIL[Ifl] < oo, by Problem 14.12, we have 
Again by Definition 14.1, we have 

SOLUTIONS 
509 
Combining Equations (37.1) and (37.2) gives 
i Xfdfl- = i Ev[X[Â£"]Â· E~t[f[.n"]dfJ-, 
VA E Â£". 
Hence by Definition 14.1, we get 
This completes the proof. 
37.2. Let {Xt : 0 :::; t :::; T} be defined as 
Xt = f 1t iJ(s,w)dB~il. 
j=l 0 
Then by Theorems 32.1 and 32.2, {Xt : 0 :::; t :::; T} is a square-integrable martin-
gale. Note that by Ito's lemma (Theorem 35.4), we have 
m 
dXf = 2XtdXt + LJJ(t,w)dt. 
j=l 
By Theorem 34.4, we know that J; X 8 dXs is a martingale. Therefore, the compen-
sator of Xt is 
(X)t = f 1t f](s,w)ds. 
j=l 0 
Thus by the assumption, we have 
It follows from Theorem 37.1 that { Mt : 0 :::; t :::; T} is a martingale. This completes 
the proof. 
37.3. By the definition of Q, we have 
Q(A) = i MTdP = Ep[MTIA], 
VA E $T. 
(37.3) 
Since $t ~ $T, Equation (37.3) leads to 
Q(A) = i MTdP = Ep[MTIA], 
VA E $t. 
(37.4) 
By Problem 14.10, we have 
Ep[Ep(MTIA[$s)] 
Ep[IAE(MT[$t)] 
Ep[IAMtJ, 
VA E $t. 
(37.5) 

510 
CHANGE OF MEASURE 
Combining Equation (37.4) and Equation (37.5) gives 
Q(A) = Ep[MtiA] = l MtdP, 
\fA E fft. 
Hence we have dQ = M 1dP on (D, Â§ 1). This completes the proof. 
37.4. First, let use show that ~(i) is a martingale under the probability measure Q. 
To do that, let K}i) = M1 ~(i). Then by Theorem 35.4, we have 
which shows that K}i) is a martingale under probability measure P. By Problem 
37 .2, M 1 is also a martingale under probability measure P. Then by Problems 37 .l 
and 37.3, we have 
Ep [Mt~(i)lffs] 
Ep [Mtlffs] 
Kii) 
Jlvfs 
y(i) 
s 
. 
Hence ~(i) is a martingale under probability measure Q. 
Next, let us show that (Y(i), y(Jl)t = O;jt. Since 
we have 
y:(i)y:(J) = it y(j)dy(i) + 1t y(i)dy(j) + 0 t 
t 
t 
S 
S 
S 
S 
ZJ 
' 
. 0 
0 
Since ~(i) and ~(j) are square integrable, it follows from Theorem 34.4 that 
1
t y(j)dy(i) + 1t y(i)dy(j) 
8 
s 
s 
s 
0 
0 
is a martingale under Q. Hence by Theorem 35.8, we have 
(Y(i), y(Jl)t = O;Jt. 

SOLUTIONS 
511 
Therefore it follows from Theorem 37.2 that {yt : 0 :::; t :::; T} is an m-
dimensional Brownian motion with respect to the probability measure Q. This com-
pletes the proof. 
37.5. 
(a) It follows from Problem 37.4 that {Bt : 0 :::; t :::; T} is an m-dimensional 
Brownian motion with respect to the probability measure Q. 
(b) Since 
we have 
m 
d~(j) 
/3j(t,w)dt + L ejkdB~k) 
k=l 
~ 
( 
'(k) 
) 
f3i(t,w)dt+ L.....-eik dBt 
-uk(t,w)dt 
k=l 
(f3i(t,w)- ~eikuk(t,w)) dt+ ~eikdB~k) 
This completes the proof. 
37.6. Using the symbols from Problem 37.5, we have 
Then we can solve u 1 and u2 to get u 1 = -3 and u2 = 1. Let Mt be the martingale 
defined as 
( 
m 
t 
1 m 
t 
) 
Mt 
exp -~fa uj(s,w)dB~j)- 2 ~fa uJ(s,w)ds 
exp ( 3BF)- B~2)- st). 
The measure Q is defined as 
dQ = MrdP. 
This finishes the solution. 

512 
CHANGE OF MEASURE 
37.7. 
Let f(t,w) = 7Â· Since r, f.l, and a are finite, f satisfies Novikov's 
condition. Let { Mt : 0 ~ t ~ T} be a process given by 
( 
f.l - r 
(f.l - r )2 ) 
Mt = exp - --Bt -
t 
, 
a 
2a2 
0 ~ t ~ T. 
Then let Q be a probability measure on (0, Â§t) defined as 
dQ = MrdP. 
By Problem 37.4, the process {Wt : 0 ~ t ~ T} is a Brownian motion under Q. 
Now we show that Q and Pare equivalent. By Problem 7.6, we only need to 
show that 
P(Mr > 0) = 1. 
(37.6) 
But 
P(Mr > 0) 
{ 
( 
11 -r 
(f.L-r) 2 
) 
} 
P exp --a-Br-
2a 2 
T 
> 0 
P{ -oo < Br < oo} 
1. 
Hence Equation (37.6) holds. This completes the proof. 
37.8. For every i = 1, 2, ... , d and j = 1, 2, ... , n, we have 
{T [a2 (u)l 
{T 
Jo E a'!(u) du ~ Jo E[1]du = T < oo. 
It follows from Theorems 32.2 and 32.3 that for every i = 1, 2, ... , d, we have 
is a continuous martingale with respect to { Â§t : 0 ~ t ~ T} under P. By Problems 
35.7, 35.9, and 35.10, we have 
(w?l,w?l)t = (t taiJ(u)dB~jl,t taiJ(u)dB~jl) 
j=l Jo ai(u) 
J=l Jo ai(u) 
t 
t 
t 
/ t aij(u) dB~), t ail(u) dB~!)) 
j=l l=l \Jo ai(u) 
}0 ai(u) 
t 
~ rt arj(u) du 
L Jn a2(u) 
j=l 0 
t 
t. 
It follows from Theorem 37.2 that {w?l : 0 ~ t ~ T} is a Brownian motion under 
the probability measure P. This completes the proof. 

BIBLIOGRAPHIC NOTES 
513 
37.5 Bibliographic Notes 
In this chapter, we introduced some results relevant to the change of measure. For 
a good introduction to how the change of measure is applied, readers are referred 
to Baxter and Rennie (1996). For more information about this subject, readers can 
consult Hunt and Kennedy (2004 ), Elliott and Kopp (2005), Sondermann (2007), and 
Hull (2008). 
N ovikov' s theorem (Theorem 3 7.1) pertains to exponential martingales constructed 
from martingales. A proof of this theorem can be found in Ikeda and Watanabe 
(1981, Theorem 5.3). 
The Levy characterization of Brownian motion theorem is very useful in that 
it allows us to check whether a stochastic process is a Brownian motion under a 
probability measure. A proof of this theorem can be found in Ikeda and Watanabe 
(1981, Chapter II) and Karatzas and Shreve (1991, Chapter 3). 


CHAPTER38 
STOCHASTIC DIFFERENTIAL 
EQUATIONS 
A stochastic differential equation is a differential equation that involves stochastic 
processes. The solution of a stochastic differential equation is also a stochastic pro-
cess. In this chapter, we present stochastic differential equations and their solutions. 
38.1 
Basic Concepts and Facts 
Definition 38.1 (Strong Solution of SDE). A stochastic process { Xt : a :::; t :::; b} is 
called a strong solution of the following stochastic differential equation 
(38.1) 
if it satisfies the following conditions: 
(a) The stochastic process a(t, Xt) belongs to .Cad(O, L2[a, b]) so that for each 
t E [a, b], J: a(s, X 8 )dB8 is an Ito integral. 
(b) Almost all sample paths of f(t, Xt) belong to Â£ 1 [a, b]. 
Measure, Probability, and Mathematical Finance. 
515 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

516 
STOCHASTIC DIFFERENTIAL EQUATIONS 
(c) For each t, the following equation 
(38.2) 
holds almost surely. 
Definition 38.2 (Weak Solution of SDE). If there exist a probability space with a 
filtration, a Brownian motion {Bt: t ~ 0}, and a process {Xt: a:<:::; t :<:::; b} adapted 
to the filtration such that they satisfy the conditions given in Definition 38.1, then 
{ Xt : a :<:::; t :<:::; b} is called a weak solution to the stochastic differential equation 
(38.1). 
Definition 38.3 (Uniqueness of Solution). A stochastic differential equation is said 
to have a strongly unique (strong or weak) solution if any two solutions { Xt : a :<:::; 
t :<:::; b} and {lt : a :<:::; t :<:::; b} of the stochastic differential equation satisfy 
P{Xt = yt: a:<:::; t :<:::; b} = 1. 
A stochastic differential equation is said to have a weakly unique (strong or weak) 
solution if any two solutions of the stochastic differential equation have the same 
finite-dimensional distributions. 
Definition 38.4 (Lipschitz Condition). A measurable function f(t, x) on [a, b] x R 
is said to satisfy the Lipschitz condition in x if there exists a constant K > 0 such 
that 
if(t, x)- f(t, y)i :S Klx- Yi 
for all t E [a, b] and x, y E R. 
Definition 38.5 (Linear Growth Condition). A measurable function f(t, x) on [a, b] 
x R is said to satisfy the linear growth condition in x if there exists a constant K > 0 
such that 
lf(t,x)l :S K(l + lxl) 
for all t E [a, b] and x E R. 
Theorem 38.1 (Uniqueness and Existence of a Solution). Let f(Â·, Â·) : [a, b] x Rn --+ 
Rn and a(Â·,Â·): [a, b] X Rn--+ Rnxm be measurable functions satisfying 
lf(t,x)l + ia(t,x)l :S C(l + lxl), 
x ERn, t E [a,b] 
(38.3) 
and 
if(t, x)- f(t, y)i + ia(t, x)- a(t, y)i :S Dlx- yi, 
x, y ERn, t E [a, b] (38.4) 
for some constants C and D, where lvl 2 is the sum of all the squared components of 
v. Let~ be a random variable that is independent of the a-algebra Â§
00 = a(Bs : 
s ~ 0) and satisfies 

PROBLEMS 
517 
Then the stochastic differential equation 
(38.5) 
has a strongly unique continuous strong solution { Xt : a :::; t :::; b} such that 
and {X t : a :::; t :::; b} is adapted to the filtration Â§te = a ( ~, B s : s :::; t ). 
Theorem 38.2. Let f(t, x) and a(t, x) satisfy the conditions given in Theorem 38.1. 
Then a (weak or strong) solution of Equation (38.5) is weakly unique. 
Theorem 38.3. Let { Xt : a :::; t :::; b} be the solution to the stochastic differential 
equation 
dXt = f(t, Xt)dt + a(t, Xt)dBt, 
Xa = ~' 
where f ( t, x) and a( t, x) satisfy the corresponding conditions given in Theorem 
38.1. Suppose that 
E [en] < oo 
for some integer n 2': 1. Then for every t E [a, b], we have 
and 
where K 1 and K 2 are constants depending only on n, C, D, and b- a. 
38.2 Problems 
38.1 (Beilman-Gronwall Inequality). Let Â¢ be a function in Â£ 1 [a, b] satisfying the 
following condition 
Â¢(t) :::; f(t) + (31t Â¢(s)ds, 
for all t E [a, b], 
where f E Â£ 1 [a, b] and (3 is a positive constant. Show that 
(a) For any t E [a, b], 
Â¢(t) :S f(t) + (31t f(s)ef3(t-s)ds. 
(38.6) 
(38.7) 

518 
STOCHASTIC DIFFERENTIAL EQUATIONS 
(b) Iff ( t) = a for some constant a, then for any t E [a, b], 
cf>(t) :S ae!3(t-a). 
38.2. Let { Bn}n>l be a sequence of functions in L1 [a, b] such that 
Bn+l(t) :S f(t) + (31t Bn(s)ds, 
for all t E [a,b], n ~ 1, 
where f E L1 [a, b] and (3 is a positive constant. Show that 
(a) For any n ~ 1 and any t E [a, b], 
(38.8) 
(38.9) 
1t 
1t (t 
s)n-l 
Bn+l(t) :S f(t) + (3 
f(s)e!3(t-s)ds + (3n 
(-_ )I BI(s)ds. 
a 
a 
n 
1 . 
(b) If f(t) = a and 81 (t) = c for some constants a and c, then for any n ~ 1 and 
any t E [a, b], 
(3n(t 
a)n 
e 
(t) < ae!3(t-a) + c 
-
n+l 
_ 
I 
n. 
38.3. Let { Zt : a :S t :S b} be a continuous stochastic process on (n, .'7, P) such 
that for each t E [a, b], we have 
Zt = 0, 
a.s. 
Show that there exists a subset no of n such that for each w E no, Zt (w) = 0 for all 
t E [a,b]. 
38.4. Let r>(t, x) and f(t, x) be measurable functions on [a, b] x R satisfying the Lip-
schitz condition in x. Let~ be an .'7a-measurable random variable with E(e) < oo. 
Then the stochastic differential equation (38.1) has at most one continuous solution 
Xt. 
38.5. Let f(t, x) be a measurable function satisfying the linear growth condition: 
if(t,x)i :S K1(1 + jxl), 
t E [O,T], x E R. 
Let r>( t, x) be a bounded measurable function: 
jr>(t, x)j :S Kz, 
t E [0, T], x E R. 
Suppose that { Xt : 0 :S t :S T} is a solution of the following stochastic differential 
equation 
Xt = Xo +lot r>(s, Xs)dBs +lot f(s, Xs)ds, 
where xo is some constant. Let Xr = sup0:'0t:'OT IXtlÂ· Show that 

PROBLEMS 
519 
(a) There exist positive constants Ct. c2 , and c3 such that 
(b) There exists a positive constant o: such that 
E [exp ( o:X?) J < oo. 
38.6. Let f ( t, x) and a ( t, x) be measurable functions satisfying the linear growth 
condition: 
lf(t,x)l + ia(t,x)l:::; K(l + lxl), 
t E [O,T], x E R. 
Suppose that { Xt : 0 :::; t :::; T} is a solution of the following stochastic differential 
equation 
Xt = Xo +lot a(s, Xs)dBs +lot f(s, Xs)ds, 
where x 0 is some constant. For every p 2: 1, show that 
38.7. Let { Bt : 0 :::; t :::; T} be a Brownian motion. Solve the following stochastic 
differential equation 
dXt = Xt(J.Ldt + adBt), 
t E [0, T], 
where J.L and a are constants. 
38.8 (Stochastic Exponential). Let {Xt : t 2: 0} be a continuous Ito process (see 
Definition 35.3) given by 
dXt = f(t)dBt + g(t)dt, 
where f(t) and g(t) are bounded. Let {Ut : t 2: 0} be a stochastic process satisfying 
the following stochastic differential equation 
(38.10) 
Suppose that {Xt :2: 0} has finite total variation. Show that the only solution of 
Equation (38.1 0) is given by 
Ut = exp ( Xt- Xo- ~[X]t), 
where [X]t is the quadratic variation process of X (see Definition 34.6). 

520 
STOCHASTIC DIFFERENTIAL EQUATIONS 
38.9 (Omstein-Uhlenbeck Equation). Let { Bt : t ~ 0} be a one-dimensional Brow-
nian motion. Solve the following stochastic differential equation, where J.l and a are 
real constants: 
38.10 (Mean-Reverting Omstein-Uhlenbeck Equation). Let 
{Bt: t ~ 0} 
be a one-dimensional Brownian motion. Solve the following stochastic differential 
equation, where m and a are real constants: 
dXt = (m- Xt)dt + adBt. 
38.11. Let {Bt : t ~ 0} be a !-dimensional Brownian motion. Solve the following 
stochastic differential equation, where r and a are real constants: 
38.12 (Brownian Bridge). Let {Bt : t ~ 0} be a !-dimensional Brownian motion. 
Solve the following stochastic differential equation 
b-Xt 
dXt = --dt + dBt, 
0 :S t < 1, 
Xo =a, 
1-t 
where a and b are real constants. 
38.13. Let {Xt : t ~ 0} be a process satisfying the following nonlinear stochastic 
differential equation: 
Here f : R x R -+ R and g : R -+ R are continuous deterministic functions. Let 
{yt : t ~ 0} be a process defined as 
yt = exp ( -1t g(s)dBs + ~ 1t l(s)ds) . 
(a) Show that 
d(Xtlt) = ytf(t, Xt)dt. 
(b) Solve the following stochastic differential equation 
where a is a real constant. 

HINTS 
521 
38.3 Hints 
38.1. To prove part (a), consider the function g(t) = J: Â¢(s)ds and note that 
d[g(t)e-,Bt] = e-,Bt[g'(t)- ,Bg(t)]dt. 
Part (b) is a special case of part (a). 
38.2. Note that by integration by parts, 
1t 1
8 fh(u)duds = 1t (t- s)lh(s)ds 
and use the induction method to establish that 
n-2 t ,Bk(t- s)k 
t (t- s)n-1 
Bn+I(t)::::; f(t) + L.B la 
k! 
f(s)ds +,en la 
(n _ 1)! B1(s)ds. 
k=O 
38.3. 
Let r 1 , r2 , â¢â¢. be an enumeration of all rational numbers in the interval 
[a, b] and consider the sequence {An}n>l of subsets of n, where An = {w E n : 
Zrn(w) = 0}. 
38.4. Use the results of Problems 38.1 and 38.3. 
38.5. Use the results of Problems 38.1 and 32.15 to prove part (a). Use the results 
of part (a) and Problem 13.12 to prove part (b). 
38.6. Consider the stochastic differential of the process 
yt = ln (1 + xn' 
and use the result of Problem 38.5. 
38.7. Apply Ito's lemma (Theorem 35.3) to lnXt. 
38.8. The existence and uniqueness of a solution can be proved by Theorem 38.1. 
Note that Xt- X 0 is a martingale and 
[X]t =fat f(s) 2ds. 
The exact formula of U can be obtained by applying Ito formula (Theorem 35.6). 
38.9. Consider 
d(e-JLtXt) 
and use Ito's lemma (Theorem 35.3). 
38.10. Consider 

522 
STOCHASTIC DIFFERENTIAL EQUATIONS 
and use Ito's lemma (Theorem 35.3). 
38.11. Let 
Consider 
and use the multidimensional Ito's lemma (Theorem 35.4). 
38.12. Consider 
d(~) 
1-t 
and use Ito's lemma (Theorem 35.3). 
38.13. Apply Ito's lemma (Theorems 35.3 and 35.4) to prove part (a). Then use part 
(a) to solve part (b). 
38.4 Solutions 
38.1. 
(a) Let g(t) = J: Â¢(s)ds fort E [a, b]. Then we have g'(t) = Â¢(t) and g(a) = 0. 
By Equation (38.6), we get 
g'(t)::::; f(t) + f3g(t). 
Note that d[g(t)e-,6t] = e-,Bt[g'(t)- f3g(t)]dt. Hence we have 
:tg(t)e-,6t::::; f(t)e-,Bt, 
which gives 
g(t)e-,6t::::; 1t f(s)e-,6 8 ds. 
Therefore by Equation (38.6), we get 
Â¢(t) :'S f(t) + f3g(t)::::; f(t) + {31t f(s)e,B(t-s)ds. 
(b) This is implied from part (a). 
This completes the proof. 
38.2. 

SOLUTIONS 
523 
(a) When n = 1, by Equation (38.9), we have 
When n = 2, by Equation (38.9), the above equation, and integration by parts, 
we have 
03(t) < f(t) + (31t [f(s) + (31
8 01(u)du] ds 
f(t) + (31t f(s)ds + (32 1t (t- s)01(s)ds. 
Similarly, we can show that 
n-2 1
t (3k(t _ s)k 
1
t (t _ s)n-1 
On+1(t) ~ f(t) + L (3 a 
k! 
f(s)ds + (3n a 
(n _ 1)! 01(s)ds. 
k=O 
Since 
n-2 (3k( 
)k 
""' 
t - s 
< ef3(t-s) 
L..-
k! 
-
' 
k=O 
we get 
1t 
1t (t 
s)n-1 
On+1(t) ~ f(t) + (3 
f(s)ef3(t-s)ds + (3n 
(-_ )' 01(s)ds. 
a 
a 
n 
1 . 
(b) This is a special case of part (a). 
This completes the proof. 
38.3. Let r 1 , r 2 , ... be the sequence of all rational numbers in the interval [a, b] and 
An= {wE 0: Zrn (w) = 0} for n = 1, 2, .... By assumption, we have P(An) = 1 
for all n. Let 
00 
n=1 
Then by Problem 11.1, we have P(A) = 1. Now since the Zt is a continuous 
process, there exists a subset B of 0 such that P(B) = 1 and for each w E B, we 
see that Zt(w) is a continuous function oft on [a, b]. Let 
Oo=AnB. 
Then P(Oo) = 1. Noting that for each wE 0 0 , we have Zrn (w) = 0 for all n ~ 1. 
Hence for each w E Oo, we have Zt(w) = 0 for all t E [a, b] because each real 
number in [a, b] can be approximated by rational numbers in [a, b]. This completes 
the proof. 

524 
STOCHASTIC DIFFERENTIAL EQUATIONS 
38.4. 
Suppose that Xt and yt are two continuous solutions of the stochastic dif-
ferential equation in Equation (38.1). Let Zt = Xt - yt. Then Zt is a continuous 
stochastic process and 
Applying the inequality (x + y) 2 :S 2x2 + 2y2 to the above equation gives 
Zz :S 2 (1t [u(s, Xs)- u(s, Ys)]dBs) 
2 + 2 (1t [f(s, Xs)- f(s, Ys)]ds) 
2 
By the assumption that u( t, x) and f ( t, x) satisfy the Lipschitz condition in x, there 
exists a constant K > 0 such that 
lu(t,x)- u(t,y)l :S Klx- Yl 
and 
lf(t,x)- f(t,y)l :S Klx- Yl 
for all t E [a, b] and x, y E R. Hence we have 
1t E [(u(s,Xs)- u(s, Ys)) 2] ds 
< K 2 1t E(z;)ds 
and by Schwarz's inequality (Theorem 8.3), we have 
(1t [f(s, Xs)- f(s, Ys)]ds) 
2 
< (t- a) 1t [f(s, Xs)- f(s, Ys)] 2ds 
< (b- a)K2 1t z;ds. 
Therefore 
Zz :S 2K2 (1 + b- a) 1t E(z;)ds. 
By Problem 38.1, we have E(Z'f) = 0 for all t E [a, b]. Hence Zt = 0 a.s. for each 
t E [a, b]. By Problem 38.3, almost all sample paths of Zt are zero. Hence Xt and 
yt are the same continuous solutions. This completes the proof. 
38.5. 
(a) Let 

SOLUTIONS 
525 
Since 
IXtl < lxol +lot K1(1 + IXsl)ds + IYtl 
< lxol + K1T + sup IYtl + K1 {t IXslds, 
o::=;t::=;T 
lo 
it follows from Problem 38.1 that 
which implies that 
(38.11) 
Then by Problem 32.15, we have 
(38.12) 
Now if we let 
then combining Equation (38.12) and Equation (38.11) gives 
(b) Let a E (0, c2), where c2 is given in part (a) of this proof. Then by Problem 
13.12, we have 
E [ exp (aX~) J 
1 + 1
00 2aA.exp (aA.2) P{Xr ~ A.}dA. 
< 
1 + 1
00 2aA.exp (aA.2) Â· c2 exp ( -c2A.2 + c3A.) dA. 
< 
00. 
This completes the proof. 

526 
STOCHASTIC DIFFERENTIAL EQUATIONS 
38.6. Let yt = ln (1 + Xl). Then by Theorem 35.3, we have 
where Yo = ln(l + x6), 
( Y,)-2Xta(t,Xt) 
rJ t, t 
-
I+ x; , 
and 
2Xtf(t, Xt) 
1- Xf 
2 
g(t, yt) = 
1 + Xf 
+ (1 + Xl)2 f (t, Xt)Â· 
Since 
I (t Y,)l < 2IXtiÂ·K(l+IXtl) < 4K(l+Xl) = 4K 
rJ ' t 
-
1 + x; 
-
1 + x; 
and 
lg(t, Y,t)l 
< 
2IXtl. K(l + IXtl) + II- Xfl . K2(1 +IX 1)2 
1 + x; 
(I + xn2 
t 
< (l+IXtl)Â· (K+K211 :I~ll) 
< (K + 2K2) (1 + IXtl), 
it follows from Problem 38.5 that for every >. > 0, we have 
where c1, c2, and c3 are some positive constants. Hence we have 
P { sup IXtl ~ >.} 
O:<;t:<;T 
Then by Problem 13.12, we have 
P{ sup yt~ln(1+>.2 )} 
O:<;t:<;T 
< 
Cl e-c2 ln2(l+A2)+c3ln(l+A2) 
Cl (1 + ).2) -c2 ln(l+A2)+c3. 
r= p>.p-l p { sup IXtl ~ >.} d>. 
lo 
o:<;t:<;T 
< 
pel 1
00 ).P-1 (1 + ).2) -c2 ln(l+A2)+c3d).. 

Now let )..0 = Jexp(c3c~P)- 1. Then we have 
rX! )..P-1(1 + )..2)-c2ln(H.>-2)+c3d).. 
J.>- 0 
Hence we have 
This completes the proof. 
38.7. By Theorem 35.3, we have 
dlnXt = 
Hence we have 
which gives 
Xt = Xo exp ( (JL- ~a2) t +a Bt) . 
This finishes the solution. 
SOLUTIONS 
527 
38.8. Since f(t) and g(t) are bounded, both xf(t) and xg(t) satisfy the Lipschitz 
condition in x and the linear growth condition in x. Hence by Theorem 38.1, the 
stochastic differential equation (38.1 0) has a unique solution. 
By Theorems 34.2 and 34.4, we have 
[X]t = (X)t = lt f(s) 2d(B)s = lt f(s) 2ds. 
Let Ut be defined as 
Ut = exp ( Xt- Xo- ~ lt f(s)ds). 
Then by Theorem 35.6, we have 
1 
Ut[- j(t)]dt + UtdXt + 2Utd(X)t 
-Utf(t)dt + UtdXt + Utf(t)dt 
UtdXt, 

528 
STOCHASTIC DIFFERENTIAL EQUATIONS 
which shows that {Ut : t ~ 0} satisfies Equation (38.10). Hence {Ut : t ~ 0} is the 
only solution of Equation (38.1 0). This completes the proof. 
38.9. By Ito's lemma, we have 
-f..Le-1Â·Lt Xtdt + e-1LtdXt 
e-,.tt ( -f..LXtdt + dXt) 
e-~"tadBt. 
Integrating both sides of the above equation gives 
e-~"tXt = Xo + 1t e-~"8adB8 â¢ 
Hence we have 
Xt = Xae~"t + 1t e~"(t-s)adB8 â¢ 
38.10. By Ito's lemma, we have 
et Xtdt + etdXt 
et (Xtdt + dXt) 
et(mdt + adBt)Â· 
Integrating both sides of the above equation gives 
et Xt = Xo + m(et- 1) +a 1t e8 dB8 â¢ 
Hence we have 
Xt = m + (Xo- m)e-t +a 1t e8-tdB8 â¢ 
This completes the solution. 
38.11. Let 
yt = exp ( -aBt + ~a2t). 
Then by Theorem 35.4, we have 
ytdXt + Xtdrt + dXtdrt 
yt(rdt + aXtdBt) + Xt[ayt(adt- dBt)] + ayt( -aXtdt) 
rytdt. 
(38.13) 
Integrating the two sides of Equation (38.13) gives 
YtXt = YoXo + r 1t Y8 ds. 

SOLUTIONS 
529 
Hence we have 
Xt = exp (aBt- ~oh) [xo + r fat exp ( -aBs + ~a2 s) ds]. 
This completes the solution. 
38.12. By Theorem 35.3, we have 
d(~) 
1-t 
Xt 
d 
dXt 
t+--
(1 - t) 2 
1 - t 
- 1- (dxt + ~dt) 
1-t 
1-t 
- 1- (-b-dt + dBt) . 
1-t 1-t 
Integrating both sides of Equation (38.14) gives 
~ 
= a + __!!!____ + ( dB s 
1 - t 
1 - t 
} 0 1 - s 
(38.14) 
We get the following result by multipling 1 - t to both sides of the above equation: 
l
t dEs 
Xt=a(1-t)+bt+(1-t) 
--. 
0 1- s 
This completes the solution. 
38.13. 
(a) By Theorem 35.3, we get 
dyt = yt ( -g(t)dBt + ~g 2 (t)dt). 
(38.15) 
Now by Theorem 35.4, we have 
d(Xtyt) 
Xtdyt + ytdXt + dXtdyt 
Xtyt ( -g(t)dBt + ~l(t)dt) + yt[j(t, Xt)dt + g(t)XtdBt] 
+~yt ( -g(t)dBt + ~g2 (t)dt) (f(t,Xt)dt + g(t)XtdBt) 
ytf(t, Xt)dt. 
(38.16) 
(b) For this particular stochastic differential equation, we have f ( t, Xt) = i, and 
g(t) =a. Then we have 

530 
STOCHASTIC DIFFERENTIAL EQUATIONS 
Now let Zt = XtY'tÂ· Then from Equation (38.15), we get 
or 
(38.17) 
Since Equation (38.17) is a deterministic equation, we can integrate both sides 
of the equation for each w; that is, we have 
which gives 
Hence we have 
1 
Xt = exp ( aBt ~ ~oh) [x + 21t exp ( ~2aB8 + a 2s) ds] 
2 
This finishes the solution. 
38.5 
Bibliographic Notes 
In this chapter, we presented stochastic differential equations. In fact, the stochas-
tic differential equation in Equation (38.1) is just a symbolic expression and must 
be interpreted as the stochastic integral equation in Equation (38.2). Under certain 
conditions, the stochastic differential equation has a unique solution. A proof of 
the uniqueness is given in Problem 38.4. For a proof of the existence, readers are 
referred to Oksendal (1998) and Kuo (2006). For a proof of Theorem 38.2 and an 
example of a stochastic differential equation that has no strong solution but a weak 
solution, readers are referred to Oksendal (1998, p71). 
Several texts on stochastic differential equations have been published since the 
mid-1990s. Oksendal (1998) is textbook on stochastic differential equations on the 
graduate level. Prevot and Rockner (2007) is a short book on stochastic partial differ-
ential equations. Allen (2007) introduced the theory, computation, and application 
of Ito stochastic differential equations. Other books that introduce stochastic dif-
ferential equations include Friedman (1975), Friedman (1976), Ikeda and Watanabe 
(1981), Karatzas and Shreve (1988), and Protter (2003). 
Numerical methods for stochastic differential equations are developed in Kloeden 
and Platen ( 1995) and Iacus (2008). For a proof of the moment inequalities given in 
Theorem 38.3, readers are referred to Kloeden and Platen ( 1995). 

CHAPTER 39 
DIFFUSION 
A diffusion or a diffusion process is a solution to a stochastic differential equation. In 
this chapter, we will present some results about diffusion, in particular, Ito diffusion. 
39.1 
Basic Concepts and Facts 
Definition 39.1 (Compact Set). A set K ~ R is called a compact set if every open 
cover of K contains a finite subcover; that is, if {VihEI is a collection of open sets 
such that 
K~ UVi, 
iEJ 
then there exists a finite subcollection {Vi1 h=1,2, ... ,n such that 
n 
Definition 39.2 (Closure). Let E ~ R. The closure of the set E, written as E, is the 
smallest closed set in R that contains E. 
Measure, Probability, and Mathematical Finance. 
531 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

532 
DIFFUSION 
Definition 39.3 (Support). The support of a function f on R is the closure of the set 
{x E R: f(x)-=/= 0}. 
Definition 39.4 (C1,2-Function). A function f on R x R is called a C 1,2-function 
if f(t, x) is continuously differentiable on t (i.e., ~{ is continuous) and twice con-
tinuously differentiable on x (i.e., ~:{ is continuous). 
Definition 39.5 (Diffusion). A diffusion is a solution to a stochastic differential 
equation of the form 
(39.1) 
where s ~ 0 and x are some constants, f-L and a are functions satisfying the Lip-
schitz continuity condition and the linear growth condition given in Theorem 38.1. 
The functions f-L and a are called the drift coefficient and the diffusion coefficient, 
respectively. 
The unique solution of Equation (39.1) is denoted by x;,x, t ~ s. If s = 0, the 
solution is denoted by Xf. 
Definition 39.6 (Ito Diffusion). An Ito diffusion is a stochastic process 
Xt = X(t,w): [O,oo) X n---+ R 
satisfying the following stochastic differential equation 
(39.2) 
where s ~ 0 and x are real constants, { Bt : t ~ 0} is a standard Brownian motion, 
and b : R ---+ R and a : R ---+ R are functions satisfying the Lipschitz continuity 
condition 
lb(z)- b(y)l + la(z)- a(y)l :S: c1lz- yl, 
z, y E R 
and the linear growth condition 
lb(z)l + la(z)l :S: c2(l + lzl), 
z E R. 
Definition 39.7 (Probability Measure Qx). Let {Xt : t ~ 0} be a diffusion as 
defined in Definition 39.5. The probability measure Qx is the probability law (see 
Definition 21.2) of {Xt : t ~ 0} assuming that X 0 = x. Mathematically, Qx is 
given by 
where P is the probability law of the underlying Brownian motion, h < t 2 < Â· Â· Â· < 
tk are arbitrary times, and E 1 , ... , Ek are arbitrary Borel sets. 
The expectation under the probability measure Qx is denoted by Ex. 

BASIC CONCEPTS AND FACTS 
533 
Definition 39.8 (Transition Function). Let { Xt : t :2: 0} be a diffusion as defined in 
Definition 39.5. The transition function of the diffusion is defined as 
Ps,t(X, A)= P(Xt E AIXs = x), 
0 :S: s < t, X E R, A E B. 
Definition 39.9 (Differential Operator Lt)â¢ Let {Xt : t :2: 0} be a diffusion as 
defined in Definition 39.5. Then the second order differential operator associated 
with the stochastic differential equation of Xt is defined as 
where f(x) is a C 2 function, !L(t, x) is the drift coefficient, and a(t, x) is the diffu-
sion coefficient. 
If { Xt : t :2: 0} is an Ito diffusion as defined in Definition 39.6, then the corre-
sponding differential operator is defined as 
Definition 39.10 (Infinitesimal Generator for Ito Diffusions). Let {Xt : t :2: 0} be 
an Ito diffusion as defined in Definition 39.6. Then the infinitesimal generator A of 
{Xt : t :2: 0} is defined by 
Af(x) =lim E[f(Xt)]- f(x) 
x E R, 
ttO 
t 
' 
where f is a function from R to R. 
Theorem 39.1 (The Markov Property for Ito Diffusions). Let {Xt : t :2: 0} be 
an Ito diffusion as defined in Definition 39.6. Then {Xt : t :2: 0} is a Markov 
process with respect to the filtration { $t : t :2: 0} generated by the Brownian motion 
{Bt : t :2: 0}; that is,for any bounded Borel function f, we have 
where 
Theorem 39.2 (The Strong Markov Property for Ito Diffusions). Let {Xt : t :2: 0} 
be an Ito diffusion as defined in Definition 39.6. Let f be a bounded Borel function 
on R. LetT be a stopping time with respect to the underlying filtration { $t : t :2: 0}. 
Suppose that T < oo a.s. Then 
where 

534 
DIFFUSION 
39.2 Problems 
39.1 (Time Homogeneity). Let {Xt : t ~ 0} be an Ito diffusion as defined in Def-
inition 39.6. Show that the process {Xt : t ~ 0} is time-homogeneous; that is, the 
transition function Ps,t of {Xt: t ~ 0} depends only on t- s. 
39.2. Let { Xt : t ~ 0} be the solution of the following stochastic differential equa-
tion 
dXt = t-tXtdt + aXtdBt, 
t ~ 0, 
where t-t and a are constants. Let x > 0 and A= ( -oo, y], where y > 0. Calculate 
the transition function Ps,t(x, A) of the process {Xt: t ~ 0}. 
39.3 (Dynkin's Formula). Let f be a C2 function on R with a compact support D. 
Let {lt : t ~ 0} be an Ito process of the form 
~x(w) = x +fat u(s, w)ds +fat v(s, w)dB8 (w). 
Let T be a stopping time with respect to the underlying filtration { fft : t ~ 0}. 
Suppose that Ex[T] < oo and that u(t, w) and v(t, w) are bounded on the set { (t, w) : 
~x(w) ED}. Show that 
39.4. Let {Xt : t ~ 0} be an Ito diffusion as defined in Definition 39.6. Let f be a 
C 2 function on R with a compact support. Show that A! exists and that 
Af(x) = Lf(x), 
where A is the infinitesimal generator for Xt and L is the differential operator for 
Xt. 
39.5. Let { Xt : t ~ 0} satisfy the stochastic differential equation 
Let f be a C 1â¢2-function. Show that 
where Lt is the second-order differential operator for Xt (see Definition 39.9). 
39.6. Let { Xt : 0 ~ t ~ T} solve the stochastic differential equation 

PROBLEMS 
535 
where J-L(t,x) and a(t,x) satisfy the corresponding conditions given in Theorem 
38.1. Let f(t, x) be a 0 1â¢2-function with bounded first derivative in x. Show that 
(a) 
Mt = f(t,Xt) -fat ( Luf(u,Xu) + ~~ (u,Xu)) du 
is a martingale. 
(b) If f(t, x) solves the backward equation 
8f 
Ltf(t,x)+ at(t,x)=O, 
then {f(t, Xt) : 0 ::; t ::; T} is a martingale. 
39.7. Let {Xt : t:::: 0} be an Ito diffusion as defined in Definition 39.6. Let D c R 
be a compact set. Let TD be the first exit time from the set D: 
TD = inf{t: Xt rJ. D}. 
Suppose that there exists a 0 2 function f on R, nonnegative over D and such that 
Lf(x) :S -1, 
\fx ED, 
where L is the differential operator defined in Definition 39.9. For every x E D, 
show that 
39.8. Let {Xt : t:::: 0} be a geometric Brownian motion given by 
where J-L and a > 0 are constants, and {Bt : t:::: 0} is a Brownian motion. Suppose 
that x E (~, R), where R is a positive constant and n is a positive integer such that 
nR > 1. Let 
and 
Show that 
(a) Ex[T 1\ Tn] < oo. 
(b) If J-L ~ ~a2 , then 
r=inf{t>O:Xt::::R} 
Tn = inf { t > 0: Xt :S ~}. 

536 
DIFFUSION 
where Qx is as defined in Definition 39.7 and 'Y = 1 -
~Â­
(c) If p # ~u2 , then 
x [ 
] _ ln ~ + (1 - P{ T < Tn}) ln n~ 
E 
T 1\ Tn -
1 
2 
. 
JL -
20" 
(d) 
Qx { lim Tn = oo} = 1. 
n--+oo 
where 'Y = 1 -
~. 
E x [ ] = ln R - ln x 
T 
1 
2 
. 
JL -
20" 
39.3 Hints 
39.1. Show that X~,x and X~_:_~ have the same distribution, and then use Theorem 
39.1. 
39.2. Use the result of Problem 38.7 and the Markov property of the process { Xt : 
t 2:: 0} (see Theorem 39.1). 
39.3. 
Use Ito's lemma (Theorem 35.3) and the property of Ito integral (Theorem 
32.1). 
39.4. Use the results of Problems 39.3 and 9.10. 
39.5. Use Ito's lemma (Theorem 35.3) and the definition of the generator (Definition 
39.9). 
39.6. To prove part (a), use the result of Problem 39.5 and Theorem 38.1 to show 
that 
that is, 
loT E [ ( ~~ ( u, Xu)u( u, Xu) r] du < oo, 
and then apply Theorem 32.2. Use part (a) to prove part (b). 

SOLUTIONS 
537 
39.7. Apply Ito's formula (Theorem 35.3) to f(XiMv) and then use the monotone 
convergence theorem (Theorem 6.2). 
39.8. 
To prove part (a), use the result of Problem 39.7. To prove part (b), con-
sider the process X{ and use Dynkin's formula (see Problem 39.3) and the result of 
Problem 14.18. To prove part (c), consider the process yt = lnXt and use Dynkin's 
formula. To prove part (d), consider the sequence ...!... and use the result of Problem 
Tn 
9.3 and Doob's martingale inequality (Theorem 24.1). To prove part (e), use part (d) 
and the result of Problem 11.6 to show that 
and then use part (b). To prove part (f), try to show that 
Ex[T] = lim Ex[T 1\ Tk] 
k--+oo 
and then use parts (b) and (c). 
39.4 Solutions 
39.1. To show that Ps,t depends only on t - s, it is sufficient to show that 
Ps,t = Po,t-sÂ· 
Since 
x:Â·x 
X+ 1t p, (X~Â·x) du + 1t a (X~Â·x) dBu 
X+ 1t-s p, (X~~s) du + 1t-s a (X~~s) dBu+s, 
we have 
Yt-s = X+ 1t-s p, (Yu) du + 1t-s a(Yu)dBu, 
(39.3) 
where Bu = Bu+s - Bs and yt = x:-t-xsÂ· Since {Bt : t ~ 0} is also a Brownian 
motion, Yt-s and X~-'-": satisfy the same stochastic differential equation. Hence Yf-s 
and X~-'-": have the same distribution. It follows from Theorem 39.1 that 
Ps,t(x, A) 
E[IA(Xt'x)] 
E[IA(Yf-s)] 
E[IA(X~_'_':)J 
Po,t-s(x, A). 
Hence Equation (39.3) holds. This completes the proof. 

538 
DIFFUSION 
39.2. By Theorem 39.1, we have 
where Â¢(x) = E[IA(Xt'x)]. By Problem 38.7, we have 
Then we have 
P{Xt'x E A} 
P{xexr((JL- ~
2 ) (t-s)+a(B 1 -Bs)) ~y} 
p { (Bt _ Bs) < ln (~)- (Jl- ~) (t- s)} 
.;t=S -
a.;t=S 
<I> ( ln ( ~) - (/L - ~) ( t - s) ) , 
a.;t=S 
where <I>(-) is as defined in Equation (19.2). This finishes the solution. 
39.3. By Theorem 35.3, we have 
t ( 
of 
1 2 
o2 f 
) 
f(Yt) = 
f(Yo)+ Jo 
u(s,w) 0x(Ys)+ 2v (s,w) 0x 2 (Ys) 
ds 
1
t 
of 
+ 
v(s, w)""i'>(Ys)dB8 â¢ 
0 
ux 
Hence we have 
By the assumption, v(t,w)~;(Yt) is bounded. Then by Theorem 32.1, for every 
integer k, we have 

SOLUTIONS 
539 
Also by Theorem 32.1, we have 
X [( r 
aj 
rl\k 
8j 
)
2
] 
E 
Jo v(s,w)ax(Y8 )dB8
- Jo 
v(s,w)ax(Ys)dBs 
Ex [1:k ( 
v(s, w) ~~ (Ys) r 
ds l 
< K 2 Ex [ T -
T 1\ k], 
where K is a bound of v(t, w) Â¥t (l't). By the assumption that Ex [T] < oo, we have 
Ex[T- T 1\ k] ~ 0 ask~ oo. Hence we have 
rl\k 
aj 
L2 r 
aj 
Jo 
v(s,w) ax (Ys)dBs---+ Jo v(s,w) ax (Ys)dBs ask~ oo. 
It follows from Problem 9.1 that 
The result follows by rearranging Equation (39.4). This completes the proof. 
39.4. By letting T =tin Problem 39.3, we get 
To prove the result, we only need to show that 
Note that 
Ex [I~ (b(Xs)Â¥x(Xs) + ~o-2 (Xs)~(Xs)) ds] 
--"------'-----t-------'-------=- - Lf (X) 
Ex [I~ (b(Xs)Â¥x(Xs) + ~o-2 (Xs)~(X8 )- Lj(x)) ds] 
t 
X 
[ 
I 
aj 
1 2 
a2 f 
IJ 
< E 
sup b(X8 )-a (Xs) + -o- (Xs) a 2 (Xs)- Lf(x) 
. 
o::;s::;t 
X 
2 
X 

540 
DIFFUSION 
Since b(Xs)Â¥x(Xs) + ~cr2 (Xs)~(Xs) is continuous, we have 
. 
I 
af 
1 2 
a2 f 
1 
hm sup b(Xs)-;::;-(Xs) + -cr (Xs),::, 2 (Xs)- Lf(x) = 0. 
t.j_O O~s~t 
uX 
2 
uX 
It follows from Fatou's lemma (Theorem 6.3) that Equation (39.5) holds. This com-
pletes the proof. 
39.5. By Theorem 35.3, we have 
af 
df(t, Xt) 
= 
ax (t, Xt)cr(t, Xt)dBt 
( af 
af 
la2f 
2 
) 
+ at (t, Xt) + ax (t, Xt)J.L(t, Xt) + 2" ax2 (t, Xt)cr (t, Xt) dt 
( Ltf(t, Xt) + ~: (t, Xt)) dt + ~~ (t, Xt)cr(t, Xt)dBt. 
This completes the proof. 
39.6. 
(a) By Problem 39.5, we have 
Mt =fat (~~(u,Xu)cr(u,Xu)) dBu. 
By Theorem 32.2, it is sufficient to show that 
1T E [ ( ~~ ( u, Xu)cr( u, Xu)) 
2
] du < oo. 
(39.6) 
By the assumption that the first derivative off in x is bounded, we have 
~~~(u,Xu)l < K1 
for some constant K 1. Also by the assumption that cr( t, x)) satisfies the linear 
growth condition, we have 
Jcr(t, x)l < K2(l + Jxl) 
for some constant K 2 . Hence we have 
1T E [ ( ~~ ( u, Xu)cr( u, Xu) r] du 
< Kf 1T E [K~(l + JXul) 2] du 
< KfK~ 1T E [2 + 2JXul 2] du 
KfK~ (2T+21T E [1Xul 2] du). 

SOLUTIONS 
541 
Since { Xt : 0 "::: t "::: T} is the solution of the stochastic differential equation, 
it follows from Theorem 38.1 that 
loT E [1Xul 2) du < oo. 
Hence Equation (39.6) holds. 
(b) By part (a) and the assumption that f solves the backward equation, we have 
Mt 
f(t,Xt)- lot ( Luf(u,Xu) + ~~ (u,Xu)) du 
f(t, Xt)Â· 
By part (a) of this proof, the Mt is a martingale. Hence the f(t, Xt) is a mar-
tingale. 
This finishes the proof. 
39.7. Lett > 0 be fixed and x E D. By Theorem 35.3, we have 
(39.7) 
Since D is a compact set in R, Dis bounded. Since x; E D for s E [0, t A Td], 
a(X':)Â¥x(X':) is bounded for s E [0, t A Td]Â· Hence it follows from Theorem 32.1 
that 
[ tiiTD 
8f 
] 
E Jo 
a( X':) Bx (X':)dBs = 0. 
Therefore, by Equation (39.7) and the assumption, we have 
Since f is nonnegative over D, we have 
It follows from Theorem 6.2 that 
Ex[Tv] = lim Ex[t A Tv]< oo. 
t-+oo 
This competes the proof. 
39.8. 
(a) By Problem 39.7, we only need to find a C 2 function, which is nonnegative over 
D = 
[~, R], such that Lf(x) "::: -1 for all x E D. In fact, if p, =/= 0, then let 
f(x) = n(R-x). In this case, we have 
'" 
-n 
Lf(x) = p,x- = -nx "::: -1, 
'Vx ED. 
p, 

542 
DIFFUSION 
f 
!( ) 
n2(R2 x2) 
I J.L = 0, then let 
x = 
a 2-
â¢ In this case, we have 
1 
-2n2 
Lf(x) = -a2x 2-- = -n2x2 < -1 
\fx ED. 
2 
a 2 
-
' 
Thus Ex[T 1\ Tn] < oo. 
(b) Let f(x) = x"~, where 'Y = 1- ~- Since J.L =f. ~a 2 , we have 'Y =f. 0. Since 
Lf(x) = 0, by Problem 39.3, we get 
Ex[J(Xri\TJ] 
= f(x) +Ex [foTI\Tn Lf(Xs)ds] 
= 
x"~. 
But by Problem 14.18, we have 
Ex[J(Xrl\rJ] 
Ex[f(R)]P{T < Tn} +Ex [t (~)] (1- P{T < Tn}) 
R"~P{T < Tn} + (~)"' (1- P{T < Tn}). 
Combining the above two equations gives 
n-"~-x"' 
P{ T < Tn} = 
_ 
R . 
n "1-
"' 
(c) Let f(x) = lnx. Then by Problem 39.3, we have 
But by Problem 14.18, we have 
Ex[J(Xri\TJ] 
f(x) +Ex [foTI\Tn Lf(Xs)ds] 
lnx + (f.L- ~a2) Ex[T 1\ Tn]Â· 
Ex[J(R)]P{T < Tn} +Ex [J (~)] (1- P{T < Tn}) 
(lnR)P{T < Tn} + (ln~) (1- P{T < Tn}). 
Solving the above two equations gives 
x [ 
] _ ln ~ + ( 1 - P { T < T n}) ln n~ 
E T 1\ Tn -
1 
2 
. 
J.L- 2a 

SOLUTIONS 
543 
(d) Note that 
{ lim T n = 00} = { lim ~ = 0} . 
n--+oo 
n--+oo T n 
By Problem 9.3, we only need to show that for every 8 > 0, 
or 
J~oo Qx L9m { :k ~ (j}} = O 
J~= Qx CO" { 
Tk ~ ~} } = 1. 
Since Tk ::; Tk+l for all k > ~, we have 
Since 
and by Theorem 24.1, 
p { Bt ~ ln ( ~) - ;IL- ~o-2)t : 0 ::; t ::; ~} 
{ 
ln (mx) + (!L- ~u2 )t 
1} 
1 - p 
Bt ~ 
CT 
: 0 ::; t ::; J 
{ 
ln (mx) -IlL- ~u 2 IR 
1} 
> 
1 - p 
Bt ~ 
CT 
: 0 ::; t ::; J 
> 1 -
CT 
1 
E [Bt] ' 
ln (mx) -IlL- 2o-2IR 
J 
we have 
J~oo Qx { T m ~ ~} = 1. 
Hence Equation (39.8) holds. 
(39.8) 
(39.9) 
(e) Since { T < Tk} <;:;; { T < Tk+d for all k ~ ~,it follows from Problem 11.6 that 
lim Qx{T < Tk} = Qx {lim {T < Tk}}. 
(39.10) 
k--+oo 
k--+oo 

544 
DIFFUSION 
Since 
we have 
Hence by part (b), and Equations (39 .1 0) and (39 .11 ), we get 
By the assumption that f.L < ~a 2 , we have"( > 0. Therefore, we have 
(f) By part (d), we have 
Qx { lim T 1\ Tk = T} = 1. 
k---too 
Hence by Theorem 6.2 and Problem 6.9, we get 
Since f.L > ~a2 , we have 
x1 - R1 
1 
lim 
In-= 0. 
k---+oo k-' - R' 
kR 
Hence it follows from parts (c) and (b) that 
This completes the proof. 
. 
In E + (1 - P{ T < Tk}) In k~ 
hm -"'"x---'-----''-:-----"-'---="'-
k---+oo 
f.L- ~a2 
I 
R 
x"~-R"~ I 
1 
I. 
n x + k -r-R-r n kR 
lm 
k---+oo 
f.L- ~a2 
InE 
X 
(39.11) 

BIBLIOGRAPHIC NOTES 
545 
39.5 
Bibliographic Notes 
In this chapter, we presented diffusions, which are defined to be the solutions of 
stochastic differential equations. For general definition of diffusions or diffusion 
processes, readers are referred to Friedman (1975), Karlin and Taylor (1981), and 
Stirzaker (2005). Diffusions are also studied in several other books such as Stroock 
and Varadhan (1979), Durrett (1996), Oksendal (1998), Rogers and Williams (2000), 
Klebaner (2005), and Pinsky (1995). Revuz and Yor (1999) discusses properties of 
the generator of Xt. 
Theorem 39.1 and Theorem 39.2 state that Ito diffusions have the Markov prop-
erty and the strong Markov property, respectively. Proofs of these theorems can be 
found in Friedman (1975), Oksendal (1998), and <;inlar (2011). 
Some concepts (e.g., compact and support) presented in this chapter are adopted 
from real analysis. For general definition of these concepts, readers are referred to 
Rudin (1970). 


CHAPTER40 
THE FEYNMAN-KAC FORMULA 
The solutions to certain second-order partial differential equations can be represented 
as expectations of stochastic functionals. In fact, the Feynman-Kac formula estab-
lishes a link between certain partial differential equations and stochastic processes. 
In this chapter, we present the Feynman-Kac formula. 
40.1 
Basic Concepts and Facts 
Definition 40.1 (Dirichlet Problem). Let D = (a, b) be an interval. A Dirichlet 
problem is an ordinary differential equation of the form 
au 
1 
a2u 
b(x) ax (x) + 2u2(x) ax2 (x)- a(x)u(x) = f(x), 
xED, 
(40.la) 
u(x) = <p(x), 
x E aD= {a, b}, 
(40.lb) 
where b, u, f, a, and <pare given functions, and aD is the boundary of of D. The 
function u is called a solution to the Dirichlet problem. 
Measure, Probability, and Mathematical Finance. 
547 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

548 
THE FEYNMAN-KAC FORMULA 
Definition 40.2 (Cauchy-Dirichlet Problem). Let Q = (0, T) x D, ~here D = (a, b) 
is an interval and T > 0. Let opQ = ([O,T] x {a,b}) U ({T} x D). A Cauchy-
Dirichlet problem is a partial differential equation of the form 
(40.2a) 
u(t, x) = cp(t, x), 
(t, x) E opQ, 
(40.2b) 
where b, u, f, a, and cp are given functions. The function u is called a solution to the 
Cauchy-Dirichlet problem. 
Definition 40.3 (Cauchy Problem). Let Q = (0, T) x R, where T > 0. A Cauchy 
problem is a partial differential equation of the form 
(40.3a) 
u(T,x) = cp(x), 
x E R, 
(40.3b) 
where b, u, f, a, and cp are given functions. The function u is called a solution to the 
Cauchy problem. 
Theorem 40.1 (The Feynman-Kac Formula). Let f be a C 2 function on R with a 
compact support. Let q be a lower bounded continuous function on R. Let v ( t, x) 
be a function on R + x R defined as 
v(t, x) =Ex [t(Xt) exp (-lot q(Xs)ds)] , 
where { Xt : t ~ 0} is an Ito diffusion as defined in Definition 39.6. Then v( t, x) is 
a solution to the following Cauchy problem 
ov 
ot (t,x) = Lv(t,x)- q(x)v(t,x), 
t > O,x E R, 
(40.4a) 
v(O, x) = f(x), 
x E R, 
(40.4b) 
where L is the second order differential operator associated with the Ito diffusion 
(see Definition 39.9 ): 
ov 
1 2 
82v 
Lv(t,x) = b(x)~(t,x) + -u (x) !l 2 (t,x). 
ux 
2 
ux 
Moreover, ifw(t, x) is a C1â¢2 function on R+ x R that is bounded on K x R+ for 
each compact K ~ Rand w( t, x) solves the initial-value problem given in Equation 
(40.4), then w(t, x) = v(t, x)_ 

PROBLEMS 
549 
40.2 
Problems 
40.1. Let D =(a, b) be an interval. Let f be a bounded function on D, <p a function 
on aD, and a a continuous nonnegative function on D. Let {Xt : t ~ 0} be an Ito 
diffusion as defined in Definition 39.6. Let TD be the first exit time of Xf from D. 
Suppose that Ex[TD] < oo and that u E C2(D) n C(D) (i.e., u is a C2 function on 
D and is continuous on the closure of D) is a solution to the Dirichlet problem 
Lu(x)- a(x)u(x) = f(x), 
xED, 
u(x) = c.p(x), 
x E aD, 
(40.5a) 
(40.5b) 
where L is the differential operator associated with Xt (see Definition 39.9). For 
every x E D, show that 
u(x) = Ex [exp ( -1TD a(Xt)dt) c.p(XTv)] -
Ex [1TD exp ( -1t a(Xs)ds) f(Xt)dt] . 
40.2. Let Q = (0, T) x D, where D = (a, b) is an interval. Let apQ = ([0, T] x 
{a, b}) U ( { T} x D). Let f be a bounded function on Q, <p be a continuous function 
on apQ, and a be a lower bounded continuous function on Q. Let {Xt : t ~ 0} be 
a diffusion as defined in Definition 39.5. If u E C 2 ( Q) n C( Q) is a solution of the 
following Cauchy-Dirichlet problem 
au 
Ltu-au+at=f, (t,x)EQ, 
u(t,x) = c.p(t,x), 
(t,x) E apQ, 
(40.6a) 
(40.6b) 
where f, a, and <p are given functions and Lt is the differential operator associated 
with Xt (see Definition 39.9). For every (t, x) E Q, show that 
u(t,x) 
= 
E [exp ( -1Tt,x a(s,X!Â·x)ds) 'Ph,x,x;;~J] 
-E [1Tt,x exp ( -1
8 a(r,x;â¢x)dr) f(s,X!â¢x)ds], 
where Tt,x = inf{ 8 > t : x;,x Â¢'. D} AT. 
40.3. Let { Xt : 0 ::; t ::; T} be a diffusion as defined in Definition 39.5. Let 
Q = (0, T) x R. Let u E C 2(Q) n C(Q) be a solution of the following Cauchy 
problem 
au 
Ltu-au+at=f, (t,x)EQ, 
u(T, x) = c.p(x), 
x E R, 
(40.7a) 
(40.7b) 

550 
THE FEYNMAN-KAC FORMULA 
where Lt is the differential operator associated with Xt (see Definition 39.9), a is a 
lower-bounded continuous function on Q, and f and <pare given functions. Suppose 
that 
(a) The coefficients J-l(t, x) and a(t, x) are measurable and have at most linear 
growth in x. 
(b) For every (t,x) E Q, there exists a solution {X!â¢x : t :S s :S T} of the 
stochastic differential equation 
dXs = J-l(s, X 8 )dB8 + a(s, X 8 )ds, 
Xt = x, s E [t, T]; 
(c) There exist two positive constants M and p such that 
Ju(t, x)l + lf(t, x)l :S M (1 + JxJP), 
(t, x) E Q; 
For every ( t, x) E Q, show that 
u(t,x) 
E [ exp ( -~T a( s, X!â¢x)ds) <p(X~x)] 
-E [lT exp ( -1
8 a(r,x;â¢x)dr) f(s,X!Â·x)ds]. 
40.4 (Kolmogorov's Backward Equation). Let f be a C 2 function on R with a com-
pact support. Let u( t, x) be a function on R + x R defined as 
where { Xt : t ~ 0} is an Ito diffusion as defined in Definition 39.6. Show that 
u( t, x) solves the following initial-value problem 
au 
at (t, x) = Lu(t, x), 
t > 0, x E R, 
(40.8a) 
u(O, x) = f(x), 
x E R, 
(40.8b) 
where Lu(t, x) denotes that Lis applied to the function x-+ u(t, x). 
40.5. Let u be a C 1 â¢2 function on R x R that satisfies the following partial differential 
equation 
au 
au 
1 2 2 82u 
at = -qu + f-lX OX + 2()" X 8x2' 
t > 0, X E R, 
u(O,x) = (x- K)+, 
x E R, 
where q > 0, f-l, a > 0, and K > 0 are constants and 
(x- K)+ = max(x- K, 0). 
(40.9a) 
(40.9b) 

HINTS 
551 
Show that for every t > 0 and x E R, 
u(t,x) = ~ L 
[xexp ( (M- ~a2) t +ay)-Kr exp ( -;:) dy. 
40.6 (Bivariate Laplace Transform). Let { Bt : t 2: 0} be a Brownian motion. Show 
that 
(a) For 0 :::;: t ::=;: T, we have 
E [ e-w It B.ds-uBT I Bt =X] 
exp (w2 (T- t) 3 + wu (T- t) 2 + u2 (T- t) - [w(T- t) + u]x) . 
6 
2 
2 
(b) For 0 ::=;: t ::=;: T ::=;: 8, we have 
E [ e-w J,s B.ds-uBT I Bt =X] 
( w2 
3 
wu 
2 
wu 
2 
u2 
) 
exp 6 (8-t) + 2 (8-t) - 2 (8-T) + 2 (T-t) x 
exp ( -[w(8- t) + u]x). 
40.3 Hints 
40.1. Apply Ito's lemma (Theorem 35.3) to the process yt = u(Xt)Zt. where 
Zt = exp (-lot a(Xs)ds) . 
40.2. 
The proof is similar to that of Problem 40.1. That is, apply Ito's lemma 
(Theorem 35.3) to the process Ys = u(X8 )Z8 , where 
40.3. Consider the exit time of Xt from D = ( -n, n), n 2: 1, and use the result of 
Problem 40.2 and the dominated convergence theorem (Theorem 6.4). 
40.4. Use Theorem 39.2 and the result of Problem 39 .4. 
40.5. Consider the C2 function f n ( x) such that 
fn(x) = (x- K)+, 
x E ( K + ~, K + n) 
and 
fn(x) = 0, 
x E (-oo,K) U (K +n+ l,oo). 

552 
THE FEYNMAN-KAC FORMULA 
Then apply the Feynman-Kac formula (Theorem 40.1) and the dominated conver-
gence theorem (Theorem 6.4). 
40.6. Apply the Feynman-Kac formula (Theorem 40.1) to prove the first part. Use 
the first part to prove the second part. 
40.4 Solutions 
40.1. Let 
Zt = exp (-lot a(Xs)ds), 
t ~ 0. 
Then by Theorem 35.3, we have 
(40.10) 
Also by Theorem 35.3 and the assumption, we have 
du(Xt) 
au 
a(Xt) ax (Xt)dBt + Lu(Xt)dt 
au 
a(Xt) ax (Xt)dBt + [a(Xt)u(Xt) + f(Xt)]dt. 
(40.11) 
Then it follows from Problem 35.6, and Equations (40.10) and (40.11) that 
Zfu(Xt) = u(x) +lot Z';a(X';) ~~ (X';)dBs +lot Z'; f(X';)ds, 
where z; = exp (- J~ a(X;)ds). Hence we have 
rD 
a 
rD 
z:Du(Xf)=u(x)+ Jo 
Z';a(X';)a~(X';)dBs+ Jo 
Z';f(X';)ds. 
By the assumption, we have z; E [0, 1]. Hence Z';a(X';) ~~(X';) and z; f(X';) 
are bounded on {(t, w) : Xf(w) ED}. Therefore, by Theorem 32.1 we have 
Hence we have 
The result follows by noting that u(X;D) = c.p(X;D ). This completes the proof. 
40.2. Let 
Z 8 =exp(-1
8 a(r,Xr)dr), 
s~t. 

SOLUTIONS 
553 
Then by Theorem 35.3, we have 
dZ8 = -a(s, X 8 )Z8 ds, 
s > t. 
Also by Theorem 35.3 and the assumption, we have 
du(s, X 8 ) 
= a~~ dB8 + ( ~~ + L 8U) ds 
au 
a ax dB8 +(au+ f) ds. 
Then by Problem 35.6, we have 
Hence we have 
zt,x u(T 
xt,x ) 
Tt,x 
t,x, 
Tt,x 
where 
z;.x = exp ( -1
8 a(r, x;Â·x)dr) . 
By the assumption that a(s, X 8 ) is lower-bounded, a satisfies the linear growth 
condition, and u is a C 2 function on Q, Z!â¢xa(s, X!Â·x) g~ (s, X!Â·x) is bounded on 
{(s,w): X!Â·x(w) ED}. Hence we have 
E [l.Tt,x zt,xa(s xt,x) au (s xt,x)dB ] = 0 
t 
8 
' 
s 
ax ' 
8 
8 
â¢ 
Therefore, taking expectation in both sides of Equation (40.12) gives 
u(t,x) = E [z;;~xu(Tt,x,X;;~J]- E [1rt,x z;,x f(s,X!â¢x)ds] 
E [zt,x rn(T 
xt,x )] - E [l.Tt,x zt,xf(s xt,x)ds] . 
'Tt,x Y 
t,x, 
Tt,x 
8 
' 
8 
t 
This completes the proof. 
40.3. Let n ~ 1 and T n = inf { s ~ t : x;,x tJ. ( -n, n)}. Then by Problem 40.2, we 
have 
u(t,x) 
E [ exp ( -1TI\Tn a(s, X!â¢x)ds) u(T A Tn, X~~rJ] 
-E [1TI\Tn exp ( -1
8 a(r,x;â¢x)dr) f(s,X!Â·x)ds] (40.13) 

554 
THE FEYNMAN-KAC FORMULA 
By the assumption, we have 
lexp ( -1T/\Tn a(s, X!Â·x)ds) u(T ATn, x~~TJI ::; MelaoiT ( 1 +X~)' 
I1T/\Tn exp ( -1'" a(r, x;Â·x)dr) f(s, X!Â·x)dsl ::; TelaoiT ( 1 +X~) ' 
where a0 is the lower bound of a and 
Xr = sup IX!â¢xl-
t~s~T 
By Problem 38.6, Xr is integrable. Since Tn AT --+ T as n --+ oo, it follows from 
Theorem 6A that 
u(t,x) 
= 
E [exp ( -1T a(s,X!â¢x)ds) u(T,X~x)] 
-E [1T exp ( -1
8 a(r,x;â¢x)dr) f(s,X!Â·x)ds]-
This completes the proof. 
40.4. 
Lett ~ 0 be fixed. Let g(x) = u(t, x). By Theorem 39.2, g(Xr) = 
E[f(Xt+r)lffr] for every r > 0 (r is a constant and hence a stopping time). Then 
we have 
r 
r 
Ex[j(Xt+r)]- Ex[f(Xt)] 
r 
u(t + r, x)- u(t, x) 
r 
By Problem 39_4, we have 
lim Ex[g(Xr)]- g(x) = Lu(t,x). 
r.j.O 
r 
Combining the above two equations gives 
au 
at (t,x) = Lu(t,x). 
This completes the proof. 
40.5. Let {Xt : t ~ 0} be the Ito diffusion given by 
dXt = JLXtdt + aXtdBt, 
Xo = x, t ~ 0. 

SOLUTIONS 
555 
Then the second-order differential operator associated with Xt is given by 
au 
1 2 2a2u 
Lu = f.LX ax + 20" X ax2 . 
For every n 2: 1, let fn(x) be a function on R given by 
where 
and 
0, 
ifx E (-oo,K); 
9n(x), 
if X E [K, K + ~]; 
fn(x)= x-K, ifxE(K+~,K+n); 
hn ( x), 
if x E [ K + n, K + n + 1]; 
0, 
if x E (K + n + 1, oo ), 
hn(x) 
= 
n+(x-K-n)-(10n+6)(x-K-n)3 
+(15n + 8)(x- K- n)4 - (6n + 3)(x- K- n)5 . 
Then f n (X) is a C 2 function with a compact support. It follows from Theorem 40.1 
that 
Un(t,x) =Ex [fn(Xt)e-qt] 
solves the following partial differential equation 
aun 
aun 
1 2 2 a2un 
8t = -qun + f.LX ax + 20" X 
ax2 ' 
t > 0, X E R, 
Un(O, x) = fn(x), 
X E R. 
Since for every x E [K, K + ~], 
lgn(x)l 
< 6n2(x- K) 3 + 8n3(x- K) 4 + 3n4(x- K) 5 
< (x- K)(6 + 8 + 3) 
< 
17 
and for every x E [K + n, K + n + 1], 
we have 
lhn(x)l < n + (x- K- n) + (10n + 6)(x- K- n)3 
+(15n + 8)(x- K + n)4 + (6n + 3)(x- K- n)5 
< n + 1 + (lOn + 6) + (15n + 8) + (6n + 3) 
< 32x + 8, 
lfn(Xf)l :S:: 321Xfl + 8 + K :S:: 32 sup IX: I+ 17 + K. 
O:S:s9 
(40.14) 

556 
THE FEYNMAN-KAC FORMULA 
Since fn(t,x) -+ (x- K)+ as n -+ oo and SUPo<s<t IX:I is integrable (see 
Problem 38.6), it follows from Theorem 6.4 that 
- -
lim Un(t,x) = u(t,x). 
n-too 
Hence we have 
The result follows by Problem 38.7 and integrating out the expectation. This com-
pletes the proof. 
40.6. 
(a) LetXr = Br+t forallr.?: O,f(x) = e-ux,andq(x) = wx. Then by Theorem 
40.1, the function 
satisfies the following Cauchy problem 
av 
1 82v 
Br (r, x) = 2 ax2 (r, x)- wxv(r, x), 
r > 0, x E R, 
(40.15a) 
v(O, x) = f(x) = e-ux, 
x E R, 
(40.15b) 
But the function 
also satisfies the Cauchy problem given in Equation (40.15). Therefore, it fol-
lows from Theorem 40.1 that 
The result follows by letting r = T - t. 

BIBLIOGRAPHIC NOTES 
557 
(b) By the first part and the tower property of conditional expectations (see Problem 
14.10), we have 
E [ e-wi,S B.ds-uBTI Bt = x] 
E [ e-w It B.ds-uBT E [ e-w Ii Bsds I Br] I Bt = X] 
E [ e-w It B.ds-uBT exp ( ~
2 (8- T) 3 - w(8- T)Br) I Bt =X] 
exp ( ~2 (8 _ T)3) E [ e-w It B.ds-[w(S-T)+u]BT I Bt =X] 
exp ( ~\8 -T) 3 ) x 
exp (w2 (T- t) 3 + wu (T- t) 2 + u2 (T- t) - [w(T- t) + u]x) 
6 
2 
2 
( w2 
3 
wu 
2 
wu 
2 
u2 
) 
exp 6 (8-t) + 2 (8-t) - 2 (8-T) + 2 (T-t) x 
exp ( -[w(8- t) + u]x), 
where u = w(8- T) + u. 
This completes the proof. 
40.5 Bibliographic Notes 
In this chapter, we presented several versions ofthe Feynman-Kac formula, each ver-
sion of which involves some technical conditions on underlying coefficients and ini-
tial data. Although these conditions are different, the idea behind the Feynman-Kac 
formula is the same. For a discussion of the technical conditions for the Feynman-
Kac formula, readers are referred to Duffie (2001). 
The Feynman-Kac formula is studied in many texts, for example, Karatzas and 
Shreve (1991), Durrett (1996), Bass (1998), Oksendal (1998), Steele (2003), and 
Pascucci (2011). In this chapter, we presented only the one-dimensional Feynman-
Kac formula. For the multidimensional Feynman-Kac formula, readers are referred 
to Karatzas and Shreve (1991), Oksendal (1998), Shreve (2004), Pinsky (1995), 
Pham (2009), and Pascucci (2011). 
The Dirichlet problem, the Cauchy problem, and the heat equation are subjects 
studied in partial differential equations. Steele (2003, Chapter 11) gives a very good 
introduction to the derivation of the heat equation. For an introduction to the heat 
equation and Cauchy problem, readers are referred to Cannon (1984). The connec-
tion between the heat equation and the Brownian motion is discussed in Karatzas and 
Shreve (1991) and Lawler (2006). 


PARTV 
STOCHASTIC FINANCIAL 
MODELS 


CHAPTER 41 
DISCRETE-TIME MODELS 
In discrete-time models, it is assumed that trading takes place at discrete time points. 
In this chapter, we present discrete-time models of financial markets. In particular, 
we will introduce the binomial model. 
41.1 
Basic Concepts and Facts 
Definition 41.1 (Discrete Market). Let T be a positive real number and N be a 
positive integer. Let 0 = t0 < t 1 < Â· Â· Â· < tN = T. Let (0, Â§, P) be a probability 
space, where 0 is finite, ,~ = 211, and P { w} > 0 for every w E 0. A discrete 
market is a ( d + 1 )-dimensional stochastic process 
s = {(S~0l, s~Il, ... , s~dl): n = o, 1, ... , N} 
defined on the probability space (0, Â§, P). 
The first entry s~O) is the price at time tn of a riskless asset and is deterministic, 
that is, 
S(O) = S(O) (1 + r ) 
n 
n-1 
n 
' 
n = 1,2, ... ,N, 
where rn > -1 is the risk-free interest rate in the nth period [tn-l, tn]Â· 
Measure, Probability, and Mathematical Finance. 
561 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

562 
DISCRETE-TIME MODELS 
For j ~ 1, the jth entry S~) is the price at time tn of the jth risky asset and 
follows the following stochastic dynamics: 
Here saj) is a real number and !JC,jl > -1 is a real random variable. 
The amount of information available in the market at time tn is represented by 
the 17-algebra Â§n given by 
Â§o = {0,0} 
and 
-
(( (1) 
(2) 
(d)) 
0 Â°-
) 
Â§n-17 
!Ji ,!Ji , ... ,!Ji 
.z-1,2, ... ,n, n = 1,2, ... ,N. 
We assume thatÂ§ N = Â§. 
Definition 41.2 (Normalized Market). Let S be a discrete market and { Â§ n : n = 
0, ... , N} be the filtration as defined in Definition 41.1. Let Y = {Yn : n = 
0, 1, ... , N} be a positive Â§n-adapted price process. The normalized market of S 
with respect to Y is defined as 
where 
- _ 
-(o) -(1) 
-(d) . 
_ 
S-{(Sn ,Sn , ... ,Sn ).n-0,1, ... ,N}, 
(j) 
-(j) _ Sn 
Sn - Y,, 
j = 0, ... , d, n = 0, ... , N. 
n 
The process Y is called a numeraire. 
Definition 41.3 (Portfolio). A portfolio or strategy is a ( d + 1 )-dimensional stochas-
tic process 
a = { ( a~0 ), a~1 ), ... , a~d)) : n = 0, 1, ... , N}. 
The value of the portfolio a at time tn is 
d 
Vn(a) = La~ls~l. 
j=O 
Definition 41.4 (Self-Financing Portfolio). A portfolio a is called self-financing if 
for every n in {1, 2, ... , N}, we have 
d 
Vn_I(a) = La~ls~2 1 . 
j=O 
Definition 41.5 (Predictable Portfolio). A portfolio a is called predictable if for 
every n in {1, 2, ... , N}, (a~o), a~1 ), ... , a~d)) is Â§n_1-measurable, where Â§n is 
as given in Definition 41.1. 

BASIC CONCEPTS AND FACTS 
563 
Definition 41.6 (Arbitrage). Let A be the family of all self-financing, predictable 
portfolios of the discrete market. A portfolio a E A is called an arbitrage if V0 (a) = 
0 and there exists n ~ 1 such that P{Vn(a) ~ 0} = 1 and P{Vn(a) > 0} > 0. 
The discrete market is called arbitrage-free if A does not contain arbitrage port-
folios. 
Definition 41.7 (Admissible Portfolio). A portfolio a is called admissible if for ev-
ery n in {1, 2, ... , N}, we have 
P{Vn(a) ~ 0} = 1. 
Definition 41.8 (Equivalent Martingale Measure). Let Y be an numeraire. An equiv-
alent martingale measure withY is a probability measure Q on (n, Â§)such that 
(a) Q"' P (see Definition 7.3). 
(b) the Â¥-normalized price processes are Q-martingales: 
n = 1, 2, ... , N, j = 0, 1, ... , d, 
where EQ denotes the expectation under the probability measure Q. 
Definition 41.9 (European Derivative). A European derivative is anÂ§ N-measurable 
random variable on (n, Â§, P), where Â§n is given in Definition 41.1. 
Definition 41.10 (Replicating Portfolio for European Derivatives). Let X be a Eu-
ropean derivative. A portfolio a E A is said to be a replicating portfolio of X if 
VN(a) =X P- a.s. 
If such a portfolio exists, the derivative is said to be replicable. 
A portfolio a E A is said to be a superreplicating portfolio for X if 
VN(a) ~X P- a.s. 
The family of all super-replicating portfolio for X is denoted by A!-: 
A!-= {a E A: P{VN(a) ~X}= 1}. 
A portfolio a E A is said to be a subreplicating portfolio for X if 
VN(a) ::; X P- a.s. 
The family of all sub-replicating portfolio for X is denoted by A _X: 
A_X ={a E A: P{VN(a)::; X}= 1}. 

564 
DISCRETE-TIME MODELS 
Definition 41.11 (American Derivative). An American derivative is a nonnegative 
discrete stochastic process X = { Xn : n = 0, 1, ... , N} adapted to the filtration 
{ $n : n = 0, 1, ... , N}, where the filtration is as given in Definition 41.1. 
Definition 41.12 (Exercise Strategy). An exercise strategy or exercise time of an 
American derivative is a stopping time v : n ---+ {0, 1, ... , N}. The set of all 
exercise strategies is denoted by To-
Definition 41.13 (Payoff of American Derivatives). Let X be an American derivative 
and v an exercise strategy. The payoff of X relative to the strategy v is the random 
variable Xv defined by 
Xv(w) = Xv(w)(w), 
\:!wE D. 
Let Q be an equivalent martingale measure with numeraire Y. An exercise strat-
egy v0 is called optimal under Q if 
Definition 41.14 (Replicating Portfolio for American Derivatives). Let X be an 
American derivative. A portfolio o: E A is said to be a superreplicating portfolio 
for X if 
Vn(o:) ~ Xn P- a.s., 
\In= 0, 1, ... , N. 
The family of all superreplicating portfolios for X is denoted by A :k: 
A:k ={a: E A: P{Vn(o:) ~ Xn} = 1, n = 0, 1, ... ,N}. 
The family Ax is defined as 
Ax = { o: E A: there exists v E To such that P{ Xv ~ Vv(o:)} = 1 }. 
Definition 41.15 (Complete Market). A market is said to be complete if every Eu-
ropean derivative is replicable. 
Definition 41.16 (Arbitrage Price). Let X be a replicable European derivative in a 
market that is free of arbitrage. Then arbitrage price or risk-neutral price of X is 
V(o:), where o: is a replicating portfolio of X (see Problem 41.16). 
Definition 41.17 (Binomial Model). In the binomial model, the market is composed 
of two assets: a riskless asset and a risky asset. The time intervals have the same 
length: 
T 
tn- tn-1 = N, 
n = 1, 2, ... , N. 
The interest rate is assumed to be constant, namely, rn = r for every n. The dynam-
ics of the riskless asset is given by 
S~0l=(1+r)n, n=0,1, ... ,N. 

PROBLEMS 
565 
The random variables /-Ll, !-L2, â¢.. , 1-L N are assumed to be independent and identically 
distributed on the probability space (0, g-, P): 
P{1 + 1-ln = u} = p, 
P{1 + 1-ln = d} = 1- p, 
where 0 < d < u and p E ( 0, 1). The sample space 0 is assumed to be 
which contains 2N elements. Each element in n is a path in the binomial tree. 
Theorem 41.1 (First Fundamental Theorem of Asset Pricing). Let S be a discrete 
market as defined in Definition 41.1. Then S is arbitrage-free if and only if there 
exists at least one equivalent martingale measure. 
Theorem 41.2 (Second Fundamental Theorem of Asset Pricing). LetS be a discrete 
market as defined in Definition 41.1. Suppose that S is arbitrage-free. Then S is 
complete if and only if there exists a unique equivalent martingale measure with 
numeraire {8~0 ) : n = 0, 1, ... , N}. 
Theorem 41.3 (European Derivative Pricing in Binomial Models). Let S be the 
binomial market as defined in Definition 41.17. Suppose that d < 1 + r < u. Then 
(a) The binomial market is arbitrage1ree and complete. 
(b) The arbitrage price at time tn of a European derivative X is given by 
(41.1) 
where Q is the equivalent martingale measure given in Problem 41.8. 
(c) If a European derivative X = f ( S~ \ then the initial price of X is given by 
Ho = 
where q is as given in Problem 41.8. 
41.2 Problems 
41.1. Let S be a discrete market as defined in Definition 41.1. Show that S is 
arbitrage-free if and only if there exist no admissible arbitrage portfolios. 

566 
DISCRETE-TIME MODELS 
41.2. Let Q be an equivalent martingale measure with numeraire Y. Let a E A (see 
Definition 41.6). Define V(a) as 
DÂ· ( 
) = Vn(a) 
Vn a 
Yn 
' 
n = 0, 1, ... 'N. 
Show that 
(a) V(a) is a Q-martingale: 
Vn-l (a)= EQ [Vn(a)lffn-1] , 
n = 1, 2, ... , N. 
(b) The following risk-neutral pricing formula holds: 
41.3 (No-Arbitrage Principle). LetS be an arbitrage-free discrete market and A the 
family of all self-financing, predictable portfolios inS. Suppose that a, (3 E A and 
Show that for every n in {0, 1, ... , N}, 
Vn(a) = Vn(f3) P- a.s. 
41.4 (Change of Numeraire ). Let S be a discrete market and { Â§ n : n = 0, ... , N} 
be the filtration as defined in Definition 41.1. Let Q be an equivalent martingale 
measure with numeraire Y. Let X be a positive ffn-adapted process such that 
{ ~: : n = 0, 1, ... , N} 
is a Q-martingale. Let Q x be a probability measure defined as 
dQx = ~:~dQ. 
Show that 
(a) For every random variable Z, we have 
(b) Q x is an equivalent martingale measure with numeraire X. 
41.5. Let X be a European derivative and Q be an equivalent martingale measure 
with numeraire Y. Show that for every n in {0, 1, ... , N}, we have 

PROBLEMS 
567 
where Ax and A1 are as defined in Definition 41.10. 
41.6 (Arbitrage Price). Let X be a replicable European derivative in an arbitrage-free 
market. For every replicating portfolio a E A and for every equivalent martingale 
measure Q with numeraire Y, show that 
E 
[~IÂ§.] = Vn(a) 
Q Y 
n 
Y, 
' 
N 
n 
n = 0, 1, ... ,N. 
41.7 (Markov Property). LetS be a discrete market as defined in Definition 41.1. Let 
(1) 
(2) 
(d) 
(1) 
(2) 
(d) 
1-ln = (J-Ln , /-ln , ... , /-ln ) and Sn = (Sn , Sn , ... , Sn ) for n = 1, 2, ... , N. 
Suppose that p,1 , p,2 , ... , J-lN are independent. Show that {Sn: n = 0, 1, ... , N} is 
a Markov process; that is, for every positive function f E mB(Rd), that 
41.8. LetS be the binomial market given in Definition 41.17. Suppose that d < 
1 + r < u. Show that 
(a) There exists a unique equivalent martingale measure Q with numeraire {8~0 ) : 
n = 0, 1, ... , N}, which is given by 
Q{1 + J-ln = u} = q, 
Q{1 + J-ln = d} = 1- q, 
where q = 1+r-d. 
u-d 
(b) The random variables p,1 , p,2 , ... , J-lN are independent under the probability 
measure Q and 
(c) The process {8~1 ) : n = 0, 1, ... , N} is a Markov process; that is, for every 
positive Borel function <p, we have 
41.9 (Snell Envelope). Let S be the discrete market as defined in Definition 41.1. 
Let X be an American derivative and Q be an equivalent martingale measure with 
numeraire Y. Let fi ={fin : n = 0, 1, ... , N} be a stochastic process defined by 
ifn = N; 
if n = 0, 1, ... , N- 1, 
-
X 
where Xn = y:n for n = 0, 1, ... , N. 
n 
Show that fi is the smallest Q-supermartingale greater than or equal to X: 

568 
DISCRETE-TIME MODELS 
41.10. Let X be an American derivative and Q be an equivalent martingale measure 
with numeraire Y. Show that 
sup Vo(a) :::; sup EQ[X..,] :::; inf Vo(a), 
<>EA~ 
vETo 
<>EAk 
where Ax and A!- are as defined in Definition 41.14, X.., = ~~, and Vo(a) 
Vo(<>) 
---y;;-. 
41.11 (Arbitrage Price for American Derivatives). Let X be an American derivative 
in the discrete market S defined in Definition 41.1. Let A!- and Ax be defined 
as in Definition 41.14. Suppose that Sis arbitrage-free and complete and Q is the 
equivalent martingale measure in the market with numeraire Y. Show that there 
exists a portfolio a 0 E A!- n Ax such that 
(a) Vn(ao) ;:::: Xn for all n = 0, 1, ... , N. 
(b) There exists an exercise strategy vo such that V..,0 (ao) = X..,0 â¢ 
(c) The initial arbitrage price of X is given by 
[Xv0 ] 
[X"] 
Vo(ao) = YoEQ Y. =Yo sup EQ Y. . 
Vo 
vETo 
v 
41.3 Hints 
41.1. The sufficiency ("only if") part is obvious. To prove the necessity part, use 
the method of contradiction. 
41.2. To prove the first part, follow the definitions of equivalent martingale measure, 
self-financing portfolio, and predictable portfolio. The second part follows from the 
first part. 
41.3. Apply the first fundamental theorem of asset pricing (Theorem 41.1) and use 
the result of Problem 41.2. 
41.4. Use the result of Problem 14.20 to prove the first part. To prove the second 
part, first use the first part to show that 
j = 0, ... , d, n = 0, ... , N, 
and then apply the tower property (see Problem 14.1 0). 
41.5. Use the results of Problems 14.5 and 14.6. 
41.6. Use the results of Problems 41.3 and 41.5. 

SOLUTIONS 
569 
41.7. UsetheresultofProblem 14.13. 
41.8. Follow the definition of equivalent martingale measures (Definition 41.8) and 
use the result of Problem 14.19 to prove part (a). Follow the definition of indepen-
dence (Definition 12.2) and use the result of Problem 14.10 to prove part (b). Use 
the result of Problem 41.7 and part (a) to prove part (c). 
41.9. Use the induction method to show that fi is the smallest Q-supermartingale; 
that is, assume Hn <::; Yn and then show that Hn-1 <::; Yn-1Â· 
41.10. 
Note that V(a) is a Q-martingale and use the optimal stopping theorem 
(Theorem 23.1). 
41.11. Use the results of Problems 41.9 and 22.11. 
41.4 Solutions 
41.1. The sufficiency part is clear. If Sis arbitrage-free, then there exist no arbitrage 
portfolios. Hence there exist no admissible arbitrage portfolios. 
Now we prove the necessity part. Assume that there exist no admissible arbitrage 
portfolios. We show that S is arbitrage-free by contradiction. If there exists an 
arbitrage portfolio a, then by Definition 41.6, we have 
d 
Vo(a) = L aij) s60) = 0, 
j=O 
and there exists an integer k :=:: 1 such that 
P{Vk(a) :=:: 0} = 1 and P{Vk(a) > 0} > 0. 
By the hypothesis, a is not admissible. Hence there exist an integer m <::; N and a 
set FE Â§m with P(F) > 0 such that 
and 
d 
l:a~l(w)Sgl(w) < 0, 
'Vw E F 
j=O 
1' { w 't,a';fl(w)s!{>(w);:, 0} ~ 1, Vm < n,; N. 
If m = N, we let (3~) = 0 on D\F for all j = 0, 1, ... , d and n = 0, 1, ... , N, 
and 
(3(j) = {-VN(a), 
n 
0, 
if n = N and j = 0; 
otherwise. 
j = 0, ... , d, n = 0, ... , N. 

570 
DISCRETE-TIME MODELS 
Hence we have Vn(,B) = 0 on 0\F, Vn(,B) = 0 on F for n < N, and VN(,B) = 
-VN(a)S~) > 0 on F. Therefore, ,B is an admissible portfolio. This contradicts the 
assumption. 
If m < N, we can also find an admissible portfolio, which contradicts the as-
sumption. This completes the proof. 
41.2. 
(a) By the assumption that a E A, we know that a is self-financing and predictable. 
Then by Problem 14.12, for every n E { 1, 2, ... , N}, we have 
which shows that V(a) is a Q-martingale. 
(b) By the first part and Problem 14.10, we have 
Repeating the above calculation gives 
EQ [Vn(a)] = EQ [Vo(a)] = Vo(a), 
because V0 (a) is a real number. 
This completes the proof. 
41.3. 
Since Sis arbitrage-free, it follows from Theorem 41.1 that there exists an 
equivalent martingale measure Q with numeraire Y. Let V(a) and V(,B) be the 
normalized portfolios with respect to Y. By Problem 41.2, V(a) and V(,B) are 
Q-martingales. By the assumption that P{VN(a) = VN(,B)} = 1 and the fact 
that P "' Q, we have Q{VN(a) = VN(,B)} = 1. Hence we have for every n in 
{0, 1, ... , N}, 
Vn(a) = EQ [VN(a)lÂ§n] = EQ [VN(,B)IÂ§n] = Vn(,B) Q- a.s. 
Since P "' Q, we get 
Vn(a) = Vn(,B) P- a.s. 

SOLUTIONS 
571 
This completes the proof. 
41.4. 
(a) Let L = d2J be the Radon-Nikodym derivative. Then by the assumption and 
by Problem 14.20, we have 
(b) By the assumption and the first part, we have for every j = 0, 1, ... , d and every 
n = 0, 1, ... ,N, 
Then by Problem 14.1 0, we have 
This finishes the proof. 
41.5. Let a E A _X. Then we have 
EQx [ EQx [ ~ 
lffn ]lffn-1] 
EQx [ ~ 
lffn-1] 
sUl 
n-1 
Xn-1. 
VN(a):::; X P- a.s. 
By Problems 14.5 and 14.6, we have 
Vn(a) = EQ [VN(a)lffn] :::; EQ [~ lffn]. 

572 
DISCRETE-TIME MODELS 
Since a is arbitrary, we have 
Similarly, we can show that 
EQ [YXN lÂ§n] ~ inf V(a). 
<>EAj( 
This completes the proof. 
41.6. Let a, f3 E A be replicating portfolios of X. Then by Problem 41.3, we have 
Vn(a) = Vn(f3) P- a.s., 
n = 0, 1, ... , N. 
In addition, we have a E Ax n A!-. It follows from Problem 41.5 that 
E 
[~~~ ] = Vn(a) 
Q Y 
n 
Y: 
N 
n 
for every equivalent martingale measure Q with numeraire Y. This completes the 
proof. 
41.7. Let n E {1, 2, ... , N}. Since 
Sn 
( S~1 l, 8~2 ), ... , 8~d)) 
( 8~1_2 1 (1 + 11~1 l), 8~2 l (1 + 11~2l), ... , 8~d) (1 + 11~dl)) , 
we can write f(8n) = cp(8n_1, fJn) for some function cp. By assumption that p 1, 
fJ2, ... , fJN are independent, fJn is independent of Â§n-1Â· Since 8n-1 is Â§n-1-
measurable, it follows from Problem 14.13 that 
where g(s) = E[cp(s, fJn)]. Similarly, we have 
Combining the above two equations gives 
This completes the proof. 
41.8. 

SOLUTIONS 
573 
(a) If Q is a equivalent martingale measure with numeraire { SA0) : n = 0, 1, ... , 
N}, then by Definition 41.8 we have 
n= 1,2, ... ,N. 
Since 8~0) = (1 + r-)" and S~1 l = S~ll 1 (1 + J-Ln), the above equation gives 
Since S~1~ 1 > 0, we have 
Let q = Q(1 + tLn = ulÂ§n-dÂ· Then by Problem 14.19 we get 
1 + T = lLq + d(1 - q), 
which gives a unique solution q = 
1 ~~dd. Hence we have 
Q{1 + f-Ln = u} = EQ[Q(1 + f-Ln = ul.~n-d] = q. 
(b) Let En E u(fLn) for n = 1,2, ... ,N. Since u(!Ln) = {0,{1 + f-Ln 
IL }, {1 + fLn = d}, rl}, by the proof of part (a) we know that EQ [len lÂ§n-1] = 
Q(EnlÂ·~n-d = Q(En) is a constant for all n = 1, 2, ... , N. Therefore by 
Problem 14.10 we have 
EQ[IE,h2 .. Â·leN] 
EQ(EQ[leJE2 â¢ â¢ Â·hNIÂ§N-l]) 
EQ(hJE2 ... leN-1 EQ[IEN 1-~N-1]) 
EQ(hJE2 ... hN-l)EQ[hN 1-~N-1] 
Q(EN )EQ(hJE2 ... IEN~l). 
Repeating the above calculation gives 
Hence J-L1, J-L2 , ... , /-LN are Q-independent. 
Â· 
(1) 
(1) Tin ( 
) 
(1) 
Smce Sn = S0 
i= 1 1 + J-L; and S0 > 0, we have 
Since tL1, J-L2 , ... , J-LN are Q-independent and identically distributed, we have 

574 
DISCRETE-TIME MODELS 
(c) By part (b) and Problem 41.7, we have 
By Problem 14.13, we have 
where 
g(x) = Eq[cp(x(1 + /Ln))] = qcp(ux) + (1- q)cp(dx). 
This completes the proof. 
41.9. By the definition of H, His adapted to the filtration and 
for all n = 0, 1, ... , N- 1. Hence fi is a Q-supermartingale. Also by the definition 
of fi, we have 
fin ::::: Xn, 
n = 0, 1, ... 'N. 
Now let Y = {Yn : n = 0, 1, ... , N} be a Q-supermartingale such that 
Yn ::::: Xn, 
n = 0, 1, ... 'N. 
fin-1 
max{Xn-1, Eq[finlÂ§n-1]} 
Therefore, we have 
< max{Xn-1, Eq[YnlÂ§n-1]} 
< max{Xn-1, Yn-d 
< Yn-1Â· 
fin :S Yn, 
n = 0, 1, ... , N. 
Thus fi is the smallest Q-supermartingale that dominates X. This completes the 
proof. 
41.10. Let o: E AxÂ· Then by Definition 41.14, there exists an exercise strategy v0 
such that 
Since P rv Q, we have 
V,0 (o:):<::;X,0 
Q-a.s. 
Then by Theorem 23.1 and Problem 41.2, we get 

SOLUTIONS 
575 
Since a is arbitrary, we have 
sup Vo(a) :S sup Eq[Xv]Â· 
aEA)( 
vETo 
Now let a EAt. Then by Definition 41.14 and the equivalence of P and Q, we 
have 
Vn(a) 2 Xn Q-a.s., n=O,l, ... ,N. 
Hence for every v E At, we have 
Vv(a) 2 Xv Q- a.s., 
which gives 
Vo(a) = Eq[Vv(a)] 2 Eq[Xv]Â· 
Since the above inequality holds for every v E At, we have 
Vo(a) 2 sup Eq[Xv]Â· 
vETo 
Since a is arbitrary, we get 
inf Vo(a) 2 sup Eq[Xv]Â· 
aEAk 
vETo 
This completes the proof. 
41.11. 
Let fi be the stochastic process as defined in Problem 41.9. Since fi is 
a supermartingale, - fi is a submartingale. Then by Problem 22.11, there exist a 
Q-martingale M and an increasing predictable process A with A0 = 0 such that 
-Hn=Mn+An, n=O,l, ... ,N 
or 
Hn=-Mn-An, 
n=O,l, ... ,N. 
By the assumption that the market is complete, there exists a replicating portfolio a 0 
for the European derivative - Y N M N. Then we have 
T-r 
( 
) _ VN(ao) _ 
M 
VN ao -
--
N 
YN 
and 
Vn(ao) = Eq[VNiffn] = -Eq[MNiffn] = -Mn 2 Hn 2 Xn 
for all n = 0, 1, ... , N. In addition, since A0 = 0, we have flo = V0(a0 ). There-
fore, 
ao EAt. 
Let v0 be a random variable defined by 
vo(w) = min{n E {0, 1, ... 'N}: Hn(w) = Xn(w)}, 
wEn. 

576 
DISCRETE-TIME MODELS 
For every n E {0, 1, ... , N}, since 
v0 is a stopping time. By the definition of fl, we have 
By the proof of Problem 22.11, we have 
n-1 
Mn =-fin- 2)Eq[flk+liffk]- flk)Â· 
k=O 
Hence we have 
Therefore, 
Hence 
ao E AxÂ· 
In addition, by Theorem 23.1 we have 
Now we show that v0 is an optimal exercise strategy. In fact, by Problem 41.10 
and the fact that ao EAt n Ax, we get 
Vo(ao) = sup Eq[Xv]Â· 
vETo 
This completes the proof. 
41.5 
Bibliographic Notes 
In this chapter, we presented discrete-time models and how European derivatives and 
American derivatives are priced. For proofs of the fundamental theorems of asset 
pricing (Theorems 41.1 and 41.2), readers are referred to Pascucci (2011, pp31-34). 
The binomial model was introduced by Cox et al. ( 1979). Hoek and Elliott (2006) 
is a textbook on binomial models. Pliska ( 1997) and Shreve (2005) are two textbooks 
devoted to discrete-time models. Follmer and Schied (2004) introduced discrete-time 
probabilistic methods in finance at the graduate level. Discrete-time financial mod-
els are also studied in Lamberton and Lapeyre ( 1996), Kallianpur and Karandikar 
(1999), Capinski and Zastawniak (2003), Franke et al. (2004), Bhar and Hamori 
(2005), Elliott and Kopp (2005), Dokuchaev (2007), Dana and Jeanblanc (2007), 

BIBLIOGRAPHIC NOTES 
577 
and Bjork (2009). Borak et al. (2010) presented many exercises related to binomial 
models. 
For numerical implementation of binomial models, readers are referred to James 
(2003), Higham (2004), Brandimarte (2006), and Rouah and Vainberg (2007). As the 
number of time steps increases, the binomial price of an European option converges 
to the Black-Scholes price (Follmer and Schied, 2004). 


CHAPTER42 
BLACK-SCHOLES OPTION PRICING 
MODELS 
The Black-Scholes model for pricing stock options is a revolutionary result in math-
ematical finance. Many of the pricing techniques and models used today in finance 
are rooted in the methods and ideas from the Black-Scholes model. In this chapter, 
we present the Black-Scholes model and relevant results. 
42.1 
Basic Concepts and Facts 
Definition 42.1 (Continuous Market). Let {(B~l), B?), ... , B~n)) : 0 :S: t :S: T} 
be an n-dimensional Brownian motion on some filtered probability space (0, ~. 
{ ~t : 0 :S: t :S: T}, P). Let { r t : 0 :S: t :S: T} be an adapted interest rate process. A 
continuous market is a (d +I)-dimensional stochastic process 
where 
-
{( (0) 
(1) 
(d)) . 
} 
s -
st , st , ... , st 
. o :s: t :s: r , 
n 
s~i) = ai(t)S~i)dt + s~i) L Uij(t)dB~j)' 
i = 1, 2, ... 'd, 
j=l 
Measure, Probability, and Mathematical Finance. 
579 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

580 
BLACK-SCHOLES OPTION PRICING MODELS 
and 
5}0 ) = exp (fat r,du) . 
Herethemeanrateofretumvector{(o:1(t),o:2 (t), ... ,o:d(t)): 0::; t::; T}and 
the volatility matrix { ( CTij (t) )i=l,2, ... ,d;j=l,2, ... ,n : 0 ::; t ::; T} are also adapted 
processes. 
Definition 42.2 (Black-Scholes Market). Let {Bt : t ;:::: 0} be a Brownian motion 
on some probability space (0, Â§, P) and let { Â§t : t ;:::: 0} be its natural filtration. 
A market is an Â§radapted two-dimensional Ito process { (Xi0 ), Xt) : 0 ::; t ::; T}, 
where X(o) is the price of a riskless asset given by 
and Xt is the price of a risky asset given by 
Here r, f-L, and cr are constants. 
Definition 42.3 (Portfolio). A portfolio in the Black-Scholes market {(X}0 , Xt) 
0 ::; t ::; T} is an two-dimensional, jointly measurable (with respect tot and w), and 
.~t-adapted stochastic process 
The value at time t of the portfolio is defined as 
A portfolio is also referred to as a trading strategy. 
Definition 42.4 (Normalized Black-Scholes Market). Let { (X}0l, Xt) : 0 ::; t ::; 
T} be a Black-Scholes market given in Definition 42.2. Then X 1(o) = ert. The 
normalized Black-Scholes market is the process given by { (1, X1 ) : 0 ::; t ::; T}, 
where Xt = e-rt Xt. 
The value at timet of a portfolioÂ¢ = { ( eio), Bt) : 0 ::; t ::; T} for the normalized 
market is given by 
Definition 42.5 (Self-Financing Portfolio). A portfolioÂ¢ = { ( 8~ 0 ), 81 ) : 0 ::; t ::; T} 
is said to be self-financing if it satisfies the following properties: 
(a) 

BASIC CONCEPTS AND FACTS 
581 
(b) For every t E [0, T], we have 
dvt(Â¢) = e~ 0)dXt(O) + BtdXt 
a.s., 
specifically, 
vt(Â¢)- Vo(Â¢) = lt B~0ldX,~0 l + lt BudXu 
a.s., 
where yt(<j>) = g~O) XIO) + BtXt. 
Definition 42.6 (Admissible Portfolio). A portfolio Â¢ = { ( e~o), B1) : 0 ::::; t ::::; T} is 
said to be admissible if it satisfies the following conditions: 
(a) Â¢is self-financing. 
(b) The value Vt ( Â¢) = e~o) + B1Xt is nonnegative for all t E [0, T] and 
sup Vt(Â¢) 
O~t~T 
is square-integrable under Q, where Q is the probability measure defined in 
Problem 37.7. 
Definition 42.7 (European Derivative). Let {.~1 : 0 ::::; t ::::; T} be the natural fil-
tration given in Definition 42.2. An European derivative h with maturity T is a 
ffr-measurable random variable such that hE LP(n, Â§, P) for some p > 1. 
Definition 42.8 (Replicable European Derivative). An European derivative h is said 
to be replicable if there is an admissible portfolio Â¢ such that 
h = Vr(Â¢), P- a.s., 
i.e., 
P{h = Vr(Â¢)} = 1. 
The admissible portfolio that replicates h is called a replicating portfolio for h. 
Definition 42.9 (Arbitrage). An admissible portfolioÂ¢ is called an arbitrage if the 
corresponding value process { vt ( Â¢) : 0 ::::; t ::::; T} satisfies 
(a) Vo(Â¢) = 0. 
(b) Vr(Â¢) ~ 0 a.s. 
(c) P{Vr(Â¢) > 0} > 0. 
Definition 42.10 (Risk-Neutral Measure). Let (n, Â§, {fft: 0::::; t::::; T},P) be 
the filtered probability space and S = { (S~o), sill, . .. , Sid)) : 0 ::::; t ::::; T} be the 
continuous market as defined in Definition 42.1. Let {yt : 0 ::::; t ::::; T} be a positive 

582 
BLACK-SCHOLES OPTION PRICING MODELS 
price process adapted to { Â§t : 0 ~ t ~ T}. A probability measure Q on (0, Â§)is 
said to be risk-neutral with respect to {yt : 0 ~ t ~ T} if 
(a) Q"' P, that is, Q and Pare equivalent. 
(b) under Q, the discounted price process 
_t_:O<t<T 
{ s<i) 
} 
yt 
-
-
is a martingale for every i = 0, 1, ... , d. 
The price process {yt : 0 ~ t ~ T} is called a numeraire. 
Theorem 42.1 (First Fundamental Theorem of Asset Pricing). Let S be a continuous 
market as defined in Definition 42.1. Then S is arbitrage-free if and only if there 
exists at least one risk-neutral measure. 
Theorem 42.2 (Second Fundamental Theorem of Asset Pricing). LetS be a contin-
uous market as defined in Definition 42.1. Suppose that S is arbitrage-free. Then 
Sis complete (see Definition 41.15) if and only ifthere exists a unique risk-neutral 
measure with numeraire { S~o) : n = 0, 1, ... , N}. 
Theorem 42.3 (Black-Scholar Option Price). Let { (X~o), Xt) : 0 ~ t ~ T} be the 
Black-Scholes market given in Definition 42.2. Let 
d _ In 2ft-+ (r + ~a 2 )(T- t) 
1 -
avT- t 
' 
(42.la) 
(42.lb) 
and 
(42.1c) 
Then the price at time t of a European call option that matures at time T with strike 
K is given by 
(42.2) 
and the price at time t of a European put option that matures at time T with strike 
K is given by 
(42.3) 
where db d2, N(Â·) are as defined in Equation (42.1). 

PROBLEMS 
583 
42.2 Problems 
42.1. Let { (Xt(o), Xt) : 0 :::; t :::; T} be a Black-Scholes market given in Defini-
tion 42.2. Let Â¢ = { ( Bi0 ), f1t) : 0 :::; t :::; T} be a portfolio for the market. Let 
Xt = e-rt Xt be the normalized price. Show that Â¢ is self-financing for market 
{ (Xio), Xt) : 0 :::; t :::; T} if and only if it is self-financing for the normalized 
market { (1, Xt) : 0 :::; t :::; T}. 
42.2. Let { (Xio), Xt) : 0 :::; t :::; T} be a Black-Scholes market given in Definition 
42.2. Let Â¢ = { ( Bio), Bt) : 0 :::; t :::; T} be an admissible portfolio for the market. 
Let Xt = e-rt Xt be the normalized price. Show that {Vt : 0 :::; t :::; T} is a square-
integrable martingale under Q, where Vt = oi0l + BtXt is the value at time t of 
the portfolio for the normalized market and Q is the probability measure defined in 
Problem 37.7. 
42.3 (No-Arbitrage Principle). Let Â¢ and 'ljJ be two admissible portfolios in the 
Black-Scholes market given in Definition 42.2. Suppose that Vr(cf>) = Vr('l/J), P-
a.s. For every t E [0, T], show that 
vt(Â¢) = vt('l/J), 
P- a.s. 
42.4. Let {Bt: 0:::; t:::; T}, {Â§t: 0:::; t:::; T}, and {(Xi0l,Xt): 0:::; t:::; T} 
be a Brownian motion, the natural filtration, and the Black-Scholes market given in 
Definition 42.2, respectively. Let {Wt : 0 :::; t :::; T} be a process defined by 
W -B 
(JL-r)t 
t-
t + 
' 
u 
t E [O,T]. 
Let Q be the probability measure under which {Wt : 0 :::; t :::; T} is a Brownian 
motion (see Problem 37.7). Let h be a nonnegative random variable that is Â§"r-
measurable and square-integrable under Q. Suppose that there are no arbitrages in 
the market. Show that 
(a) There exists an admissible portfolioÂ¢ = { ( oio), Bt) : 0 :::; t :::; T} such that for 
every t E [0, T], we have 
oiO) xi D) + BtXt = EQ [ e-r(T-t) hiÂ§t] ' 
where EQ denotes the expectation under the probability measure Q. 
(b) If the payoff of an European option that matures at time T is defined by h, then 
the value at time t of the option is given by 

584 
BLACK-SCHOLES OPTION PRICING MODELS 
42.5. Let { (X~o), Xt) : 0 :S t :S T} be the Black-Scholes market given in Definition 
42.2. Let h = f(Xr ), where f is a Borel function. Suppose that his nonnegative 
and square-integrable under Q, where Q is the probability measure given in Problem 
37.7. Show that the value at timet of an European derivative that matures at T with 
payoff his given by F(t, Xt), where 
Here {Wt : 0 :S t :S T} is the Q-Brownian motion given in Problem 37.7. 
42.6 (Black-Scholes Option Price). Let { (X~o), Xt) : 0 :S t :S T} be the Black-
Scholes market given in Definition 42.2. Let h be the payoff function of an European 
derivative that matures at T. Show that 
(a) If h = max{Xr - K, 0} be the payoff of a call option, then the call option 
value at time t is given by 
where 
d _ ln -if+ (r + ~a 2 )(T- t) 
1 -
a.../T- t 
' 
(42.4a) 
d2 = d1 - a.../T- t, 
(42.4b) 
and 
(42.4c) 
(b) If h = max { K - X T, 0} is the payoff of a put option, then the put option value 
at time t is given by 
where d1, d2, N(Â·) are as defined in Equation (42.4). 
42.7 (Put-Call Parity). Let { (Xt(o), Xt) : 0 :S t :S T} be the Black-Scholes market 
given in Definition 42.2. Let Ct and Pt be the values at time t of a European call 
option and a European put option, respectively. Suppose that both options mature at 
timeT and have a strike of K. Show that 
Ct - Pt = Xt - e-r(T-t) K. 
42.8 (Delta of European Options). Let { (Xt(o), Xt) : 0 :S t :S T} be the Black-
Scholes market given in Definition 42.2 and K > 0. Let Q be the probability mea-
sure and {Wt : 0 :S t :S T} the Q-Brownian motion given in Problem 37.7. Show 
that 

HINTS 
585 
(a) For any sequence { sn}n> 1 of nonzero real numbers such that sn ---+ 0 as n ---+ 
00, 
lim EQ[g(x + sn)]- EQ[g(x)] = EQ [lim g(x + sn)- g(x)] = N(dl), 
n--+oo 
Sn 
n--+oo 
Sn 
where 
g(x) = e-r(T-t) ( xe(r- !a2 )(T-t)+a(WT-w,) - K) + ' 
and d1 and N(Â·) are as defined in Equation (42.4); 
(b) The delta of a European call option that matures at T with strike K is 
act = N(d) 
8Xt 
1 ' 
where d1 and N(Â·) are as defined in Equation (42.4); 
(c) The delta of a European put option that matures at T with strike K is 
8Pt = N(d) -1 
8Xt 
1 
' 
where d1 and N(Â·) are as defined in Equation (42.4). 
42.3 Hints 
42.1. 
Note that X~o) = ert and use Ito's lemma (Theorem 35.3) to show that 
dVt(Â¢) = (itdXt. where Vt = e-rtVf. 
42.2. Use the result of Problem 33.7. 
42.3. Use the result of Problem 42.2 and note that P and Q are equivalent. 
42.4. Use the martingale representation theorem (Theorem 36.1) with 
to prove the first part. Use the first part and the result of Problem 42.3 to prove the 
second part. 
42.5. Use the results of Problems 38.7, 42.4, and 14.13. 
42.6. Apply the result of Problem 42.5. 
42.7. Use the result of Problem 42.6. 
42.8. 
To prove part (a), use the results of Problems9.9 and 9.10. Use part (a) to 
prove part (b). To prove part (c), use part (b) and the put-call parity (see Problem 
42.7). 

586 
BLACK-SCHOLES OPTION PRICING MODELS 
42.4 
Solutions 
42.1. Let Vi ( rp) be the value of the portfolio at time t. Then the value at time t of 
the portfolio for the normalized market is Vf(Â¢) = r;-rtv;(Â¢). 
First, let us prove the sufficiency ("if") part. Suppose that Â¢ is self-financing for 
the market { (X1(o), X 1 ) : 0 <::: t <::: T}. To show that Â¢ is self-financing for the 
normalized market, we only need to show that for every t E [0, T], we have 
(42.5) 
By Theorem 35.3, we get 
( 42.6) 
Similarly, we have 
(42.7) 
Since x/0 ) = e~' 1 and Â¢is self-financing for the market, we have vt ( rp) = eio) e~' 1 + 
81X 1 and dyt(Â¢) = 
rc~' 1 8;o) + 81dX1 a.s. Replacing Vi(Â¢) and dVi(Â¢) in Equation 
( 42. 7) gives 
(42.8) 
Combining Equation (42.6) and Equation (42.8) leads to Equation (42.5). 
Next, let us prove the necessity ("only if") part. Suppose that Â¢ is self-financing 
for the normalized market [i.e., Equation (42.5) holds]. Since yt(Â¢) = e~' 1 1it:(4J), we 
have 
dvt(d>) = re' 11it(Â¢) + e~' 1 d1it:(al) = ryt(Â¢) + c'181dX1. 
( 42.9) 
Combining Equations (42.6) and (42.9) gives 
ciVi(Â¢) = rVi(dl)- r8tXt + 8tdXt = 8~ 0 )dXI 0 ) + 8tdXt. 
Hence (/J is self-financing for {(XI0J, X1): 0 <::: t <::: T}. 
This finishes the proof. 
42.2. Since q) is self-financing for the Black-Scholes market, we have 
(42.1 0) 
Let {W1 : 0 <::: t <::: T} be the Brownian motion under Q that was defined in Problem 
37.7. Then dX1 = aX1dW1â¢ Hence from Equation (42.10), we have 
vt = Yo+ t 8saXsdWs, 
t E [0, T]. 
Jo 
By the assumption thatÂ¢ is admissible, snpo<t<T Vi is square-integrable. By Prob-
lem 33.7 and Theorem 32.1, "Vt is a square-inte-grable martingale. This finishes the 
proof. 

SOLUTIONS 
587 
42.3. By Problem 42.2, the value processes Vr ( Â¢) and Vr ( 1/J) are martingales under 
Q. Hence we have 
(42.11) 
and 
1/t('l/J) = EQ[Vr('l/J)Ifft], 
Q- a.s. 
(42.12) 
By the assumption, we have P{Vr(Â¢) -=/= Vr('l/J)} = 0. By Problem 37.7, P"' Q. 
Hence we have Q{Vr(Â¢)-=/= Vr('l/J)} = 0. Therefore, we have 
(42.13) 
Combining Equations ( 42.11 ), ( 42.12), and ( 42.13) gives 1ft ( Â¢) = 1ft ( 1/J ), Q-a.s. The 
result follows from the fact that Q and P are equivalent. This completes the proof. 
42.4. 
(a) Let {(1, Xt) : 0 :":: t :":: T} be the normalized market. By Problem 42.1, we 
only need to show that there exists an admissible portfolio cP = { ( 8~0), 8t) : 0 :":: 
t :":: T} such that for every t E [0, T], we get 
(42.14) 
To do that, let Mt = EQ [e-rThlfft]Â· Then {Mt : 0 :":: t :":: T} is a square-
integrable martingale adapted to the fft. Since { fft : 0 :":: t :":: T} is also 
the natural filtration of the Brownian motion {Wt : 0 :":: t :":: T} under Q, by 
Theorem 36.1, there exists an adapted process { Kt : 0 :":: t :":: T} such that 
and for every t E [0, T], we get 
(42.15) 
Now we define 
t E [O,T]. 
(42.16) 
Then we have 
which shows thatÂ¢ is self-financing. Since his square-integrable under Q, it 
follows from Problem 24.5 that supo<t<T 1/t(Â¢) is square-integrable under Q. 
Thus Â¢ is an admissible portfolio. 
- -

588 
BLACK-SCHOLES OPTION PRICING MODELS 
(b) Let Â¢ = { ( 0}0l, Bt) : 0 ~ t ~ T} be the admissible portfolio found in the first 
part. Since h is Â§r-measurable, by Problem 14.4, the value at time T of the 
portfolio is 
Vr(Â¢) = EQ[hlÂ§r] =h. 
Therefore, the portfolio Â¢ has the same payoff as the option at maturity. By 
Problem 42.3, the value at time t of the option is 
Vi(Â¢)= EQ [e-r(T-t)hlÂ§t] 
a.s. 
This completes the proof. 
42.5. By Problem 38.7 and the definition of Wt in Problem 37.7, we have 
X 
-X e(r-!u2)(T-t)+u(WT-Wt) 
T-
t 
, 
t E [O,T]. 
(42.17) 
Then by Problem 42.4 and Equation ( 42.17), we have 
EQ [ e-r(T-t) hlÂ§t] 
EQ [e-r(T-t) J ( Xte(r-!u 2)(T-t)+u(WT-Wt)) lÂ§t]. 
Note that Wr - Wt is independent of Â§t and that Xt is Â§t-measurable. It follows 
from Problem 14.13 that the value of the European derivative is F(t, Xt), where 
where 
F(t, x) = EQ [e-r(T-t) f ( xe(r-!u2)(T-t)+u(WT-Wt))]. 
This completes the proof. 
42.6. 
(a) If h = max{Xr- K, 0}, then 
F(t, Xt) = l e-r(T-t) ( Xte(r-!u2)(T-t)+u(WT-Wt) - K) dQ, (42.18) 
where A= {Xte(r-!u2 )(T-t)+u(WT-Wt) > K}. Let Z = 
WJ;_~'Â· Then 
Z rv N(O, 1), that is, Z is a standard normal random variable. After some 
algebraic calculation, we can get A = { Z > -d2 }, where d2 is as defined in 
Equation (42.4). Then from Equation (42.18) and the fact that N(d) = 1 -
N( -d) (see Problem 19.8), we have 
F(t, Xt) 
1
oo e-r(T-t) ( Xte(r-!u2)(T-t)+uv'T-ty - K) _l_e-:U: dy 
-d2 
~ 
(T t) 
100 
1 
(y-a,;'I=t)2 
-e-r -
KN(d2) + Xt 
--e-
2 
dy 
-d2 ~ 
XtN(di)- e-r(T-t) KN(d2). 

SOLUTIONS 
589 
(b) If h = max{K- Xr, 0}, then 
F(t, Xt) = l e-r(T-t) ( K- Xte(r-~a2)(T-t)+a(WT-Wt)) dQ, (42.19) 
where B = {Xte(r-~a 2 )(T-t)+a(WT-Wt) < K}. Similarly, we have B = 
{Z < -d2 } and 
F(t, Xt) 
1 -d2 e-r(T-t) ( K- Xte(r-~a2)(T-t)+ay"''=:ty) _l_e-~ dy 
-oo 
~ 
e-r(T-t) KN( -d2)- Xt 1-d2 _l_e- <u-av;=tl2 dy 
-oo ~ 
e-r(T-t) KN( -d2)- XtN( -dl). 
This completes the proof. 
42.7. By Problem 42.6, we have 
Ct- Pt 
XtN(dl)- Ke-r(T-t) N(d2)- Ke-r(T-t) N( -d2) + XtN( -d1) 
Xt(N(dl) + N( -d1))- Ke-r(T-t)(N(d2) + N( -d2)) 
Xt - e-r(T-t) K, 
where d1, d2 , N(Â·) are as defined in Equation (42.4). This completes the proof. 
42.8. 
(a) Let 
fn = g(x + sn)- g(x), n?:l. 
Sn 
Let A= {wEn: xe<r-~a 2 )(T-t)+a(WT(w)-W,(w)) > K} and B ={wEn: 
xe<r-~a 2 )(T-t)+a(WT(w)-W,(w)) < K}. Since 
we have 
l. 
f _ 8g(x) _ {0, 
ifw E B; 
Ill n- ---
1 
2 
n-+oo 
ax 
e-2(7 (T-t)+a(WT-Wtl, 
ifw E A, 
EQ [lim fn] 
n-+oo 
i e-~a2 (T-t)+a(WT-Wt)dQ 
N(d1). 
Now we show that 
lim EQ[fn] = EQ [lim fn]. 
n---+oo 
n--+oo 
(42.20) 
(42.21) 

590 
BLACK-SCHOLES OPTION PRICING MODELS 
To do that, let 
An= {wEn: (x + sn)e(r-~o-2)(T-t)+o-(WT(w)-W,(w)) > K}. 
On the event An n A, we have 
On the event A~ n Ac, we have lfnl2 = 0. On the event Ann Ac, we have 
and 
which give us 
Hence on the event An n A c we have 
lfnl2 =I g(x + sn) 12 < 4e-o-2(T-t)+2o-(WT-Wt). 
Sn 
Similarly, on the event A~ n A we have 
Combining the above estimations gives 
i lfnl2dQ 
innA lfnl2dQ + innAr lfnl2dQ + i;;nA lfnl2dQ 
+ i;,nNâ¢Ifnl 2dQ 
< 
6 i e-o- 2 (T-t)+2o-(WT-Wt)dQ 
6eo-2(T-t) 
< 
00. 
It follows from Problem 9.9 that {fn}n~l is uniformly integrable. Hence Equa-
tion (42.21) follows immediately from Problem 9.10. 

BIBLIOGRAPHIC NOTES 
591 
(b) By Problem 42.5 and part (a), we have 
(c) By part (b) and Problem 42.7, we have 
This completes the proof. 
42.5 
Bibliographic Notes 
In this chapter, we presented the Black-Scholes option pricing model, which was 
first discovered by Fischer Black and Myron Scholes (Black and Scholes, 1973) and 
further developed by Robert Merton (Merton, 1973). There are several approaches 
to deriving the model (Andreasen et al., 1998). 
The Black-Scholes model is discussed in many books such as Merton (1990), 
Wilmott et al. (1995), Lamberton and Lapeyre (1996), Shiryaev (1999), Ross (1999), 
Neftci (2000), Duffie (2001), Karatzas and Shreve (2001), Etheridge (2002), Steele 
(2003), Shreve (2004), Bingham and Kiesel (2004), Dineen (2005), Jiang (2005), 
Elliott and Kopp (2005), Back (2005), Klebaner (2005), Musiela and Rutkowski 
(2005), Bjork (2009), and Pascucci (2011), to name only a few. 
The option pricing models presented in this chapter are based on one risky as-
set, whose price follows a geometric Brownian motion. Cherubini et al. (2004) and 
Allen (2007) discussed models based on two risky assets. Jondeau et al. (2007) 
discussed option pricing under non-Gaussian distributions. Delbaen and Schacher-
mayer (2006) presented the mathematics of arbitrage and several original papers on 
asset pricing. Back et al. (2004) introduced models for incomplete markets, where 
European options may not be replicable. Katz and McCormick (2005) presented 
other models (e.g., neural networks) for option pricing. 
Smith (1976) presented a comprehensive discussion of the analytic properties of 
the option pricing functions. Hobson (2004) is a survey paper on mathematical fi-
nance. For introduction to various financial derivatives, readers can consult Kolb 
(1993), Wilmott et al. (1995), Houthakker and Williamson (1996), Hull (2001), 
Wilmott (2001), Eales and Choudhry (2003), Franke et al. (2004), Back (2005), Mc-
Donald (2005), Wilmott (2006), Kwok (2008), Neftci (2008), and Hull (2008). 
Theorems 42.1 and 42.2 are the two fundamental asset pricing theorems for continuous-
time markets. For proofs of these theorems, readers are referred to Shreve (2004, 
Section 5.4). 


CHAPTER43 
PATH-DEPENDENT OPTIONS 
Path-dependent options are also referred to as "exotic options", whose payoffs de-
pend on the path of the underlying asset. In this chapter, we present pricing formulas 
for some path-dependent options within the Black-Scholes framework. 
43.1 
Basic Concepts and Facts 
Theorem 43.1 (European Barrier Option Price). Let { (Xi0 ), Xt) : 0 :::; t :::; T} be 
the Black-Scholes market given in Definition 42.2. Let 
A(Â¢)= Â¢SN(Â¢xl)- Â¢Ke-rr N(Â¢x1- Â¢aVT), 
(43.la) 
(43.lb) 
(H):;;: 
(H) ;;;- 1 
C(ry, Â¢) = Â¢H S 
N(ryy1)-Â¢Ke-rT S 
N(TJYl-ryaVT), (43.lc) 
Measure, Probability, and Mathematical Finance. 
593 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

594 
PATH-DEPENDENT OPTIONS 
and 
where S = X 0 is the initial price of the risky asset, K is the strike, Tis the expiration 
time, H is the barrier, N ( Â·) is as defined in Equation ( 42.1 c), and 
In fi + (r + la2)T 
X 
_ 
K 
2 
1 -
aVT 
' 
ln lJt + (r + ~a 2 )T 
X2 = 
aVT 
' 
In !i + (r + la2)T 
Y -
s 
2 
2 -
aVT 
. 
Then 
(a) If S > H and the payoff of a down -and-in call is 
{ max(Xr- K, 0), 
ifmino::;t::;r Xt ::; H; 
0, 
if otherwise, 
then the price at time 0 of the down-and-in call is 
d 
(43.2) 
C . _ {C(1, 1), 
if K ?_ H; 
' -
A(1)- B(1) + D(1, 1), 
if K <H. 
(b) If S < Hand the payoff of an up-and-in call is 
{ max(Xr- K, 0), 
ifmaxo::;t::;T Xt ?_ H; 
0, 
if otherwise, 
then the price at time 0 of the up-and-in call is 
C . _ {A(1), 
if K ?_ H; 
m-
B(1)-C(-1,1)+D(-1,1), ifK<H. 
(43.3) 
(c) If S > H and the payoff of a down-and-in put is 
{ max(K- Xr, 0), 
ifmino::;t::;r Xt ::; H; 
0, 
if otherwise, 
then the price at time 0 of the down-and-in put is 
p. _ {B( -1)- C(1, -1) + D(1, -1), if K ?_ H; 
d,-
A( -1), 
if K <H. 
(43.4) 

BASIC CONCEPTS AND FACTS 
595 
(d) If S < H and the payoff of an up-and-in put is 
{ max(K- Xr, 0), 
ifmaxo~t~T Xt ~ H; 
0, 
if otherwise, 
then the price at time 0 of the up-and-in put is 
P . _{A( -1)- B( -1) + D( -1, -1), if K ~ H; 
uz-
C(-1,-1), 
ifK<H. 
(e) If S > H and the payoff of a down-and-out call is 
{ max(Xr - K, 0), 
ifmino~t~T Xt > H; 
0, 
if otherwise, 
then the price at time 0 of the down-and-out call is 
C 
_ {A(1)- C(1, 1), 
ifK ~ H; 
do-
B(1)- D(1, 1), 
({ K <H. 
(f) If S < H and the payoff of an up-and-out call is 
{ max(Xr - K, 0), 
ifmaxo~t~T Xt < H; 
0, 
if otherwise, 
then the price at time 0 of the up-and-out call is 
{ 0, 
ifK~H; 
Guo= A(1)-B(1)+C(-1,1)-D(-1,1), ifK<H. 
(g) If S > H and the payoff of a down-and-out put is 
{ max(K- Xr, 0), 
ifmino9~T Xt > H; 
0, 
if otherwise, 
then the price at time 0 of the down-and-out put is 
P 
_ {A( -1)- B( -1) + C(1, -1)- D(1, -1), if K ~ H; 
do-
0, 
if K <H. 
(h) If S < Hand the payoff of a up-and-out put is 
{ max(K- Xr, 0), 
ifmaxo~t~T Xt < H; 
0, 
if otherwise, 
(43.5) 
( 43.6) 
(43.7) 
(43.8) 

596 
PATH-DEPENDENT OPTIONS 
then the price at time 0 of the up-and-out put is 
Puo = { B(-1)-D(-1,-1), ifK?_H; 
A(-1)-C(-1,-1), ifK<H. 
Theorem 43.2 (Floating-Strike Lookback European Option Price). Let 
{(Xi0l,xt): o:::; t:::; T} 
be the Black-Scholes market given in Definition 42.2. Let 
(a) The payoff of a floating-strike lookback European call option is given by 
max(Xr- Lr, 0) = Xr- Lr. 
(43.9) 
The value at time t ( 0 :::; t < T) of the floating -strike lookback European call 
option is 
cfloating(t) 
a2 
XtN(al)- Lte-r(T-t) N(a2)- Xt-N( -a1) 
2r 
+ Xte-r(T-t) a2 ( Xt)- ~ N (-al + 2r VT- t) , (43.10) 
2r 
Lt 
a 
where N(Â·) is as defined in Equation (42.1c) and 
In i;- + (r + ; 2 )(T- t) 
a1 = 
a2 = a1 - aVT - t. 
a>/T-t 
' 
(b) The payoff of a floating-strike lookback European put option is given by 
max(Hr - Xr, 0) = Hr - Xr. 
The value at time t (0 :::; t < T) of the floating-strike lookback European put 
option is 
Pjloating(t) 
a2 
Hte-r(T-t) N( -b2)- XtN( -b1) + Xt-N(bi) 
2r 
-Xte-r(T-t)a2 (Xt)-~ N (b1- 2r VT- t), (43.11) 
2r 
Ht 
a 
where N ( Â·) is as defined in Equation ( 42.1c) and 
b _ In~+ (r + ~ )(T- t) 
1 -
a>/T- t 
' 

BASIC CONCEPTS AND FACTS 
597 
Theorem 43.3 (Fixed-Strike Lookback Option Price). l.Rt {(X~0 ), Xt) : 0 :-:; t :-:; 
T} be the Black-Scholes market given in Definition 42.2. Let 
Let K be the strike and 
ln.&+ (r+ u 2 )(T-t) 
d1 -
K 
2 
d2 = d1 - a.JT - t. 
-
a.JT- t 
' 
(a) The payoff of a fixed-strike lookback European call option is given by 
max(Hr- K, 0). 
When K > Ht. the value at time t (0 :-:; t < T) of the fixed-strike lookback 
European call option is 
(43.12) 
where N(Â·) is as defined in Equation (42.1c). 
When K :-:; Ht, the value at timet (0 :-:; t < T) of the fixed-strike lookback 
European call option is 
(43.13) 
where N(Â·) is as defined in Equation (42.1c) and 
ln ~ + (r + ';
2 )(T- t) 
e1 = 
e2 = e1 - a.JT- t. 
a.JT- t 
' 
(b) The payoff of a fixed-strike lookback European put option is given by 
max(K- Lr, 0). 

598 
PATH-DEPENDENT OPTIONS 
When K < L 1, the value at time t (0 ::; t < T) of the fixed-strike lookhack 
European put option is 
where N ( Â·) is as defined in Equation ( 42.1 c). 
When K 2: L 1, the value at time t (0 ::; t < T) of thefixed-strike lookhack 
European put option is 
(43.15) 
where N ( Â·) is as defined in Equation (42.1 c) and 
lnx' +(r-+cr 2 )(T-t) 
fl = 
L, 
2 
h = .fi- (TJT- t. 
(TJT- t 
43.2 
Problems 
43.1. Let { B 1 : 0 ::; t ::; T} be a Brownian motion on a probability space (n, ,ry;, P). 
Let {HT1 : 0 ::; t ::; T} be defined as 
where a E R. Let !vfr = maxo<:;t<:;T H/1. Show that under P, the joint density of 
the pair (Mr. Wy) is 
. 
2(2:r-y) 
( 
1 2 
1 
2 ) 
fMr.WT (:r:, y) = TJ27(i exp ny- 2n T- 2T (2x- y) 
, 
:tJ::; X, :1: 2: 0, 
and is zero for other values of .T and y. 
43.2. Let { B 1 : 0::; t::; T} be a Brownian motion on a probability space (fl . . r, P). 
Let {W1 : 0 ::; t ::; T} be defined as 
W 1 = od + B 1 . 
0 ::; t ::; T. 

PROBLEMS 
599 
where a E R. Let Lr = mino::;t::;T Wt. Show that under P, the joint density of the 
pair (Lr, Wr) is 
-2(2x-y) 
( 
1 2 
1 
2) 
hr,Wr(x, y) = 
T-J21rf exp ay- 2a T- 2T(2x- y) 
, 
y ~ x,x::::: 0, 
and is zero for other values of x andy. 
43.3. Let { Bt : 0 :::; t :::; T} be a Brownian motion on a probability space (0, Â§, P). 
Let Mr be a random variable defined as 
Mr= max (at+Bt), 
O:S;t:S;T 
where a E R. Let N(Â·) be the function defined in Problem 19.8. Show that 
(a) 
P{Mr:::::x}=N(x~T) -e2axN(-x:?raT), 
x~O. 
(b) The density under P of the random variable Mr is 
() 
2 
( 
1 ( 
)2) 
2ax 
(-x-aT) 
fMr x = -J27rT exp - 2T x- aT 
- 2ae 
N 
VT 
for x ~ 0 and is zero for x < 0. 
43.4 (Down-and-In European Call Price). Let { (Xi0l, Xt) : 0 ::::: t :::; T} be the 
Black-Scholes market given in Definition 42.2. Let S = X 0 be the initial price 
of the risky asset and H a barrier such that H < S. Suppose that a down-and-in 
European call option has the following payoff function: 
{ max(Xr- K,O), 
ifmino::;t::;rXt::::: H; 
0, 
if otherwise, 
where T is the maturity time and K is the strike. Show that the time-zero price of 
the down-and-in European call option is given by 
C . _ {C(1, 1), 
dt-
A(1)- B(1) + D(1, 1), 
if K ~ H; 
if K < H, 
where A, B, C, and Dare defined in Equation (43.1). 
43.5 (Up-and-Out European Call Price). Let {(Xi0l, Xt) : 0 :::; t :::; T} be the 
Black-Scholes market given in Definition 42.2. Let S = X 0 be the initial price of 
the risky asset and H be a barrier such that H > S. Suppose that an up-and-out 
European call option has the following payoff function: 
{ max(Xr- K, 0), 
0, 
if maxo::;t::;r Xt < H; 
if otherwise, 

600 
PATH-DEPENDENT OPTIONS 
where T is the maturity time and K is the strike. Show that the time-zero price of 
the up-and-out European call option is given by 
{ 0. 
Guo= A(l)- B(l) + C(-1, 1)- D(-1, 1), 
if K 2: H; 
if K < H, 
where A, B, C, and Dare as defined in Equation (43.1). 
43.6 (Floating-Strike Lookback European Put Price). Let { (Xt(o), Xt) : 0 :::; t :::; T} 
be the Black-Scholes market given in Definition 42.2. Let 
Ht = max Xu, 
0:::; t:::; T. 
o:c;u:c;t 
A standard floating-strike lookback European put option has the following payoff 
function: 
max(Hr - Xr, 0) = Hr - Xr. 
Show that the value at timet (0 :::; t < T) of the floating-strike lookback European 
put option is given by 
Pjloating(t) 
-Xte-r(T-t) 0"2 (Xt) -~ N (h- 2r vT- t)' 
2T 
Ht 
0" 
where N (-) is as defined in Equation ( 42.lc) and 
b _In~; +(r-+ u2
2 )(T-t) 
1 -
b2 = b1 - O"VT - t. 
O"VT-t 
' 
43.3 
Hints 
43.1. 
First use the Girsanov Theorem I (see Problem 37.4) to find a probability 
measure Q such that {Wt : 0 :::; t :::; T} is a Brownian motion under Q. Then use 
the result of Problem 28.16. 
43.2. Apply the result of Problem 43.1 and note that the two processes {at + Bt : 
t 2: 0} and {at- Bt : t 2: 0} have the same distribution. 
43.3. To prove the first part, use the result of Problem 43.1 and the fact that 
P{Mr:::; x} 
r1z fMr,Wr(z,y)dydz 
Jo 
-CXJ 
1x1z 
1x10 
fi..,fr,Wr (z, y)dydz + 
flvfr,Wr (z, y)dydz 
0 
0 
0 
-CXJ 
r 
r fMr,Wr(z,y)dzdy+1Â° 
r fMr,Wr(z,y)dzdy 
Jo 19 
-CX) Jo 

SOLUTIONS 
601 
Use the first part to prove the second part. 
43.4. Apply the results of Problems 42.4, 43.2, and 19.9. 
43.5. Apply the results of Problems 42.4, 43.1, and 19.9. 
43.6. Use the results of Problems 42.4, 14.15, 14.13, and 43.3. 
43.4 Solutions 
43.1. Let Q be a probability measure on (0, ff) defined as 
dQ = ZTdP, 
where 
Zt = exp ( -aBt- ~a2t) = exp ( -aWt + ~a2t), 0 ::; t ::; T. 
Then it follows from Problem 37.4 that {Wt : 0 ::; t ::; T} is a Brownian motion 
under Q. Then by Problem 28.16, the joint density of(MT, WT) under Q is 
2(2x- y) 
( 
(2x- y) 2 ) 
9MT,wT(x, y) = Tv'2i(f exp -
2T 
' 
and is zero for other values of x and y. Therefore, we have 
P{MT::; x, WT ::; y} 
In I{MT::;x,wT::;y}dP 
In ;T I{MT::;x,wT::;Y}dQ 
y::; X, X> 0 
J
x Jy 
av-la2 T 
( 
) 
-oo -oo e 
2 
9MT,WT u, v dvdu. 
Differentiating the above equation with respect to x and y gives the following joint 
density of (MT, WT) under P: 
This completes the proof. 
43.2. Let x ::; 0 andy 2: x. Then we have 
P{LT::; x, WT::; y} = j_xoo j_Yoo hT,wT(r, s)dsdr. 
(43.16) 

602 
PATH-DEPENDENT OPTIONS 
Since {-at- Bt : t 2 0} and {-at+ Bt : t 2 0} have the same distribution, we 
have 
P{Lr :S: x, Wr :S: y} 
P{ -Lr 2 -x, -Wr 2 -y} 
P { max (-at - Bt) 2 -x -aT- Br 2 -y} 
O$t$T 
' 
P{ max (-at+Bt) 2 -x,-aT+Br 2 -y}. 
O$t$T 
(43.17) 
But by Problem 43.1, we have 
P{ max (-at+Bt) 2 -x,-aT+Br 2 -y} 
0$t$T 
/
00 /
00 2(2r 
s) 
( 
(2r 
s) 2 
1 
) 
.;i;r exp -
---;, 
-as- -a2T 
dsdr.(43.18) 
-x -y T 
2 
2 
Combining Equations (43.16), (43.17), and (43.18) gives 
[xoo [Yoo hT,wT(r, s)dsdr 
f oo joo 2(2r- s) 
( 
(2r- s) 2 
1 2r) d d 
exp -
-as- -a 
s r. 
-x -y TV21ff' 
2T 
2 
Differentiating both sides of the above equation with respect to x and y gives the 
following joint density of ( Lr, W T) under P: 
-2(2x-y) 
( 
(2x-y) 2 
1 2 
) 
hT,wT(x, y) = 
TV21ff' exp -
2T 
+ ay- 2a T . 
This completes the proof. 
43.3. 
(a) By Problem 43.1 and Theorem 10.1, we have 
P{Mr :S: x} 
r fz !MT,WT (z, y)dydz 
Jo 
-oo 
r t !MT,WT(z,y)dydz+ r!O !MT,WT(z,y)dydz 
Jo Jo 
Jo 
-oo 
1x lux fMT,wT(z, y)dzdy 
+ [
0
00 1x fMT,wT(z, y)dzdy. 
(43.19) 

SOLUTIONS 
603 
Note that 
1x /MT,wT(z, w)dz 
1x 2(2z- w) exp (aw- !a2T- _!_(2z- w)2) dz 
v 
T .j'j;iT 
2 
2T 
1 
( 
1 2 1 
)2) IX 
---exp aw- -a - -(2z-w 
.j'j;iT 
2 
2T 
v 
-
1-
exp (aw- !a2 - _!_(2v- w)2)-
.j'j;iT 
2 
2T 
-
1-
exp (aw- !a2 - _!_(2x- w)2). 
.j'j;iT 
2 
2T 
(43.20) 
Combining Equations (43.19) and (43.20) gives 
P{Mr ~ x} = J
x 
1 
( 
1 2 
1 
2 ) 
-- exp ay - -a - -y dy-
- oo .j'j;iT 
2 
2T 
J
x 
1 
( 
1 2 
1 
2) 
--exp ay--a --(2x-y) 
dy 
-oo .j'j;iT 
2 
2T 
N (X -:;T) _ e2ax N ( -x :raT) . 
(b) Note that 
f 
( ) = dP{Mr ~ x} 
MT X 
dx 
. 
By the first part of this problem, we have 
.i_N (x- aT) _ .i_e2ax N (-x- aT) 
dx 
..fT 
dx 
..fT 
( 0 1 x- aT) _1_- 2ae2ax N (-x- aT) 
'P 
" 
..fT 
..fT 
..fT 
2ax (o 1 -x - aT) _1_ 
+e 
'P 
, , 
..fT 
..fT 
( 0 1 x - aT) ~ 
- 2ae2ax N ( -x - aT) 
'P 
" 
..fT 
..fT 
..fT 
2 
( 
1 ( 
T)2) 
2axN (-x- aT) 
--exp -- x-a 
-2ae 
.j'j;iT 
2T 
..fT 
' 
where 'P(O, 1, Â·)is defined in Equation (19.1). 
This completes the proof. 
43.4. Let Wt = 7t + Bt for 0 ~ t ~ T. Let Q be the risk neutral measure Q 
defined in Problem 37.7. Then {Wt : 0 ~ t ~ T} is a Brownian motion under Q. 

604 
PATH-DEPENDENT OPTIONS 
By Problem 42.4, the time-zero price of the down-and-in European call option is 
cdi = EQ [e-rT(Xr- K)+J{minoStsrX,~H}]. 
The stochastic differential equation of Xt can be written as 
Solving the above stochastic differential equation (see Problem 38.7) gives 
Xt = Sexp(aat+aWt) = Seaz,, 
0:::; t:::; T, 
where a= (r- ~a2 )/a and Zt =at+ Wt. Let Lr = mino9~T Zt. Then 
min Xt = seaLr. 
O~t~T 
Therefore, we can rewrite Equation (43.21) as 
cdi 
EQ [e-rT(Xr- K)I{Xr>K,Sexp(aLr)~H}] 
(43.21) 
EQ [e-rT(Sexp(aZr) -K)I{z >.!.InK L <.!.lnll.}J. (43.22) 
T 
CT 
S' T_CT 
s 
If K ~ H, then by Problem 43.2, we can calculate Equation (43.22) as follows: 
oo 
.!. In ll. 
Cdi = i InK[~ s e-rT (Seay- K) 
" 
s 
- 2(2x- y) exp (ay- ~a 2T- _!__(2x- y) 2 ) dxdy 
T..;2if' 
2 
2T 
1
00 
e-rT(SeaY-K) 
( 
1 2 
(~ln~-y) 2 ) 
----''-==,---=-exp ay- -a T-
dy . 
.!. In K 
..;2if' 
2 
2T 
" 
s 
It follows from Problem 19.9 that 
(H)5 
(H)5- 1 
Cdi 
= 
H S " N(y1)- Ke-rT S " 
N(y1- avT) = C(1, 1). 
Similarly, if K < H, we have 
{.!.In ll. Jy 
+ J l.~n Ks 
-CXJ e-rT (Seay- K) 
" 
s 
---2(-'-2=x=-=y'-'-) exp (ay- ~a2T- -1 (2x- y) 2 ) dxdy 
T..;2if' 
2 
2T 
A(1)- B(1) + D(1, 1). 

SOLUTIONS 
605 
This completes the proof. 
43.5. 
The proof is similar to that of Problem 43.4. Let Wt = 7t + Bt for 
0 ~ t ~ T and Q the risk-neutral measure Q defined in Problem 37.7. Then {Wt : 
0 ~ t ~ T} is a Brownian motion under Q. By Problem 42.4, the time-zero price of 
the up-and-out European call option is 
Guo= EQ [e-rT(Xr- K)+ l{max09 ~TXt<H}] Â· 
The stochastic differential equation of Xt can be written as 
Solving the above stochastic differential equation (see Problem 38.7) gives 
Xt = Sexp (aat + aWt) = Seo-z,, 
0 ~ t ~ T, 
(43.23) 
where a= (r- ~a2 )ja and Zt =at+ Wt. Let Mr = maxo:<S;t:S:T Zt. Then 
Hence, we can rewrite Equation (43.23) as 
Guo 
EQ [e-rT(Xr- K)J{XT>K,Sexp(o-MT)<H}] 
EQ [e-rT(S exp(aZr)- K)I{ZT>~ In ~,MT<~ In~}] .(43.24) 
If K 2: H, the up-and-out call option is knocked out before being in the money. 
Hence the payoff is zero and the option price is also zero. 
If K < H, then by Problem 43.1, we have 
Guo = 
{~In~ {~In~ e-rT (Seo-y - K) 
J ~In~ lmax(y,O) 
2(2x- y) exp (ay- ~a2T- _!_(2x- y) 2) dxdy 
TV2rrT 
2 
2T 
l
~ln~e-rT(Seo-y_K) 
( 
1
2 
(~lni-y) 2 ) 
-
exp ay - -a T -
dy 
.!. In K 
V2rrT 
2 
2T 
u 
s 
1
~ In~ e-rT (Seo-y - K) 
( 
1 2 y2) 
+ 
exp ay - -a T- -
dy . 
.!. In K 
V2rrT 
2 
2T 
u 
s 
By Problem 19.9, we have 
---'-===---'-exp ay- -a2T-
o-
8 
dy 
l
~ln ~ e-rT (Seo-y- K) 
( 
1 
(lin .H- y) 2 ) 
~ In ~ 
V2rrT 
2 
2T 
D( -1, 1)- G( -1, 1), 

606 
PATH-DEPENDENT OPTIONS 
and 
1
~ In i- e-rT (Seay - K) 
( 
1 2 
y2 ) 
---'--:::==------'- exp ay - -a T - -
dy 
1. In K 
.J2;T 
2 
2T 
" 
s 
A(1)- B(1). 
Hence we have 
Guo= A(1)- B(1) + C( -1, 1)- D( -1, 1). 
This completes the proof. 
43.6. Let Wt = 7 t + Bt for 0 :::; t :::; T and Q the risk neutral measure Q defined 
in Problem 37.7. Then {Wt : 0 :::; t :::; T} is a Brownian motion under Q. By 
Problem 42.4, the price at time t of the floating-strike lookback European put option 
is 
Pfloating(t) 
EQ [e-r(T-tl(Hr- Xr)l$t] 
e-r(T-t) (EQ [Hrl$t]- EQ [Xrl$t]). 
Since { e-rt Xt : 0 :::; t :::; T} is a Q-martingale, we have 
EQ [e-rTXrl$t] = e-rtxt. 
Hence we can write Equation (43.25) as 
Pfloating(t) = e-r(T-t) EQ [Hrl$t] - Xt. 
(43.25) 
(43.26) 
To compute EQ[Hrl$t]. we let a= (r- ~a 2 )/a and Zt =at+ Wt. Then we 
can write Xt as follows (see Problem 38.7): 
Xt = Xo exp (aat + aWt) = Xoeaz,, 
0 :::; t :::; T, 
Let Mt = maxo:S;u:S;t Zu fortE [0, T]. Then we have 
Since 
(43.27) 
Mr- Mt = [max Zu- Mt] + = [max (Zu- Zt)- (Mt- Zt)] + 
t:S;u:S;T 
t:S;u:S;T 
and 
we have 
1 
Ht 
Mt - Zt = - ln -, 
a 
Xt 
[ 
Ht] + 
a(Mr - Mt) = 
max a(Zu - Zt) - ln X 
t:S;u:S;T 
t 
(43.28) 

SOLUTIONS 
607 
Combining Equations (43027), (43o28), and (43026) gives 
EQ[HrlÂ§t] = EQ [Htexp ([t~~Ta(Zu- Zt) -ln ~:J+) lÂ§tlo 
Let V1 = maxt~u~ra(Zu - Zt) and V2 = ln ~0 Since Ht and V2 are Â§r 
measurable and V1 is independent of Â§t. it follows from Problems 14015 and 14013 
that 
(43029) 
where 
Since Zu- Zt = a(u- t) + Wu- Wt and Zu-t- Zo = a(u- t) + Wu-t have the 
same distribution under Q, maxt~u~T a(Zu- Zt) and maxo~u~T-t a(Zu- Zo) = 
aMr-t also have the same distribution under Qo Hence we can write <p(x) as 
<p(x) 
EQ[exp([aMr-t-xl+)] 
Q { Mr-t ::; ~} +e-x EQ [ e""MT-t I{MT-t>!}] 0 (43030) 
By Problem 4303, we have 
N (x- aa(T- t)) _ 
e2~., N (-x- aa(T-t)) 
avT- t 
avT- t 
N (x- (r- ~a 2 )(T- t)) 
avT-t 
-e 2r;2u2 x N (-X- (r- ~a2)(T-t))' 
avT- t 
(4331) 
and 
E 
[ o-MT-tf 
] 
Q e 
{MT-t>!} 
roo ay 
2 
( [y- a(T- t)]2) d 
}! e 
.J2rr(T- t) exp -
2(T- t) 
y 
- roo e""Y2ae2ay N ( -y- a(T- t)) dyo 
1! 
-vr -t 
(43o32) 
By Problem 1909, the first integral in Equation (43.32) can be written as 
roo ""Y 
2 
( [y- a(T- t)J2) d 
}! e 
y'2rr(T- t) exp -
2(T- t) 
y 
2er(T-t) N ( -x + (r + ~a2 ) (T- t)) 
0 
avT-t 
(43.33) 

608 
PATH-DEPENDENT OPTIONS 
By Problem 19.1 0, the second integral in Equation ( 43.32) can be calculated as 
f'XJ ecry2ae2ay N ( -y- a(T- t)) dy 
I;; 
vr-t 
_ (l- a 2 ) exp (2rx) N (-x- (r- ~a2 )(T- t)) 
2r 
a2 
a)T- t 
+ (1- a2) er(T-t) N ( -x + (r + ~a2)(T- t)) . 
(43.34) 
2r 
avT-t 
Then it follows from Equations (43.30)- (43.34) that 
N(x-(r-~a 2 )(T-t)) _ 
'P(x) 
a)T- t 
a 2 e ( ~ _ 1 )x N ( - x - ( r -
~ a 2 ) ( T - t) ) + 
2r 
a)T-t 
( 1 + a2) e-xer(T-t) N ( -x + (r + ~a2)(T- t)) . (43.35) 
2r 
a)T- t 
Now, combining Equations (43.26), (43.29), and (43.35) leads to 
Pfloating(t) 
This completes the proof. 
43.5 
Bibliographic Notes 
In this chapter, we presented some closed-form pricing formulas for certain path-
dependent options. The pricing formulas for the European barrier options were in-
troduced by Merton (1973), Rubinstein (1991), and Rubinstein and Reiner (1991). 
General versions of these formulas can be found in Haug (2006). 
Like the European barrier options, the lookback options also have closed form 
pricing formulas. The pricing formulas for floating-strike lookback options and 
fixed-strike lookback options were introduced by Goldman et al. (1979) and Conze 
and Viswanathan (1991), respectively. These formulas are also presented in Haug 
(2006). 
Asian options are also path-dependent options. But unlike the barrier options and 
lookback options, Asian options do not have closed form pricing formulas. The price 
of Asian options is obtained by solving partial differential equations numerically. For 
more details about Asian option pricing, readers are referred to Shreve (2004) and 
Haug (2006). 

CHAPTER44 
AMERICAN OPTIONS 
Unlike European options, American options can be exercised at any time up to and 
including the expiration date. This early exercise feature makes American options 
more difficult to price than European ones. In this chapter, we present risk-neutral 
pricing of American options. 
44.1 
Basic Concepts and Facts 
Definition 44.1 (Reward Function). A reward function is any function g: (0, oo) x 
[0, T] ---+ R that is continuous and satisfies the linear growth condition 
for some constants K 1 and K 2. 
Definition 44.2 (American Option). In a Black-Scholes market { (Xi0), Xt) : t ~ 
0}, an American option with reward function g and maturity T is a derivative that 
pays the amount g(Xt, t) when exercised at any timet E [0, T]. 
Measure, Probability, and Mathematical Finance. 
609 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

610 
AMERICAN OPTIONS 
The reward function for an American call option with strike K is g(Xt, t) 
( Xt ~ K) +. The reward function for an American put option with strike K is 
g(Xt,t) = (K ~ Xt)+. 
Definition 44.3 (Consumption Strategy). Let { (X}0l, Xt) : t 2: 0} be the Black-
Scholes market given in Definition 42.2. A consumption strategy is a stochastic 
process {At : 0 ::::; t ::::; T} satisfying the following conditions: 
(a) It is adapted to the underlying filtration {fft: 0::::; t::::; T}. 
(b) Almost all of its sample paths are nondecreasing and right-continuous with left-
hand limits. 
(c) A0 = 0 a.s. 
Definition 44.4 (Trading and Consumption Strategy). A trading and consumption 
strategy is a process ( Â¢, A) = { ( Bi0), Bt. At) : 0 ::::; t ::::; T}, where Â¢ = { ( B~o), Bt) : 
0 ::::; t ::::; T} is a trading strategy (see Definition 42.3) and A = {At : 0 ::::; t ::::; T} is 
a consumption strategy. 
Definition 44.5 (Self-Financing Trading and Consumption Strategy). In a Black-
Scholes market { ( X}0 ), Xt) : t 2: 0}, a trading and consumption strategy (Â¢,A) is 
said to be self-financing on [0, T] if it satisfies the following properties: 
(a) 
(b) For every t E [0, T], 
vt(Â¢, A)~ Vo(Â¢, A)= {t BS0lctXS0l + t BudXu ~At a.s., 
.fo 
.fo 
where Vt ( Â¢, A) is its wealth process defined as 
'tit E [O,T]. 
Definition 44.6 (Admissible Trading and Consumption Strategy). A trading and 
consumption strategy(Â¢, A) in a Black-Scholes market is said to be admissible if 
it is self-financing and 
EQ [for (BuXu) 2du l 
< oo, 
where Q is the risk-neutral measure defined in Problem 37.7. 
Definition 44.7 (Buy-and-Hold Strategy). Let To,r be the set of all stopping times 
of the underlying filtration { fft : 0 ::::; t ::::; T} that take values in [0, T] a.s. A buy-
and-hold strategy associated with an American option X(a) is a pair (c, T), where 

BASIC CONCEPTS AND FACTS 
611 
c E Rand T E To,r; that is, c units of the American option are bought (or sold if 
c < 0) at time 0 and held until timeT. 
Definition 44.8 (Extended Admissible Trading and Consumption Strategy). Let 
be a Black-Scholes market and xCa) an American option. An extended admissible 
trading and consumption strategy in the market is a collection ( Â¢, A, c, T) such that 
(a) (Â¢,A) is an admissible trading and consumption strategy in the Black-Scholes 
market. 
(b) (c, T) is a buy-and-hold strategy in xCa). 
(c) For any t E (T, T], we have 
e (O) -
e(O) 
e 
XT 
cg(XTl T) 
e 
t 
-
T + T 
(0) + 
(0) 
l 
t = 0, 
Xr 
Xr 
where g(Â·, Â·)is the reward function of the American option. 
(d) For any t E ( T, T], we have At = Ar. 
The set of all extended admissible trading and consumption strategies is denoted by 
d. Let do denote the set of strategies in d that satisfy the following conditions: 
(0) 
80 + BoXo + cUo < 0 
and 
8~) X~O) 2': 0, 
a.S. 
Definition 44.9 (Arbitrage). In a Black-Scholes market { (Xi0 ), Xt) : 0 :::; t :::; T} 
with trading in the American option X(a) with initial price U 0 , there is arbitrage if 
either 
(a) there is long arbitrage, that is, there exists a buy-and-hold strategy ( c, T) with 
c?: 0 such that for some trading and consumption strategy(Â¢, A), the strategy 
(Â¢,A, c, T) E do, or 
(b) there is short arbitrage, that is, there exists a trading and consumption strategy 
(Â¢,A) such that for any buy-and-hold strategy ( c, T) with c < 0, the strategy 
(Â¢,A, c, T) E do. 
Definition 44.10 (Essential Supremum). Let X be a nonempty family of nonnegative 
random variables defined on a probability space (0, Â§, P). The essential supremum 
of X, denoted by ess sup X, is a random variable X* satisfying the following condi-
tions: 
(a) For every X E X, X :::; X* a.s. 

612 
AMERICAN OPTIONS 
(b) If Y is a random variable such that X :S Y a.s. for all X E X, then X* :S Y 
a.s. 
Theorem 44.1 (Existence of Essential Supremum). Let X be a nonempty family of 
nonnegative random variables. Then 
(a) The essential supremum of X exists. 
(b) If X is closed under pairwise maximization (i.e., X, Y E X implies XV Y E 
X), then there exists a nondecreasing sequence {Zn}n;,::l of random variables 
in X such that 
ess sup X = lim Zn, 
a.s. 
n-+oo 
Theorem 44.2 (Snell Envelope). Let T E (0, oo]. Let { $t : 0 :S t :S T} be a 
right-continuous filtration such that $o contains only sets of probability zero or one, 
that$ oo = a(Uo<t<oo $t) ifT = oo, and that for every t E [0, T], $t contains the 
null sets of $r. Let {yt : 0 :S t :S T} be a nonnegative right-continuous stochastic 
process adapted to { $t : 0 :S t :S T} such that 
E [ sup yt] < oo. 
o:::;t:::;T 
Let { Ut : 0 :S t :S T} be a process defined as 
Ut = esssupE[Ypl$t], 
pE'Tt,T 
where Tt,r is the set of { $t : 0 :S t :S T}-stopping times with values in [t, T] a.s. 
Then 
(a) The process {Ut : 0 :S t :S T} is a supermartingale with respect to the filtration 
{ $t : 0 :S t :S T}. 
(b) For every t E [0, T], we have 
E[Ut] = sup E[Yp]Â· 
pE'Tt,T 
(c) The process {Ut : 0 :S t :S T} has a Cadtag (see Definition 21.4) modification, 
which is called the Snell envelope of {yt : 0 :S t :S T}. 
(d) The Snell envelope of {yt : 0 :S t :S T} is the smallest supermartingale that 
dominates {yt : 0 :S t :S T} (see Definition 2/./2). 
Theorem 44.3 (Optimal Stopping Time). LetT E (0, oo]. Let {yt : 0 :S t :S T} 
be a nonnegative stochastic process adapted to some filtration { $t : 0 :S t :S T}. 
Suppose that {yt : 0 :S t :S T} and { $t : 0 :S t :S T} satisfy the assumptions 
given in Theorem 44.2 and that almost all the sample paths of {yt : 0 :S t :S T} are 
continuous. Let 
p*(t) = inf{s E [t,T]: Us= Y8 }, 
t E [O,T], 

PROBLEMS 
613 
where {Ut : 0 ::; t ::; T} is the Snell envelope of {yt : 0 ::; t ::; T}. Then 
E[Yp.(t)l~t] = Ut = esssupE[Ypl~t], a.s. 
pETi,T 
Theorem 44.4 (Snell Envelope of the American Put Option). Let {(Xi0 ), Xt) : 0 ::; 
t ::; T} be the Black-Scholes market given in Definition 42.2, and let Q be the risk-
neutral measure defined in Problem 37. 7. Let { Jt : 0 ::; t ::; T} be the Snell envelope 
of the discount reward of an American put option with strike K and maturity T: 
Jt = esssupEq [e-rP(K- Xp)+l~t], t E [0, T], a.s. 
pETi,T 
Let P(x, t) be afunction on (0, oo) x [0, T) defined as 
P(x, t) = sup Eq [e-r(p-t)(K- Xp)+IXt = x]. 
(44.1) 
pETi,T 
Then the Snell envelope admits the following decomposition 
Jt = Eq [e-rT(K- XT)+I~t] + Eq [1T e-rsrKI{x.<x;}dsl~t], 
where x; =sup {x: (x, t) E V} with 
v = { (X' t) E ( 0, 00) X [0, T) : P( X' t) = ( K - X)+} . 
44.2 Problems 
44.1. Let {yt : 0 ::; t ::; T} be a nonnegative stochastic process adapted to some 
filtration { ~t : 0 ::; t ::; T}, where T E (0, oo]. Suppose that {yt : 0 ::; t ::; T} and 
{ ~t : 0 ::; t ::; T} satisfy the assumptions given in Theorem 44.2. Let v E lo,T and 
T E Tv,T, where Tv,T = {u E lo,T: u 2:: v a.s.}. Show that 
(a) The set {E[Ypl~v] : p E Tr,T} is closed under pairwise maximization, where 
7,.,T = { U E lo,T : U 2:: T a.s. }. 
(b) There exists a sequence {Pn}n;;:::l of stopping times in Tr,T such that E[YPn l~v] 
is nondecreasing and 
44.2. Let {yt : 0 ::; t ::; T} be a nonnegative stochastic process adapted to some 
filtration { ~t : 0 ::; t ::; T}, where T E (0, oo]. Suppose that {yt : 0 ::; t ::; T} 
and { ~t : 0 ::; t ::; T} satisfy the assumptions given in Theorem 44.2. For any 
w E lo,T, define 
Uw = esssupE[Ypl~w]Â· 
pE/w,T 

614 
AMERICAN OPTIONS 
Letv,u E To,r andrE Tv,TÂ· LetA= {v = u}. Show that 
(a) 
(b) Uv = Uu a.s. on {v = u}. 
(c) E[UTiffv] = esssuppETT,T E[Yrlffv] a.s. 
(d) E[UTiffv] ::; Uv a.s. 
(e) E[UT] = suppETT,T E[Yp] ::; Uo < oo. 
44.3. Let {yt : 0 ::; t ::; T} be a nonnegative stochastic process adapted to some 
filtration {fft : 0 ::; t ::; T}, where T E (0, oo]. Suppose that {yt : 0 ::; t ::; T} 
and { fft : 0 ::; t ::; T} satisfy the assumptions given in Theorem 44.2. Let {Ut : 
0 ::; t ::; T} be the Snell envelope of {yt : 0 ::; t ::; T}. Show that a stopping time 
T* E To,r is optimal, specifically, 
E[YT.] = Uo = 
sup E[YT], 
TETo,T 
if and only if 
(a) UT. = YT. a.s., and 
(b) The stopped process {UtAT. : 0 ::; t ::; T} is a martingale. 
44.4. Let { (Xi0 ), Xt) : 0 ::; t ::; T} be the Black-Scholes market given in Definition 
42.2, and let Q be the risk-neutral measure defined in Problem 37.7. Let {lit : 0 ::; 
t ::; T} be a process defined as 
vt = esssupEq [e-r(p-t)(K- Xp)+lfft], 
t E [O,T], 
pE'Tt,T 
where K > 0 is a constant. Show that {lit : 0 ::; t ::; T} is a wealth process, that is, 
there exists an admissible trading and consumption strategy ( Â¢, A) corresponding to 
vt. 
44.5 (Arbitrage-Free Price of the American Put Option). Let { (Xi0 ), Xt) : 0 ::; t ::; 
T} be the Black-Scholes market given in Definition 42.2 and let Q be the risk-neutral 
measure defined in Problem 37.7. Let xCa) be an American put option with strike 
K and maturity T. Then the arbitrage-free price at time zero of X(a) is 
Vo = esssupEq [e-rP(K- Xp)+]. 
pETo,T 

PROBLEMS 
615 
44.6. Let { Bt : t ~ 0} be a standard Brownian motion under a probability measure 
P. Let {Wt : t ~ 0} be a process defined as 
Wt =at+ Bt, 
where a E R. Let (3 > 0 and T be a stopping time defined as 
7 = {min{ t ~ 0 : Wt = (3}, 
if { t ~ 0 : Wt = (3} # 0; 
oo, 
if { t ~ 0 : Wt = (3} = 0. 
For every >. > 0, show that 
44.7 (Perpetual American Put). Let { (Xi0 ), Xt) : 0 ~ t ~ T} be the Black-Scholes 
market given in Definition 42.2 with r > 0. A person bought a perpetual American 
put option with strike K > 0. The person sets a positive level L E (0, K) and will 
exercise the option at the stopping time TÂ£ given by 
{ 0, 
TL = 
min{t ~ 0: Xt = L}, 
if Xo > L. 
if X 0 ~ L; 
Suppose that under this exercise strategy, the value of the perpetual American put is 
defined as 
v (X ) _ E [e-rn (K _X )] _ {K- Xo, 
if Xo ~ L; 
L 
0 
-
Q 
TL 
-
(K- L)EQ [e-rn], if Xo > L, 
where Q is the risk-neutral measure defined in Problem 37.7. Show that 
(a) The function vL(x) is given by 
{ K- X 
ifO <X~ L; 
vL(x)= 
(K-~)(1;)-~, ifx>L. 
(b) Given x > 0, the function VL(x) is maximized at L* = a 22_;.2rK: 
VL. (x) ~ vL(x), 
VL E (0, K). 
(c) Let L* = a22_;.2rK. show that VL. (x) satisfies the following linear complemen-
tarity conditions: 
v(x) ~ (K- x)+, 
Vx ~ 0, 
1 
rv(x)- rxv'(x)- 2a 2x2v"(x) ~ 0, 
Vx ~ 0, 
(44.2a) 
(44.2b) 

616 
AMERICAN OPTIONS 
and for each x ~ 0, equality holds in either Equation ( 44.2a) or Equation 
(44.2b). Here v'(x) = d~~) and v"(x) = dv~~x). If v"(x) is undefined, then 
v" (x) is replaced by its left-hand or right-hand limit. 
(d) The process {yt : t ~ 0} is a supermartingale under Q, where 
yt = e-rtVL. (Xt), 
t ~ 0. 
Moreover, the stopped process {YtAn. : t ~ 0} is a martingale under Q. 
(e) The price of the perpetual American option is vL. (X0 ), where 7 is the set of 
all stopping times: 
44.8 (American Call Option). Let { (XJ0l, Xt) : 0 :<:::; t :<:::; T} be the Black-Scholes 
market given in Definition 42.2, and let Q be the risk-neutral measure defined in 
Problem 37.7. Let y(a) be an American call option with strike K and maturity T. 
Show that 
(a) The discounted intrinsic value process { e-rt(Xt - K)+ : 0 :<:::; t :<:::; T} of the 
American call option is a submartingale under Q. 
(b) The price of the American option is the same as the price of the European call 
option with strike K and maturity T. 
44.3 Hints 
44.1. To prove the first part, let Pl,P2 E lr,T and consider P3 = p1IA + P2lAc, 
where 
A= {E[Yp1 lÂ§v] ~ E[YP21Â§v]}. 
The second part follows from the first part and Theorem 44.1. 
44.2. 
To prove part (a), use the definition of conditional expectations (Definition 
14.1) and the result of Problem 23.9. To prove part (b), use part (a) to show that 
I{v=u}E[YplÂ§v] :S I{v=u}Uu, 
a.s. Vp E Tv,r 
and 
I{v=u}E[YplÂ§u] :S I{v=u}Uv, 
a.s. Vp E fu,TÂ· 
Use the results of Problems 44.1 and 14.7 to prove part (c). Part (d) follows from 
part (c). Part (e) follows from parts (c) and (d). 
44.3. To prove the "only if" part, note that {Ut : 0 :<:::; t :<:::; T} dominates {yt : 0 :<:::; 
t :<:::; T} (see Theorem 44.2) and E[U,..] = E[Y,..]. 

SOLUTIONS 
617 
44.4. Use Theorem 44.4 and the martingale representation theorem (Theorem 36.1). 
44.5. 
Follow the definition of arbitrage and use the result of Problem 44.4 and 
Theorems 44.2 and 44.3. 
44.6. 
Note that { r :=:: y} = { maxo::::;t::::;y Wt :::; ,8} and then apply the result of 
Problem 43.3. 
44.7. To prove part (a), use the result of Problem 44.6. To prove part (b), consider 
ln vL(x) and the cases when x E (0, L*) and x E (L*, oo). Part (c) can be proved 
by direct calculation. To prove part (d), apply Ito's formula (Theorem 35.3) and use 
part (c). To prove part (e), use the optimal stopping theorem (Theorem 23.1) and part 
(d). 
44.8. To prove the first part, note that ( x - K) + is a convex function of x (Definition 
15.1) and use the result of Problem 22.7. The second part follows from the first part. 
44.4 Solutions 
44.1. 
(a) Let Pl, P2 E 7-r,T and 
Then A E Â§v (see Definition 14.1). Let P3 = p1IA + p2IAc, For every 
s E [0, T], since 
{plJA + P2JAc :::; S} 
( {Pl :::; s} n A) U ( {P2 :::; s} n A c) 
( {Pl :::; s} n [ (A n { v :::; s}) u (A n { v > s})]) u 
({p2:::; s} n [(Ac n {v:::; s}) u (Ac n {v > s})]) 
E 
Â§s 
and r :::; P3 :::; T a.s., we have P3 E Tr,TÂ· Since 
E[Yp3 lÂ§v] 
= 
E[YpJA + Yp2 fAcl$v] 
JAE[Yp 1 lÂ§v] + fAcE[Yp 2 lÂ§v] 
E[Yp1 l$v] V E[Yp2 l$vJ, 
we know that the set {E[YplÂ§v] : p E Tr,T} is closed under pairwise maxi-
mization. 
(b) This follows from the first part and Theorem 44.1. 
This completes the proof. 

618 
AMERICAN OPTIONS 
44.2. 
(a) Let X = E[Y7 A lffv11u]Â· Then by Definition 14.1, we know that X is ffvllu-
measurable and l XdP = l YTAdP, 
VB E ffvlluÂ· 
(44.3) 
By Problem 23.9, X is also ffv-measurable. Now let C E ffv. Since 
A n c n { u ::; t} = { v = u} n c n { v ::; t} E fft, 
\It E [ o, T], 
we have An C E ffu. Hence An C E ffvlluÂ· By Equation (44.3), we get 
r xdP = r YTAdP, 
JAne 
JAne 
or 
fc IAXdP = fc IAYTAdP. 
Since lAX is ffv-measurable and Cis an arbitrary element of ffv, the above 
equation implies that 
which gives 
JAE[YTA lffvllu] = JAE[YTA lffv]Â· 
Similarly, we have IAE[YTA lffvllu] = IAE[YTA lffu]Â· 
(b) By part (a), we have for every p E Tv,r, 
JAE[YPA lffv] 
JAE[YPA lffu] 
IAE[Yplffu] 
< JAUu, 
where PA = piA+ TIArÂ· The above equation implies that IAUv :S: IAUu. 
Similarly, we have IAUu :S: IAUv. Hence Uv = Uu a.s. on A. 
(c) By Problem 44.1, there exists a sequence {Pn}n~l of stopping times in Tr,r 
such that { E[YpniÂ§T nn~l is nondecreasing and 
Then by Problem 14.13, we have 
lim E[YPn lffv] 
n-+CXJ 
< esssupE[YplÂ·%v]Â· 
(44.4) 
pETr,T 

SOLUTIONS 
619 
On the other hand, we have Ur ~ E[Ypl$r] for every p E Tr,TÂ· Hence 
which implies 
E[Url$v] ~ esssupE[Ypl$v]Â· 
pET-r,T 
The result follows from Equations (44.4) and (44.5). 
(d) Since Tr,T s;; lv,T. we have 
esssupE[Ypl$v]:::; Uv. 
pE'Tr,T 
Hence it follows from part (c) that 
(44.5) 
(e) This follows from parts (c) and (d) by letting v = 0 and noting that E[Yp] is a 
constant for every p E Tr,TÂ· 
This completes the proof. 
44.3. 
First let us prove the "only if" part. Suppose that T* is optimal. Then by 
Problem 44.2, we have 
But by Theorem 44.2, Ur. ~ Yr. a.s. The above equation implies that Ur. = Yr. 
a.s. Also by Theorem 44.2, {Ut : 0 :::; t :::; T} is a supermartingale. It follows from 
Theorem 23.1 that {UtM. : 0:::; t:::; T} is also a supermartingale. Since 
Uo = E[Yr.] = E[Ur.], 
we have 
E[UTM.J = E[Ur.] = E[E[Ur.Jl = E[Uo] = E[UoM.JÂ· 
By Problem 22.12, {UtM. : 0 :::; t :::; T} is a martingale. 
Now we prove the "if" part. Suppose that Ur. =Yr. a.s. and the stopped process 
{UtM. : 0 :::; t :::; T} is a martingale. Then we have 
which shows that T* is optimal. This completes the proof. 
44.4. Let { Jt : 0 :::; t :::; T} be defined as 
Jt = esssupEQ [e-rP(K- Xp)+l$t], 
t E [O,T], a.s. 
pEft,T 

620 
AMERICAN OPTIONS 
Then by Theorem 44.4, we have 
Jt = EQ [e-rT(K- Xr)+l..%t] + EQ [iT e-rsrKI{Xs<X;}dsl..%tl , 
where Xt is as defined in Theorem 44.4. For every t E [0, T], let 
and 
Ct = EQ [lot e-rsrKI{Xs<X;}dsl..%t] =lot e-rsrKI{Xs<X;}ds. 
Then we have Jt = Mt - Ct. Since { Mt : 0 ::::; t ::::; T} a bounded martingale under 
Q, it is a square-integrable martingale under Q. It follows from Theorem 36.1 that 
dMt = 17tdWt, 
t E [0, T] a.s., 
where Wt = !!:.7ft + Bt and { '17t : 0 ::::; t ::::; T} is some progressively measurable 
process with 
Now let(Â¢, A) be a trading and consumption strategy defined as 
Then we have 
and 
0~0ldx;o) + BtdXt- dAt = rert Jtdt + ertdMt- ertdCt = d(ert Jt) = d\lt. 
Hence(Â¢, A) is an admissible trading and consumption strategy and {vt : 0 ::::; t ::::; 
T} is a wealth process. This completes the proof. 
44.5. Let vt be defined as 
vt = esssupEQ [e-r(p-t)(K- Xp)+l..%t], 
t E [0, T]. 
pE'Jt,T 
Then by Problem 44.4, {vt : 0 ::::; t ::::; T} is a wealth process and there exists an 
admissible trading and consumption strategy (Â¢,A) = ( e<o), B, A) corresponding to 

SOLUTIONS 
621 
it. Let x6a) be the price at time zero of the American put option. If x6a) > V0 , 
we show that there is short arbitrage. To do that, let r E To,r be an exercise policy 
selected by the buyer of the American put option. We consider the following trading 
and consumption strategy ((3, C) = ('y(o), /',C): 
(o) _ {0~0l, 
ift E [O,r]; 
l't 
-
{j~O)+e-TT{jrXr-e-rT(K-X.,.)+, iftE(r,T], 
l't = Otf[o,rj(t), 
Ct = AtMÂ· 
Since {e-rtvt : 0 ~ t ~ T} dominates {e-rt(K- Xt)+ : 0 ~ t ~ T} (see 
Theorem 44.2), we have 
l'f!l x~O) = (Vre-TT- e-TT(K- Xr)+)erT ~ 0 a.s. 
Also we have 
1'6Â°) + /'oXo - x6a) = Vo - X6Â°l < 0. 
Hence the extended strategy ((3, C, -1, r) E d 0 . 
If x6a) < Vo, we show that there is long arbitrage. Let p0 be the optimal stop-
ping time (see Theorem 44.3). We consider the following trading and consumption 
strategy ((3, C) = ('y(o), /',C): 
{ 
(0) 
(o) _ 
-Ot , 
l't 
-
-0(0)- e-rpoe X + e-rpo(K- X )+ 
~ 
~ ~ 
~ ' 
l't = -Oti[o,poJ(t), 
Ct = -Ati\PQ" 
By Theorem 44.3, we have 
if t E [0, Po]; 
if t E (po, T], 
l'f!l x!J!l = (Vpoe-TPo- e-rpo(K- Xpo)+)erT = 0 a.s. 
Also we have 
1'6Â°) + /'oXo - X6a) = - Vo + X6Â°) < 0. 
Hence the extended strategy ((3, C, 1, Po) E d 0 . This completes the proof. 
44.6. Since {r ~ y} = {maxo:s;t:<;y Wt ~ (3}, we have 
P{ r < y} = 1 - P{ r ~ y} = 1 - P { max Wt ~ (3} . 
o:s;t:<;y 
By Problem 43.3, we have 
P { T < Y} = 1 - N ( (3 -;y) + e2af3 N (-(3 "Jy ay) , 
which gives the density of r: 
fr(Y) = 
= -- exp -- (3y-2- ay2 
y-2. 
dP{r < y} 
(3 
( 
1 ( 
1 
1)2) 
a 
dy 
~ 
2 

622 
AMERICAN OPTIONS 
Then we have 
Ep [e--XT] 
1
00 e--Xy JT(y)dy 
1
00 ~ 
exp ( -~ (t3Y-~- ay~ ) 2 - AY) y-~dy 
eaf3-f3v'a2+2-X roo Le-!(f3y- L,;a2+2-Xy! / y- ~ dy. 
(44.6) 
lo J27r 
To evaluate the integral, we let 
and 
Then we have 
We use a change of variable z = ;3y- ~ - J a 2 + 2Ay~. Since 
dz 
;3 _ ;! 
1 y' 
_ ! 
-
= --y 2--
a2 + 2Ay 
2 < 0 
dy 
2 
2 
' 
we know that z is a monotonically decreasing function of y. Hence the above equa-
tion becomes 
(44.7) 
Also, we have 
2f3v'a2+2-X ( 
;3 
J a 2 + 2A 
) 
e 
--gl + 
go 
2 
2 
We also use a change of variable z = ;3y-~ + va2 + 2Ay~. In this case, z is a 
monotonically decreasing function of y when y E (0, v'af+2-X) and z is a monotoni-
cally increasing function of y when y E ( ~Â· 
oo ). Therefore the above equation 

SOLUTIONS 
623 
becomes 
2/3va2+2>- ( 
f3 
.J a 2 + 2>. 
) 
e 
--gl + 
go 
2 
2 
1~ 
1 
_lz2d ! 00 
1 
_lz2d 
--e 2 
z + 
--e 2 
z 
00 
/2-i 
~ 
/2-i 
yo:2+2A 
0. 
(44.8) 
Combining Equations (44.7) and (44.8) gives (3g1 = 1. The result follows by plug-
ging this into Equation (44.6). This completes the proof. 
44.7. 
(a) We only need to show that for X 0 > L, 
(44.9) 
Let Wt = 7t + Bt fort ;::: 0. Then {Wt : t ;:=: 0} be a Brownian motion 
under Q and Xt = X 0 exp ((r- ~u2 )t + uWt)Â· Hence we have 
. { 
1 Xo} 
TÂ£ = mm t ;:=: 0 : -at - Wt = -;;: ln L 
, 
where a= ~(r-
~o- 2 ). Note that -Wt is also a Brownian motion under Q. 
By Problem 44.6, we have 
2r 
Eq [e-rrL] = e~ln4;J.(-a-va2+2r) = ( ~o) -:;:r, 
which verifies Equation (44.9). 
(b) Letf(L) = lnvL(x). Bypart(a), we have 
'(L) _ df(L) _ {0, 
J 
-
dL 
-
2rK-(a 2+2r)L 
(K L)L 
' 
ifO <X< L; 
ifx > L. 
If x E (0, L*), then we have f'(L) > 0 for L < x; that is, f(L) is increasing 
in the interval (0, x). In this case, f(L) attains its maximum at x. Hence 
VÂ£. (x) = f(L*) = K- x = f(x) ;:=: f(L) = vL(x), 
VL E (0, K). 
If x E ( L* , oo), then f ( L) is increasing in the interval ( 0, L *) and decreasing 
in the interval ( L*, x). In this case, we also have 
VÂ£. (x) = f(L*) ;:=: f(L) = vL(x), 
VL E (0, K). 

624 
AMERICAN OPTIONS 
(c) By part (a), we have 
{
-1 
v~.(x) = 
-
~r (K- L) (2--)-~ 
'U"2X 
* 
L* 
' 
The first derivative v' ( x) is continuous at L* since both the left-hand and right-
hand limits of v(x) at L* are equal to -1. Differentiating the above equation 
gives 
{
0, 
v" 
X 
-
2r 
L. ( ) -
2r(a2 +2r) (K _ L ) (2--)- :;2" 
u4x2 
* 
L,. 
' 
The second derivative v" ( x) is undefined at L* as v" ( L*-) = 0 and v" ( L* +) 
> 0. 
When x E (0, L*], we have VL. (x) = K- x = (K- x)+ and 
rvL. (x)- rxv~. (x)- ~u2x2v~. (x) 
r(K- x) + rx 
rK. 
2r 
When x E (L*, oo), we have VÂ£. (x) = (K- L*) (!,.) -:;2" > 0 and 
rvL. (x)- rxv~. (x)- ~u2x2v~. (x) 
r(K- L*) (~) -~ + rx 2; (K- L*) (~) -~ 
L* 
(T X 
L* 
~ 2 2 2r(u2 +2r)(K-L)(~)-~ 
2 (T X 
4 2 
* 
L 
0" X 
* 
0. 
Hence v L. ( x) satisfies the linear complementarity conditions. 
(d) Note that dXt = r Xtdt + uXtdWt. By Theorem 35.3 and part (c), we have 
or 
dyt 
de-rtVL. (Xt) 
e-rtuXtv~. (Xt)dWt-
e-rt [rvL. (Xt) - r X tv~. (Xt) - ~u2 Xfv~. (Xt)] dt 
e-rtuXtv~. (Xt)dWt - rK e-rt Ico,L.) (Xt)dt, 

SOLUTIONS 
625 
By Theorem 32.2, we have 
is a martingale, and since r K > 0, that {yt : t ~ 0} is a supermartingale. 
If X 0 > L*, then Xs > L* during the period (0, t 1\ TÂ£. ). Hence Equation 
(44.10) gives 
(44.11) 
If X 0 ~ L*, we have TÂ£. = 0. The above equation still holds. It follows 
from the optimal sampling theorem (Theorem 23.2) that {ytML. : t ~ 0} is a 
martingale. 
(e) By part (d), the process { e-rtvL. (Xt) : t ~ 0} is a supermartingale. For any 
stopping timeT, by Theorem 23.1 we have 
But by the definition of vL(Xo), we have 
Hence VÂ£. (X0) is the price of the perpetual American put option. 
This completes the proof. 
44.8. 
(a) Let 0 ~ s ~ t ~ T. We need to show that 
(44.12) 
Since h(x) = (x- K)+ is a convex function of x, for A E [0, 1] and 0 ~ x1 ~ 
x2, we have 
Letting x1 = 0, x2 = Xt. and A = e-r(t-s) in the above equation gives 
( e-r(t-s) Xt - K) + ~ e-r(t-s) (Xt - K)+ 
or 

626 
AMERICAN OPTIONS 
Note that { e-rt Xt : 0 :::; t :::; T} is a martingale under Q. From the above 
equation and Problem 22.7, we have 
EQ [e-rt(Xt- K)+lffs] 
> EQ [(e-rtXt- Ke-rs)+ lffs] 
> (e-rsxs-Ke-rs)+ 
e-rs(Xs- K)+, 
from which Equation (44.12) follows. 
(b) By Problem 42.4, the price at timet of the European call option with strike K 
and maturity T is given by 
But by the first item, we have 
which shows that the price of the European call option always dominates the 
intrinsic value of the American call option. Hence the option to exercise early 
is worthless. Thus the price of the American call option agrees with the price 
of the European call option. 
This completes the proof. 
44.5 
Bibliographic Notes 
The pricing problem of the American option can be formulated in different ways 
(Barone-Adesi, 2005; Wilmott et al., 1995). In this chapter, we presented the pricing 
problem in terms of optimal stopping. For more information about optimal stopping 
and American options, readers are referred to Bensoussan ( 1984 ), Karatzas ( 1988), 
Jacka (1991), and Myneni (1992). For a survey of the results on the pricing of 
American options, readers are referred to Barone-Adesi (2005) and Ahnet al. (20 11 ). 
The American option is also studied in Briys et al. ( 1998), Oksendal ( 1998), Karatzas 
and Shreve (2001), Elliott and Kopp (2005), and Musie1a and Rutkowski (2005). 
Analytic solutions of the pricing models for American options are not avail-
able. Numerical methods for pricing American options can be found in Broadie and 
Glasserman ( 1997), Longstaff and Schwartz (200 1 ), Topper (2005), Chan and Wong 
(2006), Seydel (2006), Duffy (2006), and Korn et al. (2010). Amin and Khanna 
(1994) proved the convergence of the binomial prices of the American option. 
Although there exist no analytic pricing formulas for American options, approx-
imate analytic pricing formulas for American options have been developed. For 
such approximate pricing formulas, readers are referred to Barone-Adesi and Wha-
ley ( 1987), Kim ( 1990), and Haug (2006). 

BIBLIOGRAPHIC NOTES 
627 
For more information about the essential supremum of a family of random vari-
ables, readers are referred to Karatzas and Shreve (2001, Appendix A), where a proof 
of Theorem 44.1 can be found. Proofs of Theorems 44.2 and 44.3 can be found in 
Karatzas and Shreve (2001, Appendix D). A proof of Theorem 44.4 can be found in 
Myneni (1992, Theorem 3.2). 


CHAPTER45 
SHORT RATE MODELS 
Short rate models are the earliest stochastic interest rate models. In this chapter, we 
present several short rate models and relevant concepts. 
45.1 
Basic Concepts and Facts 
Definition 45.1 (Zero-Coupon Bond). A zero-coupon bond with maturity date T is 
a contract that guarantees the holder a cash payment of one unit on the date T. Zero-
coupon bonds are also referred to as T -bonds. The price at time t of a zero-coupon 
bond maturing at Tis denoted by P(t, T). 
Definition 45.2 (Spot Rate and Short Rate). Let 0 :::;: t < T. The simple spot rate 
for [t, T] is defined to be 
F(t,T) = T~t (P(t~T) -1). 
The continuously compounded spot rate for [t, T] is defined to be 
R(t,T)= -lnP(t,T). 
T-t 
Measure, Probability, and Mathematical Finance. 
629 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

630 
SHORT RATE MODELS 
The function T---+ R(t, T) is called the zero-coupon yield curve or yield curve. The 
instantaneous short rate at time t is defined as 
r(t) = limR(t,T). 
T.j,.t 
Definition 45.3 (Bank Account). A bank account or money-market account repre-
sents a risk-free investment. The value f3(t) at timet of a bank account is defined 
as 
f3(t) = ef~r(s)ds, 
where r( s) is the short rate at time s. 
Definition 45.4 (Discount Factor). Let 0 ::::; t ::::; T. The (stochastic) discount factor 
D(t, T) between timet and timeT is defined as 
D(t T) = f3(t) = e- It r(s)ds 
' 
f3(T) 
. 
Definition 45.5 (Short Rate Model). In general, a short rate model has the following 
form 
n 
dr(t) = b(t)dt + L <Tj(t)dBij), 
j=l 
where {(Bi1), Bi2), ... , Bin)) : t 2: 0} is ann-dimensional Brownian motion on 
some filtered probability space (n, Â§, {Â§t : t 2: 0}, P), and {b(t) : t 2: 0} and 
{<Tj(t) : t 2: 0} are adapted processes that satisfy standard conditions (see Theorem 
38.1) required to guarantee the existence of the short rate process. 
Definition 45.6 (Equivalent Martingale Measure). Let (r!, Â§, P) be the real world 
probability space for the bond market. A probability measure Q defined on (f!, Â§) 
is called an equivalent martingale measure if 
(a) Q "'P. 
(b) For every T > 0, the discounted price process { P~~~~) : 0 ::::; t ::::; T} is a mar-
tingale. 
In this definition, we can restrict T E [0, T*] for some upper bound T*. An equiva-
lent martingale measure is also referred to as a risk-neutral measure. 
Definition 45.7 (T-Contingent Claim). Let (f!, Â§, {Â§t : t 2: 0}, Q) be a filtered 
risk-neutral probability space for the bond market, where Q is an equivalent martin-
gale measure. AT-contingent claim X is a Â§r-measurable random variable such 
that 

PROBLEMS 
631 
Theorem 45.1 (Risk-Neutral Price). Let (0, $, {$t: t 2: 0}, Q) be a filtered risk-
neutral probability space for the bond market, where Q is an equivalent martingale 
measure. Then the price process of a T -contingent claim X is given by 
In particular, the price process of a zero-coupon bond maturing at time T is given 
by 
45.2 Problems 
45.1. Let 0 < T < S. A gentleman entered into a contract such that he will pay 
a price K at time Tin return for a repayment of 1 at time S. Show that at time 
0 ~ t < T, the contract is worth 
P(t,S)- KP(t,T). 
45.2. Let {r(t) : 0 ~ t ~ T} be a short rate process satisfying the following 
stochastic differential equation 
dr(t) = a(t)dt + b(t)dBt, 
where { Bt : 0 ~ t ~ T} is a Brownian motion on some filtered probability space 
(0, $, {Â§t : t 2: 0}, P), and {a(t) : t 2: 0} and {b(t) : t 2: 0} are adapted 
processes that satisfy standard conditions (see Theorem 38.1). Suppose that there 
exists an equivalent martingale measure on (0, $). 
(a) Show that P(t, T) is a function of r(t). 
(b) Show that 
dP(t, T) = P(t, T)[m(t, T)dt + v(t, T)dBt] 
(45.1) 
for some adapted processes m(t, T) and v(t, T). 
(c) Suppose that the processes m(t, T) and v(t, T) in Equation (45.1) are bounded 
and that 
where r(t) is the market price of risk defined as 
( ) _ m(t, T) - r(t) 
I t -
v(t, T) 
, 
0 ~ t ~ T. 
Let {Wt : 0 ~ t ~ T} be defined as 
Wt = Bt +fat r(u)du 

632 
SHORT RATE MODELS 
and Q be a measure defined as 
dQ 
( 1T 
11T 
) 
dP = exp -
0 f'(u)dBu- "2 
0 l'(u) 2du . 
Show that {Wt : 0 :<:; t :S T} is a Brownian motion under Q and that the 
discounted price process {P(t,T)e-f~r(u)du: 0 :<:; t :<:; T} is a martingale 
under Q. 
45.3 (Term Structure Equation). Let {r(t) : 0 :<:; t :S T} be a short rate process 
satisfying the following stochastic differential equation 
dr(t) = a(t)dt + b(t)dBt, 
where { Bt : 0 :<:; t :<:; T} is a Brownian motion on some filtered probability 
space (D, .9/, {.9/t : t ~ 0}, P), and {a(t) : t ~ 0} and {b(t) : t ~ 0} are 
adapted processes that satisfy standard conditions (see Theorem 38.1). Suppose that 
P( t, T) = P( r( t), t, T); that is, the timet price of a zero-coupon bond with maturity 
T is a function of the current short rate r( t). Suppose that the market is efficient. Let 
( T) = m(t, T) - r(t) 
/' t, 
v(t,T) 
' 
where 
1 (8P 
8P 
1 
2 82P) 
m(t, T) = p 8t + a(t) Br + 2b(t) ar2 
and 
( T) =b(t)8P 
v t, 
p 8r. 
Show that 
(a) I'( t, T) is independent ofT. 
(b) P(t, T) satisfies the following partial differential equation, where ')'(t) = !'( t, T): 
8P 
8P 
1 
8 2P 
8t + [a(t)- ')'(t)b(t)] Br + 2 b(t)2 Br2 - r(t)P(t, T) = 0. 
45.4 (Term Structure Equation Under Q). Let {r(t) : 0 :S t :S T} be a short rate 
process following the Ito diffusion (see Definition 39.6) 
dr(t) = a(r(t))dt + b(r(t))dWt, 
where {Wt : 0 :<:; t :<:; T} is a Brownian motion under the risk-neutral measure 
Q. Show that the zero-coupon bond price satisfies the following partial differential 
equation: 
1 
2 82P 
8P 
8P 
-b(r(t)) -
+ a(r(t))---- r(t)P = 0. 
2 
8r2 
8r 
8t 

PROBLEMS 
633 
45.5 (Affine Term Structure). Let {r(t) : 0 :::; t :::; T} be a short rate process 
following the Ito diffusion 
dr(t) = [a(t) + b(t)r(t)]dt + Ju(t) + ry(t)r(t)dWt, 
where a(t), b(t), u(t), and ry(t) are some continuous functions, and {Wt : 0 :::; t :::; 
T} is a Brownian motion under the risk neutral measure Q. Suppose that the price 
ofT -bonds has the following form 
P(t, T) = exp ( -A(t, T)- B(t, T)r(t)) 
for some smooth functions A(t, T) and B(t, T). Show that A(t, T) and B(t, T) 
satisfy the following system of ordinary differential equations 
8A(t T) 
1 
8; 
= 2u(t)B2 (t, T)- a(t)B(t, T), 
A(T, T) = 0, 
(45.2a) 
aB~, T) = ~ry(t)B2 (t, T) - b(t)B(t, T) - 1, 
B(T, T) = 0. 
t 
2 
(45.2b) 
45.6 (Vasicek Model). Let {r(t) : 0 :::; t :::; T} be a short rate process satisfying the 
following stochastic differential equation 
dr(t) = a[JL- r(t)]dt + udWt, 
where a > 0, JL > 0, u > 0, and {Wt : 0 :::; t :::; T} is a Brownian motion under the 
risk neutral measure Q. Show that 
(a) For every t E [0, T], 
r(t) = r(O)e-at + JL (1- e-<>t) + ue-at fat eaudWu. 
(b) For every t E [0, T], 
EQ[r(t)] = r(O)e-at- JL (e-at -1) 
and 
(72 
VarQ[r(t)] = 2a (1- e-2at), 
where VarQ[X] = EQ[X2]- EQ[Xj2. 
(c) The time t price of the T -bond is 
where 
A(t,T) 
P(t, T) = exp ( -A(t, T)- B(t, T)r(t)), 
JL ( e-a(T-t) + a(T- t) - 1) 
a 
u2 ( 4e-a(T-t) - e-2a(T-t) + 2a(T- t) - 3) 
4a3 

634 
SHORT RATE MODELS 
and 
1- e-<>(T-t) 
B(t, T) = 
. 
a 
45.7 (CIR Model). Let {r(t) : 0 ~ t ~ T} be a short rate process satisfying the 
following stochastic differential equation 
dr(t) = a[11- r(t)]dt + ay'r{t)dWt, 
where a > 0, 1-l > 0, a > 0, and {Wt : 0 ~ t ~ T} is a Brownian motion under 
the risk-neutral measure Q. Suppose that the time t price of the T-bond has the 
following form: 
P(t, T) = exp( -A(t, T)- B(t, T)r(t)), 
t E [0, T]. 
Show that 
(a) The mean of the short rate at timet is 
EQ[r(t)] = 11- [1-l- r(O)Je-<>t. 
(b) The variance of the short rate at time t is 
V: 
[ ( )] 
11a2 
[r(O) - 11Ja2 -at 
[2r(O) - l-l]a2 -2at 
arQ r t = -
+ 
e 
-
e 
. 
2a 
a 
2a 
(c) The functions A(t, T) and B(t, T) are given by 
2a/-l 
( 
20e~(O+a)(T-t) 
) 
A(t, T) =-~In (0 +a) [eO(T-t)- 1] + 20 
and 
2 [eO(T-t)- 1] 
B( t T) = ---=:---:-,.---,..--~-
' 
(0 +a) [eO(T-t) -1] + 20' 
where 0 = y,---a"2_+_,2,---a""""2. 
45.8 (Hull-White Model). Let {r(t) : 0 ~ t ~ T} be a short rate process satisfying 
the following stochastic differential equation 
dr(t) = [b(t) + ar(t)]dt + adWt, 
where a and a are constants and {Wt : 0 ~ t ~ T} is a Brownian motion under 
the risk-neutral measure Q. Suppose that the time t price of the T-bond has the 
following form 
P(t, T) = exp( -A(t, T)- B(t, T)r(t)), 
t E [0, T]. 
Show that 
e<>(T-t) 
B(t,T) = --
a 
and 
a21T 
iT 
A(t, T) = --
B 2(s, T)ds + 
b(s)B(s, T)ds. 
2 
t 
s 

HINTS 
635 
45.3 Hints 
45.1. Apply Theorem 45.1 and the tower property of conditional expectations (see 
Problem 14.10). 
45.2. To prove part (a), use Theorems 45.1 and 39.1, the result of Problem 29 .2, and 
Theorem 11.2. To prove part (b), use part (a) and Ito's lemma (Theorem 35.3). To 
prove part (c), apply the Girsanov Theorem (see Problem 37.4) and the martingale 
property of Ito integrals (see Theorem 32.2). 
45.3. To prove part (a), consider at timet a portfolio of-V1 (t) amount in T1-bond 
and V2 (t) amount in T2-bond and use the arbitrage argument to establish 
m(t, Tl)- r(t) 
v(t, Tl) 
Use part (a) to prove part (b). 
m(t, T2) - r(t) 
v(t, T2) 
45.4. Apply Theorem 45.1 and the Feynman-Kac formula (see Theorem 40.1). 
45.5. Use the result of Problem 45.4. 
45.6. To prove part (a), consider the process eo:tr(t) and use Ito's lemma (Theorem 
35.3). Part (b) follows from part (a) and Theorem 32.1. To prove part (c), use 
Theorem 45.1 and note that {r( u) - r(t) : t ::; u ::; T} is independent of Â§tÂ· 
45.7. 
To prove part (a), use Theorem 32.1 and solve EQ[r(t)] from an ordinary 
differential equation. To prove part (b), use Ito's lemma (Theorem 35.3) to calculate 
EQ[r(t) 2] and then use the formula VarQ[r(t)] = EQ[r(t) 2]- EQ[r(t)] 2 and the 
result of part (a). Use the result of Problem 45.5 to prove part (c). 
45.8. Use the result of Problem 45.5. 
45.4 Solutions 
45.1. Let vt be the value at time t of the contract. Then Vr = P(T, S) - K. It 
follows from Theorem 45.1 that 
vt 
EQ [ (P(T, S)- K)e- It r(u)dul Â§t] 
EQ [ P(T, S)e- It r(u)dul Â§t] - KEQ [ e- It r(u)dul Â§t] 
EQ [EQ [e-J.ir(u)dulÂ§r]e-Itr(u)dulÂ§t] -KP(t,T).(45.3) 
From Problem 14.10, we have 
EQ [EQ [e-J.i'r(u)dulÂ§r] e-Itr(u)dulÂ§t] 
EQ [ e- J.i r(u)due- It r(u)du I Â§t J 
P(t, S). 
(45.4) 

636 
SHORT RATE MODELS 
Combining Equations (45.3) and (45.4) gives 
vt = P(t, S)- KP(t, T). 
This completes the proof. 
45.2. 
(a) Let Q be the equivalent martingale measure on (0, ff). Then by Theorem 45.1, 
we have 
P(t, T) = Eq [ e- It r(s)dsl fft] . 
By Theorem 39.1, the short rate process {r(t) : 0 :S t :S T} is Markovian. 
Hence it follows from Problem 29.2 that 
P(t, T) = Eq [ e- It r(s)dsl r(t)]. 
By Theorem 11.2, P(t, T) is a function of r(t). 
(b) By part (a), P(t, T) is a function of r(t). Let P(t, T) = P(r(t), t, T). Then by 
Theorem 35.3, we have 
oP 
(oP 
oP 1 2 o2P) 
dP(t, T) = or b(t)dBt + at+ a(t) or + 2,b(t) or2 
dt. 
Now let 
1 (oP 
oP 
1 
2 o2 P) 
m(t, T) =-
-
+ a(t)- + -b(t) -
p 
ot 
or 
2 
or2 
and 
( T) = b(t) oP 
v t, 
p or 0 
Then we have 
dP(t, T) = P(t, T)[m(t, T)dt + v(t, T)dBt]Â· 
(c) By the Girsanov Theorem (see Problem 37.4), {Wt : 0 :S t :S T} is a Brownian 
motion under Q. Now we show that the discounted price process { P(t, T)e- I~ r(u)du : 
0 :S t :S T} is a martingale under Q. Let Z(t, T) = P(t, T)e- I,; r(u)du. By 
Theorem 35.4, we have 
dZ(t, T) 
e- I~ r(u)dudP(t, T) + P(t, T)de- I~ r(u)du + dP(t, T)de- J,; r(u)du 
Z(t, T)[m(t, T)dt + v(t, T)dBt]- Z(t, T)r(t)dt 
Z(t, T)v(t, T)dWt. 

SOLUTIONS 
637 
By the assumption that v(t, T) and m(t, T) are bounded and Theorem 38.1, we 
have 
Hence we have 
Eq [loT Z(t, T)2v(t, T) 2dt] < oo. 
It follows from Theorem 32.2 that Z(t, T) is a martingale. 
This completes the proof. 
45.3. 
(a) Let T1 < T2. Let V be a portfolio constructed by shorting V1 amount in T1-
bond and purchasing V2 amount in T2-bond. Then the value at time t of the 
portfolio is v ( t) = v2 ( t) - vl ( t). The instantaneous investment gain from t to 
t + dt is 
By Ito's lemma (Theorem 35.3), we have 
Then we have 
dV(t) = [V2(t)m(t, T2) - V1 (t)m(t, Tl)]dt 
+[V2(t)v(t, T2) - V1 (t)v(t, T1)]dBt. 
(45.5) 
Suppose that we choose V1 ( t) and V2 ( t) in such a way that 
Note that V(t) = V2(t) - V1 (t). Solving the above equations gives 
V1(t) _ 
V(t)v(t, T2) 
V2(t) = 
V(t)v(t, T1) 
- v(t, Tl) - v(t, T2)' 
v(t, Tl) - v(t, T2) 
Then Equation (45.5) becomes 
dV(t) = V(t) m(t, T2)v(t, T1) - m(t, T1)v(t, T2) dt 
(45.6) 
v(t, Tl) - v(t, T2) 
' 
which shows that the portfolio V has deterministic growth. Hence the growth 
rate must be the risk-free rate r(t): 
m(t, T2)v(t, T1) - m(t, Tl)v(t, T2) = r(t) 
v(t, T1) - v(t, T2) 
Â· 

638 
SHORT RATE MODELS 
Manipulating the above equation gives 
m(t, Tl)- r(t) 
v(t, Tl) 
Hence 'Y(t, Tl) = "f(t, T2). 
m(t, T2)- r(t) 
v(t, T2) 
(b) By part (a), we have 
b(t) aP 
m(t, T) = 'Y(t)v(t, T) + r(t) = 'Y(t)p ar + r(t). 
But by definition we have 
1 (aP 
aP 
1 
2a2P) 
m(t, T) = p at+ a(t) ar + "2b(t) ar2 
. 
Combining the above two equations gives 
aP 
aP 
1 
a2P 
-a + [a(t)- 'Y(t)b(t)]-a + -b(t)2-a 
2 - r(t)P(t,T) = 0. 
t 
r 
2 
r 
This completes the proof. 
45.4. By Theorem 45.1 and Problem 29.2, we have 
Let 
v(t, x) = P(x, T- t, T) = EQ [ e- fci r(s+T-t)ds I r(T- t) = x] . 
Then by Theorem 40.1, we have 
or 
Since 
we have 
av 
av 
1 
2 a2v 
at (t, x) = a(x) ax (t, x) + 2b(x) ax2 (t, x)- xv(t, x) 
av 
1 
2 a2v 
av 
a(x) ax (t, x) + 2b(x) ax2 (t, x)- at (t, x)- xv(t, x) = 0. 
aP(r(t), t, T) 
at 
av(T- t, r(t)) 
at 
aP 
1 
a2P 
aP 
a(r(t))-a + -b(r(t))2-a 
2 +-a - r(t)P = 0. 
r 
2 
r 
t 
This completes the proof. 

SOLUTIONS 
639 
45.5. By the assumption that P(t, T) = exp ( -A(t, T)- B(t, T)r(t)), we have 
aP 
or = -B(t, T)P(t, T), 
()2 p 
ar2 = B2(t, T)P(t, T), 
and 
aP = _ P( T) (aA(t, T) 
( ) aB(t, T)) 
at 
t, 
at 
+ r t 
at 
0 
Then by Problem 45.4, we have 
1 
2 [a(t) + 17(t)r(t)]B2(t, T)P(t, T)- [a(t) + b(t)r(t)]B(t, T)P(t, T)-
P(t, T) (a A~~ T) + r(t) aB~~ T)) - r(t)P(t, T) = 0. 
Reorganizing the above equation gives 
(~1J(t)B2 (t,T)- b(t)B(t,T)- aB~~T) -1) r(t) 
aA(t T) 
1 
0~ 
- 2a(t)B2(t, T) + a(t)B(t, T) 
Since the above equation holds for arbitrary r(t), the following two equations must 
be satisfied: 
~17(t)B2 (t, T)- b(t)B(t, T)- aB~~ T) - 1 = 0, 
aA(t T) 
1 
0~ 
- 2a(t)B2(t, T) + a(t)B(t, T) = 0. 
This completes the proof. 
45.6. 
(a) By Ito's lemma (Theorem 35.3), we have 
Hence we have 
or 
e"'tdr(t) + r(t)de"'t 
e"'t(a[J.L- r(t)]dt + adWt) + r(t)ae"'tdt 
DJ.Le"'tdt + ae"'tdWt. 

640 
SHORT RATE MODELS 
(b) By part (a) and Theorem 32.1, we have 
EQ[r(t)] 
r(O)e-at + p, (1- e-at) + EQ [ae-at fat e'-'udWu] 
r(O)e-at + p, (1 - e-<>t) . 
and 
1
t 
0"2 
VarQ[r(t)] = 
a 2e_2,te20udu = -
(1- e- 2at). 
o 
2a 
(c) By part (a), we have for u E [t, T], 
r(u)- r(t) = [p,- r(t)] ( 1- ea(t-u)) + ae-<>u iu e08dW8 â¢ 
Since {r(u) -r(t) : t ~ u ~ T} is independent of fft, it follows from Theorem 
45.1 and Problem 14.16 that 
P(t, T) 
EQ [ e- Jt r(u)du I fft] 
e-r(t)(T-t) EQ [ e- J,T (r(u)-r(t))du I fft J 
e-r(t)(T-t) EQ [e- Jt(r(u)-r(t))du]. 
(45.7) 
Note that 
EQ [e- Jt(r(u)-r(t))du J = k 
e- Jt(r(u,w)-r(t,w))dudP. 
(45_8) 
For a fixed w E 0, we have 
iT (r(u,w)- r(t,w))du 
iT [p,- r(t,w)] ( 1- ea(t-u)) du +a iT e-au iu e08dW8 (w)du 
e-a(T-t) + a(T- t) - 1 
[p,-r(t,w)] 
-
a 
~ [ e-<>u iu e08dW8 (w)[ -iT dWu(w)] 
e-<>(T-t) + a(T- t) - 1 
[p,-r(t,w)] 
-
a 
~iT (e<>(s-T) -1) dW8 (w). 
Combining Equations (45.8) and (45.9) gives 
EQ [e- Jtcr(u)-r(t))du J 
(45.9) 
[ 
( 
e-<>(T-t) + a(T- t)- 1 
)] 
EQ exp [r(t) - p,] 
a 
+ Z 
,(45.10) 

SOLUTIONS 
641 
where 
Z =~iT (ea(s-T) -1) dW8 â¢ 
By Theorem 32.1, Z is a normal random variable with mean 0 and variance 
21T 
2 
VarQ(Z) = : 2 t 
(ea(s-T) -1) ds 
4e-a(T-t) - e-2a(T-t) + 2a(T- t) - 3 2 
2a3 
a . 
It follows from Equation (45.10) and Problem 19.1 that 
EQ [ e- Jt<r(u)-r(t))du] 
= 
exp ([r(t) -ILl e-a(T-t) + :(T- t)- 1) EQ [ez] 
( 
e-a(T-t) + a(T- t) - 1 
1 
) 
exp [r(t) -ILl 
a 
+ 2varQ(Z) '45.11) 
The result follows by combining Equation (45.7) and the above equation. 
This completes the proof. 
45.7. 
(a) Let g(t) = EQ[r(t)l. Then by Theorem 32.1, we have 
g(t) = r(O) + EQ [1t a[IL- r(s)lds] = r(O) + 1t a[IL- g(s)l. 
Differentiating both sides of the above equation gives 
d~~t) =aiL- ag(t). 
Hence we have 
which leads to 
g(t)eat = g(O) +aiL 1t e08ds = g(O) + IL [eat- 1]. 
Note that g(O) = EQ[r(O)l = r(O). The above equation gives 

642 
SHORT RATE MODELS 
(b) Let us first calculate g(t) = EQ[r(t)2]. By Theorem 35.3, we have 
r(t)2 = r(0)2 + lt 2a-r(s)~dW8 + lt [(2a~-t + a-2)r(s)- 2ar(s)2] ds. 
Hence we have 
g(t) = r(Of + lt [(2a~-t + a-2)EQ[r(s)]- 2ag(s)] ds, 
which gives 
dg(t) 
dt 
Now we have 
dg(t)e2at 
dt 
(2a~-t + a-2)EQ[r(t)]- 2ag(t) 
(2a~-t + a-2)(/L + [r(O) -~-t]e-at)- 2ag(t). 
e2at ( d~~t) + 2ag(t)) 
(2a~-t + a-2) (~-te 2at + [r(O) -
~-t]eat) . 
Integrating both sides of the above equation gives 
g(t)e2at- g(O) = (2a~-t + a-2) (_!!.___ [e2at- 1] + r(O) -!L [eat- 1J). 
2a 
a 
Therefore, 
VarQ[r(t)] 
g(t)- EQ[r(tW 
r(O)e-2at + (2a~-t + a-2)/L [1- e-2at] + 
2a 
(2a~-t + a-2)(r(O) -~-t) [e-at_ e-2at] _ (!L + [r(O) -~-t]e-at)2 
a 
~-t<T2 
[r(O) -
~-t]a- 2 -at 
[2r(O) -
~-t]a- 2 -2at 
-+ 
e 
-
e 
. 
2a 
a 
2a 
(c) By Problem 45.5, the functions A(t, T) and B(t, T) satisfy the following sys-
tem of ordinary differential equations 
aA(t, T) 
at 
= -a~-tB(t, T), 
A(T, T) = 0, 
(45.12a) 
aB(t,T) 
1 2 
2 
8t 
= 2a- B (t, T) + aB(t, T)- 1, 
B(T, T) = 0. 
(45.12b) 

SOLUTIONS 
643 
Let us first solve B(t, T). To do that, let g(t) = aB(t, T) +~-Then Equation 
(45.12b) becomes 
a 
g(T) = -. 
a 
Now let f(t) = ln[g(t) + ~]. Then Equation (45.13) becomes 
or 
of(t) = ~aef(t)- () 
at 
2 
' 
f(T) = ln a+() 
a 
de-f(t)-Ot = -~e- 9tdt 
f(T) = ln a+(). 
2 
' 
a 
Integrating both sides of the above equation from t to T leads to 
e- f(T)-OT _ e- f(t)-Ot = ;() [ e-OT _ e-Ot] . 
(45.13) 
Reorganizing the above equation and using the initial conditions, we can get 
2 [e9(T-t)- 1] 
B ( t, T) = -:-:( (),..--+-a-:-)-7[ e-:-o(=T---,-t-:--) -----";1 ],..--+-2--:-() . 
From Equation (45.12a), we have 
A(t, T) = A(T, T) + 1T apB(s, T)ds 
1
T 
2 [e9(T-s) _ 1] 
= ~ 
~ 
t 
(()+a) [eO(T-s) - 1] + 2() 
1
1 
y-1 
-~ 
2aJ.L 
-
eO(T-t) (() + a)(y- 1) + 2() ()y 
2aJ.L11 
(-2-
1 
+ _1_2_) dy. 
eO(T-t) 
a-()(()+ a)y +()-a 
()-a ()y 
Since 
1
1 
_2_ 
1 
dy = _ _.!_ ln 
2() 
eO(T-t) a-()(()+ a)y +()-a 
a 2 
(() + a)[e9(T-t)- 1] + 2() 
and 
1
1 
_1 _ _!_dy __ _.!_ (0 + a)(T- t) 
eO(T-t) () -
a ()y 
-
a 2 
2 
' 
we have 
At T =--In 
2aJ.L 
( 
2()e!<O+a)(T-t) 
) 
( ' ) 
a 2 
(()+a) [e9(T-t)- 1] + 2() 
Â· 

644 
SHORT RATE MODELS 
This completes the proof. 
45.8. By Problem 45.5, B( t, T) satisfies the following ordinary differential equation 
oB(t, T) = -aB(t T) - 1 
( 
) 
t 
, 
, 
B T,T = 0. 
Hence 
which gives 
e"'(T-t)-1 
B(t,T) = ---
a 
Also by Problem 45.5, we have 
oA(:, T) = ~a2 B 2 (t, T)- b(t)B(t, T), 
A(T, T) = 0. 
Integrating both sides of the above equation from t to T leads to 
1 iT 
iT 
A(T, T)- A(t, T) = -a2 
B 2(s, T)ds-
b(s)B(s, T)ds 
2 
t 
t 
or 
1 iT 
iT 
A(t, T) = --a2 
B 2(s, T)ds + 
b(s)B(s, T)ds. 
2 
t 
t 
This completes the proof. 
45.5 
Bibliographic Notes 
In this chapter, we introduced some continuous-time short rate models for interest 
rates. In particular, we presented the Vasicek model and the CIR model. 
Table 45.1 
Some short rate models. 
Model 
Reference 
Vasicek 
Vasicek (1977), Hull and White (1990) 
Dothan 
Dothan (1978) 
CIR 
Cox et a!. ( 1985), Hull and White (1990) 
Ho-Lee 
Ho and Lee (1986) 
Black-Derman-Toy 
Black eta!. (1990) 
Black-Karasinski 
Black and Karasinski (1991) 
There are several other short rate models. For example, Table 45.1 lists some short 
rate models and the corresponding references. Assumptions of various short rate 

BIBLIOGRAPHIC NOTES 
645 
models are discussed in Svoboda (2004). For discrete interest rate models, readers 
are referred to Cairns (2004) and Pascucci and Runggaldier (2012). 
Short rate models are also studied in many other books, such as Hunt and Kennedy 
(2004), Shreve (2004), Musiela and Rutkowski (2005), Brigo and Mercurio (2006), 
Bjork (2009), Filipovic (2009), Ekstrand (2011), and Lyuu (2001), to name only a 
few. For general term structure models, readers are referred to Baxter (1997), Bjork 
et al. (1997), and Jin and Glasserman (2001). For a review on interest rate models, 
readers are referred to Rebonato (2004). 
Theorem 45.1 states the risk-neutral price of interest rate derivatives, which in-
clude zero-coupon bonds. A proof of this theorem can be found in Cairns (2004, 
Theorem 4.1). 


CHAPTER46 
INSTANTANEOUS FORWARD RATE 
MODELS 
The short rate models presented in the previous chapter are not flexible for calibra-
tion. As a consequence, Heath et al. (1992) introduced a new uniform framework, 
called the HJM framework, for modeling the interest rates. In the Heath-Jarrow-
Morton (HJM) framework, the entire forward curve is modeled directly. These inter-
est rate models are called HJM models or instantaneous forward rate models. In this 
chapter, we introduce some concepts related to the HJM framework. 
46.1 
Basic Concepts and Facts 
Definition 46.1 (Forward Rate). Let 0 :::; t < T < S. The simple (or simply 
compounded) forward rate for [T, S] prevailing at t is defined to be 
1 
(P(t, T) 
) 
F(t; T, S) = S- T 
P(t, S) - 1 , 
Measure, Probability, and Mathematical Finance. 
647 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

648 
INSTANTANEOUS FORWARD RATE MODELS 
where P(t, T) is the value at timet of a dollar at timeT. The continuously com-
pounded forward rate for [T, S] prevailing at t is defined to be 
R( . T S) = lnP(t, T) -lnP(t, S) 
t, ' 
S-T 
. 
The instantaneous forward rate with maturity T prevailing at t is defined as 
. 
8lnP(t, T) 
f(t,T) = hmR(t;T,S) =-
a 
Â· 
StT 
T 
The function T ---7 f(t, T) is called the forward curve at timet. 
Definition 46.2 (Forward Contract). Lett < T. A forward contract on an underlying 
Y, entered at timet, with maturity Tis defined as follows: 
â¢ At timeT, the contract holder at the long side pays f(t, T, Y) and receives Y 
from the contract holder at the short side, where f(t, T, Y) is the forward price 
of Y at timet. 
â¢ At time t, the forward price is chosen such that the value of the contract is zero, 
where r( u) is the short rate and Q is the equivalent martingale measure for the 
bond market: 
Definition 46.3 (Futures Contract). Lett < T. A futures contract on an underlying 
Y, entered at timet, with maturity Tis defined as follows: 
â¢ At timeT, the contract holder at the long side pays F(t, T, Y) and receives Y 
from the contract holder at the short side, where F(t, T, Y) is the futures price 
quoted at time t for the futures contract. 
â¢ At time t, the futures price is chosen such that the value of the contract is zero. 
â¢ During any infinitesimal time interval (t, t + J], the contract holder at the long 
side receives F(t + J, T, Y) - F(t, T, Y) from the contract holder at the short 
side. 
Definition 46.4 (HJM Framework). LetT* > 0. Let {(B~ 1 ), B?), ... , B~n)): 0 :S 
t :S T*} be an n-dimensional Brownian motion on some filtered probability space 
(0, y;, {g;t : 0 :S t :S T*}, P). For every T E [0, T*], the forward rate process 
{!( t, T) : 0 :S t :S T} satisfies the following stochastic differential equation: 
-
t 
~ t 
(i) 
f(t, T) - f(O, T) + Jn a(w, s, T)ds + L...t Jn u;(w, s, T)dBs . 
0 
i=l 
0 
(46.1) 
Here f(O, T), a, and u; (i = 1, 2, ... , n) satisfy the following technical conditions: 

BASIC CONCEPTS AND FACTS 
649 
(a) {!(0, T) : 0 ::; T ::; T*} is a fixed and deterministic initial forward curve. The 
map f(O, Â·) : [0, T*] -+ R is B[O, T*]-measurable and 
T* 1 if(O,v)jdv < oo. 
(b) 0: : n X {(s, t) : 0 ::; s ::; t ::; T*} -+ R is a family of drift functions and 
isÂ§ Q9 B{(s, t) : 0 ::; s ::; t ::; T*}-measurable. For every T E [0, T*], the 
process { o:( Â·, t, T) : 0 ::; t ::; T} is adapted to the filtration { Â§t : 0 ::; t ::; T} 
and 
rrÂ· r 
Jo 
Jo jo:(Â·,t,v)jdtdv<oo, P-a.s. 
(c) For every i = 1, 2, ... , n, O'i : 0 x {(s, t) : 0 ::; s ::; t ::; T*} -+ R is a family 
of drift functions and isÂ§ Q9 B{(s, t) : 0 ::; s ::; t ::; T*}-measurable. For 
for every i = 1, 2, ... , nand every T E [0, T*], the process { O'i(Â·, t, T) : 0 ::; 
t ::; T} is adapted to the filtration { Â§t : 0 ::; t ::; T} and satisfies the following 
conditions: 
T ( 
T 
)
2 
1 1 O'i(Â·, s, t)dt 
ds < oo, 
P-a.s., 
v ( 
T 
)
2 
1 1 O'i(Â·, s, t)dt 
ds < oo, 
P- a.s., 
Vv E [0, T], 
and 
v-+ 1T (1v O'i(Â·, s, t)dB~i)) 
2 dt is continuous P-a.s. 
Theorem 46.1 (Stochastic Fubini Theorem). Let { Bt : 0 ::; t ::; T} be a Brownian 
motion on some filtered probability space (0, Â§, { Â§t : 0 ::; t ::; T}, P). Let 
{ Â¢( w, s, t) : 0 ::; s, t ::; T} be a family of random variables such that 
(a) The map ((w, s), t) E (0 x [0, T]) x [0, T] -+ <f>(w, s, t) is C Q9 8[0, T]-
measurable, where Cis the smallest 0'-field to which all left-continuous { Â§t : 
0 ::; t ::; T}-adapted stochastic processes { Xt = X (w, t) : 0 ::; t ::; T} are 
measurable (see Definition 34.2). 
(b) For every v E [0, T] and every t E [0, T], we have 
1v Â¢2 (-, s, t)ds < oo, P- a.s. 
(c) For every v E [0, T], we have 
1" ([ f( ,s, t}dt)' ds < oo. 

650 
INSTANTANEOUS FORWARD RATE MODELS 
(d) The map 
v---+ loT (fov Â¢(Â·, s, t)dB8 ) 
2 dt 
is continuous P- a.s. 
Then for every v E [0, T], 
Theorem 46.2 (HJM Drift Condition). Let Q be an equivalent martingale measure 
for the bond market and {Wt : 0 ~ t ~ T*} a Brownian motion with respect to Q. 
Suppose that the forward rate satisfies the following stochastic differential equation 
df(t, T) = a(t, T)dt + rr(t, T)dWt, 
0 ~ t ~ T ~ T*. 
Then 
a(t, T) = rr(t, T) 1T rr(t, s)ds, Q- a.s., 
0 ~ t ~ T ~ T*. 
The above equation is referred to as the HJM drift condition. 
Theorem 46.3 (Futures Price). Lett < T. For a futures contract with maturity T 
and underlying Y, the futures price at time t is given by 
F(t,T,Y) = Eq[Yig-t], 
where Q is the equivalent martingale measure for the bond market. 
46.2 Problems 
46.1. Let P(t, T) be the price at timet of a zero-coupon bond maturing at timeT. 
Let f(t, T) be the instantaneous forward rate with maturity T prevailing at t. Show 
that fort~ S ~ T, we have 
P(t, T) = P(t, S) exp (-1sT f(t, u)du) . 
46.2. Let T > 0. Suppose that the price process { P( t, T) : 0 ~ t ~ T} of the 
T -bond satisfies the following stochastic differential equation: 
dP(t, T) = P(t, T)[m(t, T)dt + v(t, T)dBt]Â· 
Here {Bt : 0 ~ t ~ T} is a Brownian motion on some filtered probability space (0, 
g-, {g-t: 0 ~ t ~ T},P), and {m(t,T): 0 ~ t ~ T} and {v(t,T): 0 ~ t ~ T} 

PROBLEMS 
651 
are adapted processes that satisfy standard conditions (see Theorem 38.1). Show 
that the forward rate process {f(t, T) : 0 :::; t :::; T} satisfies the following stochastic 
differential equation 
df(t, T) = a(t, T)dt + a(t, T)dBt, 
where 
ov 
om 
a(t, T) = v(t, T) aT (t, T) - aT (t, T) 
and 
ov 
a(t, T) = -aT (t, T). 
46.3. LetT > 0. Suppose that the forward rate process {f(t, T) : 0 :::; t :::; T} 
satisfies the following stochastic differential equation 
df(t, T) = a(t, T)dt + a(t, T)dBt, 
where { Bt : 0 :::; t :::; T} is a Brownian motion on some filtered probability space ( 0, 
~. { ~t : 0 :::; t :::; T}, P), and { a(t, T) : 0 :::; t :::; T} and { a(t, T) : 0 :::; t :::; T} 
satisfy the conditions given in Definition 46.4. Show that 
(a) The short rate process satisfies the following stochastic differential equation 
dr(t) = ( a(t, t) + ~~ (t, t)) dt + a(t, t)dBt. 
(b) For every t E [0, T], we have 
1T fat a(s, u)dsdu = 
fat 1T a(s, u)duds 
fat 1T a(s, u)duds -fat lou a(s, u)dsdu. 
(c) For every t E [0, T], we have 
1T fat a(s, u)dB8 du = 
fat 1T a(s, u)dudB8 
fat 1T a(s, u)dudB8 -fat lou a(s, u)dB8 du. 
(d) The T-bond price process satisfies the following stochastic differential equa-
tion: 
dP(t, T) = P(t, T) [m(t, T)dt + v(t, T)dBt]Â· 
Here 
( 
T 
)2 
T 
m(t, T) = r(t) + ~ 1 a(t, s)ds 
- 1 a(t, s)ds 

652 
INSTANTANEOUS FORWARD RATE MODELS 
and 
v(t, T) =-iT cr(t, s)ds. 
46.4 (Risk-Neutral Measure). Let T* > 0. Suppose that for every T E [0, T*], 
the forward rate process {f(t, T) : 0 ::::; t ::::; T} satisfies the following stochastic 
differential equation 
d.f(t, T) = n(t, T)dt + cr(t, T)dB1, 
where { B 1 : 0 ::::; t ::::; T} is a Brownian motion on some filtered probability space ( D, 
Â§, {.~1 : 0 ::::; t ::::; T}, P), and { a(t, T) : 0 ::::; t ::::; T} and { cr(t, T) : 0 ::::; t ::::; T} 
satisfy the conditions given in Definition 46.4. Suppose that there exists an adapted 
process {A(t) : 0::::; t::::; T*} with the following properties: 
â¢ For every T E [0, T*], we have 
1T >.2 (t)dt < oo, 
P- a.s. 
â¢ For every T E [0, T*], Ep[L(T)] = 1, where 
L(t) = exp ( -1
1 >.(u)dB,- ~ .[ >.2(u)du); 
â¢ For every T E [0. T*] and every t E [0, T], we have 
a(t, T)- cr(t, T) iT cr(t, s)ds = cr(t, T)>.(t). 
Show that 
(a) For any T, S E [0, T*] with T < S, QT = Qs on (D. Â§T ), where 
dQT = L(T) 
dP 
' 
dQs = L(S). 
dP 
(b) There exists an equivalent martingale measure Q (see Definition 45.6). 
(46.2) 
46.5 (General HJM Model). Let T* > 0. Suppose that for every T E [0, T*], 
the forward rate process {! ( t, T) : 0 ::::; t ::::; T} satisfies the following stochastic 
differential equation 
d.f(t, T) = O"(t. T) iT cr(t, s)dsdt + O"(t, T)dW1, 
where {W1 : 0 ::::; t ::::; T} is a Brownian motion under the risk-neutral probability Q 
and the coefficients of dt and dW1 satisfy the technical conditions given in Definition 
46.4. Let 
j
Â·T 
TJ(t, T) = -
O"(t, u)du . 
. t 

PROBLEMS 
653 
Show that 
(a) For 0 :::; t :::; T :::; T*, we have 
P(t, T) 
( 
1 t 
2 
t 
) 
f3(t) 
= P(O, T) exp - 2 Jo TJ (s, T)ds + Jo ry(s, T)dWs . 
(b) For 0 :::; t :::; T :::; S :::; T*, the price at time T of a zero-coupon bond with 
maturity S is given by 
P(T S) = P(t, S) z 
' 
P(t, T) e ' 
where 
11T 
1T 
Z = --
[TJ2(u, S)- ry2(u, T)] du + 
[ry(u, S)- ry(u, T)]dWu. 
2 
t 
t 
(c) For 0 :::; t :::; T :::; S :::; T*, the futures price, quoted at time t for a futures 
contract with maturity Ton a zero-coupon bond with maturity S, is given by 
P(t,S) 
(1T 
) 
V(t,T,S) = P(t,T) exp 
t 
ry(u,T)[ry(u,T)- ry(u,S)]du . 
46.6 (Gaussian HJM Model). LetT* > 0. Suppose that for every T E [0, T*], 
the forward rate process {f(t, T) : 0 :::; t :::; T} satisfies the following stochastic 
differential equation 
df(t, T) = a 2(T- t)dt + adWt, 
where {Wt : 0 :::; t :::; T} is a Brownian motion under the risk neutral probability 
Q and a is a nonnegative constant. Let 0 :::; t :::; T :::; S :::; T*. Show that the price 
at time t of a European call option with strike K and maturity T on a zero-coupon 
bond with maturity S is given by 
C(t, T, S, K) = P(t, S)N(dl)- KP(t, T)N(d2 ), 
where N(Â·) is as defined in Definition 19.1, specifically 
ln P(t,S) + la2(S- T) 2(T- t) 
d _ 
P(t,T)K 
2 
1 -
a(S- T).JT- t 
' 
and 

654 
INSTANTANEOUS FORWARD RATE MODELS 
46.3 
Hints 
46.1. Follow the definition of instantaneous forward rates (Definition 46.1 ). 
46.2. Use the result of Problem 46.1 and Ito's lemma (Theorem 35.3). 
46.3. To prove part (a), note that r(t) = f(t, t), 
t 
t 
t r {)a 
Jo a(s,t)ds= Jo a(s,s)ds+ Jo Jo {)T(s,u)dsdu, 
and 
lot a-(s, t)dB8 =lot a(s, s)dBs +lot lou ~;(s, u)dB8 du. 
To prove parts (b) and (c), use the classical Fubini theorem (Theorem 10.2) and the 
stochastic Fubini theorem (Theorem 46.1), respectively. Part (d) can be proved by 
parts (b) and (c). 
46.4. To prove the first part, use the results of Problems 14.10 and 14.12 to show that 
Qr(A) = Qs(A) for every A E Â§r. To prove the second part, follow the defini-
tion of equivalent martingale measure (Definition 45.6) and consider the probability 
measure defined as ~~ = L(T*). 
46.5. To prove part (a), use the result of Problem 46.1 and Fubini's theorem (The-
orems 10.2 and 46.1). To prove part (b), use Theorem 45.1 and Fubini's theorem 
(Theorems 10.2 and 46.1). Use part (b) and Theorem 46.3 to prove part (c). 
46.6. Use Theorem 45.1 and the results of Problems 40.6 and 46.5. 
46.4 Solutions 
46.1. By Definition 46.1, we have 
dlnP(t,u) = -f(t,u)du. 
Integrating both sides of the above equation from S to T gives 
ln P(t, T) -In P(t, S) =- fsT f(t, u)du, 
or 
P(t, T) = P(t, S) exp (- fsT f(t, u)du) . 
This completes the proof. 

46.2. By Problem 46.1 and the fact that P(t, t) = 1, we have 
lnP(t, T) = -1T f(t, u)du. 
SOLUTIONS 
655 
Differentiating both sides of the above equation with respect to t gives 
alnP(t,T) 
a 1T 
1T aj 
at 
= -at t f(t, u)du = - f(t, t) -
t 
at (t, u)du. 
Now differentiating the above equation with respect to T gives 
a2 lnP(t,T) = _ aj (t T). 
aTat 
at ' 
But by Theorem 35.3, we get 
lnP(t,T) = 1T ( 
m(s,T)- ~v2 (s,T)) ds+ 1T v(s,T)dB8 
or 
alnP(t, T) 
( 
1 2 
) 
at 
= m(t, T) - 2v (t, T) dt + v(t, T)dBt. 
Combining the above equations gives 
aj 
( 
av 
am 
) 
av 
at (t, T) = v(t, T) aT (t, T) - aT (t, T) dt- aT (t, T)dBt. 
This completes the proof. 
46.3. 
(a) By Definitions 45.2 and 46.1, we have 
r(t) = f(t, t) = f(O, t) +lot o:(s, t)ds +lot O"(s, t)dB8. 
Since 
1
t ao: 
o:(s,t)=o:(s,s)+ 8 aT(s,u)du 
and 
1
t a(J 
O"(s,t)=O"(s,s)+ 8 aT(s,u)du, 
we have 
t 
t jt ao: 
r(t) 
f(O,t)+ Jo o:(s,s)ds+ Jo 
8 aT(s,u)duds 
t 
tjt a 
+ Jo O"(s,s)dB8 + Jo 
8 a;(s,u)dudB8 
f(O,t)+ loto:(s,s)ds+ lotlou~;(s,u)dsdu 
rt 
rt r a(J 
+ Jo O"(s, s)dB8 + Jo Jo aT (s, u)dB8du, 

656 
INSTANTANEOUS FORWARD RATE MODELS 
or 
dr(t) 
of 
t oa 
oT(O,t)dt+a(t,t)dt+ Jo oT(s,t)dsdt 
t ocr 
cr(t, t)dBt + Jo oT(s, t)dBsdt. 
(46.3) 
Note also that 
f(t, T) = f(O, T) +fat a(s, T)ds +fat cr(s, T)dB 8 â¢ 
Differentiating the above equation with respect to T gives 
0 f 
0 f 
t oa 
t ocr 
T(t,T) = oT(O,T)+ lo oT(s,T)ds+ lo oT(s,T)dBs. 
Now let T = t in the above equation, we get 
M 
M 
t~ 
t& 
T(t, t) = oT(O, t) + lo oT(s, t)ds + lo oT(s, t)dBs. 
(46.4) 
Combining Equations (46.3) and (46.4) gives 
dr(t) = ( i (t, t) + a(t, t)) dt + cr(t, t)dBt. 
(b) By assumption and Theorem 10.2, we have 
iT fat a(s, u)dsdu 
= 
fat iT a(s, u)duds 
fat 1T a(s, u)duds -fat 1t a(s, u)duds 
fat 1T a(s, u)duds -lot lou a(s, u)dsdu. 
(c) Let Â¢(w, s, u) be defined as 
Â¢(w,s,u)= 
' 
{ 0 
if (s, u) ~ [0, t] x [t, T]; 
cr(s, u)(w), if(s, u) E [0, t] x [t, T]. 

SOLUTIONS 
657 
Then by assumption and Theorem 46.1, we have 
1T lot a(s, u)dB8du 
= 
loT lot</>(Â·, s, u)dB8du 
= 
lot loT </>(Â·,s,u)dudBs 
lot 1T a(s, u)dudBs 
lot 1T a(s, u)dudB8 -lot 1t a(s, u)dudB8 
lot 1T a(s, u)dudB8 -lot lou a(s, u)dB8 du. 
(d) By Ito's lemma (Theorem 35.3), the stochastic differential equation 
dP(t, T) = P(t, T) [m(t, T)dt + v(t, T)dBt] 
is equivalent to the stochastic differential equation 
dlnP(t,T) = ( m(t,T)- ~v2 (t,T)) dt+v(t,T)dBt. 
(46.5) 
Now by assumption we have 
f(t, u) = f(O, u) +lot a(s, u)ds +lot a(s, u)ds. 
Since ln P(t, T) = - Jt f(t, u)du, we have 
lnP(t,T) 
-1T f(O, u)du- 1T lot a(s, u)dsdu -1T lot a(s, u)dsdu. 
By parts (b) and (c), the above equation becomes 
lnP(t,T) 
-1T f(O, u)du- lot 1T a(s, u)duds +lot lou a(s, u)dsdu 
-lot 1T a(s, u)dudB8 +lot lou a(s, u)dB8 du 

658 
INSTANTANEOUS FORWARD RATE MODELS 
or 
dlnP(t, T) 
f(O, t)dt- 1T a(t, u)dudt +fat a(s, t)dsdt 
-1T a(t, u)dudBt +fat a(s, t)dB8 dt 
f(t, t)dt- 1T a(t, u)dudt- 1T a(t, u)dudBt. 
(46.6) 
Note that r(t) = f(t, t). Comparing Equations (46.5) and (46.6) gives 
( 
T 
)
2 
T 
m(t, T) = r(t) + ~ 1 a(t, s)ds -1 a(t, s)ds 
and 
v(t, T) = -1T a(t, s)ds. 
This completes the proof. 
46.4. 
(a) Let A E Â§y. Since Qs(A) = EQ 8 [IA] = Ep[L(S)IA], it follows from 
Problems 14.10 and 14.12 that 
But 
Qs(A) 
Ep[L(S)IÂ§r] 
Ep[L(S)IA] 
Ep[Ep[L(S)IA]IÂ§r] 
Ep[IAEP[L(S)IÂ§r]]. 
Ep [ L(T) exp ( -Â£
8 >.(u)dBu- ~ ls >.2(u)du) I Â§y] 
L(T)Ep [exp ( -Â£
8 >.(u)dBu- ~ ls >.2(u)du)] 
L(T). 
Hence we have 

SOLUTIONS 
659 
(b) Let Z(t, t) = PJ~~fl. Then it follows from Theorem 35.3 that 
dZ(t, T) = Z(t, T) [m(t, T)dt + v(t, T)dBt], 
(46.7) 
where 
( 
T 
)2 
T 
m(t, T) = ~ 1 u(t, s)ds -1 a(t, s)ds 
and 
v(t, T) = -1T u(t, s)ds. 
Let Q be a probability measure on (f!, $râ¢) defined as ~ = L(T*). Let 
{Wt : 0 ::; t ::; T*} be a process defined as 
Then by Problem 37.4, {Wt : 0 ::; t ::; T*} is a Brownian motion under Q. 
Equation (46.7) becomes 
dZ(t, T) = Z(t, T) [(m(t, T)- v(t, T)>.(t))dt + v(t, T)dWt]Â· 
(46.8) 
Since 
1T a(t, s)ds 
we have 
1T (u(t,s) 1
8 u(t,u)du+u(t,s)>.(t)) ds 
~ ([ a(t,s)ds) 
2
- A(t)v(t,T), 
m(t, T) - v(t, T)>.(t) = 0. 
Hence Equation (46.8) becomes 
dZ(t, T) = Z(t, T)v(t, T)dWt. 
By Theorem 32.2, { Z ( t, T) : 0 ::; t ::; T} is a martingale. 
This completes the proof. 
46.5. 
(a) Since 
f(u,u) = f(t,u) -1u u(s,u)ry(s,u)ds + 1u u(s,u)dW8 , 

660 
INSTANTANEOUS FORWARD RATE MODELS 
we have 
iT r(u)du 
iT f(t, u)du-iT iu O"(s, u)'TJ(s, u)dsdu 
+iT iu O"(s, u)dW8 du. 
By Theorems 10.2 and 46.1, the above equation becomes 
iT r(u)du = iT f(t, u)du -iT iu O"(s, u)'TJ(s, u)dsdu 
+iT iu O"(s, u)dW8 du 
iT f(t, u)du-iT 1T O"(s, u)'TJ(s, u)duds 
+iT 1T O"(s, u)dudWs 
iT 
f(t, u)du +~iT 
'T]2(s, T)ds 
t 
2 t 
-iT 'TJ(S, T)dW8 â¢ 
By Problem 46.1, we have 
P(t, T) = exp (-iT f(t, u)du) . 
Combining the above two equations, we get 
f3(T) 
1 (liT 2 
iT 
) 
(3(t) = P(t, T) exp 2 t 
'TJ (s, T)ds-
t 
'TJ(s, T)dWs 
. 
Letting t = 0 in the above equation gives 
f3(T) = P(;, T) exp (~faT 'T]2(s, T)ds- faT 'TJ(s, T)dWs) . 
Plugging (3(T) in Equation (46.9) and rearranging the terms leads to 
(46.9) 
P( t, T) 
( 
1 {t 
2 
t 
) 
~ 
= P(O, T) exp - 2 Jo 'T] (s, T)ds + Jo 'TJ(s, T)dWs . 
(b) By Theorem 45.1, the price at timeT of a zero-coupon bond with maturity Sis 
(46.10) 

SOLUTIONS 
661 
Since 
r(u) = f(u,u) = f(t,u) -lu a(8,u)7)(8,u)d8 + lu a(8,u)dW8 , 
we have 
ls r(u)du 
ls f(t, u)du-ls lu a(8, u)7J(8, u)d8du 
+ ls lu a(8, u)dW8 du. 
(46.11) 
By Theorem 10.2, we have 
s llu a(8, u)7)(8, u)d8du 
1T ls a(8, u)7)(8, u)dud8 + ls 1s a(s, u)7J(8, u)dud8 
11T 
1 {S 
2 t 
[772(8, T)- 7)2(8, S)] ds- 2 Jr 7)2(8, S)d8. 
(46.12) 
By Theorem 46.1, we have 
ls lu a(8, u)dW8 du 
1T ls a(8, u)dudWs + ls 1s a(8, u)dudWs 
1T [r/(8, T)- 7)(8, S)] dWs-ls 7)(8, S)dW8 â¢ 
(46.13) 
Plugging Equations (46.12) and (46.13) into Equation (46.11) gives 
s l r(u)du 
= 1s 
11s 
f(t, u)du- Z +-
7)2(8, S)d8 
T 
2 
T 
-Irs 7)(8, S)dWs. 
(46.14) 
Since J: 7)(8, S)dWs is a normal random variable independent of Â§y, com-
bining Equations ( 46.10) and ( 46.14) gives 
P(T S) = P(t, S) z 
' 
P(t,T)e. 

662 
INSTANTANEOUS FORWARD RATE MODELS 
(c) By Theorem 46.3 and the first part, we have 
V(t,T,S) 
~(t,T,~(T, S)) 
E 
[ ~(t, S) zl ~] 
Q 
~(t,T)e 
t 
~(t,S) E [ z] 
~(t,T) Q e 
~(t,S) (iT 
) 
~(t, T) exp 
t 1J(u, T)[17(u, T) -17(u, S)]du . 
This completes the proof. 
46.6. By Theorem 45.1, we have 
C(t,T,S,K) 
EQ [ (~(T, S)- K)+e- It r(u)dul Â§t] 
EQ [IA~(T,S)e-Itr(u)dulÂ§t] 
-KEQ [ JAe- It r(u)dul Â§t]' 
where A = { ~(T, S) > K}. Also by Theorem 45.1, we have 
Hence it follows from Problem 14.10 that 
EQ [IA~(T,S)e-I,Tr(u)dulÂ§t] 
EQ [IAEQ [e-Iir(u)dulÂ§r] e-Itr(u)dulÂ§t] 
EQ [EQ [IAe-Itr(u)due-Iir(u)dulÂ§r]lÂ§t] 
EQ [ JAe- I,s r(u)dul Â§t]. 
Plugging the above equation into Equation (46.15) gives 
C(t,T,S,K) = EQ [IAe-I,sr(u)dulÂ§t] 
-KEQ [ JAe- It r(u)dul Â§t]. 
Now from the assumption, we have 
a2 
r(u) = f(u, u) = f(t, u) + 2 (u- t) 2 + a(Wu- Wt)Â· 
(46.15) 
(46.16) 

SOLUTIONS 
663 
Hence by Theorem 46.1, we have 
1
8 r(u)du = 18 
18 a2 
18 
f(t, u)du + 
-(u- t) 2du +a 
(Wu- Wt)du 
t 
t 
2 
t 
18 
a2 
18 
t 
f(t, u)du + 6 (8- t)3 +a t (Wu- Wt)du 
1
8 
a2 
{8-t 
t 
f(t, u)du + 6 (8- t)3 +a Jo 
Wudu, 
where 
By Problem 46.5, we have 
where 
P(T 8 ) = P(t, 8) z 
' 
P(t,T)e ' 
a2 
Z = --(8- T)(8- t)(T- t)- (8- T)(Wr- Wt)Â· 
2 
Hence we have 
_ { _ 
ln :~(~7f) - ~(8- T)(8- t)(T- t)} 
A -
Wr-t < 
a(8 _ T) 
. 
Since Wu is independent of $t for all u ~ 0, we have 
EQ [ IAe- J,s r(u)dul $t] 
(46.17) 
EQ [fA exp ( -18 f(t, u)du- ~
2 (8- t) 3 - a 18-t Wudu) I $tl 
EQ [IA exp ( -18 f(t, u)du- ~
2 (8- t) 3 -a 18-t Wudu)] 
P(t, 8) exp (- ~
2 (8- t) 3) EQ [IA exp (-a 18-t Wudu) ]Â· (46.18) 
By Problem 40.6, we have 
In order to evaluate the expectation in Equation (46.18), we consider the probability 
measure P 1 defined by 
dP1 
exp (-a J:-t Wudu) 
( 
8 
t -
) 
exp -a J0 -
Wudu 
dQ 
EQ [exp (-a J08 -t Wudu) J 
exp ( ";,2 (8 - t)3) 

664 
INSTANTANEOUS FORWARD RATE MODELS 
Then we have 
Eq [IA exp ( -rr 1S-t Wudu)] 
exp ( ~
2 (S- t) 3) Eq [1A ~2] 
exp ( ~
2 (S- t) 3) Ep, [IA] 
exp ( ~
2 (S- t) 3) Pl(A). 
(46.19) 
To calculate P1 (A), we need to know the distribution of Wr-t under P1. To do that, 
we consider 
Ep, [e-wwT_, J 
Eq [e-WWT-t _ex_p --'--( ---:-rr-;;-f:_-_t w_-u--:-du--'-) l 
exp ( ""6 (S- t)3) 
exp (- ~
2 (S- t) 3) Eq [ exp ( -rr 1S-t Wudu- wWr-t) ]Â· 
By Problem 40.6, the above equation becomes 
By Problem 19.1, Wr-t is a normal random variable under P1 with mean 
rr 
2 
rr 
2 
f-tl=--(S-t) +-(S-T) 
2 
2 
and variance T- t. Then we have 
{ _ 
ln :~~~~J,) -
""z2 (S- T)(S- t)(T- t)} 
P1 (A) = 
P1 Wr-t < 
rr(S _ T) 
p 1 { Wr-t- p,1 < ln ~ 
+ ~(S- T)2(T- t)} 
vT- t 
rr(S- T)vT- t 
N(d1 ). 
(46.20) 
Now combining Equations ( 46.18), ( 46.19), and ( 46.20) gives 
Eq [ !Ae- f,s r(u)dui Â§t] = P(t, S)N(dl). 

BIBLIOGRAPHIC NOTES 
665 
In a similar way we can show that 
Plugging the above two equations into Equation (46.16) completes the proof. 
46.5 
Bibliographic Notes 
In this chapter, we presented the HJM framework and the HJM drift condition. For 
more information about HJM framework, readers are referred to Bingham and Kiesel 
(2004), Svoboda (2004), Musiela and Rutkowski (2005), Carmona (2006), Brigo and 
Mercurio (2006), and Filipovic (2009). 
Theorem 46.1 is a version of Fubini's theorem for stochastic integrals. A proof of 
this theorem can be found in Svoboda (2004, p166). For a multidimensional version 
of the stochastic Fubini theorem, readers are referred to Filipovic (2009, Theorem 
6.2). A proof of Theorem 46.2 can be found in Bingham and Kiesel (2004). For the 
rational behind the futures price (see Theorem 46.3), readers are referred to Filipovic 
(2009, Section 8.2). 


CHAPTER47 
LIBOR MARKET MODELS 
The short rate models and the HJM models introduced in the previous chapters con-
centrate on unobservable rates, including short rates and instantaneous forward rates. 
Brace et al. (1997) introduced LIBOR (London interbank offered rate) market mod-
els, which model the observable LIBOR rates directly. In this chapter, we introduce 
the LIBOR model and relevant concepts. 
47.1 
Basic Concepts and Facts 
Definition 47.1 (LIBOR). Let 8 > 0 and 0::; t < T. The 8-period forward LIBOR 
for the future date T prevailing at time t is defined as 
1 ( 
P(t,T) 
) 
L(t,T)=F(t;T,T+8)=-g P(t,T+ 8) -1 . 
Definition 47.2 (T-Forward Measure). Let Q be an equivalent martingale measure 
for the bond market. LetT> 0. Then the T-forward measure on (0, .#r) is defined 
as 
dQT 
1 
dQ 
P(O, T)f3(T)' 
Measure, Probability, and Mathematical Finance. 
667 
By Guojun Gan, Chaoqun Ma, and Hong Xie CopyrightÂ© 2014 John Wiley & Sons, Inc. 

668 
LIBOR MARKET MODELS 
where /3(Â·) is defined in Definition 45.3. 
Fort :::; T, the conditional expectation of d%' given fft. written as d% I , is 
g:, 
defined as 
dQT I 
[dQT I ] 
dQ g:, = EQ 
dQ 
fft . 
Definition 47.3 (LIBOR Market Model). Let 8 > 0 and M be a positive integer. 
LetTM = M8bethefinitetimehorizon. Let(O,ff,{fft: 0:::; t:::; TM},QTM) 
be the underlying filtered probability space, where QTM is the TM-forward measure. 
For every integer m = 0, 1, ... , M- 1, there is a deterministic bounded measurable 
function .>..(t, Tm), where Tm = m8. For every integer m = 0, 1, ... , M- 1, the 
initial forward LIBOR rate is given by 
L(O, Tm) = ~ ( P(O, Tm) - 1) . 
8 
P(O, Tm+d 
A LIBOR market model is defined recursively as follows. For i = M, M -
2, ... , 1 and t E [0, Ti_ 1J, we have 
L(t, Ti-d= L(O, Ti-d exp (-~fat .A2(s, Ti-dds +fat .>..(s, Ti-ddW_?'i) , 
8L(t, Ti-d 
aTi-l,Ti(t) = 8L(t,Ti-d + 1 .A(t,Ti-1), 
and 
W Ti-1 _ WT' 
{T 
( )d 
t 
-
t 
- Jo aTi-l,Ti s 
s, 
where the process {wt'- 1 
: 0 :::; t :::; Ti-l} is a Brownian motion under QTi- 1, 
which is defined as 
dQTi-1 
( 
1 {Ti-l 
{Ti-l 
) 
dQTi 
= exp -2 Jo 
a~i-l,Ti (s)ds + Jo 
aTi-l,Ti (s)dW_?'i 
. 
47.2 Problems 
47.1. Let Q be an equivalent martingale measure for the bond market and QT be the 
T-forward measure. Fort :::; T, show that 
P(t, T) 
P(O, T)/3(t). 
47.2. LetT* > 0. Suppose that for every T E [0, T*J, the forward rate process 
{f(t, T) : 0 :::; t :::; T} satisfies the HJM model 
df(t, T) = a(t, T) 1T a(t, s)dsdt + a(t, T)dWt. 

PROBLEMS 
669 
where {Wt : 0 :::; t :::; T} is a Brownian motion under the risk-neutral probability Q 
and the coefficients of dt and dWt satisfy the technical conditions given in Definition 
46.4. Let 
ry(t, T) = -iT a(t, u)du. 
Show that 
(a) For 0 :::; t :::; T :::; T*, 
dQTi 
( 
1 t 
t 
) 
dQ Â§, = exp -2 Jo ry2 (s, T)ds + Jo ry(s, T)dW8 
â¢ 
(b) The process {Wt : 0:::; t:::; T} given by 
Wt = Wt -lot ry(s, T)ds 
(47.1) 
is a Brownian motion under QT. 
(c) For 0 :::; t :::; T :::; T* and 0 :::; t :::; S :::; T*, 
P(t, S) 
P(O, S) 
=p-;-(t'-=, T='-) = P(O, T) x 
exp (-~lot [ry(s, S)- ry(s, T)]2ds +lot [ry(s, S)- ry(s, T)]dWI) 
and the T-bond discounted S-bond price process { ~~!;~~ : 0 :::; t :::; T} is a 
QT -martingale, where WI is as defined in Equation (47.1). 
(d) For 0 :::; t :::; T :::; T* and 0 :S t :S S :::; T*, the T-forward measure and 
S-forward measure satisfy 
P(t, S)P(O, T) 
P(t,T)P(O,S). 
47.3 (Arbitrage Price). Let Q be an equivalent martingale measure for the bond 
market. Let X be a T -contingent claim such that 
[ lXI] 
EQ f3(T) < oo. 
Show that 
and for 0:::; t :::; T, 

670 
LIBOR MARKET MODELS 
47.4 (Expectation Hypothesis). LetT* > 0. Suppose that for every T E [0, T*], the 
forward rate process {f(t, T) : 0 :::; t :::; T} satisfies the HJM model 
df(t, T) = u(t, T) iT u(t, s)dsdt + u(t, T)dWt, 
where {Wt : 0 :::; t :::; T} is a Brownian motion under the risk-neutral probability Q 
and the coefficients of dt and dWt satisfy the technical conditions given in Definition 
46.4. Suppose that u(t, T) E L~d([O, T] x 0). Show that fort :::; T, 
47.5. Let L(t, Ti), i = 0, 1, ... , M be LIBOR rates that satisfy the LIBOR market 
model given in Definition 47.3. Let m, n be integers in {0, 1, ... , M}. Show that 
fortE [0, Tm A Tn], 
{
dWtn- E~:~urk,Tk+,(t)dt, ifm < n; 
dWt= = 
dWtn, 
ifm = n; 
dWtn + I:;;'~nl urk,Tk+, (t)dt, 
if m > n, 
and fort E [0, Tm A Tn+l], 
47.6. Consider the LIBOR market model defined in Definition 47.3. Let 1 :::; k -1-
m:::; M. Show that 
(a) FortE [0, Tk A Tm], 
where 
u 
(t) = {2:::::1/ ur,,r,+, (t), 
if k < m; 
Tk,Tm 
'i;"""'k-1 
( ) 
- L..i=m ur,,r,+, t , if k > m. 
(b) The forward price process 
{ P(t, Tk) : 0 < t < T. AT } 
P(t,Tm) 
-
-
k 
m 
is a positive QTm -martingale. 

PROBLEMS 
671 
47.7. Consider the LIBOR market model defined in Definition 47.3. Let 1 :::; m < 
n :::; M. Show that the price at timet of a Tm-contingent claim X is given by 
47.8 (Caplet). Consider the LIBOR market model defined in Definition 47.3. Let 
m + 1 < n :::; M. Let X be a caplet with reset date Tn-1 and settlement date Tn. 
At the settlement date, the caplet pays the holder the difference between the LIB OR 
rate L(Tn_1, Tn) and the strike rate~~:; that is, the caplet pays the holder at time Tn 
the following amount 
8(L(Tn-1,Tn)- ~~:)+. 
Show that the price at time T m of the caplet is given by 
where 
ln L(Trn,Tn-d + l rTn-1 >.2(s T 
)ds 
d -
K 
2 JTrn 
' 
n-1 
1-
J 
/J~- 1 >.2 (s, Tn_I)ds 
and 
47.9 (Implied Money-Market Account). Consider the LIBOR market model defined 
in Definition 47.3. Let {,B*(Ti) : i = 0, 1, ... , M} be a discrete-time process defined 
as 
Show that 
if i = 0; 
ifi=1,2, ... ,M. 
(a) For every t E [0, TM -1], 
where 
EQTM [;J* (TM )P(O, TM) ~~t] 
exp ( -~ 1t ~2 (s)ds + 1t ~(s)dW?'M), 
M-1 
~(t) = L ar;,Ti+ 1 (t) 
i='l](t) 
with ry(t) = k ift E [Tk-1, Tk)Â· 
(b) For every m = 0, 1, ... , M, 

672 
LIBOR MARKET MODELS 
47.10 (Sport LIBOR Measure). Consider the LIBOR market model defined in Def-
inition 47.3. Let {,B*(Ti) : i = 0, 1, ... , M} be a discrete-time process defined 
as 
if i = 0; 
if i = 1, 2, ... , M. 
Let Q* be a probability measure on (!1, Â§TM) defined as 
dQ* 
* 
dQTM = (3 (TM )P(O, TM ). 
Show that 
(a) For every t E [0, TM-1], 
where 
dQ* 
1 
( 
1 rt 
rt 
) 
dQTM Â§, = exp -2 Jo ~2(s)ds + Jo ~(s)dW.?'M ' 
M-1 
~(t) = L ar;,Ti+ 1 (t) 
i=TJ(t) 
with ry(t) = k ift E [Tk-1, Tk)Â· 
(b) Form:::; n, the price at time Tm of a Tn-contingent claim X is given by 
47.3 Hints 
47.1. Follow the definition of equivalent martingale measures (Definition 45.6) and 
the definition of dd~ I 
(Definition 47.2). 
Â§, 
47.2. Part (a) follows from Problems 47.1 and 46.5. Part (b) follows from part (a) 
and Problem 37.4. Use the result of Problem 47.1 and part (a) to prove part (c). Use 
the result of Problem 47.1 to prove part (d). 
47.3. Use the result of Problem 47.1 and Bayes' formula (see Problem 14.20). 
47.4. Consider the forward rate process under the forward measure QT and apply 
Theorem 32.2. 
47.5. Follow the definition of LIBOR market models (Definition 47.3). 
47.6. To prove the first part, use the definitions of L(t, Tm-d and arm_,,Tm (t) (see 
Definition 47.3). Use the first part to prove the second part. 

SOLUTIONS 
673 
47.7. Use the results of Problems 47.2 and 47.3. 
47.8. Use the result of Problem 47.3. 
47 .9. To prove the first part, use the result of Problem 4 7.6 and consider 
and note that 
M-1 
M-1 
L ar,,Ti+l (s) = L O'T,,Ti+l (s). 
i=O 
i=7J(s) 
The second part can be proved similarly. 
47.10. To prove the first part, use the result of Problem 47.9 and note that 
To prove the second part, use the result of Problems 4 7. 7 and 14.20. 
47.4 Solutions 
47.1. 
By the definition of equivalent martingale measures, the process { P~~~~) 
0:::; t:::; T} is a martingale under Q. Hence we have 
dQTI 
[dQTI ] 
[ P(T,T) I ] 
P(t,T) 
dQ Â§t = Eq dQ $t = Eq P(O, T)f3(T) $t = P(O, T)f3(t). 
This completes the proof. 
47.2. 
(a) This result follows from Problems 47.1 and 46.5 directly. 
(b) This result follows from part (a) and Problem 37.4 directly. 

674 
LIBOR MARKET MODELS 
(c) By Problem 4701 and part (a), we have 
P(t, S) 
--
P(t, T) 
dQsl 
P(O,S) CiQ ff, 
P(O, T) dQT I 
dQ Â§, 
P(O, S) 
P(O, T) X 
exp (-~fat [ry2(s, S) -ry2(s, T)]ds +fat [ry(s, S) -ry(s, T)]dW8 ) 
P(O, S) 
P(O, T) x 
exp (-~fat [rJ(s, S) -ry(s, TWds +fat [ry(s, S) -ry(s, T)]dW.?') 
0 
(d) By Problem 4701, we have 
dQS I 
dQS I 
dQ I 
dQT fft = 
dQ 
fft dQT fft 
P(t, S)P(O, T) 
P(t, T)P(O, S) 
0 
This completes the proof. 
47.3. By the assumption, we have 
[ 
lXI 
] 
EQr [lXI] = EQ P(O, T)f3(T) < ooo 
By Problems 14020 and 47.1, we have 
This completes the proof. 
EQ [ P(o,Af3(T) I Â§t] 
EQ [ d~ I Â§t] 
~EQ[~IÂ§t] 
P(t,T) 
P(O,T)f3(t) 
f3(t)EQ [~I Â§t] 
P(t, T) 
47.4. By part (b) of Problem 4702, the process {Wt : 0 :::; t :::; T} given by 
Wt = Wt -fat ry(s, T)ds 

SOLUTIONS 
675 
is a Brownian motion under QT. Then we have 
f(t, T) = f(O, T) +fat a(s, T)dW7', 
0:::; t:::; T. 
By the assumption that a(t, T) E L;d([O, T] x D) and Theorem 32.2, the forward 
rate process {f(t, T) : 0:::; t:::; T} is a martingale under QT. Hence 
EQr[r(T)[fft] = EQr[f(T,T)[fft] = f(t,T). 
This completes the proof. 
47.5. By the definition of LIBOR market models, we have fori = 1, 2, ... , M, 
(47.2) 
If rn < n, summing both sides of the above equation from rn + 1 to n gives 
i=m+l 
i=m+l 
i=m+l 
or 
n 
dWt= = dWt" ~ L 
O'Ti-l,Ti (t)dt, 
t E [0, Tm]Â· 
i=m+l 
If rn > n, summing both sides of Equation (47.2) from n + 1 torn gives 
rn 
rn 
m 
i=n+l 
i=n+l 
i=n+l 
or 
m 
dWt" = dwt= ~ L ari_,,Ti (t)dt, 
t E [0, TnlÂ· 
i=n+l 
Hence we have 
{
dWt" ~ 2:::~:;;, D'Tk,Tk+ 1 (t)dt, 
if rn < n; 
dWt= = 
dWt", 
ifm = n; 
dWt" +I:;;'=; D'Tk,Tk+ 1 (t)dt, 
if rn > n, 
(47.3) 
Also by the definition of LIB OR market models, fori = 1, 2, ... , M, we have 
or 
(47.4) 

676 
LIBOR MARKET MODELS 
Combining Equations (47.3) and (47.4) gives 
dL t 'T 
{.A(t, Tm)dWtn+l - >.(t, Tm) L:Z=m+1 ark,Tk+l (t)dt, 
if m < n; 
( ' m) = 
>.(t 'T )dWTn+l 
if m = nÂ·, 
L(t T ) 
' 
m 
t 
' 
' m 
>.(t, Tm)dWtn+l + >.(t, Tm) L:~n+ 1 ark,Tk+l (t)dt, 
if m > n. 
This completes the proof. 
47.6. 
(a) By the definition of L(t, Tm_l), we have 
P(t, Tm-d 
( 
) 
P(t, Tm) = 8L t, Tm-1 + 1, 
t E [0, Tm-1], 
which gives 
Since 
and 
we have 
d( P(t,Tm-d)='dL(,.,.., 
) 
P(t, Tm) 
u 
t, .Lm-1 . 
8L(t, Tm-d 
'( ,.,.., 
) 
( 
) 
/\ t,.Lm-1 
8Lt,Tm-1 +1 
P(t,Tm) 
P( T 
) 8L(t, Tm_l)>.(t, Tm_l), 
t, m-1 
Solving the above stochastic differential equation gives 
P(t, Tm-d 
P(O, Tm-d 
------'---'----------,-"- = 
X 
P(t, Tm) 
P(O, Tm) 
exp ( -~ 1t aL_ 1,r,.Js)ds + 1t arm-l,Tm(s)dW[m). (47.5) 
If k < m, multiplying both sides of Equation ( 4 7 .5) from k + 1 to m gives 
rrm P(t, Ti_l) = rrm P(O, Ti-d x 
P(t T) 
P(O 'TÂ·) 
i=k+1 
' ' 
i=k+1 
' ' 

SOLUTIONS 
677 
or 
But by Problem 47.5, we have for every i < m, 
m-1 
dWt; = dWt"'- L ari,TH 1 (t)dt. 
j=i 
We have 
Therefore, 
The case when k > m can be proved similarly. 
(b) By the assumption that .>.(t, Ti) is bounded, we know that a(Tk, Tm) satisfies 
the Novikov's condition. Hence it follows from Problem 37.2 that the forward 
price process 
{ P(t, Tk) 
} 
P(t, Tm) : 0 ~ t ~ n 1\ Tm 
is a positive QTm_martingale. 
This completes the proof. 
47.7. By Problem 47.3, the price at timet of the Tm-contingent claim X is given by 
(47.6) 

678 
LIBOR MARKET MODELS 
By Problem 47.2, we have 
P(t, Tm)P(O, Tn) 
( 
) ( 
) , t E [0, T m]Â· 
P t,Tn P O,Tm 
Hence we have 
It follows from Problem 14.20 that 
(47.7) 
Combining Equations (47.6) and (47.7) gives the price 
This completes the proof. 
47.8. By Problem 47.3, the price at time Tm of the caplet is calculated as 
P(Tm, Tn)Eqrn [ J(L(Tn-1, Tn)- K)+l g-r,.] 
JP(Tm, Tn)Eqrn [ (L(Tn-1, Tn)- K)+l g-r,.]. 
By Definition 47.3, we have 
and 

SOLUTIONS 
679 
which give 
Since 
L(Tn-1, Tn_I) 
L(Tm, Tn_I) Â· 
exp (-~ {Tn-
1 A2 (s, Tn_I)ds + 1Tn-
1 A(s, Tn-1)dWin) . 
}Tm 
Tm 
and {Win - Wj.'n : Tm :S s :S Tn-d is independent of ffrm, we know that 
L(Tn-1, Tn-I) is independent of ffr m. Hence 
Now let 
V(Tm, Tn-1, Tn) 
JP(Tm, Tn)EQrn [(L(Tn-1, Tn)- r.)+] 
JP(Tm, Tn) x EQTn 
[ ( L(Tm, Tn_ 1 )e-~ /J;;.- 1 .A 2 (s,Tn_l)ds+ /J;;.- 1 .A(s,Tn_i)dWI'" _ ,_) + ]Â· 
A = { L(Tm, Tn_I)e-~ /J;;.- 1 .A2 (s,Tn-dds+ /J;;.- 1 .A(s,Tn_l)dWI'" > ,_} 
m 
> -d2 
Â· 
{ J'j:'n- 1 A(s, Tn_I)dWI'n 
} 
V 
fJ~- 1 A2 (s, Tn_I)ds 
Since 
/J"- 1 A(s, Tn_I)dWJn 
Z = ---'j.m~===== 
V 
J:~- 1 A2(s, Tn_I)ds 
is a normal random variable with mean 0 and variance 1 under QTn, we have 
and 

680 
LIBOR MARKET MODELS 
where 
Hence 
bP(Trn, Tn)[EQTn [L(Tn-1, Tn_l)lA]- "'EQr, [IAJl 
bP(Trn, Tn)[L(T rn, Tn_l)N(dl)- "'N(d2)]. 
This completes the proof. 
47.9. 
(a) By Definition 47.1, we have 
1 
1+6L(T;-],T;_J)= 
( 
)' 
i=1,2, ... ,M, 
P T;_ 1 , T; 
leads to 
M 
1 
(3*(TM) =}] P(T;_ 1,T;)' 
By Problem 47.6, we have for every i = 1, 2, ... , !vi, 
1 
P(O, T;-1) 
~~~~= 
X 
P(T;_ 1 , T;) 
P(O, T;) 
(47.8) 
exp ( -~ .iT,_
1 al_,,T, (8)ds +for,_, or,_, ,T, (s)dw;Â·) . 
Plugging the above equation in Equation (47.8) gives 
(3*(TM) = P(O 1T ) X 
,1\1 
exp ( -~ t 1T,_
1 at_ 1 ,r,(s)ds + t 1T,_
1 ay,_ 1 ,r,(8)dw;). 
By Problem 47.5, we have for every i = 0, 1, ... , !vi- 1, 
M-1 
druT; _ dTXTTM 
~ 
( )d 
vv 8 
-
n
8 
-
L..., Oyk,Tk+l 8 8. 
k=i 
Then we have 
1 
( 
1 1\1 ~Â·T,_I 
P(O T ) exp -2 L 
a},_,,T,(s)ds-
' 
M 
i=l. 0 
(47.9) 

SOLUTIONS 
681 
Now for every s E [0, TM], let 
a . 
.(s) = {<Jr,_,,r,(s), 
T,_,,T, 
O 
' 
if s E [0, Ti~I); 
if s E [Ti~l, TM], 
Then we have 
{Ti-l 
{TM 
lo 
<J~,_,,T, (s)ds = lo 
(j-~i-l,Ti (s)ds, 
and 
loT,_, <Jy,_ 1 ,T, (s)dW[' = laTM ay,_ 1 ,T, (s)dW[M. 
Plugging the above three equations into Equation (47.9) gives 
or 
(3*(TM) 
= 
P(o\M) exp ( -~ t, forM o-~,_,,T, (s)ds-
M 
M 1
TM 
L L 
ay,_,,T, (s)ark-J,Tk(s)ds + 
i=l k=i+l 0 
t {TM ay,_ 1,r,(s)dW[M) 
i=l Jo 
laTM t, ay,_ 1 ,T, (s)dW[M) . 
Since Try(s)~l :S: s < Try(s)â¢ we have 
M 
M~l 
(47.10) 
M 
l..:ar,_,,r,(s) = L 
<Jr,_,,r,(s) = L <JT,,TH 1 (s) = ~(s). 
i=l 
i=ry(s)+l 
i=ry(s) 
Thus from Equation (47.10) and Problem 37.2, we get 
EQTM [(3* (TM )P(O, TM) lfft] 
EQrM [ exp ( -~ loTM ~2 (s)ds + loTM ~(s)dW[M) I fftl 
exp (-~lot ~ 2 (s)ds +lot ~(s)dW[M). 

682 
LIBOR MARKET MODELS 
(b) By a similar argument used in the proof of the first part, we have 
1 
1 
Tm 
m 
( 
( 
)
2 
P(O, Tm) exp 
- 21 ~ 
G-r;_,,T, (s) 
ds+ 
{Tm m 
) 
Jo 
~ 
G-r;_ 1 ,T; (s)dW[= 
1 
1 
m 
ex 
--
a . 
. s 
ds-
( 
T 
(
m 
)2 
P(O, Tm) 
p 21 
~ T,_,,T, ( ) 
(47.11) 
Note that 
where 
M-1 
M 
arm,TM (s) = L ar;,Ti+l (s) = L G-r,_,,T; (s), 
s E [0, TmlÂ· 
i=m 
i=m+l 
Equation ( 4 7.11) becomes 
(47.12) 

SOLUTIONS 
683 
But by the first item, we have 
which gives 
EqTM [,B*(TM)I$r,nl 
exp ( -~ J0Tm E2(s)ds + J0Tm E(s)dWIM) 
P(O,TM) 
Also by Problem 47.6, we have 
1 
P(O, Tm) 
=-:c=---=--:- = 
X 
P(Tm, TM) 
P(O, TM) 
(47.13) 
exp ( -~ 1Tm a~m,TM(s)ds + 1Tm aTm,TM(s)dW_?'M) (47.14) 
Combining Equation (47.13) and Equation (47.14) gives 
(47.15) 
Note that for every s E [0, T m], 
M 
M 
E(s)- arm,TM(s) = l:ar;-l,T;(s)- L ari-l,T;(s) 
i=l 
i=m+l 
m L ari-l,Ti (s). 
(47.16) 
i=l 
Combining Equations (47.12), (47.15), and (47.16), we get 
This completes the proof. 
47.10. 

684 
LIBOR MARKET MODELS 
(a) Since 
it follows from Problem 47.9 that 
dQ* I 
( 1 rt 
rt 
) 
dQTM Â§, = exp -2 Jo L:2(s)ds + Jo L:(s)dW.?'M 
. 
(b) By Problem 47.7, the price at time Tm of a Tn-contingent claim X is given by 
Hence we only need to show that 
But by Problems 14.20 and 47.9, we have 
EQÂ· [ wfrn) I Â§Tm] 
[ 
X 
~I ] 
EQTM 
li*{T;J dQTM Â§T 
m 
EQTM [ d~~~ I Â§Tm] 
EQTM [ ~j3*(TM )P(O, TM )I Â§r=] 
{3* (Tm)P(O,TM) 
P(Tm,TM) 
P(Tm,TM)EQTM [x~lÂ§r=] 
/3*(Tm) 
(47.18) 
Since X is a Tn -contingent claim, then X is Â§Tn -measurable. Then by Problem 
14.10, we have 
But by Problem 47.9, we have 

BIBLIOGRAPHIC NOTES 
685 
Combining the above two equations gives 
EQTM [x~**~~:ilg;r=] =EQTM [P(T:TM)Ig;r=] Â· 
(47.19) 
Equation (47.17) follows from Equations (47.18) and (47.19). 
This completes the proof. 
47.5 Bibliographic Notes 
In this chapter, we introduced the LIBOR market model, which is also referred to as 
the BGM model. The model is a collection of dynamics for the forward LIB OR rates 
that traders are used to working with. For more information about LIBOR market 
models, readers are referred to Rebonato (2002), Hunt and Kennedy (2004), Bing-
ham and Kiesel (2004), Musiela and Rutkowski (2005), Hull (2008), and Filipovic 
(2009). 


References 
Ahn, S., Bae, H.-0., Koo, H., and Lee, K. (2011). A survey on american options: 
Old approaches and new trends. Bulletin of the Korean Mathematical Society, 
48:791-812. 
Allen, E. (2007). Modeling with Ito Stochastic Differential Equations. Springer, 
New York. 
Amin, K. and Khanna, A. (1994). Convergence of american option values from 
discrete- to continuous-time financial models. Mathematical Finance, 4(4):289-
304. 
Andreasen, J., Jensen, B., and Poulsen, R. (1998). Eight valuation methods in fi-
nancial mathematics: The Black-Scholes formula as an example. Mathematical 
Scientist, 23(1):18-40. 
Applebaum, D. (2004). Levy processes- from probability to finance and quantum 
groups. Notices of the American Mathematical Society, 51(11):1336-1347. 
Applebaum, D. (2009). Levy Processes and Stochastic Calculus. Cambridge Uni-
versity Press, Cambridge, UK. 
Ash, R. and Doleans-Dade, C. (1999). Probability and Measure Theory. Academic 
Press, New York. 
687 

688 
REFERENCES 
Athreya, K. and Lahiri, S. (2006). Measure Theory and Probability Theory. Springer, 
New York. 
Back, K. (2005). A Course in Derivative Securities: Introduction to Theory and 
Computation. Springer Finance. Springer, New York. 
Back, K., Bielecki, T., Hipp, C., Peng, S., and Schachermayer, W. (2004). Stochastic 
Methods in Finance. Springer, New York. 
Bailey, N. (1964). The Elements of Stochastic Processes with Applications to the 
Natural Sciences. Wiley, New York. 
Balakrishnan, N. and Nevzorov, V. (2003). A Primer on Statistical Distributions. 
Wiley, New York. 
Baldi, P., Mazliak, L., and Priouret, P. (2002). Martingales and Markov Chains: 
Solved Exercises and Elements of Theory. Chapman & HalVCRC, Boca Raton, 
FL. 
Barone-Adesi, G. (2005). The saga of the american put. Journal of Banking & 
Finance, 29(11):2909-2918. 
Barone-Adesi, G. and Whaley, R. (1987). Efficient analytic approximation of Amer-
ican option values. Journal of Finance, 42(2):301-320. 
Bartoszynski, R. and Niewiadomska-Bugaj, M. (2007). Probability and Statistical 
Inference. Wiley, Hoboken, NJ. 
Bass, R. (1998). Diffusions and Elliptic Operators. Springer, New York. 
Baxter, M. (1997). General interest-rate models and the universality of HJM. In 
Mathematics of Derivative Securities. Cambridge University Press, Cambridge, 
UK. 
Baxter, M. and Rennie, A. (1996). Financial Calculus: An Introduction to Derivative 
Pricing. Cambridge University Press, Cambridge, UK. 
Beichelt, F. (2006). Stochastic Processes in Science, Engineering and Finance. 
Chapman & HalVCRC, Boca Raton, FL. 
Bensoussan, A. (1984). On the theory of option pricing. Acta Applicandae Mathe-
maticae, 2:139-158. 
Bertoin, J. (1996). Levy Processes. Cambridge University Press, Cambridge, UK. 
Bhar, R. and Hamori, S. (2005). Empirical Techniques in Finance. Springer, New 
York. 
Bhattacharya, R. and Waymire, E. (2007). A Basic Course in Probability Theory. 
Springer, New York. 

REFERENCES 
689 
Bhattacharya, R. and Waymire, E. (2009). Stochastic Processes with Applications. 
Society for Industrial and Applied Mathematics, Philadelphia. 
Bichteler, K. (2002). Stochastic Integration with Jumps. Cambridge University Press, 
Cambridge, UK. 
Billingsley, P. (1986). Probability and measure. Wiley, 2nd edition. 
Billingsley, P. (1995). Probability and measure. Wiley, New York, 3rd edition. 
Billingsley, P. (1999). Convergence of Probability Measures. Wiley, New York, 2nd 
edition. 
Bingham, N. and Kiesel, R. (2004). Risk-Neutral Valuation: Pricing and Hedging 
of Financial Derivatives. Springer, New York, NY, 2nd edition. 
Bjork, T. (2009). Arbitrage Theory in Continuous Time. Oxford University Press, 
Oxford, UK, 3rd edition. 
Bjork, T., di Masi, G., Kabanov, Y., and Runggaldier, W. (1997). Towards a general 
theory of bond markets. Finance and Stochastics, 1:141-174. 
Black, F., Derman, E., and Toy, W. (1990). A one-factor model of interest rates and 
its application to treasury bond options. Financial Analysts Journal, 46(1):33-39. 
Black, F. and Karasinski, P. (1991). Bond and option pricing when short rates are 
lognormal. Financial Analysts Journal, 47(4):52-59. 
Black, F. and Scholes, M. (1973). The pricing of options and corporate liabilities. 
Journal of Political Economy, 81(3):637-654. 
Borak, S., Hardie, W., and Cabrera, B. L. (2010). Statistics of Financial Markets: 
Exercises and Solutions. Springer, New York. 
Borodin, A. and Salminen, P. (2002). Handbook of Brownian Motion - Facts and 
Formulae. Birkhauser, Boston, 2nd edition. 
Borokov, A. (1999). Mathematical Statistics. CRC Press, Boca Raton, FL. 
Brace, A., Gatarek, D., and Musiela, M. (1997). The market model of interest rate 
dynamics. Mathematical Finance, 7(2): 127-154. 
Brandimarte, P. (2006). Numerical Methods in Finance and Economics: A MATLAB-
Based Introduction. Wiley, New York, 2nd edition. 
Brigo, D. and Mercurio, F. (2006). Interest Rate Models - Theory and Practice. 
Springer, New York, 2nd edition. 
Briys, E., Bellalah, M., Mai, H., and de Varenne, F. (1998). Options, Futures and 
Exotic Derivatives: Theory, Application and Practice. Wiley, New York. 

690 
REFERENCES 
Broadie, M. and Glasserman, P. (1997). Pricing american-style securities using sim-
ulation. Journal of Economic Dynamics and Control, 21: 1323-1352. 
Brzezniak, Z. and Zastawniak, T. (1999). Basic Stochastic Processes: A Course 
Through Exercises. Springer, New York. 
Buchanan, J. (2006). An Undergraduate Introduction to Financial Mathematics. 
World Scientific Publishing, Singapore. 
Cairns, A. (2004). Interest Rate Models: An Introduction. Princeton University 
Press, Princeton, NJ. 
Cannon, J. (1984). The One-Dimensional Heat Equation, volume 23 of Encyclope-
dia of Mathematics and Its Applications. Cambridge University Press, Cambridge, 
UK. 
Capasso, V. and Bakstein, D. (2005). An Introduction to Continuous-Time Stochastic 
Processes: Theory, Models, and Applications to Finance, Biology, and Medicine. 
Springer, New York. 
Capinski, M. and Kopp, P. (2007). Measure, Integral and Probability. Springer, New 
York, 2nd edition. 
Capinski, M. and Zastawniak, T. (2000). Probability through Problems. Springer, 
New York. 
Capinski, M. and Zastawniak, T. (2003). Mathematics for Finance: An Introduction 
to Financial Engineering. Springer, New York. 
Carmona, R. (2006). Interest Rate Models: an Infinite Dimensional Stochastic Anal-
ysis Perspective. Springer, New York, NY. 
<;inlar, E. (1974). Introduction to Stochastic Processes. Prentice Hall, New York, 
NY. 
<;inlar, E. (2011). Probability and Stochastics. Springer, New York, NY. 
Chan, N. and Wong, H.-Y. (2006). Simulation Techniques in Financial Risk Man-
agement. Wiley, New York. 
Chaumont, L. and Yor, M. (2003). Exercises in Probability: A Guided Tour from 
Measure Theory to Random Processes, via Conditioning. Cambridge University 
Press, Cambridge, UK. 
Cherubini, U., Luciano, E., and Vecchiato, W. (2004). Copula Methods in Finance. 
Wiley, New York. 
Chung, F. and Lu, L. (2006). Concentration inequalities and martingale inequalities: 
A survey. Internet Mathematics, 3(1):79-127. 

REFERENCES 
691 
Chung, K. (2000). A Course in Probability Theory. Academic Press, Singapore, 3rd 
edition. 
Chung, K. and Aitsahlia, F. (2007). Elementary Probability Theory: With Stochastic 
Processes and an Introduction to Mathematical Finance. Springer, New York. 
Chung, K. and Williams, R. (1990). 
Introduction to Stochastic Integration. 
Birkhiiuser, Boston, 2nd edition. 
Cont, R. and Tankov, P. (2003). Financial Modelling with Jump Processes. Chapman 
& HalVCRC Financial Mathematics Series. Chapman & HalVCRC, Boca Raton, 
FL. 
Conze, A. and Viswanathan (1991). Path dependent options: The case of lookback 
options. The Journal of Finance, 46(5):1893-1907. 
Cox, J., Ingersoll, Jr., J., and Ross, S. (1985). A theory of the term structure of 
interest rates. Econometrica, 53(2):385-407. 
Cox, J., Ross, S., and Rubinstein, M. (1979). Option pricing: A simplified approach. 
Journal of Financial Economics, 7(3):229-263. 
Dana, R.-A. and Jeanblanc, M. (2007). Financial Markets in Continuous Time. 
Springer, New York, 2nd edition. 
DasGupta, A. (2010). Fundamentals of Probability: A First Course. Springer, New 
York. 
Dekking, F., Kraaikamp, C., Lopuhaa, H., and Meester, L. (2005). A Modem Intro-
duction to Probability and Statistics. Springer, New York. 
Delbaen, F. and Schachermayer, W. (2006). The Mathematics of Arbitrage. Springer, 
New York. 
Dineen, S. (2005). Probability Theory in Finance: A Mathematical Guide to the 
Black-Scholes Formula. American Mathematical Society, Providence, Rl. 
Dokuchaev, N. (2007). Mathematical Finance: Core Theory, Problems and Statisti-
cal Algorithms. Routledge, London. 
Doob, J. (1990). Stochastic Processes. Wiley, New York. 
Dothan, L. (1978). On the term structure of interest rates. Journal of Financial 
Economics, 6(1):59-69. 
Dudley, R. (2002). Real Analysis and Probability. Cambridge University Press, 
Cambridge, UK, 2nd edition. 
Duffie, D. (2001). Dynamic Asset Pricing Theory. Princeton University Press, 
Princeton, NJ, 3rd edition. 

692 
REFERENCES 
Duffy, D. (2006). Finite Difference Methods in Financial Engineering: A Partial 
Differential Equation Approach. Wiley, New York. 
Durrett, R. (1996). Stochastic Calculus: A Practical Introduction. CRC Press, Boca 
Raton, FL. 
Durrett, R. (2010). Probability: Theory and Examples. Cambridge University Press, 
Cambridge, UK, 4th edition. 
Eales, B. and Choudhry, M. (2003). Derivative Instruments: A Guide to Theory and 
Practice. Butterworth-Heinemann, Oxford, UK. 
Ekstrand, C. (2011). Financial Derivatives Modeling. Springer, New York. 
Elliott, R. and Kopp, P. (2005). Mathematics of Financial Markets. Springer, New 
York. 
Etheridge, A. (2002). A Course in Financial Calculus. Cambridge University Press, 
Cambridge, UK. 
Ethier, S. and Kurtz, T. (1986). Markov Processes: Characterization and Conver-
gence. Wiley, New York. 
Evans, M., Hastings, N., and Peacock, B. (2000). Statistical Distributions. Wiley, 
Hoboken, NJ, 3rd edition. 
Feller, W. (1968). An Introduction to Probability Theory and Its Applications, Vol-
ume I. Wiley, New York. 
Filipovic, D. (2009). Term-Structure Models: A Graduate Course. Springer, New 
York. 
Follmer, H. and Schied, A. (2004). Stochastic Finance: An Introduction in Discrete 
Time 2. Walter de Gruyter, Berlin, 2nd edition. 
Forbes, C., Evans, M., Hastings, N., and Peacock, B. (2011). Statistical Distribu-
tions. Wiley, Hoboken, NJ, 4th edition. 
Franke, J., Hardie, W., and Hafner, C. (2004). Statistics of Financial Markets: An 
Introduction. Springer, New York. 
Friedman, A. (1975). Stochastic Differential Equations and Applications, Volume I. 
Academic Press, New York. 
Friedman, A. (1976). Stochastic Differential Equations and Applications, Volume 2. 
Academic Press, New York. 
Goldman, M., Sosin, H., and Gatto, M. (1979). Path-dependent options: Buy at the 
low, sell at the high. Journal of Finance, 34(5):1111-1127. 

REFERENCES 
693 
Grimmett, G. and Stirzaker, D. (2001). One Thousand Exercises in Probability. 
Oxford University Press, Oxford, UK. 
Grinstead, C. and Snell, J. (1997). Introduction to Probability. American Mathemat-
ical Society, Providence, Rl, 2nd edition. 
Gusak, D., Kukush, A., Kulik, A., Mishura, Y., and Pilipenko, A. (2010). Theory 
of Stochastic Processes: With Applications to Financial Mathematics and Risk 
Theory. Springer, New York. 
Gut, A. (2007). Probability: A Graduate Course. Springer, New York. 
Gut, A. (2009). An Immediate Course in Probability. Springer, New York, 2nd 
edition. 
Haas, M. and Pigorsch, C. (2011). Financial economics: Fat-tailed distributions. 
In Meyers, R. A., editor, Complex Systems in Finance and Econometrics, pages 
308-339. Springer, New York. 
Hall, P. and Heyde, C. (1980). Martingale Limit Theory and Its Application. Aca-
demic Press, Singapore. 
Haug, E. (2006). The Complete Guide to Option Pricing Formulas. McGraw-Hill, 
New York, 2nd edition. 
Heath, D., Jarrow, R., and Morton, A. (1992). Bond pricing and the term structure of 
interest rates: A new methodology for contingent claims valuation. Econometrica, 
60(1):77-105. 
Herrlich, H. (2006). Axiom of Choice. Springer-Verlag, New York. 
Higham, D. (2004). An Introduction to Financial Option Valuation: Mathematics, 
Stochastics and Computation. Cambridge University Press, Cambridge, UK. 
Ho, T. and Lee, S. (1986). Term structure movements and pricing interest rate con-
tingent claims. Journal of Finance, 41(5):1011-1029. 
Hobson, D. (2004). A survey of mathematical finance. Proceedings of the Royal So-
ciety of London. Series A, Mathematical and Physical Sciences, 460(2052):3369-
3401. 
Hoek, J. and Elliott, R. (2006). Binomial Models in Finance. Springer, New York. 
Hoel, P., Port, S., and Stone, C. (1972). 
Introduction to Stochastic Processes. 
Houghton-Mifflin, Boston. 
Houthakker, H. and Williamson, P. (1996). The Economics of Financial Markets. 
Oxford University Press, Oxford, UK. 
Hsu, H. (1996). Schaum's Outline of Probability, Random Variables, and Random 
Processes. McGraw-Hill, New York. 

694 
REFERENCES 
Hull, J. (2001). Fundamentals of Futures and Options Markets. Prentice Hall, New 
York, 4th edition. 
Hull, J. (2008). Options, Futures, and Other Derivatives. Prentice Hall, New York, 
7th edition. 
Hull, J. and White, A. (1990). Pricing interest-rate-derivative securities. The Review 
of Financial Studies, 3(4):573-592. 
Hunt, G. (1956). Some theorems concerning brownian motion. Transactions of the 
American Mathematical Society, 81(2):294-319. 
Hunt, P. and Kennedy, J. (2004). Financial Derivatives in Theory and Practice. 
Wiley, New York, revised edition. 
Iacus, S. (2008). Simulation and Inference for Stochastic Differential Equations: 
with R Examples. Springer, New York. 
Ikeda, N. and Watanabe, S. (1981). Stochastic Differential Equations and Diffusion 
Processes. North Holland, Amsterdam. 
Ito, K. (1944). Stochastic integral. Proceedings of the Imperial Academy, 20(8):519-
524. 
Jacka, S. (1991). Optimal stopping and the american put. Mathematical Finance, 
1(2):1-14. 
Jacod, J. and Protter, P. (2004). Probability Essentials. Springer, New York, 2nd 
edition. 
James, P. (2003). Option Theory. Wiley, New York. 
Jeanblanc, M., Yor, M., and Chesney, M. (2009). Mathematical Methods for Finan-
cial Markets. Springer, New York. 
Jiang, L. (2005). Mathematical Modeling and Methods of Option Pricing. World 
Scientific Publishing, Singapore. 
Jin, Y. and Glasserman, P. (200 1 ). Equilibrium positive interest rates: A unified view. 
The Review of Financial Studies, 14(1):187-214. 
Johnson, N., Kemp, A., and Kotz, S. (2005). Univariate Discrete Distributions. 
Wiley, Hoboken, NJ, 3rd edition. 
Johnson, N., Kotz, S., and Balakrishnan, N. (1994). Continuous Univariate Distri-
butions, Volumn 1. Wiley, Hoboken, NJ, 2nd edition. 
Johnson, N., Kotz, S., and Balakrishnan, N. (1995). Continuous Univariate Distri-
butions, Volumn 2. Wiley, Hoboken, NJ, 2nd edition. 

REFERENCES 
695 
Jondeau, E., Poon, S.-H., and Rockinger, M. (2007). Financial Modeling under 
Non-Gaussian Distributions. Springer, New York. 
Kallenberg, 0. (1997). Foundations of Modern Probability. Springer, New York. 
Ka11ianpur, G. and Karandikar, R. (1999). Introduction to Option Pricing Theory. 
Birkhliuser Boston, Boston. 
Kannan, D. (1979). Introduction to Stochastic Processes. Elsevier, New York. 
Kannan, D. and Lakshmikantham, V. (2001). Handbook of Stochastic Analysis & 
Applications. CRC Press, Boca Raton, FL. 
Kao, E. (1997). An Introduction to Stochastic Processes. Duxbury Press, Pacific 
Grove, CA. 
Karatzas, I. (1988). On the pricing of american options. Applied Mathematics and 
Optimization, 17:37-60. 
Karatzas, I. and Shreve, S. (1988). Brownian Motion and Stochastic Calculus. 
Springer, New York. 
Karatzas, I. and Shreve, S. (1991). Brownian Motion and Stochastic Calculus. 
Springer, New York, 2nd edition. 
Karatzas, I. and Shreve, S. (2001). Methods of Mathematical Finance. Springer, 
New York. 
Karlin, S. and Taylor, H. (1975). A First Course in Stochastic Processes. Academic 
Press, Singapore, 2nd edition. 
Karlin, S. and Taylor, H. (1981). A Second Course in Stochastic Processes. Aca-
demic Press, Singapore. 
Katz, J. and McCormick, D. (2005). Advanced Option Pricing Models. McGraw-
Hill, New York. 
Kim, I. (1990). The analytic valuation of american options. Review of Financial 
Studies, 3(4):547-572. 
Kinney, J. (2009). A Probability and Statistics Companion. Wiley, Hoboken, NJ. 
Klebaner, F. (2005). Introduction to Stochastic Calculus with Applications. World 
Scientific Publishing, Singapore, 2nd edition. 
Klenke, A. (2006). Probability Theory: A Comprehensive Course. Springer, New 
York. 
Kloeden, P. and Platen, E. (1995). Numerical Solution to Stochastic Differential 
Equations. Springer, New York, 2nd (corrected) edition. 

696 
REFERENCES 
Kolb, R. (1993). Financial Derivatives. Prentice Hall Press, New York. 
Kopp, E. (2011). From Measures to Ito Integrals. Cambridge University Press, 
Cambridge, UK. 
Koralov, L. and Sinai, Y. (2007). Theory of Probability and Random Processes. 
Springer, New York, 2nd edition. 
Kom, R., Kom, E., and Kroisandt, G. (2010). Monte Carlo Methods and Models in 
Finance and Insurance. Chapman & Hall/CRC, Boca Raton, FL. 
Krishnan, V. (2006). Probability and Random Processes. Wiley, Hoboken, NJ. 
Kuo, H.-H. (2006). Introduction to Stochastic Integration. Springer, New York. 
Kwok, Y.-K. (2008). Mathematical Models of Financial Derivatives. Springer, New 
York, 2nd edition. 
Kyprianou, A. (2006). Introductory Lectures on Fluctuations of Levy Processes with 
Applications. Springer, New York. 
Lamberton, D. and Lapeyre, B. (1996). Introduction to Stochastic Calculus Applied 
to Finance. Chapman & Hall/CRC, Boca Raton, FL. translated by N. Rabeu and 
F. Mantion. 
Lawler, G. (2006). Introduction to Stochastic Processes. Chapman & Hall/CRC, 
Boca Raton, FL, 2nd edition. 
Lawler, G. and Limic, V. (2010). Random Walk: A Modern Introduction. Cambridge 
University Press, Cambridge, UK. 
Lefebvre, M. (2006). Applied Probability and Statistics. Springer, New York. 
Lin, X. (2006). Introductory Stochastic Analysis for Finance and Insurance. Wiley, 
Hoboken, NJ. 
Lin, Z. and Bai, Z. (2010). Probability Inequalities. Springer, New York. 
Liptser, R. and Shiryayev, A. (1977). Statistics of Stochastic Processes I: General 
Theory. Springer, New York, NY. 
Loeve, M. (1977). Probability Theory I. Springer, New York, 4th edition. 
Loeve, M. (1978). Probability Theory II. Springer, New York, 4th edition. 
Longstaff, F. and Schwartz, E. (2001). Valuing American options by simulation: A 
simple least-squares approach. The Review of Financial Studies, 14(1): 113-147. 
Lukacs, E. (1970). Characteristic Functions. Hafner Publishing, New York, 2nd 
edition. 

REFERENCES 
697 
Lyuu, Y.-D. (2001). Financial Engineering and Computation: Principles, Mathe-
matics, and Algorithms. Cambridge University Press, Cambridge, UK. 
Malliavin, P. and Thalmaier, A. (2006). Stochastic Calculus of Variations in Mathe-
matical Finance. Springer, New York. 
McDonald, R. (2005). Derivatives Markets. Addison-Wesley, New York. 
Medvegyev, P. (2007). Stochastic Integration Theory. Oxford University Press, 
Oxford, UK. 
Merton, R. (1973). Theory of rational option pricing. Bell Journal of Economics and 
Management Science, 4(1):141-183. 
Merton, R. (1990). Continuous-Time Finance. Basil Blackwell, Cambridge, MA. 
Meucci, A. (2005). Risk and Asset Allocation. Springer, New York. 
Meyer, M. (2000). Continuous Stochastic Calculus with Applications to Finance. 
Chapman & Hall/CRC, Boca Raton, FL. 
Mikosch, T. (1999). Elementary Stochastic Calculus with Finance in View, volume 6 
of Advanced Series on Statistical Science and Applied Probability. World Scien-
tific Publishing, Singapore. 
Mills, T. (2001). Problems in Probability. World Scientific Publishing, Singapore. 
Morters, P. and Peres, Y. (2010). Brownian Motion. Cambridge University Press, 
Cambridge, UK. 
Moschovakis, Y. (2006). Notes on Set Theory. Springer, New York, 2nd edition. 
Mosteller, F. (1987). Fifty Challenging Problems in Probability with Solutions. 
Dover Publications, Mineola, NY. 
Musiela, M. and Rutkowski, M. (2005). Martingale Methods in Financial Modelling. 
Springer, New York, 2nd edition. 
Myneni, R. (1992). The pricing of the american option. Annals of Applied Probabil-
ity, 2(1):1-23. 
Neftci, S. (2000). Introduction to the Mathematics of Financial Derivatives. Aca-
demic Press, Singapore, 2nd edition. 
Neftci, S. (2008). Principles of Financial Engineering. Academic Press, Singapore, 
2nd edition. 
Novikov, A. (1973). On moment inequalities and identities for stochastic integrals. 
In Proceedings of the Second Japan-USSR Symposium on Probability Theory, vol-
ume 330 of Lecture Notes in Mathematics, pages 333-339. 

698 
REFERENCES 
Oksendal, B. (1998). Stochastic Differential Equations: An Introduction with Appli-
cations. Springer, New York, 5th edition. 
Pap, E. (2002). Handbook of Measure Theory. North Holland, Amsterdam. 
Papoulis, A. (1991). 
Probability, Random Variables and Stochastic Processes. 
McGraw-Hill, New York, 3rd edition. 
Pascucci, A. (2011). PDE and Martingale Methods in Option Pricing. Springer, 
New York. 
Pascucci, A. and Runggaldier, W. (2012). Financial Mathematics: Theory and Prob-
lems for Multi-period Models. Springer, New York. 
Paul, W. and Baschnagel, J. (1999). Stochastic Processes: From Physics to Finance. 
Springer, Berlin. 
Pham, H. (2009). Continuous-Time Stochastic Control and Optimisation with .finan-
cial applications. Springer, New York. 
Pinsky, R. (1995). Positive Harmonic Functions and Diffusion. Cambridge Univer-
sity Press, Cambridge, UK. 
Pliska, S. (1997). Introduction to Mathematical Finance: Discrete Time Models. 
Wiley, New York. 
Pollard, D. (2001). A User's Guide to Measure Theoretic Probability. Cambridge 
University Press, Cambridge, UK. 
Prevot, C. and Rockner, M. (2007). A Concise Course on Stochastic Partial Differ-
ential Equations. Springer, New York. 
Protter, P. (2003). Stochastic Integration and Differential Equations. Springer, New 
York, 2nd edition. 
Rao, M. and Swift, R. (2006). Probability Theory with Applications. Springer, New 
York, 2nd edition. 
Rebonato, R. (2002). Modem Pricing of Interest-Rate Derivatives: The UBOR 
Market Model and Beyond. Princeton University Press, Princeton, NJ. 
Rebonato, R. (2004). Interest-rate term-structure pricing models: A review. Proceed-
ings: Mathematical, Physical and Engineering Sciences, 460(2043):667-728. 
Reitano, R. (2010). Introduction to Quantitative Finance: A Math Tool Kit. The MIT 
Press, Cambridge, MA. 
Resnick, S. (1992). Adventures in Stochastic Processes. Springer, New York. 
Resnick, S. (1999). A Probability Path. Birkhauser, Boston. 

REFERENCES 
699 
Revuz, D. and Yor, M. (1999). Continuous Martingales and Brownian Motion. 
Springer, New York, 3rd edition. 
Roberts, A. (2009). 
Elementary Calculus of Financial Mathematics. 
SIAM, 
Philadelphia. 
Rogers, L. and Williams, D. (2000). Diffusions, Markov Processes and Martingales: 
Volume 2, It Calculus. Cambridge University Press, Cambridge, UK, 2nd edition. 
Rosenthal, J. (2006). A First Look at Rigorous Probability Theory. World Scientific 
Publishing, Singapore, 2nd edition. 
Ross, S. (1995). Stochastic Processes. Wiley, 2nd edition. 
Ross, S. (1999). An Introduction to Mathematical Finance: Options and Other Top-
ics. Cambridge University Press, Cambridge, UK. 
Ross, S. (2010). Introduction to Probability Models. Academic Press, Burlington, 
MA, 6th edition. 
Ross, S. and Pekoz, E. (2007). A Second Course in Probability. ProbabilityBook-
store.com, Boston. 
Rouah, F. and Vainberg, G. (2007). Option Pricing Models and Volatility Using 
Excel-VBA. Wiley, Hoboken, NJ. 
Roussas, G. (1997). A Course in Mathematical Statistics. Academic Press, Singa-
pore, 2nd edition. 
Roussas, G. (2005). An Introduction to Measure-Theoretic Probability. Academic 
Press, Burlington, MA. 
Royden, H. (1988). Real Analysis. Prentice Hall, New York, 3rd edition. 
Rubinstein, M. (1991). Double trouble. Risk Magazine, 5:53-56. 
Rubinstein, M. and Reiner, E. (1991). Breaking down the barriers. Risk Magazine, 
4(9):28-35. 
Rudin, W. (1970). Real and Complex Analysis. McGraw-Hills, New York. 
Rudnick, J. and Gaspari, G. (2004). Elements of the Random Walk: An Introduction 
for Advanced Students and Researchers. Cambridge University Press, Cambridge, 
UK. 
Sato, K.-1. (1999). Levy Processes and Infinitely Divisible Distributions. Cambridge 
University Press, Cambridge, UK. 
Schilling, R. (2005). Measures, Integrals and Martingales. Cambridge University 
Press, Cambridge, UK. 

700 
REFERENCES 
Schoutens, W. (2003). Levy Processes in Finance: Pricing Financial Derivatives. 
Wiley, Hoboken, NJ. 
Schoutens, W. and Cariboni, C. (2009). Levy Processes in Credit Risk. Wiley, Hobo-
ken, NJ. 
Seydel, R. (2006). Tools for Computational Finance. Springer, New York, 3rd 
edition. 
Shafer, G. and Vovk, V. (2001). Probability and Finance: It's only a Game! Wiley, 
Hoboken, NJ. 
Shao, J. (2003). Mathematical Statistics. Springer, New York, 2nd edition. 
Shiryaev, A. (1999). Essentials of Stochastic Finance: Facts, Models, Theory. World 
Scientific Publishing, Singapore. 
Shiryaev, A. and Boas, R. (1995). Probability. Springer, New York, 2nd edition. 
Shorack, G. (2000). Probability for Statisticians. Springer, New York. 
Shreve, S. (2004). Stochastic Calculus for Finance II: Continuous-Time Models. 
Springer, New York. 
Shreve, S. (2005). Stochastic Calculus for Finance I: The Binomial Asset Pricing 
Model. Springer, New York. 
Smith, C. (1976). Option pricing: A review. Journal of Financial Economics, 3(1-
2):3-51. 
Sondermann, D. (2007). Introduction to Stochastic Calculus for Finance: A New 
Didactic Approach. Springer, New York. 
Spitzer, F. (2001). Principles of Random Walks, volume 34 of Graduate Texts in 
Mathematics. Springer, New York, 2nd edition. 
Steele, J. (2003). Stochastic Calculus and Financial Applications. Springer, New 
York, NY. 
Stirzaker, D. (2003). Elementary Probability. Cambridge University Press, Cam-
bridge, UK, 2nd edition. 
Stirzaker, D. (2005). Stochastic Processes and Models. Oxford University Press, 
Oxford, UK. 
Stoyanov, J. (1997). Counterexamples in Probability. Wiley, New York, 2nd edition. 
Stroock, D. (2005). An Introduction to Markov Processes. Springer, New York. 
Stroock, D. (2011). Probability Theory: An Analytic View. Cambridge University 
Press, Cambridge, UK, 2nd edition. 

REFERENCES 
701 
Stroock, D. and Varadhan, S. (1979). 
Multidimensional Diffusion Processes. 
Springer, New York, NY. 
Svoboda, S. (2004). Interest Rate Modelling. Palgrave Macmillan, Gordonsville, 
VA. 
Takacs, L. (1960). Stochastic Processes: Problems and Solutions. Wiley, New York. 
Taylor, S. (1973). Introduction to Measure and Integration. Cambridge University 
Press, Cambridge, UK. 
Tijms, H. (2003). A First Course in Stochastic Models. Wiley, Hoboken, NJ. 
Topper, J. (2005). Financial Engineering with Finite Elements. Wiley, Hoboken, NJ. 
Vasicek, 0. (1977). An equilibrium characterization of the term structure. Journal 
of Financial Economics, 5(2): 177-188. 
Vaught, R. (1995). Set Theory: An Introduction. Birkhauser, Boston, 2nd edition. 
Vestrup, E. (2003). The Theory of Measures and Integration. Wiley, Hoboken, NJ. 
Watsham, T. and Parramore, K. (1997). Quantitative Methods in Finance. Thomson, 
London, UK. 
Weir, A. (1979). General integration and measure. Cambridge University Press, 
Cambridge, UK. 
Wheeden, R. and Zygmund, A. (1977). Measure and Integral: An Introduction to 
Real Analysis. CRC Press, Boca Raton, FL. 
Wiersema, U. (2008). Brownian Motion Calculus. Wiley, Hoboken, NJ. 
Williams, D. (1991). Probability with Martingales. Cambridge University Press, 
Cambridge, UK. 
Wilmott, P. (2001). Paul Wilmott Introduces Quantitative Finance. Wiley, Hoboken, 
NJ, 2nd edition. 
Wilmott, P. (2006). Paul Wilmott on Quantitative Finance 3 Volume Set. Wiley, 
Hoboken, NJ, 2nd edition. 
Wilmott, P., Howison, S., and Dewynne, J. (1995). The Mathematics of Financial 
Derivatives: A Student Introduction. Cambridge University Press, Cambridge, 
UK. 
Wimmer, G. and Altmann, G. (1999). Thesaurus of Univariate Discrete Probability 
Distributions. STAMM Verlag, Essen, Germany. 
Wise, G. and Hall, E. (1993). Counterexamples in Probability and Real Analysis. 
Oxford University Press, Oxford, UK. 

702 
REFERENCES 
Yeh, J. (2006). Real Analysis: Theory of Measure And Integration. World Scientific 
Publishing, Singapore, 2nd edition. 
Zakai, M. ( 1967). Some moment inequalities for stochastic integrals and for solu-
tions of stochastic differential equations. Israel Journal of Mathematics, 5(3): 170-
176. 

List of Symbols 
A 
A,563 
.szl, 611 
do, 611 
A=B,4 
B ~A,3 
A~B,4 
AnB,4 
A-B,4 
A\B,4 
AUB,4 
Ac,4 
a.e., 17 
a I b, 144 
An-+ A, 5 
Ant A, 4 
An-J..A,4 
a f b, 145 
A(Â¢), 593 
a.s., 128 
703 
A_K, 563,564 
AI, 563,564 
B 
B, 16 
\, 17 
8, 38 
B(Rd), 38 
B(E), 16 
Be(p), 227 
Beta(p, q), 240 
f3(t), 630 
B(n,p), 227 
B(Â¢), 593 
B(p, q), 241 
Bo(:R), 38 
Bo(Il.d), 38 
B(S), 16 
c 

704 
LIST OF SYMBOLS 
C 2 [a, b], 478 
C(a, h), 240 
C(ry, Â¢), 594 
Corr(X, Y), 163 
Cov(X, Y), 162 
Cx(t), 218 
D 
V, 17 
aD, 547 
D.i,b,aG(x1, X2, ... , Xd), 38 
D.[M] 8 , 478 
D.xoâ¢ 257 
D(ry, Â¢), 594 
d(I), 18 
Dw, 402 
apQ. 548 
~ 
dQ , 667 
dQTI 
dQ 
, 668 
g;, 
d-system, 17 
E 
E, 531 
E 1 , 272 
tÂ£:1 , 272 
0, 3, 16 
EQ. 563,583 
esssupX, 611 
Ex, 532 
E(X;F), 161 
E(XIQ), 174 
E(XI911i), 176 
Exp(>.), 241 
E(XIZ1, Z2, .. . ), 174 
E[YIH], 174 
E[YIX], 174 
F 
g-, 17, 127 
g-00, 334 
r,58 
fn ~J,98 
Fn * F, 257 
J+, 58 
g-T, 302 
g-Tâ¢ 302 
g-t-â¢ 274 
g-t+â¢ 274 
F(t, T), 629 
F(t; T, S), 647 
F(t, T, Y), 648 
f(t, T, Y), 648 
g-{, 275 
G 
r(o:,B),241 
r(x), 240 
gcd(X, Y), 156 
G(p), 228 
r(o:), 241 
H 
HG(N, m, n), 228 
I 
I, 17 
11,4 
fa J(t)dMt. 465 
I: f(t)dBt. 422 
J: f(t)dBt(w), 422 
fA fdf.l, 58 
I fdf.l, 58 
fs fdf.1, 58 
I(x, A), 390 
K 
KJ, 391 
L 
Â£ 1 (S, ~. f.l), 58, 61 
L 2 [a, b], 421 
Â£ 2(0, g-, P), 421 
Â£ 2(0, g-, P), 162 
L~red([a, b](M) X n, 464 
IL([a, b] x D), 463 
.Cad(n, L1 [a, b]), 477 
L~d([a, b] X n), 431 
.Cad(n, L2[a, b]), 453 
>..-,78 
)... Â« f.l, 78 

>.+,78 
1>-1, 78 
lim inf, 4, 5 
liminf En, 5, 128 
limn-+oo An, 5 
limn-+oo Xn, 5 
lim sup, 4, 5 
lim sup En, 5, 128 
LN(f.l, a 2), 240 
U(n,g:-,P), 161 
Lpred(Sl, L2[a, b] (M)), 465 
(LP(S, ~' f.l), dv), 87 
LP(S, ~' f.l), 85 
Lt, 533 
L(t, T), 667 
Â£x, 129 
M 
M,48 
M(A), 403 
Mw,403 
mg:-, 190 
(m~)+, 57 
m~, 47,48 
(M)t, 466 
[M]f, 478 
[1,,218 
flp, 218 
f.lo(f), 58 
f.L(f), 58 
f.l(f; A), 58 
{l-integrable, 58 
f.LK, 391 
{l-null, 17 
f.ll j_ f.l2, 78 
f.l"' >., 78 
f.lx, 162 
fly, 162 
Mx(t), 217 
N 
~ = {O,l, ... ,oo},317 
N, 17, 18 
NB(r,p), 228 
N(d), 582 
N(f.l, a 2), 239 
N(x), 240 
0 
211 , 128 
LIST OF SYMBOLS 
705 
n, 17, 127 
(n,g:-,P), 17,127 
p 
P, 17, 127 
P, 144 
P,463 
Pa(a, h), 240 
P(BIQ), 174 
P(BIX = x), 174 
iJ.l(f.L,a,x),240 
iJ.l(x), 240 
Â¢x(t), 218 
?-integrable, 161 
1r(R), 136 
1r-system, 17 
1r(X), 131 
P-null, 151 
P(B), 228 
P(t, T), 629 
Pt,uâ¢ 390 
Q 
(!,6,279,282,459 
Q*, 672 
QT, 667 
Qx, 532 
R 
R, 6,16 
:R, 115 
R+, 114 
r(t), 630 
R(t, T), 629 
R(t; T, S), 648 
s 
28 , 18 
(S, d), 86 
sF+, 57 
~Q, 15 

706 
LIST OF SYMBOLS 
I:, 15 
L;l (>9 I:2, 113 
a(C), 16 
a(I), 30 
I:-measurab1e, 47 
L:ll, 30 
I:J/I:2-measurab1e, 48 
"-', 86 
(S, I:), 16 
(S, L:, fJ), 17 
ST(v), 240 
SVT, 303 
S 1\ T, 303 
T 
T, 142 
To. 564 
TA, 302 
{Tn(a,b): n ~ 0}, 333,334 
To,r, 610 
v 
Var(X), 162 
<p(f1,a,x),239 
<p(x),239 
V,60 
lit(Â¢), 580 
vt(Â¢, A), 610 
w 
/\,60 
wr, 669 
X 
X rv Be(p), 227 
X "' Beta(p, q), 240 
X rv B(n,p), 227 
X"-' C(a, h), 240 
X "-' Exp(>.), 241 
X"' f(a, B), 241 
X"' G(p), 228 
X"' HG(N, rn, n), 228 
X "' LN(fJ, a 2), 240 
X"' NB(r,p), 228 
d 
Xn --+ Xo, 258 
X "'N(fJ, a 2), 239 
Xn--+ X, 5 
X"' Pa(a, h), 240 
X"' P(B), 228 
X "' ST(v), 240 
Xt. 580 
Xt-. 402 
Xt+â¢ 402 
[X]~Pl, 464 
x:Â·x, 532 
Xf, 532 
(x, y), 87 
X l_ y, 87 
(X, Y)t, 478 
y 
Y, 129 

Subject Index 
A 
absolute continuity, 77 
absolute moment, 162 
absolutely continuous random variable, 
see random variable 
additive set function, see set function 
admissible portfolio, see portfolio 
affine term structure, 633 
algebra, 15 
almost everywhere convergence, 98 
almost sure convergence, 199 
almost surely, 128 
almost uniform convergence, 98 
American call option, 616 
American derivative, 563 
American option, see option 
approximation theorem, 30 
arbitrage, 563, 581, 611 
arbitrage price, 564, 567 
arbitrage-free, 563 
707 
axiom of choice, 14 
B 
backward equation, 535 
bank account, 630 
barrier option, 593 
Bayes' formula, 177 
Bellman-Gronwall inequality, see in-
equality 
Bernoulli distribution, see distribution 
beta distribution, see distribution 
beta function, 241 
BGM model, 685 
binomial distribution, see distribution 
binomial model, 564 
bivariate Laplace transform, 551 
Black-Scholes market, 580 
Bonferroni inequality, see inequality 
Borel function, 47, 49 
Borel measurable, 48 

708 
SUBJECT INDEX 
Borel measure, see measure 
Borel set, 16 
Borel-Cantelli lemma 
- first, 18 
- second, 143 
Borel a-algebra, see a-algebra 
Brownian bridge, 520 
Brownian motion, 373 
- m-dimensional, 374 
- geometric, 535 
B(S)-measurable, 48 
buy-and-hold strategy, 610 
c 
C1â¢2-function, 532 
C 2-function, 4 77 
CadUtg process, 272 
Cantor ternary set, 40 
caplet, 671 
Caratheodory's extension theorem, 30 
Cartesian product, 113 
Cauchy distribution, see distribution 
Cauchy problem, 548 
Cauchy sequence, 86 
Cauchy-Dirichlet problem, 547 
central limit theorem 
- classical, 259 
- Lindeberg's, 258 
- Lyapounov's, 259 
central moment, 162 
chain, 5 
change of numeraire, 566 
Chapman-Kolmogorov equation, 390 
characteristic exponent, 404 
characteristic function, 218 
Chebyshev's inequality, see inequal-
ity 
CIR model, 634 
classical central limit theorem, see cen-
trallimit theorem 
closure, 531 
compact set, 531 
compensated Poisson process, see Pois-
son process 
compensator, 466 
complement, 4 
complete market, 564 
complete measure, see measure 
completeness, 86 
completion, 30 
conditional expectation, see expecta-
tion 
conditional independence, see indepen-
dence 
conditional Jensen's inequality, see in-
equality 
conditional probability, 174 
consistency condition, 272 
consumption strategy, 610 
continuous filtration, see filtration 
continuous function, 16 
continuous market, 579 
continuous part of quadratic variation 
processes, see quadratic vari-
ation process 
continuous realization, 454 
continuous stochastic process, see stochas-
tic process 
convergence in distribution, 258 
convergence in law, 258 
convergence in Â£P, 97 
convergence in measure, 97 
convergence in probability, 97, 199 
convex function, 189 
coordinate map, 114 
correlation, 163 
countable set, 3 
countab1y additive set function, see set 
function 
counting measure, see measure 
counting process, 358 
covariance, 162 
cover, 531 
cross-variation process, 478 
cumulant generating function, 218 
D 
degenerate distribution, see distribu-
tion 

degenerate random variable, see ran-
dom variable 
Delta, 584 
density function, 129 
difference of sets, 4 
difference operator, 38 
diffusion, 532 
diffusion coefficient, 532 
Dirac measure, 408 
Dirichlet problem, 547 
discount factor, 630 
discrete filtration, see filtration 
discrete market, 561 
discrete martingale, see martingale 
discrete probability space, see proba-
bility space 
distribution 
- Bernoulli, 227 
- beta, 240 
- binomial, 227 
- Cauchy, 240 
- degenerate, 257 
- exponential, 241 
- gamma, 241 
- geometric, 228 
- hypergeometric, 228 
- lognormal, 240 
- multivariate normal, 241 
- negative binomial, 228 
- Pareto, 240 
- Poisson, 228 
- student's t, 240 
- univariate normal, 239 
distribution function, 129 
- joint, 129 
dominance, 273 
dominated convergence theorem, 59 
Doob decomposition, 294 
Doob's submartingale inequality, see 
inequality 
Doob-Meyer decomposition, 466 
Doob-Levy martingale, 293 
Doob's maximal inequality, see inequal-
ity 
down-and-in call, 594 
SUBJECT INDEX 
709 
down-and-in put, 594 
down-and-out call, 595 
down-and-out put, 595 
drift coefficient, 532 
drift function, 649 
d-system, 17 
Dudley's representation theorem, 496 
Dynkin's formula, 534 
Dynkin's lemma, 18 
E 
Egoroff's theorem, 98 
empty set, see set 
equivalence relation, 86 
equivalent martingale measure, 563, 
630 
equivalent measure, 78 
equivalent stochastic process, see stochas-
tic process 
essential supremum, 611 
European derivative, 563, 581 
E-valued random variable, see random 
variable 
event, 127 
- eventual, 128 
- independent, 142 
- infinitely often, 128 
eventual event, see event 
exercise strategy, 564 
exercise time, 564 
exit time, 302 
exotic option, see option 
expectation, 161 
- conditional, 173 
expectation hypothesis, 670 
exponential distribution, see distribu-
tion 
exponential inequality, see inequality 
exponential martingale, see martingale 
exponential process, see stochastic pro-
cess 
F 
Fatou's lemma, 59, 130 
- reverse, 130 

71 0 
SUBJECT INDEX 
Feynman-Kac formula, 548 
field, 15 
filtration, 27 4 
- continuous, 274 
- discrete, 27 4 
- left-continuous, 274 
- right-continuous, 274 
finite measure, see measure 
finite-dimensional distribution, 272 
first Borel-Cantelli lemma, see Borel-
Cantelli lemma 
fixed-strike lookback call option, 597 
fixed-strike lookback put option, 597 
floating-strike lookback call option, 596 
floating-strike lookback put, 600 
floating-strike lookback put option, 596 
forward contract, 648 
forward curve, 648 
forward rate, 647 
Fourier uniqueness theorem, 218 
Fubini's theorem, 115 
futures contract, 648 
futures price, 650 
G 
gamma distribution, see distribution 
gamma function, 240 
Gaussian HJM model, see HJM model 
Gaussian process, 274 
geometric Brownian motion, see Brow-
nian motion 
geometric distribution, see distribution 
geometric Poisson process, see Pois-
son process 
Girsanov theorem I, 505 
Girsanov theorem II, 505 
Gronwall's lemma, 62 
H 
hitting time, 302, 303 
HJM drift condition, 650 
HJM framework, 648 
HJM model, 647, 652 
- Gaussian, 653 
Holder's inequality, see inequality 
Hull-White model, 634 
hypergeometric distribution, see dis-
tribution 
I 
identically distributed random variables, 
see random variable 
identity kernel, 390 
liD, 199 
imaginary number, 218 
increasing process, see stochastic pro-
cess 
independence 
- conditional, 389 
independent event, see event 
independent increments, 272 
independent random variable, see ran-
dom variable 
independent stochastic process, see stochas-
tic process 
independent cr-algebra, see cr-algebra 
indicator function, 4 
indistinguishable stochastic process, see 
stochastic process 
inequality 
- Bellman-Gronwall, 517 
- Bonferroni, 131 
- Chebyshev's, 61, 190 
- conditional Jensen's, 190 
- Doob submartingale, 321 
- Doob's maximal, 322 
- exponential, 436 
- Holder's, 87 
- Jensen's, 190 
- Kolmogorov's, 191 
- Levy's, 191 
- Markov's, 190 
- Minkowski's, 87 
- Schwarz's, 87 
infinite norm, see norm 
infinitely divisible distribution, 402 
infinitely divisible random variable, see 
random variable 
infinitely often event, see event 
infinitesimal generator, 533 

inner product, 87 
inner product space, 87 
instantaneous forward rate, 648 
instantaneous short rate, 630 
integral 
- Lebesgue, 58 
intersection, 4 
Ito diffusion, 532 
Ito integral, 431, 432 
Ito's formula, 478 
Ito process, 477 
Ito table, 479 
J 
Jensen's inequality, see inequality 
joint distribution function, see distri-
bution function 
joint law, see law 
Jordan-Hahn decomposition, 78 
jump, 402 
jump magnitude, 402 
jump size, 402 
jump-diffusion process, 402 
K 
Kac' s theorem, 218 
Kolmogorov's backward equation, 550 
Kolmogorov's continuity criterion, 275 
Kolmogorov's existence theorem, 275 
Kolmogorov's inequality, see inequal-
ity 
Kolmogorov's three-series criterion, 202, 
203 
Kolmogorov's 0-llaw, 144 
Kronecker delta, 480 
Kronecker lemma, 201 
L 
Levy measure, see measure 
Langevin equation, 481 
law, 129 
- joint, 129 
- of stochastic process, 271 
law of the iterated logarithm, 374 
Lebesgue decomposition theorem, 78 
Lebesgue integral, see integral 
SUBJECT INDEX 
711 
Lebesgue measure, see measure 
Lebesgue-Stieltjes measure, see mea-
sure 
left limit, 274 
left -continuous filtration, see filtration 
Levy characterization of Brownian mo-
tion, 504 
Levy's inequality, see inequality 
Levy-Ito decomposition, 404 
Levy-Khintchine formula, 403 
Levy process, 401 
LIBOR, 667 
LIBOR market model, 668 
Lindeberg's central limit theorem, see 
central limit theorem 
line of support theorem, 190 
linear complementarity condition, 615 
linear growth condition, 516 
Lipschitz condition, 516 
Lipschitz continuity condition, 532 
local martingale, see martingale 
local submartingale, see submartingale 
lognormal distribution, see distribution 
long arbitrage, 611 
lookback call option, 596, 597 
lookback put option, 596, 597 
lower limit, 4 
lower variation, 78 
LP space, 85 
Lyapounov's central limit theorem, see 
central limit theorem 
M 
market price of risk, 631 
Markov chain, 391 
Markov kernel, 390 
Markov process, 389 
- time-homogeneous, 391 
Markov property, 533 
Markov's inequality, see inequality 
Markovian transition function, 390 
martingale 
- discrete, 291 
- exponential, 504 
- local, 454 

712 
SUBJECT INDEX 
martingale representation theorem, 495 
martingale stochastic integral, 465 
maximum norm, see norm 
m-dimensional Brownian motion, see 
Brownian motion 
mean, 163 
mean square summability criterion, 201 
mean value theorem, 189 
measurable function, 47 
measurable rectangle, 113, 114 
measurable space, 16 
measurable stochastic process 
- seestochastic process, 274 
measure, 17 
- T-forward, 667 
a-finite, 17 
- Borel, 16 
complete, 30 
counting, 17 
finite, 17 
Levy,403 
- Lebesgue, 38 
- Lebesgue-Stieltjes, 37 
outer, 29 
probability, 17 
- product, 114 
measure space, 17 
- product, I 14 
metric, 86 
metric space, 86 
Minkowski's inequality, see inequal-
ity 
modification, 273 
moment, 162 
moment generating function, 217 
money-market account, 630 
monotone class of functions, 48 
monotone class theorem, 30 
monotone convergence of measures, 
18 
monotone convergence theorem, 59 
p,-integrable, 58 
multivariate normal distribution, see 
distribution 
N 
natural filtration, 275 
natural process, see stochastic process 
negative binomial distribution, see dis-
tribution 
negative part, 78 
no-arbitrage principle, 583 
nondegenerate random variable, see ran-
dom variable 
norm, 85 
- infinite, 86 
- maximum, 86 
normalized market, 562, 580 
Novikov's condition, 505, 506 
Novikov's theorem, 503 
numeraire, 562 
0 
open set, 16 
optimal sampling theorem, 303 
optimal stopping theorem, 302 
optimal stopping time, see stopping 
time 
option 
American, 609 
- exotic, 593 
- path-dependent, 593 
optional skipping theorem, 293 
Ornstein-Uhlenbeck equation, 519 
- mean-reverting, 520 
orthogonal projection, 88 
orthogonal vector, 87 
outer measure, see measure 
p 
Pareto distribution, see distribution 
partial ordering, 5 
path-dependent option, see option 
1r-system, 17, 144 
Poisson distribution, see distribution 
Poisson process, 357 
- compensated, 358 
- geometric, 360 
Poisson random measure, see random 
measure 

portfolio, 562, 580 
- admissible, 563, 581 
- predictable, 562 
- self-financing, 562, 580 
positive part, 78 
power set, 64 
predictable portfolio, see portfolio 
predictable stochastic process, see stochas-
tic process 
probability law, 129, 271 
probability law of stochastic process, 
see law 
probability measure, see measure 
probability space, 17 
- discrete, 127 
product a-algebra, see a-algebra 
product measure, see measure 
product measure space, see measure 
space 
product of kernels, 390 
progressively measurable process, see 
stochastic process 
p-th variation process, 464 
?-trivial, 144 
pure-jump process, 402 
put-call parity, 584 
Q 
quadratic variation process, 464 
- continuous part of, 478 
R 
Radon-Nikodym derivative, 79 
Radon-Nikodym theorem, 78 
random measure, 403 
- Poisson, 403 
random time, 27 4 
random variable, 128 
- E-valued, 128 
- absolutely continuous, 129 
- degenerate, 129 
- identically distributed, 199 
- independent, 142 
- infinitely divisible, 402 
- nondegenerate, 129 
SUBJECT INDEX 
713 
random vector, 128 
random walk, 343 
- scaled, 344 
rational number, 6 
rectangle, 114 
reflection equality, 376 
reflection principle, 376 
replicable European derivative, 581 
replicating portfolio, 563, 581 
representation by informative increments, 
496 
reverse Fatou's lemma, see Fatou's lemma 
reward function, 609 
Riemann-Stieltjes integral, 422 
right continuous stochastic process, see 
stochastic process 
right limit, 27 4 
right-continuous filtration, see filtra-
tion 
risk-neutral measure, 507, 581, 652 
risk-neutral price, 564 
risk-neutral pricing, 566 
s 
sample path, 271 
sample point, 127 
sample space, 127 
scaled random walk, see random walk 
scaling invariance, 375 
Scheffe's lemma A, 61 
Scheffe's lemma B, 61 
Schwarz's inequality, see inequality 
Second Borel-Cantelli lemma, see Borel-
Cantelli lemma 
self-financing, 580, 610 
self-financing portfolio, see portfolio 
set, 3 
-empty, 3 
set function, 16 
- additive, 16 
- countably additive, 16 
short arbitrage, 611 
short rate, 629 
short rate model, 630 
a-algebra, 15, 52 

714 
SUBJECT INDEX 
- Borel, 16 
- independent, 141 
- product, 113 
- tail, 142 
IT-field, 15 
IT-finite measure, see measure 
:E-measurable, 16, 47 
:E1 /:E2-measurable, 48 
signed measure, see measure 
simple function, 57 
simple random walk, 343 
singularity, 78 
Snell envelope, 567, 612 
solution of SDE 
- strong,515 
- weak, 516 
spot LIBOR measure, 672 
spot rate, 629 
square-integrable stochastic process, see 
stochastic process 
standard Brownian motion, 373 
standard normal random variable, 239 
state space, 271 
stationary increments, 272 
step stochastic process, 431 
stochastic continuity, 275 
stochastic discount factor, 630 
stochastic exponential, 519 
stochastic Fubini theorem, 649 
stochastic process, 271 
- continuous, 272 
- equivalent, 273 
- exponential, 503 
- increasing, 464 
- independent, 273 
- indistinguishable, 273 
- measurable, 274 
- natural, 464 
- predictable, 463 
- progressively measurable, 275 
- right-continuous, 272 
- square-integrable, 464 
stopping time, 301 
- optimal, 612 
strategy, 562 
strong law of large numbers, 200 
strong Markov property, 374, 533 
strong solution of SDE, see solution 
of SED 
student's t-distribution, see distribution 
submartingale, 292 
- local, 454 
submartingale convergence theorem, 334 
subset, 3 
supermartingale, 291 
support, 532 
symmetric difference of sets, 4 
T 
Tail IT-algebra, see IT-algebra 
T-bond,629 
T -contingent claim, 630 
term structure equation, 632 
T-forward measure, see measure 
time homogeneity, 534 
time-homogeneous Markov process, see 
Markov process 
time-inversion invariance, 375 
Toeplitz lemma, 201 
Tonelli's theorem, 114 
Topological space, 48 
topological space, 16 
topology, 16 
total variation, 78, 402 
total variation process, 464 
totally ordered set, 5 
tower property, 176 
trading strategy, 580, 610 
trajectory, 271 
transition function, 532 
transition kernel, 390 
translation invariance, 375 
u 
uncountable set, 3 
uniform convergence, 98 
uniformly integrable, 98 
union, 4 
uniqueness of extension, 30 
uniqueness of solution, 516 

univariate normal distribution, see dis-
tribution 
up-and-in call, 594 
up-and-in put, 595 
up-and-out call, 595 
up-and-out put, 595 
upcrossing theorem, 334 
upper limit, 4 
upper variation, 78 
v 
variance, 162, 163 
Vasicek model, 633 
version, 174, 273 
Vitali set, 28 
w 
Ward's theorem, 323 
weak convergence, 257 
weak law of large numbers, 200 
weak solution of SDE, see solution of 
SDE 
wealth process, 610 
Weierstrass M-test, 98 
Wiener integral, 422, 429 
y 
yield curve, 630 
z 
zero-coupon bond, 629 
Zorn's lemma, 6 
SUBJECT INDEX 
715 

