Academic Press Textbooks in the 
Computer Sciences 
Edited b y 
A n t h o n y R a l s t o n Director of the Computing Center 
State University of New York at Buffalo 
Anthony Hassitt: COMPUTER PROGRAMMING AND COMPUTER SYSTEMS 

COMPUTER 
PROGRAMMING 
AND 
COMPUTER SYSTEMS 
A N T H O N Y 
H A S S I T T 
Computer Center 
University of California 
San Diego 
A C A D E M I C 
PRESS 
f 
A0\ 
New York and London 
V' U J 

COPYRIGHT © 1967 BY ACADEMIC PRESS, INC. 
ALL RIGHTS RESERVED. 
NO PART OF THIS BOOK MAY BE REPRODUCED IN 
ANY FORM, BY PHOTOSTAT, MICROFILM, OR ANY 
OTHER MEANS, WITHOUT WRITTEN PERMISSION 
FROM THE PUBLISHERS. 
ACADEMIC PRESS INC. 
111 Fifth Avenue, New York, New York 10003 
United Kingdom Edition published by 
ACADEMIC PRESS INC. (LONDON) LTD. 
Berkeley Square House, London W.l 
LIBRARY OF CONGRESS CATALOG CARD 
NUMBER: 66-30137 
PRINTED IN THE UNITED STATES OF AMERICA 

The early stages of learning to program are de-
ceptively easy. The beginning student can use one of the 
several excellent textbooks or one of the many courses 
in basic programming. Within a short time, the student 
will be able to use Fortran, or Algol, or one of the other 
programming languages to solve a variety of textbook 
problems. When it comes to writing the programs that 
arise in practical situations, however, the student finds 
that programming is not so simple after all and some 
further study is necessary. This study can be divided 
into three concurrent phases. An aspiring programmer 
will need to study numerical analysis; he will need to 
study the particular techniques of his field of research; 
and he will need to learn more about the computer and 
the ways in which it can be used. This book is con-
cerned with the latter aspects of programming. 
This text is based on a course given to students and post-doctoral 
research workers at the University of California, San Diego. The text 
assumes a knowledge of programming equal to that given in the introduc-
tory texts on Fortran or one of the other compiler languages. Languages 
such as Fortran or Algol suggest that no knowledge of the actual working 
of the computer is needed. In the present state of the art, this is not usually 
true. The conscientious programmer soon finds himself referring to ob-
scure manuals on machine-language programming. This book describes 
those aspects of machine-language programming, monitor systems, com-
puter hardware, and advanced programming with which every thorough 
programmer should be acquainted. It could serve professional program-
mers as an introduction to modern programming practices, but it is espe-
cially designed for research workers in science or engineering, in both the 
academic and industrial fields, who are using the computer as an aid in 
their research. 
There is no doubt that the modern computing system is extremely 
complex. Even experienced professional programmers have wasted mil-
lions of dollars by underestimating the difficulty of developing a compre-
hensive operating system. The degree of understanding required of the 
average nonprofessional programmer can be illustrated by the following 
analogy. With the aid of a dictionary, there are many English-speaking 
people who have the reading knowledge to translate a scientific text from 
French into English; however, only very few of these people could trans-
late an English text into grammatical French. This book tries to impart a 
"reading knowledge" of computer systems. A competent programmer 
should, with the aid of a list of machine instructions, be able to under-
stand the code that is produced by a compiler. He should know the mean-
ing of terms like "interrupt," "overflow," "logical record," and so on. He 
should understand what the system is trying to do and he should use this 
knowledge to improve his programs. Hopefully, this knowledge will not 
encourage the programmer to write machine-language programs. 
Chapter 1 serves as an introduction to the rest of the book. It 
PREFACE 
V 

vi 
PREFACE 
gives a broad outline of the development of computers, starting with the 
simple machines of the early 1950's and leading up to the complex sys-
tems of today. Chapter 2 describes machine-language and assembly-lan-
guage programming of the central processing unit. The purpose of the 
chapter is to introduce concepts such as machine instructions, memory 
addressing, index registers, and so on. These ideas can be applied to 
almost any machine, but we discuss them in the context of the IBM 7090. 
We chose the 7090 because it is relatively simple with features such as 
one instruction per word, one accumulator, signed arithmetic, and so on. 
Chapter 3 extends these ideas and discusses such machines as the CDC 
3600 and the IBM 360. Much of the material in this chapter is optional. 
The sections of the chapter that should be read will depend on the inter-
ests of the user and the computer to which he has access. 
Chapters 2 and 3 should teach the student how to understand the 
symbolic instructions produced by a compiler; they do not set out to teach 
assembly-language programming. Chapter 4 discusses the symbolic in-
structions produced by compiler-language statements such as arithmetic 
statements, DO, IF, GO TO, and DIMENSION statements. Chapter 5 
considers input and output, interrupts, buffering, logical and physical rec-
ords and the relative merits of tapes, disks, and other I/O equipment. 
It also discusses the general strategy of the software and concepts such as 
time-sharing. 
Chapter 6 considers the Fortran subroutine, the communication 
of information by way of the argument list and by way of Common. It also 
describes some of the standard relocation schemes and the base address 
technique of the IBM 360. Chapter 7 is concerned with the input and 
output of BCD information. It starts with the basic processes of BCD-to-
binary and binary-to-BCD conversion and goes on to describe some 
applications of character manipulation. Chapter 8 is concerned with 
efficiency. It points out the factors that should be considered in the plan-
ning, writing, and debugging of programs. Chapter 9 is concerned with 
some of the dynamic uses of memory. It discusses the manipulation of 
arrays and the use of dope vectors, the use of a stack for local variables, 
the virtual memory of the IBM 360 Model 67 and other computers, recur-
sion and re-entrance, and finally the use of memory in list processing. 
Chapter 10 discusses PL/1, particularly the dynamic use of memory, the 
block structure, internal and external procedures, and multiprocessing. 
The relationship between Algol and PL/1 is considered. At the time of 
writing no PL/1 compiler is available; however, the description of PL/1 
is relevant because it crystallizes some of the current ideas on program-
ming and represents the practical application of many of the concepts 
discussed in earlier chapters of this book. 
I am grateful to Professor Clay Perry for suggesting that I write 
this book and for encouragement while it was being written. I am indebted 
to various members of the Computer Center for their comments on the 
manuscript. I am also grateful to Professor Anthony Ralston for his 
detailed review and constructive criticism of the manuscript. 
San Diego, 
A.H. 
California 

1-1 
INTRODUCTION 
An efficient way of learning to use a 
computing machine utilizes one of the 
problem oriented languages such as For-
tran, Algol, or PL/1. The basic elements of 
these languages are easy to learn because 
they are not too dissimilar to ordinary 
mathematical notation. With a limited 
knowledge of one of these languages, the 
computer can be used to solve a wide 
variety of problems; however, there comes 
a time when the programmer realizes that 
the computer is not the simple device that 
is described in his programming manual. 
He may realize this when he tries to under-
stand some of the advanced features of the 
language. He may have this knowledge 
thrust upon him when his program behaves 
in an unpredictable way. The fact is that 
modern computer systems are extremely 
complex, and each new system tends to 
be more complicated than its predecessor. 
In order to understand some of the 
more powerful features of programming 
languages and to use the full power of 
the computing systems, it is necessary 
to appreciate some of the aims and 
methods that lie behind the seemingly 
simple statements of the problem-oriented 
language. Before we begin a systematic 
study of computer systems it is instructive 
to take an overall view of the computing 
scene. In this first chapter we outline some 
of the present-day systems and languages. 
This will provide an introduction to topics 
that will be discussed in later chapters of 
the book. 
1 
COMPUTER 
SYSTEMS 
1 ·2 
AUTOMATIC ELECTRONIC 
DIGITAL COMPUTERS 
A convenient way to approach the complex 
computing systems of the present era is 
1 

2 
1 COMPUTER SYSTEMS 
to start with the first electronic computers and to follow the developments 
that have taken place in the last twenty years. The electronic computer 
was made possible by the technological developments that took place 
during World War II. The first electronic computer, the Eniac, was 
completed soon after the end of the war. The Eniac was not the true fore-
runner of modern computers. The course of a calculation in this machine 
was determined by physical connections between various units. It was 
soon realized that the connections could be made electronically. Several 
groups of scientists began building machines in which all operations, other 
than input and output, were electronic. The first of these new machines, 
the Edsac, was completed in 1949. 
Before describing the Edsac, let us consider how a calculation is 
done by a human operator using a desk calculator. Figure 1.1 shows the 
list of 
instructions 
mathematical 
tables 
χ 
\ 
^ 
desk 
calculator 
. \ 
f 
operator 
initial data 
paper to record 
intermediate and 
final results 
Fig. 1.1 
The computing process as performed by an operator using a desk calculator. The arrows depict 
the flow of information. 
various components of the operation. The operator has a list of instructions 
describing the steps that he must perform. The initial data has been written 
down. The operator has a pencil and paper with which to record the 
intermediate steps and the final results. 
The main components of a simple automatic computer are shown 
in Figure 1.2. The paper on which the calculator operator had his instruc-
tions and initial data and the paper on which he recorded the intermediate 
and final results are replaced in the computer by an electronic memory. The 
memory to contain 
instructions, 
initial data, 
intermediate 
and 
final results 
Fig. 1.2 
The main components of a simple computer 

1 · 2 AUTOMATIC ELECTRONIC DIGITAL COMPUTERS 
3 
memory is a physical device that can record information and generate a 
copy of this information at a later time. (Magnetic-core memories are used 
in most of the present-day computers. Edsac used the properties of an 
acoustic wave traveling down a tube of mercury.) In the computer the 
arithmetic unit can perform additions, subtractions, and multiplications. It 
can do only one such operation at a time. The processing unit takes the 
place of the operator. This unit picks up the instructions one at a time and 
processes them. A list of instructions is written down on paper, usually 
organized in lines, with one instruction on each line. The computer memory 
is organized in a similar way. The memory is divided into locations. A 
location is a piece of memory that can hold one instruction or one number. 
The Edsac had 1024 locations of memory. The locations can be numbered 
0, 1, 2,..., just as lines on a page. The processing unit can obey a limited 
number of simple instructions. Typical instructions available on Edsac 
were, "Take the number from a location and put it in the arithmetic 
unit." "Take the number from another location and add it to the number 
in the arithmetic unit." " Take the number in the arithmetic unit and place 
it in a location." The Edsac could obey 18 different instructions. All 
calculations had to be expressed in terms of these instructions. In addition 
to the simple arithmetic operations, the Edsac had one input and one 
output instruction and two control instructions. The input device read 
punched paper tape. Each row of the tape could represent a digit, a letter, 
or a special character. The input instruction read one row of the tape and 
put the result into a memory location. The output device was a paper-tape 
punch. The tape could be printed on an off-line typewriter. The output 
instruction took information from the low-order end of a memory location 
and punched one row of the tape. 
A control instruction is any instruction that may change the normal 
sequence of operations. The processing unit takes instructions from the 
memory one at a time. When one instruction has been processed, it 
normally takes the next instruction from the next memory location. In the 
case of control instructions, the next instruction need not come from the 
next location. The first of the Edsac control instructions had the form, "If 
the result of the last arithmetic operation was positive or zero then take the 
next instruction from location n ; if the result was negative then take the 
next instruction from the next location." The other control instruction had 
â similar form except that it changed control if the result was less than 
zero. Control instructions are sometimes called branch, or jump, or transfer 
instructions. 
A computer program is any sequence of instructions which directs 
the computer to perform some specific task. The essential difference 
between Edsac and all previous computers was its ability to take data and 
instructions from the same memory. This simple difference is essential to 
the development of practical programming languages. Since the instruc-
tions and the data are in the same memory, then it is reasonable to assume 

4 
1 COMPUTER 
SYSTEMS 
that the instructions are in numeric form. For example, 10123 might be 
the instruction to place the contents of location 123 in the arithmetic 
unit; 20124 might instruct the processing unit to add the contents of 
location 124 into the arithmetic unit. In practical computers (including 
Edsac), the representation of instructions is slightly more complicated 
than this. We will discuss the representation of instructions in Chapter 2; 
for the moment, we merely wish to establish the fact that a numeric form 
is possible. Since the instructions are numeric and since they are stored in 
the same memory as other numbers, then the processing unit can read cer-
tain types of data and it can use the arithmetic unit to transform this data 
into instructions. In other words the computer can translate from a form 
of instruction that is convenient for the programmer to the form of instruc-
tion that is required by the machine. Any program that is obeyed by the 
machine must consist of machine instructions; however, the machine can 
accept nonmachine instructions and transform them into machine instruc-
tions before obeying them. The translation program used on Edsac was 
very short and simple; it consisted of only 40 machine instructions. The 
language used by the programmer was necessarily very close to the language 
used by the machine; nevertheless, within a few months of the operation 
of this first stored-program computer, the following vital principle had 
been established: the program written by the programmer need not be 
identical with the program that is to be obeyed by the machine. The rapid 
development of programming is illustrated by the contents of the program-
ming book by Wilkes, Wheeler, and Gill, published in 1951. (See the 
references at the end of Chapter 10.) 
To summarize: The first stored-program electronic computer was 
completed in 1949. It had five main components: the input unit, the 
output unit, the memory, the arithmetic unit, and the processing unit. The 
processing unit obeyed about 18 different instructions. These instructions 
included input, output, arithmetic, and control operations. All programs 
had to be written in terms of these simple operations. The machine did 
provide a small amount of help in translating from programmer language 
to machine language. The memory unit could hold 1024 words. The 
machine processed about 500 instructions a second. 
1-3 
THE SECOND GENERATION of COMPUTERS 
Many machines were built in the period from 1950 to 1956. Chapin (1956) 
describes several of these machines. The IBM 704, which appeared at the 
end of 1955, marked the beginning of a new era in computing. The funda-
mental design of the machine did not differ markedly from other machines, 
but the 704 was much bigger, faster, more powerful, and more reliable 
than other machines of the period. The memory was made of ferrite cores. 
These core memories were more reliable than the acoustic delay lines and 

1 · 4 COMPILERS AND ASSEMBLERS 
5 
electrostatic storage devices of previous machines. The IBM 704 could 
add two integers in 24 microseconds (a microsecond is one-millionth of a 
second). The computer had a very wide range of instructions. The instruc-
tions were of the same basic type as those available on Edsac, but there 
was a much greater variety. For example, the 704 had floating-point 
arithmetic; that is, it could add, subtract, multiply, and divide numbers of 
type real as well as numbers of type integer. (The words real and integer 
are used in the Fortran or Algol sense. The corresponding PL/1 terms are 
fixed-point and floating-point.) Most previous machines could only 
manipulate integers ; real numbers had to be processed by time-consuming 
subroutines. The memory on the initial version of the 704 could hold 4096 
numbers, but within a few years memories that could hold up to 32,768 
numbers (or instructions) were available. The 704 had a variety of input-
output devices. Most 704's were equipped with a card reader, card punch, 
120 lines-per-minute printer, and 12 tape units. There were a small number 
of other machines which could have matched the performance of the 704 
at this time. The reasons for the outstanding performance of the 704 can 
be found in the article by Schussel (1965). 
One of the more valuable by-products of the IBM 704 was Share. 
Share was formed as an organization of users of the 704 computers. In 
later years users of other large IBM machines became members of Share. 
These users developed the techniques that are the basis of many of the 
current programming systems. 
1 -4 
COMPILERS and ASSEMBLERS 
The first programming language available on the IBM 704 was SAP 
(Share Assembly Program). The machine language of the 704 used a 
numeric code to specify the instruction and a number to specify the 
location to be used by the instruction. SAP allowed the programmer to use 
mnemonic instruction codes; ADD denoted the integer addition instruc-
tion, SUB denoted the subtract operation, and so on. SAP also allowed 
the programmer to use names in describing memory locations. The 
assembly program would read the SAP instructions, convert instructions 
like ADD into the proper numeric machine instructions, and replace 
location names by appropriate numbers. The type of instructions processed 
by SAP were called symbolic instructions because they used symbols rather 
than numbers. Symbolic instructions are still quite closely related to 
machine instructions. There is one symbolic instruction for each machine 
instruction. The assembly program does a one-for-one translation. The 
programmer still has to break his program down into a large number of 
simple steps. 
During the early days of the IBM 704, members of Share and of 
IBM together designed and implemented a language for/ormula frawslation. 

6 
1 COMPUTER 
SYSTEMS 
This Fortran language was not the first of the higher-level languages 
(see for example, Baker, 1956) but it was much more ambitious than 
previous languages. In fact, in the early days of Fortran many people felt 
that the designers had been too ambitious. The following kinds of state-
ments in Fortran I were almost identical with those of the later versions of 
Fortran: DO, GO TO, three branch IF, READ, WRITE, FORMAT, 
DIMENSION and arithmetic statements. The rules governing names of 
variables and the rules about subscripting were identical with those of 
Fortran II. This first version of Fortran appeared in 1957. It was not used 
by many programmers. There were two reasons for its lack of success. 
First, most programmers were not willing to accept a language of this 
sort. They were quick to discover any slight inefficiency in compiler-
produced programs. They were not willing to admit that most programmers 
would produce code having less than optimum efficiency. The second 
objection to Fortran was a valid one. The translation process was extremely 
slow. It could take as long as 20 or 30 minutes, and even after this length 
of time the compiler might discover an error which prevented a successful 
compilation. 
The words " compile " and " assemble " mean essentially the same 
thing as translate ; however, it is customary to use them in a more specialized 
sense. A translator such as SAP is called an "assembler," and a translator 
such as Fortran is called a " compiler." An assembly language is a program-
ming language based on symbolic instructions. Symbolic instructions are 
directly related to machine-language instructions. A symbolic instruction 
represents a machine instruction by using some convenient symbols for the 
various parts of the machine instruction. A compiler language is a language 
that is designed for the convenience of expressing certain ideas ; as far as 
possible, the design of a particular computer should not influence the main 
details of a compiler language. Compilers are problem oriented; assemblers 
are machine oriented. One compiler-language statement usually produces 
several machine-language instructions. One assembly-language instruction 
usually produces one machine-language instruction (see Section 4.8 for 
assembly-language statements that produce several machine-language 
instructions). In this book the term "compiler language" will almost 
always mean the same as "Fortran, Algol, or PL/1 " since these are the 
three most important scientific compiler languages. Statements such as 
X=A+B*C 
and 
IF (RATE>MAXIMUM_RATE) THEN GO TO OVER-CHARGE 
obviously belong to some compiler language. The statements 
LDQ 
B 
FMP 
C 
FAD 
A 
STO 
X 

1 · 4 COMPILERS AND ASSEMBLERS 
7 
are symbolic instructions for the IBM 7090. The SAP assembler would 
translate these four instructions into four machine language instructions. 
Many compilers do their translation in two or three phases. Phase one 
involves translation from compiler language into symbolic instructions; 
phase two translates these symbolic instructions into relocatable binary 
instructions; and phase three involves the translation from relocatable 
binary to the final machine-language instruction. Relocatable binary 
instructions are discussed in Chapter 6. These three phases of compilation 
are not essential, but they do make the overall process more flexible and 
more efficient. If the statement 
X=A+B*C 
were presented to the Fortran compiler, then in the first phase it would 
produce the four symbolic instructions shown above. 
The Fortran II compiler appeared in 1958. It did not differ greatly 
from Fortran I, but the few new features did transform a good but imprac-
tical compiler into a very useful and powerful programming system. The 
first of the new features involved a reorganization of the compiler. The 
compiler now searched for errors in the Fortran text at the earliest possible 
moment. The diagnostic comments produced by the compiler were a great 
improvement over those of Fortran I. These changes to the compiler 
enabled the programmer to correct many of his mistakes without too great 
an expenditure of machine time. The second new feature of Fortran was 
the introduction of subroutines and COMMON. The concept of a sub-
routine will be familiar to Fortran programmers. Subroutines do not occupy 
such a prominent place in Algol or PL/1. A subroutine is a set of instruc-
tions that performs some specific function and receives information from 
other programs by some standardized route. For example, the set of 
instructions that computes the cosine of an angle is a subroutine. The 
important thing to remember is that this cosine subroutine was written by a 
programmer at some previous time. In other words, a subroutine can be 
compiled (or assembled, if it happens to be written in assembly language) 
independently of the program that uses it. (External procedures in PL/1 
have this property. Procedures in Algol that do not use any global variables 
also have this property. Both PL/1 and Fortran allow the program to be 
split up and compiled in independent pieces. Algol compilers could allow 
this feature but they usually do not.) Fortran II allowed the programmer to 
split his program into many subroutines. Each subroutine was compiled 
independently. Successful compilations resulted in the production of a 
punched-card deck that contained relocatable binary instructions. The 
initial compilation of a large program still took quite a long time; however, 
when errors in a program were discovered, only the subroutines containing 
the errors had to be recompiled. The relocatable decks of the error-free 
subroutines could be utilized and no compiling time was necessary for those 
routines. 

8 
1 COMPUTER 
SYSTEMS 
Compilers and assemblers translate statements into machine-
language instructions. All of the translation is completed before any of the 
machine-language instructions are executed. There is an alternative mode 
of operation which is performed by an interpreter. An interpreter takes one 
statement, translates it, and then causes it to be executed. It then takes the 
next statement, translates it, and causes it to be executed. Consider the 
statements 
DO 100 1 = 1,50 
100 
X = X + Y(I) 
The Fortran compiler would translate statement number 100 and then at 
execution time the machine-language instructions would be obeyed fifty 
times. If an interpreter were to operate on these statements, then it would 
interpret each statement as it came to the statement during the course of the 
execution. Statement number 100 would be translated and executed 50 
times. If an algorithmic language is to be obeyed by the computer, then a 
compiler is nearly always used since it obviously is much more efficient 
than an interpreter. If a system or a computer is to be simulated, then it may 
be easier to use an interpreter. For example if the operation of the IBM 360 
is to be simulated on the IBM 7090, then the 7090 could read the 360 
machine-language program into the memory of the 7090 and then use an 
interpreter to take the first 360 instruction, then the second instruction, and 
so on. Instructions are taken in the order in which they would be executed 
on the 360, not in the order in which they would have appeared on the 
coding sheet. As the interpreter picks up each instruction it examines it 
and it uses several 7090 instructions to simulate the behavior of the 360. 
1 -5 
I/O CHANNELS 
Once the design and production of the IBM 704 was successfully com-
pleted, various suggestions for improving the machine were put forward. 
These suggestions resulted in a new machine, the IBM 709, which appeared 
in 1958. The 709 differed from the 704 in only two respects; there were 
some additional arithmetic and control instructions and the processing of 
I/O (input or output) was done in a completely new fashion. The new 
instructions were very useful but they did not change the essential character 
of the machine. The changes in the I/O did have several very important 
consequences. 
The input and output devices on the IBM 704 were all used in 
somewhat the same fashion. For convenience, we will consider the reading 
and writing of magnetic tape. The information on a tape could be read by 
giving a read-select instruction followed by a series of CPY instructions. 
CPY is the symbolic instruction on the 704 that reads one word from tape 

1 - 5 
I/O 
CHANNELS 
9 
and places the word in the memory. A word is the contents of one location; 
it might be an integer, a real number, six alphabetic characters, or one 
instruction. The effects of the Fortran statement 
READ TAPE 9AB,C,D,E 
could be achieved by the read-select tape 9 instruction followed by five 
CPY instructions, one CPY for each word read. The reading of magnetic 
tape is slow compared with all non-input-output operations. The 704 took 
24 microseconds to add two integers but it took about 400 microseconds to 
read one word. On more modern computers the arithmetic and the tape 
reading and writing instructions are faster, but the ratio of arithmetic to 
read or write time is still about 1 to 10 or 20. Reading from a magnetic 
disk or drum takes about the same time as reading from tape. It was 
theoretically possible on the 704 to do some computing while waiting for a 
word to be brought from tape, but in practical situations this was seldom 
achieved. Information on magnetic tapes is arranged in records. A record 
is a number of words that occupies a continuous piece of tape. A record 
usually holds anywhere from 10 to 250 words. The time sequence of 
operations in a typical job on the 704 is shown in Figure 1.3. The program 
read 
write 
compute 
time 
Fig. 1.3 
The time sequence of read, write, and compute operations in a typical job on the IBM 704 
reads some data, it computes for some time, and then writes some results. 
Since the I/O operations are slow, much of the time is spent on the I/O 
operations. 
Figure 1.2 showed the main components of a machine like the 
704. Figure 1.4 shows the main components of the 709. The channel is a 
CPU 
memory 
data synchronizer 
channel 1 
channel 2 
input and 
output units 
input and 
output units 
Fig. 1.4 
The main components of the IBM 709 

10 
1 COMPUTER 
SYSTEMS 
simple special-purpose computer. It is concerned solely with the processing 
of I/O operations. The processing unit and the arithmetic unit are combined 
into a unit called the CPU (central processing unit). The computer is used 
in the following way. The program is contained in the memory, just as it 
was in the 704. The CPU takes the instructions one at a time and processes 
them. Whenever it comes to a read or write request, it makes use of one 
of the channels. The 709 selects a tape unit on a particular channel and then 
tells the channel to read a complete record. Once the channel has accepted 
the I/O request the CPU can continue to do useful computing. The channel 
controls the reading of the words in the record and stores the words in the 
correct place in memory without any further instructions from the CPU. 
The program illustrated in Figure 1.3 has been reorganized to take advan-
tage of the 709 channels and the results are shown in Figure 1.5. As can 
1 
2 
3 
channel 1 read 
channel 1 write 
channel 2 read 
channel 2 write 
compute 
time 
Fig. 1.5 The overlay of computing the I/O which is possible on the 709. The significance of the numbers 
is explained in the text. 
be seen, reading, writing, and computing proceed in parallel. There can be 
as many simultaneous I/O operations as there are channels. The 709 
typically had either two or four channels. In the example given in Figure 1.5 
the first record is read in (the numbers over the line refer to the number of 
the record). Once the contents of record 1 have been read in, some useful 
computing can begin and record 2 can be read in; it must, of course, be 
read into some other portion of the memory. When the computing con-
nected with record 1 is complete, the results can be written'out; computa-
tion of the data from record 2 can begin, and record 3 can be read into 
memory. The degree to which I/O can be overlapped with computing 
varies from program to program and from problem to problem. For 
many problems it is possible to achieve a substantial saving of time. I/O 
operations on the card reader, the card punch, the on-line printer, and any 
other I/O device, are usually controlled through a channel. 
Rewriting 704 programs for use on the 709 should have been quite 
painless. Only the I/O portions of the programs needed to be changed. 
However, many computer centers found that the transition to the new 
machine was not easy. In searching for solutions to their problems, they did 
1 
2 
1 
2 
3 

1 - 5 
I/O 
CHANNELS 
11 
learn many valuable lessons. The first was that programs should be 
divided into a number of independent routines. I/O instructions, in 
particular, should be well separated from other parts of the program. 
Programmers should obey certain rules and use certain standard library 
routines. These ideas seem commonplace today, but before 1959 there were 
very few rules or standards. The first Fortran compiler translated some 
READ and WRITE statements into actual I/O instructions. In later 
versions of Fortran a statement such as 
READ TAPE 9,A,B,C,D,E 
would generate instructions that would cause the program to jump into a 
subroutine. The subroutine would be told that variables A,B,C,D, and E 
are to be read from tape 9. The subroutine responsible for these opera-
tions was written by some systems programmer, stored on some library 
tape (or disk or drum), and brought into memory at the same time as the 
rest of the program. There are several advantages to the use of standard 
I/O routines. Subtle errors in I/O routines are difficult to detect and can 
easily be confused with equipment malfunction. The writing of a general 
purpose I/O routine is difficult, and checking out such a routine may take 
several man years. A standard set of routines makes it easier to incorporate 
new ideas and to change over to new equipment. In a modern computer 
center, the systems programmers could change the computer from tape-
oriented operation to disk-oriented operation without the average pro-
grammer being aware of any change. They would change the I/O programs 
so that READ TAPE and WRITE TAPE statements would actually read 
and write on the disk. As long as the I/O program keeps track of all 
READ, WRITE, REWIND, and BACKSPACE operations, the pro-
grammer need never know the actual state of affairs. As we shall see later, 
the systems programmers often choose to deceive the ordinary programmer 
in this way. All that matters to the programmer is that the correct things 
appear to happen; only the external appearance is of any significance to 
the programmer. 
The second lesson that emerged from the introduction of the 
IBM 709 was the following: there can be many disasters between the initial 
design and the final appearance of a complex operating system. The 
simultaneous I/O feature of the 709 suggested many new ways of using the 
machine and several novel operating systems were planned. The most 
ambitious of these new systems was SOS (Share Operating System). It 
turned out, after several years of disputes, that the system was too sophisti-
cated for the current state of the art of programming. Several of the largest 
computer centers did persevere with the system, but most centers found it 
wiser to use a simpler system, namely, the Fortran monitor system. It was 
not until 1963 that a really powerful method for using the I/O channel 
came into general use. 

12 
1 COMPUTER 
SYSTEMS 
1 -6 THE INTERRUPT SYSTEM 
In the early days of 1960, a number of transistorized computers appeared 
on the market. They were faster and more reliable than the earlier machines. 
The IBM transistorized machine was the 7090. It was an almost exact copy 
of the 709; all instructions, other than I/O operations, were five times faster 
than the corresponding 709 instruction. The main components of the 
machine are shown in Figure 1.6. There is no longer any direct path from 
CPU 
multiplexor 
memory 
channel 1 
channel 2 
input and 
output units 
input and 
output units 
Fig. 1.6 The flow of information in the main components of the IBM 7090 
the CPU to the memory. All memory references go through a device called 
the "multiplexor." The multiplexor controls the flow of information to 
and from the memory and resolves any conflicts. The existence of the 
multiplexor does not change the way in which the programmer uses the 
machine, but it is a further stage in the evolution of the design of 
the machine. Early computers had a monolithic structure and units 
of the machine carried out many tasks. In a modern machine there are a 
number of separate asynchronous units, each with its own clearly 
defined task. 
In the previous section we described the channel, and explained 
how the CPU could tell the channel to read a complete record. The orders 
that the CPU issues to the channel are usually called "commands"; the 
word "instruction" is reserved for the orders that the CPU obeys. The 
command to read one record has already been mentioned. There are a 
number of other possible commands; for example, "read either n words or 
one record." In this case the channel reads the complete record if the record 
contains less than n +1 words ; otherwise it reads n words and ignores the 
other words in the record. There are also several different commands that 
can be given when the channel is asked to write. Suppose the channel is 
asked to read one record. When the record has been read, the channel 
stops. In some machines the channel simply remains dormant until some 
future time when the CPU reactivates it. In the IBM 7090, when the channel 
has finished its task, it sends a signal to the CPU; this signal causes an 
interrupt. The interrupt system is a major feature of many modern com-
puters. 

1 ■ 6 THE INTERRUPT SYSTEM 
13 
The operation of the interrupt system can be illustrated by the 
following analogy. Suppose you are engaged in some work and the 
telephone rings. You make a note of what you are doing and you answer 
the telephone. When the call is complete, you resume your work at the 
place where you left off. In the 7090, the CPU gives the instruction for an 
I/O operation to commence and then it starts on some other calculation. 
When the channel gives the end-of-operation signal, the computer makes a 
note of the current situation and goes off to attend to the signal. In 
practice, all that happens is that the CPU stores the location of the current 
instruction in one fixed location and then sends control to another fixed 
location. The systems programmers will have placed an interrupt processing 
routine at this fixed location. This routine examines the status of the 
channel. If the channel indicates that errors occurred during the read, then 
the routine backspaces the tape and attempts the read a second time. If 
there are no errors, then the routine looks to see if any other I/O operations 
need to be initiated. If no more work remains to be done, the routine 
returns control to the proper place in the routine that was interrupted. 
There is one respect in which the analogy of the telephone conversation is 
not valid. If you are interrupted, you usually remember that an interruption 
took place. In a computer the interrupted program never realizes that an 
interruption has taken place. The CPU suddenly takes control away from 
the main program and hands it to the input-output routine. That routine 
takes care not to destroy any of the information used by the main program, 
and when it is finished, it starts the main program from exactly the place at 
which it was interrupted. The elegant feature of the method is that the main 
program does not have to be written with interrupts in mind. The program 
is written in the normal way. The person who is writing the main program 
does not need to know about interrupts. 
A few years after the appearance of the 7090, IBM introduced the 
two models of the 7094. These machines were almost identical with the 7090 
but were faster by a factor of from 1.5 to 2.5. The IBM 704, 709, 7090, and 
7094 dominated the market for large scientific computers for ten years. 
Most of the large programming systems and many of the important ideas 
in the programming field were developed on these machines. Part of the 
reason for their success was the gradual development of the machines. It 
takes three or four years to develop the assemblers, compilers and operating 
systems necessary on a large computer. If a new computer is reasonably 
compatible with some previous computer, it can use the old systems while 
new ones are developed. Even when the new systems are operating many of 
the users' programs must be developed for the new machine. 
The CDC 1604 appeared in the same month as the IBM 7090. It is 
a transistorized machine of the same size and about half the speed of the 
7090. The 1604 and the 7090 were two of the very few large computers 
which had any great commercial success. In 1963 CDC brought out the 
3600. This machine was similar to the 1604. Programs for the 1604 that did 

14 
1 COMPUTER 
SYSTEMS 
not contain I/O instructions run, at about four times the speed, on the 3600. 
The interrupt system on the CDC 3600 has a simplicity and generality not 
found in the 7090. The interrupt mechanism of the CDC 3600 is called 
into action whenever any unusual condition occurs. For example, the 
programmer can specify how long his job should run. If this limit is 
exceeded, then an interrupt occurs. Parts of the computer memory are 
reserved for the operating system. If the programmer makes an error that 
would destroy the part of the memory belonging to the operating system, 
an interrupt occurs. Arithmetic faults such as trying to divide by zero cause 
an interrupt. The termination of any channel operation causes an interrupt. 
All interrupts are handled in the same way. The CPU stores the location of 
the current instruction in the first location in memory and then it jumps 
to the second location in memory. This second location always contains a 
jump to the start of the routine which will process the interrupt. A powerful 
interrupt-system of this sort allows a program in one part of the memory to 
keep control over programs in the other part. This routine, which takes 
control whenever anything unusual happens, is part of the monitor. 
1 -7 THE MONITOR SYSTEM 
The Fortran system used in the IBM 704 consisted of a compiler and several 
decks of cards. The card decks contained relocatable binary instructions 
of the standard subroutines. The programmer used the compiler to process 
his Fortran program ; the result was a relocatable binary deck. He manually 
added the decks of a loader and the appropriate library routines and then 
put the deck back in the computer. If loading was successful, the operation 
of his program would begin. The program would continue running until 
it reached the end of the calculation, a fatal error was encountered, or the 
operator terminated the job. Several methods of automatic operation were 
developed for the IBM 704 and the 709. The system that eventually gained 
the most widespread use was FMS, the Fortran monitor system on the 
IBM 709 and 7090. Part of the attraction of FMS was that it did not try 
to do too much. It did not use the full power of the 7090, but it was a 
great improvement over manual methods of operation and it was reliable 
and easy to use. It was not until 1963 that a more sophisticated system, 
which did use the full power of the 7090 interrupt system, was brought into 
general use. 
A monitor system is a large program. It consists of several dis-
tinct units. In a simple system such as FMS, these units are (a) the I/O and 
interrupt routines, (b) the control card scanning routine, (c) the accounting 
routines, (d) the compiler, (e) the assembler, (f ) the subroutine library, and 
(g) the loader. FMS used the Fortran II compiler and it had an assembler 
called FAP, the Fortran assembly program. FAP was similar to SAP but it 
was also more powerful. It produced relocatable binary cards that were 
in the same format as the cards produced by the compiler. It had several 

1 . 7 THE MONITOR 
SYSTEM 
15 
other features that made it easy to use Fortran-coded and FAP-coded 
subroutines within the same program. The word " monitor " seems to have 
several different meanings. The definitions in the Automatic Data Processing 
Glossary (1962) suggest that "monitor" refers to item (a) mentioned 
above, whereas "monitor system" refers to items (a) through (g). It seems 
safer to say that a monitor, supervisor, or executive system is a collection 
of standard routines that assist the programmers and control the execution 
of the program. The word "monitor" itself may refer to some component 
of the monitor system. A statement such as A = B + C implies that A should 
be set equal to the sum of B and C. Before this addition operation actually 
takes place, the program must go through the stages of compilation, 
assembly, and loading. The final phase, in which B does get added to C, is 
called execution. The execution monitor is that part of the system which 
supervises execution—it constitutes item (a). Items (b) and (c) are sometimes 
called the "job monitor." 
The first computer we discussed, the Edsac, was an electronic 
device for doing calculations. It had a very short and simple loader. The 
IBM 704 was a much more powerful machine and it had a good assembler, 
but the method of using the machines did not differ in principle. With the 
development of a system like FMS, the essential character of the computer 
was changed. The electronic and other physical parts of the computer are 
called " hardware." The monitor system is referred to as " software." These 
terms emphasize that the hardware and the software are equally important 
components of the computing system. The Edsac was all hardware. A 
modern machine like the IBM 360 is 50 percent hardware and 50 percent 
software. The hardware of the machine is fixed by the designer. The 
customer can choose the size of the memory, the number of disk units, and 
so on, but he cannot alter the basic operations of the machine. In a 
modern computer the software is also a fixed part of the system. It is true 
that the software can usually (but not always) be changed without using 
a soldering iron, but most computer centers accept the software provided 
by the manufacturer. The computer center may modify some parts of the 
software, but they do not allow the average user to circumvent the basic 
software. The central part of the software is the execution monitor—that 
is, the routines that control the I/O and the interrupts. In a modern com-
puter these routines cannot be destroyed or modified in any way by the 
programmer. In the 7090 there is nothing to prevent the programmer from 
erasing the execution monitor and seizing control of the machine. In the 
CDC 3600, the IBM 360, and most other large machines, any attempt to 
overwrite the execution monitor causes an interrupt and the job is termi-
nated. Any attempt to initiate an I/O operation also causes an interrupt. If 
the programmer needs some I/O, then he must send his request to the 
execution monitor. The compilers, assemblers and loaders are also forced 
to use the execution monitor. They are subject to almost the same restric-
tions as ordinary programs. 

16 
1 COMPUTER 
SYSTEMS 
1-8 
THE FORTRAN MONITOR SYSTEM 
The FMS system was formed by modifying existing compilers, assemblers, 
and loaders, and thus it was not feasible to use a single-execution monitor. 
Although each component of the system tended to use its own monitor, the 
FMS is a good example of a simple monitor system. A job is presented to 
the system in the form of a deck of cards. The deck may consist of the 
following. 
a job card 
cards containing Fortran statements 
for one or more routines 
* FAP 
cards containing FAP statements for 
one routine 
* FAP 
cards containing FAP statements for 
another routine 
* BINARY 
cards containing relocatable binary 
instructions for one or more 
routines 
* DATA 
any data used by the program 
an end-of-file card 
The job card contains the name of the customer, the account number, the 
maximum time and the maximum number of lines of output for the job. The 
control card scanner recognizes any card having an * in column 1. These 
cards can cause the assembler or the loader to be called. There are several 
more * cards that specify various options, such as labeling of cards, sup-
pression of listings, and so on. The deck may consist of only Fortran, only 
FAP, or only Binary cards, or it may consist of any mixture of these 
three. The end-of-file card indicates the end of the deck. In most computer 
centers the cards for several jobs are put onto magnetic tape by using a 
small computer such as the IBM 1401. The monitor routine starts by calling 
in the control card scanner. Subsequent actions are shown in Figure 1.7. 
The compiler processes all the Fortran cards. If the compilation of a routine 
is successful, then the relocatable binary cards for the routine are put on 
the punch tape. This tape serves two purposes. If all the other compilations 
and assemblies are successful, then the loader reads the binary decks from 
the punch tape and produces the machine-language form of the program. 
When all the jobs are finished, the operator can transfer the punch tape to 
a small computer that punches the binary cards. If there are any FAP 
routines, the assembler also puts its binary cards onto the punch tape. These 
binary cards can be used in subsequent runs to eliminate the need for 
compilation or assembly. 

1 . 8 THE FORTRAN 
MONITOR 
SYSTEM 
17 
St 311 
1 
i 
•η read one card 
j 
end of file? L 
1 
no 
first card ? 
i 
no 
1 * BINARY? 1 
no 
r 
| * DATA? 
no 
1 
1 * FAP? 1-
no 
r 
l 
no / 
been read? 
1 
read past end of file 
is execution required? 
record time and 
page limits 
* in column 1 ? 
no 
r 
Fortran 
compiler 
I 
T 
< 
1 
no 
accounting routine 
J 
' 
\ any errors? 
Fap assembler 
r 
S 
' 1 
no 
1 
loader f* 
process control 
card 
if 
H errors? 
y 
r 
no 
1 
Execution 
begins 
Fig. 1.7 
Actions generated by the scanning of control cards 
The flow of information through the compiler, assembler, and 
loader is shown in Figure 1.8. The loader takes the binary card images (if 
there are any) from the punch tape and converts them to machine language. 
It acts similarly on any binary card images on the input tape. During this 
conversion it makes a note of any missing routines and looks for them in 
the library. The library is a standard magnetic tape, or a standard part of a 
magnetic disk, which contains the relocatable binary instructions for some 
commonly used routines. The library always contains routines like SINF 
and EXPF, which are standard Fortran routines. It may also contain, at 

18 
1 COMPUTER 
SYSTEMS 
Fortran statements 
w 
Fortran compiler 
' f 
symbolic instructions 
' f 
assembler 
' ' 
relocatable binary 
instructions 
relocatable binary 
cards 
the Library in 
relocatable binary 
Fap statements 
Fap assembler 
relocatable binary 
instructions 
the loader 
machine language 
instructions 
execution 
Fig. 1.8 
Flow of information through the compiler,assembler, and loader. Symbolic instructions from 
Fortran could go through the FAP assembler. For historical reasons, there are two assemblers. 
the discretion of the computer center, any additional routines in common 
use. If the loader finds all the missing routines on the library tape, execution 
is begun. If it does not find the routines, execution is deleted. 
The transition from the situation shown in Figure 1.3 to that 
shown in Figure 1.5 suggests that the program must be rearranged if it is 
to take advantage of the I/O channels. The burden of this rearrangement 
need not rest on the programmer. The system can arrange for overlap of 
computing, input, and output, although it does not always manage to do 
this with optimum efficiency. The FM S method of treating a statement 
such as 
WRITE TAPE 9,A,B,C,D,E 

1 · 9 ALGOL 
19 
is to arrange a jump to a system routine called (STB). The routine (STB) 
copies the values of A,B,C,D, and E into a buffer. A buffer is simply a set 
of memory locations within the I/O routine which is used to hold data 
before it is written (or in the case of a READ, after it has been read). The 
original values of the variables are not changed by this copying; (STB) 
gives the instruction to commence writing the five words from the buffer 
and it returns to the Fortran program. The timing is illustrated in Figure 
1.9. The execution of the Fortran WRITE statement occurs at time tv This 
write operation 
routine (STB) 
Fortran program 
-
tl Î2 
U U 
time 
* -
Fig. 1.9 
causes a jump to the subroutine (STB). During the time from tx to t2 that 
routine copies the five values and starts the I/O. The I/O then continues in 
parallel with the further calculations of the Fortran program. The Fortran 
program may change the values of any of the variables, since it is the copies 
of the variables within the buffer that are being written on tape. At some 
later time, time t3, the Fortran program requests another WRITE. (STB) 
checks to see if the previous operation has been successfully completed and 
then it processes the new write statement. In this particular instance the 
technique used by (STB) is quite efficient. It has overlapped writing and 
computing although the programmer did not have to rearrange his 
program. In some other cases (STB) is not so efficient. If the WRITE is 
required to write more than 255 words, if there is a READ operation, or 
if there are several consecutive WRITE statements, then the I/O routines 
used by FMS do not achieve the efficiency of the more sophisticated systems 
which we will presently describe. 
1-9 
ALGOL 
An algorithm is an explicit sequence of instructions that leads to the 
solution of some computable problem. An algorithmic language is a 
language that can be used to specify algorithms. English and Fortran are 

20 
1 COMPUTER 
SYSTEMS 
examples of algorithmic languages. Algol is an algorithmic language that 
was specified by an international committee. The defining report is Naur 
et al. (1963). Fortran is the language that is acceptable to a certain compiler 
on a certain machine. Some of the rules of Fortran are stated in the Fortran 
manual but there are many Fortran programs that wilfully and success-
fully violate these rules. The designers of Algol wanted the language to be 
independent of machines and compilers. They tried to write a document that 
would define the syntax and the semantics of the language in a complete 
and unambiguous way. The syntax defines the combinations of symbols that 
constitute a legal statement. The semantics gives the meaning of these 
legitimate statements. The Algol document was written before any Algol 
compiler had been attempted. The committee hoped that Algol would 
become a universal language in the sense that any Algol program could be 
run on any computer. In changing from one computer to another it might 
be necessary to change from one character set to another, but no change 
in the language of the program should be necessary. The report came very 
close to defining an unambiguous language. Algol has not had the impact 
on programming that might have been expected, but it did generate many 
new ideas on the design of algorithmic languages and the writing of 
compilers. 
Fortran programs are written in the 48 characters available on the 
IBM keypunch. Algol has a standard set of symbols for use in publishing 
algorithms, but a particular compiler may substitute any unique symbol or 
set of symbols for any of the reference symbols. For example, the reference 
symbols x, := ,î, and Φ are commonly replaced by *, =, **, and 'NQ'. 
The reference language statement 
A:=B + Ctl; 
when written for the compiler on the CDC 1604 appears 
A= B + C**l$ 
The symbol ; ( or $ on the 1604) denotes the end of a statement. The end of 
a card is not used as an indication of the end of statement. 
Many of the statements in Fortran have a corresponding Algol 
statement. This is not surprising since both languages were designed to 
describe algorithms. In both languages an identifier, that is, the name of 
variable, consists of one letter followed by letters or digits. In Fortran II 
there is an upper limit of six characters; the limit stems from one of the 
characteristics of the 704. In Algol there is no limit to the number of letters 
or digits. The Fortran statement 
DIMENSION 
A(10,15),B(10,15) 

1 · 9 ALGOL 
21 
would correspond to the Algol statement 
ARRAY AB [10,15] 
but Algol also allows the more general form 
ARRAY 
C [-2:10,21 :100] 
which implies that the subscripts on the two-dimensional array C range 
from —2 to +10 and +21 to +100. All Fortran subscripts must start at 
unity. In Algol, the dimensions of an array need not be constants, for 
example 
ARRAY 
D [ 7 : 7 - N , - 1 2 : N*N + 2 * M , I - J ] 
is legitimate since any arithmetic expression may be used as an array 
bound. Fortran IV does allow variables dimensions but it places many 
unnecessary restrictions on these dimensions; the DIMENSION statement 
is not nearly as powerful as the ARRAY statement. In Fortran a subscript 
must be of the form: integer constant times integer variables plus or minus 
an integer constant. In Algol, any arithmetic expression may be used. The 
Fortran DO statement has the form 
DO s / = /l,/2,/3 
where s is a statement label, / is an integer variable and /l,/2,/3 are integer 
variables or positive constants. The corresponding Algol statement is much 
more powerful. It has the form 
FOR 
V = V1 STEP 
V3 UNTIL V2 
where Y is a real or integer variable and VI, V2, V3 are any arithmetic 
expressions. Algol introduced the idea of logical variables and logical IF 
statements. In all of these respects Algol is a much more powerful and 
convenient language than Fortran. 
A Fortran program can be divided into subroutines. Subroutines 
are useful from several points of view. Among other things (1) they allow 
one block of code to be used from different places in the same program, 
(2) they enable one block of code to operate on different sets of arguments, 
(3) they make it easy for one programmer to use routines written by some 
other person, (4) they form a convenient unit of program organization, 
(5) they make the compiling process more efficient; it is much faster to 
compile several small routines than to compile one large program, and 
mistakes are corrected with a smaller amount of recompilation. An Algol 
program is divided into blocks and procedures. These subdivisions possess 
the first four advantages listed above, but they do not possess the fifth. The 

22 
1 COMPUTER 
SYSTEMS 
structure of an Algol program makes it difficult to break it into units which 
can be compiled independently. 
There was a suggestion in 1961 that Algol should replace Fortran. 
This did not happen for several reasons. Algol compilers were written for 
small machines, but the first Algol compiler for the IBM 7090 did not 
appear until 1963, and in the words of one of the authors, " It is at best an 
experimental processor, since it lacks all the refinements of a complete 
system. There has never been an effort to develop this as a full-scale and 
efficient system" (R. G. Franciotti, An Introduction to the Share Algol 60 
translator, unpublished). Algol was a good language in theory, but it was 
not embedded in a system. The Algol report has nothing to say about 
systems—in fact, it even ignores the question of input and output. There is 
no doubt that an efficient compiler embedded in a comprehensive system 
could have been written for the 7090. Had such a system been written in 
1961, then Algol might have replaced Fortran. However, at that time 
people were still discussing whether it was even possible to write an Algol 
compiler. Algol had some success on small computers, particularly among 
programmers who had had no previous experience in computing, but it 
was ignored by the majority of the users of the large machines. As we shall 
see, many of the good ideas from Algol have been used in PL/1. 
1-10 
FORTRAN IV and FORTRAN 63 
Fortran IV is a name that has been applied to many different compilers on 
a wide variety of machines (see, for example, McCracken, 1965, Appendix 
I). We will restrict our usage of the name to the Fortran IV compiler on the 
IBM 7090-7094. The first Fortran compiler appeared in 1957 and by 1960 
it had been developed into a powerful and widely used system. During 
this time there were many developments in the design of languages, com-
pilers, and systems. Further improvement of the Fortran Monitor System 
was not feasible and the development of a new system became necessary. 
The new system, which had the name IBSYS, appeared late in 1962. It 
came into general use in 1963 when part of the system that contained Fort-
ran IV was released. Fortran IV was a disappointment. It contained many 
new features, it was a significant advance over Fortran II, but it lacked 
many of the more powerful features of Algol. It must be admitted, however, 
that a moderately good working compiler such as Fortran IV is far prefer-
able to an excellent compiler that does not work. 
Some of the new features of Fortran IV were TYPE statements; 
logical, double, and complex variables; variable dimensions; logical IF 
statements; data statements; and labeled Common. The irritating restric-
tions on subscripts and on DO loops were retained. The implementation of 
varying dimensions was not very satisfactory. The READ and WRITE 
statements still retained the troublesome and unnecessary format statement. 

1 . 11 IBSYS 
23 
Formatted reading and writing is a useful tool, in the hands of an expert, but 
it is a constant source of difficulty to the beginning programmer and to 
the many programmers who use the machine infrequently. Several of the 
supposed advantages of Fortran IV created dismay. The overall system 
was extremely large. Many programs which had worked in Fortran II 
would not operate under Fortran IV because the system used too much 
memory space. 
Fortran 63 is a compiler on the CDC 1604; a very similar compiler 
called Fortran 3600 exists on the CDC 3600. These compilers have the 
following advantages over Fortran IV. They do allow any arithmetic 
expression to be used as a subscript. They allow integer and real variables 
to be mixed in one expression. They allow the manipulation of binary bits 
and of alphabetic characters. They provide ready access to programmer-
controlled buffered input and output operations. Fortran IV includes a very 
sophisticated built-in buffering scheme which is efficient in some circum-
stances but very inefficient in others. It makes it very difficult for the pro-
grammer to control his own I/O operations. Fortran 63 provides very little 
buffering but it does make it easy for a programmer to do his own buffer-
ing. Fortran 63 is superior to Fortran IV in many respects but it lacks the 
elegant features that were promised by Algol. 
One of the interesting features of Fortran 63 is its small size. The 
Fortran compiler and the assembler are retained in memory throughout 
successive compilations. The Fortran IV compiler is much too large to 
fit in memory. The compilers on IBM machines have been noted for their 
size and their lack of speed, but on the other hand they are also noted for the 
efficiency of the compiled program. It is difficult to compare different 
compilers on different machines but Gries, Paul, and Wiehle (1965), give 
some figures for one particular program which was compiled under three 
different compilers on the IBM 7090. The figures are as follows. 
Compile and load 
Execute 
Total 
Alcor-lllinois Algol compiler 
37 
320 
357 
Fortran il 
260 
190 
450 
Share Algol compiler 
330 
630 
960 
All of the times are in seconds. For this problem, the Alcor compiler is 
superior if the program is recompiled every time but Fortran II is superior 
if the binary deck can be used on subsequent runs. 
1-11 
IBSYS 
IBSYS is the name of an operating system used on several large IBM 
machines. We are concerned with the IBSYS on the IBM 7090-7094. The 

24 
1 COMPUTER 
SYSTEMS 
system was introduced in 1962 and 1963. At that time there were many 
operational systems on the 7090. IBSYS is a monitor of monitors. It 
includes several of the older system. The subsystem of particular interest is 
IBJOB, since Fortran IV is part of IBJOB. The IBJOB part of IBSYS was 
a completely new system which was developed ab initio. It contains many 
features that are desirable in a modern system. It also contains a number of 
undesirable features which stem from deficiencies of the 7090 hardware. 
IBJOB contains a compiler, namely Fortran IV. It contains an 
assembler with the name MAP (macro assembly program). It contains 
IBLDR, a loader which accepts the relocatable binary cards produced by 
Fortran IV and MAP. In the first version of IBJOB, the symbolic language 
instructions from the compiler were passed on to MAP. MAP has many 
powerful but time-consuming features that are not used by the compiler 
output. A later version of IBJOB has introduced a simple assembler into 
the compiler. 
The operation of IBJOB can be illustrated by considering the way 
in which the memory is used : 
location 
zero 
locations for fixed cells 
locations for IBNUC 
locations for IOEX 
locations for IBJOB 
locations for variable parts of the system 
location 
32767 
The variable part of the memory contains either 
IOCS 
or 
IOCS 
or 
IOCS 
or 
the program to 
Fortran 
MAP 
LDR 
be executed 
The fixed cells contain fixed instructions that control the jumps into the 
interrupt routine. IBNUC contains a list of all the I/O equipment attached 
to the machine and a list of the way in which the equipment is being used. 
IOEX is the program that controls all the I/O operations and the inter-
rupts. IBJOB is the name of one of the components of the IBJOB system. It 
is a simple program which reads control cards. IOCS (input-output control 
system) controls the allocation and usage of buffers. It uses IOEX to do 
the actual I/O operations. 
At the start of the job the IBJOB routine receives control. It reads 
a card from the input unit. If this card contains the word IBMAP then 
IBJOB reads in the first part of the MAP assembler and hands control to 
it. The assembler processes all the assembly language cards and then it 
returns control to IBJOB. In a similar manner an IBFTC control card 
invokes the compiler. An IBLDR card causes the loader to be brought in. 
The assembler, the compiler, and the loader all use IOEX and IOCS and 
they all return control to IBJOB. The control card containing ENTRY 

1 · 11 IBSYS 
25 
causes the program to be loaded and executed. The Fortran READ and 
WRITE statements cause a jump to a library routine, and these routines 
themselves use IOEX and IOCS. In the operation of MAP programs it is 
possible to dispense with the use of IOCS. 
The IOCS routines are extensive and complicated. Any area in 
memory not being used by the current program is used as buffer space. Any 
information to be written out is first transferred into a buffer. This buffered 
copy is written out whenever the channel is free. The writing and the 
computing can proceed independently. If the program is writing short 
records on a single tape then IOCS is no more efficient than the (STB) 
routine in FMS. If the program is outputting on several tapes, or if it 
generates a high volume of output at infrequent intervals, then the IOCS 
system is much more efficient than the (STB) system. IOCS treats a READ 
operation in the following way. The first time that any tape is used, IOCS 
reads one record. It pauses while the read operation is completed. It now 
assumes that further READ operations will be requested on that tape. 
Before returning control to the main program, it requests IOEX to read 
several more records. It does not wait for these read operations to be 
completed, but returns to the main program. At some later time, when a 
further READ request is made on the same unit, IOCS is able to fill the 
request without an actual read tape operation. It transfers the information 
that is in its buffers and then issues another request to IOEX in anticipation 
of further READ requests. If a BACKSPACE operation is requested, 
IOCS has to remember that the tape is not where the programmer thinks 
it is. It has to synchronize the actual position and the apparent position of 
the tape before obeying the BACKSPACE. 
There are two major objections to IOCS. First, it is very compli-
cated. If the programmer restricts himself to the class of problem for which 
IOCS was designed, then all is well. If his problem does not fit in this class, 
then he finds it very difficult to know what to do. The second objection to 
IOCS is its limited application. In some problems there is no memory space 
available for a large number of buffers. The programmer should be allowed 
to use his special knowledge of the problem in order to optimize the I/O. 
In the FMS system the I/O routines are entered whenever a 
Fortran READ or WRITE statement occurs. In the IBSYS system IOEX 
is entered whenever a READ, a WRITE or an interrupt occurs. We 
explained in Section 1.6 that an interrupt occurs whenever a channel opera-
tion ceases. The executable program loses control. IOEX takes control. It 
checks that the I/O operation was successful. It looks to see if there are 
any I/O requests which have not yet been initiated. If there are such 
requests, then it issues the command to the channel and then returns 
control to the executable program. 
On the IBM 704, tape units were numbered serially. 
WRITE TAPE 3,A,B,C 

26 
1 COMPUTER 
SYSTEMS 
meant that certain information was to be written on tape unit number 3. On 
the IBM 7090 the channels are described by letters and the units on each 
channel are numbered serially. The FMS system contains a table that 
might look like this: 
Fortran number 
1 
2 
3 
4 
5 
6 
7 
8 
Physical number 
A1 
B1 
A2 
A3 
A4 
B2 
B3 
B4 
The table can easily be changed to suit the convenience of the computer 
center. 
WRITE TAPE 3,A,B,C 
now causes output to go on unit A2. IBJOB has two sets of tables that 
define the correspondence between the Fortran unit number and the 
physical unit. In the first table, the standard units receive a standard name. 
The name, SYSINl denotes the standard system input tape. SYSPPl 
denotes the standard punch tape; SYSUT1 denotes a utility tape: this tape 
can be used for any purpose. The first IBJOB table might contain the 
following information: Fortran unit 1 equals SYSUT1 ; it is to be used for 
binary information and the maximum size of any records is 256 words. The 
latter information enables IOCS to allocate an adequate buffer area. 
Fortran units 2, 3, 4, are SYSUT2, SYSUT3, and SYSUT4. Unit 5 is 
SYSINP1. Unit 6 is SYSOU1, and so on. The second table is contained 
in IBNUC. It might say that SYSN1 is tape Al, that SYSOU1 is tape 
A2, and so on. There is a reason for having these two sets of tables. It 
makes it easy to make major changes in I/O equipment without having to 
change programs. In Fortran IV the statement 
WRITE TAPE 3, A,B,C 
is more usually written 
WRITE (3) A,B,C 
This method of writing the statement emphasizes that it is unit 3, not tape 
unit 3. The correspondence between units and I/O equipment is under 
control of the operator, in conjunction with the systems programmers. The 
ordinary programmer is simply told SYSINl is the input unit. The 
systems programmer may decide that SYSINl is a tape unit, or they may 
use a card reader, or they may use part of a magnetic disk. The essential 
thing is that the system programmers can reassign the usage of I/O equip-
ment and can introduce new equipment without having to consult all the 
machine users. There are some occasions on which the programmer can 
control the type of equipment used. Suppose he has information which 
needs to be saved on a certain magnetic tape. The tape has a reel number 
that is an identification number by which the operators can recognize it. 

1 · 12 JOB SCHEDULING AND TIME SHARING 
27 
The programmer has to insert a card connecting the Fortran unit number 
and the reel number. The system decides which tape unit to use and tells 
the operator the reel number and the number of the unit on which it is 
to be loaded. 
To summarize the main features of a modern system. There 
should be a single interrupt and I/O routine. This routine should be used 
by the compiler, the assembler, the loader, and by the customer's programs. 
The system should be in control at all times. On the 7090 this is not always 
possible; the programmer can destroy the system. On the CDC 3600 and 
other modern computers the system is involate; any attempt to overwrite 
the system causes an interrupt. The program refers to I/O units by giving 
them a name. The correspondence between a unit number and a piece of 
physical equipment is established through a set of tables. In some systems, 
the programmers can change the tables, but normally he does not do so. In 
other systems the programmer has no control over these tables. There are 
three types of I/O information, namely, system, utility, and special. System 
information includes information on the standard input, output, punch and 
library tapes. A utility or scratch unit contains information that is generated 
during the job and is not saved on completion of the job. A special unit 
contains information that exists either before or after, or both before and 
after the job is run. The ordinary programmer never needs to know which 
physical units are used for system and utility units. In IBSYS he can specify 
that special information should be on magnetic tape. In some systems he 
cannot do this. The system arranges that the information ultimately appears 
at the appropriate place, but it may find it more efficient not to do a simple 
tape-to-memory or memory-to-tape operation. 
1 -12 JOB SCHEDULING and TIME SHARING 
In order to appreciate the way in which the computer system is used, it is 
important to know the relative size and speed of the various components 
of the system. The exact figures vary from machine to machine, but the 
following figures are correct to within a factor of 2 or 3. The addition of 
two numbers takes one microsecond. (A microsecond is one millionth of a 
second; a millisecond is one thousandth of a second.) A core memory 
holds about 40,000 words. It takes one microsecond to transfer one word 
from the arithmetic unit to any place in the core memory. A magnetic tape 
holds 2,000,000 words. The information on the tape is grouped into records. 
The time to read or write the next record on the tape is 5000 + 50/7 micro-
seconds, where n is the number of words in the record. The tape is scanned 
linearly. If a piece of information is at the far end of the tape then it may 
take as much as a minute to reach it. The design of disk memories varies 
quite widely. One commonly used memory consists of several rotating disks. 
Each disk contains a large number of circular tracks. A full circle of the 

28 
1 COMPUTER 
SYSTEMS 
disk constitutes one record of about 400 words. The complete disk system 
can hold about 8,000,000 words. There are several read/write heads asso-
ciated with each disk, but there are fewer heads than tracks. This means 
that the head sometimes has to move from track to track. The time to read 
one record is d + \r + nw, where n is the number of words in the record; r 
is the time for one revolution of the disk (about 30 milliseconds) ; d is the 
time for the head to move to the track (anywhere from zero to 200 milli-
seconds); w is the time to read one word (typically 20 microseconds). 
To summarize the overall situation. Core memory is fast but it 
does not have large capacity. Tape and disk are several orders of magnitude 
slower and larger than the core memory. Tapes can easily be removed from 
the machine so they are useful for storing permanent information. Tapes 
deteriorate if they are heavily used. For most applications disks are superior 
to tapes because all parts of the disk are equally accessible. It is feasible to 
store many blocks of dissimilar information on a disk; such information 
can be stored on a tape but it is not readily accessible. The relative speeds 
of the various devices is responsible for the elaborate buffering schemes 
discussed previously. Moving words from one part of the core memory 
to another is time consuming, but the time wasted is negligible compared 
to the time required for input or output. 
In the 1950's many of the cheaper computers used a magnetic drum 
memory in place of a core memory. As the cost of fabricating cores 
decreased, the use of drum memories was abandoned. At a later stage the 
very large disk memories were introduced. They came into use on the 7090 
at about the same time as the IBSYS system. The disk can be used to hold 
the monitor system, and commonly used programs; it can be used in place 
of utility tapes; and it can be used to store input and output. The method of 
off-line operation discussed previously was developed on a tape oriented 
system. The dispatcher collects several jobs, writes them onto magnetic 
tape, and submits them to the machine. The system writes the output from 
several jobs onto one tape, and the tape is later printed on a small computer. 
With a disk system an alternative approach is possible. The disk can be 
read or written on by both a large computer such as the IBM 7090 and a 
small computer such as an IBM 1401. The dispatcher reads the jobs into 
the 1401. He does not need to stack them, he simply puts them in as he 
receives them. The 1401 puts the jobs onto the disk. The 7090 takes the 
input for each job off the disk. It puts the output onto some other place on 
the disk. At some later time the 1401 takes the output and prints it. One of 
the important advantages of the system is that the 7090 does not have to 
take the jobs in chronological order. All parts of the disk are accessible. The 
7090 takes a job with a large amount of output and follows it with several 
jobs having a small amount of output. This smooths out the load on the 
printer. The system takes a job that uses several tapes and precedes it by a 
job that uses no tapes. This assists the operators. The system takes a job 
that has high priority and runs it before jobs that have low priority. An 

1 · 12 JOB SCHEDULING 
AND TIME SHARING 
29 
interesting description of a system of this sort can be found in the article by 
Kory and Berning (1964). 
The interrupt system can gain control in one of two ways. It can 
be called by the main program or it can be entered as the result of an 
interrupt. When an interrupt occurs, the interrupt routine performs certain 
operations and then returns control to the main program. Before returning 
control it carefully restores any locations and registers which it has used. 
By a slight extension of this process it is possible to evolve a new method 
of operation. Suppose the interrupt routine does not return control 
directly back to the main program. It could, for example, write the main 
program onto the disk and then it could process some other job. At some 
later time the interrupt routine could bring the old job back from the disk 
and by carefully restoring all the relevant information, it could restart at the 
point where the interrupt had occurred. In the old method of operation, job 
one started at time 0 and it ran for perhaps 60 seconds. Job two started at 
time 60 and it ran for perhaps 25 seconds. In the new method of operation 
job one runs from time 0 to time 5, job two runs from time 5 to 30, and 
then job one is finished in time 30 to time 85. The two jobs take the same 
length of time, but in the new system the time is shared between the two 
jobs. The term "time sharing" is used in several different ways but it 
always implies that part of one job is run, then part of another job, then 
part of another job, and so on. Notice that there is only one computer 
involved and that computer is running only one program at any one time. 
The Automatic Data Processing Glossary (1962) states that time 
sharing is " The use of a device for two or more purposes during the same 
overall time interval, accomplished by interspersing component actions in 
time." In this sense we could say that a channel is time-shared since it is 
used to transmit information to a variety of devices. At the present time, the 
term time-sharing usually refers to the sharing of all of the resources of the 
computer system by a number of simultaneous input and output stations. 
Typically there might be fifty programmers, each with a typewriter 
connected to the computer. The computer gives a small slice of time to each 
user, every few seconds. The Glossary states that multiprogramming is " a 
technique for handling numerous routines or programs simultaneously by 
means of an interweaving process." This refers to a situation in which 
there are several programs in the core memory at one time. The CPU obeys 
the instructions of the first program. After a certain time, or possibly when 
an I/O operation is requested, the CPU stops obeying the first program 
and starts obeying the second program. A time shared system is usually 
multiprogrammed but the concepts are not synonymous. According to the 
Glossary definition, a multiprocessor is "a machine with multiple arith-
metic and logic units for simultaneous use." The CDC 6600 which is 
described in the next section is one example of a multiprocessor. Some 
IBM 360 systems have two or more central processing units which are 
connected to each other and to a common set of I/O devices. 

30 
1 COMPUTER 
SYSTEMS 
There are two major advantages to be gained from multiprogram-
ming and time sharing: (1) it can be used to optimize I/O, and (2) it can 
lead to efficient man-machine interaction. Let us first consider point 1. I/O 
operations are much slower than computing operations. One way of using 
the machine more efficiently is to buffer the I/O ; however, there are many 
instances in which buffering cannot prevent the program from being I/O 
bound. A program is I/O bound when the CPU is forced to stop computing 
while it waits for some I/O operation to be completed. The only effective 
way to alleviate this situation is to mix one job having a large amount of 
I/O and another job having a small amount of I/O. The system begins the 
first job and continues with it until there is a delay due to I/O. The system 
then starts on the second job until the first job is ready to continue, then 
goes back to the first job, and so on. There are several difficulties with this 
type of time sharing. It is difficult for the system to estimate which jobs will 
be I/O bound and which will not. Each of the jobs requires core memory 
and the system must try to give each program the largest possible amount of 
memory. The changeover from one program to another can be time 
consuming. The machine must have adequate hardware so that it can jump 
from one program to another in 20 or 30 microseconds. Any system that 
tries to achieve efficient time sharing is bound to be very complicated. 
Proponents of time sharing believe that so much time is wasted in the 
normal type of operation that time sharing cannot help but be an improve-
ment. 
The second advantage to be gained from time sharing is man-
machine interaction. One of the purposes of the standard type of operating 
system is to minimize operator or programmer intervention. Humans are a 
million times slower than the machine and human intervention is costly. In 
the time-shared mode of operation, human intervention can be encouraged. 
Twenty or thirty typewriters are connected to the machine. The machine 
shares its time among 20 or 30 programs. Each program can communicate 
with a programmer who is sitting at one of the typewriters. The machine 
runs each program for a short length of time. If the program is dormant 
because it is waiting for a reply from a programmer, then the machine 
ignores it. The programmer can afford to take his time in using his type-
writer because he knows that the machine is busy with one of the 20 or 30 
other programs. Typical of the applications of such a system is instant 
compilation. The programmer sits down at a typewriter and types his 
program. As he reaches the end of each line, the machine informs him of 
any mistakes that he has made. When he reaches the end of the program, 
the machine finishes the compilation and starts to run the program. If the 
results appear to be wrong, then the programmer can ask for the program 
to be rerun, he can ask for extra printing, or he can ask for the program to 
be stopped at any place while he thinks out his next move. Some of the 
triumphs and tribulations of an experimental time-shared system are 
discussed by Schwartz (1965). 

1 . 13 THE CDC 6600 
31 
The effectiveness of any new system depends on the cost and the 
power of the available hardware, on the reliability and usability of the 
system, and on public opinion. Fortran would have been impossible on a 
machine less powerful than the IBM 704. Fortran I was not good enough 
to overcome the conservatism of the programmers of those days. Fortran II 
was a good system and it gained the support of many programmers. Fortran 
revolutionized machines because it made programming much easier and 
enabled the nonprofessional programmer to code his own problems. In a 
similar way, time sharing should have as great an impact on the use of com-
puters. There are arguments both for and against time sharing just as there 
were arguments for and against Fortran. Computers are tools, and at the 
present moment they are rather expensive tools. In the early days computers 
were so scarce and expensive that the programmer had to use his own time 
inefficiently in order to get the most out of the machine. As the cost of 
computers has been reduced, it has become economically feasible to use the 
machine with a moderate degree of inefficiency and to improve the efficiency 
of the programmer by several orders of magnitude. Time sharing does waste 
a small amount of machine time but it can open up completely new ways 
of using the computer. 
1 -13 THE CDC 6600 
All large computing machines represent a compromise. The designer tries 
to minimize the cost and maximize the power, reliability, and usefulness of 
the machine. As a result of this balancing of various factors, a number of 
unusual designs appear. The CDC 6600 is a large computer that first 
appeared in 1964. It differs quite markedly from machines of the previous 
generation. The machine has the following main components. There is a 
central processing unit; there is a central core memory of 131,072 words; 
there are ten peripheral processors, each with a memory of 4096 words. The 
words processed by these peripheral processors are quite short—they 
correspond to about four decimal digits. The words in the central memory 
are five times as long as this. The machine has 12 I/O channels. It has a 
magnetic disk that holds 8,000,000 words, and it has a card reader, card 
punch, printer, and several tape units. The CPU and each of the PP's 
(peripheral processors) has access to the central memory. The CPU is a 
very fast computing machine with no I/O capability. Each PP is a simple 
computer that can operate independently of both the CPU and the other 
PP's. If the CPU requires a write operation, it places the output in the 
central memory and sends a signal to one of the PP's. The PP accepts the 
signal and the CPU can then proceed with some other calculation. The 
PP transfers the output into its own memory and then transfers it to the 
requested output device. The operation of the PP corresponds to the 
combined operation of the routine IOEX and the data channels on the 
IBM 7090. 

32 
1 COMPUTER 
SYSTEMS 
One of the PP's has the job of supervising the operation of the 
whole system. It allocates tasks to the CPU and to the other PP's. The 
CDC 6600 normally operates in the time-sharing mode. The monitor PP 
tries to keep the CPU in continuous operation. It keeps several jobs in 
central memory and if any program requests I/O, it switches control of 
the CPU to another program while one of the PP's processes the request. 
Some of the simple jobs, such as tape copying and disk to printer, can be 
handled by a PP; they need never enter central memory. In some respects 
the CDC 6600 is like an IBM 7090 linked to ten 1401's. The 6600 CPU is 
of course much faster than the 7090, and, due to an ingenious design, the ten 
PP's are much less expensive than ten separate small computers. One of the 
virtues of the 6600 is that the CPU does not have to spend time in supervis-
ing the system. All the system functions are carried out in one of the PP's. 
The CPU of the 6600 differs quite radically from most other 
machines. The IBM 7090 has a single unit for adding, for multiplying and 
for doing all the other basic operations. The 6600 has ten units to do a 
variety of basic operations. The programmer writes his program in the 
normal way. He has to break the program down into the usual series of 
additions, subtractions, multiplications, and so on. The machine obeys 
the instructions in the sequence in which they are written; however, when-
ever possible the CPU starts one operation before the previous operation 
is finished. Most of the individual operations of the CPU take 0.3 or 0.4 
microsecond, but in many programs the machine obeys one instruction 
every 0.1 microsecond. This means that at any one time the CPU is process-
ing three instructions. 
The design and the checking of an operating system for the 
CDC 6600 is an extremely formidable task. Fortunately for the average 
programmer, the design of these systems is not his concern. Once the soft-
ware is available, the writing of programs for the 6600 is no more difficult 
than writing programs for any other machine. The programmer can affect 
the efficiency of the program by rearranging the sequence of the instruc-
tions. This can add to the labor of programming but it does not add to the 
complexity. The true complexity of the machine lies in the efficient use of 
the CPU and of the PP's, but all such questions are the responsibility of 
the system. The 6600 has a Fortran compiler. This compiler is as easy to 
use as any other Fortran compiler. Many Fortran programs that are 
operational on the CDC 3600 or the IBM 7090 could be run on the 
CDC 6600. 
1 -14 THE IBM 360 
Before discussing the IBM 360, let us consider the operation of fhe IBM 
7090. The basic unit of information in the 7090 is a bit. Bit means binary 
digit. Just as a decimal digit is 0,1,...,8, or 9, so a binary digit is 0 or 1. The 

1 · 14 THE IBM 360 
33 
memory in the 7090 consists of 36x32,768 = 1,179,648 magnetic cores. 
Each core can hold one bit of information. The basic operations of the 
7090 consist of the logical sum or logical product of two bits. The rules for 
logical summation are: 0 + 0=0, 0+1 = 1,1 + 0 = 1 and 1 + 1 = 1. The rules 
for forming a logical product are: 0 x 0=0,0 x 1 =0, 1 x 0=0 and 1x1 = 1. 
These operations are basic because they can be carried out by very simple 
electronic circuits. A complete word is formed by taking a group of 36 
bits. A machine instruction is performed by breaking the instruction down 
into a large number of basic logical operations. Let us emphasize that all 
programs are written in terms of machine instructions. The breakdown into 
basic operations is done automatically by the hardware. When we say that 
the IBM 7090 can add two numbers together in 4.8 microseconds, we mean 
that it will fetch one 36-bit word from memory and add it to another 
36-bit word in the arithmetic unit, all in 4.8 microseconds. Within this 
time many basic logical operations have been performed. Although we 
have made these statements about the 7090, with slight changes they are 
true for all electronic computers. All machine-language instructions are 
constructed from a series of basic logical operations. See, for example, 
Braun (1963). 
There is a good reason for mentioning these basic operations. 
Fortran statements can be obeyed by a wide variety of machines, even 
though each machine has its own particular machine language. By analogy, 
it is possible to have a machine language that is obeyed by a wide variety of 
machines, even though each machine has its own particular basic opera-
tions. This happens to be the case with the 360. The IBM 360 is made in 
ten or more different models by IBM, and in several other different models 
by other manufacturers. All models use the same machine language, but 
their basic operations are quite different. The prices of the various 360 
systems vary by a factor of several hundred and the computing power 
varies by a factor of several thousand. Some models have a slow, small, 
inexpensive core memory. Some models have a large fast core memory, 
supplemented by very fast transistor registers. Some models have a small 
amount of hardware and each machine operation is accomplished in a large 
number of steps. Some models have very extensive hardware which can 
perform many basic operations in parallel. There are many advantages to 
having a wide range of compatible models. The number of different 
operating systems, compilers, assemblers and other programs is reduced to 
a minimum. The customer has a wide range of equipment to choose from. 
He can start with a small model of the 360 and progress to a larger model 
when necessary. A company with computers at several locations can have 
a large model at the main plant and smaller models at the outlying 
locations. If there is a sudden demand for machine time, jobs can easily be 
switched from one location to another. The 360 is not the first of the 
compatible models, but it does carry compatibility over a very wide range 
of models. In actual practice not all of the models are completely com-

34 
1 COMPUTER 
SYSTEMS 
patible ; however, the problems of transferring an assembly language pro-
gram from one model to another model should be negligible compared to 
the effort that would be required in changing programs from an IBM 1620 
to an IBM 7090, or from a CDC 3600 to a CDC 6600. 
* The main details of the IBM 360 are not too dissimilar from those 
of the IBM 7090 or the CDC 3600. It has a CPU. It has a core memory and 
it has several I/O channels. The machine-language instructions are quite 
different from those of previous machines but they do perform the same 
sort of operations. There is one instruction to add two numbers together, 
there is another operation to multipy two numbers, and so on. As is to be 
expected, the general organization of the machine is superior to that of 
earlier machines. It has a very comprehensive interrupt system and there 
are many hardware aids to effective monitor supervision. The I/O channels 
are designed so that a wide variety of devices can easily be attached to the 
machine and all devices are programmed in the same way. Two major 
innovations on the 360 are the use of both decimal and binary arithmetic 
and a memory organized in bytes. To explain the significance of these 
features, we must say something about the different types of calculation 
for which the machine is used. Many scientific calculations consist of 
millions of arithmetic operations on numbers. Such calculations require an 
efficient arithmetic unit. It happens that a computer can do binary arith-
metic more efficiently than decimal arithmetic. The input and the output of 
the computer are usually in decimal, because decimal is more convenient 
for human understanding. The machine has to convert from decimal to 
binary on input and from binary to decimal on output. In most problems, 
the time wasted in the conversion is regained by the extra efficiency of the 
binary arithmetic. In some data processing problems and in many com-
mercial applications of computers, there is a high volume of input and 
output and little computation. For these problems, the conversion between 
decimal and binary does represent a source of inefficiency. The 360 allows 
both binary and decimal arithmetic. Either mode can be used, depending 
on the type of problem. 
The term byte means a useful grouping of binary digits. In the 
IBM 360 the term byte refers specifically to a group of eight bits. The 
memory of the 7090 is organized into words. Each word can represent an 
instruction, an integer, a real number or six alphanumeric characters. In the 
IBM 360 the memory is organized into bytes. Each byte can represent one 
alphanumeric character or two decimal digits. A word is made up of four 
bytes and it can represent an integer, a real number, four characters or 
eight decimal digits. Instructions consist of two, four or six bytes. Many of 
the more frequently used instructions occupy only two bytes and this 
results in compact programs. The advantage of the byte type memory 
comes in problems which involve characters and character manipulation. 
Examples of such problems are data processing, many of the commercial 
programs, compiling, language translation, list processing, and so on. These 

1 · 15 PL/1 
35 
problems can be solved on machines like the 7090, but they usually require 
an inefficient use of memory and an inefficient use of the arithmetic unit. 
Characters can be stored efficiently in the 360 memory and, in addition, the 
machine has a large number of instructions for manipulating bytes. With 
one or two exceptions, most other computers have either a word type 
memory with binary arithmetic or a byte type memory with decimal 
arithmetic. The former class includes the IBM 7090, the CDC 3600 and 
6600, and many other scientific computers. The latter class includes the 
IBM 1401 and IBM 7070 which are designed for commercial and data 
processing applications. The 360 is efficient in both numerical and data 
processing applications. 
1-15 
PL/1 
The 360 system has a Fortran compiler which can be used to run programs 
that were developed on other machines. Fortran is a good compiler 
language but it lacks many features that are desirable when writing 
programs for a large computer. The advent of the 360 offered an oppor-
tunity for the development of a new language. The design of the new 
language began in October 1963. The original name of the language was 
NPL (new programming language), but this was later changed to PL/1 
(programming language/one). The first report on PL/1 was issued in 1964. 
The language described in that report was not an attractive one; however, 
subsequent modifications have produced a powerful, comprehensive and 
usable language. The development of PL/1 has taken three years and has 
required thousands of man hours of effort. No doubt much more labor will 
be required before the full capabilities of the language are explored. 
On the elementary level, PL/1 is very similar to Fortran or Algol. 
Many existing Fortran programs could be converted to PL/1 by slight 
changes to some of the statements. In all three languages an identifier con-
sists of a letter followed by letters or digits. In Fortran there is a limit of 
six characters. In PL/1 there is a limit of 31 characters. In Algol there is no 
limit. This state of affairs re-occurs in many of the other elements of the 
languages. Fortran tends to be too restrictive. PL/1 has a restriction that 
aids efficient compilation but that does not place a burden on the pro-
grammer. Algol has no restriction but it makes efficient compilation 
difficult. 
In Fortran statements all spaces are ignored (except within 
Hollerith strings). The statement 
D01001 = 1,LA 
ST 
has the same meaning as 
DO 
100 
1 = 1,LAST 
The omission of the space between the DO and the 100 and between 100 

36 
1 COMPUTER 
SYSTEMS 
and the I and the inclusion of spaces between the LA and the ST is of no 
advantage to the programmer, although it is legitimate. The compiler must 
waste time allowing for the possibility of these statements. PL/1 has 
reasonable restrictions. All elements must be separated by an operator or 
a space. There must be no spaces within identifiers. Fortran uses the end of 
card to indicate the end of a statement. PL/1 follows Algol in using a 
semicolon. 
Arithmetic statements are written in similar ways in all three 
languages. 
ALPHA=BETA-GAMMA*(DELTA**2 + GAMMA) 
is legitimate Fortran, Algol, or PL/1. Algol has variables of type real, 
integer, or Boolean. Fortran has integer, real, logical, double, and complex. 
PL/1 has fixed or floating, real or complex, binary or decimal, and it allows 
the character and bit-string types. Fixed real corresponds to the Fortran 
integer, float real corresponds to the Fortran real and float complex 
corresponds to complex. There is no Fortran equivalent of fixed complex. 
Fortran has single or double precision arithmetic. PL/1 allows many 
different precisions to be specified, the actual number of digits can be 
declared. The choice between binary and decimal is to a certain extent 
a reflection of the characteristics of the 360 with its binary and decimal 
arithmetic. There are however problems where it would be useful to specify 
decimal arithmetic even on a binary machine; one might, for example, wish 
to simulate a decimal computer. PL/1 allows a great many different modes 
to be specified but luckily it does not insist on a specification. If no declara-
tion is given, then the compiler will choose some appropriate representa-
tion. As in Fortran, variables whose names begin with I through N are 
considered to be integers; this rule can be overridden by a declaration. 
An integer would be represented by a 32-bit binary number, unless the 
programmer specifies otherwise. Some representations are more efficient 
than others. For example, on a large model of the 360 the float decimal 
specification would be inefficient since floating decimal arithmetic would 
have to be done in a subroutine, whereas floating binary can be translated 
directly into simple machine instructions. 
PL/1 has removed the restrictions that Fortran placed on mixed 
expressions, DIMENSIONS, subscripts, and DO statements. Variables of 
different types may be mixed in one expression. The declaration of the 
dimensions of an array may specify both upper and lower bounds. The 
bounds may be any functions of any previously declared variables. The 
arguments of a DO may be any arithmetic expressions. PL/1 is, in most 
respects, as general as Algol, but it introduces some new features. For 
example, if A is an TV by N array and V is a vector of length N, then it is 
possible to make a declaration that ensures that K(I) and A(\,\) occupy the 
same storage locations for all N values of I. 

1 · 16 
CONCLUSIONS 
37 
Fortran uses subroutines. Algol uses blocks and procedures. The 
subroutine has the advantage that it improves the power and efficiency of 
compilation. Blocks and procedures provide a more efficient and more 
convenient way of communicating information between the parts of the 
program. PL/1 has external procedures that have the virtues of the Fortran 
subroutines and internal procedures that have the virtues of the Algol 
blocks and procedures. Fortran allocates memory in a way that makes 
efficient use of the arithmetic unit and inefficient use of the memory. 
Fortran allocates memory space during the compiling and loading phases. 
Algol allocates memory dynamically. If A is a 50 by 50 array then Fortran 
reserves 2500 locations at load time. Algol does not reserve the memory 
space until the variable A is actually used during execution, and it frees the 
memory space when A ceases to be used. The Algol scheme is very efficient 
in the use of memory but tends to use extra arithmetic operations. PL/1 
allows the static or Fortran type of storage. It also allows the dynamic or 
Algol type of storage, and it allows a third type of memory allocation which 
it calls controlled. 
In large computers the I/O and arithmetic operations can be carried 
on in parallel. Systems such as IBSYS, with more or less efficiency, arrange 
this overlap. In some systems there are other types of operation which can 
be overlapped. The system might consist of several CPU's connected 
together. In such a system it would be possible to overlap some computing 
operations. A large problem might be made up of several disjoint pieces 
and a standard computer with a single CPU might find it advantageous to 
time share the different parts of the program. PL/1 performs the usual 
overlapping of I/O operations. It also allows the programmer to indicate 
which portions of the program may be carried on in parallel. Whether or 
not these parts are carried in parallel depends on the system and the 
configuration of the hardware. 
We have said sufficient of PL/1 to demonstrate its place in com-
puting. For the average small or moderately large program it is easier to 
use than Fortran since it places far fewer restrictions on the programmer. 
Many problems that are difficult to solve in Fortran and that currently 
require special assembly-language routines, are solvable directly in PL/1. 
In particular, PL/1 has comprehensive facilities for manipulating character 
strings. Strings can be added to each other, individual characters can be 
picked out and replaced. Strings of characters can be compared. Numbers 
can be converted into character strings and vice versa. PL/1 introduces 
many new concepts necessary for intelligent communication between the 
programmer and the complex systems of current computers. 
1 -16 
CONCLUSIONS 
This review of computing systems has taken us from the simple electronic 
calculating machines of the early 1950's to the complex hardware and 

38 
1 COMPUTER 
SYSTEMS 
software of the present-day computers. In this short outline it has been 
necessary to concentrate on the main lines of development and to omit 
many important systems. Although there have been thousands of different 
machines, most of them have had little or no influence on the development 
of current computers. For example, the IBM 650 was used widely at one 
time, but it is difficult to think of any feature of the 650 which has influenced 
current thinking. The largest machines of one generation set the standards 
for both the small and large machines of the next. By tracing the develop-
ment of a few of the main ideas, we have illustrated the concepts lying 
behind current systems. 
Every system is made up of many autonomous units of both 
hardware and software. In any well designed system, each unit has an 
appearance of simplicity, even though the internal operations of the unit 
might be quite complex. For example, a program might ask the I/O monitor 
to output some data. The processing of the request inside the I/O routines 
is complicated, but the result returned to the program is very simple: the 
write is either successful or unsuccessful, or the operation is still in pro-
gress. Any system can be considered from two points of view. This chapter 
has considered the major components of the system and the interrelation 
between them. Future chapters will take some of the individual components 
and consider them in detail. 
PROBLEMS 
These are general questions in conformity with the discursive nature of the 
chapter. Answer each question with a few short sentences. 
1 ■ What is an I/O channel ? Why do all large machines use channels ? 
Assuming that the software makes the best possible use of the 
channels, draw a diagram, similar to Figure 1.5, illustrating the over-
lap of computing and I/O in the following Fortran program. 
C 
PROGRAM TO COPY 100 RECORDS 
DIMENSION L(50) 
DO 1 1 = 1,100 
READ (8) L 
1 
WRITE (10) L 
2 ■ What is the difference between a compiler and an assembler? What is 
the difference between a machine language instruction, a symbolic 
instruction and a compiler statement? Could an assembler have been 
written on the Eniac computer? The Edsac had a simple assembler. 
What feature of Edsac made the assembler possible? 
3 ■ What is an interrupt? When does an interrupt occur? In the early 
models of the IBM 709, at the end of an I/O operation the channel 

P R O B L E M S 
39 
disconnected, but no interrupt occurred. The program could ask the 
question, "Is the channel in operation, or has it disconnected?" Why 
is this method of controlling I/O inferior to the interrupt method? 
4 ■ What are the main components of a simple monitor system? At the 
beginning of a job what component of the system is in control. In 
FMS, what causes the assembler to be brought in and what causes the 
compiler to be brought in? What brings in the assembler or the 
compiler in the system which you are currently using? 
5 ■ What features of Algol or PL/I are superior to the corresponding 
features of Fortran ? 
6 ■ On the IBM 704 the Fortran statement 
WRITE TAPE 3, L 
causes output onto the tape that is on unit number 3. In IBSYS, what 
determines the action of 
WRITE (3), L 
That is to say, which piece of equipment is L written on? In the system 
you are currently using, what determines the correspondence between 
the unit numbers you use and the equipment that the computer uses ? 
Note that in some systems "file name" is used in place of "unit 
number." 
7 ■ Suppose a time-sharing system is running your job. Does it have to 
wait until your job has finished before starting some other job? Does 
it have to wait until the end of a statement ? How and when can it stop 
your job in order to do another job? 
8 ■ Fortran is available on a wide variety of computers. Is a particular 
machine language, for example IBM 7090 machine language or 
IBM 360 machine language, available on other computers? Explain 
the reason for your answer. 
9 ■ Why do some computers use decimal arithmetic and some use binary ? 
Do any computers use both? Is the memory that holds decimal 
numbers radically different from a memory that holds binary digits ? 
Explain your answer. 
10 ■ A Fortran program usually consists of several subroutines. What are 
the advantages of subroutines ? What features of PL/I correspond to 
the Fortran subroutine? 
11 ■ The tables in Computers and Automation (published monthly by 
Berkeley Enterprises, Inc., Newtonville, Mass.) give the name, approxi-
mate rental, and number delivered, of most American computers. Find 
out which model of computer represents the highest capital investment. 
Assume the capital investment equals the number delivered times the 
monthly rental times 50. 

40 
1 COMPUTER 
SYSTEMS 
12 ■ What is a byte? What are the meanings of the phrases "byte-type 
memory" and "word-type memory"? What are the advantages of 
each type ? Which type of memory has the computer that you are 
using? 
13 ■ The monitor system is supposed to be in control of the machine. In 
order to supervise your program does the monitor have to run at the 
same time as your program, or does it lie dormant? Can your program 
outwit the monitor? Can it, for example, overwrite the part of the 
memory used by the monitor? If not, why not? 
14 ■ The introduction of channels on the IBM 7090 made it possible to 
overlap computing and I/O. How were programs changed in order 
to take advantage of the simultaneous operation of CPU and the 
channels? Were all programs changed? Were the systems programs 
changed; if so, how were they changed? 

2-1 
INTRODUCTION 
Machine language is the language in which 
the instructions to the machine must be 
phrased. The machine does not obey 
Fortran statements. There are a series of 
programs, namely the Fortran compiler, 
the assembler, and the loader, which accept 
the Fortran statements as data and produce 
machine language statements as output. 
This output is fed back into the machine 
and the machine obeys the 
machine 
language instructions. Although there are 
many different machine languages, many 
concepts are common to all of these 
languages. Some of the common ideas are 
binary arithmetic, index registers, memory 
addresses, floating-point arithmetic, control 
operations, and logical operations. In this 
chapter we will examine these ideas by 
discussing one particular machine. As we 
shall see in a later chapter, these ideas can 
easily be extended to a variety of other 
machines. The particular machine that is 
studied first is the IBM 7090. Had we 
chosen a machine like the IBM 360 as the 
first example, it would subsequently be 
found that much of the discussion would be 
irrelevant to other machines such as the 
CDC 6600. The IBM 7090 has been chosen 
because it has a simple structure and most 
of what is said is relevant to the description 
of any other large computer. 
2-2 
THE MEMORY 
2 
MACHINE 
LANGUAGE 
AND 
ASSEMBLY 
LANGUAGE 
In this chapter we shall consider only the 
central part of the computer, namely the 
CPU and the memory. The memory con-
tains numbers and instructions. Informa-
tion to be used by a computer can be 
stored on a number of different devices. 
Magnetic tape, magnetic disks, or magnetic 
cores are a few examples of the more 
41 

42 
2 MACHINE LANGUAGE AND ASSEMBLY 
LANGUAGE 
common memories used in computers. Any of these devices can be called 
a memory, but in practice one is referred to as primary memory and 
several are termed secondary memories. On the 7090 the primary memory 
consists of magnetic cores. Tapes, disks, or drums can be used as secondary 
memories. The primary memory is sometimes called the immediate-access 
memory, or the random access memory. The information on tapes, disks, 
or drums is not immediately accessible to the CPU. It has to be read into 
the core memory before the CPU can use it as data or as instructions. The 
information in the secondary memory is stored in some sequential order ; it 
is not possible to pick out words at random. The specific portion of the 
recording surface has to be brought into position before the word can be 
read. The physical movement takes several milliseconds. The information 
in the core memory is readily accessible. Any word in the memory can be 
read or written in 2.4 microseconds. In this chapter, whenever a specific 
size or speed is mentioned it is to be assumed that the figures refer to the 
IBM 7090. All the operations involved in reading or writing words in the 
core memory are electronic; no mechanical movement is required. When 
the word "memory" is used without any qualifying adjective, it will 
always refer to the primary memory. 
A magnetic core is a small torus of ferrite material. It can be 
magnetized in two alternative directions. Let the digit " 0 " denote that the 
core is magnetized in one direction and let " 1 " denote that it is magnetized 
in the opposite direction. There are electronic circuits that can store a " 0 " 
or a " 1 " in a core, while other circuits can detect whether a " 0 " or a 
" 1 " has been stored. The complete memory consists of 1,179,648 cores. 
The cores are arranged in groups of 36, each group of 36 constituting a 
location. The contents of a location is called a word. A word may represent 
a number, an instruction, or several alphanumeric characters. The string of 
36 zeros and ones, 
110101111011100100101101000000010101 
might represent the contents of one location. 
2-3 
BINARY NOTATION 
The usual method of representing numbers is based on the decimal nota-
tion. The digits are 0 through 9. The numbers are 0,1,2,3,4,5,6,7,8,9,10,11, 
12,13,14 and so on. The string of digits dn ... CI^Q represents the number 
dn x 10- + — + Λ x 10l +έ/0 
for example 
73246 = 7 x 104 + 3 x 103 + 2 x 102 + 4 x 101 + 6 

2 · 3 BINARY NOTATION 
43 
In the binary notation the digits are 0 and 1. The numbers are 
0,1,10,11,100,101,110,111,1000, and so on. The string of digits dn...dxd^ 
represents the number 
dn x2" + - + A X21 + d0 
For example 
101101 = 1 x 25 + 0 x 24 + 1 x 23 + 1 x 22 + 0 x 21 + 1 
= 32 
+ 8 
+ 4 
+ 1 - 4 5 
Another notation commonly used in discussing computers is the octal 
notation. The digits are 0 through 7. The numbers are written 
0,1,2,3,4,5,6,7,10,11,12,13,14 and so on. The string of digits dn...dxd0 
represents the number 
<4x 8"+ ···+</! 
xV+do 
For example 
73246 = 7 x 8 4 + 3 x 8 3 + 2 x 8 2 + 4 x 8 1 + 6 
= 30374 decimal 
When using numbers that belong to different representations, the base of 
the representations is usually denoted in a suffix; thus 
732468 = 30374lo 
The equivalence between some decimal, octal, and binary numbers is 
shown in Table 2.1. 
The conversion from decimal to octal can be done by repeated division by 
eight. Thus 99/8 = 12, remainder 3. 12/8 = 1, remainder 4. The successive 
remainders given the successive octal digits so 9910 = 1438. To give a more 
elaborate example : 
30374/8 = 3796 with remainder 6 
3796/8 = 474 with remainder 4 
474/8 = 
59 with remainder 2 
59/8 = 
7 with remainder 3 
7/8 = 
0 with remainder 7 
Hence 30374 decimal is 73246 octal. The conversion from octal to binary 
is very simple. Replace each octal digit by three binary digits. 0 is replaced 
by 000, 1 is replaced by 001, and so on, as given in Table 2.1. 
30374 1 0= 732468= 1110110101001102 

44 
2 MACHINE LANGUAGE AND ASSEMBLY 
LANGUAGE 
TABLE 2-1 
SOME BINARY NUMBERS with OCTAL and 
DECIMAL EQUIVALENTS 
Decimal 
0 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
Octal 
0 
1 
2 
3 
4 
5 
6 
7 
10 
11 
12 
13 
14 
15 
16 
17 
20 
21 
22 
23 
Binary 
0 
1 
10 
11 
100 
101 
110 
111 
1000 
1001 
1010 
1011 
1100 
1101 
1110 
1111 
10000 
10001 
10010 
10011 
The conversion from decimal to binary can be done by repeated division 
by 2, but it is easier to convert from decimal to octal and then from octal to 
binary. The conversion from octal to decimal is done by writing the 
number as a polynomial in powers of 8 ; thus 
1438 = 1 χ 8 2 + 4 χ 8 1 + 3 = 64 + 32 + 3 = 9910 
The conversion from binary to decimal is best done through using octal as 
an intermediate stage. 
To return to the discussion of the computer memory. The contents 
of one location can be represented as a string of zeros and ones. These 
zeros and ones might represent a number in the binary notation; thus the 
decimal number 99 can be represented in the memory as 
000000000000000000000000000001100011 
Each 36-bit location can represent one integer number. It is necessary to 
represent both positive and negative numbers. The convention in the 7090 
is to use the leftmost bit to indicate the sign, where 0 denotes plus and 1 
denotes minus. Thus, —99 would be 
100000000000000000000000000001100011 
The numbers in the memory are actually represented in binary; however, in 

2 · 3 BINARY 
NOTATION 
45 
describing these numbers it is more convenient to use octal notation. The 
transformation from octal to binary is so simple that the octal description 
does not obscure any essential facts. The representation of the decimal 
numbers 99 and — 99 in the memory can be written 
000000000143 
and 
400000000143 
in octal. The largest number that can be represented in one location is 
377777777777 octal 
or 
011111111111111111111111111111111111 
which is 
234 + 
233 
+ 
232 + ... + 2 l + 2 0 =235 _ χ 
For the moment the discussion is limited to the representation of positive 
and negative integers. The representation of real numbers will be discussed 
in Section 2.12. 
The basic rules for binary addition are 
0+0-0, 
1+0=1, 
1+1 = 10. 
As an example, the addition of 1012 and 1112 would be done as follows: 
first number 
101 
second number 111 
result 
1100 
Add the units digits, that is the digits at the right hand end. 1 and 1 makes 
10. The first digit of the result is 0 and 1 to carry. 1 plus 0 plus the 1 that 
was carried gives 10. The 0 goes into the result and there is 1 to carry. 1 plus 
1 plus 1 equals 10 plus 1 which is 11. The final result is 1100. Now 
1012 = 510, 1112 = 710, and 11002 = 1210; The result of the binary addition 
must be the same as the decimal addition since they are both representations 
of natural numbers. 
Octal addition is similar to decimal addition except that there is a 
carry into the next place if the sum in any column exceeds 8. Adding 578 to 
458 could be done by the steps 7 + 5 = 1210 = 148, record the first digit of 

46 
2 MACHINE LANGUAGE AND ASSEMBLY 
LANGUAGE 
4 and carry one. 5 + 4 + 1 = 1010 = 128 so the result is 1248. We can 
write 7 + 5 rather than 78 + 58 because numbers less than 8 are the same 
in the decimal and the octal system. Adding and subtracting octal numbers 
is no more difficult than decimal addition and subtraction and it is occasion-
ally useful in checking programs. Binary addition and subtraction is simple 
but inconvenient and it is more usual to work in octal. We could easily 
deduce the rules for octal multiplication and division but in practice it 
is faster when doing these operations by hand to convert to decimal first. 
Just because the machine finds it convenient to work in binary is no reason 
why the programmer should work in binary. There are some special cases 
in which binary multiplication is very easy. The relations 
1 x 10 =10 
10 x 10 = 100 
10 x 100 = 1000 
10" x 10m = 10n+m 
are true in decimal, octal, or binary. Binary multiplication by 2n is the same 
as multiplication by 100...0, where there are n zeros. Multiplication can 
be achieved simply by adding n zeros on the end of the multiplicand. Thus 
99 1 0= 1100011 2 and 396 1 0= 1100011 2X 22= 110001100. 
Similarly division by 2" is achieved by stripping off the n rightmost digits. 
The machine addition, subtraction, multiplication, and division 
operations are carried out by doing binary arithmetic on binary numbers. If 
round-off errors are ignored then the results of any arithmetic calculations 
are independent of the representation. It is sometimes useful for the 
programmer to be able to do octal addition and subtraction and it is useful 
to know the simple rule for multiplication of a binary number by 2", but 
it is never necessary for the programmer to do elaborate calculations in 
binary or octal. There are circumstances where the representation can 
affect the final result; for example, we shall see in a later section that the 
decimal fraction 0.1 is not represented exactly in the machine. The effects 
of such approximations can be studied by standard techniques of numerical 
analysis. 
2-4 
THE REPRESENTATION of INSTRUCTIONS 
The machine has 32,768 locations in the memory. These locations are 
numbered 0 through 32,767. The numbers that form the data to a problem 
are read into memory locations. (Reading from cards or magnetic tape will 
be considered in a later chapter.) The CPU refers to any particular piece 
of data by specifying the number of the location in which it is stored. In 
describing a particular calculation in English we might say " add the first 

2 - 4 THE REPRESENTATION OF INSTRUCTIONS 
47 
number to the second number"; in machine instructions this would be 
rephrased as "add the contents of location 0 to the contents of location 
1." The "contents of location «" specifies the 36-bit signed binary integer 
that is in the memory location number n. The word " address " is another 
way of saying location number. Let / denote an integer variable with the 
value 100 decimal, which is the same as the octal number 144. The integer / 
is stored in some location; let us suppose it is in location number 1910, 
which is the same as 23 8. Location 23 8 contains the 12-digit octal number 
000000000144. The contents of location 238 is 1448. The value of / is 
1448. The address of /is 238. 
In addition to the 32,768 words of memory, the computer has a 
small number of other locations. These extra locations not in the memory 
are usually referred to as registers. The 7090 has six registers that are 
accessible to the programmer. There is the accumulator, the MQ (multiplier-
quotient register), the control register, and three index registers. There are 
two reasons for having these special registers in addition to the ordinary 
memory locations. First, there are memory devices that are much faster, 
that is to say, they have a shorter read/write time, than core memories. These 
memory devices are suitable for a small number of registers but they are too 
expensive to use for the whole 32,768 words of memory. The second reason 
for the special registers is that they lead to a more efficient and compact 
machine language. Machine instructions refer to a single word in memory. 
A calculation such as 
I - J + K 
has to be broken down into three instructions. Suppose that J is in location 
2, K is in location 3, and I is in location 4. The three instructions would be 
Take the 36-bit number from location 2 and put it in the accumu-
lator 
Take the 36-bit number from location 3 and add it into the accu-
mulator 
Take the 36-bit number in the accumulator and put it in location 4 
The accumulator holds the intermediate and final result of a calculation. 
The accumulator and the MQ can each hold one 36-bit number. The 
control register and each of the index registers can each hold one 15-bit 
integer. The address of a location can lie between 0 and 3276710, that is 
between 0 and 777778. Any address can be represented by five octal 
digits, which is the same as 15 bits. The control register and the index 
registers are used to hold addresses. 
A machine instruction consists of three parts. The first part 
specifies the particular operation such as add or subtract. The second part 
specifies the index register. If no index register is to be used, then the 

48 
2 MACHINE LANGUAGE AND ASSEMBLY 
LANGUAGE 
second part is zero. The third part specifies the location number or address 
of the variable to be used in the operation. The third part of the instruction 
is usually called the address part. A machine can obey a limited number of 
instructions. Each instruction is given a number and this number specifies 
the particular instruction; for example, 40000 represents the addition 
instruction and 40200 represents subtraction. A complete instruction 
consists of 36 bits; 18 bits specify the operation, 3 bits specify the index 
register, and 15 bits specify the location. In terms of octal digits, there are 
six digits in the first part, one digit in the second part, and five digits in the 
third part. As an example of a complete instruction, 040200 0 00003 
specifies " subtract the contents of location 3 from the contents of the 
accumulator." In writing octal instructions it is usual to give all the 
digits; zero digits are not suppressed. The IBM 7090 has about 200 different 
instructions. An operation code of 8 bits would have sufficed to distinguish 
between all the available instructions. A complete instruction could have 
been 8 + 3 + 15 = 26 bits long. A word can hold both numbers and 
instructions. Apparently the designers of the machine decided that a 36-bit 
word would be necessary in order to retain sufficient accuracy in arithmetic 
calculations, and they therefore had to waste ten bits in most instructions. 
As we shall see later, there are many computers that fit two or more 
instructions in one word. 
Let us list some machine instructions : 
040200 0 00144 Subtract the contents of location 1448 from the contents 
of the accumulator. 
040000 0 01777 Add the contents of location 17778 to the contents of the 
accumulator. 
050000 0 00002 Put the contents of location 28 into the accumulator. 
060100 0 77777 Put the contents of the accumulator into location 777778. 
The first three instructions do not. change the contents of any memory 
location ; they do change the contents of the accumulator. The last opera-
tion changes the contents of location 77777; it does not change the contents 
of any other storage location or the contents of the accumulator. The 
operations that were described at the beginning of this section can be 
expressed as follows : 
050000 0 00002 Put the contents of location 2 in the accumulator. 
040000 0 00003 Add the contents of location 3. 
060100 0 00004 Put the result in location 4. 
Since these instructions are expressible in the binary notation, it is obvious 
that they can be stored in the immediate access memory. Each instruction 
occupies one location. Numbers are stored in one part of the memory and 
instructions are stored in a different part of the memory; for example, 
050000 0 00002 Might be in location 100 
040000 0 00003 Might be in location 101 

2 · 4 THE REPRESENTATION OF INSTRUCTIONS 
49 
and so on. A sequence of instructions is called a program. The sequence of 
operations in, a program is controlled by the control register. At the start 
of the program the location of the first instruction is put into the control 
register. If the program begins at location 100, then initially the control 
register will be set to 100. After the machine has obeyed the first instruction, 
it automatically adds one to the control register so that the next instruction 
is taken from location 101. The instruction after that is taken from location 
102, and so on. 
If the machine could only obey instructions in strict sequence 
many calculations would be impossible. Instructions are usually obeyed in 
sequence; the sequence can be broken by a jump instruction. Typical jump 
instructions are 
002000 0 00110 Put 00110 into the control register; that is, take the next 
instruction from location 1108. 
012000 0 00027 If the contents of the accumulator are positive, then put 
00027 in the control register; however, if the contents of 
the accumulator are negative, then put * +1 in the control 
register. 
The symbol * is used to denote the current location, thus * +1 denotes the 
next instruction in the sequence. Consider the instructions given in Figure 
2.1. The first instruction takes the number in location 2000, and if this 
number is positive, then the control jumps to the instruction in location 104. 
If this number is negative, then control goes to the instruction at location 
102. The two instructions in 102 and 103 subtract twice the number in 
location 2000 from the accumulator, with the result that minus the contents 
of location 2000 is left in the accumulator. The final result of the sequence 
of instructions is that the absolute value of the number in location 2000 is 
placed in location 2001. 
Octal 
Location 
100 
101 
102 
103 
104 
Octal 
Instruction 
050000 0 02000 
012000 0 00104 
040200 0 02000 
040200 0 02000 
060100 0 02001 
Comment 
Put number in accumulator 
Jump to 1048 if it is positive 
Subtract number 
Subtract number 
Store result 
FIG. 2.1 
A sequence of machine instructions 
Instructions and numbers are stored in different parts of the 
memory. What would happen if, through some accident, we used the 
instruction 00200 0 02001 ? This instruction would cause control to jump 
to location 2001. Location 2001 contains a number, not an instruction. The 
machine would not detect this fact. It would take the 36 bits in location 

50 
2 MACHINE LANGUAGE AND ASSEMBLY 
LANGUAGE 
2001 and interpret them as an instruction. The result would usually be 
catastrophic: the computer might stop, or it might loop on one or two 
instructions indefinitely, and it would probably overwrite much of the 
information in the memory. A similar situation would arise if some 
sequence of instructions caused a number to be stored in the location 
occupied by an instruction. This latter fault sometimes happens in Fortran 
programs when the dimensions of an array are too small. 
2-5 
SYMBOLIC LANGUAGE 
The instructions that the machine obeys are binary instructions. In dis-
cussing these instructions we have made use of the more compact octal 
notation. While this notation is very useful because it represents the infor-
mation as it appears inside the machine, it is not a very convenient notation 
when it comes to writing programs. It is usual to write programs in a 
symbolic language. This symbolic language, which is closely related to 
machine language, is more convenient to use. The symbolic instructions 
have to be translated into machine language before they can be used by the 
machine, but this translation is quite a straightforward process. The 
translation can, of course, be performed by the machine itself. The program 
that performs this translation is called an assembler. For the moment we 
can pretend that the programs are written in symbolic form, and that they 
are then translated by hand into machine language. 
There is one symbolic instruction corresponding to each machine-
language instruction. A symbolic instruction consists of three parts. The 
first part specifies the operation code. This part consists of three letters: the 
three letters ADD stand for the instruction 040000, which is the addition 
instruction ; the three letters SUB stand for 040200 which is the subtraction 
instruction, and so on. The symbolic form of the instructions which we 
have considered so far are : 
040000 
ADD 
add 
040200 
SUB 
subtract 
050000 
CLA 
clear the accumulator and add ; 
060100 
STO 
store the contents of the accumulator 
002000 
TRA 
transfer control 
012000 
TPL 
transfer control if the accumulator sign is plus. 
The address part of the instruction consists of a number, a symbol, or an 
expression consisting of symbols and numbers. If the address is a number, 
then it specifies a location using the decimal notation. Thus, since 146 octal 
is 102 decimal, the symbolic form CLA 102 is a representation of the octal 
instruction 050000 0 00146. The index part of the instruction is written 
following the address, but when the index part is zero, then it need not be 

2 · 5 SYMBOLIC 
LANGUAGE 
51 
mentioned. In Figure 2.2 we have rewritten the small program given in 
Figure 2.1. The number 1024 decimal is the same as 2000 octal. 
CLA 
1024 
TPL 
* + 3 
SUB 
1024 
SUB 
1024 
STO 
1025 
FIG. 2.2 The program of Figure 2.1 is written in symbolic form 
The symbol * stands for "the current location" as before, and * + 3 is the 
third location after the current location. The assembler recognizes the 
symbol * and fills in the appropriate value. In Fortran programs, it is 
necessary to attach statement numbers to certain statements. In symbolic 
programs it is useful to label certain statements but a symbol rather than a 
number is used as the statement label. We could write the above program 
in the following way : 
CLA 
1024 
TPL 
A 
SUB 
1024 
SUB 
1024 
A 
STO 
1025 
As in Fortran, the statement label is put in the left-hand margin. This 
symbol can be any combination of one through six characters, except that 
the characters H 
* / and, must not be used. At least one of the characters 
must be a nondigit. Thus, all Fortran names are legitimate symbols, but in 
addition, symbols such as .125 and X.l and 22X are legitimate assembler 
symbols. Algol and PL/1 use alphanumeric labels instead of statement 
numbers. These two compilers would translate the compiler statement 
label into the same assembler statement label. 
In addition to the ordinary instructions, the assembler makes use 
of pseudo-instructions. A pseudo-instruction has the same form as a 
symbolic instruction, but is an instruction to the assembler, not an instruc-
tion to the machine. The program of Figure 2.1 was supposed to go into 
location 100,101, and so on. This information is communicated to the 
assembler by the pseudo-instruction ORG, which stands for origin. For 
example, 
ORG 
64 
means, start the program at location 64 decimal. 
It is necessary to be able to store constants in the program. This 
is achieved by using the DEC (which stands for decimal) pseudo-operation, 
for example, 

52 
2 MACHINE LANGUAGE AND ASSEMBLY 
LANGUAGE 
Location 
In Octal 
2000 
2001 
2002 
2003 
2004 
Machine Language 
In Octal 
000000000027 
000000000006 
000000000020 
400000000144 
000000020001 
Symbolic Code 
ORG 1024 
DEC 23,6,16,-100 
DEC 8193 
In the DEC pseudo-instruction, one or more numbers can be written on 
each line, and the numbers must be separated by a comma. The assembler 
translates each number into 12 octal digits, which is the same as 36 binary 
digits. 
The pseudo-instruction BSS stands for block starting symbol. It 
causes the assembler to leave a specified number of blank locations; 
thus in 
Location 
Machine Language 
In Octal 
in Octal 
Symbolic Code 
ORG. 1024 
2000 
000000000027 
DEC 
23 
BSS 
5 
2006 
000000000144 
DEC 
100 
the five locations 2001 through 2005 have been left blank. In Figure 2.3 
we rewrite the example of Figure 2.1 in the form in which it would usually 
be written 
ORG 
64 
CLA 
I 
TPL 
* + 3 
SUB 
I 
SUB 
I 
STO 
1+1 
ORG 
1024 
I 
DEC 
- 2 1 
BSS 
1 
Fig. 2.3 The program of Figure 2.2 written with symbolic addresses 
Notice that the assembler symbol 1+1 means the next location after 
location I. There is a close relationship between the symbolic and machine 
instructions. For any compiler statement, it is impossible (unless we know 
exactly how the compiler works) to know what the corresponding machine 
language will be. The compiler language is superior to assembly language in 

2 · 6 ARITHMETIC 
INSTRUCTIONS 
53 
many respects, but assembly language is necessary when we want to con-
sider the detailed working of the machine, or when the solution to a 
problem cannot be efficiently coded in a problem-orientated language. 
2-6 
ARITHMETIC INSTRUCTIONS 
A computing machine can obey a fixed number of different machine instruc-
tions. The number of instructions in the repertoire varies from machine to 
machine. There is no optimum number of instructions. The machine 
designer has to balance various factors such as cost, speed, and reliability. 
At one time the number of instructions was limited by technology. At a 
later stage it was limited by cost. At the present time it seems to be possible 
to build different machines with the same instruction set; the machines 
differ in speed, price, and in the way in which they are made, but they obey 
exactly the same instructions. It is possible to make a general purpose 
computer that has an instruction set of only three or four instructions; see 
for example Arden (Chapter 1, 1963) and Davis (1958). The machines built 
in the early 1950's usually had between 10 and 30 different instructions. 
Machines built recently have had several hundred different instructions. 
We wish to describe the instruction sets of several different 
machines. It will be convenient to use the following notation : 
a 
The accumulator 
q 
The multiplier quotient register 
aq 
The a and the q are sometimes used as though they were one double-
length register; the sign of the mq is made the same as the sign of the 
accumulator: the rest of the accumulator, mq is considered as a 70-bit 
integer 
c 
The control register 
/ 
A symbol used as an address, as in CLA I 
m 
The memory; individual words in the memory will be denoted m(0), 
m(l),m(2),...m(32767). 
An instruction such as CLA 99 can be written "a = ra(99)", where the 
symbol = is used to represent the replacement operation; that is, the 
contents of a is replaced by the quantity in location m{99). An instruction 
such as CLA I can be written a = m(I). A symbol such as / has two 
meanings. In the compiler language / denotes the name of a variable. In 
assembler language, / denotes an address. However, the compiler stores 
the variable / in the assembler location that has the name /. In the example 
of Figure 2.3, /, when considered as a Fortran variable, has the value 
— 21; however, the assembler symbol / has the value 1024. The Fortran 
statement 
/ = / 
would be compiled as 
CLA I 
STO J 

54 
2 MACHINE LANGUAGE AND ASSEMBLY 
LANGUAGE 
That is, pick up the contents of location / and store it in location J. The 
following is a list of the more common arithmetic instructions : 
CLA 1 
STO 1 
ADD 1 
MPY 1 
DVP 1 
a = m(I) 
m(I) = a 
a = a + m(I) 
aq = q*m(I) 
q = aqlm(l) 
LDQ 1 
STQ 1 
SUB 1 
XCA 
q = m(l) 
m{I)=q 
a = a — m(I) 
a=q,q 
= a 
(The remainder from the division is left in the accumulator.) 
After each of the above instructions, the control register is increased by one 
when the operation has been obeyed. Since the control register is increased 
by one in most instructions, we will only note the exceptions to this rule. 
Let us emphasize that the notation 'α = ηι(ΐγ is introduced for 
didactic reasons. It is not a notation which is in common usage. 
2-7 
TRANSFER INSTRUCTIONS 
The transfer or jump instructions affect the contents of the control register. 
TRA I 
c = I 
TPL I 
If a is positive then c = /, otherwise c = c + 1 
TMI I 
If a is negative, then c = /, otherwise c = c + 1 
TZE I 
If a is zero, then c = /, otherwise c = c + 1 
There is an instruction called TQP that is similar to TPL except that it 
tests the sign of the mq register. 
2 -8 SOME SIMPLE ASSEMBLY-LANGUAGE PROGRAMS 
As an example of an assembly-language program we will write a program to 
evaluate 
l = (J + K)*(L+M) 
The program has to be placed somewhere in the memory. When operating 
under a monitor system, the choice of a beginning location can be left to 
the system, but in order to define the program fully at this stage, we will 
specify an origin of 1008. The data of the problem can be read in at 
execution time or it can be set in the program by DEC cards. We use the 
latter method since READ statements have not been discussed. The 
program is shown in Figure 2.4. 

2 · 8 SOME SIMPLE ASS EM BLY-LAN G U AG E PROGRAMS 
55 
Octal 
location 
100 
101 
102 
103 
104 
105 
106 
107 
1000 
1001 
1002 
1003 
1004 
1005 
Octal 
Instruction 
050000 0 01007 
040000 0 01004 
060100 0 01005 
050000 0 01001 
040000 0 01002 
013100 0 00000 
022100 0 01005 
460000 0 01000 
000000000307 
400000000024 
000000000003 
000000000014 
I 
J 
K 
L 
M 
TEMP 
FIG. 2.4 Symbolic 
Symbolic 
Instruction 
ORG 
CLA 
ADD 
STO 
CLA 
ADD 
XCA 
MPY 
STQ 
ORG 
BSS 
DEC 
DEC 
DEC 
DEC 
BSS 
64 
L 
M 
TEMP 
J 
K 
TEMP 
I 
512 
1 
199 
- 2 0 
3 
12 
1 
instructions for / = (J + K)' 
Comments 
forms L + M 
and stores 
the result 
form / + K 
). 
multiply by L + M 
store result 
space for / 
space for TEMP 
*{L+M) 
The final result is 7=268510 and the contents of location 1000 is 
000000005175 
In punching the assembler language statements the label, if there is one, 
goes in columns 1 through 6. The operation code goes in columns 8, 9, and 
10. The address part begins in column 16. The first blank that occurs after this 
indicates the end of the statement. Remarks may be placed after the end 
of the statement. The assembler produces a printed sheet which is similar 
to the listing given above. It lists the address of each location used and it 
shows the octal contents of the location. These listings are very useful in 
following through a long program. They make it particularly easy to 
follow up references to variables which are defined in some other part of 
the program. 
As a second example we wish to 
set / = K if / is zero or 
set J=L if / is nonzero 
107 
056000 0 01002 
110 
050000 0 01000 
111 
010000 0 00113 
112 
056000 0 01003 
113 
460000 0 01001 
ORG 
LDQ 
CLA 
TZE 
LDQ 
ISZERO 
STQ 
71 
K 
I 
ISZERO 
L 
J 
we have assumed the same locations for I,J,K, and L as in the last problem. 

56 
2 MACHINE LANGUAGE AND ASSEMBLY 
LANGUAGE 
For the third example we wish to : 
set location LSUM equal to the sum of the contents of locations 
LV,LV+l,LV + 2, and LV + 3. 
The simple solution is 
100 
101 
102 
103 
104 
050000 0 01000 
040000 0 01001 
040000 0 01002 
040000 0 01003 
010100 0 01004 
ORG 
CLA 
ADD 
ADD 
ADD 
STO 
64 
LV 
LV+1 
LV+2 
LV+3 
LSUM 
There is an alternative solution that can be used to sum any number of 
terms. This is shown in Figure 2.5. Location FINAL is the start of the 
100 
101 
102 
103 
104 
105 
106 
107 
110 
111 
112 
113 
114 
115 
1000 
1004 
1005 
1006 
1007 
050000 0 
060100 0 
050000 0 
040000 0 
060100 0 
050000 0 
040200 0 
010000 0 
060100 0 
050000 0 
040000 0 
060100 0 
002000 0 
01005 
01004 
01004 
01000 
01004 
01007 
01006 
00115 
01007 
00103 
01006 
00103 
00102 
000000000025 
000000000000 
000000000001 
000000000004 
LOOP 
ALV 
FINAL 
LV 
LSUM 
NZ 
N1 
N 
ORG 
CLA 
STO 
CLA 
ADD 
STO 
CLA 
SUB 
TZE 
STO 
CLA 
ADD 
STO 
TRA 
ORG 
DEC 
BSS 
DEC 
DEC 
DEC 
64 
NZ 
LSUM 
LSUM 
LV 
LSUM 
N 
N1 
FINAL 
N 
ALV 
N1 
ALV 
LOOP 
512 
21,98721,56,2781 
1 
0 
1 
4 
Fig. 2.5 A program to sum the contents of LV,LV+1,LV+2,... 
next piece of program. This solution is more complicated than the previous 
one, but it will work for any value of N. It could be used to sum a thousand 
or more numbers; the length of the program is independent of the length 
of the summation. It is an example of a programming loop similar to the 
DO loop of Fortran and PL/1 or the FOR loop of Algol. The program 
starts by initializing LSUM. The first number is added into LSUM. The 
next two instructions subtract 1 from N and test to see if the end of the 
loop has been reached. If N terms have been summed, then the program 
jumps to FINAL. If TV terms have not been summed, then it prepares to go 
round the loop again. The instruction CLA ALV and two instructions that ' 

2 - 9 LOGICAL A N D SHIFT OPERATIONS 
57 
follow it pick up the contents of location ALV and add one to it. Before the 
addition ALV contains 
040000 0 01000 
which is 
ADD 
LV 
after the addition it contains 
040000 0 01001 
which is 
ADD 
LV+1 
Each time, before ALV is obeyed, its address is increased by one so that it 
successively adds LV, LV+1, LV + 2, and so on. This method of coding is 
obviously not satisfactory. It is wasteful of programming time and it is 
wasteful of machine time and space. The problem requires N additions but 
the program is doing IN additions and N subtractions. The example 
illustrates that some efficient method of handling loops is required. This 
more efficient method will be given when we consider the use on index 
registers. 
2-9 
LOGICAL and SHIFT OPERATIONS 
The first two shift operations are 
ALS 
I 
accumulator left shift; the contents of the accumulator are 
shifted / places to the left 
ARS I 
accumulator right shift; the contents of the accumulator are 
shifted / places to the right. 
Suppose the accumulator contains 
101111000000000000001101101111101011 
then ALS 5 would produce 
100000000000000110110111110101100000 
whereas ARS 5 would produce 
000001011110000000000000011011011111 
Notice that the ALS 5 causes 5 bits to be lost from the left hand end of the 
word. These shift operations are used in some arithmetic calculations and 
they are also used in manipulating patterns of binary digits. In the former 
case the programmer wants to keep the sign bit in a fixed position, whereas 
in the latter case the programmer wishes to shift the sign bit along with the 

58 
2 MACHINE 
LANGUAGE AND ASSEMBLY 
LANGUAGE 
other bits. To accommodate these two cases the accumulator is actually a 
38-bit register, with the following configuration 
S 
QP1 . . . 35 
The bits are numbered 35 through 1, S,P, and Q. S stands for the sign bit. 
Let a denote the 36 bits S12 ... 35. Let g denote the 36 bits PI2 ... 35. The 
a or arithmetic accumulator is used in arithmetic operations such as 
ADD. The g or logical accumulator is used in logical operations such as 
ALS. The g and the a accumulator have 35 bits in common. 
To give a more accurate description of some of the operations 
which have been defined so far : 
CLA 
I set a = m(I) and set the P and Q bits to zero. 
STO 
I set m(I) = a. 
ADD I add the 36-bit number in m{l) to the 38-bit number in the accumu-
lator. In normal operation the P and Q bits are zero and the opera-
tion can be expressed simply as a = a + m(I). 
In normal arithmetic operations, the P and Q bits are set to zero by the 
CLA instructions. The P and Q bits can become nonzero only if the 
addition involves a result that is greater than 235 — 1, and such a thing 
should not happen. Similar remarks hold in connection with the subtrac-
tion, multiplication and division instructions. Since the description 
ADD 
I a=a + m(I) 
holds in all normal arithmetic operations, then we will continue to use it. 
The accurate description of ALS and ARS is 
ARS I shift the bits in accumulator positions Q,P,1,2, ...35 by / places to 
the right. Do not change the sign bit. A condensed description of 
the operation is g = gj2**I 
ALS 
I shift the bits in accumulator positions Q,P,1,2, ...35 by / places to 
the left. The sign bit is unchanged. In other words g =#*2**/, 
modulo 236. 
In order to facilitate logical operations there are two more operations 
similar to CLA and STO 
CAL 
I g = m(I) and the S and Q bits are set to zero. 
SLW I 
m(I)=g. 
There are five more shift operations besides ALS and ARS. One of the 
operations which we will use later is 
LGL 
I logical left shift. The contents of bits Q,P,1,2, ...35 and the 36 bits 
of q are regarded as one 73-bit register. This operation shifts the 
bits / places to the left and leaves the sign of the accumulator 
unchanged. 

2 · 10 CHARACTERS AND BYTES 
59 
Boolean algebra can be represented in several ways. In one of the 
representations the variables have the value 0 or 1. Variables can be com-
bined by the operator " or," the operator " and " and the operator " not." 
The operators obey the rules. 
0 and 1 - 0, 1 and 0 = 0, 0 and 0 - 0, 1 and 1 - 1 
0 or 1 = 1, 1 or 0 = 1 , 0 or 0 = 0, 1 or 1 = 1 
not 0 = 1, 
not 1 =0, 
In another representation of Boolean algebra the value 0 is replaced by 
"false" and the value 1 is replaced by "true." The rules for using the 
operator "and" are 
false and true = false, 
false and false = false 
true and false = false 
true and true = true 
It can be seen that these are identical with the rules in which 0 and 1 were 
used in place of false and true. Similar rules hold for " or " and " not." The 
logical variables of Fortran IV and the Boolean variables of Algol follow 
the rules of Boolean algebra. 
The computer has machine instructions that perform the three 
basic Boolean operations. 
ANA 
I 
sets 
g = g and m(I) 
ORA 
I 
sets 
g = g or m(I) 
COM 
sets 
g = not g 
COM stands for complement. The word complement means the same as the 
logical "not" operation, namely, replace ones by zeros and zeros by ones. 
The operations are applied to each of the 36 bits of the logical accumu-
lator. If 
g contains 
000000000011111111110000011111010101 
and m(l) contains 
111000101100011101010011 010111011 011 
ANA I would set g = 
000000000000011101010000010111 01 0001 
ORA I would set g = 
11100010111111111111 0011 011111011111 
COM would set g = 
1111111111000000000011111 000001 01010 
It can be seen that the bits in each vertical column on the page follow the 
rules for "and," " o r " and "not." These operations are useful in many 
nonnumerical applications. 
2-10 
CHARACTERS and BYTES 
The details of the 7090 which have been given so far describe a machine 
that can be used for numerical calculations. The machine can also be used 
for nonnumerical problems. The format statements that are used in 

60 
2 MACHINE LANGUAGE AND ASSEMBLY 
LANGUAGE 
Fortran, PL/1, and some versions of Algol are examples of nonnumerical 
information that has to be stored in the memory. A typical format statement 
might appear as 
FORMAT(8H ANSWER = F10.2) 
This format consists of 17 alphanumeric characters, namely (, 8, H, and 
so on. A character can be stored in the memory by replacing it by some 
number. In the 7090 characters are replaced by 6-bit binary numbers 
according to the Table 2.2. There are many other possible schemes; this 
particular one is used in many computers. There is an assembler pseudo-
operation that has the form 
BCD 
nciC2Cz ... 
BCD stands for binary coded decimal. The terms BCD and Hollerith are 
commonly used in connection with ways of representing alphanumeric 
information in binary. Neither term has a unique meaning and neither term 
is particularly well chosen. The assembler pseudo-operation BCD translates 
the characters cxc2c3 ... according to Table 2.2. It stores the result with 
TABLE 2-2 
THE REPRESENTATION of CHARACTERS 
by OCTAL NUMBERS 
0 
1 
2 
3 
4 
5 
6 
7 
8 
9 
= 
00 
01 
02 
03 
04 
05 
06 
07 
10 
11 
13 
+ 
A 
B 
C 
D 
E 
F 
G 
H 
I 
. 
) 
20 
21 
22 
23 
24 
25 
26 
27 
30 
31 
33 
34 
— 
J 
K 
L 
M 
N 
0 
P 
Q 
R 
$ 
* 
40 
41 
42 
43 
44 
45 
46 
47 
50 
51 
53 
54 
/ 
S 
T 
u 
V 
w 
X 
Y 
z 
' 
( 
60 
61 
62 
63 
64 
65 
66 
67 
70 
71 
73 
"M 
six characters to one word. The n following the BCD indicates that there 
are 6n characters to be translated. The compiler might translate the format 
statement given above into 
Octal equivalent 
Assembled instruction 
741030602145 
BCD 
3(8H ANSWER = F10.2) 
626625511326 
010033023460 

2 - 10 CHARACTERS AND 
BYTES 
61 
The first character is ( which becomes 74 in octal. It is placed at the left-
hand end of the first word. The octal number 10, which represents 8, is 
placed next to it. The first word contains the representation of (8H AN, the 
next computer word contains SWER = F and the final word contains 
10.2) followed by a blank to fill out the word. These three words are put in 
successive memory locations. The digit 8 and the other digits in the string 
are stored as characters. The fact that these characters happen to represent 
decimal digits is of no relevance at this stage. 
When the program comes to use the format statement, it knows the 
location of the start of the statement but it does not know what the 
statement contains. The first thing the program might do is to check that 
the first character is an opening parenthesis. This can be done by 
LDQ 
FORMAT 
CLA 
NZ 
LGL 
6 
SUB 
PAREN 
TZE 
OK 
we assume that FORMAT is the address of the first word of the format and 
that NZ and PAREN contain 
NZ 
DEC 
0 
PAREN 
BCD 
100000( 
The piece of program goes to location OK if the character is really a (, 
otherwise it goes to the next location. The operation LGL 6 shifts the 
left-hand 6 bits of the format into the accumulator. The next two instruc-
tions test to see if these 6 bits are 74 octal. 
The other characters in the first word in the format can be 
separated out by giving further LGL instructions. When the location OK 
is reached, the accumulator will contain zero and the mq will contain 
103060214500. That is, the original first word of the format has been 
shifted six places. Another LGL 6 operation would set the accumulator 
equal to 10. In this way the separate characters can be examined and the 
appropriate action taken. 
The 6-bit character is an example of a byte. A byte is any group of 
bits which forms the unit of a calculation. The 7090 usually works in bytes 
of 36. As we have seen, by using the shift instruction it is possible to 
manipulate bytes of six bits. It is obvious that the shift and logical instruc-
tions make it possible for the 7090 to operate on bytes of any length. 
Although the 7090 can do byte manipulations, it is apparent that they 
can be quite time consuming. There are machines in which small bytes can 
be used efficiently. The byte size of 8 bits is commonly used on the 
IBM 360 and byte manipulations can be performed without extensive 
shifting operations. 

62 
2 MACHINE LANGUAGE AND ASSEMBLY 
LANGUAGE 
2-11 
OTHER TYPES of INSTRUCTIONS 
There are three other major types of machine instructions: namely, 
floating-point 
instructions, indexing instructions, and 
input-output 
instructions. A machine like the 7090 has a great number of instructions, 
but most of them do not introduce any new principle. For example, SSP 
sets the sign of the number in the accumulator to be plus, SSM sets it to be 
minus, and CHS changes the sign; STA stores the last 15 bits of the 
accumulator, and SLQ stores the last 18 bits of the q register. There is no 
necessity for these instructions ; for example, SSM could be accomplished by 
TMI 
* + 4 
STO 
X 
SUB 
X 
SUB 
X 
While it might be objected that this requires four instructions in place of 
one, setting the sign minus is not a process that is likely to be used very 
frequently. There is a reason for this plethora of instructions. Some 
additional instructions do not necessarily add to the cost of the machine. A 
computer consists of many electronic circuits. In order to obey a particular 
instruction, the computer has to select certain circuits in a certain sequence. 
By combining circuits in different ways it is possible to build up a large set 
of machine instructions. 
2-12 
FLOATING-POINT INSTRUCTIONS 
We have described the representation of numbers inside the machine. The 
numbers are represented by signed binary integers. In order to do a calcula-
tion using these numbers, it would be necessary to convert everything to 
integers. In monetary calculations it would not be inconvenient to work in 
this way; we could express every amount in cents rather than in dollars. In 
scientific calculations a similar scaling process is possible; for example, if 
we expected all the number in a calculation to lie between 0.00001 and 
10.0, then we could multiply all the numbers by 100,000 and work in 
integers. For some calculations this process is not too inconvenient, but in 
most problems it is very inconvenient; and sometimes it is difficult to 
arrange the calculation so that all numbers are within range. The solution 
to the problem is to let the machine carry a scaling factor which it adjusts 
as required. The arithmetic operations that include this automatic scaling 
are called floating-point operations. Floating-point operations do not 
operate on integers, they operate on another type of number called a 
floating-point number. These numbers are used for the Real (as opposed 
to Integer) variables of Fortran and Algol. They are used for the Float 
variables in PL/1. 

2 - 12 FLOATING-POINT 
INSTRUCTIONS 
63 
In ordinary mathematical notation a decimal fraction is indicated 
by using the decimal point; thus 
42.768 = 4 x 10 1+2 x 10°+ 7 x 10" χ+6 x 10"2 + 8 x 10'3 
Very large or very small numbers can be represented by the form " decimal 
number times 10""; thus 1.2 x 107 represents the number 12000000. For-
tran and PL/1 use this notation but they modify it to 1.2E7 in order to fit it 
on a punched card. This power-of-ten notation allows several equivalent 
forms of one number : 
42.768 = 0.42768 x 102 - 42768.0 x 10" 3 
are three of the many possible forms. The point can also be used in the 
binary notation. If dxd2 ... are binary digits then 
O.i/^2... =dx x2" 1+i/ 2 x2" 2 + ··· 
Some fractional decimal numbers with their binary equivalent are 
decimal 
0.5 0.25 0.75 
6.75 
binary 
0.1 0.01 0.11 110.11 
The power-of-two notation can also be employed: 
110.112 =0.11011 x 23 = 11011.0 x 2"2 
If the base and exponent are also written in binary, this word appears as 
110.11 =0.11011 x 1011 = 11011.0 x 10"10 
Both the number and the exponent are in binary. Numbers which have the 
form " a binary number times a power of two " are called floating-point 
binary numbers. The name refers to the fact that the point can appear 
anywhere in the number providing the exponent is adjusted accordingly. It 
is convenient to have one standard form for a number. A binary floating-
point number is said to be normalized if the digits to the left of the point 
are zero and if the first digit to the right of the point is a 1. The number 
0.11011 x 23 is normalized, whereas 110.11 and 11011.0 x 2" 2 are 
unnormalized. Any number can be normalized by moving the point and 
making the corresponding adjustment in the exponent. Some examples of 
normalized numbers follow. 
^ 
. 
normalized floating-point binary 
Decimal 
number 
fraction 
binary exponent 
1.0 
= i x 2 
0.1 
1 
10.0 
=10/16 x 2 4 
0.101 
100 
0.25 
= J x 2 " 1 ; 
0.1 
- 1 
1024.0 
= l x 2 n 
0.1 
1011 

64 
2 MACHINE LANGUAGE AND ASSEMBLY 
LANGUAGE 
The 7090 can perform arithmetic operations on floating-point binary 
numbers. These numbers are represented by a 36-bit word that has the 
following form : 
the S bit 
gives the sign of the number 
bits 1 
bits 9 
-8 
are 10000000 plus the binary exponent 
-35 
are the fractional part of the number 
A few examples should make this clear. 
Decimal 
number 
1.0 
10.0 
0.25 
1024.0 
-1024.0 
0.0 
0.1 
s 
Machine representation 
i charac-
g teristic 
fraction 
n 
010000001 100000000000000000000000000 
0 10000100 101000000000000000000000000 
0 01111111 100000000000000000000000000 
010001011100000000000000000000000000 
1 10001011 100000000000000000000000000 
0 00000000 000000000000000000000000000 
0 01111101 110011001100110011001100110 
Octal form of 
machine word 
201400000000 
204500000000 
177400000000 
213400000000 
613400000000 
000000000000 
175631463146 
The number which is 100000002 plus the exponent is called a characteristic. 
The 7090 uses the characteristic, some other machines prefer to use a signed 
exponent. There would seem to be a slight advantage in the use of the 
characteristic. A 36-bit word can represent an integer or a floating-point 
number. The operations used on the word are usually different, depending 
on whether the number is an integer or floating point. Thus ADD is used 
on integers but a completely different machine instruction called FAD is 
used to add two floating-point numbers. Since the 7090 uses a characteristic 
it turns out that certain comparison operations are independent of the form 
of the number; for example, 201400000000 is greater than 177400000000 
whether these two numbers are regarded as integers or floating-point 
numbers. 
A normalized fraction has a 1 to the right of the point. The frac-
tional parts of normalized numbers lie between 
100000000000000000000000000 
which is 
J 
111111111111111111111111111 
which is 
1 - 2"27 
in other words, all fractional parts are greater than or equal to 0.5 and less 
than 1.0. The highest characteristic is 11111111, which corresponds to an 
exponent of 12710. The largest floating-point number that can be repre-
sented is (1 -2~ 2 7) x 2127. The smallest normalized number is 2" 1 2 9, but 
of course zero itself can be represented by either 0000000000008 or 
4000000000008. Integers between 0 and 2 2 7 - 1 can be represented exactly 
by a floating-point binary number. Numbers that are 2n times these 
integers can also be represented exactly. Other numbers are represented 

2 · 12 FLOATING-POINT 
INSTRUCTIONS 
65 
with an accuracy of one part in 227. In order to convert powers of 2 to 
powers of 10 it is necessary to multiply by log10 2 which is 0.3010; thus 
227 =' 1 08.i a n d 2i27 = 1038.2 Floating-point arithmetic on the IBM 7090 
is correct to eight decimal places on numbers between 1038 and 10"38. 
A floating-point binary number can be represented in octal simply by 
grouping the bits in threes. The octal form is shorter and more convenient. 
The transfer from decimal to the octal representation of floating-point 
binary can be achieved as follows. Let the number be X. Find an integer 
n such that, 
Absolute value of X = y x 2" where \ < y < 1.0. 
Compute the characteristic as follows : 
characteristic = 2008 + octal representation of n. 
An example should make this clear. Let X = — 0.1 decimal; then y = 0.8 
and n = — 3. The characteristic is 2008 — 3= 175. The fractional part is 
found by 
8x0.8 = 6.4, 
8x0.4 = 3.2, 8 x 0 . 2 = 1 . 6 , 
8 x 0 . 6 = 4 . 8 , 
8 x 0.8 = 6.4, and so on, 
that is, we multiply y by 8, multiply the fractional part of Sy by 8, and so on. 
The integral part of each result gives the successive octal digits. These 
digits are 631463146. The representation of 0.1 is obtained by adding on 
the characteristic; thus 175631463146. The minus sign is indicated by 
adding 40000000000008, the final result is -0.1 decimal is 575631463146. 
The translation from floating point to decimal is performed by separating 
out the sign, the exponent, and the fraction. The exponent is easily 
converted. The digits of the fraction represent successive powers of 1/8; 
thus 631463146 represents 6 x £ + 3 x (£)2 + 1 x (i)3 + ···. It should not 
be necessary to perform these conversions by hand, but it is occasionally 
useful to do an order-of-magnitude calculation. Table 2.3 makes it easy to 
do a rapid approximate conversion. 
There is a set of machine instructions for operations on floating-
point numbers. 
FAD X 
a = a -f m{X) 
FSB X 
a = a-m(X) 
FMPX 
a = q*m{X) 
FDP X 
q = a/m(X) 
Note that these instructions perform all the necessary manipulations on the 
fraction and the mantissa. For example, 201400000000 divided by 
204500000000, that is, 1.0 divided by 10.0, produces 174631463146 which 
is 0.1. A number has several possible representations inside the machine. 
The number 12 has the integer representation 00000000014 or the floating-
point representation 204600000000. The programmer must not mix these 

66 
2 MACHINE LANGUAGE AND ASSEMBLY 
LANGUAGE 
TABLE 2-3 
OCTAL and DECIMAL REPRESENTATION of POWER of TWO 
l./X 
2014 
2004 
1774 
1764 
1754 
1744 
1734 
1724 
1714 
1704 
1674 
1664 
1654 
1644 
1634 
1624 
1614 
1604 
1574 
1564 
1554 
1544 
1534 
1524 
1514 
1504 
1474 
1464 
1454 
1444 
1434 
1424 
1414 
1404 
1374 
1364 
X 
2014 
2024 
2034 
2044 
2054 
2064 
2074 
2104 
2114 
2124 
2134 
2144 
2154 
2164 
2174 
2204 
2214 
2224 
2234 
2244 
2254 
2264 
2274 
2304 
2314 
2324 
2334 
2344 
2354 
2364 
2374 
2404 
2414 
2424 
2434 
2444 
N 
0 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
20 
21 
22 
23 
24 
25 
26 
27 
28 
29 
30 
31 
32 
33 
34 
35 
2»*N OCTAL 
1 
2 
4 
10 
20 
40 
100 
200 
400 
1000 
2000 
4000 
10000 
20000 
40000 
100000 
200000 
400000 
1000000 
2000000 
4000000 
10000000 
20000000 
40000000 
100000000 
200000000 
400000000 
1000000000 
2000000000 
4000000000 
10000000000 
20000000000 
40000000000 
100000000000 
200000000000 
400000000000 
2»«N DECIMAL 
1 
2 
4 
8 
16 
32 
64 
128 
256 
512 
1024 
2048 
4096 
8192 
16384 
32768 
65536 
131072 
262144 
524288 
1048576 
2097152 
4194304 
8388608 
16777216 
33554432 
67108864 
134217728 
268435456 
536870912 
1073741824 
2147483648 
4294967296 
8589934592 
17179869184 
34359738368 
2»»<-N) DECIMAL 
1.0000000E 00 
5.0000000E-01 
2.5000000E-01 
1.2500000E-01 
6.2500000E-02 
3.1250000E-02 
1.5625000E-02 
7.8125000E-03 
3.9062500E-03 
1.9531250E-03 
9.7656250E-04 
4.882812EE-04 
2.4414063E-04 
1.2207031E-04 
6.1035156E-05 
3.0517578E-05 
1.5258789E-05 
7.6293945E-06 
3.8146973E-06 
1.9073486E-06 
9.5367432E-07 
4.7683716E-07 
2.3841858E-07 
1.1920929E-07 
5.9604645E-08 
2.9802322E-08 
1.4901161E-08 
7.4505806E-09 
3.7252903E-09 
1.8626451E-09 
9.3132257E-10 
4.6566129E-10 
2.3283064E-10 
1.1641532E-10 
5.8207661E-11 
2.9103830E-11 
X* FIRST FOUR OCTAL DIGITS OF FLOATING POINT REPRESENTATION 
EXAMPLE 256.0 * 211400000000 
1./256.0 = 171400000000 

2 ■ 12 FLOATING-POINT 
INSTRUCTIONS 
67 
representations. The machine does not check the representation. If the 
programmer asks for 204600000000 plus 204600000000 by using FAD, 
then a correct result is obtained; if he uses ADD by mistake then the 
machine applies the rules for adding integers and produces the wrong 
result. It is possible to convert from one representation to the other. Let 
us take an integer such as 000000000014 and add the integer 233000000000, 
using the ADD operation. The result is 2330000000014. Now let us FAD 
the number 000000000000. This adds zero, which effectively does nothing; 
however, at the end of all floating-point operations the result is 
normalized; that is, the fractional part is shifted into the range >0.5 and 
<1.0 and the exponent is adjusted accordingly. If 233000000014 is 
normalized, then the result is 204600000000, which is the floating-point 
representation of 12.0. 
The assembler provides a method of inputting floating-point 
numbers. Numbers on a DEC card are assembled as floating-point 
numbers if they contain a decimal point. If no point appears, then the 
number is assembled as an integer. Several numbers can appear on one 
card ; for example 
ORG 
100 
DEC 0.5,2,2. 
puts the floating-point number 0.5 in location 100, the integer 2 in location 
101, and the floating-point number 2.0 in location 102. 
A full description of compiler language will be given later; how-
ever, it is useful to explain some of the features of compiler languages 
which might otherwise impede the understanding of machine language. An 
integer variable such as L is represented by a binary integer; a real variable 
such as Z is represented by a floating-point number. The compiler takes all 
the necessary steps to insure that a statement like L = L — 2 is done with 
the SUB operation, whereas Z = Z — 2 is done with a FSB. It also treats 
Z = L correctly by taking L, adding 233000000000, and so on, in order to 
convert the integer to a floating-point number. 
The STO operation simply stores the contents of the accumulator; 
it does not modify it in any way. This operation can be used to store either 
integers or floating-point numbers. Similar remarks apply to CLA and 
LDQ and the other operations that merely transmit words from one part 
of the machine to another. As an example of floating-point arithmetic 
CLA 
Y 
FAD 
Z 
FDP 
W 
STQ 
X 
sets 
X=(Y + Z)IW. 

68 
2 MACHINE LANGUAGE AND ASSEMBLY 
LANGUAGE 
Arithmetic operations may produce results that are outside the 
range of the machine. Suppose we ask the machine to add the floating-
point number 377400000000 to itself. The result is a number with charac-
teristic 400. This is an invalid number since characteristics must be between 
000 and 377: the number 400400000000 is not a number with characteristic 
400, it is the negative of 000400000000. If a floating-point arithmetic 
operation has a result with a characteristic that is too large, then it is said 
to result in overflow. If an arithmetic operation results in a characteristic 
that is too small, then this is called an underflow. Subtracting two floating 
point numbers, such as 000460000000 - 000400000000, gives underflow ; the 
result is fraction 400000000, characteristic - 3 . On the IBM 7090 an 
underflow or overflow causes an interrupt. The machine automatically 
saves certain information such as the address of current instruction, then it 
abandons the current program and jumps to a specified location. This jump 
hands control to one of the monitor routines. The monitor routine examines 
the fault. In most monitor systems, on overflow the monitor terminates 
the job; on underflow the monitor puts 0 in the accumulator and hands 
control back to the program, and the program then proceeds as though 
there had been no interruption. 
Subtracting two equal numbers (or adding a number to the 
negative of itself) does not cause underflow, but it does produce an 
exact zero. Fixed-point operations can produce overflow or a condition 
similar to underflow. On the 7090 these fault conditions do not cause an 
interrupt but their presence is recorded. On a more modern machine, 
almost all fault conditions cause an interrupt. For further details see Section 
5.4. 
2-13 
INDEX INSTRUCTIONS 
An index register contains 15 bits; that is, it contains as many bits as the 
address part of the instruction. The IBM 7090 has three index registers 
which we will denote by /T, il, and z'4. The reason for 1, 2, and 4 rather 
than 1, 2, and 3 need not concern us ; it was essentially a historical accident. 
If index register 2 contains the number 99, then CLA X,2 has the same 
effect as CLA X— 99. In general, any reference to X,n has the same effect as 
a reference to I - in, where in denotes the contents of index register n. 
Most of the operations that we have discussed can be indexed. There are 
a number of machine instructions for setting and for storing the value of 
an index register. 
LXA N,2 
i2 = m(N) 
AXT N,2 
i2 - N 
SXA N,2 
m(N) = il 
Notice the difference between these instructions; suppose location 123 

2 · 13 INDEX INSTRUCTIONS 
69 
contains the number 55; then LXA 123,4 sets index register 4 equal to 
55, whereas AXT 123,4 sets index register 4 equal to 123. Since an index 
register holds 15 bits, the instruction SX A N,2 changes the last 15 bits of 
location N without aifecting the first 21 bits. The instructions TXI, TXL, or 
TXH are the instructions that correspond to the end of a DO loop. 
TXI X,1 ,N 
sets Π == /1 + N and transfers to location X. 
TXL X,1 ,N 
has the effect TRA X if /1 is less than or equal to TV, or the 
effect TRA * + l if/l is greater than N. 
TXH X,1,N 
has the effect TRA X if Π is greater than N, or the effect 
TRA * + l if /1 is less than or equal to TV. 
TXI, TXL, and TXH have an address part, an index part, and a part called 
the decrement. In this case the decrement is N. Most instructions do not 
have a decrement—in fact there is no space for a decrement in the instruc-
tion. The decrement is stored in bits 4 through 18 of the instruction. 
Let us now reconsider the problem given at the end of Section 
2.8. The problem was to add the contents of locations LV,LV+ l,LV + 2, 
and LV + 3 and to put the result in LSUM. One solution to the problem 
was given in Figure 2.5. Another solution is 
ORG 
AXT 
AXT 
CLA 
LOOP 
ADD 
TXI 
TXI 
TXL 
STO 
64 
0,1 
0,2 
NZ 
LV,2 
* + 1,2,-1 
* + 1,1,1 
LOOP,1,3 
LSUM 
Index register 1 is used to count the number of times the loop is repeated 
and index register 2 is used to adjust the effective address of LV. It is not 
necessary to use two index registers. One index register could be used both 
to adjust the effective address and to count the number of times round the 
loop; this is done in the following solution. 
ORG 
64 
AXT 
1,1 
CLA 
LV + 3 
LOOP 
ADD 
LV + 3,1 
TXI 
* + 1,1,1 
TXL 
LOOP,1,3 
STO 
LSUM 
It can be seen that both of these solutions are superior to the one given in 
Figure 2.5 and could easily be adapted to adding any number of terms. 
The explanation of the first piece of code is the following. Index 
registers 1 and 2 and the accumulator are all set to zero. The instruction 
at LOOP adds the contents of location LV into the accumulator. Index 

70 
2 MACHINE 
LANGUAGE AND ASSEMBLY 
LANGUAGE 
register 2 is increased by minus one, that is, it is decreased by one. Index 
register 1 is increased by one and it is tested. If it is less than or equal to 
three, then the program goes back to LOOP. Index register 2 is now — 1 so 
ADD LV,2 has the same effect as ADD LV +1. This process is repeated the 
necessary number of times. 
The second example is somewhat similar except that the terms are 
added in the other LV + 3, LV + 2, LV+1, LV. 
As can be seen from these examples, index registers provide an 
efficient method of using members of an array. 
2-14 
LITERALS 
Suppose that a program is required to set the contents of location Y equal 
to the contents of location X plus a constant. For illustrative purposes let 
the constant have the value 22.6. The program could be written, 
CLA 
X 
FAD 
CON1 
STO 
Y 
CON1 
DEC 
22.6 
This is simple enough except that in large programs it is tedious to have to 
think of a name for every constant and to have to put a DEC card at the 
end of the program. The assembler provides the alternative method of 
writing the program : 
CLA 
X 
FAD 
=22.6 
STO 
Y 
The symbol =22.6 is an example of a literal. The assembler stores the num-
ber 22.6 in some location at the end of the program and it places the 
address of this constant in the address part of the FAD instruction. Any 
address or decrement can contain a literal. Decimal literals are written as 
an equals sign followed by the number. Floating-point constants should 
contain a decimal point. The absence of a point signifies an integer con-
stant, as for example 
MPY 
= - 3 
An octal literal is written as = 0 followed by the constant. An Hollerith 
literal is =H followed by six characters: any or all of these characters 
may be blanks. 
CLA 
-HPQ21 
has the same meaning as 
CLA 
CON2 
CON2 
BCD 
1PQ21 

2 - 1 5 
S U M M A R Y 
71 
All literals are placed in an area called the literal pool. The compiler 
ensures that literals are not duplicated. If =22.6 appears at several places 
in a program then only one literal 22.6 goes in the literal pool. The literal 
pool is usually placed at the end of the program. 
2-15 
SUMMARY 
There is a class of computing machines with the following properties. The 
machines have a memory. The contents of the memory can be represented 
in the binary notation, or they can be represented in the equivalent octal 
notation. The memory is divided into words. A word consists of 36 bits in 
the 7090. In some recent machines, 60- or 64-bit words are standard. A 
word can represent an integer, a floating-point number, a string of charac-
ters, or one (or more) instructions. On the machine that we have described, 
an instruction usually consists of three parts; namely the order code, the 
index part, and the address part. The address specifies a word in the 
memory; an address of 15 bits suffices to specify any one of the 32768 words 
in the store of the 7090. Each index register holds 15 bits. 
A symbolic instruction is a convenient method of representing 
machine instructions. The symbolic instruction cannot be obeyed by the 
machine, but the translation from the symbolic instruction to the binary 
machine instruction is quite straightforward. In addition to the memory, the 
machine has some special registers. These are the accumulator, the multi-
plier quotient register, the control register, and the index registers. The 7090 
has three index registers. We explained a notation by which we could 
describe machine instructions. The only unusual point about this notation 
was in the description of a location. A symbol such as X was used to denote 
an address; the symbol m(X) was used to denote the number that is 
contained in the location having the address X. The arithmetic unit can 
manipulate either integers or floating-point numbers. The floating-point 
representation is invaluable because it allows numbers of vastly different 
magnitudes to be used. 
A machine has a limited repertoire on instructions. All calculations 
have to be broken down into a series of small steps before they can be 
obeyed by the machine. The machine itself can take a program written in a 
compiler language such as Fortran ; it can operate on the program until it 
has broken it down into machine language statements, and then it can 
obey these statements. For most purposes, it is possible to communicate 
with the machine in compiler language. A fluency in symbolic language is 
not necessary, but a basic understanding of machine language is necessary 
in order to fully appreciate the compiler language. A detailed list of 
instructions for the IBM 7090 is given in Table 2.4. 
Each instruction contains 36 bits. Most instructions have the 
form: instruction part 18 bits, index part 3 bits, address part 15 bits. There 

72 
2 MACHINE LANGUAGE AND ASSEMBLY 
LANGUAGE 
TABLE 2-4 
SYMBOLIC and MACHINE INSTRUCTIONS for the IBM 7090 
0361 
0400 
0401 
0767 
4320 
0320 
0771 
4774 
0774 
4500 
0340 
ACL 
ADD 
ADM 
ALS 
ANA 
ANS 
ARS 
AXC 
AXT 
CAL 
CAS 
0760.2 
0500 
0502 
0760.6 
0221 
0322 
0300 
0241 
0260 
0302 
0000 
0535 
4340 
CHS 
CLA 
CLS 
COM 
DVP 
ERA 
FAD 
FDP 
FMP 
FSB 
HTR 
LAC 
LAS 
4535 
0560 
4763 
4765 
0763 
0765 
0534 
4534 
4200 
0761 
4520 
4501 
4602 
0737 
LDC 
LDO 
LGL 
LGR 
LLS 
LRS 
LXA 
LXD 
MPY 
NOP 
NZT 
ORA 
ORS 
PAC 
ADD AND CARRY LOGICAL 
ADD 
ADD MAGNITUDE 
ACCUMULATOR LEFT SHIFT 
AND TO ACCUMULATOR 
AND TO STORAGE 
ACCUMULATOR RIGHT SHIFT 
ADDRESS TO INDEX COMPLEMENTED 
ADDRESS TO INDEX TRUE 
CLEAR AND ADD LOGICAL 
COMPARE ACCUMULATOR WITH STORE 
CHANGE SIGN 
CLEAR ACCUMULATOR AND ADD 
CLEAR ACCUMULATOR AND SUBTRACT 
COMPLEMENT 
DIVIDE AND PROCEED 
EXCLUSIVE OR TO ACCUMULATOR 
FLOATING POINT ADD 
FLOATING POINT DIVIDE OR PROCEED 
FLOATING POINT MULTIPLY 
FLOATING POINT SUBTRACT 
HALT AND TRANSFER 
LOAD COMPLEMENT OF ADDRESS 
LOGICAL COMPARE ACCUMULATOR AND STORE 
LOAD COMPLEMENT OF DECREMENT 
LOAD MO 
LOGICAL LEFT SHIFT» SEE NOTE 1 
LOGICAL RIGHT SHIFT 
LONG 
LEFT SHIFT. SEE NOTE 1 
LONG 
RIGHT SHIFT 
LOAD INDEX FROM ADDRESS 
LOAD INDEX FROM DECREMENT 
MULTIPLY INTEGERS 
NO OPERATION 
NONE ZERO TEST 
OR TO ACCUMULATOR 
OR TO STORAGE 
PLACE COMPLEMENT OF A IN INDEX 
G»G+M(N) 
A»A+M(N) 
A»A+ABS(M(N>) 
G«G*2**N 
G*G.AND.M(N) 
M(N)»G.AND.M(N) 
G»G/2«*N 
II«.NOT.N 
I1«N 
G»M(Nl 
IF A.GT.M(N)»C«C+1 
IF A.EQ.M(N).C=C+2 
IF A.LT.M(N)»C»C+3 
A=-A 
A«M(N) 
A«-M(N) 
G-.NOT.G 
0»AO/M(N) 
G«(G.AND..NOT.M(N)) 
•OR.(.NOT.G.AND.M(N)) 
A-A-t-M(N) 
0»A/M(N) 
A«0»M(N) 
A«A-M(N) 
PAUSE 
Il«.NOT.M(N)tt 
IF G.GT.M(N).C»C+1 
IF G.EO.M(N).C«C+2 
IF G.LT.M(N)»C*C+3 
Il-.NOT.MtN)^ 
0»M(N) 
GQ»GO»2*«N 
GQ«GQ/2»*N 
GO«GO»2**N 
GQ«GQ/2**N 
11 -M ( N ) a 
Ι1«Μ(Ν)α 
AO«M(N)*Q 
IF M(N).NE.0» C*C+2 
G-G.OR.M(N) 
M(N)«M(N».OR.G 
II·· NOT. A,. 

2 · 15 SUMMARY 
73 
0734 
4737 
4734 
0754 
4754 
4773 
4400 
4620 
0602 
4760·3 
0760.3 
0621 
0622 
0601 
0630 
4600 
5000 
0600 
0402 
0634 
4634 
4120 
0120 
0162 
0020 
0074 
0021 
0100 
0131 
4131 
0520 
PAX 
PDC 
PDX 
PXA 
PXD 
RQL 
SBM 
SLO 
SLW 
SSM 
SSP 
STA 
STD 
STO 
STP 
STO 
STR 
STZ 
SUB 
SXA 
SXO 
TMI 
TPL 
TOP 
TRA 
TSX 
TTR 
TZE 
XCA 
XCA 
ZET 
INSTRUCTIONS 
3000 
1000 
7000 
2000 
6000 
FOR TXHi 
TXH 
TXI 
TXL 
TIX 
TNX 
. TXLi 
PLACE A IN INDEX 
II*AU 
PLACE COMPLEMENT OF DECREMENT PART OF A IN I Il*.NOT.Ad 
PLACE DECREMENT PART OF A IN INDEX REGISTER I1«AH 
PLACE INDEX IN A 
PLACE INDEX IN DECREMENT PART OF A 
ROTATE O LEFTt SEE NOTE 3 
SUBTRACT MAGNITUDE 
STORE LEFT HALF OF 0 
STORE LOGICAL WORD 
SET SIGM MINUS 
SET SIGN PLUS 
STORE ADDRESS 
STORE DECREMENT 
STORE 
STORE PREFIX 
STORE 0 
STORE LOCATION AND TRAP 
STORE ZERO 
SUBTRACT 
STORE INDEX IN ADDRESS 
STORE INDEX IN DECREMENT 
TRANSFER ON MINUS 
TRANSFER ON PLUS 
TRANSFER ON O POSITIVE 
TRANSFER 
TRANSFER SAVING INDEX 
TRAP TRANSFER. SEE NOTE 2 
TRANSFER ON ZERO 
EXCHANGE ACCUMULATOR 
EXCHANGE LOGICAL ACCUMULATOR 
ZERO TEST 
A M I 
A ^ U 
Q»0»2*#N CIRCULAR 
A«A-ABS(M(N)> 
M(N); »0„ 
M(N)-G 
A»-ABS(A) 
A«ABS(A) 
M(N) «A,, 
M(N> »A 
M(N)-A 
M(N)»PREFIX OF A 
Μ(Ν)·0 
M(0>«**1. C»2 
M(N)«0 
AsA-M(N) 
M ( NI * I 1 
IF A.LE.-O.C-N 
IF A.GE.+O. C«N 
IF Q.GE.+O. C«N 
C«N 
II«.NOT.·· C«N 
C«N 
IF A»«-0 OR A « - 0 . C«N 
SWOP A AND 0 
SWOP G AND 0 
IF M(N)«0. C-C + 2 
OTHERWISE C-C+l 
WHICH HAVE A DECREMENT. 
D DENOTES THE DECREMENT 
TRANSFER ON INDEX HIGH 
IF U . G E . D · C»N 
TRANSFER WITH INDEX INCREMENTED 
Il-IH-D . C«N 
TRANSFER ON INDEX LCW 
IF Il.LE.D t C-N 
TRANSFER ON INDEX 
IF U . G T . D · 11*11-N 
TRANSFER ON NO INDEX 
IF Il.LE.C ♦ C-N 
OTHERWISE Il-Il-D 
> TIX AND TNX IF THE CONDITION IS NOT SATISFIED THEN C«C+1 
Note 1. The only difference between LLS and LGL, and between LRS and LGR, is 
the way in which the sign bits are treated. 
Note 2. The 7090 can operate in the trapping mode. In this mode all transfers, except 
TTR, are trapped. 
Note 3. Bits which are shifted out of the left-hand end are shifted in to the right-hand 
end. 
M ( N )j ■ 11 

74 
2 MACHINE 
LANGUAGE AND ASSEMBLY 
LANGUAGE 
are five instructions that have the form: instruction part 3 bits, decrement 
15 bits, index part 3 bits, address part 15 bits. There are a few instructions 
that have no address but that use the last 15 bits as part of the instruction. 
The following table lists the first four octal digits of all ordinary instruc-
tions: the other two octal digits of the instruction part are always 00. Those 
instructions such as CHS which use the last 15 bits of the word as part of 
the instruction are written thus 0760.2. Examples of complete instructions 
are 
ACL 
100,1 
is 
036100 1 00144 
CHS 
is 
076000 0 00002 
TXI 
100,1,7 
is 
100007 1 00144 
The comments use the notation explained in Sections 2.6 and 2.9. The 
restriction mentioned in Section 2.9 should be noted: The comments give a 
description that is accurate enough for most purposes but they cannot 
convey all the minutae of every instruction. In addition to the notation of 
Section 2.6 we use a subscript to indicate various parts of the word, as 
follows : 
3 bits 
15 bits 
3 bits 
15 bits 
« 
1 
> < 
Y 
> 
< 
d 
> 
< 
a 
> 
In the description we assume that the address part is N. The index part is 
assumed to be zero, except in index instructions. In the instructions that 
have a decrement we assume the decrement is D. 
ACL 
N 
LXA 
N,1 
TXI 
N,1,D 
are examples of these three types of instructions. In Table 2.4, 
A denotes the accumulator, 
G denotes the logical accumulator, 
Q denotes the multiplier-quotient register, 
M denotes the memory, 
C denotes the control register, 
N denotes the address part of the instruction, 
D denotes the decrement part of the instruction, 
11 denotes the index register used in the instruction. 
AND, OR, and NOT are 36-bit logical operations. 

P R O B L E M S 
75 
PROBLEMS 
1 ■ Convert the following decimal numbers to octal: 32, 100, 1000, 512, 
32000, 1023, 1029, 4203. 
2 ■ Convert the following octal numbers to decimal: 32, 100, 1000, 512, 
32000, 77777, 1 000 000 000 000. 
3 ■ Find the floating-point representation of 128., 256., 1.25, 125., —125. 
Write down the floating-point representation of the smallest integer 
that cannot be represented exactly as a floating-point number. 
4 ■ Using Table 2.4, write down the symbolic code for the following pro-
grams. Also write a Fortran program that will accomplish the same 
result. 
Program (a) 
a = m(X) 
a = a + m(Y) 
m(Z) = a 
a = a — m(C) 
m(B) = a 
Program (b) 
i l = 0 
a = m{X) 
B. If a = 0, go to C. 
a = a/2 
i l = / l + l 
go to B. 
C. m(I) = il 
Program (c) 
/1 = 1 
a = m(X) 
D. If/1 > 9, go to B. 
i\ =/l + 1 
il = m(C.) 
il = /2-f-l 
m(C.) = il 
C. a = a + m{X) 
go to D. 
B. m(Z) = a 
5 ■ Translate the following Fortran statements into symbolic language 
statements 
(a) X = A*(B + C) 
(b) X = A*B + C 
(c) 
l = J + K 
The whole subject of Fortran into machine language will be discussed 
in Chapter 4. 
6 ■ Write a program to solve Problem 2. Assume that the octal numbers 
are punched on cards with one number per card. Put the l's digit in 
column 20, the 8's digits in column 19, and so on. Use two different 
methods. In method (a) begin with 
DIMENSION L(20) 
READ 500,L 
500 
FORMAT(20I1) 
in method (b) begin with 
READ 510,N 
510 
FORMAT(O20) 

76 
2 MACHINE LANGUAGE AND ASSEMBLY 
LANGUAGE 
7 ■ Write a program to solve Problem 3. 
8 "The machine does floating-point addition in the following way: It 
finds the number with the largest characteristic. It takes the other 
number and increases its characteristic (if necessary) until the two 
numbers have the same characteristic. If the characteristic is increased 
by n, then the fraction is shifted n places to the right. The two frac-
tional parts are now added. Suppose the machine is required to add 
0.25 to 0.125. The octal representation of these numbers is 
177400000000 and 176400000000. The second number is put in the 
form 177200000000 and then adding the fractional parts the result is 
177600000000 which is 0.375. If the addition of the two fractional parts 
gives a result that is less than one half or greater than or equal to one, 
then the machine automatically shifts the result and adjusts the 
characteristic. Show that if B < A/2.0**26, then adding B to A will 
leave A unchanged. What is the result in floating-point arithmetic of 
the following? 
(a) 1.0 + 0.7E-12 
(b) (1.0 + 0.7E-12) - (1.0 + 0.5E-12) 
(c) (1.0 - 1.0) + (0.7E-12 - 0.5E-12) 
(d) (1.25E24 x 0.28E24)/0.25E24 
9 ■ Assemble the following program. Do the assembly operation manually, 
it is not necessary to use a computer. 
ORG 
100 
AXT 
0,4 
CLA 
SUM 
B 
FAD 
X,4 
TXI 
* +1,4,1 
TXL 
B,4,10 
STO 
SUM 
HTR 
SUM 
BSS 
1 
BSS 
10 
X 
BSS 
1 
10 ■ In Figure 2.5, what is the value of LV; what is the address of LV? 
What would be the effect of LXA LV,4? What would be the effect of 
AXT LV,4? 
11 ■ What is the difference between an instruction and a pseudo-instruc-
tion? Is there an analogous difference between certain types of 
Fortran statements? 
12 ■ What is the final value of I, J, K in the following program? 
CLA 
N 
ALS 
4 
STO 
I 
CLA 
N 

P R O B L E M S 
77 
COM 
STO 
J 
ORA 
=34 
STO 
K 
HTR 
N 
DEC 
100 
13 ■ What is a literal? In compiling a Fortran program, what parts of what 
statements would be compiled as literals ? 
14 ■ What is an index register? Which of the following Fortran statements 
would cause an index register to be used ? 
(a) A=B + C 
(b) l=J*K 
(c) SUM = SUM+X(I) 
15" Does the compiler that you are using produce a print out of the 
assembly-language version after a Fortran compilation? If so, get the 
assembly-language version of the following program. 
DIMENSION X(20) 
I = 1 0 
Y=X(I) 
Z=X(10) 
Y=(Y+Z)/(X(1)+X(9))*X(I) 
END 
16 ■ Write an assembly-language program to set SUM equal to the contents 
of location X times the contents of location Y, plus the contents of 
location X + 1 times the contents of location 7 + 1 plus... the con-
tents of location X + 100 times the contents of location Y + 100. 
17 ■ Write an assembly-language program which does the same as the 
following Fortran program. 
XMAX=0. 
DO 100 1 = 1,10 
IF (X(I)-XMAX) 100, 100 101 
101 
XMAX=X(I) 
100 
CONTINUE 
Assume that X(l), X(2), X(3)...X(10) are stored in locations X, X - 1 , 
X-2, ..., X-9. 

3·1 
INTROOUCTION 
3 
Machine instructions are interpreted and 
executed by complex electronic circuits. 
These complex circuits are formed from 
many thousands of simple basic circuits. 
The basic circuits are capable of perform-
ing elementary logical operations such as 
forming the logical product of two binary 
digits. The machine-language instructions 
stand half-way between the complicated 
algorithms that the programmer wishes to 
carry out and the elementary operations 
that the basic circuits can perform. Mach-
ine instructions are the interface between 
the programmer and the hardware. The 
machine designer tries to provide instruc-
tions that will minimize the cost of the 
hardware and maximize the power and 
reliability of the machine. The precise set 
of instructions varies according to the type 
of job for which the machine is designed. 
The IBM 7090, for example, was designed 
for scientific calculations. It has floating-
point instructions but is deficient in byte-
type operations. The IBM 1401 was de-
signed for 
manipulating 
alphanumeric 
data. It has no floating-point operations 
but it does have an effective set of byte 
operations. The 1401 can carry out floating-
point operations and the 7090 can do byte 
manipulations but each operation requires 
several machine instructions with a conse-
quent loss of efficiency. 
At one time the design of machines 
was influenced by the available compo-
nents. As one example of this, in the 1950's 
the cheaper computers used a magnetic 
drum instead of a core memory. The pro-
gramming of a drum machine like the IBM 
650 was quite different from the program-
ming of a machine with a core memory. 
The cost of core memories eventually 
decreased to the point where they could be 
used economically on all machines. Almost 
CENTRAL 
PROCESSING 
UNITS 
78 

3 · 2 THE CDC 1604 AND CDC 3600 
79 
all machines now use core memories; the expensive machines have large 
fast memories and the cheaper machines have slower smaller core memo-
ries. The design differences between the large and the small machines have 
tended to decrease in many other respects. At one time the design of the 
machine rested with the design engineer and each machine tended to be 
quite different from its predecessors. With the rapid increase in the com-
plexity of software and the great expansion in the use of machines, 
both manufacturers and customers began to realize that the cost of the 
hardware does not represent the full cost of the computer. An expensive 
old-fashioned machine with adequate software and a large number of 
existing programs is of far greater use than a completely new piece of 
hardware that has no software. The idea of compatible machines was 
developed. A series of machines differ in price, power, hardware, but they 
have the same machine language and the same software. 
There is no one machine design that is better than all others. In 
this chapter we will discuss a variety of different designs. On a superficial 
level these machines are quite different from the machine that we have 
already studied in detail; however, with the knowledge of the IBM 7090 
gained the last chapter, the short descriptions of the new machines can be 
readily appreciated. 
3"2 THE CDC 1604 and CDC 3600 
The CDC 1604 is designed for the same sort of market as the IBM 7090. 
Many of the major features of the two machines are similar. The 1604 has a 
core memory of 32,768 words. It has an accumulator and an MQ register, 
index registers, and a control register. Numbers can be represented as 
binary integers or as binary floating-point numbers. Alphanumeric infor-
mation can be represented by six-bit binary numbers; the particular scheme 
used by the 1604 is only slightly different from that shown in Table 2.2. The 
machine instructions cover integer arithmetic, floating-point arithmetic, 
logical, shift, indexing, input-output, and control operations. Machine 
instructions contain three parts : the part that specifies the instruction, the 
part that specifies the index, and the address part. The 1604 has an 
assembler called Codap which translates symbolic instructions into 
machine language. 
The design of the 1604 differs from that of the 7090 in the following 
details. Each word contains 48 bits. The accumulator and mq registers and 
all the words in memory are 48 bits long. As a consequence of this, integers 
range from 0 to 247 — 1. Floating-point numbers are similar in structure to 
those of the 7090 but the characteristic and the fraction contain a greater 
number of bits. The first bit indicates the sign of the number. The second 
through the twelfth bits contain the characteristic. The characteristic is 
20008 plus the binary exponent. The thirteenth through the 48th bits 

80 
3 CENTRAL PROCESSING 
UNITS 
contain the fraction. As on the 7090, the fraction is normalized when it is 
greater than or equal to 0.5 and less than 1.0. The comparison given below 
illustrates the similarity between the two schemes. 
Decimal number 
7090 floating point 1604 floating point 
1.0 
201400000000 
2001400000000000 
1024.0 
213400000000 
2013400000000000 
100.0 
207620000000 
2007620000000000 
The exponent in the 1604 floating-point number can range up to 17778 
which is 102310. The fractional part has 36 bits; this is 9 binary digits, 
or 3 decimal digits, more accurate than the 7090 representation. There 
are many calculations in which the difference between the 8-digit and the 
11-digit accuracy can have an appreciable effect on the result. 
The memory has 32,768 words and a 15-bit address is adequate. 
The 1604 has six index registers so that the index part of the instruction 
needs three bits. It would be wasteful to use the remaining 30 bits of the 
word to specify the operation so each word is made to contain two complete 
instructions. The first part of an instruction has 6 bits, the second has 3 
bits, the address part has 15 bits, making a total of 24 bits or one-half 
word. To give an example, the machine language instruction for ADD is 
148, SUB is 158. The instructions 
ADD 
100 
would assemble as 
14 0 00144 
SUB 
512 
15 0 01000 
and the two instructions would fit in one machine word as 1400014415001000. 
After each normal instruction has been obeyed, the control counter is 
increased by one half, thus the machine obeys the instructions in successive 
half words. The symbolic instructions have different mnenomics from those 
of the 7090, but in many cases there is a close correspondence between the 
operations which are actually performed. The instructions 
7090 
CLA 
STO 
ADD 
SUB 
FAD 
FMP 
LDQ 
AXT 
TRA 
1604 
LDA 
STA 
ADD 
SUB 
FAD 
FMU 
LDQ 
ENI 
SLJ 
carry out similar operations on their respective machines. Since the instruc-
tion code on the 1604 is restricted to 6 bits, there can only be approximately 
64 different instructions. Most instructions use the second part of the 
instruction to indicate an index register but the accumulator jump instruc-
tions use it to modify the actual function. 
The 1604 
AJP 
X 
corresponds to the 7090 
TZB X 
AJP 
X,1 
TNZ X 
AJP 
X,2 
TPL 
X 
AJP 
X,3 
TMI 
X 

3 · 2 THE CDC 1604 AND CDC 3600 
81 
There is no 1604 instruction corresponding to the indexed jump instruction 
such as TZE X,2. 
The program that was given in Figure 2.3 can be coded for the 
1604 as 
octal location 
100 
101 
102 
2000 
octal instructions 
12 0 02000 
22 2 00102 
15 0 02000 
15 0 02000 
20 0 02001 
7777777777777754 
symbolic instructions 
PLUS 
I 
ORG 
LDA 
AJP 
SUB 
SUB 
STA 
ORG 
DEC 
BSS 
64 
I 
PLUS,2 
I 
I 
1 + 1 
1024 
- 2 1 
1 
The representation of negative numbers will be discussed in the section on 
the complement notation. An address is always a whole number. AJP 
PLUS,2 translates into 22 2 00102; this causes a jump (if the accumulator 
is positive) to the instruction in the first half of location 102. It is not 
possible to jump to an instruction in the second half of the word. This 
restriction does not cause any difficulty in programming because a dummy 
instruction can be inserted. Suppose we wish to write a program that will 
set J = I if / is greater than zero and will set / equal to zero otherwise. 
octal location 
100 
101 
102 
2000 
2002 
octal instructions 
12 0 02000 
22 2 00102 
12 0 02002 
50 0 00000 
symbolic instructions 
20 0 02001 
NONZ 
0000000000000143 
0000000000000000 
I 
J 
NZ 
ORG 
LDA 
AJP 
LDA 
NOP 
STA 
ORG 
DEC 
BSS 
DEC 
64 
I 
NONZ,2 
NZ 
J 
1024 
99 
1 
0 
The NOP instruction does nothing but fill in half a word so that the STA J 
comes in the first half of a word. In practice, it is not necessary to put the 
NOP in explicitly; the assembler will supply a NOP, if necessary, whenever 
it encounters a nonblank label field. 
The 1604 has six index registers, numbered 1 through 6. The 
operation of these registers is additive. If il contains 54 then LDA 200,2 
has the same effect as LDA 254. It will be remembered that the 7090 
instruction CLA 200,2 had the same effect as CLA 146. The 1604 conven-
tion is more convenient and it is the one used on most machines. A complete 

82 
3 CENTRAL PROCESSING 
UNITS 
list of 1604 instructions is given in Table 3.1. The table uses the notation 
described in sections 2.6 and 2.9. On the 1604 there is no reason to dis-
tinguish between a logical accumulator and an arithmetic accumulator. The 
meaning of the return jump instructions will be explained when we come to 
discuss subroutines. 
Section 2.13 contained a simple program for adding the contents 
of successive locations. The corresponding 1604 program is 
octal 
location 
octal instructions 
symbolic instructions 
100 
101 
102 
103 
1000 
1004 
50 6 00001 
12 0 01000 
14 6 01000 
50 0 00000 
54 6 00003 
75 0 00101 
20 0 01004 
0000000000000023 
LOOP 
LV 
LSUM 
ORG 
ENI 
LDA 
ADD 
NOP 
ISK 
SLJ 
STA 
ORG 
DEC 
BSS 
64 
1,6 
LV 
LV,6 
3,6 
LOOP 
LSUM 
512 
21,98721,56,2781 
1 
The index skip operation ISK is designed for this type of loop. It increases 
the index by one and tests for the end of the loop in one operation. If the 
loop is not finished, then control goes to the instruction in the second half 
of the word, namely, the SLJ LOOP. If the test indicates that the loop is 
finished, then control goes to the instruction in the next location, namely, 
the STA LSUM. 
Learning to write programs for the 1604 would take several weeks 
of study. Learning the principles of programming and learning to decipher 
the symbolic output of a compiler is a much simpler matter. With the little 
that has already been said, and with the aid of Table 3.1 it should be 
possible to follow simple programs such as the one given above. When it 
comes to using the output from a compiler, it will be found that a great 
amount of information can be extracted simply by looking at the symbolic 
addresses that are used. 
The relation between the CDC 3600 and the CDC 1604 is some-
what similar to the relation between the IBM 7090 and the IBM 704. The 
CDC 3600 has the same word length, the same number of index registers, 
and uses the same method of doing arithmetic as the 1604. The 1604 has 
64 different instructions numbered 00 through 77 octal. The instructions 
with order code 01 through 61, 64 through 73, and 75 and 76 are identical 
in the 1604 and 3600. Programs that do not use instructions 00, 62, 63, 74, 
or 77 can be run on either machine. The major differences in the two 
machines are (1) the 3600 is about four times faster than the 1604; (2) the 

3 - 2 THE CDC 1604 AND CDC 3600 
83 
input-output capability of the 3600 is superior to the 1604; (3) the 3600 can 
have up to 262,144 words of memory. 
The address part of a 3600 instruction contains 15 bits. This is not 
sufficient to reference the 218 words of memory. The memory is divided 
into blocks of 32,768 words, which are referred to as memory banks. A 
CDC 3600 may have one or more banks. The machine has two special 
3-bit registers called the instruction bank register and the operand bank 
register. It has instructions that set the contents of these registers. Once a 
particular instruction bank is selected, instructions are chosen from this 
bank until a change bank instruction is given. An instruction like 
SLJ 
100 
means jump to location 100 in the current instruction bank. Once a 
particular operand bank is selected, an instruction like 
STA 
200 
means store the contents of the accumulator in location 200 of the current 
operand bank. Some IBM 7090's have more than 32,768 words of memory. 
These machines are also equipped with bank registers. 
The instruction codes 00, 62, 63, 74, and 77 on the 3600 provide 
instructions that were not available on the 1604. There are floating-point 
double precision operations. There are interregister instructions that do 
operations such as 
a=il 
+i2 
in one instruction and without having to store intermediate results in the 
memory. There are instructions that operate on a byte. There are instruc-
tions for setting the bank registers and for setting and decoding other 
registers peculiar to the 3600. Since the 3600 has only five operation codes 
that are different from those of the 1604, it requires some special techniques 
to specify the large number of new instructions. One of the techniques 
is to allow some of the instructions to occupy 48 bits. All 1604 instructions 
are 24 bits long. Some of the instructions peculiar to the 3600 are 48 
bits long. 
The advantage of having machines like the 7090 and the 3600, 
which are compatible with other machines, is that existing programs can 
be run on the new machine. The 00 and 77 codes are not legal on the 
1604, the 62, 63, and 74 codes refer to input-output; hence, any program 
that does not do input-output can be run on either a 1604 or a 3600. All 
Fortran programs are in this class. Fortran I/O is done in separate sub-
routines which are on the library tape. Providing that the library tape is 
suitably changed, then Fortran programs will run on either machine. 

84 
3 CENTRAL PROCESSING UNITS 
TABLE 3-1 
CDC 1604 MACHINE INSTRUCTIONS 
OCTAL 
00 
01 
02 
03 
04 
05 
06 
07 
10 
11 
12 
13 
14 
15 
16 
17 
20 
21 
22 
23 
24 
25 
26 
27 
30 
31 
32 
33 
34 
35 
36 
SYMBOLIC 
ZRO 
ARS 
ORS 
LRS 
ENO 
ALS 
OLS 
LLS 
ENA 
INA 
LDA 
LAC 
ADO 
SUB 
LDO 
LOC 
STA 
STO 
AJP 
QJP 
MUI 
DVI 
MUF 
DVF 
FAO 
FSB 
FMU 
FDV 
SCA 
SCO 
SSK 
ZERO 
A RIGHT SHIFT 
0 RIGHT SHIFT 
LONG RIGHT SHIFT 
ENTER 0 
A LEFT SHIFT 
0 LEFT SHIFT 
LONG LEFT SHIFT 
ENTER A 
INCREASE A 
LOAO A 
LOAD A COMPLEMENTED 
ADD 
SUBTRACT 
LOAD 0 
LOAD 0 COMPLEMENTED 
STORE A 
STORE 0 
A JUMP 
0 JUMP 
MULTIPLY INTEGER 
DIVIDE INTEGER 
MULTIPLY FRACTIONAL 
DIVIDE FRACTIONAL 
FLOATING ADD 
FLOATING SUBTRACT 
FLOATING MULTIPLY 
FLOATING DIVIDE 
SCALE A 
SCALE 0 
STORAGE SKIP 
OPERATION 
ILLEGAL 
A * A/2««N 
Q -0/2··Ν 
AO « AQ/2**N 
0 « N 
A « Α»2··Ν. CIRCULAR 
Q . 0»2*»Nt CIRCULAR 
AO ■ ΑΟ·2·*Ν. CIRCULAR 
A « N 
A ■ A+N 
A * M(N) 
A * -M(N) 
A » A*M(N) 
A « A-M(N) 
0 * M(N) 
0 ■ -M(N) 
M(N) * A 
MCN) * 0 
READ 0 FOR A IN NOTE 
QA « A*M<N) 
A * AO/M(N) 
AO - AO »M (N) 
A « AO/M(N) 
A « A+M(N) 
A - A-M(N) 
A * A*M(N) 
A ■ A/M(N) 
IF M(N).LE.0. C»INF<C>*1. 
SEE NOTF 
1*2 
1 »2 
1.2 
4 
4 
5 
9 
5.9 
6 
6 
STORAGE SHIFT 
40 
41 
42 
SST 
SCL 
SCM 
SELECTIVE SET 
SELECTIVE CLEAR 
SELECTIVE COMPLEMENT 
SSU 
SELECTIVE SUBSTITUTE 
LDL 
LOAD LOGICAL 
ADL 
ADD LOGICAL 
OTHERWISE C « I N T F I O + 1/2 
DO AN SSK AND DO M(N) » 
M(N)»2 CIRCULAR 
A - A.OR.M(N) 
A - A.AND.NOT.M(N) 
A ■ (Α·ΑΝ0·ΝΟΤ·Μ(Νη 
•OR.(NOT.A.AND.M(N)) 
A * <A.AN0.NOT.Q).OR.(M(N).AND.Q) 
A » Q.AND.M(N) 
A » A«-Q.AND.M<N> 
37 
SSH 
43 
44 
45 
7 
1 
1 
1 
3 
3 
3 

3 · 2 THE CDC 1604 AND CDC 3600 
85 
46 
47 
50 
51 
52 
53 
54 
55 
56 
57 
60 
61 
62 
63 
64 
65 
66 
67 
70 
71 
72 
73 
74 
75 
76 
77 
SBL 
STL 
ENI 
INI 
LIU 
LIL 
ISK 
U P 
SIU 
SIL 
SAU 
SAL 
INT 
OUT 
EOS 
THS 
MEQ 
MTH 
RAO 
RSB 
RAO 
RSO 
EXF 
SLJ 
SLS 
SEV 
SUBTRACT LOGICAL 
STORE LOGICAL 
ENTER INDEX 
INCREASE INDEX 
LOAD INDEX UPPER 
LOAD INDEX LOWER 
INDEX SKIP 
INDEX JUMP 
STORE INDEX UPPER 
STORE INDEX LOWER 
STORE ADDRESS UPPER 
STORE ADDRESS LOWER 
INPUT 
OUTPUT 
EQUALITY SEARCH 
THRESHOLD SEARCH 
MASKED (OS 
MASKED THS 
REPLACE ADD 
REPLACE SUBTRACT 
REPLACE ADD ONE 
REPLACE SUBTRACT ONE 
EXTERNAL FUNCTION 
SELECTIVE JUMP 
SELECTIVE STOP 
ILLEGAL 
A * A-Q.AND.M(N) 
M(N) · A.AND.Q 
11 « N 
11 ■ Il+N 
11 « MCN-M 
11 - M(N-) 
IF U.NE.N» Il-M + 1 AND 
C-INTFlO+1/2. OTHERWISE 
11 · 0«C «INTF<C>+1 
IF II.NE.Ot Il-Il-l AND 
C * N 
OTHERWISE 
C - INTFCCH-1/2 
ADDRESS OF M (NO « 11 
ADDRESS OF HIN-I - 11 
ADDRESS OF MIN+) ■ LOW 
ORDER 15 BITS OF A 
ADDRESS OF M(N-) « LOW ORDER 
15 BITS OF A 
A * M(N) « A+M(N) 
A « M(N) * A-M(N) 
A « M(N) » M(N)+1 
A ■ M(N) « M(N)-1 
JUMP 
STOP 
6»7 
6t7 
6 
6 
6 
6 
6»7 
8 
7 
Note 1. In the shift operations the notation A=A/2**N is meant to imply integer 
arithmetic. 
Note 2. Bits which shift out of the left-hand end are shifted back in to the right-hand 
end. 
Note 3. N is a 15-bit number. A 48-bit number is formed from N by repeating the 
15th bit of N in bits 15 through 48. 
Note 4. The index portion shows which condition will be tested. An index of O gives a 
jump if A is zero. Similarly 1,2,3 cause a jump if A is non-zero, positive, negative. 
Note 5. Quotient is in A, remainder is in Q. 
Note 6. This instruction does not occur in Fortran programs, see 1604 manual for 
details. 
Note 7. These instructions are legitimate on the CDC 3600, but their operation on the 
3600 differs from that on the 1604. 
Note 8. If index portion is zero than C = N . If index portion is 4 then M(N — )=C-f-1 
a n d C = N + l / 2 . 
Note 9. AQ and M(N) are treated as binary fractions with the point to right of sign 
bit. 

86 
3 CENTRAL PROCESSING 
UNITS 
3-3 
COMPLEMENT NOTATION 
The idea of a complement was introduced in Section 2.9. The description 
given at that time referred to only one of the many possible complements. If 
N is any decimal integer containing n digits, then: 
the 10's complement of N = lO" - N 
the 9's complement of N = 10" - N - 1 
If N is 12345, then the 10's complement is 87655 and the 9's complement is 
87654. When dealing with binary integers, the complement is formed by 
using a power of 2. If M is a binary integer with m bits, then 
the 2's complement of M = 2m — M 
the l's complement of M = 2m — M — 1 
The reason for having several different methods of complementing is that 
there are several ways of designing the hardware for doing the operations 
involved. One designer might prefer circuits that adapt themselves to a 
2's complement notation and another might prefer l's complement type 
circuits. When manipulating binary numbers, there is a simple way of 
forming the complement. The l's complement of a 15-bit integer such as 
100011010111110 is 011100101000001 and it is obtained by replacing each 
1 bit by a 0 and each 0 by a 1. The complement discussed in Section 2.9 was 
in fact the l's complement. The octal representation of 100011010111110 
is 43276 and 011100101000001 is 34501 so that the l's complement can be 
found in octal by replacing 0 by 7,1 by 6, 2 by 5, 3 by 4 and vice versa. The 
2's complement can be found by finding the l's complement and adding 1. 
One method of representing negative numbers has already been 
discussed: The IBM 7090 uses one bit to indicate the sign. There is an 
alternative system in which the negative of the number is represented by 
the complement. The 7090 uses the 2's complement notation for the 15-bit 
integers which are carried in the index registers; thus — 1 is represented by 
777778, —2 is represented by 777768. The addition and subtraction 
operations work in the normal way except that the registers only hold 15 
bits so that any carry into the 16th place is lost. Consider adding the 
number 7 to the number —2; this is done as 7 + 77776 which is 100005, but 
the last digit is lost so that the correct result of 5 is obtained. The sum of 
- 2 and - 5 would be done as 77776 + 77773 which is 177771, but the last 
digit is lost so the result is 77771 which is the representation of —7. If an 
index register contains the number 77776, is this to be regarded as —2 or 
+ 32766? The answer is that it does not matter, since - 2 =32766 modulo 
32768. When the number is used in an indexing operation, then all addresses 
must lie between 0 and 32767; the dropping of the 16th place ensures that 
the address will lie in the correct range. 
In the l's complement representation, addition, and subtraction 

3 · 3 C O M P L E M E N T 
NOTATION 
87 
follow the rule, if the result exceeds 2m then subtract 2m and add one to the 
result. As an example, adding 7 to —2 in the l's complement notation is 
done as 7 + 77775 which is 100004; we now subtract 100000 and add 1 with 
the result of 5. This subtraction of 100000 and the addition of 1 can be 
thought of taking the overflow bit from the 16th place and adding into the 
first place. The CDC 1604 uses the ones complement notation for the 
15-bit numbers in its index registers. For didactic reasons we have explained 
the complement notation in terms of 15-bit numbers but obviously it can be 
extended to any number of bits. The CDC 1604 uses the l's complement 
notation for 48-bit negative numbers which appear in the accumulator, 
in the MQ or in the memory; thus the following table illustrates the 
representation. 
n in decimal 
n as stored 
— n as stored 
in the memory 
in the memory 
0 
0000000000000000 
7777777777777777 
1 
0000000000000001 
7777777777777776 
100 
0000000000000144 
7777777777777633 
If the result of an addition or subtraction is greater than or equal to 
248 then the high-order bit is deleted and 1 is added to the result. One of 
the advantages to the programmer of complement notation can be seen 
from the following example. Consider the instructions, 
a = -5; 
m(I) = a 
M = m(I) 
If this example is coded on the 7090, then /4 is set equal to 5, because the 
accumulator contains 200000000005 and the low-order bits of 00005 go 
into i4. If the example is coded on the 1604, then 7777777777777772 goes 
into the accumulator and 77772 which is — 5 goes into the index register. 
When using the complement notation, there is no difficulty with changes of 
sign when a number is transferred from a 48-bit to a 15-bit register. The 
1604 also takes care of the converse operation by extending the sign of a 
15-bit number in certain cases. 
ENA 
N 
takes the 15-bit number in the address part of the instruction and puts it 
into the accumulator; if the 15th bit is a one, then the machine fills the 16th 
through 48th bits with ones. Thus 
ENI 
-2,1 

88 
3 CENTRAL PROCESSING UNITS 
TABLE 3-2 
OCTAL and DECIMAL REPRESENTATIONS of POWERS of TWO 
on the CDC 1604 
l./X 
20014 
20004 
17764 
17754 
17744 
17734 
17724 
17714 
17704 
17674 
17664 
17654 
17644 
17634 
17624 
17614 
17604 
17574 
17564 
17554 
17544 
17534 
17524 
17514 
17504 
17474 
17464 
17454 
17444 
17434 
17424 
17414 
17404 
17374 
17364 
17354 
17344 
17334 
17324 
X 
20014 
20024 
20034 
20044 
20054 
20064 
20074 
20104 
20114 
20124 
20134 
20144 
20154 
20164 
20174 
20204 
20214 
20224 
20234 
20244 
20254 
20264 
20274 
20304 
20314 
20324 
20334 
20344 
20354 
20364 
20374 
20404 
20414 
20424 
20434 
20444 
20454 
20464 
20474 
N 
0 
1 
2 
3 
4 
5 
6 
7 
6 
9 
10 
11 
12 
13 
14 
15 
16 
17 
18 
19 
20 
21 
22 
23 
24 
25 
26 
27 
28 
29 
30 
31 
32 
33 
34 
35 
36 
37 
38 
2··Ν OCTAL 
1 
2 
4 
10 
20 
40 
100 
200 
400 
1000 
2000 
4000 
10000 
20000 
40000 
100000 
200000 
400000 
1000000 
2000000 
4000000 
10000000 
20000000 
40000000 
100000000 
200000000 
400000000 
1000000000 
2000000000 
4000000000 
10000000000 
20000000000 
40000000000 
100000000000 
200000000000 
400000000000 
1000000000000 
2000000000000 
4000000000000 
2»·Ν DECIMAL 
1 
2 
4 
8 
16 
32 
64 
128 
256 
512 
1024 
2048 
4096 
8192 
16384 
32768 
65536 
131072 
262144 
524288 
1048576 
2097152 
4194304 
8388608 
16777216 
33554432 
67108864 
134217728 
268435456 
536870912 
1073741824 
2147483648 
4294967296 
8589934592 
17179869184 
34359738368 
68719476736 
137438953472 
274877906944 
2»«(-N) DECIMAL 
1.0000000E 00 
5.0000000E-01 
2·5ΟΟΟ0Ο0Ε-01 
1.2500000E-01 
6.2500OO0E-02 
3.125OO00E-C2 
1.5625000E-02 
7.8125000E-03 
3.9062500E-03 
1.9531250E-03 
9.7656250E-04 
4.8828125E-04 
2.4414063E-04 
1.2207031E-04 
6.1035156E-05 
3.0517578E-05 
1.5258789E-05 
7.6293945E-06 
3.8146973E-06 
1.9073486E-06 
9.5367432E-07 
4.7683716E-07 
2·3β41858Ε-07 
1.1920929E-07 
5.9604645E-08 
2.9802322E-08 
1.4901161E-08 
7.4505806E-09 
3·7252903Ε-09 
1.8626451E-09 
9.3132257E-10 
4·6566129Ε-10 
2.3283064E-10 
1.1641532E-10 
5.8207661E-11 
2.9103830E-11 
1.4551915E-11 
7.2759576E-12 
3.6379788E-12 

3 · 3 C O M P L E M E N T 
NOTATION 
89 
l./X 
X 
N 
2··Ν OCTAL 
2··Ν DECIMAL 
2··(-Ν) 
DECIMAL 
17314 
17304 
17274 
17264 
17254 
17244 
17234 
17224 
20504 
20514 
20524 
20534 
20544 
20554 
20564 
20574 
39 
40 
41 
42 
43 
44 
45 
46 
10000000000000 
20000000000000 
40000000000000 
100000000000000 
200000000000000 
400000000000000 
1000000000000000 
2000000000000000 
549755613888 
1099511627776 
2199023255552 
4398046511104 
8796093022208 
17592186044416 
35184372088832 
70368744177664 
1.8189894E-
9.0949470E-
4.5474735E-
2.2737368E-
-12 
-13 
-13 
-13 
1.1368684E-13 
5.6843419E-
2.8421709E-
-14 
-14 
1.4210855E-14 
X» FIRST FIVE OCTAL DIGITS OF FLOATING POINT REPRESENTATION 
EXAMPLE 256.0 ■ 2011400000000000 
1./256.0 « 1770400000000000 
sets /l equal to —2 (which is 77775) and 
ENA 
- 2 
sets the accumulator equal to —2 (which is 7777777777777775). 
The 1604 uses the ones complement notation to represent both 
negative floating-point numbers and negative exponents, 
2.0 
2002400000000000 
-2.0 
5775377777777777 
The characteristic of a number whose exponent is n is given by 
if n is ^ 0, then the characteristic = 2000 + n 
if n is < 0, then the characteristic = 1777 +n 
These rules appear to be inconsistent but they are the rules that the machine 
uses. The following examples illustrate the use of these rules : 
2.0 
2002400000000000 
1.0 
2001400000000000 
0.5 
2000400000000000 
0.25 
1776400000000000 
0.125 
1775400000000000 
Table 3.2 gives a more extensive list of the representation of integer and 
floating-point numbers on the CDC 1604. 

90 
3 CENTRAL PROCESSING 
UNITS 
3-4 THE IBM 1620 
The information on the IBM 1620 and the IBM 1401 will not be used in 
the rest of the book. Sections 3.4 and 3.5 can be omitted if desired, but 
these two machines do form an interesting contrast to the other machines 
which we describe. 
The IBM 1620 is quite different from the two machines we have 
discussed so far. The IBM 7090 and the CDC 1604 were binary computers 
with a memory organized into words. Each machine instruction contained 
one address or no address at all. The machines had an accumulator, an 
MQ, and several index registers. The 1620 has none of these properties. It 
is a decimal machine with a memory organized into characters. The memory 
is made of magnetic cores, and each core represents one bit but the machine 
regards a group of six cores as one unit and uses the group of six to 
represent one decimal digit. The instructions in the 1620 have two addresses. 
The machine has no accumulator, no MQ, and no index registers. In the 
7090 the ADD operation added together two words of 36 bits each. In the 
1620 the ADD operation can cause two numbers of any length to be 
added together. Similar remarks apply to the other arithmetic operations. 
The 1620 has a ferrite core memory. The basic element of memory 
is a character. A character consists of six binary digits. These digits are 
referred to as the 1,2,4,8,F, and C bits. C is a check bit which is auto-
matically set so that the total number of bits in each character is odd. A 
check bit allows the machine to detect any errors that occur in transferring 
information from one part on the machine to another. A character can 
represent either a decimal digit or what is referred to as a flagged decimal 
digit. The digits have the standard representation below: 
Decimal digit 
0 
1 
2 
3 
4 
5 
6 
7 
8 
9 
Bits 
1 
0 
1 
0 
1 
0 
1 
0 
1 
0 
1 
2 
0 
0 
1 
1 
0 
0 
1 
1 
0 
0 
4 
0 
0 
0 
0 
1 
1 
1 
1 
0 
0 
8 
0 
0 
0 
0 
0 
0 
0 
0 
1 
1 
F 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
c 
1 
0 
0 
1 
0 
1 
1 
0 
0 
1 
A flagged digit is indicated in manuscript by writing a bar over a decimal 
digit, thus 5 is the flagged digit 5. A flagged digit is represented in the 
machine by having the F bit equal to 1. In the standard version of the 

3 · 4 THE IBM 1620 
91 
machine, the memory can hold 20,000 characters; other versions of the 
machine can have 40,000 or 60,000 characters of memory. 
An instruction consists of 12 characters. Two characters specify 
the particular instruction. The other 10 characters specify two 5-character 
addresses. The machine has no index registers. An address refers to a 
particular character in the memory, each character in the memory is 
addressable. A typical instruction is 
21 
10005 
19202 
which specifies, add the number at 10005 to the number at 19202 and 
place the result in 10005. This single instruction is equivalent to several 
7090 type instructions. In the 7090 there is a fixed word length of 36 bits. In 
the 1620 the word length is variable. A word is specified by giving the 
address of the low-order end of the word and by placing a flag at the 
high-order end of the word. Suppose the memory contains the following 
characters : 
location 
character 
10000 
7 
10001 
2 
10002 
3 
10003 
1 
10004 
4 
10005 
7 
Then the number specified by location 10005 would be the decimal integer 
3147. Suppose that another part of the memory contains 
location 
character 
19200 
2 
19201 
1 
19202 
4 
Then the instruction 
21 
10005 
19202 
adds the numbers 3147 and 214. The result is 3361. The characters 3 , 3 , 6 , 
and 1 are put in locations 10002 through 10005 respectively. 
The full definition of the addition instruction is as follows: 
21 
P Q 
operates on the characters in locations P,P — 1,P — 2,..., P — p and on 

92 
3 CENTRAL PROCESSING UNITS 
the characters in locations Q,Q — \,Q — 2,..., Q — q, where P — p is the 
first flagged location below P and Q — q is the first flagged location below 
Q. There are two possibilities. If/? is less or equal to q, then the machine 
adds a p + 1 digit number to a p + 1 digit number, ignoring the high-order 
digits in Q — p — 1 through <2 — #. It is possible that the result may be 
wrong either because the high-order digits were nonzero or because of 
overflow. If/? is greater than q, then/? + 1 digits are added top -f- 1 digits; 
p — q zero digits are placed at the end of the number at Q in order to do 
the addition. This adding of zeros does not change the characters in 
positions Q — q — 1 through Q — p. 
The subtraction and multiplication operations work in the same 
way. They operate on variable-length numbers, the numbers of digits in 
the number being indicated by the flag bit. A negative number is stored by 
putting a flag on the digit in the units position. A one-digit integer is not 
permitted. All integers have at least two digits. Arithmetic is done in a 
serial mode. The machine takes one digit from each location. It finds the 
result of operating on these two digits and stores this result. It then takes 
the next two digits, allows for a carry from the previous operation, stores 
the result, and so on. Since arithmetic is done in this fashion, then there is 
no limit to the number of digits which can be added, subtracted or multi-
plied, except that the result may exceed the size of the memory. It is quite 
feasible to multiply two 100-digit numbers. The time taken to perform any 
operation depends on the number of digits. Addition takes (3 + /?) x 80 
microseconds, where /? is the number of digits to be added. 
The 1620 has a limited order code. There are only six arithmetic 
operations. There is a quite extensive set of test instructions. Typical of the 
test instructions is 
43 
P 
Q 
which transfers control to location P if the content of Q is nonzero. If 
Q is zero, then control goes to the next instruction. There are instructions 
for moving numbers from one part of the memory to another. The standard 
machine has no floating-point arithmetic. Floating-point operations can be 
simulated by macro instructions or else extra hardware can be purchased. 
A Fortran compiler is available. 
Alphanumeric information is stored in memory by using two 
character positions for each alphanumeric character. A typical input 
instruction is 
36 
P 
Q 
which reads characters from the device specified by Q. The characters are 
placed in locations P9P + 1, P + 2,... . Reading stops when an end of line 
is encountered on the input device. The standard input devices are the 

3 · 5 THE I B M 1401 
93 
console typewriter, and a card reader or a paper tape reader. The standard 
output devices are the typewriter, the card punch or the paper tape punch. 
There are several points of particular interest in the 1620. These 
are the two-address instructions which eliminate the need for an accumu-
lator. There is the decimal arithmetic and the fact that numbers are of a 
variable length, the end of the number being indicated by the flag bit. The 
serial arithmetic makes it possible for the machine to add together very 
large numbers. With this machine it is easy to obtain results that have an 
accuracy of a hundred decimal digits. 
3-5 
THE IBM 1401 
The organization of the 1401 is similar to that of the 1620. The 1401 has a 
magnetic core memory that contains 1400, 2000, 4000, 8000, or 16,000 
characters. Each character consists of 8 bits. The two extra bits, compared 
with the 6-bit characters of the 1620, enable the 1401 to store either decimal 
or alphabetic information in one character. The bits have been given the 
names, 1,2,4,8, A,B,C, and W/M. The last bit, the word mark bit, serves 
the same purpose as the F bit of the 1620. The length of an instruction is 
variable; it can be from one to eight characters long. The operation code is 
one character. There are none, one, or two address parts in an instruction, 
and there may be a one-character modifier. The modifier selects a particular 
instance of a general operation. For example, the operation code B specifies 
a branch instruction. Branch is another name for jump or transfer. The 
branch depends on certain conditions. The modifier specifies whether the 
conditions to be tested are not equal, equals, less than, or greater than. 
An address can specify any character in the store. Since the address 
is only three characters, and since the memory has more than 1000 charac-
ters, then a mixed decimal and binary addressing system is used. The 
following table shows the method that is used. 
Decimal address 
Address used in machine 
000 to 999 
000 to 999 
1000 to 1999 
000 to 999 plus an A bit 
2000 to 2999 
000 to 999 plus a B bit 
The address of location 1523 would be written V23 since V is the character 
which has the representation consisting of a 1 bit, a 4 bit and an A bit. 
The instruction 
A 
P 
Q 
is the addition instruction. The underlining of the A is a notation used for 
the character "A plus a word mark." The addition instruction adds the 
number at P to the number at Q and puts the result in the number at Q. 

94 
3 CENTRAL PROCESSING UNITS 
Decimal addition is used and as in the 1620, the addition is serial. Digits in 
successive positions are added until a character with a word mark is 
encountered. The address denotes the units position of the number. The 
word mark denotes the high-order position. Since all instruction codes 
contain a word mark, then the length of the instruction can be variable. 
Suppose location 11 and location 111 contain a word mark ; then 
A 
15 
115 
adds the number in locations 15 through 11 to the number in locations 115 
through 111. When the operation is complete, there are two machine 
registers that contain the address 10 and the address 110; these addresses 
are one less than the last address used. If the next instruction is simply 
A 
with no address part, then the machine uses the addresses from the address 
registers. It actually does the instruction 
A 
10 
110 
This ability to omit an address is known as address chaining. 
The 1401 has six arithmetic instructions. It has no floating-point 
operations. It has eight operations for moving data from one part of the 
machine to another. It has several operations for testing and jumping on 
certain conditions. All machines have punched-card input and output and 
a fast line printer. Many of the machines have magnetic tape units or 
magnetic disk storage units. 
The overall design of the machine is well adapted to the purpose 
for which it was designed—namely, the input, output, and manipulation of 
large quantities of alphanumeric data. There are several features that 
distinguish the commercial or data processing job from the typical scientific 
calculation. There is a large amount of input and output and a compara-
tively small amount of calculation; consequently fast arithmetic operations 
are not required. The data is alphanumeric and it does not easily fit into a 
fixed-length format. The data may include a person's name, his address, his 
marital status, his salary, and so on. The name field might require 20 
characters, the address field 30 characters, the marital status one character. 
This sort of information could be manipulated in a machine like the 
IBM 7090 but the splitting off of individual characters would require many 
inefficient operations. In the 1401, fields of from one to 20 or more 
characters present no difficulty. Numeric data is initially in decimal and it 
is required in decimal form for printing. It would therefore be wasteful to 
convert to binary for the small amount of arithmetic usually required. 
Elaborate interrupt mechanisms are not required because the overall cost 
of the machine is low and a certain amount of inefficiency can be traded 
off against the gain in simplicity. 

3 ■ 6 REVERSE POLISH NOTATION 
95 
3-6 
REVERSE POLISH NOTATION 
Before discussing yet another type of computer it is necessary to consider 
a new method of writing algebraic expressions. This new notation has 
suggested a novel method of specifying machine-language instructions. 
The conventional method of writing mathematical formulas relies on 
parentheses to group the components of the expression. The Fortran 
statement, 
X = A + B * ( C - D ) / E 
is an example of this notation. The computing machine can do the basic 
operations of addition, subtraction, multiplication, and division. Com-
plicated expressions have to be expressed in terms of these simpler opera-
tions ; thus the above expression would be evaluated in the order, 
T1 = C - D 
T2 = B*T1 
T3 = T2/E 
X = A + T 3 
The translation of the parenthetic expression to the sequence of opera-
tions performed by the machine is a nontrivial task. There are, however, 
parenthesis-free notations that can be used to describe any expression. 
Reverse Polish is a variant of the notation used by the Polish logician, 
Lukasiewicz. In this notation the expression given above could be written 
A B C D - * E / + 
The rules for evaluating such an expression are simply to start at the left-
hand end, and to skip past the names of variables until an operator is 
found. The operator is applied to the two preceding variables. The result 
of this operation then replaces the operator and the two operands. Applying 
these rules to the expression given above would give the following. 
Current state of 
Operation 
the expression 
A B C D - * E / + 
T 1 = C - D 
ABT1*E/+ 
T2-B*T1 
AT2E/+ 
T3=T2/E 
AT3+ 
result 
A + T3 
Other types of Polish notation are discussed by Hamblin (1962). 

96 
3 CENTRAL PROCESSING 
UNITS 
The essential feature of the reversed Polish notation is illustrated 
as follows. 
Expression 
Reversed Polish form 
A+B*C 
ABC* + 
(A+B)*C 
AB + C* 
In any ordinary arithmetic expression, the operators have different binding 
powers. The multiplication operator binds more strongly than the addition 
operator and consequently A + B*C is taken to mean B times C added to 
A. If the A is to be added to the B, then parentheses must be used. In the 
reversed Polish form, the operator is placed immediately after the operands 
and there is no necessity for parentheses. The operators which have been 
used so far have had two operands. The use of the unary minus, illustrated 
in the expression 
X = 
- A 
requires a special treatment in Polish notation. A symbol different from 
the ordinary minus sign can be used. A suitable symbol is N E C NEG is a 
unary operator that changes the sign of the operand which is immediately 
to the left of it. The expression — A + B*C could be written in reversed 
Polish as A NEG B C * +. In the developments of compilers for Algol, it 
has been found possible to extend Polish notation to include Boolean 
operations, subscripting, and other elements of the language. See for 
example Randall and Russell (1964), Chapter 3.2. 
3-7 
THE KDF9 COMPUTER 
Polish notations have suggested a completely different way of organizing 
calculations inside a computer. The KDF9 computer has a magnetic-core 
memory of 32,768 words. Each word holds 48 bits. Each word can be 
regarded as a 48-bit integer or as a floating-point number, or as eight 6-bit 
characters, or as six 8-bit syllables. The speed of the machine is indicated by 
the core cycle time of 6 microseconds and the floating-point addition time 
of 1 microsecond. Arithmetic operations are performed in one of sixteen 
special 48-bit registers. We will denote the registers by SI through S16. The 
"Fetch" operation brings a 48-bit word from the memory into the SI 
register. The complete operation is defined by: Fetch X sets S16 = S15, 
S15 = S14, ..., S2 = S1, and SI = the contents of memory location X. A set 
of registers that works in this way is called a push-down store or a stack. 
The " Store " operation performs a push-up operation. Store X stoies SI in 
memory location X, then it sets SI =S2, S2 = S3, ... SI 5 = S16. The essential 

3 · 7 THE KDF9 COMPUTER 
97 
feature of a stack is that the first element to be put into the stack is the last 
element to be taken out of the stack. Suppose that A then B then C then D 
are put into the stack. The first element to be taken out is Z>. The next is 
C, then next is B, and the final element is A. The arithmetic operations 
work on the top two S registers. The addition operation puts SI + S2 into 
SI then sets S2 = S3, S3 = S4, ... S15 = S16. It should not be thought that 
this operation requires an excessive amount of hardware. The push-down 
and push-up operations can be realized by simply moving a pointer. There 
are 16 registers arranged in a circular fashion. One of these registers is given 
the name SI, the next register is called S2, and so on. In a push-down 
operation, hardware automatically renames the registers so that the old SI 
register is the new S2 register and so on. The KDF9 instructions for 
evaluating 
X=(A+B)*(C+D) 
would correspond directly to the reversed Polish notation 
AB+CD+* 
The contents of the relevant S registers would be 
Instruction 
Fetch A 
Fetch B 
+ 
Fetch C 
Fetch D 
+ 
* 
Store X 
Content of relevant S registers 
S1=A 
S2=A, S1=B 
S1=A+B 
S 2 - A + B , S1=C 
S3=A+B, S2 = C, S1=D 
S2=A+B, S1=C + D 
S1=(A+B)*(C+D) 
We can see that it was not necessary to store the intermediate result; the 
push-down operation automatically preserved the value of A + B. This 
automatic preservation has two useful consequences. It saves a storage 
reference; the access time for a small store such as the 16 word S register 
store can be made very short compared to the access time for words in the 
main memory. The second advantage of the Polish notation order code is 
that the code is compact. In the KDF9, instructions occupy one, two, or 
three syllables. Operations such as + , - , * , and / which require no address 
are only one syllable long. The Fetch and Store operations require a 15-bit 
address and are consequently three syllables long. Barton (1961) has 
indicated some other advantages of this type of design. One of the major 
advantages is its similarity to. the Polish notation: Polish notation is 
more convenient than the operation code of machines like the IBM 7090 

98 
3 CENTRAL PROCESSING UNITS 
and the CDC 1604. An alternative method of restricting references to the 
main memory is described in connection with the CDC 6600 and IBM 360. 
The 6600 and 360 scheme would seem to be preferable because it allows 
direct access to any of the special registers. The KDF9 scheme does not 
allow direct access to any but the top register. The expression 
X=(A+B)/(A-B) 
illustrates a case where the direct use of reversed Polish notation would be 
wasteful. The obvious way to code this is 
Fetch A 
Fetch B 
+ 
Fetch A 
Fetch B 
/ 
Store X 
but in this code there are two too many fetch operators. The KDF9 treats 
this case by use of a special operation called DUP. This operation dupli-
cates the contents of one S register in another S register. Thus 
Fetch A 
DUP 
has the same effect as 
Fetch A 
Fetch A 
but it is more efficient. The design of the KDF9 is very elegant. It is a 
decided improvement over the IBM 7090; however, it is not so obviously 
an improvement over the more conventional modern machines such as the 
CDC 6600 and the IBM 360. 
The KDF9 has another 15 special registers that can be used for 
indexing and counting. It has a special push-down store for use in sub-
routine jumps. It has the usual peripheral equipment. 
3"8 
THE CDC 6600 
The problems of designing the fastest possible computer have been 
discussed by Buckholz (1962). The designer has available to him certain 
basic units. The characteristics of these units are fixed by the current state 
of the art. In the fastest commercial computers of the present generation, 

3 · 8 THE CDC 6600 
99 
the basic memory unit is the magnetic core store. The time to read or write 
one word is typically one microsecond. Ferrite core memories can be joined 
together to form a memory of any size, but the economic limit for a fast 
memory seems to be about 150,000 words. With a memory of this size it is 
necessary to use some form of secondary memory. The usual secondary 
memory is the magnetic disk or drum with an access time of 15 milliseconds 
or more. When small amounts of memory are required, then devices that 
are much faster than magnetic cores can be used. The special registers 
such as the accumulator and the index registers can have a read/write 
time of the order of 0.1 microsecond. 
Having assembled the basic units, the designer has to fit them 
together. The object of the design is to produce the fastest machine possible, 
that is, a machine that will do ten million operations a second. The 
slowness of the disk memory and the relative slowness of the core memory 
has to be masked and the speed of calculation must be geared to the speed 
of the fastest unit. Buckholz (1962) discusses the design of the Stretch 
computer, which was completed in 1961; however, the problems which 
arose in the design of Stretch are similar to the problems which arise in the 
design of present-day machines. 
The CDC 6600 was first delivered in 1964. It consists of one 
central processor, ten peripheral processors, and the usual peripheral 
equipment. The peripheral processors do a small amount of arithmetic; 
they contain much of the monitor system and they do all the input and 
output. The CP (central processor) does most of the computing and it does 
no input-output. The CP has access to a central memory of 131,072 words 
of 60 bits each. Each peripheral processor has its own memory of 4096 
words of 12 bits each. The computer has 12 data channels. The PP's 
(peripheral processors) can read or write from the peripheral equipment 
into their own memory via any available channels. A PP can write directly 
into the central memory. Input proceeds from the magnetic tape or disk 
into the memory of a PP. The information is transmitted into the central 
memory when some conveniently large portion of it has been assembled in 
the PP memory. 
Instructions for the central processor are stored in the central 
memory. An address is 18 bits and each word of memory is addressable. 
Floating-point numbers are represented in the form k.2n where 2000 + n 
is stored in 11 bits and the integer k is stored in the other 49 bits of the 
60-bit word. Integer arithmetic can be done on long words of 60 bits, or on 
short words of 18 bits. The CP has 64 instructions. An instruction has the 
form either 
f i j k 
or 
/ / j K 
where/is a 6-bit function code, i9j, and k are 3-bit addresses, and AT is an 
18-bit address. Instructions of the first type are 15 bits long and the second 

100 
3 CENTRAL PROCESSING 
UNITS 
type are 30 bits long. Each word of central memory has four 15-bit or two 
30-bit, or one 30-bit and two 15-bit instructions. 
The CP has eight X registers, eight A registers, and eight B 
registers. An X register performs the function of an accumulator and is 
60 bits long. The A registers are 18 bits long and hold addresses. The B 
registers are 18 bits long and are used for counting. Each X register is 
linked to the corresponding A register. If the address in register An is 
changed : 
if n is zero, there is no other effect, 
if n is 1,2,3,4, or 5 then the contents of the memory location whose address is 
specified by An is placed in register Xn. 
if « is 6 or 7 then the contents of Xn is placed in the location specified by An. 
The A registers separate the address part and the function part of any 
operation and consequently they make it easier for the machine to antici-
pate memory references. The integers i,j, or k which occur in the machine 
instruction refer to an A, B, or X register. The integer K either refers to a 
location in the memory or it might be used to set a constant in an A or 
B register. To give two examples, the instruction 
30 
/ j k 
performs the 60-bit floating addition operation Xi = Xj + Xk. The operation 
50 
/ j K 
sets A/ equal to the sum of Ay and K. The number K and the contents of 
A/ and A/ are 18-bit binary integers. 
In order to achieve the fastest possible speed of operation, the 
CP has ten distinct functional units. These units are the floating add unit, 
the long add unit, the divide unit, the shift unit, the boolean unit, the 
branch unit, two multiply units, and two short add units. The operations 
that use the branch unit are the unconditional jump instructions, instruc-
tions of the form " go to location K + B/ if Xj equals zero," instructions of 
the form "go to location K if B/ = By " and ten other similar instructions 
which jump on various conditions. There are eight instructions that use 
the Boolean unit to form logical sums and products of the contents of the 
X registers. There are nine instructions that use the shift unit. The floating 
add unit is used for addition or subtraction of floating point numbers. 
There are 21 instructions of the form 
Ai = Aj + K 
A/ = By + AT 
B/ = Ay + BÄ: 
Xi = Xj + BÂ: 

3 · 8 THE CDC 6600 
101 
and so on, which use the short add unit. Eighteen-bit operations involving 
the X registers use the lower 18 bits of the 60-bit word. The register BO 
always contains zero. 
To demonstrate the order code we give the instructions for forming 
SUM = Q(1)+Q(2)+ . . . +Q(20) 
CDC 6600 assembler 
SA1 
Q 
SB1 
20 
SB2 
1 
BX6 
X1 
SA2 
A1+B2 
SB2 
B2 + 1 
FX6 
X6 + X2 
LT 
B2 B1 *-
SA6 
SUM 
-3 
Comments 
A1=Q, X1=m(Q) 
B1=20 
B2-1 
X6=X1 
A2=A1+B2, X2 = m(Q+B2) 
B2-B2 + 1 
X6 = X6 + X2 
jump if B2<B1 
A 6 - S U M , m(SUM)=X6 
These nine instructions would occupy four 60-bit words. Compared to a 
machine like the IBM 7090, the instruction code appears very unsophis-
ticated ; however, it is quite compact and can result in very fast execution 
times. The execution times are expressed in terms of minor cycles of 0.1 
microsecond. Multiplication takes ten minor cycles; division takes 29 
minor cycles ; branch instructions take 6 or 11 minor cycles. The Boolean, 
shift, long, and short add operations take three minor cycles. These times 
do not include the time taken to fetch the operands into the unit. Refer-
ences to central memory take a minimum of five minor cycles. 
The CP has 32 fifteen-bit registers (these are in addition to the 
A, B, and X registers) which are used to smooth the flow of instructions 
from the memory to the processing unit. The machine tries to fetch instruc-
tions from the memory some time before they are actually needed. This 
saves any delay due to the comparative slowness of the access to the central 
memory. In the parts of the program in which there is a small loop, the 
computer keeps the instructions of the loop in the fast registers and it need 
not fetch any instructions from the memory during the execution of the 
loop. The fast registers are refilled only if they are nearly empty, or if 
there is a jump to an instruction that is not currently in one of the registers. 
The programmer writes the program in a conventional way. The machine 
takes the instructions in strict sequence. If the appropriate functional unit 
is free and if the operands are available, then the execution of the in-
struction is commenced. The machine does not have to wait until previous 
operations are complete. In the programming example given above, the 
first two instructions are independent of each other. Both instructions use 
the short add unit, but there are two of these units and the machine can 
Instructions for 

102 
3 CENTRAL PROCESSING 
UNITS 
commence the second operation before the first operation is complete. In 
favorable cases of this sort, the machine is able to issue one instruction 
every minor cycle, even though each instruction is taking three or more 
cycles to execute. In the programming example, the third operation would 
have to wait until a short add unit is free. The fourth operation has to wait 
until the first operation is complete, but it does not have to wait for the 
second and third instructions. If a branch instruction is encountered, then 
no more instructions are issued until the branch has been executed. Cen-
tral memory is divided into 32 banks so that the CP or one or more of the 
PP's can be referring to the memory at one time. 
The CDC 6600 has an operating system that controls the use of 
the peripheral processors and the input-output equipment. This system 
will be described in Section 5.17. At this stage it is sufficient to point out 
that the 6600 has an assembler and a Fortran compiler. The machine is 
normally operated in the multiprogramming mode. The supervision of the 
time sharing and the efficient use of the complex of I/O equipment, peri-
pheral processors, and central processor is a very complicated task, but 
these complications should not bother the ordinary programmer. To the 
Fortran programmer, the machine does not appear to be any different from 
any other machine. To the assembly-language programmer, the presence 
of the ten functional units offers some scope for ingenuity but program-
ming is essentially no more difficult than on conventional machines such 
as the CDC 1604. 
3-9 
THE IBM 360 
The machines discussed so far were designed to satisfy a certain market. 
The IBM 7090 is a large, fast scientific computer. The 1401 is a small 
commercial computer. The 7040 is designed for the same class of work as 
the 7090, but it is slower and therefore cheaper. This proliferation of 
machines has produced a great waste of effort since each computer needs 
its own software and its own set of standard programs. The multiplicity of 
machines has also restricted the choice of the customer. He delays the 
purchase of a new machine because of the difficulties of converting his 
programs. The IBM 360 is a series of similar computers. The series is 
designed so that it can replace the small machines and the large machines, 
the commercial machines and the scientific machines. It should allow the 
customer to purchase a small machine, and at a later date transfer his work 
to a larger model of the machine with a minimum amount of incon-
venience. The design of the 360 allows for improvements in technology 
during the coming years; it should be possible to introduce new machines 
into the series without having to rewrite the software. Fortran was an 
algebraic language that could be used on many different computers. The 
360 has a machine language that could be used on many different versions 

3 ■ 9 THE IBM 360 
103 
of the same machine. The actual hardware is different in the different models 
of the machine, but all the machines look alike from the point of view of 
the programmer. 
The memory of the 7090 is organized into words of 36 bits each. 
An address specifies a location number. Each location holds one word. 
Addresses run from 0 to 32767 and an address is stored as a 15-bit binary 
integer. The memory of the 360 is organized into bytes of 8 bits each. An 
address specifies a location number and each location contains one byte. 
Addresses run from zero to some number which varies from model to 
model of the machine. An address is stored as a 24-bit binary integer. The 
address permits memories of up to 16,277,216 bytes but most memories 
contain a much smaller number of bytes. The machine language instruction 
can use any address in the range 0 to 224— 1 but if the hardware detects 
that the address is higher than the number of bytes in this particular 
memory, it causes an interrupt and the monitor system abandons that 
job. A memory of 131,072 bytes would approximate the 32,768-word 
memory of the 7090. The method of using addresses in the model 67 of the 
IBM 360 is quite different to the interpretation in the other models. The 
model 67 is considered in Section 9.4. 
The 7090 has an accumulator, an MQ, and three index registers. 
The 360 has 16 special registers of 32 bits each. These registers are used as 
accumulators, MQ registers, index registers, and for several other purposes. 
These registers will be denoted by R0 through R15. Floating-point arith-
metic is standard on the larger models and it can be purchased as an 
optional extra on the smaller models. We will assume in our description 
that the machine is equipped with the floating-point option. Floating-point 
operations make use of an extra four special registers of 64 bits each. We 
will denote these registers as D0, D2, D4, and D6. These are quite separate 
from the R registers and are only used in floating-point operations. Num-
bering these registers 0,2,4, and 6 rather than 0,1,2, and 3 is simply a 
peculiarity of the hardware. All models of the machine have a register 
called the PSW (program status word). The PSW is 64 bits long. The lower 
24 bits correspond to the control register of the 7090. The higher bits 
contain information on the current status of the program, including 
information such as which interrupt conditions are enabled. 
When describing the 7090, we mentioned the various types of 
instruction such as arithmetic, logical, and so on. There is another way of 
differentiating operations according to the register or memory locations to 
which they refer. The 7090 operations 
CHS 
change the sign of the accumulator 
AXT 
N,1 
set index register 1 equal to N 
LXA 
N,1 
set index register 1 equal to m(N) 
illustrate the distinction we have in mind. The CHS instruction refers to 
the contents of the accumulator alone and it does not need an address. The 

104 
3 CENTRAL PROCESSING UNITS 
AXT instruction does not use N as an address, it puts the number N itself 
into the index register. The instruction LXA uses the address part of the 
instruction as an actual address. This type of difference is important in the 
360—there are five distinct types of machine instruction corresponding to 
the way in which the address parts of the instruction are used These five 
types are called the RR, the RX, the RS, the SI, and the SS type of 
instruction. Not all instructions are of the same length. 
The RR instructions are 16 bits long; the RX, RS, and SI instruc-
tions are 32 bits long; and the SS instructions are 48 bits long. The reason 
for these different lengths is simply to save memory space. The RR instruc-
tions need only 16 bits to specify the complete instruction and it would be 
wasteful to use 32 or 48 bits. The part of the instruction that specifies the 
particular operation is 8 bits long in all cases; the other parts of the 
instructions may specify several registers or memory locations depending 
on the type of the instruction. 
The FAP assembler on the 7090 tended to-use a mnemonic instruc-
tion which was three letters long. Some of the mnemonics were inconsistent; 
for example, LXA indicates load index register, so we might expect the load 
accumulator instruction to start off with an L but for some unknown 
reason the mnemonic CLA (clear and add) was used. The 360 assembler 
uses a reasonably consistent scheme. A mnemonic instruction can be 
one, two, three, four, or ?i\c letters long. The first letter usually indicates 
the purpose of the operation. The more common first letters are as follows: 
letter 
A 
C 
E 
M 
MV 
O 
S 
operation 
add 
compare 
edit 
multiply 
move 
logical or 
subtract, shift 
letter 
B 
D 
1 
N 
ST 
T 
X 
operation 
branch 
divide 
insert 
logical and 
store 
test, translate 
logical, exclusive or 
Each initial letter may occur in several instructions; for example L, LR, 
LER, and LDR are only a few of the load instructions. The other letters 
in the instruction give an indication of the registers involved. D denotes 
one of the D registers. E denotes the left half of a D register. R usually 
denotes an R register, but it may occur in combination with D or E. The 
absence of a letter indicates that a memory location rather than a register 
is involved. L specifies that a register is loaded from a memory location. LR 
is the instruction to load a register from another register. LD specifies 
load a D register from memory. LDR specifies load a D register from 
another D register. The scheme is not as consistent as it might be. 
An RR instruction is 16 bits long. It has the form 
operation 
/ 
j 
8 bits 
4 bits 
4 bits 

3 · 9 THE I B M 360 
105 
where / and j are two binary integers. In an assembly language instruction / 
and y are decimal integers between 0 and 15. An example of an RR type of 
operation is 
LR 
7,11 
which sets R7 = R n . Another example is 
AR 
4,13 
which sets R4 = R4 + R13. The R registers hold 32-bit binary integers. In 
arithmetic operations, 32-bit binary arithmetic is performed in the two's 
complement notation. 
Floating-point numbers can be either short or long. The operations 
on short numbers are usually faster and the memory space required for 
short numbers is of course smaller; the accuracy is however much less than 
that of long numbers. The numbers are split up as follows: Short numbers 
have a sign bit, a 7-bit characteristic and a 24-bit fraction. Long numbers 
have a sign bit, a 7-bit characteristic, and a 56-bit fraction. Let x be the 
number that is to be represented in floating-point form. The 7090 used 
floating-point binary representation. It expressed x in the form α*2" where 
\ < a < 1.0. The 360 uses the floating-point hexadecimal representation. 
Hexadecimal means 16, just as binary means 2 and octal means 8. The 360 
representation expresses x in the form b*l6m where 1/16 < b < 1.0. The 
characteristic is 64 plus the exponent. Thus 0.5 has exponent zero, charac-
teristic 64 decimal which is 1000000 binary. The fraction is 0.5 or 
0.10000...00 binary. The 360 representation is 
0100000010000 . . . 00 
where there are 23 trailing zeros in the representation of a short number or 
55 trailing zeros in a long number. 1.0 decimal is 1/16 times 16. The 
characteristic is 1000001, and the fraction is .0001000...00. The 360 
representation is 
010000010001000 .. . 00 
with 20 or 52 trailing zeros. 1/64 is represented by 
0111111101000 . . . 00 
with a characteristic of 63 and a fraction of .01. The floating-point numbers 
use the sign convention (they do not use complement arithmetic), so that 
-1/64 is 
1111111101000. . . 0 0 

106 
3 CENTRAL PROCESSING UNITS 
All floating-point operations are carried out in one of the D registers. If a 
long operation is required, that is an operation involving long numbers, 
then the whole D register is used. If a short operation is required, then 
only the left half of the D register is used, except in multiplication where 
a 64-bit product is generated. We have used the notation E to denote the 
left half of a D register. 
ADR 
2,4 
sets D2 = D2 + D 4 using 64-bit floating-point hexadecimal arithmetic. 
AER 
2,4 
sets E2 = E2 + E4 using 32-bit floating-point hexadecimal arithmetic. The 
right half of D2 is not changed. The 360 has a set of floating-point instruc-
tions that omit the normalization that usually occurs at the end of floating-
point operations. AWR is the unnormalized form of ADR and AUR is 
the unnormalized AER. These operations are not often used but they can 
be invaluable in some special applications. 
An RR instruction refers to two registers. An RX instruction refers 
to one register and one memory word. For reasons that will be explained 
later, the designers of the 360 decided not to put the address of the memory 
word directly into the instruction. The RX instruction has the form 
operation code 
IR 
IX 
IB 
ID 
8 bits 
4 bits 
4 bits 
4 bits 
12 bits 
IR specifies an R, D, or E register. IX and IB specify R registers. The 
memory address is computed as follows : If IX and IB are nonzero, then 
the memory address is RIX + RIB + ID. If IX is zero, then zero is used in 
place of R0. If IB is zero, then zero is used in place of R0. Let us give some 
examples to make this clear. 
L 
7 
3 
2 
2820 
sets R7 equal to the contents of location R3 + R2 + 2820. If R3 contains 
96 and R2 contains 18724 then the instruction sets R7 equal to the contents 
of location 21640. 
L 
4 
0 
2 
2820 
sets R4 equal to the contents of location 21544 since R2 plus 2820 is 21544. 
The contents of RIX is said to be the index. RIB is said to contain the base 
address and ID is said to be the displacement. The displacement part is 
12-bits long so all displacements are between 0 and 4095. A base address 
plus a displacement is the usual way of specifying an address in a 360 
instruction. 

3 - 9 THE I B M 360 
107 
The memory is organized into 8-bit bytes and each byte is address-
able; however, the concept of a word is significant in some operations. A 
word on the 360 is defined to be four bytes. The address of a word is the 
same as the address of the byte at the left-hand end of the word. A word 
address must be a multiple of four. The address of the first word in memory 
is zero; the word is contained in bytes 0,1,2, and 3. The address of the 
second word in memory is 4 and the word is in bytes 4,5,6, and 7. The 
instruction L which loads a word into a register is a word instruction and 
the address part (that is RIX + RIB + ID) must be a multiple of four. 
Similarly the instruction 
LD 
IR 
IX 
IB 
ID 
is a load D instruction. This picks up a double word of 8 bytes from the 
memory and puts it in the D register number IR. In this double-word 
instruction the address RIX + R I B+ID must be a multiple of 8; thus 
LD 
2 
0 
0 
1024 
would load the contents of bytes 1024 through 1031 into D register 2. In 
most programs the assembler is able to ensure that words start at a location 
that is divisible by 4, that double words start at a location that is divisible 
by 8, and that half words (2 bytes) start at a location that is a multiple of 2. 
The RS type of operations have the form 
operation code 
IR 
IL 
IB 
ID 
8 bits 
4 bits 4 bits 4 bits 12 bits 
IR specifies a register. RIB + ID specifies an address. In some operations 
IL is not used ; in some operations it specifies another register. The opera-
tion 
STM 
3 
12 
13 
1024 
is an RS instruction in which IL is used. STM is the store multiple operation 
and this one instruction stores registers 3,4,5,...,12 in locations beginning 
at location R13 + 1024; since ten registers are specified, then 40 bytes of 
memory are used. The load multiple instruction 
LM 
1 
3 
7 
99 
loads registers 1,2, and 3 from memory locations starting at R7 + 99. If 
R7 contains 101 then bytes 200,201,202, and 203 go in R1# Bytes 
204,205,206 and 207 go in R2. Bytes 208,209,210, and 211 go in R3. The 
shift instructions are of RS type, but IL is not used; 
SLL 
3 
0 
5 
12 

108 
3 CENTRAL PROCESSING 
UNITS 
does a left shift of the contents of R3. R5 +12 is the number bit positions 
by which R3 is shifted. 
The SI type of instruction has the form 
operation code 
I 
IB 
ID 
8 bits 
8 bits 4 bits 
12 bits 
RIB + ID specifies a memory location and I is regarded as an 8-bit binary 
number. The instruction 
MVI 
100 
2 
96 
puts the byte 01100100, which is the binary equivalent of 100 decimal, into 
location R2 + 96. 
An SS type of instruction is 48 bits long and has the form 
operation code 
IL1 
IL2 
IB1 
ID1 
IB2 
ID2 
8 bits 
4 bits 4 bits 
4 bits 
12 bits 
4 bits 
12 bits 
RIB1 + ID1 specifies the address of one memory location, RIB2 + 
ID2 specifies the address of another memory location. IL1 and IL2 specify 
lengths, or in some operation the IL1 and IL2 field is regarded as one 
8-bit integer; for example 
MVC 
211 
3 
1024 
1 
3212 
is the move-character operation in which IL1 and IL2 are combined into 
one 8-bit field. This operation moves 211 bytes beginning with byte 
R3 + 1024 into Rx + 3212 and ending with byte R3 + 1234 into Ri + 3422. 
These few examples illustrate the five types of operation in the 360 
and show how the various parts of the instruction are used. They show in 
particular how the register-to-register, and register-to-memory instruction 
are used. We will now consider branch instructions. In normal operation 
the control counter is increased by 2,4, or 6 bytes depending on the type of 
instruction that has just been executed. The branching operations cor-
respond to the transfer instructions of the 7090. Branching instructions can 
be of type RR, RX, or RS. 
BAL 
IR 
IX 
IB 
ID 
is an RX type of instruction. BAL stands for branch and link. It stores the 
low-order 32 bits of the PSW (program status word) in register RIR and 
jumps to the address RIX + RIB + ID. It will be remembered that the PSW 
contains the value of the control counter so that BAL saves the information 
about where the jump has come from. It can be used for jumping into 
subroutines. There is a similar instruction 
BALR 
IR1 
IR2 

3 · 9 THE I B M 360 
109 
of type RR which saves the low-order 32 bits of the PSW in RIR1 and 
jumps to the location specified by RiR2. Part of the PSW contains 2 bits 
called the condition code. The condition code can be set by several of the 
arithmetic and logical operations ; for example, 
AR 
3 
7 
is the binary integer addition operation that adds R3 to R7 and puts the 
result in R3. It also sets the condition code; if the result is zero, it sets 
0; if the result is less than zero, it sets 1 ; if the result is greater than zero, 
it sets 2; and if there is an overflow, it sets 3. The condition code can be 
tested by the branch on condition instruction. 
BCR 
3 
7 
The first number is used as a mask. It is regarded as a binary integer 
hhhh I if 7o *s 1 a nd the condition code is 0 or if /\ is 1 and the condition 
code is 1, or if i2 is 1 and the condition code is 2, or if /3 is 1 and the condi-
tion cqde is 3, then the branch to location R7 is taken. In this example the 
branch is taken if the condition code is 2 or 3. There are branch instructions 
that can be used in counting through loops; for example, 
BCTR 
3 
7 
R3 is reduced by one, then if the result is nonzero, the program jumps to 
the location specified by R7, whereas if R3 is zero then the next instruction 
is taken. 
The IBM 7090 and many other machines use a 6-bit representation 
of alphanumeric characters. The IBM 360 uses an 8-bit representation. The 
6-bit representation cannot conveniently represent more than 64 different 
characters. Eight bits allows up to 256 characters and it fits in with a special 
representation of purely decimal data. When a decimal digit appears as 
part of some alphanumeric text, then it is represented by 8 bits. When a 
string of purely decimal data is to be manipulated, then each digit is 
represented by four bits. The 360 manual calls this the binary coded 
decimal representation; it is not related to the BCD representation 
discussed in Chapter 2. The binary coded decimal representation is as 
follows : 
character 
0 
1 
2 
3 
4 
5 
6 
7 
representation 
0000 
0001 
0010 
0011 
0100 
0101 
0110 
0111 
character 
8 
9 
+ 
— 
+ 
— 
+ 
+ 
representation 
1000 
1001 
1010 
1011 
1100 
1101 
1110 
1110 

110 
3 CENTRAL PROCESSING 
UNITS 
Two of these digits can be packed in one byte. The 8-bit representation of 
characters will be discussed in Section 5.6. 
The 360 has a number of instructions for operating on single 
characters, or strings of characters. The operation MVC has already been 
mentioned. The operations performed by MVC can be simulated on a 
machine like the 7090 but they require many individual 7090 operations. 
The 360 instructions 
STC 
IR1 
IX2 
IB2 
ID2 
stores the single byte from the right-hand end of register IR1, with the 
result going in the byte with the address IX2,IB2,ID2. The instruction 
CVD 
IR1 
IX2 
IB2 
ID2 
takes the contents of register IR1 and converts it into binary coded 
decimal. The result occupies 8 bytes in storage starting at the location 
specified by IX2,IB2,ID2. The left-most half-byte gives the sign and the 
remaining 15 half-bytes specify the integer in decimal. In the standard 
model of the 360, this conversion would be used when preparing data for 
output. Some models of the 360 are equipped with decimal arithmetic 
instructions. They can perform addition, subtraction, multiplication, and 
division of variable-length decimal numbers. 
3-10 
SUMMARY of INSTRUCTIONS for the IBM 360 
The following instructions are used with fixed-point arithmetic. The RR 
operations involve two of the R registers. The RX operations involve one R 
register and one memory word, or half-word. C indicates that the instruc-
tion does set the condition code. This code can subsequently be tested by a 
branch on condition instruction. 
Name 
Mnemonic 
Type 
Load 
Load 
Load half-word 
Load and test 
Load complement 
Load positive 
Load negative 
Load multiple 
LR 
L 
LH 
LTR 
LCR 
LPR 
LNR 
LM 
RR 
RX 
RX 
RR 
RR 
RR 
RR 
RS 
C 
C 
C 
C 

3 · 10 S U M M A R Y OF INSTRUCTIONS FOR THE IBM 360 
111 
Name 
Mnemonic 
Type 
Add 
Add 
Add half-word 
Add logical 
Add logical 
Subtract 
Subtract 
Subtract half-word 
Subtract logical 
Subtract logical 
Compare 
Compare 
Compare half-word 
Multiply 
Multiply 
Multiply half-word 
Divide 
Divide 
Convert to binary 
Convert to decimal 
Store 
Store half-word 
Store multiple 
Shift left single 
Shift right single 
Shift left double 
Shift right double 
AR 
A 
AH 
ALR 
AL 
SR 
S 
SH 
SLR 
SL 
CR 
C 
CH 
MR 
M 
MH 
DR 
D 
CVB 
CVD 
ST 
STH 
STM 
SLA 
SRA 
SLDA 
SRDA 
RR 
RX 
RX 
RR 
RX 
RR 
RX 
RX 
RR 
RX 
RR 
RX 
RX 
RR 
RX 
RX 
RR 
RX 
RX 
RX 
RX 
RX 
RS 
RS 
RS 
RS 
RS 
C 
C 
C 
C 
C 
C 
C 
C 
C 
C 
C 
C 
C 
C 
C 
C 
C 
The following instructions are used with decimal arithmetic. The data has 
two decimal digits packed in one byte. Decimal arithmetic is optional on 
some models. 
Name 
Mnemonic 
Type 
Add decimal 
Subtract decimal 
Zero and add 
Compare decimal 
Multiply decimal 
Divide decimal 
Pack 
Unpack 
Move with offset 
AP 
SP 
ZAP 
CP 
MP 
DP 
PACK 
UNPK 
MVO 
SS 
SS 
SS 
SS 
SS 
SS 
SS 
SS 
SS 
c 
c 
c 
c 
The following instructions use the double-length or single-length floating-
point registers. Floating-point arithmetic is an optional extra on some 
models. 

112 
3 CENTRAL PROCESSING UNITS 
Name 
Load positive (long) 
Load positive (short) 
Load negative (long) 
Load negative (short) 
Add normalized (long) 
Add normalized (long) 
Add normalized (short) 
Add normalized (short) 
Add unnormalized (long) 
Add unnormalized (long) 
Add unnormalized (short) 
Add unnormalized (short) 
Subtract normalized (long) 
Subtract normalized (long) 
Subtract normalized (short) 
Subtract normalized (short) 
Subtract unnormalized (long) 
Subtract unnormalized (long) 
Subtract unnormalized (short) 
Subtract unnormalized (short) 
Compare (long) 
Compare (long) 
Compare (short) 
Compare (short) 
Halve (long) 
Halve (short) 
Multiply (long) 
Multiply (long) 
Multiply (short) 
Multiply (short) 
Divide (long) 
Divide (long) 
Divide (short) 
Divide (short) 
Store (long) 
Store (short) 
Load (long) 
Load (long) 
Load (short) 
Load (short) 
Load and test (long) 
Load and test (short) 
Load complement (long) 
Load complement (short) 
Mnemonic 
LPDR 
LPER 
LNDR 
LNER 
ADR 
AD 
AER 
AE 
AWR 
AW 
AUR 
AU 
SDR 
SD 
SER 
SE 
SWR 
SW 
SUR 
SU 
CDR 
CD 
CER 
CE 
HDR 
HER 
MDR 
MD 
MER 
ME 
DDR 
DD 
DER 
DE 
STD 
STE 
LDR 
LD 
LER 
LE 
LTDR 
LTER 
LCDR 
LCER 
Type 
RR 
C 
RR 
C 
RR 
C 
RR 
C 
RR 
C 
RX 
C 
RR 
C 
RX 
C 
RR 
C 
RX 
C 
RR 
C 
RR 
C 
RR 
C 
RX 
C 
RR 
C 
RX 
C 
RR 
C 
RX 
C 
RR 
C 
RX 
C 
RR 
C 
RX 
C 
RR 
C 
RX 
C 
RR 
RR 
RR 
RX 
RR 
RX 
RR 
RX 
RR 
RX 
RX 
RX 
RR 
RX 
RR 
RX 
RR 
C 
RR 
C 
RR 
C 
RR 
C 
The logical operations may use one of the R registers or they may operate 
on a series of bytes in the memory. In the SS instructions up to 256 bytes 
may be operated upon. 

3 · 10 SUMMARY OF INSTRUCTIONS FOR THE IBM 360 
113 
Name 
Move 
Move 
Move numerics 
Move zones 
Compare logical 
Compare logical 
Compare logical 
Compare logical 
AND 
AND 
AND 
AND 
OR 
OR 
OR 
OR 
Exclusive OR 
Exclusive OR 
Exclusive OR 
Exclusive OR 
Test under mask 
Insert character 
Store character 
Load address 
Translate 
Translate and test 
Edit 
Edit and mark 
Shift left single logical 
Shift right single logical 
Shift left double logical 
Shift right double logical 
Mnemonic 
MVI 
MVC 
MVN 
MVZ 
CLR 
CL 
CLI 
CLC 
NR 
N 
NI 
NC 
OR 
0 
Ol 
OC 
XR 
X 
XI 
XC 
TM 
IC 
STC 
LA 
TR 
TRT 
ED 
EDMK 
SLL 
SRL 
SLDL 
SRDL 
Type 
SI 
SS 
SS 
SS 
RR C 
RX C 
SI 
C 
SS 
C 
RR C 
RX C 
SI 
C 
SS 
C 
RR C 
RX C 
SI 
C 
SS 
C 
RR C 
RX C 
SI, 
C 
SS 
C 
SI 
C 
RX 
RX 
RX 
SS 
SS 
C 
SS, 
C 
SS, C 
RS 
RS 
RS, 
RS, 
The shift double instructions operate on a pair of R registers. 
The branch on condition instructions test the condition which was 
set up by the previous arithmetic, floating-point, or logical operation. 
Name 
Branch on condition 
Branch on condition 
Branch and link 
Branch and link 
Branch on count 
Branch on count 
Branch on index high 
Branch on index low or equal 
Execute 
Mnemonic 
BCR 
BC 
BALR 
BAL 
BCTR 
BCT 
BXH 
BXLE 
EX 
Type 
RR 
RX 
RR 
RX 
RR 
RX 
RS 
RS 
RX 

114 
3 CENTRAL PROCESSING UNITS 
The BXH and BXLE instructions contain a reference to two registers Rl 
and R2, but they may use a third register R3. R3 is the odd register follow-
ing or identical with R2. For example, if R2 is register number 4 then R3 
is register number 5, but if R2 is register number 5 then R3 is also register 
number 5. BXH causes the contents of R2 to be added to the contents of 
Rl and the result is placed in Rl. The sum is compared with the contents 
of R3. If the sum is higher then the branch is taken. BXH 3,6,X would 
branch to location X if Rl + R6 is greater than R7. BXLE operates in a 
similar way except that it branches if the less-than-or-equals condition is 
satisfied. 
In discussing the monitor system we have emphasized that the 
monitor program must have complete control. In order to exercise this 
control the monitor must make sure that no program can stop the machine; 
it must make sure that no program can overwrite any other program; it 
must ensure that all I/O operations are legal. The 360 system has certain 
hardware features that enable the monitor to exercise control. Whenever 
the instructions in the monitor are being obeyed, there is a certain bit in 
the PSW which is set. When this particular bit is set, the machine is said to 
be running in the supervisor state. When the bit is off, then the machine is 
in the problem state. Certain 360 instructions are said to be privileged. This 
means that they cannot be used by the ordinary programmer. If a privileged 
instruction is used and if the machine is in the problem state, then an 
interrupt occurs, the machine is switched to the supervisory state, and 
control passes to the monitor program. All of the following instructions, 
with the exception of SPM and SVC, are privileged; they cannot be used 
by ordinary programs. SVC is the normal method of jumping into a 
monitor routine from a nonmonitor program. 
Name 
Load PSW 
Set program mask 
Set system mask 
Supervisor call 
Set storage key 
Insert storage key 
Write direct 
Read direct 
Diagnose 
Start I/O 
Test I/O 
Halt I/O 
Test channel 
Mnemonic 
LPSW 
SPM 
SSM 
SVC 
SSK 
ISK 
WRD 
RDD 
SIO 
TIO 
HIO 
TCH 
Type 
SI 
RR 
SI 
RR 
RR 
RR 
SI 
SI 
SI 
SI 
SI 
SI 
SI 
3-11 
THE IBM 360 ASSEMBLER 
The assembler-language instructions have three parts. The statement label 
consists of one letter followed by up to seven more letters or digits. The 

3 · 11 THE I B M 360 ASSEMBLER 
115 
operation consists of up to five letters. The operand is of variable length 
and specifies addresses, register numbers, and so on. A blank in column one 
of the symbolic card indicates that there is no label. The operation can 
begin anywhere to the right of column one, as long as it is separated from 
the label by at least one blank. The operand field can begin anywhere to 
the right of the operation, providing it is separated from it by at least one 
blank. The addresses or registers in the operand are separated by a comma; 
thus 
LR 
5,6 
If an address contains a base or an index, then they are put in parentheses; 
thus 
LD 
IR,ID(IX,IB) 
and 
BAL 
IR,ID(IX,IB) 
since the base and the index are part of one address, it is convenient to 
write them in this way. 
A memory address in a machine instruction has to be specified 
by giving the displacement and the base address; however, there is no 
reason why the programmer should have to use this form. The assembler 
can do the conversion from symbolic address to base plus displacement. 
The instruction 
BALR 
IR1JR2 
is the branch and link instruction. It puts the right half of the PSW in 
register IR1 and branches to the address specified by IR2. If IR2 is zero, 
then no branching takes place. An example of this instruction is 
FIRST 
BALR 
15,0 
which sets the last 24 bits of R15 equal to FIRST+ 2, and proceeds to the 
next instruction. BALR always sets the register to the first byte of the next 
instruction. The BALR instruction is itself 2 bytes long. Consider the 
following program : 
FIRST 
BALR 
15,0 
I 
DC 
F'21' 
where ... represents any set of instructions. DC stands for data constant; it 

116 
3 CENTRAL PROCESSING UNITS 
is a pseudo-operation which will be discussed presently ; it is equivalent to the 
FAP statement 
I 
DEC 
21 
Suppose we wish to put the contents of location I into register 3. We can 
use register 15, and since it contains the value FIRST + 2, the displacement 
is I-FIRST-2; thus 
L 
3,I-FIRST-2(0,15) 
is the correct instruction. There is, however, an easier way of writing this 
program, namely, 
FIRST 
BALR 
15,0 
USING 
FIRST+2,15 
L 
3,l 
USING is a pseudo-operation, which, in this example, tells the assembler 
that register 15 contains FIRST+2. In this particular case it might be 
thought that the assembler could have realized this fact, but there are many 
programs that are not so transparent. It is safer if the assembler insists on 
being given this information explicitly. Once the assembler has been given 
this information about the contents of register 15, it will accept an instruc-
tion such as 
L 
3,1 
and automatically translate it into the form 
L 
3, l-FIRST-2(0,15) 
A displacement must be between 0 and 4095, consequently in a large 
program a single-base address would not suffice. The USING operation 
can be extended to the form 
USING 
IAD,IR1,IR2,IR3 
The assembler interprets this to mean the same as 
USING 
IADJR1 
USING 
IAD+4096JR2 
USING 
IAD+8192JR3 
Any number of registers may be specified in one USING statement. If the 

3 · 11 THE IBM 360 ASSEMBLER 
117 
program is longer than 8192 bytes but shorter than 12287 bytes, then 
FIRST 
BALR 
13,0 
USING 
*,13,14,15 
would be appropriate. * denotes the current value of the location counter; it 
is another way of writing FIRST +2. The USING operation does not 
actually set the values in the registers. It would be necessary to do this by 
the following. 
Operation 
Comment 
L 
14,F'4096' 
R14 = 4096 
L 
15,14 
R15 = R14, 
AR 
14,13 
Ri4 = Ri3+Ri4, 
AR 
15,14 
R 1 5=R 1 4+R 1 5 
If the contents of the registers are changed by the program, then another 
USING operation conveys the change to the assembler, or a 
DROP 
IR1JR2 
tells the assembler that the prevk us values of registers IR1 and IR2 are 
not longer valid. 
Symbolic instruction can be written with either symbolic addresses 
or in the base address plus displacement form. RR instructions can only be 
in the form 
operation IR1,IR2 
RX instructions can be either 
operation 
IR1,ID2(IX2,IB2) 
or 
operation IR1,IS2(IX2) 
where IS2 denotes a symbolic address. The (1X2) can be omitted if 1X2 is 
zero. The ,IB2 can be omitted if IB2 is zero. RS instructions can have the 
form 
operation 
IR1,IR3,ID2(IB2) 
or 
operation IR1,IR3,IS2 

118 
3 CENTRAL PROCESSING UNITS 
in shift instructions the IR3, is omitted. SI instructions have the form 
either, 
operation 
ID1(IB1),I2 
or 
operation 
IS 1,12 
In some of the SI instructions the 12 field is omitted. The SS instructions 
have the form 
operation 
ID1 (IL1,IB1),ID2(IL2,IB2) 
or 
operation 
IS1 (IL1),IS2(IL2) 
In those operations that have an 8-bit I field (instead of two 4-bit fields), the 
IL2, is omitted. 
In some of the machines that we have discussed so far it has been 
convenient to use octal notation. In the 360 a 4-bit grouping is more 
appropriate and the 360 manuals use the hexadecimal notation. This 
notation is based on powers of 16. The digits are 0,1,2...,8,9,A,B,C,D,E,F. 
The digit A corresponds to ten decimal. B corresponds to eleven decimal. If 
dn ... d0 denotes a string of hexadecimal digits then it represents the 
number 
dnx 16« + </„_! x \6n~l +dQ 
thus 
7516 - 710 x 1610 + 510 = H7 1 0 
and 
C216 = 12 1 0x 1610 + 2 1 0 = 19410 
The use of hexadecimal digits to represent the contents of memory is 
convenient because it fits in with bytes and with binary coded decimal 
representations. 
The 360 pseudo-operation DGcorresponds to the DEC, BCD, and 
OCT of the FAP assembler. DC stands for define constant. A simple 
example of the DC pseudo-operation is 
X 
DC 
D'1.25,1.784' 

3 · 11 THE IBM 360 ASSEMBLER 
119 
The D indicates that the data is double-word floating-point data. The 
assembler ensures that the address of location X is a multiple of 8 (it leaves 
empty bytes if necessary); it assembles one double word containing the 
constant 1.25 and the next double word with the constant 1.784. The 
address of this constant is X + 8, since a double word takes eight bytes. 
The general form of the pseudo-operation is 
label 
DC 
ntm'data' 
or 
label 
DC 
ntm(data) 
The label may be omitted. If it is present, then it refers to the first byte of 
the first word of data, t specifies the type according to the following listing: 
t 
type of constant 
C 
8-bit code for each character 
D 
64-bit floating point 
E 
32-bit floating point 
F 
32-bit fixed point 
X 
4-bit code for each hexadecimal digit 
H 
16-bit fixed point 
P 
4-bit binary coded decimal for each digit 
Z 
8-bit zoned decimal digits 
A 
a 32-bit word containing an address 
V 
a 32-bit word containing an external address 
The first part of a DC statement can be used to specify a repetition factor, 
as in the example 
DC 
3D'1.25,1.784' 
which means the same as 
DC 
D'1.25,1.784,1.25,1.784,1.25,1.784' 
The m part of the DC statement can specify a modifier that changes the 
length or the scale of the data that follows. Some examples of other types 
of DC statements are 
DC 
C'TOP OF PAGE' 
which stores the twelve characters in a 12-byte field. 
DC 
F'-621' 

120 
3 CENTRAL PROCESSING 
UNITS 
which puts a 32-bit binary integer in a 4-byte field. 
DC X'127FAF0V 
which puts eight hexadecimal characters in a 4-byte field. 
DC 
A(FIRST+4096,FIRST+8192,I+J-K) 
which stores the address FIRST+ 4096 in one four-byte word. The 
address FIRST+ 8096 goes in the next word and the address I + J —K 
goes in the third word. 
DC 
D'1.275E6' 
which generates one double word containing the floating-point representa-
tion 1.275E 6. The assembler always ensures that the first byte of an 
H-type constant does occur at an even address. E,F,A, and V constants 
have an address that is a multiple of four and D-type constants start at an 
address that is a multiple of eight. 
An alternative way of setting constants is to use a literal. Suppose 
it is necessary to pick up the number —265 into register 4; this could be 
done by 
L 
4,CONA 
CONA 
DC 
F-265' 
An alternative way uses a literal : 
L 
4, = F'-265' 
A literal consists of an equals sign followed by any string of characters 
that could form the operand of a DC statement. The assembler chooses 
some locations at the end of the program and places the define constant 
information there. It also places the address of the first of the locations in 
the address where the literal occurred. Another example of the use of a 
literal is 
BALR 
13,0 
USING 
8,13,14,15 
S 
LM 
14,15,=A(S+4096,S + 8192) 
which puts S + 4096 in register 14 and S + 8192 in register 15. An alterna-
tive method of achieving this result was given when we discussed the 
USING statement. 
The pseudo-operation DS corresponds to the pseudo-operation 
BSS which appears in other assemblers. DS stands for define storage. It 

3 · 12 CONCLUSIONS 
121 
has the same form as the DC statement, except that " data " part of the 
statement is usually left blank. 
Y 
DS 
12D 
makes the address of Y a multiple of eight and would then leave bytes Y 
through Y + 95 empty. The general form of the DS statement is 
DS 
nt 
which reserves space for n variables of type /. It is sometimes convenient 
to include data. For example 
DS 
C TOP OF PAGE' 
does not store the characters TOP OF PAGE, but it does reserve 12 bytes 
of memory. The same effect results from 
DS 
CL12 
and this would be the normal way of using the DS statement. 
In Section 2.13 we illustrated the programming of the IBM 7090 
by showing how a series of numbers could be added together. The same 
problem could be solved on the IBM 360 by 
BALR 
USING 
L 
L 
A 
BCT 
ST 
DC 
DS 
15,0 
*,15 
1,LV 
2, = F'3' 
1,LV(2) 
2,LOOP 
LSUM 
R i = L V 
R2 = 3 
Ri = Rx + LV indexed by R2 
STORE RESULT 
F'21,98721,56,2781' 
F 
Some further properties of the IBM 360 and the assembler will be discussed 
in Section 6.14. 
3-12 
CONCLUSIONS 
The machines discussed in this chapter have differed markedly from the 
IBM 7090 and from each other; however, there are some basic concepts 
common to all of these machines. The memory stores information as a 
pattern of bits. The machine interprets these bits in a way that depends on 
the instructions in the program. The FAD instruction on the 7090 causes 

122 
3 CENTRAL PROCESSING 
UNITS 
the machine to regard a pattern of 36 bits as a floating-point binary 
number, whereas ADD causes it to manipulate the bits as a binary integer. 
The bits in the memory are organized into groups. On the IBM 7090, the 
CDC 1604, and many other machines, the group is called a "word." On 
the IBM 1620 and the 1401, the group is called a "character." On the 
IBM 360 the basic grouping of bits is either a "byte" or a "word," 
depending on the operation in which it is used. The large scientific 
computers have fixed-point and floating-point binary arithmetic operations. 
The numbers that are used in these instructions are of a fixed length. On 
the IBM 7090 the fixed length is 36 bits. On the CDC 3600 it is 48 bits or 
96 bits. On the CDC 6600 it is 60 or 120 bits. On the IBM 360 it is 32 or 
64 bits. An alternative way of doing arithmetic is possible. The IBM 1620, 
the IBM 1401, and some models of the IBM 360 can do decimal arithmetic 
on numbers of varying lengths. The length of the number is specified either 
in the representation of the number (flag bit or word mark method) or in 
the instruction itself. Decimal numbers waste memory space. It takes 
four bits to represent one decimal digit, whereas in the binary system four 
bits could represent any one of 16 different numbers. The binary represen-
tation is 16/10 times more efficient than the decimal representation, but 
there are data processing problems in which the use of a fixed word length 
is inefficient. 
Data words in the memory of a machine like the IBM 7090 or the 
CDC 3600 usually represent binary integers or floating-point numbers; 
however, they can carry any meaning which the programmer cares to 
attach to them. With the use of logical and shifting instructions, the 
program can manipulate single bits. It would be possible, though in-
efficient, to simulate decimal arithmetic on one of these machines. One 
common use of the logical and shifting instructions is to manipulate groups 
of 6 bits which represent alphanumeric characters. The IBM 1401, IBM 
1620, and IBM 360 have instructions that allow the direct manipulation of 
characters. 
Machine instructions are represented by a pattern of bits. On the 
IBM 7090 each instruction is one word; on the CDC 1604 it is a half word, 
on the CDC 3600 it is a half or a whole word, on the IBM 360 it is 2,4, or 
6 bytes. The faster machines have several special registers in addition to the 
ordinary memory locations. The 7090 and the 3600 have one accumulator. 
The 360 has 16 accumulators for integers and four accumulators for 
floating-point numbers. The provision of several registers saves time and 
memory space because the intermediate results need not always be stored 
in memory. The early computers concentrated on one instruction at a time. 
Later computers were able to overlap computing and I/O operations. The 
CDC 6600 (and some models of the IBM 360) can overlap several com-
puting operations. The 6600 has ten functional units and can obey several 
instructions at once. The correct sequencing of the instructions is carried 
out by the hardware. The presence of several functional units does not 

PROBLEMS 
123 
make it any more difficult to write correct program, though it can make it 
more difficult to achieve optimum efficiency. 
The contents of the memory is accessed by giving an address. The 
words, characters, or bytes of the memory are numbered successively; an 
address is the same as a location number. The actual address of the data to 
be used is usually made up from the address part of the instruction and from 
the contents of an index register. Index registers are used in counting 
through loops, and they provide an efficient way of accessing successive 
elements of an array. Many computers modify an address by using a single 
index register but some computers use two index registers in one instruction. 
Most machine instructions carry out a very simple operation such 
as adding two numbers together or transferring a number from one part 
of the machine to another. The compilation of a statement such as 
X S U M - X S U M 4-X* Y 
is divided into several phases. The compiler has to rearrange the statement 
to fit it in with the machine instructions. The rearrangement might be of 
the form, take X, floating-point multiply by Y, add XSUM, and store the 
result in XSUM. The transition to actual machine instructions varies from 
machine to machine, but is a straight-forward operation. Surprisingly 
enough, the question of where to store Y,X, and XSUM is quite complex. A 
simple compiler might assign X to the first available location, Y to the next 
available location, and so on. In most current compilers this simple 
procedure is not used because the information required for assigning 
memory is not available at compile time. The Fortran compilers usually 
assign tentative locations at compile time and the addresses are relocated— 
that is, they are changed to their final values—at loading time. Certain 
addresses, namely the address of subroutine arguments cannot be assigned 
until execution time. There are Fortran compilers which do not use 
relocation (see, for example, Rosen et al, 1966), but they cannot cope with 
very large programs. The Algol compilers usually use dynamic memory 
allocation for all variables. A memory address is assigned just before a 
variable is used. This method results in a much more efficient use of 
memory than the Fortran method, but it can waste time. PL/1 uses both 
the static method of Fortran and the dynamic method. 
PROBLEMS 
1 ■ Write a Fortran program to read a decimal number X and to print out 
the floating-point binary representation of X. If your program is 
written in Fortran on the IBM 7090 or CDC 3600 (or similar 
machines), then print the IBM 360 representation of X. If you use 
the 360, print the 7090 binary representation. It is suggested that your 
answer will use a format of the form 3211 or 3611. 

124 
3 CENTRAL PROCESSING UNITS 
2 · Ι η the 7090, a 15-bit address was used to specify any one of 215 
locations. In other machines, does a memory of size 2" always need an 
address of n bits ? Give one or more examples. 
3 ■ Explain two methods of representing negative numbers. 
4 ■ McCracken (1965) (page 126) gives a Fortran program for converting 
from ordinary notation to reverse Polish. Modify that program so that 
it would compile an expression such as 
X=(A+B)*(C+D) 
into the assembly language statements for the KDF9 which were given 
in Section 3.7. 
5 ■ On the IBM 7090, the calculation 
X+A*B + C*D 
would take approximately (3/ + 2m + n) microseconds, where / is the 
time to load one number into the arithmetic unit, m is the time to 
multiply two numbers, n is the time taken to add two numbers. How 
long would the calculation take on the CDC 6600? Explain why. 
6 ■ Write two Fortran routines called IN and OUT that put a variable 
into a stack and take a variable from a stack, respectively. See Section 
3.7 for the definition of a stack. Use 
COMMON NIN, STACK(1000) 
where STACK holds the stack variables and NIN denotes the number 
of variables in the stack. There are two possible methods of imple-
mentation. In the first method, CALL IN (X) sets NIN = NIN+1, 
STACK(NIN) = STACK(NIN -1), 
... 
STACK(2) = STACK(l), 
STACK(1) = X. In method two, CALL IN(X) sets NIN = NIN +1 and 
STACK(NIN) = X. With suitable definitions of OUT, show that the 
two methods produce the same result. 
7 ■ Extend question 6 by simulating the addition, subtraction, multiplica-
tion and division of the top two entries in the stack. 
8 ■ Consider a Fortran program such as 
DO 
100 
11=1,N1 
DO 
101 
12=1, N2 
101 
CONTINUE 
DO 
103 
I3=1,N3 
DO 
104 
I4=1,N4 
104 
CONTINUE 
103 
CONTINUE 
100 
CONTINUE 

P R O B L E M S 
125 
Whenever the Fortran compiler finds a DO statement, suppose it puts 
the statement number into a stack. Whenever the compiler finds a 
CONTINUE, suppose it takes one number from the stack. Show that 
the statement number taken from the stack agrees with the statement 
number on the CONTINUE card. 
The following problems are concerned with the IBM 360. 
9 ■ S denotes subtract. What do the following instructions do? 
S, SR, SD, SDR 
Give the reasons why the instruction SR 4,4 would set R4 equal to 
zero. 
10 ■ Is L an RX or an RR type of instruction? In the symbolic instruction 
L 
l,m(p,q) 
which part of the instruction specifies the first operand ? Which parts 
specify the second operand (see Section 3.11 on the form of symbolic 
instructions)? What is the base, the index and the displacement of the 
second operand ? How is the address of the second operand found ? If 
Rt contains 10,000, R2 contains 20,000 and R3 contains 30,000, what 
is the effect of 
L 
1,512 (2,3) 
L 
1,512 
L 
1,512 (2) 
LD 
2,512 (2,3) 
LDR 
2,4 
ADR 
2,4 
ADR 
2,2 
11 ■ How many bits are in a byte ? How many bytes in a word ? How many 
characters can be contained in one word? Suppose R2 = 10,000: 
L 1,700 (2) picks up one word consisting of four bytes. Give the 
addresses of these bytes. 
12" How many bytes does an RR instruction take ? How many bytes does 
an RX, an RS, an SI, and an SS instruction take? Give one example 
of each type of instruction and explain what it does. Pay particular 
attention to what sort of argument it uses. 
13 ■ Take the program given at the end of Section 7.11 and assemble it, do 
the assembly by hand, do not use the machine. Assume that the 
unspecified part of the program (the part indicated by ...) takes 300 
bytes. Do you need to know the location of the first instruction or is 
your assembly independent of an origin ? 

126 
3 CENTRAL PROCESSING UNITS 
14 ■ Give the floating-point binary representation of the following numbers. 
1.0, 0.5, 0.25, 0.125, 0.0625, 0.03125. Show that on the IBM 7090 
adding 0.25 to 0.25 requires a normalization at the end of the addition. 
Show that in this case no normalization is necessary on the IBM 360. 
15 ■ Write DC statements that define the following quantities. 
(a) A 32-bit integer I with the value 927. 
(b) Three 64-bit floating-point variables whose values are 1.25, 
1,000,000.0 and -97.25. 
Three numbers are stored in three successive words. The first word 
has the label X. Will the following program add the three numbers 
together? 
LD 
2,X 
A 
2,X+1 
A 
2,X+2 
If the program is wrong, what is the correct program ? 
16 ■ A Fortran compiler encounters the statements 
DOUBLE PRECISION 
P 
DIMENSION 
P(100,200), L(27), Q(91) 
Give the define storage assembler instructions that would allocate 
20,000 double words to P, 27 single words to L, and 91 single words 
toQ. 
17 ■ A Fortran compiler encounters the statement 
500 
FORMAT(9H ANSWER-F12.6) 
The compiler has to generate an assembly-language statement that 
causes the information between the parentheses to be saved. What 
assembler statement will be used ? 
18 ■ Explain the difference between an address and a value. Does the 
Fortran statement 1 = 1+1 change the value of I ? Does it change the 
address of I ? Does it change the contents of location I ? 
19 ■ Repeat Question 15 of Chapter 2. Annotate the assembly-language 
program showing which instructions correspond to which statements. 

4-1 
CHARACTER SETS and 
IDENTIFIERS 
Algorithms written in mathematical nota-
tion use symbols and conventions that do 
not usually appear in compiler languages. 
The mathematical equation 
*'=J 
\b+f{ct)] sin (-y it) dt 
illustrates some of these features. In com-
piler language the first term would prob-
ably appear as ABAR(I). The reason for 
writing it in this form is simply one of 
convenience and economy. There are type-
writers and card punches with an extensive 
set of symbols and the ability to print 
subscripts and superscripts (see Klerer and 
May (1965)) but they are expensive and not 
always easy to use. The most commonly 
used character set is the Fortran set which 
is available on the IBM 026 card punch. 
4 
COMPILER 
digits: 
0,1,2,... ,9 
letters: 
A,B,C,D,...,Z 
special characters : . H 
* / = ( ) $ , 
It is regrettable that a wider set is not 
commonly available. In Fortran the string 
of characters ABAR would be called a 
variable name, but we will use the more 
appropriate term "identifier" which origi-
nates from Algol. Compilers use several 
characters to represent 
one 
identifier 
because one character would be too 
limiting. The right-hand side of the above 
expression might be written 
(B + F(C*T))* SIN(-GAMMA(I)*T) 
The term ct is written as C*T to avoid con-
fusing it with the identifier CT. The * in 
front of the SIN could be omitted without 
causing any ambiguity, but most compilers 
insist on the presence of the operator so 
127 
LANGUAGE 

128 
4 COMPILER 
LANGUAGE 
that they can easily check the syntax. The Fortran character set has only 
one set of parentheses which have to be used for three different purposes : 
first, to indicate a subscript; second, to indicate the argument of a function; 
and third, to represent the grouping of terms in an expression. The 
compiler distinguishes the various uses by looking at the context. If the 
opening parenthesis is preceded by an operator or an equals sign, then it 
corresponds to the third usage. If the preceding identifier has appeared in 
a DIMENSION statement (or its PL/1 equivalent), then the parenthesis 
indicates a subscript; otherwise it indicates a function argument. Suppose 
the DIMENSION statement for the identifier GAMMA of the above 
example happened to be omitted. The compiler would assume that 
GAMMA was a function. If GAMMA happened to appear on the left-
hand side of an equals sign at some other point in the subroutine, then 
the compiler would realize that an error had occurred, but in general the 
compiler would not detect the error. When compiling and assembly are 
complete, and when loading is almost complete, the loader finally finds 
that the function GAMMA has not been defined. Algol insists that the 
subscript bracket should be a différent character from the function 
bracket. It uses ( for the function argument and [ for indicating subscripts. 
To return to the mathematical equation, there is no compiler equivalent of 
the mathematical integral sign because no efficient universal method of 
integration can exist. The integration can be done by calling some suitable 
subroutine. 
The general principles of expressing an algorithm in compiler 
language are similar in Fortran, Algol, and PL/1. Fortran uses the 48-
character set. An identifier is one letter, or one letter followed by more 
letters and/or digits. Fortran IV has limits of six characters in an identifier, 
but some other Fortran compilers are less restrictive. The first version of 
Fortran ignored all spaces (except in Hollerith strings), and subsequent 
compilers have retained this unfortunate rule. It is unfortunate because it 
wastes time when the compiler has to scan the statement. Fortran has the 
characters + — * and / to represent the arithmetic operators but it lacks 
such symbols as <. It uses the string .LE. to represent <, and similar 
strings for the other inequality signs. The point before the LE is necessary 
in order to separate the symbols from the preceding identifier. Statements 
in Fortran can be labeled by putting a statement number in the first five 
columns of the card. In Fortran IV one statement is written on one card. In 
Fortran 63 on the CDC 1604 and 3600, several statements can be written 
on one card providing they are separated by a $ sign. 
PL/1 uses either the 48-character Fortran set or an extended set 
of 60 characters. An identifier is one letter or one letter followed by more 
letters and/or digits. There is a limit of 31 characters. The Fortran rule of 
six characters in one identifier stems from the fact that six characters could 
be represented in one IBM 704 word. The IBM 360 has no such limita-
tion. Fortran was designed for card input, hence the rule that statement 

4 · 1 CHARACTER SETS AND IDENTIFIERS 
129 
numbers go in the first five columns and the fact that the end of the card 
indicates the end of the statement. These rules are not particularly con-
venient for card input and they are quite inconvenient for other forms of 
input. PL/1 separates statements by a semicolon (;). PL/1 does not use 
statement numbers; it uses identifiers as statement labels. The label 
precedes the statement and is separated from it by a colon. The Fortran 
statements 
IF(X.LE.Y) 
GO TO 99 
99 
P = Q 
could be written in PL/1 as 
IF( X LE Y ) THEN GO TO GREAT; 
GREAT: P = Q; 
PL/1 does recognize spaces, consequently it can scan a statement more 
efficiently and it can allow symbols such as LE. LE is separated from the 
previous identifier by a space. 
Algol was designed with no particular machine in mind and does 
not insist on a particular character set. The reference language uses a set 
of 91 characters and most published algorithms use this set. An actual 
compiler can use any character set as long as it preserves the distinctions 
between different symbols. For example, the reference language uses 
( and [. A particular hardware representation cannot use ( to correspond 
to both the ( and the [ of the reference language. The Algol compiler on 
the CDC 1604 uses the Fortran character set. It uses the two characters (/ to 
represent [ , and the characters /) to represent ]. The reference language 
uses a character set that includes symbols such as g, the 1604 compiler 
uses LE in place of ^ . In Algol a statement label can be either an identifier 
or a number, but in most Algol compilers a label must be an identifier. The 
label is separated from the statement by a colon. The end of a statement is 
indicated by a semicolon, or in some cases by the word "end." An 
identifier is either a letter or a letter followed by more letters and/or digits. 
There is no official limit to the number of characters, although some 
compilers do insist on a limit. 
An arithmetic statement such as 
ALPHA = BETA-GAMMA**2/(A+B(I,J)) 
has the same form in Fortran, Algol, and PL/1. Some versions of Algol 
use a different character set; for example | is used in place of **, but the 
form of the statement is unchanged. Fortran IV is more restrictive than 
the other languages; it is also more restrictive than many of the Fortran 

130 
4 COMPILER 
LANGUAGE 
compilers on computers other than IBM machines. It does not allow 
integer and real variables to be mixed in one expression and it insists that 
subscripts be of a very simple form. 
4-2 
DECLARATIVE STATEMENTS 
An identifier can be used to denote several different types of quantities. The 
programmer has to make a declaration that specifies the type. As we 
have seen, the computer can do both integer and floating-point arithmetic. 
There are few problems in which integer arithmetic is absolutely necessary, 
but the machine works more efficiently if the integer representation is used 
for subscripts and for counting through loops. In Fortran and Algol the 
declaration INTEGER implies the integer representation, and REAL 
implies the floating-point representation of a variable. Fortran has the 
additional types DOUBLE, COMPLEX, and LOGICAL. A type DOUBLE 
variable is represented by a two-word floating-point number. The CDC 3600 
and the IBM 7094 are two of the machines that can do double-word as well 
as single-word floating-point arithmetic. The IBM 7090 cannot do double-
word arithmetic directly but the compiler can accept the type DOUBLE 
declaration. It performs each double-length operation by doing several 
single-length operations. In most machines the double-length operations 
are slower, and the variables take up twice as much space, but the extra 
precision is necessary in parts of some calculations. A COMPLEX number 
is also stored in two words. One word represents the real part and one 
word represents the imaginary part. If B and C are two COMPLEX 
variables, then the expression B + C causes the compiler to generate 
instructions to add the real and to add the complex parts. 
An IF statement might be written IF(X.LE.Y). The expression in 
the brackets is a logical expression ; it can have the value true or the value 
false. It is a natural extension of this to introduce the LOGICAL variable, 
and such statements as 
l = X . L E . Y 
which sets I to the value true if X is less than or equal to Y, and sets I to 
the value false if X is greater than Y. A logical variable is also stored in a 
whole word, although only part of the word is used. Algol has the type 
BOOLEAN which corresponds to the Fortran LOGICAL. PL/1 has the 
type BIT which also corresponds to the Fortran LOGICAL. 
The first version of Fortran was designed for describing numerical 
calculations. Later versions introduced the DOUBLE and COMPLEX 
options because several users had programs that required them. Problems 
that require multiple-precision arithmetic, double-precision complex 
numbers, or any of the many other different types of arithmetic cannot 

4 · 2 DECLARATIVE STATEMENTS 
131 
easily be coded in Fortran. The user has to write routines to suit his 
problem. The designer of PL/1 tried to introduce a language that would 
fill all these gaps. It is true that not many problems require multiple-
precision arithmetic, but it is easy to allow such features if they are 
introduced in the design stages of the language. The availability of both 
binary and decimal arithmetic on the IBM 360 and the hope that PL/1 
would be used for both commercial and scientific problems also prompted 
the designers to allow a wide variety of types. In PL/1 a number may be 
FIXED type or it may be FLOAT type. In the former case it is represented 
by an integer and in the latter case it has a floating-point representation. A 
number may be BINARY or DECIMAL. Most scientific problems use 
the binary mode since it is more efficient. Typical of the problems that 
might use the decimal mode are simulations of a decimal computer or 
certain types of data processing. A number may be REAL or COMPLEX. 
Notice that PL/1 uses REAL to denote the alternative to COMPLEX 
whereas Fortran and Algol use it as the alternative to INTEGER. PL/1 
allows the programmer to specify any degree of precision. Most scientific 
problems use FIXED BINARY REAL variables with a precision of 32 
bits or FLOAT BINARY REAL variables with the precision of 32 or 
64 bits. Other precisions might be used to get a higher accuracy, to simulate 
other computers, to examine the effects of calculations of different 
precisions, and so on. The straightforward options produce efficient 
programs, whereas the precisions that are not either 32 or 64 require the 
compiler to produce many instructions for each operation. 
In Algol the types of all identifiers must be stated explicitly. Fortran 
and PL/1 allow the type to be stated implicitly. This saves the programmer 
a great deal of writing. In Fortran, if the identifier begins with the letter 
I,J,K,L,M, or N, then the compiler assumes that it has type INTEGER. If 
it begins with any other letter, then the type is REAL. PL/1 has similar 
rules. The initial letters I through N imply REAL FIXED and the initial 
letters A through H or O through Z imply REAL FLOAT. In both 
Fortran and PL/1 these implicit rules are used if, and only if, the identifier 
has not appeared in a type statement. 
When an identifier is the name of an array, then the size of the 
array must be stated explicitly. The statement 
DIMENSION 
A(27),B(10,21 ) 
illustrates the Fortran method of specifying arrays. The statement tells the 
compiler to reserve 27 words (or 54 words if A is DOUBLE or COMPLEX) 
for A and 210 words for B. It also indicates to the compiler how to compute 
the address of A(I) and B(I,J). The corresponding Algol declaration might 
be 
array A(-6 :20),B(5:14,21) 

132 
4 COMPILER 
LANGUAGE 
Fortran places a lower bound of unity on all subscripts. Algol allows the 
subscripts to start at any value. In this example the array A has the 
elements A(-6), A(-5),...,A(-1), A(0),A(1),...,A(20) a n d t h e a r r a y 
B 
has the elements B(5,l), B(5,2),...3(5,21)3(6,1),...,B(14,21). The PL/1 
statement 
DECLARE 
A(-6:20),B(5:14,21) 
has the same meaning as the Algol statement. 
In the rest of this chapter we will discuss the assembler-language 
representation of some simple compiler statements. Fortran is the most 
restrictive and the simplest of the three languages and we will use it in 
our examples. The extension of the ideas to the other languages is quite 
simple except where dynamic storage allocation is concerned. As we have 
seen, the three languages use differing notation but the basic ideas are 
similar. 
4-3 
FORTRAN into ASSEMBLY LANGUAGE 
In Section 1.6 we described the several stages that occur between the 
reading of the Fortran statements and the actual execution of machine-
language instructions. In the first stage the compiler translates the Fortran 
statements into assembly-language statements. A Fortran program consists 
of one or more Fortran routines together with routines from the library 
tape. We use the word "routine" to describe subroutines, function 
subroutines, and the main-program routine. Each routine is compiled 
independently of all other routines. The compiler has knowledge about the 
routine it is compiling and no knowledge of any other routine. In particular, 
the compiler does not know how much memory space the other routines 
will use. The compiler and the assembler assume that the current routine 
starts at location 0, but they assemble a list of which addresses will need 
changing if the origin is moved to some other location. This list is called 
the relocation information. At a later stage, the loader decides where to put 
each routine and performs the relocation. 
In Chapter 2 we introduced a notation for describing machine 
language instructions on the IBM 7090. The symbols a, m, c, il, i2, and 
so on, refer to the accumulator, the MQ register, the control register, index 
register 1, index register 2, and so on. Here we will use " in " to denote any 
one of the index registers. These symbols cannot be confused with Fortran 
symbols because the latter symbols can only contain capital letters. A 
symbol such as N or ALPHA was used to denote the name of a location, and 
m (ALPHA) was used to denote the contents of memory location ALPHA. 

4 · 3 FORTRAN INTO ASSEMBLY LANGUAGE 
133 
For example in the program 
ORG 
64 
ALPHA 
DEC 
1.25 
CLA 
ALPHA 
ALPHA has the value 64, and m(ALPHA) is 1.25. Thus CLA ALPHA is 
the same as CLA 64. We described some machine language instructions; for 
example, 
CLA X 
is the instruction which sets 
a=m(X) 
STO 
Y 
is the instruction which sets 
m(Y)=a 
The corresponding instructions for the CDC 1604 are LDA and STA. 
Let us consider a simple Fortran statement such as 
X=Y 
Each scalar REAL or INTEGER Fortran variable (that is, each variable 
that is not dimensioned) is allocated one location in the core memory. An 
obvious way of attaching variables to locations is to allocate the Fortran 
variable X to the location that has the name X. Since X is used in two 
different ways we should be careful when using phrases such as " the value 
of X." In the example given above, the assembler symbol ALPHA has 
the value 64, the Fortran variable ALPHA has the value 1.25. The Fortran 
statement given above can be translated into the two machine-language 
instructions 
a = m(Y) 
m(X) = a 
The compiler makes a list of all the variables used in a subroutine and at 
the end of the compiled instructions it puts a list of BSS instructions. The 
pseudo-instruction BSS tells the assembler to reserve a certain amount of 
space. In the simple example given above the compiler would generate 
X 
BSS 
1 
Y 
BSS 
1 
A Fortran statement such as 
X = Y + 22.6 
would cause the compiler to generate the instructions 
a = m(Y) 
a = a + m(=22.6) 
m(X) = a 
= 22.6 is an example of a literal; see Section 2.14. 

134 
4 COMPILER LANGUAGE 
Fortran floating-point variables are stored as 
floating-point 
numbers. Integer variables are stored as integer variables. Fortran II stores 
integer variables in an unusual way. If J has the value 99 then Fortran II 
puts the number 99 times 2**18 in location J. The reason for this is purely 
historical; the IBM 704 had an instruction SXD that could store 
the contents of an index register in the decrement part of a location. The 
704 did not have the instruction SXA that stores an index register in the 
address part of an instruction; consequently integers were stored in the 
decrement; that is, they were shifted 18 places to the left. This peculiarity 
of Fortran II causes no change in addition or subtraction, but it introduces 
extra shifting into multiplication and division. It did have the disadvantage 
that Fortran II has to limit integers to be less than 218 — 1. 
The rules for translating any simple arithmetic statement should 
now be obvious; for example 
ALPHA = X + BETA*(C - DODO) 
would be translated into 
a = m(C) 
a = a- m(DODO) 
q = a 
a — <7*m(BETA) 
a = a + m(X) 
m(ALPHA) - a 
The corresponding six machine-language instructions can be found by 
referring to the list of machine instructions. Here are examples for two 
particular machines : 
IBM 
CLA 
FSB 
XCA 
FMP 
FAD 
STO 
7090 
C 
DODO 
BETA 
X 
ALPHA 
CDC 
LDA 
FSB 
FMU 
FAD 
STA 
1604 
C 
DODO 
BETA 
X 
ALPHA 
The compiler automatically makes the correct choice between fixed- and 
floating-point arithmetic. For example, 
X = Y + Z 
causes it to use an FAD instruction for the addition, whereas 
I = J T K 

4 - 3 FORTRAN INTO ASSEMBLY LANGUAGE 
135 
causes it to use ADD. The compiler also recognizes the exceptional case 
x=i 
In Fortran II on the IBM 7090 this generates 
CLA 
I 
ARS 
18 
ACL 
= 0233000000000 
FAD 
- 0 . 0 
STO 
X 
The way in which these five instructions translate an integer into a floating-
point number was explained in Section 2.12. The Fortran IV code for 
X = I is given in Section 4.11. 
It is possible to mislead the compiler. For example, consider the 
following. 
EQUIVALENCE 
(l,Z) 
1 = 3 
X = Z 
The equivalence statement tells the compiler to attach the names I and Z to 
the same location. The compiler generates the program 
m(I) = a 
a = m(Z) 
m(X) = a 
Since I and Z are the same location, this code puts the integer 3 into I and 
into X. The integer 3 is not translated into floating-point form before 
storing it in X. There are occasions in which this device is useful. 
The Fortran 63 compiler allows mixed-mode arithmetic; for 
example, 
X = P + L 
is legitimate in Fortran 63, but not legitimate in Fortran II or Fortran IV. 
Fortran 63 treats this statement by picking up the integer L and converting 
it into floating-point form. It then does a floating add of P and stores the 
result in X. The same sequence could have been done in Fortran IV, but the 
designers of the compiler decided not to allow this option. Mixed arith-
metic is useful in some circumstances, although it may lead to errors when 
the division instruction is used. The program 
1 = 4 
J = 3 
K = 6 
L = I * J / K 

136 
4 COMPILER 
LANGUAGE 
may set L equal to zero and not 2, as might be expected. The reason for 
this is that the compiler may generate the code corresponding to "4 
divided by 6 and the result to be multiplied by 3." In integer arithmetic, 
4 divided by 6 is zero. Programmers will learn to avoid such obvious traps, 
but they may not recognize a similar situation in the middle of a complicated 
mixed-mode statement. 
It should be realized that the integers appearing in Fortran are 
meant to be used as counters or as subscripts. Index registers are the most 
efficient registers for counting and subscripting. Index registers cannot use 
floating-point numbers. In the interest of efficiency, the designers of 
Fortran allowed a type of variable, the integer variable, that could be 
manipulated in an index register. There are a few problems for which the 
mathematical concept of an integer is appropriate. It is a coincidence that 
Fortran can handle such problems. There are other, equally important types 
of calculation for which Fortran provides no facilities. 
4-4 
TYPES of VARIABLES 
In Fortran II a variable was integer if it began with one of the letters I 
through N, otherwise it was floating. Fortran 63 and Fortran IV allow the 
type of the variable to be declared explicitly. A Fortran IV type statement 
has the form INTEGER followed by a list of variables that are to be 
treated as integers, or REAL followed by a list of the floating-point 
variables. If a variable does not appear in such a list, then the Fortran II 
method of allocating types is used. As the compiler is going through a 
program it makes up a list of the integer names and a list of the floating-
point names. When any variable is used in a statement, it checks through the 
list to find out if it is an integer or a floating-point variable. 
In addition to REAL and INTEGER, Fortran IV allows the 
DOUBLE PRECISION, LOGICAL, and COMPLEX types. Fortran 63 
allows the same five types. The actual type statements are slightly different. 
The Fortran IV statement, 
INTEGER 
A,ZOO,GAMMA 
would be written as 
TYPE INTEGER 
A,ZOO,GAMMA 
in Fortran 63 but the effect is the same. A complex number occupies two 
adjacent words in the memory. If A and B are complex variables, then 
A = A + B 

4 · 5 SUBSCRIPTED VARIABLES 
137 
causes the compiler to add the real and imaginary parts; thus 
a = w(A) 
a = a + w(B) 
m(A) = a 
a = w(A + 1) 
Ö == a + w(B + 1) 
m(A + 1) = a 
Location A contains the real part of A and location A + 1 contains the 
imaginary part. A double-precision number also occupies two adjacent 
words. The compiler generates the instructions to do all the arithmetic on 
these numbers in double precision. In Fortran IV single-length numbers 
are accurate to one part in 227 and double-length numbers are accurate to 
one part in 254. In Fortran 63 single-length numbers are accurate to one 
part in 236, and double-length numbers are accurate to one part in 284. 
Fortran 63 has an 11-bit characteristic and a 36-bit fraction in the first 
word of a double-precision number; it has a 48-bit fraction in the second 
word. Fortran IV has a 9-bit characteristic and a 27-bit fraction in both 
words. 
4"5 
SUBSCRIPTED VARIABLES 
A typical Fortran dimension statement is 
DIMENSION 
A(120),B(21,4,3),LAKE(20,10) 
We will restrict the discussion to Fortran 63. The slight differences in 
Fortran II and Fortran IV will be explained later. Fortran allocates a 
contiguous block of locations to each variable; thus 
A 
BSS 
120 
B 
BSS 
252 
LAKE 
BSS 
200 
It will be remembered that the pseudo-instruction BSS tells the assembler 
to reserve a certain amount of the memory: the first of the instructions 
reserves 120 locations, and the first of these locations has the name A, the 
next A + 1 , and so on. In the translation from Fortran to symbolic 
language, the compiler associates the Fortran variable A(l) with the 
location A, it associates A(2) with A + 1 , and it associates A(I) with the 
location A+ 1—1. B(I,J,K) is associated with the symbolic location 
B + I-1+(J-1)*21+(K-1)*21*4. LAKE(I,J) is associated with the 
location LAKE+I— 1 + (J —1)*20. The compiler does not check the size of 
a subscript; for example, it would not object to the use of the subscript 

138 
4 COMPILER 
LANGUAGE 
A(199) although this is obviously out of bounds. The compiler could be 
made to check the range of a subscript, but to be of any value this would 
have to be done during the execution of the program, and checking at 
execution time would make the program appreciably slower. Simple errors 
such as A(199) could, of course, be checked during compilation, but the 
usual cause of subscript errors is the variable subscript such as A(I), in 
which the computed value of I happens to be greater than 120. If a sub-
script is too large, then it usually causes some disastrous error. A statement 
such as 
A(l) 
- 2 . 5 5 
causes the number to be stored in location A(I). If I is less than 121, then 
all is well. If I is greater than 120, then the result is unpredictable. The 
number 2.55 may overwrite a number in the B array or in the LAKE array 
or it may overwrite one of the instructions of a subroutine. If 2.55 over-
writes a variable, then the answers will be wrong; if it overwrites a part of 
the program, then when this part of the program is executed, the program 
either stops or goes out of control. 
The instruction LDA A is the instruction on the CDC 1604 which 
sets the a = m(A). If index register 2 contains the number n, then LDA A,2 
sets a = m{K -f n); it will be convenient to use the notation m(AJ2) to 
denote the quantity m(A + n). That is, A,/2 will denote the location (A + 
the contents of index register 2). A similar notation will of course apply to 
the other index registers. Consider the Fortran statement, 
X = A(l + 6 ) + A ( l - 2 ) 
this is translated into the following machine-language statements : 
il = m(I) 
a = m(A + 5,i2) 
a = a + m(A — 3,/2) 
m(X) - a 
One of the points to notice is that only one index register is needed. The 
compiler computes the address A + 5 and the address A — 3. It is not 
necessary for any address calculation to be done during the execution of the 
program. Let us suppose that I is stored in location 98, that X is in location 
99 and that A is location 100, then the actual CDC 1604 machine-language 
instructions are 
LIL 
98,2 
LDA 
105,2 
FAD 
97,2 
STA 
99 

4 · 5 SUBSCRIPTED VARIABLES 
139 
Consider the two Fortran statements 
x = A(5) 
Y = A(l) 
The first statement can be translated as 
IBM 7090 
CDC 1604 
CLA 
A+4 
LDA 
A+4 
STO 
X 
STA 
X 
It is tempting to assume that the second statement can be compiled as 
CLA 
A + l-1 
LDA 
A + l - 1 
STO 
Y 
STA 
Y 
but these instructions are not correct. Suppose that I is stored in location 
98, that A is in location 100, and that I has the value 5. Y = A(I) is supposed 
to mean the same as Y = A(5). This means that the contents of location 104 
has to be put into the accumulator. An assembler symbol such as I gives 
the address of I, it does not give the value. CLA A + I — 1 has the same 
effect as CLA 100 + 9 8 - 1 which is CLA 197. A(I) is stored in the 
location whose address is the address of A plus the value of I minus one. 
The easiest way of forming this address is to put I (or on the 7090, the 
complement of I) in an index register; thus 
LAC 
1,2 
LIL 
1,2 
CLA 
A-1,2 
LDA 
A-1,2 
STO 
Y 
STA 
Y 
There is another facet of the problem that must be mentioned. At assembly 
time, the address of I is known but the value of I cannot be known. The 
index register provides an efficient method of combining an address known 
at execution time with a value to be computed at execution time. See 
Section 6.3 for a situation where an actual address does have to be com-
puted from an address and a value. In the case of two- or three-dimensional 
subscripts, the compiler has to generate many more instructions. For 
example, 
K = LAKE(I + 3,K+1)+J 
generates the instructions 
a --
a -
a = 
m(ITEMP) = 
/4 = 
a = 
a = 
m(K) = 
= m(=20) 
= a*m(K) 
= a + m(I) 
= a 
= w(ITEMP) 
= m(LAKE + 2,/4) 
= a + mi}) 
= a 

140 
4 COMPILER 
LANGUAGE 
where ITEMP denotes some temporary storage location. The calculation 
of the two- or three-dimensional subscripts requires a fixed-point multipli-
cation. A multiplication is usually quite a slow operation; typically it 
might take three or four times as long as a fixed-point addition. The 
compiler usually tries to avoid these subscript calculations but it is some-
times not very successful. 
The statements 
l=6 
J = 3 
L=2 
DO 
100 K=1,10 
· 
100 
SUM = SUM+A(K)*B(I,J,L) 
are compiled efficiently by most Fortran compilers. The compiler notices 
that the subscript (I,J,L) can be evaluated before the DO loop is begun and 
that its value is not changed when K changes. The coding is almost identical 
with the coding produced by 
l=6 
J = 3 
L=2 
ITEMP=I + 21*J + 84*L 
K=1 
1000 
SUM = SUM+A(K)*B(ITEMP-105) 
K=K+1 
IF (K — 10) 1000,1000,100 
100 
CONTINUE 
where we now consider B as a one-dimensional array. There are, however, 
cases where the compiler can produce either inefficient or erroneous code. 
The compiler goes through the program and makes a list of all two- and 
three-dimensional subscripts. It then tries to place each subscript evaluation 
at the earliest possible place in the program. In the example we have just 
discussed, the compiler discovered that it could evaluate (I,J,L) immediately 
after the statement " L = 2." This had the effect of taking the subscript 
evaluation outside the DO loop. The following example, 
COMMON 
L 
l = 6 
J = 3 
L = 2 
CALL 
SUBA 
DO 100 
K = 1,10 
100 
SUM = SUM+A(K)*B(I,J,L) 
looks similar to the previous example, but it may contain a hidden diffi-
culty. Some compilers evaluate the subscript (I,J,L) immediately after the 

4 · 5 SUBSCRIPTED VARIABLES 
141 
statement " L = 2," and they store the result in some temporary location. 
Since L is in COMMON, there is a possibility that the value of L may get 
changed in the subroutine SUBA. If this should happen, then (I,J,L) will 
not be computed correctly; it will have been computed with the old value 
of L. In Fortran II this was referred to as a relative constant difficulty. It 
was mentioned in the Fortran manual, but it gave rise to many errors. 
To illustrate the possibilities of inefficient coding we will use an 
example from Fortran 63. The Fortran 63 compiler evaluates subscripts at 
the earliest possible moment; however, it often evaluates subscripts that 
are never used. In the program 
1 
|=8+N*M 
A(I + 2)=X 
2 
| = N*M-L 
LAKE(I,L)=99 
the compiler produces code equivalent to the following. 
1 
|=8+N*M 
ITEMP=I + 20*L 
A(I + 2)=X 
2 
l = N*M-L 
ITEMP=I + 20*L 
LAKE(ITEMP-20H99 
In this case the first computation of ITEMP was unnecessary and a com-
plete waste. 
Two- and three-dimensional subscripts are difficult to compute 
efficiently. They are a great convenience and there is no doubt that they are 
a valuable part of the compiler; however, if a subroutine is to achieve 
maximum efficiency, it may well be worthwhile to take out all the multiple 
subscripts and write them as single subscripts. Thus, instead of writing 
LAKE(I,L) = 99, you should write 
ITEMP=I + 20*L 
LAKE(ITEMP-20)=99 
where LAKE is now considered as a one-dimensional array. The whole 
question of efficiency is discussed in some detail in a later chapter. 
In Fortran IV the dimensioned variables are stored in the same 
way as in Fortran 63. There is a difference in compilation because the 
IBM 7090 indexing subtracts the index from the address. If index register 2 
contains n9 then the instruction CLA A,2 sets a = m(A — n). The Fortran 
statement 
X=A(l + 6)+A(l-2) 

142 
4 COMPILER 
LANGUAGE 
which was discussed earlier in this section, would be compiled as 
i2=-m(l) 
a = m(A + 5,i2) 
a = a + m(A - 3,/2) 
m(X) = a 
The 7090 has a number of special instructions that aid in efficient compila-
tion ; for example, there is a single machine instruction to do " il = — m(I)." 
However, index registers that subtract are not convenient, and one hopes 
they will not be used on any future machine. 
The IBM 704 had the instruction that could set il = m(l) but it 
did not have the instruction il = —m(l). Consequently Fortran II tries to 
avoid the use of — m(I) in an index register. Fortran II stores all arrays 
backwards. That is, A(l) is stored in location A, A(2) is stored in location 
A—1, and so on. 
4-6 
IF and GO TO STATEMENTS 
In an assembly-language program it is possible to attach a name to any 
location. A location may contain a number or it may contain an instruction. 
Any statement number in a Fortran program can be translated into the 
name of a location. The statement 
123 
X=Y 
which has the statement number 123, could be translated on the IBM 7090 
as 
.123 
CLA 
Y 
or on the CDC 1604 as 
.123 
LDA 
Y 
STO 
X 
STA 
X 
The quantity ".123" is a legitimate name for an assembler location. 
Fortran 63 happens to generate a name by preceding the statement number 
by a period, as we have done. Fortran II generates a symbol such as 
10A. The precise symbol generated does not matter, as long as it is 
unique. For convenience we will use the Fortran 63 system. The translation 
of the GO TO statement is now a simple matter: 
GO TO 123 
can be translated on the 7090 as 
TRA 
.123 
or as 
SLJ 
.123 

4 
6 I F AND GO TO STATEMENTS 
143 
on the 1604. The translation of IF statements can be accomplished by the 
use of the conditional transfer instructions. Consider the statement 
IF( X + Y * Z + 99.5) 
123,101,27 
The compiler generates the appropriate instructions for forming 
X + Y x Z + 99.5 and puts the result in the accumulator. The instructions 
IBM 
7090 
CDC 1604 
TZE 
.101 
AJP 
.101,Z 
TPL 
.27 
AJP .27,P 
TMI 
.123 
AJP 
.123,M 
now produce the desired jump. The zero test has to be placed first because 
TPL transfers on zero as well as for positive numbers. If statement number 
123 happens to be the next statement, then some compilers realize that the 
jump on minus instruction can be omitted. 
The mathematical description of a problem might include a 
statement such as " if Xis less than 1 then put Y = y/1 — X2, otherwise put 
Y — 0." This statement can easily be programmed in Fortran as 
Y=0. 
IF(X-1.) 
100,101,101 
100 
Y=SQRT (1.-X*X) 
101 
CONTINUE 
However, there is a reasonable chance that the programmer will make an 
error, and will mix up the statement numbers in the IF statement. Fortran 
IV allows an alternative form of IF, which is closer to the mathematical 
description. The mathematical symbols 
Φ > > < and < 
are not available on the card punch : they are transliterated as 
Φ 
> 
> 
< 
< 
.NE. 
.GT. .GE. .LE. and .LT. 
For consistency the equals sign in a comparison operation is written as 
.EQ. It cannot be written as =. The logical IF statement has the form 
IF (comparison) Statement a 
Statement b 

144 
4 COMPILER 
LANGUAGE 
If the result of the comparison is true, then statement a is obeyed. If the 
result is false, then statement a is skipped. The example given above could 
be written 
Y=0. 
IF(X.LT.L) 
Y= SQRT (1.-X*X) 
CONTINUE 
The expression X.LT.l. can have the value true or the value false. Since 
quantities with the value true or false are used in logic, these expressions 
are called logical expressions. A simple logical expression has the form: 
arithmetic expression 
logical operator 
arithmetic expression 
where the logical operator is .NE., .GT., .GE., .LE., .LT. or .EQ. For 
example, 
(X*X+ SIN(X)).LE. Y/Z 
is a legitimate logical expression. Logical expressions can be combined by 
using the operators .AND. and .OR. If Cl and C2 are logical expressions 
C1 .OR. C2 
= true if C1 is true or C2 is true or both are true, otherwise 
it is false. 
C1 .AND. C2 
= true if C1 is true and C2 is true, otherwise it is false. 
The operator .NOT. can be used to complement the value of a logical 
expression. If C is true, then .NOT. C is false, and vice versa. Extended 
logical expressions such as 
IF(A-B*C.LE.P+Q.AND.R.GT.C.OR.X*X+Y*Y.EQ.Z*Z) 
are permitted. The operator .AND. binds more strongly than .OR. so that 
C1.AND.C2.OR.C3 
is identically equal to 
(C1 .AND. C2) .OR. C3 
The compiler accepts either expression, but the use of parentheses saves 
the programmer from misinterpreting his own statements. 
The idea of a logical expression suggests the concept of a logical 
variable that has the value true or false. The statement 
LOGICAL 
l,X 
declares that I and X are logical variables. Assignment statements of the 
form: 
Logical variable = Logical expression 

4 · 6 IF AND GO TO STATEMENTS 
145 
and logical IF statements of the form 
IF (logical variable) 
are permissible. For example 
l = A*A+B*B.LT. 1.0 
sets I equals true if A*A + B*B is less than unity. 
Fortran 63 allows logical variables, logical expressions, and the 
logical IF statement. Variables and expressions are similar to those of 
Fortran IV. The Fortran 63 logical IF has the form 
IF(C3n l fn 2 
If C is true, control goes to statement nu otherwise it goes to n 2. 
Y = 0. 
IF(X.LT.L) 
101,102 
101 
Y = SQRTF(1.-X*X) 
102 
CONTINUE 
sets Y = 0 if X > 1 and Y = V l - X 2 if X < 1. The Fortran IV form of the 
statement would seem to be more convenient. Fortran 63 allows logical 
variables to be dimensioned and it stores such variables 32 per word. This 
saves storage space but can waste machine time since the variables have to 
be packed and unpacked. If J is an integer, the Fortran IV statement 
IF(J) 
P=Q 
is illegal because the statement has the form of a logical IF, and J is not 
logical. The corresponding Fortran 63 statement 
IF(J) 
100,101 
100 
P = Q 
is legal. Control goes to 100 is J is nonzero and to 101 if J is zero. There are 
several other instances in which Fortran 63 gives a reasonable interpretation 
to reasonable statements whereas Fortran IV condemns them as illegal. The 
logical operators .AND., .OR. and .NOT. are used by Fortran 63 in other 
statements in addition to the logical IF. This alternative use of the operators 
is discussed in Section 7.3. 
Any statement that uses a two-branch IF can be expressed in terms 
of one or more three-branch IF statements and the compiled program is 
constructed on similar principles. 

146 
4 COMPILER 
LANGUAGE 
4-7 
THE DO STATEMENT 
The translation of a DO loop is slightly different in Fortran 63 and 
Fortran IV. The DO loop 
SUM=0. 
DO 100 l=J,K 
100 
SUM = SUM+A(I) 
is compiled as follows : 
Fortran IV 
Fortran 63 
a=m(0) 
a = m(0) 
m(SUM)=a 
m(SUM)=a 
il = -m(J) 
il = m(J) 
.100 
a = m(SUM) 
.100A 
if il > K go to .100, otherwise 
a=a+m(A—1,il) 
go to next statement 
m(SUM)=a 
a=a+m(A-1,il) 
il=il-1 
m(SUM)=a 
if i l ^ — K, go to .100 
il = il + 1 
otherwise go to next 
go to .100A 
statement 
.100 
CONTINUE 
The two programs produce the same result if K is greater than or 
equal to J. If K is less than J, then Fortran IV goes through the loop one 
time, whereas Fortran 63 does not go through the loop at all. The Fortran 
63 convention would appear to be more reasonable. 
It will be seen that the index of a DO loop is carried in an index 
register. Index registers can hold numbers in the range 0 to 32,767. This is 
the reason for the Fortran restriction on the arguments of a DO loop. The 
arguments must be less than 32,768. The arguments must also be positive 
because the machine code fails if the arguments are negative. It would be 
possible to write a compiler that allowed positive or negative, integer or 
real arguments. All that needs to be done is to make the test of the end of 
the loop in the accumulator rather than in the index registers. Algol and 
PL/1 include this more general type of DO statement. 
4-8 
MACRO INSTRUCTIONS 
There has been a great change in the method of writing programs during 
the last ten years. The most important change is that programs are more 
standardized, and they are broken down into a number of independent 
segments. This segmentation means that major changes can be readily 
assimilated. For example, the programmer writes a simple Fortran 
statement such as "WRITE (6), X " which nominally will write X onto 

4 · 8 MACRO INSTRUCTIONS 
147 
tape unit 6. What actually happens is that the Fortran program transmits 
the information " 6 " and " X " to a library subroutine and this subroutine 
actually does the writing. The library subroutine has complete control over 
the actual writing. It may happen that a magnetic disk store is added to 
the computer. With programs written as they were ten years ago, the 
introduction of a new component such as a disk would have required the 
rewriting of many of the programs on the computer. Now the systems 
programmers need only change the library read/write routine. This takes all 
the information that formerly went on magnetic tape and puts it on the 
disk. None of the Fortian programs need to be changed; in fact, the 
average programmer may not realize that he is using a disk and not a tape. 
One of the devices for standardizing programs is the macro 
instruction. In a particular program it might be necessary to use a particular 
set of instructions over and over again. For example, the instructions 
STO 
X 
STQ 
X+1 
might occur repeatedly. A macro instruction is a short notation for a whole 
group of symbolic instructions. At the beginning of the program, the 
macros are defined. For example, 
DST 
MACRO 
X 
STO 
X 
STQ 
X+1 
ENDM 
DST 
defines the macro that has the name DST. At any later place in the program 
the instruction 
DST 
X 
automatically generates the instruction pair 
STO 
X 
STQ 
X+1 
These symbolic instructions are generated by the assembler and then they 
become part of the program to be assembled, so that DST acts just as 
though the pair STO and STQ have been written by the programmer. Any 
arguments can be used in the macro. For example, 
DST 
A 
generates 
STO 
A 
STQ 
A+1 

148 
4 COMPILER 
LANGUAGE 
Macro instructions with several arguments and macro instructions that 
generate many machine-language instructions can be defined. Most 
assemblers have two types of macros, the system macro and the defined 
macro. The system macro is stored on the system tape; any program can 
use the system macro without first defining what it does. A defined macro 
is a macro that is defined in the current program; the assembler retains the 
definition only during the assembly of the current program. 
The IBM 7094 computer has a number of instructions not on the 
7090. One of the instructions peculiar to the 7094 is the instruction DST 
which does a double-length store; it simultaneously stores the contents of 
the accumulator in one location, and the contents of the MQ in the next 
location. The Fortran compiler on the 7090 or the 7094 can make use of 
the DST instruction. When the compiled Fortran program reaches the 
assembler, the behavior varies according to the machine. Suppose X is at 
location 64; then DST on the 7094 becomes 
Symbolic 
Octal 
DST X 
460300000100 
On the 7090 the DST is translated as a macro and it becomes 
DST X 
060100000100 
060000000101 
That is, it is translated into two machine-language instructions. In this 
situation the compiler has less work to do it does not have to generate 
different codes for the two machines, but the assembler has more work 
to do. 
We stated in a previous chapter that there is a one-to-one relation 
between symbolic and machine-language instructions. If we include 
macros in the list of symbolic instructions, then the one-to-one relation is 
no longer true. The assembly language is the basic language for describing 
machine instructions. In the early days of computing, the basic language 
corresponded with the machine-language instructions. At the present time 
it has become necessary to use basic instructions that are not part of the 
vocabulary of the machine. 
In symbolic-language coding there are many other applications of 
macro instructions. One particular example is the simulation of one 
computer on another computer. To simulate the IBM 1620 on the IBM 
7090, for example, one could specify a 7090 macro for every 1620 instruc-
tion. A program written in 1620 symbolic language could then be put 
through the 7090 assembler. The output from the assembler would be a 
7090 program that would produce the same results as the corresponding 
1620 program. The 1620 has an operation 
ADD 
P Q 

4 · 9 SUBROUTINES 
149 
which adds a decimal number at location P to a decimal number at 
location Q and puts the result in location P. The corresponding macro 
could be defined by 
ADD 
MACRO 
P,Q 
CALL 
ADD20,P,Q 
ENDM 
ADD 
where ADD20 is some suitably designed subroutine that actually simulates 
the decimal addition. When a macro name is the same as the name of a 7090 
instruction, the name of the machine instruction is deleted from the list of 
operations. Once the ADD macro has been defined, the 7090 machine 
instruction with the name ADD is no longer available. It is possible in the 
Map assembler to give a different name to any instruction. A suitable name 
for the 7090 addition operation would be ADD90. The pseudo-operation 
OPD enables the programmer to define ADD90 as the machine instruction 
which does binary integer addition. 
Mcllroy (1960) discusses many more uses of the macro facility. 
4-9 
SUBROUTINES 
The idea of a subroutine is familiar from Fortran. At this stage we do not 
wish to discuss the complications of a Fortran subroutine, but as a prepara-
tion for the next chapter, we do wish to discuss some of the elements of 
subroutines. Consider the statement 
Y=SINF(X) 
The calculation of a sine function requires twenty or thirty machine-
language instructions. It is not feasible to use a macro operation since 
introducing twenty or thirty instructions every time a sine is referenced is 
very wasteful of storage space. A subroutine is a set of instructions which 
forms a unit of calculation. An example of a subroutine is the set of 
instructions that computes the sine of an angle. The main program is in 
one part of the memory and the sine subroutine is in another. The main 
program jumps out to the sine routine. When the sine has been computed, 
the sine routine does a jump back to the appropriate place in the main 
program. 
The implementation of the jump to a subroutine varies from 
machine to machine. In Fortran II on the 7090 the jump is 
CLA 
X 
TSX 
SINF,4 
STO 
Y 

150 
4 COMPILER 
LANGUAGE 
The instruction TSX (transfer saving index) jumps to the location SINF 
and puts the complement of the current address into index register 4. For 
example, if the TSX instruction is in location 12345 octal, then 65433 goes 
into index register 4. The contents of index register 4 are such that the 
SINF function can perform its calculation and then 
TRA 
1,4 
transfers back to the correct place in the main program. It jumps back to 
the instruction immediately following the TSX, that is, to the STO Y 
instruction. Any index register can be used with the TSX, but it is conven-
tional to use index register 4. 
The corresponding code in F63 on the CDC 1604 is 
LDA 
X 
L 
RTJ 
SINF 
+ 
STA 
Y 
The symbol -f- in column 1 of a card instructs the assembler to put this 
instruction in the first half of a word. The second half of the previous word 
is, if necessary, filled by an instruction that does nothing. Any instruction 
having a label automatically goes in the first half of a word. The instruction 
RTJ (return jump) jumps to the location SINF and stores the current 
address plus one in the address part of the location SINF. The sine routine 
is coded 
SINF 
SLJ 
0 
SLJ 
SINF 
where · · · denotes the code that computes the sine and puts the result into 
the accumulator. When the sine routine is entered, then the value L+1 is 
automatically stored in the address part of location SINF and the instruc-
tion at SINF + ^ is obeyed. At the end of the routine, SLJ SINF jumps to 
the location SINF, which then jumps to the location L+1. Notice the jump 
is to L +1, not L + ^; this is the reason why STA Y was forced into the 
first half of the next location. 
Other machines have other methods of entering and leaving sub-
routines. The essential thing to realize is that the sine routine can be 
entered from any place in the memory. The writer of the sine routine does 
not have to know anything about the main program; he just arranges to 
put the result in the accumulator, and to jump back to location L+1. 
Subroutines and macros add to the power of a machine. Some 
machines have a built-in square-root instruction; others compute a square 
root in a subroutine. The programmer need not be concerned with the 
properties of the real machines; he can use any of the properties of the 

4 · 10 EXAMPLE OF A PROGRAM COMPILED BY FORTRAN 63 
151 
idealized machine which consists of the real machine plus any of the sub-
routines and macros. The essential difference between a subroutine and a 
macro is that the subroutine coding appears only once and the main 
program has to jump to the subroutine. The macro coding appears as often 
as the macro is called and the coding is embedded in the main program. The 
macro is usually used for small pieces of program when it would be too 
wasteful to spend time jumping out to a subroutine. Some of the operations 
performed by macros in Fortran IV are performed by subroutines in 
Fortran 63. 
4-10 An EXAMPLE of a PROGRAM COMPILED by FORTRAN 63 
On the following pages we show an example of a Fortran program (Figure 
4.1) and the resulting symbolic code produced by the Fortran 63 compiler 
(Figure 4.2). A similar program compiled under Fortran IV on the 
IBM 7090 is discussed in Section 4.11. 
In the assembly listing, the right-hand side of the page shows the 
symbolic code produced by Fortran 63. The left-hand side of the page 
shows the binary code produced by the Codap assembler. The assembler 
assumes that the program starts at location zero. During the loading 
process the program is placed at some nonzero location and all the 
addresses are changed accordingly. For example, the listing 
00561+ 
12 0 
00550+ 
20 0 
00677+ 
means that location 561 contains the instructions 1200055020000677. If the 
program happens to be loaded into locations beginning at 27000 octal, then 
at execution time location 27561 contains 120275502027677; that is, 27000 
is added to each address. 
Starting at the top of the listing: The range gives the number of 
locations occupied by this program, which in this example is 702 octal or 
450 decimal. The first executable instruction is at location 551. The program 
PROGRAM TEST 
DIMENSION A(2U>,9(34,10) S E3dlVALENCE (XX,IX) 
1 
IX=404947 
003 
1=21 $ J=I+99 $ C=I 
4 
Z = XX 
5 
A( I*2)=A<I*2)*A(2*I)*A(10) 
6 
Z = B(1*3,J*2)*B<I,J)*C $ SUMsO. 
7 DO 100 K*I,J 
100 
SUM = SUM*A(K.)*B( I, J) 
9 
Iafl $ Z = A( I ) $ I*K«3 
10 
X = B( I+2,K-20> ï A(2l)zC f iHx-Y) 101,102,103 
101 
Y = Z % GO TO 104 
102 
IF (X.LT.Y) 101,104 
103 
P = Q 
10 4 Ys'(A + B)*SINF(A*B)/(P*SlNF(A*9) > 
END 
FIG. 4.1 
Sample program compiled in Fortran 63 

152 
4 COMPILER 
LANGUAGE 
uses three library routines. Q8QENTRY is a system routine. Q1Q10010 
converts an integer into a floating-point number. The BSS instructions 
allocate the space that was declared in the DIMENSION statement. The 
IX 
EQU 
XX statement ensures that XX and IX occupy the same 
storage location. The program begins at location TEST. The instruction 
RTJ INITIAL, causes a jump to location 665. The INITIAL, part of a 
routine usually saves index registers and does other preliminary operations. 
In this example, since we have a main program, no initialization is necessary 
and INITIAL, jumps right back to location 552 and the first Fortran 
statement is obeyed. At location 552 we see that the Fortran label 1 
translates into the assembler symbol .1. The symbols .3, .7, and .9 at later 
stages in the program show that the position of the Fortran label does not 
affect the generated symbol. Location 552 shows the use of the octal literal 
1426723 to set the decimal constant 404947. If an integer constant that is 
less than 16384 needs to be set, then the EN A or INA instruction can be 
used. This is illustrated in location 553. The symbol =SI used in the 
second half of location 553 means, save a space for the variable I and put 
its address in this location. It saves the unnecessary use of an 
I 
BSS 
1 
instruction. In this routine, storage space for I is explicitly declared at 
location 656, so STA =SI has the same effect as STA I. The symbol 
UP0002. that appears at location 554 refers to an update function. The 
code for the three update functions used in this routine is found in locations 
643 onwards. UP0002. is entered every time I changes; it recomputes the 
value of the two-dimensional subscript (I,J). UP0001. provides a similar 
service for J and UP0000. relates to K. 
The subroutine call at 560 converts the integer I into floating-point 
form before storing the result in C. Fortran 63 has two types of subscript. A 
standard subscript has the form c * I ± d where c and d are integer 
constants and I is any integer variable. A nonstandard subscript is one that 
does not have the standard form. Nonstandard subscripts are treated less 
efficiently than standard subscript. The coding starting at location 562 
shows that 2 +1 is treated as a nonstandard subscript. A(2 + I) has the same 
effect as A(I + 2) but it takes five more instructions. The instruction LIL 1 
IN0002. in location 567 picks up the contents of the pseudo-index register 
IN0002.. The update functions ensure that IN0002. always contains the 
latest value of (I,J). There is a pseudo-index register for each different two-
or three-dimensional subscript used in the program but notice that B(I,J) 
and B(I + 3,J + 2) can be accessed by the same pseudo-index register. 
Location 573 starts the DO loop. The AJP at location 576 ensures 
that the loop is not entered if J is less than I. The repetitive part of the code 
is in locations 601 through 603. Notice that this part of the code is com-
pletely efficient—there are no wasted instructions. The instruction at 

4 - 10 EXAMPLE OF A PROGRAM COMPILED BY FORTRAN 63 
153 
PROGRAM 
TEST 
IDcNT 
TEST 
RANGE 
FtfA 
- 
L*A*1 
00000 
00/02 
ENTRY POINTS 
00551 
TfcST 
EXTERNAL SYMBOLS 
00000* 
00024* 
00550* 
00551* 
00551* 
00552* 
00553* 
00554* 
00555* 
00556* 
00557* 
00560* 
00561* 
00562* 
00563* 
00564* 
00565* 
00566* 
00567* 
00570* 
00571* 
00572* 
00573* 
00574* 
00575« 
00576* 
00577* 
00600* 
00601* 
00601* 
00602* 
00603* 
00604* 
00604* 
00605* 
00606* 
00607* 
75 
75 
12 
20 
10 
20 
75 
50 
11 
20 
75 
50 
12 
50 
75 
00 
12 
20 
10 
14 
11 
20 
53 
12 
53 
30 
30 
20 
53 
12 
30 
30 
20 
10 
20 
50 
12 
20 
75 
50 
12 
15 
22 
20 
53 
53 
53 
50 
12 
32 
30 
20 
51 
55 
10 
20 
75 
50 
53 
12 
20 
10 
0 
4 
0 
0 
0 
0 
4 
0 
0 
0 
4 
0 
0 
0 
4 
0 
0 
0 
\ 
0 
0 
0 
1 
1 
2 
2 
0 
1 
1 
1 
1 
0 
0 
0 
0 
0 
0 
0 
4 
0 
0 
0 
3 
0 
1 
2 
3 
0 
1 
2 
0 
0 
1 
3 
0 
0 
4 
0 
1 
1 
0 
0 
00U01 
00002 
00Ü03 
00!?50* 
00551* 
00*51* 
00665* 
00701* 
00550* 
00025 
00656* 
00661* 
00Ü0O 
00143 
00647* 
00652* 
00U00 
00656* 
00000 
X00U01 
00700* 
00550* 
00677* 
001)02 
00656* 
77776 
00666* 
00656* 
00001* 
00666* 
00000* 
00011* 
00001* 
00633* 
00070* 
77760* 
00700* 
00677* 
00000 
00676* 
00000 
00656* 
00635* 
00643* 
00000 
00647* 
00656* 
00604* 
00675* 
00635* 
00633* 
00675* 
OOUOO 
77776* 
77760* 
00676* 
00676* 
00U01 
00601* 
00010 
00656* 
00661* 
00000 
00656* 
77776* 
00677* 
00003 
Q1O10010 
SINF 
080ENTf?Y 
A 
Θ 
XX 
IX 
ENDING. 
TEST 
-
.1 
.3 
♦ 
* 
♦ 
.4 
.5 
* 
.6 
.7 
* 
HS00001. 
.100 
Tsoonui. 
.9 
♦ 
3SS 
ass 
83S 
É3J 
ENTRY 
ÔSS 
S.J 
RTJ 
LOA 
STA 
EVA 
STA 
RTJ 
IMA 
STA 
RTj 
UOA 
CALL 
3 
uOA 
STA 
EMA 
ADO 
IMA 
STA 
L U 
LOA 
LIL 
FAD 
FAD 
STA 
LlL 
LOA 
r'AO 
TAD 
STA 
EMA 
STA 
LOA 
STA 
RTJ 
UOA 
SJB 
AJP 
STA 
LlL 
LlL 
LlL 
ess 
LOA 
FMU 
FAD 
STA 
INI 
U P 
ass 
EMA 
STA 
RTJ 
LlL 
LOA 
STA 
EMA 
1 
1 
2 
2 
1 
1 
1 
1 
3 
1 
2 
3 
1 
2 
1 
3 
1 
1 
20 
340 
1 
XX 
TEST 
0 
TEST 
INITIAL. 
=01426723 
IX 
*21 
*SI 
JP00002. 
♦ 99 
sSj 
JP00001. 
I 
31(310010 
sSC 
XX 
= SZ 
♦ 2 
I 
•1 
.NSTIFF. 
I 
A*l 
.NSTIFF. 
A 
A*9 
A*l 
IN00002. 
3*36 
3-35 
3 
»SI 
0 
«SSUM 
I 
sSK 
JP00000. 
J 
I 
TS00001. 
«SCOÜNT. 
K 
IN00002. 
COUNT. 
0 
A-l 
B-35 
SUM 
*SSUM 
*1 
4S00001. 
0 
*8 
= SI 
JP00002 
I 
A-l 
*SZ 
♦ 3 
FIG. 4.2 Assembly listing for Fortran 63 program given in Figure 4.1 

154 
4 COMPILER LANGUAGE 
PROGRAM 
TEST 
00610* 
00611* 
00612* 
00613* 
00614* 
00615* 
00616* 
00617* 
00620* 
00621* 
00622* 
U 
00623* 
00624* 
00625* 
00626* 
00627* 
00630* 
00631* 
00632* 
00002 
00633* 
00634* 
00635* 
00636* 
00637* 
00640* 
00641* 
00642* 
00643* 
00644* 
00645* 
00646* 
00647* 
00650* 
00651* 
00652* 
00653* 
00654* 
00655* 
00656* 
20 
75 
20 
75 
53 
12 
20 
12 
20 
12 
31 
22 
22 
75 
12 
20 
75 
50 
12 
31 
22 
75 
12 
20 
1.2 
30 
20 
75 
20 
12 
30 
20 
12 
32 
33 
20 
75 
50 
00 
00 
00 
00 
00 
00 
10 
70 
72 
50 
75 
75 
00 
no 
12 
20 
75 
15 
22 
20 
10 
24 
70 
75 
00 
00 
00 
00 
12 
20 
75 
15 
22 
20 
10 
24 
70 
75 
00 
no 
0 
4 
0 
4 
1 
1 
0 
0 
0 
0 
0 
0 
3 
0 
0 
0 
0 
0 
0 
0 
2 
0 
0 
0 
0 
0 
0 
4 
0 
0 
0 
0 
n 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
0 
00635* 
00643* 
00656* 
00661* 
00634* 
76512* 
00674* 
00700* 
00024* 
00674* 
00673* 
00621* 
00617* 
00623* 
00677* 
00673* 
00624* 
00000 
00674* 
00673* 
00617* 
00624* 
00702* 
00672* 
00000* 
00024* 
00670* 
X00002 
00671* 
00672* 
00671* 
00667* 
00670* 
00671* 
00667* 
00673* 
00551* 
00000 
oouno 
00000 
00000 
00000 
oouno 
oouoo 
00U42 
00634* 
00641* 
oouoo 
oiuoo 
00636* 
ooooo 
oouoo 
00633* 
00641* 
00000 
00641* 
00642* 
00641* 
00042 
00641* 
00634* 
00642* 
OOUOO 
00000 
OOUOO 
00000 
00647* 
00650* 
oouno 
00650* 
00651* 
00650* 
00U42 
00650* 
00633* 
00651* 
OOOOO 
OOOOO 
-
-
.10 
.101 
.102 
.103 
.104 
♦ 
IN0Q0J2. 
IN000U4. 
K 
POOOOü.U 
♦ 
* 
upooniio. 
j 
♦ 
UP00001. 
I 
STA 
RTJ 
STA 
RTJ 
LlL 
LDA 
STA 
LDA 
STA 
LDA 
FSB 
AJP 
AJP 
S.J 
LOA 
STA 
S.J 
LOA 
FSB 
AJP 
S.J 
LOA 
STA 
LOA 
FAD 
STA 
RTJ 
STA 
LOA 
FAD 
STA 
LOA 
F1U 
FDV 
STA 
S.J 
EXT 
ο:τ 
O:T 
O:T 
ÉMA 
RAD 
RAO 
S.J 
S-J 
O:T 
UDA 
STA 
S-J 
SJB 
AJP 
STA 
fcMA 
MJI 
RAÜ 
S.J 
O:T 
O:T 
cDA 
STA 
S.J 
SJB 
AJP 
STA 
ÉYA 
MJI 
RAO 
S.J 
OCT 
= SK 
JP00000. 
sSI 
JP00002. 
1 
IN00004. 
1 
3-713 
= SX 
c 
A*20 
X 
Y 
.102 
3 
.101 
.103 
z 
= SY 
.104 
X 
y 
3 
.101 
,104 
3 
= SP 
A 
3 
.CERASE. 
3INF 
.CERASE. 
3 
.CERASE. 
.ERASER. 
.CERASE. 
.CERASE. 
.ERASER. 
= SY 
ENDING. 
SINF 
0 
0 
0 
♦ 34 
IN00U04. 
JPO0OO0. 
0 
300000.L 
0 
< 
JP00000. 
0 
JP00000. 
JPO0000. 
JP00000. 
♦ 34 
JP00000. 
IN00004. 
JP00000. 
0 
0 
J 
JP00001. 
0 
JP00001. 
JP00001. 
JP00001. 
*34 
JP00001. 
IN00002, 
JP00001. 
0 
♦1 
♦1 
♦ 1 
-2 
1 
-2 
-2 
-1 
-2 
-2 
-1 
,-2 
-2 
,-1 
,-2 
,-2 
,-1 
FIG. 4.2 {continued) 
Assembly listing for Fortran 63 program given in Figure 4.1 

4 · 11 EXAMPLE OF A PROGRAM COMPILED BY FORTRAN IV 
155 
PROGRAM 
00657«. 
00660* 
00661* 
00662* 
00663* 
00664* 
00003 
00665* 
00665* 
00666* 
00667* 
00670* 
00701* 
NO ! 
1 
00 
00 
12 
20 
75 
15 
22 
20 
70 
12 
70 
75 
75 
75 
00 
01 
0 
0 
0 
0 
0 
0 
0 
0 
0 
n 
0 
0 
0 
0 
0 
4 
TEST 
00000 
00000 
00656* 
00657* 
00000 
00657* 
00660* 
00657* 
00633* 
00657* 
00634* 
00660* 
X00003 
00665* 
00000 
26723 
oouoo 
DOUBLY DEFINED 
♦ 
UP000D2. 
BEGIN. 
INITIAL. 
.NSTIt-F . 
.ERASER. 
•CERASF. 
UNDEFINED SYMBOLS 
ASSEMBLY 
NULLS 
ERRORS 
OCT 
IDA 
STA 
S.J 
SJB 
AJP 
STA 
RAD 
LDA 
RAO 
S.J 
EXT 
ess 
S.J 
su 
BSS 
BSS 
BSS 
END 
0 
I 
JP00002.-2 
0 
JP00002.-2 
JP00U02..-1 
JP00002.-2 
IN00002. 
JPOB002.-2 
IN00004. 
JP00002.-1 
38QENTRY 
0 
38QENTRY 
BEGIN. 
1 
1 
2 
TEST 
i 
I 
.3 
■f 
. 1 00 
FIG. 4.2 (continued) 
Assembly listing for Fortran 63 program given in Figure 4.1 
location 605 is unnecessary. It updates the index (I,J) and (I,K) although 
the value of I is changed before either of these subscripts are used. Locations 
614 through 616 show the coding of a three-branch IF. The zero branch 
must always be tested first since +0 is a positive number and —0 is a 
negative number. Locations 621 through 622 show a logical IF statement. 
Location 623 contains an undefined symbol. The variable Q is used in the 
right-hand side of an arithmetic expression but it has not previously been 
assigned a value. This error causes execution to be deleted. 
The interest of locations 624 through 631 lies in the efficiency of 
the coding. The reader will notice that A + B is evaluated once only and 
the same routine is called only once. Some compilers would evaluate 
A + B three times and enter the sine routine twice. Locations 633 through 
664 are concerned with updating the pseudo-index registers. Location 701 
contains the literal defined in location 552. 
4-11 
An EXAMPLE of a PROGRAM COMPILED by FORTRAN IV 
This program is similar to the one in the previous section. Some changes 
have been made because of the differences in the two compilers. The listing 
of the Fortran program (Figure 4.3) shows some numbers opposite each 
statement on the right-hand side of the page. These numbers are called 

Ιϊλ 
MAI. 
^ 
EXTERNAL FORMULA NUMöfcK 
- 
SOURCE STATEMENT 
- 
INTERNAL FORMULA NUMbtR(S) 
r 
c 
1 
003 
4 
5 
6 
7 
100 
10 
101 
102 
103 
104 
PROGRAM TE$T 
. . . 
. . 
PROGRAM TO TEST COMPILED FORM OF 
DIMENSION Al20)tB(34f10J 
FORTRAN STATEMENTS 
EQUIVALENCE 
1X*4C4947 
1*21 
J~l*99 
C«l 
2«XX 
A(1*2)*A(1*2)*A11*4J*AU0) 
2*eil«3.J*2J*B(I.Jl+C 
SUM-0. 
DO 100 K«IAJ 
_ 
. 
. . 
SUM=SUM+AiK)*B(I,J) 
1*8 
Z*AI1J 
1*3 
X=B(l*2,K-20) 
A(2U*0 
1FIX-V1 101,102,103 
y*z 
GO TO 104 
IF (X.LT.YJ 
Y*2 
P*Q 
Y*(A+B)*S1N {A+B)/iP*SIN ÎA+BU 
ENO 
PROGRAM SHOULD END WITH A STOP. RETURN 
(XX,IX) 
OR TRANSFER ST ATEMENT 
• 1 
,2 
,3 
• 4 
.»5 
.6 
.7 
»a 
. 
,_9„__ 
110 
J.12„. 
.13 
.14 
115 
jJ6.__ 
• 17 
JL1Ô_. 
.19 
.20 
• 23 
J24__ 
.25 
• 11 
.21 
.22 
RETURN STATEMENT SIMULATED. 
SOURCE ERROR 2 76, LEVEL 1. 
WARNING ONLY. 
, 2 6 
FIG. 4.3 Sample program compiled in Fortran IV 

4 - 11 EXAMPLE OF A PROGRAM COMPILED BY FORTRAN IV 
157 
internal formula numbers. The assembler refers to these internal numbers; 
it does not use the Fortran statement numbers. For example, Fortran 
statement 101 has internal number 18, and the code for this statement 
begins at the assembly-language statement having the label 18A. Some 
statements, such as statements at the end of a DO loop, require several 
internal formula numbers. 
The assembly listing (Figure 4.4) should be read across the page 
from left to right. The five-digit octal numbers give the locations that the 
corresponding instructions occupy; thus 
00015 
CLA 
=404947 
shows that the instruction CLA =404947 goes in location 15 octal 
relative to the beginning of the routine. The statements that begin USE 
will be explained later. At the beginning of the assembly-language listing 
there are a number of BSS pseudo-instructions. These reserve space for all 
of the variables used by the program. The first instruction of the program 
is at location 15 and has the assembler label 1A. It shows an example of a 
decimal literal. At location 21 the complement of I is put into index register 
1 ; this index register is not used until location 43. The compiler always 
tries to load an index register at the earliest possible opportunity since this 
often leads to more efficient code. The instruction at location 24 sets the 
value of J and immediately following this the program computes the 
subscript (I,J) and puts it in index register 2: this index register is used at 
locations 47 and 50. Beginning at location 31 are the instructions that 
convert I to floating point. Since an integer may contain up to 35 bits and 
since a floating-point number contains only 27 bits, the conversion has to be 
done in two parts. The 8 lower bits of the integer are shifted into the 
MQ register, the top 27 bits are converted, then the 8 lower bits are shifted 
back and converted and the two results are added together. The instructions 
in locations 43 and 44 show that A(I + 2) and A(I + 4) can be accessed 
with one setting of the index register. Similarly in locations 47 and 48 
B(I + 3, J + 2) and B(I,J) can be picked up with one index register setting. 
The instructions in locations 55 through 57 cause J — 1 to be set in the 
decrement of location 73 which is the end of the DO loop. Locations 66 
through 73 comprise the actual loop. A NULL pseudo-operation is similar 
to a Fortran CONTINUE, it does nothing but it can have a label. The 
compiler realizes that the address of B(I,J) does not change during the DO 
loop. It computes this address by the instructions in locations 60 through 
64 and in location 65 it causes this address to be stored in location 67. This 
particular technique does not offer any advantages in this example since 
the instruction FMP B —35,2 would have done just as well. However, in 
more complicated DO loops it can achieve a great saving of time since 
index registers do not have to be set and reset throughout the course of the 
loop. The instructions in locations 103 through 106 compute the subscript 

7 7 1 
TEST 
ASSEMBLED 
T E X T . 
BINARY CARD 
00015 
00151 
00156 
IX 
00727 1 
00732 
L 
00735 X 
00740 w 
BINARY CARD 
00015 
1A 
00020 
00022 
00025 
4A 
00027 
00032 
00035 
BINARY CARD 
00040 
00043 
oA 
00046 
00051 
00054 
9A 
0005ο 
OCGöl 
BINARY CARD 
00062 
0CU65 
C0066 
00071 
00073 
B.O 
*TEXT 
TEST 
10· TÇ^TOOD? 
USE .PRÛL. 
USE .ERAS. 
BSS 1 
BSS.1 
BSS 1 
BSS 1 
BSS 1 
ID. TEST0003 
CLA =404947 
STO I 
CLA 1 
NULL 
ADD 1 
LRS 8 
CLA =155Β1β 
JD. TEST0004 
STO C 
CLA A*l.l 
STÛ A*l,i 
fAD C 
NULL 
7X1 **l,4j-l 
VLM =34817,,lö 
ID. TEST0005 
ADD I 
SXA 10A2t4 
LDQ A-ltl 
STO SUM 
TXH 9A1.1·** 
00015 
00156 
00157 
007.3.9.. 
00733 
0Q736 
00015 
00016 
00021 
0Û023 
00025 
00030 
00033 
00036 
00041 
00044 
00047 
00052 
00054 
00057 
00063 
00066 
00067 
00072 
00074 
A 
__J_ 
SUM 
Y 
3A 
5A 
7A 
9A1 
10A2 
11A 
12A 
USE 
USE 
BSS 
..._BS_S. 
BSS 
...BSS. 
USE 
STO 
.MAIN. 
.STÖR. 
20 
1 
A 
.MAIN. 
IX 
NULL 
ADD =99 
LDQ 
PAC 
ÛRA 
LLS 
CLA 
FAD 
CLA 
"TU 
LAC 
SXD 
PAX 
NULL 
r-Mp 
NULL 
CLA 
J 
.2 
=163B8 
ö 
XX 
A+3,1 
B+36,2 
2 
1,1 
B.0,4 
_t.4_ 
** 
= 8 
00151 
00156 
00203 
P_Q_7_3A. 
00734 
0Q7|7 
00017 
00021 
00024 
00026 
00031 
00034 
00037 
00042 
00045 
00050 
00053 
00055 
00060 
00064 
00066 
00070 
000 72 
00075 
λΛ 
B 
.C .. 
K 
ά* 
öA 
10A 
TEST0O01 
USE .TRST. 
EOU IX 
BSS 340 
. 
.Ö.SS.A 
BSS 1 
BSS.A 
CLA =21 
LAC 1,1 
STO J 
VLM =34B17,,18 
CLA I 
STO E. 
FAD E. 
STO 1 
FAD A+9 
FAD ß-35,2 
STZ SUM 
LAC J,4 
LDQ J 
J_X.l_.*tAj 4,0-35. 
NULL 
FAD SUM 
TX1 *+l,lv-L 
STO I 

00076 
00100 
00103 
BINARY 
00104 
00107 
00112 
00115 
00120 
00123 
CüUo 
13A 
15A 
CARD 
2cr. 
NULL 
STO Z 
NULL 
ID. TEST0006 
VLM =34B17,,18 
CLA B-713,1 
STO A+20 
TIE 
20A 
STO Y 
SUB Y 
NULL 
00076 
00101 
00103 
00105 
00110 
00113 
00116 
00121 
00124 
00130 
14A 
17A 
19A 
20F. 
LAC 1,2 
CLA =3 
LDQ K 
ADD I 
STO X 
CLA X 
TPL 23A 
TRA 24A 
TZ£ 20F. 
SYN 22A 
00077 
00102 
00106 
00111 
00114 
00117 
00122 
00125 
16A 
ISA 
20A 
CLA A-1,2 
STO I 
PAC .1 
CLA C 
FSB Y 
CLA Z 
CLA X 
TPL 20F. 
- B I N A R.Y. _ CA R_D _ 1 D_._ _ T E .ST 0.0 0 7 
00126 21A 
00130 23A 
00133 
00141 
00144 
CLA Z 
CLA ft 
FAD B 
STO N.»l 
00127 
STO Y 
00131 
_STO P 
00134" 
STÖ N. 
00142 
FAD P 
00130 22A 
NULL 
00132 24A 
CLA A 
ÔÔ135 
CALL SININ.M2 
00143 
STO N.+2 
LBQ R. 
.00147 
STQ_Y 
00145 
FMP N.-H 
00150 25A 
RETURN .. 
00146 
FDP N.+2 
BINARY CARD 
00000 
00151 
I D . 
TEST0008 
USE 
EVEN 
_00000.___._..._._._ _S.AVE 
1 4 J . 2 J . 1 1 1 
00151 
N. 
BSS 3 
00151 
USE ,ER_AS_«._. 
00"Î54 
E . 
PZE 
BINARY 
00155 
00741 
00000 
CARD ID . TEST0009 
PZE 
LDIR 
END 
00741 
00743 
USE .DUMY. 
LORG 
00741 
00753 
EVEN 
BEGIN //,* 
X 
> 
30 
o 
Ω 
30 > 
O 
o 
•v 
i -
m 
Ό 
00 
■< 
■n 
o 
30 
H 
30 > 
FIG. 4.4 Assembly listing for Fortran IV program given in Figure 4.2 
- 1 
ai 
<0 

160 
4 COMPILER 
LANGUAGE 
(Ι,Κ). Notice that Fortran IV is more efficient than Fortran 63. Fortran IV 
realizes that the statement 
9 
l=8 
has no effect on the subscript at statement number 10, whereas Fortran 
63 assumed that it would have an effect. 
Locations 113 through 125 show examples of IF statements. 
Remember that Fortran 63 objected to the use of Q because it knew that 
the value of Q had not been defined. Fortran IV does not detect this fact. As 
in Fortran 63, the coding of statement 104 is very efficient. 
CALL SIN(N.) "24" 
is an assembler macroinstruction which is expanded into 
TSX 
SIN,4 
TXI 
* + 3 
PZE 
24„LK.DR 
PZE 
N. 
The meaning of these four instructions is discussed in Chapter 6. 
When writing large assembly-language programs, it is frequently 
necessary to break off in the middle of the program in order to make a 
note of some fact. For example, when the compiler encounters 
1=21 
it assembles the code 
CLA 
=21 
STO 
I 
and it makes a note that space must be allocated at some time for the 
variable I. The MAP assembler provides a method of simplifying this type 
of code. The statement 
USE 
PART1 
tells the assembler that the program will consist of several pieces and that 
the statements that follow belong to PARTI. If the program contains 
USE 
PART1 
CLA 
=21 
STO 
I 
USE 
PART2 
I 
BSS 
1 
USE 
PART1 
ADD 
=99 

PROBLEMS 
161 
then the assembler collects this together as 
USE 
PART1 
CLA 
=21 
STO 
I 
ADD 
=99 
It is not necessary to use PARTI, PART2, etc. : any name can be used. The 
various parts of the program finally.appear in the order in which they were 
first USED. The compiler places several USE instructions at the beginning 
of the assembly in order to make sure that the parts of this particular 
program are used in the following order: the part with the blank name (this 
always comes first); then comes .PROL., (this part happens to contain no 
instructions because the routine is a main program). Following .PROL., 
there is MAIN., then .TRST., then .ERAS., which is used as temporary 
storage space. .STOR. controls the allocation of memory space for all 
local variables. 
SAVE is a macro that is used upon entry to any routines. Although 
this is a main program, the compiler still arranges for the contents of the 
index registers to be saved. LDIR is a pseudo-instruction that causes the 
linkage director to be inserted : see Chapter 6 for the use of this feature. 
LORG causes the literal pool to be inserted at this point. EVEN is a 
pseudo-instruction that causes the next location to have an even address. In 
the 7094 double words have to start at an even address. 
PROBLEMS 
1 ■ Two students were asked to give the assembly language version of 
DIMENSION X(20) 
l = 6 
Y=X(i) 
They gave the following solutions. 
(b) 
(a) 
Which solution is correct? Give reasons for your answers. Remember 
the difference between the value of I and the address of I. Give the 
actual assembly-language instructions for the correct version. (In 
Fortran IV on the IBM 7090, for i4 = I substitute i4 = -I.) 

162 
4 COMPILER LANGUAGE 
2 ■ Given the Fortran statement 
DIMENSION B(10), C(5,7), D(3,4,6) 
write down the BSS instructions (or DS instructions in the case of the 
IBM 360) corresponding to this statement. If B(l) is stored in location 
B, where is B(I) stored? If C(l,l) is stored in location C, where is 
C(I,J) stored? If D(l,l,l) is stored in location D, where is D(I,J,K) 
stored? What is an index register? What are the assembly-language 
instructions for 
X=B(I) 
Y=C(I,J) 
Z=C(l + 2,J + 3) + C(l,J) 
3 ■ Some computers have double index registers. For example, on the 
IBM 360 
LD 
2,500(5,6) 
picks up the contents of location R5 + R6 + 500, where R5 is the 
contents of register 5 and R6 in the contents of register 6. Does double 
indexing lead to more efficient code than single indexing in such 
statements as these ? 
COMMON l,J,K 
DIMENSION P(10,20) 
X=P(I,J) + P(I,I) + P(K,I) 
Does it save any multiplications ; in particular can the multiplication of 
10*J and 10*1 be avoided? 
4 ■ If I and J are logical variables, we can make a table that shows the 
effect of .OR. by enumerating all possible cases: 
J 
I.OR.J 
T 
T 
T 
T 
F 
T 
F
T 
T 
F
F 
F 
T denotes true and F denotes false. Such a table is called a truth table. 
Make a truth table for I.AND.J. Make truth tables for 
(I.AND.J).OR.(.NOT.I.AND.K).OR(J.AND.K) 
and for 
(I.AND.J).OR(.NOT.I.AND.K) 

PROBLEMS 
163 
If two expressions have the same truth table, then the expressions are 
identical. Write a Fortran program that prints the truth table for the 
expressions just discussed. 
5 ■ Algol and PL/I allow a dimensioned variable to have subscripts that 
have positive or negative values. 
ARRAY A ( - 5 : 1 0 , 20:30) 
indicates that A is a 16 x 11 array with subscripts ranging from —5 
to 10 and 20 to 30. Indicate how the statement 
X=A(I,J) 
could be compiled. Assume that the first element of the array A, 
namely A( —5,20) goes in location A. 
6 ■ The statements 
DO 100 l=J,K,L 
100 
CONTINUE 
Can be replaced by 
l=J 
101 
CONTINUE 
100 
l-l + L 
IF(I.LE.K) GO TO 101 
Do these statements have the correct effect if J,K and L are positive or 
negative ? If not, modify the statements so that they are correct. What 
happens when L is greater than zero and J is greater than K ? Do you 
think that the statements inside such a loop should always be obeyed 
at least once ? How should the program be modified so that the loop is 
bypassed for suitable values of J,K, and L? 
7 ■ An electronic element called an AND gate has two inputs and one 
output. It could be simulated by the function routine, 
FUNCTION IAND(I1,I2) 
IAND-0 
IF(I1.EQ.1 .AND. I2.EQ.1) IAND = 1 
END 
We have prefixed the I to AND in order to get an integer name. An OR 
gate can be simulated by a function that produces the results, 
IOR(0,0) = 0; IOR(0,1) = IOR(1,0) = IOR(1,1)=1. An inverter cor-
responds to the Fortran routine NOT where NOT(0)=1 and 

4 COMPILER 
LANGUAGE 
NOT(1) = 0. In order to demonstrate the power of simple electronic 
gates, show that an arithmetic operation such as the addition of two 
4-bit integers can be carried out by using the I AND, IOR and NOT 
functions. 
Do not 
use any Fortran 
statements 
other 
than 
I = IAND(J,K), I = IOR(J,K), I = NOT(J), I = J and the DIMENSION 
statement 
DIMENSION 1(4), J(4), K(4) 
statements such as I = IOR(IAND(J,K),L) are allowed since they could 
be expressed in terms of the basic statements. 1(1), 1(2), 1(3), 1(4) 
represents a 4-bit integer with 1-bit per Fortran word. Similarly for J. 
Suppose I is to be added to J and the result is to go in K. Add two bits 
at a time. Draw up a truth table to show that 
K(1) = IOR(IAND(l(1), NOT(J1)), IAND(N0T(I1), J(1))) 
There is a carry into the next position; show that the carry bit is 
KARRY=IAND(I(1), J(1)) 
Now add 1(2) and J(2) together to give a result K2 and a carry of K3. 
Add K2 and KARRY to produce the result K(2) and a carry of K4. 
The final carry is really K3 + K4, however, K3 and K4 cannot both be 
one (prove this) hence the carry to the third position is 
KARRY=IOR(K3,K4) 
Continue the program by adding the remaining two positions. 
8 ■ Write a simple program to simulate the macro compiler. The format 
of the cards containing the macro can be changed to fit in with 
Fortran READ statements (however, see Question 9 in Chapter 7). We 
suggest that the macro be read from cards by 
READ 500, NAME, N, M 
500 
FORMAT(A6, 214) 
READ 501, (NARG(I), 1 = 1,N) 
501 
FORMAT(6(A6,6X)) 
J1=1 
DO 100 1 = 1, M 
J2=J1+11 
READ 502, (NBODY(J), J = J1,J2) 
502 
FORMAT(12A6) 
100 
J1 =J1 +12 
NAME is the name of the macro. N is the number of arguments. 
NARG(l), NARG(N) are the arguments. The macro contains M 
164 

PROBLEMS 
165 
instructions. The body of the macro is read into NBODY(l),..., 
NBODY(12*M). The macro call is read by 
READ 502, NMCALL, MAC,(NCALL(I), 1 = 1,N) 
The program should now print (NBODY(K), K= 1,12*M) except that 
if NBODY(K).EQ.NARG(I), then NBODY(K) is replaced by 
NCALL(I). 
9 ■ Extend the program of Problem 8 by reading in several macros. Allow 
for the possibility that one macro calls another macro, as for example 
DST 
MACRO 
X,l 
STO 
X,l 
STQ 
X + 1,l 
ENDM 
DST 
DLD 
MACRO 
X,l 
CLA 
X,l 
LDQ 
X + 1,l 
ENDM 
DLD 
DEQ 
MACRO 
Χ,Ι,Υ,ϋ 
DLD 
XJ 
DST 
Y,J 
ENDM 
DEQ 
The actual input cards must be written in the format of Question 8. 
Find out about the macro features of the compiler on your machine. 
Are there any other macro features that you can put in your program ? 
10" Compile the test program of Section 4.10 on your compiler and get the 
assembly-language listing. Annotate the listing showing the relation of 
the Fortran and the assembly language. Start with the coding of 
arithmetic expressions and statement labels. Find out how the sine 
routine is called. Find out how single and double subscripts are 
computed. Mark any portions of the listing you do not understand. 

5-1 
INTRODUCTION 
THE 
COMPUTER 
SYSTEM 
5-2 
MAGNETIC TAPE 
In this section we will consider one type of 
magnetic tape that is used on many different 
computers. The tape is 2400 feet long and 
\ inch wide. It is made of a thin plastic and 
is coated on one side with a magnetic 
material. Small areas on the surface of the 
tape can be magnetized in one of two 
directions. Each of these small areas 
represents one binary digit. These magnetic 
binary digits are arranged in rows and 
166 
In the early days of electronic computers 
the machine was simply the central com-
puter together with some simple device for 
reading and punching paper tape. At a later 
stage the auxiliary store of magnetic tape 
or magnetic drum was added, but still the 
machine had not changed in its fundamen-
tals. In 1958, three developments began to 
change the character of the machine. These 
developments were, first, compiler lan-
guages; second, monitor systems; and 
third, multicomputer and interrupt sys-
tems. These three concepts seemed to be a 
natural development of the extensive use 
of computers, and no one person was 
responsible for any one of them ; neverthe-
less, these ideas did revolutionize the use of 
computing machines and they have made it 
almost possible for the programmer to 
keep up with the technological changes in 
the 
construction of the hardware. The 
overall complex of computing machine, 
auxiliary storage devices, monitor pro-
grams, and so on, constitutes the computer 
system. Before discussing these topics it is 
necessary to consider how the machine 
communicates with other devices such as 
magnetic tapes and disks, printers, other 
computers, or people. 
5 

5 ■ 2 MAGNETIC TAPE 
167 
columns on the tape. There are seven bits across the width of the tape. The 
numbers of bits along the tape is variable but may be 15,000,000 or more. 
The tape has an aluminum strip about 10 feet from either end; these strips 
constitute the beginning and end tape markers. The operator puts the tape 
on the tape unit and presses the load button. The tape unit has a reading 
and a writing head. Pressing the load button positions the tape so that the 
read/write head is just past the beginning of tape marker. 
Because input and output on modern machines is quite compli-
cated, we will first consider the simple type of I/O used on the IBM 704. 
The symbolic instruction WTB 5 is a machine instruction that prepares 
the machine to write on the tape that is loaded on unit number 5. The 
number of tape units that may be attached to the machine is variable, but a 
typical number is twelve. The symbolic instruction CPY X takes the word 
from location X and writes it on the tape that has just been selected, 
namely, tape 5. The following program copies three words onto tape 5: 
WTB 
5 
CPY 
A 
CPY 
A + 1 
CPY 
A + 2 
ORG 
8196 
A 
DEC 
127.,0.125.0.5 
The arrangement of the bits on the tape is shown in Figure 5.1. The octal 
equivalent of 127. is 207774000000. Each of the columns in the diagram 
contains seven bits ; in the first column, six of the bits represent the octal 
0 1 1 1 1 1 1 0 
1 1 1 1 
0 1 1 0 0 0 0 1 0 0 0 0 
1 1 1 0 0 0 0 1 0 0 0 0 
0 1 1 0 0 0 1 0 0 0 0 0 
0 1 1 0 0 0 1 1 0 0 0 0 
0 1 0 0 0 0 1 
0 0 0 0 0 
0 1 0 0 0 0 1 
0 0 0 0 0 
FIG. 5.1 
Arrangement of bits on magnetic tape 
digits 2 and 0, and the seventh bit forms a check. The seventh bit is chosen 
so that there is an odd number of bits in each column. When the tape is 
read, the machine checks that the seventh bit has the correct parity.' The 
second column on the tape corresponds to the next two octal digits 7 and 
7; the check bit is 1. Each 36-bit word from the store is represented by 
6 columns of information on the tape. On a typical tape there is a distance 
of y | ^ inch between each column on the tape. Words are written onto the 
tape as long as successive CPY instructions are given. 
<- check bit 

168 
5 THE COMPUTER 
SYSTEM 
It is usual to write a number of words, then to do some computing, 
then write more words, and so on. CPY instructions must follow each other 
within a short period. If more than about half a millisecond has elapsed 
since the last CPY, then another WTB instruction must precede any 
further CPY instructions. Suppose we give a WTB, then give 100 CPY 
instructions, then do some computing, then give another WTB, then give 
another 50 CPY instructions. The block of 150 words is not contiguous. As 
is shown in Figure 5.2, there are 100 words with no intervening gap, then 
100 words 
gap 
50 words 
gap 
next record 
1.08" 
Γ 
0.54" 
I" 
FIG. 5.2 Arrangement of records on magnetic tape 
there is a gap of about £ inch, and then another 50 words without a gap, and 
then another gap of £ inch. The £ inch gap is referred to as an interrecord 
gap. The information between the gaps is referred to as a record. In this 
example we have one record of 100 words and one record of 50 words. 
There is one additional mark that can be made on the tape. The 
instruction WEF 5 writes an end of file on the tape on tape unit 5. The end 
of file is a gap of about 3 inches followed by the end-of-file mark. An 
end-of-file mark is the character 17 written in the BCD mode. It is usual to 
write an end-of-file mark after all other information has been written. The 
end-of-file mark can be detected during reading. It can be used to separate 
large blocks of information, or it can be used to denote the end of the 
information on the tape. 
Reading the tape is accomplished by the read select instruction 
RTB followed by the appropriate number of CPY instructions. The CPY 
instruction on reading does three things. It reads a word, providing there 
is a word to be read. If there is no word, it signals whether an end of record 
or an end of file has been reached. The instruction 
L 
CPY 
X 
either reads the next word on the tape into location X and goes to location 
L + 1, or it senses an end of record and goes to location L + 2, or it senses 
an end of file and goes to location L + 3. The set of instructions, 
RTB 
5 
LXA 
=0,2 
CPY 
X,2 
TXI 
* - 1 , 2 , - 1 
TRA 
ENREC 
TRA 
ENFIL 
normally reads the next record on tape 5. It copies the words on the tape 

5 · 3 DATA CHANNELS 
169 
into locations X,X + 1 ,X + 2,..., and finally when the end of record is 
reached, it goes to location ENREC. If there is no record on the tape, but 
there is an end of file, then no words are copied, and control goes to 
ENFIL. 
The instruction REW rewinds a tape; thus REW 5 rewinds the 
tape on tape unit 5. At the start of the job any tapes to be used should be 
rewound. The information on the tape can only be recognized by the 
sequence of records on the tape. The instruction RTB followed by a CPY 
reads the next record to come under the reading head. If a record that is 
some distance further on along the tape is to be read, then it is necessary to 
skip over the intervening records by giving a sufficient number of RTB 
instructions. The RTB followed by a CPY always goes through a complete 
record. The tape does not stop in the middle of a record. If there are fewer 
CPY instructions than words in the record, the machine reads as many 
words as there are CPY instructions and the tape moves on to the end of 
the record. It is not possible to add information into the middle of a tape. 
Suppose a tape contains 90 records, and suppose record 44 has to be 
altered. If the first 43 records are spaced over and record 44 rewritten, then 
records 45, 46, and so on, cannot be read. The manufacturers of the tape 
unit do not guarantee that a record occupies a fixed length of tape. Even if 
the new record has exactly the same number of words as the old record, it 
might take up a slightly different amount of space. It is, of course, possible 
to risk writing in one record, but it is a dangerous practice. The only proper 
way to change on record is to copy the first 43 records onto another tape, 
skip the 44th record on the old tape, and write the new 44th record on 
the new tape, then copy the other records, as far as record 90, onto the 
new tape. 
A reel of magnetic tape contains a ring called the file-protect ring. 
This ring can be taken out of the reel before the reel is mounted on the tape 
unit. When the file-protect ring is removed the tape can be read, but it 
cannot be written on. If a tape contains information that needs to be 
protected, then the file-protect ring should be removed. It is usually not 
good practice to try to add information to existing information on a tape. If 
it is necessary to add to the information on the tape, then the old and the 
new information should be copied onto a new tape. Keeping the file-
protect ring out of the old tape makes sure that no programming error, 
operator error, or machine error can destroy the old information. 
5-3 
DATA CHANNELS 
A general description of data channels and the way in which they are used 
was given in Chapter 1. It would be appropriate to reread Sections 1.5 and 
1.6 at this point. The main components of the IBM 7090 and the connec-
tions between these units was shown in Figure 1.6. The different channels 

170 
5 THE COMPUTER 
SYSTEM 
on the 7090 are denoted as A,B,C, and so on. Machines usually have either 
two or four channels, although they may have more. The tape units are 
designated A1,A2,...,B1,B2,..., with Α,Β,... denoting the channel and 
1,2,... the unit on that channel. There is a rotary switch on the tape unit 
which is used to indicate the unit number. Unit numbers can be changed 
simply by turning the switch but it is usual to leave the unit numbers fixed. 
Tape units on the 7090 cannot be switched from one channel to another 
(except on a few 7090's that have had their hardware modified). The 
following piece of a program shows how the contents of locations 
X,X + 1,..., X + 1 9 can be written onto the tape on unit A2. 
WTBA 2 
select tape unit 
RCHA 
CM 
give command 
CM 
IOCD 
X„20 
command to write 20 words 
The first instruction selects the required tape unit and specifies that a binary 
write operation is to be done. The second instruction tells the channel that 
the command is to be found in location CM. RCHA stands for reset and 
load channel A. Once this instruction has been given, then the program is 
free to carry out any other instructions. Channel A picks up the contents 
of location CM and uses it as a command to determine which I/O operations 
are to be performed. IOCD stands for input-output under count control 
and disconnect. The channel writes the word from location X, then the 
word from location X + 1, and so on. When 20 words have been written, an 
end-of-record gap is written and the channel disconnects. All the I/O 
processing is under the control of the channel. Between the RCHA instruc-
tion and the disconnection of the channel, the CPU program has no 
control over the write operation and the CPU is free to compute or to issue 
I/O requests on the other channels. While the writing operation is in 
progress, the CPU program should not change the contents of locations X 
through X+19. Some computers have either a hardware or a software 
mechanism that prevents the contents of these locations from being 
changed until the I/O operation is complete. On the IBM 7090 there is 
nothing to prevent the programmer from changing the contents of any 
location. The channel gets a word from memory whenever it needs to 
write that particular word. If the programmer changes the contents of 
location X + I, then the old or the new value is written onto tape depend-
ing on whether the word had not or had been written at the moment when 
the CPU program stored the new value in location X + I. It is obviously 
very poor programming and may well lead to mysterious errors if the 
program changes the contents of any of the locations that are currently 
involved in any I/O operation. 
There are several other commands in addition to IOCD. The 
command IOCP does an input-output under count control and proceeds 
to the next command. It is identical to IOCD except that the channel does 

5 · 3 DATA CHANNELS 
171 
not disconnect when all words have been written. The channel goes on to 
pick up a new command from the next location. 
WTBA 
2 
RCHA 
CMA 
CMA 
IOCP 
X„20 
IOCD 
Y„5 
would cause the channel to write one record of 25 words. The words 
would come from locations X,X + 1,...,X + 19,Y,Y + Ι,.,.,Υ + 4. Read 
operations are similar to write operations. 
RTBA 
3 
RCHA 
CMB 
CMB 
IOCD 
Z„90 
causes the channel to read 90 words from the tape on unit A3, and to place 
the words in locations Z through Z + 89. The IOCD operation causes the 
channel to read the tape and to ignore the inter-record gap. When reading 
tape, it is more usual to use the command IORP Ρ,,Ν which reads words 
into locations P,P + 1,.... It continues reading until it has read N words 
or until an end-of-record gap is reached. 
RTBA 
3 
RCHA 
CMC 
CMC 
IORP 
Z„90 
IOCD 
0„0 
reads the next record on tape A3. Suppose the record contains N words. If 
N is less than or equal to 90, then N words are read. If N is greater than 
90, then 90 words are read, but the tape continues in motion to the end of 
the record and N — 90 words are ignored. IORP does not disconnect the 
channel; the IOCD 
0,,0 is necessary for disconnection. 
These commands for reading and writing tapes on the IBM 7090 
are typical of the commands for all I/O devices and of the commands 
available on all modern machines. To summarize the situation: The 
channel is like a very simple computer that can obey simple I/O orders. It is 
usual to reserve the word " instruction " for the orders that can be obeyed 
by the CPU. The word " command " is used for the orders that are obeyed 
by the channels. The CPU waits until the channel is inactive and then 
selects the channel and the unit. It also tells the channel where to find its 
first command. The channel picks up the command and proceeds to obey it. 
The CPU and the channel operate quite independently of each other. 
Separate channels also operate independently of each other. When the 

172 
5 THE COMPUTER SYSTEM 
channel has obeyed all of the commands associated with one read or write 
operation, then it disconnects. 
The CDC 3600 communicates with the I/O equipment in a way 
similar to the 7090. There is an instruction to select the unit and an 
instruction to issue the command. Once the command has been issued, the 
CPU and the channel proceed independently of each other. There is one 
significant difference between the two computers. The 3600 computers 
usually have four channels and any unit can be accessed through any 
channel. In the 7090 the unit is fixed to the channel. In the 3600 there is a 
program-controlled switch between the channel and the unit and any unit 
can be attached to any channel. A unit may be switched from one channel 
to another throughout the course of the program. When an I/O operation 
is to be initiated, the CPU program can elect to use any channel that is not 
currently in use. This makes it easier to implement an input-output 
monitor which is both simple and efficient. 
The PSW (program status word) of the IBM 360 contains informa-
tion about the current program. One particular bit of the PSW indicates 
whether the routine that is currently in control belongs to the ordinary 
program or to the monitor program. Some of the 360 instructions are said 
to be privileged instructions. This means that they cannot be used by the 
ordinary programmer. Whenever a privileged instruction is requested, the 
machine looks at the PSW, and if it sees that an ordinary program is in 
control, the machine does not obey the instruction but it does call the 
monitor. The 360 instruction SIO is the start input-output instruction. It is 
a privileged instruction. SIO corresponds to the WTB and the RCH in-
structions of the 7090. SIO tells the machine which device on which channel 
is to be selected. Location 64 (it is a fixed location) is called the CAW, the 
channel address word. The CAW tells the channel where to find the 
CCW, the channel command word. The CCW corresponds to the com-
mand of the 7090. The CCW specifies the address of the first byte and the 
number of bytes to be transmitted. It also specifies whether reading or 
writing is to take place. 
5-4 
THE INTERRUPT SYSTEM 
The operation of a channel is initiated by the CPU. After this initiation the 
channel continues to operate without any more instructions from the 
CPU. It obeys all the commands that were given and finally it disconnects. 
On the IBM 709 the disconnection of a channel has no effect on the CPU. 
The CPU initiates the I/O operation and at some later time it looks to see 
if the channel is still in operation. If the channel is still active, then the 
CPU program stays in a small loop, waiting for activity to cease. If channel 
activity has ceased, then the CPU can begin a new I/O operation. On the 
IBM 7090, the CDC 3600, the IBM 360, and many other machines, the 
disconnection of a channel causes an interrupt. 

5 ■ 4 THE INTERRUPT SYSTEM 
173 
Suppose the CPU is currently obeying a program instruction from 
location L when the channel ceases operation. The interrupt mechanism 
causes the following events. The CPU continues obeying the instruction 
from location L and at the end of the instruction it updates the instruction 
counter in the normal way. Let N denote the new value of the location 
counter. The CPU does not take the next instruction from location N 
but it stores the number N in some fixed location and jumps to another 
fixed location. For example, on the IBM 7090 an interrupt on channel A 
causes N'to be stored at location 10 and the CPU jumps to location 11. At 
location 11 the systems programmers have placed a jump to the interrupt 
processing routine. The interrupt processing routine disables any further 
interrupts. Disable is an instruction that indicates to the interrupt hardware 
that an interrupt is being processed and that any other interrupts have to 
wait in a queue. The converse of disable is enable. Enable indicates that 
interrupts may now occur. The interrupt routine proceeds to examine the 
cause of the interrupt. From this point on the interrupt routine is similar 
to any other routine and it could be written in compiler language, although 
it usually is not. Suppose the interrupt has been caused by the termination 
of a write tape operation. The routine examines a certain word that the 
channel has set up. This word indicates how many words were written and 
it indicates whether any errors have occurred. If errors have occurred then 
the interrupt routine backspaces the tape and tries again. Experience will 
indicate how many attempts should be made and special techniques are 
available such as erasing several inches of tape and making another try. If 
all attempts fail, then the job is usually abandoned. If the write is successful, 
and, of course, it usually is successful, the interrupt routine makes a note of 
this fact and then looks at the queue to see if any more I/O operations 
need initiating. If there are entries in the queue and if the channel and the 
equipment are not currently active, then the I/O command is issued. 
Finally, the routine restores the contents of any register that it used; it 
enables the interrupt system and jumps to location N. The CPU now starts 
obeying the instruction at location N and the execution of the ordinary 
program continues. There is one further complication. When the interrupt 
routine enables the interrupt system, just prior to jumping to location N, it 
may happen that another interrupt is waiting to be processed. If this is the 
case, then the interrupt routine is re-entered and the processing of the next 
interrupt begins. 
The important point to realize about the interrupt is that it 
does not disturb the operation of the main program in any way. The 
hardware is so designed that it stops obeying the main program, goes to 
the interrupt routine, and comes back to restart the main program as 
though no interruption had occurred. The main program does not have to 
be written in any special way and it cannot detect that an interrupt has 
occurred unless it happens to have access to a clock. The following program 
illustrates this point. Suppose CLOCK (C) is a subroutine that sets X equal 

174 
5 THE COMPUTER 
SYSTEM 
to the time in seconds that has elapsed since the beginning of the job. 
CALL 
CL0CK(X1) 
CALL 
ALPHA 
CALL CL0CK(X2) 
X = X2-X1 
PRINT 
500,X 
500 
FORMAT (11 H ALPHA TOOK E15.6,8H SECONDS) 
This program supposedly prints out the time taken to go through sub-
routine ALPHA, but in fact the result might be quite erroneous. If an 
interrupt happens to occur between the two calls to CLOCK, then X 
measures the time for ALPHA plus the time for the interrupt. To time 
ALPHA accurately it would be necessary to 
CALL 
CLOCK(X1) 
DO 
100 
1 = 1,M 
100 
CALL 
ALPHA 
CALL 
CLOCK(X2) 
where M is chosen so that X2 —XI is at least 1 second. If an interrupt does 
occur due to previous READ or WRITE operations, then the time for the 
interrupt does not significantly bias X2 — XL In this discussion we have 
assumed that the computer is processing only one program at a time, and 
that only a small number of buffers full of information are waiting to be 
processed at the time when ALPHA is entered for the first time. If the 
system is involved in extensive multiprogramming, then the system ought 
to provide a separate clock for each job. When one job is running, the 
associated clock should also be running, but all other clocks should be 
stopped. In far too many present-day systems it is impossible for the user 
to time his routines. 
The advantage of the interrupt system is that the I/O routines are 
entered when they need entering. The main program does not have to keep 
jumping off to the I/O routines to see if any I/O requests need servicing. The 
main program is automatically interrupted whenever anything needs 
doing. 
The interrupt system on the 360 is similar in principle to that on 
the 7090, but it is organized more efficiently. There is an elegant mechanism 
for switching from the ordinary program to the supervisory program. The 
PSW contains information about the current program. It contains such 
things as the current address, the type of program (ordinary or supervisor), 
and the type of interrupts that are permitted. The ordinary program has a 
PSW and the I/O monitor routines have a PSW. When the ordinary 
program is in operation, the monitor PSW is not in use but it is saved at 
location 120. Whenever an I/O interrupt occurs, the machine stores the 
current PSW at location 56 and picks up a new PSW from location 120. The 

5 - 5 OTHER I/O DEVICES 
175 
single action saves the status of the program, disables further interrupts, and 
switches control to the I/O interrupt routine. When the interrupt has been 
processed, the old program can be resumed by picking up the contents of 
location 56. 
The 360 actually has several types of interrupt, namely, I/O 
interrupts, program interrupts, supervisor call interrupts, external inter-
rupts, and machine-check interrupts. The first 128 bytes of memory are 
allocated for specific purposes. Each type of interrupt has its PSW which is 
stored in a fixed location in the first 128 bytes of memory. Each type of 
interrupt has a different place to store the current PSW. A program 
interrupt is caused by such things as trying to divide by zero. A supervisor 
call is caused by the program using the instruction SVC in order to call 
the supervisor. An external interrupt can be caused by the clock or by some 
external device such as another CPU if the machine happens to have several 
CPU'S. A machine-check interrupt occurs when one of the checking circuits 
detects a machine malfunction. The provision of several different types of 
interrupt aids in the organization and efficiency of the supervisory pro-
grams. It means, for example, that one type of interrupt can interrupt 
another type of interrupt without any complications in the supervisor. It is 
usual to give different priorities to the different interrupt types. The 
program and SVC interrupts have a higher priority than the I/O interrupts. 
5-5 
OTHER I/O DEVICES 
There are many different I/O devices because there are many different 
needs and no one device can satisfy all of them. Some of the purposes for 
which the I/O units are used are 
(a) Input of programs and data 
(b) Saving information during the course of the program 
(c) 
Saving large volumes of output for later processing 
(d) Output of data 
(e) 
Saving the system and the library routines 
(f) 
Displays 
The traditional method of preparing programs and data is to use punched 
cards or punched paper tape. On the larger machines there is usually an 
off-line operation or a time-sharing operation to transfer the cards or tape 
to a tape or disk. Until 1963, magnetic tapes were used for items (b) 
through (e). With the advent of the large magnetic disk files, a new method 
of operation became economically feasible. The disks could easily be used 
for items (b) and (e). Item (d) could be stored on the disk while it was 
waiting to be printed. Some installations are saving information of type (c) 

176 
5 THE COMPUTER 
SYSTEM 
on the disk also. Each programmer is allocated many thousands of words 
of disk space. He can use this to store material from day to day and, for 
example, he might store a copy of the programs on which he is working. 
Display devices such as graph plotters and cathode-ray tubes have been 
available for a number of years, but recently the use of displays for written 
information has become common. 
The magnetic tape described at the beginning of this chapter has 
a density of 556 characters to the inch; that is, the successive columns of 
Figure 5.1 are j
^ inch apart. A tape density of 200 characters per inch was 
used on the IBM 704 and is still used on some tape units. Modern high-
performance units can write 800 characters per inch. In order to accom-
modate the tapes that were generated on other machines, many tape units 
can read or write either 200, 566, or 800 characters per inch. The density 
can be controlled by the operator or by the program. Many manufacturers 
conform to a standard in writing tapes. Tapes written on the IBM 7090, 
the IBM 1401, the CDC 3600, the CDC 160, and many other machines are 
interchangeable. These machines use different representations of binary num-
bers so that it is usually easier to use the BCD mode when transferring data 
from one machine to another (see Section 5.7). The rate of reading or writing 
is determined by the tape density and the tape speed. Many tape units are 
designed to move at 112.5 inch per second, so that, with a density of 556 
characters per inch, the information is transferred at 62,550 characters per 
second. This rate is only sustained while the record is being read. The 
inter-recorcf gap is f inch so that the actual time to read one record of N 
characters is s + 7V/62.550 milliseconds where s is the time taken to start 
the tape in motion and to traverse the inter-record gap. The starting time s 
is typically about 6 milliseconds. If the records are short, we can see that a 
significant time is wasted in starting to read or write. The tape is 2400 feet 
long so at 112 inches per second it could take 2\ minutes to rewind the 
tape. Most tape units have a special high-speed rewind that enables them 
to rewind a full tape in 1 minute. 
The tape on the IBM 360 is the standard \ inch wide, but it has 
nine tracks across the width of the tape. Eight of the tracks carry informa-
tion and one track has the parity check bit. The eight bits across the tape 
can represent one byte or two decimal characters. The tape units are 
available in several models. The 2400 model 3 uses a density of 800 bytes per 
inch and a tape speed of 112.5 inches per second, so the reading or writing 
rate is 90,000 bytes or 180,000 decimal digits per second. The inter-record 
gap is 0.016 inch. 
Some machines make use of preaddressed tape. This tape is 
similar to ordinary magnetic tape but certain information is written on the 
tape before the tape is first used. This information divides the tape into 
blocks. Each block has a number followed by sufficient space to write 
512 words. The number 512 is not a universal standard, but it is commonly 
used. The tape is used by first specifying the block number and then writing 

5 - 5 OTHER I/O DEVICES 
177 
a maximum of 512 words in one record. There are some advantages to this 
type of tape. Since each record is marked by the block number, the channel 
can be instructed to find a particular record. It is also possible to fill in 
information. For example it would be possible to write information in 
records 1,3, and 5 and then go back and fill in 2 and 4, and then later still 
one could go back and change the contents of record 1 without destroying 
the information in the other records. It will be remembered that ordinary 
tapes have to be written in strict sequence so that if record 1 is rewritten, 
none of the other records on the tape are any longer readable. 
A magnetic drum is a rotating cylinder coated with some magnetic 
material. Information is recorded magnetically on the drum in a set of 
distinct tracks. A track is the circle that would be obtained by cutting the 
surface of the drum perpendicular to its axis. The information in one 
track is usually considered as one record. Suppose the drum makes one 
complete revolution in r milliseconds; then intakes at least r milliseconds 
to read one record. A read/write head is positioned over each track. In 
some drums there is one read/write head for every track. In other drums 
there are fewer heads than tracks and it is necessary to move the head until 
it is over the desired track. Let m denote the time to move the head into 
position (if there is a head for every track, then m is zero). Let r denote the 
time for one revolution of the drum. The drum is always rotating at a 
constant speed—it does not start and stop like a tape unit does. The time 
taken to read one record is m milliseconds to move the head, plus some-
where between zero and r milliseconds to wait until the beginning of the 
record comes around, and then another r milliseconds to read the record. 
The average time is m + 3 r/2. In some drums it is possible to keep an 
account of the drum position and to minimize the time spent in waiting 
for the beginning of the record to come around. To give an example of 
magnetic-drum storage: The 7320 drum for use with the IBM 360 has 400 
tracks. The total capacity of one drum is 830,000 bytes but several drums 
can be attached to the machine. The time for one revolution is 17.2 
milliseconds. There is a head for every track so that the time to access the 
beginning of a track is 8.6 milliseconds on average. The maximum rate of 
reading and writing is 136,000 bytes per second. The IBM 2301 drum has 
a capacity of 4 million bytes. The average access time is 8.6 milliseconds 
but data is taken from several tracks in parallel so that a transfer rate of 
1.2 x 106 bytes per second is achieved. 
A disk store usually has a larger capacity than a drum but the 
access time is greater. Each disk storage unit has ten or more disks. Some 
disk files have 12-inch diameter disks but some disks are up to 48 inches in 
diameter. Each disk is coated with magnetic material and the information 
is recorded magnetically on the surface of the disk. A single track consists 
of one circle on the surface of the disk having its center on the axis. The 
disks rotate about a common axis. In most of the disk-storage units that 
are currently available there are only one or two read/write heads for each 

178 
5 THE COMPUTER SYSTEM 
disk surface. Let the disk surfaces be numbered 1 through N and let the 
tracks on each disk be numbered 1 through M. Let (/,/) denote the /th track 
on the /th disk. There are N x M tracks altogether. The read/write heads 
move in parallel; this means that if the first head is opposite track (1,/) 
then the other heads are opposite tracks (2,/),...,(#,/). If the next read 
requires access to the contents of track (L,K), then the read/write arms must 
move until they are opposite the Kth track. This movement of the heads 
requires mechanical movement and is consequently a slow operation. The 
average time to read or write one track is / + 3r/2, where t is the time taken 
to move the arm and r is the time for one revolution. The set of tracks 
(l,/),(2,/),...,(iV,/) is called a cylinder. Some disks can read every byte in 
one cylinder with one read instruction, and so the whole operation takes a 
time of only / + \r + Nr compared to the usual average time of t + 3Nr/2. 
The IBM 2302 disk model 4 has a capacity of 224 x 106 bytes— 
that is, 1.8 billion bits. It has two independent sets of access arms. Each 
track contains 4984 bytes. The minimum access time is 50 milliseconds and 
the maximum access time is 180 milliseconds. Once the reading and writing 
has begun, the data is transferred at 156,000 bytes per second. The 2311 
disk is smaller—it has a capacity of 7-million bytes—but the disks are only 
the size of a stack of phonograph records and they can easily be removed 
and replaced on the unit. This disk pack is more expensive than magnetic 
tapes for off-line storage but the semirandom access is useful in some appli-
cations. There is one large disk system that does have one head for every 
track. The provision of 5000 separate heads makes this disk expensive, but 
its performance is greatly superior to the moving-head disks. 
If the moving-head type of disk is being used on a single program, 
it can be programmed efficiently, but in more typical applications it is 
almost impossible to use the disk efficiently without a very large buffer 
area. To give an example, in a multiprocessing application the system must 
write card input onto the disk ; it must fetch printer output from the disk ; it 
must fetch system programs from the disk; and must use the disk for 
program working space. The head mechanism can be opposite only one set 
of tracks at a time and it is impossible to satisfy all these demands without 
continual time-consuming movements of the heads. 
The cost of core memory is proportional to the size and inversely 
proportional to the speed. Some computers can be equipped with a large 
slow-speed core store to supplement the main core memory. The 2361 core 
on the IBM 360 has a capacity of one or 2-million bytes. Several units can 
be attached to one machine to give 8.4-million bytes of random access 
core store with a read/write time of 8 microseconds per double word of 
8 bytes. The main memory can have up to 1-million bytes with a read/write 
time of 0.75 microsecond. 
To give some idea of the capacity of other input and output 
units, the typical card reader can read 800 cards a minute. This corresponds 
to 1066 characters per second, or in the binary mode to 12,800 bits per 

5 · 5 OTHER I/O DEVICES 
179 
second. A printer can print 1000 lines per minute, which is about 2000 
characters per second. A card punch can output about 400 characters or 
5000 bits per second. 
There are several different types of display devices. The unit used 
for time-sharing consoles consists of a typewriter keyboard and either a 
typewriter printer or a CRT (cathode-ray tube) character display. The latter 
device usually has a small memory so that the display can be maintained 
without using computer time. The user types a message on the keyboard 
and the message appears on the screen. If the message is not correct, then 
it can be edited from the keyboard. When the message is correct, the user 
presses a button to signal the computer. The computer can read the 
message and return an answer on the display. The display can accommodate 
about 1000 characters. This type of console has the advantage that the 
computer can transmit several thousand characters a second so that the 
user can receive a replay very quickly and arrange to scan through an 
extensive set of data. The typewriter printer costs approximately the same 
as the CRT display. It has the disadvantage that printing is limited to ten 
or twenty characters a second, but it has the advantage that the user has a 
copy of all messages. 
A more expensive and elaborate CRT can be used for graphical 
display. The computer can generate lines on the face of the tube. Programs 
can be written to represent any character or curve by joining segments of 
straight lines. Some displays can draw both lines and characters. It is 
possible to photograph the surface of the CRT and produce a hard copy of 
the display. The mechanical graph plotter is much cheaper than the CRT 
type of plotter. It consists of a mechanism for driving a pen across a piece 
of paper. In one commonly used plotter, the plotter is driven by commands 
from a magnetic tape. The plotter can obey ten different commands; 
namely, lift the pen off the paper, lower the pen onto the paper, move the 
pen a hundredth of an inch in the direction 0°, 45°,..., or 315°. Each 
character and each curve has to be represented by a series of short lines. 
We do not propose to discuss the programming of the great 
number of I/O devices that are available. The operation of most devices 
is similar to the tape instructions that have already been discussed. The 
CPU program selects the channel and the device and the channel controls 
the rest of the operation. In earlier machines such as the IBM 704 each 
device was programmed in a different manner. Some attempt was made 
in the 7090 to achieve uniformity, and finally in the IBM 360 the CPU 
instructions are almost completely device independent. The average 
programmer has almost no opportunity to use basic I/O instructions. In 
the sections that follow we will assume that adequate software exists for 
performing the basic operations, but we will discuss topics such as buffering, 
blocking, the translation from BCD to binary, and so on. Some of the 
typical characteristics of I/O devices are summarized in Table 5.1. Magnetic 
tapes give a cheap method of storing information and a rapid method of 

180 
5 THE COMPUTER 
SYSTEM 
TABLE 5-1 
CAPACITY and PERFORMANCE of TYPICAL I/O DEVICES. 
Time to Access 
Start of Record 
Transfer Rate 
Capacity in Characters 
in Millisecs 
Characters/sec 
TAPE 
DRUM 
DISC 
CARDS 
PRINTER 
1.5E 7 PER TAPE 
4.0E 6 
1.0E 8 TO 4.0 E 8 
80 PER CARD 
120 PER LINE 
6 
0 TO 17 
0 TO 200 
10 
10 
1.0E 5 
.1 TO 1.2E 6 
1.6E 5 
1.3E 3 
2.0E 3 
transferring data to and from the computer. Drums are more flexible and 
reliable than tapes, but they cannot be removed from the machine. Disks 
have a larger capacity than drums but they are usually much slower. Disks 
are extremely useful but the time to access information is 105 to 106 times 
the time for one machine instruction. 
5-6 
ALPHANUMERIC INFORMATION 
Information that is to be stored in the computer memory must be in 
binary form. Alphanumeric information can be stored by representing each 
character by several binary digits. The IBM 1401, the IBM 7090, the 
CDC 3600, the CDC 6600, and many other machines use six bits for each 
character. There are two 6-bit schemes in common use. These two schemes 
will be called internal and external BCD. Again, BCD stands for binary 
coded decimal. When used in connection with the machines just mentioned, 
BCD refers to the 6-bit representations shown in Table 5.2, but BCD is a 
portmanteau term that is applied to many different ways of representing 
decimal or alphanumeric information. The IBM 7090 uses internal BCD 
when characters are stored in the memory. In Section 2.10 we described 
the assembler pseudo-operation BCD that can be used to assemble BCD 
information. 
Octal 
Assembler instruction 
212223000224 
BCD 
2ABC02D49X .Z 
041167603371 
The number 2 at the beginning of the assembler operand indicates that 
2 words, that is 12 characters, are to be assembled. The assembled words 
are shown in octal on the left-hand side. The I/O instruction WTB was 
described in Section 5.2. There is an instruction WTD which writes tape 
in the BCD mode. Tapes written by the WTB instruction have odd parity; 
the check bit is chosen so that the sum of the bits in any one column of the 

5 · 6 A L P H A N U M E R I C I N F O R M A T I O N 
181 
TABLE 5-2 
OCTAL REPRESENTATION of BCD and HEXADECIMAL 
REPRESENTATION of some EBCDIC CHARACTERS. 
Internal 
External 
EBCDIC 
BCD 
BCD 
0 
1 
2 
3 
4 
5 
6 
7 
8 
9 
A 
B 
C 
D 
E 
F 
G 
H 
I 
J 
K 
L 
M 
N 
0 
P 
Q 
R 
S 
T 
u 
V 
w 
X 
Y 
z 
+ 
— 
* 
/ 
$ 
> 
( 
= 
, 
0 
1 
2 
3 
4 
5 
6 
7 
10 
11 
21 
22 
23 
24 
25 
26 
27 
30 
31 
41 
42 
43 
44 
45 
46 
47 
50 
51 
62 
63 
64 
65 
66 
67 
70 
71 
20 
40 
54 
61 
60 
53 
33 
34 
74 
13 
73 
12 
1 
2 
3 
4 
5 
6 
7 
10 
11 
61 
62 
63 
64 
65 
66 
67 
70 
71 
41 
42 
43 
44 
45 
46 
47 
50 
51 
22 
23 
24 
25 
26 
27 
30 
31 
60 
40 
54 
21 
20 
53 
73 
74 
34 
13 
33 
F0 
F1 
F2 
F3 
F4 
F5 
F6 
F7 
F8 
F9 
C1 
C2 
C3 
C4 
C5 
C6 
C7 
C8 
C9 
D1 
D2 
D3 
D4 
D5 
D6 
D7 
D8 
D9 
E2 
E3 
E4 
E5 
E6 
E7 
E8 
E9 
4E 
60 
5C 
61 
40 
5B 
4B 
5D 
4D 
7E 
6B 

182 
5 THE COMPUTER 
SYSTEM 
tape is odd. Tapes written by WTD have even parity; the check bit is 
chosen so that there is an even number of bits in each column. WTD also 
changes the characters as they are written onto the tape; it converts them 
from internal to external BCD. The translation does not slow down the 
writing operation. The reverse translation is performed on reading. The 
reason for having both internal and external BCD seems to be mainly 
historical. Internal BCD is used because the digits have their most natural 
representation and the numerical ordering of the letters corresponds to the 
alphabetic ordering. Actually a completely different scheme would be more 
useful, but it has been economically necessary to use a scheme that can 
easily be translated from the traditional punched-card representation of 
the characters. External BCD was used on the IBM 704 tapes because 
some equipment for doing card-to-tape and tape-to-printer operations was 
already available and this equipment used external BCD. The octal code 00 
cannot be written on BCD tapes. Since BCD tapes are in even parity, 00 
produces a tape character with all zero bits. Such a character cannot be 
read since it corresponds to completely blank tape. The octal code 00 is 
not used in external BCD. 
The CDC 1604 and the IBM 1401 use external BCD both on 
magnetic tapes and in the memory. On the 1604 the assembler produces 
Octal 
Assembler instruction 
6162631202640411 
BCD 
1ABC02D49 
with external BCD code and eight 6-bit characters in each word. The 
CDC 3600 uses external BCD on tapes and either internal or external BCD 
in memory, depending on a programmer option. 
The IBM 360 assembler uses an 8-bit representation of characters. 
The particular scheme usually used is EBCDIC (extended BCD for inter-
change code). A hexadecimal representation of the code is shown in 
Table 5,2. An 8-bit code allows up to 256 different characters. It is possible 
to have more than 64 characters with a 6-bit code by using a character that 
denotes a shift (similar to the use of a shift key on a typewriter). This type 
of code is used on some paper-tape punches. Shift characters are not too 
inconvenient when the characters are read one at a time, but a scheme such 
as EBCDIC, which allows a wide range of characters without the use of 
a shift, is necessary for the efficient processing of information within the 
machine. 
5-7 
BINARY VERSUS BCD 
Since a record can be written and read in the binary or BCD mode, the 
question arises of which mode should be used. The answer depends on the 

5 · 7 BINARY VERSUS BCD 
183 
circumstances. For most of the problems that arise in scientific computa-
tions, the information in the memory is in binary form. In the IBM 7090, the 
number 99 is held in memory either as an integer in the form 143 octal or 
as a floating-point number 207614000000. Numbers of this form can be 
written directly onto magnetic tape. The Fortran statement 
WRITE 
(N) 
X 
is a typical binary write statement. The BCD statement, 
WRITE 
(N,500) 
X 
500 
FORMAT(6F4.1) 
involves two distinct operations. A number such as 207614000000 has to be 
converted to the form 11113300 (that is, 99.0 in BCD) and then it is 
written onto the I/O unit. The actual BCD write operation takes exactly 
the same time as a binary write operation (assuming the same number of 
words are involved). The translation from floating binary to BCD is a 
time-consuming operation; it typically might take several milliseconds for 
each word that is translated. This translation, and the converse translation 
from BCD to binary, means that the BCD read or write is usually much 
slower than a binary read or write. 
If the information to be written on magnetic tape is to be used by 
another computer, then BCD should usually be used ; if the information is 
only to be read back by the same computer, then binary should usually be 
used. One might, for example, generate a BCD tape on the IBM 7090, and 
print or sort the tape on an IBM 1401. Even when transmitting information 
between two large machines, it is advisable to use BCD tapes. For example, 
the CDC 3600 can easily read BCD tapes generated on the IBM 7090 
providing the number of characters per record is a multiple of 8. The 
CDC 3600 can also read binary tapes produced by the IBM 7090, but there 
is a difficulty in using the tapes because of the different representation of 
binary numbers in the two machines. Small computers such as the IBM 
1401 and the CDC 160 can read binary tapes; however, if the information is 
to be printed, punched, or manipulated in any other way, then the BCD 
representation is almost invariably used. Translating from the floating-point 
form to BCD form is very difficult and time consuming on these small 
machines. This situation might change due to improvements in hardware. 
At present any information to be printed is translated to BCD in the main 
computer. In the future it may be economical to output the binary data 
plus the format and to do the translation on the off-line computer. 
In Fortran IV and Fortran II, a BCD read or write is always 
accompanied by a binary-BCD conversion. In Fortran 63 it is possible to 
read or write a BCD tape without doing the conversion. One might wish 
to avoid the conversion in the following type of problem. A tape contains 

184 
5 THE COMPUTER 
SYSTEM 
records of 120 characters. Each record refers to an experimental result. The 
first six characters of the record give the time at which the measurement 
was made. Write a program to go through the tape and print the results 
for all times that lie between certain limits. In order to solve this problem 
it is necessary to read in the 120 character records but it is not necessary 
to convert the records to binary. The ordinary Fortran BCD read opera-
tion would solve this problem, but it would be quite inefficient. BCD 
reading and writing without translation is discussed in Section 7.7. 
The IBM 360 has only one mode when writing tapes. PL/1 intro-
duces a format called IG. IG stands for internal general. If data is to be 
read or written under IG format, then it is read or written without any 
conversion. This implies that IG is the PL/1 equivalent of the Fortran binary 
read and write statements. 
5-8 
LOGICAL and PHYSICAL RECORDS 
The Fortran statement 
WRITE 
(5) 
(C(l), 1 = 1,N) 
tells the I/O routines to write the N words C(l), C(2),...C(N) onto unit 5. 
In the 704 Fortran, a single record of N words would be written. In later 
versions of Fortran and in most other I/O systems, it has been found 
necessary to write several records for each WRITE statement. For example, 
in Fortran II the WRITE operation is controlled by a routine named 
(STB), and this routine writes no more than 255 data words in each record 
on the tape. Using the WRITE statement given above, if N < 255 then one 
record is written. If 255 < N < 510 then two records are written with 
C(l), C(2), ..., C(255) in the first record and C(256), C(257), ..., C(N) in the 
second record. If N is greater than 510, then three or more records are 
written. There are two reasons for having an upper limit to the number of 
words in one record. In the first place it allows an upper limit to be placed 
on the size ôf each buffer area. In the second place it may be necessary for 
the efficient use of the I/O device. For example, when writing onto a disk, 
the upper limit may correspond to the number of words that can be placed 
on one track. 
A Fortran WRITE statement is supposed to write one record, but, 
in fact, it may write several records. It is useful to introduce the notion of 
logical and physical records. A physical record consists of the information 
that occupies a series of consecutive locations in some memory device. On 
magnetic tape a physical record is the information between two record 
gaps. On a disk or drum a physical record is usually one track. A card or a 
line of printing also constitutes a physical record. A logical record consists 
of the information transmitted by one Fortran WRITE statement. In order 

5 · 9 BASIC INPUT AND OUTPUT 
185 
to demarcate the logical record, the (STB) routine in Fortran II writes one 
extra word in each record. In the example given above, suppose N has the 
value 700. The first physical record consists of 256 words; the first word is 
zero, the other words correspond to C(l) through C(255). The second record 
contains 256 words, a zero word and words corresponding to C(256) 
through C(5l0). The last record contains 191 words. The first word 
contains the integer 3 and the integer 190. This nonzero word signifies 
that this physical record is the last physical record in this logical record. The 
3 signifies that there are 3 physical records in all. The 190 signifies that 
there are 190 words to follow. These words correspond to C(511) through 
C(700). 
Supposing we now give a BACKSPACE 5 instruction. The com-
puter backspaces one logical record. It actually proceeds as follows: It 
makes sure that the previous operations on tape 5 are complete. It back-
spaces one record. It then reads one record, and in doing so it finds the 
3 which gave the number of physical records. It then backspaces over the 
record that it has just read and over two more physical records. This is one 
more example of the deceptive behavior of the software. The programmer 
thinks that he has written one record and all operations proceed as though 
he had written one record, but actually he has written three physical 
records. 
The operation of the READ TAPE statement is controlled by a 
routine called (TSB). It contains two 256-word buffers. It reads a record 
into the first buffer and waits until the read is completed. It then looks at 
the code word. If it is zero, it gives the command to read the next record into 
the second buffer. It transfers the contents of the first buffer into the area 
specified in the READ statement. When this is complete, it checks the read 
that was being done in the second buffer, and so on. It always keeps on 
reading until it comes to the nonzero control word. If the READ state-
ment asks for fewer words than there are on the tape, the routine skips to 
the end of the logical record. If the READ asks for too many words, then 
(STB) causes the job to be abandoned. 
5-9 
BASIC INPUT and OUTPUT 
In the Fortran compiler on the IBM 704, a statement such as 
WRITE 
TAPE 
5, 
A,B,C 
generates a WTB 5 instruction followed by three CPY instructions. It was 
explained in Section 1.5 that Fortran II, Fortran IV, PL/1, and most other 
compilers, translate all READ and WRITE statements into calls to a 
library subroutine. The general principles of the operation of these routines 
was discussed in Chapter 1. In the next few sections we will describe these 

186 
5 THE COMPUTER 
SYSTEM 
routines in detail. The Fortran 63 compiler has the standard Fortran READ 
and WRITE statements but it also has two other I/O statements, namely, 
BUFFER IN and BUFFER OUT. The two statements correspond quite 
closely to the machine-language instructions that select a unit and issue a 
command. For this reason we will regard these BUFFER statements as 
basic compiler language I/O statements and we will explain the higher-
level routines in terms of them. These BUFFER statements are not 
available in Fortran IV; it would, however, be a simple matter to simulate 
these statements with a MAP routine. The MAP routine uses IOEX to 
perform the actual I/O operations. MAP routines with properties similar to 
BUFFER IN and BUFFER OUT are available at many computer 
centers. 
The Fortran 63 statement 
BUFFER 
IN 
(l,N) 
(A,A(J)) 
commences the operation of reading the information on unit number I. The 
unit is read in the binary mode if N is equal to 1 ; if N is zero, it is read in 
the BCD mode. The first word goes into location A(l), the next into 
A(2), and so on. Words continue to be read until either J words have been 
read, or the end of record is reached. The BUFFER IN statement initiates 
the I/O operation; while the words are being transmitted the Fortran 
program is free to do any other operations. At any subsequent time, the 
status of the read can be checked by the statement 
IF (UNIT, I) 
1,2,3,4 
This test sends control to statement number 1 if the unit is still being 
read ; it sends control to 2 if the input has been completed successfully ; it 
sends control to 3 if there was an end of file on the unit; it sends control 
to 4 if the reading of the unit caused parity errors. In these statements, any 
simple Fortran variable could be used in place of Ι,Ν,Α, or A(J), and any 
statement number could be used in place of 1,2,3, or 4. When an end-of-file 
is indicated, it means that the next piece of information on the unit was an 
end-of-file; no information is read into the array A. When errors are 
indicated, there is information in the array A but it may contain errors. In 
this case it does not improve matters to backspace the tape and to try 
again; the system has already made several attempts. 
K=LENGTHF(I) 
is a Fortran 63 statement that sets K equal to the number of words that 
were read from the last record on unit I. 
We can see by referring to the discussion on the interrupt system 
that the BUFFER IN statement corresponds quite closely to the software 

5 ■ 10 STANDARD BINARY INPUT AND OUTPUT 
187 
implementation of input. The BUFFER IN statement causes the software 
to generate an I/O command: A single command suffices because the 
statement inputs a single array only ; it does not allow a list of variables to 
be input. The software issues the command and sets a certain word in 
the monitor to indicate that unit 1 is in operation, it then returns to the 
Fortran program. The IF UNIT test simply interrogates this status word; 
if the word indicates that the unit is in operation, then the branch to 
statement number 1 is taken. When the reading of unit I is complete, an 
interrupt occurs. The monitor checks the read; any parity errors cause the 
monitor to backspace and try again. While these retries are being attempted 
the IF UNIT branches to 1. When the read is successful, or when a suffi-
cient number of tries have been made, the monitor sets the status word to 
indicate either success, or unrecoverable errors, or end-of-file. At any 
future time an IF UNIT can test this status word and the appropriate 
jump to 2,3, or 4 will be taken. 
The corresponding output statement: 
BUFFER OUT (l,N) 
(A(1),A(J)) 
initiates a write on unit I in mode N, taking its words from location 
A(1),A(2), and so on. A(l) is the location of the first word to be written and 
A(J) the location of the last word to be written. The IF UNIT test can be 
used to detect that the unit is still in motion, or that the write is successful, 
or that the end of tape marker has been encountered, or that the record was 
written but that the writing was accompanied by parity errors. It is unusual 
for the monitor to fail to complete a successful write operation. If the first 
few attempts do not succeed, then it writes a piece of blank tape and tries 
again. 
While a BUFFER IN or BUFFER OUT operation is in progress, 
the information in A(l) through A(J) must not be changed or read by any 
program. The IF UNIT synchronizes the Fortran program and the 
Buffer program. Until the IF UNIT has taken the second, third, or fourth 
branch, the status of any word in A(l) through A(J) is indeterminate. 
5-10 
STANDARD BINARY INPUT and OUTPUT 
A typical Fortran write statement is 
WRITE 
(N) 
B,C,(A(L),L=1,J),X 
We will assume that B,C, and X are scalar variables. Fortran II uses the 
form WRITE TAPE N, followed by the list B,C, etc. This is simply a 
different way of saying the same thing. The WRITE statement is processed 
in the following manner: 

188 
5 THE COMPUTER 
SYSTEM 
There is a call to a routine that will initiate the write operation. In Fortran 
II this routine is called (STB), in Fortran IV it is called .FWDB, and in 
Fortran 63 it is called Q8QINGOT. Following this call the program picks 
up the first word to be written—in this case the word from location B— 
and it then jumps to a library subroutine. In Fortran IV the routine is 
called .FBLT, in Fortran 63 the routine is Q8QGOTTY. In Fortran II the 
program jumps off to an alternative entry point of the (STB) routine by 
way of a trapping operation. On return from this routine, the program 
picks up the next word (in this case it is the word from location C) and it 
takes another jump to the subroutine. This process is continued for all the 
words that are to be transmitted. When all the words have been trans-
mitted, there is a call to a routine that finishes off the write operation. In 
Fortran II, the finishing routine is called (FIL); in Fortran IV, it is .FWLR; 
and in Fortran 63, it is Q8QENGOT. 
We will discuss the write operation in some detail by giving a 
Fortran program that simulates the operation of (STB). Corresponding to 
the call that initiates the write operation we will 
CALL 
WRITEB(1,N) 
where N is the number of the tape which is to be written on. Corresponding 
to the series of calls that transmit B,C,... we will use 
CALL 
WRITEB(2,B) 
CALL 
WRITEB(2,C) 
DO 
100 
L=1fJ 
100 
CALL 
WRITEB(2,A(L)) 
CALL 
WRITEB(2,X) 
and corresponding to the call to (FIL) we will use 
CALL WRITEB(3,0) 
The coding for WRITEB is shown in Figure 5.3. It uses the basic output 
statement BUFFER OUT in order to write the tape. 
The easiest way to understand a subroutine is to take the CALL 
WRITEB statements given above and to follow through the action of the 
machine. The first time the routine is called it sets I equal to 2, NREC 
equal to zero, and the number of the tape is saved in NTAP. On the 
second entry, when Nl is equal to 2, the word in N2 is stored in the buffer 
at NB(2). Subsequent calls to the routine cause words to be stored in 
NB(3),NB(4), and so on. When 255 words have been transferred into the 
buffer, control goes to statement 202 and then to 212 where the BUFFER 
OUT for the words in NB(1) through NB(256) are given. On this first 
occasion NTAPL is negative and the statement at 211 is bypassed. On 
future occasions this statement checks that previous write operations have 
been completed. While the first 256 words are being written, the rest of the 
words to be output are being transferred into NB(258), NB(259), and so on. 

5 · 10 STANDARD BINARY INPUT AND OUTPUT 
189 
SUBROUTINE WRITES (N1.N2) 
DIMENSION NB(512) 
DATA (NTAP =-1 ) 
GO TO <100»200»300) »Nl 
C 
INITIALISE 
100 
I«2 
S NTAPL»NTAP $ NTAP=N2 
N R E O O S RETURN 
200 
IFd-257) 201»202»203 
C 
PLACE A WORD IN THE BUFFER 
201 
NB(I) « N2 $ 1=1+1 $ RETURN 
202 
NB(1)«0 S <1«1 $ K2«256 
205 
IF(NTAPL) 212»211»211 
C 
CHECK ANY PREVIOUS TAPE OPERATION 
211 
IF(UNITtNTAPL) 211»212»213»214 
213 
PRINT 215»NTAPL $ STOP 
215 
FORMAT«12H EOT ON TAPE 16» 10H IN WRITEB ) 
214 
PRINT 216»NTAPL 
$ STOP 
216 
FORMAT( 21H PARITY ERROR ON TAPE 16» 10H IN WRITEB ) 
212 
NTAPL»NTAP 
$ NREC-NREC+1 
BUFFER OUT (NTAP.l) <NB(Kl)»NB<K2)) 
I» 515-1 
$ GO TO 201 
203 
IF( 1-512) 201»201.204 
204 
Kl»257 S K2=512 $ NB(257)=0 $ GO TO 205 
C 
BUFFER OUT FINAL PHYSICAL RECORD 
300 
Kl«257 S IF(1-257) 301»301»302 
301 
Kl«l 
302 
NB(K1)«NREC+1 
S K2«I-1 $ GO TO 205 
END 
FIG. 5.3 The subroutine WRITEB 
When the next 255 words have been transferred into the buffer, the 
BUFFER OUT of the first 256 words is checked, and then the next 
BUFFER OUT is given. The end of the list is denoted by a call with Nl 
equal to 3. The sequence starting at statement 300 causes previous write 
operations to be checked, and the output of the final physical record is 
initiated. The IF UNIT on this final record is given the next time that the 
routine is entered. 
A binary READ statement is processed in a somewhat similar 
way. The first physical record is buffered in, and the IF UNIT test is made. 
If the first word of the record is ^ero, then there are more records to 
follow; in this case a BUFFER IN for the next physical record is given. 
While the second record is being brought into memory, the contents of 
the first record are distributed to the locations specified in the READ list. 

190 
5 THE COMPUTER 
SYSTEM 
WRITEB is one of many possible buffering schemes. Fortran II 
and Fortran 63 monitors use this scheme. Fortran IV uses the method 
described in WRITEB for processing the READ and WRITE lists and for 
transmitting information to the buffers. However, it does make use of 
more than two buffer areas. Many Fortran programs do not use the whole 
of the memory. Fortran IV takes any unused portions of the memory and 
uses them as buffer areas. It uses two or more buffers. The exact number of 
buffers depends on the amount of memory available and on the size of the 
physical records. 
The Fortran I/O routines are unsatisfactory. The major objection 
to them is that they are inefficient. The main cause of the inefficiency is the 
transfer of the words into and out of the buffer areas. CALL WRITEB(2,X) 
takes 20 or 30 machine instructions to transfer each word into the buffer; 
this is comparable to the time it takes to write one word onto magnetic 
tape. The sequences corresponding to this in Fortran II, Fortran 63, and 
Fortran IV are equally inefficient. No provision is made for transferring a 
whole array at one time. For records of more than 255 words the Fortran 
II and Fortran 63 schemes have an additional source of inefficiency. They 
spend an appreciable time waiting for the buffers to be emptied. 
The BUFFER OUT statement is not as flexible as the WRITE 
statement, since it cannot process a list. In practice it is usually a simple 
matter to avoid this difficulty. For example, 
WRITE TAPE (N) B,C,(A(L)#L=1,J),X 
can be accomplished by 
COMMON B,C,A(900) 
A(J + 1)=X 
BUFFER OUT (N,1) (B,A(J + 1)) 
The significance of the Common statement is that it forces B,C, and A(l) 
to be in consecutive locations. Another objection to BUFFER OUT is 
that the variables B,C, and so on must be preserved until the IF UNIT 
test has been made. The answer to this objection is that if an efficient 
program is required, then the programmer has to be prepared to take some 
extra care. In many applications it is possible to design a scheme that is 
both efficient and easy to code. The fundamental objection to the compli-
cated buffering scheme provided in Fortran IV is that it is never 100 per-
cent efficient and it is often very inefficient. 
5-11 
BLOCKED TAPES 
We have seen that the Fortran WRITE statement splits each logical record 
into a series of physical records. Each physical record contains less than 
257 words. The advantage of this system is that buffers of length 256 can be 

5 ■ 12 A ROUTINE FOR READING BLOCKED TAPES 
191 
used. If the buffering system had to deal with records of arbitrary length, 
then it would have difficulty in allocating buffer space. In some applications 
it is convenient to place several logical records in one physical record : The 
information on the tape is said to be in blocked records. The following 
example will illustrate this point. The Relay satellite is in orbit around the 
earth. It contains certain experiments that count the number of protons 
and electrons of various energies which enter the various detectors. The 
readings from the counters are read out every second. The data is encoded 
in digital form. The data for 1 second can be expressed in 72 characters. The 
natural unit of data is a logical record of 72 characters. A physical record 
of 72 characters occupies γγ^ inch or 0.13 inch : the inter-record gap is about 
0.75 inch. If a logical record corresponded to a physical record, then 85 
percent of the tape would be wasted. Suppose we pack ten logical records 
in each physical record. Each record now occupies 1.3 inches, the inter-
record gap takes 0.75 inch, and so about 60 percent of the tape now 
contains useful information. (To put these facts in another way: A tape is 
approximately 2400 feet long. If there is one logical record per physical 
record, then the tape can contain 2400 x 12/0.88 or 32,700 logical records. 
If the tape is blocked with ten logical records per physical record, then it 
can hold 14,000 physical records or 140,000 logical records.) By increasing 
the number of logical records per physical record it is obviously possible 
to get more information on the tape. There is one drawback to making 
very long records. If part of the record is damaged, due to wear on the 
tape, then the whole of the physical record may become unreadable. The 
second reason for using blocked records is that it saves time in reading, 
writing, and in rewinding the tapes. The time to read or write one record is 
S + nt, where S is an initial start time, n is the number of words in the 
record, and / is the time to write one word. On an IBM 729 IV tape 
unit, S is 7.3 milliseconds and / is 96 microseconds. Reading ten records of 
72 characters each takes 112 milliseconds, reading one record of 720 
characters takes 22 milliseconds. A third reason for using the blocked 
records is to match some physical characteristic of the I/O device; for 
example, the use of a disk or drum is most efficient when the physical 
record fits exactly into one track. 
If the records are packed, then it can become more difficult to 
process the records. However, all of the complexities can be removed by 
writing a subroutine to handle the input and output. The writing of the 
subroutine to handle the input and output may be difficult, but if it is well 
designed, the care taken in writing the routine will more than pay for itself. 
5-12 
A ROUTINE for READING BLOCKED TAPES 
The routine we are about to describe will illustrate the features of a 
general purpose buffering routine. The way in which the routine anticipates 
the reading requirements is typical of the more complicated routines such 

192 
5 THE COMPUTER 
SYSTEM 
as occur in Fortran IV and IOCS. The principles used in writing these 
routines are straightforward, but the actual details of the routine are quite 
complicated. The subroutine was designed for a specific purpose and is 
quite efficient for that purpose ; a general-purpose routine would need to 
be even more elaborate than the routine that is described here. Details of 
these elaborations will be given in the next section. 
The routine has several entry points. The first entry point is 
CALL OPEN(UNT) 
where NT specifies the number of the record unit and L is a vector that 
gives some information about the record. L(l) is the number of words in a 
logical record. L(2) is the number of logical records in each physical 
record. There must be one or more logical records per physical record; the 
routine will not handle a logical record that is longer than a physical 
record. L(3) gives the mode. 0 is for BCD and 1 is for binary. L(4) specifies 
the name of the unit in A8 format. This name is not used during the reading 
and writing process, but it is printed out with the tape statistics. 
Once the unit has been declared in the OPEN statement it can be 
read by 
A=READ(X,NT) 
On return from READ, if A is negative, then an end of file has been 
encountered and there is no information in X. If A is positive, then the 
next logical record on the unit has been read into the array X(l) through 
X(L). The routine remembers the length of the logical record associated 
with each unit and transfers the correct number of words. The routine 
automatically does any necessary unblocking; the user need not realize 
that the information is in fact blocked. The READ routine presents the 
user with one logical record at a time. The information can be written by 
means of 
A=WRITE(X,NT) 
On return from WRITE, if A is negative, then the end of the tape has been 
reached. If A is positive, then the words in X(L) have been " written " onto 
the tape. The words are actually transferred into a buffer and when a full 
physical record has been accumulated, it is buffered out. 
When all reading or writing has been finished, the statement 
CALL 
CLOSE(0,NT) 
should be given. This finishes off any operations still in progress on unit 
NT. If the unit has been written on, then CLOSE also writes an end of 

5 . 12 A ROUTINE FOR READING BLOCKED TAPES 
193 
file. If a unit has been read, then it cannot be written on unless a CLOSE 
followed by an OPEN is given for the tape. The entry 
CALL 
EOF(0,NT) 
can be used to write an end of file on the unit. It should be realized that the 
ordinary Fortran statement 
ENDFILE NT 
would not do, because there may still be information sitting in the buffer 
area inside the routine. The entry 
CALL REWIND(0,NT) 
can be used to rewind the unit. Any unit that has been written on should 
have an end of file written on it before the rewind. 
The routine works in the following way. It can handle up to six 
units at any one time. Each unit is associated with two buffer areas. As 
currently assembled, the routine restricts each physical record to have less 
than 301 words. When the OPEN statement is given, the routine searches 
for the first available buffer space and allocates it to that unit. It also 
initializes various flags and counters as shown in Figure 5.4. 
Let us see what happens when a WRITE(X,NT) is given. The 
routine begins at ENTRY WRITE, goes through the list of units, and 
finds the value of I, that is, the number of the buffer which was allocated to 
NT. It checks that NRW is not +1, otherwise the unit has been read. 
This routine does not allow both reading and writing on the same unit. It 
is, of course, permissible to do the following. OPEN a unit. Give one or 
more WRITE operations on that unit. CLOSE the unit. OPEN the same 
unit. Give one or more READ operations on that unit. Many other 
routines which do buffered input and output also insist that the user must 
CLOSE a READ unit before giving (an OPEN followed by) a WRITE on 
that unit. It next checks if NLOGL is less than or equal to NBUB. If the 
answer is yes, then this physical record is not yet full, and so it transfers 
the contents of X(l) through X(NLR) into the appropriate place in the 
buffer. If the answer is no, then it checks any previous BUFFER OUT 
statements given on this unit, and then it gives the BUFFER OUT for this 
physical record. It then transfers the array X into the alternative buffer. If 
a call to EOF or CLOSE is given, the routine must first write out the 
contents of any buffers associated with that tape ; then it writes the end 
of file. 
A READ operation is somewhat similar. On the first entry the 
routine buffers in one record and then waits until the read has been 
completed. It then issues the BUFFER IN for the second record. On 

194 
5 THE COMPUTER SYSTEM 
FUNCTION 
0PEN(L»IUNIT) 
C 
NFIL IS THE NUMBER OF THE CURRENT FILE 
C 
NREC IS THE NUMBER OF THE CURRENT PHYSICAL RECORD 
C 
NLEC IS THE NUMBER OF THE CURRENT LOGICAL RECORD 
C 
NPR IS THE NUMBER OF WORDS IN A PHYSICAL RECORD 
C 
NLR IS THE NUMBER OF WORDS IN A LOGICAL RECORD 
C 
NBUB IS THE NUMBER OF LOGICAL RECORDS PER PHYSICAL RECORD 
C 
IF NRW IS 0 THEN NO READ OR WRITE HAS YET OCCURRED 
C 
IF NRW IS 1 THEN READ HAS OCCURRED» -1 DENOTES WRITE 
C 
NSTOR IS THE NUMBER OF THE CURRENT LOGICAL RECORD WITHIN 
C 
THE PHYSICAL RECORD 
C 
NTAP SELECTS ONE OF TWO BUFFER AREAS 
DIMENSION 
NUNIT(6)»NLBL(6)»NPR(6)»NLR(6)»NBUB(6)»MODE<6)»NLEC(6)» 
1NTAP(6)»NST0R(6)»NLOGL(6)»NRW(6)»NF IL(6)»NREC(6 ) ♦ NPOS(6).NuRD(6) 
DIMENSION L( 4),NBA(3600) 
DATA 
(NUNIT=0»0.0,0»0.0)»<NTAPES=6)♦(NBSIZE=300)»(NTOT=1800) 
C***» CALL OPEN 
BEGINS HERE 
C 
INDICATE AN ERROR IF UNIT IS ALREADY DECLARED 
10 
DO 18 I=1»NTAPES $NER = 6 $ I F(IUNIT.EQ.NUNIT(I)) 999»l8 
18 
CONTINUE 
C 
SEARCH FOR AN EMPTY BUFFER 
DO 11 I=1»NTAPES $ IF<NUNIT(I>.EQ.O) 12»11 
11 
CONTINUE $ NER = 1 
C 
ALL BUFFERS ARE FULL 
INDICATE AN ERROR 
999 
PRINT 998»IUNIT»NER $ 1=1 $ JUMPA=6 
$GO TO 150 
998 
FORMAT(34H ERROR IN READ-WRITE ROUTINE. TAPE I6»6H ERROR 16) 
997 
STOP 
C 
USE BUFFER NUMBER I. INITIALISE IT 
12 
NUNIT( I ) = IUNIT $ NLBL ( I ) =L ( 4 ) SNBUB<I)=L<2 ) $NRW(I)=0 
NLR(I)=L(1) 
$ MODE(I)=L(3)$ NER=2 
NPR(I )=NBUB(I)*NLR<I) 
IF( 
NBUB(I).LE.0.OR.NPR(IJ.GT.NBSIZE) 999,15 
15 
NFIL(I)=1 
16 
OPEN =1.0 
17 
NLOGHI)=NSTOR(I)=1 
SNPOSiI)=(1-1)*NBSIZE 
NLEC( I )=NTAP( I )=NREC( I)= 
NURDU)=0 $ RETURN 
C 
C*»** CALL REW 
BEGINS HERE 
ENTRY REW 
$ JUMP=1 
C 
FIND WHICH BUFFER IS BEING USED BY IUNIT 
26 
DO 20 I = 1»NTAPES S I F(NUNIT(I).EQ.IUNIT) 21»20 
C 
IF IUNIT HAS NOT BEEN DECLARED THEN INDICATE ERROR 
20 
CONTINUE $ NER=3 $ GO TO 999 
21 
GO TO (22»30.130.140*200) »JUMP 
22 
REWIND IUNIT SPRINT 27.IUNIT $ GO TO 15 
27 
FORMATÎ7H REWINDI6) 
C 
C*### CALL READ 
BEGINS HERE 
ENTRY 
READ $ NRWT=1 $ JUMP=2 $ GO TO 26 
C*»»* CALL WRITE 
BEGINS HERE 
ENTRY 
WRITES NRWT=-1S JuMP=2 S GO TO 26 
C 
A READ AND WRITE CAN NOT BOTH BE USED ON ONE UNIT 
30 
NER=8 S IF(NRW(I).NE.O.AND.NRWT.NE.NRW(I)) 999.390 
C 
GO TO 40 IF CURRENT PHYSICAL RECORD IS EXHAUSTED 
390 
NRW(I)=NRWT 
$ I F(NLOGL( I).LE.NBUB(I)) 31.40 
31 
IF (NTAP(I).EQ.O .AND.NRW(I).EQ.1) 40.32 
C 
GET INFORMATION FROM CURRENT RECORD 
32 
Kl=l+ 
(NLOGLiI)-l)*NLR(I)+NPOS(I) $ K2=K1+NLR(I)-1 
J=l SNLECtI)=NLEC(I)+1 $ IF (NSTOR(D) 39,39.33 
39 
K1=K1+NT0T $ K2=K2+NTOT 
33 
IF (NRW(I)) 34,34.35 
C 
TRANSFER WORD OUT OF BUFFER 
35 
DO 36 K=K1.K2 S L(J)=NBA(K) 
36 
J=J+1 
S GO TO 37 
C 
TRANSFER WORD INTO BUFFER 
34 
DO 38 K=K1,K2 $ NBA(K)=L(J) 
38 
J=J+1 
37 
OPEN=l.$NLOGL(I)=NLOGL(I)+l 
996 
RETURN 
C 
READ OR WRITE ONE PHYSICAL RECORD 
40 
J1=NUNIT(I) $ J2 = l+NPOS<I) 
$ IF(NTAPd)) 50.51,51 
50 
J2=J2+NTOT 
51 
J3 = J2+NPR( I )-l 
S IF(NRWU)) 90.42.42 
FIG. 5.4 A routine for buffered input and output 

5 · 12 A ROUTINE FOR READING BLOCKED TAPES 
195 
C 
CHECK PREVIOUS READ 
42 
IF (ΝΤΑΡί Ι)·ΕΟ·0) 43»44 
43 
NTAP(I)=1 
46 
MUD=MODE(I)$BUFFER IN (Ji»MUD 
) (NBA(J2)»NBA(J3)) 
44 
IF (UNIT,J1) 44,60,45.72 
71 
OPEN=-l. S NFIL(I)=NFIL(I)+l SGO TO 17 
72 
NURD<I)=NURD(I)+l S GO TO 46 
60 
KP=LENGTHF(J1) $ KL=NLR(I) 
NER=4 $ IF (KP-(KP/KD*KL 
) 620.66 
620 
PRINT 621.NUNIT(I)»NREC(I),KP.KL, 
NER 
621 
FORMAT(18H LENGTH ERROR UNIT6I6) 
GO TO 72 
C 
THIS RECORD HAS NOW BEEN READ 
C 
START READING NEXT RECORD 
66 
NREC(I)=NREC(I)+l 
S NBUB<I)=KP/KL 
65 
NSTOR(I)=NTAP(I) $ NTAP(I)=-NTAP(I) 
NLOGL(I) = l $ J2 = l + NPOS< I ) S IF(NTAPU)) 80.80.81 
80 
J2=NTOT+J2 
81 
J3=J2+NPR(I)-l $MUD=MODE(I) 
BUFFER INUl.MUD 
) ( NBA ( J2 ) »NBA ( J3 ) ) SGO TO 32 
C 
CHECK PREVIOUS WRITE 
90 
IF (NTAP(I>.EQ.0)103.92 
92 
IF(UNIT.JI) 92»102»94»95 
94 
PRINT 96 $ JUMPA=1 $ GO TO 79 
96 
FORMAT«12H END OF TAPE) 
97 
N F I H I )=NFIL( I )+l S GO TO 16 
95 
NURDtI)=NURD(I)+l 
102 
NREC(I)=NREC(I)+l 
C 
PREPARE NEXT WRITE 
103 
IF (JUMP.EQ.4) 132.109 
109 
NTAP( I )=NSTOR( I) $ NSTOR(I)=-NSTOR( I) 
J2=l+NPOS(I> ί IF (NTAP(I)) 105.104,104 
10b 
J2=NTOT+J2 
104 
J3 = J2-KNLOGL( I )-l)*NLR( I)-l 
107 
MUD=MODE(I) 
SNLOGL(I)=l 
BUFFER OUT (Jl.MUD 
) (NBA(J2)»NBA(J3)) 
GO TO (32.32. 
131.132).JUMP 
45 
PRINT 47 $ JUMPA=1 
47 
FORMATÎ12H END OF FILE) 
79 
PRINT 70.NL3L( I)»NUNITi I).NFIL( I).NREC( I).NLEC( I).NURD( I ) 
70 
FORMAT<6H LABELA8.5H UNITI6.5H FILEI6.7H RECORDI6.3H LR 
1 16.10X14.6HERRORS) 
16HERRORS) 
GO TO (71.71»97»133»144»151)»JUMPA 
(;♦#«♦ CALL EOF 
BEGINS HERE 
ENTRY 
EOF $ NONE=0 $ JUMP=3 S GO TO 26 
130 
IF (NLEC(I)) 40.132»40 
131 
JUMP=4 $ GO TO 92 
132 
ENDFILE IUNIT S JUMPA=4 $ PRINT 135 $ GO TO 79 
135 
FORMAT(20H END OF FILE WRITTEN) 
133 
NFIL(I>=NFIL<I>+l $ IF (NONE) 146»16 
C#*** CALL CLOSE 
BEGINS HERE 
ENTRY 
CLOSE $ JUMP=4 $ GO TO 26 
C 
ARE THERE ANY LOGICAL RECORDS IN BUFFER 
140 
IF (NLEC(I)) 141,144.141 
141 
IF (NRW(I)) 143,143.149 
C 
BUFFER OUT ANY RECORDS CURRENTLY IN BUFFER 
143 
NONE=l $ JUMP=3 $ GO TO 40 
149 
IF (UNIT.NUNIT(I>) 149,1490.1490.1490 
1490 BACKSPACE NUNIT(I) 
145 
JUMPA=5 $ PRINT 148 $ GO TO 79 
146 
PRINT 148 
C 
RELEASE BUFFER NUMBER I 
144 
NUNIT(I)=0 $ GO TO 16 
148 
FORMAT(13H RELEASE UNIT) 
150 
IF(NUNIT(I)) 79.151 
151 
1=1+1 $ IF(I.LE.NTAPES) 150,152 
152 
IF(NER) 997,996 
C*»** CALL REC 
BEGINS HERE 
ENTRY 
REC $ JUMP=5 $ GO TO 26 
C 
PRINT TAPE STATISTICS 
200 
L(1)=NFIL(I) $ L(2>=NREC(I) $ L(3)=NLEC(I) $ RETURN 
END 
FIG. 5.4 {concluded) A routine for buffered input and output 

196 
5 THE COMPUTER 
SYSTEM 
subsequent entries it checks to see if all the logical records in the current 
physical record have been used. If they have not, then it transfers the 
information from the buffer. If the logical records have been used, it 
checks the previous BUFFER IN and initiates another BUFFER IN. 
To give an example, the statements, 
L(1) = 18 
$ 
L(2) = 10 
L(3) = 1 
$ 
L(4)=4H X52 
CALL OPEN(L,6) 
$ 
CALL REWIND(0,6) 
DO 100 
1-1,42 
100 
CALL WRITE( X(1,l), 6) 
CALL CLOSE( 0,6) 
rewind unit 6 and write 42 logical records. The first four physical records 
contain 180 words each. The fifth record contains 36 words and is followed 
by an end of file. The particular thing to note about the routine is that it is 
easy to use. The routine handles all the complications of blocking and 
buffering. As far as the user is concerned, it is no more difficult to use than 
the ordinary WRITE or READ statement. 
What are the advantages of OPEN compared to the previous 
routine WRITEB? First, OPEN handles blocked records. Second, OPEN 
transfers information into and out of the buffers by an efficient process. 
Since it transfers a whole array at one time, it takes approximately four 
machine instructions to transfer one word, compared with the 20 or 30 
in WRITEB. Third, OPEN anticipates the request for a record to be 
read. After the first record, READ is always one record ahead of the 
request. The read routine that corresponds to WRITEB cannot read one 
record in advance because it only has two bufTer areas and it does not 
know what tape will be read next. OPEN has two buffers for each tape and 
it can always anticipate. Fourth, OPEN can keep several units moving at 
one time. As soon as WRITEB receives another call, it must wait until the 
previous write operation has been completed. If WRITE receives another 
call, it need only wait if the request is on the same tape unit. 
5-13 
lOEXand IOCS 
The input-output in Fortran IV under IBSYS is carried out by a series of 
routines. In this section we will compare and contrast these routines with 
the routine OPEN described in the previous section. The first part of the 
Fortran IV I/O system is IOEX and its associated routines. IOEX is 
concerned with the basic reading and writing operation; it corresponds 
approximately to the BUFFER IN and BUFFER OUT statements of 
OPEN. IOEX is more powerful than the BUFFER statements because 
IOEX is entered whenever the user requests a read or write and whenever 
an interrupt occurs, whereas the BUFFER statements are only activated 
when the READ and WRITE entries of the routine are called. 

5 · 13 ΙΟΕΧ AND IOCS 
197 
IOCS corresponds approximately to the parts of the route OPEN 
other than the actual BUFFER statements. IOCS handles all buffering 
arrangements and calls on IOEX to do the actual I/O. IOCS is more 
powerful than OPEN and is considerably more complex, IOCS has the 
following features that were not in OPEN. It handles a backspace operation. 
It has variable-length buffers. It has a variable number of buffers. It can 
handle labeled tapes and multireel files. Let us consider these points one 
by one. 
The backspace operation is quite complex. The programmer gives 
a BACKSPACE statement and expects to backspace one logical record. 
Not only are the physical records different from logical records, but the 
tape is not in the position that the programmer thinks it is. IOCS has to 
issue a CLOSE which empties the buffers and positions the tape correctly. 
Then it does the logical backspace of one record. The programmer should 
realize that BACKSPACE is a complex and time-consuming operation. 
The buffers in OPEN are 300 words long and each tape has two 
buffers. IOCS adjusts the buffer size to suit the length of the record. IOCS 
chooses the number of buffers according to the activity on the tape ; if tape 
A is reading many records and tape B is not reading or writing many 
records then two buffer areas suffice for tape B, but tape A is buffered more 
efficiently if it has many more buffer areas. If the data to be written onto 
tape A is produced in a steady stream, then IOCS is no more efficient than 
the routine OPEN. If the data is produced in short bursts of ten records at 
a time, then IOCS is considerably more efficient providing it has allocated 
at least ten buffer areas to tape A. 
A labeled tape contains one record at the beginning of the tape 
that identifies the tape. Labels are usually in BCD and they contain the 
following type of information. The label contains the reel number; the 
reel number is the identification by which the operator distinguishes this 
tape from other tapes. The label contains the usage of the tape, that is, 
whether it is a utility tape or a special tape. In the latter case the label 
should give the name of the programmer who last used the tape, the date 
on which the tape was written and a date after which the information on 
the tape may be erased. The label might also contain the mode, density, and 
blocking factor. The label can protect the tape against operator or pro-
grammer errors. The word "file" has two distinct meanings, and, unfor-
tunately, the two uses of the word can easily be confused. File can mean the 
information between two ends of file marks (or between the beginning of 
tape marker and an end-of-file mark). File usually means a single body or 
stream of information. For example, current account file means all the 
information relating to current accounts. A file might be too extensive to 
fit on one tape, in which case it would be a multireel file. The file, when the 
word is used in the sense of a single stream of information, need not be 
on tape, of course. It can be on any unit—a tape, a magnetic disk, punched 
cards, a printer, and so on. The system may find it convenient to change a 

198 
5 THE COMPUTER 
SYSTEM 
file from one unit to another. For example, the PRINT statement implies 
that a file of printed output will eventually appear on a printer but the 
file may go on a tape or disk before it gets to the printer. 
The IOEX part of the Fortran IV I/O routines is well designed. 
IOCS and the library routines that communicate between the Fortran 
statement and IOCS are not well designed. The library routines are very 
inefficient in the way in which they transfer variables into a buffer. Many of 
the features of IOCS are good in themselves and are used in any compre-
hensive system, but there are many problems for which IOCS is quite 
inappropriate. This failure on certain problems would not be serious if an 
alternative scheme was provided, but the IOCS buffering systems are such 
an integral part of the system that it is difficult to bypass them. The classical 
case of the failure of the buffering systems is the large two- or three-
dimensional mesh problem. In one problem of this type it is necessary to 
solve a set of simultaneous equations of the form 
A(lfJ)*F(l + 1fJ) + B(l#J)*F(lfJ + 1) + C(U)*F(l-1,J) + 
D(l,J)*F(l#J-1) + E(lfJ)*F(U) =S(I,J) 
where A,B,C,D,E and S are known and F is unknown. Once the F's have 
been found, they are written onto tape and a new set of coefficients is 
brought down from tape to start the next stage of the problem. In a com-
puter with 32,768 words of core memory, the programmer usually expects 
to use about 4000 mesh points. This means that the arrays A,B,C,D,E,S, 
and F are each of dimension 4000. In this situation there is no room for 
buffers; there are strong reasons against splitting the arrays into a small 
number of physical records and any movement of arrays from one area of 
the memory to another is liable to be uneconomical. Given a simple but 
comprehensive control over input-output, such as is provided by BUFFER 
IN and OUT, the programmer can devise a method of minimizing the time 
lost in tape transfers. Given a comprehensive buffering system such as 
the Fortran IV system, the programmer will find it difficult to bypass the 
system. 
5-14 
LOGICAL and PHYSICAL UNITS 
In 704 Fortran the print statement causes the results to be printed on the 
on-line printer and the WRITE TAPE N sent output to tape unit number 
N. In subsequent systems it has been found advantageous to distinguish 
between the name of the information and the name of the I/O device on 
which it is stored. A stream of information is identified by giving it a file 
name; for example the name NXSEC might be given to the file of informa-
tion that contains data on nuclear cross sections. There are four types of 
files: (1) the standard system files; (2) the special input and output files; 
(3) the utility or scratch files ; and (4) files of information that is saved by 

5 · 14 LOGICAL AND PHYSICAL UNITS 
199 
the system. The information on the standard print tape is an example of a 
system file. The library tape is another example of a system file. Any 
information that the programmer feeds into the system, other than the 
information he feeds in through a system file, and any information that he 
extracts from the machine, other than the information he gets out in a 
standard system file, constitute a special file. The file NXSEC might be fed 
into the system by putting it on magnetic tape and asking the operator to 
load the tape. In that case it would constitute a special file. If the table of 
cross sections was not large, then it might be preferable to include them in 
the program deck and in this case they would be part of the standard input 
system file. Utility or scratch information is created during the execution of 
the job, and it is not saved when the job is finished. If the system has a large 
disk, it is possible to save information on the disk from day to day; this 
type of file comes under the fourth category. All of these types of file have 
to be stored on some physical device. The programmer accesses the 
information by specifying the name of the file; the system has to have some 
means of connecting the name of the file with the name of the device on 
which the information is stored. 
The Scope system on the CDC 3600 has a simple but powerful 
method of connecting file names with the corresponding I/O device. All 
files are identified by a number; thus the Fortran statement 
READ (21) 
A,B,C 
tells the system to read three numbers from file number 21. The Scope 
manual uses the term "logical unit number" where we have used "file 
number." File numbers 1 through 49 may be used for any purpose. File 
numbers 50 through 59 are always scratch units. File numbers 60 through 
80 are used for standard system units. The more important of these units 
are given below. 
Logical unit 
System function 
60 
standard input unit 
61 
standard output unit 
62 
standard punch unit 
63 
standard unit for comments from operator 
64 
standard unit for comments to operator 
Units 60, 61, and 62 may be tape units or they may be on a drum. Units 63 
and 64 are a typewriter which is on the operator's console. The PRINT or 
the WRITE (61) statements have the same effect; they send output to the 
system output unit. Similarly, with READ and READ (60) and with 
PUNCH and WRITE (62). The correspondence between system units and 
actual hardware is decided by the systems programmers and/or the 

200 
5 THE COMPUTER 
SYSTEM 
operators. The software contains a table that lists all the system units and 
the corresponding physical units. The operators can change this table if, for 
example, some of the hardware is malfunctioning. The actual correspon-
dence does not concern the ordinary user. All that matters to him is that 
PRINT causes some printed results to appear. Whether the printing is done 
immediately or whether it first goes on a tape or disk does not affect the 
user. 
If the program uses only system units and scratch units, then no 
special declaration is necessary. If the program has special input or output, 
then an EQUIP card must be placed at the front of the job. This card 
enables the system to assign a physical unit to the file of information. As an 
example 
EQUIP,17 = (NXSEC),LO,RO,SV 
specifies that file number 17 is a low-density magnetic tape with the label 
NXSEC. The tape is RO (read only), and this tells the system to make 
sure that no programmer error can allow the tape to be written on. SV 
stands for save, and it tells the system to unload the tape at the end of the 
job. This system assumes that tapes contain a label. The first record of the 
tape is in a standard format and it contains the name NXSEC. The 
operator loads the tape on any tape unit. He can do this at any time before 
the job starts. As soon as the job starts the system looks at all the tape 
units. It makes a note of those units that have a tape mounted, and it notes 
the names in the label. Suppose tape unit 5 happens to have the tape whose 
name is NXSEC. As soon as the monitor reads the EQUIP card it makes 
the correspondence between tape unit number 5 and file number 17. At any 
place in the program where 
READ (17) . . . 
occurs, the software causes the tape on unit number 5 to be read. 
WRITE (17) . . . 
causes the job to be abandoned because the EQUIP card specified that the 
tape was not to be written on. If any scratch tapes are needed by the job, 
the system goes around the tape units and uses any unlabeled tapes as 
scratch tapes. It is sometimes necessary to use a special tape that contains 
no label. The card 
EQUIP, 12=**,HI,SV 
specifies that file number 12 is on an unlabeled high-density tape. The 
system prints out 
12= 

5 · 14 LOGICAL AND PHYSICAL UNITS 
201 
on the operator's typewriter and the operator types in the number of the 
tape unit on which he has put the tape. This method is less efficient and 
less reliable than the use of labeled tapes. The EQUIP card can be used to 
rename files. The following situation is frequently encountered. A program 
has been written for use under IBSYS on the IBM 7090 and it uses the 
statement WRITE (6) to put output on the standard system system tape. It 
is required to run this program on the 3600 under Scope. One solution is to 
go through the program and change all the references to file 6 into references 
to file 61, which is the standard Scope output unit. An alternative solution 
is simply 
EQUIP,6 = 61 
which tells the system to make file 6 the same as file 61. 
In the IBSYS system on the IBM 7090 all files have a symbolic 
name. The correspondence between files and units is specified on a FILE 
card, for example 
UNIT06 FILE ,OU,READY,OUTPUT,BLK=22,MULTIREEL/BCD,NOLIST 
specifies that the information from the file whose name is UNIT06 is to 
go on OU which is the standard system output. A FILE card has to be 
given for every tape that the program uses ; the average user can be spared 
some of the complexities of the FILE card by the practice of putting the 
FILE card in the system library. The use of non-numeric file names 
conflicts with the standard Fortran practice of using numeric unit numbers. 
The compiler resolves this conflict by compiling WRITE (6) as a call to 
write on file UNIT06. The FILE card is more complicated than the Scope 
EQUIP card because the ISBYS system has a complex buffering system 
that requires information on the way the tape is to be used. BLK = 22 
specifies that the maximum record size is 22 words and BCD specifies that 
all the write operations are in BCD. In the case of a special tape, the 
system decides which unit the tape should be mounted on and it tells this 
information to the operator. This method is not a good one since the 
operator cannot mount the tape until the job starts. The method by which 
the operator mounts the tape and then tells the machine where to find it 
cannot be used for two reasons. The first is connected with the inability of 
the 7090 to allocate any unit to any channel. The second is that the operator 
cannot communicate with the system because the 7090 does not have a 
console typewriter. 
To summarize what has been said. The system has a table that 
shows the correspondence between the system files and the physical unit 
numbers. The table is fixed by the systems programmers but it can be 
changed by the operators. The table must contain entries for the necessary 
units such as standard input, output, and punch, but it may also make some 

202 
5 THE COMPUTER 
SYSTEM 
specification of units to be used for scratch files. The programmer does not 
need to know which units are being used and he does not need to know if 
the PRINT unit really is a printer 01 if it is a tape, disk, or drum. When 
special files are used, there must be some way of connecting the file with the 
appropriate unit. There are three methods in common use: (a) the first 
record on the file can contain the file name, (b) the operator can put the 
file on a unit and then he can tell the system which unit he has used, and 
(c) the system can decide which unit to use and it can tell the operator 
where to put the file. The first method is usually the most efficient. In a 
large system the file can be fed into the system on tape or cards long before 
the job is to be run. The system makes a note of the name and storage 
medium of the file. The second method is often used because programmers 
refuse to use labels or to agree on a standard label. This is one of the many 
areas of systems usage in which a bad standard would be preferable to no 
standard at all. It is difficult to introduce standard labeling practice when 
tapes are brought in from other computing centers. The third method is 
quite acceptable in a multiprocessing mode where the system can give the 
operator time to load the tape, but it is often used in situations in which it 
leads to a great waste of time. 
Once a file has been read into a system, it is the job of the system 
to keep track of the file and to take any protective measures which are 
necessary. The system should ensure that information is never destroyed 
unless the programmer gives explicit instructions. The system may choose 
to send the file from one device to another and this is acceptable providing 
the programmer's request to read a file results in the file being read. In 
some large systems it is possible to save information from day to day. The 
programmer gives a file name to any information that he reads in or 
generates and wishes to save. The system keeps a list of all the names of 
files and the place where they are stored. Daley and Newman (1965) 
describe a very large system of this sort. In this system if the information is 
not used for several days, it is off-loaded onto a magnetic tape. When the 
programmer next asks for the file, the system retrieves the file from the 
disk, drum, or tape on which it is stored. The programmer does not need 
to know where or how the information is stored. 
5-15 
ATAPE DUMP PROGRAM 
One of the uses of the BUFFER IN statement is to examine the contents of 
a magnetic tape. There are several reasons for wishing to do this. The 
programmer may suspect that the tape contains errors from one of his own 
programs; or the tape may have been received from some other installation 
whose programmer omitted to say what is on the tape. The tape may have 
been written by some complicated general-purpose program, and its precise 
format may be difficult to determine. 

5 ■ 15 A TAPE D U M P PROGRAM 
203 
The routine shown in Figure 5.5 examines the tape and discovers 
its mode (binary or BCD), the number of words in each record, and gives 
an octal print of these words. In the current version, the routine reads 
records of any length but it only prints the first 300 words of long records. 
The records that are printed are, of course, physical records. By examining 
the dump of the records it would probably be possible to discover if they 
SUBROUTINE 
DMP(NT»K) 
DIMENSION AC300)tIM(2) 
DATA 
(IM*4H BCD.7H BINARY) 
DO 100 J«lt2 
S REWIND NT 
$J1»J-1 
BUFFER IN (NTtJl ) ( A i A O O O M 
101 
IF(UNIT.NT) 101.110»100.100 
100 
CONTINUE 
PRINT 500.NT $ RETURN 
500 
FORMATÎ13H DUMP ON TAPEI6»12H HAS FAILED.) 
110 
REWIND NT S PRINT 501»NT·IM(Jl+1) 
501 
FORMAT15H TAPEI6.6H IS INA8t 5H MODE ) 
DO 120 J«1»K S BUFFER IN (NT.J1 ) (Α·Α(300Μ 
121 
IF(UNIT»NT) 121♦1221123 » 124 
124 
PRINT 502tJ $ GO TO 120 
502 
F0RMAT(7H REC0RDI6»14H PARITY ERROR.) 
123 
PRINT 503 
$ GO TO 120 
503 
FORMATC13H END OF FILE.) 
122 
KL-LENGTHF(NT) S IF(KL.GE.300) 125»126 
125 
PRINT 504tJ $ GO TO 127 
504 
F0RMATC7H REC0RDI6.21H MORE THAN 299 WORDS.) 
126 
PRINT 505«JtKL 
505 
F0RMAT(7H REC0RDI6.4H HASI6»7H WORDS.) 
127 
PRINT 506·<Α<Ν).Ν«1·Κί> 
506 
F0RMATC6018) 
120 
CONTINUE 
END 
FIG. 5.5 A tape dump routine 
are blocked or if they have been written by a Fortran WRITE statement. 
It is not always possible to discover the recording density of the tape by 
means of a program. Tape units are capable of correctly reading a low-
density tape even when the unit has been set to read high density. The 
routine begins by trying the BCD mode and then the binary mode. 
The BUFFER IN statement reads records of any length. The arguments 
(A(1),A(300) cause it to read a maximum of 300 words. Any words in 

204 
5 THE COMPUTER 
SYSTEM 
excess of 300 are skipped. If there are fewer than 300 words in the record, 
then only that number of words are read. Asking for too many or too few 
words does not cause an error to be indicated in the IF UNIT test. 
The actual length of a record can be discovered by use of the routine 
LENGTHF. This routine assumes that all the records are in the same 
mode. A simple modification would allow it to try the alternative mode 
whenever a parity error is detected. 
5-16 
THE SOFTWARE SYSTEM 
The concept of software was introduced in Section 1.7 and several systems 
were described. Software is simply a collection of programs. Many of these 
programs are very complex and some of them are very extensive, but they 
do not differ in principle from the programs with which we are familiar. 
Most systems have been written in assembly language, but there is no 
absolute reason why this should be so. The use of assembly language brings 
benefits on a microscopic scale but it is obvious from the systems that are 
currently available that software written in compiler language could bring 
some much-needed improvement on the macroscopic scale. Assembly 
language helps the systems programmer to save small amounts of time and 
space in individual parts of the system. Compiler language would allow the 
systems programmer to keep a good overall view of the system and to 
introduce major modifications as they are needed. Pyle (1964) describes a 
Fortran compiler written in Fortran. Corbato et al. (1965) describe an 
ambitious multicomputer time-sharing system which is to be written in 
PL/1. The use of compiler languages in the writing of systems could reduce 
the number of years that usually elapse between the announcement of a new 
machine and the appearance of adequate software. 
The question arises of how the system can be written in compiler 
language when the compiler itself is part of the system. The first step is to 
write the system and the compiler in compiler language, ignoring for the 
moment the problem of translating the written program into machine 
language. During this writing stage various ideas can be tried out until the 
major details of the system are fixed. The second step is to translate the 
compiler language into machine language. This can be done in two ways. 
The first method is to translate the essential parts of the system by hand. 
The resultant system need not be efficient, comprehensive, or even fool-
proof. Having assembled this small working system, the full system can be 
assembled. The result is a comprehensive but possibly inefficient system. The 
final stage is to use the comprehensive system to recompile the system. The 
result should be a comprehensive and efficient system. Whenever future 
improvements are made to the compiler, it might be advantageous to re-
compile parts of the system. The second method of compiling the first ver-
sion of the system is to use another computer. This is the approach used by 

5 ■ 16 THE SOFTWARE SYSTEM 
205 
Pyle (1964). A compiler for the ICT Atlas computer was written in Fortran 
II and compiled on the IBM 7090. The 7090 produced an Atlas machine-
language program that represented the bulk of the new compiler. The 
compiling process is essentially the transformation of one string of bits, 
namely the compiler language statements, into another string of bits, namely 
the machine-language program. Any machine can produce programs for 
any other machine. In Section 7.10 we show how a simple assembler can 
be written in Fortran. This assembler produces machine instructions for the 
CDC 1604. It is obvious from the code that it could be run on any machine 
that had a suitable compiler. 
The software system includes: (a) the interrupt monitor, (b) the 
compiler, assembler, loader, and the library routines, (c) the programs to 
buffer and to initiate I/O operations, (d) the job monitor, which calls in the 
various parts of the system as they are needed. The interrupt system has 
been discussed in detail and it has been shown that the interrupt programs 
are no different from other types of program. The compilers, assemblers, 
and loaders are usually very large and complex, but this complexity usually 
arises not from the nature of the problem but from the need to achieve the 
maximum possible efficiency. Buffering techniques have been discussed 
in the earlier parts of this chapter. The job monitor has the task of super-
vising the overall operation of the system. If the system is well designed, 
this task is no more difficult than the linking together of subroutines that 
occurs in an ordinary program. 
Some of the concepts of multiprogramming can be illustrated by 
the following examples. 
A job has the following main program: 
CALL ALPHA 
CALL BETA 
END 
and another job has the main program: 
CALL GAMMA 
CALL DELTA 
END 
These two jobs could be combined into one job by writing the main 
program as 
CALL ALPHA 
CALL BETA 
CALL GAMMA 
CALL DELTA 
END 

206 
5 THE COMPUTER 
SYSTEM 
For the reasons discussed in Section 1.12, it might be advantageous to do 
part of one job and then part of the other job by arranging the main 
program as 
CALL ALPHA 
CALL GAMMA 
CALL BETA 
CALL DELTA 
END 
However, this solution might lead to difficulty if all of the routines produce 
output. The output from the first job will be mixed with the output from 
the second. The solution to this difficulty is to insist that the routines must 
put their "standard" output onto unit number NOUT. Let the actual 
standard output unit be 61 and let unit number 50 be a scratch unit. 
COMMON 
NOUT 
NOUT-61 
$ 
REWIND 50 
CALL ALPHA 
NOUT=50 
$ CALL GAMMA 
$ NOUT=61 $ENDFILE 50 
REWIND 50 
$ CALL BETA 
CALL COPY( 50,61) 
$ 
CALL DELTA 
END 
COPY (I,J) is assumed to be a routine that copies the contents of 
unit I onto unit J. The above main program sorts out the output so that all 
the output from the first job appears, and then all the output from the 
second job. The input streams could be separated in a similar way. This 
multiprocessing could run into another difficulty if the two jobs happened 
to use the same area of memory. Suppose both jobs use 5000 locations of 
COMMON storage. 
COMMON 
NOUT,X(5000) 
REWIND 51 $ 
REWIND 
52 
CALL ALPHA 
WRITE (51) 
X 
CALL GAMMA $ REWIND 
51 
WRITE (52) X 
$ 
READ (51) X 
REWIND 52 $ 
CALL BETA 
READ 
(52) 
X $ CALL DELTA 
END 
preserves the integrity of memory for each of the jobs. In this example both 
of the programs are in memory at the same time ; however, there is no 
essential difference between program and data storage and the same 
memory space could be used for both sets of programs. The Fortran II 
chain facility and the overlay feature of Fortran 63 provide a ready 

5 · 16 THE SOFTWARE SYSTEM 
207 
mechanism for sharing storage space between two programs. The operation 
of a multiprogramming system differs from the above example only in the 
fact that programs may be swapped at any interrupt, whereas the example 
only swapped programs at the end of a subroutine. 
In an actual time-sharing system the activation of any job depends 
on the way in which the user is responding to the system. We can illustrate 
this by the following example. The system has four on-line typewriter input 
and output units. The input from these units can be obtained by using a 
BUFFER IN statement. The interpretation of the 
IF (UNIT,!) 
nun2in3,n4 
differs slightly from normal usage. The nx branch is taken if no input has 
been received. n2 indicates that input has been received. n3 indicates that the 
unit has been switched off, and n4 is not used. There are four programmers 
using these units. The programmer on unit N wants to use a routine called 
ALPHAN. The programmer types his data, the routine accepts the data, 
does a calculation, and then prints an answer. The programmer can now 
type in some more data, or he can wait while he makes up his mind, or he 
can switch off the typewriter. 
DIMENSION 
ON(4), MESAGE(32) 
DATA 
(ON = 1,1,1,1) 
4 
N = 1 
2 
IF ( ON(N) 
- 
1) 
11,1,20 
1 
BUFFER 
IN (N,0) (MESAGE(8*N-7), MESAGE(8*N)) 
ON(N)=2 
20 
IF (UNIT, N) 11,12,13,13 
12 
ON(N) = 1 
GO TO (21,22,23,24) , N 
21 
CALL ALPHA1 $ GO TO 11 
22 
CALL ALPHA2 $ GO TO 11 
23 
CALL ALPHA3 $ GO TO 11 
24 
CALL ALPHA4 
11 
N = N + 1 
IF( N.LE.4) 2,3 
3 
IF(ON(1) + ON(2) + ON(3) + ON(4).EQ.O) 99,4 
99 
STOP 
13 
ON(N) = 0 $ GO TO 
11 
END 
The integer ON keeps track of whether the unit is still switched on or not. 
The units are serviced in turn, but if one user is not ready, he misses a 
turn. In an actual time-sharing system this switching between programs 
would be done at every interrupt. When one user switches off, the system 
continues to service the unit in case another user switched it on. It then 
loads his program in place of ALPHAN. We will now consider some of the 
general characteristics of time-sharing systems. 

208 
5 THE COMPUTER 
SYSTEM 
5-17 
TIME SHARING and MULTIPROGRAMMING 
The introduction of interrupt systems and the ability of the computer to do 
I/O and computing simultaneously suggested a different way of using the 
computer. In a simple example of this system the computer runs two jobs at 
once. One of the jobs may require lots of computing and not much I/O; the 
other job may require mostly I/O. The system commences by initiating the 
I/O for the second job; then it processes the first job until an interrupt 
occurs. It processes the interrupt, initiates another I/O operation, and 
returns to the first job. It was suggested in the early days of the IBM 709 
that this mode of operation would eliminate the need for peripheral com-
puters. In fact, multiprogramming has not been used to any great extent on 
the 709 or 7090 except for the simultaneous operation of computing and 
I/O within one job. There are several obstacles to its use. In the first place, 
the art of systems programming was not sufficiently well developed in the 
early days of the 7090. In the second place, there were many extant programs 
that used all of the core memory and it was impossible to force programmers 
to release this memory. In the third place, the 7090 did not have an adequate 
memory-protection device. In a modern machine it is possible to lock out 
parts of the memory so that the programmer can read from those parts, but 
he cannot write into them. The systems program can write into any part 
of the memory. This protection device means that no programmer can 
inadvertently overwrite either the systems programs or any other programs 
that the system wishes to protect. 
Improvements in the hardware and increasing competence in the 
development of software have made it possible to run modern machines in 
the multiprogramming mode. As these new systems were developed it 
became obvious that completely new methods of using the machine were 
economically possible. The most important of these new operating 
methods is the ability to have real time interaction between the computer 
and the programmer. 
Multiprogramming can operate on various levels. Let us examine 
the first of these levels. The system reads in the first job and initiates the 
processing of that job; for example, it might bring the Fortran compiler 
into core and give control to the compiler. When the next interrupt occurs, 
the system brings in a second job; for example, it might require the 
loader. The loader is brought into core and the second job is initiated. The 
system, with the aid of hardware, takes care that the two jobs do not destroy 
each other. The system proceeds in this fashion to bring several jobs into 
memory. At any one time, one job, or the system itself, has control of 
the CPU. The other jobs are all dormant, although the channels may be 
doing I/O that was previously requested by those jobs. When the current 
job is held up because it needs some I/O, the system initiates the I/O request 
and turns control over to another job. The cardinal principle of operation 
is that the system should optimize the use of hardware. The jobs that 

5 · 17 TIME SHARING AND M U L T I P R O G R A M M I N G 
209 
are in memory at any one time should be suitably mixed so that one job 
can continue CPU operations while the other jobs are waiting for I/O. The 
use of this method of operation introduces several difficulties. First, the 
ordinary programmer must not be burdened with the problems of multi-
programming. Each program, apart from the system itself, must think that 
it is the only program in the machine. The system is also subdivided so that 
only one part of the system need concern itself with the problems of 
multiprogramming. If the hardware is adequate, it is not difficult to ensure 
that programs do not interfere with each other. The simplest type of 
protection system works as follows. The system allocates a contiguous set 
of memory locations to each program. Before activating any program, the 
system sets the lower and upper limits of usable memory in a special 
register. While the program is operating, the hardware compares every 
address with the memory limits. Any transgression of the limits causes an 
interrupt. 
The second difficulty associated with multiprogramming is the 
competition for core memory. The obvious answer to this problem lies in 
the provision of much larger memories. Using a large amount of fast 
random-access memory is self-defeating: the I/O channels are being used 
more efficiently, but the memory is used less efficiently. The most promising 
solution is the coupling of a fast core memory to a cheaper disk or bulk 
core memory. The hardware keeps track of the way in which each segment 
of core memory is being used. Any segments that are not currently in use 
are relegated to the slow memory. This system is described in more detail 
in Chapter 9. 
The third difficulty of multiprogramming lies in the scheduling 
algorithm. The most advantageous mixture of jobs consists of several jobs 
with small memory requirements, together with one job that requires a great 
amount of memory. A job that requires little I/O should be mixed with 
jobs requiring a large amount of I/O. The memory requirements of each 
job can usually be estimated if necessary; the system can allocate a small 
amount of memory and then interrupt the job if this amount of memory 
proves inadequate. The I/O requirements are very difficult to anticipate. 
The system can only assume that if sufficient jobs are available, most of the 
equipment will be kept busy. 
A fourth difficulty with multiprogramming lies in estimating the 
cost of the computation. In a system that runs one job at a time, the cost 
is simply proportional to the time used. In the shared mode, it could be 
very expensive to keep count of the amount of time and equipment used 
by each job and it would be very difficult to account for the time used by 
the system. 
Despite these objections there is no doubt that multiprogramming 
will be the normal mode of operation on large systems. The aim of a 
modern system is to give the user the widest possible use of all the facilities 
of the computer, with the minimum of effort on the part of the programmer. 

210 
5 THE COMPUTER SYSTEM 
This means, for example, that the ordinary programmer should not be 
troubled with problems of the efficiency of I/O operations. Thé user should 
also be able to interact with the machine in a way that is impossible on the 
systems that run only one job at a time. The user ought to be able to see 
how his job is running. If there is a simple mistake, then he ought to be able 
to correct it immediately—he should not have to wait several hours. This 
means that the machine must run in the multiprogramming mode and it 
must share its time among a large group of users. The computing system 
consists of a large central processing unit with a large memory, with tape 
units, a disk and drum, fast line-at-a-time printers, and the usual auxiliary 
equipment, plus 20 or 30 lost-cost input-output devices. Currently available 
low-cost devices are a typewriter keyboard input and either a typewriter 
or television screen output. The system can accept input from these devices. 
Instead of punching cards and submitting these for batch operation, the 
programmer can type his program directly into the typewriter. The line 
of typing is stored in a small buffer attached to the typewriter. Then when 
the end of line key is pressed, a signal is sent to the computer. The com-
puter accepts that line and passes it on to the appropriate program. The 
straightforward application of this technique requires the programmer to 
type his whole program into the computer. The computer takes its input 
from the typewriter rather than the system input tape. However, there is a 
new factor in the situation. The compiler can talk back to the program. As 
each line is typed in, the compiler checks it. If there are any errors, the 
compiler types out a message immediately and the programmer types the 
corrected line. Some errors can only be detected when the whole program 
has been read in. When the END statement is reached, the compiler first of 
all saves the Fortran text on the disk and then does a normal compilation. 
At the end of the compilation it types out either a diagnostic or an indica-
tion of success. In the case of failure, the programmer can check his 
program. He can then indicate which lines of the Fortran code are wrong 
and type in the corrections. The copy of the program on the disk is 
amended and the compilation is retried. When the compilation is successful, 
the binary output is stored on the disk and the next subroutine is typed 
in. Finally, the loader takes over and loads the binary decks from the disk. 
This technique of editing information stored on the disk can 
obviously be extended. Providing the disk is sufficiently large, the text 
generated by each programmer can be saved from day to day. At the start 
of a run, the programmer does not have to type in the whole program. If 
any changes are necessary, he types in the changes and modifies the 
information on the disk. If no changes are necessary, he simply asks for the 
program to be loaded. During execution, the program can use simple 
Fortran statements to request data from the typewriter and to print the 
results. 
There are several obvious advantages to this mode of operation. 
The programmer can submit his program and receive immediate reaction; 

5 · 17 TIME SHARING AND M U L T I P R O G R A M M I N G 
211 
he does not have to wait several hours to discover that some minor error 
has prevented execution. During execution the programmer can check for 
obvious errors and ask for corrected data. The less obvious advantages are 
the new methods of running programs. There are many problems for which 
no foolproof methods exist. With man-machine interaction, the user can 
try various methods and can use his experience to guide the course of the 
calculation. Methods that were useless because of delays in the old system 
can now be tested out in a few minutes. Some problems require immediate 
reaction. Simple examples are the playing of games and the use of the 
machine in controlling programmed learning. 
One by-product of the use of low-cost input-output devices is the 
ability to use the machine from remote locations. Because typewriters are 
slow in printing, and because humans are slow in typing, the system has to 
minimize the amount of information that is transferred. One method of 
doing this has already been explained. The system stores information on 
the disk and allows the programmer to edit it. The volume of output can 
be restricted because the user can always ask for more output. In the 
conventional mode of programming, the programmer puts in many print 
statements because he does not know where the errors will occur. In the 
new mode of operation he prints a small number of results. If these are 
correct, all is well. If they are not correct, he requests the machine to print 
out some of the auxiliary results. This can be done immediately. It does not 
require another run and a delay of several hours. If a large amount of 
output is required, the programmer uses the typewriter to make sure that 
the program has run correctly, then he directs the bulk output to one of the 
fast printers attached to the machine. To return to the problem of remote 
operation. Transmitting information at high rates over long distances is 
very expensive. The old method of operation required high rates of 
transmission because a large program and many results had to be trans-
mitted. With the new method, little information is transmitted from or to 
the typewriters; a conventional speech telephone line is quite adequate. 
If 20 or 30 users are trying to use one machine, the system has to 
use a new method of scheduling. It cannot wait until an I/O request holds 
up a program, because this may take several minutes and the other users 
will be discouraged. For the reactive system to be effective, each user must 
receive instantaneous reaction to his simple requests. Instantaneous is, of 
course, a relative term, and since humans are involved, a delay of several 
seconds is tolerable. The system operates by initiating each job as it is 
requested. It runs job 1 for a small amount of time; job 1 is interrupted if 
it requests I/O or if it runs for more than a time Δ/ without requesting I/O. 
Job 2 is then run for a maximum of Δ/. The next job is run for a time 
At, and so on. At must be small enough so that each user can be serviced 
every few seconds. This suggests that At should be about one tenth of a 
second. At will vary with the number of users and the type of use. The 
system must change At according to the current situation. If every user is 

212 
5 THE COMPUTER SYSTEM 
requesting computation, Δ/ must be small, but in a typical situation many 
of the users are sitting thinking or slowly typing statements. 
With the core memories that are currently available, the system 
cannot hold all jobs in core. At any one time the system might be running 
job n while writing job n — 1 onto the drum and reading job n + 1 from the 
drum. The cost of this operation is divided into two parts. When the system 
switches from one job to the next, it must store the contents of the control 
register, the accumulator, and all the other registers. Modern machines are 
designed so this can be done quickly. The system must read the program 
and all its data from the drum and later it must write the data onto the 
drum. Providing the program does not modify itself, the program need not 
be written back. This reading and writing can be overlapped with the 
operation of other jobs, to a certain extent. In a small and simple system, 
lack of core or the failure of the next job to run its full quantum of time 
(that is, the time At mentioned above), frustrates the attempts to overlap. In 
a large machine with a sophisticated system, little time need be lost. 
The description of the project MAC system by the staff of the 
M.I.T. Computation Center (Crisman, 1965) is easy to read; so is the 
account of the System Development Corporation (SDC) system by 
Schwartz, et al. (1964). Schwartz (1965) gives an interesting account of the 
trials and successes of the SDC system. Both of these systems were experi-
mental and were on machines that were not designed for time sharing. It is 
felt that the application of the experience of the earlier systems and the use 
of a new generation of computers will produce vastly improved systems. 
See, for example, the articles by Corbato and Vyssotsky (1965), Glaser and 
Olver (1965), and Vyssotsky et ai (1965). 
There are a number of objections to the use of time sharing. First, 
the system is large and complicated. It is difficult to check out such systems 
and the average user may encounter many frustrations while the new system 
is being thrust upon him. Second, the new method of operation generates a 
much greater amount of I/O. Some of this I/O can be overlapped but there 
is some loss of efficiency. The answer to this objection is that current 
systems contain hidden inefficiency, and furthermore, increasing sophisti-
cation of hardware and software will help to improve the efficiency of the 
overlap. A third objection is that the reactive systems favor small jobs. This 
is to a certain extent true; however, a large job can be broken down into 
phases. The first phase involves the checkout of a large program. This 
checkout is not necessarily a large job. For example, the Fortran compiler 
is a large program but a single compilation can be accomplished in less than 
10 seconds on existing machines. The testing of the compiler could be 
accomplished in 10-second runs. If the large job involves a standard run 
on the large program, then the operation can be divided into two stages, 
namely, the data input and the run itself. If the data input is done through 
a reactive typewriter, the user can at least be sure that his data is acceptable. 
He can then be reasonably sure that the problem will run correctly and he 

5 ■ 18 THE CDC 6600 
213 
can afford to wait for the results. A final objection to reactive systems is 
that they encourage the user to use the machine inefficiently. There are two 
answers to this objection. First, it is legitimate to use the machine with less 
than optimum efficiency if there is a corresponding gain in the efficiency of 
the user. Second, even with nontime-sharing systems, the machine wastes 
a not insignificant proportion of its time. Suppose a programmer submits 
a job to a conventional system and he happens to make a mistake which the 
compiler discovers. The job is rejected. The time spent in reading the job 
into the system is thrown away. In an ideal system on a machine of the 
speed of the 7090, it should be possible to run a job of this sort in five 
seconds or less, but in actual practice it takes 20 or 30 seconds for the 
minimum job. In a time-sharing system when the compiler discovers a 
mistake, the previous operations need not be thrown away. The pro-
grammer can correct the mistake and the system can do another compi-
lation. 
We have emphasized that only one CPU is used in a time-sharing 
system. This is true of most systems, time sharing or otherwise, but 
obviously it is possible to link several machines together. The concept of a 
monitor that controls a CPU and many I/O devices can be extended to a 
monitor that controls resources of any type. 
5-18 
THE CDC 6600 
We have emphasized the role of the interrupt mechanism because it is the 
usual method of supervising large systems. The CDC 6600 does not use 
the interrupt method. The general details of the 6600 were explained in 
Section 1.13. The machine has one central processor and ten PP'S (peri-
pheral processors). Each PP is a simple computer that can do both I/O 
and normal computing operations. The timing of instructions in the CP 
(the central processor) is based on a minor cycle which is 0.1 micro-
second. A major cycle is ten minor cycles. The PP's appear to the pro-
grammer as though they were ten completely distinct computers which each 
obey one instruction every major cycle. In actual fact, there is one piece of 
hardware which does one instruction each minor cycle and which services 
each of the PP's once in every major cycle. The instructions for a PP are 
stored in the 4096-word memory that is attached to that PP. Instructions 
are 12 or 24 bits long. Each PP has its own program address register and 
one accumulator. There are 64 different PP instructions which include 
integer addition and subtraction, logical operations on 18-bit quantities, 
and conditional and unconditional jump instructions. These instructions 
are executed at the rate of one instruction every two or three major 
cycles. A PP can read or write into the central memory. This operation does 
not use an I/O channel. In the write operation, the PP transmits five 
12-bit words; the operation takes six major cycles. These short words are 

214 
5 THE COMPUTER 
SYSTEM 
assembled in a buffer and transmitted to central memory as one 60-bit 
word. The CP cannot transmit words to a PP, but it can, of course, set 
a word in central memory in anticipation of a PP looking for that word. 
A PP can communicate with peripheral equipment by any one of the 12 
channels. It can detect which channels are inactive and choose an appro-
priate channel. It can transmit one or more words with one instruction. 
There is no interrupt mechanism. The PP initiates an I/O operation and 
usually stays in a loop until the operation is complete. Since there are ten 
PP's, this is not a wasteful process. 
A PP can initiate a program in the CP by putting (or using another 
PP to put) the CP program into the central memory. The PP must then 
build up an " exchange jump package " and then do an exchange jump. The 
jump package is a sequence of 16 words in the central memory which will 
be used to set the initial values of AO through A7, XO through X7, Bl 
through B7, P,RA,FL, and EM. The A,X, and B registers were described 
in an earlier chapter. P is the address of the next CP instruction. RA is 
the reference address, which is used for program relocation. The CP has 
an automatic relocation device; any reference to memory location K is 
always interpreted as a reference to memory location K + RA. The CP 
programs can always be written as though they started in location zero. FL 
defines the number of consecutive memory locations used by this program. 
The CP stops if the program references an address outside the range defined 
by RA and FL. EM specifies the conditions that are allowed to stop the 
operation of the CP. These conditions include address out of range and 
errors in arithmetic operations. 
The exchange jump is a PP instruction. It specifies the address of 
an exchange package that is currently in central memory. It sets up the 
initial conditions for the next program ; it stores the previous contents of 
the A,X,B,P,RA,FL, and EM registers (that is, the contents of these 
registers immediately.before the interrupt) in the exchange package. Thus, 
the exchange packages of the old and the new programs are interchanged, 
and then the operation of the new program is commenced from the 
instructions in location RA + P. 
The standard operating system for the CDC 6600 uses the follow-
ing strategy. One PP is designated as the Executive PP; this processor 
contains the master control program. One PP is designated as the Monitor 
PP. Its sole function is to keep a continuous watch on the program operat-
ing in the central processor, and to pass on messages from that program 
to the Executive. The Executive PP schedules all jobs, including the jobs in 
the central processor. The eight remaining PP's are held in a pool. When 
any peripheral operations are required, the Executive PP selects a PP from 
the pool and instructs it to carry out the operation. Commonly used PP 
programs are held in the central memory and they are transferred into the 
appropriate PP whenever they are required. 
There are usually several programs in central memory at one time 

5 · 19 S U M M A R Y 
215 
but only one central processor program is in operation. This program can 
request I/O by storing the request in a specific location in central memory, 
and then stopping. The stop condition attracts the attention of the 
monitor PP. An I/O request can take one of two forms. If it is a buffered 
I/O request, then the monitor PP accepts the request and restarts the 
operation of the central processor program. At some later time the central 
processor program can examine a flag to see if the request has been 
fulfilled. If it is an unbuffered I/O request, it implies that the program 
cannot continue until the request is filled. The monitor PP passes the 
request to the executive PP. This PP does an exchange jump to start the 
central processor off on some other job and then it examines the request. At 
some later stage, when the I/O has been completed, the first program is 
continued. Besides the supervision of the central memory programs, the 
executive PP can accept requests for card to tape, tape to printer, and 
other I/O jobs. It allocates PP's to process these jobs and supervises the 
operation of these PP's. 
The CDC 6600 presents ingenious solutions to many of the 
problems of operating a large computing system. There are two aspects of 
the hardware that fall below the power of the rest of the system. First, there 
is no special provision for character manipulation. This means that 
compiling and assembling are comparatively expensive operations. Second, 
the machine has no interrupt system. The interrupt system was not included 
because there are ten PP's and so there is no loss of efficiency if one PP 
is completely tied up by each I/O operation. The 6600 has a display unit 
that shows the status of the job stack and the utilization of the PP's. 
Observation of the operation of a 6600 shows that there are rarely more 
than three PP's in use at one time; that is, three in addition to the executive 
and the monitor PP. The fact remains that the executive PP is used to 
control the total operation of the system, and it must be difficult to avoid 
significant delays in responding to the requests of the central processor 
programs. As with any large system of this sort, experience will no doubt 
suggest ways of modifying the software in order to use the machine to its 
fullest capacity. 
The CDC 6600 has an assembler for CP programs, an assembler 
for PP programs, and a series of macro operations for communication 
between the program and the system. It has a Fortran compiler which is 
modeled on Fortran 63. The CP normally operates in the multiprogramming 
mode, but the individual programmer, of course, need never be aware of 
this fact. 
5-19 
SUMMARY 
A computer system is made up of hardware and software. The hardware 
consists of the physical components from which the machine is made. The 

216 
5 THE COMPUTER 
SYSTEM 
software consists of library subroutines, monitor systems, compilers, and 
assemblers. Early computers had little software, but in recent years it has 
been realized that hardware and software are equally important. 
The hardware is divided into several distinct parts. The arithmetic 
and control section of the machine are in the central processing unit. The 
core memory is a separate unit. The channels are simple computers that 
can transmit information from the memory or CPU to the input-output 
devices. The program instructions for the CPU and the commands for the 
channels are stored in the memory. The CPU instructions direct the opera-
tion of the machine. The CPU can instruct a channel to carry out an 
input-output operation. The channel can continue the operation without 
further instructions from the CPU. 
The synchronization of CPU and channel operations is achieved 
by the interrupt system. Part of the memory contains the operating pro-
gram, part contains a resident or monitor program. An interrupt takes 
control from the operating program and hands it to the monitor. The 
monitor processes the interrupt; for example, an interrupt caused by an 
end of record encountered on an input tape might cause the monitor to 
note the fact that the read was successful and to initiate another read. The 
monitor restarts the operating program without that program being aware 
that an interrupt has occurred. In modern machines the interrupt is used 
to notify the monitor of I/O operations, arithmetic faults, illegal use of 
memory, and all other exceptional conditions. 
The monitor system has several functions. The basic monitor 
operations are control of input-output, supervision of operating programs, 
and the supervision of job flow. The monitor, the library routines, and the 
customer's program are divided into a great number of autonomous 
components; for example, the Fortran WRITE statement does not write. It 
requests a library routine to assemble certain information and that library 
routine requests the input/output monitor to do the writing. In many 
phases of the operation of the computer a seemingly simple operation is 
carried out by a series of devious steps. WRITE does cause the information 
to be written but it is not written at the time or from the place at which 
it is requested. This division of tasks makes for a more efficient and more 
flexible operation of the computer. 
In the time-shared mode of operation, several jobs are run at 
once. The machine has only one CPU (some machines can and do have 
several CPU's, but this is not the usual case), and only one control register. 
At any one time the CPU is processing only one job, but the CPU processes 
part of one job before going on to another job. The first job is held dormant 
for some time and regains control at a later time. The purpose of time 
sharing is either to optimize the use of the equipment or to allow man-
machine interaction, or, preferably, to do both of these things. Time 
sharing requires the machine to do many more operations than is required 
in a single system, but because input-output is more effectively overlapped 

PROBLEMS 
217 
with Computing, the overall result can represent a gain in efficiency. Man-
machine interaction may entail the inefficient use of some of the machine 
hardware, but it can result in a much greater efficiency on the part of the 
user. 
PROBLEMS 
1 ■ A magnetic tape has a density of 800 bits per inch and an inter-record 
gap of 0.75 inch. The tape is nine bits wide, one of the bits being a 
check bit. What length of tape would be used by 1000 records of 200 
words each with 32 bits in each word? If rewinding the tape proceeds 
at 150 inches per second, what is the rewind time? What is the length 
and the time for 2000 records of 100 words each. 
2 ■ What is the difference between an instruction and a command? What 
is a channel and why is it used? Can the channel carry out arithmetic 
operations? What is a CCW? 
3 ■ Let RANF(l.O) be a Fortran subroutine that generates random 
numbers in the range 0 to 1.0. Consider the subroutine 
SUBROUTINE BETA 
COMMON A, B, C(100) 
IF(RANF(1.0).GT.0.5) CALL ALPHA(P,Q) 
END 
What restrictions would you place on ALPHA if you wished to make 
sure that BETA could not detect whether ALPHA ever gets called? 
What is the analogy between this situation and the interrupt mecha-
nism? 
4 ■ Find out the characteristics of the auxiliary equipment on the com-
puter you are using. For tape units, find out how many there are and 
what density is usually used. Are they preaddressed ? What speed 
does the tape move at? How many bits are recorded across the width 
of the tape? How long is inter-record gap? For drums and disks, find 
out the capacity, the capacity per track, the rate of revolution, the 
number of heads, and the time to move the heads from track to track. 
5 ■ Explain the arrangement of information and the mechanism for 
reading and writing on a disk. What is a disk cylinder and why is it 
useful? What are the relative advantages of disks and drums? What 
problems arise in trying to use a disk efficiently? Does the computer 
you are using have a disk, if so how are the disk I/O operations 
scheduled ? Is each request serviced in turn or does the system try to 
minimize the movement of the access arm ? 

218 
5 THE COMPUTER 
SYSTEM 
6 ■ A mechanical graph plotter is driven by characters from a magnetic 
tape. The characters have the following effect. 0, 1, ..., 7 cause the pen 
to move 0.01 inch in the direction 0°, 45°, ..., 315°. 8 causes the pen 
to be lifted up off the paper. 9 sets the pen down on the paper; thus 
900080092222 draws a line of length 0.03 inch parallel to the JT axis, the 
pen would move a further 0.02 inch without drawing a line (the pen is 
off the paper) then it would draw a 0.04-inch line parallel to the 
Y axis. Assuming the pen starts at the lower left corner of the page, 
write a program that writes a tape suitable for plotting. The plot tape 
should cause the plotter to draw a circle of radius 4 inches with center 
6 inches to the right and 5 inches above the starting position. Write the 
tape in format 120 II. 
7 ■ On the IBM 7090, which uses internal BCD code with six characters 
per word, what would appear on the printer as a result of 
l = ((((16x64+17)*64+18)*64 + 16)*64 + 16)*64+20 
Print 500, I 
500 
FORMAT(A6) 
Do not use the computer to answer this question. The statement prints 
six characters. What IBM 360 Fortran program would produce the 
same six characters on the printer (remember that one word can hold 
only four bytes)? 
8 ■ If J is a scalar variable, the program 
DO 100 1=1,N 
100 
READ(8)J 
skips N records on tape 8 : it reads the first word and then ignores the 
rest of the record. Rewrite this program using BUFFER IN. Remember 
the distinction between logical and physical records. 
9 ■ Study the routine WRITEB. Write the Fortran program for the con-
verse routine namely READB. A description of this type of binary 
read is given in Section 5.10. 
10 ■ A tape has been written with ten logical records per physical record. 
There are 30 words in each logical record. Write a Fortran program 
subroutine with the name RDBLOK such that CALL RDBLOK(A) 
puts the next logical record in A(l), A(2), ..., A(30). RDBLOK 
should handle all tape reading (using BUFFER IN if possible) and 
unblocking. 
11 ■ Write a Fortran program with the following properties. The program 
can deal with up to six units at once. Each unit has n buffer areas, n is 
initially 2, but if any unit causes a delay, then more buffers are allo-
cated to that unit. The program writes physical records (ignore the 
complications of blocking in this problem). In OPEN we did an 
IF UNIT on unit N whenever the current buffer for unit N was 

PROBLEMS 
219 
exhausted. In this routine do an IF UNIT on every unit on every entry 
to the routine. In this way you can initiate a new I/O request whenever 
you find a unit is dormant. 
12 ■ If the software is to provide adequate buffering, are two buffers per 
I/O unit sufficient or should there be more ? Explain why. 
13 ■ You have a magnetic tape that contains certain results. You have put 
a printed label on this tape with the words "SMITH/RESULTS A " 
To run this job on the IBM 704 you could simply tell the operators to 
"Load 'SMITH/RESULTS A' on unit 8" and then use READ 
TAPE 8 to read the tape. Why is this simple equivalence between 
logical and physical units no longer used? How would you do this job 
in the system you are currently using? How is the correspondence 
between logical and physical units set up ? 
14 ■ Suppose that a printer and its associated I/O equipment rents for 
$3000 per month. If it prints 1000 lines per minute and is in use for 
200 hours each month, how much does it cost to print one line? If a 
disk with a capacity for 2 x 108 characters rents for $8000 a month, 
how much does it cost to keep 80 characters on the disk for one 
month ? Suppose that you compute some results which will be needed 
n days later. Assume that the cost of punching one card equals the cost 
of reading one card equals the cost of printing one line. What are the 
comparative costs of (a) punching the data and reading it back at a 
later date, and (b) retaining the data on the disk for n days? For what 
value of n are the costs equal ? 

6·1 
INTRODUCTION 
6 
FORTRAN 
A Fortran subroutine is any set of Fortran 
statements that is compiled and assembled 
as a single unit. Some Fortran compilers 
distinguish between main routines, sub-
routines, and function subroutines. We will 
use the term " subroutine " to describe any 
of these types of routines. The main routine 
happens to be the one that the monitor 
system enters when it begins execution. 
From the point of view of the monitor, the 
main routine is a subroutine. A function 
subroutine is similar to an ordinary routine 
except that it puts a number into the 
accumulator before returning to the calling 
program. The aspects of the subroutine 
with which we will be concerned in this 
S U B R O U T I N E S 
chapter are first, how does the machine 
transfer control from the calling program 
to the subroutine; second, how does the 
I 
| 
machine transfer information; and, third, 
how do the compiler, assembler, and loader 
facilitate this transfer. 
| 
An overall view of the compilation, 
assembly, and loading process was given 
in Figure 1.8. A program consists of one 
I 
| | 
or more subroutines. These subroutines are 
processed quite independently of each 
other until they come to the loading 
I 
phase. The compiler and the assembler do 
not remember any information from one 
routine to the next. The loader sets up some 
links between the routines. Some of the 
channels of communication are not set up 
until the subroutine is called during execu-
tion. 
A subroutine is a set of machine 
instructions that performs some well-
defined task and that can be entered from 
many different places in some calling pro-
gram. There is no need for subroutines to 
be assembled in isolation. The standard 
assemblers and compilers such as Algol and 
220 
PL/1 allow several routines to be processed 
I 
I 

6 · 2 SUBROUTINES AND RELOCATION 
221 
at one time. Fortran, however, insists on compiling subroutines one by 
one. In this chapter we will keep to the Fortran convention and this will 
simplify some of the discussion. In Chapters 9 and 10 we will explain the 
techniques and advantages of the more general type of routine. 
6-2 
SUBROUTINES and RELOCATION 
The following subroutine does no useful computing but it can be used to 
illustrate some of the details of the compilation process. 
SUBROUTINE ALPHA 
A=B 
RETURN 
END 
The RETURN is not required in Fortran 63, the END statement is taken 
to imply a return. The above program could be compiled in the follow-
ing way : 
IBM 7090 
CDC 1604 
CLA 
B 
ALPHA 
SLJ 
* * 
STO 
A 
LDA B 
TRA 
1,4 
STA A 
BSS 
1 
SLJ 
ALPHA 
BSS 
1 
A 
BSS 1 
END 
B 
BSS 1 
END 
Fortran II and Fortran 63 actually produce a somewhat longer code than 
this because they tend to be inefficient on very small programs. However, 
the differences are not essential. The statement CALL ALPHA would 
appear in any other subroutine. It would be translated as TSX ALPHA,4 
on the 7090 or as RTJ ALPHA on the 1604. These instructions cause a 
jump to the first instruction of subroutine ALPHA. The load B and store 
A instructions are obeyed and the TRA 1,4 (or the SLJ ALPHA on the 
1604) causes a jump back to the calling program. The return goes back to 
the instruction following the TSX (or RTJ) instruction. 
In discussing the assembly program we stated that the ORG card 
indicated the origin or starting location of the program. Now the compiling 
and assembly of any program is independent of all the other programs in 
the deck. The assembler does not know which locations will be available 
for ALPHA when the time comes to load the program. An absolute 
origin cannot be assigned. The assembler assumes that ALPHA will be 
loaded into location zero but it also generates relocation information. 
ALPHA 
A 
B 

222 
6 FORTRAN SUBROUTINES 
Relocation information tells the loader what changes to make when it 
decides to load ALPHA into a location other than zero. The assembled 
code on the IBM 7090 is as follows. 
Relocation information 
Location 
Instruction 
Address part 
Decrement part 
0 
050000 0 00004 
+N 
0 
1 
060100 0 00003 
+N 
0 
2 
002000 4 00001 
0 
0 
3 
A goes here 
4 
B goes here 
The relocation information tells the loader the amount that must be added 
to each address and to each decrement when the program origin is changed 
by an amount N. The CDC 1604 version of the program is given below. 
Location 
Instruction 
Relocation information 
for address part 
0 
75 0 00000 
0 
12 0 00003 
+N 
1 
20 0 00002 
+N 
75 0 00000 
+N 
2 
A goes here 
3 
B goes here 
Suppose the loader decides to place the routine at location 12300. Then the 
machine instructions of the program are the following. 
7090 instructions 
1604 instructions 
050000 0 12304 
75 0 00000 
060100 0 12303 
12 0 12303 
002000 0 00001 
20 0 12302 
75 0 12300 
These instructions should be compared with the original instructions and 
the accompanying relocation information. This description has shown the 
content and the use of the relocation information. It does not show how this 
information is stored on a binary card. There are several methods of 
recording the information on a card. These will be discussed near the end 
of this chapter. The relocation information is used only by the loader, and 
it is not retained once the loading process is finished. The loader decides 
on the memory assignments and translates all addresses into their final 
absolute value. 

6 ■ 3 COMPILING SUBROUTINE A R G U M E N T S 
223 
6-3 
COMPILING SUBROUTINE ARGUMENTS 
Consider the more elaborate subroutine, 
SUBROUTINE ΒΕΤΑ(Α,Β) 
C=A 
IF ( C-2.6) 1,1,2 
2 
C = 3.0 
1 
B = C 
RETURN 
END 
The statement that calls this subroutine might be 
CALL BETA( X,Y) 
and this statement would be translated as 
IBM 7090 
CDC 1604 
TSX 
BETA,4 
RTJ 
BETA 
TSX 
X 
+ 
ZRO X 
TSX 
Y 
ZRO Y 
The general form of the CALL sequence consists of an instruction that 
jumps into the subroutine followed by a list that specifies the arguments. 
Each item of the list takes one word in Fortran II or Fortran IV; each 
item takes half a word in Fortran 63. These differences are due to differences 
in the machine hardware, they do not represent essential differences in the 
compilers. The reason for Fortran II using TSX X instead of ZRO X is 
not relevant to the discussion. Any operation code could have been used. 
The same format of the argument list is used for all calls to subroutines. A 
subroutine that requires n arguments generates a list of n items ; the list 
takes up n words in Fortran II or (n + 1 )/2 words in Fortran 63. The first 
statement in the routine BETA is translated as 
CLA 
A 
STO 
C 
LDA 
A 
STA 
C 
and somewhere at the end of the subroutine 
Remember the rules about subroutine arguments. The variable A must be 
picked up from the place where X is stored and B must be picked up from 
the place where Y is stored. But where is X stored? The location of X can 
be found by looking it up in the argument list, and the argument list can be 

224 
6 FORTRAN SUBROUTINES 
found by looking at the contents of index register 4 in Fortran II, or by 
a slightly more devious process in Fortran 63. The actual machine instruc-
tions could look as follows : 
IBM 7090 
CDC 1604 
BETA 
CLA 
1,4 
BETA 
SLJ 
* * 
STA 
* + 1 
LIU 
BETA,4 
CLA 
A 
LDA 
0,4 
STO 
C 
ARS 
24 
SAU 
A.1 
A.1 
LDA 
A 
STA 
C 
First of all consider the Fortran II example. The instruction CLA 1,4 picks 
up the word TSX X and puts it in the accumulator. The instruction STA 
stores the address part of the accumulator so STA * + 1 effectively changes 
CLA A into CLA X, which is just what was required. Now consider the 
Fortran 63 example. The instruction RTJ BETA in the main program 
causes the program to jump to BETA and it causes the address of the next 
instruction to be put into the address part of location BETA. The instruc-
tion LIU BETA,4 picks up this address. The LDA instruction picks up the 
address of X into the left half of the accumulator. The ARS 24 shifts this 
address into the right half of the accumulator. The instruction SAU A.l 
changes the LDA A so it becomes effectively LDA X, which is what was 
required. This process must be repeated for every reference to A or B which 
occurs in subroutine BETA. The RETURN instruction in subroutine 
BETA is translated into TRA 3,4 in Fortran II, so that the return jump 
skips around the list of arguments. In Fortran 63 the subroutine computes 
the return address and stores it in location BETA. 
There is one other feature of subroutines that should be discussed 
at this point. The subroutine BETA makes use of the accumulator, the 
MQ, and some of the index registers. It may happen that the routine that 
calls BETA is also making use of these registers. The designers of the 
Fortran system have decided on the following convention. Any sub-
routine may destroy the contents of the accumulator or the MQ but it must 
not destroy the contents of the index registers. Since the subroutine must 
use the index registers this convention might seem rather restrictive. 
However, all it means is that the subroutine must save the contents of any 
index registers which it uses and restore them before returning. The start 
of the program BETA in Fortran 63 consequently has to be changed to 
BETA 
SLJ 
* * 
SIU 
SV4,4 
LIU 
BETA,4 

6 · 3 COMPILING SUBROUTINE ARGUMENTS 
225 
and so on, as indicated above. At the end of the routine 
SV4 
EN I 
**,4 
restores the original contents of the index registers. We might mention at 
this point that the 7090 code with its use of the TSX instruction looks more 
efficient than the 1604 code with its RTJ. Actually this is not altogether true. 
In most programs there are not enough index registers available to satisfy 
all demands and a glance at any Fortran II program will reveal that it is 
continually picking up and setting down index registers. 
From the simple example shown above we can demonstrate some 
of the disasters that can befall a Fortran program. As a first example 
consider the statement 
CALL BETA 
in which the arguments have been omitted. The compiler does not check 
the number of arguments. In fact, it cannot check, since it does not know 
anything about any other routine. The above statement is compiled as 
TSX 
BETA,4 
RTJ 
BETA 
As previously, we show the IBM 7090 code on the left-hand side and the 
CDC 1604 code on the right-hand side of the page. The routine BETA 
picks up some arguments but what arguments it picks up is rather unpre-
dictable. Supposing the statement after the CALL BETA is 
P = Q 
then the compiled version of the two statements might be 
TSX 
BETA,4 
RTJ BETA 
CLA 
Q 
LDA Q 
STO 
P 
STA 
P 
in this case the routine BETA picks up the next two addresses, namely, P 
and Q, and uses these as arguments. This would produce two errors. The 
statement B = C in BETA would destroy P. The RETURN statement 
would be such that the two instructions corresponding to P = Q would be 
skipped. It is not certain that this is what would happen; the compiler 
might produce the following piece of code on the IBM 7090: 
SXA 
SAVE,4 
TSX 
BETA,4 
LXA 
SAVE,4 
CLA 
Q 
STO 
P 

226 
6 FORTRAN SUBROUTINES 
In this case A would be taken to be SAVE and B would be Q. Consider now 
the opposite kind of error 
CALL 
ΒΕΤΑ(Χ,Υ,Ζ) 
that is, the error of using too many arguments. Again the compiler would 
not detect that anything is wrong and it would produce 
TSX 
BETA,4 
RTJ 
BETA 
TSX 
X 
+ 
ZRO X 
TSX 
Y 
ZRO Y 
TSX 
Z 
ZRO Z 
Inside the routine BETA there would be no errors. The trouble would 
occur in Fortran II when the TRA 3,4 tried to do the RETURN. TRA 3,4 
jumps to the location that contains TSX Z: this latter instruction causes 
control to go to location Z. Since location Z probably contains a number, 
subsequent events are unpredictable, but the program will almost certainly 
fail. In Fortran 63 on the CDC 1604, ZRO Z is an illegal instruction and 
would cause the computer to stop. On the CDC 3600, for some values of 
Z, ZRO Z is a legal instruction and it may or may not cause an error in 
the program. For some values of Z, the instruction is illegal and it causes 
an interrupt. If the CDC 3600 is requested to perform an illegal instruction, 
it does not stop. Instead of stopping, it jumps into the monitor. The 
monitor then prints a message and terminates the job. 
Another type of error can be caused by the statement 
CALL 
BETA(4.25,1.0) 
This is compiled as 
TSX 
BETA,4 
RTJ 
BETA 
TSX 
=4.25 
ZRO 
-4.25 
TSX 
=1.0 
ZRO 
= 1 . 
Again the compiler proceeds without detecting any errors. The routine 
BETA is entered and A becomes the location that contains the number 4.25 
and B is the location that contains the number 1.0. The statement B = C 
sets B equal to the contents of C which in this case is 3.0. That is, the 
number 1.0 is destroyed and is replaced by the number 3.0. This has the 
curious consequence that a statement such as 
Y=1.0 
at any subsequent place in the calling program actually sets Y equal to 
3.0. This sort of odd behavior can be very difficult to trace unless you 
have some idea of the sort of quirks of which Fortran is capable. 

6 · 3 COMPILING SUBROUTINE A R G U M E N T S 
227 
Some of the above errors could be detected by the system. In 
Fortran IV a different calling sequence is used. The call to BETA actually 
produces the following : 
TSX 
BETA,4 
TXI 
* + 4„2 
ZRO 
ID„LK.DR 
ZRO X 
ZRO Y 
The return from the subroutine BETA is always TRA 1,4, independently 
of the number of arguments. The TRA 1,4 jumps to the TXI * + 4 which 
skips around the argument list. The TXI instruction is always correct since 
it is compiled at the same time as the argument list. A similar scheme is 
used in 3600 Fortran. This is a case where a slight inefficiency in the calling 
sequence can save some disastrous errors. One would hope that all future 
compilers would provide the same safeguard. A further safeguard can be 
provided by transmitting the number of arguments as part of the argument 
list. This is actually done in Fortran IV, in the decrement part of the 
TXI. The reason for using TXI in the calling sequence is that it provides a 
jump instruction and leaves space in the decrement to store the number of 
arguments. The next word in the sequence, namely, 
ZRO 
ID„LK.DR 
is useful whenever an error occurs in a Fortran subroutine. LK.DR is a 
location that is called the "linkage director"; it contains the name of the 
current subroutine and the location from which it was called. ID is the 
number of a Fortran statement. Consider, for example, the Fortran IV 
program discussed in Section 4.11. The Fortran statement 
104 
Y = (A+B)*SIN (A+B)/(P + SIN (A+B)) 
is at internal statement number 24. The call to the SIN routine in this 
statement will be 
TSX 
SIN,4 
TXI 
* + 3„1 
PZE 
24„LK.DR 
PZE 
N. 
Every routine has its own linkage director. For this program the linkage 
director is 
LK.DR 
PZE 
* * 
BCD 1TEST 

228 
6 FORTRAN SUBROUTINES 
because TEST in the name of the routine. When the routine is entered, there 
is an instruction that does 
SXA 
LK.DR,4 
so that the address part of the linkage director always contains the value 
of index register 4 on entry to the routine. If there happens to be an error 
in the value of N., then the SIN routine can print an appropriate diagnostic. 
Within the SIN routine, 
CAL 2,4 
puts 
PZE 
24„LK.DR 
into the accumulator; thus the SIN routine can find out that the call came 
from statement number 24 and it can find the address of the linkage 
director. From the linkage director it can find the name of the calling 
routine, and it can find the address of the call that called this routine. In 
this way it can find the information necessary to print the message : 
ERROR IN SUBROUTINE SIN 
CALLED FROM STATEMENT 24 IN TEST 
In this case TEST was the main program ; had it not been the main program, 
then SIN could have printed out which routine called TEST, and which 
routine called that routine, and so on. 
Another type of error is shown by 
CALL 
BETA(21, Y) 
The error in this case is that the compiler accepts 21 as a fixed-point 
number and the routine BETA thinks that the first argument is a floating-
point number. Again there is no check made. The routine uses floating-
point arithmetic on the number 21 and the results are somewhat unpre-
dictable. 
A full translation of the routine BETA is shown in Figure 6.1. The 
1604 program appears to be longer than the 7090 program, but it should 
be remembered that each instruction takes only half a word, compared 
with one instruction per word on the 7090. The code produced by the 
compilers differs from the above code in two respects. The compiler uses 
some symbols other than SV4, PI and so on; it generates some symbols 
that could not conflict with any of the symbols used by the Fortran 
program. The compiled program is slightly less efficient than the versions 
shown here. For example, Fortran II saves all the index registers even 
when they do not need to be saved. 

6 · 3 COMPILING SUBROUTINE ARGUMENTS 
229 
BETA 
P I 
. 2 
• 1 
P2 
C 
IBM 
CLA 
STA 
CLA 
STA 
CLA 
STO 
FSB 
TZE 
TMI 
CLA 
STO 
CLA 
STO 
TRA 
BSS 
END 
7 0 9 0 
l t 4 
P I 
2 t 4 
P2 
A 
C 
» 2 . 6 
. 1 
• 1 
» 5 . 0 
c 
c 
B 
3 » 4 
1 
BETA 
P I 
. 2 
. 1 
P2 
SV4 
E X I T . 
C 
CDC 
S L J 
S I U 
L I U 
LDA 
SAU 
ARS 
SAL 
I N I 
S I U 
LDA 
STA 
FSB 
AJP 
AJP 
LDA 
STA 
LDA 
STA 
E N I 
S L J 
BSS 
END 
1 6 0 4 
** 
S V 4 t 4 
B E T A . 4 
0 * 4 
P2 
2 4 
P I 
1 . 4 
E X I T . 
A 
C 
« 2 . 6 
. l . Z 
. l t M 
- 3 . 0 
C 
C 
B 
* * * 4 
»* 
1 
FIG. 6.1 Symbolic instructions for the routine BETA 
The argument to a subroutine can be any arithmetic expression; 
for example 
CALL BETA(X*X+66.3, Z) 
might be used. In this case the compiler computes the value of the expres-
sion and stores the result in some temporary location. The code produced 
is similar to the code produced by 
TEMP=X*X+66.3 
CALL BETA(TEMP, Z) 
except that the compiler does not use the symbol TEMP, but generates 
some none-Fortran symbol such as T..001, for use as a temporary storage 
location. 
It is permissible to use a vector quantity as the argument of a 
subroutine, for example, 
CALL 
BETA(P, Q(l + 6)) 
The compiler constructs the address of the location Q(I + 6) and stores it 
in the appropriate place in the parameter list. The coding might be as 
follows : 
IBM 7090 
CLS 
I 
ARS 
18 
TRA 
* + 2 
ZRO 
Q - 5 
ADD 
* - 1 
STA 
* + 3 
TSX 
BETA,4 
TSX 
P 
TSX 
* * 
+ 
+ 
CDC 1604 
ENI 
Q-5,1 
INI 
1,1 
SIL 
* + 2,1 
RTJ 
BETA 
ZRO P 
ZRO * * 

230 
6 FORTRAN SUBROUTINES 
In Fortran II, during the execution of the program, the machine picks up 
— I and adds Q —5. At this stage the accumulator contains Q —I —5, which 
is the address of Q(I + 6), and it stores this number in the calling sequence. 
Notice that we pick up the address Q, not the contents of location Q. This 
principle can be extended to arrays of two, three, or more dimensions. The 
compiler has to generate the instructions that compute the address of the 
argument. 
The principle of subroutine linkage in Fortran should now be 
clear. The calling program places the addresses of all the arguments into a 
list. The information in the list is the only information that is transmitted 
from the calling program into the subroutine. The calling program does 
not transmit any dimension information and it does not say whether an 
argument is a real number, an integer, or a complex number. 
6-4 
FUNCTION SUBROUTINES 
A function subroutine is a routine that may have one or more arguments 
but that has a single scalar result. The only difference between a function 
and an ordinary routine is that the result is returned through the accumu-
lator. This saves a small amount of time and sometimes makes for a simpler 
code. A statement such as 
X - ZETA(Y) 
is coded as 
IBM 7090 
CDC 1604 
TSX 
ZETA,4 
RTJ 
ZETA 
TSX 
Y 
+ 
ZRO Y 
STO 
X 
+ 
STA 
X 
that is, go to subroutine ZETA using the argument Y, on return from the 
subroutine put the contents of the accumulator in X. The subroutine ZETA 
is compiled in the normal way except that it places the value of ZETA into 
the accumulator immediately before returning. 
6"5 
DIMENSION STATEMENTS in SUBROUTINES 
In an earlier chapter we discussed the treatment of dimensioned variables. 
In this section we consider what happens when a dimensioned variable is 
one of the arguments of the subroutine. 
SUBROUTINE GAMMA(A,B) 
DIMENSION 
A(21 ),B(6,9),C(56) 
l = 4 
$ 
J = 2 
A(l + 9) = B(l,J) + C(l + 2) 
RETURN 
END 

6 · 5 DIMENSION STATEMENTS IN SUBROUTINES 
231 
The points that can be illustrated by this example are the following: A 
DIMENSION statement indicates that a certain amount of storage space 
must be reserved. This DIMENSION statement produces 
C 
BSS 
56 
which reserves 56 locations for C. No space is reserved for A and B. The 
addresses of these arrays are transmitted in the argument list. The storage 
space for the arrays A and B will have been allocated in the calling sub-
routine. The DIMENSION statement for B implies that B(I,J) is stored in 
location B + I— 1 + (J—1)*6. The coding for the second arithmetic state-
ment computes 6*(J— 1) + I— 1 and put the result in index register 1, and it 
puts I in index register 2, then 
CDC 
1604 
BSUB1 
LDA 
B,1 
FAD 
C + 1,2 
ASUB1 
STA 
A+8,2 
The coding for the Fortran II or Fortran IV compilers is similar to this, 
with the appropriate changes in sign to allow for the subtractive property 
of the 7090 index registers. The first part of the subroutine must pick up 
the address of A, add 8 to the address, and store the result in the address 
part of ASUB1 ; then it must pick up the address of B and store it in the 
address part of BSUB1. The address of A is acquired by the method 
described in Section 6.3. It is then only necessary to ADD = 8 before storing 
the result in the address part of ASUB1. It can be seen that this process can 
be applied to any dimensioned quantity. The address of the first element 
of an array is called the base address. Thus the base address of the array B 
is the address of B(l,l). The subroutine gets the base address of the array 
from the argument list supplied by the main program and it constructs the 
address of any element of the array by using the information given in the 
dimension statement. 
The information contained in DIMENSION A(21) states that A is 
a vector and that it occupies 21 locations. We will see that the second fact 
was not used. If A is a singly dimensioned variable that is an argument of 
the subroutine, then it does not matter what its dimension is. A DIMEN-
SION statement must be given because otherwise the compiler objects to 
the use of the subscript in A(I + 9) = ... The statement, DIMENSION 
B(6,9) shows that B is a two-dimensional variable and gives its dimensions. 
This DIMENSION statement implies that B(I,J) is stored in locations 
B + I— 1 +6*(J— 1). The number 6 is used by the subroutine, the number 
9 is not used. If a two-dimensional variable is an argument of the sub-
routine, then the first dimensional must be correct since it is used in 
finding the address of any element of the array, but the value of the second 

232 
6 FORTRAN SUBROUTINES 
dimension is immaterial. In the case of a three-dimensional variable, the 
first two dimensions must be correct, the value of the third dimension is 
immaterial. 
6-6 
VARIABLE DIMENSIONS 
The dimension of any array is specified in a DIMENSION statement. 
Fortran II requires that each dimension should be a constant. Fortran IV 
and Fortran 63 allow the dimension to be a variable. If any array has a 
variable dimension, then the array itself and the dimension must be one 
of the arguments of the subroutine. The compilers do not allow variable 
dimensions in a main program. As an example of an array with variable 
dimensions one might have the routine 
SUBROUTINE MATMPA(A,N,M,B,C,L) 
DIMENSION A(N,M), B(M,L), C(N,L) 
DO 
100 l = 1,N 
DO 
100J = 1,L 
SUM = 0. 
DO 
101 K = 1,M 
101 
SUM = SUM+A(I,K)*B(K,J) 
100 
C(I #J)=SUM 
END 
which will form the matrix product of A and B and put the result in C. It 
would be possible to write this routine in Fortran II but it would have to 
be done without using variable dimensions. In order to do this we will have 
to treat A,B, and C as vector quantities. It should be clear from what we 
have said about subroutines that one can use A as a matrix in the calling 
program, yet use A as a vector in the subroutine. The only information 
that is passed from the calling program to the subroutine is the base address 
of A,B, and C and the values of N,M, and L. The Fortran II program is 
SUBROUTINE MATMPB(A,N,M,B,C,L) 
DIMENSION A(2),B(2),C(2) 
DO 100 1 = 1,N 
K1=l 
K2 = 0 
DO 100 
J = 1,L 
K3=l 
SUM = 0. 
DO 101 K=1,M 
C 
K1=I + ( J - 1 ) * N , 
K 2 = ( J - 1 ) * M , 
K3 = I + (K-1)*N 
K4 = K2+K 
SUM = SUM + A(K3)*B(K4) 
101 
K3 = K3+N 
K2=K2+M 
C(K1) = SUM 
100 
K1=K1+N 
END 

6 - 7 THE SUBROUTINE PROLOGUE 
233 
Any program that can be written using variable-dimension statements can 
also be written without using variable dimensions. The advantage of the 
variable-dimension statement is that it saves the programmer a certain 
amount of work and may well help him to avoid mistakes. 
The compiling of subroutines with variable-dimension statements 
does not introduce any new principles. The compiler takes MATMPA 
and produces the auxiliary statements such as 
K 4 = ( J - 1 ) * M + K 
automatically. It also generates the code that picks up the addresses of 
L, M, and N and puts these addresses in the appropriate places in the 
assembled code. 
6-7 
THE SUBROUTINE PROLOGUE 
Consider the subroutine MATMPA. The first statement is 
DO 
100 
l = 1,N 
but this is not the first instruction to be obeyed when the subroutine is 
executed. When the subroutine is entered, the first few instructions save the 
values of the index registers; the next set of instructions pick up the address 
of A and store this address at every place where A is mentioned. This 
process has to be repeated for all the other arguments. The part of the 
subroutine that does this preliminary work is called the " prologue ". When 
all the instructions of the prologue have been obeyed, the instruction for 
the first Fortran executable statement will be obeyed. 
The length of the prologue depends on the number of arguments 
in the subroutine and on the number of times they are used. The prologue 
can sometimes be a very long piece of code, which uses up both memory 
space and time. There is one simple way of reducing the length of the 
prologue. Any scalar variable that is a parameter of the subroutine can 
be set equal to a local variable. A local variable is a variable that is stored 
within a subroutine; for example, the variable SUM is a local variable in 
the subroutine MATMPB. The variable M could be made local by 
SUBROUTINE 
MATMPB(A,N,MM,B,C,L) 
DIMENSION 
A(2),B(2),C(2) 
M = MM 
the rest of the subroutine being exactly as before. The single reference to 
MM requires one substitution in the prologue, compared with the two 
substitutions which we required previously. The difference between one and 
two references to M does not make it worthwhile to use this technique in 

234 
6 FORTRAN SUBROUTINES 
this particular example ; however, if a scalar variable is used more than three 
or four times in a subroutine, it is more efficient to replace that variable 
by a local variable. The same technique cannot be applied to arrays, unless 
the whole array is copied into a local array. 
6-8 
COMMON 
Variables can be shared between two or more subroutines if the variables 
are used as formal parameters or if the variables appear in COMMON. The 
advantage of transmitting the variables by way of the parameter list is that 
one can use different variables on different occasions. The statements 
CALL 
MATMPA(P,9,9,Q,S,K-5) 
CALL 
MATMPA(S,9,K-5,W,T,I-J) 
illustrate this point. In the first statement the subroutine MATMPA 
operates on the matrices P and Q and puts the result in S. In the second 
statement it operates on the matrices S and W and puts the result in T. The 
disadvantage of transmitting variables by the parameter list is that they may 
generate a very long prologue. In the case of COMMON variables the 
circumstances are reversed. The locations of the variables are fixed but the 
compiler does not generate any calling sequence. 
The compilation of COMMON statements is almost trivial. The 
compiler simply generates a series of statements to tell the assembler that 
certain variables are in COMMON. All the work connected with the 
common variables falls on the assembler and the loader. Fortran IV and 
Fortran 63 allow COMMON and DIMENSION statements to be made 
simultaneously. The Fortran II statements 
COMMON 
A,B,ALPHA,GAMMA,l,HOME,ZEE 
DIMENSION 
PQR(6,4),B(21 ),HOME(3,3,4),ZEE(21,1 5),MOP(45) 
can be compressed into 
COMMON 
A,B(21),ALPHA,GAMMA,l,HOME(3,3,4),ZEE(21,15) 
DIMENSION 
PQR(6,4),MOP(45) 
In Fortran 63 the COMMON statements would be translated into 
BLOCK 
COMMON 
COMMON 
COMMON 
COMMON 
COMMON 
COMMON 
COMMON 
376 
A(1) 
B(21) 
ALPHA(1) 
GAMMA(1) 
1(1) 
HOME(36) 
ZEE(315) 

6 · 8 COMMON 
235 
and a similar result would be true in Fortran II or Fortran IV. The assembler 
does two things with these statements. It keeps a track of the amount of 
space used in COMMON and it includes the information in the relocation 
information. 
There are several ways of specifying COMMON in the relocation 
information. A Fortran II relocatable instruction consists of three parts: 
the 36-bit instruction, the relocation bits for the address, and the relocation 
bits for the decrement. In the 36-bit instruction the operation part and the 
index part represent the machine-language instruction directly. The address 
(and the decrement, in the case of instructions that have a decrement) 
contain a temporary address that may be altered when the program comes 
to be loaded. Fortran II uses an origin of zero for program variables and 
counts forward; it uses an origin of 32561 for COMMON variables and 
counts backward. In the subroutine 
SUBROUTINE ALPHA(A) 
COMMON P,Q,I,S 
DIMENSION 
Q(20) 
B = A - S - Q ( 6 ) 
the allocation of addresses might be as follows : A would no address since 
it is a parameter; P would have the address 32561 ; Q would have 32560; I 
would have 32540; and S would have 32539. The subroutine would require 
about sixty instructions and the addresses in the program would run from 
0 to 59. B might have the address 54. The arithmetic statement would be 
translated into the following. 
Relocation bits 
Symbolic 
Octal 
instruction 
instruction 
Decrement 
Address 
CLA 
* * 
050000 0 00000 
0 
G 
FSB 
32539 
030200 0 77433 
0 
10 
FSB 
32554 
030200 0 77452 
0 
10 
STO 
54 
060100 0 00066 
0 
10 
The address itself is used to indicate which variables are in Common. If the 
relocation bits are 0, then there is no relocation. If the relocation bits are 
10, then the address may be relocated according to amount by which the 
program origin is moved, or it may be relocated according to Common. An 
address that is less than 60 (60 was the length of this particular routine) is a 
program address ; an address greater than 59 is the address of a Common 
variable. 

236 
6 FORTRAN 
SUBROUTINES 
6" 9 LABELED COMMON 
Fortran IV and Fortran 63 have introduced a new type of Common, 
namely, labeled or block Common. Each variable in Common is associated 
with a block name. In the statement 
COMMON 
A,UV(21),SOS/ABC/l,J(6,6)/IVY/W,M,NOG(9) 
the variables A, UV, and SOS are associated with the blank block name. I 
and J are associated with the block name ABC. W,M, and NOG are 
associated with the block name IVY. A block name may be any legitimate 
Fortran name or it may be blank. The blank name is a special case, intro-
duced to maintain compatibility with Fortran II. A Common statement 
consists of a block name enclosed between two slashes, followed by the list 
of the variables that belong to that block. Variables must not belong to 
more than one block. The Dimension information relevant to a variable 
may be declared in the Common statement or it may be declared in a 
Dimension statement. The effect of the block Common statement is as 
follows : If the above statement appeared in subroutine ONE, and if 
COMMON /IVY/ W,M,NOG(9) 
appeared in subroutine TWO, then the variables W,M and NOG would 
refer to the same location in subroutine ONE as in subroutine TWO. It is 
only necessary to declare those blocks which are actually used in the 
subroutine. Thus if the second routine uses NOG but does not use I and J 
(or to be exact, does not use the I and J which were used in subroutine 
ONE), then it is necessary to declare /IVY/ but it is not necessary to declare 
/ABC/ or blank Common. 
Block Common offers few advantages on small programs but it is 
invaluable on large programs, particularly when several programmers are 
working on different subroutines belonging to the same job. With the old 
Fortran II system it was necessary for each programmer to make sure that 
his Common statements did not conflict with everyone else's Common. 
With the new system it is only necessary to ensure that the block names do 
not conflict. It is also a simple matter to put extra variables in block 
Common, since a new block can be introduced into two or three of the 
subroutines without having to recompile all the other subroutines. 
Block Common statements in different subroutines need not use 
the same variables but they must have the same length. Thus in subroutine 
THREE it would be permissible to have 
COMMON /IVY/ XX(11) 
and XX(1) would be the same location as W, XX(2) would be the same as 
M and XX(3) would be the same as NOG(l). FIV has the restriction that a 

6 ■ 10 EXTERNAL SYMBOLS 
237 
block name must not be the same as the name of any subroutine. There is no 
conflict between the names of variables and the names of blocks ; thus 
COMMON IN 
BETA /GAMMA/ A(34),GAMMA 
is legitimate. 
6-10 
EXTERNAL SYMBOLS 
The use of external symbols can best be shown by means of an example. 
Suppose we wish to find X where, 
X=COSF(X*SQRTF(1.-A*A)) 
if A < 1 . 
X=COSH(X*SQRTF(A*A-1.)) 
if A > 1. 
We assume that a subroutine COSH exists which will compute the hyper-
bolic cosine. The problem could be coded as 
B = 1. - A*A 
IF (B) 2,1,1 
1 
X=COSF(X*SQRTF(B)) 
GO TO 3 
2 
X=COSH(X*SQRTF(-B)) 
3 
CONTINUE 
and this would be a quite satisfactory solution. An alternative solution in 
Fortran II is 
B = 1.-A*A 
IF (B) 
1,1,2 
1 
CALL 
SUBR(X,B,COSF) 
F 
COSF, COSH 
GO TO 3 
2 
CALL SUBR(X,-B,COSH) 
3 
CONTINUE 
where the subroutine SUBR is 
SUBROUTINE SUBR(X,B,FUNC) 
X=FUNC(X*SQRTF(B)) 
RETURN 
END 
The second method offers no advantages in this particular example, but if 
there was an extensive calculation in which the choice between COSF and 
COSH appeared many times, then it might be advantageous to use FUNC 
to denote the appropriate function. 

238 
6 FORTRAN SUBROUTINES 
The name of any subroutine is an example of an external symbol. 
In the example above COSF, COSH, SQRTF, and SUBR are external 
symbols. The statement CALL SUBR indicates that SUBR is an external 
symbol. The usage SQRTF(B) indicates that SQRTF is an external symbol. 
In the second routine given above, the fact that COSF and COSH are 
external symbols cannot be deduced from the context in which they are 
used. An external declaration has to be stated explicitly. This statement 
takes the form given above in Fortran II. In Fortran IV and Fortran 63 it 
takes the form 
EXTERNAL 
COSF,COSH 
that is the word EXTERNAL followed by a list of the external symbols. 
The statement 
CALL 
SUBR(X,B,COSH) 
is translated in the normal way. There is a jump to SUBR followed by a 
list containing the addresses of X, B, and the first location of COSH. 
Within the subroutine SUBR the statement 
X=FUNC(X*SQRTF(B)) 
translates into the appropriate arithmetic statements followed by 
IBM 
7090 
CDC 
1604 
TSX 
**,4 
RTJ 
* * 
TSX 
TEMP 
+ 
ZRO 
TEMP 
STO 
X 
STA 
X 
where ** denotes the address of FUNC, the actual address will be filled in 
by the prologue. 
6-11 
RELOCATION and the LOADER 
The compiler and the assembler produce a deck of binary cards. In some 
systems the user has an option by which he can suppress the punching of 
the cards. The assembler does still produce the binary card images, and it is 
these which are passed to the loader. The user option merely suppresses the 
final punching of the cards. In this section we will consider the information 
on these cards and the way in which it is used by the loader. 

6 · 11 RELOCATION AND THE LOADER 
239 
The subroutine shown in Figure 6.2 illustrates the different types 
of quantities that can be used in a Fortran program. The binary cards that 
are produced by the assembler differ quite radically from assembler to 
assembler. The Fortran 63 relocation system is more general than the 
Fortran II system and it is much less complicated than the Fortran IV 
system. The general principles of relocation and the loading process will 
be demonstrated using the Fortran 63 compiler and the corresponding 
loader. Part of the code produced by the Fortran 63 and the corresponding 
assembly listing is shown in Figure 6.3. The remaining part of the code need 
not concern us. It does not introduce any new principles. The location 
INITIAL., which is mentioned in location 374, denotes the start of the 
prologue. When the routine is entered the control goes to INITIAL., and 
after the initializing of the subroutine is completed, control returns to 
location 375. 
SUBROUTINE DELTA<C»B»I) 
DIMENSION C H O ) 
COMMON /PQR/ D(5).E /F/ TS /BLOCK2/ G»H(3) 
COMMON HASH(2CU12) »PI 
X»B+SINF<E>«-H(2)-»-HASH<2.<f >+H<3) 
Y»A+DU)-E*X 
$ CALL ΒΕΤΑ(Α·Υ) 
B«Y-TS/99«6+C<I>/X 
ENO 
FIG. 6.2 The subroutine DELTA 
The relocatable binary deck is divided into six parts. Part one 
contains the following information: The name of the subroutine, which in 
this case is DELTA; the fact that the routine occupies location 374 to 
435 octal; the fact that there is a common block named PQR of length 6, a 
block F of length 1, a block BLOCK2 of length 4, and a block with the 
name blank that has length 241 decimal. Part two of the binary deck con-
tains the instructions of the program and the location of each instruction ; 
thus location 374 contains the two instructions 75 0 00374 75 4 00412, 
location 375 contains the instructions 12 0 00005 75 4 00002, and so on. Part 
two of the deck also contains the relocation bits associated with each 
instruction. There are three relocation bits associated with each address. 
These bits indicate the following : 
000 
no relocation 
001 
relocate as a subroutine address 
010 
relocate as an address in the block PQR 
011 
relocate as an address in the block F 
100 
relocate as an address in the block BLOCK2 
101 
relocate as an address in blank Common 

240 
6 FORTRAN SUBROUTINES 
SUBROUTINE 
ENTRY POINTS 
FWA 
00374 
- 
LWA+1 
00435 
EXTERNAL SYMBOLS 
00000+ 
00000+ 
00005+ 
00006+ 
00006+ 
00007+ 
00007+ 
00010+ 
00013+ 
00013+ 
00373+ 
00374+ 
00375+ 
00376+ 
00377+ 
00400+ 
00401+ 
00402+ 
00403+ 
00404+ 
75 
75 
12 
75 
30 
30 
30 
30 
20 
12 
53 
30 
31 
30 
20 
75 
00 
00 
0 
4 
0 
• 
0 
0 
0 
0 
0 
0 
1 
1 
0 
0 
0 
4 
0 
0 
00001 
00002 
00003 
00374+ 
00374+ 
00412+ 
00005+ 
X00O02 
77777 
0001J·»· 
00110+ 
00012+ 
00433+ 
00431+ 
77777 
77776+ 
00005+ 
00433+ 
00432+ 
X00001 
00431+ 
00432+ 
BETA 
SINF 
080ENTRY 
POR 
F 
BL0CK2 
DELTA 
-
FPOOÖOl. 
FP00002. 
♦ 
-
BLOCK 
COMMON 
COMMON 
BLOCK 
COMMON 
BLOCK 
COMMON 
COMMON 
BLOCK 
COMMON 
COMMON 
ENTRY 
SLJ 
RTJ 
LDA 
RTJ 
FAD 
FAD 
FAD 
FAD 
STA 
LDA 
LIL 
FAD 
FSB 
FAD 
STA 
RTJ 
0 
0 
6 
D(5) 
E(l) 
1 
TS(l) 
4 
G(l) 
H(3) 
241 
HASH(240) 
P M 1 ) 
DELTA 
DELTA 
INITIAL. 
E 
SINF 
·* 
H+l 
MASH+61 
H+2 
«SX 
A 
1 *« 
1 D-l 
E 
X 
«SY 
BETA 
«SA 
«SY 
FIG. 6.3 Symbolic code for DELTA 
RANGE 
DELTA 
IDENT 
DELTA 
0 0 3 7 « 
DELTA 

6 · 11 RELOCATION AND THE LOADER 
241 
00405+ 
00406* 
00407* 
00410* 
13 
33 
30 
20 
12 
33 
30 
20 
0 
0 
0 
0 
1 
0 
0 
0 
00006* * 
00434* 
00432* 
00430* 
77777 FP00003. 
00433* 
00430* FP00004· 
77777 
FIG. 6.3 
{concluded) 
LAC 
FOV 
FAD 
STA 
LDA 
FDV 
FAD 
STA 
TS 
■02007616314631463 
Y 
•ERASER· 
1 ·* 
X 
•ERASER. 
·· 
The address parts of location 374 are DELTA and INITIAL. Both of these 
have the relocation bits 001. The next location has E with relocation bits 
010 and SINF with relocation 000. The next location has ** with relocation 
000 (actually it does not matter what the relocation is in this case, since ** 
will be overwritten by the prologue), and H + 1 with bits 100 and so on. 
Part three of the binary deck contains the entry point name. In 
this case the name is DELTA and the entry point is at 374. Part four of the 
deck contains the names of the external symbols; these are BETA and 
SINF. Part five of the deck contains a list of those addresses in which 
external symbols are used. In this case the list is 375— and 403 — . Part six 
of the deck is a single card that denotes that the end of the deck for this 
subroutine has been reached. When the program is finally in place in the 
memory, all the addresses in the program will have been changed. The 
relocation bits contain all the information on how the addresses must be 
changed. 
The CDC 1604 has a memory of 32,768 words. At the start of the 
loading process the memory contains, 
Location 
0 through 2799 
2800 
3800 
3800 
4300 
4301 
32300 
32301 
32767 
the monitor routines 
the loader 
list of library programs 
space into which subroutines can be loaded 
remaining portion of the monitor 
The locations mentioned are approximate and may be varied from time 
to time, but they are typical of the current system. Let us suppose that 
DELTA is the first program to be loaded. The lengths of the various 
portions of DELTA are block PQR has length 6, F has 1, BLOCK2 has 
4, blank common has 241 and the program itself has 435 — 374 octal, that 
is 41 octal or 33 decimal. The loader decides to put these portions into the 
following parts of the memory : 

242 
6 FORTRAN 
SUBROUTINES 
Location 
Subroutine instructions 
32268 to 32300 
Common block Block2 
32264 
32267 
Common block F 
32263 
32263 
Common block PQR 
32257 
32262 
Blank Common 
2800 
3040 
Notice that blank common will eventually overwrite the loader; for this 
reason it is not permitted to put data statements in blank common. By the 
time that blank Common is used, that is during the execution of the 
program, the loader will no longer be in use. The loader now computes the 
amount of relocation, with the result 
Relocation bits 
000 
001 
010 
011 
100 
101 
Relocate each address by 
0 
32016 
32257 
32257 
32257 
2789 
For example, the assembler placed the beginning of BLOCK2 at location 7. 
This is relocated by 32257 so it now begins at location 32264. The loader 
goes through the program changing the address parts of all the instructions. 
Thus in location 376 on the listing there is the address H + 1 which is 
translated as 11 octal, that is 9 decimal. This address has relocation bits 
100 so it will become 9 + 32257, that is 32266. 
The loader now reads the remaining parts of the binary deck. It 
notes that the entry point to subroutine DELTA is in location 32268, and 
it remembers this for future use. It notes that the address of BETA must be 
filled in a location 32275-. It finds that SINF is in the library and that it 
requires 30 locations. It decides that SINF will go in locations 32227 
through 32256. It puts 32256 in the address part of location 32269-. The 
SINF is not loaded from the library tape until later. The next subroutine is 
then loaded. If this subroutine uses common blocks F, BLOCK2, and 
XYZ, then space is allocated for the subroutine and for XYZ. The blocks 
F and BLOCK2 have already been allocated space and the correct cross 
referencing is made. 
It will be realized from this description that common blocks (other 
than blank common) are stored below the subroutine in which they are first 
mentioned. Common blocks in different subroutines must have the same 
length. This restriction does not apply to blank common; the loader puts 
the lower end of blank common at the location 2800, and the upper end 
can vary from subroutine to subroutine. 
The loading process stops if loading a routine would overwrite the 
loader itself; it also stops if the amount of space required by the sub-

6 ■ 11 RELOCATION A N D THE LOADER 
243 
routines plus the amount of space required in blank Common exceeds 
32767 — 2800. If the program is not too large, then the loader loads all 
the subroutines. It then checks to see that all external symbols either 
correspond to the name of a library routine or to the name of a routine 
that has already been loaded. If there are any subroutines missing, the 
loading stops. If all routines are present, the loader goes through the library 
tape picking off all the requested routines, and then finally goes to the first 
instruction of the loaded program. When execution has finished, the 
program should return control to the monitor. 
The Fortran II system does not allow block Common and is able 
to use a simple relocation scheme that was described in Section 6.8. In 
Fortran II the first program to be loaded goes into the lower end of the 
memory, starting at location 100. Common storage is allocated starting at 
location 32561 and going downwards. The loader looks at the address part 
of each instruction. The assembler has arranged things so that all common 
variables have a high address and all program variables have a low address. 
If an address needs relocating and it is a low address, then it is relocated as 
a program address; if it is a high address, it is relocated as a Common 
address. The Fortran II system also allows the relocation bits 11 that 
relocate high addresses as program and low addresses as Common. The 
relocation bits 11 are required in exceptional circumstances. 
The Fortran II system treats external symbols in the following 
way. All the external symbols are put at the front of the program; thus a 
subroutine that mentioned BETA, LOG, SIN, and DELTA would start off 
Location 
0 
BCD 
1BETA 
1 
BCD 
1LOG 
2 
BCD 
1 SIN 
3 
BCD 
1 DELTA 
A reference such as CALL DELTA would be translated into 
TSX 
3,4 
When the program is loaded, the loader replaces the BCD 1 DELTA by a 
jump to the subroutine DELTA; thus the CALL DELTA first jumps to 
the third location of the current subroutine, and then that instruction 
causes it to jump to DELTA. This list of symbols at the start of the program 
is referred to as a transfer vector. The advantage of a transfer vector is 
that it channels the reference to each external symbol through one location 
in each subroutine. During the loading process the loader has to remember 
the location and length of each transfer vector. It does not have to remember 
all the separate references to external symbols. The disadvantage of the 
transfer vector is that it wastes one instruction on each CALL. When all 
binary subroutines have been loaded, the Fortran II loader goes through 

244 
6 FORTRAN SUBROUTINES 
the transfer vector and starts to fill in the cross references. It stores the 
library routines at higher locations than all the loaded subroutines. 
6 Ί 2 
THE FORTRAN IV LOADER 
The binary cards produced by the Fortran IV compiler and by the Map 
assembler are loaded by a routine called IBLDR. This loader is more 
extensive than the Fortran 63 loader; however, many of the additional 
features are not of great benefit in Fortran programs. The IBLDR intro-
duces the concept of a control section. A control section is a set of instruc-
tions or data that occupy a contiguous set of locations in memory. This set 
of instructions is relocated as a single unit. A Common block is an example 
of a control section. Different Common blocks are relocated in different 
ways, but locations within one Common block are all relocated by the 
same amount. Another example of a control section is the instructions and 
local variables of a Fortran subroutine. It can be seen that the control 
section does not imply any radical change from the Fortran 63 method of 
subdividing the subroutine; nevertheless it is a useful generalization of the 
block concept. In Fortran 63 the whole of Common can be divided 
into a number of blocks. In the Fortran IV scheme a program can also 
be divided into a number of control sections. 
Every control section has a name. In the case of a Common 
block, the control section name is the same as the name of the Common 
block. Blank Common has the control section name //. In the case of a 
Fortran subroutine the name of the control section is the same as the name 
of the subroutine. Control sections names must be unique, hence a sub-
routine must not have the same name as any Common block. Block 
Common allows the programmer to reference one set of data from several 
different subroutines. The control section makes it possible for the Map 
programmer to reference one set of instructions from several different 
subroutines. This feature is not used in Fortran programs. 
During the assembly process, if the assembler finds any symbol 
that is not defined in the current routine then it treats that symbol as a 
virtual control section. An instruction such as TSX SIN,4 which refers to 
an external library subroutine, would generate a virtual control section. At 
load time, the loader would check to make sure that each virtual control 
section does correspond to a real control section of some other routine. 
The relocatable binary deck produced by Map consists of two 
main parts, namely, the control dictionary and the relocatable text. The 
control dictionary contains information on each control section within the 
routine. It gives the name of the control section in BCD, it gives the length 
(which is zero in the case of a virtual control section) and it gives the starting 
location of each section. The text part of the deck contains the relocatable 
instructions and the relocation information. Several different relocation 
schemes are used. Each address and each decrement has two relocation 
bits, where 00 denotes that there is to be no relocation, 01 denotes standard 

6 - 13 DATA STATEMENTS 
245 
relocation, 10 or 11 denote nonstandard relocation. Standard relocation 
uses the breakpoint method. We can illustrate this method in relation to 
the subroutine DELTA of Figure 6.2. The assembler computes addresses 
in the same way as the Fortran 63 assembler. Before relocation, addresses 
in the range 0 through 5 belong to the block PQR. Addresses in the range 
6 to 6 belong to the control section F. Similarly with the other addresses. 
The loader scans through the control dictionary and it builds up a table; 
addresses 0 through 5 octal belong to control section PQR 
... 
6 
6 
... 
F 
7 
12 
. . . 
BLOCK2 
. . . 
13 
373 
. . . 
// 
. . . 
374 
434 
. . . 
DELTA 
If the loader finds an instruction such as 
050000 0 00012 
and if the address has standard relocation, then the loader sees that this 
address is associated with BLOCK2 and it relocates it accordingly. The 
address is relocated by the amount BLOCK2 + 12 — 7. Nonstandard 
relocation has to be used in several circumstances. An instruction such as 
FAD D — 1,2 would generate the address 77777. An instruction such as 
FAD E + 3,2 would generate the address 10. In both of these cases the 
actual address lies outside the range of the control section and the standard 
method of relocation would give an erroneous result. Besides coping with 
these exceptional cases nonstandard relocation allows for the relocation of 
complex addresses such as occur in the instruction FAD 2*PQR — BLOCK2. 
Fortran does not generate addresses of this sort, but there are occasions in 
symbolic programming when such addresses are useful. We will not 
describe nonstandard relocation. We can see what sort of information has 
to be stored on the binary card and there are various ways to do this. 
The several parts of the IBJOB system do not appear to be well 
matched. MAP and IBLDR have many features that Fortran never uses. 
The IOEX system is well designed but the IOCS system of total control of 
the I/O seems to confuse the ingenuous and constrain the ingenious. The 
Fortran 63 system is much less sophisticated but it does tend to be more 
efficient, and it is easier for the programmer to direct the I/O operations. 
The Fortran 63 system has its own deficiencies, however. Fortran 63 
binary decks are not labeled. Fortran IV binary decks contain a label and 
sequence check that can easily be read by eye. Fortran 63 will not accept 
two decks having the same name. It sometimes even rejects a deck because 
it has the same name as a deck that is on the library tape. The diagnostics 
that Fortran 63 produces at execution time are not adequate even for 
experienced programmers. 
6-13 
DATA STATEMENTS 
In some subroutines it is necessary to store a number of constants. To give 
an example: Let us suppose the function A(X) takes on the values 

246 
6 FORTRAN SUBROUTINES 
1.375,2.482,3.195 at the points X = l.,2., and 3. At intermediate points the 
function can be found by linear interpolation. In practice the function 
might be represented by a table of twenty or thirty values. The routine 
might be written as follows : 
FUNCTION 
A(X) 
DIMENSION CA(3) 
DATA (CA= 1.375,2.482,3.195) 
Y=0 
IF( (X-1.)*(X-3.) ) 2,2,1 
1 
STOP 
2 
l = X 
Z=l 
A=CA(I + 1)*(X-Z) + CA(I)*(Z+1.-X) 
END 
The DATA statement stores the values of CA; it corresponds to the 
Fortran II statements 
CA(1) = 1.375 
CA(2) = 2.482 
CA(3)=3.195 
The DATA statement is compiled in the following way. The DIMENSION 
statement reserves a certain amount of storage space for the array CA thus : 
CA 
BSS 
3 
When the DATA statement is encountered it compiles as 
ORG 
CA 
DEC 
1.375,2.482,3.195 
There are two points to notice about this compilation. The space for the 
array CA is reserved by the DIMENSION statement. If the DATA state-
ment contains too many numbers, then these will possibly overwrite part 
of the program. The second point to notice is that the compiler does not 
check the mode of the entries. Since CA is a floating-point variable, each 
of the entries in the DATA statement must include a decimal point or else 
will be compiled in the wrong mode. 
The DATA statement offers several advantages compared to the 
Fortran II system of using an arithmetic expression to set a constant. It is 
more compact to write. It saves space and time. The DEC statement 
produced by the DATA statement takes effectively no memory space, since 
it occupies the space reserved for the array CA. The statements CA(1) = 
1.375, and so on, which would be necessary in Fortran II, would each 
occupy three locations; namely, a location for the instruction to pick up 
the constant, a location for the instruction to store it in the appropriate 

6 · 14 INDIRECT ADDRESSING 
247 
place in the array, and a location to store the constant itself. In addition 
to numbers, a DATA statement may contain Hollerith or Octal constants. 
A Hollerith constant is written nH followed by n characters ; for example, 
DATA(IW0RD = 3HABC,1 HP,5HALPHA) 
An octal constant is written as an integer followed by the letter B in 
Fortran 63 or the letter O in Fortran IV; for example, 
DATA(IN = 100B) 
sets IN to the value 100 octal, which is the same as 64 decimal. The DATA 
statements can be more elaborate than the one shown here, but since the 
form of the DATA statement differs in Fortran 63 and Fortran IV we will 
not go into the details. 
The contents of the DATA statement are stored as the program is 
loaded. If the program contains a statement that changes the value of a 
variable set by a DATA statement, then the DATA value is lost; it is not 
reset the next time the routine is entered. 
Data statements may be applied to variables that are in block 
Common. They cannot be applied to variables that are in ordinary Com-
mon. The reason for this is that the loader uses the space that Common 
is to use, and the loader must not be overwritten at load time. 
6-14 
INDIRECT ADDRESSING 
An address gives the location of a word. An indirect address gives the 
location of address, and this latter address gives the location of a word. On 
the IBM 7090, CLA 100 picks up the word in location 100 and places it in 
the accumulator. An indirect address is indicated by an * following the 
operation code. If the location 100 contains the integer 123, then CLA* 100 
has the same effect as CLA 123. Index registers can be used in computing an 
effective address. Given the instruction CLA* n\,n2 and that index register 
nl contains the number ^3, then this instruction has the same effect as 
CLA* n\ — «3. Suppose that location n\ — n3 contains CLA n4,n5 and 
suppose that index register n5 contains the integer «6, then CLA* nl,n2 
has the same effect as CLA n4 — ηβ. In computing the indirect address 
the computer looks at the address and index part of location nl — «3; the 
operation part of this location is not used, it may contain any operation 
whatsoever. An indirect address in the machine instruction is signaled by 
bits 12 and 13; thus 
CLA 
100 
is 
050000 
0 
00144 
CLA* 
100 
is 
050060 
0 
00144 

248 
6 FORTRAN SUBROUTINES 
Most of the operations involving data transfer (for example, CLA, LDQ, 
STO, FAD) can have an indirect address. Operations involving transfer 
from or to an index register (for example, LXA, AXT, SXA), cannot have 
an indirect address. 
The CDC 1604 has an indirect address facility. On the 1604 an 
indirect address is indicated by a 7 in the index part. Thus if location 100 
contains the integer 123, then LDA 100,7 has the same effect as LDA 123. 
There are differences between 7090 and 1604 indirect addressing. On the 
1604, since the index 7 signifies an indirect address, the indirect address 
cannot use an index register; that is, LDA 100,7 is similar to CLA* 100, but 
there is no 1604 code similar to CLA* 100,1. The location specified by the 
indirect address can contain an index part. On the 1604 if the lower half 
of location n\ contains LDA «2, «3, then LDA wl,7 has the same effect as 
LDA «2,«3 ; if «3 happens to be 7, then «2,«3 will itself be used as an 
indirect address or an indirect indirect indirect address ; and so on. This 
feature is not available on the IBM 7090; on that computer, addresses can 
be direct or indirect only. 
The use of an indirect address requires an extra reference to the 
memory. This increases the time required to execute the instruction. On 
the IBM 7090 the increase is one cycle time. A cycle time is 2.4 micro-
seconds. Thus, CLA takes two cycles; CLA* takes 3 cycles. FAD takes 
7 cycles, whereas FAD* takes 8 cycles. Indirect addressing would appear, at 
first sight, to be a very useful feature. However, it turns out that it is not 
greatly used. The Fortran compilers do not normally produce programs 
with indirect address, although the facility is sometimes used in library 
routines. 
Two applications of indirect addressing should indicate its power 
and its limitations. The statement CALL ALPHA(X) is compiled as 
IBM 7090 
CDC 1604 
TSX 
ALPHA,4 
RTJ 
ALPHA 
TSX 
X 
+ 
ZRO 
X 
On the 7090, the subroutine ALPHA can place X in the accumulator by 
means of the instruction CLA* 1,4. This represents a saving of two 
instructions compared with other methods of achieving the same result. On 
the 1604 there is no comparable code. The address X cannot be used 
indirectly because it is in the upper half of a word. The real limitations of 
indirect addressing become apparent in the following example: Suppose 
subroutine ALPHA contains the statement 
X(1)=X(1)+X(2)+X(3) 
Since X is an argument of the subroutine then the addresses of X(1),X(2), 

6 · 15 SUBROUTINES AND CONTROL SECTIONS IN IBM 360 
249 
and X(3) must be set by several statements in the prologue. We could 
shorten the prologue by the following means : Place the address of X in some 
location, let us denote the location by ADDRX, and then let all references 
to X be channeled through this location. Thus, in place of the CLA X plus 
the several prologue instructions required to set X, we would simply write 
CLA* ADDRX: On the CDC 1604 the corresponding instruction is 
LDA ADDRX,7. In the normal Fortran program X(2) can be refer-
enced by FAD X + 1 plus the prologue instructions required to set the 
address of X +1. However, the same effect cannot be achieved by 
FAD* ADDRX+1 (or, on the 1604, by FAD ADDRX+1,7) since this 
instruction picks up an address from ADDRX+1, whereas what is 
required is to pick up an address from ADDRX and to add one to it. 
6-15 
SUBROUTINES and CONTROL SECTIONS in the IBM 360 
The 360 instruction Branch and Link can be used to enter and return from 
a subroutine. For example, 
EXTRN 
SINE 
BAL 
1,SINE 
In EXTRN pseudo-operation specifies that SINE is an external symbol. 
BAL causes the machine to store the current address plus 4 (the BAL 
instruction is 4 bytes long) in register 1 and then transfer to location SINE. 
The SINE routine can return to this program simply by 
BCR 
15,1 
The branch on condition instruction has the general form 
BCR 
M,R 
The machine branches to the address specified in register R if the condition 
bits corresponding to the word M are on. When M is 1111 binary, which is 
15 decimal, then the branch is always taken. 
BCR 
15,1 
branches to the address specified by register Rl and this address jumps 
back to the correct place in the main program. An alternative method of 
entering the SINE subroutine is 
L 
2,VSINE 
BALR 
1,2 
VSINE 
DC 
V(SINE) 

250 
6 FORTRAN SUBROUTINES 
The load instruction puts the address of the SINE routine in register 2. The 
BALR stores the return address in register 1 and jumps to the address 
specified by register 2. The DC pseudo-operation was described in Section 
3.10. It stands for define constant. V means that the constant to be defined 
is the address of an external symbol. If there are several jumps to one 
external routine, then this use of BALR saves space because the BALR 
instruction is 2 bytes long, whereas BAL is 4 bytes. 
The 360 assembler uses the control section concept that was 
introduced in the MAP assembler on the 7090. A control section is any set 
of instructions or data which is to be relocated as a single unit. The pseudo-
operation 
ALPHA 
CSECT 
indicates that the instructions that follow belong to the control section with 
the name ALPHA. The pseudo-operation DSECT stands for dummy 
control section. This is a control section that will be defined in some other 
routine but will be referred to in this routine. The CSECT and DSECT 
pseudo-operations apply to the instructions following them 
ALPHA 
CSECT 
11 
BETA 
DSECT 
I2 
ALPHA 
CSECT 
I3 
GAMMA 
CSECT 
I4 
Let II, 12, 13, and 14 stand for one or more symbolic instructions; then II 
and 13 belong to control section ALPHA, 12 belongs to BETA, and 14 
belongs to GAMMA. If a section name appears more than once, the 
assembler collects together instructions that belong to the same section. The 
instruction 13 goes at the end of the instruction II. Il, 13 constitutes 
the single control section with the name ALPHA. The program could have 
been written 
ALPHA 
CSECT 
11 
I3 
BETA 
DSECT 
I2 
GAMMA 
DSECT 
I4 
and the result would be exactly the same, but the programmer sometimes 
finds it useful to mix instructions from several control sections. 

6 · 15 S U B R O U T I N E S A N D C O N T R O L S E C T I O N S IN I B M 360 
251 
A Fortran Common block is an example of a control section. The 
subroutine shown in Figure 6.2 could be translated into the IBM 360 
symbolic code shown in Figure 6.4. In the Figure we have omitted the 
instructions that might be necessary to save the contents of registers 11 
through 15 and we assume that the address of B will be found in register 2. 
COM is the pseudo-operation that is used for the blank Common control 
section. The above example illustrates some of the power and the limita-
tions of the addressing system of the IBM 360. The address of each control 
section must be placed in a register. Once this has been done, then all 
addresses are quite short; they consist of the four bits that specify the base 
register and the 12 bits of the displacement. All references to external 
PQR 
D 
E 
F 
TS 
BLOCK2 
G 
H 
HASH 
PI 
DELTA 
DSECT 
DS 
DS 
DSECT 
DS 
DSECT 
DS 
DS 
COM 
DS 
DS 
CSECT 
ENTRY 
BALR 
USING 
BAL ' 
LM 
USING 
USING 
USING 
USING 
LE 
AE 
AE 
AE 
AE 
STE 
5E 
E 
E 
E 
3E 
2A0E 
E 
DELTA 
15·0 
*tl5 
14.INITIAL 
U»14»*A(D»TS.G»HASH> 
D.ll 
TS.12 
G.13 
HASH«14 
0»E 
0.2 
0»H*4 
0»HASH«-244 
O.H-l-8 
O.X 
FIG. 6.4 
IBM 360 instructions for the routine DELTA 
control sections are channeled through these base address registers. Very 
few of the instructions in the subroutines will need relocating. In general, if 
there are n control sections referred to in the routine, then only n relocatable 
addresses are needed. On an ordinary machine such as the IBM 7090 or 
CDC 3600, almost every address in a routine needs to be relocated. There 
are two drawbacks to the 360 scheme. A displacement is limited to 4096 
bytes which is only 1024 words. Large control sections require several base 
address registers. The second difficulty lies in the small number of registers. 
Only sixteen registers are available for indexing, integer arithmetic, and 
base addressing. In any large assembly-language program or in programs 
produced by an assembler, it will be difficult to avoid the continual setting 
and resetting of registers. However, we shall see in Section 9.3 that there 
are a number of new and powerful methods of using memory. With these 
new methods the setting and resetting of registers is no longer peculiar to 
the IBM 360, it becomes necessary on all machines. 

252 
6 FORTRAN SUBROUTINES 
PROBLEMS 
1 ■ In a statement such as 
CALL SUBA (B,C(I), 2.25, X**2 +6.0) 
what information is transmitted to subroutine SUBA ? Suppose SUBA 
begins 
SUBROUTINE SUBA (l,B,D,E) 
DIMENSION E(3) 
1 
B = l 
2 
D = E(2) 
3 
E(1)=6.2 
How many errors have been made ? State precisely what the effect of 
these errors will be. Will the compiler detect any of the errors ? Could a 
compiler be made to detect this type of error ? If so how could it be 
done? 
2 ■ Take the subroutine 
SUBROUTINE ADD (A,B,C,L,M) 
DIMENSION A(L,M),B(L,M),C(L,M) 
DO 100 1 = 1,L 
DO 100 J = 1,M 
100 
C (l,J)=A(l,J) + B(l,J) 
END 
and rewrite it in a form that uses only single subscripts. What are 
the advantages of this rewrite ? 
3 ■ In what circumstances is it necessary to give an EXTERNAL declara-
tion? 
4 ■ The binary deck of a program contains much less information than the 
original program. For example, the variable E of subroutine DELTA 
(Figure 6.2) is represented as the sixth location of block PQR: the 
name " E " is not retained. Describe all the information that is in the 
binary deck. Do not describe the minutae of a particular loader, just 
state the general principles. 
5 ■ What are the relocation bits for the instructions in locations 401 
through 404 of Figure 6.3 ? What are the final octal machine-language 
instructions ? At what point does the address part of 
FP000020 
LIL 
1 
* * 
receive an absolute value ? 
6 ■ Why must all Common blocks with the same name have the same 
length ? By changing the loader and by losing some efficiency, do you 
think this rule could be relaxed ? If so, how would it be done ? Can 
blank Common blocks vary in size, and if so how is the loading of 
blank Common different to that of labeled Common ? 

PROBLEMS 
253 
7 ■ Some operating systems, such as Fortran IV under IBSYS and 3600 
Fortran under Scope, provide a diagnostic trace when errors occur. 
They print such information as " Error in SQRT, which was called from 
statement 6 in subroutine ALPHA, which was called from statement 
100 in MAIN." Where and how does the system find this information ? 
You will need to consider the meaning of 
ZRO ID„LK.DR 
of Section 6.3 and to work out how it could be used. 
8 ■ What is the breakpoint method of indicating relocation ? What are the 
advantages and disadvantages of the method ? If there are a large 
number of control sections, will it take less space (on the binary card) 
than the Fortran 63 method ? Since each loading process requires the 
relocation of many addresses, it is important to have an efficient 
process. Which process leads to a more efficient loader? 
9 ■ Write a loader. Assume that the instructions and the relocation 
information are specified in the way described in Section 6.10. Simplify 
the problem by adopting a simple format for the information. We 
suggest that the information be recorded on tape and read by 
READ (8) N,I,J,(L(K),K=1,N) 
If I = 1, then the record gives the names and lengths of the subroutine 
and its common blocks. L(l) gives the name of the routine in A8 
format. L(2) gives its length. L(3) gives the name of the first Common 
block and L(4) gives it length, and so on. J gives the location of the 
entry point. If I is 2, then the record contains instructions and reloca-
tion information. L(l), L(2), ... contain the instructions L(J) contains 
the relocation information in the form II + 12*2**18 where II gives 
the relocation information for the first half of L(l) and 12 relates to the 
second half of L(l). L(J + 1) gives the relocation information for L(2), 
and so on. If I is 3, then L(l), L(2), ... contains the names of the 
external symbols and L(J), L(J 4- 1), ... gives the locations where they 
are used. 
10 ■ The program of the preceding problem is inefficient since it may load 
a large number of empty locations. For example, the program to be 
loaded might consist of some instructions followed by BSS 500 
followed by more instructions. Suggest some way of dealing with this 
inefficiency. 
1 1 " The base address plus displacement feature of the IBM 360 makes it 
easy to write programs that do not need relocation. Explain why the 
instruction AE O, H + 4 of Figure 6.4 does not need relocation whereas 
the corresponding instruction namely FAD H + 1 on the CDC 1604 
does need relocation. What addresses in Figure 6.4 will need to be 
changed at load time ? 

7-1 
INTRODUCTION 
7 
CHARACTER 
MANIPULATION 
The Fortran language is primarily con-
cerned with numerical calculations. The 
computer can be used for nonnumerical 
processes such as compiling, sorting, con-
verting from binary to BCD, and so on. In 
this chapter we examine some of the basic 
operations of bit manipulation and charac-
ter manipulation, we show how these 
operations can be expressed in the Fortran 
language, and we go on to write Fortran 
programs for such tasks as the input and 
output of alphanumeric data and the 
assembly of symbolic instructions into 
machine language. The manipulation of 
lists is deferred to a later chapter (see Sec-
tion 9.6). 
I 
I 
I 
I 
I 
II 
7-2 
TRANSLATING BCD into BINARY 
Let us suppose that a quantity of data is 
punched on cards. Let the first two cards 
contain 
b126b327.02b - 9217bb3091 b 
bALPHAb68.27.6*X-Y 
where b denotes the blank or space charac-
ter. The cards can be read directly into 
memory or they might first be transferred 
to magnetic tape. On tape there would be 
one logical record per card; the first card 
would be represented by 
200102062003020773120220401102 
010720200312110120 
254 
according to the octal representation of 
external BCD code shown in Table 5.2. The 
tape would later be read into memory. In 
the CDC 1604 there are eight characters in 
each word of memory, as shown in Figure 
7.1. In the IBM 7090 there are six characters 
in each word using internal BCD code as 

7 · 2 TRANSLATING BCD INTO BINARY 
255 
2001020620030207 
7312022040110201 
0720200312110120 
FIG. 7.1 
Representation of the first card in the memory of the CDC 1604 
shown in Figure 7.2. A full card of 80 columns generates a record of 80 
characters. In our example the last 56 characters are blank characters and 
we will ignore them in this discussion. The representation of one card 
inside the memory is called a "card image". The card image is always in 
the same BCD form irrespective of whether it came into memory directly 
from the card or by way of a tape or disk. Card images that come in via a 
tape or disk are in BCD card image form. On the 7090 the card reader 
happens to read cards by rows rather than by columns and the BCD image 
600102066003 
020733000260 
401102010760 
600300110160 
FIG. 7.2 Representation of the first card in the memory of the IBM 7090 
is not produced directly, but the software converts the row image to a 
standard BCD card image form before any other processing is done. Data 
that has been punched on paper tape or that has been typed from an on-line 
typewriter, or has been produced by any other device, arrives in the 
memory as a string of BCD characters. In some small machines the 
characters from paper tape or typewriter are brought in one at a time. This 
does not change the techniques for processing the characters in any 
essential respect. In a large machine these character-by-character devices 
are usually buffered so that the CPU program can operate on a whole line 
of characters at one time. Each card contains exactly 80 characters. A 
punched paper tape can contain any number of characters but it is usually 
divided into short blocks by the carriage return character. If the tape is 
printed, this character causes the next character to appear at the beginning 
of a line so in this respect it corresponds to the end of a card. If the tape 
does not contain carriage return characters, it is still necessary to process 
one block of characters at one time. The size of the block depends on the 
buffer size. 
Card images can be read in Fortran by use of the formatted read 
statement. Suppose the card image is on the standard input unit, then it 
might be read by 
READ 
500, K, X, J1, J2 
500 
FORMAT 
(I4, F7.2, I6, I7) 
The READ statement causes a jump to a subroutine. This subroutine 
operates in two stages. In stage one it reads the card image from the 
standard input unit and stores the result in the form shown in Figure 7.1 

256 
7 CHARACTER 
MANIPULATION 
for the 1604 or Figure 7.2 for the 7090. In stage two it looks at the format 
and makes a transformation of the data. 14 tells the read routine to convert 
the first four characters into a binary integer, with the result: 
Fortran II 
00017600000 octal 
Fortran 63 or Fortran IV 
176 octal 
Had an F4 format been used then the result would have been 
Fortran II or Fortran IV 
207770000000 octal 
Fortran 63 
200777000000000 octal 
An O format indicates that the data should be interpreted as an octal 
number. The 04 format when used on the characters bl26 produces 
Fortran IV 
000000000126 
Fortran 63 
0000000000000126 
The A format is used to read alphanumeric characters. It reads the 
characters and leaves them unchanged, except that if there are fewer than 
6 characters (8 on the 1604), the characters are put at the left-hand end of 
the word and blanks are filled in from the right. Thus the A4 format used 
with bl26 gives, 
Fortran II or Fortran IV 
600102066060 
Fortran 63 
2001020620202020 
We can see that the first character on the card was a blank and this blank 
appears at the left-hand end of the word in the memory : blanks are not 
omitted in the A type format. The A6 format in Fortran IV and the A8 
format in Fortran 63 leave the character string unchanged. Using these 
formats on the first card gives 
Fortran II or Fortran IV 600102066003 
Fortran 63 
2001020620030207 
Fortran 63 (but not Fortran IV) has an R-type format in addition to the 
A type. The R type is similar to A except that it puts characters at the 
right-hand end of the word and fills the left-hand end with zeros; thus R4 
used on the characters bl26 produces 
Fortran 63 
00000000000020010206 
While discussing these formats it is relevant to mention alpha-
numeric constants. Fortran 63 allows arithmetic statements of the form 
K =4RABCD 

7 · 2 TRANSLATING BCD INTO BINARY 
257 
which would set K equal to 61626364 octal. It allows 
K =4HABCD 
which would set K equal to 6162636420202020 octal. All of the compilers 
accept H-type arguments to a subroutine; for example, 
CALL 
SUBD(6H ALPHA,1.25) 
The compiler stores the string bALPHA in some location and puts the 
address of that location in the argument list. When used in this way, the 
argument may include up to 120 characters. For example, 
CALL SUBA(18H ALPHA EQUALS BETA,1.25) 
The compiler stores the string of characters in an array and puts the 
address of the first element of the array into the calling sequence. Both the 
Fortran 63 and Fortran IV compilers allow H-type constants in Data 
statements. Some Fortran compilers do not allow H-type constants; thus 
K = 4 HABCD is illegal in Fortran IV but the same eifect can be achieved 
by K = NHOLL (4HABCD) where NHOLL is a function routine 
FUNCTION NHOLL(I) 
NHOLL = l 
END 
Now let us consider how the READ statement does the transla-
tion of the characters that it had read in. Suppose the first word of the first 
record is read into location NB and suppose the format is 14. The read 
routine could pick up the first character by the following sequence of 
machine language instructions, 
IBM 
7090 
CDC. 1604 
ZAC 
ENA 
0 
LDQ 
NB 
LDQ 
NB 
LGL 
6 
LLS 
6 
STO 
NC 
STA 
NC 
These instructions set the accumulator to zero, they put the contents of NB 
into the MQ, they shift the accumulator and MQ six positions to the 
left, and then they store the result in NC. On the 7090, NC contains 60 
octal; on the 1604 it contains 20 octal. Another way of saying this is that 
NC equals lRb. The next character can be picked up by setting the 
accumulator to zero and doing another LLS 6. If this process is repeated 
and the results put into the array NC, the end product is 
NC(1) =1Rb, NC(2) = 1R1, NC(3) = 1 R2, NC(4) = 1 R6 

258 
7 CHARACTER 
MANIPULATION 
The translation according to the 14 format can be achieved by the state-
ments shown in Figure 7.3. The significance of the equals zero branch at 
statement 101 is that the BCD code for the character zero on the 1604 is 12 
octal or 10 decimal. 
NSIGN = 1 $ N = 0 $ DO 100 1=1,4 
1F(NC(I)-1R ) 101,102,101 
101 
1F(NC(I)-10) 103,102,109 
102 
NC(l) = 0 
103 
N = N*10+NC(I) $ GO TO 100 
109 
1F( N C ( I ) - 1 R - ) 111,110,111 
110 
NSIGN = - 1 
$ GO TO 100 
111 
1F(NC(I)-1R + ) 112,100,112 
112 
PRINT 113,NC(I) $ STOP 
113 
FORMAT(19H ILLEGAL CHARACTER 02) 
100 
CONTINUE 
N=N*NSIGN 
FIG. 7.3 
Conversion of four characters into one binary integer 
Numbers that are to be read in any other format are processed in 
a similar fashion. In the case of an F format the number is read as an 
integer but the number of characters after the decimal point are counted. 
At the end of the scan of the characters b327.02, the routine finds that 
N = 32702 
NP=number of characters after the point = 2 
The final form of the number can be found by 
XN = N 
XN = XN/10.**NP 
An example of a full READ statement is 
READ(7,500)N,A(N),J,K 
500 
F0RMAT(I4,F7.2,2I6) 
The Fortran II compiler uses READ INPUT TAPE 7,500 in place of the 
READ (7,500). The READ statement follows the three stages described in 
connection with WRITEB (see Section 5.10). There is an initiative stage 
which reads the record as a string of BCD characters. There is the data 
transmission stage: each time a number is required, the read routine is 
entered. There is a finishing stage which completes any outstanding 
operations. During the transmission stage the read routine scans the format 
statement. It discovers which format is needed, it translates the required 
characters from the input buffer into binary, and it returns to the main 
program. If a / is encountered in the format scan, then the read routine 
ignores the rest of the current record and reads in the next record. If 
) is encountered, then it goes back in the format statement to the previous (. 

7 - 3 LOGICAL OPERATIONS IN FORTRAN 
259 
The format statement itself is scanned in the same way as any 
other string of characters. The format is stored in the memory in BCD 
form. The format statement 500 given above would be stored as 
Fortran II or Fortran IV 743104732607 330273023134 
Fortran 63 
3471043366077302 3302717460606060 
The read routine picks up one character at a time by putting the appropriate 
word of the format statement in the MQ and shifting six bits into the 
accumulator. 
7-3 
LOGICAL OPERATIONS in FORTRAN 
In the previous section it was necessary to take a string of characters and 
to rearrange them. This sort of manipulation can be done in the Fortran 
language. The first character of a word can be found in the following way. 
Suppose that 
Fortran IV 
Fortran 63 
N B - 600102011003 
N B = 2001000620030207 
then 
NC=NB/2**30 
NC=NB/2**42 
produces 
NC = 400000000020 
NC=20 octal 
The Fortran IV result is not in the right form. The difficulty arises because 
the sign bit stays at the left-hand end of the word. The matter can be put 
right by the sequence 
NC=NB/2**30 
IF(NC) 100,100,101 
100 
NC = 3 2 - N C 
101 
CONTINUE 
In order to pick up the next character of the input record it is necessary 
to use some further features of the compiler. 
The Fortran 63 compiler allows octal constants. An octal constant 
is written in the same way as an integer constant, except that it is terminated 
by the letter B; B stands for Boolean, although a more logical choice would 
have been O for octal. The statement I = 100 sets I equal to 100 decimal 
which is 144 octal; I = 100B sets I equal to 100 octal which is 64 decimal. 

260 
7 CHARACTER 
MANIPULATION 
The Fortran 63 compiler has three logical operators. Logical operators can 
be used with integer or logical variables. 
I = J.AND.K 
sets I equal to the logical product of J and K. Logical operators were 
discussed in Section 4.6. The logical operations described here apply the 
logical function to each bit of the 48-bit words. A logical product is such 
that the nth bit of I is a 1 if both the nth bit of J and the nth bit of K 
are 1. If 
J = 10010011 binary 
and 
K=11001010 
then 
1-10000010 
The statement 
L=J.OR.K 
sets L equal to the logical sum of J and K. The nth bit of L is 1 if either the 
nth bit of J or the /7th bit of K is 1, or if both are 1. If J and K have the 
values given previously, then 
L= 11011011 binary 
The logical operator .NOT. operates on a word and changes all the binary 
ones into zeros and the zeros into ones. If 
N-.NOT.L 
then 
N = 111111111111111111111111111111111111111100100100 
In terms of the octal notation if 
J = 223B 
and 
K-312B 
then 
l=J.AND.K=202B 
L = J.OR.K=333B 
N = .NOT.L=7777777777777444B 

7 - 3 LOGICAL OPERATIONS IN FORTRAN 
261 
In Fortran 63 we can pick up the second character of the word NC by 
NC=NB/2**36 
which sets NC equal to 200IB and then 
NC=NC.AND.77B 
which erases all but the last two octal digits to give 01B. It is obvious that 
all the characters in a word can be obtained by this process; namely, we 
can use 2 raised to the appropriate power to bring the required character 
to the right-hand end of the word and then use the .AND.77B to erase the 
unwanted characters. In the first example given above, we did not use the 
AND process because it was unnecessary. In general, it should be used, as 
the following example will show. Let us suppose that 
N B = 6001000620030207 B 
then 
NC=NB/2**42 
sets 
NC = 7777777777777760B 
The reason for this is that NB is a negative number in this case, and 
division by a power of 2 produces another negative number. If we now set 
NC-NC.AND.77B 
then 
NC = 60B 
which is the required result. 
The Fortran II compiler allows the logical operations described 
above, but the logical statements take on a different form. A logical or, as 
it is sometimes called, a Boolean statement is indicated by putting a B in 
column one of the Fortran statement. On a card of this type the operator 
.* does not denote multiplication, it means .AND. The operator + stands 
for .OR. and the unary operator — stands for .NOT. Any constants that 
appear on the card are treated as octal constants. Variables that are used 
in Boolean statements must have floating-point names. Difficulty arises in 
trying to shift numbers by using the division or multiplication instruction. 
A statement such as 
XNB = XNB/2.**30 

262 
7 CHARACTER 
MANIPULATION 
does not work since it performs a floating-point division. Neither is it 
possible to work in integer arithmetic since integer constants are restricted 
to the range 0 to 2**17. The only satisfactory solution is to write a Fap 
routine to do the shifting .The function routine 
RS 
CLA* 
2,4 
ARS 
18 
STA 
* + 2 
CAL* 
1,4 
ARS 
* * 
TRA 
3,4 
can be called by the Fortran statement, 
B = RS(A,N) 
It shifts the number A, N places to the right. The second character of the 
word NB can be picked out by 
XNC=RS(NB,24) 
B 
XNC=XNC*77 
The other characters can be found by a similar process. 
The Fortran IV compiler has variables of the type logical. It has 
the logical operators .AND.,.OR., and .NOT., but unfortunately it does not 
allow them to be used for character manipulation. The Fortran IV logical 
variables consist of a single binary digit. Logical operators can only be used 
with logical variables; they cannot be used with integers. On most Fortran 
IV library tapes the library functions AND, OR, and NOT will be found. 
They accomplish the same purpose as the equivalent Fortran 63 or Fortran 
II operations—they operate on a full word. Octal constants are not 
allowed in arithmetic statements (the equivalent decimal integer has to be 
used) but they are allowed in Data statements. 
In describing character manipulation we have made use of state-
ments such as 
NC=NB/2**42 
This is a convenient notation but it is not efficient. The statement could be 
written 
NC= NB/100000000000000 B 
This is preferable since it avoids the necessity for computing 2**42; with 
most compilers a constant such as 2**42 is evaluated at execution time by 
the wasteful process of calling in a subroutine. Even this latter form of 
the statement is not efficient. What we are really trying to do is to shift NB 

7 · 4 CHARACTER MANIPULATION WITH R1 FORMAT 
263 
right by 42 places. The machine instruction ARS is usually faster than the 
division instruction. On the CDC 3600 ARS takes 1.25 microseconds and 
DVI takes 14.9 microseconds. On some library tapes a Fortran function 
for shifting may be available. The Fortran function is not necessarily faster 
than a divide operation because of the time it takes to enter and return from 
the subroutine. In other words, division is much slower than shifting but 
there is no direct implementation of shifting in Fortran. 
We will make use of the Fortran 63 octal constants and the 
.OR., .AND., and .NOT. operations. In Fortran compilers for which these 
operations do not exist, it is a simple matter to write an assembly-language 
function routine to perform the same operation. 
7-4 
CHARACTER MANIPULATION with R1 FORMAT 
There are several other ways of manipulating characters. One of these ways 
is to use the standard input routine to break a string of characters into a 
string of words containing one character each. This can be done by using 
the Rl format. We will illustrate this method by considering a character 
manipulation problem. The problem is—given a Fortran program that 
uses the Fortran 63 convention of writing several statements per card—to 
produce a Fortran program having only one statement per card. The 
program in Figure 7.4 will work in the Fortran 63 system. The programs 
PROGRAM MAIN 
DIMENSION L(84).LL<84> 
DO 99 J»lt72 
99 
LL(J)=1R 
3 
READ 500.(L( I),1 = 1 ,80) 
500 
FORMAT(80Rl) 
IF(LU).NE.1R») GO TO 2 
C 
READ TITLE CARD 
C 
A TITLE CARD HAS JUST BEEN READ 
1 
NN= ( <64«L<2)+L<3) )*64+L(4) >*64+L<5> 
PRINT 510 
510 
FORMATUHl) 
KARD=10 $ GO TO 3 
2 
J1«0 $1=1 
102 
J1=J1+1 $ IF(L< D.NE.1RS) GO TO 100 
C 
SEARCH FOR LEADING BLANKS 
101 
DO 120 J-7.72 
$ IF(LL(J).NE.1R ) GO TO 121 
120 
CONTINUE 
121 
IF(J.EQ.7) GO TO 122 
C 
ELIMINATE LEADING BLANKS 
123 
DO 129 11=7.72 
IF(J.LE.72> GO TO 125 
C 
FILL IN TRAILING BLANKS 
124 
LL<II)»1R 
$GO TO 129 
125 
LL(II)«LL(J) 
129 
J»J+1 
122 
PRINT 
501.<LL<ΙΙ)·ΙΙ=1.72).NN.KARD 
PUNCH 
511»(LL<II)»ΙΙ«1·72>.NN»KARD 
501 
F0RMAT(X72R1»R4.I4) 
511 
FORMATi 72RltR4tI4) 
KARD=KARD+10 
S 
DO 110 J2=l·Jl 
110 
LL(J2)«1R 
S Jl«6 
SGO TO 104 
100 
LL(J1)=L(I) 
104 
1=1+1 $ IF(I-73) 
102·101.3 
END 
FIG. 7.4 
Program to translate several statements per card to one statement per card 

264 
7 CHARACTER 
MANIPULATION 
that are to be processed are presented as data on the standard input tape. 
Each subroutine to be processed is preceded by a card with an * in Column 
1 and the name of the subroutine (or some convenient abbreviation of the 
name) in Columns 2 through 5. This name will be used to label the cards 
which are output. The routine reads the characters into the array L. If the 
card contains an * then it saves the name in the array IS and sets the card 
counter to 10. The cards will be numbered 10,20,30, and so on. It is 
convenient to have cards labeled in this fashion since it makes it easier 
to insert cards at a later date. If the card is an ordinary program card, it is 
transferred into the array LL, one character at a time. If a $ is found, the 
contents of array LL are punched out, and the column counter for array LL 
is set back to 7. 
This routine would compile in Fortran IV if some minor changes 
were made to the Data statement and if the R formats were changed to A 
formats. Unfortunately the program would not work correctly on the 
IBM 7090. The statement 
IF( L(1)-ISTAR) 
2,1,2 
is the cause of the difficulty. ISTAR has the value 1H* which is 
546060606060 octal. If L(l) had a value such as 346060606060 octal, then 
the subtract operation would produce an overflow; that is, it would produce 
a result that is too large to be expressed as an integer in the 7090. The IF 
statement cannot be used to test the equality of alphanumeric words. It is 
unfortunate that Fortran IV does not have an R-type format, since this 
would be the ideal solution to the problem. The most convenient solution 
is to write a short Map program of about five instructions that can be used 
to do the logical comparison. Once the routine has been written it can be 
used in a great many problems of this type. 
7-5 
A SIMPLE FORMAT-FREE INPUT ROUTINE 
The following routine is designed to read numbers that are punched in any 
reasonable manner. That is, if the numbers look correct when the cards are 
printed out, then the routine should be able to read them correctly. This 
seemingly sensible quality is not present in the standard Fortran formatted 
input. For example, the numbers 
125 
12.752 
- 2 1 
67 
.0 
1. 
0 
are quite readable, the first number is 125, the second is 12.752, and so on, 
but if these numbers were read with the format that began 14, the numbers 
would not be what they seem. The first number would be read as 1250. To 
be more precise, the routine to be described accepts numbers punched in 
the following way. Each number may be preceded by any number of blank 

7 · 5 A S I M P L E F O R M A T - F R E E INPUT ROUTINE 
265 
SUBROUTINE READX(NOUT) 
DIMENSION NB(81) $ DATA (NCOL«81) 
EQUIVALENCE (X.I) 
ISIN=2 $ GO TO 1 $ ENTRY READI $ ISIN*1 
NPP«NP«NOV» 
N*0 $ NSIGN*JUMP«1 
IF(NCOL-80) 3»3.2 
READ 500.ÎNBU >.I-1»80) 
SPRINT 503t(NB(I)11-1180 ) 
F0RMAT(80R1) 
FORMAT(XeORl) 
NB(81)»1R 
$ NCOL*0 $ GO TO 3 
JUMP«2 
SIF(NCOL-eO) 3.3.2 
PICK UP ONE CHARACTER. TEST FOR DIGITS 
NCOL=NCOL+l $ ICHARsNB(NCOL) S IF(ICHAR-IO) 13.14.12 
ICHAR=0 
TEST FOR POSSIBILITY 
OF OVERFLOW 
IFlN-140 737 488 355 32) 15.16.17 
N0V«N0V>1 $ GO TO 18 
IFUCHAR-7) 15.15.17 
N»10«N4ICHAR 
COUNT DIGITS 
AFTER DECIMAL POINT 
NOTE THAT NP IS ZERO BEFORE POINT 
NPP»NPP+NP $ GO TO 5 
TEST FOR ♦ .-.. AND BLANK. 
IF(ICHAR-1R+) 20.5.20 
IF(ICHAR-1R-) 22.21.22 
NSIGN=-1 $ GO TO 5 
IF(ICHAR-1R.) 24.23.24 
NP«1 $ GO TO 5 
IFMCHAR-1R ) 26.25*26 
PRINT 501.NCOL.ICHAR 
FORMAT(28H ILLEGAL CHARACTER IN COLUMN I6.2H «02) 
GO TO 4 IF INTIAL BLANK. 
GO TO 30 IF TRAILING BLANK 
GO TO (4.30) . JUMP 
NUMBER HAS BEEN TERMINATED 
N=N«NSIGN $ GO TO (31.41).ISIN 
IF(NOV) 33.33.34 
PRINT 502 
FORMAT(18 H INTEGER TOO LARGE) 
NOUT=N S RETURN 
X*N $ NP«NPP-NOV S IF(NP) 42.43.44 
Χ»Χ/10·«*ΝΡ $ GO TO 43 
Χ«Χ*10.·»(-ΝΡ) 
NOUT=I 
END 
FIG. 7.5 A format-free input routine 
characters. Once a digit, or —, or + , or ., is encountered, no more blank 
characters are allowed until the end of the number. After a number has 
been started, the first subsequent blank terminates the number. It will be 
seen that the numbers displayed above obey these simple rules. The routine 
reads one number at a time. In practice the routine reads a whole card, of 
course, but each time the routine is entered it picks one number; namely, the 
next number, from the card buffer. When the buffer is empty, the routine 
automatically reads in a new card. The routine is shown in Fig. 7.5. 
The routine has two entry points. A call to READX(A) reads the 
next number on the card and stores it as a floating-point number in A. 
A call to READI(J) reads the number as an integer. The variable NCOL 
contains the number of the current card column. When NCOL is greater 
than 80, then the current card has been completely read and another card 
is read in. The location NB(81) is set equal to the blank character; if a 
number on the cards ends in column 80, then the blank in 81 causes the 
number to be terminated. The variable NCOL gives the number of the 
column that is currently being examined. NP is zero initially and is set equal 
to unity if and when a decimal point is encountered. NPP counts the 
1 
4 
2 
500 
503 
5 
C 
3 
14 
C 
13 
17 
16 
15 
C 
c 
18 
c 
12 
20 
21 
22 
23 
24 
26 
501 
C 
C 
25 
C 
30 
31 
34 
502 
33 
41 
44 
42 
43 

266 
7 CHARACTER 
MANIPULATION 
number of digits after the decimal point. NOV counts the number of 
overflow digits, if there are any. The routine can treat about 14 decimal 
digits; digits in excess of this are counted as zeros. N is the location where 
the number is formed. JUMP is 1 before the number has been started and 
is 2 after a digit, plus, minus, or point has been read. 
The routine goes through the usual process of looking at each 
character in turn and taking some action appropriate to the type of 
character. The largest integer that can be stored in a 1604 word is 2**47—1, 
which is 140737488355327. This explains the test in statements 13 and 
16. Notice the use of the Equivalence statement which allows the routine to 
put a floating-point variable into a location with an integer name. The use 
of 10.**NP is inefficient. In a practical routine it is advisable to store a table 
of powers of 10. 
7-6 
A GENERAL-PURPOSE INPUT ROUTINE 
The writing of a general-purpose input routine does not introduce any new 
principles. It is necessary to be more careful in certain cases and to be more 
flexible in others. For example, the routine READX allows such obvious 
errors as 1..25, and reads 1. —25 as though it had been written — 1.25. The 
routine does not allow the E notation. A general-purpose decimal-input 
routine written in Fortran 63 has been described elsewhere (Hassitt, 1964). 
The routine has the following properties. 
The routine has two main entry points. Let us assume for the 
moment that the cards contain only numeric data. CALL RDNUM(X) 
reads the next number from the input stream, converts it to floating-point 
binary form, and puts it in X. CALL RDINT(I) reads the next number, 
converts it to a binary integer, and puts it in I. The numbers may be 
punched anywhere on the card. A number is of the form 
bb — b±dd — d.dd — dEbb — b±dd—dx 
where 
bb··-b = none, one or more blanks 
dd'--d = none, one or more digits 
± = + or — or may be omitted 
. = decimal point or may be omitted. 
The sequence dd---d.dd~-d must contain at least one digit. 
E denotes exponent with base 10. If E occurs, it must follow the 
fractional part immediately with no intervening spaces. This rule is 
unfortunate but necessary as the whole exponent sequence 
Ebb--b±dd--d 
may be omitted. 

7 - 6 A GENERAL-PURPOSE INPUT ROUTINE 
267 
x denotes the terminating character which is usually a blank but 
could be (1) a letter, (2) a special character ($, =, etc.), (3) a second 
appearance of the character . (that is, a point) or character E, or (4) a 
+ or — sign following a digit. If a number has been started, then the end 
of a card acts as a terminating character. The end of a card is ignored (a 
new card is read in) if only blanks have appeared so far. A typical portion 
of a program might be 
CALL RDINT(I) 
DO 1 J = 1#l 
1 
CALL RDNUM(X(J)) 
which might operate on data such as 
9 
1.234 
-0.16E2 
0.1 
54 
123456789123456789 
0 
- 9 
56E3 
21.26 
We see that 0 or 0. or .0 or 0.0 (but not .) can be written and that 54 or 
54. or 54.0 or .54E2 or .54E 2 (but not .54 E2) can be written. 
This routine also reads words and special characters. A word is 
of the form 
bb · · · b aa · ■ · ax 
where 
bb~'b = none, one or more blanks 
aa---a = one or more of the alphabetic characters A,B,C,..., Z. If there are 
more than eight characters, the ninth and subsequent characters 
are ignored. 
x = any nonalphabetic characters 
A special character is none, one, or more blank characters followed by $ 
or , or / or * or = or . or ( or ). Suppose the input card contains 
ALPHA =61.2E3 C2 E5 
then 
DO 1 J = 1,7 
1 
CALL RDNUM (X(J)) 
set 
X(1) = 5HALPHA, X(2) = 1H = , X(3) = 61.2E3, X(4) = 1HC, X(5) = 2.0, 
X(6) = 1HEandX(7)=5.0. 

268 
7 CHARACTER 
MANIPULATION 
In many contexts it is important to know whether the quantity 
just read is a number, a word or a special character. The routine has an 
alternative entry point. 
CALL RDTYPE(K) 
sets K = +1, 0, — 1 depending on whether the last quantity read was a 
number, a special character, or a word. Thus, 
DO 1 J = 1,7 
CALL RDNUM (X(J)) 
1 
CALL RDTYPE (L(J)) 
operating on the data given above would set X(l) = 5HALPHA, and so on, 
and L(l)= — 1, L(2) = 0, L(3)= + 1, and so on. In the above example the 
space separating 2 and E is taken to mean that E is a word and not an 
exponent indicator. 
The Fortran 63 version of RDNUM is given in the reference 
Hassitt (1964). One of the uses to which this routine can be put is described 
in the section on list-directed input. 
7-7 
ENCODE and DECODE 
Let us consider the following problem. There are two magnetic tapes. Each 
tape contains an unknown number of records, but there is an end of file at 
the end of each tape. The records are in the BCD mode, and they are 
blocked with ten logical records per physical record. Each physical record 
contains 144 characters. The characters in positions 3 through 11 in any 
record contain an integer. The records are such that this integer increases 
from one record to the next. The problem is to merge the two tapes onto 
one tape, making sure that the key numbers are still in increasing order. 
This is a simple example of the general merge problem that arises in many 
data processing applications. 
One potential solution is to read the tapes with READ statement 
and translate the key number into binary. In the problem we have in 
mind, there are several facts that make this impossible. The records are 
blocked and the READ statement will not read blocked tape. The logical 
records contain 144 characters and the READ routines in most Fortran 
systems are limited to 120 characters. There is, moreover, an overall 
objection to using the READ statement in this context. The conversion 
from BCD to binary is quite time consuming and it would be wasteful to 
convert 144 characters in each record when we are only interested in nine 
of the characters. The way in which the tape should be read is obviously to 
use the OPEN routine that was described in Section 5.12. 

7 · 7 ENCODE AND DECODE 
269 
Suppose that we have read one record from each tape. Let the first 
record be in the array A, and the second record be in the array B. The 
records have been read by OPEN. This routine reads the records directly 
into memory. The character string has the same form as it had on magnetic 
tape, which is essentially A8 format. The problem is to compare the value 
of the key words in the two records. One method of proceeding is the 
following: Let tape 4 denote a scratch tape, then compute the word 
KEYA by 
REWIND 4 
WRITE (4,500) 
A(1),A(2) 
500 
FORMAT(2A8) 
REWIND 
4 
READ (4,501) 
KEYA 
501 
F0RMAT(2X,I9) 
A similar process on the other array produces KEYB. KEYA and KEYB 
are binary integers so they can be compared with an ordinary IF statement. 
This method of using the scratch tape has done that which was necessary; it 
has converted the nine characters that were of interest. However, it is 
obviously somewhat inefficient. The Fortran 63 compiler provides a method 
of achieving the same effect without going through the stage of writing and 
reading the scratch tape. The statement 
DECO DE (n,m, A) LIST 
takes n characters from the array A, decodes (that is, converts) them 
according to format specification w, and puts the results in the locations 
specified by LIST. LIST can be any list of the form usually associated with 
READ and WRITE statements. The Decode statements required in the 
merge problem are 
DECODE(11,501,A) 
KEYA 
DECODE(11,501,B) 
KEYB 
501 
F0RMAT(2X,I9) 
The full routine is shown in Figure 7.6. 
The Decode statement would not have been necessary if the 
tapes had been in the binary mode. There are several good reasons for 
preferring tapes in the BCD mode for certain applications. BCD tapes can 
be read by other machines. For example the number unity is 201400000000 
octal in the IBM 7090 and it is 2001400000000000 octal in the CDC 1604, 
but the BCD form is 1.0 in both machines. The different representations 
of BCD in the memory of the 1604 and the 7090 presents no difficulty 
because both machines use the same code on magnetic tape. Another 
advantage of BCD tapes is that they might be more compact. Suppose the 
variable T represents the result of an experimental measurement, and 

270 
7 CHARACTER MANIPULATION 
suppose that T consists of just three digits. In the BCD mode, T can be 
represented by 18 bits. In the binary mode it is 36 bits on the 7090 or 48 bits 
on the 1604. If T is represented as an integer, then it could be packed into 
less than one binary word. However, the advantage of the BCD mode is 
that the packing routines are already available in the form of Encode and 
Decode. 
SUBROUTINE MERGE 
DIMENSION A(36).L<4) 
L(l )»18 S L(2)«10 $ L(3)*0 
L(4)=5HTAPE1 $ CALL OPEN(L.l) 
L(4)»5HTAPE2 S CALL OPEN(L»2) 
LU)=5HTAPE3 
S CALL OPEN(L.3) 
REWIND 1 $ REWIND 2 S REWIND 3 SFIRST«0. 
1 
NT*2 $ IF( READ(A 
. 1 ) 
) 
1 0 0 * 2 . 2 
2 
DECODE(11.501»A 
) KEYA 
S IF(FIRST) 33.33.5 
501 
FORMATC2X.I9) 
33 
FIRST«1. 
3 
NT-1 $ IF( READ<A<19).2) 
) 100.4.4 
4 
DECODE(11.501.A<19)) 
KEYB 
5 
IF(KEYA-KEYB) 
10.10.11 
C 
KEYA IS SMALLER. WRITE FROM A<1) 
10 
X»WRITE(AI1)»3) 
S IF(X) 102.1.1 
C 
KEYB IS SMALLER· WRITE FROM AI19) 
11 
X»WRITE(A<19).3) S IF(X) 102.3.3 
C 
ONE TAPE IS FINISHED 
100 
J »1+(NT-1)*18 
101 
IF( WRITE(A<J). 3)) 102.110·110 
110 
IF< READ(A(J).NT)) 
103·101·101 
103 
CALL CLOSE<0.3) 
102 
CALL CLOSE(O.l) $ CALL CLOSE (0.2) 
END 
FIG. 7.6 A program to merge two tapes 
It was explained in the previous chapter that the READ statement 
in the BCD mode takes place in two parts. Part one reads in the record and 
part two translates the record into binary. The Decode statement is 
precisely the second part of this process, with the first part omitted. The 
system obviously uses the same routines to do the Decode and the READ. 
One more example 
DECODE(84,502,BUFFER) 
( NB(I), 1 = 1,84) 
502 
FORMAT(84R1) 
should indicate the general nature of the Decode statement. 
The Encode statement corresponds in a similar manner to the 
WRITE statement. The general form is 
E N C O D E ( A ? , " 7 , A ) LIST 
This takes the words specified in the LIST and output them according to 
the format statement m. The output does not go onto a tape; it is put into 
the array A. n specifies the number of characters to be transmitted. No 
further explanation should be necessary since ENCODE is the same as the 
BCD WRITE statement except that the output goes into an array in the 
memory. 

7 · 8 FORMAT-FREE OUTPUT 
271 
The Encode and Decode statements are not available directly in 
Fortran II and Fortran IV, but again a number of installations have 
written their own version. Pyle (1962) describes an implementation of 
Encode and Decode in the Fortran II system. 
7-8 
FORMAT-FREE OUTPUT 
As an illustration of some other ways of manipulating characters we will 
examine the possibility of writing a format-free output routine. The 
routine works in the following way: 
CALL PRINT(X) 
prints the number X. The routine decides how the number is to be printed— 
that is, what format is to be used. The routine places several numbers on 
one line. It prints a line either when it is necessary or when a 
CALL PRINTNL(O) 
is given. P^INTNL forces a new line, it does not print any additional 
number. The routine also prints integers. The same calling sequence, 
namely, 
CALL PRINT(I) 
is used. 
The routine works by building up a Format statement. The array 
NDORM contains a number of skeleton formats. The numbers to be 
printed are converted into BCD and placed in the output buffer. The 
buffer has the name NOUT. The number NCOL gives the number of 
characters that have been placed in the buffer. If the next number to be 
printed will overload the buffer, the characters that are in NOUT are 
printed out and the column count is set back to unity. Suppose that NCOL 
is 24 and that the integer XIN is to be put into the array NOUT with 
format I14,X. Word one of the buffer contains characters 1 through 8. Word 
two has 9 through 16, word three has 17 through 24. XIN is placed with its 
first character at character 25, that is at the beginning of word four. The 
routine builds up the format statement 
NORM(l) contains ( 
NORM(2) 
114, 
NORM(3) 
X) 
and then the statement 
ENCODE(15,NORM, NOUT(4) ) 
XIN 

272 
7 CHARACTER 
MANIPULATION 
SUBROUTINE PRINT(ARGUE) 
DIMENSION NOUT(15)»NORM(2) 
EQUIVALENCE(XIN.IN) 
DATA (NCOL=l)♦(N0UT=1H ) 
JTYPE=1$ XIN=ARGUE 
TEST TO SEE IF CURRENT LINE IS FULL 
IF(NCOL+ 16.GT.120 
) GO TO 110 $ GO TO 111 
ENTRY PRINTNL $ JTYPE=2 $ GO TO 110 
ENTRY PRINTNP $ JTYPE=3 
PRINT ONE LINE OF DATA 
NT0P=(NC0L-i)/8+l SPRINT 114 »(NOUT( I).I = 1 »NTOP) 
FORMATU5A8) 
PREPARE FOR NEXT LINE 
NC0L=1 
$ DO 115 I»ltNTOP 
N0UT(I)=1H 
$ GO TO (111.153.80) . JTYPE 
N0UT(1)=1H1 
$ RETURN 
NW=(NC0L-l)/8 S NC=NC0L-8*NW 
N0RM(1)=1H( $ IF(NC.E0.8) GO TO 123 
NC IS NOT 8 CONSTRUCT FORMAT (A*». 
J=NC*64 $ NORMd )=J.0R.(8H 
(A ♦ · AND. .NOT. 7700B ) 
N0RM(2)=5HXI15) 
TEST TO SEE IF NUMBER IS INTEGER 
NN=XABSF(IN) $N=NN.AND.2777 0000 0000 OOOOB 
IF(N.EQ.O) GO TO 200 
N0RM(2)=7HXF15.6) 
IF(NN.LT.1.0 .OR. NN.GT.1.0E6) NORM(2>=7HXE15.6) 
IF(NC.NE.8) GO TO 151 
PUT ENCODED NUMBER INTO OUTPUT BUFFER. 
ENCODE« 16.NORMd) .N0UT(NW+2) )XIN $ GO TO 152 
I=N0UT(NW + 1) $ J= 16+NC $ ENCODE(J»NORM(1)»NOUT(NW + 1))I.X IN 
NCOL = NCOL-»· 16 
RETURN 
END 
FIG. 7.7 The subroutine PRINT 
is used to place the 15 characters in the buffer. If NCOL is not a multiple 
of eight, then a slightly different procedure is used. For instance, if NCOL 
is 20, then the format becomes 
(A5, 
114, 
X) 
and the statements 
l=NOUT(3) 
ENCODE(20,NORM,NOUT(3) ) Ι,ΧΙΝ 
ensure that the first five characters in NOUT(3) are preserved and transmit 
the other 15 characters to the buffer. 
The routine decides the format of the number to be printed in a 
series of tests. If the modulus of the number has no characteristic, that is, if 
the twelve high-order bits are zero, then the number is considered to be an 
integer. This test will be in error in the unusual case where the integer is 
greater than 236 — 1. If the number is a floating-point number, then the log 
to base 10 is used to discover the size of the number. Numbers less than 
unity or greater than 108 are printed in E format. Numbers in the range 1 to 
108 are printed in an appropriate F format. 
There are several alternative ways in which the routine could have 
been written. Statement 202 could have been done by taking the charac-
teristic of the number and dividing by the log of 2 to the base e. Statement 
no 
114 
115 
80 
111 
200 
151 
152 
153 
c 
c 
c 
c 
123 
c 

7 · 9 LIST-DIRECTED OUTPUT 
273 
142 and similar statements could have been simplified by spreading the 
skeleton out. The format itself could have been generated by the use of 
another Encode statement. 
7-9 
LIST-DIRECTED OUTPUT 
List-directed input and output have been introduced in recent versions of 
Fortran. The contents of the list are specified 
NAMELIST 
lxla,b,...lylp,q,... 
where x and y denote the names of lists and a,b,...9p,q,... denote the names 
of Fortran variables or arrays; for example. 
DIMENSION 
AA(3,10),L(5) 
NAMELIST 
/NTWO/ AA,B,C /ALPHA/ P,Q,R,I,L 
COMMON B,Q(7,7)/BETA/ C 
The names NTWO and ALPHA are the names of lists. In Fortran IV list 
names can be used in input and output statements, but must not be used 
anywhere else. The Namelist statement causes the compiler to generate a 
list that contains details of all the information known about each variable 
in the list. The information about the variables is (a) the BCD name of 
the variable, (b) the location, or in the case of an array, the base location of 
the variable, (c) the mode, and (d) the number of dimensions and the size 
of each dimension. The Namelist is used in Fortran IV by a statement 
such as 
PRINT 
ALPHA 
This statement prints 
&ALPHA 
P=12.7, Q =9.25,11.684, . . . 
R = 8.685, R=1.2E10, 
I = 7 
L=31, 27, 9, 15625, - 2 1 
A similar feature has been implemented in Fortran 63 (Hassitt, 1967). The 
Namelist statement itself takes on the same form, but the statement 
PRINT 
ALPHA 
is replaced by 
CALL OUTLIST (ALPHA) 
The use of Namelist is particularly simple. It should save the inexpert 
programmer much of the difficulty of the formated output routines. 

274 
7 CHARACTER 
MANIPULATION 
The list generated by the Namelist statement in Fortran 63 is of 
the following form. Let n denote the number of items in the list. 
Word 1 
the address of the current location 
Word 2 
« + m * 2 ** 24, where m is the number of words that the 
list information will occupy 
Word 3 
the name of the list in BCD 
Word 3+/ 
the name of the jth variable in BCD 
Word 3+«+l 
information on the location, mode and dimension of the 
zth variable. This word has the form nt +218n2 + 
224«3 + 242>u 
«4 gives the mode: 0 is for integer, 1 is for real, 2 is for double, and 3 is for 
complex. n3 gives the location of the variable, n2 gives the number of 
dimensions. If n2 is zero, then nt is also zero, otherwise n1 gives the location 
of the words containing the dimension information for this variable. Word 
nx is divided into two half-words. The first half-word gives the dimension 
of the first dimension. The second half relates to the second dimension. If 
there is a third dimension, then it is specified in the first half of word 
nt + 1. The first part of the Namelist statement given in the example above 
generates the code 
NTWO BSS 
ORG 
ZRO 
ZRO 
ZRO 
BCD 
BCD 
BCD 
BCD 
1 
2 
1 
ZRO 
1 
ZRO 
ZRO 
ZRO 
10 
NTWO 
* 
10 
3 
1NTWO 
1AA 
1B 
1C 
AA 
9 
B 
0 
C 
0 
3 
10 
If the variable has a variable dimension, then the half-word that gives this 
dimension has the form 
1 
I 
where 1 indicates that the dimension is variable and I gives the location of 
the dimension. 
The coding of the routine OUTLIST is shown in Figure 7.8. It will 
be used to illustrate some techniques in Fortran programming. 
CALL 
OUTLIST (L) 

7 · 9 LIST-DIRECTED OUTPUT 
275 
has the following effect. If L is zero, there is an immediate return to the 
calling program, and no printing occurs. This entry is useful in debug 
printing, as we shall see later. If 1 <L<49, then L lines are spaced on the 
printer. L = 50 causes the next line of print to appear at the top of a new 
page. These two entry points are useful for novice programmers who do 
not want to use formated input/output at all. If L is a NAMELIST, then 
contents of the list are printed. The entry point 
CALL 
ZEROLIST (L) 
where L is the name of a Namelist, sets every element of the list equal to 
zero 
The routine begins by examining L. A simple test is used to dis-
criminate the L < 50 type entries. If L is the name of a NAMELIST, then 
LBASE=L AND. 77777B 
sets the integer LBASE equal to the location of L, and 
MBASE=M. AND. 77777B 
LBASE= LBASE- M BASE 
sets LBASE equal to the location of L(l) minus the location of M(l). This 
implies that M(LBASE+1) is the same as L(l), and M(LBASE + I+1) is 
the same as L(I). This use of M(LBASE + I+1) in place of L(I) has two 
consequences. It is more efficient since references to M do not require 
entries in the prologue. It is also more powerful since the L of the calling 
sequence can now be either the name of a NAMELIST, or the name of any 
integer whose value is the address of a NAMELIST. 
The routine keeps a count of the number of times any list is used. 
The count is kept in the first half of the first word of the list. Statements 104 
and onwards up-date this count. Statement 105 sets NN equal to the 
number of entries in the list. Statements 1 through 109 process each list 
element in turn. Statements 10 through 18 decode the type, address and 
dimensions of each variable. Statements 600 through 633 control the actual 
printing. 
The print part of the program builds up the format for each line 
in the array. At the start of the routine ICUR = 2 indicates that the next 
item to be printed will go in column 2. NLAR= 1 indicates that the next 
piece of format will go into location IAR(NLAR+1). IAR(l) is set equal 
to 2H(X. Suppose the first variable to be printed is an integer. 
IFORM = IFORMT(JTYPE) 
$ ILEN = ILENT(JTYPE) 
will set 
IF0RM = 4H,I16 and ILEN = 16 

276 
7 CHARACTER 
MANIPULATION 
SUBROUTINE OUTLIST(L) 
C 
AUGUST 4.1965 
DIMENSION I FORMT(6)·I LENT(6)»I AR(15)»LAR(15) 
DATA(MINCOL=2)»(MAXCOL=120)·(IFORMl=2H(X)♦(NT=51). 
1(ILENT=16»16»20»16,20»16), (IF0RMT=4HtI16,6H,E16.6,7Η,Ε20.10» 
26Η»Ε16·6» 4Η.020»8Η»Α15»1Η=) 
»(LAR=0) 
DATAI I2T42 = 10000OO000Ü0OC0B) ♦ (I 2T24=1000000008)»(I 2T18=1000000B) 
DIMENSION M(5) 
$ NAMELIST /M/MIS 
EQUIVALENCEi ΐΝ,χΝ) 
IL=1 $ GO TO 7 S ENTRY ZEROLIST S IL=0 
7 
ICUR=MINC0L $ IAR=IF0RM1 $ NLAR=l 
LBASE=L.AND.77777B $ IF(LBASE-50) 5l»50.52 
50 
PRINT 53 S RETURN 
51 
DO 55 I=1»LBASE 
55 
PRINT 54 
$ RETURN 
53 
FORMAT(lHl) 
54 
FORMAT(1H ) 
52 
MBASE=M.AND.77777B$LBASE=LBASE-MBASE 
NN=M(LBASE+1).AND.77777B S I F(NN.EQ.LBASE+MBASE) 4*3 
3 
PRINT 5,L 
SRETURN 
5 
F0RMAT(17H ERROR IN OUTLIST020»18H IS NOT A NAMELIST) 
4 
IF(IL.EQ.O) 105tl04 
C 
IL = 1 MEANS ENTRY WAS AT OUTLIST 
C 
PRINT HEADING 
104 
L1=M(LBASE+1).AND.77777 000 OOOOOB * L1=L1+I2T24 
M(LBASE-H)=(M(LBASE+1).AND.777 00000 777 77777B).OR.L1 
L1=L1/I2T24 $ PRINT 6»M(LBASE+3),L1 
6 
FORMAT<XA8,17) 
105 
NN=M(LBASE+2).AND.77777B $ INUM=l 
SGOTO 42 
1 
IF(JL .NE.l) 41,42 
41 
ICUR=MAXC0L+1 
C 
FIND THE NAME, MODE AND DIMENSIONS OF ONE ITEM OF LIST 
42 
J1=M(INUM+NN+3+LBASE) * JTYP =J1/I2T42+1 $ JAD=J1/I2T24 
JAD=JAD.AND.77777B $ JDIM=J1 
/I2T18 $ JDIM=JDIM.AND.7B 
J4=J1.AND.77777B 
SJ2=1 $ IF(JDIM.EQ.O) 20,10 
C 
LI, L2» L3 WILL BE SET EQUAL TO THE DIMENSIONS OF THE ARRAY 
10 
L2=L3=1 $ J2=M<LBASE+J4+1)$ J1=J2/I2T24 $ JUMPA=0 
11 
J3 = J1.AND.7000000B S I F(J3.EQ.O) 13,12 
12 
J1=J1.AND.77777B $ J1=M(Jl-MBASE+1) 
13 
JUMPA=JUMPA+1 $ GO TO (14,15,17) , JUMPA 
14 
L1*J1 $ J1=J2.AND.7777777B $ IF(JDIM.LE.1) 18,11 
15 
L2 = J1 S IFUDIM.LE.2) 18,16 
16 
Jl=M(J4+LBASE+2)/I2T24 $ GO TO 11 
17 
L3=J1 
18 
J2 = L1*L2*L3 $ IFUTYP .E0.5) 19,20 
19 
J2=(J2-l)/32-H 
20 
IF(ICUR.NE.MINC0L.AND.J2.NE.1) 44,43 
44 
ICUR=MAXC0L+1 
43 
Il=lNUM+3+LBASES JTYPE=6 $ JUMP=1 $ JL=J2 
IF(IL.EO.O) 600,106 
C 
ENTRY POINT WAS AT ZEROLIST 
106 
IF(JTYP .EQ.3 .OR. JTYP 
.EQ.4) 107,108 
107 
J2=2*J2 
108 
I1=JAD-MBASE + 1 $ J 2 = U + J2-1 S DO 109 Jl=Il»J2 
C 
GO TO 42 FOR NEXT ITEM OF ZEROLIST 
109 
M U 1 ) = 0 $ INUM=INUM+1 I IF ( INUM.LE.NN ) 42,32 
2 
JTYPE = JTYP$I1 = JAD-MBASE + 1 $ JUMP = 2$ IF(JTYPE.EQ.4) 21,600 
21 
J2=J2«2 $ GO TO 600 
C 
GO TO 600 TO PRINT EACH NUMBER 
24 
11=11+1 S J2=J2-1 S IF(J2.LE.0) 30,600 
C 
GO TO 1 IF THERE ARE MORE ITEMS IN LIST 
30 
INUM=INUM+1 $ IF(INUM.LE.NN) 1,31 
C 
END OF LIST... EMPTY 
BUFFER 
31 
JUMP=4 $ GO TO 621 
32 
RETURN 
C 
PUT ONE NUMBER INTO PRINT BUFFER 
600 
IFORM=IFORMT(JTYPE) $ ILEN=ILENT(JTYPE) $ IN=M(I1) 
C 
DECIDE ON THE FORMAT 
IF1JTYPE-2) 601,603,620 
601 
IF(XABSF(IN).LE.999999) 602»620 
602 
IFORM=3H,I8 
$ ILEN=8 $ GO TO 620 
603 
IF(-IN.OR.IN) 
605,602 
605 
XA = ABSF(XN) $ IF(XA.GE.0.1.AND. XA.LT. 1.E5) 604,620 
604 
IF0RM=6H,F16.7 
620 
L1=LAR(NLAR) 
C 
TEST TO SEE IF NUMBER IS SAME AS PREVIOUS NUMBER 
IF(L1 
.EQ.IN .AND. I AR(NLAR).EQ.IFORM 
.AND.NLAR.NE.1)640,632 
FIG. 7.8 The subroutine OUTLIST 

7 · 9 LIST-DIRECTED OUTPUT 
277 
C 
MAKE SURE TO DISTINGUISH 0 FROM -0 
640 
L2=IN.AND.7 JL1=L1 
.AND.7 $ IF(Ll.EQ.L2) 644.632 
644 
L1=IAR<NLAR-1).AND.77B $ IF(LI.EQ·1R*) 641t642 
C 
CONTINUE WITH N ♦ X TYPE OF PRINTING 
641 
LAR(NLAR-l) =LAR(NLAR-1)+1 
$ I F(JTYPE.EQ.3) 631t633 
642 
IF(ICUR+8 .GT. MAXCOL) 632»643 
C 
BEGIN 
N * X TYPE OF PRINTING 
643 
LAR(NLAR)=2 $ IAR<NLAR)=8H#I 7» 1H*$ILEN = 8 $ GO TO 634 
632 
IF(ICUR+ILEN.GT.MAXCOL) 621*630 
621 
IAR(NLAR+1)=1H) 
C 
BUFFER IS FULL·. PRINT IT 
WRITEiNTfIAR) (LAR(I)» I=2.NLAR) S NLAR=1 $ ICUR=MINC0L 
IF(JUMP.EQ.4) 32*630 
630 
IF(JTYPE.EQ.6 .AND. IN.NE.1H ) 650*634 
C 
JTYPE=6 MEANS AN ALPHANUMERIC WORD TO BE PRINTED 
650 
L1=IN.AND.77B S IF(Ll.EQ.lR ) 651.652 
C 
STRIP OFF TRAILING BLANKS 
651 
IN=lN/64 S IN=(IN.AND.77 7777 7777 7777B).0R. 
1 2000 0000 0000 0000B $ GO TO 650 
652 
IF(ICUR+ILEN+16.GT.MAXCOL) 621*634 
634 
NLAR=NLAR+1 $ IAR(NLAR)=IFORM $ ICUR=ICUR+ILEN 
LAR(NLAR)=IN $ IF(JTYPE.EQ.3) 631.633 
631 
11=11+1 
633 
GO TO (2.24 
) · JUMP 
END 
FIG. 7.8 {concluded) 
An attempt is made to compress the printing by testing the absolute value 
of the integer. If it is less than a million, then an 18 format is used. At 
statement 632 we test to see if the current line is full, if so the format is 
rounded off with a 1H) and the line is printed. If it is not full, then 
IAR(NLAR+1) = IFORM 
LAR(NLAR) = IN 
saves the current format in IAR and the current number in the array LAR. 
At this stage the format statement appears as 
(X 
,116 
Statements 620 through 641 test to see if a series of identical items are to be 
printed. If so, the form N*N is built up. Double-precision numbers are 
printed to single precision. They could be printed to double precision 
simply by changing the E in IFORMT(3) to a D, but this would penalize 
every user since the library routines for double-precision output would be 
brought into memory. 
The use of NAMELIST makes it possible to produce a convenient 
debug print in Fortran. In the past it was an easy enough matter to produce 
the print routine but the user had the tedious job of transmitting, by way of 
a calling sequence, all of the information that is now provided by NAME-
LIST. The essential features of a debug print is that it should be easy to 
use and that it should label all the output in a convenient way. Any 
NAMELIST output will do this automatically. There are two other 
considerations. The output should be reasonably compact. This is achieved 
in NAMELIST providing the user takes a little care. OUTLIST always 
prints a complete array. If an array has a Dimension statement of (50,50) 
and if the program only uses a small part of this array, then the programmer 

278 
7 CHARACTER 
MANIPULATION 
should make sure that the unused portions of the array are set to zero. 
When a large program has been debugged, then it is a wise practice to 
suppress the printing but not to remove the print statements themselves. If 
the program appears to be in error at a later stage, then the debug printing 
can be restored and the cause of the error can be found. In Fortran IV 
the one way to do this is to put a variable in Common which controls the 
printing, for example 
NAMELIST /LISTA/ . . . 
COMMON 
DEBUG 
IF (DEBUG .EQ. 1.) PRINT LISTA 
When debugging is finished, the printing can be turned off by setting 
DEBUG equal to zero by a statement in the main program. 
The form of OUTLIST in Fortran 63 is chosen so that debug 
printing can be easily controlled. Suppose LISTA is the name of a Namelist 
and I is any integer variable. Then 
CALL 
OUTLIST(LISTA) 
and 
l = LISTA 
$ 
CALL OUTLIST(I) 
have the same effect. The statements 
l = 0 
$ 
CALL OUTLIST(I) 
produce no printing. 
If a routine contains the statements, 
SUBROUTINE 
ALPHA 
COMMON 
IDBG 
CALL 
OUTLIST(IDBG) 
then printing depends on the value of IDBG. Statements 
PROGRAM 
MAIN 
NAMELIST 
/LISTA/ . .. 
COMMON 
IDBG 
IDBG = LISTA 
in the main program cause the items of LISTA to be printed when ALPHA 
is reached, whereas 
IDBG = 0 
suppresses the printing. In this way all debug printing can be controlled 
from the main program. 

7 · 10 AN ASSEMBLY PROGRAM 
279 
1 
blank 
2-8 
symbol 
or blank 
9-11 
operation 
17 
index 
or blank 
20-39 
address 
7-10 
An ASSEMBLY PROGRAM 
As a final example of character manipulation and as a further explanation 
of the assembly process, we will examine a simple assembly program. The 
instructions to be assembled are written in the form, 
column : 
A symbol is one through seven characters, the first of which must not be a 
digit. The character * must not be used in a symbol. The operation code is 
any of the 1604 symbolic codes, or a pseudo-operation. The index is blank 
or a digit. The address part of the symbolic instruction has the form s or n 
or — n or s + n or s — n where s denotes a symbol or the character * and n 
denotes a string of digits. The pseudo-operations are BSS,DEC,COM, or 
END. BSS has its usual meaning. DEC has its usual meaning except that 
only one number must appear on the card and the E format is not allowed. 
The operation 
A 
COM 
n 
denotes that A is a Common variable of dimension n. An example of the 
code acceptable to the compiler is 
ALPHA 
S4 
A 
B 
SLJ 
SIU 
ENA 
ENI 
FAD 
UP 
STA 
LIU 
SLJ 
BSS 
COM 
COM 
END 
4 
4 
4 
4 
4 
** 
S4 
0 
10 
A 
* 
B + 2 
S4 
ALPHA 
1 
11 
3 
The assembly program is written as Fortran subroutine. The program to be 
assembled is punched on data cards. The assembler puts the assembled 
code directly into the memory. The assembler works on a two-pass method 
which is used in most current assemblers. It reads through the program and 
discovers the values of all the symbols, then it makes a second pass through 
the program and actually assembles the code. In the assembly subroutine, 
NORG gives the value of the current location and NCOM gives the value 
of the current location for the next common variable. The subroutine LOC 

280 
7 CHARACTER 
MANIPULATION 
PROGRAM 
ASSEMBL 
COMMON NIN(20).NT(lOO)»NV(100)»NOPC»NPS 
EQUIVALENCE(NORG,NV) 
DIMENSION NOP(IOO), NPROG(500) 
C 
LIST OF CDC 1604 OPERATION CODES 
C 
AND SOME PSEUDO-OPERATIONS 
DATA (NOP= 
3RBSS»3RENDt3RDEC*3RcOMt3RZRO,3RARS.3RQRS»3RLRS»3RENQ. 
1 
3RALS.3ROLS.3RLLS»3RENA.3RlNA.3RLDA.3RLACt3RADD.3RSUB. 
23RLDQt3RLQc»3RSTA»3RSTQf3RAJP»3RQJP»3RMUl»3RDVI*3RMUF»3RDVF»3RFAD» 
33RFSB»3RFMUt3RFDV»3RSCA»3RSCQ»3RSSK.3RSSH.3RSST.3RSCLt3RSCMt3RSSU» 
43RLDL,3RADL,3RSBL.3RSTL,3RENI,3RlHI»3RLlU»3RLILt3RISK»3RIJPf3RSIUt 
53RSILt3RSAU.3RSALt3RlNTt3ROUT»3REQS»3RTHS»3RMEQ.3RMTH»3RRADt3RRSB. 
63RRAO,3RRSOt3REXF»3RSLJ»3RSLSt3RSEV) 
C 
INITIALISE 
NE=NV(2)=0 $ NTP= 6$ NPS=2 * REWIND NTP 
NT*1R* $ NT(2)=2R** 
NORG=LOC(NPROG) S NCOM=LOC( NIN) 
$NBASE=NORG-l 
C 
READ ONE CARD 
1 
READ 500,NSY,NOPC,NTAG,NlN 
$NTAG=1*NTAG 
PRINT 500»NSYtNOPC»NTAG»NIN 
500 
FORMAT(XR7.XR3»4XIl»2X20Rl) 
C 
TEST FOR STATEMENT LABEL 
IF(NSY.E0.7R 
) 10,2 
C 
STORE SYMBOL AND VALUE 
2 
NORG=NORG+NE $ NE = 0 
NPS=NPS+1 $ NT(NPS)=NSY $ NV(NPS)=NORG 
C 
LOOK FOR OPERATION IN NOP TABLE 
10 
DO 11 1=1,68$ IF(NOPC.EQ.NOP<I)) 12*11 
' 
11 
CONTINUE 
$ 1=40 
12 
NOPC=I $ WRlTE(NTP).NSY,NOPC,NTAG,NIN 
C 
WRITE TAPE FOR USE IN SECOND PASS 
PRINT 501iNSY»NOPC»NTAG,NlN(l ) 
$ IFU-4) 20,24,25 
C 
I.LE.4 INDICATES A PSEUDO-OPERATION 
20 
GO TO (21,22,23) , I 
C 
THIS IS AN ORDINARY 
OPERATION 
25 
NE=NE+1 $ N=l $ IF(NE-2) 1,31,31 
C 
BSS OPERATION 
21 
N=NSCAN(1)+NE 
31 
NORG=NORG+N $ NE=0 $ GO TO 1 
C 
DEC OPERATION 
23 
N=l $ GO TO 31 
C 
COM OPERATION 
24 
N=NSCAN(1) $ IF(NSY.EQ.7R 
) 33,32 
32 
NV(NPS)=NCOM 
33 
NCOM=NCOM+N $ GO TO 1 
C 
BEGIN SECOND PASS 
C 
AN END CARD HAS BEEN READ 
22 
REWIND NTP $ NE=0 $ NORG=LOC(NPROG) 
101 
READ (NTP) NSY,N0PC,NTAG,NIN 
IF(NSY.NE.7R 
.AND.NE.EQ.1 ) 130,131 
130 
NPROG(NORG-NBASE)=NTOP.OR.50000000B 
NE=0 $ NORG=NORG+l 
C 
TEST FOR PSEUDO-OPERATION 
131 
IF(N0PC-4) 102,101,103 
C 
ORDINARY OPERATION. FORM OCTAL INSTRUCTION 
103 
NOPD=(NOPC-5)*1000000B+NTAG*100000B+NSCAN(1) 
NE=NE+1 $ GO TO (111,112)·ΝΕ 
C 
SHIFT FIRST INSTRUCTION TO LEFT HALF OF WORD 
111 
NTOP=NOPD*2**24 $ GO TO 101 
112 
NPROG(NORG-NBASE) =NOPD.OR. NTOP 
113 
NE=0 $ NORG=NORG+l $ GO TO 101 
FUNCTION NSCAN(ZERO) 
C 
SCAN THE ADDRESS PART OF THE CARD WHICH IS IN 
THE ARRAY NIN IN FORMAT 20R1 
COMMON NIN(20),NT(100),NV(100)»NOPC»NPS 
EOUI VALENCE(N0RG,NV) 
DIMENSION NCAR(5)$ DATA(NCAR=1R ,lR+t1R-,1R.,1R*) 
EQUIVALENCE (X,N) 
N=0 $ JSCAN=1 $ DO 10 J=l,5 
FIG. 7.9 
A simple program to assemble symbolic instructions. 

7 · 10 AN ASSEMBLY PROGRAM 
281 
C 
TEST FIRST CHARACTER AGAINST BLANK,+ »-,. OR * 
IF(NIN.EQ.NCAR(J>) 11»10 
10 
CONTINUE $ IF(NIN-IO) 30,30*40 
11 
GO TO (21*30*30,23»24>*J 
C 
THE ADDRCSS FIELD IS BLANK 
21 
NSCAN=N 
$ RETURN 
C 
FIRST CHARACTER IS · GO TO 30 IF DEC CARD 
23 
IF(N0PC-3 
) 30,30,40 
C 
FIRST CHARACTER IS* TEST FOR ** 
24 
IF(NIN<2)-1R*> 25*21*25 
C 
SINGLE ♦ POSSIBLY FOLLOWED BY + OR -
25 
N=NORG S JSCAN=2 
$GO TO 32 
C 
AN INITIAL LETTER OR A . INDICATES THE START 
C 
OF AN ALPHANUMERIC SYMBOL 
40 
NW=0 
$ IS=2**36 
DO 41 J=JSCAN»20 $ IF(NIN<J).EO.1R 
C .OR. NINiJ).EQ.1R* 
.OR.NIN(J).EQ.1R-) 49*42 
C 
THE SYMBOL WILL BE PUT IN NW IN XA7 FORMAT 
42 
NW=NW+NIN<J)*IS 
41 
IS=IS/64 
C 
FILL IN BLANKS AT RIGHT HAND END 
49 
JSCAN=J $ DO 48 J=l»6 S NW=NW+IS*lR 
48 
lS=IS/64 
C 
FIND VALUE OF SYMBOL FROM SYMBOL TABLE 
DO 53 J=1»NPS S IF<NW.EQ,NT(J)) 51*53 
53 
CONTINUE $ PRINT 50,NW $ GO TO 32 
50 
FORMAT«17H UNDEFINED SYBMOL R7 ) 
51 
N=NV(J) 
32 
IF(NIN(JSCAN)-1R ) 30.21,30 
C 
SEARCH REMAINDER OF FIELD FOR A NUMBER 
30 
NSIGN=1 $ NI=0 $ NP=0 $ NDS=0 
DO 31 J=JSCAN,20 $ DO 62 K=l,5 
IF<NIN(J>.EQ.NCAR(K) ) 39,62 
62 
CONTINUE $ IF(NIN<J)-10) 33*34,35 
35 
PRINT NIN(J)$ GO TO 21 
36 
FORMATÎ18H ILLEGAL CHARACTER Rl) 
34 
NINCJ1-0 
C 
BUILD UP NUMBER IN NI 
33 
NI=10*NI+NIN(J) $ NDS=NDS+NP S GO TO 31 
39 
GO TO (61,31,43,44,35)»K 
43 
NSIGN=-1 $ GO TO 31 
C 
NP =0 BEFORE DECIMAL POINT* NP=1 AFTER POINT 
C 
NDS=NDS+NP COUNTS NUMBER OF DIGITS AFTER POINT 
44 
NP=1 
31 
CONTINUE 
61 
N=N+NI*NSIGN S IF(NP) 21*21*69 
69 
X=1C.*X/10.**NDS 5 GO TO 21 
END 
C 
PSEUDO-OPERATION·.DOES PREVIOUS WORD NEED A NOP 
102 
IF(NE) 120*120*121 
121 
NPROG(NORG-NBASE)=NTOP.OR#5 0000000B 
NE=0 $ NORG=NORG+l 
120 
GO TO (122*123*124)· NOPC 
C 
BSS 
122 
NORG=NORG+NSCAN(l) $ GO TO 101 
C 
DEC 
124 
NPROG(NORG-NBASE)=NSCAN(l) $ GO TO 113 
C 
AN END CARD HAS BEEN READ 
C 
END OF SECOND PASS 
123 
J = NORG-NBASE $ PRINT 501 *(NPROG(I)» I = 1·J) 
501 
F0RMAT(4020) 
END 
FIG. 7.9 (concluded) 

282 
7 CHARACTER 
MANIPULATION 
is an assembly-language routine that will find the location of any Fortran 
variable. The coding for LOC is 
LOC 
SI 
LOC A 
ENTRY 
SLJ 
SIU 
LIU 
LDA 
ARS 
INI 
SIU 
ENI 
SLJ 
1 
1 
1 
1 
1 
1 
LOC 
** 
S1 
LOC 
0 
24 
1 
LOCA 
** 
** 
END 
The routine ASEMBL reads a card. If there is a symbol on the card, it 
enters the symbol in the table NT and it puts the value of the symbol in 
the array NV. It compares the operation code with a table of all the 
machine codes and pseudo-operations. If the operation is an ordinary 
machine instruction, then the assembler up-dates the value of NORG. The 
1604 can hold two instructions per location, the counter NE is used to 
remember whether the first or second half of the word is being filled. If an 
END or BSS or DEC is encountered, then a new location is forced, but the 
contents of the previous half location must be allowed for. 
The routine NSCAN is used to scan the address part and to find 
out its value. The information on the cards is saved on a scratch tape. When 
an END card is encountered, the scratch tape is rewound and the second 
pass begins. In order to compress the routine we have omitted some 
precautions. The routine should check that the arrays NT and NPROG 
are not exceeded. When an error is detected, the routine should print a 
more informative message. 
The routine ASEMBL assembles code that performs correctly on 
the 1604 or 3600. The assembled code could be given access to library 
routines by putting the names and locations of the routines in the symbol 
table, for example, 
NT(3)=4RSINF 
$ 
NV(3) = LOC(SINF) 
EXTERNAL 
SINF 
would allow routines to use the sine function. The statement 
GO 
TO 
NPROG 
could be used to enter the assembled programs. 
Examples of elementary compilers written in an algebraic language 
have been given by Arden (1963) and by Huskey (1964). Most of the coding 
that goes into assemblers or compilers is quite straightforward, but, in the 

PROBLEMS 
283 
present state of the art, quite time consuming. If the compiler writer is 
prepared to accept a certain amount of inefficiency, then there are a number 
of elegant ways of writing compilers with a minimum of effort. Unfor-
tunately, if the compiled program is to be efficient, and if the compiler is 
to detect logical errors and produce intelligent diagnostics, then it seems 
that there is no simple concise general method. 
PROBLEMS 
1 ■ Explain the way in which the library routines do a formatted read. 
What form does the information take when it first comes into memory? 
How does the routine separate off the various characters ? Suppose the 
number 127.95 appeared on a card, and suppose the routine has 
reached the point where the characters are separated out with 
L(1)=1R1,L(2)=1R2,L(3)=1R7,L(4)=1R.,L(5)=1R9,L(6)=1R5, 
L(7) = 1 Rb. Write a piece of program to show how the conversion, from 
BCD characters to floating point binary, is done. 
2 ■ Modify the routine of Figure 7.5 so that it detects an error if (a) two 
signs appear, as in + +1.0 (b) the sign is embedded in the number as in 
1.—0. Modify the routine to allow an optional E followed by an 
exponent. 
3 ■ Modify the routine of Figure 7.5 so that it can read either numbers or 
words. See Section 7.6 for the description of such a routine. 
4 ■ It is well known that in a large sample of English sentences, E is the 
most commonly used letter. Suppose you have a book written in 
English and punched on cards. Write a program to count the number 
of words, the number of letters, the number of E's, the number of S's 
and the number of T's in the book. 
5 ■ Demonstrate the manipulation of characters by writing a program to 
do the following: print the contents of L(1),L(2),...,L(10). Use a 
format similar to 10(XI4) but do not suppress leading zeros. Thus, the 
results might appear as 
0000 0123 1742 and so on. 
This format is sometimes used in printing mathematical tables. 
6 ■ Modify the routine of Figure 7.7 so that it has an entry point PRINTA 
(ARGUE) which prints ARGUE in A8 format. 
7 ■ When manipulating words containing alphabetic information, it is 
often convenient to put one English word per computer word. 
Suppose L(l), L(2),... contains a sentence such as L(l) = 4HCOAL, 
L(2) = 2HIS, L(3) = 5HBLACK. We could print this by 
PRINT 500, L(1), L(2), L(3) 
500 
FORMAT(3A8) 

284 
7 CHARACTER 
MANIPULATION 
but there would be too many spaces between printed words. Show how 
to print the sentence with only one blank per word. In this case, a 
format of (A5,A3,A5) will suffice, but you must write a program that 
solves the general case. There are several completely different methods 
of solving this problem. 
8 ■ In Fortran, if X is of type REAL and I is of type integer, then 
X=l 
causes a conversion from fixed to floating point. PL/I does this and 
many other types of conversion automatically. In PL/I, if X is a 
floating-point variable and I is a character string variable, then 
X=l 
causes the appropriate transformation. Write a Fortran routine 
called STRING which does a similar conversion, for example, 
X = STRING(6H1.2547) should set X equal to 1.2547. 
9 ■ Go back to Problem 8 of Chapter 4. Rewrite that program so that it 
would read cards of the format specified in Section 7.10. 
10 ■ Modify the assembler of Section 7.10 so that it produces relocatable 
binary output in the form specified by Problem 9 of Chapter 6. 

8·1 
INTRODUCTION 
8 
EFFICIENCY 
I 
I 
Most programmers have decided ideas 
about efficiency in programming and many 
of these ideas are decidedly wrong. There is, 
for example, the common belief that 
symbolic coded programs are ipso facto 
more efficient than Fortran coded pro-
grams. While it is true that Fortran pro-
grams are sometimes slower than the 
equivalent machine-language program, it 
does not mean to say that they are less 
efficient. It all depends on what is meant by 
efficiency and what is meant by Fortran. 
There are three broad categories of 
programming. In the first, speed and 
accuracy are of prime importance. In this 
category are the large real-time programs 
such as those used in support of manned 
satellite operations. A statement by Major 
General C. H. Terhune (see Oettinger, 
■ 
1964) that changes to such a program costs 
from $200 to $1000 per instruction illus- 
I 
trates the prime features of these programs. 
■ 
Cost and manpower considerations have 
had to be completely ignored in the attain- 
I ■ 
■ 
ment of the necessary speed and accuracy. 
Hopefully, as machines become larger and 
faster, it will be possible to trade a small 
I 
loss of efficiency, in the use of the com-
puter, for a large gain of efficiency in the 
utilization of manpower. The second 
category covers those programs that are 
written in support of some research pro-
ject. This type of program tends to be 
modified quite frequently and individual 
parts of the program have a short lifetime. 
The third category covers those programs 
that are written by scientists or by profes-
sional programmers and are to be used on 
long production runs. 
In discussing efficiency, we should 
first understand the meaning of the word 
in the context of present-day computer 
activity. The most efficient program is the 
285 

286 
8 EFFICIENCY 
program that best fills the need for which it was designed. The scientist has 
a certain amount of time, money, and manpower at his disposal. He has to 
balance the demands on each commodity. In the present state of program-
ming it is very often the time or the manpower that constrains the progress 
of research. The running time of any program can be decreased by lavishing 
enough programming effort on it. For most programs in the second 
category the effort is usually better spent in some other task. It is in 
programs of the third category that the tendency is to think of speed as 
equivalent to efficiency. However, some simple considerations show that 
this is usually not so. Computer time can be wasted in some of the following 
ways: 
(1) By using the wrong program 
(2) By using the wrong method 
(3) By using the wrong data 
(4) By errors in the program which necessitate a rerun 
(5) By using the wrong machine 
(6) By having to rewrite the program because it cannot be 
extended 
(7) By inefficient coding 
Perhaps it is necessary to expand some of these comments. It is 
surely a common experience that in writing the first version of a program, 
one gains an insight into the problem that makes an alternative approach 
seem attractive. If the program is in Fortran, then it may be possible to 
make major improvements with relatively little effort. If the program is 
in symbolic code, then it may be difficult to change. Although the symbolic 
code is faster than the equivalent Fortran code, it may be much slower than 
some alternative way of doing the problem. Intelligent design of data input 
can save data errors. If programming effort is available, it might well be 
employed in improving the layout of the data or in incorporating checks on 
the data into the program. Symbolic programs are longer (in manuscript 
form) than Fortran programs ; they are also more flexible and consequently 
provide many more places for errors to be hidden. Symbolic programs are 
more difficult to run on a different system. As a final argument against 
symbolic programs, there is the fact that any program receiving extensive 
use is worth extending to a wider class of problems. A program that can 
almost do the problem you want it to do is of no great use unless it can be 
easily modified. 
8-2 
EFFICIENT PLANNING 
The most important factor in writing any program is to choose the correct 
method. Sometimes it pays to modify the problem slightly in order to 
improve the overall performance. A classic example of bad planning is the 

8 ■ 2 EFFICIENT PLANNING 
287 
XLOCF function in the Fortran II library. The statement 
l=XLOCF(Y) 
sets the integer I equal to the address of the location that contains Y. On 
the IBM 7090 the statement compiles as follows : 
CLA 
Y 
or possibly 
CLA Y 
TSX 
XLOC,4 
SXD 
SX4,4 
STO 
I 
TSX 
XLOC,4 
STO 
I 
The coding of XLOC will be explained presently. For the moment, let us 
consider a similar routine that is used as follows : 
l=LOC(Y) 
This statement compiles as 
TSX 
LOC,4 
TSX 
Y 
STO 
I 
The coding of the routine LOC is very simple. 
LOC 
CAL 
1,4 
ANA 
=077777 
ALS 
18 
TRA 
2,4 
The essence of the LOC routine is that the address of Y can be found in the 
location 1,4. To return to the routine XLOCF, in Fortran II any function 
that has a name ending in F expects its argument in the accumulator. The 
routine XLOCF is entered with the value of Y in the accumulator; this is 
of no immediate use, since it is the location of Y that is required. The 
routine XLOCF has to search back through —1,4 and —2,4 and so 
on until it finds a CLA instruction. The address part of this instruction is 
assumed to be the address of Y. Not only is the XLOCF much more 
complicated than LOC, it also fails to give the correct answer in many 
cases. The statement 
l-XLOCF(Y(J + 2)) 
might compile as 
LXD 
J,4 
CLA 
Y-1,4 
SXD 
SX4,4 
TSX 
XLOC,4 
STO 
I 

288 
8 EFFICIENCY 
The address of the preceding CLA instruction does not give the address of 
Y(J + 2). The LOC function does not fail in this case because the compiler 
computes the address of Y(J + 2) and places it in the location following the 
instruction TSX LOC,4. 
The writing of a program can be divided into three stages: namely, 
planning, coding, and debugging. The planning stage should include the 
writing down of all the mathematical equations. In large codes it should 
also include some consideration of how the tape or disk store will be used. 
The planning stage may include making flow charts. Despite the evidence 
of the textbooks, flow charts are not usually used for scientific programs. A 
flow chart is useful when some aspect of the problem cannot be written 
down in mathematical notation. For a large program there can usefully be 
a chart that shows the overall flow of control between the subroutines, and 
there may be flow charts for such things as the flow of information. The 
routine OPEN described in an earlier chapter is typical of the type of sub-
routine that can best be written with the use of a flow chart. 
The planning stage of the program should include some considera-
tion of a test problem. The most demoralizing stage of debugging comes 
when you can find no more errors in the code but when the answers are 
still wrong. Under these circumstances it is vital to have a test problem that 
you can follow through in a hand calculation. A problem to which an 
engineer thinks he knows the answer makes a most unsatisfactory test 
problem. It is my experience that problems chosen at random have a non-
random chance of proving themselves difficult to solve. One of the points 
to remember, in checking any program, is that the program solves a 
definite mathematical problem. The problem that it solves is some model 
of the problem that the engineer wishes to solve. The model is not the same 
as the original. The fact that an engineer has built a nuclear reactor, for 
example, and has found that it is exactly critical does not mean to say that 
the computer solution of the mathematical model will give exact criticality. 
The program may be wrong, or on the other hand it may be that the 
program is correct but that the model is slightly in error. 
The planning and the debugging stages take much longer than the 
writing of the code. During the coding stage, the programmer usually gains 
some further insight into the problem. At this stage he should be prepared 
to throw away the coding that has been done, and to start over again. If the 
coding is well done, then the debugging proceeds at a much faster pace. 
Coding that has not yet been debugged has little intrinsic value. If a method 
of improving the code can be found, then the improved methods should 
be used. Some problems are complex. Some programmers can make even 
simple problems appear complex. 
In the writing of very large codes, it is advisable to write a small 
code to simulate the main details of the large code. If the large code is a 
rewrite of some previous version then, of course, this would not be 
necessary. In some cases the simulation can be done by hand, but if a 

8 ■ 3 ON WRITING SUBROUTINES 
289 
machine is reasonably accessible, then the simulator should be pro-
grammed. Suppose a program is to be written to simulate the control 
system in a large nuclear reactor. The final program requires elaborate data 
input and produces a large amount of output. It requires integration in 
time and in three-space dimensions. It makes extensive use of the tape or 
disk store. It requires several hours to run each problem. The simulator 
would require no input. The input could be built-in with the use of data 
statements. It may produce a large amount of output but the output must 
be in a simple format. The simulator works in one or two space dimensions 
only and it allows only one of the many control options that are to be in 
the final program. This approximation makes the mathematical analysis of 
the program easier and makes it possible to fit the whole problem into the 
random-access memory. Other simplifications of the program can be made 
because it is not necessary to strive for great efficiency. It is very often 
possible to simplify a code by several orders of magnitude if some general-
purpose nonspecific method can be used. 
Any large program is composed of several interrelated factors. The 
simulator represents only an approximation to the final solution but it gives 
invaluable help in testing methods, in understanding the difficulties of the 
problem, in deciding on the feasibility of the final code; and if the final code 
does get written, the simulator is of help in the debugging stages. Debugging 
a code becomes more difficult as the size of the code increases. Simple 
factors can be important. For example, if the program deck can be held in 
one hand, then there is less chance of it being dropped or being shuffled. 
Many installations give high priority to short runs and to runs with a small 
amount of output. If the testing stage of the program is so elaborate that 
the run is penalized because the output is too large, or the running time is 
too long, or the job requires too many tapes, then the progress of debugging 
will be considerably hampered. It is much more efficient to change your 
mode of operation than to try to get special treatment from the operations 
staff. 
One of the most important aspects of the simulator is that it gives 
the programmer some feeling for the time-consuming parts of the job. A 
seemingly trivial aspect of the problem can sometimes use a high propor-
tion of the running time. In the SAP assembly program, the assembler 
spent about 20 percent of its time waiting for a tape to rewind. A minor 
change to the program allowed it to put half of its information on one tape 
and then it rewound that tape while the rest of the information was being 
written on another tape. 
8-3 
On WRITING SUBROUTINES 
The subroutine serves a number of purposes. It saves compiling time and 
makes it possible to write very large codes in Fortran. There is a minimum 

290 
8 EFFICIENCY 
time required for compiling the smallest possible routine; beyond this 
point, the compiling time increases at a rate that is faster than linear. Users 
of the Fortran II compiler pay a large penalty for compiling long sub-
routines. In Fortran 63 the compiling time does not increase rapidly with 
the size of the routine, because the compiler does not analyze the program 
in such great detail. Fortran II simulates the flow of control through all 
possible paths through the program. It does this in an attempt to optimize 
the use of index registers. The Fortran 63 compiler does a limited amount of 
checking. It can, for example, check that all the statement numbers used in 
IF, GO, TO, DO, READ, and WRITE statements correspond to actual 
statements in the program. The following type of error 
GO TO 200 
DO 200 l = 1,J 
200 
SUM = SUM + A(I) 
which consists of a jump into the range of a DO is detected by the Fortran II 
compiler but it is not detected by Fortran 63. 
The major importance of the subroutine is that it represents a 
convenient mode of thought and is a useful unit of organization. The art of 
writing large programs consists in being able to subdivide the job into a 
series of simple subroutines. Consider the following problem which arises 
in one method of solving Poisson's equation. The values of the variable 
S(I,J) are given for I = 1 through TV and J equals 1 through M. X(IJ) is the 
solution of the equation 
X{IJ+ 1) +X(I,J- 
1) +X(I+ 1,/) +X(I- 
1,/) - 4.0 * X(I,J) = 5(7,7) 
7 = 2 t o 7 V - l , / - 2 t o M - l 
together with the boundary condition that X(I,J) is zero when 1=1 
or N 
or / has the value 1 or M. The problem is to be solved by assuming as an 
initial guess that X is unity (except on the boundary) and by finding an 
improved estimate of X by the iterative scheme 
x*(i,J + l)+*-(/,/- \)+xn-\i+ 
i9j)+X"(i- 
V) 
- 4.0 * XVJ) = S(IJ) 
where X" denotes the value of X after n iterations. The problem is coded 
by setting up Nsubsidiary problems, which have the form: given the vector 
XS, find XC where 
XC(J + 1) +XC(J- 1) - 4.0 * XC(J) =XS(J) 
for J = 2 through M - 1, and where XC(\) = XC(N) = 0.0. This subsidiary 
problem is solved in the routine SOLVER. The coding of the main sub-
routine is shown in Figure 8.1. The coding of SOLVER is not relevant in 

8 · 3 ON WRITING SUBROUTINES 
291 
c 
100 
102 
C 
250 
C 
201 
220 
200 
C 
300 
500 
SUBROUTINE POIS(N.M) 
COMMON 
X(100.100).S(100.100)»XS(100).XC< 100) 
SET UP INITIAL GUESS 
M1»M-1 $ DO 102 I»1»N 
$ DO 100 J=2»M1 
X<I.J)=1. $ IF<I.EQ.l.OR.I.EQ.N) X U » J ) * 0 . 
CONTINUE 
X(1.1 )«X( Ι·Μ)=0· 
IT«0 $ N1»N-1 
BEGIN ITERATION 
TOTER«0. 
DO 200 I»2.N1 
SOLVE FOR ONE COLUMN 
DO 201 J*2»M1 
XS<J)«S<I»J)-X<I-1»J)-X<I+l.J) 
CALL SOLVERtXS.XC.N.TOTER) 
DO 220 J=2»M1 
X(I.J)«XC(J) 
CONTINUE 
END OF ONE ITERATION 
IT-IT+1 $ IFUT.GT.50 .OR. TOTER.LE·1·Ε-5) GO TO 300 
PRINT 500.IT.TOTER 
$ GO TO 250 
PRINT 500.IT.TOTER·<<X<I »J).I*1·Ν)♦J*l.M) 
FORMAT(16.E15.6/(1OF 12.6)) 
END 
FIG. 8.1 
A routine to solve Poisson's equation 
this example. What is relevant is the way in which the introduction of this 
subroutine has simplified the appearance of the problem. The two-
dimensional problem has been split into two one-dimensional problems. 
During the writing of the routine SOLVER it is not necessary to think 
about two dimensions ; as far as this subroutine is concerned the problem 
is a one-dimensional one. If it is decided at some later stage that the 
iteration method should be changed to a scheme such as 
Y(U + l) +r(/,/- l) +*- H/ +1,/) +x*v- V) - 4.0 * Y(IJ) = s(/,y) 
and 
XVJ) =Xn~ \hJ) + a[F(/,r) -Xn~ HV)] 
then only the subroutine SOLVER needs to be changed. 
One of the statements in the main program, namely, 
220 
X(I,J) = XC(J) 
illustrates a point that often occurs in this type of work. This statement 
would appear to be inefficient since it introduces into the calculation an 
extra step that is not strictly necessary. However, the manipulation of one-
dimensional arrays is always more efficient than the use of two-dimensional 
arrays. The routine SOLVER could have used the elements X(I,J) in their 
original positions, but the compiler would almost certainly waste a great 
amount of time in computing the subscripts. An alternative approach is 
to turn the method around, replacing subscript / by subscript / and make 
use of the fact that X(l J),X(2J),X(3J) 
and so on, are in successive loca-
tions and could be regarded as the the elements of a vector. In most applica-
tions it is more efficient in the long run to keep the coding simple and not 
to take advantage of the peculiarities of the compiler. 

292 
8 EFFICIENCY 
The division of a program into a series of subroutines should be 
done so that (a) the program is divided into a number of simpler logical 
units. In the example just given, the complicated two-dimensional program 
was split into the main program which handled the rows, and the subroutine 
SOLVER which handled the columns of the arrays, (b) The division 
should isolate the independent units of the program. This division makes it 
easier to debug the program and it makes it very much easier and safer to 
modify it at a later stage, (c) Each subroutine should be of a reasonable 
length; something like 50 Fortran statements would be an average length. 
If a subroutine is too long, it becomes difficult to add statements without 
introducing errors, (d) The opportunity to use subroutines from a previous 
job should be borne in mind. This is not always possible and is very often 
not relevant. A surprising number of people never seem to be able to use 
any of the subroutines from a previous job. 
It is good practice to adopt some simple programming rules. For 
example, if the constant π is used in several places in the program, then 
Pl = 3.14159265 
will serve to fix its value. If it is used in several subroutines, then PI could 
be put in Common. If a constant of this sort is used at several places in a 
program, writing it as a constant each time it is used is likely to cause at 
least one error in which it is mispunched or written down incorrectly. 
Statement numbers should be used in a reasonably systematic way. 
One scheme is to use 10 through 15, then go on to 20 through 25, and so 
on. If statements have to be inserted at a later stage, then they can be given 
numbers ending in 6 through 9, and they can be chosen within the decade 
of their nearest neighbors. 
The names of variables should be chosen with human fallibility in 
mind. Names such as XII and XIX are liable to be confused when you are 
trying to check through the program. Variables ending in a zero or the 
letter O are likely to cause trouble. There is no doubt that you can instruct 
the keypunch operator to distinguish between A0 and AO, but in practice 
you will find it difficult to make the distinction when reading through the 
program. Long names tend to be misspelled. Certain variables such as X 
and I tend to be used without consciously thinking about it. If X is put in 
Common, there is a good chance that it will be accidentally overwritten at 
some point in the program. 
8-4 
DEBUGGING 
The most powerful aid to debugging is realization that mistakes do occur. 
The good programmer is not the one who does not make any mistakes. The 
good programmer makes mistakes, but he finds them out quickly, and most 

8 · 4 DEBUGGING 
293 
important, he does not leave any major mistakes in the program when it is 
supposed to be fully checked out. Assuming, then, that mistakes will happen, 
a few rules suggest themselves. The input data should be printed out. If it 
is manipulated during input, it should be printed both before and after the 
manipulation. Data errors, particularly in the test problem can easily be 
made. If a program contains more than a few subroutines, there should be 
a print out as each subroutine is entered. If a subroutine contains several 
branches, there should be some record of what branch was taken. Some 
programmers like to take each routine and to test it in isolation. There are 
some routines for which this is the best thing to do—for example, a sub-
routine to solve a differential equation, or to invert a matrix, or the 
subroutine OPEN which appeared in an earlier chapter. On the other 
hand, some routines are such an integral part of the whole program that 
it is more trouble to write a test program than it is to test them as part of 
the original program. In any program involving arrays, the program should 
be tested on a small array. One of the most vital aspects of debugging is 
to make use of a lot of short computer runs. Any problem that requires 
more than two or three minutes on each debug run is likely to be very 
difficult to check out. We have discussed the advantages of simulation on 
very large programs. The use of long runs to detect errors in a program 
should be reserved until all other methods have failed to reveal any more 
errors. 
The inexpert programmer makes one major mistake in attempting 
to debug programs : he assumes that the program contains no errors ; when 
the first dozen or so errors have forced themselves upon his attention, he 
still assumes that there are no more errors. The writing of a small program 
of two or three hundred Fortran statements should be done in the following 
way: The program should be written out. The novice programmer will use a 
mixture of mathematical notation, flow charts, and English language 
description at this stage. When the program has been written out, it can 
be transcribed into Fortran. Programmers with reasonable competence in 
Fortran usually omit the initial writing out and code directly into Fortran. 
The program should be punched and a printed listing of the program 
should be obtained. If the program is to make use of any data, then the 
data should be punched and listed at this time. The programmer should 
now take the listing of the program and data and go through the program 
simulating the behavior of the machine. It is not necessary to make any 
arithmetic checks at this stage, but the programmer should make sure that 
the program correctly represents the ideas that he set out out to program. 
The number and the modes of the arguments to subroutines should be 
checked. The general flow of the program should be examined and errors 
in the overall logic of the program should be detected. It is at this stage, 
when the general flow of the program is being considered, that debug 
printing should be inserted. The guiding principle should be: If the 
program happens to be wrong in this block of coding, will there be enough 

294 
8 EFFICIENCY 
printing to track down the error? Having corrected all the obvious errors, 
the program should be compiled. The compilation usually produces some 
diagnostics. When corrections are made, the programmer should be careful 
to make sure that he has checked all the diagnostics. The compiler produces 
a list of subroutines that are referenced by each of the compiled routines. 
This list should be checked for any unusual entries. Any unrecognized entry 
is either a library routine, and the names of library routines are usually 
quite distinctive, or it is the name of some subscripted variable that should 
have appeared in a Dimension statement. 
When the program loads correctly and produces some numbers, the 
next stage is to check that these numbers are correct. It is usually not 
necessary to check to the full accuracy of the machine. If enough inter-
mediate results have been printed out, a check using a slide-rule calculation 
is sufficient. If a result is seen to be wrong, and if the cause of the error is 
not obvious, then another run should be made, and all the variables on 
which the erroneous result depends should be printed out. The important 
fact to bear in mind is that if the answer is wrong, then the program (with 
very rare exceptions) is wrong. There are circumstances in which the 
available evidence seems contradictory, however it is no use saying that 
X = Y + Z and X is wrong but Y and Z are correct, therefore X must be 
correct. If the cause of the discrepancy is not obvious then it is simply a 
matter of putting in more printing until it is obvious. If the cause of an 
error is found, then the next few stages of the calculation should be checked 
in an attempt to detect some of the remaining errors. The sort of reasoning 
to be used might go as follows: X should have the value 10.2. X has the 
value 21.7. Z has the value 9.8 and it is correct. Y has the value 11.9, 
whereas it should have the value 20.0. The cause of the error in Y is traced. 
However, we see that if Y had had the value 11.9, then X should have had the 
value 2.1. A check of the program reveals that X should have been Y — Z 
not Y + Z. Chapter 4 of McCracken and Dorn (1964) gives a detailed 
history of the checking of one routine. 
In programs that use a disk or tape store, it is useful to label each 
record. Suppose that the tape has a record containing the array A(1,J), then 
a record containing the array B(1,J), then A(2,J), and so on. At the front 
of each record the program could put the symbol A or B and the value of 
the first index. When the tape is read back, then these symbols and numbers 
could be printed out. This printing will give a check on such errors as 
forgetting to rewind a tape, or making errors in buffering, or getting two 
tapes switched around. 
Given a well-defined problem with a well-defined method, then 
the debugging can proceed in a systematic way. Ill-defined problems tend 
to occur in data-processing applications. To give an example: An experi-
mental device is installed in an earth satellite. The readings from the 
instruments are transmitted to a recording station on the ground. The 
problem is to write a program that will read the data and compute various 

8 · 4 DEBUGGING 
295 
statistics. The difficulties arise because the data may be damaged while it is 
being transmitted to earth. A human observer could look at the data and 
tell, in some circumstances, when there were obvious errors. Applying the 
same techniques in an automatic program is not straightforward and 
usually requires experimenting with various strategies. 
Well-defined problems for which there is no foolproof method 
occur in many computer applications. The problem of playing the game of 
chess or the problem of pattern recognition are two examples. Many of the 
problems that arise in physics or engineering can be expressed as a problem 
of minimization. The design of an optical lens is one such problem (see 
Stavroudis (1964)). There are several standard methods of finding the 
mimimum of a well-behaved function. In many practical problems a 
systematic search for a minimum would take years of computing for each 
problem. These problems can only be solved by using standard techniques 
plus some understanding of the physical principles involved. Some of the 
situations that arise in practice are not as simple as the examples in the 
text book. In one large program, the following problem was encountered. 
For any value of x the function f(x) could be computed by the program. 
f(x) was a very complicated function; in fact, it required the solution of a 
two-dimensional partial differential equation by an iterative method. The 
program was such that / could be computed to an accuracy of n decimal 
places in a time of 2n minutes. The problem was to find the value of x that 
made/(x) equal to zero. Iff was computed to full accuracy, then it was 
known that the root could be found by the method of false position; if 
xx and x2 are two approximations to the root, then a better approximation 
could be found by 
f(Xl) 
-f(Xl) 
If/is computed to high accuracy during the early stages of the search, then 
an appreciable amount of time is wasted. If the accuracy is too low, then 
the root-finding process might fail to converge. In the case of these ill-defined 
methods the only effective rule is to start with the small simple problems 
before trying the complex problems. The large problems should be the last 
to be tried. If a large problem fails to converge, then there is always the 
feeling that it would have converged eventually. With a small problem, it 
is possible to do a sufficient number of iterations to settle the question. 
The type of printing to be used in debugging a program was 
discussed in the section on Namelist. To repeat what was said at that stage : 
The printing should give a clear indication of what variables are being 
printed. When the program has been debugged, then the printing should be 
suppressed but it should not be removed entirely. There is always the 
chance that the program will go wrong at some later date, and it is very 
useful to be able to restore the debug printing without having to recall 
which were the important intermediate results. 

296 
8 EFFICIENCY 
Some Fortran systems have a special facility for debug printing. In 
the Fortran II system, the programmer makes a debug option at the time 
of compilation. The compiler produces the usual binary cards, and in 
addition it punches out a debug dictionary. The dictionary contains the 
names and locations of the variables used in the subroutine, and it also lists 
the location of all the statements. The request for debug printing is made by 
control cards which are put at the front of the deck. The control cards are 
interpreted by the loader, which inserts instructions in the subroutines, so 
that a print routine is called at the appropriate statements. The control 
cards can specify the variables to be printed and restrictions can be made so 
that printing occurs when certain conditions are satisfied. The Fortran II 
system has several advantages. Debug printing can be inserted or deleted 
without having to recompile the subroutine. The print spécification is very 
simple and the printed output lists the names of the variables. The control 
cards are put at the front of the deck so that the danger of introducing 
accidental errors is minimized. The alternative to a special debug feature is 
for the programmer to insert print statements at the appropriate places in 
his program. In Fortran II this alternative is not an attractive one. Compila-
tion is very slow. Printing with formats is liable to produce errors, especially 
in the hands of inexperienced programmers, and although it is possible to 
arrange the format so that the variable names will be printed, the writing 
of these formats is tedious. In a modern and efficient Fortran system, these 
arguments for a special debug feature are no longer valid. Fortran II 
compiling speeds can be improved by a factor of ten or more. A feature 
such as Namelist provides the programmer with a foolproof and convenient 
way of producing properly labeled output. 
8-5 
EFFICIENCY of FORTRAN CODING 
Before discussing the efficiency of the code produced by the compiler, let 
us reiterate the statement that the choice of method and the overall plan 
of attack will usually have much more effect on efficiency than the pecca-
dilloes of the compiler. Computer programs, particularly large programs, 
can be divided into two categories. There are the programs in which most 
of the time is spent in one or two inner loops, and there are the programs 
in which the time is equally divided between all parts of the program. The 
multidimensional mesh-type problems are in the former class. In a long 
problem, more than 90 percent of the time is spent in a routine of about 50 
Fortran statements; the complete code might amount to five or ten 
thousand statements. It is obviously well worth while to optimize the inner 
loop. This repeatedly used subroutine could be written in Fortran, and 
when the program is working, this one routine could be speeded up by 
writing a machine-language version. The Fortran 63 and Fortran IV 
compilers have an option by which the symbolic code can be punched out 
on cards. A routine of this sort can be optimized by changing the order of a 

8 - 5 EFFICIENCY OF FORTRAN CODING 
297 
few cards and by discarding some of the cards. The Fortran compiler is an 
example of a program that has no inner loop. An appreciable proportion 
of the compiling time is spent in the scanning routines, but this situation 
should improve as the character handling facilities of the hardware are 
improved. For programs that have no inner loop there is little point in 
trying to optimize parts of the program. The main effort in programming 
should be devoted to choosing the best possible method of attack. 
It is a simple matter to check the efficiency of a compiler : Write 
a subroutine in Fortran, and see what sort of code the compiler produces. 
It will be found that the compiler makes a very efficient code when compiling 
arithmetic expressions. It usually codes DO loops without wasting more 
than one or two instructions. The place where the compiler usually produces 
quite inefficient code is in the treatment of variables with two or more 
subscripts. The example given at the end of Chapter 4 should be referred to. 
It was shown that the compiler can produce many redundant subscript 
operations. 
The treatment of multidimensional subscripts varies from compiler 
to compiler. Fortran II and Fortran IV are superior to Fortran 63 in this 
respect. The efficient calculation of subscripts is very difficult, and the 
efficiency of any compiler should not be relied upon until the compiled 
code has been studied. The compiler writers have usually been careful, but 
there is no guarantee that their solutions will solve all problems. A really 
foolproof solution to the problem would require changes in the hardware 
of the machine. Indexed variables are usually less than 100 decimal and a 
very fast multiplier for such numbers would obviate the need for elaborate 
schemes for minimizing subscript combinations. 
The fact that subscripts are not compiled efficiently should not 
prevent them from being used. The program can be written using whatever 
subscripts are convenient. When the program is working, any particularly 
sensitive part of the code can be changed to single subscript operation. 
An interesting example of the effects of subscripting is given by 
Cain et al. (1964). They have a routine that evaluates the sum of certain 
coefficients times certain spherical harmonics—the sum actually represents 
the earth's magnetic field. There are two versions of the routine. One 
version is written in ordinary Fortran using Do loops and subscripts of a 
two-dimensional array. The second version is also written in Fortran but 
uses no Do loops and no variable subscripts. The times for these sub-
routines are given below. 
Subscript version 
No subscript version 
12.4 
8.3 
6.8 
4.4 
8.7 
6.0 
IBM 7094 (Model I) 
IBM 7094 (Model II) 
CDC 3600 
The times are in milliseconds. 

298 
8 EFFICIENCY 
8-6 
The EFFICIENT USE of MEMORY 
One of the objections to Fortran, in the days when it was first introduced, 
was that it was wasteful of memory. The complaint was not altogether just. 
Fortran made some aspects of programming easier, with the result that 
styles of programming changed and there was a consequent increase in the 
size of the program. It is, however, true that an appreciable amount of 
memory is wasted. Much of the waste is due to the division of programs 
into small subroutines. Symbolic programs tend to be written in larger 
units: the Fortran 63 compiler, for example, is a single machine-language 
routine of 20,000 instructions. The division of Fortran programs into small 
subroutines wastes space in the following ways. If the constant 1.0 occurs 
in several routines, it is stored in several places in the memory. In fact, in 
Fortran II, the constant 1.0 and several other standard constants are stored 
in every subroutine whether they are used or not. It would be possible for 
the loader to eliminate this duplication, but this is not done. Each sub-
routine uses a certain amount of internal storage for storing the inter-
mediate results in arithmetic statements. This amounts to only five or ten 
locations in each routine, but in a large program the total is not negligible. 
The major waste of memory is due to the way in which local variables in 
different routines use different parts of the memory. The programmer can 
control this factor by putting most of the variables in Common. One way 
of doing this is to define a block of Common that can be used as erasable 
storage by any subroutine. Suppose that A,B, and C are local variables in 
subroutine ONE and X,Y, and Z are local to subroutine TWO, then 
statements such as 
SUBROUTINE ONE 
COMMON /ERASE/ A(10),B,C(4,6) 
END 
SUBROUTINE TWO 
COMMON /ERASE/ X(20),Y,Z,FILL(14) 
END 
would force them to share the same locations. The variable FILL is used 
to ensure that the ERASE block has the same length in both routines. It 
will be remembered that the names of variables in a given Common block 
do not have to agree, but the lengths of the blocks must agree. This system 
can only be used if subroutine ONE does not call subroutine TWO (or 
vice versa). Of course, it would not be difficult to remember while writing 
the program to only use ERASE in disjoint routines. 
The systems and standard programs in Fortran tend to take an 
unnecessarily large amount of memory. Part of this is due to the genuine 
complexity of the programs, and part of it is due to bad design. The usual 

8 - 6 THE EFFICIENT USE OF MEMORY 
299 
fault of the standard subroutines is that they are designed to cope with all 
eventualities. For example, the print programs have several hundred 
locations devoted to complex or double-precision output; programs that 
do not use these features still have to pay the penalty in loss of memory. 
This problem is particularly severe on the IBM 7090 where each instruction 
takes a full word. In typical applications over a third of the memory is 
pre-empted by the system and library routines. 
One method of using the memory efficiently is to allocate storage 
in a dynamic way; that is, the use of the memory changes as the program 
develops. Let us consider the subroutine POIS which was developed earlier 
in this chapter. Suppose we wish to write the routine so that it can deal with 
the largest possible problem. Let MAXS denote the maximum number of 
locations that can be made available. In Fortran II and Fortran 63 it is 
possible to find out the value of MAXS by examining certain of the system 
locations, but first of all let us be clear about the meaning of MAXS. 
Suppose the program has been written and suppose it contains the statement 
COMMON 
STORE(1) 
If the dimension of STORE is increased by a small amount, then the 
program will still load. If the dimension is increased sufficiently, then there 
will come a stage when the loader will refuse to load the program. We will 
define MAXS to be the largest possible dimension of STORE for which 
the program will still load. 
The subroutine POIS uses the arrays X,S,XS, and XC. In the 
routine, as it is currently written, the dimension of these arrays is fixed. If 
the dimensions were to be made variable, then X and S would be of 
dimension N by M, and XS and XC would have dimension M. The largest 
possible problem that can be solved has 
2 * N * ( M + 1 ) 
<MAXS 
The subroutine is called in the following way 
J 1 = N * M 
$ J 2 = J 1 + J 1 
$ 
J3=J2*M 
I F(J3 + M - MAXS) 
100,100,101 
101 
PRINT 500,N,M 
$ 
STOP 
500 
FORMAT(19 H PROBLEM TOO LARGE. 
2I6) 
100 
CALL POIS(STORE,STORE(J1+1)STORE(J2+1), 
C STORE(J3+1),N,M) 
The dimension statement in the subroutine is changed to 
SUBROUTINE POIS(X,S,XS,XC,N,M) 
DIMENSION X(N,2),S(N,M),XS(M),XC(M) 

300 
8 EFFICIENCY 
One method of finding the value of M AXS is to assemble the routine with 
a small dimension of STORE, and then to examine the storage map. In 
Fortran II the limits of the memory are stored in location 99, and a simple 
Fap coded routine picks up the value of MAXS. The useful point of this 
method is that it gives the exact value for this particular run. If the program 
is changed on a subsequent run, then the limits in location 99, which are set 
by the loader, will be changed accordingly. The same effect can be achieved 
in Fortran 63 by using the library routine MEMREC*. This technique is 
not possible in Fortran IV since the loader uses any spare store for input-
output buffers. There are, of course, methods of defeating most systems, but 
it seems unfortunate that in Fortran IV the system should find it necessary 
to prevent the programmer using the maximum amount of memory. 
Variable dimensions cannot be used in Fortran II, but the dynamic 
allocation of storage is directly applicable. As has been demonstrated 
earlier, the length of a vector need not be specified at the time at which a 
routine is compiled. The routine POIS could be written in Fortran II 
providing the arrays X and S were changed to vectors and providing 
statements such as 
X(l,J) = 0. 
were changed to 
J 1 = I + J * N - J 
X(J1) = 0. 
Variable dimensions are a convenience but not a necessity. 
There are various special devices for saving storage space, some of 
which are illustrated in the following problem. We wish to write a program 
to perform the iteration 
xn = Axn~1 
where x is a vector of dimension N, and A is a sparse matrix of order N 
by N. The maximum value of N is 1000. The matrix A is sparse if most of 
the A(I,J) are zero. Sparse matrices arise in mesh-type problems, but in 
that case the nonzero elements are distributed in some regular fashion. In 
this problem there is no regularity. The data for the problem will be 
presented on cards in the way shown in Figure 8.2, in a fairly obvious 
notation. The first number gives the value of N. The data that follows 
800 
11 
J10 12.6 
-8.247 
J99 
27.65 
J125 0.12 
12 
J29 11.68 
FIG. 8.2 Data to specify the elements of a sparse matrix 

3 · 6 THE EFFICIENT USE OF MEMORY 
301 
indicates that A(1,10),A(1,11),A(1,99),A(U25),A(2,29), and so on are 
nonzero and that their values are 12.6,-8.247, and so on. It is impossible 
to store A as a Fortran array. It must be stored in two vectors. The vector 
B contains the value of J and the value of A(I,J). L(I) indicates the position 
in the array B where the information for row I begins. For the data given 
above, 
B = 10 
12.6 11 -8.247 99 27.65 125.12 29 11.68 
L=1 
9 
The way in which this information is used should make things easier to 
understand. In order to find 
SUM = Σ A(I,J)*X(J) 
J = l 
we would proceed as follows. 
COMMON L(1000),B(5000),IB(5000),X(1000) 
EQUIVALENCE(BJB) 
SUM = 0. 
J1=L(I) 
$ 
J2=L(l + 1 ) - 2 
DO 100 K=J1,J2,2 
J3=IB(K) 
100 
SUM = SUM + B(K+1)*X(J3) 
This is obviously a compact and convenient way of storing the array. In 
order to read the array into the memory we will use the routine RDNUM 
described in Chapter 7. 
Figure 8.3 gives a program to read the data of Figure 8.2. The 
routine is designed so that reading stops when an unrecognized word or 
symbol is found. 
K=l S CALL RDINT(N) S DO 20 I»1,N 
20 
L(I)»0 $ ERR=0. 
12 
CALL RDNUM(K) $ CALL RPTYPE(Ml) $ IF(M1) 1,2,3 
C 
A LETTER HAS BEEN READ· IS IT I OR J 
1 
IF(M.EO.IHI) GO TO 10 
IF(M.NE.IHJ) 
GO TO 2 
C 
THE LETTER J HAS BEEN READ. READ THE VALUE OF J 
JL-J $ CALL RDINT(J) $ IF(J.LT.JL .OR.J.GT.N) GO TO 13 
GO TO 12 
C 
THE LETTER I HAS BEEN READ· READ THE VALUE OF I 
10 
CALL RDINT(I) $ L(I)=K $ J"l $ GO TO 12 
13 
PRINT 14,I»JL,J $ ERR-1. $ GO TO 12 
14 
FORMAT124H 
ERROR IN J 
1=16,3H J=2I6> 
C 
A NUMBER HAS BEEN READ» PUT IT IN 
I B U + 1 ) 
3 
IB(K)»J f IB(K+1)«M 
J«J+1 $ Κ=Κ+2 $ GO TO 12 
C 
ALL DATA HAS BEEN READ 
2 
L<N+1)*K $ K«K-1 
PRINT 5 0 0 , ( L < I ) » I « 1 , N ) 
$ PRINT 
5 0 1 · ( I B ( I ) , 1 = 1 , K ) 
500 
FORMAT(IOIIO) 
501 
FORMAT(5(I5,E15.6)) 
IF(ERRI 31,31,30 
30 
STOP 
31 
CONTINUE 
FIG. 8.3 Program to read the data shown in Figure 8.2 

302 
8 EFFICIENCY 
An alternative way of storing the contents of a sparse array is to 
put the elements into one vector array and to store a pattern of bits which 
indicate the zero and nonzero elements. This method tends to be more 
advantageous on small arrays. Suppose that n is less than 47. Theyth bit 
in the word L(I) could be used to indicate whether A(I,J) is zero or non-
zero. Before any data is read, the array L is set to zero. During the reading 
process, if A(I,J) is discovered to be nonzero then 
L(l) = L(l).OR.2**(J-1) 
can be used to record this fact. 
Techniques for storing lists which have a branching structure have 
been developed in the LISP system (see Section 9.6). Some of these methods 
can easily be used within Fortran. 
8-7 
CHAIN and OVERLAY 
This is a method of storing the program on magnetic tape and of bringing 
parts of the program into the memory as they are required. The most 
simple implementation of this feature is in the Fortran II system. The card 
deck for the complete program is arranged in the order, 
* 
CHAIN(1,B3) 
Part 1 
* 
CHAIN(2,B3) 
Part 2 
* 
CHA!N(3,B3) 
Part 3 
and so on. The symbol B3 denotes the tape on which the program is to be 
stored. The physical (rather than the logical) tape number is used because 
of a historical accident: the Chain feature was developed after the rest of 
the system. The numbers 1,2,3 are used for identification of the parts of 
the program. Any numbers between 1 and 32767 can be used. Part n 
denotes an ordinary Fortran deck consisting of one main program and any 
number of subroutines. The routines may be in binary or in Fortran form. 
The system goes through the deck and translates any of the routines that are 
in Fortran. The loader is called in. It loads all the routines up as far as the 
second Chain card. It gets any requested routines from the library tape. At 
this stage the memory contains the following, 
Locations 
0 -> 99 
miscellaneous system information 
100 -> n 
routines for part 1 and the associated library routines 
n + 1 -> 32767 
some empty locations followed by the loader 

8 · 7 CHAIN AND OVERLAY 
303 
Where n denotes the highest location (other than locations in Common) 
used by the program and library routines. The loader writes two records 
on tape B3. The first record is short: it contains 1, which is the number of 
the current link; it contains 99 and n which denote the limits of the memory 
used by this link; and it contains the entry point for the main program in 
this link. The second record contains the contents of locations 99 through 
n. Having written this record, the loader now loads the routines for the 
second link. The loading of this second link also starts at location 100. 
During execution only one link is in memory at any one time. When the 
loading of link 2 and all its library routines is complete, then the loader 
writes link 2 onto tape. It repeats this loading and writing process for 
link 3. Each link produces two records on the Chain tape. Finally the 
loader rewinds the chain tape, reads in the first link, and enters the first 
main program. 
During the execution of the program,'any routines can call for any 
other chain by 
CALL 
CHAIN(N,B3) 
CHAIN is an ordinary library routine which was loaded as part of the 
original loading process. CHAIN makes sure that input-output operations 
are complete. It searches through tape B3, reading the short records and 
skipping over the long records until it comes to the record with the label 
N, or it comes to an end of file. In the latter case it rewinds the tape and 
searches once more for the correct record. When the correct record is 
found, CHAIN transfers part of itself into locations higher than 32560— 
that is, above the highest location used by Common. This relocated program 
reads in the new link and enters the main program of that link. The new 
link overwrites the old link. The links can communicate through Common 
or through auxiliary memory such as tape or disk. 
Each link on a chain tape is in fixed, not relocatable, binary. Each 
link is complete, it contains all its own library routines. Chain tapes can be 
copied like any other tape, and this is of great value in large programs. 
Chain tapes can be generated on one run and saved for use on a later 
run. On a big program this can save the 5 minutes or more which the loader 
would otherwise take in generating the chain tape. Mitchell (1963) has 
written a routine that copies chain links from one tape to another. It enables 
the program to recompile and reload one link of a chain without having to 
reload all the other links. 
There are several advantages to the Chain method. It makes it 
possible to run programs that are too large to fit in the memory all at one 
time. It saves having to reload the program. It can save memory space. A 
large program might typically consist of three parts. Part one handles the 
input of data and the setting up of the problem; part two does the bulk of 
the calculation; and part three edits the results. The three parts could be 

304 
8 EFFICIENCY 
put in separate links of a chain. While part two is in memory, it can use all 
the space not being used by program as Common memory space. It is not 
restricted by the memory space used by the other links. Unfortunately, the 
library and monitor routines are so large that it is difficult to compress a 
link into less than 7000 locations decimal. 
In the Fortran II system the chain link contains a complete block 
of program including all the library routines. The Fortran 63 overlay 
system does not include a copy of the library routines with each link and it 
allows several links to be in core at one time. As a consequence of this, the 
organization of the program can be more flexible and the reading in of a 
new link is not so time consuming. The arrangement of a Fortran II 
program can be described by the following diagram 
Computer memory -> 
Time 
link 1 
| 
link 2 
link 3 
whereas the Fortran 63 overlay job can be illustrated by: 
Computer memory -> 
Time 
main program 
overlay 1 segment 1 
I 
main program 
overlay 1 segment 2 
main program 
overlay 2 segment 1 
main program 
overlay 2 segment 2 
A Fortran 63 overlay job consists of a main program and several overlays. 
Each overlay may have several segments. An overlay and a segment is a 
block of routines that occupies a contiguous set of memory locations. 
The generation of the overlay tape is similar to the process des-
cribed for Fortran II. The program deck is subdivided by control cards that 
indicate whether the cards that follow refer to the main program block, to 
an overlay, or to a segment. The control card also indicates the tape on 
which the program is to be stored and it gives the number of the overlay or 
segment. The system goes through the input tape and generates a relocat-
able binary tape. Then the loader goes through this tape and generates an 
absolute binary tape. Finally the loader loads the main program block. This 
main block consists of one main program, any number of subroutines, and 
any number of library routines. The main block remains in memory at all 
times. In most applications the main block contains a short main program 
together with the data and library routines that are used in every overlay. 
Library routines that are only used in one overlay would be included in 
that overlay and not put in the main block. The main block can cause any 
overlay to be brought into memory by 
CALL 
OVERLAYS,/?,*?) 

8 · 7 CHAIN AND OVERLAY 
305 
where n is the number of the overlay tape, o is the number of the overlay, 
and p is a parameter. An overlay consists of one main program and any 
number of subroutines. Main programs within an overlay can have a formal 
parameter; this parameter is transmitted in the parameter/? given above. 
CALL OVERLAY reads the overlay from tape and enters the main 
program of the overlay. An overlay can call in a segment by means of 
CALL 
SEGMENT(H,/?,O,S) 
where s is the segment number. 
During the execution of the program there can be a maximum 
of the main program block, one overlay, and one segment, in the memory. 
An overlay cannot call another overlay; it must first return to the main 
block. This restriction ensures that the overlay that is being read into 
memory does not destroy the calling sequence. An overlay may call a 
segment; a segment cannot call a segment. The essential difference between 
the Fortran II and the Fortran 63 system is that the Fortran 63 loader 
acknowledges the fact that the main block, an overlay, and a segment can 
be in memory at one time. It allows an overlay to reference subroutines or 
common blocks that are in the main block. Similarly, a segment can 
reference routines or common blocks in the overlay. The converse is not 
true. The main block cannot reference routines in an overlay, neither can 
an overlay reference a segment. This restriction simplifies the operation of 
the loader: the loader does not have to remember forward references. 
Unlabeled Common is always in the memory. Labeled Common blocks 
are stored along with the routine in which they first occur. Thus, if Common 
block /ABC/ does not occur in any routine in the main program block, but 
does occur in routine in overlay 1, then it will be stored in overlay 1. It can 
be referenced by any routine in overlay 1 or any of the associated segments. 
It cannot be referenced in any other overlay. If overlay 1 is in memory, then 
bringing any other overlay into memory will destroy the contents of 
Common block /ABC/. An overlay tape can be saved for running on a 
subsequent occasion. We have explained that certain parts of the monitor 
system are in memory at all times: we will refer to this part of the system as 
the resident monitor. The basic I/O routines are usually part of the resident 
monitor. A Fortran 63 overlay tape contains absolute binary instructions. 
Some of these instructions assume certain fixed locations for the resident 
monitor, a fixed location for the first word in Common, and so on. If 
changes to the monitor system cause changes to any of these fixed locations, 
then the overlay tape has to be regenerated from the relocatable binary 
version of the program. 
The Fortran IV overlay system on the 7090 is one stage more com-
plicated than the Fortran 63 system. It can be illustrated by the following 
diagram : 

306 
8 EFFICIENCY 
Computer memory -> 
Time 
link 0 
link 1 
1 
link 0 
link 2 
link 0 
link 2 
link 3 
linkO 
link 2 
link 3 
link 4 
linkO 
link 2 
link 3 
link 5 
linkO 
link 2 
link 3 
link 6 
link 7 
and so on. The division of the program into the various links is governed 
by control cards. The control cards have a simple method for indicating 
that link 1 and link 2, for example, should start at the same location in 
memory. Link 1 and link 2 cannot be in memory at the same time. Similarly, 
there is a way of indicating that the first location of link 3 comes after the 
last location of link 2, so that these links can be in memory at the same 
time. The loader makes several passes through the relocatable binary tape, 
it can therefore allow both forward and backward references. Any links 
that are in memory at the same time can use routines or control sections 
from either link. There is no equivalent to the call CHAIN or the call 
OVERLAY statement. In link 0 of a Fortran IV program 
CALL ALPHA(ANY,ARGUE,MENTS) 
can have one of two effects. If ALPHA is in link 0 or link 1, then control 
will go to ALPHA. If ALPHA is in link 3, then control will pass to an 
overlay program; this will bring links 2 and 3 into memory and then it will 
pass control to ALPHA. The overlay mechanism is controlled in the 
following way: The loader examines every CALL statement. Calls within a 
link or to links lower down the tree are loaded in the normal manner. Calls 
to a routine in a higher link receive special treatment. At load time—that 
is, before execution begins— 
CALL ALPHA 
is changed to 
CALL TEMPA? 
where TEMPw is a location containing 
TEMPA? 
OP 
ALPHAJink number of ALPHA 
TXI 
Overlay routine 
At the start of execution the instruction OP is set equal to an operation that 
does nothing. When the CALL is encountered, control passes through 
TEMPtf + 1 to the Overlay routine. This brings down the appropriate links. 
The Overlay routine now sets OP to give a direct jump to ALPHA. At any 
later stage if another link is brought into memory over the top of the link 
containing ALPHA then OP will be set back to a no operation code. 

8 · 8 T I M I N G 
307 
The Fortran IV system on the IBM 7040 does not use the 7090 
system. It insists on a direct 
CALL 
CHAIN(N) 
to bring in a new link. The 7090 system is ingenious but it would seem that 
the disadvantages of the system outweigh its advantages. The disadvan-
tages are that it complicates the loader; it uses an excessive amount of space 
in memory to store the overlay cross reference table; it eliminates the 
possibility of intelligently anticipating the positioning of the overlay tape; it 
could lead the inexpert programmer to produce very inefficient programs. 
The bringing of a link into memory is a time-consuming process; a 
programmer should be given direct control of the transfer. 
8"8 
TIMING 
Any program that is used extensively should be examined to see how it 
spends its time. The structures of programs vary so widely that no one rule 
can be applied to all programs. We can only give a few examples. The first 
step is to find out about the clock and its relation to real time. The most 
straightforward kind of clock simply shows the time of day, or the time 
that has elapsed since the start of the job. A library routine with a name 
such as CLOCK is entered by CALL CLOCK(X), and this sets X equal to 
the current time in seconds. 
CALL 
CLOCK(XI) 
$ 
CALL 
ALPHA 
$ 
CALL 
CLOCK(X2) 
X = X 2 - X 1 
sets X equal to the time taken by routine ALPHA. Some clocks are accurate 
to the nearest millisecond, some are only accurate to the nearest second. 
The routine to be timed should be repeated until a measurable time has 
elapsed. In a time-sharing system, the monitor should provide each program 
with its own clock. Each clock is incremented only when the corresponding 
program is using time. In all systems the user should take care to find out 
what sort of time the clock shows; we mentioned in Section 5.7 that 
interrupts may bias the time attributed to any routine. The provision of a 
clock that shows the time used by the program would seem to be an 
essential feature of every system, but, unfortunately, many hardware and 
software systems do not provide adequate means for timing programs. 
Certain programs have an inner loop that is used repeatedly. The 
mesh-type problem discussed in Section 8.3 is typical of many problems in 
which the major portion of the time is spent in one or two subroutines. For 
these problems it is worthwhile to examine the symbolic listing of the code 
for the inner routine. In a typical run, suppose the routine POIS is entered 
100 times and suppose N is 100 and M is 100. Subroutine SOLVER will 

308 
8 EFFICIENCY 
be called 10,000 times and parts of SOLVER will be obeyed 100xM*N 
or 1,000,000 times. Within this inner loop the saving of one instruction 
will save several seconds in an entire run. The importance of such a saving 
is relative to the overall running time. The saving of several seconds an 
hour is not important, but the saving of several seconds a minute could be 
significant. 
Data processing often involves the repeated use of one portion of 
the program. If the data contains 10,000 records of 100 characters each, then 
1,000,000 operations will be performed in reading the data. Fortran-
formatted read routines are often quite slow. In Fortran 63 the formatted 
read of one character takes about 125 microseconds. A simple special-
purpose symbolic-language routine can process one character in about 
8 microseconds. This represents a saving of nearly 2 minutes on the whole 
job. An integration along the orbit of a satellite or any other moving body 
is another example where one routine is used many thousands of times. In 
all of these problems it is possible to save significant amounts of time by 
writing the program in Fortran and then either modifying the Fortran or 
writing a small piece of the code in symbolic language. By modifying the 
Fortran we mean eliminating two- and three-dimensional subscripts, dis-
pensing with unnecessary DO loops, and so on. These modifications need 
only be done in the innermost loop. The symbolic language routines should 
be kept very short and simple, for example: 
DECODE (7,500,BUFFER) 
J,K,L 
500 
FORMAT (12,13,12) 
could be replaced by 
CALL 
DECRI (BUFFER,1,I) 
J = l(1)*10+I(2) 
K=l(3)*100+I(4)*10+I(5) 
L=l(6)*10+I(7) 
where DECRI( Α,Ν,Ι ) is a simple symbolic-language routine that takes the 
words A(l), A(2),...,A(N) and splits them into separate characters, placing 
the result in 1(1), 1(2),... . The process carried out by DECRI is made 
deliberately simple so that the routine finds many uses. 
If a program uses tapes or disks, it is sometimes more difficult to 
gauge its efficiency. On some machines it is quite helpful to actually watch 
the operation of the machine on one or two occasions. The console 
indicates the current status of the program and a watch on the console and 
the I/O units can reveal some significant facts. It might show that the 
machine is often waiting for a tape to rewind or that it is continually moving 
a disk arm from one extreme to another. In a multiprocessing system the 
user is to a great extent in the hands of the systems designers. The best the 
user can do is to find out how the system works and how this operation 
affects his problem. 

PROBLEMS 
309 
As an antidote to these comments, we repeat the caution which 
was made earlier. Efficiency has many different aspects. The programmer 
should make a reasonable effort to see that time is not wasted, but he 
should guard against wasting his time, and against complicating the 
program. 
PROBLEMS 
1 ■ Give several reasons why subroutines are important. What factors should 
be considered when dividing a large program into subroutines? How 
does the subroutine communicate with the other routines? What are the 
particular advantages of the several methods of communication? 
2 ■ A program requires the simultaneous use of four arrays whose names 
are A, B, C, and D. The program begins with 
COMMON X(10000) 
READ 500,L,M,N 
500 
FORMAT(3I10) 
A has to have the dimension N by N. B is N by M, C is M by M, and D 
is L by M by N. Show how the 10,000 locations of X can be used to 
store the arrays. 
3 ■ One method of storing the data from a sparse array was given in 
Section 8.2. Describe some alternative methods and give the appro-
priate coding for 
N 
SUM = Σ A(I,J) * X(J) 
J=l 
Compare the efficiency of the code with the method given in the text. 
4 ■ In Fortran II, what is the minimum time to load a chain of 10,000 
words ? Assume that the chain is one magnetic tape with a density of 
556 bits per inch and that the tape moves at 112.5 inches per second. 
Why are the overlays of Fortran 63 and Fortran IV usually shorter than 
the Fortran II chains ? 
5 ■ Consider the Fortran IV overlay that was illustrated in Section 8.7. In 
that job, links 4 and 5 could not be in core at the same time. Suppose 
that ALPHA is in link 4 and BETA is in link 5. A programmer found 
that ALPHA took 1 millisecond to execute and BETA took 2.5 milli-
seconds to execute. He estimated that 
DO 100 1 = 1,10 
CALL ALPHA(X(I),Y) 
100 
CALL BETA(Y,Z,W(I)) 
would take 35 milliseconds but it actually took 500 milliseconds. 
Explain this discrepancy. ALPHA and BETA did not contain any 
READ or WRITE statements. 

310 
8 EFFICIENCY 
6 ■ The final Fortran 63 overlay tape contains absolute binary instructions. 
Why do changes to the monitor require the overlay tape to be re-
written? This suggests that a relocatable overlay tape would offer some 
advantages. What information would such a tape need to contain? 
What would be the advantages and disadvantages of a relocatable as 
compared to an absolute binary tape ? 
7 ■ Explain why the use of multidimensional arrays in Fortran usually leads 
to inefficient programs and give one method of avoiding the in-
efficiency. 
8 ■ Does the system you are using allow you to read the clock? How is this 
clock used and what sort of time does it show ? For example, is the clock 
stopped during interrupts? Can the clock give misleading results and if 
so is there any way of measuring the execution time of a routine ? 

9-1 
INTRODUCTION 
9 
CALL 
ALPHA(A) 
311 
The first computing machines were simply 
devices for doing elaborate calculations. 
The structure of these early machines 
shows clearly that their designers were 
trying to automate the sort of calculation 
that can be carried out on a desk calculator. 
We can see that the modern computer is 
not just a calculating machine; it is a device 
for manipulating symbols. The ability to 
manipulate symbols has made possible the 
software systems that are an essential part 
of a modern computing system. We have 
seen some of the developments of these 
systems, but up to this point little has been 
said about advanced hardware and soft-
ware techniques for using the memory. In 
the early computers the memory was a 
device for storing numbers and instruc-
tions. The memory was divided into loca-
tions. Each location was identified by a 
numeric address. The concept of an 
address was extended by introducing sym-
bolic addresses. Each location could be 
given a symbolic name and these names 
were translated into an address by the 
assembler. When the idea of separately 
assembled subroutines was introduced, it 
was no longer possible for the assembler to 
translate the symbolic name into an 
address. The assembler allocated a nominal 
origin and the loader fixed the final value 
of the address. The communication of 
information between subroutines intro-
duced several new ways of using addresses. 
The first method of communication occurs 
in the Fortran statement 
At execution time, the value of X is sent to 
the sine subroutine and the value of Y is 
returned. The second method of communi-
cation occurs in a statement such as 
THE DYNAMIC 
USE OF 
MEMORY 

312 
9 THE D Y N A M I C USE OF MEMORY 
In this case it is the address of A and not the value of A which is trans-
mitted. If A is a scalar quantity, there is little difference between com-
municating a number or an address. If A is an array, there is a significant 
difference. The use of Common block names and the use of external 
symbols introduces the third method of communication. In this method an 
alphanumeric name is communicated to the loader and the loader associates 
a unique address with each unique symbol. 
There are many other different ways of allocating addresses and 
there are many other ways of using memory. In Fortran systems nearly all 
of the addresses are fixed at loading time and almost all of the calculations 
are concerned with fixed-length numbers. There are systems in which 
addresses are not fixed at load time. There are systems in which the 
addresses change frequently throughout the course of the calculation. 
Fixed-length numbers are satisfactory for many scientific calculations but 
there are problems in which the size of numbers and the length of strings 
of characters, must be varied throughout the calculation. We have discussed 
the difference between logical and physical I/O units. This distinction 
between a logical and a physical quantity can also be applied to addresses 
of locations in the memory. There are systems in which both logical and 
physical addresses are used. The programmer uses a logical address. 
The hardware and the software decide on the correspondence between the 
logical address and the actual physical location that is to be used. 
9-2 
ARRAYS and the STORAGE MAPPING FUNCTION 
Fortran II assumes that the maximum size of every array is known at the 
time of writing the program. Fortran IV allows the size of an array to be 
varied at execution time, but as we have seen, the use of variable dimen-
sions in Fortran is not without inconvenience. The Fortran programs that 
we will describe in this section illustrate an alternative method of treating 
arrays. 
The Fortran DIMENSION statement is replaced by 
CALL DECLARE (X,LM,N) 
which declares X to be an array of size L by M by N. If X is not a three-
dimensional array, then N, or both M and N, should be unity. The 
DECLARE statement allocates space for X. X can be undeclared, and the 
space will be returned to a central pool if 
CALL DECLARE(X,0,0,0) 
is given. The routine ADD is typical of the routines that can be used to 
manipulate arrays. 

9 · 2 ARRAYS AND THE STORAGE MAPPING FUNCTION 
313 
CALL ADD(X,Y,Z) 
may be used to add the array Y to the array Z and put the result in X. 
Before considering some of the other features of the array mani-
pulation, let us consider the coding for the routine DECLARE which is 
given in Figure 9.1. The routine adds one to the integer J and then it saves 
SUBROUTINE DECLARE <Ι·!.·Μ.Ν) 
COMMON /MATRIX/JtK, #LM< 50) »MM (50) ·ΝΜ(50) »NBASE(50) »S< 10000) 
DATA (J«0).(<«1) 
IF (L.EO.O) GO TO 200 
C 
DECLARE MATRIX 
J1*J=J+1 $ IF(J.LE.50) GO TO 101 
DO 110 Jl«1.50 
$ IF(LM( JD.EO.O) GO TO 101 
110 CONTINUE 
PRINT 500 $ STOP 
500 F0RMAT(16H TOO MANY ARRAYS) 
101 LM(J1)=L S MM(J1)=M $ NM(J1)«N S NBASE(J1)«K 
K*K+L»M»N 
$I=J1 $ IF(K.LE.10000) RETURN 
102 PRINT 501 $ STOP 
501 F0RMATO1H ALL MATRIX SPACE HAS BEEN USED) 
C 
REMOVE MATRIX 
200 Jl-NBASE(I) $ J2=LM(I)*MM(I)*NM(I) 
C 
RE-ARRANGE ALL BASE ADRRtSSES AND 
C 
SQUEEZE OUT SPACE USED BY ARRAY I 
DO 211 J4-1.50 
I F fNBASE(J4).GT.Jl) NBASE(J4)*NBASE < JA)-J2 
211 CONTINUE 
K*K-J2 S J2-J1+J2-1 $ DO 210 J4*J1»K 
J2«J2+1 
210 S(J4)=SU2) 
LM(I)=0 
END 
FIG. 9.1 The subroutine DECI ARE 
the values of L,M, and N in locations LM(J),MM(J), and NM(J). The 
integer J is stored in X. This ensures that whenever X is referenced, the 
routine can find the place where L,M, and N are stored. The routine 
allocates locations S(K) through S(K + L*M*N — 1) to the array X and 
it stores the integer K in NBASE(J). A DECLARE with L equal to zero 
causes the L*M*N locations of S to be returned and J is reduced by unity. 
Up to 50 arrays may be in use at any one time. The total space used by all 
of the arrays must not exceed 10,000. DECLARE operates correctly on 
integer or real numbers. ADD assumes that all arrays contain real numbers. 
The coding for ADD is shown in Figure 9.2. The code simply 
picks up the values of each dimension from the appropriate place in the 
arrays LM,MM, and NM. ADD checks that the first dimensions of 
X, Y, and Z are consistent. It should repeat the check for the other 
SUBROUTINE ADD(IX » IY»IZ) 
COMMON /MATRIX/JtK,LM(50).MM(50)tNM(50)»NBASE(50)»S(10000) 
L«LM(IX) S M=MM(IX) S N«NM(IX) 
IF(LM(IY).EO«L .AND. LM(IZ).EO.L) GO TO 100 
PRINT 500tL»LM(IY),LM(IZ) 
500 FORMAT(31H E3ROR IN ADD. DIMENSIONS WRONG 316) 
100 J1=NBASE( IX) $ J2»NBASE(IY) $ J3»NBASEUZ) 
J4*L«M»N 
$ DO 110 J5»1«J4 
S( J l )«S( J2)«-S< J3) $ J1»J1 + 1 $ J2-J2-M 
110 
J3=J3+1 
END 
FIG. 9.2 The Subroutine ADD 

314 
9 THE D Y N A M I C USE OF MEMORY 
dimensions. Having found the dimensions and the place in the array S in 
which X,Y, and Z are stored then ADD uses a simple loop to do the 
addition. In a series of calls such as 
CALL DECLARE(P,I*I-1,K,L) 
CALL DECLARE(Q,I*I-1,K,L) 
CALL DECLARE(R,I*I-1,K,L) 
CALL ADD(R,P,Q) 
CALL DECLARE(P,0,0,0) 
CALL DECLARE(P,N*N-M,N-M,M-N) 
the space used within the vector S is automatically allocated and reallocated 
during the execution of the program. The programmer does not have to 
keep track of the use of the memory. 
The coding of ADD illustrates how the routines for other array 
functions could be written. It would also be necessary to provide a routine 
such as 
CALL SETXEQY(X,I,J,K,Y) 
which would set the element X(I,J,K) equal to the scalar quantity Y and 
the routine 
CALL SETYEQX(X,I,J,K,Y) 
which does the converse operation. There are several other features that 
could be added to the routines. For example, if a call to DECLARE 
introduces a matrix that would bring the total amount of space used to 
more than 10,000, then the routine could save part of the vector S on a 
disk. This would give the programmer an efTectively infinite amount of 
memory without his having to take any particular precautions. The form 
of the DECLARE statement could be simplified by using NAMELIST to 
transmit some of the arguments. 
The matrix manipulation routines that have been described could 
be very useful in some Fortran calculations. However, we are more 
interested in presenting the concept of the dynamic memory allocation than 
in discussing the practical application of these ideas in Fortran. The 
essence of the ideas is as follows. If X is the name of an array, then the 
contents of location X point to the place where information on X can be 
found. The term "storage mapping function" is used to describe the 
algorithm that converts a name and a set of subscripts into a memory 
location. In the system just described the element X(I,J,K) is stored in 
location S(N) where 
N = I - 1 + (J - 1)*LM(IX) + (K - 1)*LM(IX)*MM(IX) + NBASE(IX) 

9 ■ 2 ARRAYS AND THE STORAGE MAPPING FUNCTION 
315 
where IX is the integer which is stored in location X. The storage mapping 
function in this case is a linear function of the subscripts but there are 
occasions in which more complicated functions would be appropriate. For 
example, in the case of triangular arrays it would save memory space if a 
nonlinear mapping function is used. 
The real advantages of this type of memory allocation is only 
gained when the system is embedded in the compiler. This is done in Algol 
(Randell and Russell, 1964), in MAD (Arden, 1963), and in many other 
compilers. In these compilers the information that we transmitted in the 
call to DECLARE is contained in an ARRAY or DIMENSION statement, 
and it is not necessary to use routines such as SETXEQY since the normal 
X(U,K)=Y 
causes the compiler to generate code that is the equivalent of 
CALL SETXEQY(X,I,J,K,Y) 
The advantage of this new method of memory allocation is that the size of 
each array can easily be varied at execution time and the amount of memory 
that is used depends on the actual size of the arrays and not on the maximum 
size. The disadvantages of this dynamic allocation will become apparent if 
the compiler does not optimize the calculation of subscripts, but as we have 
seen, the Fortran compilers do not always compile subscripts efficiently. 
In the routine DECLARE we stored the dimensions of X in the 
vectors LM,MM, and NM. It is more usual to store this information in a 
set of locations which are contiguous to X. The scheme 
Location 
Quantity stored 
X 
the BCD name of X 
X + I 
location of X(l,l,l) 
X-f 2 
number of dimensions 
X + 3 
first dimension 
X + 4 
second dimension 
is typical ofthat used in many compilers. The set of locations X, X + 1, ... 
is sometimes called a dope vector. There is an alternative kind of dope 
vector which can save the multiplications that are usually necessary when 
evaluating multidimensional subscripts. The statement 
ARRAY 
A(4,3) 

316 
9 THE DYNAMIC USE OF MEMORY 
could produce the dope vector 
ZRO 7 
ZRO 4 
BCD 1A 
ZRO 2 
A ZRO ABASE-1 
ZRO 0 
ZRO 3 
ZRO 6 
ZRO 9 
first dimension plus second dimension 
first dimension 
name of the array 
number of dimensions 
location of A( 1,1)— 1 
location of A( 1,1)—location of A(l,l) 
location of A(2,l)—location of A(l,l) 
location of A(3,l)—location of A(l,l) 
location of A(4,l)—location of A(l,l) 
Let m(L) denote the contents of location L; then A(I,J) is stored in 
location m(A) + m(A + I) + J. Fortran would store the elements of A in the 
order A(1,1),A(2,1),.... We are assuming that the array is stored in the 
more conventional order A(1,1),A(1,2),.... ABASE denotes the location 
of A(l,l). Locations A+l,A + 2, and A + 3 contain the location of A(1,J), 
A(2,J), and A(3,J) relative to that of A(1,J). By using this information it is 
possible to find the location of A(I,J) without any multiplication. This 
technique can be extended to any number of dimensions. If X has dimen-
sions 11,12, ... IN, then the dope vector will be of length N + 3 + II + 12 + 
... IN and will contain 
ZRO 
I N + — + 12 + 11 
ZRO 
ZRO 
ZRO 
BCD 
ZRO 
X 
ZRO 
ZRO 
ZRO 
ZRO 
ZRO 
ZRO 
13+12 + 11 
12+11 
11 
1X 
N 
XBASE - 1 
0 
location of 
location of 
0 
location of 
X(2,1 
1 ) - location of 
X(1,1 
1 ) 
location of 
X(I1,1 
1) - location of 
X(1,1 
1) 
X(1,2 
1) - location of 
X(1,1 
1) 
ZRO 
location of 
X(1,12,.. .,1 ) - location of 
X(1,1,.. .,1 ) 
The dope vector is long but its length is short compared to the 11*12*... IN 
locations that the vector itself occupies, and this form of dope vector does 
eliminate the time-consuming multiplications in evaluating subscripts. The 
location of X(J1,J2,...,JN) is 
m(X)+m(X+J1) + m(X+l1+J2) + m(X+l1+!2+J3) 
+ m(X+H+l2+l3+J4) + · · +JN 
The values of II, Il +I2, and so on, can be found from locations m(X —3), 
m(X —4), and so on. 

9 ■ 3 THE MEMORY STACK 
317 
9-3 
The MEMORY STACK 
The memory used by Fortran variables can be divided into three classes, 
namely, Common, local, and parametric. Common applies to all variables 
that occur in Common or labeled Common statements. Parametric 
variables are those variables that are the arguments of a routine. These 
variables appear on the SUBROUTINE (or FUNCTION) card. All 
variables that are not Common or parametric are local. In the program 
shown in Figure 9.3, the variables are 
Common 
Local 
Parametric 
CS,CB,C,D 
S,Z,T,U,I,L 
A,B,P,XP,XQ,XR 
PROGRAM MAIN 
COMMON /AP/CS.CB(7tl2) 
CS=21.65 
CB(1*4)=0· 
CALL ONE(CStCB) 
CALL TWO(CB(7»l)) 
CALL THREE(CB(1*2)tCB(1*3)»CS+2.> 
END 
SUBROUTINE ONE<A*3) 
COMMON /AXLE/C<20)»D 
DIMENSION S( 120)*B<7 .12) 
Z=A+B<1»4) 
CALL THRFE<A»Z*S(5)) 
• · · 
END 
SUBROUTINE TWO(P) 
COMMON /AXLE/ C(20)»D 
DIMENSION T<10*20)*U<97) 
CALL ALPHA 
CALL BETA 
T(3.M=P+D 
DO 100 1=1.10 
END 
SUBROUTINE THREE(XP*XO*XR) 
DIMENSION Li 10) 
CALL FOUR<XO) 
• · · 
END 
FIG. 9.3 
Examples of common, local, and parametric variables 

318 
9 THE D Y N A M I C USE OF MEMORY 
Since the same name can occur in different contexts in different routines, 
then we should say that "S in routine ONE is local" rather than "S is 
local " but to avoid this prolixity we will not use the same name twice. In 
Figure 9.4 we show the connections between the routines. A line between 
two routines denotes that one routine calls the other, the calling routine 
appears above the called routines. A routine may appear in the diagram in 
several different places if it is called from several routines. 
FIG. 9.4 
The hierarchy of subroutine calls 
Consider the use of a local variable such as the variable Z. Z can 
be used with routine ONE, and it can also be used in routine THREE and 
routine FOUR, since Z appears in the call to THREE and indirectly in the 
call to FOUR. By considering the general case we see that a local variable 
is accessible to the routine in which it is declared and it may be accessible to 
the routines that are at a lower level and on the same branch. A local 
variable is not accessible to routines that are on the same or higher levels 
and it is not accessible to routines on other branches. The value of Z 
cannot be used or changed in any way while the computer is obeying 
instructions in the routines MAIN,TWO,ALPHA, or BETA. It can be 
used in THREE and FOUR on the occasion on which they are called from 
ONE but it cannot be used when THREE is called from MAIN. Apart 
from one small difficulty which we will discuss later, it is obvious that the 
variables S and Z of ONE cannot be in use at the same time as the variables 
T,U, and I of TWO. The same memory locations could be shared between 
these variables, with a consequent saving of 121 locations. In general, local 
storage on different branches of a tree can be overlapped with a consequent 
saving of a great proportion of the memory space. There is a simple 
mechanism by which this sharing can be implemented, using a software 
device called a " stack." 
The stack is used in the implementation of many Algol compilers 
and it is used in PL/1. Fortran could be made to use a stack, although no 
Fortran compilers do so. We will explain the stack mechanism in the 
context of the Fortran routines shown in Figure 9.3. The memory for all 
Common variables and all program instructions are done in the normal 
Fortran manner. The memory space left unused at the end of the loading 
process is allocated to the stack. Let these locations be denoted as 
LEVEL 3 
LEVEL 2 
LEVEL 1 
LEVEL 0 

9 ■ 3 THE MEMORY STACK 
319 
STACK(l), STACK(2), ... ,STACK(NSMAX). Let NSP denote a variable 
called the " stack pointer." NSP is set to unity at the beginning of execution. 
The value of NSP changes from time to time but it must never exceed 
NSMAX. In a typical system the memory might be arranged as follows: 
I/O and interrupt routines 
Fortran and library routines and labeled Common 
STACK 
Blank Common 
The size of NSMAX depends on how much memory remains when all 
other demands have been met. The stack is used for all local storage. On 
entering the routine MAIN no local storage is needed (in this example, 
most main programs do need local storage). On entering the routine ONE 
—that is, at execution time when the CALL ONE statement is encountered, 
the system allocates location STACK(NSP) to the local variable Z, 
allocates STACK(NSP+ 1) through STACK(NSP+ 120) to the local vector 
S(l) through S(120), and then the system adds 121 to NSP. This allocation 
is done in the prologue of routine ONE. It requires the temporary address 
of Z to be replaced by the address of STACK(NSP). References to S 
also need their addresses changed. The advantage of the base register 
technique of the IBM 360 should be apparent in this context. On the 
IBM 360 one register contains the base address of all local variables and the 
prologue simply puts the address of STACK(NSP) into this register. To 
continue with the program, on entering subroutine THREE the system 
allocates STACK(NSP) through STACK(NSP + 9) to the local variables 
L(l) through L(10), and it adds 10 to NSP. Let us assume that routine 
FOUR does not use any local variables. On returning from FOUR, the 
RETURN statement of THREE is eventually reached. At this point the 
system replaces NSP by NSP-10. When the RETURN statement in ONE 
is reached, the system replaces NSP by NSP—121. NSP now has the value 
unity. Now the program enters subroutine TWO and the system allocates 
STACK(NSP) to I, STACK(NSP+1) through STACK(NSP + 200) to 
T, and STACK(NSP + 201) through STACK(NSP + 297) to U; then it 
replaces NSP by NSP+ 298. It is apparent that I and T are now using the 
memory space that was formerly used by S,Z, and L. Going through the 
whole of the program it appears that the stack is used in the following way : 
Routine 
Stack variables 
ONE 
Z,S(120) 
THREE 
L(10) 
TWO 
l,T(10,20),U(97) 
THREE 
L(10) 
Notice that L is at STACK(122) on the first call to THREE and it is at 
STACK(l) on the second call to THREE. 

320 
9 THE D Y N A M I C USE OF MEMORY 
The general procedure for using the stack is to get the memory 
space for all local variables from the stack whenever a routine is entered and 
to release this space to the stack whenever there is an exit from the routine. 
This process automatically keeps track of branches and levels. If dynamic 
memory allocation of this sort is used, then the techniques for handling 
arrays, which were discussed in the previous section, form a natural part 
of the system. Arrays of any size and any number of arrays may be used, as 
long as the total amount of local storage does not exceed NSMAX. If 
NSMAX is exceeded, then either the system must put part of the stack onto 
some I/O unit or it must terminate the job. 
It is possible to simulate the stack mechanism with a normal 
Fortran compiler. Figure 9.5 shows how the routines of Figure 9.3 can be 
rewritten in order to use a stack for the local variables. It is not suggested 
that one should use this technique in practical programs, but the new 
version of the routines does illustrate almost all of the features of a stack 
mechanism. The feature that is missing is the use of the stack for local 
variables that are hidden in the routine. If we refer back to the example at 
PROGRAM MAIN 
COMMON ZAP/ CS.CB(7.12) 
COMMON NSP»STAC<(10ÜOO)»NSPMAX 
NSP-1 $ NSPMAX=10000 
CS-21.65 S CB(1.4)=0. 
CALL ONE (CS.CB) 
CALL TW0(CB(7.11)) 
CALL THREE<CB< 1»2).CB< 1.3)»CS+2·) 
END 
SUBROUTINE 
0 Ν Ε < Α · 3 ) 
COMMON N S P t S T A C M 1 0 0 0 0 ) tNSPMAX 
N S P - N S P + 1 2 1 
$ 
I F ( N S P . G U I O O O O ) 
1 · 2 
1 
PRINT 500 * STOP 
500 
F0RMAT(29H STACK IS FULL IN ROUTINE ONE) 
2 
CALL ONES(A.B.STACK(NSP-121)»STACK(NSP-120)) 
NSP=NSP-121 
END 
SUBROUTINE ONES(A.B.Z.S) 
COMMON /AXLE/ C(20)»D 
DIMENSION S<120).B<7 ♦ 12 ) 
Z«A+B(1»4) 
CALL THREE<A»Z.S<5)) 
• · · 
END 
FIG. 9.5 
Part of Figure 8.3 rewritten to use STACK 

9 ■ 4 VIRTUAL M E M O R Y 
321 
the end of Chapter 4, it is seen that the compiler generates variables such as 
.NSTIFF, .CERASE, and .ERASER which are used for temporary local 
storage. In an integrated system these variables would also be stored in 
the stack. 
Most Algol compilers use the stack method of allocating the 
memory. PL/1 uses three methods of allocating memory space. The 
programmer can declare variables to be either STATIC, DYNAMIC, or 
CONTROLLED. The STATIC variables are allocated space at load time 
and in this respect they are similar to Fortran variables. DYNAMIC 
variables are allocated space on entry to a block and the space is released 
on exit from the block. This is precisely the stack mechanism that we have 
just described. CONTROLLED variables also receive their memory space 
from the stack but the programmer has to give an ALLOCATE statement 
when he wishes the space to be allocated and he must give a FREE state-
ment when the space is to be returned to the stack. Further details will be 
given in Chapter 10. 
The great advantage of the stack mechanism is that it automatically 
makes the best use of the memory. The disadvantage is that it increases the 
number of instructions that must be obeyed at execution time; the routine 
ONES of Figure 9.5 has a much longer prologue than the routine ONE 
of Figure 9.3. This disadvantage can be minimized by improvements in the 
hardware such as the base register technique of the IBM 360. 
There is one difficulty with the stack that we have not yet men-
tioned. In the example of Figure 9.3, the variables Z and S of routine ONE 
use the same memory locations as the variables I and T of routine TWO. If 
the program calls routine ONE, then routine TWO, and then routine ONE 
again, on this second call to ONE the previous values of Z and S will 
no longer be available. In most situations the programmer does not need 
the values of a local variable to be saved from one call to the next. On the 
few occasions on which the values have to be preserved then the PL/1 
programmer can declare these variables to be STATIC. In Algol the 
corresponding declaration is OWN 
The word " stack " is used in a number of different contexts. Stack 
usually means a piece of memory whose length increases and decreases 
throughout the course of the calculation as data is put into the top of the 
stack and is later taken from the top of the stack. If variables are put into 
the stack in the sequence A,B,C,D, they are taken out in the order 
D,C,B,A. The 16 special registers on the KDF 9 (see Section 3.5) are used 
in this way and they constitute a stack. 
9-4 
VIRTUAL MEMORY 
The techniques for using the memory that were described in the two 
previous sections are essentially software techniques, although their 
implementation could be aided by suitable hardware. The technique that 

322 
9 THE DYNAMIC USE OF MEMORY 
will be described in this section is dependent on hardware. It cannot be 
implemented unless the hardware is available. First we will consider an 
idealized example of virtual memory and then we will consider some 
spécifie examples. 
Let us take a machine in which the address part of the instruction 
is 18 bits. Suppose that the address gives the location of a byte so that 
there are 218 bytes in the memory. The bytes may be organized into words 
and double words, but they are also organized into a unit called a "page." 
A page contains 4096 bytes. The 18-bit address is split into two parts. The 
high-order 6 bits specify a page and the low-order 12 bits specify the byte 
on the page. To give an example, the byte at location 137214 (octal) could be 
referred to as byte 7214 on page 13. The machine has a table of 64 registers 
called the page directory. Let the contents of the page directory be denoted 
by NPD(l) through NPD(64). We now come to the essential feature. The 
logical page number (that is, the page number used by the programmer) 
is not necessarily the same as the physical page number (that is, the number 
of a page of the physical memory). If the programmer refers to page L, then 
the machine actually uses physical page number NPD(L). The page 
directory contains the correspondence between the physical and the logical 
page numbers. Suppose the programmer gives the instruction: Pick up the 
contents of location 137214 (octal). Suppose that NPD(13) contains 57; 
then the machine actually picks up the contents of location 577214. The 
change from 137214 to 577214 is done automatically by the hardware. This 
change should not slow down the operation of the machine, but in practice 
it may increase the time taken to obey the instruction. There are several 
ways in which the page directory can be used to improve the power of the 
machine. 
As a first example of the use of the directory, we shall assume that 
the computer has only 32 pages of core memory. Let us denote these 
physical pages as PI through P32. Suppose the computer has several hun-
dred pages of drum memory; let us denote these by D100, D101,... . The 
system may tell the programmer that he has 64 pages of memory. Let these 
64 pages be denoted as LI through L64. At the beginning of execution, the 
system might decide that 
L1 will go in P1 
L2 will go in P2 
L31 will go in P31 
L32 will go in D132 
L64 will go in D164 
It indicates these facts by setting 
NPD(1) = 1, NPD(2)=2 
NPD(31)=31, 
NPD(32) = 132 
NPD(64) = 164 

9 . 4 VIRTUAL MEMORY 
323 
In order to simplify the description, we have called the first page on the 
drum D100; in an actual system both the core and the drum pages might 
be numbered from unity, but there would then have to be a bit in each 
entry of the directory which would indicate whether the page was in core 
or on the drum. The hardware has one feature in addition to the features 
described above; if the hardware encounters a value of NPD greater than 
100, it will cause an interrupt. To see what this means let us consider the 
operation of a program. The system puts all of the pages in the correct 
physical locations and then it starts execution. Suppose the first few 
instructions of the program are 
pick up the contents of location 276172 octal 
add the contents of location 123143 octal 
add the contents of location 610125 octal 
add the contents of location 613275 octal 
The hardware picks up the contents of location 6172 on page 27, and adds 
the contents of location 3143 on page 12; then on the third instruction it 
encounters NPD(61) which is 161. This causes an interrupt. In setting up 
the physical pages, page 32 was left empty. The system reads page D161 
from the drum and puts it in P32, and then it sets NPD(61) equal to 32. The 
system now initiates a write of some other page onto the drum. Suppose it 
decides to put page 21 onto D121. It sets NPD(21) equal to 121 and 
returns to normal execution. The contents of location 610125, which is 
physical location 320125, is added to the accumulator. The fourth instruc-
tion asks for location 613275, which is physical location 323275, so this 
instruction can be obeyed without any interrupts. 
To summarize the operations: There are 31 pages of core memory 
that contain 31 of the logical pages. One page of physical memory is 
empty; it is used during the swapping operation. Thirty-three of the 
logical pages are on the drum. The programmer assumes that all of the 
64 pages are in the core memory. The machine instructions may refer to 
any of the 64 pages. When an instruction is obeyed, the hardware consults 
the page directory. If the page is in the core memory, then the instruction is 
obeyed immediately. If the page is not in memory, there is an interrupt. The 
interrupt routine brings the requested page from the drum and writes some 
other page onto the drum. Control is now returned to the executable 
program. Let us emphasize that it is the final execution time address that is 
used in the look-up of the page directory. If the instruction specifies an 
address A which is to be modified by the contents of an index register B, 
then the machine computes A plus the contents of B, takes the high-order 
6 bits of the sum, and uses this to reference the page directory. 
The techniques just described are said to utilize a virtual memory. 
The memory used by the programmer does not have the same structure as 
the memory used by the hardware. There are many variations of the 

324 
9 THE D Y N A M I C USE OF MEMORY 
virtual-memory technique. There is no reason why the virtual memory 
should be restricted to 64 pages. If the core contains n pages and the drum 
contains m pages, then the virtual memory can contain n + m pages. If the 
virtual memory is to be very large, then it will be necessary to reorganize 
the directory; however, the benefits of a large virtual memory compensate 
for complications in the directory. One of the difficult problems of using 
the virtual memory is to decide which page is to be written back onto the 
drum when space has to be found for a new page. In some systems the 
hardware makes a note of which core pages are in use. Every time a page 
is referenced it adds one to a page counter. The page counter is decreased 
by one every few milliseconds. This means that if a page has a period of 
frequent usage followed by a period of no usage, then its counter will 
increase and then gradually decrease to zero. When a page is to be elimi-
nated from the core memory, the system chooses the page having the 
lowest count. 
We have spoken of the virtual memory as it applies to the ordinary 
programmer but, of course, the concept also applies to all of the systems 
routines except the page interrupt and the I/O routines. The page interrupt 
routine uses the normal system I/O routines to read and write the pages 
from the drum. The figures that were mentioned above, such as the 
memory of 64 pages and the page of 4096 bytes, all refer to a particular 
example. The number of pages, the number of words or bytes on a page, 
and the method of distinguishihg core pages from drum pages vary from 
system to system. 
The first practical application of the virtual-memory technique 
was on the I.C.T. Atlas computer (Devonald, 1961). The Atlas has an 
address of 18 bits. The address specifies the location of a word. There are 
512 words in one page and there are a maximum of 512 pages in the 
memory. The 18-bit address is split into 9 bits for the page and 9 bits for the 
word on the page. The memory size varies from machine to machine; in a 
typical machine there are 96 pages of core memory and 256 pages of drum 
memory. The virtual-memory technique has recently been implemented in 
the GE 645, the CDC 3300, and the IBM 360, model 67. 
The IBM 360 model 67 has a core memory of from 262,000 to 
2,000,000 bytes, a drum memory of from 4 to 12 million bytes, and a disk 
memory of several hundred million bytes. An address consists of 24 bits. 
A page consists of 4096 bytes. In the system we described at the beginning 
of this section, the page directory was stored in 64 special registers. Special 
registers are used in small machines such as the CDC 3300, but the IBM 360 
stores the page directory in the core memory. This use of the core memory 
makes the system more powerful but it can slow down the machine. In 
addition to the page, the model 67 uses a unit of memory called the 
"segment." The addressing mechanism can reference either 16 or 4096 
segments, depending on the hardware of the particular model. We will 
consider the model that has 16 segments. The machine instructions and 

9 - 4 VIRTUAL M E M O R Y 
325 
addresses are specified in the same way as on the other models of the 360. 
The machine constructs a 24-bit address from the base, index, and displace-
ment parts of the instruction. We let this 24-bit address be denoted by A. 
The address is divided into three parts, 
A = S*220 + T*212+ B 
The model 67 has several registers that are not used on other models of the 
360. One of these registers, the table register, contains an address called 
the "segment table origin." Let us denote the contents of table register as 
ST. Memory locations ST, ST+ 4, ST+ 8, ... each contain a 32-bit quantity 
which we will denote as P. P is divided into 
P - PL*224 -f PT*22 + PS 
Locations PT, PT + 2, PT + 4, ..., P T + P L - 2 contain an 8-bit quantity 
that specifies the page. The translation from the logical address A to the 
final physical address is done in the following way: 
(1) Given A, find S,T, and B. 
(2) Pick up the word in location ST + 4 * S, denote this word as P. 
(3) Given P, find PL, PT, and PS. 
(4) Pick up the half-word from memory location (PT -f T) * 2, denote this 
half-word as PF. 
(5) Split PF into two parts, PF - PP*24 + PC. 
(6) PC specifies the status of the page. If PC is greater than or equal to 8, 
then the page is not in core memory and an interrupt takes place. If PC 
is less than 8, then the page is in the core memory and it is physical page 
number PP. The address of the location is PP*212 + B. 
PL provides a check on the validity of the address. PL specifies the length 
of the table at ST, and T must be less than or equal to PL. This rather 
complicated scheme seems to have lost the simplicity of our idealized 
model, but there are good reasons for the complexity. First, the directory 
may be many hundreds of words long and it would be uneconomical to put 
this directory into a special fast memory; so the ordinary core memory 
is used. Second, the model 67 is intended to be a time-sharing system and it 
must be possible to change from one page directory to another with 
a minimum loss of time. In the model 67 the page directory can be changed 
simply by changing the contents of table register. The provision of both 
segments and pages makes it possible to shorten the length of the page 
directory. The entries in the P tables refer to successive logical pages. For 
example, if the program uses logical pages 10 through 30, and 100 
through 140, then the directory can be split into two segments of 21 and 
41 entries, respectively, rather than one long table of 141 entries. 
In the usual type of core memory a particular location is indicated 
by giving the address of the location. Thus we speak of location 1234 or 

326 
9 THE D Y N A M I C USE OF MEMORY 
location 77325. It is also possible to speak of " the location which contains 
the number 99.625" or "the location which contains the alphanumeric 
string ALPHA." It would be a simple matter to write a program that 
searched through the memory until it came to the location that contained 
the required quantity. It would also be possible to look for a location whose 
contents satisfy certain conditions; for example, we might ask that the 
first four bits of the location be 1101. There are memories in which this 
type of search can be carried out by the hardware. These memories are 
called "associative memories." In an ordinary memory the basic instruc-
tion is," Pick up the contents of location N." In an associative memory the 
basic instruction is " If C is the contents of any location, and M is any mask, 
and B is any pattern of bits, then find the C that satisfies the condition 
C. AND.M = B." For example, if M is 1111 and B is 1101, then the associa-
tive hardware has to search for the location whose low-order bits are 1101. 
There might be no location satisfying the condition, in which case the hard-
ware would return a negative answer. There might be several such locations, 
in which case the hardware would probably produce the first location that 
does satisfy the condition. An associative memory is useful providing the 
hardware search is faster than a program-directed search. In the present 
state of development there are relatively few applications in which an 
associative memory is economically justified. 
Let us return to the discussion of the model 67. The complicated 
scheme of searching through the segment table and the page table, and of 
substituting the physical address for the logical address is all carried out by 
the hardware. The programmer does not have to concern himself with all 
of the complications. It is apparent, however, that these references to the 
segment and page tables are quite time consuming if only because they 
require several references to the core memory. The model 67 minimizes the 
loss of time by use of an extra set of eight associative registers. These eight 
registers contain the eight most recently used values of S and T and their 
corresponding PP value. Whenever the machine needs to use an address, it 
first looks at the eight registers for a match of S and T. The associative 
hardware can do this search very quickly by examining all registers in 
parallel. The comparison of all eight registers takes a total of 0.15 micro-
seconds. If a match is found, then the segment tables are not used; the 
PP value is already available in the associative register. If no match is 
found, then the segment tables must be consulted and this will take several 
references to the memory. The model 67 memory has a cycle time of 0.75 
microseconds: Consulting the segment tables takes 2.1 microseconds. If the 
segment and page tables show that the page is in the memory, then the 
values of S, T, and PP are inserted into the associative registers. This 
ensures that subsequent references to the same page can be made without 
having to consult the segment and page tables. There are only eight 
associative registers so that when a new page is entered into these registers, 
the reference to some other page must be dropped. The system tries to 

9 · 4 VIRTUAL M E M O R Y 
327 
drop the page that is least likely to be referenced in the near future. The 
contents of the instruction counter are kept in both the logical-address and 
the physical-address form. Updating the instruction counter does not need 
a reference to the segment and page tables unless the address crosses an 
interpage boundary. 
When an interrupt occurs, the system has available the information 
it needs to decide which page can be eliminated from the core memory. The 
hardware keeps track of the usage of all pages that are in the core memory. 
It notes whether the page has been used, and if so, it notes whether the 
contents of the page were changed by the reference. When the time comes 
to delete the page, if the page has not been changed in any way, then it 
need not be written back onto the drum because the original drum copy is 
still intact. The virtual-memory technique on the model 67 is complemen-
tary to the other techniques for using memory in a dynamic fashion ; it 
does not replace the other methods. 
The Burroughs B5000 computer has a different method of imple-
menting virtual memory. Each array of variables has a dope vector. When 
an element of the array is referenced, the hardware looks at the dope 
vector. The dope vector contains a bit that indicates whether the array is in 
core or not. If it is not in core, then an interrupt occurs. The difference 
between the B5000 system and the other systems that we have described is 
that the B5000 transfers arrays or routines between the primary and 
secondary memory whereas the other systems transfer pages. 
To be used efficiently, the virtual memory must be used in a time-
sharing system. When a page interrupt occurs, the current program cannot 
proceed until the requested page is brought from the drum. Page requests 
cannot be anticipated and the page cannot be brought into core until the 
request is made. When the page interrupt occurs, the system sends a 
request to the I/O routines so that the page transfer may take place and 
then the system can go off to some other program. The majority of programs 
use the memory in a reasonably systematic way; page interrupts do not 
occur with disastrous frequency. However, it is not difficult to think of 
awkward cases. Consider the program 
DO 100 
l = 1,IMAX 
DO 100 
J = 1,JMAX 
100 
F(I,J) = F(I-1,J)*A(I J) + F(I + 1,J)*B(I,J) + F(I,J-1)*C(I,J) + 
C 
F(I,J + 1)*D(I,J)-F(I,J)*E(I,J) 
Suppose that IMAX and JMAX both have the value 40 and suppose that 
the page size is 512 words : we are discussing the IBM 360 type of system, not 
the B5000. Each array might start on a new page so that each array will 
require just over three pages. The program itself requires one page. If the 
system allocates 25 or more pages to this program, then, once the pages are 
in memory, the loop shown above will be processed without any interrupts. 

328 
9 THE DYNAMIC USE OF MEMORY 
If there are six pages or less allocated to this program, then an interrupt 
will occur for every value of I and J. If the system allows more than six 
but less than 25 pages, then the number of interrupts will depend on the 
way the arrays are arranged in the memory. If the arrays are stored in the 
order (1,1), (1,2), ..., (1,40), (2,1), ..., then the program can go through 
J = 1 to JMAX for several values of I without having to turn a page. If the 
arrays are stored in the order (1,1), (2,1), ..., (40,1), (1,2), ..., then the 
elements (1,1) and (1,13) will be on different pages and an interrupt will 
occur several times for each value of I. For every program—in fact, for 
every part of every program—there is some optimum number of pages. For 
many typical problems ten or twenty pages would suffice, but there are 
classes of programs, such as list-processing or Monte Carlo methods, in 
which the memory is used in an unsystematic way. For this type of problem 
the virtual-memory technique is inefficient. 
The advantage of the virtual memory method is that it is automatic 
and dynamic. Anyone who has written a large program knows that the 
efficient use of magnetic tapes and disks adds an appreciable burden to the 
problem of writing the program. The use of primary and secondary 
memory is even more of a problem in systems design. All of the problems 
are quite simple and it is easy to solve them, but there are so many possible 
variations in the ways of using the machine that the systems designer has to 
make some limiting choices. Let us give one simple example. The binary to 
BCD conversion routines in some systems have the ability to convert 
double-precision and complex numbers. These features can make the 
conversion routines very long and they penalize the programmer who is 
content with single-precision real numbers. The loader can omit the 
unnecessary parts of the conversion routine if the programmer does not 
use them. However, the decision still is not simple. In a normal system, the 
decision to include routines has to be taken at load time and the pro-
grammer may not know at load time whether or not he will need the 
complex and double-precision routines. The decision may rest on the form 
of the input data. In a system with virtual memory the extra conversion 
routines could be included in all programs; they would then be brought 
into the memory if, and only if, the programmer requested them. 
9-5 
RECURSION 
A recursive routine is one that calls itself, either directly or indirectly. The 
function factorial n can be defined by 
0! = 1 
and for n>0, 
n\ =n x (n— 1)! 

9 · 5 RECURSION 
329 
A Fortran routine that tries to use this definition is 
FUNCTION NFAC(N) 
IF (N.EQ.O) GO TO 1 
2 
NFAC=N*NFAC(N-1) 
$ RETURN 
1 
NFAC=1 
END 
This routine would not compile in Fortran because it calls itself—it is 
recursive. A practical routine to evaluate factorial n would use the alter-
native definition, 
0! = 1 
and for n > 0, 
n\ = n x (n— 1) X ··· 1 
The recursive definition of factorial n is not usually used because the non-
recursive definition is available. However, there are other functions and 
processes in which the nonrecursive version of the process is not obvious. 
To give one example : Ackermann's function is defined by 
n and m are zero or positive integers, 
A(0,n) = n + 1 
A(mfl) = A(m- 1,1) 
A(m,ti) = Aim — \,A(m,n — 1)) 
It is possible to write an algorithm for A(n,m) that does not use recursion, 
but the nonrecursive version is much more complicated than the recursive 
version. 
NFAC is an example of a routine that calls itself. If routine 
ALPHA calls routine BETA, and BETA calls GAMMA, and GAMMA 
calls ALPHA, then ALPHA, BETA, and GAMMA are recursive because 
they call themselves by way of other routines. If we drew a diagram similar 
to that of Figure 9.4, these routines would appear two or more times on 
one branch of the tree. A routine is recursive if a second entry to the 
routine can take place before the first entry to the routine has had its exit. 
There are many problems in which recursion seems naturally to 
appear. Most of these examples occur in nonnumerical applications such as 
compiling, simulation, and list processing. Most of these applications are 
impossible to describe without going into great detail. We will give just two 
simple examples. Let INTEGRAL be an Algol function routine that 
calculates 
Y= 
F{X)dX 
JA 
The call to the procedure might be 
Y = INTEGRAL(A,B,F,X) 

330 
9 THE D Y N A M I C USE OF MEMORY 
The Algol compiler allows any function to be used as an argument in the 
call to a procedure. To give an example, 
Y = INTEGRAL( 0.,1.0,X*SIN(X),X) 
would find f0 x sin (x) dx. The difference between Algol and Fortran (or 
PL/1), is that Algol evaluates the argument dynamically. In a Fortran or 
PL/1 call of this sort, the value of X*SIN(X) is evaluated before the routine 
is entered and subsequent changes to X within the routine do not change 
the value of X*SIN(X). In Algol, whenever the value of X changes, the value 
of X*SIN(X), or whatever function is named by F, is changed accordingly. 
The integral 
Z=( 
dy 
\ 
(y-xYl2dx 
Jo 
Jo 
could be evaluated by the Algol statement 
Z=INTEGRAL(0.0,1.0,INTEGRAL(0.0,Y,SQRT(Y-X)/X),Y) 
Each evaluation of the function F causes the routine to call itself. We 
notice that a somewhat similar expression, namely, 
Z=SIN( SIN(B)) 
does not require recursion because it can be evaluated as 
Z=SIN( B) 
Z=SIN(Z) 
A similar separation cannot be performed in the case of the INTEGRAL 
routine. There are ways of avoiding the recursion in the case of 
INTEGRAL. Let INTEGRALA and INTEGRALB denote two routines 
whose statements are identical to INTEGRAL; then 
Z = INTEGRALA(0.0,1.0,INTEGRALB(0.0,Y,SQRT(Y -X),X),Y) 
shows a nonrecursive evaluation of the integral. 
Our second example of recursion concerns the formal mani-
pulation of expressions. Fortran is primarily concerned with numerical 
calculation. If 
Y = X * * 2 - 3 . 0 * X +21.75 
is a Fortran statement, then at execution time the value of X will be known 
by the time the statement is reached, and the Fortran program will evaluate 

9 · 5 RECURSION 
331 
the numerical value of Y. It is possible to manipulate expressions in a 
formal manner, however, without substituting the values of the variables. 
For example, if 
X = Z + 3.0 
then 
Y =Z**2 +3.0*Z +21.75 
and if DX(Y) denotes the differential of Y with respect to X then 
DX(Y) = 2.0*X - 3.0 
Tobey et al (1965) discuss computer programs that carry out this sort of 
formal manipulation, and they give several references to other programs 
of this type : 
The rules for constructing DX(Y) are well known. 
(1) If Y is independent of X, then DX(Y) is zero. 
(2) If Y is of the form X ** N, then DX(Y) = N*X**(N - 1) 
(3) If Y=P + Q or P—Q or P*Q or P/Q where P and Q are any expressions, 
then DX(Y) = DX(P)+DX(Q) or DX(P)-DX(Q) 
or P*DX(Q) 
+DX(P)*Q or DX(P)/Q-P*DX(Q)/Q**2 
A routine to perform formal differentiation would follow these rules. It 
would take the form: 
(1) If Y is independent of X, then DX = 0.0. 
(2) If Y has the form X**N, then replace Y by the expression N*X**(N— 1). 
(3) If Y has neither of these forms, then express Y in the form P+Q or 
P - Q or P*Q or P/Q and then replace DX(Y) by the expression DX(P)+ 
DX(Q) or DX(P)-DX(Q) or DX(P)*Q+P*DX(Q) or DX(P)/Q-
P*DX(Q)/Q**2, as appropriate. 
The third branch of DX requires the routine to call itself. A recursive 
routine of this type is given by Arden (1963, page 306). A nonrecursive 
differentiation routine is given by Smith (1965). 
It is not difficult to construct a compiler that allows a routine to 
be called recursively. All that is necessary is to make sure that the second 
entry to the routine does not destroy information set up on the first entry. 
It is sufficient to use a stack to store all of the local information. Algol and 
PL/1 do allow recursive routines. Fortran does not. 
To illustrate how recursion can be implemented, we will discuss 
the coding of the recursive version of NFAC. We had the IBM 7090 in 
mind when we wrote the description that follows, but the changes necessary 
to convert to another machine are obvious. The first attempt at coding 
the routine might be as follows : 

332 
9 THE DYNAMIC USE OF MEMORY 
The entry point is NFAC 
51. Save index register 4 in location SX4. 
52. Pick up the address of N and store it at locations S3 and S7. 
53. Pick up N. 
54. If the accumulator is zero, go to S10, otherwise go to S5. 
55. Subtract one from the accumulator and store the result in location NN. 
56. Call the routine NFAC with the argument which is in location NN. 
57. Multiply the accumulator by N. 
58. Put the result in the accumulator. 
59. Reset the contents of index register 4 from the contents of location 
SX4, and return. 
S10. Put 1 in the accumulator and go to S9. 
SX4 One location for saving the index register. 
NN 
One location for saving the value of N — 1. 
This code would not work on a recursive call. Consider the statement 
K=NFAC(99) 
Let L denote the memory location where the call statement occurs. Let 
L99 denote the location containing the number 99. On entry to NFAC, 
the complement of L + 1 goes into location SX4. The address L99 goes 
into statements S3 and S7. Statement S4 goes to statement S5. This puts 
98 in location NN. Statement S6 jumps to the entry point at statement SI. 
This statement stores the complement of S6 + 1 in location SX4, thus 
destroying the previous contents of SX4. Statement S2 writes the address 
of NN in statements S3 and S7. This destroys the previous address which 
was L99. The solution to these difficulties is to put SX4, NN, and the 
address of the argument into the stack. Let STACK denote the stack, and 
let NSP denote the stack pointer. The terms " stack " and " stack pointer " 
were explained in Section 9.3. The recursive version of NFAC is: 
Entry point NFAC. 
51. NSP = NSP+3. 
52. Save the contents of index register 4 in location STACK(NSP-1). 
53. Save the address of N in STACK(NSP-2). 
54. Pick up the number whose address is in STACK(NSP-2). 
55. If the accumulator is zero, go to S12, otherwise go to S6. 
56. Subtract one from the accumulator and put the result in location 
STACK(NSP-3). 
57. Call the routine NFAC with the argument that is in location STACK 
(NSP-3). 
58. Multiply the accumulator by the number whose address is in STACK 
(NSP-2). 
59. Put the result in the accumulator. 
S10. Reset index register 4 with the number that is in location STACK 
(NSP-1). 
SI 1. NSP = NSP-3 and then return. 
SI2. Put one in the accumulator and go to S10. 

9 - 5 RECURSION 
333 
Now let us reconsider the statement K = NFAC(99). Suppose 
NSP has the value 1 upon the first entry to NFAC. The complement of 
L + l goes into STACK(3). L99 goes into STACK(2). 98 goes into 
STACK(l). On re-entering NFAC, the complement of S7+1 goes into 
STACK(6). The location of STACK(l), which is the location that con-
tains 98, goes into STACK(5) and 97 goes into STACK(4). The routine 
keeps on entering itself without destroying any of the previous information. 
On the final entry, the complement of S7+ 1 goes into STACK(300). The 
location of STACK(295), which contains zero, goes into STACK(299) 
and we reach statement S5. A jump to statement S12 is taken. The integer 
1 is put into the accumulator. NSP has the value 301. This value is changed 
to 298 and the return takes control back to statement S8. This multiplies 
the accumulator by the number whose address is in STACK(296) and NSP 
is then reduced by 3. The routine continues, multiplying the accumulator 
by numbers whose addresses are in locations STACK(296), STACK(293), 
.... The return address is in location STACK(297), STACK(294), ..., 
STACK(3). All of the returns except the last one take control back to 
statement S8. The final return takes control back to statement L + 2. The 
stack has been used in the following way : 
STACK(3*I) 
contains the complement of the calling address plus one. 
STACK(3*I— 1) contains the address of the argument. 
STACK(3*I—2) contains a location for storing N — 1. 
The cost of the recursion should be obvious from this example. 
The evaluation of NFAC(N) requires 3N + 3 locations of the stack and 
N calls to the routine. The nonrecursive routine, 
FUNCTION NFAC(N) 
NFAC-1 
$ 
DO 
100 
J = 1,N 
100 
NFAC=J*NFAC 
END 
requires only two temporary storage locations and it is very much faster. 
NFAC was a simple routine and the recursive entry required only three 
stack locations for each entry; in a more complicated example many more 
locations would be required on each call. Recursion provides an elegant 
method of specifying certain types of algorithm. It is worth using if the 
gain in simplicity of the program compensates for the cost of the additional 
space and time. 
The PL/1 language has both recursive and re-entrant routines. 
Re-entrance may occur in time-sharing or multiprocessing systems. Let 
us suppose that routine Jl belongs to job one and that J2 belongs to job 
two ; and that both of these routines call some library routine such as the 
SIN function. Each job could have its own copy of the SIN routine but 
space is saved if the two routines use the same copy of SIN. Suppose job 

334 
9 THE D Y N A M I C USE OF MEMORY 
one is being executed and it is in the middle of the SIN routine. An in-
terrupt may occur and job two may be called in. Job two may now call 
SIN. This subsequent entry must not destroy any of the locations of SIN 
that were used by job one. There will be no interference providing SIN 
does not use any local memory space. When the SIN is called from job 
one, it can use memory space from the stack belonging to job one, and 
when called from job two, it can use the stack belonging to job two. From 
the point of view of implementation, the property of being re-entrant may 
look the same as the property of being recursive. However, there is an 
essential difference. The interrupt process always saves the contents of all 
registers. A re-entrant routine can assume that the contents of the registers 
are not destroyed by subsequent entries. A recursive routine must allow 
for the fact that if it uses a register, then it destroys the previous contents 
of that register. We have described re-entrant procedures, but it is obvious 
that a whole program could be made re-entrant. Each successive entry to 
the program would need to use a different portion of the memory as its 
own stack. In some multiprogramming systems it is assumed that the 
compilers and assemblers will be in use by several different jobs at the same 
time, and this means that these compilers and assemblers are re-entrant 
programs. 
9"6 
LIST PROCESSING 
The Fortran and Algol languages are designed to operate on elements 
whose structure is static. The size and shape of arrays can vary but the 
array is always concerned with single-word integers, or single- or double-
word floating-point numbers. PL/1 does allow some variation of structure; 
for example, the length of a string of characters may vary throughout the 
course of the calculation, but the maximum length of the string must be 
declared. Workers in the fields of language translation, formal manipula-
tion, heuristic programming, and other allied fields have found it useful 
to develop the idea of a list.The term "list" has a technical meaning which 
will be given in the next paragraph, but list processing is essentially con-
cerned with quantities whose length and structure changes throughout the 
course of a program. If Y is a Fortran REAL variable, then Y occupies 
one word. If Y is a formal expression such as 
Y=X**2+1.0 
then the substitution of Z + 3.0 for X produces Y = (Z + 3.0)**2+ 1.0 or 
Y = Z**2 + 6.0*Z+10.0. If such a substitution is to be carried out in a 
program, then provision must be made for changes in the length and 
structure of the expression for Y. There are a number of list-processing 
languages such as Lisp (McCarthy, 1960), IPL-V (Newell, 1961), and Slip 

9 · 6 LIST PROCESSING 
335 
(Weizenbaum, 1962). These languages are quite dissimilar in their external 
appearances, but they use somewhat similar techniques for the manipula-
tion of lists. The following description applies, for the most part, to Lisp 
on the IBM 7090. 
The basic unit of information is an atomic symbol. An atomic 
symbol can be written as a letter followed by none, one, or more letters, 
digits, or blank characters. A, APPLE, and BREADANDCAKE are 
examples of atomic symbols. An atomic symbol is stored in the memory as 
PZE 
- 1 „ * - M 
where ... denotes a series of locations containing the BCD name of the 
symbol and any other properties that the list processor may care to 
remember. It will be remembered that * +1 means the ' address of the 
location one after the current location '. If APPLE is an atomic symbol, 
then we can conveniently denote its memory representation by 
APPLE 
PZE 
- 1 „ * + 1 
It should be understood that the information indicated by ... in the de-
scription given above is also stored and that symbols are not limited to 
the six characters allowed in a conventional assembler. The next element 
of the Lisp language is the symbolic expression. The term "symbolic 
expression " should not be confused with the use of this term in mathe-
matics. In Lisp, a symbolic expression is either an atomic symbol or it has 
the form (symbolic expression.symbolic expression). If A, B, and C are 
atomic symbols then 
B 
(A.B) 
((A.B).C) 
are examples of three symbolic expressions. (A.B) is stored in the memory 
as 
PZE 
A„B 
that is, it is one word with the address of A in the address part of the word 
and the address of B in the decrement part. ((A.B).C) is represented in 
the memory as 
PZE 
* + 1 „ C 
PZE 
A„B 

336 
9 THE D Y N A M I C USE OF MEMORY 
whereas (A.(B.C)) would be 
PZE A„*+1 
PZE B„C 
A symbolic expression can be represented by a binary tree as shown in 
Figure 9.6. Each tree contains a node for every period appearing in the 
expression and it contains an end point for each atomic symbol. The 
memory representation has a word for each node; the address and de-
crement of this word points to the two branches that join at the node. A 
symbolic expression is a way of writing a binary tree. It is, of course, 
possible to have trees in which more than two branches meet at one point, 
but Lisp restricts itself to binary trees. 
A A 
A
B 
A
B
C 
(A.B) 
((A.B).C) 
A
B
C 
(A.(B.C)) 
A 
B 
C 
D 
NIL 
A 
P 
Q 
NIL 
C 
D 
NIL 
(A B C D) 
(A (P Q) C D) 
FIG. 9.6 Symbolic expressions and tree representations. 
The symbol NIL is used for the null expression. A symbolic 
expression of the form (A.(B.(C.NIL))) occurs frequently in the processing 
of symbolic expressions ; and a symbolic expression of this type is called a 
"list." In this example there are three atomic symbols on the list, but lists 
may be of any length. An alternative notation is usually used for lists, 
namely, (A B C). In this example we have used only three symbols, but 
in general lists may be of any length, (A B C D ... Z) = (A.(B.(C. ... 
(Z.NIL)))). If we look at the tree diagram of a list, we see that one symbol 
is stripped off at each node. Any item of the list can itself be a list. If 
(A F B C) and (D E) are two lists, then the list obtained by replacing F 
by (D E) is (A (D E) B C). 
The advantage of the list structure, from the point of view of 
memory organization, can be illustrated by the following example: 

9 · 6 LIST PROCESSING 
337 
Suppose we have the list (A B C) and the list (D E). These are stored in 
memory as 
LIST1 
PZE 
A „ * + 1 
PZE 
B„*+1 
PZE 
C„NIL 
and 
LIST2 
PZE 
D „ * + 1 
PZE 
E„NIL 
Suppose we wish to convert the first list into the longer list (A B C D E) ; 
this can be done simply by changing the contents of location LIST1 +2 to 
PZE 
CLIST2 
Since the decrement part of the list points to the next item, successive 
items of the list need not be in successive memory locations. We could 
convert LIST1 into the list (A (D E) B C) by changing it to 
LIST1 
PZE 
A„LIST3 
PZE 
B„*+1 
PZE 
C„NIL 
LIST2 
PZE 
D „ * + 1 
PZE 
E„NIL 
LIST3 
PZE 
LIST2„LIST1 +1 
Thus it is possible to add to lists and to replace lists by atomic symbols or 
atomic symbols by lists simply by changing a few decrements. If a list of 
symbols is stored in the more obvious way of putting successive symbols 
in successive locations, then any insertion in the list would require groups 
of symbols to be moved in order to make room for the insertions. 
Let us return to the problem of manipulating algebraic expressions. 
Given an algebraic expression such as 
Y=A*Z*Z + B*Z + C 
then we could represent Y as a list 
(A STAR Z STAR Z PLUS B STAR Z PLUS C) 
where A, Z, STAR, PLUS, B, and C are declared as atomic symbols, or 
they may also be lists. If Z is the algebraic expression 
Z = D*X + E 
then Z can be represented by the list 
(D STAR X PLUS E) 

338 
9 THE D Y N A M I C USE OF MEMORY 
The substitution of the expression for Z into the expression for Z reduces 
to the replacement of the address of an atomic symbol by the address of 
a list. 
To summarize the memory representation of lists : a list is repre-
sented by a string of words in the computer memory. The address of the 
word points to the current item of the list. The decrement points to the 
next item. Each item may be an atomic symbol or it may be another list. 
The symbol NIL is used to mark the end of a list or a sublist. 
We have described a machine representation of a list, but, in fact, 
lists can be defined independently of any machine representation. Lisp has 
the following basic functions: Let X, Y, and Z denote any symbolic 
expressions 
atom [X] = true if X is atomic, otherwise it equals false. In other words 
atom [X] is true if the address part of location X is — 1 
eq [X, Y] = true if X and Y are atomic and if X = Y; it is false if they are 
unequal, and it is not defined if they are not atomic 
Car is a function that strips off the top branch of the binary tree, for 
example 
Car [(X.Y)] = X 
Car [(X. (Y.Z))]=X 
Car [((X.Y). Z)] = (X.Y) 
Notice that Car simply takes the address part of the word that describes 
the expression. The function Cdr takes the decrement part; as an example 
Cdr [(X. (Y.Z))] = (Y.Z) 
The final basic function is Cons. This function constructs one expression 
from two subexpressions 
Cons [A,B] = (A.B) 
Cons [(A.B), C] = ((A.B).C) 
Again we can see that the operation of Cons in terms of machine operations 
is very simple. All it has to do is to form a word with the address of the 
first argument in the address part and the address of the second argument 
in the decrement part. 
With these basic functions Lisp builds up a very elaborate 
language built on a series of complex functions. One of these functions, 
the function Subst (X, Y, Z) substitutes X for all the appearances of Y in 
Z. Y must be atomic, X and Z can be expressions, for example, 
Subst [(X.Y), Z, ((P.Z).R)] = ((P.(X.Y)).R) 

9 ■ 6 LIST PROCESSING 
339 
The notation for conditional expressions in Lisp is somewhat complicated 
so we will define Subst in an Algol-like notation 
Subst [X , Y , Z] : 
= if atom [Z] 
then if eq [Z,Y] then X else Z 
else Cons[Subst [X,Y,Car[Z]], Subst [X,Y,Cdr[Z]] 
In other words, if Z is atomic, do the substitution if Z is Y, otherwise do 
nothing. If Z is not atomic, then split it into two parts and proceed down 
each branch separately. This is a good example of the use of recursion. 
Subst is defined recursively and Cons is used recursively. The diagrams of 
the type shown in Figure 9.6 are helpful in imagining the operation of 
Subst. The function starts at the root of the tree. Each time it finds a 
branch point it uses Car and Cdr to split the tree. When it reaches the end 
of the tree, it performs the substitution, then the recursive use of Cons 
pulls it back up the tree, joining the branches together again. 
We have shown that if X = (A. (B.C)) then X can be represented 
by 
X 
PZE 
A „ * + 1 
PZE 
B„C 
but it is obvious that these two words do not need to be contiguous 
ORG 1000 
X 
PZE 
A„2000 
ORG 2000 
PZE 
B„C 
is an equally good way of representing X. Lisp maintains a free list which 
contains all the unused storage. When a list grows, it takes space from the 
free list. When a list shrinks, it returns storage to the free list. Since lists 
may grow and shrink in any sequence it is obvious that the free list will 
not usually be a set of contiguous words. It will be a set of words that are 
chained together. In order to know what is on a list it is necessary to know 
the address of the first location of the memory representation of the list. 
Subsequent items on the list can be found from the address and decrement 
of successive words. 
We have considered lists from the point of view of their repre-
sentation in the machine. McCarthy (1960), Feigenbaum and Feldman 
(1963), Tobey et al. (1965), and others, describe the use of lists. There are 
many problems in which a simple list structure can be usefully used as 
part of a standard coding technique. It is not always necessary to use a 
fully developed list processor. 
We can define a simple list processor in the following terms. All 
atoms and expressions are stored in a Fortran array L. The value of the 

340 
9 THE D Y N A M I C USE OF MEMORY 
variable LF points to the first free cell of L· At the start of the job, 
COMMON LF,L(10000) 
DO 100 1 = 1,10000 
100 
L(l) = l + 1 
LF=1 
defines all cells to be free. If L(LF) = K, then L(LF) is the first free cell, 
L(K) is the next free cell and so on. An atomic symbol consists of up to 
six characters, the first character must be a letter. The symbol is stored in 
memory as a string of Hollerith characters. Every symbol also has a 
Fortran name. If the symbol APPLE has the Fortran name NAPPLE, then 
L(NAPPLE) contains 5HAPPLE. We have introduced an initial N in 
order to make the name an integer variable; a·TYPE statement could have 
been used. An atom is defined by a call to a Fortran subroutine, for 
example, 
CALL 
DATOM( NAPPLE,5HAPPLE) 
It is, of course, not necessary for the letters of the Fortran name of a 
symbol to be similar to the letters of the symbol itself. The coding of 
DATOM is very simple. 
SUBROUTINE DATOM(IJN) 
COMMON LF,L(10000) 
l = LF 
$ 
LF=L(I) 
$ 
L(I) = IN 
END 
DATOM should also make sure that L is not already full. Let A,B, and C 
denote any atoms or symbolic expressions and let IA, IB, and IC be their 
Fortran names. If C = (A.B) then we will make L(IC) = IA + IB*2**15. 
Operations, such as CAR, CDR, CONS, and so on, will operate on the 
Fortran names of expressions. The coding of these routines is very simple. 
NIL can be represented by the contents of L( 10000). We prefer not to repre-
sent NIL by 0 because we want to be able to distinguish between an atom 
and a symbolic expression by the test: if L(I).AND.7777700000B is zero, 
then I is the Fortran name of an atom. Since Fortran does not allow 
recursion it may be necessary to write a routine of the following form. 
CALL ALL(I,K) 
The user should set K equal to zero at the start of the program. If K is 
zero, then ALL starts at the beginning of the expression in L(I). ALL sets 
K equal to a number such that L(K) contains the first atom of the expres-
sion. On the next call to ALL it sets K equal to a number such that L(K) 

PROBLEMS 
341 
is the next atom, and so on. When all atoms have been returned, it sets K 
equal to zero. Since expressions can contain subexpressions, the coding of 
ALL requires some care. Looking at the diagrams of Figure 9.6 suggests 
that ALL could proceed as follows. Go down a branch of a tree. If the 
branch contains a node, then note the position of the node in a push down 
stack and take the left-hand branch of the node. When an atom is reached, 
then RETURN. Having processed one atom, take the number from the 
top of the stack and proceed down the right-hand branch of the node 
that it refers to. 
PROBLEMS 
1 ■ The subroutine DECLARE is described in Section 9.2. If the state-
ments 
CALL DECLARE(X,10,10,1) 
CALL DECLARE(Y,10,10,1) 
CALL DECLARE(Z,10,10,1) 
have been given, what are the final values of X, Y, and Z? Write a 
subroutine, similar to the ADD routine, which multiplies the matrix Y 
by the matrix Z and puts the result in the matrix X. 
2 ■ Program the routine SETXEQY which was described in Section 9.2. 
3 ■ Rewrite the subroutine DECLARE so that it uses only the vector S. 
The vector S will now contain all the dimensions and data of each 
array. Can the restriction on the number of separate arrays be 
relaxed ? 
4 ■ If an array X has dimensions 10 by 20 by 30, what would be the 
contents of the dope vector? If Y is 30 by 20 by 10, show that the 
dope vector of Y is longer than the dope vector of X. Modify the 
routines DECLARE and SETXEQY so that they use the dope vector 
method of accessing the elements of the array. 
5 ■ Continue Figure 9.5 and show how the routines TWO and THREE 
could use the stack. In the routine of Figure 7.7, which variables 
could use the stack and which variables would have to be static? 
6 ■ Write a routine to simulate the action of an associative memory. Let 
locations X(1),X(2), ... represent the contents of the memory. 1 = 
NASSOC(MASK,CONTENT) should give I the value which makes 
X(I).AND.MASK equal to CONTENT.AND.MASK. 
7 ■ In order to test the design of a virtual memory, the page mechanism 
could be simulated by a Fortran program. The Fortran program is 
run on a conventional machine. Modify the routine DECLARE in 
order to simulate a virtual memory. Replace the array S by 
COMMON NPAGE(100),SC(2000),SD(10000) 

342 
9 THE D Y N A M I C USE OF MEMORY 
Let SC represent the core memory of 20 pages of 100 words each. 
Let SD represent the drum memory of 100 pages of 100 words each. 
Replace statements such as X = S(K) by CALL XEQS(X,K) and 
replace S(K) = X by CALL SEQX(X,K). You will need to write the 
programs for these two routines. Let 
NLP=K/100 + 1$NW=K-100*(NLP-1) 
NPP=NPAGE(NLP) 
then NLP represents the logical page number, NPP the physical page 
number and NW the number of the word on the page. If NPP is less 
than or equal to 20 then the required word is in location SC((NPP— 1) 
*100 + NW). If NPP is greater than 20, then it is necessary to swap 
pages. Your program should try to minimize the number of page swaps. 
8 ■ Consider the routine, 
FUNCTION A(M,N) 
IF (M.EQ.0) GO TO 1 
IF (N.EQ.0) GO TO 2 
A = A ( M - 1 , A ( M f N - 1 ) ) 
RETURN 
2 
A = A ( M - 1 , 1 ) $ RETURN 
1 
A = N + 1 
END 
Either code the routine in assembly language or describe the routine 
in the detail with which the routine NFAC was described in the text. 
9 ■ Write the programs for the simple list processor described at the end 
of Section 9.6. Start by writing the routines DATOM, CAR,CDR, 
CONS, ATOM, and EQ, or by writing routines ADTOP, ADTAIL, 
UNTOP, UNTAIL, and DLIST. ADTOP should add one item to 
the top of a list. UNTOP should take one item from the top. ADTAIL 
should add one item to the bottom of the list. UNTAIL should delete 
one item from the bottom of the list. DLIST should define a list and 
put the first item on the list. 
10 ■ Write the routine ALL which was described in the text. Write the 
routine SUBST. One method of writing SUBST will use ALL to 
enumerate the elements of the list. 

10-1 
INTRODUCTION 
10 
During the later stages in the development 
of the IBM 360 a committee was formed 
to further the design of a new programming 
language. The language was to be on the 
level of Fortran and Algol but it was to 
recognize the many different abilities of a 
modern computing system. PL/1 has 
drawn features from Fortran, Algol, Cobol, 
and several other languages. Most of the 
concepts are implementations or extensions 
of current ideas ; nevertheless, the synthesis 
of a language so extensive as PL/1 is a 
formidable task and the designers have 
done a remarkable job in producing a 
coherent system. 
On the elementary level PL/1 is no 
more difficult to understand than Fortran. 
The beginning programmer will find it as 
easy to learn and to use a subset of PL/1. 
Some of the advanced features of PL/1 
cannot be appreciated or even understood 
unless the programmer has some know-
ledge of techniques such as the stack mech-
anism of Section 9.3. In this chapter we 
will assume that the main features of PL/1 
can be understood simply by stating what 
they do. Our main interest is in the more 
advanced features and the way in which 
they are implemented. This description is 
based on the IBM publication ' PL/1 : Lan-
guage Specifications' (Form C28-6571-0, 
1965). PL/1 will no doubt undergo future 
modifications, but the underlying concepts, 
which are our principle concern, are un-
likely to change. Fortran was essentially a 
language for describing numerical calcula-
tions, and it was understood that the 
numbers would be the one-word integer or 
floating-point numbers which the machine 
used. One could write Fortran subroutines 
that performed more elaborate calculations. 
For example, the routine 
CALL 
ADD( Χ,Υ,Ζ ) 
343 
PROGRAMMING 
LANGUAGE 
PL/1 

344 
10 P R O G R A M M I N G LANGUAGE PL/1 
of Section 9.2 adds the array Y to the array Z and puts the result in 
array X. In a more ambitious compiler such as PL/1 the statement 
X=Y+Z 
does not necessarily mean add the number Y to the number Z and put the 
result in X. The statement can mean anything that the compiler designer 
cares to specify. If X, Y, and Z are real variables, then the statement refers 
to real addition. If X, Y, and Z are arrays, then the designers of PL/1 have 
decided that matrix addition would be appropriate. In other words, 
X = Y + Z in PL/1 has the same effect as CALL ADD (X, Y, Z) in our 
Fortran program. In Fortran each statement usually produces several 
symbolic instructions. There are a few statements that generate calls to 
subroutines; for example, 
X = l 
produces a subroutine call in Fortran 63. In most Fortran statements a 
subroutine call is generated only if a CALL or a function name is used. 
In PL/1 the compiler automatically produces code to process numbers, 
arrays, strings of characters, and so on. Some of this code is in-line, some 
of it simply produces a call to a subroutine. The number of features that 
can be included in a compiler is limited only by the judgement and the 
manpower available to the compiler writers. There are many features that 
can be included which would only confuse the prospective user. On the 
other hand there are many features where external specification is very 
simple but where implementation is complex. 
X=Y+Z 
can mean many different things depending on the declarations associated 
with X, Y, and Z. If X, Y, and Z are real single-precision numbers, then 
three machine instructions will be generated. If X, Y, and Z are arrays 
or multiple-precision numbers, then a subroutine call or a macro-instruc-
tion must be generated. 
10-2 
CHARACTERS, IDENTIFIERS, OPERATORS, LABELS 
PL/1 users enter the standard Fortran 48-character set or a 60-character 
set. The characters available in both sets are: 
0 through 9 
A through Z 
H 
* / , . $ ( ) = » 
and the blank character 

1 0 - 2 CHARACTERS, IDENTIFIERS, OPERATORS, LABELS 
345 
The 60-character set has the additional symbols 
% : ; i | ε > < _ # @ ? 
The characters #, @, and ? have no 48-character equivalent but the other 
characters can be represented by two or more characters as follows : 
60-character set 
48-character set 
% 
> 
> = 
Ί = 
< = 
< 
Ί 
1 
ε 
II 
» · 
// 
GT 
GE 
NE 
LE 
LT 
NOT 
OR 
AND 
CAT 
CAT stands for catenate, the operation of joining two strings together. 
An identifier is one alphabetic character followed by none or more letters 
or digits. The characters $ and @ and # are regarded as letters so that 
$99 is a legitimate identifier. The break character 
may appear in an 
identifier; however, it must not be the first character. An identifier may 
have up to 31 characters: 
A 
X21 
ALPHANUMERICAL 
$21 
X@$20 
RATE_OF__PAY 
are examples of identifiers. The last two examples could not appear in the 
48-character set, of course. 
The operators +, —,*,/, and ** stand for addition, subtraction, 
multiplication, division, and exponentiation. Among the comparison 
operators, GT stands for greater than, GE and so on have their 
obvious meaning. NOT, OR, and AND have a meaning similar to that of 
the Fortran .NOT., .OR., and .AND. The single quote symbol ' is used 
to enclose strings of characters ; thus the Fortran I = 3HABC becomes the 
more intelligible in PL/1 as I = 'ABC Many of the PL/1 statements look 
similar to Fortran statements; however, there are two essential differences. 
In a PL/1 statement, if two words are not separated by an operator, a 
comma, or a parenthesis then they must be separated by a blank. CALL A 
is not the same thing as CALLA. If several characters stand for one symbol, 
then there must be no embedded blanks. * * is not a legitimate way of 
writing **. Because blanks are significant, PL/1 can use X GT Y for X> Y, 
whereas Fortran had to use X.GT.Y. Any number of blanks may appear 

346 
10 P R O G R A M M I N G LANGUAGE PL/1 
between words, operators, commas, and parentheses. Several statements 
may appear on one line, and they are separated by a semicolon. The end 
of a line does not necessarily indicate the end of a statement, although a 
particular computer center may elect to use the end of a line in this way. 
A statement label takes the same form as an identifier. It precedes 
the statement and is separated from it by a colon. Several labels may be 
attached to the same statement. This feature is not strictly necessary but 
it is sometimes convenient. 
IF X LT 1.25 THEN GO TO TROUBLE; 
Y = X + Z ; 
GO TO LETSGO; 
TROUBLE: 
Y=0 ; 
LETSGO: 
X=X + 0.25; 
illustrates the use of labels, colons, and semicolons. For typographical 
convenience we will use the 48-character representation of symbols such 
as <, but we may use the 60-character representation of : and ;. 
A comment may appear anywhere an extra blank may appear. 
The comment is embedded thus: /* characters */. Obviously the characters 
forming the comment must not include */. 
10"3 
DATA TYPES and DESCRIPTIONS 
A type declaration is made in a DECLARE statement. The choice of 
numeric types available is 
BINARY 
or 
DECIMAL 
FIXED 
or 
FLOAT 
REAL 
or 
COMPLEX 
(number of digits, scale factor) 
Types that we show on the same line are exclusive, but nonexclusive types 
may be combined; thus BINARY FLOAT REAL. These choices corre-
spond to certain obvious ways of representing numbers so in a sense there 
is nothing more to be said, but the user should bear in mind the impli-
cations of his choice. For scientific calculations on a 360 with the floating-
point feature the normal choice should be 
BINARY 
FLOAT 
REAL 
or 
BINARY 
FIXED 
REAL 
Any other choice leads to a great increase in computer time. However, 
there are problems for which DECIMAL or COMPLEX is necessary and 

10 ■ 3 DATA TYPES AND DESCRIPTIONS 
347 
it is a great convenience to have such options as BINARY FIXED 
COMPLEX or DECIMAL FLOAT REAL. The precision specifies the 
number of binary or decimal digits to be carried. In the case of FIXED 
data a scale factor can be specified ; thus 
DECLARE X REAL FLOAT DECIMAL (10), 
I REAL FIXED DECIMAL (5.2) 
states that X is a ten-digit decimal number and I is a fixed-point number 
in the range 0.01 to 999.99. Again the programmer should recognize that 
the standard machine has 16- or 32-bit fixed binary and 32- or 64-bit 
binary floating-point arithmetic and that any choice of representation or 
scale that differs from this will lead to time-consuming subroutines. If a 
complete set of attributes is not given, then the compiler takes a default 
option. These options are preset in the compiler so that BINARY always 
implies BINARY FLOAT REAL, and similarly with other options. 
Several variables may be declared at once by enclosing them in parentheses, 
as, for example, 
DECLARE 
( A, B, C 
BINARY FLOAT), (l,J 
BINARY FIXED) 
Each identifier and each set of declarations is separated by a comma. 
It would be quite tedious'to have to declare every variable, hence 
PL/1 has a rule similar to that of Fortran. If a variable is not declared and 
if it begins with letter I through N, then it is FIXED REAL; if it begins 
with A through H or O through Z, then it is FLOAT REAL. The precision 
is specified by parameters built into the compiler. The parameters may 
change from computer center to computer center. The IMPLICIT state-
ment allows the programmer to vary these rules; for example, 
IMPLICIT 
C 
BINARY COMPLEX FLOAT, 
I - L BINARY COMPLEX 
FIXED 
implies that any identifier beginning with C, I, J, K, or L has to have a 
binary complex representation. 
In addition to the numerical types, PL/1 has the CHARACTER 
string similar to the Hollerith string of Fortran and the BIT string similar 
to the logical variables of F63. 
DECLARE 
A 
BIT (10), C CHARACTER (21), D CHARACTER (7) 
VARYING 
specifies that A is a bit string of ten bits. C is a character string of 21 
characters. D is a character string. The length of D may vary but it is a 
maximum of 7 characters. An identifier which is used as a statement 

348 
10 P R O G R A M M I N G LANGUAGE PL/1 
label need not be declared as such unless it is used indirectly as a label, 
for example, in 
P=A; 
GO TO P; 
A 
: X = X + 1 ; 
A is used explicitly as a label but P must be declared to be a label 
DECLARE 
P 
LABEL 
indicates the way in which this is done. 
10-4 ASSIGNMENT STATEMENTS 
Fixed- and floating-point constants are written in the usual way. 
99 
221.6 
123.4E-5 
are examples of constants. The imaginary part of a complex number is 
indicated by writing a real constant followed by an I, for example 
99I 
221.61 
123.4E-5I 
A complex constant can be formed by adding or subtracting a real and an 
imaginary constant. A character string constant is written in single-quote 
signs. A bit string constant is a string of O's and l's enclosed in single 
quotes and followed by a B 
'0100'B 
'APPLES AND ORANGES' 
(6)'AB' 
shows a bit string and two character strings. An (n) before a string in-
dicates that the characters should be duplicated n times. 
(6)'AB' 
is the same as 
ΆΒΑΒΑΒΑΒΑΒΑΒ' 
Arithmetic statements are written in the same way as in Fortran. 
The types of the operands may differ from each other, but the programmer 
should realize that he has to pay in extra machine time for the cost of any 
unnecessary conversions. If A,B,C, and D are BINARY FLOAT REAL 
variables of 32-bit precision then a PL/1 statement such as 
A=D*(B + C))/(B-C) + B 
has the same meaning as it does in Fortran. 

10 · 4 A S S I G N M E N T STATEMENTS 
349 
The operators NOT, AND, and OR can be used to perform logical 
operations on bit strings. They do so on a bit-by-bit basis. If the operands 
have different lengths, then the shorter operand will be filled out with 
zeros on the left-hand end. If P and Q are bit strings, then if 
A=X 
and 
then 
NOT P 
P OR Q 
P AND Q 
Q AND NOT P 
is 
is 
is 
is 
'0011' B 
Ί11110' B 
Ό01000' B 
Ί10010' B 
The CAT operator adjoins one string onto the end of another string 
is 
The CAT operator can be applied to character strings, thus 
is 
The library routine SUBSTR can be used to extract any piece of a string 
character or bit string. SUBSTR ( A,I,J) extracts the characters 1,1 + 1, 
...,I + J— 1 from the string A. If J is omitted, then the 1,1+1,... characters 
up to the end of the string are fetched. If A and B are character strings, 
sets B = 'CD' unless the length of B is greater than 2 in which case blanks 
are added at the right-hand end to fill up B. 
Strings and numeric variables may be mixed within one expres-
sion. If A is a character string whose value is Ί234.' and X is a FLOAT 
REAL variable, then 
sets X equal to 1234.0. If it is realized that the statement actually generates 
a call to a subroutine, then there is nothing remarkable about the conver-
sion, but it should be realized that the operations involved are quite 
complicated. The corresponding Fortran 63 statement is 
Similarly 

350 
10 P R O G R A M M I N G LANGUAGE PL/1 
would correspond to an ENCODE statement. The ability to mix types in 
this way gives a convenient and compact method of doing many types of 
conversion. The statement of the problem is easier. The work done by the 
machine is not reduced in any way. 
10-5 ARRAYS 
An array may have any number of dimensions. The size and number of 
dimensions is specified in a DECLARE statement. Both a lower and an 
upper bound to a subscript may be specified. If no lower bound is specified, 
then it is assumed to be unity. 
DECLARE 
X(10,20) 
Y(-9:21,6) 
Upper and lower bounds are separated by colons. Bounds for separate 
dimensions are separated by commas. The above statement says that X 
is a 10 by 20 matrix and Y is a 31 by 6 matrix. The first subscript, on Y, 
takes on the values - 9 , - 8 , . . . , -1,0,1,...,21. An array may be defined in 
terms of another array 
DECLARE 
S(10, 10), 
SD(10) 
DEFINED 
S(1SUB,1SUB) 
states that SD is a vector whose memory allocation is such that SD(I) 
occupies the same location as S(I,I) for I = 1, 2,..., 10. With the DEFINED 
attribute it is possible to associate any array with any liner mapping 
function, the general form is 
V(«l,«2,...,«m) 
DEFINED 
B(aO+3l*1SUB + -" + am*A77SUB,£0+b1*1SUB + ···) 
where V specifies the array whose mapping function is to be declared, nm 
specifies the range of its rath subscript. B specifies the base of the array 
onto which V is to be mapped and aO + al*lSUB + ··· specifies the map-
ping. The ai, hi, ... can be any expression involving constants or variables 
whose values are already known. 
Array elements can be used just as they are in Fortran. The PL/1 
statement 
A=X (3*I + 6,J) 
has the same meaning as it has in Fortran. Any expression can be used as a 
subscript, although it is converted to an integer before being used. Any 
type of variable, including character strings, can be arrays. If X, Y, and Z 
are three arrays with the same bounds, then 
X(|,J) = Y(I,J)+Z(I,J) 

1 0 - 6 BLOCKS AND THE D Y N A M I C USE OF MEMORY 
351 
has the same meaning as in Fortran, but 
X = Y + Z 
performs the operations that would be given by the Fortran statements, 
DO 
100 
l = IMIN, IMAX 
$ 
DO 
100 
J=JMIN,JMAX 
100 
X(l,J)=Y(lfJ)+Z(l,J) 
where (IMIN: IMAX, JMIN: JMAX) are the array bounds. There is an 
obvious extension to three or more dimensions. The addition applies to 
each element of each array. The —, *, and / operators can be used in the 
same way. Notice that 
X=Y*Z 
does not give matrix multiplication, it gives 
X(I,J)=Y(I,J)*Z(I,J) 
for each I and J. PL/1 defines a cross section of an array to be any set of 
elements of the array in which one or more subscripts are fixed and one or 
more subscripts are varied. The variable subscripts are denoted by an *; 
thus X(7,*) denotes the seventh row of X. If W is a three-dimensional array 
whose second- and third-subscript bounds agree with the first and second 
subscript bounds of X, then 
W(4,*,*)=X 
has the same effect as the Fortran 
DO 100 l = IMIN, IMAX 
$ 
DO 
100 
J=JMIN / JMAX 
100 
W(4, I, J)=X(I,J) 
With these array-type operations it is easy to see how they could be im-
plemented. It is not easy to foretell how many errors programmers will 
make in trying to use them. 
10-6 
BLOCKS and the DYNAMIC USE of MEMORY 
A Fortran program is divided into subroutines. A subroutine is useful 
from several points of view. It forms an independent unit for compilation, 
it limits the scope of local names, it allows one block of coding to be used 
for several places in one program. In many ways a subroutine is inconven-
ient, for example, COMMON and DIMENSION statements have to be 

352 
10 P R O G R A M M I N G LANGUAGE PL/1 
given in every routine. PL/1 uses a completely different organization based 
on blocks and procedure blocks. Procedure blocks will be considered in 
the next section. A block has the form, 
label: 
BEGIN 
DECLARE ... 
Statement; 
Statement; 
... 
Statement; 
END label; 
The word BEGIN always denotes the beginning of a block. Any number 
and any kind of statements may appear in the block. The label is optional. 
The DECLARE statement is optional. One block may be nested within 
another block. An example is shown in Figure 10.1. 
A.. BEGIN DECLARE X (6,2), Z FLOAT, I FIXED., N = 21., M = 7., X (2,4) = 
21.65., 
L.1.. I = 64., 
B.. BEGIN DECLARE W(N + M , N - M + 2), (Ι,Κ,Μ,Ζ) FIXED., J = 21., 
W(N,J)=X(2,4)., KK=77., 
L2.. 1 = 29., 
END B., 
L=J., 
L3.. M = l., END A., 
FIG. 10.1 An example of nested blocks 
In Fortran the name of any local variable is valid within one 
subroutine. If X is used in Fortran routine ONE and X is also used in 
routine TWO, then these are two quite different X variables. The rule in 
PL/1 is more complicated at first sight but once it is understood then it is 
easy to use and it is more convenient than the Fortran rule. The rules for 
variables that occur in a DECLARE statement are quite simple. Let 
A, B, C, ... denote names of blocks and let I, J, ..., Z denote names of 
variables. 
Rule (1) If I appears in the DECLARE statement at the head of block A, then I is 
local to block A. 
Rule (2) Suppose block B is nested in block A. Suppose I is declared in A but I is not 
declared in B. Any statement in B which refers to I will apply to the I of 
block A. 
Rule (3) Suppose block B is nested in block A. Suppose I is declared in A and I is 
also declared in B. The two variables with the name I are quite distinct. Any 
statement in B which references I refers to the I declared in B. Any statement 
which is in A but not in B refers to the I that was declared in A. 
In the example of Figure 10.1 X is local to A and W is local to B. There 
are two I's, one local to A and one local to B. Statements LI and L3 refer 
to the I that is in A, statement L2 refers to the I that is in B. The value of 
I in A is not changed by statement L2 and consequently statement L3 sets 
M equal to 64. There are two Z's, one in A and one in B. 

10 · 6 BLOCKS AND THE D Y N A M I C USE OF M E M O R Y 
353 
These rules cover the DECLARED variables, but not all variables 
need be declared explicitly. The rule is : 
Rule (4) Suppose block B is nested in block A. Suppose variable J is used in block B, 
and suppose that J is not declared in a DECLARE statement at the head of 
block B. If J is declared in block A or J is used in block A, then the J in block 
B is the same variable as the J in block A. If J has not been declared or used 
in A (or any block in which A is nested), then J is local to B and J is therefore 
declared implicitly in B. 
Referring to the example: N, M, and L are declared implicitly in A 
(assuming they do not appear in any block in which A is nested). J and 
KK are declared implicitly in B. The N that is used in block B is the same 
as the N of block A. M is declared in block B so this introduces an M 
which is not the same as the M in block A. The final result is: 
Block A. Declared explicitly: X, Z, I 
Declared implicitly: N, M, L 
Block B. Declared explicitly: W, I, K, M, Z 
Declared implicitly: J, KK 
The variables I, Z, and M which appear in block A are different from the 
variable, I, Z, and M which appear in block B. 
The operation of the compiler in assigning variables to their 
correct blocks is quite simple. It goes through the statements and makes a 
note of all identifiers. If a variable appears in a DECLARE statement, 
then it certainly goes in the list. If it appears in an ordinary statement, 
then it goes in the list only if it is not already in the list. The list built up 
by the compiler in the example of Figure 10.1 is shown in Figure 10.2. 
(XZI,N,M(WJ,K,M,Z,J,KK)L) 
FIG. 10.2 List of variables for the code shown in Figure 10.1 
The parentheses indicate the scope of the two blocks. We see that X, Z, I 
and W, I, K, M, Z go in the list because they are declared explicitly. 
N, M, J, KK are put in the list the first time they occur, but, for example, 
W(N,J) = X(2,4) does not cause N to go in the list because N is already 
there. When it comes to using variables, the mechanism is straightforward. 
When a variable is referenced, the compiler starts at the right-hand end 
of the list and searches towards the left until it finds the first variable whose 
name agrees with the one referenced. When the end of a block is reached, 
it clears the list that refers to that block, thus wiping out all knowledge of 
variables that were declared in the new block. 
The overall effect of the relation of variable names to blocks can 
be summarized as follows: If a variable is declared explicitly, then it 
represents a new variable, irrespective of what variables have been named 

354 
10 P R O G R A M M I N G LANGUAGE PL/1 
before. If a variable is used without being declared in the block head, then 
it is a new variable only if it has been used in no other place. 
During the compilation process the compiler builds up a table of 
the variables local to each block. We define a variable to be local if it is 
defined either explicitly in the block or defined implicitly in the block and 
is not defined in any other block. At execution time there is a call to the 
stack mechanism (see Section 9.3) at the beginning and end of each block. 
The memory space for local storage is assigned at the beginning of the 
execution of the block and is released at the end of the execution of the 
block. This allocation occurs anew every time the block is entered. 
The advantage of the block is that it enables the programmer to 
keep track of his use of names and it enables the compiler to assign memory 
space in an efficient and dynamic manner. The block is superior to the 
Fortran program in the convenience with which information may be passed 
from outer blocks to inner blocks. In the example of Figure 10.1 we simply 
write down 
DECLARE W(N + M, N-M + 2) 
It is not necessary to put W, N, and M in a calling sequence. The compiler 
produces instructions that cause a jump to a certain system routine at the 
start of each block. At the beginning of block B, this system routine would 
be asked to allocate (N + M)*(N + M — 2) words of the stack for use by 
the array W. The values of N and M must be known at the time at which 
the stack routine is entered. Each time the block is entered the stack routine 
is called again ; the values of N and M may vary from call to call. We can 
simply use X. We do not have to put X in Common or in the calling 
sequence. 
The PL/1 GO TO statement has the same effect as the Fortran 
GO TO statement; namely, it causes a jump to the specified statement. 
We have said that the stack mechanism is invoked on entry to a block. 
For this reason the compiler insists that all blocks must be entered at the 
beginning. While in block A of Figure 10.1, 
GO TO B 
is legitimate 
GO TO L3 
is legitimate 
GO TO L2 
is not legitimate 
Thus a statement label is local to the block in which it appears. This 
implies that the same label can be used in different blocks. A block label 
is local to the block in which it is nested. In the example block label B is 
local to block A. It is legal to jump from an inner block to an outer block. 
The compiler makes sure that the proper stack mechanism is invoked. 
This is like the Fortran DO rule; you can jump out of, but not into, a DO. 
Memory space may be allocated by three different methods— 
namely, AUTOMATIC, STATIC, or CONTROLLED. AUTOMATIC 

10 · 7 INTERNAL AND EXTERNAL PROCEDURES 
355 
implies the use of the stack mechanism. This method is used for each 
and every variable unless the programmer explicitly gives a STATIC or 
CONTROLLED (or EXTERNAL, see next section) declaration for 
that variable. 
DECLARE 
XST(200) 
STATIC 
implies that XST is an array of size 200; it also implies that storage space 
should be allocated at load time and that this storage space should never 
be released. This is similar to the usual Fortran method of memory 
allocation. 
DECLARE 
YC(21, 50 ) 
CONTROLLED 
states that YC is an array of size 1050 and that memory space should be 
under the control of the programmer. At any time during execution 
within a block for which YC is declared 
ALLOCATE 
YC 
can be used to allocate memory space to YC, using the stack mechanism 
and 
FREE 
YC 
can be used to return this space to the stack. 
10-7 
INTERNAL and EXTERNAL PROCEDURES 
An external procedure corresponds to a Fortran subroutine. It is a piece 
of program that can be compiled independently. The procedure begins 
with : 
procedure name: PROCEDURE (parameters) options data definitions 
The name must be given, the parameters, options, and data definitions are 
optional. 
ALPHA: 
PROCEDURE(A,B) ; 
DECLARE X(10,20) 
is equivalent to the Fortran 
SUBROUTINE 
ALPHA(A,B) 
DIMENSION 
X(10,20) 

356 
10 P R O G R A M M I N G LANGUAGE PL/1 
The calling statement 
CALL 
ALPHA(P,Q) 
is identical in Fortran and PL/1. To return to the discussion of the pro-
cedure heading, the procedure name specifies the main entry point; it is 
the name by which the routine is called. The parameters (if there are any) 
have the same meaning as in Fortran. The addresses that appear in the 
calling sequence are substituted for the addresses of the formal parameters. 
The options are MAIN, REENTRANT, and RECURSIVE. Re-entrant 
and recursive routines were defined in Section 9.5. A procedure returns 
to the calling program when it encounters a RETURN or the END 
statement that terminates the procedure. A function-type procedure is 
indicated by placing an argument in parentheses after the RETURN. 
Figure 10.3 illustrates a function procedure that returns the value of Y. A 
POLY.. PROCEDURE (A,X)., 
DECLARE A(5)., 
Y= ((((A(5) *X+A(4)) *X+A(3)) *X+A(2)) *X+A(1 )., 
RETURN(Y)., END POLY., 
FIG. 10.3 Example of a function procedure 
function procedure can be called simply by including it in an expression 
such as 
Z=POLY(C, X**2+1.25)*X 
The fact that the IBM 360 has several accumulators does not effect the 
situation on returned values. A function can only return one value through 
a RETURN, although in the case of a multiple-precision number this 
value may occupy several machine words. 
Procedures may be nested within procedures. Any procedure that 
lies within another procedure is an internal procedure. A procedure may 
contain many blocks that may be nested blocks. The discussion of the 
Section 10.6 applies to both blocks and procedures. The scope of a variable 
name is the block or procedure in which it is implicitly or explicitly 
declared. The stack mechanism is brought into play at the beginning or 
end of a block or procedure. The only differences between blocks and pro-
cedures are, firstly, that a block has no formal parameters and, secondly, 
that a block can be entered by control passing through from the previous 
statement. A procedure may have formal parameters, and a procedure 
must be entered by a CALL or by a function call. 
The advantage of having nested procedures is similar to that of 
nested blocks. It allows information to be passed to the routine without 
having to make explicit statements. For example, Figure 10.4 illustrates 
several ways of defining dimension. The dimension of A is given explicitly. 

10 · 8 IF AND DO STATEMENTS 
357 
The B(*) indicates that the dimension of B has been given in an outer 
block. The dimensions of C and D are defined in terms of I,J,N, and M. 
The actual size of C and D must be known when the stack mechanism 
comes to allocate memory space so the values of I,J,N, and M must have 
been set in an outer block at the time when GAMMA is called. These 
values can, of course, change in successive calls to GAMMA just as the 
size of any array can vary on successive entries to a block. 
GAMMA.. PROCEDURE (A,B,C)., 
DECLARE A(7,6),B(*),C(N*N,M*N + 2),D(I + 2,J*J)., 
FIG. 10.4 Methods of transmitting dimension information 
A PL/1 program consists of one or more external procedures. 
Within each external procedure there may be many blocks and internal 
procedures. Information can be passed from one external procedure to 
another either through a calling sequence or through an EXTERNAL 
declaration. One external procedure may call another external procedure, 
of course, just as one Fortran subroutine can call another subroutine. A 
declaration such as 
DECLARE 
Q(10,25) 
EXTERNAL 
specifies that the variable Q used in this external procedure is the same as 
the variable Q that is declared to be EXTERNAL in any other external 
procedure. An external name such as Q is similar to the name of a common 
block in Fortran. In the Fortran statement 
COMMON 
/FA/ 
A,B(20) 
the loader does not see the name A or the name B ; it sees the name FA 
and the compiler translates A into FA and B into FA + 1. In PL/1 the 
loader sees the name Q if Q is declared to be external. Variables that are 
EXTERNAL are assumed to be STATIC. 
10-8 
IF and DO STATEMENTS 
Comparison of two expressions can be made by using the operators GT, 
GE, and so on. The result of a comparison is a bit string of length 1 with 
T B signifying true and Ό'Β signifying false. This implies comparisons can 
be joined together by AND and OR operators. 
X GT Y 
has the result T B if X is greater than Y. The result is Ό'Β if X is less than 
or equal to Y. Character strings and bit strings can be compared; this is 

358 
10 P R O G R A M M I N G LANGUAGE PL/1 
done on a character by character basis. Thus 'ACB ' is less than 'ACC ' 
because the first two characters of the strings agree and comparing the 
third characters B is less than C in the sense that the EBCDIC code for B 
is less than the code for C. 
An IF statement has the form 
either 
IF 
E THEN 
S1 
or 
IF 
E THEN 
S1 
ELSE 
S2 
SI and S2 denote statements. E is usually a comparison expression with 1 
denoting true and 0 denoting false. E may be a noncomparison expression, 
however, and in this case it is converted to the type bit string. If E is a bit 
string with more than one bit, then any nonzero bit signifies true and all 
zero bits signify false. In the first form of the IF statement SI is obeyed 
if E is true, otherwise control passes to the next statement. In the second 
form SI is obeyed if E is true and then control passes to the next statement 
and S2 is bypassed. If E is false, then SI is bypassed and control goes to 
S2. If SI or S2 is a GO TO statement, then, of course, control may not pass 
to the next statement. The IF statement is similar to that of Fortran IV 
except that in PL/1, SI and S2 may also be IF statements 
IF 
X GT Y 
THEN 
IF Y GT Z THEN GO TO A ; ELSE CALL D; 
ELSE 
X=Y+1.0; 
In this example SI is an IF statement. In PL/1, SI and S2 need not be 
simple statements, they can be BEGIN blocks. 
The DO statement of PL/1 fills the same purpose as the corre-
sponding Fortran statement but it is much more powerful. The general 
form of the PL/1 DO statement is 
DO values ; 
Statement ; Statement ; Statement; 
END ; 
The term " values " specifies the values for which the loop is to be repeated. 
The loop that is repeated extends over all statements between the DO and 
the END. The values specification can take several forms. 
DO 
X=1.25TO 
Y + 6 8 . 
BY 
Z**2 
specifies that the loop should be repeated for X=1.25, X=1.25 + Z**2, 
and so on until X ^ Y + 68. This is similar to the Fortran DO but much 

10 · 9 MULTIPROCESSING 
359 
more general. The variable to be used in controlling the loop can be of any 
type; the initial value and the increment can be any expressions. The second 
form of DO is 
DO 
X=E1, E2, ···, EN 
the loop is repeated with X = E1, then with X = E2, and so on. The third 
form is 
DO 
WHILE 
E 
where E is any expression. The loop is repeated as long as E is true. Some 
statement in the loop must eventually modify E in order to terminate the 
loop, or the loop can be left by means of a GO TO statement. A 
DO... TO and a DO... WHILE may be used concurrently. Several DO... 
TO or DO... WHILE loops may be specified in one statement 
DO 
X = 1.25 TO 6.I BY 0.5 
WHILE 
Z 
GT9.; 
causes the loops to be traversed for X= 1.25, 1.75,..., 5.75, but only while 
Z is also greater than 9.0 
DO 
X - 1 . 2 5 TO 6.1, 8 TO 10 
causes the loop to be repeated for X= 1.25,2.25,3.25,4.25,5.25, 8, 9, 10. 
This DO assumes that the increment is unity, because no BY appeared. 
The END statement is used to terminate DO loops, blocks, and 
procedures. The rule is that an unlabeled END is attached to the last 
preceding DO, BEGIN or PROCEDURE. A labeled END is a statement 
of the form " END space label" ; a labeled END is attached to the BEGIN 
or PROCEDURE that has the same label. This END also terminates any 
block, procedure, or DO that lies between the END and its corresponding 
BEGIN or PROCEDURE. 
The implementation of these complicated DO statements is not 
complicated. They can be first translated into simple statements involving 
only assignment statements and IF statements. 
10-9 
MULTIPROCESSING 
Compilers have had the ability to overlap computing and input-output 
operations for many years. With the advent of the interrupt system it 
became normal practice for the system to multiprocess the interrupt 
routines, the normal execution, and the I/O operations. This ability to 
direct multiprocessing operations has been almost entirely absent from 

360 
10 P R O G R A M M I N G LANGUAGE PL/1 
compiler languages. The Fortran 63 BUFFER statements represent a 
minimal attempt at allowing the Fortran programmer to multiprogram. 
The PL/1 language does provide a series of statements for controlling 
programs that are multiprocessed. 
Let us suppose the program contains a procedure A which calls 
a procedure B 
A: 
PROCEDURE 
CALL 
B(X,Y) 
END 
A: 
In normal execution the machine obeys some statements of procedure A, 
then it obeys all the statements of B, then it comes back to A. In the multi-
processing situation we want to run A and B in parallel. In PL/1 this is 
specified by changing the calling sequence to 
CALL B(X,Y), 
TASK(BFIN) 
The word TASK is a standard system name for a process that is carried on 
in parallel with another process. BFIN is simply a location in which the 
system makes a note of how B is progressing. The library routine COM-
PLETE can be used to interrogate BFIN. COMPLETE(BFIN) has the 
value true if B is finished and false if B is still in operation. Procedure A 
should not try to use any results from B until COMPLETE(BFIN) is true. 
It is comparable to the IF(UNIT) test of Fortran 63. Any identifier may 
be used in place of BFIN but it is convenient to use a name which suggests 
that the identifier is associated with the operation of B. 
The TASK simply tells the system that B may be carried on in 
parallel with A. Whether it is carried in parallel depends on the software 
system and on the hardware. A system that has several CPU's can carry 
out any type of procedure in parallel. The standard use of TASK is to 
indicate that I/O may be overlapped with computing. 
READ 
LIST 
(S,T,U) 
is a standard PL/1 read statement. The program is delayed until S,T, and 
U have been read. 
READ 
LIST 
(S,T,U) 
TASK 
(RDSTU) 
specifies that S,T,U are to be read, but the program continues without 
waiting for them to be actually read. At some later time 
WAIT 
(RDSTU) 

10 - 10 INPUT AND OUTPUT 
361 
can be used to hold up execution until the reading task is complete. WAIT 
is a procedure that sits in a loop until the task is complete; it is an alter-
native to using 
HERE : IF (NOT COMPLETE (RDSTU)) THEN GO TO HERE; 
Any read or write operation can be specified as a task. The overall opera-
tion is similar to BUFFER IN and BUFFER OUT. 
The TASK facility allows several TASKS to proceed in parallel. 
The procedure that initiates the task can test to see if it is finished or not. 
The PL/1 language also allows for an interrupt method of operation. The 
programmer can specify such things as 
ON 
OVERFLOW 
CALL 
MINE ; 
This tells the system to call procedure MINE if an overflow interrupt 
occurs. MINE is an ordinary PL/1 procedure that the programmer writes 
and includes in his deck. MINE can take any action it wishes; on reaching 
the END of MINE, the system returns control to the point of interruption. 
As was explained in the description of interrupt routines, the interrupt 
routine need not be any different from an ordinary routine. The interrupt 
process requires hardware to cause the interrupt, and hardware or software 
to save and, subsequently, to restore the contents of the registers. 
10-10 
INPUT and OUTPUT 
Many of the PL/1 facilities for input and output are similar to those of 
Fortran. There is formatted I/O similar to that of Fortran and there is 
data directed I/O that is similar to NAMELIST. The list of data that is 
to be output may include expressions, as for example 
WRITE 
LIST (A+B/C,C**2 + X,I) 
The Fortran read statements process one read at a time. If a Fortran read 
statement spécifies that one word should be read, then one word is read 
and the rest of the record is skipped. PL/1 has an option called " procedure-
directed transmission" which allows the program to read one word at a 
time or to write one word at a time. The program specifies the file, the 
system reads the record into the buffer, and the program can use the system 
routine GET to read the record one word at a time. Similarly, the program 
can put one word into an output buffer. 
The PL/1 read and write statements do not distinguish between 
the binary and the BCD method of writing tapes. The equivalent of a 
binary write is to work with the format IG. The IG (internal general) 
format specifies that the data should be written without any conversion. 

362 
10 P R O G R A M M I N G LANGUAGE PL/1 
The general strategy for manipulating files is similar to that of Fortran IV 
under IBSYS but the more undesirable elements of that system have been 
omitted. The PL/1 programmer refers to a unit by its file name. If a READ 
or WRITE does not give a file name, then the standard input or output 
units are used. File information such as which physical device is to be 
used, maximum record length, blocking factor, and so on, is included as 
part of the program. 
The language has the statement SAVE, and its complimentary 
statement RESTORE, with which the programmer can save and retrieve 
information on an external device without specifying the device or the 
method of writing. If X is an array, then 
SAVE 
(X) 
(N) 
will save the contents of the array. N is an identifying number. The system 
remembers this number and the place where it has chosen to save X. At 
any later time 
RESTORE 
(X) 
(N) 
will retrieve the array. 
10-11 
ALGOL COMPARED to PL/1 
The concepts in PL/1 that concern the structure of the program and the 
use of memory are largely derived from Algol, but PL/1 has modified 
these ideas to eliminate the difficulties that arose in the implementation of 
Algol. The nested-block structure, the use of the stack mechanism at the 
beginning and end of a block, and the scope of local variables are similar 
in Algol and PL/1. Algol requires all variable identifiers to be defined 
explicitly. PL/1 allows the convenient implicit declaration of variables. 
The IF and DO statements are very similar in the two languages, and so 
is the ability to declare dynamic arrays bounds, the freedom to use 
nonsimple subscripts, and the use of mixed expressions. The Algol 
report specifies both numeric and alphanumeric labels, but most Algol 
compilers restrict themselves to alphanumeric labels. Algol allows multiple 
replacement statements such as 
A=B = C=1.25 
and conditional replacement statements such as 
A=IF X=2 THEN 6 ELSE Y 
which has the same meaning as the PL/1 or Algol statement 
IF X=2 THEN A - 6 ELSE A=Y 

10 · 11 ALGOL COMPARED TO PL/1 
363 
Both Algol and PL/1 allow recursive procedures. The Algol 
treatment of parameters of procedures is more general than that of PL/1. 
Suppose that the head of a procedure is 
ALPHA : 
PROCEDURE( X,l) 
and suppose the procedure is called by 
CALL 
ALPHA( Y(J),J) 
In PL/1 the subscript J in Y(J) has its value computed immediately before 
the call. Statements within ALPHA can change the value of J, but they do 
not change the value of the subscript. The Algol procedure and call state-
ments use a slightly different notation, but they imply essentially the same 
idea. The Algol treatment of formal parameters does, however, introduce 
a difference. In Algol, there are two different ways of treating formal 
parameters. If the parameter appears in a "value" declaration, then it is 
said to be called by value. If it does not appear in a "value" declaration, 
then it is said to be called by name. In the following procedure, 
procedure BETA(P,Q,L) ; value P,Q; integer P; real L,Q; 
P and Q are called by value and L is called by name. When a variable is 
called by value, then the procedure causes a copy of the value of the 
variable to be placed in some local memory space. Throughout the rest 
of the procedure, all references to the variable refer to the copy. The 
original value of the variable is never changed. The effect of the value 
statement in BETA is similar to the effect of 
procedure BETA(PDASH,QDASH,L) ; integer PDASH ; real L,QDASH ; 
begin integer P; real Q; P= PDASH; Q=DASH; 
If an array is called by value, then the whole array is copied into some 
local memory space. If a variable is called by name, then any reference 
to the variable acts on the variable that was actually named in the calling 
sequence. With the procedure ALPHA, a statement such as 
1 = 1 + 6 ; 
has the same effect in Algol as it does in PL/1 ; however the statements 
1 = 1 + 6 ; X= 1.25 ; 
do not have the same effect. Suppose that on entry to the procedure J 
has the value 10. In PL/1, 1 = 1 + 6 causes J to be set equal to 16, and 
X= 1.25 causes Y(10) to be set equal to 1.25. In Algol, 1 = 1 + 6 sets J equal 

364 
10 P R O G R A M M I N G LANGUAGE PL/1 
to 16, but X=1.25 would set Y(16) equal to 1.25. In Algol, if the value 
of I is changed within ALPHA, then both J and the subscript value change. 
This dynamic use of parameters can produce some interesting programs 
(see, for example, Chapter 20 of Dijkstra, 1962), but it almost inevitably 
leads to inefficiency (see Ingerman, 1961). The designers of PL/1 have 
evidently decided to limit themselves to the address-substitution method 
and to avoid the more powerful, but potentially inefficient, dynamic 
evaluation of parameters. All Algol procedures are internal to some block. 
The PL/1 internal procedure gives the convenience of an Algol procedure. 
The PL/1 external procedure allows the efficient compilation of very large 
programs. 
These similarities between PL/1 and Algol concern only a small 
part of the whole PL/1 language. Algol is an elegant and powerful language 
for describing numerical algorithms. PL/1 is a language for describing the 
processes that can be carried out by a large computer system. As we have 
seen, the power of the computer lies in its ability to manipulate symbols 
as well as its ability to do arithmetic. 
10-12 The MACRO-PROCESSOR 
The idea of the PL/1 macro-processor is quite simple but of far-reaching 
importance. The idea is developed from the macro-feature of Fap and 
Map. A PL/1 program can consist of macro-statements and ordinary 
statements. A macro-statement is distinguished from an ordinary state-
ment by the appearance of the symbol % at the start of the statement. 
Compilation occurs in several stages. In stage one the macro-processor 
goes through the text of the program, and it makes changes to that text. 
In stage two the modified text is compiled. In stage one the macro-
processor obeys macro-statements. Any variable used in a macro-statement 
is a macro-variable 
% N = 6 ; % M = 21 
sets the macro-variable N equal to 6 and the macro-variable M equal to 21. 
The macro-processor scans ordinary statements and if it encounters any 
macro-variable, it substitutes their current value. If N and M are defined 
as above and if A, I and X are not macro-variables, then 
A(l + N, M + N)=X + N 
is changed into 
A(l + 6,27) = X+6 

PROBLEMS 
365 
The Statements 
% L1 : N = N - 2 
; 
A(I,N) = X 
; 
% IF 
N.GE.2 
THEN 
GO 
TO 
L1 
would produce 
A(I,4) = X 
; 
A(I,2)=X 
; 
A(l,0) = X 
When the macro-processor has obeyed all macro-statements and scanned 
all ordinary statements, then the final text is submitted to the compiler. 
The macro-processor allows the programmer to use the computer 
to systematically modify the text of his program before the text is processed 
by the compiler. An alternative and potentially more powerful feature 
could have been implemented. Any PL/1 program can manipulate strings of 
characters. In place of the macro-processor the designers of the PL/1 system 
could have provided (a) procedures that perform text editing similar to that 
of the macro-processor but that can be called during normal execution, 
(b) a procedure that could be called by CALL COMPILE(TEXT) during 
normal execution and that would take the character string TEXT, compile 
it, and allow the compiled program to be called into execution. This type 
of processor would offer many advantages not afforded by the current 
macro-processor. 
10-13 
SUMMARY 
An algorithmic language is a series of symbols that can be used to 
specify an algorithm. The language must have a semantics; that is, the 
language must attach some meaning to any set of legitimate symbols. 
Fortran takes most of its semantics from standard mathematical notation ; 
thus X = Y + Z means add the number Y to the number Z and call this 
new number X. The notion of number is assumed to be defined in some 
suitable sense. There is no reason why X = Y + Z should have this mean-
ing. The language may attach any meaning it wishes to the symbols +, 
X, Y, and Z, and it may vary the meaning, depending on the context. If 
the language is well designed, then the semantics aids the user in expressing 
his thoughts unambiguously and concisely. PL/1 is a more difficult language 
than Fortran or Algol largely because it allows a much wider range of 
expression. 
PROBLEMS 
1 ■ Write Fortran routines that perform the same operations as the 
character operations of PL/1. The first routine should be analogous 
to the DECLARE routine of Section 9.2. CALL DEFINE(X,N) 

366 
10 P R O G R A M M I N G LANGUAGE PL/1 
should reserve space of N characters and put a pointer to this space 
in X. CALL STRING (Χ,ΙΟΗΑΝΥ STRING, 10) should store the 
ten specified characters in the space reserved by X. SUBSTR should 
be similar to the PL/I routine. 
2 ■ Write Fortran routines that perform the same operations as the bit 
string operations of PL/I. 
3 ■ The DEFINED attribute is described in Section 10.5. Show how this 
could be implemented in the context of the subroutine DECLARE 
of Section 9.2. 
V(A?1,A>2, ...) DEFINED B(a0 + a1*1SUB + ···, bO + ···) 
could be translated into the Fortran form 
CALL DEF(V,M,I1,I2,B) 
where M is a matrix of order II by 12 with M(l,l) = αθ, M(l,2) = 
al, ... M(2,l) = bO and so on. The information specified by nl, 
«2, ... is not needed; the Fortran routine can assume that the limits 
of the Y subscripts can be determined from the limits of the B sub-
scripts. 
4 "Explain the meaning of the PL/I statements 
DECLARE X ( - 9 : 1 2 , 1 0 : 20), Y(10:20): 
Y=X(0,*) : 
5 ■ A PL/I program requires the simultaneous use of four arrays whose 
names are A, B, C, and D. The values of L, M, and N are to be read 
as data. A has the dimension N by N; B has N by M ; C has M by M ; 
and D has L by M by N. Show how these dimensions are specified 
in the program. Does the dimension statement come before or after 
the READ statement? 
6 ■ If you had to translate a Fortran program into PL/I, how would you 
treat the Common variables if (a) the PL/I program had one external 
procedure and several internal procedures, (b) the PL/I program had 
several external and internal procedures. Suppose the Fortran routine 
ALPHA uses V as a Common variable, and suppose the Fortran 
routine BETA uses V as a local variable. If BETA becomes the PL/I 
procedure BETA, how would you make sure that V is local to the 
procedure BETA ? 
7 ■ In a PL/I program, how does the compiler decide which variables 
belong to which block ? Suppose you write a block of code which is 
to be embedded in some larger block of code which is written by 
someone else. How could you ensure that your variable names did 
not conflict with any of their names ? At what point is memory space 

PROBLEMS 
367 
allocated ? If a Fortran program is too large, then it is usually rejected 
by the loader. Can a PL/I program fail in the middle of execution 
because it tries to use too much memory space or will the loader 
always detect programs that are too large? 
8 ■ The GET statement is described in Section 10.10. Does this represent 
a completely new method of doing I/O or is it a minor variation of the 
scheme described in Section 5.10? Explain your answer. 
9 ■ If I and J are character strings with I = 'JUNE' and J = 'JULY\ is 
IF(I LT J)THEN K=1 ELSE K=2 
a legitimate statement? If it is legitimate, then what will be the final 
value of K? 
10" What is the difference between an internal and an external procedure ? 
What are the advantages of being able to nest procedures and blocks : 
can it lead to more efficient programs ? 

REFERENCES 
ARDEN, B. W., An Introduction to Digital Computing, Addison-Wesley, 
Reading, Mass., 1963. 
Automatic Data Processing Glossary. Bureau of the Budget, published by 
U.S. Government Printing Office, Washington, D.C., 1962. 
BAKER, C. L., "The Pact 1 Coding System for the IBM Type 701," Jour. 
A.C.M., 3, pp. 272-278, 1956. 
BARTON, R. S., "A New Approach to the Fundamental Design of a Digital 
Computer," Proc. Western Joint Computer Conf, pp. 393-396, 
1961. 
BRAUN, E. L., Digital Computer Design. Academic, New York, 1963. 
BUCKHOLZ, W., Planning a Computer System. McGraw-Hill, New York, 
1962. 
CAIN, J. C , HENDRICKS, S., DANIELS, W. E. and JENSEN, D. C , Computa-
tions of the Main Geomagnetic Field From Spherical Harmonics 
Expansion. N.A.S.A. Report X-611-64-316, 1964. 
CHAPIN, N., An Introduction to Automatic Computers. Van Nostrand, 
Princeton, 1957. 
CORBATO, F. J. and VYSSOTSKY, V. A., "Introduction and Overview of the 
Multics System," Proc. Fall Joint Computer Conf, pp. 185-196, 
1965. Spartan Books, Washington, D.C. 
CRISMAN, P. A. (Editor), The Compatible Time Sharing System. M.I.T. 
Press, Cambridge, Mass., 1965. 
DALEY, R. C. and NEUMANN, P. G., "A General-Purpose File System for 
Secondary Storage," Proc. Fall Joint Computer Conf, pp. 213-241, 
1965. Spartan Books, Washington, D.C. 
DAVIS, M., Computability and Unsolvability. McGraw-Hill, New York, 
1958. 
DEVONALD, C. H. and FOTHERINGHAM, J. A., "The Atlas Computer," 
Datamation, 7, 5, pp. 23-27, May, 1961. 
DIJKSTRA, E. W., A Primer of Algol 60. Academic, New York, 1962. 
368 

REFERENCES 
369 
FEIGENBAUM, E. A. and FELDMAN, J. (Editors), Computers and Thought. 
McGraw-Hill, New York, 1963. 
GLASER, E. L. and, OLIVER, G. A., "System Design of a Computer for 
Time-Sharing Applications," Proc. Fall Joint Computer Conf, 
pp. 197-202, 1965. Spartan Books, Washington, D.C. 
GRIESS, D., PAUL, M. and WIEHLE, H. R., "Some Techniques Used in the 
Alcor-Illinois 7090," Comm. A.C.M., 8, pp. 496-500, 1965. 
HAMBLIN, C. L., "Translation to and from Polish Notation," Comp. Jour., 
5, pp. 210-213, 1962. 
HASSITT, A., "Design and Implementation of a General-Purpose Input 
Routine," Comm. A.C.M., 7, pp. 350-355, 1964. 
HASSITT, A., "Data Directed Input-Output in Fortran," Comm. A.C.M., 
January, 1967 (to be published). 
HUSKEY, H. H., "An Introduction to Procedure Orientated Languages," 
in Advances in Computers, 5, pp. 349-377, Academic, New York, 
1964. 
INGERMAN, P. Z., "Thunks," Comm. A.C.M., 4, pp. 55-58, 1961. 
KLERER, M. and MAY, J., "Two Dimensional Programming," Proc. Fall 
Joint Computer Conf, pp. 63-73, 1965. 
KORY, M. and BERNING, P., "The STL Integrated Computer System," 
Proc. A.C.M. Conf., 1964. Spartan Books, Baltimore, Md. 
MCCARTHY, J., "Recursive Functions of Symbolic Expressions and Their 
Computation by Machine, Part 1," Comm. A.C.M., 3, pp. 184— 
195, 1960. 
MCCARTHY, J., ABRAHMS, P. W., EDWARDS, D. J., HOLT, T. P., and LEVIN, 
M. I., Lisp 1.5 Programmers' Manual, M.I.T. Press, Cambridge, 
Mass., 1962.. 
MCCRACKEN, D. D., A Guide to Fortran IV Programming. Wiley, New 
York, 1965. 
MCCRACKEN, D. D. and DORN, W. S., Numerical Methods and Fortran 
Programming. Wiley, 1964. 
MCILROY, M. D.," Macro Extensions of Compiler Languages," Comm. 
A.C.M., 3, pp. 214-220, 1960. 
MITCHELL, M. F., 7090 CPYCHN: A Program to Copy and. Merge Chain 
Links Produced by the Fortran II System, IBM Program 7090-
1472-IGCPCN. 
NAUR, P. (Editor), " Revised Report on the Algorithmic Language Algol 
60," Comm. A.C.M., 6, pp. 1-17, 1963. 
NEWELL, A. (Editor), Information Processing Language-V Manual. Prentice-
Hall, Englewood Cliffs, 1961. 
OETTINGER, A. G., "A Bull's Eye View of Management and Engineering 
Information Systems," A.C.M. Proc. of 19th National Conf, 
B.l-1, 1964. Spartan Books, Baltimore, Md. 
PYLE, I. C , "Character Manipulation in Fortran," Comm. A.C.M., 5, 
pp. 432-433, 1962. 

370 
REFERENCES 
PYLE, I. C , " Implementation to Fortran on Atlas," in P. Wegner (Editor), 
Introduction to System Programming. 
Academic, New York, 1964. 
RANDELL, B. and RUSSELL, L. J., Algol 60 Implementation. 
Academic, New 
York, 1964. 
ROSEN, S., SPURGEON, R. A., and DONNELLY, J. K.," PUFFT—The Purdue 
University Fast Fortran Translator," Comm. A.CM., 
8, pp. 661— 
666, 1965. 
SCHUSSEL, G., " I B M vs R E M R A N D , " Datamation, 
11, p. 54, and 12, 
p. 58, 1965. 
SCHWARTZ, J. I., COFFMAN, E. G., and WEISMANN, C , Potentials 
ofaLarge-
Scale Time Sharing System. 
System Development Corporation 
SP-1723, 1964. 
SMITH, P. J., "Symbolic Derivatives Without List Processing, Subroutines 
or Recursion," Comm. A.C.M., 8, pp. 494-496, 1965. 
STAVROUDIS, O. N., "Automatic Optical Design," Advances in Computers, 
5, pp. 227-255, Academic, New York, 1964. 
TOBEY, R. G., BOBROW, R. J., and ZILLES, S. N., "Automatic Simplification 
in Formac," Proc. Fall Joint Computer Conf., pp. 37-53, 1965. 
Spartan Books, Washington, D.C. 
VYSSOTSKY, V. A., CORBATO, F. J., and GRAHAM, R. M . , " Structure of the 
Multics System," Proc. Fall Joint Computer Conf., pp. 203-212, 
1965. Spartan Books, Washington, D.C. 
WEIZENBAUM, J., "Slip—A Symmetric List Processor," Comm. A.CM., 
6, 
pp. 524-544, 1963. 
WILKES, M. V., WHEELER, D. J., and GILL, S., The Preparation of Programs 
for an Electronic 
Digital 
Computer. 
Addison-Wesley, Reading, 
Mass., 1951. 

Accumulator, 47, 48, 79, 90, 103, 224 
Ackerman, 329, 368 
Address, 47, 48, 247, 311, 319, 325 
A format, 256, 264, 269 
Algol, 19-23, 36, 129, 329, 331, 363, 369 
Allocate, 312, 315, 320 
Alphanumeric, 60, 92, 180 
And, 59, 144, 260, 261, 262, 349, 367 
Arden, 53, 282, 315, 331, 368 
Argument (of subroutine), 223, 329, 
332 
Array, 21 
Assembler, 50, 70, 79, 104, 114-121, 
132, 147,205 
Associative memory, 326 
Atlas, 324, 368, 370 
Atomic symbol, 335-341 
Baker, 6, 368 
BAL (branch and link), 249, 250 
Bank register, 83 
Barton, 97, 368 
Base address, 106, 115,231,251 
Base register, 319, 321 
BCD, 57, 109, 180-184, 254, 258, 269, 
361 
Berning, 29, 369 
Binary, 7, 16,34,36,361 
Binary addition, 45, 46 
Binary card, 7, 16,238 
Binary notation, 42-46, 48 
Binary tape, 183,269 
Bit, 32 
Bit string, 347, 349, 357, 358 
Blank common, 236, 241, 245 
Block, 21, 37, 352, 353, 354, 364 
Block common, 236, 245 
Blocked tapes, 190-196 
Boolean, 59, 96, 130,261 
Branch, 3, 108, 115,249 
Braun, 32 
Breakpoint, 244 
BSS, 52, 133, 137, 157,231 
Buckholz,98, 368 
Buffer, 19, 25, 188-190, 192-197, 360 
Buffer in, 186, 187, 189 
Buffer out, 186, 187, 189, 190 
Burroughs B5000, 327 
BYTE, 34, 40, 61,78, 103, 107 
Cain, 297, 368 
Call by name, 363 
Call by value, 363 
Card image, 17, 255 
INDEX 
371 

372 
INDEX 
CAT, 345, 349 
CDC 1604, 13,78-89,248 
CDC 3600, 13, 14, 82, 83, 176, 297 
CDC 6600, 31-32, 99-102, 213-215 
Central processor, 99-102, 214, 215 
(see also CPU) 
Chain, 206, 302-307 
Channel, 9, 10, 12, 34, 169-172, 208, 
213,216 
Chapin,4,368 
Character, 20, 60, 61, 90, 91, 92, 93, 
110,127, 161, 162,254-284 
Character string, 347, 349, 350, 357, 
358 
Characteristic, 64, 68, 89, 105 
CODAP, 79 
Command, 12, 170, 171 
Common, 234-237, 241, 245, 305, 312, 
317,351 
Complement, 86 
Complex, 130, 131,136 
Compile, 6, 7, 8 
Compiler, 6, 7, 8, 132, 204, 265 
Condition code, 109 
Control cards, 304 
Control instruction, 3, 49 
Control register, 47, 49, 54 
Control section, 244, 245, 249-251 
Corbato, 204, 368, 370 
Core memory, 4, 27, 28, 33,42, 209 
CP (central processor), 99-102, 214, 
215 
CPU (central processing unit) 10, 12, 
29,30,31,37, 170,216 
Crisman, 212, 368 
CSECT, 250 
Daley, 202, 368 
Data channel, see Channel 
Data statements, 245-247 
Davis, 53 
DC (define constant), 115, 118-121 
DEC, 51, 52 
Decimal, 34,36,90,91 
Decimal notation, 42-46, 75 
Decode, 268-271,308 
Decrement, 335, 336 
Density, 176 
Devonald, 324, 368 
Dijkstra, 364, 368 
Dimension, 137, 230-233, 246, 351 
Directory, 322, 325 
Disable, 172 
Disk, 27, 28, 29, 31, 41, 99, 177-178, 
180,209,210 
Displacement, 106, 116, 251 
Dope vector, 315, 316 
Dorn, 294, 369 
Double, 130, 131, 136 
Drum, 28, 42, 99, 177, 180, 322, 324 
DS (define storage), 120, 121 
DSECT, 250 
EBCDIC, 181,182,358 
Edsac,2,3, 15,38 
Encode, 268-271,273,350 
End-of-file, 168, 169, 197 
Enable, 172 
Eniac, 2, 38 
Error, 225, 226, 227, 293 
Exchange jump, 214 
Execution monitor, 15 
External procedure, 7, 355-357, 364 
External symbols, 237, 238, 241, 242 
Factorial, 328, 329 
FAP, 14, 16, 262 
Feldman, 339, 369 
F format, 256, 258, 272 
Fiegenbaum, 339, 369 
File, 197-202 
Filename, 198, 199, 362 
File-protect, 169 
Floating point, 62-68, 79, 80, 89, 105, 
134,347 
FMS (Fortran monitor system), 14, 16-
19, 25, 26 
For, 21 
Formal differentiation, 331 
Format free, 264-268, 271-273 
Fortran, 6, 7, 20, 22, 23, 31, 36, 127-
165, 184-190,220-284 
Function subroutine, 220, 230 
Gill, 4, 369 
Glaser, 212, 369 
Gries, 23, 369 
Hamblin, 95, 369 
Hardware, 15, 30, 33, 208, 215, 216, 
321,323,326 
Hassitt, 266, 268,273,369 
Hexadecimal, 105, 118 
Hollerith, 57, 70, 347 
Huskey, 282, 369 
IBJOB, 24, 26 
IBLDR, 244-245 

INDEX 
373 
IBM 1401,16,28,93,94 
IBM 1620, 90-93, 249-251, 319, 321, 
324-327 
IBM 360 (Model 67), 324-327 
IBM 650, 78 
IBM 704, 4, 5, 8,9,31 
IBM 7070, 35 
IBM 709, 8,9,10, 12 
IBM 7090, 12, 14, 23, 28, 33, 41-77, 
176, 248 
IBM 7094, 13,23,297 
IBSYS, 22, 23-27, 362 
Identifier, 20, 128,345 
I format, 256 
Index register, 47, 57, 68-70, 80, 81, 91, 
103, 138, 139, 224, 225, 229, 231, 
247 
Indirect address, 247-249 
Ingerman, 364, 369 
Internal procedure, 355-357, 364 
Interrecord gap, 168, 171 
Interpreter, 8 
Interrupt, 12-14, 25, 29, 38, 39, 68, 172-
175, 205, 208, 209, 212, 216, 323, 
327,361 
IOCS, 24, 25, 196-198 
IOEX, 24, 25, 196-198 
IPL-V, 334, 369 
I/O bound, 30 
Jump, 3, 49, 54, 93 
KDF9, 96-98 
Klerer, 127 
Kory, 29 
Label, 51,55, 114, 115, 197 
Labelled common, 236, 305 
Library, 17 
Linkage director, 227, 228 
Lisp, 334, 335, 336, 338, 339, 369 
List, 334-341 
List processing, 334-341 
Literal, 70, 71, 120 
Loader, 17, 205, 220, 222, 238-245, 
302-307 
Local, 233, 317-3.20, 352, 353, 354 
Local variable, 233 
Location, 3, 42, 44, 46, 314 
Logical expression, 130, 144, 145 
Logical operations, 33, 57, 78, 259 
Logical product, 32 
Logical record, 184, 185, 191 
Logical sum, 32 
Logical unit, 198 
Logical variable, 130, 136, 144, 145 
Lukasiewicz, 95 
MAC, 212 
Machine language, 4, 6, 8, 33, 34, 41, 
50, 148 
Macro, 146-151, 160, 161, 164, 165, 
364, 369 
MAD, 315 
Magnetic core, 42 {see also Core mem-
ory) 
Magnetic disk, see Disk 
Magnetic drum, see Drum 
Magnetic tape, see Tape 
MAP, 24 
Mapping function, 314, 315, 350 
May, 127, 369 
McCarthy, 334, 339, 369 
McCracken, 22, 294, 369 
Memory, 2, 3, 41, 42, 44, 103, 314, 321, 
326 
Memory-virtual, 321-328 
Merge, 268 
Microsecond, 27 
Millisecond, 27 
Mitchell, 303, 369 
Monitor, 14, 15,68,114,216 
MQ (multiplier-quotient register), 47, 
79,103,224 
Multiplexor, 12 
Multiprocessing, 359-361 
Multiprocessor, 29 
Multiprogramming, 29, 30, 102, 205, 
208-213,334 
Namelist, 273-278, 295, 314, 361 
Naur, 20, 369 
Negative, 44, 86, 89, 92 
Neumann, 202, 368 
Newell, 334, 369 
Normalized, 63, 64 
NOT, 59, 144, 260, 262, 349 
N P L , ^ P L / 1 
Octal, 70, 75 
Octal addition, 45, 46 
Octal notation, 43-46, 75 
Oettinger, 285, 369 
O format, 256 
OWer,212, 369, 370 
OR, 60, 144, 260, 262, 349, 367 
ORG, 51 

374 
INDEX 
Overflow, 68, 109 
Overlay, 302-307 
Page, 322-328 
Page directory, 322, 325 
Parameter, 229, 317 
Paul, 23, 369 
Peripheral processor, see PP 
Physical record, 184, 185, 189, 190, 191 
Physical unit, 198 
PL/1, 35-37, 321, 333, 334, 343-367 
Polish, 95,96, 97,98, 124 
PP (peripheral processor), 31, 32, 99, 
213,214,215 
Preaddressed tape, 176, 177 
Procedure, 21, 37, 352, 355-357, 363, 
364 
Prologue, 233 
Pseudo-instruction, 51 
PSW (program status word), 103, 109, 
114,172,173 
Push-down, 96, 97 
Pyle, 204, 271,369, 370 
Randall, 96, 315,370 
Reactive, 211,212 
Record, 9, 168, 177, 184, 185 
Recursion, 328-334, 339, 340, 356, 363 
Re-entrant, 333,334, 356 
Relocation, 132, 214, 221, 222, 235, 
238-245 
Relocatable binary card, 7, 16 
Reverse Polish, 95, 96,98 
Rewind, 169 
R format, 256, 263,264 
Rosen, 123,390 
Routine, see Subroutine 
RR instructions, 104, 106, 108, 110-114, 
117 
RS instructions, 104, 107, 108, 110, 
113, 117 
RTJ, 150,220,224 
Russell, 96, 315, 370 
RX instructions, 104, 106, 108, 110-
113,117 
SAP, 5,6,7, 14 
Scheduling, 209 
Schwartz, 30, 212,370 
Scope, 199 
Scratch file, 198, 199 
Semantics, 20, 365 
Share, 5 
Shift, 57, 257, 261,262 
Sign, 44, 57, 86, 105 
SI instructions, 104, 108, 1 13, 114, 118 
Slip, 334, 370 
Smith, 331, 370 
Software, 
15, 32, 79, 102, 204, 208, 
215,216,321 
SOS (share operating system), 11 
SS instructions, 104, 108, 111, 112, 118 
Stack, 96, 97, 124, 125, 318-321, 332, 
333,341,354,355 
Stavroudis, 295, 370 
Storage mapping function, see Mapping 
function 
Subroutine, 7, 21, 37, 149-151, 220-251, 
289-292, 329, 354 
Subroutine argument, see argument 
Subscript, 137-142, 152, 155, 315, 316, 
351,363 
Symbolic expression, 335-341 
Symbolic instructions, 5, 6, 50, 148 
Syntax, 20 
System file, 198, 199 
Tape, 27, 28, 41, 42, 167-169, 175, 176, 
180 
Time sharing, 27-31, 39, 208-213, 327 
Transfer instruction, 3, 54, 93 
Transfer vector, 243 
Truth table, 162, 163 
Tobey, 331,339, 370 
TSX, 150,220,224 
Typewriter, 30, 179, 210, 211, 255 
Underflow, 68 
Use, 160, 161 
Using, 116, 117 
Utility file, see Scratch file 
Value, 363 
Variable dimensions, 232, 300 
Virtual memory, 321-328 
Vyssotsky, 212, 368 
Weizenbaum, 335, 370 
Wheeler, 4, 370 
Wiehle, 23, 369 
Wilkes, 4, 370 
Word, 9, 34, 90, 107, 167 

