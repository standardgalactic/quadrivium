Cognitive Technologies
Christos Papakostas
Christos Troussas
Cleo Sgouropoulou
Special Topics 
in Artificial 
Intelligence and 
Augmented 
Reality
The Case of Spatial Intelligence 
Enhancement

Cognitive Technologies
Editor-in-Chief
Daniel Sonntag, German Research Center for AI, DFKI, 
Saarbrücken, Saarland, Germany

Titles in this series now included in the Thomson Reuters Book Citation Index 
and Scopus!
The Cognitive Technologies (CT) series is committed to the timely publishing of 
high-quality manuscripts that promote the development of cognitive technologies 
and systems on the basis of artificial intelligence, image processing and 
understanding, natural language processing, machine learning and human-computer 
interaction.
It brings together the latest developments in all areas of this multidisciplinary topic, 
ranging from theories and algorithms to various important applications. The 
intended readership includes research students and researchers in computer science, 
computer engineering, cognitive science, electrical engineering, data science and 
related fields seeking a convenient way to track the latest findings on the foundations, 
methodologies and key applications of cognitive technologies.
The series provides a publishing and communication platform for all cognitive 
technologies topics, including but not limited to these most recent examples:
•	 Interactive machine learning, interactive deep learning, machine teaching
•	 Explainability (XAI), transparency, robustness of AI and trustworthy AI
•	 Knowledge representation, automated reasoning, multiagent systems
•	 Common sense modelling, context-based interpretation, hybrid cognitive 
technologies
•	 Human-centered design, socio-technical systems, human-robot interaction, cog­
nitive robotics
•	 Learning with small datasets, never-ending learning, metacognition and 
introspection
•	 Intelligent decision support systems, prediction systems and warning systems
•	 Special transfer topics such as CT for computational sustainability, CT in busi­
ness applications and CT in mobile robotic systems
The series includes monographs, introductory and advanced textbooks, state-of-the-­
art collections, and handbooks. In addition, it supports publishing in Open 
Access mode.

Christos Papakostas  •  Christos Troussas  •  
Cleo Sgouropoulou
Special Topics in Artificial 
Intelligence and Augmented 
Reality
The Case of Spatial Intelligence 
Enhancement

ISSN 1611-2482	
        ISSN 2197-6635  (electronic)
Cognitive Technologies
ISBN 978-3-031-52004-4        ISBN 978-3-031-52005-1  (eBook)
https://doi.org/10.1007/978-3-031-52005-1
© The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024
This work is subject to copyright. All rights are solely and exclusively licensed by the Publisher, whether 
the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of 
illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and 
transmission or information storage and retrieval, electronic adaptation, computer software, or by similar 
or dissimilar methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication 
does not imply, even in the absence of a specific statement, that such names are exempt from the relevant 
protective laws and regulations and therefore free for general use.
The publisher, the authors, and the editors are safe to assume that the advice and information in this book 
are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the 
editors give a warranty, expressed or implied, with respect to the material contained herein or for any 
errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional 
claims in published maps and institutional affiliations.
This Springer imprint is published by the registered company Springer Nature Switzerland AG
The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland
Paper in this product is recyclable.
Christos Papakostas
Department of Informatics and Computer 
Engineering
University of West Attica
Εgaleo, Greece
Cleo Sgouropoulou
Department of Informatics and Computer 
Engineering
University of West Attica
Egaleo, Greece
Christos Troussas 
Department of Informatics and Computer 
Engineering
University of West Attica
Egaleo, Greece

v
Foreword
In the pages of this book, titled Special Topics in Artificial Intelligence and 
Augmented Reality with the subtitle The Case of Spatial Intelligence Enhancement, 
lies a comprehensive exploration of AI and AR at the intersection of spatial intelli­
gence. This book offers an in-depth examination of both theoretical and practical 
aspects, guiding the way toward enhancing spatial intelligence in the era of techno­
logical convergence. Readers will find valuable insights, diverse case studies, and a 
roadmap for navigating the evolving landscape of technologies that enhance human 
cognition.
This work spans various critical subjects, including the foundations and applica­
tions of AI and AR, their symbiotic relationship, and their combined impact on the 
development of spatial intelligence. The authors have undertaken a commendable 
effort to bring together expertise from diverse domains, providing a comprehensive 
view of this captivating field. By addressing both the theoretical underpinnings and 
real-world applications, this book serves as a bridge, connecting scholarly discourse 
to practical implementation, offering a clear and comprehensive understanding of 
the subject matter.
One of the notable strengths of this work is its ability to illuminate the vast poten­
tial of AI and AR in enhancing human spatial intelligence. The authors have curated a 
collection that not only sheds light on the transformative impact of these technologies 
but also encourages interdisciplinary discourse. Scholars, educators, and profession­
als alike will benefit from the diverse perspectives presented, fostering a deeper under­
standing of the profound influence of AI and AR on spatial intelligence enhancement.
In conclusion, this book represents a valuable resource that underscores the criti­
cal juncture of AI, AR, and spatial intelligence. The authors’ collective expertise 
and their commendable effort in bringing together various facets of this field make 
this work an essential asset for anyone seeking a comprehensive and insightful 
exploration of the subject. It is my hope that this book will inspire, inform, and 
spark further research in this dynamic and ever-evolving domain.
Professor of Computer Science, University of the Philippines
Jaime Caro, 
Quezon City, Philippines

vii
Preface
In an ever-evolving world driven by technological advancements, the intersection of 
spatial intelligence, augmented reality, and fuzzy logic user modeling has emerged 
as a captivating frontier of research and innovation. These three interconnected 
realms are not only at the forefront of technological development but also have the 
potential to reshape and enhance a multitude of domains, including education, arti­
ficial intelligence, and industry. However, while these concepts have made waves in 
academic circles and technology hubs, their integration into education remains rela­
tively uncharted territory.
This book sets out to bridge this gap and provide an insightful perspective on the 
transformative power of spatial intelligence, augmented reality, and fuzzy logic user 
modeling in the realm of education. In our pursuit of this endeavor, we propose an 
innovative approach that combines adaptive hypermedia with mobile training appli­
cations. This groundbreaking method seeks to revolutionize the delivery of educa­
tional content by tailoring it to the specific needs and preferences of each learner.
The use of augmented reality in this approach is a cornerstone of our endeavor, 
offering a dynamic and interactive learning environment. By superimposing digital 
content onto the physical world, learners can engage with educational materials in a 
manner that is not only immersive but also profoundly tangible. This approach not 
only encourages active participation but also stimulates creativity and deepens 
understanding through visualizations, simulations, and real-time feedback.
What truly sets this approach apart is its incorporation of spatial intelligence 
training within the augmented reality experience. This facet enhances learners’ abil­
ity to perceive and comprehend spatial relationships, nurturing skills such as spatial 
visualization, mental rotation, and spatial reasoning, which hold significant value 
across various academic disciplines and real-world applications.
Further enhancing the learning experience is the integration of fuzzy logic user 
modeling, which ensures that educational content adapts to the unique preferences, 
learning pace, and strengths of each individual. This personalized approach custom­
izes the presentation and difficulty level of content based on the learner’s responses, 
thus optimizing the learning journey, and making it not only more efficient but also 
more effective.

viii
To comprehensively evaluate the effectiveness and impact of our proposed 
approach, this book presents a multi-model evaluation based on Lynch and 
Ghergulescu’s framework. This evaluation includes various methodologies such as 
t-test analysis, control and experimental groups, and an extended technology accep­
tance model (TAM) for validation. The amalgamation of these diverse evaluation 
methods empowers readers to draw robust conclusions about the significance of 
integrating adaptive hypermedia into mobile training applications with augmented 
reality.
Through this comprehensive evaluation, we seek to underscore the potential of 
this approach to revolutionize education and contribute to advancements in 
technology-­enhanced learning and cognitive development. The findings of our 
study offer valuable insights for educators, policymakers, and researchers who 
aspire to leverage emerging technologies to create personalized and impactful learn­
ing experiences. It is our belief that this approach has the power to transform the 
way knowledge is disseminated and acquired, ushering in a new era of progress in 
the fields of education, technology, and artificial intelligence, and opening up excit­
ing avenues for further research and exploration.
As you set off on this journey through the pages of this book, we invite you to 
explore, learn, and imagine the future of education through the lens of spatial intel­
ligence, augmented reality, and fuzzy logic user modeling. Together, we will embark 
on a transformative voyage that holds the promise of shaping a brighter and more 
personalized educational landscape for generations to come.
Egaleo, Greece
Christos Papakostas  
Egaleo, Greece 
Christos Troussas  
Egaleo, Greece 
Cleo Sgouropoulou  
Preface

ix
Contents
	1	
Introduction and Overview of AI-Enhanced Augmented Reality 
in Education����������������������������������������������������������������������������������������������      1
	1.1	 Overview������������������������������������������������������������������������������������������      1
	1.2	 Motivation����������������������������������������������������������������������������������������      2
	1.3	 Research Questions��������������������������������������������������������������������������      6
	1.4	 Approach and Structure��������������������������������������������������������������������      7
References��������������������������������������������������������������������������������������������������      8
	2	
Review of the Literature on AI-Enhanced Augmented Reality 
in Education����������������������������������������������������������������������������������������������    13
	2.1	 Overview������������������������������������������������������������������������������������������    14
	2.2	 Spatial Ability: Review of Theories��������������������������������������������������    14
	2.2.1	 Spatial Ability in Engineering����������������������������������������������    15
	2.3	 Augmented Reality in Education������������������������������������������������������    20
	2.3.1	 AR in Engineering Education����������������������������������������������    21
	2.4	 Learning Theories ����������������������������������������������������������������������������    22
	2.4.1	 The Bloom’s Taxonomy��������������������������������������������������������    22
	2.4.2	 The SOLO Taxonomy����������������������������������������������������������    22
	2.4.3	 Comparison of the Learning Theories����������������������������������    23
	2.5	 Literature Review������������������������������������������������������������������������������    25
	2.5.1	 Planning the Review (Review Protocol)������������������������������    26
	2.5.2	 Conducting the Review��������������������������������������������������������    27
	2.5.3	 Screening of the Evaluation Papers��������������������������������������    28
	2.5.4	 Advantages of AR in Spatial Ability Training (RQ1)����������    31
	2.5.4.1	
Learner Outcomes ������������������������������������������������    31
	2.5.4.2	
Pedagogical Affordances ��������������������������������������    33
	2.5.4.3	
Technical Perspectives������������������������������������������    33
	2.5.5	 Limitations of AR in Spatial Ability Training (RQ2) ����������    34
	2.5.6	 Exploration of the Incorporation of Adaptivity 
and Personalization in AR Applications (RQ3)��������������������    35

x
	2.5.7	 Aspects of Spatial Abilities Having Been Evaluated Using 
AR (RQ4)������������������������������������������������������������������������������    37
	2.5.8	 Evaluation Methods Considered for AR Applications 
in Educational Scenarios (RQ5)�������������������������������������������    39
	2.6	 Summary������������������������������������������������������������������������������������������    40
References��������������������������������������������������������������������������������������������������    41
	3	
AI-Driven and SOLO-Based Domain Knowledge Modeling 
in PARSAT AR Software������������������������������������������������������������������������    51
	3.1	 Overview������������������������������������������������������������������������������������������    51
	3.2	 Domain Model����������������������������������������������������������������������������������    52
	3.2.1	 Objectives������������������������������������������������������������������������������    52
	3.3	 Domain Knowledge Alongside SOLO Taxonomy����������������������������    54
	3.4	 Examples of Learning Activities of Each SOLO Level��������������������    56
	3.5	 Summary������������������������������������������������������������������������������������������    60
References��������������������������������������������������������������������������������������������������    61
	4	
Fuzzy Logic for Modeling the Knowledge of Users in PARSAT 
AR Software���������������������������������������������������������������������������������������������    65
	4.1	 Overview������������������������������������������������������������������������������������������    66
	4.2	 Fuzzy Logic Algorithm��������������������������������������������������������������������    66
	4.3	 Initialization Process������������������������������������������������������������������������    68
	4.4	 Fuzzy Sets����������������������������������������������������������������������������������������    69
	4.5	 Fuzzy Rule Base ������������������������������������������������������������������������������    72
	4.6	 Mamdani’s Inference System������������������������������������������������������������    79
	4.7	 Defuzzification����������������������������������������������������������������������������������    80
	4.8	 Adaptation of the Learning Activities Based on Fuzzy Weights������    84
	4.8.1	 Decision Making������������������������������������������������������������������    86
	4.9	 Summary������������������������������������������������������������������������������������������    88
References��������������������������������������������������������������������������������������������������    89
	5	
Artificial Intelligence-Enhanced PARSAT AR Software: 
Architecture and Implementation����������������������������������������������������������    93
	5.1	 Overview������������������������������������������������������������������������������������������    94
	5.2	 System Architecture��������������������������������������������������������������������������    94
	5.2.1	 Hardware Layer��������������������������������������������������������������������    95
	5.2.1.1	
Tracking����������������������������������������������������������������    95
	5.2.1.2	
Processing��������������������������������������������������������������    96
	5.2.1.3	
Interacting��������������������������������������������������������������    97
	5.2.2	 Software Layer����������������������������������������������������������������������    97
	5.2.2.1	
User Interface��������������������������������������������������������    97
	5.2.2.2	
3D Rendering Engine��������������������������������������������  100
	5.2.3	 Data Layer����������������������������������������������������������������������������  106
	5.2.3.1	
Marker Database����������������������������������������������������  106
	5.2.3.2	
3D Models Database����������������������������������������������  110
	5.2.3.3	
Interaction Model��������������������������������������������������  114
Contents

xi
	5.3	 Implementation of the System����������������������������������������������������������  119
	5.3.1	 User Interface of PARSAT����������������������������������������������������  119
	5.3.2	 Fuzzy Logic Controller Implementation with 
C# Scripting��������������������������������������������������������������������������  124
	5.3.2.1	
System Initialization����������������������������������������������  124
	5.3.2.2	
Linguistic Variables and Membership 
Functions ��������������������������������������������������������������  125
	5.3.2.3	
Fuzzification Process Implementation������������������  126
	5.3.2.4	
Rules of the System����������������������������������������������  126
	5.3.2.5	
Evaluation of the Rules������������������������������������������  127
	5.3.2.6	
Defuzzification������������������������������������������������������  128
	5.4	 Summary������������������������������������������������������������������������������������������  128
References��������������������������������������������������������������������������������������������������  129
	6	
Multi-model Evaluation of the Artificial Intelligence-Enhanced 
PARSAT AR Software ����������������������������������������������������������������������������  131
	6.1	 Overview������������������������������������������������������������������������������������������  131
	6.2	 Evaluation Framework����������������������������������������������������������������������  132
	6.2.1	 Research Sample������������������������������������������������������������������  132
	6.2.2	 Training Preparation ������������������������������������������������������������  133
	6.3	 t-Test Analysis of Students’ Feedback����������������������������������������������  134
	6.4	 Comparative Analysis of Pre-test/Post-test Model in Achieving 
the Learning Outcomes��������������������������������������������������������������������  136
	6.4.1	 Discussion of the Results������������������������������������������������������  138
	6.5	 Extended Technology Acceptance Model for Detecting 
Influencing Factors����������������������������������������������������������������������������  139
	6.5.1	 Existing Acceptance Models������������������������������������������������  139
	6.5.2	 Proposed Extended Model����������������������������������������������������  141
	6.5.3	 Research Model and Hypotheses������������������������������������������  141
	6.5.4	 Research Instruments������������������������������������������������������������  143
	6.5.5	 Data Analysis������������������������������������������������������������������������  144
	6.5.6	 Model Validation������������������������������������������������������������������  145
	6.5.6.1	
Measurement Model����������������������������������������������  145
	6.5.6.2	
Structural Model����������������������������������������������������  147
	6.6	 Summary������������������������������������������������������������������������������������������  150
References��������������������������������������������������������������������������������������������������  150
	7	
Conclusions of AI-Driven AR in Education������������������������������������������  157
	7.1	 Overview������������������������������������������������������������������������������������������  157
	7.2	 Conclusions and Discussion ������������������������������������������������������������  158
	7.3	 Contribution to Intelligent Tutoring Systems�����������������������������������  163
	7.4	 Contribution to Domain Knowledge Model ������������������������������������  166
	7.5	 Contribution to Student Modeling����������������������������������������������������  169
	7.6	 Contribution to Electronic Assessment��������������������������������������������  172
	7.7	 Future Work��������������������������������������������������������������������������������������  173
References��������������������������������������������������������������������������������������������������  174
Contents

1
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024 
C. Papakostas et al., Special Topics in Artificial Intelligence and Augmented 
Reality, Cognitive Technologies, https://doi.org/10.1007/978-3-031-52005-1_1
Chapter 1 
Introduction and Overview 
of AI-Enhanced Augmented Reality 
in Education 
Abstract  This chapter of this book serves as an introductory chapter, offering read­
ers a comprehensive overview of the research. It begins with an “Overview” section 
that outlines the main sections to provide readers with a roadmap of what to expect 
in the subsequent sections. The “Motivation” section explores the reasons behind 
conducting this research, emphasizing the significance of spatial ability in human 
intelligence and its connection to success in scientific and educational fields. It also 
discusses the potential benefits of augmented reality in enhancing spatial ability and 
the importance of adaptivity in training systems, which serves as a motivation for 
the study. In the “Research Questions” section, specific research questions are intro­
duced, designed to address gaps in existing literature and examine the impact of a 
proposed blended mobile system on fostering spatial ability. These questions pro­
vide a clear focus for the study and guide the subsequent chapters. It highlights the 
iterative nature of the research and presents the overall structure of the book, help­
ing readers understand how the subsequent chapters build upon each other. 
1.1  Overview 
The first chapter introduces the purpose of the research presented in the current 
book. More specifically, Sect. 1.2 argues the research motivation and outlines the 
problem, Sect. 1.3 defines the research questions, and the final section defines the 
approach and structure of the book.

2
1.2  Motivation 
Einstein, Newton, Faraday, Maxwell, and Tesla are scientists who left their mark on 
the history of physics and technology, and they all claimed that the development of 
their ground-breaking theories involved the utilization of spatial visualization [1–5]. 
For instance, Albert Einstein gained notoriety for his utilization of creative think­
ing and his capacity to mentally comprehend challenging mathematical concepts. In 
order to create his laws of motion and gravitation, Isaac Newton also possessed a 
keen visual imagination and the ability to visually picture the motion of celestial 
bodies. The inception of the principle of the electromagnetic field and Michael 
Faraday’s research into electromagnetic induction are his two most notable accom­
plishments. Utilizing Faraday’s findings as a foundation, James Clerk Maxwell cre­
ated a series of formulas that clarify the operation of electric and magnetic fields. 
These equations are known as Maxwell’s equations. The evolution of modern inno­
vations like radio and television was facilitated by these equations. His research on 
alternating current (AC) electrical systems and his innovations linked to wireless 
communication and electricity transmission are what made Nikola Tesla, a contem­
porary of Faraday and Maxwell, so widely recognized. Tesla was also renowned for 
his prodigious visualization skills, which he allegedly used to plan and create a 
number of his inventions. 
Spatial visualization is the ability to mentally rotate, manipulate, and twist two- 
and three-dimensional stimulus objects [6]. For scientists and engineers, spatial 
visualization is a crucial ability since it may be utilized to develop new ideas, design 
new technologies, and comprehend complex data. It is an ability that can be acquired 
and refined with practice, and scientific and engineering education frequently 
emphasizes it. 
Psychologists and cognitive researchers have scrutinized and delineated the con­
cept of “spatial ability” through numerous perspectives across several decades. 
Spatial ability, one of the most extensively studied human aptitudes, has undergone 
various interpretations over time [6–16]. 
While definitions of spatial ability may vary, most researchers concur that it 
entails the skill to manipulate visual and spatial data mentally. This encompasses 
the ability to mentally rotate or manipulate objects, comprehend spatial connections 
between objects, and navigate physical environments. 
Extensive research has established a connection between spatial ability and aca­
demic performance [17, 18]. In the past decade, studies have underscored the sig­
nificant importance of spatial ability in achieving academic excellence, notably 
within the realms of STEM disciplines (science, technology, engineering, and math­
ematics) [19–24]. Spatial cognition has also shown relevance across a spectrum of 
vocations, encompassing STEM careers, as well as everyday tasks such as driving 
and navigation. 
While having better spatial skills as a child can predict a person’s future success 
in STEM fields [25], a meta-analysis of the research on spatial ability by [1] revealed 
that spatial skills can develop over time with the right kind of training [26]. 
1  Introduction and Overview of AI-Enhanced Augmented Reality in Education

3
According to research, spatial ability may be developed via practice and instruction 
and is not a set characteristic. Although there is some research that indicates that 
spatial ability may have genetic roots, contextual elements including exposure to 
spatially demanding activities and experiences can also have a significant impact on 
how spatial ability develops. 
There are several ways to train one’s own spatial skills, including playing spe­
cific video games, engaging in mental rotation and visualization exercises, and get­
ting specialized spatial instruction in school settings. For children’s spatial ability to 
develop, early exposure to challenging spatial tasks and situations can be very 
helpful. 
The importance of spatial ability, in engineering education, has been highlighted 
by several studies [26–30]. The visualization of abstract concepts, such as the geom­
etry of three-dimensional objects, has been of great interest in engineering educa­
tion [27]. Technical drawing design is considered to have a role in the training of 
spatial skills [30, 31]. The development of multimedia software, for improving 3-D 
spatial visualization skills, is based on the manipulation of physical models, provid­
ing kinaesthetic learners with a convenient way to absorb information [28]. 
Engineering education often involves the visualization and manipulation of com­
plex three-dimensional objects and structures, and the ability to think spatially is 
critical for solving many engineering problems [32–34]. Technical drawing design 
is one way in which spatial skills can be developed in engineering education. 
Technical drawing involves the use of specialized software to create detailed draw­
ings and schematics of engineering designs and requires a high degree of spatial 
visualization ability. By practicing technical drawing and other spatially challeng­
ing activities, engineering students can improve their spatial skills and better pre­
pare themselves for success in their future careers. 
The advancement of multimedia software and other digital technologies in recent 
years has provided new possibilities for enhancing spatial ability in engineering 
education. These resources offer students the ability to engage with three-­
dimensional models and representations on the display of their devices, making 
learning more engaging and immersive. For kinesthetic learners, who learn best 
through hands-on experience and physical manipulation of items, this can be 
extremely helpful. Overall, the improvement of spatial ability through focused 
training and instruction can have a positive impact on students’ future success in 
their chosen field. Engineering education places a high value on this goal. 
The challenge of student retention usually has an impact on engineering studies 
too, particularly concerning first-year university students [35]. Sorby [36] argues 
that students are more likely to lose motivation and abandon their engineering stud­
ies if they struggle with the course material right on. However, if they attend a 
course with significant spatial abilities and maintain putting up the effort to improve 
them as the course proceeds, there is a significantly lower chance that they would 
drop out. 
Students who struggle with the course material or lack confidence in their abili­
ties are more likely to drop out of engineering studies, particularly in the first year 
of university. However, enhancing spatial skills might be crucial for increasing 
1.2  Motivation

4
student retention in their coursework. Universities and educational programs can 
assist students in addressing the difficulties they may encounter in their studies and 
help them remain engaged and motivated by offering opportunities for students to 
enhance their spatial ability as well as support and guidance to help them succeed. 
Moreover, training in spatial abilities can be particularly effective in improving 
student retention in engineering studies. Teachers can assist students in developing 
the abilities and self-assurance they need to excel in their studies by giving them 
specialized instruction and expertise in spatial visualizing activities. 
Overall, addressing the issue of student retention in the classroom necessitates a 
multifaceted strategy [37] that includes offering students the chance to develop their 
spatial ability, providing them with support and advice to help them succeed, and 
developing a welcoming and inclusive learning environment that fosters engage­
ment and motivation. 
All levels of education have examined augmented reality (AR), which offers 
considerable benefits like student motivation and learning effectiveness [38–42]. 
AR is on the verge of transforming the human–computer relationship. AR contrib­
utes to interactivity and facilitates co-creation [43]; thus, AR has the potential to 
create training environments and scenarios that are cost-effective, safe and person­
alized [22, 44–49]. This represents a good fit with the spatial ability training carried 
out for engineers. The immersive nature of the training using mixed reality offers a 
unique realistic quality, which is not generally present in traditional education in the 
classroom yet retains considerable cost advantages over large-scale real-life labora­
tories and is gaining increasing acceptance [50]. 
Personalized training offers great pedagogical affordances, as it provides an 
enhanced learning experience, improves student engagement, and promotes knowl­
edge acquisition [51]. The adaptive systems integrate built-in components in order 
to offer knowledge domain adaptivity and deliver different learning activities, tai­
lored to the student’s profile. 
By tailoring learning activities to a student’s individual needs and preferences, 
adaptive systems can improve student engagement and motivation. This approach 
can also help to promote knowledge acquisition by providing students with targeted 
feedback and support. Furthermore, adaptive technologies can offer instantaneously 
evaluations of a student’s progress, enabling teachers to spot potential trouble spots 
and offer extra assistance as necessary. As a whole, employing adaptive technolo­
gies in engineering education has an upside of enhancing student learning outcomes 
and delivering a more efficient and tailored learning environment. 
The learning material’s pedagogical potential increases with how adaptable it is 
to the cognitive needs and capabilities of the students. For instance, in the case of a 
student who studies a specific domain concept, having a high knowledge level, and 
has been given many learning activities that are not appropriate for that level, then 
the learning process may not go as expected and the student would feel frustrated 
[52]. Providing inappropriate learning activities can lead to disengagement, which 
may negatively affect the student’s motivation and learning outcomes. Maintaining 
student involvement and facilitating the learning process can be achieved by tailor­
ing the learning activities to the students’ knowledge and cognitive capacities. This 
1  Introduction and Overview of AI-Enhanced Augmented Reality in Education

5
is where personalized learning comes into play since it enables specialized training 
that is catered to each student’s unique requirements and talents. 
The creation of AR applications that take use of the portable qualities and quick 
access to information that are gained with mobile devices has become popular over 
the past few years due to the trend of mixing mobile technologies with AR [53]. The 
convergence of mobile technology and augmented reality has ushered in fresh pros­
pects for education and training by granting users access to augmented reality 
encounters and materials via their mobile devices. This has the potential to make 
learning more adaptable, personalized, and engaging [54–60]. 
However, the combination of AR and its application in educational settings 
remains an open area research. The elaboration of educational content based on 
augmented reality approaches or methods for the design and construction of highly 
interactive materials so that it can offer tailored learning in any location and at any 
time are not subject to any predefined rules. The potential of augmented reality 
(AR) in education has been the subject of some studies and trials, but there is still 
much to learn and investigate in terms of setting standards and best practices for 
creating efficient AR-based learning experiences. Additionally, there is a need for 
deeper and thorough evaluation techniques to determine how AR affects learning 
results. It is anticipated that new approaches and frameworks will emerge to direct 
the development and application of augmented reality in education as the area con­
tinues to grow. 
In light of the aforementioned, the major objective of this research is to utilize 
the advantages of augmented reality and the technology of adaptive systems by fus­
ing them in a novel way to provide optimized and customized spatial ability train­
ing. By combining AR technology with adaptive systems, it may be possible to 
create a highly interactive and engaging learning environment that can provide per­
sonalized training in spatial ability. This could have important implications for edu­
cation in fields such as engineering, where spatial ability is a key skill. 
Given that the undergraduate students of the Departments of Electrical and 
Electronic Engineering, Biomedical Engineering, Industrial Design and Production 
Engineering, Informatics and Computer Engineering, Surveying and Geoinformatics 
Engineering, Mechanical Engineering, Naval Architecture, and Civil Engineering 
of the School of Engineering of the University of West Attica, are offered at their 
curriculum, courses such as the technical drawing, which is highly correlated with 
an advanced level of spatial ability, this research developed a mobile application for 
spatial ability training. The mobile application, namely PARSAT (personalized spa­
tial ability training application), incorporates learning theories to support the peda­
gogical features of the system, and fuzzy expert system for personalization and 
adaptivity. The incorporation of learning theories and a fuzzy expert system for 
personalization and adaptivity can help optimize the training experience for each 
individual student. 
In particular, PARSAT incorporates the following: 
•	 the use of the Structure of the Observed Learning Outcomes (SOLO) learning 
theory, for the instructional design of learning content, providing a framework 
1.2  Motivation

6
for organizing and assessing student learning outcomes based on increasing lev­
els of complexity; 
•	 the use of fuzzy logic in an AR system in engineering education, a mathematical 
tool for dealing with uncertain and imprecise information, to personalize the 
learning experience based on the student’s performance; 
•	 the adaptive delivery of the learning activities taught to students in the AR sys­
tem, which adjusts the difficulty and type of activities based on the student’s 
progress and needs. 
Students can provide highly engaging content that is individualized to their charac­
teristics and requirements by integrating these applications into an adaptable and 
accessible learning process. As a result, students are able to comprehend the con­
tents and correlate them to the actual world. 
Each student can benefit from a customized learning experience that takes into 
account their cognitive demands, skills, and preferences by integrating PARSAT 
with an adaptable and accessible learning process. By allowing students to apply the 
learning content to actual situations, this personalized learning experience can 
increase student engagement, knowledge acquisition, and the practical applicability 
of their learning. By incorporating AR technology, PARSAT can provide a more 
immersive and engaging learning experience, which can enhance spatial ability 
training in engineering education. 
1.3  Research Questions 
The current research has the purpose to design and develop a system for training 
students’ spatial skills, in an innovative mobile environment, using augmented real­
ity technology, and adaptive tutoring techniques. The research objective is to 
develop and evaluate a novel mobile system for spatial ability training using aug­
mented reality technology. 
Hence, the research questions are formulated as follows:
	1.	 What is the current state of research on spatial ability training through aug­
mented reality technology? (RQ1);
	2.	 How can the use of mobile devices enhance the effectiveness of the system for 
training spatial skills? (RQ2);
	3.	 What are the key components of an effective system for training spatial skills 
using augmented reality technology and adaptive tutoring techniques? (RQ3);
	4.	 What are the most effective instructional strategies and techniques for training 
spatial skills in a mobile augmented reality environment? (RQ4);
	5.	 How effective is the developed AR-based spatial ability training system in 
improving participants’ spatial abilities? (RQ5);
	6.	 How does the developed AR-based spatial ability training system compared to 
traditional spatial ability training methods in terms of effectiveness and effi­
ciency? (RQ6);
1  Introduction and Overview of AI-Enhanced Augmented Reality in Education

7
	7.	 What is the impact of the system on students’ academic achievement and moti­
vation to train spatial skills? (RQ7);
	8.	 What are the participants’ perceptions of the usability and effectiveness of the 
developed AR-based spatial ability training system? (RQ8). 
1.4  Approach and Structure 
In essence, the aim of this research is to enhance the realm of spatial ability training 
by investigating the capabilities of augmented reality (AR) technology in creating a 
mobile training system that is both effective and efficient while also capturing the 
user’s engagement. The research will encompass the following activities: 
•	 a comprehensive literature review 
•	 a design phase 
•	 an implementation phase 
•	 an evaluation phase 
to answer the research questions and achieve the research objective. 
The structure of this book is well-organized and follows a logical progression. 
Following is a brief synopsis of each chapter: 
•	 Chapter 2 “Review of the Literature on AI-enhanced Augmented Reality in 
Education”: This chapter provides an in-depth analysis of the related literature 
on the topic of the book. It attempts to highlight the research’s current deficien­
cies and offer an extensive overview of the research setting. The chapter will also 
discuss the state of the art at the point in time and offer a critical assessment of 
earlier research. 
•	 Chapter 3 “AI-driven and SOLO-based Domain Knowledge Modeling in 
PARSAT AR Software”: This chapter describes the domain knowledge model 
used in the book and the integration of the SOLO taxonomy. In-depth analysis of 
the taxonomy and domain knowledge used, as well as their applicability to the 
research question, will also be provided in this chapter. 
•	 Chapter 4 “Fuzzy Logic for modeling the Knowledge of Users in PARSAT AR 
Software”: This chapter describes the student model used in the book and the 
integration of fuzzy logic. The student model and the fuzzy logic employed will 
also be thoroughly examined in this chapter, along with their applicability to the 
subject of the study. 
•	 Chapter 5 “Artificial Intelligence-enhanced PARSAT AR Software: Architecture 
and Implementation”: This chapter provides a detailed description of the archi­
tecture and implementation of the proposed system. It will also discuss the soft­
ware tools and technologies used, the design decisions made, and the 
implementation challenges faced. 
•	 Chapter 6 “Multi-Model Evaluation of the Artificial Intelligence-Enhanced 
PARSAT AR Software”: This chapter evaluates the proposed system using a 
1.4  Approach and Structure

8
multi-model approach. Additionally, it will go through the design decisions 
made, the implementation difficulties encountered, and the software tools and 
technologies employed. The chapter will also compare the proposed system to 
existing approaches. 
•	 Chapter 7 “Conclusions of AI-driven AR in Education”: This chapter presents 
and discusses the conclusions of the book. It will highlight the research’s contri­
butions, provide a summary of the findings, and make suggestions for ­additional 
study. The chapter will also discuss the research’s shortcomings and the ramifi­
cations of its findings. 
References 
1.	D. Uttal et al., “The Malleability of Spatial Skills: A Meta-Analysis of Training Studies,” 
Psychol Bull, vol. 139, Jun. 2012, https://doi.org/10.1037/a0028446. 
2.	D. Uttal, D. Miller, and N. Newcombe, “Exploring and Enhancing Spatial Thinking Links to 
Achievement in Science, Technology, Engineering, and Mathematics?,” Curr Dir Psychol Sci, 
vol. 22, pp. 367–373, Oct. 2013, https://doi.org/10.1177/0963721413484756. 
3.	A. I. Miller, “Imagery in scientific thought: Creating 20th-century physics,” 1984. 
4.	R. N. Shepard, “The science of imagery and the imagery of science,” in Annual Meeting of the 
American Psychological Society, San Francisco, 1996. 
5.	N. J. Nersessian, “Should physicists preach what they practice?,” Sci Educ (Dordr), vol. 4, no. 
3, pp. 203–226, 1995. 
6.	M. G. McGee, Human Spatial Abilities: Sources of Sex Differences. in Praeger special studies. 
Praeger, 1979. [Online]. Available: https://books.google.gr/books?id=2HgiAAAACAAJ 
7.	E. L. Thorndike, “On the Organization of Intellect.,” Psychol Rev, vol. 28, no. 2, pp. 141–151, 
1921, https://doi.org/10.1037/h0070821. 
8.	C. Spearman, “‘General intelligence,’ objectively determined and measured.,” Am J Psychol, 
vol. 15, pp. 201–293, 1904, https://doi.org/10.2307/1412107. 
9.	A. A. H. E. Koussy, An Investigation Into the Factors in Tests Involving the Visual Perception 
of Space. in British Journal of Psychology. Monograph Supplements. University Press, 1935. 
[Online]. Available: https://books.google.gr/books?id=SZh0tAEACAAJ 
10.	L. L. Thurstone and T. G. Thurstone, Primary mental abilities, vol. 119. University of Chicago 
Press Chicago, 1938. 
11.	L. Thurstone, “Some Primary Abilities in Visual Thinking,” Proc Am Philos Soc, vol. 94, no. 
6, pp. 517–521, 1950. 
12.	H.  Gardner, Frames of mind  : the theory of multiple intelligences. New  York: Basic 
Books, 1983. 
13.	M. G. McGee, “Human spatial abilities: Psychometric studies and environmental, genetic, hor­
monal, and neurological influences.,” Psychological Bulletin, vol. 86. American Psychological 
Association, US, pp. 889–918, 1979. https://doi.org/10.1037/0033-­2909.86.5.889. 
14.	M. C. Linn and A. C. Petersen, “Emergence and Characterization of Sex Differences in Spatial 
Ability: A Meta-Analysis,” Child Dev, vol. 56, no. 6, pp. 1479–1498, Dec. 1985, https://doi. 
org/10.2307/1130467. 
15.	J. B. Carroll, Human cognitive abilities: A survey of factor-analytic studies, no. 1. Cambridge 
University Press, 1993. 
16.	J. W. Pellegrino and E. B. Hunt, “Cognitive models for understanding and assessing spatial 
abilities,” Intelligence: Reconceptualization and measurement, pp. 203–225, 1991. 
17.	I.  Macfarlane. Smith, Spatial ability  : its educational and social significance. San Diego, 
Calif.: R.R. Knapp, 1964.
1  Introduction and Overview of AI-Enhanced Augmented Reality in Education

9
18.	C. L. Gohm, L. G. Humphreys, and G. Yao, “Underachievement among spatially gifted stu­
dents.,” Am Educ Res J, vol. 35, pp. 515–531, 1998, https://doi.org/10.2307/1163447. 
19.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Exploring Users’ Behavioral 
Intention to Adopt Mobile Augmented Reality in Education through an Extended Technology 
Acceptance Model,” Int J Hum Comput Interact, vol. 39, no. 6, pp. 1294–1302, 2023, https:// 
doi.org/10.1080/10447318.2022.2062551. 
20.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “User acceptance of augmented 
reality welding simulator in engineering training,” Educ Inf Technol (Dordr), vol. 27, no. 1, 
pp. 791–817, Jan. 2022, https://doi.org/10.1007/s10639-­020-­10418-­7. 
21.	A. Marougkas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Virtual Reality in Education: 
A Review of Learning Theories, Approaches and Methodologies for the Last Decade,” 
Electronics (Basel), vol. 12, no. 13, 2023, https://doi.org/10.3390/electronics12132832. 
22.	A. Krouska, C. Troussas, K. Kabassi, and C. Sgouropoulou, “An Empirical Investigation of 
User Acceptance of Personalized Mobile Software for Sustainability Education,” Int J Hum 
Comput Interact, pp. 1–8, Aug. 2023, https://doi.org/10.1080/10447318.2023.2241614. 
23.	P.  Strousopoulos, C.  Troussas, C.  Papakostas, A.  Krouska, and C.  Sgouropoulou, 
“Revolutionizing Agricultural Education with Virtual Reality and Gamification: A Novel 
Approach for Enhancing Knowledge Transfer and Skill Acquisition,” in Novel & Intelligent 
Digital Systems: Proceedings of the 3rd International Conference (NiDS 2023), K. Kabassi, 
P. Mylonas, and J. Caro, Eds., Cham: Springer Nature Switzerland, 2023, pp. 67–80. 
24.	M. Iakovidis, C. Papakostas, C. Troussas, and C. Sgouropoulou, “Empowering Responsible 
Digital Citizenship Through an Augmented Reality Educational Game,” in Novel & Intelligent 
Digital Systems: Proceedings of the 3rd International Conference (NiDS 2023), K. Kabassi, 
P. Mylonas, and J. Caro, Eds., Cham: Springer Nature Switzerland, 2023, pp. 31–39. 
25.	J. Wai, D. Lubinski, and C. Benbow, “Spatial Ability for STEM Domains: Aligning Over 50 
Years of Cumulative Psychological Knowledge Solidifies Its Importance,” J Educ Psychol, 
Nov. 2009, https://doi.org/10.1037/a0016127. 
26.	S. Sorby, “Developing 3D spatial skills for engineering students,” Australasian Journal of 
Engineering Education, vol. 13, pp. 1–11, Jan. 2007, https://doi.org/10.1080/22054952.200 
7.11463998. 
27.	A.  R. Arslan and S.  Dazkir, “Technical Drafting and Mental Visualization in Interior 
Architecture Education,” International Journal for the Scholarship of Teaching and Learning, 
vol. 11, no. 2, 2017, https://doi.org/10.20429/ijsotl.2017.110215. 
28.	H.  B. P.  Gerson, S.  A. Sorby, A.  Wysocki, and B.  J. Baartmans, “The development and 
assessment of multimedia software for improving 3-D spatial visualization skills,” Computer 
Applications in Engineering Education, vol. 9, no. 2, pp. 105–113, 2001. 
29.	J.  L. Mohler, “Computer Graphics Education: Where and How Do We Develop Spatial 
Ability?,” in Eurographics (Education Papers), 2006, pp. 79–86. 
30.	A. Šafhalter, S. Glodež, A. Šorgo, and M. Ploj Virtič, “Development of spatial thinking abili­
ties in engineering 3D modeling course aimed at lower secondary students,” Int J Technol Des 
Educ, 2020, https://doi.org/10.1007/s10798-­020-­09597-­8. 
31.	R. H. McKim, Experiences in visual thinking. Monterey, Calif.: Brooks/Cole Pub. Co., 1980. 
32.	Z. Kanetaki et al., “Acquiring, Analyzing and Interpreting Knowledge Data for Sustainable 
Engineering Education: An Experimental Study Using YouTube,” Electronics (Basel), vol. 11, 
no. 14, 2022, https://doi.org/10.3390/electronics11142210. 
33.	A. Krouska, C. Troussas, and C. Sgouropoulou, “Fuzzy Logic for Refining the Evaluation 
of Learners’ Performance in Online Engineering Education,” European Journal of 
Engineering Research and Science, vol. 4, pp. 50–56, Jun. 2019, https://doi.org/10.24018/ 
ejers.2019.4.6.1369. 
34.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Exploration of Augmented 
Reality in Spatial Abilities Training: A Systematic Literature Review for the Last Decade,” 
Informatics in Education, vol. 20, no. 1, pp. 107–130, Mar. 2021, https://doi.org/10.15388/ 
infedu.2021.06.
References

10
35.	S. Sheppard and R. Jennison, “Freshman engineering design experiences and organizational 
framework,” International Journal of Engineering Education, vol. 13, pp. 190–197, 1997. 
36.	S. A. Sorby, “Assessment of a “new and improved” course for the development of 3-D spatial 
skills,” The Engineering Design Graphics Journal, vol. 69, no. 3, 2005. 
37.	C.  Papakostas, C.  Troussas, P.  Douros, M.  Poli, and C.  Sgouropoulou, “CoMoPAR: A 
Comprehensive Conceptual Model for Designing Personalized Augmented Reality Systems 
in Education,” in Novel & Intelligent Digital Systems: Proceedings of the 3rd International 
Conference (NiDS 2023), K. Kabassi, P. Mylonas, and J. Caro, Eds., Cham: Springer Nature 
Switzerland, 2023, pp. 67–79. 
38.	J. L. B. Acosta, S. M. B. Navarro, R. F. Gesa, and K. Kinshuk, “Framework for designing moti­
vational augmented reality applications in vocational education and training,” Australasian 
Journal of Educational Technology, vol. 35, no. 3 SE-Articles, Jun. 2019, https://doi. 
org/10.14742/ajet.4182. 
39.	S. Y. Chen and S. Y. Liu, “Using augmented reality to experiment with elements in a chemis­
try course,” Comput Human Behav, vol. 111, p. 106316, Apr. 2020, https://doi.org/10.1016/j. 
chb.2020.106418. 
40.	J.  Garzón, J.  Pavón, and S.  Baldiris, “Systematic review and meta-analysis of augmented 
reality in educational settings,” Virtual Real, vol. 23, no. 4, pp. 447–459, 2019, https://doi. 
org/10.1007/s10055-­019-­00379-­9. 
41.	M. Thees, S. Kapp, M. P. Strzys, F. Beil, P. Lukowicz, and J. Kuhn, “Effects of augmented real­
ity on learning and cognitive load in university physics laboratory courses,” Comput Human 
Behav, vol. 108, p. 106316, 2020, https://doi.org/10.1016/j.chb.2020.106316. 
42.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Measuring User Experience, 
Usability and Interactivity of a Personalized Mobile Augmented Reality Training System,” 
Sensors, vol. 21, no. 11, p. 3888, Jun. 2021, https://doi.org/10.3390/s21113888. 
43.	S. Alimamy, K. R. Deans, and J. Gnoth, “The Role of Augmented Reality in the Interactivity 
of Co-Creation: A Critical Review,” Int. J. Technol. Hum. Interact., vol. 14, no. 3, pp. 88–104, 
2018, https://doi.org/10.4018/IJTHI.2018070106. 
44.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “PARSAT: Fuzzy logic for 
adaptive spatial ability training in an augmented reality system,” Computer Science and 
Information Systems. 
45.	C.  Papakostas, C.  Troussas, A.  Krouska, and C.  Sgouropoulou, “Personalization of the 
Learning Path within an Augmented Reality Spatial Ability Training Application Based on 
Fuzzy Weights,” Sensors, vol. 22, no. 18, 2022, https://doi.org/10.3390/s22187059. 
46.	C. Troussas, C. Papakostas, A. Krouska, P. Mylonas, and C. Sgouropoulou, “Personalized 
Feedback Enhanced by Natural Language Processing in Intelligent Tutoring Systems,” 
in Augmented Intelligence and Intelligent Tutoring Systems, C.  Frasson, P.  Mylonas, and 
C.  Troussas, Eds., Cham: Springer Nature Switzerland, 2023, pp.  667–677. https://doi. 
org/10.1007/978-­3-­031-­32883-­1_58. 
47.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “On the development of a 
personalized augmented reality spatial ability training mobile application,” in Frontiers in 
Artificial Intelligence and Applications, IOS Press, 2021, pp. V–VI. https://doi.org/10.3233/ 
FAIA210078. 
48.	A.  Marougkas, C.  Troussas, A.  Krouska, and C.  Sgouropoulou, “How personalized and 
effective is immersive virtual reality in education? A systematic literature review for the last 
decade,” Multimed Tools Appl, 2023, https://doi.org/10.1007/s11042-­023-­15986-­7. 
49.	A. Marougkas, C. Troussas, A. Krouska, and C. Sgouropoulou, “A Framework for Personalized 
Fully Immersive Virtual Reality Learning Environments with Gamified Design in Education,” 
2021. https://doi.org/10.3233/FAIA210080. 
50.	E. B. Hsu, Y. Li, J. D. Bayram, D. Levinson, S. Yang, and C. Monahan, “State of virtual reality 
based disaster preparedness and response training,” PLoS Curr, vol. 5, 2013. 
51.	A.  Soofi and M.  Uddin, “A Systematic Review of Domains, Techniques, Delivery Modes 
and Validation Methods for Intelligent Tutoring Systems,” International Journal of 
1  Introduction and Overview of AI-Enhanced Augmented Reality in Education

11
Advanced Computer Science and Applications, vol. 10, Jan. 2019, https://doi.org/10.14569/ 
IJACSA.2019.0100312. 
52.	M. Holmes, A. Latham, K. A. Crockett, and J. D. O’Shea, “Near Real-Time Comprehension 
Classification with Artificial Neural Networks: Decoding e-Learner Non-Verbal Behavior,” 
IEEE Transactions on Learning Technologies, vol. 11, pp. 5–12, 2018. 
53.	G. Papagiannakis, G. Singh, and N. Thalmann, “A Survey of Mobile and Wireless Technologies 
for Augmented Reality Systems (Preprint),” Comput Animat Virtual Worlds, vol. 19, pp. 3–22, 
Feb. 2008, https://doi.org/10.1002/cav.221. 
54.	P. Strousopoulos, C. Papakostas, C. Troussas, A. Krouska, P. Mylonas, and C. Sgouropoulou, 
“SculptMate: Personalizing Cultural Heritage Experience Using Fuzzy Weights,” in Adjunct 
Proceedings of the 31st ACM Conference on User Modeling, Adaptation and Personalization, 
in UMAP ’23 Adjunct. New York, NY, USA: Association for Computing Machinery, 2023, 
pp. 397–407. https://doi.org/10.1145/3563359.3596667. 
55.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Modeling the Knowledge of 
Users in an Augmented Reality-Based Learning Environment Using Fuzzy Logic,” in Lecture 
Notes in Networks and Systems, A. Krouska, C. Troussas, and J. Caro, Eds., Cham: Springer 
International Publishing, 2023, pp. 113–123. https://doi.org/10.1007/978-­3-­031-­17601-­2_12. 
56.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Enriching Mobile Learning Software with 
Interactive Activities and Motivational Feedback for Advancing Users’ High-Level Cognitive 
Skills,” Computers, vol. 11, no. 2, 2022, https://doi.org/10.3390/computers11020018. 
57.	F. Giannakas, C. Troussas, A. Krouska, C. Sgouropoulou, and I. Voyiatzis, “XGBoost and 
Deep Neural Network Comparison: The Case of Teams’ Performance,” in Intelligent Tutoring 
Systems, A. I. Cristea and C. Troussas, Eds., Cham: Springer International Publishing, 2021, 
pp. 343–349. 
58.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Towards a Reference Model to Ensure the 
Quality of Massive Open Online Courses and E-Learning,” in Brain Function Assessment 
in Learning, C.  Frasson, P.  Bamidis, and P.  Vlamos, Eds., Cham: Springer International 
Publishing, 2020, pp. 169–175. 
59.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Dynamic Detection of Learning Modalities 
Using Fuzzy Logic in Students’ Interaction Activities,” in Intelligent Tutoring Systems, 
V. Kumar and C. Troussas, Eds., Cham: Springer International Publishing, 2020, pp. 205–213. 
60.	A. Krouska, C. Troussas, and C. Sgouropoulou, “A novel group recommender system for 
domain-independent decision support customizing a grouping genetic algorithm,” User Model 
User-adapt Interact, 2023, https://doi.org/10.1007/s11257-­023-­09360-­3.
References

13
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024 
C. Papakostas et al., Special Topics in Artificial Intelligence and Augmented 
Reality, Cognitive Technologies, https://doi.org/10.1007/978-3-031-52005-1_2
Chapter 2 
Review of the Literature on AI-Enhanced 
Augmented Reality in Education 
Abstract  This chapter provides a comprehensive review of the literature regarding 
AI-enhanced Augmented Reality (AR). It serves as the foundational knowledge 
base for the study, offering insights into relevant theories, concepts, and prior 
research studies. The chapter begins with an “Overview” section, outlining the pur­
pose and significance of the literature review in establishing a robust theoretical 
framework. It emphasizes the necessity of exploring spatial ability, AR technology, 
and learning theories to comprehend their interconnections and implications for the 
development of a mobile training system. The subsequent section, “Spatial Ability: 
Review of Theories,” delves into the concept of spatial ability, particularly within 
engineering disciplines. Various theories and models that elucidate spatial ability, its 
components, and its relevance in the context of success in engineering are discussed 
in detail, providing a theoretical underpinning. The “Augmented Reality in 
Education” section explores the use of AR in educational settings, with a focus on 
engineering education. It discusses the advantages and potential of AR technology 
in enhancing spatial ability and facilitating learning, considering both pedagogical 
and technical aspects. The “Learning Theories” section introduces different learn­
ing theories, notably Bloom’s taxonomy and the Structure of Observed Learning 
Outcomes (SOLO) taxonomy. It outlines these taxonomies’ principles, stages, and 
hierarchical levels, emphasizing their relevance to instructional design and assess­
ing learning outcomes. The “Literature Review” section elucidates the methodology 
employed in conducting the literature review, including the evaluation paper screen­
ing process. Findings from the review are presented, addressing various research 
questions, such as the benefits and drawbacks of AR in spatial ability training, adap­
tive features in AR applications, evaluation methods, and the specific aspects of 
spatial abilities assessed using AR.

14
2.1  Overview 
This chapter presents an overview of the relevant literature and is organized into five 
sections. More specifically, the first section of this chapter introduces the term “spa­
tial ability”, its multiple definitions, and its components. The second section of the 
chapter emphasizes in the importance of spatial ability in various fields, more spe­
cifically in engineering training. The third section evaluates the use of augmented 
reality technology to improve spatial skills. The fourth section presents a systematic 
literature review (SLR) on the exploration of relevant training, based on augmented 
reality technology, that has been used to improve spatial ability. The last section 
summarizes the review of the literature. 
2.2  Spatial Ability: Review of Theories 
Spatial ability, as a factor of human intelligence, was initially recognized and stud­
ied by [1]. Thorndike levelled criticism against the formulation of two-factor theory 
of intelligence [2], whose theory was based on the existence of a general intelli­
gence factor. Thorndike’s proposed model consisted of three mutually independent 
abilities, namely abstract (maintained from Spearman’s theory), mechanical and 
social intelligence, while mechanical ability was defined as the ability to visualize 
the objects’ relations and understanding of the physical world. Thorndike’s theory 
served as the early-stage research for later studies on spatial ability and highlighted 
the importance of designing measuring tools for it. 
In [3] the author also acknowledged spatial ability as a separate independent fac­
tor, opposed to Spearman’s [2] theory. Koussy researched spatial intelligence and 
contributed to the creation of tools for assessing it. Koussy identified the term factor 
“K”, as the ability to acquire and use visual spatial images. The manipulation of 
spatial relations was introduced as an additional separate component of spatial 
ability. 
In [4] the author also came to a different conclusion about the nature of intelli­
gence than [2]. Thurstone suggested that the intelligence consists of seven interre­
lated primary mental abilities, rather than a single general one. These primary 
mental abilities include a) associative memory; b) numerical ability; c) perceptual 
speed; d) reasoning; e) spatial visualization; f) verbal comprehension; and g) word 
fluency, while spatial visualization was defined as the factor involved in visualizing 
and manipulating objects. Thurstone’s theory of multiple factors [4] was the basis 
for creating each factor’s measuring tests. 
Thurstone [5] defined three core components of spatial ability, namely mental 
rotation, spatial visualization, and spatial perception. Mental rotation refers to the 
capacity to identify an object as it undergoes various orientations or angles of move­
ment; spatial visualization entails the capability to discern the components of an 
object when it is shifted or relocated from its initial position; and spatial perception 
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

15
involves the ability to utilize one’s own bodily orientation to engage with the sur­
rounding environment, thereby influencing spatial awareness [6]. 
In [7] the author put forth the theory of multiple intelligences, which challenges 
the idea of intelligence as a singular, overarching capability. Instead, he suggested 
the existence of eight distinct intelligences, each rooted in specific skills and apti­
tudes. Gardner’s argument stated that there is a wide range of cognitive abilities, not 
necessarily correlated between them, namely musical, visual-spatial, linguistic-­
verbal, logical-mathematical, bodily-kinesthetic, interpersonal, intrapersonal, and 
naturalistic. Visual-spatial intelligence is defined as the ability to accurately inter­
pret the visual environment, to alter and modify one’s first perception, and to recre­
ate some aspects of one’s visual experience, even in the lack of appropriate 
physical input. 
In [8] the author extensively studied the factor structure of spatial ability, defin­
ing two main factors, namely a) spatial visualization; and b) spatial orientation. 
Spatial visualization is the ability to mentally rotate, manipulate, and twist two- and 
three-dimensional stimulus objects [8], while spatial orientation is the comprehen­
sion of the agreement of elements within a visual stimulus pattern and the aptitude 
to remain unconfused by the changing orientation in which a spatial configuration 
may be presented [9]. 
Linn and Petersen[10] researched the gender differences in the aspects of spatial 
ability and labeled the spatial ability factors as: a) spatial perception; b) mental rota­
tion; and c) spatial visualization, separating mental rotation from spatial visualiza­
tion. In [11] the author also proposed three factors for spatial ability, giving them the 
slightly different names: a) spatial visualization; b) spatial orientation; and c) 
speeded rotation. 
12 13
­
2.1
2.2.1  Spatial Ability in Engineering 
14
­
2.2
15 16
Spatial ability stands as a pivotal cognitive prowess significantly applicable 
across numerous scientific and technical domains such as engineering, graphics, 
2.2  Spatial Ability: Review of Theories

16
Table 2.1  Spatial ability definitions 
Author(s) 
Spatial 
factor(s)
Definition 
[1]
Mechanical 
ability 
The ability of visualizing the objects’ relations and understanding 
the physical world. 
[3]
“K” factor
The ability of acquiring and using visual spatial images 
[4]
Spatial 
visualization 
Visualizing and manipulating objects 
[5]
Mental 
rotation 
The ability to recognize an object being moved in different 
directions or angles 
Spatial 
visualization 
The ability to recognize the parts of an object when it is moved or 
displaced from its original position 
Spatial 
perception 
The ability to use the human’s own body orientation to interact with 
the environment 
[8]
Spatial 
visualization 
The ability to mentally rotate, manipulate, and twist two- and 
three-dimensional stimulus objects 
Spatial 
orientation 
The comprehension of the agreement of elements within a visual 
stimulus pattern and the aptitude to remain unconfused by the 
changing orientation in which a spatial configuration may be 
presented 
[10]
Spatial 
perception 
The ability to determine spatial relationships with respect to the 
orientation of the subject’s own body 
Mental 
rotation 
Rotation of a two- or three-dimensional figure rapidly and 
accurately 
Spatial 
visualization 
The ability to involve complicated, multi-step manipulations of 
spatially presented information 
[13]
Spatial 
visualization 
The ability in manipulating visual patterns, as indicated by level of 
difficulty and complexity in visual stimulus material that can be 
handled successfully, without regard to the speed of task solution 
Spatial 
relations 
Speed in manipulating relatively simple visual patterns by whatever 
means (mental rotation, transformation, or otherwise) 
Closure speed Speed in apprehending and identifying a visual pattern, without 
knowing in advance what the pattern is, when the pattern is 
disguised or obscured in some way 
Closure 
flexibility 
Speed in finding, apprehending, and identifying a visual pattern, 
knowing in advance what is to be apprehended, when the pattern is 
disguised or obscured in some way 
Perceptual 
speed 
Speed in finding a known visual pattern, or in accurately comparing 
one or more patterns, in a visual field such that the patterns are not 
disguised or obscured
physics, and geometry [17, 18]. Those possessing robust spatial abilities are inclined 
toward triumph in these areas, and fostering spatial competence becomes a para­
mount objective for educational initiatives focused on equipping students for STEM 
careers. 
Beyond its significance in achieving success within the realm of engineering, 
spatial ability also plays a vital role in advancing innovative technologies. Engineers 
possessing robust spatial skills are more adept at conceptualizing and crafting novel 
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

17
Table 2.2  Occupations requiring top-level spatial ability [14] 
Occupation
Occupation 
1.
Air-plane Designer
43.
Engineer,
Safety 
2.
Architect, Marine
44.
''
Salvage 
3.
Botanist
45.
''
Sanitary 
4.
Cartoonist
46.
''
Sheet-metal 
5.
Cartoonist, Motion Picture
47.
''
Systems 
6.
Chemist, Metallurgical
48.
''
Time-study 
7.
Chemist, Physical
49.
''
Traffic 
8.
Detailer
50.
''
Utilization 
9.
Die Checker
51.
''
Welding 
10.
Die Designer
52.
Geophysicist 
11.
Draughtsman,
Aeronautical
53.
Industrial Designer 
12.
''
Apprentice Marine
54.
Int. Combustion Engine Designer 
13.
''
Architectural
55.
Machinery and Tool Designer 
14.
''
Construction
56.
Manager, Tarde Mark and © 
15.
''
Hull
57.
Mathematician 
16.
''
Marine
58.
Memorial Designer 
17.
''
Mechanical
59.
Modeller 
18.
''
Mine
60.
Neurologist 
19.
''
Patent
61.
Obstetrician 
20.
''
Refrigeration
62.
Oculist 
21.
''
Ship Detail
63.
Oral Surgeon 
22.
''
Ship Engineering
64.
Orthodontist 
23.
''
Structural
65.
Orthopedic Surgeon 
24.
''
Tool Design
66.
Osteopath 
25.
Engineer,
Agricultural
67.
Painter 
26.
''
Air-conditioning
68.
Pattern Checker 
27.
''
Automotive
69.
Pattern Lay-out Man 
28.
''
Ceramic
70.
Pediatrician 
29.
''
Chemical Research
71.
Physicist 
30.
''
Combustion
72.
Production Planner 
31.
''
Electrical Reearch
73.
Psychiatrist 
32.
''
Gas Distribution
74.
Psycologist, Industrial 
33.
''
Hydraulic
75.
Public Health Officer 
34.
''
Methods
76.
Sculptor 
35.
''
Mining
77.
Stage-scenery Designer 
36.
''
Petroleum
78.
Surgeon 
37.
''
Plant
79.
Tool Designer 
38.
''
Steam-power Plant
80.
Urologist 
39.
''
Production
81.
Veterinarian 
40.
''
Radio
82.
Veterinarty,
Bacteriologist 
41.
''
Railroad
83.
''
Pathologist 
42.
''
Refrigeration
84.
''
Surgeon
2.2  Spatial Ability: Review of Theories

18
technologies that align with societal requirements. To illustrate, in the domain of 
robotics, spatial ability is indispensable for crafting robotic systems capable of tra­
versing intricate surroundings and executing precise object manipulation. 
Spatial ability performs as an indicator for success in engineering students. In 
[19] the author designed a 52-h course aiming to develop skills in representing spa­
tially visualized objects through projections. The authors of [20] also launched a 
fast-remedial course based on three-dimensional modeling for improving spatial 
abilities of engineering students. Designing three-dimensional objects is highly 
considered to be a crucial factor in the development of spatial skills [21, 22]. 
In engineering university education, the enhancement of the visualization skills 
of the students is essential for the development of the design skills in many fields of 
engineering [23, 24]. Spatial skills are the most crucial indicator of success in 
objects’ manipulation and interaction [25]. Students, who have the opportunity to 
enhance their spatial skills, exhibit higher levels of self-efficacy, achieve better 
results in the fields of math and science and are more likely to maintain in engineer­
ing [26]. In [27] the author identified the challenge of improving the spatial ability 
of engineering students. In [28] the author reported that students’ spatial ability 
level is directly correlated to the success in the fields of engineering, mathematics, 
and architecture. 
Engineering drawing plays an important role in the efforts in improving stu­
dents’ spatial ability. The School of Engineering includes first-year university pro­
grams for various departments, such as Electrical and Electronic Engineering, 
Biomedical Engineering, Industrial Design and Production Engineering, Informatics 
and Computer Engineering, Surveying and Geoinformatics Engineering, Mechanical 
Engineering, Naval Architecture, and Civil Engineering. In these programs, stu­
dents are primarily exposed to courses like engineering drawing, technical drawing, 
and computer-aided design (CAD). 
29
­
­
2.1
30 31
­
32
­
­
2.1
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

19
 
To tackle these challenges, educators and instructional designers have devised an 
array of pedagogical techniques and tools aimed at enhancing the spatial ability of 
engineering students. These methods encompass the utilization of visual aids like 
three-dimensional models, computer-based simulations, and virtual reality environ­
ments. Moreover, educators may incorporate spatial visualization training programs 
and exercises to facilitate students in enhancing their spatial ability. 
Moreover, it’s crucial to acknowledge that students possess diverse learning 
styles and varying strengths and weaknesses [33, 34]. Spatial ability may be a chal­
lenge for some students, while others may demonstrate exceptional proficiency in 
this domain. Hence, educators should offer a range of instructional approaches and 
materials to support students in honing their spatial skills, guaranteeing that every 
student has the chance to thrive in the field of engineering. 
The creation of accurate engineering drawings requires a specific set of technical 
guidelines and spatial skills. The technical guidelines are typically covered in engi­
neering departments’ drawing courses. Consequently, having strong spatial skills is 
essential for producing high-quality engineering drawings [35]. Numerous studies 
have emphasized the significance of spatial ability and have suggested various peda­
gogical approaches to enhance the development of this ability in engineering stu­
dents [23, 24, 36]. In [37] the authors emphasize the importance of strong spatial 
skills, as a basic competency for future engineers, including the ability to visualize 
the rotation of objects and their different perspectives. 
A large number of studies has indicated that integrating the appropriate training 
materials, can result in the enhancement of the training of spatial skills [35, 38–40]. 
Freshmen engineering students, attending engineering graphics courses, showed 
substantive improvement in their spatial visualisation skills [41–44].
2.2  Spatial Ability: Review of Theories

20
2.3  Augmented Reality in Education 
All technologically enhanced realities fall under the broad concept of Extended 
Reality (XR), which combines the experiences of augmented reality (AR), virtual 
reality (VR), and mixed reality (MR) [45]. To improve this experience, AR overlays 
virtual content on top of the already existing real-world environment [46]. Contrarily, 
VR immerses viewers in an entirely new environment that is often developed and 
rendered by computers [47–50]. Finally, MR is a user environment that combines 
digital content and physical reality in a manner that makes it possible for users to 
interact with both real-world and virtual objects [51]. 
Augmented Reality (AR) serves as an optimal conduit for Internet of Things 
(IoT) applications by overlaying digital data concerning intelligent objects and ser­
vices onto a user’s real-world perspective [52, 53]. An AR system possesses the 
following characteristics: a) it blends actual and virtual elements within a genuine 
setting; b) it operates interactively and instantaneously; and c) it aligns real and 
virtual components with one another [46]. 
A substantial body of published research exists, detailing the benefits, con­
straints, and obstacles associated with the use of Augmented Reality (AR) in educa­
tional settings [54–59]. Various interactive and innovative applications generated by 
AR technology [57, 60, 61] have given great potential in different learning subjects 
and specifically in STEM (Science, Technology, Engineering, and Mathematics) 
education [62]. 
Many studies have explored the positive effects of AR technology in education 
[17, 63, 64], as compared to the traditional methods of teaching and learning. 
Previous authors [61] tested a firefighting training system using AR, which was 
more cost-effective and safer, compared to large-scale real-life training. Simulating 
firefighting scenarios helped the trainees evaluate their knowledge and deal with 
risky circumstances. 
Another study [65] presented a mobile AR travel guide, supporting personalized 
recommendations. The authors explored the relationship between system proper­
ties, user emotions, and adoption behavior. More specifically, the developed AR 
application built a user profile, based on users’ preferences, and according to the 
updated profile, users are offered extra media features. 
AR is considered one of the most disruptive technologies in the field of market­
ing [66]. Consumers derive tangible benefits from AR technology and expect it as 
part of their purchasing process. AR has been incorporated into store catalog appli­
cations, which allow consumers to visualize what different products would look like 
in different environments. With AR technology, marketers are able to carry out suc­
cessful digital campaigns. AR aids marketing as it can let the customers try before 
they buy, augment touring and assistance, and finally, augment branding materials. 
In [67] the authors explored the potential of VR, AR, and MR in both dental 
education and clinical dentistry. AR and VR technology can be beneficial not only 
for dental students but also for patients, as AR and VR can reduce dental anxiety and 
treat dental phobias. Furthermore, a systematic review [68] investigated the 
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

21
usability of AR in the area of health sciences on the aspect of the psychopedagogy 
of students in higher education. The usage of AR improved many aspects of the 
learning process, including motivation, satisfaction, and autonomous learning [57, 
69, 70]. 
The literature review reveals numerous studies focusing on the integration of AR 
technology in fields such as education [58, 60, 61, 71, 72], tourism [65, 73–76], 
industry [77–79], marketing [66, 80, 81], and medical [67, 68]. 
2.3.1  AR in Engineering Education 
Engineering drawing was used to be taught using chalk and board, as well as model 
blocks back in the day. Nowadays, the development of technology has introduced 
the use of computer-aided software in the teaching of engineering drawing in higher 
institutions [82–86]. Recent studies have shown that AR is considered to be one of 
the best alternative teaching approaches to cover these issues [23, 56, 87]. 
A study by [88] examined the use of AR in teaching students and future teachers 
of Descriptive Geometry, Engineering and Computer Graphics (DGECG). Their 
results showed that there is an absence of scientifically substantiated and proven 
programs and training material for training students of DGECG using AR, needing 
further scientific research in this field. However, the study examined solely nine 
articles without focusing on a detailed overview of the research in the area of 
enhancing spatial skills within AR environments; the authors mainly identified the 
indispensable need for comprehensive future research in the area of descriptive 
geometry. 
Diao and Shih [89] conducted another systematic review of literature concerning 
AR in architectural and civil engineering education. Analysis was performed based 
on fundamental information, application domains, AR development tools, system 
types, teaching devices, teaching methods, learning strategies and research meth­
ods. The study focused on domain-specific studies of architects and civil engineers, 
and ignored cross-domain contributions. Additionally, the study lacks in the evalu­
ation of the contribution of AR to spatial skills training. 
While many prior reviews of AR applications have focused on the field of educa­
tion [90], there is an absence of systematic literature review on the use of AR in 
training spatial skills. According to [91], very little or no systematic research work 
has been conducted studying the effects of VR/AR systems in training spatial skills. 
Moreover, no commercial VR/AR applications have been developed for this train­
ing purpose either. Therefore, a review of research studies in spatial ability training 
using AR technology can suggest areas in which future research can be oriented.
2.3  Augmented Reality in Education

22
2.4  Learning Theories 
2.4.1  The Bloom’s Taxonomy 
Bloom’s taxonomy of educational objectives has served as the foundation for the 
development of the majority of cognition and achievement assessments [92]. Since 
its publication in 1956, the taxonomy has thousands of citations. Numerous tests, 
created by teachers, have been based on the Bloom taxonomy, which has been 
widely utilized in teacher education to recommend learning and teaching tactics. 
The ranked classifications range from “knowledge”, at the most fundamental 
level, to “evaluation”, at the level requiring the most cognitive state, arranging dif­
ferent processes hierarchically. Each level is dependent on the student’s competence 
in the level or levels before it. Bloom’s taxonomy was developed to help teachers 
define learning objectives and serves as a framework for creating assessment criteria 
relevant to the varieties of cognitive domains, and mental and cognitive abilities 
being evaluated. 
Certain limitations of the first version of Bloom’s Taxonomy are acknowledged 
in a revised edition [93], which also adds a new dimension to knowledge types, and 
rearranges the hierarchy of the cognitive processes. The revised Bloom taxonomy 
actually defines the expected cognitive process and the type of knowledge underly­
ing a learning objective. Both taxonomies are represented as hierarchical frame­
works, in which, the upper more complicated level, encases all lower levels. 
Despite the Bloom cognitive taxonomy’s popularity, there is no evidence to sup­
port its utility in planning curriculum, instruction, or assessment. The primary issue, 
with using Bloom’s Taxonomy to control the development of questions, is the mis­
conception that its categories constitute a range of classifications that are arranged 
hierarchically [94]. 
Some of the issues arising from the Bloom’s taxonomies are the fact that the 
Bloom taxonomy assumes that there must be a connection between the questions 
raised, and the expected responses. The assumption used while applying Bloom’s 
taxonomy is that the question will elicit a specific type of Bloom response. However, 
there is no definite connection, because a student may answer the supposedly sim­
pler question with a very profound explanation, or in a similar vein, a student might 
give a perfunctory response. 
2.4.2  The SOLO Taxonomy 
The Structure of Observed Learning Outcomes (SOLO) cognitive processing tax­
onomy was developed by [95] and describes the levels of students’ understanding in 
ascending order of complexity. 
­
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

23
96
­
2.3
The SOLO taxonomy is divided into two main categories, each of which has two 
progressively more complicated stages. Unistructural and multi-structural are part 
of the surface level, whereas relational and extended abstract are included within the 
depth level. Responses, that are unistructural, need the knowledge or application of 
a single fact, or piece of information, that was directly derived from the situation. 
Multiple pieces of information or facts must be known or employed, in order to 
complete multi-structural responses or queries, as well as two or more distinct steps 
without any concept integration. Fundamentally, this is an unstructured, unsorted 
list. As opposed to surface-level inquiries, deep processes represent a shift in the 
nature of thinking that is cognitively more difficult. 
Relational answers or inquiries must integrate at least two distinct pieces of 
knowledge that, when combined, provide the solution to the problem. In other 
words, relational inquiries demand that students put an organizing structure on the 
content they are given. 
Extended abstract, the highest level of the SOLO taxonomy, requires for the 
answer to go beyond the information, knowledge, or concepts provided and deduce 
a more universal rule or proof that actually applies in all cases. The learner is driven 
to go beyond the information provided and to draw on relevant, prior knowledge 
concepts or information in order to form a response, a prediction, or a hypothesis 
that applies the information provided to a wider range of scenarios. 
2.4.3  Comparison of the Learning Theories 
Although Bloom’s taxonomy is widely adopted for educational outcomes, the 
SOLO taxonomy provides useful tools for assessing the levels attained in students’ 
effort. The SOLO taxonomy allows teachers to evaluate students’ tasks, based on 
their quality, rather than what questions they answered correctly and incorrectly. 
The taxonomy allows teachers to evaluate students’ tasks based on their quality 
rather than what they did correctly and incorrectly. There are five stages with each 
level increasing in complexity and skill. Students completely miss the point at the 
pre-structural level, which is the lowest. Students can only describe one feature of a 
topic at the following level (unistructural), and they can only identify multiple unre­
lated aspects at the third level (multi-structural). Students can combine several ideas 
into a single structure at the relational level, which is the fourth level. Finally, stu­
dents are able to generalize and formulate hypotheses at the greatest level (extended 
abstract).
2.4  Learning Theories

24
Table 2.3  Learning goals and activities per SOLO level [97] 
SOLO 
level
Learning goal
Learning activities
Description of the activities
Pre-­
structural 
(L0) 
Students get information 
on the subject 
Define concepts 
List items 
Match information 
Name facts 
Introduction to Technical 
Drawing: A history and 
current importance of 
drawing are presented. 
Students are asked TO 
illustrate the significance of 
drawing by presenting 
applications and reports of 
both good and negative uses 
of the skill 
Uni-­
structural 
(L1) 
Students define, 
recognize, name, sketch, 
reproduce, recite, follow 
simple instructions, 
calculate, reproduce, 
arrange, find 
Identify content to be 
memorized, show 
examples 
Provide disciplinary 
context 
Mnemonics in groups 
Repetition of procedures 
Games 
Repetitive testing and 
matching 
Peer testing (one student 
asks, one answers) 
Setting up a model space in 
CAD software by defining 
limits, grid, snap, layers, and 
object snap 
Video tutorials on standard 
views, views alignment, 
completion of activity sheet, 
and setting up the model 
space 
Border creation with a 
completed title block to be 
used for all future drawings, 
and drawing templates with 
all the settings necessary 
saved within it 
Multi-­
structural 
(L2) 
Students describe, list, 
classify, structure, 
enumerate, conduct, 
complete, illustrate, 
solve 
Glossaries of key terms 
with definitions, 
classifications, examples 
to build disciplinary 
vocabulary 
Simple laboratory 
exercises 
Define terms, compare 
to glossary 
Games modelled on 
Trivial Pursuit, Family 
Feud 
Orthographic drawing 
creation. 
Lines, layers 
Isometric object drawing 
Video tutorials on linetype, 
lineweight and isometric 
drawing creation of objects 
in the activity
(continued)
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

25
Table 2.3  (continued)
SOLO 
level
Learning goal
Learning activities
Description of the activities
Relational 
(L3) 
Students relate, analyze, 
compare, integrate, plan, 
construct, implement, 
summarize 
Case studies, 
simulations, and 
complex lab exercises 
Concept maps 
Research projects and 
experiential learning 
cycles 
Application of 
theoretical models 
Reflective journals 
Student seminars and 
debates 
Syndicate groups (each 
group is part of whole) 
Problem-Based 
Learning and Inquiry 
Learning 
Scaling the border and title 
block to fit the orthographic 
drawing 
Dimensioning an 
orthographic drawing 
Video tutorials on basic 
dimensioning rules and parts 
of dimensions 
Filling in a title block, 
including Name, Date, Title, 
Drawing No., and the correct 
scale 
Snapping and Text 
commands 
Extended 
abstract 
(L4) 
Students generalize, 
hypothesize, theorize, 
predict, judge, evaluate, 
assess, predict, reason, 
criticize 
Self-directed projects 
involving research, 
design, application, 
argumentation, 
evaluation 
Case studies involving 
extensive analysis, 
debate, reflection, 
argumentation, 
evaluation, forecasting 
Development of a theory 
or model 
Experiential learning 
cycles 
Problem Based Learning 
and Inquiry learning 
Printing the drawing on 8.5″ 
× 11″ paper (letter size) in 
landscape orientation 
Video tutorial on cutting 
plane, half and full sections 
Printer/plotter settings 
Export/plot an object that has 
been drawn in CAD so it can 
be exported or printed to a 
variety of other applications 
CAD software to create 
objects that are more precise 
and sometimes easier to draw 
in CAD than in other 
software
2.5  Literature Review 
This literature review follows the guideline for systematic reviews, appropriate for 
software engineering researchers, proposed by [98]. There is a variety of review 
designs and existing guidelines intended to aid medical researchers. The purpose of 
a review of healthcare literature is to summarize the knowledge around a specific 
topic and support health professionals make decisions about a care issue. 
Kitchenham’s guideline is based on a review of three existing medical guidelines 
and adapts them to the need of software engineering researchers. In particular, soft­
ware engineering research has relatively little empirical research compared with the 
large quantities of research available on medical issues, and therefore, research 
methods used by software engineers are not as rigorous as those used by medical 
2.5  Literature Review

26
researchers. The guideline has been adapted to reflect the specific problems of soft­
ware engineering research [99]. 
The guideline covers three phases of a systematic review: planning the review, 
conducting the review and reporting the review. It is at a relatively high level [98]. 
At the first phase of the planning of the review, a review protocol is developed. 
The protocol serves as a roadmap for the review and specifies the objectives, meth­
ods, and outcomes of primary interest of the systematic review. The purpose of 
having a protocol is to promote transparency of the methods. A protocol defines the 
search terms, the inclusion and exclusion criteria and the data that will be analyzed. 
At the second phase, the review is conducted. Once the protocol has been devel­
oped, the review starts. This procedure involves the finding of studies relating to the 
research questions, and then, the study of their actual relevance. Subsequently, 
inclusion and exclusion criteria are employed to refine the outcomes. Data collec­
tion forms are devised to gather all the requisite information from each study, and 
data synthesis is utilized to compile and condense the findings of these studies. 
The third phase of the review is very important as it communicates the results of 
the systematic literature review. 
2.2
­
­
2.5.1  Planning the Review (Review Protocol) 
For this review, it was conducted a thorough search of scientific articles, mainly in 
the Scopus and Google Scholar databases. The results were filtered through key­
words in the paper title, abstract and keywords list. The search results discovered 
154 papers, based on certain keywords “augmented reality” and (“spatial ability” or 
“spatial skills”) and (“training” or “teaching” or “education”). 
Afterwards, the inclusion and exclusion criteria were defined. Considering the 
research questions, general criteria defining the time frame for the studies and the 
type of relevant studies were devised. This research aims to review the most recent 
literature regarding using AR in spatial abilities training. The inclusion criteria were 
the time span of the last 12 years from 2010 to 2022, and the document language 
was determined as “English”. Journal and/or conference literature review papers 
were included, while Master’s or Ph.D. theses were excluded from the systematic 
review. Papers that were not directly related to AR and spatial abilities’ training 
were also determined as exclusion criteria. 
­
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

27
 
100
2.4
2.5.2  Conducting the Review 
All the 154 papers from the first phase were thoroughly examined to determine their 
relevance to the study. As they did not align with the study’s objectives, 114 papers 
were deemed unsuitable and consequently excluded based on the exclusion criteria. 
This led to the inclusion of a total of 40 papers, which comprised the final list for 
2.5  Literature Review

28
Table 2.4  Evaluation criteria
Research question Evaluation criteria 
RQ 1
AR advantages 
RQ 2
AR limitations 
RQ 3
Learning tool 
AR approach 
AR type 
Software 
Type of adaptation process 
RQ 4
Spatial abilities Aspects 
Test used 
RQ 5
Research sample 
Research method 
Data collection method
analysis. Among these, 29 were journal articles, 8 were conference papers, and 3 
were either books or book chapters. 
Every one of the studies underwent assessment and analysis in accordance with 
the research inquiries. An article review form was developed, as a data collection 
tool, to examine the articles to be reviewed. The data collection tool, developed by 
[101], was revised according to the research questions in the present research, and 
was implemented as a table matrix in Microsoft Excel. It is composed of six sec­
tions, one section for the screening of the evaluation papers, including article’s gen­
eral information, and five more sections, one for each research question. 
Each one of the 40 studies was thoroughly reviewed in order to determine the 
advantages and the limitations of the first and second research questions (RQ1 & 
RQ2). Advantages were arranged into three categories: learner outcomes, pedagogi­
cal contributions and technical perspectives. In the case that an article included 
more than one advantage and/or limitation, it was separately recorded. 
2.5.3  Screening of the Evaluation Papers 
The first section of the data extraction form addresses the publication year, the target 
group, the level of education and the country. The year is the date of the publication 
of the journal or the conference and has a value from 2010 to 2022. The level of 
education was divided into seven sub-categories of participants: preschool students, 
primary education students, secondary education students, technical education stu­
dents, higher education students, teachers (of any level of education) and not speci­
fied (the learner type was not clearly specified). 
­
2.3
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

29
 
2.4
102
104
­
24 105
2.5  Literature Review

30
 
106
107 108
2.5
2.5
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

31
 
2.5.4  Advantages of AR in Spatial Ability Training (RQ1) 
­
­
2.5
2.5.4.1  Learner Outcomes 
The advantages of AR in spatial abilities training that are related to either spatial 
visualization or spatial perception or mental rotation are grouped under the sub-­
section of the learning outcomes of enhancing spatial ability. Most of the studies (29 
out of 40) reported that AR technology in education leads to this learning outcome. 
Numerous studies (12 out of 40) have indicated that AR increases students’ under­
standing. For instance, AREDApps [103] was developed as an alternative to help 
increase students’ understanding, enhance visualization skills and attract students’ 
2.5  Literature Review

32
Table 2.5  The advantages of AR in spatial abilities training 
Categories
Sub-categories
Frequency 
Sample 
research 
Learning outcomes
Enhances spatial ability
29
[6, 109–111] 
Increases students’ understanding
12
[112] 
Enhances students’ motivation
6
[113] 
Improves students’ academic performance
6
[114] 
Visualizes abstract concepts
6
[104] 
Positive attitude towards the course
5
[115, 116] 
Reduces cognitive load
4
[107, 117] 
Students observe models from different 
perspectives 
3
[118] 
Enhances satisfaction
2
[119, 120] 
Assists students in solving given problems
1
[121] 
Students memorize better the learning 
material 
1
[91, 122] 
Pedagogical 
affordances 
Attracts students’ interest
13
[113] 
Students manipulate virtual objects in real 
environment 
8
[123] 
Enhances enjoyability
6
[124] 
Autonomous training
4
[106] 
Increases engagement in teaching and 
learning process 
4
[125] 
Interaction with the immersive environment
4
[31] 
Promotes self-directed learning
4
[91] 
Personalization of learning
2
[105] 
Allows students to be an active learner
1
[123] 
Develops collaborative work in students
1
[113] 
Learning by doing
1
[91] 
Student centered learning
1
[6] 
Technical 
perspectives 
Easy to use
11
[126] 
Cost effective
8
[116]
interests in engineering drawing. Moreover, AR provides the ability to help students 
develop a deeper understanding [104]. 
The review findings also indicate that AR can enhance students’ motivation, 
improve students’ academic performance, enhance positive attitude, and visualize 
abstract concepts. Students feel more motivated in class when these tools are imple­
mented in pedagogical activities in the classroom [113]. Students’ motivation to the 
instructional activities can be increased due to the enriched features of the learning 
environment [91]. Furthermore, the use of AR materials, integrated in the educa­
tional environment, improves the students’ academic achievement [114]. According 
to [116], the faculty members that participated in the validation study perceived a 
very positive and receptive attitude by the students. With the use of 3D imagery, 
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

33
students can visualize the abstract concept [127], which cannot be easily seen in a 
real-life setting [104]. 
Some researchers reported specific AR-related learning outcomes such as the 
reduction of cognitive load, the enhancement of satisfaction, student observation 
from different perspectives, the provision of assistance to students for solving given 
problems and better memorization of learning material. As an example, [107] con­
ducted a paired-sample t-test to assess mental effort and mental load scores inde­
pendently. This analysis revealed a noteworthy distinction in terms of mental effort 
and mental load between the experimental and control groups. In another study by 
[120], students expressed a high level of satisfaction when Augmented Reality (AR) 
technology was employed. 
2.5.4.2  Pedagogical Affordances 
According to the pedagogical affordances of AR, the most prominent contributions 
are the attraction of students’ interest, the manipulation of virtual objects in real 
environment, and the enhancement of enjoyability. Most of the students show a 
great interest, expressing awe and revelation in their faces while exploring with the 
new tools until they found new purposes [113, 128]. Lee et al. [108] concluded that 
the participants in the experimental group showed great interest in using their AR 
training system. AR provides a platform for students to manipulate a virtual object 
freely from various perspectives, as they can use their bare hands to make manipula­
tion [104]. In addition to that, all of the students stated that the AR application made 
the classes more enjoyable [114]. 
AR technology is valuable, engaging, and useful in the engineering design 
graphics domain, particularly when visualizing challenging models. Excitement 
and engagement could be easily observed in the participants during the exercise, 
although this could be attributed to the fact that many had never used or experienced 
AR technology before [129]. 
On the other hand, the indications of self-directed and/or personalization of 
learning and autonomous training were reported in very few studies within the 40 
reviewed research articles, and they all suggest that further study is warranted, 
regarding potential benefits for the development of the ability and the confidence in 
spatial skills. 
2.5.4.3  Technical Perspectives 
2.5
126
130
2.5  Literature Review

34
­
129
2.5.5  Limitations of AR in Spatial Ability Training (RQ2) 
2.6
106
Some other studies had the limitation of the small sample size [117–119]. While 
the results of the studies are significant, a broader sampling size in order to include 
more students of varying background could better validate the research questions. 
Another limitation was the absence of a control group. Therefore, the improve­
ment of the posttest score of students may be made not only due to the AR learning 
Table 2.6  The limitations in AR in spatial abilities’ training 
Limitations
Frequency 
Sample 
research 
Necessity for more content
7
[106] 
Small sample size
3
[121] 
Control group missing
2
[104] 
Help sections missing
2
[121] 
Country location specific results
2
[130] 
The participants had limited time for the training
2
[107] 
Data collection during very long periods of time
1
[113] 
Focuses only on beginners
1
[107] 
Gender related differences in performance could not be examined due 
to unequal gender ratio 
1
[131] 
Limited financial resources limit a further development and wider 
application of this technology in the education process 
1
[131] 
Needs a re-design in terms of pedagogical instructions
1
[121] 
Needs many environmental settings and pre-settings of the system
1
[107] 
No experimental testing
1
[31] 
Relatively new technology
1
[118] 
Requires long-term training and practice to master
1
[107] 
The app was under continued development during the course of this 
study 
1
[124] 
The application needs supportive printed material
1
[132] 
The end product must achieve certain qualities
1
[126] 
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

35
experiment but also by other variables. It is recommended to have a control group 
in the future investigation [104]. 
Additional training modules or help sections could be added to the application to 
familiarize the learner with the necessary know-how of the application usage [121]. 
A couple of studies reported the limitation that the results are specific to the location 
of the study [130, 132], while two others stated that the participants had limited time 
for the training because many had routine school homework to do and meetings to 
participate in [108, 121, 122]. 
The rest of the limitations involve application-related and technical problems. 
Future technological developments are expected to fix most of the current 
limitations. 
2.5.6  Exploration of the Incorporation of Adaptivity 
and Personalization in AR Applications (RQ3) 
2.7
116
­
­
125
134
Since 2014, the developers started to use mobile AR, mainly due to the prolifera­
tion of mobile technology (such as mobile phones, tablets, wireless network etc.). 
The freedom degree of the user increases when using mobile AR applications, com­
pared to desktop AR applications. 
Figueiredo et al. [31] presented the creation of a low-cost prototype, namely 
“EducHolo”, which enabled the visualization and interaction with holograms. Their 
aim was to provide a better perception of the model 3D shape improving the ability 
to make the 2D orthographic views and perspectives that the first year of mechanical 
engineer studied. They used Augment software which is free without requiring pro­
gramming. The “DiedricAR” application allowed students to learn autonomously 
by using their own mobile devices that work as AR displays over training material 
2.5  Literature Review

36
Table 2.7  AR applications training spatial ability 
Article Learning tool 
AR 
approach
AR type 
Software
Content 
Adaptivity? 
(Yes/No/ 
Some) 
[112] 
AR-Dehaes 
augmented book 
Desktop
Marker-­
based 
Brainstorm 
eStudio 
3D 
models 
No 
[133] 
AR models
Desktop
Marker-­
based 
ARToolKitPlus 
3D 
models 
No 
[132] 
AR enhanced 
exercise book 
Desktop
Marker-­
based 
not specified
3D 
models 
No 
[31]
EducHolo
Mobile
Marker-­
based 
AutoCAD 
Augment 
3D 
models 
No 
[106] 
DiedricAR
Mobile
Marker-­
based 
Unity 3D 
Vuforia SDK 
3D 
models 
No 
[122] 
AREDKit
Not 
specified 
Not 
specified 
AutoDesk 3DS 
Max 
Unity 3D 
Android Studio 
3D 
models 
No 
[117] 
GeoSolvAR
Mobile
Marker-­
based 
Unity 3D 
Vuforia SDK 
3D 
models 
No 
[104] 
ARScience Magic 
Book 
Desktop/ 
Laptop 
Marker-­
based 
Not specified
3D 
models 
No 
[119] 
MAR
Mobile
Marker-­
based 
AutoDesk 3DS 
Max 
Unity 3D 
Android Studio 
3D 
models 
No 
[103] 
AREDApps
Mobile
Marker-­
based 
Unity 3D 
Vuforia SDK 
Android Studio 
3D 
models 
No 
[113] 
Augmented 
Reality Chemistry 
(ARC) 
Mobile
Marker-­
based 
Unity 3D 
Vuforia SDK 
Android Studio 
3D 
models 
No 
[131] 
Geogebra AR
Mobile
Marker-­
based 
Not specified
–
No 
[134] 
Spatial-AR
Mobile/ 
smart 
glasses 
Marker-­
based 
AutoDesk 3DS 
Max 
Unity 3D 
Android Studio 
3D 
models 
No
[106]. Other applications developed during the years 2018–2019 are: i. “AREDKit” 
developing to allow manipulation of 3D virtual models with the purpose to help 
students to perform visualization tasks during the process of teaching and learning 
[126], ii. “GeoSolvAR” focusing on middle school students to improve their visual­
ization skills [121], iii. “ARScience Magic Book” Learning System (AR-SMB) 
developing to facilitate students in learning science concept, hence, enhancing their 
spatial visualization ability [104], iv. “MAR” and “AREDApps” being the most 
recently known approaches in the teaching and learning of orthographic projection 
[102, 103].
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

37
Finally, during the years 2020–2022, three more applications were presented, 
namely “ARC”, “Geogebra AR”, and “Spatial-AR”, which train the spatial skills of 
secondary students in the fields of Chemistry and Mathematics [110, 117, 135]. 
Except for the “ARScience Magic Book” and the “Geogebra AR”, that the 
authors did not clearly explain the software they used, the rest applications were all 
developed using Unity 3D software to create the AR platform. This is an object-­
oriented framework with graphic interface that can build applications for many dif­
ferent platforms including iOS and Android. Unlike other frameworks, Unity3D 
allows an easy handling of virtual models. Additionally, some of the applications 
used Autodesk 3D Studio Max as 3D modeling software to create and render 3D 
models and Android Studio as the official integrated development environment 
(IDE) for Google’s Android operating system. Vuforia is also used as a good 
Software Development Kit (SDK) that provides functionalities for the development 
of AR applications on mobile, using images or objects for targets. For the develop­
ment and deployment of the application to the mobile devices, Unity3D is used. 
Unity3D is a game engine that can be integrated with Vuforia allowing the develop­
ment of AR applications. 
Among all these teaching applications, it can be noted that the trend in the usage 
of AR approach is 3D model content. The justification for choosing three-­
dimensional model as the augmented objects is made based on the major trends and 
the effectiveness of learning using three-dimensional models towards improving 
spatial visualization skills. 
2.7
136 139
­
140
143
2.5.7  Aspects of Spatial Abilities Having Been Evaluated 
Using AR (RQ4) 
The fourth research question investigates the aspects of spatial abilities that have 
been evaluated using AR. The assessment of spatial ability is critical as specific 
standardized tests offer a valuable piece of knowledge about specific spatial sub­
components. It is important for researchers or employers to know what aspect they 
want to evaluate, so that they select a test with strong reliability and validity 
evidence.
2.5  Literature Review

38
Currently, studies on spatial abilities follow two lines of research concerning the 
definition of factors. The first one is the proposal of three factors: i) spatial percep­
tion; ii) spatial orientation or mental rotation, considered to be unique; and iii) spa­
tial visualization. The second line is the proposal of two factors: i) spatial relation, 
or mental rotation; and ii) spatial [6]. 
Numerous assessments exist for evaluating spatial ability, reflecting the absence 
of a single, unified definition of this skill. Instead, spatial ability is typically 
described in relation to multiple sub-elements. Numerous research studies have 
explored the spatial skills of students and developed standardized tests to gauge 
their proficiency in various facets of spatial ability. 
2.8
144
­
­
145
In the second place, the most frequent tests are the DAT:SR and MRT tests. 
Differential Aptitude Tests: Space Relations (DAT:SR) measures learner’s ability to 
move from 2D to 3D world. It consists of 50 questions about paper folding. Mental 
Rotation Test (MRT) of [146] was developed to measure students’ improvement in 
spatial skills. MRT is one of the most frequently used tests that measure the spatial 
relations. Mental rotation is the perceptual process of visualizing an item at differ­
ent angles in a three-dimensional world. The students compared objects depicted on 
a paper or monitor and find the identical ones. The original image and the identical 
ones are displayed at different rotations. There are 20 items in MRT, in each item, 
the left side consists of a target figure and the right side consists of four (or three in 
some revised versions) sample stimuli. The participant needs to choose the correct 
figure that represents the rotation of the target figure.
Table 2.8  Standardized tests to measure spatial skills 
Test
Frequency Percentage 
Purdue Spatial Visualization Tests: Visualization of Rotations (PSVT:R) 12
33.33 
Differential Aptitude Tests: Space Relations (DAT:SR)
9
25.00 
Mental Rotation Test (MRT)
7
19.44 
Mental Cutting Test (MCT)
3
8.33 
Middle Grades Mathematics Project (MGMP)
1
2.78 
Minnesota Paper Form Board Test (MPFBT)
1
2.78 
Picture Rotation Test (PRT)
1
2.78 
Purdue Spatial Visualization Tests: for Development (PSVT:D)
1
2.78 
Spatial Perception Scale (SPS)
1
2.78 
Spatial Orientation Test (SOT)
0
0.00 
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

39
The Mental Cutting Test (MCT) measures the ability to visualize object cutting 
and was first developed for a university entrance examination in the USA, College 
Entrance Examination Board (CEEB) in 1939. The test consists of 25 items. For 
each problem on the exam, students are shown a criterion figure which is to be cut 
with an assumed plane. They must choose the correct resulting cross-section from 
among five alternatives. 
Middle Grades Mathematics Project (MGMP) [114] and Minnesota Paper Form 
Board Test (MPFBT) [147] have been used each one of them in just one research 
study. This low usability is also observed in Picture Rotation Test (PRT) and Spatial 
Perception Scale (SPS) respectively. The first one measures the rotation skills of 
pre-and-early primary school children (ages from 4 to 6) [148], while the second 
one measures the visualization and orientation skills of 6-year-old children [118], 
but this infrequency of use is mainly due to the preschool domain, which is not 
among the target groups of AR spatial skills training. 
The last one named Spatial Orientation Test (SOT) was not found in any of the 
selected studies. This is due to the fact that the majority of authors and researchers rec­
ognize two factors: mental rotation; and visualization. They do not really include the 
third category: spatial orientation as well as the specific instrument for measuring it. 
2.5.8  Evaluation Methods Considered for AR Applications 
in Educational Scenarios (RQ5) 
The fifth research question examines the methodology in terms of AR applications. 
It is very important for the researchers to identify the correct strategy for their study 
so that the results provide valid information. 
2.9
­
2.10
Table 2.9  Distribution of 
research sample size 
Sample size
Frequency % 
Between 1–10
2
5.0 
Between 11–50 
18
45.0 
Between 51–100 10
25.0 
Above 100
4
10.0 
Not specified
6
15.0 
2.5  Literature Review

40
Table 2.10  Research 
methods applied 
Research method Frequency % 
Quantitative
13
32.5 
Qualitative
4
10.0 
Mixed
15
37.5 
Not specified
8
20.0 
Table 2.11  Data 
collection method 
Data collection tool Frequency % 
Case study
2
2.6 
Interview
4
5.2 
Post-test
22
28.6 
Pre-test
21
27.3 
Questionnaire
17
22.1 
Other
4
5.2 
Not specified
7
9.1 
2.11
­
Drawing from the literature discussed in this chapter, a handful of Augmented Reality 
(AR) applications [116, 125, 134] were designed with the objective of assisting students 
in improving their spatial skills using a desktop-based approach. Conversely, certain 
other applications [31, 104, 106, 121, 149] opted for a mobile-­centered approach to 
achieve the same goal. All of the already available augmented reality applications were 
created without reference to any particular framework but rather based on the writers’ 
previous programming and/or technological knowledge. Furthermore, intelligent tutor­
ing systems (ITS) offering more independence to students during the training sessions 
have been implemented in different educational fields and should be combined with AR, 
in order to provide next generation advanced learning systems. Intelligent augmented 
reality tutoring systems could provide a personalized interface which is currently absent. 
2.6  Summary 
In this chapter, a comprehensive review regarding AR in spatial ability training has 
been conducted and the technologies, application areas, and future research direc­
tions have been identified. General reviews of AR applications focusing on educa­
tion have been made; however, a systematic literature review is absent when it 
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

41
comes to the use of AR in spatial ability training. The identified research gaps are: 
i) the absence of commercial AR applications developed for the training of spatial 
abilities; ii) the absence of adaptivity of the systems in the existing literature; and 
iii) the need for developing a novel framework to focus on the design elements of an 
AR application. 
Trends of AR are a) the development of mobile (smartphones and tablets) AR 
applications; b) the use of Unity3D as the development platform; c) the use of 
Vuforia as the AR software development kit; and d) 3ds Max as 3D modeling soft­
ware. Spatial ability is very important in engineering education and AR technology 
can suggest areas in which to invest new research. The review offers new insight to 
researchers as it points toward unexplored regions of engineering education and 
urges educators to incorporate AR into their teaching methods. 
Based on the review of 40 studies, there is an increase in the research studies 
during the last few years. The primary education level of the target group is higher 
education, and more specifically first-year engineering students as the development 
of spatial skills is important for their future studies and career. 
AR offers unique advantages to the learners, such as the improvement of their 
spatial ability, the better understanding of the topic and gradually the improved 
academic performance and motivation. When it comes to pedagogical contribu­
tions, AR is shown to attract students’ interest, enhances enjoyability, and increases 
their engagement in the teaching and learning process. 
The development of AR applications is transitioning from desktop-based to 
mobile ones, especially with the global ease of use of mobile phones and tablets. 
The majority of AR applications, reviewed in this chapter, are marker-based and 
their content is 3D models, as 3D modeling is shown to be very effective when it 
comes to improving spatial visualization skills. However, none of them considered 
the inclusion of combined adaptivity or personalization processes, pointing out the 
research interest of the current book. 
References 
1.	E. L. Thorndike, “On the Organization of Intellect.,” Psychol Rev, vol. 28, no. 2, pp. 141–151, 
1921, https://doi.org/10.1037/h0070821. 
2.	C. Spearman, “‘General intelligence,’ objectively determined and measured.,” Am J Psychol, 
vol. 15, pp. 201–293, 1904, https://doi.org/10.2307/1412107. 
3.	A. A. H. E. Koussy, An Investigation Into the Factors in Tests Involving the Visual Perception 
of Space. in British Journal of Psychology. Monograph Supplements. University Press, 1935. 
[Online]. Available: https://books.google.gr/books?id=SZh0tAEACAAJ 
4.	L. L. Thurstone, “Primary mental abilities. Psychometric Monograph 1.” Chicago, IL: Univer. 
of Chicago Press, 1938. 
5.	L. Thurstone, “Some Primary Abilities in Visual Thinking,” Proc Am Philos Soc, vol. 94, no. 
6, pp. 517–521, 1950. 
6.	C. Roca-González, J. Martin-Gutierrez, M. García-Dominguez, and M. del C. M. Carrodeguas, 
“Virtual technologies to develop visual-spatial ability in engineering students,” Eurasia 
Journal of Mathematics, Science and Technology Education, vol. 13, no. 2, pp. 441–468, 
2017, https://doi.org/10.12973/eurasia.2017.00625a.
References

42
7.	H.  Gardner, Frames of mind  : the theory of multiple intelligences. New  York: Basic 
Books, 1983. 
8.	M. G. McGee, Human Spatial Abilities: Sources of Sex Differences. in Praeger special stud­
ies. Praeger, 1979. [Online]. Available: https://books.google.gr/books?id=2HgiAAAACAAJ 
9.	M. G. McGee, “Human spatial abilities: Psychometric studies and environmental, genetic, hor­
monal, and neurological influences.,” Psychological Bulletin, vol. 86. American Psychological 
Association, US, pp. 889–918, 1979. https://doi.org/10.1037/0033-­2909.86.5.889. 
10.	M.  C. Linn and A.  C. Petersen, “Emergence and Characterization of Sex Differences in 
Spatial Ability: A Meta-Analysis,” Child Dev, vol. 56, no. 6, pp. 1479–1498, Dec. 1985, 
https://doi.org/10.2307/1130467. 
11.	D. F. Lohman, “Spatial abilities as traits, processes, and knowledge.,” in Advances in the 
psychology of human intelligence, Vol. 4., Hillsdale, NJ, US: Lawrence Erlbaum Associates, 
Inc, 1988, pp. 181–248. 
12.	J. W. Pellegrino and E. B. Hunt, “Cognitive models for understanding and assessing spatial 
abilities,” Intelligence: Reconceptualization and measurement, pp. 203–225, 1991. 
13.	J. B. Carroll, Human cognitive abilities: A survey of factor-analytic studies, no. 1. Cambridge 
University Press, 1993. 
14.	I. Macfarlane. Smith, Spatial ability : its educational and social significance. San Diego, 
Calif.: R.R. Knapp, 1964. 
15.	H. Ault and S. John, “Assessing and Enhancing Visualization Skills of Engineering Students 
in Africa: A Comparative Study,” Engineering Design Graphics Journal, vol. 74, pp. 12–20, 
Jun. 2010. 
16.	S. Hsi, M. Linn, and J. Bell, “The Role of Spatial Reasoning in Engineering and the Design 
of Spatial Instruction,” Journal of Engineering Education, vol. 86, Apr. 1997, https://doi. 
org/10.1002/j.2168-­9830.1997.tb00278.x. 
17.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “PARSAT: Fuzzy logic for 
adaptive spatial ability training in an augmented reality system.,” Computer Science and 
Information Systems. 
18.	C.  Papakostas, C.  Troussas, A.  Krouska, and C.  Sgouropoulou, “Personalization of the 
Learning Path within an Augmented Reality Spatial Ability Training Application Based on 
Fuzzy Weights,” Sensors, vol. 22, no. 18, 2022, https://doi.org/10.3390/s22187059. 
19.	B. W. Field, “A course in spatial visualization,” Journal for Geometry and Graphics, vol. 3, 
no. 2, pp. 201–209, 1999. 
20.	N. Martín-Dorta, J. L. Saorín, and M. Contero, “Development of a fast remedial course to 
improve the spatial abilities of engineering students,” Journal of Engineering Education, vol. 
97, no. 4, pp. 505–513, 2008. 
21.	A. Šafhalter, S. Glodež, A. Šorgo, and M. Ploj Virtič, “Development of spatial thinking abili­
ties in engineering 3D modeling course aimed at lower secondary students,” Int J Technol Des 
Educ, 2020, https://doi.org/10.1007/s10798-­020-­09597-­8. 
22.	R. H. McKim, Experiences in visual thinking. Monterey, Calif.: Brooks/Cole Pub. Co., 1980. 
23.	D. F. Ali, M. Omar, M. Mokhtar, N. Suhairom, A. H. Abdullah, and N. D. A. Halim, “A 
review on augmented reality application in engineering drawing classrooms,” Man India, 
vol. 97, no. 19, pp.  195–204, 2017, [Online]. Available: https://www.researchgate.net/ 
publication/320878073 
24.	T. Serdar, E. S. S. Aziz, S. K. Esche, and C. Chassapis, “Integration of augmented reality into 
the CAD process,” ASEE Annual Conference and Exposition, Conference Proceedings, 2013. 
25.	K.  L. Norman, “Spatial Visualization—A Gateway to Computer-Based Technology:,” 
Journal of Special Education Technology, vol. 12, no. 3, pp.  195–206, 1994, https://doi. 
org/10.1177/016264349401200303. 
26.	S. Sorby, “Developing 3D spatial skills for engineering students,” Australasian Journal of 
Engineering Education, vol. 13, pp. 1–11, Jan. 2007, https://doi.org/10.1080/22054952.200 
7.11463998.
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

43
27.	C. Ferguson, “A Comparison of Instructional Methods for Improving the Spatial-Visualization 
Ability of Freshman Technology Seminar Students,” NA, vol. NA, no. NA. p. NA-NA, 2008. 
doi: NA. 
28.	E. E. Ghiselli, “THE VALIDITY OF APTITUDE TESTS IN PERSONNEL SELECTION,” 
Pers Psychol, vol. 26, no. 4, pp. 461–477, 1973, https://doi.org/10.1111/j.1744-­6570.1973. 
tb01150.x. 
29.	E. Wiebe, T. Branoff, and N. Hartman, Constraint Based, Three Dimensional Solid Modeling 
In An Introductory Engineering Graphics Course: Re Examining The Curriculum. 2001. 
https://doi.org/10.18260/1-­2%2D%2D9035. 
30.	A.  R. Arslan and S.  Dazkir, “Technical Drafting and Mental Visualization in Interior 
Architecture Education,” International Journal for the Scholarship of Teaching and Learning, 
vol. 11, no. 2, 2017, https://doi.org/10.20429/ijsotl.2017.110215. 
31.	M.  Figueiredo, P.  J. S.  Cardoso, J.  M. F.  Rodrigues, and R.  Alves, “Learning Technical 
Drawing with Augmented Reality and Holograms,” Recent Advances in Educational 
Technologies and Methodologies, pp. 1–20, 2014. 
32.	M. Garmendia Mujika, J. Guisasola, and E. Sierra, “First-year engineering students’ difficul­
ties in visualization and drawing tasks,” European Journal of Engineering Education, vol. 32, 
pp. 315–323, Jun. 2007, https://doi.org/10.1080/03043790701276874. 
33.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “On the development of a 
personalized augmented reality spatial ability training mobile application,” in Frontiers in 
Artificial Intelligence and Applications, IOS Press, 2021, pp. V–VI. https://doi.org/10.3233/ 
FAIA210078. 
34.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Modeling the Knowledge of 
Users in an Augmented Reality-Based Learning Environment Using Fuzzy Logic,” in Lecture 
Notes in Networks and Systems, A. Krouska, C. Troussas, and J. Caro, Eds., Cham: Springer 
International Publishing, 2023, pp. 113–123. https://doi.org/10.1007/978-­3-­031-­17601-­2_12. 
35.	T.  Kösa and F.  Karakuş, “The effects of computer-aided design software on engineering 
students’ spatial visualisation skills,” European Journal of Engineering Education, vol. 43, 
pp. 296–308, 2018. 
36.	S.  Strong, R.  Smith, and G.  Communications, “Spatial Visualization: Fundamentals and 
Trends in Engineering Graphics,” Journal of Industrial Technology, vol. 18, Jan. 2002. 
37.	M. Contero, F. Naya, P. Company, J. L. Saorin, and J. Conesa, “Improving visualization skills 
in engineering education,” IEEE Comput Graph Appl, vol. 25, no. 5, pp. 24–31, 2005, https:// 
doi.org/10.1109/MCG.2005.107. 
38.	S.  A. ; L.  Burnett David M., “Effects of academic instruction on spatial visualization,” 
Intelligence, vol. 4, no. 3, pp. 233–242, 1980, https://doi.org/10.1016/0160-­2896(80)90021-­5. 
39.	T. R. Lord, “Enhancing the visuo-spatial aptitude of students,” J Res Sci Teach, vol. 22, no. 5, 
pp. 395–405, 1985, https://doi.org/10.1002/tea.3660220503. 
40.	J. Torner, F. Alpiste, and M. Brigos, “Spatial Ability in Computer-Aided Design Courses,” 
Comput Aided Des Appl, vol. 12, no. 1, pp. 36–44, Jan. 2015, https://doi.org/10.1080/1686436 
0.2014.949572. 
41.	C. Leopold, R. Górska, and S. Sorby, “International experiences in developing visualiza­
tion abilities of engineering students,” Journal for Geometry and Graphics Volume, vol. 5, 
pp. 81–91, Jan. 2001. 
42.	S. A. Sorby, “Improving the Spatial Skills of Engineering Students: Impact on Graphics 
Performance and Retention.,” Engineering Design Graphics Journal, vol. 65, no. 3, 
pp. 31–36, 2001. 
43.	M. Alias, T. R. Black, and D. Gray, “The relationship between spatial visualization ability 
and problem solving in structural design,” World Transaction on Engineering and Technology 
Education, vol. 2, pp. 273–276, Jan. 2003. 
44.	Z. Jeli, B. Popokonstantinovic, and M. Stojicevic, “Usage of 3D Computer Modelling in 
Learning Engineering Graphics,” D. Cvetkovic, Ed., Rijeka: IntechOpen, 2016, p. Ch. 4. 
https://doi.org/10.5772/65217.
References

44
45.	A. Çöltekin et al., “Extended Reality in Spatial Sciences: A Review of Research Challenges 
and Future Directions,” ISPRS International Journal of Geo-Information, vol. 9, no. 7. 2020. 
https://doi.org/10.3390/ijgi9070439. 
46.	R. Azuma, Y. Baillot, R. Behringer, S. Feiner, S. Julier, and B. MacIntyre, “Recent advances 
in augmented reality,” IEEE Comput Graph Appl, vol. 21, no. 6, pp. 34–47, 2001, https://doi. 
org/10.1109/38.963459. 
47.	E. Zaretsky and V. Bar, “Intelligent virtual reality and its impact on spatial skills and aca­
demic achievements,” in The 10th International Conference on Information Systems Analysis 
and Synthesis: ISAS 2004 and International Conference on Cybernetics and Information 
Technologies, Systems and Applications: CITSA, 2004, pp. 107–113. 
48.	P.  Strousopoulos, C.  Troussas, C.  Papakostas, A.  Krouska, and C.  Sgouropoulou, 
“Revolutionizing Agricultural Education with Virtual Reality and Gamification: A Novel 
Approach for Enhancing Knowledge Transfer and Skill Acquisition,” in Novel & Intelligent 
Digital Systems: Proceedings of the 3rd International Conference (NiDS 2023), K. Kabassi, 
P. Mylonas, and J. Caro, Eds., Cham: Springer Nature Switzerland, 2023, pp. 67–80. 
49.	A. Marougkas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Virtual Reality in Education: 
A Review of Learning Theories, Approaches and Methodologies for the Last Decade,” 
Electronics (Basel), vol. 12, no. 13, 2023, https://doi.org/10.3390/electronics12132832. 
50.	A.  Marougkas, C.  Troussas, A.  Krouska, and C.  Sgouropoulou, “A Framework for 
Personalized Fully Immersive Virtual Reality Learning Environments with Gamified Design 
in Education,” 2021. https://doi.org/10.3233/FAIA210080. 
51.	S.  Rokhsaritalemi, A.  Sadeghi-Niaraki, and S.-M.  Choi, “A Review on Mixed Reality: 
Current Trends, Challenges and Prospects,” Applied Sciences, vol. 10, no. 2. 2020. https:// 
doi.org/10.3390/app10020636. 
52.	G.  White, C.  Cabrera, A.  Palade, and S.  Clarke, “Augmented reality in IoT,” Lecture 
Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence 
and Lecture Notes in Bioinformatics), vol. 11434 LNCS, pp. 149–160, 2019, https://doi. 
org/10.1007/978-­3-­030-­17642-­6_13. 
53.	C.  Papakostas, C.  Troussas, P.  Douros, M.  Poli, and C.  Sgouropoulou, “CoMoPAR: A 
Comprehensive Conceptual Model for Designing Personalized Augmented Reality Systems 
in Education,” in Novel & Intelligent Digital Systems: Proceedings of the 3rd International 
Conference (NiDS 2023), K. Kabassi, P. Mylonas, and J. Caro, Eds., Cham: Springer Nature 
Switzerland, 2023, pp. 67–79. 
54.	M. Akçayır and G. Akçayır, “Advantages and challenges associated with augmented reality 
for education: A systematic review of the literature,” Educ Res Rev, vol. 20, pp. 1–11, Feb. 
2017, https://doi.org/10.1016/j.edurev.2016.11.002. 
55.	M.  Karakus, A.  Ersozlu, and A.  Clark, “Augmented Reality Research in Education: A 
Bibliometric Study,” Eurasia Journal of Mathematics, Science and Technology Education, 
vol. 15, no. 10, 2019, https://doi.org/10.29333/ejmste/103904. 
56.	R. M. Yilmaz, “Augmented Reality Trends in Education between 2016 and 2017 Years,” State 
of the Art Virtual Reality and Augmented Reality Knowhow, 2018, https://doi.org/10.5772/ 
intechopen.74943. 
57.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Exploring Users’ Behavioral 
Intention to adopt Mobile Augmented Reality in education through an extended Technology 
Acceptance Model,” Int J Hum Comput Interact, vol. 39, no. 6, pp. 1294–1302, 2023, https:// 
doi.org/10.1080/10447318.2022.2062551. 
58.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Exploration of Augmented 
Reality in Spatial Abilities Training: A Systematic Literature Review for the Last Decade,” 
Informatics in Education, vol. 20, no. 1, pp.  107–130, 2021, https://doi.org/10.15388/ 
infedu.2021.06. 
59.	A. Marougkas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Virtual Reality in Education: 
Reviewing Different Technological Approaches and Their Implementations,” in Novel & 
Intelligent Digital Systems: Proceedings of the 2nd International Conference (NiDS 2022), 
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

45
A. Krouska, C. Troussas, and J. Caro, Eds., Cham: Springer International Publishing, 2023, 
pp. 77–83. 
60.	M. Iakovidis, C. Papakostas, C. Troussas, and C. Sgouropoulou, “Empowering Responsible 
Digital Citizenship Through an Augmented Reality Educational Game,” in Novel & Intelligent 
Digital Systems: Proceedings of the 3rd International Conference (NiDS 2023), K. Kabassi, 
P. Mylonas, and J. Caro, Eds., Cham: Springer Nature Switzerland, 2023, pp. 31–39. 
61.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Measuring User Experience, 
Usability and Interactivity of a Personalized Mobile Augmented Reality Training System,” 
Sensors, vol. 21, no. 11, p. 3888, Jun. 2021, https://doi.org/10.3390/s21113888. 
62.	N. Pellas and I. Kazanidis, “Developing and assessing augmented reality applications for 
mathematics with trainee instructional media designers: An exploratory study on user experi­
ence,” Journal of Universal Computer Science, vol. 25, no. 5, pp. 489–514, 2019. 
63.	A.  Kapetanaki, A.  Krouska, C.  Troussas, and C.  Sgouropoulou, “A Novel Framework 
Incorporating Augmented Reality and Pedagogy for Improving Reading Comprehension in 
Special Education,” in Novelties in Intelligent Digital Systems, IOS Press, 2021, pp. 105–110. 
64.	A.  Kapetanaki, A.  Krouska, C.  Troussas, and C.  Sgouropoulou, “Exploiting Augmented 
Reality Technology in Special Education: A Systematic Review,” Computers, vol. 11, no. 10, 
2022, https://doi.org/10.3390/computers11100143. 
65.	P. Kourouthanassis, C. Boletsis, C. Bardaki, and D. Chasanidou, “Tourists responses to mobile 
augmented reality travel guides: The role of emotions on adoption behavior,” Pervasive Mob 
Comput, vol. 18, pp. 71–87, 2015, https://doi.org/10.1016/j.pmcj.2014.08.009. 
66.	T. Bekus, “THE APPLICATION OF AUGMENTED REALITY IN MARKETING,” Zeszyty 
Naukowe Wyższej Szkoły Humanitas Zarządzanie, vol. 19, pp. 279–296, Oct. 2018, https:// 
doi.org/10.5604/01.3001.0013.0068. 
67.	R. Monterubbianesi et al., “Augmented, Virtual and Mixed Reality in Dentistry: A Narrative 
Review on the Existing Platforms and Future Challenges,” Applied Sciences, vol. 12, no. 2, 
2022, https://doi.org/10.3390/app12020877. 
68.	C. Rodríguez-Abad, J.-C. Fernández-de-la-Iglesia, A.-E. Martínez-Santos, and R. Rodríguez-­
González, “A Systematic Review of Augmented Reality in Health Sciences: A Guide to 
Decision-Making in Higher Education,” Int J Environ Res Public Health, vol. 18, p. 4262, 
Apr. 2021, https://doi.org/10.3390/ijerph18084262. 
69.	J. Buchner, K. Buntins, and M. Kerres, “The impact of augmented reality on cognitive load 
and performance: A systematic review,” J Comput Assist Learn, vol. 38, no. 1, pp. 285–303, 
Feb. 2022, https://doi.org/10.1111/jcal.12617. 
70.	G. Makransky and G. B. Petersen, “The Cognitive Affective Model of Immersive Learning 
(CAMIL): a Theoretical Research-Based Model of Learning in Immersive Virtual 
Reality,” Educ Psychol Rev, vol. 33, no. 3, pp.  937–958, 2021, https://doi.org/10.1007/ 
s10648-­020-­09586-­2. 
71.	J. Yu, A. R. Denham, and E. Searight, “A systematic review of augmented reality game-based 
Learning in STEM education,” Educational technology research and development, 2022, 
https://doi.org/10.1007/s11423-­022-­10122-­y. 
72.	N.  Khan et  al., “An Adaptive Game-Based Learning Strategy for Children Road Safety 
Education and Practice in Virtual Space,” Sensors, vol. 21, no. 11, 2021, https://doi. 
org/10.3390/s21113661. 
73.	D.-I. Han, M. C. tom Dieck, and T. Jung, “User experience model for augmented reality appli­
cations in urban heritage tourism,” Journal of Heritage Tourism, vol. 13, no. 1, pp. 46–61, 
Jan. 2018, https://doi.org/10.1080/1743873X.2016.1251931. 
74.	H. Kim, T. Matuszka, J.-I. Kim, J. Kim, and W. Woo, “Ontology-based mobile augmented 
reality in cultural heritage sites: information modeling and user study,” Multimed Tools Appl, 
vol. 76, no. 24, pp. 26001–26029, 2017, https://doi.org/10.1007/s11042-­017-­4868-­6. 
75.	P. Strousopoulos, C. Papakostas, C. Troussas, A. Krouska, P. Mylonas, and C. Sgouropoulou, 
“SculptMate: Personalizing Cultural Heritage Experience Using Fuzzy Weights,” in Adjunct 
Proceedings of the 31st ACM Conference on User Modeling, Adaptation and Personalization, 
References

46
in UMAP ’23 Adjunct. New York, NY, USA: Association for Computing Machinery, 2023, 
pp. 397–407. https://doi.org/10.1145/3563359.3596667. 
76.	C. Troussas, C. Papakostas, A. Krouska, P. Mylonas, and C. Sgouropoulou, “Personalized 
Feedback Enhanced by Natural Language Processing in Intelligent Tutoring Systems,” 
in Augmented Intelligence and Intelligent Tutoring Systems, C. Frasson, P. Mylonas, and 
C.  Troussas, Eds., Cham: Springer Nature Switzerland, 2023, pp.  667–677. https://doi. 
org/10.1007/978-­3-­031-­32883-­1_58. 
77.	S.  S. Alam, S.  Susmit, C.-Y.  Lin, M.  Masukujjaman, and Y.-H.  Ho, “Factors Affecting 
Augmented Reality Adoption in the Retail Industry,” Journal of Open Innovation: Technology, 
Market, and Complexity, vol. 7, no. 2, 2021, https://doi.org/10.3390/joitmc7020142. 
78.	F. de Pace, F.  Manuri, and A.  Sanna, “Augmented Reality in Industry 4.0,” American 
Journal of Computer Science and Information Technology, vol. 06, Jan. 2018, https://doi. 
org/10.21767/2349-­3917.100017. 
79.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “User acceptance of aug­
mented reality welding simulator in engineering training,” Educ Inf Technol (Dordr), vol. 27, 
no. 1, pp. 791–817, Jan. 2022, https://doi.org/10.1007/s10639-­020-­10418-­7. 
80.	K. Obara, “AUGMENTED REALITY AND MARKETING,” Mar. 2021. 
81.	K. Mitrovic, N. Novakovic, J. Spajić, and I. Cosic, “Augmented Reality in Marketing – State 
of Art,” 2021, pp. 566–575. https://doi.org/10.2507/32nd.daaam.proceedings.081. 
82.	Z. Jian, “Teaching of Engineering Drawing in the 21st century,” in 2011 Second International 
Conference on Mechanic Automation and Control Engineering, 2011, pp. 1713–1715. https:// 
doi.org/10.1109/MACE.2011.5987287. 
83.	Z. Kanetaki, C. Stergiou, C. Troussas, and C. Sgouropoulou, “Developing Novel Learning 
Spaces Through Social Media Channels for Sustainable CAD Engineering Education,” in 
Novel & Intelligent Digital Systems: Proceedings of the 2nd International Conference (NiDS 
2022), A. Krouska, C. Troussas, and J. Caro, Eds., Cham: Springer International Publishing, 
2023, pp. 359–371. 
84.	A. Sideris, C. Troussas, A. Krouska, and C. Sgouropoulou, “A 2D Platform Game Offering 
Personalized Guidance to Players to Promote Environmental Awareness,” in Novel & 
Intelligent Digital Systems: Proceedings of the 2nd International Conference (NiDS 2022), 
A. Krouska, C. Troussas, and J. Caro, Eds., Cham: Springer International Publishing, 2023, 
pp. 134–146. 
85.	M. Go et al., “Evaluating digital mathematical games in improving the basic mathematical 
skills of university students,” Int J Math Educ Sci Technol, pp. 1–23, Jul. 2022, https://doi. 
org/10.1080/0020739X.2022.2089604. 
86.	Z. Kanetaki et al., “Acquiring, Analyzing and Interpreting Knowledge Data for Sustainable 
Engineering Education: An Experimental Study Using YouTube,” Electronics (Basel), vol. 
11, no. 14, 2022, https://doi.org/10.3390/electronics11142210. 
87.	O. Huerta et al., “A design-based approach to enhancing technical drawing skills in design 
and engineering education using VR and AR tools,” VISIGRAPP 2019  – Proceedings 
of the 14th International Joint Conference on Computer Vision, Imaging and Computer 
Graphics Theory and Applications, vol. 3, no. March, pp.  306–313, 2019, https://doi. 
org/10.5220/0007566003060313. 
88.	M. Voronina, Z. Tretyakova, E. Krivonozhkina, S. Buslaev, and G. Sidorenko, “Augmented 
Reality in Teaching Descriptive Geometry, Engineering and Computer Graphics – Systematic 
Review and Results of the Russian Teachers’ Experience,” Eurasia Journal of Mathematics, 
Science and Technology Education, vol. 15, no. 12, 2019, https://doi.org/10.29333/ 
ejmste/113503. 
89.	P. H. Diao and N. J. Shih, “Trends and research issues of augmented reality studies in archi­
tectural and civil engineering education-A review of academic journal publications,” Applied 
Sciences (Switzerland), vol. 9, no. 9, 2019, https://doi.org/10.3390/app9091840.
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

47
90.	J. Garzón, J. Pavón, and S. Baldiris, “Systematic review and meta-analysis of augmented 
reality in educational settings,” Virtual Real, vol. 23, no. 4, pp. 447–459, 2019, https://doi. 
org/10.1007/s10055-­019-­00379-­9. 
91.	C.  Tuker, “Training Spatial Skills with Virtual Reality and Augmented Reality,” in 
Encyclopedia of Computer Graphics and Games, N. Lee, Ed., Cham: Springer International 
Publishing, 2018, pp. 1–9. https://doi.org/10.1007/978-­3-­319-­08234-­9_173-­1. 
92.	B. S. Bloom, M. D. Engelhart, E. J. Furst, W. H. Hill, and D. R. Krathwohl, “Handbook I: 
cognitive domain,” New York: David McKay, 1956. 
93.	A. LW et al., A Taxonomy for Learning, Teaching, and Assessing: A Revision of Bloom’s 
Taxonomy of Educational Objectives. 2001. 
94.	J. H. McMillan, Classroom assessment: Principles and practice for effective standards-based 
instruction. Pearson, 2014. 
95.	J. B. Biggs and K. F. Collis, Evaluating the Quality of Learning: The SOLO Taxonomy (struc­
ture of the Observed Learning Outcome). in Educational psychology. Academic Press, 1982. 
96.	R. el Mouhayar, Levels of generalization and the SOLO taxonomy. 2018. 
97.	J. Biggs, “Teaching for Quality Learning at University. Society for Research into Higher 
Education,” The Higher Education Academy.(2008). Groupwork, Retrieved August, vol. 6, 
p. 2008, Jan. 2003. 
98.	B. Kitchenham, “Procedures for Performing Systematic Literature Reviews,” Joint Technical 
Report, Keele University TR/SE-0401 and NICTA TR-0400011T.1, p. 33, 2004. 
99.	K.  BA and S.  Charters, “Guidelines for performing Systematic Literature Reviews in 
Software Engineering,” vol. 2, Jan. 2007. 
100.	J. Bacca-Acosta, S. Baldiris, R. Fabregat, S. Graf, and D. Kinshuk, “Augmented Reality 
Trends in Education: A Systematic Review of Research and Applications,” Educational 
Technology and Society, vol. 17, pp. 133–149, Oct. 2014. 
101.	Y. Goktas et al., “Educational Technology Research Trends in Turkey: A Content Analysis of 
the 2000-2009 Decade,” Jan. 2012. 
102.	M. Omar, D. F. Ali, M. Mokhtar, N. M. Zaid, H. Jambari, and N. H. Ibrahim, “Effects of 
Mobile Augmented Reality (MAR) towards Students’ Visualization Skills when Learning 
Orthographic Projection,” International Journal of Emerging Technologies in Learning 
(iJET), vol. 14, no. 20, p. 106, 2019, https://doi.org/10.3991/ijet.v14i20.11463. 
103.	M. Omar, D. F. Ali, A. N. Nasir, and M. S. Sunar, “AREDApps: Integrating mobile aug­
mented reality in orthographic projection teaching and learning,” International Journal of 
Recent Technology and Engineering, vol. 8, no. 1C2, pp. 821–825, 2019. 
104.	D. N. A. L. E. Phon, M. H. A. Rahman, N. I. Utama, M. B. Ali, N. D. A. Halim, and S. Kasim, 
“The effect of augmented reality on spatial visualization ability of elementary school student,” 
Int J Adv Sci Eng Inf Technol, vol. 9, no. 2, pp. 624–629, 2019, https://doi.org/10.18517/ 
ijaseit.8.5.4971. 
105.	S. Tumkor, “Personalization of engineering education with the mixed reality mobile appli­
cations,” Computer Applications in Engineering Education, vol. 26, no. 5, pp. 1734–1741, 
2018, https://doi.org/10.1002/cae.21942. 
106.	E. G. de Ravé, F. J. Jiménez-Hornero, A. B. Ariza-Villaverde, and J. Taguas-Ruiz, “DiedricAR: 
a mobile augmented reality system designed for the ubiquitous descriptive geometry learn­
ing,” Multimed Tools Appl, vol. 75, no. 16, pp. 9641–9663, 2016, https://doi.org/10.1007/ 
s11042-­016-­3384-­4. 
107.	I. J. Lee, “Using augmented reality to train students to visualize three-dimensional drawings 
of mortise–tenon joints in furniture carpentry,” Interactive Learning Environments, vol. 28, 
no. 7, pp. 930–944, 2020, https://doi.org/10.1080/10494820.2019.1572629. 
108.	I. J. Lee, T. C. Hsu, T. L. Chen, and M. C. Zheng, “The application of ar technology to spatial 
skills learning in carpentry training,” International Journal of Information and Education 
Technology, vol. 9, no. 1, pp. 56–60, 2019, https://doi.org/10.18178/ijiet.2019.9.1.1173.
References

48
109.	B. Özçakır and E. Çakıroğlu, “Fostering spatial abilities of middle school students through 
augmented reality: Spatial strategies,” Educ Inf Technol (Dordr), vol. 27, no. 3, pp. 2977–3010, 
2022, https://doi.org/10.1007/s10639-­021-­10729-­3. 
110.	B. Ozcakir and E. Cakiroglu, “An augmented reality learning toolkit for fostering spatial 
ability in mathematics lesson: Design and development,” European Journal of Science 
and Mathematics Education, vol. 9, no. 4, pp.  145–167, 2021, https://doi.org/10.30935/ 
SCIMATH/11204. 
111.	J.  Weidinger, S.  Schlauderer, and S.  Overhage, “Information Technology to the 
Rescue? Explaining the Acceptance of Emergency Response Information Systems by 
Firefighters,” IEEE Trans Eng Manag, vol. PP, pp. 1–15, Jan. 2021, https://doi.org/10.1109/ 
TEM.2020.3044720. 
112.	D.  F. Ali et  al., “The Use of Augmented Reality Learning Environment in Enhancing 
Students’ Mental Rotation Skills,” Adv Sci Lett, vol. 24, no. 5, pp. 3705–3708, 2018, https:// 
doi.org/10.1166/asl.2018.11470. 
113.	L.  Medina Herrera, J.  Castro Pérez, and S.  Juárez Ordóñez, “Developing spatial mathe­
matical skills through 3D tools: augmented reality, virtual environments and 3D printing,” 
International Journal on Interactive Design and Manufacturing (IJIDeM), vol. 13, no. 4, 
pp. 1385–1399, Dec. 2019, https://doi.org/10.1007/s12008-­019-­00595-­2. 
114.	E. T. Gün and B. Atasoy, “The effects of augmented reality on elementary school students’ 
spatial ability and academic achievement,” Egitim ve Bilim, vol. 42, no. 191, pp. 31–51, 2017, 
https://doi.org/10.15390/EB.2017.7140. 
115.	D.  Sumardani, E.  R. Sipayung, and P.-S.  Chiu, “Enabling spatial thinking through an 
augmented reality for teaching crystal structure,” Innovations in Education and Teaching 
International, 2022, https://doi.org/10.1080/14703297.2022.2076716. 
116.	J.  Martín-Gutiérrez, J.  Luís Saorín, M.  Contero, M.  Alcañiz, D.  C. Pérez-López, and 
M. Ortega, “Design and validation of an augmented book for spatial abilities development in 
engineering students,” Computers and Graphics (Pergamon), vol. 34, no. 1, pp. 77–91, 2010, 
https://doi.org/10.1016/j.cag.2009.11.003. 
117.	S. Habig, “Who can benefit from augmented reality in chemistry? Sex differences in solv­
ing stereochemistry problems using augmented reality,” British Journal of Educational 
Technology, vol. 51, no. 3, pp. 629–644, May 2020, https://doi.org/10.1111/bjet.12891. 
118.	Z. Gecu-Parmaksiz and Ö. Delialioğlu, “The effect of augmented reality activities on improv­
ing preschool children’s spatial skills,” Interactive Learning Environments, vol. 0, no. 0, 
pp. 1–14, 2018, https://doi.org/10.1080/10494820.2018.1546747. 
119.	H. C. ; M.-G. Gómez-Tone Jorge; Anci, Lili Valencia; Luis, Carlos Efrén Mora, “International 
Comparative Pilot Study of Spatial Skill Development in Engineering Students through 
Autonomous Augmented Reality-Based Training,” Symmetry (Basel), vol. 12, no. 9, 
pp. 1401-NA, 2020, https://doi.org/10.3390/sym12091401. 
120.	J. M. Gutiérrez, M. G. Domínguez, and C. R. González, “Using 3D virtual technologies to 
train spatial skills in engineering,” International Journal of Engineering Education, vol. 31, 
no. 1, pp. 323–334, 2015. 
121.	N.  Kaur, R.  Pathan, U.  Khwaja, and S.  Murthy, “GeoSolvAR: Augmented reality based 
solution for visualizing 3D Solids,” Proceedings – IEEE 18th International Conference on 
Advanced Learning Technologies, ICALT 2018, pp. 372–376, 2018, https://doi.org/10.1109/ 
ICALT.2018.00093. 
122.	C. Tuker and M. S. Fine, Training Spatial Skills with, no. January. 2018. 
123.	M. A. Omar Dayana Farzeeha; Mokhtar, Mahani; Zaid, Norasykin Mohd; Jambari, Hanifah; 
Ibrahim, Nor Hasniza, “Effects of Mobile Augmented Reality (MAR) towards Students’ 
Visualization Skills when Learning Orthographic Projection,” International Journal of 
Emerging Technologies in Learning (iJET), vol. 14, no. 20, pp. 106–119, 2019, https://doi. 
org/10.3991/ijet.v14i20.11463. 
124.	J. Bell et al., “A Study of Augmented Reality for the Development of Spatial Reasoning 
Ability,” Jun. 2017. https://doi.org/10.18260/1-­2%2D%2D27831.
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

49
125.	Y.  C. C.  Chen Hung-Lin; Hung, Wei-Han; Kang, Shih-Chung, “Use of Tangible and 
Augmented Reality Models in Engineering Graphics Courses,” Journal of Professional 
Issues in Engineering Education and Practice, vol. 137, no. 4, pp. 267–276, 2011, https:// 
doi.org/10.1061/(asce)ei.1943-­5541.0000078. 
126.	M.  Omar, D.  Farzeeha, and M.  Mokhtar, “USING AREDKIT TO IMPROVE SPATIAL 
VISUALIZATION SKILLS FOR ORTHOGRAPHIC PROJECTION,” 2018. 
127.	D. F. Ali, M. Omar, N. H. Ibrahim, J. Surif, M. Ali, and S. Ismail, “Overcoming the problems 
faced by student’s in learning engineering drawing with the implementation of augmented 
reality learning environment,” Man India, vol. 97, no. 17, pp. 147–159, 2017. 
128.	A. Krouska, C. Troussas, and C. Sgouropoulou, “Mobile game-based learning as a solu­
tion in COVID-19 era: Modeling the pedagogical affordance and student interactions,” 
Educ Inf Technol (Dordr), vol. 27, no. 1, pp.  229–241, 2022, https://doi.org/10.1007/ 
s10639-­021-­10672-­3. 
129.	J. Dorribo-Camba and M. Contero, “Incorporating augmented reality content in engineer­
ing design graphics materials,” Proceedings  – Frontiers in Education Conference, FIE, 
pp. 35–40, 2013, https://doi.org/10.1109/FIE.2013.6684784. 
130.	T. Chandrasekera and S. Y. Yoon, “Adopting augmented reality in design communication: 
Focusing on improving spatial abilities,” International Journal of Architectonic, Spatial, and 
Environmental Design, vol. 9, no. 1, pp. 1–14, 2015, https://doi.org/10.18848/2325-­1662/ 
CGP/v09i01/38384. 
131.	Z.  Veide, V.  Strozheva, and M.  Dobelis, “Application of Augmented Reality for teach­
ing Descriptive Geometry and Engineering Graphics Course to First-Year Students,” 
Joint International Conference on Engineering Education & International Conference on 
Information Technology, pp. 158–164, 2014. 
132.	A. Buchori, P. Setyosari, I. Wayan Dasna, and S. Ulfa, “Mobile augmented reality media 
design with waterfall model for learning geometry in college,” International Journal of 
Applied Engineering Research, vol. 12, no. 13, pp. 3773–3780, 2017. 
133.	J. Kim and J. Irizarry, “Assessing the effectiveness of augmented reality on the spatial skills of 
postsecondary construction management students in the U.S.,” in ISARC 2017 – Proceedings 
of the 34th International Symposium on Automation and Robotics in Construction, 2017, 
pp. 173–180. https://doi.org/10.22260/isarc2017/0023. 
134.	M. Contero, J. M. Gomis, F. Naya, F. Albert, and J. Martin-Gutierrez, “Development of an 
augmented reality based remedial course to improve the spatial ability of engineering stu­
dents,” Proceedings – Frontiers in Education Conference, FIE, 2012, https://doi.org/10.1109/ 
FIE.2012.6462312. 
135.	F. del Cerro Velázquez and G.  Morales Méndez, “Application in Augmented Reality for 
Learning Mathematical Functions: A Study for the Development of Spatial Intelligence in 
Secondary Education Students,” Mathematics, vol. 9, no. 4, p. 369, Feb. 2021, https://doi. 
org/10.3390/math9040369. 
136.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Enriching Mobile Learning Software with 
Interactive Activities and Motivational Feedback for Advancing Users’ High-Level Cognitive 
Skills,” Computers, vol. 11, no. 2, 2022, https://doi.org/10.3390/computers11020018. 
137.	F. Giannakas, C. Troussas, A. Krouska, C. Sgouropoulou, and I. Voyiatzis, “XGBoost and 
Deep Neural Network Comparison: The Case of Teams’ Performance,” in Intelligent Tutoring 
Systems, A. I. Cristea and C. Troussas, Eds., Cham: Springer International Publishing, 2021, 
pp. 343–349. 
138.	A. Krouska, C. Troussas, and C. Sgouropoulou, “Fuzzy Logic for Refining the Evaluation 
of Learners’ Performance in Online Engineering Education,” European Journal of 
Engineering Research and Science, vol. 4, pp. 50–56, Jun. 2019, https://doi.org/10.24018/ 
ejers.2019.4.6.1369. 
139.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Towards a Reference Model to Ensure the 
Quality of Massive Open Online Courses and E-Learning,” in Brain Function Assessment 
References

50
in Learning, C.  Frasson, P.  Bamidis, and P.  Vlamos, Eds., Cham: Springer International 
Publishing, 2020, pp. 169–175. 
140.	A.  Marougkas, C.  Troussas, A.  Krouska, and C.  Sgouropoulou, “How personalized and 
effective is immersive virtual reality in education? A systematic literature review for the last 
decade,” Multimed Tools Appl, 2023, https://doi.org/10.1007/s11042-­023-­15986-­7. 
141.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Dynamic Detection of Learning Modalities 
Using Fuzzy Logic in Students’ Interaction Activities,” in Intelligent Tutoring Systems, 
V. Kumar and C. Troussas, Eds., Cham: Springer International Publishing, 2020, pp. 205–213. 
142.	A. Krouska, C. Troussas, and C. Sgouropoulou, “A novel group recommender system for 
domain-independent decision support customizing a grouping genetic algorithm,” User 
Model User-adapt Interact, 2023, https://doi.org/10.1007/s11257-­023-­09360-­3. 
143.	A. Krouska, C. Troussas, K. Kabassi, and C. Sgouropoulou, “An Empirical Investigation of 
User Acceptance of Personalized Mobile Software for Sustainability Education,” Int J Hum 
Comput Interact, pp. 1–8, Aug. 2023, https://doi.org/10.1080/10447318.2023.2241614. 
144.	Roland. Guay, Purdue spatial visualization test. [West Layfette, Ind.]: Purdue University, 1976. 
145.	Y.  Maeda, S.  Y. Yoon, G.  Kim-Kang, and P.  K. Imbrie, “Psychometric properties of the 
revised PSVT:R for measuring First Year Engineering students’ spatial ability,” International 
Journal of Engineering Education, vol. 29, no. 3, pp. 763–776, 2013. 
146.	S. G. Vandenberg and A. R. Kuse, “Mental rotations, a group test of three-dimensional spatial 
visualization,” Percept Mot Skills, vol. 47, no. 2, pp. 599–604, 1978, https://doi.org/10.2466/ 
pms.1978.47.2.599. 
147.	D. F. Ali, M. Omar, H. Mohamed, N. M. Zaid, M. Mokhtar, and A. H. Abdullah, “Application 
of Augmented Reality Learning Environment in Enhancing Students’ Mental Cutting Skills 
and Mental Folding Skills,” Adv Sci Lett, vol. 24, no. 5, pp. 3701–3704, 2018, https://doi. 
org/10.1166/asl.2018.11469. 
148.	C. Quaiser-Pohl, “The Mental Cutting Test ‘Schnitte’ and the Picture Rotation Test-Two New 
Measures to Assess Spatial Ability,” Int J Test, vol. 3, no. 3, pp. 219–231, Sep. 2003, https:// 
doi.org/10.1207/S15327574IJT0303_2. 
149.	M.  Omar, D.  Farzeeha, and M.  Mokhtar, “USING AREDKIT TO IMPROVE SPATIAL 
VISUALIZATION SKILLS FOR USING AREDKIT TO IMPROVE SPATIAL 
VISUALIZATION,” 2018.
2  Review of the Literature on AI-Enhanced Augmented Reality in Education

51
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024 
C. Papakostas et al., Special Topics in Artificial Intelligence and Augmented 
Reality, Cognitive Technologies, https://doi.org/10.1007/978-3-031-52005-1_3
Chapter 3 
AI-Driven and SOLO-Based Domain 
Knowledge Modeling in PARSAT AR 
Software 
Abstract  This chapter of this book centers on the enrichment of the domain knowl­
edge model through the incorporation of the Structure of Observed Learning 
Outcomes (SOLO) taxonomy. It investigates the correlation between the domain 
knowledge model and the SOLO taxonomy, offering practical instances of learning 
tasks aligned with each SOLO level. The “Overview” section introduces the chap­
ter’s purpose, emphasizing the significance of aligning learning activities with 
SOLO-defined cognitive levels. The “Domain Model” section outlines the model’s 
objectives and relevance in spatial ability training, highlighting specific knowledge 
areas targeted in the mobile training system. In the “Domain Knowledge alongside 
SOLO Taxonomy” section, the integration of the SOLO taxonomy into the domain 
model is explored. This section underscores the importance of gradually developing 
students’ spatial ability through scaffolded learning experiences. The “Examples of 
Learning Activities of Each SOLO Level” section furnishes detailed examples of 
learning activities spanning from prestructural to extended abstract SOLO levels. 
These examples illustrate the practical application of the SOLO taxonomy within 
the domain knowledge model. The “Summary” section concludes by summarizing 
key points, highlighting the integration of the SOLO taxonomy as a scaffolding 
mechanism to enhance spatial ability training. This chapter serves as the foundation 
for subsequent chapters, which delve into the implementation and evaluation of the 
mobile training system. 
3.1  Overview 
In this chapter, the training system’s domain knowledge is presented, considering 
the Structure of Observed Learning Outcomes (SOLO) taxonomy. The content of 
the domain model [1, 2] is a critical component of the application’s structure, 
whereas the combination of the learning theory with adaptive learning activities 
[3–6] enhances the students’ motivation and improves their learning outcome [7–17].

52
3.2  Domain Model 
3.1
3.2.1  Objectives 
The Technical Drawing (TD) objectives, in detail, are as follows:
	 1.	 Recognize the exploratory potential of technical drawing while acknowledging 
the universality of objective language in information transmission and 
comprehension.
	 2.	 Strengthen the skills necessary for them to represent the graphical solutions 
precisely and objectively.
	 3.	 Have a basic understanding of technical drawing so that students can utilize it 
to read and interpret simple designs and artistic creations as well as to develop 
well-thought-out solutions to mathematical challenges in both the plane 
and space.
	 4.	 Recognize normalization as the optimum realist for condensing communication 
and giving it a more universal tone.
	 5.	 Include technical drawing tasks in a study area where aesthetic considerations 
are relevant, such as art, architecture, or industrial design.
	 6.	 Recognize and depict shapes in accordance with ISO standards.
	 7.	 Recognize how different approaches enhance the traditional idea of technical 
drawing.
	 8.	 Include the information provided by technical drawing in technological, artis­
tic, or scientific research process.
	 9.	 Encourage method and rationality in sketching, as a way to convey scientific 
and technological concepts.
	10.	 Acquire abilities that enable the expression of graphical solutions with accu­
racy, clarity, and objectivity.
	11.	 Skillfully employ the specialized tools of technical drawing, and pay attention 
to the drawing’s proper execution, as well as the enhancements that various 
graphical styles can provide to the depiction.
	12.	 Master the art of sketching to improve the speed and accuracy while expressing 
graphically.
	13.	 Connect the space to the plane, recognizing the requirement to complete exer­
cises from the activity book.
3  AI-Driven and SOLO-Based Domain Knowledge Modeling in PARSAT AR Software

53
Table 3.1  Domain knowledge 
Level
Topics
Objective 
Reading—perquisition, background 
knowledge, ISO 128-1:2020 general 
principles of graphical representation of 
objects on technical drawings 
Basic
Introduction to 
Technical Drawing 
Identify the most popular 
drawing instruments and 
equipment, along with their 
purposes. 
Drawing 
instruments and 
accessories 
Isometric views 
Introduction to 
orthographic 
projections 
The six principal 
views 
The glass box 
method 
Standard views 
Alignment of the 
views 
Visualization—understanding shapes and 
mentally rotate them in two dimensions 
whilst comparing to a model 
Intermediate
Line types
Accurately and unambiguously 
capture all the geometric 
features of a 3D model 
Line weights 
Creating an 
orthographic 
projection 
Orthographic 
projection drawing 
details 
Basics of 
dimensioning rules 
Dimension types 
Dimension parts 
Dimensioning of 
the views 
Drawing the visualizations 
Advanced
Scaling
Convey all the required 
information that will allow a 
manufacturer to produce the 
designed model 
Types of scaling 
Cutting plane 
Cutting plane line 
Section lining 
Full sections 
Half sections 
Technical symbols
3.2  Domain Model

54
3.3  Domain Knowledge Alongside SOLO Taxonomy 
Several studies have highlighted the broader applicability of the learning theories in 
the design of effective training systems, showcasing their utility in organizing 
domain knowledge, structuring learning activities, and boosting student engage­
ment, thus offering a blueprint for creating more personalized and impactful learn­
ing experiences across various domains [18–23]. SOLO taxonomy was created, 
within a constructivist context, as a tool for teaching students how to use basic 
rubrics to think more thoroughly about their own understanding. In addition to eval­
uation, SOLO is used in the developed system to design the curriculum according to 
the expected level of learning outcomes, which helps in establishing constructive 
alignment. 
The choice of SOLO taxonomy versus the Bloom’s taxonomy was made based 
on the following reasons: 
•	 Bloom’s theory has uncleared hierarchical connection between levels, whereas 
SOLO is based on stages of progressive cognitive complexity 
•	 Bloom’s theory is concerned with knowledge, whereas SOLO is a theory about 
teaching and learning 
•	 While Bloom’s model was not designed to, or could not be used, to compare 
outcomes to each task, SOLO provides task and outcome to be at separate levels 
•	 Aa task’s cognitive complexity and its difficulty can be separated using SOLO 
•	 Each level of SOLO contains clear verb usage, while Bloom’s verb use across 
levels is perplexing. The clarity of verb level is a strong advantage when educa­
tors are planning and writing the learning objectives 
•	 Levels of declarative knowledge and functioning knowledge, including metacog­
nitive reflection, can be examined using SOLO 
•	 Students, even of younger age, can use SOLO to examine their own learning 
outcomes and the learning outcomes of their teammates, since it is rigor­
ously simple 
•	 The SOLO approach teaches students that learning comes from work and strate­
gies, and it is not an innate talent, displaying their individual learning progress 
2 24
­
­
3.2
3  AI-Driven and SOLO-Based Domain Knowledge Modeling in PARSAT AR Software

55
Table 3.2  Learning goals and activities per SOLO level [25, 26] 
SOLO 
level
Learning goal
Learning activities
Description of the activities
Pre-­
structural 
(L0) 
Students get information 
on the subject 
Define concepts 
List items 
Match information 
Name facts 
Introduction to Technical 
Drawing: A history and 
current importance of 
drawing are presented 
Students are asked to 
illustrate the significance of 
drawing by presenting 
applications and reports of 
both good and negative uses 
of the skill 
Uni-­
structural 
(L1) 
Students define, 
recognize, name, sketch, 
reproduce, recite, follow 
simple instructions, 
calculate, reproduce, 
arrange, find 
Identify content to be 
memorized, show 
examples 
Provide disciplinary 
context 
Mnemonics in groups 
Repetition of procedures 
Games 
Repetitive testing and 
matching 
Peer testing (one student 
asks, one answers) 
Setting up a model space in 
CAD software by defining 
limits, grid, snap, layers, and 
object snap 
Video tutorials on standard 
views, views’ alignment, 
completion of activity sheet, 
and setting up the model 
space 
Border creation with a 
completed title block to be 
used for all future drawings, 
and drawing templates with 
all the settings necessary 
saved within it 
Multi-­
structural 
(L2) 
Students describe, list, 
classify, structure, 
enumerate, conduct, 
complete, illustrate, 
solve 
Glossaries of key terms 
with definitions, 
classifications, examples 
to build disciplinary 
vocabulary 
Simple laboratory 
exercises 
Define terms, compare 
to glossary 
Games modelled on 
Trivial Pursuit, Family 
Feud 
Orthographic drawing 
creation 
Lines, layers 
Isometric object drawing 
Video tutorials on linetype, 
lineweight and isometric 
drawing creation of objects 
in the activity
(continued)
3.3  Domain Knowledge Alongside SOLO Taxonomy

56
Table 3.2  (continued)
SOLO 
level
Learning goal
Learning activities
Description of the activities
Relational 
(L3) 
Students relate, analyze, 
compare, integrate, plan, 
construct, implement, 
summarize 
Case studies, 
simulations, and 
complex lab exercises 
Concept maps 
Research projects and 
experiential learning 
cycles 
Application of 
theoretical models 
Reflective journals 
Student seminars and 
debates 
Syndicate groups (each 
group is part of whole) 
Problem-Based 
Learning and Inquiry 
Learning 
Scaling the border and title 
block to fit the orthographic 
drawing 
Dimensioning an 
orthographic drawing 
Video tutorials on basic 
dimensioning rules and parts 
of dimensions 
Filling in a title block, 
including Name, Date, Title, 
Drawing No., and the correct 
scale 
Snapping and Text 
commands 
Extended 
abstract 
(L4) 
Students generalize, 
hypothesize, theorize, 
predict, judge, evaluate, 
assess, predict, reason, 
criticize 
Self-directed projects 
involving research, 
design, application, 
argumentation, 
evaluation 
Case studies involving 
extensive analysis, 
debate, reflection, 
argumentation, 
evaluation, forecasting 
Development of a theory 
or model 
Experiential learning 
cycles 
Problem Based Learning 
and Inquiry learning 
Printing the drawing on 8.5″ 
× 11″ paper (letter size) in 
landscape orientation 
Video tutorial on cutting 
plane, half and full sections 
Printer/plotter settings 
Export/plot an object that has 
been drawn in CAD so it can 
be exported or printed to a 
variety of other applications 
CAD software to create 
objects that are more precise 
and sometimes easier to draw 
in CAD than in other 
software 
3.4  Examples of Learning Activities of Each SOLO Level 
3.1
3.1
­
3  AI-Driven and SOLO-Based Domain Knowledge Modeling in PARSAT AR Software

57
 
In technical drawing, this perspective is usually depicted as a 2D projection of 
the object onto a flat surface, like a sheet of paper. This projection should accurately 
represent the object’s shape and features, as well as any relevant measurements or 
dimensions. 
In order to produce a front view projection of an object, the student must apply 
fundamental principles of graphical representation, which encompass techniques 
like orthographic projection and dimensioning. Orthographic projection entails 
generating various perspectives of the object from different angles, which can sub­
sequently be employed to construct a 2D portrayal of the object from any viewpoint. 
Dimensioning, on the other hand, involves incorporating precise measurements and 
dimensions into the drawing to guarantee the accuracy of the final depiction of 
the object. 
Overall, creating a front view projection of an object in 2D requires careful 
observation, an understanding of technical drawing principles, and attention 
to detail. 
3.2
3.4  Examples of Learning Activities of Each SOLO Level

58
 
3.2
­
In technical drawing, these aspects are usually depicted using orthographic pro­
jection, a method that involves projecting various angles/views of the object onto a 
flat surface. To identify the front view and top view of the object in question, the 
student needs to combine multiple views that are related but handled 
independently. 
To approach this assignment, the student should start by carefully examining the 
available views of the object and identifying the ones that correspond to the front 
and top views. An effective strategy involves searching for visual hints, such as the 
alignment of edges and characteristics, the positioning of critical elements, and any 
3  AI-Driven and SOLO-Based Domain Knowledge Modeling in PARSAT AR Software

59
recognizable patterns or symmetries that can assist in determining the accurate 
perspectives. 
After identifying the correct perspectives, the student will then have to integrate 
them in a manner that faithfully portrays the object’s geometry. This could entail 
modifying the scale or orientation of the perspectives or aligning significant features 
to ensure their proper alignment. 
Overall, identifying the front view and top view of a 3D object in 2D requires 
careful observation, an understanding of technical drawing principles, and the abil­
ity to combine multiple views into a coherent representation of the object’s geometry. 
3.3
 
3.4  Examples of Learning Activities of Each SOLO Level

60
3.3
­
Additionally, students are encouraged to apply critical thinking skills to assess 
the inherent constraints of each perspective and find strategies to make them mutu­
ally reinforcing. As an illustration, the front view may adeptly communicate the 
object’s dimensions in terms of height and width, while the top view might be better 
suited to illustrate its depth and overall form. 
In essence, this assignment demands that students employ higher-order thinking 
skills and contemplate the interplay between diverse pieces of information to con­
struct a more unified and comprehensive grasp of the object. 
The final level of SOLO taxonomy, namely extended abstraction, within the 
domain of technical drawing is achieved by paying detailed attention to more widely 
valid principles. In an extended abstract assignment, the student has to compare the 
given front views, with their corresponding top views and left-side views respec­
tively, and afterwards, relate them integrating into the object’s structure. The stu­
dents would need to demonstrate a deep understanding of the underlying principles 
of technical drawing, including orthographic projection and geometric construction. 
They would be required to elucidate how these principles are employed to generate 
precise and logically consistent depictions of three-dimensional objects in a two-­
dimensional format. 
Furthermore, students would have to put these principles into practice when gen­
erating and fusing front, top, and left-side perspectives of a three-dimensional 
object. This task entails scrutinizing the connections between these various view­
points and recognizing shared characteristics and components that can be harnessed 
to produce a more comprehensive and unified portrayal of the object’s structure 
and form. 
Overall, this assignment requires students to engage in advanced levels of 
abstraction and demonstrate a deep understanding of the underlying principles and 
processes involved in technical drawing. 
3.5  Summary 
This chapter discussed the use of the SOLO taxonomy in developing the training 
system. The SOLO taxonomy is a framework used to categorize learning outcomes 
and can be used to design effective teaching strategies. 
In this context, the chapter outlined how the domain knowledge of the subject of 
the technical drawing course is categorized according to the SOLO taxonomy. The 
3  AI-Driven and SOLO-Based Domain Knowledge Modeling in PARSAT AR Software

61
chapter also discussed how the learning activities within the training system are 
structured and how they align with the SOLO levels to promote effective learning. 
Furthermore, the chapter presented how the use of adaptive learning activities 
based on the SOLO levels can enhance student motivation and improve learning 
outcomes. By providing activities that match the student’s current level of under­
standing, the training system can better support their learning journey and provide a 
more personalized experience. 
Overall, the chapter focused on how the SOLO taxonomy and adaptive learning 
activities can be used to design an effective training system for technical drawing. 
In addition, the incorporated learning theory was explained, providing detailed 
learning goals per SOLO level, as well as a description of each learning activity. 
Finally, examples of assignments, and activities per SOLO level, were presented. 
References 
1.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “On the development of a 
personalized augmented reality spatial ability training mobile application,” in Frontiers in 
Artificial Intelligence and Applications, IOS Press, 2021, pp. V–VI. https://doi.org/10.3233/ 
FAIA210078. 
2.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Exploration of Augmented 
Reality in Spatial Abilities Training: A Systematic Literature Review for the Last Decade,” 
Informatics in Education, vol. 20, no. 1, pp. 107–130, Mar. 2021, https://doi.org/10.15388/ 
infedu.2021.06. 
3.	P. Strousopoulos, C. Papakostas, C. Troussas, A. Krouska, P. Mylonas, and C. Sgouropoulou, 
“SculptMate: Personalizing Cultural Heritage Experience Using Fuzzy Weights,” in Adjunct 
Proceedings of the 31st ACM Conference on User Modeling, Adaptation and Personalization, 
in UMAP ’23 Adjunct. New York, NY, USA: Association for Computing Machinery, 2023, 
pp. 397–407. https://doi.org/10.1145/3563359.3596667. 
4.	C. Troussas, C. Papakostas, A. Krouska, P. Mylonas, and C. Sgouropoulou, “Personalized 
Feedback Enhanced by Natural Language Processing in Intelligent Tutoring Systems,” 
in Augmented Intelligence and Intelligent Tutoring Systems, C.  Frasson, P.  Mylonas, and 
C.  Troussas, Eds., Cham: Springer Nature Switzerland, 2023, pp.  667–677. https://doi. 
org/10.1007/978-­3-­031-­32883-­1_58. 
5.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Exploring Users’ Behavioral 
Intention to Adopt Mobile Augmented Reality in Education through an Extended Technology 
Acceptance Model,” Int J Hum Comput Interact, vol. 39, no. 6, pp. 1294–1302, 2023, https:// 
doi.org/10.1080/10447318.2022.2062551. 
6.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Modeling the Knowledge of 
Users in an Augmented Reality-Based Learning Environment Using Fuzzy Logic,” in Lecture 
Notes in Networks and Systems, A. Krouska, C. Troussas, and J. Caro, Eds., Cham: Springer 
International Publishing, 2023, pp. 113–123. https://doi.org/10.1007/978-­3-­031-­17601-­2_12. 
7.	Z. Kanetaki et al., “Acquiring, Analyzing and Interpreting Knowledge Data for Sustainable 
Engineering Education: An Experimental Study Using YouTube,” Electronics (Basel), vol. 11, 
no. 14, 2022, https://doi.org/10.3390/electronics11142210. 
8.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Enriching Mobile Learning Software with 
Interactive Activities and Motivational Feedback for Advancing Users’ High-Level Cognitive 
Skills,” Computers, vol. 11, no. 2, 2022, https://doi.org/10.3390/computers11020018.
References

62
9.	A. Krouska, C. Troussas, and C. Sgouropoulou, “Fuzzy Logic for Refining the Evaluation 
of Learners’ Performance in Online Engineering Education,” European Journal of 
Engineering Research and Science, vol. 4, pp. 50–56, Jun. 2019, https://doi.org/10.24018/ 
ejers.2019.4.6.1369. 
10.	A.  Marougkas, C.  Troussas, A.  Krouska, and C.  Sgouropoulou, “How personalized and 
effective is immersive virtual reality in education? A systematic literature review for the last 
decade,” Multimed Tools Appl, 2023, https://doi.org/10.1007/s11042-­023-­15986-­7. 
11.	A. Marougkas, C. Troussas, A. Krouska, and C. Sgouropoulou, “A Framework for Personalized 
Fully Immersive Virtual Reality Learning Environments with Gamified Design in Education,” 
2021. https://doi.org/10.3233/FAIA210080. 
12.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Dynamic Detection of Learning Modalities 
Using Fuzzy Logic in Students’ Interaction Activities,” in Intelligent Tutoring Systems, 
V. Kumar and C. Troussas, Eds., Cham: Springer International Publishing, 2020, pp. 205–213. 
13.	A. Krouska, C. Troussas, and C. Sgouropoulou, “A novel group recommender system for 
domain-independent decision support customizing a grouping genetic algorithm,” User Model 
User-adapt Interact, 2023, https://doi.org/10.1007/s11257-­023-­09360-­3. 
14.	C.  Papakostas, C.  Troussas, P.  Douros, M.  Poli, and C.  Sgouropoulou, “CoMoPAR: A 
Comprehensive Conceptual Model for Designing Personalized Augmented Reality Systems 
in Education,” in Novel & Intelligent Digital Systems: Proceedings of the 3rd International 
Conference (NiDS 2023), K. Kabassi, P. Mylonas, and J. Caro, Eds., Cham: Springer Nature 
Switzerland, 2023, pp. 67–79. 
15.	C.  Papakostas, C.  Troussas, A.  Krouska, and C.  Sgouropoulou, “Personalization of the 
Learning Path within an Augmented Reality Spatial Ability Training Application Based on 
Fuzzy Weights,” Sensors, vol. 22, no. 18, 2022, https://doi.org/10.3390/s22187059. 
16.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Towards a Reference Model to Ensure the 
Quality of Massive Open Online Courses and E-Learning,” in Brain Function Assessment 
in Learning, C.  Frasson, P.  Bamidis, and P.  Vlamos, Eds., Cham: Springer International 
Publishing, 2020, pp. 169–175. 
17.	A. Krouska, C. Troussas, K. Kabassi, and C. Sgouropoulou, “An Empirical Investigation of 
User Acceptance of Personalized Mobile Software for Sustainability Education,” Int J Hum 
Comput Interact, pp. 1–8, Aug. 2023, https://doi.org/10.1080/10447318.2023.2241614. 
18.	A. Marougkas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Virtual Reality in Education: 
A Review of Learning Theories, Approaches and Methodologies for the Last Decade,” 
Electronics (Basel), vol. 12, no. 13, 2023, https://doi.org/10.3390/electronics12132832. 
19.	F. Giannakas, C. Troussas, A. Krouska, C. Sgouropoulou, and I. Voyiatzis, “XGBoost and 
Deep Neural Network Comparison: The Case of Teams’ Performance,” in Intelligent Tutoring 
Systems, A. I. Cristea and C. Troussas, Eds., Cham: Springer International Publishing, 2021, 
pp. 343–349. 
20.	M. Iakovidis, C. Papakostas, C. Troussas, and C. Sgouropoulou, “Empowering Responsible 
Digital Citizenship Through an Augmented Reality Educational Game,” in Novel & Intelligent 
Digital Systems: Proceedings of the 3rd International Conference (NiDS 2023), K. Kabassi, 
P. Mylonas, and J. Caro, Eds., Cham: Springer Nature Switzerland, 2023, pp. 31–39. 
21.	P.  Strousopoulos, C.  Troussas, C.  Papakostas, A.  Krouska, and C.  Sgouropoulou, 
“Revolutionizing Agricultural Education with Virtual Reality and Gamification: A Novel 
Approach for Enhancing Knowledge Transfer and Skill Acquisition,” in Novel & Intelligent 
Digital Systems: Proceedings of the 3rd International Conference (NiDS 2023), K. Kabassi, 
P. Mylonas, and J. Caro, Eds., Cham: Springer Nature Switzerland, 2023, pp. 67–80. 
22.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “User acceptance of augmented 
reality welding simulator in engineering training,” Educ Inf Technol (Dordr), vol. 27, no. 1, 
pp. 791–817, Jan. 2022, https://doi.org/10.1007/s10639-­020-­10418-­7. 
23.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Measuring User Experience, 
Usability and Interactivity of a Personalized Mobile Augmented Reality Training System,” 
Sensors, vol. 21, no. 11, p. 3888, Jun. 2021, https://doi.org/10.3390/s21113888.
3  AI-Driven and SOLO-Based Domain Knowledge Modeling in PARSAT AR Software

63
24.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “PARSAT: Fuzzy logic for 
adaptive spatial ability training in an augmented reality system,” Computer Science and 
Information Systems, vol. 20, no. 4, 2023, https://doi.org/10.2298/CSIS230130043P. 
25.	J.  Biggs, “Teaching for Quality Learning at University. Society for Research into Higher 
Education,” The Higher Education Academy.(2008). Groupwork, Retrieved August, vol. 6, 
p. 2008, Jan. 2003. 
26.	J. Biggs and C. Tang, Teaching for Quality Learning at University. in UK Higher Education 
OUP Humanities & Social Sciences Higher Education OUP. McGraw-Hill Education, 2011. 
[Online]. Available: https://books.google.gr/books?id=VC1FBgAAQBAJ
References

65
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024 
C. Papakostas et al., Special Topics in Artificial Intelligence and Augmented 
Reality, Cognitive Technologies, https://doi.org/10.1007/978-3-031-52005-1_4
Chapter 4 
Fuzzy Logic for Modeling the Knowledge 
of Users in PARSAT AR Software 
Abstract  This chapter of the book centers on the application of fuzzy logic for 
modeling students’ knowledge, with a primary focus on enhancing spatial ability 
training through personalized and adaptive learning experiences. The chapter begins 
with an overview, emphasizing the utility of fuzzy logic in capturing and adapting 
to students’ knowledge levels. It underscores the significance of tailoring learning 
activities to individual students’ needs. The core components of the fuzzy logic 
algorithm are elaborated upon in detail. This includes an explanation of how fuzzy 
logic handles imprecise and uncertain knowledge through linguistic variables and 
fuzzy sets. The initialization process is discussed, outlining how the model is set up 
to capture students’ knowledge levels at the outset of training, underscoring the 
importance of accurate initialization for effective adaptation of learning activities. 
The concept of fuzzy sets and their role in representing linguistic variables is 
explored, shedding light on how they measure the degree of membership or fuzzy 
truth values associated with various knowledge levels. The construction of the fuzzy 
rule base is explained, detailing how rules are defined to link linguistic variables and 
their corresponding fuzzy sets to appropriate learning activities, emphasizing the 
rule-based decision-making nature of fuzzy logic. Mamdani’s inference system, a 
crucial component of the fuzzy logic model, is examined in terms of how it com­
bines fuzzy rules to determine adaptive learning activities based on students’ knowl­
edge levels. The process of defuzzification is described, highlighting its role in 
converting fuzzy outputs into actionable decisions. The chapter concludes by illus­
trating how fuzzy weights obtained through the fuzzy logic model are employed for 
real-time adaptation of learning activities, influencing the selection and customiza­
tion of learning materials.

66
4.1  Overview 
In this chapter, the principles of the design of the student model, within the spatial 
ability training platform, are discussed. The model allows steering of the sequence 
of the educational material and the deliverable learning activities, through the incor­
poration of fuzzy logic, quantitative inputs, and fuzzy weights [1, 2]. 
The design of the student model in the spatial ability training platform involves 
the use of fuzzy logic, quantitative inputs, and fuzzy weights to control the sequence 
of educational material and learning activities [3–6]. 
Fuzzy logic is a type of logic that allows for the handling of uncertain or impre­
cise information by using linguistic variables and fuzzy sets to represent qualitative 
concepts. In the context of the spatial ability training platform, fuzzy logic could be 
used to represent the student’s level of understanding or mastery of certain concepts, 
and to make decisions about which educational material or learning activities to 
present next. 
Quantitative inputs refer to numeric data that can be employed as input variables 
for a fuzzy system. In the context of a student model, these inputs could encompass 
measurements like a student’s past performance in educational tasks, the time dedi­
cated to each task, or the student’s self-assessed confidence in their grasp of the 
subject matter. 
Fuzzy weights are used to assign importance or priority to different inputs or 
rules in the fuzzy system. Within the student model framework, fuzzy weights could 
be applied to give priority to specific learning activities, considering their perceived 
significance or alignment with the student’s learning objectives. 
In the exploration of fuzzy logic’s application for personalized spatial ability 
training in this chapter, a significant body of research is referenced, drawing on 
influential works, as well as insightful contributions from the educational [7–21]. 
In general, incorporating fuzzy logic, numerical inputs, and fuzzy weights into 
the construction of the student model can enhance the customization of the learning 
journey for individual students, enabling them to advance through the educational 
content autonomously and with increased control over their progress. 
4.2  Fuzzy Logic Algorithm 
Users of PARSAT are students with various levels of prior knowledge in the field of 
technical drawing, and, as a result, they have different learning needs. The signifi­
cance of the parameter of prior knowledge is in line with [22], as according to them, 
the engineering background of the students should be taken into consideration while 
planning the curriculum and lessons. An AR system, namely PARSAT, was devel­
oped to identify each learner’s knowledge level and instructional needs, in order to 
provide them the most appropriate learning path and content. The student model, 
which may be found in the majority of the latest adaptive educational software [23], 
is responsible for defining the student’s knowledge level.
4  Fuzzy Logic for Modeling the Knowledge of Users in PARSAT AR Software

67
A student model serves as a vital element within adaptive educational software, 
preserving data pertaining to a student’s knowledge, competencies, preferences, and 
educational objectives. This information is leveraged to individualize the learning 
process for each student, encompassing the selection of suitable learning tasks, 
offering tailored feedback, and adjusting the content’s difficulty level to align with 
the student’s skill level. 
In the case of PARSAT, the student model likely takes into account the student’s 
prior knowledge of technical drawing, as well as other factors such as their perfor­
mance on previous learning activities, and their self-reported level of confidence. 
By using this information to personalize the learning experience, PARSAT can help 
each student to progress through the content at their own pace and with a greater 
degree of engagement and motivation. 
The purpose of the student model is to represent the students’ current level of 
knowledge [2, 4, 24], and the system needs to provide the necessary level of custom­
ization on every student’s learning requirement. Other approaches regarding adaptiv­
ity, are those of neural networks, machine learning, fuzzy logic networks, etc., which 
can be utilized to build the student model [19, 25–28]. The backbone of PARSAT’s 
student model is fuzzy logic, which defines the students’ current level of knowledge. 
Fuzzy logic is a type of logic that allows for the handling of uncertain or impre­
cise information by using linguistic variables and fuzzy sets to represent qualitative 
concepts. In the realm of student modeling, fuzzy logic offers a valuable tool for 
depicting a student’s grasp or proficiency in specific topics. 
Fuzzy logic stands out as an ideal choice for portraying intricate, ambiguous, or 
vague systems, especially when it comes to human cognition and the learning pro­
cess. By using fuzzy logic to define the student’s current level of knowledge, 
PARSAT can more accurately assess their learning needs and personalize the learn­
ing experience accordingly. 
PARSAT’s fuzzy system consists of three main parts: a) the part of the linguistic 
variables, b) the part of the membership functions, and c) the rules, which are 
described as follows: 
Linguistic variables: Linguistic variables are used in fuzzy logic to represent 
qualitative concepts. In the context of PARSAT’s student model, linguistic variables 
might be used to represent the student’s level of understanding or mastery of certain 
concepts. 
Membership functions: Membership functions are used to map the linguistic 
variables onto fuzzy sets. A membership function specifies the degree of member­
ship of a particular input value in a given fuzzy set. In the context of PARSAT’s 
student model, membership functions might be used to map the student’s perfor­
mance on a particular learning activity onto a fuzzy set representing their level of 
understanding of the material. 
Rules: Rules are used to define the relationships between the input variables (in 
this case, the linguistic variables and their associated membership functions) and 
the output variable (the student’s level of knowledge). In the context of PARSAT’s 
student model, rules might be used to specify how the student’s performance on dif­
ferent learning activities should be combined to determine their overall level of 
understanding.
4.2  Fuzzy Logic Algorithm

68
The general process of designing a fuzzy system for PARSAT’s student model 
would involve selecting appropriate linguistic variables, designing appropriate 
membership functions to map the input values onto fuzzy sets, and defining appro­
priate rules to combine the input variables and produce the output variable. The 
design process involved iterative refinement and testing to ensure that the fuzzy 
system accurately captures the relevant aspects of the student’s learning needs and 
produces appropriate recommendations for learning activities. This section describes 
the general process of designing the fuzzy system. 
4.3  Initialization Process 
The process of developing the fuzzy system starts by defining the linguistic vari­
ables, which represent, in words, the system’s input and output variables. Each lin­
guistic variable is described by a specific number of linguistic values, while in most 
cases 3–7 terms are enough. 
In most cases, 3–7 linguistic values are sufficient for representing a linguistic 
variable. However, the number and specificity of the linguistic values will depend 
on the particular application and the level of detail required. 
­
4.1
Table 4.1  Linguistic input variables and their ranges 
Linguistic value
Notation
Range (normalized) 
Linguistic variable: Prior Knowledge (PRK)
    Poor
PRK_PR
[0, 0.35]
    Medium
PRK_MDM
[0.30, 0.75]
    Good
PRK_GD
[0.70, 1.00] 
Linguistic variable: Video-based Learning Duration (VLD)
    Short
VLD_SRT
[0, 0.35]
    Normal
VLD_NRML
[0.30, 0.70]
    Long
VLD_LNG
[0.60, 1.00] 
Linguistic variable: Augmented-Reality Interaction Duration (ARID)
    Short
ARID_SRT
[0, 0.60]
    Normal
ARID_NRML
[0.40, 0.80]
    Long
ARID_LNG
[0.70, 1.00] 
Linguistic variable: Number of Errors (NoE)
    Small
NoE_SMLL
[0, 0.40]
    Medium
NoE_MDM
[0.35, 0.65]
    Large
NoE_LRG
[0.60, 1.00]
4  Fuzzy Logic for Modeling the Knowledge of Users in PARSAT AR Software

69
4.4  Fuzzy Sets 
In the second part of the process of developing the fuzzy system for PARSAT’s 
student model, fuzzy sets are determined by mapping all input values into fuzzy 
ones using membership functions. In this case, trapezoidal membership functions 
are used, which are assigned to each linguistic variable. The membership functions 
are formed using straight lines, having the advantage of simplicity. 
­
4.1
Using trapezoidal membership functions, the input variables of PRK, VLD, 
ARID, and NoE can be mapped onto their corresponding linguistic variables with 
fuzzy sets. These fuzzy sets would have degrees of membership between 0 and 1, 
representing the uncertainty and imprecision of the input values. 
Once the input values have been mapped onto fuzzy sets, appropriate rules can 
be defined to combine the input variables and produce the output variable, CLK. The 
rules would take into account the degrees of membership for each fuzzy set and use 
them to determine the appropriate level of knowledge for the student. Based on the 
attained knowledge level, personalized suggestions for learning activities that align 
with the student’s unique requirements and learning preferences can be offered. 
­
4.2 4.3 4.4
4.5
 
4.4  Fuzzy Sets

70
 
 
­
­
4.3
4  Fuzzy Logic for Modeling the Knowledge of Users in PARSAT AR Software

71
 
 
4.4
­
­
4.5
4.4  Fuzzy Sets

72
The outcome produced by the fuzzy system, along with its associated linguistic 
label, represents the student’s existing level of knowledge (referred to as CLK). This 
level can fall into one of the following categories: “Novice” (N), “Beginner” (B), 
“Competent” (C), “Very Good” (VG), “Proficient” (P), or “Expert” (E). Each of 
these levels is defined by specific attributes as follows: 
•	 Novice (N): the student has minimal or textbook knowledge of the educational 
material, without connecting it to the practice. The student has a low level of 
knowledge and understanding of the topic. 
•	 Beginner (B): the student has working knowledge of key aspects of the educa­
tional material. The student has some basic understanding of the topic but lacks 
experience and depth of knowledge. 
•	 Competent (C): the student has good working and background knowledge of the 
educational material. The student possesses a solid grasp of the subject matter 
and is able to execute tasks with a reasonable degree of competence. 
•	 Very Good (VG): the student has very good knowledge of the educational mate­
rial. The student has a strong understanding of the topic and can perform tasks 
with high proficiency 
•	 Proficient (P): The student demonstrates a profound comprehension of the edu­
cational content. They have attained an advanced level of expertise in the subject 
and can execute intricate tasks with a remarkable level of skill. 
•	 Expert (E): the student has authoritative knowledge of the educational material 
and a deep tacit understanding across the domain. 
4.5  Fuzzy Rule Base 
In the fuzzy IF-THEN rules, each input variable is assigned a fuzzy set, and the 
output variable is assigned a fuzzy set as well. The IF-THEN rules define how the 
input variables will affect the output variable. Every rule comprises two compo­
nents: an antecedent (IF) and a consequent (THEN). The antecedent defines the 
circumstances for which the rule is relevant, and the consequent outlines the action 
to be executed when those circumstances are satisfied. 
Professionals with expertise in the field are responsible for crafting these fuzzy 
IF-THEN rules. They leverage their knowledge and experience to determine the 
most suitable rules for the system. These rules undergo testing and refinement over 
time to ensure their accuracy and effectiveness. 
The quantity of rules (r) within the fuzzy system follows an exponential relation­
ship with the number of inputs (m) and the number of linguistic values (w) that each 
input can assume. All four inputs (PRK, VLD, ARID, and NoE) have a constant 
number of three alternative values, so the maximum number of rules is given by Eq. 
(4.1) from [29]: 
	
	
(4.1)
4  Fuzzy Logic for Modeling the Knowledge of Users in PARSAT AR Software

73
4.2
4.2
Example Rule 1: 
IF PRK is PRK_PR AND VLD is VLD_LNG AND ARID is ARID_LNG AND 
NoE is NoE_LRG THEN CLK is N 
This rule (rule 1) is an example of how the PARSAT fuzzy inference system uses 
the input variables (PRK, VLD, ARID, NoE) to classify the student’s current level 
of knowledge (CLK) as “Novice” based on certain conditions. In this case, the rule 
suggests that if the student has poor prior knowledge, spends a long time on video 
tutorials (maybe by replaying them all the time, or constantly pausing and rewind­
ing them) and AR interactions (maybe finding it difficult to conceptualize their 
geometry), and scores a large number of errors, then she/he is likely to be classified 
as a novice student. 
4.6
4.2
Example Rule 2: 
IF PRK is PRK_GD AND VLD is VLD_NRML AND ARID is ARID_NRML 
AND NoE is NoE_SMLL THEN CLK is E 
4.7
Example Rule 3: 
IF PRK is PRK_MDM AND VLD is VLD_NRML AND ARID is ARID_NRML 
AND NoE is NoE_SMLL THEN CLK is P 
­
4.8
­
The next two rules (rule 4 and rule 5) consider the various inputs that all contrib­
ute to the knowledge level rating of the student being a beginner.
4.5  Fuzzy Rule Base

74
Table 4.2  Fuzzy rules 
PRK
VLD
ARID
NoE
CLK
PRK
VLD
ARID
NoE
CLK 
1 Poor
Short
Short
Small
VG
41 Medium 
Normal Normal Medium 
VG 
2 Poor
Short
Normal Small
VG
42 Medium 
Normal Long
Medium 
VG 
3 Poor
Short
Long
Small
C
43 Medium 
Long
Short
Medium 
C 
4 Poor
Normal Short
Small
C
44 Medium 
Long
Normal Medium 
VG 
5 Poor
Normal Normal Small
VG
45 Medium 
Long
Long
Medium 
C 
6 Poor
Normal Long
Small
VG
46 Medium 
Short
Short
Large
B 
7 Poor
Long
Short
Small
VG
47 Medium 
Short
Normal Large
C 
8 Poor
Long
Normal Small
C
48 Medium 
Short
Long
Large
B 
9 Poor
Long
Long
Small
C
49 Medium 
Normal Short
Large
B 
10 Poor
Short
Short
Medium 
VG
50 Medium 
Normal Normal Large
C 
11 Poor
Short
Normal Medium 
VG
51 Medium 
Normal Long
Large
B 
12 Poor
Short
Long
Medium 
C
52 Medium 
Long
Short
Large
C 
13 Poor
Normal Short
Medium 
VG
53 Medium 
Long
Normal Large
C 
14 Poor
Normal Normal Medium 
VG
54 Medium 
Long
Long
Large
B 
15 Poor
Normal Long
Medium 
C
55 Good
Short
Short
Small
E 
16 Poor
Long
Short
Medium 
C
56 Good
Short
Normal Small
E 
17 Poor
Long
Normal Medium 
VG
57 Good
Short
Long
Small
E 
18 Poor
Long
Long
Medium 
C
58 Good
Normal Short
Small
E 
19 Poor
Short
Short
Large
N
59 Good
Normal Normal Small
E 
20 Poor
Short
Normal Large
N
60 Good
Normal Long
Small
E 
21 Poor
Short
Long
Large
N
61 Good
Long
Short
Small
E 
22 Poor
Normal Short
Large
N
62 Good
Long
Normal Small
E 
23 Poor
Normal Normal Large
C
63 Good
Long
Long
Small
E 
24 Poor
Normal Long
Large
B
64 Good
Short
Short
Medium 
P 
25 Poor
Long
Short
Large
N
65 Good
Short
Normal Medium 
P 
26 Poor
Long
Normal Large
B
66 Good
Short
Long
Medium 
VG 
27 Poor
Long
Long
Large
N
67 Good
Normal Short
Medium 
P 
28 Medium 
Short
Short
Small
P
68 Good
Normal Normal Medium 
P 
29 Medium 
Short
Normal Small
P
69 Good
Normal Long
Medium 
VG 
30 Medium 
Short
Long
Small
P
70 Good
Long
Short
Medium 
VG 
31 Medium 
Normal Short
Small
P
71 Good
Long
Normal Medium 
P 
32 Medium 
Normal Normal Small
P
72 Good
Long
Long
Medium 
VG 
33 Medium 
Normal Long
Small
P
73 Good
Short
Short
Large
C 
34 Medium 
Long
Short
Small
P
74 Good
Short
Normal Large
C 
35 Medium 
Long
Normal Small
P
75 Good
Short
Long
Large
C 
36 Medium 
Long
Long
Small
P
76 Good
Normal Short
Large
C 
37 Medium 
Short
Short
Medium 
VG
77 Good
Normal Normal Large
C 
38 Medium 
Short
Normal Medium 
VG
78 Good
Normal Long
Large
B 
39 Medium 
Short
Long
Medium 
C
79 Good
Long
Short
Large
C 
40 Medium 
Normal Short
Medium 
VG
80 Good
Long
Normal Large
B 
81 Good
Long
Long
Large
B
4  Fuzzy Logic for Modeling the Knowledge of Users in PARSAT AR Software

75
 
 
Example Rule 4: 
IF PRK is PRK_PR AND VLD is VLD_NRML AND ARID is ARID_LNG 
AND NoE is NoE_LRG THEN CLK is B 
If prior knowledge is poor and video-based learning duration is normal and 
augmented-­reality interaction duration is long and number of errors is large, then 
the current level of knowledge is beginner. 
This rule (rule 4) implies that a student with poor prior knowledge, who has 
spent anormal time watching the video tutorials, long time in manipulating the 3D 
models, and scored a large average number of errors in the assessment, is classified 
as a beginner.
4.5  Fuzzy Rule Base

76
 
 
4.9
Example Rule 5: 
IF PRK is PRK_PR AND VLD is VLD_LNG AND ARID is ARID_NRML 
AND NoE is NoE_LRG THEN CLK is B 
4.10
­
4.11
4  Fuzzy Logic for Modeling the Knowledge of Users in PARSAT AR Software

77
 
 
4.2
Example Rule 6: 
IF PRK is PRK_PR AND VLD is VLD_NRML AND ARID is ARID_NRML 
AND NoE is NoE_LRG THEN CLK is C 
4.12
4.13
4.5  Fuzzy Rule Base

78
 
 
In the case of a proficient student, the inference engine’s output is due to the 
input values of 82, 59, 17 and 56 for the variables PRK, VLD, ARID, and NoE, 
respectively. 
Example Rule 7: 
IF PRK is PRK_MDM AND VLD is VLD_SRT AND ARID is ARID_NRML 
AND NoE is NoE_MDM THEN CLK is VG 
Example Rule 8: 
IF PRK is PRK_GD AND VLD is VLD_NRML AND ARID is ARID_SRT 
AND NoE is NoE_MDM THEN CLK is VG
4  Fuzzy Logic for Modeling the Knowledge of Users in PARSAT AR Software

79
4.6  Mamdani’s Inference System 
4.14
81 fuzzy rules were designed to classify the inputs into the appropriate output 
linguistic terms, or student knowledge levels, using the fuzzy inference engine. The 
output linguistic terms were defined as “Novice”, “Beginner”, “Competent”, “Very 
Good”, “Proficient”, and “Expert”. The fuzzy inference engine uses the member­
ship functions and fuzzy rules to compute the appropriate degree of membership for 
each output linguistic term, and then applies the defuzzification method to generate 
the crisp output value, or the final student knowledge level. 
There are two main types of fuzzy inference systems: Mamdani FIS and Sugeno 
FIS. Mamdani fuzzy inference was first introduced as a method to create a control 
system, by synthesizing a set of linguistic control rules obtained from experienced 
human operators [30]. In a Mamdani system, the output of each rule is a fuzzy set. 
Since Mamdani systems have more intuitive and easier to understand rule bases, 
they are well-suited to expert system applications, where the rules are created from 
human expert knowledge. The output of each rule is a fuzzy set, derived from the 
output membership function and the implication method of the FIS. These output 
fuzzy sets are combined into a single fuzzy set using the aggregation method of the 
FIS. Then, to compute a final crisp output value, the combined output fuzzy set is 
defuzzified.
 
4.6  Mamdani’s Inference System

80
Table 4.3  Comparison between Mamdani and Sugeno fuzzy inference system 
Mamdani FIS
Sugeno FIS 
There is an output membership function
There is no output membership 
function 
Surface produces a discontinuous output
Surface produces a continuous 
output 
Consequent crisp values are obtained through 
defuzzification 
There is no defuzzification 
Applied in Multiple Input and Single Output (MISO) and 
Multiple Input and Multiple Output (MIMO) systems 
Applied only in Multiple Input and 
Single Output (MISO) 
Effectively suited to human input
Effectively suited to mathematical 
analysis 
In a Sugeno fuzzy inference system, also referred to as Takagi-Sugeno-Kang 
(TSK) fuzzy inference, the output membership functions are represented by con­
stants or linear functions of the input variables, rather than fuzzy sets as in a 
Mamdani system. The output of a Sugeno system is a crisp value, rather than a 
fuzzy set. This makes the defuzzification process simpler, as it involves computing 
a weighted sum or average of a few data points rather than computing the centroid 
of a fuzzy set [31]. Sugeno systems are often used in applications where the output 
needs to be a precise numerical value, rather than a fuzzy set. 
4.3
­
In this book, the Mamdani FIS is employed, as it is typically used to capture 
expert knowledge. It enables us to communicate more naturally, while describing 
the expertise. 
The fuzzy inputs must be combined into a single fuzzy output, by using the 
Mamdani inference engine’s fuzzy implication. The fuzzy input variables for each 
of the rules are then connected using the AND operator. This operator’s function is 
to extract the minimum membership function value from the fuzzy input variables. 
Using the value obtained from the input component, the fuzzy output variable is 
truncated. By taking the maximum value of the membership degree, the entire 
shortened output is therefore aggregated into a single graph and employed in the 
final stage of the fuzzy logic system. 
4.7  Defuzzification 
The defuzzifier procedure maps the fuzzy output to a crisp value according to the 
membership function of the output variable. In order to get the crisp value, a diverse 
method is required. This defuzzification is not part of the “mathematical fuzzy 
logic” and various methods are possible [32–34], such as:
4  Fuzzy Logic for Modeling the Knowledge of Users in PARSAT AR Software

81
•	 Center of Sums Method (COS): This method calculates the center of gravity or 
the center of the area of the fuzzy output set. The defuzzification process is 
accomplished by computing the weighted average of the values of the output 
variable for all the fuzzy sets that are active. The COS method involves the fol­
lowing steps:
	
1.	 Divide the output variable universe of discourse into a number of dis­
crete points.
	
2.	 Evaluate the degree of membership of the fuzzy output set at each of 
these points.
	
3.	 Multiply each point’s degree of membership by the point’s position (i.e., the 
crisp value of the output variable at that point).
	
4.	 Sum the results obtained in step 3.
	
5.	 Divide the result obtained in step 4 by the sum of the degrees of membership 
of the fuzzy output set. 
The final result obtained in step 5 is the crisp output value of the fuzzy logic system. 
The COS method is easy to understand and implement, but it may not always pro­
vide the best results for all types of fuzzy systems. 
•	 Center of gravity (COG)/Centroid of Area (COA) Method: This is another com­
monly used defuzzification technique. It calculates the center of mass of the 
fuzzy output’s area, which represents the final crisp value. 
Mathematically, the COG/COA method can be expressed as: 
	
	
(4.2) 
where x is the input value of the fuzzy output variable and μ(x) is the membership 
function value of the fuzzy output variable at input value x. 
The numerator calculates the weighted sum of the input values, where the weight 
is the membership function value of each input value. The denominator calculates 
the sum of the membership function values. The result is a weighted average of the 
input values, representing the crisp output value. 
The COG/COA method is often preferred over the COS method because it takes 
into account the shape of the fuzzy output’s membership function, rather than just 
the center point. It also produces a more accurate and stable result for non-­symmetric 
membership functions. 
•	 Center of Area/Bisector of Area Method (BOA): In this method, the centroid or 
center of gravity of the area under the membership function curve is calculated. 
The BOA method can be used for any type of membership function, including 
non-symmetric ones. 
To calculate the BOA, the output membership function is first divided into small 
intervals along the x-axis. Then, the area of each interval is calculated by 
4.7  Defuzzification

82
multiplying the membership value of that interval with its width. The total area 
under the curve is then divided into two equal halves, and the point where the two 
halves intersect is determined as the BOA. 
The BOA method is more computationally expensive than the COS method, but 
it provides better results for non-symmetric membership functions. 
•	 Weighted Average Method: This method, also known as the weighted mean 
method, is a defuzzification method that calculates the crisp output value as the 
weighted average of the centroid values of the fuzzy sets in the output variable. 
The formula for calculating the crisp output value using the weighted average 
method is: 
	
	
(4.3) 
where Y is the crisp output value, wi is the weight of the i-th fuzzy set, and yi is the 
centroid value of the i-th fuzzy set. 
The weights can be determined in several ways, such as using the degree of 
membership of each fuzzy set in the output variable or using the confidence level of 
each rule that fired during the inference process. 
•	 Maxima Methods: This method, also known as the max-of-max method, selects 
the output value that has the highest degree of membership among all the output 
membership functions. This method is simple and easy to implement, but it may 
not be the most accurate method in some cases where there is overlap between 
the membership functions. 
•	 First of Maxima Method (FOM): This method selects the crisp output value as 
the first value in the output membership function that achieves the maximum 
membership degree. In other words, the output value corresponding to the first 
peak of the membership function is chosen. This method is simple to compute 
but may not provide an accurate representation of the output value, especially if 
there are multiple peaks in the membership function. 
•	 Last of Maximum Method (LOM): This method selects the output value corre­
sponding to the last maximum value in the aggregated output fuzzy set. This 
method can be useful in situations where it is important to prioritize the higher 
output values, as the last maximum value corresponds to the highest membership 
degree. It can be expressed mathematically as: 
	
	
(4.4) 
where y is the crisp output value and x is the aggregated fuzzy output set. The maxi­
mum function selects the highest value in the set, corresponding to the last maxi­
mum membership degree. 
•	 Mean of Maximum Method (MOM): This method is a type of defuzzification 
method used in fuzzy logic. It is a weighted average of the output values corre­
sponding to the highest membership degrees of the output variable.
4  Fuzzy Logic for Modeling the Knowledge of Users in PARSAT AR Software

83
In the MOM method, the output variable is first divided into a set of discrete 
points, and the membership values for each point are computed using the fuzzy 
inference system. Then, the points with the highest membership degrees are identi­
fied, and their corresponding output values are averaged, with the degree of mem­
bership serving as the weight for each point. 
Mathematically, the MOM method can be expressed as: 
	
	
(4.5) 
where yi is the output value at the ith point, mi is the membership degree of the ith 
point, and the summation is taken over all points with non-zero membership degrees. 
The defuzzification process involves converting a fuzzy set of the aggregated 
output into a single numerical value. The Centroid of Gravity (COG) method is the 
most prevalent and physically appealing of all the defuzzification methods [31], 
which is a popular and physically intuitive method of defuzzification, where the 
center of gravity of the aggregated output fuzzy set is calculated to obtain a single 
numerical value. 
The COG method involves calculating the weighted average of the membership 
function values of the fuzzy set. This weighted average is calculated using the cen­
troid formula, which is the ratio of the first moment of the fuzzy set to its area. 
The COG method evaluates the center of area under the curve of the aggregated 
output fuzzy set. This involves calculating the first moment of the fuzzy set, which 
is the weighted sum of the input values, and dividing it by the area of the fuzzy set. 
The resulting value is the center of gravity or the centroid of the fuzzy set, which is 
used as the defuzzified output. 
Overall, the COG method provides a simple and intuitive approach to defuzzifi­
cation and is widely used in various applications of fuzzy logic. The basic principle 
in the COG method is a centroid approach, which finds the point where a vertical 
line slices the aggregate set into two equal masses. 
Consider μ(x) to be the output membership function of the output variable x, then 
the position of the center of gravity of a fuzzy set A, in the interval ab, is given by 
(4.6), as follows: 
	
	
(4.6) 
There are multiple sub-areas within the overall area of the membership function 
distribution, that are utilized to represent the combined control action. To determine 
the defuzzified value for a discrete fuzzy set, the area and centroid of each sub-area 
are determined, and the sum of all these sub-areas is then used.
4.7  Defuzzification

84
4.8  Adaptation of the Learning Activities Based 
on Fuzzy Weights 
Technical drawing assumes a high-level training in spatial ability, while it is 
achieved by using adaptive learning activities considering the student’s level of 
knowledge. This is accomplished by converting students’ current knowledge level 
to fuzzy weights to deliver appropriate both, in quantity and level of difficulty, 
learning activities. 
To calculate the six fuzzy weights that represent the student’s knowledge level, 
membership functions are used. These membership functions are used to determine 
the extent to which the student’s knowledge level belongs to each of the six fuzzy 
sets. The resulting values for each fuzzy set are then combined to calculate the sex­
tet that best defines the student’s current level of knowledge. 
4.15
This approach uses fuzzy logic techniques to adapt learning activities to the stu­
dent’s current level of knowledge and ability, which can potentially improve learn­
ing outcomes in the domain of technical drawing. 
The membership functions discussed in the aforementioned context are limited 
between 0 and 1. These membership functions are used in both the fuzzification and 
defuzzification steps of the fuzzy logic system to map non-fuzzy input values to 
fuzzy linguistic terms and vice versa. 
In the fuzzification step, non-fuzzy input values are mapped to fuzzy linguistic 
terms using membership functions. These membership functions determine the 
degree to which the input values belong to each fuzzy set and assign a membership 
value between 0 and 1 for each fuzzy set. The resulting membership values repre­
sent the degree of membership of the input values in each fuzzy set and are used to 
form fuzzy sets. 
In the defuzzification step, the output of the fuzzy logic system is converted from 
fuzzy linguistic terms back to a non-fuzzy numerical value. This is done by calculat­
ing a single numerical value that represents the degree of truth of the aggregated 
output fuzzy set. This process involves using a defuzzification method, namely the 
COG method, which uses the membership values of the fuzzy set to calculate a 
single numerical value that represents the output of the system. The membership 
functions play a crucial role in the fuzzification and defuzzification steps of the 
fuzzy logic system. 
4.16
­
4  Fuzzy Logic for Modeling the Knowledge of Users in PARSAT AR Software

85
 
By combining trapezoidal membership functions constructed with straight lines, 
the system can harness the simplicity of linear functions while still capturing the 
4.8  Adaptation of the Learning Activities Based on Fuzzy Weights

86
 
intricacy and precision associated with trapezoidal membership functions. This can 
potentially improve the performance and ease of implementation of the fuzzy 
logic system. 
Student’s knowledge level is described by the sextet (N, B, C, VG, P, and E), and 
as such, the student may be fully assigned to one, or partially assigned to more fuzzy 
sets, meaning that student’s knowledge level can be described as ‘Competent’ or 
partially ‘Very Good’ and partially ‘Proficient’, respectively. As an example, a stu­
dent’s sextet of (0, 1, 0, 0, 0, 0), classifies the student as 100% ‘Beginner’. An addi­
tional instance of a student’s sextet, represented as (0, 0, 0, 0.70, 0.30, 0), categorizes 
the student as 70% ‘Very Good’ and 30% ‘Proficient.’ However, it’s important to 
note that regardless of the specific values within the sextet, the equation μN(x) + 
μB(x) + μC(x) + μVG(x) + μP(x) + μE(x) = 1 remains constant. 
4.8.1  Decision Making 
A teaching strategy is being developed that adapts to the student’s knowledge level 
using fuzzy logic [35–39]. In this section, the analysis of the rules, in combination 
with the fuzzy weights, is presented to achieve this. 
The teaching strategy involves dynamically defining the number of learning 
activities that the student must learn in each chapter based on their current level of 
knowledge. This is done by analyzing the rules and combining them with the fuzzy 
4  Fuzzy Logic for Modeling the Knowledge of Users in PARSAT AR Software

87
weights that represent the student’s knowledge level. The rules define the relation­
ship between the student’s knowledge level and the number of learning activities 
that they need to complete [40, 41]. 
By tailoring the teaching approach to match the student’s knowledge level, the 
system can offer suitable learning tasks that align with the student’s existing skill 
level. This approach helps prevent situations where the student is either swamped 
with overly challenging material or disengaged due to overly simplistic content 
[42, 43]. 
The formulation of rules is of paramount importance in shaping the quantity and 
complexity of the learning activities offered to students. In this case, the rules were 
developed by eight professors who utilized fuzzy rules and related thresholds at the 
membership functions. The rules are related to technical drawing knowledge levels 
that students acquire during the course of an entire semester. 
The fact that all faculty members have over 15 years of experience teaching tech­
nical drawing in academic settings indicates that they have a wealth of knowledge 
and expertise in this area. Their contributions to matching each learning activity 
with the corresponding SOLO level was significant, as SOLO is a framework for 
assessing and describing the complexity of student learning outcomes. 
The use of experienced faculty members to develop rules and match learning 
activities with SOLO levels suggests a thoughtful and intentional approach to 
designing the course and assessing student progress. By utilizing the expertise of 
these instructors, the course can be tailored to the needs of the students and provide 
a comprehensive and effective learning experience. 
An example highlights how the rules take into account the different knowledge 
levels of beginner and expert students. Beginners may need to study many topics of 
low difficulty (uni-structural and multi-structural level), while experts can focus on 
fewer topics but at higher levels of complexity (relational and extended abstract). 
By utilizing the SOLO taxonomy and involving experienced faculty members in 
the development of the rules and matching of learning activities with SOLO levels, 
the course has been designed to effectively address the needs of students with vary­
ing levels of knowledge and experience in technical drawing. Adopting a deliberate 
and methodical course design is crucial to establishing well-defined learning goals 
and aligning course materials and tasks effectively to support students in attaining 
those objectives. Additionally, it aids in ensuring that students are adequately stimu­
lated and engaged throughout the course, ultimately resulting in improved learning 
outcomes and student achievement. 
4.4
­
4.4
•	 no learning activity of SOLO-L0; 
•	 no learning activity of SOLO-L1; 
•	 one learning activities of SOLO-L2; 
•	 four learning activities of SOLO-L3; and 
•	 two learning activities of SOLO-L4.
4.8  Adaptation of the Learning Activities Based on Fuzzy Weights

88
Table 4.4  Decision rules for adaptive instruction 
Current Level of Knowledge
L0
L1
L2
L3
L4
Sum of LAs 
μΝ = 1
9
5
0
0
14 
μΝ < 1 and μΒ < 1
8
5
0
0
13 
μΒ = 1
6
6
0
0
12 
μΒ < 1 and μC < 1
5
5
1
0
11 
μC = 1
4
4
2
0
10 
μC < 1 and μVG < 1
3
3
3
0
9 
μVG = 1
1
2
4
1
8 
μVG < 1 and μP < 1
0
1
4
2
7 
μP = 1
0
0
3
3
6 
μP < 1 and μE < 1
0
0
2
3
5 
μE = 1
0
0
0
4
4
 
4.17
4.4
­
4.4
3
4
4.9  Summary 
In this chapter, fuzzy logic was introduced. More specific, the problem was speci­
fied, and the linguistic variables were defined. Afterwards, the fuzzy sets were 
determined, while 81 fuzzy rules were constructed. Fuzzy sets, fuzzy rules and pro­
cedures were encoded to perform fuzzy inference, and finally, determine the sys­
tem’s adaptation as far as the learning activities are considered.
4  Fuzzy Logic for Modeling the Knowledge of Users in PARSAT AR Software

89
Overall, the use of fuzzy logic and the specific classifications and learning activi­
ties assigned to students based on their output values and SOLO levels suggests a 
detailed and customized approach to learning and assessment that can be beneficial 
for students. By tailoring the course to individual students’ needs and knowledge 
levels, the current proposed system can provide an effective learning experience that 
helps students achieve their learning objectives. 
References 
1.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “PARSAT: Fuzzy logic for 
adaptive spatial ability training in an augmented reality system.,” Computer Science and 
Information Systems, vol. 20, no. 4, 2023, https://doi.org/10.2298/CSIS230130043P. 
2.	C.  Papakostas, C.  Troussas, A.  Krouska, and C.  Sgouropoulou, “Personalization of the 
Learning Path within an Augmented Reality Spatial Ability Training Application Based on 
Fuzzy Weights,” Sensors, vol. 22, no. 18, 2022, https://doi.org/10.3390/s22187059. 
3.	C. Troussas, C. Papakostas, A. Krouska, P. Mylonas, and C. Sgouropoulou, “Personalized 
Feedback Enhanced by Natural Language Processing in Intelligent Tutoring Systems,” 
in Augmented Intelligence and Intelligent Tutoring Systems, C.  Frasson, P.  Mylonas, and 
C.  Troussas, Eds., Cham: Springer Nature Switzerland, 2023, pp.  667–677. https://doi. 
org/10.1007/978-­3-­031-­32883-­1_58. 
4.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Modeling the Knowledge of 
Users in an Augmented Reality-Based Learning Environment Using Fuzzy Logic,” in Lecture 
Notes in Networks and Systems, A. Krouska, C. Troussas, and J. Caro, Eds., Cham: Springer 
International Publishing, 2023, pp. 113–123. https://doi.org/10.1007/978-­3-­031-­17601-­2_12. 
5.	P. Strousopoulos, C. Papakostas, C. Troussas, A. Krouska, P. Mylonas, and C. Sgouropoulou, 
“SculptMate: Personalizing Cultural Heritage Experience Using Fuzzy Weights,” in Adjunct 
Proceedings of the 31st ACM Conference on User Modeling, Adaptation and Personalization, 
in UMAP ’23 Adjunct. New York, NY, USA: Association for Computing Machinery, 2023, 
pp. 397–407. https://doi.org/10.1145/3563359.3596667. 
6.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “User acceptance of augmented 
reality welding simulator in engineering training,” Educ Inf Technol (Dordr), vol. 27, no. 1, 
pp. 791–817, Jan. 2022, https://doi.org/10.1007/s10639-­020-­10418-­7. 
7.	M. Iakovidis, C. Papakostas, C. Troussas, and C. Sgouropoulou, “Empowering Responsible 
Digital Citizenship Through an Augmented Reality Educational Game,” in Novel & Intelligent 
Digital Systems: Proceedings of the 3rd International Conference (NiDS 2023), K. Kabassi, 
P. Mylonas, and J. Caro, Eds., Cham: Springer Nature Switzerland, 2023, pp. 31–39. 
8.	P.  Strousopoulos, C.  Troussas, C.  Papakostas, A.  Krouska, and C.  Sgouropoulou, 
“Revolutionizing Agricultural Education with Virtual Reality and Gamification: A Novel 
Approach for Enhancing Knowledge Transfer and Skill Acquisition,” in Novel & Intelligent 
Digital Systems: Proceedings of the 3rd International Conference (NiDS 2023), K. Kabassi, 
P. Mylonas, and J. Caro, Eds., Cham: Springer Nature Switzerland, 2023, pp. 67–80. 
9.	C.  Papakostas, C.  Troussas, P.  Douros, M.  Poli, and C.  Sgouropoulou, “CoMoPAR: A 
Comprehensive Conceptual Model for Designing Personalized Augmented Reality Systems 
in Education,” in Novel & Intelligent Digital Systems: Proceedings of the 3rd International 
Conference (NiDS 2023), K. Kabassi, P. Mylonas, and J. Caro, Eds., Cham: Springer Nature 
Switzerland, 2023, pp. 67–79. 
10.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Exploration of Augmented 
Reality in Spatial Abilities Training: A Systematic Literature Review for the Last Decade,” 
Informatics in Education, vol. 20, no. 1, pp. 107–130, Mar. 2021, https://doi.org/10.15388/ 
infedu.2021.06.
References

90
11.	Z. Kanetaki et al., “Acquiring, Analyzing and Interpreting Knowledge Data for Sustainable 
Engineering Education: An Experimental Study Using YouTube,” Electronics (Basel), vol. 11, 
no. 14, 2022, https://doi.org/10.3390/electronics11142210. 
12.	A. Marougkas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Virtual Reality in Education: 
A Review of Learning Theories, Approaches and Methodologies for the Last Decade,” 
Electronics (Basel), vol. 12, no. 13, 2023, https://doi.org/10.3390/electronics12132832. 
13.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Enriching Mobile Learning Software with 
Interactive Activities and Motivational Feedback for Advancing Users’ High-Level Cognitive 
Skills,” Computers, vol. 11, no. 2, 2022, https://doi.org/10.3390/computers11020018. 
14.	F. Giannakas, C. Troussas, A. Krouska, C. Sgouropoulou, and I. Voyiatzis, “XGBoost and 
Deep Neural Network Comparison: The Case of Teams’ Performance,” in Intelligent Tutoring 
Systems, A. I. Cristea and C. Troussas, Eds., Cham: Springer International Publishing, 2021, 
pp. 343–349. 
15.	A. Krouska, C. Troussas, and C. Sgouropoulou, “Fuzzy Logic for Refining the Evaluation 
of Learners’ Performance in Online Engineering Education,” European Journal of 
Engineering Research and Science, vol. 4, pp. 50–56, Jun. 2019, https://doi.org/10.24018/ 
ejers.2019.4.6.1369. 
16.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Towards a Reference Model to Ensure the 
Quality of Massive Open Online Courses and E-Learning,” in Brain Function Assessment 
in Learning, C.  Frasson, P.  Bamidis, and P.  Vlamos, Eds., Cham: Springer International 
Publishing, 2020, pp. 169–175. 
17.	A.  Marougkas, C.  Troussas, A.  Krouska, and C.  Sgouropoulou, “How personalized and 
effective is immersive virtual reality in education? A systematic literature review for the last 
decade,” Multimed Tools Appl, 2023, https://doi.org/10.1007/s11042-­023-­15986-­7. 
18.	A. Marougkas, C. Troussas, A. Krouska, and C. Sgouropoulou, “A Framework for Personalized 
Fully Immersive Virtual Reality Learning Environments with Gamified Design in Education,” 
2021. https://doi.org/10.3233/FAIA210080. 
19.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Dynamic Detection of Learning Modalities 
Using Fuzzy Logic in Students’ Interaction Activities,” in Intelligent Tutoring Systems, 
V. Kumar and C. Troussas, Eds., Cham: Springer International Publishing, 2020, pp. 205–213. 
20.	A. Krouska, C. Troussas, and C. Sgouropoulou, “A novel group recommender system for 
domain-independent decision support customizing a grouping genetic algorithm,” User Model 
User-adapt Interact, 2023, https://doi.org/10.1007/s11257-­023-­09360-­3. 
21.	A. Krouska, C. Troussas, K. Kabassi, and C. Sgouropoulou, “An Empirical Investigation of 
User Acceptance of Personalized Mobile Software for Sustainability Education,” Int J Hum 
Comput Interact, pp. 1–8, Aug. 2023, https://doi.org/10.1080/10447318.2023.2241614. 
22.	T. Hailikari, N. Katajavuori, and S. Lindblom-Ylänne, “The Relevance of Prior Knowledge in 
Learning and Instructional Design,” Am J Pharm Educ, vol. 72, p. 113, Nov. 2008, https://doi. 
org/10.5688/aj7205113. 
23.	N. Medina-Medina and L. García-Cabrera, “A taxonomy for user models in adaptive systems: 
special considerations for learning environments,” Knowl Eng Rev, vol. 31, pp. 124–141, Mar. 
2016, https://doi.org/10.1017/S0269888916000035. 
24.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “On the development of a 
personalized augmented reality spatial ability training mobile application,” in Frontiers in 
Artificial Intelligence and Applications, IOS Press, 2021, pp. V–VI. https://doi.org/10.3233/ 
FAIA210078. 
25.	E.  Mousavinasab, N.  Zarifsanaiey, S.  R. Niakan Kalhori, M.  Rakhshan, L.  Keikha, and 
M. Ghazi Saeedi, “Intelligent tutoring systems: a systematic review of characteristics, applica­
tions, and evaluation methods,” Interactive Learning Environments, vol. 29, no. 1, pp. 142–163, 
Jan. 2021, https://doi.org/10.1080/10494820.2018.1558257. 
26.	A. Krouska, C. Troussas, and C. Sgouropoulou, “Fuzzy logic for refining the evaluation of 
learners’ performance in online engineering education,” European Journal of Engineering and 
Technology Research, vol. 4, no. 6, pp. 50–56, 2019.
4  Fuzzy Logic for Modeling the Knowledge of Users in PARSAT AR Software

91
27.	C.  Troussas, A.  Krouska, C.  Sgouropoulou, and I.  Voyiatzis, “Ensemble Learning Using 
Fuzzy Weights to Improve Learning Style Identification for Adapted Instructional Routines,” 
Entropy, vol. 22, no. 7, 2020, https://doi.org/10.3390/e22070735. 
28.	C.  Troussas, F.  Giannakas, C.  Sgouropoulou, and I.  Voyiatzis, “Collaborative activities 
recommendation based on students’ collaborative learning styles using ANN and WSM,” 
Interactive Learning Environments, pp.  1–14, May 2020, https://doi.org/10.1080/1049482 
0.2020.1761835. 
29.	Y. H. Kim, S. C. Ahn, and W. H. Kwon, “Computational complexity of general fuzzy logic con­
trol and its simplification for a loop controller,” Fuzzy Sets Syst, vol. 111, no. 2, pp. 215–224, 
Apr. 2000, https://doi.org/10.1016/S0165-­0114(97)00409-­0. 
30.	E. H. Mamdani and S. Assilian, “An experiment in linguistic synthesis with a fuzzy logic 
controller,” Int J Man Mach Stud, vol. 7, no. 1, pp.  1–13, 1975, https://doi.org/10.1016/ 
S0020-­7373(75)80002-­2. 
31.	T. Takagi and M. Sugeno, “Fuzzy identification of systems and its applications to modeling 
and control,” IEEE Trans Syst Man Cybern, vol. SMC-15, no. 1, pp. 116–132, 1985, https:// 
doi.org/10.1109/TSMC.1985.6313399. 
32.	H. Diab, “Defuzzification methods and new techniques for fuzzy controllers,” Iranian Journal 
of Electrical and Computer Engineering, vol. 3, Jul. 2004. 
33.	A.  Chandramohan, M.  V. C.  Rao, and M.  Senthil Arumugam, “Two New and Useful 
Defuzzification Methods Based on Root Mean Square Value,” Soft comput, vol. 10, no. 11, 
pp. 1047–1059, 2006, https://doi.org/10.1007/s00500-­005-­0042-­6. 
34.	N. Mogharreban and L. Dilalla, Comparison of Defuzzification Techniques for Analysis of 
Non-interval Data. 2006. https://doi.org/10.1109/NAFIPS.2006.365418. 
35.	N. Elghouch, M. Kouissi, and E.-N. el Mokhtar, “Multi-Agent System of an Adaptive Learning 
Hypermedia Based on Incremental Hybrid Case-Based Reasoning,” 2020, pp.  143–156. 
https://doi.org/10.1007/978-­3-­030-­37629-­1_12. 
36.	T.  K. F.  Chiu and I.  Mok, “Learner expertise and mathematics different order thinking 
skills in multimedia learning,” Comput Educ, vol. 107, pp. 147–164, Apr. 2017, https://doi. 
org/10.1016/j.compedu.2017.01.008. 
37.	A.  Khamparia and B.  Pandey, “SVM and PCA Based Learning Feature Classification 
Approaches for E-Learning System,” International Journal of Web-Based Learning 
and Teaching Technologies, vol. 13, pp.  32–45, Apr. 2018, https://doi.org/10.4018/ 
IJWLTT.2018040103. 
38.	C.  Troussas, A.  Krouska, F.  Giannakas, C.  Sgouropoulou, and I.  Voyiatzis, “Redesigning 
Teaching Strategies through an Information Filtering System,” in 24th Pan-Hellenic 
Conference on Informatics, in PCI 2020. New York, NY, USA: Association for Computing 
Machinery, 2021, pp. 111–114. https://doi.org/10.1145/3437120.3437287. 
39.	A. Krouska, C. Troussas, A. Voulodimos, and C. Sgouropoulou, “A 2-tier fuzzy control sys­
tem for grade adjustment based on students’ social interactions,” Expert Syst Appl, vol. 203, 
p. 117503, 2022, https://doi.org/10.1016/j.eswa.2022.117503. 
40.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Improving Learner-Computer Interaction 
through Intelligent Learning Material Delivery Using Instructional Design Modeling,” 
Entropy, vol. 23, no. 6, 2021, https://doi.org/10.3390/e23060668. 
41.	C. Troussas, A. Krouska, and C. Sgouropoulou, “A Novel Teaching Strategy Through Adaptive 
Learning Activities for Computer Programming,” IEEE Transactions on Education, vol. 64, 
no. 2, pp. 103–109, 2021, https://doi.org/10.1109/TE.2020.3012744. 
42.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Exploring Users’ Behavioral 
Intention to Adopt Mobile Augmented Reality in Education through an Extended Technology 
Acceptance Model,” Int J Hum Comput Interact, vol. 39, no. 6, pp. 1294–1302, 2023, https:// 
doi.org/10.1080/10447318.2022.2062551. 
43.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Measuring User Experience, 
Usability and Interactivity of a Personalized Mobile Augmented Reality Training System,” 
Sensors, vol. 21, no. 11, p. 3888, Jun. 2021, https://doi.org/10.3390/s21113888.
References

93
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024
C. Papakostas et al., Special Topics in Artificial Intelligence and Augmented 
Reality, Cognitive Technologies, https://doi.org/10.1007/978-3-031-52005-1_5
Chapter 5
Artificial Intelligence-Enhanced PARSAT 
AR Software: Architecture 
and Implementation
Abstract  This chapter offers a comprehensive exploration of the architecture and 
practical implementation of a mobile training system, enriched with augmented 
reality (AR) features and adaptive capabilities based on fuzzy logic. It commences 
with an overview that encapsulates the core concepts and objectives of the system, 
followed by a detailed exposition of its structural underpinnings. The “Overview” 
section provides a high-level synopsis of the mobile training system’s architecture, 
with a specific emphasis on its integration of AR features and its pivotal role in 
enhancing spatial ability training. The subsequent section, “System Architecture,” 
conducts an intricate examination of the system’s architecture, delineating the dis­
tinct layers involved, namely the hardware layer, software layer, and data layer. This 
section elucidates the interplay of components within each layer, fostering a com­
prehensive understanding of the system’s holistic structure. The “Hardware Layer” 
section delves into the physical components of the system, elucidating their roles in 
tracking user movements, computational processes, and facilitating user interac­
tions in real-time. In “Software Layer,” the focus shifts to the software components, 
encompassing the user interface’s interactive capabilities and the 3D rendering 
engine’s pivotal role in creating and presenting virtual elements within the real-­
world context. The “Data Layer” section addresses data storage and management, 
encompassing marker databases for AR tracking, 3D models repositories, and inter­
action models defining system rules and behaviors. The chapter further illuminates 
the practical implementation of the system, specifically detailing the user interface’s 
design and its interaction with AR learning activities. Additionally, it elucidates the 
incorporation of a fuzzy logic controller through C# scripting, facilitating adaptive 
learning based on fuzzy weight parameters.

94
5.1  Overview
This chapter provides a comprehensive overview of a mobile training system featur­
ing augmented reality (AR) capabilities and adaptive functionality driven by fuzzy 
logic, including an exploration of its architecture, hardware and software layers, and 
practical implementation [1–14].
The current chapter provides a thorough view of the system’s architecture, ana­
lyzing all the layers involved in the training application, while the second section of 
the chapter presents the system’s implementation.
5.2  System Architecture
­
15
16
­
5.1
The utilization of fuzzy logic for automatic assessment of students’ knowledge 
levels is particularly intriguing. This approach offers a more adaptable and flexible 
training system capable of catering to the unique needs and abilities of individual 
students. Augmented reality technology also holds substantial potential in the realm 
of spatial ability training, enabling students to engage with virtual objects in a more 
immersive and lifelike manner.
In summary, the book presents an innovative and promising approach to spatial 
ability training. Its findings and implications hold substantial promise for education 
and training across various domains, especially those that rely on robust spatial 
reasoning skills.
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

95
 
5.2.1  Hardware Layer
5.2.1.1  Tracking
Within the context of this book, a diverse array of sensors, comprising the acceler­
ometer, gyroscope, magnetometer, and GPS, assumes a central role in the establish­
ment of the system’s spatial position and orientation. This orchestration of sensors 
is instrumental in ensuring the seamless alignment of virtual content with the 
5.2  System Architecture

96
physical environment. Importantly, the prevailing landscape of contemporary 
mobile devices, inclusive of smartphones and tablets, uniformly incorporates these 
sensors as integral components.
These sensors are consistently featured in contemporary mobile devices, thereby 
endowing them with the intrinsic capability to facilitate augmented reality applica­
tions that seamlessly superimpose virtual data onto the tangible reality. Notably, the 
accelerometer functions to quantitatively assess changes in acceleration and tilt, 
while the gyroscope is pivotal in quantifying rotations and orientation shifts. The 
magnetometer, in turn, is dedicated to the precise measurement of magnetic fields, 
whereas the GPS system provides indispensable geolocation data. This collective 
integration of sensors collaborates in real-time to furnish precise and immediate 
information pertaining to the dynamic position and orientation of the device. It is 
imperative to underscore that such precision assumes a paramount role in the real­
ization of an uninterrupted and fully immersive augmented reality experience for 
end-users.
5.2.1.2  Processing
Within the framework of the AR system, it is imperative to acknowledge that critical 
computational processes, namely the fuzzy inference system, 3D rendering, and the 
overarching user interface, impose substantial demands on hardware resources. 
Consequently, contemporary mobile devices are fortified with potent processing 
units, firmly establishing them as capable platforms for the execution of these com­
putational tasks. These mobile devices, typically exemplified by smartphones and 
tablets, house robust processors that encompass both central processing units 
(CPUs) and graphics processing units (GPUs).
The CPUs, constituting the brains of these devices, are adept at executing user 
instructions and adeptly overseeing the allocation of system resources. In parallel, 
GPUs assume the mantle of processing extensive volumes of graphical data with 
swiftness and precision. This tandem operation between CPU and GPU is pivotal in 
ensuring the seamless functioning of our augmented reality system and the delivery 
of an uninterrupted and engaging user experience.
In essence, this hardware synergy underscores the competence of contemporary 
mobile devices as formidable computational powerhouses, well-suited for the intri­
cate demands of 3D rendering, fuzzy logic inference, and other resource-intensive 
computational facets intrinsic to augmented reality technology. This symbiotic rela­
tionship between hardware and software represents a cornerstone of the system’s 
capacity to realize the AR experience.
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

97
5.2.1.3  Interacting
This element includes various sensors like touch surfaces, gesture recognition, and 
biometric sensors, all of which interpret the user’s engagement with the system. The 
tactile sensor is integrated into PARSAT so that the identified information is due to 
the contact of the student’s fingers on the mobile screen. All mobile devices support 
touch commands, which are identified by key components, such as a tactile sensor.
Tactile sensors are widely employed in mobile devices to perceive touch inputs, 
enhancing the interactivity of the user experience. Whenever a user interacts with 
a mobile device’s screen, the tactile sensor identifies the touch and transmits a 
signal to the device’s processor. Subsequently, the processor interprets this signal, 
triggering particular actions like launching an application or navigating through a 
webpage. Gesture recognition and biometrics are also becoming more common in 
mobile devices, allowing for more advanced and secure methods of user 
interaction.
5.2.2  Software Layer
5.2.2.1  User Interface
A user interface’s success is determined by how discretely people may use it, with­
out interruptions from other interface components. In the context of AR applica­
tions, this is also accurate. Due to AR’s immersive and captivating nature, PARSAT’s 
user interface aims to focus on how students engage with the system.
The primary objective of PARSAT’s user interface is to furnish students with an 
immersive and uninterrupted learning experience, concurrently mitigating potential 
distractions that might impede the learning process. This endeavor is underpinned 
by a deliberate intent to reduce any extraneous interruptions, thereby optimizing the 
efficacy of the learning environment.
The design philosophy governing the user interface is rooted in principles of 
intuitiveness and accessibility. It is meticulously crafted to facilitate user naviga­
tion, offering lucid and concise guidance to steer students through the training mod­
ules seamlessly.
AR technology, integral to PARSAT’s interface, contributes to the realization of 
a more natural and instinctive user interaction paradigm. Students engage with vir­
tual objects in a manner that mirrors their interaction with real-world counterparts, 
employing familiar gestures and movements. The incorporation of tactile sensors 
and gesture recognition further elevates the user experience, enabling students to 
engage with the system in an intuitive and organic manner.
In summation, PARSAT’s user interface is unwavering in its commitment to pri­
oritizing user-friendliness, intuitiveness, and immersive qualities. By meticulously 
addressing these facets, it ensures that students are positioned to embark on an 
engaging and highly effective learning journey, characterized by minimal 
5.2  System Architecture

98
disruptions and maximal educational benefit. In summary, PARSAT’s user interface 
prioritizes user-friendliness, intuitiveness, and immersion, ensuring that students 
benefit from an engaging and effective learning journey with minimal disruptions. 
PARSAT’s user interface is designed by focusing on the essential User Interface 
(UI)—User Experience (UX) AR pillars [17–19] as listed below:
•	 Environment: in the realm of AR application design, meticulous attention to the 
environmental context within which users engage with the application is impera­
tive[20, 21]. This encompasses a comprehensive evaluation of various environ­
mental facets, encompassing lighting conditions, spatial configuration, and the 
safety parameters governing user interactions. Within the context of PARSAT, an 
AR-based educational platform, students were afforded the opportunity to inter­
act with the application within the controlled confines of their university labora­
tories, environments thoughtfully designed to optimize user ergonomics and 
safety. The contextual backdrop within which AR applications are deployed 
bears profound implications, influencing both the application’s performance and 
the quality of the user experience. Notably, the interplay between environmental 
factors and application functionality is a pivotal determinant of efficacy. Factors 
such as lighting levels and spatial dimensions must be meticulously calibrated to 
harmonize with the intended application usage, thereby ensuring a congruent 
and conducive environment. In the case of PARSAT, the tailored design was 
intrinsically aligned with its designated utilization within university laboratories. 
These settings are notably characterized by a deliberate emphasis on user com­
fort and safety. Consequently, lighting conditions and spatial layouts within 
these environments are attuned to the precise requisites of the application, foster­
ing an optimal user experience. Furthermore, stringent safety protocols are typi­
cally instituted to safeguard students’ well-being during application usage. The 
conscientious consideration of the environmental milieu in which the application 
operates underscores the strategic design approach adopted by PARSAT. This 
prescient approach ensures that the application seamlessly integrates into its des­
ignated environment, facilitating both safe and effective utilization as envisaged.
•	 Interaction design: this parameter is also crucial, as the interaction design deter­
mines how the user interacts with the context of PARSAT. The primary gestures 
essential for operating the application and enhancing the AR experience include:
–– Tapping, executed with a gentle touch of the student’s finger, primarily 
employed for pressing buttons and making selections.
–– Double tapping, utilized to zoom in on 3D models.
–– Pinching, involving two fingers brought close together or spread apart to 
adjust the size of 3D models.
–– Rotating, the fundamental gesture for comprehending the spatial aspects of 
3D models from various angles, thereby revealing hidden views.
These interactions are of paramount importance and necessitate thoughtful design 
to ensure they are intuitive, user-friendly, and efficacious in achieving the desired 
outcomes. The gestures should feel natural and comfortable to the user, and the 
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

99
system should offer clear visual feedback to elucidate how user actions impact the 
AR environment. Furthermore, interaction design should maintain consistency 
throughout different sections of the application to prevent confusion and facilitate 
rapid user comprehension and mastery of the system.
•	 Colors: The discipline of color theory, widely acknowledged in diverse design 
domains encompassing print, mobile applications, and web interfaces, bears 
equal relevance in the domain of AR design. In the context of PARSAT, an edu­
cational AR platform, the choice of colors has been scrupulously tailored to align 
with its pedagogical objectives. This strategic color selection ensures that textual 
content remains clearly discernible, with fonts chosen judiciously to optimize 
readability. It is noteworthy that the selection of font type may vary depending on 
contextual factors, with San Serif fonts often favored for enhanced legibility. 
Critical to the effectiveness of color selection in AR applications is the establish­
ment of optimal contrast schemes. This typically entails the utilization of light 
text on a dark background, a configuration empirically recognized as conducive 
to comfortable reading experiences. It is imperative to underscore that the cura­
tion of color palettes within AR applications necessitates a comprehensive 
assessment of various parameters. Environmental factors, including ambient 
lighting conditions specific to the application’s usage setting, merit meticulous 
consideration. Additionally, user-centric factors, including visual abilities and 
individual preferences, play a significant role in color selection. For instance, 
high-contrast color schemes may be more suitable for users with visual impair­
ments, ensuring enhanced visibility. Conversely, subdued and muted color pal­
ettes may be preferred in scenarios where a tranquil and less distracting user 
experience is deemed essential. In summation, the selection of colors in AR 
applications, exemplified by PARSAT, transcends aesthetics to embrace func­
tional and contextual considerations. Each color choice is not only a visual ele­
ment but a strategic component in the optimization of user experience, aligning 
closely with the specific educational objectives and the nuances of the AR appli­
cation’s operational context. Such considerations underscore the interdisciplin­
ary nature of AR design, where visual and functional parameters intersect to 
cultivate engaging and effective user interactions.
•	 Feedback: it is a critical parameter which is considered, defining how students 
will be informed of their activities and the results or outcome of those actions. 
Whether it is the feedback on the assessment score, or feedback encouraging the 
student to continue the effort on training, it is a parameter which adaptive sys­
tems usually integrate. Feedback is an important parameter in any interactive 
system, and especially in adaptive systems like PARSAT. Feedback serves as a 
motivational tool for students, assisting them in monitoring their advancement 
and pinpointing areas requiring enhancement. Feedback can be conveyed in 
diverse formats, including visual, auditory, or haptic modes. For example, in 
PARSAT, the system provides visual feedback by highlighting the correct or 
incorrect answers, and by displaying a progress bar indicating the completion of 
a task. Auditory feedback could be provided through sounds or speech, such as 
5.2  System Architecture

100
congratulatory remarks when the student successfully completes a task. Haptic 
feedback could be provided through vibrations or touch, such as a vibration 
when a button is pressed.
5.2.2.2  3D Rendering Engine
The 3D rendering engine is a combination of the software integrated into the 
PARSAT application. More specifically, this engine maintains an internal 3D repre­
sentation of the virtual scene augmenting the real world.
This internal representation is updated in real-time according to several factors 
such as the user’s profile, student’s interactions, the 3D objects’ behavior, the 
updated knowledge domain, and the fuzzy inference adaptation. Both the hardware 
components, including the CPU and GPU, as well as the data components, are dedi­
cated to empowering the 3D rendering engine for crafting the user interface screens.
The 3D rendering engine holds the responsibility of crafting the 3D graphics 
presented on the screen, utilizing a blend of algorithms and mathematical models. It 
takes into consideration the user’s viewpoint and movements to craft an authentic 
and immersive encounter. Additionally, the engine employs lighting and shading 
effects to infuse depth and realism into virtual objects.
The engine is frequently fine-tuned to maximize the utilization of accessible 
hardware resources, notably the GPU, to ensure a fluid and responsive graphical 
performance. Data components, such as 3D models and textures, are stored in the 
device’s memory and are summoned by the engine as required.
In the context of PARSAT, the 3D rendering engine stands as a pivotal compo­
nent in delivering an engaging and interactive learning journey. It empowers stu­
dents to delve into and interact with 3D models and visualizations, thereby enriching 
their comprehension of intricate concepts.
PARSAT was implemented in a HP Pavilion TP01-2014nv PC (Ryzen 
7-5700G/8GB DDR4/512GB SSD/GeForce GTX 1650/W10, to which a large for­
mat monitor was connected. The Ryzen 7-5700G processor and 8GB of DDR4 
memory provided good performance for running Unity and other software. The 
512GB SSD also helped with faster boot times and loading of large files.
The GeForce GTX 1650 graphics card, classified as a mid-range GPU, exhibited 
commendable performance in executing PARSAT with a high level of graphical 
fidelity, particularly when coupled with a spacious display monitor.
In the development of PARSAT on the PC platform, a comprehensive software 
toolkit played a pivotal role, comprising several integral components. Noteworthy 
among these components were the utilization of the Unity 3D cross-platform game 
engine, specifically version 2020.3.43f1 LTS, alongside the Vuforia Software 
Development Kit (SDK), Autodesk 3ds Max 2020, meticulously crafted custom 
scripts in the C# programming language, the esteemed Visual Studio 2019 inte­
grated development environment (IDE), and the Android Studio Integrated 
Development Environment (IDE).
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

101
Unity 3D distinguishes itself by virtue of its extensive array of tools and func­
tionalities, catering to the needs of developers and designers engaged in the cre­
ation, design, and animation of 3D elements. These tools empower creators by 
providing features such as a robust audio system, networking capabilities, and a 
sophisticated physics engine. The audio system seamlessly integrates soundscapes 
and audio effects, enriching the immersive quality of applications developed using 
this platform.
Networking capabilities inherent to Unity 3D foster the seamless implementa­
tion of multiplayer experiences, substantially enhancing the platform’s versatility. 
This specific feature plays a pivotal role in the development of online multiplayer 
games and collaborative virtual environments, thereby expanding the scope of Unity 
3D beyond traditional gaming.
A pivotal advantage of Unity lies in its cross-platform compatibility, enabling 
developers to produce applications that seamlessly function across multiple plat­
forms. This compatibility, complemented by a unified codebase, streamlines the 
development process, curtails time-to-market, and eliminates the necessity for 
extensive platform-specific modifications. It empowers developers to efficiently tar­
get a diverse array of devices.
Unity 3D’s unwavering commitment to continual evolution is clearly evident 
through its regular iterative updates, introducing fresh features and enhancements. 
This unwavering dedication ensures that Unity 3D consistently maintains its posi­
tion at the forefront of 3D content creation, adapting adeptly to evolving industry 
trends and technological advancements.
Unity 3D finds itself in direct competition with Unreal Engine, another formi­
dable contender in the game engine and application development sphere. While 
both engines offer robust capabilities for crafting interactive 3D content, each pos­
sesses its own distinctive strengths and limitations.
Unity is highly regarded for its user-friendly interface, which fosters accessibil­
ity for developers across different skill levels. Its intuitive design and visual script­
ing tools simplify the development process, enabling swift prototyping and 
experimentation. This accessibility has significantly contributed to the widespread 
adoption of Unity, particularly among indie developers.
In contrast, Unreal Engine has garnered renowned for its advanced graphics 
capabilities and extensive utilization of the C++ scripting language. It excels in 
rendering photorealistic visuals and lends robust support to high-end graphics and 
rendering pipelines, making it the preferred choice for AAA game development and 
the creation of high-fidelity simulations.
It is imperative to acknowledge that Unity 3D and Unreal Engine represent 
merely a fraction of the available game engines, as numerous alternatives exist for 
developers seeking to craft interactive 3D content. Prominent among these alterna­
tives are Godot, CryEngine, and GameMaker Studio, among others. Ultimately, the 
selection of an engine hinges upon the specific requirements and preferences of the 
development team.
In summary, Unity 3D and Unreal Engine stand as potent game engines and 
application development platforms, facilitating the creation of interactive 3D 
5.2  System Architecture

102
content. The ensuing discussion provides a brief comparative overview of these two 
engines, emphasizing their respective strengths and distinctive attributes:
•	 Ease of Use: Unity 3D is widely acknowledged for its user-friendliness and 
lower learning curve, making it an attractive choice for beginners. In contrast, 
Unreal Engine may appear more intricate and challenging to newcomers due to 
its advanced feature set and interface.
•	 Graphics: Unreal Engine is celebrated for its cutting-edge graphical prowess, 
excelling in rendering photorealistic environments with intricate lighting and 
shadow effects. In contrast, Unity 3D, though making substantial progress in 
enhancing its graphics, has not achieved the same advanced level of realism as 
Unreal Engine.
•	 Scripting Languages: Unity 3D predominantly employs the C# scripting lan­
guage, known for its accessibility and productivity benefits, particularly for 
smaller development teams. Unreal Engine, on the flip side, utilizes C++, a lan­
guage known for its power and adaptability, although it comes with a more chal­
lenging learning curve.
•	 Licensing: Unity 3D provides a range of licensing options, including a free ver­
sion with limited features and paid versions offering enhanced features and sup­
port. In contrast, Unreal Engine offers no initial cost for usage but mandates 
developers to pay a royalty fee based on project revenue.
Platforms: Unity 3D stands as a cross-platform engine, accommodating an exten­
sive array of platforms, encompassing desktop, mobile, console, and virtual/aug­
mented reality. Unreal Engine is also versatile in platform support but is particularly 
suited for high-end PC and console development.
In conclusion, the choice between Unity 3D and Unreal Engine is contingent 
upon the unique requirements and preferences of the development team. Each 
engine presents its own set of advantages and drawbacks, with the capacity to 
deliver exceptional interactive 3D content.
PARSAT was integrated with Unity 3D. Unity 3D stands as a potent and versatile 
game engine ideal for crafting interactive 3D applications, encompassing simula­
tions and educational content such as PARSAT. Leveraging Unity 3D equips devel­
opers with an array of resources and functionalities to construct captivating 3D 
worlds. These resources include a visual editor, a robust scripting language (C#), 
and compatibility with numerous platforms and devices.
In addition to Unity 3D, the development of PARSAT encompassed the utiliza­
tion of the Vuforia Software Development Kit (SDK). Within the augmented reality 
(AR) development domain, Vuforia faces competition from several notable counter­
parts, including:
––
1
­
1 http://www.hitl.washington.edu/artoolkit.html
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

103
­
––
2
­
––
3
––
4
––
5
It’s crucial to recognize that these are just a few options among the many AR devel­
opment kits available today. Selecting a specific development kit depends on vari­
ous factors, such as project needs, the intended platform, and the developer’s skills 
and preferences.
PARSAT was seamlessly incorporated with Vuforia due to its widespread popu­
larity and strong support, offering an array of features and extensive platform com­
patibility, rendering it a highly suitable option for numerous AR projects.
Unity supports C# and Python as scripting languages for game development. A 
brief analysis of each is as follows:
•	
6
­
•	
7
In the context of PARSAT, the decision to adopt C# as the primary programming 
language was based on its extensive adoption and prominence within the Unity 
ecosystem. This choice was underpinned by C#’s commendable performance 
2 https://www.wikitude.com/
3 https://www.easyar.com/
4 https://www.kudan.io/
5 https://developer.maxst.com/
6 https://learn.microsoft.com/en-us/dotnet/csharp/
7 https://www.python.org/
5.2  System Architecture

104
attributes and the robust support it enjoys within the Unity game engine. Python can 
serve as a valuable tool for certain tasks, especially for developers already profi­
cient in it.
Furthermore, in the developmental process of PARSAT, Visual Studio was 
employed as the designated integrated development environment (IDE), a selection 
frequently endorsed for the creation of diverse software applications, encompassing 
game development. It is noteworthy that Visual Studio assumes the role of the rec­
ommended IDE for C# scripting within the Unity framework. It is pertinent to 
acknowledge the existence of alternative IDEs endowed with commensurate func­
tionality and features, thereby warranting contemplation:
•	
8
•	
9
•	
10
­
Ultimately, the choice of the integrated development environment (IDE) was con­
tingent upon the specific requirements of the project and the preferences and exper­
tise of the developer.
C# is a programming language that is used when developing PARSAT in Unity 
for scripting gameplay logic, fuzzy logic, Mamdani’s inference algorithm, decision 
making with fuzzy weights, user interfaces, and other components of games. Visual 
Studio offers an array of features and tools designed to facilitate the creation, debug­
ging, and management of C# code in Unity, encompassing:
•	 IntelliSense: Visual Studio’s IntelliSense feature provides code completion and 
suggestions as you type, making it easier to write code and avoid errors.
•	 Debugging tools: Visual Studio provides a range of debugging tools, including 
breakpoints, call stacks, and exception handling, that make it easier to identify 
and fix errors in your code.
•	 Integrated development: Visual Studio integrates seamlessly with Unity, allow­
ing you to edit and debug your scripts directly in the Unity editor.
•	 Community support: Visual Studio has a large and active community of develop­
ers, with a range of resources and tools available for Unity developers.
In summary, the combination of Visual Studio and C# within Unity offers a potent 
and adaptable development environment for crafting games and interactive applica­
tions. This pairing aids in streamlining the development journey, enhancing code 
quality, and optimizing performance.
8 https://www.eclipse.org/
9 https://www.jetbrains.com/idea/
10 https://netbeans.apache.org/
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

105
These tools collectively played a pivotal role in enabling the developer to craft 
and enhance various facets of the PARSAT application, including its augmented 
reality features, 3D models, and user interfaces [22–27]. Altogether, the PARSAT 
development harnessed a comprehensive array of tools and technologies to deliver 
a top-tier educational experience that is engaging and of high quality.
5.2
­
­
Evaluating PARSAT on mobile devices is crucial for assessing its practicality 
and effectiveness. However, it’s essential to acknowledge that results may not apply 
universally to all mobile devices due to disparities in hardware and software 
specifications.
One common challenge in implementing AR solutions is the disparity in technol­
ogy across AR devices. Different mobile devices exhibit varying hardware and 
 
5.2  System Architecture

106
software capabilities, resulting in inconsistent performance and user experiences. 
This poses a significant challenge for developers striving to create applications that 
seamlessly function across a spectrum of devices.
In the case of PARSAT, the comprehensive AR design faced compatibility issues 
with certain students’ smartphones due to hardware limitations. This underscores 
the importance of considering device compatibility during the design and develop­
ment of AR applications. Developers may need to adapt their applications to differ­
ent hardware configurations or narrow down the scope to ensure broader 
compatibility.
To address this challenge, the PARSAT author resolved the issue by installing the 
application on personal tablet devices (specifically, three Samsung Galaxy Tab S5e 
10.5″) that met the necessary hardware and software prerequisites for effective 
operation.
5.2.3  Data Layer
5.2.3.1  Marker Database
PARSAT integrates marker-based AR, requiring a trigger image or a QR code to 
activate the AR experience. The student detects and scans the marker using the 
mobile device’s camera, the image is identified as a marker, and then, the device 
renders the virtual content on top of the marker. This feature allows the student to 
move around the marker and observe the perspectives of the 3D content.
The incorporation of marker-based AR in PARSAT enhances the learning experi­
ence for students, offering a more interactive and immersive approach. This hands-
­on engagement fosters improved comprehension and retention of the subject matter. 
PARSAT’s ability to enable students to navigate around markers and view 3D con­
tent from various perspectives allows for a more intuitive exploration of intricate 
concepts. Overall, the use of marker-based AR in PARSAT can enhance the learning 
experience and help to make education more engaging and effective.
Cloud-based or device-localized are the two categories of marker-based AR. In 
the first category, since the AR assets must be downloaded from the server, a cloud-­
based AR experience may require a few additional minutes to load. In the second 
category, since the AR assets have already been pre-downloaded to the student’s 
mobile device via the application, a localized AR experience may be accessed 
instantly. For greater storage capacity, the choice of the cloud-based AR is pre­
ferred, but localized AR is less expensive and not dependent on network availability.
PARSAT integrates device-localized marker-based AR, which means that the AR 
assets are pre-downloaded onto the user’s device via the application, enabling 
instant access to the AR experience. This approach is less dependent on network 
availability, making it a suitable choice for educational environments where internet 
connectivity may not always be reliable. Additionally, since the AR assets are stored 
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

107
locally, the device-localized approach can be more cost-effective than cloud-based 
AR, as there is no need for additional storage or bandwidth on the server side.
The marker-based AR experience is created using a software development kit 
(SDK), namely Vuforia, one of the best-known AR tools sets available. Vuforia pro­
vides advanced computer vision functionality that enables the AR experiences to 
realistically interact with the 3D geometrical objects displayed at each level.
Vuforia offers a significant advantage by accommodating a wide array of devices, 
including Android and iOS smartphones, tablets, as well as AR headsets like 
Microsoft Hololens and Magic Leap. This versatility broadens the scope for a more 
adaptable and immersive AR experience, ensuring accessibility to a larger audience. 
Furthermore, Vuforia equips developers with the necessary tools and resources for 
the swift and efficient creation of robust AR experiences, allowing them to concen­
trate on delivering engaging and effective educational content.
­
11
5.3
5.4
Image targets are a critical component of marker-based AR, as they enable the 
AR system to identify and track the marker, allowing the virtual content to be ren­
dered accurately. The basic plan of Vuforia provides this essential feature, making it 
a suitable choice for PARSAT.  The license key is used to enable the AR 
11 https://developer.vuforia.com/
 
5.2  System Architecture

108
 
functionality within the PARSAT application, allowing students to scan and view 
the AR content using their mobile devices.
The image targets in PARSAT are created using the Vuforia Target Manager. The 
supported formats for the input images are JPEG or PNG images in either RGB or 
grayscale format.
Size limitations are in place when generating image targets. Input images should 
not exceed 2.25MB in file size and must possess a minimum width of 320 pixels. 
These specifications guarantee that the image targets are appropriately sized for 
processing on various devices.
The features of the input images are extracted and stored in the marker database, 
which is then packaged together with the PARSAT application. When the user scans 
the marker using their mobile device’s camera, the system matches the features of 
the input image with those stored in the marker database to identify the marker and 
display the associated AR content. This process allows the AR system to render the 
virtual content accurately on top of the marker, creating an immersive and engaging 
educational experience for students.
5.5
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

109
 
Creating image targets involves two primary steps. The initial step revolves 
around the design of the target image itself. This entails the selection of a suitable 
image and its preparation for use as an image target. Such preparations may involve 
fine-tuning brightness and contrast, as well as the removal of undesired backgrounds 
or noise.
5.6
­
­
The Vuforia Target Manager is an online platform that is used to create and man­
age image targets for use in the AR application. The Target Manager provides a 
user-friendly interface that allows image uploading and processing to create image 
targets.
Once the image targets have been created, they can be downloaded as a package 
and integrated into the PARSAT application. This allows the PARSAT application 
to recognize and track the image targets, and display AR content on top of them. By 
using the Vuforia Target Manager, developers can easily create and manage image 
targets, and ensure that the AR experience in the PARSAT application is accurate 
and engaging.
When an image is uploaded to the Target Manager, it undergoes processing to 
create data and visual representations of its attributes. This process involves 
5.2  System Architecture

110
 
extracting features from the image and evaluating its visual traits, such as contrast 
and brightness.
The Vuforia Target Manager provides an anticipated detection and tracking per­
formance score for each image target, which can help developers evaluate the suit­
ability of the image for use as a marker in the PARSAT application. The performance 
score takes into account factors such as the image quality, lighting conditions, and 
contrast, and can help developers choose the best image targets for their AR 
experience.
5.7
­
5.2.3.2  3D Models Database
The 3D model library within the PARSAT application plays a pivotal role in enabling 
student interaction with virtual models and fostering spatial visualization skills. In 
the endeavor to produce these indispensable 3D models, developers are presented 
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

111
 
with a spectrum of choices within the realm of 3D modeling software. These alter­
natives can be systematically categorized into two principal types: those that are 
available free of charge and those that necessitate a paid license for usage. Within 
the domain of freely accessible options, prominent software tools such as Blender, 
SketchUp, and Tinkercad emerge as noteworthy selections. These applications offer 
a comprehensive suite of functionalities encompassing 3D modeling, texturing, and 
5.2  System Architecture

112
animation. These choices are particularly attractive for beginners and those with 
budget constraints.
12
13
14
­
15
16
Conversely, licensed 3D modeling software introduces alternatives that encom­
pass industry-standard applications, including but not limited to Autodesk 3ds Max, 
Maya, and Cinema 4D, among others. These tools offer a more sophisticated set of 
features and capabilities, rendering them particularly suitable for professional utili­
zation across domains like architecture, engineering, and animation.
­
17
­
18
­
19
­
20
Irrespective of the software employed, the resultant 3D models assume a pivotal 
role within the framework of the PARSAT application. Their meticulous design and 
12 https://www.sketchup.com/plans-and-pricing/sketchup-free
13 https://www.blender.org/
14 https://www.autodesk.com/products/fusion-360/personal
15 https://www.shapr3d.com/
16 https://www.vectary.com/
17 https://www.autodesk.com/products/3ds-max/overview?term=1-YEAR&tab=subscription
18 https://www.rhino3d.com/
19 https://www.autodesk.com/products/maya/overview?term=1-YEAR&tab=subscription
20 https://www.maxon.net/en/cinema-4d
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

113
optimization are imperative, as they must facilitate swift and precise rendering 
across a diverse array of devices.
The selection of the 3D modeling software considered several factors including:
•	 Object design: Different software is better suited for different types of objects. 
Some software is optimized for designing characters, while others are better for 
architectural or mechanical designs.
•	 Interface: The user interface of the software is crucial to consider as it can impact 
the ease of use and productivity of the user.
•	 Community support: Having a supportive community behind the software can 
make a significant difference in the learning process.
•	 Cost: The cost of the software is also an important factor to consider, especially 
if a paid license is required.
Considering these factors, PARSAT’s 3D model’s database was prepared using 
Autodesk 3ds Max due to the following reasons:
•	 The author’s background is based on engineering education, and as such, the 
author is trained, both at an undergraduate and professional level, at Autodesk’s 
products of AutoCAD, 3ds Max, and Tinkercad.
•	 Additionally, being a Ph.D. student at the Laboratory of Educational Technology 
and e-Learning Systems, the author has free access to Autodesk’s products and 
services, renewable as long as the author remains eligible, making it a cost-­
effective option.
•	 Furthermore, 3ds Max is widely used in many industries for generating graphics, 
including mechanical and organic objects. Its toolset is highly capable, making it 
a powerful tool for modeling. The software is also commonly used in the engi­
neering, manufacturing, educational, and medical industries for visualization 
needs, making it a versatile choice.
5.8
­
All 3D models were seamlessly transferred from Autodesk 3ds Max to Unity, 
employing the Autodesk .fbx format as the chosen conduit. The selection of this 
format was predicated on its manifold advantages during the process of importing 
meshes from 3ds Max into Unity.
Primarily, the .fbx format facilitates the import of nodes imbued with attributes 
such as position, rotation, and scale from 3ds Max to Unity. This affords the preser­
vation of the intricate structure and hierarchy inherent in the 3D models originally 
conceived in 3ds Max. Such preservation significantly economizes time and effort 
that would otherwise be expended in reconstituting these models within the Unity 
environment.
5.2  System Architecture

114
 
Secondly, the .fbx format lends itself to the importation of meshes replete with 
vertex colors from 3ds Max to Unity. The granular control over vertex colors per­
mits the creation of meticulously detailed and lifelike textures.
Thirdly, the format accommodates the import of materials complete with diffuse 
textures and colors from 3ds Max to Unity. This seamless transition ensures that the 
materials and textures meticulously applied to the 3D models within 3ds Max are 
faithfully transposed into Unity, simplifying the endeavor of crafting realistic and 
intricate virtual environments.
Lastly, animations painstakingly fashioned in 3ds Max find a harmonious inte­
gration into Unity through the .fbx format. This facilitates the incorporation of com­
plex and dynamic interactions between objects and characters within the game or 
application.
In summation, the capability to import nodes, vertex-colored meshes, materials, 
and animations from 3ds Max into Unity via the .fbx format serves as a profound 
streamlining mechanism for the construction of 3D environments and characters 
in Unity.
5.2.3.3  Interaction Model
Within the domain of augmented reality (AR) technology, the interaction model 
expounded in this chapter epitomizes a quintessential archetype. AR fundamentally 
revolves around the overlaying of digital content onto the tangible real-world envi­
ronment. In the case at hand, the AR application endeavors to enrich the educational 
journey of students by granting them the capacity to interact with 3D models of 
objects, thus affording a more verisimilar and immersive experience.
The crux of the interaction model hinges on the deployment of markers, pre­
defined images meticulously cataloged within a database. When students align their 
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

115
mobile device’s camera with one of these markers, the application adeptly discerns 
the marker’s identity and overlays the corresponding 3D model atop it. This engen­
ders an illusion where students perceive the 3D model coexisting within the tangible 
world, akin to a corporeal entity.
Moreover, students are empowered to engage actively with the 3D model by 
manipulating its size, position, and orientation. This facet of interaction bequeaths 
a deeper comprehension of the spatial intricacies inherent in the object. Such inter­
active pedagogy assumes paramount significance in educational contexts, as it 
empowers students to probe and manipulate 3D objects in a manner heretofore 
inconceivable with conventional learning materials.
In summary, the interaction model epitomizes an influential and innovative peda­
gogical approach that engages students actively in the learning process, thereby 
augmenting their grasp of 3D objects and their contextual understanding.
The previously referenced term encapsulates the intricate process of amalgamat­
ing Vuforia with Unity to institute augmented reality (AR) functionalities within an 
application. Vuforia stands as a venerated AR platform, replete with tools for the 
detection and tracking of image targets. These image targets serve as conduits for 
the superimposition of 3D content onto tangible real-world objects.
The inaugural step in the Vuforia-Unity amalgamation entails the procurement of 
the Vuforia package, which is subsequently imported into the Unity editor. 
Subsequent to this importation, the Unity main camera is supplanted with the spe­
cialized Vuforia engine AR camera, tailored to the precise demands of detecting and 
tracking image targets.
The subsequent pivotal step revolves around the integration of the Vuforia license 
key into the Unity project. This key, graciously furnished by Vuforia, stands as the 
linchpin for enabling AR functionalities within the application.
Following this, the marker database, an inventory of predefined images primed 
for service as image targets within the AR application, is seamlessly incorporated 
into the Unity project.
The denouement of this intricate process materializes when the application 
adroitly overlays 3D content upon an image target, facilitated by the Vuforia engine. 
Once the camera identifies a designated image target, the corresponding 3D content 
is artfully superimposed, birthing an immersive augmented reality experience for 
the end-user.
In synthesis, the orchestration of Vuforia with Unity unfolds through a meticu­
lously orchestrated sequence of steps, encompassing the importation of the Vuforia 
package, the substitution of the main camera with the Vuforia AR camera, the infu­
sion of the Vuforia license key, and the integration of the marker database. The 
culmination of these steps bequeaths the application with the capability to seam­
lessly drape 3D content over tangible real-world objects, ultimately engendering a 
more immersive and interactive user experience.
­
5.9
­
5.2  System Architecture

116
 
To this direction, the “Import Package” option was selected from the “Assets” 
menu in the Unity editor and then the Vuforia package, that was downloaded, 
was chosen.
Once the package is imported, it can be verified that the Vuforia engine has been 
successfully imported by checking the “Hierarchy” panel in the Unity editor. The 
Vuforia engine will have created a new hierarchy in the panel, which includes the 
“ARCamera” object, among others.
The “ARCamera” object is the main camera used for augmented reality applica­
tions in Unity with Vuforia. It is responsible for detecting and tracking image targets 
and rendering 3D content on top of them.
Once the Vuforia engine is successfully imported and the “ARCamera” object is 
present in the Unity hierarchy, the next step involves setting up the image targets 
and 3D content to be overlaid on top of them.
In the setup process for using Vuforia in Unity, the main camera in Unity is 
deleted, and the AR camera from the Vuforia package is added instead. This is 
because the AR camera is responsible for detecting and tracking image targets and 
rendering 3D content on top of them.
5.10
Finally, the marker database is imported into the Unity project. The marker data­
base contains the image targets that Vuforia will use to detect and track in order to 
overlay 3D content on top of them. Once the marker database is imported, the user 
can associate the image targets with the corresponding 3D models in the Unity 
scene and configure the interactions and behaviors of the 3D content.
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

117
 
5.11
The image target behavior script includes properties for setting the type of image 
target, the marker database to use, and the marker to associate with the image target. 
These properties are used to specify which image target Vuforia should detect and 
track, and which 3D content should be rendered on top of it.
Following the configuration of the image target behavior script, users may advance 
by establishing an association between the script and an image target object situated 
5.2  System Architecture

118
 
within the Unity scene. Furthermore, they possess the capability to affix the 3D content 
designated for superimposition onto the image target, assigning it as a subordinate ele­
ment of said image target. As a result of this procedural arrangement, the opportunity 
arises to meticulously refine the conduct of the aforementioned 3D content, enhancing 
its capacity to responsively engage with user interactions, which may encompass tactile 
input or gesture-based commands. This intricate interactive response framework is 
instrumental in furnishing users with both visual feedback and pertinent informational 
content, thereby enriching their overall experiential engagement.
The successful import of the Vuforia engine is verified by checking the 
“Hierarchy” panel in the Unity Editor.
After importing the Vuforia package, the Vuforia engine’s AR camera appears in 
the “Hierarchy” panel. The AR camera is responsible for detecting and tracking 
image targets, and rendering 3D content on top of them.
In the case of PARSAT, the AR camera did not appear in the “Hierarchy” panel 
at first, so it was necessary to restart Unity and re-import the Vuforia package. 
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

119
Additionally, it was important to make sure that the correct version of the Vuforia 
package was imported for the version of Unity being used, as compatibility issues 
occasionally cause errors or issues with the AR camera and other Vuforia features.
5.3  Implementation of the System
5.3.1  User Interface of PARSAT
­
5.12
5.13
­
5.14
It is important to point out that the feature of the grayed-out menu items, which 
are enabled as the student progresses through the training tasks, can help provide a 
sense of achievement and progress, which in turn can be motivating for students.
5.15
­
5.16
 
5.3  Implementation of the System

120
 
 
­
­
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

121
 
 
5.17
5.3  Implementation of the System

122
 
 
5.18
The operation of augmenting a 3D model involves the following steps:
•	 Printing out a marker that correspond to the specific 3D model of each SOLO 
level. The marker is designed in such a way that PARSAT can recognize it and 
use it as an anchor point for overlaying the 3D model.
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

123
•	 Launching the PARSAT on the mobile device and pointing the camera at the 
marker. The application uses the device’s camera to detect the marker and over­
lay the 3D model onto the corresponding marker position.
•	 Once the 3D model is overlaid on the marker, the student can interact with and 
can rotate and zoom in/out using touch gestures on the device’s screen.
5.19
­
5.20
 
 
5.3  Implementation of the System

124
5.3.2  Fuzzy Logic Controller Implementation 
with C# Scripting
Fuzzy logic controller (FLC) is based on Mamdani’s inference engine, which was 
developed in the 1970s as a way to deal with imprecise or uncertain information. 
FLC uses fuzzy sets and fuzzy rules to approximate human reasoning and decision-­
making processes.
In the fuzzy logic controller, crisp inputs are first translated into fuzzy values 
using linguistic variables, which represent the qualitative aspects of the system 
being controlled.
The fuzzy rules in the FLC specify how the input fuzzy values should be com­
bined to produce output fuzzy values, which are then defuzzified to produce crisp 
outputs.
Mamdani’s inference engine uses a method called “max-min composition” to 
combine the input fuzzy values according to the fuzzy rules. This involves taking 
the maximum of the minimum values of the fuzzy sets that correspond to each input 
and rule. The resulting output fuzzy set is then defuzzified to produce a crisp out­
put value.
Overall, fuzzy logic controller is useful for controlling systems that are complex, 
nonlinear, or poorly understood, as it can capture and approximate the behavior of 
these systems in a more intuitive way than traditional control methods.
5.3.2.1  System Initialization
5.21
 
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

125
5.3.2.2  Linguistic Variables and Membership Functions
­
5.22
5.22
5.23
­
 
 
5.3  Implementation of the System

126
5.3.2.3  Fuzzification Process Implementation
The fuzzification process evaluates the crisp inputs against the membership func­
tions of the linguistic variables. The membership functions are an abstract class, 
with the method “getOutput”. The objects, which inherit the class, need to define 
their getOutput(double) function. The fuzzy controller capabilities are extended by 
implementing all the necessary membership functions.
The fuzzification method returns the list of the fuzzy numbers, each of which has 
two parts, namely the name of the function and the amount of contribution. Then, 
the fuzzy numbers are added to a fuzzy set for further process. After the fuzzifica­
tion of all inputs is completed, they are added to a list of fuzzy sets.
5.3.2.4  Rules of the System
5.24
­
5.24
 
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

127
5.25
4.2
5.26
5.3.2.5  Evaluation of the Rules
­
5.27
 
5.3  Implementation of the System

128
 
 
 
5.3.2.6  Defuzzification
5.28
5.4  Summary
Chapter 5 presented the architecture of the system, analyzing in depth all the layers 
involved in the training application, namely the hardware layer, the software layer, 
and the data layer. For each layer, a detailed representation of the module was made. 
The second part of Chap. 5 presented the implementation of the system, by provid­
ing screenshots of the system’s environment, the user interface of a training sce­
nario, while the last section presents parts of the scripts in C# programming 
language, used for the implementation of the fuzzy system controller.
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

129
References
1.	Z. Kanetaki et al., “Acquiring, Analyzing and Interpreting Knowledge Data for Sustainable 
Engineering Education: An Experimental Study Using YouTube,” Electronics (Basel), vol. 11, 
no. 14, 2022, https://doi.org/10.3390/electronics11142210.
2.	A. Marougkas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Virtual Reality in Education: 
A Review of Learning Theories, Approaches and Methodologies for the Last Decade,” 
Electronics (Basel), vol. 12, no. 13, 2023, https://doi.org/10.3390/electronics12132832.
3.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Enriching Mobile Learning Software with 
Interactive Activities and Motivational Feedback for Advancing Users’ High-Level Cognitive 
Skills,” Computers, vol. 11, no. 2, 2022, https://doi.org/10.3390/computers11020018.
4.	F. Giannakas, C. Troussas, A. Krouska, C. Sgouropoulou, and I. Voyiatzis, “XGBoost and 
Deep Neural Network Comparison: The Case of Teams’ Performance,” in Intelligent Tutoring 
Systems, A. I. Cristea and C. Troussas, Eds., Cham: Springer International Publishing, 2021, 
pp. 343–349.
5.	A. Krouska, C. Troussas, and C. Sgouropoulou, “Fuzzy Logic for Refining the Evaluation 
of Learners’ Performance in Online Engineering Education,” European Journal of 
Engineering Research and Science, vol. 4, pp. 50–56, Jun. 2019, https://doi.org/10.24018/
ejers.2019.4.6.1369.
6.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Towards a Reference Model to Ensure the 
Quality of Massive Open Online Courses and E-Learning,” in Brain Function Assessment 
in Learning, C.  Frasson, P.  Bamidis, and P.  Vlamos, Eds., Cham: Springer International 
Publishing, 2020, pp. 169–175.
7.	A.  Marougkas, C.  Troussas, A.  Krouska, and C.  Sgouropoulou, “How personalized and 
effective is immersive virtual reality in education? A systematic literature review for the last 
decade,” Multimed Tools Appl, 2023, https://doi.org/10.1007/s11042-023-15986-7.
8.	A. Marougkas, C. Troussas, A. Krouska, and C. Sgouropoulou, “A Framework for Personalized 
Fully Immersive Virtual Reality Learning Environments with Gamified Design in Education,” 
2021. https://doi.org/10.3233/FAIA210080.
9.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Dynamic Detection of Learning Modalities 
Using Fuzzy Logic in Students’ Interaction Activities,” in Intelligent Tutoring Systems, 
V. Kumar and C. Troussas, Eds., Cham: Springer International Publishing, 2020, pp. 205–213.
10.	A. Krouska, C. Troussas, and C. Sgouropoulou, “A novel group recommender system for 
domain-independent decision support customizing a grouping genetic algorithm,” User Model 
User-adapt Interact, 2023, https://doi.org/10.1007/s11257-023-09360-3.
11.	A. Krouska, C. Troussas, K. Kabassi, and C. Sgouropoulou, “An Empirical Investigation of 
User Acceptance of Personalized Mobile Software for Sustainability Education,” Int J Hum 
Comput Interact, pp. 1–8, Aug. 2023, https://doi.org/10.1080/10447318.2023.2241614.
12.	C.  Papakostas, C.  Troussas, A.  Krouska, and C.  Sgouropoulou, “Personalization of the 
Learning Path within an Augmented Reality Spatial Ability Training Application Based on 
Fuzzy Weights,” Sensors, vol. 22, no. 18, 2022, https://doi.org/10.3390/s22187059.
13.	C. Troussas, C. Papakostas, A. Krouska, P. Mylonas, and C. Sgouropoulou, “Personalized 
Feedback Enhanced by Natural Language Processing in Intelligent Tutoring Systems,” 
in Augmented Intelligence and Intelligent Tutoring Systems, C.  Frasson, P.  Mylonas, and 
C.  Troussas, Eds., Cham: Springer Nature Switzerland, 2023, pp.  667–677. https://doi.
org/10.1007/978-3-031-32883-1_58.
14.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Measuring User Experience, 
Usability and Interactivity of a Personalized Mobile Augmented Reality Training System,” 
Sensors, vol. 21, no. 11, p. 3888, Jun. 2021, https://doi.org/10.3390/s21113888.
15.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “PARSAT: Fuzzy logic for 
adaptive spatial ability training in an augmented reality system,” Computer Science and 
Information Systems, vol. 20, no. 4, 2023, https://doi.org/10.2298/CSIS230130043P.
References

130
16.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “On the development of a 
personalized augmented reality spatial ability training mobile application,” in Frontiers in 
Artificial Intelligence and Applications, IOS Press, 2021, pp. V–VI. https://doi.org/10.3233/
FAIA210078.
17.	X.  Wang, S.  K. Ong, and A.  Y. C.  Nee, “A comprehensive survey of augmented real­
ity assembly research,” Adv Manuf, vol. 4, no. 1, pp.  1–22, 2016, https://doi.org/10.1007/
s40436-015-0131-4.
18.	F.  Redzuan, A.-N.  A. Khairuddin, and N.  A. Daud, “Emotional augmented reality-based 
mobile learning design elements: a kansei engineering approach,” Indones. J. Electr. Eng. 
Comput. Sci, vol. 14, no. 1, pp. 413–420, 2019.
19.	T. Masood and J. Egger, “Adopting augmented reality in the age of industrial digitalisation,” 
Comput Ind, vol. 115, p. 103112, 2020.
20.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “User acceptance of augmented 
reality welding simulator in engineering training,” Educ Inf Technol (Dordr), vol. 27, no. 1, 
pp. 791–817, Jan. 2022, https://doi.org/10.1007/s10639-020-10418-7.
21.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Exploring Users’ Behavioral 
Intention to Adopt Mobile Augmented Reality in Education through an Extended Technology 
Acceptance Model,” Int J Hum Comput Interact, vol. 39, no. 6, pp. 1294–1302, 2023, https://
doi.org/10.1080/10447318.2022.2062551.
22.	M. Iakovidis, C. Papakostas, C. Troussas, and C. Sgouropoulou, “Empowering Responsible 
Digital Citizenship Through an Augmented Reality Educational Game,” in Novel & Intelligent 
Digital Systems: Proceedings of the 3rd International Conference (NiDS 2023), K. Kabassi, 
P. Mylonas, and J. Caro, Eds., Cham: Springer Nature Switzerland, 2023, pp. 31–39.
23.	P.  Strousopoulos, C.  Troussas, C.  Papakostas, A.  Krouska, and C.  Sgouropoulou, 
“Revolutionizing Agricultural Education with Virtual Reality and Gamification: A Novel 
Approach for Enhancing Knowledge Transfer and Skill Acquisition,” in Novel & Intelligent 
Digital Systems: Proceedings of the 3rd International Conference (NiDS 2023), K. Kabassi, 
P. Mylonas, and J. Caro, Eds., Cham: Springer Nature Switzerland, 2023, pp. 67–80.
24.	C.  Papakostas, C.  Troussas, P.  Douros, M.  Poli, and C.  Sgouropoulou, “CoMoPAR: A 
Comprehensive Conceptual Model for Designing Personalized Augmented Reality Systems 
in Education,” in Novel & Intelligent Digital Systems: Proceedings of the 3rd International 
Conference (NiDS 2023), K. Kabassi, P. Mylonas, and J. Caro, Eds., Cham: Springer Nature 
Switzerland, 2023, pp. 67–79.
25.	P. Strousopoulos, C. Papakostas, C. Troussas, A. Krouska, P. Mylonas, and C. Sgouropoulou, 
“SculptMate: Personalizing Cultural Heritage Experience Using Fuzzy Weights,” in Adjunct 
Proceedings of the 31st ACM Conference on User Modeling, Adaptation and Personalization, 
in UMAP ’23 Adjunct. New York, NY, USA: Association for Computing Machinery, 2023, 
pp. 397–407. https://doi.org/10.1145/3563359.3596667.
26.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Exploration of Augmented 
Reality in Spatial Abilities Training: A Systematic Literature Review for the Last Decade,” 
Informatics in Education, vol. 20, no. 1, pp. 107–130, Mar. 2021, https://doi.org/10.15388/
infedu.2021.06.
27.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Modeling the Knowledge of 
Users in an Augmented Reality-Based Learning Environment Using Fuzzy Logic,” in Lecture 
Notes in Networks and Systems, A. Krouska, C. Troussas, and J. Caro, Eds., Cham: Springer 
International Publishing, 2023, pp. 113–123. https://doi.org/10.1007/978-3-031-17601-2_12.
5  Artificial Intelligence-Enhanced PARSAT AR Software: Architecture…

131
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024 
C. Papakostas et al., Special Topics in Artificial Intelligence and Augmented 
Reality, Cognitive Technologies, https://doi.org/10.1007/978-3-031-52005-1_6
Chapter 6 
Multi-model Evaluation of the Artificial 
Intelligence-Enhanced PARSAT AR 
Software 
Abstract  This chapter of the book delves into the meticulous evaluation of an 
Artificial Intelligence-enhanced Augmented Reality (AR) mobile training system 
designed to enhance spatial ability training. This chapter adopts a multi-model eval­
uation approach, employing various research methods and techniques to compre­
hensively assess the system’s effectiveness and impact. The chapter commences 
with an overview stressing the importance of evaluating the system’s impact on 
spatial ability training and introduces the need for a comprehensive evaluation 
framework. It then delves into the “Evaluation Framework,” outlining the overall 
structure, research sample, and participant preparation for the training phase. The 
“t-Test Analysis of Students’ Feedback” section focuses on analyzing participant 
feedback, utilizing t-test analysis to identify differences in feedback between the 
experimental and control groups. This sheds light on participants’ perceptions and 
satisfaction with the system. Next, the “Comparative Analysis of Pre-Test/Post-Test 
Model” assesses the system’s impact on spatial ability development through a pre-­
test and post-test model, providing valuable insights into its effectiveness. The 
chapter also introduces an “Extended Technology Acceptance Model” tailored to 
evaluate the human-system interaction, exploring factors influencing system accep­
tance and usability. 
6.1  Overview 
The current chapter presents the evaluation of the system, which is a significant 
phase, determining the software’s usability. The evaluation is deployed in multiple 
levels, in terms of quantitative measurements, questionnaires’ reliability, t-tests, 
pre-test and post-test analysis, and an extended acceptance model [1, 2], so that both 
pedagogical affordance and learning outcomes have been thoroughly evaluated.

132
6.2  Evaluation Framework 
The evaluation of the proposed system is an important stage of the current research, 
and it is based on well-established evaluation frameworks [3, 4], in order to produce 
more accurate results and improve the usability of the software. According to the 
overview on evaluation of training [5], the experimental measurement is one of the 
most popular and efficient methodologies, and as such, this technique is integrated 
into the current evaluation. 
The Lynch and Ghergulescu framework [6] is used for PARSAT’s evaluation, 
which is specifically oriented to evaluate adaptive and intelligent learning systems. 
The proposed framework comprises four distinctive evaluation criteria, namely a) 
learning, and training, b) system, c) user experience, and d) affective dimension. 
More specific, each criterion serves as a separate factor contributing to an overall 
framework. Learning and training assessment involves the evaluation of the effec­
tiveness of the system by measuring the volume of the finished learning activities, 
and the duration of the time spent on each learning improvement. 
In terms of the system’s accuracy, the algorithmic approach is evaluated on how 
precisely the system fits standardized tests and determines the student model, which 
is critical for the adaptivity process. 
The criterion of the user experience evaluates the ease with which users operate 
the system and their level of satisfaction and actual intention of using the system in 
the future. This dimension involves the human-computer interaction (HCI) user 
experience, the system’s usefulness and the students’ behavioral intention towards 
using it. 
­
6.1
6.2.1  Research Sample 
The evaluation of PARSAT took place during the winter academic semester 
2022–2023, while students took the following courses: (a) Computer-Aided-Design, 
(b) Technical Drawing, and (c) 3D Monument Modeling, at an undergraduate cur­
riculum of a public University, located in the nation’s capital. 
­
­
6.2
The assessment process involved the active participation of three faculty mem­
bers, who contributed by presenting the system to students, demonstrating its func­
tionality, and providing guidance to students throughout the experiment.
6  Multi-model Evaluation of the Artificial Intelligence-Enhanced PARSAT AR Software

133
Table 6.1  Evaluation framework [6] 
Evaluation 
direction
Attribute
Description
References 
Learning and 
training 
Effectiveness
Learning improvements (with and without 
revisions); 
Amount of completed, or studied content (in 
comparison with other learning instructions) 
[7–10] 
System
Efficiency
How efficient is the use of the time
[7, 11] 
Accuracy
How accurate the user model is (i.e., how accurate 
is the system grading in comparison with their 
tests/exams) and how accurate the 
recommendation algorithms are (higher accuracy 
scores or lower predictive errors) 
Usability/ 
User 
experience 
Ease of use and 
satisfaction 
How easy is to use the system
[8, 12, 13] 
Affective
Engagement, 
motivation 
How engaged are the learners both in class and out 
of class 
[6, 14]
Table 6.2  Population demographics 
Measure
Item
Frequency 
Percentage 
(%) 
Sample size
240
100.0 
Gender
Male
151
62.9 
Female
88
36.7 
Non-binary
1
0.4 
Age
15–17
0
0 
18–19
199
82.9 
Over 20
41
17.1 
Level of prior 
knowledge 
None
198
82.5 
Technical background
42
17.5 
Computer skills
Knowledge of computers at a high level 
Motivation
All students wanted to achieve a high grade at 
the attended course
6.2.2  Training Preparation 
The instructors evenly divided the population into two groups of 120 students. The 
experimental group, namely group A, was instructed to run the PARSAT indepen­
dently while utilizing the system’s adaptability. For instance, the modeling of stu­
dents’ knowledge levels enabled them to watch video tutorials of various lengths 
and rotate 3D objects of various complexity to see and comprehend their structures, 
and generally engage in various learning activities adjusted to their unique profiles. 
The control group, namely group B, used the same instructional material and 
exercises, without any customization based on the students’ individual profiles. The 
6.2  Evaluation Framework

134
students were given instructions on how to carry out the learning activities, which 
included the same content and approach of the learning activity presented in 
group A. 
However, the visualization and explanation techniques were different for both 
groups. The experimental group with AR application could use PARSAT and see the 
system in action on their smartphones and/or tablets and leverage the proposed 
framework to derive pedagogically meaningful semantics, while group B did not 
use PARSAT.  The educators were involved in the educational procedure in 
both groups. 
To carry out the measurement tests, a procedure was implemented for each par­
ticipant in both the experimental and control groups. The PSVT:R test was admin­
istered on the days and times corresponding to the start of individual training 
sessions for the experimental group participants. Each participant received a desig­
nated time and day for their training sessions, which were spread across vari­
ous days. 
Each session, lasting 45 min in duration, was individually administered to dis­
tinct groups of participants. These sessions were distributed across various days 
throughout the week. Both the experimental and control groups were again con­
tacted to conduct the tests, after each participant had finished the sessions and, con­
sequently, the training. Pre- and posttest results from the group that engaged in a 
visuospatial mental task were acquired in order to compare and confirm if there 
were significant differences. 
Under the guidance of the three faculty members, the students were handed ques­
tionnaires to complete at the completion of the semester. The questions were orga­
nized based on the Lynch-Ghergulescu framework. 
6.3  t-Test Analysis of Students’ Feedback 
At the end of the semester, after the successful completion of all three courses, the 
two groups were delivered a questionnaire [4, 15, 16] and were asked to respond to 
the following questions, using a 10-point Likert scale ranging from “Not at all” (0), 
to “Very much” (10): 
•	 How much did the activities match your level of knowledge? (Q1); 
•	 Was the quantity of the activities used efficient? (Q2); 
•	 Did the activities’ level of complexity enhance your learning? (Q3). 
6.3 6.4
6.5
First, two conditions are formed, namely an experimental condition, in which 
students receive the AR-assisted approach, and a control condition in which they do 
not. The two conditions were compared to define whether the difference between 
them was clear enough or not. In this context, the t-test was utilized to ascertain 
6  Multi-model Evaluation of the Artificial Intelligence-Enhanced PARSAT AR Software

135
Table 6.3  t-Test 
results of Q1 
Group A Group B 
Mean
8.236
6.581 
Variance
1.053
0.368 
Observations
120
120 
Hypothesized mean 
difference 
0 
df
239 
t Stat
16.900 
P (T ≤ t) one-tail
<0.001 
t Critical one-tail
1.651 
P (T ≤ t) two-tail
<0.001 
t Critical two-tail
1.970 
Table 6.4  t-Test 
results of Q2 
Group A Group B 
Mean
8.899
6.500 
Variance
0.772
0.415 
Observations
120
120 
Hypothesized mean difference
0 
df
270 
t Stat
26.785 
P (T ≤ t) one-tail
<0.001 
t Critical one-tail
1.651 
P (T ≤ t) two-tail
<0.001 
t Critical two-tail
1.969 
Table 6.5  t-Test 
results of Q3 
Group A Group B 
Mean
9.047
6.378 
Variance
1.025
0.618 
Observations
120
120 
Hypothesized mean difference
0 
df
277 
t Stat
25.333 
P (T ≤ t) one-tail
<0.001 
t Critical one-tail
1.650 
P (T ≤ t) two-tail
<0.001 
t Critical two-tail
1.969
6.3  t-Test Analysis of Students’ Feedback

136
whether the disparities between the two scenarios had statistical significance or 
were simply the result of random variations. Within the framework of the t-test, the 
p-value held significance, with the t-value serving as an intermediate step for its 
calculation. 
•	 Condition 0 (null hypothesis): μ1 = μ2 (group A and group B means are equal) 
•	 Condition 1: μ1 ≠ μ2 (group A and group B means are not equal) 
­
­
6.3
6.4
6.5
These results furnish substantial grounds for rejecting the null hypothesis, 
indicating significant variations in means between both groups across all three 
questions. 
6.3 6.5
­
­
­
6.4  Comparative Analysis of Pre-test/Post-test Model 
in Achieving the Learning Outcomes 
In order to compare the learning outcome between the two groups and assess the 
improvement in their knowledge, the pre-test and post-test non-equivalent groups 
design was used [4, 17–19]. In particular, the same pre-test was delivered to each 
student of group A and group B to evaluate their prior domain knowledge.
6  Multi-model Evaluation of the Artificial Intelligence-Enhanced PARSAT AR Software

137
The PSVT:R test consists of 30 questions, showing objects in two different posi­
tions. The first object is rotated on the X, Y or Z-axis, to show the rotation pattern. 
A second object is presented with five alternative views, one represents the second 
object subjected to the same rotation as the example. Coordinate axes were added to 
the first and second stimulus objects, but they were not added to the five solution 
choices. The first stimulus object was shown in its new, rotated position [20]. 
6.6
6.7
21
6.8
­
However, the control group achieved an improvement to a lesser extent than in 
the experimental group, demonstrating the benefits that the proposed approach 
brought to students’ learning.
Table 6.6  t-Test results of 
pre-test and post-test 
Group A Group B 
Pre-test mean
4.973
5.014 
Post-test mean
6.027
5.493 
Difference
1.054
0.480 
Standard 
deviation 
0.932
0.837 
Pearson 
correlation 
0.828
0.892 
t Stat
−13.765 −6.974 
p-value
<0.001 
<0.001 
6.4  Comparative Analysis of Pre-test/Post-test Model in Achieving the Learning…

138
Table 6.7  t-Test: Paired two 
samples for means of group A 
Pre-­test 
Post-­test 
Mean
4.973
6.027 
Variance
2.054
2.748 
Observations
120
120 
Pearson correlation
0.828 
Hypothesized mean 
difference 
0 
df
147 
t Stat
−13.765 
P (T ≤ t) one-tail
<0.001 
t Critical one-tail
1.655 
P (T ≤ t) two-tail
<0.001 
t Critical two-tail
1.976
Table 6.8  t-Test: Paired two 
samples for means of group B 
Pre-­test Post-­test 
Mean
5.014
5.493 
Variance
2.068
3.272 
Observations
120
120 
Pearson correlation
0.892 
Hypothesized mean 
difference 
0 
df
147 
t Stat
−6.974 
P (T ≤ t) one-tail
<0.001 
t Critical one-tail
1.655 
P (T ≤ t) two-tail
<0.001 
t Critical two-tail
1.976
6.4.1  Discussion of the Results 
Regarding the evaluation results, they show high levels of student satisfaction and 
improvement in their learning outcomes. Specifically, the pre-test and post-test 
evaluation showed a significant improvement in student outcomes, confirming the 
pedagogical affordability of the proposed learning method. Lastly, the comparison 
of the proposed system with the traditional method showed that it outperforms the 
second one in terms of enhancing the effectiveness of adopted adaptivity and using 
rule-based training, as well as confirming the efficacy of the teaching method 
employed in learning activities.
6  Multi-model Evaluation of the Artificial Intelligence-Enhanced PARSAT AR Software

139
6.5  Extended Technology Acceptance Model for Detecting 
Influencing Factors 
The acceptance of AR technology for spatial ability training was assessed, by pro­
posing an acceptance model specific to PARSAT. The suggested model includes the 
basic TAM variables, namely, usefulness, ease of use, and intention to use [22], 
extended by two more constructs, namely, perceived interactivity and personaliza­
tion, which are addressed to evaluate the human–AR system interaction and the 
contextual affordances to support the training of the students [23, 24]. 
6.5.1  Existing Acceptance Models 
25
­
6.9
­
Yusoff et al. [26] evaluated the use of a mixed reality prototype, named the mixed 
reality regenerative concept, in the training of biomedical science students. The 
Table 6.9  Existing research on the acceptance of AR applications in chronological order 
Study AR application
Constructs
Sample
Method
Context 
[26] 
Mixed Reality 
Regenerative 
Concept (MRRC) 
PU, PEOU, 
BI, PE, PI 
63 Biomedical 
Science students 
Regression 
analysis 
University 
education 
[27] 
ARIES
PU, PEOU, 
AT, BI, PE, 
IS 
42 students of the 
second grade of 
lower secondary 
school 
Descriptive 
statistics 
Regression 
analysis 
Secondary 
education 
[28] 
AR instructions
PU, PEOU, 
AT, BI 
41 undergraduate 
students 
Regression 
analysis 
Aviation 
[29] 
AR-based 
military 
decision-making 
process 
(ARB-MDMP) 
PU, PEOU, 
AT, BI, IS, 
PSA 
40 officers receiving 
the training in Army 
Command and Staff 
College 
Regression 
analysis 
College 
[30] 
Augmented 
Reality Geometry 
Tutorial System 
(ARGTS) 
PU, PEOU, 
AT, BI, SF, 
ANX, SN 
148 mathematics 
teachers 
Structural 
Equation 
Modeling 
(SEM) 
Primary 
education 
[31] 
Soldamatic
PU, PEOU, 
AT, BI, SQ, 
PE 
200 trainees
Factor and 
regression 
analysis 
Manufacturing 
training 
6.5  Extended Technology Acceptance Model for Detecting Influencing Factors

140
study was based on a modified TAM, incorporating the external variables of per­
ceived innovativeness and perceived enjoyment. The findings showed positive cor­
relations between the constructs; however, the results needed further advanced 
regression analysis to better evaluate the proposed model. 
Wojciechowski and Cellary [27] presented a 3D image-based AR learning envi­
ronment, namely ARIES. The evaluation of the system was based on TAM, enhanced 
with the constructs of perceived enjoyment and interface style. The study on the 
attitude of the learners toward ARIES showed great potential for education; how­
ever, more experimental studies should be carried out to determine the achievement 
of the learning goals. 
Wang et al. [28] conducted a case study of 41 aviation students in order to evalu­
ate their acceptance of AR instructions and the future utilization of AR maintenance 
manuals in aviation training. The authors were based on the simplified four-­construct 
TAM, excluding the actual system use and external variables. The study was one of 
the first ones to incorporate TAM in aviation training, and the findings showed that 
the students accepted the integration of AR in their educational settings. 
Mao et al. [29] evaluated officers’ acceptance of an AR-based military decision-­
making process (ARB-MDMP) training system, which provided realistic troop pat­
terns, terrain environment, and battlefield intelligence. The research model was 
based on TAM, and two external variables were added, namely, interface style and 
perceived situation awareness. The findings were encouraging and showed that the 
ARB-MDMP system had significant effectiveness for the officers during their 
courses. 
Ibili et al. [30] developed a mobile AR application to teach geometry and exam­
ined the mathematics teachers’ level of acceptance of the tutoring system. The 
authors extended the TAM model by including the external variables of anxiety, 
social norms, and satisfaction. The results supported 9 out of a total of 14 hypothe­
ses, providing important implications for future AR tutoring applications. 
Papakostas et al. [31] examined the integration of AR simulation in vocational 
education and training (VET), specifically in the field of industrial manufacturing. 
The authors were based on a modified TAM and extended it by two external vari­
ables in order to evaluate the use of a marker-based AR application, named 
Soldamatic, in welding training. The findings showed that both external variables, 
namely, perceived enjoyment and system quality, were strong predictors of the pro­
posed model, and evaluated pedagogical affordance and technological innovation at 
the same time. 
Although there has been a lot of research on the adoption of AR for training 
[32–41], few studies have concentrated on the educational context of spatial ability 
training [42]. As such, this research details the user experience of augmented reality 
in spatial ability training and provides a deeper understanding of the behavioral 
purpose to use augmented reality in training. Special reference is made to the fac­
tors related to the human sensory experience, such as interactivity and 
personalization.
6  Multi-model Evaluation of the Artificial Intelligence-Enhanced PARSAT AR Software

141
6.5.2  Proposed Extended Model 
The related research questions that form the hypotheses of the proposed model are 
as follows: 
•	 Is AR acceptable by students as part of their training to develop their spatial 
skills? (RQ1); 
•	 How do the technical aspects of using AR affect learners’ experiences of using 
it? (RQ2); 
•	 What effect does the AR application’s content have on the learners’ user experi­
ence? (RQ3). 
We evaluated the AR application by expanding a TAM model, according to the 
research statement. Furthermore, the use of augmented reality in spatial ability 
training has been shown to have a high potential for making training sessions more 
attractive, and students more motivated. 
6.5.3  Research Model and Hypotheses 
25
43
44
6.1
In this study, the final version of the model TAM, consisting of the variables of 
perceived usefulness, perceived ease of use, and behavioral intention, is proposed 
and found to be useful in predicting the use of AR for spatial ability training, and the 
following hypotheses are proposed:
–– Hypothesis 1 (H1): PEOU of the AR application positively affects its PU.
–– Hypothesis 2 (H2): PEOU of the AR application positively affects its BI.
–– Hypothesis 3 (H3): PU of the AR application positively affects its BI. 
The belief of a system user may be influenced by external factors, referred to as 
external variables [45, 46]. In addition to the TAM model, two external variables are 
integrated into the extended TAM model, with an effect on PU and PEOU. 
Lee and Lee [47] provided empirical evidence supporting perceived interactivity 
(PI) as a prerequisite factor for extending the core TAM model, in order to under­
stand usage behavior. McMillan and Hwang [48] measured interactivity based on 
6.5  Extended Technology Acceptance Model for Detecting Influencing Factors

142
 
44
three elements, namely, the direction of communication, user control, and time. The 
direction of communication is focused on the way that computers facilitate human 
interaction, emphasizing two-way communication. The user control examines the 
way humans control computers, while some HCI studies focus on human percep­
tion, and others on computer design [49]. The third element of interactivity is time, 
which evaluates the user’s ability to navigate the application quickly and easily. An 
interactive system provides the users the benefits of working on their own time and 
choosing their preferred navigation paths [50]. 
In the context of the current research, PI results in students’ positive beliefs about 
the usefulness and ease of use of the AR application, which in turn influences their 
behavioral intentions in the spatial ability training. We advanced the TAM model by 
employing the interactivity variable, as a prerequisite variable, and therefore, the 
following hypotheses are composed:
–– Hypothesis 4 (H4): PI of the AR application positively affects its PU.
–– Hypothesis 5 (H5): PI of the AR application positively affects its PEOU. 
Furthermore, personalization has been found to be a major component of many 
information technology-based systems [51]. Training through an AR environment 
can personalize the learning needs in order to promote the quality of the training. 
AR is ideal for abstract terms, such as spatial recognition, allowing the students to 
use dynamic learning, giving them a sense of control as they can repeat the training 
stages as many times as they need, learning at their own pace. Individualized, adap­
tive systems, facilitated by technologies such as AR, can represent the revolutionary 
capacity for lifelong learning, which can be incorporated into the future of training 
systems [52]. Hubert et al. [53] pointed out that the perceived value of personaliza­
tion plays a significant role in the IT system’s acceptance.
6  Multi-model Evaluation of the Artificial Intelligence-Enhanced PARSAT AR Software

143
In the context of the current research, the perceived value for personalization 
(PP) might play an important role regarding the students’ positive attitude towards 
the training AR application. We advanced the TAM model by employing the person­
alization as the second prerequisite variable of the proposed TAM model, and the 
hypotheses included in the model are as follows:
–– Hypothesis 6 (H6): PP of the AR application positively affects its PU;
–– Hypothesis 7 (H7): PP of the AR application positively affects its PEOU. 
6.2
This study tested the proposed TAM model in the training of spatial ability. 
6.5.4  Research Instruments 
6.10
57 60
 
6.5  Extended Technology Acceptance Model for Detecting Influencing Factors

144
Table 6.10  Questionnaire details used in the survey 
Constructs
Indicator Questionnaire
Source 
Perceived interactivity 
(PI) 
PI1
I felt that I had a lot of control over my experiences 
of using the AR application. 
[54, 
55] 
PI2
Getting information from the AR application was 
very fast. 
PI3
I think using the AR application was enjoyable.
[55] 
Perceived 
personalization (PP) 
PP1
I value AR application that is personalized for the 
device that I use. 
[53] 
PP2
I value AR application that is personalized for my 
usage experience preference. 
PP3
I value AR application that acquires my personal 
preferences and personalizes the services 
themselves. 
Perceived usefulness 
(PU) 
PU1
Using AR application improves my learning 
performance. 
[56] 
PU2
Using AR application makes my training more 
productive. 
PU3
Using AR application enhances my effectiveness on 
my training. 
PU4
Overall, I find AR application useful in my job. 
Perceived ease of use 
(PEOU) 
PEOU1 
Learning to operate AR application is easy for me.
[56] 
PEOU2 
I find it easy to get AR application to do what I want 
to do. 
PEOU3 
My interaction with the AR application is clear and 
understandable. 
PEOU4 
Overall, I find AR application easy to use. 
Behavioral intention 
to use (BI) 
BI1
Using AR application enhances my training interest. [43] 
BI2
I intend to use AR application for training in the 
future. 
BI3
I will recommend others to use AR application for 
training. 
6.5.5  Data Analysis 
In the research of this book, the Structural Equation Modeling (SEM) approach was 
employed to rigorously analyze the amassed dataset. The development of the regres­
sion analysis model for the variables was carried out utilizing the Partial Least 
Squares (PLS) algorithm. PLS enables the simultaneous assessment of both the 
measurement and structural models by estimating individual item loadings on their 
respective variables and examining the causal relationships among these vari­
ables [61]. 
Given the exploratory nature of the sample, where the primary aim is to compre­
hend how the independent variables induce variance in the dependent variables 
rather than assessing the model’s fit to the data, PLS emerges as a robust choice for 
data analysis [58].
6  Multi-model Evaluation of the Artificial Intelligence-Enhanced PARSAT AR Software

145
In this analysis, PLS is used to test seven hypotheses and assess the relationships 
between the variables. SmartPLS v.3.3.3, a software tool for PLS-SEM developed 
by [62], was used to conduct the data analysis. 
6.5.6  Model Validation 
In the current study, a reflective measurement model was used, which assumes that 
the measures represent the indication of an underlying construct [63]. Initially the 
quality of the measurement model was assessed by using the criteria of internal 
consistency, convergent validity, and discriminant validity. The satisfactory results 
of the first phase led the author use the structural model in order to test the 
hypotheses. 
6.5.6.1  Measurement Model 
­
6.11
64 65
Table 6.11  Descriptive statistics of the indicators 
Indicator
M
SD
Kurtosis
Skewness 
BI1
5.630
1.050
−0.273
−0.543 
BI2
5.540
1.117
−0.349
−0.491 
BI3
5.470
1.131
−0.332
−0.583 
PEOU1
5.125
1.208
−0.494
−0.277 
PEOU2
5.455
1.191
−0.204
−0.528 
PEOU3
4.955
1.242
−0.618
−0.088 
PEOU4
5.265
1.321
−0.094
−0.499 
PI1
5.030
1.067
−0.631
−0.010 
PI2
6.160
0.771
0.935
−0.908 
PI3
5.210
1.130
−0.734
−0.191 
PP1
5.210
1.130
−0.734
−0.191 
PP2
5.380
1.164
−0.676
−0.396 
PP3
4.940
1.240
−0.915
0.083 
PU1
5.240
1.040
−0.737
0.042 
PU2
5.200
1.058
−0.484
−0.026 
PU3
5.640
1.044
−0.217
−0.563 
PU4
5.440
1.160
−0.719
−0.298
6.5  Extended Technology Acceptance Model for Detecting Influencing Factors

146
6.12
66
­
­
63
67 68
6.12
­
69
70
6.13
68
­
6.14
Table 6.12  Measurement model’s reliability and convergent validity 
Construct
Indicator
Outer loading
CA
CR
AVE 
BI
BI1
0.992
0.9`79
0.986
0.959 
BI2
0.978 
BI3
0.969 
PEOU
PEOU1
0.970
0.981
0.986
0.947 
PEOU2
0.975 
PEOU3
0.961 
PEOU4
0.985 
PI
PI1
0.949
0.902
0.940
0.839 
PI2
0.833 
PI3
0.961 
PP
PP1
0.983
0.976
0.985
0.955 
PP2
0.977 
PP3
0.972 
PU
PU1
0.933
0.967
0.976
0.911 
PU2
0.947 
PU3
0.971 
PU4
0.966 
6  Multi-model Evaluation of the Artificial Intelligence-Enhanced PARSAT AR Software

147
Table 6.13  Measurement model’s discriminant validity (Fornell Larcker criterion) 
BI
PEOU
PI
PP
PU 
BI
0.979 
PEOU
0.896
0.973 
PI
0.900
0.854
0.916 
PP
0.909
0.894
0.828
0.977 
PU
0.952
0.918
0.899
0.949
0.954
Table 6.14  HTMT results 
BI
PEOU
PI
PP
PU 
BI
X 
PEOU
0.814
X 
PI
0.859
0.809
X 
PP
0.830
0.813
0.882
X 
PU
0.876
0.841
0.861
0.876
X 
6.12
6.12
­
6.12
6.13
70
6.14
71
6.5.6.2  Structural Model 
After the assessment of the measurement model, the PLS algorithm was used to 
evaluate the path coefficients and to test the hypotheses along with their significance 
levels. bootstrapping estimation was ran with the 2000 resampling method and 
obtained the t-statistics corresponding to each path of our model. 
6.5  Extended Technology Acceptance Model for Detecting Influencing Factors

148
72
6.3
­
72
6.15
2
73 74
2
75
2
76
2
6.16
2
77
2
6.17
­
78
75
2
 
6  Multi-model Evaluation of the Artificial Intelligence-Enhanced PARSAT AR Software

149
Table 6.15  Structural model’s results 
Hypothesis
Path
β coefficients
t-Statistics
p-Value
Supported? (Y/N) 
H1
PEOU → PU 
0.182
40.610
0.000
Yes 
H2
PEOU → BI
0.142
20.876
0.004
Yes 
H3
PU → BI
0.822
170.790
0.000
Yes 
H4
PI → PU
0.294
100.417
0.000
Yes 
H5
PI → PEOU
0.363
60.988
0.000
Yes 
H6
PP → PU
0.542
190.631
0.000
Yes 
H7
PP → PEOU 
0.593
110.891
0.000
Yes
Table 6.16  R2 and Q2 results
Constructs R2
Q2 
BI
0.910 0.867 
PEOU
0.840 0.790 
PU
0.946 0.855
Table 6.17  f2 results 
BI
PEOU
PU 
BI 
PEOU
0.040
0.102 
PI
0.270
0.416 
PP
0.687
1.027 
PU
1.208 
6.16
2
2
­
­
2
6.17
2
2
2
2
2
2
2
6.5  Extended Technology Acceptance Model for Detecting Influencing Factors

150
6.6  Summary 
The comprehensive evaluation presented in this chapter lays the essential ground­
work for comprehending the potential outcomes and effectiveness of the proposed 
AI-enhanced AR mobile training system, playing a crucial role in its success and 
acceptance, all within the framework of a comprehensive evaluation approach that 
incorporates various analytical techniques [79–83]. 
The evaluation chapter is valuable, as it significantly assists in understanding the 
proposed system’s intended outcomes and assess the system’s efficiency. The evalu­
ation results are crucial for the system’s success, and therefore its acceptance from 
the users. The evaluation framework, used in the current research, was analyzed and 
techniques such as t-tests, pre-test/post-test, and TAM were integrated and pre­
sented into the evaluation process. 
References 
1.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “PARSAT: Fuzzy logic for 
adaptive spatial ability training in an augmented reality system,” Computer Science and 
Information Systems, vol. 20, no. 4, 2023, https://doi.org/10.2298/CSIS230130043P. 
2.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “On the development of a 
personalized augmented reality spatial ability training mobile application,” in Frontiers in 
Artificial Intelligence and Applications, IOS Press, 2021, pp. V–VI. https://doi.org/10.3233/ 
FAIA210078. 
3.	A. Marougkas, C. Troussas, A. Krouska, and C. Sgouropoulou, “A Framework for Personalized 
Fully Immersive Virtual Reality Learning Environments with Gamified Design in Education,” 
2021. https://doi.org/10.3233/FAIA210080. 
4.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Towards a Reference Model to Ensure the 
Quality of Massive Open Online Courses and E-Learning,” in Brain Function Assessment 
in Learning, C.  Frasson, P.  Bamidis, and P.  Vlamos, Eds., Cham: Springer International 
Publishing, 2020, pp. 169–175. 
5.	H. M. H.; T. Mustafa Fadhel Ben; Ramadan Ramadan M., “An Overview on Evaluation of 
E-Learning/Training Response Time Considering Artificial Neural Networks Modeling,” J Educ 
Elearn Res, vol. 4, no. 2, pp. 46–62, 2017, https://doi.org/10.20448/journal.509.2017.42.46.62. 
6.	T. Lynch and I. Ghergulescu, “An evaluation framework for adaptive and intelligent tutoring 
systems,” in E-learn: world conference on e-learning in corporate, government, healthcare, 
and higher education, Association for the Advancement of Computing in Education (AACE), 
2016, pp. 1385–1390. 
7.	N. Manouselis, H. Drachsler, R. Vuorikari, H. Hummel, and R. Koper, “Recommender sys­
tems in technology enhanced learning,” Recommender systems handbook, pp. 387–415, 2011. 
8.	C. Mulwa, S. Lawless, I. O’Keeffe, M. Sharp, and V. Wade, “A recommender framework 
for the evaluation of end user experience in adaptive technology enhanced learning,” 
International Journal of Technology Enhanced Learning, vol. 4, pp. 67–84, Jul. 2012, https:// 
doi.org/10.1504/IJTEL.2012.048312. 
9.	J. F. Pane, B. A. Griffin, D. F. McCaffrey, and R. Karam, “Effectiveness of Cognitive Tutor 
Algebra I at Scale,” Educ Eval Policy Anal, vol. 36, no. 2, pp. 127–144, Jun. 2014, https://doi. 
org/10.3102/0162373713507480.
6  Multi-model Evaluation of the Artificial Intelligence-Enhanced PARSAT AR Software

151
10.	J. Greer and M. Mark, “Evaluation Methods for Intelligent Tutoring Systems Revisited,” Int J 
Artif Intell Educ, vol. 26, no. 1, pp. 387–392, 2016, https://doi.org/10.1007/s40593-­015-­0043-­2. 
11.	C.  Mulwa, S.  Lawless, M.  Sharp, and V.  Wade, “The evaluation of adaptive and person­
alised information retrieval systems: A review,” I. J. Knowledge and Web Intelligence, vol. 2, 
pp. 138–156, Jan. 2011, https://doi.org/10.1504/IJKWI.2011.044120. 
12.	N. Tintarev and J. Masthoff, “A Survey of Explanations in Recommender Systems,” 2007 
IEEE 23rd International Conference on Data Engineering Workshop, pp. 801–810, 2007. 
13.	B. P. Knijnenburg, M. C. Willemsen, Z. Gantner, H. Soncu, and C. Newell, “Explaining the 
user experience of recommender systems,” User Model User-adapt Interact, vol. 22, no. 4, 
pp. 441–504, 2012, https://doi.org/10.1007/s11257-­011-­9118-­4. 
14.	M. Cocea and S. Weibelzahl, “Disengagement Detection in Online Learning: Validation Studies 
and Perspectives,” IEEE Transactions on Learning Technologies, vol. 4, no. 2, pp. 114–124, 
2011, https://doi.org/10.1109/TLT.2010.14. 
15.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Impact of social networking for advancing 
learners’ knowledge in E-learning environments,” Educ Inf Technol (Dordr), vol. 26, no. 4, 
pp. 4285–4305, 2021, https://doi.org/10.1007/s10639-­021-­10483-­6. 
16.	N.  Coulianos, A.  Sapalidou, A.  Krouska, C.  Troussas, and C.  Sgouropoulou, “Evaluating 
E-Learning Process on Virtual Classroom Systems Using an ISO-Based Model,” in Novel & 
Intelligent Digital Systems: Proceedings of the 2nd International Conference (NiDS 2022), 
A. Krouska, C. Troussas, and J. Caro, Eds., Cham: Springer International Publishing, 2023, 
pp. 33–45. 
17.	J. M. Oakes and H. A. Feldman, “Statistical Power for Nonequivalent Pretest-Posttest Designs: 
The Impact of Change-Score versus ANCOVA Models,” Eval Rev, vol. 25, no. 1, pp. 3–28, 
Feb. 2001, https://doi.org/10.1177/0193841X0102500101. 
18.	Z.  Kanetaki, C.  Stergiou, G.  Bekas, C.  Troussas, and C.  Sgouropoulou, “Analysis of 
Engineering Student Data in Online Higher Education During the COVID-19 Pandemic,” 
International Journal of Engineering Pedagogy (iJEP), vol. 11, no. 6, pp. 27–49, Dec. 2021, 
https://doi.org/10.3991/ijep.v11i6.23259. 
19.	A. Koliarakis, A. Krouska, C. Troussas, and C. Sgouropoulou, “Modified collaborative filtering 
for hybrid recommender systems and personalized search: The case of digital library,” in 2022 
17th International Workshop on Semantic and Social Media Adaptation & Personalization 
(SMAP), 2022, pp. 1–6. https://doi.org/10.1109/SMAP56125.2022.9942020. 
20.	P. E. Connolly and T. J. Branoff, “The Addition Of Coordinate Axes To The Purdue Spatial 
Visualization Test Visualization Of Rotations: A Study At Two Universities,” 1999. 
21.	R. H. Evans, “An Analysis of Criterion Variable Reliability in Conjoint Analysis,” Percept 
Mot Skills, vol. 82, no. 3, pp. 988–990, Jun. 1996, https://doi.org/10.2466/pms.1996.82.3.988. 
22.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Measuring User Experience, 
Usability and Interactivity of a Personalized Mobile Augmented Reality Training System,” 
Sensors, vol. 21, no. 11, p. 3888, Jun. 2021, https://doi.org/10.3390/s21113888. 
23.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Exploring Users’ Behavioral 
Intention to Adopt Mobile Augmented Reality in Education through an Extended Technology 
Acceptance Model,” Int J Hum Comput Interact, vol. 39, no. 6, pp. 1294–1302, 2023, https:// 
doi.org/10.1080/10447318.2022.2062551. 
24.	A. Krouska, C. Troussas, K. Kabassi, and C. Sgouropoulou, “An Empirical Investigation of 
User Acceptance of Personalized Mobile Software for Sustainability Education,” Int J Hum 
Comput Interact, pp. 1–8, Aug. 2023, https://doi.org/10.1080/10447318.2023.2241614. 
25.	F. D. Davis, “A technology acceptance model for empirically testing new end-user informa­
tion systems: Theory and results,” PhD Thesis, Massachusetts Institute of Technology, Sloan 
School of Management, 1985. doi: oclc/56932490. 
26.	R. C. M. Yusoff, R. Ibrahim, H. B. Zaman, and A. Ahmad, “Evaluation of user acceptance of 
mixed reality technology,” Australasian Journal of Educational Technology, vol. 27, no. 8, 
pp. 1369–1387, Dec. 2011, https://doi.org/10.14742/ajet.899.
References

152
27.	R. Wojciechowski and W. Cellary, “Evaluation of learners’ attitude toward learning in ARIES 
augmented reality environments,” Comput Educ, vol. 68, pp. 570–585, Oct. 2013, https://doi. 
org/10.1016/j.compedu.2013.02.014. 
28.	Y. Wang, A. Anne, and T. Ropp, “Applying the technology acceptance model to understand 
aviation students’ perceptions toward augmented reality maintenance training instruction,” 
International Journal of Aviation, Aeronautics, and Aerospace, vol. 3, no. 4, Jan. 2016, https:// 
doi.org/10.15394/ijaaa.2016.1144. 
29.	C.-C.  Mao, C.-C.  Sun, and C.-H.  Chen, Evaluate Learner’s Acceptance of Augmented 
Reality Based Military Decision Making Process Training System. 2017. https://doi. 
org/10.1145/3029387.3029418. 
30.	E. Ibili, D. Resnyansky, and M. Billinghurst, “Applying the technology acceptance model 
to understand maths teachers’ perceptions towards an augmented reality tutoring system,” 
Educ Inf Technol (Dordr), vol. 24, no. 5, pp.  2653–2675, 2019, https://doi.org/10.1007/ 
s10639-­019-­09925-­z. 
31.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “User acceptance of augmented 
reality welding simulator in engineering training,” Educ Inf Technol (Dordr), vol. 27, no. 1, 
pp. 791–817, Jan. 2022, https://doi.org/10.1007/s10639-­020-­10418-­7. 
32.	M. Iakovidis, C. Papakostas, C. Troussas, and C. Sgouropoulou, “Empowering Responsible 
Digital Citizenship Through an Augmented Reality Educational Game,” in Novel & Intelligent 
Digital Systems: Proceedings of the 3rd International Conference (NiDS 2023), K. Kabassi, 
P. Mylonas, and J. Caro, Eds., Cham: Springer Nature Switzerland, 2023, pp. 31–39. 
33.	P.  Strousopoulos, C.  Troussas, C.  Papakostas, A.  Krouska, and C.  Sgouropoulou, 
“Revolutionizing Agricultural Education with Virtual Reality and Gamification: A Novel 
Approach for Enhancing Knowledge Transfer and Skill Acquisition,” in Novel & Intelligent 
Digital Systems: Proceedings of the 3rd International Conference (NiDS 2023), K. Kabassi, 
P. Mylonas, and J. Caro, Eds., Cham: Springer Nature Switzerland, 2023, pp. 67–80. 
34.	P. Strousopoulos, C. Papakostas, C. Troussas, A. Krouska, P. Mylonas, and C. Sgouropoulou, 
“SculptMate: Personalizing Cultural Heritage Experience Using Fuzzy Weights,” in Adjunct 
Proceedings of the 31st ACM Conference on User Modeling, Adaptation and Personalization, 
in UMAP ’23 Adjunct. New York, NY, USA: Association for Computing Machinery, 2023, 
pp. 397–407. https://doi.org/10.1145/3563359.3596667. 
35.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Modeling the Knowledge of 
Users in an Augmented Reality-Based Learning Environment Using Fuzzy Logic,” in Lecture 
Notes in Networks and Systems, A. Krouska, C. Troussas, and J. Caro, Eds., Cham: Springer 
International Publishing, 2023, pp. 113–123. https://doi.org/10.1007/978-­3-­031-­17601-­2_12. 
36.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Exploration of Augmented 
Reality in Spatial Abilities Training: A Systematic Literature Review for the Last Decade,” 
Informatics in Education, vol. 20, no. 1, pp. 107–130, Mar. 2021, https://doi.org/10.15388/ 
infedu.2021.06. 
37.	A. Marougkas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Virtual Reality in Education: 
A Review of Learning Theories, Approaches and Methodologies for the Last Decade,” 
Electronics (Basel), vol. 12, no. 13, 2023, https://doi.org/10.3390/electronics12132832. 
38.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Enriching Mobile Learning Software with 
Interactive Activities and Motivational Feedback for Advancing Users’ High-Level Cognitive 
Skills,” Computers, vol. 11, no. 2, 2022, https://doi.org/10.3390/computers11020018. 
39.	F. Giannakas, C. Troussas, A. Krouska, C. Sgouropoulou, and I. Voyiatzis, “XGBoost and 
Deep Neural Network Comparison: The Case of Teams’ Performance,” in Intelligent Tutoring 
Systems, A. I. Cristea and C. Troussas, Eds., Cham: Springer International Publishing, 2021, 
pp. 343–349. 
40.	A.  Marougkas, C.  Troussas, A.  Krouska, and C.  Sgouropoulou, “How personalized and 
effective is immersive virtual reality in education? A systematic literature review for the last 
decade,” Multimed Tools Appl, 2023, https://doi.org/10.1007/s11042-­023-­15986-­7.
6  Multi-model Evaluation of the Artificial Intelligence-Enhanced PARSAT AR Software

153
41.	A. Krouska, C. Troussas, and C. Sgouropoulou, “A novel group recommender system for 
domain-independent decision support customizing a grouping genetic algorithm,” User Model 
User-adapt Interact, 2023, https://doi.org/10.1007/s11257-­023-­09360-­3. 
42.	C.  Papakostas, C.  Troussas, A.  Krouska, and C.  Sgouropoulou, “Personalization of the 
Learning Path within an Augmented Reality Spatial Ability Training Application Based on 
Fuzzy Weights,” Sensors, vol. 22, no. 18, 2022, https://doi.org/10.3390/s22187059. 
43.	M. Fishbein and I. Ajzen, Belief, attitude, intention and behaviour: An introduction to theory 
and research, vol. 27. 1975. 
44.	F. D. Davis and V. Venkatesh, “A critical assessment of potential measurement biases in the 
technology acceptance model: Three experiments,” International Journal of Human Computer 
Studies, vol. 45, no. 1, pp. 19–45, 1996, https://doi.org/10.1006/ijhc.1996.0040. 
45.	P.  C. Lai, “THE LITERATURE REVIEW OF TECHNOLOGY ADOPTION MODELS 
AND THEORIES FOR THE NOVELTY TECHNOLOGY,” Journal of Information Systems 
and Technology Management, vol. 14, pp.  21–38, Apr. 2017, https://doi.org/10.4301/ 
s1807-­17752017000100002. 
46.	A. Krouska, C. Troussas, and C. Sgouropoulou, “Extended Technology Acceptance Models 
for Digital Learning: Review of External Factors,” in Novel & Intelligent Digital Systems: 
Proceedings of the 2nd International Conference (NiDS 2022), A. Krouska, C. Troussas, and 
J. Caro, Eds., Cham: Springer International Publishing, 2023, pp. 52–63. 
47.	J.-H. Lee and C.-F. Lee, “Extension of TAM by Perceived Interactivity to Understand Usage 
Behaviors on ACG Social Media Sites,” Sustainability, vol. 11, p. 5723, Oct. 2019, https://doi. 
org/10.3390/su11205723. 
48.	S. J. McMillan and J.-S. Hwang, “Measures of Perceived Interactivity: An Exploration of 
the Role of Direction of Communication, User Control, and Time in Shaping Perceptions of 
Interactivity,” J Advert, vol. 31, no. 3, pp. 29–42, Oct. 2002, https://doi.org/10.1080/0091336 
7.2002.10673674. 
49.	B. Reeves and C. Nass, “The Media Equation: How People Treat Computers, Television, and 
New Media Like Real People and Pla,” Bibliovault OAI Repository, the University of Chicago 
Press, Jan. 1996. 
50.	J. Williamson, C. Latchem, and L. Henderson-Lancett, Interactive multimedia: practice and 
promise. London: Kogan Page, 1993. 
51.	T.-P. Liang, H.-Y. Chen, and E. Turban, “Effect of personalization on the perceived usefulness 
of online customer services: A dual-core theory,” ACM International Conference Proceeding 
Series, Jan. 2009, https://doi.org/10.1145/1593254.1593296. 
52.	M. Marienko, Y. Nosenko, and M. Shyshkina, Personalization of learning using adaptive tech­
nologies and augmented reality. 2020. 
53.	M. Hubert, A. Carugati, C. Brock, and B. Obel, Take it Personally – The Role of Consumers’ 
Perceived Value of Personalization on Cross-Category Use in a Smart Home Ecosystem. 2020. 
https://doi.org/10.24251/HICSS.2020.144. 
54.	W.-S.  Yoo, Y.  Lee, and J.  Park, “The role of interactivity in e-tailing: Creating value and 
increasing satisfaction,” Journal of Retailing and Consumer Services, vol. 17, no. 2, pp. 89–96, 
2010, https://doi.org/10.1016/j.jretconser.2009.10.003. 
55.	L.  Zhao and Y.  Lu, “Enhancing perceived interactivity through network externalities: An 
empirical study on micro-blogging service satisfaction and continuance intention,” Decis 
Support Syst, vol. 53, no. 4, pp. 825–834, 2012, https://doi.org/10.1016/j.dss.2012.05.019. 
56.	F. D. Davis, “A technology acceptance model for empirically testing new end-user informa­
tion systems: Theory and results,” Management, vol. Ph.D., p. 291, 1985, doi: oclc/56932490. 
57.	C. Esterwood, X. J. Yang, and L. Robert, “Barriers to AV Bus Acceptance: A U.S. National 
Survey and Research Agenda,” Int J Hum Comput Interact, Feb. 2021, https://doi.org/10.108 
0/10447318.2021.1886485. 
58.	D. Pal and S. Patra, “University Students’ Perception of Video-Based Learning in Times of 
COVID-19: A TAM/TTF Perspective,” Int J Hum Comput Interact, Dec. 2020, https://doi. 
org/10.1080/10447318.2020.1848164.
References

154
59.	C. Sagnier, E. Loup-Escande, D. Lourdeaux, I. Thouvenin, and G. Valléry, “User Acceptance 
of Virtual Reality: An Extended Technology Acceptance Model,” Int J Hum Comput Interact, 
vol. 36, no. 11, pp. 993–1007, Jul. 2020, https://doi.org/10.1080/10447318.2019.1708612. 
60.	D.  Shin, “Understanding User Acceptance of DMB in South Korea Using the Modified 
Technology Acceptance Model,” Int. J. Hum. Comput. Interaction, vol. 25, pp. 173–198, Mar. 
2009, https://doi.org/10.1080/10447310802629785. 
61.	M.  Sarstedt and J.-H.  Cheah, “Partial least squares structural equation modeling using 
SmartPLS: a software review,” Journal of Marketing Analytics, vol. 7, no. 3, pp. 196–202, 
2019, https://doi.org/10.1057/s41270-­019-­00058-­3. 
62.	C. Ringle, S. Wende, and J.-M. Becker, SmartPLS 3. 2015. 
63.	J. Hair, G. T. M. Hult, C. Ringle, and M. Sarstedt, A Primer on Partial Least Squares Structural 
Equation Modeling. 2014. 
64.	F. J. Gravetter and L. B. Wallnau, Essentials of statistics for the behavioral sciences. 2014. 
65.	J. F. Hair Jr, G. T. M. Hult, C. Ringle, and M. Sarstedt, A primer on partial least squares struc­
tural equation modeling (PLS-SEM). Sage publications, 2016. 
66.	J. Hulland, “Use of Partial Least Squares (PLS) in Strategic Management Research: A Review 
of Four Recent Studies,” Strategic Management Journal, vol. 20, no. 2, pp. 195–204, Jul. 1999, 
[Online]. Available: http://www.jstor.org/stable/3094025 
67.	R. Bagozzi and Y. Yi, “On the Evaluation of Structure Equation Models,” J Acad Mark Sci, vol. 
16, pp. 74–94, Jan. 1988, https://doi.org/10.1007/BF02723327. 
68.	J. F. Hair, M. Sarstedt, C. M. Ringle, and J. A. Mena, “An assessment of the use of partial least 
squares structural equation modeling in marketing research,” J Acad Mark Sci, vol. 40, no. 3, 
pp. 414–433, 2012, https://doi.org/10.1007/s11747-­011-­0261-­6. 
69.	W. W. Chin and P. A. Todd, “On the Use, Usefulness, and Ease of Use of Structural Equation 
Modeling in MIS Research: A Note of Caution,” MIS Quarterly, vol. 19, no. 2, pp. 237–246, 
Jul. 1995, https://doi.org/10.2307/249690. 
70.	C.  Fornell and D.  F. Larcker, “Evaluating Structural Equation Models with Unobservable 
Variables and Measurement Error,” Journal of Marketing Research, vol. 18, no. 1, pp. 39–50, 
Jul. 1981, https://doi.org/10.2307/3151312. 
71.	J. Henseler, C. Ringle, and M. Sarstedt, “A New Criterion for Assessing Discriminant Validity 
in Variance-based Structural Equation Modeling,” J Acad Mark Sci, vol. 43, pp. 115–135, Jan. 
2015, https://doi.org/10.1007/s11747-­014-­0403-­8. 
72.	K.  Wong, “Partial least square structural equation modeling (PLS-SEM) techniques using 
SmartPLS,” Marketing Bulletin, vol. 24, pp. 1–32, Jan. 2013. 
73.	S. Geisser, “A Predictive Approach to the Random Effect Model,” Biometrika, vol. 61, no. 1, 
pp. 101–107, May 1974, https://doi.org/10.2307/2334290. 
74.	M. Stone, “Cross-Validatory Choice and Assessment of Statistical Predictions,” Journal of the 
Royal Statistical Society. Series B (Methodological), vol. 36, no. 2, pp. 111–147, May 1974, 
[Online]. Available: http://www.jstor.org/stable/2984809 
75.	J.  Cohen, “Set Correlation and Contingency Tables,” Appl Psychol Meas, vol. 12, no. 4, 
pp. 425–434, Dec. 1988, https://doi.org/10.1177/014662168801200410. 
76.	G. D. Garson, Partial Least Squares: Regression and Structural Equation Models. Asheboro, 
NC: Statistical Associates Publishers, 2016. 
77.	W. W. Chin, “How to Write Up and Report PLS Analyses BT - Handbook of Partial Least 
Squares: Concepts, Methods and Applications,” V. Esposito Vinzi, W. W. Chin, J. Henseler, 
and H.  Wang, Eds., Berlin, Heidelberg: Springer Berlin Heidelberg, 2010, pp.  655–690. 
https://doi.org/10.1007/978-­3-­540-­32827-­8_29. 
78.	A. Selya, J. Rose, L. Dierker, D. Hedeker, and R. Mermelstein, “A practical guide to calculat­
ing Cohen’s f2, a measure of local effect size, from PROC MIXED,” Front Psychol, vol. 3, 
p. 111, Apr. 2012, https://doi.org/10.3389/fpsyg.2012.00111. 
79.	Z. Kanetaki et al., “Acquiring, Analyzing and Interpreting Knowledge Data for Sustainable 
Engineering Education: An Experimental Study Using YouTube,” Electronics (Basel), vol. 11, 
no. 14, 2022, https://doi.org/10.3390/electronics11142210.
6  Multi-model Evaluation of the Artificial Intelligence-Enhanced PARSAT AR Software

155
80.	A. Krouska, C. Troussas, and C. Sgouropoulou, “Fuzzy Logic for Refining the Evaluation 
of Learners’ Performance in Online Engineering Education,” European Journal of 
Engineering Research and Science, vol. 4, pp. 50–56, Jun. 2019, https://doi.org/10.24018/ 
ejers.2019.4.6.1369. 
81.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Dynamic Detection of Learning Modalities 
Using Fuzzy Logic in Students’ Interaction Activities,” in Intelligent Tutoring Systems, 
V. Kumar and C. Troussas, Eds., Cham: Springer International Publishing, 2020, pp. 205–213. 
82.	C.  Papakostas, C.  Troussas, P.  Douros, M.  Poli, and C.  Sgouropoulou, “CoMoPAR: A 
Comprehensive Conceptual Model for Designing Personalized Augmented Reality Systems 
in Education,” in Novel & Intelligent Digital Systems: Proceedings of the 3rd International 
Conference (NiDS 2023), K. Kabassi, P. Mylonas, and J. Caro, Eds., Cham: Springer Nature 
Switzerland, 2023, pp. 67–79. 
83.	C. Troussas, C. Papakostas, A. Krouska, P. Mylonas, and C. Sgouropoulou, “Personalized 
Feedback Enhanced by Natural Language Processing in Intelligent Tutoring Systems,” 
in Augmented Intelligence and Intelligent Tutoring Systems, C.  Frasson, P.  Mylonas, and 
C.  Troussas, Eds., Cham: Springer Nature Switzerland, 2023, pp.  667–677. https://doi. 
org/10.1007/978-­3-­031-­32883-­1_58.
References

157
© The Author(s), under exclusive license to Springer Nature 
Switzerland AG 2024 
C. Papakostas et al., Special Topics in Artificial Intelligence and Augmented 
Reality, Cognitive Technologies, https://doi.org/10.1007/978-3-031-52005-1_7
Chapter 7 
Conclusions of AI-Driven AR in Education 
Abstract  This book concluding chapter encapsulates the essence of our extensive 
research, which explores the intricate intersection of artificial intelligence (AI) and 
augmented reality (AR). Within these pages, we synthesize the pivotal findings, 
implications, and contributions distilled from our comprehensive study, shedding 
light on the multifaceted relationship between these transformative technologies. 
This final segment of our scholarly endeavor begins by distilling the salient findings 
unearthed throughout our multidimensional inquiry. Our investigation spans diverse 
domains, including knowledge representation, automated reasoning, multiagent 
systems, hybrid cognitive technologies, human-centered design, socio-technical 
systems, human-computer interaction, intelligent decision support systems, and 
prediction systems. Within these areas, we uncover profound insights that illumi­
nate the vast potential of integrating AI into the realm of AR. Beyond elucidating 
these insights, our work extends to far-reaching implications that resonate across 
various fields. We underscore the transformative influence of AI-AR synergy and 
offer a roadmap for innovators, researchers, and practitioners keen on harnessing 
these technologies’ potential. By bridging existing knowledge gaps, we lay the 
foundation for a future characterized by collaborative human-machine partnerships. 
In summary, this book concluding chapter represents the culmination of our collec­
tive scholarly endeavors. It offers a panoramic view of the intricate interplay 
between AI and AR, showcasing the boundless possibilities that await those who 
dare to traverse this dynamic landscape. By marrying human creativity with techno­
logical innovation, we aim to shape the course of future developments in this field. 
7.1  Overview 
The last chapter of the book states the conclusions drawn by this research, provides 
a discussion on them, and presents its contributions on different scientific fields in 
learning. Finally, this section concludes with recommendations for future work.

158
In this concluding chapter, we provide a succinct and lucid summary of our 
research and its far-reaching implications. To offer a clear preview of the content in 
this section, we present the following review: 
Conclusions: In this concluding section, we distill the primary conclusions 
derived from our research. Herein, we offer a succinct summation of the discoveries 
unearthed in each chapter of the book. 
Discussion: In this subsection, the significance of the findings is discussed and 
how they relate to existing literature in the field. 
Contributions: Within this section, we accentuate the distinctive contributions 
that our research brings to the realm of spatial ability training. Furthermore, we 
delve into the potential ramifications of these findings, both in terms of advancing 
theory and enhancing practical applications. 
Recommendations and future work: Finally, the last subsection concludes with 
recommendations for future research. This sub section also discusses any limita­
tions of the current study. 
7.2  Conclusions and Discussion 
The objective of this research was the development of a novel spatial ability training 
system that offers adaptive learning activities to students as a promising approach to 
enhancing their spatial skills. By utilizing knowledge of the domain’s representa­
tion and students’ modeling, a mobile training application was developed to teach 
technical drawing. 
The incorporation of learning theories and the fuzzy expert system in the 
PARSAT (personalized spatial ability training application) application [1, 2] is a 
significant advantage. The use of the Structure of the Observed Learning Outcomes 
(SOLO) theory for the instructional design of learning content ensures that the con­
tent is structured and presented in a way that maximizes learning outcomes. The 
SOLO theory helps to ensure that students’ understanding of the content is struc­
tured and hierarchical, progressing from simple to complex concepts. 
The use of fuzzy logic in an augmented reality (AR) system is another innovative 
feature of the PARSAT application. Fuzzy logic enables the system to make deci­
sions based on uncertain or vague information, making it ideal for personalized 
learning environments [3, 4]. The incorporation of the fuzzy expert system allows 
PARSAT to adapt to students’ individual learning needs and preferences, providing 
an optimized learning experience. 
PARSAT incorporates a crucial feature in its design—adaptive delivery of learn­
ing activities. This functionality enables PARSAT to tailor learning activities to 
each student’s unique learning requirements and preferences. It ensures that the 
content is aligned with their comprehension level and learning pace, fostering sus­
tained engagement and motivation throughout the learning journey. 
The integration of applications like PARSAT, which offer adaptability and acces­
sibility in the learning process, represents a significant stride towards providing 
7  Conclusions of AI-Driven AR in Education

159
students with interactive and personalized learning experiences. These applications, 
by adjusting to individual student characteristics and requirements, have the poten­
tial to enhance engagement, motivation, and ultimately, improve learning outcomes. 
Furthermore, PARSAT leverages augmented reality (AR) technology, introduc­
ing an innovative dimension to the learning experience. By introducing 3D models 
and interactive modules, the application empowers students to visualize and engage 
with the educational content in a manner that closely mirrors real-world scenarios. 
This approach not only enhances comprehension of complex concepts but also 
injects an element of enjoyment and engagement into the learning process. 
The inclusion of an accompanying booklet containing AR markers greatly 
enhances the utility of the PARSAT application. These markers serve as triggers for 
the 3D models and interaction module, resulting in a seamless and user-friendly 
learning experience. Additionally, the utilization of physical markers enables stu­
dents to interact with the content in a tangible manner, ultimately elevating the 
overall quality of their learning journey. 
The instructional strategy introduced in the current research marks a fresh and 
innovative approach to delivering adaptive learning activities to students. Drawing 
from the learning theory embodied by the Structure of the Observed Learning 
Outcomes (SOLO) model, the instructional content is thoughtfully structured and 
presented to optimize learning outcomes. 
Employing a fuzzy weight-based decision-making system to assess students’ 
knowledge levels proves to be an efficient means of tailoring learning activities 
according to their individual knowledge proficiency. This approach significantly 
personalizes the learning experience, catering to each student’s unique level of 
understanding. By using fuzzy logic to make decisions based on uncertain or vague 
information, the system can adapt to individual student’s learning needs and prefer­
ences, providing an optimized learning experience. The use of assessment in techni­
cal drawing domain concepts to define students’ knowledge level is a reliable and 
valid approach to measuring their level of knowledge. This ensures that students 
receive different learning activities based on their level of knowledge, allowing 
them to learn at their own pace and maximize their learning outcomes. 
The evaluation of the implemented novel educational system, namely PARSAT, 
using the Lynch and Ghergulescu framework is an important step towards assessing 
its effectiveness and impact on student learning outcomes. The framework is spe­
cifically oriented towards evaluating adaptive and intelligent learning systems and 
provides a comprehensive evaluation of PARSAT based on four distinct parameters. 
The initial parameter, which is the learning and training aspect, assesses the sys­
tem’s ability to successfully attain the intended learning objectives. This evaluation 
encompasses criteria related to the caliber and pertinence of the educational content, 
the efficacy of the learning activities, and the influence on student learning 
achievements. 
The second parameter, referred to as the system aspect, appraises the technical 
dimensions of the system, encompassing its dependability, user-friendliness, and 
scalability. This parameter is dedicated to ensuring that the system operates soundly 
7.2  Conclusions and Discussion

160
from a technical standpoint and can be effectively employed within a real-world 
learning context. 
The third parameter, denoted as the user experience dimension, gauges the qual­
ity of the overall user experience and the ease of use of the system. This aspect is 
primarily concerned with guaranteeing that the system is approachable and provides 
a seamless and instinctive learning encounter for users. 
The fourth parameter, namely affective dimension, evaluates the emotional and 
motivational aspects of the learning experience. This parameter focuses on ensuring 
that the learning experience is engaging, motivating, and enjoyable for students. 
Overall, the use of the Lynch and Ghergulescu framework provides a compre­
hensive evaluation of PARSAT, ensuring that all aspects of the system are evaluated 
and assessed. This approach helped to identify strengths and weaknesses in the 
system and guide future development and improvement. 
The evaluation results of PARSAT indicate that the system is effective in improv­
ing student learning outcomes and providing a satisfactory learning experience. The 
pre-test and post-test evaluation showed a significant improvement in student out­
comes, indicating that the adaptive learning approach employed in PARSAT is 
effective in improving student knowledge and understanding of technical drawing 
concepts. 
The substantial student contentment levels with the system serve as additional 
affirmation of the efficacy of the approach implemented in PARSAT. Moreover, the 
positive evaluations of the system’s technical facets, encompassing its dependabil­
ity, user-friendliness, and scalability, underscore its suitability for practical applica­
tion within a real-world learning context. 
The comparison of PARSAT with the traditional method showed that the system 
outperforms the latter in terms of enhancing the effectiveness of adopted adaptivity 
and using rule-based training. This indicates that the approach employed in PARSAT 
is superior to the traditional method in terms of providing a personalized and adap­
tive learning experience. 
Overall, the evaluation results of PARSAT confirm the efficacy of the teaching 
method employed in learning activities and demonstrate the potential of adaptive 
and intelligent learning systems to improve student learning outcomes and satisfac­
tion. The positive outcomes of the evaluation suggest that PARSAT has the potential 
to be implemented in other domains to enhance the effectiveness and efficiency of 
the learning process. 
The multi-model evaluation of the proposed PARSAT system involved an 
extended Technology Acceptance Model (TAM). The TAM is a widely used model 
for evaluating user acceptance of new technology [5–8]. This comprises two pri­
mary components: perceived usefulness and perceived ease of use. Perceived use­
fulness pertains to how users perceive the system’s effectiveness in helping them 
attain their objectives, perceived ease of use relates to how users perceive the sys­
tem’s ease of operation. 
Assessing the acceptance of AR technology for spatial ability training is an 
important aspect of evaluating the effectiveness of PARSAT. The proposed accep­
tance model for PARSAT extends the basic Technology Acceptance Model (TAM) 
7  Conclusions of AI-Driven AR in Education

161
variables of usefulness, ease of use, and intention to use to include two additional 
constructs: perceived interactivity and personalization. 
Perceived interactivity is a key construct in the proposed acceptance model as it 
addresses the human-AR system interaction. This variable centers on the extent to 
which users perceive the system as interactive and attuned to their input. This is of 
special significance in spatial ability training, where the capacity to engage with 3D 
models and receive immediate feedback can notably elevate the quality of the learn­
ing process [9, 10]. 
Personalization is another key construct in the proposed acceptance model as it 
addresses the contextual affordances to support the training of students These vari­
able concentrates on the extent to which the system tailors itself to the unique 
requirements and attributes of each user. The capability to offer personalized learn­
ing activities and adjust the system to match the user’s level of knowledge can con­
siderably augment the training’s effectiveness. 
Overall, the proposed acceptance model for PARSAT provides a comprehensive 
evaluation of the system’s effectiveness in training spatial abilities using AR tech­
nology. By extending the basic TAM variables to include perceived interactivity and 
personalization, the model addresses important aspects of the human-AR system 
interaction and contextual affordances to support the training of students. The model 
can be used to evaluate the acceptance of PARSAT and guide future development 
and improvement of the system. 
Summarizing, PARSAT is an adaptive learning system for spatial ability training 
that incorporates the following: 
The fuzzy logic algorithm in PARSAT which takes as input four features—one 
static (prior knowledge) and three dynamic (video-based duration, augmented real­
ity interaction duration, and number of assessment errors)—to detect a student’s 
current level of knowledge. This allows the system to adapt and deliver learning 
activities according to the student’s knowledge level 
The Mamdani inference system which is used in PARSAT to map the input fea­
tures obtained through the fuzzy logic algorithm (prior knowledge, video-based 
duration, augmented reality interaction duration, and number of assessment errors) 
to appropriate classes. The Mamdani system uses fuzzy rules and membership func­
tions to generate an output, which in this case is the student’s current knowledge 
level. This knowledge level is then used to determine the appropriate learning activ­
ities to be delivered to the student. 
PARSAT employs a fuzzy weights algorithm to make decisions about the learn­
ing activities to be delivered to the student. The learning activities are customized to 
the needs and personal preferences of each learner using this method. 
PARSAT uses a blended learning design that incorporates the Structure of the 
Observed Learning Outcomes (SOLO) taxonomy. Within the realm of educational 
design, the utilization of taxonomy holds a pivotal role in shaping the landscape of 
learning content and activities. This intricate framework serves as the scaffolding 
upon which learning experiences are meticulously constructed, subsequently 
enriching the student’s educational journey. In this novel approach, we seamlessly 
meld the realms of augmented reality and conventional pedagogical resources, such 
7.2  Conclusions and Discussion

162
as printed booklets, to deliver a diversified and immersive learning encounter. 
Central to the methodology lies the application of the Structure of Observed 
Learning Outcomes (SOLO) taxonomy. This taxonomy functions as the linchpin, 
orchestrating the orchestration of learning activities in a manner that guides the 
student’s progression from a rudimentary grasp of fundamental concepts to a more 
sophisticated and profound comprehension thereof. The SOLO taxonomy thus 
serves as the compass steering our pedagogical voyage towards enhanced learning 
outcomes. Furthermore, the instructional design underscores the importance of 
blended learning, fostering a learning environment where students encounter a 
spectrum of educational modalities. This multifaceted approach ensures that stu­
dents engage with an array of learning experiences, thereby augmenting their levels 
of motivation and overall engagement in the educational process. In essence, our 
comprehensive approach amalgamates pedagogical taxonomy, cutting-edge tech­
nology, and diverse learning experiences, fostering a dynamic and enriching educa­
tional milieu for students. 
PARSAT incorporates an augmented reality (AR) training environment to sup­
port the delivery of the learning activities. This environment allows students to 
interact with 3D models of technical drawing concepts and apply their spatial ability 
skills in a realistic and immersive way. The AR technology provides students with 
visual and interactive feedback, which enhances their understanding of the concepts 
and helps them to retain the information better. The use of AR also makes the learn­
ing experience more engaging and motivating for students. 
PARSAT uses visualization of 3D models to support spatial cognition. In the 
realm of technical education, the integration of three-dimensional (3D) models 
emerges as a pivotal innovation, with the primary objective of affording students a 
profound and immersive encounter with the intricacies of technical drawing con­
cepts. This innovative approach serves as a catalyst in elevating their comprehen­
sion and retention of the subject matter. The essence of our pedagogical strategy lies 
in the creation of meticulously crafted 3D models, each tailored to provide students 
with a heightened sense of realism and immersion. This immersive quality, intrinsic 
to the 3D models, fundamentally augments the students’ grasp of technical drawing 
concepts. By actively engaging with these models, students gain the unique oppor­
tunity to explore these intricate ideas from a multitude of angles and perspectives. 
This multi-dimensional interaction, in turn, cultivates and nurtures their spatial 
abilities, a critical skill set within the domain of technical drawing. In essence, our 
research elucidates the transformative impact of 3D models in the pedagogical land­
scape, underscoring their pivotal role in facilitating a deeper understanding of tech­
nical drawing concepts and the concurrent development of essential spatial abilities 
among students. Through this innovative approach, we aim to redefine the educa­
tional paradigm, enriching the learning experiences and outcomes of future techni­
cal professionals. The use of 3D visualization also supports the SOLO taxonomy 
approach, which focuses on the progression from surface-level to deeper under­
standing of concepts. By providing visual and interactive feedback, the 3D models 
facilitate this progression and enable students to develop a deeper understanding of 
the material.
7  Conclusions of AI-Driven AR in Education

163
7.3  Contribution to Intelligent Tutoring Systems 
The PARSAT system presented in this research makes a significant contribution to 
the field of intelligent tutoring systems [11–14]. According to a set of guidelines, 
limitations, or principles, an intelligent tutoring system (ITS) is a computer-based 
training system that offers individualized learner support, such as error detection, 
and task selection without the human intervention [15]. Artificial intelligence-based 
systems with the capacity to make decisions based on processing collected data in 
accordance with a set of rules are the backbone of an ITS. 
By incorporating fuzzy logic algorithms, the Mamdani inference system, and 
fuzzy weights in decision-making, PARSAT offers individualized learner support 
without human intervention. This personalized approach to training allows for the 
system to detect a student’s current level of knowledge and adapt the learning activi­
ties delivered accordingly. The use of blended learning with the SOLO taxonomy, 
augmented reality training environment, and visualization of 3D models further 
enhances the learner’s experience and supports spatial cognition. 
The PARSAT system’s ability to adapt to individual learners’ needs and provide 
personalized training is a significant step towards creating an intelligent tutoring 
system that can make decisions similarly to a human professional in the field while 
taking into account the learner’s prior knowledge. This research demonstrates the 
potential of fuzzy logic algorithms in the development of intelligent tutoring sys­
tems and opens the door to further exploration of this approach in future ITS 
research. 
There is relatively little research that integrates ITS with AR [16–19]; instead, 
both concepts are typically utilized separately in research literature [20]. Each one 
of both technologies implies a combination of highly complicated hardware and 
software elements as well as a high level of expertise across many domains, ranging 
from engineering to computer science. 
Integrating AR and ITS can provide significant benefits, such as enhancing the 
interactivity of the learning environment and enabling more personalized and adap­
tive learning experiences for students. The confluence of ITS and AR heralds a 
transformative era in education. This synergy promises to infuse intelligence into 
AR, thereby enabling the delivery of highly tailored guidance and support to learn­
ers, precisely attuned to their unique needs and proficiencies. Beyond this personal­
ized facet, AR amplifies the learning journey by offering an immersive and 
captivating educational experience, which in turn facilitates the comprehension of 
intricate concepts and ideas. Central to our exploration is the realization that the 
amalgamation of AR and ITS redefines conventional paradigms in education and 
training. This groundbreaking fusion ushers in a new era of adaptability, where 
learning is no longer confined to a one-size-fits-all approach. Instead, it pivots 
towards a bespoke educational landscape that aligns seamlessly with the specific 
requisites of individual learners. Intrinsically tied to this evolution is the ever-­
advancing frontier of technology. As technological advancements continue their 
relentless march forward, it is plausible that further research and development 
7.3  Contribution to Intelligent Tutoring Systems

164
endeavors in this domain will yield increasingly sophisticated and efficacious 
AR-ITS systems. This inexorable progression paves the way for a future where 
education and training stand at the threshold of unparalleled personalization, effi­
cacy, and engagement. 
In essence, this book investigation illuminates the remarkable potential of 
AR-ITS integration as an educational paradigm shift, offering a dynamic, adaptable, 
and deeply enriching approach to learning—one that heralds an exciting future 
where learners are empowered as never before. 
A groundbreaking innovation in the realm of Intelligent Tutoring Systems (ITS) 
unfolds as augmented reality (AR) seamlessly becomes an integral part of the learn­
ing landscape. Unlike virtual reality (VR), which constructs entirely artificial envi­
ronments, AR harmoniously blends the virtual and real-world domains. This 
immersive fusion empowers learners to interact with virtual objects and information 
within their natural surroundings, elevating the learning experience to new heights 
of interactivity. AR’s distinctive prowess shines when applied to hands-on training 
tasks that demand practical expertise and real-world application, spanning technical 
skills to physical training. By facilitating real-time feedback and information deliv­
ery in authentic contexts, AR bridges the gap between theory and practice, enhanc­
ing the efficacy of training initiatives. Additionally, AR-based intelligent tutoring 
systems can provide personalized feedback and adaptive learning activities, which 
can improve learning outcomes and engagement. 
Due of its novelty and the capacity for designing creative and attractive inter­
faces, AR has the ability to naturally engage learners. AR technology, a versatile 
marvel, finds application across a spectrum of devices, spanning desktops to smart­
phones. This ubiquity renders it a portable and adaptable tool, a transformative asset 
in the realm of education. Its engaging interface, a hallmark of AR, holds the poten­
tial to elevate the learning experience, transcending boundaries—be it within con­
ventional classrooms or specialized settings, such as those tailored to special 
education. Within the domain of learning and professional growth, AR emerges as a 
formidable force poised to redefine the pedagogical landscape. In particular, techni­
cal disciplines, notably engineering, stand to undergo a profound metamorphosis 
under AR’s influence. Yet, amidst the promise, a formidable challenge looms large: 
the development of AR applications that are not only adaptable but also scalable. 
Achieving this equilibrium is critical to the effective integration of AR across 
diverse learning environments. 
In conclusion, this book exploration unveils the multifaceted role of AR technol­
ogy as a catalyst for learning and productivity enhancements. Its pervasive presence 
across devices, coupled with its inherent engagement-enhancing capabilities, por­
tends a future where AR transcends conventional boundaries, enriching educational 
and professional pursuits. However, addressing the challenge of adaptable and scal­
able applications remains pivotal on the path to realizing AR’s transformative 
potential in diverse learning and working environments. 
Integrating AR with intelligent tutoring systems (ITS) is a promising approach to 
addressing this challenge. By tailoring learning activities to individual learners’ 
7  Conclusions of AI-Driven AR in Education

165
knowledge levels and providing personalized support, ITS can enhance the effec­
tiveness of AR-based training and improve learning outcomes. 
The research findings on the positive impact of a mobile AR application person­
alized to learners’ knowledge levels on their learning motivation are noteworthy. 
This suggests that implementing AR with ITS could be a viable solution to help 
engineers keep up with the latest knowledge and skills in their field, which is critical 
to maintaining their competitiveness. 
Personalized AR spatial ability training can make the learning process more 
engaging and exciting for students, which can have a positive impact on their moti­
vation and engagement levels. By tailoring the training activities to the individual 
learner’s knowledge level, the personalized AR application can help students feel 
more confident in their abilities and more invested in their learning. 
AR technology, with its inherently interactive nature, emerges as a groundbreak­
ing tool that promises to revolutionize spatial ability training. In contrast to conven­
tional training methodologies, AR’s dynamic interactivity provides a distinctive 
advantage in fostering effective spatial skills development. Central to AR’s efficacy 
is its ability to immerse learners in an environment where they can actively engage 
with virtual objects within a three-dimensional space. This unique capability 
empowers learners to cultivate a profound comprehension of spatial relationships, 
transcending the limitations of traditional methods. As learners interact with and 
manipulate virtual objects, they gain the invaluable ability to visualize and internal­
ize intricate concepts with greater precision. 
The integration of Intelligent Tutoring Systems into Personalized AR Spatial 
Ability Training (PARSAT) can contribute in several ways: 
The integration of ITS into PARSAT can enhance the usability of the training 
system, particularly when compared to traditional paper-based teaching booklets 
commonly used by ITS. PARSAT’s use of augmented reality can create a more 
intuitive and immersive learning experience that enhances learners’ motivation, 
engagement, and usage of the training system. Augmented reality technology can 
help learners visualize complex concepts and understand spatial relationships more 
effectively. By overlaying virtual objects onto the physical environment, PARSAT 
can create a more interactive and engaging learning experience than traditional 
teaching booklets. This can help learners stay engaged with the training and achieve 
better learning outcomes. Overall, the combination of augmented reality and ITS in 
PARSAT can create a more usable and effective training system that enhances learn­
ers’ motivation, engagement, and usage. 
The combination of ITSs with AR technology can enable users to create a cus­
tomized learning environment that enhances learning gains. By linking spatial 
information to physical locations, ITSs with AR can provide real-time spatial visu­
alization, and misconception remediation, which can increase student retention and 
engagement. Using AR technology, learners can visualize complex concepts and 
understand spatial relationships more effectively, which can enhance their compre­
hension and retention of the material. Additionally, ITSs can tailor the learning 
activities to the individual learner’s knowledge level and provide adaptive support, 
which can help learners overcome any misconceptions they may have. Overall, the 
7.3  Contribution to Intelligent Tutoring Systems

166
use of ITSs with AR technology can create a customized learning environment that 
enhances student engagement and learning gains. By combining personalized learn­
ing activities, and real-time spatial visualization, learners can overcome misconcep­
tions and better understand complex concepts, leading to improved learning 
outcomes. 
Problems in spatial ability training are typically the result of a discrepancy 
between one’s mental understanding of the spatial context and the actual rotation of 
the parts. Even experienced educators are prone to making mistakes in this area. By 
providing spatial information through monitored annotations, AR reduces these 
inaccuracies. Users employing AR interfaces perform faster than those using non-
­AR interfaces, indicating a mental model that is more accurate. AR facilitates cogni­
tive processing more efficiently than paper-based learning environments. 
Furthermore, users are not diverted by reading textbooks because AR overlays 
annotations directly on the workspace. This enhances cognitive capacity and enables 
improved learning focus. In the realm of AR learning, the fusion of the real world 
with the virtual realm heralds a cognitive efficiency breakthrough. When learners 
seamlessly meld these two domains, as exemplified in AR systems, a striking reduc­
tion in cognitive resources needed for mental representation development becomes 
evident. 
Interactivity with the surrounding environment is an integral facet of the learning 
process. As students engage with tangible objects in their surroundings, they embark 
on a journey to construct a mental model, a cognitive scaffold that underpins their 
comprehension of the subject matter. In this context, the incorporation of AR anno­
tations into the real world unveils a transformative educational landscape. AR’s 
prowess lies in the creation of an environment where learners can interact with vir­
tual objects, thereby nurturing their innate capacity to develop bespoke mental mod­
els of the domain at hand. This is achieved by seamlessly overlaying virtual objects 
onto the physical realm, a convergence that catapults learners into a realm of immer­
sive and captivating educational experiences. Within this augmented space, com­
plex concepts are visualized, and spatial relationships are grasped with enhanced 
effectiveness. Moreover, AR annotations serve as a gateway to additional layers of 
information about the environment’s objects, unveiling their functions, properties, 
and interrelationships in real-time. This real-time infusion of knowledge equips 
learners with the tools to construct a comprehensive mental model of the domain. 
Consequently, their understanding and retention of the material are significantly 
augmented. 
7.4  Contribution to Domain Knowledge Model 
Educational taxonomies offer an integrated structure and a common language that 
instructors can use to classify and arrange cognitive skills based on their complex­
ity. These taxonomies can be used to analyze existing educational materials such as 
7  Conclusions of AI-Driven AR in Education

167
learning objectives, curriculum plans, lessons, and assessments to determine which 
levels of analytical thinking they cover. 
Harnessing taxonomies as a foundational framework for crafting educational 
content empowers instructors to meticulously target desired cognitive levels. This 
strategic approach forms the cornerstone of effective learning outcomes, aligning 
the educational material with the cognitive capabilities of students. 
Incorporating AR technology into the educational landscape serves as a potent 
enhancer of these taxonomies. AR’s immersive prowess elevates the educational 
experience, offering students an engaging medium to bridge the cognitive gap. This 
dynamic technology equips learners with real-time feedback and remediation, 
unraveling complex concepts and spatial relationships with heightened efficacy. 
Moreover, the synergy of ITSs and AR technology emerges as a transformative 
educational paradigm. Instructors can now sculpt learning activities to precisely 
match each learner’s knowledge level, delivering adaptive feedback and targeted 
remedial support. This personalized approach is instrumental in dispelling miscon­
ceptions and fortifying the effectiveness of taxonomies. Consequently, students are 
furnished with bespoke learning activities that harmonize seamlessly with their cog­
nitive abilities. 
Overall, the combination of educational taxonomies with AR technology and 
ITSs can contribute to the domain knowledge model by providing students with a 
more effective and personalized learning experience. By tailoring the learning activ­
ities to the individual learner’s knowledge level and providing real-time feedback 
and remediation, students can build a more comprehensive mental model of the 
domain and improve their learning outcomes. 
Educational taxonomies can also be modified to serve as an evaluation tool by 
examining whether students exhibited the necessary level of cognition during 
assessment activities. This approach can be used to ensure that the assessment tasks 
align with the cognitive skills being addressed by the educational objectives. 
Additionally, taxonomies can be used to determine whether the cognitive skills 
being addressed by the educational objectives and assessment materials align or not. 
This process can be applied when creating new educational material or when 
reviewing existing materials. By ensuring alignment, instructors can ensure that 
students are being provided with appropriate learning activities and assessments 
that match their cognitive abilities. 
Educational taxonomies can be applied in various educational contexts and cus­
tomized to suit the specific subject being addressed [21–26]. By utilizing taxono­
mies in this way, instructors can provide students with a more effective and 
personalized learning experience. Furthermore, incorporating AR technology and 
ITSs with educational taxonomies can enhance the effectiveness of learning activi­
ties and assessments by providing real-time feedback and personalized support. 
By incorporating AR technology and ITSs into learning activities that require 
students to manipulate 3D objects, this study enhances the domain knowledge 
model by providing a more effective and engaging approach to learning. The use of 
AR technology allows students to interact with virtual objects in a more intuitive 
and immersive way, improving their understanding of the object’s geometry and 
7.4  Contribution to Domain Knowledge Model

168
properties. Furthermore, by incorporating ITSs, students receive personalized sup­
port, enabling them to progress through the domain knowledge model at their 
own pace. 
The domain knowledge model itself consists of 24 chapters, covering a range of 
topics from introductory to advanced complexity sections. By employing learning 
activities that utilize AR technology and ITSs, students are better equipped to navi­
gate the various levels of complexity and master the concepts presented in each 
chapter. Additionally, the personalized support provided by ITSs allows students to 
focus on areas where they may be struggling, while still providing a challenging 
learning experience for those who are more advanced. 
Overall, this study’s contribution to the domain knowledge model lies in its inno­
vative approach to learning and its ability to enhance student engagement, under­
standing, and mastery of complex concepts. By incorporating AR technology and 
ITSs into learning activities, the domain knowledge model becomes more accessi­
ble and effective for a wider range of learners, leading to better educational 
outcomes. 
The SOLO taxonomy stands as an invaluable scaffold, intricately guiding the 
creation of instructional activities and the development of educational products. 
This framework artfully integrates five categories of knowledge, each meticulously 
arranged in a hierarchical progression, leading learners through ascending levels of 
cognitive complexity. These five distinct categories, namely pre-structural, unis­
tructural, multi-structural, relational, and extended abstract, serve as the cornerstone 
of the SOLO taxonomy. They form a nuanced spectrum that enriches the learning 
journey, providing educators with a structured roadmap to tailor their instructional 
methods and curricular offerings. Rooted in the fertile soil of Piaget’s seminal the­
ory of cognitive development, SOLO taxonomy draws inspiration from his pro­
found insights. Piaget’s theory posits that as individuals mature and evolve, their 
cognitive capabilities undergo a transformative journey, steadily ascending the lad­
der of complexity [27]. 
The pre-structural level refers to the absence of any knowledge or understanding 
of the topic. The unistructural level signifies the acquisition of one or more pieces 
of information, but with limited understanding of the topic. The multi-structural 
level involves the connection of multiple pieces of information to form a more com­
plete understanding. The relational level signifies the connection of different aspects 
of information to form a more coherent understanding. Finally, the extended abstract 
level involves the creation of new ideas and connections beyond the current under­
standing of the topic. 
The SOLO taxonomy helps instructors to identify the current level of under­
standing of the students and develop appropriate learning activities to move them to 
the next level of understanding. It also helps in developing assessment criteria and 
rubrics by providing a mapping of levels of understanding that can be incorporated 
into the intended learning outcomes. 
The SOLO model was used in PARSAT to tailor learning activities to each stu­
dent’s level of understanding. By identifying a student’s level of knowledge using 
the SOLO taxonomy, PARSAT can provide appropriate learning activities that are 
7  Conclusions of AI-Driven AR in Education

169
neither too easy nor too difficult for the student, thereby maximizing the effective­
ness of the learning experience. 
The SOLO taxonomy provides a clear framework for defining learning outcomes 
and assessing students’ understanding of the subject matter. By mapping levels of 
understanding onto the different categories of the SOLO model, educators can cre­
ate assessment criteria and rubrics that are aligned with their learning objectives and 
tailored to the specific needs of their students. This can help ensure that students are 
able to progress through the levels of understanding and achieve the desired learn­
ing outcomes. 
Students’ cognition progresses from surface to deep to conceptual as they 
advance through the five SOLO stages. Since students learn that cognitive and utili­
tarian learning outcomes emerge from practice and the adoption of effective meth­
ods rather than innate ability, the SOLO taxonomy also encourages the formation of 
a self-motivation. 
As SOLO encourages students to assess their own progress and deliberate on 
their potential actions, students also develop metacognitive abilities. In order to 
thrive in SOLO, students also evaluate the advantages and disadvantages of their 
particular learning approach and choose their upcoming learning path carefully. 
The SOLO taxonomy, a versatile educational tool, extends its influence in diverse 
and profound ways, enriching the educational landscape on multiple fronts. First 
and foremost, SOLO taxonomy serves as a guiding light, illuminating the path to 
enhanced student learning and comprehension. By providing a structured frame­
work, it empowers educators to cultivate a deeper understanding among students, 
thereby fostering a solid foundational knowledge base. In this regard, SOLO 
becomes a cornerstone, organizing information within a coherent conceptual frame­
work. Beyond the realms of content, SOLO’s influence extends to the cognitive 
realm, nurturing the development of meta-cognition. This intricate ability enables 
learners to embark on a journey of introspection, allowing them to contemplate and 
reflect upon their own cognitive processes. This profound self-awareness is instru­
mental in honing their learning strategies, unveiling pathways for improvement and 
refinement. Incorporating SOLO taxonomy into the educational landscape goes 
beyond the dissemination of knowledge; it equips learners with the tools to become 
architects of their own learning journey. By deciphering the intricacies of their 
learning progression, students gain not only a comprehensive grasp of subject mat­
ter but also the insight and agency to enhance their learning strategies. 
7.5  Contribution to Student Modeling 
The integration of fuzzy logic into the student modeling process heralds a transfor­
mative stride in the realm of personalized learning. This innovative approach 
empowers the model to gracefully accommodate imprecise or uncertain data that 
can emerge during the assessment phase. As a result, it ushers in a new era of assess­
ment accuracy, one that is finely attuned to the intricacies and uncertainties inherent 
7.5  Contribution to Student Modeling

170
in each student’s unique learning journey. Moreover, when augmented reality (AR) 
technology harmonizes with fuzzy logic, it begets a dynamic, interactive learning 
experience that transcends conventional boundaries. This synergy amplifies student 
motivation and engagement, propelling the learning process to new heights of inter­
activity and immersion. At its essence, this approach to student modeling signifies a 
seminal stride forward in the realm of evaluating students’ knowledge and compe­
tencies. By embracing the nuances and intricacies inherent to each student’s indi­
vidual learning journey, it charts a course toward assessments that are not only more 
precise but also inherently more effective. The ultimate beneficiaries are the learn­
ers, as this approach is poised to elevate the quality of their learning outcomes. 
The student model, a cornerstone of personalized learning, embodies a student’s 
knowledge, skills, and abilities, culled from a diverse array of data sources, includ­
ing assessments, performance metrics, and demographic particulars. Once forged, 
this model metamorphoses into a compass, steering the learner through personal­
ized recommendations for learning activities, resources, and assessments. Indeed, 
crafting an effective student model is the linchpin for designing an adaptive training 
system that optimizes the learning experience. As elucidated by [28], the student 
model serves as an avatar, a virtual representation of the student in the educational 
ecosystem. Its dimensions echo the facets of the student’s capabilities, and its attri­
butes mirror the student’s unique characteristics. 
The use of fuzzy logic in student modeling can improve the accuracy of the 
model by allowing for the representation of uncertainty and imprecision. Fuzzy 
logic is a mathematical framework for dealing with uncertainty and imprecision in 
data. By incorporating fuzzy sets to represent a student’s current level of under­
standing, the model can more accurately represent the student’s knowledge state. 
Overall, this study’s contribution to student modeling is the use of fuzzy logic to 
assess students’ knowledge level through AR technology, which can lead to more 
personalized and effective training systems for engineering students’ spatial skills. 
In order to create an effective student model, it is important to identify what data 
about students should be represented. This can include demographic information, 
academic performance data, learning style preferences, and more. Additionally, 
selecting the appropriate modeling methodologies is crucial in order to effectively 
utilize the data collected. These methodologies can range from statistical and 
machine learning techniques to more traditional rule-based approaches. 
In an adaptive tutoring system, student modeling is regarded as a crucial task 
since it facilitates the representation of students’ profiles, which can then be utilized 
to adapt the training session. Therefore, a comprehensive identification of the fea­
tures of the students is necessary for the development of an effective adaptive train­
ing system. There are two different kinds of student characteristic integrated in 
PARSAT, namely the static characteristics, which can be obtained at the start page 
of the application through questionnaires, and dynamic characteristics, which can 
be acquired by analyzing how the users interacts as they engage with the system. 
Since these features represent the students’ needs and preferences, it is challenging 
to identify the dynamic student features that are thought to be crucial to the adaption 
process. By incorporating both static and dynamic student characteristics in the 
7  Conclusions of AI-Driven AR in Education

171
student model, PARSAT is able to provide a personalized and adaptive learning 
experience to each student. 
In the realm of student modeling, the quintessential feature most frequently 
under scrutiny is the student’s knowledge level. This encompasses not only their 
existing grasp of subject matter but also their prior knowledge in the field. To gauge 
a student’s competence accurately, diverse methods come into play, including tests, 
questionnaires, and the meticulous analysis of their interactions with the training 
system. This multifaceted approach facilitates a dynamic and precise representation 
of the student’s knowledge level, one that evolves over time and adapts in response 
to ongoing interactions with the educational system. 
Students who used PARSAT had varying levels of prior knowledge in the area of 
technical drawing, which resulted in having varying learning demands. To deter­
mine each learner’s instructional needs and knowledge level in order to give them 
the most suitable learning path and content, the proposed AR system was devel­
oped. The majority of the most recent adaptive educational software uses a student 
model to determine the student’s knowledge level. By using a student model, 
PARSAT can determine each learner’s knowledge level and provide them with a 
personalized learning path and content that suits their needs. 
Cognitive features are challenging to anticipate and represent in a student model 
because they are related to a student’s mental processes and abilities. These attri­
butes are often not directly observable, and their representation requires more com­
plex modeling techniques. While it may not offer a complete picture, delving into 
students’ performance and their interactions within the system affords a glimpse 
into their cognitive abilities. This invaluable insight, though partial, serves as a 
foundation for personalizing the learning experience. Armed with this data, educa­
tors can tailor their approach, delivering tailored support to each student, thus 
enhancing their educational journey. 
This study contributes by exploring fuzzy logic as a tool for assessing students’ 
knowledge levels through AR technology. In the proposed model, six fuzzy sets 
representing the students’ current level of understanding were incorporated, namely 
novice, beginner, competent, very good, proficient and expert, providing a meaning­
ful addition to the standard training method of engineering students’ spatial skills. 
The fuzzy logic-based approach to assessing students’ knowledge levels through 
AR technology is a novel contribution that has not been explored extensively in the 
past. The incorporation of six fuzzy sets representing different levels of understand­
ing, ranging from novice to expert, provides a more nuanced assessment of stu­
dents’ knowledge levels. Furthermore, the study conducted an assessment of the 
collective performance of students who embraced the proposed methodology, dem­
onstrating its efficacy in augmenting their interactive proficiencies. In summation, 
this investigation presents a significant addition to the realm of spatial ability train­
ing, thereby opening a promising avenue for future research endeavors within 
this domain.
7.5  Contribution to Student Modeling

172
7.6  Contribution to Electronic Assessment 
This study contributes to electronic assessment by incorporating an algorithm that 
collects data on the student’s performance during the training session, including the 
number of assessment errors made. This data is then used to personalize the learning 
activities delivered to the student. By providing real-time feedback and personalized 
learning activities, PARSAT enables electronic assessment that is tailored to each 
student’s unique needs and knowledge level. Additionally, the use of AR technology 
in PARSAT provides a novel and engaging way for students to be assessed and 
trained in their spatial abilities. Overall, PARSAT offers a promising approach for 
incorporating electronic assessment into spatial ability training. 
Additionally, PARSAT also considers dynamic input parameters such as video-­
based duration, augmented reality interaction duration, and the number of assess­
ment errors made by the student. The system utilizes a fuzzy logic algorithm and a 
Mamdani inference system to map these input parameters to specific knowledge 
levels and deliver personalized learning activities based on the student’s current 
level of knowledge. The use of augmented reality and visualization of 3D models 
further enhances the spatial cognition training provided by PARSAT. 
The rest of the input parameters that contribute to the knowledge level are: age, 
which can affect the student’s learning needs and can take a value amongst three age 
categories, namely high school students (15–17 years old), first-year university stu­
dents (18–19 years old), and older university students (more than 20 years old), 
gender, which can also affect the learning needs and takes values, namely male, 
female, and non-binary, and prior knowledge, which refers to the prior academic 
performance. 
The fuzzy weights algorithm in PARSAT uses fuzzy logic to assign weights to 
different learning activities based on their relevance and importance to the learner’s 
current knowledge level. This allows the system to prioritize and personalize learn­
ing activities for each individual learner. 
The SOLO taxonomy is used as a framework for designing learning activities 
that match the learner’s current cognitive level. The taxonomy distinguishes between 
different levels of understanding, ranging from pre-structural (no understanding) to 
extended abstract (deep understanding and transfer of knowledge to new contexts). 
By designing learning activities that match the learner’s current level of understand­
ing, the system can provide appropriate challenges and support to enhance the 
learner’s knowledge acquisition. 
Overall, the combination of fuzzy weights algorithm and SOLO taxonomy in 
PARSAT enables the system to deliver personalized and adaptive learning activities 
that match the learner’s knowledge level and enhance their spatial cognition skills. 
The system evaluation’s findings show a high level of student satisfaction and an 
improvement in their learning outcomes, which is positive. Students specifically 
gave this innovative training technique a high rating, indicating the suitability of the 
volume and complexity of the learning activities as well as the reliability of the 
learning activities presented according to their knowledge level.
7  Conclusions of AI-Driven AR in Education

173
Additionally, a considerable improvement in students’ scores between the pre-­
test and post-test evaluation supported the pedagogical suitability of the suggested 
training intervention. Results showed that the proposed system outperformed its 
conventional version in terms of boosting learning outcomes, enhancing the effec­
tiveness of the adaptivity adopted and the usage of SOLO taxonomy, as well as vali­
dating the efficacy of the training technique. 
7.7  Future Work 
This book presented a novel adaptive spatial ability training system, which applies 
pedagogical theories in system design, incorporates student modeling, enhances 
spatial visualization by 3D models’ rendering, and provides the student with differ­
ent learning activities, in accordance with the student profile and SOLO taxonomy. 
The evaluation results showed promising outcomes, and the study suggested several 
directions for future research in this field. 
In the realm of mobile AR applications, a notable challenge pertains to the con­
strained screen size of mobile devices, posing difficulties in rendering intricate 3D 
models and graphics. Furthermore, the inherent diversity in hardware and software 
configurations among various mobile devices presents a formidable obstacle in 
achieving uniform performance and functionality across the spectrum. Nevertheless, 
despite these inherent challenges, the adoption of mobile devices for augmented 
reality applications has witnessed a remarkable upsurge in popularity. This surge 
can be attributed to the ubiquity and convenience afforded by these devices, under­
scoring the enduring potential and allure of mobile-based AR experiences. 
Regarding the architecture of the system, the study integrated Augmented Reality 
to mobile phones, and thus to the general public. Implementing technologies on 
limited devices, such as smartphones and tablets, poses a number of challenges. 
These include the limited computational resources with little or no possibility to 
upgrade or add hardware. 
Head-mounted display (HMD) devices represent a frontier brimming with pos­
sibilities for the integration of AR technologies, promising an enriched and immer­
sive user experience. However, a significant hurdle looms in the form of the 
substantial cost associated with HMDs, limiting their widespread accessibility. 
Nevertheless, with the inexorable march of technological progress, coupled with 
corresponding price reductions, a future marked by more affordable and attainable 
HMD devices appears imminent. 
In the interim, the optimization of AR experiences on handheld devices remains 
paramount, necessitating innovative strategies to overcome inherent hardware and 
computational constraints. Designing AR applications for smartphones or tablets, 
while considerably constrained in comparison to dedicated HMDs, warrants dedi­
cated attention. The inherent limitations must be meticulously addressed to ensure 
user-friendliness and alignment with the augmented activity’s objectives.
7.7  Future Work

174
The horizon beckons towards a potential transition from handheld applications to 
HMD devices in forthcoming system upgrades. Despite the current financial barri­
ers to entry, global market trends augur a scenario wherein cost constraints gradu­
ally recede, thus facilitating broader product adoption. 
In conclusion, extending the research’s temporal purview to encompass multiple 
semesters offers a unique vantage point for evaluating the long-term influence of the 
proposed system on students’ spatial ability and their receptivity to AR technology. 
Furthermore, enlarging the sample size holds promise in augmenting the study’s 
findings’ generalizability, thus enriching the empirical foundations of AR in educa­
tional contexts. 
References 
1.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “PARSAT: Fuzzy logic for 
adaptive spatial ability training in an augmented reality system.,” Computer Science and 
Information Systems, vol. 20, no. 4, 2023, https://doi.org/10.2298/CSIS230130043P. 
2.	C.  Papakostas, C.  Troussas, A.  Krouska, and C.  Sgouropoulou, “Personalization of the 
Learning Path within an Augmented Reality Spatial Ability Training Application Based on 
Fuzzy Weights,” Sensors, vol. 22, no. 18, 2022, https://doi.org/10.3390/s22187059. 
3.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Dynamic Detection of Learning Modalities 
Using Fuzzy Logic in Students’ Interaction Activities,” in Intelligent Tutoring Systems, 
V. Kumar and C. Troussas, Eds., Cham: Springer International Publishing, 2020, pp. 205–213. 
4.	A. Krouska, C. Troussas, and C. Sgouropoulou, “Fuzzy Logic for Refining the Evaluation 
of Learners’ Performance in Online Engineering Education,” European Journal of 
Engineering Research and Science, vol. 4, pp. 50–56, Jun. 2019, https://doi.org/10.24018/ 
ejers.2019.4.6.1369. 
5.	A. Krouska, C. Troussas, K. Kabassi, and C. Sgouropoulou, “An Empirical Investigation of 
User Acceptance of Personalized Mobile Software for Sustainability Education,” Int J Hum 
Comput Interact, pp. 1–8, Aug. 2023, https://doi.org/10.1080/10447318.2023.2241614. 
6.	A. Marougkas, C. Troussas, A. Krouska, and C. Sgouropoulou, “A Framework for Personalized 
Fully Immersive Virtual Reality Learning Environments with Gamified Design in Education,” 
2021. https://doi.org/10.3233/FAIA210080. 
7.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Measuring User Experience, 
Usability and Interactivity of a Personalized Mobile Augmented Reality Training System,” 
Sensors, vol. 21, no. 11, p. 3888, Jun. 2021, https://doi.org/10.3390/s21113888. 
8.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Exploring Users’ Behavioral 
Intention to Adopt Mobile Augmented Reality in Education through an Extended Technology 
Acceptance Model,” Int J Hum Comput Interact, vol. 39, no. 6, pp. 1294–1302, 2023, https:// 
doi.org/10.1080/10447318.2022.2062551. 
9.	C. Troussas, C. Papakostas, A. Krouska, P. Mylonas, and C. Sgouropoulou, “Personalized 
Feedback Enhanced by Natural Language Processing in Intelligent Tutoring Systems,” 
in Augmented Intelligence and Intelligent Tutoring Systems, C.  Frasson, P.  Mylonas, and 
C.  Troussas, Eds., Cham: Springer Nature Switzerland, 2023, pp.  667–677. https://doi. 
org/10.1007/978-­3-­031-­32883-­1_58. 
10.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Modeling the Knowledge of 
Users in an Augmented Reality-Based Learning Environment Using Fuzzy Logic,” in Lecture 
Notes in Networks and Systems, A. Krouska, C. Troussas, and J. Caro, Eds., Cham: Springer 
International Publishing, 2023, pp. 113–123. https://doi.org/10.1007/978-­3-­031-­17601-­2_12.
7  Conclusions of AI-Driven AR in Education

175
11.	F. Giannakas, C. Troussas, A. Krouska, C. Sgouropoulou, and I. Voyiatzis, “XGBoost and 
Deep Neural Network Comparison: The Case of Teams’ Performance,” in Intelligent Tutoring 
Systems, A. I. Cristea and C. Troussas, Eds., Cham: Springer International Publishing, 2021, 
pp. 343–349. 
12.	A. Krouska, C. Troussas, and C. Sgouropoulou, “A novel group recommender system for 
domain-independent decision support customizing a grouping genetic algorithm,” User Model 
User-adapt Interact, 2023, https://doi.org/10.1007/s11257-­023-­09360-­3. 
13.	C.  Papakostas, C.  Troussas, P.  Douros, M.  Poli, and C.  Sgouropoulou, “CoMoPAR: A 
Comprehensive Conceptual Model for Designing Personalized Augmented Reality Systems 
in Education,” in Novel & Intelligent Digital Systems: Proceedings of the 3rd International 
Conference (NiDS 2023), K. Kabassi, P. Mylonas, and J. Caro, Eds., Cham: Springer Nature 
Switzerland, 2023, pp. 67–79. 
14.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “On the development of a 
personalized augmented reality spatial ability training mobile application,” in Frontiers in 
Artificial Intelligence and Applications, IOS Press, 2021, pp. V–VI. https://doi.org/10.3233/ 
FAIA210078. 
15.	A. C. Latham Keeley; McLean David; Edmonds Bruce, “A conversational intelligent tutoring 
system to automatically predict learning styles,” Comput Educ, vol. 59, no. 1, pp. 95–109, 
2012, https://doi.org/10.1016/j.compedu.2011.11.001. 
16.	M. Iakovidis, C. Papakostas, C. Troussas, and C. Sgouropoulou, “Empowering Responsible 
Digital Citizenship Through an Augmented Reality Educational Game,” in Novel & Intelligent 
Digital Systems: Proceedings of the 3rd International Conference (NiDS 2023), K. Kabassi, 
P. Mylonas, and J. Caro, Eds., Cham: Springer Nature Switzerland, 2023, pp. 31–39. 
17.	P.  Strousopoulos, C.  Troussas, C.  Papakostas, A.  Krouska, and C.  Sgouropoulou, 
“Revolutionizing Agricultural Education with Virtual Reality and Gamification: A Novel 
Approach for Enhancing Knowledge Transfer and Skill Acquisition,” in Novel & Intelligent 
Digital Systems: Proceedings of the 3rd International Conference (NiDS 2023), K. Kabassi, 
P. Mylonas, and J. Caro, Eds., Cham: Springer Nature Switzerland, 2023, pp. 67–80. 
18.	P. Strousopoulos, C. Papakostas, C. Troussas, A. Krouska, P. Mylonas, and C. Sgouropoulou, 
“SculptMate: Personalizing Cultural Heritage Experience Using Fuzzy Weights,” in Adjunct 
Proceedings of the 31st ACM Conference on User Modeling, Adaptation and Personalization, 
in UMAP ’23 Adjunct. New York, NY, USA: Association for Computing Machinery, 2023, 
pp. 397–407. https://doi.org/10.1145/3563359.3596667. 
19.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Exploration of Augmented 
Reality in Spatial Abilities Training: A Systematic Literature Review for the Last Decade,” 
Informatics in Education, vol. 20, no. 1, pp. 107–130, Mar. 2021, https://doi.org/10.15388/ 
infedu.2021.06. 
20.	B.  Herbert, B.  Ens, A.  Weerasinghe, M.  Billinghurst, and G.  Wigley, “Design consider­
ations for combining augmented reality with intelligent tutors,” Comput Graph, vol. 77, 
pp. 166–182, 2018. 
21.	Z. Kanetaki et al., “Acquiring, Analyzing and Interpreting Knowledge Data for Sustainable 
Engineering Education: An Experimental Study Using YouTube,” Electronics (Basel), vol. 11, 
no. 14, 2022, https://doi.org/10.3390/electronics11142210. 
22.	A. Marougkas, C. Troussas, A. Krouska, and C. Sgouropoulou, “Virtual Reality in Education: 
A Review of Learning Theories, Approaches and Methodologies for the Last Decade,” 
Electronics (Basel), vol. 12, no. 13, 2023, https://doi.org/10.3390/electronics12132832. 
23.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Enriching Mobile Learning Software with 
Interactive Activities and Motivational Feedback for Advancing Users’ High-Level Cognitive 
Skills,” Computers, vol. 11, no. 2, 2022, https://doi.org/10.3390/computers11020018. 
24.	C. Troussas, A. Krouska, and C. Sgouropoulou, “Towards a Reference Model to Ensure the 
Quality of Massive Open Online Courses and E-Learning,” in Brain Function Assessment 
in Learning, C.  Frasson, P.  Bamidis, and P.  Vlamos, Eds., Cham: Springer International 
Publishing, 2020, pp. 169–175.
References

176
25.	A.  Marougkas, C.  Troussas, A.  Krouska, and C.  Sgouropoulou, “How personalized and 
effective is immersive virtual reality in education? A systematic literature review for the last 
decade,” Multimed Tools Appl, 2023, https://doi.org/10.1007/s11042-­023-­15986-­7. 
26.	C. Papakostas, C. Troussas, A. Krouska, and C. Sgouropoulou, “User acceptance of augmented 
reality welding simulator in engineering training,” Educ Inf Technol (Dordr), vol. 27, no. 1, 
pp. 791–817, Jan. 2022, https://doi.org/10.1007/s10639-­020-­10418-­7. 
27.	J.  Piaget, “Épistémologie génétique et méthodologie dialectique II,” Dialectica, 
pp. 287–295, 1950. 
28.	G. Yang, Kinshuk, and S. Graf, “A practical student model for a location-aware and context-­
sensitive Personalized Adaptive Learning System,” in 2010 International Conference on 
Technology for Education, 2010, pp. 130–133. https://doi.org/10.1109/T4E.2010.5550048.
7  Conclusions of AI-Driven AR in Education

